commit 4eaf0b5c5e04c21a866431bd763ab4b1f24c4d16
Author: Andrii Nakryiko <andriin@fb.com>
Date:   Tue May 12 12:24:44 2020 -0700

    selftest/bpf: Fmod_ret prog and implement test_overhead as part of bench
    
    Add fmod_ret BPF program to existing test_overhead selftest. Also re-implement
    user-space benchmarking part into benchmark runner to compare results. Results
    with ./bench are consistently somewhat lower than test_overhead's, but relative
    performance of various types of BPF programs stay consisten (e.g., kretprobe is
    noticeably slower). This slowdown seems to be coming from the fact that
    test_overhead is single-threaded, while benchmark always spins off at least
    one thread for producer. This has been confirmed by hacking multi-threaded
    test_overhead variant and also single-threaded bench variant. Resutls are
    below. run_bench_rename.sh script from benchs/ subdirectory was used to
    produce results for ./bench.
    
    Single-threaded implementations
    ===============================
    
    /* bench: single-threaded, atomics */
    base      :    4.622 ± 0.049M/s
    kprobe    :    3.673 ± 0.052M/s
    kretprobe :    2.625 ± 0.052M/s
    rawtp     :    4.369 ± 0.089M/s
    fentry    :    4.201 ± 0.558M/s
    fexit     :    4.309 ± 0.148M/s
    fmodret   :    4.314 ± 0.203M/s
    
    /* selftest: single-threaded, no atomics */
    task_rename base        4555K events per sec
    task_rename kprobe      3643K events per sec
    task_rename kretprobe   2506K events per sec
    task_rename raw_tp      4303K events per sec
    task_rename fentry      4307K events per sec
    task_rename fexit       4010K events per sec
    task_rename fmod_ret    3984K events per sec
    
    Multi-threaded implementations
    ==============================
    
    /* bench: multi-threaded w/ atomics */
    base      :    3.910 ± 0.023M/s
    kprobe    :    3.048 ± 0.037M/s
    kretprobe :    2.300 ± 0.015M/s
    rawtp     :    3.687 ± 0.034M/s
    fentry    :    3.740 ± 0.087M/s
    fexit     :    3.510 ± 0.009M/s
    fmodret   :    3.485 ± 0.050M/s
    
    /* selftest: multi-threaded w/ atomics */
    task_rename base        3872K events per sec
    task_rename kprobe      3068K events per sec
    task_rename kretprobe   2350K events per sec
    task_rename raw_tp      3731K events per sec
    task_rename fentry      3639K events per sec
    task_rename fexit       3558K events per sec
    task_rename fmod_ret    3511K events per sec
    
    /* selftest: multi-threaded, no atomics */
    task_rename base        3945K events per sec
    task_rename kprobe      3298K events per sec
    task_rename kretprobe   2451K events per sec
    task_rename raw_tp      3718K events per sec
    task_rename fentry      3782K events per sec
    task_rename fexit       3543K events per sec
    task_rename fmod_ret    3526K events per sec
    
    Note that the fact that ./bench benchmark always uses atomic increments for
    counting, while test_overhead doesn't, doesn't influence test results all that
    much.
    
    Signed-off-by: Andrii Nakryiko <andriin@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: John Fastabend <john.fastabend@gmail.com>
    Acked-by: Yonghong Song <yhs@fb.com>
    Link: https://lore.kernel.org/bpf/20200512192445.2351848-4-andriin@fb.com

diff --git a/tools/testing/selftests/bpf/benchs/bench_rename.c b/tools/testing/selftests/bpf/benchs/bench_rename.c
new file mode 100644
index 000000000000..e74cff40f4fe
--- /dev/null
+++ b/tools/testing/selftests/bpf/benchs/bench_rename.c
@@ -0,0 +1,195 @@
+// SPDX-License-Identifier: GPL-2.0
+/* Copyright (c) 2020 Facebook */
+#include <fcntl.h>
+#include "bench.h"
+#include "test_overhead.skel.h"
+
+/* BPF triggering benchmarks */
+static struct ctx {
+	struct test_overhead *skel;
+	struct counter hits;
+	int fd;
+} ctx;
+
+static void validate()
+{
+	if (env.producer_cnt != 1) {
+		fprintf(stderr, "benchmark doesn't support multi-producer!\n");
+		exit(1);
+	}
+	if (env.consumer_cnt != 1) {
+		fprintf(stderr, "benchmark doesn't support multi-consumer!\n");
+		exit(1);
+	}
+}
+
+static void *producer(void *input)
+{
+	char buf[] = "test_overhead";
+	int err;
+
+	while (true) {
+		err = write(ctx.fd, buf, sizeof(buf));
+		if (err < 0) {
+			fprintf(stderr, "write failed\n");
+			exit(1);
+		}
+		atomic_inc(&ctx.hits.value);
+	}
+}
+
+static void measure(struct bench_res *res)
+{
+	res->hits = atomic_swap(&ctx.hits.value, 0);
+}
+
+static void setup_ctx()
+{
+	setup_libbpf();
+
+	ctx.skel = test_overhead__open_and_load();
+	if (!ctx.skel) {
+		fprintf(stderr, "failed to open skeleton\n");
+		exit(1);
+	}
+
+	ctx.fd = open("/proc/self/comm", O_WRONLY|O_TRUNC);
+	if (ctx.fd < 0) {
+		fprintf(stderr, "failed to open /proc/self/comm: %d\n", -errno);
+		exit(1);
+	}
+}
+
+static void attach_bpf(struct bpf_program *prog)
+{
+	struct bpf_link *link;
+
+	link = bpf_program__attach(prog);
+	if (IS_ERR(link)) {
+		fprintf(stderr, "failed to attach program!\n");
+		exit(1);
+	}
+}
+
+static void setup_base()
+{
+	setup_ctx();
+}
+
+static void setup_kprobe()
+{
+	setup_ctx();
+	attach_bpf(ctx.skel->progs.prog1);
+}
+
+static void setup_kretprobe()
+{
+	setup_ctx();
+	attach_bpf(ctx.skel->progs.prog2);
+}
+
+static void setup_rawtp()
+{
+	setup_ctx();
+	attach_bpf(ctx.skel->progs.prog3);
+}
+
+static void setup_fentry()
+{
+	setup_ctx();
+	attach_bpf(ctx.skel->progs.prog4);
+}
+
+static void setup_fexit()
+{
+	setup_ctx();
+	attach_bpf(ctx.skel->progs.prog5);
+}
+
+static void setup_fmodret()
+{
+	setup_ctx();
+	attach_bpf(ctx.skel->progs.prog6);
+}
+
+static void *consumer(void *input)
+{
+	return NULL;
+}
+
+const struct bench bench_rename_base = {
+	.name = "rename-base",
+	.validate = validate,
+	.setup = setup_base,
+	.producer_thread = producer,
+	.consumer_thread = consumer,
+	.measure = measure,
+	.report_progress = hits_drops_report_progress,
+	.report_final = hits_drops_report_final,
+};
+
+const struct bench bench_rename_kprobe = {
+	.name = "rename-kprobe",
+	.validate = validate,
+	.setup = setup_kprobe,
+	.producer_thread = producer,
+	.consumer_thread = consumer,
+	.measure = measure,
+	.report_progress = hits_drops_report_progress,
+	.report_final = hits_drops_report_final,
+};
+
+const struct bench bench_rename_kretprobe = {
+	.name = "rename-kretprobe",
+	.validate = validate,
+	.setup = setup_kretprobe,
+	.producer_thread = producer,
+	.consumer_thread = consumer,
+	.measure = measure,
+	.report_progress = hits_drops_report_progress,
+	.report_final = hits_drops_report_final,
+};
+
+const struct bench bench_rename_rawtp = {
+	.name = "rename-rawtp",
+	.validate = validate,
+	.setup = setup_rawtp,
+	.producer_thread = producer,
+	.consumer_thread = consumer,
+	.measure = measure,
+	.report_progress = hits_drops_report_progress,
+	.report_final = hits_drops_report_final,
+};
+
+const struct bench bench_rename_fentry = {
+	.name = "rename-fentry",
+	.validate = validate,
+	.setup = setup_fentry,
+	.producer_thread = producer,
+	.consumer_thread = consumer,
+	.measure = measure,
+	.report_progress = hits_drops_report_progress,
+	.report_final = hits_drops_report_final,
+};
+
+const struct bench bench_rename_fexit = {
+	.name = "rename-fexit",
+	.validate = validate,
+	.setup = setup_fexit,
+	.producer_thread = producer,
+	.consumer_thread = consumer,
+	.measure = measure,
+	.report_progress = hits_drops_report_progress,
+	.report_final = hits_drops_report_final,
+};
+
+const struct bench bench_rename_fmodret = {
+	.name = "rename-fmodret",
+	.validate = validate,
+	.setup = setup_fmodret,
+	.producer_thread = producer,
+	.consumer_thread = consumer,
+	.measure = measure,
+	.report_progress = hits_drops_report_progress,
+	.report_final = hits_drops_report_final,
+};
