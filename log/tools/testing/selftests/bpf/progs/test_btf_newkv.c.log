commit e1cebd841b0aa1ceda771706d54a0501986a3c88
Author: Stanislav Fomichev <sdf@google.com>
Date:   Tue Apr 21 17:37:53 2020 -0700

    selftests/bpf: Fix a couple of broken test_btf cases
    
    Commit 51c39bb1d5d1 ("bpf: Introduce function-by-function verification")
    introduced function linkage flag and changed the error message from
    "vlen != 0" to "Invalid func linkage" and broke some fake BPF programs.
    
    Adjust the test accordingly.
    
    AFACT, the programs don't really need any arguments and only look
    at BTF for maps, so let's drop the args altogether.
    
    Before:
    BTF raw test[103] (func (Non zero vlen)): do_test_raw:3703:FAIL expected
    err_str:vlen != 0
    magic: 0xeb9f
    version: 1
    flags: 0x0
    hdr_len: 24
    type_off: 0
    type_len: 72
    str_off: 72
    str_len: 10
    btf_total_size: 106
    [1] INT (anon) size=4 bits_offset=0 nr_bits=32 encoding=SIGNED
    [2] INT (anon) size=4 bits_offset=0 nr_bits=32 encoding=(none)
    [3] FUNC_PROTO (anon) return=0 args=(1 a, 2 b)
    [4] FUNC func type_id=3 Invalid func linkage
    
    BTF libbpf test[1] (test_btf_haskv.o): libbpf: load bpf program failed:
    Invalid argument
    libbpf: -- BEGIN DUMP LOG ---
    libbpf:
    Validating test_long_fname_2() func#1...
    Arg#0 type PTR in test_long_fname_2() is not supported yet.
    processed 0 insns (limit 1000000) max_states_per_insn 0 total_states 0
    peak_states 0 mark_read 0
    
    libbpf: -- END LOG --
    libbpf: failed to load program 'dummy_tracepoint'
    libbpf: failed to load object 'test_btf_haskv.o'
    do_test_file:4201:FAIL bpf_object__load: -4007
    BTF libbpf test[2] (test_btf_newkv.o): libbpf: load bpf program failed:
    Invalid argument
    libbpf: -- BEGIN DUMP LOG ---
    libbpf:
    Validating test_long_fname_2() func#1...
    Arg#0 type PTR in test_long_fname_2() is not supported yet.
    processed 0 insns (limit 1000000) max_states_per_insn 0 total_states 0
    peak_states 0 mark_read 0
    
    libbpf: -- END LOG --
    libbpf: failed to load program 'dummy_tracepoint'
    libbpf: failed to load object 'test_btf_newkv.o'
    do_test_file:4201:FAIL bpf_object__load: -4007
    BTF libbpf test[3] (test_btf_nokv.o): libbpf: load bpf program failed:
    Invalid argument
    libbpf: -- BEGIN DUMP LOG ---
    libbpf:
    Validating test_long_fname_2() func#1...
    Arg#0 type PTR in test_long_fname_2() is not supported yet.
    processed 0 insns (limit 1000000) max_states_per_insn 0 total_states 0
    peak_states 0 mark_read 0
    
    libbpf: -- END LOG --
    libbpf: failed to load program 'dummy_tracepoint'
    libbpf: failed to load object 'test_btf_nokv.o'
    do_test_file:4201:FAIL bpf_object__load: -4007
    
    Fixes: 51c39bb1d5d1 ("bpf: Introduce function-by-function verification")
    Signed-off-by: Stanislav Fomichev <sdf@google.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/bpf/20200422003753.124921-1-sdf@google.com

diff --git a/tools/testing/selftests/bpf/progs/test_btf_newkv.c b/tools/testing/selftests/bpf/progs/test_btf_newkv.c
index a924e53c8e9d..6c5560162746 100644
--- a/tools/testing/selftests/bpf/progs/test_btf_newkv.c
+++ b/tools/testing/selftests/bpf/progs/test_btf_newkv.c
@@ -28,20 +28,12 @@ struct {
 	__type(value, struct ipv_counts);
 } btf_map SEC(".maps");
 
-struct dummy_tracepoint_args {
-	unsigned long long pad;
-	struct sock *sock;
-};
-
 __attribute__((noinline))
-int test_long_fname_2(struct dummy_tracepoint_args *arg)
+int test_long_fname_2(void)
 {
 	struct ipv_counts *counts;
 	int key = 0;
 
-	if (!arg->sock)
-		return 0;
-
 	counts = bpf_map_lookup_elem(&btf_map, &key);
 	if (!counts)
 		return 0;
@@ -57,15 +49,15 @@ int test_long_fname_2(struct dummy_tracepoint_args *arg)
 }
 
 __attribute__((noinline))
-int test_long_fname_1(struct dummy_tracepoint_args *arg)
+int test_long_fname_1(void)
 {
-	return test_long_fname_2(arg);
+	return test_long_fname_2();
 }
 
 SEC("dummy_tracepoint")
-int _dummy_tracepoint(struct dummy_tracepoint_args *arg)
+int _dummy_tracepoint(void *arg)
 {
-	return test_long_fname_1(arg);
+	return test_long_fname_1();
 }
 
 char _license[] SEC("license") = "GPL";

commit 3e689141e64df91b009a289c0559adedfe62f511
Author: Toke Høiland-Jørgensen <toke@redhat.com>
Date:   Mon Jan 20 14:06:45 2020 +0100

    selftests: Use consistent include paths for libbpf
    
    Fix all selftests to include libbpf header files with the bpf/ prefix, to
    be consistent with external users of the library. Also ensure that all
    includes of exported libbpf header files (those that are exported on 'make
    install' of the library) use bracketed includes instead of quoted.
    
    To not break the build, keep the old include path until everything has been
    changed to the new one; a subsequent patch will remove that.
    
    Fixes: 6910d7d3867a ("selftests/bpf: Ensure bpf_helper_defs.h are taken from selftests dir")
    Signed-off-by: Toke Høiland-Jørgensen <toke@redhat.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Andrii Nakryiko <andriin@fb.com>
    Link: https://lore.kernel.org/bpf/157952560568.1683545.9649335788846513446.stgit@toke.dk

diff --git a/tools/testing/selftests/bpf/progs/test_btf_newkv.c b/tools/testing/selftests/bpf/progs/test_btf_newkv.c
index fb8d91a1dbe0..a924e53c8e9d 100644
--- a/tools/testing/selftests/bpf/progs/test_btf_newkv.c
+++ b/tools/testing/selftests/bpf/progs/test_btf_newkv.c
@@ -1,7 +1,7 @@
 /* SPDX-License-Identifier: GPL-2.0 */
 /* Copyright (c) 2018 Facebook */
 #include <linux/bpf.h>
-#include "bpf_helpers.h"
+#include <bpf/bpf_helpers.h>
 #include "bpf_legacy.h"
 
 int _version SEC("version") = 1;

commit a0d7da26ce86a25e97ae191cb90574ada6daea98
Author: Andrii Nakryiko <andriin@fb.com>
Date:   Tue Nov 19 14:44:47 2019 -0800

    libbpf: Fix call relocation offset calculation bug
    
    When relocating subprogram call, libbpf doesn't take into account
    relo->text_off, which comes from symbol's value. This generally works fine for
    subprograms implemented as static functions, but breaks for global functions.
    
    Taking a simplified test_pkt_access.c as an example:
    
    __attribute__ ((noinline))
    static int test_pkt_access_subprog1(volatile struct __sk_buff *skb)
    {
            return skb->len * 2;
    }
    
    __attribute__ ((noinline))
    static int test_pkt_access_subprog2(int val, volatile struct __sk_buff *skb)
    {
            return skb->len + val;
    }
    
    SEC("classifier/test_pkt_access")
    int test_pkt_access(struct __sk_buff *skb)
    {
            if (test_pkt_access_subprog1(skb) != skb->len * 2)
                    return TC_ACT_SHOT;
            if (test_pkt_access_subprog2(2, skb) != skb->len + 2)
                    return TC_ACT_SHOT;
            return TC_ACT_UNSPEC;
    }
    
    When compiled, we get two relocations, pointing to '.text' symbol. .text has
    st_value set to 0 (it points to the beginning of .text section):
    
    0000000000000008  000000050000000a R_BPF_64_32            0000000000000000 .text
    0000000000000040  000000050000000a R_BPF_64_32            0000000000000000 .text
    
    test_pkt_access_subprog1 and test_pkt_access_subprog2 offsets (targets of two
    calls) are encoded within call instruction's imm32 part as -1 and 2,
    respectively:
    
    0000000000000000 test_pkt_access_subprog1:
           0:       61 10 00 00 00 00 00 00 r0 = *(u32 *)(r1 + 0)
           1:       64 00 00 00 01 00 00 00 w0 <<= 1
           2:       95 00 00 00 00 00 00 00 exit
    
    0000000000000018 test_pkt_access_subprog2:
           3:       61 10 00 00 00 00 00 00 r0 = *(u32 *)(r1 + 0)
           4:       04 00 00 00 02 00 00 00 w0 += 2
           5:       95 00 00 00 00 00 00 00 exit
    
    0000000000000000 test_pkt_access:
           0:       bf 16 00 00 00 00 00 00 r6 = r1
    ===>   1:       85 10 00 00 ff ff ff ff call -1
           2:       bc 01 00 00 00 00 00 00 w1 = w0
           3:       b4 00 00 00 02 00 00 00 w0 = 2
           4:       61 62 00 00 00 00 00 00 r2 = *(u32 *)(r6 + 0)
           5:       64 02 00 00 01 00 00 00 w2 <<= 1
           6:       5e 21 08 00 00 00 00 00 if w1 != w2 goto +8 <LBB0_3>
           7:       bf 61 00 00 00 00 00 00 r1 = r6
    ===>   8:       85 10 00 00 02 00 00 00 call 2
           9:       bc 01 00 00 00 00 00 00 w1 = w0
          10:       61 62 00 00 00 00 00 00 r2 = *(u32 *)(r6 + 0)
          11:       04 02 00 00 02 00 00 00 w2 += 2
          12:       b4 00 00 00 ff ff ff ff w0 = -1
          13:       1e 21 01 00 00 00 00 00 if w1 == w2 goto +1 <LBB0_3>
          14:       b4 00 00 00 02 00 00 00 w0 = 2
    0000000000000078 LBB0_3:
          15:       95 00 00 00 00 00 00 00 exit
    
    Now, if we compile example with global functions, the setup changes.
    Relocations are now against specifically test_pkt_access_subprog1 and
    test_pkt_access_subprog2 symbols, with test_pkt_access_subprog2 pointing 24
    bytes into its respective section (.text), i.e., 3 instructions in:
    
    0000000000000008  000000070000000a R_BPF_64_32            0000000000000000 test_pkt_access_subprog1
    0000000000000048  000000080000000a R_BPF_64_32            0000000000000018 test_pkt_access_subprog2
    
    Calls instructions now encode offsets relative to function symbols and are both
    set ot -1:
    
    0000000000000000 test_pkt_access_subprog1:
           0:       61 10 00 00 00 00 00 00 r0 = *(u32 *)(r1 + 0)
           1:       64 00 00 00 01 00 00 00 w0 <<= 1
           2:       95 00 00 00 00 00 00 00 exit
    
    0000000000000018 test_pkt_access_subprog2:
           3:       61 20 00 00 00 00 00 00 r0 = *(u32 *)(r2 + 0)
           4:       0c 10 00 00 00 00 00 00 w0 += w1
           5:       95 00 00 00 00 00 00 00 exit
    
    0000000000000000 test_pkt_access:
           0:       bf 16 00 00 00 00 00 00 r6 = r1
    ===>   1:       85 10 00 00 ff ff ff ff call -1
           2:       bc 01 00 00 00 00 00 00 w1 = w0
           3:       b4 00 00 00 02 00 00 00 w0 = 2
           4:       61 62 00 00 00 00 00 00 r2 = *(u32 *)(r6 + 0)
           5:       64 02 00 00 01 00 00 00 w2 <<= 1
           6:       5e 21 09 00 00 00 00 00 if w1 != w2 goto +9 <LBB2_3>
           7:       b4 01 00 00 02 00 00 00 w1 = 2
           8:       bf 62 00 00 00 00 00 00 r2 = r6
    ===>   9:       85 10 00 00 ff ff ff ff call -1
          10:       bc 01 00 00 00 00 00 00 w1 = w0
          11:       61 62 00 00 00 00 00 00 r2 = *(u32 *)(r6 + 0)
          12:       04 02 00 00 02 00 00 00 w2 += 2
          13:       b4 00 00 00 ff ff ff ff w0 = -1
          14:       1e 21 01 00 00 00 00 00 if w1 == w2 goto +1 <LBB2_3>
          15:       b4 00 00 00 02 00 00 00 w0 = 2
    0000000000000080 LBB2_3:
          16:       95 00 00 00 00 00 00 00 exit
    
    Thus the right formula to calculate target call offset after relocation should
    take into account relocation's target symbol value (offset within section),
    call instruction's imm32 offset, and (subtracting, to get relative instruction
    offset) instruction index of call instruction itself. All that is shifted by
    number of instructions in main program, given all sub-programs are copied over
    after main program.
    
    Convert few selftests relying on bpf-to-bpf calls to use global functions
    instead of static ones.
    
    Fixes: 48cca7e44f9f ("libbpf: add support for bpf_call")
    Reported-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Andrii Nakryiko <andriin@fb.com>
    Acked-by: Yonghong Song <yhs@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/bpf/20191119224447.3781271-1-andriin@fb.com

diff --git a/tools/testing/selftests/bpf/progs/test_btf_newkv.c b/tools/testing/selftests/bpf/progs/test_btf_newkv.c
index 96f9e8451029..fb8d91a1dbe0 100644
--- a/tools/testing/selftests/bpf/progs/test_btf_newkv.c
+++ b/tools/testing/selftests/bpf/progs/test_btf_newkv.c
@@ -34,7 +34,7 @@ struct dummy_tracepoint_args {
 };
 
 __attribute__((noinline))
-static int test_long_fname_2(struct dummy_tracepoint_args *arg)
+int test_long_fname_2(struct dummy_tracepoint_args *arg)
 {
 	struct ipv_counts *counts;
 	int key = 0;
@@ -57,7 +57,7 @@ static int test_long_fname_2(struct dummy_tracepoint_args *arg)
 }
 
 __attribute__((noinline))
-static int test_long_fname_1(struct dummy_tracepoint_args *arg)
+int test_long_fname_1(struct dummy_tracepoint_args *arg)
 {
 	return test_long_fname_2(arg);
 }

commit 36b5d471135c3ef5f4922aa23f6566b6a07227f7
Author: Andrii Nakryiko <andriin@fb.com>
Date:   Tue Oct 8 10:59:37 2019 -0700

    selftests/bpf: samples/bpf: Split off legacy stuff from bpf_helpers.h
    
    Split off few legacy things from bpf_helpers.h into separate
    bpf_legacy.h file:
    - load_{byte|half|word};
    - remove extra inner_idx and numa_node fields from bpf_map_def and
      introduce bpf_map_def_legacy for use in samples;
    - move BPF_ANNOTATE_KV_PAIR into bpf_legacy.h.
    
    Adjust samples and selftests accordingly by either including
    bpf_legacy.h and using bpf_map_def_legacy, or switching to BTF-defined
    maps altogether.
    
    Signed-off-by: Andrii Nakryiko <andriin@fb.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: John Fastabend <john.fastabend@gmail.com>
    Acked-by: Song Liu <songliubraving@fb.com>
    Link: https://lore.kernel.org/bpf/20191008175942.1769476-3-andriin@fb.com

diff --git a/tools/testing/selftests/bpf/progs/test_btf_newkv.c b/tools/testing/selftests/bpf/progs/test_btf_newkv.c
index 5ee3622ddebb..96f9e8451029 100644
--- a/tools/testing/selftests/bpf/progs/test_btf_newkv.c
+++ b/tools/testing/selftests/bpf/progs/test_btf_newkv.c
@@ -2,6 +2,7 @@
 /* Copyright (c) 2018 Facebook */
 #include <linux/bpf.h>
 #include "bpf_helpers.h"
+#include "bpf_legacy.h"
 
 int _version SEC("version") = 1;
 

commit bc7430cc8bfb51577e466a8ca02ad87375a70bde
Author: Andrii Nakryiko <andriin@fb.com>
Date:   Fri Jul 5 08:50:11 2019 -0700

    selftests/bpf: convert selftests using BTF-defined maps to new syntax
    
    Convert all the existing selftests that are already using BTF-defined
    maps to use new syntax (with no static data initialization).
    
    Signed-off-by: Andrii Nakryiko <andriin@fb.com>
    Acked-by: Song Liu <songliubraving@fb.com>
    Acked-by: Yonghong Song <yhs@fb.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/tools/testing/selftests/bpf/progs/test_btf_newkv.c b/tools/testing/selftests/bpf/progs/test_btf_newkv.c
index 28c16bb583b6..5ee3622ddebb 100644
--- a/tools/testing/selftests/bpf/progs/test_btf_newkv.c
+++ b/tools/testing/selftests/bpf/progs/test_btf_newkv.c
@@ -21,14 +21,11 @@ struct bpf_map_def SEC("maps") btf_map_legacy = {
 BPF_ANNOTATE_KV_PAIR(btf_map_legacy, int, struct ipv_counts);
 
 struct {
-	int *key;
-	struct ipv_counts *value;
-	unsigned int type;
-	unsigned int max_entries;
-} btf_map SEC(".maps") = {
-	.type = BPF_MAP_TYPE_ARRAY,
-	.max_entries = 4,
-};
+	__uint(type, BPF_MAP_TYPE_ARRAY);
+	__uint(max_entries, 4);
+	__type(key, int);
+	__type(value, struct ipv_counts);
+} btf_map SEC(".maps");
 
 struct dummy_tracepoint_args {
 	unsigned long long pad;

commit 9e3d709c47ca3d10df461635b350edef94f3cf11
Author: Andrii Nakryiko <andriin@fb.com>
Date:   Mon Jun 17 12:26:57 2019 -0700

    selftests/bpf: add test for BTF-defined maps
    
    Add file test for BTF-defined map definition.
    
    Signed-off-by: Andrii Nakryiko <andriin@fb.com>
    Acked-by: Song Liu <songliubraving@fb.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/tools/testing/selftests/bpf/progs/test_btf_newkv.c b/tools/testing/selftests/bpf/progs/test_btf_newkv.c
new file mode 100644
index 000000000000..28c16bb583b6
--- /dev/null
+++ b/tools/testing/selftests/bpf/progs/test_btf_newkv.c
@@ -0,0 +1,73 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/* Copyright (c) 2018 Facebook */
+#include <linux/bpf.h>
+#include "bpf_helpers.h"
+
+int _version SEC("version") = 1;
+
+struct ipv_counts {
+	unsigned int v4;
+	unsigned int v6;
+};
+
+/* just to validate we can handle maps in multiple sections */
+struct bpf_map_def SEC("maps") btf_map_legacy = {
+	.type = BPF_MAP_TYPE_ARRAY,
+	.key_size = sizeof(int),
+	.value_size = sizeof(long long),
+	.max_entries = 4,
+};
+
+BPF_ANNOTATE_KV_PAIR(btf_map_legacy, int, struct ipv_counts);
+
+struct {
+	int *key;
+	struct ipv_counts *value;
+	unsigned int type;
+	unsigned int max_entries;
+} btf_map SEC(".maps") = {
+	.type = BPF_MAP_TYPE_ARRAY,
+	.max_entries = 4,
+};
+
+struct dummy_tracepoint_args {
+	unsigned long long pad;
+	struct sock *sock;
+};
+
+__attribute__((noinline))
+static int test_long_fname_2(struct dummy_tracepoint_args *arg)
+{
+	struct ipv_counts *counts;
+	int key = 0;
+
+	if (!arg->sock)
+		return 0;
+
+	counts = bpf_map_lookup_elem(&btf_map, &key);
+	if (!counts)
+		return 0;
+
+	counts->v6++;
+
+	/* just verify we can reference both maps */
+	counts = bpf_map_lookup_elem(&btf_map_legacy, &key);
+	if (!counts)
+		return 0;
+
+	return 0;
+}
+
+__attribute__((noinline))
+static int test_long_fname_1(struct dummy_tracepoint_args *arg)
+{
+	return test_long_fname_2(arg);
+}
+
+SEC("dummy_tracepoint")
+int _dummy_tracepoint(struct dummy_tracepoint_args *arg)
+{
+	return test_long_fname_1(arg);
+}
+
+char _license[] SEC("license") = "GPL";
