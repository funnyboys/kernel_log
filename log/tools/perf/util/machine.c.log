commit e12a89ef73b227e9f56c41502aefcee59fd2a05b
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Tue May 12 14:23:10 2020 +0200

    perf tools: Fix is_bpf_image function logic
    
    Adrian reported that is_bpf_image is not working the way it was intended
    - passing on trampolines and dispatcher names. Instead it returned true
    for all the bpf names.
    
    The reason even this logic worked properly is that all bpf objects, even
    trampolines and dispatcher, were assigned DSO_BINARY_TYPE__BPF_IMAGE
    binary_type.
    
    The later for bpf_prog objects, the binary_type was fixed in bpf load
    event processing, which is executed after the ksymbol code.
    
    Fixing the is_bpf_image logic, so it properly recognizes trampoline and
    dispatcher objects.
    
    Fixes: 3c29d4483e85 ("perf annotate: Add basic support for bpf_image")
    Reported-by: Adrian Hunter <adrian.hunter@intel.com>
    Signed-off-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Michael Petlan <mpetlan@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lore.kernel.org/lkml/20200512122310.3154754-1-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 8ed2135893bb..d5384807372b 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -738,8 +738,8 @@ int machine__process_switch_event(struct machine *machine __maybe_unused,
 
 static int is_bpf_image(const char *name)
 {
-	return strncmp(name, "bpf_trampoline_", sizeof("bpf_trampoline_") - 1) ||
-	       strncmp(name, "bpf_dispatcher_", sizeof("bpf_dispatcher_") - 1);
+	return strncmp(name, "bpf_trampoline_", sizeof("bpf_trampoline_") - 1) == 0 ||
+	       strncmp(name, "bpf_dispatcher_", sizeof("bpf_dispatcher_") - 1) == 0;
 }
 
 static int machine__process_ksymbol_register(struct machine *machine,

commit 6e6d1d654ecdfd07890f9c0fc30f3222885c7571
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon May 4 13:44:03 2020 -0300

    perf evsel: Rename perf_evsel__env() to evsel__env()
    
    As it is a 'struct evsel' method, not part of tools/lib/perf/, aka
    libperf, to whom the perf_ prefix belongs.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index da630e9339d3..8ed2135893bb 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2619,7 +2619,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 		chain_nr = chain->nr;
 
 	if (evsel__has_branch_callstack(evsel)) {
-		struct perf_env *env = perf_evsel__env(evsel);
+		struct perf_env *env = evsel__env(evsel);
 
 		err = resolve_lbr_callchain_sample(thread, cursor, sample, parent,
 						   root_al, max_stack,

commit 4f138a9e08a9635ab2b243c1970308766fd14918
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Apr 30 11:19:45 2020 -0300

    perf evsel: Rename perf_evsel__has*() to evsel__has*()
    
    As those are 'struct evsel' methods, not part of tools/lib/perf/, aka
    libperf, to whom the perf_ prefix belongs.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 5ac32cabe4e6..da630e9339d3 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2618,7 +2618,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	if (chain)
 		chain_nr = chain->nr;
 
-	if (perf_evsel__has_branch_callstack(evsel)) {
+	if (evsel__has_branch_callstack(evsel)) {
 		struct perf_env *env = perf_evsel__env(evsel);
 
 		err = resolve_lbr_callchain_sample(thread, cursor, sample, parent,

commit ff165628d72644e37674c5485658e8bd9f4a348b
Author: Kan Liang <kan.liang@linux.intel.com>
Date:   Thu Mar 19 13:25:12 2020 -0700

    perf callchain: Stitch LBR call stack
    
    In LBR call stack mode, the depth of reconstructed LBR call stack limits
    to the number of LBR registers.
    
      For example, on skylake, the depth of reconstructed LBR call stack is
      always <= 32.
    
      # To display the perf.data header info, please use
      # --header/--header-only options.
      #
      #
      # Total Lost Samples: 0
      #
      # Samples: 6K of event 'cycles'
      # Event count (approx.): 6487119731
      #
      # Children      Self  Command          Shared Object       Symbol
      # ........  ........  ...............  ..................
      # ................................
    
        99.97%    99.97%  tchain_edit      tchain_edit        [.] f43
                |
                 --99.64%--f11
                           f12
                           f13
                           f14
                           f15
                           f16
                           f17
                           f18
                           f19
                           f20
                           f21
                           f22
                           f23
                           f24
                           f25
                           f26
                           f27
                           f28
                           f29
                           f30
                           f31
                           f32
                           f33
                           f34
                           f35
                           f36
                           f37
                           f38
                           f39
                           f40
                           f41
                           f42
                           f43
    
    For a call stack which is deeper than LBR limit, HW will overwrite the
    LBR register with oldest branch. Only partial call stacks can be
    reconstructed.
    
    However, the overwritten LBRs may still be retrieved from previous
    sample. At that moment, HW hasn't overwritten the LBR registers yet.
    Perf tools can stitch those overwritten LBRs on current call stacks to
    get a more complete call stack.
    
    To determine if LBRs can be stitched, perf tools need to compare current
    sample with previous sample.
    
    - They should have identical LBR records (Same from, to and flags
      values, and the same physical index of LBR registers).
    
    - The searching starts from the base-of-stack of current sample.
    
    Once perf determines to stitch the previous LBRs, the corresponding LBR
    cursor nodes will be copied to 'lists'.  The 'lists' is to track the LBR
    cursor nodes which are going to be stitched.
    
    When the stitching is over, the nodes will not be freed immediately.
    They will be moved to 'free_lists'. Next stitching may reuse the space.
    Both 'lists' and 'free_lists' will be freed when all samples are
    processed.
    
    Committer notes:
    
    Fix the intel-pt.c initialization of the union with 'struct
    branch_flags', that breaks the build with its unnamed union on older gcc
    versions.
    
    Uninline thread__free_stitch_list(), as it grew big and started dragging
    includes to thread.h, so move it to thread.c where what it needs in
    terms of headers are already there.
    
    This fixes the build in several systems such as debian:experimental when
    cross building to the MIPS32 architecture, i.e. in the other cases what
    was needed was being included by sheer luck.
    
      In file included from builtin-sched.c:11:
      util/thread.h: In function 'thread__free_stitch_list':
      util/thread.h:169:3: error: implicit declaration of function 'free' [-Werror=implicit-function-declaration]
        169 |   free(pos);
            |   ^~~~
      util/thread.h:169:3: error: incompatible implicit declaration of built-in function 'free' [-Werror]
      util/thread.h:19:1: note: include '<stdlib.h>' or provide a declaration of 'free'
         18 | #include "callchain.h"
        +++ |+#include <stdlib.h>
         19 |
      util/thread.h:174:3: error: incompatible implicit declaration of built-in function 'free' [-Werror]
        174 |   free(pos);
            |   ^~~~
      util/thread.h:174:3: note: include '<stdlib.h>' or provide a declaration of 'free'
    
    Signed-off-by: Kan Liang <kan.liang@linux.intel.com>
    Reviewed-by: Andi Kleen <ak@linux.intel.com>
    Acked-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexey Budankov <alexey.budankov@linux.intel.com>
    Cc: Mathieu Poirier <mathieu.poirier@linaro.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Pavel Gerasimov <pavel.gerasimov@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Vitaly Slobodskoy <vitaly.slobodskoy@intel.com>
    Link: http://lore.kernel.org/lkml/20200319202517.23423-13-kan.liang@linux.intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 737dee723a57..5ac32cabe4e6 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2348,6 +2348,119 @@ static int lbr_callchain_add_lbr_ip(struct thread *thread,
 	return 0;
 }
 
+static int lbr_callchain_add_stitched_lbr_ip(struct thread *thread,
+					     struct callchain_cursor *cursor)
+{
+	struct lbr_stitch *lbr_stitch = thread->lbr_stitch;
+	struct callchain_cursor_node *cnode;
+	struct stitch_list *stitch_node;
+	int err;
+
+	list_for_each_entry(stitch_node, &lbr_stitch->lists, node) {
+		cnode = &stitch_node->cursor;
+
+		err = callchain_cursor_append(cursor, cnode->ip,
+					      &cnode->ms,
+					      cnode->branch,
+					      &cnode->branch_flags,
+					      cnode->nr_loop_iter,
+					      cnode->iter_cycles,
+					      cnode->branch_from,
+					      cnode->srcline);
+		if (err)
+			return err;
+	}
+	return 0;
+}
+
+static struct stitch_list *get_stitch_node(struct thread *thread)
+{
+	struct lbr_stitch *lbr_stitch = thread->lbr_stitch;
+	struct stitch_list *stitch_node;
+
+	if (!list_empty(&lbr_stitch->free_lists)) {
+		stitch_node = list_first_entry(&lbr_stitch->free_lists,
+					       struct stitch_list, node);
+		list_del(&stitch_node->node);
+
+		return stitch_node;
+	}
+
+	return malloc(sizeof(struct stitch_list));
+}
+
+static bool has_stitched_lbr(struct thread *thread,
+			     struct perf_sample *cur,
+			     struct perf_sample *prev,
+			     unsigned int max_lbr,
+			     bool callee)
+{
+	struct branch_stack *cur_stack = cur->branch_stack;
+	struct branch_entry *cur_entries = perf_sample__branch_entries(cur);
+	struct branch_stack *prev_stack = prev->branch_stack;
+	struct branch_entry *prev_entries = perf_sample__branch_entries(prev);
+	struct lbr_stitch *lbr_stitch = thread->lbr_stitch;
+	int i, j, nr_identical_branches = 0;
+	struct stitch_list *stitch_node;
+	u64 cur_base, distance;
+
+	if (!cur_stack || !prev_stack)
+		return false;
+
+	/* Find the physical index of the base-of-stack for current sample. */
+	cur_base = max_lbr - cur_stack->nr + cur_stack->hw_idx + 1;
+
+	distance = (prev_stack->hw_idx > cur_base) ? (prev_stack->hw_idx - cur_base) :
+						     (max_lbr + prev_stack->hw_idx - cur_base);
+	/* Previous sample has shorter stack. Nothing can be stitched. */
+	if (distance + 1 > prev_stack->nr)
+		return false;
+
+	/*
+	 * Check if there are identical LBRs between two samples.
+	 * Identicall LBRs must have same from, to and flags values. Also,
+	 * they have to be saved in the same LBR registers (same physical
+	 * index).
+	 *
+	 * Starts from the base-of-stack of current sample.
+	 */
+	for (i = distance, j = cur_stack->nr - 1; (i >= 0) && (j >= 0); i--, j--) {
+		if ((prev_entries[i].from != cur_entries[j].from) ||
+		    (prev_entries[i].to != cur_entries[j].to) ||
+		    (prev_entries[i].flags.value != cur_entries[j].flags.value))
+			break;
+		nr_identical_branches++;
+	}
+
+	if (!nr_identical_branches)
+		return false;
+
+	/*
+	 * Save the LBRs between the base-of-stack of previous sample
+	 * and the base-of-stack of current sample into lbr_stitch->lists.
+	 * These LBRs will be stitched later.
+	 */
+	for (i = prev_stack->nr - 1; i > (int)distance; i--) {
+
+		if (!lbr_stitch->prev_lbr_cursor[i].valid)
+			continue;
+
+		stitch_node = get_stitch_node(thread);
+		if (!stitch_node)
+			return false;
+
+		memcpy(&stitch_node->cursor, &lbr_stitch->prev_lbr_cursor[i],
+		       sizeof(struct callchain_cursor_node));
+
+		if (callee)
+			list_add(&stitch_node->node, &lbr_stitch->lists);
+		else
+			list_add_tail(&stitch_node->node, &lbr_stitch->lists);
+	}
+
+	return true;
+}
+
 static bool alloc_lbr_stitch(struct thread *thread, unsigned int max_lbr)
 {
 	if (thread->lbr_stitch)
@@ -2361,6 +2474,9 @@ static bool alloc_lbr_stitch(struct thread *thread, unsigned int max_lbr)
 	if (!thread->lbr_stitch->prev_lbr_cursor)
 		goto free_lbr_stitch;
 
+	INIT_LIST_HEAD(&thread->lbr_stitch->lists);
+	INIT_LIST_HEAD(&thread->lbr_stitch->free_lists);
+
 	return true;
 
 free_lbr_stitch:
@@ -2386,9 +2502,11 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 					int max_stack,
 					unsigned int max_lbr)
 {
+	bool callee = (callchain_param.order == ORDER_CALLEE);
 	struct ip_callchain *chain = sample->callchain;
 	int chain_nr = min(max_stack, (int)chain->nr), i;
 	struct lbr_stitch *lbr_stitch;
+	bool stitched_lbr = false;
 	u64 branch_from = 0;
 	int err;
 
@@ -2405,10 +2523,18 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 	    (max_lbr > 0) && alloc_lbr_stitch(thread, max_lbr)) {
 		lbr_stitch = thread->lbr_stitch;
 
+		stitched_lbr = has_stitched_lbr(thread, sample,
+						&lbr_stitch->prev_sample,
+						max_lbr, callee);
+
+		if (!stitched_lbr && !list_empty(&lbr_stitch->lists)) {
+			list_replace_init(&lbr_stitch->lists,
+					  &lbr_stitch->free_lists);
+		}
 		memcpy(&lbr_stitch->prev_sample, sample, sizeof(*sample));
 	}
 
-	if (callchain_param.order == ORDER_CALLEE) {
+	if (callee) {
 		/* Add kernel ip */
 		err = lbr_callchain_add_kernel_ip(thread, cursor, sample,
 						  parent, root_al, branch_from,
@@ -2421,7 +2547,18 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 		if (err)
 			goto error;
 
+		if (stitched_lbr) {
+			err = lbr_callchain_add_stitched_lbr_ip(thread, cursor);
+			if (err)
+				goto error;
+		}
+
 	} else {
+		if (stitched_lbr) {
+			err = lbr_callchain_add_stitched_lbr_ip(thread, cursor);
+			if (err)
+				goto error;
+		}
 		err = lbr_callchain_add_lbr_ip(thread, cursor, sample, parent,
 					       root_al, &branch_from, false);
 		if (err)

commit 7f1d39317c071268b4204175df7cfbb2187acb72
Author: Kan Liang <kan.liang@linux.intel.com>
Date:   Thu Mar 19 13:25:11 2020 -0700

    perf callchain: Save previous cursor nodes for LBR stitching approach
    
    The cursor nodes which generates from sample are eventually added into
    callchain. To avoid generating cursor nodes from previous samples again,
    the previous cursor nodes are also saved for LBR stitching approach.
    
    Some option, e.g. hide-unresolved, may hide some LBRs.  Add a variable
    'valid' in struct callchain_cursor_node to indicate this case. The LBR
    stitching approach will only append the valid cursor nodes from previous
    samples later.
    
    Signed-off-by: Kan Liang <kan.liang@linux.intel.com>
    Reviewed-by: Andi Kleen <ak@linux.intel.com>
    Acked-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexey Budankov <alexey.budankov@linux.intel.com>
    Cc: Mathieu Poirier <mathieu.poirier@linaro.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Pavel Gerasimov <pavel.gerasimov@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Vitaly Slobodskoy <vitaly.slobodskoy@intel.com>
    Link: http://lore.kernel.org/lkml/20200319202517.23423-12-kan.liang@linux.intel.com
    [ Use zfree() instead of open coded equivalent, and use it when freeing members of structs ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index a54ca09a1d00..737dee723a57 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2224,6 +2224,31 @@ static int lbr_callchain_add_kernel_ip(struct thread *thread,
 	return 0;
 }
 
+static void save_lbr_cursor_node(struct thread *thread,
+				 struct callchain_cursor *cursor,
+				 int idx)
+{
+	struct lbr_stitch *lbr_stitch = thread->lbr_stitch;
+
+	if (!lbr_stitch)
+		return;
+
+	if (cursor->pos == cursor->nr) {
+		lbr_stitch->prev_lbr_cursor[idx].valid = false;
+		return;
+	}
+
+	if (!cursor->curr)
+		cursor->curr = cursor->first;
+	else
+		cursor->curr = cursor->curr->next;
+	memcpy(&lbr_stitch->prev_lbr_cursor[idx], cursor->curr,
+	       sizeof(struct callchain_cursor_node));
+
+	lbr_stitch->prev_lbr_cursor[idx].valid = true;
+	cursor->pos++;
+}
+
 static int lbr_callchain_add_lbr_ip(struct thread *thread,
 				    struct callchain_cursor *cursor,
 				    struct perf_sample *sample,
@@ -2240,6 +2265,21 @@ static int lbr_callchain_add_lbr_ip(struct thread *thread,
 	int err, i;
 	u64 ip;
 
+	/*
+	 * The curr and pos are not used in writing session. They are cleared
+	 * in callchain_cursor_commit() when the writing session is closed.
+	 * Using curr and pos to track the current cursor node.
+	 */
+	if (thread->lbr_stitch) {
+		cursor->curr = NULL;
+		cursor->pos = cursor->nr;
+		if (cursor->nr) {
+			cursor->curr = cursor->first;
+			for (i = 0; i < (int)(cursor->nr - 1); i++)
+				cursor->curr = cursor->curr->next;
+		}
+	}
+
 	if (callee) {
 		/* Add LBR ip from first entries.to */
 		ip = entries[0].to;
@@ -2252,6 +2292,20 @@ static int lbr_callchain_add_lbr_ip(struct thread *thread,
 		if (err)
 			return err;
 
+		/*
+		 * The number of cursor node increases.
+		 * Move the current cursor node.
+		 * But does not need to save current cursor node for entry 0.
+		 * It's impossible to stitch the whole LBRs of previous sample.
+		 */
+		if (thread->lbr_stitch && (cursor->pos != cursor->nr)) {
+			if (!cursor->curr)
+				cursor->curr = cursor->first;
+			else
+				cursor->curr = cursor->curr->next;
+			cursor->pos++;
+		}
+
 		/* Add LBR ip from entries.from one by one. */
 		for (i = 0; i < lbr_nr; i++) {
 			ip = entries[i].from;
@@ -2262,6 +2316,7 @@ static int lbr_callchain_add_lbr_ip(struct thread *thread,
 					       *branch_from);
 			if (err)
 				return err;
+			save_lbr_cursor_node(thread, cursor, i);
 		}
 		return 0;
 	}
@@ -2276,6 +2331,7 @@ static int lbr_callchain_add_lbr_ip(struct thread *thread,
 				       *branch_from);
 		if (err)
 			return err;
+		save_lbr_cursor_node(thread, cursor, i);
 	}
 
 	/* Add LBR ip from first entries.to */
@@ -2292,7 +2348,7 @@ static int lbr_callchain_add_lbr_ip(struct thread *thread,
 	return 0;
 }
 
-static bool alloc_lbr_stitch(struct thread *thread)
+static bool alloc_lbr_stitch(struct thread *thread, unsigned int max_lbr)
 {
 	if (thread->lbr_stitch)
 		return true;
@@ -2301,6 +2357,14 @@ static bool alloc_lbr_stitch(struct thread *thread)
 	if (!thread->lbr_stitch)
 		goto err;
 
+	thread->lbr_stitch->prev_lbr_cursor = calloc(max_lbr + 1, sizeof(struct callchain_cursor_node));
+	if (!thread->lbr_stitch->prev_lbr_cursor)
+		goto free_lbr_stitch;
+
+	return true;
+
+free_lbr_stitch:
+	zfree(&thread->lbr_stitch);
 err:
 	pr_warning("Failed to allocate space for stitched LBRs. Disable LBR stitch\n");
 	thread->lbr_stitch_enable = false;
@@ -2319,7 +2383,8 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 					struct perf_sample *sample,
 					struct symbol **parent,
 					struct addr_location *root_al,
-					int max_stack)
+					int max_stack,
+					unsigned int max_lbr)
 {
 	struct ip_callchain *chain = sample->callchain;
 	int chain_nr = min(max_stack, (int)chain->nr), i;
@@ -2337,7 +2402,7 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 		return 0;
 
 	if (thread->lbr_stitch_enable && !sample->no_hw_idx &&
-	    alloc_lbr_stitch(thread)) {
+	    (max_lbr > 0) && alloc_lbr_stitch(thread, max_lbr)) {
 		lbr_stitch = thread->lbr_stitch;
 
 		memcpy(&lbr_stitch->prev_sample, sample, sizeof(*sample));
@@ -2417,8 +2482,11 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 		chain_nr = chain->nr;
 
 	if (perf_evsel__has_branch_callstack(evsel)) {
+		struct perf_env *env = perf_evsel__env(evsel);
+
 		err = resolve_lbr_callchain_sample(thread, cursor, sample, parent,
-						   root_al, max_stack);
+						   root_al, max_stack,
+						   !env ? 0 : env->max_branches);
 		if (err)
 			return (err < 0) ? err : 0;
 	}

commit 9c6c3f471d85a9b0bcda3ce6fc1e2646685e3f60
Author: Kan Liang <kan.liang@linux.intel.com>
Date:   Thu Mar 19 13:25:10 2020 -0700

    perf thread: Save previous sample for LBR stitching approach
    
    To retrieve the overwritten LBRs from previous sample for LBR stitching
    approach, perf has to save the previous sample.
    
    Only allocate the struct lbr_stitch once, when LBR stitching approach is
    enabled and kernel supports hw_idx.
    
    Signed-off-by: Kan Liang <kan.liang@linux.intel.com>
    Reviewed-by: Andi Kleen <ak@linux.intel.com>
    Acked-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexey Budankov <alexey.budankov@linux.intel.com>
    Cc: Mathieu Poirier <mathieu.poirier@linaro.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Pavel Gerasimov <pavel.gerasimov@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Vitaly Slobodskoy <vitaly.slobodskoy@intel.com>
    Link: http://lore.kernel.org/lkml/20200319202517.23423-11-kan.liang@linux.intel.com
    [ Use zalloc()/zfree() for thread->lbr_stitch ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index f9d69fce584a..a54ca09a1d00 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2292,6 +2292,21 @@ static int lbr_callchain_add_lbr_ip(struct thread *thread,
 	return 0;
 }
 
+static bool alloc_lbr_stitch(struct thread *thread)
+{
+	if (thread->lbr_stitch)
+		return true;
+
+	thread->lbr_stitch = zalloc(sizeof(*thread->lbr_stitch));
+	if (!thread->lbr_stitch)
+		goto err;
+
+err:
+	pr_warning("Failed to allocate space for stitched LBRs. Disable LBR stitch\n");
+	thread->lbr_stitch_enable = false;
+	return false;
+}
+
 /*
  * Recolve LBR callstack chain sample
  * Return:
@@ -2308,6 +2323,7 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 {
 	struct ip_callchain *chain = sample->callchain;
 	int chain_nr = min(max_stack, (int)chain->nr), i;
+	struct lbr_stitch *lbr_stitch;
 	u64 branch_from = 0;
 	int err;
 
@@ -2320,6 +2336,13 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 	if (i == chain_nr)
 		return 0;
 
+	if (thread->lbr_stitch_enable && !sample->no_hw_idx &&
+	    alloc_lbr_stitch(thread)) {
+		lbr_stitch = thread->lbr_stitch;
+
+		memcpy(&lbr_stitch->prev_sample, sample, sizeof(*sample));
+	}
+
 	if (callchain_param.order == ORDER_CALLEE) {
 		/* Add kernel ip */
 		err = lbr_callchain_add_kernel_ip(thread, cursor, sample,

commit e2b23483eb1d851b4c48935a995f79b2de41c3ed
Author: Kan Liang <kan.liang@linux.intel.com>
Date:   Thu Mar 19 13:25:08 2020 -0700

    perf machine: Factor out lbr_callchain_add_lbr_ip()
    
    Both caller and callee needs to add ip from LBR to callchain.
    Factor out lbr_callchain_add_lbr_ip() to improve code readability.
    
    Signed-off-by: Kan Liang <kan.liang@linux.intel.com>
    Reviewed-by: Andi Kleen <ak@linux.intel.com>
    Acked-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexey Budankov <alexey.budankov@linux.intel.com>
    Cc: Mathieu Poirier <mathieu.poirier@linaro.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Pavel Gerasimov <pavel.gerasimov@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Vitaly Slobodskoy <vitaly.slobodskoy@intel.com>
    Link: http://lore.kernel.org/lkml/20200319202517.23423-9-kan.liang@linux.intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index a7f75fd43b0f..f9d69fce584a 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2224,6 +2224,74 @@ static int lbr_callchain_add_kernel_ip(struct thread *thread,
 	return 0;
 }
 
+static int lbr_callchain_add_lbr_ip(struct thread *thread,
+				    struct callchain_cursor *cursor,
+				    struct perf_sample *sample,
+				    struct symbol **parent,
+				    struct addr_location *root_al,
+				    u64 *branch_from,
+				    bool callee)
+{
+	struct branch_stack *lbr_stack = sample->branch_stack;
+	struct branch_entry *entries = perf_sample__branch_entries(sample);
+	u8 cpumode = PERF_RECORD_MISC_USER;
+	int lbr_nr = lbr_stack->nr;
+	struct branch_flags *flags;
+	int err, i;
+	u64 ip;
+
+	if (callee) {
+		/* Add LBR ip from first entries.to */
+		ip = entries[0].to;
+		flags = &entries[0].flags;
+		*branch_from = entries[0].from;
+		err = add_callchain_ip(thread, cursor, parent,
+				       root_al, &cpumode, ip,
+				       true, flags, NULL,
+				       *branch_from);
+		if (err)
+			return err;
+
+		/* Add LBR ip from entries.from one by one. */
+		for (i = 0; i < lbr_nr; i++) {
+			ip = entries[i].from;
+			flags = &entries[i].flags;
+			err = add_callchain_ip(thread, cursor, parent,
+					       root_al, &cpumode, ip,
+					       true, flags, NULL,
+					       *branch_from);
+			if (err)
+				return err;
+		}
+		return 0;
+	}
+
+	/* Add LBR ip from entries.from one by one. */
+	for (i = lbr_nr - 1; i >= 0; i--) {
+		ip = entries[i].from;
+		flags = &entries[i].flags;
+		err = add_callchain_ip(thread, cursor, parent,
+				       root_al, &cpumode, ip,
+				       true, flags, NULL,
+				       *branch_from);
+		if (err)
+			return err;
+	}
+
+	/* Add LBR ip from first entries.to */
+	ip = entries[0].to;
+	flags = &entries[0].flags;
+	*branch_from = entries[0].from;
+	err = add_callchain_ip(thread, cursor, parent,
+			       root_al, &cpumode, ip,
+			       true, flags, NULL,
+			       *branch_from);
+	if (err)
+		return err;
+
+	return 0;
+}
+
 /*
  * Recolve LBR callstack chain sample
  * Return:
@@ -2240,14 +2308,7 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 {
 	struct ip_callchain *chain = sample->callchain;
 	int chain_nr = min(max_stack, (int)chain->nr), i;
-	u8 cpumode = PERF_RECORD_MISC_USER;
-	u64 ip, branch_from = 0;
-	struct branch_stack *lbr_stack;
-	struct branch_entry *entries;
-	int lbr_nr, j, k;
-	bool branch;
-	struct branch_flags *flags;
-	int mix_chain_nr;
+	u64 branch_from = 0;
 	int err;
 
 	for (i = 0; i < chain_nr; i++) {
@@ -2259,21 +2320,6 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 	if (i == chain_nr)
 		return 0;
 
-	lbr_stack = sample->branch_stack;
-	entries = perf_sample__branch_entries(sample);
-	lbr_nr = lbr_stack->nr;
-	/*
-	 * LBR callstack can only get user call chain.
-	 * The mix_chain_nr is kernel call chain
-	 * number plus LBR user call chain number.
-	 * i is kernel call chain number,
-	 * 1 is PERF_CONTEXT_USER,
-	 * lbr_nr + 1 is the user call chain number.
-	 * For details, please refer to the comments
-	 * in callchain__printf
-	 */
-	mix_chain_nr = i + 1 + lbr_nr + 1;
-
 	if (callchain_param.order == ORDER_CALLEE) {
 		/* Add kernel ip */
 		err = lbr_callchain_add_kernel_ip(thread, cursor, sample,
@@ -2282,57 +2328,14 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 		if (err)
 			goto error;
 
-		/* Add LBR ip from first entries.to */
-		ip = entries[0].to;
-		branch = true;
-		flags = &entries[0].flags;
-		branch_from = entries[0].from;
-		err = add_callchain_ip(thread, cursor, parent,
-				       root_al, &cpumode, ip,
-				       branch, flags, NULL,
-				       branch_from);
+		err = lbr_callchain_add_lbr_ip(thread, cursor, sample, parent,
+					       root_al, &branch_from, true);
 		if (err)
 			goto error;
 
-		/* Add LBR ip from entries.from one by one. */
-		for (j = i + 2; j < mix_chain_nr; j++) {
-			k = j - i - 2;
-			ip = entries[k].from;
-			branch = true;
-			flags = &entries[k].flags;
-
-			err = add_callchain_ip(thread, cursor, parent,
-					       root_al, &cpumode, ip,
-					       branch, flags, NULL,
-					       branch_from);
-			if (err)
-				goto error;
-		}
 	} else {
-		/* Add LBR ip from entries.from one by one. */
-		for (j = 0; j < lbr_nr; j++) {
-			k = lbr_nr - j - 1;
-			ip = entries[k].from;
-			branch = true;
-			flags = &entries[k].flags;
-
-			err = add_callchain_ip(thread, cursor, parent,
-					       root_al, &cpumode, ip,
-					       branch, flags, NULL,
-					       branch_from);
-			if (err)
-				goto error;
-		}
-
-		/* Add LBR ip from first entries.to */
-		ip = entries[0].to;
-		branch = true;
-		flags = &entries[0].flags;
-		branch_from = entries[0].from;
-		err = add_callchain_ip(thread, cursor, parent,
-				       root_al, &cpumode, ip,
-				       branch, flags, NULL,
-				       branch_from);
+		err = lbr_callchain_add_lbr_ip(thread, cursor, sample, parent,
+					       root_al, &branch_from, false);
 		if (err)
 			goto error;
 

commit dd3e249a0c0ad88098922803b149c788bb364c23
Author: Kan Liang <kan.liang@linux.intel.com>
Date:   Thu Mar 19 13:25:07 2020 -0700

    perf machine: Factor out lbr_callchain_add_kernel_ip()
    
    Both caller and callee needs to add kernel ip to callchain.  Factor out
    lbr_callchain_add_kernel_ip() to improve code readability.
    
    Signed-off-by: Kan Liang <kan.liang@linux.intel.com>
    Reviewed-by: Andi Kleen <ak@linux.intel.com>
    Acked-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexey Budankov <alexey.budankov@linux.intel.com>
    Cc: Mathieu Poirier <mathieu.poirier@linaro.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Pavel Gerasimov <pavel.gerasimov@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Vitaly Slobodskoy <vitaly.slobodskoy@intel.com>
    Link: http://lore.kernel.org/lkml/20200319202517.23423-8-kan.liang@linux.intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 0da540e6f803..a7f75fd43b0f 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2190,6 +2190,40 @@ static int remove_loops(struct branch_entry *l, int nr,
 	return nr;
 }
 
+static int lbr_callchain_add_kernel_ip(struct thread *thread,
+				       struct callchain_cursor *cursor,
+				       struct perf_sample *sample,
+				       struct symbol **parent,
+				       struct addr_location *root_al,
+				       u64 branch_from,
+				       bool callee, int end)
+{
+	struct ip_callchain *chain = sample->callchain;
+	u8 cpumode = PERF_RECORD_MISC_USER;
+	int err, i;
+
+	if (callee) {
+		for (i = 0; i < end + 1; i++) {
+			err = add_callchain_ip(thread, cursor, parent,
+					       root_al, &cpumode, chain->ips[i],
+					       false, NULL, NULL, branch_from);
+			if (err)
+				return err;
+		}
+		return 0;
+	}
+
+	for (i = end; i >= 0; i--) {
+		err = add_callchain_ip(thread, cursor, parent,
+				       root_al, &cpumode, chain->ips[i],
+				       false, NULL, NULL, branch_from);
+		if (err)
+			return err;
+	}
+
+	return 0;
+}
+
 /*
  * Recolve LBR callstack chain sample
  * Return:
@@ -2242,17 +2276,12 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 
 	if (callchain_param.order == ORDER_CALLEE) {
 		/* Add kernel ip */
-		for (j = 0; j < i + 1; j++) {
-			ip = chain->ips[j];
-			branch = false;
-			flags = NULL;
-			err = add_callchain_ip(thread, cursor, parent,
-					       root_al, &cpumode, ip,
-					       branch, flags, NULL,
-					       branch_from);
-			if (err)
-				goto error;
-		}
+		err = lbr_callchain_add_kernel_ip(thread, cursor, sample,
+						  parent, root_al, branch_from,
+						  true, i);
+		if (err)
+			goto error;
+
 		/* Add LBR ip from first entries.to */
 		ip = entries[0].to;
 		branch = true;
@@ -2308,17 +2337,11 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 			goto error;
 
 		/* Add kernel ip */
-		for (j = lbr_nr + 1; j < mix_chain_nr; j++) {
-			ip = chain->ips[i + 1 - (j - lbr_nr)];
-			branch = false;
-			flags = NULL;
-			err = add_callchain_ip(thread, cursor, parent,
-					       root_al, &cpumode, ip,
-					       branch, flags, NULL,
-					       branch_from);
-			if (err)
-				goto error;
-		}
+		err = lbr_callchain_add_kernel_ip(thread, cursor, sample,
+						  parent, root_al, branch_from,
+						  false, i);
+		if (err)
+			goto error;
 	}
 	return 1;
 

commit e48b8311ca4538ec716196a1625812b045999f21
Author: Kan Liang <kan.liang@linux.intel.com>
Date:   Thu Mar 19 13:25:06 2020 -0700

    perf machine: Refine the function for LBR call stack reconstruction
    
    LBR only collect the user call stack. To reconstruct a call stack, both
    kernel call stack and user call stack are required. The function
    resolve_lbr_callchain_sample() mix the kernel call stack and user call
    stack.
    
    Now, with the help of HW idx, perf tool can reconstruct a more complete
    call stack by adding some user call stack from previous sample. However,
    current implementation is hard to be extended to support it.
    
    Current code path for resolve_lbr_callchain_sample()
    
      for (j = 0; j < mix_chain_nr; j++) {
           if (ORDER_CALLEE) {
                 if (kernel callchain)
                      Fill callchain info
                 else if (LBR callchain)
                      Fill callchain info
           } else {
                 if (LBR callchain)
                      Fill callchain info
                 else if (kernel callchain)
                      Fill callchain info
           }
           add_callchain_ip();
      }
    
    With the patch,
    
      if (ORDER_CALLEE) {
           for (j = 0; j < NUM of kernel callchain) {
                 Fill callchain info
                 add_callchain_ip();
           }
           for (; j < mix_chain_nr) {
                 Fill callchain info
                 add_callchain_ip();
           }
      } else {
           for (; j < NUM of LBR callchain) {
                 Fill callchain info
                 add_callchain_ip();
           }
           for (j = 0; j < mix_chain_nr) {
                 Fill callchain info
                 add_callchain_ip();
           }
      }
    
    No functional changes.
    
    Signed-off-by: Kan Liang <kan.liang@linux.intel.com>
    Reviewed-by: Andi Kleen <ak@linux.intel.com>
    Acked-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexey Budankov <alexey.budankov@linux.intel.com>
    Cc: Mathieu Poirier <mathieu.poirier@linaro.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Pavel Gerasimov <pavel.gerasimov@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Vitaly Slobodskoy <vitaly.slobodskoy@intel.com>
    Link: http://lore.kernel.org/lkml/20200319202517.23423-7-kan.liang@linux.intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index be1bd9277471..0da540e6f803 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2214,6 +2214,7 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 	bool branch;
 	struct branch_flags *flags;
 	int mix_chain_nr;
+	int err;
 
 	for (i = 0; i < chain_nr; i++) {
 		if (chain->ips[i] == PERF_CONTEXT_USER)
@@ -2239,50 +2240,90 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 	 */
 	mix_chain_nr = i + 1 + lbr_nr + 1;
 
-	for (j = 0; j < mix_chain_nr; j++) {
-		int err;
-
-		branch = false;
-		flags = NULL;
-
-		if (callchain_param.order == ORDER_CALLEE) {
-			if (j < i + 1)
-				ip = chain->ips[j];
-			else if (j > i + 1) {
-				k = j - i - 2;
-				ip = entries[k].from;
-				branch = true;
-				flags = &entries[k].flags;
-			} else {
-				ip = entries[0].to;
-				branch = true;
-				flags = &entries[0].flags;
-				branch_from = entries[0].from;
-			}
-		} else {
-			if (j < lbr_nr) {
-				k = lbr_nr - j - 1;
-				ip = entries[k].from;
-				branch = true;
-				flags = &entries[k].flags;
-			} else if (j > lbr_nr)
-				ip = chain->ips[i + 1 - (j - lbr_nr)];
-			else {
-				ip = entries[0].to;
-				branch = true;
-				flags = &entries[0].flags;
-				branch_from = entries[0].from;
-			}
+	if (callchain_param.order == ORDER_CALLEE) {
+		/* Add kernel ip */
+		for (j = 0; j < i + 1; j++) {
+			ip = chain->ips[j];
+			branch = false;
+			flags = NULL;
+			err = add_callchain_ip(thread, cursor, parent,
+					       root_al, &cpumode, ip,
+					       branch, flags, NULL,
+					       branch_from);
+			if (err)
+				goto error;
 		}
+		/* Add LBR ip from first entries.to */
+		ip = entries[0].to;
+		branch = true;
+		flags = &entries[0].flags;
+		branch_from = entries[0].from;
+		err = add_callchain_ip(thread, cursor, parent,
+				       root_al, &cpumode, ip,
+				       branch, flags, NULL,
+				       branch_from);
+		if (err)
+			goto error;
 
+		/* Add LBR ip from entries.from one by one. */
+		for (j = i + 2; j < mix_chain_nr; j++) {
+			k = j - i - 2;
+			ip = entries[k].from;
+			branch = true;
+			flags = &entries[k].flags;
+
+			err = add_callchain_ip(thread, cursor, parent,
+					       root_al, &cpumode, ip,
+					       branch, flags, NULL,
+					       branch_from);
+			if (err)
+				goto error;
+		}
+	} else {
+		/* Add LBR ip from entries.from one by one. */
+		for (j = 0; j < lbr_nr; j++) {
+			k = lbr_nr - j - 1;
+			ip = entries[k].from;
+			branch = true;
+			flags = &entries[k].flags;
+
+			err = add_callchain_ip(thread, cursor, parent,
+					       root_al, &cpumode, ip,
+					       branch, flags, NULL,
+					       branch_from);
+			if (err)
+				goto error;
+		}
+
+		/* Add LBR ip from first entries.to */
+		ip = entries[0].to;
+		branch = true;
+		flags = &entries[0].flags;
+		branch_from = entries[0].from;
 		err = add_callchain_ip(thread, cursor, parent,
 				       root_al, &cpumode, ip,
 				       branch, flags, NULL,
 				       branch_from);
 		if (err)
-			return (err < 0) ? err : 0;
+			goto error;
+
+		/* Add kernel ip */
+		for (j = lbr_nr + 1; j < mix_chain_nr; j++) {
+			ip = chain->ips[i + 1 - (j - lbr_nr)];
+			branch = false;
+			flags = NULL;
+			err = add_callchain_ip(thread, cursor, parent,
+					       root_al, &cpumode, ip,
+					       branch, flags, NULL,
+					       branch_from);
+			if (err)
+				goto error;
+		}
 	}
 	return 1;
+
+error:
+	return (err < 0) ? err : 0;
 }
 
 static int find_prev_cpumode(struct ip_callchain *chain, struct thread *thread,

commit f8603267bf8589f2a6a3e0a7de0a8dc6b6bd3c7d
Author: Kan Liang <kan.liang@linux.intel.com>
Date:   Thu Mar 19 13:25:05 2020 -0700

    perf machine: Remove the indent in resolve_lbr_callchain_sample
    
    The indent is unnecessary in resolve_lbr_callchain_sample.  Removing it
    will make the following patch simpler.
    
    Current code path for resolve_lbr_callchain_sample()
    
            /* LBR only affects the user callchain */
            if (i != chain_nr) {
                    body of the function
                    ....
                    return 1;
            }
    
            return 0;
    
    With the patch,
    
            /* LBR only affects the user callchain */
            if (i == chain_nr)
                    return 0;
    
            body of the function
            ...
            return 1;
    
    No functional changes.
    
    Signed-off-by: Kan Liang <kan.liang@linux.intel.com>
    Reviewed-by: Andi Kleen <ak@linux.intel.com>
    Acked-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexey Budankov <alexey.budankov@linux.intel.com>
    Cc: Mathieu Poirier <mathieu.poirier@linaro.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Pavel Gerasimov <pavel.gerasimov@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Vitaly Slobodskoy <vitaly.slobodskoy@intel.com>
    Link: http://lore.kernel.org/lkml/20200319202517.23423-6-kan.liang@linux.intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 09845eae9c03..be1bd9277471 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2208,6 +2208,12 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 	int chain_nr = min(max_stack, (int)chain->nr), i;
 	u8 cpumode = PERF_RECORD_MISC_USER;
 	u64 ip, branch_from = 0;
+	struct branch_stack *lbr_stack;
+	struct branch_entry *entries;
+	int lbr_nr, j, k;
+	bool branch;
+	struct branch_flags *flags;
+	int mix_chain_nr;
 
 	for (i = 0; i < chain_nr; i++) {
 		if (chain->ips[i] == PERF_CONTEXT_USER)
@@ -2215,71 +2221,68 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 	}
 
 	/* LBR only affects the user callchain */
-	if (i != chain_nr) {
-		struct branch_stack *lbr_stack = sample->branch_stack;
-		struct branch_entry *entries = perf_sample__branch_entries(sample);
-		int lbr_nr = lbr_stack->nr, j, k;
-		bool branch;
-		struct branch_flags *flags;
-		/*
-		 * LBR callstack can only get user call chain.
-		 * The mix_chain_nr is kernel call chain
-		 * number plus LBR user call chain number.
-		 * i is kernel call chain number,
-		 * 1 is PERF_CONTEXT_USER,
-		 * lbr_nr + 1 is the user call chain number.
-		 * For details, please refer to the comments
-		 * in callchain__printf
-		 */
-		int mix_chain_nr = i + 1 + lbr_nr + 1;
-
-		for (j = 0; j < mix_chain_nr; j++) {
-			int err;
-			branch = false;
-			flags = NULL;
+	if (i == chain_nr)
+		return 0;
 
-			if (callchain_param.order == ORDER_CALLEE) {
-				if (j < i + 1)
-					ip = chain->ips[j];
-				else if (j > i + 1) {
-					k = j - i - 2;
-					ip = entries[k].from;
-					branch = true;
-					flags = &entries[k].flags;
-				} else {
-					ip = entries[0].to;
-					branch = true;
-					flags = &entries[0].flags;
-					branch_from = entries[0].from;
-				}
+	lbr_stack = sample->branch_stack;
+	entries = perf_sample__branch_entries(sample);
+	lbr_nr = lbr_stack->nr;
+	/*
+	 * LBR callstack can only get user call chain.
+	 * The mix_chain_nr is kernel call chain
+	 * number plus LBR user call chain number.
+	 * i is kernel call chain number,
+	 * 1 is PERF_CONTEXT_USER,
+	 * lbr_nr + 1 is the user call chain number.
+	 * For details, please refer to the comments
+	 * in callchain__printf
+	 */
+	mix_chain_nr = i + 1 + lbr_nr + 1;
+
+	for (j = 0; j < mix_chain_nr; j++) {
+		int err;
+
+		branch = false;
+		flags = NULL;
+
+		if (callchain_param.order == ORDER_CALLEE) {
+			if (j < i + 1)
+				ip = chain->ips[j];
+			else if (j > i + 1) {
+				k = j - i - 2;
+				ip = entries[k].from;
+				branch = true;
+				flags = &entries[k].flags;
 			} else {
-				if (j < lbr_nr) {
-					k = lbr_nr - j - 1;
-					ip = entries[k].from;
-					branch = true;
-					flags = &entries[k].flags;
-				}
-				else if (j > lbr_nr)
-					ip = chain->ips[i + 1 - (j - lbr_nr)];
-				else {
-					ip = entries[0].to;
-					branch = true;
-					flags = &entries[0].flags;
-					branch_from = entries[0].from;
-				}
+				ip = entries[0].to;
+				branch = true;
+				flags = &entries[0].flags;
+				branch_from = entries[0].from;
+			}
+		} else {
+			if (j < lbr_nr) {
+				k = lbr_nr - j - 1;
+				ip = entries[k].from;
+				branch = true;
+				flags = &entries[k].flags;
+			} else if (j > lbr_nr)
+				ip = chain->ips[i + 1 - (j - lbr_nr)];
+			else {
+				ip = entries[0].to;
+				branch = true;
+				flags = &entries[0].flags;
+				branch_from = entries[0].from;
 			}
-
-			err = add_callchain_ip(thread, cursor, parent,
-					       root_al, &cpumode, ip,
-					       branch, flags, NULL,
-					       branch_from);
-			if (err)
-				return (err < 0) ? err : 0;
 		}
-		return 1;
-	}
 
-	return 0;
+		err = add_callchain_ip(thread, cursor, parent,
+				       root_al, &cpumode, ip,
+				       branch, flags, NULL,
+				       branch_from);
+		if (err)
+			return (err < 0) ? err : 0;
+	}
+	return 1;
 }
 
 static int find_prev_cpumode(struct ip_callchain *chain, struct thread *thread,

commit 3c29d4483e855b6ba5c6e35b0c81caad7d9e3984
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Thu Mar 12 20:56:10 2020 +0100

    perf annotate: Add basic support for bpf_image
    
    Add the DSO_BINARY_TYPE__BPF_IMAGE dso binary type to recognize BPF
    images that carry trampoline or dispatcher.
    
    Upcoming patches will add support to read the image data, store it
    within the BPF feature in perf.data and display it for annotation
    purposes.
    
    Currently we only display following message:
    
      # ./perf annotate bpf_trampoline_24456 --stdio
       Percent |      Source code & Disassembly of . for cycles (504  ...
      --------------------------------------------------------------- ...
               :       to be implemented
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Acked-by: Song Liu <songliubraving@fb.com>
    Cc: Alexei Starovoitov <ast@kernel.org>
    Cc: Andrii Nakryiko <andriin@fb.com>
    Cc: BjÃ¶rn TÃ¶pel <bjorn.topel@intel.com>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: David S. Miller <davem@redhat.com>
    Cc: Jakub Kicinski <kuba@kernel.org>
    Cc: Jesper Dangaard Brouer <hawk@kernel.org>
    Cc: John Fastabend <john.fastabend@gmail.com>
    Cc: Martin KaFai Lau <kafai@fb.com>
    Cc: Yonghong Song <yhs@fb.com>
    Link: https://lore.kernel.org/bpf/20200312195610.346362-16-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 06aa4e4db63d..09845eae9c03 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -736,6 +736,12 @@ int machine__process_switch_event(struct machine *machine __maybe_unused,
 	return 0;
 }
 
+static int is_bpf_image(const char *name)
+{
+	return strncmp(name, "bpf_trampoline_", sizeof("bpf_trampoline_") - 1) ||
+	       strncmp(name, "bpf_dispatcher_", sizeof("bpf_dispatcher_") - 1);
+}
+
 static int machine__process_ksymbol_register(struct machine *machine,
 					     union perf_event *event,
 					     struct perf_sample *sample __maybe_unused)
@@ -760,6 +766,11 @@ static int machine__process_ksymbol_register(struct machine *machine,
 		map->end = map->start + event->ksymbol.len;
 		maps__insert(&machine->kmaps, map);
 		dso__set_loaded(dso);
+
+		if (is_bpf_image(event->ksymbol.name)) {
+			dso->binary_type = DSO_BINARY_TYPE__BPF_IMAGE;
+			dso__set_long_name(dso, "", false);
+		}
 	}
 
 	sym = symbol__new(map->map_ip(map, map->start),

commit 7eddf7e74e54aea3b24410b3fb8911927836632f
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Thu Mar 12 20:56:09 2020 +0100

    perf machine: Set ksymbol dso as loaded on arrival
    
    There's no special load action for ksymbol data on map__load/dso__load
    action, where the kernel is getting loaded. It only gets confused with
    kernel kallsyms/vmlinux load for bpf object, which fails and could mess
    up with the map.
    
    Disabling any further load of the map for ksymbol related dso/map.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Acked-by: Song Liu <songliubraving@fb.com>
    Cc: Alexei Starovoitov <ast@kernel.org>
    Cc: Andrii Nakryiko <andriin@fb.com>
    Cc: BjÃ¶rn TÃ¶pel <bjorn.topel@intel.com>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: David S. Miller <davem@redhat.com>
    Cc: Jakub Kicinski <kuba@kernel.org>
    Cc: Jesper Dangaard Brouer <hawk@kernel.org>
    Cc: John Fastabend <john.fastabend@gmail.com>
    Cc: Martin KaFai Lau <kafai@fb.com>
    Cc: Yonghong Song <yhs@fb.com>
    Link: https://lore.kernel.org/bpf/20200312195610.346362-15-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 97142e9671be..06aa4e4db63d 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -759,6 +759,7 @@ static int machine__process_ksymbol_register(struct machine *machine,
 		map->start = event->ksymbol.addr;
 		map->end = map->start + event->ksymbol.len;
 		maps__insert(&machine->kmaps, map);
+		dso__set_loaded(dso);
 	}
 
 	sym = symbol__new(map->map_ip(map, map->start),

commit d1277aa36bff4bfc1a187a469fc6a6a1d17cf59c
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Wed Mar 25 21:45:31 2020 +0900

    perf cgroup: Maintain cgroup hierarchy
    
    Each cgroup is kept in the perf_env's cgroup_tree sorted by the cgroup
    id.  Hist entries have cgroup id can compare it directly and later it
    can be used to find a group name using this tree.
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lore.kernel.org/lkml/20200325124536.2800725-5-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 399b4731b246..97142e9671be 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -33,6 +33,7 @@
 #include "asm/bug.h"
 #include "bpf-event.h"
 #include <internal/lib.h> // page_size
+#include "cgroup.h"
 
 #include <linux/ctype.h>
 #include <symbol/kallsyms.h>
@@ -654,13 +655,19 @@ int machine__process_namespaces_event(struct machine *machine __maybe_unused,
 	return err;
 }
 
-int machine__process_cgroup_event(struct machine *machine __maybe_unused,
+int machine__process_cgroup_event(struct machine *machine,
 				  union perf_event *event,
 				  struct perf_sample *sample __maybe_unused)
 {
+	struct cgroup *cgrp;
+
 	if (dump_trace)
 		perf_event__fprintf_cgroup(event, stdout);
 
+	cgrp = cgroup__findnew(machine->env, event->cgroup.id, event->cgroup.path);
+	if (cgrp == NULL)
+		return -ENOMEM;
+
 	return 0;
 }
 

commit ba78c1c5461c2fc2f57b777e971b3a9ec0df5666
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Wed Mar 25 21:45:30 2020 +0900

    perf tools: Basic support for CGROUP event
    
    Implement basic functionality to support cgroup tracking.  Each cgroup
    can be identified by inode number which can be read from userspace too.
    The actual cgroup processing will come in the later patch.
    
    Reported-by: kernel test robot <rong.a.chen@intel.com>
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    [ fix perf test failure on sampling parsing ]
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lore.kernel.org/lkml/20200325124536.2800725-4-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index fd14f1489802..399b4731b246 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -654,6 +654,16 @@ int machine__process_namespaces_event(struct machine *machine __maybe_unused,
 	return err;
 }
 
+int machine__process_cgroup_event(struct machine *machine __maybe_unused,
+				  union perf_event *event,
+				  struct perf_sample *sample __maybe_unused)
+{
+	if (dump_trace)
+		perf_event__fprintf_cgroup(event, stdout);
+
+	return 0;
+}
+
 int machine__process_lost_event(struct machine *machine __maybe_unused,
 				union perf_event *event, struct perf_sample *sample __maybe_unused)
 {
@@ -1878,6 +1888,8 @@ int machine__process_event(struct machine *machine, union perf_event *event,
 		ret = machine__process_mmap_event(machine, event, sample); break;
 	case PERF_RECORD_NAMESPACES:
 		ret = machine__process_namespaces_event(machine, event, sample); break;
+	case PERF_RECORD_CGROUP:
+		ret = machine__process_cgroup_event(machine, event, sample); break;
 	case PERF_RECORD_MMAP2:
 		ret = machine__process_mmap2_event(machine, event, sample); break;
 	case PERF_RECORD_FORK:

commit 42bbabed09ce6208026648a71a45b4394c74585a
Author: Kan Liang <kan.liang@linux.intel.com>
Date:   Fri Feb 28 08:30:00 2020 -0800

    perf tools: Add hw_idx in struct branch_stack
    
    The low level index of raw branch records for the most recent branch can
    be recorded in a sample with PERF_SAMPLE_BRANCH_HW_INDEX
    branch_sample_type. Extend struct branch_stack to support it.
    
    However, if the PERF_SAMPLE_BRANCH_HW_INDEX is not applied, only nr and
    entries[] will be output by kernel. The pointer of entries[] could be
    wrong, since the output format is different with new struct
    branch_stack.  Add a variable no_hw_idx in struct perf_sample to
    indicate whether the hw_idx is output.  Add get_branch_entry() to return
    corresponding pointer of entries[0].
    
    To make dummy branch sample consistent as new branch sample, add hw_idx
    in struct dummy_branch_stack for cs-etm and intel-pt.
    
    Apply the new struct branch_stack for synthetic events as well.
    
    Extend test case sample-parsing to support new struct branch_stack.
    
    Committer notes:
    
    Renamed get_branch_entries() to perf_sample__branch_entries() to have
    proper namespacing and pave the way for this to be moved to libperf,
    eventually.
    
    Add 'static' to that inline as it is in a header.
    
    Add 'hw_idx' to 'struct dummy_branch_stack' in cs-etm.c to fix the build
    on arm64.
    
    Signed-off-by: Kan Liang <kan.liang@linux.intel.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexey Budankov <alexey.budankov@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mathieu Poirier <mathieu.poirier@linaro.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Pavel Gerasimov <pavel.gerasimov@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Vitaly Slobodskoy <vitaly.slobodskoy@intel.com>
    Link: http://lore.kernel.org/lkml/20200228163011.19358-2-kan.liang@linux.intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index fb5c2cd44d30..fd14f1489802 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2081,15 +2081,16 @@ struct branch_info *sample__resolve_bstack(struct perf_sample *sample,
 {
 	unsigned int i;
 	const struct branch_stack *bs = sample->branch_stack;
+	struct branch_entry *entries = perf_sample__branch_entries(sample);
 	struct branch_info *bi = calloc(bs->nr, sizeof(struct branch_info));
 
 	if (!bi)
 		return NULL;
 
 	for (i = 0; i < bs->nr; i++) {
-		ip__resolve_ams(al->thread, &bi[i].to, bs->entries[i].to);
-		ip__resolve_ams(al->thread, &bi[i].from, bs->entries[i].from);
-		bi[i].flags = bs->entries[i].flags;
+		ip__resolve_ams(al->thread, &bi[i].to, entries[i].to);
+		ip__resolve_ams(al->thread, &bi[i].from, entries[i].from);
+		bi[i].flags = entries[i].flags;
 	}
 	return bi;
 }
@@ -2185,6 +2186,7 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 	/* LBR only affects the user callchain */
 	if (i != chain_nr) {
 		struct branch_stack *lbr_stack = sample->branch_stack;
+		struct branch_entry *entries = perf_sample__branch_entries(sample);
 		int lbr_nr = lbr_stack->nr, j, k;
 		bool branch;
 		struct branch_flags *flags;
@@ -2210,31 +2212,29 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 					ip = chain->ips[j];
 				else if (j > i + 1) {
 					k = j - i - 2;
-					ip = lbr_stack->entries[k].from;
+					ip = entries[k].from;
 					branch = true;
-					flags = &lbr_stack->entries[k].flags;
+					flags = &entries[k].flags;
 				} else {
-					ip = lbr_stack->entries[0].to;
+					ip = entries[0].to;
 					branch = true;
-					flags = &lbr_stack->entries[0].flags;
-					branch_from =
-						lbr_stack->entries[0].from;
+					flags = &entries[0].flags;
+					branch_from = entries[0].from;
 				}
 			} else {
 				if (j < lbr_nr) {
 					k = lbr_nr - j - 1;
-					ip = lbr_stack->entries[k].from;
+					ip = entries[k].from;
 					branch = true;
-					flags = &lbr_stack->entries[k].flags;
+					flags = &entries[k].flags;
 				}
 				else if (j > lbr_nr)
 					ip = chain->ips[i + 1 - (j - lbr_nr)];
 				else {
-					ip = lbr_stack->entries[0].to;
+					ip = entries[0].to;
 					branch = true;
-					flags = &lbr_stack->entries[0].flags;
-					branch_from =
-						lbr_stack->entries[0].from;
+					flags = &entries[0].flags;
+					branch_from = entries[0].from;
 				}
 			}
 
@@ -2281,6 +2281,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 					    int max_stack)
 {
 	struct branch_stack *branch = sample->branch_stack;
+	struct branch_entry *entries = perf_sample__branch_entries(sample);
 	struct ip_callchain *chain = sample->callchain;
 	int chain_nr = 0;
 	u8 cpumode = PERF_RECORD_MISC_USER;
@@ -2328,7 +2329,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 
 		for (i = 0; i < nr; i++) {
 			if (callchain_param.order == ORDER_CALLEE) {
-				be[i] = branch->entries[i];
+				be[i] = entries[i];
 
 				if (chain == NULL)
 					continue;
@@ -2347,7 +2348,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 				    be[i].from >= chain->ips[first_call] - 8)
 					first_call++;
 			} else
-				be[i] = branch->entries[branch->nr - i - 1];
+				be[i] = entries[branch->nr - i - 1];
 		}
 
 		memset(iter, 0, sizeof(struct iterations) * nr);

commit 484214f49bd0948d716832a94e4737ca4dd02c16
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Mon Feb 10 15:32:18 2020 +0100

    perf maps: Move kmap::kmaps setup to maps__insert()
    
    So the kmaps pointer setup is centralized and we do not need to update
    it in all those places (2 current places and few more missing) after
    calling maps__insert().
    
    Reported-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Tested-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Tested-by: Kim Phillips <kim.phillips@amd.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Michael Petlan <mpetlan@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lore.kernel.org/lkml/20200210143218.24948-5-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 0ad026561c7f..fb5c2cd44d30 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -981,7 +981,6 @@ int machine__create_extra_kernel_map(struct machine *machine,
 
 	kmap = map__kmap(map);
 
-	kmap->kmaps = &machine->kmaps;
 	strlcpy(kmap->name, xm->name, KMAP_NAME_LEN);
 
 	maps__insert(&machine->kmaps, map);
@@ -1091,9 +1090,6 @@ int __weak machine__create_extra_kernel_maps(struct machine *machine __maybe_unu
 static int
 __machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
 {
-	struct kmap *kmap;
-	struct map *map;
-
 	/* In case of renewal the kernel map, destroy previous one */
 	machine__destroy_kernel_maps(machine);
 
@@ -1102,14 +1098,7 @@ __machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
 		return -1;
 
 	machine->vmlinux_map->map_ip = machine->vmlinux_map->unmap_ip = identity__map_ip;
-	map = machine__kernel_map(machine);
-	kmap = map__kmap(map);
-	if (!kmap)
-		return -1;
-
-	kmap->kmaps = &machine->kmaps;
-	maps__insert(&machine->kmaps, map);
-
+	maps__insert(&machine->kmaps, machine->vmlinux_map);
 	return 0;
 }
 

commit 4a4eb6154d67f7766cc7eb74e9f1db424073e832
Author: Jiri Olsa <jolsa@redhat.com>
Date:   Mon Feb 10 21:08:47 2020 +0100

    perf maps: Mark ksymbol DSOs with kernel type
    
    We add ksymbol map into machine->kmaps, so it needs to be created as
    'struct kmap', which is dependent on its dso having kernel type.
    
    Reported-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Tested-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Tested-by: Kim Phillips <kim.phillips@amd.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Michael Petlan <mpetlan@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lore.kernel.org/lkml/20200210200847.GA36715@krava
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index e3e5490f6de5..0ad026561c7f 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -727,9 +727,17 @@ static int machine__process_ksymbol_register(struct machine *machine,
 	struct map *map = maps__find(&machine->kmaps, event->ksymbol.addr);
 
 	if (!map) {
-		map = dso__new_map(event->ksymbol.name);
-		if (!map)
+		struct dso *dso = dso__new(event->ksymbol.name);
+
+		if (dso) {
+			dso->kernel = DSO_TYPE_KERNEL;
+			map = map__new2(0, dso);
+		}
+
+		if (!dso || !map) {
+			dso__put(dso);
 			return -ENOMEM;
+		}
 
 		map->start = event->ksymbol.addr;
 		map->end = map->start + event->ksymbol.len;

commit 02213cec64bbef66d7ad9ddc3b7c47236da64343
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Mon Feb 10 15:32:15 2020 +0100

    perf maps: Mark module DSOs with kernel type
    
    We add kernel module map into machine->kmaps, so it needs to be created
    as 'struct kmap', which is dependent on its dso having kernel type.
    
    Reported-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Tested-by: Kim Phillips <kim.phillips@amd.com>
    Tested-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Michael Petlan <mpetlan@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lore.kernel.org/lkml/20200210143218.24948-2-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index c8c5410315e8..e3e5490f6de5 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -686,6 +686,7 @@ static struct dso *machine__findnew_module_dso(struct machine *machine,
 
 		dso__set_module_info(dso, m, machine);
 		dso__set_long_name(dso, strdup(filename), true);
+		dso->kernel = DSO_TYPE_KERNEL;
 	}
 
 	dso__get(dso);

commit 77b91c1a525d84cb560a4baef6f5f548b5c23f80
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri Nov 29 15:47:51 2019 -0300

    perf machine: Fill map_symbol->maps in append_inlines() to fix segfault
    
    I forgot to fill in the map_symbol->maps field in append_inlines() which
    then makes code down the line segfault when trying to deref it.
    
    It doesn't make any sense to have an addr_location with its 'map' member
    not NULL while its 'maps' is NULL, after all al->maps is where al->map
    is in.
    
    It is done that way so that we don't have to have in each 'struct map' a
    pointer to the 'struct maps' it is in, as we had in the past when we
    would have 'map->mg', before 'struct maps' was combined with 'struct
    map_groups', because there was always a one-to-one relationship for
    these structs.
    
    This fixes a segfault when processing DWARF callgraphs in 'perf report'.
    
    Reported-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Fixes: 08f6680e627e ("perf tools: Add a 'struct map_groups' pointer to 'struct map_symbol'")
    Link: http://lore.kernel.org/lkml/20191129160631.GD26963@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 416d174d223c..c8c5410315e8 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2446,6 +2446,7 @@ static int append_inlines(struct callchain_cursor *cursor, struct map_symbol *ms
 
 	list_for_each_entry(ilist, &inline_node->val, list) {
 		struct map_symbol ilist_ms = {
+			.maps = ms->maps,
 			.map = map,
 			.sym = ilist->symbol,
 		};

commit 9a29ceee6bb14aeb58ab2222c8e792576fe90fb8
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Nov 25 22:21:28 2019 -0300

    perf maps: Rename 'mg' variables to 'maps'
    
    Continuing the merge of 'struct maps' with 'struct map_groups'.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-z8d14wrw393a0fbvmnk1bqd9@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index c1ae5e6f84e2..416d174d223c 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1259,10 +1259,10 @@ static bool is_kmod_dso(struct dso *dso)
 	       dso->symtab_type == DSO_BINARY_TYPE__GUEST_KMODULE;
 }
 
-static int maps__set_module_path(struct maps *mg, const char *path, struct kmod_path *m)
+static int maps__set_module_path(struct maps *maps, const char *path, struct kmod_path *m)
 {
 	char *long_name;
-	struct map *map = maps__find_by_name(mg, m->name);
+	struct map *map = maps__find_by_name(maps, m->name);
 
 	if (map == NULL)
 		return 0;
@@ -1286,7 +1286,7 @@ static int maps__set_module_path(struct maps *mg, const char *path, struct kmod_
 	return 0;
 }
 
-static int maps__set_modules_path_dir(struct maps *mg, const char *dir_name, int depth)
+static int maps__set_modules_path_dir(struct maps *maps, const char *dir_name, int depth)
 {
 	struct dirent *dent;
 	DIR *dir = opendir(dir_name);
@@ -1318,7 +1318,7 @@ static int maps__set_modules_path_dir(struct maps *mg, const char *dir_name, int
 					continue;
 			}
 
-			ret = maps__set_modules_path_dir(mg, path, depth + 1);
+			ret = maps__set_modules_path_dir(maps, path, depth + 1);
 			if (ret < 0)
 				goto out;
 		} else {
@@ -1329,7 +1329,7 @@ static int maps__set_modules_path_dir(struct maps *mg, const char *dir_name, int
 				goto out;
 
 			if (m.kmod)
-				ret = maps__set_module_path(mg, path, &m);
+				ret = maps__set_module_path(maps, path, &m);
 
 			zfree(&m.name);
 

commit f2eaea09d684177f57db55a9ce2b67d048083fd5
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Nov 25 22:15:35 2019 -0300

    perf map_symbol: Rename ms->mg to ms->maps
    
    One more step on the merge of 'struct maps' with 'struct map_groups'.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-61rra2wg392rhvdgw421wzpt@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index de5d6b4727e3..c1ae5e6f84e2 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1934,7 +1934,7 @@ static void ip__resolve_ams(struct thread *thread,
 
 	ams->addr = ip;
 	ams->al_addr = al.addr;
-	ams->ms.mg  = al.maps;
+	ams->ms.maps = al.maps;
 	ams->ms.sym = al.sym;
 	ams->ms.map = al.map;
 	ams->phys_addr = 0;
@@ -1952,7 +1952,7 @@ static void ip__resolve_data(struct thread *thread,
 
 	ams->addr = addr;
 	ams->al_addr = al.addr;
-	ams->ms.mg  = al.maps;
+	ams->ms.maps = al.maps;
 	ams->ms.sym = al.sym;
 	ams->ms.map = al.map;
 	ams->phys_addr = phys_addr;
@@ -2069,7 +2069,7 @@ static int add_callchain_ip(struct thread *thread,
 		iter_cycles = iter->cycles;
 	}
 
-	ms.mg  = al.maps;
+	ms.maps = al.maps;
 	ms.map = al.map;
 	ms.sym = al.sym;
 	srcline = callchain_srcline(&ms, al.addr);

commit 694520dfeb474619402620b68edf08e60ca36a17
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Nov 25 22:11:20 2019 -0300

    perf addr_location: Rename al->mg to al->maps
    
    One more step on the merge of 'struct maps' with 'struct map_groups'.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-foo95pyyp3bhocbt7yd8qrvq@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index b351476407e6..de5d6b4727e3 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1934,7 +1934,7 @@ static void ip__resolve_ams(struct thread *thread,
 
 	ams->addr = ip;
 	ams->al_addr = al.addr;
-	ams->ms.mg  = al.mg;
+	ams->ms.mg  = al.maps;
 	ams->ms.sym = al.sym;
 	ams->ms.map = al.map;
 	ams->phys_addr = 0;
@@ -1952,7 +1952,7 @@ static void ip__resolve_data(struct thread *thread,
 
 	ams->addr = addr;
 	ams->al_addr = al.addr;
-	ams->ms.mg  = al.mg;
+	ams->ms.mg  = al.maps;
 	ams->ms.sym = al.sym;
 	ams->ms.map = al.map;
 	ams->phys_addr = phys_addr;
@@ -2069,7 +2069,7 @@ static int add_callchain_ip(struct thread *thread,
 		iter_cycles = iter->cycles;
 	}
 
-	ms.mg  = al.mg;
+	ms.mg  = al.maps;
 	ms.map = al.map;
 	ms.sym = al.sym;
 	srcline = callchain_srcline(&ms, al.addr);

commit fe87797dea79b59e97a4ea67441bf91f2905bf23
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Nov 25 22:07:43 2019 -0300

    perf thread: Rename thread->mg to thread->maps
    
    One more step on the merge of 'struct maps' with 'struct map_groups'.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-69vcr8pubpym90skxhmbwhiw@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index d646aea39333..b351476407e6 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -412,28 +412,28 @@ static void machine__update_thread_pid(struct machine *machine,
 	if (!leader)
 		goto out_err;
 
-	if (!leader->mg)
-		leader->mg = maps__new(machine);
+	if (!leader->maps)
+		leader->maps = maps__new(machine);
 
-	if (!leader->mg)
+	if (!leader->maps)
 		goto out_err;
 
-	if (th->mg == leader->mg)
+	if (th->maps == leader->maps)
 		return;
 
-	if (th->mg) {
+	if (th->maps) {
 		/*
 		 * Maps are created from MMAP events which provide the pid and
 		 * tid.  Consequently there never should be any maps on a thread
 		 * with an unknown pid.  Just print an error if there are.
 		 */
-		if (!maps__empty(th->mg))
+		if (!maps__empty(th->maps))
 			pr_err("Discarding thread maps for %d:%d\n",
 			       th->pid_, th->tid);
-		maps__put(th->mg);
+		maps__put(th->maps);
 	}
 
-	th->mg = maps__get(leader->mg);
+	th->maps = maps__get(leader->maps);
 out_put:
 	thread__put(leader);
 	return;

commit 79b6bb73f888933cbcd20b0ef3976cde67951b72
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Nov 25 21:58:33 2019 -0300

    perf maps: Merge 'struct maps' with 'struct map_groups'
    
    And pick the shortest name: 'struct maps'.
    
    The split existed because we used to have two groups of maps, one for
    functions and one for variables, but that only complicated things,
    sometimes we needed to figure out what was at some address and then had
    to first try it on the functions group and if that failed, fall back to
    the variables one.
    
    That split is long gone, so for quite a while we had only one struct
    maps per struct map_groups, simplify things by combining those structs.
    
    First patch is the minimum needed to merge both, follow up patches will
    rename 'thread->mg' to 'thread->maps', etc.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-hom6639ro7020o708trhxh59@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index e2a312c649f0..d646aea39333 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -86,7 +86,7 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 	int err = -ENOMEM;
 
 	memset(machine, 0, sizeof(*machine));
-	map_groups__init(&machine->kmaps, machine);
+	maps__init(&machine->kmaps, machine);
 	RB_CLEAR_NODE(&machine->rb_node);
 	dsos__init(&machine->dsos);
 
@@ -217,7 +217,7 @@ void machine__exit(struct machine *machine)
 		return;
 
 	machine__destroy_kernel_maps(machine);
-	map_groups__exit(&machine->kmaps);
+	maps__exit(&machine->kmaps);
 	dsos__exit(&machine->dsos);
 	machine__exit_vdso(machine);
 	zfree(&machine->root_dir);
@@ -413,7 +413,7 @@ static void machine__update_thread_pid(struct machine *machine,
 		goto out_err;
 
 	if (!leader->mg)
-		leader->mg = map_groups__new(machine);
+		leader->mg = maps__new(machine);
 
 	if (!leader->mg)
 		goto out_err;
@@ -427,13 +427,13 @@ static void machine__update_thread_pid(struct machine *machine,
 		 * tid.  Consequently there never should be any maps on a thread
 		 * with an unknown pid.  Just print an error if there are.
 		 */
-		if (!map_groups__empty(th->mg))
+		if (!maps__empty(th->mg))
 			pr_err("Discarding thread maps for %d:%d\n",
 			       th->pid_, th->tid);
-		map_groups__put(th->mg);
+		maps__put(th->mg);
 	}
 
-	th->mg = map_groups__get(leader->mg);
+	th->mg = maps__get(leader->mg);
 out_put:
 	thread__put(leader);
 	return;
@@ -536,14 +536,13 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 		rb_insert_color_cached(&th->rb_node, &threads->entries, leftmost);
 
 		/*
-		 * We have to initialize map_groups separately
-		 * after rb tree is updated.
+		 * We have to initialize maps separately after rb tree is updated.
 		 *
 		 * The reason is that we call machine__findnew_thread
-		 * within thread__init_map_groups to find the thread
+		 * within thread__init_maps to find the thread
 		 * leader and that would screwed the rb tree.
 		 */
-		if (thread__init_map_groups(th, machine)) {
+		if (thread__init_maps(th, machine)) {
 			rb_erase_cached(&th->rb_node, &threads->entries);
 			RB_CLEAR_NODE(&th->rb_node);
 			thread__put(th);
@@ -724,9 +723,8 @@ static int machine__process_ksymbol_register(struct machine *machine,
 					     struct perf_sample *sample __maybe_unused)
 {
 	struct symbol *sym;
-	struct map *map;
+	struct map *map = maps__find(&machine->kmaps, event->ksymbol.addr);
 
-	map = map_groups__find(&machine->kmaps, event->ksymbol.addr);
 	if (!map) {
 		map = dso__new_map(event->ksymbol.name);
 		if (!map)
@@ -734,7 +732,7 @@ static int machine__process_ksymbol_register(struct machine *machine,
 
 		map->start = event->ksymbol.addr;
 		map->end = map->start + event->ksymbol.len;
-		map_groups__insert(&machine->kmaps, map);
+		maps__insert(&machine->kmaps, map);
 	}
 
 	sym = symbol__new(map->map_ip(map, map->start),
@@ -752,9 +750,9 @@ static int machine__process_ksymbol_unregister(struct machine *machine,
 {
 	struct map *map;
 
-	map = map_groups__find(&machine->kmaps, event->ksymbol.addr);
+	map = maps__find(&machine->kmaps, event->ksymbol.addr);
 	if (map)
-		map_groups__remove(&machine->kmaps, map);
+		maps__remove(&machine->kmaps, map);
 
 	return 0;
 }
@@ -790,9 +788,9 @@ static struct map *machine__addnew_module_map(struct machine *machine, u64 start
 	if (map == NULL)
 		goto out;
 
-	map_groups__insert(&machine->kmaps, map);
+	maps__insert(&machine->kmaps, map);
 
-	/* Put the map here because map_groups__insert alread got it */
+	/* Put the map here because maps__insert alread got it */
 	map__put(map);
 out:
 	/* put the dso here, corresponding to  machine__findnew_module_dso */
@@ -977,7 +975,7 @@ int machine__create_extra_kernel_map(struct machine *machine,
 	kmap->kmaps = &machine->kmaps;
 	strlcpy(kmap->name, xm->name, KMAP_NAME_LEN);
 
-	map_groups__insert(&machine->kmaps, map);
+	maps__insert(&machine->kmaps, map);
 
 	pr_debug2("Added extra kernel map %s %" PRIx64 "-%" PRIx64 "\n",
 		  kmap->name, map->start, map->end);
@@ -1022,8 +1020,7 @@ static u64 find_entry_trampoline(struct dso *dso)
 int machine__map_x86_64_entry_trampolines(struct machine *machine,
 					  struct dso *kernel)
 {
-	struct map_groups *kmaps = &machine->kmaps;
-	struct maps *maps = &kmaps->maps;
+	struct maps *kmaps = &machine->kmaps;
 	int nr_cpus_avail, cpu;
 	bool found = false;
 	struct map *map;
@@ -1033,14 +1030,14 @@ int machine__map_x86_64_entry_trampolines(struct machine *machine,
 	 * In the vmlinux case, pgoff is a virtual address which must now be
 	 * mapped to a vmlinux offset.
 	 */
-	maps__for_each_entry(maps, map) {
+	maps__for_each_entry(kmaps, map) {
 		struct kmap *kmap = __map__kmap(map);
 		struct map *dest_map;
 
 		if (!kmap || !is_entry_trampoline(kmap->name))
 			continue;
 
-		dest_map = map_groups__find(kmaps, map->pgoff);
+		dest_map = maps__find(kmaps, map->pgoff);
 		if (dest_map != map)
 			map->pgoff = dest_map->map_ip(dest_map, map->pgoff);
 		found = true;
@@ -1102,7 +1099,7 @@ __machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
 		return -1;
 
 	kmap->kmaps = &machine->kmaps;
-	map_groups__insert(&machine->kmaps, map);
+	maps__insert(&machine->kmaps, map);
 
 	return 0;
 }
@@ -1116,7 +1113,7 @@ void machine__destroy_kernel_maps(struct machine *machine)
 		return;
 
 	kmap = map__kmap(map);
-	map_groups__remove(&machine->kmaps, map);
+	maps__remove(&machine->kmaps, map);
 	if (kmap && kmap->ref_reloc_sym) {
 		zfree((char **)&kmap->ref_reloc_sym->name);
 		zfree(&kmap->ref_reloc_sym);
@@ -1211,7 +1208,7 @@ int machine__load_kallsyms(struct machine *machine, const char *filename)
 		 * kernel, with modules between them, fixup the end of all
 		 * sections.
 		 */
-		map_groups__fixup_end(&machine->kmaps);
+		maps__fixup_end(&machine->kmaps);
 	}
 
 	return ret;
@@ -1262,11 +1259,10 @@ static bool is_kmod_dso(struct dso *dso)
 	       dso->symtab_type == DSO_BINARY_TYPE__GUEST_KMODULE;
 }
 
-static int map_groups__set_module_path(struct map_groups *mg, const char *path,
-				       struct kmod_path *m)
+static int maps__set_module_path(struct maps *mg, const char *path, struct kmod_path *m)
 {
 	char *long_name;
-	struct map *map = map_groups__find_by_name(mg, m->name);
+	struct map *map = maps__find_by_name(mg, m->name);
 
 	if (map == NULL)
 		return 0;
@@ -1290,8 +1286,7 @@ static int map_groups__set_module_path(struct map_groups *mg, const char *path,
 	return 0;
 }
 
-static int map_groups__set_modules_path_dir(struct map_groups *mg,
-				const char *dir_name, int depth)
+static int maps__set_modules_path_dir(struct maps *mg, const char *dir_name, int depth)
 {
 	struct dirent *dent;
 	DIR *dir = opendir(dir_name);
@@ -1323,8 +1318,7 @@ static int map_groups__set_modules_path_dir(struct map_groups *mg,
 					continue;
 			}
 
-			ret = map_groups__set_modules_path_dir(mg, path,
-							       depth + 1);
+			ret = maps__set_modules_path_dir(mg, path, depth + 1);
 			if (ret < 0)
 				goto out;
 		} else {
@@ -1335,7 +1329,7 @@ static int map_groups__set_modules_path_dir(struct map_groups *mg,
 				goto out;
 
 			if (m.kmod)
-				ret = map_groups__set_module_path(mg, path, &m);
+				ret = maps__set_module_path(mg, path, &m);
 
 			zfree(&m.name);
 
@@ -1362,7 +1356,7 @@ static int machine__set_modules_path(struct machine *machine)
 		 machine->root_dir, version);
 	free(version);
 
-	return map_groups__set_modules_path_dir(&machine->kmaps, modules_path, 0);
+	return maps__set_modules_path_dir(&machine->kmaps, modules_path, 0);
 }
 int __weak arch__fix_module_text_start(u64 *start __maybe_unused,
 				u64 *size __maybe_unused,
@@ -1435,11 +1429,11 @@ static void machine__update_kernel_mmap(struct machine *machine,
 	struct map *map = machine__kernel_map(machine);
 
 	map__get(map);
-	map_groups__remove(&machine->kmaps, map);
+	maps__remove(&machine->kmaps, map);
 
 	machine__set_kernel_mmap(machine, start, end);
 
-	map_groups__insert(&machine->kmaps, map);
+	maps__insert(&machine->kmaps, map);
 	map__put(map);
 }
 

commit 0e3149f86b99ddabde8c5029eea0a9267e34f1a0
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Nov 19 18:44:22 2019 -0300

    perf dso: Move dso_id from 'struct map' to 'struct dso'
    
    And take it into account when looking up DSOs when we have the dso_id
    fields obtained from somewhere, like from PERF_RECORD_MMAP2 records.
    
    Instances of struct map pointing to the same DSO pathname but with
    anything in dso_id different are in fact different DSOs, so better have
    different 'struct dso' instances to reflect that. At some point we may
    want to get copies of the contents of the different objects if we want
    to do correct annotation or other analysis.
    
    With this we get 'struct map' 24 bytes leaner:
    
      $ pahole -C map ~/bin/perf
      struct map {
            union {
                    struct rb_node     rb_node __attribute__((__aligned__(8))); /*     0    24 */
                    struct list_head   node;                 /*     0    16 */
            } __attribute__((__aligned__(8)));               /*     0    24 */
            u64                        start;                /*    24     8 */
            u64                        end;                  /*    32     8 */
            _Bool                      erange_warned:1;      /*    40: 0  1 */
            _Bool                      priv:1;               /*    40: 1  1 */
    
            /* XXX 6 bits hole, try to pack */
            /* XXX 3 bytes hole, try to pack */
    
            u32                        prot;                 /*    44     4 */
            u64                        pgoff;                /*    48     8 */
            u64                        reloc;                /*    56     8 */
            /* --- cacheline 1 boundary (64 bytes) --- */
            u64                        (*map_ip)(struct map *, u64); /*    64     8 */
            u64                        (*unmap_ip)(struct map *, u64); /*    72     8 */
            struct dso *               dso;                  /*    80     8 */
            refcount_t                 refcnt;               /*    88     4 */
            u32                        flags;                /*    92     4 */
    
            /* size: 96, cachelines: 2, members: 13 */
            /* sum members: 92, holes: 1, sum holes: 3 */
            /* sum bitfield members: 2 bits, bit holes: 1, sum bit holes: 6 bits */
            /* forced alignments: 1 */
            /* last cacheline: 32 bytes */
      } __attribute__((__aligned__(8)));
      $
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-g4hxxmraplo7wfjmk384mfsb@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 41b4263c073d..e2a312c649f0 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2711,9 +2711,14 @@ u8 machine__addr_cpumode(struct machine *machine, u8 cpumode, u64 addr)
 	return addr_cpumode;
 }
 
+struct dso *machine__findnew_dso_id(struct machine *machine, const char *filename, struct dso_id *id)
+{
+	return dsos__findnew_id(&machine->dsos, filename, id);
+}
+
 struct dso *machine__findnew_dso(struct machine *machine, const char *filename)
 {
-	return dsos__findnew(&machine->dsos, filename);
+	return machine__findnew_dso_id(machine, filename, NULL);
 }
 
 char *machine__resolve_kernel_addr(void *vmachine, unsigned long long *addrp, char **modp)

commit 4a7380a52ec90fbb1565dd638ee7f5b6e709f7fb
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Nov 19 12:40:29 2019 -0300

    perf map: Pass a dso_id to map__new()
    
    Instead of the 4 fields, a step in the direction of moving this to
    struct dso.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-gp5s1xgxacurmih5d1l94ymy@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 71ee078d30f4..41b4263c073d 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1651,6 +1651,12 @@ int machine__process_mmap2_event(struct machine *machine,
 {
 	struct thread *thread;
 	struct map *map;
+	struct dso_id dso_id = {
+		.maj = event->mmap2.maj,
+		.min = event->mmap2.min,
+		.ino = event->mmap2.ino,
+		.ino_generation = event->mmap2.ino_generation,
+	};
 	int ret = 0;
 
 	if (dump_trace)
@@ -1671,10 +1677,7 @@ int machine__process_mmap2_event(struct machine *machine,
 
 	map = map__new(machine, event->mmap2.start,
 			event->mmap2.len, event->mmap2.pgoff,
-			event->mmap2.maj,
-			event->mmap2.min, event->mmap2.ino,
-			event->mmap2.ino_generation,
-			event->mmap2.prot,
+			&dso_id, event->mmap2.prot,
 			event->mmap2.flags,
 			event->mmap2.filename, thread);
 
@@ -1727,9 +1730,7 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 
 	map = map__new(machine, event->mmap.start,
 			event->mmap.len, event->mmap.pgoff,
-			0, 0, 0, 0, prot, 0,
-			event->mmap.filename,
-			thread);
+			NULL, prot, 0, event->mmap.filename, thread);
 
 	if (map == NULL)
 		goto out_problem_map;

commit aceb98261ea7d9fe38f9c140c5531f0b13623832
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Thu Nov 14 16:25:38 2019 +0200

    perf callchain: Fix segfault in thread__resolve_callchain_sample()
    
    Do not dereference 'chain' when it is NULL.
    
      $ perf record -e intel_pt//u -e branch-misses:u uname
      $ perf report --itrace=l --branch-history
      perf: Segmentation fault
    
    Fixes: e9024d519d89 ("perf callchain: Honour the ordering of PERF_CONTEXT_{USER,KERNEL,etc}")
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Link: http://lore.kernel.org/lkml/20191114142538.4097-1-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 7d2e211e376c..71ee078d30f4 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2385,7 +2385,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	}
 
 check_calls:
-	if (callchain_param.order != ORDER_CALLEE) {
+	if (chain && callchain_param.order != ORDER_CALLEE) {
 		err = find_prev_cpumode(chain, thread, cursor, parent, root_al,
 					&cpumode, chain->nr - first_call);
 		if (err)

commit a94ab91a54c63b9101715b03171219279cc0ee26
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Nov 14 12:28:41 2019 -0300

    perf machine: No need to check if kernel module maps pre-exist
    
    We'only populating maps for kernel modules either from perf.data file
    PERF_RECORD_MMAP records or when parsing /proc/modules, so there is no
    need to first look if we already have those module maps in the list,
    that would mean the kernel has duplicate entries.
    
    So ditch one use of looking up maps by name.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-gnzjg2hhuz6jnrw91m35059y@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 6804c8247782..7d2e211e376c 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -772,20 +772,16 @@ int machine__process_ksymbol(struct machine *machine __maybe_unused,
 	return machine__process_ksymbol_register(machine, event, sample);
 }
 
-struct map *machine__findnew_module_map(struct machine *machine, u64 start,
-					const char *filename)
+static struct map *machine__addnew_module_map(struct machine *machine, u64 start,
+					      const char *filename)
 {
 	struct map *map = NULL;
-	struct dso *dso = NULL;
 	struct kmod_path m;
+	struct dso *dso;
 
 	if (kmod_path__parse_name(&m, filename))
 		return NULL;
 
-	map = map_groups__find_by_name(&machine->kmaps, m.name);
-	if (map)
-		goto out;
-
 	dso = machine__findnew_module_dso(machine, &m, filename);
 	if (dso == NULL)
 		goto out;
@@ -1384,7 +1380,7 @@ static int machine__create_module(void *arg, const char *name, u64 start,
 	if (arch__fix_module_text_start(&start, &size, name) < 0)
 		return -1;
 
-	map = machine__findnew_module_map(machine, start, name);
+	map = machine__addnew_module_map(machine, start, name);
 	if (map == NULL)
 		return -1;
 	map->end = start + size;
@@ -1559,8 +1555,8 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 				strlen(machine->mmap_name) - 1) == 0;
 	if (event->mmap.filename[0] == '/' ||
 	    (!is_kernel_mmap && event->mmap.filename[0] == '[')) {
-		map = machine__findnew_module_map(machine, event->mmap.start,
-						  event->mmap.filename);
+		map = machine__addnew_module_map(machine, event->mmap.start,
+						 event->mmap.filename);
 		if (map == NULL)
 			goto out_problem;
 

commit f068435d9bb2d825d59e3c101bc579f09315ee01
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Nov 14 10:46:45 2019 -0300

    perf map: No need to adjust the long name of modules
    
    At some point in the past we needed to make sure we would get the long
    name of modules and not just what we get from /proc/modules, but that
    need, as described in the cset that introduced the adjustment function:
    
    Fixes: c03d5184f0e9 ("perf machine: Adjust dso->long_name for offline module")
    
    Without using the buildid-cache:
    
      # lsmod | grep trusted
      # insmod trusted.ko
      # lsmod | grep trusted
      trusted                24576  0
      # strace -e open,openat perf probe -m ./trusted.ko key_seal |& grep trusted
      openat(AT_FDCWD, "/sys/module/trusted/notes/.note.gnu.build-id", O_RDONLY) = 4
      openat(AT_FDCWD, "/sys/module/trusted/notes/.note.gnu.build-id", O_RDONLY) = 7
      openat(AT_FDCWD, "/root/trusted.ko", O_RDONLY) = 3
      openat(AT_FDCWD, "/root/.debug/root/trusted.ko/dd3d355d567394d540f527e093e0f64b95879584/probes", O_RDWR|O_CREAT, 0644) = 3
      openat(AT_FDCWD, "/usr/lib/debug/root/trusted.ko.debug", O_RDONLY) = -1 ENOENT (No such file or directory)
      openat(AT_FDCWD, "/usr/lib/debug/root/trusted.ko", O_RDONLY) = -1 ENOENT (No such file or directory)
      openat(AT_FDCWD, "/root/.debug/trusted.ko", O_RDONLY) = -1 ENOENT (No such file or directory)
      openat(AT_FDCWD, "/root/trusted.ko", O_RDONLY) = 3
      openat(AT_FDCWD, "trusted.ko.debug", O_RDONLY) = -1 ENOENT (No such file or directory)
      openat(AT_FDCWD, ".debug/trusted.ko.debug", O_RDONLY) = -1 ENOENT (No such file or directory)
      openat(AT_FDCWD, "trusted.ko.debug", O_RDONLY) = -1 ENOENT (No such file or directory)
      openat(AT_FDCWD, "/root/trusted.ko", O_RDONLY) = 3
      openat(AT_FDCWD, "/root/trusted.ko", O_RDONLY) = 3
      openat(AT_FDCWD, "/root/trusted.ko", O_RDONLY) = 4
      openat(AT_FDCWD, "/root/trusted.ko", O_RDONLY) = 3
        probe:key_seal       (on key_seal in trusted)
      # perf probe -l
        probe:key_seal       (on key_seal in trusted)
      #
    
    No attempt at opening '[trusted]'.
    
    Now using the build-id cache:
    
      # rmmod trusted
      # perf buildid-cache --add ./trusted.ko
      # insmod trusted.ko
      # strace -e open,openat perf probe -m ./trusted.ko key_seal |& grep trusted
      openat(AT_FDCWD, "/sys/module/trusted/notes/.note.gnu.build-id", O_RDONLY) = 4
      openat(AT_FDCWD, "/sys/module/trusted/notes/.note.gnu.build-id", O_RDONLY) = 7
      openat(AT_FDCWD, "/root/trusted.ko", O_RDONLY) = 3
      openat(AT_FDCWD, "/root/.debug/root/trusted.ko/dd3d355d567394d540f527e093e0f64b95879584/probes", O_RDWR|O_CREAT, 0644) = 3
      openat(AT_FDCWD, "/usr/lib/debug/root/trusted.ko.debug", O_RDONLY) = -1 ENOENT (No such file or directory)
      openat(AT_FDCWD, "/usr/lib/debug/root/trusted.ko", O_RDONLY) = -1 ENOENT (No such file or directory)
      openat(AT_FDCWD, "/root/.debug/trusted.ko", O_RDONLY) = -1 ENOENT (No such file or directory)
      openat(AT_FDCWD, "/root/trusted.ko", O_RDONLY) = 3
      openat(AT_FDCWD, "trusted.ko.debug", O_RDONLY) = -1 ENOENT (No such file or directory)
      openat(AT_FDCWD, ".debug/trusted.ko.debug", O_RDONLY) = -1 ENOENT (No such file or directory)
      openat(AT_FDCWD, "trusted.ko.debug", O_RDONLY) = -1 ENOENT (No such file or directory)
      openat(AT_FDCWD, "/root/trusted.ko", O_RDONLY) = 3
      openat(AT_FDCWD, "/root/trusted.ko", O_RDONLY) = 3
      openat(AT_FDCWD, "/root/trusted.ko", O_RDONLY) = 4
      openat(AT_FDCWD, "/root/trusted.ko", O_RDONLY) = 3
      #
    
    Again, no attempt at reading '[trusted]'.
    
    Finally, adding a probe to that function and then using:
    
    [root@quaco ~]# perf trace -e probe_perf:*/max-stack=16/ --max-events=2
         0.000 perf/13456 probe_perf:dso__adjust_kmod_long_name(__probe_ip: 5492263)
                                           dso__adjust_kmod_long_name (/home/acme/bin/perf)
                                           machine__process_kernel_mmap_event (/home/acme/bin/perf)
                                           machine__process_mmap_event (/home/acme/bin/perf)
                                           perf_event__process_mmap (/home/acme/bin/perf)
                                           machines__deliver_event (/home/acme/bin/perf)
                                           perf_session__deliver_event (/home/acme/bin/perf)
                                           perf_session__process_event (/home/acme/bin/perf)
                                           process_simple (/home/acme/bin/perf)
                                           reader__process_events (/home/acme/bin/perf)
                                           __perf_session__process_events (/home/acme/bin/perf)
                                           perf_session__process_events (/home/acme/bin/perf)
                                           process_buildids (/home/acme/bin/perf)
                                           record__finish_output (/home/acme/bin/perf)
                                           __cmd_record (/home/acme/bin/perf)
                                           cmd_record (/home/acme/bin/perf)
                                           run_builtin (/home/acme/bin/perf)
         0.055 perf/13456 probe_perf:dso__adjust_kmod_long_name(__probe_ip: 5492263)
                                           dso__adjust_kmod_long_name (/home/acme/bin/perf)
                                           machine__process_kernel_mmap_event (/home/acme/bin/perf)
                                           machine__process_mmap_event (/home/acme/bin/perf)
                                           perf_event__process_mmap (/home/acme/bin/perf)
                                           machines__deliver_event (/home/acme/bin/perf)
                                           perf_session__deliver_event (/home/acme/bin/perf)
                                           perf_session__process_event (/home/acme/bin/perf)
                                           process_simple (/home/acme/bin/perf)
                                           reader__process_events (/home/acme/bin/perf)
                                           __perf_session__process_events (/home/acme/bin/perf)
                                           perf_session__process_events (/home/acme/bin/perf)
                                           process_buildids (/home/acme/bin/perf)
                                           record__finish_output (/home/acme/bin/perf)
                                           __cmd_record (/home/acme/bin/perf)
                                           cmd_record (/home/acme/bin/perf)
                                           run_builtin (/home/acme/bin/perf)
      #
    
    This was the only path I could find using the perf tools that reach at this
    function, then as of november/2019, if we put a probe in the line where the
    actuall setting of the dso->long_name is done:
    
      # perf trace -e probe_perf:*
      ^C[root@quaco ~]
      # perf stat -e probe_perf:*  -I 2000
           2.000404265                  0      probe_perf:dso__adjust_kmod_long_name
           4.001142200                  0      probe_perf:dso__adjust_kmod_long_name
           6.001704120                  0      probe_perf:dso__adjust_kmod_long_name
           8.002398316                  0      probe_perf:dso__adjust_kmod_long_name
          10.002984010                  0      probe_perf:dso__adjust_kmod_long_name
          12.003597851                  0      probe_perf:dso__adjust_kmod_long_name
          14.004113303                  0      probe_perf:dso__adjust_kmod_long_name
          16.004582773                  0      probe_perf:dso__adjust_kmod_long_name
          18.005176373                  0      probe_perf:dso__adjust_kmod_long_name
          20.005801605                  0      probe_perf:dso__adjust_kmod_long_name
          22.006467540                  0      probe_perf:dso__adjust_kmod_long_name
      ^C    23.683261941                  0      probe_perf:dso__adjust_kmod_long_name
    
      #
    
    Its not being used at all.
    
    To further test this I used kvm.ko as the offline module, i.e. removed
    if from the buildid-cache by nuking it completely (rm -rf ~/.debug) and
    moved it from the normal kernel distro path, removed the modules, stoped
    the kvm guest, and then installed it manually, etc.
    
      # rmmod kvm-intel
      # rmmod kvm
      # lsmod | grep kvm
      # modprobe kvm-intel
      modprobe: ERROR: ctx=0x55d3b1722260 path=/lib/modules/5.3.8-200.fc30.x86_64/kernel/arch/x86/kvm/kvm.ko.xz error=No such file or directory
      modprobe: ERROR: ctx=0x55d3b1722260 path=/lib/modules/5.3.8-200.fc30.x86_64/kernel/arch/x86/kvm/kvm.ko.xz error=No such file or directory
      modprobe: ERROR: could not insert 'kvm_intel': Unknown symbol in module, or unknown parameter (see dmesg)
      # insmod ./kvm.ko
      # modprobe kvm-intel
      modprobe: ERROR: ctx=0x562f34026260 path=/lib/modules/5.3.8-200.fc30.x86_64/kernel/arch/x86/kvm/kvm.ko.xz error=No such file or directory
      modprobe: ERROR: ctx=0x562f34026260 path=/lib/modules/5.3.8-200.fc30.x86_64/kernel/arch/x86/kvm/kvm.ko.xz error=No such file or directory
      # lsmod | grep kvm
      kvm_intel             299008  0
      kvm                   765952  1 kvm_intel
      irqbypass              16384  1 kvm
      #
      # perf probe -x ~/bin/perf machine__findnew_module_map:12 mname=m.name:string filename=filename:string 'dso_long_name=map->dso->long_name:string' 'dso_name=map->dso->name:string'
      # perf probe -l
        probe_perf:machine__findnew_module_map (on machine__findnew_module_map:12@util/machine.c in /home/acme/bin/perf with mname filename dso_long_name dso_name)
      # perf record
      ^C[ perf record: Woken up 2 times to write data ]
      [ perf record: Captured and wrote 3.416 MB perf.data (33956 samples) ]
      # perf trace -e probe_perf:machine*
      <SNIP>
           6.322 perf/23099 probe_perf:machine__findnew_module_map(__probe_ip: 5492493, mname: "[salsa20_generic]", filename: "/lib/modules/5.3.8-200.fc30.x86_64/kernel/crypto/salsa20_generic.ko.xz", dso_long_name: "/lib/modules/5.3.8-200.fc30.x86_64/kernel/crypto/salsa20_generic.ko.xz", dso_name: "[salsa20_generic]")
           6.375 perf/23099 probe_perf:machine__findnew_module_map(__probe_ip: 5492493, mname: "[kvm]", filename: "[kvm]", dso_long_name: "[kvm]", dso_name: "[kvm]")
      <SNIP>
    
    The filename doesn't come with the path, no point in trying to set the dso->long_name.
    
      [root@quaco ~]# strace -e open,openat perf probe -m ./kvm.ko kvm_apic_local_deliver |& egrep 'open.*kvm'
      openat(AT_FDCWD, "/sys/module/kvm_intel/notes/.note.gnu.build-id", O_RDONLY) = 4
      openat(AT_FDCWD, "/sys/module/kvm/notes/.note.gnu.build-id", O_RDONLY) = 4
      openat(AT_FDCWD, "/lib/modules/5.3.8-200.fc30.x86_64/kernel/arch/x86/kvm", O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 7
      openat(AT_FDCWD, "/sys/module/kvm_intel/notes/.note.gnu.build-id", O_RDONLY) = 8
      openat(AT_FDCWD, "/root/kvm.ko", O_RDONLY) = 3
      openat(AT_FDCWD, "/root/.debug/root/kvm.ko/5955f426cb93f03f30f3e876814be2db80ab0b55/probes", O_RDWR|O_CREAT, 0644) = 3
      openat(AT_FDCWD, "/usr/lib/debug/root/kvm.ko.debug", O_RDONLY) = -1 ENOENT (No such file or directory)
      openat(AT_FDCWD, "/usr/lib/debug/root/kvm.ko", O_RDONLY) = -1 ENOENT (No such file or directory)
      openat(AT_FDCWD, "/root/.debug/kvm.ko", O_RDONLY) = -1 ENOENT (No such file or directory)
      openat(AT_FDCWD, "/root/kvm.ko", O_RDONLY) = 3
      openat(AT_FDCWD, "kvm.ko.debug", O_RDONLY) = -1 ENOENT (No such file or directory)
      openat(AT_FDCWD, ".debug/kvm.ko.debug", O_RDONLY) = -1 ENOENT (No such file or directory)
      openat(AT_FDCWD, "kvm.ko.debug", O_RDONLY) = -1 ENOENT (No such file or directory)
      openat(AT_FDCWD, "/root/kvm.ko", O_RDONLY) = 3
      openat(AT_FDCWD, "/root/kvm.ko", O_RDONLY) = 3
      openat(AT_FDCWD, "/root/kvm.ko", O_RDONLY) = 4
      openat(AT_FDCWD, "/root/kvm.ko", O_RDONLY) = 3
      [root@quaco ~]#
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: https://lkml.kernel.org/n/tip-jlfew3lyb24d58egrp0o72o2@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 6a0f5c25ce3e..6804c8247782 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -772,24 +772,6 @@ int machine__process_ksymbol(struct machine *machine __maybe_unused,
 	return machine__process_ksymbol_register(machine, event, sample);
 }
 
-static void dso__adjust_kmod_long_name(struct dso *dso, const char *filename)
-{
-	const char *dup_filename;
-
-	if (!filename || !dso || !dso->long_name)
-		return;
-	if (dso->long_name[0] != '[')
-		return;
-	if (!strchr(filename, '/'))
-		return;
-
-	dup_filename = strdup(filename);
-	if (!dup_filename)
-		return;
-
-	dso__set_long_name(dso, dup_filename, true);
-}
-
 struct map *machine__findnew_module_map(struct machine *machine, u64 start,
 					const char *filename)
 {
@@ -801,15 +783,8 @@ struct map *machine__findnew_module_map(struct machine *machine, u64 start,
 		return NULL;
 
 	map = map_groups__find_by_name(&machine->kmaps, m.name);
-	if (map) {
-		/*
-		 * If the map's dso is an offline module, give dso__load()
-		 * a chance to find the file path of that module by fixing
-		 * long_name.
-		 */
-		dso__adjust_kmod_long_name(map->dso, filename);
+	if (map)
 		goto out;
-	}
 
 	dso = machine__findnew_module_dso(machine, &m, filename);
 	if (dso == NULL)

commit 08f6680e627edf913c6d6adb9bb9ecc9d57a408d
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Nov 4 16:02:35 2019 -0300

    perf tools: Add a 'struct map_groups' pointer to 'struct map_symbol'
    
    And fill it whenever we setup a a 'struct map_symbol', now we need to
    use it, next cset.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-fzwfcnddenz1o7uj1fzw3g46@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 614094d87f05..6a0f5c25ce3e 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1968,6 +1968,7 @@ static void ip__resolve_ams(struct thread *thread,
 
 	ams->addr = ip;
 	ams->al_addr = al.addr;
+	ams->ms.mg  = al.mg;
 	ams->ms.sym = al.sym;
 	ams->ms.map = al.map;
 	ams->phys_addr = 0;
@@ -1985,6 +1986,7 @@ static void ip__resolve_data(struct thread *thread,
 
 	ams->addr = addr;
 	ams->al_addr = al.addr;
+	ams->ms.mg  = al.mg;
 	ams->ms.sym = al.sym;
 	ams->ms.map = al.map;
 	ams->phys_addr = phys_addr;
@@ -2101,6 +2103,7 @@ static int add_callchain_ip(struct thread *thread,
 		iter_cycles = iter->cycles;
 	}
 
+	ms.mg  = al.mg;
 	ms.map = al.map;
 	ms.sym = al.sym;
 	srcline = callchain_srcline(&ms, al.addr);

commit d46a4cdf49937b0b3abeb2cd7fa5dc65795e7ea7
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Nov 4 15:57:38 2019 -0300

    pref tools: Make 'struct addr_map_symbol' contain 'struct map_symbol'
    
    So that we pass that substructure around and with it consolidate lots of
    functions that receive a (map, symbol) pair and now can receive just a
    'struct map_symbol' pointer.
    
    This further paves the way to add 'struct map_groups' to 'struct
    map_symbol' so that we can have all we need for annotation so that we
    can ditch 'struct map'->groups, i.e. have the map_groups pointer in a
    more central place, avoiding the pointer in the 'struct map' that have
    tons of instances.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-fs90ttd9q12l7989fo7pw81q@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index d08c7285c708..614094d87f05 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1968,8 +1968,8 @@ static void ip__resolve_ams(struct thread *thread,
 
 	ams->addr = ip;
 	ams->al_addr = al.addr;
-	ams->sym = al.sym;
-	ams->map = al.map;
+	ams->ms.sym = al.sym;
+	ams->ms.map = al.map;
 	ams->phys_addr = 0;
 }
 
@@ -1985,8 +1985,8 @@ static void ip__resolve_data(struct thread *thread,
 
 	ams->addr = addr;
 	ams->al_addr = al.addr;
-	ams->sym = al.sym;
-	ams->map = al.map;
+	ams->ms.sym = al.sym;
+	ams->ms.map = al.map;
 	ams->phys_addr = phys_addr;
 }
 

commit 5f0fef8ac3e7a5707751493293ba8ff2ffc0f8a4
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Nov 4 12:14:32 2019 -0300

    perf callchain: Use 'struct map_symbol' in 'struct callchain_cursor_node'
    
    To ease passing around map+symbol, just like done for other parts of the
    tree recently.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 3874bb89ac79..d08c7285c708 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2006,8 +2006,9 @@ struct mem_info *sample__resolve_mem(struct perf_sample *sample,
 	return mi;
 }
 
-static char *callchain_srcline(struct map *map, struct symbol *sym, u64 ip)
+static char *callchain_srcline(struct map_symbol *ms, u64 ip)
 {
+	struct map *map = ms->map;
 	char *srcline = NULL;
 
 	if (!map || callchain_param.key == CCKEY_FUNCTION)
@@ -2019,7 +2020,7 @@ static char *callchain_srcline(struct map *map, struct symbol *sym, u64 ip)
 		bool show_addr = callchain_param.key == CCKEY_ADDRESS;
 
 		srcline = get_srcline(map->dso, map__rip_2objdump(map, ip),
-				      sym, show_sym, show_addr, ip);
+				      ms->sym, show_sym, show_addr, ip);
 		srcline__tree_insert(&map->dso->srclines, ip, srcline);
 	}
 
@@ -2042,6 +2043,7 @@ static int add_callchain_ip(struct thread *thread,
 			    struct iterations *iter,
 			    u64 branch_from)
 {
+	struct map_symbol ms;
 	struct addr_location al;
 	int nr_loop_iter = 0;
 	u64 iter_cycles = 0;
@@ -2099,8 +2101,10 @@ static int add_callchain_ip(struct thread *thread,
 		iter_cycles = iter->cycles;
 	}
 
-	srcline = callchain_srcline(al.map, al.sym, al.addr);
-	return callchain_cursor_append(cursor, ip, al.map, al.sym,
+	ms.map = al.map;
+	ms.sym = al.sym;
+	srcline = callchain_srcline(&ms, al.addr);
+	return callchain_cursor_append(cursor, ip, &ms,
 				       branch, flags, nr_loop_iter,
 				       iter_cycles, branch_from, srcline);
 }
@@ -2472,8 +2476,11 @@ static int append_inlines(struct callchain_cursor *cursor, struct map_symbol *ms
 	}
 
 	list_for_each_entry(ilist, &inline_node->val, list) {
-		ret = callchain_cursor_append(cursor, ip, map,
-					      ilist->symbol, false,
+		struct map_symbol ilist_ms = {
+			.map = map,
+			.sym = ilist->symbol,
+		};
+		ret = callchain_cursor_append(cursor, ip, &ilist_ms, false,
 					      NULL, 0, 0, 0, ilist->srcline);
 
 		if (ret != 0)
@@ -2502,9 +2509,8 @@ static int unwind_entry(struct unwind_entry *entry, void *arg)
 	if (entry->ms.map)
 		addr = map__map_ip(entry->ms.map, entry->ip);
 
-	srcline = callchain_srcline(entry->ms.map, entry->ms.sym, addr);
-	return callchain_cursor_append(cursor, entry->ip,
-				       entry->ms.map, entry->ms.sym,
+	srcline = callchain_srcline(&entry->ms, addr);
+	return callchain_cursor_append(cursor, entry->ip, &entry->ms,
 				       false, NULL, 0, 0, 0, srcline);
 }
 

commit c1529738f5eb5fe7c472e0374ad7954d52566df9
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Nov 4 11:58:21 2019 -0300

    perf unwind: Use 'struct map_symbol' in 'struct unwind_entry'
    
    To help in passing that info around to callchain routines that, for the
    same reason, are moving to use 'struct map_symbol'.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-epsiibeprpxa8qpwji47uskc@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index e768ef24633f..3874bb89ac79 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2448,9 +2448,10 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	return 0;
 }
 
-static int append_inlines(struct callchain_cursor *cursor,
-			  struct map *map, struct symbol *sym, u64 ip)
+static int append_inlines(struct callchain_cursor *cursor, struct map_symbol *ms, u64 ip)
 {
+	struct symbol *sym = ms->sym;
+	struct map *map = ms->map;
 	struct inline_node *inline_node;
 	struct inline_list *ilist;
 	u64 addr;
@@ -2488,22 +2489,22 @@ static int unwind_entry(struct unwind_entry *entry, void *arg)
 	const char *srcline = NULL;
 	u64 addr = entry->ip;
 
-	if (symbol_conf.hide_unresolved && entry->sym == NULL)
+	if (symbol_conf.hide_unresolved && entry->ms.sym == NULL)
 		return 0;
 
-	if (append_inlines(cursor, entry->map, entry->sym, entry->ip) == 0)
+	if (append_inlines(cursor, &entry->ms, entry->ip) == 0)
 		return 0;
 
 	/*
 	 * Convert entry->ip from a virtual address to an offset in
 	 * its corresponding binary.
 	 */
-	if (entry->map)
-		addr = map__map_ip(entry->map, entry->ip);
+	if (entry->ms.map)
+		addr = map__map_ip(entry->ms.map, entry->ip);
 
-	srcline = callchain_srcline(entry->map, entry->sym, addr);
+	srcline = callchain_srcline(entry->ms.map, entry->ms.sym, addr);
 	return callchain_cursor_append(cursor, entry->ip,
-				       entry->map, entry->sym,
+				       entry->ms.map, entry->ms.sym,
 				       false, NULL, 0, 0, 0, srcline);
 }
 

commit 93730f85eb37d9cf592c18dad7e488abed09b461
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Oct 31 15:22:24 2019 -0300

    perf machine: Add kernel_dso() method
    
    To reduce boilerplate in some places.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-9s1bgoxxhlnu037e1nqx0tw3@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 24d9e284daad..e768ef24633f 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -42,6 +42,11 @@
 
 static void __machine__remove_thread(struct machine *machine, struct thread *th, bool lock);
 
+static struct dso *machine__kernel_dso(struct machine *machine)
+{
+	return machine->vmlinux_map->dso;
+}
+
 static void dsos__init(struct dsos *dsos)
 {
 	INIT_LIST_HEAD(&dsos->head);
@@ -861,7 +866,7 @@ size_t machine__fprintf_vmlinux_path(struct machine *machine, FILE *fp)
 {
 	int i;
 	size_t printed = 0;
-	struct dso *kdso = machine__kernel_map(machine)->dso;
+	struct dso *kdso = machine__kernel_dso(machine);
 
 	if (kdso->has_build_id) {
 		char filename[PATH_MAX];
@@ -1543,8 +1548,7 @@ static bool perf_event__is_extra_kernel_mmap(struct machine *machine,
 static int machine__process_extra_kernel_map(struct machine *machine,
 					     union perf_event *event)
 {
-	struct map *kernel_map = machine__kernel_map(machine);
-	struct dso *kernel = kernel_map ? kernel_map->dso : NULL;
+	struct dso *kernel = machine__kernel_dso(machine);
 	struct extra_kernel_map xm = {
 		.start = event->mmap.start,
 		.end   = event->mmap.start + event->mmap.len,

commit 8efc4f05685dae2da1d21973eba5e59e7863c77f
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Oct 28 11:31:38 2019 -0300

    perf maps: Add for_each_entry()/_safe() iterators
    
    To reduce boilerplate, provide a more compact form using an idiom
    present in other trees of data structures.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-59gmq4kg1r68ou1wknyjl78x@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 70a9f8716a4b..24d9e284daad 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1057,7 +1057,7 @@ int machine__map_x86_64_entry_trampolines(struct machine *machine,
 	 * In the vmlinux case, pgoff is a virtual address which must now be
 	 * mapped to a vmlinux offset.
 	 */
-	for (map = maps__first(maps); map; map = map__next(map)) {
+	maps__for_each_entry(maps, map) {
 		struct kmap *kmap = __map__kmap(map);
 		struct map *dest_map;
 

commit 20f2be1d48ec293b5a935595bd0c2e2915ffa77c
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Tue Aug 6 15:25:25 2019 +0200

    libperf: Move 'page_size' global variable to libperf
    
    We need the 'page_size' variable in libperf, so move it there.
    
    Add a libperf_init() as a global libperf init function to obtain this
    value via sysconf() at tool start.
    
    Committer notes:
    
    Add internal/lib.h to tools/perf/ files using 'page_size', sometimes
    replacing util.h with it if that was the only reason for having util.h
    included.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Michael Petlan <mpetlan@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lore.kernel.org/lkml/20190913132355.21634-33-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 0535338f2d7a..70a9f8716a4b 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -32,6 +32,7 @@
 #include "linux/hash.h"
 #include "asm/bug.h"
 #include "bpf-event.h"
+#include <internal/lib.h> // page_size
 
 #include <linux/ctype.h>
 #include <symbol/kallsyms.h>

commit 055c67ed39887c5563e9540470a4617c1b772aec
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Sep 18 16:08:52 2019 -0300

    perf tools: Move event synthesizing routines to separate .c file
    
    For better grouping, in time we may end up making most of these static,
    i.e. generalizing the 'perf record' synthesizing code so that based on
    the target it can do the right thing and call the needed synthesizers.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-s9zxxhk40s95pjng9panet16@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 132de5cfb9b9..0535338f2d7a 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -20,7 +20,6 @@
 #include "symbol.h"
 #include "sort.h"
 #include "strlist.h"
-#include "util/synthetic-events.h"
 #include "target.h"
 #include "thread.h"
 #include "util.h"
@@ -2610,30 +2609,6 @@ int machines__for_each_thread(struct machines *machines,
 	return rc;
 }
 
-int __machine__synthesize_threads(struct machine *machine, struct perf_tool *tool,
-				  struct target *target, struct perf_thread_map *threads,
-				  perf_event__handler_t process, bool data_mmap,
-				  unsigned int nr_threads_synthesize)
-{
-	if (target__has_task(target))
-		return perf_event__synthesize_thread_map(tool, threads, process, machine, data_mmap);
-	else if (target__has_cpu(target))
-		return perf_event__synthesize_threads(tool, process,
-						      machine, data_mmap,
-						      nr_threads_synthesize);
-	/* command specified */
-	return 0;
-}
-
-int machine__synthesize_threads(struct machine *machine, struct target *target,
-				struct perf_thread_map *threads, bool data_mmap,
-				unsigned int nr_threads_synthesize)
-{
-	return __machine__synthesize_threads(machine, NULL, target, threads,
-					     perf_event__process, data_mmap,
-					     nr_threads_synthesize);
-}
-
 pid_t machine__get_current_tid(struct machine *machine, int cpu)
 {
 	int nr_cpus = min(machine->env->nr_cpus_online, MAX_NR_CPUS);

commit ea49e01cfabd73c94a61649cd04fa524a2beff3c
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Sep 18 11:36:13 2019 -0300

    perf tools: Move event synthesizing routines to separate header
    
    Those are the only routines using the perf_event__handler_t typedef and
    are all related, so move to a separate header to reduce the header
    dependency tree, lots of places were getting event.h and even stdio.h,
    limits.h indirectly, so fix those as well.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-yvx9u1mf7baq6cu1abfhbqgs@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index b4749d3eed08..132de5cfb9b9 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -20,6 +20,7 @@
 #include "symbol.h"
 #include "sort.h"
 #include "strlist.h"
+#include "util/synthetic-events.h"
 #include "target.h"
 #include "thread.h"
 #include "util.h"
@@ -2624,6 +2625,15 @@ int __machine__synthesize_threads(struct machine *machine, struct perf_tool *too
 	return 0;
 }
 
+int machine__synthesize_threads(struct machine *machine, struct target *target,
+				struct perf_thread_map *threads, bool data_mmap,
+				unsigned int nr_threads_synthesize)
+{
+	return __machine__synthesize_threads(machine, NULL, target, threads,
+					     perf_event__process, data_mmap,
+					     nr_threads_synthesize);
+}
+
 pid_t machine__get_current_tid(struct machine *machine, int cpu)
 {
 	int nr_cpus = min(machine->env->nr_cpus_online, MAX_NR_CPUS);

commit d3300a3c4e76ccecf4daa889327e340a870c550b
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri Aug 30 15:09:54 2019 -0300

    perf symbols: Move mem_info and branch_info out of symbol.h
    
    The mem_info struct goes to mem-events.h and branch_info goes to
    branch.h, where they belong, this way we can remove several headers from
    symbols.h and trim the include dependency tree more.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-aupw71xnravcsu2xoabfmhpc@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 6a77aefbe319..b4749d3eed08 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -13,6 +13,9 @@
 #include "hist.h"
 #include "machine.h"
 #include "map.h"
+#include "map_symbol.h"
+#include "branch.h"
+#include "mem-events.h"
 #include "srcline.h"
 #include "symbol.h"
 #include "sort.h"

commit f2a39fe84901df2b3d1bec3459b65cee3e8db57c
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri Aug 30 14:45:20 2019 -0300

    perf auxtrace: Uninline functions that touch perf_session
    
    So that we don't carry the session.h include directive in auxtrace.h,
    which in turn opens a can of worms of files that were getting all sorts
    of things via that include, fix them all.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-d2d83aovpgri2z75wlitquni@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 003025465198..6a77aefbe319 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -3,9 +3,11 @@
 #include <errno.h>
 #include <inttypes.h>
 #include <regex.h>
+#include <stdlib.h>
 #include "callchain.h"
 #include "debug.h"
 #include "dso.h"
+#include "env.h"
 #include "event.h"
 #include "evsel.h"
 #include "hist.h"

commit 4a3cec84949d14dc3ef7fb8a51b8949af93cac13
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri Aug 30 11:11:01 2019 -0300

    perf dsos: Move the dsos struct and its methods to separate source files
    
    So that we can reduce the header dependency tree further, in the process
    noticed that lots of places were getting even things like build-id
    routines and 'struct perf_tool' definition indirectly, so fix all those
    too.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-ti0btma9ow5ndrytyoqdk62j@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 6e9afe4e55dd..003025465198 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -5,6 +5,7 @@
 #include <regex.h>
 #include "callchain.h"
 #include "debug.h"
+#include "dso.h"
 #include "event.h"
 #include "evsel.h"
 #include "hist.h"

commit 8520a98dbab61e9e340cdfb72dd17ccc8a98961e
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Aug 29 16:18:59 2019 -0300

    perf debug: Remove needless include directives from debug.h
    
    All we need there is a forward declaration for 'union perf_event', so
    remove it from there and add missing header directives in places using
    things from this indirect include.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-7ftk0ztstqub1tirjj8o8xbl@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index a1542b4c047b..6e9afe4e55dd 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -30,6 +30,7 @@
 #include <linux/ctype.h>
 #include <symbol/kallsyms.h>
 #include <linux/mman.h>
+#include <linux/string.h>
 #include <linux/zalloc.h>
 
 static void __machine__remove_thread(struct machine *machine, struct thread *th, bool lock);

commit 8c7274691f0de5fb56f3b9fe9208ce7e515a2d2c
Author: Kyle Meyer <meyerk@hpe.com>
Date:   Tue Aug 27 16:43:50 2019 -0500

    perf machine: Replace MAX_NR_CPUS with perf_env::nr_cpus_online
    
    nr_cpus, the number of CPUs online during a record session bound by
    MAX_NR_CPUS, can be used as a dynamic alternative for MAX_NR_CPUS in
    __machine__synthesize_threads and machine__set_current_tid.
    
    Signed-off-by: Kyle Meyer <kyle.meyer@hpe.com>
    Reviewed-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Russ Anderson <russ.anderson@hpe.com>
    Link: http://lore.kernel.org/lkml/20190827214352.94272-6-meyerk@stormcage.eag.rdlabs.hpecorp.net
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 93483f1764d3..a1542b4c047b 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2619,7 +2619,9 @@ int __machine__synthesize_threads(struct machine *machine, struct perf_tool *too
 
 pid_t machine__get_current_tid(struct machine *machine, int cpu)
 {
-	if (cpu < 0 || cpu >= MAX_NR_CPUS || !machine->current_tid)
+	int nr_cpus = min(machine->env->nr_cpus_online, MAX_NR_CPUS);
+
+	if (cpu < 0 || cpu >= nr_cpus || !machine->current_tid)
 		return -1;
 
 	return machine->current_tid[cpu];
@@ -2629,6 +2631,7 @@ int machine__set_current_tid(struct machine *machine, int cpu, pid_t pid,
 			     pid_t tid)
 {
 	struct thread *thread;
+	int nr_cpus = min(machine->env->nr_cpus_online, MAX_NR_CPUS);
 
 	if (cpu < 0)
 		return -EINVAL;
@@ -2636,14 +2639,14 @@ int machine__set_current_tid(struct machine *machine, int cpu, pid_t pid,
 	if (!machine->current_tid) {
 		int i;
 
-		machine->current_tid = calloc(MAX_NR_CPUS, sizeof(pid_t));
+		machine->current_tid = calloc(nr_cpus, sizeof(pid_t));
 		if (!machine->current_tid)
 			return -ENOMEM;
-		for (i = 0; i < MAX_NR_CPUS; i++)
+		for (i = 0; i < nr_cpus; i++)
 			machine->current_tid[i] = -1;
 	}
 
-	if (cpu >= MAX_NR_CPUS) {
+	if (cpu >= nr_cpus) {
 		pr_err("Requested CPU %d too large. ", cpu);
 		pr_err("Consider raising MAX_NR_CPUS\n");
 		return -EINVAL;

commit 3f604b5f61dbff80725392c99827d6617f7bb180
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Aug 26 19:28:13 2019 -0300

    perf tool: Rename perf_tool::bpf_event to bpf
    
    No need for that _event suffix, do just like all the other meta event
    handlers and suppress that suffix.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Song Liu <songliubraving@fb.com>
    Link: https://lkml.kernel.org/n/tip-03spzxtqafbabbbmnm7y4xfx@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 86b7fd24b1e1..93483f1764d3 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1922,7 +1922,7 @@ int machine__process_event(struct machine *machine, union perf_event *event,
 	case PERF_RECORD_KSYMBOL:
 		ret = machine__process_ksymbol(machine, event, sample); break;
 	case PERF_RECORD_BPF_EVENT:
-		ret = machine__process_bpf_event(machine, event, sample); break;
+		ret = machine__process_bpf(machine, event, sample); break;
 	default:
 		ret = -1;
 		break;

commit ebdba16e95f728e94dba07fe0f1221b0e8efdb9d
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Aug 26 19:15:18 2019 -0300

    perf tools: Rename perf_event::ksymbol_event to perf_event::ksymbol
    
    Just like all the other meta events, that extra _event suffix is just
    redundant, ditch it.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Song Liu <songliubraving@fb.com>
    Link: https://lkml.kernel.org/n/tip-0q8b2xnfs17q0g523oej75s0@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 823aaf7b1b83..86b7fd24b1e1 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -713,20 +713,20 @@ static int machine__process_ksymbol_register(struct machine *machine,
 	struct symbol *sym;
 	struct map *map;
 
-	map = map_groups__find(&machine->kmaps, event->ksymbol_event.addr);
+	map = map_groups__find(&machine->kmaps, event->ksymbol.addr);
 	if (!map) {
-		map = dso__new_map(event->ksymbol_event.name);
+		map = dso__new_map(event->ksymbol.name);
 		if (!map)
 			return -ENOMEM;
 
-		map->start = event->ksymbol_event.addr;
-		map->end = map->start + event->ksymbol_event.len;
+		map->start = event->ksymbol.addr;
+		map->end = map->start + event->ksymbol.len;
 		map_groups__insert(&machine->kmaps, map);
 	}
 
 	sym = symbol__new(map->map_ip(map, map->start),
-			  event->ksymbol_event.len,
-			  0, 0, event->ksymbol_event.name);
+			  event->ksymbol.len,
+			  0, 0, event->ksymbol.name);
 	if (!sym)
 		return -ENOMEM;
 	dso__insert_symbol(map->dso, sym);
@@ -739,7 +739,7 @@ static int machine__process_ksymbol_unregister(struct machine *machine,
 {
 	struct map *map;
 
-	map = map_groups__find(&machine->kmaps, event->ksymbol_event.addr);
+	map = map_groups__find(&machine->kmaps, event->ksymbol.addr);
 	if (map)
 		map_groups__remove(&machine->kmaps, map);
 
@@ -753,7 +753,7 @@ int machine__process_ksymbol(struct machine *machine __maybe_unused,
 	if (dump_trace)
 		perf_event__fprintf_ksymbol(event, stdout);
 
-	if (event->ksymbol_event.flags & PERF_RECORD_KSYMBOL_FLAGS_UNREGISTER)
+	if (event->ksymbol.flags & PERF_RECORD_KSYMBOL_FLAGS_UNREGISTER)
 		return machine__process_ksymbol_unregister(machine, event,
 							   sample);
 	return machine__process_ksymbol_register(machine, event, sample);

commit a2e254d84172f7eb638261a83024d849f78c89e9
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Sun Aug 25 20:17:47 2019 +0200

    libperf: Add PERF_RECORD_LOST_SAMPLES 'struct lost_samples_event' to perf/event.h
    
    Move the PERF_RECORD_LOST_SAMPLES event definition into libperf's
    event.h header include.
    
    In order to keep libperf simple, we switch 'u64/u32/u16/u8' types used
    events to their generic '__u*' versions.
    
    Perf added 'u*' types mainly to ease up printing __u64 values
    as stated in the linux/types.h comment:
    
      /*
       * We define u64 as uint64_t for every architecture
       * so that we can print it with "%"PRIx64 without getting warnings.
       *
       * typedef __u64 u64;
       * typedef __s64 s64;
       */
    
    Add and use new PRI_lu64 and PRI_lx64 macros for that.  Use extra '_' to
    ease up the reading and differentiate them from standard PRI*64 macros.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Michael Petlan <mpetlan@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20190825181752.722-8-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 1ad6e984c2f5..823aaf7b1b83 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -653,7 +653,7 @@ int machine__process_lost_event(struct machine *machine __maybe_unused,
 int machine__process_lost_samples_event(struct machine *machine __maybe_unused,
 					union perf_event *event, struct perf_sample *sample)
 {
-	dump_printf(": id:%" PRIu64 ": lost samples :%" PRIu64 "\n",
+	dump_printf(": id:%" PRIu64 ": lost samples :%" PRI_lu64 "\n",
 		    sample->id, event->lost_samples.lost);
 	return 0;
 }

commit 5290ed6955ebc481d5cd62f7175e8514931058bc
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Sun Aug 25 20:17:46 2019 +0200

    libperf: Add PERF_RECORD_LOST 'struct lost_event' to perf/event.h
    
    Move the lost_event event definition to libperf's event.h header
    include.
    
    In order to keep libperf simple, we switch 'u64/u32/u16/u8' types used
    events to their generic '__u*' versions.
    
    Perf added 'u*' types mainly to ease up printing __u64 values as stated
    in the linux/types.h comment:
    
      /*
       * We define u64 as uint64_t for every architecture
       * so that we can print it with "%"PRIx64 without getting warnings.
       *
       * typedef __u64 u64;
       * typedef __s64 s64;
       */
    
    Add and use new PRI_lu64 and PRI_lx64 macros for that.  Use extra '_' to
    ease up the reading and differentiate them from standard PRI*64 macros.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Michael Petlan <mpetlan@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20190825181752.722-7-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 47430afd3c2d..1ad6e984c2f5 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -645,7 +645,7 @@ int machine__process_namespaces_event(struct machine *machine __maybe_unused,
 int machine__process_lost_event(struct machine *machine __maybe_unused,
 				union perf_event *event, struct perf_sample *sample __maybe_unused)
 {
-	dump_printf(": id:%" PRIu64 ": lost:%" PRIu64 "\n",
+	dump_printf(": id:%" PRI_lu64 ": lost:%" PRI_lu64 "\n",
 		    event->lost.id, event->lost.lost);
 	return 0;
 }

commit 97b9d866a66cf9884cea623cde3300073815873d
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Aug 22 17:10:08 2019 -0300

    perf srcline: Add missing srcline.h header to files needing its defs
    
    When srcline was introduced it wrongly added the include to util/sort.h,
    even with that header not needing the definitions it provides, fix it by
    adding it to the places that need it as a pre patch to remove srcline.h
    from sort.h.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-shuebppedtye8hrgxk15qe3x@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index f7c1a7e6c4ba..47430afd3c2d 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -10,11 +10,13 @@
 #include "hist.h"
 #include "machine.h"
 #include "map.h"
+#include "srcline.h"
 #include "symbol.h"
 #include "sort.h"
 #include "strlist.h"
 #include "target.h"
 #include "thread.h"
+#include "util.h"
 #include "vdso.h"
 #include <stdbool.h>
 #include <sys/types.h>

commit aeb00b1aeab6dadd72c24f93bea51a46e109c2ba
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Aug 22 15:40:29 2019 -0300

    perf record: Move record_opts and other record decls out of perf.h
    
    And into a separate util/record.h, to better isolate things and make
    sure that those who use record_opts and the other moved declarations
    are explicitly including the necessary header.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-31q8mei1qkh74qvkl9nwidfq@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 5734460fc89e..f7c1a7e6c4ba 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -13,6 +13,7 @@
 #include "symbol.h"
 #include "sort.h"
 #include "strlist.h"
+#include "target.h"
 #include "thread.h"
 #include "vdso.h"
 #include <stdbool.h>

commit 272172bd418cc32aa466588150c8001bc229c712
Merge: 7f06d0aa530c d45331b00ddb
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Aug 12 16:25:00 2019 -0300

    Merge remote-tracking branch 'torvalds/master' into perf/core
    
    To get closer to upstream and check if we need to sync more UAPI
    headers, pick up fixes for libbpf that prevent perf's container tests
    from completing successfuly, etc.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

commit 12a6d2940b5f02b4b9f71ce098e3bb02bc24a9ea
Author: Thomas Richter <tmricht@linux.ibm.com>
Date:   Wed Jul 24 14:27:02 2019 +0200

    perf record: Fix module size on s390
    
    On s390 the modules loaded in memory have the text segment located after
    the GOT and Relocation table. This can be seen with this output:
    
      [root@m35lp76 perf]# fgrep qeth /proc/modules
      qeth 151552 1 qeth_l2, Live 0x000003ff800b2000
      ...
      [root@m35lp76 perf]# cat /sys/module/qeth/sections/.text
      0x000003ff800b3990
      [root@m35lp76 perf]#
    
    There is an offset of 0x1990 bytes. The size of the qeth module is
    151552 bytes (0x25000 in hex).
    
    The location of the GOT/relocation table at the beginning of a module is
    unique to s390.
    
    commit 203d8a4aa6ed ("perf s390: Fix 'start' address of module's map")
    adjusts the start address of a module in the map structures, but does
    not adjust the size of the modules. This leads to overlapping of module
    maps as this example shows:
    
    [root@m35lp76 perf] # ./perf report -D
         0 0 0xfb0 [0xa0]: PERF_RECORD_MMAP -1/0: [0x3ff800b3990(0x25000)
              @ 0]:  x /lib/modules/.../qeth.ko.xz
         0 0 0x1050 [0xb0]: PERF_RECORD_MMAP -1/0: [0x3ff800d85a0(0x8000)
              @ 0]:  x /lib/modules/.../ip6_tables.ko.xz
    
    The module qeth.ko has an adjusted start address modified to b3990, but
    its size is unchanged and the module ends at 0x3ff800d8990.  This end
    address overlaps with the next modules start address of 0x3ff800d85a0.
    
    When the size of the leading GOT/Relocation table stored in the
    beginning of the text segment (0x1990 bytes) is subtracted from module
    qeth end address, there are no overlaps anymore:
    
       0x3ff800d8990 - 0x1990 = 0x0x3ff800d7000
    
    which is the same as
    
       0x3ff800b2000 + 0x25000 = 0x0x3ff800d7000.
    
    To fix this issue, also adjust the modules size in function
    arch__fix_module_text_start(). Add another function parameter named size
    and reduce the size of the module when the text segment start address is
    changed.
    
    Output after:
         0 0 0xfb0 [0xa0]: PERF_RECORD_MMAP -1/0: [0x3ff800b3990(0x23670)
              @ 0]:  x /lib/modules/.../qeth.ko.xz
         0 0 0x1050 [0xb0]: PERF_RECORD_MMAP -1/0: [0x3ff800d85a0(0x7a60)
              @ 0]:  x /lib/modules/.../ip6_tables.ko.xz
    
    Reported-by: Stefan Liebler <stli@linux.ibm.com>
    Signed-off-by: Thomas Richter <tmricht@linux.ibm.com>
    Acked-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Hendrik Brueckner <brueckner@linux.ibm.com>
    Cc: Vasily Gorbik <gor@linux.ibm.com>
    Cc: stable@vger.kernel.org
    Fixes: 203d8a4aa6ed ("perf s390: Fix 'start' address of module's map")
    Link: http://lkml.kernel.org/r/20190724122703.3996-1-tmricht@linux.ibm.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index cf826eca3aaf..83b2fbbeeb90 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1378,6 +1378,7 @@ static int machine__set_modules_path(struct machine *machine)
 	return map_groups__set_modules_path_dir(&machine->kmaps, modules_path, 0);
 }
 int __weak arch__fix_module_text_start(u64 *start __maybe_unused,
+				u64 *size __maybe_unused,
 				const char *name __maybe_unused)
 {
 	return 0;
@@ -1389,7 +1390,7 @@ static int machine__create_module(void *arg, const char *name, u64 start,
 	struct machine *machine = arg;
 	struct map *map;
 
-	if (arch__fix_module_text_start(&start, name) < 0)
+	if (arch__fix_module_text_start(&start, &size, name) < 0)
 		return -1;
 
 	map = machine__findnew_module_map(machine, start, name);

commit 1fc632cef4ea137bc45fd0fc4cb902e374064163
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Sun Jul 21 13:24:29 2019 +0200

    libperf: Move perf_event_attr field from perf's evsel to libperf's perf_evsel
    
    Move the perf_event_attr struct fron 'struct evsel' to 'struct perf_evsel'.
    
    Committer notes:
    
    Fixed up these:
    
     tools/perf/arch/arm/util/auxtrace.c
     tools/perf/arch/arm/util/cs-etm.c
     tools/perf/arch/arm64/util/arm-spe.c
     tools/perf/arch/s390/util/auxtrace.c
     tools/perf/util/cs-etm.c
    
    Also
    
      cc1: warnings being treated as errors
      tests/sample-parsing.c: In function 'do_test':
      tests/sample-parsing.c:162: error: missing initializer
      tests/sample-parsing.c:162: error: (near initialization for 'evsel.core.cpus')
    
            struct evsel evsel = {
                    .needs_swap = false,
      -             .core.attr = {
      -                     .sample_type = sample_type,
      -                     .read_format = read_format,
      +             .core = {
      +                     . attr = {
      +                             .sample_type = sample_type,
      +                             .read_format = read_format,
      +                     },
    
      [perfbuilder@a70e4eeb5549 /]$ gcc --version |& head -1
      gcc (GCC) 4.4.7
    
    Also we don't need to include perf_event.h in
    tools/perf/lib/include/perf/evsel.h, forward declaring 'struct
    perf_event_attr' is enough. And this even fixes the build in some
    systems where things are used somewhere down the include path from
    perf_event.h without defining __always_inline.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Alexey Budankov <alexey.budankov@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Michael Petlan <mpetlan@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20190721112506.12306-43-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index ec0675b0caa8..f6ee7fbad3e4 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2498,8 +2498,8 @@ static int thread__resolve_callchain_unwind(struct thread *thread,
 					    int max_stack)
 {
 	/* Can we do dwarf post unwind? */
-	if (!((evsel->attr.sample_type & PERF_SAMPLE_REGS_USER) &&
-	      (evsel->attr.sample_type & PERF_SAMPLE_STACK_USER)))
+	if (!((evsel->core.attr.sample_type & PERF_SAMPLE_REGS_USER) &&
+	      (evsel->core.attr.sample_type & PERF_SAMPLE_STACK_USER)))
 		return 0;
 
 	/* Bail out if nothing was captured. */

commit 32dcd021d004038ca12ac17319da5aa4756e9312
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Sun Jul 21 13:23:51 2019 +0200

    perf evsel: Rename struct perf_evsel to struct evsel
    
    Rename struct perf_evsel to struct evsel, so we don't have a name clash
    when we add struct perf_evsel in libperf.
    
    Committer notes:
    
    Added fixes for arm64, provided by Jiri.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Alexey Budankov <alexey.budankov@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Michael Petlan <mpetlan@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20190721112506.12306-5-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index a2359a33c748..ec0675b0caa8 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2287,7 +2287,7 @@ static int find_prev_cpumode(struct ip_callchain *chain, struct thread *thread,
 
 static int thread__resolve_callchain_sample(struct thread *thread,
 					    struct callchain_cursor *cursor,
-					    struct perf_evsel *evsel,
+					    struct evsel *evsel,
 					    struct perf_sample *sample,
 					    struct symbol **parent,
 					    struct addr_location *root_al,
@@ -2493,7 +2493,7 @@ static int unwind_entry(struct unwind_entry *entry, void *arg)
 
 static int thread__resolve_callchain_unwind(struct thread *thread,
 					    struct callchain_cursor *cursor,
-					    struct perf_evsel *evsel,
+					    struct evsel *evsel,
 					    struct perf_sample *sample,
 					    int max_stack)
 {
@@ -2513,7 +2513,7 @@ static int thread__resolve_callchain_unwind(struct thread *thread,
 
 int thread__resolve_callchain(struct thread *thread,
 			      struct callchain_cursor *cursor,
-			      struct perf_evsel *evsel,
+			      struct evsel *evsel,
 			      struct perf_sample *sample,
 			      struct symbol **parent,
 			      struct addr_location *root_al,

commit 9749b90e566ca1a235fc8e2118f99c5690969342
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Sun Jul 21 13:23:50 2019 +0200

    perf tools: Rename struct thread_map to struct perf_thread_map
    
    Rename struct thread_map to struct perf_thread_map, so it could be part
    of libperf.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Alexey Budankov <alexey.budankov@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Michael Petlan <mpetlan@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20190721112506.12306-4-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index cf826eca3aaf..a2359a33c748 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2599,7 +2599,7 @@ int machines__for_each_thread(struct machines *machines,
 }
 
 int __machine__synthesize_threads(struct machine *machine, struct perf_tool *tool,
-				  struct target *target, struct thread_map *threads,
+				  struct target *target, struct perf_thread_map *threads,
 				  perf_event__handler_t process, bool data_mmap,
 				  unsigned int nr_threads_synthesize)
 {

commit d8f9da240495b50766239410f9b0c715ca506a67
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Jul 4 12:06:20 2019 -0300

    perf tools: Use zfree() where applicable
    
    In places where the equivalent was already being done, i.e.:
    
       free(a);
       a = NULL;
    
    And in placs where struct members are being freed so that if we have
    some erroneous reference to its struct, then accesses to freed members
    will result in segfaults, which we can detect faster than use after free
    to areas that may still have something seemingly valid.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-jatyoofo5boc1bsvoig6bb6i@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index f523da3009e4..cf826eca3aaf 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -810,7 +810,7 @@ struct map *machine__findnew_module_map(struct machine *machine, u64 start,
 out:
 	/* put the dso here, corresponding to  machine__findnew_module_dso */
 	dso__put(dso);
-	free(m.name);
+	zfree(&m.name);
 	return map;
 }
 
@@ -1350,7 +1350,7 @@ static int map_groups__set_modules_path_dir(struct map_groups *mg,
 			if (m.kmod)
 				ret = map_groups__set_module_path(mg, path, &m);
 
-			free(m.name);
+			zfree(&m.name);
 
 			if (ret)
 				goto out;

commit 7f7c536f23e6afaa5d5d4b0e0958b0be8922491f
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Jul 4 11:32:27 2019 -0300

    tools lib: Adopt zalloc()/zfree() from tools/perf
    
    Eroding a bit more the tools/perf/util/util.h hodpodge header.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-natazosyn9rwjka25tvcnyi0@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 147ed85ea2bc..f523da3009e4 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -15,7 +15,6 @@
 #include "strlist.h"
 #include "thread.h"
 #include "vdso.h"
-#include "util.h"
 #include <stdbool.h>
 #include <sys/types.h>
 #include <sys/stat.h>
@@ -28,6 +27,7 @@
 #include <linux/ctype.h>
 #include <symbol/kallsyms.h>
 #include <linux/mman.h>
+#include <linux/zalloc.h>
 
 static void __machine__remove_thread(struct machine *machine, struct thread *th, bool lock);
 

commit e3b22a65348ab54261a98b6bc90ecf8977ff8ebf
Merge: 05c78468a60f 552a031ba12a
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Jul 8 13:06:57 2019 -0300

    Merge remote-tracking branch 'tip/perf/core' into perf/urgent
    
    To pick up fixes.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

commit 4c00af0e94cd01b8c5a5e6b3323d34677b04e192
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri Jul 5 12:11:35 2019 -0300

    perf thread: Allow references to thread objects after machine__exit()
    
    Threads are created when we either synthesize PERF_RECORD_FORK events
    for pre-existing threads or when we receive PERF_RECORD_FORK events from
    the kernel as new threads get created.
    
    We then keep them in machine->threads[].entries rb trees till when we
    receive a PERF_RECORD_EXIT, i.e. that thread terminated.
    
    The thread object has a reference count that is grabbed when, for
    instance, we keep that thread referenced in struct hist_entry, in 'perf
    report' and 'perf top'.
    
    When we receive a PERF_RECORD_EXIT we remove the thread object from the
    rb tree and move it to the corresponding machine->threads[].dead list,
    then we do a thread__put(), dropping the reference we had for keeping it
    in the rb tree.
    
    In thread__put() we were assuming that when the reference count hit zero
    we should remove it from the dead list by simply doing a
    list_del_init(&thread->node).
    
    That works well when all the thread lifetime is during the machine that
    has the list heads lifetime, since we know that we can do the
    list_del_init() and it will update the 'dead' list_head.
    
    But in 'perf sched lat' we were doing:
    
        machine__new() (via perf_session__new)
    
        process events, grabbing refcounts to keep those thread objects
        in 'perf sched' local data structures.
    
        machine__exit() (via perf_session__delete) which would delete the
        'dead' list heads.
    
        And then doing the final thread__put() for the refcounts 'perf sched'
        rightfully obtained for keeping those thread object references.
    
        b00m, since thread__put() would do the list_del_init() touching
        a dead dead list head.
    
    Fix it by removing all the dead threads from machine->threads[].dead at
    machine__exit(), since whatever is there should have refcounts taken by
    things like 'perf sched lat', and make thread__put() check if the thread
    is in a linked list before removing it from that list.
    
    Reported-by: Wei Li <liwei391@huawei.com>
    Link: https://lkml.kernel.org/r/20190508143648.8153-1-liwei391@huawei.com
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Zhipeng Xie <xiezhipeng1@huawei.com>
    Link: https://lkml.kernel.org/r/20190704194355.GI10740@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index dc7aafe45a2b..e00dc413652d 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -209,6 +209,18 @@ void machine__exit(struct machine *machine)
 
 	for (i = 0; i < THREADS__TABLE_SIZE; i++) {
 		struct threads *threads = &machine->threads[i];
+		struct thread *thread, *n;
+		/*
+		 * Forget about the dead, at this point whatever threads were
+		 * left in the dead lists better have a reference count taken
+		 * by who is using them, and then, when they drop those references
+		 * and it finally hits zero, thread__put() will check and see that
+		 * its not in the dead threads list and will not try to remove it
+		 * from there, just calling thread__delete() straight away.
+		 */
+		list_for_each_entry_safe(thread, n, &threads->dead, node)
+			list_del_init(&thread->node);
+
 		exit_rwsem(&threads->lock);
 	}
 }
@@ -1758,9 +1770,11 @@ static void __machine__remove_thread(struct machine *machine, struct thread *th,
 	if (threads->last_match == th)
 		threads__set_last_match(threads, NULL);
 
-	BUG_ON(refcount_read(&th->refcnt) == 0);
 	if (lock)
 		down_write(&threads->lock);
+
+	BUG_ON(refcount_read(&th->refcnt) == 0);
+
 	rb_erase_cached(&th->rb_node, &threads->entries);
 	RB_CLEAR_NODE(&th->rb_node);
 	--threads->nr;
@@ -1770,9 +1784,16 @@ static void __machine__remove_thread(struct machine *machine, struct thread *th,
 	 * will be called and we will remove it from the dead_threads list.
 	 */
 	list_add_tail(&th->node, &threads->dead);
+
+	/*
+	 * We need to do the put here because if this is the last refcount,
+	 * then we will be touching the threads->dead head when removing the
+	 * thread.
+	 */
+	thread__put(th);
+
 	if (lock)
 		up_write(&threads->lock);
-	thread__put(th);
 }
 
 void machine__remove_thread(struct machine *machine, struct thread *th)

commit 3052ba56bcb589046eca6a931bd897742653d2cb
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Jun 25 17:27:31 2019 -0300

    tools perf: Move from sane_ctype.h obtained from git to the Linux's original
    
    We got the sane_ctype.h headers from git and kept using it so far, but
    since that code originally came from the kernel sources to the git
    sources, perhaps its better to just use the one in the kernel, so that
    we can leverage tools/perf/check_headers.sh to be notified when our copy
    gets out of sync, i.e. when fixes or goodies are added to the code we've
    copied.
    
    This will help with things like tools/lib/string.c where we want to have
    more things in common with the kernel, such as strim(), skip_spaces(),
    etc so as to go on removing the things that we have in tools/perf/util/
    and instead using the code in the kernel, indirectly and removing things
    like EXPORT_SYMBOL(), etc, getting notified when fixes and improvements
    are made to the original code.
    
    Hopefully this also should help with reducing the difference of code
    hosted in tools/ to the one in the kernel proper.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-7k9868l713wqtgo01xxygn12@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index a0bb05dd008f..1b3d7265bca9 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -25,7 +25,7 @@
 #include "asm/bug.h"
 #include "bpf-event.h"
 
-#include "sane_ctype.h"
+#include <linux/ctype.h>
 #include <symbol/kallsyms.h>
 #include <linux/mman.h>
 

commit 1b2fc358ddfb1b0915922e441182cda7043f5116
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Jun 25 18:35:34 2019 -0300

    perf tools: Add missing util.h to pick up 'page_size' variable
    
    Not to depend of getting it indirectly.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-tirjsmvu4ektw0k7lm8k9lhu@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 17eec39e775e..a0bb05dd008f 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -15,6 +15,7 @@
 #include "strlist.h"
 #include "thread.h"
 #include "vdso.h"
+#include "util.h"
 #include <stdbool.h>
 #include <sys/types.h>
 #include <sys/stat.h>

commit 34b65affe18daad31fed83e50d1f3b817786a2b7
Author: Donald Yandt <donald.yandt@gmail.com>
Date:   Tue May 28 09:41:28 2019 -0400

    perf machine: Return NULL instead of null-terminating /proc/version array
    
    Return NULL instead of null-terminating version char array when fgets
    fails due to end-of-file or error.
    
    Signed-off-by: Donald Yandt <donald.yandt@gmail.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Yanmin Zhang <yanmin_zhang@linux.intel.com>
    Fixes: 30ba5b0e66c8 ("perf machine: Null-terminate version char array upon fgets(/proc/version) error")
    Link: http://lkml.kernel.org/r/20190528134128.30841-1-donald.yandt@gmail.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index f5569f005cf3..17eec39e775e 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1241,9 +1241,9 @@ static char *get_kernel_version(const char *root_dir)
 		return NULL;
 
 	tmp = fgets(version, sizeof(version), file);
-	if (!tmp)
-		*version = '\0';
 	fclose(file);
+	if (!tmp)
+		return NULL;
 
 	name = strstr(version, prefix);
 	if (!name)

commit 8529f2e67313fb623da7ce81bc14cf12ccc0e12f
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Wed May 8 15:20:04 2019 +0200

    perf machine: Keep zero in pgoff BPF map
    
    With pgoff set to zero, the map__map_ip function will return BPF
    addresses based from 0, which is what we need when we read the data from
    a BPF DSO.
    
    Adding BPF symbols with mapped IP addresses as well.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Acked-by: Song Liu <songliubraving@fb.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stanislav Fomichev <sdf@google.com>
    Link: http://lkml.kernel.org/r/20190508132010.14512-7-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index dc7aafe45a2b..f5569f005cf3 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -704,12 +704,12 @@ static int machine__process_ksymbol_register(struct machine *machine,
 			return -ENOMEM;
 
 		map->start = event->ksymbol_event.addr;
-		map->pgoff = map->start;
 		map->end = map->start + event->ksymbol_event.len;
 		map_groups__insert(&machine->kmaps, map);
 	}
 
-	sym = symbol__new(event->ksymbol_event.addr, event->ksymbol_event.len,
+	sym = symbol__new(map->map_ip(map, map->start),
+			  event->ksymbol_event.len,
 			  0, 0, event->ksymbol_event.name);
 	if (!sym)
 		return -ENOMEM;

commit ed9adb2035b5be5896d465b19040262be5f4a824
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Wed May 8 15:20:03 2019 +0200

    perf machine: Read also the end of the kernel
    
    We mark the end of kernel based on the first module, but that could
    cover some bpf program maps. Reading _etext symbol if it's present to
    get precise kernel map end.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Acked-by: Song Liu <songliubraving@fb.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stanislav Fomichev <sdf@google.com>
    Cc: Thomas Richter <tmricht@linux.ibm.com>
    Link: http://lkml.kernel.org/r/20190508132010.14512-6-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 28a9541c4835..dc7aafe45a2b 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -924,7 +924,8 @@ const char *ref_reloc_sym_names[] = {"_text", "_stext", NULL};
  * symbol_name if it's not that important.
  */
 static int machine__get_running_kernel_start(struct machine *machine,
-					     const char **symbol_name, u64 *start)
+					     const char **symbol_name,
+					     u64 *start, u64 *end)
 {
 	char filename[PATH_MAX];
 	int i, err = -1;
@@ -949,6 +950,11 @@ static int machine__get_running_kernel_start(struct machine *machine,
 		*symbol_name = name;
 
 	*start = addr;
+
+	err = kallsyms__get_function_start(filename, "_etext", &addr);
+	if (!err)
+		*end = addr;
+
 	return 0;
 }
 
@@ -1441,7 +1447,7 @@ int machine__create_kernel_maps(struct machine *machine)
 	struct dso *kernel = machine__get_kernel(machine);
 	const char *name = NULL;
 	struct map *map;
-	u64 addr = 0;
+	u64 start = 0, end = ~0ULL;
 	int ret;
 
 	if (kernel == NULL)
@@ -1460,9 +1466,9 @@ int machine__create_kernel_maps(struct machine *machine)
 				 "continuing anyway...\n", machine->pid);
 	}
 
-	if (!machine__get_running_kernel_start(machine, &name, &addr)) {
+	if (!machine__get_running_kernel_start(machine, &name, &start, &end)) {
 		if (name &&
-		    map__set_kallsyms_ref_reloc_sym(machine->vmlinux_map, name, addr)) {
+		    map__set_kallsyms_ref_reloc_sym(machine->vmlinux_map, name, start)) {
 			machine__destroy_kernel_maps(machine);
 			ret = -1;
 			goto out_put;
@@ -1472,16 +1478,19 @@ int machine__create_kernel_maps(struct machine *machine)
 		 * we have a real start address now, so re-order the kmaps
 		 * assume it's the last in the kmaps
 		 */
-		machine__update_kernel_mmap(machine, addr, ~0ULL);
+		machine__update_kernel_mmap(machine, start, end);
 	}
 
 	if (machine__create_extra_kernel_maps(machine, kernel))
 		pr_debug("Problems creating extra kernel maps, continuing anyway...\n");
 
-	/* update end address of the kernel map using adjacent module address */
-	map = map__next(machine__kernel_map(machine));
-	if (map)
-		machine__set_kernel_mmap(machine, addr, map->start);
+	if (end == ~0ULL) {
+		/* update end address of the kernel map using adjacent module address */
+		map = map__next(machine__kernel_map(machine));
+		if (map)
+			machine__set_kernel_mmap(machine, start, map->start);
+	}
+
 out_put:
 	dso__put(kernel);
 	return ret;

commit 30ba5b0e66c872faa416a458d32cc3956ecb548a
Author: Donald Yandt <donald.yandt@gmail.com>
Date:   Tue May 14 07:01:00 2019 -0400

    perf machine: Null-terminate version char array upon fgets(/proc/version) error
    
    If fgets() fails due to any other error besides end-of-file, the version
    char array may not even be null-terminated.
    
    Signed-off-by: Donald Yandt <donald.yandt@gmail.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Avi Kivity <avi@scylladb.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Yanmin Zhang <yanmin_zhang@linux.intel.com>
    Fixes: a1645ce12adb ("perf: 'perf kvm' tool for monitoring guest performance from host")
    Link: http://lkml.kernel.org/r/20190514110100.22019-1-donald.yandt@gmail.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 3c520baa198c..28a9541c4835 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1234,8 +1234,9 @@ static char *get_kernel_version(const char *root_dir)
 	if (!file)
 		return NULL;
 
-	version[0] = '\0';
 	tmp = fgets(version, sizeof(version), file);
+	if (!tmp)
+		*version = '\0';
 	fclose(file);
 
 	name = strstr(version, prefix);

commit 977c7a6d1e263ff1d755f28595b99e4bc0c48a9f
Author: Wei Li <liwei391@huawei.com>
Date:   Thu Feb 28 17:20:03 2019 +0800

    perf machine: Update kernel map address and re-order properly
    
    Since commit 1fb87b8e9599 ("perf machine: Don't search for active kernel
    start in __machine__create_kernel_maps"), the __machine__create_kernel_maps()
    just create a map what start and end are both zero. Though the address will be
    updated later, the order of map in the rbtree may be incorrect.
    
    The commit ee05d21791db ("perf machine: Set main kernel end address properly")
    fixed the logic in machine__create_kernel_maps(), but it's still wrong in
    function machine__process_kernel_mmap_event().
    
    To reproduce this issue, we need an environment which the module address
    is before the kernel text segment. I tested it on an aarch64 machine with
    kernel 4.19.25:
    
      [root@localhost hulk]# grep _stext /proc/kallsyms
      ffff000008081000 T _stext
      [root@localhost hulk]# grep _etext /proc/kallsyms
      ffff000009780000 R _etext
      [root@localhost hulk]# tail /proc/modules
      hisi_sas_v2_hw 77824 0 - Live 0xffff00000191d000
      nvme_core 126976 7 nvme, Live 0xffff0000018b6000
      mdio 20480 1 ixgbe, Live 0xffff0000018ab000
      hisi_sas_main 106496 1 hisi_sas_v2_hw, Live 0xffff000001861000
      hns_mdio 20480 2 - Live 0xffff000001822000
      hnae 28672 3 hns_dsaf,hns_enet_drv, Live 0xffff000001815000
      dm_mirror 40960 0 - Live 0xffff000001804000
      dm_region_hash 32768 1 dm_mirror, Live 0xffff0000017f5000
      dm_log 32768 2 dm_mirror,dm_region_hash, Live 0xffff0000017e7000
      dm_mod 315392 17 dm_mirror,dm_log, Live 0xffff000001780000
      [root@localhost hulk]#
    
    Before fix:
    
      [root@localhost bin]# perf record sleep 3
      [ perf record: Woken up 1 times to write data ]
      [ perf record: Captured and wrote 0.011 MB perf.data (9 samples) ]
      [root@localhost bin]# perf buildid-list -i perf.data
      4c4e46c971ca935f781e603a09b52a92e8bdfee8 [vdso]
      [root@localhost bin]# perf buildid-list -i perf.data -H
      0000000000000000000000000000000000000000 /proc/kcore
      [root@localhost bin]#
    
    After fix:
    
      [root@localhost tools]# ./perf/perf record sleep 3
      [ perf record: Woken up 1 times to write data ]
      [ perf record: Captured and wrote 0.011 MB perf.data (9 samples) ]
      [root@localhost tools]# ./perf/perf buildid-list -i perf.data
      28a6c690262896dbd1b5e1011ed81623e6db0610 [kernel.kallsyms]
      106c14ce6e4acea3453e484dc604d66666f08a2f [vdso]
      [root@localhost tools]# ./perf/perf buildid-list -i perf.data -H
      28a6c690262896dbd1b5e1011ed81623e6db0610 /proc/kcore
    
    Signed-off-by: Wei Li <liwei391@huawei.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Acked-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Hanjun Guo <guohanjun@huawei.com>
    Cc: Kim Phillips <kim.phillips@arm.com>
    Cc: Li Bin <huawei.libin@huawei.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20190228092003.34071-1-liwei391@huawei.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 61959aba7e27..3c520baa198c 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1421,6 +1421,20 @@ static void machine__set_kernel_mmap(struct machine *machine,
 		machine->vmlinux_map->end = ~0ULL;
 }
 
+static void machine__update_kernel_mmap(struct machine *machine,
+				     u64 start, u64 end)
+{
+	struct map *map = machine__kernel_map(machine);
+
+	map__get(map);
+	map_groups__remove(&machine->kmaps, map);
+
+	machine__set_kernel_mmap(machine, start, end);
+
+	map_groups__insert(&machine->kmaps, map);
+	map__put(map);
+}
+
 int machine__create_kernel_maps(struct machine *machine)
 {
 	struct dso *kernel = machine__get_kernel(machine);
@@ -1453,17 +1467,11 @@ int machine__create_kernel_maps(struct machine *machine)
 			goto out_put;
 		}
 
-		/* we have a real start address now, so re-order the kmaps */
-		map = machine__kernel_map(machine);
-
-		map__get(map);
-		map_groups__remove(&machine->kmaps, map);
-
-		/* assume it's the last in the kmaps */
-		machine__set_kernel_mmap(machine, addr, ~0ULL);
-
-		map_groups__insert(&machine->kmaps, map);
-		map__put(map);
+		/*
+		 * we have a real start address now, so re-order the kmaps
+		 * assume it's the last in the kmaps
+		 */
+		machine__update_kernel_mmap(machine, addr, ~0ULL);
 	}
 
 	if (machine__create_extra_kernel_maps(machine, kernel))
@@ -1599,7 +1607,7 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 		if (strstr(kernel->long_name, "vmlinux"))
 			dso__set_short_name(kernel, "[kernel.vmlinux]", false);
 
-		machine__set_kernel_mmap(machine, event->mmap.start,
+		machine__update_kernel_mmap(machine, event->mmap.start,
 					 event->mmap.start + event->mmap.len);
 
 		/*

commit daecf9e0fa8e1bb3b227fcc15c4070caccbbb14f
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Jan 28 00:03:34 2019 +0100

    perf tools: Add missing include for symbols.h
    
    Several places were using definitions found in symbols.h but not
    including it, getting it by sheer luck from some other headers that now
    are in the process of removing that include because they don't need it
    or because simply having struct forward declarations is enough, fix it.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-xbcvvx296d70kpg9wb0qmeq9@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 66f019fdc510..61959aba7e27 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -10,6 +10,7 @@
 #include "hist.h"
 #include "machine.h"
 #include "map.h"
+#include "symbol.h"
 #include "sort.h"
 #include "strlist.h"
 #include "thread.h"

commit f3acb3a8a2081344801974ac5ec8e1b0d6f0ef36
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Thu Dec 6 11:18:14 2018 -0800

    perf machine: Use cached rbtrees
    
    At the cost of an extra pointer, we can avoid the O(logN) cost of
    finding the first element in the tree (smallest node), which is
    something required for nearly every operation dealing with
    machine->guests and threads->entries.
    
    The conversion is straightforward, however, it's worth noticing that the
    rb_erase_init() calls have been replaced by rb_erase_cached() which has
    no _init() flavor, however, the node is explicitly cleared next anyway,
    which was redundant until now.
    
    Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: http://lkml.kernel.org/r/20181206191819.30182-3-dave@stgolabs.net
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index ae85106bb5bf..66f019fdc510 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -42,7 +42,7 @@ static void machine__threads_init(struct machine *machine)
 
 	for (i = 0; i < THREADS__TABLE_SIZE; i++) {
 		struct threads *threads = &machine->threads[i];
-		threads->entries = RB_ROOT;
+		threads->entries = RB_ROOT_CACHED;
 		init_rwsem(&threads->lock);
 		threads->nr = 0;
 		INIT_LIST_HEAD(&threads->dead);
@@ -180,7 +180,7 @@ void machine__delete_threads(struct machine *machine)
 	for (i = 0; i < THREADS__TABLE_SIZE; i++) {
 		struct threads *threads = &machine->threads[i];
 		down_write(&threads->lock);
-		nd = rb_first(&threads->entries);
+		nd = rb_first_cached(&threads->entries);
 		while (nd) {
 			struct thread *t = rb_entry(nd, struct thread, rb_node);
 
@@ -223,7 +223,7 @@ void machine__delete(struct machine *machine)
 void machines__init(struct machines *machines)
 {
 	machine__init(&machines->host, "", HOST_KERNEL_ID);
-	machines->guests = RB_ROOT;
+	machines->guests = RB_ROOT_CACHED;
 }
 
 void machines__exit(struct machines *machines)
@@ -235,9 +235,10 @@ void machines__exit(struct machines *machines)
 struct machine *machines__add(struct machines *machines, pid_t pid,
 			      const char *root_dir)
 {
-	struct rb_node **p = &machines->guests.rb_node;
+	struct rb_node **p = &machines->guests.rb_root.rb_node;
 	struct rb_node *parent = NULL;
 	struct machine *pos, *machine = malloc(sizeof(*machine));
+	bool leftmost = true;
 
 	if (machine == NULL)
 		return NULL;
@@ -252,12 +253,14 @@ struct machine *machines__add(struct machines *machines, pid_t pid,
 		pos = rb_entry(parent, struct machine, rb_node);
 		if (pid < pos->pid)
 			p = &(*p)->rb_left;
-		else
+		else {
 			p = &(*p)->rb_right;
+			leftmost = false;
+		}
 	}
 
 	rb_link_node(&machine->rb_node, parent, p);
-	rb_insert_color(&machine->rb_node, &machines->guests);
+	rb_insert_color_cached(&machine->rb_node, &machines->guests, leftmost);
 
 	return machine;
 }
@@ -268,7 +271,7 @@ void machines__set_comm_exec(struct machines *machines, bool comm_exec)
 
 	machines->host.comm_exec = comm_exec;
 
-	for (nd = rb_first(&machines->guests); nd; nd = rb_next(nd)) {
+	for (nd = rb_first_cached(&machines->guests); nd; nd = rb_next(nd)) {
 		struct machine *machine = rb_entry(nd, struct machine, rb_node);
 
 		machine->comm_exec = comm_exec;
@@ -277,7 +280,7 @@ void machines__set_comm_exec(struct machines *machines, bool comm_exec)
 
 struct machine *machines__find(struct machines *machines, pid_t pid)
 {
-	struct rb_node **p = &machines->guests.rb_node;
+	struct rb_node **p = &machines->guests.rb_root.rb_node;
 	struct rb_node *parent = NULL;
 	struct machine *machine;
 	struct machine *default_machine = NULL;
@@ -340,7 +343,7 @@ void machines__process_guests(struct machines *machines,
 {
 	struct rb_node *nd;
 
-	for (nd = rb_first(&machines->guests); nd; nd = rb_next(nd)) {
+	for (nd = rb_first_cached(&machines->guests); nd; nd = rb_next(nd)) {
 		struct machine *pos = rb_entry(nd, struct machine, rb_node);
 		process(pos, data);
 	}
@@ -353,7 +356,8 @@ void machines__set_id_hdr_size(struct machines *machines, u16 id_hdr_size)
 
 	machines->host.id_hdr_size = id_hdr_size;
 
-	for (node = rb_first(&machines->guests); node; node = rb_next(node)) {
+	for (node = rb_first_cached(&machines->guests); node;
+	     node = rb_next(node)) {
 		machine = rb_entry(node, struct machine, rb_node);
 		machine->id_hdr_size = id_hdr_size;
 	}
@@ -466,9 +470,10 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 						  pid_t pid, pid_t tid,
 						  bool create)
 {
-	struct rb_node **p = &threads->entries.rb_node;
+	struct rb_node **p = &threads->entries.rb_root.rb_node;
 	struct rb_node *parent = NULL;
 	struct thread *th;
+	bool leftmost = true;
 
 	th = threads__get_last_match(threads, machine, pid, tid);
 	if (th)
@@ -486,8 +491,10 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 
 		if (tid < th->tid)
 			p = &(*p)->rb_left;
-		else
+		else {
 			p = &(*p)->rb_right;
+			leftmost = false;
+		}
 	}
 
 	if (!create)
@@ -496,7 +503,7 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 	th = thread__new(pid, tid);
 	if (th != NULL) {
 		rb_link_node(&th->rb_node, parent, p);
-		rb_insert_color(&th->rb_node, &threads->entries);
+		rb_insert_color_cached(&th->rb_node, &threads->entries, leftmost);
 
 		/*
 		 * We have to initialize map_groups separately
@@ -507,7 +514,7 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 		 * leader and that would screwed the rb tree.
 		 */
 		if (thread__init_map_groups(th, machine)) {
-			rb_erase_init(&th->rb_node, &threads->entries);
+			rb_erase_cached(&th->rb_node, &threads->entries);
 			RB_CLEAR_NODE(&th->rb_node);
 			thread__put(th);
 			return NULL;
@@ -798,7 +805,7 @@ size_t machines__fprintf_dsos(struct machines *machines, FILE *fp)
 	struct rb_node *nd;
 	size_t ret = __dsos__fprintf(&machines->host.dsos.head, fp);
 
-	for (nd = rb_first(&machines->guests); nd; nd = rb_next(nd)) {
+	for (nd = rb_first_cached(&machines->guests); nd; nd = rb_next(nd)) {
 		struct machine *pos = rb_entry(nd, struct machine, rb_node);
 		ret += __dsos__fprintf(&pos->dsos.head, fp);
 	}
@@ -818,7 +825,7 @@ size_t machines__fprintf_dsos_buildid(struct machines *machines, FILE *fp,
 	struct rb_node *nd;
 	size_t ret = machine__fprintf_dsos_buildid(&machines->host, fp, skip, parm);
 
-	for (nd = rb_first(&machines->guests); nd; nd = rb_next(nd)) {
+	for (nd = rb_first_cached(&machines->guests); nd; nd = rb_next(nd)) {
 		struct machine *pos = rb_entry(nd, struct machine, rb_node);
 		ret += machine__fprintf_dsos_buildid(pos, fp, skip, parm);
 	}
@@ -858,7 +865,8 @@ size_t machine__fprintf(struct machine *machine, FILE *fp)
 
 		ret = fprintf(fp, "Threads: %u\n", threads->nr);
 
-		for (nd = rb_first(&threads->entries); nd; nd = rb_next(nd)) {
+		for (nd = rb_first_cached(&threads->entries); nd;
+		     nd = rb_next(nd)) {
 			struct thread *pos = rb_entry(nd, struct thread, rb_node);
 
 			ret += thread__fprintf(pos, fp);
@@ -1161,7 +1169,7 @@ int machines__create_guest_kernel_maps(struct machines *machines)
 
 void machines__destroy_kernel_maps(struct machines *machines)
 {
-	struct rb_node *next = rb_first(&machines->guests);
+	struct rb_node *next = rb_first_cached(&machines->guests);
 
 	machine__destroy_kernel_maps(&machines->host);
 
@@ -1169,7 +1177,7 @@ void machines__destroy_kernel_maps(struct machines *machines)
 		struct machine *pos = rb_entry(next, struct machine, rb_node);
 
 		next = rb_next(&pos->rb_node);
-		rb_erase(&pos->rb_node, &machines->guests);
+		rb_erase_cached(&pos->rb_node, &machines->guests);
 		machine__delete(pos);
 	}
 }
@@ -1734,7 +1742,7 @@ static void __machine__remove_thread(struct machine *machine, struct thread *th,
 	BUG_ON(refcount_read(&th->refcnt) == 0);
 	if (lock)
 		down_write(&threads->lock);
-	rb_erase_init(&th->rb_node, &threads->entries);
+	rb_erase_cached(&th->rb_node, &threads->entries);
 	RB_CLEAR_NODE(&th->rb_node);
 	--threads->nr;
 	/*
@@ -2511,7 +2519,8 @@ int machine__for_each_thread(struct machine *machine,
 
 	for (i = 0; i < THREADS__TABLE_SIZE; i++) {
 		threads = &machine->threads[i];
-		for (nd = rb_first(&threads->entries); nd; nd = rb_next(nd)) {
+		for (nd = rb_first_cached(&threads->entries); nd;
+		     nd = rb_next(nd)) {
 			thread = rb_entry(nd, struct thread, rb_node);
 			rc = fn(thread, priv);
 			if (rc != 0)
@@ -2538,7 +2547,7 @@ int machines__for_each_thread(struct machines *machines,
 	if (rc != 0)
 		return rc;
 
-	for (nd = rb_first(&machines->guests); nd; nd = rb_next(nd)) {
+	for (nd = rb_first_cached(&machines->guests); nd; nd = rb_next(nd)) {
 		struct machine *machine = rb_entry(nd, struct machine, rb_node);
 
 		rc = machine__for_each_thread(machine, fn, priv);

commit 45178a928a4b7c6093f6621e627d09909e81cc13
Author: Song Liu <songliubraving@fb.com>
Date:   Thu Jan 17 08:15:18 2019 -0800

    perf tools: Handle PERF_RECORD_BPF_EVENT
    
    This patch adds basic handling of PERF_RECORD_BPF_EVENT.  Tracking of
    PERF_RECORD_BPF_EVENT is OFF by default. Option --bpf-event is added to
    turn it on.
    
    Committer notes:
    
    Add dummy machine__process_bpf_event() variant that returns zero for
    systems without HAVE_LIBBPF_SUPPORT, such as Alpine Linux, unbreaking
    the build in such systems.
    
    Remove the needless include <machine.h> from bpf->event.h, provide just
    forward declarations for the structs and unions in the parameters, to
    reduce compilation time and needless rebuilds when machine.h gets
    changed.
    
    Committer testing:
    
    When running with:
    
     # perf record --bpf-event
    
    On an older kernel where PERF_RECORD_BPF_EVENT and PERF_RECORD_KSYMBOL
    is not present, we fallback to removing those two bits from
    perf_event_attr, making the tool to continue to work on older kernels:
    
      perf_event_attr:
        size                             112
        { sample_period, sample_freq }   4000
        sample_type                      IP|TID|TIME|PERIOD
        read_format                      ID
        disabled                         1
        inherit                          1
        mmap                             1
        comm                             1
        freq                             1
        enable_on_exec                   1
        task                             1
        precise_ip                       3
        sample_id_all                    1
        exclude_guest                    1
        mmap2                            1
        comm_exec                        1
        ksymbol                          1
        bpf_event                        1
      ------------------------------------------------------------
      sys_perf_event_open: pid 5779  cpu 0  group_fd -1  flags 0x8
      sys_perf_event_open failed, error -22
      switching off bpf_event
      ------------------------------------------------------------
      perf_event_attr:
        size                             112
        { sample_period, sample_freq }   4000
        sample_type                      IP|TID|TIME|PERIOD
        read_format                      ID
        disabled                         1
        inherit                          1
        mmap                             1
        comm                             1
        freq                             1
        enable_on_exec                   1
        task                             1
        precise_ip                       3
        sample_id_all                    1
        exclude_guest                    1
        mmap2                            1
        comm_exec                        1
        ksymbol                          1
      ------------------------------------------------------------
      sys_perf_event_open: pid 5779  cpu 0  group_fd -1  flags 0x8
      sys_perf_event_open failed, error -22
      switching off ksymbol
      ------------------------------------------------------------
      perf_event_attr:
        size                             112
        { sample_period, sample_freq }   4000
        sample_type                      IP|TID|TIME|PERIOD
        read_format                      ID
        disabled                         1
        inherit                          1
        mmap                             1
        comm                             1
        freq                             1
        enable_on_exec                   1
        task                             1
        precise_ip                       3
        sample_id_all                    1
        exclude_guest                    1
        mmap2                            1
        comm_exec                        1
      ------------------------------------------------------------
    
    And then proceeds to work without those two features.
    
    As passing --bpf-event is an explicit action performed by the user, perhaps we
    should emit a warning telling that the kernel has no such feature, but this can
    be done on top of this patch.
    
    Now with a kernel that supports these events, start the 'record --bpf-event -a'
    and then run 'perf trace sleep 10000' that will use the BPF
    augmented_raw_syscalls.o prebuilt (for another kernel version even) and thus
    should generate PERF_RECORD_BPF_EVENT events:
    
      [root@quaco ~]# perf record -e dummy -a --bpf-event
      ^C[ perf record: Woken up 1 times to write data ]
      [ perf record: Captured and wrote 0.713 MB perf.data ]
    
      [root@quaco ~]# bpftool prog
      13: cgroup_skb  tag 7be49e3934a125ba  gpl
            loaded_at 2019-01-19T09:09:43-0300  uid 0
            xlated 296B  jited 229B  memlock 4096B  map_ids 13,14
      14: cgroup_skb  tag 2a142ef67aaad174  gpl
            loaded_at 2019-01-19T09:09:43-0300  uid 0
            xlated 296B  jited 229B  memlock 4096B  map_ids 13,14
      15: cgroup_skb  tag 7be49e3934a125ba  gpl
            loaded_at 2019-01-19T09:09:43-0300  uid 0
            xlated 296B  jited 229B  memlock 4096B  map_ids 15,16
      16: cgroup_skb  tag 2a142ef67aaad174  gpl
            loaded_at 2019-01-19T09:09:43-0300  uid 0
            xlated 296B  jited 229B  memlock 4096B  map_ids 15,16
      17: cgroup_skb  tag 7be49e3934a125ba  gpl
            loaded_at 2019-01-19T09:09:44-0300  uid 0
            xlated 296B  jited 229B  memlock 4096B  map_ids 17,18
      18: cgroup_skb  tag 2a142ef67aaad174  gpl
            loaded_at 2019-01-19T09:09:44-0300  uid 0
            xlated 296B  jited 229B  memlock 4096B  map_ids 17,18
      21: cgroup_skb  tag 7be49e3934a125ba  gpl
            loaded_at 2019-01-19T09:09:45-0300  uid 0
            xlated 296B  jited 229B  memlock 4096B  map_ids 21,22
      22: cgroup_skb  tag 2a142ef67aaad174  gpl
            loaded_at 2019-01-19T09:09:45-0300  uid 0
            xlated 296B  jited 229B  memlock 4096B  map_ids 21,22
      31: tracepoint  name sys_enter  tag 12504ba9402f952f  gpl
            loaded_at 2019-01-19T09:19:56-0300  uid 0
            xlated 512B  jited 374B  memlock 4096B  map_ids 30,29,28
      32: tracepoint  name sys_exit  tag c1bd85c092d6e4aa  gpl
            loaded_at 2019-01-19T09:19:56-0300  uid 0
            xlated 256B  jited 191B  memlock 4096B  map_ids 30,29
      # perf report -D | grep PERF_RECORD_BPF_EVENT | nl
         1  0 55834574849 0x4fc8 [0x18]: PERF_RECORD_BPF_EVENT bpf event with type 1, flags 0, id 13
         2  0 60129542145 0x5118 [0x18]: PERF_RECORD_BPF_EVENT bpf event with type 1, flags 0, id 14
         3  0 64424509441 0x5268 [0x18]: PERF_RECORD_BPF_EVENT bpf event with type 1, flags 0, id 15
         4  0 68719476737 0x53b8 [0x18]: PERF_RECORD_BPF_EVENT bpf event with type 1, flags 0, id 16
         5  0 73014444033 0x5508 [0x18]: PERF_RECORD_BPF_EVENT bpf event with type 1, flags 0, id 17
         6  0 77309411329 0x5658 [0x18]: PERF_RECORD_BPF_EVENT bpf event with type 1, flags 0, id 18
         7  0 90194313217 0x57a8 [0x18]: PERF_RECORD_BPF_EVENT bpf event with type 1, flags 0, id 21
         8  0 94489280513 0x58f8 [0x18]: PERF_RECORD_BPF_EVENT bpf event with type 1, flags 0, id 22
         9  7 620922484360 0xb6390 [0x30]: PERF_RECORD_BPF_EVENT bpf event with type 1, flags 0, id 29
        10  7 620922486018 0xb6410 [0x30]: PERF_RECORD_BPF_EVENT bpf event with type 2, flags 0, id 29
        11  7 620922579199 0xb6490 [0x30]: PERF_RECORD_BPF_EVENT bpf event with type 1, flags 0, id 30
        12  7 620922580240 0xb6510 [0x30]: PERF_RECORD_BPF_EVENT bpf event with type 2, flags 0, id 30
        13  7 620922765207 0xb6598 [0x30]: PERF_RECORD_BPF_EVENT bpf event with type 1, flags 0, id 31
        14  7 620922874543 0xb6620 [0x30]: PERF_RECORD_BPF_EVENT bpf event with type 1, flags 0, id 32
      #
    
    There, the 31 and 32 tracepoint BPF programs put in place by 'perf trace'.
    
    Signed-off-by: Song Liu <songliubraving@fb.com>
    Reviewed-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Alexei Starovoitov <ast@kernel.org>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: kernel-team@fb.com
    Cc: netdev@vger.kernel.org
    Link: http://lkml.kernel.org/r/20190117161521.1341602-7-songliubraving@fb.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 9bca61c7d5bf..ae85106bb5bf 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -21,6 +21,7 @@
 #include "unwind.h"
 #include "linux/hash.h"
 #include "asm/bug.h"
+#include "bpf-event.h"
 
 #include "sane_ctype.h"
 #include <symbol/kallsyms.h>
@@ -1867,6 +1868,8 @@ int machine__process_event(struct machine *machine, union perf_event *event,
 		ret = machine__process_switch_event(machine, event); break;
 	case PERF_RECORD_KSYMBOL:
 		ret = machine__process_ksymbol(machine, event, sample); break;
+	case PERF_RECORD_BPF_EVENT:
+		ret = machine__process_bpf_event(machine, event, sample); break;
 	default:
 		ret = -1;
 		break;

commit 9aa0bfa370b278a539077002b3c660468d66b5e7
Author: Song Liu <songliubraving@fb.com>
Date:   Thu Jan 17 08:15:17 2019 -0800

    perf tools: Handle PERF_RECORD_KSYMBOL
    
    This patch handles PERF_RECORD_KSYMBOL in perf record/report.
    Specifically, map and symbol are created for ksymbol register, and
    removed for ksymbol unregister.
    
    This patch also sets perf_event_attr.ksymbol properly. The flag is ON by
    default.
    
    Committer notes:
    
    Use proper inttypes.h for u64, fixing the build in some environments
    like in the android NDK r15c targetting ARM 32-bit.
    
    I.e. fixing this build error:
    
      util/event.c: In function 'perf_event__fprintf_ksymbol':
      util/event.c:1489:10: error: format '%lx' expects argument of type 'long unsigned int', but argument 3 has type 'u64' [-Werror=format=]
                event->ksymbol_event.flags, event->ksymbol_event.name);
                ^
      cc1: all warnings being treated as errors
    
    Signed-off-by: Song Liu <songliubraving@fb.com>
    Reviewed-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Alexei Starovoitov <ast@kernel.org>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: kernel-team@fb.com
    Cc: netdev@vger.kernel.org
    Link: http://lkml.kernel.org/r/20190117161521.1341602-6-songliubraving@fb.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 143f7057d581..9bca61c7d5bf 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -681,6 +681,59 @@ int machine__process_switch_event(struct machine *machine __maybe_unused,
 	return 0;
 }
 
+static int machine__process_ksymbol_register(struct machine *machine,
+					     union perf_event *event,
+					     struct perf_sample *sample __maybe_unused)
+{
+	struct symbol *sym;
+	struct map *map;
+
+	map = map_groups__find(&machine->kmaps, event->ksymbol_event.addr);
+	if (!map) {
+		map = dso__new_map(event->ksymbol_event.name);
+		if (!map)
+			return -ENOMEM;
+
+		map->start = event->ksymbol_event.addr;
+		map->pgoff = map->start;
+		map->end = map->start + event->ksymbol_event.len;
+		map_groups__insert(&machine->kmaps, map);
+	}
+
+	sym = symbol__new(event->ksymbol_event.addr, event->ksymbol_event.len,
+			  0, 0, event->ksymbol_event.name);
+	if (!sym)
+		return -ENOMEM;
+	dso__insert_symbol(map->dso, sym);
+	return 0;
+}
+
+static int machine__process_ksymbol_unregister(struct machine *machine,
+					       union perf_event *event,
+					       struct perf_sample *sample __maybe_unused)
+{
+	struct map *map;
+
+	map = map_groups__find(&machine->kmaps, event->ksymbol_event.addr);
+	if (map)
+		map_groups__remove(&machine->kmaps, map);
+
+	return 0;
+}
+
+int machine__process_ksymbol(struct machine *machine __maybe_unused,
+			     union perf_event *event,
+			     struct perf_sample *sample)
+{
+	if (dump_trace)
+		perf_event__fprintf_ksymbol(event, stdout);
+
+	if (event->ksymbol_event.flags & PERF_RECORD_KSYMBOL_FLAGS_UNREGISTER)
+		return machine__process_ksymbol_unregister(machine, event,
+							   sample);
+	return machine__process_ksymbol_register(machine, event, sample);
+}
+
 static void dso__adjust_kmod_long_name(struct dso *dso, const char *filename)
 {
 	const char *dup_filename;
@@ -1812,6 +1865,8 @@ int machine__process_event(struct machine *machine, union perf_event *event,
 	case PERF_RECORD_SWITCH:
 	case PERF_RECORD_SWITCH_CPU_WIDE:
 		ret = machine__process_switch_event(machine, event); break;
+	case PERF_RECORD_KSYMBOL:
+		ret = machine__process_ksymbol(machine, event, sample); break;
 	default:
 		ret = -1;
 		break;

commit a3366db06bb656cef2e03f30f780d93059bcc594
Author: Jin Yao <yao.jin@linux.intel.com>
Date:   Fri Jan 4 14:10:30 2019 +0800

    perf report: Fix wrong iteration count in --branch-history
    
    By calculating the removed loops, we can get the iteration count.
    
    But the iteration count could be reported incorrectly, reporting
    impossibly high counts.
    
    That's because previous code uses the number of removed LBR entries for
    the iteration count. That's not good. Fix this by increasing the
    iteration count when a loop is detected.
    
    When matching the chain, the iteration count would be added up, finally we need
    to compute the average value when printing out.
    
    For example,
    
      $ perf report --branch-history --stdio --no-children
    
    Before:
    
      ---f2 +0
         |
         |--33.62%--f1 +9 (cycles:1)
         |          f1 +0
         |          main +22 (cycles:1)
         |          main +17
         |          main +38 (cycles:1)
         |          main +27
         |          f1 +26 (cycles:1)
         |          f1 +24
         |          f2 +27 (cycles:7)
         |          f2 +0
         |          f1 +19 (cycles:1)
         |          f1 +14
         |          f2 +27 (cycles:11)
         |          f2 +0
         |          f1 +9 (cycles:1 iter:2968 avg_cycles:3)
         |          f1 +0
         |          main +22 (cycles:1 iter:2968 avg_cycles:3)
         |          main +17
         |          main +38 (cycles:1 iter:2968 avg_cycles:3)
    
    2968 is an impossible high iteration count and avg_cycles is too small.
    
    After:
    
      ---f2 +0
         |
         |--33.62%--f1 +9 (cycles:1)
         |          f1 +0
         |          main +22 (cycles:1)
         |          main +17
         |          main +38 (cycles:1)
         |          main +27
         |          f1 +26 (cycles:1)
         |          f1 +24
         |          f2 +27 (cycles:7)
         |          f2 +0
         |          f1 +19 (cycles:1)
         |          f1 +14
         |          f2 +27 (cycles:11)
         |          f2 +0
         |          f1 +9 (cycles:1 iter:1 avg_cycles:23)
         |          f1 +0
         |          main +22 (cycles:1 iter:1 avg_cycles:23)
         |          main +17
         |          main +38 (cycles:1 iter:1 avg_cycles:23)
    
    avg_cycles:23 is the average cycles of this iteration.
    
    Fixes: c4ee06251d42 ("perf report: Calculate the average cycles of iterations")
    
    Signed-off-by: Jin Yao <yao.jin@linux.intel.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Kan Liang <kan.liang@linux.intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1546582230-17507-1-git-send-email-yao.jin@linux.intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 6fcb3bce0442..143f7057d581 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2005,7 +2005,7 @@ static void save_iterations(struct iterations *iter,
 {
 	int i;
 
-	iter->nr_loop_iter = nr;
+	iter->nr_loop_iter++;
 	iter->cycles = 0;
 
 	for (i = 0; i < nr; i++)

commit 3fcb10e496505e5573a7fc386cd1152781d37fe6
Author: Mark Drayton <mbd@fb.com>
Date:   Tue Dec 4 12:34:20 2018 -0800

    perf tools: Allow specifying proc-map-timeout in config file
    
    The default timeout of 500ms for parsing /proc/<pid>/maps files is too
    short for profiling many of our services.
    
    This can be overridden by passing --proc-map-timeout to the relevant
    command but it'd be nice to globally increase our default value.
    
    This patch permits setting a different default with the
    core.proc-map-timeout config file parameter.
    
    Signed-off-by: Mark Drayton <mbd@fb.com>
    Acked-by: Song Liu <songliubraving@fb.com>
    Acked-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20181204203420.1683114-1-mbd@fb.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index d1309201c1d2..6fcb3bce0442 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2493,15 +2493,13 @@ int machines__for_each_thread(struct machines *machines,
 int __machine__synthesize_threads(struct machine *machine, struct perf_tool *tool,
 				  struct target *target, struct thread_map *threads,
 				  perf_event__handler_t process, bool data_mmap,
-				  unsigned int proc_map_timeout,
 				  unsigned int nr_threads_synthesize)
 {
 	if (target__has_task(target))
-		return perf_event__synthesize_thread_map(tool, threads, process, machine, data_mmap, proc_map_timeout);
+		return perf_event__synthesize_thread_map(tool, threads, process, machine, data_mmap);
 	else if (target__has_cpu(target))
 		return perf_event__synthesize_threads(tool, process,
 						      machine, data_mmap,
-						      proc_map_timeout,
 						      nr_threads_synthesize);
 	/* command specified */
 	return 0;

commit adba163441597ffb56141233a2ef722b75caca87
Author: Ingo Molnar <mingo@kernel.org>
Date:   Mon Dec 3 11:22:00 2018 +0100

    perf tools: Fix diverse comment typos
    
    Go over the tools/ files that are maintained in Arnaldo's tree and
    fix common typos: half of them were in comments, the other half
    in JSON files.
    
    No change in functionality intended.
    
    Committer notes:
    
    This was split from a larger patch as there are code that is,
    additionally, maintained outside the kernel tree, so to ease
    cherry-picking and/or backporting, split this into multiple patches.
    
    Just typos in comments, no need to backport, reducing the possibility of
    possible backporting artifacts.
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20181203102200.GA104797@gmail.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 9397e3f2444d..d1309201c1d2 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -137,7 +137,7 @@ struct machine *machine__new_kallsyms(void)
 	struct machine *machine = machine__new_host();
 	/*
 	 * FIXME:
-	 * 1) We should switch to machine__load_kallsyms(), i.e. not explicitely
+	 * 1) We should switch to machine__load_kallsyms(), i.e. not explicitly
 	 *    ask for not using the kcore parsing code, once this one is fixed
 	 *    to create a map per module.
 	 */

commit 8e80ad9983caeee09c3a0a1a37e05bff93becce4
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Tue Nov 6 23:07:10 2018 +0200

    perf thread: Add fallback functions for cases where cpumode is insufficient
    
    For branch stacks or branch samples, the sample cpumode might not be
    correct because it applies only to the sample 'ip' and not necessary to
    'addr' or branch stack addresses. Add fallback functions that can be
    used to deal with those cases
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Leo Yan <leo.yan@linaro.org>
    Cc: Mathieu Poirier <mathieu.poirier@linaro.org>
    Cc: stable@vger.kernel.org # 4.19
    Link: http://lkml.kernel.org/r/20181106210712.12098-2-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 8f36ce813bc5..9397e3f2444d 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2592,6 +2592,33 @@ int machine__get_kernel_start(struct machine *machine)
 	return err;
 }
 
+u8 machine__addr_cpumode(struct machine *machine, u8 cpumode, u64 addr)
+{
+	u8 addr_cpumode = cpumode;
+	bool kernel_ip;
+
+	if (!machine->single_address_space)
+		goto out;
+
+	kernel_ip = machine__kernel_ip(machine, addr);
+	switch (cpumode) {
+	case PERF_RECORD_MISC_KERNEL:
+	case PERF_RECORD_MISC_USER:
+		addr_cpumode = kernel_ip ? PERF_RECORD_MISC_KERNEL :
+					   PERF_RECORD_MISC_USER;
+		break;
+	case PERF_RECORD_MISC_GUEST_KERNEL:
+	case PERF_RECORD_MISC_GUEST_USER:
+		addr_cpumode = kernel_ip ? PERF_RECORD_MISC_GUEST_KERNEL :
+					   PERF_RECORD_MISC_GUEST_USER;
+		break;
+	default:
+		break;
+	}
+out:
+	return addr_cpumode;
+}
+
 struct dso *machine__findnew_dso(struct machine *machine, const char *filename)
 {
 	return dsos__findnew(&machine->dsos, filename);

commit 4f8f382e635707ddaddf8269a116e4f8cc8835c0
Author: David Miller <davem@davemloft.net>
Date:   Tue Oct 30 22:24:04 2018 -0700

    perf tools: Don't clone maps from parent when synthesizing forks
    
    When synthesizing FORK events, we are trying to create thread objects
    for the already running tasks on the machine.
    
    Normally, for a kernel FORK event, we want to clone the parent's maps
    because that is what the kernel just did.
    
    But when synthesizing, this should not be done.  If we do, we end up
    with overlapping maps as we process the sythesized MMAP2 events that
    get delivered shortly thereafter.
    
    Use the FORK event misc flags in an internal way to signal this
    situation, so we can elide the map clone when appropriate.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Joe Mario <jmario@redhat.com>
    Link: http://lkml.kernel.org/r/20181030.222404.2085088822877051075.davem@davemloft.net
    [ Added comment about flag use in machine__process_fork_event(),
      use ternary op in thread__clone_map_groups() as suggested by Jiri ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 8ee8ab39d8ac..8f36ce813bc5 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1708,6 +1708,7 @@ int machine__process_fork_event(struct machine *machine, union perf_event *event
 	struct thread *parent = machine__findnew_thread(machine,
 							event->fork.ppid,
 							event->fork.ptid);
+	bool do_maps_clone = true;
 	int err = 0;
 
 	if (dump_trace)
@@ -1736,9 +1737,25 @@ int machine__process_fork_event(struct machine *machine, union perf_event *event
 
 	thread = machine__findnew_thread(machine, event->fork.pid,
 					 event->fork.tid);
+	/*
+	 * When synthesizing FORK events, we are trying to create thread
+	 * objects for the already running tasks on the machine.
+	 *
+	 * Normally, for a kernel FORK event, we want to clone the parent's
+	 * maps because that is what the kernel just did.
+	 *
+	 * But when synthesizing, this should not be done.  If we do, we end up
+	 * with overlapping maps as we process the sythesized MMAP2 events that
+	 * get delivered shortly thereafter.
+	 *
+	 * Use the FORK event misc flags in an internal way to signal this
+	 * situation, so we can elide the map clone when appropriate.
+	 */
+	if (event->fork.header.misc & PERF_RECORD_MISC_FORK_EXEC)
+		do_maps_clone = false;
 
 	if (thread == NULL || parent == NULL ||
-	    thread__fork(thread, parent, sample->time) < 0) {
+	    thread__fork(thread, parent, sample->time, do_maps_clone) < 0) {
 		dump_printf("problem processing PERF_RECORD_FORK, skipping event.\n");
 		err = -1;
 	}

commit e9024d519d892b38176cafd46f68a7cdddd77412
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Oct 30 12:12:26 2018 -0300

    perf callchain: Honour the ordering of PERF_CONTEXT_{USER,KERNEL,etc}
    
    When processing using 'perf report -g caller', which is the default, we
    ended up reverting the callchain entries received from the kernel, but
    simply reverting throws away the information that tells that from a
    point onwards the addresses are for userspace, kernel, guest kernel,
    guest user, hypervisor.
    
    The idea is that if we are walking backwards, for each cluster of
    non-cpumode entries we have to first scan backwards for the next one and
    use that for the cluster.
    
    This seems silly and more expensive than it needs to be but it is enough
    for a initial fix.
    
    The code here is really complicated because it is intimately intertwined
    with the lbr and branch handling, as well as this callchain order,
    further fixes will be needed to properly take into account the cpumode
    in those cases.
    
    Another problem with ORDER_CALLER is that the NULL "0" IP that is at the
    end of most callchains shows up at the top of the histogram because
    every callchain contains it and with ORDER_CALLER it is the first entry.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Souvik Banerjee <souvik1997@gmail.com>
    Cc: Wang Nan <wangnan0@huawei.com>
    Cc: stable@vger.kernel.org # 4.19
    Link: https://lkml.kernel.org/n/tip-2wt3ayp6j2y2f2xowixa8y6y@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 111ae858cbcb..8ee8ab39d8ac 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2140,6 +2140,27 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 	return 0;
 }
 
+static int find_prev_cpumode(struct ip_callchain *chain, struct thread *thread,
+			     struct callchain_cursor *cursor,
+			     struct symbol **parent,
+			     struct addr_location *root_al,
+			     u8 *cpumode, int ent)
+{
+	int err = 0;
+
+	while (--ent >= 0) {
+		u64 ip = chain->ips[ent];
+
+		if (ip >= PERF_CONTEXT_MAX) {
+			err = add_callchain_ip(thread, cursor, parent,
+					       root_al, cpumode, ip,
+					       false, NULL, NULL, 0);
+			break;
+		}
+	}
+	return err;
+}
+
 static int thread__resolve_callchain_sample(struct thread *thread,
 					    struct callchain_cursor *cursor,
 					    struct perf_evsel *evsel,
@@ -2246,6 +2267,12 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	}
 
 check_calls:
+	if (callchain_param.order != ORDER_CALLEE) {
+		err = find_prev_cpumode(chain, thread, cursor, parent, root_al,
+					&cpumode, chain->nr - first_call);
+		if (err)
+			return (err < 0) ? err : 0;
+	}
 	for (i = first_call, nr_entries = 0;
 	     i < chain_nr && nr_entries < max_stack; i++) {
 		u64 ip;
@@ -2260,9 +2287,15 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 			continue;
 #endif
 		ip = chain->ips[j];
-
 		if (ip < PERF_CONTEXT_MAX)
                        ++nr_entries;
+		else if (callchain_param.order != ORDER_CALLEE) {
+			err = find_prev_cpumode(chain, thread, cursor, parent,
+						root_al, &cpumode, j);
+			if (err)
+				return (err < 0) ? err : 0;
+			continue;
+		}
 
 		err = add_callchain_ip(thread, cursor, parent,
 				       root_al, &cpumode, ip,

commit 7a8a8fcf7b860e4b2d4edc787c844d41cad9dfcf
Author: Milian Wolff <milian.wolff@kdab.com>
Date:   Wed Sep 26 15:52:06 2018 +0200

    perf record: Use unmapped IP for inline callchain cursors
    
    Only use the mapped IP to find inline frames, but keep using the
    unmapped IP for the callchain cursor. This ensures we properly show the
    unmapped IP when displaying a frame we received via the
    dso__parse_addr_inlines API for a module which does not contain
    sufficient debug symbols to show the srcline.
    
    This is another follow-up to commit 19610184693c ("perf script: Show
    virtual addresses instead of offsets").
    
    Signed-off-by: Milian Wolff <milian.wolff@kdab.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Tested-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Jin Yao <yao.jin@linux.intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Sandipan Das <sandipan@linux.ibm.com>
    Fixes: 19610184693c ("perf script: Show virtual addresses instead of offsets")
    Link: http://lkml.kernel.org/r/20180926135207.30263-2-milian.wolff@kdab.com
    Link: http://lkml.kernel.org/r/20181002073949.3297-1-milian.wolff@kdab.com
    [ Squashed a fix from Milian for a problem reported by Ravi, fixed up space damage ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 0cb4f8bf3ca7..111ae858cbcb 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2286,7 +2286,8 @@ static int append_inlines(struct callchain_cursor *cursor,
 	if (!symbol_conf.inline_name || !map || !sym)
 		return ret;
 
-	addr = map__rip_2objdump(map, ip);
+	addr = map__map_ip(map, ip);
+	addr = map__rip_2objdump(map, addr);
 
 	inline_node = inlines__tree_find(&map->dso->inlined_nodes, addr);
 	if (!inline_node) {

commit ff4ce2885af8f9e8e99864d78dbeb4673f089c76
Author: Milian Wolff <milian.wolff@kdab.com>
Date:   Wed Sep 26 15:52:05 2018 +0200

    perf report: Don't try to map ip to invalid map
    
    Fixes a crash when the report encounters an address that could not be
    associated with an mmaped region:
    
      #0  0x00005555557bdc4a in callchain_srcline (ip=<error reading variable: Cannot access memory at address 0x38>, sym=0x0, map=0x0) at util/machine.c:2329
      #1  unwind_entry (entry=entry@entry=0x7fffffff9180, arg=arg@entry=0x7ffff5642498) at util/machine.c:2329
      #2  0x00005555558370af in entry (arg=0x7ffff5642498, cb=0x5555557bdb50 <unwind_entry>, thread=<optimized out>, ip=18446744073709551615) at util/unwind-libunwind-local.c:586
      #3  get_entries (ui=ui@entry=0x7fffffff9620, cb=0x5555557bdb50 <unwind_entry>, arg=0x7ffff5642498, max_stack=<optimized out>) at util/unwind-libunwind-local.c:703
      #4  0x0000555555837192 in _unwind__get_entries (cb=<optimized out>, arg=<optimized out>, thread=<optimized out>, data=<optimized out>, max_stack=<optimized out>) at util/unwind-libunwind-local.c:725
      #5  0x00005555557c310f in thread__resolve_callchain_unwind (max_stack=127, sample=0x7fffffff9830, evsel=0x555555c7b3b0, cursor=0x7ffff5642498, thread=0x555555c7f6f0) at util/machine.c:2351
      #6  thread__resolve_callchain (thread=0x555555c7f6f0, cursor=0x7ffff5642498, evsel=0x555555c7b3b0, sample=0x7fffffff9830, parent=0x7fffffff97b8, root_al=0x7fffffff9750, max_stack=127) at util/machine.c:2378
      #7  0x00005555557ba4ee in sample__resolve_callchain (sample=<optimized out>, cursor=<optimized out>, parent=parent@entry=0x7fffffff97b8, evsel=<optimized out>, al=al@entry=0x7fffffff9750,
          max_stack=<optimized out>) at util/callchain.c:1085
    
    Signed-off-by: Milian Wolff <milian.wolff@kdab.com>
    Tested-by: Sandipan Das <sandipan@linux.ibm.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Jin Yao <yao.jin@linux.intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Fixes: 2a9d5050dc84 ("perf script: Show correct offsets for DWARF-based unwinding")
    Link: http://lkml.kernel.org/r/20180926135207.30263-1-milian.wolff@kdab.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index c4acd2001db0..0cb4f8bf3ca7 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2312,7 +2312,7 @@ static int unwind_entry(struct unwind_entry *entry, void *arg)
 {
 	struct callchain_cursor *cursor = arg;
 	const char *srcline = NULL;
-	u64 addr;
+	u64 addr = entry->ip;
 
 	if (symbol_conf.hide_unresolved && entry->sym == NULL)
 		return 0;
@@ -2324,7 +2324,8 @@ static int unwind_entry(struct unwind_entry *entry, void *arg)
 	 * Convert entry->ip from a virtual address to an offset in
 	 * its corresponding binary.
 	 */
-	addr = map__map_ip(entry->map, entry->ip);
+	if (entry->map)
+		addr = map__map_ip(entry->map, entry->ip);
 
 	srcline = callchain_srcline(entry->map, entry->sym, addr);
 	return callchain_cursor_append(cursor, entry->ip,

commit 2af5247530e073f4146d74ecd96cf64c953c001c
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Fri Aug 17 11:48:07 2018 +0200

    perf tools: Store compression id into struct dso
    
    Add comp to 'struct dso' to hold the compression index.  It will be used
    in the following patches.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Michael Petlan <mpetlan@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20180817094813.15086-8-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index b300a3973448..c4acd2001db0 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1212,8 +1212,10 @@ static int map_groups__set_module_path(struct map_groups *mg, const char *path,
 	 * Full name could reveal us kmod compression, so
 	 * we need to update the symtab_type if needed.
 	 */
-	if (m->comp && is_kmod_dso(map->dso))
+	if (m->comp && is_kmod_dso(map->dso)) {
 		map->dso->symtab_type++;
+		map->dso->comp = m->comp;
+	}
 
 	return 0;
 }

commit b57334b9453949bf81281321d14d86d60aee6fde
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Thu Jul 19 16:33:44 2018 +0200

    perf machine: Use last_match threads cache only in single thread mode
    
    There's an issue with using threads::last_match in multithread mode
    which is enabled during the perf top synthesize. It might crash with
    following assertion:
    
      perf: ...include/linux/refcount.h:109: refcount_inc:
            Assertion `!(!refcount_inc_not_zero(r))' failed.
    
    The gdb backtrace looks like this:
    
      0x00007ffff50839fb in raise () from /lib64/libc.so.6
      (gdb)
      #0  0x00007ffff50839fb in raise () from /lib64/libc.so.6
      #1  0x00007ffff5085800 in abort () from /lib64/libc.so.6
      #2  0x00007ffff507c0da in __assert_fail_base () from /lib64/libc.so.6
      #3  0x00007ffff507c152 in __assert_fail () from /lib64/libc.so.6
      #4  0x0000000000535ff9 in refcount_inc (r=0x7fffe8009a70)
          at ...include/linux/refcount.h:109
      #5  0x0000000000536771 in thread__get (thread=0x7fffe8009a40)
          at util/thread.c:115
      #6  0x0000000000523cd0 in ____machine__findnew_thread (machine=0xbfde38,
          threads=0xbfdf28, pid=2, tid=2, create=true) at util/machine.c:432
      #7  0x0000000000523eb4 in __machine__findnew_thread (machine=0xbfde38,
          pid=2, tid=2) at util/machine.c:489
      #8  0x0000000000523f24 in machine__findnew_thread (machine=0xbfde38,
          pid=2, tid=2) at util/machine.c:499
      #9  0x0000000000526fbe in machine__process_fork_event (machine=0xbfde38,
      ...
    
    The failing assertion is this one:
    
      REFCOUNT_WARN(!refcount_inc_not_zero(r), ...
    
    the problem is that we don't serialize access to threads::last_match.
    We serialize the access to the threads tree, but we don't care how's
    threads::last_match being accessed. Both locked/unlocked paths use
    that data and can set it. In multithreaded mode we can end up with
    invalid object in thread__get call, like in following paths race:
    
      thread 1
        ...
        machine__findnew_thread
          down_write(&threads->lock);
          __machine__findnew_thread
            ____machine__findnew_thread
              th = threads->last_match;
              if (th->tid == tid) {
                thread__get
    
      thread 2
        ...
        machine__find_thread
          down_read(&threads->lock);
          __machine__findnew_thread
            ____machine__findnew_thread
              th = threads->last_match;
              if (th->tid == tid) {
                thread__get
    
      thread 3
        ...
        machine__process_fork_event
          machine__remove_thread
            __machine__remove_thread
              threads->last_match = NULL
              thread__put
          thread__put
    
    Thread 1 and 2 might got stale last_match, before thread 3 clears
    it. Thread 1 and 2 then race with thread 3's thread__put and they
    might trigger the refcnt == 0 assertion above.
    
    The patch is disabling the last_match cache for multiple thread
    mode. It was originally meant for single thread scenarios, where
    it's common to have multiple sequential searches of the same
    thread.
    
    In multithread mode this does not make sense, because top's threads
    processes different /proc entries and so the 'struct threads' object
    is queried for various threads. Moreover we'd need to add more locks
    to make it work.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Kan Liang <kan.liang@linux.intel.com>
    Cc: Lukasz Odzioba <lukasz.odzioba@intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/r/20180719143345.12963-4-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 8992fcf42257..b300a3973448 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -413,8 +413,8 @@ static void machine__update_thread_pid(struct machine *machine,
  * the full rbtree:
  */
 static struct thread*
-threads__get_last_match(struct threads *threads, struct machine *machine,
-			int pid, int tid)
+__threads__get_last_match(struct threads *threads, struct machine *machine,
+			  int pid, int tid)
 {
 	struct thread *th;
 
@@ -431,12 +431,31 @@ threads__get_last_match(struct threads *threads, struct machine *machine,
 	return NULL;
 }
 
+static struct thread*
+threads__get_last_match(struct threads *threads, struct machine *machine,
+			int pid, int tid)
+{
+	struct thread *th = NULL;
+
+	if (perf_singlethreaded)
+		th = __threads__get_last_match(threads, machine, pid, tid);
+
+	return th;
+}
+
 static void
-threads__set_last_match(struct threads *threads, struct thread *th)
+__threads__set_last_match(struct threads *threads, struct thread *th)
 {
 	threads->last_match = th;
 }
 
+static void
+threads__set_last_match(struct threads *threads, struct thread *th)
+{
+	if (perf_singlethreaded)
+		__threads__set_last_match(threads, th);
+}
+
 /*
  * Caller must eventually drop thread->refcnt returned with a successful
  * lookup/new thread inserted.

commit 67fda0f32cd9428cb9a3166796162097d7fcbcbf
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Thu Jul 19 16:33:43 2018 +0200

    perf machine: Add threads__set_last_match function
    
    Separating threads::last_match cache set into separate
    threads__set_last_match function.  This will be useful in following
    patch.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Kan Liang <kan.liang@linux.intel.com>
    Cc: Lukasz Odzioba <lukasz.odzioba@intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/r/20180719143345.12963-3-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index df41aa1a4cf9..8992fcf42257 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -431,6 +431,12 @@ threads__get_last_match(struct threads *threads, struct machine *machine,
 	return NULL;
 }
 
+static void
+threads__set_last_match(struct threads *threads, struct thread *th)
+{
+	threads->last_match = th;
+}
+
 /*
  * Caller must eventually drop thread->refcnt returned with a successful
  * lookup/new thread inserted.
@@ -453,7 +459,7 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 		th = rb_entry(parent, struct thread, rb_node);
 
 		if (th->tid == tid) {
-			threads->last_match = th;
+			threads__set_last_match(threads, th);
 			machine__update_thread_pid(machine, th, pid);
 			return thread__get(th);
 		}
@@ -490,7 +496,7 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 		 * It is now in the rbtree, get a ref
 		 */
 		thread__get(th);
-		threads->last_match = th;
+		threads__set_last_match(threads, th);
 		++threads->nr;
 	}
 
@@ -1648,7 +1654,7 @@ static void __machine__remove_thread(struct machine *machine, struct thread *th,
 	struct threads *threads = machine__threads(machine, th->tid);
 
 	if (threads->last_match == th)
-		threads->last_match = NULL;
+		threads__set_last_match(threads, NULL);
 
 	BUG_ON(refcount_read(&th->refcnt) == 0);
 	if (lock)

commit f8b2ebb532e0553b60ae5ad1b84d1d4f0c285752
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Thu Jul 19 16:33:42 2018 +0200

    perf machine: Add threads__get_last_match function
    
    Separating threads::last_match cache read/check into separate
    threads__get_last_match function. This will be useful in following
    patch.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Kan Liang <kan.liang@linux.intel.com>
    Cc: Lukasz Odzioba <lukasz.odzioba@intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/r/20180719143345.12963-2-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 22dbb6612b41..df41aa1a4cf9 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -408,23 +408,16 @@ static void machine__update_thread_pid(struct machine *machine,
 }
 
 /*
- * Caller must eventually drop thread->refcnt returned with a successful
- * lookup/new thread inserted.
+ * Front-end cache - TID lookups come in blocks,
+ * so most of the time we dont have to look up
+ * the full rbtree:
  */
-static struct thread *____machine__findnew_thread(struct machine *machine,
-						  struct threads *threads,
-						  pid_t pid, pid_t tid,
-						  bool create)
+static struct thread*
+threads__get_last_match(struct threads *threads, struct machine *machine,
+			int pid, int tid)
 {
-	struct rb_node **p = &threads->entries.rb_node;
-	struct rb_node *parent = NULL;
 	struct thread *th;
 
-	/*
-	 * Front-end cache - TID lookups come in blocks,
-	 * so most of the time we dont have to look up
-	 * the full rbtree:
-	 */
 	th = threads->last_match;
 	if (th != NULL) {
 		if (th->tid == tid) {
@@ -435,6 +428,26 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 		threads->last_match = NULL;
 	}
 
+	return NULL;
+}
+
+/*
+ * Caller must eventually drop thread->refcnt returned with a successful
+ * lookup/new thread inserted.
+ */
+static struct thread *____machine__findnew_thread(struct machine *machine,
+						  struct threads *threads,
+						  pid_t pid, pid_t tid,
+						  bool create)
+{
+	struct rb_node **p = &threads->entries.rb_node;
+	struct rb_node *parent = NULL;
+	struct thread *th;
+
+	th = threads__get_last_match(threads, machine, pid, tid);
+	if (th)
+		return th;
+
 	while (*p != NULL) {
 		parent = *p;
 		th = rb_entry(parent, struct thread, rb_node);

commit 2a9d5050dc84fa2060f08a52f632976923e0fa7e
Author: Sandipan Das <sandipan@linux.ibm.com>
Date:   Tue Jul 3 17:35:55 2018 +0530

    perf script: Show correct offsets for DWARF-based unwinding
    
    When perf/data is recorded with the dwarf call-graph option, the
    callchain shown by 'perf script' still shows the binary offsets of the
    userspace symbols instead of their virtual addresses. Since the symbol
    offset calculation is based on using virtual address as the ip, we see
    incorrect offsets as well.
    
    The use of virtual addresses affects the ability to find out the
    line number in the corresponding source file to which an address
    maps to as described in commit 67540759151a ("perf unwind: Use
    addr_location::addr instead of ip for entries").
    
    This has also been addressed by temporarily converting the virtual
    address to the correponding binary offset so that it can be mapped
    to the source line number correctly.
    
    This is a follow-up for commit 19610184693c ("perf script: Show
    virtual addresses instead of offsets").
    
    This can be verified on a powerpc64le system running Fedora 27 as
    shown below:
    
      # perf probe -x /usr/lib64/libc-2.26.so -a inet_pton
      # perf record -e probe_libc:inet_pton --call-graph=dwarf ping -6 -c 1 ::1
    
    Before:
    
      # perf report --stdio --no-children -s sym,srcline -g address
    
      # Samples: 1  of event 'probe_libc:inet_pton'
      # Event count (approx.): 1
      #
      # Overhead  Symbol                Source:Line
      # ........  ....................  ...........
      #
         100.00%  [.] __GI___inet_pton  inet_pton.c
                  |
                  ---gaih_inet getaddrinfo.c:537 (inlined)
                     __GI_getaddrinfo getaddrinfo.c:2304 (inlined)
                     main ping.c:519
                     generic_start_main libc-start.c:308 (inlined)
                     __libc_start_main libc-start.c:102
      ...
    
      # perf script -F comm,ip,sym,symoff,srcline,dso
    
      ping
                        15af28 __GI___inet_pton+0xffff000099160008 (/usr/lib64/libc-2.26.so)
        libc-2.26.so[ffff80004ca0af28]
                        10fa53 gaih_inet+0xffff000099160f43
        libc-2.26.so[ffff80004c9bfa53] (inlined)
                        1105b3 __GI_getaddrinfo+0xffff000099160163
        libc-2.26.so[ffff80004c9c05b3] (inlined)
                          2d6f main+0xfffffffd9f1003df (/usr/bin/ping)
        ping[fffffffecf882d6f]
                         2369f generic_start_main+0xffff00009916013f
        libc-2.26.so[ffff80004c8d369f] (inlined)
                         23897 __libc_start_main+0xffff0000991600b7 (/usr/lib64/libc-2.26.so)
        libc-2.26.so[ffff80004c8d3897]
    
    After:
    
      # perf report --stdio --no-children -s sym,srcline -g address
    
      # Samples: 1  of event 'probe_libc:inet_pton'
      # Event count (approx.): 1
      #
      # Overhead  Symbol                Source:Line
      # ........  ....................  ...........
      #
         100.00%  [.] __GI___inet_pton  inet_pton.c
                  |
                  ---gaih_inet.constprop.7 getaddrinfo.c:537
                     getaddrinfo getaddrinfo.c:2304
                     main ping.c:519
                     generic_start_main.isra.0 libc-start.c:308
                     __libc_start_main libc-start.c:102
      ...
    
      # perf script -F comm,ip,sym,symoff,srcline,dso
    
      ping
                  7fffb38aaf28 __GI___inet_pton+0x8 (/usr/lib64/libc-2.26.so)
        inet_pton.c:68
                  7fffb385fa53 gaih_inet.constprop.7+0xf43 (/usr/lib64/libc-2.26.so)
        getaddrinfo.c:537
                  7fffb38605b3 getaddrinfo+0x163 (/usr/lib64/libc-2.26.so)
        getaddrinfo.c:2304
                     130782d6f main+0x3df (/usr/bin/ping)
        ping.c:519
                  7fffb377369f generic_start_main.isra.0+0x13f (/usr/lib64/libc-2.26.so)
        libc-start.c:308
                  7fffb3773897 __libc_start_main+0xb7 (/usr/lib64/libc-2.26.so)
        libc-start.c:102
    
    Signed-off-by: Sandipan Das <sandipan@linux.ibm.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Milian Wolff <milian.wolff@kdab.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Cc: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Fixes: 67540759151a ("perf unwind: Use addr_location::addr instead of ip for entries")
    Link: http://lkml.kernel.org/r/20180703120555.32971-1-sandipan@linux.ibm.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index e7b4a8b513f2..22dbb6612b41 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2272,6 +2272,7 @@ static int unwind_entry(struct unwind_entry *entry, void *arg)
 {
 	struct callchain_cursor *cursor = arg;
 	const char *srcline = NULL;
+	u64 addr;
 
 	if (symbol_conf.hide_unresolved && entry->sym == NULL)
 		return 0;
@@ -2279,7 +2280,13 @@ static int unwind_entry(struct unwind_entry *entry, void *arg)
 	if (append_inlines(cursor, entry->map, entry->sym, entry->ip) == 0)
 		return 0;
 
-	srcline = callchain_srcline(entry->map, entry->sym, entry->ip);
+	/*
+	 * Convert entry->ip from a virtual address to an offset in
+	 * its corresponding binary.
+	 */
+	addr = map__map_ip(entry->map, entry->ip);
+
+	srcline = callchain_srcline(entry->map, entry->sym, addr);
 	return callchain_cursor_append(cursor, entry->ip,
 				       entry->map, entry->sym,
 				       false, NULL, 0, 0, 0, srcline);

commit a8ce99b0ee9ad32debad0a9f28d21451ba237cc1
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Tue May 22 13:54:37 2018 +0300

    perf machine: Synthesize and process mmap events for x86 PTI entry trampolines
    
    Like the kernel text, the location of x86 PTI entry trampolines must be
    recorded in the perf.data file. Like the kernel, synthesize a mmap event
    for that, and add processing for it.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: x86@kernel.org
    Link: http://lkml.kernel.org/r/1526986485-6562-10-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index dd7ab0731167..e7b4a8b513f2 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1387,6 +1387,32 @@ static bool machine__uses_kcore(struct machine *machine)
 	return false;
 }
 
+static bool perf_event__is_extra_kernel_mmap(struct machine *machine,
+					     union perf_event *event)
+{
+	return machine__is(machine, "x86_64") &&
+	       is_entry_trampoline(event->mmap.filename);
+}
+
+static int machine__process_extra_kernel_map(struct machine *machine,
+					     union perf_event *event)
+{
+	struct map *kernel_map = machine__kernel_map(machine);
+	struct dso *kernel = kernel_map ? kernel_map->dso : NULL;
+	struct extra_kernel_map xm = {
+		.start = event->mmap.start,
+		.end   = event->mmap.start + event->mmap.len,
+		.pgoff = event->mmap.pgoff,
+	};
+
+	if (kernel == NULL)
+		return -1;
+
+	strlcpy(xm.name, event->mmap.filename, KMAP_NAME_LEN);
+
+	return machine__create_extra_kernel_map(machine, kernel, &xm);
+}
+
 static int machine__process_kernel_mmap_event(struct machine *machine,
 					      union perf_event *event)
 {
@@ -1490,6 +1516,8 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 			 */
 			dso__load(kernel, machine__kernel_map(machine));
 		}
+	} else if (perf_event__is_extra_kernel_mmap(machine, event)) {
+		return machine__process_extra_kernel_map(machine, event);
 	}
 	return 0;
 out_problem:

commit 1c5aae7710bb9ecf82a5cc88e35a028a8b385763
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Tue May 22 13:54:36 2018 +0300

    perf machine: Create maps for x86 PTI entry trampolines
    
    Create maps for x86 PTI entry trampolines, based on symbols found in
    kallsyms. It is also necessary to keep track of whether the trampolines
    have been mapped particularly when the kernel dso is kcore.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: x86@kernel.org
    Link: http://lkml.kernel.org/r/1526986485-6562-9-git-send-email-adrian.hunter@intel.com
    [ Fix extra_kernel_map_info.cnt designed struct initializer on gcc 4.4.7 (centos:6, etc) ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 355d23bcd443..dd7ab0731167 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -807,8 +807,8 @@ struct process_args {
 	u64 start;
 };
 
-static void machine__get_kallsyms_filename(struct machine *machine, char *buf,
-					   size_t bufsz)
+void machine__get_kallsyms_filename(struct machine *machine, char *buf,
+				    size_t bufsz)
 {
 	if (machine__is_default_guest(machine))
 		scnprintf(buf, bufsz, "%s", symbol_conf.default_guest_kallsyms);
@@ -851,17 +851,9 @@ static int machine__get_running_kernel_start(struct machine *machine,
 	return 0;
 }
 
-/* Kernel-space maps for symbols that are outside the main kernel map and module maps */
-struct extra_kernel_map {
-	u64 start;
-	u64 end;
-	u64 pgoff;
-	char name[KMAP_NAME_LEN];
-};
-
-static int machine__create_extra_kernel_map(struct machine *machine,
-					    struct dso *kernel,
-					    struct extra_kernel_map *xm)
+int machine__create_extra_kernel_map(struct machine *machine,
+				     struct dso *kernel,
+				     struct extra_kernel_map *xm)
 {
 	struct kmap *kmap;
 	struct map *map;
@@ -923,9 +915,33 @@ static u64 find_entry_trampoline(struct dso *dso)
 int machine__map_x86_64_entry_trampolines(struct machine *machine,
 					  struct dso *kernel)
 {
-	u64 pgoff = find_entry_trampoline(kernel);
+	struct map_groups *kmaps = &machine->kmaps;
+	struct maps *maps = &kmaps->maps;
 	int nr_cpus_avail, cpu;
+	bool found = false;
+	struct map *map;
+	u64 pgoff;
+
+	/*
+	 * In the vmlinux case, pgoff is a virtual address which must now be
+	 * mapped to a vmlinux offset.
+	 */
+	for (map = maps__first(maps); map; map = map__next(map)) {
+		struct kmap *kmap = __map__kmap(map);
+		struct map *dest_map;
+
+		if (!kmap || !is_entry_trampoline(kmap->name))
+			continue;
+
+		dest_map = map_groups__find(kmaps, map->pgoff);
+		if (dest_map != map)
+			map->pgoff = dest_map->map_ip(dest_map, map->pgoff);
+		found = true;
+	}
+	if (found || machine->trampolines_mapped)
+		return 0;
 
+	pgoff = find_entry_trampoline(kernel);
 	if (!pgoff)
 		return 0;
 
@@ -948,6 +964,14 @@ int machine__map_x86_64_entry_trampolines(struct machine *machine,
 			return -1;
 	}
 
+	machine->trampolines_mapped = nr_cpus_avail;
+
+	return 0;
+}
+
+int __weak machine__create_extra_kernel_maps(struct machine *machine __maybe_unused,
+					     struct dso *kernel __maybe_unused)
+{
 	return 0;
 }
 
@@ -1306,9 +1330,8 @@ int machine__create_kernel_maps(struct machine *machine)
 		return -1;
 
 	ret = __machine__create_kernel_maps(machine, kernel);
-	dso__put(kernel);
 	if (ret < 0)
-		return -1;
+		goto out_put;
 
 	if (symbol_conf.use_modules && machine__create_modules(machine) < 0) {
 		if (machine__is_host(machine))
@@ -1323,7 +1346,8 @@ int machine__create_kernel_maps(struct machine *machine)
 		if (name &&
 		    map__set_kallsyms_ref_reloc_sym(machine->vmlinux_map, name, addr)) {
 			machine__destroy_kernel_maps(machine);
-			return -1;
+			ret = -1;
+			goto out_put;
 		}
 
 		/* we have a real start address now, so re-order the kmaps */
@@ -1339,12 +1363,16 @@ int machine__create_kernel_maps(struct machine *machine)
 		map__put(map);
 	}
 
+	if (machine__create_extra_kernel_maps(machine, kernel))
+		pr_debug("Problems creating extra kernel maps, continuing anyway...\n");
+
 	/* update end address of the kernel map using adjacent module address */
 	map = map__next(machine__kernel_map(machine));
 	if (map)
 		machine__set_kernel_mmap(machine, addr, map->start);
-
-	return 0;
+out_put:
+	dso__put(kernel);
+	return ret;
 }
 
 static bool machine__uses_kcore(struct machine *machine)

commit 5759a6820aadd38b2c8c10e93919eae8e31a9f9a
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Tue May 22 13:54:35 2018 +0300

    perf machine: Allow for extra kernel maps
    
    Identify extra kernel maps by name so that they can be distinguished
    from the kernel map and module maps.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: x86@kernel.org
    Link: http://lkml.kernel.org/r/1526986485-6562-8-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index db695603873b..355d23bcd443 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -856,6 +856,7 @@ struct extra_kernel_map {
 	u64 start;
 	u64 end;
 	u64 pgoff;
+	char name[KMAP_NAME_LEN];
 };
 
 static int machine__create_extra_kernel_map(struct machine *machine,
@@ -875,11 +876,12 @@ static int machine__create_extra_kernel_map(struct machine *machine,
 	kmap = map__kmap(map);
 
 	kmap->kmaps = &machine->kmaps;
+	strlcpy(kmap->name, xm->name, KMAP_NAME_LEN);
 
 	map_groups__insert(&machine->kmaps, map);
 
-	pr_debug2("Added extra kernel map %" PRIx64 "-%" PRIx64 "\n",
-		  map->start, map->end);
+	pr_debug2("Added extra kernel map %s %" PRIx64 "-%" PRIx64 "\n",
+		  kmap->name, map->start, map->end);
 
 	map__put(map);
 
@@ -940,6 +942,8 @@ int machine__map_x86_64_entry_trampolines(struct machine *machine,
 			.pgoff = pgoff,
 		};
 
+		strlcpy(xm.name, ENTRY_TRAMPOLINE_NAME, KMAP_NAME_LEN);
+
 		if (machine__create_extra_kernel_map(machine, kernel, &xm) < 0)
 			return -1;
 	}

commit 4d99e4136580d178e3523281a820be17bf814bf8
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Tue May 22 13:54:33 2018 +0300

    perf machine: Workaround missing maps for x86 PTI entry trampolines
    
    On x86_64 the PTI entry trampolines are not in the kernel map created by
    perf tools. That results in the addresses having no symbols and prevents
    annotation.  It also causes Intel PT to have decoding errors at the
    trampoline addresses.
    
    Workaround that by creating maps for the trampolines.
    
    At present the kernel does not export information revealing where the
    trampolines are.  Until that happens, the addresses are hardcoded.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: x86@kernel.org
    Link: http://lkml.kernel.org/r/1526986485-6562-6-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index f62ecd9c36e8..db695603873b 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -851,6 +851,102 @@ static int machine__get_running_kernel_start(struct machine *machine,
 	return 0;
 }
 
+/* Kernel-space maps for symbols that are outside the main kernel map and module maps */
+struct extra_kernel_map {
+	u64 start;
+	u64 end;
+	u64 pgoff;
+};
+
+static int machine__create_extra_kernel_map(struct machine *machine,
+					    struct dso *kernel,
+					    struct extra_kernel_map *xm)
+{
+	struct kmap *kmap;
+	struct map *map;
+
+	map = map__new2(xm->start, kernel);
+	if (!map)
+		return -1;
+
+	map->end   = xm->end;
+	map->pgoff = xm->pgoff;
+
+	kmap = map__kmap(map);
+
+	kmap->kmaps = &machine->kmaps;
+
+	map_groups__insert(&machine->kmaps, map);
+
+	pr_debug2("Added extra kernel map %" PRIx64 "-%" PRIx64 "\n",
+		  map->start, map->end);
+
+	map__put(map);
+
+	return 0;
+}
+
+static u64 find_entry_trampoline(struct dso *dso)
+{
+	/* Duplicates are removed so lookup all aliases */
+	const char *syms[] = {
+		"_entry_trampoline",
+		"__entry_trampoline_start",
+		"entry_SYSCALL_64_trampoline",
+	};
+	struct symbol *sym = dso__first_symbol(dso);
+	unsigned int i;
+
+	for (; sym; sym = dso__next_symbol(sym)) {
+		if (sym->binding != STB_GLOBAL)
+			continue;
+		for (i = 0; i < ARRAY_SIZE(syms); i++) {
+			if (!strcmp(sym->name, syms[i]))
+				return sym->start;
+		}
+	}
+
+	return 0;
+}
+
+/*
+ * These values can be used for kernels that do not have symbols for the entry
+ * trampolines in kallsyms.
+ */
+#define X86_64_CPU_ENTRY_AREA_PER_CPU	0xfffffe0000000000ULL
+#define X86_64_CPU_ENTRY_AREA_SIZE	0x2c000
+#define X86_64_ENTRY_TRAMPOLINE		0x6000
+
+/* Map x86_64 PTI entry trampolines */
+int machine__map_x86_64_entry_trampolines(struct machine *machine,
+					  struct dso *kernel)
+{
+	u64 pgoff = find_entry_trampoline(kernel);
+	int nr_cpus_avail, cpu;
+
+	if (!pgoff)
+		return 0;
+
+	nr_cpus_avail = machine__nr_cpus_avail(machine);
+
+	/* Add a 1 page map for each CPU's entry trampoline */
+	for (cpu = 0; cpu < nr_cpus_avail; cpu++) {
+		u64 va = X86_64_CPU_ENTRY_AREA_PER_CPU +
+			 cpu * X86_64_CPU_ENTRY_AREA_SIZE +
+			 X86_64_ENTRY_TRAMPOLINE;
+		struct extra_kernel_map xm = {
+			.start = va,
+			.end   = va + page_size,
+			.pgoff = pgoff,
+		};
+
+		if (machine__create_extra_kernel_map(machine, kernel, &xm) < 0)
+			return -1;
+	}
+
+	return 0;
+}
+
 static int
 __machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
 {

commit 9cecca325ea879c84fcd31a5e609a514c1a1dbd1
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Tue May 22 13:54:32 2018 +0300

    perf machine: Add nr_cpus_avail()
    
    Add a function to return the number of the machine's available CPUs.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: x86@kernel.org
    Link: http://lkml.kernel.org/r/1526986485-6562-5-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index e011a7160380..f62ecd9c36e8 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2305,6 +2305,11 @@ bool machine__is(struct machine *machine, const char *arch)
 	return machine && !strcmp(perf_env__raw_arch(machine->env), arch);
 }
 
+int machine__nr_cpus_avail(struct machine *machine)
+{
+	return machine ? perf_env__nr_cpus_avail(machine->env) : 0;
+}
+
 int machine__get_kernel_start(struct machine *machine)
 {
 	struct map *map = machine__kernel_map(machine);

commit 19422a9f2a3be7f3a046285ffae4cbb571aa853a
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Thu May 17 12:21:54 2018 +0300

    perf tools: Fix kernel_start for PTI on x86
    
    Opickn x86_64, PTI entry trampolines are less than the start of kernel text,
    but still above 2^63. So leave kernel_start = 1ULL << 63 for x86_64.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Tested-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: x86@kernel.org
    Link: http://lkml.kernel.org/r/1526548928-20790-7-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 107bae7676b1..e011a7160380 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2321,7 +2321,12 @@ int machine__get_kernel_start(struct machine *machine)
 	machine->kernel_start = 1ULL << 63;
 	if (map) {
 		err = map__load(map);
-		if (!err)
+		/*
+		 * On x86_64, PTI entry trampolines are less than the
+		 * start of kernel text, but still above 2^63. So leave
+		 * kernel_start = 1ULL << 63 for x86_64.
+		 */
+		if (!err && !machine__is(machine, "x86_64"))
 			machine->kernel_start = map->start;
 	}
 	return err;

commit dbbd34a666ee117d0e39e71a47f38f02c4a5c698
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Thu May 17 12:21:53 2018 +0300

    perf machine: Add machine__is() to identify machine arch
    
    Add a function to identify the machine architecture.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Tested-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: x86@kernel.org
    Link: http://lkml.kernel.org/r/1526548928-20790-6-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 7c777cb32806..107bae7676b1 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2296,6 +2296,15 @@ int machine__set_current_tid(struct machine *machine, int cpu, pid_t pid,
 	return 0;
 }
 
+/*
+ * Compares the raw arch string. N.B. see instead perf_env__arch() if a
+ * normalized arch is needed.
+ */
+bool machine__is(struct machine *machine, const char *arch)
+{
+	return machine && !strcmp(perf_env__raw_arch(machine->env), arch);
+}
+
 int machine__get_kernel_start(struct machine *machine)
 {
 	struct map *map = machine__kernel_map(machine);

commit 19610184693c547b4c12738df4156589892c4018
Author: Sandipan Das <sandipan@linux.vnet.ibm.com>
Date:   Thu May 17 12:03:25 2018 +0530

    perf script: Show virtual addresses instead of offsets
    
    When perf data is recorded with the call-graph option enabled, the
    callchain shown by perf script shows the binary offsets of the symbols
    as the ip. This is incorrect for kernel symbols as the ip values are
    always off by a fixed offset depending on the architecture. If the
    offsets from the start of the symbols are printed, they are also
    incorrect for both kernel and userspace symbols.
    
    Without the call-graph option, the callchain shows the virtual addresses
    of the symbols rather than their binary offsets. The offsets printed in
    this case are also correct.
    
    This fixes the inconsistency in perf script's output.
    
    This can be verified on a powerpc64le system running Fedora 27 as
    follows:
    
      # cat /proc/kallsyms | grep sys_write
      ...
      c0000000004025a0 T sys_write
      c0000000004025a0 T __se_sys_write
      ...
    
      # perf probe -a sys_write
    
    Before applying this patch:
    
      # perf record -e probe:sys_write -g ~/test
      # perf script -F ip,sym,symoff
    
                        4125b0 sys_write+0x8000000000008010
                         1b9e0 system_call+0x8000000000008058
                        118234 __GI___libc_write+0xffff0000f52c0024
                         92c74 _IO_file_write@@GLIBC_2.17+0xffff0000f52c0044
                      5afbfd8a [unknown]
                         91a60 new_do_write+0xffff0000f52c0090
                         94638 _IO_do_write@@GLIBC_2.17+0xffff0000f52c0038
                         94bbc _IO_file_overflow@@GLIBC_2.17+0xffff0000f52c014c
                         95a24 __overflow+0xffff0000f52c0064
                         84548 _IO_puts+0xffff0000f52c0218
                           440 main+0xffffffffe0000020
                         236a0 generic_start_main.isra.0+0xffff0000f52c0140
                         23898 __libc_start_main+0xffff0000f52c00b8
                             0 [unknown]
      ...
    
      # perf record -e probe:sys_write ~/test
      # perf script -F ip,sym,symoff
    
      c0000000004025b0 sys_write+0x10
      ...
    
    After applying this patch:
    
      # perf record -e probe:sys_write -g ~/test
      # perf script -F ip,sym,symoff
    
              c0000000004025b0 sys_write+0x10
              c00000000000b9e0 system_call+0x58
                  7fffb70d8234 __GI___libc_write+0x24
                  7fffb7052c74 _IO_file_write@@GLIBC_2.17+0x44
                      5afc1818 [unknown]
                  7fffb7051a60 new_do_write+0x90
                  7fffb7054638 _IO_do_write@@GLIBC_2.17+0x38
                  7fffb7054bbc _IO_file_overflow@@GLIBC_2.17+0x14c
                  7fffb7055a24 __overflow+0x64
                  7fffb7044548 _IO_puts+0x218
                      10000440 main+0x20
                  7fffb6fe36a0 generic_start_main.isra.0+0x140
                  7fffb6fe3898 __libc_start_main+0xb8
                             0 [unknown]
      ...
    
      # perf record -e probe:sys_write ~/test
      # perf script -F ip,sym,symoff
    
      c0000000004025b0 sys_write+0x10
      ...
    
    Signed-off-by: Sandipan Das <sandipan@linux.vnet.ibm.com>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Cc: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Link: http://lkml.kernel.org/r/20180517063326.6319-1-sandipan@linux.vnet.ibm.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 72a351613d85..7c777cb32806 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1764,7 +1764,7 @@ static int add_callchain_ip(struct thread *thread,
 	}
 
 	srcline = callchain_srcline(al.map, al.sym, al.addr);
-	return callchain_cursor_append(cursor, al.addr, al.map, al.sym,
+	return callchain_cursor_append(cursor, ip, al.map, al.sym,
 				       branch, flags, nr_loop_iter,
 				       iter_cycles, branch_from, srcline);
 }

commit 107cad95ffd81afad295ed5c29d006e525f1f80f
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Apr 30 12:20:54 2018 -0300

    perf machine: Ditch find_kernel_function variants
    
    Since we do not have split symtabs anymore, no need to have explicit
    find_kernel_function variants, use the find_kernel_symbol ones.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: https://lkml.kernel.org/n/tip-hiw2ryflju000f6wl62128it@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index b707041f9a22..72a351613d85 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2327,7 +2327,7 @@ char *machine__resolve_kernel_addr(void *vmachine, unsigned long long *addrp, ch
 {
 	struct machine *machine = vmachine;
 	struct map *map;
-	struct symbol *sym = machine__find_kernel_function(machine, *addrp, &map);
+	struct symbol *sym = machine__find_kernel_symbol(machine, *addrp, &map);
 
 	if (sym == NULL)
 		return NULL;

commit 3183f8ca304fd84096c44332f9bb699943beb6f1
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Apr 26 16:52:34 2018 -0300

    perf symbols: Unify symbol maps
    
    Remove the split of symbol tables for data (MAP__VARIABLE) and for
    functions (MAP__FUNCTION), its unneeded and there were various places
    doing two lookups to find a symbol, so simplify this.
    
    We still will consider only the symbols that matched the filters in
    place, i.e. see the (elf_(sec,sym)|symbol_type)__filter() routines in
    the patch, just so that we consider only the same symbols as before,
    to reduce the possibility of regressions.
    
    All the tests on 50-something build environments, in varios versions
    of lots of distros and cross build environments were performed without
    build regressions, as usual with all pull requests the other tests were
    also performed: 'perf test' and 'make -C tools/perf build-test'.
    
    Also this was done at a great granularity so that regressions can be
    bisected more easily.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: https://lkml.kernel.org/n/tip-hiq0fy2rsleupnqqwuojo1ne@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 53bc2fb88be4..b707041f9a22 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -82,8 +82,7 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 	machine->kptr_restrict_warned = false;
 	machine->comm_exec = false;
 	machine->kernel_start = 0;
-
-	memset(machine->vmlinux_maps, 0, sizeof(machine->vmlinux_maps));
+	machine->vmlinux_map = NULL;
 
 	machine->root_dir = strdup(root_dir);
 	if (machine->root_dir == NULL)
@@ -687,7 +686,7 @@ struct map *machine__findnew_module_map(struct machine *machine, u64 start,
 	if (dso == NULL)
 		goto out;
 
-	map = map__new2(start, dso, MAP__FUNCTION);
+	map = map__new2(start, dso);
 	if (map == NULL)
 		goto out;
 
@@ -855,62 +854,44 @@ static int machine__get_running_kernel_start(struct machine *machine,
 static int
 __machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
 {
-	int type;
+	struct kmap *kmap;
+	struct map *map;
 
 	/* In case of renewal the kernel map, destroy previous one */
 	machine__destroy_kernel_maps(machine);
 
-	for (type = 0; type < MAP__NR_TYPES; ++type) {
-		struct kmap *kmap;
-		struct map *map;
-
-		machine->vmlinux_maps[type] = map__new2(0, kernel, type);
-		if (machine->vmlinux_maps[type] == NULL)
-			return -1;
+	machine->vmlinux_map = map__new2(0, kernel);
+	if (machine->vmlinux_map == NULL)
+		return -1;
 
-		machine->vmlinux_maps[type]->map_ip =
-			machine->vmlinux_maps[type]->unmap_ip =
-				identity__map_ip;
-		map = __machine__kernel_map(machine, type);
-		kmap = map__kmap(map);
-		if (!kmap)
-			return -1;
+	machine->vmlinux_map->map_ip = machine->vmlinux_map->unmap_ip = identity__map_ip;
+	map = machine__kernel_map(machine);
+	kmap = map__kmap(map);
+	if (!kmap)
+		return -1;
 
-		kmap->kmaps = &machine->kmaps;
-		map_groups__insert(&machine->kmaps, map);
-	}
+	kmap->kmaps = &machine->kmaps;
+	map_groups__insert(&machine->kmaps, map);
 
 	return 0;
 }
 
 void machine__destroy_kernel_maps(struct machine *machine)
 {
-	int type;
-
-	for (type = 0; type < MAP__NR_TYPES; ++type) {
-		struct kmap *kmap;
-		struct map *map = __machine__kernel_map(machine, type);
-
-		if (map == NULL)
-			continue;
+	struct kmap *kmap;
+	struct map *map = machine__kernel_map(machine);
 
-		kmap = map__kmap(map);
-		map_groups__remove(&machine->kmaps, map);
-		if (kmap && kmap->ref_reloc_sym) {
-			/*
-			 * ref_reloc_sym is shared among all maps, so free just
-			 * on one of them.
-			 */
-			if (type == MAP__FUNCTION) {
-				zfree((char **)&kmap->ref_reloc_sym->name);
-				zfree(&kmap->ref_reloc_sym);
-			} else
-				kmap->ref_reloc_sym = NULL;
-		}
+	if (map == NULL)
+		return;
 
-		map__put(machine->vmlinux_maps[type]);
-		machine->vmlinux_maps[type] = NULL;
+	kmap = map__kmap(map);
+	map_groups__remove(&machine->kmaps, map);
+	if (kmap && kmap->ref_reloc_sym) {
+		zfree((char **)&kmap->ref_reloc_sym->name);
+		zfree(&kmap->ref_reloc_sym);
 	}
+
+	map__zput(machine->vmlinux_map);
 }
 
 int machines__create_guest_kernel_maps(struct machines *machines)
@@ -987,20 +968,19 @@ int machines__create_kernel_maps(struct machines *machines, pid_t pid)
 	return machine__create_kernel_maps(machine);
 }
 
-int __machine__load_kallsyms(struct machine *machine, const char *filename,
-			     enum map_type type)
+int machine__load_kallsyms(struct machine *machine, const char *filename)
 {
 	struct map *map = machine__kernel_map(machine);
 	int ret = __dso__load_kallsyms(map->dso, filename, map, true);
 
 	if (ret > 0) {
-		dso__set_loaded(map->dso, type);
+		dso__set_loaded(map->dso);
 		/*
 		 * Since /proc/kallsyms will have multiple sessions for the
 		 * kernel, with modules between them, fixup the end of all
 		 * sections.
 		 */
-		__map_groups__fixup_end(&machine->kmaps, type);
+		map_groups__fixup_end(&machine->kmaps);
 	}
 
 	return ret;
@@ -1012,7 +992,7 @@ int machine__load_vmlinux_path(struct machine *machine)
 	int ret = dso__load_vmlinux_path(map->dso, map);
 
 	if (ret > 0)
-		dso__set_loaded(map->dso, map->type);
+		dso__set_loaded(map->dso);
 
 	return ret;
 }
@@ -1204,19 +1184,14 @@ static int machine__create_modules(struct machine *machine)
 static void machine__set_kernel_mmap(struct machine *machine,
 				     u64 start, u64 end)
 {
-	int i;
-
-	for (i = 0; i < MAP__NR_TYPES; i++) {
-		machine->vmlinux_maps[i]->start = start;
-		machine->vmlinux_maps[i]->end   = end;
-
-		/*
-		 * Be a bit paranoid here, some perf.data file came with
-		 * a zero sized synthesized MMAP event for the kernel.
-		 */
-		if (start == 0 && end == 0)
-			machine->vmlinux_maps[i]->end = ~0ULL;
-	}
+	machine->vmlinux_map->start = start;
+	machine->vmlinux_map->end   = end;
+	/*
+	 * Be a bit paranoid here, some perf.data file came with
+	 * a zero sized synthesized MMAP event for the kernel.
+	 */
+	if (start == 0 && end == 0)
+		machine->vmlinux_map->end = ~0ULL;
 }
 
 int machine__create_kernel_maps(struct machine *machine)
@@ -1246,7 +1221,7 @@ int machine__create_kernel_maps(struct machine *machine)
 
 	if (!machine__get_running_kernel_start(machine, &name, &addr)) {
 		if (name &&
-		    maps__set_kallsyms_ref_reloc_sym(machine->vmlinux_maps, name, addr)) {
+		    map__set_kallsyms_ref_reloc_sym(machine->vmlinux_map, name, addr)) {
 			machine__destroy_kernel_maps(machine);
 			return -1;
 		}
@@ -1376,9 +1351,9 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 		 * time /proc/sys/kernel/kptr_restrict was non zero.
 		 */
 		if (event->mmap.pgoff != 0) {
-			maps__set_kallsyms_ref_reloc_sym(machine->vmlinux_maps,
-							 symbol_name,
-							 event->mmap.pgoff);
+			map__set_kallsyms_ref_reloc_sym(machine->vmlinux_map,
+							symbol_name,
+							event->mmap.pgoff);
 		}
 
 		if (machine__is_default_guest(machine)) {
@@ -1399,7 +1374,6 @@ int machine__process_mmap2_event(struct machine *machine,
 {
 	struct thread *thread;
 	struct map *map;
-	enum map_type type;
 	int ret = 0;
 
 	if (dump_trace)
@@ -1418,11 +1392,6 @@ int machine__process_mmap2_event(struct machine *machine,
 	if (thread == NULL)
 		goto out_problem;
 
-	if (event->header.misc & PERF_RECORD_MISC_MMAP_DATA)
-		type = MAP__VARIABLE;
-	else
-		type = MAP__FUNCTION;
-
 	map = map__new(machine, event->mmap2.start,
 			event->mmap2.len, event->mmap2.pgoff,
 			event->mmap2.maj,
@@ -1430,7 +1399,7 @@ int machine__process_mmap2_event(struct machine *machine,
 			event->mmap2.ino_generation,
 			event->mmap2.prot,
 			event->mmap2.flags,
-			event->mmap2.filename, type, thread);
+			event->mmap2.filename, thread);
 
 	if (map == NULL)
 		goto out_problem_map;
@@ -1457,7 +1426,6 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 {
 	struct thread *thread;
 	struct map *map;
-	enum map_type type;
 	u32 prot = 0;
 	int ret = 0;
 
@@ -1477,18 +1445,14 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 	if (thread == NULL)
 		goto out_problem;
 
-	if (event->header.misc & PERF_RECORD_MISC_MMAP_DATA)
-		type = MAP__VARIABLE;
-	else {
-		type = MAP__FUNCTION;
+	if (!(event->header.misc & PERF_RECORD_MISC_MMAP_DATA))
 		prot = PROT_EXEC;
-	}
 
 	map = map__new(machine, event->mmap.start,
 			event->mmap.len, event->mmap.pgoff,
 			0, 0, 0, 0, prot, 0,
 			event->mmap.filename,
-			type, thread);
+			thread);
 
 	if (map == NULL)
 		goto out_problem_map;

commit 0f476f2bbc1b46f76f9383dfe647858a888549aa
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Apr 26 11:30:50 2018 -0300

    perf machine: Set PROT_EXEC for executable PERF_RECORD_MMAP records
    
    The kernel doesn't fill the map 'prot' field for PERF_RECORD_MMAP
    records, and we will use that info to replace checking for
    MAP__VARIABLE, so store that when processing the
    PERF_RECORD_MISC_MMAP_DATA perf_event_attr.header.misc bit.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: https://lkml.kernel.org/n/tip-es3zz9r0q2qlssg4wh1w1d8p@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 3422ef67ec21..53bc2fb88be4 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -24,6 +24,7 @@
 
 #include "sane_ctype.h"
 #include <symbol/kallsyms.h>
+#include <linux/mman.h>
 
 static void __machine__remove_thread(struct machine *machine, struct thread *th, bool lock);
 
@@ -1457,6 +1458,7 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 	struct thread *thread;
 	struct map *map;
 	enum map_type type;
+	u32 prot = 0;
 	int ret = 0;
 
 	if (dump_trace)
@@ -1477,12 +1479,14 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 
 	if (event->header.misc & PERF_RECORD_MISC_MMAP_DATA)
 		type = MAP__VARIABLE;
-	else
+	else {
 		type = MAP__FUNCTION;
+		prot = PROT_EXEC;
+	}
 
 	map = map__new(machine, event->mmap.start,
 			event->mmap.len, event->mmap.pgoff,
-			0, 0, 0, 0, 0, 0,
+			0, 0, 0, 0, prot, 0,
 			event->mmap.filename,
 			type, thread);
 

commit 117d3c2474a24ab842af00972598c25abffee1e6
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Apr 25 18:16:53 2018 -0300

    perf thread: Ditch __thread__find_symbol()
    
    Simulate having all symbols in just one tree by searching the still
    existing two trees.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: https://lkml.kernel.org/n/tip-uss70e8tvzzbzs326330t83q@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index a00e82b83e0a..3422ef67ec21 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1677,15 +1677,7 @@ static void ip__resolve_data(struct thread *thread,
 
 	memset(&al, 0, sizeof(al));
 
-	__thread__find_symbol(thread, m, MAP__VARIABLE, addr, &al);
-	if (al.map == NULL) {
-		/*
-		 * some shared data regions have execute bit set which puts
-		 * their mapping in the MAP__FUNCTION type array.
-		 * Check there as a fallback option before dropping the sample.
-		 */
-		thread__find_symbol(thread, m, addr, &al);
-	}
+	thread__find_symbol(thread, m, addr, &al);
 
 	ams->addr = addr;
 	ams->al_addr = al.addr;

commit 128cde3379358d43c3cf2cb5ea00bac8bf9cf1cf
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Apr 25 18:04:45 2018 -0300

    perf machine: Use machine__find_kernel_function() instead of open coded version
    
    We have that equivalent, shorter helper, use it.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: https://lkml.kernel.org/n/tip-1hcgu3k7vxdy4vknqf3kbtzt@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 10364e829aba..a00e82b83e0a 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2367,7 +2367,7 @@ char *machine__resolve_kernel_addr(void *vmachine, unsigned long long *addrp, ch
 {
 	struct machine *machine = vmachine;
 	struct map *map;
-	struct symbol *sym = map_groups__find_symbol(&machine->kmaps, MAP__FUNCTION, *addrp, &map);
+	struct symbol *sym = machine__find_kernel_function(machine, *addrp, &map);
 
 	if (sym == NULL)
 		return NULL;

commit 26bd93316451256f92d18a331a3fd2f7e3b563ab
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Apr 25 17:58:03 2018 -0300

    perf thread: Remove addr_type arg from thread__find_cpumode_addr_location()
    
    All callers are for MAP__FUNCTION, so just ditch it and use
    thread__find_symbol(), that already ditched MAP__FUNCTION, i.e.
    internally uses it till we ditch it for good.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: https://lkml.kernel.org/n/tip-i0ocxs00b4a0tlrx31lyh2cs@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 0017c4a1fb97..10364e829aba 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1660,7 +1660,7 @@ static void ip__resolve_ams(struct thread *thread,
 	 * Thus, we have to try consecutively until we find a match
 	 * or else, the symbol is unknown
 	 */
-	thread__find_cpumode_addr_location(thread, MAP__FUNCTION, ip, &al);
+	thread__find_cpumode_addr_location(thread, ip, &al);
 
 	ams->addr = ip;
 	ams->al_addr = al.addr;
@@ -1754,8 +1754,7 @@ static int add_callchain_ip(struct thread *thread,
 	al.filtered = 0;
 	al.sym = NULL;
 	if (!cpumode) {
-		thread__find_cpumode_addr_location(thread, MAP__FUNCTION,
-						   ip, &al);
+		thread__find_cpumode_addr_location(thread, ip, &al);
 	} else {
 		if (ip >= PERF_CONTEXT_MAX) {
 			switch (ip) {

commit 1d1a2654fffe1e5a80479ed4b6202467d2d0db46
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Apr 25 12:18:11 2018 -0300

    perf machine: Remove needless map_type from machine__load_vmlinux_path()
    
    Since it uses machine__kernel_map() and this function always returns the
    MAP__FUNCTION map, it doesn't make sense to call it with MAP__VARIABLE.
    
    And also this is a step in the direction of nuking the MAP__{FUNCTION,VARIABLE}
    split.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: https://lkml.kernel.org/n/tip-0h3eof3kx3kq32ixg5fquf3p@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index d39432c7db86..0017c4a1fb97 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1005,13 +1005,13 @@ int __machine__load_kallsyms(struct machine *machine, const char *filename,
 	return ret;
 }
 
-int machine__load_vmlinux_path(struct machine *machine, enum map_type type)
+int machine__load_vmlinux_path(struct machine *machine)
 {
 	struct map *map = machine__kernel_map(machine);
 	int ret = dso__load_vmlinux_path(map->dso, map);
 
 	if (ret > 0)
-		dso__set_loaded(map->dso, type);
+		dso__set_loaded(map->dso, map->type);
 
 	return ret;
 }

commit 329f0adef39aedb8ac4be279c3394f32b53b1a88
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Apr 25 11:40:32 2018 -0300

    perf machine: Shorten machine__load_kallsyms() signature
    
    So far the only use is for MAP__FUNCTION, and since we're going to
    remove that split, remove the map_type argument in machine__load_kallsyms().
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: https://lkml.kernel.org/n/tip-5dhgh7x8g9hx5hpxlp3k08jp@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index fc71f2c69c8b..d39432c7db86 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -137,13 +137,11 @@ struct machine *machine__new_kallsyms(void)
 	struct machine *machine = machine__new_host();
 	/*
 	 * FIXME:
-	 * 1) MAP__FUNCTION will go away when we stop loading separate maps for
-	 *    functions and data objects.
-	 * 2) We should switch to machine__load_kallsyms(), i.e. not explicitely
+	 * 1) We should switch to machine__load_kallsyms(), i.e. not explicitely
 	 *    ask for not using the kcore parsing code, once this one is fixed
 	 *    to create a map per module.
 	 */
-	if (machine && machine__load_kallsyms(machine, "/proc/kallsyms", MAP__FUNCTION) <= 0) {
+	if (machine && machine__load_kallsyms(machine, "/proc/kallsyms") <= 0) {
 		machine__delete(machine);
 		machine = NULL;
 	}
@@ -988,7 +986,7 @@ int machines__create_kernel_maps(struct machines *machines, pid_t pid)
 	return machine__create_kernel_maps(machine);
 }
 
-int machine__load_kallsyms(struct machine *machine, const char *filename,
+int __machine__load_kallsyms(struct machine *machine, const char *filename,
 			     enum map_type type)
 {
 	struct map *map = machine__kernel_map(machine);

commit 83cf774b028fa67acfdd0176d54aa9387c2ad10d
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Apr 24 12:16:09 2018 -0300

    perf map: Shorten map_groups__find_by_name() signature
    
    Another step in the road to elliminate the MAP_{FUNCTION,VARIABLE}
    separation, reducing the exposure to these details in the tools using
    the symbol APIs.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: https://lkml.kernel.org/n/tip-8a1hvrqe3r5i0kw865u3uxwt@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index e354d94a68e8..fc71f2c69c8b 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -673,8 +673,7 @@ struct map *machine__findnew_module_map(struct machine *machine, u64 start,
 	if (kmod_path__parse_name(&m, filename))
 		return NULL;
 
-	map = map_groups__find_by_name(&machine->kmaps, MAP__FUNCTION,
-				       m.name);
+	map = map_groups__find_by_name(&machine->kmaps, m.name);
 	if (map) {
 		/*
 		 * If the map's dso is an offline module, give dso__load()
@@ -1055,10 +1054,9 @@ static bool is_kmod_dso(struct dso *dso)
 static int map_groups__set_module_path(struct map_groups *mg, const char *path,
 				       struct kmod_path *m)
 {
-	struct map *map;
 	char *long_name;
+	struct map *map = map_groups__find_by_name(mg, m->name);
 
-	map = map_groups__find_by_name(mg, MAP__FUNCTION, m->name);
 	if (map == NULL)
 		return 0;
 

commit 4546263d72e22ea84b49dafad26d8ca679d5e83d
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Apr 24 11:24:49 2018 -0300

    perf thread: Introduce thread__find_symbol()
    
    Out of thread__find_addr_location(..., MAP__FUNCTION, ...), idea here is to
    continue removing references to MAP__{FUNCTION,VARIABLE} ahead of
    getting both types of symbols in the same rbtree, as various places do
    two lookups, looking first at MAP__FUNCTION, then at MAP__VARIABLE.
    
    So thread__find_symbol() will eventually do just that, and 'struct
    symbol' will have the symbol type, for code that cares about that.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: https://lkml.kernel.org/n/tip-n7528en9e08yd3flzmb26tth@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 32d50492505d..e354d94a68e8 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1681,14 +1681,14 @@ static void ip__resolve_data(struct thread *thread,
 
 	memset(&al, 0, sizeof(al));
 
-	thread__find_addr_location(thread, m, MAP__VARIABLE, addr, &al);
+	__thread__find_symbol(thread, m, MAP__VARIABLE, addr, &al);
 	if (al.map == NULL) {
 		/*
 		 * some shared data regions have execute bit set which puts
 		 * their mapping in the MAP__FUNCTION type array.
 		 * Check there as a fallback option before dropping the sample.
 		 */
-		thread__find_addr_location(thread, m, MAP__FUNCTION, addr, &al);
+		thread__find_symbol(thread, m, addr, &al);
 	}
 
 	ams->addr = addr;
@@ -1784,8 +1784,7 @@ static int add_callchain_ip(struct thread *thread,
 			}
 			return 0;
 		}
-		thread__find_addr_location(thread, *cpumode, MAP__FUNCTION,
-					   ip, &al);
+		thread__find_symbol(thread, *cpumode, ip, &al);
 	}
 
 	if (al.sym != NULL) {

commit ee05d21791db6db954bbb7b79bb18d88b5f6b7ff
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Mon Feb 19 19:05:45 2018 +0900

    perf machine: Set main kernel end address properly
    
    map_groups__fixup_end() was called to set the end addresses of kernel
    and module maps.  But now since machine__create_modules() sets the end
    address of modules properly, the only remaining piece is the kernel map.
    
    We can set it with adjacent module's address directly instead of calling
    map_groups__fixup_end().  If there's no module after the kernel map, the
    end address will be ~0ULL.
    
    Since it also changes the start address of the kernel map, it needs to
    re-insert the map to the kmaps in order to keep a correct ordering.  Kim
    reported that it caused problems on ARM64.
    
    Reported-by: Kim Phillips <kim.phillips@arm.com>
    Tested-by: Kim Phillips <kim.phillips@arm.com>
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: kernel-team@lge.com
    Link: http://lkml.kernel.org/r/20180419235915.GA19067@sejong
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 2eca8478e24f..32d50492505d 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1019,13 +1019,6 @@ int machine__load_vmlinux_path(struct machine *machine, enum map_type type)
 	return ret;
 }
 
-static void map_groups__fixup_end(struct map_groups *mg)
-{
-	int i;
-	for (i = 0; i < MAP__NR_TYPES; ++i)
-		__map_groups__fixup_end(mg, i);
-}
-
 static char *get_kernel_version(const char *root_dir)
 {
 	char version[PATH_MAX];
@@ -1233,6 +1226,7 @@ int machine__create_kernel_maps(struct machine *machine)
 {
 	struct dso *kernel = machine__get_kernel(machine);
 	const char *name = NULL;
+	struct map *map;
 	u64 addr = 0;
 	int ret;
 
@@ -1259,13 +1253,25 @@ int machine__create_kernel_maps(struct machine *machine)
 			machine__destroy_kernel_maps(machine);
 			return -1;
 		}
-		machine__set_kernel_mmap(machine, addr, 0);
+
+		/* we have a real start address now, so re-order the kmaps */
+		map = machine__kernel_map(machine);
+
+		map__get(map);
+		map_groups__remove(&machine->kmaps, map);
+
+		/* assume it's the last in the kmaps */
+		machine__set_kernel_mmap(machine, addr, ~0ULL);
+
+		map_groups__insert(&machine->kmaps, map);
+		map__put(map);
 	}
 
-	/*
-	 * Now that we have all the maps created, just set the ->end of them:
-	 */
-	map_groups__fixup_end(&machine->kmaps);
+	/* update end address of the kernel map using adjacent module address */
+	map = map__next(machine__kernel_map(machine));
+	if (map)
+		machine__set_kernel_mmap(machine, addr, map->start);
+
 	return 0;
 }
 

commit c192524e6fe8a4bd18f2549f9556b81ed9e05a86
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Mon Mar 12 16:24:06 2018 +0100

    perf machine: Fix mmap name setup
    
    Leo reported broken -k option behavior. The reason is that we used
    symbol_conf.vmlinux_name as a source for mmap event name, but in fact
    it's a vmlinux path.
    
    Moving the symbol_conf.vmlinux_name check for both host and guest to the
    proper place and out of the machine__set_mmap_name function.
    
    Reported-by: Leo Yan <leo.yan@linaro.org>
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Tested-by: Leo Yan <leo.yan@linaro.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Fixes: commit ("8c7f1bb37b29 perf machine: Move kernel mmap name into struct machine")
    Link: http://lkml.kernel.org/r/20180312152406.10141-1-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 43fbbee409ec..2eca8478e24f 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -50,21 +50,13 @@ static void machine__threads_init(struct machine *machine)
 
 static int machine__set_mmap_name(struct machine *machine)
 {
-	if (machine__is_host(machine)) {
-		if (symbol_conf.vmlinux_name)
-			machine->mmap_name = strdup(symbol_conf.vmlinux_name);
-		else
-			machine->mmap_name = strdup("[kernel.kallsyms]");
-	} else if (machine__is_default_guest(machine)) {
-		if (symbol_conf.default_guest_vmlinux_name)
-			machine->mmap_name = strdup(symbol_conf.default_guest_vmlinux_name);
-		else
-			machine->mmap_name = strdup("[guest.kernel.kallsyms]");
-	} else {
-		if (asprintf(&machine->mmap_name, "[guest.kernel.kallsyms.%d]",
-			 machine->pid) < 0)
-			machine->mmap_name = NULL;
-	}
+	if (machine__is_host(machine))
+		machine->mmap_name = strdup("[kernel.kallsyms]");
+	else if (machine__is_default_guest(machine))
+		machine->mmap_name = strdup("[guest.kernel.kallsyms]");
+	else if (asprintf(&machine->mmap_name, "[guest.kernel.kallsyms.%d]",
+			  machine->pid) < 0)
+		machine->mmap_name = NULL;
 
 	return machine->mmap_name ? 0 : -ENOMEM;
 }
@@ -794,9 +786,15 @@ static struct dso *machine__get_kernel(struct machine *machine)
 	struct dso *kernel;
 
 	if (machine__is_host(machine)) {
+		if (symbol_conf.vmlinux_name)
+			vmlinux_name = symbol_conf.vmlinux_name;
+
 		kernel = machine__findnew_kernel(machine, vmlinux_name,
 						 "[kernel]", DSO_TYPE_KERNEL);
 	} else {
+		if (symbol_conf.default_guest_vmlinux_name)
+			vmlinux_name = symbol_conf.default_guest_vmlinux_name;
+
 		kernel = machine__findnew_kernel(machine, vmlinux_name,
 						 "[guest.kernel]",
 						 DSO_TYPE_GUEST_KERNEL);

commit 9f87498f1cb72958c6f8725eb93d2f7ef81fa11e
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Wed Mar 7 16:50:06 2018 +0100

    perf tools: Add refcnt into struct mem_info
    
    It's passed along several hists entries in --hierarchy mode, so it's
    better we keep track of it.
    
    The current fail I see is that it gets removed in hierarchy --mem-mode
    mode, where it's shared in the different hierarchies, but removed from
    the template hist entry, so the report crashes.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20180307155020.32613-6-jolsa@kernel.org
    [ Rename mem_info__aloc() to mem_info__new(), to fix the typo and use the convention for constructors ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 12b7427444a3..43fbbee409ec 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1697,7 +1697,7 @@ static void ip__resolve_data(struct thread *thread,
 struct mem_info *sample__resolve_mem(struct perf_sample *sample,
 				     struct addr_location *al)
 {
-	struct mem_info *mi = zalloc(sizeof(*mi));
+	struct mem_info *mi = mem_info__new();
 
 	if (!mi)
 		return NULL;

commit 1d12cec6ce99614297e10945d917fd8a62cd2b09
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Mon Feb 19 19:00:46 2018 +0900

    perf machine: Fix paranoid check in machine__set_kernel_mmap()
    
    The machine__set_kernel_mmap() is to setup addresses of the kernel map
    using external info.  But it has a check when the address is given from
    an incorrect input which should have the start and end address of 0
    (i.e. machine__process_kernel_mmap_event).
    
    But we also use the end address of 0 for a valid input so change it to
    check both start and end addresses.
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: kernel-team@lge.com
    Link: http://lkml.kernel.org/r/20180219101936.GD1583@sejong
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index fe27ef55cbb9..12b7427444a3 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1226,7 +1226,7 @@ static void machine__set_kernel_mmap(struct machine *machine,
 		 * Be a bit paranoid here, some perf.data file came with
 		 * a zero sized synthesized MMAP event for the kernel.
 		 */
-		if (machine->vmlinux_maps[i]->end == 0)
+		if (start == 0 && end == 0)
 			machine->vmlinux_maps[i]->end = ~0ULL;
 	}
 }

commit e8f3879f762ffe75a24fd354dd87f073214428fa
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Thu Feb 15 13:26:33 2018 +0100

    perf machine: Remove machine__load_kallsyms()
    
    The current machine__load_kallsyms() function has no caller, so replace
    it directly with __machine__load_kallsyms().  Also remove the no_kcore
    argument as it was always called with a 'true' value.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20180215122635.24029-8-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 2db8d7dd0f80..fe27ef55cbb9 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -151,7 +151,7 @@ struct machine *machine__new_kallsyms(void)
 	 *    ask for not using the kcore parsing code, once this one is fixed
 	 *    to create a map per module.
 	 */
-	if (machine && __machine__load_kallsyms(machine, "/proc/kallsyms", MAP__FUNCTION, true) <= 0) {
+	if (machine && machine__load_kallsyms(machine, "/proc/kallsyms", MAP__FUNCTION) <= 0) {
 		machine__delete(machine);
 		machine = NULL;
 	}
@@ -991,11 +991,11 @@ int machines__create_kernel_maps(struct machines *machines, pid_t pid)
 	return machine__create_kernel_maps(machine);
 }
 
-int __machine__load_kallsyms(struct machine *machine, const char *filename,
-			     enum map_type type, bool no_kcore)
+int machine__load_kallsyms(struct machine *machine, const char *filename,
+			     enum map_type type)
 {
 	struct map *map = machine__kernel_map(machine);
-	int ret = __dso__load_kallsyms(map->dso, filename, map, no_kcore);
+	int ret = __dso__load_kallsyms(map->dso, filename, map, true);
 
 	if (ret > 0) {
 		dso__set_loaded(map->dso, type);
@@ -1010,12 +1010,6 @@ int __machine__load_kallsyms(struct machine *machine, const char *filename,
 	return ret;
 }
 
-int machine__load_kallsyms(struct machine *machine, const char *filename,
-			   enum map_type type)
-{
-	return __machine__load_kallsyms(machine, filename, type, false);
-}
-
 int machine__load_vmlinux_path(struct machine *machine, enum map_type type)
 {
 	struct map *map = machine__kernel_map(machine);

commit 1fb87b8e9599932e1d8b11c3a1b03b4414aaf7ba
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Thu Feb 15 13:26:32 2018 +0100

    perf machine: Don't search for active kernel start in __machine__create_kernel_maps
    
    We should not search for the kernel start address in
    __machine__create_kernel_maps(), because it's being used in the 'report'
    code path, where we are interested in kernel MMAP data address (the one
    recorded via 'perf record', possibly on another machine, or an older or
    newer kernel on the same machine where analysis is being performed)
    instead of in current kernel address.
    
    The __machine__create_kernel_maps() function serves purely for creating
    the machines kernel maps and setting up the kmap group. The report code
    path then sets the address based on the data from kernel MMAP event in
    the machine__set_kernel_mmap() function.
    
    The kallsyms search address logic is used for test code, that calls
    machine__create_kernel_maps() to get current maps and calls
    machine__get_running_kernel_start() to get kernel starting address.
    
    Use machine__set_kernel_mmap() to set the kernel maps start address and
    moving map_groups__fixup_end to be call when all maps are in place.
    
    Also make __machine__create_kernel_maps static, because there's no
    external user.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20180215122635.24029-7-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 292e70c774bd..2db8d7dd0f80 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -856,13 +856,10 @@ static int machine__get_running_kernel_start(struct machine *machine,
 	return 0;
 }
 
-int __machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
+static int
+__machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
 {
 	int type;
-	u64 start = 0;
-
-	if (machine__get_running_kernel_start(machine, NULL, &start))
-		return -1;
 
 	/* In case of renewal the kernel map, destroy previous one */
 	machine__destroy_kernel_maps(machine);
@@ -871,7 +868,7 @@ int __machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
 		struct kmap *kmap;
 		struct map *map;
 
-		machine->vmlinux_maps[type] = map__new2(start, kernel, type);
+		machine->vmlinux_maps[type] = map__new2(0, kernel, type);
 		if (machine->vmlinux_maps[type] == NULL)
 			return -1;
 
@@ -1222,6 +1219,24 @@ static int machine__create_modules(struct machine *machine)
 	return 0;
 }
 
+static void machine__set_kernel_mmap(struct machine *machine,
+				     u64 start, u64 end)
+{
+	int i;
+
+	for (i = 0; i < MAP__NR_TYPES; i++) {
+		machine->vmlinux_maps[i]->start = start;
+		machine->vmlinux_maps[i]->end   = end;
+
+		/*
+		 * Be a bit paranoid here, some perf.data file came with
+		 * a zero sized synthesized MMAP event for the kernel.
+		 */
+		if (machine->vmlinux_maps[i]->end == 0)
+			machine->vmlinux_maps[i]->end = ~0ULL;
+	}
+}
+
 int machine__create_kernel_maps(struct machine *machine)
 {
 	struct dso *kernel = machine__get_kernel(machine);
@@ -1246,40 +1261,22 @@ int machine__create_kernel_maps(struct machine *machine)
 				 "continuing anyway...\n", machine->pid);
 	}
 
-	/*
-	 * Now that we have all the maps created, just set the ->end of them:
-	 */
-	map_groups__fixup_end(&machine->kmaps);
-
 	if (!machine__get_running_kernel_start(machine, &name, &addr)) {
 		if (name &&
 		    maps__set_kallsyms_ref_reloc_sym(machine->vmlinux_maps, name, addr)) {
 			machine__destroy_kernel_maps(machine);
 			return -1;
 		}
+		machine__set_kernel_mmap(machine, addr, 0);
 	}
 
+	/*
+	 * Now that we have all the maps created, just set the ->end of them:
+	 */
+	map_groups__fixup_end(&machine->kmaps);
 	return 0;
 }
 
-static void machine__set_kernel_mmap(struct machine *machine,
-				     u64 start, u64 end)
-{
-	int i;
-
-	for (i = 0; i < MAP__NR_TYPES; i++) {
-		machine->vmlinux_maps[i]->start = start;
-		machine->vmlinux_maps[i]->end   = end;
-
-		/*
-		 * Be a bit paranoid here, some perf.data file came with
-		 * a zero sized synthesized MMAP event for the kernel.
-		 */
-		if (machine->vmlinux_maps[i]->end == 0)
-			machine->vmlinux_maps[i]->end = ~0ULL;
-	}
-}
-
 static bool machine__uses_kcore(struct machine *machine)
 {
 	struct dso *dso;

commit 05db6ff73d805ecc70947c9eee2ed9948d0be52b
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Thu Feb 15 13:26:31 2018 +0100

    perf machine: Generalize machine__set_kernel_mmap()
    
    So it could be called without event object, just with start and end
    values. It will be used in following patch.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20180215122635.24029-6-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index b1f1961b13f4..292e70c774bd 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1262,15 +1262,15 @@ int machine__create_kernel_maps(struct machine *machine)
 	return 0;
 }
 
-static void machine__set_kernel_mmap_len(struct machine *machine,
-					 union perf_event *event)
+static void machine__set_kernel_mmap(struct machine *machine,
+				     u64 start, u64 end)
 {
 	int i;
 
 	for (i = 0; i < MAP__NR_TYPES; i++) {
-		machine->vmlinux_maps[i]->start = event->mmap.start;
-		machine->vmlinux_maps[i]->end   = (event->mmap.start +
-						   event->mmap.len);
+		machine->vmlinux_maps[i]->start = start;
+		machine->vmlinux_maps[i]->end   = end;
+
 		/*
 		 * Be a bit paranoid here, some perf.data file came with
 		 * a zero sized synthesized MMAP event for the kernel.
@@ -1375,7 +1375,8 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 		if (strstr(kernel->long_name, "vmlinux"))
 			dso__set_short_name(kernel, "[kernel.vmlinux]", false);
 
-		machine__set_kernel_mmap_len(machine, event);
+		machine__set_kernel_mmap(machine, event->mmap.start,
+					 event->mmap.start + event->mmap.len);
 
 		/*
 		 * Avoid using a zero address (kptr_restrict) for the ref reloc

commit 8c7f1bb37b29f140e08175132f3abb4d5ad229fc
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Thu Feb 15 13:26:30 2018 +0100

    perf machine: Move kernel mmap name into struct machine
    
    It simplifies and centralizes the code. The kernel mmap name is set for
    machine type, which we know from the beginning, so there's no reason to
    generate it every time we need it.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20180215122635.24029-5-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index c976384f9022..b1f1961b13f4 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -48,6 +48,27 @@ static void machine__threads_init(struct machine *machine)
 	}
 }
 
+static int machine__set_mmap_name(struct machine *machine)
+{
+	if (machine__is_host(machine)) {
+		if (symbol_conf.vmlinux_name)
+			machine->mmap_name = strdup(symbol_conf.vmlinux_name);
+		else
+			machine->mmap_name = strdup("[kernel.kallsyms]");
+	} else if (machine__is_default_guest(machine)) {
+		if (symbol_conf.default_guest_vmlinux_name)
+			machine->mmap_name = strdup(symbol_conf.default_guest_vmlinux_name);
+		else
+			machine->mmap_name = strdup("[guest.kernel.kallsyms]");
+	} else {
+		if (asprintf(&machine->mmap_name, "[guest.kernel.kallsyms.%d]",
+			 machine->pid) < 0)
+			machine->mmap_name = NULL;
+	}
+
+	return machine->mmap_name ? 0 : -ENOMEM;
+}
+
 int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 {
 	int err = -ENOMEM;
@@ -75,6 +96,9 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 	if (machine->root_dir == NULL)
 		return -ENOMEM;
 
+	if (machine__set_mmap_name(machine))
+		goto out;
+
 	if (pid != HOST_KERNEL_ID) {
 		struct thread *thread = machine__findnew_thread(machine, -1,
 								pid);
@@ -92,8 +116,10 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 	err = 0;
 
 out:
-	if (err)
+	if (err) {
 		zfree(&machine->root_dir);
+		zfree(&machine->mmap_name);
+	}
 	return 0;
 }
 
@@ -186,6 +212,7 @@ void machine__exit(struct machine *machine)
 	dsos__exit(&machine->dsos);
 	machine__exit_vdso(machine);
 	zfree(&machine->root_dir);
+	zfree(&machine->mmap_name);
 	zfree(&machine->current_tid);
 
 	for (i = 0; i < THREADS__TABLE_SIZE; i++) {
@@ -328,20 +355,6 @@ void machines__process_guests(struct machines *machines,
 	}
 }
 
-char *machine__mmap_name(struct machine *machine, char *bf, size_t size)
-{
-	if (machine__is_host(machine))
-		snprintf(bf, size, "[%s]", "kernel.kallsyms");
-	else if (machine__is_default_guest(machine))
-		snprintf(bf, size, "[%s]", "guest.kernel.kallsyms");
-	else {
-		snprintf(bf, size, "[%s.%d]", "guest.kernel.kallsyms",
-			 machine->pid);
-	}
-
-	return bf;
-}
-
 void machines__set_id_hdr_size(struct machines *machines, u16 id_hdr_size)
 {
 	struct rb_node *node;
@@ -777,25 +790,13 @@ size_t machine__fprintf(struct machine *machine, FILE *fp)
 
 static struct dso *machine__get_kernel(struct machine *machine)
 {
-	const char *vmlinux_name = NULL;
+	const char *vmlinux_name = machine->mmap_name;
 	struct dso *kernel;
 
 	if (machine__is_host(machine)) {
-		vmlinux_name = symbol_conf.vmlinux_name;
-		if (!vmlinux_name)
-			vmlinux_name = DSO__NAME_KALLSYMS;
-
 		kernel = machine__findnew_kernel(machine, vmlinux_name,
 						 "[kernel]", DSO_TYPE_KERNEL);
 	} else {
-		char bf[PATH_MAX];
-
-		if (machine__is_default_guest(machine))
-			vmlinux_name = symbol_conf.default_guest_vmlinux_name;
-		if (!vmlinux_name)
-			vmlinux_name = machine__mmap_name(machine, bf,
-							  sizeof(bf));
-
 		kernel = machine__findnew_kernel(machine, vmlinux_name,
 						 "[guest.kernel]",
 						 DSO_TYPE_GUEST_KERNEL);
@@ -1295,7 +1296,6 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 					      union perf_event *event)
 {
 	struct map *map;
-	char kmmap_prefix[PATH_MAX];
 	enum dso_kernel_type kernel_type;
 	bool is_kernel_mmap;
 
@@ -1303,15 +1303,14 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 	if (machine__uses_kcore(machine))
 		return 0;
 
-	machine__mmap_name(machine, kmmap_prefix, sizeof(kmmap_prefix));
 	if (machine__is_host(machine))
 		kernel_type = DSO_TYPE_KERNEL;
 	else
 		kernel_type = DSO_TYPE_GUEST_KERNEL;
 
 	is_kernel_mmap = memcmp(event->mmap.filename,
-				kmmap_prefix,
-				strlen(kmmap_prefix) - 1) == 0;
+				machine->mmap_name,
+				strlen(machine->mmap_name) - 1) == 0;
 	if (event->mmap.filename[0] == '/' ||
 	    (!is_kernel_mmap && event->mmap.filename[0] == '[')) {
 		map = machine__findnew_module_map(machine, event->mmap.start,
@@ -1322,7 +1321,7 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 		map->end = map->start + event->mmap.len;
 	} else if (is_kernel_mmap) {
 		const char *symbol_name = (event->mmap.filename +
-				strlen(kmmap_prefix));
+				strlen(machine->mmap_name));
 		/*
 		 * Should be there already, from the build-id table in
 		 * the header.
@@ -1363,7 +1362,7 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 		up_read(&machine->dsos.lock);
 
 		if (kernel == NULL)
-			kernel = machine__findnew_dso(machine, kmmap_prefix);
+			kernel = machine__findnew_dso(machine, machine->mmap_name);
 		if (kernel == NULL)
 			goto out_problem;
 

commit 81f981d7ec43ed93901c12b6521d39b06f1ed3d3
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Thu Feb 15 13:26:29 2018 +0100

    perf machine: Free root_dir in machine__init() error path
    
    Free root_dir in machine__init() error path.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20180215122635.24029-4-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index b05a67464c03..c976384f9022 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -50,6 +50,8 @@ static void machine__threads_init(struct machine *machine)
 
 int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 {
+	int err = -ENOMEM;
+
 	memset(machine, 0, sizeof(*machine));
 	map_groups__init(&machine->kmaps, machine);
 	RB_CLEAR_NODE(&machine->rb_node);
@@ -79,7 +81,7 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 		char comm[64];
 
 		if (thread == NULL)
-			return -ENOMEM;
+			goto out;
 
 		snprintf(comm, sizeof(comm), "[guest/%d]", pid);
 		thread__set_comm(thread, comm, 0);
@@ -87,7 +89,11 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 	}
 
 	machine->current_tid = NULL;
+	err = 0;
 
+out:
+	if (err)
+		zfree(&machine->root_dir);
 	return 0;
 }
 

commit 935f5a9d4500020879858c9224c98dfabf16101d
Author: Jin Yao <yao.jin@linux.intel.com>
Date:   Sat Dec 30 00:26:52 2017 +0800

    perf report: Fix a wrong offset issue when using /proc/kcore
    
    When a valid vmlinux is not found, 'perf report' falls back to look at
    /proc/kcore. In this case, it will report the impossible large offset.
    
    For example:
    
      # perf record -b -e cycles:k find /etc/ > /dev/null
      # perf report --stdio --branch-history
    
        22.77%  _vm_normal_page+18446603336221188162
                |
                ---page_remove_rmap +18446603336221188324
                   page_remove_rmap +18446603336221188487 (cycles:5)
                   unlock_page_memcg +18446603336221188096
                   page_remove_rmap +18446603336221188327 (cycles:1)
    
    The issue is the value which is passed to parameter 'addr' in
    __get_srcline() is the objdump address. It's not correct if we calculate
    the offset by using 'addr - sym->start'.
    
    This patch creates a new parameter 'ip' in __get_srcline(). It is not
    converted to objdump address.
    
    With this patch, the perf report output is:
    
        22.77%  _vm_normal_page+66
                |
                ---page_remove_rmap +228
                   page_remove_rmap +391 (cycles:5)
                   unlock_page_memcg +0
                   page_remove_rmap +231 (cycles:1)
                   page_remove_rmap +236
    
    Committer testing:
    
    Make sure you get any valid vmlinux out of the way, using '-v' on the
    'perf report' case and deleting it from places where perf searches them,
    like your kernel build dir and the build-id cache, in ~/.debug/.
    
    Reported-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: Jin Yao <yao.jin@linux.intel.com>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Kan Liang <kan.liang@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1514564812-17344-1-git-send-email-yao.jin@linux.intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 64d255f6a537..b05a67464c03 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1726,7 +1726,7 @@ static char *callchain_srcline(struct map *map, struct symbol *sym, u64 ip)
 		bool show_addr = callchain_param.key == CCKEY_ADDRESS;
 
 		srcline = get_srcline(map->dso, map__rip_2objdump(map, ip),
-				      sym, show_sym, show_addr);
+				      sym, show_sym, show_addr, ip);
 		srcline__tree_insert(&map->dso->srclines, ip, srcline);
 	}
 

commit 914eb9ca51117776d83e6761a1c555fb76f0ded2
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Sun Aug 6 16:39:39 2017 +0200

    perf callchain: Reset cursor arg instead of callchain_cursor
    
    We already pass cursor into thread__resolve_callchain function, so
    there's no point in resetting the global instance.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-puk015qvuppao9m1xtdy9v7j@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 270f3223c6df..64d255f6a537 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2204,7 +2204,7 @@ int thread__resolve_callchain(struct thread *thread,
 {
 	int ret = 0;
 
-	callchain_cursor_reset(&callchain_cursor);
+	callchain_cursor_reset(cursor);
 
 	if (callchain_param.order == ORDER_CALLEE) {
 		ret = thread__resolve_callchain_sample(thread, cursor,

commit 19993b82a571893e661afd90f1d77fa698785cee
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Nov 13 16:06:29 2017 -0300

    perf machine: Guard against NULL in machine__exit()
    
    A recent fix for 'perf trace' introduced a bug where
    machine__exit(trace->host) could be called while trace->host was still
    NULL, so make this more robust by guarding against NULL, just like
    free() does.
    
    The problem happens, for instance, when !root users try to run 'perf
    trace':
    
      [acme@jouet linux]$ trace
      Error:        No permissions to read /sys/kernel/debug/tracing/events/raw_syscalls/sys_(enter|exit)
      Hint: Try 'sudo mount -o remount,mode=755 /sys/kernel/debug/tracing'
    
      perf: Segmentation fault
      Obtained 7 stack frames.
      [0x4f1b2e]
      /lib64/libc.so.6(+0x3671f) [0x7f43a1dd971f]
      [0x4f3fec]
      [0x47468b]
      [0x42a2db]
      /lib64/libc.so.6(__libc_start_main+0xe9) [0x7f43a1dc3509]
      [0x42a6c9]
      Segmentation fault (core dumped)
      [acme@jouet linux]$
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andrei Vagin <avagin@openvz.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Vasily Averin <vvs@virtuozzo.com>
    Cc: Wang Nan <wangnan0@huawei.com>
    Fixes: 33974a414ce2 ("perf trace: Call machine__exit() at exit")
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 6a8d03c3d9b7..270f3223c6df 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -172,6 +172,9 @@ void machine__exit(struct machine *machine)
 {
 	int i;
 
+	if (machine == NULL)
+		return;
+
 	machine__destroy_kernel_maps(machine);
 	map_groups__exit(&machine->kmaps);
 	dsos__exit(&machine->dsos);

commit 15bcdc9477b03eb035052412c3a087e11e855e76
Merge: 340b5319c98e e4880bc5dfb1
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Nov 7 10:30:18 2017 +0100

    Merge branch 'linus' into perf/core, to fix conflicts
    
    Conflicts:
            tools/perf/arch/arm/annotate/instructions.c
            tools/perf/arch/arm64/annotate/instructions.c
            tools/perf/arch/powerpc/annotate/instructions.c
            tools/perf/arch/s390/annotate/instructions.c
            tools/perf/arch/x86/tests/intel-cqm.c
            tools/perf/ui/tui/progress.c
            tools/perf/util/zlib.c
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index df709363ef69..bd5d5b5e2218 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 #include <dirent.h>
 #include <errno.h>
 #include <inttypes.h>

commit 21ac9d547fdde79c1e8692587d9044fde549214b
Author: Milian Wolff <milian.wolff@kdab.com>
Date:   Thu Oct 19 13:38:34 2017 +0200

    perf report: Cache srclines for callchain nodes
    
    On one hand this ensures that the memory is properly freed when the DSO
    gets freed. On the other hand this significantly speeds up the
    processing of the callchain nodes when lots of srclines are requested.
    For one of my data files e.g.:
    
    Before:
    
     Performance counter stats for 'perf report -s srcline -g srcline --stdio':
    
          52496.495043      task-clock (msec)         #    0.999 CPUs utilized
                   634      context-switches          #    0.012 K/sec
                     2      cpu-migrations            #    0.000 K/sec
               191,561      page-faults               #    0.004 M/sec
       165,074,498,235      cycles                    #    3.144 GHz
       334,170,832,408      instructions              #    2.02  insn per cycle
        90,220,029,745      branches                  # 1718.591 M/sec
           654,525,177      branch-misses             #    0.73% of all branches
    
          52.533273822 seconds time elapsedProcessed 236605 events and lost 40 chunks!
    
    After:
    
     Performance counter stats for 'perf report -s srcline -g srcline --stdio':
    
          22606.323706      task-clock (msec)         #    1.000 CPUs utilized
                    31      context-switches          #    0.001 K/sec
                     0      cpu-migrations            #    0.000 K/sec
               185,471      page-faults               #    0.008 M/sec
        71,188,113,681      cycles                    #    3.149 GHz
       133,204,943,083      instructions              #    1.87  insn per cycle
        34,886,384,979      branches                  # 1543.214 M/sec
           278,214,495      branch-misses             #    0.80% of all branches
    
          22.609857253 seconds time elapsed
    
    Note that the difference is only this large when `--inline` is not
    passed. In such situations, we would use the inliner cache and thus do
    not run this code path that often.
    
    I think that this cache should actually be used in other places, too.
    When looking at the valgrind leak report for perf report, we see tons of
    srclines being leaked, most notably from calls to
    hist_entry__get_srcline. The problem is that get_srcline has many
    different formatting options (show_sym, show_addr, potentially even
    unwind_inlines when calling __get_srcline directly). As such, the
    srcline cannot easily be cached for all calls, or we'd have to add
    caches for all formatting combinations (6 so far). An alternative would
    be to remove the formatting options and handle that on a different level
    - i.e. print the sym/addr on demand wherever we actually output
    something. And the unwind_inlines could be moved into a separate
    function that does not return the srcline.
    
    Signed-off-by: Milian Wolff <milian.wolff@kdab.com>
    Reviewed-by: Andi Kleen <ak@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jin Yao <yao.jin@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20171019113836.5548-4-milian.wolff@kdab.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 177c1d4088f8..94d8f1ccedd9 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1711,11 +1711,22 @@ struct mem_info *sample__resolve_mem(struct perf_sample *sample,
 
 static char *callchain_srcline(struct map *map, struct symbol *sym, u64 ip)
 {
+	char *srcline = NULL;
+
 	if (!map || callchain_param.key == CCKEY_FUNCTION)
-		return NULL;
+		return srcline;
+
+	srcline = srcline__tree_find(&map->dso->srclines, ip);
+	if (!srcline) {
+		bool show_sym = false;
+		bool show_addr = callchain_param.key == CCKEY_ADDRESS;
+
+		srcline = get_srcline(map->dso, map__rip_2objdump(map, ip),
+				      sym, show_sym, show_addr);
+		srcline__tree_insert(&map->dso->srclines, ip, srcline);
+	}
 
-	return get_srcline(map->dso, map__rip_2objdump(map, ip),
-			   sym, false, callchain_param.key == CCKEY_ADDRESS);
+	return srcline;
 }
 
 struct iterations {

commit b38775cf7678d7715b35dded3dcfab66e244baae
Author: Milian Wolff <milian.wolff@kdab.com>
Date:   Thu Oct 19 13:38:33 2017 +0200

    perf report: Cache failed lookups of inlined frames
    
    When no inlined frames could be found for a given address, we did not
    store this information anywhere. That means we potentially do the costly
    inliner lookup repeatedly for cases where we know it can never succeed.
    
    This patch makes dso__parse_addr_inlines always return a valid
    inline_node. It will be empty when no inliners are found. This enables
    us to cache the empty list in the DSO, thereby improving the performance
    when many addresses fail to find the inliners.
    
    For my trivial example, the performance impact is already quite
    significant:
    
    Before:
    
    ~~~~~
     Performance counter stats for 'perf report --stdio --inline -g srcline -s srcline' (5 runs):
    
            594.804032      task-clock (msec)         #    0.998 CPUs utilized            ( +-  0.07% )
                    53      context-switches          #    0.089 K/sec                    ( +-  4.09% )
                     0      cpu-migrations            #    0.000 K/sec                    ( +-100.00% )
                 5,687      page-faults               #    0.010 M/sec                    ( +-  0.02% )
         2,300,918,213      cycles                    #    3.868 GHz                      ( +-  0.09% )
         4,395,839,080      instructions              #    1.91  insn per cycle           ( +-  0.00% )
           939,177,205      branches                  # 1578.969 M/sec                    ( +-  0.00% )
            11,824,633      branch-misses             #    1.26% of all branches          ( +-  0.10% )
    
           0.596246531 seconds time elapsed                                          ( +-  0.07% )
    ~~~~~
    
    After:
    
    ~~~~~
     Performance counter stats for 'perf report --stdio --inline -g srcline -s srcline' (5 runs):
    
            113.111405      task-clock (msec)         #    0.990 CPUs utilized            ( +-  0.89% )
                    29      context-switches          #    0.255 K/sec                    ( +- 54.25% )
                     0      cpu-migrations            #    0.000 K/sec
                 5,380      page-faults               #    0.048 M/sec                    ( +-  0.01% )
           432,378,779      cycles                    #    3.823 GHz                      ( +-  0.75% )
           670,057,633      instructions              #    1.55  insn per cycle           ( +-  0.01% )
           141,001,247      branches                  # 1246.570 M/sec                    ( +-  0.01% )
             2,346,845      branch-misses             #    1.66% of all branches          ( +-  0.19% )
    
           0.114222393 seconds time elapsed                                          ( +-  1.19% )
    ~~~~~
    
    Signed-off-by: Milian Wolff <milian.wolff@kdab.com>
    Reviewed-by: Andi Kleen <ak@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jin Yao <yao.jin@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20171019113836.5548-3-milian.wolff@kdab.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 3d049cb313ac..177c1d4088f8 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2115,9 +2115,10 @@ static int append_inlines(struct callchain_cursor *cursor,
 	struct inline_node *inline_node;
 	struct inline_list *ilist;
 	u64 addr;
+	int ret = 1;
 
 	if (!symbol_conf.inline_name || !map || !sym)
-		return 1;
+		return ret;
 
 	addr = map__rip_2objdump(map, ip);
 
@@ -2125,22 +2126,20 @@ static int append_inlines(struct callchain_cursor *cursor,
 	if (!inline_node) {
 		inline_node = dso__parse_addr_inlines(map->dso, addr, sym);
 		if (!inline_node)
-			return 1;
-
+			return ret;
 		inlines__tree_insert(&map->dso->inlined_nodes, inline_node);
 	}
 
 	list_for_each_entry(ilist, &inline_node->val, list) {
-		int ret = callchain_cursor_append(cursor, ip, map,
-						  ilist->symbol, false,
-						  NULL, 0, 0, 0,
-						  ilist->srcline);
+		ret = callchain_cursor_append(cursor, ip, map,
+					      ilist->symbol, false,
+					      NULL, 0, 0, 0, ilist->srcline);
 
 		if (ret != 0)
 			return ret;
 	}
 
-	return 0;
+	return ret;
 }
 
 static int unwind_entry(struct unwind_entry *entry, void *arg)

commit 11ea2515f32e783b9a7984c148e742c377383915
Author: Milian Wolff <milian.wolff@kdab.com>
Date:   Mon Oct 9 22:32:59 2017 +0200

    perf callchain: Create real callchain entries for inlined frames
    
    The inline_node structs are maintained by the new dso->inlines tree.
    This in turn keeps ownership of the fake symbols and srcline string
    representing an inline frame.
    
    This tree is sorted by address to allow quick lookups. All other entries
    of the symbol beside the function name are unused for inline frames. The
    advantage of this approach is that all existing users of the callchain
    API can now transparently display inlined frames without having to patch
    their code.
    
    Signed-off-by: Milian Wolff <milian.wolff@kdab.com>
    Reviewed-by: Jiri Olsa <jolsa@redhat.com>
    Reviewed-by: Namhyung Kim <namhyung@kernel.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Yao Jin <yao.jin@linux.intel.com>
    Link: http://lkml.kernel.org/r/20171009203310.17362-6-milian.wolff@kdab.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index a37e1c056415..3d049cb313ac 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2109,6 +2109,40 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	return 0;
 }
 
+static int append_inlines(struct callchain_cursor *cursor,
+			  struct map *map, struct symbol *sym, u64 ip)
+{
+	struct inline_node *inline_node;
+	struct inline_list *ilist;
+	u64 addr;
+
+	if (!symbol_conf.inline_name || !map || !sym)
+		return 1;
+
+	addr = map__rip_2objdump(map, ip);
+
+	inline_node = inlines__tree_find(&map->dso->inlined_nodes, addr);
+	if (!inline_node) {
+		inline_node = dso__parse_addr_inlines(map->dso, addr, sym);
+		if (!inline_node)
+			return 1;
+
+		inlines__tree_insert(&map->dso->inlined_nodes, inline_node);
+	}
+
+	list_for_each_entry(ilist, &inline_node->val, list) {
+		int ret = callchain_cursor_append(cursor, ip, map,
+						  ilist->symbol, false,
+						  NULL, 0, 0, 0,
+						  ilist->srcline);
+
+		if (ret != 0)
+			return ret;
+	}
+
+	return 0;
+}
+
 static int unwind_entry(struct unwind_entry *entry, void *arg)
 {
 	struct callchain_cursor *cursor = arg;
@@ -2117,6 +2151,9 @@ static int unwind_entry(struct unwind_entry *entry, void *arg)
 	if (symbol_conf.hide_unresolved && entry->sym == NULL)
 		return 0;
 
+	if (append_inlines(cursor, entry->map, entry->sym, entry->ip) == 0)
+		return 0;
+
 	srcline = callchain_srcline(entry->map, entry->sym, entry->ip);
 	return callchain_cursor_append(cursor, entry->ip,
 				       entry->map, entry->sym,

commit 40a342cda2cd9bc8f7bf81c5ce1a141584760757
Author: Milian Wolff <milian.wolff@kdab.com>
Date:   Mon Oct 9 22:32:56 2017 +0200

    perf callchain: Store srcline in callchain_cursor_node
    
    This is mostly a preparation to enable the creation of full callchain
    nodes for inline frames. Such frames will reference the IP of the
    non-inlined frame, but hold the symbol and srcline for an inlined
    location. As such, we won't be able to query the srcline on-demand based
    on the IP alone. Instead, we will leverage the functionality provided by
    this patch here, and store the srcline for the inlined nodes in the new
    srcline member of callchain_cursor_node.
    
    Note that this patch on its own leaks the srcline, as there is no
    free_callchain_cursor_node or similar. A future patch will add caching
    of the srcline and handle deletion properly.
    
    Signed-off-by: Milian Wolff <milian.wolff@kdab.com>
    Reviewed-by: Jiri Olsa <jolsa@redhat.com>
    Reviewed-by: Namhyung Kim <namhyung@kernel.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Yao Jin <yao.jin@linux.intel.com>
    Link: http://lkml.kernel.org/r/20171009203310.17362-3-milian.wolff@kdab.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 7c3aa479201a..a37e1c056415 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1709,6 +1709,15 @@ struct mem_info *sample__resolve_mem(struct perf_sample *sample,
 	return mi;
 }
 
+static char *callchain_srcline(struct map *map, struct symbol *sym, u64 ip)
+{
+	if (!map || callchain_param.key == CCKEY_FUNCTION)
+		return NULL;
+
+	return get_srcline(map->dso, map__rip_2objdump(map, ip),
+			   sym, false, callchain_param.key == CCKEY_ADDRESS);
+}
+
 struct iterations {
 	int nr_loop_iter;
 	u64 cycles;
@@ -1728,6 +1737,7 @@ static int add_callchain_ip(struct thread *thread,
 	struct addr_location al;
 	int nr_loop_iter = 0;
 	u64 iter_cycles = 0;
+	const char *srcline = NULL;
 
 	al.filtered = 0;
 	al.sym = NULL;
@@ -1783,9 +1793,10 @@ static int add_callchain_ip(struct thread *thread,
 		iter_cycles = iter->cycles;
 	}
 
+	srcline = callchain_srcline(al.map, al.sym, al.addr);
 	return callchain_cursor_append(cursor, al.addr, al.map, al.sym,
 				       branch, flags, nr_loop_iter,
-				       iter_cycles, branch_from);
+				       iter_cycles, branch_from, srcline);
 }
 
 struct branch_info *sample__resolve_bstack(struct perf_sample *sample,
@@ -2101,12 +2112,15 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 static int unwind_entry(struct unwind_entry *entry, void *arg)
 {
 	struct callchain_cursor *cursor = arg;
+	const char *srcline = NULL;
 
 	if (symbol_conf.hide_unresolved && entry->sym == NULL)
 		return 0;
+
+	srcline = callchain_srcline(entry->map, entry->sym, entry->ip);
 	return callchain_cursor_append(cursor, entry->ip,
 				       entry->map, entry->sym,
-				       false, NULL, 0, 0, 0);
+				       false, NULL, 0, 0, 0, srcline);
 }
 
 static int thread__resolve_callchain_unwind(struct thread *thread,

commit 340b47f510bbe55a76b7309107276f02ea11f117
Author: Kan Liang <kan.liang@intel.com>
Date:   Fri Sep 29 07:47:54 2017 -0700

    perf top: Implement multithreading for perf_event__synthesize_threads
    
    The proc files which is sorted with alphabetical order are evenly
    assigned to several synthesize threads to be processed in parallel.
    
    For 'perf top', the threads number hard code to online CPU number. The
    following patch will introduce an option to set it.
    
    For other perf tools, the thread number is 1. Because the process
    function is not ready for multithreading, e.g.
    process_synthesized_event.
    
    This patch series only support event synthesize multithreading for 'perf
    top'. For other tools, it can be done separately later.
    
    With multithread applied, the total processing time can get up to 1.56x
    speedup on Knights Mill for 'perf top'.
    
    For specific single event processing, the processing time could increase
    because of the lock contention. So proc_map_timeout may need to be
    increased. Otherwise some proc maps will be truncated.
    
    Based on my test, increasing the proc_map_timeout has small impact
    on the total processing time. The total processing time still get 1.49x
    speedup on Knights Mill after increasing the proc_map_timeout.
    The patch itself doesn't increase the proc_map_timeout.
    
    Doesn't need to implement multithreading for per task monitoring,
    perf_event__synthesize_thread_map. It doesn't have performance issue.
    
    Committer testing:
    
      # getconf _NPROCESSORS_ONLN
      4
      # perf trace --no-inherit -e clone -o /tmp/output perf top
      # tail -4 /tmp/bla
         0.124 ( 0.041 ms): clone(flags: VM|FS|FILES|SIGHAND|THREAD|SYSVSEM|SETTLS|PARENT_SETTID|CHILD_CLEARTID, child_stack: 0x7fc3eb3a8f30, parent_tidptr: 0x7fc3eb3a99d0, child_tidptr: 0x7fc3eb3a99d0, tls: 0x7fc3eb3a9700) = 9548 (perf)
         0.246 ( 0.023 ms): clone(flags: VM|FS|FILES|SIGHAND|THREAD|SYSVSEM|SETTLS|PARENT_SETTID|CHILD_CLEARTID, child_stack: 0x7fc3eaba7f30, parent_tidptr: 0x7fc3eaba89d0, child_tidptr: 0x7fc3eaba89d0, tls: 0x7fc3eaba8700) = 9549 (perf)
         0.286 ( 0.019 ms): clone(flags: VM|FS|FILES|SIGHAND|THREAD|SYSVSEM|SETTLS|PARENT_SETTID|CHILD_CLEARTID, child_stack: 0x7fc3ea3a6f30, parent_tidptr: 0x7fc3ea3a79d0, child_tidptr: 0x7fc3ea3a79d0, tls: 0x7fc3ea3a7700) = 9550 (perf)
       246.540 ( 0.047 ms): clone(flags: VM|FS|FILES|SIGHAND|THREAD|SYSVSEM|SETTLS|PARENT_SETTID|CHILD_CLEARTID, child_stack: 0x7fc3ea3a6f30, parent_tidptr: 0x7fc3ea3a79d0, child_tidptr: 0x7fc3ea3a79d0, tls: 0x7fc3ea3a7700) = 9551 (perf)
      #
    
    Signed-off-by: Kan Liang <kan.liang@intel.com>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexei Starovoitov <ast@kernel.org>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: He Kuang <hekuang@huawei.com>
    Cc: Lukasz Odzioba <lukasz.odzioba@intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/r/1506696477-146932-4-git-send-email-kan.liang@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 585b4a3d64a4..7c3aa479201a 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2218,12 +2218,16 @@ int machines__for_each_thread(struct machines *machines,
 int __machine__synthesize_threads(struct machine *machine, struct perf_tool *tool,
 				  struct target *target, struct thread_map *threads,
 				  perf_event__handler_t process, bool data_mmap,
-				  unsigned int proc_map_timeout)
+				  unsigned int proc_map_timeout,
+				  unsigned int nr_threads_synthesize)
 {
 	if (target__has_task(target))
 		return perf_event__synthesize_thread_map(tool, threads, process, machine, data_mmap, proc_map_timeout);
 	else if (target__has_cpu(target))
-		return perf_event__synthesize_threads(tool, process, machine, data_mmap, proc_map_timeout);
+		return perf_event__synthesize_threads(tool, process,
+						      machine, data_mmap,
+						      proc_map_timeout,
+						      nr_threads_synthesize);
 	/* command specified */
 	return 0;
 }

commit 0a7c74eae307894c6c95316c382f118aef8481e8
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Apr 4 13:15:04 2017 -0300

    perf tools: Provide mutex wrappers for pthreads rwlocks
    
    Andi reported a performance drop in single threaded perf tools such as
    'perf script' due to the growing number of locks being put in place to
    allow for multithreaded tools, so wrap the POSIX threads rwlock routines
    with the names used for such kinds of locks in the Linux kernel and then
    allow for tools to ask for those locks to be used or not.
    
    I.e. a tool may have a multithreaded phase and then switch to single
    threaded, like the upcoming patches for the synthesizing of
    PERF_RECORD_{FORK,MMAP,etc} for pre-existing processes to then switch to
    single threaded mode in 'perf top'.
    
    The init routines will not be conditional, this way starting as single
    threaded to then move to multi threaded mode should be possible.
    
    Reported-by: Andi Kleen <ak@linux.intel.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Kan Liang <kan.liang@intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/r/20170404161739.GH12903@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index ddeea05eae86..585b4a3d64a4 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -30,7 +30,7 @@ static void dsos__init(struct dsos *dsos)
 {
 	INIT_LIST_HEAD(&dsos->head);
 	dsos->root = RB_ROOT;
-	pthread_rwlock_init(&dsos->lock, NULL);
+	init_rwsem(&dsos->lock);
 }
 
 static void machine__threads_init(struct machine *machine)
@@ -40,7 +40,7 @@ static void machine__threads_init(struct machine *machine)
 	for (i = 0; i < THREADS__TABLE_SIZE; i++) {
 		struct threads *threads = &machine->threads[i];
 		threads->entries = RB_ROOT;
-		pthread_rwlock_init(&threads->lock, NULL);
+		init_rwsem(&threads->lock);
 		threads->nr = 0;
 		INIT_LIST_HEAD(&threads->dead);
 		threads->last_match = NULL;
@@ -130,7 +130,7 @@ static void dsos__purge(struct dsos *dsos)
 {
 	struct dso *pos, *n;
 
-	pthread_rwlock_wrlock(&dsos->lock);
+	down_write(&dsos->lock);
 
 	list_for_each_entry_safe(pos, n, &dsos->head, node) {
 		RB_CLEAR_NODE(&pos->rb_node);
@@ -139,13 +139,13 @@ static void dsos__purge(struct dsos *dsos)
 		dso__put(pos);
 	}
 
-	pthread_rwlock_unlock(&dsos->lock);
+	up_write(&dsos->lock);
 }
 
 static void dsos__exit(struct dsos *dsos)
 {
 	dsos__purge(dsos);
-	pthread_rwlock_destroy(&dsos->lock);
+	exit_rwsem(&dsos->lock);
 }
 
 void machine__delete_threads(struct machine *machine)
@@ -155,7 +155,7 @@ void machine__delete_threads(struct machine *machine)
 
 	for (i = 0; i < THREADS__TABLE_SIZE; i++) {
 		struct threads *threads = &machine->threads[i];
-		pthread_rwlock_wrlock(&threads->lock);
+		down_write(&threads->lock);
 		nd = rb_first(&threads->entries);
 		while (nd) {
 			struct thread *t = rb_entry(nd, struct thread, rb_node);
@@ -163,7 +163,7 @@ void machine__delete_threads(struct machine *machine)
 			nd = rb_next(nd);
 			__machine__remove_thread(machine, t, false);
 		}
-		pthread_rwlock_unlock(&threads->lock);
+		up_write(&threads->lock);
 	}
 }
 
@@ -180,7 +180,7 @@ void machine__exit(struct machine *machine)
 
 	for (i = 0; i < THREADS__TABLE_SIZE; i++) {
 		struct threads *threads = &machine->threads[i];
-		pthread_rwlock_destroy(&threads->lock);
+		exit_rwsem(&threads->lock);
 	}
 }
 
@@ -482,9 +482,9 @@ struct thread *machine__findnew_thread(struct machine *machine, pid_t pid,
 	struct threads *threads = machine__threads(machine, tid);
 	struct thread *th;
 
-	pthread_rwlock_wrlock(&threads->lock);
+	down_write(&threads->lock);
 	th = __machine__findnew_thread(machine, pid, tid);
-	pthread_rwlock_unlock(&threads->lock);
+	up_write(&threads->lock);
 	return th;
 }
 
@@ -494,9 +494,9 @@ struct thread *machine__find_thread(struct machine *machine, pid_t pid,
 	struct threads *threads = machine__threads(machine, tid);
 	struct thread *th;
 
-	pthread_rwlock_rdlock(&threads->lock);
+	down_read(&threads->lock);
 	th =  ____machine__findnew_thread(machine, threads, pid, tid, false);
-	pthread_rwlock_unlock(&threads->lock);
+	up_read(&threads->lock);
 	return th;
 }
 
@@ -588,7 +588,7 @@ static struct dso *machine__findnew_module_dso(struct machine *machine,
 {
 	struct dso *dso;
 
-	pthread_rwlock_wrlock(&machine->dsos.lock);
+	down_write(&machine->dsos.lock);
 
 	dso = __dsos__find(&machine->dsos, m->name, true);
 	if (!dso) {
@@ -602,7 +602,7 @@ static struct dso *machine__findnew_module_dso(struct machine *machine,
 
 	dso__get(dso);
 out_unlock:
-	pthread_rwlock_unlock(&machine->dsos.lock);
+	up_write(&machine->dsos.lock);
 	return dso;
 }
 
@@ -749,7 +749,8 @@ size_t machine__fprintf(struct machine *machine, FILE *fp)
 
 	for (i = 0; i < THREADS__TABLE_SIZE; i++) {
 		struct threads *threads = &machine->threads[i];
-		pthread_rwlock_rdlock(&threads->lock);
+
+		down_read(&threads->lock);
 
 		ret = fprintf(fp, "Threads: %u\n", threads->nr);
 
@@ -759,7 +760,7 @@ size_t machine__fprintf(struct machine *machine, FILE *fp)
 			ret += thread__fprintf(pos, fp);
 		}
 
-		pthread_rwlock_unlock(&threads->lock);
+		up_read(&threads->lock);
 	}
 	return ret;
 }
@@ -1319,7 +1320,7 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 		struct dso *kernel = NULL;
 		struct dso *dso;
 
-		pthread_rwlock_rdlock(&machine->dsos.lock);
+		down_read(&machine->dsos.lock);
 
 		list_for_each_entry(dso, &machine->dsos.head, node) {
 
@@ -1349,7 +1350,7 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 			break;
 		}
 
-		pthread_rwlock_unlock(&machine->dsos.lock);
+		up_read(&machine->dsos.lock);
 
 		if (kernel == NULL)
 			kernel = machine__findnew_dso(machine, kmmap_prefix);
@@ -1513,7 +1514,7 @@ static void __machine__remove_thread(struct machine *machine, struct thread *th,
 
 	BUG_ON(refcount_read(&th->refcnt) == 0);
 	if (lock)
-		pthread_rwlock_wrlock(&threads->lock);
+		down_write(&threads->lock);
 	rb_erase_init(&th->rb_node, &threads->entries);
 	RB_CLEAR_NODE(&th->rb_node);
 	--threads->nr;
@@ -1524,7 +1525,7 @@ static void __machine__remove_thread(struct machine *machine, struct thread *th,
 	 */
 	list_add_tail(&th->node, &threads->dead);
 	if (lock)
-		pthread_rwlock_unlock(&threads->lock);
+		up_write(&threads->lock);
 	thread__put(th);
 }
 

commit 75e45e432052c7b1a5da866cff88192db8be1445
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Sep 14 16:16:34 2017 -0300

    perf machine: Optimize a bit the machine__findnew_thread() methods
    
    In some cases we already have calculated the hash bucket, so reuse it.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Kan Liang <kan.liang@intel.com>
    Cc: Lukasz Odzioba <lukasz.odzioba@intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-800zehjsyy03er4s4jf0e99v@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index f4f926753209..ddeea05eae86 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -399,10 +399,10 @@ static void machine__update_thread_pid(struct machine *machine,
  * lookup/new thread inserted.
  */
 static struct thread *____machine__findnew_thread(struct machine *machine,
+						  struct threads *threads,
 						  pid_t pid, pid_t tid,
 						  bool create)
 {
-	struct threads *threads = machine__threads(machine, tid);
 	struct rb_node **p = &threads->entries.rb_node;
 	struct rb_node *parent = NULL;
 	struct thread *th;
@@ -473,7 +473,7 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 
 struct thread *__machine__findnew_thread(struct machine *machine, pid_t pid, pid_t tid)
 {
-	return ____machine__findnew_thread(machine, pid, tid, true);
+	return ____machine__findnew_thread(machine, machine__threads(machine, tid), pid, tid, true);
 }
 
 struct thread *machine__findnew_thread(struct machine *machine, pid_t pid,
@@ -495,7 +495,7 @@ struct thread *machine__find_thread(struct machine *machine, pid_t pid,
 	struct thread *th;
 
 	pthread_rwlock_rdlock(&threads->lock);
-	th =  ____machine__findnew_thread(machine, pid, tid, false);
+	th =  ____machine__findnew_thread(machine, threads, pid, tid, false);
 	pthread_rwlock_unlock(&threads->lock);
 	return th;
 }

commit 91e467bc568f15da2eac688e131010601e889184
Author: Kan Liang <kan.liang@intel.com>
Date:   Sun Sep 10 19:23:14 2017 -0700

    perf machine: Use hashtable for machine threads
    
    To process any events, it needs to find the thread in the machine first.
    The machine maintains a rb tree to store all threads. The rb tree is
    protected by a rw lock.
    
    It is not a problem for current perf which serially processing events.
    However, it will have scalability performance issue to process events in
    parallel, especially on a heavy load system which have many threads.
    
    Introduce a hashtable to divide the big rb tree into many samll rb tree
    for threads. The index is thread id % hashtable size. It can reduce the
    lock contention.
    
    Committer notes:
    
    Renamed some variables and function names to reduce semantic confusion:
    
      'struct threads' pointers: thread -> threads
      threads hastable index: tid -> hash_bucket
      struct threads *machine__thread() -> machine__threads()
      Cast tid to (unsigned int) to handle -1 in machine__threads() (Kan Liang)
    
    Signed-off-by: Kan Liang <kan.liang@intel.com>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Lukasz Odzioba <lukasz.odzioba@intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1505096603-215017-2-git-send-email-kan.liang@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index df709363ef69..f4f926753209 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -33,6 +33,20 @@ static void dsos__init(struct dsos *dsos)
 	pthread_rwlock_init(&dsos->lock, NULL);
 }
 
+static void machine__threads_init(struct machine *machine)
+{
+	int i;
+
+	for (i = 0; i < THREADS__TABLE_SIZE; i++) {
+		struct threads *threads = &machine->threads[i];
+		threads->entries = RB_ROOT;
+		pthread_rwlock_init(&threads->lock, NULL);
+		threads->nr = 0;
+		INIT_LIST_HEAD(&threads->dead);
+		threads->last_match = NULL;
+	}
+}
+
 int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 {
 	memset(machine, 0, sizeof(*machine));
@@ -40,11 +54,7 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 	RB_CLEAR_NODE(&machine->rb_node);
 	dsos__init(&machine->dsos);
 
-	machine->threads = RB_ROOT;
-	pthread_rwlock_init(&machine->threads_lock, NULL);
-	machine->nr_threads = 0;
-	INIT_LIST_HEAD(&machine->dead_threads);
-	machine->last_match = NULL;
+	machine__threads_init(machine);
 
 	machine->vdso_info = NULL;
 	machine->env = NULL;
@@ -141,27 +151,37 @@ static void dsos__exit(struct dsos *dsos)
 void machine__delete_threads(struct machine *machine)
 {
 	struct rb_node *nd;
+	int i;
 
-	pthread_rwlock_wrlock(&machine->threads_lock);
-	nd = rb_first(&machine->threads);
-	while (nd) {
-		struct thread *t = rb_entry(nd, struct thread, rb_node);
+	for (i = 0; i < THREADS__TABLE_SIZE; i++) {
+		struct threads *threads = &machine->threads[i];
+		pthread_rwlock_wrlock(&threads->lock);
+		nd = rb_first(&threads->entries);
+		while (nd) {
+			struct thread *t = rb_entry(nd, struct thread, rb_node);
 
-		nd = rb_next(nd);
-		__machine__remove_thread(machine, t, false);
+			nd = rb_next(nd);
+			__machine__remove_thread(machine, t, false);
+		}
+		pthread_rwlock_unlock(&threads->lock);
 	}
-	pthread_rwlock_unlock(&machine->threads_lock);
 }
 
 void machine__exit(struct machine *machine)
 {
+	int i;
+
 	machine__destroy_kernel_maps(machine);
 	map_groups__exit(&machine->kmaps);
 	dsos__exit(&machine->dsos);
 	machine__exit_vdso(machine);
 	zfree(&machine->root_dir);
 	zfree(&machine->current_tid);
-	pthread_rwlock_destroy(&machine->threads_lock);
+
+	for (i = 0; i < THREADS__TABLE_SIZE; i++) {
+		struct threads *threads = &machine->threads[i];
+		pthread_rwlock_destroy(&threads->lock);
+	}
 }
 
 void machine__delete(struct machine *machine)
@@ -382,7 +402,8 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 						  pid_t pid, pid_t tid,
 						  bool create)
 {
-	struct rb_node **p = &machine->threads.rb_node;
+	struct threads *threads = machine__threads(machine, tid);
+	struct rb_node **p = &threads->entries.rb_node;
 	struct rb_node *parent = NULL;
 	struct thread *th;
 
@@ -391,14 +412,14 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 	 * so most of the time we dont have to look up
 	 * the full rbtree:
 	 */
-	th = machine->last_match;
+	th = threads->last_match;
 	if (th != NULL) {
 		if (th->tid == tid) {
 			machine__update_thread_pid(machine, th, pid);
 			return thread__get(th);
 		}
 
-		machine->last_match = NULL;
+		threads->last_match = NULL;
 	}
 
 	while (*p != NULL) {
@@ -406,7 +427,7 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 		th = rb_entry(parent, struct thread, rb_node);
 
 		if (th->tid == tid) {
-			machine->last_match = th;
+			threads->last_match = th;
 			machine__update_thread_pid(machine, th, pid);
 			return thread__get(th);
 		}
@@ -423,7 +444,7 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 	th = thread__new(pid, tid);
 	if (th != NULL) {
 		rb_link_node(&th->rb_node, parent, p);
-		rb_insert_color(&th->rb_node, &machine->threads);
+		rb_insert_color(&th->rb_node, &threads->entries);
 
 		/*
 		 * We have to initialize map_groups separately
@@ -434,7 +455,7 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 		 * leader and that would screwed the rb tree.
 		 */
 		if (thread__init_map_groups(th, machine)) {
-			rb_erase_init(&th->rb_node, &machine->threads);
+			rb_erase_init(&th->rb_node, &threads->entries);
 			RB_CLEAR_NODE(&th->rb_node);
 			thread__put(th);
 			return NULL;
@@ -443,8 +464,8 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 		 * It is now in the rbtree, get a ref
 		 */
 		thread__get(th);
-		machine->last_match = th;
-		++machine->nr_threads;
+		threads->last_match = th;
+		++threads->nr;
 	}
 
 	return th;
@@ -458,21 +479,24 @@ struct thread *__machine__findnew_thread(struct machine *machine, pid_t pid, pid
 struct thread *machine__findnew_thread(struct machine *machine, pid_t pid,
 				       pid_t tid)
 {
+	struct threads *threads = machine__threads(machine, tid);
 	struct thread *th;
 
-	pthread_rwlock_wrlock(&machine->threads_lock);
+	pthread_rwlock_wrlock(&threads->lock);
 	th = __machine__findnew_thread(machine, pid, tid);
-	pthread_rwlock_unlock(&machine->threads_lock);
+	pthread_rwlock_unlock(&threads->lock);
 	return th;
 }
 
 struct thread *machine__find_thread(struct machine *machine, pid_t pid,
 				    pid_t tid)
 {
+	struct threads *threads = machine__threads(machine, tid);
 	struct thread *th;
-	pthread_rwlock_rdlock(&machine->threads_lock);
+
+	pthread_rwlock_rdlock(&threads->lock);
 	th =  ____machine__findnew_thread(machine, pid, tid, false);
-	pthread_rwlock_unlock(&machine->threads_lock);
+	pthread_rwlock_unlock(&threads->lock);
 	return th;
 }
 
@@ -719,21 +743,24 @@ size_t machine__fprintf_vmlinux_path(struct machine *machine, FILE *fp)
 
 size_t machine__fprintf(struct machine *machine, FILE *fp)
 {
-	size_t ret;
 	struct rb_node *nd;
+	size_t ret;
+	int i;
 
-	pthread_rwlock_rdlock(&machine->threads_lock);
-
-	ret = fprintf(fp, "Threads: %u\n", machine->nr_threads);
+	for (i = 0; i < THREADS__TABLE_SIZE; i++) {
+		struct threads *threads = &machine->threads[i];
+		pthread_rwlock_rdlock(&threads->lock);
 
-	for (nd = rb_first(&machine->threads); nd; nd = rb_next(nd)) {
-		struct thread *pos = rb_entry(nd, struct thread, rb_node);
+		ret = fprintf(fp, "Threads: %u\n", threads->nr);
 
-		ret += thread__fprintf(pos, fp);
-	}
+		for (nd = rb_first(&threads->entries); nd; nd = rb_next(nd)) {
+			struct thread *pos = rb_entry(nd, struct thread, rb_node);
 
-	pthread_rwlock_unlock(&machine->threads_lock);
+			ret += thread__fprintf(pos, fp);
+		}
 
+		pthread_rwlock_unlock(&threads->lock);
+	}
 	return ret;
 }
 
@@ -1479,23 +1506,25 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 
 static void __machine__remove_thread(struct machine *machine, struct thread *th, bool lock)
 {
-	if (machine->last_match == th)
-		machine->last_match = NULL;
+	struct threads *threads = machine__threads(machine, th->tid);
+
+	if (threads->last_match == th)
+		threads->last_match = NULL;
 
 	BUG_ON(refcount_read(&th->refcnt) == 0);
 	if (lock)
-		pthread_rwlock_wrlock(&machine->threads_lock);
-	rb_erase_init(&th->rb_node, &machine->threads);
+		pthread_rwlock_wrlock(&threads->lock);
+	rb_erase_init(&th->rb_node, &threads->entries);
 	RB_CLEAR_NODE(&th->rb_node);
-	--machine->nr_threads;
+	--threads->nr;
 	/*
 	 * Move it first to the dead_threads list, then drop the reference,
 	 * if this is the last reference, then the thread__delete destructor
 	 * will be called and we will remove it from the dead_threads list.
 	 */
-	list_add_tail(&th->node, &machine->dead_threads);
+	list_add_tail(&th->node, &threads->dead);
 	if (lock)
-		pthread_rwlock_unlock(&machine->threads_lock);
+		pthread_rwlock_unlock(&threads->lock);
 	thread__put(th);
 }
 
@@ -2140,21 +2169,26 @@ int machine__for_each_thread(struct machine *machine,
 			     int (*fn)(struct thread *thread, void *p),
 			     void *priv)
 {
+	struct threads *threads;
 	struct rb_node *nd;
 	struct thread *thread;
 	int rc = 0;
+	int i;
 
-	for (nd = rb_first(&machine->threads); nd; nd = rb_next(nd)) {
-		thread = rb_entry(nd, struct thread, rb_node);
-		rc = fn(thread, priv);
-		if (rc != 0)
-			return rc;
-	}
+	for (i = 0; i < THREADS__TABLE_SIZE; i++) {
+		threads = &machine->threads[i];
+		for (nd = rb_first(&threads->entries); nd; nd = rb_next(nd)) {
+			thread = rb_entry(nd, struct thread, rb_node);
+			rc = fn(thread, priv);
+			if (rc != 0)
+				return rc;
+		}
 
-	list_for_each_entry(thread, &machine->dead_threads, node) {
-		rc = fn(thread, priv);
-		if (rc != 0)
-			return rc;
+		list_for_each_entry(thread, &threads->dead, node) {
+			rc = fn(thread, priv);
+			if (rc != 0)
+				return rc;
+		}
 	}
 	return rc;
 }

commit 8780fb25ab060bafa5a8149e79b703e0fc7ee847
Author: Kan Liang <kan.liang@intel.com>
Date:   Tue Aug 29 13:11:09 2017 -0400

    perf sort: Add sort option for physical address
    
    Add a new sort option "phys_daddr" for --mem-mode sort.  With this
    option applied, perf can sort and report by sample's physical address.
    
    Signed-off-by: Kan Liang <kan.liang@intel.com>
    Tested-by: Jiri Olsa <jolsa@redhat.com>
    Acked-by: Stephane Eranian <eranian@google.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1504026672-7304-3-git-send-email-kan.liang@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 9eaa95302c86..df709363ef69 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1635,10 +1635,12 @@ static void ip__resolve_ams(struct thread *thread,
 	ams->al_addr = al.addr;
 	ams->sym = al.sym;
 	ams->map = al.map;
+	ams->phys_addr = 0;
 }
 
 static void ip__resolve_data(struct thread *thread,
-			     u8 m, struct addr_map_symbol *ams, u64 addr)
+			     u8 m, struct addr_map_symbol *ams,
+			     u64 addr, u64 phys_addr)
 {
 	struct addr_location al;
 
@@ -1658,6 +1660,7 @@ static void ip__resolve_data(struct thread *thread,
 	ams->al_addr = al.addr;
 	ams->sym = al.sym;
 	ams->map = al.map;
+	ams->phys_addr = phys_addr;
 }
 
 struct mem_info *sample__resolve_mem(struct perf_sample *sample,
@@ -1669,7 +1672,8 @@ struct mem_info *sample__resolve_mem(struct perf_sample *sample,
 		return NULL;
 
 	ip__resolve_ams(al->thread, &mi->iaddr, sample->ip);
-	ip__resolve_data(al->thread, al->cpumode, &mi->daddr, sample->addr);
+	ip__resolve_data(al->thread, al->cpumode, &mi->daddr,
+			 sample->addr, sample->phys_addr);
 	mi->data_src.val = sample->data_src;
 
 	return mi;

commit c4ee06251d4212a0d55e2371f2db464f6a1e0901
Author: Jin Yao <yao.jin@linux.intel.com>
Date:   Mon Aug 7 21:05:15 2017 +0800

    perf report: Calculate the average cycles of iterations
    
    The branch history code has a loop detection function. With this, we can
    get the number of iterations by calculating the removed loops.
    
    While it would be nice for knowing the average cycles of iterations.
    This patch adds up the cycles in branch entries of removed loops and
    save the result to the next branch entry (e.g. branch entry A).
    
    Finally it will display the iteration number and average cycles at the
    "from" of branch entry A.
    
    For example:
    perf record -g -j any,save_type ./div
    perf report --branch-history --no-children --stdio
    
    --22.63%--main div.c:42 (RET CROSS_2M)
              compute_flag div.c:28 (cycles:2 iter:173115 avg_cycles:2)
              |
               --10.73%--compute_flag div.c:27 (RET CROSS_2M)
                         rand rand.c:28 (cycles:1)
                         rand rand.c:28 (RET CROSS_2M)
                         __random random.c:298 (cycles:1)
                         __random random.c:297 (COND_BWD CROSS_2M)
                         __random random.c:295 (cycles:1)
                         __random random.c:295 (COND_BWD CROSS_2M)
                         __random random.c:295 (cycles:1)
                         __random random.c:295 (RET CROSS_2M)
    
    Signed-off-by: Yao Jin <yao.jin@linux.intel.com>
    Reviewed-by: Andi Kleen <ak@linux.intel.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Kan Liang <kan.liang@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1502111115-18305-1-git-send-email-yao.jin@linux.intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 5c8eacaca4f4..9eaa95302c86 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1675,6 +1675,11 @@ struct mem_info *sample__resolve_mem(struct perf_sample *sample,
 	return mi;
 }
 
+struct iterations {
+	int nr_loop_iter;
+	u64 cycles;
+};
+
 static int add_callchain_ip(struct thread *thread,
 			    struct callchain_cursor *cursor,
 			    struct symbol **parent,
@@ -1683,11 +1688,12 @@ static int add_callchain_ip(struct thread *thread,
 			    u64 ip,
 			    bool branch,
 			    struct branch_flags *flags,
-			    int nr_loop_iter,
-			    int samples,
+			    struct iterations *iter,
 			    u64 branch_from)
 {
 	struct addr_location al;
+	int nr_loop_iter = 0;
+	u64 iter_cycles = 0;
 
 	al.filtered = 0;
 	al.sym = NULL;
@@ -1737,9 +1743,15 @@ static int add_callchain_ip(struct thread *thread,
 
 	if (symbol_conf.hide_unresolved && al.sym == NULL)
 		return 0;
+
+	if (iter) {
+		nr_loop_iter = iter->nr_loop_iter;
+		iter_cycles = iter->cycles;
+	}
+
 	return callchain_cursor_append(cursor, al.addr, al.map, al.sym,
-				       branch, flags, nr_loop_iter, samples,
-				       branch_from);
+				       branch, flags, nr_loop_iter,
+				       iter_cycles, branch_from);
 }
 
 struct branch_info *sample__resolve_bstack(struct perf_sample *sample,
@@ -1760,6 +1772,18 @@ struct branch_info *sample__resolve_bstack(struct perf_sample *sample,
 	return bi;
 }
 
+static void save_iterations(struct iterations *iter,
+			    struct branch_entry *be, int nr)
+{
+	int i;
+
+	iter->nr_loop_iter = nr;
+	iter->cycles = 0;
+
+	for (i = 0; i < nr; i++)
+		iter->cycles += be[i].flags.cycles;
+}
+
 #define CHASHSZ 127
 #define CHASHBITS 7
 #define NO_ENTRY 0xff
@@ -1767,7 +1791,8 @@ struct branch_info *sample__resolve_bstack(struct perf_sample *sample,
 #define PERF_MAX_BRANCH_DEPTH 127
 
 /* Remove loops. */
-static int remove_loops(struct branch_entry *l, int nr)
+static int remove_loops(struct branch_entry *l, int nr,
+			struct iterations *iter)
 {
 	int i, j, off;
 	unsigned char chash[CHASHSZ];
@@ -1792,8 +1817,18 @@ static int remove_loops(struct branch_entry *l, int nr)
 					break;
 				}
 			if (is_loop) {
-				memmove(l + i, l + i + off,
-					(nr - (i + off)) * sizeof(*l));
+				j = nr - (i + off);
+				if (j > 0) {
+					save_iterations(iter + i + off,
+						l + i, off);
+
+					memmove(iter + i, iter + i + off,
+						j * sizeof(*iter));
+
+					memmove(l + i, l + i + off,
+						j * sizeof(*l));
+				}
+
 				nr -= off;
 			}
 		}
@@ -1883,7 +1918,7 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 
 			err = add_callchain_ip(thread, cursor, parent,
 					       root_al, &cpumode, ip,
-					       branch, flags, 0, 0,
+					       branch, flags, NULL,
 					       branch_from);
 			if (err)
 				return (err < 0) ? err : 0;
@@ -1909,7 +1944,6 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	int i, j, err, nr_entries;
 	int skip_idx = -1;
 	int first_call = 0;
-	int nr_loop_iter;
 
 	if (chain)
 		chain_nr = chain->nr;
@@ -1942,6 +1976,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	if (branch && callchain_param.branch_callstack) {
 		int nr = min(max_stack, (int)branch->nr);
 		struct branch_entry be[nr];
+		struct iterations iter[nr];
 
 		if (branch->nr > PERF_MAX_BRANCH_DEPTH) {
 			pr_warning("corrupted branch chain. skipping...\n");
@@ -1972,38 +2007,21 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 				be[i] = branch->entries[branch->nr - i - 1];
 		}
 
-		nr_loop_iter = nr;
-		nr = remove_loops(be, nr);
-
-		/*
-		 * Get the number of iterations.
-		 * It's only approximation, but good enough in practice.
-		 */
-		if (nr_loop_iter > nr)
-			nr_loop_iter = nr_loop_iter - nr + 1;
-		else
-			nr_loop_iter = 0;
+		memset(iter, 0, sizeof(struct iterations) * nr);
+		nr = remove_loops(be, nr, iter);
 
 		for (i = 0; i < nr; i++) {
-			if (i == nr - 1)
-				err = add_callchain_ip(thread, cursor, parent,
-						       root_al,
-						       NULL, be[i].to,
-						       true, &be[i].flags,
-						       nr_loop_iter, 1,
-						       be[i].from);
-			else
-				err = add_callchain_ip(thread, cursor, parent,
-						       root_al,
-						       NULL, be[i].to,
-						       true, &be[i].flags,
-						       0, 0, be[i].from);
+			err = add_callchain_ip(thread, cursor, parent,
+					       root_al,
+					       NULL, be[i].to,
+					       true, &be[i].flags,
+					       NULL, be[i].from);
 
 			if (!err)
 				err = add_callchain_ip(thread, cursor, parent, root_al,
 						       NULL, be[i].from,
 						       true, &be[i].flags,
-						       0, 0, 0);
+						       &iter[i], 0);
 			if (err == -EINVAL)
 				break;
 			if (err)
@@ -2037,7 +2055,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 
 		err = add_callchain_ip(thread, cursor, parent,
 				       root_al, &cpumode, ip,
-				       false, NULL, 0, 0, 0);
+				       false, NULL, NULL, 0);
 
 		if (err)
 			return (err < 0) ? err : 0;

commit 9ad4652b66f19a60f07e63b942b80b5c2d7465bf
Author: Thomas Richter <tmricht@linux.vnet.ibm.com>
Date:   Thu Aug 3 15:49:02 2017 +0200

    perf record: Fix wrong size in perf_record_mmap for last kernel module
    
    During work on perf report for s390 I ran into the following issue:
    
    0 0x318 [0x78]: PERF_RECORD_MMAP -1/0:
            [0x3ff804d6990(0xfffffc007fb2966f) @ 0]:
            x /lib/modules/4.12.0perf1+/kernel/drivers/s390/net/qeth_l2.ko
    
    This is a PERF_RECORD_MMAP entry of the perf.data file with an invalid
    module size for qeth_l2.ko (the s390 ethernet device driver).
    
    Even a mainframe does not have 0xfffffc007fb2966f bytes of main memory.
    
    It turned out that this wrong size is created by the perf record
    command.  What happens is this function call sequence from
    __cmd_record():
    
      perf_session__new():
        perf_session__create_kernel_maps():
          machine__create_kernel_maps():
            machine__create_modules():   Creates map for all loaded kernel modules.
              modules__parse():   Reads /proc/modules and extracts module name and
                                  load address (1st and last column)
                machine__create_module():   Called for every module found in /proc/modules.
                                  Creates a new map for every module found and enters
                                  module name and start address into the map. Since the
                                  module end address is unknown it is set to zero.
    
    This ends up with a kernel module map list sorted by module start
    addresses.  All module end addresses are zero.
    
    Last machine__create_kernel_maps() calls function map_groups__fixup_end().
    This function iterates through the maps and assigns each map entry's
    end address the successor map entry start address. The last entry of the
    map group has no successor, so ~0 is used as end to consume the remaining
    memory.
    
    Later __cmd_record calls function record__synthesize() which in turn calls
    perf_event__synthesize_kernel_mmap() and perf_event__synthesize_modules()
    to create PERF_REPORT_MMAP entries into the perf.data file.
    
    On s390 this results in the last module qeth_l2.ko
    (which has highest start address, see module table:
            [root@s8360047 perf]# cat /proc/modules
            qeth_l2 86016 1 - Live 0x000003ff804d6000
            qeth 266240 1 qeth_l2, Live 0x000003ff80296000
            ccwgroup 24576 1 qeth, Live 0x000003ff80218000
            vmur 36864 0 - Live 0x000003ff80182000
            qdio 143360 2 qeth_l2,qeth, Live 0x000003ff80002000
            [root@s8360047 perf]# )
    to be the last entry and its map has an end address of ~0.
    
    When the PERF_RECORD_MMAP entry is created for kernel module qeth_l2.ko
    its start address and length is written. The length is calculated in line:
        event->mmap.len   = pos->end - pos->start;
    and results in 0xffffffffffffffff - 0x3ff804d6990(*) = 0xfffffc007fb2966f
    
    (*) On s390 the module start address is actually determined by a __weak function
    named arch__fix_module_text_start() in machine__create_module().
    
    I think this improvable. We can use the module size (2nd column of /proc/modules)
    to get each loaded kernel module size and calculate its end address.
    Only for map entries which do not have a valid end address (end is still zero)
    we can use the heuristic we have now, that is use successor start address or ~0.
    
    Signed-off-by: Thomas-Mich Richter <tmricht@linux.vnet.ibm.com>
    Reviewed-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
    Cc: Thomas-Mich Richter <tmricht@linux.vnet.ibm.com>
    Cc: Zvonko Kosic <zvonko.kosic@de.ibm.com>
    LPU-Reference: 20170803134902.47207-2-tmricht@linux.vnet.ibm.com
    Link: http://lkml.kernel.org/n/tip-nmoqij5b5vxx7rq2ckwu8iaj@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index d4df353051af..5c8eacaca4f4 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1138,7 +1138,8 @@ int __weak arch__fix_module_text_start(u64 *start __maybe_unused,
 	return 0;
 }
 
-static int machine__create_module(void *arg, const char *name, u64 start)
+static int machine__create_module(void *arg, const char *name, u64 start,
+				  u64 size)
 {
 	struct machine *machine = arg;
 	struct map *map;
@@ -1149,6 +1150,7 @@ static int machine__create_module(void *arg, const char *name, u64 start)
 	map = machine__findnew_module_map(machine, start, name);
 	if (map == NULL)
 		return -1;
+	map->end = start + size;
 
 	dso__kernel_module_get_build_id(map->dso, machine->root_dir);
 

commit b49a821ed9e05fa0ccbaec2555052b2a920be517
Author: Jin Yao <yao.jin@linux.intel.com>
Date:   Mon May 8 18:43:02 2017 +0800

    perf report: Make --branch-history work without callgraphs(-g) option in perf record
    
      perf record -b -g <command>
      perf report --branch-history
    
    This merges the LBRs with the callgraphs.
    
    However it would be nice if it also works without callgraphs (-g) set in
    perf record, so that only the LBRs are displayed.  But currently perf
    report errors in this case. For example,
    
      perf record -b <command>
      perf report --branch-history
    
      Error:
      Selected -g or --branch-history but no callchain data. Did
      you call 'perf record' without -g?
    
    This patch displays the LBRs only even if callgraphs(-g) is not enabled
    in perf record.
    
    Change log:
    
    v2: According to Milian Wolff's comment, change the obsolete error
    message. Now the error message is:
    
                     ┌─Error:─────────────────────────────────────┐
                     │Selected -g or --branch-history.            │
                     │But no callchain or branch data.            │
                     │Did you call 'perf record' without -g or -b?│
                     │                                            │
                     │                                            │
                     │Press any key...                            │
                     └────────────────────────────────────────────┘
    
    When passing the last parameter to hists__fprintf,
    changes "|" to "||".
    
      hists__fprintf(hists, !quiet, 0, 0, rep->min_percent, stdout,
                     symbol_conf.use_callchain || symbol_conf.show_branchflag_count);
    
    Signed-off-by: Yao Jin <yao.jin@linux.intel.com>
    Reviewed-by: Andi Kleen <ak@linux.intel.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Kan Liang <kan.liang@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1494240182-28899-1-git-send-email-yao.jin@linux.intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 79d08ea694da..d4df353051af 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1902,13 +1902,16 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 {
 	struct branch_stack *branch = sample->branch_stack;
 	struct ip_callchain *chain = sample->callchain;
-	int chain_nr = chain->nr;
+	int chain_nr = 0;
 	u8 cpumode = PERF_RECORD_MISC_USER;
 	int i, j, err, nr_entries;
 	int skip_idx = -1;
 	int first_call = 0;
 	int nr_loop_iter;
 
+	if (chain)
+		chain_nr = chain->nr;
+
 	if (perf_evsel__has_branch_callstack(evsel)) {
 		err = resolve_lbr_callchain_sample(thread, cursor, sample, parent,
 						   root_al, max_stack);
@@ -1946,6 +1949,10 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 		for (i = 0; i < nr; i++) {
 			if (callchain_param.order == ORDER_CALLEE) {
 				be[i] = branch->entries[i];
+
+				if (chain == NULL)
+					continue;
+
 				/*
 				 * Check for overlap into the callchain.
 				 * The return address is one off compared to
@@ -2000,6 +2007,10 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 			if (err)
 				return err;
 		}
+
+		if (chain_nr == 0)
+			return 0;
+
 		chain_nr -= nr;
 	}
 

commit b851dd49868e295e18c5d72fc3bad85ff1c444b1
Author: Jin Yao <yao.jin@linux.intel.com>
Date:   Tue Jul 18 20:13:15 2017 +0800

    perf report: Show branch type in callchain entry
    
    Show branch type in callchain entry. The branch type is printed
    with other LBR information (such as cycles/abort/...).
    
    For example:
    
      perf record -g -j any,save_type
      perf report --branch-history --stdio --no-children
    
      38.50%  div.c:45                [.] main                    div
              |
              ---main div.c:42 (RET CROSS_2M cycles:2)
                 compute_flag div.c:28 (cycles:2)
                 compute_flag div.c:27 (RET CROSS_2M cycles:1)
                 rand rand.c:28 (cycles:1)
                 rand rand.c:28 (RET CROSS_2M cycles:1)
                 __random random.c:298 (cycles:1)
                 __random random.c:297 (COND_BWD CROSS_2M cycles:1)
                 __random random.c:295 (cycles:1)
                 __random random.c:295 (COND_BWD CROSS_2M cycles:1)
                 __random random.c:295 (cycles:1)
                 __random random.c:295 (RET CROSS_2M cycles:9)
    
    Change log
    
    v6: Remove the branch_type_str() since it's moved to branch.c.
    
    v5: Rewrite the branch info print code in util/callchain.c.
    
    v4: Comparing to previous version, the major changes are:
    
    Signed-off-by: Yao Jin <yao.jin@linux.intel.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Kan Liang <kan.liang@intel.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1500379995-6449-8-git-send-email-yao.jin@linux.intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index a54a2be5eda4..79d08ea694da 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1682,7 +1682,8 @@ static int add_callchain_ip(struct thread *thread,
 			    bool branch,
 			    struct branch_flags *flags,
 			    int nr_loop_iter,
-			    int samples)
+			    int samples,
+			    u64 branch_from)
 {
 	struct addr_location al;
 
@@ -1735,7 +1736,8 @@ static int add_callchain_ip(struct thread *thread,
 	if (symbol_conf.hide_unresolved && al.sym == NULL)
 		return 0;
 	return callchain_cursor_append(cursor, al.addr, al.map, al.sym,
-				       branch, flags, nr_loop_iter, samples);
+				       branch, flags, nr_loop_iter, samples,
+				       branch_from);
 }
 
 struct branch_info *sample__resolve_bstack(struct perf_sample *sample,
@@ -1814,7 +1816,7 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 	struct ip_callchain *chain = sample->callchain;
 	int chain_nr = min(max_stack, (int)chain->nr), i;
 	u8 cpumode = PERF_RECORD_MISC_USER;
-	u64 ip;
+	u64 ip, branch_from = 0;
 
 	for (i = 0; i < chain_nr; i++) {
 		if (chain->ips[i] == PERF_CONTEXT_USER)
@@ -1856,6 +1858,8 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 					ip = lbr_stack->entries[0].to;
 					branch = true;
 					flags = &lbr_stack->entries[0].flags;
+					branch_from =
+						lbr_stack->entries[0].from;
 				}
 			} else {
 				if (j < lbr_nr) {
@@ -1870,12 +1874,15 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 					ip = lbr_stack->entries[0].to;
 					branch = true;
 					flags = &lbr_stack->entries[0].flags;
+					branch_from =
+						lbr_stack->entries[0].from;
 				}
 			}
 
 			err = add_callchain_ip(thread, cursor, parent,
 					       root_al, &cpumode, ip,
-					       branch, flags, 0, 0);
+					       branch, flags, 0, 0,
+					       branch_from);
 			if (err)
 				return (err < 0) ? err : 0;
 		}
@@ -1974,19 +1981,20 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 						       root_al,
 						       NULL, be[i].to,
 						       true, &be[i].flags,
-						       nr_loop_iter, 1);
+						       nr_loop_iter, 1,
+						       be[i].from);
 			else
 				err = add_callchain_ip(thread, cursor, parent,
 						       root_al,
 						       NULL, be[i].to,
 						       true, &be[i].flags,
-						       0, 0);
+						       0, 0, be[i].from);
 
 			if (!err)
 				err = add_callchain_ip(thread, cursor, parent, root_al,
 						       NULL, be[i].from,
 						       true, &be[i].flags,
-						       0, 0);
+						       0, 0, 0);
 			if (err == -EINVAL)
 				break;
 			if (err)
@@ -2016,7 +2024,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 
 		err = add_callchain_ip(thread, cursor, parent,
 				       root_al, &cpumode, ip,
-				       false, NULL, 0, 0);
+				       false, NULL, 0, 0, 0);
 
 		if (err)
 			return (err < 0) ? err : 0;
@@ -2033,7 +2041,7 @@ static int unwind_entry(struct unwind_entry *entry, void *arg)
 		return 0;
 	return callchain_cursor_append(cursor, entry->ip,
 				       entry->map, entry->sym,
-				       false, NULL, 0, 0);
+				       false, NULL, 0, 0, 0);
 }
 
 static int thread__resolve_callchain_unwind(struct thread *thread,

commit d2396999c998b4e0006aef247e154eff0ed3d8f9
Author: Krister Johansen <kjlx@templeofstupid.com>
Date:   Wed Jul 5 18:48:13 2017 -0700

    perf buildid-cache: Cache debuginfo
    
    If a stripped binary is placed in the cache, the user is in a situation
    where there's a cached elf file present, but it doesn't have any symtab
    to use for name resolution.  Grab the debuginfo for binaries that don't
    end in .ko.  This yields a better chance of resolving symbols from older
    traces.
    
    Signed-off-by: Krister Johansen <kjlx@templeofstupid.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Brendan Gregg <brendan.d.gregg@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas-Mich Richter <tmricht@linux.vnet.ibm.com>
    Link: http://lkml.kernel.org/r/1499305693-1599-7-git-send-email-kjlx@templeofstupid.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 246b441110a1..a54a2be5eda4 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -705,7 +705,8 @@ size_t machine__fprintf_vmlinux_path(struct machine *machine, FILE *fp)
 
 	if (kdso->has_build_id) {
 		char filename[PATH_MAX];
-		if (dso__build_id_filename(kdso, filename, sizeof(filename)))
+		if (dso__build_id_filename(kdso, filename, sizeof(filename),
+					   false))
 			printed += fprintf(fp, "[0] %s\n", filename);
 	}
 

commit bf2e710b3cb8445c052f2ff50b4875a2523bb279
Author: Krister Johansen <kjlx@templeofstupid.com>
Date:   Wed Jul 5 18:48:09 2017 -0700

    perf maps: Lookup maps in both intitial mountns and inner mountns.
    
    If a process is in a mountns and has symbols in /tmp/perf-<pid>.map,
    look first in the namespace using the tgid for the pidns that the
    process might be in.  If the map isn't found there, try looking in the
    mountns where perf is running, and use the tgid that's appropriate for
    perf's pid namespace.  If all else fails, use the original pid.
    
    This allows us to locate a symbol map file in the mount namespace, if it
    was generated there.  However, we also try the tool's /tmp in case it's
    there instead.
    
    Signed-off-by: Krister Johansen <kjlx@templeofstupid.com>
    Tested-by: Brendan Gregg <brendan.d.gregg@gmail.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas-Mich Richter <tmricht@linux.vnet.ibm.com>
    Link: http://lkml.kernel.org/r/1499305693-1599-3-git-send-email-kjlx@templeofstupid.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 2e9eb6aa3ce2..246b441110a1 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1392,7 +1392,7 @@ int machine__process_mmap2_event(struct machine *machine,
 
 	map = map__new(machine, event->mmap2.start,
 			event->mmap2.len, event->mmap2.pgoff,
-			event->mmap2.pid, event->mmap2.maj,
+			event->mmap2.maj,
 			event->mmap2.min, event->mmap2.ino,
 			event->mmap2.ino_generation,
 			event->mmap2.prot,
@@ -1450,7 +1450,7 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 
 	map = map__new(machine, event->mmap.start,
 			event->mmap.len, event->mmap.pgoff,
-			event->mmap.pid, 0, 0, 0, 0, 0, 0,
+			0, 0, 0, 0, 0, 0,
 			event->mmap.filename,
 			type, thread);
 

commit 4b1303d0b01440f224cf81493b7e8e43d9b4965e
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Jul 11 16:21:40 2017 -0300

    perf symbols: Accept zero as the kernel base address
    
    Which is the case in S/390, where symbols were not being resolved
    because machine__get_kernel_start was only setting machine->kernel_start
    when the just successfully loaded kernel symtab had its map->start set
    to !0, when it was left at (1ULL << 63) assuming a partitioning of the
    address space for user/kernel, which is not the case in S/390 nor in
    Sparc.
    
    So just check if map__load() was successfull and set
    machine->kernel_start to zero, fixing kernel symbol resolution on S/390.
    
    Test performed by Thomas:
    
     ----
    
      I like this patch. I have done a new build and removed all my debug output to start
      from scratch. Without your patch I get this:
    
      # Samples: 4  of event 'cpu-clock'
      # Event count (approx.): 1000000
      #
      # Children      Self  Command  Shared Object     Symbol
      # ........  ........  .......  ................  ........................
          75.00%     0.00%  true     [unknown]         [k] 0x00000000004bedda
                  |
                  ---0x4bedda
                     |
                     |--50.00%--0x42693a
                     |          |
                     |           --25.00%--0x2a72e0
                     |                     0x2af0ca
                     |                     0x3d1003fe4c0
                     |
                      --25.00%--0x4272bc
                                0x26fa84
    
      and with your patch (I just rebuilt the perf tool, nothing else and used the same
      perf.data file as input):
    
      # Samples: 4  of event 'cpu-clock'
      # Event count (approx.): 1000000
      #
      # Children      Self  Command  Shared Object               Symbol
      # ........  ........  .......  ..........................  ..................................
          75.00%     0.00%  true     [kernel.vmlinux]            [k] pgm_check_handler
                  |
                  ---pgm_check_handler
                     do_dat_exception
                     handle_mm_fault
                     __handle_mm_fault
                     filemap_map_pages
                     |
                     |--25.00%--rcu_read_lock_held
                     |          rcu_lockdep_current_cpu_online
                     |          0x3d1003ff4c0
                     |
                      --25.00%--lock_release
    
      Looks good to me....
     ----
    
    Reported-and-Tested-by: Thomas-Mich Richter <tmricht@linux.vnet.ibm.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Cc: Zvonko Kosic <zvonko.kosic@de.ibm.com>
    Link: http://lkml.kernel.org/n/tip-dk0n1uzmbe0tbthrpfqlx6bz@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 5de2b86b9880..2e9eb6aa3ce2 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2209,7 +2209,7 @@ int machine__get_kernel_start(struct machine *machine)
 	machine->kernel_start = 1ULL << 63;
 	if (map) {
 		err = map__load(map);
-		if (map->start)
+		if (!err)
 			machine->kernel_start = map->start;
 	}
 	return err;

commit 3f938ee2f6c4fff8d95b24636a0964b5a93cf547
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Mon Jun 26 11:51:53 2017 +0200

    perf machine: Fix segfault for kernel.kptr_restrict=2
    
    Michael reported the segfault when kernel.kptr_restrict=2 is set.
    
      $ perf record ls
      ...
      perf: Segmentation fault
      Obtained 16 stack frames.
      ./perf(dump_stack+0x2d) [0x5068df]
      ./perf(sighandler_dump_stack+0x2d) [0x5069bf]
      ./perf() [0x43e47b]
      /lib64/libc.so.6(+0x3594f) [0x7f762004794f]
      /lib64/libc.so.6(strlen+0x26) [0x7f762009ef86]
      /lib64/libc.so.6(__strdup+0xd) [0x7f762009ecbd]
      ./perf(maps__set_kallsyms_ref_reloc_sym+0x4d) [0x51590f]
      ./perf(machine__create_kernel_maps+0x136) [0x50a7de]
      ./perf(perf_session__create_kernel_maps+0x2c) [0x510a81]
      ./perf(perf_session__new+0x13d) [0x510e23]
      ./perf() [0x43fd61]
      ./perf(cmd_record+0x704) [0x441823]
      ./perf() [0x4bc1a0]
      ./perf() [0x4bc40d]
      ./perf() [0x4bc55f]
      ./perf(main+0x2d5) [0x4bc939]
      Segmentation fault (core dumped)
    
    The reason is that with kernel.kptr_restrict=2, we don't get
    the symbol from machine__get_running_kernel_start, which we
    want to use in maps__set_kallsyms_ref_reloc_sym and we crash.
    
    Check the symbol name value before calling
    maps__set_kallsyms_ref_reloc_sym() and succeed without ref_reloc_sym
    being set. It's safe because we check its existence before we use it.
    
    Reported-by: Michael Petlan <mpetlan@redhat.com>
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/20170626095153.553-1-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index d7f31cb0a4cb..5de2b86b9880 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1209,10 +1209,12 @@ int machine__create_kernel_maps(struct machine *machine)
 	 */
 	map_groups__fixup_end(&machine->kmaps);
 
-	if (machine__get_running_kernel_start(machine, &name, &addr)) {
-	} else if (maps__set_kallsyms_ref_reloc_sym(machine->vmlinux_maps, name, addr)) {
-		machine__destroy_kernel_maps(machine);
-		return -1;
+	if (!machine__get_running_kernel_start(machine, &name, &addr)) {
+		if (name &&
+		    maps__set_kallsyms_ref_reloc_sym(machine->vmlinux_maps, name, addr)) {
+			machine__destroy_kernel_maps(machine);
+			return -1;
+		}
 	}
 
 	return 0;

commit 6b335e8f545591c07df0f34231bd7ff7506c98c1
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Wed May 31 21:01:04 2017 +0900

    perf symbols: Set module info when build-id event found
    
    Like machine__findnew_module_dso(), it should set necessary info for
    kernel modules to find symbol info from the file.  Factor out
    dso__set_module_info() to do it.
    
    This is needed for dso__needs_decompress() to detect such DSOs.
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: kernel-team@lge.com
    Link: http://lkml.kernel.org/r/20170531120105.21731-2-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index d97e014c3df3..d7f31cb0a4cb 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -572,16 +572,7 @@ static struct dso *machine__findnew_module_dso(struct machine *machine,
 		if (dso == NULL)
 			goto out_unlock;
 
-		if (machine__is_host(machine))
-			dso->symtab_type = DSO_BINARY_TYPE__SYSTEM_PATH_KMODULE;
-		else
-			dso->symtab_type = DSO_BINARY_TYPE__GUEST_KMODULE;
-
-		/* _KMODULE_COMP should be next to _KMODULE */
-		if (m->kmod && m->comp)
-			dso->symtab_type++;
-
-		dso__set_short_name(dso, strdup(m->name), true);
+		dso__set_module_info(dso, m, machine);
 		dso__set_long_name(dso, strdup(filename), true);
 	}
 

commit b843f62ad942f3879c2d7acd27b44f931c609685
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Apr 27 21:21:09 2017 -0300

    perf symbols: Accept symbols starting at address 0
    
    That is the case of _text on s390, and we have some functions that return an
    address, using address zero to report problems, oops.
    
    This would lead the symbol loading routines to not use "_text" as the reference
    relocation symbol, or the first symbol for the kernel, but use instead
    "_stext", that is at the same address on x86_64 and others, but not on s390:
    
      [acme@localhost perf-4.11.0-rc6]$ head -15 /proc/kallsyms
      0000000000000000 T _text
      0000000000000418 t iplstart
      0000000000000800 T start
      000000000000080a t .base
      000000000000082e t .sk8x8
      0000000000000834 t .gotr
      0000000000000842 t .cmd
      0000000000000846 t .parm
      000000000000084a t .lowcase
      0000000000010000 T startup
      0000000000010010 T startup_kdump
      0000000000010214 t startup_kdump_relocated
      0000000000011000 T startup_continue
      00000000000112a0 T _ehead
      0000000000100000 T _stext
      [acme@localhost perf-4.11.0-rc6]$
    
    Which in turn would make 'perf test vmlinux' to fail because it wouldn't find
    the symbols before "_stext" in kallsyms.
    
    Fix it by using the return value only for errors and storing the
    address, when the symbol is successfully found, in a provided pointer
    arg.
    
    Before this patch:
    
    After:
    
      [acme@localhost perf-4.11.0-rc6]$ tools/perf/perf test -v 1
       1: vmlinux symtab matches kallsyms            :
      --- start ---
      test child forked, pid 40693
      Looking at the vmlinux_path (8 entries long)
      Using /usr/lib/debug/lib/modules/3.10.0-654.el7.s390x/vmlinux for symbols
      ERR : 0: _text not on kallsyms
      ERR : 0x418: iplstart not on kallsyms
      ERR : 0x800: start not on kallsyms
      ERR : 0x80a: .base not on kallsyms
      ERR : 0x82e: .sk8x8 not on kallsyms
      ERR : 0x834: .gotr not on kallsyms
      ERR : 0x842: .cmd not on kallsyms
      ERR : 0x846: .parm not on kallsyms
      ERR : 0x84a: .lowcase not on kallsyms
      ERR : 0x10000: startup not on kallsyms
      ERR : 0x10010: startup_kdump not on kallsyms
      ERR : 0x10214: startup_kdump_relocated not on kallsyms
      ERR : 0x11000: startup_continue not on kallsyms
      ERR : 0x112a0: _ehead not on kallsyms
      <SNIP warnings>
      test child finished with -1
      ---- end ----
      vmlinux symtab matches kallsyms: FAILED!
      [acme@localhost perf-4.11.0-rc6]$
    
    After:
    
      [acme@localhost perf-4.11.0-rc6]$ tools/perf/perf test -v 1
       1: vmlinux symtab matches kallsyms            :
      --- start ---
      test child forked, pid 47160
      <SNIP warnings>
      test child finished with 0
      ---- end ----
      vmlinux symtab matches kallsyms: Ok
      [acme@localhost perf-4.11.0-rc6]$
    
    Reported-by: Michael Petlan <mpetlan@redhat.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-9x9bwgd3btwdk1u51xie93fz@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 7a47f52ccfcc..d97e014c3df3 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -796,11 +796,11 @@ const char *ref_reloc_sym_names[] = {"_text", "_stext", NULL};
  * Returns the name of the start symbol in *symbol_name. Pass in NULL as
  * symbol_name if it's not that important.
  */
-static u64 machine__get_running_kernel_start(struct machine *machine,
-					     const char **symbol_name)
+static int machine__get_running_kernel_start(struct machine *machine,
+					     const char **symbol_name, u64 *start)
 {
 	char filename[PATH_MAX];
-	int i;
+	int i, err = -1;
 	const char *name;
 	u64 addr = 0;
 
@@ -810,21 +810,28 @@ static u64 machine__get_running_kernel_start(struct machine *machine,
 		return 0;
 
 	for (i = 0; (name = ref_reloc_sym_names[i]) != NULL; i++) {
-		addr = kallsyms__get_function_start(filename, name);
-		if (addr)
+		err = kallsyms__get_function_start(filename, name, &addr);
+		if (!err)
 			break;
 	}
 
+	if (err)
+		return -1;
+
 	if (symbol_name)
 		*symbol_name = name;
 
-	return addr;
+	*start = addr;
+	return 0;
 }
 
 int __machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
 {
 	int type;
-	u64 start = machine__get_running_kernel_start(machine, NULL);
+	u64 start = 0;
+
+	if (machine__get_running_kernel_start(machine, NULL, &start))
+		return -1;
 
 	/* In case of renewal the kernel map, destroy previous one */
 	machine__destroy_kernel_maps(machine);
@@ -1185,8 +1192,8 @@ static int machine__create_modules(struct machine *machine)
 int machine__create_kernel_maps(struct machine *machine)
 {
 	struct dso *kernel = machine__get_kernel(machine);
-	const char *name;
-	u64 addr;
+	const char *name = NULL;
+	u64 addr = 0;
 	int ret;
 
 	if (kernel == NULL)
@@ -1211,8 +1218,7 @@ int machine__create_kernel_maps(struct machine *machine)
 	 */
 	map_groups__fixup_end(&machine->kmaps);
 
-	addr = machine__get_running_kernel_start(machine, &name);
-	if (!addr) {
+	if (machine__get_running_kernel_start(machine, &name, &addr)) {
 	} else if (maps__set_kallsyms_ref_reloc_sym(machine->vmlinux_maps, name, addr)) {
 		machine__destroy_kernel_maps(machine);
 		return -1;

commit 7a8ef4c4b5fd5c578da4dadbcb1c5da650426c74
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Apr 19 20:57:47 2017 -0300

    perf tools: Remove string.h, unistd.h and sys/stat.h from util.h
    
    Not needed in this header, added to the places that need FILE,
    putchar(), access() and a few other prototypes.
    
    Link: http://lkml.kernel.org/n/tip-xxtdsl6nsna82j7puwbdjqhs@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 988e84ce6f88..7a47f52ccfcc 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -14,6 +14,9 @@
 #include "thread.h"
 #include "vdso.h"
 #include <stdbool.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <unistd.h>
 #include "unwind.h"
 #include "linux/hash.h"
 #include "asm/bug.h"

commit 1eae20c1d40acf7676aa799b48f747d9b28bf352
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Apr 18 12:33:30 2017 -0300

    perf tools: Remove regex.h and fnmatch.h from util.h
    
    The users of regex and fnmatch functions should include those headers
    instead.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-ixzm5kuamsq1ixbkuv6kmwzj@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 46411742d03c..988e84ce6f88 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1,6 +1,7 @@
 #include <dirent.h>
 #include <errno.h>
 #include <inttypes.h>
+#include <regex.h>
 #include "callchain.h"
 #include "debug.h"
 #include "event.h"

commit 76b31a29ddaf2fa5f0a70458c214bed02a4a70e9
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Apr 18 12:26:44 2017 -0300

    perf tools: Remove include dirent.h from util.h
    
    The files using the dirent.h routines should instead include it,
    reducing the includes hell that lead to longer build times.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-42g2f4z6nfg7mdb2ae97n7tj@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index cdbfe3e32e5a..46411742d03c 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1,3 +1,4 @@
+#include <dirent.h>
 #include <errno.h>
 #include <inttypes.h>
 #include "callchain.h"

commit a43783aeec5fac8ef372ff8c0a5bbb3056fc0604
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Apr 18 10:46:11 2017 -0300

    perf tools: Include errno.h where needed
    
    Removing it from util.h, part of an effort to disentangle the includes
    hell, that makes changes to util.h or something included by it to cause
    a complete rebuild of the tools.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-ztrjy52q1rqcchuy3rubfgt2@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index f13f46a99b36..cdbfe3e32e5a 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1,3 +1,4 @@
+#include <errno.h>
 #include <inttypes.h>
 #include "callchain.h"
 #include "debug.h"

commit 3d689ed6099a1a11c38bb78aff7498e78e287e0b
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Apr 17 16:10:49 2017 -0300

    perf tools: Move sane ctype stuff from util.h to sane_ctype.h
    
    More stuff that came from git, out of the hodge-podge that is util.h
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-e3lana4gctz3ub4hn4y29hkw@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 15b2a17cf76e..f13f46a99b36 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -11,11 +11,13 @@
 #include "thread.h"
 #include "vdso.h"
 #include <stdbool.h>
-#include <symbol/kallsyms.h>
 #include "unwind.h"
 #include "linux/hash.h"
 #include "asm/bug.h"
 
+#include "sane_ctype.h"
+#include <symbol/kallsyms.h>
+
 static void __machine__remove_thread(struct machine *machine, struct thread *th, bool lock);
 
 static void dsos__init(struct dsos *dsos)

commit fd20e8111cc0e51ce12fb8ee17c863088fe95065
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Apr 17 15:23:08 2017 -0300

    perf tools: Including missing inttypes.h header
    
    Needed to use the PRI[xu](32,64) formatting macros.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-wkbho8kaw24q67dd11q0j39f@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index dfc600446586..15b2a17cf76e 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1,3 +1,4 @@
+#include <inttypes.h>
 #include "callchain.h"
 #include "debug.h"
 #include "event.h"

commit f3b3614a284deb124018155a618a7b19694c8b5c
Author: Hari Bathini <hbathini@linux.vnet.ibm.com>
Date:   Wed Mar 8 02:11:43 2017 +0530

    perf tools: Add PERF_RECORD_NAMESPACES to include namespaces related info
    
    Introduce a new option to record PERF_RECORD_NAMESPACES events emitted
    by the kernel when fork, clone, setns or unshare are invoked. And update
    perf-record documentation with the new option to record namespace
    events.
    
    Committer notes:
    
    Combined it with a later patch to allow printing it via 'perf report -D'
    and be able to test the feature introduced in this patch. Had to move
    here also perf_ns__name(), that was introduced in another later patch.
    
    Also used PRIu64 and PRIx64 to fix the build in some enfironments wrt:
    
      util/event.c:1129:39: error: format '%lx' expects argument of type 'long unsigned int', but argument 6 has type 'long long unsigned int' [-Werror=format=]
         ret  += fprintf(fp, "%u/%s: %lu/0x%lx%s", idx
                                             ^
    Testing it:
    
      # perf record --namespaces -a
      ^C[ perf record: Woken up 1 times to write data ]
      [ perf record: Captured and wrote 1.083 MB perf.data (423 samples) ]
      #
      # perf report -D
      <SNIP>
      3 2028902078892 0x115140 [0xa0]: PERF_RECORD_NAMESPACES 14783/14783 - nr_namespaces: 7
                    [0/net: 3/0xf0000081, 1/uts: 3/0xeffffffe, 2/ipc: 3/0xefffffff, 3/pid: 3/0xeffffffc,
                     4/user: 3/0xeffffffd, 5/mnt: 3/0xf0000000, 6/cgroup: 3/0xeffffffb]
    
      0x1151e0 [0x30]: event: 9
      .
      . ... raw event: size 48 bytes
      .  0000:  09 00 00 00 02 00 30 00 c4 71 82 68 0c 7f 00 00  ......0..q.h....
      .  0010:  a9 39 00 00 a9 39 00 00 94 28 fe 63 d8 01 00 00  .9...9...(.c....
      .  0020:  03 00 00 00 00 00 00 00 ce c4 02 00 00 00 00 00  ................
      <SNIP>
            NAMESPACES events:          1
      <SNIP>
      #
    
    Signed-off-by: Hari Bathini <hbathini@linux.vnet.ibm.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Alexei Starovoitov <ast@fb.com>
    Cc: Ananth N Mavinakayanahalli <ananth@linux.vnet.ibm.com>
    Cc: Aravinda Prasad <aravinda@linux.vnet.ibm.com>
    Cc: Brendan Gregg <brendan.d.gregg@gmail.com>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Eric Biederman <ebiederm@xmission.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Sargun Dhillon <sargun@sargun.me>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Link: http://lkml.kernel.org/r/148891930386.25309.18412039920746995488.stgit@hbathini.in.ibm.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index b9974fe41bc1..dfc600446586 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -13,6 +13,7 @@
 #include <symbol/kallsyms.h>
 #include "unwind.h"
 #include "linux/hash.h"
+#include "asm/bug.h"
 
 static void __machine__remove_thread(struct machine *machine, struct thread *th, bool lock);
 
@@ -501,6 +502,37 @@ int machine__process_comm_event(struct machine *machine, union perf_event *event
 	return err;
 }
 
+int machine__process_namespaces_event(struct machine *machine __maybe_unused,
+				      union perf_event *event,
+				      struct perf_sample *sample __maybe_unused)
+{
+	struct thread *thread = machine__findnew_thread(machine,
+							event->namespaces.pid,
+							event->namespaces.tid);
+	int err = 0;
+
+	WARN_ONCE(event->namespaces.nr_namespaces > NR_NAMESPACES,
+		  "\nWARNING: kernel seems to support more namespaces than perf"
+		  " tool.\nTry updating the perf tool..\n\n");
+
+	WARN_ONCE(event->namespaces.nr_namespaces < NR_NAMESPACES,
+		  "\nWARNING: perf tool seems to support more namespaces than"
+		  " the kernel.\nTry updating the kernel..\n\n");
+
+	if (dump_trace)
+		perf_event__fprintf_namespaces(event, stdout);
+
+	if (thread == NULL ||
+	    thread__set_namespaces(thread, sample->time, &event->namespaces)) {
+		dump_printf("problem processing PERF_RECORD_NAMESPACES, skipping event.\n");
+		err = -1;
+	}
+
+	thread__put(thread);
+
+	return err;
+}
+
 int machine__process_lost_event(struct machine *machine __maybe_unused,
 				union perf_event *event, struct perf_sample *sample __maybe_unused)
 {
@@ -1538,6 +1570,8 @@ int machine__process_event(struct machine *machine, union perf_event *event,
 		ret = machine__process_comm_event(machine, event, sample); break;
 	case PERF_RECORD_MMAP:
 		ret = machine__process_mmap_event(machine, event, sample); break;
+	case PERF_RECORD_NAMESPACES:
+		ret = machine__process_namespaces_event(machine, event, sample); break;
 	case PERF_RECORD_MMAP2:
 		ret = machine__process_mmap2_event(machine, event, sample); break;
 	case PERF_RECORD_FORK:

commit e34f5b11cd51fbe723e481c1db03a77260be6f4c
Author: Elena Reshetova <elena.reshetova@intel.com>
Date:   Tue Feb 21 17:35:02 2017 +0200

    perf thread: convert thread.refcnt from atomic_t to refcount_t
    
    The refcount_t type and corresponding API should be used instead of atomic_t
    when the variable is used as a reference counter.
    
    This allows to avoid accidental refcounter overflows that might lead to
    use-after-free situations.
    
    Signed-off-by: Elena Reshetova <elena.reshetova@intel.com>
    Signed-off-by: David Windsor <dwindsor@gmail.com>
    Signed-off-by: Hans Liljestrand <ishkamiel@gmail.com>
    Signed-off-by: Kees Kook <keescook@chromium.org>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: David Windsor <dwindsor@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Hans Liljestrand <ishkamiel@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Kees Kook <keescook@chromium.org>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Matija Glavinic Pecotic <matija.glavinic-pecotic.ext@nokia.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: alsa-devel@alsa-project.org
    Link: http://lkml.kernel.org/r/1487691303-31858-9-git-send-email-elena.reshetova@intel.com
    [ Did missing conversion in __machine__remove_thread() ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 71c9720d4973..b9974fe41bc1 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1439,7 +1439,7 @@ static void __machine__remove_thread(struct machine *machine, struct thread *th,
 	if (machine->last_match == th)
 		machine->last_match = NULL;
 
-	BUG_ON(atomic_read(&th->refcnt) == 0);
+	BUG_ON(refcount_read(&th->refcnt) == 0);
 	if (lock)
 		pthread_rwlock_wrlock(&machine->threads_lock);
 	rb_erase_init(&th->rb_node, &machine->threads);

commit a0b2f5af4c99d3da7ce9bc2b3b4641c8ffd22615
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Feb 14 16:19:56 2017 -0300

    perf tools: Be consistent on the type of map->symbols[] interator
    
    In a few cases we were using 'enum map_type' and that triggered this
    warning when using clang:
    
      util/session.c:1923:16: error: comparison of constant 2 with expression of type 'enum map_type' is always true
          [-Werror,-Wtautological-constant-out-of-range-compare]
            for (i = 0; i < MAP__NR_TYPES; ++i) {
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-i6uyo6bsopa2dghnx8qo7rri@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index a1043cf9b89c..71c9720d4973 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -782,7 +782,7 @@ static u64 machine__get_running_kernel_start(struct machine *machine,
 
 int __machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
 {
-	enum map_type type;
+	int type;
 	u64 start = machine__get_running_kernel_start(machine, NULL);
 
 	/* In case of renewal the kernel map, destroy previous one */
@@ -813,7 +813,7 @@ int __machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
 
 void machine__destroy_kernel_maps(struct machine *machine)
 {
-	enum map_type type;
+	int type;
 
 	for (type = 0; type < MAP__NR_TYPES; ++type) {
 		struct kmap *kmap;

commit a7c3899c06865c75f8887f33d9043f6e8e780e71
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Feb 13 16:52:15 2017 -0300

    perf symbols: No need to check if sym->name is NULL
    
    As it is an array, so will always evaluate to 'true', as reported by
    clang:
    
      builtin-sched.c:2070:19: error: address of array 'sym->name' will always evaluate to 'true' [-Werror,-Wpointer-bool-conversion]
                      if (sym && sym->name) {
                              ~~ ~~~~~^~~~
      1 warning generated.
    
    So just ditch all those useless checks.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-ydpm927col06paixb775jjx5@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 747a034d1ff3..a1043cf9b89c 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1565,7 +1565,7 @@ int machine__process_event(struct machine *machine, union perf_event *event,
 
 static bool symbol__match_regex(struct symbol *sym, regex_t *regex)
 {
-	if (sym->name && !regexec(regex, sym->name, 0, NULL, 0))
+	if (!regexec(regex, sym->name, 0, NULL, 0))
 		return 1;
 	return 0;
 }

commit 7d132caaf9392853ad637c8e6e53333cbeb99aa5
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Jan 5 15:31:48 2017 -0300

    perf machine: Add a kallsyms loading constructor
    
    To reduce the boilerplate for searching for functions in the running
    kernel and modules.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-93iqzayafpaxaguoiwjqezgz@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 9b33bef54581..747a034d1ff3 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -87,6 +87,25 @@ struct machine *machine__new_host(void)
 	return NULL;
 }
 
+struct machine *machine__new_kallsyms(void)
+{
+	struct machine *machine = machine__new_host();
+	/*
+	 * FIXME:
+	 * 1) MAP__FUNCTION will go away when we stop loading separate maps for
+	 *    functions and data objects.
+	 * 2) We should switch to machine__load_kallsyms(), i.e. not explicitely
+	 *    ask for not using the kcore parsing code, once this one is fixed
+	 *    to create a map per module.
+	 */
+	if (machine && __machine__load_kallsyms(machine, "/proc/kallsyms", MAP__FUNCTION, true) <= 0) {
+		machine__delete(machine);
+		machine = NULL;
+	}
+
+	return machine;
+}
+
 static void dsos__purge(struct dsos *dsos)
 {
 	struct dso *pos, *n;

commit 410024dbbcb1df5b8140a812b4f1a4dbd62ef924
Author: Jin Yao <yao.jin@linux.intel.com>
Date:   Mon Oct 31 09:19:49 2016 +0800

    perf report: Add branch flag to callchain cursor node
    
    Since the branch ip has been added to call stack for easier browsing,
    this patch adds more branch information. For example, add a flag to
    indicate if this ip is a branch, and also add with the branch flag.
    
    Then we can know if the cursor node represents a branch and know what
    the branch flag it has.
    
    The branch history code has a loop detection pass that removes loops. It
    would be nice for knowing how many loops were removed then in next
    steps, we can compute out the average number of iterations.
    
    For example:
    
    Before remove_loops(),
    entry0: from = 0x100, to = 0x200
    entry1: from = 0x300, to = 0x250
    entry2: from = 0x300, to = 0x250
    entry3: from = 0x300, to = 0x250
    entry4: from = 0x700, to = 0x800
    
    After remove_loops()
    entry0: from = 0x100, to = 0x200
    entry1: from = 0x300, to = 0x250
    entry2: from = 0x700, to = 0x800
    
    The original entry2 and entry3 are removed. So the number of iterations
    (from = 0x300, to = 0x250) is equal to removed number + 1 (2 + 1).
    
    iterations = removed number + 1;
    average iteractions = Sum(iteractions) / number of samples
    
    This formula ignores other cases, for example, iterations cross multiple
    buffers and one buffer contains 2+ loops. Because in practice, it's good
    enough.
    
    Signed-off-by: Yao Jin <yao.jin@linux.intel.com>
    Acked-by: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Kan Liang <kan.liang@intel.com>
    Cc: Linux-kernel@vger.kernel.org
    Cc: Yao Jin <yao.jin@linux.intel.com>
    Link: http://lkml.kernel.org/n/1477876794-30749-2-git-send-email-yao.jin@linux.intel.com
    [ Renamed 'iter' to 'nr_loop_iter' for clarity ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index df85b9efd80f..9b33bef54581 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1616,7 +1616,11 @@ static int add_callchain_ip(struct thread *thread,
 			    struct symbol **parent,
 			    struct addr_location *root_al,
 			    u8 *cpumode,
-			    u64 ip)
+			    u64 ip,
+			    bool branch,
+			    struct branch_flags *flags,
+			    int nr_loop_iter,
+			    int samples)
 {
 	struct addr_location al;
 
@@ -1668,7 +1672,8 @@ static int add_callchain_ip(struct thread *thread,
 
 	if (symbol_conf.hide_unresolved && al.sym == NULL)
 		return 0;
-	return callchain_cursor_append(cursor, al.addr, al.map, al.sym);
+	return callchain_cursor_append(cursor, al.addr, al.map, al.sym,
+				       branch, flags, nr_loop_iter, samples);
 }
 
 struct branch_info *sample__resolve_bstack(struct perf_sample *sample,
@@ -1757,7 +1762,9 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 	/* LBR only affects the user callchain */
 	if (i != chain_nr) {
 		struct branch_stack *lbr_stack = sample->branch_stack;
-		int lbr_nr = lbr_stack->nr, j;
+		int lbr_nr = lbr_stack->nr, j, k;
+		bool branch;
+		struct branch_flags *flags;
 		/*
 		 * LBR callstack can only get user call chain.
 		 * The mix_chain_nr is kernel call chain
@@ -1772,23 +1779,41 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 
 		for (j = 0; j < mix_chain_nr; j++) {
 			int err;
+			branch = false;
+			flags = NULL;
+
 			if (callchain_param.order == ORDER_CALLEE) {
 				if (j < i + 1)
 					ip = chain->ips[j];
-				else if (j > i + 1)
-					ip = lbr_stack->entries[j - i - 2].from;
-				else
+				else if (j > i + 1) {
+					k = j - i - 2;
+					ip = lbr_stack->entries[k].from;
+					branch = true;
+					flags = &lbr_stack->entries[k].flags;
+				} else {
 					ip = lbr_stack->entries[0].to;
+					branch = true;
+					flags = &lbr_stack->entries[0].flags;
+				}
 			} else {
-				if (j < lbr_nr)
-					ip = lbr_stack->entries[lbr_nr - j - 1].from;
+				if (j < lbr_nr) {
+					k = lbr_nr - j - 1;
+					ip = lbr_stack->entries[k].from;
+					branch = true;
+					flags = &lbr_stack->entries[k].flags;
+				}
 				else if (j > lbr_nr)
 					ip = chain->ips[i + 1 - (j - lbr_nr)];
-				else
+				else {
 					ip = lbr_stack->entries[0].to;
+					branch = true;
+					flags = &lbr_stack->entries[0].flags;
+				}
 			}
 
-			err = add_callchain_ip(thread, cursor, parent, root_al, &cpumode, ip);
+			err = add_callchain_ip(thread, cursor, parent,
+					       root_al, &cpumode, ip,
+					       branch, flags, 0, 0);
 			if (err)
 				return (err < 0) ? err : 0;
 		}
@@ -1813,6 +1838,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	int i, j, err, nr_entries;
 	int skip_idx = -1;
 	int first_call = 0;
+	int nr_loop_iter;
 
 	if (perf_evsel__has_branch_callstack(evsel)) {
 		err = resolve_lbr_callchain_sample(thread, cursor, sample, parent,
@@ -1868,14 +1894,37 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 				be[i] = branch->entries[branch->nr - i - 1];
 		}
 
+		nr_loop_iter = nr;
 		nr = remove_loops(be, nr);
 
+		/*
+		 * Get the number of iterations.
+		 * It's only approximation, but good enough in practice.
+		 */
+		if (nr_loop_iter > nr)
+			nr_loop_iter = nr_loop_iter - nr + 1;
+		else
+			nr_loop_iter = 0;
+
 		for (i = 0; i < nr; i++) {
-			err = add_callchain_ip(thread, cursor, parent, root_al,
-					       NULL, be[i].to);
+			if (i == nr - 1)
+				err = add_callchain_ip(thread, cursor, parent,
+						       root_al,
+						       NULL, be[i].to,
+						       true, &be[i].flags,
+						       nr_loop_iter, 1);
+			else
+				err = add_callchain_ip(thread, cursor, parent,
+						       root_al,
+						       NULL, be[i].to,
+						       true, &be[i].flags,
+						       0, 0);
+
 			if (!err)
 				err = add_callchain_ip(thread, cursor, parent, root_al,
-						       NULL, be[i].from);
+						       NULL, be[i].from,
+						       true, &be[i].flags,
+						       0, 0);
 			if (err == -EINVAL)
 				break;
 			if (err)
@@ -1903,7 +1952,9 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 		if (ip < PERF_CONTEXT_MAX)
                        ++nr_entries;
 
-		err = add_callchain_ip(thread, cursor, parent, root_al, &cpumode, ip);
+		err = add_callchain_ip(thread, cursor, parent,
+				       root_al, &cpumode, ip,
+				       false, NULL, 0, 0);
 
 		if (err)
 			return (err < 0) ? err : 0;
@@ -1919,7 +1970,8 @@ static int unwind_entry(struct unwind_entry *entry, void *arg)
 	if (symbol_conf.hide_unresolved && entry->sym == NULL)
 		return 0;
 	return callchain_cursor_append(cursor, entry->ip,
-				       entry->map, entry->sym);
+				       entry->map, entry->sym,
+				       false, NULL, 0, 0);
 }
 
 static int thread__resolve_callchain_unwind(struct thread *thread,

commit 18ef15c675a5d5d97f844ebcf340a2a6c7cf3142
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Oct 3 11:07:24 2016 -0300

    perf tools: Experiment with cppcheck
    
    Experimenting a bit using cppcheck[1], a static checker brought to my
    attention by Colin, reducing the scope of some variables, reducing the
    line of source code lines in the process:
    
      $ cppcheck --enable=style tools/perf/util/thread.c
      Checking tools/perf/util/thread.c...
      [tools/perf/util/thread.c:17]: (style) The scope of the variable 'leader' can be reduced.
      [tools/perf/util/thread.c:133]: (style) The scope of the variable 'err' can be reduced.
      [tools/perf/util/thread.c:273]: (style) The scope of the variable 'err' can be reduced.
    
    Will continue later, but these are already useful, keep them.
    
    1: https://sourceforge.net/p/cppcheck/wiki/Home/
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Colin Ian King <colin.king@canonical.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-ixws7lbycihhpmq9cc949ti6@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 18e4519abef2..df85b9efd80f 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1745,9 +1745,8 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 					int max_stack)
 {
 	struct ip_callchain *chain = sample->callchain;
-	int chain_nr = min(max_stack, (int)chain->nr);
+	int chain_nr = min(max_stack, (int)chain->nr), i;
 	u8 cpumode = PERF_RECORD_MISC_USER;
-	int i, j, err;
 	u64 ip;
 
 	for (i = 0; i < chain_nr; i++) {
@@ -1758,7 +1757,7 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 	/* LBR only affects the user callchain */
 	if (i != chain_nr) {
 		struct branch_stack *lbr_stack = sample->branch_stack;
-		int lbr_nr = lbr_stack->nr;
+		int lbr_nr = lbr_stack->nr, j;
 		/*
 		 * LBR callstack can only get user call chain.
 		 * The mix_chain_nr is kernel call chain
@@ -1772,6 +1771,7 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 		int mix_chain_nr = i + 1 + lbr_nr + 1;
 
 		for (j = 0; j < mix_chain_nr; j++) {
+			int err;
 			if (callchain_param.order == ORDER_CALLEE) {
 				if (j < i + 1)
 					ip = chain->ips[j];

commit be39db9f2932f0ce4e116c71ba5ae2b542e536a7
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Sep 1 19:25:52 2016 -0300

    perf symbols: Remove symbol_filter_t machinery
    
    We're not using it anymore, few users were, but we really could do
    without it, simplify lots of functions by removing it.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-1zng8wdznn00iiz08bb7q3vn@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 7940ddc98f8c..18e4519abef2 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -897,10 +897,10 @@ int machines__create_kernel_maps(struct machines *machines, pid_t pid)
 }
 
 int __machine__load_kallsyms(struct machine *machine, const char *filename,
-			     enum map_type type, bool no_kcore, symbol_filter_t filter)
+			     enum map_type type, bool no_kcore)
 {
 	struct map *map = machine__kernel_map(machine);
-	int ret = __dso__load_kallsyms(map->dso, filename, map, no_kcore, filter);
+	int ret = __dso__load_kallsyms(map->dso, filename, map, no_kcore);
 
 	if (ret > 0) {
 		dso__set_loaded(map->dso, type);
@@ -916,16 +916,15 @@ int __machine__load_kallsyms(struct machine *machine, const char *filename,
 }
 
 int machine__load_kallsyms(struct machine *machine, const char *filename,
-			   enum map_type type, symbol_filter_t filter)
+			   enum map_type type)
 {
-	return __machine__load_kallsyms(machine, filename, type, false, filter);
+	return __machine__load_kallsyms(machine, filename, type, false);
 }
 
-int machine__load_vmlinux_path(struct machine *machine, enum map_type type,
-			       symbol_filter_t filter)
+int machine__load_vmlinux_path(struct machine *machine, enum map_type type)
 {
 	struct map *map = machine__kernel_map(machine);
-	int ret = dso__load_vmlinux_path(map->dso, map, filter);
+	int ret = dso__load_vmlinux_path(map->dso, map);
 
 	if (ret > 0)
 		dso__set_loaded(map->dso, type);
@@ -1294,7 +1293,7 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 			/*
 			 * preload dso of guest kernel and modules
 			 */
-			dso__load(kernel, machine__kernel_map(machine), NULL);
+			dso__load(kernel, machine__kernel_map(machine));
 		}
 	}
 	return 0;
@@ -2096,7 +2095,7 @@ int machine__get_kernel_start(struct machine *machine)
 	 */
 	machine->kernel_start = 1ULL << 63;
 	if (map) {
-		err = map__load(map, NULL);
+		err = map__load(map);
 		if (map->start)
 			machine->kernel_start = map->start;
 	}
@@ -2112,7 +2111,7 @@ char *machine__resolve_kernel_addr(void *vmachine, unsigned long long *addrp, ch
 {
 	struct machine *machine = vmachine;
 	struct map *map;
-	struct symbol *sym = map_groups__find_symbol(&machine->kmaps, MAP__FUNCTION, *addrp, &map,  NULL);
+	struct symbol *sym = map_groups__find_symbol(&machine->kmaps, MAP__FUNCTION, *addrp, &map);
 
 	if (sym == NULL)
 		return NULL;

commit 0890e97c20333c439a9bda6a94dd16ed5f508429
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Sep 1 18:53:58 2016 -0300

    perf machine: Remove machine->symbol_filter and friends
    
    Including machines__set_symbol_filter(), not used anymore.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-7o1qgmrpvzuis4a9f0t8mnri@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index cb6388dbdd98..7940ddc98f8c 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -41,7 +41,6 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 
 	machine->pid = pid;
 
-	machine->symbol_filter = NULL;
 	machine->id_hdr_size = 0;
 	machine->kptr_restrict_warned = false;
 	machine->comm_exec = false;
@@ -148,7 +147,6 @@ void machines__init(struct machines *machines)
 {
 	machine__init(&machines->host, "", HOST_KERNEL_ID);
 	machines->guests = RB_ROOT;
-	machines->symbol_filter = NULL;
 }
 
 void machines__exit(struct machines *machines)
@@ -172,8 +170,6 @@ struct machine *machines__add(struct machines *machines, pid_t pid,
 		return NULL;
 	}
 
-	machine->symbol_filter = machines->symbol_filter;
-
 	while (*p != NULL) {
 		parent = *p;
 		pos = rb_entry(parent, struct machine, rb_node);
@@ -189,21 +185,6 @@ struct machine *machines__add(struct machines *machines, pid_t pid,
 	return machine;
 }
 
-void machines__set_symbol_filter(struct machines *machines,
-				 symbol_filter_t symbol_filter)
-{
-	struct rb_node *nd;
-
-	machines->symbol_filter = symbol_filter;
-	machines->host.symbol_filter = symbol_filter;
-
-	for (nd = rb_first(&machines->guests); nd; nd = rb_next(nd)) {
-		struct machine *machine = rb_entry(nd, struct machine, rb_node);
-
-		machine->symbol_filter = symbol_filter;
-	}
-}
-
 void machines__set_comm_exec(struct machines *machines, bool comm_exec)
 {
 	struct rb_node *nd;
@@ -2115,7 +2096,7 @@ int machine__get_kernel_start(struct machine *machine)
 	 */
 	machine->kernel_start = 1ULL << 63;
 	if (map) {
-		err = map__load(map, machine->symbol_filter);
+		err = map__load(map, NULL);
 		if (map->start)
 			machine->kernel_start = map->start;
 	}

commit 203d8a4aa6edf2c19206316d439ec5dae52ce581
Author: Song Shan Gong <gongss@linux.vnet.ibm.com>
Date:   Thu Jul 21 11:10:51 2016 +0800

    perf s390: Fix 'start' address of module's map
    
    At present, when creating module's map, perf gets 'start' address by
    parsing '/proc/modules', but it's the module base address, it isn't the
    start address of the '.text' section.
    
    In most arches, it's OK. But for s390, it places 'GOT' and 'PLT'
    relocations before '.text' section. So there exists an offset between
    module base address and '.text' section, which will incur wrong symbol
    resolution for modules.
    
    Fix this bug by getting 'start' address of module's map from parsing
    '/sys/module/[module name]/sections/.text', not from '/proc/modules'.
    
    Signed-off-by: Song Shan Gong <gongss@linux.vnet.ibm.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: David Ahern <dsahern@gmail.com>
    Link: http://lkml.kernel.org/r/1469070651-6447-2-git-send-email-gongss@linux.vnet.ibm.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index bc2cdbd09a25..cb6388dbdd98 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1093,12 +1093,20 @@ static int machine__set_modules_path(struct machine *machine)
 
 	return map_groups__set_modules_path_dir(&machine->kmaps, modules_path, 0);
 }
+int __weak arch__fix_module_text_start(u64 *start __maybe_unused,
+				const char *name __maybe_unused)
+{
+	return 0;
+}
 
 static int machine__create_module(void *arg, const char *name, u64 start)
 {
 	struct machine *machine = arg;
 	struct map *map;
 
+	if (arch__fix_module_text_start(&start, name) < 0)
+		return -1;
+
 	map = machine__findnew_module_map(machine, start, name);
 	if (map == NULL)
 		return -1;

commit 32ca678dcd250f05183cf0c8a9e516545c6068bc
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Jun 22 10:19:11 2016 -0300

    perf machine: Destructors should accept NULL
    
    And do nothing, just like free(), to avoid having to test it in callers,
    usually in error paths.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-q42gj3b3znhho9z1mrbo4jce@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index a0c186acb1f3..bc2cdbd09a25 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -138,8 +138,10 @@ void machine__exit(struct machine *machine)
 
 void machine__delete(struct machine *machine)
 {
-	machine__exit(machine);
-	free(machine);
+	if (machine) {
+		machine__exit(machine);
+		free(machine);
+	}
 }
 
 void machines__init(struct machines *machines)

commit b8ab92201a64886fd3d8078fe46e51f658379823
Merge: aa3a655b159f 057fbfb25cde
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Jun 8 09:34:15 2016 +0200

    Merge tag 'perf-core-for-mingo-20160607' of git://git.kernel.org/pub/scm/linux/kernel/git/acme/linux into perf/core
    
    Pull perf/core improvements and fixes from Arnaldo Carvalho de Melo:
    
    User visible changes:
    
    - Support cross unwinding, i.e. collecting '--call-graph dwarf' perf.data files
      in one machine and then doing analysis in another machine of a different
      hardware architecture. This enables, for instance, to do:
    
            perf record -a --call-graph dwarf
    
      on a x86-32 or aarch64 system and then do 'perf report' on it on a
      x86_64 workstation. (He Kuang)
    
    - Fix crash in build_id_cache__kallsyms_path(), recent regression (Wang Nan)
    
    Infrastructure changes:
    
    - Make tools/lib/bpf use the IS_ERR return facility consistently and also stop
      using the _get_ term for non-reference count methods (Arnaldo Carvalho de Melo)
    
    - 'perf config' refactorings (Taeung Song)
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 8132a2a84147d3c98cf580d5759387325fbabf73
Author: He Kuang <hekuang@huawei.com>
Date:   Fri Jun 3 03:33:13 2016 +0000

    perf unwind: Move unwind__prepare_access from thread_new into thread__insert_map
    
    To determine the libunwind methods to use, we should get the
    32bit/64bit information from maps of a thread. When a thread is newly
    created, the information is not prepared. This patch moves
    unwind__prepare_access() into thread__insert_map() so we can get the
    information we need from maps. Meanwhile, let thread__insert_map()
    return value and show messages on error.
    
    Signed-off-by: He Kuang <hekuang@huawei.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ekaterina Tumanova <tumanova@linux.vnet.ibm.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Kan Liang <kan.liang@intel.com>
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Pekka Enberg <penberg@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/r/1464924803-22214-5-git-send-email-hekuang@huawei.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 205d27017361..9d931f5d47d0 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1353,11 +1353,16 @@ int machine__process_mmap2_event(struct machine *machine,
 	if (map == NULL)
 		goto out_problem_map;
 
-	thread__insert_map(thread, map);
+	ret = thread__insert_map(thread, map);
+	if (ret)
+		goto out_problem_insert;
+
 	thread__put(thread);
 	map__put(map);
 	return 0;
 
+out_problem_insert:
+	map__put(map);
 out_problem_map:
 	thread__put(thread);
 out_problem:
@@ -1403,11 +1408,16 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 	if (map == NULL)
 		goto out_problem_map;
 
-	thread__insert_map(thread, map);
+	ret = thread__insert_map(thread, map);
+	if (ret)
+		goto out_problem_insert;
+
 	thread__put(thread);
 	map__put(map);
 	return 0;
 
+out_problem_insert:
+	map__put(map);
 out_problem_map:
 	thread__put(thread);
 out_problem:

commit bdc6b758e443c21c39a14c075e5b7e01f095b37b
Merge: c4a346002bc0 0c9f790fcbda
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 25 17:05:40 2016 -0700

    Merge branch 'perf-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull perf updates from Ingo Molnar:
     "Mostly tooling and PMU driver fixes, but also a number of late updates
      such as the reworking of the call-chain size limiting logic to make
      call-graph recording more robust, plus tooling side changes for the
      new 'backwards ring-buffer' extension to the perf ring-buffer"
    
    * 'perf-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (34 commits)
      perf record: Read from backward ring buffer
      perf record: Rename variable to make code clear
      perf record: Prevent reading invalid data in record__mmap_read
      perf evlist: Add API to pause/resume
      perf trace: Use the ptr->name beautifier as default for "filename" args
      perf trace: Use the fd->name beautifier as default for "fd" args
      perf report: Add srcline_from/to branch sort keys
      perf evsel: Record fd into perf_mmap
      perf evsel: Add overwrite attribute and check write_backward
      perf tools: Set buildid dir under symfs when --symfs is provided
      perf trace: Only auto set call-graph to "dwarf" when syscalls are being traced
      perf annotate: Sort list of recognised instructions
      perf annotate: Fix identification of ARM blt and bls instructions
      perf tools: Fix usage of max_stack sysctl
      perf callchain: Stop validating callchains by the max_stack sysctl
      perf trace: Fix exit_group() formatting
      perf top: Use machine->kptr_restrict_warned
      perf trace: Warn when trying to resolve kernel addresses with kptr_restrict=1
      perf machine: Do not bail out if not managing to read ref reloc symbol
      perf/x86/intel/p4: Trival indentation fix, remove space
      ...

commit bf8bddbf1971d40549f33bc6f70623cf53bbfa2f
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu May 19 11:14:15 2016 -0300

    perf callchain: Stop validating callchains by the max_stack sysctl
    
    As thread__resolve_callchain_sample can be used for handling perf.data
    files, that could've been recorded with a large max_stack sysctl setting
    than what the system used for analysis has set.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Alexei Starovoitov <ast@kernel.org>
    Cc: Brendan Gregg <brendan.d.gregg@gmail.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: He Kuang <hekuang@huawei.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Milian Wolff <milian.wolff@kdab.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vince Weaver <vincent.weaver@maine.edu>
    Cc: Wang Nan <wangnan0@huawei.com>
    Cc: Zefan Li <lizefan@huawei.com>
    Link: http://lkml.kernel.org/n/tip-2995bt2g5yq2m05vga4kip6m@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index bdc33ce40bdc..205d27017361 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1771,11 +1771,6 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 		 */
 		int mix_chain_nr = i + 1 + lbr_nr + 1;
 
-		if (mix_chain_nr > (int)sysctl_perf_event_max_stack + PERF_MAX_BRANCH_DEPTH) {
-			pr_warning("corrupted callchain. skipping...\n");
-			return 0;
-		}
-
 		for (j = 0; j < mix_chain_nr; j++) {
 			if (callchain_param.order == ORDER_CALLEE) {
 				if (j < i + 1)
@@ -1815,7 +1810,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	struct ip_callchain *chain = sample->callchain;
 	int chain_nr = chain->nr;
 	u8 cpumode = PERF_RECORD_MISC_USER;
-	int i, j, err, nr_entries, nr_contexts;
+	int i, j, err, nr_entries;
 	int skip_idx = -1;
 	int first_call = 0;
 
@@ -1830,8 +1825,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	 * Based on DWARF debug information, some architectures skip
 	 * a callchain entry saved by the kernel.
 	 */
-	if (chain_nr < sysctl_perf_event_max_stack)
-		skip_idx = arch_skip_callchain_idx(thread, chain);
+	skip_idx = arch_skip_callchain_idx(thread, chain);
 
 	/*
 	 * Add branches to call stack for easier browsing. This gives
@@ -1891,7 +1885,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	}
 
 check_calls:
-	for (i = first_call, nr_entries = 0, nr_contexts = 0;
+	for (i = first_call, nr_entries = 0;
 	     i < chain_nr && nr_entries < max_stack; i++) {
 		u64 ip;
 
@@ -1906,13 +1900,8 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 #endif
 		ip = chain->ips[j];
 
-		if (ip >= PERF_CONTEXT_MAX) {
-			if (++nr_contexts > sysctl_perf_event_max_contexts_per_stack)
-				goto out_corrupted_callchain;
-		} else {
-			if (++nr_entries > sysctl_perf_event_max_stack)
-				goto out_corrupted_callchain;
-		}
+		if (ip < PERF_CONTEXT_MAX)
+                       ++nr_entries;
 
 		err = add_callchain_ip(thread, cursor, parent, root_al, &cpumode, ip);
 
@@ -1921,10 +1910,6 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	}
 
 	return 0;
-
-out_corrupted_callchain:
-	pr_warning("corrupted callchain. skipping...\n");
-	return 0;
 }
 
 static int unwind_entry(struct unwind_entry *entry, void *arg)

commit caf8a0d0499792ac1b3f5b0b84e5890df0039cb6
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue May 17 11:56:24 2016 -0300

    perf trace: Warn when trying to resolve kernel addresses with kptr_restrict=1
    
    Hook into the libtraceevent plugin kernel symbol resolver to warn the
    user that that can't happen with kptr_restrict=1.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Milian Wolff <milian.wolff@kdab.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-9gc412xx1gl0lvqj1d1xwlyb@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index b277984aaa93..bdc33ce40bdc 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -43,6 +43,7 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 
 	machine->symbol_filter = NULL;
 	machine->id_hdr_size = 0;
+	machine->kptr_restrict_warned = false;
 	machine->comm_exec = false;
 	machine->kernel_start = 0;
 

commit 45e90056904b12d8dd74e0d2ea6dfd5e4394104d
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue May 17 11:52:26 2016 -0300

    perf machine: Do not bail out if not managing to read ref reloc symbol
    
    This means the user can't access /proc/kallsyms, for instance, because
    /proc/sys/kernel/kptr_restrict is set to 1.
    
    Instead leave the ref_reloc_sym as NULL and code using it will cope.
    
    This allows 'perf trace' to work on such systems for !root, the only
    issue would be when trying to resolve kernel symbols, which happens,
    for instance, in some libtracevent plugins.  A warning for that case
    will be provided in the next patch in this series.
    
    Noticed in Ubuntu 16.04, that comes with kptr_restrict=1.
    
    Reported-by: Milian Wolff <milian.wolff@kdab.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-knpu3z4iyp2dxpdfm798fac4@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 7ba9fadb68af..b277984aaa93 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1135,10 +1135,10 @@ int machine__create_kernel_maps(struct machine *machine)
 {
 	struct dso *kernel = machine__get_kernel(machine);
 	const char *name;
-	u64 addr = machine__get_running_kernel_start(machine, &name);
+	u64 addr;
 	int ret;
 
-	if (!addr || kernel == NULL)
+	if (kernel == NULL)
 		return -1;
 
 	ret = __machine__create_kernel_maps(machine, kernel);
@@ -1160,8 +1160,9 @@ int machine__create_kernel_maps(struct machine *machine)
 	 */
 	map_groups__fixup_end(&machine->kmaps);
 
-	if (maps__set_kallsyms_ref_reloc_sym(machine->vmlinux_maps, name,
-					     addr)) {
+	addr = machine__get_running_kernel_start(machine, &name);
+	if (!addr) {
+	} else if (maps__set_kallsyms_ref_reloc_sym(machine->vmlinux_maps, name, addr)) {
 		machine__destroy_kernel_maps(machine);
 		return -1;
 	}

commit 16bf8348055fe4615bd08ef50f9874f5dcc10268
Merge: a7fd20d1c476 52bbe141f37f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue May 17 17:05:30 2016 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/trivial
    
    Pull trivial tree updates from Jiri Kosina.
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/trivial: (21 commits)
      gitignore: fix wording
      mfd: ab8500-debugfs: fix "between" in printk
      memstick: trivial fix of spelling mistake on management
      cpupowerutils: bench: fix "average"
      treewide: Fix typos in printk
      IB/mlx4: printk fix
      pinctrl: sirf/atlas7: fix printk spelling
      serial: mctrl_gpio: Grammar s/lines GPIOs/line GPIOs/, /sets/set/
      w1: comment spelling s/minmum/minimum/
      Blackfin: comment spelling s/divsor/divisor/
      metag: Fix misspellings in comments.
      ia64: Fix misspellings in comments.
      hexagon: Fix misspellings in comments.
      tools/perf: Fix misspellings in comments.
      cris: Fix misspellings in comments.
      c6x: Fix misspellings in comments.
      blackfin: Fix misspelling of 'register' in comment.
      avr32: Fix misspelling of 'definitions' in comment.
      treewide: Fix typos in printk
      Doc: treewide : Fix typos in DocBook/filesystem.xml
      ...

commit a29d5c9b8167dbc21a7ca8c0302e3799f9063b4e
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon May 16 21:16:54 2016 -0300

    perf tools: Separate accounting of contexts and real addresses in a stack trace
    
    The perf_sample->ip_callchain->nr value includes all the entries in the
    ip_callchain->ip[] array, real addresses and PERF_CONTEXT_{KERNEL,USER,etc},
    while what the user expects is that what is in the kernel.perf_event_max_stack
    sysctl or in the upcoming per event perf_event_attr.sample_max_stack knob be
    honoured in terms of IP addresses in the stack trace.
    
    So match the kernel support and validate chain->nr taking into account
    both kernel.perf_event_max_stack and kernel.perf_event_max_contexts_per_stack.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Alexei Starovoitov <ast@kernel.org>
    Cc: Brendan Gregg <brendan.d.gregg@gmail.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: He Kuang <hekuang@huawei.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Milian Wolff <milian.wolff@kdab.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vince Weaver <vincent.weaver@maine.edu>
    Cc: Wang Nan <wangnan0@huawei.com>
    Cc: Zefan Li <lizefan@huawei.com>
    Link: http://lkml.kernel.org/n/tip-mgx0jpzfdq4uq4abfa40byu0@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 18dd96bdde05..7ba9fadb68af 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1811,9 +1811,9 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 {
 	struct branch_stack *branch = sample->branch_stack;
 	struct ip_callchain *chain = sample->callchain;
-	int chain_nr = min(max_stack, (int)chain->nr);
+	int chain_nr = chain->nr;
 	u8 cpumode = PERF_RECORD_MISC_USER;
-	int i, j, err;
+	int i, j, err, nr_entries, nr_contexts;
 	int skip_idx = -1;
 	int first_call = 0;
 
@@ -1828,7 +1828,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	 * Based on DWARF debug information, some architectures skip
 	 * a callchain entry saved by the kernel.
 	 */
-	if (chain->nr < sysctl_perf_event_max_stack)
+	if (chain_nr < sysctl_perf_event_max_stack)
 		skip_idx = arch_skip_callchain_idx(thread, chain);
 
 	/*
@@ -1889,12 +1889,8 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	}
 
 check_calls:
-	if (chain->nr > sysctl_perf_event_max_stack && (int)chain->nr > max_stack) {
-		pr_warning("corrupted callchain. skipping...\n");
-		return 0;
-	}
-
-	for (i = first_call; i < chain_nr; i++) {
+	for (i = first_call, nr_entries = 0, nr_contexts = 0;
+	     i < chain_nr && nr_entries < max_stack; i++) {
 		u64 ip;
 
 		if (callchain_param.order == ORDER_CALLEE)
@@ -1908,6 +1904,14 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 #endif
 		ip = chain->ips[j];
 
+		if (ip >= PERF_CONTEXT_MAX) {
+			if (++nr_contexts > sysctl_perf_event_max_contexts_per_stack)
+				goto out_corrupted_callchain;
+		} else {
+			if (++nr_entries > sysctl_perf_event_max_stack)
+				goto out_corrupted_callchain;
+		}
+
 		err = add_callchain_ip(thread, cursor, parent, root_al, &cpumode, ip);
 
 		if (err)
@@ -1915,6 +1919,10 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	}
 
 	return 0;
+
+out_corrupted_callchain:
+	pr_warning("corrupted callchain. skipping...\n");
+	return 0;
 }
 
 static int unwind_entry(struct unwind_entry *entry, void *arg)

commit 0a77582f0407e7f9b5d775bebc31297a1b890be0
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Sun May 15 12:19:40 2016 +0900

    perf symbols: Introduce DSO__NAME_KALLSYMS and DSO__NAME_KCORE
    
    Instead of using a raw string, use DSO__NAME_KALLSYMS and
    DSO__NAME_KCORE macros for kallsyms and kcore.
    
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Ananth N Mavinakayanahalli <ananth@linux.vnet.ibm.com>
    Cc: Brendan Gregg <brendan.d.gregg@gmail.com>
    Cc: Hemant Kumar <hemant@linux.vnet.ibm.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20160515031935.4017.50971.stgit@devbox
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 639a2903065e..18dd96bdde05 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -709,7 +709,7 @@ static struct dso *machine__get_kernel(struct machine *machine)
 	if (machine__is_host(machine)) {
 		vmlinux_name = symbol_conf.vmlinux_name;
 		if (!vmlinux_name)
-			vmlinux_name = "[kernel.kallsyms]";
+			vmlinux_name = DSO__NAME_KALLSYMS;
 
 		kernel = machine__findnew_kernel(machine, vmlinux_name,
 						 "[kernel]", DSO_TYPE_KERNEL);

commit 9919a65ec532799544dfdfd6df6f994b74c12b42
Author: Chris Phlipot <cphlipot0@gmail.com>
Date:   Thu Apr 28 01:19:06 2016 -0700

    perf callchain: Fix incorrect ordering of entries
    
    The existing implementation of thread__resolve_callchain, under certain
    circumstances, can assemble callchain entries in the incorrect order.
    
    The callchain entries are resolved incorrectly for a sample when all of
    the following conditions are met:
    
    1. callchain_param.order is set to ORDER_CALLER
    
    2. thread__resolve_callchain_sample is able to resolve callchain entries
       for the sample.
    
    3. unwind__get_entries is also able to resolve callchain entries for the
       sample.
    
    The fix is accomplished by reversing the order in which
    thread__resolve_callchain_sample and unwind__get_entries are called when
    callchain_param.order is set to ORDER_CALLER.
    
    Unwind specific code from thread__resolve_callchain is also moved into a
    new static function to improve readability of the fix.
    
    How to Reproduce the Existing Bug:
    
    Modifying perf script to print call trees in the opposite order or
    applying the remaining patches from this series and comparing the
    results output from export-to-postgtresql.py are the easiest ways to see
    the bug, however it can still be seen in current builds using perf
    report.
    
    Here is how i can reproduce the bug using perf report:
    
      # perf record --call-graph=dwarf stress -c 1 -t 5
    
    when i run this command:
    
      # perf report --call-graph=flat,0,0,callee
    
    This callchain, containing kernel (handle_irq_event, etc) and userspace
    samples (__libc_start_main, etc) is contained in the output, which looks
    correct (callee order):
    
                    gen8_irq_handler
                    handle_irq_event_percpu
                    handle_irq_event
                    handle_edge_irq
                    handle_irq
                    do_IRQ
                    ret_from_intr
                    __random
                    rand
                    0x558f2a04dded
                    0x558f2a04c774
                    __libc_start_main
                    0x558f2a04dcd9
    
    Now run this command using caller order:
    
      # perf report --call-graph=flat,0,0,caller
    
    It is expected to see the exact reverse of the above when using caller
    order (with "0x558f2a04dcd9" at the top and "gen8_irq_handler" at the
    bottom) in the output, but it is nowhere to be found.
    
    instead you see this:
    
                    ret_from_intr
                    do_IRQ
                    handle_irq
                    handle_edge_irq
                    handle_irq_event
                    handle_irq_event_percpu
                    gen8_irq_handler
                    0x558f2a04dcd9
                    __libc_start_main
                    0x558f2a04c774
                    0x558f2a04dded
                    rand
                    __random
    
    Notice how internally the kernel symbols are reversed and the user space
    symbols are reversed, but the kernel symbols still appear above the user
    space symbols.
    
    if this patch is applied and perf script is re-run, you will see the
    expected output (with "0x558f2a04dcd9" at the top and "gen8_irq_handler"
    at the bottom):
    
                    0x558f2a04dcd9
                    __libc_start_main
                    0x558f2a04c774
                    0x558f2a04dded
                    rand
                    __random
                    ret_from_intr
                    do_IRQ
                    handle_irq
                    handle_edge_irq
                    handle_irq_event
                    handle_irq_event_percpu
                    gen8_irq_handler
    
    Signed-off-by: Chris Phlipot <cphlipot0@gmail.com>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1461831551-12213-2-git-send-email-cphlipot0@gmail.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 8c7bf4dbd479..639a2903065e 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1817,8 +1817,6 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	int skip_idx = -1;
 	int first_call = 0;
 
-	callchain_cursor_reset(cursor);
-
 	if (perf_evsel__has_branch_callstack(evsel)) {
 		err = resolve_lbr_callchain_sample(thread, cursor, sample, parent,
 						   root_al, max_stack);
@@ -1929,20 +1927,12 @@ static int unwind_entry(struct unwind_entry *entry, void *arg)
 				       entry->map, entry->sym);
 }
 
-int thread__resolve_callchain(struct thread *thread,
-			      struct callchain_cursor *cursor,
-			      struct perf_evsel *evsel,
-			      struct perf_sample *sample,
-			      struct symbol **parent,
-			      struct addr_location *root_al,
-			      int max_stack)
+static int thread__resolve_callchain_unwind(struct thread *thread,
+					    struct callchain_cursor *cursor,
+					    struct perf_evsel *evsel,
+					    struct perf_sample *sample,
+					    int max_stack)
 {
-	int ret = thread__resolve_callchain_sample(thread, cursor, evsel,
-						   sample, parent,
-						   root_al, max_stack);
-	if (ret)
-		return ret;
-
 	/* Can we do dwarf post unwind? */
 	if (!((evsel->attr.sample_type & PERF_SAMPLE_REGS_USER) &&
 	      (evsel->attr.sample_type & PERF_SAMPLE_STACK_USER)))
@@ -1955,7 +1945,43 @@ int thread__resolve_callchain(struct thread *thread,
 
 	return unwind__get_entries(unwind_entry, cursor,
 				   thread, sample, max_stack);
+}
 
+int thread__resolve_callchain(struct thread *thread,
+			      struct callchain_cursor *cursor,
+			      struct perf_evsel *evsel,
+			      struct perf_sample *sample,
+			      struct symbol **parent,
+			      struct addr_location *root_al,
+			      int max_stack)
+{
+	int ret = 0;
+
+	callchain_cursor_reset(&callchain_cursor);
+
+	if (callchain_param.order == ORDER_CALLEE) {
+		ret = thread__resolve_callchain_sample(thread, cursor,
+						       evsel, sample,
+						       parent, root_al,
+						       max_stack);
+		if (ret)
+			return ret;
+		ret = thread__resolve_callchain_unwind(thread, cursor,
+						       evsel, sample,
+						       max_stack);
+	} else {
+		ret = thread__resolve_callchain_unwind(thread, cursor,
+						       evsel, sample,
+						       max_stack);
+		if (ret)
+			return ret;
+		ret = thread__resolve_callchain_sample(thread, cursor,
+						       evsel, sample,
+						       parent, root_al,
+						       max_stack);
+	}
+
+	return ret;
 }
 
 int machine__for_each_thread(struct machine *machine,

commit de7e6a7c8bf9ee46dcbee749bc3cdd0d9c21998a
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Tue May 3 13:54:43 2016 +0200

    perf hists: Move sort__has_parent into struct perf_hpp_list
    
    Now we have sort dimensions private for struct hists, we need to make
    dimension booleans hists specific as well.
    
    Moving sort__has_parent into struct perf_hpp_list.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1462276488-26683-3-git-send-email-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 9d0913107dc7..8c7bf4dbd479 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1652,7 +1652,7 @@ static int add_callchain_ip(struct thread *thread,
 	}
 
 	if (al.sym != NULL) {
-		if (sort__has_parent && !*parent &&
+		if (perf_hpp_list.parent && !*parent &&
 		    symbol__match_regex(al.sym, &parent_regex))
 			*parent = al.sym;
 		else if (have_ignore_callees && root_al &&

commit d2c11034406733374d1cdc588c53bb076d95a4e2
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed May 4 10:09:33 2016 -0300

    perf machine: Introduce number of threads member
    
    To be used, for instance, for pre-allocating an rb_tree array for
    sorting by other keys besides the current pid one.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Milian Wolff <milian.wolff@kdab.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-ja0ifkwue7ttjhbwijn6g6eu@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 2cb95bbf9ea6..9d0913107dc7 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -32,6 +32,7 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 
 	machine->threads = RB_ROOT;
 	pthread_rwlock_init(&machine->threads_lock, NULL);
+	machine->nr_threads = 0;
 	INIT_LIST_HEAD(&machine->dead_threads);
 	machine->last_match = NULL;
 
@@ -430,6 +431,7 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 		 */
 		thread__get(th);
 		machine->last_match = th;
+		++machine->nr_threads;
 	}
 
 	return th;
@@ -681,11 +683,13 @@ size_t machine__fprintf_vmlinux_path(struct machine *machine, FILE *fp)
 
 size_t machine__fprintf(struct machine *machine, FILE *fp)
 {
-	size_t ret = 0;
+	size_t ret;
 	struct rb_node *nd;
 
 	pthread_rwlock_rdlock(&machine->threads_lock);
 
+	ret = fprintf(fp, "Threads: %u\n", machine->nr_threads);
+
 	for (nd = rb_first(&machine->threads); nd; nd = rb_next(nd)) {
 		struct thread *pos = rb_entry(nd, struct thread, rb_node);
 
@@ -1419,6 +1423,7 @@ static void __machine__remove_thread(struct machine *machine, struct thread *th,
 		pthread_rwlock_wrlock(&machine->threads_lock);
 	rb_erase_init(&th->rb_node, &machine->threads);
 	RB_CLEAR_NODE(&th->rb_node);
+	--machine->nr_threads;
 	/*
 	 * Move it first to the dead_threads list, then drop the reference,
 	 * if this is the last reference, then the thread__delete destructor

commit 4cb93446c587d56e2a54f4f83113daba2c0b6dee
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Apr 27 10:16:24 2016 -0300

    perf tools: Set the maximum allowed stack from /proc/sys/kernel/perf_event_max_stack
    
    There is an upper limit to what tooling considers a valid callchain,
    and it was tied to the hardcoded value in the kernel,
    PERF_MAX_STACK_DEPTH (127), now that this can be tuned via a sysctl,
    make it read it and use that as the upper limit, falling back to
    PERF_MAX_STACK_DEPTH for kernels where this sysctl isn't present.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Brendan Gregg <brendan.d.gregg@gmail.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Milian Wolff <milian.wolff@kdab.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-yjqsd30nnkogvj5oyx9ghir9@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 656c1d7ee7d4..2cb95bbf9ea6 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1764,7 +1764,7 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 		 */
 		int mix_chain_nr = i + 1 + lbr_nr + 1;
 
-		if (mix_chain_nr > PERF_MAX_STACK_DEPTH + PERF_MAX_BRANCH_DEPTH) {
+		if (mix_chain_nr > (int)sysctl_perf_event_max_stack + PERF_MAX_BRANCH_DEPTH) {
 			pr_warning("corrupted callchain. skipping...\n");
 			return 0;
 		}
@@ -1825,7 +1825,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	 * Based on DWARF debug information, some architectures skip
 	 * a callchain entry saved by the kernel.
 	 */
-	if (chain->nr < PERF_MAX_STACK_DEPTH)
+	if (chain->nr < sysctl_perf_event_max_stack)
 		skip_idx = arch_skip_callchain_idx(thread, chain);
 
 	/*
@@ -1886,7 +1886,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	}
 
 check_calls:
-	if (chain->nr > PERF_MAX_STACK_DEPTH && (int)chain->nr > max_stack) {
+	if (chain->nr > sysctl_perf_event_max_stack && (int)chain->nr > max_stack) {
 		pr_warning("corrupted callchain. skipping...\n");
 		return 0;
 	}

commit e02092b9a922f17e951b2df5f12f4aafe7383a21
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Apr 19 12:12:49 2016 -0300

    perf symbols: Allow loading kallsyms without considering kcore files
    
    Before the support for using /proc/kcore was introduced, the kallsyms
    routines used /proc/modules and the first 'perf test' entry expected
    finding maps for each module in the system, which is not the case with
    the kcore code. Provide a way to ignore kcore files so that the test can
    have its expectations met.
    
    Improving the test to cover kcore files as well needs to be done.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-ek5urnu103dlhfk4l6pcw041@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 52b51e004fe8..656c1d7ee7d4 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -908,11 +908,11 @@ int machines__create_kernel_maps(struct machines *machines, pid_t pid)
 	return machine__create_kernel_maps(machine);
 }
 
-int machine__load_kallsyms(struct machine *machine, const char *filename,
-			   enum map_type type, symbol_filter_t filter)
+int __machine__load_kallsyms(struct machine *machine, const char *filename,
+			     enum map_type type, bool no_kcore, symbol_filter_t filter)
 {
 	struct map *map = machine__kernel_map(machine);
-	int ret = dso__load_kallsyms(map->dso, filename, map, filter);
+	int ret = __dso__load_kallsyms(map->dso, filename, map, no_kcore, filter);
 
 	if (ret > 0) {
 		dso__set_loaded(map->dso, type);
@@ -927,6 +927,12 @@ int machine__load_kallsyms(struct machine *machine, const char *filename,
 	return ret;
 }
 
+int machine__load_kallsyms(struct machine *machine, const char *filename,
+			   enum map_type type, symbol_filter_t filter)
+{
+	return __machine__load_kallsyms(machine, filename, type, false, filter);
+}
+
 int machine__load_vmlinux_path(struct machine *machine, enum map_type type,
 			       symbol_filter_t filter)
 {

commit acf2abbd0b7fcc6325e9690a8a32ee924c827f70
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Apr 18 10:35:03 2016 -0300

    perf evsel: Add missign class prefix to has_branch_stack method
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Milian Wolff <milian.wolff@kdab.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-5i07ivw1yjsweb7gztr255jd@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 0c4dabc69932..52b51e004fe8 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1808,7 +1808,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 
 	callchain_cursor_reset(cursor);
 
-	if (has_branch_callstack(evsel)) {
+	if (perf_evsel__has_branch_callstack(evsel)) {
 		err = resolve_lbr_callchain_sample(thread, cursor, sample, parent,
 						   root_al, max_stack);
 		if (err)

commit bd1a0be5154788a052c6b851dbfa97bcd71f21d6
Author: Adam Buchbinder <adam.buchbinder@gmail.com>
Date:   Wed Feb 24 10:02:25 2016 -0800

    tools/perf: Fix misspellings in comments.
    
    Signed-off-by: Adam Buchbinder <adam.buchbinder@gmail.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 80b9b6a87990..2fa6d25b94bf 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -361,7 +361,7 @@ static void machine__update_thread_pid(struct machine *machine,
 }
 
 /*
- * Caller must eventually drop thread->refcnt returned with a successfull
+ * Caller must eventually drop thread->refcnt returned with a successful
  * lookup/new thread inserted.
  */
 static struct thread *____machine__findnew_thread(struct machine *machine,

commit 91d7b2de318ff701451dfc7ede1c029b150ef0e9
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Apr 14 14:48:07 2016 -0300

    perf callchain: Start moving away from global per thread cursors
    
    The recent perf_evsel__fprintf_callchain() move to evsel.c added several
    new symbol requirements to the python binding, for instance:
    
      # perf test -v python
      16: Try 'import perf' in python, checking link problems      :
      --- start ---
      test child forked, pid 18030
      Traceback (most recent call last):
        File "<stdin>", line 1, in <module>
      ImportError: /tmp/build/perf/python/perf.so: undefined symbol:
      callchain_cursor
      test child finished with -1
      ---- end ----
      Try 'import perf' in python, checking link problems: FAILED!
      #
    
    This would require linking against callchain.c to access to the global
    callchain_cursor variables.
    
    Since lots of functions already receive as a parameter a
    callchain_cursor struct pointer, make that be the case for some more
    function so that we can start phasing out usage of yet another global
    variable.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-djko3097eyg2rn66v2qcqfvn@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 80b9b6a87990..0c4dabc69932 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1599,6 +1599,7 @@ struct mem_info *sample__resolve_mem(struct perf_sample *sample,
 }
 
 static int add_callchain_ip(struct thread *thread,
+			    struct callchain_cursor *cursor,
 			    struct symbol **parent,
 			    struct addr_location *root_al,
 			    u8 *cpumode,
@@ -1630,7 +1631,7 @@ static int add_callchain_ip(struct thread *thread,
 				 * It seems the callchain is corrupted.
 				 * Discard all.
 				 */
-				callchain_cursor_reset(&callchain_cursor);
+				callchain_cursor_reset(cursor);
 				return 1;
 			}
 			return 0;
@@ -1648,13 +1649,13 @@ static int add_callchain_ip(struct thread *thread,
 			/* Treat this symbol as the root,
 			   forgetting its callees. */
 			*root_al = al;
-			callchain_cursor_reset(&callchain_cursor);
+			callchain_cursor_reset(cursor);
 		}
 	}
 
 	if (symbol_conf.hide_unresolved && al.sym == NULL)
 		return 0;
-	return callchain_cursor_append(&callchain_cursor, al.addr, al.map, al.sym);
+	return callchain_cursor_append(cursor, al.addr, al.map, al.sym);
 }
 
 struct branch_info *sample__resolve_bstack(struct perf_sample *sample,
@@ -1724,6 +1725,7 @@ static int remove_loops(struct branch_entry *l, int nr)
  * negative error code on other errors.
  */
 static int resolve_lbr_callchain_sample(struct thread *thread,
+					struct callchain_cursor *cursor,
 					struct perf_sample *sample,
 					struct symbol **parent,
 					struct addr_location *root_al,
@@ -1778,7 +1780,7 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 					ip = lbr_stack->entries[0].to;
 			}
 
-			err = add_callchain_ip(thread, parent, root_al, &cpumode, ip);
+			err = add_callchain_ip(thread, cursor, parent, root_al, &cpumode, ip);
 			if (err)
 				return (err < 0) ? err : 0;
 		}
@@ -1789,6 +1791,7 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 }
 
 static int thread__resolve_callchain_sample(struct thread *thread,
+					    struct callchain_cursor *cursor,
 					    struct perf_evsel *evsel,
 					    struct perf_sample *sample,
 					    struct symbol **parent,
@@ -1803,10 +1806,10 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	int skip_idx = -1;
 	int first_call = 0;
 
-	callchain_cursor_reset(&callchain_cursor);
+	callchain_cursor_reset(cursor);
 
 	if (has_branch_callstack(evsel)) {
-		err = resolve_lbr_callchain_sample(thread, sample, parent,
+		err = resolve_lbr_callchain_sample(thread, cursor, sample, parent,
 						   root_al, max_stack);
 		if (err)
 			return (err < 0) ? err : 0;
@@ -1863,10 +1866,10 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 		nr = remove_loops(be, nr);
 
 		for (i = 0; i < nr; i++) {
-			err = add_callchain_ip(thread, parent, root_al,
+			err = add_callchain_ip(thread, cursor, parent, root_al,
 					       NULL, be[i].to);
 			if (!err)
-				err = add_callchain_ip(thread, parent, root_al,
+				err = add_callchain_ip(thread, cursor, parent, root_al,
 						       NULL, be[i].from);
 			if (err == -EINVAL)
 				break;
@@ -1896,7 +1899,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 #endif
 		ip = chain->ips[j];
 
-		err = add_callchain_ip(thread, parent, root_al, &cpumode, ip);
+		err = add_callchain_ip(thread, cursor, parent, root_al, &cpumode, ip);
 
 		if (err)
 			return (err < 0) ? err : 0;
@@ -1916,13 +1919,14 @@ static int unwind_entry(struct unwind_entry *entry, void *arg)
 }
 
 int thread__resolve_callchain(struct thread *thread,
+			      struct callchain_cursor *cursor,
 			      struct perf_evsel *evsel,
 			      struct perf_sample *sample,
 			      struct symbol **parent,
 			      struct addr_location *root_al,
 			      int max_stack)
 {
-	int ret = thread__resolve_callchain_sample(thread, evsel,
+	int ret = thread__resolve_callchain_sample(thread, cursor, evsel,
 						   sample, parent,
 						   root_al, max_stack);
 	if (ret)
@@ -1938,7 +1942,7 @@ int thread__resolve_callchain(struct thread *thread,
 	    (!sample->user_stack.size))
 		return 0;
 
-	return unwind__get_entries(unwind_entry, &callchain_cursor,
+	return unwind__get_entries(unwind_entry, cursor,
 				   thread, sample, max_stack);
 
 }

commit 473398a21d28c089555117a8db4ea04e371dd03c
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Mar 22 18:23:43 2016 -0300

    perf tools: Add cpumode to struct perf_sample
    
    To avoid parsing event->header.misc in many locations.
    
    This will also allow setting perf.sample.{ip,cpumode} in a single place,
    from tracepoint fields, as needed by 'perf kvm' with PPC guests, where
    the guest hardware counters is not available at the host.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Hemant Kumar <hemant@linux.vnet.ibm.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Cc: Ravi Bangoria <ravi.bangoria@linux.vnet.ibm.com>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-qp3yradhyt6q3wl895b1aat0@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index ad79297c76c8..80b9b6a87990 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1301,9 +1301,8 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 
 int machine__process_mmap2_event(struct machine *machine,
 				 union perf_event *event,
-				 struct perf_sample *sample __maybe_unused)
+				 struct perf_sample *sample)
 {
-	u8 cpumode = event->header.misc & PERF_RECORD_MISC_CPUMODE_MASK;
 	struct thread *thread;
 	struct map *map;
 	enum map_type type;
@@ -1312,8 +1311,8 @@ int machine__process_mmap2_event(struct machine *machine,
 	if (dump_trace)
 		perf_event__fprintf_mmap2(event, stdout);
 
-	if (cpumode == PERF_RECORD_MISC_GUEST_KERNEL ||
-	    cpumode == PERF_RECORD_MISC_KERNEL) {
+	if (sample->cpumode == PERF_RECORD_MISC_GUEST_KERNEL ||
+	    sample->cpumode == PERF_RECORD_MISC_KERNEL) {
 		ret = machine__process_kernel_mmap_event(machine, event);
 		if (ret < 0)
 			goto out_problem;
@@ -1355,9 +1354,8 @@ int machine__process_mmap2_event(struct machine *machine,
 }
 
 int machine__process_mmap_event(struct machine *machine, union perf_event *event,
-				struct perf_sample *sample __maybe_unused)
+				struct perf_sample *sample)
 {
-	u8 cpumode = event->header.misc & PERF_RECORD_MISC_CPUMODE_MASK;
 	struct thread *thread;
 	struct map *map;
 	enum map_type type;
@@ -1366,8 +1364,8 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 	if (dump_trace)
 		perf_event__fprintf_mmap(event, stdout);
 
-	if (cpumode == PERF_RECORD_MISC_GUEST_KERNEL ||
-	    cpumode == PERF_RECORD_MISC_KERNEL) {
+	if (sample->cpumode == PERF_RECORD_MISC_GUEST_KERNEL ||
+	    sample->cpumode == PERF_RECORD_MISC_KERNEL) {
 		ret = machine__process_kernel_mmap_event(machine, event);
 		if (ret < 0)
 			goto out_problem;

commit abd828688407eb86044f1bc9e5133c55d7597596
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri Dec 11 19:11:23 2015 -0300

    perf thread: Fix reference count initial state
    
    We should always return from thread__new(), the constructor, with the
    object with a reference count of one, so that:
    
         struct thread *thread = thread__new();
         thread__put(thread);
    
    Will call thread__delete().
    
    If any reference is made to that 'thread' variable, it better use
    thread__get(thread) to hold a reference.
    
    We were returning with thread->refcnt set to zero, fix it and some cases
    where thread__delete() was being called, which were not a problem
    because just one reference was being used, now that we set it to 1, use
    thread__put() instead.
    
    Reported-by: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-4b9mkuk66to4ecckpmpvqx6s@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 1407d5107480..ad79297c76c8 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -352,13 +352,18 @@ static void machine__update_thread_pid(struct machine *machine,
 	}
 
 	th->mg = map_groups__get(leader->mg);
-
+out_put:
+	thread__put(leader);
 	return;
-
 out_err:
 	pr_err("Failed to join map groups for %d:%d\n", th->pid_, th->tid);
+	goto out_put;
 }
 
+/*
+ * Caller must eventually drop thread->refcnt returned with a successfull
+ * lookup/new thread inserted.
+ */
 static struct thread *____machine__findnew_thread(struct machine *machine,
 						  pid_t pid, pid_t tid,
 						  bool create)
@@ -376,7 +381,7 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 	if (th != NULL) {
 		if (th->tid == tid) {
 			machine__update_thread_pid(machine, th, pid);
-			return th;
+			return thread__get(th);
 		}
 
 		machine->last_match = NULL;
@@ -389,7 +394,7 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 		if (th->tid == tid) {
 			machine->last_match = th;
 			machine__update_thread_pid(machine, th, pid);
-			return th;
+			return thread__get(th);
 		}
 
 		if (tid < th->tid)
@@ -417,7 +422,7 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 		if (thread__init_map_groups(th, machine)) {
 			rb_erase_init(&th->rb_node, &machine->threads);
 			RB_CLEAR_NODE(&th->rb_node);
-			thread__delete(th);
+			thread__put(th);
 			return NULL;
 		}
 		/*
@@ -441,7 +446,7 @@ struct thread *machine__findnew_thread(struct machine *machine, pid_t pid,
 	struct thread *th;
 
 	pthread_rwlock_wrlock(&machine->threads_lock);
-	th = thread__get(__machine__findnew_thread(machine, pid, tid));
+	th = __machine__findnew_thread(machine, pid, tid);
 	pthread_rwlock_unlock(&machine->threads_lock);
 	return th;
 }
@@ -451,7 +456,7 @@ struct thread *machine__find_thread(struct machine *machine, pid_t pid,
 {
 	struct thread *th;
 	pthread_rwlock_rdlock(&machine->threads_lock);
-	th =  thread__get(____machine__findnew_thread(machine, pid, tid, false));
+	th =  ____machine__findnew_thread(machine, pid, tid, false);
 	pthread_rwlock_unlock(&machine->threads_lock);
 	return th;
 }

commit 93b0ba3c60da89043ce2b9f601cd2b3da408903b
Author: Wang Nan <wangnan0@huawei.com>
Date:   Tue Dec 8 02:25:44 2015 +0000

    perf tools: Clear struct machine during machine__init()
    
    There are so many test cases use stack allocated 'struct machine'.
    Including:
      test__hists_link
      test__hists_filter
      test__mmap_thread_lookup
      test__thread_mg_share
      test__hists_output
      test__hists_cumulate
    
    Also, in non-test code (for example, machine__new_host()) there are
    code use 'malloc()' to alloc struct machine.
    
    These are dangerous operations, cause some tests fail or hung in
    machines__exit(). For example, in
    
     machines__exit ->
       machine__destroy_kernel_maps ->
         map_groups__remove ->
           maps__remove ->
             pthread_rwlock_wrlock
    
    a incorrectly initialized lock causes unintended behavior.
    
    This patch memset(0) that structure in machine__init() to ensure all
    fields in 'struct machine' are initialized to zero.
    
    Signed-off-by: Wang Nan <wangnan0@huawei.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Zefan Li <lizefan@huawei.com>
    Cc: pi3orama@163.com
    Link: http://lkml.kernel.org/r/1449541544-67621-17-git-send-email-wangnan0@huawei.com
    [ Use memset, see 'man bzero' ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index f5882b8c8db9..1407d5107480 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -25,6 +25,7 @@ static void dsos__init(struct dsos *dsos)
 
 int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 {
+	memset(machine, 0, sizeof(*machine));
 	map_groups__init(&machine->kmaps, machine);
 	RB_CLEAR_NODE(&machine->rb_node);
 	dsos__init(&machine->dsos);

commit cc1121ab9687d660cc02f50b1a4974112f87a8e6
Author: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
Date:   Wed Dec 9 11:11:33 2015 +0900

    perf machine: Fix machine.vmlinux_maps to make sure to clear the old one
    
    Fix machine.vmlinux_maps to make sure to clear the old one if it is
    renewal. This can leak the previous maps on the vmlinux_maps because
    those are just overwritten.
    
    Signed-off-by: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/20151209021133.10245.93730.stgit@localhost.localdomain
    [ Simplified the memset, same end result ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index bfc289c73c22..f5882b8c8db9 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -44,6 +44,8 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 	machine->comm_exec = false;
 	machine->kernel_start = 0;
 
+	memset(machine->vmlinux_maps, 0, sizeof(machine->vmlinux_maps));
+
 	machine->root_dir = strdup(root_dir);
 	if (machine->root_dir == NULL)
 		return -ENOMEM;
@@ -770,6 +772,9 @@ int __machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
 	enum map_type type;
 	u64 start = machine__get_running_kernel_start(machine, NULL);
 
+	/* In case of renewal the kernel map, destroy previous one */
+	machine__destroy_kernel_maps(machine);
+
 	for (type = 0; type < MAP__NR_TYPES; ++type) {
 		struct kmap *kmap;
 		struct map *map;

commit 5dcf16df3ce48b2e4f798b1a11b5de2fc3cfd73a
Author: Wang Nan <wangnan0@huawei.com>
Date:   Mon Dec 7 02:36:25 2015 +0000

    perf machine: Pass correct string to dso__adjust_kmod_long_name
    
    There's a mistake in dso__adjust_kmod_long_name() that it use strdup()
    to dup the new long_name of a dso, but passes the original string to
    dso__set_long_name(). Which causes random crash during cleanup.
    
    Signed-off-by: Wang Nan <wangnan0@huawei.com>
    Reviewed-by: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Zefan Li <lizefan@huawei.com>
    Cc: pi3orama@163.com
    Fixes: c03d5184f0e9 ("perf machine: Adjust dso->long_name for offline module")
    Link: http://lkml.kernel.org/r/1449455785-42020-1-git-send-email-wangnan0@huawei.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 95a7f6087346..bfc289c73c22 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -576,7 +576,7 @@ static void dso__adjust_kmod_long_name(struct dso *dso, const char *filename)
 	if (!dup_filename)
 		return;
 
-	dso__set_long_name(dso, filename, true);
+	dso__set_long_name(dso, dup_filename, true);
 }
 
 struct map *machine__findnew_module_map(struct machine *machine, u64 start,

commit c03d5184f0e92fa696e4b57f54ffc3b19a92f704
Author: Wang Nan <wangnan0@huawei.com>
Date:   Thu Nov 26 03:59:57 2015 +0000

    perf machine: Adjust dso->long_name for offline module
    
    Something unexpected may happen if copy statically linked perf to a
    production environment:
    
      # ./perf probe -m ./mymodule.ko my_func
      [mymodule] with build id 326ab42550ef3d24944f53c817533728367effeb not found, continuing without symbols
      Failed to find symbol my_func in /home/wangnan/kmodule/mymodule.ko
        Error: Failed to add events.
      # ./perf buildid-cache -a ./mymodule.ko
      # ./perf probe -m ./mymodule.ko my_func
      Added new event:
        probe:my_func        (on my_func in /home/wangnan/kmodule/mymodule.ko)
    
      You can now use it in all perf tools, such as:
    
            perf record -e probe:my_func -aR sleep 1
    
    Where:
    
      # ldd ./perf
            not a dynamic executable
      # strace -e open ./perf probe -m ./mymodule.ko my_func
      ...
      open("/home/wangnan/kmodule/mymodule.ko", O_RDONLY) = 3
      open("/home/wangnan/kmodule/../lib64/elfutils/libebl_x86_64.so", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
      ...
      open("/lib64/tls/libebl_x86_64.so", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
      open("/lib64/libebl_x86_64.so", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
      open("/usr/lib64/tls/libebl_x86_64.so", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
      open("/usr/lib64/libebl_x86_64.so", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
      open("[mymodule]", O_RDONLY)            = -1 ENOENT (No such file or directory)
      open("/home/wangnan/.debug/.build-id/32/6ab42550ef3d24944f53c817533728367effeb", O_RDONLY) = -1 ENOENT (No such file or directory)
      open("[mymodule]", O_RDONLY)            = -1 ENOENT (No such file or directory)
    
    In the above example, probe fails before we put the module into
    buildid-cache. However, user would expect it success in both case
    because perf is able to find probe points actually.
    
    The reason is because perf won't utilize module's full path if it failed
    to open debuginfo. In:
    
         convert_to_probe_trace_events ->
            find_probe_trace_events_from_map ->
                get_target_map ->
                    kernel_get_module_map ->
                        machine__findnew_module_map ->
                            map_groups__find_by_name
    
    map_groups__find_by_name() is able to find the map of that module, but
    this information is found from /proc/module before it knows the real
    path of the offline module. Therefore, the map->dso->long_name is set to
    something like '[mymodule]', which prevent dso__load() find the real
    path of the module file.
    
    In another aspect, if dso__load() can get the offline module through
    buildid cache, it can read symble table from that ko. Even if debuginfo
    is not available, 'perf probe' can success if the '.symtab' can be
    found.
    
    This patch improves machine__findnew_module_map(): when dso->long_name
    is leading with '[' (doesn't find path of module when parsing
    /proc/modules), fixes it by dso__set_long_name(), so following
    dso__load() is possible to find the symbol table.
    
    This patch won't interfere with buildid matching. Here is the test
    result:
    
      # ./perf probe -m ./mymodule.ko my_func
      Added new event:
        probe:my_func        (on my_func in /home/wangnan/kmodule/mymodule.ko)
    
      You can now use it in all perf tools, such as:
    
            perf record -e probe:my_func -aR sleep 1
    
      # ./perf probe -d '*'
      Removed event: probe:my_func
      # mv ./mymodule.{ko,.bak}
      # mv ./moduleb.ko mymodule.ko
      # ./perf probe -m ./mymodule.ko my_func
      /home/wangnan/kmodule/mymodule.ko with build id 326ab42550ef3d24944f53c817533728367effeb not found, continuing without symbols
      Failed to find symbol my_func in /home/wangnan/kmodule/mymodule.ko
        Error: Failed to add events.
    
      # ./perf probe -v -m ./mymodule.ko my_func
      probe-definition(0): my_func
      symbol:my_func file:(null) line:0 offset:0 return:0 lazy:(null)
      0 arguments
      Could not open debuginfo. Try to use symbols.
      symsrc__init: build id mismatch for /home/wangnan/kmodule/mymodule.ko.
      /home/wangnan/kmodule/mymodule.ko with build id 326ab42550ef3d24944f53c817533728367effeb not found, continuing without symbols
      Failed to find symbol my_func in /home/wangnan/kmodule/mymodule.ko
        Error: Failed to add events. Reason: No such file or directory (Code: -2)
    
    Signed-off-by: Wang Nan <wangnan0@huawei.com>
    Cc: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Zefan Li <lizefan@huawei.com>
    Cc: pi3orama@163.com
    Link: http://lkml.kernel.org/r/1448510397-187965-1-git-send-email-wangnan0@huawei.com
    [ Renamed adjust_dso_long_name() do dso__adjust_kmod_long_name() ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index f0019b72db48..95a7f6087346 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -561,6 +561,24 @@ int machine__process_switch_event(struct machine *machine __maybe_unused,
 	return 0;
 }
 
+static void dso__adjust_kmod_long_name(struct dso *dso, const char *filename)
+{
+	const char *dup_filename;
+
+	if (!filename || !dso || !dso->long_name)
+		return;
+	if (dso->long_name[0] != '[')
+		return;
+	if (!strchr(filename, '/'))
+		return;
+
+	dup_filename = strdup(filename);
+	if (!dup_filename)
+		return;
+
+	dso__set_long_name(dso, filename, true);
+}
+
 struct map *machine__findnew_module_map(struct machine *machine, u64 start,
 					const char *filename)
 {
@@ -573,8 +591,15 @@ struct map *machine__findnew_module_map(struct machine *machine, u64 start,
 
 	map = map_groups__find_by_name(&machine->kmaps, MAP__FUNCTION,
 				       m.name);
-	if (map)
+	if (map) {
+		/*
+		 * If the map's dso is an offline module, give dso__load()
+		 * a chance to find the file path of that module by fixing
+		 * long_name.
+		 */
+		dso__adjust_kmod_long_name(map->dso, filename);
 		goto out;
+	}
 
 	dso = machine__findnew_module_dso(machine, &m, filename);
 	if (dso == NULL)

commit b49a8fe52626814968b9a9d27d7ad1cadc5532ed
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Thu Nov 26 16:08:20 2015 +0900

    perf callchain: Honor hide_unresolved
    
    If user requested to hide unresolved entries, skip unresolved callchains
    as well as hist entries.
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Kan Liang <kan.liang@intel.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/r/1448521700-32062-3-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 7f5071a4d9aa..f0019b72db48 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1618,6 +1618,8 @@ static int add_callchain_ip(struct thread *thread,
 		}
 	}
 
+	if (symbol_conf.hide_unresolved && al.sym == NULL)
+		return 0;
 	return callchain_cursor_append(&callchain_cursor, al.addr, al.map, al.sym);
 }
 
@@ -1872,6 +1874,9 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 static int unwind_entry(struct unwind_entry *entry, void *arg)
 {
 	struct callchain_cursor *cursor = arg;
+
+	if (symbol_conf.hide_unresolved && entry->sym == NULL)
+		return 0;
 	return callchain_cursor_append(cursor, entry->ip,
 				       entry->map, entry->sym);
 }

commit 566c69c36e6178774dd484ea4a02b76f6bd0ede4
Author: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
Date:   Wed Nov 18 15:40:35 2015 +0900

    perf machine: Fix machine__findnew_module_map to put dso
    
    Fix machine__findnew_module_map to drop the reference to the dso because
    it is already referenced by both machine__findnew_module_dso() and
    map__new2().
    
    Refcnt debugger shows:
    
      ==== [1] ====
      Unreclaimed dso: 0x1ffd980
      Refcount +1 => 1 at
        ./perf(dso__new+0x1ff) [0x4a62df]
        ./perf(__dsos__addnew+0x29) [0x4a6e19]
        ./perf() [0x4b8b91]
        ./perf(modules__parse+0xfc) [0x4a9d5c]
        ./perf() [0x4b8460]
        ./perf(machine__create_kernel_maps+0x150) [0x4bb550]
        ./perf(machine__new_host+0xfa) [0x4bb75a]
        ./perf(init_probe_symbol_maps+0x93) [0x506623]
        ./perf() [0x455ffa]
        ./perf(cmd_probe+0x6c) [0x4566bc]
        ./perf() [0x47abc5]
        ./perf(main+0x610) [0x421f90]
        /lib64/libc.so.6(__libc_start_main+0xf5) [0x7f1345a8eaf5]
        ./perf() [0x4220a9]
    
    This map_groups__insert(0x4b8b91) already gets a reference to the new
    dso:
    
      ----
      eu-addr2line -e ./perf -f 0x4b8b91
      map_groups__insert inlined at util/machine.c:586 in
      machine__create_module
      util/map.h:207
      ----
    
    So this dso refcnt will be released when map_groups gets released.
    
      [snip]
      Refcount +1 => 2 at
        ./perf(dso__get+0x34) [0x4a65f4]
        ./perf() [0x4b8b35]
        ./perf(modules__parse+0xfc) [0x4a9d5c]
        ./perf() [0x4b8460]
        ./perf(machine__create_kernel_maps+0x150) [0x4bb550]
        ./perf(machine__new_host+0xfa) [0x4bb75a]
        ./perf(init_probe_symbol_maps+0x93) [0x506623]
        ./perf() [0x455ffa]
        ./perf(cmd_probe+0x6c) [0x4566bc]
        ./perf() [0x47abc5]
        ./perf(main+0x610) [0x421f90]
        /lib64/libc.so.6(__libc_start_main+0xf5) [0x7f1345a8eaf5]
        ./perf() [0x4220a9]
    
    Here, machine__findnew_module_dso(0x4b8b35) gets the dso (and stores it
    in a local variable):
    
      ----
      # eu-addr2line -e ./perf -f 0x4b8b35
      machine__findnew_module_dso inlined at util/machine.c:578 in
      machine__create_module
      util/machine.c:514
      ----
    
      Refcount +1 => 3 at
        ./perf(dso__get+0x34) [0x4a65f4]
        ./perf(map__new2+0x76) [0x4be1c6]
        ./perf() [0x4b8b4f]
        ./perf(modules__parse+0xfc) [0x4a9d5c]
        ./perf() [0x4b8460]
        ./perf(machine__create_kernel_maps+0x150) [0x4bb550]
        ./perf(machine__new_host+0xfa) [0x4bb75a]
        ./perf(init_probe_symbol_maps+0x93) [0x506623]
        ./perf() [0x455ffa]
        ./perf(cmd_probe+0x6c) [0x4566bc]
        ./perf() [0x47abc5]
        ./perf(main+0x610) [0x421f90]
        /lib64/libc.so.6(__libc_start_main+0xf5) [0x7f1345a8eaf5]
        ./perf() [0x4220a9]
    
    But also map__new2() gets the dso which will be put when the map is
    released.
    
    So, we have to drop the constructor reference obtained in
    machine__findnew_module_dso().
    
    Signed-off-by: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/20151118064035.30709.58824.stgit@localhost.localdomain
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 0b4a05c14204..7f5071a4d9aa 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -565,7 +565,7 @@ struct map *machine__findnew_module_map(struct machine *machine, u64 start,
 					const char *filename)
 {
 	struct map *map = NULL;
-	struct dso *dso;
+	struct dso *dso = NULL;
 	struct kmod_path m;
 
 	if (kmod_path__parse_name(&m, filename))
@@ -589,6 +589,8 @@ struct map *machine__findnew_module_map(struct machine *machine, u64 start,
 	/* Put the map here because map_groups__insert alread got it */
 	map__put(map);
 out:
+	/* put the dso here, corresponding to  machine__findnew_module_dso */
+	dso__put(dso);
 	free(m.name);
 	return map;
 }

commit 1154c957607afdf5936ae14e1be27d7ca4e7bd30
Author: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
Date:   Wed Nov 18 15:40:33 2015 +0900

    perf tools: Fix machine__create_kernel_maps to put kernel dso refcount
    
    Fix machine__create_kernel_maps() to put kernel dso because the dso has
    been gotten via __machine__create_kernel_maps().
    
    Refcnt debugger shows:
      ==== [0] ====
      Unreclaimed dso: 0x3036ab0
      Refcount +1 => 1 at
        ./perf(dso__new+0x1ff) [0x4a62df]
        ./perf(__dsos__addnew+0x29) [0x4a6e19]
        ./perf(dsos__findnew+0xd1) [0x4a7181]
        ./perf(machine__findnew_kernel+0x27) [0x4a5e17]
        ./perf() [0x4b8cf2]
        ./perf(machine__create_kernel_maps+0x28) [0x4bb428]
        ./perf(machine__new_host+0xfa) [0x4bb74a]
        ./perf(init_probe_symbol_maps+0x93) [0x506613]
        ./perf() [0x455ffa]
        ./perf(cmd_probe+0x6c) [0x4566bc]
        ./perf() [0x47abc5]
        ./perf(main+0x610) [0x421f90]
        /lib64/libc.so.6(__libc_start_main+0xf5) [0x7ffa6809eaf5]
        ./perf() [0x4220a9]
      [snip]
      Refcount +1 => 2 at
        ./perf(dsos__findnew+0x7e) [0x4a712e]
        ./perf(machine__findnew_kernel+0x27) [0x4a5e17]
        ./perf() [0x4b8cf2]
        ./perf(machine__create_kernel_maps+0x28) [0x4bb428]
        ./perf(machine__new_host+0xfa) [0x4bb74a]
        ./perf(init_probe_symbol_maps+0x93) [0x506613]
        ./perf() [0x455ffa]
        ./perf(cmd_probe+0x6c) [0x4566bc]
        ./perf() [0x47abc5]
        ./perf(main+0x610) [0x421f90]
        /lib64/libc.so.6(__libc_start_main+0xf5) [0x7ffa6809eaf5]
        ./perf() [0x4220a9]
      [snip]
      Refcount -1 => 1 at
        ./perf(dso__put+0x2f) [0x4a664f]
        ./perf(machine__delete+0xfe) [0x4b93ee]
        ./perf(exit_probe_symbol_maps+0x28) [0x5066b8]
        ./perf() [0x45628a]
        ./perf(cmd_probe+0x6c) [0x4566bc]
        ./perf() [0x47abc5]
        ./perf(main+0x610) [0x421f90]
        /lib64/libc.so.6(__libc_start_main+0xf5) [0x7ffa6809eaf5]
        ./perf() [0x4220a9]
    
    Actually, dsos__findnew gets the dso before returning it, so the dso
    user (in this case machine__create_kernel_maps) has to put the dso after
    used.
    
    Signed-off-by: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/20151118064033.30709.98954.stgit@localhost.localdomain
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index a358771fe9e3..0b4a05c14204 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1088,11 +1088,14 @@ int machine__create_kernel_maps(struct machine *machine)
 	struct dso *kernel = machine__get_kernel(machine);
 	const char *name;
 	u64 addr = machine__get_running_kernel_start(machine, &name);
-	if (!addr)
+	int ret;
+
+	if (!addr || kernel == NULL)
 		return -1;
 
-	if (kernel == NULL ||
-	    __machine__create_kernel_maps(machine, kernel) < 0)
+	ret = __machine__create_kernel_maps(machine, kernel);
+	dso__put(kernel);
+	if (ret < 0)
 		return -1;
 
 	if (symbol_conf.use_modules && machine__create_modules(machine) < 0) {

commit ebe9729c8c3171aa46ad5d7af40acdc29806689d
Author: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
Date:   Wed Nov 18 15:40:24 2015 +0900

    perf machine: Fix to destroy kernel maps when machine exits
    
    Actually machine__exit forgot to call machine__destroy_kernel_maps.
    
    This fixes some memory leaks on map as below.
    
    Without this fix.
      ----
      ./perf probe vfs_read
      Added new event:
        probe:vfs_read       (on vfs_read)
    
      You can now use it in all perf tools, such as:
    
              perf record -e probe:vfs_read -aR sleep 1
    
      REFCNT: BUG: Unreclaimed objects found.
      REFCNT: Total 4 objects are not reclaimed.
         To see all backtraces, rerun with -v option
      ----
    With this fix.
      ----
      ./perf probe vfs_read
      Added new event:
        probe:vfs_read       (on vfs_read)
    
      You can now use it in all perf tools, such as:
    
              perf record -e probe:vfs_read -aR sleep 1
    
      REFCNT: BUG: Unreclaimed objects found.
      REFCNT: Total 2 objects are not reclaimed.
         To see all backtraces, rerun with -v option
      ----
    
    Signed-off-by: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/20151118064024.30709.43577.stgit@localhost.localdomain
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index e9e09bee221c..a358771fe9e3 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -122,6 +122,7 @@ void machine__delete_threads(struct machine *machine)
 
 void machine__exit(struct machine *machine)
 {
+	machine__destroy_kernel_maps(machine);
 	map_groups__exit(&machine->kmaps);
 	dsos__exit(&machine->dsos);
 	machine__exit_vdso(machine);

commit e96e4078e9a5ea150b3ad9a296440a7976439e4a
Author: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
Date:   Wed Nov 18 15:40:22 2015 +0900

    perf machine: Fix machine__destroy_kernel_maps to drop vmlinux_maps references
    
    Fix machine__destroy_kernel_maps() to drop vmlinux_maps references
    before filling it with NULL.
    
    Refcnt debugger shows
      ==== [1] ====
      Unreclaimed map: 0x36b1070
      Refcount +1 => 1 at
        ./perf(map__new2+0xb5) [0x4bdec5]
        ./perf(machine__create_kernel_maps+0x72) [0x4bb152]
        ./perf(machine__new_host+0xfa) [0x4bb41a]
        ./perf(init_probe_symbol_maps+0x93) [0x5062d3]
        ./perf() [0x455ffa]
        ./perf(cmd_probe+0x6c) [0x4566bc]
        ./perf() [0x47abc5]
        ./perf(main+0x610) [0x421f90]
        /lib64/libc.so.6(__libc_start_main+0xf5) [0x7f1fc9fc4af5]
        ./perf() [0x4220a9]
      Refcount +1 => 2 at
        ./perf(maps__insert+0x9a) [0x4bfd6a]
        ./perf(machine__create_kernel_maps+0xc3) [0x4bb1a3]
        ./perf(machine__new_host+0xfa) [0x4bb41a]
        ./perf(init_probe_symbol_maps+0x93) [0x5062d3]
        ./perf() [0x455ffa]
        ./perf(cmd_probe+0x6c) [0x4566bc]
        ./perf() [0x47abc5]
        ./perf(main+0x610) [0x421f90]
        /lib64/libc.so.6(__libc_start_main+0xf5) [0x7f1fc9fc4af5]
        ./perf() [0x4220a9]
      Refcount -1 => 1 at
        ./perf(map_groups__exit+0x94) [0x4bea74]
        ./perf(machine__delete+0x3d) [0x4b91fd]
        ./perf(exit_probe_symbol_maps+0x28) [0x506378]
        ./perf() [0x45628a]
        ./perf(cmd_probe+0x6c) [0x4566bc]
        ./perf() [0x47abc5]
        ./perf(main+0x610) [0x421f90]
        /lib64/libc.so.6(__libc_start_main+0xf5) [0x7f1fc9fc4af5]
        ./perf() [0x4220a9]
    
    map__new2() returns map with refcnt = 1, and also map_groups__insert
    gets it again in__machine__create_kernel_maps().
    
    machine__destroy_kernel_maps() calls map_groups__remove() to
    decrement the refcnt, but before decrement it again (corresponding
    to map__new2), it makes vmlinux_maps[type] = NULL. And this may
    cause a refcnt leak.
    
    Signed-off-by: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/20151118064022.30709.3897.stgit@localhost.localdomain
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 0487d7795f13..e9e09bee221c 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -790,6 +790,7 @@ void machine__destroy_kernel_maps(struct machine *machine)
 				kmap->ref_reloc_sym = NULL;
 		}
 
+		map__put(machine->vmlinux_maps[type]);
 		machine->vmlinux_maps[type] = NULL;
 	}
 }

commit 9afcb420d6cfeadf5d872f395061c611536615fb
Author: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
Date:   Wed Nov 18 15:40:20 2015 +0900

    perf machine: Fix machine__findnew_module_map to put registered map
    
    Fix machine object to drop the reference to the map object after it
    inserted it into machine->kmaps.
    
    refcnt debugger shows what happened:
      ----
      ==== [2] ====
      Unreclaimed map: 0x346f750
      Refcount +1 => 1 at
        ./perf(map__new2+0xb5) [0x4bdea5]
        ./perf() [0x4b8aaf]
        ./perf(modules__parse+0xfc) [0x4a9cbc]
        ./perf() [0x4b83c0]
        ./perf(machine__create_kernel_maps+0x148) [0x4bb208]
        ./perf(machine__new_host+0xfa) [0x4bb3fa]
        ./perf(init_probe_symbol_maps+0x93) [0x5062b3]
        ./perf() [0x455ffa]
        ./perf(cmd_probe+0x6c) [0x4566bc]
        ./perf() [0x47abc5]
        ./perf(main+0x610) [0x421f90]
        /lib64/libc.so.6(__libc_start_main+0xf5) [0x7f5373899af5]
        ./perf() [0x4220a9]
      Refcount +1 => 2 at
        ./perf(maps__insert+0x9a) [0x4bfd4a]
        ./perf() [0x4b8acb]
        ./perf(modules__parse+0xfc) [0x4a9cbc]
        ./perf() [0x4b83c0]
        ./perf(machine__create_kernel_maps+0x148) [0x4bb208]
        ./perf(machine__new_host+0xfa) [0x4bb3fa]
        ./perf(init_probe_symbol_maps+0x93) [0x5062b3]
        ./perf() [0x455ffa]
        ./perf(cmd_probe+0x6c) [0x4566bc]
        ./perf() [0x47abc5]
        ./perf(main+0x610) [0x421f90]
        /lib64/libc.so.6(__libc_start_main+0xf5) [0x7f5373899af5]
        ./perf() [0x4220a9]
      Refcount -1 => 1 at
        ./perf(map_groups__exit+0x94) [0x4bea54]
        ./perf(machine__delete+0x3d) [0x4b91ed]
        ./perf(exit_probe_symbol_maps+0x28) [0x506358]
        ./perf() [0x45628a]
        ./perf(cmd_probe+0x6c) [0x4566bc]
        ./perf() [0x47abc5]
        ./perf(main+0x610) [0x421f90]
        /lib64/libc.so.6(__libc_start_main+0xf5) [0x7f5373899af5]
        ./perf() [0x4220a9]
      ----
    
    This pattern clearly shows that the refcnt of the map is acquired twice
    by map__new2 and maps__insert but released onlu once at
    map_groups__exit, when we purge its maps rbtree.
    
    Since maps__insert already reference counted the map, we have to drop
    the constructor (map__new2) reference count right after inserting it.
    
    These happened in machine__findnew_module_map, as below.
    
      ----
      # eu-addr2line -e ./perf -f 0x4b8aaf
      machine__findnew_module_map inlined at util/machine.c:1046
      in machine__create_module
      util/machine.c:582
      # eu-addr2line -e ./perf -f 0x4b8acb
      map_groups__insert inlined at util/machine.c:585
      in machine__create_module
      util/map.h:208
      ----
    
    (note that both are at util/machine.c:58X which is
     machine__findnew_module_map)
    
    Signed-off-by: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/20151118064020.30709.40499.stgit@localhost.localdomain
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 8b303ff20289..0487d7795f13 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -585,6 +585,8 @@ struct map *machine__findnew_module_map(struct machine *machine, u64 start,
 
 	map_groups__insert(&machine->kmaps, map);
 
+	/* Put the map here because map_groups__insert alread got it */
+	map__put(map);
 out:
 	free(m.name);
 	return map;

commit e266a753bf51b2c3b46d0d230349662c35ac5629
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Fri Nov 13 11:48:30 2015 +0200

    perf symbols: Fix dso lookup by long name and missing buildids
    
    Commit 4598a0a6d22f ("perf symbols: Improve DSO long names lookup speed
    with rbtree") Added a tree to lookup dsos by long name.  That tree gets
    corrupted whenever a dso long name is changed because the tree is not
    updated.
    
    One effect of that is buildid-list does not work with the 'with-hits'
    option because dso lookup fails and results in two structs for the same
    dso.  The first has the buildid but no hits, the second has hits but no
    buildid. e.g.
    
    Before:
    
      $ tools/perf/perf record ls
      arch     certs    CREDITS  Documentation  firmware  include
      ipc      Kconfig  lib      Makefile       net       REPORTING-BUGS
      scripts  sound    usr      block          COPYING   crypto
      drivers  fs       init     Kbuild         kernel    MAINTAINERS
      mm       README   samples  security       tools     virt
      [ perf record: Woken up 1 times to write data ]
      [ perf record: Captured and wrote 0.012 MB perf.data (11 samples) ]
      $ tools/perf/perf buildid-list
      574da826c66538a8d9060d393a8866289bd06005 [kernel.kallsyms]
      30c94dc66a1fe95180c3d68d2b89e576d5ae213c /lib/x86_64-linux-gnu/libc-2.19.so
      $ tools/perf/perf buildid-list -H
      574da826c66538a8d9060d393a8866289bd06005 [kernel.kallsyms]
      0000000000000000000000000000000000000000 /lib/x86_64-linux-gnu/libc-2.19.so
    
    After:
    
      $ tools/perf/perf buildid-list -H
      574da826c66538a8d9060d393a8866289bd06005 [kernel.kallsyms]
      30c94dc66a1fe95180c3d68d2b89e576d5ae213c /lib/x86_64-linux-gnu/libc-2.19.so
    
    The fix is to record the root of the tree on the dso so that
    dso__set_long_name() can update the tree when the long name changes.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Douglas Hatch <doug.hatch@hp.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Scott J Norton <scott.norton@hp.com>
    Cc: Waiman Long <Waiman.Long@hp.com>
    Fixes: 4598a0a6d22f ("perf symbols: Improve DSO long names lookup speed with rbtree")
    Link: http://lkml.kernel.org/r/1447408112-1920-2-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 5ef90be2a249..8b303ff20289 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -91,6 +91,7 @@ static void dsos__purge(struct dsos *dsos)
 
 	list_for_each_entry_safe(pos, n, &dsos->head, node) {
 		RB_CLEAR_NODE(&pos->rb_node);
+		pos->root = NULL;
 		list_del_init(&pos->node);
 		dso__put(pos);
 	}

commit 0edd453368c6b9cdb756bde2b6675bb0d5d0eb0a
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Fri Sep 25 16:15:48 2015 +0300

    perf callchain: Allow for max_stack greater than PERF_MAX_STACK_DEPTH
    
    Adjust the validation to allow for max_stack greater than
    PERF_MAX_STACK_DEPTH.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Link: http://lkml.kernel.org/r/1443186956-18718-18-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 76fe167c359e..5ef90be2a249 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1831,7 +1831,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	}
 
 check_calls:
-	if (chain->nr > PERF_MAX_STACK_DEPTH) {
+	if (chain->nr > PERF_MAX_STACK_DEPTH && (int)chain->nr > max_stack) {
 		pr_warning("corrupted callchain. skipping...\n");
 		return 0;
 	}

commit a5e813c68649366aaa3f785772b00ea6ccad7b8d
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Sep 30 11:54:04 2015 -0300

    perf machine: Add method for common kernel_map(FUNCTION) operation
    
    And it is also a step in the direction of killing the separation of data
    and text maps in map_groups.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-rrds86kb3wx5wk8v38v56gw8@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index d71b7dcf4579..76fe167c359e 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -625,7 +625,7 @@ size_t machine__fprintf_vmlinux_path(struct machine *machine, FILE *fp)
 {
 	int i;
 	size_t printed = 0;
-	struct dso *kdso = machine__kernel_map(machine, MAP__FUNCTION)->dso;
+	struct dso *kdso = machine__kernel_map(machine)->dso;
 
 	if (kdso->has_build_id) {
 		char filename[PATH_MAX];
@@ -750,7 +750,7 @@ int __machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
 		machine->vmlinux_maps[type]->map_ip =
 			machine->vmlinux_maps[type]->unmap_ip =
 				identity__map_ip;
-		map = machine__kernel_map(machine, type);
+		map = __machine__kernel_map(machine, type);
 		kmap = map__kmap(map);
 		if (!kmap)
 			return -1;
@@ -768,7 +768,7 @@ void machine__destroy_kernel_maps(struct machine *machine)
 
 	for (type = 0; type < MAP__NR_TYPES; ++type) {
 		struct kmap *kmap;
-		struct map *map = machine__kernel_map(machine, type);
+		struct map *map = __machine__kernel_map(machine, type);
 
 		if (map == NULL)
 			continue;
@@ -868,7 +868,7 @@ int machines__create_kernel_maps(struct machines *machines, pid_t pid)
 int machine__load_kallsyms(struct machine *machine, const char *filename,
 			   enum map_type type, symbol_filter_t filter)
 {
-	struct map *map = machine__kernel_map(machine, MAP__FUNCTION);
+	struct map *map = machine__kernel_map(machine);
 	int ret = dso__load_kallsyms(map->dso, filename, map, filter);
 
 	if (ret > 0) {
@@ -887,7 +887,7 @@ int machine__load_kallsyms(struct machine *machine, const char *filename,
 int machine__load_vmlinux_path(struct machine *machine, enum map_type type,
 			       symbol_filter_t filter)
 {
-	struct map *map = machine__kernel_map(machine, MAP__FUNCTION);
+	struct map *map = machine__kernel_map(machine);
 	int ret = dso__load_vmlinux_path(map->dso, map, filter);
 
 	if (ret > 0)
@@ -1245,8 +1245,7 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 			/*
 			 * preload dso of guest kernel and modules
 			 */
-			dso__load(kernel, machine__kernel_map(machine, MAP__FUNCTION),
-				  NULL);
+			dso__load(kernel, machine__kernel_map(machine), NULL);
 		}
 	}
 	return 0;
@@ -1998,7 +1997,7 @@ int machine__set_current_tid(struct machine *machine, int cpu, pid_t pid,
 
 int machine__get_kernel_start(struct machine *machine)
 {
-	struct map *map = machine__kernel_map(machine, MAP__FUNCTION);
+	struct map *map = machine__kernel_map(machine);
 	int err = 0;
 
 	/*

commit 77e65977495cd6f6fcfacd8c16bdd9c8c18a1d72
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Sep 30 11:08:58 2015 -0300

    perf machine: Use machine__kernel_map() thoroughly
    
    In places where we were using its open coded equivalent.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-khkdugcdoqy3tkszm3jdxgbe@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index fd1efeafb343..d71b7dcf4579 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -625,7 +625,7 @@ size_t machine__fprintf_vmlinux_path(struct machine *machine, FILE *fp)
 {
 	int i;
 	size_t printed = 0;
-	struct dso *kdso = machine->vmlinux_maps[MAP__FUNCTION]->dso;
+	struct dso *kdso = machine__kernel_map(machine, MAP__FUNCTION)->dso;
 
 	if (kdso->has_build_id) {
 		char filename[PATH_MAX];
@@ -741,6 +741,7 @@ int __machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
 
 	for (type = 0; type < MAP__NR_TYPES; ++type) {
 		struct kmap *kmap;
+		struct map *map;
 
 		machine->vmlinux_maps[type] = map__new2(start, kernel, type);
 		if (machine->vmlinux_maps[type] == NULL)
@@ -749,13 +750,13 @@ int __machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
 		machine->vmlinux_maps[type]->map_ip =
 			machine->vmlinux_maps[type]->unmap_ip =
 				identity__map_ip;
-		kmap = map__kmap(machine->vmlinux_maps[type]);
+		map = machine__kernel_map(machine, type);
+		kmap = map__kmap(map);
 		if (!kmap)
 			return -1;
 
 		kmap->kmaps = &machine->kmaps;
-		map_groups__insert(&machine->kmaps,
-				   machine->vmlinux_maps[type]);
+		map_groups__insert(&machine->kmaps, map);
 	}
 
 	return 0;
@@ -767,13 +768,13 @@ void machine__destroy_kernel_maps(struct machine *machine)
 
 	for (type = 0; type < MAP__NR_TYPES; ++type) {
 		struct kmap *kmap;
+		struct map *map = machine__kernel_map(machine, type);
 
-		if (machine->vmlinux_maps[type] == NULL)
+		if (map == NULL)
 			continue;
 
-		kmap = map__kmap(machine->vmlinux_maps[type]);
-		map_groups__remove(&machine->kmaps,
-				   machine->vmlinux_maps[type]);
+		kmap = map__kmap(map);
+		map_groups__remove(&machine->kmaps, map);
 		if (kmap && kmap->ref_reloc_sym) {
 			/*
 			 * ref_reloc_sym is shared among all maps, so free just
@@ -867,7 +868,7 @@ int machines__create_kernel_maps(struct machines *machines, pid_t pid)
 int machine__load_kallsyms(struct machine *machine, const char *filename,
 			   enum map_type type, symbol_filter_t filter)
 {
-	struct map *map = machine->vmlinux_maps[type];
+	struct map *map = machine__kernel_map(machine, MAP__FUNCTION);
 	int ret = dso__load_kallsyms(map->dso, filename, map, filter);
 
 	if (ret > 0) {
@@ -886,7 +887,7 @@ int machine__load_kallsyms(struct machine *machine, const char *filename,
 int machine__load_vmlinux_path(struct machine *machine, enum map_type type,
 			       symbol_filter_t filter)
 {
-	struct map *map = machine->vmlinux_maps[type];
+	struct map *map = machine__kernel_map(machine, MAP__FUNCTION);
 	int ret = dso__load_vmlinux_path(map->dso, map, filter);
 
 	if (ret > 0)
@@ -1244,7 +1245,7 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 			/*
 			 * preload dso of guest kernel and modules
 			 */
-			dso__load(kernel, machine->vmlinux_maps[MAP__FUNCTION],
+			dso__load(kernel, machine__kernel_map(machine, MAP__FUNCTION),
 				  NULL);
 		}
 	}

commit 4cde998d205894705b534878122631142a3eefe4
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Sep 9 12:25:00 2015 -0300

    perf machine: Add pointer to sample's environment
    
    The 'struct machine' represents the machine where the samples were/are
    being collected, and we also have a 'struct perf_env' with extra details
    about such machine, that we were collecting at 'perf.data' creation time
    but we also needed when no perf.data file is being used, such as in
    'perf top'.
    
    So, get those structs closer together, as they provide a bigger picture
    of the sample's environment.
    
    In 'perf session', when the file argument is NULL, we can assume that
    the tool is sampling the running machine, so point machine->env to
    the global put in place in previous patches, while set it to the
    perf_header.env one when reading from a file.
    
    This paves the way for machine->env to be used in
    perf_event__preprocess_sample to populate addr_location.socket.
    
    Tested-by: Wang Nan <wangnan0@huawei.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Kan Liang <kan.liang@intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-2ajotl0khscutm68exictoy9@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 6309f7ceb08f..fd1efeafb343 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -35,6 +35,7 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 	machine->last_match = NULL;
 
 	machine->vdso_info = NULL;
+	machine->env = NULL;
 
 	machine->pid = pid;
 

commit 40a2ea1bd988e3bbdb07a0708681fdb05cd7d267
Merge: a897b5f0393a 196676497f25
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Aug 20 11:48:56 2015 +0200

    Merge branch 'perf/urgent' into perf/core, to pick up fixes before adding more changes
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 5cb73340d92a716fd2776700742c3558206ae298
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Wed Aug 19 17:29:20 2015 +0300

    perf tools: Make fork event processing more resilient
    
    When processing a fork event, the tools lookup the parent thread by its
    tid.  In a couple of cases, it is possible for that thread to have the
    wrong pid.
    
    That can happen if the data is being processed out of order, or if the
    (fork) event that would have removed the erroneous thread was lost.
    
    Assume the latter case, print a dump message, remove the erroneous
    thread, create a new one with the correct pid, and keep going.
    
    Reported-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Tested-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Link: http://lkml.kernel.org/r/1439994561-27436-3-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 7ff682770fdb..f1a4c833121e 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1387,6 +1387,24 @@ int machine__process_fork_event(struct machine *machine, union perf_event *event
 							event->fork.ptid);
 	int err = 0;
 
+	if (dump_trace)
+		perf_event__fprintf_task(event, stdout);
+
+	/*
+	 * There may be an existing thread that is not actually the parent,
+	 * either because we are processing events out of order, or because the
+	 * (fork) event that would have removed the thread was lost. Assume the
+	 * latter case and continue on as best we can.
+	 */
+	if (parent->pid_ != (pid_t)event->fork.ppid) {
+		dump_printf("removing erroneous parent thread %d/%d\n",
+			    parent->pid_, parent->tid);
+		machine__remove_thread(machine, parent);
+		thread__put(parent);
+		parent = machine__findnew_thread(machine, event->fork.ppid,
+						 event->fork.ptid);
+	}
+
 	/* if a thread currently exists for the thread id remove it */
 	if (thread != NULL) {
 		machine__remove_thread(machine, thread);
@@ -1395,8 +1413,6 @@ int machine__process_fork_event(struct machine *machine, union perf_event *event
 
 	thread = machine__findnew_thread(machine, event->fork.pid,
 					 event->fork.tid);
-	if (dump_trace)
-		perf_event__fprintf_task(event, stdout);
 
 	if (thread == NULL || parent == NULL ||
 	    thread__fork(thread, parent, sample->time) < 0) {

commit 0286039f777ec0b6684868c34f7b16f97a069d6e
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Tue Jul 21 12:44:03 2015 +0300

    perf tools: Add new PERF_RECORD_SWITCH event
    
    Support processing of PERF_RECORD_SWITCH events and
    PERF_RECORD_SWITCH_CPU_WIDE events. There is a single
    tools callback for them both so that the tool must
    check the event type before using the extra members
    in PERF_RECORD_SWITCH_CPU_WIDE.
    
    There is still no way to select the events, though.
    That is added in a subsequest patch.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Tested-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Mathieu Poirier <mathieu.poirier@linaro.org>
    Cc: Pawel Moll <pawel.moll@arm.com>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1437471846-26995-3-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 22006c15edf4..be3e00891d22 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -550,6 +550,14 @@ int machine__process_itrace_start_event(struct machine *machine __maybe_unused,
 	return 0;
 }
 
+int machine__process_switch_event(struct machine *machine __maybe_unused,
+				  union perf_event *event)
+{
+	if (dump_trace)
+		perf_event__fprintf_switch(event, stdout);
+	return 0;
+}
+
 struct map *machine__findnew_module_map(struct machine *machine, u64 start,
 					const char *filename)
 {
@@ -1451,6 +1459,9 @@ int machine__process_event(struct machine *machine, union perf_event *event,
 		ret = machine__process_itrace_start_event(machine, event); break;
 	case PERF_RECORD_LOST_SAMPLES:
 		ret = machine__process_lost_samples_event(machine, event, sample); break;
+	case PERF_RECORD_SWITCH:
+	case PERF_RECORD_SWITCH_CPU_WIDE:
+		ret = machine__process_switch_event(machine, event); break;
 	default:
 		ret = -1;
 		break;

commit c3168b0db93ad5ffeede4ecdf807dab64270f55d
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Jul 22 16:14:29 2015 -0300

    perf symbols: Provide libtraceevent callback to resolve kernel symbols
    
    That provides the function signature expected by libtraceevent's
    pevent_set_function_resolver().
    
    Acked-by: David Ahern <dsahern@gmail.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Link: http://lkml.kernel.org/n/tip-ie6hvlb6u15y4ulg9j1612zg@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index d0bf1e590479..22006c15edf4 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1993,3 +1993,17 @@ struct dso *machine__findnew_dso(struct machine *machine, const char *filename)
 {
 	return dsos__findnew(&machine->dsos, filename);
 }
+
+char *machine__resolve_kernel_addr(void *vmachine, unsigned long long *addrp, char **modp)
+{
+	struct machine *machine = vmachine;
+	struct map *map;
+	struct symbol *sym = map_groups__find_symbol(&machine->kmaps, MAP__FUNCTION, *addrp, &map,  NULL);
+
+	if (sym == NULL)
+		return NULL;
+
+	*modp = __map__is_kmodule(map) ? (char *)map->dso->short_name : NULL;
+	*addrp = map->unmap_ip(map, sym->start);
+	return sym->name;
+}

commit 4a77e2183fc0260c0efc7adeccf933fef893ad5f
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Jul 20 12:13:34 2015 -0300

    perf strlist: Make dupstr be the default and part of an extensible config parm
    
    So that we can pass more info to strlist__new() without having to change
    its function signature, just adding entries to the strlist_config struct
    with sensible defaults for when those fields are not specified.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-5uaaler4931i0s9sedxjquhq@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 7ff682770fdb..d0bf1e590479 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -250,7 +250,7 @@ struct machine *machines__findnew(struct machines *machines, pid_t pid)
 			static struct strlist *seen;
 
 			if (!seen)
-				seen = strlist__new(true, NULL);
+				seen = strlist__new(NULL, NULL);
 
 			if (!strlist__has_entry(seen, path)) {
 				pr_err("Can't access file %s\n", path);

commit ceb92913078e41e2305250754e0ea144fc3e9b28
Author: Jiri Olsa <jolsa@redhat.com>
Date:   Mon Jun 29 13:27:45 2015 +0200

    perf tools: Add missing break for PERF_RECORD_ITRACE_START
    
    Missing switch break since introduction of new event:
    
      c4937a91ea56 perf tools: handle PERF_RECORD_LOST_SAMPLES
    
    Also removing unneeded break for PERF_RECORD_LOST_SAMPLES.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Kan Liang <kan.liang@intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/20150629112745.GA21507@krava.brq.redhat.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 4744673aff1b..7ff682770fdb 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1448,10 +1448,9 @@ int machine__process_event(struct machine *machine, union perf_event *event,
 	case PERF_RECORD_AUX:
 		ret = machine__process_aux_event(machine, event); break;
 	case PERF_RECORD_ITRACE_START:
-		ret = machine__process_itrace_start_event(machine, event);
+		ret = machine__process_itrace_start_event(machine, event); break;
 	case PERF_RECORD_LOST_SAMPLES:
 		ret = machine__process_lost_samples_event(machine, event, sample); break;
-		break;
 	default:
 		ret = -1;
 		break;

commit 9d9cad763ca79dd3697e9f2d1df648e37496582b
Author: Kan Liang <kan.liang@intel.com>
Date:   Wed Jun 17 09:51:11 2015 -0400

    perf tools: Configurable per thread proc map processing time out
    
    The time out to limit the individual proc map processing was hard code
    to 500ms. This patch introduce a new option --proc-map-timeout to make
    the time limit configurable.
    
    Signed-off-by: Kan Liang <kan.liang@intel.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ying Huang <ying.huang@intel.com>
    Link: http://lkml.kernel.org/r/1434549071-25611-2-git-send-email-kan.liang@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 8b3b1937cb9e..4744673aff1b 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1913,12 +1913,13 @@ int machines__for_each_thread(struct machines *machines,
 
 int __machine__synthesize_threads(struct machine *machine, struct perf_tool *tool,
 				  struct target *target, struct thread_map *threads,
-				  perf_event__handler_t process, bool data_mmap)
+				  perf_event__handler_t process, bool data_mmap,
+				  unsigned int proc_map_timeout)
 {
 	if (target__has_task(target))
-		return perf_event__synthesize_thread_map(tool, threads, process, machine, data_mmap);
+		return perf_event__synthesize_thread_map(tool, threads, process, machine, data_mmap, proc_map_timeout);
 	else if (target__has_cpu(target))
-		return perf_event__synthesize_threads(tool, process, machine, data_mmap);
+		return perf_event__synthesize_threads(tool, process, machine, data_mmap, proc_map_timeout);
 	/* command specified */
 	return 0;
 }

commit a5499b37197ab4b5fed101370df7ccadacbb4340
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Fri May 29 16:33:30 2015 +0300

    perf tools: Ensure thread-stack is flushed
    
    The thread-stack represents a thread's current stack.  When a thread
    exits there can still be many functions on the stack e.g. exit() can be
    called many levels deep, so all the callers will never return.  To get
    that information output, the thread-stack must be flushed.
    
    Previously it was assumed the thread-stack would be flushed when the
    struct thread was deleted.  With thread ref-counting it is no longer
    clear when that will be, if ever. So instead explicitly flush all the
    thread-stacks at the end of a session.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Link: http://lkml.kernel.org/r/1432906425-9911-3-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 132e35765101..8b3b1937cb9e 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1890,6 +1890,27 @@ int machine__for_each_thread(struct machine *machine,
 	return rc;
 }
 
+int machines__for_each_thread(struct machines *machines,
+			      int (*fn)(struct thread *thread, void *p),
+			      void *priv)
+{
+	struct rb_node *nd;
+	int rc = 0;
+
+	rc = machine__for_each_thread(&machines->host, fn, priv);
+	if (rc != 0)
+		return rc;
+
+	for (nd = rb_first(&machines->guests); nd; nd = rb_next(nd)) {
+		struct machine *machine = rb_entry(nd, struct machine, rb_node);
+
+		rc = machine__for_each_thread(machine, fn, priv);
+		if (rc != 0)
+			return rc;
+	}
+	return rc;
+}
+
 int __machine__synthesize_threads(struct machine *machine, struct perf_tool *tool,
 				  struct target *target, struct thread_map *threads,
 				  perf_event__handler_t process, bool data_mmap)

commit d3a7c489c7fd2463e3b2c3a2179c7be879dd9cb4
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Jun 2 11:53:26 2015 -0300

    perf tools: Reference count struct dso
    
    This has a different model than the 'thread' and 'map' struct lifetimes:
    there is not a definitive "don't use this DSO anymore" event, i.e. we may
    get many 'struct map' holding references to the '/usr/lib64/libc-2.20.so'
    DSO but then at some point some DSO may have no references but we still
    don't want to straight away release its resources, because "soon" we may
    get a new 'struct map' that needs it and we want to reuse its symtab or
    other resources.
    
    So we need some way to garbage collect it when crossing some memory
    usage threshold, which is left for anoter patch, for now it is
    sufficient to release it when calling dsos__exit(), i.e. when deleting
    the whole list as part of deleting the 'struct machine' containing it,
    which will leave only referenced objects being used.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: http://lkml.kernel.org/n/tip-majzgz07cm90t2tejrjy4clf@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 0cf56d6f073a..132e35765101 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -82,7 +82,7 @@ struct machine *machine__new_host(void)
 	return NULL;
 }
 
-static void dsos__exit(struct dsos *dsos)
+static void dsos__purge(struct dsos *dsos)
 {
 	struct dso *pos, *n;
 
@@ -90,12 +90,16 @@ static void dsos__exit(struct dsos *dsos)
 
 	list_for_each_entry_safe(pos, n, &dsos->head, node) {
 		RB_CLEAR_NODE(&pos->rb_node);
-		list_del(&pos->node);
-		dso__delete(pos);
+		list_del_init(&pos->node);
+		dso__put(pos);
 	}
 
 	pthread_rwlock_unlock(&dsos->lock);
+}
 
+static void dsos__exit(struct dsos *dsos)
+{
+	dsos__purge(dsos);
 	pthread_rwlock_destroy(&dsos->lock);
 }
 
@@ -524,6 +528,7 @@ static struct dso *machine__findnew_module_dso(struct machine *machine,
 		dso__set_long_name(dso, strdup(filename), true);
 	}
 
+	dso__get(dso);
 out_unlock:
 	pthread_rwlock_unlock(&machine->dsos.lock);
 	return dso;
@@ -1205,8 +1210,10 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 			goto out_problem;
 
 		kernel->kernel = kernel_type;
-		if (__machine__create_kernel_maps(machine, kernel) < 0)
+		if (__machine__create_kernel_maps(machine, kernel) < 0) {
+			dso__put(kernel);
 			goto out_problem;
+		}
 
 		if (strstr(kernel->long_name, "vmlinux"))
 			dso__set_short_name(kernel, "[kernel.vmlinux]", false);

commit e88078442232f3bbcb4ff1d24b3f9ab3dca472b9
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Jun 1 15:40:01 2015 -0300

    perf tools: Protect accesses the dso rbtrees/lists with a rw lock
    
    To allow concurrent access, next step: refcount struct dso instances, so
    that we can ditch unused them when the last map pointing to it goes
    away.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: http://lkml.kernel.org/n/tip-yk1k08etpd2aoe3tnrf0oizn@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index dfd419797e6e..0cf56d6f073a 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -20,6 +20,7 @@ static void dsos__init(struct dsos *dsos)
 {
 	INIT_LIST_HEAD(&dsos->head);
 	dsos->root = RB_ROOT;
+	pthread_rwlock_init(&dsos->lock, NULL);
 }
 
 int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
@@ -81,15 +82,21 @@ struct machine *machine__new_host(void)
 	return NULL;
 }
 
-static void dsos__delete(struct dsos *dsos)
+static void dsos__exit(struct dsos *dsos)
 {
 	struct dso *pos, *n;
 
+	pthread_rwlock_wrlock(&dsos->lock);
+
 	list_for_each_entry_safe(pos, n, &dsos->head, node) {
 		RB_CLEAR_NODE(&pos->rb_node);
 		list_del(&pos->node);
 		dso__delete(pos);
 	}
+
+	pthread_rwlock_unlock(&dsos->lock);
+
+	pthread_rwlock_destroy(&dsos->lock);
 }
 
 void machine__delete_threads(struct machine *machine)
@@ -110,7 +117,7 @@ void machine__delete_threads(struct machine *machine)
 void machine__exit(struct machine *machine)
 {
 	map_groups__exit(&machine->kmaps);
-	dsos__delete(&machine->dsos);
+	dsos__exit(&machine->dsos);
 	machine__exit_vdso(machine);
 	zfree(&machine->root_dir);
 	zfree(&machine->current_tid);
@@ -496,11 +503,13 @@ static struct dso *machine__findnew_module_dso(struct machine *machine,
 {
 	struct dso *dso;
 
-	dso = dsos__find(&machine->dsos, m->name, true);
+	pthread_rwlock_wrlock(&machine->dsos.lock);
+
+	dso = __dsos__find(&machine->dsos, m->name, true);
 	if (!dso) {
-		dso = dsos__addnew(&machine->dsos, m->name);
+		dso = __dsos__addnew(&machine->dsos, m->name);
 		if (dso == NULL)
-			return NULL;
+			goto out_unlock;
 
 		if (machine__is_host(machine))
 			dso->symtab_type = DSO_BINARY_TYPE__SYSTEM_PATH_KMODULE;
@@ -515,6 +524,8 @@ static struct dso *machine__findnew_module_dso(struct machine *machine,
 		dso__set_long_name(dso, strdup(filename), true);
 	}
 
+out_unlock:
+	pthread_rwlock_unlock(&machine->dsos.lock);
 	return dso;
 }
 
@@ -1156,6 +1167,8 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 		struct dso *kernel = NULL;
 		struct dso *dso;
 
+		pthread_rwlock_rdlock(&machine->dsos.lock);
+
 		list_for_each_entry(dso, &machine->dsos.head, node) {
 
 			/*
@@ -1184,6 +1197,8 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 			break;
 		}
 
+		pthread_rwlock_unlock(&machine->dsos.lock);
+
 		if (kernel == NULL)
 			kernel = machine__findnew_dso(machine, kmmap_prefix);
 		if (kernel == NULL)
@@ -1948,5 +1963,5 @@ int machine__get_kernel_start(struct machine *machine)
 
 struct dso *machine__findnew_dso(struct machine *machine, const char *filename)
 {
-	return __dsos__findnew(&machine->dsos, filename);
+	return dsos__findnew(&machine->dsos, filename);
 }

commit 9f2de31542f1ac38a15117f90ee6b8449951d86e
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Jun 1 12:01:02 2015 -0300

    perf machine: Fix up some more method names
    
    Calling the function 'machine__new_module' implies a new 'module' will
    be allocated, when in fact what is returned is a 'struct map' instance,
    that not necessarily will be instantiated, as if one already exists with
    the given module name, it will be returned instead.
    
    So be consistent with other "find and if not there, create" like
    functions, like machine__findnew_thread, machine__findnew_dso, etc, and
    rename it to machine__findnew_module_map(), that in turn will call
    machine__findnew_module_dso().
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: http://lkml.kernel.org/n/tip-acv830vd3hwww2ih5vjtbmu3@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index f15ed24a22ac..dfd419797e6e 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -490,9 +490,9 @@ int machine__process_lost_samples_event(struct machine *machine __maybe_unused,
 	return 0;
 }
 
-static struct dso*
-machine__module_dso(struct machine *machine, struct kmod_path *m,
-		    const char *filename)
+static struct dso *machine__findnew_module_dso(struct machine *machine,
+					       struct kmod_path *m,
+					       const char *filename)
 {
 	struct dso *dso;
 
@@ -534,8 +534,8 @@ int machine__process_itrace_start_event(struct machine *machine __maybe_unused,
 	return 0;
 }
 
-struct map *machine__new_module(struct machine *machine, u64 start,
-				const char *filename)
+struct map *machine__findnew_module_map(struct machine *machine, u64 start,
+					const char *filename)
 {
 	struct map *map = NULL;
 	struct dso *dso;
@@ -549,7 +549,7 @@ struct map *machine__new_module(struct machine *machine, u64 start,
 	if (map)
 		goto out;
 
-	dso = machine__module_dso(machine, &m, filename);
+	dso = machine__findnew_module_dso(machine, &m, filename);
 	if (dso == NULL)
 		goto out;
 
@@ -1017,7 +1017,7 @@ static int machine__create_module(void *arg, const char *name, u64 start)
 	struct machine *machine = arg;
 	struct map *map;
 
-	map = machine__new_module(machine, start, name);
+	map = machine__findnew_module_map(machine, start, name);
 	if (map == NULL)
 		return -1;
 
@@ -1140,8 +1140,8 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 				strlen(kmmap_prefix) - 1) == 0;
 	if (event->mmap.filename[0] == '/' ||
 	    (!is_kernel_mmap && event->mmap.filename[0] == '[')) {
-		map = machine__new_module(machine, event->mmap.start,
-					  event->mmap.filename);
+		map = machine__findnew_module_map(machine, event->mmap.start,
+						  event->mmap.filename);
 		if (map == NULL)
 			goto out_problem;
 

commit c4937a91ea56b546234b0608a413ebad90536d26
Author: Kan Liang <kan.liang@intel.com>
Date:   Sun May 10 15:13:15 2015 -0400

    perf tools: handle PERF_RECORD_LOST_SAMPLES
    
    This patch modifies the perf tool to handle the new RECORD type,
    PERF_RECORD_LOST_SAMPLES.
    
    The number of lost-sample events is stored in
    .nr_events[PERF_RECORD_LOST_SAMPLES]. The exact number of samples
    which the kernel dropped is stored in total_lost_samples.
    
    When the percentage of dropped samples is greater than 5%, a warning
    is printed.
    
    Here are some examples:
    
    Eg 1, Recording different frequently-occurring events is safe with the
          patch. Only a very low drop rate is associated with such actions.
    
    $ perf record -e '{cycles:p,instructions:p}' -c 20003 --no-time ~/tchain ~/tchain
    
    $ perf report -D | tail
              SAMPLE events:     120243
               MMAP2 events:          5
        LOST_SAMPLES events:         24
      FINISHED_ROUND events:         15
    cycles:p stats:
               TOTAL events:      59348
              SAMPLE events:      59348
    instructions:p stats:
               TOTAL events:      60895
              SAMPLE events:      60895
    
    $ perf report --stdio --group
     # To display the perf.data header info, please use --header/--header-only options.
     #
     #
     # Total Lost Samples: 24
     #
     # Samples: 120K of event 'anon group { cycles:p, instructions:p }'
     # Event count (approx.): 24048600000
     #
     #         Overhead  Command      Shared Object     Symbol
     # ................  ...........  ................
     ..................................
     #
        99.74%  99.86%  tchain_edit  tchain_edit       [.] f3
         0.09%   0.02%  tchain_edit  tchain_edit       [.] f2
         0.04%   0.00%  tchain_edit  [kernel.vmlinux]  [k] ixgbe_read_reg
    
    Eg 2, Recording the same thing multiple times can lead to high drop
          rate, but it is not a useful configuration.
    
    $ perf record -e '{cycles:p,cycles:p}' -c 20003 --no-time ~/tchain
    Warning: Processed 600592 samples and lost 99.73% samples!
    [perf record: Woken up 148 times to write data]
    [perf record: Captured and wrote 36.922 MB perf.data (1206322 samples)]
    [perf record: Woken up 1 times to write data]
    [perf record: Captured and wrote 0.121 MB perf.data (1629 samples)]
    
    Signed-off-by: Kan Liang <kan.liang@intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: acme@infradead.org
    Cc: eranian@google.com
    Link: http://lkml.kernel.org/r/1431285195-14269-9-git-send-email-kan.liang@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 9e02c86f39f5..f15ed24a22ac 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -482,6 +482,14 @@ int machine__process_lost_event(struct machine *machine __maybe_unused,
 	return 0;
 }
 
+int machine__process_lost_samples_event(struct machine *machine __maybe_unused,
+					union perf_event *event, struct perf_sample *sample)
+{
+	dump_printf(": id:%" PRIu64 ": lost samples :%" PRIu64 "\n",
+		    sample->id, event->lost_samples.lost);
+	return 0;
+}
+
 static struct dso*
 machine__module_dso(struct machine *machine, struct kmod_path *m,
 		    const char *filename)
@@ -1419,6 +1427,8 @@ int machine__process_event(struct machine *machine, union perf_event *event,
 		ret = machine__process_aux_event(machine, event); break;
 	case PERF_RECORD_ITRACE_START:
 		ret = machine__process_itrace_start_event(machine, event);
+	case PERF_RECORD_LOST_SAMPLES:
+		ret = machine__process_lost_samples_event(machine, event, sample); break;
 		break;
 	default:
 		ret = -1;

commit 1f121b03d058dd07199d8924373d3c52a207f63b
Author: Wang Nan <wangnan0@huawei.com>
Date:   Wed Jun 3 08:52:21 2015 +0000

    perf tools: Deal with kernel module names in '[]' correctly
    
    Before patch ba92732e9808 ('perf kmaps: Check kmaps to make code more
    robust'), 'perf report' and 'perf annotate' will segfault if trace data
    contains kernel module information like this:
    
     # perf report -D -i ./perf.data
     ...
     0 0 0x188 [0x50]: PERF_RECORD_MMAP -1/0: [0xffffffbff1018000(0xf068000) @ 0]: x [test_module]
     ...
    
     # perf report -i ./perf.data --objdump=/path/to/objdump --kallsyms=/path/to/kallsyms
    
     perf: Segmentation fault
     -------- backtrace --------
     /path/to/perf[0x503478]
     /lib64/libc.so.6(+0x3545f)[0x7fb201f3745f]
     /path/to/perf[0x499b56]
     /path/to/perf(dso__load_kallsyms+0x13c)[0x49b56c]
     /path/to/perf(dso__load+0x72e)[0x49c21e]
     /path/to/perf(map__load+0x6e)[0x4ae9ee]
     /path/to/perf(thread__find_addr_map+0x24c)[0x47deec]
     /path/to/perf(perf_event__preprocess_sample+0x88)[0x47e238]
     /path/to/perf[0x43ad02]
     /path/to/perf[0x4b55bc]
     /path/to/perf(ordered_events__flush+0xca)[0x4b57ea]
     /path/to/perf[0x4b1a01]
     /path/to/perf(perf_session__process_events+0x3be)[0x4b428e]
     /path/to/perf(cmd_report+0xf11)[0x43bfc1]
     /path/to/perf[0x474702]
     /path/to/perf(main+0x5f5)[0x42de95]
     /lib64/libc.so.6(__libc_start_main+0xf4)[0x7fb201f23bd4]
     /path/to/perf[0x42dfc4]
    
    This is because __kmod_path__parse treats '[' leading names as kernel
    name instead of names of kernel module.
    
    If perf.data contains build information and the buildid of such modules
    can be found, the dso->kernel of it will be set to DSO_TYPE_KERNEL by
    __event_process_build_id(), not kernel module.
    
    It will then be passed to dso__load() -> dso__load_kernel_sym() ->
    dso__load_kcore() if --kallsyms is provided.
    
    The refered patch adds NULL pointer checker to avoid segfault. However,
    such kernel modules are still processed incorrectly.
    
    This patch fixes __kmod_path__parse, makes it treat names like
    '[test_module]' as kernel modules.
    
    kmod-path.c is also update to reflect the above changes.
    
    Signed-off-by: Wang Nan <wangnan0@huawei.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Zefan Li <lizefan@huawei.com>
    Link: http://lkml.kernel.org/r/1433321541-170245-1-git-send-email-wangnan0@huawei.com
    [ Fixed the merged with 0443f36b0de0 ("perf machine: Fix the search
      for the kernel DSO on the unified list" ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 4e29e80932e5..9e02c86f39f5 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1149,9 +1149,29 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 		struct dso *dso;
 
 		list_for_each_entry(dso, &machine->dsos.head, node) {
-			if (!dso->kernel || is_kernel_module(dso->long_name))
+
+			/*
+			 * The cpumode passed to is_kernel_module is not the
+			 * cpumode of *this* event. If we insist on passing
+			 * correct cpumode to is_kernel_module, we should
+			 * record the cpumode when we adding this dso to the
+			 * linked list.
+			 *
+			 * However we don't really need passing correct
+			 * cpumode.  We know the correct cpumode must be kernel
+			 * mode (if not, we should not link it onto kernel_dsos
+			 * list).
+			 *
+			 * Therefore, we pass PERF_RECORD_MISC_CPUMODE_UNKNOWN.
+			 * is_kernel_module() treats it as a kernel cpumode.
+			 */
+
+			if (!dso->kernel ||
+			    is_kernel_module(dso->long_name,
+					     PERF_RECORD_MISC_CPUMODE_UNKNOWN))
 				continue;
 
+
 			kernel = dso;
 			break;
 		}

commit 0443f36b0de026143a78c858aac773572f7dd5db
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Jun 2 11:28:13 2015 -0300

    perf machine: Fix the search for the kernel DSO on the unified list
    
    When unifying the user_dsos and kernel_dsos a bug was introduced by
    inverting the check for dso->kernel, fix it.
    
    Fixes: 3d39ac538629 ("perf machine: No need to have two DSOs lists")
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: http://lkml.kernel.org/n/tip-xnrnq0kams3s2z9ek1wjb506@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 2ed61f59d415..4e29e80932e5 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1149,7 +1149,7 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 		struct dso *dso;
 
 		list_for_each_entry(dso, &machine->dsos.head, node) {
-			if (dso->kernel && is_kernel_module(dso->long_name))
+			if (!dso->kernel || is_kernel_module(dso->long_name))
 				continue;
 
 			kernel = dso;

commit 9a4388c711d07889217b19eaf63485122dec8817
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri May 29 11:54:08 2015 -0300

    perf machine: Fix up vdso methods names
    
    To make it consistent with the other dso lifetime routines.
    
    For instance:
    
     struct dso *vdso__new(struct machine *machine, const char *short_name,
                            const char *long_name)
    
    Becomes:
    
     struct dso *machine__addnew_vdso(struct machine *machine, const
                                      char *short_name, const char *long_name)
    
    Because:
    
    1) There is no 'struct vdso' for us to have vdso__ prefixed routines.
    
    2) Because it will not really just create a new instance of 'struct
       dso', it'll call dso__new() but it will also insert it into the
       DSO's list/rbtree, and we have a method name for that: 'addnew',
       just like we have dsos__addnew().
    
    3) So it is really a 'struct machine' operation, it is the first
       argument, etc.
    
    This way the place where this is used gets consistent:
    
                    if (vdso) {
                            pgoff = 0;
    -                       dso = vdso__dso_findnew(machine, thread);
    +                       dso = machine__findnew_vdso(machine, thread);
                    } else
                            dso = machine__findnew_dso(machine, filename);
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: http://lkml.kernel.org/n/tip-r3w3tvh8exm9xfz3p4tz9qbz@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 698da1da5168..2ed61f59d415 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -111,7 +111,7 @@ void machine__exit(struct machine *machine)
 {
 	map_groups__exit(&machine->kmaps);
 	dsos__delete(&machine->dsos);
-	vdso__exit(machine);
+	machine__exit_vdso(machine);
 	zfree(&machine->root_dir);
 	zfree(&machine->current_tid);
 	pthread_rwlock_destroy(&machine->threads_lock);

commit aa7cc2ae5ae69aff555793fbfcff514141bb23f3
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri May 29 11:31:12 2015 -0300

    perf machine: Introduce machine__findnew_dso() method
    
    Similar to machine__findnew_thread(), also prepping for refcounting and
    locking, this time for struct dso instances.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: http://lkml.kernel.org/n/tip-fv3tshv5o1413coh147lszjc@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index ffd31079d447..698da1da5168 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1157,7 +1157,7 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 		}
 
 		if (kernel == NULL)
-			kernel = __dsos__findnew(&machine->dsos, kmmap_prefix);
+			kernel = machine__findnew_dso(machine, kmmap_prefix);
 		if (kernel == NULL)
 			goto out_problem;
 
@@ -1915,3 +1915,8 @@ int machine__get_kernel_start(struct machine *machine)
 	}
 	return err;
 }
+
+struct dso *machine__findnew_dso(struct machine *machine, const char *filename)
+{
+	return __dsos__findnew(&machine->dsos, filename);
+}

commit 3d39ac538629e4f00a6e1c38d46346f1b8e69505
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu May 28 13:06:42 2015 -0300

    perf machine: No need to have two DSOs lists
    
    We can, given a DSO, figure out if it is a kernel, a kernel module or
    a userlevel DSO, so stop having to process two lists in several
    functions.
    
    If searching becomes an issue at some point, we can have them in a
    rbtree, etc.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-s4yb0onpdywu6dj2xl9lxi4t@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 8934dc4345fe..ffd31079d447 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -26,8 +26,7 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 {
 	map_groups__init(&machine->kmaps, machine);
 	RB_CLEAR_NODE(&machine->rb_node);
-	dsos__init(&machine->user_dsos);
-	dsos__init(&machine->kernel_dsos);
+	dsos__init(&machine->dsos);
 
 	machine->threads = RB_ROOT;
 	pthread_rwlock_init(&machine->threads_lock, NULL);
@@ -111,8 +110,7 @@ void machine__delete_threads(struct machine *machine)
 void machine__exit(struct machine *machine)
 {
 	map_groups__exit(&machine->kmaps);
-	dsos__delete(&machine->user_dsos);
-	dsos__delete(&machine->kernel_dsos);
+	dsos__delete(&machine->dsos);
 	vdso__exit(machine);
 	zfree(&machine->root_dir);
 	zfree(&machine->current_tid);
@@ -490,9 +488,9 @@ machine__module_dso(struct machine *machine, struct kmod_path *m,
 {
 	struct dso *dso;
 
-	dso = dsos__find(&machine->kernel_dsos, m->name, true);
+	dso = dsos__find(&machine->dsos, m->name, true);
 	if (!dso) {
-		dso = dsos__addnew(&machine->kernel_dsos, m->name);
+		dso = dsos__addnew(&machine->dsos, m->name);
 		if (dso == NULL)
 			return NULL;
 
@@ -561,13 +559,11 @@ struct map *machine__new_module(struct machine *machine, u64 start,
 size_t machines__fprintf_dsos(struct machines *machines, FILE *fp)
 {
 	struct rb_node *nd;
-	size_t ret = __dsos__fprintf(&machines->host.kernel_dsos.head, fp) +
-		     __dsos__fprintf(&machines->host.user_dsos.head, fp);
+	size_t ret = __dsos__fprintf(&machines->host.dsos.head, fp);
 
 	for (nd = rb_first(&machines->guests); nd; nd = rb_next(nd)) {
 		struct machine *pos = rb_entry(nd, struct machine, rb_node);
-		ret += __dsos__fprintf(&pos->kernel_dsos.head, fp);
-		ret += __dsos__fprintf(&pos->user_dsos.head, fp);
+		ret += __dsos__fprintf(&pos->dsos.head, fp);
 	}
 
 	return ret;
@@ -576,8 +572,7 @@ size_t machines__fprintf_dsos(struct machines *machines, FILE *fp)
 size_t machine__fprintf_dsos_buildid(struct machine *m, FILE *fp,
 				     bool (skip)(struct dso *dso, int parm), int parm)
 {
-	return __dsos__fprintf_buildid(&m->kernel_dsos.head, fp, skip, parm) +
-	       __dsos__fprintf_buildid(&m->user_dsos.head, fp, skip, parm);
+	return __dsos__fprintf_buildid(&m->dsos.head, fp, skip, parm);
 }
 
 size_t machines__fprintf_dsos_buildid(struct machines *machines, FILE *fp,
@@ -1106,7 +1101,7 @@ static bool machine__uses_kcore(struct machine *machine)
 {
 	struct dso *dso;
 
-	list_for_each_entry(dso, &machine->kernel_dsos.head, node) {
+	list_for_each_entry(dso, &machine->dsos.head, node) {
 		if (dso__is_kcore(dso))
 			return true;
 	}
@@ -1153,8 +1148,8 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 		struct dso *kernel = NULL;
 		struct dso *dso;
 
-		list_for_each_entry(dso, &machine->kernel_dsos.head, node) {
-			if (is_kernel_module(dso->long_name))
+		list_for_each_entry(dso, &machine->dsos.head, node) {
+			if (dso->kernel && is_kernel_module(dso->long_name))
 				continue;
 
 			kernel = dso;
@@ -1162,8 +1157,7 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 		}
 
 		if (kernel == NULL)
-			kernel = __dsos__findnew(&machine->kernel_dsos,
-						 kmmap_prefix);
+			kernel = __dsos__findnew(&machine->dsos, kmmap_prefix);
 		if (kernel == NULL)
 			goto out_problem;
 

commit 459ce518d9b563a99faa73aa340b764e0b3fb143
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu May 28 12:40:55 2015 -0300

    perf machine: Adopt findnew_kernel method
    
    It never was a 'struct dso' method, so fix that by rename
    dso__kernel_findnew() to machine__findnew_kernel().
    
    At some point I'll move it all to the machine.[ch] files, for now
    lets ease patch review by not moving too much stuff.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-zrxmblgsg5vx0iv4rhvq2f6l@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 0c0e61cce577..8934dc4345fe 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -640,9 +640,8 @@ static struct dso *machine__get_kernel(struct machine *machine)
 		if (!vmlinux_name)
 			vmlinux_name = "[kernel.kallsyms]";
 
-		kernel = dso__kernel_findnew(machine, vmlinux_name,
-					     "[kernel]",
-					     DSO_TYPE_KERNEL);
+		kernel = machine__findnew_kernel(machine, vmlinux_name,
+						 "[kernel]", DSO_TYPE_KERNEL);
 	} else {
 		char bf[PATH_MAX];
 
@@ -652,9 +651,9 @@ static struct dso *machine__get_kernel(struct machine *machine)
 			vmlinux_name = machine__mmap_name(machine, bf,
 							  sizeof(bf));
 
-		kernel = dso__kernel_findnew(machine, vmlinux_name,
-					     "[guest.kernel]",
-					     DSO_TYPE_GUEST_KERNEL);
+		kernel = machine__findnew_kernel(machine, vmlinux_name,
+						 "[guest.kernel]",
+						 DSO_TYPE_GUEST_KERNEL);
 	}
 
 	if (kernel != NULL && (!kernel->has_build_id))

commit 84c2cafa288939e11d21c7830e32b2aee21b723e
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon May 25 16:59:56 2015 -0300

    perf tools: Reference count struct map
    
    We have pointers to struct map instances in several places, like in the
    hist_entry instances, so we need a way to know when we can destroy them,
    otherwise we may either keep leaking them or end up referencing deleted
    instances.
    
    Start fixing it by reference counting them.
    
    This patch puts the reference count for struct map in place, replacing
    direct map__delete() calls with map__put() ones and then grabbing a
    reference count when adding it to the maps struct where maps for a
    struct thread are kept.
    
    Next we'll grab reference counts when setting pointers to struct map
    instances, in places like in the hist_entry code.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-wi19xczk0t2a41r1i2chuio5@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 6bf845758ae3..0c0e61cce577 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -759,7 +759,6 @@ void machine__destroy_kernel_maps(struct machine *machine)
 				kmap->ref_reloc_sym = NULL;
 		}
 
-		map__delete(machine->vmlinux_maps[type]);
 		machine->vmlinux_maps[type] = NULL;
 	}
 }
@@ -1247,6 +1246,7 @@ int machine__process_mmap2_event(struct machine *machine,
 
 	thread__insert_map(thread, map);
 	thread__put(thread);
+	map__put(map);
 	return 0;
 
 out_problem_map:
@@ -1297,6 +1297,7 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 
 	thread__insert_map(thread, map);
 	thread__put(thread);
+	map__put(map);
 	return 0;
 
 out_problem_map:

commit 0170b14f5f5462524d05ee96275b7a0a0d34ae77
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon May 25 15:23:05 2015 -0300

    perf machine: Mark removed threads as such
    
    We use:
    
      BUG_ON(!RB_EMPTY_NODE(&thread->rb_node));
    
    in the thread destructor as a debugging check to find out about
    possibly still referenced thread instances being deleted, to do that
    we need to make sure we use RB_CLEAR_NODE() right after rb_erase(),
    i.e. that we use the newly introduced rb_erase_init(), that works
    just like list_del_init().
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-4fcqo5ypy1cjjf15ilb0hn78@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 7ec3188d3cb3..6bf845758ae3 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -400,7 +400,7 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 		 * leader and that would screwed the rb tree.
 		 */
 		if (thread__init_map_groups(th, machine)) {
-			rb_erase(&th->rb_node, &machine->threads);
+			rb_erase_init(&th->rb_node, &machine->threads);
 			RB_CLEAR_NODE(&th->rb_node);
 			thread__delete(th);
 			return NULL;
@@ -1314,7 +1314,7 @@ static void __machine__remove_thread(struct machine *machine, struct thread *th,
 	BUG_ON(atomic_read(&th->refcnt) == 0);
 	if (lock)
 		pthread_rwlock_wrlock(&machine->threads_lock);
-	rb_erase(&th->rb_node, &machine->threads);
+	rb_erase_init(&th->rb_node, &machine->threads);
 	RB_CLEAR_NODE(&th->rb_node);
 	/*
 	 * Move it first to the dead_threads list, then drop the reference,

commit 8e160b2e1e3efdd84ddef726f9b5136dd192a682
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue May 19 20:07:14 2015 -0300

    perf machine: Do not call map_groups__delete(), drop refcnt instead
    
    It could be used somewhere, so just call map__groups_put() to make sure
    we don't delete it prematurely
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-dxmh8mr12i65p8h909vi88cp@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index daa55910ff28..7ec3188d3cb3 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -333,7 +333,7 @@ static void machine__update_thread_pid(struct machine *machine,
 		if (!map_groups__empty(th->mg))
 			pr_err("Discarding thread maps for %d:%d\n",
 			       th->pid_, th->tid);
-		map_groups__delete(th->mg);
+		map_groups__put(th->mg);
 	}
 
 	th->mg = map_groups__get(leader->mg);

commit 59a51c1dc9fbb3fb4af928b852d7b35df83edd74
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri May 15 15:32:55 2015 -0300

    perf machine: Stop accessing atomic_t::counter directly
    
    Use atomic_read(&counter) instead.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-k3hvfvpaut8wp02lzq27muhb@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 34bf89f7f4f3..daa55910ff28 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1311,7 +1311,7 @@ static void __machine__remove_thread(struct machine *machine, struct thread *th,
 	if (machine->last_match == th)
 		machine->last_match = NULL;
 
-	BUG_ON(th->refcnt.counter == 0);
+	BUG_ON(atomic_read(&th->refcnt) == 0);
 	if (lock)
 		pthread_rwlock_wrlock(&machine->threads_lock);
 	rb_erase(&th->rb_node, &machine->threads);

commit 0ceb8f6e6cbafee0fa0e671e48213e24fae887f7
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon May 11 18:08:12 2015 -0300

    perf machine: No need to keep a refcnt for last_match
    
    Since it is all associated with the refcount for keeping the thread
    in the rbtree, it is excessive and unecessarily complex to hold a
    refcont when changing machine->last_match.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-98kuesmfwtvhsrzx7ttyb0kt@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 8b0b307d91f4..34bf89f7f4f3 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -364,7 +364,7 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 			return th;
 		}
 
-		thread__zput(machine->last_match);
+		machine->last_match = NULL;
 	}
 
 	while (*p != NULL) {
@@ -372,7 +372,7 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 		th = rb_entry(parent, struct thread, rb_node);
 
 		if (th->tid == tid) {
-			machine->last_match = thread__get(th);
+			machine->last_match = th;
 			machine__update_thread_pid(machine, th, pid);
 			return th;
 		}
@@ -409,7 +409,7 @@ static struct thread *____machine__findnew_thread(struct machine *machine,
 		 * It is now in the rbtree, get a ref
 		 */
 		thread__get(th);
-		machine->last_match = thread__get(th);
+		machine->last_match = th;
 	}
 
 	return th;
@@ -1309,7 +1309,7 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 static void __machine__remove_thread(struct machine *machine, struct thread *th, bool lock)
 {
 	if (machine->last_match == th)
-		thread__zput(machine->last_match);
+		machine->last_match = NULL;
 
 	BUG_ON(th->refcnt.counter == 0);
 	if (lock)

commit b91fc39f4ad7503419dd617df78401fa36266cb3
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Apr 6 20:43:22 2015 -0300

    perf machine: Protect the machine->threads with a rwlock
    
    In addition to using refcounts for the struct thread lifetime
    management, we need to protect access to machine->threads from
    concurrent access.
    
    That happens in 'perf top', where a thread processes events, inserting
    and deleting entries from that rb_tree while another thread decays
    hist_entries, that end up dropping references and ultimately deleting
    threads from the rb_tree and releasing its resources when no further
    hist_entry (or other data structures, like in 'perf sched') references
    it.
    
    So the rule is the same for refcounts + protected trees in the kernel,
    get the tree lock, find object, bump the refcount, drop the tree lock,
    return, use object, drop the refcount if no more use of it is needed,
    keep it if storing it in some other data structure, drop when releasing
    that data structure.
    
    I.e. pair "t = machine__find(new)_thread()" with a "thread__put(t)", and
    "perf_event__preprocess_sample(&al)" with "addr_location__put(&al)".
    
    The addr_location__put() one is because as we return references to
    several data structures, we may end up adding more reference counting
    for the other data structures and then we'll drop it at
    addr_location__put() time.
    
    Acked-by: David Ahern <dsahern@gmail.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-bs9rt4n0jw3hi9f3zxyy3xln@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 2f471105efb1..8b0b307d91f4 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -14,6 +14,8 @@
 #include "unwind.h"
 #include "linux/hash.h"
 
+static void __machine__remove_thread(struct machine *machine, struct thread *th, bool lock);
+
 static void dsos__init(struct dsos *dsos)
 {
 	INIT_LIST_HEAD(&dsos->head);
@@ -28,6 +30,7 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 	dsos__init(&machine->kernel_dsos);
 
 	machine->threads = RB_ROOT;
+	pthread_rwlock_init(&machine->threads_lock, NULL);
 	INIT_LIST_HEAD(&machine->dead_threads);
 	machine->last_match = NULL;
 
@@ -54,6 +57,7 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 
 		snprintf(comm, sizeof(comm), "[guest/%d]", pid);
 		thread__set_comm(thread, comm, 0);
+		thread__put(thread);
 	}
 
 	machine->current_tid = NULL;
@@ -91,14 +95,17 @@ static void dsos__delete(struct dsos *dsos)
 
 void machine__delete_threads(struct machine *machine)
 {
-	struct rb_node *nd = rb_first(&machine->threads);
+	struct rb_node *nd;
 
+	pthread_rwlock_wrlock(&machine->threads_lock);
+	nd = rb_first(&machine->threads);
 	while (nd) {
 		struct thread *t = rb_entry(nd, struct thread, rb_node);
 
 		nd = rb_next(nd);
-		machine__remove_thread(machine, t);
+		__machine__remove_thread(machine, t, false);
 	}
+	pthread_rwlock_unlock(&machine->threads_lock);
 }
 
 void machine__exit(struct machine *machine)
@@ -109,6 +116,7 @@ void machine__exit(struct machine *machine)
 	vdso__exit(machine);
 	zfree(&machine->root_dir);
 	zfree(&machine->current_tid);
+	pthread_rwlock_destroy(&machine->threads_lock);
 }
 
 void machine__delete(struct machine *machine)
@@ -303,7 +311,7 @@ static void machine__update_thread_pid(struct machine *machine,
 	if (th->pid_ == th->tid)
 		return;
 
-	leader = machine__findnew_thread(machine, th->pid_, th->pid_);
+	leader = __machine__findnew_thread(machine, th->pid_, th->pid_);
 	if (!leader)
 		goto out_err;
 
@@ -336,9 +344,9 @@ static void machine__update_thread_pid(struct machine *machine,
 	pr_err("Failed to join map groups for %d:%d\n", th->pid_, th->tid);
 }
 
-static struct thread *__machine__findnew_thread(struct machine *machine,
-						pid_t pid, pid_t tid,
-						bool create)
+static struct thread *____machine__findnew_thread(struct machine *machine,
+						  pid_t pid, pid_t tid,
+						  bool create)
 {
 	struct rb_node **p = &machine->threads.rb_node;
 	struct rb_node *parent = NULL;
@@ -393,6 +401,7 @@ static struct thread *__machine__findnew_thread(struct machine *machine,
 		 */
 		if (thread__init_map_groups(th, machine)) {
 			rb_erase(&th->rb_node, &machine->threads);
+			RB_CLEAR_NODE(&th->rb_node);
 			thread__delete(th);
 			return NULL;
 		}
@@ -406,16 +415,30 @@ static struct thread *__machine__findnew_thread(struct machine *machine,
 	return th;
 }
 
+struct thread *__machine__findnew_thread(struct machine *machine, pid_t pid, pid_t tid)
+{
+	return ____machine__findnew_thread(machine, pid, tid, true);
+}
+
 struct thread *machine__findnew_thread(struct machine *machine, pid_t pid,
 				       pid_t tid)
 {
-	return __machine__findnew_thread(machine, pid, tid, true);
+	struct thread *th;
+
+	pthread_rwlock_wrlock(&machine->threads_lock);
+	th = thread__get(__machine__findnew_thread(machine, pid, tid));
+	pthread_rwlock_unlock(&machine->threads_lock);
+	return th;
 }
 
 struct thread *machine__find_thread(struct machine *machine, pid_t pid,
 				    pid_t tid)
 {
-	return __machine__findnew_thread(machine, pid, tid, false);
+	struct thread *th;
+	pthread_rwlock_rdlock(&machine->threads_lock);
+	th =  thread__get(____machine__findnew_thread(machine, pid, tid, false));
+	pthread_rwlock_unlock(&machine->threads_lock);
+	return th;
 }
 
 struct comm *machine__thread_exec_comm(struct machine *machine,
@@ -434,6 +457,7 @@ int machine__process_comm_event(struct machine *machine, union perf_event *event
 							event->comm.pid,
 							event->comm.tid);
 	bool exec = event->header.misc & PERF_RECORD_MISC_COMM_EXEC;
+	int err = 0;
 
 	if (exec)
 		machine->comm_exec = true;
@@ -444,10 +468,12 @@ int machine__process_comm_event(struct machine *machine, union perf_event *event
 	if (thread == NULL ||
 	    __thread__set_comm(thread, event->comm.comm, sample->time, exec)) {
 		dump_printf("problem processing PERF_RECORD_COMM, skipping event.\n");
-		return -1;
+		err = -1;
 	}
 
-	return 0;
+	thread__put(thread);
+
+	return err;
 }
 
 int machine__process_lost_event(struct machine *machine __maybe_unused,
@@ -591,12 +617,16 @@ size_t machine__fprintf(struct machine *machine, FILE *fp)
 	size_t ret = 0;
 	struct rb_node *nd;
 
+	pthread_rwlock_rdlock(&machine->threads_lock);
+
 	for (nd = rb_first(&machine->threads); nd; nd = rb_next(nd)) {
 		struct thread *pos = rb_entry(nd, struct thread, rb_node);
 
 		ret += thread__fprintf(pos, fp);
 	}
 
+	pthread_rwlock_unlock(&machine->threads_lock);
+
 	return ret;
 }
 
@@ -1213,11 +1243,14 @@ int machine__process_mmap2_event(struct machine *machine,
 			event->mmap2.filename, type, thread);
 
 	if (map == NULL)
-		goto out_problem;
+		goto out_problem_map;
 
 	thread__insert_map(thread, map);
+	thread__put(thread);
 	return 0;
 
+out_problem_map:
+	thread__put(thread);
 out_problem:
 	dump_printf("problem processing PERF_RECORD_MMAP2, skipping event.\n");
 	return 0;
@@ -1260,31 +1293,45 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 			type, thread);
 
 	if (map == NULL)
-		goto out_problem;
+		goto out_problem_map;
 
 	thread__insert_map(thread, map);
+	thread__put(thread);
 	return 0;
 
+out_problem_map:
+	thread__put(thread);
 out_problem:
 	dump_printf("problem processing PERF_RECORD_MMAP, skipping event.\n");
 	return 0;
 }
 
-void machine__remove_thread(struct machine *machine, struct thread *th)
+static void __machine__remove_thread(struct machine *machine, struct thread *th, bool lock)
 {
 	if (machine->last_match == th)
 		thread__zput(machine->last_match);
 
+	BUG_ON(th->refcnt.counter == 0);
+	if (lock)
+		pthread_rwlock_wrlock(&machine->threads_lock);
 	rb_erase(&th->rb_node, &machine->threads);
+	RB_CLEAR_NODE(&th->rb_node);
 	/*
 	 * Move it first to the dead_threads list, then drop the reference,
 	 * if this is the last reference, then the thread__delete destructor
 	 * will be called and we will remove it from the dead_threads list.
 	 */
 	list_add_tail(&th->node, &machine->dead_threads);
+	if (lock)
+		pthread_rwlock_unlock(&machine->threads_lock);
 	thread__put(th);
 }
 
+void machine__remove_thread(struct machine *machine, struct thread *th)
+{
+	return __machine__remove_thread(machine, th, true);
+}
+
 int machine__process_fork_event(struct machine *machine, union perf_event *event,
 				struct perf_sample *sample)
 {
@@ -1294,10 +1341,13 @@ int machine__process_fork_event(struct machine *machine, union perf_event *event
 	struct thread *parent = machine__findnew_thread(machine,
 							event->fork.ppid,
 							event->fork.ptid);
+	int err = 0;
 
 	/* if a thread currently exists for the thread id remove it */
-	if (thread != NULL)
+	if (thread != NULL) {
 		machine__remove_thread(machine, thread);
+		thread__put(thread);
+	}
 
 	thread = machine__findnew_thread(machine, event->fork.pid,
 					 event->fork.tid);
@@ -1307,10 +1357,12 @@ int machine__process_fork_event(struct machine *machine, union perf_event *event
 	if (thread == NULL || parent == NULL ||
 	    thread__fork(thread, parent, sample->time) < 0) {
 		dump_printf("problem processing PERF_RECORD_FORK, skipping event.\n");
-		return -1;
+		err = -1;
 	}
+	thread__put(thread);
+	thread__put(parent);
 
-	return 0;
+	return err;
 }
 
 int machine__process_exit_event(struct machine *machine, union perf_event *event,
@@ -1323,8 +1375,10 @@ int machine__process_exit_event(struct machine *machine, union perf_event *event
 	if (dump_trace)
 		perf_event__fprintf_task(event, stdout);
 
-	if (thread != NULL)
+	if (thread != NULL) {
 		thread__exited(thread);
+		thread__put(thread);
+	}
 
 	return 0;
 }
@@ -1841,6 +1895,7 @@ int machine__set_current_tid(struct machine *machine, int cpu, pid_t pid,
 		return -ENOMEM;
 
 	thread->cpu = cpu;
+	thread__put(thread);
 
 	return 0;
 }

commit 0ad21f6869222fd7fd7c63f02febea082e801fc2
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Thu Apr 30 17:37:30 2015 +0300

    perf tools: Add support for PERF_RECORD_ITRACE_START
    
    Add support for the PERF_RECORD_ITRACE_START event type.  This event can
    be used to determine the pid and tid that are running when Instruction
    Tracing starts.  Generally that information would come from a
    sched_switch event but, at the start, no sched_switch events may yet
    have been recorded.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1430404667-10593-8-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index a7ad51100b55..2f471105efb1 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -494,6 +494,14 @@ int machine__process_aux_event(struct machine *machine __maybe_unused,
 	return 0;
 }
 
+int machine__process_itrace_start_event(struct machine *machine __maybe_unused,
+					union perf_event *event)
+{
+	if (dump_trace)
+		perf_event__fprintf_itrace_start(event, stdout);
+	return 0;
+}
+
 struct map *machine__new_module(struct machine *machine, u64 start,
 				const char *filename)
 {
@@ -1341,6 +1349,9 @@ int machine__process_event(struct machine *machine, union perf_event *event,
 		ret = machine__process_lost_event(machine, event, sample); break;
 	case PERF_RECORD_AUX:
 		ret = machine__process_aux_event(machine, event); break;
+	case PERF_RECORD_ITRACE_START:
+		ret = machine__process_itrace_start_event(machine, event);
+		break;
 	default:
 		ret = -1;
 		break;

commit 4a96f7a02eb52b1b618ab610e689bd82770f00b0
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Thu Apr 30 17:37:29 2015 +0300

    perf tools: Add support for PERF_RECORD_AUX
    
    Add support for the PERF_RECORD_AUX event type.
    
    PERF_RECORD_AUX is a new kernel event that records when new data lands
    in the AUX buffer. Currently it is assumed that AUX data follows the
    same ring buffer conventions used by the perf events buffer, and
    consequently the AUX event is not processed during recording.
    
    It is processed during session processing so that the information in the
    'flags' member is made available.
    
    The format of PERF_RECORD_AUX is outlined in the linux/perf_events.h
    header file. The 'flags' are also enumerated.
    
    Intel PT and Intel BTS use the flag named PERF_AUX_FLAG_TRUNCATED to
    determine if data has been lost because the buffer became full as perf
    was not able to empty it fast enough.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1430404667-10593-7-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 527e032e24f6..a7ad51100b55 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -486,6 +486,14 @@ machine__module_dso(struct machine *machine, struct kmod_path *m,
 	return dso;
 }
 
+int machine__process_aux_event(struct machine *machine __maybe_unused,
+			       union perf_event *event)
+{
+	if (dump_trace)
+		perf_event__fprintf_aux(event, stdout);
+	return 0;
+}
+
 struct map *machine__new_module(struct machine *machine, u64 start,
 				const char *filename)
 {
@@ -1331,6 +1339,8 @@ int machine__process_event(struct machine *machine, union perf_event *event,
 		ret = machine__process_exit_event(machine, event, sample); break;
 	case PERF_RECORD_LOST:
 		ret = machine__process_lost_event(machine, event, sample); break;
+	case PERF_RECORD_AUX:
+		ret = machine__process_aux_event(machine, event); break;
 	default:
 		ret = -1;
 		break;

commit 5e78c69b72276853ac64070a010e6df64723dba9
Author: He Kuang <hekuang@huawei.com>
Date:   Fri Apr 10 17:35:00 2015 +0800

    perf buildid-list: Fix segfault when show DSOs with hits
    
    commit: f3b623b8490a ("perf tools: Reference count struct thread")
    appends every thread->node to dead_threads in machine__remove_thread()
    and list_del_init() this node in thread__put().
    
    perf_event__exit_del_thread() releases thread wihout using
    machine__remove_thread(), and causes a NULL pointer crash when
    list_del_init(&thread->node) is called. Fix this by using
    machine_remove_thread() instead of using thread__put() directly.
    
    This problem can be reproduced as following:
    
      $ perf record ls
      $ perf buildid-list --with-hits
      [ 3874.195070] perf[1018]: segfault at 0 ip 00000000004b0b15 sp
      00007ffc35b44780 error 6 in perf[400000+166000]
      Segmentation fault
    
    After this patch:
      $ perf record ls
      $ perf buildid-list --with-hits
      bc23e7c3281e542650ba4324421d6acf78f4c23e /proc/kcore
      643324cb0e969f30c56d660f167f84a150845511 [vdso]
      0000000000000000000000000000000000000000 /bin/busybox
      ...
    
    Signed-off-by: He Kuang <hekuang@huawei.com>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/r/1428658500-6483-1-git-send-email-hekuang@huawei.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 9c380a2caa54..527e032e24f6 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -14,8 +14,6 @@
 #include "unwind.h"
 #include "linux/hash.h"
 
-static void machine__remove_thread(struct machine *machine, struct thread *th);
-
 static void dsos__init(struct dsos *dsos)
 {
 	INIT_LIST_HEAD(&dsos->head);
@@ -1256,7 +1254,7 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 	return 0;
 }
 
-static void machine__remove_thread(struct machine *machine, struct thread *th)
+void machine__remove_thread(struct machine *machine, struct thread *th)
 {
 	if (machine->last_match == th)
 		thread__zput(machine->last_match);

commit ba92732e9808df679ddf75c5ea1c0caae6d7dce2
Author: Wang Nan <wangnan0@huawei.com>
Date:   Tue Apr 7 08:22:45 2015 +0000

    perf kmaps: Check kmaps to make code more robust
    
    This patch add checks in places where map__kmap is used to get kmaps
    from struct kmap.
    
    Error messages are added at map__kmap to warn invalid accessing of kmap
    (for the case of !map->dso->kernel, kmap(map) does not exists at all).
    
    Also, introduces map__kmaps() to warn uninitialized kmaps.
    
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Wang Nan <wangnan0@huawei.com>
    Cc: pi3orama@163.com
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Zefan Li <lizefan@huawei.com>
    Link: http://lkml.kernel.org/r/1428394966-131044-2-git-send-email-wangnan0@huawei.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index e45c8f33a8fd..9c380a2caa54 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -679,6 +679,9 @@ int __machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
 			machine->vmlinux_maps[type]->unmap_ip =
 				identity__map_ip;
 		kmap = map__kmap(machine->vmlinux_maps[type]);
+		if (!kmap)
+			return -1;
+
 		kmap->kmaps = &machine->kmaps;
 		map_groups__insert(&machine->kmaps,
 				   machine->vmlinux_maps[type]);
@@ -700,7 +703,7 @@ void machine__destroy_kernel_maps(struct machine *machine)
 		kmap = map__kmap(machine->vmlinux_maps[type]);
 		map_groups__remove(&machine->kmaps,
 				   machine->vmlinux_maps[type]);
-		if (kmap->ref_reloc_sym) {
+		if (kmap && kmap->ref_reloc_sym) {
 			/*
 			 * ref_reloc_sym is shared among all maps, so free just
 			 * on one of them.

commit 73dbcd6537f0ef6bf98d84f8fd7f8ab9994c6cd8
Author: David Hildenbrand <dahi@linux.vnet.ibm.com>
Date:   Mon Mar 30 10:11:00 2015 +0200

    perf callchain: Fix kernel symbol resolution by remembering the cpumode
    
    Commit 2e77784bb7d8 ("perf callchain: Move cpumode resolve code to
    add_callchain_ip") promised "No change in behavior.".
    
    As this commit breaks callchains on s390x (symbols not getting resolved,
    observed when profiling the kernel), this statement is wrong. The cpumode
    must be kept when iterating over all ips, otherwise the default
    (PERF_RECORD_MISC_USER) will be used by error.
    
    Signed-off-by: David Hildenbrand <dahi@linux.vnet.ibm.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: David Hildenbrand <dahi@linux.vnet.ibm.com>
    Cc: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
    Cc: Kan Liang <kan.liang@intel.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1427703060-59883-1-git-send-email-dahi@linux.vnet.ibm.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index e3353307330c..e45c8f33a8fd 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1408,29 +1408,27 @@ struct mem_info *sample__resolve_mem(struct perf_sample *sample,
 static int add_callchain_ip(struct thread *thread,
 			    struct symbol **parent,
 			    struct addr_location *root_al,
-			    bool branch_history,
+			    u8 *cpumode,
 			    u64 ip)
 {
 	struct addr_location al;
 
 	al.filtered = 0;
 	al.sym = NULL;
-	if (branch_history)
+	if (!cpumode) {
 		thread__find_cpumode_addr_location(thread, MAP__FUNCTION,
 						   ip, &al);
-	else {
-		u8 cpumode = PERF_RECORD_MISC_USER;
-
+	} else {
 		if (ip >= PERF_CONTEXT_MAX) {
 			switch (ip) {
 			case PERF_CONTEXT_HV:
-				cpumode = PERF_RECORD_MISC_HYPERVISOR;
+				*cpumode = PERF_RECORD_MISC_HYPERVISOR;
 				break;
 			case PERF_CONTEXT_KERNEL:
-				cpumode = PERF_RECORD_MISC_KERNEL;
+				*cpumode = PERF_RECORD_MISC_KERNEL;
 				break;
 			case PERF_CONTEXT_USER:
-				cpumode = PERF_RECORD_MISC_USER;
+				*cpumode = PERF_RECORD_MISC_USER;
 				break;
 			default:
 				pr_debug("invalid callchain context: "
@@ -1444,8 +1442,8 @@ static int add_callchain_ip(struct thread *thread,
 			}
 			return 0;
 		}
-		thread__find_addr_location(thread, cpumode, MAP__FUNCTION,
-				   ip, &al);
+		thread__find_addr_location(thread, *cpumode, MAP__FUNCTION,
+					   ip, &al);
 	}
 
 	if (al.sym != NULL) {
@@ -1538,6 +1536,7 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 {
 	struct ip_callchain *chain = sample->callchain;
 	int chain_nr = min(max_stack, (int)chain->nr);
+	u8 cpumode = PERF_RECORD_MISC_USER;
 	int i, j, err;
 	u64 ip;
 
@@ -1584,7 +1583,7 @@ static int resolve_lbr_callchain_sample(struct thread *thread,
 					ip = lbr_stack->entries[0].to;
 			}
 
-			err = add_callchain_ip(thread, parent, root_al, false, ip);
+			err = add_callchain_ip(thread, parent, root_al, &cpumode, ip);
 			if (err)
 				return (err < 0) ? err : 0;
 		}
@@ -1604,6 +1603,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	struct branch_stack *branch = sample->branch_stack;
 	struct ip_callchain *chain = sample->callchain;
 	int chain_nr = min(max_stack, (int)chain->nr);
+	u8 cpumode = PERF_RECORD_MISC_USER;
 	int i, j, err;
 	int skip_idx = -1;
 	int first_call = 0;
@@ -1669,10 +1669,10 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 
 		for (i = 0; i < nr; i++) {
 			err = add_callchain_ip(thread, parent, root_al,
-					       true, be[i].to);
+					       NULL, be[i].to);
 			if (!err)
 				err = add_callchain_ip(thread, parent, root_al,
-						       true, be[i].from);
+						       NULL, be[i].from);
 			if (err == -EINVAL)
 				break;
 			if (err)
@@ -1701,7 +1701,7 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 #endif
 		ip = chain->ips[j];
 
-		err = add_callchain_ip(thread, parent, root_al, false, ip);
+		err = add_callchain_ip(thread, parent, root_al, &cpumode, ip);
 
 		if (err)
 			return (err < 0) ? err : 0;

commit bc84f464862489e687c98dea1a8ff20dc4413f93
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Tue Feb 17 17:31:18 2015 +0100

    perf tools: Try to lookup kernel module map before creating one
    
    Currently we assume machine__new_module is called only once for each
    module so we create its map&dso unconditionally.
    
    However it's possible that it's called multiple times for same module.
    Like for perf record:
    
      1) via machine__create_module during machine init
      2) via kernel MMAP event processing
    
    Trying to lookup kernel module map before creating one.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Acked-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-kx76xfqpnrpho5hdaapbqm09@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 1de5438ad070..e3353307330c 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -498,6 +498,11 @@ struct map *machine__new_module(struct machine *machine, u64 start,
 	if (kmod_path__parse_name(&m, filename))
 		return NULL;
 
+	map = map_groups__find_by_name(&machine->kmaps, MAP__FUNCTION,
+				       m.name);
+	if (map)
+		goto out;
+
 	dso = machine__module_dso(machine, &m, filename);
 	if (dso == NULL)
 		goto out;

commit e746b3ea0d414b3382bb61c8cecc45cefb370fbf
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Thu Feb 12 22:16:34 2015 +0100

    perf tools: Remove compressed argument from is_kernel_module
    
    We no longer need the 'compressed' argument, because all
    current users use 'NULL' for it.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Acked-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-d72q2s7ggbmy2yzhumux4zzw@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 6ca61a3427a6..1de5438ad070 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1104,7 +1104,7 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 		struct dso *dso;
 
 		list_for_each_entry(dso, &machine->kernel_dsos.head, node) {
-			if (is_kernel_module(dso->long_name, NULL))
+			if (is_kernel_module(dso->long_name))
 				continue;
 
 			kernel = dso;

commit bb58a8a459c322196613ad4af8801de41469cebb
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Thu Feb 12 22:20:01 2015 +0100

    perf tools: Use kmod_path__parse in map_groups__set_modules_path_dir
    
    Replacing the file name parsing with kmod_path__parse
    and moving the dso update into new separate function.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Acked-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-q0ed76ajcyoaofotntrg5sla@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index eb95b883fb44..6ca61a3427a6 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -851,6 +851,39 @@ static char *get_kernel_version(const char *root_dir)
 	return strdup(name);
 }
 
+static bool is_kmod_dso(struct dso *dso)
+{
+	return dso->symtab_type == DSO_BINARY_TYPE__SYSTEM_PATH_KMODULE ||
+	       dso->symtab_type == DSO_BINARY_TYPE__GUEST_KMODULE;
+}
+
+static int map_groups__set_module_path(struct map_groups *mg, const char *path,
+				       struct kmod_path *m)
+{
+	struct map *map;
+	char *long_name;
+
+	map = map_groups__find_by_name(mg, MAP__FUNCTION, m->name);
+	if (map == NULL)
+		return 0;
+
+	long_name = strdup(path);
+	if (long_name == NULL)
+		return -ENOMEM;
+
+	dso__set_long_name(map->dso, long_name, true);
+	dso__kernel_module_get_build_id(map->dso, "");
+
+	/*
+	 * Full name could reveal us kmod compression, so
+	 * we need to update the symtab_type if needed.
+	 */
+	if (m->comp && is_kmod_dso(map->dso))
+		map->dso->symtab_type++;
+
+	return 0;
+}
+
 static int map_groups__set_modules_path_dir(struct map_groups *mg,
 				const char *dir_name, int depth)
 {
@@ -889,35 +922,19 @@ static int map_groups__set_modules_path_dir(struct map_groups *mg,
 			if (ret < 0)
 				goto out;
 		} else {
-			char *dot = strrchr(dent->d_name, '.'),
-			     dso_name[PATH_MAX];
-			struct map *map;
-			char *long_name;
+			struct kmod_path m;
 
-			if (dot == NULL)
-				continue;
+			ret = kmod_path__parse_name(&m, dent->d_name);
+			if (ret)
+				goto out;
 
-			/* On some system, modules are compressed like .ko.gz */
-			if (is_supported_compression(dot + 1) &&
-			    is_kmodule_extension(dot - 2))
-				dot -= 3;
+			if (m.kmod)
+				ret = map_groups__set_module_path(mg, path, &m);
 
-			snprintf(dso_name, sizeof(dso_name), "[%.*s]",
-				 (int)(dot - dent->d_name), dent->d_name);
+			free(m.name);
 
-			strxfrchar(dso_name, '-', '_');
-			map = map_groups__find_by_name(mg, MAP__FUNCTION,
-						       dso_name);
-			if (map == NULL)
-				continue;
-
-			long_name = strdup(path);
-			if (long_name == NULL) {
-				ret = -1;
+			if (ret)
 				goto out;
-			}
-			dso__set_long_name(map->dso, long_name, true);
-			dso__kernel_module_get_build_id(map->dso, "");
 		}
 	}
 

commit ca33380adf74afb985bf7aab09ec46707a5d2d57
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Tue Feb 17 17:29:57 2015 +0100

    perf tools: Use kmod_path__parse for machine__new_dso
    
    Using kmod_path__parse to get the module name and update the dso short
    name within machine__new_dso function.
    
    This way it's done only first time when dso is created, unlike the
    current way when we update it all the time we process memory map of the
    kernel module.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Acked-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-8gjmt1ggf5ls1xkk7qi2ko4k@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index dbb5f0367005..eb95b883fb44 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -460,14 +460,15 @@ int machine__process_lost_event(struct machine *machine __maybe_unused,
 	return 0;
 }
 
-static struct dso *machine__module_dso(struct machine *machine, const char *filename)
+static struct dso*
+machine__module_dso(struct machine *machine, struct kmod_path *m,
+		    const char *filename)
 {
 	struct dso *dso;
-	bool compressed;
 
-	dso = dsos__find(&machine->kernel_dsos, filename, false);
+	dso = dsos__find(&machine->kernel_dsos, m->name, true);
 	if (!dso) {
-		dso = dsos__addnew(&machine->kernel_dsos, filename);
+		dso = dsos__addnew(&machine->kernel_dsos, m->name);
 		if (dso == NULL)
 			return NULL;
 
@@ -477,8 +478,11 @@ static struct dso *machine__module_dso(struct machine *machine, const char *file
 			dso->symtab_type = DSO_BINARY_TYPE__GUEST_KMODULE;
 
 		/* _KMODULE_COMP should be next to _KMODULE */
-		if (is_kernel_module(filename, &compressed) && compressed)
+		if (m->kmod && m->comp)
 			dso->symtab_type++;
+
+		dso__set_short_name(dso, strdup(m->name), true);
+		dso__set_long_name(dso, strdup(filename), true);
 	}
 
 	return dso;
@@ -487,17 +491,25 @@ static struct dso *machine__module_dso(struct machine *machine, const char *file
 struct map *machine__new_module(struct machine *machine, u64 start,
 				const char *filename)
 {
-	struct map *map;
-	struct dso *dso = machine__module_dso(machine, filename);
+	struct map *map = NULL;
+	struct dso *dso;
+	struct kmod_path m;
 
-	if (dso == NULL)
+	if (kmod_path__parse_name(&m, filename))
 		return NULL;
 
+	dso = machine__module_dso(machine, &m, filename);
+	if (dso == NULL)
+		goto out;
+
 	map = map__new2(start, dso, MAP__FUNCTION);
 	if (map == NULL)
-		return NULL;
+		goto out;
 
 	map_groups__insert(&machine->kmaps, map);
+
+out:
+	free(m.name);
 	return map;
 }
 
@@ -1058,40 +1070,11 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 				strlen(kmmap_prefix) - 1) == 0;
 	if (event->mmap.filename[0] == '/' ||
 	    (!is_kernel_mmap && event->mmap.filename[0] == '[')) {
-
-		char short_module_name[1024];
-		char *name, *dot;
-
-		if (event->mmap.filename[0] == '/') {
-			name = strrchr(event->mmap.filename, '/');
-			if (name == NULL)
-				goto out_problem;
-
-			++name; /* skip / */
-			dot = strrchr(name, '.');
-			if (dot == NULL)
-				goto out_problem;
-			/* On some system, modules are compressed like .ko.gz */
-			if (is_supported_compression(dot + 1))
-				dot -= 3;
-			if (!is_kmodule_extension(dot + 1))
-				goto out_problem;
-			snprintf(short_module_name, sizeof(short_module_name),
-					"[%.*s]", (int)(dot - name), name);
-			strxfrchar(short_module_name, '-', '_');
-		} else
-			strcpy(short_module_name, event->mmap.filename);
-
 		map = machine__new_module(machine, event->mmap.start,
 					  event->mmap.filename);
 		if (map == NULL)
 			goto out_problem;
 
-		name = strdup(short_module_name);
-		if (name == NULL)
-			goto out_problem;
-
-		dso__set_short_name(map->dso, name, true);
 		map->end = map->start + event->mmap.len;
 	} else if (is_kernel_mmap) {
 		const char *symbol_name = (event->mmap.filename +

commit da17ea33e5a5d0c5226a37c375575d689f6a741b
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Thu Feb 12 22:10:52 2015 +0100

    perf tools: Add machine__module_dso function
    
    Separate the dso object addition and update when adding new kernel
    module.
    
    Currently we update dso's symtab_type any time we find it in the list,
    because we can't distinguish between new and found dso from
    __dsos__findnew function.
    
    Adding machine__module_dso that separates finding and adding new dso
    objects, so there's no superfluous update of dso.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Acked-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-uvqgs5tyq4wssnq6fm43hgvk@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 24f8c978cfd4..dbb5f0367005 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -460,12 +460,35 @@ int machine__process_lost_event(struct machine *machine __maybe_unused,
 	return 0;
 }
 
+static struct dso *machine__module_dso(struct machine *machine, const char *filename)
+{
+	struct dso *dso;
+	bool compressed;
+
+	dso = dsos__find(&machine->kernel_dsos, filename, false);
+	if (!dso) {
+		dso = dsos__addnew(&machine->kernel_dsos, filename);
+		if (dso == NULL)
+			return NULL;
+
+		if (machine__is_host(machine))
+			dso->symtab_type = DSO_BINARY_TYPE__SYSTEM_PATH_KMODULE;
+		else
+			dso->symtab_type = DSO_BINARY_TYPE__GUEST_KMODULE;
+
+		/* _KMODULE_COMP should be next to _KMODULE */
+		if (is_kernel_module(filename, &compressed) && compressed)
+			dso->symtab_type++;
+	}
+
+	return dso;
+}
+
 struct map *machine__new_module(struct machine *machine, u64 start,
 				const char *filename)
 {
 	struct map *map;
-	struct dso *dso = __dsos__findnew(&machine->kernel_dsos, filename);
-	bool compressed;
+	struct dso *dso = machine__module_dso(machine, filename);
 
 	if (dso == NULL)
 		return NULL;
@@ -474,15 +497,6 @@ struct map *machine__new_module(struct machine *machine, u64 start,
 	if (map == NULL)
 		return NULL;
 
-	if (machine__is_host(machine))
-		dso->symtab_type = DSO_BINARY_TYPE__SYSTEM_PATH_KMODULE;
-	else
-		dso->symtab_type = DSO_BINARY_TYPE__GUEST_KMODULE;
-
-	/* _KMODULE_COMP should be next to _KMODULE */
-	if (is_kernel_module(filename, &compressed) && compressed)
-		dso->symtab_type++;
-
 	map_groups__insert(&machine->kmaps, map);
 	return map;
 }

commit f3b623b8490af7a9b819cbcf2d99ab4597ece94b
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Mar 2 22:21:35 2015 -0300

    perf tools: Reference count struct thread
    
    We need to do that to stop accumulating entries in the dead_threads
    linked list, i.e. we were keeping references to threads in struct hists
    that continue to exist even after a thread exited and was removed from
    the machine threads rbtree.
    
    We still keep the dead_threads list, but just for debugging, allowing us
    to iterate at any given point over the threads that still are referenced
    by things like struct hist_entry.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-3ejvfyed0r7ue61dkurzjux4@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 9e0f60a7e7b3..24f8c978cfd4 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -14,6 +14,8 @@
 #include "unwind.h"
 #include "linux/hash.h"
 
+static void machine__remove_thread(struct machine *machine, struct thread *th);
+
 static void dsos__init(struct dsos *dsos)
 {
 	INIT_LIST_HEAD(&dsos->head);
@@ -89,16 +91,6 @@ static void dsos__delete(struct dsos *dsos)
 	}
 }
 
-void machine__delete_dead_threads(struct machine *machine)
-{
-	struct thread *n, *t;
-
-	list_for_each_entry_safe(t, n, &machine->dead_threads, node) {
-		list_del(&t->node);
-		thread__delete(t);
-	}
-}
-
 void machine__delete_threads(struct machine *machine)
 {
 	struct rb_node *nd = rb_first(&machine->threads);
@@ -106,9 +98,8 @@ void machine__delete_threads(struct machine *machine)
 	while (nd) {
 		struct thread *t = rb_entry(nd, struct thread, rb_node);
 
-		rb_erase(&t->rb_node, &machine->threads);
 		nd = rb_next(nd);
-		thread__delete(t);
+		machine__remove_thread(machine, t);
 	}
 }
 
@@ -361,9 +352,13 @@ static struct thread *__machine__findnew_thread(struct machine *machine,
 	 * the full rbtree:
 	 */
 	th = machine->last_match;
-	if (th && th->tid == tid) {
-		machine__update_thread_pid(machine, th, pid);
-		return th;
+	if (th != NULL) {
+		if (th->tid == tid) {
+			machine__update_thread_pid(machine, th, pid);
+			return th;
+		}
+
+		thread__zput(machine->last_match);
 	}
 
 	while (*p != NULL) {
@@ -371,7 +366,7 @@ static struct thread *__machine__findnew_thread(struct machine *machine,
 		th = rb_entry(parent, struct thread, rb_node);
 
 		if (th->tid == tid) {
-			machine->last_match = th;
+			machine->last_match = thread__get(th);
 			machine__update_thread_pid(machine, th, pid);
 			return th;
 		}
@@ -403,8 +398,11 @@ static struct thread *__machine__findnew_thread(struct machine *machine,
 			thread__delete(th);
 			return NULL;
 		}
-
-		machine->last_match = th;
+		/*
+		 * It is now in the rbtree, get a ref
+		 */
+		thread__get(th);
+		machine->last_match = thread__get(th);
 	}
 
 	return th;
@@ -1238,13 +1236,17 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 
 static void machine__remove_thread(struct machine *machine, struct thread *th)
 {
-	machine->last_match = NULL;
+	if (machine->last_match == th)
+		thread__zput(machine->last_match);
+
 	rb_erase(&th->rb_node, &machine->threads);
 	/*
-	 * We may have references to this thread, for instance in some hist_entry
-	 * instances, so just move them to a separate list.
+	 * Move it first to the dead_threads list, then drop the reference,
+	 * if this is the last reference, then the thread__delete destructor
+	 * will be called and we will remove it from the dead_threads list.
 	 */
 	list_add_tail(&th->node, &machine->dead_threads);
+	thread__put(th);
 }
 
 int machine__process_fork_event(struct machine *machine, union perf_event *event,

commit 384b60557b5522fcb99646f0eb6e7a344cdb94c6
Author: Kan Liang <kan.liang@intel.com>
Date:   Mon Jan 5 13:23:05 2015 -0500

    perf tools: Construct LBR call chain
    
    LBR call stack only has user-space callchains. It is output in the
    PERF_SAMPLE_BRANCH_STACK data format. For kernel callchains, it's
    still in the form of PERF_SAMPLE_CALLCHAIN.
    
    The perf tool has to handle both data sources to construct a
    complete callstack.
    
    For the "perf report -D" option, both lbr and fp information will be
    displayed.
    
    A new call chain recording option "lbr" is introduced into the perf
    tool for LBR call stack. The user can use --call-graph lbr to get
    the call stack information from hardware.
    
    Here are some examples.
    
    When profiling bc(1) on Fedora 19:
    
      echo 'scale=2000; 4*a(1)' > cmd; perf record --call-graph lbr bc -l < cmd
    
    If enabling LBR, perf report output looks like:
    
        50.36%       bc  bc                 [.] bc_divide
                     |
                     --- bc_divide
                         execute
                         run_code
                         yyparse
                         main
                         __libc_start_main
                         _start
        33.66%       bc  bc                 [.] _one_mult
                     |
                     --- _one_mult
                         bc_divide
                         execute
                         run_code
                         yyparse
                         main
                         __libc_start_main
                         _start
         7.62%       bc  bc                 [.] _bc_do_add
                     |
                     --- _bc_do_add
                        |
                        |--99.89%-- 0x2000186a8
                         --0.11%-- [...]
         6.83%       bc  bc                 [.] _bc_do_sub
                     |
                     --- _bc_do_sub
                        |
                        |--99.94%-- bc_add
                        |          execute
                        |          run_code
                        |          yyparse
                        |          main
                        |          __libc_start_main
                        |          _start
                         --0.06%-- [...]
         0.46%       bc  libc-2.17.so       [.] __memset_sse2
                     |
                     --- __memset_sse2
                        |
                        |--54.13%-- bc_new_num
                        |          |
                        |          |--51.00%-- bc_divide
                        |          |          execute
                        |          |          run_code
                        |          |          yyparse
                        |          |          main
                        |          |          __libc_start_main
                        |          |          _start
                        |          |
                        |          |--30.46%-- _bc_do_sub
                        |          |          bc_add
                        |          |          execute
                        |          |          run_code
                        |          |          yyparse
                        |          |          main
                        |          |          __libc_start_main
                        |          |          _start
                        |          |
                        |           --18.55%-- _bc_do_add
                        |                     bc_add
                        |                     execute
                        |                     run_code
                        |                     yyparse
                        |                     main
                        |                     __libc_start_main
                        |                     _start
                        |
                         --45.87%-- bc_divide
                                   execute
                                   run_code
                                   yyparse
                                   main
                                   __libc_start_main
                                   _start
    
    If using FP, perf report output looks like:
    
      echo 'scale=2000; 4*a(1)' > cmd; perf record --call-graph fp bc -l < cmd
    
        50.49%       bc  bc                 [.] bc_divide
                     |
                     --- bc_divide
        33.57%       bc  bc                 [.] _one_mult
                     |
                     --- _one_mult
         7.61%       bc  bc                 [.] _bc_do_add
                     |
                     --- _bc_do_add
                         0x2000186a8
         6.88%       bc  bc                 [.] _bc_do_sub
                     |
                     --- _bc_do_sub
         0.42%       bc  libc-2.17.so       [.] __memcpy_ssse3_back
                     |
                     --- __memcpy_ssse3_back
    
    If using LBR, perf report -D output looks like:
    
    3458145275743 0x2fd750 [0xd8]: PERF_RECORD_SAMPLE(IP, 0x2): 9748/9748: 0x408ea8 period: 609644 addr: 0
    ... LBR call chain: nr:8
    .....  0: fffffffffffffe00
    .....  1: 0000000000408e50
    .....  2: 000000000040a458
    .....  3: 000000000040562e
    .....  4: 0000000000408590
    .....  5: 00000000004022c0
    .....  6: 00000000004015dd
    .....  7: 0000003d1cc21b43
    ... FP chain: nr:2
    .....  0: fffffffffffffe00
    .....  1: 0000000000408ea8
     ... thread: bc:9748
     ...... dso: /usr/bin/bc
    
    The LBR call stack has the following known limitations:
    
     - Zero length calls are not filtered out by the hardware
    
     - Exception handing such as setjmp/longjmp will have calls/returns not
       match
    
     - Pushing different return address onto the stack will have
       calls/returns not match
    
     - If callstack is deeper than the LBR, only the last entries are
       captured
    
    Tested-by: Jiri Olsa <jolsa@kernel.org>
    Signed-off-by: Kan Liang <kan.liang@intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Simon Que <sque@chromium.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1420482185-29830-3-git-send-email-kan.liang@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 1bca3a9f2b16..9e0f60a7e7b3 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1502,18 +1502,100 @@ static int remove_loops(struct branch_entry *l, int nr)
 	return nr;
 }
 
-static int thread__resolve_callchain_sample(struct thread *thread,
-					     struct ip_callchain *chain,
-					     struct branch_stack *branch,
-					     struct symbol **parent,
-					     struct addr_location *root_al,
-					     int max_stack)
+/*
+ * Recolve LBR callstack chain sample
+ * Return:
+ * 1 on success get LBR callchain information
+ * 0 no available LBR callchain information, should try fp
+ * negative error code on other errors.
+ */
+static int resolve_lbr_callchain_sample(struct thread *thread,
+					struct perf_sample *sample,
+					struct symbol **parent,
+					struct addr_location *root_al,
+					int max_stack)
 {
+	struct ip_callchain *chain = sample->callchain;
+	int chain_nr = min(max_stack, (int)chain->nr);
+	int i, j, err;
+	u64 ip;
+
+	for (i = 0; i < chain_nr; i++) {
+		if (chain->ips[i] == PERF_CONTEXT_USER)
+			break;
+	}
+
+	/* LBR only affects the user callchain */
+	if (i != chain_nr) {
+		struct branch_stack *lbr_stack = sample->branch_stack;
+		int lbr_nr = lbr_stack->nr;
+		/*
+		 * LBR callstack can only get user call chain.
+		 * The mix_chain_nr is kernel call chain
+		 * number plus LBR user call chain number.
+		 * i is kernel call chain number,
+		 * 1 is PERF_CONTEXT_USER,
+		 * lbr_nr + 1 is the user call chain number.
+		 * For details, please refer to the comments
+		 * in callchain__printf
+		 */
+		int mix_chain_nr = i + 1 + lbr_nr + 1;
+
+		if (mix_chain_nr > PERF_MAX_STACK_DEPTH + PERF_MAX_BRANCH_DEPTH) {
+			pr_warning("corrupted callchain. skipping...\n");
+			return 0;
+		}
+
+		for (j = 0; j < mix_chain_nr; j++) {
+			if (callchain_param.order == ORDER_CALLEE) {
+				if (j < i + 1)
+					ip = chain->ips[j];
+				else if (j > i + 1)
+					ip = lbr_stack->entries[j - i - 2].from;
+				else
+					ip = lbr_stack->entries[0].to;
+			} else {
+				if (j < lbr_nr)
+					ip = lbr_stack->entries[lbr_nr - j - 1].from;
+				else if (j > lbr_nr)
+					ip = chain->ips[i + 1 - (j - lbr_nr)];
+				else
+					ip = lbr_stack->entries[0].to;
+			}
+
+			err = add_callchain_ip(thread, parent, root_al, false, ip);
+			if (err)
+				return (err < 0) ? err : 0;
+		}
+		return 1;
+	}
+
+	return 0;
+}
+
+static int thread__resolve_callchain_sample(struct thread *thread,
+					    struct perf_evsel *evsel,
+					    struct perf_sample *sample,
+					    struct symbol **parent,
+					    struct addr_location *root_al,
+					    int max_stack)
+{
+	struct branch_stack *branch = sample->branch_stack;
+	struct ip_callchain *chain = sample->callchain;
 	int chain_nr = min(max_stack, (int)chain->nr);
 	int i, j, err;
 	int skip_idx = -1;
 	int first_call = 0;
 
+	callchain_cursor_reset(&callchain_cursor);
+
+	if (has_branch_callstack(evsel)) {
+		err = resolve_lbr_callchain_sample(thread, sample, parent,
+						   root_al, max_stack);
+		if (err)
+			return (err < 0) ? err : 0;
+	}
+
 	/*
 	 * Based on DWARF debug information, some architectures skip
 	 * a callchain entry saved by the kernel.
@@ -1521,8 +1603,6 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	if (chain->nr < PERF_MAX_STACK_DEPTH)
 		skip_idx = arch_skip_callchain_idx(thread, chain);
 
-	callchain_cursor_reset(&callchain_cursor);
-
 	/*
 	 * Add branches to call stack for easier browsing. This gives
 	 * more context for a sample than just the callers.
@@ -1623,9 +1703,9 @@ int thread__resolve_callchain(struct thread *thread,
 			      struct addr_location *root_al,
 			      int max_stack)
 {
-	int ret = thread__resolve_callchain_sample(thread, sample->callchain,
-						   sample->branch_stack,
-						   parent, root_al, max_stack);
+	int ret = thread__resolve_callchain_sample(thread, evsel,
+						   sample, parent,
+						   root_al, max_stack);
 	if (ret)
 		return ret;
 

commit 260d819e3abdbdaa2b88fb983d1314f1b263f9e2
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Fri Jan 9 09:38:12 2015 +0900

    perf machine: Fix __machine__findnew_thread() error path
    
    When thread__init_map_groups() fails, a new thread should be removed
    from the rbtree since it's gonna be freed.  Also update last match cache
    only if the function succeeded.
    
    Reported-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1420763892-15535-1-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 94de3e48b490..1bca3a9f2b16 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -389,7 +389,6 @@ static struct thread *__machine__findnew_thread(struct machine *machine,
 	if (th != NULL) {
 		rb_link_node(&th->rb_node, parent, p);
 		rb_insert_color(&th->rb_node, &machine->threads);
-		machine->last_match = th;
 
 		/*
 		 * We have to initialize map_groups separately
@@ -400,9 +399,12 @@ static struct thread *__machine__findnew_thread(struct machine *machine,
 		 * leader and that would screwed the rb tree.
 		 */
 		if (thread__init_map_groups(th, machine)) {
+			rb_erase(&th->rb_node, &machine->threads);
 			thread__delete(th);
 			return NULL;
 		}
+
+		machine->last_match = th;
 	}
 
 	return th;

commit 2e77784bb7d882647c33d8e75a650625e6df0f8b
Author: Kan Liang <kan.liang@intel.com>
Date:   Tue Dec 2 10:06:53 2014 -0500

    perf callchain: Move cpumode resolve code to add_callchain_ip
    
    Using flag to distinguish between branch_history and normal callchain.
    
    Move the cpumode to add_callchain_ip function.
    
    No change in behavior.
    
    Signed-off-by: Kan Liang <kan.liang@intel.com>
    Acked-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1417532814-26208-3-git-send-email-kan.liang@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 15dd0a9691ce..94de3e48b490 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1385,19 +1385,46 @@ struct mem_info *sample__resolve_mem(struct perf_sample *sample,
 static int add_callchain_ip(struct thread *thread,
 			    struct symbol **parent,
 			    struct addr_location *root_al,
-			    int cpumode,
+			    bool branch_history,
 			    u64 ip)
 {
 	struct addr_location al;
 
 	al.filtered = 0;
 	al.sym = NULL;
-	if (cpumode == -1)
+	if (branch_history)
 		thread__find_cpumode_addr_location(thread, MAP__FUNCTION,
 						   ip, &al);
-	else
+	else {
+		u8 cpumode = PERF_RECORD_MISC_USER;
+
+		if (ip >= PERF_CONTEXT_MAX) {
+			switch (ip) {
+			case PERF_CONTEXT_HV:
+				cpumode = PERF_RECORD_MISC_HYPERVISOR;
+				break;
+			case PERF_CONTEXT_KERNEL:
+				cpumode = PERF_RECORD_MISC_KERNEL;
+				break;
+			case PERF_CONTEXT_USER:
+				cpumode = PERF_RECORD_MISC_USER;
+				break;
+			default:
+				pr_debug("invalid callchain context: "
+					 "%"PRId64"\n", (s64) ip);
+				/*
+				 * It seems the callchain is corrupted.
+				 * Discard all.
+				 */
+				callchain_cursor_reset(&callchain_cursor);
+				return 1;
+			}
+			return 0;
+		}
 		thread__find_addr_location(thread, cpumode, MAP__FUNCTION,
 				   ip, &al);
+	}
+
 	if (al.sym != NULL) {
 		if (sort__has_parent && !*parent &&
 		    symbol__match_regex(al.sym, &parent_regex))
@@ -1480,11 +1507,8 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 					     struct addr_location *root_al,
 					     int max_stack)
 {
-	u8 cpumode = PERF_RECORD_MISC_USER;
 	int chain_nr = min(max_stack, (int)chain->nr);
-	int i;
-	int j;
-	int err;
+	int i, j, err;
 	int skip_idx = -1;
 	int first_call = 0;
 
@@ -1542,10 +1566,10 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 
 		for (i = 0; i < nr; i++) {
 			err = add_callchain_ip(thread, parent, root_al,
-					       -1, be[i].to);
+					       true, be[i].to);
 			if (!err)
 				err = add_callchain_ip(thread, parent, root_al,
-						       -1, be[i].from);
+						       true, be[i].from);
 			if (err == -EINVAL)
 				break;
 			if (err)
@@ -1574,36 +1598,10 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 #endif
 		ip = chain->ips[j];
 
-		if (ip >= PERF_CONTEXT_MAX) {
-			switch (ip) {
-			case PERF_CONTEXT_HV:
-				cpumode = PERF_RECORD_MISC_HYPERVISOR;
-				break;
-			case PERF_CONTEXT_KERNEL:
-				cpumode = PERF_RECORD_MISC_KERNEL;
-				break;
-			case PERF_CONTEXT_USER:
-				cpumode = PERF_RECORD_MISC_USER;
-				break;
-			default:
-				pr_debug("invalid callchain context: "
-					 "%"PRId64"\n", (s64) ip);
-				/*
-				 * It seems the callchain is corrupted.
-				 * Discard all.
-				 */
-				callchain_cursor_reset(&callchain_cursor);
-				return 0;
-			}
-			continue;
-		}
+		err = add_callchain_ip(thread, parent, root_al, false, ip);
 
-		err = add_callchain_ip(thread, parent, root_al,
-				       cpumode, ip);
-		if (err == -EINVAL)
-			break;
 		if (err)
-			return err;
+			return (err < 0) ? err : 0;
 	}
 
 	return 0;

commit 8b7bad58efb7e3aaff60f7c1fa4361fb8c23181d
Author: Andi Kleen <ak@linux.intel.com>
Date:   Wed Nov 12 18:05:20 2014 -0800

    perf callchain: Support handling complete branch stacks as histograms
    
    Currently branch stacks can be only shown as edge histograms for
    individual branches. I never found this display particularly useful.
    
    This implements an alternative mode that creates histograms over
    complete branch traces, instead of individual branches, similar to how
    normal callgraphs are handled. This is done by putting it in front of
    the normal callgraph and then using the normal callgraph histogram
    infrastructure to unify them.
    
    This way in complex functions we can understand the control flow that
    lead to a particular sample, and may even see some control flow in the
    caller for short functions.
    
    Example (simplified, of course for such simple code this is usually not
    needed), please run this after the whole patchkit is in, as at this
    point in the patch order there is no --branch-history, that will be
    added in a patch after this one:
    
    tcall.c:
    
    volatile a = 10000, b = 100000, c;
    
    __attribute__((noinline)) f2()
    {
            c = a / b;
    }
    
    __attribute__((noinline)) f1()
    {
            f2();
            f2();
    }
    main()
    {
            int i;
            for (i = 0; i < 1000000; i++)
                    f1();
    }
    
    % perf record -b -g ./tsrc/tcall
    [ perf record: Woken up 1 times to write data ]
    [ perf record: Captured and wrote 0.044 MB perf.data (~1923 samples) ]
    % perf report --no-children --branch-history
    ...
        54.91%  tcall.c:6  [.] f2                      tcall
                |
                |--65.53%-- f2 tcall.c:5
                |          |
                |          |--70.83%-- f1 tcall.c:11
                |          |          f1 tcall.c:10
                |          |          main tcall.c:18
                |          |          main tcall.c:18
                |          |          main tcall.c:17
                |          |          main tcall.c:17
                |          |          f1 tcall.c:13
                |          |          f1 tcall.c:13
                |          |          f2 tcall.c:7
                |          |          f2 tcall.c:5
                |          |          f1 tcall.c:12
                |          |          f1 tcall.c:12
                |          |          f2 tcall.c:7
                |          |          f2 tcall.c:5
                |          |          f1 tcall.c:11
                |          |
                |           --29.17%-- f1 tcall.c:12
                |                     f1 tcall.c:12
                |                     f2 tcall.c:7
                |                     f2 tcall.c:5
                |                     f1 tcall.c:11
                |                     f1 tcall.c:10
                |                     main tcall.c:18
                |                     main tcall.c:18
                |                     main tcall.c:17
                |                     main tcall.c:17
                |                     f1 tcall.c:13
                |                     f1 tcall.c:13
                |                     f2 tcall.c:7
                |                     f2 tcall.c:5
                |                     f1 tcall.c:12
    
    The default output is unchanged.
    
    This is only implemented in perf report, no change to record or anywhere
    else.
    
    This adds the basic code to report:
    
    - add a new "branch" option to the -g option parser to enable this mode
    - when the flag is set include the LBR into the callstack in machine.c.
    
    The rest of the history code is unchanged and doesn't know the
    difference between LBR entry and normal call entry.
    
    - detect overlaps with the callchain
    - remove small loop duplicates in the LBR
    
    Current limitations:
    
    - The LBR flags (mispredict etc.) are not shown in the history
    and LBR entries have no special marker.
    - It would be nice if annotate marked the LBR entries somehow
    (e.g. with arrows)
    
    v2: Various fixes.
    v3: Merge further patches into this one. Fix white space.
    v4: Improve manpage. Address review feedback.
    v5: Rename functions. Better error message without -g. Fix crash without
        -b.
    v6: Rebase
    v7: Rebase. Use NO_ENTRY in memset.
    v8: Port to latest tip. Move add_callchain_ip to separate
        patch. Skip initial entries in callchain. Minor cleanups.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: http://lkml.kernel.org/r/1415844328-4884-3-git-send-email-andi@firstfloor.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index b75b487574c7..15dd0a9691ce 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -12,6 +12,7 @@
 #include <stdbool.h>
 #include <symbol/kallsyms.h>
 #include "unwind.h"
+#include "linux/hash.h"
 
 static void dsos__init(struct dsos *dsos)
 {
@@ -1391,7 +1392,11 @@ static int add_callchain_ip(struct thread *thread,
 
 	al.filtered = 0;
 	al.sym = NULL;
-	thread__find_addr_location(thread, cpumode, MAP__FUNCTION,
+	if (cpumode == -1)
+		thread__find_cpumode_addr_location(thread, MAP__FUNCTION,
+						   ip, &al);
+	else
+		thread__find_addr_location(thread, cpumode, MAP__FUNCTION,
 				   ip, &al);
 	if (al.sym != NULL) {
 		if (sort__has_parent && !*parent &&
@@ -1427,8 +1432,50 @@ struct branch_info *sample__resolve_bstack(struct perf_sample *sample,
 	return bi;
 }
 
+#define CHASHSZ 127
+#define CHASHBITS 7
+#define NO_ENTRY 0xff
+
+#define PERF_MAX_BRANCH_DEPTH 127
+
+/* Remove loops. */
+static int remove_loops(struct branch_entry *l, int nr)
+{
+	int i, j, off;
+	unsigned char chash[CHASHSZ];
+
+	memset(chash, NO_ENTRY, sizeof(chash));
+
+	BUG_ON(PERF_MAX_BRANCH_DEPTH > 255);
+
+	for (i = 0; i < nr; i++) {
+		int h = hash_64(l[i].from, CHASHBITS) % CHASHSZ;
+
+		/* no collision handling for now */
+		if (chash[h] == NO_ENTRY) {
+			chash[h] = i;
+		} else if (l[chash[h]].from == l[i].from) {
+			bool is_loop = true;
+			/* check if it is a real loop */
+			off = 0;
+			for (j = chash[h]; j < i && i + off < nr; j++, off++)
+				if (l[j].from != l[i + off].from) {
+					is_loop = false;
+					break;
+				}
+			if (is_loop) {
+				memmove(l + i, l + i + off,
+					(nr - (i + off)) * sizeof(*l));
+				nr -= off;
+			}
+		}
+	}
+	return nr;
+}
+
 static int thread__resolve_callchain_sample(struct thread *thread,
 					     struct ip_callchain *chain,
+					     struct branch_stack *branch,
 					     struct symbol **parent,
 					     struct addr_location *root_al,
 					     int max_stack)
@@ -1438,22 +1485,82 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 	int i;
 	int j;
 	int err;
-	int skip_idx __maybe_unused;
+	int skip_idx = -1;
+	int first_call = 0;
+
+	/*
+	 * Based on DWARF debug information, some architectures skip
+	 * a callchain entry saved by the kernel.
+	 */
+	if (chain->nr < PERF_MAX_STACK_DEPTH)
+		skip_idx = arch_skip_callchain_idx(thread, chain);
 
 	callchain_cursor_reset(&callchain_cursor);
 
+	/*
+	 * Add branches to call stack for easier browsing. This gives
+	 * more context for a sample than just the callers.
+	 *
+	 * This uses individual histograms of paths compared to the
+	 * aggregated histograms the normal LBR mode uses.
+	 *
+	 * Limitations for now:
+	 * - No extra filters
+	 * - No annotations (should annotate somehow)
+	 */
+
+	if (branch && callchain_param.branch_callstack) {
+		int nr = min(max_stack, (int)branch->nr);
+		struct branch_entry be[nr];
+
+		if (branch->nr > PERF_MAX_BRANCH_DEPTH) {
+			pr_warning("corrupted branch chain. skipping...\n");
+			goto check_calls;
+		}
+
+		for (i = 0; i < nr; i++) {
+			if (callchain_param.order == ORDER_CALLEE) {
+				be[i] = branch->entries[i];
+				/*
+				 * Check for overlap into the callchain.
+				 * The return address is one off compared to
+				 * the branch entry. To adjust for this
+				 * assume the calling instruction is not longer
+				 * than 8 bytes.
+				 */
+				if (i == skip_idx ||
+				    chain->ips[first_call] >= PERF_CONTEXT_MAX)
+					first_call++;
+				else if (be[i].from < chain->ips[first_call] &&
+				    be[i].from >= chain->ips[first_call] - 8)
+					first_call++;
+			} else
+				be[i] = branch->entries[branch->nr - i - 1];
+		}
+
+		nr = remove_loops(be, nr);
+
+		for (i = 0; i < nr; i++) {
+			err = add_callchain_ip(thread, parent, root_al,
+					       -1, be[i].to);
+			if (!err)
+				err = add_callchain_ip(thread, parent, root_al,
+						       -1, be[i].from);
+			if (err == -EINVAL)
+				break;
+			if (err)
+				return err;
+		}
+		chain_nr -= nr;
+	}
+
+check_calls:
 	if (chain->nr > PERF_MAX_STACK_DEPTH) {
 		pr_warning("corrupted callchain. skipping...\n");
 		return 0;
 	}
 
-	/*
-	 * Based on DWARF debug information, some architectures skip
-	 * a callchain entry saved by the kernel.
-	 */
-	skip_idx = arch_skip_callchain_idx(thread, chain);
-
-	for (i = 0; i < chain_nr; i++) {
+	for (i = first_call; i < chain_nr; i++) {
 		u64 ip;
 
 		if (callchain_param.order == ORDER_CALLEE)
@@ -1517,6 +1624,7 @@ int thread__resolve_callchain(struct thread *thread,
 			      int max_stack)
 {
 	int ret = thread__resolve_callchain_sample(thread, sample->callchain,
+						   sample->branch_stack,
 						   parent, root_al, max_stack);
 	if (ret)
 		return ret;

commit 330dfa224fcc8594977785a6493ca06d124f0cfe
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Tue Nov 18 13:30:28 2014 +0900

    perf tools: Fix segfault due to invalid kernel dso access
    
    Jiri reported that the commit 96d78059d6d9 ("perf tools: Make vmlinux
    short name more like kallsyms short name") segfaults on perf script.
    
    When processing kernel mmap event, it should access the 'kernel'
    variable as sometimes it cannot find a matching dso from build-id table
    so 'dso' might be invalid.
    
    Reported-by: Jiri Olsa <jolsa@redhat.com>
    Tested-by: Jiri Olsa <jolsa@redhat.com>
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1416285028-30572-1-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index d97309c87bd6..b75b487574c7 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1106,8 +1106,8 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 		if (__machine__create_kernel_maps(machine, kernel) < 0)
 			goto out_problem;
 
-		if (strstr(dso->long_name, "vmlinux"))
-			dso__set_short_name(dso, "[kernel.vmlinux]", false);
+		if (strstr(kernel->long_name, "vmlinux"))
+			dso__set_short_name(kernel, "[kernel.vmlinux]", false);
 
 		machine__set_kernel_mmap_len(machine, event);
 

commit 5550171b2a9f8df26ff483051d060db06376b26d
Author: Andi Kleen <ak@linux.intel.com>
Date:   Wed Nov 12 18:05:21 2014 -0800

    perf callchain: Use al.addr to set up call chain
    
    Use the relative address, this makes get_srcline work correctly in the
    end.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: http://lkml.kernel.org/r/1415844328-4884-4-git-send-email-andi@firstfloor.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 84390eecab06..d97309c87bd6 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1406,7 +1406,7 @@ static int add_callchain_ip(struct thread *thread,
 		}
 	}
 
-	return callchain_cursor_append(&callchain_cursor, ip, al.map, al.sym);
+	return callchain_cursor_append(&callchain_cursor, al.addr, al.map, al.sym);
 }
 
 struct branch_info *sample__resolve_bstack(struct perf_sample *sample,

commit 37592b8afb7151994e760d1727c264329d9c13c8
Author: Andi Kleen <ak@linux.intel.com>
Date:   Wed Nov 12 18:05:19 2014 -0800

    perf callchain: Factor out adding new call chain entries
    
    Move the code to resolve and add a new callchain entry into a new
    add_callchain_ip function. This will be used in the next patches to add
    LBRs too.
    
    No change in behavior.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: http://lkml.kernel.org/r/1415844328-4884-2-git-send-email-andi@firstfloor.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 52e94902afb1..84390eecab06 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1381,6 +1381,34 @@ struct mem_info *sample__resolve_mem(struct perf_sample *sample,
 	return mi;
 }
 
+static int add_callchain_ip(struct thread *thread,
+			    struct symbol **parent,
+			    struct addr_location *root_al,
+			    int cpumode,
+			    u64 ip)
+{
+	struct addr_location al;
+
+	al.filtered = 0;
+	al.sym = NULL;
+	thread__find_addr_location(thread, cpumode, MAP__FUNCTION,
+				   ip, &al);
+	if (al.sym != NULL) {
+		if (sort__has_parent && !*parent &&
+		    symbol__match_regex(al.sym, &parent_regex))
+			*parent = al.sym;
+		else if (have_ignore_callees && root_al &&
+		  symbol__match_regex(al.sym, &ignore_callees_regex)) {
+			/* Treat this symbol as the root,
+			   forgetting its callees. */
+			*root_al = al;
+			callchain_cursor_reset(&callchain_cursor);
+		}
+	}
+
+	return callchain_cursor_append(&callchain_cursor, ip, al.map, al.sym);
+}
+
 struct branch_info *sample__resolve_bstack(struct perf_sample *sample,
 					   struct addr_location *al)
 {
@@ -1427,7 +1455,6 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 
 	for (i = 0; i < chain_nr; i++) {
 		u64 ip;
-		struct addr_location al;
 
 		if (callchain_param.order == ORDER_CALLEE)
 			j = i;
@@ -1464,24 +1491,10 @@ static int thread__resolve_callchain_sample(struct thread *thread,
 			continue;
 		}
 
-		al.filtered = 0;
-		thread__find_addr_location(thread, cpumode,
-					   MAP__FUNCTION, ip, &al);
-		if (al.sym != NULL) {
-			if (sort__has_parent && !*parent &&
-			    symbol__match_regex(al.sym, &parent_regex))
-				*parent = al.sym;
-			else if (have_ignore_callees && root_al &&
-			  symbol__match_regex(al.sym, &ignore_callees_regex)) {
-				/* Treat this symbol as the root,
-				   forgetting its callees. */
-				*root_al = al;
-				callchain_cursor_reset(&callchain_cursor);
-			}
-		}
-
-		err = callchain_cursor_append(&callchain_cursor,
-					      ip, al.map, al.sym);
+		err = add_callchain_ip(thread, parent, root_al,
+				       cpumode, ip);
+		if (err == -EINVAL)
+			break;
 		if (err)
 			return err;
 	}

commit 96d78059d6d9da45d77078a219924304860497f2
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Tue Nov 4 10:14:34 2014 +0900

    perf tools: Make vmlinux short name more like kallsyms short name
    
    The previous patch changed kernel dso name from '[kernel.kallsyms]' to
    vmlinux.  However it might add confusion to old users accustomed to the
    old name.  So change the short name to '[kernel.vmlinux]' to reduce such
    confusion.
    
    Before:
      # Overhead  Command         Shared Object            Symbol
      # ........  ..............  .......................  ...............................
      #
           9.83%  swapper         vmlinux                  [k] intel_idle
           4.10%  awk             libc-2.20.so             [.] __strcmp_sse2
           1.86%  sed             libc-2.20.so             [.] __strcmp_sse2
           1.78%  netctl-auto     libc-2.20.so             [.] __strcmp_sse2
           1.23%  netctl-auto     libc-2.20.so             [.] __mbrtowc
           1.21%  firefox         libxul.so                [.] 0x00000000024b62bd
           1.20%  swapper         vmlinux                  [k] cpuidle_enter_state
           1.03%  sleep           vmlinux                  [k] copy_user_generic_unrolled
    
    After:
      # Overhead  Command         Shared Object            Symbol
      # ........  ..............  .......................  ...............................
      #
           9.83%  swapper         [kernel.vmlinux]         [k] intel_idle
           4.10%  awk             libc-2.20.so             [.] __strcmp_sse2
           1.86%  sed             libc-2.20.so             [.] __strcmp_sse2
           1.78%  netctl-auto     libc-2.20.so             [.] __strcmp_sse2
           1.23%  netctl-auto     libc-2.20.so             [.] __mbrtowc
           1.21%  firefox         libxul.so                [.] 0x00000000024b62bd
           1.20%  swapper         [kernel.vmlinux]         [k] cpuidle_enter_state
           1.03%  sleep           [kernel.vmlinux]         [k] copy_user_generic_unrolled
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1415063674-17206-9-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 53f90e9c65fe..52e94902afb1 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1106,6 +1106,9 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 		if (__machine__create_kernel_maps(machine, kernel) < 0)
 			goto out_problem;
 
+		if (strstr(dso->long_name, "vmlinux"))
+			dso__set_short_name(dso, "[kernel.vmlinux]", false);
+
 		machine__set_kernel_mmap_len(machine, event);
 
 		/*

commit b837a8bdc48925e6512412973b845c53cbe2b412
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Tue Nov 4 10:14:33 2014 +0900

    perf tools: Fix build-id matching on vmlinux
    
    There's a problem on finding correct kernel symbols when perf report
    runs on a different kernel.  Although a part of the problem was solved
    by the prior commit 0a7e6d1b6844 ("perf tools: Check recorded kernel
    version when finding vmlinux"), there's a remaining problem still.
    
    When perf records samples, it synthesizes the kernel map using
    machine__mmap_name() and ref_reloc_sym like "[kernel.kallsyms]_text".
    You can easily see it using 'perf report -D' command.
    
    After finishing record, it goes through the recorded events to find
    maps/dsos actually used.  And then record build-id info of them.
    
    During this process, it needs to load symbols in a dso and it'd call
    dso__load_vmlinux_path() since the default value of the symbol_conf.
    try_vmlinux_path is true.  However it changes dso->long_name to a real
    path of the vmlinux file (e.g. /lib/modules/3.16.4/build/vmlinux) if one
    is running on a custom kernel.
    
    It resulted in that perf report reads the build-id of the vmlinux, but
    cannot use it since it only knows about the [kernel.kallsyms] map.  It
    then falls back to possible vmlinux paths by using the recorded kernel
    version (in case of a recent version) or a running kernel silently.
    
    Even with the recent tools, this still has a possibility of breaking
    the result.  As the build directory is a symbolic link, if one built a
    new kernel in the same directory with different source/config, the old
    link to vmlinux will point the new file.  So it's absolutely needed to
    use build-id when finding a kernel image.
    
    In this patch, it's now changed to try to search a kernel dso in the
    existing dso list which was constructed during build-id table parsing
    so it'll always have a build-id.  If not found, search "[kernel.kallsyms]".
    
    Before:
    
      $ perf report
      # Children      Self  Command  Shared Object      Symbol
      # ........  ........  .......  .................  ...............................
      #
          72.15%     0.00%  swapper  [kernel.kallsyms]  [k] set_curr_task_rt
          72.15%     0.00%  swapper  [kernel.kallsyms]  [k] native_calibrate_tsc
          72.15%     0.00%  swapper  [kernel.kallsyms]  [k] tsc_refine_calibration_work
          71.87%    71.87%  swapper  [kernel.kallsyms]  [k] module_finalize
       ...
    
    After (for the same perf.data):
    
          72.15%     0.00%  swapper  vmlinux  [k] cpu_startup_entry
          72.15%     0.00%  swapper  vmlinux  [k] arch_cpu_idle
          72.15%     0.00%  swapper  vmlinux  [k] default_idle
          71.87%    71.87%  swapper  vmlinux  [k] native_safe_halt
       ...
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Link: http://lkml.kernel.org/r/20140924073356.GB1962@gmail.com
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1415063674-17206-8-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 946c7d62cb6e..53f90e9c65fe 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1085,8 +1085,20 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 		 * Should be there already, from the build-id table in
 		 * the header.
 		 */
-		struct dso *kernel = __dsos__findnew(&machine->kernel_dsos,
-						     kmmap_prefix);
+		struct dso *kernel = NULL;
+		struct dso *dso;
+
+		list_for_each_entry(dso, &machine->kernel_dsos.head, node) {
+			if (is_kernel_module(dso->long_name, NULL))
+				continue;
+
+			kernel = dso;
+			break;
+		}
+
+		if (kernel == NULL)
+			kernel = __dsos__findnew(&machine->kernel_dsos,
+						 kmmap_prefix);
 		if (kernel == NULL)
 			goto out_problem;
 

commit c00c48fc6e6ef63d83a7417923a06b08089bb34b
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Tue Nov 4 10:14:27 2014 +0900

    perf symbols: Preparation for compressed kernel module support
    
    This patch adds basic support to handle compressed kernel module as some
    distro (such as Archlinux) carries on it now.  The actual work using
    compression library will be added later.
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1415063674-17206-2-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 51a630301afa..946c7d62cb6e 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -464,6 +464,7 @@ struct map *machine__new_module(struct machine *machine, u64 start,
 {
 	struct map *map;
 	struct dso *dso = __dsos__findnew(&machine->kernel_dsos, filename);
+	bool compressed;
 
 	if (dso == NULL)
 		return NULL;
@@ -476,6 +477,11 @@ struct map *machine__new_module(struct machine *machine, u64 start,
 		dso->symtab_type = DSO_BINARY_TYPE__SYSTEM_PATH_KMODULE;
 	else
 		dso->symtab_type = DSO_BINARY_TYPE__GUEST_KMODULE;
+
+	/* _KMODULE_COMP should be next to _KMODULE */
+	if (is_kernel_module(filename, &compressed) && compressed)
+		dso->symtab_type++;
+
 	map_groups__insert(&machine->kmaps, map);
 	return map;
 }
@@ -861,8 +867,14 @@ static int map_groups__set_modules_path_dir(struct map_groups *mg,
 			struct map *map;
 			char *long_name;
 
-			if (dot == NULL || strcmp(dot, ".ko"))
+			if (dot == NULL)
 				continue;
+
+			/* On some system, modules are compressed like .ko.gz */
+			if (is_supported_compression(dot + 1) &&
+			    is_kmodule_extension(dot - 2))
+				dot -= 3;
+
 			snprintf(dso_name, sizeof(dso_name), "[%.*s]",
 				 (int)(dot - dent->d_name), dent->d_name);
 
@@ -1044,6 +1056,11 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 			dot = strrchr(name, '.');
 			if (dot == NULL)
 				goto out_problem;
+			/* On some system, modules are compressed like .ko.gz */
+			if (is_supported_compression(dot + 1))
+				dot -= 3;
+			if (!is_kmodule_extension(dot + 1))
+				goto out_problem;
 			snprintf(short_module_name, sizeof(short_module_name),
 					"[%.*s]", (int)(dot - name), name);
 			strxfrchar(short_module_name, '-', '_');

commit dd8c17a5fe80148aab8844e8774cf341212a4eb1
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Oct 23 16:42:19 2014 -0300

    perf callchains: Use thread->mg->machine
    
    The unwind__get_entries() already receives the thread parameter, from where it can
    obtain the matching machine structure, shorten the signature.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jean Pihet <jean.pihet@linaro.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-isjc6bm8mv4612mhi6af64go@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index fd192e4885cc..51a630301afa 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1486,7 +1486,7 @@ int thread__resolve_callchain(struct thread *thread,
 	    (!sample->user_stack.size))
 		return 0;
 
-	return unwind__get_entries(unwind_entry, &callchain_cursor, thread->mg->machine,
+	return unwind__get_entries(unwind_entry, &callchain_cursor,
 				   thread, sample, max_stack);
 
 }

commit cc8b7c2bf553151a579a8009020875faa1d43e29
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Oct 23 15:26:17 2014 -0300

    perf thread: Adopt resolve_callchain method from machine
    
    Shortening function signature lenght too, since a thread's machine can be
    obtained from thread->mg->machine, no need to pass thread, machine.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jean Pihet <jean.pihet@linaro.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-5wb6css280ty0cel5p0zo2b1@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 08e63fdbd14f..fd192e4885cc 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1464,13 +1464,12 @@ static int unwind_entry(struct unwind_entry *entry, void *arg)
 				       entry->map, entry->sym);
 }
 
-int machine__resolve_callchain(struct machine *machine,
-			       struct perf_evsel *evsel,
-			       struct thread *thread,
-			       struct perf_sample *sample,
-			       struct symbol **parent,
-			       struct addr_location *root_al,
-			       int max_stack)
+int thread__resolve_callchain(struct thread *thread,
+			      struct perf_evsel *evsel,
+			      struct perf_sample *sample,
+			      struct symbol **parent,
+			      struct addr_location *root_al,
+			      int max_stack)
 {
 	int ret = thread__resolve_callchain_sample(thread, sample->callchain,
 						   parent, root_al, max_stack);
@@ -1487,7 +1486,7 @@ int machine__resolve_callchain(struct machine *machine,
 	    (!sample->user_stack.size))
 		return 0;
 
-	return unwind__get_entries(unwind_entry, &callchain_cursor, machine,
+	return unwind__get_entries(unwind_entry, &callchain_cursor, thread->mg->machine,
 				   thread, sample, max_stack);
 
 }

commit bb871a9c8d68692ed2513b3f0e1c010c2ac12f44
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Oct 23 12:50:25 2014 -0300

    perf tools: A thread's machine can be found via thread->mg->machine
    
    So stop passing both machine and thread to several thread methods,
    reducing function signature length.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jean Pihet <jean.pihet@linaro.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-ckcy19dcp1jfkmdihdjcqdn1@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index c70b3ff7b289..08e63fdbd14f 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1289,7 +1289,7 @@ static bool symbol__match_regex(struct symbol *sym, regex_t *regex)
 	return 0;
 }
 
-static void ip__resolve_ams(struct machine *machine, struct thread *thread,
+static void ip__resolve_ams(struct thread *thread,
 			    struct addr_map_symbol *ams,
 			    u64 ip)
 {
@@ -1303,7 +1303,7 @@ static void ip__resolve_ams(struct machine *machine, struct thread *thread,
 	 * Thus, we have to try consecutively until we find a match
 	 * or else, the symbol is unknown
 	 */
-	thread__find_cpumode_addr_location(thread, machine, MAP__FUNCTION, ip, &al);
+	thread__find_cpumode_addr_location(thread, MAP__FUNCTION, ip, &al);
 
 	ams->addr = ip;
 	ams->al_addr = al.addr;
@@ -1311,23 +1311,21 @@ static void ip__resolve_ams(struct machine *machine, struct thread *thread,
 	ams->map = al.map;
 }
 
-static void ip__resolve_data(struct machine *machine, struct thread *thread,
+static void ip__resolve_data(struct thread *thread,
 			     u8 m, struct addr_map_symbol *ams, u64 addr)
 {
 	struct addr_location al;
 
 	memset(&al, 0, sizeof(al));
 
-	thread__find_addr_location(thread, machine, m, MAP__VARIABLE, addr,
-				   &al);
+	thread__find_addr_location(thread, m, MAP__VARIABLE, addr, &al);
 	if (al.map == NULL) {
 		/*
 		 * some shared data regions have execute bit set which puts
 		 * their mapping in the MAP__FUNCTION type array.
 		 * Check there as a fallback option before dropping the sample.
 		 */
-		thread__find_addr_location(thread, machine, m, MAP__FUNCTION, addr,
-					   &al);
+		thread__find_addr_location(thread, m, MAP__FUNCTION, addr, &al);
 	}
 
 	ams->addr = addr;
@@ -1344,9 +1342,8 @@ struct mem_info *sample__resolve_mem(struct perf_sample *sample,
 	if (!mi)
 		return NULL;
 
-	ip__resolve_ams(al->machine, al->thread, &mi->iaddr, sample->ip);
-	ip__resolve_data(al->machine, al->thread, al->cpumode,
-			 &mi->daddr, sample->addr);
+	ip__resolve_ams(al->thread, &mi->iaddr, sample->ip);
+	ip__resolve_data(al->thread, al->cpumode, &mi->daddr, sample->addr);
 	mi->data_src.val = sample->data_src;
 
 	return mi;
@@ -1363,15 +1360,14 @@ struct branch_info *sample__resolve_bstack(struct perf_sample *sample,
 		return NULL;
 
 	for (i = 0; i < bs->nr; i++) {
-		ip__resolve_ams(al->machine, al->thread, &bi[i].to, bs->entries[i].to);
-		ip__resolve_ams(al->machine, al->thread, &bi[i].from, bs->entries[i].from);
+		ip__resolve_ams(al->thread, &bi[i].to, bs->entries[i].to);
+		ip__resolve_ams(al->thread, &bi[i].from, bs->entries[i].from);
 		bi[i].flags = bs->entries[i].flags;
 	}
 	return bi;
 }
 
-static int machine__resolve_callchain_sample(struct machine *machine,
-					     struct thread *thread,
+static int thread__resolve_callchain_sample(struct thread *thread,
 					     struct ip_callchain *chain,
 					     struct symbol **parent,
 					     struct addr_location *root_al,
@@ -1395,7 +1391,7 @@ static int machine__resolve_callchain_sample(struct machine *machine,
 	 * Based on DWARF debug information, some architectures skip
 	 * a callchain entry saved by the kernel.
 	 */
-	skip_idx = arch_skip_callchain_idx(machine, thread, chain);
+	skip_idx = arch_skip_callchain_idx(thread, chain);
 
 	for (i = 0; i < chain_nr; i++) {
 		u64 ip;
@@ -1437,7 +1433,7 @@ static int machine__resolve_callchain_sample(struct machine *machine,
 		}
 
 		al.filtered = 0;
-		thread__find_addr_location(thread, machine, cpumode,
+		thread__find_addr_location(thread, cpumode,
 					   MAP__FUNCTION, ip, &al);
 		if (al.sym != NULL) {
 			if (sort__has_parent && !*parent &&
@@ -1476,11 +1472,8 @@ int machine__resolve_callchain(struct machine *machine,
 			       struct addr_location *root_al,
 			       int max_stack)
 {
-	int ret;
-
-	ret = machine__resolve_callchain_sample(machine, thread,
-						sample->callchain, parent,
-						root_al, max_stack);
+	int ret = thread__resolve_callchain_sample(thread, sample->callchain,
+						   parent, root_al, max_stack);
 	if (ret)
 		return ret;
 

commit 11246c708acdfa9512d7b69c18938810c20fd6ab
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Oct 21 17:29:02 2014 -0300

    perf tools: Set thread->mg.machine in all places
    
    We were setting this only in machine__init(), i.e. for the map_groups that
    holds the kernel module maps, not for the one used for a thread's executable
    mmaps.
    
    Now we are sure that we can obtain the machine where a thread is by going
    via thread->mg->machine, thus we can, in the following patch, make all
    codepaths that receive machine _and_ thread, drop the machine one.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jean Pihet <jean.pihet@linaro.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-y6zgaqsvhrf04v57u15e4ybm@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 34fc7c8672e4..c70b3ff7b289 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -21,7 +21,7 @@ static void dsos__init(struct dsos *dsos)
 
 int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 {
-	map_groups__init(&machine->kmaps);
+	map_groups__init(&machine->kmaps, machine);
 	RB_CLEAR_NODE(&machine->rb_node);
 	dsos__init(&machine->user_dsos);
 	dsos__init(&machine->kernel_dsos);
@@ -32,7 +32,6 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 
 	machine->vdso_info = NULL;
 
-	machine->kmaps.machine = machine;
 	machine->pid = pid;
 
 	machine->symbol_filter = NULL;
@@ -319,7 +318,7 @@ static void machine__update_thread_pid(struct machine *machine,
 		goto out_err;
 
 	if (!leader->mg)
-		leader->mg = map_groups__new();
+		leader->mg = map_groups__new(machine);
 
 	if (!leader->mg)
 		goto out_err;

commit e167f995e26249aa93708589c5eea539652351fa
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Oct 14 15:07:48 2014 -0300

    perf machine: Add missing dsos->root rbtree root initialization
    
    A segfault happens on 'perf test hists_link' because we end up using a
    struct machines on the stack, and then machines__init() was not
    initializing the newly introduced rb_root, just the existing list_head.
    
    When we introduced struct dsos, to group the two ways to store dsos,
    i.e. the linked list and the rbtree, we didn't turned the initialization
    done in:
    
            machines__init(machines->host) ->
                    machine__init() ->
                            INIT_LIST_HEAD
    
    into a dsos__init() to keep on initializing the list_head but _as well_
    initializing the rb_root, oops.
    
    All worked because outside perf-test we probably zalloc the whole thing
    which ends up initializing it in to NULL.
    
    So the problem looks contained to 'perf test' that uses it on stack,
    etc.
    
    Reported-by: Jiri Olsa <jolsa@redhat.com>
    Acked-by: Waiman Long <Waiman.Long@hp.com>,
    Cc: Adrian Hunter <adrian.hunter@intel.com>,
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Douglas Hatch <doug.hatch@hp.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Scott J Norton <scott.norton@hp.com>
    Cc: Waiman Long <Waiman.Long@hp.com>,
    Link: http://lkml.kernel.org/r/20141014180353.GF3198@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index b7d477fbda02..34fc7c8672e4 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -13,12 +13,18 @@
 #include <symbol/kallsyms.h>
 #include "unwind.h"
 
+static void dsos__init(struct dsos *dsos)
+{
+	INIT_LIST_HEAD(&dsos->head);
+	dsos->root = RB_ROOT;
+}
+
 int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 {
 	map_groups__init(&machine->kmaps);
 	RB_CLEAR_NODE(&machine->rb_node);
-	INIT_LIST_HEAD(&machine->user_dsos.head);
-	INIT_LIST_HEAD(&machine->kernel_dsos.head);
+	dsos__init(&machine->user_dsos);
+	dsos__init(&machine->kernel_dsos);
 
 	machine->threads = RB_ROOT;
 	INIT_LIST_HEAD(&machine->dead_threads);

commit 4598a0a6d22fadfb7b37f2b44ee7fdcb24632fcf
Author: Waiman Long <Waiman.Long@hp.com>
Date:   Tue Sep 30 13:36:15 2014 -0400

    perf symbols: Improve DSO long names lookup speed with rbtree
    
    With workload that spawns and destroys many threads and processes, it
    was found that perf-mem could took a long time to post-process the perf
    data after the target workload had completed its operation.
    
    The performance bottleneck was found to be the lookup and insertion of
    the new DSO structures (thousands of them in this case).
    
    In a dual-socket Ivy-Bridge E7-4890 v2 machine (30-core, 60-thread), the
    perf profile below shows what perf was doing after the profiled AIM7
    shared workload completed:
    
    -     83.94%  perf  libc-2.11.3.so     [.] __strcmp_sse42
       - __strcmp_sse42
          - 99.82% map__new
               machine__process_mmap_event
               perf_session_deliver_event
               perf_session__process_event
               __perf_session__process_events
               cmd_record
               cmd_mem
               run_builtin
               main
               __libc_start_main
    -     13.17%  perf  perf               [.] __dsos__findnew
         __dsos__findnew
         map__new
         machine__process_mmap_event
         perf_session_deliver_event
         perf_session__process_event
         __perf_session__process_events
         cmd_record
         cmd_mem
         run_builtin
         main
         __libc_start_main
    
    So about 97% of CPU times were spent in the map__new() function trying
    to insert new DSO entry into the DSO linked list. The whole
    post-processing step took about 9 minutes.
    
    The DSO structures are currently searched linearly. So the total
    processing time will be proportional to n^2.
    
    To overcome this performance problem, the DSO code is modified to also
    put the DSO structures in a RB tree sorted by its long name in
    additional to being in a simple linked list. With this change, the
    processing time will become proportional to n*log(n) which will be much
    quicker for large n. However, the short name will still be searched
    using the old linear searching method.  With that patch in place, the
    same perf-mem post-processing step took less than 30 seconds to
    complete.
    
    Signed-off-by: Waiman Long <Waiman.Long@hp.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Douglas Hatch <doug.hatch@hp.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Scott J Norton <scott.norton@hp.com>
    Link: http://lkml.kernel.org/r/1412098575-27863-3-git-send-email-Waiman.Long@hp.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 49a75ec4c47b..b7d477fbda02 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -77,6 +77,7 @@ static void dsos__delete(struct dsos *dsos)
 	struct dso *pos, *n;
 
 	list_for_each_entry_safe(pos, n, &dsos->head, node) {
+		RB_CLEAR_NODE(&pos->rb_node);
 		list_del(&pos->node);
 		dso__delete(pos);
 	}

commit 8fa7d87f91479f7124142ca4ad93a37b80f8c1c0
Author: Waiman Long <Waiman.Long@hp.com>
Date:   Mon Sep 29 16:07:28 2014 -0400

    perf symbols: Encapsulate dsos list head into struct dsos
    
    This is a precursor patch to enable long name searching of DSOs using
    a rbtree.
    
    In this patch, a new dsos structure is created which contains only a
    list head structure for the moment.
    
    The new dsos structure is used, in turn, in the machine structure for
    the user_dsos and kernel_dsos fields.
    
    Only the following 3 dsos functions are modified to accept the new dsos
    structure parameter instead of list_head:
    
     - dsos__add()
     - dsos__find()
     - __dsos__findnew()
    
    Signed-off-by: Waiman Long <Waiman.Long@hp.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Douglas Hatch <doug.hatch@hp.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Scott J Norton <scott.norton@hp.com>
    Link: http://lkml.kernel.org/r/1412021249-19201-2-git-send-email-Waiman.Long@hp.com
    [ Move struct dsos to dso.h to reduce the dso methods depends on machine.h ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index b2ec38bf211e..49a75ec4c47b 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -17,8 +17,8 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 {
 	map_groups__init(&machine->kmaps);
 	RB_CLEAR_NODE(&machine->rb_node);
-	INIT_LIST_HEAD(&machine->user_dsos);
-	INIT_LIST_HEAD(&machine->kernel_dsos);
+	INIT_LIST_HEAD(&machine->user_dsos.head);
+	INIT_LIST_HEAD(&machine->kernel_dsos.head);
 
 	machine->threads = RB_ROOT;
 	INIT_LIST_HEAD(&machine->dead_threads);
@@ -72,11 +72,11 @@ struct machine *machine__new_host(void)
 	return NULL;
 }
 
-static void dsos__delete(struct list_head *dsos)
+static void dsos__delete(struct dsos *dsos)
 {
 	struct dso *pos, *n;
 
-	list_for_each_entry_safe(pos, n, dsos, node) {
+	list_for_each_entry_safe(pos, n, &dsos->head, node) {
 		list_del(&pos->node);
 		dso__delete(pos);
 	}
@@ -477,23 +477,23 @@ struct map *machine__new_module(struct machine *machine, u64 start,
 size_t machines__fprintf_dsos(struct machines *machines, FILE *fp)
 {
 	struct rb_node *nd;
-	size_t ret = __dsos__fprintf(&machines->host.kernel_dsos, fp) +
-		     __dsos__fprintf(&machines->host.user_dsos, fp);
+	size_t ret = __dsos__fprintf(&machines->host.kernel_dsos.head, fp) +
+		     __dsos__fprintf(&machines->host.user_dsos.head, fp);
 
 	for (nd = rb_first(&machines->guests); nd; nd = rb_next(nd)) {
 		struct machine *pos = rb_entry(nd, struct machine, rb_node);
-		ret += __dsos__fprintf(&pos->kernel_dsos, fp);
-		ret += __dsos__fprintf(&pos->user_dsos, fp);
+		ret += __dsos__fprintf(&pos->kernel_dsos.head, fp);
+		ret += __dsos__fprintf(&pos->user_dsos.head, fp);
 	}
 
 	return ret;
 }
 
-size_t machine__fprintf_dsos_buildid(struct machine *machine, FILE *fp,
+size_t machine__fprintf_dsos_buildid(struct machine *m, FILE *fp,
 				     bool (skip)(struct dso *dso, int parm), int parm)
 {
-	return __dsos__fprintf_buildid(&machine->kernel_dsos, fp, skip, parm) +
-	       __dsos__fprintf_buildid(&machine->user_dsos, fp, skip, parm);
+	return __dsos__fprintf_buildid(&m->kernel_dsos.head, fp, skip, parm) +
+	       __dsos__fprintf_buildid(&m->user_dsos.head, fp, skip, parm);
 }
 
 size_t machines__fprintf_dsos_buildid(struct machines *machines, FILE *fp,
@@ -994,7 +994,7 @@ static bool machine__uses_kcore(struct machine *machine)
 {
 	struct dso *dso;
 
-	list_for_each_entry(dso, &machine->kernel_dsos, node) {
+	list_for_each_entry(dso, &machine->kernel_dsos.head, node) {
 		if (dso__is_kcore(dso))
 			return true;
 	}

commit 06b2afc0b9a26e7673856a24ab57bfb307dad394
Author: Don Zickus <dzickus@redhat.com>
Date:   Wed Aug 20 23:25:11 2014 -0400

    perf machine: Fallback to MAP__FUNCTION if daddr maps are NULL
    
    As we run "perf c2c" on more applications, we noticed we're missing
    significant samples from a common customer's application.  Looking at
    the /proc/<pid>/maps file for the app, we see "rwxs" and "rwxp"
    permissions on many of the shared memory & heap regions, and on all the
    thread stacks.
    
    Because those regions have the "x" bit set, perf marks them with a
    MAP_FUNCTION type.  Hence ip_resolve_data() never finds load or store
    events coming from them.
    
    We fixed this by re-calling thread__find_addr_location with
    MAP__FUNCTION in the case where map is NULL as a last ditch effort to
    map the sample before giving up and dropping it.
    
    Reported-by: Joe Mario <jmario@redhat.com>
    Tested-by: Joe Mario <jmario@redhat.com>
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Joe Mario <jmario@redhat.com>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1408591511-57884-1-git-send-email-dzickus@redhat.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index e00daf0d2bde..b2ec38bf211e 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1314,6 +1314,16 @@ static void ip__resolve_data(struct machine *machine, struct thread *thread,
 
 	thread__find_addr_location(thread, machine, m, MAP__VARIABLE, addr,
 				   &al);
+	if (al.map == NULL) {
+		/*
+		 * some shared data regions have execute bit set which puts
+		 * their mapping in the MAP__FUNCTION type array.
+		 * Check there as a fallback option before dropping the sample.
+		 */
+		thread__find_addr_location(thread, machine, m, MAP__FUNCTION, addr,
+					   &al);
+	}
+
 	ams->addr = addr;
 	ams->al_addr = al.addr;
 	ams->sym = al.sym;

commit fbe2af45f6bd27ee69fd775303c936c3af4a4807
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Fri Aug 15 22:08:39 2014 +0300

    perf tools: Add machine__kernel_ip()
    
    Add a function to determine if an address is in the kernel.  This is
    based on the kernel function kernel_ip().
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1408129739-17368-5-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 37f8dc557ec0..e00daf0d2bde 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -32,6 +32,7 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 	machine->symbol_filter = NULL;
 	machine->id_hdr_size = 0;
 	machine->comm_exec = false;
+	machine->kernel_start = 0;
 
 	machine->root_dir = strdup(root_dir);
 	if (machine->root_dir == NULL)
@@ -1559,3 +1560,25 @@ int machine__set_current_tid(struct machine *machine, int cpu, pid_t pid,
 
 	return 0;
 }
+
+int machine__get_kernel_start(struct machine *machine)
+{
+	struct map *map = machine__kernel_map(machine, MAP__FUNCTION);
+	int err = 0;
+
+	/*
+	 * The only addresses above 2^63 are kernel addresses of a 64-bit
+	 * kernel.  Note that addresses are unsigned so that on a 32-bit system
+	 * all addresses including kernel addresses are less than 2^32.  In
+	 * that case (32-bit system), if the kernel mapping is unknown, all
+	 * addresses will be assumed to be in user space - see
+	 * machine__kernel_ip().
+	 */
+	machine->kernel_start = 1ULL << 63;
+	if (map) {
+		err = map__load(map, machine->symbol_filter);
+		if (map->start)
+			machine->kernel_start = map->start;
+	}
+	return err;
+}

commit 4b99375b38fa137f501cfa60b70e3f0a9da39c93
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Fri Aug 15 22:08:38 2014 +0300

    perf machine: Rename machine__get_kernel_start_addr() method
    
    Rename machine__get_kernel_start_addr() to
    machine__get_running_kernel_start() so that a new function, with a
    similar name to the original name, can be added that gets the kernel
    start address from the kernel map.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1408129739-17368-4-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index b093b93607fb..37f8dc557ec0 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -593,8 +593,8 @@ const char *ref_reloc_sym_names[] = {"_text", "_stext", NULL};
  * Returns the name of the start symbol in *symbol_name. Pass in NULL as
  * symbol_name if it's not that important.
  */
-static u64 machine__get_kernel_start_addr(struct machine *machine,
-					  const char **symbol_name)
+static u64 machine__get_running_kernel_start(struct machine *machine,
+					     const char **symbol_name)
 {
 	char filename[PATH_MAX];
 	int i;
@@ -621,7 +621,7 @@ static u64 machine__get_kernel_start_addr(struct machine *machine,
 int __machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
 {
 	enum map_type type;
-	u64 start = machine__get_kernel_start_addr(machine, NULL);
+	u64 start = machine__get_running_kernel_start(machine, NULL);
 
 	for (type = 0; type < MAP__NR_TYPES; ++type) {
 		struct kmap *kmap;
@@ -940,7 +940,7 @@ int machine__create_kernel_maps(struct machine *machine)
 {
 	struct dso *kernel = machine__get_kernel(machine);
 	const char *name;
-	u64 addr = machine__get_kernel_start_addr(machine, &name);
+	u64 addr = machine__get_running_kernel_start(machine, &name);
 	if (!addr)
 		return -1;
 

commit cfe1c41405fe9a559f8b3c24c904b2bb42d4a6e8
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Thu Jul 31 09:00:45 2014 +0300

    perf machine: Add machine__thread_exec_comm()
    
    Add machine__thread_exec_comm() to return the comm that matches the last
    exec, if the comm_exec flag is present, or the last comm otherwise.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1406786474-9306-3-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index ea3e09f6a9c6..b093b93607fb 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -31,6 +31,7 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 
 	machine->symbol_filter = NULL;
 	machine->id_hdr_size = 0;
+	machine->comm_exec = false;
 
 	machine->root_dir = strdup(root_dir);
 	if (machine->root_dir == NULL)
@@ -179,6 +180,19 @@ void machines__set_symbol_filter(struct machines *machines,
 	}
 }
 
+void machines__set_comm_exec(struct machines *machines, bool comm_exec)
+{
+	struct rb_node *nd;
+
+	machines->host.comm_exec = comm_exec;
+
+	for (nd = rb_first(&machines->guests); nd; nd = rb_next(nd)) {
+		struct machine *machine = rb_entry(nd, struct machine, rb_node);
+
+		machine->comm_exec = comm_exec;
+	}
+}
+
 struct machine *machines__find(struct machines *machines, pid_t pid)
 {
 	struct rb_node **p = &machines->guests.rb_node;
@@ -398,6 +412,15 @@ struct thread *machine__find_thread(struct machine *machine, pid_t pid,
 	return __machine__findnew_thread(machine, pid, tid, false);
 }
 
+struct comm *machine__thread_exec_comm(struct machine *machine,
+				       struct thread *thread)
+{
+	if (machine->comm_exec)
+		return thread__exec_comm(thread);
+	else
+		return thread__comm(thread);
+}
+
 int machine__process_comm_event(struct machine *machine, union perf_event *event,
 				struct perf_sample *sample)
 {
@@ -406,6 +429,9 @@ int machine__process_comm_event(struct machine *machine, union perf_event *event
 							event->comm.tid);
 	bool exec = event->header.misc & PERF_RECORD_MISC_COMM_EXEC;
 
+	if (exec)
+		machine->comm_exec = true;
+
 	if (dump_trace)
 		perf_event__fprintf_comm(event, stdout);
 

commit 65de51f93ebf9305ec011da59c0b5fe29429d1b9
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Thu Jul 31 09:00:44 2014 +0300

    perf tools: Identify which comms are from exec
    
    For grouping together all the data from a single execution, which is
    needed for pairing calls and returns e.g. any outstanding calls when a
    process exec's will never return.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1406786474-9306-2-git-send-email-adrian.hunter@intel.com
    [ Remove testing if comm->exec is false before setting it to true ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 16bba9fff2c8..ea3e09f6a9c6 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -404,11 +404,13 @@ int machine__process_comm_event(struct machine *machine, union perf_event *event
 	struct thread *thread = machine__findnew_thread(machine,
 							event->comm.pid,
 							event->comm.tid);
+	bool exec = event->header.misc & PERF_RECORD_MISC_COMM_EXEC;
 
 	if (dump_trace)
 		perf_event__fprintf_comm(event, stdout);
 
-	if (thread == NULL || thread__set_comm(thread, event->comm.comm, sample->time)) {
+	if (thread == NULL ||
+	    __thread__set_comm(thread, event->comm.comm, sample->time, exec)) {
 		dump_printf("problem processing PERF_RECORD_COMM, skipping event.\n");
 		return -1;
 	}

commit 5835eddab6f162b38e9a6a5447a2c3a128637956
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Tue Jul 22 16:18:00 2014 +0300

    perf tools: Add thread parameter to vdso__dso_findnew()
    
    The thread will be needed to determine the VDSO type.
    
    Reviewed-by: Jiri Olsa <jolsa@redhat.com>
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1406035081-14301-52-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 65269b8ac186..16bba9fff2c8 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1106,7 +1106,7 @@ int machine__process_mmap2_event(struct machine *machine,
 			event->mmap2.ino_generation,
 			event->mmap2.prot,
 			event->mmap2.flags,
-			event->mmap2.filename, type);
+			event->mmap2.filename, type, thread);
 
 	if (map == NULL)
 		goto out_problem;
@@ -1153,7 +1153,7 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 			event->mmap.len, event->mmap.pgoff,
 			event->mmap.pid, 0, 0, 0, 0, 0, 0,
 			event->mmap.filename,
-			type);
+			type, thread);
 
 	if (map == NULL)
 		goto out_problem;

commit d027b64001b21328cc92d35c6444e1a7a926ea76
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Wed Jul 23 14:23:00 2014 +0300

    perf machine: Fix the lifetime of the VDSO temporary file
    
    The VDSO temporary file is unlinked when a session is deleted.  That
    precludes the possibilities that there is no session or there is more
    than one session.
    
    Correctly the vdso belongs to the machine so put the information on
    'struct machine' and get rid of the global variables.
    
    Reviewed-by: Jiri Olsa <jolsa@redhat.com>
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/53CF9B14.7040408@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index a25f3ee1b5b3..65269b8ac186 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -8,6 +8,7 @@
 #include "sort.h"
 #include "strlist.h"
 #include "thread.h"
+#include "vdso.h"
 #include <stdbool.h>
 #include <symbol/kallsyms.h>
 #include "unwind.h"
@@ -23,6 +24,8 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 	INIT_LIST_HEAD(&machine->dead_threads);
 	machine->last_match = NULL;
 
+	machine->vdso_info = NULL;
+
 	machine->kmaps.machine = machine;
 	machine->pid = pid;
 
@@ -105,6 +108,7 @@ void machine__exit(struct machine *machine)
 	map_groups__exit(&machine->kmaps);
 	dsos__delete(&machine->user_dsos);
 	dsos__delete(&machine->kernel_dsos);
+	vdso__exit(machine);
 	zfree(&machine->root_dir);
 	zfree(&machine->current_tid);
 }

commit 2a03068c5cfa104768703cbefa2e23a6353f8de5
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Tue Jul 22 16:17:53 2014 +0300

    perf tools: Pass machine to vdso__dso_findnew()
    
    This is preparation for removing the global variables used in vdso.c and
    thereby fixing the lifetime of the VDSO temporary file.
    
    Reviewed-by: Jiri Olsa <jolsa@redhat.com>
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1406035081-14301-45-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index cfc691000f13..a25f3ee1b5b3 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1095,7 +1095,7 @@ int machine__process_mmap2_event(struct machine *machine,
 	else
 		type = MAP__FUNCTION;
 
-	map = map__new(&machine->user_dsos, event->mmap2.start,
+	map = map__new(machine, event->mmap2.start,
 			event->mmap2.len, event->mmap2.pgoff,
 			event->mmap2.pid, event->mmap2.maj,
 			event->mmap2.min, event->mmap2.ino,
@@ -1145,7 +1145,7 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 	else
 		type = MAP__FUNCTION;
 
-	map = map__new(&machine->user_dsos, event->mmap.start,
+	map = map__new(machine, event->mmap.start,
 			event->mmap.len, event->mmap.pgoff,
 			event->mmap.pid, 0, 0, 0, 0, 0, 0,
 			event->mmap.filename,

commit b9d266baac0429f70df3f9cf751b045730d612e3
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Tue Jul 22 16:17:25 2014 +0300

    perf machine: Add ability to record the current tid for each cpu
    
    Add an array to struct machine to store the current tid running on each
    cpu.
    
    Add machine functions to get / set the tid for a cpu.
    
    This will be used to determine the tid when decoding a per-cpu
    Instruction Trace.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1406035081-14301-17-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 93c8b6fbc799..cfc691000f13 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -45,6 +45,8 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 		thread__set_comm(thread, comm, 0);
 	}
 
+	machine->current_tid = NULL;
+
 	return 0;
 }
 
@@ -104,6 +106,7 @@ void machine__exit(struct machine *machine)
 	dsos__delete(&machine->user_dsos);
 	dsos__delete(&machine->kernel_dsos);
 	zfree(&machine->root_dir);
+	zfree(&machine->current_tid);
 }
 
 void machine__delete(struct machine *machine)
@@ -1481,3 +1484,46 @@ int __machine__synthesize_threads(struct machine *machine, struct perf_tool *too
 	/* command specified */
 	return 0;
 }
+
+pid_t machine__get_current_tid(struct machine *machine, int cpu)
+{
+	if (cpu < 0 || cpu >= MAX_NR_CPUS || !machine->current_tid)
+		return -1;
+
+	return machine->current_tid[cpu];
+}
+
+int machine__set_current_tid(struct machine *machine, int cpu, pid_t pid,
+			     pid_t tid)
+{
+	struct thread *thread;
+
+	if (cpu < 0)
+		return -EINVAL;
+
+	if (!machine->current_tid) {
+		int i;
+
+		machine->current_tid = calloc(MAX_NR_CPUS, sizeof(pid_t));
+		if (!machine->current_tid)
+			return -ENOMEM;
+		for (i = 0; i < MAX_NR_CPUS; i++)
+			machine->current_tid[i] = -1;
+	}
+
+	if (cpu >= MAX_NR_CPUS) {
+		pr_err("Requested CPU %d too large. ", cpu);
+		pr_err("Consider raising MAX_NR_CPUS\n");
+		return -EINVAL;
+	}
+
+	machine->current_tid[cpu] = tid;
+
+	thread = machine__findnew_thread(machine, pid, tid);
+	if (!thread)
+		return -ENOMEM;
+
+	thread->cpu = cpu;
+
+	return 0;
+}

commit 418029b7324f8b90ac1dfbc8a44555d6905be761
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Wed Jul 16 10:19:44 2014 +0300

    perf machine: Fix leak of 'struct thread' on error path
    
    __machine__findnew_thread() creates a 'struct thread' but does not free
    it on the error path. Fix it.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1405495184-20441-3-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 5484fa4385fc..93c8b6fbc799 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -370,8 +370,10 @@ static struct thread *__machine__findnew_thread(struct machine *machine,
 		 * within thread__init_map_groups to find the thread
 		 * leader and that would screwed the rb tree.
 		 */
-		if (thread__init_map_groups(th, machine))
+		if (thread__init_map_groups(th, machine)) {
+			thread__delete(th);
 			return NULL;
+		}
 	}
 
 	return th;

commit 29ce36121e6738012aaf00d983d25260627f2b0d
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Wed Jul 16 11:07:13 2014 +0300

    perf machine: Fix map groups of threads with unknown pids
    
    Events like sched_switch do not provide a pid (tgid) which can result in
    threads with an unknown pid.  If the pid is later discovered, join the
    map groups.
    
    Note the thread's map groups should be empty because they are populated
    by MMAP events which do provide the pid and tid.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1405498033-23817-1-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 5b8087728f28..5484fa4385fc 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -272,6 +272,52 @@ void machines__set_id_hdr_size(struct machines *machines, u16 id_hdr_size)
 	return;
 }
 
+static void machine__update_thread_pid(struct machine *machine,
+				       struct thread *th, pid_t pid)
+{
+	struct thread *leader;
+
+	if (pid == th->pid_ || pid == -1 || th->pid_ != -1)
+		return;
+
+	th->pid_ = pid;
+
+	if (th->pid_ == th->tid)
+		return;
+
+	leader = machine__findnew_thread(machine, th->pid_, th->pid_);
+	if (!leader)
+		goto out_err;
+
+	if (!leader->mg)
+		leader->mg = map_groups__new();
+
+	if (!leader->mg)
+		goto out_err;
+
+	if (th->mg == leader->mg)
+		return;
+
+	if (th->mg) {
+		/*
+		 * Maps are created from MMAP events which provide the pid and
+		 * tid.  Consequently there never should be any maps on a thread
+		 * with an unknown pid.  Just print an error if there are.
+		 */
+		if (!map_groups__empty(th->mg))
+			pr_err("Discarding thread maps for %d:%d\n",
+			       th->pid_, th->tid);
+		map_groups__delete(th->mg);
+	}
+
+	th->mg = map_groups__get(leader->mg);
+
+	return;
+
+out_err:
+	pr_err("Failed to join map groups for %d:%d\n", th->pid_, th->tid);
+}
+
 static struct thread *__machine__findnew_thread(struct machine *machine,
 						pid_t pid, pid_t tid,
 						bool create)
@@ -285,10 +331,10 @@ static struct thread *__machine__findnew_thread(struct machine *machine,
 	 * so most of the time we dont have to look up
 	 * the full rbtree:
 	 */
-	if (machine->last_match && machine->last_match->tid == tid) {
-		if (pid != -1 && pid != machine->last_match->pid_)
-			machine->last_match->pid_ = pid;
-		return machine->last_match;
+	th = machine->last_match;
+	if (th && th->tid == tid) {
+		machine__update_thread_pid(machine, th, pid);
+		return th;
 	}
 
 	while (*p != NULL) {
@@ -297,8 +343,7 @@ static struct thread *__machine__findnew_thread(struct machine *machine,
 
 		if (th->tid == tid) {
 			machine->last_match = th;
-			if (pid != -1 && pid != th->pid_)
-				th->pid_ = pid;
+			machine__update_thread_pid(machine, th, pid);
 			return th;
 		}
 

commit 1fcb8768636d38cb6fdfeef83a5ee596c4bd9c56
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Mon Jul 14 13:02:25 2014 +0300

    perf machine: Fix the value used for unknown pids
    
    The value used for unknown pids cannot be zero because that is used by
    the "idle" task.
    
    Use -1 instead.  Also handle the unknown pid case when creating map
    groups.
    
    Note that, threads with an unknown pid should not occur because fork (or
    synthesized) events precede the thread's existence.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1405332185-4050-2-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index e9b943acaa5e..5b8087728f28 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -34,7 +34,7 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 		return -ENOMEM;
 
 	if (pid != HOST_KERNEL_ID) {
-		struct thread *thread = machine__findnew_thread(machine, 0,
+		struct thread *thread = machine__findnew_thread(machine, -1,
 								pid);
 		char comm[64];
 
@@ -286,7 +286,7 @@ static struct thread *__machine__findnew_thread(struct machine *machine,
 	 * the full rbtree:
 	 */
 	if (machine->last_match && machine->last_match->tid == tid) {
-		if (pid && pid != machine->last_match->pid_)
+		if (pid != -1 && pid != machine->last_match->pid_)
 			machine->last_match->pid_ = pid;
 		return machine->last_match;
 	}
@@ -297,7 +297,7 @@ static struct thread *__machine__findnew_thread(struct machine *machine,
 
 		if (th->tid == tid) {
 			machine->last_match = th;
-			if (pid && pid != th->pid_)
+			if (pid != -1 && pid != th->pid_)
 				th->pid_ = pid;
 			return th;
 		}

commit a60335ba32981db5bc057b35782644e9e2436407
Author: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
Date:   Wed Jun 25 08:49:03 2014 -0700

    perf tools powerpc: Adjust callchain based on DWARF debug info
    
    When saving the callchain on Power, the kernel conservatively saves excess
    entries in the callchain. A few of these entries are needed in some cases
    but not others. We should use the DWARF debug information to determine
    when the entries are  needed.
    
    Eg: the value in the link register (LR) is needed only when it holds the
    return address of a function. At other times it must be ignored.
    
    If the unnecessary entries are not ignored, we end up with duplicate arcs
    in the call-graphs.
    
    Use the DWARF debug information to determine if any callchain entries
    should be ignored when building call-graphs.
    
    Callgraph before the patch:
    
        14.67%          2234  sprintft  libc-2.18.so       [.] __random
                |
                --- __random
                   |
                   |--61.12%-- __random
                   |          |
                   |          |--97.15%-- rand
                   |          |          do_my_sprintf
                   |          |          main
                   |          |          generic_start_main.isra.0
                   |          |          __libc_start_main
                   |          |          0x0
                   |          |
                   |           --2.85%-- do_my_sprintf
                   |                     main
                   |                     generic_start_main.isra.0
                   |                     __libc_start_main
                   |                     0x0
                   |
                    --38.88%-- rand
                              |
                              |--94.01%-- rand
                              |          do_my_sprintf
                              |          main
                              |          generic_start_main.isra.0
                              |          __libc_start_main
                              |          0x0
                              |
                               --5.99%-- do_my_sprintf
                                         main
                                         generic_start_main.isra.0
                                         __libc_start_main
                                         0x0
    
    Callgraph after the patch:
    
        14.67%          2234  sprintft  libc-2.18.so       [.] __random
                |
                --- __random
                   |
                   |--95.93%-- rand
                   |          do_my_sprintf
                   |          main
                   |          generic_start_main.isra.0
                   |          __libc_start_main
                   |          0x0
                   |
                    --4.07%-- do_my_sprintf
                              main
                              generic_start_main.isra.0
                              __libc_start_main
                              0x0
    
    TODO:   For split-debug info objects like glibc, we can only determine
            the call-frame-address only when both .eh_frame and .debug_info
            sections are available. We should be able to determin the CFA
            even without the .eh_frame section.
    
    Fix suggested by Anton Blanchard.
    
    Thanks to valuable input on DWARF debug information from Ulrich Weigand.
    
    Reported-by: Maynard Johnson <maynard@us.ibm.com>
    Tested-by: Maynard Johnson <maynard@us.ibm.com>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Link: http://lkml.kernel.org/r/20140625154903.GA29607@us.ibm.com
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index c73e1fc12e53..e9b943acaa5e 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1281,7 +1281,9 @@ static int machine__resolve_callchain_sample(struct machine *machine,
 	u8 cpumode = PERF_RECORD_MISC_USER;
 	int chain_nr = min(max_stack, (int)chain->nr);
 	int i;
+	int j;
 	int err;
+	int skip_idx __maybe_unused;
 
 	callchain_cursor_reset(&callchain_cursor);
 
@@ -1290,14 +1292,26 @@ static int machine__resolve_callchain_sample(struct machine *machine,
 		return 0;
 	}
 
+	/*
+	 * Based on DWARF debug information, some architectures skip
+	 * a callchain entry saved by the kernel.
+	 */
+	skip_idx = arch_skip_callchain_idx(machine, thread, chain);
+
 	for (i = 0; i < chain_nr; i++) {
 		u64 ip;
 		struct addr_location al;
 
 		if (callchain_param.order == ORDER_CALLEE)
-			ip = chain->ips[i];
+			j = i;
 		else
-			ip = chain->ips[chain->nr - i - 1];
+			j = chain->nr - i - 1;
+
+#ifdef HAVE_SKIP_CALLCHAIN_IDX
+		if (j == skip_idx)
+			continue;
+#endif
+		ip = chain->ips[j];
 
 		if (ip >= PERF_CONTEXT_MAX) {
 			switch (ip) {

commit a93f0e551af9e194db38bfe16001e17a3a1d189a
Author: Simon Que <sque@chromium.org>
Date:   Mon Jun 16 11:32:09 2014 -0700

    perf symbols: Get kernel start address by symbol name
    
    The function machine__get_kernel_start_addr() was taking the first symbol
    of kallsyms as the start address. This is incorrect in certain cases
    where the first symbol is something at 0, while the actual kernel
    functions begin at a later point (e.g. 0x80200000).
    
    This patch fixes machine__get_kernel_start_addr() to search for the
    symbol "_text" or "_stext", which marks the beginning of kernel mapping.
    This was already being done in machine__create_kernel_maps(). Thus, this
    patch is just a refactor, to move that code into
    machine__get_kernel_start_addr().
    
    Signed-off-by: Simon Que <sque@chromium.org>
    Link: http://lkml.kernel.org/r/1402943529-13244-1-git-send-email-sque@chromium.org
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 0e5fea95d596..c73e1fc12e53 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -496,18 +496,6 @@ struct process_args {
 	u64 start;
 };
 
-static int symbol__in_kernel(void *arg, const char *name,
-			     char type __maybe_unused, u64 start)
-{
-	struct process_args *args = arg;
-
-	if (strchr(name, '['))
-		return 0;
-
-	args->start = start;
-	return 1;
-}
-
 static void machine__get_kallsyms_filename(struct machine *machine, char *buf,
 					   size_t bufsz)
 {
@@ -517,27 +505,41 @@ static void machine__get_kallsyms_filename(struct machine *machine, char *buf,
 		scnprintf(buf, bufsz, "%s/proc/kallsyms", machine->root_dir);
 }
 
-/* Figure out the start address of kernel map from /proc/kallsyms */
-static u64 machine__get_kernel_start_addr(struct machine *machine)
+const char *ref_reloc_sym_names[] = {"_text", "_stext", NULL};
+
+/* Figure out the start address of kernel map from /proc/kallsyms.
+ * Returns the name of the start symbol in *symbol_name. Pass in NULL as
+ * symbol_name if it's not that important.
+ */
+static u64 machine__get_kernel_start_addr(struct machine *machine,
+					  const char **symbol_name)
 {
 	char filename[PATH_MAX];
-	struct process_args args;
+	int i;
+	const char *name;
+	u64 addr = 0;
 
 	machine__get_kallsyms_filename(machine, filename, PATH_MAX);
 
 	if (symbol__restricted_filename(filename, "/proc/kallsyms"))
 		return 0;
 
-	if (kallsyms__parse(filename, &args, symbol__in_kernel) <= 0)
-		return 0;
+	for (i = 0; (name = ref_reloc_sym_names[i]) != NULL; i++) {
+		addr = kallsyms__get_function_start(filename, name);
+		if (addr)
+			break;
+	}
+
+	if (symbol_name)
+		*symbol_name = name;
 
-	return args.start;
+	return addr;
 }
 
 int __machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
 {
 	enum map_type type;
-	u64 start = machine__get_kernel_start_addr(machine);
+	u64 start = machine__get_kernel_start_addr(machine, NULL);
 
 	for (type = 0; type < MAP__NR_TYPES; ++type) {
 		struct kmap *kmap;
@@ -852,23 +854,11 @@ static int machine__create_modules(struct machine *machine)
 	return 0;
 }
 
-const char *ref_reloc_sym_names[] = {"_text", "_stext", NULL};
-
 int machine__create_kernel_maps(struct machine *machine)
 {
 	struct dso *kernel = machine__get_kernel(machine);
-	char filename[PATH_MAX];
 	const char *name;
-	u64 addr = 0;
-	int i;
-
-	machine__get_kallsyms_filename(machine, filename, PATH_MAX);
-
-	for (i = 0; (name = ref_reloc_sym_names[i]) != NULL; i++) {
-		addr = kallsyms__get_function_start(filename, name);
-		if (addr)
-			break;
-	}
+	u64 addr = machine__get_kernel_start_addr(machine, &name);
 	if (!addr)
 		return -1;
 

commit 7ef807034ef33f8afe33fa7957c73954e8e4f89c
Author: Don Zickus <dzickus@redhat.com>
Date:   Mon May 19 15:13:49 2014 -0400

    perf tools: Update mmap2 interface with protection and flag bits
    
    The kernel piece passes more info now.  Update the perf tool to reflect
    that and adjust the synthesized maps to play along.
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Link: http://lkml.kernel.org/r/1400526833-141779-4-git-send-email-dzickus@redhat.com
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 7409ac8de51c..0e5fea95d596 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1060,6 +1060,8 @@ int machine__process_mmap2_event(struct machine *machine,
 			event->mmap2.pid, event->mmap2.maj,
 			event->mmap2.min, event->mmap2.ino,
 			event->mmap2.ino_generation,
+			event->mmap2.prot,
+			event->mmap2.flags,
 			event->mmap2.filename, type);
 
 	if (map == NULL)
@@ -1105,7 +1107,7 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 
 	map = map__new(&machine->user_dsos, event->mmap.start,
 			event->mmap.len, event->mmap.pgoff,
-			event->mmap.pid, 0, 0, 0, 0,
+			event->mmap.pid, 0, 0, 0, 0, 0, 0,
 			event->mmap.filename,
 			type);
 

commit aeffe2abc894b585acbe0923c0d4f21b4c5c1035
Merge: 201131998fbf 399f0c220a0e
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu May 1 08:24:39 2014 +0200

    Merge branch 'perf/urgent' into perf/core, to resolve conflict
    
    Conflicts:
            tools/perf/arch/x86/tests/dwarf-unwind.c
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 61d4290cc1f10588147b76b385875f06827d47ff
Author: Richard Yao <ryao@gentoo.org>
Date:   Sat Apr 26 13:17:55 2014 -0400

    perf machine: Search for modules in %s/lib/modules/%s
    
    Modules installed outside of the kernel's build system should go into
    "%s/lib/modules/%s/extra", but at present, perf will only look at them
    when they are in "%s/lib/modules/%s/kernel". Lets encourage good
    citizenship by relaxing this requirement to "%s/lib/modules/%s". This
    way open source modules that are out-of-tree have no incentive to start
    populating a directory reserved for in-kernel modules and I can stop
    hex-editing my system's perf binary when profiling OSS out-of-tree
    modules.
    
    Feedback from Namhyung Kim correctly revealed that the hex-edits that I
    had been doing meant that perf was also traversing the build and source
    symlinks in %s/lib/modules/%s. That is undesireable, so we explicitly
    exclude them from traversal with a minor tweak to the traversal routine.
    
    Signed-off-by: Richard Yao <ryao@gentoo.org>
    Acked-by: Namhyung kim <namhyung@kernel.org>
    Link: http://lkml.kernel.org/r/1398532675-13684-1-git-send-email-ryao@gentoo.org
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index a53cd0b8c151..27c2a5efe450 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -717,7 +717,7 @@ static char *get_kernel_version(const char *root_dir)
 }
 
 static int map_groups__set_modules_path_dir(struct map_groups *mg,
-				const char *dir_name)
+				const char *dir_name, int depth)
 {
 	struct dirent *dent;
 	DIR *dir = opendir(dir_name);
@@ -742,7 +742,15 @@ static int map_groups__set_modules_path_dir(struct map_groups *mg,
 			    !strcmp(dent->d_name, ".."))
 				continue;
 
-			ret = map_groups__set_modules_path_dir(mg, path);
+			/* Do not follow top-level source and build symlinks */
+			if (depth == 0) {
+				if (!strcmp(dent->d_name, "source") ||
+				    !strcmp(dent->d_name, "build"))
+					continue;
+			}
+
+			ret = map_groups__set_modules_path_dir(mg, path,
+							       depth + 1);
 			if (ret < 0)
 				goto out;
 		} else {
@@ -786,11 +794,11 @@ static int machine__set_modules_path(struct machine *machine)
 	if (!version)
 		return -1;
 
-	snprintf(modules_path, sizeof(modules_path), "%s/lib/modules/%s/kernel",
+	snprintf(modules_path, sizeof(modules_path), "%s/lib/modules/%s",
 		 machine->root_dir, version);
 	free(version);
 
-	return map_groups__set_modules_path_dir(&machine->kmaps, modules_path);
+	return map_groups__set_modules_path_dir(&machine->kmaps, modules_path, 0);
 }
 
 static int machine__create_module(void *arg, const char *name, u64 start)

commit cddcef607782966f1601808c17fe9c4c5f79f9f4
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Wed Apr 9 20:54:29 2014 +0200

    perf tools: Share map_groups among threads of the same group
    
    Sharing map groups within all process threads. This way
    there's only one copy of mmap info and it's reachable
    from any thread within the process.
    
    Original-patch-by: Arnaldo Carvalho de Melo <acme@kernel.org>
    Acked-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1397490723-1992-5-git-send-email-jolsa@redhat.com
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index a53cd0b8c151..98ec56dc890b 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -316,6 +316,17 @@ static struct thread *__machine__findnew_thread(struct machine *machine,
 		rb_link_node(&th->rb_node, parent, p);
 		rb_insert_color(&th->rb_node, &machine->threads);
 		machine->last_match = th;
+
+		/*
+		 * We have to initialize map_groups separately
+		 * after rb tree is updated.
+		 *
+		 * The reason is that we call machine__findnew_thread
+		 * within thread__init_map_groups to find the thread
+		 * leader and that would screwed the rb tree.
+		 */
+		if (thread__init_map_groups(th, machine))
+			return NULL;
 	}
 
 	return th;

commit 11c9abf2270793bd1c1b8828edb4223f8010e56c
Author: Don Zickus <dzickus@redhat.com>
Date:   Wed Feb 26 10:45:27 2014 -0500

    perf tools: Use tid in mmap/mmap2 events to find maps
    
    Now that we can properly synthesize threads system-wide, make sure the
    mmap and mmap2 events use tids instead of pids to locate their maps.
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1393429527-167840-3-git-send-email-dzickus@redhat.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index d280bf210183..a53cd0b8c151 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1027,7 +1027,7 @@ int machine__process_mmap2_event(struct machine *machine,
 	}
 
 	thread = machine__findnew_thread(machine, event->mmap2.pid,
-					event->mmap2.pid);
+					event->mmap2.tid);
 	if (thread == NULL)
 		goto out_problem;
 
@@ -1075,7 +1075,7 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 	}
 
 	thread = machine__findnew_thread(machine, event->mmap.pid,
-					 event->mmap.pid);
+					 event->mmap.tid);
 	if (thread == NULL)
 		goto out_problem;
 

commit b3cef7f60f17d953545f7069f6407fc24202a64d
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Mon Mar 17 16:59:21 2014 -0300

    perf symbols: Record the reason for filtering an address_location
    
    By turning the addr_location->filtered member from a boolean to a u8
    bitmap, reusing (and extending) the hist_filter enum for that.
    
    This patch doesn't change the logic at all, as it keeps the meaning of
    al->filtered !0 to mean that the entry _was_ filtered, so no change in
    how this value is interpreted needs to be done at this point.
    
    This will be soon used in upcoming patches.
    
    Signed-off-by: Namhyung Kim <namhyung.kim@lge.com>
    Acked-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/n/tip-89hmfgtr9t22sky1lyg7nw7l@git.kernel.org
    [ yanked this out of a previous patch ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 5cecd98c1bc0..d280bf210183 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1312,7 +1312,7 @@ static int machine__resolve_callchain_sample(struct machine *machine,
 			continue;
 		}
 
-		al.filtered = false;
+		al.filtered = 0;
 		thread__find_addr_location(thread, machine, cpumode,
 					   MAP__FUNCTION, ip, &al);
 		if (al.sym != NULL) {

commit d75e6097ef1f7669deb500fbbdf53cfe524f1b53
Author: Jiri Olsa <jolsa@redhat.com>
Date:   Fri Mar 14 15:00:03 2014 +0100

    perf machine: Factor machine__find_thread to take tid argument
    
    Forcing the code to always search thread by pid/tid pair.
    
    The PID value will be needed in future to determine the process thread
    leader for map groups sharing.
    
    Signed-off-by: Jiri Olsa <jolsa@redhat.com>
    Acked-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1394805606-25883-3-git-send-email-jolsa@redhat.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index a6799538069c..5cecd98c1bc0 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -327,9 +327,10 @@ struct thread *machine__findnew_thread(struct machine *machine, pid_t pid,
 	return __machine__findnew_thread(machine, pid, tid, true);
 }
 
-struct thread *machine__find_thread(struct machine *machine, pid_t tid)
+struct thread *machine__find_thread(struct machine *machine, pid_t pid,
+				    pid_t tid)
 {
-	return __machine__findnew_thread(machine, 0, tid, false);
+	return __machine__findnew_thread(machine, pid, tid, false);
 }
 
 int machine__process_comm_event(struct machine *machine, union perf_event *event,
@@ -1114,7 +1115,9 @@ static void machine__remove_thread(struct machine *machine, struct thread *th)
 int machine__process_fork_event(struct machine *machine, union perf_event *event,
 				struct perf_sample *sample)
 {
-	struct thread *thread = machine__find_thread(machine, event->fork.tid);
+	struct thread *thread = machine__find_thread(machine,
+						     event->fork.pid,
+						     event->fork.tid);
 	struct thread *parent = machine__findnew_thread(machine,
 							event->fork.ppid,
 							event->fork.ptid);
@@ -1140,7 +1143,9 @@ int machine__process_fork_event(struct machine *machine, union perf_event *event
 int machine__process_exit_event(struct machine *machine, union perf_event *event,
 				struct perf_sample *sample __maybe_unused)
 {
-	struct thread *thread = machine__find_thread(machine, event->fork.tid);
+	struct thread *thread = machine__find_thread(machine,
+						     event->fork.pid,
+						     event->fork.tid);
 
 	if (dump_trace)
 		perf_event__fprintf_task(event, stdout);

commit 52a3cb8cfca16db73cf825cb94325cf54da8304f
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Mar 11 16:16:49 2014 -0300

    perf symbols: Introduce thread__find_cpumode_addr_location
    
    Its one level up thread__find_addr_location, where it will look in
    different domains for a sample: user, kernel, hypervisor, etc.
    
    Will soon be used by a patchkit by Andi Kleen.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-so6nxkh7xj48bc5kq4jpj991@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 813e94e7cf29..a6799538069c 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1184,39 +1184,22 @@ static bool symbol__match_regex(struct symbol *sym, regex_t *regex)
 	return 0;
 }
 
-static const u8 cpumodes[] = {
-	PERF_RECORD_MISC_USER,
-	PERF_RECORD_MISC_KERNEL,
-	PERF_RECORD_MISC_GUEST_USER,
-	PERF_RECORD_MISC_GUEST_KERNEL
-};
-#define NCPUMODES (sizeof(cpumodes)/sizeof(u8))
-
 static void ip__resolve_ams(struct machine *machine, struct thread *thread,
 			    struct addr_map_symbol *ams,
 			    u64 ip)
 {
 	struct addr_location al;
-	size_t i;
-	u8 m;
 
 	memset(&al, 0, sizeof(al));
+	/*
+	 * We cannot use the header.misc hint to determine whether a
+	 * branch stack address is user, kernel, guest, hypervisor.
+	 * Branches may straddle the kernel/user/hypervisor boundaries.
+	 * Thus, we have to try consecutively until we find a match
+	 * or else, the symbol is unknown
+	 */
+	thread__find_cpumode_addr_location(thread, machine, MAP__FUNCTION, ip, &al);
 
-	for (i = 0; i < NCPUMODES; i++) {
-		m = cpumodes[i];
-		/*
-		 * We cannot use the header.misc hint to determine whether a
-		 * branch stack address is user, kernel, guest, hypervisor.
-		 * Branches may straddle the kernel/user/hypervisor boundaries.
-		 * Thus, we have to try consecutively until we find a match
-		 * or else, the symbol is unknown
-		 */
-		thread__find_addr_location(thread, machine, m, MAP__FUNCTION,
-				ip, &al);
-		if (al.map)
-			goto found;
-	}
-found:
 	ams->addr = ip;
 	ams->al_addr = al.addr;
 	ams->sym = al.sym;

commit 0066f3b93e144762b409940fa37bb1cd36c1baf7
Merge: e65312fe868d b8ad0f912b93
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Mar 11 11:53:50 2014 +0100

    Merge branch 'perf/urgent' into perf/core
    
    Merge the latest fixes.
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit fdf57dd052d5cbd415533ae98f4d423286a85220
Author: Don Zickus <dzickus@redhat.com>
Date:   Tue Feb 25 22:43:45 2014 -0500

    perf machine: Use map as success in ip__resolve_ams
    
    When trying to map a bunch of instruction addresses to their respective
    threads, I kept getting a lot of bogus entries [I forget the exact
    reason as I patched my code months ago].
    
    Looking through ip__resolve_ams, I noticed the check for
    
      if (al.sym)
    
    and realized, most times I have an al.map definition but sometimes an
    al.sym is undefined.  In the cases where al.sym is undefined, the loop
    keeps going even though a valid al.map exists.
    
    Modify this check to use the more reliable al.map.  This fixed my bogus
    entries.
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1393386227-149412-2-git-send-email-dzickus@redhat.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index c872991e0f65..620a1983b76b 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1213,7 +1213,7 @@ static void ip__resolve_ams(struct machine *machine, struct thread *thread,
 		 */
 		thread__find_addr_location(thread, machine, m, MAP__FUNCTION,
 				ip, &al);
-		if (al.sym)
+		if (al.map)
 			goto found;
 	}
 found:

commit 352ea45a7229df8f5ae83c0757f6d426ba0f41b5
Author: Jiri Olsa <jolsa@redhat.com>
Date:   Tue Jan 7 13:47:25 2014 +0100

    perf callchain: Add mask into struct regs_dump
    
    Adding mask info into struct regs_dump to make the registers information
    compact.
    
    The mask was always passed along, so logically the mask info fits more
    into the struct regs_dump.
    
    Signed-off-by: Jiri Olsa <jolsa@redhat.com>
    Acked-by: Jean Pihet <jean.pihet@linaro.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jean Pihet <jean.pihet@linaro.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1389098853-14466-9-git-send-email-jolsa@redhat.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 6c08ab03a697..ac37d788b5cb 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1383,8 +1383,7 @@ int machine__resolve_callchain(struct machine *machine,
 		return 0;
 
 	return unwind__get_entries(unwind_entry, &callchain_cursor, machine,
-				   thread, evsel->attr.sample_regs_user,
-				   sample, max_stack);
+				   thread, sample, max_stack);
 
 }
 

commit 644f2df29faf66f408fea2e50f16d3b5302403da
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Jan 22 13:15:36 2014 -0300

    perf tools: Shorten sample symbol resolving function signature
    
    Since two of the parameters come from the same 'struct
    addr_location', rename machine__resolve_bstack() to sample__resolve_bstack()
    and pass the that addr_location instead.
    
    This is also for consistency with the same change that resulted in the
    sample__resolve_mem() function.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-99ecqt8jiyyksiyx3se7l5ia@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 0d304d84afb4..6c08ab03a697 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1254,20 +1254,19 @@ struct mem_info *sample__resolve_mem(struct perf_sample *sample,
 	return mi;
 }
 
-struct branch_info *machine__resolve_bstack(struct machine *machine,
-					    struct thread *thr,
-					    struct branch_stack *bs)
+struct branch_info *sample__resolve_bstack(struct perf_sample *sample,
+					   struct addr_location *al)
 {
-	struct branch_info *bi;
 	unsigned int i;
+	const struct branch_stack *bs = sample->branch_stack;
+	struct branch_info *bi = calloc(bs->nr, sizeof(struct branch_info));
 
-	bi = calloc(bs->nr, sizeof(struct branch_info));
 	if (!bi)
 		return NULL;
 
 	for (i = 0; i < bs->nr; i++) {
-		ip__resolve_ams(machine, thr, &bi[i].to, bs->entries[i].to);
-		ip__resolve_ams(machine, thr, &bi[i].from, bs->entries[i].from);
+		ip__resolve_ams(al->machine, al->thread, &bi[i].to, bs->entries[i].to);
+		ip__resolve_ams(al->machine, al->thread, &bi[i].from, bs->entries[i].from);
 		bi[i].flags = bs->entries[i].flags;
 	}
 	return bi;

commit e80faac0460f178a5be576b4260897f997109e73
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Jan 22 13:05:06 2014 -0300

    perf tools: Shorten sample symbol resolving function signature
    
    Since three of the parameters come from the same 'struct addr_location',
    rename machine__resolve_mem() to sample__resolve_mem() and pass the
    that addr_location instead.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-3f5otpssefh9l5hi1t259h8n@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index c872991e0f65..0d304d84afb4 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1238,18 +1238,17 @@ static void ip__resolve_data(struct machine *machine, struct thread *thread,
 	ams->map = al.map;
 }
 
-struct mem_info *machine__resolve_mem(struct machine *machine,
-				      struct thread *thr,
-				      struct perf_sample *sample,
-				      u8 cpumode)
+struct mem_info *sample__resolve_mem(struct perf_sample *sample,
+				     struct addr_location *al)
 {
 	struct mem_info *mi = zalloc(sizeof(*mi));
 
 	if (!mi)
 		return NULL;
 
-	ip__resolve_ams(machine, thr, &mi->iaddr, sample->ip);
-	ip__resolve_data(machine, thr, cpumode, &mi->daddr, sample->addr);
+	ip__resolve_ams(al->machine, al->thread, &mi->iaddr, sample->ip);
+	ip__resolve_data(al->machine, al->thread, al->cpumode,
+			 &mi->daddr, sample->addr);
 	mi->data_src.val = sample->data_src;
 
 	return mi;

commit 5512cf24bed2de56f1ef44b6cc9a0a9b15499cea
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Wed Jan 29 16:14:39 2014 +0200

    perf machine: Set up ref_reloc_sym in machine__create_kernel_maps()
    
    The ref_reloc_sym is always needed for the kernel map in order to check
    for relocation.  Consequently set it up when the kernel map is created.
    Otherwise it was only being set up by 'perf record'.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Tested-by: Jiri Olsa <jolsa@redhat.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1391004884-10334-5-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 290c2e6d4001..c872991e0f65 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -832,9 +832,25 @@ static int machine__create_modules(struct machine *machine)
 	return 0;
 }
 
+const char *ref_reloc_sym_names[] = {"_text", "_stext", NULL};
+
 int machine__create_kernel_maps(struct machine *machine)
 {
 	struct dso *kernel = machine__get_kernel(machine);
+	char filename[PATH_MAX];
+	const char *name;
+	u64 addr = 0;
+	int i;
+
+	machine__get_kallsyms_filename(machine, filename, PATH_MAX);
+
+	for (i = 0; (name = ref_reloc_sym_names[i]) != NULL; i++) {
+		addr = kallsyms__get_function_start(filename, name);
+		if (addr)
+			break;
+	}
+	if (!addr)
+		return -1;
 
 	if (kernel == NULL ||
 	    __machine__create_kernel_maps(machine, kernel) < 0)
@@ -853,6 +869,13 @@ int machine__create_kernel_maps(struct machine *machine)
 	 * Now that we have all the maps created, just set the ->end of them:
 	 */
 	map_groups__fixup_end(&machine->kmaps);
+
+	if (maps__set_kallsyms_ref_reloc_sym(machine->vmlinux_maps, name,
+					     addr)) {
+		machine__destroy_kernel_maps(machine);
+		return -1;
+	}
+
 	return 0;
 }
 

commit 15a0a8706c32bd38bff9ebf7c6ef24f32d1ea921
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Wed Jan 29 16:14:38 2014 +0200

    perf machine: Add machine__get_kallsyms_filename()
    
    Separate out the logic used to make the kallsyms full path name for a
    machine.  It will be reused in a subsequent patch.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Tested-by: Jiri Olsa <jolsa@redhat.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1391004884-10334-4-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index ded74590b92f..290c2e6d4001 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -496,19 +496,22 @@ static int symbol__in_kernel(void *arg, const char *name,
 	return 1;
 }
 
+static void machine__get_kallsyms_filename(struct machine *machine, char *buf,
+					   size_t bufsz)
+{
+	if (machine__is_default_guest(machine))
+		scnprintf(buf, bufsz, "%s", symbol_conf.default_guest_kallsyms);
+	else
+		scnprintf(buf, bufsz, "%s/proc/kallsyms", machine->root_dir);
+}
+
 /* Figure out the start address of kernel map from /proc/kallsyms */
 static u64 machine__get_kernel_start_addr(struct machine *machine)
 {
-	const char *filename;
-	char path[PATH_MAX];
+	char filename[PATH_MAX];
 	struct process_args args;
 
-	if (machine__is_default_guest(machine))
-		filename = (char *)symbol_conf.default_guest_kallsyms;
-	else {
-		sprintf(path, "%s/proc/kallsyms", machine->root_dir);
-		filename = path;
-	}
+	machine__get_kallsyms_filename(machine, filename, PATH_MAX);
 
 	if (symbol__restricted_filename(filename, "/proc/kallsyms"))
 		return 0;

commit 540476de74c9b11403656791838ede91405d3859
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Tue Jan 14 14:25:34 2014 +0900

    perf tools: Remove symbol_conf.use_callchain check
    
    The machine__resolve_callchain() is called only if symbol_conf.
    use_callchain is set so no need to check it again.
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Rodrigo Campos <rodrigo@sdfg.com.ar>
    Link: http://lkml.kernel.org/r/1389677157-30513-2-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 0130279aac51..ded74590b92f 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1314,8 +1314,6 @@ static int machine__resolve_callchain_sample(struct machine *machine,
 				*root_al = al;
 				callchain_cursor_reset(&callchain_cursor);
 			}
-			if (!symbol_conf.use_callchain)
-				break;
 		}
 
 		err = callchain_cursor_append(&callchain_cursor,

commit 14bd6d20fef603060474701967085442b716b6a9
Author: Jiri Olsa <jolsa@redhat.com>
Date:   Tue Jan 7 13:47:19 2014 +0100

    perf machine: Fix id_hdr_size initialization
    
    The id_hdr_size field was not properly initialized, set it to zero, as
    the machine struct may have come from some non zeroing allocation
    routine or from the stack without any field being initialized.
    
    Signed-off-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jean Pihet <jean.pihet@linaro.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1389098853-14466-3-git-send-email-jolsa@redhat.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index a98538dc465a..0130279aac51 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -27,6 +27,7 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 	machine->pid = pid;
 
 	machine->symbol_filter = NULL;
+	machine->id_hdr_size = 0;
 
 	machine->root_dir = strdup(root_dir);
 	if (machine->root_dir == NULL)

commit 046625231a0397f1776eb353a4ec9ff142cd2f6b
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Dec 26 17:41:15 2013 -0300

    perf tools: Introduce zfree
    
    For the frequent idiom of:
    
       free(ptr);
       ptr = NULL;
    
    Make it expect a pointer to the pointer being freed, so that it becomes
    clear at first sight that the variable being freed is being modified.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-pfw02ezuab37kha18wlut7ir@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index c78cc84f433e..a98538dc465a 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -102,8 +102,7 @@ void machine__exit(struct machine *machine)
 	map_groups__exit(&machine->kmaps);
 	dsos__delete(&machine->user_dsos);
 	dsos__delete(&machine->kernel_dsos);
-	free(machine->root_dir);
-	machine->root_dir = NULL;
+	zfree(&machine->root_dir);
 }
 
 void machine__delete(struct machine *machine)
@@ -562,11 +561,10 @@ void machine__destroy_kernel_maps(struct machine *machine)
 			 * on one of them.
 			 */
 			if (type == MAP__FUNCTION) {
-				free((char *)kmap->ref_reloc_sym->name);
-				kmap->ref_reloc_sym->name = NULL;
-				free(kmap->ref_reloc_sym);
-			}
-			kmap->ref_reloc_sym = NULL;
+				zfree((char **)&kmap->ref_reloc_sym->name);
+				zfree(&kmap->ref_reloc_sym);
+			} else
+				kmap->ref_reloc_sym = NULL;
 		}
 
 		map__delete(machine->vmlinux_maps[type]);

commit c506c96b61fa96c9a52ad4d25e895e45c1692650
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Dec 11 09:15:00 2013 -0300

    tools lib symbol: Start carving out symbol parsing routines from perf
    
    Eventually this should be useful to other tools/ living utilities.
    
    For now don't try to build any .a, just trying the minimal approach of
    separating existing code into multiple .c files that can then be
    included wherever they are needed, using whatever build machinery
    already in place.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-pfa8i5zpf4bf9rcccryi0lt3@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 751454bcde69..c78cc84f433e 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -9,6 +9,7 @@
 #include "strlist.h"
 #include "thread.h"
 #include <stdbool.h>
+#include <symbol/kallsyms.h>
 #include "unwind.h"
 
 int machine__init(struct machine *machine, const char *root_dir, pid_t pid)

commit 7e155d4d5e2912f75443c18c02dd6f1dbd4eef84
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Dec 10 15:08:44 2013 -0300

    perf symbols: Remove open coded management of  long_name_allocated member
    
    Instead of expecting callers to set this member accodingly so that later
    at dso destruction it can, if needed, be correctly free()d, make it a
    requirement by passing it as a parameter to dso__set_long_name.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-na7t1tqim22vuqkt4zq5n4ri@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 09d5c66d4087..751454bcde69 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -763,8 +763,7 @@ static int map_groups__set_modules_path_dir(struct map_groups *mg,
 				ret = -1;
 				goto out;
 			}
-			dso__set_long_name(map->dso, long_name);
-			map->dso->long_name_allocated = 1;
+			dso__set_long_name(map->dso, long_name, true);
 			dso__kernel_module_get_build_id(map->dso, "");
 		}
 	}

commit 58a98c9cc583435784a93f23754128363b4cca94
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Tue Dec 10 11:11:46 2013 -0300

    perf symbols: Remove open coded management of  short_name_allocated member
    
    Instead of expecting callers to set this member accodingly so that later
    at dso destruction it can, if needed, be correctly free()d, make it a
    requirement by passing it as a parameter to dso__set_short_name.
    
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Dongsheng Yang <yangds.fnst@cn.fujitsu.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    CC: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Link: http://lkml.kernel.org/r/52A707A2.5020802@intel.com
    [ Renamed the 'allocated' parameter to clearly indicate to which variable it refers to. ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index f85da9a9a5d9..09d5c66d4087 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -935,8 +935,7 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 		if (name == NULL)
 			goto out_problem;
 
-		dso__set_short_name(map->dso, name);
-		map->dso->short_name_allocated = 1;
+		dso__set_short_name(map->dso, name, true);
 		map->end = map->start + event->mmap.len;
 	} else if (is_kernel_mmap) {
 		const char *symbol_name = (event->mmap.filename +

commit 7521ab592550d9e6542a496bcea11b40900690da
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Dec 10 10:58:47 2013 -0300

    perf machine: Don't open code assign dso->short_name
    
    Use dso__set_short_name instead, as it will release any previously,
    possibly allocated, short name.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-1v39elw7v6nxczpntpp7ljwr@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index f66f309a091a..f85da9a9a5d9 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -935,7 +935,7 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 		if (name == NULL)
 			goto out_problem;
 
-		map->dso->short_name = name;
+		dso__set_short_name(map->dso, name);
 		map->dso->short_name_allocated = 1;
 		map->end = map->start + event->mmap.len;
 	} else if (is_kernel_mmap) {

commit c7282f2efff9f115378b450b7aea51210fabb6ef
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Dec 10 10:44:37 2013 -0300

    perf symbols: Rename [sl]name_alloc to match the members they refer to
    
    So we now have:
    
       dso->short_name
       dso->short_name_len
       dso->short_name_allocated
    
    Ditto for the 'long  variants. To more quickly grasp what they refer to.
    
    Suggested-by: Ingo Molnar <mingo@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-nu228f8vlp9w0lr7c0q77dqi@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index bac817ab2068..f66f309a091a 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -764,7 +764,7 @@ static int map_groups__set_modules_path_dir(struct map_groups *mg,
 				goto out;
 			}
 			dso__set_long_name(map->dso, long_name);
-			map->dso->lname_alloc = 1;
+			map->dso->long_name_allocated = 1;
 			dso__kernel_module_get_build_id(map->dso, "");
 		}
 	}
@@ -936,7 +936,7 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 			goto out_problem;
 
 		map->dso->short_name = name;
-		map->dso->sname_alloc = 1;
+		map->dso->short_name_allocated = 1;
 		map->end = map->start + event->mmap.len;
 	} else if (is_kernel_mmap) {
 		const char *symbol_name = (event->mmap.filename +

commit 2f37573507643407d0a8f38c676ed2e90b795db3
Author: Dongsheng Yang <yangds.fnst@cn.fujitsu.com>
Date:   Wed Dec 4 17:56:39 2013 -0500

    perf tools: Remove condition in machine__get_kernel_start_addr.
    
    In machine__get_kernel_start_addr, the code, which is using
    machine->root_dir to build filename, works for both host and guests
    initialized from guestmount, as root_dir is set to "" for the host
    machine in the machine__init() function.
    
    So this patch remove the branch for machine__is_host.
    
    Signed-off-by: Dongsheng Yang <yangds.fnst@cn.fujitsu.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/0a81645dd0b384a12cb4f962cf193ef8c3ce2010.1386197481.git.yangds.fnst@cn.fujitsu.com
    [ Clarified changeset mentioning root_dir setup in machine__init() ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 84cdb072ac83..bac817ab2068 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -502,15 +502,11 @@ static u64 machine__get_kernel_start_addr(struct machine *machine)
 	char path[PATH_MAX];
 	struct process_args args;
 
-	if (machine__is_host(machine)) {
-		filename = "/proc/kallsyms";
-	} else {
-		if (machine__is_default_guest(machine))
-			filename = (char *)symbol_conf.default_guest_kallsyms;
-		else {
-			sprintf(path, "%s/proc/kallsyms", machine->root_dir);
-			filename = path;
-		}
+	if (machine__is_default_guest(machine))
+		filename = (char *)symbol_conf.default_guest_kallsyms;
+	else {
+		sprintf(path, "%s/proc/kallsyms", machine->root_dir);
+		filename = path;
 	}
 
 	if (symbol__restricted_filename(filename, "/proc/kallsyms"))

commit 37676af15c8d5a9689c9d1220d2a27d510cbe238
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Nov 13 17:40:36 2013 -0300

    perf symbols: Limit max callchain using max_stack on DWARF unwinding too
    
    It was affecting only frame-pointer (fp) based callchain processing.
    
    Usage example:
    
      perf top --call-graph dwarf,1024 --max-stack 2
    
    Works for any tool that does callchain resolving and provides a
    --max-stack option.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Waiman Long <Waiman.Long@hp.com>
    Link: http://lkml.kernel.org/n/tip-eu45v8s3tq9ruay8tpfyon79@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 0393912d8033..84cdb072ac83 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1368,7 +1368,7 @@ int machine__resolve_callchain(struct machine *machine,
 
 	return unwind__get_entries(unwind_entry, &callchain_cursor, machine,
 				   thread, evsel->attr.sample_regs_user,
-				   sample);
+				   sample, max_stack);
 
 }
 

commit 602ad878d41ef097cc9aa2def7830d5bb27a15d8
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Nov 12 16:46:16 2013 -0300

    perf target: Shorten perf_target__ to target__
    
    Getting unwieldly long, for this app domain should be descriptive enough
    and the use of __ to separate the class from the method names should
    help with avoiding clashes with other code bases.
    
    Reported-by: David Ahern <dsahern@gmail.com>
    Suggested-by: Ingo Molnar <mingo@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/20131112113427.GA4053@ghostprotocols.net
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 680700b6d779..0393912d8033 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1396,12 +1396,12 @@ int machine__for_each_thread(struct machine *machine,
 }
 
 int __machine__synthesize_threads(struct machine *machine, struct perf_tool *tool,
-				  struct perf_target *target, struct thread_map *threads,
+				  struct target *target, struct thread_map *threads,
 				  perf_event__handler_t process, bool data_mmap)
 {
-	if (perf_target__has_task(target))
+	if (target__has_task(target))
 		return perf_event__synthesize_thread_map(tool, threads, process, machine, data_mmap);
-	else if (perf_target__has_cpu(target))
+	else if (target__has_cpu(target))
 		return perf_event__synthesize_threads(tool, process, machine, data_mmap);
 	/* command specified */
 	return 0;

commit a33fbd56ec83b5421090b4d8f2032f635e6a9488
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Nov 11 11:36:12 2013 -0300

    perf machine: Simplify synthesize_threads method
    
    Several tools (top, kvm) don't need to be called back to process each of
    the syntheiszed records, instead relying on the machine__process_event
    function to change the per machine data structures that represent
    threads and mmaps, so provide a way to ask for this common idiom.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-pusqibp8n3c4ynegd1frn4zd@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 9f2c61d5a9ed..680700b6d779 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1395,9 +1395,9 @@ int machine__for_each_thread(struct machine *machine,
 	return rc;
 }
 
-int machine__synthesize_threads(struct machine *machine, struct perf_tool *tool,
-				struct perf_target *target, struct thread_map *threads,
-				perf_event__handler_t process, bool data_mmap)
+int __machine__synthesize_threads(struct machine *machine, struct perf_tool *tool,
+				  struct perf_target *target, struct thread_map *threads,
+				  perf_event__handler_t process, bool data_mmap)
 {
 	if (perf_target__has_task(target))
 		return perf_event__synthesize_thread_map(tool, threads, process, machine, data_mmap);

commit 58d925dcede9e8765876707a33a3406011fe1c11
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Nov 11 11:28:02 2013 -0300

    perf machine: Introduce synthesize_threads method out of open coded equivalent
    
    Further simplifications to be done on following patch, as most tools
    don't use the callback, using instead just the canned
    machine__process_event one.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-r1m0vuuj3cat4bampno9yc8d@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index ce034c183a7e..9f2c61d5a9ed 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1394,3 +1394,15 @@ int machine__for_each_thread(struct machine *machine,
 	}
 	return rc;
 }
+
+int machine__synthesize_threads(struct machine *machine, struct perf_tool *tool,
+				struct perf_target *target, struct thread_map *threads,
+				perf_event__handler_t process, bool data_mmap)
+{
+	if (perf_target__has_task(target))
+		return perf_event__synthesize_thread_map(tool, threads, process, machine, data_mmap);
+	else if (perf_target__has_cpu(target))
+		return perf_event__synthesize_threads(tool, process, machine, data_mmap);
+	/* command specified */
+	return 0;
+}

commit 162f0befda3becc2cc9f44075fccc030e55baec1
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Wed Sep 11 16:18:24 2013 +0200

    perf tools: Add time argument on COMM setting
    
    This way we can later delimit a lifecycle for the COMM and map a hist to
    a precise COMM:timeslice couple.
    
    PERF_RECORD_COMM and PERF_RECORD_FORK events that don't have
    PERF_SAMPLE_TIME samples can only send 0 value as a timestamp and thus
    should overwrite any previous COMM on a given thread because there is no
    sensible way to keep track of all the comms lifecycles in a thread
    without time informations.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Tested-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-6tyow99vgmmtt9qwr2u2lqd7@git.kernel.org
    [ Made it cope with PERF_RECORD_MMAP2 ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index ea93425cce95..ce034c183a7e 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -40,7 +40,7 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 			return -ENOMEM;
 
 		snprintf(comm, sizeof(comm), "[guest/%d]", pid);
-		thread__set_comm(thread, comm);
+		thread__set_comm(thread, comm, 0);
 	}
 
 	return 0;
@@ -331,7 +331,8 @@ struct thread *machine__find_thread(struct machine *machine, pid_t tid)
 	return __machine__findnew_thread(machine, 0, tid, false);
 }
 
-int machine__process_comm_event(struct machine *machine, union perf_event *event)
+int machine__process_comm_event(struct machine *machine, union perf_event *event,
+				struct perf_sample *sample)
 {
 	struct thread *thread = machine__findnew_thread(machine,
 							event->comm.pid,
@@ -340,7 +341,7 @@ int machine__process_comm_event(struct machine *machine, union perf_event *event
 	if (dump_trace)
 		perf_event__fprintf_comm(event, stdout);
 
-	if (thread == NULL || thread__set_comm(thread, event->comm.comm)) {
+	if (thread == NULL || thread__set_comm(thread, event->comm.comm, sample->time)) {
 		dump_printf("problem processing PERF_RECORD_COMM, skipping event.\n");
 		return -1;
 	}
@@ -349,7 +350,7 @@ int machine__process_comm_event(struct machine *machine, union perf_event *event
 }
 
 int machine__process_lost_event(struct machine *machine __maybe_unused,
-				union perf_event *event)
+				union perf_event *event, struct perf_sample *sample __maybe_unused)
 {
 	dump_printf(": id:%" PRIu64 ": lost:%" PRIu64 "\n",
 		    event->lost.id, event->lost.lost);
@@ -984,7 +985,8 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 }
 
 int machine__process_mmap2_event(struct machine *machine,
-				 union perf_event *event)
+				 union perf_event *event,
+				 struct perf_sample *sample __maybe_unused)
 {
 	u8 cpumode = event->header.misc & PERF_RECORD_MISC_CPUMODE_MASK;
 	struct thread *thread;
@@ -1031,7 +1033,8 @@ int machine__process_mmap2_event(struct machine *machine,
 	return 0;
 }
 
-int machine__process_mmap_event(struct machine *machine, union perf_event *event)
+int machine__process_mmap_event(struct machine *machine, union perf_event *event,
+				struct perf_sample *sample __maybe_unused)
 {
 	u8 cpumode = event->header.misc & PERF_RECORD_MISC_CPUMODE_MASK;
 	struct thread *thread;
@@ -1088,7 +1091,8 @@ static void machine__remove_thread(struct machine *machine, struct thread *th)
 	list_add_tail(&th->node, &machine->dead_threads);
 }
 
-int machine__process_fork_event(struct machine *machine, union perf_event *event)
+int machine__process_fork_event(struct machine *machine, union perf_event *event,
+				struct perf_sample *sample)
 {
 	struct thread *thread = machine__find_thread(machine, event->fork.tid);
 	struct thread *parent = machine__findnew_thread(machine,
@@ -1105,7 +1109,7 @@ int machine__process_fork_event(struct machine *machine, union perf_event *event
 		perf_event__fprintf_task(event, stdout);
 
 	if (thread == NULL || parent == NULL ||
-	    thread__fork(thread, parent) < 0) {
+	    thread__fork(thread, parent, sample->time) < 0) {
 		dump_printf("problem processing PERF_RECORD_FORK, skipping event.\n");
 		return -1;
 	}
@@ -1113,8 +1117,8 @@ int machine__process_fork_event(struct machine *machine, union perf_event *event
 	return 0;
 }
 
-int machine__process_exit_event(struct machine *machine __maybe_unused,
-				union perf_event *event)
+int machine__process_exit_event(struct machine *machine, union perf_event *event,
+				struct perf_sample *sample __maybe_unused)
 {
 	struct thread *thread = machine__find_thread(machine, event->fork.tid);
 
@@ -1127,23 +1131,24 @@ int machine__process_exit_event(struct machine *machine __maybe_unused,
 	return 0;
 }
 
-int machine__process_event(struct machine *machine, union perf_event *event)
+int machine__process_event(struct machine *machine, union perf_event *event,
+			   struct perf_sample *sample)
 {
 	int ret;
 
 	switch (event->header.type) {
 	case PERF_RECORD_COMM:
-		ret = machine__process_comm_event(machine, event); break;
+		ret = machine__process_comm_event(machine, event, sample); break;
 	case PERF_RECORD_MMAP:
-		ret = machine__process_mmap_event(machine, event); break;
+		ret = machine__process_mmap_event(machine, event, sample); break;
 	case PERF_RECORD_MMAP2:
-		ret = machine__process_mmap2_event(machine, event); break;
+		ret = machine__process_mmap2_event(machine, event, sample); break;
 	case PERF_RECORD_FORK:
-		ret = machine__process_fork_event(machine, event); break;
+		ret = machine__process_fork_event(machine, event, sample); break;
 	case PERF_RECORD_EXIT:
-		ret = machine__process_exit_event(machine, event); break;
+		ret = machine__process_exit_event(machine, event, sample); break;
 	case PERF_RECORD_LOST:
-		ret = machine__process_lost_event(machine, event); break;
+		ret = machine__process_lost_event(machine, event, sample); break;
 	default:
 		ret = -1;
 		break;

commit 91e95617429cb272fd908b1928a1915b37b9655f
Author: Waiman Long <Waiman.Long@hp.com>
Date:   Fri Oct 18 10:38:48 2013 -0400

    perf report: Add --max-stack option to limit callchain stack scan
    
    When callgraph data was included in the perf data file, it may take a
    long time to scan all those data and merge them together especially if
    the stored callchains are long and the perf data file itself is large,
    like a Gbyte or so.
    
    The callchain stack is currently limited to PERF_MAX_STACK_DEPTH (127).
    This is a large value. Usually the callgraph data that developers are
    most interested in are the first few levels, the rests are usually not
    looked at.
    
    This patch adds a new --max-stack option to perf-report to limit the
    depth of callchain stack data to look at to reduce the time it takes for
    perf-report to finish its processing. It trades the presence of trailing
    stack information with faster speed.
    
    The following table shows the elapsed time of doing perf-report on a
    perf.data file of size 985,531,828 bytes.
    
      --max_stack   Elapsed Time    Output data size
      -----------   ------------    ----------------
      not set        88.0s          124,422,651
      64             87.5s          116,303,213
      32             87.2s          112,023,804
      16             86.6s           94,326,380
      8              59.9s           33,697,248
      4              40.7s           10,116,637
      -g none        27.1s            2,555,810
    
    Signed-off-by: Waiman Long <Waiman.Long@hp.com>
    Acked-by: David Ahern <dsahern@gmail.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Aswin Chandramouleeswaran <aswin@hp.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Scott J Norton <scott.norton@hp.com>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1382107129-2010-4-git-send-email-Waiman.Long@hp.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 6b861aefd99a..ea93425cce95 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1253,10 +1253,12 @@ static int machine__resolve_callchain_sample(struct machine *machine,
 					     struct thread *thread,
 					     struct ip_callchain *chain,
 					     struct symbol **parent,
-					     struct addr_location *root_al)
+					     struct addr_location *root_al,
+					     int max_stack)
 {
 	u8 cpumode = PERF_RECORD_MISC_USER;
-	unsigned int i;
+	int chain_nr = min(max_stack, (int)chain->nr);
+	int i;
 	int err;
 
 	callchain_cursor_reset(&callchain_cursor);
@@ -1266,7 +1268,7 @@ static int machine__resolve_callchain_sample(struct machine *machine,
 		return 0;
 	}
 
-	for (i = 0; i < chain->nr; i++) {
+	for (i = 0; i < chain_nr; i++) {
 		u64 ip;
 		struct addr_location al;
 
@@ -1338,12 +1340,14 @@ int machine__resolve_callchain(struct machine *machine,
 			       struct thread *thread,
 			       struct perf_sample *sample,
 			       struct symbol **parent,
-			       struct addr_location *root_al)
+			       struct addr_location *root_al,
+			       int max_stack)
 {
 	int ret;
 
 	ret = machine__resolve_callchain_sample(machine, thread,
-						sample->callchain, parent, root_al);
+						sample->callchain, parent,
+						root_al, max_stack);
 	if (ret)
 		return ret;
 

commit 316d70d6dbde540b275289563cbddd9f0c903fc6
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Tue Oct 8 11:45:48 2013 +0300

    perf symbols: Make a separate function to parse /proc/modules
    
    Make a separate function to parse /proc/modules so that it can be
    reused.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1381221956-16699-2-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 901397ae82be..6b861aefd99a 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -793,12 +793,22 @@ static int machine__set_modules_path(struct machine *machine)
 	return map_groups__set_modules_path_dir(&machine->kmaps, modules_path);
 }
 
-static int machine__create_modules(struct machine *machine)
+static int machine__create_module(void *arg, const char *name, u64 start)
 {
-	char *line = NULL;
-	size_t n;
-	FILE *file;
+	struct machine *machine = arg;
 	struct map *map;
+
+	map = machine__new_module(machine, start, name);
+	if (map == NULL)
+		return -1;
+
+	dso__kernel_module_get_build_id(map->dso, machine->root_dir);
+
+	return 0;
+}
+
+static int machine__create_modules(struct machine *machine)
+{
 	const char *modules;
 	char path[PATH_MAX];
 
@@ -812,56 +822,15 @@ static int machine__create_modules(struct machine *machine)
 	if (symbol__restricted_filename(modules, "/proc/modules"))
 		return -1;
 
-	file = fopen(modules, "r");
-	if (file == NULL)
+	if (modules__parse(modules, machine, machine__create_module))
 		return -1;
 
-	while (!feof(file)) {
-		char name[PATH_MAX];
-		u64 start;
-		char *sep;
-		int line_len;
-
-		line_len = getline(&line, &n, file);
-		if (line_len < 0)
-			break;
-
-		if (!line)
-			goto out_failure;
-
-		line[--line_len] = '\0'; /* \n */
-
-		sep = strrchr(line, 'x');
-		if (sep == NULL)
-			continue;
-
-		hex2u64(sep + 1, &start);
-
-		sep = strchr(line, ' ');
-		if (sep == NULL)
-			continue;
-
-		*sep = '\0';
-
-		snprintf(name, sizeof(name), "[%s]", line);
-		map = machine__new_module(machine, start, name);
-		if (map == NULL)
-			goto out_delete_line;
-		dso__kernel_module_get_build_id(map->dso, machine->root_dir);
-	}
+	if (!machine__set_modules_path(machine))
+		return 0;
 
-	free(line);
-	fclose(file);
+	pr_debug("Problems setting modules path maps, continuing anyway...\n");
 
-	if (machine__set_modules_path(machine) < 0) {
-		pr_debug("Problems setting modules path maps, continuing anyway...\n");
-	}
 	return 0;
-
-out_delete_line:
-	free(line);
-out_failure:
-	return -1;
 }
 
 int machine__create_kernel_maps(struct machine *machine)

commit 35feee19f9fda7447f51073b5be3f6d082b508f5
Author: David Ahern <dsahern@gmail.com>
Date:   Sat Sep 28 13:12:58 2013 -0600

    perf machine: Add method to loop over threads and invoke handler
    
    Loop over all threads within a machine - including threads moved to the
    dead threads list -- and invoked a function.
    
    This allows commands to run some specific function on each thread (eg.,
    dump statistics) yet hides how the threads are maintained within the
    machine.
    
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1380395584-9025-2-git-send-email-dsahern@gmail.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index fc14f9bf82c8..901397ae82be 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1393,3 +1393,26 @@ int machine__resolve_callchain(struct machine *machine,
 				   sample);
 
 }
+
+int machine__for_each_thread(struct machine *machine,
+			     int (*fn)(struct thread *thread, void *p),
+			     void *priv)
+{
+	struct rb_node *nd;
+	struct thread *thread;
+	int rc = 0;
+
+	for (nd = rb_first(&machine->threads); nd; nd = rb_next(nd)) {
+		thread = rb_entry(nd, struct thread, rb_node);
+		rc = fn(thread, priv);
+		if (rc != 0)
+			return rc;
+	}
+
+	list_for_each_entry(thread, &machine->dead_threads, node) {
+		rc = fn(thread, priv);
+		if (rc != 0)
+			return rc;
+	}
+	return rc;
+}

commit 8fb598e5a3b0ac213012e8461a309843ba0f2e74
Author: David Ahern <dsahern@gmail.com>
Date:   Sat Sep 28 13:13:00 2013 -0600

    perf trace: Fix comm resolution when reading events from file
    
    Task comm's are getting lost when processing events from a file. The
    problem is that the trace struct used by the live processing has its
    host machine and the perf-session used for file based processing has its
    host machine.  Fix by having both references point to the same machine.
    
    Before:
    
         0.030 ( 0.001 ms): :27743/27743 brk( ...
         0.057 ( 0.004 ms): :27743/27743 mmap(len: 4096, prot: READ|WRITE, flags: ...
         0.075 ( 0.006 ms): :27743/27743 access(filename: 0x7f3809fbce00, mode: R ...
         0.091 ( 0.005 ms): :27743/27743 open(filename: 0x7f3809fba14c, flags: CLOEXEC ...
    ...
    
    After:
         0.030 ( 0.001 ms): make/27743 brk( ...
         0.057 ( 0.004 ms): make/27743 mmap(len: 4096, prot: READ|WRITE, flags: ...
         0.075 ( 0.006 ms): make/27743 access(filename: 0x7f3809fbce00, mode: R ...
         0.091 ( 0.005 ms): make/27743 open(filename: 0x7f3809fba14c, flags: CLOEXEC ...
    ...
    
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1380395584-9025-4-git-send-email-dsahern@gmail.com
    [ Moved creation of new host machine to a separate constructor: machine__new_host() ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index ddf917b787fa..fc14f9bf82c8 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -46,6 +46,23 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 	return 0;
 }
 
+struct machine *machine__new_host(void)
+{
+	struct machine *machine = malloc(sizeof(*machine));
+
+	if (machine != NULL) {
+		machine__init(machine, "", HOST_KERNEL_ID);
+
+		if (machine__create_kernel_maps(machine) < 0)
+			goto out_delete;
+	}
+
+	return machine;
+out_delete:
+	free(machine);
+	return NULL;
+}
+
 static void dsos__delete(struct list_head *dsos)
 {
 	struct dso *pos, *n;

commit f4be904d2fa7c65e230ed4b1008ebdf5f4053ac3
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Sun Sep 22 13:22:09 2013 +0300

    perf machine: Use snprintf instead of sprintf
    
    To avoid buffer overruns.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1379845338-29637-2-git-send-email-adrian.hunter@intel.com
    [ Split from aa7fe3b ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 6188d2876a71..ddf917b787fa 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -785,10 +785,10 @@ static int machine__create_modules(struct machine *machine)
 	const char *modules;
 	char path[PATH_MAX];
 
-	if (machine__is_default_guest(machine))
+	if (machine__is_default_guest(machine)) {
 		modules = symbol_conf.default_guest_modules;
-	else {
-		sprintf(path, "%s/proc/modules", machine->root_dir);
+	} else {
+		snprintf(path, PATH_MAX, "%s/proc/modules", machine->root_dir);
 		modules = path;
 	}
 

commit aa7fe3b0c499fb7987245ac40295af03546f2bd2
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Sun Sep 22 13:22:09 2013 +0300

    perf machine: Fix path unpopulated in machine__create_modules()
    
    In machine__create_modules() the 'path' char array was used in a call to
    symbol__restricted_filename() without always being populated.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1379845338-29637-2-git-send-email-adrian.hunter@intel.com
    [ Split patch removing unrelated conversion of sprintf to snprintf to perf/core ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 933d14f287ca..6188d2876a71 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -792,7 +792,7 @@ static int machine__create_modules(struct machine *machine)
 		modules = path;
 	}
 
-	if (symbol__restricted_filename(path, "/proc/modules"))
+	if (symbol__restricted_filename(modules, "/proc/modules"))
 		return -1;
 
 	file = fopen(modules, "r");

commit 5c5e854bc760a2e2c878df3cfcf2afa4febcd511
Author: Stephane Eranian <eranian@google.com>
Date:   Wed Aug 21 12:10:25 2013 +0200

    perf tools: Add attr->mmap2 support
    
    This patch adds support for the new PERF_RECORD_MMAP2 record type
    exposed by the kernel. This is an extended PERF_RECORD_MMAP record.
    
    It adds for each file-backed mapping the device major, minor number and
    the inode number and generation.
    
    This triplet uniquely identifies the source of a file-backed mapping. It
    can be used to detect identical virtual mappings between processes, for
    instance.
    
    The patch will prefer MMAP2 over MMAP.
    
    Signed-off-by: Stephane Eranian <eranian@google.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1377079825-19057-3-git-send-email-eranian@google.com
    [ Cope with 314add6 "Change machine__findnew_thread() to set thread pid",
      fix 'perf test' regression test entry affected,
      use perf_missing_features.mmap2 to fallback to not using .mmap2 in older kernels,
      so that new tools can work with kernels where this feature is not present ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 1dca61f0512d..933d14f287ca 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -997,6 +997,54 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 	return -1;
 }
 
+int machine__process_mmap2_event(struct machine *machine,
+				 union perf_event *event)
+{
+	u8 cpumode = event->header.misc & PERF_RECORD_MISC_CPUMODE_MASK;
+	struct thread *thread;
+	struct map *map;
+	enum map_type type;
+	int ret = 0;
+
+	if (dump_trace)
+		perf_event__fprintf_mmap2(event, stdout);
+
+	if (cpumode == PERF_RECORD_MISC_GUEST_KERNEL ||
+	    cpumode == PERF_RECORD_MISC_KERNEL) {
+		ret = machine__process_kernel_mmap_event(machine, event);
+		if (ret < 0)
+			goto out_problem;
+		return 0;
+	}
+
+	thread = machine__findnew_thread(machine, event->mmap2.pid,
+					event->mmap2.pid);
+	if (thread == NULL)
+		goto out_problem;
+
+	if (event->header.misc & PERF_RECORD_MISC_MMAP_DATA)
+		type = MAP__VARIABLE;
+	else
+		type = MAP__FUNCTION;
+
+	map = map__new(&machine->user_dsos, event->mmap2.start,
+			event->mmap2.len, event->mmap2.pgoff,
+			event->mmap2.pid, event->mmap2.maj,
+			event->mmap2.min, event->mmap2.ino,
+			event->mmap2.ino_generation,
+			event->mmap2.filename, type);
+
+	if (map == NULL)
+		goto out_problem;
+
+	thread__insert_map(thread, map);
+	return 0;
+
+out_problem:
+	dump_printf("problem processing PERF_RECORD_MMAP2, skipping event.\n");
+	return 0;
+}
+
 int machine__process_mmap_event(struct machine *machine, union perf_event *event)
 {
 	u8 cpumode = event->header.misc & PERF_RECORD_MISC_CPUMODE_MASK;
@@ -1028,7 +1076,8 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 
 	map = map__new(&machine->user_dsos, event->mmap.start,
 			event->mmap.len, event->mmap.pgoff,
-			event->mmap.pid, event->mmap.filename,
+			event->mmap.pid, 0, 0, 0, 0,
+			event->mmap.filename,
 			type);
 
 	if (map == NULL)
@@ -1101,6 +1150,8 @@ int machine__process_event(struct machine *machine, union perf_event *event)
 		ret = machine__process_comm_event(machine, event); break;
 	case PERF_RECORD_MMAP:
 		ret = machine__process_mmap_event(machine, event); break;
+	case PERF_RECORD_MMAP2:
+		ret = machine__process_mmap2_event(machine, event); break;
 	case PERF_RECORD_FORK:
 		ret = machine__process_fork_event(machine, event); break;
 	case PERF_RECORD_EXIT:

commit 314add6b1f045b59ca39683bd0cbc5310cd203f2
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Tue Aug 27 11:23:03 2013 +0300

    perf tools: change machine__findnew_thread() to set thread pid
    
    Add a new parameter for 'pid' to machine__findnew_thread().
    Change callers to pass 'pid' when it is known.
    
    Note that callers sometimes want to find the main thread
    which has the memory maps.  The main thread has tid == pid
    so the usage in that case is:
    
            machine__findnew_thread(machine, pid, pid)
    
    whereas the usage to find the specific thread is:
    
            machine__findnew_thread(machine, pid, tid)
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Acked-by: David Ahern <dsahern@gmail.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1377591794-30553-2-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 59486c180626..1dca61f0512d 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -32,7 +32,8 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 		return -ENOMEM;
 
 	if (pid != HOST_KERNEL_ID) {
-		struct thread *thread = machine__findnew_thread(machine, pid);
+		struct thread *thread = machine__findnew_thread(machine, 0,
+								pid);
 		char comm[64];
 
 		if (thread == NULL)
@@ -302,9 +303,10 @@ static struct thread *__machine__findnew_thread(struct machine *machine,
 	return th;
 }
 
-struct thread *machine__findnew_thread(struct machine *machine, pid_t tid)
+struct thread *machine__findnew_thread(struct machine *machine, pid_t pid,
+				       pid_t tid)
 {
-	return __machine__findnew_thread(machine, 0, tid, true);
+	return __machine__findnew_thread(machine, pid, tid, true);
 }
 
 struct thread *machine__find_thread(struct machine *machine, pid_t tid)
@@ -314,7 +316,9 @@ struct thread *machine__find_thread(struct machine *machine, pid_t tid)
 
 int machine__process_comm_event(struct machine *machine, union perf_event *event)
 {
-	struct thread *thread = machine__findnew_thread(machine, event->comm.tid);
+	struct thread *thread = machine__findnew_thread(machine,
+							event->comm.pid,
+							event->comm.tid);
 
 	if (dump_trace)
 		perf_event__fprintf_comm(event, stdout);
@@ -1012,7 +1016,8 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 		return 0;
 	}
 
-	thread = machine__findnew_thread(machine, event->mmap.pid);
+	thread = machine__findnew_thread(machine, event->mmap.pid,
+					 event->mmap.pid);
 	if (thread == NULL)
 		goto out_problem;
 
@@ -1051,13 +1056,16 @@ static void machine__remove_thread(struct machine *machine, struct thread *th)
 int machine__process_fork_event(struct machine *machine, union perf_event *event)
 {
 	struct thread *thread = machine__find_thread(machine, event->fork.tid);
-	struct thread *parent = machine__findnew_thread(machine, event->fork.ptid);
+	struct thread *parent = machine__findnew_thread(machine,
+							event->fork.ppid,
+							event->fork.ptid);
 
 	/* if a thread currently exists for the thread id remove it */
 	if (thread != NULL)
 		machine__remove_thread(machine, thread);
 
-	thread = machine__findnew_thread(machine, event->fork.tid);
+	thread = machine__findnew_thread(machine, event->fork.pid,
+					 event->fork.tid);
 	if (dump_trace)
 		perf_event__fprintf_task(event, stdout);
 

commit 99d725fc65563a85d4290342c81b00a673c6be66
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Mon Aug 26 16:00:19 2013 +0300

    perf tools: Add pid to struct thread
    
    Record pid on struct thread.  The member is named 'pid_' to avoid
    confusion with the 'tid' member which was previously named 'pid'.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Acked-by: David Ahern <dsahern@gmail.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1377522030-27870-3-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 574feb7003ab..59486c180626 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -253,7 +253,8 @@ void machines__set_id_hdr_size(struct machines *machines, u16 id_hdr_size)
 	return;
 }
 
-static struct thread *__machine__findnew_thread(struct machine *machine, pid_t tid,
+static struct thread *__machine__findnew_thread(struct machine *machine,
+						pid_t pid, pid_t tid,
 						bool create)
 {
 	struct rb_node **p = &machine->threads.rb_node;
@@ -265,8 +266,11 @@ static struct thread *__machine__findnew_thread(struct machine *machine, pid_t t
 	 * so most of the time we dont have to look up
 	 * the full rbtree:
 	 */
-	if (machine->last_match && machine->last_match->tid == tid)
+	if (machine->last_match && machine->last_match->tid == tid) {
+		if (pid && pid != machine->last_match->pid_)
+			machine->last_match->pid_ = pid;
 		return machine->last_match;
+	}
 
 	while (*p != NULL) {
 		parent = *p;
@@ -274,6 +278,8 @@ static struct thread *__machine__findnew_thread(struct machine *machine, pid_t t
 
 		if (th->tid == tid) {
 			machine->last_match = th;
+			if (pid && pid != th->pid_)
+				th->pid_ = pid;
 			return th;
 		}
 
@@ -286,7 +292,7 @@ static struct thread *__machine__findnew_thread(struct machine *machine, pid_t t
 	if (!create)
 		return NULL;
 
-	th = thread__new(tid);
+	th = thread__new(pid, tid);
 	if (th != NULL) {
 		rb_link_node(&th->rb_node, parent, p);
 		rb_insert_color(&th->rb_node, &machine->threads);
@@ -298,12 +304,12 @@ static struct thread *__machine__findnew_thread(struct machine *machine, pid_t t
 
 struct thread *machine__findnew_thread(struct machine *machine, pid_t tid)
 {
-	return __machine__findnew_thread(machine, tid, true);
+	return __machine__findnew_thread(machine, 0, tid, true);
 }
 
 struct thread *machine__find_thread(struct machine *machine, pid_t tid)
 {
-	return __machine__findnew_thread(machine, tid, false);
+	return __machine__findnew_thread(machine, 0, tid, false);
 }
 
 int machine__process_comm_event(struct machine *machine, union perf_event *event)

commit 236a3bbd5cb51edbf9550f5a7df885665d18a271
Author: David Ahern <dsahern@gmail.com>
Date:   Wed Aug 14 08:49:27 2013 -0600

    perf tools: Sample after exit loses thread correlation
    
    Occassionally events (e.g., context-switch, sched tracepoints) are losing
    the conversion of sample data associated with a thread. For example:
    
    $ perf record -e sched:sched_switch -c 1 -a -- sleep 5
    $ perf script
    <selected events shown>
        ls 30482 [000] 1379727.583037: sched:sched_switch: prev_comm=ls prev_pid=30482 ...
        ls 30482 [000] 1379727.586339: sched:sched_switch: prev_comm=ls prev_pid=30482 ...
    :30482 30482 [000] 1379727.589462: sched:sched_switch: prev_comm=ls prev_pid=30482 ...
    
    The last line lost the conversion from tid to comm. If you look at the events
    (perf script -D) you see why - a SAMPLE event is generated after the EXIT:
    
    0 1379727589449774 0x1540b0 [0x38]: PERF_RECORD_EXIT(30482:30482):(30482:30482)
    0 1379727589462497 0x1540e8 [0x80]: PERF_RECORD_SAMPLE(IP, 1): 30482/30482: 0xffffffff816416f1 period: 1 addr: 0
    ... thread: :30482:30482
    
    When perf processes the EXIT event the thread is moved to the dead_threads
    list. When the SAMPLE event is processed no thread exists for the pid so a new
    one is created by machine__findnew_thread.
    
    This patch address the problem by delaying the move to the dead_threads list
    until the tid is re-used (per Adrian's suggestion).
    
    With this patch we get the previous example shows:
    
      ls 30482 [000] 1379727.583037: sched:sched_switch: prev_comm=ls prev_pid=30482 ...
      ls 30482 [000] 1379727.586339: sched:sched_switch: prev_comm=ls prev_pid=30482 ...
      ls 30482 [000] 1379727.589462: sched:sched_switch: prev_comm=ls prev_pid=30482 ...
    
    and
    
      0 1379727589449774 0x1540b0 [0x38]: PERF_RECORD_EXIT(30482:30482):(30482:30482)
      0 1379727589462497 0x1540e8 [0x80]: PERF_RECORD_SAMPLE(IP, 1): 30482/30482: 0xffffffff816416f1 period: 1 addr: 0
      ... thread: ls:30482
    
    v4: per Arnaldo's request add dead flag to thread struct and set when task exits
    
    v3: re-do from a time based check to a delayed move to dead_threads list
    
    v2: Rebased to latest perf/core branch. Changed time comparison to use
        a macro which explicitly shows the time basis
    
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Acked-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1376491767-84171-1-git-send-email-dsahern@gmail.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 4514e7e9b659..574feb7003ab 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1031,11 +1031,27 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 	return 0;
 }
 
+static void machine__remove_thread(struct machine *machine, struct thread *th)
+{
+	machine->last_match = NULL;
+	rb_erase(&th->rb_node, &machine->threads);
+	/*
+	 * We may have references to this thread, for instance in some hist_entry
+	 * instances, so just move them to a separate list.
+	 */
+	list_add_tail(&th->node, &machine->dead_threads);
+}
+
 int machine__process_fork_event(struct machine *machine, union perf_event *event)
 {
-	struct thread *thread = machine__findnew_thread(machine, event->fork.tid);
+	struct thread *thread = machine__find_thread(machine, event->fork.tid);
 	struct thread *parent = machine__findnew_thread(machine, event->fork.ptid);
 
+	/* if a thread currently exists for the thread id remove it */
+	if (thread != NULL)
+		machine__remove_thread(machine, thread);
+
+	thread = machine__findnew_thread(machine, event->fork.tid);
 	if (dump_trace)
 		perf_event__fprintf_task(event, stdout);
 
@@ -1048,18 +1064,8 @@ int machine__process_fork_event(struct machine *machine, union perf_event *event
 	return 0;
 }
 
-static void machine__remove_thread(struct machine *machine, struct thread *th)
-{
-	machine->last_match = NULL;
-	rb_erase(&th->rb_node, &machine->threads);
-	/*
-	 * We may have references to this thread, for instance in some hist_entry
-	 * instances, so just move them to a separate list.
-	 */
-	list_add_tail(&th->node, &machine->dead_threads);
-}
-
-int machine__process_exit_event(struct machine *machine, union perf_event *event)
+int machine__process_exit_event(struct machine *machine __maybe_unused,
+				union perf_event *event)
 {
 	struct thread *thread = machine__find_thread(machine, event->fork.tid);
 
@@ -1067,7 +1073,7 @@ int machine__process_exit_event(struct machine *machine, union perf_event *event
 		perf_event__fprintf_task(event, stdout);
 
 	if (thread != NULL)
-		machine__remove_thread(machine, thread);
+		thread__exited(thread);
 
 	return 0;
 }

commit 61710bdee324aab1c148c8573ee49cea59d05874
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Thu Aug 8 14:32:26 2013 +0300

    perf tools: Remove filter parameter of thread__find_addr_location()
    
    Now that the symbol filter is recorded on the machine there is no need
    to pass it to thread__find_addr_location().  So remove it.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1375961547-30267-8-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 4c7e0a28bf3d..4514e7e9b659 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1130,7 +1130,7 @@ static void ip__resolve_ams(struct machine *machine, struct thread *thread,
 		 * or else, the symbol is unknown
 		 */
 		thread__find_addr_location(thread, machine, m, MAP__FUNCTION,
-				ip, &al, NULL);
+				ip, &al);
 		if (al.sym)
 			goto found;
 	}
@@ -1148,8 +1148,8 @@ static void ip__resolve_data(struct machine *machine, struct thread *thread,
 
 	memset(&al, 0, sizeof(al));
 
-	thread__find_addr_location(thread, machine, m, MAP__VARIABLE, addr, &al,
-				   NULL);
+	thread__find_addr_location(thread, machine, m, MAP__VARIABLE, addr,
+				   &al);
 	ams->addr = addr;
 	ams->al_addr = al.addr;
 	ams->sym = al.sym;
@@ -1244,7 +1244,7 @@ static int machine__resolve_callchain_sample(struct machine *machine,
 
 		al.filtered = false;
 		thread__find_addr_location(thread, machine, cpumode,
-					   MAP__FUNCTION, ip, &al, NULL);
+					   MAP__FUNCTION, ip, &al);
 		if (al.sym != NULL) {
 			if (sort__has_parent && !*parent &&
 			    symbol__match_regex(al.sym, &parent_regex))

commit 611a5ce8aa4cdb2daefbd9bed77ec3b3e9bd00ea
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Thu Aug 8 14:32:20 2013 +0300

    perf machine: Add symbol filter to struct machine
    
    The symbol filter needs to be applied machine-wide, so add it to struct
    machine.
    
    Currently tools pass the symbol filter as a parameter to various
    map-related functions.  However a need to load a map can occur anywhere
    in the code, at which point the filter is needed.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1375961547-30267-2-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 6fcc358138ae..4c7e0a28bf3d 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -25,6 +25,8 @@ int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 	machine->kmaps.machine = machine;
 	machine->pid = pid;
 
+	machine->symbol_filter = NULL;
+
 	machine->root_dir = strdup(root_dir);
 	if (machine->root_dir == NULL)
 		return -ENOMEM;
@@ -95,6 +97,7 @@ void machines__init(struct machines *machines)
 {
 	machine__init(&machines->host, "", HOST_KERNEL_ID);
 	machines->guests = RB_ROOT;
+	machines->symbol_filter = NULL;
 }
 
 void machines__exit(struct machines *machines)
@@ -118,6 +121,8 @@ struct machine *machines__add(struct machines *machines, pid_t pid,
 		return NULL;
 	}
 
+	machine->symbol_filter = machines->symbol_filter;
+
 	while (*p != NULL) {
 		parent = *p;
 		pos = rb_entry(parent, struct machine, rb_node);
@@ -133,6 +138,21 @@ struct machine *machines__add(struct machines *machines, pid_t pid,
 	return machine;
 }
 
+void machines__set_symbol_filter(struct machines *machines,
+				 symbol_filter_t symbol_filter)
+{
+	struct rb_node *nd;
+
+	machines->symbol_filter = symbol_filter;
+	machines->host.symbol_filter = symbol_filter;
+
+	for (nd = rb_first(&machines->guests); nd; nd = rb_next(nd)) {
+		struct machine *machine = rb_entry(nd, struct machine, rb_node);
+
+		machine->symbol_filter = symbol_filter;
+	}
+}
+
 struct machine *machines__find(struct machines *machines, pid_t pid)
 {
 	struct rb_node **p = &machines->guests.rb_node;

commit 8f76fcd902e3b3a7d6f6c695cc8bc053579eb179
Author: Jason Wessel <jason.wessel@windriver.com>
Date:   Mon Jul 15 15:27:53 2013 -0500

    perf machine: Do not require /lib/modules/* on a guest
    
    For some types of work loads and special guest environments, you might
    have a kernel that has no kernel modules.  The perf kvm record tool
    fails instantiate vmlinux maps when the kernel modules directory cannot
    be opened, even though the kallsyms has been properly processed.  This
    leads to a perf kvm report that has no guest symbols resolved.
    
    This patch changes the failure to locate kernel modules to be non-fatal.
    
    Signed-off-by: Jason Wessel <jason.wessel@windriver.com>
    Acked-by: David Ahern <dsahern@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1373920073-4874-1-git-send-email-jason.wessel@windriver.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index ef3b49cde04e..6fcc358138ae 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -806,7 +806,10 @@ static int machine__create_modules(struct machine *machine)
 	free(line);
 	fclose(file);
 
-	return machine__set_modules_path(machine);
+	if (machine__set_modules_path(machine) < 0) {
+		pr_debug("Problems setting modules path maps, continuing anyway...\n");
+	}
+	return 0;
 
 out_delete_line:
 	free(line);

commit 8e0cf965f95edd41df11cca50b92b4cb6ea8d80a
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Wed Aug 7 14:38:51 2013 +0300

    perf symbols: Add support for reading from /proc/kcore
    
    In the absence of vmlinux, perf tools uses kallsyms for symbols.  If the
    user has access, now also map to /proc/kcore.
    
    The dso data_type is now set to either DSO_BINARY_TYPE__KCORE or
    DSO_BINARY_TYPE__GUEST_KCORE as approprite.
    
    This patch breaks the "vmlinux symtab matches kallsyms" test.  That is
    fixed in a following patch.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1375875537-4509-8-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index dc35dcffbd05..ef3b49cde04e 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -856,6 +856,18 @@ static void machine__set_kernel_mmap_len(struct machine *machine,
 	}
 }
 
+static bool machine__uses_kcore(struct machine *machine)
+{
+	struct dso *dso;
+
+	list_for_each_entry(dso, &machine->kernel_dsos, node) {
+		if (dso__is_kcore(dso))
+			return true;
+	}
+
+	return false;
+}
+
 static int machine__process_kernel_mmap_event(struct machine *machine,
 					      union perf_event *event)
 {
@@ -864,6 +876,10 @@ static int machine__process_kernel_mmap_event(struct machine *machine,
 	enum dso_kernel_type kernel_type;
 	bool is_kernel_mmap;
 
+	/* If we have maps from kcore then we do not need or want any others */
+	if (machine__uses_kcore(machine))
+		return 0;
+
 	machine__mmap_name(machine, kmmap_prefix, sizeof(kmmap_prefix));
 	if (machine__is_host(machine))
 		kernel_type = DSO_TYPE_KERNEL;

commit 39b12f7812710e9a5896805d96812b3ede7491e8
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Wed Aug 7 14:38:47 2013 +0300

    perf tools: Make it possible to read object code from vmlinux
    
    The new "object code reading" test shows that it is not possible to read
    object code from vmlinux.  That is because the mappings do not map to
    the dso.  This patch fixes that.
    
    A side-effect of changing the kernel map is that the "reloc" offset must
    be taken into account.  As a result of that separate map functions for
    relocation are no longer needed.
    
    Also fixing up the maps to match the symbols no longer makes sense and
    so is not done.
    
    The vmlinux dso data_type is now set to either DSO_BINARY_TYPE__VMLINUX
    or DSO_BINARY_TYPE__GUEST_VMLINUX as approprite, which enables the
    correct file name to be determined by dso__binary_type_file().
    
    This patch breaks the "vmlinux symtab matches kallsyms" test.  That is
    fixed in a following patch.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1375875537-4509-4-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index f9f9d6381b9a..dc35dcffbd05 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -628,10 +628,8 @@ int machine__load_vmlinux_path(struct machine *machine, enum map_type type,
 	struct map *map = machine->vmlinux_maps[type];
 	int ret = dso__load_vmlinux_path(map->dso, map, filter);
 
-	if (ret > 0) {
+	if (ret > 0)
 		dso__set_loaded(map->dso, type);
-		map__reloc_vmlinux(map);
-	}
 
 	return ret;
 }

commit b21484f1a1f300d422cfe5d4f8f50015e22cea24
Author: Greg Price <price@MIT.EDU>
Date:   Thu Dec 6 21:48:05 2012 -0800

    perf report/top: Add option to collapse undesired parts of call graph
    
    For example, in an application with an expensive function implemented
    with deeply nested recursive calls, the default call-graph presentation
    is dominated by the different callchains within that function.  By
    ignoring these callees, we can collect the callchains leading into the
    function and compactly identify what to blame for expensive calls.
    
    For example, in this report the callers of garbage_collect() are
    scattered across the tree:
    
      $ perf report -d ruby 2>- | grep -m10 ^[^#]*[a-z]
          22.03%     ruby  [.] gc_mark
                     --- gc_mark
                        |--59.40%-- mark_keyvalue
                        |          st_foreach
                        |          gc_mark_children
                        |          |--99.75%-- rb_gc_mark
                        |          |          rb_vm_mark
                        |          |          gc_mark_children
                        |          |          gc_marks
                        |          |          |--99.00%-- garbage_collect
    
    If we ignore the callees of garbage_collect(), its callers are coalesced:
    
      $ perf report --ignore-callees garbage_collect -d ruby 2>- | grep -m10 ^[^#]*[a-z]
          72.92%     ruby  [.] garbage_collect
                     --- garbage_collect
                         vm_xmalloc
                        |--47.08%-- ruby_xmalloc
                        |          st_insert2
                        |          rb_hash_aset
                        |          |--98.45%-- features_index_add
                        |          |          rb_provide_feature
                        |          |          rb_require_safe
                        |          |          vm_call_method
    
    Signed-off-by: Greg Price <price@mit.edu>
    Tested-by: Jiri Olsa <jolsa@redhat.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/20130623031720.GW22203@biohazard-cafe.mit.edu
    Link: http://lkml.kernel.org/r/20130708115746.GO22203@biohazard-cafe.mit.edu
    Cc: Fengguang Wu <fengguang.wu@intel.com>
    [ remove spaces at beginning of line, reported by Fengguang Wu ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 5dd5026a82ef..f9f9d6381b9a 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1058,11 +1058,10 @@ int machine__process_event(struct machine *machine, union perf_event *event)
 	return ret;
 }
 
-static bool symbol__match_parent_regex(struct symbol *sym)
+static bool symbol__match_regex(struct symbol *sym, regex_t *regex)
 {
-	if (sym->name && !regexec(&parent_regex, sym->name, 0, NULL, 0))
+	if (sym->name && !regexec(regex, sym->name, 0, NULL, 0))
 		return 1;
-
 	return 0;
 }
 
@@ -1159,8 +1158,8 @@ struct branch_info *machine__resolve_bstack(struct machine *machine,
 static int machine__resolve_callchain_sample(struct machine *machine,
 					     struct thread *thread,
 					     struct ip_callchain *chain,
-					     struct symbol **parent)
-
+					     struct symbol **parent,
+					     struct addr_location *root_al)
 {
 	u8 cpumode = PERF_RECORD_MISC_USER;
 	unsigned int i;
@@ -1211,8 +1210,15 @@ static int machine__resolve_callchain_sample(struct machine *machine,
 					   MAP__FUNCTION, ip, &al, NULL);
 		if (al.sym != NULL) {
 			if (sort__has_parent && !*parent &&
-			    symbol__match_parent_regex(al.sym))
+			    symbol__match_regex(al.sym, &parent_regex))
 				*parent = al.sym;
+			else if (have_ignore_callees && root_al &&
+			  symbol__match_regex(al.sym, &ignore_callees_regex)) {
+				/* Treat this symbol as the root,
+				   forgetting its callees. */
+				*root_al = al;
+				callchain_cursor_reset(&callchain_cursor);
+			}
 			if (!symbol_conf.use_callchain)
 				break;
 		}
@@ -1237,13 +1243,13 @@ int machine__resolve_callchain(struct machine *machine,
 			       struct perf_evsel *evsel,
 			       struct thread *thread,
 			       struct perf_sample *sample,
-			       struct symbol **parent)
-
+			       struct symbol **parent,
+			       struct addr_location *root_al)
 {
 	int ret;
 
 	ret = machine__resolve_callchain_sample(machine, thread,
-						sample->callchain, parent);
+						sample->callchain, parent, root_al);
 	if (ret)
 		return ret;
 

commit 380512345e13c3af64e59627f1b993c4faa94a84
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Thu Jul 4 16:20:31 2013 +0300

    perf tools: struct thread has a tid not a pid
    
    As evident from 'machine__process_fork_event()' and
    'machine__process_exit_event()' the 'pid' member of struct thread is
    actually the tid.
    
    Rename 'pid' to 'tid' in struct thread accordingly.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Acked-by: David Ahern <dsahern@gmail.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1372944040-32690-13-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 93527afb09d5..5dd5026a82ef 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -233,7 +233,7 @@ void machines__set_id_hdr_size(struct machines *machines, u16 id_hdr_size)
 	return;
 }
 
-static struct thread *__machine__findnew_thread(struct machine *machine, pid_t pid,
+static struct thread *__machine__findnew_thread(struct machine *machine, pid_t tid,
 						bool create)
 {
 	struct rb_node **p = &machine->threads.rb_node;
@@ -241,23 +241,23 @@ static struct thread *__machine__findnew_thread(struct machine *machine, pid_t p
 	struct thread *th;
 
 	/*
-	 * Font-end cache - PID lookups come in blocks,
+	 * Front-end cache - TID lookups come in blocks,
 	 * so most of the time we dont have to look up
 	 * the full rbtree:
 	 */
-	if (machine->last_match && machine->last_match->pid == pid)
+	if (machine->last_match && machine->last_match->tid == tid)
 		return machine->last_match;
 
 	while (*p != NULL) {
 		parent = *p;
 		th = rb_entry(parent, struct thread, rb_node);
 
-		if (th->pid == pid) {
+		if (th->tid == tid) {
 			machine->last_match = th;
 			return th;
 		}
 
-		if (pid < th->pid)
+		if (tid < th->tid)
 			p = &(*p)->rb_left;
 		else
 			p = &(*p)->rb_right;
@@ -266,7 +266,7 @@ static struct thread *__machine__findnew_thread(struct machine *machine, pid_t p
 	if (!create)
 		return NULL;
 
-	th = thread__new(pid);
+	th = thread__new(tid);
 	if (th != NULL) {
 		rb_link_node(&th->rb_node, parent, p);
 		rb_insert_color(&th->rb_node, &machine->threads);
@@ -276,14 +276,14 @@ static struct thread *__machine__findnew_thread(struct machine *machine, pid_t p
 	return th;
 }
 
-struct thread *machine__findnew_thread(struct machine *machine, pid_t pid)
+struct thread *machine__findnew_thread(struct machine *machine, pid_t tid)
 {
-	return __machine__findnew_thread(machine, pid, true);
+	return __machine__findnew_thread(machine, tid, true);
 }
 
-struct thread *machine__find_thread(struct machine *machine, pid_t pid)
+struct thread *machine__find_thread(struct machine *machine, pid_t tid)
 {
-	return __machine__findnew_thread(machine, pid, false);
+	return __machine__findnew_thread(machine, tid, false);
 }
 
 int machine__process_comm_event(struct machine *machine, union perf_event *event)

commit fa1531fdd7b6332aa61bcc9fda495583acba460d
Author: Jiri Olsa <jolsa@redhat.com>
Date:   Mon Jun 10 16:31:28 2013 -0400

    perf tools: Remove callchain_cursor_reset call
    
    Removing callchain_cursor_reset call as it is called in subsequent
    machine__resolve_callchain_sample function.
    
    Signed-off-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/n/tip-ic53wabwmmgvvwve2ymv3yf7@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index b2ecad6ec46b..93527afb09d5 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1242,8 +1242,6 @@ int machine__resolve_callchain(struct machine *machine,
 {
 	int ret;
 
-	callchain_cursor_reset(&callchain_cursor);
-
 	ret = machine__resolve_callchain_sample(machine, thread,
 						sample->callchain, parent);
 	if (ret)

commit bad4091791b0bb8c2d7919ddefe2f0d109299b5a
Author: Stephane Eranian <eranian@google.com>
Date:   Thu Jan 24 16:10:40 2013 +0100

    perf machine: Detect data vs. text mappings
    
    Leverages the PERF_RECORD_MISC_MMAP_DATA bit in the RECORD_MMAP record
    header. When the bit is set then the mapping type is set to
    MAP__VARIABLE.
    
    Signed-off-by: Stephane Eranian <eranian@google.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1359040242-8269-17-git-send-email-eranian@google.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index d77ba869d7ed..b2ecad6ec46b 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -955,6 +955,7 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 	u8 cpumode = event->header.misc & PERF_RECORD_MISC_CPUMODE_MASK;
 	struct thread *thread;
 	struct map *map;
+	enum map_type type;
 	int ret = 0;
 
 	if (dump_trace)
@@ -971,10 +972,17 @@ int machine__process_mmap_event(struct machine *machine, union perf_event *event
 	thread = machine__findnew_thread(machine, event->mmap.pid);
 	if (thread == NULL)
 		goto out_problem;
+
+	if (event->header.misc & PERF_RECORD_MISC_MMAP_DATA)
+		type = MAP__VARIABLE;
+	else
+		type = MAP__FUNCTION;
+
 	map = map__new(&machine->user_dsos, event->mmap.start,
 			event->mmap.len, event->mmap.pgoff,
 			event->mmap.pid, event->mmap.filename,
-			MAP__FUNCTION);
+			type);
+
 	if (map == NULL)
 		goto out_problem;
 

commit 98a3b32c99ada4bca8aaf4f91efd96fc906dd5c4
Author: Stephane Eranian <eranian@google.com>
Date:   Thu Jan 24 16:10:35 2013 +0100

    perf tools: Add mem access sampling core support
    
    This patch adds the sorting and histogram support
    functions to enable profiling of memory accesses.
    
    The following sorting orders are added:
     - symbol_daddr: data address symbol (or raw address)
     - dso_daddr: data address shared object
     - locked: access uses locked transaction
     - tlb : TLB access
     - mem : memory level of the access (L1, L2, L3, RAM, ...)
     - snoop: access snoop mode
    
    Signed-off-by: Stephane Eranian <eranian@google.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1359040242-8269-12-git-send-email-eranian@google.com
    [ committer note: changed to cope with fc5871ed, the move of methods to
      machine.[ch], and the rename of dsrc to data_src, to match the change
      made in the PERF_SAMPLE_DSRC in a previous patch. ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index c5e3b123782b..d77ba869d7ed 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1097,6 +1097,38 @@ static void ip__resolve_ams(struct machine *machine, struct thread *thread,
 	ams->map = al.map;
 }
 
+static void ip__resolve_data(struct machine *machine, struct thread *thread,
+			     u8 m, struct addr_map_symbol *ams, u64 addr)
+{
+	struct addr_location al;
+
+	memset(&al, 0, sizeof(al));
+
+	thread__find_addr_location(thread, machine, m, MAP__VARIABLE, addr, &al,
+				   NULL);
+	ams->addr = addr;
+	ams->al_addr = al.addr;
+	ams->sym = al.sym;
+	ams->map = al.map;
+}
+
+struct mem_info *machine__resolve_mem(struct machine *machine,
+				      struct thread *thr,
+				      struct perf_sample *sample,
+				      u8 cpumode)
+{
+	struct mem_info *mi = zalloc(sizeof(*mi));
+
+	if (!mi)
+		return NULL;
+
+	ip__resolve_ams(machine, thr, &mi->iaddr, sample->ip);
+	ip__resolve_data(machine, thr, cpumode, &mi->daddr, sample->addr);
+	mi->data_src.val = sample->data_src;
+
+	return mi;
+}
+
 struct branch_info *machine__resolve_bstack(struct machine *machine,
 					    struct thread *thr,
 					    struct branch_stack *bs)

commit ed8996a6d59b9eb00a50d7d30887ba9f28eb4bb0
Author: David Ahern <dsahern@gmail.com>
Date:   Tue Mar 12 23:07:28 2013 -0600

    perf machine: Move machine__remove_thread and make static
    
    As the now only user, machine__process_exit_event, that is what tools
    use to process PERF_RECORD_EXIT events, is on the same object file.
    
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Link: http://lkml.kernel.org/r/1363151248-16674-5-git-send-email-dsahern@gmail.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index efdb38e65a92..c5e3b123782b 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1003,6 +1003,17 @@ int machine__process_fork_event(struct machine *machine, union perf_event *event
 	return 0;
 }
 
+static void machine__remove_thread(struct machine *machine, struct thread *th)
+{
+	machine->last_match = NULL;
+	rb_erase(&th->rb_node, &machine->threads);
+	/*
+	 * We may have references to this thread, for instance in some hist_entry
+	 * instances, so just move them to a separate list.
+	 */
+	list_add_tail(&th->node, &machine->dead_threads);
+}
+
 int machine__process_exit_event(struct machine *machine, union perf_event *event)
 {
 	struct thread *thread = machine__find_thread(machine, event->fork.tid);
@@ -1039,17 +1050,6 @@ int machine__process_event(struct machine *machine, union perf_event *event)
 	return ret;
 }
 
-void machine__remove_thread(struct machine *machine, struct thread *th)
-{
-	machine->last_match = NULL;
-	rb_erase(&th->rb_node, &machine->threads);
-	/*
-	 * We may have references to this thread, for instance in some hist_entry
-	 * instances, so just move them to a separate list.
-	 */
-	list_add_tail(&th->node, &machine->dead_threads);
-}
-
 static bool symbol__match_parent_regex(struct symbol *sym)
 {
 	if (sym->name && !regexec(&parent_regex, sym->name, 0, NULL, 0))

commit 876650e6c3209861a8949111140d805b3440951f
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Dec 18 19:15:48 2012 -0300

    perf machine: Introduce struct machines
    
    That consolidates the grouping of host + guests, isolating a bit more of
    functionality now centered on 'perf_session' that can be used
    independently in tools that don't need a 'perf_session' instance, but
    needs to have all the thread/map/symbol machinery.
    
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-c700rsiphpmzv8klogojpfut@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 71fa90391fe4..efdb38e65a92 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -91,10 +91,22 @@ void machine__delete(struct machine *machine)
 	free(machine);
 }
 
-struct machine *machines__add(struct rb_root *machines, pid_t pid,
+void machines__init(struct machines *machines)
+{
+	machine__init(&machines->host, "", HOST_KERNEL_ID);
+	machines->guests = RB_ROOT;
+}
+
+void machines__exit(struct machines *machines)
+{
+	machine__exit(&machines->host);
+	/* XXX exit guest */
+}
+
+struct machine *machines__add(struct machines *machines, pid_t pid,
 			      const char *root_dir)
 {
-	struct rb_node **p = &machines->rb_node;
+	struct rb_node **p = &machines->guests.rb_node;
 	struct rb_node *parent = NULL;
 	struct machine *pos, *machine = malloc(sizeof(*machine));
 
@@ -116,18 +128,21 @@ struct machine *machines__add(struct rb_root *machines, pid_t pid,
 	}
 
 	rb_link_node(&machine->rb_node, parent, p);
-	rb_insert_color(&machine->rb_node, machines);
+	rb_insert_color(&machine->rb_node, &machines->guests);
 
 	return machine;
 }
 
-struct machine *machines__find(struct rb_root *machines, pid_t pid)
+struct machine *machines__find(struct machines *machines, pid_t pid)
 {
-	struct rb_node **p = &machines->rb_node;
+	struct rb_node **p = &machines->guests.rb_node;
 	struct rb_node *parent = NULL;
 	struct machine *machine;
 	struct machine *default_machine = NULL;
 
+	if (pid == HOST_KERNEL_ID)
+		return &machines->host;
+
 	while (*p != NULL) {
 		parent = *p;
 		machine = rb_entry(parent, struct machine, rb_node);
@@ -144,7 +159,7 @@ struct machine *machines__find(struct rb_root *machines, pid_t pid)
 	return default_machine;
 }
 
-struct machine *machines__findnew(struct rb_root *machines, pid_t pid)
+struct machine *machines__findnew(struct machines *machines, pid_t pid)
 {
 	char path[PATH_MAX];
 	const char *root_dir = "";
@@ -178,12 +193,12 @@ struct machine *machines__findnew(struct rb_root *machines, pid_t pid)
 	return machine;
 }
 
-void machines__process(struct rb_root *machines,
-		       machine__process_t process, void *data)
+void machines__process_guests(struct machines *machines,
+			      machine__process_t process, void *data)
 {
 	struct rb_node *nd;
 
-	for (nd = rb_first(machines); nd; nd = rb_next(nd)) {
+	for (nd = rb_first(&machines->guests); nd; nd = rb_next(nd)) {
 		struct machine *pos = rb_entry(nd, struct machine, rb_node);
 		process(pos, data);
 	}
@@ -203,12 +218,14 @@ char *machine__mmap_name(struct machine *machine, char *bf, size_t size)
 	return bf;
 }
 
-void machines__set_id_hdr_size(struct rb_root *machines, u16 id_hdr_size)
+void machines__set_id_hdr_size(struct machines *machines, u16 id_hdr_size)
 {
 	struct rb_node *node;
 	struct machine *machine;
 
-	for (node = rb_first(machines); node; node = rb_next(node)) {
+	machines->host.id_hdr_size = id_hdr_size;
+
+	for (node = rb_first(&machines->guests); node; node = rb_next(node)) {
 		machine = rb_entry(node, struct machine, rb_node);
 		machine->id_hdr_size = id_hdr_size;
 	}
@@ -313,12 +330,13 @@ struct map *machine__new_module(struct machine *machine, u64 start,
 	return map;
 }
 
-size_t machines__fprintf_dsos(struct rb_root *machines, FILE *fp)
+size_t machines__fprintf_dsos(struct machines *machines, FILE *fp)
 {
 	struct rb_node *nd;
-	size_t ret = 0;
+	size_t ret = __dsos__fprintf(&machines->host.kernel_dsos, fp) +
+		     __dsos__fprintf(&machines->host.user_dsos, fp);
 
-	for (nd = rb_first(machines); nd; nd = rb_next(nd)) {
+	for (nd = rb_first(&machines->guests); nd; nd = rb_next(nd)) {
 		struct machine *pos = rb_entry(nd, struct machine, rb_node);
 		ret += __dsos__fprintf(&pos->kernel_dsos, fp);
 		ret += __dsos__fprintf(&pos->user_dsos, fp);
@@ -334,13 +352,13 @@ size_t machine__fprintf_dsos_buildid(struct machine *machine, FILE *fp,
 	       __dsos__fprintf_buildid(&machine->user_dsos, fp, skip, parm);
 }
 
-size_t machines__fprintf_dsos_buildid(struct rb_root *machines, FILE *fp,
+size_t machines__fprintf_dsos_buildid(struct machines *machines, FILE *fp,
 				     bool (skip)(struct dso *dso, int parm), int parm)
 {
 	struct rb_node *nd;
-	size_t ret = 0;
+	size_t ret = machine__fprintf_dsos_buildid(&machines->host, fp, skip, parm);
 
-	for (nd = rb_first(machines); nd; nd = rb_next(nd)) {
+	for (nd = rb_first(&machines->guests); nd; nd = rb_next(nd)) {
 		struct machine *pos = rb_entry(nd, struct machine, rb_node);
 		ret += machine__fprintf_dsos_buildid(pos, fp, skip, parm);
 	}
@@ -511,7 +529,7 @@ void machine__destroy_kernel_maps(struct machine *machine)
 	}
 }
 
-int machines__create_guest_kernel_maps(struct rb_root *machines)
+int machines__create_guest_kernel_maps(struct machines *machines)
 {
 	int ret = 0;
 	struct dirent **namelist = NULL;
@@ -560,20 +578,22 @@ int machines__create_guest_kernel_maps(struct rb_root *machines)
 	return ret;
 }
 
-void machines__destroy_guest_kernel_maps(struct rb_root *machines)
+void machines__destroy_kernel_maps(struct machines *machines)
 {
-	struct rb_node *next = rb_first(machines);
+	struct rb_node *next = rb_first(&machines->guests);
+
+	machine__destroy_kernel_maps(&machines->host);
 
 	while (next) {
 		struct machine *pos = rb_entry(next, struct machine, rb_node);
 
 		next = rb_next(&pos->rb_node);
-		rb_erase(&pos->rb_node, machines);
+		rb_erase(&pos->rb_node, &machines->guests);
 		machine__delete(pos);
 	}
 }
 
-int machines__create_kernel_maps(struct rb_root *machines, pid_t pid)
+int machines__create_kernel_maps(struct machines *machines, pid_t pid)
 {
 	struct machine *machine = machines__findnew(machines, pid);
 

commit 3f067dcab711c2df7eefcfc5b3aa9a0e2b5f7d42
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri Dec 7 17:39:39 2012 -0300

    perf machine: Move more machine methods to machine.c
    
    Mechanical, no functional changes.
    
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-9ib6qtqge1jmms2luwu4udbx@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 1f09d0581e6b..71fa90391fe4 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1,10 +1,15 @@
+#include "callchain.h"
 #include "debug.h"
 #include "event.h"
+#include "evsel.h"
+#include "hist.h"
 #include "machine.h"
 #include "map.h"
+#include "sort.h"
 #include "strlist.h"
 #include "thread.h"
 #include <stdbool.h>
+#include "unwind.h"
 
 int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
 {
@@ -48,6 +53,29 @@ static void dsos__delete(struct list_head *dsos)
 	}
 }
 
+void machine__delete_dead_threads(struct machine *machine)
+{
+	struct thread *n, *t;
+
+	list_for_each_entry_safe(t, n, &machine->dead_threads, node) {
+		list_del(&t->node);
+		thread__delete(t);
+	}
+}
+
+void machine__delete_threads(struct machine *machine)
+{
+	struct rb_node *nd = rb_first(&machine->threads);
+
+	while (nd) {
+		struct thread *t = rb_entry(nd, struct thread, rb_node);
+
+		rb_erase(&t->rb_node, &machine->threads);
+		nd = rb_next(nd);
+		thread__delete(t);
+	}
+}
+
 void machine__exit(struct machine *machine)
 {
 	map_groups__exit(&machine->kmaps);
@@ -264,6 +292,534 @@ int machine__process_lost_event(struct machine *machine __maybe_unused,
 	return 0;
 }
 
+struct map *machine__new_module(struct machine *machine, u64 start,
+				const char *filename)
+{
+	struct map *map;
+	struct dso *dso = __dsos__findnew(&machine->kernel_dsos, filename);
+
+	if (dso == NULL)
+		return NULL;
+
+	map = map__new2(start, dso, MAP__FUNCTION);
+	if (map == NULL)
+		return NULL;
+
+	if (machine__is_host(machine))
+		dso->symtab_type = DSO_BINARY_TYPE__SYSTEM_PATH_KMODULE;
+	else
+		dso->symtab_type = DSO_BINARY_TYPE__GUEST_KMODULE;
+	map_groups__insert(&machine->kmaps, map);
+	return map;
+}
+
+size_t machines__fprintf_dsos(struct rb_root *machines, FILE *fp)
+{
+	struct rb_node *nd;
+	size_t ret = 0;
+
+	for (nd = rb_first(machines); nd; nd = rb_next(nd)) {
+		struct machine *pos = rb_entry(nd, struct machine, rb_node);
+		ret += __dsos__fprintf(&pos->kernel_dsos, fp);
+		ret += __dsos__fprintf(&pos->user_dsos, fp);
+	}
+
+	return ret;
+}
+
+size_t machine__fprintf_dsos_buildid(struct machine *machine, FILE *fp,
+				     bool (skip)(struct dso *dso, int parm), int parm)
+{
+	return __dsos__fprintf_buildid(&machine->kernel_dsos, fp, skip, parm) +
+	       __dsos__fprintf_buildid(&machine->user_dsos, fp, skip, parm);
+}
+
+size_t machines__fprintf_dsos_buildid(struct rb_root *machines, FILE *fp,
+				     bool (skip)(struct dso *dso, int parm), int parm)
+{
+	struct rb_node *nd;
+	size_t ret = 0;
+
+	for (nd = rb_first(machines); nd; nd = rb_next(nd)) {
+		struct machine *pos = rb_entry(nd, struct machine, rb_node);
+		ret += machine__fprintf_dsos_buildid(pos, fp, skip, parm);
+	}
+	return ret;
+}
+
+size_t machine__fprintf_vmlinux_path(struct machine *machine, FILE *fp)
+{
+	int i;
+	size_t printed = 0;
+	struct dso *kdso = machine->vmlinux_maps[MAP__FUNCTION]->dso;
+
+	if (kdso->has_build_id) {
+		char filename[PATH_MAX];
+		if (dso__build_id_filename(kdso, filename, sizeof(filename)))
+			printed += fprintf(fp, "[0] %s\n", filename);
+	}
+
+	for (i = 0; i < vmlinux_path__nr_entries; ++i)
+		printed += fprintf(fp, "[%d] %s\n",
+				   i + kdso->has_build_id, vmlinux_path[i]);
+
+	return printed;
+}
+
+size_t machine__fprintf(struct machine *machine, FILE *fp)
+{
+	size_t ret = 0;
+	struct rb_node *nd;
+
+	for (nd = rb_first(&machine->threads); nd; nd = rb_next(nd)) {
+		struct thread *pos = rb_entry(nd, struct thread, rb_node);
+
+		ret += thread__fprintf(pos, fp);
+	}
+
+	return ret;
+}
+
+static struct dso *machine__get_kernel(struct machine *machine)
+{
+	const char *vmlinux_name = NULL;
+	struct dso *kernel;
+
+	if (machine__is_host(machine)) {
+		vmlinux_name = symbol_conf.vmlinux_name;
+		if (!vmlinux_name)
+			vmlinux_name = "[kernel.kallsyms]";
+
+		kernel = dso__kernel_findnew(machine, vmlinux_name,
+					     "[kernel]",
+					     DSO_TYPE_KERNEL);
+	} else {
+		char bf[PATH_MAX];
+
+		if (machine__is_default_guest(machine))
+			vmlinux_name = symbol_conf.default_guest_vmlinux_name;
+		if (!vmlinux_name)
+			vmlinux_name = machine__mmap_name(machine, bf,
+							  sizeof(bf));
+
+		kernel = dso__kernel_findnew(machine, vmlinux_name,
+					     "[guest.kernel]",
+					     DSO_TYPE_GUEST_KERNEL);
+	}
+
+	if (kernel != NULL && (!kernel->has_build_id))
+		dso__read_running_kernel_build_id(kernel, machine);
+
+	return kernel;
+}
+
+struct process_args {
+	u64 start;
+};
+
+static int symbol__in_kernel(void *arg, const char *name,
+			     char type __maybe_unused, u64 start)
+{
+	struct process_args *args = arg;
+
+	if (strchr(name, '['))
+		return 0;
+
+	args->start = start;
+	return 1;
+}
+
+/* Figure out the start address of kernel map from /proc/kallsyms */
+static u64 machine__get_kernel_start_addr(struct machine *machine)
+{
+	const char *filename;
+	char path[PATH_MAX];
+	struct process_args args;
+
+	if (machine__is_host(machine)) {
+		filename = "/proc/kallsyms";
+	} else {
+		if (machine__is_default_guest(machine))
+			filename = (char *)symbol_conf.default_guest_kallsyms;
+		else {
+			sprintf(path, "%s/proc/kallsyms", machine->root_dir);
+			filename = path;
+		}
+	}
+
+	if (symbol__restricted_filename(filename, "/proc/kallsyms"))
+		return 0;
+
+	if (kallsyms__parse(filename, &args, symbol__in_kernel) <= 0)
+		return 0;
+
+	return args.start;
+}
+
+int __machine__create_kernel_maps(struct machine *machine, struct dso *kernel)
+{
+	enum map_type type;
+	u64 start = machine__get_kernel_start_addr(machine);
+
+	for (type = 0; type < MAP__NR_TYPES; ++type) {
+		struct kmap *kmap;
+
+		machine->vmlinux_maps[type] = map__new2(start, kernel, type);
+		if (machine->vmlinux_maps[type] == NULL)
+			return -1;
+
+		machine->vmlinux_maps[type]->map_ip =
+			machine->vmlinux_maps[type]->unmap_ip =
+				identity__map_ip;
+		kmap = map__kmap(machine->vmlinux_maps[type]);
+		kmap->kmaps = &machine->kmaps;
+		map_groups__insert(&machine->kmaps,
+				   machine->vmlinux_maps[type]);
+	}
+
+	return 0;
+}
+
+void machine__destroy_kernel_maps(struct machine *machine)
+{
+	enum map_type type;
+
+	for (type = 0; type < MAP__NR_TYPES; ++type) {
+		struct kmap *kmap;
+
+		if (machine->vmlinux_maps[type] == NULL)
+			continue;
+
+		kmap = map__kmap(machine->vmlinux_maps[type]);
+		map_groups__remove(&machine->kmaps,
+				   machine->vmlinux_maps[type]);
+		if (kmap->ref_reloc_sym) {
+			/*
+			 * ref_reloc_sym is shared among all maps, so free just
+			 * on one of them.
+			 */
+			if (type == MAP__FUNCTION) {
+				free((char *)kmap->ref_reloc_sym->name);
+				kmap->ref_reloc_sym->name = NULL;
+				free(kmap->ref_reloc_sym);
+			}
+			kmap->ref_reloc_sym = NULL;
+		}
+
+		map__delete(machine->vmlinux_maps[type]);
+		machine->vmlinux_maps[type] = NULL;
+	}
+}
+
+int machines__create_guest_kernel_maps(struct rb_root *machines)
+{
+	int ret = 0;
+	struct dirent **namelist = NULL;
+	int i, items = 0;
+	char path[PATH_MAX];
+	pid_t pid;
+	char *endp;
+
+	if (symbol_conf.default_guest_vmlinux_name ||
+	    symbol_conf.default_guest_modules ||
+	    symbol_conf.default_guest_kallsyms) {
+		machines__create_kernel_maps(machines, DEFAULT_GUEST_KERNEL_ID);
+	}
+
+	if (symbol_conf.guestmount) {
+		items = scandir(symbol_conf.guestmount, &namelist, NULL, NULL);
+		if (items <= 0)
+			return -ENOENT;
+		for (i = 0; i < items; i++) {
+			if (!isdigit(namelist[i]->d_name[0])) {
+				/* Filter out . and .. */
+				continue;
+			}
+			pid = (pid_t)strtol(namelist[i]->d_name, &endp, 10);
+			if ((*endp != '\0') ||
+			    (endp == namelist[i]->d_name) ||
+			    (errno == ERANGE)) {
+				pr_debug("invalid directory (%s). Skipping.\n",
+					 namelist[i]->d_name);
+				continue;
+			}
+			sprintf(path, "%s/%s/proc/kallsyms",
+				symbol_conf.guestmount,
+				namelist[i]->d_name);
+			ret = access(path, R_OK);
+			if (ret) {
+				pr_debug("Can't access file %s\n", path);
+				goto failure;
+			}
+			machines__create_kernel_maps(machines, pid);
+		}
+failure:
+		free(namelist);
+	}
+
+	return ret;
+}
+
+void machines__destroy_guest_kernel_maps(struct rb_root *machines)
+{
+	struct rb_node *next = rb_first(machines);
+
+	while (next) {
+		struct machine *pos = rb_entry(next, struct machine, rb_node);
+
+		next = rb_next(&pos->rb_node);
+		rb_erase(&pos->rb_node, machines);
+		machine__delete(pos);
+	}
+}
+
+int machines__create_kernel_maps(struct rb_root *machines, pid_t pid)
+{
+	struct machine *machine = machines__findnew(machines, pid);
+
+	if (machine == NULL)
+		return -1;
+
+	return machine__create_kernel_maps(machine);
+}
+
+int machine__load_kallsyms(struct machine *machine, const char *filename,
+			   enum map_type type, symbol_filter_t filter)
+{
+	struct map *map = machine->vmlinux_maps[type];
+	int ret = dso__load_kallsyms(map->dso, filename, map, filter);
+
+	if (ret > 0) {
+		dso__set_loaded(map->dso, type);
+		/*
+		 * Since /proc/kallsyms will have multiple sessions for the
+		 * kernel, with modules between them, fixup the end of all
+		 * sections.
+		 */
+		__map_groups__fixup_end(&machine->kmaps, type);
+	}
+
+	return ret;
+}
+
+int machine__load_vmlinux_path(struct machine *machine, enum map_type type,
+			       symbol_filter_t filter)
+{
+	struct map *map = machine->vmlinux_maps[type];
+	int ret = dso__load_vmlinux_path(map->dso, map, filter);
+
+	if (ret > 0) {
+		dso__set_loaded(map->dso, type);
+		map__reloc_vmlinux(map);
+	}
+
+	return ret;
+}
+
+static void map_groups__fixup_end(struct map_groups *mg)
+{
+	int i;
+	for (i = 0; i < MAP__NR_TYPES; ++i)
+		__map_groups__fixup_end(mg, i);
+}
+
+static char *get_kernel_version(const char *root_dir)
+{
+	char version[PATH_MAX];
+	FILE *file;
+	char *name, *tmp;
+	const char *prefix = "Linux version ";
+
+	sprintf(version, "%s/proc/version", root_dir);
+	file = fopen(version, "r");
+	if (!file)
+		return NULL;
+
+	version[0] = '\0';
+	tmp = fgets(version, sizeof(version), file);
+	fclose(file);
+
+	name = strstr(version, prefix);
+	if (!name)
+		return NULL;
+	name += strlen(prefix);
+	tmp = strchr(name, ' ');
+	if (tmp)
+		*tmp = '\0';
+
+	return strdup(name);
+}
+
+static int map_groups__set_modules_path_dir(struct map_groups *mg,
+				const char *dir_name)
+{
+	struct dirent *dent;
+	DIR *dir = opendir(dir_name);
+	int ret = 0;
+
+	if (!dir) {
+		pr_debug("%s: cannot open %s dir\n", __func__, dir_name);
+		return -1;
+	}
+
+	while ((dent = readdir(dir)) != NULL) {
+		char path[PATH_MAX];
+		struct stat st;
+
+		/*sshfs might return bad dent->d_type, so we have to stat*/
+		snprintf(path, sizeof(path), "%s/%s", dir_name, dent->d_name);
+		if (stat(path, &st))
+			continue;
+
+		if (S_ISDIR(st.st_mode)) {
+			if (!strcmp(dent->d_name, ".") ||
+			    !strcmp(dent->d_name, ".."))
+				continue;
+
+			ret = map_groups__set_modules_path_dir(mg, path);
+			if (ret < 0)
+				goto out;
+		} else {
+			char *dot = strrchr(dent->d_name, '.'),
+			     dso_name[PATH_MAX];
+			struct map *map;
+			char *long_name;
+
+			if (dot == NULL || strcmp(dot, ".ko"))
+				continue;
+			snprintf(dso_name, sizeof(dso_name), "[%.*s]",
+				 (int)(dot - dent->d_name), dent->d_name);
+
+			strxfrchar(dso_name, '-', '_');
+			map = map_groups__find_by_name(mg, MAP__FUNCTION,
+						       dso_name);
+			if (map == NULL)
+				continue;
+
+			long_name = strdup(path);
+			if (long_name == NULL) {
+				ret = -1;
+				goto out;
+			}
+			dso__set_long_name(map->dso, long_name);
+			map->dso->lname_alloc = 1;
+			dso__kernel_module_get_build_id(map->dso, "");
+		}
+	}
+
+out:
+	closedir(dir);
+	return ret;
+}
+
+static int machine__set_modules_path(struct machine *machine)
+{
+	char *version;
+	char modules_path[PATH_MAX];
+
+	version = get_kernel_version(machine->root_dir);
+	if (!version)
+		return -1;
+
+	snprintf(modules_path, sizeof(modules_path), "%s/lib/modules/%s/kernel",
+		 machine->root_dir, version);
+	free(version);
+
+	return map_groups__set_modules_path_dir(&machine->kmaps, modules_path);
+}
+
+static int machine__create_modules(struct machine *machine)
+{
+	char *line = NULL;
+	size_t n;
+	FILE *file;
+	struct map *map;
+	const char *modules;
+	char path[PATH_MAX];
+
+	if (machine__is_default_guest(machine))
+		modules = symbol_conf.default_guest_modules;
+	else {
+		sprintf(path, "%s/proc/modules", machine->root_dir);
+		modules = path;
+	}
+
+	if (symbol__restricted_filename(path, "/proc/modules"))
+		return -1;
+
+	file = fopen(modules, "r");
+	if (file == NULL)
+		return -1;
+
+	while (!feof(file)) {
+		char name[PATH_MAX];
+		u64 start;
+		char *sep;
+		int line_len;
+
+		line_len = getline(&line, &n, file);
+		if (line_len < 0)
+			break;
+
+		if (!line)
+			goto out_failure;
+
+		line[--line_len] = '\0'; /* \n */
+
+		sep = strrchr(line, 'x');
+		if (sep == NULL)
+			continue;
+
+		hex2u64(sep + 1, &start);
+
+		sep = strchr(line, ' ');
+		if (sep == NULL)
+			continue;
+
+		*sep = '\0';
+
+		snprintf(name, sizeof(name), "[%s]", line);
+		map = machine__new_module(machine, start, name);
+		if (map == NULL)
+			goto out_delete_line;
+		dso__kernel_module_get_build_id(map->dso, machine->root_dir);
+	}
+
+	free(line);
+	fclose(file);
+
+	return machine__set_modules_path(machine);
+
+out_delete_line:
+	free(line);
+out_failure:
+	return -1;
+}
+
+int machine__create_kernel_maps(struct machine *machine)
+{
+	struct dso *kernel = machine__get_kernel(machine);
+
+	if (kernel == NULL ||
+	    __machine__create_kernel_maps(machine, kernel) < 0)
+		return -1;
+
+	if (symbol_conf.use_modules && machine__create_modules(machine) < 0) {
+		if (machine__is_host(machine))
+			pr_debug("Problems creating module maps, "
+				 "continuing anyway...\n");
+		else
+			pr_debug("Problems creating module maps for guest %d, "
+				 "continuing anyway...\n", machine->pid);
+	}
+
+	/*
+	 * Now that we have all the maps created, just set the ->end of them:
+	 */
+	map_groups__fixup_end(&machine->kmaps);
+	return 0;
+}
+
 static void machine__set_kernel_mmap_len(struct machine *machine,
 					 union perf_event *event)
 {
@@ -462,3 +1018,189 @@ int machine__process_event(struct machine *machine, union perf_event *event)
 
 	return ret;
 }
+
+void machine__remove_thread(struct machine *machine, struct thread *th)
+{
+	machine->last_match = NULL;
+	rb_erase(&th->rb_node, &machine->threads);
+	/*
+	 * We may have references to this thread, for instance in some hist_entry
+	 * instances, so just move them to a separate list.
+	 */
+	list_add_tail(&th->node, &machine->dead_threads);
+}
+
+static bool symbol__match_parent_regex(struct symbol *sym)
+{
+	if (sym->name && !regexec(&parent_regex, sym->name, 0, NULL, 0))
+		return 1;
+
+	return 0;
+}
+
+static const u8 cpumodes[] = {
+	PERF_RECORD_MISC_USER,
+	PERF_RECORD_MISC_KERNEL,
+	PERF_RECORD_MISC_GUEST_USER,
+	PERF_RECORD_MISC_GUEST_KERNEL
+};
+#define NCPUMODES (sizeof(cpumodes)/sizeof(u8))
+
+static void ip__resolve_ams(struct machine *machine, struct thread *thread,
+			    struct addr_map_symbol *ams,
+			    u64 ip)
+{
+	struct addr_location al;
+	size_t i;
+	u8 m;
+
+	memset(&al, 0, sizeof(al));
+
+	for (i = 0; i < NCPUMODES; i++) {
+		m = cpumodes[i];
+		/*
+		 * We cannot use the header.misc hint to determine whether a
+		 * branch stack address is user, kernel, guest, hypervisor.
+		 * Branches may straddle the kernel/user/hypervisor boundaries.
+		 * Thus, we have to try consecutively until we find a match
+		 * or else, the symbol is unknown
+		 */
+		thread__find_addr_location(thread, machine, m, MAP__FUNCTION,
+				ip, &al, NULL);
+		if (al.sym)
+			goto found;
+	}
+found:
+	ams->addr = ip;
+	ams->al_addr = al.addr;
+	ams->sym = al.sym;
+	ams->map = al.map;
+}
+
+struct branch_info *machine__resolve_bstack(struct machine *machine,
+					    struct thread *thr,
+					    struct branch_stack *bs)
+{
+	struct branch_info *bi;
+	unsigned int i;
+
+	bi = calloc(bs->nr, sizeof(struct branch_info));
+	if (!bi)
+		return NULL;
+
+	for (i = 0; i < bs->nr; i++) {
+		ip__resolve_ams(machine, thr, &bi[i].to, bs->entries[i].to);
+		ip__resolve_ams(machine, thr, &bi[i].from, bs->entries[i].from);
+		bi[i].flags = bs->entries[i].flags;
+	}
+	return bi;
+}
+
+static int machine__resolve_callchain_sample(struct machine *machine,
+					     struct thread *thread,
+					     struct ip_callchain *chain,
+					     struct symbol **parent)
+
+{
+	u8 cpumode = PERF_RECORD_MISC_USER;
+	unsigned int i;
+	int err;
+
+	callchain_cursor_reset(&callchain_cursor);
+
+	if (chain->nr > PERF_MAX_STACK_DEPTH) {
+		pr_warning("corrupted callchain. skipping...\n");
+		return 0;
+	}
+
+	for (i = 0; i < chain->nr; i++) {
+		u64 ip;
+		struct addr_location al;
+
+		if (callchain_param.order == ORDER_CALLEE)
+			ip = chain->ips[i];
+		else
+			ip = chain->ips[chain->nr - i - 1];
+
+		if (ip >= PERF_CONTEXT_MAX) {
+			switch (ip) {
+			case PERF_CONTEXT_HV:
+				cpumode = PERF_RECORD_MISC_HYPERVISOR;
+				break;
+			case PERF_CONTEXT_KERNEL:
+				cpumode = PERF_RECORD_MISC_KERNEL;
+				break;
+			case PERF_CONTEXT_USER:
+				cpumode = PERF_RECORD_MISC_USER;
+				break;
+			default:
+				pr_debug("invalid callchain context: "
+					 "%"PRId64"\n", (s64) ip);
+				/*
+				 * It seems the callchain is corrupted.
+				 * Discard all.
+				 */
+				callchain_cursor_reset(&callchain_cursor);
+				return 0;
+			}
+			continue;
+		}
+
+		al.filtered = false;
+		thread__find_addr_location(thread, machine, cpumode,
+					   MAP__FUNCTION, ip, &al, NULL);
+		if (al.sym != NULL) {
+			if (sort__has_parent && !*parent &&
+			    symbol__match_parent_regex(al.sym))
+				*parent = al.sym;
+			if (!symbol_conf.use_callchain)
+				break;
+		}
+
+		err = callchain_cursor_append(&callchain_cursor,
+					      ip, al.map, al.sym);
+		if (err)
+			return err;
+	}
+
+	return 0;
+}
+
+static int unwind_entry(struct unwind_entry *entry, void *arg)
+{
+	struct callchain_cursor *cursor = arg;
+	return callchain_cursor_append(cursor, entry->ip,
+				       entry->map, entry->sym);
+}
+
+int machine__resolve_callchain(struct machine *machine,
+			       struct perf_evsel *evsel,
+			       struct thread *thread,
+			       struct perf_sample *sample,
+			       struct symbol **parent)
+
+{
+	int ret;
+
+	callchain_cursor_reset(&callchain_cursor);
+
+	ret = machine__resolve_callchain_sample(machine, thread,
+						sample->callchain, parent);
+	if (ret)
+		return ret;
+
+	/* Can we do dwarf post unwind? */
+	if (!((evsel->attr.sample_type & PERF_SAMPLE_REGS_USER) &&
+	      (evsel->attr.sample_type & PERF_SAMPLE_STACK_USER)))
+		return 0;
+
+	/* Bail out if nothing was captured. */
+	if ((!sample->user_regs.regs) ||
+	    (!sample->user_stack.size))
+		return 0;
+
+	return unwind__get_entries(unwind_entry, &callchain_cursor, machine,
+				   thread, evsel->attr.sample_regs_user,
+				   sample);
+
+}

commit 69d2591a829132492662bbfe164fcde5e44ad1c4
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri Nov 9 11:32:52 2012 -0300

    perf machine: Move more methods to machine.[ch]
    
    This time out of map.[ch] mostly, just code move plus a buch of 'self'
    removal, using machine or machines instead.
    
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-j1vtux3vnu6wzmrjutpxnjcz@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 4c6754ac6b20..1f09d0581e6b 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -2,9 +2,192 @@
 #include "event.h"
 #include "machine.h"
 #include "map.h"
+#include "strlist.h"
 #include "thread.h"
 #include <stdbool.h>
 
+int machine__init(struct machine *machine, const char *root_dir, pid_t pid)
+{
+	map_groups__init(&machine->kmaps);
+	RB_CLEAR_NODE(&machine->rb_node);
+	INIT_LIST_HEAD(&machine->user_dsos);
+	INIT_LIST_HEAD(&machine->kernel_dsos);
+
+	machine->threads = RB_ROOT;
+	INIT_LIST_HEAD(&machine->dead_threads);
+	machine->last_match = NULL;
+
+	machine->kmaps.machine = machine;
+	machine->pid = pid;
+
+	machine->root_dir = strdup(root_dir);
+	if (machine->root_dir == NULL)
+		return -ENOMEM;
+
+	if (pid != HOST_KERNEL_ID) {
+		struct thread *thread = machine__findnew_thread(machine, pid);
+		char comm[64];
+
+		if (thread == NULL)
+			return -ENOMEM;
+
+		snprintf(comm, sizeof(comm), "[guest/%d]", pid);
+		thread__set_comm(thread, comm);
+	}
+
+	return 0;
+}
+
+static void dsos__delete(struct list_head *dsos)
+{
+	struct dso *pos, *n;
+
+	list_for_each_entry_safe(pos, n, dsos, node) {
+		list_del(&pos->node);
+		dso__delete(pos);
+	}
+}
+
+void machine__exit(struct machine *machine)
+{
+	map_groups__exit(&machine->kmaps);
+	dsos__delete(&machine->user_dsos);
+	dsos__delete(&machine->kernel_dsos);
+	free(machine->root_dir);
+	machine->root_dir = NULL;
+}
+
+void machine__delete(struct machine *machine)
+{
+	machine__exit(machine);
+	free(machine);
+}
+
+struct machine *machines__add(struct rb_root *machines, pid_t pid,
+			      const char *root_dir)
+{
+	struct rb_node **p = &machines->rb_node;
+	struct rb_node *parent = NULL;
+	struct machine *pos, *machine = malloc(sizeof(*machine));
+
+	if (machine == NULL)
+		return NULL;
+
+	if (machine__init(machine, root_dir, pid) != 0) {
+		free(machine);
+		return NULL;
+	}
+
+	while (*p != NULL) {
+		parent = *p;
+		pos = rb_entry(parent, struct machine, rb_node);
+		if (pid < pos->pid)
+			p = &(*p)->rb_left;
+		else
+			p = &(*p)->rb_right;
+	}
+
+	rb_link_node(&machine->rb_node, parent, p);
+	rb_insert_color(&machine->rb_node, machines);
+
+	return machine;
+}
+
+struct machine *machines__find(struct rb_root *machines, pid_t pid)
+{
+	struct rb_node **p = &machines->rb_node;
+	struct rb_node *parent = NULL;
+	struct machine *machine;
+	struct machine *default_machine = NULL;
+
+	while (*p != NULL) {
+		parent = *p;
+		machine = rb_entry(parent, struct machine, rb_node);
+		if (pid < machine->pid)
+			p = &(*p)->rb_left;
+		else if (pid > machine->pid)
+			p = &(*p)->rb_right;
+		else
+			return machine;
+		if (!machine->pid)
+			default_machine = machine;
+	}
+
+	return default_machine;
+}
+
+struct machine *machines__findnew(struct rb_root *machines, pid_t pid)
+{
+	char path[PATH_MAX];
+	const char *root_dir = "";
+	struct machine *machine = machines__find(machines, pid);
+
+	if (machine && (machine->pid == pid))
+		goto out;
+
+	if ((pid != HOST_KERNEL_ID) &&
+	    (pid != DEFAULT_GUEST_KERNEL_ID) &&
+	    (symbol_conf.guestmount)) {
+		sprintf(path, "%s/%d", symbol_conf.guestmount, pid);
+		if (access(path, R_OK)) {
+			static struct strlist *seen;
+
+			if (!seen)
+				seen = strlist__new(true, NULL);
+
+			if (!strlist__has_entry(seen, path)) {
+				pr_err("Can't access file %s\n", path);
+				strlist__add(seen, path);
+			}
+			machine = NULL;
+			goto out;
+		}
+		root_dir = path;
+	}
+
+	machine = machines__add(machines, pid, root_dir);
+out:
+	return machine;
+}
+
+void machines__process(struct rb_root *machines,
+		       machine__process_t process, void *data)
+{
+	struct rb_node *nd;
+
+	for (nd = rb_first(machines); nd; nd = rb_next(nd)) {
+		struct machine *pos = rb_entry(nd, struct machine, rb_node);
+		process(pos, data);
+	}
+}
+
+char *machine__mmap_name(struct machine *machine, char *bf, size_t size)
+{
+	if (machine__is_host(machine))
+		snprintf(bf, size, "[%s]", "kernel.kallsyms");
+	else if (machine__is_default_guest(machine))
+		snprintf(bf, size, "[%s]", "guest.kernel.kallsyms");
+	else {
+		snprintf(bf, size, "[%s.%d]", "guest.kernel.kallsyms",
+			 machine->pid);
+	}
+
+	return bf;
+}
+
+void machines__set_id_hdr_size(struct rb_root *machines, u16 id_hdr_size)
+{
+	struct rb_node *node;
+	struct machine *machine;
+
+	for (node = rb_first(machines); node; node = rb_next(node)) {
+		machine = rb_entry(node, struct machine, rb_node);
+		machine->id_hdr_size = id_hdr_size;
+	}
+
+	return;
+}
+
 static struct thread *__machine__findnew_thread(struct machine *machine, pid_t pid,
 						bool create)
 {

commit 4552cf0f774ae3d24bf31e91324586274a552a66
Author: Namhyung Kim <namhyung.kim@lge.com>
Date:   Wed Nov 7 16:27:10 2012 +0900

    perf machine: Set kernel data mapping length
    
    Currently only text (function) mapping was set, so that the kernel data
    addresses couldn't parsed correctly.  Fix it.
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1352273234-28912-3-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 502eec0d4773..4c6754ac6b20 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -84,15 +84,19 @@ int machine__process_lost_event(struct machine *machine __maybe_unused,
 static void machine__set_kernel_mmap_len(struct machine *machine,
 					 union perf_event *event)
 {
-	machine->vmlinux_maps[MAP__FUNCTION]->start = event->mmap.start;
-	machine->vmlinux_maps[MAP__FUNCTION]->end   = (event->mmap.start +
-						       event->mmap.len);
-	/*
-	 * Be a bit paranoid here, some perf.data file came with
-	 * a zero sized synthesized MMAP event for the kernel.
-	 */
-	if (machine->vmlinux_maps[MAP__FUNCTION]->end == 0)
-		machine->vmlinux_maps[MAP__FUNCTION]->end = ~0ULL;
+	int i;
+
+	for (i = 0; i < MAP__NR_TYPES; i++) {
+		machine->vmlinux_maps[i]->start = event->mmap.start;
+		machine->vmlinux_maps[i]->end   = (event->mmap.start +
+						   event->mmap.len);
+		/*
+		 * Be a bit paranoid here, some perf.data file came with
+		 * a zero sized synthesized MMAP event for the kernel.
+		 */
+		if (machine->vmlinux_maps[i]->end == 0)
+			machine->vmlinux_maps[i]->end = ~0ULL;
+	}
 }
 
 static int machine__process_kernel_mmap_event(struct machine *machine,

commit b0a7d1a0cd2e228dc06d099db2e1bb02f1b7d591
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sat Oct 6 16:26:02 2012 -0300

    perf machine: Carve up event processing specific from perf_tool
    
    The perf_tool vtable expects methods that receive perf_tool and
    perf_sample entries, but for tools not interested in doing any special
    processing on non PERF_RECORD_SAMPLE events, like 'perf top', and for
    those not using perf_session, like 'perf trace', they were using
    perf_event__process passing tool and sample paramenters that were just
    not used.
    
    Provide 'machine' methods for this purpose and make the perf_event
    ones use them.
    
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-ot9cc6mt025o8kbngzckcrx9@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
index 9d36d7eeda92..502eec0d4773 100644
--- a/tools/perf/util/machine.c
+++ b/tools/perf/util/machine.c
@@ -1,3 +1,5 @@
+#include "debug.h"
+#include "event.h"
 #include "machine.h"
 #include "map.h"
 #include "thread.h"
@@ -55,3 +57,221 @@ struct thread *machine__find_thread(struct machine *machine, pid_t pid)
 {
 	return __machine__findnew_thread(machine, pid, false);
 }
+
+int machine__process_comm_event(struct machine *machine, union perf_event *event)
+{
+	struct thread *thread = machine__findnew_thread(machine, event->comm.tid);
+
+	if (dump_trace)
+		perf_event__fprintf_comm(event, stdout);
+
+	if (thread == NULL || thread__set_comm(thread, event->comm.comm)) {
+		dump_printf("problem processing PERF_RECORD_COMM, skipping event.\n");
+		return -1;
+	}
+
+	return 0;
+}
+
+int machine__process_lost_event(struct machine *machine __maybe_unused,
+				union perf_event *event)
+{
+	dump_printf(": id:%" PRIu64 ": lost:%" PRIu64 "\n",
+		    event->lost.id, event->lost.lost);
+	return 0;
+}
+
+static void machine__set_kernel_mmap_len(struct machine *machine,
+					 union perf_event *event)
+{
+	machine->vmlinux_maps[MAP__FUNCTION]->start = event->mmap.start;
+	machine->vmlinux_maps[MAP__FUNCTION]->end   = (event->mmap.start +
+						       event->mmap.len);
+	/*
+	 * Be a bit paranoid here, some perf.data file came with
+	 * a zero sized synthesized MMAP event for the kernel.
+	 */
+	if (machine->vmlinux_maps[MAP__FUNCTION]->end == 0)
+		machine->vmlinux_maps[MAP__FUNCTION]->end = ~0ULL;
+}
+
+static int machine__process_kernel_mmap_event(struct machine *machine,
+					      union perf_event *event)
+{
+	struct map *map;
+	char kmmap_prefix[PATH_MAX];
+	enum dso_kernel_type kernel_type;
+	bool is_kernel_mmap;
+
+	machine__mmap_name(machine, kmmap_prefix, sizeof(kmmap_prefix));
+	if (machine__is_host(machine))
+		kernel_type = DSO_TYPE_KERNEL;
+	else
+		kernel_type = DSO_TYPE_GUEST_KERNEL;
+
+	is_kernel_mmap = memcmp(event->mmap.filename,
+				kmmap_prefix,
+				strlen(kmmap_prefix) - 1) == 0;
+	if (event->mmap.filename[0] == '/' ||
+	    (!is_kernel_mmap && event->mmap.filename[0] == '[')) {
+
+		char short_module_name[1024];
+		char *name, *dot;
+
+		if (event->mmap.filename[0] == '/') {
+			name = strrchr(event->mmap.filename, '/');
+			if (name == NULL)
+				goto out_problem;
+
+			++name; /* skip / */
+			dot = strrchr(name, '.');
+			if (dot == NULL)
+				goto out_problem;
+			snprintf(short_module_name, sizeof(short_module_name),
+					"[%.*s]", (int)(dot - name), name);
+			strxfrchar(short_module_name, '-', '_');
+		} else
+			strcpy(short_module_name, event->mmap.filename);
+
+		map = machine__new_module(machine, event->mmap.start,
+					  event->mmap.filename);
+		if (map == NULL)
+			goto out_problem;
+
+		name = strdup(short_module_name);
+		if (name == NULL)
+			goto out_problem;
+
+		map->dso->short_name = name;
+		map->dso->sname_alloc = 1;
+		map->end = map->start + event->mmap.len;
+	} else if (is_kernel_mmap) {
+		const char *symbol_name = (event->mmap.filename +
+				strlen(kmmap_prefix));
+		/*
+		 * Should be there already, from the build-id table in
+		 * the header.
+		 */
+		struct dso *kernel = __dsos__findnew(&machine->kernel_dsos,
+						     kmmap_prefix);
+		if (kernel == NULL)
+			goto out_problem;
+
+		kernel->kernel = kernel_type;
+		if (__machine__create_kernel_maps(machine, kernel) < 0)
+			goto out_problem;
+
+		machine__set_kernel_mmap_len(machine, event);
+
+		/*
+		 * Avoid using a zero address (kptr_restrict) for the ref reloc
+		 * symbol. Effectively having zero here means that at record
+		 * time /proc/sys/kernel/kptr_restrict was non zero.
+		 */
+		if (event->mmap.pgoff != 0) {
+			maps__set_kallsyms_ref_reloc_sym(machine->vmlinux_maps,
+							 symbol_name,
+							 event->mmap.pgoff);
+		}
+
+		if (machine__is_default_guest(machine)) {
+			/*
+			 * preload dso of guest kernel and modules
+			 */
+			dso__load(kernel, machine->vmlinux_maps[MAP__FUNCTION],
+				  NULL);
+		}
+	}
+	return 0;
+out_problem:
+	return -1;
+}
+
+int machine__process_mmap_event(struct machine *machine, union perf_event *event)
+{
+	u8 cpumode = event->header.misc & PERF_RECORD_MISC_CPUMODE_MASK;
+	struct thread *thread;
+	struct map *map;
+	int ret = 0;
+
+	if (dump_trace)
+		perf_event__fprintf_mmap(event, stdout);
+
+	if (cpumode == PERF_RECORD_MISC_GUEST_KERNEL ||
+	    cpumode == PERF_RECORD_MISC_KERNEL) {
+		ret = machine__process_kernel_mmap_event(machine, event);
+		if (ret < 0)
+			goto out_problem;
+		return 0;
+	}
+
+	thread = machine__findnew_thread(machine, event->mmap.pid);
+	if (thread == NULL)
+		goto out_problem;
+	map = map__new(&machine->user_dsos, event->mmap.start,
+			event->mmap.len, event->mmap.pgoff,
+			event->mmap.pid, event->mmap.filename,
+			MAP__FUNCTION);
+	if (map == NULL)
+		goto out_problem;
+
+	thread__insert_map(thread, map);
+	return 0;
+
+out_problem:
+	dump_printf("problem processing PERF_RECORD_MMAP, skipping event.\n");
+	return 0;
+}
+
+int machine__process_fork_event(struct machine *machine, union perf_event *event)
+{
+	struct thread *thread = machine__findnew_thread(machine, event->fork.tid);
+	struct thread *parent = machine__findnew_thread(machine, event->fork.ptid);
+
+	if (dump_trace)
+		perf_event__fprintf_task(event, stdout);
+
+	if (thread == NULL || parent == NULL ||
+	    thread__fork(thread, parent) < 0) {
+		dump_printf("problem processing PERF_RECORD_FORK, skipping event.\n");
+		return -1;
+	}
+
+	return 0;
+}
+
+int machine__process_exit_event(struct machine *machine, union perf_event *event)
+{
+	struct thread *thread = machine__find_thread(machine, event->fork.tid);
+
+	if (dump_trace)
+		perf_event__fprintf_task(event, stdout);
+
+	if (thread != NULL)
+		machine__remove_thread(machine, thread);
+
+	return 0;
+}
+
+int machine__process_event(struct machine *machine, union perf_event *event)
+{
+	int ret;
+
+	switch (event->header.type) {
+	case PERF_RECORD_COMM:
+		ret = machine__process_comm_event(machine, event); break;
+	case PERF_RECORD_MMAP:
+		ret = machine__process_mmap_event(machine, event); break;
+	case PERF_RECORD_FORK:
+		ret = machine__process_fork_event(machine, event); break;
+	case PERF_RECORD_EXIT:
+		ret = machine__process_exit_event(machine, event); break;
+	case PERF_RECORD_LOST:
+		ret = machine__process_lost_event(machine, event); break;
+	default:
+		ret = -1;
+		break;
+	}
+
+	return ret;
+}

commit 9d2f8e22fc965bcdd5561d000d234fe2d23657ba
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sat Oct 6 15:43:20 2012 -0300

    perf machine: Introduce find_thread method
    
    There are cases where we want just to find a thread if it exists
    already, so provide a method for that.
    
    While doing that start moving 'machine' methods to a separate file.
    
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-8wpzqs9kfupng6xq8hx6lnxa@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/machine.c b/tools/perf/util/machine.c
new file mode 100644
index 000000000000..9d36d7eeda92
--- /dev/null
+++ b/tools/perf/util/machine.c
@@ -0,0 +1,57 @@
+#include "machine.h"
+#include "map.h"
+#include "thread.h"
+#include <stdbool.h>
+
+static struct thread *__machine__findnew_thread(struct machine *machine, pid_t pid,
+						bool create)
+{
+	struct rb_node **p = &machine->threads.rb_node;
+	struct rb_node *parent = NULL;
+	struct thread *th;
+
+	/*
+	 * Font-end cache - PID lookups come in blocks,
+	 * so most of the time we dont have to look up
+	 * the full rbtree:
+	 */
+	if (machine->last_match && machine->last_match->pid == pid)
+		return machine->last_match;
+
+	while (*p != NULL) {
+		parent = *p;
+		th = rb_entry(parent, struct thread, rb_node);
+
+		if (th->pid == pid) {
+			machine->last_match = th;
+			return th;
+		}
+
+		if (pid < th->pid)
+			p = &(*p)->rb_left;
+		else
+			p = &(*p)->rb_right;
+	}
+
+	if (!create)
+		return NULL;
+
+	th = thread__new(pid);
+	if (th != NULL) {
+		rb_link_node(&th->rb_node, parent, p);
+		rb_insert_color(&th->rb_node, &machine->threads);
+		machine->last_match = th;
+	}
+
+	return th;
+}
+
+struct thread *machine__findnew_thread(struct machine *machine, pid_t pid)
+{
+	return __machine__findnew_thread(machine, pid, true);
+}
+
+struct thread *machine__find_thread(struct machine *machine, pid_t pid)
+{
+	return __machine__findnew_thread(machine, pid, false);
+}
