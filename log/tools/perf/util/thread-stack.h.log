commit 3749e0bbdef24efbf1698bf0dbd9575fddb9ed22
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Wed Apr 29 18:07:48 2020 +0300

    perf thread-stack: Add thread_stack__br_sample_late()
    
    Add a thread stack function to create a branch stack for hardware events
    where the sample records get created some time after the event occurred.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Link: http://lore.kernel.org/lkml/20200429150751.12570-7-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/thread-stack.h b/tools/perf/util/thread-stack.h
index c279a0cbbdd0..3bc47a42af8e 100644
--- a/tools/perf/util/thread-stack.h
+++ b/tools/perf/util/thread-stack.h
@@ -91,6 +91,9 @@ void thread_stack__sample_late(struct thread *thread, int cpu,
 			       u64 kernel_start);
 void thread_stack__br_sample(struct thread *thread, int cpu,
 			     struct branch_stack *dst, unsigned int sz);
+void thread_stack__br_sample_late(struct thread *thread, int cpu,
+				  struct branch_stack *dst, unsigned int sz,
+				  u64 sample_ip, u64 kernel_start);
 int thread_stack__flush(struct thread *thread);
 void thread_stack__free(struct thread *thread);
 size_t thread_stack__depth(struct thread *thread, int cpu);

commit 86d67180b920d178ae1c2923f50a0759d6ce1a10
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Wed Apr 29 18:07:43 2020 +0300

    perf thread-stack: Add branch stack support
    
    Intel PT already has support for creating branch stacks for each context
    (per-cpu or per-thread). In the more common per-cpu case, the branch stack
    is not separated for different threads, instead being cleared in between
    each sample.
    
    That approach will not work very well for adding branch stacks to
    regular events. The branch stacks really need to be accumulated
    separately for each thread.
    
    As a start to accomplishing that, this patch adds support for putting
    branch stack support into the thread-stack. The advantages are:
    
    1. the branches are accumulated separately for each thread
    2. the branch stack is cleared only in between continuous traces
    
    This helps pave the way for adding branch stacks to regular events, not
    just synthesized events as at present.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Link: http://lore.kernel.org/lkml/20200429150751.12570-2-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/thread-stack.h b/tools/perf/util/thread-stack.h
index 8962ddc4e1ab..c279a0cbbdd0 100644
--- a/tools/perf/util/thread-stack.h
+++ b/tools/perf/util/thread-stack.h
@@ -81,13 +81,16 @@ struct call_return_processor {
 };
 
 int thread_stack__event(struct thread *thread, int cpu, u32 flags, u64 from_ip,
-			u64 to_ip, u16 insn_len, u64 trace_nr);
+			u64 to_ip, u16 insn_len, u64 trace_nr, bool callstack,
+			unsigned int br_stack_sz, bool mispred_all);
 void thread_stack__set_trace_nr(struct thread *thread, int cpu, u64 trace_nr);
 void thread_stack__sample(struct thread *thread, int cpu, struct ip_callchain *chain,
 			  size_t sz, u64 ip, u64 kernel_start);
 void thread_stack__sample_late(struct thread *thread, int cpu,
 			       struct ip_callchain *chain, size_t sz, u64 ip,
 			       u64 kernel_start);
+void thread_stack__br_sample(struct thread *thread, int cpu,
+			     struct branch_stack *dst, unsigned int sz);
 int thread_stack__flush(struct thread *thread);
 void thread_stack__free(struct thread *thread);
 size_t thread_stack__depth(struct thread *thread, int cpu);

commit 4fef41bfb1d8d2ada4a18eb3ab80c2682bcbae12
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Wed Apr 1 13:16:06 2020 +0300

    perf thread-stack: Add thread_stack__sample_late()
    
    Add a thread stack function to create a call chain for hardware events
    where the sample records get created some time after the event occurred.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Link: http://lore.kernel.org/lkml/20200401101613.6201-10-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/thread-stack.h b/tools/perf/util/thread-stack.h
index e1ec5a58f1b2..8962ddc4e1ab 100644
--- a/tools/perf/util/thread-stack.h
+++ b/tools/perf/util/thread-stack.h
@@ -85,6 +85,9 @@ int thread_stack__event(struct thread *thread, int cpu, u32 flags, u64 from_ip,
 void thread_stack__set_trace_nr(struct thread *thread, int cpu, u64 trace_nr);
 void thread_stack__sample(struct thread *thread, int cpu, struct ip_callchain *chain,
 			  size_t sz, u64 ip, u64 kernel_start);
+void thread_stack__sample_late(struct thread *thread, int cpu,
+			       struct ip_callchain *chain, size_t sz, u64 ip,
+			       u64 kernel_start);
 int thread_stack__flush(struct thread *thread);
 void thread_stack__free(struct thread *thread);
 size_t thread_stack__depth(struct thread *thread, int cpu);

commit 3ce5aceb5dee298b082adfa2baa0df5a447c1b0b
Merge: d0e1a507bdc7 04c41bcb862b
Author: Ingo Molnar <mingo@kernel.org>
Date:   Mon Jun 17 20:48:14 2019 +0200

    Merge tag 'perf-core-for-mingo-5.3-20190611' of git://git.kernel.org/pub/scm/linux/kernel/git/acme/linux into perf/core
    
    Pull perf/core improvements and fixes from Arnaldo Carvalho de Melo:
    
    perf record:
    
      Alexey Budankov:
    
      - Allow mixing --user-regs with --call-graph=dwarf, making sure that
        the minimal set of registers for DWARF unwinding is present in the
        set of user registers requested to be present in each sample, while
        warning the user that this may make callchains unreliable if more
        that the minimal set of registers is needed to unwind.
    
      yuzhoujian:
    
      - Add support to collect callchains from kernel or user space only,
        IOW allow setting the perf_event_attr.exclude_callchain_{kernel,user}
        bits from the command line.
    
    perf trace:
    
      Arnaldo Carvalho de Melo:
    
      - Remove x86_64 specific syscall numbers from the augmented_raw_syscalls
        BPF in-kernel collector of augmented raw_syscalls:sys_{enter,exit}
        payloads, use instead the syscall numbers obtainer either by the
        arch specific syscalltbl generators or from audit-libs.
    
      - Allow 'perf trace' to ask for the number of bytes to collect for
        string arguments, for now ask for PATH_MAX, i.e. the whole
        pathnames, which ends up being just a way to speficy which syscall
        args are pathnames and thus should be read using bpf_probe_read_str().
    
      - Skip unknown syscalls when expanding strace like syscall groups.
        This helps using the 'string' group of syscalls to work in arm64,
        where some of the syscalls present in x86_64 that deal with
        strings, for instance 'access', are deprecated and this should not
        be asked for tracing.
    
      Leo Yan:
    
      - Exit when failing to build eBPF program.
    
    perf config:
    
      Arnaldo Carvalho de Melo:
    
      - Bail out when a handler returns failure for a key-value pair. This
        helps with cases where processing a key-value pair is not just a
        matter of setting some tool specific knob, involving, for instance
        building a BPF program to then attach to the list of events 'perf
        trace' will use, e.g. augmented_raw_syscalls.c.
    
    perf.data:
    
      Kan Liang:
    
      - Read and store die ID information available in new Intel processors
        in CPUID.1F in the CPU topology written in the perf.data header.
    
    perf stat:
    
      Kan Liang:
    
      - Support per-die aggregation.
    
    Documentation:
    
      Arnaldo Carvalho de Melo:
    
      - Update perf.data documentation about the CPU_TOPOLOGY, MEM_TOPOLOGY,
        CLOCKID and DIR_FORMAT headers.
    
      Song Liu:
    
      - Add description of headers HEADER_BPF_PROG_INFO and HEADER_BPF_BTF.
    
      Leo Yan:
    
      - Update default value for llvm.clang-bpf-cmd-template in 'man perf-config'.
    
    JVMTI:
    
      Jiri Olsa:
    
      - Address gcc string overflow warning for strncpy()
    
    core:
    
      - Remove superfluous nthreads system_wide setup in perf_evsel__alloc_fd().
    
    Intel PT:
    
      Adrian Hunter:
    
      - Add support for samples to contain IPC ratio, collecting cycles
        information from CYC packets, showing the IPC info periodically, because
        Intel PT does not update the cycle count on every branch or instruction,
        the incremental values will often be zero.  When there are values, they
        will be the number of instructions and number of cycles since the last
        update, and thus represent the average IPC since the last IPC value.
    
        E.g.:
    
        # perf record --cpu 1 -m200000 -a -e intel_pt/cyc/u sleep 0.0001
        rounding mmap pages size to 1024M (262144 pages)
        [ perf record: Woken up 0 times to write data ]
        [ perf record: Captured and wrote 2.208 MB perf.data ]
        # perf script --insn-trace --xed -F+ipc,-dso,-cpu,-tid
        #
        <SNIP + add line numbering to make sense of IPC counts e.g.: (18/3)>
        1   cc1 63501.650479626: 7f5219ac27bf _int_free+0x3f   jnz 0x7f5219ac2af0       IPC: 0.81 (36/44)
        2   cc1 63501.650479626: 7f5219ac27c5 _int_free+0x45   cmp $0x1f, %rbp
        3   cc1 63501.650479626: 7f5219ac27c9 _int_free+0x49   jbe 0x7f5219ac2b00
        4   cc1 63501.650479626: 7f5219ac27cf _int_free+0x4f   test $0x8, %al
        5   cc1 63501.650479626: 7f5219ac27d1 _int_free+0x51   jnz 0x7f5219ac2b00
        6   cc1 63501.650479626: 7f5219ac27d7 _int_free+0x57   movq  0x13c58a(%rip), %rcx
        7   cc1 63501.650479626: 7f5219ac27de _int_free+0x5e   mov %rdi, %r12
        8   cc1 63501.650479626: 7f5219ac27e1 _int_free+0x61   movq  %fs:(%rcx), %rax
        9   cc1 63501.650479626: 7f5219ac27e5 _int_free+0x65   test %rax, %rax
       10   cc1 63501.650479626: 7f5219ac27e8 _int_free+0x68   jz 0x7f5219ac2821
       11   cc1 63501.650479626: 7f5219ac27ea _int_free+0x6a   leaq  -0x11(%rbp), %rdi
       12   cc1 63501.650479626: 7f5219ac27ee _int_free+0x6e   mov %rdi, %rsi
       13   cc1 63501.650479626: 7f5219ac27f1 _int_free+0x71   shr $0x4, %rsi
       14   cc1 63501.650479626: 7f5219ac27f5 _int_free+0x75   cmpq  %rsi, 0x13caf4(%rip)
       15   cc1 63501.650479626: 7f5219ac27fc _int_free+0x7c   jbe 0x7f5219ac2821
       16   cc1 63501.650479626: 7f5219ac2821 _int_free+0xa1   cmpq  0x13f138(%rip), %rbp
       17   cc1 63501.650479626: 7f5219ac2828 _int_free+0xa8   jnbe 0x7f5219ac28d8
       18   cc1 63501.650479626: 7f5219ac28d8 _int_free+0x158  testb  $0x2, 0x8(%rbx)
       19   cc1 63501.650479628: 7f5219ac28dc _int_free+0x15c  jnz 0x7f5219ac2ab0       IPC: 6.00 (18/3)
        <SNIP>
    
      - Allow using time ranges with Intel PT, i.e. these features, already
        present but not optimially usable with Intel PT, should be now:
    
            Select the second 10% time slice:
    
            $ perf script --time 10%/2
    
            Select from 0% to 10% time slice:
    
            $ perf script --time 0%-10%
    
            Select the first and second 10% time slices:
    
            $ perf script --time 10%/1,10%/2
    
            Select from 0% to 10% and 30% to 40% slices:
    
            $ perf script --time 0%-10%,30%-40%
    
    cs-etm (ARM):
    
      Mathieu Poirier:
    
      - Add support for CPU-wide trace scenarios.
    
    s390:
    
      Thomas Richter:
    
      - Fix missing kvm module load for s390.
    
      - Fix OOM error in TUI mode on s390
    
      - Support s390 diag event display when doing analysis on !s390
        architectures.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 2025cf9e193de05b0654570dd639acb49ebd3adf
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed May 29 07:18:02 2019 -0700

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 288
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms and conditions of the gnu general public license
      version 2 as published by the free software foundation this program
      is distributed in the hope it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 263 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190529141901.208660670@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/tools/perf/util/thread-stack.h b/tools/perf/util/thread-stack.h
index 9c45f947f5a9..71e15d4ec533 100644
--- a/tools/perf/util/thread-stack.h
+++ b/tools/perf/util/thread-stack.h
@@ -1,16 +1,7 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
 /*
  * thread-stack.h: Synthesize a thread's stack using call / return events
  * Copyright (c) 2014, Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify it
- * under the terms and conditions of the GNU General Public License,
- * version 2, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
- * more details.
- *
  */
 
 #ifndef __PERF_THREAD_STACK_H

commit 003ccdc7165accee073ce261fc670f64cc98d0f7
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Mon May 20 14:37:19 2019 +0300

    perf thread-stack: Accumulate IPC information
    
    Cycle and instruction counts are added to the stack. The IPC of a
    function and all functions it calls, is also recorded.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Link: http://lkml.kernel.org/r/20190520113728.14389-14-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/thread-stack.h b/tools/perf/util/thread-stack.h
index 9c45f947f5a9..bddb1daf6453 100644
--- a/tools/perf/util/thread-stack.h
+++ b/tools/perf/util/thread-stack.h
@@ -52,6 +52,8 @@ enum {
  * @call_time: timestamp of call (if known)
  * @return_time: timestamp of return (if known)
  * @branch_count: number of branches seen between call and return
+ * @insn_count: approx. number of instructions between call and return
+ * @cyc_count: approx. number of cycles between call and return
  * @call_ref: external reference to 'call' sample (e.g. db_id)
  * @return_ref:  external reference to 'return' sample (e.g. db_id)
  * @db_id: id used for db-export
@@ -65,6 +67,8 @@ struct call_return {
 	u64 call_time;
 	u64 return_time;
 	u64 branch_count;
+	u64 insn_count;
+	u64 cyc_count;
 	u64 call_ref;
 	u64 return_ref;
 	u64 db_id;

commit f435887ec0c941b97301bd6ed1f3e4b5200df409
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Thu Feb 28 15:00:24 2019 +0200

    perf db-export: Add calls parent_id to enable creation of call trees
    
    The call_path can be used to find the parent symbol for a call but not
    the exact parent call. To do that add parent_id to the call_return
    export. This enables the creation of a call tree from the exported data.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Link: https://lkml.kernel.org/n/tip-6j7tzdxo67cox6kan7k22oo6@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/thread-stack.h b/tools/perf/util/thread-stack.h
index b7c04e19ad41..9c45f947f5a9 100644
--- a/tools/perf/util/thread-stack.h
+++ b/tools/perf/util/thread-stack.h
@@ -55,6 +55,7 @@ enum {
  * @call_ref: external reference to 'call' sample (e.g. db_id)
  * @return_ref:  external reference to 'return' sample (e.g. db_id)
  * @db_id: id used for db-export
+ * @parent_db_id: id of parent call used for db-export
  * @flags: Call/Return flags
  */
 struct call_return {
@@ -67,6 +68,7 @@ struct call_return {
 	u64 call_ref;
 	u64 return_ref;
 	u64 db_id;
+	u64 parent_db_id;
 	u32 flags;
 };
 
@@ -79,7 +81,7 @@ struct call_return {
  */
 struct call_return_processor {
 	struct call_path_root *cpr;
-	int (*process)(struct call_return *cr, void *data);
+	int (*process)(struct call_return *cr, u64 *parent_db_id, void *data);
 	void *data;
 };
 
@@ -93,7 +95,7 @@ void thread_stack__free(struct thread *thread);
 size_t thread_stack__depth(struct thread *thread, int cpu);
 
 struct call_return_processor *
-call_return_processor__new(int (*process)(struct call_return *cr, void *data),
+call_return_processor__new(int (*process)(struct call_return *cr, u64 *parent_db_id, void *data),
 			   void *data);
 void call_return_processor__free(struct call_return_processor *crp);
 int thread_stack__process(struct thread *thread, struct comm *comm,

commit f08046cb3082b313e7b08dc35838cf8bd902c36b
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Wed Jan 9 11:18:33 2019 +0200

    perf thread-stack: Represent jmps to the start of a different symbol
    
    The compiler might optimize a call/ret combination by making it a jmp.
    However the thread-stack does not presently cater for that, so that such
    control flow is not visible in the call graph. Make it visible by
    recording on the stack a branch to the start of a different symbol.
    Note, that means when a ret pops the stack, all jmps must be popped off
    first.
    
    Example:
    
      $ cat jmp-to-fn.c
      __attribute__((noinline)) int bar(void)
      {
              return -1;
      }
    
      __attribute__((noinline)) int foo(void)
      {
              return bar() + 1;
      }
    
      int main()
      {
              return foo();
      }
      $ gcc -ggdb3 -Wall -Wextra -O2 -o jmp-to-fn jmp-to-fn.c
      $ objdump -d jmp-to-fn
      <SNIP>
      0000000000001040 <main>:
          1040:       31 c0                   xor    %eax,%eax
          1042:       e9 09 01 00 00          jmpq   1150 <foo>
      <SNIP>
      0000000000001140 <bar>:
          1140:       b8 ff ff ff ff          mov    $0xffffffff,%eax
          1145:       c3                      retq
      <SNIP>
      0000000000001150 <foo>:
          1150:       31 c0                   xor    %eax,%eax
          1152:       e8 e9 ff ff ff          callq  1140 <bar>
          1157:       83 c0 01                add    $0x1,%eax
          115a:       c3                      retq
      <SNIP>
      $ perf record -o jmp-to-fn.perf.data -e intel_pt/cyc/u ./jmp-to-fn
      [ perf record: Woken up 1 times to write data ]
      [ perf record: Captured and wrote 0,017 MB jmp-to-fn.perf.data ]
      $ perf script -i jmp-to-fn.perf.data --itrace=be -s ~/libexec/perf-core/scripts/python/export-to-sqlite.py jmp-to-fn.db branches calls
      2019-01-08 13:24:58.783069 Creating database...
      2019-01-08 13:24:58.794650 Writing records...
      2019-01-08 13:24:59.008050 Adding indexes
      2019-01-08 13:24:59.015802 Done
      $  ~/libexec/perf-core/scripts/python/exported-sql-viewer.py jmp-to-fn.db
    
    Before:
    
        main
            -> bar
    
    After:
    
        main
            -> foo
                -> bar
    
    Committer testing:
    
    Install the python2-pyside package, then select these menu options
    on the GUI:
    
       "Reports"
          "Context sensitive callgraphs"
    
    Then go on expanding the symbols, to get, full picture when doing this
    on a fedora:29 with gcc version 8.2.1 20181215 (Red Hat 8.2.1-6) (GCC):
    
    jmp-to-fn
      PID:TID
        _start                (ld-2.28.so)
          __libc_start_main
            main
              foo
                bar
    
    To verify that indeed, this fixes the problem.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Link: http://lkml.kernel.org/r/20190109091835.5570-5-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/thread-stack.h b/tools/perf/util/thread-stack.h
index 1f626f4a1c40..b7c04e19ad41 100644
--- a/tools/perf/util/thread-stack.h
+++ b/tools/perf/util/thread-stack.h
@@ -35,10 +35,13 @@ struct call_path;
  *
  * CALL_RETURN_NO_CALL: 'return' but no matching 'call'
  * CALL_RETURN_NO_RETURN: 'call' but no matching 'return'
+ * CALL_RETURN_NON_CALL: a branch but not a 'call' to the start of a different
+ *                       symbol
  */
 enum {
 	CALL_RETURN_NO_CALL	= 1 << 0,
 	CALL_RETURN_NO_RETURN	= 1 << 1,
+	CALL_RETURN_NON_CALL	= 1 << 2,
 };
 
 /**

commit 256d92bc93fd40411a02be5cdba74a7bf91e6e09
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Fri Dec 21 14:06:19 2018 +0200

    perf thread-stack: Fix thread stack processing for the idle task
    
    perf creates a single 'struct thread' to represent the idle task. That
    is because threads are identified by PID and TID, and the idle task
    always has PID == TID == 0.
    
    However, there are actually separate idle tasks for each CPU. That
    creates a problem for thread stack processing which assumes that each
    thread has a single stack, not one stack per CPU.
    
    Fix that by passing through the CPU number, and in the case of the idle
    "thread", pick the thread stack from an array based on the CPU number.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Link: http://lkml.kernel.org/r/20181221120620.9659-8-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/thread-stack.h b/tools/perf/util/thread-stack.h
index f97c00a8c251..1f626f4a1c40 100644
--- a/tools/perf/util/thread-stack.h
+++ b/tools/perf/util/thread-stack.h
@@ -80,14 +80,14 @@ struct call_return_processor {
 	void *data;
 };
 
-int thread_stack__event(struct thread *thread, u32 flags, u64 from_ip,
+int thread_stack__event(struct thread *thread, int cpu, u32 flags, u64 from_ip,
 			u64 to_ip, u16 insn_len, u64 trace_nr);
-void thread_stack__set_trace_nr(struct thread *thread, u64 trace_nr);
-void thread_stack__sample(struct thread *thread, struct ip_callchain *chain,
+void thread_stack__set_trace_nr(struct thread *thread, int cpu, u64 trace_nr);
+void thread_stack__sample(struct thread *thread, int cpu, struct ip_callchain *chain,
 			  size_t sz, u64 ip, u64 kernel_start);
 int thread_stack__flush(struct thread *thread);
 void thread_stack__free(struct thread *thread);
-size_t thread_stack__depth(struct thread *thread);
+size_t thread_stack__depth(struct thread *thread, int cpu);
 
 struct call_return_processor *
 call_return_processor__new(int (*process)(struct call_return *cr, void *data),

commit 242483068b4b9ad02f1653819b6e683577681e0e
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Wed Oct 31 11:10:42 2018 +0200

    perf intel-pt: Insert callchain context into synthesized callchains
    
    In the absence of a fallback, callchains must encode also the callchain
    context. Do that now there is no fallback.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Reviewed-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Leo Yan <leo.yan@linaro.org>
    Cc: Mathieu Poirier <mathieu.poirier@linaro.org>
    Cc: stable@vger.kernel.org # 4.19
    Link: http://lkml.kernel.org/r/100ea2ec-ed14-b56d-d810-e0a6d2f4b069@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/thread-stack.h b/tools/perf/util/thread-stack.h
index b7e41c4ebfdd..f97c00a8c251 100644
--- a/tools/perf/util/thread-stack.h
+++ b/tools/perf/util/thread-stack.h
@@ -84,7 +84,7 @@ int thread_stack__event(struct thread *thread, u32 flags, u64 from_ip,
 			u64 to_ip, u16 insn_len, u64 trace_nr);
 void thread_stack__set_trace_nr(struct thread *thread, u64 trace_nr);
 void thread_stack__sample(struct thread *thread, struct ip_callchain *chain,
-			  size_t sz, u64 ip);
+			  size_t sz, u64 ip, u64 kernel_start);
 int thread_stack__flush(struct thread *thread);
 void thread_stack__free(struct thread *thread);
 size_t thread_stack__depth(struct thread *thread);

commit e216708d982a1c262f411fee2fcac2bd9ec93a32
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Thu Jun 23 16:40:58 2016 +0300

    perf script: Add callindent option
    
    Based on patches from Andi Kleen.
    
    When printing PT instruction traces with perf script it is rather useful
    to see some indentation for the call tree. This patch adds a new
    callindent field to perf script that prints spaces for the function call
    stack depth.
    
    We already have code to track the function call stack for PT, that we
    can reuse with minor modifications.
    
    The resulting output is not quite as nice as ftrace yet, but a lot
    better than what was there before.
    
    Note there are some corner cases when the thread stack gets code
    confused and prints incorrect indentation. Even with that it is fairly
    useful.
    
    When displaying kernel code traces it is recommended to run as root, as
    otherwise perf doesn't understand the kernel addresses properly, and may
    not reset the call stack correctly on kernel boundaries.
    
    Example output:
    
            sudo perf-with-kcore record eg2 -a -e intel_pt// -- sleep 1
            sudo perf-with-kcore script eg2 --ns -F callindent,time,comm,pid,sym,ip,addr,flags,cpu --itrace=cre | less
            ...
             swapper     0 [000]  5830.389116586:   call        irq_exit                                                     ffffffff8104d620 smp_call_function_single_interrupt+0x30 => ffffffff8107e720 irq_exit
             swapper     0 [000]  5830.389116586:   call            idle_cpu                                                 ffffffff8107e769 irq_exit+0x49 => ffffffff810a3970 idle_cpu
             swapper     0 [000]  5830.389116586:   return          idle_cpu                                                 ffffffff810a39b7 idle_cpu+0x47 => ffffffff8107e76e irq_exit
             swapper     0 [000]  5830.389116586:   call            tick_nohz_irq_exit                                       ffffffff8107e7bd irq_exit+0x9d => ffffffff810f2fc0 tick_nohz_irq_exit
             swapper     0 [000]  5830.389116919:   call                __tick_nohz_idle_enter                               ffffffff810f2fe0 tick_nohz_irq_exit+0x20 => ffffffff810f28d0 __tick_nohz_idle_enter
             swapper     0 [000]  5830.389116919:   call                    ktime_get                                        ffffffff810f28f1 __tick_nohz_idle_enter+0x21 => ffffffff810e9ec0 ktime_get
             swapper     0 [000]  5830.389116919:   call                        read_tsc                                     ffffffff810e9ef6 ktime_get+0x36 => ffffffff81035070 read_tsc
             swapper     0 [000]  5830.389116919:   return                      read_tsc                                     ffffffff81035084 read_tsc+0x14 => ffffffff810e9efc ktime_get
             swapper     0 [000]  5830.389116919:   return                  ktime_get                                        ffffffff810e9f46 ktime_get+0x86 => ffffffff810f28f6 __tick_nohz_idle_enter
             swapper     0 [000]  5830.389116919:   call                    sched_clock_idle_sleep_event                     ffffffff810f290b __tick_nohz_idle_enter+0x3b => ffffffff810a7380 sched_clock_idle_sleep_event
             swapper     0 [000]  5830.389116919:   call                        sched_clock_cpu                              ffffffff810a738b sched_clock_idle_sleep_event+0xb => ffffffff810a72e0 sched_clock_cpu
             swapper     0 [000]  5830.389116919:   call                            sched_clock                              ffffffff810a734d sched_clock_cpu+0x6d => ffffffff81035750 sched_clock
             swapper     0 [000]  5830.389116919:   call                                native_sched_clock                   ffffffff81035754 sched_clock+0x4 => ffffffff81035640 native_sched_clock
             swapper     0 [000]  5830.389116919:   return                              native_sched_clock                   ffffffff8103568c native_sched_clock+0x4c => ffffffff81035759 sched_clock
             swapper     0 [000]  5830.389116919:   return                          sched_clock                              ffffffff8103575c sched_clock+0xc => ffffffff810a7352 sched_clock_cpu
             swapper     0 [000]  5830.389116919:   return                      sched_clock_cpu                              ffffffff810a7356 sched_clock_cpu+0x76 => ffffffff810a7390 sched_clock_idle_sleep_event
             swapper     0 [000]  5830.389116919:   return                  sched_clock_idle_sleep_event                     ffffffff810a7391 sched_clock_idle_sleep_event+0x11 => ffffffff810f2910 __tick_nohz_idle_enter
            ...
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Acked-by: Andi Kleen <ak@linux.intel.com>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Link: http://lkml.kernel.org/r/1466689258-28493-4-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/thread-stack.h b/tools/perf/util/thread-stack.h
index ad44c7944b8e..b7e41c4ebfdd 100644
--- a/tools/perf/util/thread-stack.h
+++ b/tools/perf/util/thread-stack.h
@@ -87,6 +87,7 @@ void thread_stack__sample(struct thread *thread, struct ip_callchain *chain,
 			  size_t sz, u64 ip);
 int thread_stack__flush(struct thread *thread);
 void thread_stack__free(struct thread *thread);
+size_t thread_stack__depth(struct thread *thread);
 
 struct call_return_processor *
 call_return_processor__new(int (*process)(struct call_return *cr, void *data),

commit 2c15f5eb04e9e7e19a2c8be6b50c63a4c6062a44
Author: Chris Phlipot <cphlipot0@gmail.com>
Date:   Thu Apr 28 01:19:10 2016 -0700

    perf script: Expose usage of the callchain db export via the python api
    
    This change allows python scripts to be able to utilize the recent
    changes to the db export api allowing the export of call_paths derived
    from sampled callchains. These call paths are also now associated with
    the samples from which they were derived.
    
    - This feature is enabled by setting "perf_db_export_callchains" to true
    
    - When enabled, samples that have callchain information will have the
      callchains exported via call_path_table
    
    - The call_path_id field is added to sample_table to enable association of
      samples with the corresponding callchain stored in the call paths
      table. A call_path_id of 0 will be exported if there is no
      corresponding callchain.
    
    - When "perf_db_export_callchains" and "perf_db_export_calls" are both
      set to True, the call path root data structure will be shared. This
      prevents duplicating of data and call path ids that would result from
      building two separate call path trees in memory.
    
    - The call_return_processor structure definition was relocated to the header
      file to make its contents visible to db-export.c. This enables the
      sharing of call path trees between the two features, as mentioned
      above.
    
    This change is visible to python scripts using the python db export api.
    
    The change is backwards compatible with scripts written against the
    previous API, assuming that the scripts model the sample_table function
    after the one in export-to-postgresql.py script by allowing for
    additional arguments to be added in the future. ie. using *x as the
    final argument of the sample_table function.
    
    Signed-off-by: Chris Phlipot <cphlipot0@gmail.com>
    Acked-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1461831551-12213-6-git-send-email-cphlipot0@gmail.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/thread-stack.h b/tools/perf/util/thread-stack.h
index ec9beddfdbab..ad44c7944b8e 100644
--- a/tools/perf/util/thread-stack.h
+++ b/tools/perf/util/thread-stack.h
@@ -25,7 +25,6 @@ struct comm;
 struct ip_callchain;
 struct symbol;
 struct dso;
-struct call_return_processor;
 struct comm;
 struct perf_sample;
 struct addr_location;
@@ -68,6 +67,19 @@ struct call_return {
 	u32 flags;
 };
 
+/**
+ * struct call_return_processor - provides a call-back to consume call-return
+ *                                information.
+ * @cpr: call path root
+ * @process: call-back that accepts call/return information
+ * @data: anonymous data for call-back
+ */
+struct call_return_processor {
+	struct call_path_root *cpr;
+	int (*process)(struct call_return *cr, void *data);
+	void *data;
+};
+
 int thread_stack__event(struct thread *thread, u32 flags, u64 from_ip,
 			u64 to_ip, u16 insn_len, u64 trace_nr);
 void thread_stack__set_trace_nr(struct thread *thread, u64 trace_nr);

commit 451db12617bc6ff1bb8ed456ed4f257594134255
Author: Chris Phlipot <cphlipot0@gmail.com>
Date:   Thu Apr 28 01:19:07 2016 -0700

    perf tools: Refactor code to move call path handling out of thread-stack
    
    Move the call path handling code out of thread-stack.c and
    thread-stack.h to allow other components that are not part of
    thread-stack to create call paths.
    
    Summary:
    
    - Create call-path.c and call-path.h and add them to the build.
    
    - Move all call path related code out of thread-stack.c and thread-stack.h
      and into call-path.c and call-path.h.
    
    - A small subset of structures and functions are now visible through
      call-path.h, which is required for thread-stack.c to continue to
      compile.
    
    This change is a prerequisite for subsequent patches in this change set
    and by itself contains no user-visible changes.
    
    Signed-off-by: Chris Phlipot <cphlipot0@gmail.com>
    Acked-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1461831551-12213-3-git-send-email-cphlipot0@gmail.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/thread-stack.h b/tools/perf/util/thread-stack.h
index e1528f1374c3..ec9beddfdbab 100644
--- a/tools/perf/util/thread-stack.h
+++ b/tools/perf/util/thread-stack.h
@@ -19,7 +19,6 @@
 #include <sys/types.h>
 
 #include <linux/types.h>
-#include <linux/rbtree.h>
 
 struct thread;
 struct comm;
@@ -30,6 +29,7 @@ struct call_return_processor;
 struct comm;
 struct perf_sample;
 struct addr_location;
+struct call_path;
 
 /*
  * Call/Return flags.
@@ -68,29 +68,6 @@ struct call_return {
 	u32 flags;
 };
 
-/**
- * struct call_path - node in list of calls leading to a function call.
- * @parent: call path to the parent function call
- * @sym: symbol of function called
- * @ip: only if sym is null, the ip of the function
- * @db_id: id used for db-export
- * @in_kernel: whether function is a in the kernel
- * @rb_node: node in parent's tree of called functions
- * @children: tree of call paths of functions called
- *
- * In combination with the call_return structure, the call_path structure
- * defines a context-sensitve call-graph.
- */
-struct call_path {
-	struct call_path *parent;
-	struct symbol *sym;
-	u64 ip;
-	u64 db_id;
-	bool in_kernel;
-	struct rb_node rb_node;
-	struct rb_root children;
-};
-
 int thread_stack__event(struct thread *thread, u32 flags, u64 from_ip,
 			u64 to_ip, u16 insn_len, u64 trace_nr);
 void thread_stack__set_trace_nr(struct thread *thread, u64 trace_nr);

commit a5499b37197ab4b5fed101370df7ccadacbb4340
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Fri May 29 16:33:30 2015 +0300

    perf tools: Ensure thread-stack is flushed
    
    The thread-stack represents a thread's current stack.  When a thread
    exits there can still be many functions on the stack e.g. exit() can be
    called many levels deep, so all the callers will never return.  To get
    that information output, the thread-stack must be flushed.
    
    Previously it was assumed the thread-stack would be flushed when the
    struct thread was deleted.  With thread ref-counting it is no longer
    clear when that will be, if ever. So instead explicitly flush all the
    thread-stacks at the end of a session.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Link: http://lkml.kernel.org/r/1432906425-9911-3-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/thread-stack.h b/tools/perf/util/thread-stack.h
index b843bbef8ba2..e1528f1374c3 100644
--- a/tools/perf/util/thread-stack.h
+++ b/tools/perf/util/thread-stack.h
@@ -96,6 +96,7 @@ int thread_stack__event(struct thread *thread, u32 flags, u64 from_ip,
 void thread_stack__set_trace_nr(struct thread *thread, u64 trace_nr);
 void thread_stack__sample(struct thread *thread, struct ip_callchain *chain,
 			  size_t sz, u64 ip);
+int thread_stack__flush(struct thread *thread);
 void thread_stack__free(struct thread *thread);
 
 struct call_return_processor *

commit 92a9e4f7db89a013e1bdef2e548928fc71e9867c
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Thu Oct 30 16:09:45 2014 +0200

    perf tools: Enhance the thread stack to output call/return data
    
    Enhance the thread stack to output detailed information about paired
    calls and returns.
    
    The enhanced processing consumes sample information via
    thread_stack__process() and outputs information about paired calls /
    returns via a call-back.
    
    While the call-back makes it possible for the facility to be used by
    arbitrary tools, a subsequent patch will provide the information to
    Python scripting via the db-export interface.
    
    An important part of the call/return information is the
    call path which provides a structure that defines a context
    sensitive call graph.
    
    Note that there are now two ways to use the thread stack.
    
    For simply providing a call stack (like you would get from the perf
    record -g option) the interface consists of thread_stack__event() and
    thread_stack__sample().
    
    Whereas the enhanced interface consists of call_return_processor__new()
    and thread_stack__process().
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1414678188-14946-5-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/thread-stack.h b/tools/perf/util/thread-stack.h
index 7c41579aec74..b843bbef8ba2 100644
--- a/tools/perf/util/thread-stack.h
+++ b/tools/perf/util/thread-stack.h
@@ -19,14 +19,93 @@
 #include <sys/types.h>
 
 #include <linux/types.h>
+#include <linux/rbtree.h>
 
 struct thread;
+struct comm;
 struct ip_callchain;
+struct symbol;
+struct dso;
+struct call_return_processor;
+struct comm;
+struct perf_sample;
+struct addr_location;
+
+/*
+ * Call/Return flags.
+ *
+ * CALL_RETURN_NO_CALL: 'return' but no matching 'call'
+ * CALL_RETURN_NO_RETURN: 'call' but no matching 'return'
+ */
+enum {
+	CALL_RETURN_NO_CALL	= 1 << 0,
+	CALL_RETURN_NO_RETURN	= 1 << 1,
+};
+
+/**
+ * struct call_return - paired call/return information.
+ * @thread: thread in which call/return occurred
+ * @comm: comm in which call/return occurred
+ * @cp: call path
+ * @call_time: timestamp of call (if known)
+ * @return_time: timestamp of return (if known)
+ * @branch_count: number of branches seen between call and return
+ * @call_ref: external reference to 'call' sample (e.g. db_id)
+ * @return_ref:  external reference to 'return' sample (e.g. db_id)
+ * @db_id: id used for db-export
+ * @flags: Call/Return flags
+ */
+struct call_return {
+	struct thread *thread;
+	struct comm *comm;
+	struct call_path *cp;
+	u64 call_time;
+	u64 return_time;
+	u64 branch_count;
+	u64 call_ref;
+	u64 return_ref;
+	u64 db_id;
+	u32 flags;
+};
+
+/**
+ * struct call_path - node in list of calls leading to a function call.
+ * @parent: call path to the parent function call
+ * @sym: symbol of function called
+ * @ip: only if sym is null, the ip of the function
+ * @db_id: id used for db-export
+ * @in_kernel: whether function is a in the kernel
+ * @rb_node: node in parent's tree of called functions
+ * @children: tree of call paths of functions called
+ *
+ * In combination with the call_return structure, the call_path structure
+ * defines a context-sensitve call-graph.
+ */
+struct call_path {
+	struct call_path *parent;
+	struct symbol *sym;
+	u64 ip;
+	u64 db_id;
+	bool in_kernel;
+	struct rb_node rb_node;
+	struct rb_root children;
+};
 
 int thread_stack__event(struct thread *thread, u32 flags, u64 from_ip,
 			u64 to_ip, u16 insn_len, u64 trace_nr);
+void thread_stack__set_trace_nr(struct thread *thread, u64 trace_nr);
 void thread_stack__sample(struct thread *thread, struct ip_callchain *chain,
 			  size_t sz, u64 ip);
 void thread_stack__free(struct thread *thread);
 
+struct call_return_processor *
+call_return_processor__new(int (*process)(struct call_return *cr, void *data),
+			   void *data);
+void call_return_processor__free(struct call_return_processor *crp);
+int thread_stack__process(struct thread *thread, struct comm *comm,
+			  struct perf_sample *sample,
+			  struct addr_location *from_al,
+			  struct addr_location *to_al, u64 ref,
+			  struct call_return_processor *crp);
+
 #endif

commit 00447ccdf3335ea467841fc3c7d65ffd30748895
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Thu Oct 30 16:09:42 2014 +0200

    perf tools: Add a thread stack for synthesizing call chains
    
    Add a thread stack for synthesizing call chains from call and return
    events.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1414678188-14946-2-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/util/thread-stack.h b/tools/perf/util/thread-stack.h
new file mode 100644
index 000000000000..7c41579aec74
--- /dev/null
+++ b/tools/perf/util/thread-stack.h
@@ -0,0 +1,32 @@
+/*
+ * thread-stack.h: Synthesize a thread's stack using call / return events
+ * Copyright (c) 2014, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#ifndef __PERF_THREAD_STACK_H
+#define __PERF_THREAD_STACK_H
+
+#include <sys/types.h>
+
+#include <linux/types.h>
+
+struct thread;
+struct ip_callchain;
+
+int thread_stack__event(struct thread *thread, u32 flags, u64 from_ip,
+			u64 to_ip, u16 insn_len, u64 trace_nr);
+void thread_stack__sample(struct thread *thread, struct ip_callchain *chain,
+			  size_t sz, u64 ip);
+void thread_stack__free(struct thread *thread);
+
+#endif
