commit 8cf5d0e09df3176f9afd334b77b216cbc6daf239
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon May 4 13:56:02 2020 -0300

    perf kmem: Rename perf_evsel__*() operating on 'struct evsel *' to evsel__*()
    
    As those is a 'struct evsel' methods, not part of tools/lib/perf/, aka
    libperf, to whom the perf_ prefix belongs.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 0a296fbf9194..38a5ab683ebc 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -169,8 +169,7 @@ static int insert_caller_stat(unsigned long call_site,
 	return 0;
 }
 
-static int perf_evsel__process_alloc_event(struct evsel *evsel,
-					   struct perf_sample *sample)
+static int evsel__process_alloc_event(struct evsel *evsel, struct perf_sample *sample)
 {
 	unsigned long ptr = evsel__intval(evsel, sample, "ptr"),
 		      call_site = evsel__intval(evsel, sample, "call_site");
@@ -188,10 +187,9 @@ static int perf_evsel__process_alloc_event(struct evsel *evsel,
 	return 0;
 }
 
-static int perf_evsel__process_alloc_node_event(struct evsel *evsel,
-						struct perf_sample *sample)
+static int evsel__process_alloc_node_event(struct evsel *evsel, struct perf_sample *sample)
 {
-	int ret = perf_evsel__process_alloc_event(evsel, sample);
+	int ret = evsel__process_alloc_event(evsel, sample);
 
 	if (!ret) {
 		int node1 = cpu__get_node(sample->cpu),
@@ -232,8 +230,7 @@ static struct alloc_stat *search_alloc_stat(unsigned long ptr,
 	return NULL;
 }
 
-static int perf_evsel__process_free_event(struct evsel *evsel,
-					  struct perf_sample *sample)
+static int evsel__process_free_event(struct evsel *evsel, struct perf_sample *sample)
 {
 	unsigned long ptr = evsel__intval(evsel, sample, "ptr");
 	struct alloc_stat *s_alloc, *s_caller;
@@ -784,8 +781,7 @@ static int parse_gfp_flags(struct evsel *evsel, struct perf_sample *sample,
 	return 0;
 }
 
-static int perf_evsel__process_page_alloc_event(struct evsel *evsel,
-						struct perf_sample *sample)
+static int evsel__process_page_alloc_event(struct evsel *evsel, struct perf_sample *sample)
 {
 	u64 page;
 	unsigned int order = evsel__intval(evsel, sample, "order");
@@ -857,8 +853,7 @@ static int perf_evsel__process_page_alloc_event(struct evsel *evsel,
 	return 0;
 }
 
-static int perf_evsel__process_page_free_event(struct evsel *evsel,
-						struct perf_sample *sample)
+static int evsel__process_page_free_event(struct evsel *evsel, struct perf_sample *sample)
 {
 	u64 page;
 	unsigned int order = evsel__intval(evsel, sample, "order");
@@ -1371,15 +1366,15 @@ static int __cmd_kmem(struct perf_session *session)
 	struct evsel *evsel;
 	const struct evsel_str_handler kmem_tracepoints[] = {
 		/* slab allocator */
-		{ "kmem:kmalloc",		perf_evsel__process_alloc_event, },
-    		{ "kmem:kmem_cache_alloc",	perf_evsel__process_alloc_event, },
-		{ "kmem:kmalloc_node",		perf_evsel__process_alloc_node_event, },
-    		{ "kmem:kmem_cache_alloc_node", perf_evsel__process_alloc_node_event, },
-		{ "kmem:kfree",			perf_evsel__process_free_event, },
-    		{ "kmem:kmem_cache_free",	perf_evsel__process_free_event, },
+		{ "kmem:kmalloc",		evsel__process_alloc_event, },
+		{ "kmem:kmem_cache_alloc",	evsel__process_alloc_event, },
+		{ "kmem:kmalloc_node",		evsel__process_alloc_node_event, },
+		{ "kmem:kmem_cache_alloc_node", evsel__process_alloc_node_event, },
+		{ "kmem:kfree",			evsel__process_free_event, },
+		{ "kmem:kmem_cache_free",	evsel__process_free_event, },
 		/* page allocator */
-		{ "kmem:mm_page_alloc",		perf_evsel__process_page_alloc_event, },
-		{ "kmem:mm_page_free",		perf_evsel__process_page_free_event, },
+		{ "kmem:mm_page_alloc",		evsel__process_page_alloc_event, },
+		{ "kmem:mm_page_free",		evsel__process_page_free_event, },
 	};
 
 	if (!perf_session__has_traces(session, "kmem record"))

commit efc0cdc9ed5e6cfb060ff7b77834cad9d3c97d1d
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Apr 29 16:26:57 2020 -0300

    perf evsel: Rename perf_evsel__{str,int}val() and other tracepoint field metehods to to evsel__*()
    
    As those are not 'struct evsel' methods, not part of tools/lib/perf/,
    aka libperf, to whom the perf_ prefix belongs.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index f91a050bda11..0a296fbf9194 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -172,10 +172,10 @@ static int insert_caller_stat(unsigned long call_site,
 static int perf_evsel__process_alloc_event(struct evsel *evsel,
 					   struct perf_sample *sample)
 {
-	unsigned long ptr = perf_evsel__intval(evsel, sample, "ptr"),
-		      call_site = perf_evsel__intval(evsel, sample, "call_site");
-	int bytes_req = perf_evsel__intval(evsel, sample, "bytes_req"),
-	    bytes_alloc = perf_evsel__intval(evsel, sample, "bytes_alloc");
+	unsigned long ptr = evsel__intval(evsel, sample, "ptr"),
+		      call_site = evsel__intval(evsel, sample, "call_site");
+	int bytes_req = evsel__intval(evsel, sample, "bytes_req"),
+	    bytes_alloc = evsel__intval(evsel, sample, "bytes_alloc");
 
 	if (insert_alloc_stat(call_site, ptr, bytes_req, bytes_alloc, sample->cpu) ||
 	    insert_caller_stat(call_site, bytes_req, bytes_alloc))
@@ -195,7 +195,7 @@ static int perf_evsel__process_alloc_node_event(struct evsel *evsel,
 
 	if (!ret) {
 		int node1 = cpu__get_node(sample->cpu),
-		    node2 = perf_evsel__intval(evsel, sample, "node");
+		    node2 = evsel__intval(evsel, sample, "node");
 
 		if (node1 != node2)
 			nr_cross_allocs++;
@@ -235,7 +235,7 @@ static struct alloc_stat *search_alloc_stat(unsigned long ptr,
 static int perf_evsel__process_free_event(struct evsel *evsel,
 					  struct perf_sample *sample)
 {
-	unsigned long ptr = perf_evsel__intval(evsel, sample, "ptr");
+	unsigned long ptr = evsel__intval(evsel, sample, "ptr");
 	struct alloc_stat *s_alloc, *s_caller;
 
 	s_alloc = search_alloc_stat(ptr, 0, &root_alloc_stat, ptr_cmp);
@@ -788,9 +788,9 @@ static int perf_evsel__process_page_alloc_event(struct evsel *evsel,
 						struct perf_sample *sample)
 {
 	u64 page;
-	unsigned int order = perf_evsel__intval(evsel, sample, "order");
-	unsigned int gfp_flags = perf_evsel__intval(evsel, sample, "gfp_flags");
-	unsigned int migrate_type = perf_evsel__intval(evsel, sample,
+	unsigned int order = evsel__intval(evsel, sample, "order");
+	unsigned int gfp_flags = evsel__intval(evsel, sample, "gfp_flags");
+	unsigned int migrate_type = evsel__intval(evsel, sample,
 						       "migratetype");
 	u64 bytes = kmem_page_size << order;
 	u64 callsite;
@@ -802,9 +802,9 @@ static int perf_evsel__process_page_alloc_event(struct evsel *evsel,
 	};
 
 	if (use_pfn)
-		page = perf_evsel__intval(evsel, sample, "pfn");
+		page = evsel__intval(evsel, sample, "pfn");
 	else
-		page = perf_evsel__intval(evsel, sample, "page");
+		page = evsel__intval(evsel, sample, "page");
 
 	nr_page_allocs++;
 	total_page_alloc_bytes += bytes;
@@ -861,7 +861,7 @@ static int perf_evsel__process_page_free_event(struct evsel *evsel,
 						struct perf_sample *sample)
 {
 	u64 page;
-	unsigned int order = perf_evsel__intval(evsel, sample, "order");
+	unsigned int order = evsel__intval(evsel, sample, "order");
 	u64 bytes = kmem_page_size << order;
 	struct page_stat *pstat;
 	struct page_stat this = {
@@ -869,9 +869,9 @@ static int perf_evsel__process_page_free_event(struct evsel *evsel,
 	};
 
 	if (use_pfn)
-		page = perf_evsel__intval(evsel, sample, "pfn");
+		page = evsel__intval(evsel, sample, "pfn");
 	else
-		page = perf_evsel__intval(evsel, sample, "page");
+		page = evsel__intval(evsel, sample, "page");
 
 	nr_page_frees++;
 	total_page_free_bytes += bytes;
@@ -1392,7 +1392,7 @@ static int __cmd_kmem(struct perf_session *session)
 
 	evlist__for_each_entry(session->evlist, evsel) {
 		if (!strcmp(evsel__name(evsel), "kmem:mm_page_alloc") &&
-		    perf_evsel__field(evsel, "pfn")) {
+		    evsel__field(evsel, "pfn")) {
 			use_pfn = true;
 			break;
 		}

commit 8ab2e96d8ff188006f1e3346a56443cd07fe1858
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Apr 29 16:07:09 2020 -0300

    perf evsel: Rename *perf_evsel__*name() to *evsel__*name()
    
    As they are 'struct evsel' methods or related routines, not part of
    tools/lib/perf/, aka libperf, to whom the perf_ prefix belongs.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 003c85f5f56c..f91a050bda11 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1391,7 +1391,7 @@ static int __cmd_kmem(struct perf_session *session)
 	}
 
 	evlist__for_each_entry(session->evlist, evsel) {
-		if (!strcmp(perf_evsel__name(evsel), "kmem:mm_page_alloc") &&
+		if (!strcmp(evsel__name(evsel), "kmem:mm_page_alloc") &&
 		    perf_evsel__field(evsel, "pfn")) {
 			use_pfn = true;
 			break;

commit 5f0fef8ac3e7a5707751493293ba8ff2ffc0f8a4
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Nov 4 12:14:32 2019 -0300

    perf callchain: Use 'struct map_symbol' in 'struct callchain_cursor_node'
    
    To ease passing around map+symbol, just like done for other parts of the
    tree recently.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 9661671cc26e..003c85f5f56c 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -412,8 +412,8 @@ static u64 find_callsite(struct evsel *evsel, struct perf_sample *sample)
 				 sizeof(key), callcmp);
 		if (!caller) {
 			/* found */
-			if (node->map)
-				addr = map__unmap_ip(node->map, node->ip);
+			if (node->ms.map)
+				addr = map__unmap_ip(node->ms.map, node->ip);
 			else
 				addr = node->ip;
 

commit 1abecfcaa7bba21c9985e0136fa49836164dd8fd
Author: Yunfeng Ye <yeyunfeng@huawei.com>
Date:   Wed Oct 16 16:38:45 2019 +0800

    perf kmem: Fix memory leak in compact_gfp_flags()
    
    The memory @orig_flags is allocated by strdup(), it is freed on the
    normal path, but leak to free on the error path.
    
    Fix this by adding free(orig_flags) on the error path.
    
    Fixes: 0e11115644b3 ("perf kmem: Print gfp flags in human readable string")
    Signed-off-by: Yunfeng Ye <yeyunfeng@huawei.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Feilong Lin <linfeilong@huawei.com>
    Cc: Hu Shiyuan <hushiyuan@huawei.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lore.kernel.org/lkml/f9e9f458-96f3-4a97-a1d5-9feec2420e07@huawei.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 1e61e353f579..9661671cc26e 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -691,6 +691,7 @@ static char *compact_gfp_flags(char *gfp_flags)
 			new = realloc(new_flags, len + strlen(cpt) + 2);
 			if (new == NULL) {
 				free(new_flags);
+				free(orig_flags);
 				return NULL;
 			}
 

commit 6ef81c55a2b6584cb642917f5fdf3632ef44b670
Author: Mamatha Inamdar <mamatha4@linux.vnet.ibm.com>
Date:   Thu Aug 22 12:50:49 2019 +0530

    perf session: Return error code for perf_session__new() function on failure
    
    This patch is to return error code of perf_new_session function on
    failure instead of NULL.
    
    Test Results:
    
    Before Fix:
    
      $ perf c2c report -input
      failed to open nput: No such file or directory
    
      $ echo $?
      0
      $
    
    After Fix:
    
      $ perf c2c report -input
      failed to open nput: No such file or directory
    
      $ echo $?
      254
      $
    
    Committer notes:
    
    Fix 'perf tests topology' case, where we use that TEST_ASSERT_VAL(...,
    session), i.e. we need to pass zero in case of failure, which was the
    case before when NULL was returned by perf_session__new() for failure,
    but now we need to negate the result of IS_ERR(session) to respect that
    TEST_ASSERT_VAL) expectation of zero meaning failure.
    
    Reported-by: Nageswara R Sastry <rnsastry@linux.vnet.ibm.com>
    Signed-off-by: Mamatha Inamdar <mamatha4@linux.vnet.ibm.com>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Tested-by: Nageswara R Sastry <rnsastry@linux.vnet.ibm.com>
    Acked-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Reviewed-by: Jiri Olsa <jolsa@redhat.com>
    Reviewed-by: Mukesh Ojha <mojha@codeaurora.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Alexey Budankov <alexey.budankov@linux.intel.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Jeremie Galarneau <jeremie.galarneau@efficios.com>
    Cc: Kate Stewart <kstewart@linuxfoundation.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Shawn Landden <shawn@git.icu>
    Cc: Song Liu <songliubraving@fb.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tzvetomir Stoyanov <tstoyanov@vmware.com>
    Link: http://lore.kernel.org/lkml/20190822071223.17892.45782.stgit@localhost.localdomain
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index b5682beaad72..1e61e353f579 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -14,6 +14,7 @@
 #include "util/tool.h"
 #include "util/callchain.h"
 #include "util/time-utils.h"
+#include <linux/err.h>
 
 #include <subcmd/pager.h>
 #include <subcmd/parse-options.h>
@@ -1956,8 +1957,8 @@ int cmd_kmem(int argc, const char **argv)
 	data.path = input_name;
 
 	kmem_session = session = perf_session__new(&data, false, &perf_kmem);
-	if (session == NULL)
-		return -1;
+	if (IS_ERR(session))
+		return PTR_ERR(session);
 
 	ret = -1;
 

commit 4a3cec84949d14dc3ef7fb8a51b8949af93cac13
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri Aug 30 11:11:01 2019 -0300

    perf dsos: Move the dsos struct and its methods to separate source files
    
    So that we can reduce the header dependency tree further, in the process
    noticed that lots of places were getting even things like build-id
    routines and 'struct perf_tool' definition indirectly, so fix all those
    too.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-ti0btma9ow5ndrytyoqdk62j@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 378b09c910a8..b5682beaad72 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -2,6 +2,7 @@
 #include "builtin.h"
 #include "perf.h"
 
+#include "util/dso.h"
 #include "util/evlist.h"
 #include "util/evsel.h"
 #include "util/config.h"

commit 38847db9740a984e8538ce2573cbc0fc7edf22b3
Author: Tzvetomir Stoyanov <tstoyanov@vmware.com>
Date:   Mon Aug 5 16:43:13 2019 -0400

    libtraceevent, perf tools: Changes in tep_print_event_* APIs
    
    Libtraceevent APIs for printing various trace events information are
    complicated, there are complex extra parameters. To control the way
    event information is printed, the user should call a set of functions in
    a specific sequence.
    
    These APIs are reimplemented to provide a more simple interface for
    printing event information.
    
    Removed APIs:
    
            tep_print_event_task()
            tep_print_event_time()
            tep_print_event_data()
            tep_event_info()
            tep_is_latency_format()
            tep_set_latency_format()
            tep_data_latency_format()
            tep_set_print_raw()
    
    A new API for printing event information is introduced:
       void tep_print_event(struct tep_handle *tep, struct trace_seq *s,
                            struct tep_record *record, const char *fmt, ...);
    where "fmt" is a printf-like format string, followed by the event
    fields to be printed. Supported fields:
     TEP_PRINT_PID, "%d" - event PID
     TEP_PRINT_CPU, "%d" - event CPU
     TEP_PRINT_COMM, "%s" - event command string
     TEP_PRINT_NAME, "%s" - event name
     TEP_PRINT_LATENCY, "%s" - event latency
     TEP_PRINT_TIME, %d - event time stamp. A divisor and precision
       can be specified as part of this format string:
       "%precision.divisord". Example:
       "%3.1000d" - divide the time by 1000 and print the first 3 digits
       before the dot. Thus, the time stamp "123456000" will be printed as
       "123.456"
     TEP_PRINT_INFO, "%s" - event information.
     TEP_PRINT_INFO_RAW, "%s" - event information, in raw format.
    
    Example:
      tep_print_event(tep, s, record, "%16s-%-5d [%03d] %s %6.1000d %s %s",
                      TEP_PRINT_COMM, TEP_PRINT_PID, TEP_PRINT_CPU,
                      TEP_PRINT_LATENCY, TEP_PRINT_TIME, TEP_PRINT_NAME, TEP_PRINT_INFO);
    Output:
            ls-11314 [005] d.h. 185207.366383 function __wake_up
    
    Signed-off-by: Tzvetomir Stoyanov <tstoyanov@vmware.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: linux-trace-devel@vger.kernel.org
    Cc: Patrick McLean <chutzpah@gentoo.org>
    Link: http://lore.kernel.org/linux-trace-devel/20190801074959.22023-2-tz.stoyanov@gmail.com
    Link: http://lore.kernel.org/lkml/20190805204355.041132030@goodmis.org
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 7eec0da64c46..378b09c910a8 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -750,7 +750,8 @@ static int parse_gfp_flags(struct evsel *evsel, struct perf_sample *sample,
 	}
 
 	trace_seq_init(&seq);
-	tep_event_info(&seq, evsel->tp_format, &record);
+	tep_print_event(evsel->tp_format->tep,
+			&seq, &record, "%s", TEP_PRINT_INFO);
 
 	str = strtok_r(seq.buffer, " ", &pos);
 	while (str) {

commit 8520a98dbab61e9e340cdfb72dd17ccc8a98961e
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Aug 29 16:18:59 2019 -0300

    perf debug: Remove needless include directives from debug.h
    
    All we need there is a forward declaration for 'union perf_event', so
    remove it from there and add missing header directives in places using
    things from this indirect include.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-7ftk0ztstqub1tirjj8o8xbl@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 46f828936120..7eec0da64c46 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -14,6 +14,7 @@
 #include "util/callchain.h"
 #include "util/time-utils.h"
 
+#include <subcmd/pager.h>
 #include <subcmd/parse-options.h>
 #include "util/trace-event.h"
 #include "util/data.h"

commit 32dcd021d004038ca12ac17319da5aa4756e9312
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Sun Jul 21 13:23:51 2019 +0200

    perf evsel: Rename struct perf_evsel to struct evsel
    
    Rename struct perf_evsel to struct evsel, so we don't have a name clash
    when we add struct perf_evsel in libperf.
    
    Committer notes:
    
    Added fixes for arm64, provided by Jiri.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Alexey Budankov <alexey.budankov@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Michael Petlan <mpetlan@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20190721112506.12306-5-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 9e5e60898083..46f828936120 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -166,7 +166,7 @@ static int insert_caller_stat(unsigned long call_site,
 	return 0;
 }
 
-static int perf_evsel__process_alloc_event(struct perf_evsel *evsel,
+static int perf_evsel__process_alloc_event(struct evsel *evsel,
 					   struct perf_sample *sample)
 {
 	unsigned long ptr = perf_evsel__intval(evsel, sample, "ptr"),
@@ -185,7 +185,7 @@ static int perf_evsel__process_alloc_event(struct perf_evsel *evsel,
 	return 0;
 }
 
-static int perf_evsel__process_alloc_node_event(struct perf_evsel *evsel,
+static int perf_evsel__process_alloc_node_event(struct evsel *evsel,
 						struct perf_sample *sample)
 {
 	int ret = perf_evsel__process_alloc_event(evsel, sample);
@@ -229,7 +229,7 @@ static struct alloc_stat *search_alloc_stat(unsigned long ptr,
 	return NULL;
 }
 
-static int perf_evsel__process_free_event(struct perf_evsel *evsel,
+static int perf_evsel__process_free_event(struct evsel *evsel,
 					  struct perf_sample *sample)
 {
 	unsigned long ptr = perf_evsel__intval(evsel, sample, "ptr");
@@ -381,7 +381,7 @@ static int build_alloc_func_list(void)
  * Find first non-memory allocation function from callchain.
  * The allocation functions are in the 'alloc_func_list'.
  */
-static u64 find_callsite(struct perf_evsel *evsel, struct perf_sample *sample)
+static u64 find_callsite(struct evsel *evsel, struct perf_sample *sample)
 {
 	struct addr_location al;
 	struct machine *machine = &kmem_session->machines.host;
@@ -728,7 +728,7 @@ static char *compact_gfp_string(unsigned long gfp_flags)
 	return NULL;
 }
 
-static int parse_gfp_flags(struct perf_evsel *evsel, struct perf_sample *sample,
+static int parse_gfp_flags(struct evsel *evsel, struct perf_sample *sample,
 			   unsigned int gfp_flags)
 {
 	struct tep_record record = {
@@ -779,7 +779,7 @@ static int parse_gfp_flags(struct perf_evsel *evsel, struct perf_sample *sample,
 	return 0;
 }
 
-static int perf_evsel__process_page_alloc_event(struct perf_evsel *evsel,
+static int perf_evsel__process_page_alloc_event(struct evsel *evsel,
 						struct perf_sample *sample)
 {
 	u64 page;
@@ -852,7 +852,7 @@ static int perf_evsel__process_page_alloc_event(struct perf_evsel *evsel,
 	return 0;
 }
 
-static int perf_evsel__process_page_free_event(struct perf_evsel *evsel,
+static int perf_evsel__process_page_free_event(struct evsel *evsel,
 						struct perf_sample *sample)
 {
 	u64 page;
@@ -930,13 +930,13 @@ static bool perf_kmem__skip_sample(struct perf_sample *sample)
 	return false;
 }
 
-typedef int (*tracepoint_handler)(struct perf_evsel *evsel,
+typedef int (*tracepoint_handler)(struct evsel *evsel,
 				  struct perf_sample *sample);
 
 static int process_sample_event(struct perf_tool *tool __maybe_unused,
 				union perf_event *event,
 				struct perf_sample *sample,
-				struct perf_evsel *evsel,
+				struct evsel *evsel,
 				struct machine *machine)
 {
 	int err = 0;
@@ -1363,8 +1363,8 @@ static void sort_result(void)
 static int __cmd_kmem(struct perf_session *session)
 {
 	int err = -EINVAL;
-	struct perf_evsel *evsel;
-	const struct perf_evsel_str_handler kmem_tracepoints[] = {
+	struct evsel *evsel;
+	const struct evsel_str_handler kmem_tracepoints[] = {
 		/* slab allocator */
 		{ "kmem:kmalloc",		perf_evsel__process_alloc_event, },
     		{ "kmem:kmem_cache_alloc",	perf_evsel__process_alloc_event, },
@@ -1967,7 +1967,7 @@ int cmd_kmem(int argc, const char **argv)
 	}
 
 	if (kmem_page) {
-		struct perf_evsel *evsel;
+		struct evsel *evsel;
 
 		evsel = perf_evlist__find_tracepoint_by_name(session->evlist,
 							     "kmem:mm_page_alloc");

commit 7f7c536f23e6afaa5d5d4b0e0958b0be8922491f
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Jul 4 11:32:27 2019 -0300

    tools lib: Adopt zalloc()/zfree() from tools/perf
    
    Eroding a bit more the tools/perf/util/util.h hodpodge header.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-natazosyn9rwjka25tvcnyi0@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 9bd3829de76d..9e5e60898083 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -4,7 +4,6 @@
 
 #include "util/evlist.h"
 #include "util/evsel.h"
-#include "util/util.h"
 #include "util/config.h"
 #include "util/map.h"
 #include "util/symbol.h"
@@ -26,6 +25,7 @@
 #include <linux/kernel.h>
 #include <linux/rbtree.h>
 #include <linux/string.h>
+#include <linux/zalloc.h>
 #include <errno.h>
 #include <inttypes.h>
 #include <locale.h>

commit 3052ba56bcb589046eca6a931bd897742653d2cb
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Jun 25 17:27:31 2019 -0300

    tools perf: Move from sane_ctype.h obtained from git to the Linux's original
    
    We got the sane_ctype.h headers from git and kept using it so far, but
    since that code originally came from the kernel sources to the git
    sources, perhaps its better to just use the one in the kernel, so that
    we can leverage tools/perf/check_headers.sh to be notified when our copy
    gets out of sync, i.e. when fixes or goodies are added to the code we've
    copied.
    
    This will help with things like tools/lib/string.c where we want to have
    more things in common with the kernel, such as strim(), skip_spaces(),
    etc so as to go on removing the things that we have in tools/perf/util/
    and instead using the code in the kernel, indirectly and removing things
    like EXPORT_SYMBOL(), etc, getting notified when fixes and improvements
    are made to the original code.
    
    Hopefully this also should help with reducing the difference of code
    hosted in tools/ to the one in the kernel proper.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-7k9868l713wqtgo01xxygn12@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index b833b03d7195..9bd3829de76d 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -31,7 +31,7 @@
 #include <locale.h>
 #include <regex.h>
 
-#include "sane_ctype.h"
+#include <linux/ctype.h>
 
 static int	kmem_slab;
 static int	kmem_page;

commit 6a9fa4e3bddedc027b691b6470c500d51d04e56c
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Jun 25 17:31:26 2019 -0300

    perf string: Move 'dots' and 'graph_dotted_line' out of sane_ctype.h
    
    Those are not in that file in the git repo, lets move it from there so
    that we get that sane ctype code fully isolated to allow getting it in
    sync either with the git sources or better with the kernel sources
    (include/linux/ctype.h + lib/ctype.h), that way we can use
    check_headers.h to get notified when changes are made in the original
    code so that we can cherry-pick.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-ioh5sghn3943j0rxg6lb2dgs@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index b80eee455111..b833b03d7195 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -21,6 +21,7 @@
 #include "util/cpumap.h"
 
 #include "util/debug.h"
+#include "util/string2.h"
 
 #include <linux/kernel.h>
 #include <linux/rbtree.h>

commit 69769ce159cbfd7567815a86cfc3ea63423de61b
Author: Tzvetomir Stoyanov <tstoyanov@vmware.com>
Date:   Mon Apr 1 12:43:18 2019 -0400

    perf tools, tools lib traceevent: Rename "pevent" member of struct tep_event to "tep"
    
    The member "pevent" of the struct tep_event is renamed to "tep". This
    makes the struct consistent with the chosen naming convention:
    
      tep (trace event parser), instead of the old pevent.
    
    Signed-off-by: Tzvetomir Stoyanov <tstoyanov@vmware.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: http://lore.kernel.org/linux-trace-devel/20190401132111.13727-3-tstoyanov@vmware.com
    Link: http://lkml.kernel.org/r/20190401164344.627724996@goodmis.org
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index fa520f4b8095..b80eee455111 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1975,7 +1975,7 @@ int cmd_kmem(int argc, const char **argv)
 			goto out_delete;
 		}
 
-		kmem_page_size = tep_get_page_size(evsel->tp_format->pevent);
+		kmem_page_size = tep_get_page_size(evsel->tp_format->tep);
 		symbol_conf.use_callchain = true;
 	}
 

commit 2d4f27999b8877409f326682fd8cc40c52f47cea
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Thu Feb 21 10:41:30 2019 +0100

    perf data: Add global path holder
    
    Add a 'path' member to 'struct perf_data'. It will keep the configured
    path for the data (const char *). The path in struct perf_data_file is
    now dynamically allocated (duped) from it.
    
    This scheme is useful/used in following patches where struct
    perf_data::path holds the 'configure' directory path and struct
    perf_data_file::path holds the allocated path for specific files.
    
    Also it actually makes the code little simpler.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Alexey Budankov <alexey.budankov@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/20190221094145.9151-3-jolsa@kernel.org
    [ Fixup data-convert-bt.c missing conversion ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index b80ec0883537..fa520f4b8095 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1949,7 +1949,7 @@ int cmd_kmem(int argc, const char **argv)
 		return __cmd_record(argc, argv);
 	}
 
-	data.file.path = input_name;
+	data.path = input_name;
 
 	kmem_session = session = perf_session__new(&data, false, &perf_kmem);
 	if (session == NULL)

commit 1101f69af5335a863765100d1df1999fd1e8c5bf
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sun Jan 27 13:42:37 2019 +0100

    pref tools: Add missing map.h includes
    
    Lots of places get the map.h file indirectly, and since we're going to
    remove it from machine.h, then those need to include it directly, do it
    now, before we remove that dep.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: https://lkml.kernel.org/n/tip-ob8jehdjda8h5jsrv9dqj9tf@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 088705c167bf..b80ec0883537 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -6,6 +6,7 @@
 #include "util/evsel.h"
 #include "util/util.h"
 #include "util/config.h"
+#include "util/map.h"
 #include "util/symbol.h"
 #include "util/thread.h"
 #include "util/header.h"

commit 49b8e2beceda79ae25938faf68fad0ad62534852
Author: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Date:   Sat Nov 3 00:06:23 2018 +0100

    perf tools: Replace automatic const char[] variables by statics
    
    An automatic const char[] variable gets initialized at runtime, just
    like any other automatic variable. For long strings, that uses a lot of
    stack and wastes time building the string; e.g. for the "No %s
    allocation events..." case one has:
    
      444516:       48 b8 4e 6f 20 25 73 20 61 6c   movabs $0x6c61207325206f4e,%rax # "No %s al"
      ...
      444674:       48 89 45 80                     mov    %rax,-0x80(%rbp)
      444678:       48 b8 6c 6f 63 61 74 69 6f 6e   movabs $0x6e6f697461636f6c,%rax # "location"
      444682:       48 89 45 88                     mov    %rax,-0x78(%rbp)
      444686:       48 b8 20 65 76 65 6e 74 73 20   movabs $0x2073746e65766520,%rax # " events "
      444690:       66 44 89 55 c4                  mov    %r10w,-0x3c(%rbp)
      444695:       48 89 45 90                     mov    %rax,-0x70(%rbp)
      444699:       48 b8 66 6f 75 6e 64 2e 20 20   movabs $0x20202e646e756f66,%rax
    
    Make them all static so that the compiler just references objects in .rodata.
    
    Committer testing:
    
    Ok, using dwarves's codiff tool:
    
        $ codiff --functions /tmp/perf.before ~/bin/perf
      builtin-sched.c:
        cmd_sched                 |  -48
       1 function changed, 48 bytes removed, diff: -48
    
      builtin-report.c:
        cmd_report                |  -32
       1 function changed, 32 bytes removed, diff: -32
    
      builtin-kmem.c:
        cmd_kmem                  |  -64
        build_alloc_func_list     |  -50
       2 functions changed, 114 bytes removed, diff: -114
    
      builtin-c2c.c:
        perf_c2c__report          | -390
       1 function changed, 390 bytes removed, diff: -390
    
      ui/browsers/header.c:
        tui__header_window        | -104
       1 function changed, 104 bytes removed, diff: -104
    
      /home/acme/bin/perf:
       9 functions changed, 688 bytes removed, diff: -688
    
    Signed-off-by: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20181102230624.20064-1-linux@rasmusvillemoes.dk
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index b63bca4b0c2a..088705c167bf 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -334,7 +334,7 @@ static int build_alloc_func_list(void)
 	struct alloc_func *func;
 	struct machine *machine = &kmem_session->machines.host;
 	regex_t alloc_func_regex;
-	const char pattern[] = "^_?_?(alloc|get_free|get_zeroed)_pages?";
+	static const char pattern[] = "^_?_?(alloc|get_free|get_zeroed)_pages?";
 
 	ret = regcomp(&alloc_func_regex, pattern, REG_EXTENDED);
 	if (ret) {
@@ -1924,7 +1924,7 @@ int cmd_kmem(int argc, const char **argv)
 		NULL
 	};
 	struct perf_session *session;
-	const char errmsg[] = "No %s allocation events found.  Have you run 'perf kmem record --%s'?\n";
+	static const char errmsg[] = "No %s allocation events found.  Have you run 'perf kmem record --%s'?\n";
 	int ret = perf_config(kmem_config, NULL);
 
 	if (ret)

commit 6fed932e9242b55a32dd75da7c2448b9b0c48a73
Author: Tzvetomir Stoyanov (VMware) <tz.stoyanov@gmail.com>
Date:   Wed Aug 8 14:02:57 2018 -0400

    tools lib traceevent, perf tools: Rename 'enum pevent_flag' to 'enum tep_flag'
    
    In order to make libtraceevent into a proper library, variables, data
    structures and functions require a unique prefix to prevent name space
    conflicts. That prefix will be "tep_" and not "pevent_". This changes
    pevent_get_page_size API and enum pevent_flag to enum tep_flag
    
    Signed-off-by: Tzvetomir Stoyanov (VMware) <tz.stoyanov@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Yordan Karadzhov (VMware) <y.karadz@gmail.com>
    Cc: linux-trace-devel@vger.kernel.org
    Link: http://lkml.kernel.org/r/20180808180701.623942406@goodmis.org
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 73c073ade71c..b63bca4b0c2a 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1974,7 +1974,7 @@ int cmd_kmem(int argc, const char **argv)
 			goto out_delete;
 		}
 
-		kmem_page_size = pevent_get_page_size(evsel->tp_format->pevent);
+		kmem_page_size = tep_get_page_size(evsel->tp_format->pevent);
 		symbol_conf.use_callchain = true;
 	}
 

commit 4d5c58b15c4363219e19380848eb74ca60143187
Author: Tzvetomir Stoyanov (VMware) <tz.stoyanov@gmail.com>
Date:   Wed Aug 8 14:02:49 2018 -0400

    tools lib traceevent, perf tools: Rename pevent alloc / free APIs
    
    In order to make libtraceevent into a proper library, variables, data
    structures and functions require a unique prefix to prevent name space
    conflicts. That prefix will be "tep_" and not "pevent_". This changes
    APIs: pevent_alloc, pevent_free, pevent_event_info and pevent_func_resolver_t
    
    Signed-off-by: Tzvetomir Stoyanov (VMware) <tz.stoyanov@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Yordan Karadzhov (VMware) <y.karadz@gmail.com>
    Cc: linux-trace-devel@vger.kernel.org
    Link: http://lkml.kernel.org/r/20180808180700.152609945@goodmis.org
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index b23e861fa6ae..73c073ade71c 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -747,7 +747,7 @@ static int parse_gfp_flags(struct perf_evsel *evsel, struct perf_sample *sample,
 	}
 
 	trace_seq_init(&seq);
-	pevent_event_info(&seq, evsel->tp_format, &record);
+	tep_event_info(&seq, evsel->tp_format, &record);
 
 	str = strtok_r(seq.buffer, " ", &pos);
 	while (str) {

commit cbc49b25b9cf26bf8c91169085be27382d945dd7
Author: Tzvetomir Stoyanov (VMware) <tz.stoyanov@gmail.com>
Date:   Wed Aug 8 14:02:47 2018 -0400

    tools lib traceevent, perf tools: Rename 'struct pevent_record' to 'struct tep_record'
    
    In order to make libtraceevent into a proper library, variables, data
    structures and functions require a unique prefix to prevent name space
    conflicts. That prefix will be "tep_" and not "pevent_". This changes
    the 'struct pevent_record' to 'struct tep_record'.
    
    Signed-off-by: Tzvetomir Stoyanov (VMware) <tz.stoyanov@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Yordan Karadzhov (VMware) <y.karadz@gmail.com>
    Cc: linux-trace-devel@vger.kernel.org
    Link: http://lkml.kernel.org/r/20180808180659.866021298@goodmis.org
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 54d3f21b0e62..b23e861fa6ae 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -729,7 +729,7 @@ static char *compact_gfp_string(unsigned long gfp_flags)
 static int parse_gfp_flags(struct perf_evsel *evsel, struct perf_sample *sample,
 			   unsigned int gfp_flags)
 {
-	struct pevent_record record = {
+	struct tep_record record = {
 		.cpu = sample->cpu,
 		.data = sample->raw_data,
 		.size = sample->raw_size,

commit 107cad95ffd81afad295ed5c29d006e525f1f80f
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Apr 30 12:20:54 2018 -0300

    perf machine: Ditch find_kernel_function variants
    
    Since we do not have split symtabs anymore, no need to have explicit
    find_kernel_function variants, use the find_kernel_symbol ones.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: https://lkml.kernel.org/n/tip-hiw2ryflju000f6wl62128it@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index ae11e4c3516a..54d3f21b0e62 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1004,7 +1004,7 @@ static void __print_slab_result(struct rb_root *root,
 		if (is_caller) {
 			addr = data->call_site;
 			if (!raw_ip)
-				sym = machine__find_kernel_function(machine, addr, &map);
+				sym = machine__find_kernel_symbol(machine, addr, &map);
 		} else
 			addr = data->ptr;
 
@@ -1068,7 +1068,7 @@ static void __print_page_alloc_result(struct perf_session *session, int n_lines)
 		char *caller = buf;
 
 		data = rb_entry(next, struct page_stat, node);
-		sym = machine__find_kernel_function(machine, data->callsite, &map);
+		sym = machine__find_kernel_symbol(machine, data->callsite, &map);
 		if (sym)
 			caller = sym->name;
 		else
@@ -1110,7 +1110,7 @@ static void __print_page_caller_result(struct perf_session *session, int n_lines
 		char *caller = buf;
 
 		data = rb_entry(next, struct page_stat, node);
-		sym = machine__find_kernel_function(machine, data->callsite, &map);
+		sym = machine__find_kernel_symbol(machine, data->callsite, &map);
 		if (sym)
 			caller = sym->name;
 		else

commit 453f85d43fa9ee243f0fc3ac4e1be45615301e3f
Author: Mel Gorman <mgorman@techsingularity.net>
Date:   Wed Nov 15 17:38:03 2017 -0800

    mm: remove __GFP_COLD
    
    As the page free path makes no distinction between cache hot and cold
    pages, there is no real useful ordering of pages in the free list that
    allocation requests can take advantage of.  Juding from the users of
    __GFP_COLD, it is likely that a number of them are the result of copying
    other sites instead of actually measuring the impact.  Remove the
    __GFP_COLD parameter which simplifies a number of paths in the page
    allocator.
    
    This is potentially controversial but bear in mind that the size of the
    per-cpu pagelists versus modern cache sizes means that the whole per-cpu
    list can often fit in the L3 cache.  Hence, there is only a potential
    benefit for microbenchmarks that alloc/free pages in a tight loop.  It's
    even worse when THP is taken into account which has little or no chance
    of getting a cache-hot page as the per-cpu list is bypassed and the
    zeroing of multiple pages will thrash the cache anyway.
    
    The truncate microbenchmarks are not shown as this patch affects the
    allocation path and not the free path.  A page fault microbenchmark was
    tested but it showed no sigificant difference which is not surprising
    given that the __GFP_COLD branches are a miniscule percentage of the
    fault path.
    
    Link: http://lkml.kernel.org/r/20171018075952.10627-9-mgorman@techsingularity.net
    Signed-off-by: Mel Gorman <mgorman@techsingularity.net>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index cbf70738ef5f..ae11e4c3516a 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -641,7 +641,6 @@ static const struct {
 	{ "__GFP_ATOMIC",		"_A" },
 	{ "__GFP_IO",			"I" },
 	{ "__GFP_FS",			"F" },
-	{ "__GFP_COLD",			"CO" },
 	{ "__GFP_NOWARN",		"NWR" },
 	{ "__GFP_RETRY_MAYFAIL",	"R" },
 	{ "__GFP_NOFAIL",		"NF" },

commit d8be75663cec0069b85f80191abd2682ce4a512f
Author: Levin, Alexander (Sasha Levin) <alexander.levin@verizon.com>
Date:   Wed Nov 15 17:35:58 2017 -0800

    kmemcheck: remove whats left of NOTRACK flags
    
    Now that kmemcheck is gone, we don't need the NOTRACK flags.
    
    Link: http://lkml.kernel.org/r/20171007030159.22241-5-alexander.levin@verizon.com
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Pekka Enberg <penberg@kernel.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Tim Hansen <devtimhansen@gmail.com>
    Cc: Vegard Nossum <vegardno@ifi.uio.no>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 557d391f564a..cbf70738ef5f 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -655,7 +655,6 @@ static const struct {
 	{ "__GFP_RECLAIMABLE",		"RC" },
 	{ "__GFP_MOVABLE",		"M" },
 	{ "__GFP_ACCOUNT",		"AC" },
-	{ "__GFP_NOTRACK",		"NT" },
 	{ "__GFP_WRITE",		"WR" },
 	{ "__GFP_RECLAIM",		"R" },
 	{ "__GFP_DIRECT_RECLAIM",	"DR" },

commit 15bcdc9477b03eb035052412c3a087e11e855e76
Merge: 340b5319c98e e4880bc5dfb1
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Nov 7 10:30:18 2017 +0100

    Merge branch 'linus' into perf/core, to fix conflicts
    
    Conflicts:
            tools/perf/arch/arm/annotate/instructions.c
            tools/perf/arch/arm64/annotate/instructions.c
            tools/perf/arch/powerpc/annotate/instructions.c
            tools/perf/arch/s390/annotate/instructions.c
            tools/perf/arch/x86/tests/intel-cqm.c
            tools/perf/ui/tui/progress.c
            tools/perf/util/zlib.c
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 24ee68ecdd42..35d4b9c9a9e8 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 #include "builtin.h"
 #include "perf.h"
 

commit eae8ad8042d82775da1ddf3faa915b32854d9cf4
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Mon Jan 23 22:25:41 2017 +0100

    perf tools: Add struct perf_data_file
    
    Add struct perf_data_file to represent a single file within a perf_data
    struct.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Changbin Du <changbin.du@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jin Yao <yao.jin@linux.intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-c3f9p4xzykr845ktqcek6p4t@git.kernel.org
    [ Fixup recent changes in 'perf script --per-event-dump' ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index d45740a3e5f1..abcab75cc5b9 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1949,7 +1949,7 @@ int cmd_kmem(int argc, const char **argv)
 		return __cmd_record(argc, argv);
 	}
 
-	data.path = input_name;
+	data.file.path = input_name;
 
 	kmem_session = session = perf_session__new(&data, false, &perf_kmem);
 	if (session == NULL)

commit 8ceb41d7e305f186543c58178d2e1fe34f708948
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Mon Jan 23 22:07:59 2017 +0100

    perf tools: Rename struct perf_data_file to perf_data
    
    Rename struct perf_data_file to perf_data, because we will add the
    possibility to have multiple files under perf.data, so the 'perf_data'
    name fits better.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Changbin Du <changbin.du@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jin Yao <yao.jin@linux.intel.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-39wn4d77phel3dgkzo3lyan0@git.kernel.org
    [ Fixup recent changes in 'perf script --per-event-dump' ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index d8f25ef8157b..d45740a3e5f1 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1893,7 +1893,7 @@ int cmd_kmem(int argc, const char **argv)
 {
 	const char * const default_slab_sort = "frag,hit,bytes";
 	const char * const default_page_sort = "bytes,hit";
-	struct perf_data_file file = {
+	struct perf_data data = {
 		.mode = PERF_DATA_MODE_READ,
 	};
 	const struct option kmem_options[] = {
@@ -1909,7 +1909,7 @@ int cmd_kmem(int argc, const char **argv)
 		     "page, order, migtype, gfp", parse_sort_opt),
 	OPT_CALLBACK('l', "line", NULL, "num", "show n lines", parse_line_opt),
 	OPT_BOOLEAN(0, "raw-ip", &raw_ip, "show raw ip instead of symbol"),
-	OPT_BOOLEAN('f', "force", &file.force, "don't complain, do it"),
+	OPT_BOOLEAN('f', "force", &data.force, "don't complain, do it"),
 	OPT_CALLBACK_NOOPT(0, "slab", NULL, NULL, "Analyze slab allocator",
 			   parse_slab_opt),
 	OPT_CALLBACK_NOOPT(0, "page", NULL, NULL, "Analyze page allocator",
@@ -1949,9 +1949,9 @@ int cmd_kmem(int argc, const char **argv)
 		return __cmd_record(argc, argv);
 	}
 
-	file.path = input_name;
+	data.path = input_name;
 
-	kmem_session = session = perf_session__new(&file, false, &perf_kmem);
+	kmem_session = session = perf_session__new(&data, false, &perf_kmem);
 	if (session == NULL)
 		return -1;
 

commit 79f56ebe2ae33aa54c69bbc9854a9a31f622913e
Author: Christophe JAILLET <christophe.jaillet@wanadoo.fr>
Date:   Sat Sep 16 08:09:36 2017 +0200

    perf kmem: Perform some cleanup if '--time' is given an invalid value
    
    If the string passed in '--time' is invalid, we must do some cleanup
    before leaving. As in the other error handling paths of this function.
    
    Signed-off-by: Christophe JAILLET <christophe.jaillet@wanadoo.fr>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: kernel-janitors@vger.kernel.org
    Fixes: 2a865bd8dddd ("perf kmem: Add option to specify time window of interest")
    Link: http://lkml.kernel.org/r/20170916060936.28199-1-christophe.jaillet@wanadoo.fr
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 24ee68ecdd42..d8f25ef8157b 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1983,7 +1983,8 @@ int cmd_kmem(int argc, const char **argv)
 
 	if (perf_time__parse_str(&ptime, time_str) != 0) {
 		pr_err("Invalid time string\n");
-		return -EINVAL;
+		ret = -EINVAL;
+		goto out_delete;
 	}
 
 	if (!strcmp(argv[0], "stat")) {

commit 0ee931c4e31a5efb134c76440405e9219f896e33
Author: Michal Hocko <mhocko@suse.com>
Date:   Wed Sep 13 16:28:29 2017 -0700

    mm: treewide: remove GFP_TEMPORARY allocation flag
    
    GFP_TEMPORARY was introduced by commit e12ba74d8ff3 ("Group short-lived
    and reclaimable kernel allocations") along with __GFP_RECLAIMABLE.  It's
    primary motivation was to allow users to tell that an allocation is
    short lived and so the allocator can try to place such allocations close
    together and prevent long term fragmentation.  As much as this sounds
    like a reasonable semantic it becomes much less clear when to use the
    highlevel GFP_TEMPORARY allocation flag.  How long is temporary? Can the
    context holding that memory sleep? Can it take locks? It seems there is
    no good answer for those questions.
    
    The current implementation of GFP_TEMPORARY is basically GFP_KERNEL |
    __GFP_RECLAIMABLE which in itself is tricky because basically none of
    the existing caller provide a way to reclaim the allocated memory.  So
    this is rather misleading and hard to evaluate for any benefits.
    
    I have checked some random users and none of them has added the flag
    with a specific justification.  I suspect most of them just copied from
    other existing users and others just thought it might be a good idea to
    use without any measuring.  This suggests that GFP_TEMPORARY just
    motivates for cargo cult usage without any reasoning.
    
    I believe that our gfp flags are quite complex already and especially
    those with highlevel semantic should be clearly defined to prevent from
    confusion and abuse.  Therefore I propose dropping GFP_TEMPORARY and
    replace all existing users to simply use GFP_KERNEL.  Please note that
    SLAB users with shrinkers will still get __GFP_RECLAIMABLE heuristic and
    so they will be placed properly for memory fragmentation prevention.
    
    I can see reasons we might want some gfp flag to reflect shorterm
    allocations but I propose starting from a clear semantic definition and
    only then add users with proper justification.
    
    This was been brought up before LSF this year by Matthew [1] and it
    turned out that GFP_TEMPORARY really doesn't have a clear semantic.  It
    seems to be a heuristic without any measured advantage for most (if not
    all) its current users.  The follow up discussion has revealed that
    opinions on what might be temporary allocation differ a lot between
    developers.  So rather than trying to tweak existing users into a
    semantic which they haven't expected I propose to simply remove the flag
    and start from scratch if we really need a semantic for short term
    allocations.
    
    [1] http://lkml.kernel.org/r/20170118054945.GD18349@bombadil.infradead.org
    
    [akpm@linux-foundation.org: fix typo]
    [akpm@linux-foundation.org: coding-style fixes]
    [sfr@canb.auug.org.au: drm/i915: fix up]
      Link: http://lkml.kernel.org/r/20170816144703.378d4f4d@canb.auug.org.au
    Link: http://lkml.kernel.org/r/20170728091904.14627-1-mhocko@kernel.org
    Signed-off-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Acked-by: Mel Gorman <mgorman@suse.de>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Neil Brown <neilb@suse.de>
    Cc: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index a1497c516d85..24ee68ecdd42 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -627,7 +627,6 @@ static const struct {
 	{ "GFP_HIGHUSER_MOVABLE",	"HUM" },
 	{ "GFP_HIGHUSER",		"HU" },
 	{ "GFP_USER",			"U" },
-	{ "GFP_TEMPORARY",		"TMP" },
 	{ "GFP_KERNEL_ACCOUNT",		"KAC" },
 	{ "GFP_KERNEL",			"K" },
 	{ "GFP_NOFS",			"NF" },

commit dcda9b04713c3f6ff0875652924844fae28286ea
Author: Michal Hocko <mhocko@suse.com>
Date:   Wed Jul 12 14:36:45 2017 -0700

    mm, tree wide: replace __GFP_REPEAT by __GFP_RETRY_MAYFAIL with more useful semantic
    
    __GFP_REPEAT was designed to allow retry-but-eventually-fail semantic to
    the page allocator.  This has been true but only for allocations
    requests larger than PAGE_ALLOC_COSTLY_ORDER.  It has been always
    ignored for smaller sizes.  This is a bit unfortunate because there is
    no way to express the same semantic for those requests and they are
    considered too important to fail so they might end up looping in the
    page allocator for ever, similarly to GFP_NOFAIL requests.
    
    Now that the whole tree has been cleaned up and accidental or misled
    usage of __GFP_REPEAT flag has been removed for !costly requests we can
    give the original flag a better name and more importantly a more useful
    semantic.  Let's rename it to __GFP_RETRY_MAYFAIL which tells the user
    that the allocator would try really hard but there is no promise of a
    success.  This will work independent of the order and overrides the
    default allocator behavior.  Page allocator users have several levels of
    guarantee vs.  cost options (take GFP_KERNEL as an example)
    
     - GFP_KERNEL & ~__GFP_RECLAIM - optimistic allocation without _any_
       attempt to free memory at all. The most light weight mode which even
       doesn't kick the background reclaim. Should be used carefully because
       it might deplete the memory and the next user might hit the more
       aggressive reclaim
    
     - GFP_KERNEL & ~__GFP_DIRECT_RECLAIM (or GFP_NOWAIT)- optimistic
       allocation without any attempt to free memory from the current
       context but can wake kswapd to reclaim memory if the zone is below
       the low watermark. Can be used from either atomic contexts or when
       the request is a performance optimization and there is another
       fallback for a slow path.
    
     - (GFP_KERNEL|__GFP_HIGH) & ~__GFP_DIRECT_RECLAIM (aka GFP_ATOMIC) -
       non sleeping allocation with an expensive fallback so it can access
       some portion of memory reserves. Usually used from interrupt/bh
       context with an expensive slow path fallback.
    
     - GFP_KERNEL - both background and direct reclaim are allowed and the
       _default_ page allocator behavior is used. That means that !costly
       allocation requests are basically nofail but there is no guarantee of
       that behavior so failures have to be checked properly by callers
       (e.g. OOM killer victim is allowed to fail currently).
    
     - GFP_KERNEL | __GFP_NORETRY - overrides the default allocator behavior
       and all allocation requests fail early rather than cause disruptive
       reclaim (one round of reclaim in this implementation). The OOM killer
       is not invoked.
    
     - GFP_KERNEL | __GFP_RETRY_MAYFAIL - overrides the default allocator
       behavior and all allocation requests try really hard. The request
       will fail if the reclaim cannot make any progress. The OOM killer
       won't be triggered.
    
     - GFP_KERNEL | __GFP_NOFAIL - overrides the default allocator behavior
       and all allocation requests will loop endlessly until they succeed.
       This might be really dangerous especially for larger orders.
    
    Existing users of __GFP_REPEAT are changed to __GFP_RETRY_MAYFAIL
    because they already had their semantic.  No new users are added.
    __alloc_pages_slowpath is changed to bail out for __GFP_RETRY_MAYFAIL if
    there is no progress and we have already passed the OOM point.
    
    This means that all the reclaim opportunities have been exhausted except
    the most disruptive one (the OOM killer) and a user defined fallback
    behavior is more sensible than keep retrying in the page allocator.
    
    [akpm@linux-foundation.org: fix arch/sparc/kernel/mdesc.c]
    [mhocko@suse.com: semantic fix]
      Link: http://lkml.kernel.org/r/20170626123847.GM11534@dhcp22.suse.cz
    [mhocko@kernel.org: address other thing spotted by Vlastimil]
      Link: http://lkml.kernel.org/r/20170626124233.GN11534@dhcp22.suse.cz
    Link: http://lkml.kernel.org/r/20170623085345.11304-3-mhocko@kernel.org
    Signed-off-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Alex Belits <alex.belits@cavium.com>
    Cc: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Darrick J. Wong <darrick.wong@oracle.com>
    Cc: David Daney <david.daney@cavium.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: NeilBrown <neilb@suse.com>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 0a8a1c45af87..a1497c516d85 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -643,7 +643,7 @@ static const struct {
 	{ "__GFP_FS",			"F" },
 	{ "__GFP_COLD",			"CO" },
 	{ "__GFP_NOWARN",		"NWR" },
-	{ "__GFP_REPEAT",		"R" },
+	{ "__GFP_RETRY_MAYFAIL",	"R" },
 	{ "__GFP_NOFAIL",		"NF" },
 	{ "__GFP_NORETRY",		"NR" },
 	{ "__GFP_COMP",			"C" },

commit 62d94b00f80b0ecb7fa9eea0539c59e9f82b0fcd
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Jun 27 11:22:31 2017 -0300

    perf tools: Replace error() with pr_err()
    
    To consolidate the error reporting facility.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-b41iot1094katoffdf19w9zk@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 9409c9464667..0a8a1c45af87 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1715,7 +1715,7 @@ static int setup_slab_sorting(struct list_head *sort_list, const char *arg)
 		if (!tok)
 			break;
 		if (slab_sort_dimension__add(tok, sort_list) < 0) {
-			error("Unknown slab --sort key: '%s'", tok);
+			pr_err("Unknown slab --sort key: '%s'", tok);
 			free(str);
 			return -1;
 		}
@@ -1741,7 +1741,7 @@ static int setup_page_sorting(struct list_head *sort_list, const char *arg)
 		if (!tok)
 			break;
 		if (page_sort_dimension__add(tok, sort_list) < 0) {
-			error("Unknown page --sort key: '%s'", tok);
+			pr_err("Unknown page --sort key: '%s'", tok);
 			free(str);
 			return -1;
 		}

commit a43783aeec5fac8ef372ff8c0a5bbb3056fc0604
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Apr 18 10:46:11 2017 -0300

    perf tools: Include errno.h where needed
    
    Removing it from util.h, part of an effort to disentangle the includes
    hell, that makes changes to util.h or something included by it to cause
    a complete rebuild of the tools.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-ztrjy52q1rqcchuy3rubfgt2@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 15754a492cad..9409c9464667 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -23,6 +23,7 @@
 #include <linux/kernel.h>
 #include <linux/rbtree.h>
 #include <linux/string.h>
+#include <errno.h>
 #include <inttypes.h>
 #include <locale.h>
 #include <regex.h>

commit 3d689ed6099a1a11c38bb78aff7498e78e287e0b
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Apr 17 16:10:49 2017 -0300

    perf tools: Move sane ctype stuff from util.h to sane_ctype.h
    
    More stuff that came from git, out of the hodge-podge that is util.h
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-e3lana4gctz3ub4hn4y29hkw@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index fa6bf1c39b65..15754a492cad 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -27,6 +27,8 @@
 #include <locale.h>
 #include <regex.h>
 
+#include "sane_ctype.h"
+
 static int	kmem_slab;
 static int	kmem_page;
 

commit fd20e8111cc0e51ce12fb8ee17c863088fe95065
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Apr 17 15:23:08 2017 -0300

    perf tools: Including missing inttypes.h header
    
    Needed to use the PRI[xu](32,64) formatting macros.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-wkbho8kaw24q67dd11q0j39f@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 8f0b94563936..fa6bf1c39b65 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -23,6 +23,7 @@
 #include <linux/kernel.h>
 #include <linux/rbtree.h>
 #include <linux/string.h>
+#include <inttypes.h>
 #include <locale.h>
 #include <regex.h>
 

commit 877a7a11050ee4d465364c57f8fbf78f6b1a2559
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Apr 17 11:39:06 2017 -0300

    perf tools: Add include <linux/kernel.h> where ARRAY_SIZE() is used
    
    To pave the way for further cleanups where linux/kernel.h may stop being
    included in some header.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-qqxan6tfsl6qx3l0v3nwgjvk@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 515587825af4..8f0b94563936 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -20,6 +20,7 @@
 
 #include "util/debug.h"
 
+#include <linux/kernel.h>
 #include <linux/rbtree.h>
 #include <linux/string.h>
 #include <locale.h>

commit b0ad8ea66445d64a469df0c710947f4cdb8ef16b
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Mar 27 11:47:20 2017 -0300

    perf tools: Remove unused 'prefix' from builtin functions
    
    We got it from the git sources but never used it for anything, with the
    place where this would be somehow used remaining:
    
      static int run_builtin(struct cmd_struct *p, int argc, const char **argv)
      {
            prefix = NULL;
            if (p->option & RUN_SETUP)
                    prefix = NULL; /* setup_perf_directory(); */
    
    Ditch it.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-uw5swz05vol0qpr32c5lpvus@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index d509e74bc6e8..515587825af4 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1866,7 +1866,7 @@ static int __cmd_record(int argc, const char **argv)
 	for (j = 1; j < (unsigned int)argc; j++, i++)
 		rec_argv[i] = argv[j];
 
-	return cmd_record(i, rec_argv, NULL);
+	return cmd_record(i, rec_argv);
 }
 
 static int kmem_config(const char *var, const char *value, void *cb __maybe_unused)
@@ -1885,7 +1885,7 @@ static int kmem_config(const char *var, const char *value, void *cb __maybe_unus
 	return 0;
 }
 
-int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
+int cmd_kmem(int argc, const char **argv)
 {
 	const char * const default_slab_sort = "frag,hit,bytes";
 	const char * const default_page_sort = "bytes,hit";

commit f3b3614a284deb124018155a618a7b19694c8b5c
Author: Hari Bathini <hbathini@linux.vnet.ibm.com>
Date:   Wed Mar 8 02:11:43 2017 +0530

    perf tools: Add PERF_RECORD_NAMESPACES to include namespaces related info
    
    Introduce a new option to record PERF_RECORD_NAMESPACES events emitted
    by the kernel when fork, clone, setns or unshare are invoked. And update
    perf-record documentation with the new option to record namespace
    events.
    
    Committer notes:
    
    Combined it with a later patch to allow printing it via 'perf report -D'
    and be able to test the feature introduced in this patch. Had to move
    here also perf_ns__name(), that was introduced in another later patch.
    
    Also used PRIu64 and PRIx64 to fix the build in some enfironments wrt:
    
      util/event.c:1129:39: error: format '%lx' expects argument of type 'long unsigned int', but argument 6 has type 'long long unsigned int' [-Werror=format=]
         ret  += fprintf(fp, "%u/%s: %lu/0x%lx%s", idx
                                             ^
    Testing it:
    
      # perf record --namespaces -a
      ^C[ perf record: Woken up 1 times to write data ]
      [ perf record: Captured and wrote 1.083 MB perf.data (423 samples) ]
      #
      # perf report -D
      <SNIP>
      3 2028902078892 0x115140 [0xa0]: PERF_RECORD_NAMESPACES 14783/14783 - nr_namespaces: 7
                    [0/net: 3/0xf0000081, 1/uts: 3/0xeffffffe, 2/ipc: 3/0xefffffff, 3/pid: 3/0xeffffffc,
                     4/user: 3/0xeffffffd, 5/mnt: 3/0xf0000000, 6/cgroup: 3/0xeffffffb]
    
      0x1151e0 [0x30]: event: 9
      .
      . ... raw event: size 48 bytes
      .  0000:  09 00 00 00 02 00 30 00 c4 71 82 68 0c 7f 00 00  ......0..q.h....
      .  0010:  a9 39 00 00 a9 39 00 00 94 28 fe 63 d8 01 00 00  .9...9...(.c....
      .  0020:  03 00 00 00 00 00 00 00 ce c4 02 00 00 00 00 00  ................
      <SNIP>
            NAMESPACES events:          1
      <SNIP>
      #
    
    Signed-off-by: Hari Bathini <hbathini@linux.vnet.ibm.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Alexei Starovoitov <ast@fb.com>
    Cc: Ananth N Mavinakayanahalli <ananth@linux.vnet.ibm.com>
    Cc: Aravinda Prasad <aravinda@linux.vnet.ibm.com>
    Cc: Brendan Gregg <brendan.d.gregg@gmail.com>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Eric Biederman <ebiederm@xmission.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Sargun Dhillon <sargun@sargun.me>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Link: http://lkml.kernel.org/r/148891930386.25309.18412039920746995488.stgit@hbathini.in.ibm.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 6da8d083e4e5..d509e74bc6e8 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -964,6 +964,7 @@ static struct perf_tool perf_kmem = {
 	.comm		 = perf_event__process_comm,
 	.mmap		 = perf_event__process_mmap,
 	.mmap2		 = perf_event__process_mmap2,
+	.namespaces	 = perf_event__process_namespaces,
 	.ordered_events	 = true,
 };
 

commit a7c3899c06865c75f8887f33d9043f6e8e780e71
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Feb 13 16:52:15 2017 -0300

    perf symbols: No need to check if sym->name is NULL
    
    As it is an array, so will always evaluate to 'true', as reported by
    clang:
    
      builtin-sched.c:2070:19: error: address of array 'sym->name' will always evaluate to 'true' [-Werror,-Wpointer-bool-conversion]
                      if (sym && sym->name) {
                              ~~ ~~~~~^~~~
      1 warning generated.
    
    So just ditch all those useless checks.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-ydpm927col06paixb775jjx5@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 29f4751a3574..6da8d083e4e5 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1065,7 +1065,7 @@ static void __print_page_alloc_result(struct perf_session *session, int n_lines)
 
 		data = rb_entry(next, struct page_stat, node);
 		sym = machine__find_kernel_function(machine, data->callsite, &map);
-		if (sym && sym->name)
+		if (sym)
 			caller = sym->name;
 		else
 			scnprintf(buf, sizeof(buf), "%"PRIx64, data->callsite);
@@ -1107,7 +1107,7 @@ static void __print_page_caller_result(struct perf_session *session, int n_lines
 
 		data = rb_entry(next, struct page_stat, node);
 		sym = machine__find_kernel_function(machine, data->callsite, &map);
-		if (sym && sym->name)
+		if (sym)
 			caller = sym->name;
 		else
 			scnprintf(buf, sizeof(buf), "%"PRIx64, data->callsite);

commit ecc4c5614b24ee8ebaa35b834b5768dc9302ee3e
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Jan 24 13:44:10 2017 -0300

    perf tools: Propagate perf_config() errors
    
    Previously these were being ignored, sometimes silently.
    
    Stop doing that, emitting debug messages and handling the errors.
    
    Testing it:
    
      $ cat ~/.perfconfig
      cat: /home/acme/.perfconfig: No such file or directory
      $ perf stat -e cycles usleep 1
    
       Performance counter stats for 'usleep 1':
    
               938,996      cycles:u
    
           0.003813731 seconds time elapsed
    
      $ perf top --stdio
      Error:
      You may not have permission to collect system-wide stats.
    
      Consider tweaking /proc/sys/kernel/perf_event_paranoid,
      <SNIP>
      [ perf record: Captured and wrote 0.019 MB perf.data (7 samples) ]
      [acme@jouet linux]$ perf report --stdio
      # To display the perf.data header info, please use --header/--header-only options.
      # Overhead  Command  Shared Object      Symbol
      # ........  .......  .................  .........................
        71.77%  usleep   libc-2.24.so       [.] _dl_addr
        27.07%  usleep   ld-2.24.so         [.] _dl_next_ld_env_entry
         1.13%  usleep   [kernel.kallsyms]  [k] page_fault
      $
      $ touch ~/.perfconfig
      $ ls -la ~/.perfconfig
      -rw-rw-r--. 1 acme acme 0 Jan 27 12:14 /home/acme/.perfconfig
      $
      $ perf stat -e instructions usleep 1
    
       Performance counter stats for 'usleep 1':
    
               244,610      instructions:u
    
           0.000805383 seconds time elapsed
    
      $
      [root@jouet ~]# chown acme.acme ~/.perfconfig
      [root@jouet ~]# perf stat -e cycles usleep 1
        Warning: File /root/.perfconfig not owned by current user or root, ignoring it.
    
       Performance counter stats for 'usleep 1':
    
               937,615      cycles
    
           0.000836931 seconds time elapsed
      #
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-j2rq96so6xdqlr8p8rd6a3jx@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 915869e00d86..29f4751a3574 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1920,10 +1920,12 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 		NULL
 	};
 	struct perf_session *session;
-	int ret = -1;
 	const char errmsg[] = "No %s allocation events found.  Have you run 'perf kmem record --%s'?\n";
+	int ret = perf_config(kmem_config, NULL);
+
+	if (ret)
+		return ret;
 
-	perf_config(kmem_config, NULL);
 	argc = parse_options_subcommand(argc, argv, kmem_options,
 					kmem_subcommands, kmem_usage, 0);
 
@@ -1948,6 +1950,8 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 	if (session == NULL)
 		return -1;
 
+	ret = -1;
+
 	if (kmem_slab) {
 		if (!perf_evlist__find_tracepoint_by_name(session->evlist,
 							  "kmem:kmalloc")) {

commit 41b6167e8f746b475668f1da78599fc4284f18db
Author: Michal Hocko <mhocko@suse.com>
Date:   Tue Jan 10 16:57:42 2017 -0800

    mm: get rid of __GFP_OTHER_NODE
    
    The flag was introduced by commit 78afd5612deb ("mm: add
    __GFP_OTHER_NODE flag") to allow proper accounting of remote node
    allocations done by kernel daemons on behalf of a process - e.g.
    khugepaged.
    
    After "mm: fix remote numa hits statistics" we do not need and actually
    use the flag so we can safely remove it because all allocations which
    are satisfied from their "home" node are accounted properly.
    
    [mhocko@suse.com: fix build]
    Link: http://lkml.kernel.org/r/20170106122225.GK5556@dhcp22.suse.cz
    Link: http://lkml.kernel.org/r/20170102153057.9451-3-mhocko@kernel.org
    Signed-off-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Mel Gorman <mgorman@suse.de>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Cc: Taku Izumi <izumi.taku@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 35a02f8e5a4a..915869e00d86 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -655,7 +655,6 @@ static const struct {
 	{ "__GFP_RECLAIM",		"R" },
 	{ "__GFP_DIRECT_RECLAIM",	"DR" },
 	{ "__GFP_KSWAPD_RECLAIM",	"KR" },
-	{ "__GFP_OTHER_NODE",		"ON" },
 };
 
 static size_t max_gfp_len;

commit 2a865bd8dddd44315c88bf922761e4fd3374d046
Author: David Ahern <dsa@cumulusnetworks.com>
Date:   Tue Nov 29 10:15:45 2016 -0700

    perf kmem: Add option to specify time window of interest
    
    Add option to allow user to control analysis window. e.g., collect data
    for time window and analyze a segment of interest within that window.
    
    Committer notes:
    
    Testing it:
    
      # perf kmem record usleep 1
      [ perf record: Woken up 0 times to write data ]
      [ perf record: Captured and wrote 1.540 MB perf.data (2049 samples) ]
      # perf evlist
      kmem:kmalloc
      kmem:kmalloc_node
      kmem:kfree
      kmem:kmem_cache_alloc
      kmem:kmem_cache_alloc_node
      kmem:kmem_cache_free
      # Tip: use 'perf evlist --trace-fields' to show fields for tracepoint events
      #
      # # Use 'perf script' to get a first approach, select a chunk for then using
      # # with 'perf kmem stat --time'
      #
      # perf script | tail -15
        usleep 9889 [0] 20119.782088:  kmem:kmem_cache_free: (selinux_file_free_security+0x27) call_site=ffffffffb936aa07 ptr=0xffff888a1df49fc0
          perf 9888 [3] 20119.782088:  kmem:kmem_cache_free: (jbd2_journal_stop+0x1a1) call_site=ffffffffb9334581 ptr=0xffff888bdf1a39c0
          perf 9888 [3] 20119.782089: kmem:kmem_cache_alloc: (jbd2__journal_start+0x72) call_site=ffffffffb9333b42 ptr=0xffff888bdf1a39c0 bytes_req=48 bytes_alloc=48 gfp_flags=GFP_NOFS|__GFP_ZERO
          perf 9888 [3] 20119.782090:  kmem:kmem_cache_free: (jbd2_journal_stop+0x1a1) call_site=ffffffffb9334581 ptr=0xffff888bdf1a39c0
          perf 9888 [3] 20119.782090: kmem:kmem_cache_alloc: (jbd2__journal_start+0x72) call_site=ffffffffb9333b42 ptr=0xffff888bdf1a39c0 bytes_req=48 bytes_alloc=48 gfp_flags=GFP_NOFS|__GFP_ZERO
        usleep 9889 [0] 20119.782091: kmem:kmem_cache_alloc: (__sigqueue_alloc+0x4a) call_site=ffffffffb90ad33a ptr=0xffff8889f071f6e0 bytes_req=160 bytes_alloc=160 gfp_flags=GFP_ATOMIC|__GFP_NOTRACK
          perf 9888 [3] 20119.782091:  kmem:kmem_cache_free: (jbd2_journal_stop+0x1a1) call_site=ffffffffb9334581 ptr=0xffff888bdf1a39c0
          perf 9888 [3] 20119.782093:  kmem:kmem_cache_free: (__sigqueue_free.part.17+0x33) call_site=ffffffffb90ad3f3 ptr=0xffff8889f071f6e0
          perf 9888 [3] 20119.782098: kmem:kmem_cache_alloc: (jbd2__journal_start+0x72) call_site=ffffffffb9333b42 ptr=0xffff888bdf1a39c0 bytes_req=48 bytes_alloc=48 gfp_flags=GFP_NOFS|__GFP_ZERO
          perf 9888 [3] 20119.782098:  kmem:kmem_cache_free: (jbd2_journal_stop+0x1a1) call_site=ffffffffb9334581 ptr=0xffff888bdf1a39c0
          perf 9888 [3] 20119.782099: kmem:kmem_cache_alloc: (jbd2__journal_start+0x72) call_site=ffffffffb9333b42 ptr=0xffff888bdf1a39c0 bytes_req=48 bytes_alloc=48 gfp_flags=GFP_NOFS|__GFP_ZERO
          perf 9888 [3] 20119.782100: kmem:kmem_cache_alloc: (alloc_buffer_head+0x21) call_site=ffffffffb9287cc1 ptr=0xffff8889b12722d8 bytes_req=104 bytes_alloc=104 gfp_flags=GFP_NOFS|__GFP_ZERO
          perf 9888 [3] 20119.782101:  kmem:kmem_cache_free: (jbd2_journal_stop+0x1a1) call_site=ffffffffb9334581 ptr=0xffff888bdf1a39c0
          perf 9888 [3] 20119.782102: kmem:kmem_cache_alloc: (jbd2__journal_start+0x72) call_site=ffffffffb9333b42 ptr=0xffff888bdf1a39c0 bytes_req=48 bytes_alloc=48 gfp_flags=GFP_NOFS|__GFP_ZERO
          perf 9888 [3] 20119.782103:  kmem:kmem_cache_free: (jbd2_journal_stop+0x1a1) call_site=ffffffffb9334581 ptr=0xffff888bdf1a39c0
      #
      # # stats for the whole perf.data file, i.e. no interval specified
      #
      # perf kmem stat
    
      SUMMARY (SLAB allocator)
      ========================
      Total bytes requested: 172,628
      Total bytes allocated: 173,088
      Total bytes freed:     161,280
      Net total bytes allocated: 11,808
      Total bytes wasted on internal fragmentation: 460
      Internal fragmentation: 0.265761%
      Cross CPU allocations: 0/851
      #
      # # stats for an end open interval, after a certain time:
      #
      # perf kmem stat --time 20119.782088,
    
      SUMMARY (SLAB allocator)
      ========================
      Total bytes requested: 552
      Total bytes allocated: 552
      Total bytes freed:     448
      Net total bytes allocated: 104
      Total bytes wasted on internal fragmentation: 0
      Internal fragmentation: 0.000000%
      Cross CPU allocations: 0/8
      #
    
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Acked-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1480439746-42695-6-git-send-email-dsahern@gmail.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 7fd6f1e1e293..35a02f8e5a4a 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -11,6 +11,7 @@
 #include "util/session.h"
 #include "util/tool.h"
 #include "util/callchain.h"
+#include "util/time-utils.h"
 
 #include <subcmd/parse-options.h>
 #include "util/trace-event.h"
@@ -66,6 +67,10 @@ static struct rb_root root_caller_sorted;
 static unsigned long total_requested, total_allocated, total_freed;
 static unsigned long nr_allocs, nr_cross_allocs;
 
+/* filters for controlling start and stop of time of analysis */
+static struct perf_time_interval ptime;
+const char *time_str;
+
 static int insert_alloc_stat(unsigned long call_site, unsigned long ptr,
 			     int bytes_req, int bytes_alloc, int cpu)
 {
@@ -912,6 +917,15 @@ static int perf_evsel__process_page_free_event(struct perf_evsel *evsel,
 	return 0;
 }
 
+static bool perf_kmem__skip_sample(struct perf_sample *sample)
+{
+	/* skip sample based on time? */
+	if (perf_time__skip_sample(&ptime, sample->time))
+		return true;
+
+	return false;
+}
+
 typedef int (*tracepoint_handler)(struct perf_evsel *evsel,
 				  struct perf_sample *sample);
 
@@ -931,6 +945,9 @@ static int process_sample_event(struct perf_tool *tool __maybe_unused,
 		return -1;
 	}
 
+	if (perf_kmem__skip_sample(sample))
+		return 0;
+
 	dump_printf(" ... thread: %s:%d\n", thread__comm_str(thread), thread->tid);
 
 	if (evsel->handler != NULL) {
@@ -1894,6 +1911,8 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 	OPT_CALLBACK_NOOPT(0, "page", NULL, NULL, "Analyze page allocator",
 			   parse_page_opt),
 	OPT_BOOLEAN(0, "live", &live_page, "Show live page stat"),
+	OPT_STRING(0, "time", &time_str, "str",
+		   "Time span of interest (start,stop)"),
 	OPT_END()
 	};
 	const char *const kmem_subcommands[] = { "record", "stat", NULL };
@@ -1954,6 +1973,11 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 
 	symbol__init(&session->header.env);
 
+	if (perf_time__parse_str(&ptime, time_str) != 0) {
+		pr_err("Invalid time string\n");
+		return -EINVAL;
+	}
+
 	if (!strcmp(argv[0], "stat")) {
 		setlocale(LC_ALL, "");
 

commit aa58e9afb613fab74f33292705bb43beb0f1828d
Author: David Ahern <dsa@cumulusnetworks.com>
Date:   Fri Nov 25 14:42:13 2016 -0700

    perf kmem stat: Track memory freed
    
    Track freed memory as well as allocations and show the net in the
    summary.
    
    Committer notes:
    
    Testing it:
    
      # perf kmem record usleep 1
      [ perf record: Woken up 0 times to write data ]
      [ perf record: Captured and wrote 1.626 MB perf.data (4208 samples) ]
      [root@jouet ~]# perf kmem stat --slab
    
      SUMMARY (SLAB allocator)
      ========================
      Total bytes requested: 234,011
      Total bytes allocated: 234,504
      Total bytes freed:     213,328                                 <------
      Net total bytes allocated: 21,176
      Total bytes wasted on internal fragmentation: 493
      Internal fragmentation: 0.210231%
      Cross CPU allocations: 4/1,963
      #
    
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1480110133-37039-1-git-send-email-dsahern@gmail.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index d426dcb18ce9..7fd6f1e1e293 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -49,6 +49,7 @@ struct alloc_stat {
 	u64	ptr;
 	u64	bytes_req;
 	u64	bytes_alloc;
+	u64	last_alloc;
 	u32	hit;
 	u32	pingpong;
 
@@ -62,7 +63,7 @@ static struct rb_root root_alloc_sorted;
 static struct rb_root root_caller_stat;
 static struct rb_root root_caller_sorted;
 
-static unsigned long total_requested, total_allocated;
+static unsigned long total_requested, total_allocated, total_freed;
 static unsigned long nr_allocs, nr_cross_allocs;
 
 static int insert_alloc_stat(unsigned long call_site, unsigned long ptr,
@@ -105,6 +106,8 @@ static int insert_alloc_stat(unsigned long call_site, unsigned long ptr,
 	}
 	data->call_site = call_site;
 	data->alloc_cpu = cpu;
+	data->last_alloc = bytes_alloc;
+
 	return 0;
 }
 
@@ -223,6 +226,8 @@ static int perf_evsel__process_free_event(struct perf_evsel *evsel,
 	if (!s_alloc)
 		return 0;
 
+	total_freed += s_alloc->last_alloc;
+
 	if ((short)sample->cpu != s_alloc->alloc_cpu) {
 		s_alloc->pingpong++;
 
@@ -1128,6 +1133,11 @@ static void print_slab_summary(void)
 	printf("\n========================\n");
 	printf("Total bytes requested: %'lu\n", total_requested);
 	printf("Total bytes allocated: %'lu\n", total_allocated);
+	printf("Total bytes freed:     %'lu\n", total_freed);
+	if (total_allocated > total_freed) {
+		printf("Net total bytes allocated: %'lu\n",
+		total_allocated - total_freed);
+	}
 	printf("Total bytes wasted on internal fragmentation: %'lu\n",
 	       total_allocated - total_requested);
 	printf("Internal fragmentation: %f%%\n",

commit be39db9f2932f0ce4e116c71ba5ae2b542e536a7
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Sep 1 19:25:52 2016 -0300

    perf symbols: Remove symbol_filter_t machinery
    
    We're not using it anymore, few users were, but we really could do
    without it, simplify lots of functions by removing it.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-1zng8wdznn00iiz08bb7q3vn@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index fdde1bd3e306..d426dcb18ce9 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -330,7 +330,7 @@ static int build_alloc_func_list(void)
 	}
 
 	kernel_map = machine__kernel_map(machine);
-	if (map__load(kernel_map, NULL) < 0) {
+	if (map__load(kernel_map) < 0) {
 		pr_err("cannot load kernel map\n");
 		return -ENOENT;
 	}
@@ -979,7 +979,7 @@ static void __print_slab_result(struct rb_root *root,
 		if (is_caller) {
 			addr = data->call_site;
 			if (!raw_ip)
-				sym = machine__find_kernel_function(machine, addr, &map, NULL);
+				sym = machine__find_kernel_function(machine, addr, &map);
 		} else
 			addr = data->ptr;
 
@@ -1043,8 +1043,7 @@ static void __print_page_alloc_result(struct perf_session *session, int n_lines)
 		char *caller = buf;
 
 		data = rb_entry(next, struct page_stat, node);
-		sym = machine__find_kernel_function(machine, data->callsite,
-						    &map, NULL);
+		sym = machine__find_kernel_function(machine, data->callsite, &map);
 		if (sym && sym->name)
 			caller = sym->name;
 		else
@@ -1086,8 +1085,7 @@ static void __print_page_caller_result(struct perf_session *session, int n_lines
 		char *caller = buf;
 
 		data = rb_entry(next, struct page_stat, node);
-		sym = machine__find_kernel_function(machine, data->callsite,
-						    &map, NULL);
+		sym = machine__find_kernel_function(machine, data->callsite, &map);
 		if (sym && sym->name)
 			caller = sym->name;
 		else

commit 2516035499b9555f6acd373c9f12e44bcb50dbec
Author: Vlastimil Babka <vbabka@suse.cz>
Date:   Thu Jul 28 15:49:25 2016 -0700

    mm, thp: remove __GFP_NORETRY from khugepaged and madvised allocations
    
    After the previous patch, we can distinguish costly allocations that
    should be really lightweight, such as THP page faults, with
    __GFP_NORETRY.  This means we don't need to recognize khugepaged
    allocations via PF_KTHREAD anymore.  We can also change THP page faults
    in areas where madvise(MADV_HUGEPAGE) was used to try as hard as
    khugepaged, as the process has indicated that it benefits from THP's and
    is willing to pay some initial latency costs.
    
    We can also make the flags handling less cryptic by distinguishing
    GFP_TRANSHUGE_LIGHT (no reclaim at all, default mode in page fault) from
    GFP_TRANSHUGE (only direct reclaim, khugepaged default).  Adding
    __GFP_NORETRY or __GFP_KSWAPD_RECLAIM is done where needed.
    
    The patch effectively changes the current GFP_TRANSHUGE users as
    follows:
    
    * get_huge_zero_page() - the zero page lifetime should be relatively
      long and it's shared by multiple users, so it's worth spending some
      effort on it.  We use GFP_TRANSHUGE, and __GFP_NORETRY is not added.
      This also restores direct reclaim to this allocation, which was
      unintentionally removed by commit e4a49efe4e7e ("mm: thp: set THP defrag
      by default to madvise and add a stall-free defrag option")
    
    * alloc_hugepage_khugepaged_gfpmask() - this is khugepaged, so latency
      is not an issue.  So if khugepaged "defrag" is enabled (the default), do
      reclaim via GFP_TRANSHUGE without __GFP_NORETRY.  We can remove the
      PF_KTHREAD check from page alloc.
    
      As a side-effect, khugepaged will now no longer check if the initial
      compaction was deferred or contended.  This is OK, as khugepaged sleep
      times between collapsion attempts are long enough to prevent noticeable
      disruption, so we should allow it to spend some effort.
    
    * migrate_misplaced_transhuge_page() - already was masking out
      __GFP_RECLAIM, so just convert to GFP_TRANSHUGE_LIGHT which is
      equivalent.
    
    * alloc_hugepage_direct_gfpmask() - vma's with VM_HUGEPAGE (via madvise)
      are now allocating without __GFP_NORETRY.  Other vma's keep using
      __GFP_NORETRY if direct reclaim/compaction is at all allowed (by default
      it's allowed only for madvised vma's).  The rest is conversion to
      GFP_TRANSHUGE(_LIGHT).
    
    [mhocko@suse.com: suggested GFP_TRANSHUGE_LIGHT]
    Link: http://lkml.kernel.org/r/20160721073614.24395-7-vbabka@suse.cz
    Signed-off-by: Vlastimil Babka <vbabka@suse.cz>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Mel Gorman <mgorman@techsingularity.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index b1d491c2e704..fdde1bd3e306 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -608,6 +608,7 @@ static const struct {
 	const char *compact;
 } gfp_compact_table[] = {
 	{ "GFP_TRANSHUGE",		"THP" },
+	{ "GFP_TRANSHUGE_LIGHT",	"THL" },
 	{ "GFP_HIGHUSER_MOVABLE",	"HUM" },
 	{ "GFP_HIGHUSER",		"HU" },
 	{ "GFP_USER",			"U" },

commit e5cadb93d0839d268a7c4199e0fdef0f94722117
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Jun 23 11:26:15 2016 -0300

    perf evlist: Rename for_each() macros to for_each_entry()
    
    To match the semantics for list.h in the kernel, that are used to
    implement those macros.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Milian Wolff <milian.wolff@kdab.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Taeung Song <treeze.taeung@gmail.com>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-qbcjlgj0ffxquxscahbpddi3@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 4defe44a4a83..b1d491c2e704 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1354,7 +1354,7 @@ static int __cmd_kmem(struct perf_session *session)
 		goto out;
 	}
 
-	evlist__for_each(session->evlist, evsel) {
+	evlist__for_each_entry(session->evlist, evsel) {
 		if (!strcmp(perf_evsel__name(evsel), "kmem:mm_page_alloc") &&
 		    perf_evsel__field(evsel, "pfn")) {
 			use_pfn = true;

commit 41840d211c518e6af6e327b03e09323824e563bf
Author: Taeung Song <treeze.taeung@gmail.com>
Date:   Thu Jun 23 17:55:17 2016 +0900

    perf config: Move config declarations from util/cache.h to util/config.h
    
    Lately util/config.h has been added but util/cache.h has declarations of
    functions and a global variable for config features.
    
    To manage codes about configuration at one spot, move them to
    util/config.h and let source files that need config features include
    config.h And if the source files that included previous cache.h need
    only config.h, remove including cache.h.
    
    Signed-off-by: Taeung Song <treeze.taeung@gmail.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/r/1466672119-4852-2-git-send-email-treeze.taeung@gmail.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 58adfee230de..4defe44a4a83 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -4,7 +4,7 @@
 #include "util/evlist.h"
 #include "util/evsel.h"
 #include "util/util.h"
-#include "util/cache.h"
+#include "util/config.h"
 #include "util/symbol.h"
 #include "util/thread.h"
 #include "util/header.h"

commit 91d7b2de318ff701451dfc7ede1c029b150ef0e9
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Apr 14 14:48:07 2016 -0300

    perf callchain: Start moving away from global per thread cursors
    
    The recent perf_evsel__fprintf_callchain() move to evsel.c added several
    new symbol requirements to the python binding, for instance:
    
      # perf test -v python
      16: Try 'import perf' in python, checking link problems      :
      --- start ---
      test child forked, pid 18030
      Traceback (most recent call last):
        File "<stdin>", line 1, in <module>
      ImportError: /tmp/build/perf/python/perf.so: undefined symbol:
      callchain_cursor
      test child finished with -1
      ---- end ----
      Try 'import perf' in python, checking link problems: FAILED!
      #
    
    This would require linking against callchain.c to access to the global
    callchain_cursor variables.
    
    Since lots of functions already receive as a parameter a
    callchain_cursor struct pointer, make that be the case for some more
    function so that we can start phasing out usage of yet another global
    variable.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-djko3097eyg2rn66v2qcqfvn@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index c9cb3be47cff..58adfee230de 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -375,7 +375,7 @@ static u64 find_callsite(struct perf_evsel *evsel, struct perf_sample *sample)
 	}
 
 	al.thread = machine__findnew_thread(machine, sample->pid, sample->tid);
-	sample__resolve_callchain(sample, NULL, evsel, &al, 16);
+	sample__resolve_callchain(sample, &callchain_cursor, NULL, evsel, &al, 16);
 
 	callchain_cursor_commit(&callchain_cursor);
 	while (true) {

commit 420adbe9fc1a45187cfa74df9dbfd72272c4e2fa
Author: Vlastimil Babka <vbabka@suse.cz>
Date:   Tue Mar 15 14:55:52 2016 -0700

    mm, tracing: unify mm flags handling in tracepoints and printk
    
    In tracepoints, it's possible to print gfp flags in a human-friendly
    format through a macro show_gfp_flags(), which defines a translation
    array and passes is to __print_flags().  Since the following patch will
    introduce support for gfp flags printing in printk(), it would be nice
    to reuse the array.  This is not straightforward, since __print_flags()
    can't simply reference an array defined in a .c file such as mm/debug.c
    - it has to be a macro to allow the macro magic to communicate the
    format to userspace tools such as trace-cmd.
    
    The solution is to create a macro __def_gfpflag_names which is used both
    in show_gfp_flags(), and to define the gfpflag_names[] array in
    mm/debug.c.
    
    On the other hand, mm/debug.c also defines translation tables for page
    flags and vma flags, and desire was expressed (but not implemented in
    this series) to use these also from tracepoints.  Thus, this patch also
    renames the events/gfpflags.h file to events/mmflags.h and moves the
    table definitions there, using the same macro approach as for gfpflags.
    This allows translating all three kinds of mm-specific flags both in
    tracepoints and printk.
    
    Signed-off-by: Vlastimil Babka <vbabka@suse.cz>
    Reviewed-by: Michal Hocko <mhocko@suse.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Sasha Levin <sasha.levin@oracle.com>
    Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
    Cc: Mel Gorman <mgorman@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 83343ed30e8f..c9cb3be47cff 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -602,7 +602,7 @@ static int gfpcmp(const void *a, const void *b)
 	return fa->flags - fb->flags;
 }
 
-/* see include/trace/events/gfpflags.h */
+/* see include/trace/events/mmflags.h */
 static const struct {
 	const char *original;
 	const char *compact;

commit 14e0a214d62d284ff40b1fd7d687cb66fca9fc67
Author: Vlastimil Babka <vbabka@suse.cz>
Date:   Tue Mar 15 14:55:49 2016 -0700

    tools, perf: make gfp_compact_table up to date
    
    When updating tracing's show_gfp_flags() I have noticed that perf's
    gfp_compact_table is also outdated.  Fill in the missing flags and place
    a note in gfp.h to increase chance that future updates are synced.
    Convert the __GFP_X flags from "GFP_X" to "__GFP_X" strings in line with
    the previous patch.
    
    Signed-off-by: Vlastimil Babka <vbabka@suse.cz>
    Acked-by: David Rientjes <rientjes@google.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Sasha Levin <sasha.levin@oracle.com>
    Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 4d3340cce9a0..83343ed30e8f 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -612,30 +612,39 @@ static const struct {
 	{ "GFP_HIGHUSER",		"HU" },
 	{ "GFP_USER",			"U" },
 	{ "GFP_TEMPORARY",		"TMP" },
+	{ "GFP_KERNEL_ACCOUNT",		"KAC" },
 	{ "GFP_KERNEL",			"K" },
 	{ "GFP_NOFS",			"NF" },
 	{ "GFP_ATOMIC",			"A" },
 	{ "GFP_NOIO",			"NI" },
-	{ "GFP_HIGH",			"H" },
-	{ "GFP_WAIT",			"W" },
-	{ "GFP_IO",			"I" },
-	{ "GFP_COLD",			"CO" },
-	{ "GFP_NOWARN",			"NWR" },
-	{ "GFP_REPEAT",			"R" },
-	{ "GFP_NOFAIL",			"NF" },
-	{ "GFP_NORETRY",		"NR" },
-	{ "GFP_COMP",			"C" },
-	{ "GFP_ZERO",			"Z" },
-	{ "GFP_NOMEMALLOC",		"NMA" },
-	{ "GFP_MEMALLOC",		"MA" },
-	{ "GFP_HARDWALL",		"HW" },
-	{ "GFP_THISNODE",		"TN" },
-	{ "GFP_RECLAIMABLE",		"RC" },
-	{ "GFP_MOVABLE",		"M" },
-	{ "GFP_NOTRACK",		"NT" },
-	{ "GFP_NO_KSWAPD",		"NK" },
-	{ "GFP_OTHER_NODE",		"ON" },
 	{ "GFP_NOWAIT",			"NW" },
+	{ "GFP_DMA",			"D" },
+	{ "__GFP_HIGHMEM",		"HM" },
+	{ "GFP_DMA32",			"D32" },
+	{ "__GFP_HIGH",			"H" },
+	{ "__GFP_ATOMIC",		"_A" },
+	{ "__GFP_IO",			"I" },
+	{ "__GFP_FS",			"F" },
+	{ "__GFP_COLD",			"CO" },
+	{ "__GFP_NOWARN",		"NWR" },
+	{ "__GFP_REPEAT",		"R" },
+	{ "__GFP_NOFAIL",		"NF" },
+	{ "__GFP_NORETRY",		"NR" },
+	{ "__GFP_COMP",			"C" },
+	{ "__GFP_ZERO",			"Z" },
+	{ "__GFP_NOMEMALLOC",		"NMA" },
+	{ "__GFP_MEMALLOC",		"MA" },
+	{ "__GFP_HARDWALL",		"HW" },
+	{ "__GFP_THISNODE",		"TN" },
+	{ "__GFP_RECLAIMABLE",		"RC" },
+	{ "__GFP_MOVABLE",		"M" },
+	{ "__GFP_ACCOUNT",		"AC" },
+	{ "__GFP_NOTRACK",		"NT" },
+	{ "__GFP_WRITE",		"WR" },
+	{ "__GFP_RECLAIM",		"R" },
+	{ "__GFP_DIRECT_RECLAIM",	"DR" },
+	{ "__GFP_KSWAPD_RECLAIM",	"KR" },
+	{ "__GFP_OTHER_NODE",		"ON" },
 };
 
 static size_t max_gfp_len;

commit b8cbb349061edda648463b086cfa869a7ab583af
Author: Wang Nan <wangnan0@huawei.com>
Date:   Fri Feb 26 09:31:51 2016 +0000

    perf config: Bring perf_default_config to the very beginning at main()
    
    Before this patch each subcommand calls perf_config() by themself,
    reading the default configuration together with subcommand specific
    options. If a subcommand doesn't have it own options, it needs to call
    'perf_config(perf_default_config, NULL)' to ensure .perfconfig is
    loaded.
    
    This patch brings perf_config(perf_default_config, NULL) to the very
    start of main(), so subcommands don't need to do it.
    
    After this patch, 'llvm.clang-path' works for 'perf trace'.
    
    Signed-off-by: Wang Nan <wangnan0@huawei.com>
    Suggested-and-Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Alexei Starovoitov <ast@kernel.org>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Li Zefan <lizefan@huawei.com>
    Cc: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: pi3orama@163.com
    Link: http://lkml.kernel.org/r/1456479154-136027-4-git-send-email-wangnan0@huawei.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 118010553d0c..4d3340cce9a0 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1834,7 +1834,7 @@ static int __cmd_record(int argc, const char **argv)
 	return cmd_record(i, rec_argv, NULL);
 }
 
-static int kmem_config(const char *var, const char *value, void *cb)
+static int kmem_config(const char *var, const char *value, void *cb __maybe_unused)
 {
 	if (!strcmp(var, "kmem.default")) {
 		if (!strcmp(value, "slab"))
@@ -1847,7 +1847,7 @@ static int kmem_config(const char *var, const char *value, void *cb)
 		return 0;
 	}
 
-	return perf_default_config(var, value, cb);
+	return 0;
 }
 
 int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)

commit 4b6ab94eabe4f55371cff4569750bb3996c55db6
Author: Josh Poimboeuf <jpoimboe@redhat.com>
Date:   Tue Dec 15 09:39:39 2015 -0600

    perf subcmd: Create subcmd library
    
    Move the subcommand-related files from perf to a new library named
    libsubcmd.a.
    
    Since we're moving files anyway, go ahead and rename 'exec_cmd.*' to
    'exec-cmd.*' to be consistent with the naming of all the other files.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/c0a838d4c878ab17fee50998811612b2281355c1.1450193761.git.jpoimboe@redhat.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 93ce665f976f..118010553d0c 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -12,7 +12,7 @@
 #include "util/tool.h"
 #include "util/callchain.h"
 
-#include "util/parse-options.h"
+#include <subcmd/parse-options.h>
 #include "util/trace-event.h"
 #include "util/data.h"
 #include "util/cpumap.h"

commit a5e813c68649366aaa3f785772b00ea6ccad7b8d
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Sep 30 11:54:04 2015 -0300

    perf machine: Add method for common kernel_map(FUNCTION) operation
    
    And it is also a step in the direction of killing the separation of data
    and text maps in map_groups.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-rrds86kb3wx5wk8v38v56gw8@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index b122c4e0818e..93ce665f976f 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -329,7 +329,7 @@ static int build_alloc_func_list(void)
 		return -EINVAL;
 	}
 
-	kernel_map = machine__kernel_map(machine, MAP__FUNCTION)
+	kernel_map = machine__kernel_map(machine);
 	if (map__load(kernel_map, NULL) < 0) {
 		pr_err("cannot load kernel map\n");
 		return -ENOENT;

commit 77e65977495cd6f6fcfacd8c16bdd9c8c18a1d72
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Sep 30 11:08:58 2015 -0300

    perf machine: Use machine__kernel_map() thoroughly
    
    In places where we were using its open coded equivalent.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/n/tip-khkdugcdoqy3tkszm3jdxgbe@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 23b1faaaa4cc..b122c4e0818e 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -329,7 +329,7 @@ static int build_alloc_func_list(void)
 		return -EINVAL;
 	}
 
-	kernel_map = machine->vmlinux_maps[MAP__FUNCTION];
+	kernel_map = machine__kernel_map(machine, MAP__FUNCTION)
 	if (map__load(kernel_map, NULL) < 0) {
 		pr_err("cannot load kernel map\n");
 		return -ENOENT;

commit 249ca1a86067e6a4198f7b2b7e19b505e2f41864
Author: Taeung Song <treeze.taeung@gmail.com>
Date:   Tue Jun 30 17:15:21 2015 +0900

    perf kmem: Fill in the missing session freeing after an error occurs
    
    When an error occurs an error value is just returned without freeing the
    session. So allocating and freeing session have to be matched as a pair
    even if an error occurs.
    
    Signed-off-by: Taeung Song <treeze.taeung@gmail.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: http://lkml.kernel.org/r/1435652124-22414-3-git-send-email-treeze.taeung@gmail.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 950f296dfcf7..23b1faaaa4cc 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1916,7 +1916,7 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 		if (!perf_evlist__find_tracepoint_by_name(session->evlist,
 							  "kmem:kmalloc")) {
 			pr_err(errmsg, "slab", "slab");
-			return -1;
+			goto out_delete;
 		}
 	}
 
@@ -1927,7 +1927,7 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 							     "kmem:mm_page_alloc");
 		if (evsel == NULL) {
 			pr_err(errmsg, "page", "page");
-			return -1;
+			goto out_delete;
 		}
 
 		kmem_page_size = pevent_get_page_size(evsel->tp_format->pevent);

commit b236512280fb96dcca45a3f5bbae1839bd673e58
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri May 29 09:48:13 2015 -0300

    perf kmem: Fix compiler warning about may be accessing uninitialized variable
    
    The last argument to strtok_r doesn't need to be initialized, its just a
    placeholder to make this routine reentrant, but gcc doesn't know about
    that and complains, breaking the build, fix it by setting it to NULL.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: http://lkml.kernel.org/n/tip-8e8rgbg3aom9uarsyqjrsctg@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 254614b10c4a..950f296dfcf7 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -644,7 +644,7 @@ static char *compact_gfp_flags(char *gfp_flags)
 {
 	char *orig_flags = strdup(gfp_flags);
 	char *new_flags = NULL;
-	char *str, *pos;
+	char *str, *pos = NULL;
 	size_t len = 0;
 
 	if (orig_flags == NULL)

commit 08a9b9857fc2d77600f09f3d342f6c64d25083b2
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon May 11 11:41:17 2015 -0300

    perf kmem: Fix compiler warning about may be accessing uninitialized variable
    
    The last argument to strtok_r doesn't need to be initialized, its just a
    placeholder to make this routine reentrant, but gcc doesn't know about
    that and complains, breaking the build, fix it by setting it to NULL.
    
    Fixes: 0e11115644b3 ("perf kmem: Print gfp flags in human readable string")
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-iyyvkbnkrd9g19f6ta9zfkem@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index e0173c7f17b1..254614b10c4a 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -713,7 +713,7 @@ static int parse_gfp_flags(struct perf_evsel *evsel, struct perf_sample *sample,
 		.size = sample->raw_size,
 	};
 	struct trace_seq seq;
-	char *str, *pos;
+	char *str, *pos = NULL;
 
 	if (nr_gfps) {
 		struct gfp_flag key = {

commit f7dc7fd1c08c6d8109688694fd93d80645df89ff
Merge: 32b0ed3ae66c 44b11fee5171
Author: Ingo Molnar <mingo@kernel.org>
Date:   Mon May 11 11:56:27 2015 +0200

    Merge branch 'perf/urgent' into perf/core, to resolve conflicts
    
    Conflicts:
            tools/perf/builtin-kmem.c
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit b91fc39f4ad7503419dd617df78401fa36266cb3
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Apr 6 20:43:22 2015 -0300

    perf machine: Protect the machine->threads with a rwlock
    
    In addition to using refcounts for the struct thread lifetime
    management, we need to protect access to machine->threads from
    concurrent access.
    
    That happens in 'perf top', where a thread processes events, inserting
    and deleting entries from that rb_tree while another thread decays
    hist_entries, that end up dropping references and ultimately deleting
    threads from the rb_tree and releasing its resources when no further
    hist_entry (or other data structures, like in 'perf sched') references
    it.
    
    So the rule is the same for refcounts + protected trees in the kernel,
    get the tree lock, find object, bump the refcount, drop the tree lock,
    return, use object, drop the refcount if no more use of it is needed,
    keep it if storing it in some other data structure, drop when releasing
    that data structure.
    
    I.e. pair "t = machine__find(new)_thread()" with a "thread__put(t)", and
    "perf_event__preprocess_sample(&al)" with "addr_location__put(&al)".
    
    The addr_location__put() one is because as we return references to
    several data structures, we may end up adding more reference counting
    for the other data structures and then we'll drop it at
    addr_location__put() time.
    
    Acked-by: David Ahern <dsahern@gmail.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-bs9rt4n0jw3hi9f3zxyy3xln@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index e628bf1a0c24..fe3fcb75f20a 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -906,6 +906,7 @@ static int process_sample_event(struct perf_tool *tool __maybe_unused,
 				struct perf_evsel *evsel,
 				struct machine *machine)
 {
+	int err = 0;
 	struct thread *thread = machine__findnew_thread(machine, sample->pid,
 							sample->tid);
 
@@ -919,10 +920,12 @@ static int process_sample_event(struct perf_tool *tool __maybe_unused,
 
 	if (evsel->handler != NULL) {
 		tracepoint_handler f = evsel->handler;
-		return f(evsel, sample);
+		err = f(evsel, sample);
 	}
 
-	return 0;
+	thread__put(thread);
+
+	return err;
 }
 
 static struct perf_tool perf_kmem = {

commit a923e2c4b14f99f70692f82ee7bd63717604b738
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Tue May 5 23:52:52 2015 +0900

    perf kmem: Show warning when trying to run stat without record
    
    Sometimes one can mistakenly run 'perf kmem stat' without running 'perf
    kmem record' before or with a different configuration like recording
    --slab and stat --page.  Show a warning message like the one below to
    inform the user:
    
      # perf kmem stat --page --caller
      No page allocation events found.  Have you run 'perf kmem record --page'?
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Acked-by: Pekka Enberg <penberg@kernel.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/1430837572-31395-1-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 828b7284e547..e628bf1a0c24 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1882,6 +1882,7 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 	};
 	struct perf_session *session;
 	int ret = -1;
+	const char errmsg[] = "No %s allocation events found.  Have you run 'perf kmem record --%s'?\n";
 
 	perf_config(kmem_config, NULL);
 	argc = parse_options_subcommand(argc, argv, kmem_options,
@@ -1908,11 +1909,21 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 	if (session == NULL)
 		return -1;
 
+	if (kmem_slab) {
+		if (!perf_evlist__find_tracepoint_by_name(session->evlist,
+							  "kmem:kmalloc")) {
+			pr_err(errmsg, "slab", "slab");
+			return -1;
+		}
+	}
+
 	if (kmem_page) {
-		struct perf_evsel *evsel = perf_evlist__first(session->evlist);
+		struct perf_evsel *evsel;
 
-		if (evsel == NULL || evsel->tp_format == NULL) {
-			pr_err("invalid event found.. aborting\n");
+		evsel = perf_evlist__find_tracepoint_by_name(session->evlist,
+							     "kmem:mm_page_alloc");
+		if (evsel == NULL) {
+			pr_err(errmsg, "page", "page");
 			return -1;
 		}
 

commit 0c160d495b5616e071bb4f873812e8f473128149
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Tue Apr 21 13:55:06 2015 +0900

    perf kmem: Add kmem.default config option
    
    Currently perf kmem command will select --slab if neither --slab nor
    --page is given for backward compatibility.  Add kmem.default config
    option to select the default value ('page' or 'slab').
    
      # cat ~/.perfconfig
      [kmem]
            default = page
    
      # perf kmem stat
    
      SUMMARY (page allocator)
      ========================
      Total allocation requests     :            1,518   [            6,096 KB ]
      Total free requests           :            1,431   [            5,748 KB ]
    
      Total alloc+freed requests    :            1,330   [            5,344 KB ]
      Total alloc-only requests     :              188   [              752 KB ]
      Total free-only requests      :              101   [              404 KB ]
    
      Total allocation failures     :                0   [                0 KB ]
      ...
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Acked-by: Pekka Enberg <penberg@kernel.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Taeung Song <treeze.taeung@gmail.com>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/1429592107-1807-6-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 1c668953c7ec..828b7284e547 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -28,6 +28,10 @@ static int	kmem_slab;
 static int	kmem_page;
 
 static long	kmem_page_size;
+static enum {
+	KMEM_SLAB,
+	KMEM_PAGE,
+} kmem_default = KMEM_SLAB;  /* for backward compatibility */
 
 struct alloc_stat;
 typedef int (*sort_fn_t)(void *, void *);
@@ -1710,7 +1714,8 @@ static int parse_sort_opt(const struct option *opt __maybe_unused,
 	if (!arg)
 		return -1;
 
-	if (kmem_page > kmem_slab) {
+	if (kmem_page > kmem_slab ||
+	    (kmem_page == 0 && kmem_slab == 0 && kmem_default == KMEM_PAGE)) {
 		if (caller_flag > alloc_flag)
 			return setup_page_sorting(&page_caller_sort, arg);
 		else
@@ -1826,6 +1831,22 @@ static int __cmd_record(int argc, const char **argv)
 	return cmd_record(i, rec_argv, NULL);
 }
 
+static int kmem_config(const char *var, const char *value, void *cb)
+{
+	if (!strcmp(var, "kmem.default")) {
+		if (!strcmp(value, "slab"))
+			kmem_default = KMEM_SLAB;
+		else if (!strcmp(value, "page"))
+			kmem_default = KMEM_PAGE;
+		else
+			pr_err("invalid default value ('slab' or 'page' required): %s\n",
+			       value);
+		return 0;
+	}
+
+	return perf_default_config(var, value, cb);
+}
+
 int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 {
 	const char * const default_slab_sort = "frag,hit,bytes";
@@ -1862,14 +1883,19 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 	struct perf_session *session;
 	int ret = -1;
 
+	perf_config(kmem_config, NULL);
 	argc = parse_options_subcommand(argc, argv, kmem_options,
 					kmem_subcommands, kmem_usage, 0);
 
 	if (!argc)
 		usage_with_options(kmem_usage, kmem_options);
 
-	if (kmem_slab == 0 && kmem_page == 0)
-		kmem_slab = 1;  /* for backward compatibility */
+	if (kmem_slab == 0 && kmem_page == 0) {
+		if (kmem_default == KMEM_SLAB)
+			kmem_slab = 1;
+		else
+			kmem_page = 1;
+	}
 
 	if (!strncmp(argv[0], "rec", 3)) {
 		symbol__init(NULL);

commit 0e11115644b39ff9e986eb308b6c44ca75cd475f
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Tue Apr 21 13:55:05 2015 +0900

    perf kmem: Print gfp flags in human readable string
    
    Save libtraceevent output and print it in the header.
    
      # perf kmem stat --page --caller
      #
      # GFP flags
      # ---------
      # 00000010:       NI: GFP_NOIO
      # 000000d0:        K: GFP_KERNEL
      # 00000200:      NWR: GFP_NOWARN
      # 000084d0:    K|R|Z: GFP_KERNEL|GFP_REPEAT|GFP_ZERO
      # 000200d2:       HU: GFP_HIGHUSER
      # 000200da:      HUM: GFP_HIGHUSER_MOVABLE
      # 000280da:    HUM|Z: GFP_HIGHUSER_MOVABLE|GFP_ZERO
      # 002084d0: K|R|Z|NT: GFP_KERNEL|GFP_REPEAT|GFP_ZERO|GFP_NOTRACK
      # 0102005a:  NF|HW|M: GFP_NOFS|GFP_HARDWALL|GFP_MOVABLE
    
      ---------------------------------------------------------------------------------------------------------
       Total alloc (KB) | Hits      | Order | Mig.type | GFP flags | Callsite
      ---------------------------------------------------------------------------------------------------------
                     60 |        15 |     0 | UNMOVABL | K|R|Z|NT  | pte_alloc_one
                     40 |        10 |     0 |  MOVABLE | HUM|Z     | handle_mm_fault
                     24 |         6 |     0 |  MOVABLE | HUM       | do_wp_page
                     24 |         6 |     0 | UNMOVABL | K         | __pollwait
       ...
    
    Requested-by: Joonsoo Kim <js1304@gmail.com>
    Suggested-by: Minchan Kim <minchan@kernel.org>
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Acked-by: Pekka Enberg <penberg@kernel.org>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/1429592107-1807-5-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 7ead9423fd7a..1c668953c7ec 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -581,6 +581,176 @@ static bool valid_page(u64 pfn_or_page)
 	return true;
 }
 
+struct gfp_flag {
+	unsigned int flags;
+	char *compact_str;
+	char *human_readable;
+};
+
+static struct gfp_flag *gfps;
+static int nr_gfps;
+
+static int gfpcmp(const void *a, const void *b)
+{
+	const struct gfp_flag *fa = a;
+	const struct gfp_flag *fb = b;
+
+	return fa->flags - fb->flags;
+}
+
+/* see include/trace/events/gfpflags.h */
+static const struct {
+	const char *original;
+	const char *compact;
+} gfp_compact_table[] = {
+	{ "GFP_TRANSHUGE",		"THP" },
+	{ "GFP_HIGHUSER_MOVABLE",	"HUM" },
+	{ "GFP_HIGHUSER",		"HU" },
+	{ "GFP_USER",			"U" },
+	{ "GFP_TEMPORARY",		"TMP" },
+	{ "GFP_KERNEL",			"K" },
+	{ "GFP_NOFS",			"NF" },
+	{ "GFP_ATOMIC",			"A" },
+	{ "GFP_NOIO",			"NI" },
+	{ "GFP_HIGH",			"H" },
+	{ "GFP_WAIT",			"W" },
+	{ "GFP_IO",			"I" },
+	{ "GFP_COLD",			"CO" },
+	{ "GFP_NOWARN",			"NWR" },
+	{ "GFP_REPEAT",			"R" },
+	{ "GFP_NOFAIL",			"NF" },
+	{ "GFP_NORETRY",		"NR" },
+	{ "GFP_COMP",			"C" },
+	{ "GFP_ZERO",			"Z" },
+	{ "GFP_NOMEMALLOC",		"NMA" },
+	{ "GFP_MEMALLOC",		"MA" },
+	{ "GFP_HARDWALL",		"HW" },
+	{ "GFP_THISNODE",		"TN" },
+	{ "GFP_RECLAIMABLE",		"RC" },
+	{ "GFP_MOVABLE",		"M" },
+	{ "GFP_NOTRACK",		"NT" },
+	{ "GFP_NO_KSWAPD",		"NK" },
+	{ "GFP_OTHER_NODE",		"ON" },
+	{ "GFP_NOWAIT",			"NW" },
+};
+
+static size_t max_gfp_len;
+
+static char *compact_gfp_flags(char *gfp_flags)
+{
+	char *orig_flags = strdup(gfp_flags);
+	char *new_flags = NULL;
+	char *str, *pos;
+	size_t len = 0;
+
+	if (orig_flags == NULL)
+		return NULL;
+
+	str = strtok_r(orig_flags, "|", &pos);
+	while (str) {
+		size_t i;
+		char *new;
+		const char *cpt;
+
+		for (i = 0; i < ARRAY_SIZE(gfp_compact_table); i++) {
+			if (strcmp(gfp_compact_table[i].original, str))
+				continue;
+
+			cpt = gfp_compact_table[i].compact;
+			new = realloc(new_flags, len + strlen(cpt) + 2);
+			if (new == NULL) {
+				free(new_flags);
+				return NULL;
+			}
+
+			new_flags = new;
+
+			if (!len) {
+				strcpy(new_flags, cpt);
+			} else {
+				strcat(new_flags, "|");
+				strcat(new_flags, cpt);
+				len++;
+			}
+
+			len += strlen(cpt);
+		}
+
+		str = strtok_r(NULL, "|", &pos);
+	}
+
+	if (max_gfp_len < len)
+		max_gfp_len = len;
+
+	free(orig_flags);
+	return new_flags;
+}
+
+static char *compact_gfp_string(unsigned long gfp_flags)
+{
+	struct gfp_flag key = {
+		.flags = gfp_flags,
+	};
+	struct gfp_flag *gfp;
+
+	gfp = bsearch(&key, gfps, nr_gfps, sizeof(*gfps), gfpcmp);
+	if (gfp)
+		return gfp->compact_str;
+
+	return NULL;
+}
+
+static int parse_gfp_flags(struct perf_evsel *evsel, struct perf_sample *sample,
+			   unsigned int gfp_flags)
+{
+	struct pevent_record record = {
+		.cpu = sample->cpu,
+		.data = sample->raw_data,
+		.size = sample->raw_size,
+	};
+	struct trace_seq seq;
+	char *str, *pos;
+
+	if (nr_gfps) {
+		struct gfp_flag key = {
+			.flags = gfp_flags,
+		};
+
+		if (bsearch(&key, gfps, nr_gfps, sizeof(*gfps), gfpcmp))
+			return 0;
+	}
+
+	trace_seq_init(&seq);
+	pevent_event_info(&seq, evsel->tp_format, &record);
+
+	str = strtok_r(seq.buffer, " ", &pos);
+	while (str) {
+		if (!strncmp(str, "gfp_flags=", 10)) {
+			struct gfp_flag *new;
+
+			new = realloc(gfps, (nr_gfps + 1) * sizeof(*gfps));
+			if (new == NULL)
+				return -ENOMEM;
+
+			gfps = new;
+			new += nr_gfps++;
+
+			new->flags = gfp_flags;
+			new->human_readable = strdup(str + 10);
+			new->compact_str = compact_gfp_flags(str + 10);
+			if (!new->human_readable || !new->compact_str)
+				return -ENOMEM;
+
+			qsort(gfps, nr_gfps, sizeof(*gfps), gfpcmp);
+		}
+
+		str = strtok_r(NULL, " ", &pos);
+	}
+
+	trace_seq_destroy(&seq);
+	return 0;
+}
+
 static int perf_evsel__process_page_alloc_event(struct perf_evsel *evsel,
 						struct perf_sample *sample)
 {
@@ -613,6 +783,9 @@ static int perf_evsel__process_page_alloc_event(struct perf_evsel *evsel,
 		return 0;
 	}
 
+	if (parse_gfp_flags(evsel, sample, gfp_flags) < 0)
+		return -1;
+
 	callsite = find_callsite(evsel, sample);
 
 	/*
@@ -832,16 +1005,18 @@ static void __print_page_alloc_result(struct perf_session *session, int n_lines)
 	struct rb_node *next = rb_first(&page_alloc_sorted);
 	struct machine *machine = &session->machines.host;
 	const char *format;
+	int gfp_len = max(strlen("GFP flags"), max_gfp_len);
 
 	printf("\n%.105s\n", graph_dotted_line);
-	printf(" %-16s | %5s alloc (KB) | Hits      | Order | Mig.type | GFP flags | Callsite\n",
-	       use_pfn ? "PFN" : "Page", live_page ? "Live" : "Total");
+	printf(" %-16s | %5s alloc (KB) | Hits      | Order | Mig.type | %-*s | Callsite\n",
+	       use_pfn ? "PFN" : "Page", live_page ? "Live" : "Total",
+	       gfp_len, "GFP flags");
 	printf("%.105s\n", graph_dotted_line);
 
 	if (use_pfn)
-		format = " %16llu | %'16llu | %'9d | %5d | %8s |  %08lx | %s\n";
+		format = " %16llu | %'16llu | %'9d | %5d | %8s | %-*s | %s\n";
 	else
-		format = " %016llx | %'16llu | %'9d | %5d | %8s |  %08lx | %s\n";
+		format = " %016llx | %'16llu | %'9d | %5d | %8s | %-*s | %s\n";
 
 	while (next && n_lines--) {
 		struct page_stat *data;
@@ -862,13 +1037,15 @@ static void __print_page_alloc_result(struct perf_session *session, int n_lines)
 		       (unsigned long long)data->alloc_bytes / 1024,
 		       data->nr_alloc, data->order,
 		       migrate_type_str[data->migrate_type],
-		       (unsigned long)data->gfp_flags, caller);
+		       gfp_len, compact_gfp_string(data->gfp_flags), caller);
 
 		next = rb_next(next);
 	}
 
-	if (n_lines == -1)
-		printf(" ...              | ...              | ...       | ...   | ...      | ...       | ...\n");
+	if (n_lines == -1) {
+		printf(" ...              | ...              | ...       | ...   | ...      | %-*s | ...\n",
+		       gfp_len, "...");
+	}
 
 	printf("%.105s\n", graph_dotted_line);
 }
@@ -877,10 +1054,11 @@ static void __print_page_caller_result(struct perf_session *session, int n_lines
 {
 	struct rb_node *next = rb_first(&page_caller_sorted);
 	struct machine *machine = &session->machines.host;
+	int gfp_len = max(strlen("GFP flags"), max_gfp_len);
 
 	printf("\n%.105s\n", graph_dotted_line);
-	printf(" %5s alloc (KB) | Hits      | Order | Mig.type | GFP flags | Callsite\n",
-	       live_page ? "Live" : "Total");
+	printf(" %5s alloc (KB) | Hits      | Order | Mig.type | %-*s | Callsite\n",
+	       live_page ? "Live" : "Total", gfp_len, "GFP flags");
 	printf("%.105s\n", graph_dotted_line);
 
 	while (next && n_lines--) {
@@ -898,21 +1076,37 @@ static void __print_page_caller_result(struct perf_session *session, int n_lines
 		else
 			scnprintf(buf, sizeof(buf), "%"PRIx64, data->callsite);
 
-		printf(" %'16llu | %'9d | %5d | %8s |  %08lx | %s\n",
+		printf(" %'16llu | %'9d | %5d | %8s | %-*s | %s\n",
 		       (unsigned long long)data->alloc_bytes / 1024,
 		       data->nr_alloc, data->order,
 		       migrate_type_str[data->migrate_type],
-		       (unsigned long)data->gfp_flags, caller);
+		       gfp_len, compact_gfp_string(data->gfp_flags), caller);
 
 		next = rb_next(next);
 	}
 
-	if (n_lines == -1)
-		printf(" ...              | ...       | ...   | ...      | ...       | ...\n");
+	if (n_lines == -1) {
+		printf(" ...              | ...       | ...   | ...      | %-*s | ...\n",
+		       gfp_len, "...");
+	}
 
 	printf("%.105s\n", graph_dotted_line);
 }
 
+static void print_gfp_flags(void)
+{
+	int i;
+
+	printf("#\n");
+	printf("# GFP flags\n");
+	printf("# ---------\n");
+	for (i = 0; i < nr_gfps; i++) {
+		printf("# %08x: %*s: %s\n", gfps[i].flags,
+		       (int) max_gfp_len, gfps[i].compact_str,
+		       gfps[i].human_readable);
+	}
+}
+
 static void print_slab_summary(void)
 {
 	printf("\nSUMMARY (SLAB allocator)");
@@ -982,6 +1176,8 @@ static void print_slab_result(struct perf_session *session)
 
 static void print_page_result(struct perf_session *session)
 {
+	if (caller_flag || alloc_flag)
+		print_gfp_flags();
 	if (caller_flag)
 		__print_page_caller_result(session, caller_lines);
 	if (alloc_flag)

commit 2a7ef02c9ca0172cd48945407893f38c2438e754
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Tue Apr 21 13:55:04 2015 +0900

    perf kmem: Add --live option for current allocation stat
    
    Currently 'perf kmem stat --page' shows total (page) allocation stat by
    default, but sometimes one might want to see live (total alloc-only)
    requests/pages only.  The new --live option does this by subtracting freed
    allocation from the stat.
    
    E.g.:
    
     # perf kmem stat --page
    
     SUMMARY (page allocator)
     ========================
     Total allocation requests     :          988,858   [        4,045,368 KB ]
     Total free requests           :          886,484   [        3,624,996 KB ]
    
     Total alloc+freed requests    :          885,969   [        3,622,628 KB ]
     Total alloc-only requests     :          102,889   [          422,740 KB ]
     Total free-only requests      :              515   [            2,368 KB ]
    
     Total allocation failures     :                0   [                0 KB ]
    
     Order     Unmovable   Reclaimable       Movable      Reserved  CMA/Isolated
     -----  ------------  ------------  ------------  ------------  ------------
         0       172,173         3,083       806,686             .             .
         1           284             .             .             .             .
         2         6,124            58             .             .             .
         3           114           335             .             .             .
         4             .             .             .             .             .
         5             .             .             .             .             .
         6             .             .             .             .             .
         7             .             .             .             .             .
         8             .             .             .             .             .
         9             .             .             1             .             .
        10             .             .             .             .             .
     # perf kmem stat --page --live
    
     SUMMARY (page allocator)
     ========================
     Total allocation requests     :          988,858   [        4,045,368 KB ]
     Total free requests           :          886,484   [        3,624,996 KB ]
    
     Total alloc+freed requests    :          885,969   [        3,622,628 KB ]
     Total alloc-only requests     :          102,889   [          422,740 KB ]
     Total free-only requests      :              515   [            2,368 KB ]
    
     Total allocation failures     :                0   [                0 KB ]
    
     Order     Unmovable   Reclaimable       Movable      Reserved  CMA/Isolated
     -----  ------------  ------------  ------------  ------------  ------------
         0         2,214         3,025        97,156             .             .
         1            59             .             .             .             .
         2            19            58             .             .             .
         3            23           335             .             .             .
         4             .             .             .             .             .
         5             .             .             .             .             .
         6             .             .             .             .             .
         7             .             .             .             .             .
         8             .             .             .             .             .
         9             .             .             .             .             .
        10             .             .             .             .             .
     #
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Acked-by: Pekka Enberg <penberg@kernel.org>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/1429592107-1807-4-git-send-email-namhyung@kernel.org
    [ Added examples to the changeset log ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 0393a7f3fa35..7ead9423fd7a 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -244,6 +244,7 @@ static unsigned long nr_page_fails;
 static unsigned long nr_page_nomatch;
 
 static bool use_pfn;
+static bool live_page;
 static struct perf_session *kmem_session;
 
 #define MAX_MIGRATE_TYPES  6
@@ -264,7 +265,7 @@ struct page_stat {
 	int 		nr_free;
 };
 
-static struct rb_root page_tree;
+static struct rb_root page_live_tree;
 static struct rb_root page_alloc_tree;
 static struct rb_root page_alloc_sorted;
 static struct rb_root page_caller_tree;
@@ -403,10 +404,19 @@ static u64 find_callsite(struct perf_evsel *evsel, struct perf_sample *sample)
 	return sample->ip;
 }
 
+struct sort_dimension {
+	const char		name[20];
+	sort_fn_t		cmp;
+	struct list_head	list;
+};
+
+static LIST_HEAD(page_alloc_sort_input);
+static LIST_HEAD(page_caller_sort_input);
+
 static struct page_stat *
-__page_stat__findnew_page(u64 page, bool create)
+__page_stat__findnew_page(struct page_stat *pstat, bool create)
 {
-	struct rb_node **node = &page_tree.rb_node;
+	struct rb_node **node = &page_live_tree.rb_node;
 	struct rb_node *parent = NULL;
 	struct page_stat *data;
 
@@ -416,7 +426,7 @@ __page_stat__findnew_page(u64 page, bool create)
 		parent = *node;
 		data = rb_entry(*node, struct page_stat, node);
 
-		cmp = data->page - page;
+		cmp = data->page - pstat->page;
 		if (cmp < 0)
 			node = &parent->rb_left;
 		else if (cmp > 0)
@@ -430,34 +440,28 @@ __page_stat__findnew_page(u64 page, bool create)
 
 	data = zalloc(sizeof(*data));
 	if (data != NULL) {
-		data->page = page;
+		data->page = pstat->page;
+		data->order = pstat->order;
+		data->gfp_flags = pstat->gfp_flags;
+		data->migrate_type = pstat->migrate_type;
 
 		rb_link_node(&data->node, parent, node);
-		rb_insert_color(&data->node, &page_tree);
+		rb_insert_color(&data->node, &page_live_tree);
 	}
 
 	return data;
 }
 
-static struct page_stat *page_stat__find_page(u64 page)
+static struct page_stat *page_stat__find_page(struct page_stat *pstat)
 {
-	return __page_stat__findnew_page(page, false);
+	return __page_stat__findnew_page(pstat, false);
 }
 
-static struct page_stat *page_stat__findnew_page(u64 page)
+static struct page_stat *page_stat__findnew_page(struct page_stat *pstat)
 {
-	return __page_stat__findnew_page(page, true);
+	return __page_stat__findnew_page(pstat, true);
 }
 
-struct sort_dimension {
-	const char		name[20];
-	sort_fn_t		cmp;
-	struct list_head	list;
-};
-
-static LIST_HEAD(page_alloc_sort_input);
-static LIST_HEAD(page_caller_sort_input);
-
 static struct page_stat *
 __page_stat__findnew_alloc(struct page_stat *pstat, bool create)
 {
@@ -615,17 +619,8 @@ static int perf_evsel__process_page_alloc_event(struct perf_evsel *evsel,
 	 * This is to find the current page (with correct gfp flags and
 	 * migrate type) at free event.
 	 */
-	pstat = page_stat__findnew_page(page);
-	if (pstat == NULL)
-		return -ENOMEM;
-
-	pstat->order = order;
-	pstat->gfp_flags = gfp_flags;
-	pstat->migrate_type = migrate_type;
-	pstat->callsite = callsite;
-
 	this.page = page;
-	pstat = page_stat__findnew_alloc(&this);
+	pstat = page_stat__findnew_page(&this);
 	if (pstat == NULL)
 		return -ENOMEM;
 
@@ -633,6 +628,16 @@ static int perf_evsel__process_page_alloc_event(struct perf_evsel *evsel,
 	pstat->alloc_bytes += bytes;
 	pstat->callsite = callsite;
 
+	if (!live_page) {
+		pstat = page_stat__findnew_alloc(&this);
+		if (pstat == NULL)
+			return -ENOMEM;
+
+		pstat->nr_alloc++;
+		pstat->alloc_bytes += bytes;
+		pstat->callsite = callsite;
+	}
+
 	this.callsite = callsite;
 	pstat = page_stat__findnew_caller(&this);
 	if (pstat == NULL)
@@ -665,7 +670,8 @@ static int perf_evsel__process_page_free_event(struct perf_evsel *evsel,
 	nr_page_frees++;
 	total_page_free_bytes += bytes;
 
-	pstat = page_stat__find_page(page);
+	this.page = page;
+	pstat = page_stat__find_page(&this);
 	if (pstat == NULL) {
 		pr_debug2("missing free at page %"PRIx64" (order: %d)\n",
 			  page, order);
@@ -676,20 +682,23 @@ static int perf_evsel__process_page_free_event(struct perf_evsel *evsel,
 		return 0;
 	}
 
-	this.page = page;
 	this.gfp_flags = pstat->gfp_flags;
 	this.migrate_type = pstat->migrate_type;
 	this.callsite = pstat->callsite;
 
-	rb_erase(&pstat->node, &page_tree);
+	rb_erase(&pstat->node, &page_live_tree);
 	free(pstat);
 
-	pstat = page_stat__find_alloc(&this);
-	if (pstat == NULL)
-		return -ENOENT;
+	if (live_page) {
+		order_stats[this.order][this.migrate_type]--;
+	} else {
+		pstat = page_stat__find_alloc(&this);
+		if (pstat == NULL)
+			return -ENOMEM;
 
-	pstat->nr_free++;
-	pstat->free_bytes += bytes;
+		pstat->nr_free++;
+		pstat->free_bytes += bytes;
+	}
 
 	pstat = page_stat__find_caller(&this);
 	if (pstat == NULL)
@@ -698,6 +707,16 @@ static int perf_evsel__process_page_free_event(struct perf_evsel *evsel,
 	pstat->nr_free++;
 	pstat->free_bytes += bytes;
 
+	if (live_page) {
+		pstat->nr_alloc--;
+		pstat->alloc_bytes -= bytes;
+
+		if (pstat->nr_alloc == 0) {
+			rb_erase(&pstat->node, &page_caller_tree);
+			free(pstat);
+		}
+	}
+
 	return 0;
 }
 
@@ -815,8 +834,8 @@ static void __print_page_alloc_result(struct perf_session *session, int n_lines)
 	const char *format;
 
 	printf("\n%.105s\n", graph_dotted_line);
-	printf(" %-16s | Total alloc (KB) | Hits      | Order | Mig.type | GFP flags | Callsite\n",
-	       use_pfn ? "PFN" : "Page");
+	printf(" %-16s | %5s alloc (KB) | Hits      | Order | Mig.type | GFP flags | Callsite\n",
+	       use_pfn ? "PFN" : "Page", live_page ? "Live" : "Total");
 	printf("%.105s\n", graph_dotted_line);
 
 	if (use_pfn)
@@ -860,7 +879,8 @@ static void __print_page_caller_result(struct perf_session *session, int n_lines
 	struct machine *machine = &session->machines.host;
 
 	printf("\n%.105s\n", graph_dotted_line);
-	printf(" Total alloc (KB) | Hits      | Order | Mig.type | GFP flags | Callsite\n");
+	printf(" %5s alloc (KB) | Hits      | Order | Mig.type | GFP flags | Callsite\n",
+	       live_page ? "Live" : "Total");
 	printf("%.105s\n", graph_dotted_line);
 
 	while (next && n_lines--) {
@@ -1085,8 +1105,13 @@ static void sort_result(void)
 				   &slab_caller_sort);
 	}
 	if (kmem_page) {
-		__sort_page_result(&page_alloc_tree, &page_alloc_sorted,
-				   &page_alloc_sort);
+		if (live_page)
+			__sort_page_result(&page_live_tree, &page_alloc_sorted,
+					   &page_alloc_sort);
+		else
+			__sort_page_result(&page_alloc_tree, &page_alloc_sorted,
+					   &page_alloc_sort);
+
 		__sort_page_result(&page_caller_tree, &page_caller_sorted,
 				   &page_caller_sort);
 	}
@@ -1630,6 +1655,7 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 			   parse_slab_opt),
 	OPT_CALLBACK_NOOPT(0, "page", NULL, NULL, "Analyze page allocator",
 			   parse_page_opt),
+	OPT_BOOLEAN(0, "live", &live_page, "Show live page stat"),
 	OPT_END()
 	};
 	const char *const kmem_subcommands[] = { "record", "stat", NULL };

commit fb4f313d304b0a5120e870a6cd9ecf90c1023037
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Tue Apr 21 13:55:03 2015 +0900

    perf kmem: Support sort keys on page analysis
    
    Add new sort keys for page: page, order, migtype, gfp - existing
    'bytes', 'hit' and 'callsite' sort keys also work for page.  Note that
    -s/--sort option should be preceded by either of --slab or --page option
    to determine where the sort keys applies.
    
    Now it properly groups and sorts allocation stats - so same
    page/caller with different order/migtype/gfp will be printed on a
    different line.
    
     # perf kmem stat --page --caller -l 10 -s order,hit
    
     -----------------------------------------------------------------------------
     Total alloc (KB) | Hits   | Order | Mig.type | GFP flags | Callsite
     -----------------------------------------------------------------------------
                   64 |      4 |     2 |  RECLAIM |  00285250 | new_slab
               50,144 | 12,536 |     0 |  MOVABLE |  0102005a | __page_cache_alloc
                   52 |     13 |     0 | UNMOVABL |  002084d0 | pte_alloc_one
                   40 |     10 |     0 |  MOVABLE |  000280da | handle_mm_fault
                   28 |      7 |     0 | UNMOVABL |  000000d0 | __pollwait
                   20 |      5 |     0 |  MOVABLE |  000200da | do_wp_page
                   20 |      5 |     0 |  MOVABLE |  000200da | do_cow_fault
                   16 |      4 |     0 | UNMOVABL |  00000200 | __tlb_remove_page
                   16 |      4 |     0 | UNMOVABL |  000084d0 | __pmd_alloc
                    8 |      2 |     0 | UNMOVABL |  000084d0 | __pud_alloc
     ...              | ...    | ...   | ...      | ...       | ...
     -----------------------------------------------------------------------------
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Acked-by: Pekka Enberg <penberg@kernel.org>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/1429592107-1807-3-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 3649eec6807f..0393a7f3fa35 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -30,7 +30,7 @@ static int	kmem_page;
 static long	kmem_page_size;
 
 struct alloc_stat;
-typedef int (*sort_fn_t)(struct alloc_stat *, struct alloc_stat *);
+typedef int (*sort_fn_t)(void *, void *);
 
 static int			alloc_flag;
 static int			caller_flag;
@@ -181,8 +181,8 @@ static int perf_evsel__process_alloc_node_event(struct perf_evsel *evsel,
 	return ret;
 }
 
-static int ptr_cmp(struct alloc_stat *, struct alloc_stat *);
-static int callsite_cmp(struct alloc_stat *, struct alloc_stat *);
+static int ptr_cmp(void *, void *);
+static int slab_callsite_cmp(void *, void *);
 
 static struct alloc_stat *search_alloc_stat(unsigned long ptr,
 					    unsigned long call_site,
@@ -223,7 +223,8 @@ static int perf_evsel__process_free_event(struct perf_evsel *evsel,
 		s_alloc->pingpong++;
 
 		s_caller = search_alloc_stat(0, s_alloc->call_site,
-					     &root_caller_stat, callsite_cmp);
+					     &root_caller_stat,
+					     slab_callsite_cmp);
 		if (!s_caller)
 			return -1;
 		s_caller->pingpong++;
@@ -448,26 +449,14 @@ static struct page_stat *page_stat__findnew_page(u64 page)
 	return __page_stat__findnew_page(page, true);
 }
 
-static int page_stat_cmp(struct page_stat *a, struct page_stat *b)
-{
-	if (a->page > b->page)
-		return -1;
-	if (a->page < b->page)
-		return 1;
-	if (a->order > b->order)
-		return -1;
-	if (a->order < b->order)
-		return 1;
-	if (a->migrate_type > b->migrate_type)
-		return -1;
-	if (a->migrate_type < b->migrate_type)
-		return 1;
-	if (a->gfp_flags > b->gfp_flags)
-		return -1;
-	if (a->gfp_flags < b->gfp_flags)
-		return 1;
-	return 0;
-}
+struct sort_dimension {
+	const char		name[20];
+	sort_fn_t		cmp;
+	struct list_head	list;
+};
+
+static LIST_HEAD(page_alloc_sort_input);
+static LIST_HEAD(page_caller_sort_input);
 
 static struct page_stat *
 __page_stat__findnew_alloc(struct page_stat *pstat, bool create)
@@ -475,14 +464,20 @@ __page_stat__findnew_alloc(struct page_stat *pstat, bool create)
 	struct rb_node **node = &page_alloc_tree.rb_node;
 	struct rb_node *parent = NULL;
 	struct page_stat *data;
+	struct sort_dimension *sort;
 
 	while (*node) {
-		s64 cmp;
+		int cmp = 0;
 
 		parent = *node;
 		data = rb_entry(*node, struct page_stat, node);
 
-		cmp = page_stat_cmp(data, pstat);
+		list_for_each_entry(sort, &page_alloc_sort_input, list) {
+			cmp = sort->cmp(pstat, data);
+			if (cmp)
+				break;
+		}
+
 		if (cmp < 0)
 			node = &parent->rb_left;
 		else if (cmp > 0)
@@ -519,19 +514,25 @@ static struct page_stat *page_stat__findnew_alloc(struct page_stat *pstat)
 }
 
 static struct page_stat *
-__page_stat__findnew_caller(u64 callsite, bool create)
+__page_stat__findnew_caller(struct page_stat *pstat, bool create)
 {
 	struct rb_node **node = &page_caller_tree.rb_node;
 	struct rb_node *parent = NULL;
 	struct page_stat *data;
+	struct sort_dimension *sort;
 
 	while (*node) {
-		s64 cmp;
+		int cmp = 0;
 
 		parent = *node;
 		data = rb_entry(*node, struct page_stat, node);
 
-		cmp = data->callsite - callsite;
+		list_for_each_entry(sort, &page_caller_sort_input, list) {
+			cmp = sort->cmp(pstat, data);
+			if (cmp)
+				break;
+		}
+
 		if (cmp < 0)
 			node = &parent->rb_left;
 		else if (cmp > 0)
@@ -545,7 +546,10 @@ __page_stat__findnew_caller(u64 callsite, bool create)
 
 	data = zalloc(sizeof(*data));
 	if (data != NULL) {
-		data->callsite = callsite;
+		data->callsite = pstat->callsite;
+		data->order = pstat->order;
+		data->gfp_flags = pstat->gfp_flags;
+		data->migrate_type = pstat->migrate_type;
 
 		rb_link_node(&data->node, parent, node);
 		rb_insert_color(&data->node, &page_caller_tree);
@@ -554,14 +558,14 @@ __page_stat__findnew_caller(u64 callsite, bool create)
 	return data;
 }
 
-static struct page_stat *page_stat__find_caller(u64 callsite)
+static struct page_stat *page_stat__find_caller(struct page_stat *pstat)
 {
-	return __page_stat__findnew_caller(callsite, false);
+	return __page_stat__findnew_caller(pstat, false);
 }
 
-static struct page_stat *page_stat__findnew_caller(u64 callsite)
+static struct page_stat *page_stat__findnew_caller(struct page_stat *pstat)
 {
-	return __page_stat__findnew_caller(callsite, true);
+	return __page_stat__findnew_caller(pstat, true);
 }
 
 static bool valid_page(u64 pfn_or_page)
@@ -629,14 +633,11 @@ static int perf_evsel__process_page_alloc_event(struct perf_evsel *evsel,
 	pstat->alloc_bytes += bytes;
 	pstat->callsite = callsite;
 
-	pstat = page_stat__findnew_caller(callsite);
+	this.callsite = callsite;
+	pstat = page_stat__findnew_caller(&this);
 	if (pstat == NULL)
 		return -ENOMEM;
 
-	pstat->order = order;
-	pstat->gfp_flags = gfp_flags;
-	pstat->migrate_type = migrate_type;
-
 	pstat->nr_alloc++;
 	pstat->alloc_bytes += bytes;
 
@@ -690,7 +691,7 @@ static int perf_evsel__process_page_free_event(struct perf_evsel *evsel,
 	pstat->nr_free++;
 	pstat->free_bytes += bytes;
 
-	pstat = page_stat__find_caller(this.callsite);
+	pstat = page_stat__find_caller(&this);
 	if (pstat == NULL)
 		return -ENOENT;
 
@@ -976,14 +977,10 @@ static void print_result(struct perf_session *session)
 		print_page_result(session);
 }
 
-struct sort_dimension {
-	const char		name[20];
-	sort_fn_t		cmp;
-	struct list_head	list;
-};
-
-static LIST_HEAD(caller_sort);
-static LIST_HEAD(alloc_sort);
+static LIST_HEAD(slab_caller_sort);
+static LIST_HEAD(slab_alloc_sort);
+static LIST_HEAD(page_caller_sort);
+static LIST_HEAD(page_alloc_sort);
 
 static void sort_slab_insert(struct rb_root *root, struct alloc_stat *data,
 			     struct list_head *sort_list)
@@ -1032,10 +1029,12 @@ static void __sort_slab_result(struct rb_root *root, struct rb_root *root_sorted
 	}
 }
 
-static void sort_page_insert(struct rb_root *root, struct page_stat *data)
+static void sort_page_insert(struct rb_root *root, struct page_stat *data,
+			     struct list_head *sort_list)
 {
 	struct rb_node **new = &root->rb_node;
 	struct rb_node *parent = NULL;
+	struct sort_dimension *sort;
 
 	while (*new) {
 		struct page_stat *this;
@@ -1044,8 +1043,11 @@ static void sort_page_insert(struct rb_root *root, struct page_stat *data)
 		this = rb_entry(*new, struct page_stat, node);
 		parent = *new;
 
-		/* TODO: support more sort key */
-		cmp = data->alloc_bytes - this->alloc_bytes;
+		list_for_each_entry(sort, sort_list, list) {
+			cmp = sort->cmp(data, this);
+			if (cmp)
+				break;
+		}
 
 		if (cmp > 0)
 			new = &parent->rb_left;
@@ -1057,7 +1059,8 @@ static void sort_page_insert(struct rb_root *root, struct page_stat *data)
 	rb_insert_color(&data->node, root);
 }
 
-static void __sort_page_result(struct rb_root *root, struct rb_root *root_sorted)
+static void __sort_page_result(struct rb_root *root, struct rb_root *root_sorted,
+			       struct list_head *sort_list)
 {
 	struct rb_node *node;
 	struct page_stat *data;
@@ -1069,7 +1072,7 @@ static void __sort_page_result(struct rb_root *root, struct rb_root *root_sorted
 
 		rb_erase(node, root);
 		data = rb_entry(node, struct page_stat, node);
-		sort_page_insert(root_sorted, data);
+		sort_page_insert(root_sorted, data, sort_list);
 	}
 }
 
@@ -1077,13 +1080,15 @@ static void sort_result(void)
 {
 	if (kmem_slab) {
 		__sort_slab_result(&root_alloc_stat, &root_alloc_sorted,
-				   &alloc_sort);
+				   &slab_alloc_sort);
 		__sort_slab_result(&root_caller_stat, &root_caller_sorted,
-				   &caller_sort);
+				   &slab_caller_sort);
 	}
 	if (kmem_page) {
-		__sort_page_result(&page_alloc_tree, &page_alloc_sorted);
-		__sort_page_result(&page_caller_tree, &page_caller_sorted);
+		__sort_page_result(&page_alloc_tree, &page_alloc_sorted,
+				   &page_alloc_sort);
+		__sort_page_result(&page_caller_tree, &page_caller_sorted,
+				   &page_caller_sort);
 	}
 }
 
@@ -1132,8 +1137,12 @@ static int __cmd_kmem(struct perf_session *session)
 	return err;
 }
 
-static int ptr_cmp(struct alloc_stat *l, struct alloc_stat *r)
+/* slab sort keys */
+static int ptr_cmp(void *a, void *b)
 {
+	struct alloc_stat *l = a;
+	struct alloc_stat *r = b;
+
 	if (l->ptr < r->ptr)
 		return -1;
 	else if (l->ptr > r->ptr)
@@ -1146,8 +1155,11 @@ static struct sort_dimension ptr_sort_dimension = {
 	.cmp	= ptr_cmp,
 };
 
-static int callsite_cmp(struct alloc_stat *l, struct alloc_stat *r)
+static int slab_callsite_cmp(void *a, void *b)
 {
+	struct alloc_stat *l = a;
+	struct alloc_stat *r = b;
+
 	if (l->call_site < r->call_site)
 		return -1;
 	else if (l->call_site > r->call_site)
@@ -1157,11 +1169,14 @@ static int callsite_cmp(struct alloc_stat *l, struct alloc_stat *r)
 
 static struct sort_dimension callsite_sort_dimension = {
 	.name	= "callsite",
-	.cmp	= callsite_cmp,
+	.cmp	= slab_callsite_cmp,
 };
 
-static int hit_cmp(struct alloc_stat *l, struct alloc_stat *r)
+static int hit_cmp(void *a, void *b)
 {
+	struct alloc_stat *l = a;
+	struct alloc_stat *r = b;
+
 	if (l->hit < r->hit)
 		return -1;
 	else if (l->hit > r->hit)
@@ -1174,8 +1189,11 @@ static struct sort_dimension hit_sort_dimension = {
 	.cmp	= hit_cmp,
 };
 
-static int bytes_cmp(struct alloc_stat *l, struct alloc_stat *r)
+static int bytes_cmp(void *a, void *b)
 {
+	struct alloc_stat *l = a;
+	struct alloc_stat *r = b;
+
 	if (l->bytes_alloc < r->bytes_alloc)
 		return -1;
 	else if (l->bytes_alloc > r->bytes_alloc)
@@ -1188,9 +1206,11 @@ static struct sort_dimension bytes_sort_dimension = {
 	.cmp	= bytes_cmp,
 };
 
-static int frag_cmp(struct alloc_stat *l, struct alloc_stat *r)
+static int frag_cmp(void *a, void *b)
 {
 	double x, y;
+	struct alloc_stat *l = a;
+	struct alloc_stat *r = b;
 
 	x = fragmentation(l->bytes_req, l->bytes_alloc);
 	y = fragmentation(r->bytes_req, r->bytes_alloc);
@@ -1207,8 +1227,11 @@ static struct sort_dimension frag_sort_dimension = {
 	.cmp	= frag_cmp,
 };
 
-static int pingpong_cmp(struct alloc_stat *l, struct alloc_stat *r)
+static int pingpong_cmp(void *a, void *b)
 {
+	struct alloc_stat *l = a;
+	struct alloc_stat *r = b;
+
 	if (l->pingpong < r->pingpong)
 		return -1;
 	else if (l->pingpong > r->pingpong)
@@ -1221,7 +1244,135 @@ static struct sort_dimension pingpong_sort_dimension = {
 	.cmp	= pingpong_cmp,
 };
 
-static struct sort_dimension *avail_sorts[] = {
+/* page sort keys */
+static int page_cmp(void *a, void *b)
+{
+	struct page_stat *l = a;
+	struct page_stat *r = b;
+
+	if (l->page < r->page)
+		return -1;
+	else if (l->page > r->page)
+		return 1;
+	return 0;
+}
+
+static struct sort_dimension page_sort_dimension = {
+	.name	= "page",
+	.cmp	= page_cmp,
+};
+
+static int page_callsite_cmp(void *a, void *b)
+{
+	struct page_stat *l = a;
+	struct page_stat *r = b;
+
+	if (l->callsite < r->callsite)
+		return -1;
+	else if (l->callsite > r->callsite)
+		return 1;
+	return 0;
+}
+
+static struct sort_dimension page_callsite_sort_dimension = {
+	.name	= "callsite",
+	.cmp	= page_callsite_cmp,
+};
+
+static int page_hit_cmp(void *a, void *b)
+{
+	struct page_stat *l = a;
+	struct page_stat *r = b;
+
+	if (l->nr_alloc < r->nr_alloc)
+		return -1;
+	else if (l->nr_alloc > r->nr_alloc)
+		return 1;
+	return 0;
+}
+
+static struct sort_dimension page_hit_sort_dimension = {
+	.name	= "hit",
+	.cmp	= page_hit_cmp,
+};
+
+static int page_bytes_cmp(void *a, void *b)
+{
+	struct page_stat *l = a;
+	struct page_stat *r = b;
+
+	if (l->alloc_bytes < r->alloc_bytes)
+		return -1;
+	else if (l->alloc_bytes > r->alloc_bytes)
+		return 1;
+	return 0;
+}
+
+static struct sort_dimension page_bytes_sort_dimension = {
+	.name	= "bytes",
+	.cmp	= page_bytes_cmp,
+};
+
+static int page_order_cmp(void *a, void *b)
+{
+	struct page_stat *l = a;
+	struct page_stat *r = b;
+
+	if (l->order < r->order)
+		return -1;
+	else if (l->order > r->order)
+		return 1;
+	return 0;
+}
+
+static struct sort_dimension page_order_sort_dimension = {
+	.name	= "order",
+	.cmp	= page_order_cmp,
+};
+
+static int migrate_type_cmp(void *a, void *b)
+{
+	struct page_stat *l = a;
+	struct page_stat *r = b;
+
+	/* for internal use to find free'd page */
+	if (l->migrate_type == -1U)
+		return 0;
+
+	if (l->migrate_type < r->migrate_type)
+		return -1;
+	else if (l->migrate_type > r->migrate_type)
+		return 1;
+	return 0;
+}
+
+static struct sort_dimension migrate_type_sort_dimension = {
+	.name	= "migtype",
+	.cmp	= migrate_type_cmp,
+};
+
+static int gfp_flags_cmp(void *a, void *b)
+{
+	struct page_stat *l = a;
+	struct page_stat *r = b;
+
+	/* for internal use to find free'd page */
+	if (l->gfp_flags == -1U)
+		return 0;
+
+	if (l->gfp_flags < r->gfp_flags)
+		return -1;
+	else if (l->gfp_flags > r->gfp_flags)
+		return 1;
+	return 0;
+}
+
+static struct sort_dimension gfp_flags_sort_dimension = {
+	.name	= "gfp",
+	.cmp	= gfp_flags_cmp,
+};
+
+static struct sort_dimension *slab_sorts[] = {
 	&ptr_sort_dimension,
 	&callsite_sort_dimension,
 	&hit_sort_dimension,
@@ -1230,16 +1381,24 @@ static struct sort_dimension *avail_sorts[] = {
 	&pingpong_sort_dimension,
 };
 
-#define NUM_AVAIL_SORTS	((int)ARRAY_SIZE(avail_sorts))
+static struct sort_dimension *page_sorts[] = {
+	&page_sort_dimension,
+	&page_callsite_sort_dimension,
+	&page_hit_sort_dimension,
+	&page_bytes_sort_dimension,
+	&page_order_sort_dimension,
+	&migrate_type_sort_dimension,
+	&gfp_flags_sort_dimension,
+};
 
-static int sort_dimension__add(const char *tok, struct list_head *list)
+static int slab_sort_dimension__add(const char *tok, struct list_head *list)
 {
 	struct sort_dimension *sort;
 	int i;
 
-	for (i = 0; i < NUM_AVAIL_SORTS; i++) {
-		if (!strcmp(avail_sorts[i]->name, tok)) {
-			sort = memdup(avail_sorts[i], sizeof(*avail_sorts[i]));
+	for (i = 0; i < (int)ARRAY_SIZE(slab_sorts); i++) {
+		if (!strcmp(slab_sorts[i]->name, tok)) {
+			sort = memdup(slab_sorts[i], sizeof(*slab_sorts[i]));
 			if (!sort) {
 				pr_err("%s: memdup failed\n", __func__);
 				return -1;
@@ -1252,7 +1411,27 @@ static int sort_dimension__add(const char *tok, struct list_head *list)
 	return -1;
 }
 
-static int setup_sorting(struct list_head *sort_list, const char *arg)
+static int page_sort_dimension__add(const char *tok, struct list_head *list)
+{
+	struct sort_dimension *sort;
+	int i;
+
+	for (i = 0; i < (int)ARRAY_SIZE(page_sorts); i++) {
+		if (!strcmp(page_sorts[i]->name, tok)) {
+			sort = memdup(page_sorts[i], sizeof(*page_sorts[i]));
+			if (!sort) {
+				pr_err("%s: memdup failed\n", __func__);
+				return -1;
+			}
+			list_add_tail(&sort->list, list);
+			return 0;
+		}
+	}
+
+	return -1;
+}
+
+static int setup_slab_sorting(struct list_head *sort_list, const char *arg)
 {
 	char *tok;
 	char *str = strdup(arg);
@@ -1267,8 +1446,34 @@ static int setup_sorting(struct list_head *sort_list, const char *arg)
 		tok = strsep(&pos, ",");
 		if (!tok)
 			break;
-		if (sort_dimension__add(tok, sort_list) < 0) {
-			error("Unknown --sort key: '%s'", tok);
+		if (slab_sort_dimension__add(tok, sort_list) < 0) {
+			error("Unknown slab --sort key: '%s'", tok);
+			free(str);
+			return -1;
+		}
+	}
+
+	free(str);
+	return 0;
+}
+
+static int setup_page_sorting(struct list_head *sort_list, const char *arg)
+{
+	char *tok;
+	char *str = strdup(arg);
+	char *pos = str;
+
+	if (!str) {
+		pr_err("%s: strdup failed\n", __func__);
+		return -1;
+	}
+
+	while (true) {
+		tok = strsep(&pos, ",");
+		if (!tok)
+			break;
+		if (page_sort_dimension__add(tok, sort_list) < 0) {
+			error("Unknown page --sort key: '%s'", tok);
 			free(str);
 			return -1;
 		}
@@ -1284,10 +1489,17 @@ static int parse_sort_opt(const struct option *opt __maybe_unused,
 	if (!arg)
 		return -1;
 
-	if (caller_flag > alloc_flag)
-		return setup_sorting(&caller_sort, arg);
-	else
-		return setup_sorting(&alloc_sort, arg);
+	if (kmem_page > kmem_slab) {
+		if (caller_flag > alloc_flag)
+			return setup_page_sorting(&page_caller_sort, arg);
+		else
+			return setup_page_sorting(&page_alloc_sort, arg);
+	} else {
+		if (caller_flag > alloc_flag)
+			return setup_slab_sorting(&slab_caller_sort, arg);
+		else
+			return setup_slab_sorting(&slab_alloc_sort, arg);
+	}
 
 	return 0;
 }
@@ -1395,7 +1607,8 @@ static int __cmd_record(int argc, const char **argv)
 
 int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 {
-	const char * const default_sort_order = "frag,hit,bytes";
+	const char * const default_slab_sort = "frag,hit,bytes";
+	const char * const default_page_sort = "bytes,hit";
 	struct perf_data_file file = {
 		.mode = PERF_DATA_MODE_READ,
 	};
@@ -1408,8 +1621,8 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 	OPT_CALLBACK_NOOPT(0, "alloc", NULL, NULL,
 			   "show per-allocation statistics", parse_alloc_opt),
 	OPT_CALLBACK('s', "sort", NULL, "key[,key2...]",
-		     "sort by keys: ptr, call_site, bytes, hit, pingpong, frag",
-		     parse_sort_opt),
+		     "sort by keys: ptr, callsite, bytes, hit, pingpong, frag, "
+		     "page, order, migtype, gfp", parse_sort_opt),
 	OPT_CALLBACK('l', "line", NULL, "num", "show n lines", parse_line_opt),
 	OPT_BOOLEAN(0, "raw-ip", &raw_ip, "show raw ip instead of symbol"),
 	OPT_BOOLEAN('f', "force", &file.force, "don't complain, do it"),
@@ -1467,11 +1680,21 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 		if (cpu__setup_cpunode_map())
 			goto out_delete;
 
-		if (list_empty(&caller_sort))
-			setup_sorting(&caller_sort, default_sort_order);
-		if (list_empty(&alloc_sort))
-			setup_sorting(&alloc_sort, default_sort_order);
-
+		if (list_empty(&slab_caller_sort))
+			setup_slab_sorting(&slab_caller_sort, default_slab_sort);
+		if (list_empty(&slab_alloc_sort))
+			setup_slab_sorting(&slab_alloc_sort, default_slab_sort);
+		if (list_empty(&page_caller_sort))
+			setup_page_sorting(&page_caller_sort, default_page_sort);
+		if (list_empty(&page_alloc_sort))
+			setup_page_sorting(&page_alloc_sort, default_page_sort);
+
+		if (kmem_page) {
+			setup_page_sorting(&page_alloc_sort_input,
+					   "page,order,migtype,gfp");
+			setup_page_sorting(&page_caller_sort_input,
+					   "callsite,order,migtype,gfp");
+		}
 		ret = __cmd_kmem(session);
 	} else
 		usage_with_options(kmem_usage, kmem_options);

commit c9758cc4569955c6d8ad519adf539848e8824c72
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Tue Apr 21 13:55:02 2015 +0900

    perf kmem: Implement stat --page --caller
    
    It is 'perf kmem' support caller statistics for page.  Unlike slab case,
    the tracepoints in page allocator don't provide callsite info.  So it
    records with callchain and extracts callsite info.
    
    Note that the callchain contains several memory allocation functions
    which has no meaning for users.  So skip those functions to get proper
    callsites.  I used following regex pattern to skip the allocator
    functions:
    
      ^_?_?(alloc|get_free|get_zeroed)_pages?
    
    This gave me a following list of functions:
    
      # perf kmem record --page sleep 3
      # perf kmem stat --page -v
      ...
      alloc func: __get_free_pages
      alloc func: get_zeroed_page
      alloc func: alloc_pages_exact
      alloc func: __alloc_pages_direct_compact
      alloc func: __alloc_pages_nodemask
      alloc func: alloc_page_interleave
      alloc func: alloc_pages_current
      alloc func: alloc_pages_vma
      alloc func: alloc_page_buffers
      alloc func: alloc_pages_exact_nid
      ...
    
    The output looks mostly same as --alloc (I also added callsite column
    to that) but groups entries by callsite.  Currently, the order,
    migrate type and GFP flag info is for the last allocation and not
    guaranteed to be same for all allocations from the callsite.
    
      ---------------------------------------------------------------------------------------------
       Total_alloc (KB) | Hits      | Order | Mig.type | GFP flags | Callsite
      ---------------------------------------------------------------------------------------------
                  1,064 |       266 |     0 | UNMOVABL |  000000d0 | __pollwait
                     52 |        13 |     0 | UNMOVABL |  002084d0 | pte_alloc_one
                     44 |        11 |     0 |  MOVABLE |  000280da | handle_mm_fault
                     20 |         5 |     0 |  MOVABLE |  000200da | do_cow_fault
                     20 |         5 |     0 |  MOVABLE |  000200da | do_wp_page
                     16 |         4 |     0 | UNMOVABL |  000084d0 | __pmd_alloc
                     16 |         4 |     0 | UNMOVABL |  00000200 | __tlb_remove_page
                     12 |         3 |     0 | UNMOVABL |  000084d0 | __pud_alloc
                      8 |         2 |     0 | UNMOVABL |  00000010 | bio_copy_user_iov
                      4 |         1 |     0 | UNMOVABL |  000200d2 | pipe_write
                      4 |         1 |     0 |  MOVABLE |  000280da | do_wp_page
                      4 |         1 |     0 | UNMOVABL |  002084d0 | pgd_alloc
      ---------------------------------------------------------------------------------------------
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Acked-by: Pekka Enberg <penberg@kernel.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/1429592107-1807-2-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 4f0f38462d97..3649eec6807f 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -10,6 +10,7 @@
 #include "util/header.h"
 #include "util/session.h"
 #include "util/tool.h"
+#include "util/callchain.h"
 
 #include "util/parse-options.h"
 #include "util/trace-event.h"
@@ -21,6 +22,7 @@
 #include <linux/rbtree.h>
 #include <linux/string.h>
 #include <locale.h>
+#include <regex.h>
 
 static int	kmem_slab;
 static int	kmem_page;
@@ -241,6 +243,7 @@ static unsigned long nr_page_fails;
 static unsigned long nr_page_nomatch;
 
 static bool use_pfn;
+static struct perf_session *kmem_session;
 
 #define MAX_MIGRATE_TYPES  6
 #define MAX_PAGE_ORDER     11
@@ -250,6 +253,7 @@ static int order_stats[MAX_PAGE_ORDER][MAX_MIGRATE_TYPES];
 struct page_stat {
 	struct rb_node 	node;
 	u64 		page;
+	u64 		callsite;
 	int 		order;
 	unsigned 	gfp_flags;
 	unsigned 	migrate_type;
@@ -262,8 +266,144 @@ struct page_stat {
 static struct rb_root page_tree;
 static struct rb_root page_alloc_tree;
 static struct rb_root page_alloc_sorted;
+static struct rb_root page_caller_tree;
+static struct rb_root page_caller_sorted;
 
-static struct page_stat *search_page(unsigned long page, bool create)
+struct alloc_func {
+	u64 start;
+	u64 end;
+	char *name;
+};
+
+static int nr_alloc_funcs;
+static struct alloc_func *alloc_func_list;
+
+static int funcmp(const void *a, const void *b)
+{
+	const struct alloc_func *fa = a;
+	const struct alloc_func *fb = b;
+
+	if (fa->start > fb->start)
+		return 1;
+	else
+		return -1;
+}
+
+static int callcmp(const void *a, const void *b)
+{
+	const struct alloc_func *fa = a;
+	const struct alloc_func *fb = b;
+
+	if (fb->start <= fa->start && fa->end < fb->end)
+		return 0;
+
+	if (fa->start > fb->start)
+		return 1;
+	else
+		return -1;
+}
+
+static int build_alloc_func_list(void)
+{
+	int ret;
+	struct map *kernel_map;
+	struct symbol *sym;
+	struct rb_node *node;
+	struct alloc_func *func;
+	struct machine *machine = &kmem_session->machines.host;
+	regex_t alloc_func_regex;
+	const char pattern[] = "^_?_?(alloc|get_free|get_zeroed)_pages?";
+
+	ret = regcomp(&alloc_func_regex, pattern, REG_EXTENDED);
+	if (ret) {
+		char err[BUFSIZ];
+
+		regerror(ret, &alloc_func_regex, err, sizeof(err));
+		pr_err("Invalid regex: %s\n%s", pattern, err);
+		return -EINVAL;
+	}
+
+	kernel_map = machine->vmlinux_maps[MAP__FUNCTION];
+	if (map__load(kernel_map, NULL) < 0) {
+		pr_err("cannot load kernel map\n");
+		return -ENOENT;
+	}
+
+	map__for_each_symbol(kernel_map, sym, node) {
+		if (regexec(&alloc_func_regex, sym->name, 0, NULL, 0))
+			continue;
+
+		func = realloc(alloc_func_list,
+			       (nr_alloc_funcs + 1) * sizeof(*func));
+		if (func == NULL)
+			return -ENOMEM;
+
+		pr_debug("alloc func: %s\n", sym->name);
+		func[nr_alloc_funcs].start = sym->start;
+		func[nr_alloc_funcs].end   = sym->end;
+		func[nr_alloc_funcs].name  = sym->name;
+
+		alloc_func_list = func;
+		nr_alloc_funcs++;
+	}
+
+	qsort(alloc_func_list, nr_alloc_funcs, sizeof(*func), funcmp);
+
+	regfree(&alloc_func_regex);
+	return 0;
+}
+
+/*
+ * Find first non-memory allocation function from callchain.
+ * The allocation functions are in the 'alloc_func_list'.
+ */
+static u64 find_callsite(struct perf_evsel *evsel, struct perf_sample *sample)
+{
+	struct addr_location al;
+	struct machine *machine = &kmem_session->machines.host;
+	struct callchain_cursor_node *node;
+
+	if (alloc_func_list == NULL) {
+		if (build_alloc_func_list() < 0)
+			goto out;
+	}
+
+	al.thread = machine__findnew_thread(machine, sample->pid, sample->tid);
+	sample__resolve_callchain(sample, NULL, evsel, &al, 16);
+
+	callchain_cursor_commit(&callchain_cursor);
+	while (true) {
+		struct alloc_func key, *caller;
+		u64 addr;
+
+		node = callchain_cursor_current(&callchain_cursor);
+		if (node == NULL)
+			break;
+
+		key.start = key.end = node->ip;
+		caller = bsearch(&key, alloc_func_list, nr_alloc_funcs,
+				 sizeof(key), callcmp);
+		if (!caller) {
+			/* found */
+			if (node->map)
+				addr = map__unmap_ip(node->map, node->ip);
+			else
+				addr = node->ip;
+
+			return addr;
+		} else
+			pr_debug3("skipping alloc function: %s\n", caller->name);
+
+		callchain_cursor_advance(&callchain_cursor);
+	}
+
+out:
+	pr_debug2("unknown callsite: %"PRIx64 "\n", sample->ip);
+	return sample->ip;
+}
+
+static struct page_stat *
+__page_stat__findnew_page(u64 page, bool create)
 {
 	struct rb_node **node = &page_tree.rb_node;
 	struct rb_node *parent = NULL;
@@ -298,6 +438,16 @@ static struct page_stat *search_page(unsigned long page, bool create)
 	return data;
 }
 
+static struct page_stat *page_stat__find_page(u64 page)
+{
+	return __page_stat__findnew_page(page, false);
+}
+
+static struct page_stat *page_stat__findnew_page(u64 page)
+{
+	return __page_stat__findnew_page(page, true);
+}
+
 static int page_stat_cmp(struct page_stat *a, struct page_stat *b)
 {
 	if (a->page > b->page)
@@ -319,7 +469,8 @@ static int page_stat_cmp(struct page_stat *a, struct page_stat *b)
 	return 0;
 }
 
-static struct page_stat *search_page_alloc_stat(struct page_stat *pstat, bool create)
+static struct page_stat *
+__page_stat__findnew_alloc(struct page_stat *pstat, bool create)
 {
 	struct rb_node **node = &page_alloc_tree.rb_node;
 	struct rb_node *parent = NULL;
@@ -357,6 +508,62 @@ static struct page_stat *search_page_alloc_stat(struct page_stat *pstat, bool cr
 	return data;
 }
 
+static struct page_stat *page_stat__find_alloc(struct page_stat *pstat)
+{
+	return __page_stat__findnew_alloc(pstat, false);
+}
+
+static struct page_stat *page_stat__findnew_alloc(struct page_stat *pstat)
+{
+	return __page_stat__findnew_alloc(pstat, true);
+}
+
+static struct page_stat *
+__page_stat__findnew_caller(u64 callsite, bool create)
+{
+	struct rb_node **node = &page_caller_tree.rb_node;
+	struct rb_node *parent = NULL;
+	struct page_stat *data;
+
+	while (*node) {
+		s64 cmp;
+
+		parent = *node;
+		data = rb_entry(*node, struct page_stat, node);
+
+		cmp = data->callsite - callsite;
+		if (cmp < 0)
+			node = &parent->rb_left;
+		else if (cmp > 0)
+			node = &parent->rb_right;
+		else
+			return data;
+	}
+
+	if (!create)
+		return NULL;
+
+	data = zalloc(sizeof(*data));
+	if (data != NULL) {
+		data->callsite = callsite;
+
+		rb_link_node(&data->node, parent, node);
+		rb_insert_color(&data->node, &page_caller_tree);
+	}
+
+	return data;
+}
+
+static struct page_stat *page_stat__find_caller(u64 callsite)
+{
+	return __page_stat__findnew_caller(callsite, false);
+}
+
+static struct page_stat *page_stat__findnew_caller(u64 callsite)
+{
+	return __page_stat__findnew_caller(callsite, true);
+}
+
 static bool valid_page(u64 pfn_or_page)
 {
 	if (use_pfn && pfn_or_page == -1UL)
@@ -375,6 +582,7 @@ static int perf_evsel__process_page_alloc_event(struct perf_evsel *evsel,
 	unsigned int migrate_type = perf_evsel__intval(evsel, sample,
 						       "migratetype");
 	u64 bytes = kmem_page_size << order;
+	u64 callsite;
 	struct page_stat *pstat;
 	struct page_stat this = {
 		.order = order,
@@ -397,23 +605,38 @@ static int perf_evsel__process_page_alloc_event(struct perf_evsel *evsel,
 		return 0;
 	}
 
+	callsite = find_callsite(evsel, sample);
+
 	/*
 	 * This is to find the current page (with correct gfp flags and
 	 * migrate type) at free event.
 	 */
-	pstat = search_page(page, true);
+	pstat = page_stat__findnew_page(page);
 	if (pstat == NULL)
 		return -ENOMEM;
 
 	pstat->order = order;
 	pstat->gfp_flags = gfp_flags;
 	pstat->migrate_type = migrate_type;
+	pstat->callsite = callsite;
 
 	this.page = page;
-	pstat = search_page_alloc_stat(&this, true);
+	pstat = page_stat__findnew_alloc(&this);
 	if (pstat == NULL)
 		return -ENOMEM;
 
+	pstat->nr_alloc++;
+	pstat->alloc_bytes += bytes;
+	pstat->callsite = callsite;
+
+	pstat = page_stat__findnew_caller(callsite);
+	if (pstat == NULL)
+		return -ENOMEM;
+
+	pstat->order = order;
+	pstat->gfp_flags = gfp_flags;
+	pstat->migrate_type = migrate_type;
+
 	pstat->nr_alloc++;
 	pstat->alloc_bytes += bytes;
 
@@ -441,7 +664,7 @@ static int perf_evsel__process_page_free_event(struct perf_evsel *evsel,
 	nr_page_frees++;
 	total_page_free_bytes += bytes;
 
-	pstat = search_page(page, false);
+	pstat = page_stat__find_page(page);
 	if (pstat == NULL) {
 		pr_debug2("missing free at page %"PRIx64" (order: %d)\n",
 			  page, order);
@@ -455,11 +678,19 @@ static int perf_evsel__process_page_free_event(struct perf_evsel *evsel,
 	this.page = page;
 	this.gfp_flags = pstat->gfp_flags;
 	this.migrate_type = pstat->migrate_type;
+	this.callsite = pstat->callsite;
 
 	rb_erase(&pstat->node, &page_tree);
 	free(pstat);
 
-	pstat = search_page_alloc_stat(&this, false);
+	pstat = page_stat__find_alloc(&this);
+	if (pstat == NULL)
+		return -ENOENT;
+
+	pstat->nr_free++;
+	pstat->free_bytes += bytes;
+
+	pstat = page_stat__find_caller(this.callsite);
 	if (pstat == NULL)
 		return -ENOENT;
 
@@ -576,41 +807,89 @@ static const char * const migrate_type_str[] = {
 	"UNKNOWN",
 };
 
-static void __print_page_result(struct rb_root *root,
-				struct perf_session *session __maybe_unused,
-				int n_lines)
+static void __print_page_alloc_result(struct perf_session *session, int n_lines)
 {
-	struct rb_node *next = rb_first(root);
+	struct rb_node *next = rb_first(&page_alloc_sorted);
+	struct machine *machine = &session->machines.host;
 	const char *format;
 
-	printf("\n%.80s\n", graph_dotted_line);
-	printf(" %-16s | Total alloc (KB) | Hits      | Order | Mig.type | GFP flags\n",
+	printf("\n%.105s\n", graph_dotted_line);
+	printf(" %-16s | Total alloc (KB) | Hits      | Order | Mig.type | GFP flags | Callsite\n",
 	       use_pfn ? "PFN" : "Page");
-	printf("%.80s\n", graph_dotted_line);
+	printf("%.105s\n", graph_dotted_line);
 
 	if (use_pfn)
-		format = " %16llu | %'16llu | %'9d | %5d | %8s |  %08lx\n";
+		format = " %16llu | %'16llu | %'9d | %5d | %8s |  %08lx | %s\n";
 	else
-		format = " %016llx | %'16llu | %'9d | %5d | %8s |  %08lx\n";
+		format = " %016llx | %'16llu | %'9d | %5d | %8s |  %08lx | %s\n";
 
 	while (next && n_lines--) {
 		struct page_stat *data;
+		struct symbol *sym;
+		struct map *map;
+		char buf[32];
+		char *caller = buf;
 
 		data = rb_entry(next, struct page_stat, node);
+		sym = machine__find_kernel_function(machine, data->callsite,
+						    &map, NULL);
+		if (sym && sym->name)
+			caller = sym->name;
+		else
+			scnprintf(buf, sizeof(buf), "%"PRIx64, data->callsite);
 
 		printf(format, (unsigned long long)data->page,
 		       (unsigned long long)data->alloc_bytes / 1024,
 		       data->nr_alloc, data->order,
 		       migrate_type_str[data->migrate_type],
-		       (unsigned long)data->gfp_flags);
+		       (unsigned long)data->gfp_flags, caller);
 
 		next = rb_next(next);
 	}
 
 	if (n_lines == -1)
-		printf(" ...              | ...              | ...       | ...   | ...      | ...     \n");
+		printf(" ...              | ...              | ...       | ...   | ...      | ...       | ...\n");
 
-	printf("%.80s\n", graph_dotted_line);
+	printf("%.105s\n", graph_dotted_line);
+}
+
+static void __print_page_caller_result(struct perf_session *session, int n_lines)
+{
+	struct rb_node *next = rb_first(&page_caller_sorted);
+	struct machine *machine = &session->machines.host;
+
+	printf("\n%.105s\n", graph_dotted_line);
+	printf(" Total alloc (KB) | Hits      | Order | Mig.type | GFP flags | Callsite\n");
+	printf("%.105s\n", graph_dotted_line);
+
+	while (next && n_lines--) {
+		struct page_stat *data;
+		struct symbol *sym;
+		struct map *map;
+		char buf[32];
+		char *caller = buf;
+
+		data = rb_entry(next, struct page_stat, node);
+		sym = machine__find_kernel_function(machine, data->callsite,
+						    &map, NULL);
+		if (sym && sym->name)
+			caller = sym->name;
+		else
+			scnprintf(buf, sizeof(buf), "%"PRIx64, data->callsite);
+
+		printf(" %'16llu | %'9d | %5d | %8s |  %08lx | %s\n",
+		       (unsigned long long)data->alloc_bytes / 1024,
+		       data->nr_alloc, data->order,
+		       migrate_type_str[data->migrate_type],
+		       (unsigned long)data->gfp_flags, caller);
+
+		next = rb_next(next);
+	}
+
+	if (n_lines == -1)
+		printf(" ...              | ...       | ...   | ...      | ...       | ...\n");
+
+	printf("%.105s\n", graph_dotted_line);
 }
 
 static void print_slab_summary(void)
@@ -682,8 +961,10 @@ static void print_slab_result(struct perf_session *session)
 
 static void print_page_result(struct perf_session *session)
 {
+	if (caller_flag)
+		__print_page_caller_result(session, caller_lines);
 	if (alloc_flag)
-		__print_page_result(&page_alloc_sorted, session, alloc_lines);
+		__print_page_alloc_result(session, alloc_lines);
 	print_page_summary();
 }
 
@@ -802,6 +1083,7 @@ static void sort_result(void)
 	}
 	if (kmem_page) {
 		__sort_page_result(&page_alloc_tree, &page_alloc_sorted);
+		__sort_page_result(&page_caller_tree, &page_caller_sorted);
 	}
 }
 
@@ -1084,7 +1366,7 @@ static int __cmd_record(int argc, const char **argv)
 	if (kmem_slab)
 		rec_argc += ARRAY_SIZE(slab_events);
 	if (kmem_page)
-		rec_argc += ARRAY_SIZE(page_events);
+		rec_argc += ARRAY_SIZE(page_events) + 1; /* for -g */
 
 	rec_argv = calloc(rec_argc + 1, sizeof(char *));
 
@@ -1099,6 +1381,8 @@ static int __cmd_record(int argc, const char **argv)
 			rec_argv[i] = strdup(slab_events[j]);
 	}
 	if (kmem_page) {
+		rec_argv[i++] = strdup("-g");
+
 		for (j = 0; j < ARRAY_SIZE(page_events); j++, i++)
 			rec_argv[i] = strdup(page_events[j]);
 	}
@@ -1159,7 +1443,7 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 
 	file.path = input_name;
 
-	session = perf_session__new(&file, false, &perf_kmem);
+	kmem_session = session = perf_session__new(&file, false, &perf_kmem);
 	if (session == NULL)
 		return -1;
 
@@ -1172,6 +1456,7 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 		}
 
 		kmem_page_size = pevent_get_page_size(evsel->tp_format->pevent);
+		symbol_conf.use_callchain = true;
 	}
 
 	symbol__init(&session->header.env);

commit 6b1a27520f990700d0dd23976afd8992bf659698
Author: David Ahern <david.ahern@oracle.com>
Date:   Tue Apr 14 13:49:33 2015 -0400

    perf kmem: Fix compiles on RHEL6/OL6
    
    0d68bc92c48 breaks compiles on RHEL6/OL6:
        cc1: warnings being treated as errors
        builtin-kmem.c: In function ‘search_page_alloc_stat’:
        builtin-kmem.c:322: error: declaration of ‘stat’ shadows a global declaration
                                node = &parent->rb_left;
        /usr/include/sys/stat.h:455: error: shadowed declaration is here
        builtin-kmem.c: In function ‘perf_evsel__process_page_alloc_event’:
        builtin-kmem.c:378: error: declaration of ‘stat’ shadows a global declaration
        /usr/include/sys/stat.h:455: error: shadowed declaration is here
        builtin-kmem.c: In function ‘perf_evsel__process_page_free_event’:
        builtin-kmem.c:431: error: declaration of ‘stat’ shadows a global declaration
        /usr/include/sys/stat.h:455: error: shadowed declaration is here
    
    Rename local variable to pstat to avoid the name conflict.
    
    Signed-off-by: David Ahern <david.ahern@oracle.com>
    Link: http://lkml.kernel.org/r/1429033773-31383-1-git-send-email-david.ahern@oracle.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 63ea01349b6e..4f0f38462d97 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -319,7 +319,7 @@ static int page_stat_cmp(struct page_stat *a, struct page_stat *b)
 	return 0;
 }
 
-static struct page_stat *search_page_alloc_stat(struct page_stat *stat, bool create)
+static struct page_stat *search_page_alloc_stat(struct page_stat *pstat, bool create)
 {
 	struct rb_node **node = &page_alloc_tree.rb_node;
 	struct rb_node *parent = NULL;
@@ -331,7 +331,7 @@ static struct page_stat *search_page_alloc_stat(struct page_stat *stat, bool cre
 		parent = *node;
 		data = rb_entry(*node, struct page_stat, node);
 
-		cmp = page_stat_cmp(data, stat);
+		cmp = page_stat_cmp(data, pstat);
 		if (cmp < 0)
 			node = &parent->rb_left;
 		else if (cmp > 0)
@@ -345,10 +345,10 @@ static struct page_stat *search_page_alloc_stat(struct page_stat *stat, bool cre
 
 	data = zalloc(sizeof(*data));
 	if (data != NULL) {
-		data->page = stat->page;
-		data->order = stat->order;
-		data->gfp_flags = stat->gfp_flags;
-		data->migrate_type = stat->migrate_type;
+		data->page = pstat->page;
+		data->order = pstat->order;
+		data->gfp_flags = pstat->gfp_flags;
+		data->migrate_type = pstat->migrate_type;
 
 		rb_link_node(&data->node, parent, node);
 		rb_insert_color(&data->node, &page_alloc_tree);
@@ -375,7 +375,7 @@ static int perf_evsel__process_page_alloc_event(struct perf_evsel *evsel,
 	unsigned int migrate_type = perf_evsel__intval(evsel, sample,
 						       "migratetype");
 	u64 bytes = kmem_page_size << order;
-	struct page_stat *stat;
+	struct page_stat *pstat;
 	struct page_stat this = {
 		.order = order,
 		.gfp_flags = gfp_flags,
@@ -401,21 +401,21 @@ static int perf_evsel__process_page_alloc_event(struct perf_evsel *evsel,
 	 * This is to find the current page (with correct gfp flags and
 	 * migrate type) at free event.
 	 */
-	stat = search_page(page, true);
-	if (stat == NULL)
+	pstat = search_page(page, true);
+	if (pstat == NULL)
 		return -ENOMEM;
 
-	stat->order = order;
-	stat->gfp_flags = gfp_flags;
-	stat->migrate_type = migrate_type;
+	pstat->order = order;
+	pstat->gfp_flags = gfp_flags;
+	pstat->migrate_type = migrate_type;
 
 	this.page = page;
-	stat = search_page_alloc_stat(&this, true);
-	if (stat == NULL)
+	pstat = search_page_alloc_stat(&this, true);
+	if (pstat == NULL)
 		return -ENOMEM;
 
-	stat->nr_alloc++;
-	stat->alloc_bytes += bytes;
+	pstat->nr_alloc++;
+	pstat->alloc_bytes += bytes;
 
 	order_stats[order][migrate_type]++;
 
@@ -428,7 +428,7 @@ static int perf_evsel__process_page_free_event(struct perf_evsel *evsel,
 	u64 page;
 	unsigned int order = perf_evsel__intval(evsel, sample, "order");
 	u64 bytes = kmem_page_size << order;
-	struct page_stat *stat;
+	struct page_stat *pstat;
 	struct page_stat this = {
 		.order = order,
 	};
@@ -441,8 +441,8 @@ static int perf_evsel__process_page_free_event(struct perf_evsel *evsel,
 	nr_page_frees++;
 	total_page_free_bytes += bytes;
 
-	stat = search_page(page, false);
-	if (stat == NULL) {
+	pstat = search_page(page, false);
+	if (pstat == NULL) {
 		pr_debug2("missing free at page %"PRIx64" (order: %d)\n",
 			  page, order);
 
@@ -453,18 +453,18 @@ static int perf_evsel__process_page_free_event(struct perf_evsel *evsel,
 	}
 
 	this.page = page;
-	this.gfp_flags = stat->gfp_flags;
-	this.migrate_type = stat->migrate_type;
+	this.gfp_flags = pstat->gfp_flags;
+	this.migrate_type = pstat->migrate_type;
 
-	rb_erase(&stat->node, &page_tree);
-	free(stat);
+	rb_erase(&pstat->node, &page_tree);
+	free(pstat);
 
-	stat = search_page_alloc_stat(&this, false);
-	if (stat == NULL)
+	pstat = search_page_alloc_stat(&this, false);
+	if (pstat == NULL)
 		return -ENOENT;
 
-	stat->nr_free++;
-	stat->free_bytes += bytes;
+	pstat->nr_free++;
+	pstat->free_bytes += bytes;
 
 	return 0;
 }

commit 4ad1f4300e3bddf63109aa63cfb2d37e8585ecc7
Author: David Ahern <david.ahern@oracle.com>
Date:   Tue Apr 14 13:49:33 2015 -0400

    perf kmem: Fix compiles on RHEL6/OL6
    
    0d68bc92c48 breaks compiles on RHEL6/OL6:
        cc1: warnings being treated as errors
        builtin-kmem.c: In function ‘search_page_alloc_stat’:
        builtin-kmem.c:322: error: declaration of ‘stat’ shadows a global declaration
                                node = &parent->rb_left;
        /usr/include/sys/stat.h:455: error: shadowed declaration is here
        builtin-kmem.c: In function ‘perf_evsel__process_page_alloc_event’:
        builtin-kmem.c:378: error: declaration of ‘stat’ shadows a global declaration
        /usr/include/sys/stat.h:455: error: shadowed declaration is here
        builtin-kmem.c: In function ‘perf_evsel__process_page_free_event’:
        builtin-kmem.c:431: error: declaration of ‘stat’ shadows a global declaration
        /usr/include/sys/stat.h:455: error: shadowed declaration is here
    
    Rename local variable to pstat to avoid the name conflict.
    
    Signed-off-by: David Ahern <david.ahern@oracle.com>
    Link: http://lkml.kernel.org/r/1429033773-31383-1-git-send-email-david.ahern@oracle.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index a1915b430044..1634186d537c 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -319,7 +319,7 @@ static int page_stat_cmp(struct page_stat *a, struct page_stat *b)
 	return 0;
 }
 
-static struct page_stat *search_page_alloc_stat(struct page_stat *stat, bool create)
+static struct page_stat *search_page_alloc_stat(struct page_stat *pstat, bool create)
 {
 	struct rb_node **node = &page_alloc_tree.rb_node;
 	struct rb_node *parent = NULL;
@@ -331,7 +331,7 @@ static struct page_stat *search_page_alloc_stat(struct page_stat *stat, bool cre
 		parent = *node;
 		data = rb_entry(*node, struct page_stat, node);
 
-		cmp = page_stat_cmp(data, stat);
+		cmp = page_stat_cmp(data, pstat);
 		if (cmp < 0)
 			node = &parent->rb_left;
 		else if (cmp > 0)
@@ -345,10 +345,10 @@ static struct page_stat *search_page_alloc_stat(struct page_stat *stat, bool cre
 
 	data = zalloc(sizeof(*data));
 	if (data != NULL) {
-		data->page = stat->page;
-		data->order = stat->order;
-		data->gfp_flags = stat->gfp_flags;
-		data->migrate_type = stat->migrate_type;
+		data->page = pstat->page;
+		data->order = pstat->order;
+		data->gfp_flags = pstat->gfp_flags;
+		data->migrate_type = pstat->migrate_type;
 
 		rb_link_node(&data->node, parent, node);
 		rb_insert_color(&data->node, &page_alloc_tree);
@@ -375,7 +375,7 @@ static int perf_evsel__process_page_alloc_event(struct perf_evsel *evsel,
 	unsigned int migrate_type = perf_evsel__intval(evsel, sample,
 						       "migratetype");
 	u64 bytes = kmem_page_size << order;
-	struct page_stat *stat;
+	struct page_stat *pstat;
 	struct page_stat this = {
 		.order = order,
 		.gfp_flags = gfp_flags,
@@ -401,21 +401,21 @@ static int perf_evsel__process_page_alloc_event(struct perf_evsel *evsel,
 	 * This is to find the current page (with correct gfp flags and
 	 * migrate type) at free event.
 	 */
-	stat = search_page(page, true);
-	if (stat == NULL)
+	pstat = search_page(page, true);
+	if (pstat == NULL)
 		return -ENOMEM;
 
-	stat->order = order;
-	stat->gfp_flags = gfp_flags;
-	stat->migrate_type = migrate_type;
+	pstat->order = order;
+	pstat->gfp_flags = gfp_flags;
+	pstat->migrate_type = migrate_type;
 
 	this.page = page;
-	stat = search_page_alloc_stat(&this, true);
-	if (stat == NULL)
+	pstat = search_page_alloc_stat(&this, true);
+	if (pstat == NULL)
 		return -ENOMEM;
 
-	stat->nr_alloc++;
-	stat->alloc_bytes += bytes;
+	pstat->nr_alloc++;
+	pstat->alloc_bytes += bytes;
 
 	order_stats[order][migrate_type]++;
 
@@ -428,7 +428,7 @@ static int perf_evsel__process_page_free_event(struct perf_evsel *evsel,
 	u64 page;
 	unsigned int order = perf_evsel__intval(evsel, sample, "order");
 	u64 bytes = kmem_page_size << order;
-	struct page_stat *stat;
+	struct page_stat *pstat;
 	struct page_stat this = {
 		.order = order,
 	};
@@ -441,8 +441,8 @@ static int perf_evsel__process_page_free_event(struct perf_evsel *evsel,
 	nr_page_frees++;
 	total_page_free_bytes += bytes;
 
-	stat = search_page(page, false);
-	if (stat == NULL) {
+	pstat = search_page(page, false);
+	if (pstat == NULL) {
 		pr_debug2("missing free at page %"PRIx64" (order: %d)\n",
 			  page, order);
 
@@ -453,18 +453,18 @@ static int perf_evsel__process_page_free_event(struct perf_evsel *evsel,
 	}
 
 	this.page = page;
-	this.gfp_flags = stat->gfp_flags;
-	this.migrate_type = stat->migrate_type;
+	this.gfp_flags = pstat->gfp_flags;
+	this.migrate_type = pstat->migrate_type;
 
-	rb_erase(&stat->node, &page_tree);
-	free(stat);
+	rb_erase(&pstat->node, &page_tree);
+	free(pstat);
 
-	stat = search_page_alloc_stat(&this, false);
-	if (stat == NULL)
+	pstat = search_page_alloc_stat(&this, false);
+	if (pstat == NULL)
 		return -ENOENT;
 
-	stat->nr_free++;
-	stat->free_bytes += bytes;
+	pstat->nr_free++;
+	pstat->free_bytes += bytes;
 
 	return 0;
 }

commit 6145c259cd454bcb7a1288f7bbb7b4fbc18175dd
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Apr 23 14:40:37 2015 +0100

    perf kmem: Consistently use PRIu64 for printing u64 values
    
    Building the perf tool for 32-bit ARM results in the following build
    error due to a combination of an incorrect conversion specifier and
    compiling with -Werror:
    
      builtin-kmem.c: In function ‘print_page_summary’:
      builtin-kmem.c:644:9: error: format ‘%lu’ expects argument of type ‘long unsigned int’, but argument 3 has type ‘u64’ [-Werror=format=]
               nr_alloc_freed, (total_alloc_freed_bytes) / 1024);
               ^
      builtin-kmem.c:647:9: error: format ‘%lu’ expects argument of type ‘long unsigned int’, but argument 3 has type ‘u64’ [-Werror=format=]
               (total_page_alloc_bytes - total_alloc_freed_bytes) / 1024);
               ^
      cc1: all warnings being treated as errors
    
    This patch fixes the problem by consistently using PRIu64 for printing
    out u64 values.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1429796437-1790-1-git-send-email-will.deacon@arm.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 63ea01349b6e..a1915b430044 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -640,9 +640,9 @@ static void print_page_summary(void)
 	       nr_page_frees, total_page_free_bytes / 1024);
 	printf("\n");
 
-	printf("%-30s: %'16lu   [ %'16"PRIu64" KB ]\n", "Total alloc+freed requests",
+	printf("%-30s: %'16"PRIu64"   [ %'16"PRIu64" KB ]\n", "Total alloc+freed requests",
 	       nr_alloc_freed, (total_alloc_freed_bytes) / 1024);
-	printf("%-30s: %'16lu   [ %'16"PRIu64" KB ]\n", "Total alloc-only requests",
+	printf("%-30s: %'16"PRIu64"   [ %'16"PRIu64" KB ]\n", "Total alloc-only requests",
 	       nr_page_allocs - nr_alloc_freed,
 	       (total_page_alloc_bytes - total_alloc_freed_bytes) / 1024);
 	printf("%-30s: %'16lu   [ %'16"PRIu64" KB ]\n", "Total free-only requests",

commit 0d68bc92c48167130b61b449f08be27dc862dba2
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Mon Apr 6 14:36:10 2015 +0900

    perf kmem: Analyze page allocator events also
    
    The perf kmem command records and analyze kernel memory allocation only
    for SLAB objects.  This patch implement a simple page allocator analyzer
    using kmem:mm_page_alloc and kmem:mm_page_free events.
    
    It adds two new options of --slab and --page.  The --slab option is for
    analyzing SLAB allocator and that's what perf kmem currently does.
    
    The new --page option enables page allocator events and analyze kernel
    memory usage in page unit.  Currently, 'stat --alloc' subcommand is
    implemented only.
    
    If none of these --slab nor --page is specified, --slab is implied.
    
    First run 'perf kmem record' to generate a suitable perf.data file:
    
      # perf kmem record --page sleep 5
    
    Then run 'perf kmem stat' to postprocess the perf.data file:
    
      # perf kmem stat --page --alloc --line 10
    
      -------------------------------------------------------------------------------
       PFN              | Total alloc (KB) | Hits     | Order | Mig.type | GFP flags
      -------------------------------------------------------------------------------
                4045014 |               16 |        1 |     2 |  RECLAIM |  00285250
                4143980 |               16 |        1 |     2 |  RECLAIM |  00285250
                3938658 |               16 |        1 |     2 |  RECLAIM |  00285250
                4045400 |               16 |        1 |     2 |  RECLAIM |  00285250
                3568708 |               16 |        1 |     2 |  RECLAIM |  00285250
                3729824 |               16 |        1 |     2 |  RECLAIM |  00285250
                3657210 |               16 |        1 |     2 |  RECLAIM |  00285250
                4120750 |               16 |        1 |     2 |  RECLAIM |  00285250
                3678850 |               16 |        1 |     2 |  RECLAIM |  00285250
                3693874 |               16 |        1 |     2 |  RECLAIM |  00285250
       ...              | ...              | ...      | ...   | ...      | ...
      -------------------------------------------------------------------------------
    
      SUMMARY (page allocator)
      ========================
      Total allocation requests     :           44,260   [          177,256 KB ]
      Total free requests           :              117   [              468 KB ]
    
      Total alloc+freed requests    :               49   [              196 KB ]
      Total alloc-only requests     :           44,211   [          177,060 KB ]
      Total free-only requests      :               68   [              272 KB ]
    
      Total allocation failures     :                0   [                0 KB ]
    
      Order     Unmovable   Reclaimable       Movable      Reserved  CMA/Isolated
      -----  ------------  ------------  ------------  ------------  ------------
          0            32             .        44,210             .             .
          1             .             .             .             .             .
          2             .            18             .             .             .
          3             .             .             .             .             .
          4             .             .             .             .             .
          5             .             .             .             .             .
          6             .             .             .             .             .
          7             .             .             .             .             .
          8             .             .             .             .             .
          9             .             .             .             .             .
         10             .             .             .             .             .
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/1428298576-9785-4-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 4ebf65c79434..63ea01349b6e 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -22,6 +22,11 @@
 #include <linux/string.h>
 #include <locale.h>
 
+static int	kmem_slab;
+static int	kmem_page;
+
+static long	kmem_page_size;
+
 struct alloc_stat;
 typedef int (*sort_fn_t)(struct alloc_stat *, struct alloc_stat *);
 
@@ -226,6 +231,244 @@ static int perf_evsel__process_free_event(struct perf_evsel *evsel,
 	return 0;
 }
 
+static u64 total_page_alloc_bytes;
+static u64 total_page_free_bytes;
+static u64 total_page_nomatch_bytes;
+static u64 total_page_fail_bytes;
+static unsigned long nr_page_allocs;
+static unsigned long nr_page_frees;
+static unsigned long nr_page_fails;
+static unsigned long nr_page_nomatch;
+
+static bool use_pfn;
+
+#define MAX_MIGRATE_TYPES  6
+#define MAX_PAGE_ORDER     11
+
+static int order_stats[MAX_PAGE_ORDER][MAX_MIGRATE_TYPES];
+
+struct page_stat {
+	struct rb_node 	node;
+	u64 		page;
+	int 		order;
+	unsigned 	gfp_flags;
+	unsigned 	migrate_type;
+	u64		alloc_bytes;
+	u64 		free_bytes;
+	int 		nr_alloc;
+	int 		nr_free;
+};
+
+static struct rb_root page_tree;
+static struct rb_root page_alloc_tree;
+static struct rb_root page_alloc_sorted;
+
+static struct page_stat *search_page(unsigned long page, bool create)
+{
+	struct rb_node **node = &page_tree.rb_node;
+	struct rb_node *parent = NULL;
+	struct page_stat *data;
+
+	while (*node) {
+		s64 cmp;
+
+		parent = *node;
+		data = rb_entry(*node, struct page_stat, node);
+
+		cmp = data->page - page;
+		if (cmp < 0)
+			node = &parent->rb_left;
+		else if (cmp > 0)
+			node = &parent->rb_right;
+		else
+			return data;
+	}
+
+	if (!create)
+		return NULL;
+
+	data = zalloc(sizeof(*data));
+	if (data != NULL) {
+		data->page = page;
+
+		rb_link_node(&data->node, parent, node);
+		rb_insert_color(&data->node, &page_tree);
+	}
+
+	return data;
+}
+
+static int page_stat_cmp(struct page_stat *a, struct page_stat *b)
+{
+	if (a->page > b->page)
+		return -1;
+	if (a->page < b->page)
+		return 1;
+	if (a->order > b->order)
+		return -1;
+	if (a->order < b->order)
+		return 1;
+	if (a->migrate_type > b->migrate_type)
+		return -1;
+	if (a->migrate_type < b->migrate_type)
+		return 1;
+	if (a->gfp_flags > b->gfp_flags)
+		return -1;
+	if (a->gfp_flags < b->gfp_flags)
+		return 1;
+	return 0;
+}
+
+static struct page_stat *search_page_alloc_stat(struct page_stat *stat, bool create)
+{
+	struct rb_node **node = &page_alloc_tree.rb_node;
+	struct rb_node *parent = NULL;
+	struct page_stat *data;
+
+	while (*node) {
+		s64 cmp;
+
+		parent = *node;
+		data = rb_entry(*node, struct page_stat, node);
+
+		cmp = page_stat_cmp(data, stat);
+		if (cmp < 0)
+			node = &parent->rb_left;
+		else if (cmp > 0)
+			node = &parent->rb_right;
+		else
+			return data;
+	}
+
+	if (!create)
+		return NULL;
+
+	data = zalloc(sizeof(*data));
+	if (data != NULL) {
+		data->page = stat->page;
+		data->order = stat->order;
+		data->gfp_flags = stat->gfp_flags;
+		data->migrate_type = stat->migrate_type;
+
+		rb_link_node(&data->node, parent, node);
+		rb_insert_color(&data->node, &page_alloc_tree);
+	}
+
+	return data;
+}
+
+static bool valid_page(u64 pfn_or_page)
+{
+	if (use_pfn && pfn_or_page == -1UL)
+		return false;
+	if (!use_pfn && pfn_or_page == 0)
+		return false;
+	return true;
+}
+
+static int perf_evsel__process_page_alloc_event(struct perf_evsel *evsel,
+						struct perf_sample *sample)
+{
+	u64 page;
+	unsigned int order = perf_evsel__intval(evsel, sample, "order");
+	unsigned int gfp_flags = perf_evsel__intval(evsel, sample, "gfp_flags");
+	unsigned int migrate_type = perf_evsel__intval(evsel, sample,
+						       "migratetype");
+	u64 bytes = kmem_page_size << order;
+	struct page_stat *stat;
+	struct page_stat this = {
+		.order = order,
+		.gfp_flags = gfp_flags,
+		.migrate_type = migrate_type,
+	};
+
+	if (use_pfn)
+		page = perf_evsel__intval(evsel, sample, "pfn");
+	else
+		page = perf_evsel__intval(evsel, sample, "page");
+
+	nr_page_allocs++;
+	total_page_alloc_bytes += bytes;
+
+	if (!valid_page(page)) {
+		nr_page_fails++;
+		total_page_fail_bytes += bytes;
+
+		return 0;
+	}
+
+	/*
+	 * This is to find the current page (with correct gfp flags and
+	 * migrate type) at free event.
+	 */
+	stat = search_page(page, true);
+	if (stat == NULL)
+		return -ENOMEM;
+
+	stat->order = order;
+	stat->gfp_flags = gfp_flags;
+	stat->migrate_type = migrate_type;
+
+	this.page = page;
+	stat = search_page_alloc_stat(&this, true);
+	if (stat == NULL)
+		return -ENOMEM;
+
+	stat->nr_alloc++;
+	stat->alloc_bytes += bytes;
+
+	order_stats[order][migrate_type]++;
+
+	return 0;
+}
+
+static int perf_evsel__process_page_free_event(struct perf_evsel *evsel,
+						struct perf_sample *sample)
+{
+	u64 page;
+	unsigned int order = perf_evsel__intval(evsel, sample, "order");
+	u64 bytes = kmem_page_size << order;
+	struct page_stat *stat;
+	struct page_stat this = {
+		.order = order,
+	};
+
+	if (use_pfn)
+		page = perf_evsel__intval(evsel, sample, "pfn");
+	else
+		page = perf_evsel__intval(evsel, sample, "page");
+
+	nr_page_frees++;
+	total_page_free_bytes += bytes;
+
+	stat = search_page(page, false);
+	if (stat == NULL) {
+		pr_debug2("missing free at page %"PRIx64" (order: %d)\n",
+			  page, order);
+
+		nr_page_nomatch++;
+		total_page_nomatch_bytes += bytes;
+
+		return 0;
+	}
+
+	this.page = page;
+	this.gfp_flags = stat->gfp_flags;
+	this.migrate_type = stat->migrate_type;
+
+	rb_erase(&stat->node, &page_tree);
+	free(stat);
+
+	stat = search_page_alloc_stat(&this, false);
+	if (stat == NULL)
+		return -ENOENT;
+
+	stat->nr_free++;
+	stat->free_bytes += bytes;
+
+	return 0;
+}
+
 typedef int (*tracepoint_handler)(struct perf_evsel *evsel,
 				  struct perf_sample *sample);
 
@@ -270,8 +513,9 @@ static double fragmentation(unsigned long n_req, unsigned long n_alloc)
 		return 100.0 - (100.0 * n_req / n_alloc);
 }
 
-static void __print_result(struct rb_root *root, struct perf_session *session,
-			   int n_lines, int is_caller)
+static void __print_slab_result(struct rb_root *root,
+				struct perf_session *session,
+				int n_lines, int is_caller)
 {
 	struct rb_node *next;
 	struct machine *machine = &session->machines.host;
@@ -323,9 +567,56 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 	printf("%.105s\n", graph_dotted_line);
 }
 
-static void print_summary(void)
+static const char * const migrate_type_str[] = {
+	"UNMOVABL",
+	"RECLAIM",
+	"MOVABLE",
+	"RESERVED",
+	"CMA/ISLT",
+	"UNKNOWN",
+};
+
+static void __print_page_result(struct rb_root *root,
+				struct perf_session *session __maybe_unused,
+				int n_lines)
+{
+	struct rb_node *next = rb_first(root);
+	const char *format;
+
+	printf("\n%.80s\n", graph_dotted_line);
+	printf(" %-16s | Total alloc (KB) | Hits      | Order | Mig.type | GFP flags\n",
+	       use_pfn ? "PFN" : "Page");
+	printf("%.80s\n", graph_dotted_line);
+
+	if (use_pfn)
+		format = " %16llu | %'16llu | %'9d | %5d | %8s |  %08lx\n";
+	else
+		format = " %016llx | %'16llu | %'9d | %5d | %8s |  %08lx\n";
+
+	while (next && n_lines--) {
+		struct page_stat *data;
+
+		data = rb_entry(next, struct page_stat, node);
+
+		printf(format, (unsigned long long)data->page,
+		       (unsigned long long)data->alloc_bytes / 1024,
+		       data->nr_alloc, data->order,
+		       migrate_type_str[data->migrate_type],
+		       (unsigned long)data->gfp_flags);
+
+		next = rb_next(next);
+	}
+
+	if (n_lines == -1)
+		printf(" ...              | ...              | ...       | ...   | ...      | ...     \n");
+
+	printf("%.80s\n", graph_dotted_line);
+}
+
+static void print_slab_summary(void)
 {
-	printf("\nSUMMARY\n=======\n");
+	printf("\nSUMMARY (SLAB allocator)");
+	printf("\n========================\n");
 	printf("Total bytes requested: %'lu\n", total_requested);
 	printf("Total bytes allocated: %'lu\n", total_allocated);
 	printf("Total bytes wasted on internal fragmentation: %'lu\n",
@@ -335,13 +626,73 @@ static void print_summary(void)
 	printf("Cross CPU allocations: %'lu/%'lu\n", nr_cross_allocs, nr_allocs);
 }
 
-static void print_result(struct perf_session *session)
+static void print_page_summary(void)
+{
+	int o, m;
+	u64 nr_alloc_freed = nr_page_frees - nr_page_nomatch;
+	u64 total_alloc_freed_bytes = total_page_free_bytes - total_page_nomatch_bytes;
+
+	printf("\nSUMMARY (page allocator)");
+	printf("\n========================\n");
+	printf("%-30s: %'16lu   [ %'16"PRIu64" KB ]\n", "Total allocation requests",
+	       nr_page_allocs, total_page_alloc_bytes / 1024);
+	printf("%-30s: %'16lu   [ %'16"PRIu64" KB ]\n", "Total free requests",
+	       nr_page_frees, total_page_free_bytes / 1024);
+	printf("\n");
+
+	printf("%-30s: %'16lu   [ %'16"PRIu64" KB ]\n", "Total alloc+freed requests",
+	       nr_alloc_freed, (total_alloc_freed_bytes) / 1024);
+	printf("%-30s: %'16lu   [ %'16"PRIu64" KB ]\n", "Total alloc-only requests",
+	       nr_page_allocs - nr_alloc_freed,
+	       (total_page_alloc_bytes - total_alloc_freed_bytes) / 1024);
+	printf("%-30s: %'16lu   [ %'16"PRIu64" KB ]\n", "Total free-only requests",
+	       nr_page_nomatch, total_page_nomatch_bytes / 1024);
+	printf("\n");
+
+	printf("%-30s: %'16lu   [ %'16"PRIu64" KB ]\n", "Total allocation failures",
+	       nr_page_fails, total_page_fail_bytes / 1024);
+	printf("\n");
+
+	printf("%5s  %12s  %12s  %12s  %12s  %12s\n", "Order",  "Unmovable",
+	       "Reclaimable", "Movable", "Reserved", "CMA/Isolated");
+	printf("%.5s  %.12s  %.12s  %.12s  %.12s  %.12s\n", graph_dotted_line,
+	       graph_dotted_line, graph_dotted_line, graph_dotted_line,
+	       graph_dotted_line, graph_dotted_line);
+
+	for (o = 0; o < MAX_PAGE_ORDER; o++) {
+		printf("%5d", o);
+		for (m = 0; m < MAX_MIGRATE_TYPES - 1; m++) {
+			if (order_stats[o][m])
+				printf("  %'12d", order_stats[o][m]);
+			else
+				printf("  %12c", '.');
+		}
+		printf("\n");
+	}
+}
+
+static void print_slab_result(struct perf_session *session)
 {
 	if (caller_flag)
-		__print_result(&root_caller_sorted, session, caller_lines, 1);
+		__print_slab_result(&root_caller_sorted, session, caller_lines, 1);
+	if (alloc_flag)
+		__print_slab_result(&root_alloc_sorted, session, alloc_lines, 0);
+	print_slab_summary();
+}
+
+static void print_page_result(struct perf_session *session)
+{
 	if (alloc_flag)
-		__print_result(&root_alloc_sorted, session, alloc_lines, 0);
-	print_summary();
+		__print_page_result(&page_alloc_sorted, session, alloc_lines);
+	print_page_summary();
+}
+
+static void print_result(struct perf_session *session)
+{
+	if (kmem_slab)
+		print_slab_result(session);
+	if (kmem_page)
+		print_page_result(session);
 }
 
 struct sort_dimension {
@@ -353,8 +704,8 @@ struct sort_dimension {
 static LIST_HEAD(caller_sort);
 static LIST_HEAD(alloc_sort);
 
-static void sort_insert(struct rb_root *root, struct alloc_stat *data,
-			struct list_head *sort_list)
+static void sort_slab_insert(struct rb_root *root, struct alloc_stat *data,
+			     struct list_head *sort_list)
 {
 	struct rb_node **new = &(root->rb_node);
 	struct rb_node *parent = NULL;
@@ -383,8 +734,8 @@ static void sort_insert(struct rb_root *root, struct alloc_stat *data,
 	rb_insert_color(&data->node, root);
 }
 
-static void __sort_result(struct rb_root *root, struct rb_root *root_sorted,
-			  struct list_head *sort_list)
+static void __sort_slab_result(struct rb_root *root, struct rb_root *root_sorted,
+			       struct list_head *sort_list)
 {
 	struct rb_node *node;
 	struct alloc_stat *data;
@@ -396,26 +747,79 @@ static void __sort_result(struct rb_root *root, struct rb_root *root_sorted,
 
 		rb_erase(node, root);
 		data = rb_entry(node, struct alloc_stat, node);
-		sort_insert(root_sorted, data, sort_list);
+		sort_slab_insert(root_sorted, data, sort_list);
+	}
+}
+
+static void sort_page_insert(struct rb_root *root, struct page_stat *data)
+{
+	struct rb_node **new = &root->rb_node;
+	struct rb_node *parent = NULL;
+
+	while (*new) {
+		struct page_stat *this;
+		int cmp = 0;
+
+		this = rb_entry(*new, struct page_stat, node);
+		parent = *new;
+
+		/* TODO: support more sort key */
+		cmp = data->alloc_bytes - this->alloc_bytes;
+
+		if (cmp > 0)
+			new = &parent->rb_left;
+		else
+			new = &parent->rb_right;
+	}
+
+	rb_link_node(&data->node, parent, new);
+	rb_insert_color(&data->node, root);
+}
+
+static void __sort_page_result(struct rb_root *root, struct rb_root *root_sorted)
+{
+	struct rb_node *node;
+	struct page_stat *data;
+
+	for (;;) {
+		node = rb_first(root);
+		if (!node)
+			break;
+
+		rb_erase(node, root);
+		data = rb_entry(node, struct page_stat, node);
+		sort_page_insert(root_sorted, data);
 	}
 }
 
 static void sort_result(void)
 {
-	__sort_result(&root_alloc_stat, &root_alloc_sorted, &alloc_sort);
-	__sort_result(&root_caller_stat, &root_caller_sorted, &caller_sort);
+	if (kmem_slab) {
+		__sort_slab_result(&root_alloc_stat, &root_alloc_sorted,
+				   &alloc_sort);
+		__sort_slab_result(&root_caller_stat, &root_caller_sorted,
+				   &caller_sort);
+	}
+	if (kmem_page) {
+		__sort_page_result(&page_alloc_tree, &page_alloc_sorted);
+	}
 }
 
 static int __cmd_kmem(struct perf_session *session)
 {
 	int err = -EINVAL;
+	struct perf_evsel *evsel;
 	const struct perf_evsel_str_handler kmem_tracepoints[] = {
+		/* slab allocator */
 		{ "kmem:kmalloc",		perf_evsel__process_alloc_event, },
     		{ "kmem:kmem_cache_alloc",	perf_evsel__process_alloc_event, },
 		{ "kmem:kmalloc_node",		perf_evsel__process_alloc_node_event, },
     		{ "kmem:kmem_cache_alloc_node", perf_evsel__process_alloc_node_event, },
 		{ "kmem:kfree",			perf_evsel__process_free_event, },
     		{ "kmem:kmem_cache_free",	perf_evsel__process_free_event, },
+		/* page allocator */
+		{ "kmem:mm_page_alloc",		perf_evsel__process_page_alloc_event, },
+		{ "kmem:mm_page_free",		perf_evsel__process_page_free_event, },
 	};
 
 	if (!perf_session__has_traces(session, "kmem record"))
@@ -426,10 +830,20 @@ static int __cmd_kmem(struct perf_session *session)
 		goto out;
 	}
 
+	evlist__for_each(session->evlist, evsel) {
+		if (!strcmp(perf_evsel__name(evsel), "kmem:mm_page_alloc") &&
+		    perf_evsel__field(evsel, "pfn")) {
+			use_pfn = true;
+			break;
+		}
+	}
+
 	setup_pager();
 	err = perf_session__process_events(session);
-	if (err != 0)
+	if (err != 0) {
+		pr_err("error during process events: %d\n", err);
 		goto out;
+	}
 	sort_result();
 	print_result(session);
 out:
@@ -612,6 +1026,22 @@ static int parse_alloc_opt(const struct option *opt __maybe_unused,
 	return 0;
 }
 
+static int parse_slab_opt(const struct option *opt __maybe_unused,
+			  const char *arg __maybe_unused,
+			  int unset __maybe_unused)
+{
+	kmem_slab = (kmem_page + 1);
+	return 0;
+}
+
+static int parse_page_opt(const struct option *opt __maybe_unused,
+			  const char *arg __maybe_unused,
+			  int unset __maybe_unused)
+{
+	kmem_page = (kmem_slab + 1);
+	return 0;
+}
+
 static int parse_line_opt(const struct option *opt __maybe_unused,
 			  const char *arg, int unset __maybe_unused)
 {
@@ -634,6 +1064,8 @@ static int __cmd_record(int argc, const char **argv)
 {
 	const char * const record_args[] = {
 	"record", "-a", "-R", "-c", "1",
+	};
+	const char * const slab_events[] = {
 	"-e", "kmem:kmalloc",
 	"-e", "kmem:kmalloc_node",
 	"-e", "kmem:kfree",
@@ -641,10 +1073,19 @@ static int __cmd_record(int argc, const char **argv)
 	"-e", "kmem:kmem_cache_alloc_node",
 	"-e", "kmem:kmem_cache_free",
 	};
+	const char * const page_events[] = {
+	"-e", "kmem:mm_page_alloc",
+	"-e", "kmem:mm_page_free",
+	};
 	unsigned int rec_argc, i, j;
 	const char **rec_argv;
 
 	rec_argc = ARRAY_SIZE(record_args) + argc - 1;
+	if (kmem_slab)
+		rec_argc += ARRAY_SIZE(slab_events);
+	if (kmem_page)
+		rec_argc += ARRAY_SIZE(page_events);
+
 	rec_argv = calloc(rec_argc + 1, sizeof(char *));
 
 	if (rec_argv == NULL)
@@ -653,6 +1094,15 @@ static int __cmd_record(int argc, const char **argv)
 	for (i = 0; i < ARRAY_SIZE(record_args); i++)
 		rec_argv[i] = strdup(record_args[i]);
 
+	if (kmem_slab) {
+		for (j = 0; j < ARRAY_SIZE(slab_events); j++, i++)
+			rec_argv[i] = strdup(slab_events[j]);
+	}
+	if (kmem_page) {
+		for (j = 0; j < ARRAY_SIZE(page_events); j++, i++)
+			rec_argv[i] = strdup(page_events[j]);
+	}
+
 	for (j = 1; j < (unsigned int)argc; j++, i++)
 		rec_argv[i] = argv[j];
 
@@ -679,6 +1129,10 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 	OPT_CALLBACK('l', "line", NULL, "num", "show n lines", parse_line_opt),
 	OPT_BOOLEAN(0, "raw-ip", &raw_ip, "show raw ip instead of symbol"),
 	OPT_BOOLEAN('f', "force", &file.force, "don't complain, do it"),
+	OPT_CALLBACK_NOOPT(0, "slab", NULL, NULL, "Analyze slab allocator",
+			   parse_slab_opt),
+	OPT_CALLBACK_NOOPT(0, "page", NULL, NULL, "Analyze page allocator",
+			   parse_page_opt),
 	OPT_END()
 	};
 	const char *const kmem_subcommands[] = { "record", "stat", NULL };
@@ -695,6 +1149,9 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 	if (!argc)
 		usage_with_options(kmem_usage, kmem_options);
 
+	if (kmem_slab == 0 && kmem_page == 0)
+		kmem_slab = 1;  /* for backward compatibility */
+
 	if (!strncmp(argv[0], "rec", 3)) {
 		symbol__init(NULL);
 		return __cmd_record(argc, argv);
@@ -706,6 +1163,17 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 	if (session == NULL)
 		return -1;
 
+	if (kmem_page) {
+		struct perf_evsel *evsel = perf_evlist__first(session->evlist);
+
+		if (evsel == NULL || evsel->tp_format == NULL) {
+			pr_err("invalid event found.. aborting\n");
+			return -1;
+		}
+
+		kmem_page_size = pevent_get_page_size(evsel->tp_format->pevent);
+	}
+
 	symbol__init(&session->header.env);
 
 	if (!strcmp(argv[0], "stat")) {

commit 28939e1a1f6d198239d86b1d77fa9fd55773189a
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Mon Apr 6 14:36:08 2015 +0900

    perf kmem: Respect -i option
    
    Currently the perf kmem does not respect -i option.
    
    Initializing the file.path properly after options get parsed.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/1428298576-9785-2-git-send-email-namhyung@kernel.org
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index ac303ef9f2f0..4ebf65c79434 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -663,7 +663,6 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 {
 	const char * const default_sort_order = "frag,hit,bytes";
 	struct perf_data_file file = {
-		.path = input_name,
 		.mode = PERF_DATA_MODE_READ,
 	};
 	const struct option kmem_options[] = {
@@ -701,6 +700,8 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 		return __cmd_record(argc, argv);
 	}
 
+	file.path = input_name;
+
 	session = perf_session__new(&file, false, &perf_kmem);
 	if (session == NULL)
 		return -1;

commit d1eeb77c1811fd178442ccb8f58004a19ec40dd3
Author: Yunlong Song <yunlong.song@huawei.com>
Date:   Thu Apr 2 21:47:12 2015 +0800

    perf kmem: Support using -f to override perf.data file ownership
    
    Enable perf kmem to use perf.data when it is not owned by current user
    or root.
    
    Example:
    
     # perf kmem record ls
     # chown Yunlong.Song:Yunlong.Song perf.data
     # ls -al perf.data
     -rw------- 1 Yunlong.Song Yunlong.Song 5315665 Apr  2 10:54 perf.data
     # id
     uid=0(root) gid=0(root) groups=0(root),64(pkcs11)
    
    Before this patch:
    
     # perf kmem stat
     File perf.data not owned by current user or root (use -f to override)
     # perf kmem stat -f
       Error: unknown switch `f'
    
      usage: perf kmem [<options>] {record|stat}
    
         -i, --input <file>    input file name
         -v, --verbose         be more verbose (show symbol address, etc)
             --caller          show per-callsite statistics
             --alloc           show per-allocation statistics
         -s, --sort <key[,key2...]>
                               sort by keys: ptr, call_site, bytes, hit,
                               pingpong, frag
         -l, --line <num>      show n lines
             --raw-ip          show raw ip instead of symbol
    
    As shown above, the -f option does not work at all.
    
    After this patch:
    
     # perf kmem stat
     File perf.data not owned by current user or root (use -f to override)
     # perf kmem stat -f
     SUMMARY
     =======
     Total bytes requested: 437599
     Total bytes allocated: 615472
     Total bytes wasted on internal fragmentation: 177873
     Internal fragmentation: 28.900259%
     Cross CPU allocations: 6/1192
    
    As shown above, the -f option really works now.
    
    Signed-off-by: Yunlong Song <yunlong.song@huawei.com>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lkml.kernel.org/r/1427982439-27388-4-git-send-email-yunlong.song@huawei.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 64d3623d45a0..ac303ef9f2f0 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -662,6 +662,10 @@ static int __cmd_record(int argc, const char **argv)
 int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 {
 	const char * const default_sort_order = "frag,hit,bytes";
+	struct perf_data_file file = {
+		.path = input_name,
+		.mode = PERF_DATA_MODE_READ,
+	};
 	const struct option kmem_options[] = {
 	OPT_STRING('i', "input", &input_name, "file", "input file name"),
 	OPT_INCR('v', "verbose", &verbose,
@@ -675,6 +679,7 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 		     parse_sort_opt),
 	OPT_CALLBACK('l', "line", NULL, "num", "show n lines", parse_line_opt),
 	OPT_BOOLEAN(0, "raw-ip", &raw_ip, "show raw ip instead of symbol"),
+	OPT_BOOLEAN('f', "force", &file.force, "don't complain, do it"),
 	OPT_END()
 	};
 	const char *const kmem_subcommands[] = { "record", "stat", NULL };
@@ -683,10 +688,6 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 		NULL
 	};
 	struct perf_session *session;
-	struct perf_data_file file = {
-		.path = input_name,
-		.mode = PERF_DATA_MODE_READ,
-	};
 	int ret = -1;
 
 	argc = parse_options_subcommand(argc, argv, kmem_options,

commit 77cfe388767572586b7d4fd533c38f902d020f17
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Mon Mar 23 15:30:40 2015 +0900

    perf kmem: Print big numbers using thousands' group
    
    Like perf stat, this makes easy to read the numbers on stat like below:
    
      # perf kmem stat
    
      SUMMARY
      =======
      Total bytes requested: 9,770,900
      Total bytes allocated: 9,782,712
      Total bytes wasted on internal fragmentation: 11,812
      Internal fragmentation: 0.120744%
      Cross CPU allocations: 74/152,819
    
    Suggested-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1427092244-22764-2-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 8c85aeb3327a..64d3623d45a0 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -20,6 +20,7 @@
 
 #include <linux/rbtree.h>
 #include <linux/string.h>
+#include <locale.h>
 
 struct alloc_stat;
 typedef int (*sort_fn_t)(struct alloc_stat *, struct alloc_stat *);
@@ -325,13 +326,13 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 static void print_summary(void)
 {
 	printf("\nSUMMARY\n=======\n");
-	printf("Total bytes requested: %lu\n", total_requested);
-	printf("Total bytes allocated: %lu\n", total_allocated);
-	printf("Total bytes wasted on internal fragmentation: %lu\n",
+	printf("Total bytes requested: %'lu\n", total_requested);
+	printf("Total bytes allocated: %'lu\n", total_allocated);
+	printf("Total bytes wasted on internal fragmentation: %'lu\n",
 	       total_allocated - total_requested);
 	printf("Internal fragmentation: %f%%\n",
 	       fragmentation(total_requested, total_allocated));
-	printf("Cross CPU allocations: %lu/%lu\n", nr_cross_allocs, nr_allocs);
+	printf("Cross CPU allocations: %'lu/%'lu\n", nr_cross_allocs, nr_allocs);
 }
 
 static void print_result(struct perf_session *session)
@@ -706,6 +707,8 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 	symbol__init(&session->header.env);
 
 	if (!strcmp(argv[0], "stat")) {
+		setlocale(LC_ALL, "");
+
 		if (cpu__setup_cpunode_map())
 			goto out_delete;
 

commit 65f46e0214c64198a0266c37181a7776e16b7e53
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Thu Mar 12 16:32:48 2015 +0900

    perf kmem: Fix alignment of slab result table
    
    Its table was a bit misaligned.  Fix it.
    
    Before:
    
      # perf kmem stat --caller -l 10
      ------------------------------------------------------------------------------------------------------
       Callsite                           | Total_alloc/Per | Total_req/Per   | Hit      | Ping-pong | Frag
      ------------------------------------------------------------------------------------------------------
       radeon_cs_parser_init.part.1+11a   |      2080/260   |      1504/188   |        8 |        0 | 27.692%
       radeon_cs_parser_init.part.1+e1    |       384/96    |       288/72    |        4 |        0 | 25.000%
       radeon_cs_parser_init.part.1+93    |       128/32    |        96/24    |        4 |        0 | 25.000%
       load_elf_binary+a39                |       512/512   |       392/392   |        1 |        0 | 23.438%
       __alloc_skb+89                     |      6144/877   |      4800/685   |        7 |        6 | 21.875%
       radeon_fence_emit+5c               |      1152/192   |       912/152   |        6 |        0 | 20.833%
       radeon_cs_parser_relocs+ad         |      8192/2048  |      6624/1656  |        4 |        0 | 19.141%
       radeon_sa_bo_new+78                |      1280/64    |      1120/56    |       20 |        0 | 12.500%
       load_elf_binary+2c4                |        32/32    |        28/28    |        1 |        0 | 12.500%
       anon_vma_prepare+101               |       576/72    |       512/64    |        8 |        0 | 11.111%
       ...                                | ...             | ...             | ...    | ...      | ...
      ------------------------------------------------------------------------------------------------------
    
    After:
    
      ---------------------------------------------------------------------------------------------------------
       Callsite                           | Total_alloc/Per | Total_req/Per   | Hit      | Ping-pong | Frag
      ---------------------------------------------------------------------------------------------------------
       radeon_cs_parser_init.part.1+11a   |      2080/260   |      1504/188   |        8 |         0 | 27.692%
       radeon_cs_parser_init.part.1+e1    |       384/96    |       288/72    |        4 |         0 | 25.000%
       radeon_cs_parser_init.part.1+93    |       128/32    |        96/24    |        4 |         0 | 25.000%
       load_elf_binary+a39                |       512/512   |       392/392   |        1 |         0 | 23.438%
       __alloc_skb+89                     |      6144/877   |      4800/685   |        7 |         6 | 21.875%
       radeon_fence_emit+5c               |      1152/192   |       912/152   |        6 |         0 | 20.833%
       radeon_cs_parser_relocs+ad         |      8192/2048  |      6624/1656  |        4 |         0 | 19.141%
       radeon_sa_bo_new+78                |      1280/64    |      1120/56    |       20 |         0 | 12.500%
       load_elf_binary+2c4                |        32/32    |        28/28    |        1 |         0 | 12.500%
       anon_vma_prepare+101               |       576/72    |       512/64    |        8 |         0 | 11.111%
       ...                                | ...             | ...             | ...      | ...       | ...
      ---------------------------------------------------------------------------------------------------------
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1426145571-3065-4-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 02b76976b288..8c85aeb3327a 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -275,10 +275,10 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 	struct rb_node *next;
 	struct machine *machine = &session->machines.host;
 
-	printf("%.102s\n", graph_dotted_line);
+	printf("%.105s\n", graph_dotted_line);
 	printf(" %-34s |",  is_caller ? "Callsite": "Alloc Ptr");
 	printf(" Total_alloc/Per | Total_req/Per   | Hit      | Ping-pong | Frag\n");
-	printf("%.102s\n", graph_dotted_line);
+	printf("%.105s\n", graph_dotted_line);
 
 	next = rb_first(root);
 
@@ -304,7 +304,7 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 			snprintf(buf, sizeof(buf), "%#" PRIx64 "", addr);
 		printf(" %-34s |", buf);
 
-		printf(" %9llu/%-5lu | %9llu/%-5lu | %8lu | %8lu | %6.3f%%\n",
+		printf(" %9llu/%-5lu | %9llu/%-5lu | %8lu | %9lu | %6.3f%%\n",
 		       (unsigned long long)data->bytes_alloc,
 		       (unsigned long)data->bytes_alloc / data->hit,
 		       (unsigned long long)data->bytes_req,
@@ -317,9 +317,9 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 	}
 
 	if (n_lines == -1)
-		printf(" ...                                | ...             | ...             | ...    | ...      | ...   \n");
+		printf(" ...                                | ...             | ...             | ...      | ...       | ...   \n");
 
-	printf("%.102s\n", graph_dotted_line);
+	printf("%.105s\n", graph_dotted_line);
 }
 
 static void print_summary(void)

commit bd72a33ebae8b4d37e3d2a3f0f3f3333ac9654dd
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Thu Mar 12 16:32:47 2015 +0900

    perf kmem: Allow -v option
    
    Current perf kmem fails when -v option is used.  As it's very useful for
    debugging, let's allow it.
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1426145571-3065-3-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 1e69ea57a1cc..02b76976b288 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -663,6 +663,8 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 	const char * const default_sort_order = "frag,hit,bytes";
 	const struct option kmem_options[] = {
 	OPT_STRING('i', "input", &input_name, "file", "input file name"),
+	OPT_INCR('v', "verbose", &verbose,
+		    "be more verbose (show symbol address, etc)"),
 	OPT_CALLBACK_NOOPT(0, "caller", NULL, NULL,
 			   "show per-callsite statistics", parse_caller_opt),
 	OPT_CALLBACK_NOOPT(0, "alloc", NULL, NULL,

commit 405f87557da35a03ba4663eca971ffac58b0a818
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Thu Mar 12 16:32:46 2015 +0900

    perf kmem: Fix segfault when invalid sort key is given
    
    When it tries to free 'str', it was already updated by strsep() - so it
    needs to save the original pointer.
    
      # perf kmem stat -s xxx,hit
        Error: Unknown --sort key: 'xxx'
      *** Error in `perf': free(): invalid pointer: 0x0000000000e9e7b6 ***
      ======= Backtrace: =========
      /usr/lib/libc.so.6(+0x7198e)[0x7fc7e6e0d98e]
      /usr/lib/libc.so.6(+0x76dee)[0x7fc7e6e12dee]
      /usr/lib/libc.so.6(+0x775cb)[0x7fc7e6e135cb]
      ./perf[0x44a1b5]
      ./perf[0x490b20]
      ./perf(parse_options_step+0x173)[0x491773]
      ./perf(parse_options_subcommand+0xa7)[0x491fb7]
      ./perf(cmd_kmem+0x2bc)[0x44ae4c]
      ./perf[0x47aa13]
      ./perf(main+0x60a)[0x427a9a]
      /usr/lib/libc.so.6(__libc_start_main+0xf0)[0x7fc7e6dbc800]
      ./perf(_start+0x29)[0x427bb9]
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1426145571-3065-2-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 62f165a9fa40..1e69ea57a1cc 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -559,6 +559,7 @@ static int setup_sorting(struct list_head *sort_list, const char *arg)
 {
 	char *tok;
 	char *str = strdup(arg);
+	char *pos = str;
 
 	if (!str) {
 		pr_err("%s: strdup failed\n", __func__);
@@ -566,7 +567,7 @@ static int setup_sorting(struct list_head *sort_list, const char *arg)
 	}
 
 	while (true) {
-		tok = strsep(&str, ",");
+		tok = strsep(&pos, ",");
 		if (!tok)
 			break;
 		if (sort_dimension__add(tok, sort_list) < 0) {

commit b7b61cbebd789a3dbca522e3fdb727fe5c95593f
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Mar 3 11:58:45 2015 -0300

    perf ordered_events: Shorten function signatures
    
    By keeping pointers to machines, evlist and tool in ordered_events.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-0c6huyaf59mqtm2ek9pmposl@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index f295141025bc..62f165a9fa40 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -426,7 +426,7 @@ static int __cmd_kmem(struct perf_session *session)
 	}
 
 	setup_pager();
-	err = perf_session__process_events(session, &perf_kmem);
+	err = perf_session__process_events(session);
 	if (err != 0)
 		goto out;
 	sort_result();

commit 52e0283497ccb1e675d56c9499cc2cc5ec271094
Author: Taeung Song <treeze.taeung@gmail.com>
Date:   Wed Sep 24 10:33:37 2014 +0900

    perf tools: Modify error code for when perf_session__new() fails
    
    Because perf_session__new() can fail for more reasons than just ENOMEM,
    modify error code(ENOMEM or EINVAL) to -1.
    
    Signed-off-by: Taeung Song <treeze.taeung@gmail.com>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Acked-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: http://lkml.kernel.org/r/1411522417-9917-1-git-send-email-treeze.taeung@gmail.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 23762187a219..f295141025bc 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -698,7 +698,7 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 
 	session = perf_session__new(&file, false, &perf_kmem);
 	if (session == NULL)
-		return -ENOMEM;
+		return -1;
 
 	symbol__init(&session->header.env);
 

commit 0a7e6d1b6844bec2d6817615a693c7fce447b80d
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Tue Aug 12 15:40:45 2014 +0900

    perf tools: Check recorded kernel version when finding vmlinux
    
    Currently vmlinux_path__init() only tries to find vmlinux file from
    current directory, /boot and some canonical directories with version
    number of the running kernel.  This can be a problem when reporting old
    data recorded on a kernel version not running currently.
    
    We can use --symfs option for this but it's annoying for user to do it
    always.  As we already have the info in the perf.data file, it can be
    changed to use it for the search automatically.
    
    Before:
    
      $ perf report
      ...
      # Samples: 4K of event 'cpu-clock'
      # Event count (approx.): 1067250000
      #
      # Overhead  Command     Shared Object      Symbol
      # ........  ..........  .................  ..............................
          71.87%     swapper  [kernel.kallsyms]  [k] recover_probed_instruction
    
    After:
    
      # Overhead  Command     Shared Object      Symbol
      # ........  ..........  .................  ....................
          71.87%     swapper  [kernel.kallsyms]  [k] native_safe_halt
    
    This requires to change signature of symbol__init() to receive struct
    perf_session_env *.
    
    Reported-by: Minchan Kim <minchan@kernel.org>
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1407825645-24586-14-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 349d9b46098e..23762187a219 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -692,7 +692,7 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 		usage_with_options(kmem_usage, kmem_options);
 
 	if (!strncmp(argv[0], "rec", 3)) {
-		symbol__init();
+		symbol__init(NULL);
 		return __cmd_record(argc, argv);
 	}
 
@@ -700,7 +700,7 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 	if (session == NULL)
 		return -ENOMEM;
 
-	symbol__init();
+	symbol__init(&session->header.env);
 
 	if (!strcmp(argv[0], "stat")) {
 		if (cpu__setup_cpunode_map())

commit 2b2b2c68c64fb9db392940b42355944064f2a4ca
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Tue Aug 12 15:40:38 2014 +0900

    perf kmem: Move session handling out of __cmd_kmem()
    
    This is a preparation of fixing dso__load_kernel_sym().  It needs a
    session info before calling symbol__init().
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1407825645-24586-7-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 84b82397a28e..349d9b46098e 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -405,10 +405,9 @@ static void sort_result(void)
 	__sort_result(&root_caller_stat, &root_caller_sorted, &caller_sort);
 }
 
-static int __cmd_kmem(void)
+static int __cmd_kmem(struct perf_session *session)
 {
 	int err = -EINVAL;
-	struct perf_session *session;
 	const struct perf_evsel_str_handler kmem_tracepoints[] = {
 		{ "kmem:kmalloc",		perf_evsel__process_alloc_event, },
     		{ "kmem:kmem_cache_alloc",	perf_evsel__process_alloc_event, },
@@ -417,31 +416,22 @@ static int __cmd_kmem(void)
 		{ "kmem:kfree",			perf_evsel__process_free_event, },
     		{ "kmem:kmem_cache_free",	perf_evsel__process_free_event, },
 	};
-	struct perf_data_file file = {
-		.path = input_name,
-		.mode = PERF_DATA_MODE_READ,
-	};
-
-	session = perf_session__new(&file, false, &perf_kmem);
-	if (session == NULL)
-		return -ENOMEM;
 
 	if (!perf_session__has_traces(session, "kmem record"))
-		goto out_delete;
+		goto out;
 
 	if (perf_session__set_tracepoints_handlers(session, kmem_tracepoints)) {
 		pr_err("Initializing perf session tracepoint handlers failed\n");
-		return -1;
+		goto out;
 	}
 
 	setup_pager();
 	err = perf_session__process_events(session, &perf_kmem);
 	if (err != 0)
-		goto out_delete;
+		goto out;
 	sort_result();
 	print_result(session);
-out_delete:
-	perf_session__delete(session);
+out:
 	return err;
 }
 
@@ -688,29 +678,46 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 		NULL,
 		NULL
 	};
+	struct perf_session *session;
+	struct perf_data_file file = {
+		.path = input_name,
+		.mode = PERF_DATA_MODE_READ,
+	};
+	int ret = -1;
+
 	argc = parse_options_subcommand(argc, argv, kmem_options,
 					kmem_subcommands, kmem_usage, 0);
 
 	if (!argc)
 		usage_with_options(kmem_usage, kmem_options);
 
-	symbol__init();
-
 	if (!strncmp(argv[0], "rec", 3)) {
+		symbol__init();
 		return __cmd_record(argc, argv);
-	} else if (!strcmp(argv[0], "stat")) {
+	}
+
+	session = perf_session__new(&file, false, &perf_kmem);
+	if (session == NULL)
+		return -ENOMEM;
+
+	symbol__init();
+
+	if (!strcmp(argv[0], "stat")) {
 		if (cpu__setup_cpunode_map())
-			return -1;
+			goto out_delete;
 
 		if (list_empty(&caller_sort))
 			setup_sorting(&caller_sort, default_sort_order);
 		if (list_empty(&alloc_sort))
 			setup_sorting(&alloc_sort, default_sort_order);
 
-		return __cmd_kmem();
+		ret = __cmd_kmem(session);
 	} else
 		usage_with_options(kmem_usage, kmem_options);
 
-	return 0;
+out_delete:
+	perf_session__delete(session);
+
+	return ret;
 }
 

commit 64c40908938953d7afa90e9363327875286349e5
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Fri Aug 1 14:59:31 2014 +0900

    perf kmem: Do not ignore mmap events
    
    The perf kmem command didn't process mmap events for some unknown reason
    and it instead gets symbol info from a running kernel.  This is
    problematic if perf kmem record was run on a different kernel.
    
    This patch adds the mmap event handlers and reverts the commit
    e727ca73f85d ("perf kmem: Resolve kernel symbols again").
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1406872771-23933-1-git-send-email-namhyung@kernel.org
    [ Fixed up merge conflict with Jiri's ordered_events rename patch set ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index b5721116713b..84b82397a28e 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -256,6 +256,8 @@ static int process_sample_event(struct perf_tool *tool __maybe_unused,
 static struct perf_tool perf_kmem = {
 	.sample		 = process_sample_event,
 	.comm		 = perf_event__process_comm,
+	.mmap		 = perf_event__process_mmap,
+	.mmap2		 = perf_event__process_mmap2,
 	.ordered_events	 = true,
 };
 
@@ -424,9 +426,6 @@ static int __cmd_kmem(void)
 	if (session == NULL)
 		return -ENOMEM;
 
-	if (perf_session__create_kernel_maps(session) < 0)
-		goto out_delete;
-
 	if (!perf_session__has_traces(session, "kmem record"))
 		goto out_delete;
 

commit 0a8cb85c200c4082ed7e57efd90dd9d18c8d40b6
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Sun Jul 6 14:18:21 2014 +0200

    perf tools: Rename ordered_samples bool to ordered_events
    
    The time ordering is generic for all kinds of events, so using generic
    name 'ordered_events' for ordered_samples bool in perf_tool struct.
    
    No functional change was intended.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Acked-by: David Ahern <dsahern@gmail.com>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jean Pihet <jean.pihet@linaro.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/n/tip-07mrqzcuhsks9wfmxrzsvemz@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index bef3376bfaf3..b5721116713b 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -256,7 +256,7 @@ static int process_sample_event(struct perf_tool *tool __maybe_unused,
 static struct perf_tool perf_kmem = {
 	.sample		 = process_sample_event,
 	.comm		 = perf_event__process_comm,
-	.ordered_samples = true,
+	.ordered_events	 = true,
 };
 
 static double fragmentation(unsigned long n_req, unsigned long n_alloc)

commit 13ce34df11833482cd698331fdbb3f8ced06340d
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Mon May 12 09:56:42 2014 +0900

    perf tools: Use tid for finding thread
    
    I believe that passing pid (instead of tid) as the 3rd arg of the
    machine__find*_thread() was to find a main thread so that it can
    search proper map group for symbols.  However with the map sharing
    patch applied, it now can do it in any thread.
    
    It fixes a bug when each thread has different name, it only reports a
    main thread for samples in other threads.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Acked-by: David Ahern <dsahern@gmail.com>
    Acked-by: Stephane Eranian <eranian@google.com>
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Link: http://lkml.kernel.org/r/1399856202-26221-1-git-send-email-namhyung@kernel.org
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index f91fa4376f4b..bef3376bfaf3 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -235,7 +235,7 @@ static int process_sample_event(struct perf_tool *tool __maybe_unused,
 				struct machine *machine)
 {
 	struct thread *thread = machine__findnew_thread(machine, sample->pid,
-							sample->pid);
+							sample->tid);
 
 	if (thread == NULL) {
 		pr_debug("problem processing %d event, skipping it.\n",

commit 4b6279579c84cca7f162cfbcb98f66418f3062f3
Author: Don Zickus <dzickus@redhat.com>
Date:   Mon Apr 7 14:55:23 2014 -0400

    perf kmem: Utilize the new generic cpunode_map
    
    Use the previous patch implementation of cpunode_map for builtin-kmem.c
    Should not be any functional difference.
    
    Signed-off-by: Don Zickus <dzickus@redhat.com>
    Reviewed-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Link: http://lkml.kernel.org/r/1396896924-129847-4-git-send-email-dzickus@redhat.com
    Signed-off-by: Jiri Olsa <jolsa@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index bd91de07d2a9..f91fa4376f4b 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -14,6 +14,7 @@
 #include "util/parse-options.h"
 #include "util/trace-event.h"
 #include "util/data.h"
+#include "util/cpumap.h"
 
 #include "util/debug.h"
 
@@ -31,9 +32,6 @@ static int			caller_lines = -1;
 
 static bool			raw_ip;
 
-static int			*cpunode_map;
-static int			max_cpu_num;
-
 struct alloc_stat {
 	u64	call_site;
 	u64	ptr;
@@ -55,76 +53,6 @@ static struct rb_root root_caller_sorted;
 static unsigned long total_requested, total_allocated;
 static unsigned long nr_allocs, nr_cross_allocs;
 
-#define PATH_SYS_NODE	"/sys/devices/system/node"
-
-static int init_cpunode_map(void)
-{
-	FILE *fp;
-	int i, err = -1;
-
-	fp = fopen("/sys/devices/system/cpu/kernel_max", "r");
-	if (!fp) {
-		max_cpu_num = 4096;
-		return 0;
-	}
-
-	if (fscanf(fp, "%d", &max_cpu_num) < 1) {
-		pr_err("Failed to read 'kernel_max' from sysfs");
-		goto out_close;
-	}
-
-	max_cpu_num++;
-
-	cpunode_map = calloc(max_cpu_num, sizeof(int));
-	if (!cpunode_map) {
-		pr_err("%s: calloc failed\n", __func__);
-		goto out_close;
-	}
-
-	for (i = 0; i < max_cpu_num; i++)
-		cpunode_map[i] = -1;
-
-	err = 0;
-out_close:
-	fclose(fp);
-	return err;
-}
-
-static int setup_cpunode_map(void)
-{
-	struct dirent *dent1, *dent2;
-	DIR *dir1, *dir2;
-	unsigned int cpu, mem;
-	char buf[PATH_MAX];
-
-	if (init_cpunode_map())
-		return -1;
-
-	dir1 = opendir(PATH_SYS_NODE);
-	if (!dir1)
-		return 0;
-
-	while ((dent1 = readdir(dir1)) != NULL) {
-		if (dent1->d_type != DT_DIR ||
-		    sscanf(dent1->d_name, "node%u", &mem) < 1)
-			continue;
-
-		snprintf(buf, PATH_MAX, "%s/%s", PATH_SYS_NODE, dent1->d_name);
-		dir2 = opendir(buf);
-		if (!dir2)
-			continue;
-		while ((dent2 = readdir(dir2)) != NULL) {
-			if (dent2->d_type != DT_LNK ||
-			    sscanf(dent2->d_name, "cpu%u", &cpu) < 1)
-				continue;
-			cpunode_map[cpu] = mem;
-		}
-		closedir(dir2);
-	}
-	closedir(dir1);
-	return 0;
-}
-
 static int insert_alloc_stat(unsigned long call_site, unsigned long ptr,
 			     int bytes_req, int bytes_alloc, int cpu)
 {
@@ -235,7 +163,7 @@ static int perf_evsel__process_alloc_node_event(struct perf_evsel *evsel,
 	int ret = perf_evsel__process_alloc_event(evsel, sample);
 
 	if (!ret) {
-		int node1 = cpunode_map[sample->cpu],
+		int node1 = cpu__get_node(sample->cpu),
 		    node2 = perf_evsel__intval(evsel, sample, "node");
 
 		if (node1 != node2)
@@ -772,7 +700,7 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 	if (!strncmp(argv[0], "rec", 3)) {
 		return __cmd_record(argc, argv);
 	} else if (!strcmp(argv[0], "stat")) {
-		if (setup_cpunode_map())
+		if (cpu__setup_cpunode_map())
 			return -1;
 
 		if (list_empty(&caller_sort))

commit 3bca23543b910a84d3c58a819663e0a4fad72bb6
Author: Ramkumar Ramachandra <artagnon@gmail.com>
Date:   Fri Mar 14 23:17:51 2014 -0400

    perf kmem: Introduce --list-cmds for use by scripts
    
    Signed-off-by: Ramkumar Ramachandra <artagnon@gmail.com>
    Acked-by: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Link: http://lkml.kernel.org/r/1394853474-31019-2-git-send-email-artagnon@gmail.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: Jiri Olsa <jolsa@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 929462aa4943..bd91de07d2a9 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -756,11 +756,13 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 	OPT_BOOLEAN(0, "raw-ip", &raw_ip, "show raw ip instead of symbol"),
 	OPT_END()
 	};
-	const char * const kmem_usage[] = {
-		"perf kmem [<options>] {record|stat}",
+	const char *const kmem_subcommands[] = { "record", "stat", NULL };
+	const char *kmem_usage[] = {
+		NULL,
 		NULL
 	};
-	argc = parse_options(argc, argv, kmem_options, kmem_usage, 0);
+	argc = parse_options_subcommand(argc, argv, kmem_options,
+					kmem_subcommands, kmem_usage, 0);
 
 	if (!argc)
 		usage_with_options(kmem_usage, kmem_options);

commit 744a971940520cf0818e1fe882b64892c528e6de
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Nov 6 10:17:38 2013 -0300

    perf evsel: Ditch evsel->handler.data field
    
    Not needed since this cset:
    
      fcf65bf149af: perf evsel: Cache associated event_format
    
    So lets trim this struct a bit.
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-j8setslokt0goiwxq9dogzqm@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index a28970f7ddfb..929462aa4943 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -317,8 +317,8 @@ static int process_sample_event(struct perf_tool *tool __maybe_unused,
 
 	dump_printf(" ... thread: %s:%d\n", thread__comm_str(thread), thread->tid);
 
-	if (evsel->handler.func != NULL) {
-		tracepoint_handler f = evsel->handler.func;
+	if (evsel->handler != NULL) {
+		tracepoint_handler f = evsel->handler;
 		return f(evsel, sample);
 	}
 

commit b9c5143a012a543c4ee872498d6dbae5c10beb2e
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Wed Sep 11 14:46:56 2013 +0200

    perf tools: Use an accessor to read thread comm
    
    As the thread comm is going to be implemented by way of a more
    complicated data structure than just a pointer to a string from the
    thread struct, convert the readers of comm to use an accessor instead of
    accessing it directly.
    
    The accessor will be later overriden to support an enhanced comm
    implementation.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Tested-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-wr683zwy94hmj4ibogmnv9ce@git.kernel.org
    [ Rename thread__comm_curr() to thread__comm_str() ]
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    [ Fixed up some minor const pointer issues ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 1126382659a9..a28970f7ddfb 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -315,7 +315,7 @@ static int process_sample_event(struct perf_tool *tool __maybe_unused,
 		return -1;
 	}
 
-	dump_printf(" ... thread: %s:%d\n", thread->comm, thread->tid);
+	dump_printf(" ... thread: %s:%d\n", thread__comm_str(thread), thread->tid);
 
 	if (evsel->handler.func != NULL) {
 		tracepoint_handler f = evsel->handler.func;

commit f5fc14124c5cefdd052a2b2a6a3f0ed531540113
Author: Jiri Olsa <jolsa@redhat.com>
Date:   Tue Oct 15 16:27:32 2013 +0200

    perf tools: Add data object to handle perf data file
    
    This patch is adding 'struct perf_data_file' object as a placeholder for
    all attributes regarding perf.data file handling. Changing
    perf_session__new to take it as an argument.
    
    The rest of the functionality will be added later to keep this change
    simple enough, because all the places using perf_session are changed
    now.
    
    Signed-off-by: Jiri Olsa <jolsa@redhat.com>
    Acked-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1381847254-28809-2-git-send-email-jolsa@redhat.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 9b5f077fee5b..1126382659a9 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -13,6 +13,7 @@
 
 #include "util/parse-options.h"
 #include "util/trace-event.h"
+#include "util/data.h"
 
 #include "util/debug.h"
 
@@ -486,8 +487,12 @@ static int __cmd_kmem(void)
 		{ "kmem:kfree",			perf_evsel__process_free_event, },
     		{ "kmem:kmem_cache_free",	perf_evsel__process_free_event, },
 	};
+	struct perf_data_file file = {
+		.path = input_name,
+		.mode = PERF_DATA_MODE_READ,
+	};
 
-	session = perf_session__new(input_name, O_RDONLY, 0, false, &perf_kmem);
+	session = perf_session__new(&file, false, &perf_kmem);
 	if (session == NULL)
 		return -ENOMEM;
 

commit 4921e320244e099bdf237fd10428594ce5f5b87d
Author: Jiri Olsa <jolsa@redhat.com>
Date:   Thu Sep 12 18:39:36 2013 +0200

    perf kmem: Make it work again on non NUMA machines
    
    The commit '2814eb0 perf kmem: Remove die() calls' disabled 'perf kmem'
    command for machines without numa support. It made the command fail if
    '/sys/devices/system/node' dir wasn't found.
    
    Skipping the numa based initialization in case the directory is not
    found and continue execution.
    
    Signed-off-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1379003976-5839-5-git-send-email-jolsa@redhat.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index c2dff9cb1f2c..9b5f077fee5b 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -101,7 +101,7 @@ static int setup_cpunode_map(void)
 
 	dir1 = opendir(PATH_SYS_NODE);
 	if (!dir1)
-		return -1;
+		return 0;
 
 	while ((dent1 = readdir(dir1)) != NULL) {
 		if (dent1->d_type != DT_DIR ||

commit ef89325f773bc9f2f4e6019bd7f3d968ba85df9a
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Tue Aug 27 11:23:06 2013 +0300

    perf tools: Remove references to struct ip_event
    
    The ip_event struct assumes fixed positions for ip, pid and tid.  That
    is no longer true with the addition of PERF_SAMPLE_IDENTIFIER.  The
    information is anyway in struct sample, so use that instead.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Acked-by: Namhyung Kim <namhyung@kernel.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1377591794-30553-5-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index c32477837cb0..c2dff9cb1f2c 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -305,8 +305,8 @@ static int process_sample_event(struct perf_tool *tool __maybe_unused,
 				struct perf_evsel *evsel,
 				struct machine *machine)
 {
-	struct thread *thread = machine__findnew_thread(machine, event->ip.pid,
-							event->ip.pid);
+	struct thread *thread = machine__findnew_thread(machine, sample->pid,
+							sample->pid);
 
 	if (thread == NULL) {
 		pr_debug("problem processing %d event, skipping it.\n",

commit 314add6b1f045b59ca39683bd0cbc5310cd203f2
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Tue Aug 27 11:23:03 2013 +0300

    perf tools: change machine__findnew_thread() to set thread pid
    
    Add a new parameter for 'pid' to machine__findnew_thread().
    Change callers to pass 'pid' when it is known.
    
    Note that callers sometimes want to find the main thread
    which has the memory maps.  The main thread has tid == pid
    so the usage in that case is:
    
            machine__findnew_thread(machine, pid, pid)
    
    whereas the usage to find the specific thread is:
    
            machine__findnew_thread(machine, pid, tid)
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Acked-by: David Ahern <dsahern@gmail.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1377591794-30553-2-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index b49f5c58e152..c32477837cb0 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -305,7 +305,8 @@ static int process_sample_event(struct perf_tool *tool __maybe_unused,
 				struct perf_evsel *evsel,
 				struct machine *machine)
 {
-	struct thread *thread = machine__findnew_thread(machine, event->ip.pid);
+	struct thread *thread = machine__findnew_thread(machine, event->ip.pid,
+							event->ip.pid);
 
 	if (thread == NULL) {
 		pr_debug("problem processing %d event, skipping it.\n",

commit 380512345e13c3af64e59627f1b993c4faa94a84
Author: Adrian Hunter <adrian.hunter@intel.com>
Date:   Thu Jul 4 16:20:31 2013 +0300

    perf tools: struct thread has a tid not a pid
    
    As evident from 'machine__process_fork_event()' and
    'machine__process_exit_event()' the 'pid' member of struct thread is
    actually the tid.
    
    Rename 'pid' to 'tid' in struct thread accordingly.
    
    Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
    Acked-by: David Ahern <dsahern@gmail.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1372944040-32690-13-git-send-email-adrian.hunter@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 0259502638b4..b49f5c58e152 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -313,7 +313,7 @@ static int process_sample_event(struct perf_tool *tool __maybe_unused,
 		return -1;
 	}
 
-	dump_printf(" ... thread: %s:%d\n", thread->comm, thread->pid);
+	dump_printf(" ... thread: %s:%d\n", thread->comm, thread->tid);
 
 	if (evsel->handler.func != NULL) {
 		tracepoint_handler f = evsel->handler.func;

commit 4a4d371a4dfbd3b84a7eab8d535d4c7c3647b09e
Author: Jiri Olsa <jolsa@redhat.com>
Date:   Wed Jun 5 13:37:21 2013 +0200

    perf record: Remove -f/--force option
    
    It no longer have any affect on the processing and is marked as obsolete
    anyway.
    
    Signed-off-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/n/tip-tvwyspiqr4getzfib2lw06ty@git.kernel.org
    Link: http://lkml.kernel.org/r/1372307120-737-1-git-send-email-namhyung@kernel.org
    [ combined patch removing the -f usage in various sub-commands, such as 'perf sched', etc, by Namhyung Kim ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 46878daca5cc..0259502638b4 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -708,7 +708,7 @@ static int parse_line_opt(const struct option *opt __maybe_unused,
 static int __cmd_record(int argc, const char **argv)
 {
 	const char * const record_args[] = {
-	"record", "-a", "-R", "-f", "-c", "1",
+	"record", "-a", "-R", "-c", "1",
 	"-e", "kmem:kmalloc",
 	"-e", "kmem:kmalloc_node",
 	"-e", "kmem:kfree",

commit 8d9233f205e8855dc762665e28012354cd46af45
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Jan 24 22:24:57 2013 -0300

    perf kmem: Use memdup()
    
    Instead of hand coded equivalent.
    
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-42ldngi973f4ssvzlklo8t2k@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index c746108c5d48..46878daca5cc 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -17,6 +17,7 @@
 #include "util/debug.h"
 
 #include <linux/rbtree.h>
+#include <linux/string.h>
 
 struct alloc_stat;
 typedef int (*sort_fn_t)(struct alloc_stat *, struct alloc_stat *);
@@ -618,12 +619,11 @@ static int sort_dimension__add(const char *tok, struct list_head *list)
 
 	for (i = 0; i < NUM_AVAIL_SORTS; i++) {
 		if (!strcmp(avail_sorts[i]->name, tok)) {
-			sort = malloc(sizeof(*sort));
+			sort = memdup(avail_sorts[i], sizeof(*avail_sorts[i]));
 			if (!sort) {
-				pr_err("%s: malloc failed\n", __func__);
+				pr_err("%s: memdup failed\n", __func__);
 				return -1;
 			}
-			memcpy(sort, avail_sorts[i], sizeof(*sort));
 			list_add_tail(&sort->list, list);
 			return 0;
 		}

commit 49e4ba54592435cbd150aea8f5ae6b776fc687f9
Author: Sasha Levin <sasha.levin@oracle.com>
Date:   Thu Dec 20 14:11:16 2012 -0500

    perf kmem: use ARRAY_SIZE instead of reinventing it
    
    Signed-off-by: Sasha Levin <sasha.levin@oracle.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1356030701-16284-8-git-send-email-sasha.levin@oracle.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 9fddca749ca2..c746108c5d48 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -609,8 +609,7 @@ static struct sort_dimension *avail_sorts[] = {
 	&pingpong_sort_dimension,
 };
 
-#define NUM_AVAIL_SORTS	\
-	(int)(sizeof(avail_sorts) / sizeof(struct sort_dimension *))
+#define NUM_AVAIL_SORTS	((int)ARRAY_SIZE(avail_sorts))
 
 static int sort_dimension__add(const char *tok, struct list_head *list)
 {

commit 34ba5122bf198c9cdfcbecc9b23eaa414244a3f6
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Dec 19 09:04:24 2012 -0300

    perf machine: Simplify accessing the host machine
    
    It is always there, no sense in calling a function named
    "perf_session__find_host_machine".
    
    Also no sense in checking if that function return is NULL, so ditch
    needless error handling.
    
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-a6a3zx3afbrxo8p2zqm5mxo8@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 0b4b796167be..9fddca749ca2 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -340,7 +340,7 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 			   int n_lines, int is_caller)
 {
 	struct rb_node *next;
-	struct machine *machine;
+	struct machine *machine = &session->machines.host;
 
 	printf("%.102s\n", graph_dotted_line);
 	printf(" %-34s |",  is_caller ? "Callsite": "Alloc Ptr");
@@ -349,11 +349,6 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 
 	next = rb_first(root);
 
-	machine = perf_session__find_host_machine(session);
-	if (!machine) {
-		pr_err("__print_result: couldn't find kernel information\n");
-		return;
-	}
 	while (next && n_lines--) {
 		struct alloc_stat *data = rb_entry(next, struct alloc_stat,
 						   node);

commit 70cb4e963f77dae90ae2aa3dd9385a43737c469f
Author: Feng Tang <feng.tang@intel.com>
Date:   Tue Oct 30 11:56:02 2012 +0800

    perf tools: Add a global variable "const char *input_name"
    
    Currently many perf commands annotate/evlist/report/script/lock etc all
    support "-i" option to chose a specific perf data, and all of them
    create a local "input_name" to save the file name for that perf data.
    
    Since most of these commands need it, we can add a global variable for
    it, also it can some other benefits:
    
    1. When calling script browser inside hists/annotation browser, it needs
    to know the perf data file name to run that script.
    
    2. For further feature like runtime switching to another perf data file,
    this variable can also help.
    
    Signed-off-by: Feng Tang <feng.tang@intel.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1351569369-26732-2-git-send-email-feng.tang@intel.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 14bf82f63659..0b4b796167be 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -477,7 +477,7 @@ static void sort_result(void)
 	__sort_result(&root_caller_stat, &root_caller_sorted, &caller_sort);
 }
 
-static int __cmd_kmem(const char *input_name)
+static int __cmd_kmem(void)
 {
 	int err = -EINVAL;
 	struct perf_session *session;
@@ -743,7 +743,6 @@ static int __cmd_record(int argc, const char **argv)
 int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 {
 	const char * const default_sort_order = "frag,hit,bytes";
-	const char *input_name = NULL;
 	const struct option kmem_options[] = {
 	OPT_STRING('i', "input", &input_name, "file", "input file name"),
 	OPT_CALLBACK_NOOPT(0, "caller", NULL, NULL,
@@ -779,7 +778,7 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 		if (list_empty(&alloc_sort))
 			setup_sorting(&alloc_sort, default_sort_order);
 
-		return __cmd_kmem(input_name);
+		return __cmd_kmem();
 	} else
 		usage_with_options(kmem_usage, kmem_options);
 

commit 0433ffbe47d66c5c561b54340ee47adf8826bcc4
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Oct 1 15:20:58 2012 -0300

    perf kmem: Don't use globals where not needed to
    
    Some variables were global but used in just one function, so move it to
    where it belongs.
    
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-wu8lz0g2qg26aqgi51xgzkpp@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index bc912c68f49a..14bf82f63659 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -21,8 +21,6 @@
 struct alloc_stat;
 typedef int (*sort_fn_t)(struct alloc_stat *, struct alloc_stat *);
 
-static const char		*input_name;
-
 static int			alloc_flag;
 static int			caller_flag;
 
@@ -31,8 +29,6 @@ static int			caller_lines = -1;
 
 static bool			raw_ip;
 
-static char			default_sort_order[] = "frag,hit,bytes";
-
 static int			*cpunode_map;
 static int			max_cpu_num;
 
@@ -481,7 +477,7 @@ static void sort_result(void)
 	__sort_result(&root_caller_stat, &root_caller_sorted, &caller_sort);
 }
 
-static int __cmd_kmem(void)
+static int __cmd_kmem(const char *input_name)
 {
 	int err = -EINVAL;
 	struct perf_session *session;
@@ -520,11 +516,6 @@ static int __cmd_kmem(void)
 	return err;
 }
 
-static const char * const kmem_usage[] = {
-	"perf kmem [<options>] {record|stat}",
-	NULL
-};
-
 static int ptr_cmp(struct alloc_stat *l, struct alloc_stat *r)
 {
 	if (l->ptr < r->ptr)
@@ -720,41 +711,17 @@ static int parse_line_opt(const struct option *opt __maybe_unused,
 	return 0;
 }
 
-static const struct option kmem_options[] = {
-	OPT_STRING('i', "input", &input_name, "file",
-		   "input file name"),
-	OPT_CALLBACK_NOOPT(0, "caller", NULL, NULL,
-			   "show per-callsite statistics",
-			   parse_caller_opt),
-	OPT_CALLBACK_NOOPT(0, "alloc", NULL, NULL,
-			   "show per-allocation statistics",
-			   parse_alloc_opt),
-	OPT_CALLBACK('s', "sort", NULL, "key[,key2...]",
-		     "sort by keys: ptr, call_site, bytes, hit, pingpong, frag",
-		     parse_sort_opt),
-	OPT_CALLBACK('l', "line", NULL, "num",
-		     "show n lines",
-		     parse_line_opt),
-	OPT_BOOLEAN(0, "raw-ip", &raw_ip, "show raw ip instead of symbol"),
-	OPT_END()
-};
-
-static const char *record_args[] = {
-	"record",
-	"-a",
-	"-R",
-	"-f",
-	"-c", "1",
+static int __cmd_record(int argc, const char **argv)
+{
+	const char * const record_args[] = {
+	"record", "-a", "-R", "-f", "-c", "1",
 	"-e", "kmem:kmalloc",
 	"-e", "kmem:kmalloc_node",
 	"-e", "kmem:kfree",
 	"-e", "kmem:kmem_cache_alloc",
 	"-e", "kmem:kmem_cache_alloc_node",
 	"-e", "kmem:kmem_cache_free",
-};
-
-static int __cmd_record(int argc, const char **argv)
-{
+	};
 	unsigned int rec_argc, i, j;
 	const char **rec_argv;
 
@@ -775,6 +742,25 @@ static int __cmd_record(int argc, const char **argv)
 
 int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 {
+	const char * const default_sort_order = "frag,hit,bytes";
+	const char *input_name = NULL;
+	const struct option kmem_options[] = {
+	OPT_STRING('i', "input", &input_name, "file", "input file name"),
+	OPT_CALLBACK_NOOPT(0, "caller", NULL, NULL,
+			   "show per-callsite statistics", parse_caller_opt),
+	OPT_CALLBACK_NOOPT(0, "alloc", NULL, NULL,
+			   "show per-allocation statistics", parse_alloc_opt),
+	OPT_CALLBACK('s', "sort", NULL, "key[,key2...]",
+		     "sort by keys: ptr, call_site, bytes, hit, pingpong, frag",
+		     parse_sort_opt),
+	OPT_CALLBACK('l', "line", NULL, "num", "show n lines", parse_line_opt),
+	OPT_BOOLEAN(0, "raw-ip", &raw_ip, "show raw ip instead of symbol"),
+	OPT_END()
+	};
+	const char * const kmem_usage[] = {
+		"perf kmem [<options>] {record|stat}",
+		NULL
+	};
 	argc = parse_options(argc, argv, kmem_options, kmem_usage, 0);
 
 	if (!argc)
@@ -793,7 +779,7 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 		if (list_empty(&alloc_sort))
 			setup_sorting(&alloc_sort, default_sort_order);
 
-		return __cmd_kmem();
+		return __cmd_kmem(input_name);
 	} else
 		usage_with_options(kmem_usage, kmem_options);
 

commit 0f7d2f1b65e3415854bbe842705f698a3350d7da
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Sep 24 10:46:54 2012 -0300

    perf kmem: Use perf_evsel__intval and perf_session__set_tracepoints_handlers
    
    Following the model of 'perf sched':
    
    . raw_field_value searches first on the common fields, that are unused
      in this tool
    
    . Using perf_session__set_tracepoints_handlers will save all those
      strcmp to find the right handler at sample processing time, do it just
      once and get the handler from evsel->handler.func.
    
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-v9x3q9rv4caxtox7wtjpchq5@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index f5f8a6b745a3..bc912c68f49a 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1,6 +1,7 @@
 #include "builtin.h"
 #include "perf.h"
 
+#include "util/evlist.h"
 #include "util/evsel.h"
 #include "util/util.h"
 #include "util/cache.h"
@@ -212,36 +213,38 @@ static int insert_caller_stat(unsigned long call_site,
 }
 
 static int perf_evsel__process_alloc_event(struct perf_evsel *evsel,
-					   struct perf_sample *sample, int node)
+					   struct perf_sample *sample)
 {
-	struct event_format *event = evsel->tp_format;
-	void *data = sample->raw_data;
-	unsigned long call_site;
-	unsigned long ptr;
-	int bytes_req, cpu = sample->cpu;
-	int bytes_alloc;
-	int node1, node2;
-
-	ptr = raw_field_value(event, "ptr", data);
-	call_site = raw_field_value(event, "call_site", data);
-	bytes_req = raw_field_value(event, "bytes_req", data);
-	bytes_alloc = raw_field_value(event, "bytes_alloc", data);
-
-	if (insert_alloc_stat(call_site, ptr, bytes_req, bytes_alloc, cpu) ||
+	unsigned long ptr = perf_evsel__intval(evsel, sample, "ptr"),
+		      call_site = perf_evsel__intval(evsel, sample, "call_site");
+	int bytes_req = perf_evsel__intval(evsel, sample, "bytes_req"),
+	    bytes_alloc = perf_evsel__intval(evsel, sample, "bytes_alloc");
+
+	if (insert_alloc_stat(call_site, ptr, bytes_req, bytes_alloc, sample->cpu) ||
 	    insert_caller_stat(call_site, bytes_req, bytes_alloc))
 		return -1;
 
 	total_requested += bytes_req;
 	total_allocated += bytes_alloc;
 
-	if (node) {
-		node1 = cpunode_map[cpu];
-		node2 = raw_field_value(event, "node", data);
+	nr_allocs++;
+	return 0;
+}
+
+static int perf_evsel__process_alloc_node_event(struct perf_evsel *evsel,
+						struct perf_sample *sample)
+{
+	int ret = perf_evsel__process_alloc_event(evsel, sample);
+
+	if (!ret) {
+		int node1 = cpunode_map[sample->cpu],
+		    node2 = perf_evsel__intval(evsel, sample, "node");
+
 		if (node1 != node2)
 			nr_cross_allocs++;
 	}
-	nr_allocs++;
-	return 0;
+
+	return ret;
 }
 
 static int ptr_cmp(struct alloc_stat *, struct alloc_stat *);
@@ -275,8 +278,7 @@ static struct alloc_stat *search_alloc_stat(unsigned long ptr,
 static int perf_evsel__process_free_event(struct perf_evsel *evsel,
 					  struct perf_sample *sample)
 {
-	unsigned long ptr = raw_field_value(evsel->tp_format, "ptr",
-					    sample->raw_data);
+	unsigned long ptr = perf_evsel__intval(evsel, sample, "ptr");
 	struct alloc_stat *s_alloc, *s_caller;
 
 	s_alloc = search_alloc_stat(ptr, 0, &root_alloc_stat, ptr_cmp);
@@ -297,28 +299,8 @@ static int perf_evsel__process_free_event(struct perf_evsel *evsel,
 	return 0;
 }
 
-static int perf_evsel__process_kmem_event(struct perf_evsel *evsel,
-					  struct perf_sample *sample)
-{
-	struct event_format *event = evsel->tp_format;
-
-	if (!strcmp(event->name, "kmalloc") ||
-	    !strcmp(event->name, "kmem_cache_alloc")) {
-		return perf_evsel__process_alloc_event(evsel, sample, 0);
-	}
-
-	if (!strcmp(event->name, "kmalloc_node") ||
-	    !strcmp(event->name, "kmem_cache_alloc_node")) {
-		return perf_evsel__process_alloc_event(evsel, sample, 1);
-	}
-
-	if (!strcmp(event->name, "kfree") ||
-	    !strcmp(event->name, "kmem_cache_free")) {
-		return perf_evsel__process_free_event(evsel, sample);
-	}
-
-	return 0;
-}
+typedef int (*tracepoint_handler)(struct perf_evsel *evsel,
+				  struct perf_sample *sample);
 
 static int process_sample_event(struct perf_tool *tool __maybe_unused,
 				union perf_event *event,
@@ -336,7 +318,12 @@ static int process_sample_event(struct perf_tool *tool __maybe_unused,
 
 	dump_printf(" ... thread: %s:%d\n", thread->comm, thread->pid);
 
-	return perf_evsel__process_kmem_event(evsel, sample);
+	if (evsel->handler.func != NULL) {
+		tracepoint_handler f = evsel->handler.func;
+		return f(evsel, sample);
+	}
+
+	return 0;
 }
 
 static struct perf_tool perf_kmem = {
@@ -498,6 +485,14 @@ static int __cmd_kmem(void)
 {
 	int err = -EINVAL;
 	struct perf_session *session;
+	const struct perf_evsel_str_handler kmem_tracepoints[] = {
+		{ "kmem:kmalloc",		perf_evsel__process_alloc_event, },
+    		{ "kmem:kmem_cache_alloc",	perf_evsel__process_alloc_event, },
+		{ "kmem:kmalloc_node",		perf_evsel__process_alloc_node_event, },
+    		{ "kmem:kmem_cache_alloc_node", perf_evsel__process_alloc_node_event, },
+		{ "kmem:kfree",			perf_evsel__process_free_event, },
+    		{ "kmem:kmem_cache_free",	perf_evsel__process_free_event, },
+	};
 
 	session = perf_session__new(input_name, O_RDONLY, 0, false, &perf_kmem);
 	if (session == NULL)
@@ -509,6 +504,11 @@ static int __cmd_kmem(void)
 	if (!perf_session__has_traces(session, "kmem record"))
 		goto out_delete;
 
+	if (perf_session__set_tracepoints_handlers(session, kmem_tracepoints)) {
+		pr_err("Initializing perf session tracepoint handlers failed\n");
+		return -1;
+	}
+
 	setup_pager();
 	err = perf_session__process_events(session, &perf_kmem);
 	if (err != 0)

commit 1d037ca1648b775277fc96401ec2aa233724906c
Author: Irina Tirdea <irina.tirdea@gmail.com>
Date:   Tue Sep 11 01:15:03 2012 +0300

    perf tools: Use __maybe_used for unused variables
    
    perf defines both __used and __unused variables to use for marking
    unused variables. The variable __used is defined to
    __attribute__((__unused__)), which contradicts the kernel definition to
    __attribute__((__used__)) for new gcc versions. On Android, __used is
    also defined in system headers and this leads to warnings like: warning:
    '__used__' attribute ignored
    
    __unused is not defined in the kernel and is not a standard definition.
    If __unused is included everywhere instead of __used, this leads to
    conflicts with glibc headers, since glibc has a variables with this name
    in its headers.
    
    The best approach is to use __maybe_unused, the definition used in the
    kernel for __attribute__((unused)). In this way there is only one
    definition in perf sources (instead of 2 definitions that point to the
    same thing: __used and __unused) and it works on both Linux and Android.
    This patch simply replaces all instances of __used and __unused with
    __maybe_unused.
    
    Signed-off-by: Irina Tirdea <irina.tirdea@intel.com>
    Acked-by: Pekka Enberg <penberg@kernel.org>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Link: http://lkml.kernel.org/r/1347315303-29906-7-git-send-email-irina.tirdea@intel.com
    [ committer note: fixed up conflict with a116e05 in builtin-sched.c ]
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index ad9f52097388..f5f8a6b745a3 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -320,7 +320,7 @@ static int perf_evsel__process_kmem_event(struct perf_evsel *evsel,
 	return 0;
 }
 
-static int process_sample_event(struct perf_tool *tool __used,
+static int process_sample_event(struct perf_tool *tool __maybe_unused,
 				union perf_event *event,
 				struct perf_sample *sample,
 				struct perf_evsel *evsel,
@@ -672,8 +672,8 @@ static int setup_sorting(struct list_head *sort_list, const char *arg)
 	return 0;
 }
 
-static int parse_sort_opt(const struct option *opt __used,
-			  const char *arg, int unset __used)
+static int parse_sort_opt(const struct option *opt __maybe_unused,
+			  const char *arg, int unset __maybe_unused)
 {
 	if (!arg)
 		return -1;
@@ -686,22 +686,24 @@ static int parse_sort_opt(const struct option *opt __used,
 	return 0;
 }
 
-static int parse_caller_opt(const struct option *opt __used,
-			  const char *arg __used, int unset __used)
+static int parse_caller_opt(const struct option *opt __maybe_unused,
+			    const char *arg __maybe_unused,
+			    int unset __maybe_unused)
 {
 	caller_flag = (alloc_flag + 1);
 	return 0;
 }
 
-static int parse_alloc_opt(const struct option *opt __used,
-			  const char *arg __used, int unset __used)
+static int parse_alloc_opt(const struct option *opt __maybe_unused,
+			   const char *arg __maybe_unused,
+			   int unset __maybe_unused)
 {
 	alloc_flag = (caller_flag + 1);
 	return 0;
 }
 
-static int parse_line_opt(const struct option *opt __used,
-			  const char *arg, int unset __used)
+static int parse_line_opt(const struct option *opt __maybe_unused,
+			  const char *arg, int unset __maybe_unused)
 {
 	int lines;
 
@@ -771,7 +773,7 @@ static int __cmd_record(int argc, const char **argv)
 	return cmd_record(i, rec_argv, NULL);
 }
 
-int cmd_kmem(int argc, const char **argv, const char *prefix __used)
+int cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)
 {
 	argc = parse_options(argc, argv, kmem_options, kmem_usage, 0);
 

commit 2814eb05720baa54ffe0950714fd55a5bcc8a565
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sat Sep 8 22:53:06 2012 -0300

    perf kmem: Remove die() calls
    
    Just use pr_err() + return -1 and perf_session__process_events to abort
    when some event would call die(), then let the perf's main() exit doing
    whatever it needs.
    
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-i7rhuqfwshjiwc9gr9m1vov4@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index fc6607b383f2..ad9f52097388 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -58,41 +58,52 @@ static unsigned long nr_allocs, nr_cross_allocs;
 
 #define PATH_SYS_NODE	"/sys/devices/system/node"
 
-static void init_cpunode_map(void)
+static int init_cpunode_map(void)
 {
 	FILE *fp;
-	int i;
+	int i, err = -1;
 
 	fp = fopen("/sys/devices/system/cpu/kernel_max", "r");
 	if (!fp) {
 		max_cpu_num = 4096;
-		return;
+		return 0;
+	}
+
+	if (fscanf(fp, "%d", &max_cpu_num) < 1) {
+		pr_err("Failed to read 'kernel_max' from sysfs");
+		goto out_close;
 	}
 
-	if (fscanf(fp, "%d", &max_cpu_num) < 1)
-		die("Failed to read 'kernel_max' from sysfs");
 	max_cpu_num++;
 
 	cpunode_map = calloc(max_cpu_num, sizeof(int));
-	if (!cpunode_map)
-		die("calloc");
+	if (!cpunode_map) {
+		pr_err("%s: calloc failed\n", __func__);
+		goto out_close;
+	}
+
 	for (i = 0; i < max_cpu_num; i++)
 		cpunode_map[i] = -1;
+
+	err = 0;
+out_close:
 	fclose(fp);
+	return err;
 }
 
-static void setup_cpunode_map(void)
+static int setup_cpunode_map(void)
 {
 	struct dirent *dent1, *dent2;
 	DIR *dir1, *dir2;
 	unsigned int cpu, mem;
 	char buf[PATH_MAX];
 
-	init_cpunode_map();
+	if (init_cpunode_map())
+		return -1;
 
 	dir1 = opendir(PATH_SYS_NODE);
 	if (!dir1)
-		return;
+		return -1;
 
 	while ((dent1 = readdir(dir1)) != NULL) {
 		if (dent1->d_type != DT_DIR ||
@@ -112,10 +123,11 @@ static void setup_cpunode_map(void)
 		closedir(dir2);
 	}
 	closedir(dir1);
+	return 0;
 }
 
-static void insert_alloc_stat(unsigned long call_site, unsigned long ptr,
-			      int bytes_req, int bytes_alloc, int cpu)
+static int insert_alloc_stat(unsigned long call_site, unsigned long ptr,
+			     int bytes_req, int bytes_alloc, int cpu)
 {
 	struct rb_node **node = &root_alloc_stat.rb_node;
 	struct rb_node *parent = NULL;
@@ -139,8 +151,10 @@ static void insert_alloc_stat(unsigned long call_site, unsigned long ptr,
 		data->bytes_alloc += bytes_alloc;
 	} else {
 		data = malloc(sizeof(*data));
-		if (!data)
-			die("malloc");
+		if (!data) {
+			pr_err("%s: malloc failed\n", __func__);
+			return -1;
+		}
 		data->ptr = ptr;
 		data->pingpong = 0;
 		data->hit = 1;
@@ -152,9 +166,10 @@ static void insert_alloc_stat(unsigned long call_site, unsigned long ptr,
 	}
 	data->call_site = call_site;
 	data->alloc_cpu = cpu;
+	return 0;
 }
 
-static void insert_caller_stat(unsigned long call_site,
+static int insert_caller_stat(unsigned long call_site,
 			      int bytes_req, int bytes_alloc)
 {
 	struct rb_node **node = &root_caller_stat.rb_node;
@@ -179,8 +194,10 @@ static void insert_caller_stat(unsigned long call_site,
 		data->bytes_alloc += bytes_alloc;
 	} else {
 		data = malloc(sizeof(*data));
-		if (!data)
-			die("malloc");
+		if (!data) {
+			pr_err("%s: malloc failed\n", __func__);
+			return -1;
+		}
 		data->call_site = call_site;
 		data->pingpong = 0;
 		data->hit = 1;
@@ -190,11 +207,12 @@ static void insert_caller_stat(unsigned long call_site,
 		rb_link_node(&data->node, parent, node);
 		rb_insert_color(&data->node, &root_caller_stat);
 	}
+
+	return 0;
 }
 
-static void perf_evsel__process_alloc_event(struct perf_evsel *evsel,
-					    struct perf_sample *sample,
-					    int node)
+static int perf_evsel__process_alloc_event(struct perf_evsel *evsel,
+					   struct perf_sample *sample, int node)
 {
 	struct event_format *event = evsel->tp_format;
 	void *data = sample->raw_data;
@@ -209,8 +227,9 @@ static void perf_evsel__process_alloc_event(struct perf_evsel *evsel,
 	bytes_req = raw_field_value(event, "bytes_req", data);
 	bytes_alloc = raw_field_value(event, "bytes_alloc", data);
 
-	insert_alloc_stat(call_site, ptr, bytes_req, bytes_alloc, cpu);
-	insert_caller_stat(call_site, bytes_req, bytes_alloc);
+	if (insert_alloc_stat(call_site, ptr, bytes_req, bytes_alloc, cpu) ||
+	    insert_caller_stat(call_site, bytes_req, bytes_alloc))
+		return -1;
 
 	total_requested += bytes_req;
 	total_allocated += bytes_alloc;
@@ -222,6 +241,7 @@ static void perf_evsel__process_alloc_event(struct perf_evsel *evsel,
 			nr_cross_allocs++;
 	}
 	nr_allocs++;
+	return 0;
 }
 
 static int ptr_cmp(struct alloc_stat *, struct alloc_stat *);
@@ -252,8 +272,8 @@ static struct alloc_stat *search_alloc_stat(unsigned long ptr,
 	return NULL;
 }
 
-static void perf_evsel__process_free_event(struct perf_evsel *evsel,
-					   struct perf_sample *sample)
+static int perf_evsel__process_free_event(struct perf_evsel *evsel,
+					  struct perf_sample *sample)
 {
 	unsigned long ptr = raw_field_value(evsel->tp_format, "ptr",
 					    sample->raw_data);
@@ -261,41 +281,43 @@ static void perf_evsel__process_free_event(struct perf_evsel *evsel,
 
 	s_alloc = search_alloc_stat(ptr, 0, &root_alloc_stat, ptr_cmp);
 	if (!s_alloc)
-		return;
+		return 0;
 
 	if ((short)sample->cpu != s_alloc->alloc_cpu) {
 		s_alloc->pingpong++;
 
 		s_caller = search_alloc_stat(0, s_alloc->call_site,
 					     &root_caller_stat, callsite_cmp);
-		assert(s_caller);
+		if (!s_caller)
+			return -1;
 		s_caller->pingpong++;
 	}
 	s_alloc->alloc_cpu = -1;
+
+	return 0;
 }
 
-static void perf_evsel__process_kmem_event(struct perf_evsel *evsel,
-					   struct perf_sample *sample)
+static int perf_evsel__process_kmem_event(struct perf_evsel *evsel,
+					  struct perf_sample *sample)
 {
 	struct event_format *event = evsel->tp_format;
 
 	if (!strcmp(event->name, "kmalloc") ||
 	    !strcmp(event->name, "kmem_cache_alloc")) {
-		perf_evsel__process_alloc_event(evsel, sample, 0);
-		return;
+		return perf_evsel__process_alloc_event(evsel, sample, 0);
 	}
 
 	if (!strcmp(event->name, "kmalloc_node") ||
 	    !strcmp(event->name, "kmem_cache_alloc_node")) {
-		perf_evsel__process_alloc_event(evsel, sample, 1);
-		return;
+		return perf_evsel__process_alloc_event(evsel, sample, 1);
 	}
 
 	if (!strcmp(event->name, "kfree") ||
 	    !strcmp(event->name, "kmem_cache_free")) {
-		perf_evsel__process_free_event(evsel, sample);
-		return;
+		return perf_evsel__process_free_event(evsel, sample);
 	}
+
+	return 0;
 }
 
 static int process_sample_event(struct perf_tool *tool __used,
@@ -314,8 +336,7 @@ static int process_sample_event(struct perf_tool *tool __used,
 
 	dump_printf(" ... thread: %s:%d\n", thread->comm, thread->pid);
 
-	perf_evsel__process_kmem_event(evsel, sample);
-	return 0;
+	return perf_evsel__process_kmem_event(evsel, sample);
 }
 
 static struct perf_tool perf_kmem = {
@@ -613,8 +634,10 @@ static int sort_dimension__add(const char *tok, struct list_head *list)
 	for (i = 0; i < NUM_AVAIL_SORTS; i++) {
 		if (!strcmp(avail_sorts[i]->name, tok)) {
 			sort = malloc(sizeof(*sort));
-			if (!sort)
-				die("malloc");
+			if (!sort) {
+				pr_err("%s: malloc failed\n", __func__);
+				return -1;
+			}
 			memcpy(sort, avail_sorts[i], sizeof(*sort));
 			list_add_tail(&sort->list, list);
 			return 0;
@@ -629,8 +652,10 @@ static int setup_sorting(struct list_head *sort_list, const char *arg)
 	char *tok;
 	char *str = strdup(arg);
 
-	if (!str)
-		die("strdup");
+	if (!str) {
+		pr_err("%s: strdup failed\n", __func__);
+		return -1;
+	}
 
 	while (true) {
 		tok = strsep(&str, ",");
@@ -758,7 +783,8 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __used)
 	if (!strncmp(argv[0], "rec", 3)) {
 		return __cmd_record(argc, argv);
 	} else if (!strcmp(argv[0], "stat")) {
-		setup_cpunode_map();
+		if (setup_cpunode_map())
+			return -1;
 
 		if (list_empty(&caller_sort))
 			setup_sorting(&caller_sort, default_sort_order);

commit 22ad798c37cb554afae79a72c1d420ecb4d27b86
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Aug 7 10:56:43 2012 -0300

    perf kmem: Use evsel->tp_format and perf_sample
    
    To reduce the number of parameters passed to the various event handling
    functions.
    
    Cc: Andrey Wagin <avagin@gmail.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-p936ngz06yo5h797ggsm7xru@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index ffb93f424953..fc6607b383f2 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -192,16 +192,15 @@ static void insert_caller_stat(unsigned long call_site,
 	}
 }
 
-static void process_alloc_event(void *data,
-				struct event_format *event,
-				int cpu,
-				u64 timestamp __used,
-				struct thread *thread __used,
-				int node)
+static void perf_evsel__process_alloc_event(struct perf_evsel *evsel,
+					    struct perf_sample *sample,
+					    int node)
 {
+	struct event_format *event = evsel->tp_format;
+	void *data = sample->raw_data;
 	unsigned long call_site;
 	unsigned long ptr;
-	int bytes_req;
+	int bytes_req, cpu = sample->cpu;
 	int bytes_alloc;
 	int node1, node2;
 
@@ -253,22 +252,18 @@ static struct alloc_stat *search_alloc_stat(unsigned long ptr,
 	return NULL;
 }
 
-static void process_free_event(void *data,
-			       struct event_format *event,
-			       int cpu,
-			       u64 timestamp __used,
-			       struct thread *thread __used)
+static void perf_evsel__process_free_event(struct perf_evsel *evsel,
+					   struct perf_sample *sample)
 {
-	unsigned long ptr;
+	unsigned long ptr = raw_field_value(evsel->tp_format, "ptr",
+					    sample->raw_data);
 	struct alloc_stat *s_alloc, *s_caller;
 
-	ptr = raw_field_value(event, "ptr", data);
-
 	s_alloc = search_alloc_stat(ptr, 0, &root_alloc_stat, ptr_cmp);
 	if (!s_alloc)
 		return;
 
-	if (cpu != s_alloc->alloc_cpu) {
+	if ((short)sample->cpu != s_alloc->alloc_cpu) {
 		s_alloc->pingpong++;
 
 		s_caller = search_alloc_stat(0, s_alloc->call_site,
@@ -279,26 +274,26 @@ static void process_free_event(void *data,
 	s_alloc->alloc_cpu = -1;
 }
 
-static void process_raw_event(struct perf_evsel *evsel, void *data,
-			      int cpu, u64 timestamp, struct thread *thread)
+static void perf_evsel__process_kmem_event(struct perf_evsel *evsel,
+					   struct perf_sample *sample)
 {
 	struct event_format *event = evsel->tp_format;
 
 	if (!strcmp(event->name, "kmalloc") ||
 	    !strcmp(event->name, "kmem_cache_alloc")) {
-		process_alloc_event(data, event, cpu, timestamp, thread, 0);
+		perf_evsel__process_alloc_event(evsel, sample, 0);
 		return;
 	}
 
 	if (!strcmp(event->name, "kmalloc_node") ||
 	    !strcmp(event->name, "kmem_cache_alloc_node")) {
-		process_alloc_event(data, event, cpu, timestamp, thread, 1);
+		perf_evsel__process_alloc_event(evsel, sample, 1);
 		return;
 	}
 
 	if (!strcmp(event->name, "kfree") ||
 	    !strcmp(event->name, "kmem_cache_free")) {
-		process_free_event(data, event, cpu, timestamp, thread);
+		perf_evsel__process_free_event(evsel, sample);
 		return;
 	}
 }
@@ -319,9 +314,7 @@ static int process_sample_event(struct perf_tool *tool __used,
 
 	dump_printf(" ... thread: %s:%d\n", thread->comm, thread->pid);
 
-	process_raw_event(evsel, sample->raw_data, sample->cpu,
-			  sample->time, thread);
-
+	perf_evsel__process_kmem_event(evsel, sample);
 	return 0;
 }
 

commit fcf65bf149afa91b875ffde4455967cb63ee0be9
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Aug 7 09:58:03 2012 -0300

    perf evsel: Cache associated event_format
    
    We already lookup the associated event_format when reading the perf.data
    header, so that we can cache the tracepoint name in evsel->name, so do
    it a little further and save the event_format itself, so that we can
    avoid relookups in tools that need to access it.
    
    Change the tools to take the most obvious advantage, when they were
    using pevent_find_event directly. More work is needed for further
    removing the need of a pointer to pevent, such as when asking for event
    field values ("common_pid" and the other common fields and per
    event_format fields).
    
    This is something that was planned but only got actually done when
    Andrey Wagin needed to do this lookup at perf_tool->sample() time, when
    we don't have access to pevent (session->pevent) to use with
    pevent_find_event().
    
    Cc: Andrey Wagin <avagin@gmail.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Link: http://lkml.kernel.org/n/tip-txkvew2ckko0b594ae8fbnyk@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index ce35015f2dc6..ffb93f424953 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -1,6 +1,7 @@
 #include "builtin.h"
 #include "perf.h"
 
+#include "util/evsel.h"
 #include "util/util.h"
 #include "util/cache.h"
 #include "util/symbol.h"
@@ -57,11 +58,6 @@ static unsigned long nr_allocs, nr_cross_allocs;
 
 #define PATH_SYS_NODE	"/sys/devices/system/node"
 
-struct perf_kmem {
-	struct perf_tool    tool;
-	struct perf_session *session;
-};
-
 static void init_cpunode_map(void)
 {
 	FILE *fp;
@@ -283,16 +279,10 @@ static void process_free_event(void *data,
 	s_alloc->alloc_cpu = -1;
 }
 
-static void process_raw_event(struct perf_tool *tool,
-			      union perf_event *raw_event __used, void *data,
+static void process_raw_event(struct perf_evsel *evsel, void *data,
 			      int cpu, u64 timestamp, struct thread *thread)
 {
-	struct perf_kmem *kmem = container_of(tool, struct perf_kmem, tool);
-	struct event_format *event;
-	int type;
-
-	type = trace_parse_common_type(kmem->session->pevent, data);
-	event = pevent_find_event(kmem->session->pevent, type);
+	struct event_format *event = evsel->tp_format;
 
 	if (!strcmp(event->name, "kmalloc") ||
 	    !strcmp(event->name, "kmem_cache_alloc")) {
@@ -313,10 +303,10 @@ static void process_raw_event(struct perf_tool *tool,
 	}
 }
 
-static int process_sample_event(struct perf_tool *tool,
+static int process_sample_event(struct perf_tool *tool __used,
 				union perf_event *event,
 				struct perf_sample *sample,
-				struct perf_evsel *evsel __used,
+				struct perf_evsel *evsel,
 				struct machine *machine)
 {
 	struct thread *thread = machine__findnew_thread(machine, event->ip.pid);
@@ -329,18 +319,16 @@ static int process_sample_event(struct perf_tool *tool,
 
 	dump_printf(" ... thread: %s:%d\n", thread->comm, thread->pid);
 
-	process_raw_event(tool, event, sample->raw_data, sample->cpu,
+	process_raw_event(evsel, sample->raw_data, sample->cpu,
 			  sample->time, thread);
 
 	return 0;
 }
 
-static struct perf_kmem perf_kmem = {
-	.tool = {
-		.sample			= process_sample_event,
-		.comm			= perf_event__process_comm,
-		.ordered_samples	= true,
-	},
+static struct perf_tool perf_kmem = {
+	.sample		 = process_sample_event,
+	.comm		 = perf_event__process_comm,
+	.ordered_samples = true,
 };
 
 static double fragmentation(unsigned long n_req, unsigned long n_alloc)
@@ -497,13 +485,10 @@ static int __cmd_kmem(void)
 	int err = -EINVAL;
 	struct perf_session *session;
 
-	session = perf_session__new(input_name, O_RDONLY, 0, false,
-				    &perf_kmem.tool);
+	session = perf_session__new(input_name, O_RDONLY, 0, false, &perf_kmem);
 	if (session == NULL)
 		return -ENOMEM;
 
-	perf_kmem.session = session;
-
 	if (perf_session__create_kernel_maps(session) < 0)
 		goto out_delete;
 
@@ -511,7 +496,7 @@ static int __cmd_kmem(void)
 		goto out_delete;
 
 	setup_pager();
-	err = perf_session__process_events(session, &perf_kmem.tool);
+	err = perf_session__process_events(session, &perf_kmem);
 	if (err != 0)
 		goto out_delete;
 	sort_result();

commit da3789628f88684d3f0fb4e6a6bc086c395ac3cb
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Jun 27 13:08:42 2012 -0300

    perf tools: Stop using a global trace events description list
    
    The pevent thing is per perf.data file, so I made it stop being static
    and become a perf_session member, so tools processing perf.data files
    use perf_session and _there_ we read the trace events description into
    session->pevent and then change everywhere to stop using that single
    global pevent variable and use the per session one.
    
    Note that it _doesn't_ fall backs to trace__event_id, as we're not
    interested at all in what is present in the
    /sys/kernel/debug/tracing/events in the workstation doing the analysis,
    just in what is in the perf.data file.
    
    This patch also introduces perf_session__set_tracepoints_handlers that
    is the perf perf.data/session way to associate handlers to tracepoint
    events by resolving their IDs using the events descriptions stored in a
    perf.data file. Make 'perf sched' use it.
    
    Reported-by: Dmitry Antipov <dmitry.antipov@linaro.org>
    Tested-by: Dmitry Antipov <dmitry.antipov@linaro.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: linaro-dev@lists.linaro.org
    Cc: patches@linaro.org
    Link: http://lkml.kernel.org/r/20120625232016.GA28525@infradead.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 547af48deb4f..ce35015f2dc6 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -57,6 +57,11 @@ static unsigned long nr_allocs, nr_cross_allocs;
 
 #define PATH_SYS_NODE	"/sys/devices/system/node"
 
+struct perf_kmem {
+	struct perf_tool    tool;
+	struct perf_session *session;
+};
+
 static void init_cpunode_map(void)
 {
 	FILE *fp;
@@ -278,14 +283,16 @@ static void process_free_event(void *data,
 	s_alloc->alloc_cpu = -1;
 }
 
-static void process_raw_event(union perf_event *raw_event __used, void *data,
+static void process_raw_event(struct perf_tool *tool,
+			      union perf_event *raw_event __used, void *data,
 			      int cpu, u64 timestamp, struct thread *thread)
 {
+	struct perf_kmem *kmem = container_of(tool, struct perf_kmem, tool);
 	struct event_format *event;
 	int type;
 
-	type = trace_parse_common_type(data);
-	event = trace_find_event(type);
+	type = trace_parse_common_type(kmem->session->pevent, data);
+	event = pevent_find_event(kmem->session->pevent, type);
 
 	if (!strcmp(event->name, "kmalloc") ||
 	    !strcmp(event->name, "kmem_cache_alloc")) {
@@ -306,7 +313,7 @@ static void process_raw_event(union perf_event *raw_event __used, void *data,
 	}
 }
 
-static int process_sample_event(struct perf_tool *tool __used,
+static int process_sample_event(struct perf_tool *tool,
 				union perf_event *event,
 				struct perf_sample *sample,
 				struct perf_evsel *evsel __used,
@@ -322,16 +329,18 @@ static int process_sample_event(struct perf_tool *tool __used,
 
 	dump_printf(" ... thread: %s:%d\n", thread->comm, thread->pid);
 
-	process_raw_event(event, sample->raw_data, sample->cpu,
+	process_raw_event(tool, event, sample->raw_data, sample->cpu,
 			  sample->time, thread);
 
 	return 0;
 }
 
-static struct perf_tool perf_kmem = {
-	.sample			= process_sample_event,
-	.comm			= perf_event__process_comm,
-	.ordered_samples	= true,
+static struct perf_kmem perf_kmem = {
+	.tool = {
+		.sample			= process_sample_event,
+		.comm			= perf_event__process_comm,
+		.ordered_samples	= true,
+	},
 };
 
 static double fragmentation(unsigned long n_req, unsigned long n_alloc)
@@ -486,11 +495,15 @@ static void sort_result(void)
 static int __cmd_kmem(void)
 {
 	int err = -EINVAL;
-	struct perf_session *session = perf_session__new(input_name, O_RDONLY,
-							 0, false, &perf_kmem);
+	struct perf_session *session;
+
+	session = perf_session__new(input_name, O_RDONLY, 0, false,
+				    &perf_kmem.tool);
 	if (session == NULL)
 		return -ENOMEM;
 
+	perf_kmem.session = session;
+
 	if (perf_session__create_kernel_maps(session) < 0)
 		goto out_delete;
 
@@ -498,7 +511,7 @@ static int __cmd_kmem(void)
 		goto out_delete;
 
 	setup_pager();
-	err = perf_session__process_events(session, &perf_kmem);
+	err = perf_session__process_events(session, &perf_kmem.tool);
 	if (err != 0)
 		goto out_delete;
 	sort_result();

commit aaf045f72335653b24784d6042be8e4aee114403
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Fri Apr 6 00:47:56 2012 +0200

    perf: Have perf use the new libtraceevent.a library
    
    The event parsing code in perf was originally copied from trace-cmd
    but never was kept up-to-date with the changes that was done there.
    The trace-cmd libtraceevent.a code is much more mature than what is
    currently in perf.
    
    This updates the code to use wrappers to handle the calls to the
    new event parsing code. The new code requires a handle to be pass
    around, which removes the global event variables and allows
    more than one event structure to be read from different files
    (and different machines).
    
    But perf still has the old global events and the code throughout
    perf does not yet have a nice way to pass around a handle.
    A global 'pevent' has been made for perf and the old calls have
    been created as wrappers to the new event parsing code that uses
    the global pevent.
    
    With this change, perf can later incorporate the pevent handle into
    the perf structures and allow more than one file to be read and
    compared, that contains different events.
    
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Arnaldo Carvalho de Melo <acme@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Arun Sharma <asharma@fb.com>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 39104c0beea3..547af48deb4f 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -192,7 +192,7 @@ static void insert_caller_stat(unsigned long call_site,
 }
 
 static void process_alloc_event(void *data,
-				struct event *event,
+				struct event_format *event,
 				int cpu,
 				u64 timestamp __used,
 				struct thread *thread __used,
@@ -253,7 +253,7 @@ static struct alloc_stat *search_alloc_stat(unsigned long ptr,
 }
 
 static void process_free_event(void *data,
-			       struct event *event,
+			       struct event_format *event,
 			       int cpu,
 			       u64 timestamp __used,
 			       struct thread *thread __used)
@@ -281,7 +281,7 @@ static void process_free_event(void *data,
 static void process_raw_event(union perf_event *raw_event __used, void *data,
 			      int cpu, u64 timestamp, struct thread *thread)
 {
-	struct event *event;
+	struct event_format *event;
 	int type;
 
 	type = trace_parse_common_type(data);

commit 1b22859d4320d472a7a51ff4a43f62b0578469de
Author: Namhyung Kim <namhyung@gmail.com>
Date:   Sun Jan 8 02:25:29 2012 +0900

    perf kmem: Fix a memory leak
    
    The 'str' should be freed when sort_dimension__add() failed too.
    
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1325957132-10600-5-git-send-email-namhyung@gmail.com
    Signed-off-by: Namhyung Kim <namhyung@gmail.com>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 7a9b5c55ad5a..39104c0beea3 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -647,6 +647,7 @@ static int setup_sorting(struct list_head *sort_list, const char *arg)
 			break;
 		if (sort_dimension__add(tok, sort_list) < 0) {
 			error("Unknown --sort key: '%s'", tok);
+			free(str);
 			return -1;
 		}
 	}

commit 8442da1d9f445b454accdb148355ee990ebf3b32
Author: Namhyung Kim <namhyung@gmail.com>
Date:   Sun Jan 8 02:25:28 2012 +0900

    perf kmem: Add missing closedir() calls
    
    The setup_cpunode_map() calls opendir() but misses corresponding
    closedir(). Add them.
    
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1325957132-10600-4-git-send-email-namhyung@gmail.com
    Signed-off-by: Namhyung Kim <namhyung@gmail.com>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index fe1ad8f21961..7a9b5c55ad5a 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -108,7 +108,9 @@ static void setup_cpunode_map(void)
 				continue;
 			cpunode_map[cpu] = mem;
 		}
+		closedir(dir2);
 	}
+	closedir(dir1);
 }
 
 static void insert_alloc_stat(unsigned long call_site, unsigned long ptr,

commit efad14150a0b4429f37da7245001a8096ef7ee38
Author: Robert Richter <robert.richter@amd.com>
Date:   Wed Dec 7 10:02:54 2011 +0100

    perf report: Accept fifos as input file
    
    The default input file for perf report is not handled the same way as
    perf record does it for its output file. This leads to unexpected
    behavior of perf report, etc. E.g.:
    
     # perf record -a -e cpu-cycles sleep 2 | perf report | cat
     failed to open perf.data: No such file or directory  (try 'perf record' first)
    
    While perf record writes to a fifo, perf report expects perf.data to be
    read. This patch changes this to accept fifos as input file.
    
    Applies to the following commands:
    
     perf annotate
     perf buildid-list
     perf evlist
     perf kmem
     perf lock
     perf report
     perf sched
     perf script
     perf timechart
    
    Also fixes char const* -> const char* type declaration for filename
    strings.
    
    v2:
    * Prevent potential null pointer access to input_name in
      builtin-report.c. Needed due to removal of patch "perf report: Setup
      browser if stdout is a pipe"
    
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1323248577-11268-5-git-send-email-robert.richter@amd.com
    Signed-off-by: Robert Richter <robert.richter@amd.com>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 886174e9525b..fe1ad8f21961 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -19,7 +19,7 @@
 struct alloc_stat;
 typedef int (*sort_fn_t)(struct alloc_stat *, struct alloc_stat *);
 
-static char const		*input_name = "perf.data";
+static const char		*input_name;
 
 static int			alloc_flag;
 static int			caller_flag;

commit 45694aa7702bc44d538a3bcb51bb2bb96cf190c0
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Nov 28 08:30:20 2011 -0200

    perf tools: Rename perf_event_ops to perf_tool
    
    To better reflect that it became the base class for all tools, that must
    be in each tool struct and where common stuff will be put.
    
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-qgpc4msetqlwr8y2k7537cxe@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 27b2a15dc7b2..886174e9525b 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -7,6 +7,7 @@
 #include "util/thread.h"
 #include "util/header.h"
 #include "util/session.h"
+#include "util/tool.h"
 
 #include "util/parse-options.h"
 #include "util/trace-event.h"
@@ -303,7 +304,7 @@ static void process_raw_event(union perf_event *raw_event __used, void *data,
 	}
 }
 
-static int process_sample_event(struct perf_event_ops *ops __used,
+static int process_sample_event(struct perf_tool *tool __used,
 				union perf_event *event,
 				struct perf_sample *sample,
 				struct perf_evsel *evsel __used,
@@ -325,7 +326,7 @@ static int process_sample_event(struct perf_event_ops *ops __used,
 	return 0;
 }
 
-static struct perf_event_ops event_ops = {
+static struct perf_tool perf_kmem = {
 	.sample			= process_sample_event,
 	.comm			= perf_event__process_comm,
 	.ordered_samples	= true,
@@ -484,7 +485,7 @@ static int __cmd_kmem(void)
 {
 	int err = -EINVAL;
 	struct perf_session *session = perf_session__new(input_name, O_RDONLY,
-							 0, false, &event_ops);
+							 0, false, &perf_kmem);
 	if (session == NULL)
 		return -ENOMEM;
 
@@ -495,7 +496,7 @@ static int __cmd_kmem(void)
 		goto out_delete;
 
 	setup_pager();
-	err = perf_session__process_events(session, &event_ops);
+	err = perf_session__process_events(session, &perf_kmem);
 	if (err != 0)
 		goto out_delete;
 	sort_result();

commit 743eb868657bdb1b26c7b24077ca21c67c82c777
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Nov 28 07:56:39 2011 -0200

    perf tools: Resolve machine earlier and pass it to perf_event_ops
    
    Reducing the exposure of perf_session further, so that we can use the
    classes in cases where no perf.data file is created.
    
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-stua66dcscsezzrcdugvbmvd@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 5d01218e50e0..27b2a15dc7b2 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -307,9 +307,9 @@ static int process_sample_event(struct perf_event_ops *ops __used,
 				union perf_event *event,
 				struct perf_sample *sample,
 				struct perf_evsel *evsel __used,
-				struct perf_session *session)
+				struct machine *machine)
 {
-	struct thread *thread = perf_session__findnew(session, event->ip.pid);
+	struct thread *thread = machine__findnew_thread(machine, event->ip.pid);
 
 	if (thread == NULL) {
 		pr_debug("problem processing %d event, skipping it.\n",

commit d20deb64e0490ee9442b5181bc08a62d2cadcb90
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri Nov 25 08:19:45 2011 -0200

    perf tools: Pass tool context in the the perf_event_ops functions
    
    So that we don't need to have that many globals.
    
    Next steps will remove the 'session' pointer, that in most cases is
    not needed.
    
    Then we can rename perf_event_ops to 'perf_tool' that better describes
    this class hierarchy.
    
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/n/tip-wp4djox7x6w1i2bab1pt4xxp@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 225e963df105..5d01218e50e0 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -303,7 +303,8 @@ static void process_raw_event(union perf_event *raw_event __used, void *data,
 	}
 }
 
-static int process_sample_event(union perf_event *event,
+static int process_sample_event(struct perf_event_ops *ops __used,
+				union perf_event *event,
 				struct perf_sample *sample,
 				struct perf_evsel *evsel __used,
 				struct perf_session *session)

commit 9e69c210822c4035708a6111567c96364ca244d5
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Mar 15 15:44:01 2011 -0300

    perf session: Pass evsel in event_ops->sample()
    
    Resolving the sample->id to an evsel since the most advanced tools,
    report and annotate, and the others will too when they evolve to
    properly support multi-event perf.data files.
    
    Good also because it does an extra validation, checking that the ID is
    valid when present. When that is not the case, the overhead is just a
    branch + function call (perf_evlist__id2evsel).
    
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Tom Zanussi <tzanussi@gmail.com>
    LKML-Reference: <new-submission>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 7f618f4e7b79..225e963df105 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -305,6 +305,7 @@ static void process_raw_event(union perf_event *raw_event __used, void *data,
 
 static int process_sample_event(union perf_event *event,
 				struct perf_sample *sample,
+				struct perf_evsel *evsel __used,
 				struct perf_session *session)
 {
 	struct thread *thread = perf_session__findnew(session, event->ip.pid);

commit 8115d60c323dd9931b95221c0a392aeddc1d6ef3
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sat Jan 29 14:01:45 2011 -0200

    perf tools: Kill event_t typedef, use 'union perf_event' instead
    
    And move the event_t methods to the perf_event__ too.
    
    No code changes, just namespace consistency.
    
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Tom Zanussi <tzanussi@gmail.com>
    LKML-Reference: <new-submission>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 3c1cdcf29902..7f618f4e7b79 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -275,9 +275,8 @@ static void process_free_event(void *data,
 	s_alloc->alloc_cpu = -1;
 }
 
-static void
-process_raw_event(event_t *raw_event __used, void *data,
-		  int cpu, u64 timestamp, struct thread *thread)
+static void process_raw_event(union perf_event *raw_event __used, void *data,
+			      int cpu, u64 timestamp, struct thread *thread)
 {
 	struct event *event;
 	int type;
@@ -304,7 +303,8 @@ process_raw_event(event_t *raw_event __used, void *data,
 	}
 }
 
-static int process_sample_event(event_t *event, struct perf_sample *sample,
+static int process_sample_event(union perf_event *event,
+				struct perf_sample *sample,
 				struct perf_session *session)
 {
 	struct thread *thread = perf_session__findnew(session, event->ip.pid);
@@ -325,7 +325,7 @@ static int process_sample_event(event_t *event, struct perf_sample *sample,
 
 static struct perf_event_ops event_ops = {
 	.sample			= process_sample_event,
-	.comm			= event__process_comm,
+	.comm			= perf_event__process_comm,
 	.ordered_samples	= true,
 };
 

commit 8d50e5b4171a69cf48ca94a1e7c14033d0b4771d
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sat Jan 29 13:02:00 2011 -0200

    perf tools: Rename 'struct sample_data' to 'struct perf_sample'
    
    Making the namespace more uniform.
    
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Tom Zanussi <tzanussi@gmail.com>
    LKML-Reference: <new-submission>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index d97256d65980..3c1cdcf29902 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -304,7 +304,7 @@ process_raw_event(event_t *raw_event __used, void *data,
 	}
 }
 
-static int process_sample_event(event_t *event, struct sample_data *sample,
+static int process_sample_event(event_t *event, struct perf_sample *sample,
 				struct perf_session *session)
 {
 	struct thread *thread = perf_session__findnew(session, event->ip.pid);

commit 9486aa38771661e96fbb51c549b9901b5df609d8
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sat Jan 22 20:37:02 2011 -0200

    perf tools: Fix 64 bit integer format strings
    
    Using %L[uxd] has issues in some architectures, like on ppc64.  Fix it
    by making our 64 bit integers typedefs of stdint.h types and using
    PRI[ux]64 like, for instance, git does.
    
    Reported by Denis Kirjanov that provided a patch for one case, I went
    and changed all cases.
    
    Reported-by: Denis Kirjanov <dkirjanov@kernel.org>
    Tested-by: Denis Kirjanov <dkirjanov@kernel.org>
    LKML-Reference: <20110120093246.GA8031@hera.kernel.org>
    Cc: Denis Kirjanov <dkirjanov@kernel.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Pingtian Han <phan@redhat.com>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Tom Zanussi <tzanussi@gmail.com>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index def7ddc2fd4f..d97256d65980 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -371,10 +371,10 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 			addr = data->ptr;
 
 		if (sym != NULL)
-			snprintf(buf, sizeof(buf), "%s+%Lx", sym->name,
+			snprintf(buf, sizeof(buf), "%s+%" PRIx64 "", sym->name,
 				 addr - map->unmap_ip(map, sym->start));
 		else
-			snprintf(buf, sizeof(buf), "%#Lx", addr);
+			snprintf(buf, sizeof(buf), "%#" PRIx64 "", addr);
 		printf(" %-34s |", buf);
 
 		printf(" %9llu/%-5lu | %9llu/%-5lu | %8lu | %8lu | %6.3f%%\n",

commit 21ef97f05a7da5bc23b26cb34d6746f83ca9bf20
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Fri Dec 10 14:09:16 2010 +1100

    perf session: Fallback to unordered processing if no sample_id_all
    
    If we are running the new perf on an old kernel without support for
    sample_id_all, we should fall back to the old unordered processing of
    events. If we didn't than we would *always* process events without
    timestamps out of order, whether or not we hit a reordering race. In
    other words, instead of there being a chance of not attributing samples
    correctly, we would guarantee that samples would not be attributed.
    
    While processing all events without timestamps before events with
    timestamps may seem like an intuitive solution, it falls down as
    PERF_RECORD_EXIT events would also be processed before any samples.
    Even with a workaround for that case, samples before/after an exec would
    not be attributed correctly.
    
    This patch allows commands to indicate whether they need to fall back to
    unordered processing, so that commands that do not care about timestamps
    on every event will not be affected. If we do fallback, this will print
    out a warning if report -D was invoked.
    
    This patch adds the test in perf_session__new so that we only need to
    test once per session. Commands that do not use an event_ops (such as
    record and top) can simply pass NULL in it's place.
    
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    LKML-Reference: <1291951882-sup-6069@au1.ibm.com>
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index c9620ff6496f..def7ddc2fd4f 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -481,7 +481,8 @@ static void sort_result(void)
 static int __cmd_kmem(void)
 {
 	int err = -EINVAL;
-	struct perf_session *session = perf_session__new(input_name, O_RDONLY, 0, false);
+	struct perf_session *session = perf_session__new(input_name, O_RDONLY,
+							 0, false, &event_ops);
 	if (session == NULL)
 		return -ENOMEM;
 

commit ce47dc56a2241dc035160a85bc5e34283cdd622c
Author: Chris Samuel <chris@csamuel.org>
Date:   Sat Nov 13 13:35:06 2010 +1100

    perf tools: Catch a few uncheck calloc/malloc's
    
    There were a few stray calloc()'s and malloc()'s which were not having
    their return values checked for success.
    
    As the calling code either already coped with failure or didn't actually
    care we just return -ENOMEM at that point.
    
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Chris Samuel <chris@csamuel.org>
    LKML-Reference: <4CDDF95A.1050400@csamuel.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index d0a652e9c708..c9620ff6496f 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -736,6 +736,9 @@ static int __cmd_record(int argc, const char **argv)
 	rec_argc = ARRAY_SIZE(record_args) + argc - 1;
 	rec_argv = calloc(rec_argc + 1, sizeof(char *));
 
+	if (rec_argv == NULL)
+		return -ENOMEM;
+
 	for (i = 0; i < ARRAY_SIZE(record_args); i++)
 		rec_argv[i] = strdup(record_args[i]);
 

commit 640c03ce837fe8d4b56342aba376ea0da3960459
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Dec 2 14:10:21 2010 -0200

    perf session: Parse sample earlier
    
    At perf_session__process_event, so that we reduce the number of lines in eache
    tool sample processing routine that now receives a sample_data pointer already
    parsed.
    
    This will also be useful in the next patch, where we'll allow sample the
    identity fields in MMAP, FORK, EXIT, etc, when it will be possible to see (cpu,
    timestamp) just after before every event.
    
    Also validate callchains in perf_session__process_event, i.e. as early as
    possible, and keep a counter of the number of events discarded due to invalid
    callchains, warning the user about it if it happens.
    
    There is an assumption that was kept that all events have the same sample_type,
    that will be dealt with in the future, when this preexisting limitation will be
    removed.
    
    Tested-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Ian Munsie <imunsie@au1.ibm.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Ian Munsie <imunsie@au1.ibm.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Stephane Eranian <eranian@google.com>
    LKML-Reference: <1291318772-30880-4-git-send-email-acme@infradead.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 31f60a2535e0..d0a652e9c708 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -304,22 +304,11 @@ process_raw_event(event_t *raw_event __used, void *data,
 	}
 }
 
-static int process_sample_event(event_t *event, struct perf_session *session)
+static int process_sample_event(event_t *event, struct sample_data *sample,
+				struct perf_session *session)
 {
-	struct sample_data data;
-	struct thread *thread;
+	struct thread *thread = perf_session__findnew(session, event->ip.pid);
 
-	memset(&data, 0, sizeof(data));
-	data.time = -1;
-	data.cpu = -1;
-	data.period = 1;
-
-	event__parse_sample(event, session->sample_type, &data);
-
-	dump_printf("(IP, %d): %d/%d: %#Lx period: %Ld\n", event->header.misc,
-		    data.pid, data.tid, data.ip, data.period);
-
-	thread = perf_session__findnew(session, event->ip.pid);
 	if (thread == NULL) {
 		pr_debug("problem processing %d event, skipping it.\n",
 			 event->header.type);
@@ -328,8 +317,8 @@ static int process_sample_event(event_t *event, struct perf_session *session)
 
 	dump_printf(" ... thread: %s:%d\n", thread->comm, thread->pid);
 
-	process_raw_event(event, data.raw_data, data.cpu,
-			  data.time, thread);
+	process_raw_event(event, sample->raw_data, sample->cpu,
+			  sample->time, thread);
 
 	return 0;
 }

commit 454c407ec17a0c63e4023ac0877d687945a7df4a
Author: Tom Zanussi <tzanussi@gmail.com>
Date:   Sat May 1 01:41:20 2010 -0500

    perf: add perf-inject builtin
    
    Currently, perf 'live mode' writes build-ids at the end of the
    session, which isn't actually useful for processing live mode events.
    
    What would be better would be to have the build-ids sent before any of
    the samples that reference them, which can be done by processing the
    event stream and retrieving the build-ids on the first hit.  Doing
    that in perf-record itself, however, is off-limits.
    
    This patch introduces perf-inject, which does the same job while
    leaving perf-record untouched.  Normal mode perf still records the
    build-ids at the end of the session as it should, but for live mode,
    perf-inject can be injected in between the record and report steps
    e.g.:
    
    perf record -o - ./hackbench 10 | perf inject -v -b | perf report -v -i -
    
    perf-inject reads a perf-record event stream and repipes it to stdout.
    At any point the processing code can inject other events into the
    event stream - in this case build-ids (-b option) are read and
    injected as needed into the event stream.
    
    Build-ids are just the first user of perf-inject - potentially
    anything that needs userspace processing to augment the trace stream
    with additional information could make use of this facility.
    
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    LKML-Reference: <1272696080-16435-3-git-send-email-tzanussi@gmail.com>
    Signed-off-by: Tom Zanussi <tzanussi@gmail.com>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index ee05dba9609a..31f60a2535e0 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -492,7 +492,7 @@ static void sort_result(void)
 static int __cmd_kmem(void)
 {
 	int err = -EINVAL;
-	struct perf_session *session = perf_session__new(input_name, O_RDONLY, 0);
+	struct perf_session *session = perf_session__new(input_name, O_RDONLY, 0, false);
 	if (session == NULL)
 		return -ENOMEM;
 

commit 5c0541d53ef3897494768decb09eb8f1087953a5
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Apr 29 15:25:23 2010 -0300

    perf symbols: Add machine helper routines
    
    Created when writing the first 'perf test' regression testing routine.
    
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    LKML-Reference: <new-submission>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 15635612e596..ee05dba9609a 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -377,7 +377,7 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 		if (is_caller) {
 			addr = data->call_site;
 			if (!raw_ip)
-				sym = machine__find_function(machine, addr, &map, NULL);
+				sym = machine__find_kernel_function(machine, addr, &map, NULL);
 		} else
 			addr = data->ptr;
 

commit d28c62232e50eab202bcd3f19b5c7a25b8b900b6
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Apr 27 21:20:43 2010 -0300

    perf machine: Adopt some map_groups functions
    
    Those functions operated on members now grouped in 'struct machine', so
    move those methods to this new class.
    
    The changes made to 'perf probe' shows that using this abstraction
    inserting probes on guests almost got supported for free.
    
    Cc: Avi Kivity <avi@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Masami Hiramatsu <mhiramat@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Zhang, Yanmin <yanmin_zhang@linux.intel.com>
    LKML-Reference: <new-submission>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 20674759464e..15635612e596 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -370,7 +370,6 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 		struct alloc_stat *data = rb_entry(next, struct alloc_stat,
 						   node);
 		struct symbol *sym = NULL;
-		struct map_groups *kmaps = &machine->kmaps;
 		struct map *map;
 		char buf[BUFSIZ];
 		u64 addr;
@@ -378,8 +377,7 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 		if (is_caller) {
 			addr = data->call_site;
 			if (!raw_ip)
-				sym = map_groups__find_function(kmaps, addr,
-								&map, NULL);
+				sym = machine__find_function(machine, addr, &map, NULL);
 		} else
 			addr = data->ptr;
 

commit 23346f21b277e3aae5e9989e711a11cbe8133a45
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Apr 27 21:17:50 2010 -0300

    perf tools: Rename "kernel_info" to "machine"
    
    struct kernel_info and kerninfo__ are too vague, what they really
    describe are machines, virtual ones or hosts.
    
    There are more changes to introduce helpers to shorten function calls
    and to make more clear what is really being done, but I left that for
    subsequent patches.
    
    Cc: Avi Kivity <avi@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Zhang, Yanmin <yanmin_zhang@linux.intel.com>
    LKML-Reference: <new-submission>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index ab906cbd5c79..20674759464e 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -352,7 +352,7 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 			   int n_lines, int is_caller)
 {
 	struct rb_node *next;
-	struct kernel_info *kerninfo;
+	struct machine *machine;
 
 	printf("%.102s\n", graph_dotted_line);
 	printf(" %-34s |",  is_caller ? "Callsite": "Alloc Ptr");
@@ -361,8 +361,8 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 
 	next = rb_first(root);
 
-	kerninfo = kerninfo__findhost(&session->kerninfo_root);
-	if (!kerninfo) {
+	machine = perf_session__find_host_machine(session);
+	if (!machine) {
 		pr_err("__print_result: couldn't find kernel information\n");
 		return;
 	}
@@ -370,7 +370,7 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 		struct alloc_stat *data = rb_entry(next, struct alloc_stat,
 						   node);
 		struct symbol *sym = NULL;
-		struct map_groups *kmaps = &kerninfo->kmaps;
+		struct map_groups *kmaps = &machine->kmaps;
 		struct map *map;
 		char buf[BUFSIZ];
 		u64 addr;

commit 587570d4cc3cac80da7d569bee9cea3ca104d60e
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Sat Apr 24 00:34:53 2010 +0200

    perf: Use generic sample reordering in perf kmem
    
    Use the new generic sample events reordering from perf kmem,
    this drops the need of multiplexing the buffers on record time,
    improving the scalability of perf kmem.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Hitoshi Mitake <mitake@dcl.info.waseda.ac.jp>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Masami Hiramatsu <mhiramat@redhat.com>
    Cc: Tom Zanussi <tzanussi@gmail.com>
    Cc: Pekka Enberg <penberg@cs.helsinki.fi>
    Cc: Li Zefan <lizf@cn.fujitsu.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index db474bbf3322..ab906cbd5c79 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -335,8 +335,9 @@ static int process_sample_event(event_t *event, struct perf_session *session)
 }
 
 static struct perf_event_ops event_ops = {
-	.sample	= process_sample_event,
-	.comm	= event__process_comm,
+	.sample			= process_sample_event,
+	.comm			= event__process_comm,
+	.ordered_samples	= true,
 };
 
 static double fragmentation(unsigned long n_req, unsigned long n_alloc)
@@ -730,7 +731,6 @@ static const char *record_args[] = {
 	"record",
 	"-a",
 	"-R",
-	"-M",
 	"-f",
 	"-c", "1",
 	"-e", "kmem:kmalloc",

commit a1645ce12adb6c9cc9e19d7695466204e3f017fe
Author: Zhang, Yanmin <yanmin_zhang@linux.intel.com>
Date:   Mon Apr 19 13:32:50 2010 +0800

    perf: 'perf kvm' tool for monitoring guest performance from host
    
    Here is the patch of userspace perf tool.
    
    Signed-off-by: Zhang Yanmin <yanmin_zhang@linux.intel.com>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 513aa8a55db6..db474bbf3322 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -351,6 +351,7 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 			   int n_lines, int is_caller)
 {
 	struct rb_node *next;
+	struct kernel_info *kerninfo;
 
 	printf("%.102s\n", graph_dotted_line);
 	printf(" %-34s |",  is_caller ? "Callsite": "Alloc Ptr");
@@ -359,10 +360,16 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 
 	next = rb_first(root);
 
+	kerninfo = kerninfo__findhost(&session->kerninfo_root);
+	if (!kerninfo) {
+		pr_err("__print_result: couldn't find kernel information\n");
+		return;
+	}
 	while (next && n_lines--) {
 		struct alloc_stat *data = rb_entry(next, struct alloc_stat,
 						   node);
 		struct symbol *sym = NULL;
+		struct map_groups *kmaps = &kerninfo->kmaps;
 		struct map *map;
 		char buf[BUFSIZ];
 		u64 addr;
@@ -370,8 +377,8 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 		if (is_caller) {
 			addr = data->call_site;
 			if (!raw_ip)
-				sym = map_groups__find_function(&session->kmaps,
-								addr, &map, NULL);
+				sym = map_groups__find_function(kmaps, addr,
+								&map, NULL);
 		} else
 			addr = data->ptr;
 

commit 71cf8b8ff7d6a79af086be9e4c72628da9d62d58
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Apr 1 21:24:38 2010 -0300

    perf kmem: Fixup the symbol address before using it
    
    We get absolute addresses in the events, but relative ones from the
    symbol subsystem, so calculate the absolute address by asking for the
    map where the symbol was found, that has the place where the DSO was
    actually loaded.
    
    For the core kernel this poses no problems if the kernel is not
    relocated by things like kexec, or if we use /proc/kallsyms, but for
    modules we were getting really large, negative offsets.
    
    LKML-Reference: <new-submission>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 7cbb5eb15101..513aa8a55db6 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -363,6 +363,7 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 		struct alloc_stat *data = rb_entry(next, struct alloc_stat,
 						   node);
 		struct symbol *sym = NULL;
+		struct map *map;
 		char buf[BUFSIZ];
 		u64 addr;
 
@@ -370,13 +371,13 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 			addr = data->call_site;
 			if (!raw_ip)
 				sym = map_groups__find_function(&session->kmaps,
-								addr, NULL, NULL);
+								addr, &map, NULL);
 		} else
 			addr = data->ptr;
 
 		if (sym != NULL)
 			snprintf(buf, sizeof(buf), "%s+%Lx", sym->name,
-				 addr - sym->start);
+				 addr - map->unmap_ip(map, sym->start));
 		else
 			snprintf(buf, sizeof(buf), "%#Lx", addr);
 		printf(" %-34s |", buf);

commit e727ca73f85d4c5be3547eda674168219d1c22d8
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Apr 1 19:12:13 2010 -0300

    perf kmem: Resolve kernel symbols again
    
    Due to the assumption in perf_session__new that the kernel maps would be
    created using the fake PERF_RECORD_MMAP event in a perf.data file 'perf
    kmem --stat caller', that doesn't have such event, ends up not being
    able to resolve the kernel addresses.
    
    Fix it by calling perf_session__create_kernel_maps() in __cmd_kmem().
    
    LKML-Reference: <new-submission>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 32edb6a86876..7cbb5eb15101 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -489,6 +489,9 @@ static int __cmd_kmem(void)
 	if (session == NULL)
 		return -ENOMEM;
 
+	if (perf_session__create_kernel_maps(session) < 0)
+		goto out_delete;
+
 	if (!perf_session__has_traces(session, "kmem record"))
 		goto out_delete;
 

commit 7e5e1b1404c30db5f6bc3f5203b6c21c1d244f99
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri Mar 26 12:30:40 2010 -0300

    perf symbols: map_groups__find_symbol must return the map too
    
    Tools need to know from which map in the map_group a symbol was resolved
    to, so that, for isntance, we can annotate kernel modules symbols by
    getting its precise name, etc.
    
    Also add the _by_name variants for completeness.
    
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 924a9518931a..32edb6a86876 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -369,7 +369,8 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 		if (is_caller) {
 			addr = data->call_site;
 			if (!raw_ip)
-				sym = map_groups__find_function(&session->kmaps, addr, NULL);
+				sym = map_groups__find_function(&session->kmaps,
+								addr, NULL, NULL);
 		} else
 			addr = data->ptr;
 

commit 9de89fe7c577847877ae00ea1aa6315559b10243
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Feb 3 16:52:00 2010 -0200

    perf symbols: Remove perf_session usage in symbols layer
    
    I noticed while writing the first test in 'perf regtest' that to
    just test the symbol handling routines one needs to create a
    perf session, that is a layer centered on a perf.data file,
    events, etc, so I untied these layers.
    
    This reduces the complexity for the users as the number of
    parameters to most of the symbols and session APIs now was
    reduced while not adding more state to all the map instances by
    only having data that is needed to split the kernel (kallsyms
    and ELF symtab sections) maps and do vmlinux relocation on the
    main kernel map.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1265223128-11786-1-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 5d5dc6b09617..924a9518931a 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -369,7 +369,7 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 		if (is_caller) {
 			addr = data->call_site;
 			if (!raw_ip)
-				sym = map_groups__find_function(&session->kmaps, session, addr, NULL);
+				sym = map_groups__find_function(&session->kmaps, addr, NULL);
 		} else
 			addr = data->ptr;
 

commit ae7f6711d6231c9ba54feb5ba9856c3775e482f8
Merge: 64abebf731df b23ff0e9330e
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Jan 29 09:24:57 2010 +0100

    Merge branch 'perf/urgent' into perf/core
    
    Merge reason: We want to queue up a dependent patch. Also update to
                  later -rc's.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 64abebf731df87e6f4ae7d9ffc340bdf0c033e44
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Jan 27 21:05:52 2010 -0200

    perf session: Create kernel maps in the constructor
    
    Removing one extra step needed in the tools that need this,
    fixing a bug in 'perf probe' where this was not being done.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Masami Hiramatsu <mhiramat@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1264633557-17597-4-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 7323d9dfbce8..38b8ca900eda 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -491,11 +491,6 @@ static int __cmd_kmem(void)
 	if (!perf_session__has_traces(session, "kmem record"))
 		goto out_delete;
 
-	if (perf_session__create_kernel_maps(session) < 0) {
-		pr_err("Problems creating kernel maps\n");
-		return -1;
-	}
-
 	setup_pager();
 	err = perf_session__process_events(session, &event_ops);
 	if (err != 0)

commit b00eca8cd66029128615e8be9a19e284a950c0f2
Author: Pekka Enberg <penberg@cs.helsinki.fi>
Date:   Tue Jan 19 19:26:11 2010 +0200

    perf kmem: Print usage help for unknown commands
    
    This patch fixes "perf kmem" to print usage help instead of
    doing nothing.
    
    Signed-off-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
    LKML-Reference: <1263921971-10782-1-git-send-email-penberg@cs.helsinki.fi>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 33bb9dfb8e68..93c67bf53d2c 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -784,7 +784,8 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __used)
 			setup_sorting(&alloc_sort, default_sort_order);
 
 		return __cmd_kmem();
-	}
+	} else
+		usage_with_options(kmem_usage, kmem_options);
 
 	return 0;
 }

commit 47103277f8861dcb48ab845533db331ddb9427ca
Author: Pekka Enberg <penberg@cs.helsinki.fi>
Date:   Tue Jan 19 19:23:23 2010 +0200

    perf kmem: Increase "Hit" column length
    
    It's fairly easy to overflow the "Hit" column with just few
    seconds of tracing so increase the column length to avoid broken
    formatting.
    
    Signed-off-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
    LKML-Reference: <1263921803-10214-1-git-send-email-penberg@cs.helsinki.fi>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 7ceb7416c316..33bb9dfb8e68 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -375,7 +375,7 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 
 	printf("%.102s\n", graph_dotted_line);
 	printf(" %-34s |",  is_caller ? "Callsite": "Alloc Ptr");
-	printf(" Total_alloc/Per | Total_req/Per   | Hit   | Ping-pong | Frag\n");
+	printf(" Total_alloc/Per | Total_req/Per   | Hit      | Ping-pong | Frag\n");
 	printf("%.102s\n", graph_dotted_line);
 
 	next = rb_first(root);
@@ -401,7 +401,7 @@ static void __print_result(struct rb_root *root, struct perf_session *session,
 			snprintf(buf, sizeof(buf), "%#Lx", addr);
 		printf(" %-34s |", buf);
 
-		printf(" %9llu/%-5lu | %9llu/%-5lu | %6lu | %8lu | %6.3f%%\n",
+		printf(" %9llu/%-5lu | %9llu/%-5lu | %8lu | %8lu | %6.3f%%\n",
 		       (unsigned long long)data->bytes_alloc,
 		       (unsigned long)data->bytes_alloc / data->hit,
 		       (unsigned long long)data->bytes_req,

commit 0d755034dbd01e240eadf2d31f4f75d3088ccd21
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Jan 14 12:23:09 2010 -0200

    perf tools: Don't cast RIP to pointers
    
    Since they can come from another architecture with bigger
    pointers, i.e. processing a 64-bit perf.data on a 32-bit arch.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1263478990-8200-1-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 4af7199c5af7..7323d9dfbce8 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -316,11 +316,8 @@ static int process_sample_event(event_t *event, struct perf_session *session)
 
 	event__parse_sample(event, session->sample_type, &data);
 
-	dump_printf("(IP, %d): %d/%d: %p period: %Ld\n",
-		event->header.misc,
-		data.pid, data.tid,
-		(void *)(long)data.ip,
-		(long long)data.period);
+	dump_printf("(IP, %d): %d/%d: %#Lx period: %Ld\n", event->header.misc,
+		    data.pid, data.tid, data.ip, data.period);
 
 	thread = perf_session__findnew(session, event->ip.pid);
 	if (thread == NULL) {

commit b7cece76783c68fb391f9882235b4b0c9c300c46
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Jan 13 13:22:17 2010 -0200

    perf tools: Encode kernel module mappings in perf.data
    
    We were always looking at the running machine /proc/modules,
    even when processing a perf.data file, which only makes sense
    when we're doing 'perf record' and 'perf report' on the same
    machine, and in close sucession, or if we don't use modules at
    all, right Peter? ;-)
    
    Now, at 'perf record' time we read /proc/modules, find the long
    path for modules, and put them as PERF_MMAP events, just like we
    did to encode the reloc reference symbol for vmlinux. Talking
    about that now it is encoded in .pgoff, so that we can use
    .{start,len} to store the address boundaries for the kernel so
    that when we reconstruct the kmaps tree we can do lookups right
    away, without having to fixup the end of the kernel maps like we
    did in the past (and now only in perf record).
    
    One more step in the 'perf archive' direction when we'll finally
    be able to collect data in one machine and analyse in another.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1263396139-4798-1-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 88c570c18e3e..4af7199c5af7 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -494,6 +494,11 @@ static int __cmd_kmem(void)
 	if (!perf_session__has_traces(session, "kmem record"))
 		goto out_delete;
 
+	if (perf_session__create_kernel_maps(session) < 0) {
+		pr_err("Problems creating kernel maps\n");
+		return -1;
+	}
+
 	setup_pager();
 	err = perf_session__process_events(session, &event_ops);
 	if (err != 0)

commit 61405fea92c42d072d9b8bd189689f1502a838af
Merge: 9c443dfdd31e 1703f2c321a8
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Jan 13 09:58:37 2010 +0100

    Merge branch 'perf/urgent' into perf/core
    
    Merge reason: queue up dependent patch, update to -rc4
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 4efb5290ae187514bd31af8c2d7755e175245e19
Author: Wenji Huang <wenji.huang@oracle.com>
Date:   Mon Dec 21 17:52:55 2009 +0800

    perf kmem: Fix statistics typo
    
    Replace bytes_req with bytes_alloc.
    
    Signed-off-by: Wenji Huang <wenji.huang@oracle.com>
    Reviewed-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: acme@redhat.com
    LKML-Reference: <1261389175-2227-1-git-send-email-wenji.huang@oracle.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index fc21ad79dd83..7ceb7416c316 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -137,7 +137,7 @@ static void insert_alloc_stat(unsigned long call_site, unsigned long ptr,
 	if (data && data->ptr == ptr) {
 		data->hit++;
 		data->bytes_req += bytes_req;
-		data->bytes_alloc += bytes_req;
+		data->bytes_alloc += bytes_alloc;
 	} else {
 		data = malloc(sizeof(*data));
 		if (!data)
@@ -177,7 +177,7 @@ static void insert_caller_stat(unsigned long call_site,
 	if (data && data->call_site == call_site) {
 		data->hit++;
 		data->bytes_req += bytes_req;
-		data->bytes_alloc += bytes_req;
+		data->bytes_alloc += bytes_alloc;
 	} else {
 		data = malloc(sizeof(*data));
 		if (!data)

commit 659d8cfbb225f1fa5a4f8671a847ef3ab5a89660
Author: Ulrich Drepper <drepper@redhat.com>
Date:   Sat Dec 19 16:40:28 2009 -0500

    perf tools: Do a few more directory handling optimizations
    
    A few more optimizations for perf when dealing with directories.
    
    Some of them significantly cut down the work which has to be
    done. d_type should always be set; otherwise fix the kernel
    code. And there are functions available to parse fstab-like
    files, so use them.
    
    Signed-off-by: Ulrich Drepper <drepper@redhat.com>
    Acked-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Cc: a.p.zijlstra@chello.nl
    Cc: acme@redhat.com
    Cc: eranian@google.com
    Cc: fweisbec@gmail.com
    Cc: lizf@cn.fujitsu.com
    Cc: paulus@samba.org
    Cc: xiaoguangrong@cn.fujitsu.com
    LKML-Reference: <200912192140.nBJLeSfA028905@hs20-bc2-1.build.redhat.com>
    [ v2: two small stylistic fixlets ]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 4c06828fe39d..05dc5a735039 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -92,23 +92,18 @@ static void setup_cpunode_map(void)
 	if (!dir1)
 		return;
 
-	while (true) {
-		dent1 = readdir(dir1);
-		if (!dent1)
-			break;
-
-		if (sscanf(dent1->d_name, "node%u", &mem) < 1)
+	while ((dent1 = readdir(dir1)) != NULL) {
+		if (dent1->d_type != DT_DIR ||
+		    sscanf(dent1->d_name, "node%u", &mem) < 1)
 			continue;
 
 		snprintf(buf, PATH_MAX, "%s/%s", PATH_SYS_NODE, dent1->d_name);
 		dir2 = opendir(buf);
 		if (!dir2)
 			continue;
-		while (true) {
-			dent2 = readdir(dir2);
-			if (!dent2)
-				break;
-			if (sscanf(dent2->d_name, "cpu%u", &cpu) < 1)
+		while ((dent2 = readdir(dir2)) != NULL) {
+			if (dent2->d_type != DT_LNK ||
+			    sscanf(dent2->d_name, "cpu%u", &cpu) < 1)
 				continue;
 			cpunode_map[cpu] = mem;
 		}

commit 55aa640f54280da25046acd2075842d464f451e6
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sun Dec 27 21:37:05 2009 -0200

    perf session: Remove redundant prefix & suffix from perf_event_ops
    
    Since now all that we have are perf event handlers, leave just
    the name of the event.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1261957026-15580-9-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 73b065022e27..4c06828fe39d 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -343,8 +343,8 @@ static int process_sample_event(event_t *event, struct perf_session *session)
 }
 
 static struct perf_event_ops event_ops = {
-	.process_sample_event	= process_sample_event,
-	.process_comm_event	= event__process_comm,
+	.sample	= process_sample_event,
+	.comm	= event__process_comm,
 };
 
 static double fragmentation(unsigned long n_req, unsigned long n_alloc)

commit d549c7690190d9739005e19604faad6da4b802ac
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sun Dec 27 21:37:02 2009 -0200

    perf session: Remove sample_type_check from event_ops
    
    This is really something tools need to do before asking for the
    events to be processed, leaving perf_session__process_events to
    do just that, process events.
    
    Also add a msg parameter to perf_session__has_traces() so that
    the right message can be printed, fixing a regression added by
    me in the previous cset (right timechart message) and also
    fixing 'perf kmem', that was not asking if 'perf kmem record'
    was ran.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1261957026-15580-6-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index a85936f09f3e..73b065022e27 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -345,7 +345,6 @@ static int process_sample_event(event_t *event, struct perf_session *session)
 static struct perf_event_ops event_ops = {
 	.process_sample_event	= process_sample_event,
 	.process_comm_event	= event__process_comm,
-	.sample_type_check	= perf_session__has_traces,
 };
 
 static double fragmentation(unsigned long n_req, unsigned long n_alloc)
@@ -492,11 +491,14 @@ static void sort_result(void)
 
 static int __cmd_kmem(void)
 {
-	int err;
+	int err = -EINVAL;
 	struct perf_session *session = perf_session__new(input_name, O_RDONLY, 0);
 	if (session == NULL)
 		return -ENOMEM;
 
+	if (!perf_session__has_traces(session, "kmem record"))
+		goto out_delete;
+
 	setup_pager();
 	err = perf_session__process_events(session, &event_ops);
 	if (err != 0)

commit 27295592c22e71bbd38110c302da8dbb43912a60
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sun Dec 27 21:37:01 2009 -0200

    perf session: Share the common trace sample_check routine as perf_session__has_traces
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1261957026-15580-5-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index fc21ad79dd83..a85936f09f3e 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -342,22 +342,10 @@ static int process_sample_event(event_t *event, struct perf_session *session)
 	return 0;
 }
 
-static int sample_type_check(struct perf_session *session)
-{
-	if (!(session->sample_type & PERF_SAMPLE_RAW)) {
-		fprintf(stderr,
-			"No trace sample to read. Did you call perf record "
-			"without -R?");
-		return -1;
-	}
-
-	return 0;
-}
-
 static struct perf_event_ops event_ops = {
 	.process_sample_event	= process_sample_event,
 	.process_comm_event	= event__process_comm,
-	.sample_type_check	= sample_type_check,
+	.sample_type_check	= perf_session__has_traces,
 };
 
 static double fragmentation(unsigned long n_req, unsigned long n_alloc)

commit 655000e7c75a559681ee7f15f6fa870c80ae3194
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Dec 15 20:04:40 2009 -0200

    perf symbols: Adopt the strlists for dso, comm
    
    Will be used in perf diff too.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1260914682-29652-2-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index e078797ab1f1..fc21ad79dd83 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -766,13 +766,13 @@ static int __cmd_record(int argc, const char **argv)
 
 int cmd_kmem(int argc, const char **argv, const char *prefix __used)
 {
-	symbol__init();
-
 	argc = parse_options(argc, argv, kmem_options, kmem_usage, 0);
 
 	if (!argc)
 		usage_with_options(kmem_usage, kmem_options);
 
+	symbol__init();
+
 	if (!strncmp(argv[0], "rec", 3)) {
 		return __cmd_record(argc, argv);
 	} else if (!strcmp(argv[0], "stat")) {

commit 75be6cf48738aec68aac49b428423569492cfba3
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Dec 15 20:04:39 2009 -0200

    perf symbols: Make symbol_conf global
    
    This simplifies a lot of functions, less stuff to be done by
    tool writers.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1260914682-29652-1-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index dda60869faad..e078797ab1f1 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -505,8 +505,7 @@ static void sort_result(void)
 static int __cmd_kmem(void)
 {
 	int err;
-	struct perf_session *session = perf_session__new(input_name, O_RDONLY,
-							 0, NULL);
+	struct perf_session *session = perf_session__new(input_name, O_RDONLY, 0);
 	if (session == NULL)
 		return -ENOMEM;
 
@@ -767,7 +766,7 @@ static int __cmd_record(int argc, const char **argv)
 
 int cmd_kmem(int argc, const char **argv, const char *prefix __used)
 {
-	symbol__init(0);
+	symbol__init();
 
 	argc = parse_options(argc, argv, kmem_options, kmem_usage, 0);
 

commit c019879bcc5692ec9267c1cedad91f1794d0b693
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Dec 14 14:23:00 2009 -0200

    perf session: Adopt the sample_type variable
    
    All tools had copies, and perf diff would have to specify a
    sample_type_check method just for copying it.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1260807780-19377-2-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 3b329c66b505..dda60869faad 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -20,8 +20,6 @@ typedef int (*sort_fn_t)(struct alloc_stat *, struct alloc_stat *);
 
 static char const		*input_name = "perf.data";
 
-static u64			sample_type;
-
 static int			alloc_flag;
 static int			caller_flag;
 
@@ -321,7 +319,7 @@ static int process_sample_event(event_t *event, struct perf_session *session)
 	data.cpu = -1;
 	data.period = 1;
 
-	event__parse_sample(event, sample_type, &data);
+	event__parse_sample(event, session->sample_type, &data);
 
 	dump_printf("(IP, %d): %d/%d: %p period: %Ld\n",
 		event->header.misc,
@@ -344,11 +342,9 @@ static int process_sample_event(event_t *event, struct perf_session *session)
 	return 0;
 }
 
-static int sample_type_check(u64 type, struct perf_session *session __used)
+static int sample_type_check(struct perf_session *session)
 {
-	sample_type = type;
-
-	if (!(sample_type & PERF_SAMPLE_RAW)) {
+	if (!(session->sample_type & PERF_SAMPLE_RAW)) {
 		fprintf(stderr,
 			"No trace sample to read. Did you call perf record "
 			"without -R?");

commit 4e4f06e4c8f17ea96f7dd76251cab99511026401
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Dec 14 13:10:39 2009 -0200

    perf session: Move the hist_entries rb tree to perf_session
    
    As we'll need to sort multiple times for multiple perf sessions,
    so that we can then do a diff.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1260803439-16783-1-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index e79ecbc17181..3b329c66b505 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -344,7 +344,7 @@ static int process_sample_event(event_t *event, struct perf_session *session)
 	return 0;
 }
 
-static int sample_type_check(u64 type)
+static int sample_type_check(u64 type, struct perf_session *session __used)
 {
 	sample_type = type;
 

commit 4aa65636411ccb12f006a6ad593930655c445ff6
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sun Dec 13 19:50:29 2009 -0200

    perf session: Move kmaps to perf_session
    
    There is still some more work to do to disentangle map creation
    from DSO loading, but this happens only for the kernel, and for
    the early adopters of perf diff, where this disentanglement
    matters most, we'll be testing different kernels, so no problem
    here.
    
    Further clarification: right now we create the kernel maps for
    the various modules and discontiguous kernel text maps when
    loading the DSO, we should do it as a two step process, first
    creating the maps, for multiple mappings with the same DSO
    store, then doing the dso load just once, for the first hit on
    one of the maps sharing this DSO backing store.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1260741029-4430-6-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index de194958fe6e..e79ecbc17181 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -364,19 +364,6 @@ static struct perf_event_ops event_ops = {
 	.sample_type_check	= sample_type_check,
 };
 
-static int read_events(void)
-{
-	int err;
-	struct perf_session *session = perf_session__new(input_name, O_RDONLY, 0);
-
-	if (session == NULL)
-		return -ENOMEM;
-
-	err = perf_session__process_events(session, &event_ops);
-	perf_session__delete(session);
-	return err;
-}
-
 static double fragmentation(unsigned long n_req, unsigned long n_alloc)
 {
 	if (n_alloc == 0)
@@ -385,7 +372,8 @@ static double fragmentation(unsigned long n_req, unsigned long n_alloc)
 		return 100.0 - (100.0 * n_req / n_alloc);
 }
 
-static void __print_result(struct rb_root *root, int n_lines, int is_caller)
+static void __print_result(struct rb_root *root, struct perf_session *session,
+			   int n_lines, int is_caller)
 {
 	struct rb_node *next;
 
@@ -406,7 +394,7 @@ static void __print_result(struct rb_root *root, int n_lines, int is_caller)
 		if (is_caller) {
 			addr = data->call_site;
 			if (!raw_ip)
-				sym = map_groups__find_function(kmaps, addr, NULL);
+				sym = map_groups__find_function(&session->kmaps, session, addr, NULL);
 		} else
 			addr = data->ptr;
 
@@ -447,12 +435,12 @@ static void print_summary(void)
 	printf("Cross CPU allocations: %lu/%lu\n", nr_cross_allocs, nr_allocs);
 }
 
-static void print_result(void)
+static void print_result(struct perf_session *session)
 {
 	if (caller_flag)
-		__print_result(&root_caller_sorted, caller_lines, 1);
+		__print_result(&root_caller_sorted, session, caller_lines, 1);
 	if (alloc_flag)
-		__print_result(&root_alloc_sorted, alloc_lines, 0);
+		__print_result(&root_alloc_sorted, session, alloc_lines, 0);
 	print_summary();
 }
 
@@ -520,12 +508,21 @@ static void sort_result(void)
 
 static int __cmd_kmem(void)
 {
+	int err;
+	struct perf_session *session = perf_session__new(input_name, O_RDONLY,
+							 0, NULL);
+	if (session == NULL)
+		return -ENOMEM;
+
 	setup_pager();
-	read_events();
+	err = perf_session__process_events(session, &event_ops);
+	if (err != 0)
+		goto out_delete;
 	sort_result();
-	print_result();
-
-	return 0;
+	print_result(session);
+out_delete:
+	perf_session__delete(session);
+	return err;
 }
 
 static const char * const kmem_usage[] = {

commit b3165f414416a717f72a376720564012af5a2e01
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sun Dec 13 19:50:28 2009 -0200

    perf session: Move the global threads list to perf_session
    
    So that we can process two perf.data files.
    
    We still need to add a O_MMAP mode for perf_session so that we
    can do all the mmap stuff in it.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1260741029-4430-5-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 237155fa756b..de194958fe6e 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -311,7 +311,7 @@ process_raw_event(event_t *raw_event __used, void *data,
 	}
 }
 
-static int process_sample_event(event_t *event, struct perf_session *session __used)
+static int process_sample_event(event_t *event, struct perf_session *session)
 {
 	struct sample_data data;
 	struct thread *thread;
@@ -329,7 +329,7 @@ static int process_sample_event(event_t *event, struct perf_session *session __u
 		(void *)(long)data.ip,
 		(long long)data.period);
 
-	thread = threads__findnew(event->ip.pid);
+	thread = perf_session__findnew(session, event->ip.pid);
 	if (thread == NULL) {
 		pr_debug("problem processing %d event, skipping it.\n",
 			 event->header.type);

commit ec913369733923dbfd6bdff5953a918107059701
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sun Dec 13 19:50:27 2009 -0200

    perf session: Reduce the number of parms to perf_session__process_events
    
    By having the cwd/cwdlen in the perf_session struct and
    full_paths in perf_event_ops.
    
    Now its just a matter of passing the ops.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1260741029-4430-4-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 37a849906afe..237155fa756b 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -372,8 +372,7 @@ static int read_events(void)
 	if (session == NULL)
 		return -ENOMEM;
 
-	err = perf_session__process_events(session, &event_ops, 0,
-					   &event__cwdlen, &event__cwd);
+	err = perf_session__process_events(session, &event_ops);
 	perf_session__delete(session);
 	return err;
 }

commit 13df45ca1c9a430d5f53862854070fcc324e015c
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sun Dec 13 19:50:26 2009 -0200

    perf session: Register the idle thread in perf_session__process_events
    
    No need for all tools to register it and then immediately call
    perf_session__process_events.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1260741029-4430-3-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 6f74bd8d20e6..37a849906afe 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -372,7 +372,6 @@ static int read_events(void)
 	if (session == NULL)
 		return -ENOMEM;
 
-	register_idle_thread();
 	err = perf_session__process_events(session, &event_ops, 0,
 					   &event__cwdlen, &event__cwd);
 	perf_session__delete(session);

commit 301a0b020210360c6e441c7765521248bc87d58e
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sun Dec 13 19:50:25 2009 -0200

    perf session: Ditch register_perf_file_handler
    
    Pass the event_ops to perf_session__process_events instead.
    
    Also move the event_ops definition to session.h, starting to
    move things around to their right place, trimming the many
    unneeded headers we have.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1260741029-4430-2-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 101b2682b4df..6f74bd8d20e6 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -12,7 +12,6 @@
 #include "util/trace-event.h"
 
 #include "util/debug.h"
-#include "util/data_map.h"
 
 #include <linux/rbtree.h>
 
@@ -359,7 +358,7 @@ static int sample_type_check(u64 type)
 	return 0;
 }
 
-static struct perf_file_handler file_handler = {
+static struct perf_event_ops event_ops = {
 	.process_sample_event	= process_sample_event,
 	.process_comm_event	= event__process_comm,
 	.sample_type_check	= sample_type_check,
@@ -374,9 +373,8 @@ static int read_events(void)
 		return -ENOMEM;
 
 	register_idle_thread();
-	register_perf_file_handler(&file_handler);
-
-	err = perf_session__process_events(session, 0, &event__cwdlen, &event__cwd);
+	err = perf_session__process_events(session, &event_ops, 0,
+					   &event__cwdlen, &event__cwd);
 	perf_session__delete(session);
 	return err;
 }

commit d8f66248d6f25f7c935cc5307c43bf394db07272
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sun Dec 13 19:50:24 2009 -0200

    perf session: Pass the perf_session to the event handling operations
    
    They will need it to get the right threads list, etc.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1260741029-4430-1-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 2071d2485913..101b2682b4df 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -312,7 +312,7 @@ process_raw_event(event_t *raw_event __used, void *data,
 	}
 }
 
-static int process_sample_event(event_t *event)
+static int process_sample_event(event_t *event, struct perf_session *session __used)
 {
 	struct sample_data data;
 	struct thread *thread;

commit 94c744b6c0c6c5802a85ebfebbec429ac5851f2b
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri Dec 11 21:24:02 2009 -0200

    perf tools: Introduce perf_session class
    
    That does all the initialization boilerplate, opening the file,
    reading the header, checking if it is valid, etc.
    
    And that will as well have the threads list, kmap (now) global
    variable, etc, so that we can handle two (or more) perf.data files
    describing sessions to compare.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1260573842-19720-1-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index fe73435192b3..2071d2485913 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -6,6 +6,7 @@
 #include "util/symbol.h"
 #include "util/thread.h"
 #include "util/header.h"
+#include "util/session.h"
 
 #include "util/parse-options.h"
 #include "util/trace-event.h"
@@ -20,7 +21,6 @@ typedef int (*sort_fn_t)(struct alloc_stat *, struct alloc_stat *);
 
 static char const		*input_name = "perf.data";
 
-static struct perf_header	*header;
 static u64			sample_type;
 
 static int			alloc_flag;
@@ -367,11 +367,18 @@ static struct perf_file_handler file_handler = {
 
 static int read_events(void)
 {
+	int err;
+	struct perf_session *session = perf_session__new(input_name, O_RDONLY, 0);
+
+	if (session == NULL)
+		return -ENOMEM;
+
 	register_idle_thread();
 	register_perf_file_handler(&file_handler);
 
-	return mmap_dispatch_perf_file(&header, input_name, 0, 0,
-				       &event__cwdlen, &event__cwd);
+	err = perf_session__process_events(session, 0, &event__cwdlen, &event__cwd);
+	perf_session__delete(session);
+	return err;
 }
 
 static double fragmentation(unsigned long n_req, unsigned long n_alloc)

commit 9958e1f0aee632c3665162c9c93cf8fde8006a94
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri Dec 11 14:50:36 2009 -0200

    perf symbols: Rename kthreads to kmaps, using another abstraction for it
    
    Using a struct thread instance just to hold the kernel space maps
    (vmlinux + modules) is overkill and confuses people trying to
    understand the perf symbols abstractions.
    
    The kernel maps are really present in all threads, i.e. the kernel
    is a library, not a separate thread.
    
    So introduce the 'map_groups' abstraction and use it for the kernel
    maps, now in the kmaps global variable.
    
    It, in turn, will move, together with the threads list to the
    perf_file abstraction, so that we can support multiple perf_file
    instances, needed by perf diff.
    
    Brainstormed-with: Eduardo Habkost <ehabkost@redhat.com>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Eduardo Habkost <ehabkost@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1260550239-5372-1-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 5f209514f657..fe73435192b3 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -403,7 +403,7 @@ static void __print_result(struct rb_root *root, int n_lines, int is_caller)
 		if (is_caller) {
 			addr = data->call_site;
 			if (!raw_ip)
-				sym = thread__find_function(kthread, addr, NULL);
+				sym = map_groups__find_function(kmaps, addr, NULL);
 		} else
 			addr = data->ptr;
 

commit 7931241694b25589658b1ceb02218d2750540ae0
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Dec 10 08:43:34 2009 +0100

    perf kmem: Fix unused argument build warning
    
    Fix:
    
     builtin-kmem.c: In function 'parse_caller_opt':
     builtin-kmem.c:690: error: unused parameter 'arg'
     builtin-kmem.c: In function 'parse_alloc_opt':
     builtin-kmem.c:697: error: unused parameter 'arg'
    
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Pekka Enberg <penberg@cs.helsinki.fi>
    LKML-Reference: <4B20A195.8030106@cn.fujitsu.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 1b04787ed90a..5f209514f657 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -687,14 +687,14 @@ static int parse_sort_opt(const struct option *opt __used,
 }
 
 static int parse_caller_opt(const struct option *opt __used,
-			  const char *arg, int unset __used)
+			  const char *arg __used, int unset __used)
 {
 	caller_flag = (alloc_flag + 1);
 	return 0;
 }
 
 static int parse_alloc_opt(const struct option *opt __used,
-			  const char *arg, int unset __used)
+			  const char *arg __used, int unset __used)
 {
 	alloc_flag = (caller_flag + 1);
 	return 0;

commit 90b86a9f7dc22e7ff8e8c79ed553860454ff8dd9
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Thu Dec 10 15:21:57 2009 +0800

    perf kmem: Show usage if no option is specified
    
    As Ingo suggested, make "perf kmem" show help information.
    "perf kmem stat [--caller] [--alloc] .." will show memory
    statistics.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Acked-by: Pekka Enberg <penberg@cs.helsinki.fi>
    LKML-Reference: <4B20A195.8030106@cn.fujitsu.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 7551a5f834b8..1b04787ed90a 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -526,7 +526,7 @@ static int __cmd_kmem(void)
 }
 
 static const char * const kmem_usage[] = {
-	"perf kmem [<options>] {record}",
+	"perf kmem [<options>] {record|stat}",
 	NULL
 };
 
@@ -686,18 +686,17 @@ static int parse_sort_opt(const struct option *opt __used,
 	return 0;
 }
 
-static int parse_stat_opt(const struct option *opt __used,
+static int parse_caller_opt(const struct option *opt __used,
 			  const char *arg, int unset __used)
 {
-	if (!arg)
-		return -1;
+	caller_flag = (alloc_flag + 1);
+	return 0;
+}
 
-	if (strcmp(arg, "alloc") == 0)
-		alloc_flag = (caller_flag + 1);
-	else if (strcmp(arg, "caller") == 0)
-		caller_flag = (alloc_flag + 1);
-	else
-		return -1;
+static int parse_alloc_opt(const struct option *opt __used,
+			  const char *arg, int unset __used)
+{
+	alloc_flag = (caller_flag + 1);
 	return 0;
 }
 
@@ -722,14 +721,17 @@ static int parse_line_opt(const struct option *opt __used,
 static const struct option kmem_options[] = {
 	OPT_STRING('i', "input", &input_name, "file",
 		   "input file name"),
-	OPT_CALLBACK(0, "stat", NULL, "<alloc>|<caller>",
-		     "stat selector, Pass 'alloc' or 'caller'.",
-		     parse_stat_opt),
+	OPT_CALLBACK_NOOPT(0, "caller", NULL, NULL,
+			   "show per-callsite statistics",
+			   parse_caller_opt),
+	OPT_CALLBACK_NOOPT(0, "alloc", NULL, NULL,
+			   "show per-allocation statistics",
+			   parse_alloc_opt),
 	OPT_CALLBACK('s', "sort", NULL, "key[,key2...]",
 		     "sort by keys: ptr, call_site, bytes, hit, pingpong, frag",
 		     parse_sort_opt),
 	OPT_CALLBACK('l', "line", NULL, "num",
-		     "show n lins",
+		     "show n lines",
 		     parse_line_opt),
 	OPT_BOOLEAN(0, "raw-ip", &raw_ip, "show raw ip instead of symbol"),
 	OPT_END()
@@ -773,18 +775,22 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __used)
 
 	argc = parse_options(argc, argv, kmem_options, kmem_usage, 0);
 
-	if (argc && !strncmp(argv[0], "rec", 3))
-		return __cmd_record(argc, argv);
-	else if (argc)
+	if (!argc)
 		usage_with_options(kmem_usage, kmem_options);
 
-	if (list_empty(&caller_sort))
-		setup_sorting(&caller_sort, default_sort_order);
-	if (list_empty(&alloc_sort))
-		setup_sorting(&alloc_sort, default_sort_order);
+	if (!strncmp(argv[0], "rec", 3)) {
+		return __cmd_record(argc, argv);
+	} else if (!strcmp(argv[0], "stat")) {
+		setup_cpunode_map();
+
+		if (list_empty(&caller_sort))
+			setup_sorting(&caller_sort, default_sort_order);
+		if (list_empty(&alloc_sort))
+			setup_sorting(&alloc_sort, default_sort_order);
 
-	setup_cpunode_map();
+		return __cmd_kmem();
+	}
 
-	return __cmd_kmem();
+	return 0;
 }
 

commit f48f669d42e133db839af16656fd720107ef6742
Author: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
Date:   Mon Dec 7 13:04:04 2009 +0800

    perf_event: Eliminate raw->size
    
    raw->size is not used, this patch just cleans it up.
    
    Signed-off-by: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    LKML-Reference: <4B1C8CC4.4050007@cn.fujitsu.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index f84d7a3db681..7551a5f834b8 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -57,11 +57,6 @@ static struct rb_root root_caller_sorted;
 static unsigned long total_requested, total_allocated;
 static unsigned long nr_allocs, nr_cross_allocs;
 
-struct raw_event_sample {
-	u32 size;
-	char data[0];
-};
-
 #define PATH_SYS_NODE	"/sys/devices/system/node"
 
 static void init_cpunode_map(void)
@@ -201,7 +196,7 @@ static void insert_caller_stat(unsigned long call_site,
 	}
 }
 
-static void process_alloc_event(struct raw_event_sample *raw,
+static void process_alloc_event(void *data,
 				struct event *event,
 				int cpu,
 				u64 timestamp __used,
@@ -214,10 +209,10 @@ static void process_alloc_event(struct raw_event_sample *raw,
 	int bytes_alloc;
 	int node1, node2;
 
-	ptr = raw_field_value(event, "ptr", raw->data);
-	call_site = raw_field_value(event, "call_site", raw->data);
-	bytes_req = raw_field_value(event, "bytes_req", raw->data);
-	bytes_alloc = raw_field_value(event, "bytes_alloc", raw->data);
+	ptr = raw_field_value(event, "ptr", data);
+	call_site = raw_field_value(event, "call_site", data);
+	bytes_req = raw_field_value(event, "bytes_req", data);
+	bytes_alloc = raw_field_value(event, "bytes_alloc", data);
 
 	insert_alloc_stat(call_site, ptr, bytes_req, bytes_alloc, cpu);
 	insert_caller_stat(call_site, bytes_req, bytes_alloc);
@@ -227,7 +222,7 @@ static void process_alloc_event(struct raw_event_sample *raw,
 
 	if (node) {
 		node1 = cpunode_map[cpu];
-		node2 = raw_field_value(event, "node", raw->data);
+		node2 = raw_field_value(event, "node", data);
 		if (node1 != node2)
 			nr_cross_allocs++;
 	}
@@ -262,7 +257,7 @@ static struct alloc_stat *search_alloc_stat(unsigned long ptr,
 	return NULL;
 }
 
-static void process_free_event(struct raw_event_sample *raw,
+static void process_free_event(void *data,
 			       struct event *event,
 			       int cpu,
 			       u64 timestamp __used,
@@ -271,7 +266,7 @@ static void process_free_event(struct raw_event_sample *raw,
 	unsigned long ptr;
 	struct alloc_stat *s_alloc, *s_caller;
 
-	ptr = raw_field_value(event, "ptr", raw->data);
+	ptr = raw_field_value(event, "ptr", data);
 
 	s_alloc = search_alloc_stat(ptr, 0, &root_alloc_stat, ptr_cmp);
 	if (!s_alloc)
@@ -289,35 +284,30 @@ static void process_free_event(struct raw_event_sample *raw,
 }
 
 static void
-process_raw_event(event_t *raw_event __used, u32 size, void *data,
+process_raw_event(event_t *raw_event __used, void *data,
 		  int cpu, u64 timestamp, struct thread *thread)
 {
-	struct raw_event_sample *raw;
 	struct event *event;
 	int type;
 
-	raw = malloc_or_die(sizeof(*raw)+size);
-	raw->size = size;
-	memcpy(raw->data, data, size);
-
-	type = trace_parse_common_type(raw->data);
+	type = trace_parse_common_type(data);
 	event = trace_find_event(type);
 
 	if (!strcmp(event->name, "kmalloc") ||
 	    !strcmp(event->name, "kmem_cache_alloc")) {
-		process_alloc_event(raw, event, cpu, timestamp, thread, 0);
+		process_alloc_event(data, event, cpu, timestamp, thread, 0);
 		return;
 	}
 
 	if (!strcmp(event->name, "kmalloc_node") ||
 	    !strcmp(event->name, "kmem_cache_alloc_node")) {
-		process_alloc_event(raw, event, cpu, timestamp, thread, 1);
+		process_alloc_event(data, event, cpu, timestamp, thread, 1);
 		return;
 	}
 
 	if (!strcmp(event->name, "kfree") ||
 	    !strcmp(event->name, "kmem_cache_free")) {
-		process_free_event(raw, event, cpu, timestamp, thread);
+		process_free_event(data, event, cpu, timestamp, thread);
 		return;
 	}
 }
@@ -349,7 +339,7 @@ static int process_sample_event(event_t *event)
 
 	dump_printf(" ... thread: %s:%d\n", thread->comm, thread->pid);
 
-	process_raw_event(event, data.raw_size, data.raw_data, data.cpu,
+	process_raw_event(event, data.raw_data, data.cpu,
 			  data.time, thread);
 
 	return 0;

commit d8bd9e0aedabcb47887712497bc386a06ddcbd12
Author: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
Date:   Mon Dec 7 12:06:29 2009 +0800

    perf_event: Fix raw event processing
    
    We use 'data.raw_data' parameter to call process_raw_event(),
    but data.raw_data buffer not include data size. it can make perf
    tool crash.
    
    This bug was introduced by commit 180f95e29a ("perf: Make common
    SAMPLE_EVENT parser").
    
    Signed-off-by: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
    Cc: Pekka Enberg <penberg@cs.helsinki.fi>
    Cc: Eduard - Gabriel Munteanu <eduard.munteanu@linux360.ro>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    LKML-Reference: <4B1C7F45.5080105@cn.fujitsu.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index f218990de0cd..f84d7a3db681 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -289,13 +289,17 @@ static void process_free_event(struct raw_event_sample *raw,
 }
 
 static void
-process_raw_event(event_t *raw_event __used, void *more_data,
+process_raw_event(event_t *raw_event __used, u32 size, void *data,
 		  int cpu, u64 timestamp, struct thread *thread)
 {
-	struct raw_event_sample *raw = more_data;
+	struct raw_event_sample *raw;
 	struct event *event;
 	int type;
 
+	raw = malloc_or_die(sizeof(*raw)+size);
+	raw->size = size;
+	memcpy(raw->data, data, size);
+
 	type = trace_parse_common_type(raw->data);
 	event = trace_find_event(type);
 
@@ -345,7 +349,8 @@ static int process_sample_event(event_t *event)
 
 	dump_printf(" ... thread: %s:%d\n", thread->comm, thread->pid);
 
-	process_raw_event(event, data.raw_data, data.cpu, data.time, thread);
+	process_raw_event(event, data.raw_size, data.raw_data, data.cpu,
+			  data.time, thread);
 
 	return 0;
 }

commit 180f95e29aa8782c019caa64ede2a28d8ab62564
Author: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
Date:   Sun Dec 6 20:08:24 2009 +0900

    perf: Make common SAMPLE_EVENT parser
    
    Currently, sample event data is parsed for each commands, and it
    is assuming that the data is not including other data. (E.g.
    timechart, trace, etc. can't parse the event if it has
    PERF_SAMPLE_CALLCHAIN)
    
    So, even if we record the superset data for multiple commands at
    a time, commands can't parse. etc.
    
    To fix it, this makes common sample event parser, and use it to
    parse sample event correctly. (PERF_SAMPLE_READ is unsupported
    for now though, it seems to be not using.)
    
    Signed-off-by: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    LKML-Reference: <87hbs48imv.fsf@devron.myhome.or.jp>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 047fef74bd52..f218990de0cd 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -320,35 +320,23 @@ process_raw_event(event_t *raw_event __used, void *more_data,
 
 static int process_sample_event(event_t *event)
 {
-	u64 ip = event->ip.ip;
-	u64 timestamp = -1;
-	u32 cpu = -1;
-	u64 period = 1;
-	void *more_data = event->ip.__more_data;
-	struct thread *thread = threads__findnew(event->ip.pid);
-
-	if (sample_type & PERF_SAMPLE_TIME) {
-		timestamp = *(u64 *)more_data;
-		more_data += sizeof(u64);
-	}
+	struct sample_data data;
+	struct thread *thread;
 
-	if (sample_type & PERF_SAMPLE_CPU) {
-		cpu = *(u32 *)more_data;
-		more_data += sizeof(u32);
-		more_data += sizeof(u32); /* reserved */
-	}
+	memset(&data, 0, sizeof(data));
+	data.time = -1;
+	data.cpu = -1;
+	data.period = 1;
 
-	if (sample_type & PERF_SAMPLE_PERIOD) {
-		period = *(u64 *)more_data;
-		more_data += sizeof(u64);
-	}
+	event__parse_sample(event, sample_type, &data);
 
 	dump_printf("(IP, %d): %d/%d: %p period: %Ld\n",
 		event->header.misc,
-		event->ip.pid, event->ip.tid,
-		(void *)(long)ip,
-		(long long)period);
+		data.pid, data.tid,
+		(void *)(long)data.ip,
+		(long long)data.period);
 
+	thread = threads__findnew(event->ip.pid);
 	if (thread == NULL) {
 		pr_debug("problem processing %d event, skipping it.\n",
 			 event->header.type);
@@ -357,7 +345,7 @@ static int process_sample_event(event_t *event)
 
 	dump_printf(" ... thread: %s:%d\n", thread->comm, thread->pid);
 
-	process_raw_event(event, more_data, cpu, timestamp, thread);
+	process_raw_event(event, data.raw_data, data.cpu, data.time, thread);
 
 	return 0;
 }

commit 1ed091c45ae33b2179d387573c3fe3f3b4adf60a
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri Nov 27 16:29:23 2009 -0200

    perf tools: Consolidate symbol resolving across all tools
    
    Now we have a very high level routine for simple tools to
    process IP sample events:
    
            int event__preprocess_sample(const event_t *self,
                                         struct addr_location *al,
                                         symbol_filter_t filter)
    
    It receives the event itself and will insert new threads in the
    global threads list and resolve the map and symbol, filling all
    this info into the new addr_location struct, so that tools like
    annotate and report can further process the event by creating
    hist_entries in their specific way (with or without callgraphs,
    etc).
    
    It in turn uses the new next layer function:
    
            void thread__find_addr_location(struct thread *self, u8 cpumode,
                                            enum map_type type, u64 addr,
                                            struct addr_location *al,
                                            symbol_filter_t filter)
    
    This one will, given a thread (userspace or the kernel kthread
    one), will find the given type (MAP__FUNCTION now, MAP__VARIABLE
    too in the near future) at the given cpumode, taking vdsos into
    account (userspace hit, but kernel symbol) and will fill all
    these details in the addr_location given.
    
    Tools that need a more compact API for plain function
    resolution, like 'kmem', can use this other one:
    
            struct symbol *thread__find_function(struct thread *self, u64 addr,
                                                 symbol_filter_t filter)
    
    So, to resolve a kernel symbol, that is all the 'kmem' tool
    needs, its just a matter of calling:
    
            sym = thread__find_function(kthread, addr, NULL);
    
    The 'filter' parameter is needed because we do lazy
    parsing/loading of ELF symtabs or /proc/kallsyms.
    
    With this we remove more code duplication all around, which is
    always good, huh? :-)
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: John Kacur <jkacur@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1259346563-12568-12-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index e7294c8fc620..047fef74bd52 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -420,7 +420,7 @@ static void __print_result(struct rb_root *root, int n_lines, int is_caller)
 		if (is_caller) {
 			addr = data->call_site;
 			if (!raw_ip)
-				sym = kernel_maps__find_function(addr, NULL, NULL);
+				sym = thread__find_function(kthread, addr, NULL);
 		} else
 			addr = data->ptr;
 

commit 62daacb51a2bf8480e6f6b3696b03f102fc15eb0
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri Nov 27 16:29:22 2009 -0200

    perf tools: Reorganize event processing routines, lotsa dups killed
    
    While implementing event__preprocess_sample, that will do all of
    the symbol lookup in one convenient function, I noticed that
    util/process_event.[ch] were not being used at all, then started
    looking if there were other functions that could be shared
    and...
    
    All those functions really don't need to receive offset + head,
    the only thing they did was common to all of them, so do it at
    one place instead.
    
    Stats about number of each type of event processed now is done
    in a central place.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: John Kacur <jkacur@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1259346563-12568-11-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 35722fafc4d1..e7294c8fc620 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -33,9 +33,6 @@ static bool			raw_ip;
 
 static char			default_sort_order[] = "frag,hit,bytes";
 
-static char			*cwd;
-static int			cwdlen;
-
 static int			*cpunode_map;
 static int			max_cpu_num;
 
@@ -126,25 +123,6 @@ static void setup_cpunode_map(void)
 	}
 }
 
-static int
-process_comm_event(event_t *event, unsigned long offset, unsigned long head)
-{
-	struct thread *thread = threads__findnew(event->comm.pid);
-
-	dump_printf("%p [%p]: PERF_RECORD_COMM: %s:%d\n",
-		(void *)(offset + head),
-		(void *)(long)(event->header.size),
-		event->comm.comm, event->comm.pid);
-
-	if (thread == NULL ||
-	    thread__set_comm(thread, event->comm.comm)) {
-		dump_printf("problem processing PERF_RECORD_COMM, skipping event.\n");
-		return -1;
-	}
-
-	return 0;
-}
-
 static void insert_alloc_stat(unsigned long call_site, unsigned long ptr,
 			      int bytes_req, int bytes_alloc, int cpu)
 {
@@ -340,8 +318,7 @@ process_raw_event(event_t *raw_event __used, void *more_data,
 	}
 }
 
-static int
-process_sample_event(event_t *event, unsigned long offset, unsigned long head)
+static int process_sample_event(event_t *event)
 {
 	u64 ip = event->ip.ip;
 	u64 timestamp = -1;
@@ -366,9 +343,7 @@ process_sample_event(event_t *event, unsigned long offset, unsigned long head)
 		more_data += sizeof(u64);
 	}
 
-	dump_printf("%p [%p]: PERF_RECORD_SAMPLE (IP, %d): %d/%d: %p period: %Ld\n",
-		(void *)(offset + head),
-		(void *)(long)(event->header.size),
+	dump_printf("(IP, %d): %d/%d: %p period: %Ld\n",
 		event->header.misc,
 		event->ip.pid, event->ip.tid,
 		(void *)(long)ip,
@@ -403,7 +378,7 @@ static int sample_type_check(u64 type)
 
 static struct perf_file_handler file_handler = {
 	.process_sample_event	= process_sample_event,
-	.process_comm_event	= process_comm_event,
+	.process_comm_event	= event__process_comm,
 	.sample_type_check	= sample_type_check,
 };
 
@@ -413,7 +388,7 @@ static int read_events(void)
 	register_perf_file_handler(&file_handler);
 
 	return mmap_dispatch_perf_file(&header, input_name, 0, 0,
-				       &cwdlen, &cwd);
+				       &event__cwdlen, &event__cwd);
 }
 
 static double fragmentation(unsigned long n_req, unsigned long n_alloc)

commit fcf1203a919c3a3d212c0ed01f5240fd592bf5ae
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Nov 24 13:01:52 2009 -0200

    perf symbols: Rename find_symbol routines to find_function
    
    Paving the way for supporting variable in adition to function
    symbols.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1259074912-5924-1-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 330dbc762f9e..35722fafc4d1 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -445,8 +445,7 @@ static void __print_result(struct rb_root *root, int n_lines, int is_caller)
 		if (is_caller) {
 			addr = data->call_site;
 			if (!raw_ip)
-				sym = kernel_maps__find_symbol(addr,
-							       NULL, NULL);
+				sym = kernel_maps__find_function(addr, NULL, NULL);
 		} else
 			addr = data->ptr;
 

commit b32d133aec5dc882cf783a293f393bfb3f4379e1
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Nov 24 12:05:15 2009 -0200

    perf symbols: Simplify symbol machinery setup
    
    And also express its configuration toggles via a struct.
    
    Now all one has to do is to call symbol__init(NULL) if the
    defaults are OK, or pass a struct symbol_conf pointer with the
    desired configuration.
    
    If a tool uses kernel_maps__find_symbol() to look at the kernel
    and modules mappings for a symbol but didn't call symbol__init()
    first, that will generate a one time warning too, alerting the
    subcommand developer that symbol__init() must be called.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1259071517-3242-2-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 173d6db42ecb..330dbc762f9e 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -412,7 +412,7 @@ static int read_events(void)
 	register_idle_thread();
 	register_perf_file_handler(&file_handler);
 
-	return mmap_dispatch_perf_file(&header, input_name, NULL, false, 0, 0,
+	return mmap_dispatch_perf_file(&header, input_name, 0, 0,
 				       &cwdlen, &cwd);
 }
 

commit 079d3f653134e2f2ac99dae28b08c0cc64268103
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Tue Nov 24 13:26:55 2009 +0800

    perf kmem: Measure kmalloc/kfree CPU ping-pong call-sites
    
    Show statistics for allocations and frees on different cpus:
    
    ------------------------------------------------------------------------------------------------------
    Callsite                           | Total_alloc/Per | Total_req/Per   | Hit   | Ping-pong | Frag
    ------------------------------------------------------------------------------------------------------
     perf_event_alloc.clone.0+0         |      7504/682   |      7128/648   |     11 |        0 |  5.011%
     alloc_buffer_head+16               |       288/57    |       280/56    |      5 |        0 |  2.778%
     radix_tree_preload+51              |       296/296   |       288/288   |      1 |        0 |  2.703%
     tracepoint_add_probe+32e           |       157/31    |       154/30    |      5 |        0 |  1.911%
     do_maps_open+0                     |       796/12    |       792/12    |     66 |        0 |  0.503%
     sock_alloc_send_pskb+16e           |     23780/495   |     23744/494   |     48 |       38 |  0.151%
     anon_vma_prepare+9a                |      3744/44    |      3740/44    |     85 |        0 |  0.107%
     d_alloc+21                         |     64948/164   |     64944/164   |    396 |        0 |  0.006%
     proc_alloc_inode+23                |    262292/676   |    262288/676   |    388 |        0 |  0.002%
     create_object+28                   |    459600/200   |    459600/200   |   2298 |       71 |  0.000%
     journal_start+67                   |     14440/40    |     14440/40    |    361 |        0 |  0.000%
     get_empty_filp+df                  |     53504/256   |     53504/256   |    209 |        0 |  0.000%
     getname+2a                         |    823296/4096  |    823296/4096  |    201 |        0 |  0.000%
     seq_read+2b0                       |    544768/4096  |    544768/4096  |    133 |        0 |  0.000%
     seq_open+6d                        |     17024/128   |     17024/128   |    133 |        0 |  0.000%
     mmap_region+2e6                    |     11704/88    |     11704/88    |    133 |        0 |  0.000%
     single_open+0                      |      1072/16    |      1072/16    |     67 |        0 |  0.000%
     __alloc_skb+2e                     |     12544/256   |     12544/256   |     49 |       38 |  0.000%
     __sigqueue_alloc+4a                |      1296/144   |      1296/144   |      9 |        8 |  0.000%
     tracepoint_add_probe+6f            |        80/16    |        80/16    |      5 |        0 |  0.000%
    ------------------------------------------------------------------------------------------------------
    ...
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Acked-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Cc: Eduard - Gabriel Munteanu <eduard.munteanu@linux360.ro>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: linux-mm@kvack.org <linux-mm@kvack.org>
    LKML-Reference: <4B0B6E9F.6020309@cn.fujitsu.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 1ecf3f4415ce..173d6db42ecb 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -40,13 +40,14 @@ static int			*cpunode_map;
 static int			max_cpu_num;
 
 struct alloc_stat {
-	union {
-		u64	call_site;
-		u64	ptr;
-	};
+	u64	call_site;
+	u64	ptr;
 	u64	bytes_req;
 	u64	bytes_alloc;
 	u32	hit;
+	u32	pingpong;
+
+	short	alloc_cpu;
 
 	struct rb_node node;
 };
@@ -144,16 +145,13 @@ process_comm_event(event_t *event, unsigned long offset, unsigned long head)
 	return 0;
 }
 
-static void insert_alloc_stat(unsigned long ptr,
-			      int bytes_req, int bytes_alloc)
+static void insert_alloc_stat(unsigned long call_site, unsigned long ptr,
+			      int bytes_req, int bytes_alloc, int cpu)
 {
 	struct rb_node **node = &root_alloc_stat.rb_node;
 	struct rb_node *parent = NULL;
 	struct alloc_stat *data = NULL;
 
-	if (!alloc_flag)
-		return;
-
 	while (*node) {
 		parent = *node;
 		data = rb_entry(*node, struct alloc_stat, node);
@@ -172,7 +170,10 @@ static void insert_alloc_stat(unsigned long ptr,
 		data->bytes_alloc += bytes_req;
 	} else {
 		data = malloc(sizeof(*data));
+		if (!data)
+			die("malloc");
 		data->ptr = ptr;
+		data->pingpong = 0;
 		data->hit = 1;
 		data->bytes_req = bytes_req;
 		data->bytes_alloc = bytes_alloc;
@@ -180,6 +181,8 @@ static void insert_alloc_stat(unsigned long ptr,
 		rb_link_node(&data->node, parent, node);
 		rb_insert_color(&data->node, &root_alloc_stat);
 	}
+	data->call_site = call_site;
+	data->alloc_cpu = cpu;
 }
 
 static void insert_caller_stat(unsigned long call_site,
@@ -189,9 +192,6 @@ static void insert_caller_stat(unsigned long call_site,
 	struct rb_node *parent = NULL;
 	struct alloc_stat *data = NULL;
 
-	if (!caller_flag)
-		return;
-
 	while (*node) {
 		parent = *node;
 		data = rb_entry(*node, struct alloc_stat, node);
@@ -210,7 +210,10 @@ static void insert_caller_stat(unsigned long call_site,
 		data->bytes_alloc += bytes_req;
 	} else {
 		data = malloc(sizeof(*data));
+		if (!data)
+			die("malloc");
 		data->call_site = call_site;
+		data->pingpong = 0;
 		data->hit = 1;
 		data->bytes_req = bytes_req;
 		data->bytes_alloc = bytes_alloc;
@@ -238,7 +241,7 @@ static void process_alloc_event(struct raw_event_sample *raw,
 	bytes_req = raw_field_value(event, "bytes_req", raw->data);
 	bytes_alloc = raw_field_value(event, "bytes_alloc", raw->data);
 
-	insert_alloc_stat(ptr, bytes_req, bytes_alloc);
+	insert_alloc_stat(call_site, ptr, bytes_req, bytes_alloc, cpu);
 	insert_caller_stat(call_site, bytes_req, bytes_alloc);
 
 	total_requested += bytes_req;
@@ -253,12 +256,58 @@ static void process_alloc_event(struct raw_event_sample *raw,
 	nr_allocs++;
 }
 
-static void process_free_event(struct raw_event_sample *raw __used,
-			       struct event *event __used,
-			       int cpu __used,
+static int ptr_cmp(struct alloc_stat *, struct alloc_stat *);
+static int callsite_cmp(struct alloc_stat *, struct alloc_stat *);
+
+static struct alloc_stat *search_alloc_stat(unsigned long ptr,
+					    unsigned long call_site,
+					    struct rb_root *root,
+					    sort_fn_t sort_fn)
+{
+	struct rb_node *node = root->rb_node;
+	struct alloc_stat key = { .ptr = ptr, .call_site = call_site };
+
+	while (node) {
+		struct alloc_stat *data;
+		int cmp;
+
+		data = rb_entry(node, struct alloc_stat, node);
+
+		cmp = sort_fn(&key, data);
+		if (cmp < 0)
+			node = node->rb_left;
+		else if (cmp > 0)
+			node = node->rb_right;
+		else
+			return data;
+	}
+	return NULL;
+}
+
+static void process_free_event(struct raw_event_sample *raw,
+			       struct event *event,
+			       int cpu,
 			       u64 timestamp __used,
 			       struct thread *thread __used)
 {
+	unsigned long ptr;
+	struct alloc_stat *s_alloc, *s_caller;
+
+	ptr = raw_field_value(event, "ptr", raw->data);
+
+	s_alloc = search_alloc_stat(ptr, 0, &root_alloc_stat, ptr_cmp);
+	if (!s_alloc)
+		return;
+
+	if (cpu != s_alloc->alloc_cpu) {
+		s_alloc->pingpong++;
+
+		s_caller = search_alloc_stat(0, s_alloc->call_site,
+					     &root_caller_stat, callsite_cmp);
+		assert(s_caller);
+		s_caller->pingpong++;
+	}
+	s_alloc->alloc_cpu = -1;
 }
 
 static void
@@ -379,10 +428,10 @@ static void __print_result(struct rb_root *root, int n_lines, int is_caller)
 {
 	struct rb_node *next;
 
-	printf("%.78s\n", graph_dotted_line);
-	printf("%-28s|",  is_caller ? "Callsite": "Alloc Ptr");
-	printf("Total_alloc/Per | Total_req/Per | Hit  | Frag\n");
-	printf("%.78s\n", graph_dotted_line);
+	printf("%.102s\n", graph_dotted_line);
+	printf(" %-34s |",  is_caller ? "Callsite": "Alloc Ptr");
+	printf(" Total_alloc/Per | Total_req/Per   | Hit   | Ping-pong | Frag\n");
+	printf("%.102s\n", graph_dotted_line);
 
 	next = rb_first(root);
 
@@ -390,7 +439,7 @@ static void __print_result(struct rb_root *root, int n_lines, int is_caller)
 		struct alloc_stat *data = rb_entry(next, struct alloc_stat,
 						   node);
 		struct symbol *sym = NULL;
-		char bf[BUFSIZ];
+		char buf[BUFSIZ];
 		u64 addr;
 
 		if (is_caller) {
@@ -402,26 +451,28 @@ static void __print_result(struct rb_root *root, int n_lines, int is_caller)
 			addr = data->ptr;
 
 		if (sym != NULL)
-			snprintf(bf, sizeof(bf), "%s+%Lx", sym->name,
+			snprintf(buf, sizeof(buf), "%s+%Lx", sym->name,
 				 addr - sym->start);
 		else
-			snprintf(bf, sizeof(bf), "%#Lx", addr);
+			snprintf(buf, sizeof(buf), "%#Lx", addr);
+		printf(" %-34s |", buf);
 
-		printf("%-28s|%8llu/%-6lu |%8llu/%-6lu|%6lu|%8.3f%%\n",
-		       bf, (unsigned long long)data->bytes_alloc,
+		printf(" %9llu/%-5lu | %9llu/%-5lu | %6lu | %8lu | %6.3f%%\n",
+		       (unsigned long long)data->bytes_alloc,
 		       (unsigned long)data->bytes_alloc / data->hit,
 		       (unsigned long long)data->bytes_req,
 		       (unsigned long)data->bytes_req / data->hit,
 		       (unsigned long)data->hit,
+		       (unsigned long)data->pingpong,
 		       fragmentation(data->bytes_req, data->bytes_alloc));
 
 		next = rb_next(next);
 	}
 
 	if (n_lines == -1)
-		printf(" ...                        | ...            | ...           | ...    | ...   \n");
+		printf(" ...                                | ...             | ...             | ...    | ...      | ...   \n");
 
-	printf("%.78s\n", graph_dotted_line);
+	printf("%.102s\n", graph_dotted_line);
 }
 
 static void print_summary(void)
@@ -597,12 +648,27 @@ static struct sort_dimension frag_sort_dimension = {
 	.cmp	= frag_cmp,
 };
 
+static int pingpong_cmp(struct alloc_stat *l, struct alloc_stat *r)
+{
+	if (l->pingpong < r->pingpong)
+		return -1;
+	else if (l->pingpong > r->pingpong)
+		return 1;
+	return 0;
+}
+
+static struct sort_dimension pingpong_sort_dimension = {
+	.name	= "pingpong",
+	.cmp	= pingpong_cmp,
+};
+
 static struct sort_dimension *avail_sorts[] = {
 	&ptr_sort_dimension,
 	&callsite_sort_dimension,
 	&hit_sort_dimension,
 	&bytes_sort_dimension,
 	&frag_sort_dimension,
+	&pingpong_sort_dimension,
 };
 
 #define NUM_AVAIL_SORTS	\
@@ -703,7 +769,7 @@ static const struct option kmem_options[] = {
 		     "stat selector, Pass 'alloc' or 'caller'.",
 		     parse_stat_opt),
 	OPT_CALLBACK('s', "sort", NULL, "key[,key2...]",
-		     "sort by key(s): ptr, call_site, bytes, hit, frag",
+		     "sort by keys: ptr, call_site, bytes, hit, pingpong, frag",
 		     parse_sort_opt),
 	OPT_CALLBACK('l', "line", NULL, "num",
 		     "show n lins",

commit 7d0d39459dab20bf60cac30a1a7d50b286c60cc1
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Tue Nov 24 13:26:31 2009 +0800

    perf kmem: Collect cross node allocation statistics
    
    Show cross node memory allocations:
    
     # ./perf kmem
    
     SUMMARY
     =======
     ...
     Cross node allocations: 0/3633
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Acked-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Cc: Eduard - Gabriel Munteanu <eduard.munteanu@linux360.ro>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: linux-mm@kvack.org <linux-mm@kvack.org>
    LKML-Reference: <4B0B6E87.10906@cn.fujitsu.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index dc86f1e64b66..1ecf3f4415ce 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -36,6 +36,9 @@ static char			default_sort_order[] = "frag,hit,bytes";
 static char			*cwd;
 static int			cwdlen;
 
+static int			*cpunode_map;
+static int			max_cpu_num;
+
 struct alloc_stat {
 	union {
 		u64	call_site;
@@ -54,12 +57,74 @@ static struct rb_root root_caller_stat;
 static struct rb_root root_caller_sorted;
 
 static unsigned long total_requested, total_allocated;
+static unsigned long nr_allocs, nr_cross_allocs;
 
 struct raw_event_sample {
 	u32 size;
 	char data[0];
 };
 
+#define PATH_SYS_NODE	"/sys/devices/system/node"
+
+static void init_cpunode_map(void)
+{
+	FILE *fp;
+	int i;
+
+	fp = fopen("/sys/devices/system/cpu/kernel_max", "r");
+	if (!fp) {
+		max_cpu_num = 4096;
+		return;
+	}
+
+	if (fscanf(fp, "%d", &max_cpu_num) < 1)
+		die("Failed to read 'kernel_max' from sysfs");
+	max_cpu_num++;
+
+	cpunode_map = calloc(max_cpu_num, sizeof(int));
+	if (!cpunode_map)
+		die("calloc");
+	for (i = 0; i < max_cpu_num; i++)
+		cpunode_map[i] = -1;
+	fclose(fp);
+}
+
+static void setup_cpunode_map(void)
+{
+	struct dirent *dent1, *dent2;
+	DIR *dir1, *dir2;
+	unsigned int cpu, mem;
+	char buf[PATH_MAX];
+
+	init_cpunode_map();
+
+	dir1 = opendir(PATH_SYS_NODE);
+	if (!dir1)
+		return;
+
+	while (true) {
+		dent1 = readdir(dir1);
+		if (!dent1)
+			break;
+
+		if (sscanf(dent1->d_name, "node%u", &mem) < 1)
+			continue;
+
+		snprintf(buf, PATH_MAX, "%s/%s", PATH_SYS_NODE, dent1->d_name);
+		dir2 = opendir(buf);
+		if (!dir2)
+			continue;
+		while (true) {
+			dent2 = readdir(dir2);
+			if (!dent2)
+				break;
+			if (sscanf(dent2->d_name, "cpu%u", &cpu) < 1)
+				continue;
+			cpunode_map[cpu] = mem;
+		}
+	}
+}
+
 static int
 process_comm_event(event_t *event, unsigned long offset, unsigned long head)
 {
@@ -157,15 +222,16 @@ static void insert_caller_stat(unsigned long call_site,
 
 static void process_alloc_event(struct raw_event_sample *raw,
 				struct event *event,
-				int cpu __used,
+				int cpu,
 				u64 timestamp __used,
 				struct thread *thread __used,
-				int node __used)
+				int node)
 {
 	unsigned long call_site;
 	unsigned long ptr;
 	int bytes_req;
 	int bytes_alloc;
+	int node1, node2;
 
 	ptr = raw_field_value(event, "ptr", raw->data);
 	call_site = raw_field_value(event, "call_site", raw->data);
@@ -177,6 +243,14 @@ static void process_alloc_event(struct raw_event_sample *raw,
 
 	total_requested += bytes_req;
 	total_allocated += bytes_alloc;
+
+	if (node) {
+		node1 = cpunode_map[cpu];
+		node2 = raw_field_value(event, "node", raw->data);
+		if (node1 != node2)
+			nr_cross_allocs++;
+	}
+	nr_allocs++;
 }
 
 static void process_free_event(struct raw_event_sample *raw __used,
@@ -359,6 +433,7 @@ static void print_summary(void)
 	       total_allocated - total_requested);
 	printf("Internal fragmentation: %f%%\n",
 	       fragmentation(total_requested, total_allocated));
+	printf("Cross CPU allocations: %lu/%lu\n", nr_cross_allocs, nr_allocs);
 }
 
 static void print_result(void)
@@ -685,6 +760,8 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __used)
 	if (list_empty(&alloc_sort))
 		setup_sorting(&alloc_sort, default_sort_order);
 
+	setup_cpunode_map();
+
 	return __cmd_kmem();
 }
 

commit 29b3e15289eb66788a0bf5ea4903f9fbeb1ec751
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Tue Nov 24 13:26:10 2009 +0800

    perf kmem: Default to sort by fragmentation
    
    Make the output sort by fragmentation by default.
    
    Also make the usage of "--sort" option consistent with other
    perf tools. That is, we support multi keys: "--sort
    key1[,key2]...".
    
     # ./perf kmem --stat caller
     ------------------------------------------------------------------------------
     Callsite                    |Total_alloc/Per | Total_req/Per | Hit  | Frag
     ------------------------------------------------------------------------------
     __netdev_alloc_skb+23       |    5048/1682   |    4564/1521  |     3|   9.588%
     perf_event_alloc.clone.0+0  |    7504/682    |    7128/648   |    11|   5.011%
     tracepoint_add_probe+32e    |     157/31     |     154/30    |     5|   1.911%
     alloc_buffer_head+16        |     456/57     |     448/56    |     8|   1.754%
     radix_tree_preload+51       |     584/292    |     576/288   |     2|   1.370%
     ...
    
    TODO:
    - Extract duplicate code in builtin-kmem.c and builtin-sched.c
      into util/sort.c.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Acked-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Cc: Eduard - Gabriel Munteanu <eduard.munteanu@linux360.ro>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: linux-mm@kvack.org <linux-mm@kvack.org>
    LKML-Reference: <4B0B6E72.7010200@cn.fujitsu.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 1ef43c212d9a..dc86f1e64b66 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -26,14 +26,13 @@ static u64			sample_type;
 static int			alloc_flag;
 static int			caller_flag;
 
-sort_fn_t			alloc_sort_fn;
-sort_fn_t			caller_sort_fn;
-
 static int			alloc_lines = -1;
 static int			caller_lines = -1;
 
 static bool			raw_ip;
 
+static char			default_sort_order[] = "frag,hit,bytes";
+
 static char			*cwd;
 static int			cwdlen;
 
@@ -371,20 +370,34 @@ static void print_result(void)
 	print_summary();
 }
 
+struct sort_dimension {
+	const char		name[20];
+	sort_fn_t		cmp;
+	struct list_head	list;
+};
+
+static LIST_HEAD(caller_sort);
+static LIST_HEAD(alloc_sort);
+
 static void sort_insert(struct rb_root *root, struct alloc_stat *data,
-			sort_fn_t sort_fn)
+			struct list_head *sort_list)
 {
 	struct rb_node **new = &(root->rb_node);
 	struct rb_node *parent = NULL;
+	struct sort_dimension *sort;
 
 	while (*new) {
 		struct alloc_stat *this;
-		int cmp;
+		int cmp = 0;
 
 		this = rb_entry(*new, struct alloc_stat, node);
 		parent = *new;
 
-		cmp = sort_fn(data, this);
+		list_for_each_entry(sort, sort_list, list) {
+			cmp = sort->cmp(data, this);
+			if (cmp)
+				break;
+		}
 
 		if (cmp > 0)
 			new = &((*new)->rb_left);
@@ -397,7 +410,7 @@ static void sort_insert(struct rb_root *root, struct alloc_stat *data,
 }
 
 static void __sort_result(struct rb_root *root, struct rb_root *root_sorted,
-			  sort_fn_t sort_fn)
+			  struct list_head *sort_list)
 {
 	struct rb_node *node;
 	struct alloc_stat *data;
@@ -409,14 +422,14 @@ static void __sort_result(struct rb_root *root, struct rb_root *root_sorted,
 
 		rb_erase(node, root);
 		data = rb_entry(node, struct alloc_stat, node);
-		sort_insert(root_sorted, data, sort_fn);
+		sort_insert(root_sorted, data, sort_list);
 	}
 }
 
 static void sort_result(void)
 {
-	__sort_result(&root_alloc_stat, &root_alloc_sorted, alloc_sort_fn);
-	__sort_result(&root_caller_stat, &root_caller_sorted, caller_sort_fn);
+	__sort_result(&root_alloc_stat, &root_alloc_sorted, &alloc_sort);
+	__sort_result(&root_caller_stat, &root_caller_sorted, &caller_sort);
 }
 
 static int __cmd_kmem(void)
@@ -434,7 +447,6 @@ static const char * const kmem_usage[] = {
 	NULL
 };
 
-
 static int ptr_cmp(struct alloc_stat *l, struct alloc_stat *r)
 {
 	if (l->ptr < r->ptr)
@@ -444,6 +456,11 @@ static int ptr_cmp(struct alloc_stat *l, struct alloc_stat *r)
 	return 0;
 }
 
+static struct sort_dimension ptr_sort_dimension = {
+	.name	= "ptr",
+	.cmp	= ptr_cmp,
+};
+
 static int callsite_cmp(struct alloc_stat *l, struct alloc_stat *r)
 {
 	if (l->call_site < r->call_site)
@@ -453,6 +470,11 @@ static int callsite_cmp(struct alloc_stat *l, struct alloc_stat *r)
 	return 0;
 }
 
+static struct sort_dimension callsite_sort_dimension = {
+	.name	= "callsite",
+	.cmp	= callsite_cmp,
+};
+
 static int hit_cmp(struct alloc_stat *l, struct alloc_stat *r)
 {
 	if (l->hit < r->hit)
@@ -462,6 +484,11 @@ static int hit_cmp(struct alloc_stat *l, struct alloc_stat *r)
 	return 0;
 }
 
+static struct sort_dimension hit_sort_dimension = {
+	.name	= "hit",
+	.cmp	= hit_cmp,
+};
+
 static int bytes_cmp(struct alloc_stat *l, struct alloc_stat *r)
 {
 	if (l->bytes_alloc < r->bytes_alloc)
@@ -471,6 +498,11 @@ static int bytes_cmp(struct alloc_stat *l, struct alloc_stat *r)
 	return 0;
 }
 
+static struct sort_dimension bytes_sort_dimension = {
+	.name	= "bytes",
+	.cmp	= bytes_cmp,
+};
+
 static int frag_cmp(struct alloc_stat *l, struct alloc_stat *r)
 {
 	double x, y;
@@ -485,31 +517,73 @@ static int frag_cmp(struct alloc_stat *l, struct alloc_stat *r)
 	return 0;
 }
 
+static struct sort_dimension frag_sort_dimension = {
+	.name	= "frag",
+	.cmp	= frag_cmp,
+};
+
+static struct sort_dimension *avail_sorts[] = {
+	&ptr_sort_dimension,
+	&callsite_sort_dimension,
+	&hit_sort_dimension,
+	&bytes_sort_dimension,
+	&frag_sort_dimension,
+};
+
+#define NUM_AVAIL_SORTS	\
+	(int)(sizeof(avail_sorts) / sizeof(struct sort_dimension *))
+
+static int sort_dimension__add(const char *tok, struct list_head *list)
+{
+	struct sort_dimension *sort;
+	int i;
+
+	for (i = 0; i < NUM_AVAIL_SORTS; i++) {
+		if (!strcmp(avail_sorts[i]->name, tok)) {
+			sort = malloc(sizeof(*sort));
+			if (!sort)
+				die("malloc");
+			memcpy(sort, avail_sorts[i], sizeof(*sort));
+			list_add_tail(&sort->list, list);
+			return 0;
+		}
+	}
+
+	return -1;
+}
+
+static int setup_sorting(struct list_head *sort_list, const char *arg)
+{
+	char *tok;
+	char *str = strdup(arg);
+
+	if (!str)
+		die("strdup");
+
+	while (true) {
+		tok = strsep(&str, ",");
+		if (!tok)
+			break;
+		if (sort_dimension__add(tok, sort_list) < 0) {
+			error("Unknown --sort key: '%s'", tok);
+			return -1;
+		}
+	}
+
+	free(str);
+	return 0;
+}
+
 static int parse_sort_opt(const struct option *opt __used,
 			  const char *arg, int unset __used)
 {
-	sort_fn_t sort_fn;
-
 	if (!arg)
 		return -1;
 
-	if (strcmp(arg, "ptr") == 0)
-		sort_fn = ptr_cmp;
-	else if (strcmp(arg, "call_site") == 0)
-		sort_fn = callsite_cmp;
-	else if (strcmp(arg, "hit") == 0)
-		sort_fn = hit_cmp;
-	else if (strcmp(arg, "bytes") == 0)
-		sort_fn = bytes_cmp;
-	else if (strcmp(arg, "frag") == 0)
-		sort_fn = frag_cmp;
-	else
-		return -1;
-
 	if (caller_flag > alloc_flag)
-		caller_sort_fn = sort_fn;
+		return setup_sorting(&caller_sort, arg);
 	else
-		alloc_sort_fn = sort_fn;
+		return setup_sorting(&alloc_sort, arg);
 
 	return 0;
 }
@@ -553,8 +627,8 @@ static const struct option kmem_options[] = {
 	OPT_CALLBACK(0, "stat", NULL, "<alloc>|<caller>",
 		     "stat selector, Pass 'alloc' or 'caller'.",
 		     parse_stat_opt),
-	OPT_CALLBACK('s', "sort", NULL, "key",
-		     "sort by key: ptr, call_site, hit, bytes, frag",
+	OPT_CALLBACK('s', "sort", NULL, "key[,key2...]",
+		     "sort by key(s): ptr, call_site, bytes, hit, frag",
 		     parse_sort_opt),
 	OPT_CALLBACK('l', "line", NULL, "num",
 		     "show n lins",
@@ -606,10 +680,10 @@ int cmd_kmem(int argc, const char **argv, const char *prefix __used)
 	else if (argc)
 		usage_with_options(kmem_usage, kmem_options);
 
-	if (!alloc_sort_fn)
-		alloc_sort_fn = bytes_cmp;
-	if (!caller_sort_fn)
-		caller_sort_fn = bytes_cmp;
+	if (list_empty(&caller_sort))
+		setup_sorting(&caller_sort, default_sort_order);
+	if (list_empty(&alloc_sort))
+		setup_sorting(&alloc_sort, default_sort_order);
 
 	return __cmd_kmem();
 }

commit 7707b6b6f8d9188b612f9fc88c65411264b1ed57
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Tue Nov 24 13:25:48 2009 +0800

    perf kmem: Add new option to show raw ip
    
    Add option "--raw-ip" to show raw ip instead of symbols:
    
     # ./perf kmem --stat caller --raw-ip
     ------------------------------------------------------------------------------
     Callsite                    |Total_alloc/Per | Total_req/Per | Hit  | Frag
     ------------------------------------------------------------------------------
     0xc05301aa                  |  733184/4096   |  733184/4096  |   179|   0.000%
     0xc0542ba0                  |  483328/4096   |  483328/4096  |   118|   0.000%
     ...
    
    Also show symbols with format sym+offset instead of sym/offset.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Acked-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Cc: Eduard - Gabriel Munteanu <eduard.munteanu@linux360.ro>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: linux-mm@kvack.org <linux-mm@kvack.org>
    LKML-Reference: <4B0B6E5C.4080900@cn.fujitsu.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 256d18fa0471..1ef43c212d9a 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -32,15 +32,14 @@ sort_fn_t			caller_sort_fn;
 static int			alloc_lines = -1;
 static int			caller_lines = -1;
 
+static bool			raw_ip;
+
 static char			*cwd;
 static int			cwdlen;
 
 struct alloc_stat {
 	union {
-		struct {
-			char	*name;
-			u64	call_site;
-		};
+		u64	call_site;
 		u64	ptr;
 	};
 	u64	bytes_req;
@@ -323,12 +322,14 @@ static void __print_result(struct rb_root *root, int n_lines, int is_caller)
 
 		if (is_caller) {
 			addr = data->call_site;
-			sym = kernel_maps__find_symbol(addr, NULL, NULL);
+			if (!raw_ip)
+				sym = kernel_maps__find_symbol(addr,
+							       NULL, NULL);
 		} else
 			addr = data->ptr;
 
 		if (sym != NULL)
-			snprintf(bf, sizeof(bf), "%s/%Lx", sym->name,
+			snprintf(bf, sizeof(bf), "%s+%Lx", sym->name,
 				 addr - sym->start);
 		else
 			snprintf(bf, sizeof(bf), "%#Lx", addr);
@@ -345,9 +346,9 @@ static void __print_result(struct rb_root *root, int n_lines, int is_caller)
 	}
 
 	if (n_lines == -1)
-		printf(" ...               | ...             | ...             | ...    | ...   \n");
+		printf(" ...                        | ...            | ...           | ...    | ...   \n");
 
-	printf(" ------------------------------------------------------------------------------\n");
+	printf("%.78s\n", graph_dotted_line);
 }
 
 static void print_summary(void)
@@ -558,6 +559,7 @@ static const struct option kmem_options[] = {
 	OPT_CALLBACK('l', "line", NULL, "num",
 		     "show n lins",
 		     parse_line_opt),
+	OPT_BOOLEAN(0, "raw-ip", &raw_ip, "show raw ip instead of symbol"),
 	OPT_END()
 };
 

commit 1b145ae58035f30353d78d25bea665091df9b438
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Nov 23 17:51:09 2009 -0200

    perf kmem: Resolve symbols
    
    E.g.:
    
      [root@doppio linux-2.6-tip]# perf kmem record sleep 3s
      [ perf record: Woken up 2 times to write data ]
      [ perf record: Captured and wrote 0.804 MB perf.data (~35105 samples) ]
    
      [root@doppio linux-2.6-tip]# perf kmem --stat caller | head -10
      ------------------------------------------------------------------------------
      Callsite                    |Total_alloc/Per | Total_req/Per | Hit  | Frag
      ------------------------------------------------------------------------------
      getname/40                  | 1519616/4096   | 1519616/4096  |   371|   0.000%
      seq_read/a2                 |  987136/4096   |  987136/4096  |   241|   0.000%
      __netdev_alloc_skb/43       |  260368/1049   |  259968/1048  |   248|   0.154%
      __alloc_skb/5a              |   77312/256    |   77312/256   |   302|   0.000%
      proc_alloc_inode/33         |   76480/632    |   76472/632   |   121|   0.010%
      get_empty_filp/8d           |   70272/192    |   70272/192   |   366|   0.000%
      split_vma/8e                |   42064/176    |   42064/176   |   239|   0.000%
      [root@doppio linux-2.6-tip]#
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Acked-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Cc: Eduard - Gabriel Munteanu <eduard.munteanu@linux360.ro>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: linux-mm@kvack.org <linux-mm@kvack.org>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    LKML-Reference: <1259005869-13487-2-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 5d8aeae50004..256d18fa0471 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -307,25 +307,34 @@ static void __print_result(struct rb_root *root, int n_lines, int is_caller)
 {
 	struct rb_node *next;
 
-	printf("\n ------------------------------------------------------------------------------\n");
-	if (is_caller)
-		printf(" Callsite          |");
-	else
-		printf(" Alloc Ptr         |");
-	printf(" Total_alloc/Per |  Total_req/Per  |  Hit   | Fragmentation\n");
-	printf(" ------------------------------------------------------------------------------\n");
+	printf("%.78s\n", graph_dotted_line);
+	printf("%-28s|",  is_caller ? "Callsite": "Alloc Ptr");
+	printf("Total_alloc/Per | Total_req/Per | Hit  | Frag\n");
+	printf("%.78s\n", graph_dotted_line);
 
 	next = rb_first(root);
 
 	while (next && n_lines--) {
-		struct alloc_stat *data;
-
-		data = rb_entry(next, struct alloc_stat, node);
+		struct alloc_stat *data = rb_entry(next, struct alloc_stat,
+						   node);
+		struct symbol *sym = NULL;
+		char bf[BUFSIZ];
+		u64 addr;
+
+		if (is_caller) {
+			addr = data->call_site;
+			sym = kernel_maps__find_symbol(addr, NULL, NULL);
+		} else
+			addr = data->ptr;
+
+		if (sym != NULL)
+			snprintf(bf, sizeof(bf), "%s/%Lx", sym->name,
+				 addr - sym->start);
+		else
+			snprintf(bf, sizeof(bf), "%#Lx", addr);
 
-		printf(" %-16p  | %8llu/%-6lu | %8llu/%-6lu | %6lu | %8.3f%%\n",
-		       is_caller ? (void *)(unsigned long)data->call_site :
-				   (void *)(unsigned long)data->ptr,
-		       (unsigned long long)data->bytes_alloc,
+		printf("%-28s|%8llu/%-6lu |%8llu/%-6lu|%6lu|%8.3f%%\n",
+		       bf, (unsigned long long)data->bytes_alloc,
 		       (unsigned long)data->bytes_alloc / data->hit,
 		       (unsigned long long)data->bytes_req,
 		       (unsigned long)data->bytes_req / data->hit,

commit cc612d8199089413719397c9d92e5823da578eac
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Mon Nov 23 16:39:10 2009 -0200

    perf symbols: Look for vmlinux in more places
    
    Now that we can check the buildid to see if it really matches,
    this can be done safely:
    
      vmlinux
      /boot/vmlinux
      /boot/vmlinux-<uts.release>
      /lib/modules/<uts.release>/build/vmlinux
      /usr/lib/debug/lib/modules/%s/vmlinux
    
    More can be added - if you know about distros that put the
    vmlinux somewhere else please let us know.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frédéric Weisbecker <fweisbec@gmail.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    LKML-Reference: <1259001550-8194-1-git-send-email-acme@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index 4145049e7bf5..5d8aeae50004 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -291,7 +291,7 @@ static int read_events(void)
 	register_idle_thread();
 	register_perf_file_handler(&file_handler);
 
-	return mmap_dispatch_perf_file(&header, input_name, 0, 0,
+	return mmap_dispatch_perf_file(&header, input_name, NULL, false, 0, 0,
 				       &cwdlen, &cwd);
 }
 

commit f3ced7cdb24e7968a353d828955fa2daf4167e72
Author: Pekka Enberg <penberg@cs.helsinki.fi>
Date:   Sun Nov 22 11:58:00 2009 +0200

    perf kmem: Add --sort hit and --sort frag
    
    This patch adds support for "--sort hit" and "--sort frag" to
    the "perf kmem" tool. The former was already mentioned in the
    help text and the latter is useful for finding call-sites that
    exhibit worst case behavior for SLAB allocators.
    
    Signed-off-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Eduard - Gabriel Munteanu <eduard.munteanu@linux360.ro>
    Cc: linux-mm@kvack.org <linux-mm@kvack.org>
    LKML-Reference: <1258883880-7149-1-git-send-email-penberg@cs.helsinki.fi>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
index f315b052f819..4145049e7bf5 100644
--- a/tools/perf/builtin-kmem.c
+++ b/tools/perf/builtin-kmem.c
@@ -443,6 +443,15 @@ static int callsite_cmp(struct alloc_stat *l, struct alloc_stat *r)
 	return 0;
 }
 
+static int hit_cmp(struct alloc_stat *l, struct alloc_stat *r)
+{
+	if (l->hit < r->hit)
+		return -1;
+	else if (l->hit > r->hit)
+		return 1;
+	return 0;
+}
+
 static int bytes_cmp(struct alloc_stat *l, struct alloc_stat *r)
 {
 	if (l->bytes_alloc < r->bytes_alloc)
@@ -452,6 +461,20 @@ static int bytes_cmp(struct alloc_stat *l, struct alloc_stat *r)
 	return 0;
 }
 
+static int frag_cmp(struct alloc_stat *l, struct alloc_stat *r)
+{
+	double x, y;
+
+	x = fragmentation(l->bytes_req, l->bytes_alloc);
+	y = fragmentation(r->bytes_req, r->bytes_alloc);
+
+	if (x < y)
+		return -1;
+	else if (x > y)
+		return 1;
+	return 0;
+}
+
 static int parse_sort_opt(const struct option *opt __used,
 			  const char *arg, int unset __used)
 {
@@ -464,8 +487,12 @@ static int parse_sort_opt(const struct option *opt __used,
 		sort_fn = ptr_cmp;
 	else if (strcmp(arg, "call_site") == 0)
 		sort_fn = callsite_cmp;
+	else if (strcmp(arg, "hit") == 0)
+		sort_fn = hit_cmp;
 	else if (strcmp(arg, "bytes") == 0)
 		sort_fn = bytes_cmp;
+	else if (strcmp(arg, "frag") == 0)
+		sort_fn = frag_cmp;
 	else
 		return -1;
 
@@ -517,7 +544,7 @@ static const struct option kmem_options[] = {
 		     "stat selector, Pass 'alloc' or 'caller'.",
 		     parse_stat_opt),
 	OPT_CALLBACK('s', "sort", NULL, "key",
-		     "sort by key: ptr, call_site, hit, bytes",
+		     "sort by key: ptr, call_site, hit, bytes, frag",
 		     parse_sort_opt),
 	OPT_CALLBACK('l', "line", NULL, "num",
 		     "show n lins",

commit ba77c9e11111a172c9e8687fe16a6a173a61916f
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Fri Nov 20 15:53:25 2009 +0800

    perf: Add 'perf kmem' tool
    
    This tool is mostly a perf version of kmemtrace-user.
    
    The following information is provided by this tool:
    
     - the total amount of memory allocated and fragmentation per
       call-site
    
     - the total amount of memory allocated and fragmentation per
       allocation
    
     - total memory allocated and fragmentation in the collected
       dataset - ...
    
    Sample output:
    
     # ./perf kmem record
     ^C
     # ./perf kmem --stat caller --stat alloc -l 10
    
     ------------------------------------------------------------------------------
     Callsite          | Total_alloc/Per |  Total_req/Per  |  Hit   | Fragmentation
     ------------------------------------------------------------------------------
     0xc052f37a        |   790528/4096   |   790528/4096   |    193 |    0.000%
     0xc0541d70        |   524288/4096   |   524288/4096   |    128 |    0.000%
     0xc051cc68        |   481600/200    |   481600/200    |   2408 |    0.000%
     0xc0572623        |   297444/676    |   297440/676    |    440 |    0.001%
     0xc05399f1        |    73476/164    |    73472/164    |    448 |    0.005%
     0xc05243bf        |    51456/256    |    51456/256    |    201 |    0.000%
     0xc0730d0e        |    31844/497    |    31808/497    |     64 |    0.113%
     0xc0734c4e        |    17152/256    |    17152/256    |     67 |    0.000%
     0xc0541a6d        |    16384/128    |    16384/128    |    128 |    0.000%
     0xc059c217        |    13120/40     |    13120/40     |    328 |    0.000%
     0xc0501ee6        |    11264/88     |    11264/88     |    128 |    0.000%
     0xc04daef0        |     7504/682    |     7128/648    |     11 |    5.011%
     0xc04e14a3        |     4216/191    |     4216/191    |     22 |    0.000%
     0xc05041ca        |     3524/44     |     3520/44     |     80 |    0.114%
     0xc0734fa3        |     2104/701    |     1620/540    |      3 |   23.004%
     0xc05ec9f1        |     2024/289    |     2016/288    |      7 |    0.395%
     0xc06a1999        |     1792/256    |     1792/256    |      7 |    0.000%
     0xc0463b9a        |     1584/144    |     1584/144    |     11 |    0.000%
     0xc0541eb0        |     1024/16     |     1024/16     |     64 |    0.000%
     0xc06a19ac        |      896/128    |      896/128    |      7 |    0.000%
     0xc05721c0        |      772/12     |      768/12     |     64 |    0.518%
     0xc054d1e6        |      288/57     |      280/56     |      5 |    2.778%
     0xc04b562e        |      157/31     |      154/30     |      5 |    1.911%
     0xc04b536f        |       80/16     |       80/16     |      5 |    0.000%
     0xc05855a0        |       64/64     |       36/36     |      1 |   43.750%
     ------------------------------------------------------------------------------
    
     ------------------------------------------------------------------------------
     Alloc Ptr         | Total_alloc/Per |  Total_req/Per  |  Hit   | Fragmentation
     ------------------------------------------------------------------------------
     0xda884000        |  1052672/4096   |  1052672/4096   |    257 |    0.000%
     0xda886000        |   262144/4096   |   262144/4096   |     64 |    0.000%
     0xf60c7c00        |    16512/128    |    16512/128    |    129 |    0.000%
     0xf59a4118        |    13120/40     |    13120/40     |    328 |    0.000%
     0xdfd4b2c0        |    11264/88     |    11264/88     |    128 |    0.000%
     0xf5274600        |     7680/256    |     7680/256    |     30 |    0.000%
     0xe8395000        |     5948/594    |     5464/546    |     10 |    8.137%
     0xe59c3c00        |     5748/479    |     5712/476    |     12 |    0.626%
     0xf4cd1a80        |     3524/44     |     3520/44     |     80 |    0.114%
     0xe5bd1600        |     2892/482    |     2856/476    |      6 |    1.245%
     ...               | ...             | ...             | ...    | ...
     ------------------------------------------------------------------------------
    
    SUMMARY
    =======
    Total bytes requested: 2333626
    Total bytes allocated: 2353712
    Total bytes wasted on internal fragmentation: 20086
    Internal fragmentation: 0.853375%
    
    TODO:
    - show sym+offset in 'callsite' column
    - show cross node allocation stats
    - collect more useful stats?
    - ...
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Acked-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Eduard - Gabriel Munteanu <eduard.munteanu@linux360.ro>
    Cc: linux-mm@kvack.org <linux-mm@kvack.org>
    LKML-Reference: <4B064AF5.9060208@cn.fujitsu.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c
new file mode 100644
index 000000000000..f315b052f819
--- /dev/null
+++ b/tools/perf/builtin-kmem.c
@@ -0,0 +1,578 @@
+#include "builtin.h"
+#include "perf.h"
+
+#include "util/util.h"
+#include "util/cache.h"
+#include "util/symbol.h"
+#include "util/thread.h"
+#include "util/header.h"
+
+#include "util/parse-options.h"
+#include "util/trace-event.h"
+
+#include "util/debug.h"
+#include "util/data_map.h"
+
+#include <linux/rbtree.h>
+
+struct alloc_stat;
+typedef int (*sort_fn_t)(struct alloc_stat *, struct alloc_stat *);
+
+static char const		*input_name = "perf.data";
+
+static struct perf_header	*header;
+static u64			sample_type;
+
+static int			alloc_flag;
+static int			caller_flag;
+
+sort_fn_t			alloc_sort_fn;
+sort_fn_t			caller_sort_fn;
+
+static int			alloc_lines = -1;
+static int			caller_lines = -1;
+
+static char			*cwd;
+static int			cwdlen;
+
+struct alloc_stat {
+	union {
+		struct {
+			char	*name;
+			u64	call_site;
+		};
+		u64	ptr;
+	};
+	u64	bytes_req;
+	u64	bytes_alloc;
+	u32	hit;
+
+	struct rb_node node;
+};
+
+static struct rb_root root_alloc_stat;
+static struct rb_root root_alloc_sorted;
+static struct rb_root root_caller_stat;
+static struct rb_root root_caller_sorted;
+
+static unsigned long total_requested, total_allocated;
+
+struct raw_event_sample {
+	u32 size;
+	char data[0];
+};
+
+static int
+process_comm_event(event_t *event, unsigned long offset, unsigned long head)
+{
+	struct thread *thread = threads__findnew(event->comm.pid);
+
+	dump_printf("%p [%p]: PERF_RECORD_COMM: %s:%d\n",
+		(void *)(offset + head),
+		(void *)(long)(event->header.size),
+		event->comm.comm, event->comm.pid);
+
+	if (thread == NULL ||
+	    thread__set_comm(thread, event->comm.comm)) {
+		dump_printf("problem processing PERF_RECORD_COMM, skipping event.\n");
+		return -1;
+	}
+
+	return 0;
+}
+
+static void insert_alloc_stat(unsigned long ptr,
+			      int bytes_req, int bytes_alloc)
+{
+	struct rb_node **node = &root_alloc_stat.rb_node;
+	struct rb_node *parent = NULL;
+	struct alloc_stat *data = NULL;
+
+	if (!alloc_flag)
+		return;
+
+	while (*node) {
+		parent = *node;
+		data = rb_entry(*node, struct alloc_stat, node);
+
+		if (ptr > data->ptr)
+			node = &(*node)->rb_right;
+		else if (ptr < data->ptr)
+			node = &(*node)->rb_left;
+		else
+			break;
+	}
+
+	if (data && data->ptr == ptr) {
+		data->hit++;
+		data->bytes_req += bytes_req;
+		data->bytes_alloc += bytes_req;
+	} else {
+		data = malloc(sizeof(*data));
+		data->ptr = ptr;
+		data->hit = 1;
+		data->bytes_req = bytes_req;
+		data->bytes_alloc = bytes_alloc;
+
+		rb_link_node(&data->node, parent, node);
+		rb_insert_color(&data->node, &root_alloc_stat);
+	}
+}
+
+static void insert_caller_stat(unsigned long call_site,
+			      int bytes_req, int bytes_alloc)
+{
+	struct rb_node **node = &root_caller_stat.rb_node;
+	struct rb_node *parent = NULL;
+	struct alloc_stat *data = NULL;
+
+	if (!caller_flag)
+		return;
+
+	while (*node) {
+		parent = *node;
+		data = rb_entry(*node, struct alloc_stat, node);
+
+		if (call_site > data->call_site)
+			node = &(*node)->rb_right;
+		else if (call_site < data->call_site)
+			node = &(*node)->rb_left;
+		else
+			break;
+	}
+
+	if (data && data->call_site == call_site) {
+		data->hit++;
+		data->bytes_req += bytes_req;
+		data->bytes_alloc += bytes_req;
+	} else {
+		data = malloc(sizeof(*data));
+		data->call_site = call_site;
+		data->hit = 1;
+		data->bytes_req = bytes_req;
+		data->bytes_alloc = bytes_alloc;
+
+		rb_link_node(&data->node, parent, node);
+		rb_insert_color(&data->node, &root_caller_stat);
+	}
+}
+
+static void process_alloc_event(struct raw_event_sample *raw,
+				struct event *event,
+				int cpu __used,
+				u64 timestamp __used,
+				struct thread *thread __used,
+				int node __used)
+{
+	unsigned long call_site;
+	unsigned long ptr;
+	int bytes_req;
+	int bytes_alloc;
+
+	ptr = raw_field_value(event, "ptr", raw->data);
+	call_site = raw_field_value(event, "call_site", raw->data);
+	bytes_req = raw_field_value(event, "bytes_req", raw->data);
+	bytes_alloc = raw_field_value(event, "bytes_alloc", raw->data);
+
+	insert_alloc_stat(ptr, bytes_req, bytes_alloc);
+	insert_caller_stat(call_site, bytes_req, bytes_alloc);
+
+	total_requested += bytes_req;
+	total_allocated += bytes_alloc;
+}
+
+static void process_free_event(struct raw_event_sample *raw __used,
+			       struct event *event __used,
+			       int cpu __used,
+			       u64 timestamp __used,
+			       struct thread *thread __used)
+{
+}
+
+static void
+process_raw_event(event_t *raw_event __used, void *more_data,
+		  int cpu, u64 timestamp, struct thread *thread)
+{
+	struct raw_event_sample *raw = more_data;
+	struct event *event;
+	int type;
+
+	type = trace_parse_common_type(raw->data);
+	event = trace_find_event(type);
+
+	if (!strcmp(event->name, "kmalloc") ||
+	    !strcmp(event->name, "kmem_cache_alloc")) {
+		process_alloc_event(raw, event, cpu, timestamp, thread, 0);
+		return;
+	}
+
+	if (!strcmp(event->name, "kmalloc_node") ||
+	    !strcmp(event->name, "kmem_cache_alloc_node")) {
+		process_alloc_event(raw, event, cpu, timestamp, thread, 1);
+		return;
+	}
+
+	if (!strcmp(event->name, "kfree") ||
+	    !strcmp(event->name, "kmem_cache_free")) {
+		process_free_event(raw, event, cpu, timestamp, thread);
+		return;
+	}
+}
+
+static int
+process_sample_event(event_t *event, unsigned long offset, unsigned long head)
+{
+	u64 ip = event->ip.ip;
+	u64 timestamp = -1;
+	u32 cpu = -1;
+	u64 period = 1;
+	void *more_data = event->ip.__more_data;
+	struct thread *thread = threads__findnew(event->ip.pid);
+
+	if (sample_type & PERF_SAMPLE_TIME) {
+		timestamp = *(u64 *)more_data;
+		more_data += sizeof(u64);
+	}
+
+	if (sample_type & PERF_SAMPLE_CPU) {
+		cpu = *(u32 *)more_data;
+		more_data += sizeof(u32);
+		more_data += sizeof(u32); /* reserved */
+	}
+
+	if (sample_type & PERF_SAMPLE_PERIOD) {
+		period = *(u64 *)more_data;
+		more_data += sizeof(u64);
+	}
+
+	dump_printf("%p [%p]: PERF_RECORD_SAMPLE (IP, %d): %d/%d: %p period: %Ld\n",
+		(void *)(offset + head),
+		(void *)(long)(event->header.size),
+		event->header.misc,
+		event->ip.pid, event->ip.tid,
+		(void *)(long)ip,
+		(long long)period);
+
+	if (thread == NULL) {
+		pr_debug("problem processing %d event, skipping it.\n",
+			 event->header.type);
+		return -1;
+	}
+
+	dump_printf(" ... thread: %s:%d\n", thread->comm, thread->pid);
+
+	process_raw_event(event, more_data, cpu, timestamp, thread);
+
+	return 0;
+}
+
+static int sample_type_check(u64 type)
+{
+	sample_type = type;
+
+	if (!(sample_type & PERF_SAMPLE_RAW)) {
+		fprintf(stderr,
+			"No trace sample to read. Did you call perf record "
+			"without -R?");
+		return -1;
+	}
+
+	return 0;
+}
+
+static struct perf_file_handler file_handler = {
+	.process_sample_event	= process_sample_event,
+	.process_comm_event	= process_comm_event,
+	.sample_type_check	= sample_type_check,
+};
+
+static int read_events(void)
+{
+	register_idle_thread();
+	register_perf_file_handler(&file_handler);
+
+	return mmap_dispatch_perf_file(&header, input_name, 0, 0,
+				       &cwdlen, &cwd);
+}
+
+static double fragmentation(unsigned long n_req, unsigned long n_alloc)
+{
+	if (n_alloc == 0)
+		return 0.0;
+	else
+		return 100.0 - (100.0 * n_req / n_alloc);
+}
+
+static void __print_result(struct rb_root *root, int n_lines, int is_caller)
+{
+	struct rb_node *next;
+
+	printf("\n ------------------------------------------------------------------------------\n");
+	if (is_caller)
+		printf(" Callsite          |");
+	else
+		printf(" Alloc Ptr         |");
+	printf(" Total_alloc/Per |  Total_req/Per  |  Hit   | Fragmentation\n");
+	printf(" ------------------------------------------------------------------------------\n");
+
+	next = rb_first(root);
+
+	while (next && n_lines--) {
+		struct alloc_stat *data;
+
+		data = rb_entry(next, struct alloc_stat, node);
+
+		printf(" %-16p  | %8llu/%-6lu | %8llu/%-6lu | %6lu | %8.3f%%\n",
+		       is_caller ? (void *)(unsigned long)data->call_site :
+				   (void *)(unsigned long)data->ptr,
+		       (unsigned long long)data->bytes_alloc,
+		       (unsigned long)data->bytes_alloc / data->hit,
+		       (unsigned long long)data->bytes_req,
+		       (unsigned long)data->bytes_req / data->hit,
+		       (unsigned long)data->hit,
+		       fragmentation(data->bytes_req, data->bytes_alloc));
+
+		next = rb_next(next);
+	}
+
+	if (n_lines == -1)
+		printf(" ...               | ...             | ...             | ...    | ...   \n");
+
+	printf(" ------------------------------------------------------------------------------\n");
+}
+
+static void print_summary(void)
+{
+	printf("\nSUMMARY\n=======\n");
+	printf("Total bytes requested: %lu\n", total_requested);
+	printf("Total bytes allocated: %lu\n", total_allocated);
+	printf("Total bytes wasted on internal fragmentation: %lu\n",
+	       total_allocated - total_requested);
+	printf("Internal fragmentation: %f%%\n",
+	       fragmentation(total_requested, total_allocated));
+}
+
+static void print_result(void)
+{
+	if (caller_flag)
+		__print_result(&root_caller_sorted, caller_lines, 1);
+	if (alloc_flag)
+		__print_result(&root_alloc_sorted, alloc_lines, 0);
+	print_summary();
+}
+
+static void sort_insert(struct rb_root *root, struct alloc_stat *data,
+			sort_fn_t sort_fn)
+{
+	struct rb_node **new = &(root->rb_node);
+	struct rb_node *parent = NULL;
+
+	while (*new) {
+		struct alloc_stat *this;
+		int cmp;
+
+		this = rb_entry(*new, struct alloc_stat, node);
+		parent = *new;
+
+		cmp = sort_fn(data, this);
+
+		if (cmp > 0)
+			new = &((*new)->rb_left);
+		else
+			new = &((*new)->rb_right);
+	}
+
+	rb_link_node(&data->node, parent, new);
+	rb_insert_color(&data->node, root);
+}
+
+static void __sort_result(struct rb_root *root, struct rb_root *root_sorted,
+			  sort_fn_t sort_fn)
+{
+	struct rb_node *node;
+	struct alloc_stat *data;
+
+	for (;;) {
+		node = rb_first(root);
+		if (!node)
+			break;
+
+		rb_erase(node, root);
+		data = rb_entry(node, struct alloc_stat, node);
+		sort_insert(root_sorted, data, sort_fn);
+	}
+}
+
+static void sort_result(void)
+{
+	__sort_result(&root_alloc_stat, &root_alloc_sorted, alloc_sort_fn);
+	__sort_result(&root_caller_stat, &root_caller_sorted, caller_sort_fn);
+}
+
+static int __cmd_kmem(void)
+{
+	setup_pager();
+	read_events();
+	sort_result();
+	print_result();
+
+	return 0;
+}
+
+static const char * const kmem_usage[] = {
+	"perf kmem [<options>] {record}",
+	NULL
+};
+
+
+static int ptr_cmp(struct alloc_stat *l, struct alloc_stat *r)
+{
+	if (l->ptr < r->ptr)
+		return -1;
+	else if (l->ptr > r->ptr)
+		return 1;
+	return 0;
+}
+
+static int callsite_cmp(struct alloc_stat *l, struct alloc_stat *r)
+{
+	if (l->call_site < r->call_site)
+		return -1;
+	else if (l->call_site > r->call_site)
+		return 1;
+	return 0;
+}
+
+static int bytes_cmp(struct alloc_stat *l, struct alloc_stat *r)
+{
+	if (l->bytes_alloc < r->bytes_alloc)
+		return -1;
+	else if (l->bytes_alloc > r->bytes_alloc)
+		return 1;
+	return 0;
+}
+
+static int parse_sort_opt(const struct option *opt __used,
+			  const char *arg, int unset __used)
+{
+	sort_fn_t sort_fn;
+
+	if (!arg)
+		return -1;
+
+	if (strcmp(arg, "ptr") == 0)
+		sort_fn = ptr_cmp;
+	else if (strcmp(arg, "call_site") == 0)
+		sort_fn = callsite_cmp;
+	else if (strcmp(arg, "bytes") == 0)
+		sort_fn = bytes_cmp;
+	else
+		return -1;
+
+	if (caller_flag > alloc_flag)
+		caller_sort_fn = sort_fn;
+	else
+		alloc_sort_fn = sort_fn;
+
+	return 0;
+}
+
+static int parse_stat_opt(const struct option *opt __used,
+			  const char *arg, int unset __used)
+{
+	if (!arg)
+		return -1;
+
+	if (strcmp(arg, "alloc") == 0)
+		alloc_flag = (caller_flag + 1);
+	else if (strcmp(arg, "caller") == 0)
+		caller_flag = (alloc_flag + 1);
+	else
+		return -1;
+	return 0;
+}
+
+static int parse_line_opt(const struct option *opt __used,
+			  const char *arg, int unset __used)
+{
+	int lines;
+
+	if (!arg)
+		return -1;
+
+	lines = strtoul(arg, NULL, 10);
+
+	if (caller_flag > alloc_flag)
+		caller_lines = lines;
+	else
+		alloc_lines = lines;
+
+	return 0;
+}
+
+static const struct option kmem_options[] = {
+	OPT_STRING('i', "input", &input_name, "file",
+		   "input file name"),
+	OPT_CALLBACK(0, "stat", NULL, "<alloc>|<caller>",
+		     "stat selector, Pass 'alloc' or 'caller'.",
+		     parse_stat_opt),
+	OPT_CALLBACK('s', "sort", NULL, "key",
+		     "sort by key: ptr, call_site, hit, bytes",
+		     parse_sort_opt),
+	OPT_CALLBACK('l', "line", NULL, "num",
+		     "show n lins",
+		     parse_line_opt),
+	OPT_END()
+};
+
+static const char *record_args[] = {
+	"record",
+	"-a",
+	"-R",
+	"-M",
+	"-f",
+	"-c", "1",
+	"-e", "kmem:kmalloc",
+	"-e", "kmem:kmalloc_node",
+	"-e", "kmem:kfree",
+	"-e", "kmem:kmem_cache_alloc",
+	"-e", "kmem:kmem_cache_alloc_node",
+	"-e", "kmem:kmem_cache_free",
+};
+
+static int __cmd_record(int argc, const char **argv)
+{
+	unsigned int rec_argc, i, j;
+	const char **rec_argv;
+
+	rec_argc = ARRAY_SIZE(record_args) + argc - 1;
+	rec_argv = calloc(rec_argc + 1, sizeof(char *));
+
+	for (i = 0; i < ARRAY_SIZE(record_args); i++)
+		rec_argv[i] = strdup(record_args[i]);
+
+	for (j = 1; j < (unsigned int)argc; j++, i++)
+		rec_argv[i] = argv[j];
+
+	return cmd_record(i, rec_argv, NULL);
+}
+
+int cmd_kmem(int argc, const char **argv, const char *prefix __used)
+{
+	symbol__init(0);
+
+	argc = parse_options(argc, argv, kmem_options, kmem_usage, 0);
+
+	if (argc && !strncmp(argv[0], "rec", 3))
+		return __cmd_record(argc, argv);
+	else if (argc)
+		usage_with_options(kmem_usage, kmem_options);
+
+	if (!alloc_sort_fn)
+		alloc_sort_fn = bytes_cmp;
+	if (!caller_sort_fn)
+		caller_sort_fn = bytes_cmp;
+
+	return __cmd_kmem();
+}
+
