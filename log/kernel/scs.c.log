commit 333ed74689b8fca097574124fef7fa0e3d7f79d4
Author: Will Deacon <will@kernel.org>
Date:   Wed Jun 3 12:16:37 2020 +0100

    scs: Report SCS usage in bytes rather than number of entries
    
    Fix the SCS debug usage check so that we report the number of bytes
    used, rather than the number of entries.
    
    Fixes: 5bbaf9d1fcb9 ("scs: Add support for stack usage debugging")
    Reported-by: Sami Tolvanen <samitolvanen@google.com>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/kernel/scs.c b/kernel/scs.c
index 222a7a9ad543..5d4d9bbdec36 100644
--- a/kernel/scs.c
+++ b/kernel/scs.c
@@ -74,7 +74,7 @@ static void scs_check_usage(struct task_struct *tsk)
 	for (p = task_scs(tsk); p < __scs_magic(tsk); ++p) {
 		if (!READ_ONCE_NOCHECK(*p))
 			break;
-		used++;
+		used += sizeof(*p);
 	}
 
 	while (used > curr) {

commit aa7a65ae5b8f459617e5ed1422301386e7f12274
Author: Will Deacon <will@kernel.org>
Date:   Fri May 15 16:15:46 2020 +0100

    scs: Remove references to asm/scs.h from core code
    
    asm/scs.h is no longer needed by the core code, so remove a redundant
    header inclusion and update the stale Kconfig text.
    
    Tested-by: Sami Tolvanen <samitolvanen@google.com>
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/kernel/scs.c b/kernel/scs.c
index faf0ecd7b893..222a7a9ad543 100644
--- a/kernel/scs.c
+++ b/kernel/scs.c
@@ -10,7 +10,6 @@
 #include <linux/scs.h>
 #include <linux/slab.h>
 #include <linux/vmstat.h>
-#include <asm/scs.h>
 
 static struct kmem_cache *scs_cache;
 

commit 88485be531f4aee841ddc53b56e2f6e6a338854d
Author: Will Deacon <will@kernel.org>
Date:   Fri May 15 14:56:05 2020 +0100

    scs: Move scs_overflow_check() out of architecture code
    
    There is nothing architecture-specific about scs_overflow_check() as
    it's just a trivial wrapper around scs_corrupted().
    
    For parity with task_stack_end_corrupted(), rename scs_corrupted() to
    task_scs_end_corrupted() and call it from schedule_debug() when
    CONFIG_SCHED_STACK_END_CHECK_is enabled, which better reflects its
    purpose as a debug feature to catch inadvertent overflow of the SCS.
    Finally, remove the unused scs_overflow_check() function entirely.
    
    This has absolutely no impact on architectures that do not support SCS
    (currently arm64 only).
    
    Tested-by: Sami Tolvanen <samitolvanen@google.com>
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/kernel/scs.c b/kernel/scs.c
index aea841cd7586..faf0ecd7b893 100644
--- a/kernel/scs.c
+++ b/kernel/scs.c
@@ -98,7 +98,8 @@ void scs_release(struct task_struct *tsk)
 	if (!s)
 		return;
 
-	WARN(scs_corrupted(tsk), "corrupted shadow stack detected when freeing task\n");
+	WARN(task_scs_end_corrupted(tsk),
+	     "corrupted shadow stack detected when freeing task\n");
 	scs_check_usage(tsk);
 	scs_free(s);
 }

commit bee348fab099b0f551caa874663e82a7f3bb64b3
Author: Will Deacon <will@kernel.org>
Date:   Fri May 15 14:43:11 2020 +0100

    scs: Move accounting into alloc/free functions
    
    There's no need to perform the shadow stack page accounting independently
    of the lifetime of the underlying allocation, so call the accounting code
    from the {alloc,free}() functions and simplify the code in the process.
    
    Tested-by: Sami Tolvanen <samitolvanen@google.com>
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/kernel/scs.c b/kernel/scs.c
index 5ff8663e4a67..aea841cd7586 100644
--- a/kernel/scs.c
+++ b/kernel/scs.c
@@ -14,25 +14,35 @@
 
 static struct kmem_cache *scs_cache;
 
+static void __scs_account(void *s, int account)
+{
+	struct page *scs_page = virt_to_page(s);
+
+	mod_zone_page_state(page_zone(scs_page), NR_KERNEL_SCS_KB,
+			    account * (SCS_SIZE / SZ_1K));
+}
+
 static void *scs_alloc(int node)
 {
-	void *s;
-
-	s = kmem_cache_alloc_node(scs_cache, GFP_SCS, node);
-	if (s) {
-		*__scs_magic(s) = SCS_END_MAGIC;
-		/*
-		 * Poison the allocation to catch unintentional accesses to
-		 * the shadow stack when KASAN is enabled.
-		 */
-		kasan_poison_object_data(scs_cache, s);
-	}
+	void *s = kmem_cache_alloc_node(scs_cache, GFP_SCS, node);
+
+	if (!s)
+		return NULL;
 
+	*__scs_magic(s) = SCS_END_MAGIC;
+
+	/*
+	 * Poison the allocation to catch unintentional accesses to
+	 * the shadow stack when KASAN is enabled.
+	 */
+	kasan_poison_object_data(scs_cache, s);
+	__scs_account(s, 1);
 	return s;
 }
 
 static void scs_free(void *s)
 {
+	__scs_account(s, -1);
 	kasan_unpoison_object_data(scs_cache, s);
 	kmem_cache_free(scs_cache, s);
 }
@@ -42,17 +52,6 @@ void __init scs_init(void)
 	scs_cache = kmem_cache_create("scs_cache", SCS_SIZE, 0, 0, NULL);
 }
 
-static struct page *__scs_page(struct task_struct *tsk)
-{
-	return virt_to_page(task_scs(tsk));
-}
-
-static void scs_account(struct task_struct *tsk, int account)
-{
-	mod_zone_page_state(page_zone(__scs_page(tsk)), NR_KERNEL_SCS_KB,
-		account * (SCS_SIZE / 1024));
-}
-
 int scs_prepare(struct task_struct *tsk, int node)
 {
 	void *s = scs_alloc(node);
@@ -61,7 +60,6 @@ int scs_prepare(struct task_struct *tsk, int node)
 		return -ENOMEM;
 
 	task_scs(tsk) = task_scs_sp(tsk) = s;
-	scs_account(tsk, 1);
 	return 0;
 }
 
@@ -102,6 +100,5 @@ void scs_release(struct task_struct *tsk)
 
 	WARN(scs_corrupted(tsk), "corrupted shadow stack detected when freeing task\n");
 	scs_check_usage(tsk);
-	scs_account(tsk, -1);
 	scs_free(s);
 }

commit 51189c7a7ed1b4ed4493e27275d466ff60406d3a
Author: Will Deacon <will@kernel.org>
Date:   Fri May 15 14:11:05 2020 +0100

    arm64: scs: Store absolute SCS stack pointer value in thread_info
    
    Storing the SCS information in thread_info as a {base,offset} pair
    introduces an additional load instruction on the ret-to-user path,
    since the SCS stack pointer in x18 has to be converted back to an offset
    by subtracting the base.
    
    Replace the offset with the absolute SCS stack pointer value instead
    and avoid the redundant load.
    
    Tested-by: Sami Tolvanen <samitolvanen@google.com>
    Reviewed-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/kernel/scs.c b/kernel/scs.c
index 9389c28f0853..5ff8663e4a67 100644
--- a/kernel/scs.c
+++ b/kernel/scs.c
@@ -60,8 +60,7 @@ int scs_prepare(struct task_struct *tsk, int node)
 	if (!s)
 		return -ENOMEM;
 
-	task_scs(tsk) = s;
-	task_scs_offset(tsk) = 0;
+	task_scs(tsk) = task_scs_sp(tsk) = s;
 	scs_account(tsk, 1);
 	return 0;
 }

commit 5bbaf9d1fcb9be696ee9a61636ab6803556c70f2
Author: Sami Tolvanen <samitolvanen@google.com>
Date:   Mon Apr 27 09:00:09 2020 -0700

    scs: Add support for stack usage debugging
    
    Implements CONFIG_DEBUG_STACK_USAGE for shadow stacks. When enabled,
    also prints out the highest shadow stack usage per process.
    
    Signed-off-by: Sami Tolvanen <samitolvanen@google.com>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Acked-by: Will Deacon <will@kernel.org>
    [will: rewrote most of scs_check_usage()]
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/kernel/scs.c b/kernel/scs.c
index 6d2f983ac54e..9389c28f0853 100644
--- a/kernel/scs.c
+++ b/kernel/scs.c
@@ -63,10 +63,37 @@ int scs_prepare(struct task_struct *tsk, int node)
 	task_scs(tsk) = s;
 	task_scs_offset(tsk) = 0;
 	scs_account(tsk, 1);
-
 	return 0;
 }
 
+static void scs_check_usage(struct task_struct *tsk)
+{
+	static unsigned long highest;
+
+	unsigned long *p, prev, curr = highest, used = 0;
+
+	if (!IS_ENABLED(CONFIG_DEBUG_STACK_USAGE))
+		return;
+
+	for (p = task_scs(tsk); p < __scs_magic(tsk); ++p) {
+		if (!READ_ONCE_NOCHECK(*p))
+			break;
+		used++;
+	}
+
+	while (used > curr) {
+		prev = cmpxchg_relaxed(&highest, curr, used);
+
+		if (prev == curr) {
+			pr_info("%s (%d): highest shadow stack usage: %lu bytes\n",
+				tsk->comm, task_pid_nr(tsk), used);
+			break;
+		}
+
+		curr = prev;
+	}
+}
+
 void scs_release(struct task_struct *tsk)
 {
 	void *s = task_scs(tsk);
@@ -75,6 +102,7 @@ void scs_release(struct task_struct *tsk)
 		return;
 
 	WARN(scs_corrupted(tsk), "corrupted shadow stack detected when freeing task\n");
+	scs_check_usage(tsk);
 	scs_account(tsk, -1);
 	scs_free(s);
 }

commit 628d06a48f57c36abdc2a024930212e654a501b7
Author: Sami Tolvanen <samitolvanen@google.com>
Date:   Mon Apr 27 09:00:08 2020 -0700

    scs: Add page accounting for shadow call stack allocations
    
    This change adds accounting for the memory allocated for shadow stacks.
    
    Signed-off-by: Sami Tolvanen <samitolvanen@google.com>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Acked-by: Will Deacon <will@kernel.org>
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/kernel/scs.c b/kernel/scs.c
index 38f8f31c9451..6d2f983ac54e 100644
--- a/kernel/scs.c
+++ b/kernel/scs.c
@@ -6,8 +6,10 @@
  */
 
 #include <linux/kasan.h>
+#include <linux/mm.h>
 #include <linux/scs.h>
 #include <linux/slab.h>
+#include <linux/vmstat.h>
 #include <asm/scs.h>
 
 static struct kmem_cache *scs_cache;
@@ -40,6 +42,17 @@ void __init scs_init(void)
 	scs_cache = kmem_cache_create("scs_cache", SCS_SIZE, 0, 0, NULL);
 }
 
+static struct page *__scs_page(struct task_struct *tsk)
+{
+	return virt_to_page(task_scs(tsk));
+}
+
+static void scs_account(struct task_struct *tsk, int account)
+{
+	mod_zone_page_state(page_zone(__scs_page(tsk)), NR_KERNEL_SCS_KB,
+		account * (SCS_SIZE / 1024));
+}
+
 int scs_prepare(struct task_struct *tsk, int node)
 {
 	void *s = scs_alloc(node);
@@ -49,6 +62,7 @@ int scs_prepare(struct task_struct *tsk, int node)
 
 	task_scs(tsk) = s;
 	task_scs_offset(tsk) = 0;
+	scs_account(tsk, 1);
 
 	return 0;
 }
@@ -61,5 +75,6 @@ void scs_release(struct task_struct *tsk)
 		return;
 
 	WARN(scs_corrupted(tsk), "corrupted shadow stack detected when freeing task\n");
+	scs_account(tsk, -1);
 	scs_free(s);
 }

commit d08b9f0ca6605e13dcb48f04e55a30545b3c71eb
Author: Sami Tolvanen <samitolvanen@google.com>
Date:   Mon Apr 27 09:00:07 2020 -0700

    scs: Add support for Clang's Shadow Call Stack (SCS)
    
    This change adds generic support for Clang's Shadow Call Stack,
    which uses a shadow stack to protect return addresses from being
    overwritten by an attacker. Details are available here:
    
      https://clang.llvm.org/docs/ShadowCallStack.html
    
    Note that security guarantees in the kernel differ from the ones
    documented for user space. The kernel must store addresses of
    shadow stacks in memory, which means an attacker capable reading
    and writing arbitrary memory may be able to locate them and hijack
    control flow by modifying the stacks.
    
    Signed-off-by: Sami Tolvanen <samitolvanen@google.com>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Miguel Ojeda <miguel.ojeda.sandonis@gmail.com>
    [will: Numerous cosmetic changes]
    Signed-off-by: Will Deacon <will@kernel.org>

diff --git a/kernel/scs.c b/kernel/scs.c
new file mode 100644
index 000000000000..38f8f31c9451
--- /dev/null
+++ b/kernel/scs.c
@@ -0,0 +1,65 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Shadow Call Stack support.
+ *
+ * Copyright (C) 2019 Google LLC
+ */
+
+#include <linux/kasan.h>
+#include <linux/scs.h>
+#include <linux/slab.h>
+#include <asm/scs.h>
+
+static struct kmem_cache *scs_cache;
+
+static void *scs_alloc(int node)
+{
+	void *s;
+
+	s = kmem_cache_alloc_node(scs_cache, GFP_SCS, node);
+	if (s) {
+		*__scs_magic(s) = SCS_END_MAGIC;
+		/*
+		 * Poison the allocation to catch unintentional accesses to
+		 * the shadow stack when KASAN is enabled.
+		 */
+		kasan_poison_object_data(scs_cache, s);
+	}
+
+	return s;
+}
+
+static void scs_free(void *s)
+{
+	kasan_unpoison_object_data(scs_cache, s);
+	kmem_cache_free(scs_cache, s);
+}
+
+void __init scs_init(void)
+{
+	scs_cache = kmem_cache_create("scs_cache", SCS_SIZE, 0, 0, NULL);
+}
+
+int scs_prepare(struct task_struct *tsk, int node)
+{
+	void *s = scs_alloc(node);
+
+	if (!s)
+		return -ENOMEM;
+
+	task_scs(tsk) = s;
+	task_scs_offset(tsk) = 0;
+
+	return 0;
+}
+
+void scs_release(struct task_struct *tsk)
+{
+	void *s = task_scs(tsk);
+
+	if (!s)
+		return;
+
+	WARN(scs_corrupted(tsk), "corrupted shadow stack detected when freeing task\n");
+	scs_free(s);
+}
