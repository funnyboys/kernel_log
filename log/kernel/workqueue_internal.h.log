commit 6d25be5782e482eb93e3de0c94d0a517879377d0
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Mar 13 17:55:48 2019 +0100

    sched/core, workqueues: Distangle worker accounting from rq lock
    
    The worker accounting for CPU bound workers is plugged into the core
    scheduler code and the wakeup code. This is not a hard requirement and
    can be avoided by keeping track of the state in the workqueue code
    itself.
    
    Keep track of the sleeping state in the worker itself and call the
    notifier before entering the core scheduler. There might be false
    positives when the task is woken between that call and actually
    scheduling, but that's not really different from scheduling and being
    woken immediately after switching away. When nr_running is updated when
    the task is retunrning from schedule() then it is later compared when it
    is done from ttwu().
    
    [ bigeasy: preempt_disable() around wq_worker_sleeping() by Daniel Bristot de Oliveira ]
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Tejun Heo <tj@kernel.org>
    Cc: Daniel Bristot de Oliveira <bristot@redhat.com>
    Cc: Lai Jiangshan <jiangshanlai@gmail.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/ad2b29b5715f970bffc1a7026cabd6ff0b24076a.1532952814.git.bristot@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index cb68b03ca89a..498de0e909a4 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -44,6 +44,7 @@ struct worker {
 	unsigned long		last_active;	/* L: last active timestamp */
 	unsigned int		flags;		/* X: flags */
 	int			id;		/* I: worker id */
+	int			sleeping;	/* None */
 
 	/*
 	 * Opaque string set with work_set_desc().  Printed out with task
@@ -72,8 +73,8 @@ static inline struct worker *current_wq_worker(void)
  * Scheduler hooks for concurrency managed workqueue.  Only to be used from
  * sched/ and workqueue.c.
  */
-void wq_worker_waking_up(struct task_struct *task, int cpu);
-struct task_struct *wq_worker_sleeping(struct task_struct *task);
+void wq_worker_running(struct task_struct *task);
+void wq_worker_sleeping(struct task_struct *task);
 work_func_t wq_worker_last_func(struct task_struct *task);
 
 #endif /* _KERNEL_WORKQUEUE_INTERNAL_H */

commit 1b69ac6b40ebd85eed73e4dbccde2a36961ab990
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Fri Feb 1 14:20:42 2019 -0800

    psi: fix aggregation idle shut-off
    
    psi has provisions to shut off the periodic aggregation worker when
    there is a period of no task activity - and thus no data that needs
    aggregating.  However, while developing psi monitoring, Suren noticed
    that the aggregation clock currently won't stay shut off for good.
    
    Debugging this revealed a flaw in the idle design: an aggregation run
    will see no task activity and decide to go to sleep; shortly thereafter,
    the kworker thread that executed the aggregation will go idle and cause
    a scheduling change, during which the psi callback will kick the
    !pending worker again.  This will ping-pong forever, and is equivalent
    to having no shut-off logic at all (but with more code!)
    
    Fix this by exempting aggregation workers from psi's clock waking logic
    when the state change is them going to sleep.  To do this, tag workers
    with the last work function they executed, and if in psi we see a worker
    going to sleep after aggregating psi data, we will not reschedule the
    aggregation work item.
    
    What if the worker is also executing other items before or after?
    
    Any psi state times that were incurred by work items preceding the
    aggregation work will have been collected from the per-cpu buckets
    during the aggregation itself.  If there are work items following the
    aggregation work, the worker's last_func tag will be overwritten and the
    aggregator will be kept alive to process this genuine new activity.
    
    If the aggregation work is the last thing the worker does, and we decide
    to go idle, the brief period of non-idle time incurred between the
    aggregation run and the kworker's dequeue will be stranded in the
    per-cpu buckets until the clock is woken by later activity.  But that
    should not be a problem.  The buckets can hold 4s worth of time, and
    future activity will wake the clock with a 2s delay, giving us 2s worth
    of data we can leave behind when disabling aggregation.  If it takes a
    worker more than two seconds to go idle after it finishes its last work
    item, we likely have bigger problems in the system, and won't notice one
    sample that was averaged with a bogus per-CPU weight.
    
    Link: http://lkml.kernel.org/r/20190116193501.1910-1-hannes@cmpxchg.org
    Fixes: eb414681d5a0 ("psi: pressure stall information for CPU, memory, and IO")
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reported-by: Suren Baghdasaryan <surenb@google.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Lai Jiangshan <jiangshanlai@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index 66fbb5a9e633..cb68b03ca89a 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -53,6 +53,9 @@ struct worker {
 
 	/* used only by rescuers to point to the target workqueue */
 	struct workqueue_struct	*rescue_wq;	/* I: the workqueue to rescue */
+
+	/* used by the scheduler to determine a worker's last known identity */
+	work_func_t		last_func;
 };
 
 /**
@@ -67,9 +70,10 @@ static inline struct worker *current_wq_worker(void)
 
 /*
  * Scheduler hooks for concurrency managed workqueue.  Only to be used from
- * sched/core.c and workqueue.c.
+ * sched/ and workqueue.c.
  */
 void wq_worker_waking_up(struct task_struct *task, int cpu);
 struct task_struct *wq_worker_sleeping(struct task_struct *task);
+work_func_t wq_worker_last_func(struct task_struct *task);
 
 #endif /* _KERNEL_WORKQUEUE_INTERNAL_H */

commit 8bf895931ee3b635888b5a302055f97362c92d79
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 18 08:47:13 2018 -0700

    workqueue: Set worker->desc to workqueue name by default
    
    Work functions can use set_worker_desc() to improve the visibility of
    what the worker task is doing.  Currently, the desc field is unset at
    the beginning of each execution and there is a separate field to track
    the field is set during the current execution.
    
    Instead of leaving empty till desc is set, worker->desc can be used to
    remember the last workqueue the worker worked on by default and users
    that use set_worker_desc() can override it to something more
    informative as necessary.
    
    This simplifies desc handling and helps tracking the last workqueue
    that the worker exected on to improve visibility.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index 4a182e027207..66fbb5a9e633 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -31,7 +31,6 @@ struct worker {
 	struct work_struct	*current_work;	/* L: work being processed */
 	work_func_t		current_func;	/* L: current_work's fn */
 	struct pool_workqueue	*current_pwq; /* L: current_work's pwq */
-	bool			desc_valid;	/* ->desc is valid */
 	struct list_head	scheduled;	/* L: scheduled works */
 
 	/* 64 bytes boundary on 64bit, 32 on 32bit */

commit a2d812a27a4530b999a92f245d0d8291663e8c38
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 18 08:47:13 2018 -0700

    workqueue: Make worker_attach/detach_pool() update worker->pool
    
    For historical reasons, the worker attach/detach functions don't
    currently manage worker->pool and the callers are manually and
    inconsistently updating it.
    
    This patch moves worker->pool updates into the worker attach/detach
    functions.  This makes worker->pool consistent and clearly defines how
    worker->pool updates are synchronized.
    
    This will help later workqueue visibility improvements by allowing
    safe access to workqueue information from worker->task.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index d390d1be3748..4a182e027207 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -37,7 +37,7 @@ struct worker {
 	/* 64 bytes boundary on 64bit, 32 on 32bit */
 
 	struct task_struct	*task;		/* I: worker task */
-	struct worker_pool	*pool;		/* I: the associated pool */
+	struct worker_pool	*pool;		/* A: the associated pool */
 						/* L: for rescuers */
 	struct list_head	node;		/* A: anchored at pool->workers */
 						/* A: runs through worker->node */

commit e4880bc5dfb1f02b152e62a894b5c6f3e995b3cf
Merge: 136fc5c41f34 cef572ad9bd7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 6 12:26:49 2017 -0800

    Merge branch 'for-4.14-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/wq
    
    Pull workqueue fix from Tejun Heo:
     "Another fix for a really old bug.
    
      It only affects drain_workqueue() which isn't used often and even then
      triggers only during a pretty small race window, so it isn't too
      surprising that it stayed hidden for so long.
    
      The fix is straight-forward and low-risk. Kudos to Li Bin for
      reporting and fixing the bug"
    
    * 'for-4.14-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/wq:
      workqueue: Fix NULL pointer dereference

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index 8635417c587b..efdd72e15794 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  * kernel/workqueue_internal.h
  *

commit cef572ad9bd7f85035ba8272e5352040e8be0152
Author: Li Bin <huawei.libin@huawei.com>
Date:   Sat Oct 28 11:07:28 2017 +0800

    workqueue: Fix NULL pointer dereference
    
    When queue_work() is used in irq (not in task context), there is
    a potential case that trigger NULL pointer dereference.
    ----------------------------------------------------------------
    worker_thread()
    |-spin_lock_irq()
    |-process_one_work()
            |-worker->current_pwq = pwq
            |-spin_unlock_irq()
            |-worker->current_func(work)
            |-spin_lock_irq()
            |-worker->current_pwq = NULL
    |-spin_unlock_irq()
    
                                    //interrupt here
                                    |-irq_handler
                                            |-__queue_work()
                                                    //assuming that the wq is draining
                                                    |-is_chained_work(wq)
                                                            |-current_wq_worker()
                                                            //Here, 'current' is the interrupted worker!
                                                                    |-current->current_pwq is NULL here!
    |-schedule()
    ----------------------------------------------------------------
    
    Avoid it by checking for task context in current_wq_worker(), and
    if not in task context, we shouldn't use the 'current' to check the
    condition.
    
    Reported-by: Xiaofei Tan <tanxiaofei@huawei.com>
    Signed-off-by: Li Bin <huawei.libin@huawei.com>
    Reviewed-by: Lai Jiangshan <jiangshanlai@gmail.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Fixes: 8d03ecfe4718 ("workqueue: reimplement is_chained_work() using current_wq_worker()")
    Cc: stable@vger.kernel.org # v3.9+

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index 8635417c587b..29fa81f0f51a 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -9,6 +9,7 @@
 
 #include <linux/workqueue.h>
 #include <linux/kthread.h>
+#include <linux/preempt.h>
 
 struct worker_pool;
 
@@ -59,7 +60,7 @@ struct worker {
  */
 static inline struct worker *current_wq_worker(void)
 {
-	if (current->flags & PF_WQ_WORKER)
+	if (in_task() && (current->flags & PF_WQ_WORKER))
 		return kthread_data(current);
 	return NULL;
 }

commit 9b7f6597f013d449d6700d11820faf91ee0ec985
Author: Alexander Gordeev <agordeev@redhat.com>
Date:   Wed Mar 2 12:53:31 2016 +0100

    sched/core: Get rid of 'cpu' argument in wq_worker_sleeping()
    
    Given that wq_worker_sleeping() could only be called for a
    CPU it is running on, we do not need passing a CPU ID as an
    argument.
    
    Suggested-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Alexander Gordeev <agordeev@redhat.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index 45215870ac6c..8635417c587b 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -69,6 +69,6 @@ static inline struct worker *current_wq_worker(void)
  * sched/core.c and workqueue.c.
  */
 void wq_worker_waking_up(struct task_struct *task, int cpu);
-struct task_struct *wq_worker_sleeping(struct task_struct *task, int cpu);
+struct task_struct *wq_worker_sleeping(struct task_struct *task);
 
 #endif /* _KERNEL_WORKQUEUE_INTERNAL_H */

commit 92f9c5c40cc67ffcc5ac7f55fdbd6ae8afc7e0b4
Author: Lai Jiangshan <laijs@cn.fujitsu.com>
Date:   Tue May 20 17:46:34 2014 +0800

    workqueue: rename manager_mutex to attach_mutex
    
    manager_mutex is only used to protect the attaching for the pool
    and the pool->workers list. It protects the pool->workers and operations
    based on this list, such as:
    
            cpu-binding for the workers in the pool->workers
            the operations to set/clear WORKER_UNBOUND
    
    So let's rename manager_mutex to attach_mutex to better reflect its
    role. This patch is a pure rename.
    
    tj: Minor command and description updates.
    
    Signed-off-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index 8888e0672442..45215870ac6c 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -37,8 +37,8 @@ struct worker {
 	struct task_struct	*task;		/* I: worker task */
 	struct worker_pool	*pool;		/* I: the associated pool */
 						/* L: for rescuers */
-	struct list_head	node;		/* M: anchored at pool->workers */
-						/* M: runs through worker->node */
+	struct list_head	node;		/* A: anchored at pool->workers */
+						/* A: runs through worker->node */
 
 	unsigned long		last_active;	/* L: last active timestamp */
 	unsigned int		flags;		/* X: flags */

commit da028469ba173e9c634b6ecf80bb0c69c7d1024d
Author: Lai Jiangshan <laijs@cn.fujitsu.com>
Date:   Tue May 20 17:46:31 2014 +0800

    workqueue: separate iteration role from worker_idr
    
    worker_idr has the iteration (iterating for attached workers) and
    worker ID duties. These two duties don't have to be tied together. We
    can separate them and use a list for tracking attached workers and
    iteration.
    
    Before this separation, it wasn't possible to add rescuer workers to
    worker_idr due to rescuer workers couldn't allocate ID dynamically
    because ID-allocation depends on memory-allocation, which rescuer
    can't depend on.
    
    After separation, we can easily add the rescuer workers to the list for
    iteration without any memory-allocation. It is required when we attach
    the rescuer worker to the pool in later patch.
    
    tj: Minor description updates.
    
    Signed-off-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index 7e2204db0b1a..8888e0672442 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -37,6 +37,8 @@ struct worker {
 	struct task_struct	*task;		/* I: worker task */
 	struct worker_pool	*pool;		/* I: the associated pool */
 						/* L: for rescuers */
+	struct list_head	node;		/* M: anchored at pool->workers */
+						/* M: runs through worker->node */
 
 	unsigned long		last_active;	/* L: last active timestamp */
 	unsigned int		flags;		/* X: flags */

commit 0a0fca9d832b704f116a25badd1ca8c16771dcac
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Tue Jun 4 13:10:24 2013 +0530

    sched: Rename sched.c as sched/core.c in comments and Documentation
    
    Most of the stuff from kernel/sched.c was moved to kernel/sched/core.c long time
    back and the comments/Documentation never got updated.
    
    I figured it out when I was going through sched-domains.txt and so thought of
    fixing it globally.
    
    I haven't crossed check if the stuff that is referenced in sched/core.c by all
    these files is still present and hasn't changed as that wasn't the motive behind
    this patch.
    
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/cdff76a265326ab8d71922a1db5be599f20aad45.1370329560.git.viresh.kumar@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index ad83c96b2ece..7e2204db0b1a 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -64,7 +64,7 @@ static inline struct worker *current_wq_worker(void)
 
 /*
  * Scheduler hooks for concurrency managed workqueue.  Only to be used from
- * sched.c and workqueue.c.
+ * sched/core.c and workqueue.c.
  */
 void wq_worker_waking_up(struct task_struct *task, int cpu);
 struct task_struct *wq_worker_sleeping(struct task_struct *task, int cpu);

commit 3d1cb2059d9374e58da481b783332cf191cb6620
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Apr 30 15:27:22 2013 -0700

    workqueue: include workqueue info when printing debug dump of a worker task
    
    One of the problems that arise when converting dedicated custom
    threadpool to workqueue is that the shared worker pool used by workqueue
    anonimizes each worker making it more difficult to identify what the
    worker was doing on which target from the output of sysrq-t or debug
    dump from oops, BUG() and friends.
    
    This patch implements set_worker_desc() which can be called from any
    workqueue work function to set its description.  When the worker task is
    dumped for whatever reason - sysrq-t, WARN, BUG, oops, lockdep assertion
    and so on - the description will be printed out together with the
    workqueue name and the worker function pointer.
    
    The printing side is implemented by print_worker_info() which is called
    from functions in task dump paths - sched_show_task() and
    dump_stack_print_info().  print_worker_info() can be safely called on
    any task in any state as long as the task struct itself is accessible.
    It uses probe_*() functions to access worker fields.  It may print
    garbage if something went very wrong, but it wouldn't cause (another)
    oops.
    
    The description is currently limited to 24bytes including the
    terminating \0.  worker->desc_valid and workder->desc[] are added and
    the 64 bytes marker which was already incorrect before adding the new
    fields is moved to the correct position.
    
    Here's an example dump with writeback updated to set the bdi name as
    worker desc.
    
     Hardware name: Bochs
     Modules linked in:
     Pid: 7, comm: kworker/u9:0 Not tainted 3.9.0-rc1-work+ #1
     Workqueue: writeback bdi_writeback_workfn (flush-8:0)
      ffffffff820a3ab0 ffff88000f6e9cb8 ffffffff81c61845 ffff88000f6e9cf8
      ffffffff8108f50f 0000000000000000 0000000000000000 ffff88000cde16b0
      ffff88000cde1aa8 ffff88001ee19240 ffff88000f6e9fd8 ffff88000f6e9d08
     Call Trace:
      [<ffffffff81c61845>] dump_stack+0x19/0x1b
      [<ffffffff8108f50f>] warn_slowpath_common+0x7f/0xc0
      [<ffffffff8108f56a>] warn_slowpath_null+0x1a/0x20
      [<ffffffff81200150>] bdi_writeback_workfn+0x2a0/0x3b0
     ...
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Acked-by: Jan Kara <jack@suse.cz>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Dave Chinner <david@fromorbit.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index 84ab6e1dc6fb..ad83c96b2ece 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -29,15 +29,25 @@ struct worker {
 	struct work_struct	*current_work;	/* L: work being processed */
 	work_func_t		current_func;	/* L: current_work's fn */
 	struct pool_workqueue	*current_pwq; /* L: current_work's pwq */
+	bool			desc_valid;	/* ->desc is valid */
 	struct list_head	scheduled;	/* L: scheduled works */
+
+	/* 64 bytes boundary on 64bit, 32 on 32bit */
+
 	struct task_struct	*task;		/* I: worker task */
 	struct worker_pool	*pool;		/* I: the associated pool */
 						/* L: for rescuers */
-	/* 64 bytes boundary on 64bit, 32 on 32bit */
+
 	unsigned long		last_active;	/* L: last active timestamp */
 	unsigned int		flags;		/* X: flags */
 	int			id;		/* I: worker id */
 
+	/*
+	 * Opaque string set with work_set_desc().  Printed out with task
+	 * dump for debugging - WARN, BUG, panic or sysrq.
+	 */
+	char			desc[WORKER_DESC_LEN];
+
 	/* used only by rescuers to point to the target workqueue */
 	struct workqueue_struct	*rescue_wq;	/* I: the workqueue to rescue */
 };

commit a9ab775bcadf122d91e1a201eb66ae2eec90365a
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Mar 19 13:45:21 2013 -0700

    workqueue: directly restore CPU affinity of workers from CPU_ONLINE
    
    Rebinding workers of a per-cpu pool after a CPU comes online involves
    a lot of back-and-forth mostly because only the task itself could
    adjust CPU affinity if PF_THREAD_BOUND was set.
    
    As CPU_ONLINE itself couldn't adjust affinity, it had to somehow
    coerce the workers themselves to perform set_cpus_allowed_ptr().  Due
    to the various states a worker can be in, this led to three different
    paths a worker may be rebound.  worker->rebind_work is queued to busy
    workers.  Idle ones are signaled by unlinking worker->entry and call
    idle_worker_rebind().  The manager isn't covered by either and
    implements its own mechanism.
    
    PF_THREAD_BOUND has been relaced with PF_NO_SETAFFINITY and CPU_ONLINE
    itself now can manipulate CPU affinity of workers.  This patch
    replaces the existing rebind mechanism with direct one where
    CPU_ONLINE iterates over all workers using for_each_pool_worker(),
    restores CPU affinity, and clears WORKER_UNBOUND.
    
    There are a couple subtleties.  All bound idle workers should have
    their runqueues set to that of the bound CPU; however, if the target
    task isn't running, set_cpus_allowed_ptr() just updates the
    cpus_allowed mask deferring the actual migration to when the task
    wakes up.  This is worked around by waking up idle workers after
    restoring CPU affinity before any workers can become bound.
    
    Another subtlety is stems from matching @pool->nr_running with the
    number of running unbound workers.  While DISASSOCIATED, all workers
    are unbound and nr_running is zero.  As workers become bound again,
    nr_running needs to be adjusted accordingly; however, there is no good
    way to tell whether a given worker is running without poking into
    scheduler internals.  Instead of clearing UNBOUND directly,
    rebind_workers() replaces UNBOUND with another new NOT_RUNNING flag -
    REBOUND, which will later be cleared by the workers themselves while
    preparing for the next round of work item execution.  The only change
    needed for the workers is clearing REBOUND along with PREP.
    
    * This patch leaves for_each_busy_worker() without any user.  Removed.
    
    * idle_worker_rebind(), busy_worker_rebind_fn(), worker->rebind_work
      and rebind logic in manager_workers() removed.
    
    * worker_thread() now looks at WORKER_DIE instead of testing whether
      @worker->entry is empty to determine whether it needs to do
      something special as dying is the only special thing now.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Lai Jiangshan <laijs@cn.fujitsu.com>

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index f116f071d919..84ab6e1dc6fb 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -38,9 +38,6 @@ struct worker {
 	unsigned int		flags;		/* X: flags */
 	int			id;		/* I: worker id */
 
-	/* for rebinding worker to CPU */
-	struct work_struct	rebind_work;	/* L: for busy worker */
-
 	/* used only by rescuers to point to the target workqueue */
 	struct workqueue_struct	*rescue_wq;	/* I: the workqueue to rescue */
 };

commit d84ff0512f1bfc0d8c864efadb4523fce68919cc
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Mar 12 11:29:59 2013 -0700

    workqueue: consistently use int for @cpu variables
    
    Workqueue is mixing unsigned int and int for @cpu variables.  There's
    no point in using unsigned int for cpus - many of cpu related APIs
    take int anyway.  Consistently use int for @cpu variables so that we
    can use negative values to mark special ones.
    
    This patch doesn't introduce any visible behavior changes.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Lai Jiangshan <laijs@cn.fujitsu.com>

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index f9c887731e2b..f116f071d919 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -59,8 +59,7 @@ static inline struct worker *current_wq_worker(void)
  * Scheduler hooks for concurrency managed workqueue.  Only to be used from
  * sched.c and workqueue.c.
  */
-void wq_worker_waking_up(struct task_struct *task, unsigned int cpu);
-struct task_struct *wq_worker_sleeping(struct task_struct *task,
-				       unsigned int cpu);
+void wq_worker_waking_up(struct task_struct *task, int cpu);
+struct task_struct *wq_worker_sleeping(struct task_struct *task, int cpu);
 
 #endif /* _KERNEL_WORKQUEUE_INTERNAL_H */

commit b31041042a8cdece67f925e4bae55b5f5fd754ca
Author: Lai Jiangshan <laijs@cn.fujitsu.com>
Date:   Tue Feb 19 12:17:02 2013 -0800

    workqueue: better define synchronization rule around rescuer->pool updates
    
    Rescuers visit different worker_pools to process work items from pools
    under pressure.  Currently, rescuer->pool is updated outside any
    locking and when an outsider looks at a rescuer, there's no way to
    tell when and whether rescuer->pool is gonna change.  While this
    doesn't currently cause any problem, it is nasty.
    
    With recent worker_maybe_bind_and_lock() changes, we can move
    rescuer->pool updates inside pool locks such that if rescuer->pool
    equals a locked pool, it's guaranteed to stay that way until the pool
    is unlocked.
    
    Move rescuer->pool inside pool->lock.
    
    This patch doesn't introduce any visible behavior difference.
    
    tj: Updated the description.
    
    Signed-off-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index 07650264ec15..f9c887731e2b 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -32,6 +32,7 @@ struct worker {
 	struct list_head	scheduled;	/* L: scheduled works */
 	struct task_struct	*task;		/* I: worker task */
 	struct worker_pool	*pool;		/* I: the associated pool */
+						/* L: for rescuers */
 	/* 64 bytes boundary on 64bit, 32 on 32bit */
 	unsigned long		last_active;	/* L: last active timestamp */
 	unsigned int		flags;		/* X: flags */

commit 112202d9098aae2c36436e5178c0cf3ced423c7b
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Feb 13 19:29:12 2013 -0800

    workqueue: rename cpu_workqueue to pool_workqueue
    
    workqueue has moved away from global_cwqs to worker_pools and with the
    scheduled custom worker pools, wforkqueues will be associated with
    pools which don't have anything to do with CPUs.  The workqueue code
    went through significant amount of changes recently and mass renaming
    isn't likely to hurt much additionally.  Let's replace 'cpu' with
    'pool' so that it reflects the current design.
    
    * s/struct cpu_workqueue_struct/struct pool_workqueue/
    * s/cpu_wq/pool_wq/
    * s/cwq/pwq/
    
    This patch is purely cosmetic.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index 328be4a269aa..07650264ec15 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -28,7 +28,7 @@ struct worker {
 
 	struct work_struct	*current_work;	/* L: work being processed */
 	work_func_t		current_func;	/* L: current_work's fn */
-	struct cpu_workqueue_struct *current_cwq; /* L: current_work's cwq */
+	struct pool_workqueue	*current_pwq; /* L: current_work's pwq */
 	struct list_head	scheduled;	/* L: scheduled works */
 	struct task_struct	*task;		/* I: worker task */
 	struct worker_pool	*pool;		/* I: the associated pool */

commit a60dc39c016a65bfdbd05c43b3707962d5ed04c7
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jan 24 11:01:34 2013 -0800

    workqueue: remove global_cwq
    
    global_cwq is now nothing but a container for per-cpu standard
    worker_pools.  Declare the worker pools directly as
    cpu/unbound_std_worker_pools[] and remove global_cwq.
    
    * ____cacheline_aligned_in_smp moved from global_cwq to worker_pool.
      This probably would have made sense even before this change as we
      want each pool to be aligned.
    
    * get_gcwq() is replaced with std_worker_pools() which returns the
      pointer to the standard pool array for a given CPU.
    
    * __alloc_workqueue_key() updated to use get_std_worker_pool() instead
      of open-coding pool determination.
    
    This is part of an effort to remove global_cwq and make worker_pool
    the top level abstraction, which in turn will help implementing worker
    pools with user-specified attributes.
    
    v2: Joonsoo pointed out that it'd better to align struct worker_pool
        rather than the array so that every pool is aligned.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Cc: Joonsoo Kim <js1304@gmail.com>

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index cc35e7e62091..328be4a269aa 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -10,7 +10,6 @@
 #include <linux/workqueue.h>
 #include <linux/kthread.h>
 
-struct global_cwq;
 struct worker_pool;
 
 /*

commit 84b233adcca3cacd5cfa8013a5feda7a3db4a9af
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Jan 18 14:05:56 2013 -0800

    workqueue: implement current_is_async()
    
    This function queries whether %current is an async worker executing an
    async item.  This will be used to implement warning on synchronous
    request_module() from async workers.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index 02549fa04587..cc35e7e62091 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -8,6 +8,7 @@
 #define _KERNEL_WORKQUEUE_INTERNAL_H
 
 #include <linux/workqueue.h>
+#include <linux/kthread.h>
 
 struct global_cwq;
 struct worker_pool;
@@ -44,6 +45,16 @@ struct worker {
 	struct workqueue_struct	*rescue_wq;	/* I: the workqueue to rescue */
 };
 
+/**
+ * current_wq_worker - return struct worker if %current is a workqueue worker
+ */
+static inline struct worker *current_wq_worker(void)
+{
+	if (current->flags & PF_WQ_WORKER)
+		return kthread_data(current);
+	return NULL;
+}
+
 /*
  * Scheduler hooks for concurrency managed workqueue.  Only to be used from
  * sched.c and workqueue.c.

commit 2eaebdb33e1911c0cf3d44fd3596c42c6f502fab
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Jan 18 14:05:55 2013 -0800

    workqueue: move struct worker definition to workqueue_internal.h
    
    This will be used to implement an inline function to query whether
    %current is a workqueue worker and, if so, allow determining which
    work item it's executing.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
index b3ea6ad5566b..02549fa04587 100644
--- a/kernel/workqueue_internal.h
+++ b/kernel/workqueue_internal.h
@@ -7,6 +7,43 @@
 #ifndef _KERNEL_WORKQUEUE_INTERNAL_H
 #define _KERNEL_WORKQUEUE_INTERNAL_H
 
+#include <linux/workqueue.h>
+
+struct global_cwq;
+struct worker_pool;
+
+/*
+ * The poor guys doing the actual heavy lifting.  All on-duty workers are
+ * either serving the manager role, on idle list or on busy hash.  For
+ * details on the locking annotation (L, I, X...), refer to workqueue.c.
+ *
+ * Only to be used in workqueue and async.
+ */
+struct worker {
+	/* on idle list while idle, on busy hash table while busy */
+	union {
+		struct list_head	entry;	/* L: while idle */
+		struct hlist_node	hentry;	/* L: while busy */
+	};
+
+	struct work_struct	*current_work;	/* L: work being processed */
+	work_func_t		current_func;	/* L: current_work's fn */
+	struct cpu_workqueue_struct *current_cwq; /* L: current_work's cwq */
+	struct list_head	scheduled;	/* L: scheduled works */
+	struct task_struct	*task;		/* I: worker task */
+	struct worker_pool	*pool;		/* I: the associated pool */
+	/* 64 bytes boundary on 64bit, 32 on 32bit */
+	unsigned long		last_active;	/* L: last active timestamp */
+	unsigned int		flags;		/* X: flags */
+	int			id;		/* I: worker id */
+
+	/* for rebinding worker to CPU */
+	struct work_struct	rebind_work;	/* L: for busy worker */
+
+	/* used only by rescuers to point to the target workqueue */
+	struct workqueue_struct	*rescue_wq;	/* I: the workqueue to rescue */
+};
+
 /*
  * Scheduler hooks for concurrency managed workqueue.  Only to be used from
  * sched.c and workqueue.c.

commit ea138446e51f7bfe55cdeffa3f1dd9cafc786bd8
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Jan 18 14:05:55 2013 -0800

    workqueue: rename kernel/workqueue_sched.h to kernel/workqueue_internal.h
    
    Workqueue wants to expose more interface internal to kernel/.  Instead
    of adding a new header file, repurpose kernel/workqueue_sched.h.
    Rename it to workqueue_internal.h and add include protector.
    
    This patch doesn't introduce any functional changes.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>

diff --git a/kernel/workqueue_internal.h b/kernel/workqueue_internal.h
new file mode 100644
index 000000000000..b3ea6ad5566b
--- /dev/null
+++ b/kernel/workqueue_internal.h
@@ -0,0 +1,18 @@
+/*
+ * kernel/workqueue_internal.h
+ *
+ * Workqueue internal header file.  Only to be included by workqueue and
+ * core kernel subsystems.
+ */
+#ifndef _KERNEL_WORKQUEUE_INTERNAL_H
+#define _KERNEL_WORKQUEUE_INTERNAL_H
+
+/*
+ * Scheduler hooks for concurrency managed workqueue.  Only to be used from
+ * sched.c and workqueue.c.
+ */
+void wq_worker_waking_up(struct task_struct *task, unsigned int cpu);
+struct task_struct *wq_worker_sleeping(struct task_struct *task,
+				       unsigned int cpu);
+
+#endif /* _KERNEL_WORKQUEUE_INTERNAL_H */
