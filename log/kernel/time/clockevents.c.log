commit 1b72d43237980eab9b6ae6bb8181e51c840377e6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Mar 21 16:39:20 2019 +0100

    tick: Remove outgoing CPU from broadcast masks
    
    Valentin reported that unplugging a CPU occasionally results in a warning
    in the tick broadcast code which is triggered when an offline CPU is in the
    broadcast mask.
    
    This happens because the outgoing CPU is not removing itself from the
    broadcast masks, especially not from the broadcast_force_mask. The removal
    happens on the control CPU after the outgoing CPU is dead. It's a long
    standing issue, but the warning is harmless.
    
    Rework the hotplug mechanism so that the outgoing CPU removes itself from
    the broadcast masks after disabling interrupts and removing itself from the
    online mask.
    
    Reported-by: Valentin Schneider <valentin.schneider@arm.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Valentin Schneider <valentin.schneider@arm.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Link: https://lkml.kernel.org/r/alpine.DEB.2.21.1903211540180.1784@nanos.tec.linutronix.de

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 5e77662dd2d9..f5490222e134 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -611,6 +611,22 @@ void clockevents_resume(void)
 }
 
 #ifdef CONFIG_HOTPLUG_CPU
+
+# ifdef CONFIG_GENERIC_CLOCKEVENTS_BROADCAST
+/**
+ * tick_offline_cpu - Take CPU out of the broadcast mechanism
+ * @cpu:	The outgoing CPU
+ *
+ * Called on the outgoing CPU after it took itself offline.
+ */
+void tick_offline_cpu(unsigned int cpu)
+{
+	raw_spin_lock(&clockevents_lock);
+	tick_broadcast_offline(cpu);
+	raw_spin_unlock(&clockevents_lock);
+}
+# endif
+
 /**
  * tick_cleanup_dead_cpu - Cleanup the tick and clockevents of a dead cpu
  */
@@ -621,8 +637,6 @@ void tick_cleanup_dead_cpu(int cpu)
 
 	raw_spin_lock_irqsave(&clockevents_lock, flags);
 
-	tick_shutdown_broadcast_oneshot(cpu);
-	tick_shutdown_broadcast(cpu);
 	tick_shutdown(cpu);
 	/*
 	 * Unregister the clock event devices which were

commit f49c174b5f431db9fa17315269e288d4548b651c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Oct 31 19:21:10 2018 +0100

    hrtimers/tick/clockevents: Remove sloppy license references
    
    "For licencing details see kernel-base/COPYING" and similar license
    references have no value over the SPDX identifier. Remove them.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Kees Cook <keescook@chromium.org>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: John Stultz <john.stultz@linaro.org>
    Acked-by: Corey Minyard <cminyard@mvista.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Kate Stewart <kstewart@linuxfoundation.org>
    Cc: Philippe Ombredanne <pombredanne@nexb.com>
    Cc: Peter Anvin <hpa@zytor.com>
    Cc: Russell King <rmk+kernel@armlinux.org.uk>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    Cc: Nicolas Pitre <nicolas.pitre@linaro.org>
    Cc: David Riley <davidriley@chromium.org>
    Cc: Colin Cross <ccross@android.com>
    Cc: Mark Brown <broonie@kernel.org>
    Link: https://lkml.kernel.org/r/20181031182252.963632760@linutronix.de

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 0fdbdf17f8a2..5e77662dd2d9 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -5,9 +5,6 @@
  * Copyright(C) 2005-2006, Thomas Gleixner <tglx@linutronix.de>
  * Copyright(C) 2005-2007, Red Hat, Inc., Ingo Molnar
  * Copyright(C) 2006-2007, Timesys Corp., Thomas Gleixner
- *
- * This code is licenced under the GPL version 2. For details see
- * kernel-base/COPYING.
  */
 
 #include <linux/clockchips.h>

commit 35728b8209ee7d25b6241a56304ee926469bd154
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Oct 31 19:21:09 2018 +0100

    time: Add SPDX license identifiers
    
    Update the time(r) core files files with the correct SPDX license
    identifier based on the license text in the file itself. The SPDX
    identifier is a legally binding shorthand, which can be used instead of the
    full boiler plate text.
    
    This work is based on a script and data from Philippe Ombredanne, Kate
    Stewart and myself. The data has been created with two independent license
    scanners and manual inspection.
    
    The following files do not contain any direct license information and have
    been omitted from the big initial SPDX changes:
    
      timeconst.bc: The .bc files were not touched
      time.c, timer.c, timekeeping.c: Licence was deduced from EXPORT_SYMBOL_GPL
    
    As those files do not contain direct license references they fall under the
    project license, i.e. GPL V2 only.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Kees Cook <keescook@chromium.org>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: John Stultz <john.stultz@linaro.org>
    Acked-by: Corey Minyard <cminyard@mvista.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Kate Stewart <kstewart@linuxfoundation.org>
    Cc: Philippe Ombredanne <pombredanne@nexb.com>
    Cc: Russell King <rmk+kernel@armlinux.org.uk>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Nicolas Pitre <nicolas.pitre@linaro.org>
    Cc: David Riley <davidriley@chromium.org>
    Cc: Colin Cross <ccross@android.com>
    Cc: Mark Brown <broonie@kernel.org>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Link: https://lkml.kernel.org/r/20181031182252.879109557@linutronix.de

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 9b8c7c0fd113..0fdbdf17f8a2 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * This file contains functions which manage clock event devices.
  *

commit 58c5fc2b96e4ae65068d815a1c3ca81da92fa1c9
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Oct 31 19:21:08 2018 +0100

    time: Remove useless filenames in top level comments
    
    Remove the pointless filenames in the top level comments. They have no
    value at all and just occupy space. While at it tidy up some of the
    comments and remove a stale one.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Nicolas Pitre <nico@linaro.org>
    Acked-by: Kees Cook <keescook@chromium.org>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: John Stultz <john.stultz@linaro.org>
    Acked-by: Corey Minyard <cminyard@mvista.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Kate Stewart <kstewart@linuxfoundation.org>
    Cc: Philippe Ombredanne <pombredanne@nexb.com>
    Cc: Peter Anvin <hpa@zytor.com>
    Cc: Russell King <rmk+kernel@armlinux.org.uk>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    Cc: David Riley <davidriley@chromium.org>
    Cc: Colin Cross <ccross@android.com>
    Cc: Mark Brown <broonie@kernel.org>
    Link: https://lkml.kernel.org/r/20181031182252.794898238@linutronix.de

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index af58898d9ebf..9b8c7c0fd113 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -1,6 +1,4 @@
 /*
- * linux/kernel/time/clockevents.c
- *
  * This file contains functions which manage clock event devices.
  *
  * Copyright(C) 2005-2006, Thomas Gleixner <tglx@linutronix.de>

commit 7d9df98be66fec64349f9f1c9d3e896293fe7b45
Author: Yangtao Li <tiny.windzz@gmail.com>
Date:   Sat Nov 3 22:31:04 2018 -0400

    clockevents: Remove unnecessary unlikely()
    
    WARN_ON() and WARN_ON_ONCE() already contains an unlikely(), so it's not
    necessary to use unlikely.
    
    Signed-off-by: Yangtao Li <tiny.windzz@gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20181104023104.2572-1-tiny.windzz@gmail.com

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 8c0e4092f661..af58898d9ebf 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -39,10 +39,8 @@ static u64 cev_delta2ns(unsigned long latch, struct clock_event_device *evt,
 	u64 clc = (u64) latch << evt->shift;
 	u64 rnd;
 
-	if (unlikely(!evt->mult)) {
+	if (WARN_ON(!evt->mult))
 		evt->mult = 1;
-		WARN_ON(1);
-	}
 	rnd = (u64) evt->mult - 1;
 
 	/*
@@ -164,10 +162,8 @@ void clockevents_switch_state(struct clock_event_device *dev,
 		 * on it, so fix it up and emit a warning:
 		 */
 		if (clockevent_state_oneshot(dev)) {
-			if (unlikely(!dev->mult)) {
+			if (WARN_ON(!dev->mult))
 				dev->mult = 1;
-				WARN_ON(1);
-			}
 		}
 	}
 }
@@ -315,10 +311,8 @@ int clockevents_program_event(struct clock_event_device *dev, ktime_t expires,
 	int64_t delta;
 	int rc;
 
-	if (unlikely(expires < 0)) {
-		WARN_ON_ONCE(1);
+	if (WARN_ON_ONCE(expires < 0))
 		return -ETIME;
-	}
 
 	dev->next_event = expires;
 

commit fbfa9260085b5b578a049a90135e5c51928c5f7f
Author: Sudeep Holla <sudeep.holla@arm.com>
Date:   Wed Jul 11 12:24:24 2018 +0100

    clockevents: Warn if cpu_all_mask is used as cpumask
    
    Using cpu_all_mask in clockevents cpumask may result in issues while
    comparing multiple clockevent devices to choose the preferred one.
    
    On one of the platforms with 2 system (i.e. non per-CPU) timers with
    different ratings, having cpu_all_mask for one of the device resulted in a
    boot hang due to a endless loop in clockevents_notify_released() as both
    were clocksources were selected as preferred.
    
    In order to prevent such issues in the future, warn if any clockevent
    driver sets cpu_all_mask as it's cpumask and just override it to use
    cpu_possible_mask. All the existing occurrences of cpu_all_mask are already
    replaced with cpu_possible_mask.
    
    Signed-off-by: Sudeep Holla <sudeep.holla@arm.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-arm-kernel@lists.infradead.org
    Link: https://lkml.kernel.org/r/1531308264-24220-3-git-send-email-sudeep.holla@arm.com

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 16c027e9cc73..8c0e4092f661 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -463,6 +463,12 @@ void clockevents_register_device(struct clock_event_device *dev)
 		dev->cpumask = cpumask_of(smp_processor_id());
 	}
 
+	if (dev->cpumask == cpu_all_mask) {
+		WARN(1, "%s cpumask == cpu_all_mask, using cpu_possible_mask instead\n",
+		     dev->name);
+		dev->cpumask = cpu_possible_mask;
+	}
+
 	raw_spin_lock_irqsave(&clockevents_lock, flags);
 
 	list_add(&dev->list, &clockevent_devices);

commit 3a29ddb1c5986a6d3f941bfb1f434105203ce7f6
Author: James Hogan <jhogan@kernel.org>
Date:   Thu Oct 19 15:17:23 2017 +0100

    clockevents: Retry programming min delta up to 10 times
    
    When CONFIG_GENERIC_CLOCKEVENTS_MIN_ADJUST=n, the call path
    hrtimer_reprogram -> clockevents_program_event ->
    clockevents_program_min_delta will not retry if the clock event driver
    returns -ETIME.
    
    If the driver could not satisfy the program_min_delta for any reason, the
    lack of a retry means the CPU may not receive a tick interrupt, potentially
    until the counter does a full period. This leads to rcu_sched timeout
    messages as the stalled CPU is detected by other CPUs, and other issues if
    the CPU is holding locks or other resources at the point at which it
    stalls.
    
    There have been a couple of observed mechanisms through which a clock event
    driver could not satisfy the requested min_delta and return -ETIME.
    
    With the MIPS GIC driver, the shared execution resource within MT cores
    means inconventient latency due to execution of instructions from other
    hardware threads in the core, within gic_next_event, can result in an event
    being set in the past.
    
    Additionally under virtualisation it is possible to get unexpected latency
    during a clockevent device's set_next_event() callback which can make it
    return -ETIME even for a delta based on min_delta_ns.
    
    It isn't appropriate to use MIN_ADJUST in the virtualisation case as
    occasional hypervisor induced high latency will cause min_delta_ns to
    quickly increase to the maximum.
    
    Instead, borrow the retry pattern from the MIN_ADJUST case, but without
    making adjustments. Retry up to 10 times, each time increasing the
    attempted delta by min_delta, before giving up.
    
    [ Matt: Reworked the loop and made retry increase the delta. ]
    
    Signed-off-by: James Hogan <jhogan@kernel.org>
    Signed-off-by: Matt Redfearn <matt.redfearn@mips.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-mips@linux-mips.org
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: "Martin Schwidefsky" <schwidefsky@de.ibm.com>
    Cc: James Hogan <james.hogan@mips.com>
    Link: https://lkml.kernel.org/r/1508422643-6075-1-git-send-email-matt.redfearn@mips.com

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 4237e0744e26..16c027e9cc73 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -280,17 +280,22 @@ static int clockevents_program_min_delta(struct clock_event_device *dev)
 static int clockevents_program_min_delta(struct clock_event_device *dev)
 {
 	unsigned long long clc;
-	int64_t delta;
+	int64_t delta = 0;
+	int i;
 
-	delta = dev->min_delta_ns;
-	dev->next_event = ktime_add_ns(ktime_get(), delta);
+	for (i = 0; i < 10; i++) {
+		delta += dev->min_delta_ns;
+		dev->next_event = ktime_add_ns(ktime_get(), delta);
 
-	if (clockevent_state_shutdown(dev))
-		return 0;
+		if (clockevent_state_shutdown(dev))
+			return 0;
 
-	dev->retries++;
-	clc = ((unsigned long long) delta * dev->mult) >> dev->shift;
-	return dev->set_next_event((unsigned long) clc, dev);
+		dev->retries++;
+		clc = ((unsigned long long) delta * dev->mult) >> dev->shift;
+		if (dev->set_next_event((unsigned long) clc, dev) == 0)
+			return 0;
+	}
+	return -ETIME;
 }
 
 #endif /* CONFIG_GENERIC_CLOCKEVENTS_MIN_ADJUST */

commit 0695bd99c0d22bef4d9d4c72cf537b722ba98531
Author: Nicolai Stange <nicstange@gmail.com>
Date:   Mon Feb 6 22:12:04 2017 +0100

    clockevents: Make clockevents_config() static
    
    A clockevent device's rate should be configured before or at registration
    and changed afterwards through clockevents_update_freq() only.
    
    For the configuration at registration, we already have
    clockevents_config_and_register().
    
    Right now, there are no clockevents_config() users outside of the
    clockevents core.
    
    To mitigiate the risk of drivers errorneously reconfiguring their rates
    through clockevents_config() *after* device registration, make
    clockevents_config() static.
    
    Signed-off-by: Nicolai Stange <nicstange@gmail.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 97ac0951f164..4237e0744e26 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -468,7 +468,7 @@ void clockevents_register_device(struct clock_event_device *dev)
 }
 EXPORT_SYMBOL_GPL(clockevents_register_device);
 
-void clockevents_config(struct clock_event_device *dev, u32 freq)
+static void clockevents_config(struct clock_event_device *dev, u32 freq)
 {
 	u64 sec;
 

commit 2456e855354415bfaeb7badaa14e11b3e02c8466
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Dec 25 11:38:40 2016 +0100

    ktime: Get rid of the union
    
    ktime is a union because the initial implementation stored the time in
    scalar nanoseconds on 64 bit machine and in a endianess optimized timespec
    variant for 32bit machines. The Y2038 cleanup removed the timespec variant
    and switched everything to scalar nanoseconds. The union remained, but
    become completely pointless.
    
    Get rid of the union and just keep ktime_t as simple typedef of type s64.
    
    The conversion was done with coccinelle and some manual mopping up.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 2c5bc77c0bb0..97ac0951f164 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -179,7 +179,7 @@ void clockevents_switch_state(struct clock_event_device *dev,
 void clockevents_shutdown(struct clock_event_device *dev)
 {
 	clockevents_switch_state(dev, CLOCK_EVT_STATE_SHUTDOWN);
-	dev->next_event.tv64 = KTIME_MAX;
+	dev->next_event = KTIME_MAX;
 }
 
 /**
@@ -213,7 +213,7 @@ static int clockevents_increase_min_delta(struct clock_event_device *dev)
 	if (dev->min_delta_ns >= MIN_DELTA_LIMIT) {
 		printk_deferred(KERN_WARNING
 				"CE: Reprogramming failure. Giving up\n");
-		dev->next_event.tv64 = KTIME_MAX;
+		dev->next_event = KTIME_MAX;
 		return -ETIME;
 	}
 
@@ -310,7 +310,7 @@ int clockevents_program_event(struct clock_event_device *dev, ktime_t expires,
 	int64_t delta;
 	int rc;
 
-	if (unlikely(expires.tv64 < 0)) {
+	if (unlikely(expires < 0)) {
 		WARN_ON_ONCE(1);
 		return -ETIME;
 	}

commit 775be506266a860f141f6b848c92c316c602a94f
Author: Ben Dooks <ben.dooks@codethink.co.uk>
Date:   Fri Jun 17 16:56:14 2016 +0100

    clockevents: Make clockevents_subsys static
    
    The clockevents_subsys struct is used for sysfs support and
    is not declared or used outside the file it is defined in.
    Fix the following warning by making it static:
    
    kernel/time/clockevents.c:648:17: warning: symbol 'clockevents_subsys' was not declared. Should it be static?
    
    Signed-off-by: Ben Dooks <ben.dooks@codethink.co.uk>
    Cc: linux-kernel@lists.codethink.co.uk
    Link: http://lkml.kernel.org/r/1466178974-7105-1-git-send-email-ben.dooks@codethink.co.uk
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index a9b76a40319e..2c5bc77c0bb0 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -645,7 +645,7 @@ void tick_cleanup_dead_cpu(int cpu)
 #endif
 
 #ifdef CONFIG_SYSFS
-struct bus_type clockevents_subsys = {
+static struct bus_type clockevents_subsys = {
 	.name		= "clockevents",
 	.dev_name       = "clockevent",
 };

commit eef7635a22f6b144206b5ca2f1398f637acffc4d
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Fri Sep 11 09:34:26 2015 +0530

    clockevents: Remove unused set_mode() callback
    
    All users are migrated to the per-state callbacks, get rid of the
    unused interface and the core support code.
    
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: linaro-kernel@lists.linaro.org
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/fd60de14cf6d125489c031207567bb255ad946f6.1441943991.git.viresh.kumar@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 50eb107f1198..a9b76a40319e 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -97,20 +97,6 @@ EXPORT_SYMBOL_GPL(clockevent_delta2ns);
 static int __clockevents_switch_state(struct clock_event_device *dev,
 				      enum clock_event_state state)
 {
-	/* Transition with legacy set_mode() callback */
-	if (dev->set_mode) {
-		/* Legacy callback doesn't support new modes */
-		if (state > CLOCK_EVT_STATE_ONESHOT)
-			return -ENOSYS;
-		/*
-		 * 'clock_event_state' and 'clock_event_mode' have 1-to-1
-		 * mapping until *_ONESHOT, and so a simple cast will work.
-		 */
-		dev->set_mode((enum clock_event_mode)state, dev);
-		dev->mode = (enum clock_event_mode)state;
-		return 0;
-	}
-
 	if (dev->features & CLOCK_EVT_FEAT_DUMMY)
 		return 0;
 
@@ -204,12 +190,8 @@ int clockevents_tick_resume(struct clock_event_device *dev)
 {
 	int ret = 0;
 
-	if (dev->set_mode) {
-		dev->set_mode(CLOCK_EVT_MODE_RESUME, dev);
-		dev->mode = CLOCK_EVT_MODE_RESUME;
-	} else if (dev->tick_resume) {
+	if (dev->tick_resume)
 		ret = dev->tick_resume(dev);
-	}
 
 	return ret;
 }
@@ -460,26 +442,6 @@ int clockevents_unbind_device(struct clock_event_device *ced, int cpu)
 }
 EXPORT_SYMBOL_GPL(clockevents_unbind_device);
 
-/* Sanity check of state transition callbacks */
-static int clockevents_sanity_check(struct clock_event_device *dev)
-{
-	/* Legacy set_mode() callback */
-	if (dev->set_mode) {
-		/* We shouldn't be supporting new modes now */
-		WARN_ON(dev->set_state_periodic || dev->set_state_oneshot ||
-			dev->set_state_shutdown || dev->tick_resume ||
-			dev->set_state_oneshot_stopped);
-
-		BUG_ON(dev->mode != CLOCK_EVT_MODE_UNUSED);
-		return 0;
-	}
-
-	if (dev->features & CLOCK_EVT_FEAT_DUMMY)
-		return 0;
-
-	return 0;
-}
-
 /**
  * clockevents_register_device - register a clock event device
  * @dev:	device to register
@@ -488,8 +450,6 @@ void clockevents_register_device(struct clock_event_device *dev)
 {
 	unsigned long flags;
 
-	BUG_ON(clockevents_sanity_check(dev));
-
 	/* Initialize state to DETACHED */
 	clockevent_set_state(dev, CLOCK_EVT_STATE_DETACHED);
 

commit 7c4a976cd55972b68c75a978f171b6db5df4ce66
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Tue Jul 7 10:14:35 2015 +0200

    clockevents: Allow set-state callbacks to be optional
    
    Its mandatory for the drivers to provide set_state_{oneshot|periodic}()
    (only if related modes are supported) and set_state_shutdown() callbacks
    today, if they are implementing the new set-state interface.
    
    But this leads to unnecessary noop callbacks for drivers which don't
    want to implement them. Over that, it will lead to a full function call
    for nothing really useful.
    
    Lets make all set-state callbacks optional.
    
    Suggested-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Link: http://lkml.kernel.org/r/1436256875-15562-1-git-send-email-daniel.lezcano@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 08ccc3da3ca0..50eb107f1198 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -120,19 +120,25 @@ static int __clockevents_switch_state(struct clock_event_device *dev,
 		/* The clockevent device is getting replaced. Shut it down. */
 
 	case CLOCK_EVT_STATE_SHUTDOWN:
-		return dev->set_state_shutdown(dev);
+		if (dev->set_state_shutdown)
+			return dev->set_state_shutdown(dev);
+		return 0;
 
 	case CLOCK_EVT_STATE_PERIODIC:
 		/* Core internal bug */
 		if (!(dev->features & CLOCK_EVT_FEAT_PERIODIC))
 			return -ENOSYS;
-		return dev->set_state_periodic(dev);
+		if (dev->set_state_periodic)
+			return dev->set_state_periodic(dev);
+		return 0;
 
 	case CLOCK_EVT_STATE_ONESHOT:
 		/* Core internal bug */
 		if (!(dev->features & CLOCK_EVT_FEAT_ONESHOT))
 			return -ENOSYS;
-		return dev->set_state_oneshot(dev);
+		if (dev->set_state_oneshot)
+			return dev->set_state_oneshot(dev);
+		return 0;
 
 	case CLOCK_EVT_STATE_ONESHOT_STOPPED:
 		/* Core internal bug */
@@ -471,18 +477,6 @@ static int clockevents_sanity_check(struct clock_event_device *dev)
 	if (dev->features & CLOCK_EVT_FEAT_DUMMY)
 		return 0;
 
-	/* New state-specific callbacks */
-	if (!dev->set_state_shutdown)
-		return -EINVAL;
-
-	if ((dev->features & CLOCK_EVT_FEAT_PERIODIC) &&
-	    !dev->set_state_periodic)
-		return -EINVAL;
-
-	if ((dev->features & CLOCK_EVT_FEAT_ONESHOT) &&
-	    !dev->set_state_oneshot)
-		return -EINVAL;
-
 	return 0;
 }
 

commit a9d20988ac7db47fec4510cefc966e876a4ce674
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Wed Jun 17 16:04:46 2015 +0530

    clockevents: Check state instead of mode in suspend/resume path
    
    CLOCK_EVT_MODE_* macros are present for backward compatibility (as most
    of the drivers are still using old ->set_mode() interface).
    
    These macro's shouldn't be used anymore in code, that is common to both
    driver interfaces, i.e. ->set_mode() and ->set_state_*().
    
    Drivers implementing ->set_state_*() interface, which have their
    clkevt->mode set to 0 (clkevt device structures are normally globally
    defined), will not participate in suspend/resume as they will always be
    marked as UNUSED.
    
    Fix this by checking state of the clockevent device instead of mode,
    which is updated for both the interfaces.
    
    Fixes: ac34ad27fc16 ("clockevents: Do not suspend/resume if unused")
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Cc: linaro-kernel@lists.linaro.org
    Cc: alexandre.belloni@free-electrons.com
    Cc: sylvain.rochet@finsecur.com
    Link: http://lkml.kernel.org/r/a1964eef6e8a47d02b1ff9083c6c91f73f0ff643.1434537215.git.viresh.kumar@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 2397b97320d8..08ccc3da3ca0 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -639,7 +639,7 @@ void clockevents_suspend(void)
 	struct clock_event_device *dev;
 
 	list_for_each_entry_reverse(dev, &clockevent_devices, list)
-		if (dev->suspend && dev->mode != CLOCK_EVT_MODE_UNUSED)
+		if (dev->suspend && !clockevent_state_detached(dev))
 			dev->suspend(dev);
 }
 
@@ -651,7 +651,7 @@ void clockevents_resume(void)
 	struct clock_event_device *dev;
 
 	list_for_each_entry(dev, &clockevent_devices, list)
-		if (dev->resume && dev->mode != CLOCK_EVT_MODE_UNUSED)
+		if (dev->resume && !clockevent_state_detached(dev))
 			dev->resume(dev);
 }
 

commit 051ebd101b05c09d9b5b673e19fb0586e9bfec56
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 2 14:13:46 2015 +0200

    clockevents: Use set/get state helper functions
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Viresh Kumar <viresh.kumar@linaro.org>
    Cc: Peter Zijlstra <peterz@infradead.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index a45f90c4b2d5..2397b97320d8 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -137,7 +137,8 @@ static int __clockevents_switch_state(struct clock_event_device *dev,
 	case CLOCK_EVT_STATE_ONESHOT_STOPPED:
 		/* Core internal bug */
 		if (WARN_ONCE(!clockevent_state_oneshot(dev),
-			      "Current state: %d\n", dev->state))
+			      "Current state: %d\n",
+			      clockevent_get_state(dev)))
 			return -EINVAL;
 
 		if (dev->set_state_oneshot_stopped)
@@ -160,11 +161,11 @@ static int __clockevents_switch_state(struct clock_event_device *dev,
 void clockevents_switch_state(struct clock_event_device *dev,
 			      enum clock_event_state state)
 {
-	if (dev->state != state) {
+	if (clockevent_get_state(dev) != state) {
 		if (__clockevents_switch_state(dev, state))
 			return;
 
-		dev->state = state;
+		clockevent_set_state(dev, state);
 
 		/*
 		 * A nsec2cyc multiplicator of 0 is invalid and we'd crash
@@ -333,7 +334,7 @@ int clockevents_program_event(struct clock_event_device *dev, ktime_t expires,
 
 	/* We must be in ONESHOT state here */
 	WARN_ONCE(!clockevent_state_oneshot(dev), "Current state: %d\n",
-		  dev->state);
+		  clockevent_get_state(dev));
 
 	/* Shortcut for clockevent devices that can deal with ktime. */
 	if (dev->features & CLOCK_EVT_FEAT_KTIME)
@@ -496,7 +497,7 @@ void clockevents_register_device(struct clock_event_device *dev)
 	BUG_ON(clockevents_sanity_check(dev));
 
 	/* Initialize state to DETACHED */
-	dev->state = CLOCK_EVT_STATE_DETACHED;
+	clockevent_set_state(dev, CLOCK_EVT_STATE_DETACHED);
 
 	if (!dev->cpumask) {
 		WARN_ON(num_possible_cpus() > 1);

commit d7eb231c71420bc34ac3d35403115600f920cfc2
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 2 14:08:46 2015 +0200

    clockevents: Provide functions to set and get the state
    
    We want to rename dev->state, so provide proper get and set
    functions. Rename clockevents_set_state() to
    clockevents_switch_state() to avoid confusion.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Viresh Kumar <viresh.kumar@linaro.org>
    Cc: Peter Zijlstra <peterz@infradead.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index e568ec8c320b..a45f90c4b2d5 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -94,8 +94,8 @@ u64 clockevent_delta2ns(unsigned long latch, struct clock_event_device *evt)
 }
 EXPORT_SYMBOL_GPL(clockevent_delta2ns);
 
-static int __clockevents_set_state(struct clock_event_device *dev,
-				   enum clock_event_state state)
+static int __clockevents_switch_state(struct clock_event_device *dev,
+				      enum clock_event_state state)
 {
 	/* Transition with legacy set_mode() callback */
 	if (dev->set_mode) {
@@ -151,17 +151,17 @@ static int __clockevents_set_state(struct clock_event_device *dev,
 }
 
 /**
- * clockevents_set_state - set the operating state of a clock event device
+ * clockevents_switch_state - set the operating state of a clock event device
  * @dev:	device to modify
  * @state:	new state
  *
  * Must be called with interrupts disabled !
  */
-void clockevents_set_state(struct clock_event_device *dev,
-			   enum clock_event_state state)
+void clockevents_switch_state(struct clock_event_device *dev,
+			      enum clock_event_state state)
 {
 	if (dev->state != state) {
-		if (__clockevents_set_state(dev, state))
+		if (__clockevents_switch_state(dev, state))
 			return;
 
 		dev->state = state;
@@ -185,7 +185,7 @@ void clockevents_set_state(struct clock_event_device *dev,
  */
 void clockevents_shutdown(struct clock_event_device *dev)
 {
-	clockevents_set_state(dev, CLOCK_EVT_STATE_SHUTDOWN);
+	clockevents_switch_state(dev, CLOCK_EVT_STATE_SHUTDOWN);
 	dev->next_event.tv64 = KTIME_MAX;
 }
 
@@ -565,7 +565,7 @@ int __clockevents_update_freq(struct clock_event_device *dev, u32 freq)
 		return clockevents_program_event(dev, dev->next_event, false);
 
 	if (clockevent_state_periodic(dev))
-		return __clockevents_set_state(dev, CLOCK_EVT_STATE_PERIODIC);
+		return __clockevents_switch_state(dev, CLOCK_EVT_STATE_PERIODIC);
 
 	return 0;
 }
@@ -619,7 +619,7 @@ void clockevents_exchange_device(struct clock_event_device *old,
 	 */
 	if (old) {
 		module_put(old->owner);
-		clockevents_set_state(old, CLOCK_EVT_STATE_DETACHED);
+		clockevents_switch_state(old, CLOCK_EVT_STATE_DETACHED);
 		list_del(&old->list);
 		list_add(&old->list, &clockevents_released);
 	}

commit 472c4a9437d3c6a0b1e59df7c5aa14075946aa70
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Thu May 21 13:33:46 2015 +0530

    clockevents: Use helpers to check the state of a clockevent device
    
    Use accessor functions to check the state of clockevent devices in
    core code.
    
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Cc: linaro-kernel@lists.linaro.org
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/fa2b9869fd17f210eaa156ec2b594efd0230b6c7.1432192527.git.viresh.kumar@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 2a5c369e50ab..e568ec8c320b 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -136,7 +136,7 @@ static int __clockevents_set_state(struct clock_event_device *dev,
 
 	case CLOCK_EVT_STATE_ONESHOT_STOPPED:
 		/* Core internal bug */
-		if (WARN_ONCE(dev->state != CLOCK_EVT_STATE_ONESHOT,
+		if (WARN_ONCE(!clockevent_state_oneshot(dev),
 			      "Current state: %d\n", dev->state))
 			return -EINVAL;
 
@@ -170,7 +170,7 @@ void clockevents_set_state(struct clock_event_device *dev,
 		 * A nsec2cyc multiplicator of 0 is invalid and we'd crash
 		 * on it, so fix it up and emit a warning:
 		 */
-		if (state == CLOCK_EVT_STATE_ONESHOT) {
+		if (clockevent_state_oneshot(dev)) {
 			if (unlikely(!dev->mult)) {
 				dev->mult = 1;
 				WARN_ON(1);
@@ -259,7 +259,7 @@ static int clockevents_program_min_delta(struct clock_event_device *dev)
 		delta = dev->min_delta_ns;
 		dev->next_event = ktime_add_ns(ktime_get(), delta);
 
-		if (dev->state == CLOCK_EVT_STATE_SHUTDOWN)
+		if (clockevent_state_shutdown(dev))
 			return 0;
 
 		dev->retries++;
@@ -296,7 +296,7 @@ static int clockevents_program_min_delta(struct clock_event_device *dev)
 	delta = dev->min_delta_ns;
 	dev->next_event = ktime_add_ns(ktime_get(), delta);
 
-	if (dev->state == CLOCK_EVT_STATE_SHUTDOWN)
+	if (clockevent_state_shutdown(dev))
 		return 0;
 
 	dev->retries++;
@@ -328,11 +328,11 @@ int clockevents_program_event(struct clock_event_device *dev, ktime_t expires,
 
 	dev->next_event = expires;
 
-	if (dev->state == CLOCK_EVT_STATE_SHUTDOWN)
+	if (clockevent_state_shutdown(dev))
 		return 0;
 
 	/* We must be in ONESHOT state here */
-	WARN_ONCE(dev->state != CLOCK_EVT_STATE_ONESHOT, "Current state: %d\n",
+	WARN_ONCE(!clockevent_state_oneshot(dev), "Current state: %d\n",
 		  dev->state);
 
 	/* Shortcut for clockevent devices that can deal with ktime. */
@@ -377,7 +377,7 @@ static int clockevents_replace(struct clock_event_device *ced)
 	struct clock_event_device *dev, *newdev = NULL;
 
 	list_for_each_entry(dev, &clockevent_devices, list) {
-		if (dev == ced || dev->state != CLOCK_EVT_STATE_DETACHED)
+		if (dev == ced || !clockevent_state_detached(dev))
 			continue;
 
 		if (!tick_check_replacement(newdev, dev))
@@ -403,7 +403,7 @@ static int clockevents_replace(struct clock_event_device *ced)
 static int __clockevents_try_unbind(struct clock_event_device *ced, int cpu)
 {
 	/* Fast track. Device is unused */
-	if (ced->state == CLOCK_EVT_STATE_DETACHED) {
+	if (clockevent_state_detached(ced)) {
 		list_del_init(&ced->list);
 		return 0;
 	}
@@ -561,10 +561,10 @@ int __clockevents_update_freq(struct clock_event_device *dev, u32 freq)
 {
 	clockevents_config(dev, freq);
 
-	if (dev->state == CLOCK_EVT_STATE_ONESHOT)
+	if (clockevent_state_oneshot(dev))
 		return clockevents_program_event(dev, dev->next_event, false);
 
-	if (dev->state == CLOCK_EVT_STATE_PERIODIC)
+	if (clockevent_state_periodic(dev))
 		return __clockevents_set_state(dev, CLOCK_EVT_STATE_PERIODIC);
 
 	return 0;
@@ -625,7 +625,7 @@ void clockevents_exchange_device(struct clock_event_device *old,
 	}
 
 	if (new) {
-		BUG_ON(new->state != CLOCK_EVT_STATE_DETACHED);
+		BUG_ON(!clockevent_state_detached(new));
 		clockevents_shutdown(new);
 	}
 }
@@ -681,7 +681,7 @@ void tick_cleanup_dead_cpu(int cpu)
 		if (cpumask_test_cpu(cpu, dev->cpumask) &&
 		    cpumask_weight(dev->cpumask) == 1 &&
 		    !tick_is_broadcast_device(dev)) {
-			BUG_ON(dev->state != CLOCK_EVT_STATE_DETACHED);
+			BUG_ON(!clockevent_state_detached(dev));
 			list_del(&dev->list);
 		}
 	}

commit ac34ad27fc160b5bd31c731cdaaf6e1d1890ccb2
Author: Alexandre Belloni <alexandre.belloni@free-electrons.com>
Date:   Fri Jan 16 10:05:51 2015 +0100

    clockevents: Do not suspend/resume if unused
    
    There is no point in calling suspend/resume for unused clockevents as
    they are already stopped and disabled.
    
    This is really important for AT91 as the hardware is a trainwreck and
    takes ages to synchronize.
    
    Reported-by: Sylvain Rochet <sylvain.rochet@finsecur.com>
    Signed-off-by: Alexandre Belloni <alexandre.belloni@free-electrons.com>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Nicolas Ferre <nicolas.ferre@atmel.com>
    Cc: Boris Brezillon <boris.brezillon@free-electrons.com>
    Cc: Maxime Ripard <maxime.ripard@free-electrons.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Link: http://lkml.kernel.org/r/1421399151-26800-1-git-send-email-alexandre.belloni@free-electrons.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 4922f1b805ea..2a5c369e50ab 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -638,7 +638,7 @@ void clockevents_suspend(void)
 	struct clock_event_device *dev;
 
 	list_for_each_entry_reverse(dev, &clockevent_devices, list)
-		if (dev->suspend)
+		if (dev->suspend && dev->mode != CLOCK_EVT_MODE_UNUSED)
 			dev->suspend(dev);
 }
 
@@ -650,7 +650,7 @@ void clockevents_resume(void)
 	struct clock_event_device *dev;
 
 	list_for_each_entry(dev, &clockevent_devices, list)
-		if (dev->resume)
+		if (dev->resume && dev->mode != CLOCK_EVT_MODE_UNUSED)
 			dev->resume(dev);
 }
 

commit d25408756accbd2171abaa0678f986adae139e6f
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Fri Apr 3 09:04:05 2015 +0530

    clockevents: Stop unused clockevent devices
    
    To avoid getting spurious interrupts on a tickless CPU, clockevent
    device can now be stopped by switching to ONESHOT_STOPPED state.
    
    The natural place for handling this transition is tick_program_event().
    
    On 'expires == KTIME_MAX', we skip programming the event and so we need
    to fix such call sites as well, to always call tick_program_event()
    irrespective of the expires value.
    
    Once the clockevent device is required again, check if it was earlier
    put into ONESHOT_STOPPED state. If yes, switch its state to ONESHOT
    before programming its event.
    
    To make sure we haven't missed any corner case, add a WARN() for the
    case where we try to reprogram clockevent device while we aren't
    configured in ONESHOT_STOPPED state.
    
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Cc: linaro-kernel@lists.linaro.org
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Kevin Hilman <khilman@linaro.org>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/5146b07be7f0bc497e0ebae036590ec2fa73e540.1428031396.git.viresh.kumar@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index dc6afb485027..4922f1b805ea 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -331,6 +331,10 @@ int clockevents_program_event(struct clock_event_device *dev, ktime_t expires,
 	if (dev->state == CLOCK_EVT_STATE_SHUTDOWN)
 		return 0;
 
+	/* We must be in ONESHOT state here */
+	WARN_ONCE(dev->state != CLOCK_EVT_STATE_ONESHOT, "Current state: %d\n",
+		  dev->state);
+
 	/* Shortcut for clockevent devices that can deal with ktime. */
 	if (dev->features & CLOCK_EVT_FEAT_KTIME)
 		return dev->set_next_ktime(expires, dev);

commit 8fff52fd50934580c5108afed12043a774edf728
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Fri Apr 3 09:04:04 2015 +0530

    clockevents: Introduce CLOCK_EVT_STATE_ONESHOT_STOPPED state
    
    When no timers/hrtimers are pending, the expiry time is set to a
    special value: 'KTIME_MAX'. This normally happens with
    NO_HZ_{IDLE|FULL} in both LOWRES/HIGHRES modes.
    
    When 'expiry == KTIME_MAX', we either cancel the 'tick-sched' hrtimer
    (NOHZ_MODE_HIGHRES) or skip reprogramming clockevent device
    (NOHZ_MODE_LOWRES).  But, the clockevent device is already
    reprogrammed from the tick-handler for next tick.
    
    As the clock event device is programmed in ONESHOT mode it will at
    least fire one more time (unnecessarily). Timers on few
    implementations (like arm_arch_timer, etc.) only support PERIODIC mode
    and their drivers emulate ONESHOT over that. Which means that on these
    platforms we will get spurious interrupts periodically (at last
    programmed interval rate, normally tick rate).
    
    In order to avoid spurious interrupts, the clockevent device should be
    stopped or its interrupts should be masked.
    
    A simple (yet hacky) solution to get this fixed could be: update
    hrtimer_force_reprogram() to always reprogram clockevent device and
    update clockevent drivers to STOP generating events (or delay it to
    max time) when 'expires' is set to KTIME_MAX. But the drawback here is
    that every clockevent driver has to be hacked for this particular case
    and its very easy for new ones to miss this.
    
    However, Thomas suggested to add an optional state ONESHOT_STOPPED to
    solve this problem: lkml.org/lkml/2014/5/9/508.
    
    This patch adds support for ONESHOT_STOPPED state in clockevents
    core. It will only be available to drivers that implement the
    state-specific callbacks instead of the legacy ->set_mode() callback.
    
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Reviewed-by: Preeti U. Murthy <preeti@linux.vnet.ibm.com>
    Cc: linaro-kernel@lists.linaro.org
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Kevin Hilman <khilman@linaro.org>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/b8b383a03ac07b13312c16850b5106b82e4245b5.1428031396.git.viresh.kumar@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 637a09461c1d..dc6afb485027 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -134,6 +134,17 @@ static int __clockevents_set_state(struct clock_event_device *dev,
 			return -ENOSYS;
 		return dev->set_state_oneshot(dev);
 
+	case CLOCK_EVT_STATE_ONESHOT_STOPPED:
+		/* Core internal bug */
+		if (WARN_ONCE(dev->state != CLOCK_EVT_STATE_ONESHOT,
+			      "Current state: %d\n", dev->state))
+			return -EINVAL;
+
+		if (dev->set_state_oneshot_stopped)
+			return dev->set_state_oneshot_stopped(dev);
+		else
+			return -ENOSYS;
+
 	default:
 		return -ENOSYS;
 	}
@@ -445,7 +456,8 @@ static int clockevents_sanity_check(struct clock_event_device *dev)
 	if (dev->set_mode) {
 		/* We shouldn't be supporting new modes now */
 		WARN_ON(dev->set_state_periodic || dev->set_state_oneshot ||
-			dev->set_state_shutdown || dev->tick_resume);
+			dev->set_state_shutdown || dev->tick_resume ||
+			dev->set_state_oneshot_stopped);
 
 		BUG_ON(dev->mode != CLOCK_EVT_MODE_UNUSED);
 		return 0;

commit 95f3b1f4b1df4716ce2db8aa2243b7e288eeb9a7
Merge: 1a9f064f516c 149aabcc44e3
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat May 9 14:57:49 2015 -0700

    Merge branch 'timers-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull timer fix from Thomas Gleixner:
     "A simple fix to actually shut down a detached device instead of
      keeping it active"
    
    * 'timers-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      clockevents: Shutdown detached clockevent device

commit 149aabcc44e3e2c1f8fe4f0832be53d2db55b598
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Fri Apr 10 12:56:41 2015 +0530

    clockevents: Shutdown detached clockevent device
    
    A clockevent device is marked DETACHED when it is replaced by another
    clockevent device.
    
    The device is shutdown properly for drivers that implement legacy
    ->set_mode() callback, as we call ->set_mode() for CLOCK_EVT_MODE_UNUSED
    as well.
    
    But for the new per-state callback interface, we skip shutting down the
    device, as we thought its an internal state change. That wasn't correct.
    
    The effect is that the device is left programmed in oneshot or periodic
    mode.
    
    Fall-back to 'case CLOCK_EVT_STATE_SHUTDOWN', to shutdown the device.
    
    Fixes: bd624d75db21 "clockevents: Introduce mode specific callbacks"
    Reported-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Cc: linaro-kernel@lists.linaro.org
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/eef0a91c51b74d4e52c8e5a95eca27b5a0563f07.1428650683.git.viresh.kumar@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 25d942d1da27..629be4e21e96 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -117,11 +117,7 @@ static int __clockevents_set_state(struct clock_event_device *dev,
 	/* Transition with new state-specific callbacks */
 	switch (state) {
 	case CLOCK_EVT_STATE_DETACHED:
-		/*
-		 * This is an internal state, which is guaranteed to go from
-		 * SHUTDOWN to DETACHED. No driver interaction required.
-		 */
-		return 0;
+		/* The clockevent device is getting replaced. Shut it down. */
 
 	case CLOCK_EVT_STATE_SHUTDOWN:
 		return dev->set_state_shutdown(dev);

commit 1fc149933fd49a5b0e7738dc0853dbfbac4ae0e1
Merge: 41d5e08ea86a ea5505fabd3b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Apr 21 09:42:58 2015 -0700

    Merge tag 'char-misc-4.1-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/char-misc
    
    Pull char/misc driver updates from Greg KH:
     "Here's the big char/misc driver patchset for 4.1-rc1.
    
      Lots of different driver subsystem updates here, nothing major, full
      details are in the shortlog.
    
      All of this has been in linux-next for a while"
    
    * tag 'char-misc-4.1-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/char-misc: (133 commits)
      mei: trace: remove unused TRACE_SYSTEM_STRING
      DTS: ARM: OMAP3-N900: Add lis3lv02d support
      Documentation: DT: lis302: update wakeup binding
      lis3lv02d: DT: add wakeup unit 2 and wakeup threshold
      lis3lv02d: DT: use s32 to support negative values
      Drivers: hv: hv_balloon: correctly handle num_pages>INT_MAX case
      Drivers: hv: hv_balloon: correctly handle val.freeram<num_pages case
      mei: replace check for connection instead of transitioning
      mei: use mei_cl_is_connected consistently
      mei: fix mei_poll operation
      hv_vmbus: Add gradually increased delay for retries in vmbus_post_msg()
      Drivers: hv: hv_balloon: survive ballooning request with num_pages=0
      Drivers: hv: hv_balloon: eliminate jumps in piecewiese linear floor function
      Drivers: hv: hv_balloon: do not online pages in offline blocks
      hv: remove the per-channel workqueue
      hv: don't schedule new works in vmbus_onoffer()/vmbus_onoffer_rescind()
      hv: run non-blocking message handlers in the dispatch tasklet
      coresight: moving to new "hwtracing" directory
      coresight-tmc: Adding a status interface to sysfs
      coresight: remove the unnecessary configuration coresight-default-sink
      ...

commit a49b116dcb1265f238f3169507424257b0519069
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Apr 3 02:38:05 2015 +0200

    clockevents: Cleanup dead cpu explicitely
    
    clockevents_notify() is a leftover from the early design of the
    clockevents facility. It's really not a notification mechanism,
    it's a multiplex call. We are way better off to have explicit
    calls instead of this monstrosity.
    
    Split out the cleanup function for a dead cpu and invoke it
    directly from the cpu down code. Make it conditional on
    CPU_HOTPLUG as well.
    
    Temporary change, will be refined in the future.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    [ Rebased, added clockevents_notify() removal ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1735025.raBZdQHM3m@vostro.rjw.lan
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 88fb3b96c7cc..25d942d1da27 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -642,49 +642,40 @@ void clockevents_resume(void)
 			dev->resume(dev);
 }
 
+#ifdef CONFIG_HOTPLUG_CPU
 /**
- * clockevents_notify - notification about relevant events
- * Returns 0 on success, any other value on error
+ * tick_cleanup_dead_cpu - Cleanup the tick and clockevents of a dead cpu
  */
-int clockevents_notify(unsigned long reason, void *arg)
+void tick_cleanup_dead_cpu(int cpu)
 {
 	struct clock_event_device *dev, *tmp;
 	unsigned long flags;
-	int cpu, ret = 0;
 
 	raw_spin_lock_irqsave(&clockevents_lock, flags);
 
-	switch (reason) {
-	case CLOCK_EVT_NOTIFY_CPU_DEAD:
-		tick_shutdown_broadcast_oneshot(arg);
-		tick_shutdown_broadcast(arg);
-		tick_shutdown(arg);
-		/*
-		 * Unregister the clock event devices which were
-		 * released from the users in the notify chain.
-		 */
-		list_for_each_entry_safe(dev, tmp, &clockevents_released, list)
+	tick_shutdown_broadcast_oneshot(cpu);
+	tick_shutdown_broadcast(cpu);
+	tick_shutdown(cpu);
+	/*
+	 * Unregister the clock event devices which were
+	 * released from the users in the notify chain.
+	 */
+	list_for_each_entry_safe(dev, tmp, &clockevents_released, list)
+		list_del(&dev->list);
+	/*
+	 * Now check whether the CPU has left unused per cpu devices
+	 */
+	list_for_each_entry_safe(dev, tmp, &clockevent_devices, list) {
+		if (cpumask_test_cpu(cpu, dev->cpumask) &&
+		    cpumask_weight(dev->cpumask) == 1 &&
+		    !tick_is_broadcast_device(dev)) {
+			BUG_ON(dev->state != CLOCK_EVT_STATE_DETACHED);
 			list_del(&dev->list);
-		/*
-		 * Now check whether the CPU has left unused per cpu devices
-		 */
-		cpu = *((int *)arg);
-		list_for_each_entry_safe(dev, tmp, &clockevent_devices, list) {
-			if (cpumask_test_cpu(cpu, dev->cpumask) &&
-			    cpumask_weight(dev->cpumask) == 1 &&
-			    !tick_is_broadcast_device(dev)) {
-				BUG_ON(dev->state != CLOCK_EVT_STATE_DETACHED);
-				list_del(&dev->list);
-			}
 		}
-		break;
-	default:
-		break;
 	}
 	raw_spin_unlock_irqrestore(&clockevents_lock, flags);
-	return ret;
 }
-EXPORT_SYMBOL_GPL(clockevents_notify);
+#endif
 
 #ifdef CONFIG_SYSFS
 struct bus_type clockevents_subsys = {

commit 52c063d1adbc16c76e70fffa20727fcd4e9343b3
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Apr 3 02:37:24 2015 +0200

    clockevents: Make tick handover explicit
    
    clockevents_notify() is a leftover from the early design of the
    clockevents facility. It's really not a notification mechanism,
    it's a multiplex call. We are way better off to have explicit
    calls instead of this monstrosity.
    
    Split out the tick_handover call and invoke it explicitely from
    the hotplug code. Temporary solution will be cleaned up in later
    patches.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    [ Rebase ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Link: http://lkml.kernel.org/r/1658173.RkEEILFiQZ@vostro.rjw.lan
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index be9abf32c0b9..88fb3b96c7cc 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -655,10 +655,6 @@ int clockevents_notify(unsigned long reason, void *arg)
 	raw_spin_lock_irqsave(&clockevents_lock, flags);
 
 	switch (reason) {
-	case CLOCK_EVT_NOTIFY_CPU_DYING:
-		tick_handover_do_timer(arg);
-		break;
-
 	case CLOCK_EVT_NOTIFY_CPU_DEAD:
 		tick_shutdown_broadcast_oneshot(arg);
 		tick_shutdown_broadcast(arg);

commit ffa48c0d76803057ee89bf220305466d74256d7b
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Fri Apr 3 02:36:10 2015 +0200

    clockevents: Remove broadcast oneshot control leftovers
    
    Now that all users are converted over to explicit calls into the
    clockevents state machine, remove the notification chain leftovers.
    
    Original-from: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: John Stultz <john.stultz@linaro.org>
    Link: http://lkml.kernel.org/r/14018863.NQUzkFuafr@vostro.rjw.lan
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 7791b1c94ef2..be9abf32c0b9 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -655,13 +655,6 @@ int clockevents_notify(unsigned long reason, void *arg)
 	raw_spin_lock_irqsave(&clockevents_lock, flags);
 
 	switch (reason) {
-	case CLOCK_EVT_NOTIFY_BROADCAST_ENTER:
-		tick_broadcast_enter();
-		break;
-	case CLOCK_EVT_NOTIFY_BROADCAST_EXIT:
-		tick_broadcast_exit();
-		break;
-
 	case CLOCK_EVT_NOTIFY_CPU_DYING:
 		tick_handover_do_timer(arg);
 		break;

commit 1fe5d5c3c9ba0c4ade18e3325cba0ffe35127941
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Apr 3 02:05:15 2015 +0200

    clockevents: Provide explicit broadcast oneshot control functions
    
    clockevents_notify() is a leftover from the early design of the
    clockevents facility. It's really not a notification mechanism,
    it's a multiplex call. We are way better off to have explicit
    calls instead of this monstrosity.
    
    Split out the broadcast oneshot control into a separate function
    and provide inline helpers. Switch clockevents_notify() over.
    This will go away once all callers are converted.
    
    This also gets rid of the nested locking of clockevents_lock and
    broadcast_lock. The broadcast oneshot control functions do not
    require clockevents_lock. Only the managing functions
    (setup/shutdown/suspend/resume of the broadcast device require
    clockevents_lock.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: Alexandre Courbot <gnurou@gmail.com>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Len Brown <lenb@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Warren <swarren@wwwdotorg.org>
    Cc: Thierry Reding <thierry.reding@gmail.com>
    Cc: Tony Lindgren <tony@atomide.com>
    Link: http://lkml.kernel.org/r/13000649.8qZuEDV0OA@vostro.rjw.lan
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index dba0b83708b3..7791b1c94ef2 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -656,8 +656,10 @@ int clockevents_notify(unsigned long reason, void *arg)
 
 	switch (reason) {
 	case CLOCK_EVT_NOTIFY_BROADCAST_ENTER:
+		tick_broadcast_enter();
+		break;
 	case CLOCK_EVT_NOTIFY_BROADCAST_EXIT:
-		ret = tick_broadcast_oneshot_control(reason);
+		tick_broadcast_exit();
 		break;
 
 	case CLOCK_EVT_NOTIFY_CPU_DYING:

commit 89feddbfe7023ccfb4a6d7f5e3f5161d91b28b18
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Apr 3 02:03:42 2015 +0200

    clockevents: Remove the broadcast control leftovers
    
    All users converted. Remove the notify leftovers.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/2076318.76XJZ8QYP3@vostro.rjw.lan
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 599ff8d3fda5..dba0b83708b3 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -655,16 +655,6 @@ int clockevents_notify(unsigned long reason, void *arg)
 	raw_spin_lock_irqsave(&clockevents_lock, flags);
 
 	switch (reason) {
-	case CLOCK_EVT_NOTIFY_BROADCAST_ON:
-		tick_broadcast_enable();
-		break;
-	case CLOCK_EVT_NOTIFY_BROADCAST_OFF:
-		tick_broadcast_disable();
-		break;
-	case CLOCK_EVT_NOTIFY_BROADCAST_FORCE:
-		tick_broadcast_force();
-		break;
-
 	case CLOCK_EVT_NOTIFY_BROADCAST_ENTER:
 	case CLOCK_EVT_NOTIFY_BROADCAST_EXIT:
 		ret = tick_broadcast_oneshot_control(reason);

commit 592a438ff3fea61d303c5784c209b3f1fd3e16df
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Apr 3 02:01:10 2015 +0200

    clockevents: Provide explicit broadcast control functions
    
    clockevents_notify() is a leftover from the early design of the
    clockevents facility. It's really not a notification mechanism,
    it's a multiplex call. We are way better off to have explicit
    calls instead of this monstrosity.
    
    Split out the broadcast control into a separate function and
    provide inline helpers. Switch clockevents_notify() over. This
    will go away once all callers are converted.
    
    This also gets rid of the nested locking of clockevents_lock and
    broadcast_lock. The broadcast control functions do not require
    clockevents_lock. Only the managing functions
    (setup/shutdown/suspend/resume of the broadcast device require
    clockevents_lock.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Len Brown <lenb@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Tony Lindgren <tony@atomide.com>
    Link: http://lkml.kernel.org/r/8086559.ttsuS0n1Xr@vostro.rjw.lan
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 7af614829da1..599ff8d3fda5 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -656,9 +656,13 @@ int clockevents_notify(unsigned long reason, void *arg)
 
 	switch (reason) {
 	case CLOCK_EVT_NOTIFY_BROADCAST_ON:
+		tick_broadcast_enable();
+		break;
 	case CLOCK_EVT_NOTIFY_BROADCAST_OFF:
+		tick_broadcast_disable();
+		break;
 	case CLOCK_EVT_NOTIFY_BROADCAST_FORCE:
-		tick_broadcast_on_off(reason, arg);
+		tick_broadcast_force();
 		break;
 
 	case CLOCK_EVT_NOTIFY_BROADCAST_ENTER:

commit 4ffee521f36390c7720d493591b764ca35c8030b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Mar 25 13:09:16 2015 +0100

    clockevents: Make suspend/resume calls explicit
    
    clockevents_notify() is a leftover from the early design of the
    clockevents facility. It's really not a notification mechanism,
    it's a multiplex call.
    
    We are way better off to have explicit calls instead of this
    monstrosity. Split out the suspend/resume() calls and invoke
    them directly from the call sites.
    
    No locking required at this point because these calls happen
    with interrupts disabled and a single cpu online.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    [ Rebased on top of 4.0-rc5. ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/713674030.jVm1qaHuPf@vostro.rjw.lan
    [ Rebased on top of latest timers/core. ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index b73002718536..7af614829da1 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -670,15 +670,6 @@ int clockevents_notify(unsigned long reason, void *arg)
 		tick_handover_do_timer(arg);
 		break;
 
-	case CLOCK_EVT_NOTIFY_SUSPEND:
-		tick_suspend();
-		tick_suspend_broadcast();
-		break;
-
-	case CLOCK_EVT_NOTIFY_RESUME:
-		tick_resume();
-		break;
-
 	case CLOCK_EVT_NOTIFY_CPU_DEAD:
 		tick_shutdown_broadcast_oneshot(arg);
 		tick_shutdown_broadcast(arg);

commit db6f672ef11d7a3c5aa128a3c3e57c92580a25f7
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Mar 25 13:08:27 2015 +0100

    clockevents: Remove extra local_irq_save() in clockevents_exchange_device()
    
    Called with 'clockevents_lock' held and interrupts disabled
    already.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/51005827.yXt5tjZMBs@vostro.rjw.lan
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 3531beecbe95..b73002718536 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -595,14 +595,12 @@ void clockevents_handle_noop(struct clock_event_device *dev)
  * @old:	device to release (can be NULL)
  * @new:	device to request (can be NULL)
  *
- * Called from the notifier chain. clockevents_lock is held already
+ * Called from various tick functions with clockevents_lock held and
+ * interrupts disabled.
  */
 void clockevents_exchange_device(struct clock_event_device *old,
 				 struct clock_event_device *new)
 {
-	unsigned long flags;
-
-	local_irq_save(flags);
 	/*
 	 * Caller releases a clock event device. We queue it into the
 	 * released list and do a notify add later.
@@ -618,7 +616,6 @@ void clockevents_exchange_device(struct clock_event_device *old,
 		BUG_ON(new->state != CLOCK_EVT_STATE_DETACHED);
 		clockevents_shutdown(new);
 	}
-	local_irq_restore(flags);
 }
 
 /**

commit 9f083b74df3a7eaa100b456f2dc195512daf728e
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Mar 25 13:05:19 2015 +0100

    clockevents: Remove CONFIG_GENERIC_CLOCKEVENTS_BUILD
    
    This option was for simpler migration to the clock events code.
    Most architectures have been converted and the option has been
    disfunctional as a standalone option for quite some time. Remove
    it.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/5021859.jl9OC1medj@vostro.rjw.lan
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 73689df1e4b8..3531beecbe95 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -645,7 +645,6 @@ void clockevents_resume(void)
 			dev->resume(dev);
 }
 
-#ifdef CONFIG_GENERIC_CLOCKEVENTS
 /**
  * clockevents_notify - notification about relevant events
  * Returns 0 on success, any other value on error
@@ -831,5 +830,3 @@ static int __init clockevents_init_sysfs(void)
 }
 device_initcall(clockevents_init_sysfs);
 #endif /* SYSFS */
-
-#endif /* GENERIC_CLOCK_EVENTS */

commit de81e64b250d3865a75d221a80b4311e3273670a
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Fri Feb 27 17:21:34 2015 +0530

    clockevents: Don't validate dev->mode against CLOCK_EVT_MODE_UNUSED for new interface
    
    It was a requirement in the legacy interface that drivers must
    initialize ->mode field to 'CLOCK_EVT_MODE_UNUSED'. This field
    isn't used anymore by the new interface and so should be only
    checked for the legacy interface.
    
    Probably it can be dropped as well as core doesn't rely on it
    anymore, but lets keep it to support legacy interface.
    
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Kevin Hilman <khilman@linaro.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Cc: linaro-kernel@lists.linaro.org
    Cc: linaro-networking@linaro.org
    Cc: linux-arm-kernel@lists.infradead.org
    Link: http://lkml.kernel.org/r/c6604fa1a77fe1fc8dcab87769857228fb1dadd5.1425037853.git.viresh.kumar@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 6e53e9a0c2e8..73689df1e4b8 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -450,6 +450,8 @@ static int clockevents_sanity_check(struct clock_event_device *dev)
 		/* We shouldn't be supporting new modes now */
 		WARN_ON(dev->set_state_periodic || dev->set_state_oneshot ||
 			dev->set_state_shutdown || dev->tick_resume);
+
+		BUG_ON(dev->mode != CLOCK_EVT_MODE_UNUSED);
 		return 0;
 	}
 
@@ -479,7 +481,6 @@ void clockevents_register_device(struct clock_event_device *dev)
 {
 	unsigned long flags;
 
-	BUG_ON(dev->mode != CLOCK_EVT_MODE_UNUSED);
 	BUG_ON(clockevents_sanity_check(dev));
 
 	/* Initialize state to DETACHED */

commit 77e32c89a7117614ab3d66d20c1088de721abfaa
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Fri Feb 27 17:21:33 2015 +0530

    clockevents: Manage device's state separately for the core
    
    'enum clock_event_mode' is used for two purposes today:
    
     - to pass mode to the driver of clockevent device::set_mode().
    
     - for managing state of the device for clockevents core.
    
    For supporting new modes/states we have moved away from the
    legacy set_mode() callback to new per-mode/state callbacks. New
    modes/states shouldn't be exposed to the legacy (now OBSOLOTE)
    callbacks and so we shouldn't add new states to 'enum
    clock_event_mode'.
    
    Lets have separate enums for the two use cases mentioned above.
    Keep using the earlier enum for legacy set_mode() callback and
    mark it OBSOLETE. And add another enum to clearly specify the
    possible states of a clockevent device.
    
    This also renames the newly added per-mode callbacks to reflect
    state changes.
    
    We haven't got rid of 'mode' member of 'struct
    clock_event_device' as it is used by some of the clockevent
    drivers and it would automatically die down once we migrate
    those drivers to the new interface. It ('mode') is only updated
    now for the drivers using the legacy interface.
    
    Suggested-by: Peter Zijlstra <peterz@infradead.org>
    Suggested-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Kevin Hilman <khilman@linaro.org>
    Cc: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Cc: linaro-kernel@lists.linaro.org
    Cc: linaro-networking@linaro.org
    Cc: linux-arm-kernel@lists.infradead.org
    Link: http://lkml.kernel.org/r/b6b0143a8a57bd58352ad35e08c25424c879c0cb.1425037853.git.viresh.kumar@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 1b0ea63de69c..6e53e9a0c2e8 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -94,44 +94,49 @@ u64 clockevent_delta2ns(unsigned long latch, struct clock_event_device *evt)
 }
 EXPORT_SYMBOL_GPL(clockevent_delta2ns);
 
-static int __clockevents_set_mode(struct clock_event_device *dev,
-				  enum clock_event_mode mode)
+static int __clockevents_set_state(struct clock_event_device *dev,
+				   enum clock_event_state state)
 {
 	/* Transition with legacy set_mode() callback */
 	if (dev->set_mode) {
 		/* Legacy callback doesn't support new modes */
-		if (mode > CLOCK_EVT_MODE_ONESHOT)
+		if (state > CLOCK_EVT_STATE_ONESHOT)
 			return -ENOSYS;
-		dev->set_mode(mode, dev);
+		/*
+		 * 'clock_event_state' and 'clock_event_mode' have 1-to-1
+		 * mapping until *_ONESHOT, and so a simple cast will work.
+		 */
+		dev->set_mode((enum clock_event_mode)state, dev);
+		dev->mode = (enum clock_event_mode)state;
 		return 0;
 	}
 
 	if (dev->features & CLOCK_EVT_FEAT_DUMMY)
 		return 0;
 
-	/* Transition with new mode-specific callbacks */
-	switch (mode) {
-	case CLOCK_EVT_MODE_UNUSED:
+	/* Transition with new state-specific callbacks */
+	switch (state) {
+	case CLOCK_EVT_STATE_DETACHED:
 		/*
 		 * This is an internal state, which is guaranteed to go from
-		 * SHUTDOWN to UNUSED. No driver interaction required.
+		 * SHUTDOWN to DETACHED. No driver interaction required.
 		 */
 		return 0;
 
-	case CLOCK_EVT_MODE_SHUTDOWN:
-		return dev->set_mode_shutdown(dev);
+	case CLOCK_EVT_STATE_SHUTDOWN:
+		return dev->set_state_shutdown(dev);
 
-	case CLOCK_EVT_MODE_PERIODIC:
+	case CLOCK_EVT_STATE_PERIODIC:
 		/* Core internal bug */
 		if (!(dev->features & CLOCK_EVT_FEAT_PERIODIC))
 			return -ENOSYS;
-		return dev->set_mode_periodic(dev);
+		return dev->set_state_periodic(dev);
 
-	case CLOCK_EVT_MODE_ONESHOT:
+	case CLOCK_EVT_STATE_ONESHOT:
 		/* Core internal bug */
 		if (!(dev->features & CLOCK_EVT_FEAT_ONESHOT))
 			return -ENOSYS;
-		return dev->set_mode_oneshot(dev);
+		return dev->set_state_oneshot(dev);
 
 	default:
 		return -ENOSYS;
@@ -139,26 +144,26 @@ static int __clockevents_set_mode(struct clock_event_device *dev,
 }
 
 /**
- * clockevents_set_mode - set the operating mode of a clock event device
+ * clockevents_set_state - set the operating state of a clock event device
  * @dev:	device to modify
- * @mode:	new mode
+ * @state:	new state
  *
  * Must be called with interrupts disabled !
  */
-void clockevents_set_mode(struct clock_event_device *dev,
-				 enum clock_event_mode mode)
+void clockevents_set_state(struct clock_event_device *dev,
+			   enum clock_event_state state)
 {
-	if (dev->mode != mode) {
-		if (__clockevents_set_mode(dev, mode))
+	if (dev->state != state) {
+		if (__clockevents_set_state(dev, state))
 			return;
 
-		dev->mode = mode;
+		dev->state = state;
 
 		/*
 		 * A nsec2cyc multiplicator of 0 is invalid and we'd crash
 		 * on it, so fix it up and emit a warning:
 		 */
-		if (mode == CLOCK_EVT_MODE_ONESHOT) {
+		if (state == CLOCK_EVT_STATE_ONESHOT) {
 			if (unlikely(!dev->mult)) {
 				dev->mult = 1;
 				WARN_ON(1);
@@ -173,7 +178,7 @@ void clockevents_set_mode(struct clock_event_device *dev,
  */
 void clockevents_shutdown(struct clock_event_device *dev)
 {
-	clockevents_set_mode(dev, CLOCK_EVT_MODE_SHUTDOWN);
+	clockevents_set_state(dev, CLOCK_EVT_STATE_SHUTDOWN);
 	dev->next_event.tv64 = KTIME_MAX;
 }
 
@@ -185,13 +190,12 @@ int clockevents_tick_resume(struct clock_event_device *dev)
 {
 	int ret = 0;
 
-	if (dev->set_mode)
+	if (dev->set_mode) {
 		dev->set_mode(CLOCK_EVT_MODE_RESUME, dev);
-	else if (dev->tick_resume)
-		ret = dev->tick_resume(dev);
-
-	if (likely(!ret))
 		dev->mode = CLOCK_EVT_MODE_RESUME;
+	} else if (dev->tick_resume) {
+		ret = dev->tick_resume(dev);
+	}
 
 	return ret;
 }
@@ -248,7 +252,7 @@ static int clockevents_program_min_delta(struct clock_event_device *dev)
 		delta = dev->min_delta_ns;
 		dev->next_event = ktime_add_ns(ktime_get(), delta);
 
-		if (dev->mode == CLOCK_EVT_MODE_SHUTDOWN)
+		if (dev->state == CLOCK_EVT_STATE_SHUTDOWN)
 			return 0;
 
 		dev->retries++;
@@ -285,7 +289,7 @@ static int clockevents_program_min_delta(struct clock_event_device *dev)
 	delta = dev->min_delta_ns;
 	dev->next_event = ktime_add_ns(ktime_get(), delta);
 
-	if (dev->mode == CLOCK_EVT_MODE_SHUTDOWN)
+	if (dev->state == CLOCK_EVT_STATE_SHUTDOWN)
 		return 0;
 
 	dev->retries++;
@@ -317,7 +321,7 @@ int clockevents_program_event(struct clock_event_device *dev, ktime_t expires,
 
 	dev->next_event = expires;
 
-	if (dev->mode == CLOCK_EVT_MODE_SHUTDOWN)
+	if (dev->state == CLOCK_EVT_STATE_SHUTDOWN)
 		return 0;
 
 	/* Shortcut for clockevent devices that can deal with ktime. */
@@ -362,7 +366,7 @@ static int clockevents_replace(struct clock_event_device *ced)
 	struct clock_event_device *dev, *newdev = NULL;
 
 	list_for_each_entry(dev, &clockevent_devices, list) {
-		if (dev == ced || dev->mode != CLOCK_EVT_MODE_UNUSED)
+		if (dev == ced || dev->state != CLOCK_EVT_STATE_DETACHED)
 			continue;
 
 		if (!tick_check_replacement(newdev, dev))
@@ -388,7 +392,7 @@ static int clockevents_replace(struct clock_event_device *ced)
 static int __clockevents_try_unbind(struct clock_event_device *ced, int cpu)
 {
 	/* Fast track. Device is unused */
-	if (ced->mode == CLOCK_EVT_MODE_UNUSED) {
+	if (ced->state == CLOCK_EVT_STATE_DETACHED) {
 		list_del_init(&ced->list);
 		return 0;
 	}
@@ -438,30 +442,30 @@ int clockevents_unbind_device(struct clock_event_device *ced, int cpu)
 }
 EXPORT_SYMBOL_GPL(clockevents_unbind);
 
-/* Sanity check of mode transition callbacks */
+/* Sanity check of state transition callbacks */
 static int clockevents_sanity_check(struct clock_event_device *dev)
 {
 	/* Legacy set_mode() callback */
 	if (dev->set_mode) {
 		/* We shouldn't be supporting new modes now */
-		WARN_ON(dev->set_mode_periodic || dev->set_mode_oneshot ||
-			dev->set_mode_shutdown || dev->tick_resume);
+		WARN_ON(dev->set_state_periodic || dev->set_state_oneshot ||
+			dev->set_state_shutdown || dev->tick_resume);
 		return 0;
 	}
 
 	if (dev->features & CLOCK_EVT_FEAT_DUMMY)
 		return 0;
 
-	/* New mode-specific callbacks */
-	if (!dev->set_mode_shutdown)
+	/* New state-specific callbacks */
+	if (!dev->set_state_shutdown)
 		return -EINVAL;
 
 	if ((dev->features & CLOCK_EVT_FEAT_PERIODIC) &&
-	    !dev->set_mode_periodic)
+	    !dev->set_state_periodic)
 		return -EINVAL;
 
 	if ((dev->features & CLOCK_EVT_FEAT_ONESHOT) &&
-	    !dev->set_mode_oneshot)
+	    !dev->set_state_oneshot)
 		return -EINVAL;
 
 	return 0;
@@ -478,6 +482,9 @@ void clockevents_register_device(struct clock_event_device *dev)
 	BUG_ON(dev->mode != CLOCK_EVT_MODE_UNUSED);
 	BUG_ON(clockevents_sanity_check(dev));
 
+	/* Initialize state to DETACHED */
+	dev->state = CLOCK_EVT_STATE_DETACHED;
+
 	if (!dev->cpumask) {
 		WARN_ON(num_possible_cpus() > 1);
 		dev->cpumask = cpumask_of(smp_processor_id());
@@ -541,11 +548,11 @@ int __clockevents_update_freq(struct clock_event_device *dev, u32 freq)
 {
 	clockevents_config(dev, freq);
 
-	if (dev->mode == CLOCK_EVT_MODE_ONESHOT)
+	if (dev->state == CLOCK_EVT_STATE_ONESHOT)
 		return clockevents_program_event(dev, dev->next_event, false);
 
-	if (dev->mode == CLOCK_EVT_MODE_PERIODIC)
-		return __clockevents_set_mode(dev, CLOCK_EVT_MODE_PERIODIC);
+	if (dev->state == CLOCK_EVT_STATE_PERIODIC)
+		return __clockevents_set_state(dev, CLOCK_EVT_STATE_PERIODIC);
 
 	return 0;
 }
@@ -601,13 +608,13 @@ void clockevents_exchange_device(struct clock_event_device *old,
 	 */
 	if (old) {
 		module_put(old->owner);
-		clockevents_set_mode(old, CLOCK_EVT_MODE_UNUSED);
+		clockevents_set_state(old, CLOCK_EVT_STATE_DETACHED);
 		list_del(&old->list);
 		list_add(&old->list, &clockevents_released);
 	}
 
 	if (new) {
-		BUG_ON(new->mode != CLOCK_EVT_MODE_UNUSED);
+		BUG_ON(new->state != CLOCK_EVT_STATE_DETACHED);
 		clockevents_shutdown(new);
 	}
 	local_irq_restore(flags);
@@ -693,7 +700,7 @@ int clockevents_notify(unsigned long reason, void *arg)
 			if (cpumask_test_cpu(cpu, dev->cpumask) &&
 			    cpumask_weight(dev->cpumask) == 1 &&
 			    !tick_is_broadcast_device(dev)) {
-				BUG_ON(dev->mode != CLOCK_EVT_MODE_UNUSED);
+				BUG_ON(dev->state != CLOCK_EVT_STATE_DETACHED);
 				list_del(&dev->list);
 			}
 		}

commit 554ef3876c6acdff1331feab10275e9e9e0adb84
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Fri Feb 27 17:21:32 2015 +0530

    clockevents: Handle tick device's resume separately
    
    Upcoming patch will redefine possible states of a clockevent
    device. The RESUME mode is a special case only for tick's
    clockevent devices. In future it can be replaced by ->resume()
    callback already available for clockevent devices.
    
    Lets handle it separately so that clockevents_set_mode() only
    handles states valid across all devices. This also renames
    set_mode_resume() to tick_resume() to make it more explicit.
    
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Kevin Hilman <khilman@linaro.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Cc: linaro-kernel@lists.linaro.org
    Cc: linaro-networking@linaro.org
    Cc: linux-arm-kernel@lists.infradead.org
    Link: http://lkml.kernel.org/r/c1b0112410870f49e7bf06958e1483eac6c15e20.1425037853.git.viresh.kumar@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 489642b08d64..1b0ea63de69c 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -100,7 +100,7 @@ static int __clockevents_set_mode(struct clock_event_device *dev,
 	/* Transition with legacy set_mode() callback */
 	if (dev->set_mode) {
 		/* Legacy callback doesn't support new modes */
-		if (mode > CLOCK_EVT_MODE_RESUME)
+		if (mode > CLOCK_EVT_MODE_ONESHOT)
 			return -ENOSYS;
 		dev->set_mode(mode, dev);
 		return 0;
@@ -133,13 +133,6 @@ static int __clockevents_set_mode(struct clock_event_device *dev,
 			return -ENOSYS;
 		return dev->set_mode_oneshot(dev);
 
-	case CLOCK_EVT_MODE_RESUME:
-		/* Optional callback */
-		if (dev->set_mode_resume)
-			return dev->set_mode_resume(dev);
-		else
-			return 0;
-
 	default:
 		return -ENOSYS;
 	}
@@ -184,6 +177,25 @@ void clockevents_shutdown(struct clock_event_device *dev)
 	dev->next_event.tv64 = KTIME_MAX;
 }
 
+/**
+ * clockevents_tick_resume -	Resume the tick device before using it again
+ * @dev:			device to resume
+ */
+int clockevents_tick_resume(struct clock_event_device *dev)
+{
+	int ret = 0;
+
+	if (dev->set_mode)
+		dev->set_mode(CLOCK_EVT_MODE_RESUME, dev);
+	else if (dev->tick_resume)
+		ret = dev->tick_resume(dev);
+
+	if (likely(!ret))
+		dev->mode = CLOCK_EVT_MODE_RESUME;
+
+	return ret;
+}
+
 #ifdef CONFIG_GENERIC_CLOCKEVENTS_MIN_ADJUST
 
 /* Limit min_delta to a jiffie */
@@ -433,7 +445,7 @@ static int clockevents_sanity_check(struct clock_event_device *dev)
 	if (dev->set_mode) {
 		/* We shouldn't be supporting new modes now */
 		WARN_ON(dev->set_mode_periodic || dev->set_mode_oneshot ||
-			dev->set_mode_shutdown || dev->set_mode_resume);
+			dev->set_mode_shutdown || dev->tick_resume);
 		return 0;
 	}
 

commit 32a158325acf12842764b1681f53903673f2f22e
Author: Vitaly Kuznetsov <vkuznets@redhat.com>
Date:   Fri Feb 27 11:25:56 2015 -0800

    clockevents: export clockevents_unbind_device instead of clockevents_unbind
    
    It looks like clockevents_unbind is being exported by mistake as:
    - it is static;
    - it is not listed in include/linux/clockchips.h;
    - EXPORT_SYMBOL_GPL(clockevents_unbind) follows clockevents_unbind_device()
      implementation.
    
    I think clockevents_unbind_device should be exported instead. This is going to
    be used to teardown Hyper-V clockevent devices on module unload.
    
    Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
    Signed-off-by: K. Y. Srinivasan <kys@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 55449909f114..888ecc114ddc 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -371,7 +371,7 @@ int clockevents_unbind_device(struct clock_event_device *ced, int cpu)
 	mutex_unlock(&clockevents_mutex);
 	return ret;
 }
-EXPORT_SYMBOL_GPL(clockevents_unbind);
+EXPORT_SYMBOL_GPL(clockevents_unbind_device);
 
 /**
  * clockevents_register_device - register a clock event device

commit bd624d75db21ea5402f9ecf4450b311794d80352
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Fri Feb 13 08:54:56 2015 +0800

    clockevents: Introduce mode specific callbacks
    
    It is not possible for the clockevents core to know which modes (other than
    those with a corresponding feature flag) are supported by a particular
    implementation. And drivers are expected to handle transition to all modes
    elegantly, as ->set_mode() would be issued for them unconditionally.
    
    Now, adding support for a new mode complicates things a bit if we want to use
    the legacy ->set_mode() callback. We need to closely review all clockevents
    drivers to see if they would break on addition of a new mode. And after such
    reviews, it is found that we have to do non-trivial changes to most of the
    drivers [1].
    
    Introduce mode-specific set_mode_*() callbacks, some of which the drivers may or
    may not implement. A missing callback would clearly convey the message that the
    corresponding mode isn't supported.
    
    A driver may still choose to keep supporting the legacy ->set_mode() callback,
    but ->set_mode() wouldn't be supporting any new modes beyond RESUME. If a driver
    wants to benefit from using a new mode, it would be required to migrate to
    the mode specific callbacks.
    
    The legacy ->set_mode() callback and the newly introduced mode-specific
    callbacks are mutually exclusive. Only one of them should be supported by the
    driver.
    
    Sanity check is done at the time of registration to distinguish between optional
    and required callbacks and to make error recovery and handling simpler. If the
    legacy ->set_mode() callback is provided, all mode specific ones would be
    ignored by the core but a warning is thrown if they are present.
    
    Call sites calling ->set_mode() directly are also updated to use
    __clockevents_set_mode() instead, as ->set_mode() may not be available anymore
    for few drivers.
    
     [1] https://lkml.org/lkml/2014/12/9/605
     [2] https://lkml.org/lkml/2015/1/23/255
    
    Suggested-by: Thomas Gleixner <tglx@linutronix.de> [2]
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: Kevin Hilman <khilman@linaro.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Cc: linaro-kernel@lists.linaro.org
    Cc: linaro-networking@linaro.org
    Link: http://lkml.kernel.org/r/792d59a40423f0acffc9bb0bec9de1341a06fa02.1423788565.git.viresh.kumar@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 55449909f114..489642b08d64 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -94,6 +94,57 @@ u64 clockevent_delta2ns(unsigned long latch, struct clock_event_device *evt)
 }
 EXPORT_SYMBOL_GPL(clockevent_delta2ns);
 
+static int __clockevents_set_mode(struct clock_event_device *dev,
+				  enum clock_event_mode mode)
+{
+	/* Transition with legacy set_mode() callback */
+	if (dev->set_mode) {
+		/* Legacy callback doesn't support new modes */
+		if (mode > CLOCK_EVT_MODE_RESUME)
+			return -ENOSYS;
+		dev->set_mode(mode, dev);
+		return 0;
+	}
+
+	if (dev->features & CLOCK_EVT_FEAT_DUMMY)
+		return 0;
+
+	/* Transition with new mode-specific callbacks */
+	switch (mode) {
+	case CLOCK_EVT_MODE_UNUSED:
+		/*
+		 * This is an internal state, which is guaranteed to go from
+		 * SHUTDOWN to UNUSED. No driver interaction required.
+		 */
+		return 0;
+
+	case CLOCK_EVT_MODE_SHUTDOWN:
+		return dev->set_mode_shutdown(dev);
+
+	case CLOCK_EVT_MODE_PERIODIC:
+		/* Core internal bug */
+		if (!(dev->features & CLOCK_EVT_FEAT_PERIODIC))
+			return -ENOSYS;
+		return dev->set_mode_periodic(dev);
+
+	case CLOCK_EVT_MODE_ONESHOT:
+		/* Core internal bug */
+		if (!(dev->features & CLOCK_EVT_FEAT_ONESHOT))
+			return -ENOSYS;
+		return dev->set_mode_oneshot(dev);
+
+	case CLOCK_EVT_MODE_RESUME:
+		/* Optional callback */
+		if (dev->set_mode_resume)
+			return dev->set_mode_resume(dev);
+		else
+			return 0;
+
+	default:
+		return -ENOSYS;
+	}
+}
+
 /**
  * clockevents_set_mode - set the operating mode of a clock event device
  * @dev:	device to modify
@@ -105,7 +156,9 @@ void clockevents_set_mode(struct clock_event_device *dev,
 				 enum clock_event_mode mode)
 {
 	if (dev->mode != mode) {
-		dev->set_mode(mode, dev);
+		if (__clockevents_set_mode(dev, mode))
+			return;
+
 		dev->mode = mode;
 
 		/*
@@ -373,6 +426,35 @@ int clockevents_unbind_device(struct clock_event_device *ced, int cpu)
 }
 EXPORT_SYMBOL_GPL(clockevents_unbind);
 
+/* Sanity check of mode transition callbacks */
+static int clockevents_sanity_check(struct clock_event_device *dev)
+{
+	/* Legacy set_mode() callback */
+	if (dev->set_mode) {
+		/* We shouldn't be supporting new modes now */
+		WARN_ON(dev->set_mode_periodic || dev->set_mode_oneshot ||
+			dev->set_mode_shutdown || dev->set_mode_resume);
+		return 0;
+	}
+
+	if (dev->features & CLOCK_EVT_FEAT_DUMMY)
+		return 0;
+
+	/* New mode-specific callbacks */
+	if (!dev->set_mode_shutdown)
+		return -EINVAL;
+
+	if ((dev->features & CLOCK_EVT_FEAT_PERIODIC) &&
+	    !dev->set_mode_periodic)
+		return -EINVAL;
+
+	if ((dev->features & CLOCK_EVT_FEAT_ONESHOT) &&
+	    !dev->set_mode_oneshot)
+		return -EINVAL;
+
+	return 0;
+}
+
 /**
  * clockevents_register_device - register a clock event device
  * @dev:	device to register
@@ -382,6 +464,8 @@ void clockevents_register_device(struct clock_event_device *dev)
 	unsigned long flags;
 
 	BUG_ON(dev->mode != CLOCK_EVT_MODE_UNUSED);
+	BUG_ON(clockevents_sanity_check(dev));
+
 	if (!dev->cpumask) {
 		WARN_ON(num_possible_cpus() > 1);
 		dev->cpumask = cpumask_of(smp_processor_id());
@@ -449,7 +533,7 @@ int __clockevents_update_freq(struct clock_event_device *dev, u32 freq)
 		return clockevents_program_event(dev, dev->next_event, false);
 
 	if (dev->mode == CLOCK_EVT_MODE_PERIODIC)
-		dev->set_mode(CLOCK_EVT_MODE_PERIODIC, dev);
+		return __clockevents_set_mode(dev, CLOCK_EVT_MODE_PERIODIC);
 
 	return 0;
 }

commit 10632008b9e18b76cbff0ffc69c15e948aa548e0
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Oct 20 15:07:50 2014 +0400

    clockevents: Prevent shift out of bounds
    
    Andrey reported that on a kernel with UBSan enabled he found:
    
         UBSan: Undefined behaviour in ../kernel/time/clockevents.c:75:34
    
         I guess it should be 1ULL here instead of 1U:
                (!ismax || evt->mult <= (1U << evt->shift)))
    
    That's indeed the correct solution because shift might be 32.
    
    Reported-by: Andrey Ryabinin <a.ryabinin@samsung.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 9c94c19f1305..55449909f114 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -72,7 +72,7 @@ static u64 cev_delta2ns(unsigned long latch, struct clock_event_device *evt,
 	 * Also omit the add if it would overflow the u64 boundary.
 	 */
 	if ((~0ULL - clc > rnd) &&
-	    (!ismax || evt->mult <= (1U << evt->shift)))
+	    (!ismax || evt->mult <= (1ULL << evt->shift)))
 		clc += rnd;
 
 	do_div(clc, evt->mult);

commit 504d58745c9ca28d33572e2d8a9990b43e06075d
Author: Jan Kara <jack@suse.cz>
Date:   Fri Aug 1 12:20:02 2014 +0200

    timer: Fix lock inversion between hrtimer_bases.lock and scheduler locks
    
    clockevents_increase_min_delta() calls printk() from under
    hrtimer_bases.lock. That causes lock inversion on scheduler locks because
    printk() can call into the scheduler. Lockdep puts it as:
    
    ======================================================
    [ INFO: possible circular locking dependency detected ]
    3.15.0-rc8-06195-g939f04b #2 Not tainted
    -------------------------------------------------------
    trinity-main/74 is trying to acquire lock:
     (&port_lock_key){-.....}, at: [<811c60be>] serial8250_console_write+0x8c/0x10c
    
    but task is already holding lock:
     (hrtimer_bases.lock){-.-...}, at: [<8103caeb>] hrtimer_try_to_cancel+0x13/0x66
    
    which lock already depends on the new lock.
    
    the existing dependency chain (in reverse order) is:
    
    -> #5 (hrtimer_bases.lock){-.-...}:
           [<8104a942>] lock_acquire+0x92/0x101
           [<8142f11d>] _raw_spin_lock_irqsave+0x2e/0x3e
           [<8103c918>] __hrtimer_start_range_ns+0x1c/0x197
           [<8107ec20>] perf_swevent_start_hrtimer.part.41+0x7a/0x85
           [<81080792>] task_clock_event_start+0x3a/0x3f
           [<810807a4>] task_clock_event_add+0xd/0x14
           [<8108259a>] event_sched_in+0xb6/0x17a
           [<810826a2>] group_sched_in+0x44/0x122
           [<81082885>] ctx_sched_in.isra.67+0x105/0x11f
           [<810828e6>] perf_event_sched_in.isra.70+0x47/0x4b
           [<81082bf6>] __perf_install_in_context+0x8b/0xa3
           [<8107eb8e>] remote_function+0x12/0x2a
           [<8105f5af>] smp_call_function_single+0x2d/0x53
           [<8107e17d>] task_function_call+0x30/0x36
           [<8107fb82>] perf_install_in_context+0x87/0xbb
           [<810852c9>] SYSC_perf_event_open+0x5c6/0x701
           [<810856f9>] SyS_perf_event_open+0x17/0x19
           [<8142f8ee>] syscall_call+0x7/0xb
    
    -> #4 (&ctx->lock){......}:
           [<8104a942>] lock_acquire+0x92/0x101
           [<8142f04c>] _raw_spin_lock+0x21/0x30
           [<81081df3>] __perf_event_task_sched_out+0x1dc/0x34f
           [<8142cacc>] __schedule+0x4c6/0x4cb
           [<8142cae0>] schedule+0xf/0x11
           [<8142f9a6>] work_resched+0x5/0x30
    
    -> #3 (&rq->lock){-.-.-.}:
           [<8104a942>] lock_acquire+0x92/0x101
           [<8142f04c>] _raw_spin_lock+0x21/0x30
           [<81040873>] __task_rq_lock+0x33/0x3a
           [<8104184c>] wake_up_new_task+0x25/0xc2
           [<8102474b>] do_fork+0x15c/0x2a0
           [<810248a9>] kernel_thread+0x1a/0x1f
           [<814232a2>] rest_init+0x1a/0x10e
           [<817af949>] start_kernel+0x303/0x308
           [<817af2ab>] i386_start_kernel+0x79/0x7d
    
    -> #2 (&p->pi_lock){-.-...}:
           [<8104a942>] lock_acquire+0x92/0x101
           [<8142f11d>] _raw_spin_lock_irqsave+0x2e/0x3e
           [<810413dd>] try_to_wake_up+0x1d/0xd6
           [<810414cd>] default_wake_function+0xb/0xd
           [<810461f3>] __wake_up_common+0x39/0x59
           [<81046346>] __wake_up+0x29/0x3b
           [<811b8733>] tty_wakeup+0x49/0x51
           [<811c3568>] uart_write_wakeup+0x17/0x19
           [<811c5dc1>] serial8250_tx_chars+0xbc/0xfb
           [<811c5f28>] serial8250_handle_irq+0x54/0x6a
           [<811c5f57>] serial8250_default_handle_irq+0x19/0x1c
           [<811c56d8>] serial8250_interrupt+0x38/0x9e
           [<810510e7>] handle_irq_event_percpu+0x5f/0x1e2
           [<81051296>] handle_irq_event+0x2c/0x43
           [<81052cee>] handle_level_irq+0x57/0x80
           [<81002a72>] handle_irq+0x46/0x5c
           [<810027df>] do_IRQ+0x32/0x89
           [<8143036e>] common_interrupt+0x2e/0x33
           [<8142f23c>] _raw_spin_unlock_irqrestore+0x3f/0x49
           [<811c25a4>] uart_start+0x2d/0x32
           [<811c2c04>] uart_write+0xc7/0xd6
           [<811bc6f6>] n_tty_write+0xb8/0x35e
           [<811b9beb>] tty_write+0x163/0x1e4
           [<811b9cd9>] redirected_tty_write+0x6d/0x75
           [<810b6ed6>] vfs_write+0x75/0xb0
           [<810b7265>] SyS_write+0x44/0x77
           [<8142f8ee>] syscall_call+0x7/0xb
    
    -> #1 (&tty->write_wait){-.....}:
           [<8104a942>] lock_acquire+0x92/0x101
           [<8142f11d>] _raw_spin_lock_irqsave+0x2e/0x3e
           [<81046332>] __wake_up+0x15/0x3b
           [<811b8733>] tty_wakeup+0x49/0x51
           [<811c3568>] uart_write_wakeup+0x17/0x19
           [<811c5dc1>] serial8250_tx_chars+0xbc/0xfb
           [<811c5f28>] serial8250_handle_irq+0x54/0x6a
           [<811c5f57>] serial8250_default_handle_irq+0x19/0x1c
           [<811c56d8>] serial8250_interrupt+0x38/0x9e
           [<810510e7>] handle_irq_event_percpu+0x5f/0x1e2
           [<81051296>] handle_irq_event+0x2c/0x43
           [<81052cee>] handle_level_irq+0x57/0x80
           [<81002a72>] handle_irq+0x46/0x5c
           [<810027df>] do_IRQ+0x32/0x89
           [<8143036e>] common_interrupt+0x2e/0x33
           [<8142f23c>] _raw_spin_unlock_irqrestore+0x3f/0x49
           [<811c25a4>] uart_start+0x2d/0x32
           [<811c2c04>] uart_write+0xc7/0xd6
           [<811bc6f6>] n_tty_write+0xb8/0x35e
           [<811b9beb>] tty_write+0x163/0x1e4
           [<811b9cd9>] redirected_tty_write+0x6d/0x75
           [<810b6ed6>] vfs_write+0x75/0xb0
           [<810b7265>] SyS_write+0x44/0x77
           [<8142f8ee>] syscall_call+0x7/0xb
    
    -> #0 (&port_lock_key){-.....}:
           [<8104a62d>] __lock_acquire+0x9ea/0xc6d
           [<8104a942>] lock_acquire+0x92/0x101
           [<8142f11d>] _raw_spin_lock_irqsave+0x2e/0x3e
           [<811c60be>] serial8250_console_write+0x8c/0x10c
           [<8104e402>] call_console_drivers.constprop.31+0x87/0x118
           [<8104f5d5>] console_unlock+0x1d7/0x398
           [<8104fb70>] vprintk_emit+0x3da/0x3e4
           [<81425f76>] printk+0x17/0x19
           [<8105bfa0>] clockevents_program_min_delta+0x104/0x116
           [<8105c548>] clockevents_program_event+0xe7/0xf3
           [<8105cc1c>] tick_program_event+0x1e/0x23
           [<8103c43c>] hrtimer_force_reprogram+0x88/0x8f
           [<8103c49e>] __remove_hrtimer+0x5b/0x79
           [<8103cb21>] hrtimer_try_to_cancel+0x49/0x66
           [<8103cb4b>] hrtimer_cancel+0xd/0x18
           [<8107f102>] perf_swevent_cancel_hrtimer.part.60+0x2b/0x30
           [<81080705>] task_clock_event_stop+0x20/0x64
           [<81080756>] task_clock_event_del+0xd/0xf
           [<81081350>] event_sched_out+0xab/0x11e
           [<810813e0>] group_sched_out+0x1d/0x66
           [<81081682>] ctx_sched_out+0xaf/0xbf
           [<81081e04>] __perf_event_task_sched_out+0x1ed/0x34f
           [<8142cacc>] __schedule+0x4c6/0x4cb
           [<8142cae0>] schedule+0xf/0x11
           [<8142f9a6>] work_resched+0x5/0x30
    
    other info that might help us debug this:
    
    Chain exists of:
      &port_lock_key --> &ctx->lock --> hrtimer_bases.lock
    
     Possible unsafe locking scenario:
    
           CPU0                    CPU1
           ----                    ----
      lock(hrtimer_bases.lock);
                                   lock(&ctx->lock);
                                   lock(hrtimer_bases.lock);
      lock(&port_lock_key);
    
     *** DEADLOCK ***
    
    4 locks held by trinity-main/74:
     #0:  (&rq->lock){-.-.-.}, at: [<8142c6f3>] __schedule+0xed/0x4cb
     #1:  (&ctx->lock){......}, at: [<81081df3>] __perf_event_task_sched_out+0x1dc/0x34f
     #2:  (hrtimer_bases.lock){-.-...}, at: [<8103caeb>] hrtimer_try_to_cancel+0x13/0x66
     #3:  (console_lock){+.+...}, at: [<8104fb5d>] vprintk_emit+0x3c7/0x3e4
    
    stack backtrace:
    CPU: 0 PID: 74 Comm: trinity-main Not tainted 3.15.0-rc8-06195-g939f04b #2
     00000000 81c3a310 8b995c14 81426f69 8b995c44 81425a99 8161f671 8161f570
     8161f538 8161f559 8161f538 8b995c78 8b142bb0 00000004 8b142fdc 8b142bb0
     8b995ca8 8104a62d 8b142fac 000016f2 81c3a310 00000001 00000001 00000003
    Call Trace:
     [<81426f69>] dump_stack+0x16/0x18
     [<81425a99>] print_circular_bug+0x18f/0x19c
     [<8104a62d>] __lock_acquire+0x9ea/0xc6d
     [<8104a942>] lock_acquire+0x92/0x101
     [<811c60be>] ? serial8250_console_write+0x8c/0x10c
     [<811c6032>] ? wait_for_xmitr+0x76/0x76
     [<8142f11d>] _raw_spin_lock_irqsave+0x2e/0x3e
     [<811c60be>] ? serial8250_console_write+0x8c/0x10c
     [<811c60be>] serial8250_console_write+0x8c/0x10c
     [<8104af87>] ? lock_release+0x191/0x223
     [<811c6032>] ? wait_for_xmitr+0x76/0x76
     [<8104e402>] call_console_drivers.constprop.31+0x87/0x118
     [<8104f5d5>] console_unlock+0x1d7/0x398
     [<8104fb70>] vprintk_emit+0x3da/0x3e4
     [<81425f76>] printk+0x17/0x19
     [<8105bfa0>] clockevents_program_min_delta+0x104/0x116
     [<8105cc1c>] tick_program_event+0x1e/0x23
     [<8103c43c>] hrtimer_force_reprogram+0x88/0x8f
     [<8103c49e>] __remove_hrtimer+0x5b/0x79
     [<8103cb21>] hrtimer_try_to_cancel+0x49/0x66
     [<8103cb4b>] hrtimer_cancel+0xd/0x18
     [<8107f102>] perf_swevent_cancel_hrtimer.part.60+0x2b/0x30
     [<81080705>] task_clock_event_stop+0x20/0x64
     [<81080756>] task_clock_event_del+0xd/0xf
     [<81081350>] event_sched_out+0xab/0x11e
     [<810813e0>] group_sched_out+0x1d/0x66
     [<81081682>] ctx_sched_out+0xaf/0xbf
     [<81081e04>] __perf_event_task_sched_out+0x1ed/0x34f
     [<8104416d>] ? __dequeue_entity+0x23/0x27
     [<81044505>] ? pick_next_task_fair+0xb1/0x120
     [<8142cacc>] __schedule+0x4c6/0x4cb
     [<81047574>] ? trace_hardirqs_off_caller+0xd7/0x108
     [<810475b0>] ? trace_hardirqs_off+0xb/0xd
     [<81056346>] ? rcu_irq_exit+0x64/0x77
    
    Fix the problem by using printk_deferred() which does not call into the
    scheduler.
    
    Reported-by: Fengguang Wu <fengguang.wu@intel.com>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Cc: stable@vger.kernel.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index ad362c260ef4..9c94c19f1305 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -146,7 +146,8 @@ static int clockevents_increase_min_delta(struct clock_event_device *dev)
 {
 	/* Nothing to do if we already reached the limit */
 	if (dev->min_delta_ns >= MIN_DELTA_LIMIT) {
-		printk(KERN_WARNING "CE: Reprogramming failure. Giving up\n");
+		printk_deferred(KERN_WARNING
+				"CE: Reprogramming failure. Giving up\n");
 		dev->next_event.tv64 = KTIME_MAX;
 		return -ETIME;
 	}
@@ -159,9 +160,10 @@ static int clockevents_increase_min_delta(struct clock_event_device *dev)
 	if (dev->min_delta_ns > MIN_DELTA_LIMIT)
 		dev->min_delta_ns = MIN_DELTA_LIMIT;
 
-	printk(KERN_WARNING "CE: %s increased min_delta_ns to %llu nsec\n",
-	       dev->name ? dev->name : "?",
-	       (unsigned long long) dev->min_delta_ns);
+	printk_deferred(KERN_WARNING
+			"CE: %s increased min_delta_ns to %llu nsec\n",
+			dev->name ? dev->name : "?",
+			(unsigned long long) dev->min_delta_ns);
 	return 0;
 }
 

commit da7e6f45c34d39186b72328bacc4dd86bff60e0a
Author: Preeti U Murthy <preeti@linux.vnet.ibm.com>
Date:   Fri Feb 7 13:36:06 2014 +0530

    time: Change the return type of clockevents_notify() to integer
    
    The broadcast framework can potentially be made use of by archs which do not have an
    external clock device as well. Then, it is required that one of the CPUs need
    to handle the broadcasting of wakeup IPIs to the CPUs in deep idle. As a
    result its local timers should remain functional all the time. For such
    a CPU, the BROADCAST_ENTER notification has to fail indicating that its clock
    device cannot be shutdown. To make way for this support, change the return
    type of tick_broadcast_oneshot_control() and hence clockevents_notify() to
    indicate such scenarios.
    
    Signed-off-by: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Cc: deepthi@linux.vnet.ibm.com
    Cc: paulmck@linux.vnet.ibm.com
    Cc: fweisbec@gmail.com
    Cc: paulus@samba.org
    Cc: srivatsa.bhat@linux.vnet.ibm.com
    Cc: svaidy@linux.vnet.ibm.com
    Cc: peterz@infradead.org
    Cc: benh@kernel.crashing.org
    Cc: rafael.j.wysocki@intel.com
    Cc: linuxppc-dev@lists.ozlabs.org
    Link: http://lkml.kernel.org/r/20140207080606.17187.78306.stgit@preeti.in.ibm.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index f85e5fda9c66..ad362c260ef4 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -542,12 +542,13 @@ void clockevents_resume(void)
 #ifdef CONFIG_GENERIC_CLOCKEVENTS
 /**
  * clockevents_notify - notification about relevant events
+ * Returns 0 on success, any other value on error
  */
-void clockevents_notify(unsigned long reason, void *arg)
+int clockevents_notify(unsigned long reason, void *arg)
 {
 	struct clock_event_device *dev, *tmp;
 	unsigned long flags;
-	int cpu;
+	int cpu, ret = 0;
 
 	raw_spin_lock_irqsave(&clockevents_lock, flags);
 
@@ -560,7 +561,7 @@ void clockevents_notify(unsigned long reason, void *arg)
 
 	case CLOCK_EVT_NOTIFY_BROADCAST_ENTER:
 	case CLOCK_EVT_NOTIFY_BROADCAST_EXIT:
-		tick_broadcast_oneshot_control(reason);
+		ret = tick_broadcast_oneshot_control(reason);
 		break;
 
 	case CLOCK_EVT_NOTIFY_CPU_DYING:
@@ -603,6 +604,7 @@ void clockevents_notify(unsigned long reason, void *arg)
 		break;
 	}
 	raw_spin_unlock_irqrestore(&clockevents_lock, flags);
+	return ret;
 }
 EXPORT_SYMBOL_GPL(clockevents_notify);
 

commit fe79a9ba11962a603fb6af68fcb476e64031e46c
Author: Soren Brinkmann <soren.brinkmann@xilinx.com>
Date:   Mon Feb 3 14:34:32 2014 -0800

    clockevents: Adjust timer interval when frequency changes
    
    clockevent devices in periodic mode are not updated when the frequency
    of the device changes. Issue a dev->set_mode() callback which forces
    the device to reevaluate the timer settings.
    
    Signed-off-by: Soren Brinkmann <soren.brinkmann@xilinx.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Michal Simek <michal.simek@xilinx.com>
    Link: http://lkml.kernel.org/r/1391466877-28908-3-git-send-email-soren.brinkmann@xilinx.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 641d91003a45..f85e5fda9c66 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -443,10 +443,13 @@ int __clockevents_update_freq(struct clock_event_device *dev, u32 freq)
 {
 	clockevents_config(dev, freq);
 
-	if (dev->mode != CLOCK_EVT_MODE_ONESHOT)
-		return 0;
+	if (dev->mode == CLOCK_EVT_MODE_ONESHOT)
+		return clockevents_program_event(dev, dev->next_event, false);
+
+	if (dev->mode == CLOCK_EVT_MODE_PERIODIC)
+		dev->set_mode(CLOCK_EVT_MODE_PERIODIC, dev);
 
-	return clockevents_program_event(dev, dev->next_event, false);
+	return 0;
 }
 
 /**

commit 627ee7947e2e83ba565c31c5c9373d6e364b1ecd
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Feb 3 14:34:31 2014 -0800

    clockevents: Serialize calls to clockevents_update_freq() in the core
    
    We can identify the broadcast device in the core and serialize all
    callers including interrupts on a different CPU against the update.
    Also, disabling interrupts is moved into the core allowing callers to
    leave interrutps enabled when calling clockevents_update_freq().
    
    Signed-off-by: Soren Brinkmann <soren.brinkmann@xilinx.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: Soeren Brinkmann <soren.brinkmann@xilinx.com>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Michal Simek <michal.simek@xilinx.com>
    Link: http://lkml.kernel.org/r/1391466877-28908-2-git-send-email-soren.brinkmann@xilinx.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 086ad6043bcb..641d91003a45 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -439,6 +439,16 @@ void clockevents_config_and_register(struct clock_event_device *dev,
 }
 EXPORT_SYMBOL_GPL(clockevents_config_and_register);
 
+int __clockevents_update_freq(struct clock_event_device *dev, u32 freq)
+{
+	clockevents_config(dev, freq);
+
+	if (dev->mode != CLOCK_EVT_MODE_ONESHOT)
+		return 0;
+
+	return clockevents_program_event(dev, dev->next_event, false);
+}
+
 /**
  * clockevents_update_freq - Update frequency and reprogram a clock event device.
  * @dev:	device to modify
@@ -446,17 +456,22 @@ EXPORT_SYMBOL_GPL(clockevents_config_and_register);
  *
  * Reconfigure and reprogram a clock event device in oneshot
  * mode. Must be called on the cpu for which the device delivers per
- * cpu timer events with interrupts disabled!  Returns 0 on success,
- * -ETIME when the event is in the past.
+ * cpu timer events. If called for the broadcast device the core takes
+ * care of serialization.
+ *
+ * Returns 0 on success, -ETIME when the event is in the past.
  */
 int clockevents_update_freq(struct clock_event_device *dev, u32 freq)
 {
-	clockevents_config(dev, freq);
-
-	if (dev->mode != CLOCK_EVT_MODE_ONESHOT)
-		return 0;
+	unsigned long flags;
+	int ret;
 
-	return clockevents_program_event(dev, dev->next_event, false);
+	local_irq_save(flags);
+	ret = tick_broadcast_update_freq(dev, freq);
+	if (ret == -ENODEV)
+		ret = __clockevents_update_freq(dev, freq);
+	local_irq_restore(flags);
+	return ret;
 }
 
 /*

commit 87093826aa0172d9135ca1f301c4298a258ceee6
Merge: 39cf275a1a18 ee5872befc93
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 12 10:36:00 2013 +0900

    Merge branch 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull timer changes from Ingo Molnar:
     "Main changes in this cycle were:
    
       - Updated full dynticks support.
    
       - Event stream support for architected (ARM) timers.
    
       - ARM clocksource driver updates.
    
       - Move arm64 to using the generic sched_clock framework & resulting
         cleanup in the generic sched_clock code.
    
       - Misc fixes and cleanups"
    
    * 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (50 commits)
      x86/time: Honor ACPI FADT flag indicating absence of a CMOS RTC
      clocksource: sun4i: remove IRQF_DISABLED
      clocksource: sun4i: Report the minimum tick that we can program
      clocksource: sun4i: Select CLKSRC_MMIO
      clocksource: Provide timekeeping for efm32 SoCs
      clocksource: em_sti: convert to clk_prepare/unprepare
      time: Fix signedness bug in sysfs_get_uname() and its callers
      timekeeping: Fix some trivial typos in comments
      alarmtimer: return EINVAL instead of ENOTSUPP if rtcdev doesn't exist
      clocksource: arch_timer: Do not register arch_sys_counter twice
      timer stats: Add a 'Collection: active/inactive' line to timer usage statistics
      sched_clock: Remove sched_clock_func() hook
      arch_timer: Move to generic sched_clock framework
      clocksource: tcb_clksrc: Remove IRQF_DISABLED
      clocksource: tcb_clksrc: Improve driver robustness
      clocksource: tcb_clksrc: Replace clk_enable/disable with clk_prepare_enable/disable_unprepare
      clocksource: arm_arch_timer: Use clocksource for suspend timekeeping
      clocksource: dw_apb_timer_of: Mark a few more functions as __init
      clocksource: Put nodes passed to CLOCKSOURCE_OF_DECLARE callbacks centrally
      arm: zynq: Enable arm_global_timer
      ...

commit 97b9410643475d6557d2517c2aff9fd2221141a9
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Sep 24 21:50:23 2013 +0200

    clockevents: Sanitize ticks to nsec conversion
    
    Marc Kleine-Budde pointed out, that commit 77cc982 "clocksource: use
    clockevents_config_and_register() where possible" caused a regression
    for some of the converted subarchs.
    
    The reason is, that the clockevents core code converts the minimal
    hardware tick delta to a nanosecond value for core internal
    usage. This conversion is affected by integer math rounding loss, so
    the backwards conversion to hardware ticks will likely result in a
    value which is less than the configured hardware limitation. The
    affected subarchs used their own workaround (SIGH!) which got lost in
    the conversion.
    
    The solution for the issue at hand is simple: adding evt->mult - 1 to
    the shifted value before the integer divison in the core conversion
    function takes care of it. But this only works for the case where for
    the scaled math mult/shift pair "mult <= 1 << shift" is true. For the
    case where "mult > 1 << shift" we can apply the rounding add only for
    the minimum delta value to make sure that the backward conversion is
    not less than the given hardware limit. For the upper bound we need to
    omit the rounding add, because the backwards conversion is always
    larger than the original latch value. That would violate the upper
    bound of the hardware device.
    
    Though looking closer at the details of that function reveals another
    bogosity: The upper bounds check is broken as well. Checking for a
    resulting "clc" value greater than KTIME_MAX after the conversion is
    pointless. The conversion does:
    
          u64 clc = (latch << evt->shift) / evt->mult;
    
    So there is no sanity check for (latch << evt->shift) exceeding the
    64bit boundary. The latch argument is "unsigned long", so on a 64bit
    arch the handed in argument could easily lead to an unnoticed shift
    overflow. With the above rounding fix applied the calculation before
    the divison is:
    
           u64 clc = (latch << evt->shift) + evt->mult - 1;
    
    So we need to make sure, that neither the shift nor the rounding add
    is overflowing the u64 boundary.
    
    [ukl: move assignment to rnd after eventually changing mult, fix build
     issue and correct comment with the right math]
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Russell King - ARM Linux <linux@arm.linux.org.uk>
    Cc: Marc Kleine-Budde <mkl@pengutronix.de>
    Cc: nicolas.ferre@atmel.com
    Cc: Marc Pignat <marc.pignat@hevs.ch>
    Cc: john.stultz@linaro.org
    Cc: kernel@pengutronix.de
    Cc: Ronald Wahl <ronald.wahl@raritan.com>
    Cc: LAK <linux-arm-kernel@lists.infradead.org>
    Cc: Ludovic Desroches <ludovic.desroches@atmel.com>
    Cc: stable@vger.kernel.org
    Link: http://lkml.kernel.org/r/1380052223-24139-1-git-send-email-u.kleine-koenig@pengutronix.de
    Signed-off-by: Uwe Kleine-Knig <u.kleine-koenig@pengutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 38959c866789..662c5798a685 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -33,29 +33,64 @@ struct ce_unbind {
 	int res;
 };
 
-/**
- * clockevents_delta2ns - Convert a latch value (device ticks) to nanoseconds
- * @latch:	value to convert
- * @evt:	pointer to clock event device descriptor
- *
- * Math helper, returns latch value converted to nanoseconds (bound checked)
- */
-u64 clockevent_delta2ns(unsigned long latch, struct clock_event_device *evt)
+static u64 cev_delta2ns(unsigned long latch, struct clock_event_device *evt,
+			bool ismax)
 {
 	u64 clc = (u64) latch << evt->shift;
+	u64 rnd;
 
 	if (unlikely(!evt->mult)) {
 		evt->mult = 1;
 		WARN_ON(1);
 	}
+	rnd = (u64) evt->mult - 1;
+
+	/*
+	 * Upper bound sanity check. If the backwards conversion is
+	 * not equal latch, we know that the above shift overflowed.
+	 */
+	if ((clc >> evt->shift) != (u64)latch)
+		clc = ~0ULL;
+
+	/*
+	 * Scaled math oddities:
+	 *
+	 * For mult <= (1 << shift) we can safely add mult - 1 to
+	 * prevent integer rounding loss. So the backwards conversion
+	 * from nsec to device ticks will be correct.
+	 *
+	 * For mult > (1 << shift), i.e. device frequency is > 1GHz we
+	 * need to be careful. Adding mult - 1 will result in a value
+	 * which when converted back to device ticks can be larger
+	 * than latch by up to (mult - 1) >> shift. For the min_delta
+	 * calculation we still want to apply this in order to stay
+	 * above the minimum device ticks limit. For the upper limit
+	 * we would end up with a latch value larger than the upper
+	 * limit of the device, so we omit the add to stay below the
+	 * device upper boundary.
+	 *
+	 * Also omit the add if it would overflow the u64 boundary.
+	 */
+	if ((~0ULL - clc > rnd) &&
+	    (!ismax || evt->mult <= (1U << evt->shift)))
+		clc += rnd;
 
 	do_div(clc, evt->mult);
-	if (clc < 1000)
-		clc = 1000;
-	if (clc > KTIME_MAX)
-		clc = KTIME_MAX;
 
-	return clc;
+	/* Deltas less than 1usec are pointless noise */
+	return clc > 1000 ? clc : 1000;
+}
+
+/**
+ * clockevents_delta2ns - Convert a latch value (device ticks) to nanoseconds
+ * @latch:	value to convert
+ * @evt:	pointer to clock event device descriptor
+ *
+ * Math helper, returns latch value converted to nanoseconds (bound checked)
+ */
+u64 clockevent_delta2ns(unsigned long latch, struct clock_event_device *evt)
+{
+	return cev_delta2ns(latch, evt, false);
 }
 EXPORT_SYMBOL_GPL(clockevent_delta2ns);
 
@@ -380,8 +415,8 @@ void clockevents_config(struct clock_event_device *dev, u32 freq)
 		sec = 600;
 
 	clockevents_calc_mult_shift(dev, freq, sec);
-	dev->min_delta_ns = clockevent_delta2ns(dev->min_delta_ticks, dev);
-	dev->max_delta_ns = clockevent_delta2ns(dev->max_delta_ticks, dev);
+	dev->min_delta_ns = cev_delta2ns(dev->min_delta_ticks, dev, false);
+	dev->max_delta_ns = cev_delta2ns(dev->max_delta_ticks, dev, true);
 }
 
 /**

commit 891292a767c2453af0e5be9465e95b06b4b29ebe
Author: Patrick Palka <patrick@parcs.ath.cx>
Date:   Fri Oct 11 13:11:55 2013 -0400

    time: Fix signedness bug in sysfs_get_uname() and its callers
    
    sysfs_get_uname() is erroneously declared as returning size_t even
    though it may return a negative value, specifically -EINVAL.  Its
    callers then check whether its return value is less than zero and indeed
    that is never the case for size_t.
    
    This patch changes sysfs_get_uname() to return ssize_t and makes sure
    its callers use ssize_t accordingly.
    
    Signed-off-by: Patrick Palka <patrick@parcs.ath.cx>
    [jstultz: Didn't apply cleanly, as a similar partial fix was also applied
    so had to resolve the collisions]
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 38959c866789..30554b9fb1f7 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -584,7 +584,7 @@ static ssize_t sysfs_unbind_tick_dev(struct device *dev,
 				     const char *buf, size_t count)
 {
 	char name[CS_NAME_LEN];
-	size_t ret = sysfs_get_uname(buf, name, count);
+	ssize_t ret = sysfs_get_uname(buf, name, count);
 	struct clock_event_device *ce;
 
 	if (ret < 0)

commit 03e13cf5ee60584fe0c831682c67212effb7fca4
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Apr 25 20:31:50 2013 +0000

    clockevents: Implement unbind functionality
    
    Provide a sysfs interface to allow unbinding of clockevent
    devices. The device is unbound if it is unused or if there is a
    replacement device available. Unbinding of broadcast devices is not
    supported as we don't want to foster that nonsense. If no replacement
    device is available the unbind returns -EBUSY. Unbind is available
    from the kernel and through sysfs, which is necessary to drop the
    module refcount.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: Magnus Damm <magnus.damm@gmail.com>
    Link: http://lkml.kernel.org/r/20130425143436.499216659@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 0a23f4f29934..38959c866789 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -25,6 +25,13 @@ static LIST_HEAD(clockevent_devices);
 static LIST_HEAD(clockevents_released);
 /* Protection for the above */
 static DEFINE_RAW_SPINLOCK(clockevents_lock);
+/* Protection for unbind operations */
+static DEFINE_MUTEX(clockevents_mutex);
+
+struct ce_unbind {
+	struct clock_event_device *ce;
+	int res;
+};
 
 /**
  * clockevents_delta2ns - Convert a latch value (device ticks) to nanoseconds
@@ -245,6 +252,90 @@ static void clockevents_notify_released(void)
 	}
 }
 
+/*
+ * Try to install a replacement clock event device
+ */
+static int clockevents_replace(struct clock_event_device *ced)
+{
+	struct clock_event_device *dev, *newdev = NULL;
+
+	list_for_each_entry(dev, &clockevent_devices, list) {
+		if (dev == ced || dev->mode != CLOCK_EVT_MODE_UNUSED)
+			continue;
+
+		if (!tick_check_replacement(newdev, dev))
+			continue;
+
+		if (!try_module_get(dev->owner))
+			continue;
+
+		if (newdev)
+			module_put(newdev->owner);
+		newdev = dev;
+	}
+	if (newdev) {
+		tick_install_replacement(newdev);
+		list_del_init(&ced->list);
+	}
+	return newdev ? 0 : -EBUSY;
+}
+
+/*
+ * Called with clockevents_mutex and clockevents_lock held
+ */
+static int __clockevents_try_unbind(struct clock_event_device *ced, int cpu)
+{
+	/* Fast track. Device is unused */
+	if (ced->mode == CLOCK_EVT_MODE_UNUSED) {
+		list_del_init(&ced->list);
+		return 0;
+	}
+
+	return ced == per_cpu(tick_cpu_device, cpu).evtdev ? -EAGAIN : -EBUSY;
+}
+
+/*
+ * SMP function call to unbind a device
+ */
+static void __clockevents_unbind(void *arg)
+{
+	struct ce_unbind *cu = arg;
+	int res;
+
+	raw_spin_lock(&clockevents_lock);
+	res = __clockevents_try_unbind(cu->ce, smp_processor_id());
+	if (res == -EAGAIN)
+		res = clockevents_replace(cu->ce);
+	cu->res = res;
+	raw_spin_unlock(&clockevents_lock);
+}
+
+/*
+ * Issues smp function call to unbind a per cpu device. Called with
+ * clockevents_mutex held.
+ */
+static int clockevents_unbind(struct clock_event_device *ced, int cpu)
+{
+	struct ce_unbind cu = { .ce = ced, .res = -ENODEV };
+
+	smp_call_function_single(cpu, __clockevents_unbind, &cu, 1);
+	return cu.res;
+}
+
+/*
+ * Unbind a clockevents device.
+ */
+int clockevents_unbind_device(struct clock_event_device *ced, int cpu)
+{
+	int ret;
+
+	mutex_lock(&clockevents_mutex);
+	ret = clockevents_unbind(ced, cpu);
+	mutex_unlock(&clockevents_mutex);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(clockevents_unbind);
+
 /**
  * clockevents_register_device - register a clock event device
  * @dev:	device to register
@@ -487,6 +578,38 @@ static ssize_t sysfs_show_current_tick_dev(struct device *dev,
 }
 static DEVICE_ATTR(current_device, 0444, sysfs_show_current_tick_dev, NULL);
 
+/* We don't support the abomination of removable broadcast devices */
+static ssize_t sysfs_unbind_tick_dev(struct device *dev,
+				     struct device_attribute *attr,
+				     const char *buf, size_t count)
+{
+	char name[CS_NAME_LEN];
+	size_t ret = sysfs_get_uname(buf, name, count);
+	struct clock_event_device *ce;
+
+	if (ret < 0)
+		return ret;
+
+	ret = -ENODEV;
+	mutex_lock(&clockevents_mutex);
+	raw_spin_lock_irq(&clockevents_lock);
+	list_for_each_entry(ce, &clockevent_devices, list) {
+		if (!strcmp(ce->name, name)) {
+			ret = __clockevents_try_unbind(ce, dev->id);
+			break;
+		}
+	}
+	raw_spin_unlock_irq(&clockevents_lock);
+	/*
+	 * We hold clockevents_mutex, so ce can't go away
+	 */
+	if (ret == -EAGAIN)
+		ret = clockevents_unbind(ce, dev->id);
+	mutex_unlock(&clockevents_mutex);
+	return ret ? ret : count;
+}
+static DEVICE_ATTR(unbind_device, 0200, NULL, sysfs_unbind_tick_dev);
+
 #ifdef CONFIG_GENERIC_CLOCKEVENTS_BROADCAST
 static struct device tick_bc_dev = {
 	.init_name	= "broadcast",
@@ -529,6 +652,8 @@ static int __init tick_init_sysfs(void)
 		err = device_register(dev);
 		if (!err)
 			err = device_create_file(dev, &dev_attr_current_device);
+		if (!err)
+			err = device_create_file(dev, &dev_attr_unbind_device);
 		if (err)
 			return err;
 	}

commit 501f867064e95f9a6f540e60705be0937280e7ec
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Apr 25 20:31:49 2013 +0000

    clockevents: Provide sysfs interface
    
    Provide a simple sysfs interface for the clockevent devices. Show the
    current active clockevent device.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: Magnus Damm <magnus.damm@gmail.com>
    Link: http://lkml.kernel.org/r/20130425143436.371634778@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 89e394caa769..0a23f4f29934 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -16,6 +16,7 @@
 #include <linux/init.h>
 #include <linux/module.h>
 #include <linux/smp.h>
+#include <linux/device.h>
 
 #include "tick-internal.h"
 
@@ -460,4 +461,89 @@ void clockevents_notify(unsigned long reason, void *arg)
 	raw_spin_unlock_irqrestore(&clockevents_lock, flags);
 }
 EXPORT_SYMBOL_GPL(clockevents_notify);
+
+#ifdef CONFIG_SYSFS
+struct bus_type clockevents_subsys = {
+	.name		= "clockevents",
+	.dev_name       = "clockevent",
+};
+
+static DEFINE_PER_CPU(struct device, tick_percpu_dev);
+static struct tick_device *tick_get_tick_dev(struct device *dev);
+
+static ssize_t sysfs_show_current_tick_dev(struct device *dev,
+					   struct device_attribute *attr,
+					   char *buf)
+{
+	struct tick_device *td;
+	ssize_t count = 0;
+
+	raw_spin_lock_irq(&clockevents_lock);
+	td = tick_get_tick_dev(dev);
+	if (td && td->evtdev)
+		count = snprintf(buf, PAGE_SIZE, "%s\n", td->evtdev->name);
+	raw_spin_unlock_irq(&clockevents_lock);
+	return count;
+}
+static DEVICE_ATTR(current_device, 0444, sysfs_show_current_tick_dev, NULL);
+
+#ifdef CONFIG_GENERIC_CLOCKEVENTS_BROADCAST
+static struct device tick_bc_dev = {
+	.init_name	= "broadcast",
+	.id		= 0,
+	.bus		= &clockevents_subsys,
+};
+
+static struct tick_device *tick_get_tick_dev(struct device *dev)
+{
+	return dev == &tick_bc_dev ? tick_get_broadcast_device() :
+		&per_cpu(tick_cpu_device, dev->id);
+}
+
+static __init int tick_broadcast_init_sysfs(void)
+{
+	int err = device_register(&tick_bc_dev);
+
+	if (!err)
+		err = device_create_file(&tick_bc_dev, &dev_attr_current_device);
+	return err;
+}
+#else
+static struct tick_device *tick_get_tick_dev(struct device *dev)
+{
+	return &per_cpu(tick_cpu_device, dev->id);
+}
+static inline int tick_broadcast_init_sysfs(void) { return 0; }
 #endif
+
+static int __init tick_init_sysfs(void)
+{
+	int cpu;
+
+	for_each_possible_cpu(cpu) {
+		struct device *dev = &per_cpu(tick_percpu_dev, cpu);
+		int err;
+
+		dev->id = cpu;
+		dev->bus = &clockevents_subsys;
+		err = device_register(dev);
+		if (!err)
+			err = device_create_file(dev, &dev_attr_current_device);
+		if (err)
+			return err;
+	}
+	return tick_broadcast_init_sysfs();
+}
+
+static int __init clockevents_init_sysfs(void)
+{
+	int err = subsys_system_register(&clockevents_subsys, NULL);
+
+	if (!err)
+		err = tick_init_sysfs();
+	return err;
+}
+device_initcall(clockevents_init_sysfs);
+#endif /* SYSFS */
+
+#endif /* GENERIC_CLOCK_EVENTS */

commit ccf33d6880f39a35158fff66db13000ae4943fac
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Apr 25 20:31:49 2013 +0000

    clockevents: Add module refcount
    
    We want to be able to remove clockevent modules as well. Add a
    refcount so we don't remove a module with an active clock event
    device.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: Magnus Damm <magnus.damm@gmail.com>
    Link: http://lkml.kernel.org/r/20130425143436.307435149@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 0e3a8448e115..89e394caa769 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -357,6 +357,7 @@ void clockevents_exchange_device(struct clock_event_device *old,
 	 * released list and do a notify add later.
 	 */
 	if (old) {
+		module_put(old->owner);
 		clockevents_set_mode(old, CLOCK_EVT_MODE_UNUSED);
 		list_del(&old->list);
 		list_add(&old->list, &clockevents_released);

commit 8c53daf63f56791ed47fc585206ef3049489612f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Apr 25 20:31:48 2013 +0000

    clockevents: Move the tick_notify() switch case to clockevents_notify()
    
    No need to call another function and have duplicated cases.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: Magnus Damm <magnus.damm@gmail.com>
    Link: http://lkml.kernel.org/r/20130425143436.235746557@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index dd70b4842c62..0e3a8448e115 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -404,10 +404,36 @@ void clockevents_notify(unsigned long reason, void *arg)
 	int cpu;
 
 	raw_spin_lock_irqsave(&clockevents_lock, flags);
-	tick_notify(reason, arg);
 
 	switch (reason) {
+	case CLOCK_EVT_NOTIFY_BROADCAST_ON:
+	case CLOCK_EVT_NOTIFY_BROADCAST_OFF:
+	case CLOCK_EVT_NOTIFY_BROADCAST_FORCE:
+		tick_broadcast_on_off(reason, arg);
+		break;
+
+	case CLOCK_EVT_NOTIFY_BROADCAST_ENTER:
+	case CLOCK_EVT_NOTIFY_BROADCAST_EXIT:
+		tick_broadcast_oneshot_control(reason);
+		break;
+
+	case CLOCK_EVT_NOTIFY_CPU_DYING:
+		tick_handover_do_timer(arg);
+		break;
+
+	case CLOCK_EVT_NOTIFY_SUSPEND:
+		tick_suspend();
+		tick_suspend_broadcast();
+		break;
+
+	case CLOCK_EVT_NOTIFY_RESUME:
+		tick_resume();
+		break;
+
 	case CLOCK_EVT_NOTIFY_CPU_DEAD:
+		tick_shutdown_broadcast_oneshot(arg);
+		tick_shutdown_broadcast(arg);
+		tick_shutdown(arg);
 		/*
 		 * Unregister the clock event devices which were
 		 * released from the users in the notify chain.

commit 7172a286ced0c1f4f239a0fa09db54ed37d3ead2
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Apr 25 20:31:47 2013 +0000

    clockevents: Get rid of the notifier chain
    
    7+ years and still a single user. Kill it.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: Magnus Damm <magnus.damm@gmail.com>
    Link: http://lkml.kernel.org/r/20130425143436.098520211@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index c6d6400ee137..dd70b4842c62 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -15,7 +15,6 @@
 #include <linux/hrtimer.h>
 #include <linux/init.h>
 #include <linux/module.h>
-#include <linux/notifier.h>
 #include <linux/smp.h>
 
 #include "tick-internal.h"
@@ -23,10 +22,6 @@
 /* The registered clock event devices */
 static LIST_HEAD(clockevent_devices);
 static LIST_HEAD(clockevents_released);
-
-/* Notification for clock events */
-static RAW_NOTIFIER_HEAD(clockevents_chain);
-
 /* Protection for the above */
 static DEFINE_RAW_SPINLOCK(clockevents_lock);
 
@@ -232,30 +227,6 @@ int clockevents_program_event(struct clock_event_device *dev, ktime_t expires,
 	return (rc && force) ? clockevents_program_min_delta(dev) : rc;
 }
 
-/**
- * clockevents_register_notifier - register a clock events change listener
- */
-int clockevents_register_notifier(struct notifier_block *nb)
-{
-	unsigned long flags;
-	int ret;
-
-	raw_spin_lock_irqsave(&clockevents_lock, flags);
-	ret = raw_notifier_chain_register(&clockevents_chain, nb);
-	raw_spin_unlock_irqrestore(&clockevents_lock, flags);
-
-	return ret;
-}
-
-/*
- * Notify about a clock event change. Called with clockevents_lock
- * held.
- */
-static void clockevents_do_notify(unsigned long reason, void *dev)
-{
-	raw_notifier_call_chain(&clockevents_chain, reason, dev);
-}
-
 /*
  * Called after a notify add to make devices available which were
  * released from the notifier call.
@@ -269,7 +240,7 @@ static void clockevents_notify_released(void)
 				 struct clock_event_device, list);
 		list_del(&dev->list);
 		list_add(&dev->list, &clockevent_devices);
-		clockevents_do_notify(CLOCK_EVT_NOTIFY_ADD, dev);
+		tick_check_new_device(dev);
 	}
 }
 
@@ -290,7 +261,7 @@ void clockevents_register_device(struct clock_event_device *dev)
 	raw_spin_lock_irqsave(&clockevents_lock, flags);
 
 	list_add(&dev->list, &clockevent_devices);
-	clockevents_do_notify(CLOCK_EVT_NOTIFY_ADD, dev);
+	tick_check_new_device(dev);
 	clockevents_notify_released();
 
 	raw_spin_unlock_irqrestore(&clockevents_lock, flags);
@@ -433,7 +404,7 @@ void clockevents_notify(unsigned long reason, void *arg)
 	int cpu;
 
 	raw_spin_lock_irqsave(&clockevents_lock, flags);
-	clockevents_do_notify(reason, arg);
+	tick_notify(reason, arg);
 
 	switch (reason) {
 	case CLOCK_EVT_NOTIFY_CPU_DEAD:

commit c35ef95c273c06471818f9245a05ac5a6e3ffa34
Author: Shawn Guo <shawn.guo@linaro.org>
Date:   Sat Jan 12 11:50:04 2013 +0000

    clockevents: export clockevents_config_and_register for module use
    
    clockevents_config_and_register is a handy helper for clockevent
    drivers, some of which might support module build, so export the symbol.
    
    Signed-off-by: Shawn Guo <shawn.guo@linaro.org>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Olof Johansson <olof@lixom.net>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 30b6de0d977c..c6d6400ee137 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -339,6 +339,7 @@ void clockevents_config_and_register(struct clock_event_device *dev,
 	clockevents_config(dev, freq);
 	clockevents_register_device(dev);
 }
+EXPORT_SYMBOL_GPL(clockevents_config_and_register);
 
 /**
  * clockevents_update_freq - Update frequency and reprogram a clock event device.

commit adc78e6b9946a4b22e22403d961f3b03c469e5d3
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Mon Aug 6 01:40:41 2012 +0200

    timekeeping: Add suspend and resume of clock event devices
    
    Some clock event devices, for example such that belong to PM domains,
    need to be handled in a spcial way during the timekeeping suspend
    and resume (which takes place in the system core, or "syscore",
    stages of system power transitions) in analogy with clock sources.
    
    Introduce .suspend() and .resume() callbacks for clock event devices
    that will be executed by timekeeping_suspend/_resume(), respectively,
    next the the clock sources' .suspend() and .resume() callbacks.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 7e1ce012a851..30b6de0d977c 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -397,6 +397,30 @@ void clockevents_exchange_device(struct clock_event_device *old,
 	local_irq_restore(flags);
 }
 
+/**
+ * clockevents_suspend - suspend clock devices
+ */
+void clockevents_suspend(void)
+{
+	struct clock_event_device *dev;
+
+	list_for_each_entry_reverse(dev, &clockevent_devices, list)
+		if (dev->suspend)
+			dev->suspend(dev);
+}
+
+/**
+ * clockevents_resume - resume clock devices
+ */
+void clockevents_resume(void)
+{
+	struct clock_event_device *dev;
+
+	list_for_each_entry(dev, &clockevent_devices, list)
+		if (dev->resume)
+			dev->resume(dev);
+}
+
 #ifdef CONFIG_GENERIC_CLOCKEVENTS
 /**
  * clockevents_notify - notification about relevant events

commit e5400321a6f15ce0fe77c8455954f213ef7dcc54
Author: Magnus Damm <magnus.damm@gmail.com>
Date:   Wed May 9 23:39:34 2012 +0900

    clockevents: Make clockevents_config() a global symbol
    
    Make clockevents_config() into a global symbol to allow it to be used
    by compiled-in clockevent drivers. This is needed by drivers that want
    to update the timer frequency after registration time.
    
    Signed-off-by: Magnus Damm <damm@opensource.se>
    Tested-by: Simon Horman <horms@verge.net.au>
    Cc: arnd@arndb.de
    Cc: johnstul@us.ibm.com
    Cc: rjw@sisk.pl
    Cc: lethal@linux-sh.org
    Cc: gregkh@linuxfoundation.org
    Cc: olof@lixom.net
    Cc: Magnus Damm <magnus.damm@gmail.com>
    Link: http://lkml.kernel.org/r/20120509143934.27521.46553.sendpatchset@w520
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 9cd928f7a7c6..7e1ce012a851 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -297,8 +297,7 @@ void clockevents_register_device(struct clock_event_device *dev)
 }
 EXPORT_SYMBOL_GPL(clockevents_register_device);
 
-static void clockevents_config(struct clock_event_device *dev,
-			       u32 freq)
+void clockevents_config(struct clock_event_device *dev, u32 freq)
 {
 	u64 sec;
 

commit 7239f65cf364180cdb100a4ed211b2a9f9a72119
Author: Kay Sievers <kay.sievers@vrfy.org>
Date:   Wed Dec 21 16:12:37 2011 -0800

    clockevents: remove sysdev.h
    
    This isn't needed in the clockevents.c file, and the header file is
    going away soon, so just remove the #include
    
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Kay Sievers <kay.sievers@vrfy.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 1ecd6ba36d6c..9cd928f7a7c6 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -17,7 +17,6 @@
 #include <linux/module.h>
 #include <linux/notifier.h>
 #include <linux/smp.h>
-#include <linux/sysdev.h>
 
 #include "tick-internal.h"
 

commit 65516f8a7c2028381f0dae4c16ddb621c96158cc
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Aug 23 15:29:43 2011 +0200

    clockevents: Add direct ktime programming function
    
    There is at least one architecture (s390) with a sane clockevent device
    that can be programmed with the equivalent of a ktime. No need to create
    a delta against the current time, the ktime can be used directly.
    
    A new clock device function 'set_next_ktime' is introduced that is called
    with the unmodified ktime for the timer if the clock event device has the
    CLOCK_EVT_FEAT_KTIME bit set.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: john stultz <johnstul@us.ibm.com>
    Link: http://lkml.kernel.org/r/20110823133142.815350967@de.ibm.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 713ef94eceef..1ecd6ba36d6c 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -216,6 +216,10 @@ int clockevents_program_event(struct clock_event_device *dev, ktime_t expires,
 	if (dev->mode == CLOCK_EVT_MODE_SHUTDOWN)
 		return 0;
 
+	/* Shortcut for clockevent devices that can deal with ktime. */
+	if (dev->features & CLOCK_EVT_FEAT_KTIME)
+		return dev->set_next_ktime(expires, dev);
+
 	delta = ktime_to_ns(ktime_sub(expires, ktime_get()));
 	if (delta <= 0)
 		return force ? clockevents_program_min_delta(dev) : -ETIME;

commit d1748302f70be7469809809283fe164156a34231
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Aug 23 15:29:42 2011 +0200

    clockevents: Make minimum delay adjustments configurable
    
    The automatic increase of the min_delta_ns of a clockevents device
    should be done in the clockevents code as the minimum delay is an
    attribute of the clockevents device.
    
    In addition not all architectures want the automatic adjustment, on a
    massively virtualized system it can happen that the programming of a
    clock event fails several times in a row because the virtual cpu has
    been rescheduled quickly enough. In that case the minimum delay will
    erroneously be increased with no way back. The new config symbol
    GENERIC_CLOCKEVENTS_MIN_ADJUST is used to enable the automatic
    adjustment. The config option is selected only for x86.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: john stultz <johnstul@us.ibm.com>
    Link: http://lkml.kernel.org/r/20110823133142.494157493@de.ibm.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index e4c699dfa4e8..713ef94eceef 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -94,42 +94,139 @@ void clockevents_shutdown(struct clock_event_device *dev)
 	dev->next_event.tv64 = KTIME_MAX;
 }
 
+#ifdef CONFIG_GENERIC_CLOCKEVENTS_MIN_ADJUST
+
+/* Limit min_delta to a jiffie */
+#define MIN_DELTA_LIMIT		(NSEC_PER_SEC / HZ)
+
+/**
+ * clockevents_increase_min_delta - raise minimum delta of a clock event device
+ * @dev:       device to increase the minimum delta
+ *
+ * Returns 0 on success, -ETIME when the minimum delta reached the limit.
+ */
+static int clockevents_increase_min_delta(struct clock_event_device *dev)
+{
+	/* Nothing to do if we already reached the limit */
+	if (dev->min_delta_ns >= MIN_DELTA_LIMIT) {
+		printk(KERN_WARNING "CE: Reprogramming failure. Giving up\n");
+		dev->next_event.tv64 = KTIME_MAX;
+		return -ETIME;
+	}
+
+	if (dev->min_delta_ns < 5000)
+		dev->min_delta_ns = 5000;
+	else
+		dev->min_delta_ns += dev->min_delta_ns >> 1;
+
+	if (dev->min_delta_ns > MIN_DELTA_LIMIT)
+		dev->min_delta_ns = MIN_DELTA_LIMIT;
+
+	printk(KERN_WARNING "CE: %s increased min_delta_ns to %llu nsec\n",
+	       dev->name ? dev->name : "?",
+	       (unsigned long long) dev->min_delta_ns);
+	return 0;
+}
+
+/**
+ * clockevents_program_min_delta - Set clock event device to the minimum delay.
+ * @dev:	device to program
+ *
+ * Returns 0 on success, -ETIME when the retry loop failed.
+ */
+static int clockevents_program_min_delta(struct clock_event_device *dev)
+{
+	unsigned long long clc;
+	int64_t delta;
+	int i;
+
+	for (i = 0;;) {
+		delta = dev->min_delta_ns;
+		dev->next_event = ktime_add_ns(ktime_get(), delta);
+
+		if (dev->mode == CLOCK_EVT_MODE_SHUTDOWN)
+			return 0;
+
+		dev->retries++;
+		clc = ((unsigned long long) delta * dev->mult) >> dev->shift;
+		if (dev->set_next_event((unsigned long) clc, dev) == 0)
+			return 0;
+
+		if (++i > 2) {
+			/*
+			 * We tried 3 times to program the device with the
+			 * given min_delta_ns. Try to increase the minimum
+			 * delta, if that fails as well get out of here.
+			 */
+			if (clockevents_increase_min_delta(dev))
+				return -ETIME;
+			i = 0;
+		}
+	}
+}
+
+#else  /* CONFIG_GENERIC_CLOCKEVENTS_MIN_ADJUST */
+
+/**
+ * clockevents_program_min_delta - Set clock event device to the minimum delay.
+ * @dev:	device to program
+ *
+ * Returns 0 on success, -ETIME when the retry loop failed.
+ */
+static int clockevents_program_min_delta(struct clock_event_device *dev)
+{
+	unsigned long long clc;
+	int64_t delta;
+
+	delta = dev->min_delta_ns;
+	dev->next_event = ktime_add_ns(ktime_get(), delta);
+
+	if (dev->mode == CLOCK_EVT_MODE_SHUTDOWN)
+		return 0;
+
+	dev->retries++;
+	clc = ((unsigned long long) delta * dev->mult) >> dev->shift;
+	return dev->set_next_event((unsigned long) clc, dev);
+}
+
+#endif /* CONFIG_GENERIC_CLOCKEVENTS_MIN_ADJUST */
+
 /**
  * clockevents_program_event - Reprogram the clock event device.
+ * @dev:	device to program
  * @expires:	absolute expiry time (monotonic clock)
+ * @force:	program minimum delay if expires can not be set
  *
  * Returns 0 on success, -ETIME when the event is in the past.
  */
 int clockevents_program_event(struct clock_event_device *dev, ktime_t expires,
-			      ktime_t now)
+			      bool force)
 {
 	unsigned long long clc;
 	int64_t delta;
+	int rc;
 
 	if (unlikely(expires.tv64 < 0)) {
 		WARN_ON_ONCE(1);
 		return -ETIME;
 	}
 
-	delta = ktime_to_ns(ktime_sub(expires, now));
-
-	if (delta <= 0)
-		return -ETIME;
-
 	dev->next_event = expires;
 
 	if (dev->mode == CLOCK_EVT_MODE_SHUTDOWN)
 		return 0;
 
-	if (delta > dev->max_delta_ns)
-		delta = dev->max_delta_ns;
-	if (delta < dev->min_delta_ns)
-		delta = dev->min_delta_ns;
+	delta = ktime_to_ns(ktime_sub(expires, ktime_get()));
+	if (delta <= 0)
+		return force ? clockevents_program_min_delta(dev) : -ETIME;
 
-	clc = delta * dev->mult;
-	clc >>= dev->shift;
+	delta = min(delta, (int64_t) dev->max_delta_ns);
+	delta = max(delta, (int64_t) dev->min_delta_ns);
 
-	return dev->set_next_event((unsigned long) clc, dev);
+	clc = ((unsigned long long) delta * dev->mult) >> dev->shift;
+	rc = dev->set_next_event((unsigned long) clc, dev);
+
+	return (rc && force) ? clockevents_program_min_delta(dev) : rc;
 }
 
 /**
@@ -258,7 +355,7 @@ int clockevents_update_freq(struct clock_event_device *dev, u32 freq)
 	if (dev->mode != CLOCK_EVT_MODE_ONESHOT)
 		return 0;
 
-	return clockevents_program_event(dev, dev->next_event, ktime_get());
+	return clockevents_program_event(dev, dev->next_event, false);
 }
 
 /*

commit 1b054b67d3bfc6dca9f634c104780f3f24ff3eec
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jun 3 11:13:33 2011 +0200

    clockevents: Handle empty cpumask gracefully
    
    For UP it's stupid to request an initialized cpumask for the clock
    event devices. Though we need the mask set even on UP to avoid a
    horrible ifdeffery especially in the broadcast code.
    
    For SMP we can at least try to survive with a warning and set the
    cpumask of the cpu we're running on. That gives a decent chance to
    bring the machine up and retrieve the debug info.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Linus Walleij <linus.walleij@linaro.org
    Cc: Lee Jones <lee.jones@linaro.org>
    Cc: Russell King - ARM Linux <linux@arm.linux.org.uk>
    Cc: Stephen Boyd <sboyd@codeaurora.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index c027d4f602f1..e4c699dfa4e8 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -182,7 +182,10 @@ void clockevents_register_device(struct clock_event_device *dev)
 	unsigned long flags;
 
 	BUG_ON(dev->mode != CLOCK_EVT_MODE_UNUSED);
-	BUG_ON(!dev->cpumask);
+	if (!dev->cpumask) {
+		WARN_ON(num_possible_cpus() > 1);
+		dev->cpumask = cpumask_of(smp_processor_id());
+	}
 
 	raw_spin_lock_irqsave(&clockevents_lock, flags);
 

commit c0e299b1a91cbdb21ae08e382a4176200398bc36
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri May 20 10:50:52 2011 +0200

    clockevents/source: Use u64 to make 32bit happy
    
    unsigned long is not 64bit on 32bit machine.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 22a9da9a9c96..c027d4f602f1 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -197,7 +197,7 @@ EXPORT_SYMBOL_GPL(clockevents_register_device);
 static void clockevents_config(struct clock_event_device *dev,
 			       u32 freq)
 {
-	unsigned long sec;
+	u64 sec;
 
 	if (!(dev->features & CLOCK_EVT_FEAT_ONESHOT))
 		return;

commit 80b816b736cfa5b9582279127099b20a479ab7d9
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed May 18 21:33:42 2011 +0000

    clockevents: Provide interface to reconfigure an active clock event device
    
    Some ARM SoCs have clock event devices which have their frequency
    modified due to frequency scaling. Provide an interface which allows
    to reconfigure an active device. After reconfiguration reprogram the
    current pending event.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: LAK <linux-arm-kernel@lists.infradead.org>
    Cc: John Stultz <john.stultz@linaro.org>
    Acked-by: Linus Walleij <linus.walleij@linaro.org>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>
    Link: http://lkml.kernel.org/r/%3C20110518210136.437459958%40linutronix.de%3E

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index c69e88c94446..22a9da9a9c96 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -238,6 +238,26 @@ void clockevents_config_and_register(struct clock_event_device *dev,
 	clockevents_register_device(dev);
 }
 
+/**
+ * clockevents_update_freq - Update frequency and reprogram a clock event device.
+ * @dev:	device to modify
+ * @freq:	new device frequency
+ *
+ * Reconfigure and reprogram a clock event device in oneshot
+ * mode. Must be called on the cpu for which the device delivers per
+ * cpu timer events with interrupts disabled!  Returns 0 on success,
+ * -ETIME when the event is in the past.
+ */
+int clockevents_update_freq(struct clock_event_device *dev, u32 freq)
+{
+	clockevents_config(dev, freq);
+
+	if (dev->mode != CLOCK_EVT_MODE_ONESHOT)
+		return 0;
+
+	return clockevents_program_event(dev, dev->next_event, ktime_get());
+}
+
 /*
  * Noop handler when we shut down an event device
  */

commit 57f0fcbe1dea8a36c9d1673086326059991c5f81
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed May 18 21:33:41 2011 +0000

    clockevents: Provide combined configure and register function
    
    All clockevent devices have the same open coded initialization
    functions. Provide an interface which does all necessary
    initialization in the core code.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: John Stultz <john.stultz@linaro.org>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>
    Link: http://lkml.kernel.org/r/%3C20110518210136.331975870%40linutronix.de%3E

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 0d74b9ba90c8..c69e88c94446 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -194,6 +194,50 @@ void clockevents_register_device(struct clock_event_device *dev)
 }
 EXPORT_SYMBOL_GPL(clockevents_register_device);
 
+static void clockevents_config(struct clock_event_device *dev,
+			       u32 freq)
+{
+	unsigned long sec;
+
+	if (!(dev->features & CLOCK_EVT_FEAT_ONESHOT))
+		return;
+
+	/*
+	 * Calculate the maximum number of seconds we can sleep. Limit
+	 * to 10 minutes for hardware which can program more than
+	 * 32bit ticks so we still get reasonable conversion values.
+	 */
+	sec = dev->max_delta_ticks;
+	do_div(sec, freq);
+	if (!sec)
+		sec = 1;
+	else if (sec > 600 && dev->max_delta_ticks > UINT_MAX)
+		sec = 600;
+
+	clockevents_calc_mult_shift(dev, freq, sec);
+	dev->min_delta_ns = clockevent_delta2ns(dev->min_delta_ticks, dev);
+	dev->max_delta_ns = clockevent_delta2ns(dev->max_delta_ticks, dev);
+}
+
+/**
+ * clockevents_config_and_register - Configure and register a clock event device
+ * @dev:	device to register
+ * @freq:	The clock frequency
+ * @min_delta:	The minimum clock ticks to program in oneshot mode
+ * @max_delta:	The maximum clock ticks to program in oneshot mode
+ *
+ * min/max_delta can be 0 for devices which do not support oneshot mode.
+ */
+void clockevents_config_and_register(struct clock_event_device *dev,
+				     u32 freq, unsigned long min_delta,
+				     unsigned long max_delta)
+{
+	dev->min_delta_ticks = min_delta;
+	dev->max_delta_ticks = max_delta;
+	clockevents_config(dev, freq);
+	clockevents_register_device(dev);
+}
+
 /*
  * Noop handler when we shut down an event device
  */

commit e2830b5c1b2b2217894370a3b95af87d4a958401
Author: Torben Hohn <torbenh@gmx.de>
Date:   Thu Jan 27 16:00:32 2011 +0100

    time: Make do_timer() and xtime_lock local to kernel/time/
    
    All callers of do_timer() are converted to xtime_update(). The only
    users of xtime_lock are in kernel/time/. Make both local to
    kernel/time/ and remove them from the global header files.
    
    [ tglx: Reuse tick-internal.h instead of creating another local header
            file. Massaged changelog ]
    
    Signed-off-by: Torben Hohn <torbenh@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: johnstul@us.ibm.com
    Cc: yong.zhang0@gmail.com
    Cc: hch@infradead.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index d7395fdfb9f3..0d74b9ba90c8 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -18,7 +18,6 @@
 #include <linux/notifier.h>
 #include <linux/smp.h>
 #include <linux/sysdev.h>
-#include <linux/tick.h>
 
 #include "tick-internal.h"
 

commit ea9d8e3f45404d411c00ae67b45cc35c58265bb7
Author: Xiaotian Feng <dfeng@redhat.com>
Date:   Thu Jan 7 11:22:44 2010 +0800

    clockevent: Don't remove broadcast device when cpu is dead
    
    Marc reported that the BUG_ON in clockevents_notify() triggers on his
    system. This happens because the kernel tries to remove an active
    clock event device (used for broadcasting) from the device list.
    
    The handling of devices which can be used as per cpu device and as a
    global broadcast device is suboptimal.
    
    The simplest solution for now (and for stable) is to check whether the
    device is used as global broadcast device, but this needs to be
    revisited.
    
    [ tglx: restored the cpuweight check and massaged the changelog ]
    
    Reported-by: Marc Dionne <marc.c.dionne@gmail.com>
    Tested-by: Marc Dionne <marc.c.dionne@gmail.com>
    Signed-off-by: Xiaotian Feng <dfeng@redhat.com>
    LKML-Reference: <1262834564-13033-1-git-send-email-dfeng@redhat.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@kernel.org

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 6f740d9f0948..d7395fdfb9f3 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -259,7 +259,8 @@ void clockevents_notify(unsigned long reason, void *arg)
 		cpu = *((int *)arg);
 		list_for_each_entry_safe(dev, tmp, &clockevent_devices, list) {
 			if (cpumask_test_cpu(cpu, dev->cpumask) &&
-			    cpumask_weight(dev->cpumask) == 1) {
+			    cpumask_weight(dev->cpumask) == 1 &&
+			    !tick_is_broadcast_device(dev)) {
 				BUG_ON(dev->mode != CLOCK_EVT_MODE_UNUSED);
 				list_del(&dev->list);
 			}

commit 3cd312c3e887b4bee2d94668a481b3d19c07732c
Merge: ecd5907a200b cf1e367ee84e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Dec 19 09:47:18 2009 -0800

    Merge branch 'timers-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'timers-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      timers: Remove duplicate setting of new_base in __mod_timer()
      clockevents: Prevent clockevent_devices list corruption on cpu hotplug

commit b5f91da0a6973bb6f9ff3b91b0e92c0773a458f3
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Dec 8 12:40:31 2009 +0100

    clockevents: Convert to raw_spinlock
    
    Convert locks which cannot be sleeping locks in preempt-rt to
    raw_spinlocks.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Acked-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 20a8920029ee..3d5fc0fd1cca 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -30,7 +30,7 @@ static LIST_HEAD(clockevents_released);
 static RAW_NOTIFIER_HEAD(clockevents_chain);
 
 /* Protection for the above */
-static DEFINE_SPINLOCK(clockevents_lock);
+static DEFINE_RAW_SPINLOCK(clockevents_lock);
 
 /**
  * clockevents_delta2ns - Convert a latch value (device ticks) to nanoseconds
@@ -141,9 +141,9 @@ int clockevents_register_notifier(struct notifier_block *nb)
 	unsigned long flags;
 	int ret;
 
-	spin_lock_irqsave(&clockevents_lock, flags);
+	raw_spin_lock_irqsave(&clockevents_lock, flags);
 	ret = raw_notifier_chain_register(&clockevents_chain, nb);
-	spin_unlock_irqrestore(&clockevents_lock, flags);
+	raw_spin_unlock_irqrestore(&clockevents_lock, flags);
 
 	return ret;
 }
@@ -185,13 +185,13 @@ void clockevents_register_device(struct clock_event_device *dev)
 	BUG_ON(dev->mode != CLOCK_EVT_MODE_UNUSED);
 	BUG_ON(!dev->cpumask);
 
-	spin_lock_irqsave(&clockevents_lock, flags);
+	raw_spin_lock_irqsave(&clockevents_lock, flags);
 
 	list_add(&dev->list, &clockevent_devices);
 	clockevents_do_notify(CLOCK_EVT_NOTIFY_ADD, dev);
 	clockevents_notify_released();
 
-	spin_unlock_irqrestore(&clockevents_lock, flags);
+	raw_spin_unlock_irqrestore(&clockevents_lock, flags);
 }
 EXPORT_SYMBOL_GPL(clockevents_register_device);
 
@@ -241,7 +241,7 @@ void clockevents_notify(unsigned long reason, void *arg)
 	struct list_head *node, *tmp;
 	unsigned long flags;
 
-	spin_lock_irqsave(&clockevents_lock, flags);
+	raw_spin_lock_irqsave(&clockevents_lock, flags);
 	clockevents_do_notify(reason, arg);
 
 	switch (reason) {
@@ -256,7 +256,7 @@ void clockevents_notify(unsigned long reason, void *arg)
 	default:
 		break;
 	}
-	spin_unlock_irqrestore(&clockevents_lock, flags);
+	raw_spin_unlock_irqrestore(&clockevents_lock, flags);
 }
 EXPORT_SYMBOL_GPL(clockevents_notify);
 #endif

commit bb6eddf7676e1c1f3e637aa93c5224488d99036f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Dec 10 15:35:10 2009 +0100

    clockevents: Prevent clockevent_devices list corruption on cpu hotplug
    
    Xiaotian Feng triggered a list corruption in the clock events list on
    CPU hotplug and debugged the root cause.
    
    If a CPU registers more than one per cpu clock event device, then only
    the active clock event device is removed on CPU_DEAD. The unused
    devices are kept in the clock events device list.
    
    On CPU up the clock event devices are registered again, which means
    that we list_add an already enqueued list_head. That results in list
    corruption.
    
    Resolve this by removing all devices which are associated to the dead
    CPU on CPU_DEAD.
    
    Reported-by: Xiaotian Feng <dfeng@redhat.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Xiaotian Feng <dfeng@redhat.com>
    Cc: stable@kernel.org

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 20a8920029ee..91db2e33d86a 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -238,8 +238,9 @@ void clockevents_exchange_device(struct clock_event_device *old,
  */
 void clockevents_notify(unsigned long reason, void *arg)
 {
-	struct list_head *node, *tmp;
+	struct clock_event_device *dev, *tmp;
 	unsigned long flags;
+	int cpu;
 
 	spin_lock_irqsave(&clockevents_lock, flags);
 	clockevents_do_notify(reason, arg);
@@ -250,8 +251,19 @@ void clockevents_notify(unsigned long reason, void *arg)
 		 * Unregister the clock event devices which were
 		 * released from the users in the notify chain.
 		 */
-		list_for_each_safe(node, tmp, &clockevents_released)
-			list_del(node);
+		list_for_each_entry_safe(dev, tmp, &clockevents_released, list)
+			list_del(&dev->list);
+		/*
+		 * Now check whether the CPU has left unused per cpu devices
+		 */
+		cpu = *((int *)arg);
+		list_for_each_entry_safe(dev, tmp, &clockevent_devices, list) {
+			if (cpumask_test_cpu(cpu, dev->cpumask) &&
+			    cpumask_weight(dev->cpumask) == 1) {
+				BUG_ON(dev->mode != CLOCK_EVT_MODE_UNUSED);
+				list_del(&dev->list);
+			}
+		}
 		break;
 	default:
 		break;

commit 8e1a928a2ed7e8d5cad97c8e985294b4caedd168
Author: H Hartley Sweeten <hartleys@visionengravers.com>
Date:   Fri Oct 16 18:19:01 2009 -0400

    clockevents: Add missing include to pacify sparse
    
    Include "tick-internal.h" in order to pick up the extern function
    prototype for clockevents_shutdown(). This quiets the following sparse
    build noise:
    
      warning: symbol 'clockevents_shutdown' was not declared. Should it be static?
    
    Signed-off-by: H Hartley Sweeten <hsweeten@visionengravers.com>
    LKML-Reference: <BD79186B4FD85F4B8E60E381CAEE190901E24550@mi8nycmail19.Mi8.com>
    Reviewed-by: Yong Zhang <yong.zhang0@gmail.com>
    Cc: johnstul@us.ibm.com
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 05e8aeedcdf3..20a8920029ee 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -20,6 +20,8 @@
 #include <linux/sysdev.h>
 #include <linux/tick.h>
 
+#include "tick-internal.h"
+
 /* The registered clock event devices */
 static LIST_HEAD(clockevent_devices);
 static LIST_HEAD(clockevents_released);

commit 97813f2fe77804a4464564c75ba8d8826377feea
Author: Jon Hunter <jon-hunter@ti.com>
Date:   Tue Aug 18 12:45:11 2009 -0500

    nohz: Allow 32-bit machines to sleep for more than 2.15 seconds
    
    In the dynamic tick code, "max_delta_ns" (member of the
    "clock_event_device" structure) represents the maximum sleep time
    that can occur between timer events in nanoseconds.
    
    The variable, "max_delta_ns", is defined as an unsigned long
    which is a 32-bit integer for 32-bit machines and a 64-bit
    integer for 64-bit machines (if -m64 option is used for gcc).
    The value of max_delta_ns is set by calling the function
    "clockevent_delta2ns()" which returns a maximum value of LONG_MAX.
    For a 32-bit machine LONG_MAX is equal to 0x7fffffff and in
    nanoseconds this equates to ~2.15 seconds. Hence, the maximum
    sleep time for a 32-bit machine is ~2.15 seconds, where as for
    a 64-bit machine it will be many years.
    
    This patch changes the type of max_delta_ns to be "u64" instead of
    "unsigned long" so that this variable is a 64-bit type for both 32-bit
    and 64-bit machines. It also changes the maximum value returned by
    clockevent_delta2ns() to KTIME_MAX.  Hence this allows a 32-bit
    machine to sleep for longer than ~2.15 seconds. Please note that this
    patch also changes "min_delta_ns" to be "u64" too and although this is
    unnecessary, it makes the patch simpler as it avoids to fixup all
    callers of clockevent_delta2ns().
    
    [ tglx: changed "unsigned long long" to u64 as we use this data type
            through out the time code ]
    
    Signed-off-by: Jon Hunter <jon-hunter@ti.com>
    Cc: John Stultz <johnstul@us.ibm.com>
    LKML-Reference: <1250617512-23567-3-git-send-email-jon-hunter@ti.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 620b58abdc32..05e8aeedcdf3 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -37,10 +37,9 @@ static DEFINE_SPINLOCK(clockevents_lock);
  *
  * Math helper, returns latch value converted to nanoseconds (bound checked)
  */
-unsigned long clockevent_delta2ns(unsigned long latch,
-				  struct clock_event_device *evt)
+u64 clockevent_delta2ns(unsigned long latch, struct clock_event_device *evt)
 {
-	u64 clc = ((u64) latch << evt->shift);
+	u64 clc = (u64) latch << evt->shift;
 
 	if (unlikely(!evt->mult)) {
 		evt->mult = 1;
@@ -50,10 +49,10 @@ unsigned long clockevent_delta2ns(unsigned long latch,
 	do_div(clc, evt->mult);
 	if (clc < 1000)
 		clc = 1000;
-	if (clc > LONG_MAX)
-		clc = LONG_MAX;
+	if (clc > KTIME_MAX)
+		clc = KTIME_MAX;
 
-	return (unsigned long) clc;
+	return clc;
 }
 EXPORT_SYMBOL_GPL(clockevent_delta2ns);
 

commit f833bab87fca5c3ce13778421b1365845843b976
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Mon Aug 17 14:34:59 2009 -0700

    clockevent: Prevent dead lock on clockevents_lock
    
    Currently clockevents_notify() is called with interrupts enabled at
    some places and interrupts disabled at some other places.
    
    This results in a deadlock in this scenario.
    
    cpu A holds clockevents_lock in clockevents_notify() with irqs enabled
    cpu B waits for clockevents_lock in clockevents_notify() with irqs disabled
    cpu C doing set_mtrr() which will try to rendezvous of all the cpus.
    
    This will result in C and A come to the rendezvous point and waiting
    for B. B is stuck forever waiting for the spinlock and thus not
    reaching the rendezvous point.
    
    Fix the clockevents code so that clockevents_lock is taken with
    interrupts disabled and thus avoid the above deadlock.
    
    Also call lapic_timer_propagate_broadcast() on the destination cpu so
    that we avoid calling smp_call_function() in the clockevents notifier
    chain.
    
    This issue left us wondering if we need to change the MTRR rendezvous
    logic to use stop machine logic (instead of smp_call_function) or add
    a check in spinlock debug code to see if there are other spinlocks
    which gets taken under both interrupts enabled/disabled conditions.
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Cc: "Pallipadi Venkatesh" <venkatesh.pallipadi@intel.com>
    Cc: "Brown Len" <len.brown@intel.com>
    LKML-Reference: <1250544899.2709.210.camel@sbs-t61.sc.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index a6dcd67b041d..620b58abdc32 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -137,11 +137,12 @@ int clockevents_program_event(struct clock_event_device *dev, ktime_t expires,
  */
 int clockevents_register_notifier(struct notifier_block *nb)
 {
+	unsigned long flags;
 	int ret;
 
-	spin_lock(&clockevents_lock);
+	spin_lock_irqsave(&clockevents_lock, flags);
 	ret = raw_notifier_chain_register(&clockevents_chain, nb);
-	spin_unlock(&clockevents_lock);
+	spin_unlock_irqrestore(&clockevents_lock, flags);
 
 	return ret;
 }
@@ -178,16 +179,18 @@ static void clockevents_notify_released(void)
  */
 void clockevents_register_device(struct clock_event_device *dev)
 {
+	unsigned long flags;
+
 	BUG_ON(dev->mode != CLOCK_EVT_MODE_UNUSED);
 	BUG_ON(!dev->cpumask);
 
-	spin_lock(&clockevents_lock);
+	spin_lock_irqsave(&clockevents_lock, flags);
 
 	list_add(&dev->list, &clockevent_devices);
 	clockevents_do_notify(CLOCK_EVT_NOTIFY_ADD, dev);
 	clockevents_notify_released();
 
-	spin_unlock(&clockevents_lock);
+	spin_unlock_irqrestore(&clockevents_lock, flags);
 }
 EXPORT_SYMBOL_GPL(clockevents_register_device);
 
@@ -235,8 +238,9 @@ void clockevents_exchange_device(struct clock_event_device *old,
 void clockevents_notify(unsigned long reason, void *arg)
 {
 	struct list_head *node, *tmp;
+	unsigned long flags;
 
-	spin_lock(&clockevents_lock);
+	spin_lock_irqsave(&clockevents_lock, flags);
 	clockevents_do_notify(reason, arg);
 
 	switch (reason) {
@@ -251,7 +255,7 @@ void clockevents_notify(unsigned long reason, void *arg)
 	default:
 		break;
 	}
-	spin_unlock(&clockevents_lock);
+	spin_unlock_irqrestore(&clockevents_lock, flags);
 }
 EXPORT_SYMBOL_GPL(clockevents_notify);
 #endif

commit 6ff7041dbfeb3bd7dfe9aa67275c21199ef760d6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jul 10 14:57:05 2009 +0200

    hrtimer: Fix migration expiry check
    
    The timer migration expiry check should prevent the migration of a
    timer to another CPU when the timer expires before the next event is
    scheduled on the other CPU. Migrating the timer might delay it because
    we can not reprogram the clock event device on the other CPU. But the
    code implementing that check has two flaws:
    
    - for !HIGHRES the check compares the expiry value with the clock
      events device expiry value which is wrong for CLOCK_REALTIME based
      timers.
    
    - the check is racy. It holds the hrtimer base lock of the target CPU,
      but the clock event device expiry value can be modified
      nevertheless, e.g. by an timer interrupt firing.
    
    The !HIGHRES case is easy to fix as we can enqueue the timer on the
    cpu which was selected by the load balancer. It runs the idle
    balancing code once per jiffy anyway. So the maximum delay for the
    timer is the same as when we keep the tick on the current cpu going.
    
    In the HIGHRES case we can get the next expiry value from the hrtimer
    cpu_base of the target CPU and serialize the update with the cpu_base
    lock. This moves the lock section in hrtimer_interrupt() so we can set
    next_event to KTIME_MAX while we are handling the expired timers and
    set it to the next expiry value after we handled the timers under the
    base lock. While the expired timers are processed timer migration is
    blocked because the expiry time of the timer is always <= KTIME_MAX.
    
    Also remove the now useless clockevents_get_next_event() function.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 1ad6dd461119..a6dcd67b041d 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -254,15 +254,4 @@ void clockevents_notify(unsigned long reason, void *arg)
 	spin_unlock(&clockevents_lock);
 }
 EXPORT_SYMBOL_GPL(clockevents_notify);
-
-ktime_t clockevents_get_next_event(int cpu)
-{
-	struct tick_device *td;
-	struct clock_event_device *dev;
-
-	td = &per_cpu(tick_cpu_device, cpu);
-	dev = td->evtdev;
-
-	return dev->next_event;
-}
 #endif

commit 19035e5b5d1e3127b4925d86f6a77964f91f2c3c
Merge: f9db6e095115 eea08f32adb3
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jun 15 10:06:19 2009 -0700

    Merge branch 'timers-for-linus-migration' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'timers-for-linus-migration' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      timers: Logic to move non pinned timers
      timers: /proc/sys sysctl hook to enable timer migration
      timers: Identifying the existing pinned timers
      timers: Framework for identifying pinned timers
      timers: allow deferrable timers for intervals tv2-tv5 to be deferred
    
    Fix up conflicts in kernel/sched.c and kernel/timer.c manually

commit eea08f32adb3f97553d49a4f79a119833036000a
Author: Arun R Bharadwaj <arun@linux.vnet.ibm.com>
Date:   Thu Apr 16 12:16:41 2009 +0530

    timers: Logic to move non pinned timers
    
    * Arun R Bharadwaj <arun@linux.vnet.ibm.com> [2009-04-16 12:11:36]:
    
    This patch migrates all non pinned timers and hrtimers to the current
    idle load balancer, from all the idle CPUs. Timers firing on busy CPUs
    are not migrated.
    
    While migrating hrtimers, care should be taken to check if migrating
    a hrtimer would result in a latency or not. So we compare the expiry of the
    hrtimer with the next timer interrupt on the target cpu and migrate the
    hrtimer only if it expires *after* the next interrupt on the target cpu.
    So, added a clockevents_get_next_event() helper function to return the
    next_event on the target cpu's clock_event_device.
    
    [ tglx: cleanups and simplifications ]
    
    Signed-off-by: Arun R Bharadwaj <arun@linux.vnet.ibm.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index d13be216a790..ab20ded013bd 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -18,6 +18,7 @@
 #include <linux/notifier.h>
 #include <linux/smp.h>
 #include <linux/sysdev.h>
+#include <linux/tick.h>
 
 /* The registered clock event devices */
 static LIST_HEAD(clockevent_devices);
@@ -251,4 +252,15 @@ void clockevents_notify(unsigned long reason, void *arg)
 	spin_unlock(&clockevents_lock);
 }
 EXPORT_SYMBOL_GPL(clockevents_notify);
+
+ktime_t clockevents_get_next_event(int cpu)
+{
+	struct tick_device *td;
+	struct clock_event_device *dev;
+
+	td = &per_cpu(tick_cpu_device, cpu);
+	dev = td->evtdev;
+
+	return dev->next_event;
+}
 #endif

commit c81fc2c331b8514ad112054cd2d87e6ec132286b
Author: Magnus Damm <magnus.damm@gmail.com>
Date:   Fri May 1 14:52:47 2009 +0900

    clockevent: export register_device and delta2ns
    
    Export the following symbols using EXPORT_SYMBOL_GPL:
     - clockevent_delta2ns
     - clockevents_register_device
    
    This allows us to build SuperH clockevent and clocksource
    drivers as modules, see drivers/clocksource/sh_*.c
    
    [ Impact: allow modular build of clockevent drivers ]
    
    Signed-off-by: Magnus Damm <damm@igel.co.jp>
    LKML-Reference: <20090501055247.8286.64067.sendpatchset@rx1.opensource.se>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index d13be216a790..3948fa644a2d 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -54,6 +54,7 @@ unsigned long clockevent_delta2ns(unsigned long latch,
 
 	return (unsigned long) clc;
 }
+EXPORT_SYMBOL_GPL(clockevent_delta2ns);
 
 /**
  * clockevents_set_mode - set the operating mode of a clock event device
@@ -187,6 +188,7 @@ void clockevents_register_device(struct clock_event_device *dev)
 
 	spin_unlock(&clockevents_lock);
 }
+EXPORT_SYMBOL_GPL(clockevents_register_device);
 
 /*
  * Noop handler when we shut down an event device

commit 2d68259db26ad57fd9643f1c69b5181ec9836ca9
Author: Magnus Damm <magnus.damm@gmail.com>
Date:   Fri Jan 16 17:14:38 2009 +0900

    clockevents: let set_mode() setup delta information
    
    Allow the set_mode() clockevent callback to decide and fill in delta
    details such as shift, mult, max_delta_ns and min_delta_ns.
    
    With this change the clockevent can be registered without delta details
    which allows us to keep the parent clock disabled until the clockevent
    gets setup using set_mode().
    
    Letting set_mode() fill in or update delta details allows us to save
    power by disabling the parent clock while the clockevent is unused.
    This may however make the parent clock rate change, so next time the
    clockevent gets enabled we need let set_mode() to update the detla
    details accordingly. Doing it at registration time is not enough.
    
    Furthermore, the delta details seem unused in the case of periodic-only
    clockevent drivers, so this change also allows registration of such
    drivers without the delta details filled in.
    
    Signed-off-by: Magnus Damm <damm@igel.co.jp>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index ea2f48af83cf..d13be216a790 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -68,6 +68,17 @@ void clockevents_set_mode(struct clock_event_device *dev,
 	if (dev->mode != mode) {
 		dev->set_mode(mode, dev);
 		dev->mode = mode;
+
+		/*
+		 * A nsec2cyc multiplicator of 0 is invalid and we'd crash
+		 * on it, so fix it up and emit a warning:
+		 */
+		if (mode == CLOCK_EVT_MODE_ONESHOT) {
+			if (unlikely(!dev->mult)) {
+				dev->mult = 1;
+				WARN_ON(1);
+			}
+		}
 	}
 }
 
@@ -168,15 +179,6 @@ void clockevents_register_device(struct clock_event_device *dev)
 	BUG_ON(dev->mode != CLOCK_EVT_MODE_UNUSED);
 	BUG_ON(!dev->cpumask);
 
-	/*
-	 * A nsec2cyc multiplicator of 0 is invalid and we'd crash
-	 * on it, so fix it up and emit a warning:
-	 */
-	if (unlikely(!dev->mult)) {
-		dev->mult = 1;
-		WARN_ON(1);
-	}
-
 	spin_lock(&clockevents_lock);
 
 	list_add(&dev->list, &clockevent_devices);

commit 320ab2b0b1e08e3805a3e1084a2f0eb1938d5d67
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Sat Dec 13 21:20:26 2008 +1030

    cpumask: convert struct clock_event_device to cpumask pointers.
    
    Impact: change calling convention of existing clock_event APIs
    
    struct clock_event_timer's cpumask field gets changed to take pointer,
    as does the ->broadcast function.
    
    Another single-patch change.  For safety, we BUG_ON() in
    clockevents_register_device() if it's not set.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index f8d968063cea..ea2f48af83cf 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -166,6 +166,8 @@ static void clockevents_notify_released(void)
 void clockevents_register_device(struct clock_event_device *dev)
 {
 	BUG_ON(dev->mode != CLOCK_EVT_MODE_UNUSED);
+	BUG_ON(!dev->cpumask);
+
 	/*
 	 * A nsec2cyc multiplicator of 0 is invalid and we'd crash
 	 * on it, so fix it up and emit a warning:

commit 2344abbcbdb82140050e8be29d3d55e4f6fe860b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Sep 16 11:32:50 2008 -0700

    clockevents: make device shutdown robust
    
    The device shut down does not cleanup the next_event variable of the
    clock event device. So when the device is reactivated the possible
    stale next_event value can prevent the device to be reprogrammed as it
    claims to wait on a event already.
    
    This is the root cause of the resurfacing suspend/resume problem,
    where systems need key press to come back to life.
    
    Fix this by setting next_event to KTIME_MAX when the device is shut
    down. Use a separate function for shutdown which takes care of that
    and only keep the direct set mode call in the broadcast code, where we
    can not touch the next_event value.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 1876b526c778..f8d968063cea 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -71,6 +71,16 @@ void clockevents_set_mode(struct clock_event_device *dev,
 	}
 }
 
+/**
+ * clockevents_shutdown - shutdown the device and clear next_event
+ * @dev:	device to shutdown
+ */
+void clockevents_shutdown(struct clock_event_device *dev)
+{
+	clockevents_set_mode(dev, CLOCK_EVT_MODE_SHUTDOWN);
+	dev->next_event.tv64 = KTIME_MAX;
+}
+
 /**
  * clockevents_program_event - Reprogram the clock event device.
  * @expires:	absolute expiry time (monotonic clock)
@@ -206,7 +216,7 @@ void clockevents_exchange_device(struct clock_event_device *old,
 
 	if (new) {
 		BUG_ON(new->mode != CLOCK_EVT_MODE_UNUSED);
-		clockevents_set_mode(new, CLOCK_EVT_MODE_SHUTDOWN);
+		clockevents_shutdown(new);
 	}
 	local_irq_restore(flags);
 }

commit 7c1e76897492d92b6a1c2d6892494d39ded9680c
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Wed Sep 3 21:36:50 2008 +0000

    clockevents: prevent clockevent event_handler ending up handler_noop
    
    There is a ordering related problem with clockevents code, due to which
    clockevents_register_device() called after tickless/highres switch
    will not work. The new clockevent ends up with clockevents_handle_noop as
    event handler, resulting in no timer activity.
    
    The problematic path seems to be
    
    * old device already has hrtimer_interrupt as the event_handler
    * new clockevent device registers with a higher rating
    * tick_check_new_device() is called
      * clockevents_exchange_device() gets called
        * old->event_handler is set to clockevents_handle_noop
      * tick_setup_device() is called for the new device
        * which sets new->event_handler using the old->event_handler which is noop.
    
    Change the ordering so that new device inherits the proper handler.
    
    This does not have any issue in normal case as most likely all the clockevent
    devices are setup before the highres switch. But, can potentially be affecting
    some corner case where HPET force detect happens after the highres switch.
    This was a problem with HPET in MSI mode code that we have been experimenting
    with.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Shaohua Li <shaohua.li@intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 3d1e3e1a1971..1876b526c778 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -177,7 +177,7 @@ void clockevents_register_device(struct clock_event_device *dev)
 /*
  * Noop handler when we shut down an event device
  */
-static void clockevents_handle_noop(struct clock_event_device *dev)
+void clockevents_handle_noop(struct clock_event_device *dev)
 {
 }
 
@@ -199,7 +199,6 @@ void clockevents_exchange_device(struct clock_event_device *old,
 	 * released list and do a notify add later.
 	 */
 	if (old) {
-		old->event_handler = clockevents_handle_noop;
 		clockevents_set_mode(old, CLOCK_EVT_MODE_UNUSED);
 		list_del(&old->list);
 		list_add(&old->list, &clockevents_released);

commit 3eb056764dd806bbe84eb604e45e7470feeaafd8
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Fri Feb 8 04:19:25 2008 -0800

    time: fix typo in comments
    
    Fix typo in comments.
    
    BTW: I have to fix coding style in arch/ia64/kernel/time.c also, otherwise
    checkpatch.pl will be complaining.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: john stultz <johnstul@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 1d327f6db424..3d1e3e1a1971 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -133,7 +133,7 @@ static void clockevents_do_notify(unsigned long reason, void *dev)
 }
 
 /*
- * Called after a notify add to make devices availble which were
+ * Called after a notify add to make devices available which were
  * released from the notifier call.
  */
 static void clockevents_notify_released(void)

commit 0b858e6ff9a38b987a83d22e6f2a2f621c80608d
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Fri Feb 8 04:19:24 2008 -0800

    clockevent: simplify list operations
    
    list_for_each_safe() suffices here.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: john stultz <johnstul@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 3e59fce6dd43..1d327f6db424 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -218,6 +218,8 @@ void clockevents_exchange_device(struct clock_event_device *old,
  */
 void clockevents_notify(unsigned long reason, void *arg)
 {
+	struct list_head *node, *tmp;
+
 	spin_lock(&clockevents_lock);
 	clockevents_do_notify(reason, arg);
 
@@ -227,13 +229,8 @@ void clockevents_notify(unsigned long reason, void *arg)
 		 * Unregister the clock event devices which were
 		 * released from the users in the notify chain.
 		 */
-		while (!list_empty(&clockevents_released)) {
-			struct clock_event_device *dev;
-
-			dev = list_entry(clockevents_released.next,
-					 struct clock_event_device, list);
-			list_del(&dev->list);
-		}
+		list_for_each_safe(node, tmp, &clockevents_released)
+			list_del(node);
 		break;
 	default:
 		break;

commit 45fe4fe19120a22f7339f5bb110447170c25fca9
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Jan 30 13:30:03 2008 +0100

    x86: make clockevents more robust
    
    detect zero event-device multiplicators - they then cause
    division-by-zero crashes if a clockevent has been initialized
    incorrectly.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 5fb139fef9fa..3e59fce6dd43 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -41,6 +41,11 @@ unsigned long clockevent_delta2ns(unsigned long latch,
 {
 	u64 clc = ((u64) latch << evt->shift);
 
+	if (unlikely(!evt->mult)) {
+		evt->mult = 1;
+		WARN_ON(1);
+	}
+
 	do_div(clc, evt->mult);
 	if (clc < 1000)
 		clc = 1000;
@@ -151,6 +156,14 @@ static void clockevents_notify_released(void)
 void clockevents_register_device(struct clock_event_device *dev)
 {
 	BUG_ON(dev->mode != CLOCK_EVT_MODE_UNUSED);
+	/*
+	 * A nsec2cyc multiplicator of 0 is invalid and we'd crash
+	 * on it, so fix it up and emit a warning:
+	 */
+	if (unlikely(!dev->mult)) {
+		dev->mult = 1;
+		WARN_ON(1);
+	}
 
 	spin_lock(&clockevents_lock);
 

commit 167b1de3ee4e50d65a2bd0a2667c9cd48faf54f3
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Dec 7 19:16:17 2007 +0100

    clockevents: warn once when program_event() is called with negative expiry
    
    The hrtimer problem with large relative timeouts resulting in a
    negative expiry time went unnoticed as there is no check in the
    clockevents_program_event() code. Put a check there with a WARN_ONCE
    to avoid such problems in the future.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 822beebe664a..5fb139fef9fa 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -78,6 +78,11 @@ int clockevents_program_event(struct clock_event_device *dev, ktime_t expires,
 	unsigned long long clc;
 	int64_t delta;
 
+	if (unlikely(expires.tv64 < 0)) {
+		WARN_ON_ONCE(1);
+		return -ETIME;
+	}
+
 	delta = ktime_to_ns(ktime_sub(expires, now));
 
 	if (delta <= 0)

commit de68d9b173ee657115dd0e584c2365b7954253a5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Oct 12 23:04:05 2007 +0200

    clockevents: Allow build w/o run-tine usage for migration purposes
    
    Migration aid to allow preparatory patches which introduce not yet
    used parts of clock events code.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 41dd3105ce7f..822beebe664a 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -194,6 +194,7 @@ void clockevents_exchange_device(struct clock_event_device *old,
 	local_irq_restore(flags);
 }
 
+#ifdef CONFIG_GENERIC_CLOCKEVENTS
 /**
  * clockevents_notify - notification about relevant events
  */
@@ -222,4 +223,4 @@ void clockevents_notify(unsigned long reason, void *arg)
 	spin_unlock(&clockevents_lock);
 }
 EXPORT_SYMBOL_GPL(clockevents_notify);
-
+#endif

commit 6ddfca9548d8ecc26096a30667423ba919109533
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Fri Aug 10 13:01:09 2007 -0700

    timer: remove clockevents_unregister_notifier
    
    I find a function(clockevents_unregister_notifier) which is not called by
    anything in tree.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 2ad1c37b8dfe..41dd3105ce7f 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -113,16 +113,6 @@ int clockevents_register_notifier(struct notifier_block *nb)
 	return ret;
 }
 
-/**
- * clockevents_unregister_notifier - unregister a clock events change listener
- */
-void clockevents_unregister_notifier(struct notifier_block *nb)
-{
-	spin_lock(&clockevents_lock);
-	raw_notifier_chain_unregister(&clockevents_chain, nb);
-	spin_unlock(&clockevents_lock);
-}
-
 /*
  * Notify about a clock event change. Called with clockevents_lock
  * held.

commit 78c1b0657475dbafa008c71e3ccdc32141d8c7c7
Author: Andi Kleen <ak@suse.de>
Date:   Sun Jul 15 23:40:15 2007 -0700

    Remove clockevents_{release,request}_device
    
    Not called by anything in tree.
    
    Signed-off-by: Andi Kleen <ak@suse.de>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: john stultz <johnstul@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 76212b2a99de..2ad1c37b8dfe 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -204,47 +204,6 @@ void clockevents_exchange_device(struct clock_event_device *old,
 	local_irq_restore(flags);
 }
 
-/**
- * clockevents_request_device
- */
-struct clock_event_device *clockevents_request_device(unsigned int features,
-						      cpumask_t cpumask)
-{
-	struct clock_event_device *cur, *dev = NULL;
-	struct list_head *tmp;
-
-	spin_lock(&clockevents_lock);
-
-	list_for_each(tmp, &clockevent_devices) {
-		cur = list_entry(tmp, struct clock_event_device, list);
-
-		if ((cur->features & features) == features &&
-		    cpus_equal(cpumask, cur->cpumask)) {
-			if (!dev || dev->rating < cur->rating)
-				dev = cur;
-		}
-	}
-
-	clockevents_exchange_device(NULL, dev);
-
-	spin_unlock(&clockevents_lock);
-
-	return dev;
-}
-
-/**
- * clockevents_release_device
- */
-void clockevents_release_device(struct clock_event_device *dev)
-{
-	spin_lock(&clockevents_lock);
-
-	clockevents_exchange_device(dev, NULL);
-	clockevents_notify_released();
-
-	spin_unlock(&clockevents_lock);
-}
-
 /**
  * clockevents_notify - notification about relevant events
  */

commit 291bc047e125ff02c9affe06a7df28bed57b054d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Mar 26 11:21:08 2007 +0200

    [PATCH] clockevents: remove bad designed sysfs support for now
    
    The current sysfs support of clockevents does not obey the "only one
    value per file" rule.
    
    The real fix is not 2.6.21 material. Therefor remove the sysfs support
    for now.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: Greg Kroah-Hartman <gregkh@suse.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
index 67932ea78c17..76212b2a99de 100644
--- a/kernel/time/clockevents.c
+++ b/kernel/time/clockevents.c
@@ -274,72 +274,3 @@ void clockevents_notify(unsigned long reason, void *arg)
 }
 EXPORT_SYMBOL_GPL(clockevents_notify);
 
-#ifdef CONFIG_SYSFS
-
-/**
- * clockevents_show_registered - sysfs interface for listing clockevents
- * @dev:	unused
- * @buf:	char buffer to be filled with clock events list
- *
- * Provides sysfs interface for listing registered clock event devices
- */
-static ssize_t clockevents_show_registered(struct sys_device *dev, char *buf)
-{
-	struct list_head *tmp;
-	char *p = buf;
-	int cpu;
-
-	spin_lock(&clockevents_lock);
-
-	list_for_each(tmp, &clockevent_devices) {
-		struct clock_event_device *ce;
-
-		ce = list_entry(tmp, struct clock_event_device, list);
-		p += sprintf(p, "%-20s F:%04x M:%d", ce->name,
-			     ce->features, ce->mode);
-		p += sprintf(p, " C:");
-		if (!cpus_equal(ce->cpumask, cpu_possible_map)) {
-			for_each_cpu_mask(cpu, ce->cpumask)
-				p += sprintf(p, " %d", cpu);
-		} else {
-			/*
-			 * FIXME: Add the cpu which is handling this sucker
-			 */
-		}
-		p += sprintf(p, "\n");
-	}
-
-	spin_unlock(&clockevents_lock);
-
-	return p - buf;
-}
-
-/*
- * Sysfs setup bits:
- */
-static SYSDEV_ATTR(registered, 0600,
-		   clockevents_show_registered, NULL);
-
-static struct sysdev_class clockevents_sysclass = {
-	set_kset_name("clockevents"),
-};
-
-static struct sys_device clockevents_sys_device = {
-	.id	= 0,
-	.cls	= &clockevents_sysclass,
-};
-
-static int __init clockevents_sysfs_init(void)
-{
-	int error = sysdev_class_register(&clockevents_sysclass);
-
-	if (!error)
-		error = sysdev_register(&clockevents_sys_device);
-	if (!error)
-		error = sysdev_create_file(
-				&clockevents_sys_device,
-				&attr_registered);
-	return error;
-}
-device_initcall(clockevents_sysfs_init);
-#endif

commit d316c57ff6bfad9557462b9100f25c6260d2b774
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Feb 16 01:28:00 2007 -0800

    [PATCH] clockevents: add core functionality
    
    Architectures register their clock event devices, in the clock events core.
    Users of the clockevents core can get clock event devices for their use.  The
    clockevents core code provides notification mechanisms for various clock
    related management events.
    
    This allows to control the clock event devices without the architectures
    having to worry about the details of function assignment.  This is also a
    preliminary for high resolution timers and dynamic ticks to allow the core
    code to control the clock functionality without intrusive changes to the
    architecture code.
    
    [Fixes-by: Ingo Molnar <mingo@elte.hu>]
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Cc: john stultz <johnstul@us.ibm.com>
    Cc: Andi Kleen <ak@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/time/clockevents.c b/kernel/time/clockevents.c
new file mode 100644
index 000000000000..67932ea78c17
--- /dev/null
+++ b/kernel/time/clockevents.c
@@ -0,0 +1,345 @@
+/*
+ * linux/kernel/time/clockevents.c
+ *
+ * This file contains functions which manage clock event devices.
+ *
+ * Copyright(C) 2005-2006, Thomas Gleixner <tglx@linutronix.de>
+ * Copyright(C) 2005-2007, Red Hat, Inc., Ingo Molnar
+ * Copyright(C) 2006-2007, Timesys Corp., Thomas Gleixner
+ *
+ * This code is licenced under the GPL version 2. For details see
+ * kernel-base/COPYING.
+ */
+
+#include <linux/clockchips.h>
+#include <linux/hrtimer.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/notifier.h>
+#include <linux/smp.h>
+#include <linux/sysdev.h>
+
+/* The registered clock event devices */
+static LIST_HEAD(clockevent_devices);
+static LIST_HEAD(clockevents_released);
+
+/* Notification for clock events */
+static RAW_NOTIFIER_HEAD(clockevents_chain);
+
+/* Protection for the above */
+static DEFINE_SPINLOCK(clockevents_lock);
+
+/**
+ * clockevents_delta2ns - Convert a latch value (device ticks) to nanoseconds
+ * @latch:	value to convert
+ * @evt:	pointer to clock event device descriptor
+ *
+ * Math helper, returns latch value converted to nanoseconds (bound checked)
+ */
+unsigned long clockevent_delta2ns(unsigned long latch,
+				  struct clock_event_device *evt)
+{
+	u64 clc = ((u64) latch << evt->shift);
+
+	do_div(clc, evt->mult);
+	if (clc < 1000)
+		clc = 1000;
+	if (clc > LONG_MAX)
+		clc = LONG_MAX;
+
+	return (unsigned long) clc;
+}
+
+/**
+ * clockevents_set_mode - set the operating mode of a clock event device
+ * @dev:	device to modify
+ * @mode:	new mode
+ *
+ * Must be called with interrupts disabled !
+ */
+void clockevents_set_mode(struct clock_event_device *dev,
+				 enum clock_event_mode mode)
+{
+	if (dev->mode != mode) {
+		dev->set_mode(mode, dev);
+		dev->mode = mode;
+	}
+}
+
+/**
+ * clockevents_program_event - Reprogram the clock event device.
+ * @expires:	absolute expiry time (monotonic clock)
+ *
+ * Returns 0 on success, -ETIME when the event is in the past.
+ */
+int clockevents_program_event(struct clock_event_device *dev, ktime_t expires,
+			      ktime_t now)
+{
+	unsigned long long clc;
+	int64_t delta;
+
+	delta = ktime_to_ns(ktime_sub(expires, now));
+
+	if (delta <= 0)
+		return -ETIME;
+
+	dev->next_event = expires;
+
+	if (dev->mode == CLOCK_EVT_MODE_SHUTDOWN)
+		return 0;
+
+	if (delta > dev->max_delta_ns)
+		delta = dev->max_delta_ns;
+	if (delta < dev->min_delta_ns)
+		delta = dev->min_delta_ns;
+
+	clc = delta * dev->mult;
+	clc >>= dev->shift;
+
+	return dev->set_next_event((unsigned long) clc, dev);
+}
+
+/**
+ * clockevents_register_notifier - register a clock events change listener
+ */
+int clockevents_register_notifier(struct notifier_block *nb)
+{
+	int ret;
+
+	spin_lock(&clockevents_lock);
+	ret = raw_notifier_chain_register(&clockevents_chain, nb);
+	spin_unlock(&clockevents_lock);
+
+	return ret;
+}
+
+/**
+ * clockevents_unregister_notifier - unregister a clock events change listener
+ */
+void clockevents_unregister_notifier(struct notifier_block *nb)
+{
+	spin_lock(&clockevents_lock);
+	raw_notifier_chain_unregister(&clockevents_chain, nb);
+	spin_unlock(&clockevents_lock);
+}
+
+/*
+ * Notify about a clock event change. Called with clockevents_lock
+ * held.
+ */
+static void clockevents_do_notify(unsigned long reason, void *dev)
+{
+	raw_notifier_call_chain(&clockevents_chain, reason, dev);
+}
+
+/*
+ * Called after a notify add to make devices availble which were
+ * released from the notifier call.
+ */
+static void clockevents_notify_released(void)
+{
+	struct clock_event_device *dev;
+
+	while (!list_empty(&clockevents_released)) {
+		dev = list_entry(clockevents_released.next,
+				 struct clock_event_device, list);
+		list_del(&dev->list);
+		list_add(&dev->list, &clockevent_devices);
+		clockevents_do_notify(CLOCK_EVT_NOTIFY_ADD, dev);
+	}
+}
+
+/**
+ * clockevents_register_device - register a clock event device
+ * @dev:	device to register
+ */
+void clockevents_register_device(struct clock_event_device *dev)
+{
+	BUG_ON(dev->mode != CLOCK_EVT_MODE_UNUSED);
+
+	spin_lock(&clockevents_lock);
+
+	list_add(&dev->list, &clockevent_devices);
+	clockevents_do_notify(CLOCK_EVT_NOTIFY_ADD, dev);
+	clockevents_notify_released();
+
+	spin_unlock(&clockevents_lock);
+}
+
+/*
+ * Noop handler when we shut down an event device
+ */
+static void clockevents_handle_noop(struct clock_event_device *dev)
+{
+}
+
+/**
+ * clockevents_exchange_device - release and request clock devices
+ * @old:	device to release (can be NULL)
+ * @new:	device to request (can be NULL)
+ *
+ * Called from the notifier chain. clockevents_lock is held already
+ */
+void clockevents_exchange_device(struct clock_event_device *old,
+				 struct clock_event_device *new)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+	/*
+	 * Caller releases a clock event device. We queue it into the
+	 * released list and do a notify add later.
+	 */
+	if (old) {
+		old->event_handler = clockevents_handle_noop;
+		clockevents_set_mode(old, CLOCK_EVT_MODE_UNUSED);
+		list_del(&old->list);
+		list_add(&old->list, &clockevents_released);
+	}
+
+	if (new) {
+		BUG_ON(new->mode != CLOCK_EVT_MODE_UNUSED);
+		clockevents_set_mode(new, CLOCK_EVT_MODE_SHUTDOWN);
+	}
+	local_irq_restore(flags);
+}
+
+/**
+ * clockevents_request_device
+ */
+struct clock_event_device *clockevents_request_device(unsigned int features,
+						      cpumask_t cpumask)
+{
+	struct clock_event_device *cur, *dev = NULL;
+	struct list_head *tmp;
+
+	spin_lock(&clockevents_lock);
+
+	list_for_each(tmp, &clockevent_devices) {
+		cur = list_entry(tmp, struct clock_event_device, list);
+
+		if ((cur->features & features) == features &&
+		    cpus_equal(cpumask, cur->cpumask)) {
+			if (!dev || dev->rating < cur->rating)
+				dev = cur;
+		}
+	}
+
+	clockevents_exchange_device(NULL, dev);
+
+	spin_unlock(&clockevents_lock);
+
+	return dev;
+}
+
+/**
+ * clockevents_release_device
+ */
+void clockevents_release_device(struct clock_event_device *dev)
+{
+	spin_lock(&clockevents_lock);
+
+	clockevents_exchange_device(dev, NULL);
+	clockevents_notify_released();
+
+	spin_unlock(&clockevents_lock);
+}
+
+/**
+ * clockevents_notify - notification about relevant events
+ */
+void clockevents_notify(unsigned long reason, void *arg)
+{
+	spin_lock(&clockevents_lock);
+	clockevents_do_notify(reason, arg);
+
+	switch (reason) {
+	case CLOCK_EVT_NOTIFY_CPU_DEAD:
+		/*
+		 * Unregister the clock event devices which were
+		 * released from the users in the notify chain.
+		 */
+		while (!list_empty(&clockevents_released)) {
+			struct clock_event_device *dev;
+
+			dev = list_entry(clockevents_released.next,
+					 struct clock_event_device, list);
+			list_del(&dev->list);
+		}
+		break;
+	default:
+		break;
+	}
+	spin_unlock(&clockevents_lock);
+}
+EXPORT_SYMBOL_GPL(clockevents_notify);
+
+#ifdef CONFIG_SYSFS
+
+/**
+ * clockevents_show_registered - sysfs interface for listing clockevents
+ * @dev:	unused
+ * @buf:	char buffer to be filled with clock events list
+ *
+ * Provides sysfs interface for listing registered clock event devices
+ */
+static ssize_t clockevents_show_registered(struct sys_device *dev, char *buf)
+{
+	struct list_head *tmp;
+	char *p = buf;
+	int cpu;
+
+	spin_lock(&clockevents_lock);
+
+	list_for_each(tmp, &clockevent_devices) {
+		struct clock_event_device *ce;
+
+		ce = list_entry(tmp, struct clock_event_device, list);
+		p += sprintf(p, "%-20s F:%04x M:%d", ce->name,
+			     ce->features, ce->mode);
+		p += sprintf(p, " C:");
+		if (!cpus_equal(ce->cpumask, cpu_possible_map)) {
+			for_each_cpu_mask(cpu, ce->cpumask)
+				p += sprintf(p, " %d", cpu);
+		} else {
+			/*
+			 * FIXME: Add the cpu which is handling this sucker
+			 */
+		}
+		p += sprintf(p, "\n");
+	}
+
+	spin_unlock(&clockevents_lock);
+
+	return p - buf;
+}
+
+/*
+ * Sysfs setup bits:
+ */
+static SYSDEV_ATTR(registered, 0600,
+		   clockevents_show_registered, NULL);
+
+static struct sysdev_class clockevents_sysclass = {
+	set_kset_name("clockevents"),
+};
+
+static struct sys_device clockevents_sys_device = {
+	.id	= 0,
+	.cls	= &clockevents_sysclass,
+};
+
+static int __init clockevents_sysfs_init(void)
+{
+	int error = sysdev_class_register(&clockevents_sysclass);
+
+	if (!error)
+		error = sysdev_register(&clockevents_sys_device);
+	if (!error)
+		error = sysdev_create_file(
+				&clockevents_sys_device,
+				&attr_registered);
+	return error;
+}
+device_initcall(clockevents_sysfs_init);
+#endif
