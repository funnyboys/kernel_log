commit 7e35e4eb7e56233dcf445992d7b835a9ba93408e
Author: Petr Mladek <pmladek@suse.com>
Date:   Wed Oct 30 16:43:09 2019 +0100

    livepatch: Keep replaced patches until post_patch callback is called
    
    Pre/post (un)patch callbacks might manipulate the system state. Cumulative
    livepatches might need to take over the changes made by the replaced
    ones. For this they might need to access some data stored or referenced
    by the old livepatches.
    
    Therefore the replaced livepatches have to stay around until post_patch()
    callback is called. It is achieved by calling the free functions later.
    It is the same location where disabled livepatches have already been
    freed.
    
    Link: http://lkml.kernel.org/r/20191030154313.13263-2-pmladek@suse.com
    To: Jiri Kosina <jikos@kernel.org>
    Cc: Kamalesh Babulal <kamalesh@linux.vnet.ibm.com>
    Cc: Nicolai Stange <nstange@suse.de>
    Cc: live-patching@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org
    Acked-by: Miroslav Benes <mbenes@suse.cz>
    Acked-by: Joe Lawrence <joe.lawrence@redhat.com>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Petr Mladek <pmladek@suse.com>

diff --git a/kernel/livepatch/core.h b/kernel/livepatch/core.h
index ec43a40b853f..38209c7361b6 100644
--- a/kernel/livepatch/core.h
+++ b/kernel/livepatch/core.h
@@ -13,8 +13,9 @@ extern struct list_head klp_patches;
 #define klp_for_each_patch(patch)	\
 	list_for_each_entry(patch, &klp_patches, list)
 
-void klp_free_patch_start(struct klp_patch *patch);
-void klp_discard_replaced_patches(struct klp_patch *new_patch);
+void klp_free_patch_async(struct klp_patch *patch);
+void klp_free_replaced_patches_async(struct klp_patch *new_patch);
+void klp_unpatch_replaced_patches(struct klp_patch *new_patch);
 void klp_discard_nops(struct klp_patch *new_patch);
 
 static inline bool klp_is_object_loaded(struct klp_object *obj)

commit ecba29f434a8fa333356d54d2491d174c4aab8de
Author: Petr Mladek <pmladek@suse.com>
Date:   Mon Feb 4 14:56:50 2019 +0100

    livepatch: Introduce klp_for_each_patch macro
    
    There are already macros to iterate over struct klp_func and klp_object.
    
    Add also klp_for_each_patch(). But make it internal because also
    klp_patches list is internal.
    
    Suggested-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Acked-by: Miroslav Benes <mbenes@suse.cz>
    Acked-by: Joe Lawrence <joe.lawrence@redhat.com>
    Signed-off-by: Petr Mladek <pmladek@suse.com>

diff --git a/kernel/livepatch/core.h b/kernel/livepatch/core.h
index e6200f38701f..ec43a40b853f 100644
--- a/kernel/livepatch/core.h
+++ b/kernel/livepatch/core.h
@@ -7,6 +7,12 @@
 extern struct mutex klp_mutex;
 extern struct list_head klp_patches;
 
+#define klp_for_each_patch_safe(patch, tmp_patch)		\
+	list_for_each_entry_safe(patch, tmp_patch, &klp_patches, list)
+
+#define klp_for_each_patch(patch)	\
+	list_for_each_entry(patch, &klp_patches, list)
+
 void klp_free_patch_start(struct klp_patch *patch);
 void klp_discard_replaced_patches(struct klp_patch *new_patch);
 void klp_discard_nops(struct klp_patch *new_patch);

commit d697bad588eb4e76311193e6eaacc7c7aaa5a4ba
Author: Petr Mladek <pmladek@suse.com>
Date:   Wed Jan 9 13:43:26 2019 +0100

    livepatch: Remove Nop structures when unused
    
    Replaced patches are removed from the stack when the transition is
    finished. It means that Nop structures will never be needed again
    and can be removed. Why should we care?
    
      + Nop structures give the impression that the function is patched
        even though the ftrace handler has no effect.
    
      + Ftrace handlers do not come for free. They cause slowdown that might
        be visible in some workloads. The ftrace-related slowdown might
        actually be the reason why the function is no longer patched in
        the new cumulative patch. One would expect that cumulative patch
        would help solve these problems as well.
    
      + Cumulative patches are supposed to replace any earlier version of
        the patch. The amount of NOPs depends on which version was replaced.
        This multiplies the amount of scenarios that might happen.
    
        One might say that NOPs are innocent. But there are even optimized
        NOP instructions for different processors, for example, see
        arch/x86/kernel/alternative.c. And klp_ftrace_handler() is much
        more complicated.
    
      + It sounds natural to clean up a mess that is no longer needed.
        It could only be worse if we do not do it.
    
    This patch allows to unpatch and free the dynamic structures independently
    when the transition finishes.
    
    The free part is a bit tricky because kobject free callbacks are called
    asynchronously. We could not wait for them easily. Fortunately, we do
    not have to. Any further access can be avoided by removing them from
    the dynamic lists.
    
    Signed-off-by: Petr Mladek <pmladek@suse.com>
    Acked-by: Miroslav Benes <mbenes@suse.cz>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/kernel/livepatch/core.h b/kernel/livepatch/core.h
index f6a853adcc00..e6200f38701f 100644
--- a/kernel/livepatch/core.h
+++ b/kernel/livepatch/core.h
@@ -9,6 +9,7 @@ extern struct list_head klp_patches;
 
 void klp_free_patch_start(struct klp_patch *patch);
 void klp_discard_replaced_patches(struct klp_patch *new_patch);
+void klp_discard_nops(struct klp_patch *new_patch);
 
 static inline bool klp_is_object_loaded(struct klp_object *obj)
 {

commit e1452b607c48c642caf57299f4da83aa002f8533
Author: Jason Baron <jbaron@akamai.com>
Date:   Wed Jan 9 13:43:25 2019 +0100

    livepatch: Add atomic replace
    
    Sometimes we would like to revert a particular fix. Currently, this
    is not easy because we want to keep all other fixes active and we
    could revert only the last applied patch.
    
    One solution would be to apply new patch that implemented all
    the reverted functions like in the original code. It would work
    as expected but there will be unnecessary redirections. In addition,
    it would also require knowing which functions need to be reverted at
    build time.
    
    Another problem is when there are many patches that touch the same
    functions. There might be dependencies between patches that are
    not enforced on the kernel side. Also it might be pretty hard to
    actually prepare the patch and ensure compatibility with the other
    patches.
    
    Atomic replace && cumulative patches:
    
    A better solution would be to create cumulative patch and say that
    it replaces all older ones.
    
    This patch adds a new "replace" flag to struct klp_patch. When it is
    enabled, a set of 'nop' klp_func will be dynamically created for all
    functions that are already being patched but that will no longer be
    modified by the new patch. They are used as a new target during
    the patch transition.
    
    The idea is to handle Nops' structures like the static ones. When
    the dynamic structures are allocated, we initialize all values that
    are normally statically defined.
    
    The only exception is "new_func" in struct klp_func. It has to point
    to the original function and the address is known only when the object
    (module) is loaded. Note that we really need to set it. The address is
    used, for example, in klp_check_stack_func().
    
    Nevertheless we still need to distinguish the dynamically allocated
    structures in some operations. For this, we add "nop" flag into
    struct klp_func and "dynamic" flag into struct klp_object. They
    need special handling in the following situations:
    
      + The structures are added into the lists of objects and functions
        immediately. In fact, the lists were created for this purpose.
    
      + The address of the original function is known only when the patched
        object (module) is loaded. Therefore it is copied later in
        klp_init_object_loaded().
    
      + The ftrace handler must not set PC to func->new_func. It would cause
        infinite loop because the address points back to the beginning of
        the original function.
    
      + The various free() functions must free the structure itself.
    
    Note that other ways to detect the dynamic structures are not considered
    safe. For example, even the statically defined struct klp_object might
    include empty funcs array. It might be there just to run some callbacks.
    
    Also note that the safe iterator must be used in the free() functions.
    Otherwise already freed structures might get accessed.
    
    Special callbacks handling:
    
    The callbacks from the replaced patches are _not_ called by intention.
    It would be pretty hard to define a reasonable semantic and implement it.
    
    It might even be counter-productive. The new patch is cumulative. It is
    supposed to include most of the changes from older patches. In most cases,
    it will not want to call pre_unpatch() post_unpatch() callbacks from
    the replaced patches. It would disable/break things for no good reasons.
    Also it should be easier to handle various scenarios in a single script
    in the new patch than think about interactions caused by running many
    scripts from older patches. Not to say that the old scripts even would
    not expect to be called in this situation.
    
    Removing replaced patches:
    
    One nice effect of the cumulative patches is that the code from the
    older patches is no longer used. Therefore the replaced patches can
    be removed. It has several advantages:
    
      + Nops' structs will no longer be necessary and might be removed.
        This would save memory, restore performance (no ftrace handler),
        allow clear view on what is really patched.
    
      + Disabling the patch will cause using the original code everywhere.
        Therefore the livepatch callbacks could handle only one scenario.
        Note that the complication is already complex enough when the patch
        gets enabled. It is currently solved by calling callbacks only from
        the new cumulative patch.
    
      + The state is clean in both the sysfs interface and lsmod. The modules
        with the replaced livepatches might even get removed from the system.
    
    Some people actually expected this behavior from the beginning. After all
    a cumulative patch is supposed to "completely" replace an existing one.
    It is like when a new version of an application replaces an older one.
    
    This patch does the first step. It removes the replaced patches from
    the list of patches. It is safe. The consistency model ensures that
    they are no longer used. By other words, each process works only with
    the structures from klp_transition_patch.
    
    The removal is done by a special function. It combines actions done by
    __disable_patch() and klp_complete_transition(). But it is a fast
    track without all the transaction-related stuff.
    
    Signed-off-by: Jason Baron <jbaron@akamai.com>
    [pmladek@suse.com: Split, reuse existing code, simplified]
    Signed-off-by: Petr Mladek <pmladek@suse.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Jessica Yu <jeyu@kernel.org>
    Cc: Jiri Kosina <jikos@kernel.org>
    Cc: Miroslav Benes <mbenes@suse.cz>
    Acked-by: Miroslav Benes <mbenes@suse.cz>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/kernel/livepatch/core.h b/kernel/livepatch/core.h
index d4eefc520c08..f6a853adcc00 100644
--- a/kernel/livepatch/core.h
+++ b/kernel/livepatch/core.h
@@ -8,6 +8,7 @@ extern struct mutex klp_mutex;
 extern struct list_head klp_patches;
 
 void klp_free_patch_start(struct klp_patch *patch);
+void klp_discard_replaced_patches(struct klp_patch *new_patch);
 
 static inline bool klp_is_object_loaded(struct klp_object *obj)
 {

commit 958ef1e39d24d6cb8bf2a7406130a98c9564230f
Author: Petr Mladek <pmladek@suse.com>
Date:   Wed Jan 9 13:43:23 2019 +0100

    livepatch: Simplify API by removing registration step
    
    The possibility to re-enable a registered patch was useful for immediate
    patches where the livepatch module had to stay until the system reboot.
    The improved consistency model allows to achieve the same result by
    unloading and loading the livepatch module again.
    
    Also we are going to add a feature called atomic replace. It will allow
    to create a patch that would replace all already registered patches.
    The aim is to handle dependent patches more securely. It will obsolete
    the stack of patches that helped to handle the dependencies so far.
    Then it might be unclear when a cumulative patch re-enabling is safe.
    
    It would be complicated to support the many modes. Instead we could
    actually make the API and code easier to understand.
    
    Therefore, remove the two step public API. All the checks and init calls
    are moved from klp_register_patch() to klp_enabled_patch(). Also the patch
    is automatically freed, including the sysfs interface when the transition
    to the disabled state is completed.
    
    As a result, there is never a disabled patch on the top of the stack.
    Therefore we do not need to check the stack in __klp_enable_patch().
    And we could simplify the check in __klp_disable_patch().
    
    Also the API and logic is much easier. It is enough to call
    klp_enable_patch() in module_init() call. The patch can be disabled
    by writing '0' into /sys/kernel/livepatch/<patch>/enabled. Then the module
    can be removed once the transition finishes and sysfs interface is freed.
    
    The only problem is how to free the structures and kobjects safely.
    The operation is triggered from the sysfs interface. We could not put
    the related kobject from there because it would cause lock inversion
    between klp_mutex and kernfs locks, see kn->count lockdep map.
    
    Therefore, offload the free task to a workqueue. It is perfectly fine:
    
      + The patch can no longer be used in the livepatch operations.
    
      + The module could not be removed until the free operation finishes
        and module_put() is called.
    
      + The operation is asynchronous already when the first
        klp_try_complete_transition() fails and another call
        is queued with a delay.
    
    Suggested-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Petr Mladek <pmladek@suse.com>
    Acked-by: Miroslav Benes <mbenes@suse.cz>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/kernel/livepatch/core.h b/kernel/livepatch/core.h
index d0cb5390e247..d4eefc520c08 100644
--- a/kernel/livepatch/core.h
+++ b/kernel/livepatch/core.h
@@ -7,6 +7,8 @@
 extern struct mutex klp_mutex;
 extern struct list_head klp_patches;
 
+void klp_free_patch_start(struct klp_patch *patch);
+
 static inline bool klp_is_object_loaded(struct klp_object *obj)
 {
 	return !obj->name || obj->mod;

commit 68007289bf3cd937a5b8fc4987d2787167bd06ca
Author: Petr Mladek <pmladek@suse.com>
Date:   Wed Jan 9 13:43:22 2019 +0100

    livepatch: Don't block the removal of patches loaded after a forced transition
    
    module_put() is currently never called in klp_complete_transition() when
    klp_force is set. As a result, we might keep the reference count even when
    klp_enable_patch() fails and klp_cancel_transition() is called.
    
    This might give the impression that a module might get blocked in some
    strange init state. Fortunately, it is not the case. The reference count
    is ignored when mod->init fails and erroneous modules are always removed.
    
    Anyway, this might be confusing. Instead, this patch moves
    the global klp_forced flag into struct klp_patch. As a result,
    we block only modules that might still be in use after a forced
    transition. Newly loaded livepatches might be eventually completely
    removed later.
    
    It is not a big deal. But the code is at least consistent with
    the reality.
    
    Signed-off-by: Petr Mladek <pmladek@suse.com>
    Acked-by: Joe Lawrence <joe.lawrence@redhat.com>
    Acked-by: Miroslav Benes <mbenes@suse.cz>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/kernel/livepatch/core.h b/kernel/livepatch/core.h
index 48a83d4364cf..d0cb5390e247 100644
--- a/kernel/livepatch/core.h
+++ b/kernel/livepatch/core.h
@@ -5,6 +5,7 @@
 #include <linux/livepatch.h>
 
 extern struct mutex klp_mutex;
+extern struct list_head klp_patches;
 
 static inline bool klp_is_object_loaded(struct klp_object *obj)
 {

commit 0ef76878cfcf4d6b64972b283021f576a95d9216
Merge: 9682b3dea221 fc41efc18430
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Nov 15 10:21:58 2017 -0800

    Merge branch 'for-linus' of ssh://gitolite.kernel.org/pub/scm/linux/kernel/git/jikos/livepatching
    
    Pull livepatching updates from Jiri Kosina:
    
     - shadow variables support, allowing livepatches to associate new
       "shadow" fields to existing data structures, from Joe Lawrence
    
     - pre/post patch callbacks API, allowing livepatch writers to register
       callbacks to be called before and after patch application, from Joe
       Lawrence
    
    * 'for-linus' of ssh://gitolite.kernel.org/pub/scm/linux/kernel/git/jikos/livepatching:
      livepatch: __klp_disable_patch() should never be called for disabled patches
      livepatch: Correctly call klp_post_unpatch_callback() in error paths
      livepatch: add transition notices
      livepatch: move transition "complete" notice into klp_complete_transition()
      livepatch: add (un)patch callbacks
      livepatch: Small shadow variable documentation fixes
      livepatch: __klp_shadow_get_or_alloc() is local to shadow.c
      livepatch: introduce shadow variable API

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/kernel/livepatch/core.h b/kernel/livepatch/core.h
index c74f24c47837..a351601d7f76 100644
--- a/kernel/livepatch/core.h
+++ b/kernel/livepatch/core.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _LIVEPATCH_CORE_H
 #define _LIVEPATCH_CORE_H
 

commit 5aaf1ab55389aeb6ce5527580a1a4d4dbc0f41ff
Author: Petr Mladek <pmladek@suse.com>
Date:   Fri Oct 20 16:56:50 2017 +0200

    livepatch: Correctly call klp_post_unpatch_callback() in error paths
    
    The post_unpatch_enabled flag in struct klp_callbacks is set when a
    pre-patch callback successfully executes, indicating that we need to
    call a corresponding post-unpatch callback when the patch is reverted.
    This is true for ordinary patch disable as well as the error paths of
    klp_patch_object() callers.
    
    As currently coded, we inadvertently execute the post-patch callback
    twice in klp_module_coming() when klp_patch_object() fails:
    
      - We explicitly call klp_post_unpatch_callback() for the failed object
      - We call it again for the same object (and all the others) via
        klp_cleanup_module_patches_limited()
    
    We should clear the flag in klp_post_unpatch_callback() to make
    sure that the callback is not called twice. It makes the API
    more safe.
    
    (We could have removed the callback from the former error path as it
    would be covered by the latter call, but I think that is is cleaner to
    clear the post_unpatch_enabled after its invoked. For example, someone
    might later decide to call the callback only when obj->patched flag is
    set.)
    
    There is another mistake in the error path of klp_coming_module() in
    which it skips the post-unpatch callback for the klp_transition_patch.
    However, the pre-patch callback was called even for this patch, so be
    sure to make the corresponding callbacks for all patches.
    
    Finally, I used this opportunity to make klp_pre_patch_callback() more
    readable.
    
    [jkosina@suse.cz: incorporate changelog wording changes proposed by Joe Lawrence]
    Signed-off-by: Petr Mladek <pmladek@suse.com>
    Acked-by: Joe Lawrence <joe.lawrence@redhat.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/kernel/livepatch/core.h b/kernel/livepatch/core.h
index 6fc907b54e71..cc3aa708e0b4 100644
--- a/kernel/livepatch/core.h
+++ b/kernel/livepatch/core.h
@@ -12,10 +12,10 @@ static inline bool klp_is_object_loaded(struct klp_object *obj)
 
 static inline int klp_pre_patch_callback(struct klp_object *obj)
 {
-	int ret;
+	int ret = 0;
 
-	ret = (obj->callbacks.pre_patch) ?
-		(*obj->callbacks.pre_patch)(obj) : 0;
+	if (obj->callbacks.pre_patch)
+		ret = (*obj->callbacks.pre_patch)(obj);
 
 	obj->callbacks.post_unpatch_enabled = !ret;
 
@@ -39,6 +39,8 @@ static inline void klp_post_unpatch_callback(struct klp_object *obj)
 	if (obj->callbacks.post_unpatch_enabled &&
 	    obj->callbacks.post_unpatch)
 		(*obj->callbacks.post_unpatch)(obj);
+
+	obj->callbacks.post_unpatch_enabled = false;
 }
 
 #endif /* _LIVEPATCH_CORE_H */

commit 93862e385ded7c60351e09fcd2a541d273650905
Author: Joe Lawrence <joe.lawrence@redhat.com>
Date:   Fri Oct 13 15:08:41 2017 -0400

    livepatch: add (un)patch callbacks
    
    Provide livepatch modules a klp_object (un)patching notification
    mechanism.  Pre and post-(un)patch callbacks allow livepatch modules to
    setup or synchronize changes that would be difficult to support in only
    patched-or-unpatched code contexts.
    
    Callbacks can be registered for target module or vmlinux klp_objects,
    but each implementation is klp_object specific.
    
      - Pre-(un)patch callbacks run before any (un)patching transition
        starts.
    
      - Post-(un)patch callbacks run once an object has been (un)patched and
        the klp_patch fully transitioned to its target state.
    
    Example use cases include modification of global data and registration
    of newly available services/handlers.
    
    See Documentation/livepatch/callbacks.txt for details and
    samples/livepatch/ for examples.
    
    Signed-off-by: Joe Lawrence <joe.lawrence@redhat.com>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Acked-by: Miroslav Benes <mbenes@suse.cz>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/kernel/livepatch/core.h b/kernel/livepatch/core.h
index c74f24c47837..6fc907b54e71 100644
--- a/kernel/livepatch/core.h
+++ b/kernel/livepatch/core.h
@@ -1,6 +1,44 @@
 #ifndef _LIVEPATCH_CORE_H
 #define _LIVEPATCH_CORE_H
 
+#include <linux/livepatch.h>
+
 extern struct mutex klp_mutex;
 
+static inline bool klp_is_object_loaded(struct klp_object *obj)
+{
+	return !obj->name || obj->mod;
+}
+
+static inline int klp_pre_patch_callback(struct klp_object *obj)
+{
+	int ret;
+
+	ret = (obj->callbacks.pre_patch) ?
+		(*obj->callbacks.pre_patch)(obj) : 0;
+
+	obj->callbacks.post_unpatch_enabled = !ret;
+
+	return ret;
+}
+
+static inline void klp_post_patch_callback(struct klp_object *obj)
+{
+	if (obj->callbacks.post_patch)
+		(*obj->callbacks.post_patch)(obj);
+}
+
+static inline void klp_pre_unpatch_callback(struct klp_object *obj)
+{
+	if (obj->callbacks.pre_unpatch)
+		(*obj->callbacks.pre_unpatch)(obj);
+}
+
+static inline void klp_post_unpatch_callback(struct klp_object *obj)
+{
+	if (obj->callbacks.post_unpatch_enabled &&
+	    obj->callbacks.post_unpatch)
+		(*obj->callbacks.post_unpatch)(obj);
+}
+
 #endif /* _LIVEPATCH_CORE_H */

commit 10517429b5ac242498d7d847f79f10c21d7eedb0
Author: Jiri Kosina <jkosina@suse.cz>
Date:   Wed Mar 8 14:27:05 2017 +0100

    livepatch: make klp_mutex proper part of API
    
    klp_mutex is shared between core.c and transition.c, and as such would
    rather be properly located in a header so that we don't have to play
    'extern' games from .c sources.
    
    This also silences sparse warning (wrongly) suggesting that klp_mutex
    should be defined static.
    
    Acked-by: Miroslav Benes <mbenes@suse.cz>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/kernel/livepatch/core.h b/kernel/livepatch/core.h
new file mode 100644
index 000000000000..c74f24c47837
--- /dev/null
+++ b/kernel/livepatch/core.h
@@ -0,0 +1,6 @@
+#ifndef _LIVEPATCH_CORE_H
+#define _LIVEPATCH_CORE_H
+
+extern struct mutex klp_mutex;
+
+#endif /* _LIVEPATCH_CORE_H */
