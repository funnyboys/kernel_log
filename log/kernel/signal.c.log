commit e91b48162332480f5840902268108bb7fb7a44c7
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Jun 30 17:32:54 2020 +0200

    task_work: teach task_work_add() to do signal_wake_up()
    
    So that the target task will exit the wait_event_interruptible-like
    loop and call task_work_run() asap.
    
    The patch turns "bool notify" into 0,TWA_RESUME,TWA_SIGNAL enum, the
    new TWA_SIGNAL flag implies signal_wake_up().  However, it needs to
    avoid the race with recalc_sigpending(), so the patch also adds the
    new JOBCTL_TASK_WORK bit included in JOBCTL_PENDING_MASK.
    
    TODO: once this patch is merged we need to change all current users
    of task_work_add(notify = true) to use TWA_RESUME.
    
    Cc: stable@vger.kernel.org # v5.7
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5ca48cc5da76..ee22ec78fd6d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2529,9 +2529,6 @@ bool get_signal(struct ksignal *ksig)
 	struct signal_struct *signal = current->signal;
 	int signr;
 
-	if (unlikely(current->task_works))
-		task_work_run();
-
 	if (unlikely(uprobe_deny_signal()))
 		return false;
 
@@ -2544,6 +2541,13 @@ bool get_signal(struct ksignal *ksig)
 
 relock:
 	spin_lock_irq(&sighand->siglock);
+	current->jobctl &= ~JOBCTL_TASK_WORK;
+	if (unlikely(current->task_works)) {
+		spin_unlock_irq(&sighand->siglock);
+		task_work_run();
+		goto relock;
+	}
+
 	/*
 	 * Every stopped thread goes here after wakeup. Check to see if
 	 * we should notify the parent, prepare_signal(SIGCONT) encodes

commit 8b39a57e965403c12a27d0859901a8a7d1d7318f
Merge: 062ea674ae8a 38cdabb7d835
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jun 1 16:21:46 2020 -0700

    Merge branch 'work.set_fs-exec' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull uaccess/coredump updates from Al Viro:
     "set_fs() removal in coredump-related area - mostly Christoph's
      stuff..."
    
    * 'work.set_fs-exec' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      binfmt_elf_fdpic: remove the set_fs(KERNEL_DS) in elf_fdpic_core_dump
      binfmt_elf: remove the set_fs(KERNEL_DS) in elf_core_dump
      binfmt_elf: remove the set_fs in fill_siginfo_note
      signal: refactor copy_siginfo_to_user32
      powerpc/spufs: simplify spufs core dumping
      powerpc/spufs: stop using access_ok
      powerpc/spufs: fix copy_to_user while atomic

commit c3b3f52476412a3899f2c65b220075aceb18dd2c
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue May 5 12:12:53 2020 +0200

    signal: refactor copy_siginfo_to_user32
    
    Factor out a copy_siginfo_to_external32 helper from
    copy_siginfo_to_user32 that fills out the compat_siginfo, but does so
    on a kernel space data structure.  With that we can let architectures
    override copy_siginfo_to_user32 with their own implementations using
    copy_siginfo_to_external32.  That allows moving the x32 SIGCHLD purely
    to x86 architecture code.
    
    As a nice side effect copy_siginfo_to_external32 also comes in handy
    for avoiding a set_fs() call in the coredump code later on.
    
    Contains improvements from Eric W. Biederman <ebiederm@xmission.com>
    and Arnd Bergmann <arnd@arndb.de>.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index e58a6c619824..2bc9458d40bd 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3235,94 +3235,94 @@ int copy_siginfo_from_user(kernel_siginfo_t *to, const siginfo_t __user *from)
 }
 
 #ifdef CONFIG_COMPAT
-int copy_siginfo_to_user32(struct compat_siginfo __user *to,
-			   const struct kernel_siginfo *from)
-#if defined(CONFIG_X86_X32_ABI) || defined(CONFIG_IA32_EMULATION)
-{
-	return __copy_siginfo_to_user32(to, from, in_x32_syscall());
-}
-int __copy_siginfo_to_user32(struct compat_siginfo __user *to,
-			     const struct kernel_siginfo *from, bool x32_ABI)
-#endif
+/**
+ * copy_siginfo_to_external32 - copy a kernel siginfo into a compat user siginfo
+ * @to: compat siginfo destination
+ * @from: kernel siginfo source
+ *
+ * Note: This function does not work properly for the SIGCHLD on x32, but
+ * fortunately it doesn't have to.  The only valid callers for this function are
+ * copy_siginfo_to_user32, which is overriden for x32 and the coredump code.
+ * The latter does not care because SIGCHLD will never cause a coredump.
+ */
+void copy_siginfo_to_external32(struct compat_siginfo *to,
+		const struct kernel_siginfo *from)
 {
-	struct compat_siginfo new;
-	memset(&new, 0, sizeof(new));
+	memset(to, 0, sizeof(*to));
 
-	new.si_signo = from->si_signo;
-	new.si_errno = from->si_errno;
-	new.si_code  = from->si_code;
+	to->si_signo = from->si_signo;
+	to->si_errno = from->si_errno;
+	to->si_code  = from->si_code;
 	switch(siginfo_layout(from->si_signo, from->si_code)) {
 	case SIL_KILL:
-		new.si_pid = from->si_pid;
-		new.si_uid = from->si_uid;
+		to->si_pid = from->si_pid;
+		to->si_uid = from->si_uid;
 		break;
 	case SIL_TIMER:
-		new.si_tid     = from->si_tid;
-		new.si_overrun = from->si_overrun;
-		new.si_int     = from->si_int;
+		to->si_tid     = from->si_tid;
+		to->si_overrun = from->si_overrun;
+		to->si_int     = from->si_int;
 		break;
 	case SIL_POLL:
-		new.si_band = from->si_band;
-		new.si_fd   = from->si_fd;
+		to->si_band = from->si_band;
+		to->si_fd   = from->si_fd;
 		break;
 	case SIL_FAULT:
-		new.si_addr = ptr_to_compat(from->si_addr);
+		to->si_addr = ptr_to_compat(from->si_addr);
 #ifdef __ARCH_SI_TRAPNO
-		new.si_trapno = from->si_trapno;
+		to->si_trapno = from->si_trapno;
 #endif
 		break;
 	case SIL_FAULT_MCEERR:
-		new.si_addr = ptr_to_compat(from->si_addr);
+		to->si_addr = ptr_to_compat(from->si_addr);
 #ifdef __ARCH_SI_TRAPNO
-		new.si_trapno = from->si_trapno;
+		to->si_trapno = from->si_trapno;
 #endif
-		new.si_addr_lsb = from->si_addr_lsb;
+		to->si_addr_lsb = from->si_addr_lsb;
 		break;
 	case SIL_FAULT_BNDERR:
-		new.si_addr = ptr_to_compat(from->si_addr);
+		to->si_addr = ptr_to_compat(from->si_addr);
 #ifdef __ARCH_SI_TRAPNO
-		new.si_trapno = from->si_trapno;
+		to->si_trapno = from->si_trapno;
 #endif
-		new.si_lower = ptr_to_compat(from->si_lower);
-		new.si_upper = ptr_to_compat(from->si_upper);
+		to->si_lower = ptr_to_compat(from->si_lower);
+		to->si_upper = ptr_to_compat(from->si_upper);
 		break;
 	case SIL_FAULT_PKUERR:
-		new.si_addr = ptr_to_compat(from->si_addr);
+		to->si_addr = ptr_to_compat(from->si_addr);
 #ifdef __ARCH_SI_TRAPNO
-		new.si_trapno = from->si_trapno;
+		to->si_trapno = from->si_trapno;
 #endif
-		new.si_pkey = from->si_pkey;
+		to->si_pkey = from->si_pkey;
 		break;
 	case SIL_CHLD:
-		new.si_pid    = from->si_pid;
-		new.si_uid    = from->si_uid;
-		new.si_status = from->si_status;
-#ifdef CONFIG_X86_X32_ABI
-		if (x32_ABI) {
-			new._sifields._sigchld_x32._utime = from->si_utime;
-			new._sifields._sigchld_x32._stime = from->si_stime;
-		} else
-#endif
-		{
-			new.si_utime = from->si_utime;
-			new.si_stime = from->si_stime;
-		}
+		to->si_pid = from->si_pid;
+		to->si_uid = from->si_uid;
+		to->si_status = from->si_status;
+		to->si_utime = from->si_utime;
+		to->si_stime = from->si_stime;
 		break;
 	case SIL_RT:
-		new.si_pid = from->si_pid;
-		new.si_uid = from->si_uid;
-		new.si_int = from->si_int;
+		to->si_pid = from->si_pid;
+		to->si_uid = from->si_uid;
+		to->si_int = from->si_int;
 		break;
 	case SIL_SYS:
-		new.si_call_addr = ptr_to_compat(from->si_call_addr);
-		new.si_syscall   = from->si_syscall;
-		new.si_arch      = from->si_arch;
+		to->si_call_addr = ptr_to_compat(from->si_call_addr);
+		to->si_syscall   = from->si_syscall;
+		to->si_arch      = from->si_arch;
 		break;
 	}
+}
 
+int __copy_siginfo_to_user32(struct compat_siginfo __user *to,
+			   const struct kernel_siginfo *from)
+{
+	struct compat_siginfo new;
+
+	copy_siginfo_to_external32(&new, from);
 	if (copy_to_user(to, &new, sizeof(struct compat_siginfo)))
 		return -EFAULT;
-
 	return 0;
 }
 

commit b4f633221f0aeac102e463a4be46a643b2e3b819
Merge: 25b1fa8dfb3f 61e713bdca36
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Apr 23 13:30:18 2020 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull SIGCHLD fix from Eric Biederman:
     "Christof Meerwald reported that do_notify_parent has not been
      successfully populating si_pid and si_uid for multi-threaded
      processes.
    
      This is the one-liner fix. Strictly speaking a one-liner plus
      comment"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace:
      signal: Avoid corrupting si_pid and si_uid in do_notify_parent

commit 61e713bdca3678e84815f2427f7a063fc353a1fc
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Apr 20 11:41:50 2020 -0500

    signal: Avoid corrupting si_pid and si_uid in do_notify_parent
    
    Christof Meerwald <cmeerw@cmeerw.org> writes:
    > Hi,
    >
    > this is probably related to commit
    > 7a0cf094944e2540758b7f957eb6846d5126f535 (signal: Correct namespace
    > fixups of si_pid and si_uid).
    >
    > With a 5.6.5 kernel I am seeing SIGCHLD signals that don't include a
    > properly set si_pid field - this seems to happen for multi-threaded
    > child processes.
    >
    > A simple test program (based on the sample from the signalfd man page):
    >
    > #include <sys/signalfd.h>
    > #include <signal.h>
    > #include <unistd.h>
    > #include <spawn.h>
    > #include <stdlib.h>
    > #include <stdio.h>
    >
    > #define handle_error(msg) \
    >     do { perror(msg); exit(EXIT_FAILURE); } while (0)
    >
    > int main(int argc, char *argv[])
    > {
    >   sigset_t mask;
    >   int sfd;
    >   struct signalfd_siginfo fdsi;
    >   ssize_t s;
    >
    >   sigemptyset(&mask);
    >   sigaddset(&mask, SIGCHLD);
    >
    >   if (sigprocmask(SIG_BLOCK, &mask, NULL) == -1)
    >     handle_error("sigprocmask");
    >
    >   pid_t chldpid;
    >   char *chldargv[] = { "./sfdclient", NULL };
    >   posix_spawn(&chldpid, "./sfdclient", NULL, NULL, chldargv, NULL);
    >
    >   sfd = signalfd(-1, &mask, 0);
    >   if (sfd == -1)
    >     handle_error("signalfd");
    >
    >   for (;;) {
    >     s = read(sfd, &fdsi, sizeof(struct signalfd_siginfo));
    >     if (s != sizeof(struct signalfd_siginfo))
    >       handle_error("read");
    >
    >     if (fdsi.ssi_signo == SIGCHLD) {
    >       printf("Got SIGCHLD %d %d %d %d\n",
    >           fdsi.ssi_status, fdsi.ssi_code,
    >           fdsi.ssi_uid, fdsi.ssi_pid);
    >       return 0;
    >     } else {
    >       printf("Read unexpected signal\n");
    >     }
    >   }
    > }
    >
    >
    > and a multi-threaded client to test with:
    >
    > #include <unistd.h>
    > #include <pthread.h>
    >
    > void *f(void *arg)
    > {
    >   sleep(100);
    > }
    >
    > int main()
    > {
    >   pthread_t t[8];
    >
    >   for (int i = 0; i != 8; ++i)
    >   {
    >     pthread_create(&t[i], NULL, f, NULL);
    >   }
    > }
    >
    > I tried to do a bit of debugging and what seems to be happening is
    > that
    >
    >   /* From an ancestor pid namespace? */
    >   if (!task_pid_nr_ns(current, task_active_pid_ns(t))) {
    >
    > fails inside task_pid_nr_ns because the check for "pid_alive" fails.
    >
    > This code seems to be called from do_notify_parent and there we
    > actually have "tsk != current" (I am assuming both are threads of the
    > current process?)
    
    I instrumented the code with a warning and received the following backtrace:
    > WARNING: CPU: 0 PID: 777 at kernel/pid.c:501 __task_pid_nr_ns.cold.6+0xc/0x15
    > Modules linked in:
    > CPU: 0 PID: 777 Comm: sfdclient Not tainted 5.7.0-rc1userns+ #2924
    > Hardware name: Bochs Bochs, BIOS Bochs 01/01/2011
    > RIP: 0010:__task_pid_nr_ns.cold.6+0xc/0x15
    > Code: ff 66 90 48 83 ec 08 89 7c 24 04 48 8d 7e 08 48 8d 74 24 04 e8 9a b6 44 00 48 83 c4 08 c3 48 c7 c7 59 9f ac 82 e8 c2 c4 04 00 <0f> 0b e9 3fd
    > RSP: 0018:ffffc9000042fbf8 EFLAGS: 00010046
    > RAX: 000000000000000c RBX: 0000000000000000 RCX: ffffc9000042faf4
    > RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffffffff81193d29
    > RBP: ffffc9000042fc18 R08: 0000000000000000 R09: 0000000000000001
    > R10: 000000100f938416 R11: 0000000000000309 R12: ffff8880b941c140
    > R13: 0000000000000000 R14: 0000000000000000 R15: ffff8880b941c140
    > FS:  0000000000000000(0000) GS:ffff8880bca00000(0000) knlGS:0000000000000000
    > CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    > CR2: 00007f2e8c0a32e0 CR3: 0000000002e10000 CR4: 00000000000006f0
    > Call Trace:
    >  send_signal+0x1c8/0x310
    >  do_notify_parent+0x50f/0x550
    >  release_task.part.21+0x4fd/0x620
    >  do_exit+0x6f6/0xaf0
    >  do_group_exit+0x42/0xb0
    >  get_signal+0x13b/0xbb0
    >  do_signal+0x2b/0x670
    >  ? __audit_syscall_exit+0x24d/0x2b0
    >  ? rcu_read_lock_sched_held+0x4d/0x60
    >  ? kfree+0x24c/0x2b0
    >  do_syscall_64+0x176/0x640
    >  ? trace_hardirqs_off_thunk+0x1a/0x1c
    >  entry_SYSCALL_64_after_hwframe+0x49/0xb3
    
    The immediate problem is as Christof noticed that "pid_alive(current) == false".
    This happens because do_notify_parent is called from the last thread to exit
    in a process after that thread has been reaped.
    
    The bigger issue is that do_notify_parent can be called from any
    process that manages to wait on a thread of a multi-threaded process
    from wait_task_zombie.  So any logic based upon current for
    do_notify_parent is just nonsense, as current can be pretty much
    anything.
    
    So change do_notify_parent to call __send_signal directly.
    
    Inspecting the code it appears this problem has existed since the pid
    namespace support started handling this case in 2.6.30.  This fix only
    backports to 7a0cf094944e ("signal: Correct namespace fixups of si_pid and si_uid")
    where the problem logic was moved out of __send_signal and into send_signal.
    
    Cc: stable@vger.kernel.org
    Fixes: 6588c1e3ff01 ("signals: SI_USER: Masquerade si_pid when crossing pid ns boundary")
    Ref: 921cf9f63089 ("signals: protect cinit from unblocked SIG_DFL signals")
    Link: https://lore.kernel.org/lkml/20200419201336.GI22017@edge.cmeerw.net/
    Reported-by: Christof Meerwald <cmeerw@cmeerw.org>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Christian Brauner <christian.brauner@ubuntu.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index e58a6c619824..7938c60e11dd 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1993,8 +1993,12 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 		if (psig->action[SIGCHLD-1].sa.sa_handler == SIG_IGN)
 			sig = 0;
 	}
+	/*
+	 * Send with __send_signal as si_pid and si_uid are in the
+	 * parent's namespaces.
+	 */
 	if (valid_signal(sig) && sig)
-		__group_send_sig_info(sig, &info, tsk->parent);
+		__send_signal(sig, &info, tsk->parent, PIDTYPE_TGID, false);
 	__wake_up_parent(tsk, tsk->parent);
 	spin_unlock_irqrestore(&psig->siglock, flags);
 

commit 3075afdf15b89a063f8d31c0db08a50472bb7faf
Author: Zhiqiang Liu <liuzhiqiang26@huawei.com>
Date:   Mon Mar 30 10:44:43 2020 +0800

    signal: use kill_proc_info instead of kill_pid_info in kill_something_info
    
    signal.c provides kill_proc_info, we can use it instead of kill_pid_info
    in kill_something_info func gracefully.
    
    Signed-off-by: Zhiqiang Liu <liuzhiqiang26@huawei.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Christian Brauner <christian.brauner@ubuntu.com>
    Link: https://lore.kernel.org/r/80236965-f0b5-c888-95ff-855bdec75bb3@huawei.com
    Signed-off-by: Christian Brauner <christian.brauner@ubuntu.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 3f94894d1253..713104884414 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1557,12 +1557,8 @@ static int kill_something_info(int sig, struct kernel_siginfo *info, pid_t pid)
 {
 	int ret;
 
-	if (pid > 0) {
-		rcu_read_lock();
-		ret = kill_pid_info(sig, info, find_vpid(pid));
-		rcu_read_unlock();
-		return ret;
-	}
+	if (pid > 0)
+		return kill_proc_info(sig, info, pid);
 
 	/* -INT_MIN is undefined.  Exclude this case to avoid a UBSAN warning */
 	if (pid == INT_MIN)

commit eaec2b0bd30690575c581eebffae64bfb7f684ac
Author: Zhiqiang Liu <liuzhiqiang26@huawei.com>
Date:   Mon Mar 30 10:18:33 2020 +0800

    signal: check sig before setting info in kill_pid_usb_asyncio
    
    In kill_pid_usb_asyncio, if signal is not valid, we do not need to
    set info struct.
    
    Signed-off-by: Zhiqiang Liu <liuzhiqiang26@huawei.com>
    Acked-by: Christian Brauner <christian.brauner@ubuntu.com>
    Link: https://lore.kernel.org/r/f525fd08-1cf7-fb09-d20c-4359145eb940@huawei.com
    Signed-off-by: Christian Brauner <christian.brauner@ubuntu.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index e58a6c619824..3f94894d1253 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1510,15 +1510,15 @@ int kill_pid_usb_asyncio(int sig, int errno, sigval_t addr,
 	unsigned long flags;
 	int ret = -EINVAL;
 
+	if (!valid_signal(sig))
+		return ret;
+
 	clear_siginfo(&info);
 	info.si_signo = sig;
 	info.si_errno = errno;
 	info.si_code = SI_ASYNCIO;
 	*((sigval_t *)&info.si_pid) = addr;
 
-	if (!valid_signal(sig))
-		return ret;
-
 	rcu_read_lock();
 	p = pid_task(pid, PIDTYPE_PID);
 	if (!p) {

commit d987ca1c6b7e22fbd30664111e85cec7aa66000d
Merge: 919dce24701f d1e7fd6462ca
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Apr 2 11:22:17 2020 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull exec/proc updates from Eric Biederman:
     "This contains two significant pieces of work: the work to sort out
      proc_flush_task, and the work to solve a deadlock between strace and
      exec.
    
      Fixing proc_flush_task so that it no longer requires a persistent
      mount makes improvements to proc possible. The removal of the
      persistent mount solves an old regression that that caused the hidepid
      mount option to only work on remount not on mount. The regression was
      found and reported by the Android folks. This further allows Alexey
      Gladkov's work making proc mount options specific to an individual
      mount of proc to move forward.
    
      The work on exec starts solving a long standing issue with exec that
      it takes mutexes of blocking userspace applications, which makes exec
      extremely deadlock prone. For the moment this adds a second mutex with
      a narrower scope that handles all of the easy cases. Which makes the
      tricky cases easy to spot. With a little luck the code to solve those
      deadlocks will be ready by next merge window"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (25 commits)
      signal: Extend exec_id to 64bits
      pidfd: Use new infrastructure to fix deadlocks in execve
      perf: Use new infrastructure to fix deadlocks in execve
      proc: io_accounting: Use new infrastructure to fix deadlocks in execve
      proc: Use new infrastructure to fix deadlocks in execve
      kernel/kcmp.c: Use new infrastructure to fix deadlocks in execve
      kernel: doc: remove outdated comment cred.c
      mm: docs: Fix a comment in process_vm_rw_core
      selftests/ptrace: add test cases for dead-locks
      exec: Fix a deadlock in strace
      exec: Add exec_update_mutex to replace cred_guard_mutex
      exec: Move exec_mmap right after de_thread in flush_old_exec
      exec: Move cleanup of posix timers on exec out of de_thread
      exec: Factor unshare_sighand out of de_thread and call it separately
      exec: Only compute current once in flush_old_exec
      pid: Improve the comment about waiting in zap_pid_ns_processes
      proc: Remove the now unnecessary internal mount of proc
      uml: Create a private mount of proc for mconsole
      uml: Don't consult current to find the proc_mnt in mconsole_proc
      proc: Use a list of inodes to flush from proc
      ...

commit d1e7fd6462ca9fc76650fbe6ca800e35b24267da
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Mar 30 19:01:04 2020 -0500

    signal: Extend exec_id to 64bits
    
    Replace the 32bit exec_id with a 64bit exec_id to make it impossible
    to wrap the exec_id counter.  With care an attacker can cause exec_id
    wrap and send arbitrary signals to a newly exec'd parent.  This
    bypasses the signal sending checks if the parent changes their
    credentials during exec.
    
    The severity of this problem can been seen that in my limited testing
    of a 32bit exec_id it can take as little as 19s to exec 65536 times.
    Which means that it can take as little as 14 days to wrap a 32bit
    exec_id.  Adam Zabrocki has succeeded wrapping the self_exe_id in 7
    days.  Even my slower timing is in the uptime of a typical server.
    Which means self_exec_id is simply a speed bump today, and if exec
    gets noticably faster self_exec_id won't even be a speed bump.
    
    Extending self_exec_id to 64bits introduces a problem on 32bit
    architectures where reading self_exec_id is no longer atomic and can
    take two read instructions.  Which means that is is possible to hit
    a window where the read value of exec_id does not match the written
    value.  So with very lucky timing after this change this still
    remains expoiltable.
    
    I have updated the update of exec_id on exec to use WRITE_ONCE
    and the read of exec_id in do_notify_parent to use READ_ONCE
    to make it clear that there is no locking between these two
    locations.
    
    Link: https://lore.kernel.org/kernel-hardening/20200324215049.GA3710@pi3.com.pl
    Fixes: 2.3.23pre2
    Cc: stable@vger.kernel.org
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9ad8dea93dbb..5383b562df85 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1926,7 +1926,7 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 		 * This is only possible if parent == real_parent.
 		 * Check if it has changed security domain.
 		 */
-		if (tsk->parent_exec_id != tsk->parent->self_exec_id)
+		if (tsk->parent_exec_id != READ_ONCE(tsk->parent->self_exec_id))
 			sig = SIGCHLD;
 	}
 

commit fda31c50292a5062332fa0343c084bd9f46604d9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Feb 24 12:47:14 2020 -0800

    signal: avoid double atomic counter increments for user accounting
    
    When queueing a signal, we increment both the users count of pending
    signals (for RLIMIT_SIGPENDING tracking) and we increment the refcount
    of the user struct itself (because we keep a reference to the user in
    the signal structure in order to correctly account for it when freeing).
    
    That turns out to be fairly expensive, because both of them are atomic
    updates, and particularly under extreme signal handling pressure on big
    machines, you can get a lot of cache contention on the user struct.
    That can then cause horrid cacheline ping-pong when you do these
    multiple accesses.
    
    So change the reference counting to only pin the user for the _first_
    pending signal, and to unpin it when the last pending signal is
    dequeued.  That means that when a user sees a lot of concurrent signal
    queuing - which is the only situation when this matters - the only
    atomic access needed is generally the 'sigpending' count update.
    
    This was noticed because of a particularly odd timing artifact on a
    dual-socket 96C/192T Cascade Lake platform: when you get into bad
    contention, on that machine for some reason seems to be much worse when
    the contention happens in the upper 32-byte half of the cacheline.
    
    As a result, the kernel test robot will-it-scale 'signal1' benchmark had
    an odd performance regression simply due to random alignment of the
    'struct user_struct' (and pointed to a completely unrelated and
    apparently nonsensical commit for the regression).
    
    Avoiding the double increments (and decrements on the dequeueing side,
    of course) makes for much less contention and hugely improved
    performance on that will-it-scale microbenchmark.
    
    Quoting Feng Tang:
    
     "It makes a big difference, that the performance score is tripled! bump
      from original 17000 to 54000. Also the gap between 5.0-rc6 and
      5.0-rc6+Jiri's patch is reduced to around 2%"
    
    [ The "2% gap" is the odd cacheline placement difference on that
      platform: under the extreme contention case, the effect of which half
      of the cacheline was hot was 5%, so with the reduced contention the
      odd timing artifact is reduced too ]
    
    It does help in the non-contended case too, but is not nearly as
    noticeable.
    
    Reported-and-tested-by: Feng Tang <feng.tang@intel.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Huang, Ying <ying.huang@intel.com>
    Cc: Philip Li <philip.li@intel.com>
    Cc: Andi Kleen <andi.kleen@intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9ad8dea93dbb..5b2396350dd1 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -413,27 +413,32 @@ __sigqueue_alloc(int sig, struct task_struct *t, gfp_t flags, int override_rlimi
 {
 	struct sigqueue *q = NULL;
 	struct user_struct *user;
+	int sigpending;
 
 	/*
 	 * Protect access to @t credentials. This can go away when all
 	 * callers hold rcu read lock.
+	 *
+	 * NOTE! A pending signal will hold on to the user refcount,
+	 * and we get/put the refcount only when the sigpending count
+	 * changes from/to zero.
 	 */
 	rcu_read_lock();
-	user = get_uid(__task_cred(t)->user);
-	atomic_inc(&user->sigpending);
+	user = __task_cred(t)->user;
+	sigpending = atomic_inc_return(&user->sigpending);
+	if (sigpending == 1)
+		get_uid(user);
 	rcu_read_unlock();
 
-	if (override_rlimit ||
-	    atomic_read(&user->sigpending) <=
-			task_rlimit(t, RLIMIT_SIGPENDING)) {
+	if (override_rlimit || likely(sigpending <= task_rlimit(t, RLIMIT_SIGPENDING))) {
 		q = kmem_cache_alloc(sigqueue_cachep, flags);
 	} else {
 		print_dropped_signal(sig);
 	}
 
 	if (unlikely(q == NULL)) {
-		atomic_dec(&user->sigpending);
-		free_uid(user);
+		if (atomic_dec_and_test(&user->sigpending))
+			free_uid(user);
 	} else {
 		INIT_LIST_HEAD(&q->list);
 		q->flags = 0;
@@ -447,8 +452,8 @@ static void __sigqueue_free(struct sigqueue *q)
 {
 	if (q->flags & SIGQUEUE_PREALLOC)
 		return;
-	atomic_dec(&q->user->sigpending);
-	free_uid(q->user);
+	if (atomic_dec_and_test(&q->user->sigpending))
+		free_uid(q->user);
 	kmem_cache_free(sigqueue_cachep, q);
 }
 

commit 913292c97d750fe4188b4f5aa770e5e0ca1e5a91
Author: Madhuparna Bhowmik <madhuparnabhowmik10@gmail.com>
Date:   Fri Jan 24 10:29:08 2020 +0530

    sched.h: Annotate sighand_struct with __rcu
    
    This patch fixes the following sparse errors by annotating the
    sighand_struct with __rcu
    
    kernel/fork.c:1511:9: error: incompatible types in comparison expression
    kernel/exit.c:100:19: error: incompatible types in comparison expression
    kernel/signal.c:1370:27: error: incompatible types in comparison expression
    
    This fix introduces the following sparse error in signal.c due to
    checking the sighand pointer without rcu primitives:
    
    kernel/signal.c:1386:21: error: incompatible types in comparison expression
    
    This new sparse error is also fixed in this patch.
    
    Signed-off-by: Madhuparna Bhowmik <madhuparnabhowmik10@gmail.com>
    Acked-by: Paul E. McKenney <paulmck@kernel.org>
    Link: https://lore.kernel.org/r/20200124045908.26389-1-madhuparnabhowmik10@gmail.com
    Signed-off-by: Christian Brauner <christian.brauner@ubuntu.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index bcd46f547db3..9ad8dea93dbb 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1383,7 +1383,7 @@ struct sighand_struct *__lock_task_sighand(struct task_struct *tsk,
 		 * must see ->sighand == NULL.
 		 */
 		spin_lock_irqsave(&sighand->siglock, *flags);
-		if (likely(sighand == tsk->sighand))
+		if (likely(sighand == rcu_access_pointer(tsk->sighand)))
 			break;
 		spin_unlock_irqrestore(&sighand->siglock, *flags);
 	}

commit 937c6b27c73e02cd4114f95f5c37ba2c29fadba1
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Oct 9 17:02:30 2019 +0200

    cgroup: freezer: call cgroup_enter_frozen() with preemption disabled in ptrace_stop()
    
    ptrace_stop() does preempt_enable_no_resched() to avoid the preemption,
    but after that cgroup_enter_frozen() does spin_lock/unlock and this adds
    another preemption point.
    
    Reported-and-tested-by: Bruce Ashfield <bruce.ashfield@gmail.com>
    Fixes: 76f969e8948d ("cgroup: cgroup v2 freezer")
    Cc: stable@vger.kernel.org # v5.2+
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Roman Gushchin <guro@fb.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index c4da1ef56fdf..bcd46f547db3 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2205,8 +2205,8 @@ static void ptrace_stop(int exit_code, int why, int clear_code, kernel_siginfo_t
 		 */
 		preempt_disable();
 		read_unlock(&tasklist_lock);
-		preempt_enable_no_resched();
 		cgroup_enter_frozen();
+		preempt_enable_no_resched();
 		freezable_schedule();
 		cgroup_leave_frozen(true);
 	} else {

commit c17112a5c413f20188da276c138484e7127cdc84
Merge: 4d856f72c10e 821cc7b0b205
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Sep 16 09:28:19 2019 -0700

    Merge tag 'core-process-v5.4' of git://git.kernel.org/pub/scm/linux/kernel/git/brauner/linux
    
    Pull pidfd/waitid updates from Christian Brauner:
     "This contains two features and various tests.
    
      First, it adds support for waiting on process through pidfds by adding
      the P_PIDFD type to the waitid() syscall. This completes the basic
      functionality of the pidfd api (cf. [1]). In the meantime we also have
      a new adition to the userspace projects that make use of the pidfd
      api. The qt project was nice enough to send a mail pointing out that
      they have a pr up to switch to the pidfd api (cf. [2]).
    
      Second, this tag contains an extension to the waitid() syscall to make
      it possible to wait on the current process group in a race free manner
      (even though the actual problem is very unlikely) by specifing 0
      together with the P_PGID type. This extension traces back to a
      discussion on the glibc development mailing list.
    
      There are also a range of tests for the features above. Additionally,
      the test-suite which detected the pidfd-polling race we fixed in [3]
      is included in this tag"
    
    [1] https://lwn.net/Articles/794707/
    [2] https://codereview.qt-project.org/c/qt/qtbase/+/108456
    [3] commit b191d6491be6 ("pidfd: fix a poll race when setting exit_state")
    
    * tag 'core-process-v5.4' of git://git.kernel.org/pub/scm/linux/kernel/git/brauner/linux:
      waitid: Add support for waiting for the current process group
      tests: add pidfd poll tests
      tests: move common definitions and functions into pidfd.h
      pidfd: add pidfd_wait tests
      pidfd: add P_PIDFD to waitid()

commit 33da8e7c814f77310250bb54a9db36a44c5de784
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Aug 16 12:33:54 2019 -0500

    signal: Allow cifs and drbd to receive their terminating signals
    
    My recent to change to only use force_sig for a synchronous events
    wound up breaking signal reception cifs and drbd.  I had overlooked
    the fact that by default kthreads start out with all signals set to
    SIG_IGN.  So a change I thought was safe turned out to have made it
    impossible for those kernel thread to catch their signals.
    
    Reverting the work on force_sig is a bad idea because what the code
    was doing was very much a misuse of force_sig.  As the way force_sig
    ultimately allowed the signal to happen was to change the signal
    handler to SIG_DFL.  Which after the first signal will allow userspace
    to send signals to these kernel threads.  At least for
    wake_ack_receiver in drbd that does not appear actively wrong.
    
    So correct this problem by adding allow_kernel_signal that will allow
    signals whose siginfo reports they were sent by the kernel through,
    but will not allow userspace generated signals, and update cifs and
    drbd to call allow_kernel_signal in an appropriate place so that their
    thread can receive this signal.
    
    Fixing things this way ensures that userspace won't be able to send
    signals and cause problems, that it is clear which signals the
    threads are expecting to receive, and it guarantees that nothing
    else in the system will be affected.
    
    This change was partly inspired by similar cifs and drbd patches that
    added allow_signal.
    
    Reported-by: ronnie sahlberg <ronniesahlberg@gmail.com>
    Reported-by: Christoph Böhmwalder <christoph.boehmwalder@linbit.com>
    Tested-by: Christoph Böhmwalder <christoph.boehmwalder@linbit.com>
    Cc: Steve French <smfrench@gmail.com>
    Cc: Philipp Reisner <philipp.reisner@linbit.com>
    Cc: David Laight <David.Laight@ACULAB.COM>
    Fixes: 247bc9470b1e ("cifs: fix rmmod regression in cifs.ko caused by force_sig changes")
    Fixes: 72abe3bcf091 ("signal/cifs: Fix cifs_put_tcp_session to call send_sig instead of force_sig")
    Fixes: fee109901f39 ("signal/drbd: Use send_sig not force_sig")
    Fixes: 3cf5d076fb4d ("signal: Remove task parameter from force_sig")
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index e667be6907d7..534fec266a33 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -90,6 +90,11 @@ static bool sig_task_ignored(struct task_struct *t, int sig, bool force)
 	    handler == SIG_DFL && !(force && sig_kernel_only(sig)))
 		return true;
 
+	/* Only allow kernel generated signals to this kthread */
+	if (unlikely((t->flags & PF_KTHREAD) &&
+		     (handler == SIG_KTHREAD_KERNEL) && !force))
+		return true;
+
 	return sig_handler_ignored(handler, sig);
 }
 

commit 68d8681e97bd1c90259f341c1695af05002070ef
Author: Mauro Carvalho Chehab <mchehab+samsung@kernel.org>
Date:   Fri Aug 2 21:48:33 2019 -0700

    kernel/signal.c: fix a kernel-doc markup
    
    The kernel-doc parser doesn't handle expressions with %foo*.  Instead,
    when an asterisk should be part of a constant, it uses an alternative
    notation: `foo*`.
    
    Link: http://lkml.kernel.org/r/7f18c2e0b5e39e6b7eb55ddeb043b8b260b49f2d.1563361575.git.mchehab+samsung@kernel.org
    Signed-off-by: Mauro Carvalho Chehab <mchehab+samsung@kernel.org>
    Cc: Deepa Dinamani <deepa.kernel@gmail.com>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 349f5a67f100..e667be6907d7 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -349,7 +349,7 @@ void task_clear_jobctl_pending(struct task_struct *task, unsigned long mask)
  * @task has %JOBCTL_STOP_PENDING set and is participating in a group stop.
  * Group stop states are cleared and the group stop count is consumed if
  * %JOBCTL_STOP_CONSUME was set.  If the consumption completes the group
- * stop, the appropriate %SIGNAL_* flags are set.
+ * stop, the appropriate `SIGNAL_*` flags are set.
  *
  * CONTEXT:
  * Must be called with @task->sighand->siglock held.

commit 3695eae5fee0605f316fbaad0b9e3de791d7dfaf
Author: Christian Brauner <christian.brauner@ubuntu.com>
Date:   Sun Jul 28 00:22:29 2019 +0200

    pidfd: add P_PIDFD to waitid()
    
    This adds the P_PIDFD type to waitid().
    One of the last remaining bits for the pidfd api is to make it possible
    to wait on pidfds. With P_PIDFD added to waitid() the parts of userspace
    that want to use the pidfd api to exclusively manage processes can do so
    now.
    
    One of the things this will unblock in the future is the ability to make
    it possible to retrieve the exit status via waitid(P_PIDFD) for
    non-parent processes if handed a _suitable_ pidfd that has this feature
    set. This is similar to what you can do on FreeBSD with kqueue(). It
    might even end up being possible to wait on a process as a non-parent if
    an appropriate property is enabled on the pidfd.
    
    With P_PIDFD no scoping of the process identified by the pidfd is
    possible, i.e. it explicitly blocks things such as wait4(-1), wait4(0),
    waitid(P_ALL), waitid(P_PGID) etc. It only allows for semantics
    equivalent to wait4(pid), waitid(P_PID). Users that need scoping should
    rely on pid-based wait*() syscalls for now.
    
    Signed-off-by: Christian Brauner <christian.brauner@ubuntu.com>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Joel Fernandes (Google) <joel@joelfernandes.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Jann Horn <jannh@google.com>
    Cc: Andy Lutomirsky <luto@kernel.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Aleksa Sarai <cyphar@cyphar.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Link: https://lore.kernel.org/r/20190727222229.6516-2-christian@brauner.io

diff --git a/kernel/signal.c b/kernel/signal.c
index 91b789dd6e72..2e567f64812f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3672,8 +3672,11 @@ static int copy_siginfo_from_user_any(kernel_siginfo_t *kinfo, siginfo_t *info)
 
 static struct pid *pidfd_to_pid(const struct file *file)
 {
-	if (file->f_op == &pidfd_fops)
-		return file->private_data;
+	struct pid *pid;
+
+	pid = pidfd_pid(file);
+	if (!IS_ERR(pid))
+		return pid;
 
 	return tgid_pidfd_to_pid(file);
 }

commit 1caf7d50f46bd0388e38e653b146aa81700e8eb8
Author: Joel Fernandes (Google) <joel@joelfernandes.org>
Date:   Wed Jul 24 12:48:16 2019 -0400

    pidfd: Add warning if exit_state is 0 during notification
    
    Previously a condition got missed where the pidfd waiters are awakened
    before the exit_state gets set. This can result in a missed notification
    [1] and the polling thread waiting forever.
    
    It is fixed now, however it would be nice to avoid this kind of issue
    going unnoticed in the future. So just add a warning to catch it in the
    future.
    
    /* References */
    [1]: https://lore.kernel.org/lkml/20190717172100.261204-1-joel@joelfernandes.org/
    
    Signed-off-by: Joel Fernandes (Google) <joel@joelfernandes.org>
    Link: https://lore.kernel.org/r/20190724164816.201099-1-joel@joelfernandes.org
    Signed-off-by: Christian Brauner <christian@brauner.io>

diff --git a/kernel/signal.c b/kernel/signal.c
index 91b789dd6e72..349f5a67f100 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1885,6 +1885,7 @@ static void do_notify_pidfd(struct task_struct *task)
 {
 	struct pid *pid;
 
+	WARN_ON(task->exit_state == 0);
 	pid = task_pid(task);
 	wake_up_all(&pid->wait_pidfd);
 }

commit b772434be0891ed1081a08ae7cfd4666728f8e82
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Jul 16 16:29:53 2019 -0700

    signal: simplify set_user_sigmask/restore_user_sigmask
    
    task->saved_sigmask and ->restore_sigmask are only used in the ret-from-
    syscall paths.  This means that set_user_sigmask() can save ->blocked in
    ->saved_sigmask and do set_restore_sigmask() to indicate that ->blocked
    was modified.
    
    This way the callers do not need 2 sigset_t's passed to set/restore and
    restore_user_sigmask() renamed to restore_saved_sigmask_unless() turns
    into the trivial helper which just calls restore_saved_sigmask().
    
    Link: http://lkml.kernel.org/r/20190606113206.GA9464@redhat.com
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Deepa Dinamani <deepa.kernel@gmail.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: Eric Wong <e@80x24.org>
    Cc: Jason Baron <jbaron@akamai.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: David Laight <David.Laight@aculab.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index dabe100d2091..91b789dd6e72 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2951,80 +2951,49 @@ EXPORT_SYMBOL(sigprocmask);
  *
  * This is useful for syscalls such as ppoll, pselect, io_pgetevents and
  * epoll_pwait where a new sigmask is passed from userland for the syscalls.
+ *
+ * Note that it does set_restore_sigmask() in advance, so it must be always
+ * paired with restore_saved_sigmask_unless() before return from syscall.
  */
-int set_user_sigmask(const sigset_t __user *usigmask, sigset_t *set,
-		     sigset_t *oldset, size_t sigsetsize)
+int set_user_sigmask(const sigset_t __user *umask, size_t sigsetsize)
 {
-	if (!usigmask)
-		return 0;
+	sigset_t kmask;
 
+	if (!umask)
+		return 0;
 	if (sigsetsize != sizeof(sigset_t))
 		return -EINVAL;
-	if (copy_from_user(set, usigmask, sizeof(sigset_t)))
+	if (copy_from_user(&kmask, umask, sizeof(sigset_t)))
 		return -EFAULT;
 
-	*oldset = current->blocked;
-	set_current_blocked(set);
+	set_restore_sigmask();
+	current->saved_sigmask = current->blocked;
+	set_current_blocked(&kmask);
 
 	return 0;
 }
-EXPORT_SYMBOL(set_user_sigmask);
 
 #ifdef CONFIG_COMPAT
-int set_compat_user_sigmask(const compat_sigset_t __user *usigmask,
-			    sigset_t *set, sigset_t *oldset,
+int set_compat_user_sigmask(const compat_sigset_t __user *umask,
 			    size_t sigsetsize)
 {
-	if (!usigmask)
-		return 0;
+	sigset_t kmask;
 
+	if (!umask)
+		return 0;
 	if (sigsetsize != sizeof(compat_sigset_t))
 		return -EINVAL;
-	if (get_compat_sigset(set, usigmask))
+	if (get_compat_sigset(&kmask, umask))
 		return -EFAULT;
 
-	*oldset = current->blocked;
-	set_current_blocked(set);
+	set_restore_sigmask();
+	current->saved_sigmask = current->blocked;
+	set_current_blocked(&kmask);
 
 	return 0;
 }
-EXPORT_SYMBOL(set_compat_user_sigmask);
 #endif
 
-/*
- * restore_user_sigmask:
- * usigmask: sigmask passed in from userland.
- * sigsaved: saved sigmask when the syscall started and changed the sigmask to
- *           usigmask.
- *
- * This is useful for syscalls such as ppoll, pselect, io_pgetevents and
- * epoll_pwait where a new sigmask is passed in from userland for the syscalls.
- */
-void restore_user_sigmask(const void __user *usigmask, sigset_t *sigsaved,
-				bool interrupted)
-{
-
-	if (!usigmask)
-		return;
-	/*
-	 * When signals are pending, do not restore them here.
-	 * Restoring sigmask here can lead to delivering signals that the above
-	 * syscalls are intended to block because of the sigmask passed in.
-	 */
-	if (interrupted) {
-		current->saved_sigmask = *sigsaved;
-		set_restore_sigmask();
-		return;
-	}
-
-	/*
-	 * This is needed because the fast syscall return path does not restore
-	 * saved_sigmask when signals are not pending.
-	 */
-	set_current_blocked(sigsaved);
-}
-EXPORT_SYMBOL(restore_user_sigmask);
-
 /**
  *  sys_rt_sigprocmask - change the list of currently blocked signals
  *  @how: whether to add, remove, or set signals

commit 5450e8a316a64cddcbc15f90733ebc78aa736545
Merge: 29cd581b5949 172bb24a4f48
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 10 22:17:21 2019 -0700

    Merge tag 'pidfd-updates-v5.3' of git://git.kernel.org/pub/scm/linux/kernel/git/brauner/linux
    
    Pull pidfd updates from Christian Brauner:
     "This adds two main features.
    
       - First, it adds polling support for pidfds. This allows process
         managers to know when a (non-parent) process dies in a race-free
         way.
    
         The notification mechanism used follows the same logic that is
         currently used when the parent of a task is notified of a child's
         death. With this patchset it is possible to put pidfds in an
         {e}poll loop and get reliable notifications for process (i.e.
         thread-group) exit.
    
       - The second feature compliments the first one by making it possible
         to retrieve pollable pidfds for processes that were not created
         using CLONE_PIDFD.
    
         A lot of processes get created with traditional PID-based calls
         such as fork() or clone() (without CLONE_PIDFD). For these
         processes a caller can currently not create a pollable pidfd. This
         is a problem for Android's low memory killer (LMK) and service
         managers such as systemd.
    
      Both patchsets are accompanied by selftests.
    
      It's perhaps worth noting that the work done so far and the work done
      in this branch for pidfd_open() and polling support do already see
      some adoption:
    
       - Android is in the process of backporting this work to all their LTS
         kernels [1]
    
       - Service managers make use of pidfd_send_signal but will need to
         wait until we enable waiting on pidfds for full adoption.
    
       - And projects I maintain make use of both pidfd_send_signal and
         CLONE_PIDFD [2] and will use polling support and pidfd_open() too"
    
    [1] https://android-review.googlesource.com/q/topic:%22pidfd+polling+support+4.9+backport%22
        https://android-review.googlesource.com/q/topic:%22pidfd+polling+support+4.14+backport%22
        https://android-review.googlesource.com/q/topic:%22pidfd+polling+support+4.19+backport%22
    
    [2] https://github.com/lxc/lxc/blob/aab6e3eb73c343231cdde775db938994fc6f2803/src/lxc/start.c#L1753
    
    * tag 'pidfd-updates-v5.3' of git://git.kernel.org/pub/scm/linux/kernel/git/brauner/linux:
      tests: add pidfd_open() tests
      arch: wire-up pidfd_open()
      pid: add pidfd_open()
      pidfd: add polling selftests
      pidfd: add polling support

commit 5ad18b2e60b75c7297a998dea702451d33a052ed
Merge: 92c1d6522135 318759b4737c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 8 21:48:15 2019 -0700

    Merge branch 'siginfo-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull force_sig() argument change from Eric Biederman:
     "A source of error over the years has been that force_sig has taken a
      task parameter when it is only safe to use force_sig with the current
      task.
    
      The force_sig function is built for delivering synchronous signals
      such as SIGSEGV where the userspace application caused a synchronous
      fault (such as a page fault) and the kernel responded with a signal.
    
      Because the name force_sig does not make this clear, and because the
      force_sig takes a task parameter the function force_sig has been
      abused for sending other kinds of signals over the years. Slowly those
      have been fixed when the oopses have been tracked down.
    
      This set of changes fixes the remaining abusers of force_sig and
      carefully rips out the task parameter from force_sig and friends
      making this kind of error almost impossible in the future"
    
    * 'siginfo-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (27 commits)
      signal/x86: Move tsk inside of CONFIG_MEMORY_FAILURE in do_sigbus
      signal: Remove the signal number and task parameters from force_sig_info
      signal: Factor force_sig_info_to_task out of force_sig_info
      signal: Generate the siginfo in force_sig
      signal: Move the computation of force into send_signal and correct it.
      signal: Properly set TRACE_SIGNAL_LOSE_INFO in __send_signal
      signal: Remove the task parameter from force_sig_fault
      signal: Use force_sig_fault_to_task for the two calls that don't deliver to current
      signal: Explicitly call force_sig_fault on current
      signal/unicore32: Remove tsk parameter from __do_user_fault
      signal/arm: Remove tsk parameter from __do_user_fault
      signal/arm: Remove tsk parameter from ptrace_break
      signal/nds32: Remove tsk parameter from send_sigtrap
      signal/riscv: Remove tsk parameter from do_trap
      signal/sh: Remove tsk parameter from force_sig_info_fault
      signal/um: Remove task parameter from send_sigtrap
      signal/x86: Remove task parameter from send_sigtrap
      signal: Remove task parameter from force_sig_mceerr
      signal: Remove task parameter from force_sig
      signal: Remove task parameter from force_sigsegv
      ...

commit 61fc5771f5e729a2ce235af42f69c8506725e84a
Merge: 884922591e2b 839d05e41385
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 8 18:55:42 2019 -0700

    Merge tag 'audit-pr-20190702' of git://git.kernel.org/pub/scm/linux/kernel/git/pcmoore/audit
    
    Pull audit updates from Paul Moore:
     "This pull request is a bit early, but with some vacation time coming
      up I wanted to send this out now just in case the remote Internet Gods
      decide not to smile on me once the merge window opens. The patchset
      for v5.3 is pretty minor this time, the highlights include:
    
       - When the audit daemon is sent a signal, ensure we deliver
         information about the sender even when syscall auditing is not
         enabled/supported.
    
       - Add the ability to filter audit records based on network address
         family.
    
       - Tighten the audit field filtering restrictions on string based
         fields.
    
       - Cleanup the audit field filtering verification code.
    
       - Remove a few BUG() calls from the audit code"
    
    * tag 'audit-pr-20190702' of git://git.kernel.org/pub/scm/linux/kernel/git/pcmoore/audit:
      audit: remove the BUG() calls in the audit rule comparison functions
      audit: enforce op for string fields
      audit: add saddr_fam filter field
      audit: re-structure audit field valid checks
      audit: deliver signal_info regarless of syscall

commit 97abc889ee296faf95ca0e978340fb7b942a3e32
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Jun 28 12:06:50 2019 -0700

    signal: remove the wrong signal_pending() check in restore_user_sigmask()
    
    This is the minimal fix for stable, I'll send cleanups later.
    
    Commit 854a6ed56839 ("signal: Add restore_user_sigmask()") introduced
    the visible change which breaks user-space: a signal temporary unblocked
    by set_user_sigmask() can be delivered even if the caller returns
    success or timeout.
    
    Change restore_user_sigmask() to accept the additional "interrupted"
    argument which should be used instead of signal_pending() check, and
    update the callers.
    
    Eric said:
    
    : For clarity.  I don't think this is required by posix, or fundamentally to
    : remove the races in select.  It is what linux has always done and we have
    : applications who care so I agree this fix is needed.
    :
    : Further in any case where the semantic change that this patch rolls back
    : (aka where allowing a signal to be delivered and the select like call to
    : complete) would be advantage we can do as well if not better by using
    : signalfd.
    :
    : Michael is there any chance we can get this guarantee of the linux
    : implementation of pselect and friends clearly documented.  The guarantee
    : that if the system call completes successfully we are guaranteed that no
    : signal that is unblocked by using sigmask will be delivered?
    
    Link: http://lkml.kernel.org/r/20190604134117.GA29963@redhat.com
    Fixes: 854a6ed56839a40f6b5d02a2962f48841482eec4 ("signal: Add restore_user_sigmask()")
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reported-by: Eric Wong <e@80x24.org>
    Tested-by: Eric Wong <e@80x24.org>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Deepa Dinamani <deepa.kernel@gmail.com>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: Jason Baron <jbaron@akamai.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: David Laight <David.Laight@ACULAB.COM>
    Cc: <stable@vger.kernel.org>    [5.0+]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index d622eac9d169..edf8915ddd54 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2912,7 +2912,8 @@ EXPORT_SYMBOL(set_compat_user_sigmask);
  * This is useful for syscalls such as ppoll, pselect, io_pgetevents and
  * epoll_pwait where a new sigmask is passed in from userland for the syscalls.
  */
-void restore_user_sigmask(const void __user *usigmask, sigset_t *sigsaved)
+void restore_user_sigmask(const void __user *usigmask, sigset_t *sigsaved,
+				bool interrupted)
 {
 
 	if (!usigmask)
@@ -2922,7 +2923,7 @@ void restore_user_sigmask(const void __user *usigmask, sigset_t *sigsaved)
 	 * Restoring sigmask here can lead to delivering signals that the above
 	 * syscalls are intended to block because of the sigmask passed in.
 	 */
-	if (signal_pending(current)) {
+	if (interrupted) {
 		current->saved_sigmask = *sigsaved;
 		set_restore_sigmask();
 		return;

commit b53b0b9d9a613c418057f6cb921c2f40a6f78c24
Author: Joel Fernandes (Google) <joel@joelfernandes.org>
Date:   Tue Apr 30 12:21:53 2019 -0400

    pidfd: add polling support
    
    This patch adds polling support to pidfd.
    
    Android low memory killer (LMK) needs to know when a process dies once
    it is sent the kill signal. It does so by checking for the existence of
    /proc/pid which is both racy and slow. For example, if a PID is reused
    between when LMK sends a kill signal and checks for existence of the
    PID, since the wrong PID is now possibly checked for existence.
    Using the polling support, LMK will be able to get notified when a process
    exists in race-free and fast way, and allows the LMK to do other things
    (such as by polling on other fds) while awaiting the process being killed
    to die.
    
    For notification to polling processes, we follow the same existing
    mechanism in the kernel used when the parent of the task group is to be
    notified of a child's death (do_notify_parent). This is precisely when the
    tasks waiting on a poll of pidfd are also awakened in this patch.
    
    We have decided to include the waitqueue in struct pid for the following
    reasons:
    1. The wait queue has to survive for the lifetime of the poll. Including
       it in task_struct would not be option in this case because the task can
       be reaped and destroyed before the poll returns.
    
    2. By including the struct pid for the waitqueue means that during
       de_thread(), the new thread group leader automatically gets the new
       waitqueue/pid even though its task_struct is different.
    
    Appropriate test cases are added in the second patch to provide coverage of
    all the cases the patch is handling.
    
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Daniel Colascione <dancol@google.com>
    Cc: Jann Horn <jannh@google.com>
    Cc: Tim Murray <timmurray@google.com>
    Cc: Jonathan Kowalski <bl0pbl33p@gmail.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: kernel-team@android.com
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Co-developed-by: Daniel Colascione <dancol@google.com>
    Signed-off-by: Daniel Colascione <dancol@google.com>
    Signed-off-by: Joel Fernandes (Google) <joel@joelfernandes.org>
    Signed-off-by: Christian Brauner <christian@brauner.io>

diff --git a/kernel/signal.c b/kernel/signal.c
index a1eb44dc9ff5..1c86b78a7597 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1803,6 +1803,14 @@ int send_sigqueue(struct sigqueue *q, struct pid *pid, enum pid_type type)
 	return ret;
 }
 
+static void do_notify_pidfd(struct task_struct *task)
+{
+	struct pid *pid;
+
+	pid = task_pid(task);
+	wake_up_all(&pid->wait_pidfd);
+}
+
 /*
  * Let a parent know about the death of a child.
  * For a stopped/continued status change, use do_notify_parent_cldstop instead.
@@ -1826,6 +1834,9 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 	BUG_ON(!tsk->ptrace &&
 	       (tsk->group_leader != tsk || !thread_group_empty(tsk)));
 
+	/* Wake up all pidfd waiters */
+	do_notify_pidfd(tsk);
+
 	if (sig != SIGCHLD) {
 		/*
 		 * This is only possible if parent == real_parent.

commit c732327f04a3818f35fa97d07b1d64d31b691d78
Author: Christian Brauner <christian@brauner.io>
Date:   Tue Jun 4 15:18:43 2019 +0200

    signal: improve comments
    
    Improve the comments for pidfd_send_signal().
    First, the comment still referred to a file descriptor for a process as a
    "task file descriptor" which stems from way back at the beginning of the
    discussion. Replace this with "pidfd" for consistency.
    Second, the wording for the explanation of the arguments to the syscall
    was a bit inconsistent, e.g. some used the past tense some used present
    tense. Make the wording more consistent.
    
    Signed-off-by: Christian Brauner <christian@brauner.io>

diff --git a/kernel/signal.c b/kernel/signal.c
index 328a01e1a2f0..d622eac9d169 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3621,12 +3621,11 @@ static struct pid *pidfd_to_pid(const struct file *file)
 }
 
 /**
- * sys_pidfd_send_signal - send a signal to a process through a task file
- *                          descriptor
- * @pidfd:  the file descriptor of the process
- * @sig:    signal to be sent
- * @info:   the signal info
- * @flags:  future flags to be passed
+ * sys_pidfd_send_signal - Signal a process through a pidfd
+ * @pidfd:  file descriptor of the process
+ * @sig:    signal to send
+ * @info:   signal info
+ * @flags:  future flags
  *
  * The syscall currently only signals via PIDTYPE_PID which covers
  * kill(<positive-pid>, <signal>. It does not signal threads or process

commit 98af37d624ed8c83f1953b1b6b2f6866011fc064
Author: Zhenliang Wei <weizhenliang@huawei.com>
Date:   Fri May 31 22:30:52 2019 -0700

    kernel/signal.c: trace_signal_deliver when signal_group_exit
    
    In the fixes commit, removing SIGKILL from each thread signal mask and
    executing "goto fatal" directly will skip the call to
    "trace_signal_deliver".  At this point, the delivery tracking of the
    SIGKILL signal will be inaccurate.
    
    Therefore, we need to add trace_signal_deliver before "goto fatal" after
    executing sigdelset.
    
    Note: SEND_SIG_NOINFO matches the fact that SIGKILL doesn't have any info.
    
    Link: http://lkml.kernel.org/r/20190425025812.91424-1-weizhenliang@huawei.com
    Fixes: cf43a757fd4944 ("signal: Restore the stop PTRACE_EVENT_EXIT")
    Signed-off-by: Zhenliang Wei <weizhenliang@huawei.com>
    Reviewed-by: Christian Brauner <christian@brauner.io>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Ivan Delalande <colona@arista.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Deepa Dinamani <deepa.kernel@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index d7b9d14ac80d..328a01e1a2f0 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2485,6 +2485,8 @@ bool get_signal(struct ksignal *ksig)
 	if (signal_group_exit(signal)) {
 		ksig->info.si_signo = signr = SIGKILL;
 		sigdelset(&current->pending.signal, SIGKILL);
+		trace_signal_deliver(SIGKILL, SEND_SIG_NOINFO,
+				&sighand->action[SIGKILL - 1]);
 		recalc_sigpending();
 		goto fatal;
 	}

commit a89e9b8abf82725e4ac96100e07c8104dbe8a240
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed May 15 10:11:09 2019 -0500

    signal: Remove the signal number and task parameters from force_sig_info
    
    force_sig_info always delivers to the current task and the signal
    parameter always matches info.si_signo.  So remove those parameters to
    make it a simpler less error prone interface, and to make it clear
    that none of the callers are doing anything clever.
    
    This guarantees that force_sig_info will not grow any new buggy
    callers that attempt to call force_sig on a non-current task, or that
    pass an signal number that does not match info.si_signo.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0984158cd41a..ff6944e4964e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1325,9 +1325,9 @@ force_sig_info_to_task(struct kernel_siginfo *info, struct task_struct *t)
 	return ret;
 }
 
-int force_sig_info(int sig, struct kernel_siginfo *info, struct task_struct *t)
+int force_sig_info(struct kernel_siginfo *info)
 {
-	return force_sig_info_to_task(info, t);
+	return force_sig_info_to_task(info, current);
 }
 
 /*
@@ -1619,7 +1619,7 @@ void force_sig(int sig)
 	info.si_code = SI_KERNEL;
 	info.si_pid = 0;
 	info.si_uid = 0;
-	force_sig_info(info.si_signo, &info, current);
+	force_sig_info(&info);
 }
 EXPORT_SYMBOL(force_sig);
 
@@ -1708,7 +1708,7 @@ int force_sig_mceerr(int code, void __user *addr, short lsb)
 	info.si_code = code;
 	info.si_addr = addr;
 	info.si_addr_lsb = lsb;
-	return force_sig_info(info.si_signo, &info, current);
+	return force_sig_info(&info);
 }
 
 int send_sig_mceerr(int code, void __user *addr, short lsb, struct task_struct *t)
@@ -1737,7 +1737,7 @@ int force_sig_bnderr(void __user *addr, void __user *lower, void __user *upper)
 	info.si_addr  = addr;
 	info.si_lower = lower;
 	info.si_upper = upper;
-	return force_sig_info(info.si_signo, &info, current);
+	return force_sig_info(&info);
 }
 
 #ifdef SEGV_PKUERR
@@ -1751,7 +1751,7 @@ int force_sig_pkuerr(void __user *addr, u32 pkey)
 	info.si_code  = SEGV_PKUERR;
 	info.si_addr  = addr;
 	info.si_pkey  = pkey;
-	return force_sig_info(info.si_signo, &info, current);
+	return force_sig_info(&info);
 }
 #endif
 
@@ -1767,7 +1767,7 @@ int force_sig_ptrace_errno_trap(int errno, void __user *addr)
 	info.si_errno = errno;
 	info.si_code  = TRAP_HWBKPT;
 	info.si_addr  = addr;
-	return force_sig_info(info.si_signo, &info, current);
+	return force_sig_info(&info);
 }
 
 int kill_pgrp(struct pid *pid, int sig, int priv)

commit 59c0e696a6c0fe6a8d718a43aecd72347db6a7f0
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Feb 7 11:01:20 2019 -0600

    signal: Factor force_sig_info_to_task out of force_sig_info
    
    All callers of force_sig_info pass info.si_signo in for the signal
    by definition as well as in practice.
    
    Further all callers of force_sig_info except force_sig_fault_to_task
    pass current as the target task to force_sig_info.
    
    Factor out a static force_sig_info_to_task that
    force_sig_fault_to_task can call.
    
    This prepares the way for force_sig_info to have it's task and signal
    parameters removed.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index d5f9ed5da9c5..0984158cd41a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1294,12 +1294,13 @@ int do_send_sig_info(int sig, struct kernel_siginfo *info, struct task_struct *p
  * We don't want to have recursive SIGSEGV's etc, for example,
  * that is why we also clear SIGNAL_UNKILLABLE.
  */
-int
-force_sig_info(int sig, struct kernel_siginfo *info, struct task_struct *t)
+static int
+force_sig_info_to_task(struct kernel_siginfo *info, struct task_struct *t)
 {
 	unsigned long int flags;
 	int ret, blocked, ignored;
 	struct k_sigaction *action;
+	int sig = info->si_signo;
 
 	spin_lock_irqsave(&t->sighand->siglock, flags);
 	action = &t->sighand->action[sig-1];
@@ -1324,6 +1325,11 @@ force_sig_info(int sig, struct kernel_siginfo *info, struct task_struct *t)
 	return ret;
 }
 
+int force_sig_info(int sig, struct kernel_siginfo *info, struct task_struct *t)
+{
+	return force_sig_info_to_task(info, t);
+}
+
 /*
  * Nuke all other threads in the group.
  */
@@ -1656,7 +1662,7 @@ int force_sig_fault_to_task(int sig, int code, void __user *addr
 	info.si_flags = flags;
 	info.si_isr = isr;
 #endif
-	return force_sig_info(info.si_signo, &info, t);
+	return force_sig_info_to_task(&info, t);
 }
 
 int force_sig_fault(int sig, int code, void __user *addr

commit ffafd23b2cf14093b559c3e33b427058ce8aa577
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue May 14 19:17:47 2019 -0500

    signal: Generate the siginfo in force_sig
    
    In preparation for removing the special case in force_sig_info for
    only having a signal number generate an appropriate siginfo in
    force_sig the last caller of force_sig_info that does not
    pass a filled out siginfo.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0da35880261e..d5f9ed5da9c5 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1605,7 +1605,15 @@ EXPORT_SYMBOL(send_sig);
 
 void force_sig(int sig)
 {
-	force_sig_info(sig, SEND_SIG_PRIV, current);
+	struct kernel_siginfo info;
+
+	clear_siginfo(&info);
+	info.si_signo = sig;
+	info.si_errno = 0;
+	info.si_code = SI_KERNEL;
+	info.si_pid = 0;
+	info.si_uid = 0;
+	force_sig_info(info.si_signo, &info, current);
 }
 EXPORT_SYMBOL(force_sig);
 

commit 8ad23dea808042ffb8bb1b45111af6ddc1bac5d3
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed May 15 22:23:32 2019 -0500

    signal: Move the computation of force into send_signal and correct it.
    
    Forcing a signal or not allowing a pid namespace init to ignore
    SIGKILL or SIGSTOP is more cleanly computed in send_signal.
    
    There are two cases where we don't allow a pid namespace init
    to ignore SIGKILL or SIGSTOP.  If the sending process is
    from an ancestor pid namespace and as such is effectively
    the god to the target process, and if the it is the kernel
    that is sending the signal, not another application.
    
    It is known that a process is from an ancestor pid namespace if
    it can see it's target but it's target does not have a pid for
    the sender in it's pid namespace.
    
    It is know that a signal is sent from the kernel if si_code is set to
    SI_KERNEL or info is SEND_SIG_PRIV (which ultimately generates
    a signal with si_code == SI_KERNEL).
    
    The only signals that matter are SIGKILL and SIGSTOP neither of
    which can really be caught, and both of which always have a siginfo
    layout that includes si_uid and si_pid.  Therefore we never need
    to worry about forcing a signal when si_pid and si_uid are absent.
    
    So handle the two special cases of info and the case when si_pid and
    si_uid are present.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index b2f0cf3a68aa..0da35880261e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1057,7 +1057,7 @@ static inline bool legacy_queue(struct sigpending *signals, int sig)
 }
 
 static int __send_signal(int sig, struct kernel_siginfo *info, struct task_struct *t,
-			enum pid_type type, int from_ancestor_ns)
+			enum pid_type type, bool force)
 {
 	struct sigpending *pending;
 	struct sigqueue *q;
@@ -1067,8 +1067,7 @@ static int __send_signal(int sig, struct kernel_siginfo *info, struct task_struc
 	assert_spin_locked(&t->sighand->siglock);
 
 	result = TRACE_SIGNAL_IGNORED;
-	if (!prepare_signal(sig, t,
-			from_ancestor_ns || (info == SEND_SIG_PRIV)))
+	if (!prepare_signal(sig, t, force))
 		goto ret;
 
 	pending = (type != PIDTYPE_PID) ? &t->signal->shared_pending : &t->pending;
@@ -1198,13 +1197,17 @@ static inline bool has_si_pid_and_uid(struct kernel_siginfo *info)
 static int send_signal(int sig, struct kernel_siginfo *info, struct task_struct *t,
 			enum pid_type type)
 {
-	int from_ancestor_ns = 0;
-
-#ifdef CONFIG_PID_NS
-	from_ancestor_ns = si_fromuser(info) &&
-			   !task_pid_nr_ns(current, task_active_pid_ns(t));
-#endif
-	if (!is_si_special(info) && has_si_pid_and_uid(info)) {
+	/* Should SIGKILL or SIGSTOP be received by a pid namespace init? */
+	bool force = false;
+
+	if (info == SEND_SIG_NOINFO) {
+		/* Force if sent from an ancestor pid namespace */
+		force = !task_pid_nr_ns(current, task_active_pid_ns(t));
+	} else if (info == SEND_SIG_PRIV) {
+		/* Don't ignore kernel generated signals */
+		force = true;
+	} else if (has_si_pid_and_uid(info)) {
+		/* SIGKILL and SIGSTOP is special or has ids */
 		struct user_namespace *t_user_ns;
 
 		rcu_read_lock();
@@ -1215,10 +1218,16 @@ static int send_signal(int sig, struct kernel_siginfo *info, struct task_struct
 		}
 		rcu_read_unlock();
 
-		if (!task_pid_nr_ns(current, task_active_pid_ns(t)))
+		/* A kernel generated signal? */
+		force = (info->si_code == SI_KERNEL);
+
+		/* From an ancestor pid namespace? */
+		if (!task_pid_nr_ns(current, task_active_pid_ns(t))) {
 			info->si_pid = 0;
+			force = true;
+		}
 	}
-	return __send_signal(sig, info, t, type, from_ancestor_ns);
+	return __send_signal(sig, info, t, type, force);
 }
 
 static void print_fatal_signal(int signr)
@@ -1509,7 +1518,7 @@ int kill_pid_usb_asyncio(int sig, int errno, sigval_t addr,
 
 	if (sig) {
 		if (lock_task_sighand(p, &flags)) {
-			ret = __send_signal(sig, &info, p, PIDTYPE_TGID, 0);
+			ret = __send_signal(sig, &info, p, PIDTYPE_TGID, false);
 			unlock_task_sighand(p, &flags);
 		} else
 			ret = -ESRCH;

commit 8917bef336f5301edd616cfa97b97d0319fd0496
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed May 15 22:56:17 2019 -0500

    signal: Properly set TRACE_SIGNAL_LOSE_INFO in __send_signal
    
    Any time siginfo is not stored in the signal queue information is
    lost.  Therefore set TRACE_SIGNAL_LOSE_INFO every time the code does
    not allocate a signal queue entry, and a queue overflow abort is not
    triggered.
    
    Fixes: ba005e1f4172 ("tracepoint: Add signal loss events")
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index d92b636b4e9d..b2f0cf3a68aa 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1131,23 +1131,22 @@ static int __send_signal(int sig, struct kernel_siginfo *info, struct task_struc
 			copy_siginfo(&q->info, info);
 			break;
 		}
-	} else if (!is_si_special(info)) {
-		if (sig >= SIGRTMIN && info->si_code != SI_USER) {
-			/*
-			 * Queue overflow, abort.  We may abort if the
-			 * signal was rt and sent by user using something
-			 * other than kill().
-			 */
-			result = TRACE_SIGNAL_OVERFLOW_FAIL;
-			ret = -EAGAIN;
-			goto ret;
-		} else {
-			/*
-			 * This is a silent loss of information.  We still
-			 * send the signal, but the *info bits are lost.
-			 */
-			result = TRACE_SIGNAL_LOSE_INFO;
-		}
+	} else if (!is_si_special(info) &&
+		   sig >= SIGRTMIN && info->si_code != SI_USER) {
+		/*
+		 * Queue overflow, abort.  We may abort if the
+		 * signal was rt and sent by user using something
+		 * other than kill().
+		 */
+		result = TRACE_SIGNAL_OVERFLOW_FAIL;
+		ret = -EAGAIN;
+		goto ret;
+	} else {
+		/*
+		 * This is a silent loss of information.  We still
+		 * send the signal, but the *info bits are lost.
+		 */
+		result = TRACE_SIGNAL_LOSE_INFO;
 	}
 
 out_set:

commit 2e1661d2673667d886cd40ad9f414cb6db48d8da
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu May 23 11:04:24 2019 -0500

    signal: Remove the task parameter from force_sig_fault
    
    As synchronous exceptions really only make sense against the current
    task (otherwise how are you synchronous) remove the task parameter
    from from force_sig_fault to make it explicit that is what is going
    on.
    
    The two known exceptions that deliver a synchronous exception to a
    stopped ptraced task have already been changed to
    force_sig_fault_to_task.
    
    The callers have been changed with the following emacs regular expression
    (with obvious variations on the architectures that take more arguments)
    to avoid typos:
    
    force_sig_fault[(]\([^,]+\)[,]\([^,]+\)[,]\([^,]+\)[,]\W+current[)]
    ->
    force_sig_fault(\1,\2,\3)
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index e420489ac4c9..d92b636b4e9d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1645,12 +1645,11 @@ int force_sig_fault_to_task(int sig, int code, void __user *addr
 
 int force_sig_fault(int sig, int code, void __user *addr
 	___ARCH_SI_TRAPNO(int trapno)
-	___ARCH_SI_IA64(int imm, unsigned int flags, unsigned long isr)
-	, struct task_struct *t)
+	___ARCH_SI_IA64(int imm, unsigned int flags, unsigned long isr))
 {
 	return force_sig_fault_to_task(sig, code, addr
 				       ___ARCH_SI_TRAPNO(trapno)
-				       ___ARCH_SI_IA64(imm, flags, isr), t);
+				       ___ARCH_SI_IA64(imm, flags, isr), current);
 }
 
 int send_sig_fault(int sig, int code, void __user *addr

commit 91ca180dbdd687d45fe4aab055b02d29c91b90df
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Feb 6 16:39:13 2019 -0600

    signal: Use force_sig_fault_to_task for the two calls that don't deliver to current
    
    In preparation for removing the task parameter from force_sig_fault
    introduce force_sig_fault_to_task and use it for the two cases where
    it matters.
    
    On mips force_fcr31_sig calls force_sig_fault and is called on either
    the current task, or a task that is suspended and is being switched to
    by the scheduler.  This is safe because the task being switched to by
    the scheduler is guaranteed to be suspended.  This ensures that
    task->sighand is stable while the signal is delivered to it.
    
    On parisc user_enable_single_step calls force_sig_fault and is in turn
    called by ptrace_request.  The function ptrace_request always calls
    user_enable_single_step on a child that is stopped for tracing.  The
    child being traced and not reaped ensures that child->sighand is not
    NULL, and that the child will not change child->sighand.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 398489facf9f..e420489ac4c9 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1620,7 +1620,7 @@ void force_sigsegv(int sig)
 	force_sig(SIGSEGV);
 }
 
-int force_sig_fault(int sig, int code, void __user *addr
+int force_sig_fault_to_task(int sig, int code, void __user *addr
 	___ARCH_SI_TRAPNO(int trapno)
 	___ARCH_SI_IA64(int imm, unsigned int flags, unsigned long isr)
 	, struct task_struct *t)
@@ -1643,6 +1643,16 @@ int force_sig_fault(int sig, int code, void __user *addr
 	return force_sig_info(info.si_signo, &info, t);
 }
 
+int force_sig_fault(int sig, int code, void __user *addr
+	___ARCH_SI_TRAPNO(int trapno)
+	___ARCH_SI_IA64(int imm, unsigned int flags, unsigned long isr)
+	, struct task_struct *t)
+{
+	return force_sig_fault_to_task(sig, code, addr
+				       ___ARCH_SI_TRAPNO(trapno)
+				       ___ARCH_SI_IA64(imm, flags, isr), t);
+}
+
 int send_sig_fault(int sig, int code, void __user *addr
 	___ARCH_SI_TRAPNO(int trapno)
 	___ARCH_SI_IA64(int imm, unsigned int flags, unsigned long isr)

commit f8eac9011b6be56acfb5d1d0dfd5ee30082a12ee
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Feb 5 18:14:19 2019 -0600

    signal: Remove task parameter from force_sig_mceerr
    
    All of the callers pass current into force_sig_mceer so remove the
    task parameter to make this obvious.
    
    This also makes it clear that force_sig_mceerr passes current
    into force_sig_info.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 20878c4c28c2..398489facf9f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1666,7 +1666,7 @@ int send_sig_fault(int sig, int code, void __user *addr
 	return send_sig_info(info.si_signo, &info, t);
 }
 
-int force_sig_mceerr(int code, void __user *addr, short lsb, struct task_struct *t)
+int force_sig_mceerr(int code, void __user *addr, short lsb)
 {
 	struct kernel_siginfo info;
 
@@ -1677,7 +1677,7 @@ int force_sig_mceerr(int code, void __user *addr, short lsb, struct task_struct
 	info.si_code = code;
 	info.si_addr = addr;
 	info.si_addr_lsb = lsb;
-	return force_sig_info(info.si_signo, &info, t);
+	return force_sig_info(info.si_signo, &info, current);
 }
 
 int send_sig_mceerr(int code, void __user *addr, short lsb, struct task_struct *t)

commit 3cf5d076fb4d48979f382bc9452765bf8b79e740
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu May 23 10:17:27 2019 -0500

    signal: Remove task parameter from force_sig
    
    All of the remaining callers pass current into force_sig so
    remove the task parameter to make this obvious and to make
    misuse more difficult in the future.
    
    This also makes it clear force_sig passes current into force_sig_info.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index f7669d240ce4..20878c4c28c2 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1595,9 +1595,9 @@ send_sig(int sig, struct task_struct *p, int priv)
 }
 EXPORT_SYMBOL(send_sig);
 
-void force_sig(int sig, struct task_struct *p)
+void force_sig(int sig)
 {
-	force_sig_info(sig, SEND_SIG_PRIV, p);
+	force_sig_info(sig, SEND_SIG_PRIV, current);
 }
 EXPORT_SYMBOL(force_sig);
 
@@ -1617,7 +1617,7 @@ void force_sigsegv(int sig)
 		p->sighand->action[sig - 1].sa.sa_handler = SIG_DFL;
 		spin_unlock_irqrestore(&p->sighand->siglock, flags);
 	}
-	force_sig(SIGSEGV, p);
+	force_sig(SIGSEGV);
 }
 
 int force_sig_fault(int sig, int code, void __user *addr

commit cb44c9a0ab21a9ae4dfcabac1ed8e38aa872d1af
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue May 21 10:03:48 2019 -0500

    signal: Remove task parameter from force_sigsegv
    
    The function force_sigsegv is always called on the current task
    so passing in current is redundant and not passing in current
    makes this fact obvious.
    
    This also makes it clear force_sigsegv always calls force_sig
    on the current task.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 39a3eca5ce22..f7669d240ce4 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1607,8 +1607,10 @@ EXPORT_SYMBOL(force_sig);
  * the problem was already a SIGSEGV, we'll want to
  * make sure we don't even try to deliver the signal..
  */
-void force_sigsegv(int sig, struct task_struct *p)
+void force_sigsegv(int sig)
 {
+	struct task_struct *p = current;
+
 	if (sig == SIGSEGV) {
 		unsigned long flags;
 		spin_lock_irqsave(&p->sighand->siglock, flags);
@@ -2717,7 +2719,7 @@ static void signal_delivered(struct ksignal *ksig, int stepping)
 void signal_setup_done(int failed, struct ksignal *ksig, int stepping)
 {
 	if (failed)
-		force_sigsegv(ksig->sig, current);
+		force_sigsegv(ksig->sig);
 	else
 		signal_delivered(ksig, stepping);
 }

commit 7a0cf094944e2540758b7f957eb6846d5126f535
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed May 15 22:54:56 2019 -0500

    signal: Correct namespace fixups of si_pid and si_uid
    
    The function send_signal was split from __send_signal so that it would
    be possible to bypass the namespace logic based upon current[1].  As it
    turns out the si_pid and the si_uid fixup are both inappropriate in
    the case of kill_pid_usb_asyncio so move that logic into send_signal.
    
    It is difficult to arrange but possible for a signal with an si_code
    of SI_TIMER or SI_SIGIO to be sent across namespace boundaries.  In
    which case tests for when it is ok to change si_pid and si_uid based
    on SI_FROMUSER are incorrect.  Replace the use of SI_FROMUSER with a
    new test has_si_pid_and_used based on siginfo_layout.
    
    Now that the uid fixup is no longer present after expanding
    SEND_SIG_NOINFO properly calculate the si_uid that the target
    task needs to read.
    
    [1] 7978b567d315 ("signals: add from_ancestor_ns parameter to send_signal()")
    Cc: stable@vger.kernel.org
    Fixes: 6588c1e3ff01 ("signals: SI_USER: Masquerade si_pid when crossing pid ns boundary")
    Fixes: 6b550f949594 ("user namespace: make signal.c respect user namespaces")
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 18040d6bd63a..39a3eca5ce22 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1056,27 +1056,6 @@ static inline bool legacy_queue(struct sigpending *signals, int sig)
 	return (sig < SIGRTMIN) && sigismember(&signals->signal, sig);
 }
 
-#ifdef CONFIG_USER_NS
-static inline void userns_fixup_signal_uid(struct kernel_siginfo *info, struct task_struct *t)
-{
-	if (current_user_ns() == task_cred_xxx(t, user_ns))
-		return;
-
-	if (SI_FROMKERNEL(info))
-		return;
-
-	rcu_read_lock();
-	info->si_uid = from_kuid_munged(task_cred_xxx(t, user_ns),
-					make_kuid(current_user_ns(), info->si_uid));
-	rcu_read_unlock();
-}
-#else
-static inline void userns_fixup_signal_uid(struct kernel_siginfo *info, struct task_struct *t)
-{
-	return;
-}
-#endif
-
 static int __send_signal(int sig, struct kernel_siginfo *info, struct task_struct *t,
 			enum pid_type type, int from_ancestor_ns)
 {
@@ -1134,7 +1113,11 @@ static int __send_signal(int sig, struct kernel_siginfo *info, struct task_struc
 			q->info.si_code = SI_USER;
 			q->info.si_pid = task_tgid_nr_ns(current,
 							task_active_pid_ns(t));
-			q->info.si_uid = from_kuid_munged(current_user_ns(), current_uid());
+			rcu_read_lock();
+			q->info.si_uid =
+				from_kuid_munged(task_cred_xxx(t, user_ns),
+						 current_uid());
+			rcu_read_unlock();
 			break;
 		case (unsigned long) SEND_SIG_PRIV:
 			clear_siginfo(&q->info);
@@ -1146,13 +1129,8 @@ static int __send_signal(int sig, struct kernel_siginfo *info, struct task_struc
 			break;
 		default:
 			copy_siginfo(&q->info, info);
-			if (from_ancestor_ns)
-				q->info.si_pid = 0;
 			break;
 		}
-
-		userns_fixup_signal_uid(&q->info, t);
-
 	} else if (!is_si_special(info)) {
 		if (sig >= SIGRTMIN && info->si_code != SI_USER) {
 			/*
@@ -1196,6 +1174,28 @@ static int __send_signal(int sig, struct kernel_siginfo *info, struct task_struc
 	return ret;
 }
 
+static inline bool has_si_pid_and_uid(struct kernel_siginfo *info)
+{
+	bool ret = false;
+	switch (siginfo_layout(info->si_signo, info->si_code)) {
+	case SIL_KILL:
+	case SIL_CHLD:
+	case SIL_RT:
+		ret = true;
+		break;
+	case SIL_TIMER:
+	case SIL_POLL:
+	case SIL_FAULT:
+	case SIL_FAULT_MCEERR:
+	case SIL_FAULT_BNDERR:
+	case SIL_FAULT_PKUERR:
+	case SIL_SYS:
+		ret = false;
+		break;
+	}
+	return ret;
+}
+
 static int send_signal(int sig, struct kernel_siginfo *info, struct task_struct *t,
 			enum pid_type type)
 {
@@ -1205,7 +1205,20 @@ static int send_signal(int sig, struct kernel_siginfo *info, struct task_struct
 	from_ancestor_ns = si_fromuser(info) &&
 			   !task_pid_nr_ns(current, task_active_pid_ns(t));
 #endif
+	if (!is_si_special(info) && has_si_pid_and_uid(info)) {
+		struct user_namespace *t_user_ns;
 
+		rcu_read_lock();
+		t_user_ns = task_cred_xxx(t, user_ns);
+		if (current_user_ns() != t_user_ns) {
+			kuid_t uid = make_kuid(current_user_ns(), info->si_uid);
+			info->si_uid = from_kuid_munged(t_user_ns, uid);
+		}
+		rcu_read_unlock();
+
+		if (!task_pid_nr_ns(current, task_active_pid_ns(t)))
+			info->si_pid = 0;
+	}
 	return __send_signal(sig, info, t, type, from_ancestor_ns);
 }
 

commit 70f1b0d34bdf03065fe869e93cc17cad1ea20c4a
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Feb 7 19:44:12 2019 -0600

    signal/usb: Replace kill_pid_info_as_cred with kill_pid_usb_asyncio
    
    The usb support for asyncio encoded one of it's values in the wrong
    field.  It should have used si_value but instead used si_addr which is
    not present in the _rt union member of struct siginfo.
    
    The practical result of this is that on a 64bit big endian kernel
    when delivering a signal to a 32bit process the si_addr field
    is set to NULL, instead of the expected pointer value.
    
    This issue can not be fixed in copy_siginfo_to_user32 as the usb
    usage of the the _sigfault (aka si_addr) member of the siginfo
    union when SI_ASYNCIO is set is incompatible with the POSIX and
    glibc usage of the _rt member of the siginfo union.
    
    Therefore replace kill_pid_info_as_cred with kill_pid_usb_asyncio a
    dedicated function for this one specific case.  There are no other
    users of kill_pid_info_as_cred so this specialization should have no
    impact on the amount of code in the kernel.  Have kill_pid_usb_asyncio
    take instead of a siginfo_t which is difficult and error prone, 3
    arguments, a signal number, an errno value, and an address enconded as
    a sigval_t.  The encoding of the address as a sigval_t allows the
    code that reads the userspace request for a signal to handle this
    compat issue along with all of the other compat issues.
    
    Add BUILD_BUG_ONs in kernel/signal.c to ensure that we can now place
    the pointer value at the in si_pid (instead of si_addr).  That is the
    code now verifies that si_pid and si_addr always occur at the same
    location.  Further the code veries that for native structures a value
    placed in si_pid and spilling into si_uid will appear in userspace in
    si_addr (on a byte by byte copy of siginfo or a field by field copy of
    siginfo).  The code also verifies that for a 64bit kernel and a 32bit
    userspace the 32bit pointer will fit in si_pid.
    
    I have used the usbsig.c program below written by Alan Stern and
    slightly tweaked by me to run on a big endian machine to verify the
    issue exists (on sparc64) and to confirm the patch below fixes the issue.
    
     /* usbsig.c -- test USB async signal delivery */
    
     #define _GNU_SOURCE
     #include <stdio.h>
     #include <fcntl.h>
     #include <signal.h>
     #include <string.h>
     #include <sys/ioctl.h>
     #include <unistd.h>
     #include <endian.h>
     #include <linux/usb/ch9.h>
     #include <linux/usbdevice_fs.h>
    
     static struct usbdevfs_urb urb;
     static struct usbdevfs_disconnectsignal ds;
     static volatile sig_atomic_t done = 0;
    
     void urb_handler(int sig, siginfo_t *info , void *ucontext)
     {
            printf("Got signal %d, signo %d errno %d code %d addr: %p urb: %p\n",
                   sig, info->si_signo, info->si_errno, info->si_code,
                   info->si_addr, &urb);
    
            printf("%s\n", (info->si_addr == &urb) ? "Good" : "Bad");
     }
    
     void ds_handler(int sig, siginfo_t *info , void *ucontext)
     {
            printf("Got signal %d, signo %d errno %d code %d addr: %p ds: %p\n",
                   sig, info->si_signo, info->si_errno, info->si_code,
                   info->si_addr, &ds);
    
            printf("%s\n", (info->si_addr == &ds) ? "Good" : "Bad");
            done = 1;
     }
    
     int main(int argc, char **argv)
     {
            char *devfilename;
            int fd;
            int rc;
            struct sigaction act;
            struct usb_ctrlrequest *req;
            void *ptr;
            char buf[80];
    
            if (argc != 2) {
                    fprintf(stderr, "Usage: usbsig device-file-name\n");
                    return 1;
            }
    
            devfilename = argv[1];
            fd = open(devfilename, O_RDWR);
            if (fd == -1) {
                    perror("Error opening device file");
                    return 1;
            }
    
            act.sa_sigaction = urb_handler;
            sigemptyset(&act.sa_mask);
            act.sa_flags = SA_SIGINFO;
    
            rc = sigaction(SIGUSR1, &act, NULL);
            if (rc == -1) {
                    perror("Error in sigaction");
                    return 1;
            }
    
            act.sa_sigaction = ds_handler;
            sigemptyset(&act.sa_mask);
            act.sa_flags = SA_SIGINFO;
    
            rc = sigaction(SIGUSR2, &act, NULL);
            if (rc == -1) {
                    perror("Error in sigaction");
                    return 1;
            }
    
            memset(&urb, 0, sizeof(urb));
            urb.type = USBDEVFS_URB_TYPE_CONTROL;
            urb.endpoint = USB_DIR_IN | 0;
            urb.buffer = buf;
            urb.buffer_length = sizeof(buf);
            urb.signr = SIGUSR1;
    
            req = (struct usb_ctrlrequest *) buf;
            req->bRequestType = USB_DIR_IN | USB_TYPE_STANDARD | USB_RECIP_DEVICE;
            req->bRequest = USB_REQ_GET_DESCRIPTOR;
            req->wValue = htole16(USB_DT_DEVICE << 8);
            req->wIndex = htole16(0);
            req->wLength = htole16(sizeof(buf) - sizeof(*req));
    
            rc = ioctl(fd, USBDEVFS_SUBMITURB, &urb);
            if (rc == -1) {
                    perror("Error in SUBMITURB ioctl");
                    return 1;
            }
    
            rc = ioctl(fd, USBDEVFS_REAPURB, &ptr);
            if (rc == -1) {
                    perror("Error in REAPURB ioctl");
                    return 1;
            }
    
            memset(&ds, 0, sizeof(ds));
            ds.signr = SIGUSR2;
            ds.context = &ds;
            rc = ioctl(fd, USBDEVFS_DISCSIGNAL, &ds);
            if (rc == -1) {
                    perror("Error in DISCSIGNAL ioctl");
                    return 1;
            }
    
            printf("Waiting for usb disconnect\n");
            while (!done) {
                    sleep(1);
            }
    
            close(fd);
            return 0;
     }
    
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: linux-usb@vger.kernel.org
    Cc: Alan Stern <stern@rowland.harvard.edu>
    Cc: Oliver Neukum <oneukum@suse.com>
    Fixes: v2.3.39
    Cc: stable@vger.kernel.org
    Acked-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index a1eb44dc9ff5..18040d6bd63a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1439,13 +1439,44 @@ static inline bool kill_as_cred_perm(const struct cred *cred,
 	       uid_eq(cred->uid, pcred->uid);
 }
 
-/* like kill_pid_info(), but doesn't use uid/euid of "current" */
-int kill_pid_info_as_cred(int sig, struct kernel_siginfo *info, struct pid *pid,
-			 const struct cred *cred)
+/*
+ * The usb asyncio usage of siginfo is wrong.  The glibc support
+ * for asyncio which uses SI_ASYNCIO assumes the layout is SIL_RT.
+ * AKA after the generic fields:
+ *	kernel_pid_t	si_pid;
+ *	kernel_uid32_t	si_uid;
+ *	sigval_t	si_value;
+ *
+ * Unfortunately when usb generates SI_ASYNCIO it assumes the layout
+ * after the generic fields is:
+ *	void __user 	*si_addr;
+ *
+ * This is a practical problem when there is a 64bit big endian kernel
+ * and a 32bit userspace.  As the 32bit address will encoded in the low
+ * 32bits of the pointer.  Those low 32bits will be stored at higher
+ * address than appear in a 32 bit pointer.  So userspace will not
+ * see the address it was expecting for it's completions.
+ *
+ * There is nothing in the encoding that can allow
+ * copy_siginfo_to_user32 to detect this confusion of formats, so
+ * handle this by requiring the caller of kill_pid_usb_asyncio to
+ * notice when this situration takes place and to store the 32bit
+ * pointer in sival_int, instead of sival_addr of the sigval_t addr
+ * parameter.
+ */
+int kill_pid_usb_asyncio(int sig, int errno, sigval_t addr,
+			 struct pid *pid, const struct cred *cred)
 {
-	int ret = -EINVAL;
+	struct kernel_siginfo info;
 	struct task_struct *p;
 	unsigned long flags;
+	int ret = -EINVAL;
+
+	clear_siginfo(&info);
+	info.si_signo = sig;
+	info.si_errno = errno;
+	info.si_code = SI_ASYNCIO;
+	*((sigval_t *)&info.si_pid) = addr;
 
 	if (!valid_signal(sig))
 		return ret;
@@ -1456,17 +1487,17 @@ int kill_pid_info_as_cred(int sig, struct kernel_siginfo *info, struct pid *pid,
 		ret = -ESRCH;
 		goto out_unlock;
 	}
-	if (si_fromuser(info) && !kill_as_cred_perm(cred, p)) {
+	if (!kill_as_cred_perm(cred, p)) {
 		ret = -EPERM;
 		goto out_unlock;
 	}
-	ret = security_task_kill(p, info, sig, cred);
+	ret = security_task_kill(p, &info, sig, cred);
 	if (ret)
 		goto out_unlock;
 
 	if (sig) {
 		if (lock_task_sighand(p, &flags)) {
-			ret = __send_signal(sig, info, p, PIDTYPE_TGID, 0);
+			ret = __send_signal(sig, &info, p, PIDTYPE_TGID, 0);
 			unlock_task_sighand(p, &flags);
 		} else
 			ret = -ESRCH;
@@ -1475,7 +1506,7 @@ int kill_pid_info_as_cred(int sig, struct kernel_siginfo *info, struct pid *pid,
 	rcu_read_unlock();
 	return ret;
 }
-EXPORT_SYMBOL_GPL(kill_pid_info_as_cred);
+EXPORT_SYMBOL_GPL(kill_pid_usb_asyncio);
 
 /*
  * kill_something_info() interprets pid in interesting ways just like kill(2).
@@ -4474,6 +4505,28 @@ static inline void siginfo_buildtime_checks(void)
 	CHECK_OFFSET(si_syscall);
 	CHECK_OFFSET(si_arch);
 #undef CHECK_OFFSET
+
+	/* usb asyncio */
+	BUILD_BUG_ON(offsetof(struct siginfo, si_pid) !=
+		     offsetof(struct siginfo, si_addr));
+	if (sizeof(int) == sizeof(void __user *)) {
+		BUILD_BUG_ON(sizeof_field(struct siginfo, si_pid) !=
+			     sizeof(void __user *));
+	} else {
+		BUILD_BUG_ON((sizeof_field(struct siginfo, si_pid) +
+			      sizeof_field(struct siginfo, si_uid)) !=
+			     sizeof(void __user *));
+		BUILD_BUG_ON(offsetofend(struct siginfo, si_pid) !=
+			     offsetof(struct siginfo, si_uid));
+	}
+#ifdef CONFIG_COMPAT
+	BUILD_BUG_ON(offsetof(struct compat_siginfo, si_pid) !=
+		     offsetof(struct compat_siginfo, si_addr));
+	BUILD_BUG_ON(sizeof_field(struct compat_siginfo, si_pid) !=
+		     sizeof(compat_uptr_t));
+	BUILD_BUG_ON(sizeof_field(struct compat_siginfo, si_pid) !=
+		     sizeof_field(struct siginfo, si_pid));
+#endif
 }
 
 void __init signals_init(void)

commit b48345aafb203803ccda4488cb5409b1ed435c0a
Author: Richard Guy Briggs <rgb@redhat.com>
Date:   Fri May 10 12:21:49 2019 -0400

    audit: deliver signal_info regarless of syscall
    
    When a process signals the audit daemon (shutdown, rotate, resume,
    reconfig) but syscall auditing is not enabled, we still want to know the
    identity of the process sending the signal to the audit daemon.
    
    Move audit_signal_info() out of syscall auditing to general auditing but
    create a new function audit_signal_info_syscall() to take care of the
    syscall dependent parts for when syscall auditing is enabled.
    
    Please see the github kernel audit issue
    https://github.com/linux-audit/audit-kernel/issues/111
    
    Signed-off-by: Richard Guy Briggs <rgb@redhat.com>
    Signed-off-by: Paul Moore <paul@paul-moore.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index a1eb44dc9ff5..5cfc8611867b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -44,6 +44,7 @@
 #include <linux/posix-timers.h>
 #include <linux/livepatch.h>
 #include <linux/cgroup.h>
+#include <linux/audit.h>
 
 #define CREATE_TRACE_POINTS
 #include <trace/events/signal.h>
@@ -53,7 +54,6 @@
 #include <asm/unistd.h>
 #include <asm/siginfo.h>
 #include <asm/cacheflush.h>
-#include "audit.h"	/* audit_signal_info() */
 
 /*
  * SLAB caches for signal bits.

commit 457c89965399115e5cd8bf38f9c597293405703d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun May 19 13:08:55 2019 +0100

    treewide: Add SPDX license identifier for missed files
    
    Add SPDX license identifiers to all files which:
    
     - Have no license information of any form
    
     - Have EXPORT_.*_SYMBOL_GPL inside which was used in the
       initial scan/conversion to ignore the file
    
    These files fall under the project license, GPL v2 only. The resulting SPDX
    license identifier is:
    
      GPL-2.0-only
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index a1eb44dc9ff5..d7b9d14ac80d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  *  linux/kernel/signal.c
  *

commit 05b289263772b0698589abc47771264a685cd365
Author: Roman Gushchin <guro@fb.com>
Date:   Thu May 16 10:38:21 2019 -0700

    signal: unconditionally leave the frozen state in ptrace_stop()
    
    Alex Xu reported a regression in strace, caused by the introduction of
    the cgroup v2 freezer. The regression can be reproduced by stracing
    the following simple program:
    
      #include <unistd.h>
    
      int main() {
          write(1, "a", 1);
          return 0;
      }
    
    An attempt to run strace ./a.out leads to the infinite loop:
      [ pre-main omitted ]
      write(1, "a", 1)                        = ? ERESTARTSYS (To be restarted if SA_RESTART is set)
      write(1, "a", 1)                        = ? ERESTARTSYS (To be restarted if SA_RESTART is set)
      write(1, "a", 1)                        = ? ERESTARTSYS (To be restarted if SA_RESTART is set)
      write(1, "a", 1)                        = ? ERESTARTSYS (To be restarted if SA_RESTART is set)
      write(1, "a", 1)                        = ? ERESTARTSYS (To be restarted if SA_RESTART is set)
      write(1, "a", 1)                        = ? ERESTARTSYS (To be restarted if SA_RESTART is set)
      [ repeats forever ]
    
    The problem occurs because the traced task leaves ptrace_stop()
    (and the signal handling loop) with the frozen bit set. So let's
    call cgroup_leave_frozen(true) unconditionally after sleeping
    in ptrace_stop().
    
    With this patch applied, strace works as expected:
      [ pre-main omitted ]
      write(1, "a", 1)                        = 1
      exit_group(0)                           = ?
      +++ exited with 0 +++
    
    Reported-by: Alex Xu <alex_y_xu@yahoo.ca>
    Fixes: 76f969e8948d ("cgroup: cgroup v2 freezer")
    Signed-off-by: Roman Gushchin <guro@fb.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Tejun Heo <tj@kernel.org>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index c4dd66436fc5..a1eb44dc9ff5 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2113,6 +2113,7 @@ static void ptrace_stop(int exit_code, int why, int clear_code, kernel_siginfo_t
 		preempt_enable_no_resched();
 		cgroup_enter_frozen();
 		freezable_schedule();
+		cgroup_leave_frozen(true);
 	} else {
 		/*
 		 * By the time we got the lock, our tracer went away.

commit b028fb612849add771679c1b99a50d99264c9632
Author: Mathieu Malaterre <malat@debian.org>
Date:   Tue May 14 15:44:35 2019 -0700

    kernel/signal.c: annotate implicit fall through
    
    There is a plan to build the kernel with -Wimplicit-fallthrough and this
    place in the code produced a warning (W=1).
    
    This commit remove the following warning:
    
      kernel/signal.c:795:13: warning: this statement may fall through [-Wimplicit-fallthrough=]
    
    Link: http://lkml.kernel.org/r/20190114203505.17875-1-malat@debian.org
    Signed-off-by: Mathieu Malaterre <malat@debian.org>
    Acked-by: Gustavo A. R. Silva <gustavo@embeddedor.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 62f9aea4a15a..c4dd66436fc5 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -840,6 +840,7 @@ static int check_kill_permission(int sig, struct kernel_siginfo *info,
 			 */
 			if (!sid || sid == task_session(current))
 				break;
+			/* fall through */
 		default:
 			return -EPERM;
 		}

commit abde77eb5c66b2f98539c4644b54f34b7e179e6b
Merge: 23c970608a09 f2b31bb59824
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu May 9 13:52:12 2019 -0700

    Merge branch 'for-5.2' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup
    
    Pull cgroup updates from Tejun Heo:
     "This includes Roman's cgroup2 freezer implementation.
    
      It's a separate machanism from cgroup1 freezer. Instead of blocking
      user tasks in arbitrary uninterruptible sleeps, the new implementation
      extends jobctl stop - frozen tasks are trapped in jobctl stop until
      thawed and can be killed and ptraced. Lots of thanks to Oleg for
      sheperding the effort.
    
      Other than that, there are a few trivial changes"
    
    * 'for-5.2' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup:
      cgroup: never call do_group_exit() with task->frozen bit set
      kernel: cgroup: fix misuse of %x
      cgroup: get rid of cgroup_freezer_frozen_exit()
      cgroup: prevent spurious transition into non-frozen state
      cgroup: Remove unused cgrp variable
      cgroup: document cgroup v2 freezer interface
      cgroup: add tracing points for cgroup v2 freezer
      cgroup: make TRACE_CGROUP_PATH irq-safe
      kselftests: cgroup: add freezer controller self-tests
      kselftests: cgroup: don't fail on cg_kill_all() error in cg_destroy()
      cgroup: cgroup v2 freezer
      cgroup: protect cgroup->nr_(dying_)descendants by css_set_lock
      cgroup: implement __cgroup_task_count() helper
      cgroup: rename freezer.c into legacy_freezer.c
      cgroup: remove extra cgroup_migrate_finish() call

commit f2b31bb598248c04721cb8485e6091a9feb045ac
Author: Roman Gushchin <guro@fb.com>
Date:   Wed May 8 13:34:20 2019 -0700

    cgroup: never call do_group_exit() with task->frozen bit set
    
    I've got two independent reports that cgroup_task_frozen() check
    in cgroup_exit() has been triggered by lkp libhugetlbfs-test and
    LTP ptrace01 tests.
    
    For example:
    [   44.576072] WARNING: CPU: 1 PID: 3028 at kernel/cgroup/cgroup.c:5932 cgroup_exit+0x148/0x160
    [   44.577724] Modules linked in: crct10dif_pclmul crc32_pclmul crc32c_intel ghash_clmulni_intel sr_mod cdrom
    bochs_drm sg ttm ata_generic pata_acpi ppdev drm_kms_helper snd_pcm syscopyarea aesni_intel snd_timer
    sysfillrect sysimgblt snd crypto_simd cryptd glue_helper soundcore fb_sys_fops joydev drm serio_raw pcspkr
    ata_piix libata i2c_piix4 floppy parport_pc parport ip_tables
    [   44.583106] CPU: 1 PID: 3028 Comm: ptrace-write-hu Not tainted 5.1.0-rc3-00053-g9262503 #5
    [   44.584600] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.2-1 04/01/2014
    [   44.586116] RIP: 0010:cgroup_exit+0x148/0x160
    [   44.587135] Code: 0f 84 50 ff ff ff 48 8b 85 c8 0c 00 00 48 8b 78 70 e8 ec 2e 00 00 e9 3b ff ff ff f0 ff 43 60
    0f 88 72 21 89 00 e9 48 ff ff ff <0f> 0b e9 1b ff ff ff e8 3c 73 f4 ff 66 90 66 2e 0f 1f 84 00 00 00
    [   44.590113] RSP: 0018:ffffb25702dcfd30 EFLAGS: 00010002
    [   44.591167] RAX: ffff96a7fee32410 RBX: ffff96a7ff1d6000 RCX: dead000000000200
    [   44.592446] RDX: ffff96a7ff1d6080 RSI: ffff96a7fec75290 RDI: ffff96a7fec75290
    [   44.593715] RBP: ffff96a7fec745c0 R08: ffff96a7fec74658 R09: 0000000000000000
    [   44.594985] R10: 0000000000000000 R11: 0000000000000001 R12: ffff96a7fec75101
    [   44.596266] R13: ffff96a7fec745c0 R14: ffff96a7ff3bde30 R15: ffff96a7fec75130
    [   44.597550] FS:  0000000000000000(0000) GS:ffff96a7dd700000(0000) knlGS:0000000000000000
    [   44.598950] CS:  0010 DS: 002b ES: 002b CR0: 0000000080050033
    [   44.600098] CR2: 00000000f7a00000 CR3: 000000000d20e000 CR4: 00000000000406e0
    [   44.601417] Call Trace:
    [   44.602777]  do_exit+0x337/0xc40
    [   44.603677]  do_group_exit+0x3a/0xa0
    [   44.604610]  get_signal+0x12e/0x8d0
    [   44.605533]  ? __switch_to_asm+0x40/0x70
    [   44.606503]  do_signal+0x36/0x650
    [   44.607409]  ? __switch_to_asm+0x40/0x70
    [   44.608383]  ? __schedule+0x267/0x860
    [   44.609329]  exit_to_usermode_loop+0x89/0xf0
    [   44.610349]  do_fast_syscall_32+0x251/0x2e3
    [   44.611357]  entry_SYSENTER_compat+0x7f/0x91
    [   44.612376] ---[ end trace e4ca5cfc4b7f7964 ]---
    
    The problem is caused by the ptrace_signal() call in the for loop
    in get_signal(). There is a cgroup_enter_frozen() call inside
    ptrace_signal(), so after exit from ptrace_signal() the task->frozen
    bit might be set. In this case do_group_exit() can be called with the
    task->frozen bit set and trigger the warning. This is only place where
    we can leave the loop with the task->frozen bit set and without
    setting JOBCTL_TRAP_FREEZE and TIF_SIGPENDING.
    
    To resolve this problem, let's move cgroup_leave_frozen(true) call to
    just after the fatal label. If the task is going to die, the frozen
    bit must be cleared no matter how we get into this point.
    
    Reported-by: kernel test robot <rong.a.chen@intel.com>
    Reported-by: Qian Cai <cai@lca.pw>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Tejun Heo <tj@kernel.org>
    Signed-off-by: Roman Gushchin <guro@fb.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 16b72f4f14df..8607b11ff936 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2483,10 +2483,6 @@ bool get_signal(struct ksignal *ksig)
 		ksig->info.si_signo = signr = SIGKILL;
 		sigdelset(&current->pending.signal, SIGKILL);
 		recalc_sigpending();
-		current->jobctl &= ~JOBCTL_TRAP_FREEZE;
-		spin_unlock_irq(&sighand->siglock);
-		if (unlikely(cgroup_task_frozen(current)))
-			cgroup_leave_frozen(true);
 		goto fatal;
 	}
 
@@ -2608,8 +2604,10 @@ bool get_signal(struct ksignal *ksig)
 			continue;
 		}
 
-		spin_unlock_irq(&sighand->siglock);
 	fatal:
+		spin_unlock_irq(&sighand->siglock);
+		if (unlikely(cgroup_task_frozen(current)))
+			cgroup_leave_frozen(true);
 
 		/*
 		 * Anything else is fatal, maybe with a core dump.

commit eac7078a0fff1e72cf2b641721e3f55ec7e5e21e
Merge: 41bc10cabe96 43c6afee48d4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue May 7 12:30:24 2019 -0700

    Merge tag 'pidfd-v5.2-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/brauner/linux
    
    Pull pidfd updates from Christian Brauner:
     "This patchset makes it possible to retrieve pidfds at process creation
      time by introducing the new flag CLONE_PIDFD to the clone() system
      call. Linus originally suggested to implement this as a new flag to
      clone() instead of making it a separate system call.
    
      After a thorough review from Oleg CLONE_PIDFD returns pidfds in the
      parent_tidptr argument. This means we can give back the associated pid
      and the pidfd at the same time. Access to process metadata information
      thus becomes rather trivial.
    
      As has been agreed, CLONE_PIDFD creates file descriptors based on
      anonymous inodes similar to the new mount api. They are made
      unconditional by this patchset as they are now needed by core kernel
      code (vfs, pidfd) even more than they already were before (timerfd,
      signalfd, io_uring, epoll etc.). The core patchset is rather small.
      The bulky looking changelist is caused by David's very simple changes
      to Kconfig to make anon inodes unconditional.
    
      A pidfd comes with additional information in fdinfo if the kernel
      supports procfs. The fdinfo file contains the pid of the process in
      the callers pid namespace in the same format as the procfs status
      file, i.e. "Pid:\t%d".
    
      To remove worries about missing metadata access this patchset comes
      with a sample/test program that illustrates how a combination of
      CLONE_PIDFD and pidfd_send_signal() can be used to gain race-free
      access to process metadata through /proc/<pid>.
    
      Further work based on this patchset has been done by Joel. His work
      makes pidfds pollable. It finished too late for this merge window. I
      would prefer to have it sitting in linux-next for a while and send it
      for inclusion during the 5.3 merge window"
    
    * tag 'pidfd-v5.2-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/brauner/linux:
      samples: show race-free pidfd metadata access
      signal: support CLONE_PIDFD with pidfd_send_signal
      clone: add CLONE_PIDFD
      Make anon_inodes unconditional

commit 2151ad1b067275730de1b38c7257478cae47d29e
Author: Christian Brauner <christian@brauner.io>
Date:   Wed Apr 17 22:50:25 2019 +0200

    signal: support CLONE_PIDFD with pidfd_send_signal
    
    Let pidfd_send_signal() use pidfds retrieved via CLONE_PIDFD.  With this
    patch pidfd_send_signal() becomes independent of procfs.  This fullfils
    the request made when we merged the pidfd_send_signal() patchset.  The
    pidfd_send_signal() syscall is now always available allowing for it to
    be used by users without procfs mounted or even users without procfs
    support compiled into the kernel.
    
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Co-developed-by: Jann Horn <jannh@google.com>
    Signed-off-by: Jann Horn <jannh@google.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: David Howells <dhowells@redhat.com>
    Cc: "Michael Kerrisk (man-pages)" <mtk.manpages@gmail.com>
    Cc: Andy Lutomirsky <luto@kernel.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Aleksa Sarai <cyphar@cyphar.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index f98448cf2def..1581140f2d99 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3513,7 +3513,6 @@ SYSCALL_DEFINE2(kill, pid_t, pid, int, sig)
 	return kill_something_info(sig, &info, pid);
 }
 
-#ifdef CONFIG_PROC_FS
 /*
  * Verify that the signaler and signalee either are in the same pid namespace
  * or that the signaler's pid namespace is an ancestor of the signalee's pid
@@ -3550,6 +3549,14 @@ static int copy_siginfo_from_user_any(kernel_siginfo_t *kinfo, siginfo_t *info)
 	return copy_siginfo_from_user(kinfo, info);
 }
 
+static struct pid *pidfd_to_pid(const struct file *file)
+{
+	if (file->f_op == &pidfd_fops)
+		return file->private_data;
+
+	return tgid_pidfd_to_pid(file);
+}
+
 /**
  * sys_pidfd_send_signal - send a signal to a process through a task file
  *                          descriptor
@@ -3586,7 +3593,7 @@ SYSCALL_DEFINE4(pidfd_send_signal, int, pidfd, int, sig,
 		return -EBADF;
 
 	/* Is this a pidfd? */
-	pid = tgid_pidfd_to_pid(f.file);
+	pid = pidfd_to_pid(f.file);
 	if (IS_ERR(pid)) {
 		ret = PTR_ERR(pid);
 		goto err;
@@ -3620,7 +3627,6 @@ SYSCALL_DEFINE4(pidfd_send_signal, int, pidfd, int, sig,
 	fdput(f);
 	return ret;
 }
-#endif /* CONFIG_PROC_FS */
 
 static int
 do_send_specific(pid_t tgid, pid_t pid, int sig, struct kernel_siginfo *info)

commit cb2c4cd87874a7975b7b8615866b3a87bae10aab
Author: Roman Gushchin <guro@fb.com>
Date:   Fri Apr 26 10:59:44 2019 -0700

    cgroup: prevent spurious transition into non-frozen state
    
    If freezing of a cgroup races with waking of a task from
    the frozen state (like waiting in vfork() or in do_signal_stop()),
    a spurious transition of the cgroup state can happen.
    
    The task enters cgroup_leave_frozen(true), the cgroup->nr_frozen_tasks
    counter decrements, and the cgroup is switched to the unfrozen state.
    
    To prevent it, let's reserve cgroup_leave_frozen(true) for
    terminating processes and use cgroup_leave_frozen(false) otherwise.
    
    To avoid busy-looping in the signal handling loop waiting
    for JOBCTL_TRAP_FREEZE set from the cgroup freezing path,
    let's do it explicitly in cgroup_leave_frozen(), if the task
    is going to stay frozen.
    
    Suggested-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Roman Gushchin <guro@fb.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 095e0fc57b25..16b72f4f14df 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2514,7 +2514,7 @@ bool get_signal(struct ksignal *ksig)
 		 */
 		if (unlikely(cgroup_task_frozen(current))) {
 			spin_unlock_irq(&sighand->siglock);
-			cgroup_leave_frozen(true);
+			cgroup_leave_frozen(false);
 			goto relock;
 		}
 

commit 76f969e8948d82e78e1bc4beb6b9465908e74873
Author: Roman Gushchin <guro@fb.com>
Date:   Fri Apr 19 10:03:04 2019 -0700

    cgroup: cgroup v2 freezer
    
    Cgroup v1 implements the freezer controller, which provides an ability
    to stop the workload in a cgroup and temporarily free up some
    resources (cpu, io, network bandwidth and, potentially, memory)
    for some other tasks. Cgroup v2 lacks this functionality.
    
    This patch implements freezer for cgroup v2.
    
    Cgroup v2 freezer tries to put tasks into a state similar to jobctl
    stop. This means that tasks can be killed, ptraced (using
    PTRACE_SEIZE*), and interrupted. It is possible to attach to
    a frozen task, get some information (e.g. read registers) and detach.
    It's also possible to migrate a frozen tasks to another cgroup.
    
    This differs cgroup v2 freezer from cgroup v1 freezer, which mostly
    tried to imitate the system-wide freezer. However uninterruptible
    sleep is fine when all tasks are going to be frozen (hibernation case),
    it's not the acceptable state for some subset of the system.
    
    Cgroup v2 freezer is not supporting freezing kthreads.
    If a non-root cgroup contains kthread, the cgroup still can be frozen,
    but the kthread will remain running, the cgroup will be shown
    as non-frozen, and the notification will not be delivered.
    
    * PTRACE_ATTACH is not working because non-fatal signal delivery
    is blocked in frozen state.
    
    There are some interface differences between cgroup v1 and cgroup v2
    freezer too, which are required to conform the cgroup v2 interface
    design principles:
    1) There is no separate controller, which has to be turned on:
    the functionality is always available and is represented by
    cgroup.freeze and cgroup.events cgroup control files.
    2) The desired state is defined by the cgroup.freeze control file.
    Any hierarchical configuration is allowed.
    3) The interface is asynchronous. The actual state is available
    using cgroup.events control file ("frozen" field). There are no
    dedicated transitional states.
    4) It's allowed to make any changes with the cgroup hierarchy
    (create new cgroups, remove old cgroups, move tasks between cgroups)
    no matter if some cgroups are frozen.
    
    Signed-off-by: Roman Gushchin <guro@fb.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    No-objection-from-me-by: Oleg Nesterov <oleg@redhat.com>
    Cc: kernel-team@fb.com

diff --git a/kernel/signal.c b/kernel/signal.c
index f98448cf2def..095e0fc57b25 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -43,6 +43,7 @@
 #include <linux/compiler.h>
 #include <linux/posix-timers.h>
 #include <linux/livepatch.h>
+#include <linux/cgroup.h>
 
 #define CREATE_TRACE_POINTS
 #include <trace/events/signal.h>
@@ -146,9 +147,10 @@ static inline bool has_pending_signals(sigset_t *signal, sigset_t *blocked)
 
 static bool recalc_sigpending_tsk(struct task_struct *t)
 {
-	if ((t->jobctl & JOBCTL_PENDING_MASK) ||
+	if ((t->jobctl & (JOBCTL_PENDING_MASK | JOBCTL_TRAP_FREEZE)) ||
 	    PENDING(&t->pending, &t->blocked) ||
-	    PENDING(&t->signal->shared_pending, &t->blocked)) {
+	    PENDING(&t->signal->shared_pending, &t->blocked) ||
+	    cgroup_task_frozen(t)) {
 		set_tsk_thread_flag(t, TIF_SIGPENDING);
 		return true;
 	}
@@ -2108,6 +2110,7 @@ static void ptrace_stop(int exit_code, int why, int clear_code, kernel_siginfo_t
 		preempt_disable();
 		read_unlock(&tasklist_lock);
 		preempt_enable_no_resched();
+		cgroup_enter_frozen();
 		freezable_schedule();
 	} else {
 		/*
@@ -2286,6 +2289,7 @@ static bool do_signal_stop(int signr)
 		}
 
 		/* Now we don't run again until woken by SIGCONT or SIGKILL */
+		cgroup_enter_frozen();
 		freezable_schedule();
 		return true;
 	} else {
@@ -2332,6 +2336,43 @@ static void do_jobctl_trap(void)
 	}
 }
 
+/**
+ * do_freezer_trap - handle the freezer jobctl trap
+ *
+ * Puts the task into frozen state, if only the task is not about to quit.
+ * In this case it drops JOBCTL_TRAP_FREEZE.
+ *
+ * CONTEXT:
+ * Must be called with @current->sighand->siglock held,
+ * which is always released before returning.
+ */
+static void do_freezer_trap(void)
+	__releases(&current->sighand->siglock)
+{
+	/*
+	 * If there are other trap bits pending except JOBCTL_TRAP_FREEZE,
+	 * let's make another loop to give it a chance to be handled.
+	 * In any case, we'll return back.
+	 */
+	if ((current->jobctl & (JOBCTL_PENDING_MASK | JOBCTL_TRAP_FREEZE)) !=
+	     JOBCTL_TRAP_FREEZE) {
+		spin_unlock_irq(&current->sighand->siglock);
+		return;
+	}
+
+	/*
+	 * Now we're sure that there is no pending fatal signal and no
+	 * pending traps. Clear TIF_SIGPENDING to not get out of schedule()
+	 * immediately (if there is a non-fatal signal pending), and
+	 * put the task into sleep.
+	 */
+	__set_current_state(TASK_INTERRUPTIBLE);
+	clear_thread_flag(TIF_SIGPENDING);
+	spin_unlock_irq(&current->sighand->siglock);
+	cgroup_enter_frozen();
+	freezable_schedule();
+}
+
 static int ptrace_signal(int signr, kernel_siginfo_t *info)
 {
 	/*
@@ -2442,6 +2483,10 @@ bool get_signal(struct ksignal *ksig)
 		ksig->info.si_signo = signr = SIGKILL;
 		sigdelset(&current->pending.signal, SIGKILL);
 		recalc_sigpending();
+		current->jobctl &= ~JOBCTL_TRAP_FREEZE;
+		spin_unlock_irq(&sighand->siglock);
+		if (unlikely(cgroup_task_frozen(current)))
+			cgroup_leave_frozen(true);
 		goto fatal;
 	}
 
@@ -2452,9 +2497,24 @@ bool get_signal(struct ksignal *ksig)
 		    do_signal_stop(0))
 			goto relock;
 
-		if (unlikely(current->jobctl & JOBCTL_TRAP_MASK)) {
-			do_jobctl_trap();
+		if (unlikely(current->jobctl &
+			     (JOBCTL_TRAP_MASK | JOBCTL_TRAP_FREEZE))) {
+			if (current->jobctl & JOBCTL_TRAP_MASK) {
+				do_jobctl_trap();
+				spin_unlock_irq(&sighand->siglock);
+			} else if (current->jobctl & JOBCTL_TRAP_FREEZE)
+				do_freezer_trap();
+
+			goto relock;
+		}
+
+		/*
+		 * If the task is leaving the frozen state, let's update
+		 * cgroup counters and reset the frozen bit.
+		 */
+		if (unlikely(cgroup_task_frozen(current))) {
 			spin_unlock_irq(&sighand->siglock);
+			cgroup_leave_frozen(true);
 			goto relock;
 		}
 
@@ -2548,8 +2608,8 @@ bool get_signal(struct ksignal *ksig)
 			continue;
 		}
 
-	fatal:
 		spin_unlock_irq(&sighand->siglock);
+	fatal:
 
 		/*
 		 * Anything else is fatal, maybe with a core dump.

commit 738a7832d21e3d911fcddab98ce260b79010b461
Author: Christian Brauner <christian@brauner.io>
Date:   Thu Apr 18 12:18:39 2019 +0200

    signal: use fdget() since we don't allow O_PATH
    
    As stated in the original commit for pidfd_send_signal() we don't allow
    to signal processes through O_PATH file descriptors since it is
    semantically equivalent to a write on the pidfd.
    
    We already correctly error out right now and return EBADF if an O_PATH
    fd is passed.  This is because we use file->f_op to detect whether a
    pidfd is passed and O_PATH fds have their file->f_op set to empty_fops
    in do_dentry_open() and thus fail the test.
    
    Thus, there is no regression.  It's just semantically correct to use
    fdget() and return an error right from there instead of taking a
    reference and returning an error later.
    
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jann Horn <jann@thejh.net>
    Cc: David Howells <dhowells@redhat.com>
    Cc: "Michael Kerrisk (man-pages)" <mtk.manpages@gmail.com>
    Cc: Andy Lutomirsky <luto@kernel.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Aleksa Sarai <cyphar@cyphar.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index f98448cf2def..227ba170298e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3581,7 +3581,7 @@ SYSCALL_DEFINE4(pidfd_send_signal, int, pidfd, int, sig,
 	if (flags)
 		return -EINVAL;
 
-	f = fdget_raw(pidfd);
+	f = fdget(pidfd);
 	if (!f.file)
 		return -EBADF;
 

commit 556a888a14afe27164191955618990fb3ccc9aad
Author: Jann Horn <jannh@google.com>
Date:   Sat Mar 30 03:12:32 2019 +0100

    signal: don't silently convert SI_USER signals to non-current pidfd
    
    The current sys_pidfd_send_signal() silently turns signals with explicit
    SI_USER context that are sent to non-current tasks into signals with
    kernel-generated siginfo.
    This is unlike do_rt_sigqueueinfo(), which returns -EPERM in this case.
    If a user actually wants to send a signal with kernel-provided siginfo,
    they can do that with pidfd_send_signal(pidfd, sig, NULL, 0); so allowing
    this case is unnecessary.
    
    Instead of silently replacing the siginfo, just bail out with an error;
    this is consistent with other interfaces and avoids special-casing behavior
    based on security checks.
    
    Fixes: 3eb39f47934f ("signal: add pidfd_send_signal() syscall")
    Signed-off-by: Jann Horn <jannh@google.com>
    Signed-off-by: Christian Brauner <christian@brauner.io>

diff --git a/kernel/signal.c b/kernel/signal.c
index b7953934aa99..f98448cf2def 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3605,16 +3605,11 @@ SYSCALL_DEFINE4(pidfd_send_signal, int, pidfd, int, sig,
 		if (unlikely(sig != kinfo.si_signo))
 			goto err;
 
+		/* Only allow sending arbitrary signals to yourself. */
+		ret = -EPERM;
 		if ((task_pid(current) != pid) &&
-		    (kinfo.si_code >= 0 || kinfo.si_code == SI_TKILL)) {
-			/* Only allow sending arbitrary signals to yourself. */
-			ret = -EPERM;
-			if (kinfo.si_code != SI_USER)
-				goto err;
-
-			/* Turn this into a regular kill signal. */
-			prepare_kill_siginfo(sig, &kinfo);
-		}
+		    (kinfo.si_code >= 0 || kinfo.si_code == SI_TKILL))
+			goto err;
 	} else {
 		prepare_kill_siginfo(sig, &kinfo);
 	}

commit a9dce6679d736cb3d612af39bab9f31f8db66f9b
Merge: f67e3fb48912 575a0ae9744d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Mar 16 13:47:14 2019 -0700

    Merge tag 'pidfd-v5.1-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/brauner/linux
    
    Pull pidfd system call from Christian Brauner:
     "This introduces the ability to use file descriptors from /proc/<pid>/
      as stable handles on struct pid. Even if a pid is recycled the handle
      will not change. For a start these fds can be used to send signals to
      the processes they refer to.
    
      With the ability to use /proc/<pid> fds as stable handles on struct
      pid we can fix a long-standing issue where after a process has exited
      its pid can be reused by another process. If a caller sends a signal
      to a reused pid it will end up signaling the wrong process.
    
      With this patchset we enable a variety of use cases. One obvious
      example is that we can now safely delegate an important part of
      process management - sending signals - to processes other than the
      parent of a given process by sending file descriptors around via scm
      rights and not fearing that the given process will have been recycled
      in the meantime. It also allows for easy testing whether a given
      process is still alive or not by sending signal 0 to a pidfd which is
      quite handy.
    
      There has been some interest in this feature e.g. from systems
      management (systemd, glibc) and container managers. I have requested
      and gotten comments from glibc to make sure that this syscall is
      suitable for their needs as well. In the future I expect it to take on
      most other pid-based signal syscalls. But such features are left for
      the future once they are needed.
    
      This has been sitting in linux-next for quite a while and has not
      caused any issues. It comes with selftests which verify basic
      functionality and also test that a recycled pid cannot be signaled via
      a pidfd.
    
      Jon has written about a prior version of this patchset. It should
      cover the basic functionality since not a lot has changed since then:
    
          https://lwn.net/Articles/773459/
    
      The commit message for the syscall itself is extensively documenting
      the syscall, including it's functionality and extensibility"
    
    * tag 'pidfd-v5.1-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/brauner/linux:
      selftests: add tests for pidfd_send_signal()
      signal: add pidfd_send_signal() syscall

commit b1b988a6a035212f5ea205155c49ce449beedee8
Merge: edaed168e135 cfbe271667b7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Mar 5 14:08:26 2019 -0800

    Merge branch 'timers-2038-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull year 2038 updates from Thomas Gleixner:
     "Another round of changes to make the kernel ready for 2038. After lots
      of preparatory work this is the first set of syscalls which are 2038
      safe:
    
        403 clock_gettime64
        404 clock_settime64
        405 clock_adjtime64
        406 clock_getres_time64
        407 clock_nanosleep_time64
        408 timer_gettime64
        409 timer_settime64
        410 timerfd_gettime64
        411 timerfd_settime64
        412 utimensat_time64
        413 pselect6_time64
        414 ppoll_time64
        416 io_pgetevents_time64
        417 recvmmsg_time64
        418 mq_timedsend_time64
        419 mq_timedreceiv_time64
        420 semtimedop_time64
        421 rt_sigtimedwait_time64
        422 futex_time64
        423 sched_rr_get_interval_time64
    
      The syscall numbers are identical all over the architectures"
    
    * 'timers-2038-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (36 commits)
      riscv: Use latest system call ABI
      checksyscalls: fix up mq_timedreceive and stat exceptions
      unicore32: Fix __ARCH_WANT_STAT64 definition
      asm-generic: Make time32 syscall numbers optional
      asm-generic: Drop getrlimit and setrlimit syscalls from default list
      32-bit userspace ABI: introduce ARCH_32BIT_OFF_T config option
      compat ABI: use non-compat openat and open_by_handle_at variants
      y2038: add 64-bit time_t syscalls to all 32-bit architectures
      y2038: rename old time and utime syscalls
      y2038: remove struct definition redirects
      y2038: use time32 syscall names on 32-bit
      syscalls: remove obsolete __IGNORE_ macros
      y2038: syscalls: rename y2038 compat syscalls
      x86/x32: use time64 versions of sigtimedwait and recvmmsg
      timex: change syscalls to use struct __kernel_timex
      timex: use __kernel_timex internally
      sparc64: add custom adjtimex/clock_adjtime functions
      time: fix sys_timer_settime prototype
      time: Add struct __kernel_timex
      time: make adjtime compat handling available for 32 bit
      ...

commit 3eb39f47934f9d5a3027fe00d906a45fe3a15fad
Author: Christian Brauner <christian@brauner.io>
Date:   Mon Nov 19 00:51:56 2018 +0100

    signal: add pidfd_send_signal() syscall
    
    The kill() syscall operates on process identifiers (pid). After a process
    has exited its pid can be reused by another process. If a caller sends a
    signal to a reused pid it will end up signaling the wrong process. This
    issue has often surfaced and there has been a push to address this problem [1].
    
    This patch uses file descriptors (fd) from proc/<pid> as stable handles on
    struct pid. Even if a pid is recycled the handle will not change. The fd
    can be used to send signals to the process it refers to.
    Thus, the new syscall pidfd_send_signal() is introduced to solve this
    problem. Instead of pids it operates on process fds (pidfd).
    
    /* prototype and argument /*
    long pidfd_send_signal(int pidfd, int sig, siginfo_t *info, unsigned int flags);
    
    /* syscall number 424 */
    The syscall number was chosen to be 424 to align with Arnd's rework in his
    y2038 to minimize merge conflicts (cf. [25]).
    
    In addition to the pidfd and signal argument it takes an additional
    siginfo_t and flags argument. If the siginfo_t argument is NULL then
    pidfd_send_signal() is equivalent to kill(<positive-pid>, <signal>). If it
    is not NULL pidfd_send_signal() is equivalent to rt_sigqueueinfo().
    The flags argument is added to allow for future extensions of this syscall.
    It currently needs to be passed as 0. Failing to do so will cause EINVAL.
    
    /* pidfd_send_signal() replaces multiple pid-based syscalls */
    The pidfd_send_signal() syscall currently takes on the job of
    rt_sigqueueinfo(2) and parts of the functionality of kill(2), Namely, when a
    positive pid is passed to kill(2). It will however be possible to also
    replace tgkill(2) and rt_tgsigqueueinfo(2) if this syscall is extended.
    
    /* sending signals to threads (tid) and process groups (pgid) */
    Specifically, the pidfd_send_signal() syscall does currently not operate on
    process groups or threads. This is left for future extensions.
    In order to extend the syscall to allow sending signal to threads and
    process groups appropriately named flags (e.g. PIDFD_TYPE_PGID, and
    PIDFD_TYPE_TID) should be added. This implies that the flags argument will
    determine what is signaled and not the file descriptor itself. Put in other
    words, grouping in this api is a property of the flags argument not a
    property of the file descriptor (cf. [13]). Clarification for this has been
    requested by Eric (cf. [19]).
    When appropriate extensions through the flags argument are added then
    pidfd_send_signal() can additionally replace the part of kill(2) which
    operates on process groups as well as the tgkill(2) and
    rt_tgsigqueueinfo(2) syscalls.
    How such an extension could be implemented has been very roughly sketched
    in [14], [15], and [16]. However, this should not be taken as a commitment
    to a particular implementation. There might be better ways to do it.
    Right now this is intentionally left out to keep this patchset as simple as
    possible (cf. [4]).
    
    /* naming */
    The syscall had various names throughout iterations of this patchset:
    - procfd_signal()
    - procfd_send_signal()
    - taskfd_send_signal()
    In the last round of reviews it was pointed out that given that if the
    flags argument decides the scope of the signal instead of different types
    of fds it might make sense to either settle for "procfd_" or "pidfd_" as
    prefix. The community was willing to accept either (cf. [17] and [18]).
    Given that one developer expressed strong preference for the "pidfd_"
    prefix (cf. [13]) and with other developers less opinionated about the name
    we should settle for "pidfd_" to avoid further bikeshedding.
    
    The  "_send_signal" suffix was chosen to reflect the fact that the syscall
    takes on the job of multiple syscalls. It is therefore intentional that the
    name is not reminiscent of neither kill(2) nor rt_sigqueueinfo(2). Not the
    fomer because it might imply that pidfd_send_signal() is a replacement for
    kill(2), and not the latter because it is a hassle to remember the correct
    spelling - especially for non-native speakers - and because it is not
    descriptive enough of what the syscall actually does. The name
    "pidfd_send_signal" makes it very clear that its job is to send signals.
    
    /* zombies */
    Zombies can be signaled just as any other process. No special error will be
    reported since a zombie state is an unreliable state (cf. [3]). However,
    this can be added as an extension through the @flags argument if the need
    ever arises.
    
    /* cross-namespace signals */
    The patch currently enforces that the signaler and signalee either are in
    the same pid namespace or that the signaler's pid namespace is an ancestor
    of the signalee's pid namespace. This is done for the sake of simplicity
    and because it is unclear to what values certain members of struct
    siginfo_t would need to be set to (cf. [5], [6]).
    
    /* compat syscalls */
    It became clear that we would like to avoid adding compat syscalls
    (cf. [7]).  The compat syscall handling is now done in kernel/signal.c
    itself by adding __copy_siginfo_from_user_generic() which lets us avoid
    compat syscalls (cf. [8]). It should be noted that the addition of
    __copy_siginfo_from_user_any() is caused by a bug in the original
    implementation of rt_sigqueueinfo(2) (cf. 12).
    With upcoming rework for syscall handling things might improve
    significantly (cf. [11]) and __copy_siginfo_from_user_any() will not gain
    any additional callers.
    
    /* testing */
    This patch was tested on x64 and x86.
    
    /* userspace usage */
    An asciinema recording for the basic functionality can be found under [9].
    With this patch a process can be killed via:
    
     #define _GNU_SOURCE
     #include <errno.h>
     #include <fcntl.h>
     #include <signal.h>
     #include <stdio.h>
     #include <stdlib.h>
     #include <string.h>
     #include <sys/stat.h>
     #include <sys/syscall.h>
     #include <sys/types.h>
     #include <unistd.h>
    
     static inline int do_pidfd_send_signal(int pidfd, int sig, siginfo_t *info,
                                             unsigned int flags)
     {
     #ifdef __NR_pidfd_send_signal
             return syscall(__NR_pidfd_send_signal, pidfd, sig, info, flags);
     #else
             return -ENOSYS;
     #endif
     }
    
     int main(int argc, char *argv[])
     {
             int fd, ret, saved_errno, sig;
    
             if (argc < 3)
                     exit(EXIT_FAILURE);
    
             fd = open(argv[1], O_DIRECTORY | O_CLOEXEC);
             if (fd < 0) {
                     printf("%s - Failed to open \"%s\"\n", strerror(errno), argv[1]);
                     exit(EXIT_FAILURE);
             }
    
             sig = atoi(argv[2]);
    
             printf("Sending signal %d to process %s\n", sig, argv[1]);
             ret = do_pidfd_send_signal(fd, sig, NULL, 0);
    
             saved_errno = errno;
             close(fd);
             errno = saved_errno;
    
             if (ret < 0) {
                     printf("%s - Failed to send signal %d to process %s\n",
                            strerror(errno), sig, argv[1]);
                     exit(EXIT_FAILURE);
             }
    
             exit(EXIT_SUCCESS);
     }
    
    /* Q&A
     * Given that it seems the same questions get asked again by people who are
     * late to the party it makes sense to add a Q&A section to the commit
     * message so it's hopefully easier to avoid duplicate threads.
     *
     * For the sake of progress please consider these arguments settled unless
     * there is a new point that desperately needs to be addressed. Please make
     * sure to check the links to the threads in this commit message whether
     * this has not already been covered.
     */
    Q-01: (Florian Weimer [20], Andrew Morton [21])
          What happens when the target process has exited?
    A-01: Sending the signal will fail with ESRCH (cf. [22]).
    
    Q-02:  (Andrew Morton [21])
           Is the task_struct pinned by the fd?
    A-02:  No. A reference to struct pid is kept. struct pid - as far as I
           understand - was created exactly for the reason to not require to
           pin struct task_struct (cf. [22]).
    
    Q-03: (Andrew Morton [21])
          Does the entire procfs directory remain visible? Just one entry
          within it?
    A-03: The same thing that happens right now when you hold a file descriptor
          to /proc/<pid> open (cf. [22]).
    
    Q-04: (Andrew Morton [21])
          Does the pid remain reserved?
    A-04: No. This patchset guarantees a stable handle not that pids are not
          recycled (cf. [22]).
    
    Q-05: (Andrew Morton [21])
          Do attempts to signal that fd return errors?
    A-05: See {Q,A}-01.
    
    Q-06: (Andrew Morton [22])
          Is there a cleaner way of obtaining the fd? Another syscall perhaps.
    A-06: Userspace can already trivially retrieve file descriptors from procfs
          so this is something that we will need to support anyway. Hence,
          there's no immediate need to add another syscalls just to make
          pidfd_send_signal() not dependent on the presence of procfs. However,
          adding a syscalls to get such file descriptors is planned for a
          future patchset (cf. [22]).
    
    Q-07: (Andrew Morton [21] and others)
          This fd-for-a-process sounds like a handy thing and people may well
          think up other uses for it in the future, probably unrelated to
          signals. Are the code and the interface designed to permit such
          future applications?
    A-07: Yes (cf. [22]).
    
    Q-08: (Andrew Morton [21] and others)
          Now I think about it, why a new syscall? This thing is looking
          rather like an ioctl?
    A-08: This has been extensively discussed. It was agreed that a syscall is
          preferred for a variety or reasons. Here are just a few taken from
          prior threads. Syscalls are safer than ioctl()s especially when
          signaling to fds. Processes are a core kernel concept so a syscall
          seems more appropriate. The layout of the syscall with its four
          arguments would require the addition of a custom struct for the
          ioctl() thereby causing at least the same amount or even more
          complexity for userspace than a simple syscall. The new syscall will
          replace multiple other pid-based syscalls (see description above).
          The file-descriptors-for-processes concept introduced with this
          syscall will be extended with other syscalls in the future. See also
          [22], [23] and various other threads already linked in here.
    
    Q-09: (Florian Weimer [24])
          What happens if you use the new interface with an O_PATH descriptor?
    A-09:
          pidfds opened as O_PATH fds cannot be used to send signals to a
          process (cf. [2]). Signaling processes through pidfds is the
          equivalent of writing to a file. Thus, this is not an operation that
          operates "purely at the file descriptor level" as required by the
          open(2) manpage. See also [4].
    
    /* References */
    [1]:  https://lore.kernel.org/lkml/20181029221037.87724-1-dancol@google.com/
    [2]:  https://lore.kernel.org/lkml/874lbtjvtd.fsf@oldenburg2.str.redhat.com/
    [3]:  https://lore.kernel.org/lkml/20181204132604.aspfupwjgjx6fhva@brauner.io/
    [4]:  https://lore.kernel.org/lkml/20181203180224.fkvw4kajtbvru2ku@brauner.io/
    [5]:  https://lore.kernel.org/lkml/20181121213946.GA10795@mail.hallyn.com/
    [6]:  https://lore.kernel.org/lkml/20181120103111.etlqp7zop34v6nv4@brauner.io/
    [7]:  https://lore.kernel.org/lkml/36323361-90BD-41AF-AB5B-EE0D7BA02C21@amacapital.net/
    [8]:  https://lore.kernel.org/lkml/87tvjxp8pc.fsf@xmission.com/
    [9]:  https://asciinema.org/a/IQjuCHew6bnq1cr78yuMv16cy
    [11]: https://lore.kernel.org/lkml/F53D6D38-3521-4C20-9034-5AF447DF62FF@amacapital.net/
    [12]: https://lore.kernel.org/lkml/87zhtjn8ck.fsf@xmission.com/
    [13]: https://lore.kernel.org/lkml/871s6u9z6u.fsf@xmission.com/
    [14]: https://lore.kernel.org/lkml/20181206231742.xxi4ghn24z4h2qki@brauner.io/
    [15]: https://lore.kernel.org/lkml/20181207003124.GA11160@mail.hallyn.com/
    [16]: https://lore.kernel.org/lkml/20181207015423.4miorx43l3qhppfz@brauner.io/
    [17]: https://lore.kernel.org/lkml/CAGXu5jL8PciZAXvOvCeCU3wKUEB_dU-O3q0tDw4uB_ojMvDEew@mail.gmail.com/
    [18]: https://lore.kernel.org/lkml/20181206222746.GB9224@mail.hallyn.com/
    [19]: https://lore.kernel.org/lkml/20181208054059.19813-1-christian@brauner.io/
    [20]: https://lore.kernel.org/lkml/8736rebl9s.fsf@oldenburg.str.redhat.com/
    [21]: https://lore.kernel.org/lkml/20181228152012.dbf0508c2508138efc5f2bbe@linux-foundation.org/
    [22]: https://lore.kernel.org/lkml/20181228233725.722tdfgijxcssg76@brauner.io/
    [23]: https://lwn.net/Articles/773459/
    [24]: https://lore.kernel.org/lkml/8736rebl9s.fsf@oldenburg.str.redhat.com/
    [25]: https://lore.kernel.org/lkml/CAK8P3a0ej9NcJM8wXNPbcGUyOUZYX+VLoDFdbenW3s3114oQZw@mail.gmail.com/
    
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Jann Horn <jannh@google.com>
    Cc: Andy Lutomirsky <luto@kernel.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Florian Weimer <fweimer@redhat.com>
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Reviewed-by: Tycho Andersen <tycho@tycho.ws>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: David Howells <dhowells@redhat.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Serge Hallyn <serge@hallyn.com>
    Acked-by: Aleksa Sarai <cyphar@cyphar.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index e1d7ad8e6ab1..268bed80244f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -19,7 +19,9 @@
 #include <linux/sched/task.h>
 #include <linux/sched/task_stack.h>
 #include <linux/sched/cputime.h>
+#include <linux/file.h>
 #include <linux/fs.h>
+#include <linux/proc_fs.h>
 #include <linux/tty.h>
 #include <linux/binfmts.h>
 #include <linux/coredump.h>
@@ -3429,6 +3431,16 @@ COMPAT_SYSCALL_DEFINE4(rt_sigtimedwait, compat_sigset_t __user *, uthese,
 #endif
 #endif
 
+static inline void prepare_kill_siginfo(int sig, struct kernel_siginfo *info)
+{
+	clear_siginfo(info);
+	info->si_signo = sig;
+	info->si_errno = 0;
+	info->si_code = SI_USER;
+	info->si_pid = task_tgid_vnr(current);
+	info->si_uid = from_kuid_munged(current_user_ns(), current_uid());
+}
+
 /**
  *  sys_kill - send a signal to a process
  *  @pid: the PID of the process
@@ -3438,16 +3450,125 @@ SYSCALL_DEFINE2(kill, pid_t, pid, int, sig)
 {
 	struct kernel_siginfo info;
 
-	clear_siginfo(&info);
-	info.si_signo = sig;
-	info.si_errno = 0;
-	info.si_code = SI_USER;
-	info.si_pid = task_tgid_vnr(current);
-	info.si_uid = from_kuid_munged(current_user_ns(), current_uid());
+	prepare_kill_siginfo(sig, &info);
 
 	return kill_something_info(sig, &info, pid);
 }
 
+#ifdef CONFIG_PROC_FS
+/*
+ * Verify that the signaler and signalee either are in the same pid namespace
+ * or that the signaler's pid namespace is an ancestor of the signalee's pid
+ * namespace.
+ */
+static bool access_pidfd_pidns(struct pid *pid)
+{
+	struct pid_namespace *active = task_active_pid_ns(current);
+	struct pid_namespace *p = ns_of_pid(pid);
+
+	for (;;) {
+		if (!p)
+			return false;
+		if (p == active)
+			break;
+		p = p->parent;
+	}
+
+	return true;
+}
+
+static int copy_siginfo_from_user_any(kernel_siginfo_t *kinfo, siginfo_t *info)
+{
+#ifdef CONFIG_COMPAT
+	/*
+	 * Avoid hooking up compat syscalls and instead handle necessary
+	 * conversions here. Note, this is a stop-gap measure and should not be
+	 * considered a generic solution.
+	 */
+	if (in_compat_syscall())
+		return copy_siginfo_from_user32(
+			kinfo, (struct compat_siginfo __user *)info);
+#endif
+	return copy_siginfo_from_user(kinfo, info);
+}
+
+/**
+ * sys_pidfd_send_signal - send a signal to a process through a task file
+ *                          descriptor
+ * @pidfd:  the file descriptor of the process
+ * @sig:    signal to be sent
+ * @info:   the signal info
+ * @flags:  future flags to be passed
+ *
+ * The syscall currently only signals via PIDTYPE_PID which covers
+ * kill(<positive-pid>, <signal>. It does not signal threads or process
+ * groups.
+ * In order to extend the syscall to threads and process groups the @flags
+ * argument should be used. In essence, the @flags argument will determine
+ * what is signaled and not the file descriptor itself. Put in other words,
+ * grouping is a property of the flags argument not a property of the file
+ * descriptor.
+ *
+ * Return: 0 on success, negative errno on failure
+ */
+SYSCALL_DEFINE4(pidfd_send_signal, int, pidfd, int, sig,
+		siginfo_t __user *, info, unsigned int, flags)
+{
+	int ret;
+	struct fd f;
+	struct pid *pid;
+	kernel_siginfo_t kinfo;
+
+	/* Enforce flags be set to 0 until we add an extension. */
+	if (flags)
+		return -EINVAL;
+
+	f = fdget_raw(pidfd);
+	if (!f.file)
+		return -EBADF;
+
+	/* Is this a pidfd? */
+	pid = tgid_pidfd_to_pid(f.file);
+	if (IS_ERR(pid)) {
+		ret = PTR_ERR(pid);
+		goto err;
+	}
+
+	ret = -EINVAL;
+	if (!access_pidfd_pidns(pid))
+		goto err;
+
+	if (info) {
+		ret = copy_siginfo_from_user_any(&kinfo, info);
+		if (unlikely(ret))
+			goto err;
+
+		ret = -EINVAL;
+		if (unlikely(sig != kinfo.si_signo))
+			goto err;
+
+		if ((task_pid(current) != pid) &&
+		    (kinfo.si_code >= 0 || kinfo.si_code == SI_TKILL)) {
+			/* Only allow sending arbitrary signals to yourself. */
+			ret = -EPERM;
+			if (kinfo.si_code != SI_USER)
+				goto err;
+
+			/* Turn this into a regular kill signal. */
+			prepare_kill_siginfo(sig, &kinfo);
+		}
+	} else {
+		prepare_kill_siginfo(sig, &kinfo);
+	}
+
+	ret = kill_pid_info(sig, &kinfo, pid);
+
+err:
+	fdput(f);
+	return ret;
+}
+#endif /* CONFIG_PROC_FS */
+
 static int
 do_send_specific(pid_t tgid, pid_t pid, int sig, struct kernel_siginfo *info)
 {

commit cf43a757fd49442bc38f76088b70c2299eed2c2f
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Feb 11 23:27:42 2019 -0600

    signal: Restore the stop PTRACE_EVENT_EXIT
    
    In the middle of do_exit() there is there is a call
    "ptrace_event(PTRACE_EVENT_EXIT, code);" That call places the process
    in TACKED_TRACED aka "(TASK_WAKEKILL | __TASK_TRACED)" and waits for
    for the debugger to release the task or SIGKILL to be delivered.
    
    Skipping past dequeue_signal when we know a fatal signal has already
    been delivered resulted in SIGKILL remaining pending and
    TIF_SIGPENDING remaining set.  This in turn caused the
    scheduler to not sleep in PTACE_EVENT_EXIT as it figured
    a fatal signal was pending.  This also caused ptrace_freeze_traced
    in ptrace_check_attach to fail because it left a per thread
    SIGKILL pending which is what fatal_signal_pending tests for.
    
    This difference in signal state caused strace to report
    strace: Exit of unknown pid NNNNN ignored
    
    Therefore update the signal handling state like dequeue_signal
    would when removing a per thread SIGKILL, by removing SIGKILL
    from the per thread signal mask and clearing TIF_SIGPENDING.
    
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Reported-by: Oleg Nesterov <oleg@redhat.com>
    Reported-by: Ivan Delalande <colona@arista.com>
    Cc: stable@vger.kernel.org
    Fixes: 35634ffa1751 ("signal: Always notice exiting tasks")
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 99fa8ff06fd9..57b7771e20d7 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2436,9 +2436,12 @@ bool get_signal(struct ksignal *ksig)
 	}
 
 	/* Has this task already been marked for death? */
-	ksig->info.si_signo = signr = SIGKILL;
-	if (signal_group_exit(signal))
+	if (signal_group_exit(signal)) {
+		ksig->info.si_signo = signr = SIGKILL;
+		sigdelset(&current->pending.signal, SIGKILL);
+		recalc_sigpending();
 		goto fatal;
+	}
 
 	for (;;) {
 		struct k_sigaction *ka;

commit 7146db3317c67b517258cb5e1b08af387da0618b
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Feb 6 17:51:47 2019 -0600

    signal: Better detection of synchronous signals
    
    Recently syzkaller was able to create unkillablle processes by
    creating a timer that is delivered as a thread local signal on SIGHUP,
    and receiving SIGHUP SA_NODEFERER.  Ultimately causing a loop failing
    to deliver SIGHUP but always trying.
    
    When the stack overflows delivery of SIGHUP fails and force_sigsegv is
    called.  Unfortunately because SIGSEGV is numerically higher than
    SIGHUP next_signal tries again to deliver a SIGHUP.
    
    From a quality of implementation standpoint attempting to deliver the
    timer SIGHUP signal is wrong.  We should attempt to deliver the
    synchronous SIGSEGV signal we just forced.
    
    We can make that happening in a fairly straight forward manner by
    instead of just looking at the signal number we also look at the
    si_code.  In particular for exceptions (aka synchronous signals) the
    si_code is always greater than 0.
    
    That still has the potential to pick up a number of asynchronous
    signals as in a few cases the same si_codes that are used
    for synchronous signals are also used for asynchronous signals,
    and SI_KERNEL is also included in the list of possible si_codes.
    
    Still the heuristic is much better and timer signals are definitely
    excluded.  Which is enough to prevent all known ways for someone
    sending a process signals fast enough to cause unexpected and
    arguably incorrect behavior.
    
    Cc: stable@vger.kernel.org
    Fixes: a27341cd5fcb ("Prioritize synchronous signals over 'normal' signals")
    Tested-by: Dmitry Vyukov <dvyukov@google.com>
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5424cb0006bc..99fa8ff06fd9 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -688,6 +688,48 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, kernel_siginfo_t *in
 }
 EXPORT_SYMBOL_GPL(dequeue_signal);
 
+static int dequeue_synchronous_signal(kernel_siginfo_t *info)
+{
+	struct task_struct *tsk = current;
+	struct sigpending *pending = &tsk->pending;
+	struct sigqueue *q, *sync = NULL;
+
+	/*
+	 * Might a synchronous signal be in the queue?
+	 */
+	if (!((pending->signal.sig[0] & ~tsk->blocked.sig[0]) & SYNCHRONOUS_MASK))
+		return 0;
+
+	/*
+	 * Return the first synchronous signal in the queue.
+	 */
+	list_for_each_entry(q, &pending->list, list) {
+		/* Synchronous signals have a postive si_code */
+		if ((q->info.si_code > SI_USER) &&
+		    (sigmask(q->info.si_signo) & SYNCHRONOUS_MASK)) {
+			sync = q;
+			goto next;
+		}
+	}
+	return 0;
+next:
+	/*
+	 * Check if there is another siginfo for the same signal.
+	 */
+	list_for_each_entry_continue(q, &pending->list, list) {
+		if (q->info.si_signo == sync->info.si_signo)
+			goto still_pending;
+	}
+
+	sigdelset(&pending->signal, sync->info.si_signo);
+	recalc_sigpending();
+still_pending:
+	list_del_init(&sync->list);
+	copy_siginfo(info, &sync->info);
+	__sigqueue_free(sync);
+	return info->si_signo;
+}
+
 /*
  * Tell a process that it has a new active signal..
  *
@@ -2411,7 +2453,15 @@ bool get_signal(struct ksignal *ksig)
 			goto relock;
 		}
 
-		signr = dequeue_signal(current, &current->blocked, &ksig->info);
+		/*
+		 * Signals generated by the execution of an instruction
+		 * need to be delivered before any other pending signals
+		 * so that the instruction pointer in the signal stack
+		 * frame points to the faulting instruction.
+		 */
+		signr = dequeue_synchronous_signal(&ksig->info);
+		if (!signr)
+			signr = dequeue_signal(current, &current->blocked, &ksig->info);
 
 		if (!signr)
 			break; /* will return 0 */

commit 35634ffa1751b6efd8cf75010b509dcb0263e29b
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Feb 6 18:39:40 2019 -0600

    signal: Always notice exiting tasks
    
    Recently syzkaller was able to create unkillablle processes by
    creating a timer that is delivered as a thread local signal on SIGHUP,
    and receiving SIGHUP SA_NODEFERER.  Ultimately causing a loop
    failing to deliver SIGHUP but always trying.
    
    Upon examination it turns out part of the problem is actually most of
    the solution.  Since 2.5 signal delivery has found all fatal signals,
    marked the signal group for death, and queued SIGKILL in every threads
    thread queue relying on signal->group_exit_code to preserve the
    information of which was the actual fatal signal.
    
    The conversion of all fatal signals to SIGKILL results in the
    synchronous signal heuristic in next_signal kicking in and preferring
    SIGHUP to SIGKILL.  Which is especially problematic as all
    fatal signals have already been transformed into SIGKILL.
    
    Instead of dequeueing signals and depending upon SIGKILL to
    be the first signal dequeued, first test if the signal group
    has already been marked for death.  This guarantees that
    nothing in the signal queue can prevent a process that needs
    to exit from exiting.
    
    Cc: stable@vger.kernel.org
    Tested-by: Dmitry Vyukov <dvyukov@google.com>
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Ref: ebf5ebe31d2c ("[PATCH] signal-fixes-2.5.59-A4")
    History Tree: https://git.kernel.org/pub/scm/linux/kernel/git/tglx/history.git
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9ca8e5278c8e..5424cb0006bc 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2393,6 +2393,11 @@ bool get_signal(struct ksignal *ksig)
 		goto relock;
 	}
 
+	/* Has this task already been marked for death? */
+	ksig->info.si_signo = signr = SIGKILL;
+	if (signal_group_exit(signal))
+		goto fatal;
+
 	for (;;) {
 		struct k_sigaction *ka;
 
@@ -2488,6 +2493,7 @@ bool get_signal(struct ksignal *ksig)
 			continue;
 		}
 
+	fatal:
 		spin_unlock_irq(&sighand->siglock);
 
 		/*

commit 8dabe7245bbc134f2cfcc12cde75c019dab924cc
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon Jan 7 00:33:08 2019 +0100

    y2038: syscalls: rename y2038 compat syscalls
    
    A lot of system calls that pass a time_t somewhere have an implementation
    using a COMPAT_SYSCALL_DEFINEx() on 64-bit architectures, and have
    been reworked so that this implementation can now be used on 32-bit
    architectures as well.
    
    The missing step is to redefine them using the regular SYSCALL_DEFINEx()
    to get them out of the compat namespace and make it possible to build them
    on 32-bit architectures.
    
    Any system call that ends in 'time' gets a '32' suffix on its name for
    that version, while the others get a '_time32' suffix, to distinguish
    them from the normal version, which takes a 64-bit time argument in the
    future.
    
    In this step, only 64-bit architectures are changed, doing this rename
    first lets us avoid touching the 32-bit architectures twice.
    
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/kernel/signal.c b/kernel/signal.c
index e1d7ad8e6ab1..af27629918cf 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3397,7 +3397,7 @@ COMPAT_SYSCALL_DEFINE4(rt_sigtimedwait_time64, compat_sigset_t __user *, uthese,
 }
 
 #ifdef CONFIG_COMPAT_32BIT_TIME
-COMPAT_SYSCALL_DEFINE4(rt_sigtimedwait, compat_sigset_t __user *, uthese,
+COMPAT_SYSCALL_DEFINE4(rt_sigtimedwait_time32, compat_sigset_t __user *, uthese,
 		struct compat_siginfo __user *, uinfo,
 		struct old_timespec32 __user *, uts, compat_size_t, sigsetsize)
 {

commit a692933a87691681e880feb708081681ff32400a
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Feb 5 07:19:11 2019 -0600

    signal: Always attempt to allocate siginfo for SIGSTOP
    
    Since 2.5.34 the code has had the potential to not allocate siginfo
    for SIGSTOP signals.  Except for ptrace this is perfectly fine as only
    ptrace can use PTRACE_PEEK_SIGINFO and see what the contents of
    the delivered siginfo are.
    
    Users of PTRACE_PEEK_SIGINFO that care about the contents siginfo
    for SIGSTOP are rare, but they do exist.  A seccomp self test
    has cared and lldb cares.
    
    Jack Andersen <jackoalan@gmail.com> writes:
    
    > The patch titled
    > `signal: Never allocate siginfo for SIGKILL or SIGSTOP`
    > created a regression for users of PTRACE_GETSIGINFO needing to
    > discern signals that were raised via the tgkill syscall.
    >
    > A notable user of this tgkill+ptrace combination is lldb while
    > debugging a multithreaded program. Without the ability to detect a
    > SIGSTOP originating from tgkill, lldb does not have a way to
    > synchronize on a per-thread basis and falls back to SIGSTOP-ing the
    > entire process.
    
    Everyone affected by this please note.  The kernel can still fail to
    allocate a siginfo structure.  The allocation is with GFP_KERNEL and
    is best effort only.  If memory is tight when the signal allocation
    comes in this will fail to allocate a siginfo.
    
    So I strongly recommend looking at more robust solutions for
    synchronizing with a single thread such as PTRACE_INTERRUPT.  Or if
    that does not work persuading your friendly local kernel developer to
    build the interface you need.
    
    Reported-by: Tycho Andersen <tycho@tycho.ws>
    Reported-by: Kees Cook <keescook@chromium.org>
    Reported-by: Jack Andersen <jackoalan@gmail.com>
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Reviewed-by: Christian Brauner <christian@brauner.io>
    Cc: stable@vger.kernel.org
    Fixes: f149b3155744 ("signal: Never allocate siginfo for SIGKILL or SIGSTOP")
    Fixes: 6dfc88977e42 ("[PATCH] shared thread signals")
    History Tree: https://git.kernel.org/pub/scm/linux/kernel/git/tglx/history.git
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index e1d7ad8e6ab1..9ca8e5278c8e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1057,10 +1057,9 @@ static int __send_signal(int sig, struct kernel_siginfo *info, struct task_struc
 
 	result = TRACE_SIGNAL_DELIVERED;
 	/*
-	 * Skip useless siginfo allocation for SIGKILL SIGSTOP,
-	 * and kernel threads.
+	 * Skip useless siginfo allocation for SIGKILL and kernel threads.
 	 */
-	if (sig_kernel_only(sig) || (t->flags & PF_KTHREAD))
+	if ((sig == SIGKILL) || (t->flags & PF_KTHREAD))
 		goto out_set;
 
 	/*

commit 96d4f267e40f9509e8a66e2b39e8b95655617693
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 3 18:57:57 2019 -0800

    Remove 'type' argument from access_ok() function
    
    Nobody has actually used the type (VERIFY_READ vs VERIFY_WRITE) argument
    of the user address range verification function since we got rid of the
    old racy i386-only code to walk page tables by hand.
    
    It existed because the original 80386 would not honor the write protect
    bit when in kernel mode, so you had to do COW by hand before doing any
    user access.  But we haven't supported that in a long time, and these
    days the 'type' argument is a purely historical artifact.
    
    A discussion about extending 'user_access_begin()' to do the range
    checking resulted this patch, because there is no way we're going to
    move the old VERIFY_xyz interface to that model.  And it's best done at
    the end of the merge window when I've done most of my merges, so let's
    just get this done once and for all.
    
    This patch was mostly done with a sed-script, with manual fix-ups for
    the cases that weren't of the trivial 'access_ok(VERIFY_xyz' form.
    
    There were a couple of notable cases:
    
     - csky still had the old "verify_area()" name as an alias.
    
     - the iter_iov code had magical hardcoded knowledge of the actual
       values of VERIFY_{READ,WRITE} (not that they mattered, since nothing
       really used it)
    
     - microblaze used the type argument for a debug printout
    
    but other than those oddities this should be a total no-op patch.
    
    I tried to fix up all architectures, did fairly extensive grepping for
    access_ok() uses, and the changes are trivial, but I may have missed
    something.  Any missed conversion should be trivially fixable, though.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 53e07d97ffe0..e1d7ad8e6ab1 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3997,7 +3997,7 @@ SYSCALL_DEFINE3(sigaction, int, sig,
 
 	if (act) {
 		old_sigset_t mask;
-		if (!access_ok(VERIFY_READ, act, sizeof(*act)) ||
+		if (!access_ok(act, sizeof(*act)) ||
 		    __get_user(new_ka.sa.sa_handler, &act->sa_handler) ||
 		    __get_user(new_ka.sa.sa_restorer, &act->sa_restorer) ||
 		    __get_user(new_ka.sa.sa_flags, &act->sa_flags) ||
@@ -4012,7 +4012,7 @@ SYSCALL_DEFINE3(sigaction, int, sig,
 	ret = do_sigaction(sig, act ? &new_ka : NULL, oact ? &old_ka : NULL);
 
 	if (!ret && oact) {
-		if (!access_ok(VERIFY_WRITE, oact, sizeof(*oact)) ||
+		if (!access_ok(oact, sizeof(*oact)) ||
 		    __put_user(old_ka.sa.sa_handler, &oact->sa_handler) ||
 		    __put_user(old_ka.sa.sa_restorer, &oact->sa_restorer) ||
 		    __put_user(old_ka.sa.sa_flags, &oact->sa_flags) ||
@@ -4034,7 +4034,7 @@ COMPAT_SYSCALL_DEFINE3(sigaction, int, sig,
 	compat_uptr_t handler, restorer;
 
 	if (act) {
-		if (!access_ok(VERIFY_READ, act, sizeof(*act)) ||
+		if (!access_ok(act, sizeof(*act)) ||
 		    __get_user(handler, &act->sa_handler) ||
 		    __get_user(restorer, &act->sa_restorer) ||
 		    __get_user(new_ka.sa.sa_flags, &act->sa_flags) ||
@@ -4052,7 +4052,7 @@ COMPAT_SYSCALL_DEFINE3(sigaction, int, sig,
 	ret = do_sigaction(sig, act ? &new_ka : NULL, oact ? &old_ka : NULL);
 
 	if (!ret && oact) {
-		if (!access_ok(VERIFY_WRITE, oact, sizeof(*oact)) ||
+		if (!access_ok(oact, sizeof(*oact)) ||
 		    __put_user(ptr_to_compat(old_ka.sa.sa_handler),
 			       &oact->sa_handler) ||
 		    __put_user(ptr_to_compat(old_ka.sa.sa_restorer),

commit 2367c4b5fa09b2947d03c5cd23d7bc0200b7fe4f
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed Apr 18 16:18:35 2018 +0200

    y2038: signal: Add compat_sys_rt_sigtimedwait_time64
    
    Now that 32-bit architectures have two variants of sys_rt_sigtimedwaid()
    for 32-bit and 64-bit time_t, we also need to have a second compat system
    call entry point on the corresponding 64-bit architectures.
    
    The traditional system call keeps getting handled
    by compat_sys_rt_sigtimedwait(), and this adds a new
    compat_sys_rt_sigtimedwait_time64() that differs only in the timeout
    argument type.
    
    The naming remains a bit asymmetric for the moment. Ideally we would
    want to have compat_sys_rt_sigtimedwait_time32() for the old version
    and compat_sys_rt_sigtimedwait() for the new one to mirror the names
    of the native entry points, but renaming the existing system call
    tables causes unnecessary churn. I would suggest renaming all such
    system calls together at a later point.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/kernel/signal.c b/kernel/signal.c
index be6744cd0a11..53e07d97ffe0 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3366,6 +3366,37 @@ SYSCALL_DEFINE4(rt_sigtimedwait_time32, const sigset_t __user *, uthese,
 #endif
 
 #ifdef CONFIG_COMPAT
+COMPAT_SYSCALL_DEFINE4(rt_sigtimedwait_time64, compat_sigset_t __user *, uthese,
+		struct compat_siginfo __user *, uinfo,
+		struct __kernel_timespec __user *, uts, compat_size_t, sigsetsize)
+{
+	sigset_t s;
+	struct timespec64 t;
+	kernel_siginfo_t info;
+	long ret;
+
+	if (sigsetsize != sizeof(sigset_t))
+		return -EINVAL;
+
+	if (get_compat_sigset(&s, uthese))
+		return -EFAULT;
+
+	if (uts) {
+		if (get_timespec64(&t, uts))
+			return -EFAULT;
+	}
+
+	ret = do_sigtimedwait(&s, &info, uts ? &t : NULL);
+
+	if (ret > 0 && uinfo) {
+		if (copy_siginfo_to_user32(uinfo, &info))
+			ret = -EFAULT;
+	}
+
+	return ret;
+}
+
+#ifdef CONFIG_COMPAT_32BIT_TIME
 COMPAT_SYSCALL_DEFINE4(rt_sigtimedwait, compat_sigset_t __user *, uthese,
 		struct compat_siginfo __user *, uinfo,
 		struct old_timespec32 __user *, uts, compat_size_t, sigsetsize)
@@ -3396,6 +3427,7 @@ COMPAT_SYSCALL_DEFINE4(rt_sigtimedwait, compat_sigset_t __user *, uthese,
 	return ret;
 }
 #endif
+#endif
 
 /**
  *  sys_kill - send a signal to a process

commit df8522a340ee4ccb725036e1f9145f5646939aed
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed Apr 18 16:15:37 2018 +0200

    y2038: signal: Add sys_rt_sigtimedwait_time32
    
    Once sys_rt_sigtimedwait() gets changed to a 64-bit time_t, we have
    to provide compatibility support for existing binaries.
    
    An earlier version of this patch reused the compat_sys_rt_sigtimedwait
    entry point to avoid code duplication, but this newer approach
    duplicates the existing native entry point instead, which seems
    a bit cleaner.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/kernel/signal.c b/kernel/signal.c
index 3c8ea7a328e0..be6744cd0a11 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3332,6 +3332,39 @@ SYSCALL_DEFINE4(rt_sigtimedwait, const sigset_t __user *, uthese,
 	return ret;
 }
 
+#ifdef CONFIG_COMPAT_32BIT_TIME
+SYSCALL_DEFINE4(rt_sigtimedwait_time32, const sigset_t __user *, uthese,
+		siginfo_t __user *, uinfo,
+		const struct old_timespec32 __user *, uts,
+		size_t, sigsetsize)
+{
+	sigset_t these;
+	struct timespec64 ts;
+	kernel_siginfo_t info;
+	int ret;
+
+	if (sigsetsize != sizeof(sigset_t))
+		return -EINVAL;
+
+	if (copy_from_user(&these, uthese, sizeof(these)))
+		return -EFAULT;
+
+	if (uts) {
+		if (get_old_timespec32(&ts, uts))
+			return -EFAULT;
+	}
+
+	ret = do_sigtimedwait(&these, &info, uts ? &ts : NULL);
+
+	if (ret > 0 && uinfo) {
+		if (copy_siginfo_to_user(uinfo, &info))
+			ret = -EFAULT;
+	}
+
+	return ret;
+}
+#endif
+
 #ifdef CONFIG_COMPAT
 COMPAT_SYSCALL_DEFINE4(rt_sigtimedwait, compat_sigset_t __user *, uthese,
 		struct compat_siginfo __user *, uinfo,

commit 854a6ed56839a40f6b5d02a2962f48841482eec4
Author: Deepa Dinamani <deepa.kernel@gmail.com>
Date:   Wed Sep 19 21:41:05 2018 -0700

    signal: Add restore_user_sigmask()
    
    Refactor the logic to restore the sigmask before the syscall
    returns into an api.
    This is useful for versions of syscalls that pass in the
    sigmask and expect the current->sigmask to be changed during
    the execution and restored after the execution of the syscall.
    
    With the advent of new y2038 syscalls in the subsequent patches,
    we add two more new versions of the syscalls (for pselect, ppoll
    and io_pgetevents) in addition to the existing native and compat
    versions. Adding such an api reduces the logic that would need to
    be replicated otherwise.
    
    Signed-off-by: Deepa Dinamani <deepa.kernel@gmail.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/kernel/signal.c b/kernel/signal.c
index 811b5d440617..3c8ea7a328e0 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2780,6 +2780,39 @@ int set_compat_user_sigmask(const compat_sigset_t __user *usigmask,
 EXPORT_SYMBOL(set_compat_user_sigmask);
 #endif
 
+/*
+ * restore_user_sigmask:
+ * usigmask: sigmask passed in from userland.
+ * sigsaved: saved sigmask when the syscall started and changed the sigmask to
+ *           usigmask.
+ *
+ * This is useful for syscalls such as ppoll, pselect, io_pgetevents and
+ * epoll_pwait where a new sigmask is passed in from userland for the syscalls.
+ */
+void restore_user_sigmask(const void __user *usigmask, sigset_t *sigsaved)
+{
+
+	if (!usigmask)
+		return;
+	/*
+	 * When signals are pending, do not restore them here.
+	 * Restoring sigmask here can lead to delivering signals that the above
+	 * syscalls are intended to block because of the sigmask passed in.
+	 */
+	if (signal_pending(current)) {
+		current->saved_sigmask = *sigsaved;
+		set_restore_sigmask();
+		return;
+	}
+
+	/*
+	 * This is needed because the fast syscall return path does not restore
+	 * saved_sigmask when signals are not pending.
+	 */
+	set_current_blocked(sigsaved);
+}
+EXPORT_SYMBOL(restore_user_sigmask);
+
 /**
  *  sys_rt_sigprocmask - change the list of currently blocked signals
  *  @how: whether to add, remove, or set signals

commit ded653ccbec0335a78fa7a7aff3ec9870349fafb
Author: Deepa Dinamani <deepa.kernel@gmail.com>
Date:   Wed Sep 19 21:41:04 2018 -0700

    signal: Add set_user_sigmask()
    
    Refactor reading sigset from userspace and updating sigmask
    into an api.
    
    This is useful for versions of syscalls that pass in the
    sigmask and expect the current->sigmask to be changed during,
    and restored after, the execution of the syscall.
    
    With the advent of new y2038 syscalls in the subsequent patches,
    we add two more new versions of the syscalls (for pselect, ppoll,
    and io_pgetevents) in addition to the existing native and compat
    versions. Adding such an api reduces the logic that would need to
    be replicated otherwise.
    
    Note that the calls to sigprocmask() ignored the return value
    from the api as the function only returns an error on an invalid
    first argument that is hardcoded at these call sites.
    The updated logic uses set_current_blocked() instead.
    
    Signed-off-by: Deepa Dinamani <deepa.kernel@gmail.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9a32bc2088c9..811b5d440617 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2735,6 +2735,51 @@ int sigprocmask(int how, sigset_t *set, sigset_t *oldset)
 }
 EXPORT_SYMBOL(sigprocmask);
 
+/*
+ * The api helps set app-provided sigmasks.
+ *
+ * This is useful for syscalls such as ppoll, pselect, io_pgetevents and
+ * epoll_pwait where a new sigmask is passed from userland for the syscalls.
+ */
+int set_user_sigmask(const sigset_t __user *usigmask, sigset_t *set,
+		     sigset_t *oldset, size_t sigsetsize)
+{
+	if (!usigmask)
+		return 0;
+
+	if (sigsetsize != sizeof(sigset_t))
+		return -EINVAL;
+	if (copy_from_user(set, usigmask, sizeof(sigset_t)))
+		return -EFAULT;
+
+	*oldset = current->blocked;
+	set_current_blocked(set);
+
+	return 0;
+}
+EXPORT_SYMBOL(set_user_sigmask);
+
+#ifdef CONFIG_COMPAT
+int set_compat_user_sigmask(const compat_sigset_t __user *usigmask,
+			    sigset_t *set, sigset_t *oldset,
+			    size_t sigsetsize)
+{
+	if (!usigmask)
+		return 0;
+
+	if (sigsetsize != sizeof(compat_sigset_t))
+		return -EINVAL;
+	if (get_compat_sigset(set, usigmask))
+		return -EFAULT;
+
+	*oldset = current->blocked;
+	set_current_blocked(set);
+
+	return 0;
+}
+EXPORT_SYMBOL(set_compat_user_sigmask);
+#endif
+
 /**
  *  sys_rt_sigprocmask - change the list of currently blocked signals
  *  @how: whether to add, remove, or set signals

commit 2e58f57d859fbe0ce79e052d7a63bba32d5786e8
Author: Weikang Shi <swkhack@gmail.com>
Date:   Tue Oct 30 15:07:05 2018 -0700

    kernel/signal.c: fix a comment error
    
    Because get_signal_to_deliver() was renamed to get_signal() the
    comment should be fixed.
    
    Link: http://lkml.kernel.org/r/1539179128-45709-1-git-send-email-swkhack@gmail.com
    Signed-off-by: Weikang Shi <swkhack@gmail.com>
    Reported-by: Christian Brauner <christian@brauner.io>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Anna-Maria Gleixner <anna-maria@linutronix.de>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 17565240b1c6..9a32bc2088c9 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -892,7 +892,7 @@ static bool prepare_signal(int sig, struct task_struct *p, bool force)
 			/*
 			 * The first thread which returns from do_signal_stop()
 			 * will take ->siglock, notice SIGNAL_CLD_MASK, and
-			 * notify its parent. See get_signal_to_deliver().
+			 * notify its parent. See get_signal().
 			 */
 			signal_set_stop_flags(signal, why | SIGNAL_STOP_CONTINUED);
 			signal->group_stop_count = 0;

commit 4dcb9239dad6cee17c538482619a5b659774ee51
Merge: 3acbd2de6bc3 d59e0ba19481
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 25 11:14:36 2018 -0700

    Merge branch 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull timekeeping updates from Thomas Gleixner:
     "The timers and timekeeping departement provides:
    
       - Another large y2038 update with further preparations for providing
         the y2038 safe timespecs closer to the syscalls.
    
       - An overhaul of the SHCMT clocksource driver
    
       - SPDX license identifier updates
    
       - Small cleanups and fixes all over the place"
    
    * 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (31 commits)
      tick/sched : Remove redundant cpu_online() check
      clocksource/drivers/dw_apb: Add reset control
      clocksource: Remove obsolete CLOCKSOURCE_OF_DECLARE
      clocksource/drivers: Unify the names to timer-* format
      clocksource/drivers/sh_cmt: Add R-Car gen3 support
      dt-bindings: timer: renesas: cmt: document R-Car gen3 support
      clocksource/drivers/sh_cmt: Properly line-wrap sh_cmt_of_table[] initializer
      clocksource/drivers/sh_cmt: Fix clocksource width for 32-bit machines
      clocksource/drivers/sh_cmt: Fixup for 64-bit machines
      clocksource/drivers/sh_tmu: Convert to SPDX identifiers
      clocksource/drivers/sh_mtu2: Convert to SPDX identifiers
      clocksource/drivers/sh_cmt: Convert to SPDX identifiers
      clocksource/drivers/renesas-ostm: Convert to SPDX identifiers
      clocksource: Convert to using %pOFn instead of device_node.name
      tick/broadcast: Remove redundant check
      RISC-V: Request newstat syscalls
      y2038: signal: Change rt_sigtimedwait to use __kernel_timespec
      y2038: socket: Change recvmmsg to use __kernel_timespec
      y2038: sched: Change sched_rr_get_interval to use __kernel_timespec
      y2038: utimes: Rework #ifdef guards for compat syscalls
      ...

commit ba9f6f8954afa5224e3ed60332f7b92242b7ed0f
Merge: a978a5b8d83f a36700589b85
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Oct 24 11:22:39 2018 +0100

    Merge branch 'siginfo-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull siginfo updates from Eric Biederman:
     "I have been slowly sorting out siginfo and this is the culmination of
      that work.
    
      The primary result is in several ways the signal infrastructure has
      been made less error prone. The code has been updated so that manually
      specifying SEND_SIG_FORCED is never necessary. The conversion to the
      new siginfo sending functions is now complete, which makes it
      difficult to send a signal without filling in the proper siginfo
      fields.
    
      At the tail end of the patchset comes the optimization of decreasing
      the size of struct siginfo in the kernel from 128 bytes to about 48
      bytes on 64bit. The fundamental observation that enables this is by
      definition none of the known ways to use struct siginfo uses the extra
      bytes.
    
      This comes at the cost of a small user space observable difference.
      For the rare case of siginfo being injected into the kernel only what
      can be copied into kernel_siginfo is delivered to the destination, the
      rest of the bytes are set to 0. For cases where the signal and the
      si_code are known this is safe, because we know those bytes are not
      used. For cases where the signal and si_code combination is unknown
      the bits that won't fit into struct kernel_siginfo are tested to
      verify they are zero, and the send fails if they are not.
    
      I made an extensive search through userspace code and I could not find
      anything that would break because of the above change. If it turns out
      I did break something it will take just the revert of a single change
      to restore kernel_siginfo to the same size as userspace siginfo.
    
      Testing did reveal dependencies on preferring the signo passed to
      sigqueueinfo over si->signo, so bit the bullet and added the
      complexity necessary to handle that case.
    
      Testing also revealed bad things can happen if a negative signal
      number is passed into the system calls. Something no sane application
      will do but something a malicious program or a fuzzer might do. So I
      have fixed the code that performs the bounds checks to ensure negative
      signal numbers are handled"
    
    * 'siginfo-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (80 commits)
      signal: Guard against negative signal numbers in copy_siginfo_from_user32
      signal: Guard against negative signal numbers in copy_siginfo_from_user
      signal: In sigqueueinfo prefer sig not si_signo
      signal: Use a smaller struct siginfo in the kernel
      signal: Distinguish between kernel_siginfo and siginfo
      signal: Introduce copy_siginfo_from_user and use it's return value
      signal: Remove the need for __ARCH_SI_PREABLE_SIZE and SI_PAD_SIZE
      signal: Fail sigqueueinfo if si_signo != sig
      signal/sparc: Move EMT_TAGOVF into the generic siginfo.h
      signal/unicore32: Use force_sig_fault where appropriate
      signal/unicore32: Generate siginfo in ucs32_notify_die
      signal/unicore32: Use send_sig_fault where appropriate
      signal/arc: Use force_sig_fault where appropriate
      signal/arc: Push siginfo generation into unhandled_exception
      signal/ia64: Use force_sig_fault where appropriate
      signal/ia64: Use the force_sig(SIGSEGV,...) in ia64_rt_sigreturn
      signal/ia64: Use the generic force_sigsegv in setup_frame
      signal/arm/kvm: Use send_sig_mceerr
      signal/arm: Use send_sig_fault where appropriate
      signal/arm: Use force_sig_fault where appropriate
      ...

commit a36700589b85443e28170be59fa11c8a104130a5
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Oct 10 20:29:44 2018 -0500

    signal: Guard against negative signal numbers in copy_siginfo_from_user32
    
    While fixing an out of bounds array access in known_siginfo_layout
    reported by the kernel test robot it became apparent that the same bug
    exists in siginfo_layout and affects copy_siginfo_from_user32.
    
    The straight forward fix that makes guards against making this mistake
    in the future and should keep the code size small is to just take an
    unsigned signal number instead of a signed signal number, as I did to
    fix known_siginfo_layout.
    
    Cc: stable@vger.kernel.org
    Fixes: cc731525f26a ("signal: Remove kernel interal si_code magic")
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5f5bf374512b..4fd431ce4f91 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2879,7 +2879,7 @@ static bool known_siginfo_layout(unsigned sig, int si_code)
 	return false;
 }
 
-enum siginfo_layout siginfo_layout(int sig, int si_code)
+enum siginfo_layout siginfo_layout(unsigned sig, int si_code)
 {
 	enum siginfo_layout layout = SIL_KILL;
 	if ((si_code > SI_USER) && (si_code < SI_KERNEL)) {

commit b2a2ab527d6de02fbf2331bae4a299d58ab52266
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Oct 10 20:11:25 2018 -0500

    signal: Guard against negative signal numbers in copy_siginfo_from_user
    
    The bounds checks in known_siginfo_layout only guards against positive
    numbers that are too large, large negative can slip through and
    can cause out of bounds accesses.
    
    Ordinarily this is not a concern because early in signal processing
    the signal number is filtered with valid_signal which ensures it
    is a small positive signal number, but copy_siginfo_from_user
    is called before this check is performed.
    
    [   73.031126] BUG: unable to handle kernel paging request at ffffffff6281bcb6
    [   73.032038] PGD 3014067 P4D 3014067 PUD 0
    [   73.032565] Oops: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC PTI
    [   73.033287] CPU: 0 PID: 732 Comm: trinity-c3 Tainted: G        W       T 4.19.0-rc1-00077-g4ce5f9c #1
    [   73.034423] RIP: 0010:copy_siginfo_from_user+0x4d/0xd0
    [   73.034908] Code: 00 8b 53 08 81 fa 80 00 00 00 0f 84 90 00 00 00 85 d2 7e 2d 48 63 0b 83 f9 1f 7f 1c 8d 71 ff bf d8 04 01 50 48 0f a3 f7 73 0e <0f> b6 8c 09 20 bb 81 82 39 ca 7f 15 eb 68 31 c0 83 fa 06 7f 0c eb
    [   73.036665] RSP: 0018:ffff88001b8f7e20 EFLAGS: 00010297
    [   73.037160] RAX: 0000000000000000 RBX: ffff88001b8f7e90 RCX: fffffffff00000cb
    [   73.037865] RDX: 0000000000000001 RSI: 00000000f00000ca RDI: 00000000500104d8
    [   73.038546] RBP: ffff88001b8f7e80 R08: 0000000000000000 R09: 0000000000000000
    [   73.039201] R10: 0000000000000001 R11: 0000000000000000 R12: 0000000000000008
    [   73.039874] R13: 00000000000002dc R14: 0000000000000000 R15: 0000000000000000
    [   73.040613] FS:  000000000104a880(0000) GS:ffff88001f000000(0000) knlGS:0000000000000000
    [   73.041649] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [   73.042405] CR2: ffffffff6281bcb6 CR3: 000000001cb52003 CR4: 00000000001606b0
    [   73.043351] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [   73.044286] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000600
    [   73.045221] Call Trace:
    [   73.045556]  __x64_sys_rt_tgsigqueueinfo+0x34/0xa0
    [   73.046199]  do_syscall_64+0x1a4/0x390
    [   73.046708]  ? vtime_user_enter+0x61/0x80
    [   73.047242]  ? __context_tracking_enter+0x4e/0x60
    [   73.047714]  ? __context_tracking_enter+0x4e/0x60
    [   73.048278]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Therefore fix known_siginfo_layout to take an unsigned signal number
    instead of a signed signal number.  All valid signal numbers are small
    positive numbers so they will not be affected, but invalid negative
    signal numbers will now become large positive signal numbers and will
    not be used as indices into the sig_sicodes array.
    
    Making the signal number unsigned makes it difficult for similar mistakes to
    happen in the future.
    
    Fixes: 4ce5f9c9e754 ("signal: Use a smaller struct siginfo in the kernel")
    Inspired-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Reported-by: kernel test robot <rong.a.chen@intel.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2bffc5a50183..5f5bf374512b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2860,7 +2860,7 @@ static const struct {
 	[SIGSYS]  = { NSIGSYS,  SIL_SYS },
 };
 
-static bool known_siginfo_layout(int sig, int si_code)
+static bool known_siginfo_layout(unsigned sig, int si_code)
 {
 	if (si_code == SI_KERNEL)
 		return true;

commit 601d5abfeaf244b86bb68c1e05c6e0d57be2f6b0
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Oct 5 09:02:48 2018 +0200

    signal: In sigqueueinfo prefer sig not si_signo
    
    Andrei Vagin <avagin@gmail.com> reported:
    
    > Accoding to the man page, the user should not set si_signo, it has to be set
    > by kernel.
    >
    > $ man 2 rt_sigqueueinfo
    >
    >     The uinfo argument specifies the data to accompany  the  signal.   This
    >        argument  is  a  pointer to a structure of type siginfo_t, described in
    >        sigaction(2) (and defined  by  including  <sigaction.h>).   The  caller
    >        should set the following fields in this structure:
    >
    >        si_code
    >               This  must  be  one of the SI_* codes in the Linux kernel source
    >               file include/asm-generic/siginfo.h, with  the  restriction  that
    >               the  code  must  be  negative (i.e., cannot be SI_USER, which is
    >               used by the kernel to indicate a signal  sent  by  kill(2))  and
    >               cannot  (since  Linux  2.6.39) be SI_TKILL (which is used by the
    >               kernel to indicate a signal sent using tgkill(2)).
    >
    >        si_pid This should be set to a process ID, typically the process ID  of
    >               the sender.
    >
    >        si_uid This  should  be set to a user ID, typically the real user ID of
    >               the sender.
    >
    >        si_value
    >               This field contains the user data to accompany the signal.   For
    >               more information, see the description of the last (union sigval)
    >               argument of sigqueue(3).
    >
    >        Internally, the kernel sets the si_signo field to the  value  specified
    >        in  sig,  so that the receiver of the signal can also obtain the signal
    >        number via that field.
    >
    > On Tue, Sep 25, 2018 at 07:19:02PM +0200, Eric W. Biederman wrote:
    >>
    >> If there is some application that calls sigqueueinfo directly that has
    >> a problem with this added sanity check we can revisit this when we see
    >> what kind of crazy that application is doing.
    >
    >
    > I already know two "applications" ;)
    >
    > https://github.com/torvalds/linux/blob/master/tools/testing/selftests/ptrace/peeksiginfo.c
    > https://github.com/checkpoint-restore/criu/blob/master/test/zdtm/static/sigpending.c
    >
    > Disclaimer: I'm the author of both of them.
    
    Looking at the kernel code the historical behavior has alwasy been to prefer
    the signal number passed in by the kernel.
    
    So sigh.  Implmenet __copy_siginfo_from_user and __copy_siginfo_from_user32 to
    take that signal number and prefer it.  The user of ptrace will still
    use copy_siginfo_from_user and copy_siginfo_from_user32 as they do not and
    never have had a signal number there.
    
    Luckily this change has never made it farther than linux-next.
    
    Fixes: e75dc036c445 ("signal: Fail sigqueueinfo if si_signo != sig")
    Reported-by: Andrei Vagin <avagin@gmail.com>
    Tested-by: Andrei Vagin <avagin@gmail.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1c2dd117fee0..2bffc5a50183 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2925,11 +2925,10 @@ int copy_siginfo_to_user(siginfo_t __user *to, const kernel_siginfo_t *from)
 	return 0;
 }
 
-int copy_siginfo_from_user(kernel_siginfo_t *to, const siginfo_t __user *from)
+static int post_copy_siginfo_from_user(kernel_siginfo_t *info,
+				       const siginfo_t __user *from)
 {
-	if (copy_from_user(to, from, sizeof(struct kernel_siginfo)))
-		return -EFAULT;
-	if (unlikely(!known_siginfo_layout(to->si_signo, to->si_code))) {
+	if (unlikely(!known_siginfo_layout(info->si_signo, info->si_code))) {
 		char __user *expansion = si_expansion(from);
 		char buf[SI_EXPANSION_SIZE];
 		int i;
@@ -2949,6 +2948,22 @@ int copy_siginfo_from_user(kernel_siginfo_t *to, const siginfo_t __user *from)
 	return 0;
 }
 
+static int __copy_siginfo_from_user(int signo, kernel_siginfo_t *to,
+				    const siginfo_t __user *from)
+{
+	if (copy_from_user(to, from, sizeof(struct kernel_siginfo)))
+		return -EFAULT;
+	to->si_signo = signo;
+	return post_copy_siginfo_from_user(to, from);
+}
+
+int copy_siginfo_from_user(kernel_siginfo_t *to, const siginfo_t __user *from)
+{
+	if (copy_from_user(to, from, sizeof(struct kernel_siginfo)))
+		return -EFAULT;
+	return post_copy_siginfo_from_user(to, from);
+}
+
 #ifdef CONFIG_COMPAT
 int copy_siginfo_to_user32(struct compat_siginfo __user *to,
 			   const struct kernel_siginfo *from)
@@ -3041,88 +3056,106 @@ int __copy_siginfo_to_user32(struct compat_siginfo __user *to,
 	return 0;
 }
 
-int copy_siginfo_from_user32(struct kernel_siginfo *to,
-			     const struct compat_siginfo __user *ufrom)
+static int post_copy_siginfo_from_user32(kernel_siginfo_t *to,
+					 const struct compat_siginfo *from)
 {
-	struct compat_siginfo from;
-
-	if (copy_from_user(&from, ufrom, sizeof(struct compat_siginfo)))
-		return -EFAULT;
-
 	clear_siginfo(to);
-	to->si_signo = from.si_signo;
-	to->si_errno = from.si_errno;
-	to->si_code  = from.si_code;
-	switch(siginfo_layout(from.si_signo, from.si_code)) {
+	to->si_signo = from->si_signo;
+	to->si_errno = from->si_errno;
+	to->si_code  = from->si_code;
+	switch(siginfo_layout(from->si_signo, from->si_code)) {
 	case SIL_KILL:
-		to->si_pid = from.si_pid;
-		to->si_uid = from.si_uid;
+		to->si_pid = from->si_pid;
+		to->si_uid = from->si_uid;
 		break;
 	case SIL_TIMER:
-		to->si_tid     = from.si_tid;
-		to->si_overrun = from.si_overrun;
-		to->si_int     = from.si_int;
+		to->si_tid     = from->si_tid;
+		to->si_overrun = from->si_overrun;
+		to->si_int     = from->si_int;
 		break;
 	case SIL_POLL:
-		to->si_band = from.si_band;
-		to->si_fd   = from.si_fd;
+		to->si_band = from->si_band;
+		to->si_fd   = from->si_fd;
 		break;
 	case SIL_FAULT:
-		to->si_addr = compat_ptr(from.si_addr);
+		to->si_addr = compat_ptr(from->si_addr);
 #ifdef __ARCH_SI_TRAPNO
-		to->si_trapno = from.si_trapno;
+		to->si_trapno = from->si_trapno;
 #endif
 		break;
 	case SIL_FAULT_MCEERR:
-		to->si_addr = compat_ptr(from.si_addr);
+		to->si_addr = compat_ptr(from->si_addr);
 #ifdef __ARCH_SI_TRAPNO
-		to->si_trapno = from.si_trapno;
+		to->si_trapno = from->si_trapno;
 #endif
-		to->si_addr_lsb = from.si_addr_lsb;
+		to->si_addr_lsb = from->si_addr_lsb;
 		break;
 	case SIL_FAULT_BNDERR:
-		to->si_addr = compat_ptr(from.si_addr);
+		to->si_addr = compat_ptr(from->si_addr);
 #ifdef __ARCH_SI_TRAPNO
-		to->si_trapno = from.si_trapno;
+		to->si_trapno = from->si_trapno;
 #endif
-		to->si_lower = compat_ptr(from.si_lower);
-		to->si_upper = compat_ptr(from.si_upper);
+		to->si_lower = compat_ptr(from->si_lower);
+		to->si_upper = compat_ptr(from->si_upper);
 		break;
 	case SIL_FAULT_PKUERR:
-		to->si_addr = compat_ptr(from.si_addr);
+		to->si_addr = compat_ptr(from->si_addr);
 #ifdef __ARCH_SI_TRAPNO
-		to->si_trapno = from.si_trapno;
+		to->si_trapno = from->si_trapno;
 #endif
-		to->si_pkey = from.si_pkey;
+		to->si_pkey = from->si_pkey;
 		break;
 	case SIL_CHLD:
-		to->si_pid    = from.si_pid;
-		to->si_uid    = from.si_uid;
-		to->si_status = from.si_status;
+		to->si_pid    = from->si_pid;
+		to->si_uid    = from->si_uid;
+		to->si_status = from->si_status;
 #ifdef CONFIG_X86_X32_ABI
 		if (in_x32_syscall()) {
-			to->si_utime = from._sifields._sigchld_x32._utime;
-			to->si_stime = from._sifields._sigchld_x32._stime;
+			to->si_utime = from->_sifields._sigchld_x32._utime;
+			to->si_stime = from->_sifields._sigchld_x32._stime;
 		} else
 #endif
 		{
-			to->si_utime = from.si_utime;
-			to->si_stime = from.si_stime;
+			to->si_utime = from->si_utime;
+			to->si_stime = from->si_stime;
 		}
 		break;
 	case SIL_RT:
-		to->si_pid = from.si_pid;
-		to->si_uid = from.si_uid;
-		to->si_int = from.si_int;
+		to->si_pid = from->si_pid;
+		to->si_uid = from->si_uid;
+		to->si_int = from->si_int;
 		break;
 	case SIL_SYS:
-		to->si_call_addr = compat_ptr(from.si_call_addr);
-		to->si_syscall   = from.si_syscall;
-		to->si_arch      = from.si_arch;
+		to->si_call_addr = compat_ptr(from->si_call_addr);
+		to->si_syscall   = from->si_syscall;
+		to->si_arch      = from->si_arch;
 		break;
 	}
 	return 0;
 }
+
+static int __copy_siginfo_from_user32(int signo, struct kernel_siginfo *to,
+				      const struct compat_siginfo __user *ufrom)
+{
+	struct compat_siginfo from;
+
+	if (copy_from_user(&from, ufrom, sizeof(struct compat_siginfo)))
+		return -EFAULT;
+
+	from.si_signo = signo;
+	return post_copy_siginfo_from_user32(to, &from);
+}
+
+int copy_siginfo_from_user32(struct kernel_siginfo *to,
+			     const struct compat_siginfo __user *ufrom)
+{
+	struct compat_siginfo from;
+
+	if (copy_from_user(&from, ufrom, sizeof(struct compat_siginfo)))
+		return -EFAULT;
+
+	return post_copy_siginfo_from_user32(to, &from);
+}
 #endif /* CONFIG_COMPAT */
 
 /**
@@ -3359,9 +3392,6 @@ static int do_rt_sigqueueinfo(pid_t pid, int sig, kernel_siginfo_t *info)
 	    (task_pid_vnr(current) != pid))
 		return -EPERM;
 
-	if (info->si_signo != sig)
-		return -EINVAL;
-
 	/* POSIX.1b doesn't mention process groups.  */
 	return kill_proc_info(sig, info, pid);
 }
@@ -3376,7 +3406,7 @@ SYSCALL_DEFINE3(rt_sigqueueinfo, pid_t, pid, int, sig,
 		siginfo_t __user *, uinfo)
 {
 	kernel_siginfo_t info;
-	int ret = copy_siginfo_from_user(&info, uinfo);
+	int ret = __copy_siginfo_from_user(sig, &info, uinfo);
 	if (unlikely(ret))
 		return ret;
 	return do_rt_sigqueueinfo(pid, sig, &info);
@@ -3389,7 +3419,7 @@ COMPAT_SYSCALL_DEFINE3(rt_sigqueueinfo,
 			struct compat_siginfo __user *, uinfo)
 {
 	kernel_siginfo_t info;
-	int ret = copy_siginfo_from_user32(&info, uinfo);
+	int ret = __copy_siginfo_from_user32(sig, &info, uinfo);
 	if (unlikely(ret))
 		return ret;
 	return do_rt_sigqueueinfo(pid, sig, &info);
@@ -3409,9 +3439,6 @@ static int do_rt_tgsigqueueinfo(pid_t tgid, pid_t pid, int sig, kernel_siginfo_t
 	    (task_pid_vnr(current) != pid))
 		return -EPERM;
 
-	if (info->si_signo != sig)
-		return -EINVAL;
-
 	return do_send_specific(tgid, pid, sig, info);
 }
 
@@ -3419,7 +3446,7 @@ SYSCALL_DEFINE4(rt_tgsigqueueinfo, pid_t, tgid, pid_t, pid, int, sig,
 		siginfo_t __user *, uinfo)
 {
 	kernel_siginfo_t info;
-	int ret = copy_siginfo_from_user(&info, uinfo);
+	int ret = __copy_siginfo_from_user(sig, &info, uinfo);
 	if (unlikely(ret))
 		return ret;
 	return do_rt_tgsigqueueinfo(tgid, pid, sig, &info);
@@ -3433,7 +3460,7 @@ COMPAT_SYSCALL_DEFINE4(rt_tgsigqueueinfo,
 			struct compat_siginfo __user *, uinfo)
 {
 	kernel_siginfo_t info;
-	int ret = copy_siginfo_from_user32(&info, uinfo);
+	int ret = __copy_siginfo_from_user32(sig, &info, uinfo);
 	if (unlikely(ret))
 		return ret;
 	return do_rt_tgsigqueueinfo(tgid, pid, sig, &info);

commit 4ce5f9c9e7546915c559ffae594e6d73f918db00
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Sep 25 12:59:31 2018 +0200

    signal: Use a smaller struct siginfo in the kernel
    
    We reserve 128 bytes for struct siginfo but only use about 48 bytes on
    64bit and 32 bytes on 32bit.  Someday we might use more but it is unlikely
    to be anytime soon.
    
    Userspace seems content with just enough bytes of siginfo to implement
    sigqueue.  Or in the case of checkpoint/restart reinjecting signals
    the kernel has sent.
    
    Reducing the stack footprint and the work to copy siginfo around from
    2 cachelines to 1 cachelines seems worth doing even if I don't have
    benchmarks to show a performance difference.
    
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 161cad4e448c..1c2dd117fee0 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2844,27 +2844,48 @@ COMPAT_SYSCALL_DEFINE2(rt_sigpending, compat_sigset_t __user *, uset,
 }
 #endif
 
+static const struct {
+	unsigned char limit, layout;
+} sig_sicodes[] = {
+	[SIGILL]  = { NSIGILL,  SIL_FAULT },
+	[SIGFPE]  = { NSIGFPE,  SIL_FAULT },
+	[SIGSEGV] = { NSIGSEGV, SIL_FAULT },
+	[SIGBUS]  = { NSIGBUS,  SIL_FAULT },
+	[SIGTRAP] = { NSIGTRAP, SIL_FAULT },
+#if defined(SIGEMT)
+	[SIGEMT]  = { NSIGEMT,  SIL_FAULT },
+#endif
+	[SIGCHLD] = { NSIGCHLD, SIL_CHLD },
+	[SIGPOLL] = { NSIGPOLL, SIL_POLL },
+	[SIGSYS]  = { NSIGSYS,  SIL_SYS },
+};
+
+static bool known_siginfo_layout(int sig, int si_code)
+{
+	if (si_code == SI_KERNEL)
+		return true;
+	else if ((si_code > SI_USER)) {
+		if (sig_specific_sicodes(sig)) {
+			if (si_code <= sig_sicodes[sig].limit)
+				return true;
+		}
+		else if (si_code <= NSIGPOLL)
+			return true;
+	}
+	else if (si_code >= SI_DETHREAD)
+		return true;
+	else if (si_code == SI_ASYNCNL)
+		return true;
+	return false;
+}
+
 enum siginfo_layout siginfo_layout(int sig, int si_code)
 {
 	enum siginfo_layout layout = SIL_KILL;
 	if ((si_code > SI_USER) && (si_code < SI_KERNEL)) {
-		static const struct {
-			unsigned char limit, layout;
-		} filter[] = {
-			[SIGILL]  = { NSIGILL,  SIL_FAULT },
-			[SIGFPE]  = { NSIGFPE,  SIL_FAULT },
-			[SIGSEGV] = { NSIGSEGV, SIL_FAULT },
-			[SIGBUS]  = { NSIGBUS,  SIL_FAULT },
-			[SIGTRAP] = { NSIGTRAP, SIL_FAULT },
-#if defined(SIGEMT)
-			[SIGEMT]  = { NSIGEMT,  SIL_FAULT },
-#endif
-			[SIGCHLD] = { NSIGCHLD, SIL_CHLD },
-			[SIGPOLL] = { NSIGPOLL, SIL_POLL },
-			[SIGSYS]  = { NSIGSYS,  SIL_SYS },
-		};
-		if ((sig < ARRAY_SIZE(filter)) && (si_code <= filter[sig].limit)) {
-			layout = filter[sig].layout;
+		if ((sig < ARRAY_SIZE(sig_sicodes)) &&
+		    (si_code <= sig_sicodes[sig].limit)) {
+			layout = sig_sicodes[sig].layout;
 			/* Handle the exceptions */
 			if ((sig == SIGBUS) &&
 			    (si_code >= BUS_MCEERR_AR) && (si_code <= BUS_MCEERR_AO))
@@ -2889,17 +2910,42 @@ enum siginfo_layout siginfo_layout(int sig, int si_code)
 	return layout;
 }
 
+static inline char __user *si_expansion(const siginfo_t __user *info)
+{
+	return ((char __user *)info) + sizeof(struct kernel_siginfo);
+}
+
 int copy_siginfo_to_user(siginfo_t __user *to, const kernel_siginfo_t *from)
 {
+	char __user *expansion = si_expansion(to);
 	if (copy_to_user(to, from , sizeof(struct kernel_siginfo)))
 		return -EFAULT;
+	if (clear_user(expansion, SI_EXPANSION_SIZE))
+		return -EFAULT;
 	return 0;
 }
 
 int copy_siginfo_from_user(kernel_siginfo_t *to, const siginfo_t __user *from)
 {
-	if (copy_from_user(to, from, sizeof(struct siginfo)))
+	if (copy_from_user(to, from, sizeof(struct kernel_siginfo)))
 		return -EFAULT;
+	if (unlikely(!known_siginfo_layout(to->si_signo, to->si_code))) {
+		char __user *expansion = si_expansion(from);
+		char buf[SI_EXPANSION_SIZE];
+		int i;
+		/*
+		 * An unknown si_code might need more than
+		 * sizeof(struct kernel_siginfo) bytes.  Verify all of the
+		 * extra bytes are 0.  This guarantees copy_siginfo_to_user
+		 * will return this data to userspace exactly.
+		 */
+		if (copy_from_user(&buf, expansion, SI_EXPANSION_SIZE))
+			return -EFAULT;
+		for (i = 0; i < SI_EXPANSION_SIZE; i++) {
+			if (buf[i] != 0)
+				return -E2BIG;
+		}
+	}
 	return 0;
 }
 

commit ae7795bc6187a15ec51cf258abae656a625f9980
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Sep 25 11:27:20 2018 +0200

    signal: Distinguish between kernel_siginfo and siginfo
    
    Linus recently observed that if we did not worry about the padding
    member in struct siginfo it is only about 48 bytes, and 48 bytes is
    much nicer than 128 bytes for allocating on the stack and copying
    around in the kernel.
    
    The obvious thing of only adding the padding when userspace is
    including siginfo.h won't work as there are sigframe definitions in
    the kernel that embed struct siginfo.
    
    So split siginfo in two; kernel_siginfo and siginfo.  Keeping the
    traditional name for the userspace definition.  While the version that
    is used internally to the kernel and ultimately will not be padded to
    128 bytes is called kernel_siginfo.
    
    The definition of struct kernel_siginfo I have put in include/signal_types.h
    
    A set of buildtime checks has been added to verify the two structures have
    the same field offsets.
    
    To make it easy to verify the change kernel_siginfo retains the same
    size as siginfo.  The reduction in size comes in a following change.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index c0e289e62d77..161cad4e448c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -549,7 +549,7 @@ bool unhandled_signal(struct task_struct *tsk, int sig)
 	return !tsk->ptrace;
 }
 
-static void collect_signal(int sig, struct sigpending *list, siginfo_t *info,
+static void collect_signal(int sig, struct sigpending *list, kernel_siginfo_t *info,
 			   bool *resched_timer)
 {
 	struct sigqueue *q, *first = NULL;
@@ -595,7 +595,7 @@ static void collect_signal(int sig, struct sigpending *list, siginfo_t *info,
 }
 
 static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,
-			siginfo_t *info, bool *resched_timer)
+			kernel_siginfo_t *info, bool *resched_timer)
 {
 	int sig = next_signal(pending, mask);
 
@@ -610,7 +610,7 @@ static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,
  *
  * All callers have to hold the siglock.
  */
-int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
+int dequeue_signal(struct task_struct *tsk, sigset_t *mask, kernel_siginfo_t *info)
 {
 	bool resched_timer = false;
 	int signr;
@@ -737,12 +737,12 @@ static void flush_sigqueue_mask(sigset_t *mask, struct sigpending *s)
 	}
 }
 
-static inline int is_si_special(const struct siginfo *info)
+static inline int is_si_special(const struct kernel_siginfo *info)
 {
 	return info <= SEND_SIG_PRIV;
 }
 
-static inline bool si_fromuser(const struct siginfo *info)
+static inline bool si_fromuser(const struct kernel_siginfo *info)
 {
 	return info == SEND_SIG_NOINFO ||
 		(!is_si_special(info) && SI_FROMUSER(info));
@@ -767,7 +767,7 @@ static bool kill_ok_by_cred(struct task_struct *t)
  * Bad permissions for sending the signal
  * - the caller must hold the RCU read lock
  */
-static int check_kill_permission(int sig, struct siginfo *info,
+static int check_kill_permission(int sig, struct kernel_siginfo *info,
 				 struct task_struct *t)
 {
 	struct pid *sid;
@@ -1010,7 +1010,7 @@ static inline bool legacy_queue(struct sigpending *signals, int sig)
 }
 
 #ifdef CONFIG_USER_NS
-static inline void userns_fixup_signal_uid(struct siginfo *info, struct task_struct *t)
+static inline void userns_fixup_signal_uid(struct kernel_siginfo *info, struct task_struct *t)
 {
 	if (current_user_ns() == task_cred_xxx(t, user_ns))
 		return;
@@ -1024,13 +1024,13 @@ static inline void userns_fixup_signal_uid(struct siginfo *info, struct task_str
 	rcu_read_unlock();
 }
 #else
-static inline void userns_fixup_signal_uid(struct siginfo *info, struct task_struct *t)
+static inline void userns_fixup_signal_uid(struct kernel_siginfo *info, struct task_struct *t)
 {
 	return;
 }
 #endif
 
-static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
+static int __send_signal(int sig, struct kernel_siginfo *info, struct task_struct *t,
 			enum pid_type type, int from_ancestor_ns)
 {
 	struct sigpending *pending;
@@ -1150,7 +1150,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	return ret;
 }
 
-static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
+static int send_signal(int sig, struct kernel_siginfo *info, struct task_struct *t,
 			enum pid_type type)
 {
 	int from_ancestor_ns = 0;
@@ -1197,12 +1197,12 @@ static int __init setup_print_fatal_signals(char *str)
 __setup("print-fatal-signals=", setup_print_fatal_signals);
 
 int
-__group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
+__group_send_sig_info(int sig, struct kernel_siginfo *info, struct task_struct *p)
 {
 	return send_signal(sig, info, p, PIDTYPE_TGID);
 }
 
-int do_send_sig_info(int sig, struct siginfo *info, struct task_struct *p,
+int do_send_sig_info(int sig, struct kernel_siginfo *info, struct task_struct *p,
 			enum pid_type type)
 {
 	unsigned long flags;
@@ -1228,7 +1228,7 @@ int do_send_sig_info(int sig, struct siginfo *info, struct task_struct *p,
  * that is why we also clear SIGNAL_UNKILLABLE.
  */
 int
-force_sig_info(int sig, struct siginfo *info, struct task_struct *t)
+force_sig_info(int sig, struct kernel_siginfo *info, struct task_struct *t)
 {
 	unsigned long int flags;
 	int ret, blocked, ignored;
@@ -1316,8 +1316,8 @@ struct sighand_struct *__lock_task_sighand(struct task_struct *tsk,
 /*
  * send signal info to all the members of a group
  */
-int group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p,
-			enum pid_type type)
+int group_send_sig_info(int sig, struct kernel_siginfo *info,
+			struct task_struct *p, enum pid_type type)
 {
 	int ret;
 
@@ -1336,7 +1336,7 @@ int group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p,
  * control characters do (^C, ^Z etc)
  * - the caller must hold at least a readlock on tasklist_lock
  */
-int __kill_pgrp_info(int sig, struct siginfo *info, struct pid *pgrp)
+int __kill_pgrp_info(int sig, struct kernel_siginfo *info, struct pid *pgrp)
 {
 	struct task_struct *p = NULL;
 	int retval, success;
@@ -1351,7 +1351,7 @@ int __kill_pgrp_info(int sig, struct siginfo *info, struct pid *pgrp)
 	return success ? 0 : retval;
 }
 
-int kill_pid_info(int sig, struct siginfo *info, struct pid *pid)
+int kill_pid_info(int sig, struct kernel_siginfo *info, struct pid *pid)
 {
 	int error = -ESRCH;
 	struct task_struct *p;
@@ -1373,7 +1373,7 @@ int kill_pid_info(int sig, struct siginfo *info, struct pid *pid)
 	}
 }
 
-static int kill_proc_info(int sig, struct siginfo *info, pid_t pid)
+static int kill_proc_info(int sig, struct kernel_siginfo *info, pid_t pid)
 {
 	int error;
 	rcu_read_lock();
@@ -1394,7 +1394,7 @@ static inline bool kill_as_cred_perm(const struct cred *cred,
 }
 
 /* like kill_pid_info(), but doesn't use uid/euid of "current" */
-int kill_pid_info_as_cred(int sig, struct siginfo *info, struct pid *pid,
+int kill_pid_info_as_cred(int sig, struct kernel_siginfo *info, struct pid *pid,
 			 const struct cred *cred)
 {
 	int ret = -EINVAL;
@@ -1438,7 +1438,7 @@ EXPORT_SYMBOL_GPL(kill_pid_info_as_cred);
  * is probably wrong.  Should make it like BSD or SYSV.
  */
 
-static int kill_something_info(int sig, struct siginfo *info, pid_t pid)
+static int kill_something_info(int sig, struct kernel_siginfo *info, pid_t pid)
 {
 	int ret;
 
@@ -1482,7 +1482,7 @@ static int kill_something_info(int sig, struct siginfo *info, pid_t pid)
  * These are for backward compatibility with the rest of the kernel source.
  */
 
-int send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
+int send_sig_info(int sig, struct kernel_siginfo *info, struct task_struct *p)
 {
 	/*
 	 * Make sure legacy kernel users don't send in bad values
@@ -1533,7 +1533,7 @@ int force_sig_fault(int sig, int code, void __user *addr
 	___ARCH_SI_IA64(int imm, unsigned int flags, unsigned long isr)
 	, struct task_struct *t)
 {
-	struct siginfo info;
+	struct kernel_siginfo info;
 
 	clear_siginfo(&info);
 	info.si_signo = sig;
@@ -1556,7 +1556,7 @@ int send_sig_fault(int sig, int code, void __user *addr
 	___ARCH_SI_IA64(int imm, unsigned int flags, unsigned long isr)
 	, struct task_struct *t)
 {
-	struct siginfo info;
+	struct kernel_siginfo info;
 
 	clear_siginfo(&info);
 	info.si_signo = sig;
@@ -1576,7 +1576,7 @@ int send_sig_fault(int sig, int code, void __user *addr
 
 int force_sig_mceerr(int code, void __user *addr, short lsb, struct task_struct *t)
 {
-	struct siginfo info;
+	struct kernel_siginfo info;
 
 	WARN_ON((code != BUS_MCEERR_AO) && (code != BUS_MCEERR_AR));
 	clear_siginfo(&info);
@@ -1590,7 +1590,7 @@ int force_sig_mceerr(int code, void __user *addr, short lsb, struct task_struct
 
 int send_sig_mceerr(int code, void __user *addr, short lsb, struct task_struct *t)
 {
-	struct siginfo info;
+	struct kernel_siginfo info;
 
 	WARN_ON((code != BUS_MCEERR_AO) && (code != BUS_MCEERR_AR));
 	clear_siginfo(&info);
@@ -1605,7 +1605,7 @@ EXPORT_SYMBOL(send_sig_mceerr);
 
 int force_sig_bnderr(void __user *addr, void __user *lower, void __user *upper)
 {
-	struct siginfo info;
+	struct kernel_siginfo info;
 
 	clear_siginfo(&info);
 	info.si_signo = SIGSEGV;
@@ -1620,7 +1620,7 @@ int force_sig_bnderr(void __user *addr, void __user *lower, void __user *upper)
 #ifdef SEGV_PKUERR
 int force_sig_pkuerr(void __user *addr, u32 pkey)
 {
-	struct siginfo info;
+	struct kernel_siginfo info;
 
 	clear_siginfo(&info);
 	info.si_signo = SIGSEGV;
@@ -1637,7 +1637,7 @@ int force_sig_pkuerr(void __user *addr, u32 pkey)
  */
 int force_sig_ptrace_errno_trap(int errno, void __user *addr)
 {
-	struct siginfo info;
+	struct kernel_siginfo info;
 
 	clear_siginfo(&info);
 	info.si_signo = SIGTRAP;
@@ -1766,7 +1766,7 @@ int send_sigqueue(struct sigqueue *q, struct pid *pid, enum pid_type type)
  */
 bool do_notify_parent(struct task_struct *tsk, int sig)
 {
-	struct siginfo info;
+	struct kernel_siginfo info;
 	unsigned long flags;
 	struct sighand_struct *psig;
 	bool autoreap = false;
@@ -1871,7 +1871,7 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 static void do_notify_parent_cldstop(struct task_struct *tsk,
 				     bool for_ptracer, int why)
 {
-	struct siginfo info;
+	struct kernel_siginfo info;
 	unsigned long flags;
 	struct task_struct *parent;
 	struct sighand_struct *sighand;
@@ -1971,7 +1971,7 @@ static bool sigkill_pending(struct task_struct *tsk)
  * If we actually decide not to stop at all because the tracer
  * is gone, we keep current->exit_code unless clear_code.
  */
-static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
+static void ptrace_stop(int exit_code, int why, int clear_code, kernel_siginfo_t *info)
 	__releases(&current->sighand->siglock)
 	__acquires(&current->sighand->siglock)
 {
@@ -2108,7 +2108,7 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 
 static void ptrace_do_notify(int signr, int exit_code, int why)
 {
-	siginfo_t info;
+	kernel_siginfo_t info;
 
 	clear_siginfo(&info);
 	info.si_signo = signr;
@@ -2289,7 +2289,7 @@ static void do_jobctl_trap(void)
 	}
 }
 
-static int ptrace_signal(int signr, siginfo_t *info)
+static int ptrace_signal(int signr, kernel_siginfo_t *info)
 {
 	/*
 	 * We do not check sig_kernel_stop(signr) but set this marker
@@ -2889,14 +2889,14 @@ enum siginfo_layout siginfo_layout(int sig, int si_code)
 	return layout;
 }
 
-int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
+int copy_siginfo_to_user(siginfo_t __user *to, const kernel_siginfo_t *from)
 {
-	if (copy_to_user(to, from , sizeof(struct siginfo)))
+	if (copy_to_user(to, from , sizeof(struct kernel_siginfo)))
 		return -EFAULT;
 	return 0;
 }
 
-int copy_siginfo_from_user(siginfo_t *to, const siginfo_t __user *from)
+int copy_siginfo_from_user(kernel_siginfo_t *to, const siginfo_t __user *from)
 {
 	if (copy_from_user(to, from, sizeof(struct siginfo)))
 		return -EFAULT;
@@ -2905,13 +2905,13 @@ int copy_siginfo_from_user(siginfo_t *to, const siginfo_t __user *from)
 
 #ifdef CONFIG_COMPAT
 int copy_siginfo_to_user32(struct compat_siginfo __user *to,
-			   const struct siginfo *from)
+			   const struct kernel_siginfo *from)
 #if defined(CONFIG_X86_X32_ABI) || defined(CONFIG_IA32_EMULATION)
 {
 	return __copy_siginfo_to_user32(to, from, in_x32_syscall());
 }
 int __copy_siginfo_to_user32(struct compat_siginfo __user *to,
-			     const struct siginfo *from, bool x32_ABI)
+			     const struct kernel_siginfo *from, bool x32_ABI)
 #endif
 {
 	struct compat_siginfo new;
@@ -2995,7 +2995,7 @@ int __copy_siginfo_to_user32(struct compat_siginfo __user *to,
 	return 0;
 }
 
-int copy_siginfo_from_user32(struct siginfo *to,
+int copy_siginfo_from_user32(struct kernel_siginfo *to,
 			     const struct compat_siginfo __user *ufrom)
 {
 	struct compat_siginfo from;
@@ -3085,7 +3085,7 @@ int copy_siginfo_from_user32(struct siginfo *to,
  *  @info: if non-null, the signal's siginfo is returned here
  *  @ts: upper bound on process time suspension
  */
-static int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
+static int do_sigtimedwait(const sigset_t *which, kernel_siginfo_t *info,
 		    const struct timespec *ts)
 {
 	ktime_t *to = NULL, timeout = KTIME_MAX;
@@ -3149,7 +3149,7 @@ SYSCALL_DEFINE4(rt_sigtimedwait, const sigset_t __user *, uthese,
 {
 	sigset_t these;
 	struct timespec ts;
-	siginfo_t info;
+	kernel_siginfo_t info;
 	int ret;
 
 	/* XXX: Don't preclude handling different sized sigset_t's.  */
@@ -3181,7 +3181,7 @@ COMPAT_SYSCALL_DEFINE4(rt_sigtimedwait, compat_sigset_t __user *, uthese,
 {
 	sigset_t s;
 	struct timespec t;
-	siginfo_t info;
+	kernel_siginfo_t info;
 	long ret;
 
 	if (sigsetsize != sizeof(sigset_t))
@@ -3213,7 +3213,7 @@ COMPAT_SYSCALL_DEFINE4(rt_sigtimedwait, compat_sigset_t __user *, uthese,
  */
 SYSCALL_DEFINE2(kill, pid_t, pid, int, sig)
 {
-	struct siginfo info;
+	struct kernel_siginfo info;
 
 	clear_siginfo(&info);
 	info.si_signo = sig;
@@ -3226,7 +3226,7 @@ SYSCALL_DEFINE2(kill, pid_t, pid, int, sig)
 }
 
 static int
-do_send_specific(pid_t tgid, pid_t pid, int sig, struct siginfo *info)
+do_send_specific(pid_t tgid, pid_t pid, int sig, struct kernel_siginfo *info)
 {
 	struct task_struct *p;
 	int error = -ESRCH;
@@ -3257,7 +3257,7 @@ do_send_specific(pid_t tgid, pid_t pid, int sig, struct siginfo *info)
 
 static int do_tkill(pid_t tgid, pid_t pid, int sig)
 {
-	struct siginfo info;
+	struct kernel_siginfo info;
 
 	clear_siginfo(&info);
 	info.si_signo = sig;
@@ -3304,7 +3304,7 @@ SYSCALL_DEFINE2(tkill, pid_t, pid, int, sig)
 	return do_tkill(0, pid, sig);
 }
 
-static int do_rt_sigqueueinfo(pid_t pid, int sig, siginfo_t *info)
+static int do_rt_sigqueueinfo(pid_t pid, int sig, kernel_siginfo_t *info)
 {
 	/* Not even root can pretend to send signals from the kernel.
 	 * Nor can they impersonate a kill()/tgkill(), which adds source info.
@@ -3329,7 +3329,7 @@ static int do_rt_sigqueueinfo(pid_t pid, int sig, siginfo_t *info)
 SYSCALL_DEFINE3(rt_sigqueueinfo, pid_t, pid, int, sig,
 		siginfo_t __user *, uinfo)
 {
-	siginfo_t info;
+	kernel_siginfo_t info;
 	int ret = copy_siginfo_from_user(&info, uinfo);
 	if (unlikely(ret))
 		return ret;
@@ -3342,7 +3342,7 @@ COMPAT_SYSCALL_DEFINE3(rt_sigqueueinfo,
 			int, sig,
 			struct compat_siginfo __user *, uinfo)
 {
-	siginfo_t info;
+	kernel_siginfo_t info;
 	int ret = copy_siginfo_from_user32(&info, uinfo);
 	if (unlikely(ret))
 		return ret;
@@ -3350,7 +3350,7 @@ COMPAT_SYSCALL_DEFINE3(rt_sigqueueinfo,
 }
 #endif
 
-static int do_rt_tgsigqueueinfo(pid_t tgid, pid_t pid, int sig, siginfo_t *info)
+static int do_rt_tgsigqueueinfo(pid_t tgid, pid_t pid, int sig, kernel_siginfo_t *info)
 {
 	/* This is only valid for single tasks */
 	if (pid <= 0 || tgid <= 0)
@@ -3372,7 +3372,7 @@ static int do_rt_tgsigqueueinfo(pid_t tgid, pid_t pid, int sig, siginfo_t *info)
 SYSCALL_DEFINE4(rt_tgsigqueueinfo, pid_t, tgid, pid_t, pid, int, sig,
 		siginfo_t __user *, uinfo)
 {
-	siginfo_t info;
+	kernel_siginfo_t info;
 	int ret = copy_siginfo_from_user(&info, uinfo);
 	if (unlikely(ret))
 		return ret;
@@ -3386,7 +3386,7 @@ COMPAT_SYSCALL_DEFINE4(rt_tgsigqueueinfo,
 			int, sig,
 			struct compat_siginfo __user *, uinfo)
 {
-	siginfo_t info;
+	kernel_siginfo_t info;
 	int ret = copy_siginfo_from_user32(&info, uinfo);
 	if (unlikely(ret))
 		return ret;
@@ -3968,10 +3968,57 @@ __weak const char *arch_vma_name(struct vm_area_struct *vma)
 	return NULL;
 }
 
-void __init signals_init(void)
+static inline void siginfo_buildtime_checks(void)
 {
 	BUILD_BUG_ON(sizeof(struct siginfo) != SI_MAX_SIZE);
 
+	/* Verify the offsets in the two siginfos match */
+#define CHECK_OFFSET(field) \
+	BUILD_BUG_ON(offsetof(siginfo_t, field) != offsetof(kernel_siginfo_t, field))
+
+	/* kill */
+	CHECK_OFFSET(si_pid);
+	CHECK_OFFSET(si_uid);
+
+	/* timer */
+	CHECK_OFFSET(si_tid);
+	CHECK_OFFSET(si_overrun);
+	CHECK_OFFSET(si_value);
+
+	/* rt */
+	CHECK_OFFSET(si_pid);
+	CHECK_OFFSET(si_uid);
+	CHECK_OFFSET(si_value);
+
+	/* sigchld */
+	CHECK_OFFSET(si_pid);
+	CHECK_OFFSET(si_uid);
+	CHECK_OFFSET(si_status);
+	CHECK_OFFSET(si_utime);
+	CHECK_OFFSET(si_stime);
+
+	/* sigfault */
+	CHECK_OFFSET(si_addr);
+	CHECK_OFFSET(si_addr_lsb);
+	CHECK_OFFSET(si_lower);
+	CHECK_OFFSET(si_upper);
+	CHECK_OFFSET(si_pkey);
+
+	/* sigpoll */
+	CHECK_OFFSET(si_band);
+	CHECK_OFFSET(si_fd);
+
+	/* sigsys */
+	CHECK_OFFSET(si_call_addr);
+	CHECK_OFFSET(si_syscall);
+	CHECK_OFFSET(si_arch);
+#undef CHECK_OFFSET
+}
+
+void __init signals_init(void)
+{
+	siginfo_buildtime_checks();
+
 	sigqueue_cachep = KMEM_CACHE(sigqueue, SLAB_PANIC);
 }
 

commit 4cd2e0e70af6897ca2247fa1ffb1553ca16b4903
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Apr 18 17:30:19 2018 -0500

    signal: Introduce copy_siginfo_from_user and use it's return value
    
    In preparation for using a smaller version of siginfo in the kernel
    introduce copy_siginfo_from_user and use it when siginfo is copied from
    userspace.
    
    Make the pattern for using copy_siginfo_from_user and
    copy_siginfo_from_user32 to capture the return value and return that
    value on error.
    
    This is a necessary prerequisite for using a smaller siginfo
    in the kernel than the kernel exports to userspace.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index debb485a76db..c0e289e62d77 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2896,6 +2896,13 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 	return 0;
 }
 
+int copy_siginfo_from_user(siginfo_t *to, const siginfo_t __user *from)
+{
+	if (copy_from_user(to, from, sizeof(struct siginfo)))
+		return -EFAULT;
+	return 0;
+}
+
 #ifdef CONFIG_COMPAT
 int copy_siginfo_to_user32(struct compat_siginfo __user *to,
 			   const struct siginfo *from)
@@ -3323,8 +3330,9 @@ SYSCALL_DEFINE3(rt_sigqueueinfo, pid_t, pid, int, sig,
 		siginfo_t __user *, uinfo)
 {
 	siginfo_t info;
-	if (copy_from_user(&info, uinfo, sizeof(siginfo_t)))
-		return -EFAULT;
+	int ret = copy_siginfo_from_user(&info, uinfo);
+	if (unlikely(ret))
+		return ret;
 	return do_rt_sigqueueinfo(pid, sig, &info);
 }
 
@@ -3365,10 +3373,9 @@ SYSCALL_DEFINE4(rt_tgsigqueueinfo, pid_t, tgid, pid_t, pid, int, sig,
 		siginfo_t __user *, uinfo)
 {
 	siginfo_t info;
-
-	if (copy_from_user(&info, uinfo, sizeof(siginfo_t)))
-		return -EFAULT;
-
+	int ret = copy_siginfo_from_user(&info, uinfo);
+	if (unlikely(ret))
+		return ret;
 	return do_rt_tgsigqueueinfo(tgid, pid, sig, &info);
 }
 
@@ -3380,9 +3387,9 @@ COMPAT_SYSCALL_DEFINE4(rt_tgsigqueueinfo,
 			struct compat_siginfo __user *, uinfo)
 {
 	siginfo_t info;
-
-	if (copy_siginfo_from_user32(&info, uinfo))
-		return -EFAULT;
+	int ret = copy_siginfo_from_user32(&info, uinfo);
+	if (unlikely(ret))
+		return ret;
 	return do_rt_tgsigqueueinfo(tgid, pid, sig, &info);
 }
 #endif

commit f28380185193610c716a90ec9b9e696638a495ce
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Apr 18 17:48:49 2018 -0500

    signal: Remove the need for __ARCH_SI_PREABLE_SIZE and SI_PAD_SIZE
    
    Rework the defintion of struct siginfo so that the array padding
    struct siginfo to SI_MAX_SIZE can be placed in a union along side of
    the rest of the struct siginfo members.  The result is that we no
    longer need the __ARCH_SI_PREAMBLE_SIZE or SI_PAD_SIZE definitions.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index e445b0a63faa..debb485a76db 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3963,9 +3963,6 @@ __weak const char *arch_vma_name(struct vm_area_struct *vma)
 
 void __init signals_init(void)
 {
-	/* If this check fails, the __ARCH_SI_PREAMBLE_SIZE value is wrong! */
-	BUILD_BUG_ON(__ARCH_SI_PREAMBLE_SIZE
-		!= offsetof(struct siginfo, _sifields._pad));
 	BUILD_BUG_ON(sizeof(struct siginfo) != SI_MAX_SIZE);
 
 	sigqueue_cachep = KMEM_CACHE(sigqueue, SLAB_PANIC);

commit e75dc036c445b91b8b2ad4e6c9b05f04b6be6d3f
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Sep 25 12:04:47 2018 +0200

    signal: Fail sigqueueinfo if si_signo != sig
    
    The kernel needs to validate that the contents of struct siginfo make
    sense as siginfo is copied into the kernel, so that the proper union
    members can be put in the appropriate locations.  The field si_signo
    is a fundamental part of that validation.  As such changing the
    contents of si_signo after the validation make no sense and can result
    in nonsense values in the kernel.
    
    As such simply fail if someone is silly enough to set si_signo out of
    sync with the signal number passed to sigqueueinfo.
    
    I don't expect a problem as glibc's sigqueue implementation sets
    "si_signo = sig" and CRIU just returns to the kernel what the kernel
    gave to it.
    
    If there is some application that calls sigqueueinfo directly that has
    a problem with this added sanity check we can revisit this when we see
    what kind of crazy that application is doing.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 7b49c31d3fdb..e445b0a63faa 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3306,7 +3306,8 @@ static int do_rt_sigqueueinfo(pid_t pid, int sig, siginfo_t *info)
 	    (task_pid_vnr(current) != pid))
 		return -EPERM;
 
-	info->si_signo = sig;
+	if (info->si_signo != sig)
+		return -EINVAL;
 
 	/* POSIX.1b doesn't mention process groups.  */
 	return kill_proc_info(sig, info, pid);
@@ -3354,7 +3355,8 @@ static int do_rt_tgsigqueueinfo(pid_t tgid, pid_t pid, int sig, siginfo_t *info)
 	    (task_pid_vnr(current) != pid))
 		return -EPERM;
 
-	info->si_signo = sig;
+	if (info->si_signo != sig)
+		return -EINVAL;
 
 	return do_send_specific(tgid, pid, sig, info);
 }

commit 018303a931a89b91dacd76140b8ebe51893dc5fe
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Apr 18 19:15:59 2018 -0500

    signal/sparc: Move EMT_TAGOVF into the generic siginfo.h
    
    When moving all of the architectures specific si_codes into
    siginfo.h, I apparently overlooked EMT_TAGOVF.  Move it now.
    
    Remove the now redundant test in siginfo_layout for SIGEMT
    as now NSIGEMT is always defined.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index e16278710b36..7b49c31d3fdb 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2856,7 +2856,7 @@ enum siginfo_layout siginfo_layout(int sig, int si_code)
 			[SIGSEGV] = { NSIGSEGV, SIL_FAULT },
 			[SIGBUS]  = { NSIGBUS,  SIL_FAULT },
 			[SIGTRAP] = { NSIGTRAP, SIL_FAULT },
-#if defined(SIGEMT) && defined(NSIGEMT)
+#if defined(SIGEMT)
 			[SIGEMT]  = { NSIGEMT,  SIL_FAULT },
 #endif
 			[SIGCHLD] = { NSIGCHLD, SIL_CHLD },

commit 22839869f21ab3850fbbac9b425ccc4c0023926f
Author: Will Deacon <will.deacon@arm.com>
Date:   Wed Sep 5 15:34:42 2018 +0100

    signal: Introduce COMPAT_SIGMINSTKSZ for use in compat_sys_sigaltstack
    
    The sigaltstack(2) system call fails with -ENOMEM if the new alternative
    signal stack is found to be smaller than SIGMINSTKSZ. On architectures
    such as arm64, where the native value for SIGMINSTKSZ is larger than
    the compat value, this can result in an unexpected error being reported
    to a compat task. See, for example:
    
      https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=904385
    
    This patch fixes the problem by extending do_sigaltstack to take the
    minimum signal stack size as an additional parameter, allowing the
    native and compat system call entry code to pass in their respective
    values. COMPAT_SIGMINSTKSZ is just defined as SIGMINSTKSZ if it has not
    been defined by the architecture.
    
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Dominik Brodowski <linux@dominikbrodowski.net>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Reported-by: Steve McIntyre <steve.mcintyre@arm.com>
    Tested-by: Steve McIntyre <93sam@debian.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5843c541fda9..e4aad0e90882 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3460,7 +3460,8 @@ int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 }
 
 static int
-do_sigaltstack (const stack_t *ss, stack_t *oss, unsigned long sp)
+do_sigaltstack (const stack_t *ss, stack_t *oss, unsigned long sp,
+		size_t min_ss_size)
 {
 	struct task_struct *t = current;
 
@@ -3490,7 +3491,7 @@ do_sigaltstack (const stack_t *ss, stack_t *oss, unsigned long sp)
 			ss_size = 0;
 			ss_sp = NULL;
 		} else {
-			if (unlikely(ss_size < MINSIGSTKSZ))
+			if (unlikely(ss_size < min_ss_size))
 				return -ENOMEM;
 		}
 
@@ -3508,7 +3509,8 @@ SYSCALL_DEFINE2(sigaltstack,const stack_t __user *,uss, stack_t __user *,uoss)
 	if (uss && copy_from_user(&new, uss, sizeof(stack_t)))
 		return -EFAULT;
 	err = do_sigaltstack(uss ? &new : NULL, uoss ? &old : NULL,
-			      current_user_stack_pointer());
+			      current_user_stack_pointer(),
+			      MINSIGSTKSZ);
 	if (!err && uoss && copy_to_user(uoss, &old, sizeof(stack_t)))
 		err = -EFAULT;
 	return err;
@@ -3519,7 +3521,8 @@ int restore_altstack(const stack_t __user *uss)
 	stack_t new;
 	if (copy_from_user(&new, uss, sizeof(stack_t)))
 		return -EFAULT;
-	(void)do_sigaltstack(&new, NULL, current_user_stack_pointer());
+	(void)do_sigaltstack(&new, NULL, current_user_stack_pointer(),
+			     MINSIGSTKSZ);
 	/* squash all but EFAULT for now */
 	return 0;
 }
@@ -3553,7 +3556,8 @@ static int do_compat_sigaltstack(const compat_stack_t __user *uss_ptr,
 		uss.ss_size = uss32.ss_size;
 	}
 	ret = do_sigaltstack(uss_ptr ? &uss : NULL, &uoss,
-			     compat_user_stack_pointer());
+			     compat_user_stack_pointer(),
+			     COMPAT_MINSIGSTKSZ);
 	if (ret >= 0 && uoss_ptr)  {
 		compat_stack_t old;
 		memset(&old, 0, sizeof(old));

commit fb50f5a4011c499bc1b1fae77299cfcb3945e51b
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Sep 13 19:26:35 2018 +0200

    signal: Pair exports with their functions
    
    For readability and consistency with the other exports in
    kernel/signal.c pair the exports of signal sending functions with
    their functions, instead of having the exports in one big clump.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 99e91163c9a3..e16278710b36 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -176,6 +176,7 @@ void recalc_sigpending(void)
 		clear_thread_flag(TIF_SIGPENDING);
 
 }
+EXPORT_SYMBOL(recalc_sigpending);
 
 void calculate_sigpending(void)
 {
@@ -466,6 +467,7 @@ void flush_signals(struct task_struct *t)
 	flush_sigqueue(&t->signal->shared_pending);
 	spin_unlock_irqrestore(&t->sighand->siglock, flags);
 }
+EXPORT_SYMBOL(flush_signals);
 
 #ifdef CONFIG_POSIX_TIMERS
 static void __flush_itimer_signals(struct sigpending *pending)
@@ -684,6 +686,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 #endif
 	return signr;
 }
+EXPORT_SYMBOL_GPL(dequeue_signal);
 
 /*
  * Tell a process that it has a new active signal..
@@ -1490,6 +1493,7 @@ int send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 
 	return do_send_sig_info(sig, info, p, PIDTYPE_PID);
 }
+EXPORT_SYMBOL(send_sig_info);
 
 #define __si_special(priv) \
 	((priv) ? SEND_SIG_PRIV : SEND_SIG_NOINFO)
@@ -1499,11 +1503,13 @@ send_sig(int sig, struct task_struct *p, int priv)
 {
 	return send_sig_info(sig, __si_special(priv), p);
 }
+EXPORT_SYMBOL(send_sig);
 
 void force_sig(int sig, struct task_struct *p)
 {
 	force_sig_info(sig, SEND_SIG_PRIV, p);
 }
+EXPORT_SYMBOL(force_sig);
 
 /*
  * When things go south during signal handling, we
@@ -2634,14 +2640,6 @@ void exit_signals(struct task_struct *tsk)
 	}
 }
 
-EXPORT_SYMBOL(recalc_sigpending);
-EXPORT_SYMBOL_GPL(dequeue_signal);
-EXPORT_SYMBOL(flush_signals);
-EXPORT_SYMBOL(force_sig);
-EXPORT_SYMBOL(send_sig);
-EXPORT_SYMBOL(send_sig_info);
-EXPORT_SYMBOL(sigprocmask);
-
 /*
  * System call entry points.
  */
@@ -2735,6 +2733,7 @@ int sigprocmask(int how, sigset_t *set, sigset_t *oldset)
 	__set_current_blocked(&newset);
 	return 0;
 }
+EXPORT_SYMBOL(sigprocmask);
 
 /**
  *  sys_rt_sigprocmask - change the list of currently blocked signals

commit b21c5bd562dd97ac0b936439fc64bd30ec09b2e0
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Jul 21 11:34:03 2018 -0500

    signal: Remove specific_send_sig_info
    
    This function is static and it only has two callers.  As
    specific_send_sig_info is only called twice remembering what
    specific_send_sig_info does when reading the code is difficutl and it
    makes it hard to see which sending sending functions are equivalent to
    which others.
    
    So remove specific_send_sig_info to make the code easier to read.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index ec136fda457a..99e91163c9a3 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1199,12 +1199,6 @@ __group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 	return send_signal(sig, info, p, PIDTYPE_TGID);
 }
 
-static int
-specific_send_sig_info(int sig, struct siginfo *info, struct task_struct *t)
-{
-	return send_signal(sig, info, t, PIDTYPE_PID);
-}
-
 int do_send_sig_info(int sig, struct siginfo *info, struct task_struct *p,
 			enum pid_type type)
 {
@@ -1254,7 +1248,7 @@ force_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 	 */
 	if (action->sa.sa_handler == SIG_DFL && !t->ptrace)
 		t->signal->flags &= ~SIGNAL_UNKILLABLE;
-	ret = specific_send_sig_info(sig, info, t);
+	ret = send_signal(sig, info, t, PIDTYPE_PID);
 	spin_unlock_irqrestore(&t->sighand->siglock, flags);
 
 	return ret;
@@ -2330,7 +2324,7 @@ static int ptrace_signal(int signr, siginfo_t *info)
 
 	/* If the (new) signal is now blocked, requeue it.  */
 	if (sigismember(&current->blocked, signr)) {
-		specific_send_sig_info(signr, info, current);
+		send_signal(signr, info, current, PIDTYPE_PID);
 		signr = 0;
 	}
 

commit 4ff4c31a6e85f4c49fbeebeaa28018d002884b5a
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Sep 3 10:39:04 2018 +0200

    signal: Remove SEND_SIG_FORCED
    
    There are no more users of SEND_SIG_FORCED so it may be safely removed.
    
    Remove the definition of SEND_SIG_FORCED, it's use in is_si_special,
    it's use in TP_STORE_SIGINFO, and it's use in __send_signal as without
    any users the uses of SEND_SIG_FORCED are now unncessary.
    
    This makes the code simpler, easier to understand and use.  Users of
    signal sending functions now no longer need to ask themselves do I
    need to use SEND_SIG_FORCED.
    
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index d7d1adf735f4..ec136fda457a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -736,7 +736,7 @@ static void flush_sigqueue_mask(sigset_t *mask, struct sigpending *s)
 
 static inline int is_si_special(const struct siginfo *info)
 {
-	return info <= SEND_SIG_FORCED;
+	return info <= SEND_SIG_PRIV;
 }
 
 static inline bool si_fromuser(const struct siginfo *info)
@@ -1039,7 +1039,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 
 	result = TRACE_SIGNAL_IGNORED;
 	if (!prepare_signal(sig, t,
-			from_ancestor_ns || (info == SEND_SIG_PRIV) || (info == SEND_SIG_FORCED)))
+			from_ancestor_ns || (info == SEND_SIG_PRIV)))
 		goto ret;
 
 	pending = (type != PIDTYPE_PID) ? &t->signal->shared_pending : &t->pending;
@@ -1057,8 +1057,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	 * Skip useless siginfo allocation for SIGKILL SIGSTOP,
 	 * and kernel threads.
 	 */
-	if ((info == SEND_SIG_FORCED) ||
-	    sig_kernel_only(sig) || (t->flags & PF_KTHREAD))
+	if (sig_kernel_only(sig) || (t->flags & PF_KTHREAD))
 		goto out_set;
 
 	/*

commit f149b31557446aff9ca96d4be7e39cc266f6e7cc
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Sep 3 09:50:36 2018 +0200

    signal: Never allocate siginfo for SIGKILL or SIGSTOP
    
    The SIGKILL and SIGSTOP signals are never delivered to userspace so
    queued siginfo for these signals can never be observed.  Therefore
    remove the chance of failure by never even attempting to allocate
    siginfo in those cases.
    
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 20931a892ace..d7d1adf735f4 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1054,10 +1054,11 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 
 	result = TRACE_SIGNAL_DELIVERED;
 	/*
-	 * fast-pathed signals for kernel-internal things like SIGSTOP
-	 * or SIGKILL.
+	 * Skip useless siginfo allocation for SIGKILL SIGSTOP,
+	 * and kernel threads.
 	 */
-	if ((info == SEND_SIG_FORCED) || (t->flags & PF_KTHREAD))
+	if ((info == SEND_SIG_FORCED) ||
+	    sig_kernel_only(sig) || (t->flags & PF_KTHREAD))
 		goto out_set;
 
 	/*

commit 035150540545f62bada95860ba00fe1e0cd62f63
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Jul 20 05:31:53 2018 -0500

    signal: Don't send siginfo to kthreads.
    
    Today kernel threads never dequeue siginfo so it is pointless to
    enqueue siginfo for them.  The usb gadget mass storage driver goes
    one farther and uses SEND_SIG_FORCED to guarantee that no siginfo is
    even enqueued.
    
    Generalize the optimization of the usb mass storage driver and never
    perform an unnecessary allocation when delivering signals to kthreads.
    
    Switch the mass storage driver from sending signals with
    SEND_SIG_FORCED to SEND_SIG_PRIV.  As using SEND_SIG_FORCED is now
    unnecessary.
    
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8081ab79e97d..20931a892ace 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1057,7 +1057,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	 * fast-pathed signals for kernel-internal things like SIGSTOP
 	 * or SIGKILL.
 	 */
-	if (info == SEND_SIG_FORCED)
+	if ((info == SEND_SIG_FORCED) || (t->flags & PF_KTHREAD))
 		goto out_set;
 
 	/*

commit 3597dfe01d12f570bc739da67f857fd222a3ea66
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Sep 3 20:02:46 2018 +0200

    signal: Always deliver the kernel's SIGKILL and SIGSTOP to a pid namespace init
    
    Instead of playing whack-a-mole and changing SEND_SIG_PRIV to
    SEND_SIG_FORCED throughout the kernel to ensure a pid namespace init
    gets signals sent by the kernel, stop allowing a pid namespace init to
    ignore SIGKILL or SIGSTOP sent by the kernel.  A pid namespace init is
    only supposed to be able to ignore signals sent from itself and
    children with SIG_DFL.
    
    Fixes: 921cf9f63089 ("signals: protect cinit from unblocked SIG_DFL signals")
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index b33264bb2064..8081ab79e97d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1039,7 +1039,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 
 	result = TRACE_SIGNAL_IGNORED;
 	if (!prepare_signal(sig, t,
-			from_ancestor_ns || (info == SEND_SIG_FORCED)))
+			from_ancestor_ns || (info == SEND_SIG_PRIV) || (info == SEND_SIG_FORCED)))
 		goto ret;
 
 	pending = (type != PIDTYPE_PID) ? &t->signal->shared_pending : &t->pending;

commit 86989c41b5ea08776c450cb759592532314a4ed6
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Jul 19 19:47:27 2018 -0500

    signal: Always ignore SIGKILL and SIGSTOP sent to the global init
    
    If the first process started (aka /sbin/init) receives a SIGKILL it
    will panic the system if it is delivered.  Making the system unusable
    and undebugable.  It isn't much better if the first process started
    receives SIGSTOP.
    
    So always ignore SIGSTOP and SIGKILL sent to init.
    
    This is done in a separate clause in sig_task_ignored as force_sig_info
    can clear SIG_UNKILLABLE and this protection should work even then.
    
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5843c541fda9..b33264bb2064 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -78,6 +78,10 @@ static bool sig_task_ignored(struct task_struct *t, int sig, bool force)
 
 	handler = sig_handler(t, sig);
 
+	/* SIGKILL and SIGSTOP may not be sent to the global init */
+	if (unlikely(is_global_init(t) && sig_kernel_only(sig)))
+		return true;
+
 	if (unlikely(t->signal->flags & SIGNAL_UNKILLABLE) &&
 	    handler == SIG_DFL && !(force && sig_kernel_only(sig)))
 		return true;

commit 49c39f8464a9af702e9d45800c00a572753aeb06
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed Apr 18 15:56:13 2018 +0200

    y2038: signal: Change rt_sigtimedwait to use __kernel_timespec
    
    This changes sys_rt_sigtimedwait() to use get_timespec64(), changing
    the timeout type to __kernel_timespec, which will be changed to use
    a 64-bit time_t in the future. Since the do_sigtimedwait() core
    function changes, we also have to modify the compat version of this
    system call in the same way.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/kernel/signal.c b/kernel/signal.c
index a4db724e14c1..0831d56a731a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3082,7 +3082,7 @@ int copy_siginfo_from_user32(struct siginfo *to,
  *  @ts: upper bound on process time suspension
  */
 static int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
-		    const struct timespec *ts)
+		    const struct timespec64 *ts)
 {
 	ktime_t *to = NULL, timeout = KTIME_MAX;
 	struct task_struct *tsk = current;
@@ -3090,9 +3090,9 @@ static int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
 	int sig, ret = 0;
 
 	if (ts) {
-		if (!timespec_valid(ts))
+		if (!timespec64_valid(ts))
 			return -EINVAL;
-		timeout = timespec_to_ktime(*ts);
+		timeout = timespec64_to_ktime(*ts);
 		to = &timeout;
 	}
 
@@ -3140,11 +3140,12 @@ static int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
  *  @sigsetsize: size of sigset_t type
  */
 SYSCALL_DEFINE4(rt_sigtimedwait, const sigset_t __user *, uthese,
-		siginfo_t __user *, uinfo, const struct timespec __user *, uts,
+		siginfo_t __user *, uinfo,
+		const struct __kernel_timespec __user *, uts,
 		size_t, sigsetsize)
 {
 	sigset_t these;
-	struct timespec ts;
+	struct timespec64 ts;
 	siginfo_t info;
 	int ret;
 
@@ -3156,7 +3157,7 @@ SYSCALL_DEFINE4(rt_sigtimedwait, const sigset_t __user *, uthese,
 		return -EFAULT;
 
 	if (uts) {
-		if (copy_from_user(&ts, uts, sizeof(ts)))
+		if (get_timespec64(&ts, uts))
 			return -EFAULT;
 	}
 
@@ -3176,7 +3177,7 @@ COMPAT_SYSCALL_DEFINE4(rt_sigtimedwait, compat_sigset_t __user *, uthese,
 		struct old_timespec32 __user *, uts, compat_size_t, sigsetsize)
 {
 	sigset_t s;
-	struct timespec t;
+	struct timespec64 t;
 	siginfo_t info;
 	long ret;
 
@@ -3187,7 +3188,7 @@ COMPAT_SYSCALL_DEFINE4(rt_sigtimedwait, compat_sigset_t __user *, uthese,
 		return -EFAULT;
 
 	if (uts) {
-		if (compat_get_timespec(&t, uts))
+		if (get_old_timespec32(&t, uts))
 			return -EFAULT;
 	}
 

commit 9afc5eee65ca7d717a99d6fe8f4adfe32a40940a
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Fri Jul 13 12:52:28 2018 +0200

    y2038: globally rename compat_time to old_time32
    
    Christoph Hellwig suggested a slightly different path for handling
    backwards compatibility with the 32-bit time_t based system calls:
    
    Rather than simply reusing the compat_sys_* entry points on 32-bit
    architectures unchanged, we get rid of those entry points and the
    compat_time types by renaming them to something that makes more sense
    on 32-bit architectures (which don't have a compat mode otherwise),
    and then share the entry points under the new name with the 64-bit
    architectures that use them for implementing the compatibility.
    
    The following types and interfaces are renamed here, and moved
    from linux/compat_time.h to linux/time32.h:
    
    old                             new
    ---                             ---
    compat_time_t                   old_time32_t
    struct compat_timeval           struct old_timeval32
    struct compat_timespec          struct old_timespec32
    struct compat_itimerspec        struct old_itimerspec32
    ns_to_compat_timeval()          ns_to_old_timeval32()
    get_compat_itimerspec64()       get_old_itimerspec32()
    put_compat_itimerspec64()       put_old_itimerspec32()
    compat_get_timespec64()         get_old_timespec32()
    compat_put_timespec64()         put_old_timespec32()
    
    As we already have aliases in place, this patch addresses only the
    instances that are relevant to the system call interface in particular,
    not those that occur in device drivers and other modules. Those
    will get handled separately, while providing the 64-bit version
    of the respective interfaces.
    
    I'm not renaming the timex, rusage and itimerval structures, as we are
    still debating what the new interface will look like, and whether we
    will need a replacement at all.
    
    This also doesn't change the names of the syscall entry points, which can
    be done more easily when we actually switch over the 32-bit architectures
    to use them, at that point we need to change COMPAT_SYSCALL_DEFINEx to
    SYSCALL_DEFINEx with a new name, e.g. with a _time32 suffix.
    
    Suggested-by: Christoph Hellwig <hch@infradead.org>
    Link: https://lore.kernel.org/lkml/20180705222110.GA5698@infradead.org/
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5843c541fda9..a4db724e14c1 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3173,7 +3173,7 @@ SYSCALL_DEFINE4(rt_sigtimedwait, const sigset_t __user *, uthese,
 #ifdef CONFIG_COMPAT
 COMPAT_SYSCALL_DEFINE4(rt_sigtimedwait, compat_sigset_t __user *, uthese,
 		struct compat_siginfo __user *, uinfo,
-		struct compat_timespec __user *, uts, compat_size_t, sigsetsize)
+		struct old_timespec32 __user *, uts, compat_size_t, sigsetsize)
 {
 	sigset_t s;
 	struct timespec t;

commit cd9b44f90763c3367e8dd0601849ffb028e8ba52
Merge: df2def49c57b 2a9d64810042
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Aug 22 12:34:08 2018 -0700

    Merge branch 'akpm' (patches from Andrew)
    
    Merge more updates from Andrew Morton:
    
     - the rest of MM
    
     - procfs updates
    
     - various misc things
    
     - more y2038 fixes
    
     - get_maintainer updates
    
     - lib/ updates
    
     - checkpatch updates
    
     - various epoll updates
    
     - autofs updates
    
     - hfsplus
    
     - some reiserfs work
    
     - fatfs updates
    
     - signal.c cleanups
    
     - ipc/ updates
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (166 commits)
      ipc/util.c: update return value of ipc_getref from int to bool
      ipc/util.c: further variable name cleanups
      ipc: simplify ipc initialization
      ipc: get rid of ids->tables_initialized hack
      lib/rhashtable: guarantee initial hashtable allocation
      lib/rhashtable: simplify bucket_table_alloc()
      ipc: drop ipc_lock()
      ipc/util.c: correct comment in ipc_obtain_object_check
      ipc: rename ipcctl_pre_down_nolock()
      ipc/util.c: use ipc_rcu_putref() for failues in ipc_addid()
      ipc: reorganize initialization of kern_ipc_perm.seq
      ipc: compute kern_ipc_perm.id under the ipc lock
      init/Kconfig: remove EXPERT from CHECKPOINT_RESTORE
      fs/sysv/inode.c: use ktime_get_real_seconds() for superblock stamp
      adfs: use timespec64 for time conversion
      kernel/sysctl.c: fix typos in comments
      drivers/rapidio/devices/rio_mport_cdev.c: remove redundant pointer md
      fork: don't copy inconsistent signal handler state to child
      signal: make get_signal() return bool
      signal: make sigkill_pending() return bool
      ...

commit 20ab7218d2507b2dbec9c053c2f1b96054e266b6
Author: Christian Brauner <christian@brauner.io>
Date:   Tue Aug 21 22:00:54 2018 -0700

    signal: make get_signal() return bool
    
    make get_signal() already behaves like a boolean function.  Let's actually
    declare it as such too.
    
    Link: http://lkml.kernel.org/r/20180602103653.18181-18-christian@brauner.io
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: James Morris <james.morris@microsoft.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9f9b4183178e..786bacc60649 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2287,7 +2287,7 @@ static int ptrace_signal(int signr, siginfo_t *info)
 	return signr;
 }
 
-int get_signal(struct ksignal *ksig)
+bool get_signal(struct ksignal *ksig)
 {
 	struct sighand_struct *sighand = current->sighand;
 	struct signal_struct *signal = current->signal;
@@ -2297,7 +2297,7 @@ int get_signal(struct ksignal *ksig)
 		task_work_run();
 
 	if (unlikely(uprobe_deny_signal()))
-		return 0;
+		return false;
 
 	/*
 	 * Do this once, we can't return to user-mode if freezing() == T.

commit f99e9d8c5c7f5539e6d97fd04a4ad213e52daac0
Author: Christian Brauner <christian@brauner.io>
Date:   Tue Aug 21 22:00:50 2018 -0700

    signal: make sigkill_pending() return bool
    
    sigkill_pending() already behaves like a boolean function.  Let's actually
    declare it as such too.
    
    Link: http://lkml.kernel.org/r/20180602103653.18181-17-christian@brauner.io
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: James Morris <james.morris@microsoft.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 3de1ba2af032..9f9b4183178e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1904,10 +1904,10 @@ static inline bool may_ptrace_stop(void)
  * Return non-zero if there is a SIGKILL that should be waking us up.
  * Called with the siglock held.
  */
-static int sigkill_pending(struct task_struct *tsk)
+static bool sigkill_pending(struct task_struct *tsk)
 {
-	return	sigismember(&tsk->pending.signal, SIGKILL) ||
-		sigismember(&tsk->signal->shared_pending.signal, SIGKILL);
+	return sigismember(&tsk->pending.signal, SIGKILL) ||
+	       sigismember(&tsk->signal->shared_pending.signal, SIGKILL);
 }
 
 /*

commit a19e2c01f71bb4b8442db450200a01a28db36a04
Author: Christian Brauner <christian@brauner.io>
Date:   Tue Aug 21 22:00:46 2018 -0700

    signal: make legacy_queue() return bool
    
    legacy_queue() already behaves like a boolean function.  Let's actually
    declare it as such too.
    
    Link: http://lkml.kernel.org/r/20180602103653.18181-16-christian@brauner.io
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: James Morris <james.morris@microsoft.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0e48dbc6649e..3de1ba2af032 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -972,7 +972,7 @@ static void complete_signal(int sig, struct task_struct *p, int group)
 	return;
 }
 
-static inline int legacy_queue(struct sigpending *signals, int sig)
+static inline bool legacy_queue(struct sigpending *signals, int sig)
 {
 	return (sig < SIGRTMIN) && sigismember(&signals->signal, sig);
 }

commit acd14e62f075f44cd04e1ac2920a515f9b80146e
Author: Christian Brauner <christian@brauner.io>
Date:   Tue Aug 21 22:00:42 2018 -0700

    signal: make wants_signal() return bool
    
    wants_signal() already behaves like a boolean function.  Let's actually
    declare it as such too.
    
    Link: http://lkml.kernel.org/r/20180602103653.18181-15-christian@brauner.io
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: James Morris <james.morris@microsoft.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index fe0e9e82ce44..0e48dbc6649e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -879,16 +879,20 @@ static bool prepare_signal(int sig, struct task_struct *p, bool force)
  * as soon as they're available, so putting the signal on the shared queue
  * will be equivalent to sending it to one such thread.
  */
-static inline int wants_signal(int sig, struct task_struct *p)
+static inline bool wants_signal(int sig, struct task_struct *p)
 {
 	if (sigismember(&p->blocked, sig))
-		return 0;
+		return false;
+
 	if (p->flags & PF_EXITING)
-		return 0;
+		return false;
+
 	if (sig == SIGKILL)
-		return 1;
+		return true;
+
 	if (task_is_stopped_or_traced(p))
-		return 0;
+		return false;
+
 	return task_curr(p) || !signal_pending(p);
 }
 

commit 8f11351eee9524c179361fcbf1538c993f2390e4
Author: Christian Brauner <christian@brauner.io>
Date:   Tue Aug 21 22:00:38 2018 -0700

    signal: make flush_sigqueue_mask() void
    
    The return value of flush_sigqueue_mask() is never checked anywhere.
    
    Link: http://lkml.kernel.org/r/20180602103653.18181-14-christian@brauner.io
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: James Morris <james.morris@microsoft.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index c10c09fc4ec3..fe0e9e82ce44 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -687,14 +687,14 @@ void signal_wake_up_state(struct task_struct *t, unsigned int state)
  *
  * All callers must be holding the siglock.
  */
-static int flush_sigqueue_mask(sigset_t *mask, struct sigpending *s)
+static void flush_sigqueue_mask(sigset_t *mask, struct sigpending *s)
 {
 	struct sigqueue *q, *n;
 	sigset_t m;
 
 	sigandsets(&m, mask, &s->signal);
 	if (sigisemptyset(&m))
-		return 0;
+		return;
 
 	sigandnsets(&s->signal, &s->signal, mask);
 	list_for_each_entry_safe(q, n, &s->list, list) {
@@ -703,7 +703,6 @@ static int flush_sigqueue_mask(sigset_t *mask, struct sigpending *s)
 			__sigqueue_free(q);
 		}
 	}
-	return 1;
 }
 
 static inline int is_si_special(const struct siginfo *info)

commit 67a48a24478841525ba73ec6d64caaf079cf3b7c
Author: Christian Brauner <christian@brauner.io>
Date:   Tue Aug 21 22:00:34 2018 -0700

    signal: make unhandled_signal() return bool
    
    unhandled_signal() already behaves like a boolean function.  Let's
    actually declare it as such too.  All callers treat it as such too.
    
    Link: http://lkml.kernel.org/r/20180602103653.18181-13-christian@brauner.io
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: James Morris <james.morris@microsoft.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 7eec2dba597e..c10c09fc4ec3 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -505,13 +505,15 @@ flush_signal_handlers(struct task_struct *t, int force_default)
 	}
 }
 
-int unhandled_signal(struct task_struct *tsk, int sig)
+bool unhandled_signal(struct task_struct *tsk, int sig)
 {
 	void __user *handler = tsk->sighand->action[sig-1].sa.sa_handler;
 	if (is_global_init(tsk))
-		return 1;
+		return true;
+
 	if (handler != SIG_IGN && handler != SIG_DFL)
-		return 0;
+		return false;
+
 	/* if ptraced, let the tracer determine */
 	return !tsk->ptrace;
 }

commit 09ae854edb2d275d98a874c21c24c58cee4df14e
Author: Christian Brauner <christian@brauner.io>
Date:   Tue Aug 21 22:00:30 2018 -0700

    signal: make recalc_sigpending_tsk() return bool
    
    recalc_sigpending_tsk() already behaves like a boolean function.  Let's
    actually declare it as such too.
    
    Link: http://lkml.kernel.org/r/20180602103653.18181-12-christian@brauner.io
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: James Morris <james.morris@microsoft.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index e00e96a7b24f..7eec2dba597e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -138,20 +138,21 @@ static inline bool has_pending_signals(sigset_t *signal, sigset_t *blocked)
 
 #define PENDING(p,b) has_pending_signals(&(p)->signal, (b))
 
-static int recalc_sigpending_tsk(struct task_struct *t)
+static bool recalc_sigpending_tsk(struct task_struct *t)
 {
 	if ((t->jobctl & JOBCTL_PENDING_MASK) ||
 	    PENDING(&t->pending, &t->blocked) ||
 	    PENDING(&t->signal->shared_pending, &t->blocked)) {
 		set_tsk_thread_flag(t, TIF_SIGPENDING);
-		return 1;
+		return true;
 	}
+
 	/*
 	 * We must never clear the flag in another thread, or in current
 	 * when it's possible the current syscall is returning -ERESTART*.
 	 * So we don't clear it here, and only callers who know they should do.
 	 */
-	return 0;
+	return false;
 }
 
 /*

commit 938696a82974c33b93be9657b72521bc84f5c587
Author: Christian Brauner <christian@brauner.io>
Date:   Tue Aug 21 22:00:27 2018 -0700

    signal: make has_pending_signals() return bool
    
    has_pending_signals() already behaves like a boolean function.  Let's
    actually declare it as such too.
    
    Link: http://lkml.kernel.org/r/20180602103653.18181-11-christian@brauner.io
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: James Morris <james.morris@microsoft.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index bcd4272639ca..e00e96a7b24f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -110,7 +110,7 @@ static bool sig_ignored(struct task_struct *t, int sig, bool force)
  * Re-calculate pending state from the set of locally pending
  * signals, globally pending signals, and blocked signals.
  */
-static inline int has_pending_signals(sigset_t *signal, sigset_t *blocked)
+static inline bool has_pending_signals(sigset_t *signal, sigset_t *blocked)
 {
 	unsigned long ready;
 	long i;

commit 6a0cdcd78892d4508e77cbec913eaf099ab4a8e9
Author: Christian Brauner <christian@brauner.io>
Date:   Tue Aug 21 22:00:23 2018 -0700

    signal: make sig_ignored() return bool
    
    sig_ignored() already behaves like a boolean function.  Let's actually
    declare it as such too.
    
    Link: http://lkml.kernel.org/r/20180602103653.18181-10-christian@brauner.io
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: James Morris <james.morris@microsoft.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 6e92adddd667..bcd4272639ca 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -85,7 +85,7 @@ static bool sig_task_ignored(struct task_struct *t, int sig, bool force)
 	return sig_handler_ignored(handler, sig);
 }
 
-static int sig_ignored(struct task_struct *t, int sig, bool force)
+static bool sig_ignored(struct task_struct *t, int sig, bool force)
 {
 	/*
 	 * Blocked signals are never ignored, since the
@@ -93,7 +93,7 @@ static int sig_ignored(struct task_struct *t, int sig, bool force)
 	 * unblocked.
 	 */
 	if (sigismember(&t->blocked, sig) || sigismember(&t->real_blocked, sig))
-		return 0;
+		return false;
 
 	/*
 	 * Tracers may want to know about even ignored signal unless it
@@ -101,7 +101,7 @@ static int sig_ignored(struct task_struct *t, int sig, bool force)
 	 * by SIGNAL_UNKILLABLE task.
 	 */
 	if (t->ptrace && sig != SIGKILL)
-		return 0;
+		return false;
 
 	return sig_task_ignored(t, sig, force);
 }

commit 41aaa481197dc566f691d403e0247bb53a017770
Author: Christian Brauner <christian@brauner.io>
Date:   Tue Aug 21 22:00:19 2018 -0700

    signal: make sig_task_ignored() return bool
    
    sig_task_ignored() already behaves like a boolean function.  Let's
    actually declare it as such too.
    
    Link: http://lkml.kernel.org/r/20180602103653.18181-9-christian@brauner.io
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: James Morris <james.morris@microsoft.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index a032a9bae5fb..6e92adddd667 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -72,7 +72,7 @@ static inline bool sig_handler_ignored(void __user *handler, int sig)
 	       (handler == SIG_DFL && sig_kernel_ignore(sig));
 }
 
-static int sig_task_ignored(struct task_struct *t, int sig, bool force)
+static bool sig_task_ignored(struct task_struct *t, int sig, bool force)
 {
 	void __user *handler;
 
@@ -80,7 +80,7 @@ static int sig_task_ignored(struct task_struct *t, int sig, bool force)
 
 	if (unlikely(t->signal->flags & SIGNAL_UNKILLABLE) &&
 	    handler == SIG_DFL && !(force && sig_kernel_only(sig)))
-		return 1;
+		return true;
 
 	return sig_handler_ignored(handler, sig);
 }

commit e4a8b4efbfdf8ce86b1d410cc96d2790a05f1fd5
Author: Christian Brauner <christian@brauner.io>
Date:   Tue Aug 21 22:00:15 2018 -0700

    signal: make sig_handler_ignored() return bool
    
    sig_handler_ignored() already behaves like a boolean function.  Let's
    actually declare it as such too.
    
    Link: http://lkml.kernel.org/r/20180602103653.18181-8-christian@brauner.io
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: James Morris <james.morris@microsoft.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0e1bb87415c4..a032a9bae5fb 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -65,11 +65,11 @@ static void __user *sig_handler(struct task_struct *t, int sig)
 	return t->sighand->action[sig - 1].sa.sa_handler;
 }
 
-static int sig_handler_ignored(void __user *handler, int sig)
+static inline bool sig_handler_ignored(void __user *handler, int sig)
 {
 	/* Is it explicitly or implicitly ignored? */
 	return handler == SIG_IGN ||
-		(handler == SIG_DFL && sig_kernel_ignore(sig));
+	       (handler == SIG_DFL && sig_kernel_ignore(sig));
 }
 
 static int sig_task_ignored(struct task_struct *t, int sig, bool force)

commit 2a9b90940957d3c0f744011b02b4575323be5947
Author: Christian Brauner <christian@brauner.io>
Date:   Tue Aug 21 22:00:11 2018 -0700

    signal: make kill_ok_by_cred() return bool
    
    kill_ok_by_cred() already behaves like a boolean function.  Let's actually
    declare it as such too.
    
    Link: http://lkml.kernel.org/r/20180602103653.18181-7-christian@brauner.io
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: James Morris <james.morris@microsoft.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index adeee5095039..0e1bb87415c4 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -717,21 +717,16 @@ static inline bool si_fromuser(const struct siginfo *info)
 /*
  * called with RCU read lock from check_kill_permission()
  */
-static int kill_ok_by_cred(struct task_struct *t)
+static bool kill_ok_by_cred(struct task_struct *t)
 {
 	const struct cred *cred = current_cred();
 	const struct cred *tcred = __task_cred(t);
 
-	if (uid_eq(cred->euid, tcred->suid) ||
-	    uid_eq(cred->euid, tcred->uid)  ||
-	    uid_eq(cred->uid,  tcred->suid) ||
-	    uid_eq(cred->uid,  tcred->uid))
-		return 1;
-
-	if (ns_capable(tcred->user_ns, CAP_KILL))
-		return 1;
-
-	return 0;
+	return uid_eq(cred->euid, tcred->suid) ||
+	       uid_eq(cred->euid, tcred->uid) ||
+	       uid_eq(cred->uid, tcred->suid) ||
+	       uid_eq(cred->uid, tcred->uid) ||
+	       ns_capable(tcred->user_ns, CAP_KILL);
 }
 
 /*

commit d8f993b3dba05ff354f9b9592afc44b1b3dbfd46
Author: Christian Brauner <christian@brauner.io>
Date:   Tue Aug 21 22:00:07 2018 -0700

    signal: simplify rt_sigaction()
    
    The goto is not needed and does not add any clarity.  Simply return
    -EINVAL on unexpected sigset_t struct size directly.
    
    Link: http://lkml.kernel.org/r/20180602103653.18181-6-christian@brauner.io
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: James Morris <james.morris@microsoft.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 10918c7b2ee3..adeee5095039 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3648,25 +3648,23 @@ SYSCALL_DEFINE4(rt_sigaction, int, sig,
 		size_t, sigsetsize)
 {
 	struct k_sigaction new_sa, old_sa;
-	int ret = -EINVAL;
+	int ret;
 
 	/* XXX: Don't preclude handling different sized sigset_t's.  */
 	if (sigsetsize != sizeof(sigset_t))
-		goto out;
+		return -EINVAL;
 
-	if (act) {
-		if (copy_from_user(&new_sa.sa, act, sizeof(new_sa.sa)))
-			return -EFAULT;
-	}
+	if (act && copy_from_user(&new_sa.sa, act, sizeof(new_sa.sa)))
+		return -EFAULT;
 
 	ret = do_sigaction(sig, act ? &new_sa : NULL, oact ? &old_sa : NULL);
+	if (ret)
+		return ret;
 
-	if (!ret && oact) {
-		if (copy_to_user(oact, &old_sa.sa, sizeof(old_sa.sa)))
-			return -EFAULT;
-	}
-out:
-	return ret;
+	if (oact && copy_to_user(oact, &old_sa.sa, sizeof(old_sa.sa)))
+		return -EFAULT;
+
+	return 0;
 }
 #ifdef CONFIG_COMPAT
 COMPAT_SYSCALL_DEFINE4(rt_sigaction, int, sig,

commit b1d294c80393e7ba18b3c646fe9d8e6a206c7988
Author: Christian Brauner <christian@brauner.io>
Date:   Tue Aug 21 22:00:02 2018 -0700

    signal: make do_sigpending() void
    
    do_sigpending() returned 0 unconditionally so it doesn't make sense to
    have it return at all.  This allows us to simplify a bunch of syscall
    callers.
    
    Link: http://lkml.kernel.org/r/20180602103653.18181-5-christian@brauner.io
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Acked-by: Al Viro <viro@zeniv.linux.org.uk>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: James Morris <james.morris@microsoft.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index f03886cd064e..10918c7b2ee3 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2753,7 +2753,7 @@ COMPAT_SYSCALL_DEFINE4(rt_sigprocmask, int, how, compat_sigset_t __user *, nset,
 }
 #endif
 
-static int do_sigpending(sigset_t *set)
+static void do_sigpending(sigset_t *set)
 {
 	spin_lock_irq(&current->sighand->siglock);
 	sigorsets(set, &current->pending.signal,
@@ -2762,7 +2762,6 @@ static int do_sigpending(sigset_t *set)
 
 	/* Outside the lock because only this thread touches it.  */
 	sigandsets(set, &current->blocked, set);
-	return 0;
 }
 
 /**
@@ -2774,15 +2773,16 @@ static int do_sigpending(sigset_t *set)
 SYSCALL_DEFINE2(rt_sigpending, sigset_t __user *, uset, size_t, sigsetsize)
 {
 	sigset_t set;
-	int err;
 
 	if (sigsetsize > sizeof(*uset))
 		return -EINVAL;
 
-	err = do_sigpending(&set);
-	if (!err && copy_to_user(uset, &set, sigsetsize))
-		err = -EFAULT;
-	return err;
+	do_sigpending(&set);
+
+	if (copy_to_user(uset, &set, sigsetsize))
+		return -EFAULT;
+
+	return 0;
 }
 
 #ifdef CONFIG_COMPAT
@@ -2790,15 +2790,13 @@ COMPAT_SYSCALL_DEFINE2(rt_sigpending, compat_sigset_t __user *, uset,
 		compat_size_t, sigsetsize)
 {
 	sigset_t set;
-	int err;
 
 	if (sigsetsize > sizeof(*uset))
 		return -EINVAL;
 
-	err = do_sigpending(&set);
-	if (!err)
-		err = put_compat_sigset(uset, &set, sigsetsize);
-	return err;
+	do_sigpending(&set);
+
+	return put_compat_sigset(uset, &set, sigsetsize);
 }
 #endif
 
@@ -3560,25 +3558,26 @@ int __compat_save_altstack(compat_stack_t __user *uss, unsigned long sp)
 SYSCALL_DEFINE1(sigpending, old_sigset_t __user *, uset)
 {
 	sigset_t set;
-	int err;
 
 	if (sizeof(old_sigset_t) > sizeof(*uset))
 		return -EINVAL;
 
-	err = do_sigpending(&set);
-	if (!err && copy_to_user(uset, &set, sizeof(old_sigset_t)))
-		err = -EFAULT;
-	return err;
+	do_sigpending(&set);
+
+	if (copy_to_user(uset, &set, sizeof(old_sigset_t)))
+		return -EFAULT;
+
+	return 0;
 }
 
 #ifdef CONFIG_COMPAT
 COMPAT_SYSCALL_DEFINE1(sigpending, compat_old_sigset_t __user *, set32)
 {
 	sigset_t set;
-	int err = do_sigpending(&set);
-	if (!err)
-		err = put_user(set.sig[0], set32);
-	return err;
+
+	do_sigpending(&set);
+
+	return put_user(set.sig[0], set32);
 }
 #endif
 

commit 6527de953354e550bf6d941fdcd1aaf832317e8d
Author: Christian Brauner <christian@brauner.io>
Date:   Tue Aug 21 21:59:59 2018 -0700

    signal: make may_ptrace_stop() return bool
    
    may_ptrace_stop() already behaves like a boolean function.  Let's actually
    declare it as such too.
    
    Link: http://lkml.kernel.org/r/20180602103653.18181-4-christian@brauner.io
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: James Morris <james.morris@microsoft.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5b0fb57b23f0..f03886cd064e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1875,10 +1875,10 @@ static void do_notify_parent_cldstop(struct task_struct *tsk,
 	spin_unlock_irqrestore(&sighand->siglock, flags);
 }
 
-static inline int may_ptrace_stop(void)
+static inline bool may_ptrace_stop(void)
 {
 	if (!likely(current->ptrace))
-		return 0;
+		return false;
 	/*
 	 * Are we in the middle of do_coredump?
 	 * If so and our tracer is also part of the coredump stopping
@@ -1894,9 +1894,9 @@ static inline int may_ptrace_stop(void)
 	 */
 	if (unlikely(current->mm->core_state) &&
 	    unlikely(current->mm == current->parent->mm))
-		return 0;
+		return false;
 
-	return 1;
+	return true;
 }
 
 /*

commit bb17fcca078fc56ea7c7611cbe92687021cf6a31
Author: Christian Brauner <christian@brauner.io>
Date:   Tue Aug 21 21:59:55 2018 -0700

    signal: make kill_as_cred_perm() return bool
    
    kill_as_cred_perm() already behaves like a boolean function.  Let's
    actually declare it as such too.
    
    Link: http://lkml.kernel.org/r/20180602103653.18181-3-christian@brauner.io
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: James Morris <james.morris@microsoft.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8a828baa0f93..5b0fb57b23f0 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1339,14 +1339,15 @@ static int kill_proc_info(int sig, struct siginfo *info, pid_t pid)
 	return error;
 }
 
-static int kill_as_cred_perm(const struct cred *cred,
-			     struct task_struct *target)
+static inline bool kill_as_cred_perm(const struct cred *cred,
+				     struct task_struct *target)
 {
 	const struct cred *pcred = __task_cred(target);
-	if (!uid_eq(cred->euid, pcred->suid) && !uid_eq(cred->euid, pcred->uid) &&
-	    !uid_eq(cred->uid,  pcred->suid) && !uid_eq(cred->uid,  pcred->uid))
-		return 0;
-	return 1;
+
+	return uid_eq(cred->euid, pcred->suid) ||
+	       uid_eq(cred->euid, pcred->uid) ||
+	       uid_eq(cred->uid, pcred->suid) ||
+	       uid_eq(cred->uid, pcred->uid);
 }
 
 /* like kill_pid_info(), but doesn't use uid/euid of "current" */

commit 52cba1a274818c3ee6299c1a1b476e7bc5037a2f
Author: Christian Brauner <christian@brauner.io>
Date:   Tue Aug 21 21:59:51 2018 -0700

    signal: make force_sigsegv() void
    
    Patch series "signal: refactor some functions", v3.
    
    This series refactors a bunch of functions in signal.c to simplify parts
    of the code.
    
    The greatest single change is declaring the static do_sigpending() helper
    as void which makes it possible to remove a bunch of unnecessary checks in
    the syscalls later on.
    
    This patch (of 17):
    
    force_sigsegv() returned 0 unconditionally so it doesn't make sense to have
    it return at all. In addition, there are no callers that check
    force_sigsegv()'s return value.
    
    Link: http://lkml.kernel.org/r/20180602103653.18181-2-christian@brauner.io
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: James Morris <james.morris@microsoft.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8d8a940422a8..8a828baa0f93 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1458,8 +1458,7 @@ send_sig(int sig, struct task_struct *p, int priv)
 	return send_sig_info(sig, __si_special(priv), p);
 }
 
-void
-force_sig(int sig, struct task_struct *p)
+void force_sig(int sig, struct task_struct *p)
 {
 	force_sig_info(sig, SEND_SIG_PRIV, p);
 }
@@ -1470,8 +1469,7 @@ force_sig(int sig, struct task_struct *p)
  * the problem was already a SIGSEGV, we'll want to
  * make sure we don't even try to deliver the signal..
  */
-int
-force_sigsegv(int sig, struct task_struct *p)
+void force_sigsegv(int sig, struct task_struct *p)
 {
 	if (sig == SIGSEGV) {
 		unsigned long flags;
@@ -1480,7 +1478,6 @@ force_sigsegv(int sig, struct task_struct *p)
 		spin_unlock_irqrestore(&p->sighand->siglock, flags);
 	}
 	force_sig(SIGSEGV, p);
-	return 0;
 }
 
 int force_sig_fault(int sig, int code, void __user *addr

commit c3ad2c3b02e953ead2b8d52a0c9e70312930c3d0
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Jul 23 15:20:37 2018 -0500

    signal: Don't restart fork when signals come in.
    
    Wen Yang <wen.yang99@zte.com.cn> and majiang <ma.jiang@zte.com.cn>
    report that a periodic signal received during fork can cause fork to
    continually restart preventing an application from making progress.
    
    The code was being overly pessimistic.  Fork needs to guarantee that a
    signal sent to multiple processes is logically delivered before the
    fork and just to the forking process or logically delivered after the
    fork to both the forking process and it's newly spawned child.  For
    signals like periodic timers that are always delivered to a single
    process fork can safely complete and let them appear to logically
    delivered after the fork().
    
    While examining this issue I also discovered that fork today will miss
    signals delivered to multiple processes during the fork and handled by
    another thread.  Similarly the current code will also miss blocked
    signals that are delivered to multiple process, as those signals will
    not appear pending during fork.
    
    Add a list of each thread that is currently forking, and keep on that
    list a signal set that records all of the signals sent to multiple
    processes.  When fork completes initialize the new processes
    shared_pending signal set with it.  The calculate_sigpending function
    will see those signals and set TIF_SIGPENDING causing the new task to
    take the slow path to userspace to handle those signals.  Making it
    appear as if those signals were received immediately after the fork.
    
    It is not possible to send real time signals to multiple processes and
    exceptions don't go to multiple processes, which means that that are
    no signals sent to multiple processes that require siginfo.  This
    means it is safe to not bother collecting siginfo on signals sent
    during fork.
    
    The sigaction of a child of fork is initially the same as the
    sigaction of the parent process.  So a signal the parent ignores the
    child will also initially ignore.  Therefore it is safe to ignore
    signals sent to multiple processes and ignored by the forking process.
    
    Signals sent to only a single process or only a single thread and delivered
    during fork are treated as if they are received after the fork, and generally
    not dealt with.  They won't cause any problems.
    
    V2: Added removal from the multiprocess list on failure.
    V3: Use -ERESTARTNOINTR directly
    V4: - Don't queue both SIGCONT and SIGSTOP
        - Initialize signal_struct.multiprocess in init_task
        - Move setting of shared_pending to before the new task
          is visible to signals.  This prevents signals from comming
          in before shared_pending.signal is set to delayed.signal
          and being lost.
    V5: - rework list add and delete to account for idle threads
    v6: - Use sigdelsetmask when removing stop signals
    
    Bugzilla: https://bugzilla.kernel.org/show_bug.cgi?id=200447
    Reported-by: Wen Yang <wen.yang99@zte.com.cn> and
    Reported-by: majiang <ma.jiang@zte.com.cn>
    Fixes: 4a2c7a7837da ("[PATCH] make fork() atomic wrt pgrp/session signals")
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9f0eafb6d474..cfa9d10e731a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1121,6 +1121,21 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 out_set:
 	signalfd_notify(t, sig);
 	sigaddset(&pending->signal, sig);
+
+	/* Let multiprocess signals appear after on-going forks */
+	if (type > PIDTYPE_TGID) {
+		struct multiprocess_signals *delayed;
+		hlist_for_each_entry(delayed, &t->signal->multiprocess, node) {
+			sigset_t *signal = &delayed->signal;
+			/* Can't queue both a stop and a continue signal */
+			if (sig == SIGCONT)
+				sigdelsetmask(signal, SIG_KERNEL_STOP_MASK);
+			else if (sig_kernel_stop(sig))
+				sigdelset(signal, SIGCONT);
+			sigaddset(signal, sig);
+		}
+	}
+
 	complete_signal(sig, t, type);
 ret:
 	trace_signal_generate(sig, info, t, type != PIDTYPE_PID, result);

commit 924de3b8c9410c404c6eda7abffd282b97b3ff7f
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Jul 23 13:38:00 2018 -0500

    fork: Have new threads join on-going signal group stops
    
    There are only two signals that are delivered to every member of a
    signal group: SIGSTOP and SIGKILL.  Signal delivery requires every
    signal appear to be delivered either before or after a clone syscall.
    SIGKILL terminates the clone so does not need to be considered.  Which
    leaves only SIGSTOP that needs to be considered when creating new
    threads.
    
    Today in the event of a group stop TIF_SIGPENDING will get set and the
    fork will restart ensuring the fork syscall participates in the group
    stop.
    
    A fork (especially of a process with a lot of memory) is one of the
    most expensive system so we really only want to restart a fork when
    necessary.
    
    It is easy so check to see if a SIGSTOP is ongoing and have the new
    thread join it immediate after the clone completes.  Making it appear
    the clone completed happened just before the SIGSTOP.
    
    The calculate_sigpending function will see the bits set in jobctl and
    set TIF_SIGPENDING to ensure the new task takes the slow path to userspace.
    
    V2: The call to task_join_group_stop was moved before the new task is
        added to the thread group list.  This should not matter as
        sighand->siglock is held over both the addition of the threads,
        the call to task_join_group_stop and do_signal_stop.  But the change
        is trivial and it is one less thing to worry about when reading
        the code.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1e06f1eba363..9f0eafb6d474 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -373,6 +373,20 @@ static bool task_participate_group_stop(struct task_struct *task)
 	return false;
 }
 
+void task_join_group_stop(struct task_struct *task)
+{
+	/* Have the new thread join an on-going signal group stop */
+	unsigned long jobctl = current->jobctl;
+	if (jobctl & JOBCTL_STOP_PENDING) {
+		struct signal_struct *sig = current->signal;
+		unsigned long signr = jobctl & JOBCTL_STOP_SIGMASK;
+		unsigned long gstop = JOBCTL_STOP_PENDING | JOBCTL_STOP_CONSUME;
+		if (task_set_jobctl_pending(task, signr | gstop)) {
+			sig->group_stop_count++;
+		}
+	}
+}
+
 /*
  * allocate a new signal queue record
  * - this may be called without locks if and only if t == current, otherwise an

commit 088fe47ce952542389e604e83f533811750aaf7c
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Jul 23 17:26:49 2018 -0500

    signal: Add calculate_sigpending()
    
    Add a function calculate_sigpending to test to see if any signals are
    pending for a new task immediately following fork.  Signals have to
    happen either before or after fork.  Today our practice is to push
    all of the signals to before the fork, but that has the downside that
    frequent or periodic signals can make fork take much much longer than
    normal or prevent fork from completing entirely.
    
    So we need move signals that we can after the fork to prevent that.
    
    This updates the code to set TIF_SIGPENDING on a new task if there
    are signals or other activities that have moved so that they appear
    to happen after the fork.
    
    As the code today restarts if it sees any such activity this won't
    immediately have an effect, as there will be no reason for it
    to set TIF_SIGPENDING immediately after the fork.
    
    Adding calculate_sigpending means the code in fork can safely be
    changed to not always restart if a signal is pending.
    
    The new calculate_sigpending function sets sigpending if there
    are pending bits in jobctl, pending signals, the freezer needs
    to freeze the new task or the live kernel patching framework
    need the new thread to take the slow path to userspace.
    
    I have verified that setting TIF_SIGPENDING does make a new process
    take the slow path to userspace before it executes it's first userspace
    instruction.
    
    I have looked at the callers of signal_wake_up and the code paths
    setting TIF_SIGPENDING and I don't see anything else that needs to be
    handled.  The code probably doesn't need to set TIF_SIGPENDING for the
    kernel live patching as it uses a separate thread flag as well.  But
    at this point it seems safer reuse the recalc_sigpending logic and get
    the kernel live patching folks to sort out their story later.
    
    V2: I have moved the test into schedule_tail where siglock can
        be grabbed and recalc_sigpending can be reused directly.
        Further as the last action of setting up a new task this
        guarantees that TIF_SIGPENDING will be properly set in the
        new process.
    
        The helper calculate_sigpending takes the siglock and
        uncontitionally sets TIF_SIGPENDING and let's recalc_sigpending
        clear TIF_SIGPENDING if it is unnecessary.  This allows reusing
        the existing code and keeps maintenance of the conditions simple.
    
        Oleg Nesterov <oleg@redhat.com>  suggested the movement
        and pointed out the need to take siglock if this code
        was going to be called while the new task is discoverable.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index dddbea558455..1e06f1eba363 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -172,6 +172,17 @@ void recalc_sigpending(void)
 
 }
 
+void calculate_sigpending(void)
+{
+	/* Have any signals or users of TIF_SIGPENDING been delayed
+	 * until after fork?
+	 */
+	spin_lock_irq(&current->sighand->siglock);
+	set_tsk_thread_flag(current, TIF_SIGPENDING);
+	recalc_sigpending();
+	spin_unlock_irq(&current->sighand->siglock);
+}
+
 /* Given the mask, find the first available signal that should be serviced. */
 
 #define SYNCHRONOUS_MASK \

commit 0729614992c946f6e8ccb9ef260aea1f06993df0
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Jul 13 21:39:13 2018 -0500

    signal: Push pid type down into complete_signal.
    
    This is the bottom and by pushing this down it simplifies the callers
    and otherwise leaves things as is.  This is in preparation for allowing
    fork to implement better handling of signals set to groups of processes.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1ef94303d87a..dddbea558455 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -895,7 +895,7 @@ static inline int wants_signal(int sig, struct task_struct *p)
 	return task_curr(p) || !signal_pending(p);
 }
 
-static void complete_signal(int sig, struct task_struct *p, int group)
+static void complete_signal(int sig, struct task_struct *p, enum pid_type type)
 {
 	struct signal_struct *signal = p->signal;
 	struct task_struct *t;
@@ -908,7 +908,7 @@ static void complete_signal(int sig, struct task_struct *p, int group)
 	 */
 	if (wants_signal(sig, p))
 		t = p;
-	else if (!group || thread_group_empty(p))
+	else if ((type == PIDTYPE_PID) || thread_group_empty(p))
 		/*
 		 * There is just one thread and it does not need to be woken.
 		 * It will dequeue unblocked signals before it runs again.
@@ -1096,7 +1096,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 out_set:
 	signalfd_notify(t, sig);
 	sigaddset(&pending->signal, sig);
-	complete_signal(sig, t, type != PIDTYPE_PID);
+	complete_signal(sig, t, type);
 ret:
 	trace_signal_generate(sig, info, t, type != PIDTYPE_PID, result);
 	return ret;
@@ -1704,7 +1704,7 @@ int send_sigqueue(struct sigqueue *q, struct pid *pid, enum pid_type type)
 	pending = (type != PIDTYPE_PID) ? &t->signal->shared_pending : &t->pending;
 	list_add_tail(&q->list, &pending->list);
 	sigaddset(&pending->signal, sig);
-	complete_signal(sig, t, type != PIDTYPE_PID);
+	complete_signal(sig, t, type);
 	result = TRACE_SIGNAL_DELIVERED;
 out:
 	trace_signal_generate(sig, &q->info, t, type != PIDTYPE_PID, result);

commit 5a883cee7442a5fd72e18eae895113fbd7b16110
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Jul 13 19:26:27 2018 -0500

    signal: Push pid type down into __send_signal
    
    This information is already available in the callers and by pushing it
    down it makes the code a little clearer, and allows implementing
    better handling of signales set to a group of processes in fork.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8decc70c1dc2..1ef94303d87a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -998,7 +998,7 @@ static inline void userns_fixup_signal_uid(struct siginfo *info, struct task_str
 #endif
 
 static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
-			int group, int from_ancestor_ns)
+			enum pid_type type, int from_ancestor_ns)
 {
 	struct sigpending *pending;
 	struct sigqueue *q;
@@ -1012,7 +1012,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			from_ancestor_ns || (info == SEND_SIG_FORCED)))
 		goto ret;
 
-	pending = group ? &t->signal->shared_pending : &t->pending;
+	pending = (type != PIDTYPE_PID) ? &t->signal->shared_pending : &t->pending;
 	/*
 	 * Short-circuit ignored signals and support queuing
 	 * exactly one non-rt signal, so that we can get more
@@ -1096,9 +1096,9 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 out_set:
 	signalfd_notify(t, sig);
 	sigaddset(&pending->signal, sig);
-	complete_signal(sig, t, group);
+	complete_signal(sig, t, type != PIDTYPE_PID);
 ret:
-	trace_signal_generate(sig, info, t, group, result);
+	trace_signal_generate(sig, info, t, type != PIDTYPE_PID, result);
 	return ret;
 }
 
@@ -1112,7 +1112,7 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			   !task_pid_nr_ns(current, task_active_pid_ns(t));
 #endif
 
-	return __send_signal(sig, info, t, type != PIDTYPE_PID, from_ancestor_ns);
+	return __send_signal(sig, info, t, type, from_ancestor_ns);
 }
 
 static void print_fatal_signal(int signr)
@@ -1377,7 +1377,7 @@ int kill_pid_info_as_cred(int sig, struct siginfo *info, struct pid *pid,
 
 	if (sig) {
 		if (lock_task_sighand(p, &flags)) {
-			ret = __send_signal(sig, info, p, 1, 0);
+			ret = __send_signal(sig, info, p, PIDTYPE_TGID, 0);
 			unlock_task_sighand(p, &flags);
 		} else
 			ret = -ESRCH;

commit b213984bd3987e6f5bf96b7847d151b7b42e1efd
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Jul 20 15:49:17 2018 -0500

    signal: Push pid type down into send_signal
    
    This information is already available in the callers and by pushing it
    down it makes the code a little clearer, and allows better group
    signal behavior in fork.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2c09e6143dd8..8decc70c1dc2 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1103,7 +1103,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 }
 
 static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
-			int group)
+			enum pid_type type)
 {
 	int from_ancestor_ns = 0;
 
@@ -1112,7 +1112,7 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			   !task_pid_nr_ns(current, task_active_pid_ns(t));
 #endif
 
-	return __send_signal(sig, info, t, group, from_ancestor_ns);
+	return __send_signal(sig, info, t, type != PIDTYPE_PID, from_ancestor_ns);
 }
 
 static void print_fatal_signal(int signr)
@@ -1151,13 +1151,13 @@ __setup("print-fatal-signals=", setup_print_fatal_signals);
 int
 __group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 {
-	return send_signal(sig, info, p, 1);
+	return send_signal(sig, info, p, PIDTYPE_TGID);
 }
 
 static int
 specific_send_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 {
-	return send_signal(sig, info, t, 0);
+	return send_signal(sig, info, t, PIDTYPE_PID);
 }
 
 int do_send_sig_info(int sig, struct siginfo *info, struct task_struct *p,
@@ -1167,7 +1167,7 @@ int do_send_sig_info(int sig, struct siginfo *info, struct task_struct *p,
 	int ret = -ESRCH;
 
 	if (lock_task_sighand(p, &flags)) {
-		ret = send_signal(sig, info, p, type != PIDTYPE_PID);
+		ret = send_signal(sig, info, p, type);
 		unlock_task_sighand(p, &flags);
 	}
 
@@ -3966,7 +3966,7 @@ void kdb_send_sig(struct task_struct *t, int sig)
 			   "the deadlock.\n");
 		return;
 	}
-	ret = send_signal(sig, SEND_SIG_PRIV, t, false);
+	ret = send_signal(sig, SEND_SIG_PRIV, t, PIDTYPE_PID);
 	spin_unlock(&t->sighand->siglock);
 	if (ret)
 		kdb_printf("Fail to deliver Signal %d to process %d.\n",

commit 40b3b02535621027f56d248139e0e467573c3098
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Jul 21 10:45:15 2018 -0500

    signal: Pass pid type into do_send_sig_info
    
    This passes the information we already have at the call sight into
    do_send_sig_info.  Ultimately allowing for better handling of signals
    sent to a group of processes during fork.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index c7527338fe9d..2c09e6143dd8 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1161,13 +1161,13 @@ specific_send_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 }
 
 int do_send_sig_info(int sig, struct siginfo *info, struct task_struct *p,
-			bool group)
+			enum pid_type type)
 {
 	unsigned long flags;
 	int ret = -ESRCH;
 
 	if (lock_task_sighand(p, &flags)) {
-		ret = send_signal(sig, info, p, group);
+		ret = send_signal(sig, info, p, type != PIDTYPE_PID);
 		unlock_task_sighand(p, &flags);
 	}
 
@@ -1284,7 +1284,7 @@ int group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p,
 	rcu_read_unlock();
 
 	if (!ret && sig)
-		ret = do_send_sig_info(sig, info, p, true);
+		ret = do_send_sig_info(sig, info, p, type);
 
 	return ret;
 }
@@ -1448,7 +1448,7 @@ int send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 	if (!valid_signal(sig))
 		return -EINVAL;
 
-	return do_send_sig_info(sig, info, p, false);
+	return do_send_sig_info(sig, info, p, PIDTYPE_PID);
 }
 
 #define __si_special(priv) \
@@ -3199,7 +3199,7 @@ do_send_specific(pid_t tgid, pid_t pid, int sig, struct siginfo *info)
 		 * probe.  No signal is actually delivered.
 		 */
 		if (!error && sig) {
-			error = do_send_sig_info(sig, info, p, false);
+			error = do_send_sig_info(sig, info, p, PIDTYPE_PID);
 			/*
 			 * If lock_task_sighand() failed we pretend the task
 			 * dies after receiving the signal. The window is tiny,

commit 0102498083d58d8b17759642c602b525215e1a54
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Jul 13 18:40:57 2018 -0500

    signal: Pass pid type into group_send_sig_info
    
    This passes the information we already have at the call sight
    into group_send_sig_info.  Ultimatelly allowing for to better handle
    signals sent to a group of processes.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 40feb14e276d..c7527338fe9d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1274,7 +1274,8 @@ struct sighand_struct *__lock_task_sighand(struct task_struct *tsk,
 /*
  * send signal info to all the members of a group
  */
-int group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
+int group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p,
+			enum pid_type type)
 {
 	int ret;
 
@@ -1301,7 +1302,7 @@ int __kill_pgrp_info(int sig, struct siginfo *info, struct pid *pgrp)
 	success = 0;
 	retval = -ESRCH;
 	do_each_pid_task(pgrp, PIDTYPE_PGID, p) {
-		int err = group_send_sig_info(sig, info, p);
+		int err = group_send_sig_info(sig, info, p, PIDTYPE_PGID);
 		success |= !err;
 		retval = err;
 	} while_each_pid_task(pgrp, PIDTYPE_PGID, p);
@@ -1317,7 +1318,7 @@ int kill_pid_info(int sig, struct siginfo *info, struct pid *pid)
 		rcu_read_lock();
 		p = pid_task(pid, PIDTYPE_PID);
 		if (p)
-			error = group_send_sig_info(sig, info, p);
+			error = group_send_sig_info(sig, info, p, PIDTYPE_TGID);
 		rcu_read_unlock();
 		if (likely(!p || error != -ESRCH))
 			return error;
@@ -1420,7 +1421,8 @@ static int kill_something_info(int sig, struct siginfo *info, pid_t pid)
 		for_each_process(p) {
 			if (task_pid_vnr(p) > 1 &&
 					!same_thread_group(p, current)) {
-				int err = group_send_sig_info(sig, info, p);
+				int err = group_send_sig_info(sig, info, p,
+							      PIDTYPE_MAX);
 				++count;
 				if (err != -EPERM)
 					retval = err;

commit 24122c7f4969adeeaeca3fb1656a31569e9aa59b
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Jul 20 14:30:23 2018 -0500

    signal: Pass pid and pid type into send_sigqueue
    
    Make the code more maintainable by performing more of the signal
    related work in send_sigqueue.
    
    A quick inspection of do_timer_create will show that this code path
    does not lookup a thread group by a thread's pid.  Making it safe
    to find the task pointed to by it_pid with "pid_task(it_pid, type)";
    
    This supports the changes needed in fork to tell if a signal was sent
    to a single process or a group of processes.
    
    Having the pid to task transition in signal.c will also make it easier
    to sort out races with de_thread and and the thread group leader
    exiting when it comes time to address that.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8d8a940422a8..40feb14e276d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1664,17 +1664,20 @@ void sigqueue_free(struct sigqueue *q)
 		__sigqueue_free(q);
 }
 
-int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)
+int send_sigqueue(struct sigqueue *q, struct pid *pid, enum pid_type type)
 {
 	int sig = q->info.si_signo;
 	struct sigpending *pending;
+	struct task_struct *t;
 	unsigned long flags;
 	int ret, result;
 
 	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
 
 	ret = -1;
-	if (!likely(lock_task_sighand(t, &flags)))
+	rcu_read_lock();
+	t = pid_task(pid, type);
+	if (!t || !likely(lock_task_sighand(t, &flags)))
 		goto ret;
 
 	ret = 1; /* the signal is ignored */
@@ -1696,15 +1699,16 @@ int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)
 	q->info.si_overrun = 0;
 
 	signalfd_notify(t, sig);
-	pending = group ? &t->signal->shared_pending : &t->pending;
+	pending = (type != PIDTYPE_PID) ? &t->signal->shared_pending : &t->pending;
 	list_add_tail(&q->list, &pending->list);
 	sigaddset(&pending->signal, sig);
-	complete_signal(sig, t, group);
+	complete_signal(sig, t, type != PIDTYPE_PID);
 	result = TRACE_SIGNAL_DELIVERED;
 out:
-	trace_signal_generate(sig, &q->info, t, group, result);
+	trace_signal_generate(sig, &q->info, t, type != PIDTYPE_PID, result);
 	unlock_task_sighand(t, &flags);
 ret:
+	rcu_read_unlock();
 	return ret;
 }
 

commit 59dc6f3c6d81c0c4379025c4eb56919391d62b67
Author: Anna-Maria Gleixner <anna-maria@linutronix.de>
Date:   Fri May 25 11:05:07 2018 +0200

    signal: Remove no longer required irqsave/restore
    
    Commit a841796f11c9 ("signal: align __lock_task_sighand() irq disabling and
    RCU") introduced a rcu read side critical section with interrupts
    disabled. The changelog suggested that a better long-term fix would be "to
    make rt_mutex_unlock() disable irqs when acquiring the rt_mutex structure's
    ->wait_lock".
    
    This long-term fix has been made in commit b4abf91047cf ("rtmutex: Make
    wait_lock irq safe") for a different reason.
    
    Therefore revert commit a841796f11c9 ("signal: align >
    __lock_task_sighand() irq disabling and RCU") as the interrupt disable
    dance is not longer required.
    
    The change was tested on the base of b4abf91047cf ("rtmutex: Make wait_lock
    irq safe") with a four hour run of rcutorture scenario TREE03 with lockdep
    enabled as suggested by Paul McKenney.
    
    Signed-off-by: Anna-Maria Gleixner <anna-maria@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: bigeasy@linutronix.de
    Link: https://lkml.kernel.org/r/20180525090507.22248-3-anna-maria@linutronix.de

diff --git a/kernel/signal.c b/kernel/signal.c
index 0f865d67415d..8d8a940422a8 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1244,19 +1244,12 @@ struct sighand_struct *__lock_task_sighand(struct task_struct *tsk,
 {
 	struct sighand_struct *sighand;
 
+	rcu_read_lock();
 	for (;;) {
-		/*
-		 * Disable interrupts early to avoid deadlocks.
-		 * See rcu_read_unlock() comment header for details.
-		 */
-		local_irq_save(*flags);
-		rcu_read_lock();
 		sighand = rcu_dereference(tsk->sighand);
-		if (unlikely(sighand == NULL)) {
-			rcu_read_unlock();
-			local_irq_restore(*flags);
+		if (unlikely(sighand == NULL))
 			break;
-		}
+
 		/*
 		 * This sighand can be already freed and even reused, but
 		 * we rely on SLAB_TYPESAFE_BY_RCU and sighand_ctor() which
@@ -1268,15 +1261,12 @@ struct sighand_struct *__lock_task_sighand(struct task_struct *tsk,
 		 * __exit_signal(). In the latter case the next iteration
 		 * must see ->sighand == NULL.
 		 */
-		spin_lock(&sighand->siglock);
-		if (likely(sighand == tsk->sighand)) {
-			rcu_read_unlock();
+		spin_lock_irqsave(&sighand->siglock, *flags);
+		if (likely(sighand == tsk->sighand))
 			break;
-		}
-		spin_unlock(&sighand->siglock);
-		rcu_read_unlock();
-		local_irq_restore(*flags);
+		spin_unlock_irqrestore(&sighand->siglock, *flags);
 	}
+	rcu_read_unlock();
 
 	return sighand;
 }

commit 93e95fa57441b6976b39029bd658b6bbe7ccfe28
Merge: d8aed8415b86 26da35010c6d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jun 4 15:23:48 2018 -0700

    Merge branch 'siginfo-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull siginfo updates from Eric Biederman:
     "This set of changes close the known issues with setting si_code to an
      invalid value, and with not fully initializing struct siginfo. There
      remains work to do on nds32, arc, unicore32, powerpc, arm, arm64, ia64
      and x86 to get the code that generates siginfo into a simpler and more
      maintainable state. Most of that work involves refactoring the signal
      handling code and thus careful code review.
    
      Also not included is the work to shrink the in kernel version of
      struct siginfo. That depends on getting the number of places that
      directly manipulate struct siginfo under control, as it requires the
      introduction of struct kernel_siginfo for the in kernel things.
    
      Overall this set of changes looks like it is making good progress, and
      with a little luck I will be wrapping up the siginfo work next
      development cycle"
    
    * 'siginfo-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (46 commits)
      signal/sh: Stop gcc warning about an impossible case in do_divide_error
      signal/mips: Report FPE_FLTUNK for undiagnosed floating point exceptions
      signal/um: More carefully relay signals in relay_signal.
      signal: Extend siginfo_layout with SIL_FAULT_{MCEERR|BNDERR|PKUERR}
      signal: Remove unncessary #ifdef SEGV_PKUERR in 32bit compat code
      signal/signalfd: Add support for SIGSYS
      signal/signalfd: Remove __put_user from signalfd_copyinfo
      signal/xtensa: Use force_sig_fault where appropriate
      signal/xtensa: Consistenly use SIGBUS in do_unaligned_user
      signal/um: Use force_sig_fault where appropriate
      signal/sparc: Use force_sig_fault where appropriate
      signal/sparc: Use send_sig_fault where appropriate
      signal/sh: Use force_sig_fault where appropriate
      signal/s390: Use force_sig_fault where appropriate
      signal/riscv: Replace do_trap_siginfo with force_sig_fault
      signal/riscv: Use force_sig_fault where appropriate
      signal/parisc: Use force_sig_fault where appropriate
      signal/parisc: Use force_sig_mceerr where appropriate
      signal/openrisc: Use force_sig_fault where appropriate
      signal/nios2: Use force_sig_fault where appropriate
      ...

commit b5bf9a90bbebffba888c9144c5a8a10317b04064
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Apr 30 14:51:01 2018 +0200

    sched/core: Introduce set_special_state()
    
    Gaurav reported a perceived problem with TASK_PARKED, which turned out
    to be a broken wait-loop pattern in __kthread_parkme(), but the
    reported issue can (and does) in fact happen for states that do not do
    condition based sleeps.
    
    When the 'current->state = TASK_RUNNING' store of a previous
    (concurrent) try_to_wake_up() collides with the setting of a 'special'
    sleep state, we can loose the sleep state.
    
    Normal condition based wait-loops are immune to this problem, but for
    sleep states that are not condition based are subject to this problem.
    
    There already is a fix for TASK_DEAD. Abstract that and also apply it
    to TASK_STOPPED and TASK_TRACED, both of which are also without
    condition based wait-loop.
    
    Reported-by: Gaurav Kohli <gkohli@codeaurora.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index d4ccea599692..9c33163a6165 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1961,14 +1961,27 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 			return;
 	}
 
+	set_special_state(TASK_TRACED);
+
 	/*
 	 * We're committing to trapping.  TRACED should be visible before
 	 * TRAPPING is cleared; otherwise, the tracer might fail do_wait().
 	 * Also, transition to TRACED and updates to ->jobctl should be
 	 * atomic with respect to siglock and should be done after the arch
 	 * hook as siglock is released and regrabbed across it.
+	 *
+	 *     TRACER				    TRACEE
+	 *
+	 *     ptrace_attach()
+	 * [L]   wait_on_bit(JOBCTL_TRAPPING)	[S] set_special_state(TRACED)
+	 *     do_wait()
+	 *       set_current_state()                smp_wmb();
+	 *       ptrace_do_wait()
+	 *         wait_task_stopped()
+	 *           task_stopped_code()
+	 * [L]         task_is_traced()		[S] task_clear_jobctl_trapping();
 	 */
-	set_current_state(TASK_TRACED);
+	smp_wmb();
 
 	current->last_siginfo = info;
 	current->exit_code = exit_code;
@@ -2176,7 +2189,7 @@ static bool do_signal_stop(int signr)
 		if (task_participate_group_stop(current))
 			notify = CLD_STOPPED;
 
-		__set_current_state(TASK_STOPPED);
+		set_special_state(TASK_STOPPED);
 		spin_unlock_irq(&current->sighand->siglock);
 
 		/*

commit 31931c93dfe05a76385a443ed28244a50e915a46
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Apr 24 20:59:47 2018 -0500

    signal: Extend siginfo_layout with SIL_FAULT_{MCEERR|BNDERR|PKUERR}
    
    Update the siginfo_layout function and enum siginfo_layout to represent
    all of the possible field layouts of struct siginfo.
    
    This allows the uses of siginfo_layout in um and arm64 where they are testing
    for SIL_FAULT to be more accurate as this rules out the other cases.
    
    Further this allows the switch statements on siginfo_layout to be simpler
    if perhaps a little more wordy.  Making it easier to understand what is
    actually going on.
    
    As SIL_FAULT_BNDERR and SIL_FAULT_PKUERR are never expected to appear
    in signalfd just treat them as SIL_FAULT.  To include them would take
    20 extra bytes an pretty much fill up what is left of
    signalfd_siginfo.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 376b42f26e6d..8a85da8aaa7c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2820,8 +2820,19 @@ enum siginfo_layout siginfo_layout(int sig, int si_code)
 			[SIGPOLL] = { NSIGPOLL, SIL_POLL },
 			[SIGSYS]  = { NSIGSYS,  SIL_SYS },
 		};
-		if ((sig < ARRAY_SIZE(filter)) && (si_code <= filter[sig].limit))
+		if ((sig < ARRAY_SIZE(filter)) && (si_code <= filter[sig].limit)) {
 			layout = filter[sig].layout;
+			/* Handle the exceptions */
+			if ((sig == SIGBUS) &&
+			    (si_code >= BUS_MCEERR_AR) && (si_code <= BUS_MCEERR_AO))
+				layout = SIL_FAULT_MCEERR;
+			else if ((sig == SIGSEGV) && (si_code == SEGV_BNDERR))
+				layout = SIL_FAULT_BNDERR;
+#ifdef SEGV_PKUERR
+			else if ((sig == SIGSEGV) && (si_code == SEGV_PKUERR))
+				layout = SIL_FAULT_PKUERR;
+#endif
+		}
 		else if (si_code <= NSIGPOLL)
 			layout = SIL_POLL;
 	} else {
@@ -2878,19 +2889,28 @@ int __copy_siginfo_to_user32(struct compat_siginfo __user *to,
 #ifdef __ARCH_SI_TRAPNO
 		new.si_trapno = from->si_trapno;
 #endif
-		if ((from->si_signo == SIGBUS) &&
-		    ((from->si_code == BUS_MCEERR_AR) ||
-		     (from->si_code == BUS_MCEERR_AO)))
-			new.si_addr_lsb = from->si_addr_lsb;
-
-		if ((from->si_signo == SIGSEGV) &&
-		    (from->si_code == SEGV_BNDERR)) {
-			new.si_lower = ptr_to_compat(from->si_lower);
-			new.si_upper = ptr_to_compat(from->si_upper);
-		}
-		if ((from->si_signo == SIGSEGV) &&
-		    (from->si_code == SEGV_PKUERR))
-			new.si_pkey = from->si_pkey;
+		break;
+	case SIL_FAULT_MCEERR:
+		new.si_addr = ptr_to_compat(from->si_addr);
+#ifdef __ARCH_SI_TRAPNO
+		new.si_trapno = from->si_trapno;
+#endif
+		new.si_addr_lsb = from->si_addr_lsb;
+		break;
+	case SIL_FAULT_BNDERR:
+		new.si_addr = ptr_to_compat(from->si_addr);
+#ifdef __ARCH_SI_TRAPNO
+		new.si_trapno = from->si_trapno;
+#endif
+		new.si_lower = ptr_to_compat(from->si_lower);
+		new.si_upper = ptr_to_compat(from->si_upper);
+		break;
+	case SIL_FAULT_PKUERR:
+		new.si_addr = ptr_to_compat(from->si_addr);
+#ifdef __ARCH_SI_TRAPNO
+		new.si_trapno = from->si_trapno;
+#endif
+		new.si_pkey = from->si_pkey;
 		break;
 	case SIL_CHLD:
 		new.si_pid    = from->si_pid;
@@ -2956,17 +2976,28 @@ int copy_siginfo_from_user32(struct siginfo *to,
 #ifdef __ARCH_SI_TRAPNO
 		to->si_trapno = from.si_trapno;
 #endif
-		if ((from.si_signo == SIGBUS) &&
-		    ((from.si_code == BUS_MCEERR_AR) ||
-		     (from.si_code == BUS_MCEERR_AO)))
-			to->si_addr_lsb = from.si_addr_lsb;
-
-		if ((from.si_signo == SIGSEGV) && (from.si_code == SEGV_BNDERR)) {
-			to->si_lower = compat_ptr(from.si_lower);
-			to->si_upper = compat_ptr(from.si_upper);
-		}
-		if ((from.si_signo == SIGSEGV) && (from.si_code == SEGV_PKUERR))
-			to->si_pkey = from.si_pkey;
+		break;
+	case SIL_FAULT_MCEERR:
+		to->si_addr = compat_ptr(from.si_addr);
+#ifdef __ARCH_SI_TRAPNO
+		to->si_trapno = from.si_trapno;
+#endif
+		to->si_addr_lsb = from.si_addr_lsb;
+		break;
+	case SIL_FAULT_BNDERR:
+		to->si_addr = compat_ptr(from.si_addr);
+#ifdef __ARCH_SI_TRAPNO
+		to->si_trapno = from.si_trapno;
+#endif
+		to->si_lower = compat_ptr(from.si_lower);
+		to->si_upper = compat_ptr(from.si_upper);
+		break;
+	case SIL_FAULT_PKUERR:
+		to->si_addr = compat_ptr(from.si_addr);
+#ifdef __ARCH_SI_TRAPNO
+		to->si_trapno = from.si_trapno;
+#endif
+		to->si_pkey = from.si_pkey;
 		break;
 	case SIL_CHLD:
 		to->si_pid    = from.si_pid;

commit 36a4ca3d9b5205819e4c47686cafb4e9b7ae76d3
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Apr 24 21:06:43 2018 -0500

    signal: Remove unncessary #ifdef SEGV_PKUERR in 32bit compat code
    
    The only architecture that does not support SEGV_PKUERR is ia64 and
    ia64 has not had 32bit support since some time in 2008.  Therefore
    copy_siginfo_to_user32 and copy_siginfo_from_user32 do not need to
    include support for a missing SEGV_PKUERR.
    
    Compile test on ia64.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index b87a9c21f698..376b42f26e6d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2888,12 +2888,9 @@ int __copy_siginfo_to_user32(struct compat_siginfo __user *to,
 			new.si_lower = ptr_to_compat(from->si_lower);
 			new.si_upper = ptr_to_compat(from->si_upper);
 		}
-#ifdef SEGV_PKUERR
 		if ((from->si_signo == SIGSEGV) &&
 		    (from->si_code == SEGV_PKUERR))
 			new.si_pkey = from->si_pkey;
-#endif
-
 		break;
 	case SIL_CHLD:
 		new.si_pid    = from->si_pid;
@@ -2968,10 +2965,8 @@ int copy_siginfo_from_user32(struct siginfo *to,
 			to->si_lower = compat_ptr(from.si_lower);
 			to->si_upper = compat_ptr(from.si_upper);
 		}
-#ifdef SEGV_PKUERR
 		if ((from.si_signo == SIGSEGV) && (from.si_code == SEGV_PKUERR))
 			to->si_pkey = from.si_pkey;
-#endif
 		break;
 	case SIL_CHLD:
 		to->si_pid    = from.si_pid;

commit 4181d22596f61d060139bb114724f89b3ad28c8d
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sun Apr 15 19:40:02 2018 -0500

    signal: Remove ifdefs for BUS_MCEERR_AR and BUS_MCEERR_AO
    
    With the recent architecture cleanups these si_codes are always
    defined so there is no need to test for them.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index a6d55a6e9915..b87a9c21f698 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1539,7 +1539,6 @@ int send_sig_fault(int sig, int code, void __user *addr
 	return send_sig_info(info.si_signo, &info, t);
 }
 
-#if defined(BUS_MCEERR_AO) && defined(BUS_MCEERR_AR)
 int force_sig_mceerr(int code, void __user *addr, short lsb, struct task_struct *t)
 {
 	struct siginfo info;
@@ -1568,7 +1567,6 @@ int send_sig_mceerr(int code, void __user *addr, short lsb, struct task_struct *
 	return send_sig_info(info.si_signo, &info, t);
 }
 EXPORT_SYMBOL(send_sig_mceerr);
-#endif
 
 int force_sig_bnderr(void __user *addr, void __user *lower, void __user *upper)
 {
@@ -2880,14 +2878,11 @@ int __copy_siginfo_to_user32(struct compat_siginfo __user *to,
 #ifdef __ARCH_SI_TRAPNO
 		new.si_trapno = from->si_trapno;
 #endif
-#ifdef BUS_MCEERR_AR
-		if ((from->si_signo == SIGBUS) && (from->si_code == BUS_MCEERR_AR))
-			new.si_addr_lsb = from->si_addr_lsb;
-#endif
-#ifdef BUS_MCEERR_AO
-		if ((from->si_signo == SIGBUS) && (from->si_code == BUS_MCEERR_AO))
+		if ((from->si_signo == SIGBUS) &&
+		    ((from->si_code == BUS_MCEERR_AR) ||
+		     (from->si_code == BUS_MCEERR_AO)))
 			new.si_addr_lsb = from->si_addr_lsb;
-#endif
+
 		if ((from->si_signo == SIGSEGV) &&
 		    (from->si_code == SEGV_BNDERR)) {
 			new.si_lower = ptr_to_compat(from->si_lower);
@@ -2964,14 +2959,11 @@ int copy_siginfo_from_user32(struct siginfo *to,
 #ifdef __ARCH_SI_TRAPNO
 		to->si_trapno = from.si_trapno;
 #endif
-#ifdef BUS_MCEERR_AR
-		if ((from.si_signo == SIGBUS) && (from.si_code == BUS_MCEERR_AR))
+		if ((from.si_signo == SIGBUS) &&
+		    ((from.si_code == BUS_MCEERR_AR) ||
+		     (from.si_code == BUS_MCEERR_AO)))
 			to->si_addr_lsb = from.si_addr_lsb;
-#endif
-#ifdef BUS_MCEER_AO
-		if ((from.si_signo == SIGBUS) && (from.si_code == BUS_MCEERR_AO))
-			to->si_addr_lsb = from.si_addr_lsb;
-#endif
+
 		if ((from.si_signo == SIGSEGV) && (from.si_code == SEGV_BNDERR)) {
 			to->si_lower = compat_ptr(from.si_lower);
 			to->si_upper = compat_ptr(from.si_upper);

commit 3a11ab148ac21747f00449d2b8b389c24475e10a
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sun Apr 15 19:36:16 2018 -0500

    signal: Remove SEGV_BNDERR ifdefs
    
    After the last round of cleanups to siginfo.h SEGV_BNDERR is defined
    on all architectures so testing to see if it is defined is unnecessary.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index fc82d2c0918f..a6d55a6e9915 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1570,7 +1570,6 @@ int send_sig_mceerr(int code, void __user *addr, short lsb, struct task_struct *
 EXPORT_SYMBOL(send_sig_mceerr);
 #endif
 
-#ifdef SEGV_BNDERR
 int force_sig_bnderr(void __user *addr, void __user *lower, void __user *upper)
 {
 	struct siginfo info;
@@ -1584,7 +1583,6 @@ int force_sig_bnderr(void __user *addr, void __user *lower, void __user *upper)
 	info.si_upper = upper;
 	return force_sig_info(info.si_signo, &info, current);
 }
-#endif
 
 #ifdef SEGV_PKUERR
 int force_sig_pkuerr(void __user *addr, u32 pkey)
@@ -2890,13 +2888,11 @@ int __copy_siginfo_to_user32(struct compat_siginfo __user *to,
 		if ((from->si_signo == SIGBUS) && (from->si_code == BUS_MCEERR_AO))
 			new.si_addr_lsb = from->si_addr_lsb;
 #endif
-#ifdef SEGV_BNDERR
 		if ((from->si_signo == SIGSEGV) &&
 		    (from->si_code == SEGV_BNDERR)) {
 			new.si_lower = ptr_to_compat(from->si_lower);
 			new.si_upper = ptr_to_compat(from->si_upper);
 		}
-#endif
 #ifdef SEGV_PKUERR
 		if ((from->si_signo == SIGSEGV) &&
 		    (from->si_code == SEGV_PKUERR))
@@ -2976,12 +2972,10 @@ int copy_siginfo_from_user32(struct siginfo *to,
 		if ((from.si_signo == SIGBUS) && (from.si_code == BUS_MCEERR_AO))
 			to->si_addr_lsb = from.si_addr_lsb;
 #endif
-#ifdef SEGV_BNDERR
 		if ((from.si_signo == SIGSEGV) && (from.si_code == SEGV_BNDERR)) {
 			to->si_lower = compat_ptr(from.si_lower);
 			to->si_upper = compat_ptr(from.si_upper);
 		}
-#endif
 #ifdef SEGV_PKUERR
 		if ((from.si_signo == SIGSEGV) && (from.si_code == SEGV_PKUERR))
 			to->si_pkey = from.si_pkey;

commit 0c362f96e1c6bb76ab9b0b828985655fd2516bfa
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Apr 14 14:20:30 2018 -0500

    signal: Stop special casing TRAP_FIXME and FPE_FIXME in siginfo_layout
    
    After more experience with the cases where no one the si_code of 0
    is used both as a signal specific si_code, and as SI_USER it appears
    that no one cares about the signal specific si_code case and the
    good solution is to just fix the architectures by using
    a different si_code.
    
    In none of the conversations has anyone even suggested that
    anything depends on the signal specific redefinition of SI_USER.
    
    There are at least test cases that care when si_code as 0 does
    not work as si_user.
    
    So make things simple and keep the generic code from introducing
    problems by removing the special casing of TRAP_FIXME and FPE_FIXME.
    This will ensure the generic case of sending a signal with
    kill will always set SI_USER and work.
    
    The architecture specific, and signal specific overloads that
    set si_code to 0 will now have problems with signalfd and
    the 32bit compat versions of siginfo copying.   At least
    until they are fixed.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index d56f4d496c89..fc82d2c0918f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2835,15 +2835,6 @@ enum siginfo_layout siginfo_layout(int sig, int si_code)
 			layout = SIL_POLL;
 		else if (si_code < 0)
 			layout = SIL_RT;
-		/* Tests to support buggy kernel ABIs */
-#ifdef TRAP_FIXME
-		if ((sig == SIGTRAP) && (si_code == TRAP_FIXME))
-			layout = SIL_FAULT;
-#endif
-#ifdef FPE_FIXME
-		if ((sig == SIGFPE) && (si_code == FPE_FIXME))
-			layout = SIL_FAULT;
-#endif
 	}
 	return layout;
 }

commit c999b933faa5e281e3af2e110eccaf91698b0a81
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Apr 14 13:03:25 2018 -0500

    signal: Reduce copy_siginfo_to_user to just copy_to_user
    
    Now that every instance of struct siginfo is now initialized it is no
    longer necessary to copy struct siginfo piece by piece to userspace
    but instead the entire structure can be copied.
    
    As well as making the code simpler and more efficient this means that
    copy_sinfo_to_user no longer cares which union member of struct
    siginfo is in use.
    
    In practice this means that all 32bit architectures that define
    FPE_FIXME will handle properly send SI_USER when kill(SIGFPE) is sent.
    While still performing their historic architectural brokenness when 0
    is used a floating pointer signal.  This matches the current behavior
    of 64bit architectures that define FPE_FIXME who get lucky and an
    overloaded SI_USER has continuted to work through copy_siginfo_to_user
    because the 8 byte si_addr occupies the same bytes in struct siginfo
    as the 4 byte si_pid and the 4 byte si_uid.
    
    Problematic architectures still need to fix their ABI so that signalfd
    and 32bit compat code will work properly.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index d4ccea599692..d56f4d496c89 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2850,89 +2850,9 @@ enum siginfo_layout siginfo_layout(int sig, int si_code)
 
 int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 {
-	int err;
-
-	if (!access_ok (VERIFY_WRITE, to, sizeof(siginfo_t)))
+	if (copy_to_user(to, from , sizeof(struct siginfo)))
 		return -EFAULT;
-	if (from->si_code < 0)
-		return __copy_to_user(to, from, sizeof(siginfo_t))
-			? -EFAULT : 0;
-	/*
-	 * If you change siginfo_t structure, please be sure
-	 * this code is fixed accordingly.
-	 * Please remember to update the signalfd_copyinfo() function
-	 * inside fs/signalfd.c too, in case siginfo_t changes.
-	 * It should never copy any pad contained in the structure
-	 * to avoid security leaks, but must copy the generic
-	 * 3 ints plus the relevant union member.
-	 */
-	err = __put_user(from->si_signo, &to->si_signo);
-	err |= __put_user(from->si_errno, &to->si_errno);
-	err |= __put_user(from->si_code, &to->si_code);
-	switch (siginfo_layout(from->si_signo, from->si_code)) {
-	case SIL_KILL:
-		err |= __put_user(from->si_pid, &to->si_pid);
-		err |= __put_user(from->si_uid, &to->si_uid);
-		break;
-	case SIL_TIMER:
-		/* Unreached SI_TIMER is negative */
-		break;
-	case SIL_POLL:
-		err |= __put_user(from->si_band, &to->si_band);
-		err |= __put_user(from->si_fd, &to->si_fd);
-		break;
-	case SIL_FAULT:
-		err |= __put_user(from->si_addr, &to->si_addr);
-#ifdef __ARCH_SI_TRAPNO
-		err |= __put_user(from->si_trapno, &to->si_trapno);
-#endif
-#ifdef __ia64__
-		err |= __put_user(from->si_imm, &to->si_imm);
-		err |= __put_user(from->si_flags, &to->si_flags);
-		err |= __put_user(from->si_isr, &to->si_isr);
-#endif
-		/*
-		 * Other callers might not initialize the si_lsb field,
-		 * so check explicitly for the right codes here.
-		 */
-#ifdef BUS_MCEERR_AR
-		if (from->si_signo == SIGBUS && from->si_code == BUS_MCEERR_AR)
-			err |= __put_user(from->si_addr_lsb, &to->si_addr_lsb);
-#endif
-#ifdef BUS_MCEERR_AO
-		if (from->si_signo == SIGBUS && from->si_code == BUS_MCEERR_AO)
-			err |= __put_user(from->si_addr_lsb, &to->si_addr_lsb);
-#endif
-#ifdef SEGV_BNDERR
-		if (from->si_signo == SIGSEGV && from->si_code == SEGV_BNDERR) {
-			err |= __put_user(from->si_lower, &to->si_lower);
-			err |= __put_user(from->si_upper, &to->si_upper);
-		}
-#endif
-#ifdef SEGV_PKUERR
-		if (from->si_signo == SIGSEGV && from->si_code == SEGV_PKUERR)
-			err |= __put_user(from->si_pkey, &to->si_pkey);
-#endif
-		break;
-	case SIL_CHLD:
-		err |= __put_user(from->si_pid, &to->si_pid);
-		err |= __put_user(from->si_uid, &to->si_uid);
-		err |= __put_user(from->si_status, &to->si_status);
-		err |= __put_user(from->si_utime, &to->si_utime);
-		err |= __put_user(from->si_stime, &to->si_stime);
-		break;
-	case SIL_RT:
-		err |= __put_user(from->si_pid, &to->si_pid);
-		err |= __put_user(from->si_uid, &to->si_uid);
-		err |= __put_user(from->si_ptr, &to->si_ptr);
-		break;
-	case SIL_SYS:
-		err |= __put_user(from->si_call_addr, &to->si_call_addr);
-		err |= __put_user(from->si_syscall, &to->si_syscall);
-		err |= __put_user(from->si_arch, &to->si_arch);
-		break;
-	}
-	return err;
+	return 0;
 }
 
 #ifdef CONFIG_COMPAT

commit 3612605a5a5bc3d3ae0ec861328be8a2990f2c7a
Merge: 62f8e6c5dcb6 df0ce17331e2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Apr 7 11:11:41 2018 -0700

    Merge branch 'next-general' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security
    
    Pull general security layer updates from James Morris:
    
     - Convert security hooks from list to hlist, a nice cleanup, saving
       about 50% of space, from Sargun Dhillon.
    
     - Only pass the cred, not the secid, to kill_pid_info_as_cred and
       security_task_kill (as the secid can be determined from the cred),
       from Stephen Smalley.
    
     - Close a potential race in kernel_read_file(), by making the file
       unwritable before calling the LSM check (vs after), from Kees Cook.
    
    * 'next-general' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security:
      security: convert security hooks to use hlist
      exec: Set file unwritable before LSM check
      usb, signal, security: only pass the cred, not the secid, to kill_pid_info_as_cred and security_task_kill

commit 23221d997b3d28cb80c4d4d1b4bd36610f8e12fc
Merge: 5b1f3dc927a2 65896545b69f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Apr 4 16:01:43 2018 -0700

    Merge tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux
    
    Pull arm64 updates from Will Deacon:
     "Nothing particularly stands out here, probably because people were
      tied up with spectre/meltdown stuff last time around. Still, the main
      pieces are:
    
       - Rework of our CPU features framework so that we can whitelist CPUs
         that don't require kpti even in a heterogeneous system
    
       - Support for the IDC/DIC architecture extensions, which allow us to
         elide instruction and data cache maintenance when writing out
         instructions
    
       - Removal of the large memory model which resulted in suboptimal
         codegen by the compiler and increased the use of literal pools,
         which could potentially be used as ROP gadgets since they are
         mapped as executable
    
       - Rework of forced signal delivery so that the siginfo_t is
         well-formed and handling of show_unhandled_signals is consolidated
         and made consistent between different fault types
    
       - More siginfo cleanup based on the initial patches from Eric
         Biederman
    
       - Workaround for Cortex-A55 erratum #1024718
    
       - Some small ACPI IORT updates and cleanups from Lorenzo Pieralisi
    
       - Misc cleanups and non-critical fixes"
    
    * tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux: (70 commits)
      arm64: uaccess: Fix omissions from usercopy whitelist
      arm64: fpsimd: Split cpu field out from struct fpsimd_state
      arm64: tlbflush: avoid writing RES0 bits
      arm64: cmpxchg: Include linux/compiler.h in asm/cmpxchg.h
      arm64: move percpu cmpxchg implementation from cmpxchg.h to percpu.h
      arm64: cmpxchg: Include build_bug.h instead of bug.h for BUILD_BUG
      arm64: lse: Include compiler_types.h and export.h for out-of-line LL/SC
      arm64: fpsimd: include <linux/init.h> in fpsimd.h
      drivers/perf: arm_pmu_platform: do not warn about affinity on uniprocessor
      perf: arm_spe: include linux/vmalloc.h for vmap()
      Revert "arm64: Revert L1_CACHE_SHIFT back to 6 (64-byte cache line size)"
      arm64: cpufeature: Avoid warnings due to unused symbols
      arm64: Add work around for Arm Cortex-A55 Erratum 1024718
      arm64: Delay enabling hardware DBM feature
      arm64: Add MIDR encoding for Arm Cortex-A55 and Cortex-A35
      arm64: capabilities: Handle shared entries
      arm64: capabilities: Add support for checks based on a list of MIDRs
      arm64: Add helpers for checking CPU MIDR against a range
      arm64: capabilities: Clean up midr range helpers
      arm64: capabilities: Change scope of VHE to Boot CPU feature
      ...

commit 6203deb0a76f35b6dc476fecb228c850099a1bc4
Author: Dominik Brodowski <linux@dominikbrodowski.net>
Date:   Sat Mar 17 17:11:51 2018 +0100

    kernel: add do_compat_sigaltstack() helper; remove in-kernel call to compat syscall
    
    Using this helper allows us to avoid the in-kernel call to the
    compat_sys_sigaltstack() syscall.
    
    This patch is part of a series which removes in-kernel calls to syscalls.
    On this basis, the syscall entry path can be streamlined. For details, see
    http://lkml.kernel.org/r/20180325162527.GA17492@light.dominikbrodowski.net
    
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Dominik Brodowski <linux@dominikbrodowski.net>

diff --git a/kernel/signal.c b/kernel/signal.c
index 985c61749bcf..f04466655238 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3573,9 +3573,8 @@ int __save_altstack(stack_t __user *uss, unsigned long sp)
 }
 
 #ifdef CONFIG_COMPAT
-COMPAT_SYSCALL_DEFINE2(sigaltstack,
-			const compat_stack_t __user *, uss_ptr,
-			compat_stack_t __user *, uoss_ptr)
+static int do_compat_sigaltstack(const compat_stack_t __user *uss_ptr,
+				 compat_stack_t __user *uoss_ptr)
 {
 	stack_t uss, uoss;
 	int ret;
@@ -3602,9 +3601,16 @@ COMPAT_SYSCALL_DEFINE2(sigaltstack,
 	return ret;
 }
 
+COMPAT_SYSCALL_DEFINE2(sigaltstack,
+			const compat_stack_t __user *, uss_ptr,
+			compat_stack_t __user *, uoss_ptr)
+{
+	return do_compat_sigaltstack(uss_ptr, uoss_ptr);
+}
+
 int compat_restore_altstack(const compat_stack_t __user *uss)
 {
-	int err = compat_sys_sigaltstack(uss, NULL);
+	int err = do_compat_sigaltstack(uss, NULL);
 	/* squash all but -EFAULT for now */
 	return err == -EFAULT ? err : 0;
 }

commit d53238cd51a80f6f2e5b9d64830c62e2086787bd
Author: Dominik Brodowski <linux@dominikbrodowski.net>
Date:   Sun Mar 11 11:34:37 2018 +0100

    kernel: open-code sys_rt_sigpending() in sys_sigpending()
    
    A similar but not fully equivalent code path is already open-coded
    three times (in sys_rt_sigpending and in the two compat stubs), so
    do it a fourth time here.
    
    This patch is part of a series which removes in-kernel calls to syscalls.
    On this basis, the syscall entry path can be streamlined. For details, see
    http://lkml.kernel.org/r/20180325162527.GA17492@light.dominikbrodowski.net
    
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Dominik Brodowski <linux@dominikbrodowski.net>

diff --git a/kernel/signal.c b/kernel/signal.c
index c6e4c83dc090..985c61749bcf 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3629,11 +3629,20 @@ int __compat_save_altstack(compat_stack_t __user *uss, unsigned long sp)
 
 /**
  *  sys_sigpending - examine pending signals
- *  @set: where mask of pending signal is returned
+ *  @uset: where mask of pending signal is returned
  */
-SYSCALL_DEFINE1(sigpending, old_sigset_t __user *, set)
+SYSCALL_DEFINE1(sigpending, old_sigset_t __user *, uset)
 {
-	return sys_rt_sigpending((sigset_t __user *)set, sizeof(old_sigset_t)); 
+	sigset_t set;
+	int err;
+
+	if (sizeof(old_sigset_t) > sizeof(*uset))
+		return -EINVAL;
+
+	err = do_sigpending(&set);
+	if (!err && copy_to_user(uset, &set, sizeof(old_sigset_t)))
+		err = -EFAULT;
+	return err;
 }
 
 #ifdef CONFIG_COMPAT

commit af40ff687bc9d351030685fde2f57ba45ab4fc14
Author: Dave Martin <Dave.Martin@arm.com>
Date:   Thu Mar 8 17:41:05 2018 +0000

    arm64: signal: Ensure si_code is valid for all fault signals
    
    Currently, as reported by Eric, an invalid si_code value 0 is
    passed in many signals delivered to userspace in response to faults
    and other kernel errors.  Typically 0 is passed when the fault is
    insufficiently diagnosable or when there does not appear to be any
    sensible alternative value to choose.
    
    This appears to violate POSIX, and is intuitively wrong for at
    least two reasons arising from the fact that 0 == SI_USER:
    
     1) si_code is a union selector, and SI_USER (and si_code <= 0 in
        general) implies the existence of a different set of fields
        (siginfo._kill) from that which exists for a fault signal
        (siginfo._sigfault).  However, the code raising the signal
        typically writes only the _sigfault fields, and the _kill
        fields make no sense in this case.
    
        Thus when userspace sees si_code == 0 (SI_USER) it may
        legitimately inspect fields in the inactive union member _kill
        and obtain garbage as a result.
    
        There appears to be software in the wild relying on this,
        albeit generally only for printing diagnostic messages.
    
     2) Software that wants to be robust against spurious signals may
        discard signals where si_code == SI_USER (or <= 0), or may
        filter such signals based on the si_uid and si_pid fields of
        siginfo._sigkill.  In the case of fault signals, this means
        that important (and usually fatal) error conditions may be
        silently ignored.
    
    In practice, many of the faults for which arm64 passes si_code == 0
    are undiagnosable conditions such as exceptions with syndrome
    values in ESR_ELx to which the architecture does not yet assign any
    meaning, or conditions indicative of a bug or error in the kernel
    or system and thus that are unrecoverable and should never occur in
    normal operation.
    
    The approach taken in this patch is to translate all such
    undiagnosable or "impossible" synchronous fault conditions to
    SIGKILL, since these are at least probably localisable to a single
    process.  Some of these conditions should really result in a kernel
    panic, but due to the lack of diagnostic information it is
    difficult to be certain: this patch does not add any calls to
    panic(), but this could change later if justified.
    
    Although si_code will not reach userspace in the case of SIGKILL,
    it is still desirable to pass a nonzero value so that the common
    siginfo handling code can detect incorrect use of si_code == 0
    without false positives.  In this case the si_code dependent
    siginfo fields will not be correctly initialised, but since they
    are not passed to userspace I deem this not to matter.
    
    A few faults can reasonably occur in realistic userspace scenarios,
    and _should_ raise a regular, handleable (but perhaps not
    ignorable/blockable) signal: for these, this patch attempts to
    choose a suitable standard si_code value for the raised signal in
    each case instead of 0.
    
    arm64 was the only arch to define a BUS_FIXME code, so after this
    patch nobody defines it.  This patch therefore also removes the
    relevant code from siginfo_layout().
    
    Cc: James Morse <james.morse@arm.com>
    Reported-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Dave Martin <Dave.Martin@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index c6e4c83dc090..049a482e705c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2843,10 +2843,6 @@ enum siginfo_layout siginfo_layout(int sig, int si_code)
 #ifdef FPE_FIXME
 		if ((sig == SIGFPE) && (si_code == FPE_FIXME))
 			layout = SIL_FAULT;
-#endif
-#ifdef BUS_FIXME
-		if ((sig == SIGBUS) && (si_code == BUS_FIXME))
-			layout = SIL_FAULT;
 #endif
 	}
 	return layout;

commit 6b4f3d01052a479c7ebbe99d52a663558dc1be2a
Author: Stephen Smalley <sds@tycho.nsa.gov>
Date:   Fri Sep 8 12:40:01 2017 -0400

    usb, signal, security: only pass the cred, not the secid, to kill_pid_info_as_cred and security_task_kill
    
    commit d178bc3a708f39cbfefc3fab37032d3f2511b4ec ("user namespace: usb:
     make usb urbs user namespace aware (v2)") changed kill_pid_info_as_uid
    to kill_pid_info_as_cred, saving and passing a cred structure instead of
    uids.  Since the secid can be obtained from the cred, drop the secid fields
    from the usb_dev_state and async structures, and drop the secid argument to
    kill_pid_info_as_cred.  Replace the secid argument to security_task_kill
    with the cred.  Update SELinux, Smack, and AppArmor to use the cred, which
    avoids the need for Smack and AppArmor to use a secid at all in this hook.
    Further changes to Smack might still be required to take full advantage of
    this change, since it should now be possible to perform capability
    checking based on the supplied cred.  The changes to Smack and AppArmor
    have only been compile-tested.
    
    Signed-off-by: Stephen Smalley <sds@tycho.nsa.gov>
    Acked-by: Paul Moore <paul@paul-moore.com>
    Acked-by: Casey Schaufler <casey@schaufler-ca.com>
    Acked-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Acked-by: John Johansen <john.johansen@canonical.com>
    Signed-off-by: James Morris <james.morris@microsoft.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index c6e4c83dc090..b033292f4beb 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -770,7 +770,7 @@ static int check_kill_permission(int sig, struct siginfo *info,
 		}
 	}
 
-	return security_task_kill(t, info, sig, 0);
+	return security_task_kill(t, info, sig, NULL);
 }
 
 /**
@@ -1361,7 +1361,7 @@ static int kill_as_cred_perm(const struct cred *cred,
 
 /* like kill_pid_info(), but doesn't use uid/euid of "current" */
 int kill_pid_info_as_cred(int sig, struct siginfo *info, struct pid *pid,
-			 const struct cred *cred, u32 secid)
+			 const struct cred *cred)
 {
 	int ret = -EINVAL;
 	struct task_struct *p;
@@ -1380,7 +1380,7 @@ int kill_pid_info_as_cred(int sig, struct siginfo *info, struct pid *pid,
 		ret = -EPERM;
 		goto out_unlock;
 	}
-	ret = security_task_kill(p, info, sig, secid);
+	ret = security_task_kill(p, info, sig, cred);
 	if (ret)
 		goto out_unlock;
 

commit e1c70f32386c4984ed8ca1a7aedb9bbff9ed3414
Merge: 183b6366cf47 d05b695c25bf
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jan 31 13:02:18 2018 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/livepatching
    
    Pull livepatching updates from Jiri Kosina:
    
     - handle 'infinitely'-long sleeping tasks, from Miroslav Benes
    
     - remove 'immediate' feature, as it turns out it doesn't provide the
       originally expected semantics, and brings more issues than value
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/livepatching:
      livepatch: add locking to force and signal functions
      livepatch: Remove immediate feature
      livepatch: force transition to finish
      livepatch: send a fake signal to all blocking tasks

commit f71dd7dc2dc989dc712b246a74d243e4b2c5f8a7
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Jan 22 14:37:25 2018 -0600

    signal/ptrace: Add force_sig_ptrace_errno_trap and use it where needed
    
    There are so many places that build struct siginfo by hand that at
    least one of them is bound to get it wrong.  A handful of cases in the
    kernel arguably did just that when using the errno field of siginfo to
    pass no errno values to userspace.  The usage is limited to a single
    si_code so at least does not mess up anything else.
    
    Encapsulate this questionable pattern in a helper function so
    that the userspace ABI is preserved.
    
    Update all of the places that use this pattern to use the new helper
    function.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 4f6300ef8062..e549174c0831 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1599,6 +1599,21 @@ int force_sig_pkuerr(void __user *addr, u32 pkey)
 }
 #endif
 
+/* For the crazy architectures that include trap information in
+ * the errno field, instead of an actual errno value.
+ */
+int force_sig_ptrace_errno_trap(int errno, void __user *addr)
+{
+	struct siginfo info;
+
+	clear_siginfo(&info);
+	info.si_signo = SIGTRAP;
+	info.si_errno = errno;
+	info.si_code  = TRAP_HWBKPT;
+	info.si_addr  = addr;
+	return force_sig_info(info.si_signo, &info, current);
+}
+
 int kill_pgrp(struct pid *pid, int sig, int priv)
 {
 	int ret;

commit 382467358ac9675b1b6814400a9a9e36dc7da14f
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Jan 18 18:54:31 2018 -0600

    signal: Helpers for faults with specialized siginfo layouts
    
    The helpers added are:
    send_sig_mceerr
    force_sig_mceerr
    force_sig_bnderr
    force_sig_pkuerr
    
    Filling out siginfo properly can ge tricky.  Especially for these
    specialized cases where the temptation is to share code with other
    cases which use a different subset of siginfo fields.  Unfortunately
    that code sharing frequently results in bugs with the wrong siginfo
    fields filled in, and makes it harder to verify that the siginfo
    structure was properly initialized.
    
    Provide these helpers instead that get all of the details right, and
    guarantee that siginfo is properly initialized.
    
    send_sig_mceerr and force_sig_mceer are a little special as two si
    codes BUS_MCEERR_AO and BUS_MCEER_AR both use the same extended
    signinfo layout.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 15ec7b3cbe69..4f6300ef8062 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1537,6 +1537,67 @@ int send_sig_fault(int sig, int code, void __user *addr
 	return send_sig_info(info.si_signo, &info, t);
 }
 
+#if defined(BUS_MCEERR_AO) && defined(BUS_MCEERR_AR)
+int force_sig_mceerr(int code, void __user *addr, short lsb, struct task_struct *t)
+{
+	struct siginfo info;
+
+	WARN_ON((code != BUS_MCEERR_AO) && (code != BUS_MCEERR_AR));
+	clear_siginfo(&info);
+	info.si_signo = SIGBUS;
+	info.si_errno = 0;
+	info.si_code = code;
+	info.si_addr = addr;
+	info.si_addr_lsb = lsb;
+	return force_sig_info(info.si_signo, &info, t);
+}
+
+int send_sig_mceerr(int code, void __user *addr, short lsb, struct task_struct *t)
+{
+	struct siginfo info;
+
+	WARN_ON((code != BUS_MCEERR_AO) && (code != BUS_MCEERR_AR));
+	clear_siginfo(&info);
+	info.si_signo = SIGBUS;
+	info.si_errno = 0;
+	info.si_code = code;
+	info.si_addr = addr;
+	info.si_addr_lsb = lsb;
+	return send_sig_info(info.si_signo, &info, t);
+}
+EXPORT_SYMBOL(send_sig_mceerr);
+#endif
+
+#ifdef SEGV_BNDERR
+int force_sig_bnderr(void __user *addr, void __user *lower, void __user *upper)
+{
+	struct siginfo info;
+
+	clear_siginfo(&info);
+	info.si_signo = SIGSEGV;
+	info.si_errno = 0;
+	info.si_code  = SEGV_BNDERR;
+	info.si_addr  = addr;
+	info.si_lower = lower;
+	info.si_upper = upper;
+	return force_sig_info(info.si_signo, &info, current);
+}
+#endif
+
+#ifdef SEGV_PKUERR
+int force_sig_pkuerr(void __user *addr, u32 pkey)
+{
+	struct siginfo info;
+
+	clear_siginfo(&info);
+	info.si_signo = SIGSEGV;
+	info.si_errno = 0;
+	info.si_code  = SEGV_PKUERR;
+	info.si_addr  = addr;
+	info.si_pkey  = pkey;
+	return force_sig_info(info.si_signo, &info, current);
+}
+#endif
 
 int kill_pgrp(struct pid *pid, int sig, int priv)
 {

commit f8ec66014ffd95a783b1f9f3b62d7cadb96b78d5
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Jan 18 14:54:54 2018 -0600

    signal: Add send_sig_fault and force_sig_fault
    
    The vast majority of signals sent from architecture specific code are
    simple faults.  Encapsulate this reality with two helper functions so
    that the nit-picky implementation of preparing a siginfo does not need
    to be repeated many times on each architecture.
    
    As only some architectures support the trapno field, make the trapno
    arguement only present on those architectures.
    
    Similary as ia64 has three fields: imm, flags, and isr that
    are specific to it.  Have those arguments always present on ia64
    and no where else.
    
    This ensures the architecture specific code always remembers which
    fields it needs to pass into the siginfo structure.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index f14492ff976f..15ec7b3cbe69 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1491,6 +1491,53 @@ force_sigsegv(int sig, struct task_struct *p)
 	return 0;
 }
 
+int force_sig_fault(int sig, int code, void __user *addr
+	___ARCH_SI_TRAPNO(int trapno)
+	___ARCH_SI_IA64(int imm, unsigned int flags, unsigned long isr)
+	, struct task_struct *t)
+{
+	struct siginfo info;
+
+	clear_siginfo(&info);
+	info.si_signo = sig;
+	info.si_errno = 0;
+	info.si_code  = code;
+	info.si_addr  = addr;
+#ifdef __ARCH_SI_TRAPNO
+	info.si_trapno = trapno;
+#endif
+#ifdef __ia64__
+	info.si_imm = imm;
+	info.si_flags = flags;
+	info.si_isr = isr;
+#endif
+	return force_sig_info(info.si_signo, &info, t);
+}
+
+int send_sig_fault(int sig, int code, void __user *addr
+	___ARCH_SI_TRAPNO(int trapno)
+	___ARCH_SI_IA64(int imm, unsigned int flags, unsigned long isr)
+	, struct task_struct *t)
+{
+	struct siginfo info;
+
+	clear_siginfo(&info);
+	info.si_signo = sig;
+	info.si_errno = 0;
+	info.si_code  = code;
+	info.si_addr  = addr;
+#ifdef __ARCH_SI_TRAPNO
+	info.si_trapno = trapno;
+#endif
+#ifdef __ia64__
+	info.si_imm = imm;
+	info.si_flags = flags;
+	info.si_isr = isr;
+#endif
+	return send_sig_info(info.si_signo, &info, t);
+}
+
+
 int kill_pgrp(struct pid *pid, int sig, int priv)
 {
 	int ret;

commit 5f74972ce69fdc6473f74253283408af75a3be15
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Jan 22 14:58:57 2018 -0600

    signal: Don't use structure initializers for struct siginfo
    
    The siginfo structure has all manners of holes with the result that a
    structure initializer is not guaranteed to initialize all of the bits.
    As we have to copy the structure to userspace don't even try to use
    a structure initializer.  Instead use clear_siginfo followed by initializing
    selected fields.  This gives a guarantee that uninitialized kernel memory
    is not copied to userspace.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 4976f05aa09b..f14492ff976f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3163,8 +3163,9 @@ do_send_specific(pid_t tgid, pid_t pid, int sig, struct siginfo *info)
 
 static int do_tkill(pid_t tgid, pid_t pid, int sig)
 {
-	struct siginfo info = {};
+	struct siginfo info;
 
+	clear_siginfo(&info);
 	info.si_signo = sig;
 	info.si_errno = 0;
 	info.si_code = SI_TKILL;

commit ea64d5acc8f033cd586182ae31531246cdeaea73
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Jan 15 18:03:33 2018 -0600

    signal: Unify and correct copy_siginfo_to_user32
    
    Among the existing architecture specific versions of
    copy_siginfo_to_user32 there are several different implementation
    problems.  Some architectures fail to handle all of the cases in in
    the siginfo union.  Some architectures perform a blind copy of the
    siginfo union when the si_code is negative.  A blind copy suggests the
    data is expected to be in 32bit siginfo format, which means that
    receiving such a signal via signalfd won't work, or that the data is
    in 64bit siginfo and the code is copying nonsense to userspace.
    
    Create a single instance of copy_siginfo_to_user32 that all of the
    architectures can share, and teach it to handle all of the cases in
    the siginfo union correctly, with the assumption that siginfo is
    stored internally to the kernel is 64bit siginfo format.
    
    A special case is made for x86 x32 format.  This is needed as presence
    of both x32 and ia32 on x86_64 results in two different 32bit signal
    formats.  By allowing this small special case there winds up being
    exactly one code base that needs to be maintained between all of the
    architectures.  Vastly increasing the testing base and the chances of
    finding bugs.
    
    As the x86 copy of copy_siginfo_to_user32 the call of the x86
    signal_compat_build_tests were moved into sigaction_compat_abi, so
    that they will keep running.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index bebe44265b8b..4976f05aa09b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2815,6 +2815,96 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 }
 
 #ifdef CONFIG_COMPAT
+int copy_siginfo_to_user32(struct compat_siginfo __user *to,
+			   const struct siginfo *from)
+#if defined(CONFIG_X86_X32_ABI) || defined(CONFIG_IA32_EMULATION)
+{
+	return __copy_siginfo_to_user32(to, from, in_x32_syscall());
+}
+int __copy_siginfo_to_user32(struct compat_siginfo __user *to,
+			     const struct siginfo *from, bool x32_ABI)
+#endif
+{
+	struct compat_siginfo new;
+	memset(&new, 0, sizeof(new));
+
+	new.si_signo = from->si_signo;
+	new.si_errno = from->si_errno;
+	new.si_code  = from->si_code;
+	switch(siginfo_layout(from->si_signo, from->si_code)) {
+	case SIL_KILL:
+		new.si_pid = from->si_pid;
+		new.si_uid = from->si_uid;
+		break;
+	case SIL_TIMER:
+		new.si_tid     = from->si_tid;
+		new.si_overrun = from->si_overrun;
+		new.si_int     = from->si_int;
+		break;
+	case SIL_POLL:
+		new.si_band = from->si_band;
+		new.si_fd   = from->si_fd;
+		break;
+	case SIL_FAULT:
+		new.si_addr = ptr_to_compat(from->si_addr);
+#ifdef __ARCH_SI_TRAPNO
+		new.si_trapno = from->si_trapno;
+#endif
+#ifdef BUS_MCEERR_AR
+		if ((from->si_signo == SIGBUS) && (from->si_code == BUS_MCEERR_AR))
+			new.si_addr_lsb = from->si_addr_lsb;
+#endif
+#ifdef BUS_MCEERR_AO
+		if ((from->si_signo == SIGBUS) && (from->si_code == BUS_MCEERR_AO))
+			new.si_addr_lsb = from->si_addr_lsb;
+#endif
+#ifdef SEGV_BNDERR
+		if ((from->si_signo == SIGSEGV) &&
+		    (from->si_code == SEGV_BNDERR)) {
+			new.si_lower = ptr_to_compat(from->si_lower);
+			new.si_upper = ptr_to_compat(from->si_upper);
+		}
+#endif
+#ifdef SEGV_PKUERR
+		if ((from->si_signo == SIGSEGV) &&
+		    (from->si_code == SEGV_PKUERR))
+			new.si_pkey = from->si_pkey;
+#endif
+
+		break;
+	case SIL_CHLD:
+		new.si_pid    = from->si_pid;
+		new.si_uid    = from->si_uid;
+		new.si_status = from->si_status;
+#ifdef CONFIG_X86_X32_ABI
+		if (x32_ABI) {
+			new._sifields._sigchld_x32._utime = from->si_utime;
+			new._sifields._sigchld_x32._stime = from->si_stime;
+		} else
+#endif
+		{
+			new.si_utime = from->si_utime;
+			new.si_stime = from->si_stime;
+		}
+		break;
+	case SIL_RT:
+		new.si_pid = from->si_pid;
+		new.si_uid = from->si_uid;
+		new.si_int = from->si_int;
+		break;
+	case SIL_SYS:
+		new.si_call_addr = ptr_to_compat(from->si_call_addr);
+		new.si_syscall   = from->si_syscall;
+		new.si_arch      = from->si_arch;
+		break;
+	}
+
+	if (copy_to_user(to, &new, sizeof(struct compat_siginfo)))
+		return -EFAULT;
+
+	return 0;
+}
+
 int copy_siginfo_from_user32(struct siginfo *to,
 			     const struct compat_siginfo __user *ufrom)
 {

commit eb5346c379cb272eca77f63473de09103a22ebee
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Jul 31 17:18:40 2017 -0500

    signal: Remove the code to clear siginfo before calling copy_siginfo_from_user32
    
    The new unified copy_siginfo_from_user32 takes care of this.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5211b1b57163..bebe44265b8b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3155,7 +3155,7 @@ COMPAT_SYSCALL_DEFINE3(rt_sigqueueinfo,
 			int, sig,
 			struct compat_siginfo __user *, uinfo)
 {
-	siginfo_t info = {};
+	siginfo_t info;
 	int ret = copy_siginfo_from_user32(&info, uinfo);
 	if (unlikely(ret))
 		return ret;
@@ -3199,7 +3199,7 @@ COMPAT_SYSCALL_DEFINE4(rt_tgsigqueueinfo,
 			int, sig,
 			struct compat_siginfo __user *, uinfo)
 {
-	siginfo_t info = {};
+	siginfo_t info;
 
 	if (copy_siginfo_from_user32(&info, uinfo))
 		return -EFAULT;

commit 212a36a17efe4d696d1e3c31ebd79a9fb0cbb14b
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Jul 31 17:15:31 2017 -0500

    signal: Unify and correct copy_siginfo_from_user32
    
    The function copy_siginfo_from_user32 is used for two things, in ptrace
    since the dawn of siginfo for arbirarily modifying a signal that
    user space sees, and in sigqueueinfo to send a signal with arbirary
    siginfo data.
    
    Create a single copy of copy_siginfo_from_user32 that all architectures
    share, and teach it to handle all of the cases in the siginfo union.
    
    In the generic version of copy_siginfo_from_user32 ensure that all
    of the fields in siginfo are initialized so that the siginfo structure
    can be safely copied to userspace if necessary.
    
    When copying the embedded sigval union copy the si_int member.  That
    ensures the 32bit values passes through the kernel unchanged.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 4c3f4448c5f1..5211b1b57163 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2814,6 +2814,87 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 	return err;
 }
 
+#ifdef CONFIG_COMPAT
+int copy_siginfo_from_user32(struct siginfo *to,
+			     const struct compat_siginfo __user *ufrom)
+{
+	struct compat_siginfo from;
+
+	if (copy_from_user(&from, ufrom, sizeof(struct compat_siginfo)))
+		return -EFAULT;
+
+	clear_siginfo(to);
+	to->si_signo = from.si_signo;
+	to->si_errno = from.si_errno;
+	to->si_code  = from.si_code;
+	switch(siginfo_layout(from.si_signo, from.si_code)) {
+	case SIL_KILL:
+		to->si_pid = from.si_pid;
+		to->si_uid = from.si_uid;
+		break;
+	case SIL_TIMER:
+		to->si_tid     = from.si_tid;
+		to->si_overrun = from.si_overrun;
+		to->si_int     = from.si_int;
+		break;
+	case SIL_POLL:
+		to->si_band = from.si_band;
+		to->si_fd   = from.si_fd;
+		break;
+	case SIL_FAULT:
+		to->si_addr = compat_ptr(from.si_addr);
+#ifdef __ARCH_SI_TRAPNO
+		to->si_trapno = from.si_trapno;
+#endif
+#ifdef BUS_MCEERR_AR
+		if ((from.si_signo == SIGBUS) && (from.si_code == BUS_MCEERR_AR))
+			to->si_addr_lsb = from.si_addr_lsb;
+#endif
+#ifdef BUS_MCEER_AO
+		if ((from.si_signo == SIGBUS) && (from.si_code == BUS_MCEERR_AO))
+			to->si_addr_lsb = from.si_addr_lsb;
+#endif
+#ifdef SEGV_BNDERR
+		if ((from.si_signo == SIGSEGV) && (from.si_code == SEGV_BNDERR)) {
+			to->si_lower = compat_ptr(from.si_lower);
+			to->si_upper = compat_ptr(from.si_upper);
+		}
+#endif
+#ifdef SEGV_PKUERR
+		if ((from.si_signo == SIGSEGV) && (from.si_code == SEGV_PKUERR))
+			to->si_pkey = from.si_pkey;
+#endif
+		break;
+	case SIL_CHLD:
+		to->si_pid    = from.si_pid;
+		to->si_uid    = from.si_uid;
+		to->si_status = from.si_status;
+#ifdef CONFIG_X86_X32_ABI
+		if (in_x32_syscall()) {
+			to->si_utime = from._sifields._sigchld_x32._utime;
+			to->si_stime = from._sifields._sigchld_x32._stime;
+		} else
+#endif
+		{
+			to->si_utime = from.si_utime;
+			to->si_stime = from.si_stime;
+		}
+		break;
+	case SIL_RT:
+		to->si_pid = from.si_pid;
+		to->si_uid = from.si_uid;
+		to->si_int = from.si_int;
+		break;
+	case SIL_SYS:
+		to->si_call_addr = compat_ptr(from.si_call_addr);
+		to->si_syscall   = from.si_syscall;
+		to->si_arch      = from.si_arch;
+		break;
+	}
+	return 0;
+}
+#endif /* CONFIG_COMPAT */
+
 /**
  *  do_sigtimedwait - wait for queued signals specified in @which
  *  @which: queued signals to wait for

commit 71ee78d538a7bcb7a876dcbd65eb73627425df6f
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Jan 13 18:25:09 2018 -0600

    signal/blackfin: Move the blackfin specific si_codes to asm-generic/siginfo.h
    
    Having si_codes in many different files simply encourages duplicate definitions
    that can cause problems later.  To avoid that merge the blackfin specific si_codes
    into uapi/asm-generic/siginfo.h
    
    Update copy_siginfo_to_user to copy with the absence of BUS_MCEERR_AR that blackfin
    defines to be something else.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 47c87b1d0b8a..4c3f4448c5f1 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2770,13 +2770,16 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 		err |= __put_user(from->si_flags, &to->si_flags);
 		err |= __put_user(from->si_isr, &to->si_isr);
 #endif
-#ifdef BUS_MCEERR_AO
 		/*
 		 * Other callers might not initialize the si_lsb field,
 		 * so check explicitly for the right codes here.
 		 */
-		if (from->si_signo == SIGBUS &&
-		    (from->si_code == BUS_MCEERR_AR || from->si_code == BUS_MCEERR_AO))
+#ifdef BUS_MCEERR_AR
+		if (from->si_signo == SIGBUS && from->si_code == BUS_MCEERR_AR)
+			err |= __put_user(from->si_addr_lsb, &to->si_addr_lsb);
+#endif
+#ifdef BUS_MCEERR_AO
+		if (from->si_signo == SIGBUS && from->si_code == BUS_MCEERR_AO)
 			err |= __put_user(from->si_addr_lsb, &to->si_addr_lsb);
 #endif
 #ifdef SEGV_BNDERR

commit 0326e7ef057d214ed43a77557078c24e98b84af9
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Jul 27 11:59:46 2017 -0500

    signal: Remove unnecessary ifdefs now that there is only one struct siginfo
    
    Remove HAVE_ARCH_SIGINFO_T
    Remove __ARCH_SIGSYS
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 62c642899290..47c87b1d0b8a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2697,9 +2697,7 @@ enum siginfo_layout siginfo_layout(int sig, int si_code)
 #endif
 			[SIGCHLD] = { NSIGCHLD, SIL_CHLD },
 			[SIGPOLL] = { NSIGPOLL, SIL_POLL },
-#ifdef __ARCH_SIGSYS
 			[SIGSYS]  = { NSIGSYS,  SIL_SYS },
-#endif
 		};
 		if ((sig < ARRAY_SIZE(filter)) && (si_code <= filter[sig].limit))
 			layout = filter[sig].layout;
@@ -2804,13 +2802,11 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 		err |= __put_user(from->si_uid, &to->si_uid);
 		err |= __put_user(from->si_ptr, &to->si_ptr);
 		break;
-#ifdef __ARCH_SIGSYS
 	case SIL_SYS:
 		err |= __put_user(from->si_call_addr, &to->si_call_addr);
 		err |= __put_user(from->si_syscall, &to->si_syscall);
 		err |= __put_user(from->si_arch, &to->si_arch);
 		break;
-#endif
 	}
 	return err;
 }

commit 30073566ca64cbc005f4fbcc21f0af7db83940a2
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Jul 31 15:47:40 2017 -0500

    signal/ia64: switch the last arch-specific copy_siginfo_to_user() to generic version
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 18aa55c1bb4f..62c642899290 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2729,8 +2729,6 @@ enum siginfo_layout siginfo_layout(int sig, int si_code)
 	return layout;
 }
 
-#ifndef HAVE_ARCH_COPY_SIGINFO_TO_USER
-
 int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 {
 	int err;
@@ -2769,6 +2767,11 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 #ifdef __ARCH_SI_TRAPNO
 		err |= __put_user(from->si_trapno, &to->si_trapno);
 #endif
+#ifdef __ia64__
+		err |= __put_user(from->si_imm, &to->si_imm);
+		err |= __put_user(from->si_flags, &to->si_flags);
+		err |= __put_user(from->si_isr, &to->si_isr);
+#endif
 #ifdef BUS_MCEERR_AO
 		/*
 		 * Other callers might not initialize the si_lsb field,
@@ -2812,8 +2815,6 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 	return err;
 }
 
-#endif
-
 /**
  *  do_sigtimedwait - wait for queued signals specified in @which
  *  @which: queued signals to wait for

commit 9943d3accb4ec5a85e72c65a9959257fa7d12500
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Jul 24 14:53:03 2017 -0500

    signal: Clear si_sys_private before copying siginfo to userspace
    
    In preparation for unconditionally copying the whole of siginfo
    to userspace clear si_sys_private.  So this kernel internal
    value is guaranteed not to make it to userspace.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index b9e5d825ee46..18aa55c1bb4f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -643,6 +643,9 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 		spin_unlock(&tsk->sighand->siglock);
 		posixtimer_rearm(info);
 		spin_lock(&tsk->sighand->siglock);
+
+		/* Don't expose the si_sys_private value to userspace */
+		info->si_sys_private = 0;
 	}
 #endif
 	return signr;

commit aba1be2f8c26ea322dd9c43047c1aff90528f032
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Jul 19 21:23:15 2017 -0500

    signal: Ensure no siginfo union member increases the size of struct siginfo
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 241d54958bbb..b9e5d825ee46 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3688,6 +3688,7 @@ void __init signals_init(void)
 	/* If this check fails, the __ARCH_SI_PREAMBLE_SIZE value is wrong! */
 	BUILD_BUG_ON(__ARCH_SI_PREAMBLE_SIZE
 		!= offsetof(struct siginfo, _sifields._pad));
+	BUILD_BUG_ON(sizeof(struct siginfo) != SI_MAX_SIZE);
 
 	sigqueue_cachep = KMEM_CACHE(sigqueue, SLAB_PANIC);
 }

commit faf1f22b61f2715224ba9b579e2a983e99b86823
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Jan 5 17:27:42 2018 -0600

    signal: Ensure generic siginfos the kernel sends have all bits initialized
    
    Call clear_siginfo to ensure stack allocated siginfos are fully
    initialized before being passed to the signal sending functions.
    
    This ensures that if there is the kind of confusion documented by
    TRAP_FIXME, FPE_FIXME, or BUS_FIXME the kernel won't send unitialized
    data to userspace when the kernel generates a signal with SI_USER but
    the copy to userspace assumes it is a different kind of signal, and
    different fields are initialized.
    
    This also prepares the way for turning copy_siginfo_to_user
    into a copy_to_user, by removing the need in many cases to perform
    a field by field copy simply to skip the uninitialized fields.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index fd182a845490..241d54958bbb 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -549,6 +549,7 @@ static void collect_signal(int sig, struct sigpending *list, siginfo_t *info,
 		 * a fast-pathed signal or we must have been
 		 * out of queue space.  So zero out the info.
 		 */
+		clear_siginfo(info);
 		info->si_signo = sig;
 		info->si_errno = 0;
 		info->si_code = SI_USER;
@@ -1043,6 +1044,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 		list_add_tail(&q->list, &pending->list);
 		switch ((unsigned long) info) {
 		case (unsigned long) SEND_SIG_NOINFO:
+			clear_siginfo(&q->info);
 			q->info.si_signo = sig;
 			q->info.si_errno = 0;
 			q->info.si_code = SI_USER;
@@ -1051,6 +1053,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			q->info.si_uid = from_kuid_munged(current_user_ns(), current_uid());
 			break;
 		case (unsigned long) SEND_SIG_PRIV:
+			clear_siginfo(&q->info);
 			q->info.si_signo = sig;
 			q->info.si_errno = 0;
 			q->info.si_code = SI_KERNEL;
@@ -1623,6 +1626,7 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 			sig = SIGCHLD;
 	}
 
+	clear_siginfo(&info);
 	info.si_signo = sig;
 	info.si_errno = 0;
 	/*
@@ -1717,6 +1721,7 @@ static void do_notify_parent_cldstop(struct task_struct *tsk,
 		parent = tsk->real_parent;
 	}
 
+	clear_siginfo(&info);
 	info.si_signo = SIGCHLD;
 	info.si_errno = 0;
 	/*
@@ -1929,7 +1934,7 @@ static void ptrace_do_notify(int signr, int exit_code, int why)
 {
 	siginfo_t info;
 
-	memset(&info, 0, sizeof info);
+	clear_siginfo(&info);
 	info.si_signo = signr;
 	info.si_code = exit_code;
 	info.si_pid = task_pid_vnr(current);
@@ -2136,6 +2141,7 @@ static int ptrace_signal(int signr, siginfo_t *info)
 	 * have updated *info via PTRACE_SETSIGINFO.
 	 */
 	if (signr != info->si_signo) {
+		clear_siginfo(info);
 		info->si_signo = signr;
 		info->si_errno = 0;
 		info->si_code = SI_USER;
@@ -2941,6 +2947,7 @@ SYSCALL_DEFINE2(kill, pid_t, pid, int, sig)
 {
 	struct siginfo info;
 
+	clear_siginfo(&info);
 	info.si_signo = sig;
 	info.si_errno = 0;
 	info.si_code = SI_USER;

commit 526c3ddb6aa270fe6f71d227eac1e189746cc257
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Jan 3 18:07:12 2018 -0600

    signal/arm64: Document conflicts with SI_USER and SIGFPE,SIGTRAP,SIGBUS
    
    Setting si_code to 0 results in a userspace seeing an si_code of 0.
    This is the same si_code as SI_USER.  Posix and common sense requires
    that SI_USER not be a signal specific si_code.  As such this use of 0
    for the si_code is a pretty horribly broken ABI.
    
    Further use of si_code == 0 guaranteed that copy_siginfo_to_user saw a
    value of __SI_KILL and now sees a value of SIL_KILL with the result
    that uid and pid fields are copied and which might copying the si_addr
    field by accident but certainly not by design.  Making this a very
    flakey implementation.
    
    Utilizing FPE_FIXME, BUS_FIXME, TRAP_FIXME siginfo_layout will now return
    SIL_FAULT and the appropriate fields will be reliably copied.
    
    But folks this is a new and unique kind of bad.  This is massively
    untested code bad.  This is inventing new and unique was to get
    siginfo wrong bad.  This is don't even think about Posix or what
    siginfo means bad.  This is lots of eyeballs all missing the fact
    that the code does the wrong thing bad.  This is getting stuck
    and keep making the same mistake bad.
    
    I really hope we can find a non userspace breaking fix for this on a
    port as new as arm64.
    
    Possible ABI fixes include:
    - Send the signal without siginfo
    - Don't generate a signal
    - Possibly assign and use an appropriate si_code
    - Don't handle cases which can't happen
    
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Tyler Baicar <tbaicar@codeaurora.org>
    Cc: James Morse <james.morse@arm.com>
    Cc: Tony Lindgren <tony@atomide.com>
    Cc: Nicolas Pitre <nico@linaro.org>
    Cc: Olof Johansson <olof@lixom.net>
    Cc: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: linux-arm-kernel@lists.infradead.org
    Ref: 53631b54c870 ("arm64: Floating point and SIMD")
    Ref: 32015c235603 ("arm64: exception: handle Synchronous External Abort")
    Ref: 1d18c47c735e ("arm64: MMU fault handling and page table management")
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index c894162ec96c..fd182a845490 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2711,6 +2711,10 @@ enum siginfo_layout siginfo_layout(int sig, int si_code)
 #ifdef FPE_FIXME
 		if ((sig == SIGFPE) && (si_code == FPE_FIXME))
 			layout = SIL_FAULT;
+#endif
+#ifdef BUS_FIXME
+		if ((sig == SIGBUS) && (si_code == BUS_FIXME))
+			layout = SIL_FAULT;
 #endif
 	}
 	return layout;

commit 0b44bf9a6f5cde099ae21b4aa94553484203769a
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Aug 17 15:45:38 2017 -0500

    signal: Simplify and fix kdb_send_sig
    
    - Rename from kdb_send_sig_info to kdb_send_sig
      As there is no meaningful siginfo sent
    
    - Use SEND_SIG_PRIV instead of generating a siginfo for a kdb
      signal.  The generated siginfo had a bogus rationale and was
      not correct in the face of pid namespaces.  SEND_SIG_PRIV
      is simpler and actually correct.
    
    - As the code grabs siglock just send the signal with siglock
      held instead of dropping siglock and attempting to grab it again.
    
    - Move the sig_valid test into kdb_kill where it can generate
      a good error message.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9558664bd9ec..c894162ec96c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3684,26 +3684,25 @@ void __init signals_init(void)
 #ifdef CONFIG_KGDB_KDB
 #include <linux/kdb.h>
 /*
- * kdb_send_sig_info - Allows kdb to send signals without exposing
+ * kdb_send_sig - Allows kdb to send signals without exposing
  * signal internals.  This function checks if the required locks are
  * available before calling the main signal code, to avoid kdb
  * deadlocks.
  */
-void
-kdb_send_sig_info(struct task_struct *t, struct siginfo *info)
+void kdb_send_sig(struct task_struct *t, int sig)
 {
 	static struct task_struct *kdb_prev_t;
-	int sig, new_t;
+	int new_t, ret;
 	if (!spin_trylock(&t->sighand->siglock)) {
 		kdb_printf("Can't do kill command now.\n"
 			   "The sigmask lock is held somewhere else in "
 			   "kernel, try again later\n");
 		return;
 	}
-	spin_unlock(&t->sighand->siglock);
 	new_t = kdb_prev_t != t;
 	kdb_prev_t = t;
 	if (t->state != TASK_RUNNING && new_t) {
+		spin_unlock(&t->sighand->siglock);
 		kdb_printf("Process is not RUNNING, sending a signal from "
 			   "kdb risks deadlock\n"
 			   "on the run queue locks. "
@@ -3712,8 +3711,9 @@ kdb_send_sig_info(struct task_struct *t, struct siginfo *info)
 			   "the deadlock.\n");
 		return;
 	}
-	sig = info->si_signo;
-	if (send_sig_info(sig, info, t))
+	ret = send_signal(sig, SEND_SIG_PRIV, t, false);
+	spin_unlock(&t->sighand->siglock);
+	if (ret)
 		kdb_printf("Fail to deliver Signal %d to process %d.\n",
 			   sig, t->pid);
 	else

commit 43347d56c8d9dd732cee2f8efd384ad21dd1f6c4
Author: Miroslav Benes <mbenes@suse.cz>
Date:   Wed Nov 15 14:50:13 2017 +0100

    livepatch: send a fake signal to all blocking tasks
    
    Live patching consistency model is of LEAVE_PATCHED_SET and
    SWITCH_THREAD. This means that all tasks in the system have to be marked
    one by one as safe to call a new patched function. Safe means when a
    task is not (sleeping) in a set of patched functions. That is, no
    patched function is on the task's stack. Another clearly safe place is
    the boundary between kernel and userspace. The patching waits for all
    tasks to get outside of the patched set or to cross the boundary. The
    transition is completed afterwards.
    
    The problem is that a task can block the transition for quite a long
    time, if not forever. It could sleep in a set of patched functions, for
    example.  Luckily we can force the task to leave the set by sending it a
    fake signal, that is a signal with no data in signal pending structures
    (no handler, no sign of proper signal delivered). Suspend/freezer use
    this to freeze the tasks as well. The task gets TIF_SIGPENDING set and
    is woken up (if it has been sleeping in the kernel before) or kicked by
    rescheduling IPI (if it was running on other CPU). This causes the task
    to go to kernel/userspace boundary where the signal would be handled and
    the task would be marked as safe in terms of live patching.
    
    There are tasks which are not affected by this technique though. The
    fake signal is not sent to kthreads. They should be handled differently.
    They can be woken up so they leave the patched set and their
    TIF_PATCH_PENDING can be cleared thanks to stack checking.
    
    For the sake of completeness, if the task is in TASK_RUNNING state but
    not currently running on some CPU it doesn't get the IPI, but it would
    eventually handle the signal anyway. Second, if the task runs in the
    kernel (in TASK_RUNNING state) it gets the IPI, but the signal is not
    handled on return from the interrupt. It would be handled on return to
    the userspace in the future when the fake signal is sent again. Stack
    checking deals with these cases in a better way.
    
    If the task was sleeping in a syscall it would be woken by our fake
    signal, it would check if TIF_SIGPENDING is set (by calling
    signal_pending() predicate) and return ERESTART* or EINTR. Syscalls with
    ERESTART* return values are restarted in case of the fake signal (see
    do_signal()). EINTR is propagated back to the userspace program. This
    could disturb the program, but...
    
    * each process dealing with signals should react accordingly to EINTR
      return values.
    * syscalls returning EINTR happen to be quite common situation in the
      system even if no fake signal is sent.
    * freezer sends the fake signal and does not deal with EINTR anyhow.
      Thus EINTR values are returned when the system is resumed.
    
    The very safe marking is done in architectures' "entry" on syscall and
    interrupt/exception exit paths, and in a stack checking functions of
    livepatch.  TIF_PATCH_PENDING is cleared and the next
    recalc_sigpending() drops TIF_SIGPENDING. In connection with this, also
    call klp_update_patch_state() before do_signal(), so that
    recalc_sigpending() in dequeue_signal() can clear TIF_PATCH_PENDING
    immediately and thus prevent a double call of do_signal().
    
    Note that the fake signal is not sent to stopped/traced tasks. Such task
    prevents the patching to finish till it continues again (is not traced
    anymore).
    
    Last, sending the fake signal is not automatic. It is done only when
    admin requests it by writing 1 to signal sysfs attribute in livepatch
    sysfs directory.
    
    Signed-off-by: Miroslav Benes <mbenes@suse.cz>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: x86@kernel.org
    Acked-by: Michael Ellerman <mpe@ellerman.id.au> (powerpc)
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8dcd8825b2de..186143b06d00 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -40,6 +40,7 @@
 #include <linux/cn_proc.h>
 #include <linux/compiler.h>
 #include <linux/posix-timers.h>
+#include <linux/livepatch.h>
 
 #define CREATE_TRACE_POINTS
 #include <trace/events/signal.h>
@@ -163,7 +164,8 @@ void recalc_sigpending_and_wake(struct task_struct *t)
 
 void recalc_sigpending(void)
 {
-	if (!recalc_sigpending_tsk(current) && !freezing(current))
+	if (!recalc_sigpending_tsk(current) && !freezing(current) &&
+	    !klp_patch_pending(current))
 		clear_thread_flag(TIF_SIGPENDING);
 
 }

commit fa7f578076a8814caa5371e9f4949e408140766d
Merge: 2dcd9c71c1ff d1b069f5febc
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 17 16:56:17 2017 -0800

    Merge branch 'akpm' (patches from Andrew)
    
    Merge more updates from Andrew Morton:
    
     - a bit more MM
    
     - procfs updates
    
     - dynamic-debug fixes
    
     - lib/ updates
    
     - checkpatch
    
     - epoll
    
     - nilfs2
    
     - signals
    
     - rapidio
    
     - PID management cleanup and optimization
    
     - kcov updates
    
     - sysvipc updates
    
     - quite a few misc things all over the place
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (94 commits)
      EXPERT Kconfig menu: fix broken EXPERT menu
      include/asm-generic/topology.h: remove unused parent_node() macro
      arch/tile/include/asm/topology.h: remove unused parent_node() macro
      arch/sparc/include/asm/topology_64.h: remove unused parent_node() macro
      arch/sh/include/asm/topology.h: remove unused parent_node() macro
      arch/ia64/include/asm/topology.h: remove unused parent_node() macro
      drivers/pcmcia/sa1111_badge4.c: avoid unused function warning
      mm: add infrastructure for get_user_pages_fast() benchmarking
      sysvipc: make get_maxid O(1) again
      sysvipc: properly name ipc_addid() limit parameter
      sysvipc: duplicate lock comments wrt ipc_addid()
      sysvipc: unteach ids->next_id for !CHECKPOINT_RESTORE
      initramfs: use time64_t timestamps
      drivers/watchdog: make use of devm_register_reboot_notifier()
      kernel/reboot.c: add devm_register_reboot_notifier()
      kcov: update documentation
      Makefile: support flag -fsanitizer-coverage=trace-cmp
      kcov: support comparison operands collection
      kcov: remove pointless current != NULL check
      kernel/panic.c: add TAINT_AUX
      ...

commit 426915796ccaf9c2bd9bb06dc5702225957bc2e5
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Nov 17 15:30:08 2017 -0800

    kernel/signal.c: remove the no longer needed SIGNAL_UNKILLABLE check in complete_signal()
    
    complete_signal() checks SIGNAL_UNKILLABLE before it starts to destroy
    the thread group, today this is wrong in many ways.
    
    If nothing else, fatal_signal_pending() should always imply that the
    whole thread group (except ->group_exit_task if it is not NULL) is
    killed, this check breaks the rule.
    
    After the previous changes we can rely on sig_task_ignored();
    sig_fatal(sig) && SIGNAL_UNKILLABLE can only be true if we actually want
    to kill this task and sig == SIGKILL OR it is traced and debugger can
    intercept the signal.
    
    This should hopefully fix the problem reported by Dmitry.  This
    test-case
    
            static int init(void *arg)
            {
                    for (;;)
                            pause();
            }
    
            int main(void)
            {
                    char stack[16 * 1024];
    
                    for (;;) {
                            int pid = clone(init, stack + sizeof(stack)/2,
                                            CLONE_NEWPID | SIGCHLD, NULL);
                            assert(pid > 0);
    
                            assert(ptrace(PTRACE_ATTACH, pid, 0, 0) == 0);
                            assert(waitpid(-1, NULL, WSTOPPED) == pid);
    
                            assert(ptrace(PTRACE_DETACH, pid, 0, SIGSTOP) == 0);
                            assert(syscall(__NR_tkill, pid, SIGKILL) == 0);
                            assert(pid == wait(NULL));
                    }
            }
    
    triggers the WARN_ON_ONCE(!(task->jobctl & JOBCTL_STOP_PENDING)) in
    task_participate_group_stop().  do_signal_stop()->signal_group_exit()
    checks SIGNAL_GROUP_EXIT and return false, but task_set_jobctl_pending()
    checks fatal_signal_pending() and does not set JOBCTL_STOP_PENDING.
    
    And his should fix the minor security problem reported by Kyle,
    SECCOMP_RET_TRACE can miss fatal_signal_pending() the same way if the
    task is the root of a pid namespace.
    
    Link: http://lkml.kernel.org/r/20171103184246.GD21036@redhat.com
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Reported-by: Kyle Huey <me@kylehuey.com>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Tested-by: Kyle Huey <me@kylehuey.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 01ba166a5e3a..6895f6bb98a7 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -931,9 +931,9 @@ static void complete_signal(int sig, struct task_struct *p, int group)
 	 * then start taking the whole group down immediately.
 	 */
 	if (sig_fatal(p, sig) &&
-	    !(signal->flags & (SIGNAL_UNKILLABLE | SIGNAL_GROUP_EXIT)) &&
+	    !(signal->flags & SIGNAL_GROUP_EXIT) &&
 	    !sigismember(&t->real_blocked, sig) &&
-	    (sig == SIGKILL || !t->ptrace)) {
+	    (sig == SIGKILL || !p->ptrace)) {
 		/*
 		 * This signal will be fatal to the whole group.
 		 */

commit ac25385089f673560867eb5179228a44ade0cfc1
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Nov 17 15:30:04 2017 -0800

    kernel/signal.c: protect the SIGNAL_UNKILLABLE tasks from !sig_kernel_only() signals
    
    Change sig_task_ignored() to drop the SIG_DFL && !sig_kernel_only()
    signals even if force == T.  This simplifies the next change and this
    matches the same check in get_signal() which will drop these signals
    anyway.
    
    Link: http://lkml.kernel.org/r/20171103184227.GC21036@redhat.com
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Tested-by: Kyle Huey <me@kylehuey.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index be5913134742..01ba166a5e3a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -78,7 +78,7 @@ static int sig_task_ignored(struct task_struct *t, int sig, bool force)
 	handler = sig_handler(t, sig);
 
 	if (unlikely(t->signal->flags & SIGNAL_UNKILLABLE) &&
-			handler == SIG_DFL && !force)
+	    handler == SIG_DFL && !(force && sig_kernel_only(sig)))
 		return 1;
 
 	return sig_handler_ignored(handler, sig);

commit 628c1bcba204052d19b686b5bac149a644cdb72e
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Nov 17 15:30:01 2017 -0800

    kernel/signal.c: protect the traced SIGNAL_UNKILLABLE tasks from SIGKILL
    
    The comment in sig_ignored() says "Tracers may want to know about even
    ignored signals" but SIGKILL can not be reported to debugger and it is
    just wrong to return 0 in this case: SIGKILL should only kill the
    SIGNAL_UNKILLABLE task if it comes from the parent ns.
    
    Change sig_ignored() to ignore ->ptrace if sig == SIGKILL and rely on
    sig_task_ignored().
    
    SISGTOP coming from within the namespace is not really right too but at
    least debugger can intercept it, and we can't drop it here because this
    will break "gdb -p 1": ptrace_attach() won't work.  Perhaps we will add
    another ->ptrace check later, we will see.
    
    Link: http://lkml.kernel.org/r/20171103184206.GB21036@redhat.com
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Tested-by: Kyle Huey <me@kylehuey.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index aa1fb9f905db..be5913134742 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -94,13 +94,15 @@ static int sig_ignored(struct task_struct *t, int sig, bool force)
 	if (sigismember(&t->blocked, sig) || sigismember(&t->real_blocked, sig))
 		return 0;
 
-	if (!sig_task_ignored(t, sig, force))
-		return 0;
-
 	/*
-	 * Tracers may want to know about even ignored signals.
+	 * Tracers may want to know about even ignored signal unless it
+	 * is SIGKILL which can't be reported anyway but can be ignored
+	 * by SIGNAL_UNKILLABLE task.
 	 */
-	return !t->ptrace;
+	if (t->ptrace && sig != SIGKILL)
+		return 0;
+
+	return sig_task_ignored(t, sig, force);
 }
 
 /*

commit 93f30c73ecd0281cf3685ef0e4e384980a176176
Merge: 06ede5f60867 96271654f55c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 17 11:54:55 2017 -0800

    Merge branch 'misc.compat' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull compat and uaccess updates from Al Viro:
    
     - {get,put}_compat_sigset() series
    
     - assorted compat ioctl stuff
    
     - more set_fs() elimination
    
     - a few more timespec64 conversions
    
     - several removals of pointless access_ok() in places where it was
       followed only by non-__ variants of primitives
    
    * 'misc.compat' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (24 commits)
      coredump: call do_unlinkat directly instead of sys_unlink
      fs: expose do_unlinkat for built-in callers
      ext4: take handling of EXT4_IOC_GROUP_ADD into a helper, get rid of set_fs()
      ipmi: get rid of pointless access_ok()
      pi433: sanitize ioctl
      cxlflash: get rid of pointless access_ok()
      mtdchar: get rid of pointless access_ok()
      r128: switch compat ioctls to drm_ioctl_kernel()
      selection: get rid of field-by-field copyin
      VT_RESIZEX: get rid of field-by-field copyin
      i2c compat ioctls: move to ->compat_ioctl()
      sched_rr_get_interval(): move compat to native, get rid of set_fs()
      mips: switch to {get,put}_compat_sigset()
      sparc: switch to {get,put}_compat_sigset()
      s390: switch to {get,put}_compat_sigset()
      ppc: switch to {get,put}_compat_sigset()
      parisc: switch to {get,put}_compat_sigset()
      get_compat_sigset()
      get rid of {get,put}_compat_itimerspec()
      io_getevents: Use timespec64 to represent timeouts
      ...

commit 75f296d93bcebcfe375884ddac79e30263a31766
Author: Levin, Alexander (Sasha Levin) <alexander.levin@verizon.com>
Date:   Wed Nov 15 17:35:54 2017 -0800

    kmemcheck: stop using GFP_NOTRACK and SLAB_NOTRACK
    
    Convert all allocations that used a NOTRACK flag to stop using it.
    
    Link: http://lkml.kernel.org/r/20171007030159.22241-3-alexander.levin@verizon.com
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Pekka Enberg <penberg@kernel.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Tim Hansen <devtimhansen@gmail.com>
    Cc: Vegard Nossum <vegardno@ifi.uio.no>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8dcd8825b2de..aa1fb9f905db 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1036,8 +1036,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	else
 		override_rlimit = 0;
 
-	q = __sigqueue_alloc(sig, t, GFP_ATOMIC | __GFP_NOTRACK_FALSE_POSITIVE,
-		override_rlimit);
+	q = __sigqueue_alloc(sig, t, GFP_ATOMIC, override_rlimit);
 	if (q) {
 		list_add_tail(&q->list, &pending->list);
 		switch ((unsigned long) info) {

commit c3aff086ea11f17f5c0bec77bdbf4365ba6b41fc
Author: Andrew Clayton <andrew@digital-domain.net>
Date:   Wed Nov 1 15:49:59 2017 +0000

    signal: Fix name of SIGEMT in #if defined() check
    
    Commit cc731525f26a ("signal: Remove kernel interal si_code magic")
    added a check for SIGMET and NSIGEMT being defined. That SIGMET should
    in fact be SIGEMT, with SIGEMT being defined in
    arch/{alpha,mips,sparc}/include/uapi/asm/signal.h
    
    This was actually pointed out by BenHutchings in a lwn.net comment
    here https://lwn.net/Comments/734608/
    
    Fixes: cc731525f26a ("signal: Remove kernel interal si_code magic")
    Signed-off-by: Andrew Clayton <andrew@digital-domain.net>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 800a18f77732..8dcd8825b2de 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2698,7 +2698,7 @@ enum siginfo_layout siginfo_layout(int sig, int si_code)
 			[SIGSEGV] = { NSIGSEGV, SIL_FAULT },
 			[SIGBUS]  = { NSIGBUS,  SIL_FAULT },
 			[SIGTRAP] = { NSIGTRAP, SIL_FAULT },
-#if defined(SIGMET) && defined(NSIGEMT)
+#if defined(SIGEMT) && defined(NSIGEMT)
 			[SIGEMT]  = { NSIGEMT,  SIL_FAULT },
 #endif
 			[SIGCHLD] = { NSIGCHLD, SIL_CHLD },

commit 3968cf623892d710e651070243fd16af312a9797
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Sep 3 21:45:17 2017 -0400

    get_compat_sigset()
    
    similar to put_compat_sigset()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9fbc574ced10..36a523640894 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2600,7 +2600,6 @@ SYSCALL_DEFINE4(rt_sigprocmask, int, how, sigset_t __user *, nset,
 COMPAT_SYSCALL_DEFINE4(rt_sigprocmask, int, how, compat_sigset_t __user *, nset,
 		compat_sigset_t __user *, oset, compat_size_t, sigsetsize)
 {
-#ifdef __BIG_ENDIAN
 	sigset_t old_set = current->blocked;
 
 	/* XXX: Don't preclude handling different sized sigset_t's.  */
@@ -2608,13 +2607,10 @@ COMPAT_SYSCALL_DEFINE4(rt_sigprocmask, int, how, compat_sigset_t __user *, nset,
 		return -EINVAL;
 
 	if (nset) {
-		compat_sigset_t new32;
 		sigset_t new_set;
 		int error;
-		if (copy_from_user(&new32, nset, sizeof(compat_sigset_t)))
+		if (get_compat_sigset(&new_set, nset))
 			return -EFAULT;
-
-		sigset_from_compat(&new_set, &new32);
 		sigdelsetmask(&new_set, sigmask(SIGKILL)|sigmask(SIGSTOP));
 
 		error = sigprocmask(how, &new_set, NULL);
@@ -2622,10 +2618,6 @@ COMPAT_SYSCALL_DEFINE4(rt_sigprocmask, int, how, compat_sigset_t __user *, nset,
 			return error;
 	}
 	return oset ? put_compat_sigset(oset, &old_set, sizeof(*oset)) : 0;
-#else
-	return sys_rt_sigprocmask(how, (sigset_t __user *)nset,
-				  (sigset_t __user *)oset, sigsetsize);
-#endif
 }
 #endif
 
@@ -2908,7 +2900,6 @@ COMPAT_SYSCALL_DEFINE4(rt_sigtimedwait, compat_sigset_t __user *, uthese,
 		struct compat_siginfo __user *, uinfo,
 		struct compat_timespec __user *, uts, compat_size_t, sigsetsize)
 {
-	compat_sigset_t s32;
 	sigset_t s;
 	struct timespec t;
 	siginfo_t info;
@@ -2917,9 +2908,8 @@ COMPAT_SYSCALL_DEFINE4(rt_sigtimedwait, compat_sigset_t __user *, uthese,
 	if (sigsetsize != sizeof(sigset_t))
 		return -EINVAL;
 
-	if (copy_from_user(&s32, uthese, sizeof(compat_sigset_t)))
+	if (get_compat_sigset(&s, uthese))
 		return -EFAULT;
-	sigset_from_compat(&s, &s32);
 
 	if (uts) {
 		if (compat_get_timespec(&t, uts))
@@ -3450,18 +3440,16 @@ COMPAT_SYSCALL_DEFINE4(rt_sigaction, int, sig,
 
 	if (act) {
 		compat_uptr_t handler;
-		compat_sigset_t mask;
 		ret = get_user(handler, &act->sa_handler);
 		new_ka.sa.sa_handler = compat_ptr(handler);
 #ifdef __ARCH_HAS_SA_RESTORER
 		ret |= get_user(restorer, &act->sa_restorer);
 		new_ka.sa.sa_restorer = compat_ptr(restorer);
 #endif
-		ret |= copy_from_user(&mask, &act->sa_mask, sizeof(mask));
+		ret |= get_compat_sigset(&new_ka.sa.sa_mask, &act->sa_mask);
 		ret |= get_user(new_ka.sa.sa_flags, &act->sa_flags);
 		if (ret)
 			return -EFAULT;
-		sigset_from_compat(&new_ka.sa.sa_mask, &mask);
 	}
 
 	ret = do_sigaction(sig, act ? &new_ka : NULL, oact ? &old_ka : NULL);
@@ -3649,22 +3637,15 @@ SYSCALL_DEFINE2(rt_sigsuspend, sigset_t __user *, unewset, size_t, sigsetsize)
 #ifdef CONFIG_COMPAT
 COMPAT_SYSCALL_DEFINE2(rt_sigsuspend, compat_sigset_t __user *, unewset, compat_size_t, sigsetsize)
 {
-#ifdef __BIG_ENDIAN
 	sigset_t newset;
-	compat_sigset_t newset32;
 
 	/* XXX: Don't preclude handling different sized sigset_t's.  */
 	if (sigsetsize != sizeof(sigset_t))
 		return -EINVAL;
 
-	if (copy_from_user(&newset32, unewset, sizeof(compat_sigset_t)))
+	if (get_compat_sigset(&newset, unewset))
 		return -EFAULT;
-	sigset_from_compat(&newset, &newset32);
 	return sigsuspend(&newset);
-#else
-	/* on little-endian bitmaps don't care about granularity */
-	return sys_rt_sigsuspend((sigset_t __user *)unewset, sigsetsize);
-#endif
 }
 #endif
 

commit 176826af03666758c656dd27f098cc889b71638b
Author: Dmitry V. Levin <ldv@altlinux.org>
Date:   Tue Aug 22 02:16:43 2017 +0300

    signal: lift sigset size check out of do_sigpending()
    
    As sigsetsize argument of do_sigpending() is not used anywhere else in
    that function after the check, remove this argument and move the check
    out of do_sigpending() into rt_sigpending() and its compat analog.
    
    Suggested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Dmitry V. Levin <ldv@altlinux.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index f59c05fc374a..9fbc574ced10 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2629,11 +2629,8 @@ COMPAT_SYSCALL_DEFINE4(rt_sigprocmask, int, how, compat_sigset_t __user *, nset,
 }
 #endif
 
-static int do_sigpending(void *set, unsigned long sigsetsize)
+static int do_sigpending(sigset_t *set)
 {
-	if (sigsetsize > sizeof(sigset_t))
-		return -EINVAL;
-
 	spin_lock_irq(&current->sighand->siglock);
 	sigorsets(set, &current->pending.signal,
 		  &current->signal->shared_pending.signal);
@@ -2653,7 +2650,12 @@ static int do_sigpending(void *set, unsigned long sigsetsize)
 SYSCALL_DEFINE2(rt_sigpending, sigset_t __user *, uset, size_t, sigsetsize)
 {
 	sigset_t set;
-	int err = do_sigpending(&set, sigsetsize);
+	int err;
+
+	if (sigsetsize > sizeof(*uset))
+		return -EINVAL;
+
+	err = do_sigpending(&set);
 	if (!err && copy_to_user(uset, &set, sigsetsize))
 		err = -EFAULT;
 	return err;
@@ -2664,7 +2666,12 @@ COMPAT_SYSCALL_DEFINE2(rt_sigpending, compat_sigset_t __user *, uset,
 		compat_size_t, sigsetsize)
 {
 	sigset_t set;
-	int err = do_sigpending(&set, sigsetsize);
+	int err;
+
+	if (sigsetsize > sizeof(*uset))
+		return -EINVAL;
+
+	err = do_sigpending(&set);
 	if (!err)
 		err = put_compat_sigset(uset, &set, sigsetsize);
 	return err;
@@ -3331,7 +3338,7 @@ SYSCALL_DEFINE1(sigpending, old_sigset_t __user *, set)
 COMPAT_SYSCALL_DEFINE1(sigpending, compat_old_sigset_t __user *, set32)
 {
 	sigset_t set;
-	int err = do_sigpending(&set, sizeof(set.sig[0]));
+	int err = do_sigpending(&set);
 	if (!err)
 		err = put_user(set.sig[0], set32);
 	return err;

commit 1681634b8c70353d8ca211b9b3443889a16dafeb
Author: Dmitry V. Levin <ldv@altlinux.org>
Date:   Tue Aug 22 02:16:29 2017 +0300

    signal: simplify compat_sigpending()
    
    Remove "if it's big-endian..." ifdef in compat_sigpending(),
    use the endian-agnostic variant.
    
    Suggested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Dmitry V. Levin <ldv@altlinux.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 14ad6bb90dad..f59c05fc374a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3330,15 +3330,11 @@ SYSCALL_DEFINE1(sigpending, old_sigset_t __user *, set)
 #ifdef CONFIG_COMPAT
 COMPAT_SYSCALL_DEFINE1(sigpending, compat_old_sigset_t __user *, set32)
 {
-#ifdef __BIG_ENDIAN
 	sigset_t set;
 	int err = do_sigpending(&set, sizeof(set.sig[0]));
 	if (!err)
 		err = put_user(set.sig[0], set32);
 	return err;
-#else
-	return sys_rt_sigpending((sigset_t __user *)set32, sizeof(*set32));
-#endif
 }
 #endif
 

commit f454322efbf6faee695f517c6b52c4dc03cacd3e
Author: Dmitry V. Levin <ldv@altlinux.org>
Date:   Tue Aug 22 02:16:11 2017 +0300

    signal: replace sigset_to_compat() with put_compat_sigset()
    
    There are 4 callers of sigset_to_compat() in the entire kernel.  One is
    in sparc compat rt_sigaction(2), the rest are in kernel/signal.c itself.
    All are followed by copy_to_user(), and all but the sparc one are under
    "if it's big-endian..." ifdefs.
    
    Let's transform sigset_to_compat() into put_compat_sigset() that also
    calls copy_to_user().
    
    Suggested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Dmitry V. Levin <ldv@altlinux.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 800a18f77732..14ad6bb90dad 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2621,13 +2621,7 @@ COMPAT_SYSCALL_DEFINE4(rt_sigprocmask, int, how, compat_sigset_t __user *, nset,
 		if (error)
 			return error;
 	}
-	if (oset) {
-		compat_sigset_t old32;
-		sigset_to_compat(&old32, &old_set);
-		if (copy_to_user(oset, &old32, sizeof(compat_sigset_t)))
-			return -EFAULT;
-	}
-	return 0;
+	return oset ? put_compat_sigset(oset, &old_set, sizeof(*oset)) : 0;
 #else
 	return sys_rt_sigprocmask(how, (sigset_t __user *)nset,
 				  (sigset_t __user *)oset, sigsetsize);
@@ -2669,20 +2663,11 @@ SYSCALL_DEFINE2(rt_sigpending, sigset_t __user *, uset, size_t, sigsetsize)
 COMPAT_SYSCALL_DEFINE2(rt_sigpending, compat_sigset_t __user *, uset,
 		compat_size_t, sigsetsize)
 {
-#ifdef __BIG_ENDIAN
 	sigset_t set;
 	int err = do_sigpending(&set, sigsetsize);
-	if (!err) {
-		compat_sigset_t set32;
-		sigset_to_compat(&set32, &set);
-		/* we can get here only if sigsetsize <= sizeof(set) */
-		if (copy_to_user(uset, &set32, sigsetsize))
-			err = -EFAULT;
-	}
+	if (!err)
+		err = put_compat_sigset(uset, &set, sigsetsize);
 	return err;
-#else
-	return sys_rt_sigpending((sigset_t __user *)uset, sigsetsize);
-#endif
 }
 #endif
 
@@ -3451,7 +3436,6 @@ COMPAT_SYSCALL_DEFINE4(rt_sigaction, int, sig,
 		compat_size_t, sigsetsize)
 {
 	struct k_sigaction new_ka, old_ka;
-	compat_sigset_t mask;
 #ifdef __ARCH_HAS_SA_RESTORER
 	compat_uptr_t restorer;
 #endif
@@ -3463,6 +3447,7 @@ COMPAT_SYSCALL_DEFINE4(rt_sigaction, int, sig,
 
 	if (act) {
 		compat_uptr_t handler;
+		compat_sigset_t mask;
 		ret = get_user(handler, &act->sa_handler);
 		new_ka.sa.sa_handler = compat_ptr(handler);
 #ifdef __ARCH_HAS_SA_RESTORER
@@ -3478,10 +3463,10 @@ COMPAT_SYSCALL_DEFINE4(rt_sigaction, int, sig,
 
 	ret = do_sigaction(sig, act ? &new_ka : NULL, oact ? &old_ka : NULL);
 	if (!ret && oact) {
-		sigset_to_compat(&mask, &old_ka.sa.sa_mask);
 		ret = put_user(ptr_to_compat(old_ka.sa.sa_handler), 
 			       &oact->sa_handler);
-		ret |= copy_to_user(&oact->sa_mask, &mask, sizeof(mask));
+		ret |= put_compat_sigset(&oact->sa_mask, &old_ka.sa.sa_mask,
+					 sizeof(oact->sa_mask));
 		ret |= put_user(old_ka.sa.sa_flags, &oact->sa_flags);
 #ifdef __ARCH_HAS_SA_RESTORER
 		ret |= put_user(ptr_to_compat(old_ka.sa.sa_restorer),

commit dd198ce7141aa8dd9ffcc9549de422fb055508de
Merge: 89fd915c4021 076a9bcacfc7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Sep 11 18:34:47 2017 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull namespace updates from Eric Biederman:
     "Life has been busy and I have not gotten half as much done this round
      as I would have liked. I delayed it so that a minor conflict
      resolution with the mips tree could spend a little time in linux-next
      before I sent this pull request.
    
      This includes two long delayed user namespace changes from Kirill
      Tkhai. It also includes a very useful change from Serge Hallyn that
      allows the security capability attribute to be used inside of user
      namespaces. The practical effect of this is people can now untar
      tarballs and install rpms in user namespaces. It had been suggested to
      generalize this and encode some of the namespace information
      information in the xattr name. Upon close inspection that makes the
      things that should be hard easy and the things that should be easy
      more expensive.
    
      Then there is my bugfix/cleanup for signal injection that removes the
      magic encoding of the siginfo union member from the kernel internal
      si_code. The mips folks reported the case where I had used FPE_FIXME
      me is impossible so I have remove FPE_FIXME from mips, while at the
      same time including a return statement in that case to keep gcc from
      complaining about unitialized variables.
    
      I almost finished the work to get make copy_siginfo_to_user a trivial
      copy to user. The code is available at:
    
         git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace.git neuter-copy_siginfo_to_user-v3
    
      But I did not have time/energy to get the code posted and reviewed
      before the merge window opened.
    
      I was able to see that the security excuse for just copying fields
      that we know are initialized doesn't work in practice there are buggy
      initializations that don't initialize the proper fields in siginfo. So
      we still sometimes copy unitialized data to userspace"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace:
      Introduce v3 namespaced file capabilities
      mips/signal: In force_fcr31_sig return in the impossible case
      signal: Remove kernel interal si_code magic
      fcntl: Don't use ambiguous SIG_POLL si_codes
      prctl: Allow local CAP_SYS_ADMIN changing exe_file
      security: Use user_namespace::level to avoid redundant iterations in cap_capable()
      userns,pidns: Verify the userns for new pid namespaces
      signal/testing: Don't look for __SI_FAULT in userspace
      signal/mips: Document a conflict with SI_USER with SIGFPE
      signal/sparc: Document a conflict with SI_USER with SIGFPE
      signal/ia64: Document a conflict with SI_USER with SIGFPE
      signal/alpha: Document a conflict with SI_USER for SIGTRAP

commit eb61b5911bdc923875cde99eb25203a0e2b06d43
Author: Jamie Iles <jamie.iles@oracle.com>
Date:   Fri Aug 18 15:16:18 2017 -0700

    signal: don't remove SIGNAL_UNKILLABLE for traced tasks.
    
    When forcing a signal, SIGNAL_UNKILLABLE is removed to prevent recursive
    faults, but this is undesirable when tracing.  For example, debugging an
    init process (whether global or namespace), hitting a breakpoint and
    SIGTRAP will force SIGTRAP and then remove SIGNAL_UNKILLABLE.
    Everything continues fine, but then once debugging has finished, the
    init process is left killable which is unlikely what the user expects,
    resulting in either an accidentally killed init or an init that stops
    reaping zombies.
    
    Link: http://lkml.kernel.org/r/20170815112806.10728-1-jamie.iles@oracle.com
    Signed-off-by: Jamie Iles <jamie.iles@oracle.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 7e33f8c583e6..ed804a470dcd 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1194,7 +1194,11 @@ force_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 			recalc_sigpending_and_wake(t);
 		}
 	}
-	if (action->sa.sa_handler == SIG_DFL)
+	/*
+	 * Don't clear SIGNAL_UNKILLABLE for traced tasks, users won't expect
+	 * debugging to leave init killable.
+	 */
+	if (action->sa.sa_handler == SIG_DFL && !t->ptrace)
 		t->signal->flags &= ~SIGNAL_UNKILLABLE;
 	ret = specific_send_sig_info(sig, info, t);
 	spin_unlock_irqrestore(&t->sighand->siglock, flags);

commit fbb77611e95d3d5b2af86a59754a3130877cb667
Author: Dmitry V. Levin <ldv@altlinux.org>
Date:   Sat Aug 5 23:00:50 2017 +0300

    Fix compat_sys_sigpending breakage
    
    The latest change of compat_sys_sigpending in commit 8f13621abced
    ("sigpending(): move compat to native") has broken it in two ways.
    
    First, it tries to write 4 bytes more than userspace expects:
    sizeof(old_sigset_t) == sizeof(long) == 8 instead of
    sizeof(compat_old_sigset_t) == sizeof(u32) == 4.
    
    Second, on big endian architectures these bytes are being written in the
    wrong order.
    
    This bug was found by strace test suite.
    
    Reported-by: Anatoly Pugachev <matorola@gmail.com>
    Inspired-by: Eugene Syromyatnikov <evgsyr@gmail.com>
    Fixes: 8f13621abced ("sigpending(): move compat to native")
    Signed-off-by: Dmitry V. Levin <ldv@altlinux.org>
    Acked-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index caed9133ae52..7e33f8c583e6 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3303,12 +3303,15 @@ SYSCALL_DEFINE1(sigpending, old_sigset_t __user *, set)
 #ifdef CONFIG_COMPAT
 COMPAT_SYSCALL_DEFINE1(sigpending, compat_old_sigset_t __user *, set32)
 {
+#ifdef __BIG_ENDIAN
 	sigset_t set;
-	int err = do_sigpending(&set, sizeof(old_sigset_t)); 
-	if (err == 0)
-		if (copy_to_user(set32, &set, sizeof(old_sigset_t)))
-			err = -EFAULT;
+	int err = do_sigpending(&set, sizeof(set.sig[0]));
+	if (!err)
+		err = put_user(set.sig[0], set32);
 	return err;
+#else
+	return sys_rt_sigpending((sigset_t __user *)set32, sizeof(*set32));
+#endif
 }
 #endif
 

commit cc731525f26af85a1c3537da41e0abd1d35e0bdb
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sun Jul 16 22:36:59 2017 -0500

    signal: Remove kernel interal si_code magic
    
    struct siginfo is a union and the kernel since 2.4 has been hiding a union
    tag in the high 16bits of si_code using the values:
    __SI_KILL
    __SI_TIMER
    __SI_POLL
    __SI_FAULT
    __SI_CHLD
    __SI_RT
    __SI_MESGQ
    __SI_SYS
    
    While this looks plausible on the surface, in practice this situation has
    not worked well.
    
    - Injected positive signals are not copied to user space properly
      unless they have these magic high bits set.
    
    - Injected positive signals are not reported properly by signalfd
      unless they have these magic high bits set.
    
    - These kernel internal values leaked to userspace via ptrace_peek_siginfo
    
    - It was possible to inject these kernel internal values and cause the
      the kernel to misbehave.
    
    - Kernel developers got confused and expected these kernel internal values
      in userspace in kernel self tests.
    
    - Kernel developers got confused and set si_code to __SI_FAULT which
      is SI_USER in userspace which causes userspace to think an ordinary user
      sent the signal and that it was not kernel generated.
    
    - The values make it impossible to reorganize the code to transform
      siginfo_copy_to_user into a plain copy_to_user.  As si_code must
      be massaged before being passed to userspace.
    
    So remove these kernel internal si codes and make the kernel code simpler
    and more maintainable.
    
    To replace these kernel internal magic si_codes introduce the helper
    function siginfo_layout, that takes a signal number and an si_code and
    computes which union member of siginfo is being used.  Have
    siginfo_layout return an enumeration so that gcc will have enough
    information to warn if a switch statement does not handle all of union
    members.
    
    A couple of architectures have a messed up ABI that defines signal
    specific duplications of SI_USER which causes more special cases in
    siginfo_layout than I would like.  The good news is only problem
    architectures pay the cost.
    
    Update all of the code that used the previous magic __SI_ values to
    use the new SIL_ values and to call siginfo_layout to get those
    values.  Escept where not all of the cases are handled remove the
    defaults in the switch statements so that if a new case is missed in
    the future the lack will show up at compile time.
    
    Modify the code that copies siginfo si_code to userspace to just copy
    the value and not cast si_code to a short first.  The high bits are no
    longer used to hold a magic union member.
    
    Fixup the siginfo header files to stop including the __SI_ values in
    their constants and for the headers that were missing it to properly
    update the number of si_codes for each signal type.
    
    The fixes to copy_siginfo_from_user32 implementations has the
    interesting property that several of them perviously should never have
    worked as the __SI_ values they depended up where kernel internal.
    With that dependency gone those implementations should work much
    better.
    
    The idea of not passing the __SI_ values out to userspace and then
    not reinserting them has been tested with criu and criu worked without
    changes.
    
    Ref: 2.4.0-test1
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index caed9133ae52..6bd53c8189f0 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2682,6 +2682,51 @@ COMPAT_SYSCALL_DEFINE2(rt_sigpending, compat_sigset_t __user *, uset,
 }
 #endif
 
+enum siginfo_layout siginfo_layout(int sig, int si_code)
+{
+	enum siginfo_layout layout = SIL_KILL;
+	if ((si_code > SI_USER) && (si_code < SI_KERNEL)) {
+		static const struct {
+			unsigned char limit, layout;
+		} filter[] = {
+			[SIGILL]  = { NSIGILL,  SIL_FAULT },
+			[SIGFPE]  = { NSIGFPE,  SIL_FAULT },
+			[SIGSEGV] = { NSIGSEGV, SIL_FAULT },
+			[SIGBUS]  = { NSIGBUS,  SIL_FAULT },
+			[SIGTRAP] = { NSIGTRAP, SIL_FAULT },
+#if defined(SIGMET) && defined(NSIGEMT)
+			[SIGEMT]  = { NSIGEMT,  SIL_FAULT },
+#endif
+			[SIGCHLD] = { NSIGCHLD, SIL_CHLD },
+			[SIGPOLL] = { NSIGPOLL, SIL_POLL },
+#ifdef __ARCH_SIGSYS
+			[SIGSYS]  = { NSIGSYS,  SIL_SYS },
+#endif
+		};
+		if ((sig < ARRAY_SIZE(filter)) && (si_code <= filter[sig].limit))
+			layout = filter[sig].layout;
+		else if (si_code <= NSIGPOLL)
+			layout = SIL_POLL;
+	} else {
+		if (si_code == SI_TIMER)
+			layout = SIL_TIMER;
+		else if (si_code == SI_SIGIO)
+			layout = SIL_POLL;
+		else if (si_code < 0)
+			layout = SIL_RT;
+		/* Tests to support buggy kernel ABIs */
+#ifdef TRAP_FIXME
+		if ((sig == SIGTRAP) && (si_code == TRAP_FIXME))
+			layout = SIL_FAULT;
+#endif
+#ifdef FPE_FIXME
+		if ((sig == SIGFPE) && (si_code == FPE_FIXME))
+			layout = SIL_FAULT;
+#endif
+	}
+	return layout;
+}
+
 #ifndef HAVE_ARCH_COPY_SIGINFO_TO_USER
 
 int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
@@ -2704,22 +2749,20 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 	 */
 	err = __put_user(from->si_signo, &to->si_signo);
 	err |= __put_user(from->si_errno, &to->si_errno);
-	err |= __put_user((short)from->si_code, &to->si_code);
-	switch (from->si_code & __SI_MASK) {
-	case __SI_KILL:
+	err |= __put_user(from->si_code, &to->si_code);
+	switch (siginfo_layout(from->si_signo, from->si_code)) {
+	case SIL_KILL:
 		err |= __put_user(from->si_pid, &to->si_pid);
 		err |= __put_user(from->si_uid, &to->si_uid);
 		break;
-	case __SI_TIMER:
-		 err |= __put_user(from->si_tid, &to->si_tid);
-		 err |= __put_user(from->si_overrun, &to->si_overrun);
-		 err |= __put_user(from->si_ptr, &to->si_ptr);
+	case SIL_TIMER:
+		/* Unreached SI_TIMER is negative */
 		break;
-	case __SI_POLL:
+	case SIL_POLL:
 		err |= __put_user(from->si_band, &to->si_band);
 		err |= __put_user(from->si_fd, &to->si_fd);
 		break;
-	case __SI_FAULT:
+	case SIL_FAULT:
 		err |= __put_user(from->si_addr, &to->si_addr);
 #ifdef __ARCH_SI_TRAPNO
 		err |= __put_user(from->si_trapno, &to->si_trapno);
@@ -2744,30 +2787,25 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 			err |= __put_user(from->si_pkey, &to->si_pkey);
 #endif
 		break;
-	case __SI_CHLD:
+	case SIL_CHLD:
 		err |= __put_user(from->si_pid, &to->si_pid);
 		err |= __put_user(from->si_uid, &to->si_uid);
 		err |= __put_user(from->si_status, &to->si_status);
 		err |= __put_user(from->si_utime, &to->si_utime);
 		err |= __put_user(from->si_stime, &to->si_stime);
 		break;
-	case __SI_RT: /* This is not generated by the kernel as of now. */
-	case __SI_MESGQ: /* But this is */
+	case SIL_RT:
 		err |= __put_user(from->si_pid, &to->si_pid);
 		err |= __put_user(from->si_uid, &to->si_uid);
 		err |= __put_user(from->si_ptr, &to->si_ptr);
 		break;
 #ifdef __ARCH_SIGSYS
-	case __SI_SYS:
+	case SIL_SYS:
 		err |= __put_user(from->si_call_addr, &to->si_call_addr);
 		err |= __put_user(from->si_syscall, &to->si_syscall);
 		err |= __put_user(from->si_arch, &to->si_arch);
 		break;
 #endif
-	default: /* this is just in case for now ... */
-		err |= __put_user(from->si_pid, &to->si_pid);
-		err |= __put_user(from->si_uid, &to->si_uid);
-		break;
 	}
 	return err;
 }

commit 4ea77014af0d6205b05503d1c7aac6eace11d473
Author: zhongjiang <zhongjiang@huawei.com>
Date:   Mon Jul 10 15:52:57 2017 -0700

    kernel/signal.c: avoid undefined behaviour in kill_something_info
    
    When running kill(72057458746458112, 0) in userspace I hit the following
    issue.
    
      UBSAN: Undefined behaviour in kernel/signal.c:1462:11
      negation of -2147483648 cannot be represented in type 'int':
      CPU: 226 PID: 9849 Comm: test Tainted: G    B          ---- -------   3.10.0-327.53.58.70.x86_64_ubsan+ #116
      Hardware name: Huawei Technologies Co., Ltd. RH8100 V3/BC61PBIA, BIOS BLHSV028 11/11/2014
      Call Trace:
        dump_stack+0x19/0x1b
        ubsan_epilogue+0xd/0x50
        __ubsan_handle_negate_overflow+0x109/0x14e
        SYSC_kill+0x43e/0x4d0
        SyS_kill+0xe/0x10
        system_call_fastpath+0x16/0x1b
    
    Add code to avoid the UBSAN detection.
    
    [akpm@linux-foundation.org: tweak comment]
    Link: http://lkml.kernel.org/r/1496670008-59084-1-git-send-email-zhongjiang@huawei.com
    Signed-off-by: zhongjiang <zhongjiang@huawei.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: Xishi Qiu <qiuxishi@huawei.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 48a59eefd8ad..caed9133ae52 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1402,6 +1402,10 @@ static int kill_something_info(int sig, struct siginfo *info, pid_t pid)
 		return ret;
 	}
 
+	/* -INT_MIN is undefined.  Exclude this case to avoid a UBSAN warning */
+	if (pid == INT_MIN)
+		return -ESRCH;
+
 	read_lock(&tasklist_lock);
 	if (pid != -1) {
 		ret = __kill_pgrp_info(sig, info,

commit c856863988ebf612d159e55eeddbcd27de63b40d
Merge: 771d3feb4b79 0d0606060bae
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jul 6 20:57:13 2017 -0700

    Merge branch 'misc.compat' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull misc compat stuff updates from Al Viro:
     "This part is basically untangling various compat stuff. Compat
      syscalls moved to their native counterparts, getting rid of quite a
      bit of double-copying and/or set_fs() uses. A lot of field-by-field
      copyin/copyout killed off.
    
       - kernel/compat.c is much closer to containing just the
         copyin/copyout of compat structs. Not all compat syscalls are gone
         from it yet, but it's getting there.
    
       - ipc/compat_mq.c killed off completely.
    
       - block/compat_ioctl.c cleaned up; floppy compat ioctls moved to
         drivers/block/floppy.c where they belong. Yes, there are several
         drivers that implement some of the same ioctls. Some are m68k and
         one is 32bit-only pmac. drivers/block/floppy.c is the only one in
         that bunch that can be built on biarch"
    
    * 'misc.compat' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      mqueue: move compat syscalls to native ones
      usbdevfs: get rid of field-by-field copyin
      compat_hdio_ioctl: get rid of set_fs()
      take floppy compat ioctls to sodding floppy.c
      ipmi: get rid of field-by-field __get_user()
      ipmi: get COMPAT_IPMICTL_RECEIVE_MSG in sync with the native one
      rt_sigtimedwait(): move compat to native
      select: switch compat_{get,put}_fd_set() to compat_{get,put}_bitmap()
      put_compat_rusage(): switch to copy_to_user()
      sigpending(): move compat to native
      getrlimit()/setrlimit(): move compat to native
      times(2): move compat to native
      compat_{get,put}_bitmap(): use unsafe_{get,put}_user()
      fb_get_fscreeninfo(): don't bother with do_fb_ioctl()
      do_sigaltstack(): lift copying to/from userland into callers
      take compat_sys_old_getrlimit() to native syscall
      trim __ARCH_WANT_SYS_OLD_GETRLIMIT

commit 1b044f1cfc65a7d90b209dfabd57e16d98b58c5b
Merge: e0f3e8f14da8 2287d8664fe7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 3 16:14:51 2017 -0700

    Merge branch 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull timer updates from Thomas Gleixner:
     "A rather large update for timers/timekeeping:
    
       - compat syscall consolidation (Al Viro)
    
       - Posix timer consolidation (Christoph Helwig / Thomas Gleixner)
    
       - Cleanup of the device tree based initialization for clockevents and
         clocksources (Daniel Lezcano)
    
       - Consolidation of the FTTMR010 clocksource/event driver (Linus
         Walleij)
    
       - The usual set of small fixes and updates all over the place"
    
    * 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (93 commits)
      timers: Make the cpu base lock raw
      clocksource/drivers/mips-gic-timer: Fix an error code in 'gic_clocksource_of_init()'
      clocksource/drivers/fsl_ftm_timer: Unmap region obtained by of_iomap
      clocksource/drivers/tcb_clksrc: Make IO endian agnostic
      clocksource/drivers/sun4i: Switch to the timer-of common init
      clocksource/drivers/timer-of: Fix invalid iomap check
      Revert "ktime: Simplify ktime_compare implementation"
      clocksource/drivers: Fix uninitialized variable use in timer_of_init
      kselftests: timers: Add test for frequency step
      kselftests: timers: Fix inconsistency-check to not ignore first timestamp
      time: Add warning about imminent deprecation of CONFIG_GENERIC_TIME_VSYSCALL_OLD
      time: Clean up CLOCK_MONOTONIC_RAW time handling
      posix-cpu-timers: Make timespec to nsec conversion safe
      itimer: Make timeval to nsec conversion range limited
      timers: Fix parameter description of try_to_del_timer_sync()
      ktime: Simplify ktime_compare implementation
      clocksource/drivers/fttmr010: Factor out clock read code
      clocksource/drivers/fttmr010: Implement delay timer
      clocksource/drivers: Add timer-of common init routine
      clocksource/drivers/tcb_clksrc: Save timer context on suspend/resume
      ...

commit 241e5e6f0497769d37240215047b9473ae3ae3f0
Merge: 7a69f9c60b49 204a2be30a7a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 3 15:12:52 2017 -0700

    Merge tag 'm68k-for-v4.13-tag1' of git://git.kernel.org/pub/scm/linux/kernel/git/geert/linux-m68k
    
    Pull m68k updates from Geert Uytterhoeven:
    
      - NuBus improvements and cleanups
    
      - defconfig updates
    
      - Fix debugger syscall restart interactions, leading to the global
        removal of ptrace_signal_deliver()
    
    * tag 'm68k-for-v4.13-tag1' of git://git.kernel.org/pub/scm/linux/kernel/git/geert/linux-m68k:
      m68k: Remove ptrace_signal_deliver
      m68k/defconfig: Update defconfigs for v4.12-rc1
      nubus: Fix pointer validation
      nubus: Remove slot zero probe

commit 204a2be30a7a8a8d12642f23f3fbdc8b9923b500
Author: Andreas Schwab <schwab@linux-m68k.org>
Date:   Wed Jun 7 00:11:44 2017 +0200

    m68k: Remove ptrace_signal_deliver
    
    This fixes debugger syscall restart interactions.  A debugger that
    modifies the tracee's program counter is expected to set the orig_d0
    pseudo register to -1, to disable a possible syscall restart.
    
    This removes the last user of the ptrace_signal_deliver hook in the ptrace
    signal handling, so remove that as well.
    
    Signed-off-by: Andreas Schwab <schwab@linux-m68k.org>
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index ca92bcfeb322..f0a48e5b1f0b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2092,7 +2092,6 @@ static void do_jobctl_trap(void)
 
 static int ptrace_signal(int signr, siginfo_t *info)
 {
-	ptrace_signal_deliver();
 	/*
 	 * We do not check sig_kernel_stop(signr) but set this marker
 	 * unconditionally because we do not know whether debugger will

commit 57db7e4a2d92c2d3dfbca4ef8057849b2682436b
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Jun 13 04:31:16 2017 -0500

    signal: Only reschedule timers on signals timers have sent
    
    Thomas Gleixner  wrote:
    > The CRIU support added a 'feature' which allows a user space task to send
    > arbitrary (kernel) signals to itself. The changelog says:
    >
    >   The kernel prevents sending of siginfo with positive si_code, because
    >   these codes are reserved for kernel.  I think we can allow a task to
    >   send such a siginfo to itself.  This operation should not be dangerous.
    >
    > Quite contrary to that claim, it turns out that it is outright dangerous
    > for signals with info->si_code == SI_TIMER. The following code sequence in
    > a user space task allows to crash the kernel:
    >
    >    id = timer_create(CLOCK_XXX, ..... signo = SIGX);
    >    timer_set(id, ....);
    >    info->si_signo = SIGX;
    >    info->si_code = SI_TIMER:
    >    info->_sifields._timer._tid = id;
    >    info->_sifields._timer._sys_private = 2;
    >    rt_[tg]sigqueueinfo(..., SIGX, info);
    >    sigemptyset(&sigset);
    >    sigaddset(&sigset, SIGX);
    >    rt_sigtimedwait(sigset, info);
    >
    > For timers based on CLOCK_PROCESS_CPUTIME_ID, CLOCK_THREAD_CPUTIME_ID this
    > results in a kernel crash because sigwait() dequeues the signal and the
    > dequeue code observes:
    >
    >   info->si_code == SI_TIMER && info->_sifields._timer._sys_private != 0
    >
    > which triggers the following callchain:
    >
    >  do_schedule_next_timer() -> posix_cpu_timer_schedule() -> arm_timer()
    >
    > arm_timer() executes a list_add() on the timer, which is already armed via
    > the timer_set() syscall. That's a double list add which corrupts the posix
    > cpu timer list. As a consequence the kernel crashes on the next operation
    > touching the posix cpu timer list.
    >
    > Posix clocks which are internally implemented based on hrtimers are not
    > affected by this because hrtimer_start() can handle already armed timers
    > nicely, but it's a reliable way to trigger the WARN_ON() in
    > hrtimer_forward(), which complains about calling that function on an
    > already armed timer.
    
    This problem has existed since the posix timer code was merged into
    2.5.63. A few releases earlier in 2.5.60 ptrace gained the ability to
    inject not just a signal (which linux has supported since 1.0) but the
    full siginfo of a signal.
    
    The core problem is that the code will reschedule in response to
    signals getting dequeued not just for signals the timers sent but
    for other signals that happen to a si_code of SI_TIMER.
    
    Avoid this confusion by testing to see if the queued signal was
    preallocated as all timer signals are preallocated, and so far
    only the timer code preallocates signals.
    
    Move the check for if a timer needs to be rescheduled up into
    collect_signal where the preallocation check must be performed,
    and pass the result back to dequeue_signal where the code reschedules
    timers.   This makes it clear why the code cares about preallocated
    timers.
    
    Cc: stable@vger.kernel.org
    Reported-by: Thomas Gleixner <tglx@linutronix.de>
    History Tree: https://git.kernel.org/pub/scm/linux/kernel/git/tglx/history.git
    Reference: 66dd34ad31e5 ("signal: allow to send any siginfo to itself")
    Reference: 1669ce53e2ff ("Add PTRACE_GETSIGINFO and PTRACE_SETSIGINFO")
    Fixes: db8b50ba75f2 ("[PATCH] POSIX clocks & timers")
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index ca92bcfeb322..45b4c1ffe14e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -510,7 +510,8 @@ int unhandled_signal(struct task_struct *tsk, int sig)
 	return !tsk->ptrace;
 }
 
-static void collect_signal(int sig, struct sigpending *list, siginfo_t *info)
+static void collect_signal(int sig, struct sigpending *list, siginfo_t *info,
+			   bool *resched_timer)
 {
 	struct sigqueue *q, *first = NULL;
 
@@ -532,6 +533,12 @@ static void collect_signal(int sig, struct sigpending *list, siginfo_t *info)
 still_pending:
 		list_del_init(&first->list);
 		copy_siginfo(info, &first->info);
+
+		*resched_timer =
+			(first->flags & SIGQUEUE_PREALLOC) &&
+			(info->si_code == SI_TIMER) &&
+			(info->si_sys_private);
+
 		__sigqueue_free(first);
 	} else {
 		/*
@@ -548,12 +555,12 @@ static void collect_signal(int sig, struct sigpending *list, siginfo_t *info)
 }
 
 static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,
-			siginfo_t *info)
+			siginfo_t *info, bool *resched_timer)
 {
 	int sig = next_signal(pending, mask);
 
 	if (sig)
-		collect_signal(sig, pending, info);
+		collect_signal(sig, pending, info, resched_timer);
 	return sig;
 }
 
@@ -565,15 +572,16 @@ static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,
  */
 int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 {
+	bool resched_timer = false;
 	int signr;
 
 	/* We only dequeue private signals from ourselves, we don't let
 	 * signalfd steal them
 	 */
-	signr = __dequeue_signal(&tsk->pending, mask, info);
+	signr = __dequeue_signal(&tsk->pending, mask, info, &resched_timer);
 	if (!signr) {
 		signr = __dequeue_signal(&tsk->signal->shared_pending,
-					 mask, info);
+					 mask, info, &resched_timer);
 #ifdef CONFIG_POSIX_TIMERS
 		/*
 		 * itimer signal ?
@@ -621,7 +629,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 		current->jobctl |= JOBCTL_STOP_DEQUEUED;
 	}
 #ifdef CONFIG_POSIX_TIMERS
-	if ((info->si_code & __SI_MASK) == __SI_TIMER && info->si_sys_private) {
+	if (resched_timer) {
 		/*
 		 * Release the siglock to ensure proper locking order
 		 * of timer locks outside of siglocks.  Note, we leave

commit 1b3c872c8342803d0fcd8042e4e007d173191db6
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed May 31 04:46:17 2017 -0400

    rt_sigtimedwait(): move compat to native
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 6237f492adfc..fe5b3608c31c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2768,7 +2768,7 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
  *  @info: if non-null, the signal's siginfo is returned here
  *  @ts: upper bound on process time suspension
  */
-int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
+static int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
 		    const struct timespec *ts)
 {
 	ktime_t *to = NULL, timeout = KTIME_MAX;
@@ -2857,6 +2857,40 @@ SYSCALL_DEFINE4(rt_sigtimedwait, const sigset_t __user *, uthese,
 	return ret;
 }
 
+#ifdef CONFIG_COMPAT
+COMPAT_SYSCALL_DEFINE4(rt_sigtimedwait, compat_sigset_t __user *, uthese,
+		struct compat_siginfo __user *, uinfo,
+		struct compat_timespec __user *, uts, compat_size_t, sigsetsize)
+{
+	compat_sigset_t s32;
+	sigset_t s;
+	struct timespec t;
+	siginfo_t info;
+	long ret;
+
+	if (sigsetsize != sizeof(sigset_t))
+		return -EINVAL;
+
+	if (copy_from_user(&s32, uthese, sizeof(compat_sigset_t)))
+		return -EFAULT;
+	sigset_from_compat(&s, &s32);
+
+	if (uts) {
+		if (compat_get_timespec(&t, uts))
+			return -EFAULT;
+	}
+
+	ret = do_sigtimedwait(&s, &info, uts ? &t : NULL);
+
+	if (ret > 0 && uinfo) {
+		if (copy_siginfo_to_user32(uinfo, &info))
+			ret = -EFAULT;
+	}
+
+	return ret;
+}
+#endif
+
 /**
  *  sys_kill - send a signal to a process
  *  @pid: the PID of the process

commit 8f13621abcedb278cfecf9703583743f9c474c97
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed May 31 04:42:07 2017 -0400

    sigpending(): move compat to native
    
    ... and kill set_fs() use
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index d1eed0d7ca64..6237f492adfc 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3254,6 +3254,18 @@ SYSCALL_DEFINE1(sigpending, old_sigset_t __user *, set)
 	return sys_rt_sigpending((sigset_t __user *)set, sizeof(old_sigset_t)); 
 }
 
+#ifdef CONFIG_COMPAT
+COMPAT_SYSCALL_DEFINE1(sigpending, compat_old_sigset_t __user *, set32)
+{
+	sigset_t set;
+	int err = do_sigpending(&set, sizeof(old_sigset_t)); 
+	if (err == 0)
+		if (copy_to_user(set32, &set, sizeof(old_sigset_t)))
+			err = -EFAULT;
+	return err;
+}
+#endif
+
 #endif
 
 #ifdef __ARCH_WANT_SYS_SIGPROCMASK

commit 96fe3b072f134e4993f829d599eaa1e0eb5a10e5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue May 30 23:15:46 2017 +0200

    posix-timers: Rename do_schedule_next_timer
    
    That function is a misnomer. Rename it with a proper prefix to
    posixtimer_rearm().
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: John Stultz <john.stultz@linaro.org>
    Link: http://lkml.kernel.org/r/20170530211656.811362578@linutronix.de

diff --git a/kernel/signal.c b/kernel/signal.c
index 1f85c843be8e..d031cd24f8a9 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -630,7 +630,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 		 * about to disable them again anyway.
 		 */
 		spin_unlock(&tsk->sighand->siglock);
-		do_schedule_next_timer(info);
+		posixtimer_rearm(info);
 		spin_lock(&tsk->sighand->siglock);
 	}
 #endif

commit 31ea70e0308b73a1b862bd17c06efc3cbcfd2016
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jun 3 21:01:00 2017 +0200

    posix-timers: Move the do_schedule_next_timer declaration
    
    Having it in asm-generic/siginfo.h doesn't make any sense as it is in no way
    architecture specific.  Move it to posix-timers.h instead.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-arch@vger.kernel.org
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: linux-ia64@vger.kernel.org
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: sparclinux@vger.kernel.org
    Cc: "David S. Miller" <davem@davemloft.net>
    Link: http://lkml.kernel.org/r/20170603190102.28866-4-hch@lst.de

diff --git a/kernel/signal.c b/kernel/signal.c
index ca92bcfeb322..1f85c843be8e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -39,6 +39,7 @@
 #include <linux/compat.h>
 #include <linux/cn_proc.h>
 #include <linux/compiler.h>
+#include <linux/posix-timers.h>
 
 #define CREATE_TRACE_POINTS
 #include <trace/events/signal.h>

commit bcfe8ad8ef55a1cf3c935c2667e8e5ae598b3b7e
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat May 27 00:29:34 2017 -0400

    do_sigaltstack(): lift copying to/from userland into callers
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index ca92bcfeb322..d1eed0d7ca64 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3113,78 +3113,68 @@ int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 }
 
 static int
-do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long sp)
+do_sigaltstack (const stack_t *ss, stack_t *oss, unsigned long sp)
 {
-	stack_t oss;
-	int error;
+	struct task_struct *t = current;
 
-	oss.ss_sp = (void __user *) current->sas_ss_sp;
-	oss.ss_size = current->sas_ss_size;
-	oss.ss_flags = sas_ss_flags(sp) |
-		(current->sas_ss_flags & SS_FLAG_BITS);
+	if (oss) {
+		memset(oss, 0, sizeof(stack_t));
+		oss->ss_sp = (void __user *) t->sas_ss_sp;
+		oss->ss_size = t->sas_ss_size;
+		oss->ss_flags = sas_ss_flags(sp) |
+			(current->sas_ss_flags & SS_FLAG_BITS);
+	}
 
-	if (uss) {
-		void __user *ss_sp;
-		size_t ss_size;
-		unsigned ss_flags;
+	if (ss) {
+		void __user *ss_sp = ss->ss_sp;
+		size_t ss_size = ss->ss_size;
+		unsigned ss_flags = ss->ss_flags;
 		int ss_mode;
 
-		error = -EFAULT;
-		if (!access_ok(VERIFY_READ, uss, sizeof(*uss)))
-			goto out;
-		error = __get_user(ss_sp, &uss->ss_sp) |
-			__get_user(ss_flags, &uss->ss_flags) |
-			__get_user(ss_size, &uss->ss_size);
-		if (error)
-			goto out;
-
-		error = -EPERM;
-		if (on_sig_stack(sp))
-			goto out;
+		if (unlikely(on_sig_stack(sp)))
+			return -EPERM;
 
 		ss_mode = ss_flags & ~SS_FLAG_BITS;
-		error = -EINVAL;
-		if (ss_mode != SS_DISABLE && ss_mode != SS_ONSTACK &&
-				ss_mode != 0)
-			goto out;
+		if (unlikely(ss_mode != SS_DISABLE && ss_mode != SS_ONSTACK &&
+				ss_mode != 0))
+			return -EINVAL;
 
 		if (ss_mode == SS_DISABLE) {
 			ss_size = 0;
 			ss_sp = NULL;
 		} else {
-			error = -ENOMEM;
-			if (ss_size < MINSIGSTKSZ)
-				goto out;
+			if (unlikely(ss_size < MINSIGSTKSZ))
+				return -ENOMEM;
 		}
 
-		current->sas_ss_sp = (unsigned long) ss_sp;
-		current->sas_ss_size = ss_size;
-		current->sas_ss_flags = ss_flags;
-	}
-
-	error = 0;
-	if (uoss) {
-		error = -EFAULT;
-		if (!access_ok(VERIFY_WRITE, uoss, sizeof(*uoss)))
-			goto out;
-		error = __put_user(oss.ss_sp, &uoss->ss_sp) |
-			__put_user(oss.ss_size, &uoss->ss_size) |
-			__put_user(oss.ss_flags, &uoss->ss_flags);
+		t->sas_ss_sp = (unsigned long) ss_sp;
+		t->sas_ss_size = ss_size;
+		t->sas_ss_flags = ss_flags;
 	}
-
-out:
-	return error;
+	return 0;
 }
+
 SYSCALL_DEFINE2(sigaltstack,const stack_t __user *,uss, stack_t __user *,uoss)
 {
-	return do_sigaltstack(uss, uoss, current_user_stack_pointer());
+	stack_t new, old;
+	int err;
+	if (uss && copy_from_user(&new, uss, sizeof(stack_t)))
+		return -EFAULT;
+	err = do_sigaltstack(uss ? &new : NULL, uoss ? &old : NULL,
+			      current_user_stack_pointer());
+	if (!err && uoss && copy_to_user(uoss, &old, sizeof(stack_t)))
+		err = -EFAULT;
+	return err;
 }
 
 int restore_altstack(const stack_t __user *uss)
 {
-	int err = do_sigaltstack(uss, NULL, current_user_stack_pointer());
+	stack_t new;
+	if (copy_from_user(&new, uss, sizeof(stack_t)))
+		return -EFAULT;
+	(void)do_sigaltstack(&new, NULL, current_user_stack_pointer());
 	/* squash all but EFAULT for now */
-	return err == -EFAULT ? err : 0;
+	return 0;
 }
 
 int __save_altstack(stack_t __user *uss, unsigned long sp)
@@ -3207,29 +3197,24 @@ COMPAT_SYSCALL_DEFINE2(sigaltstack,
 {
 	stack_t uss, uoss;
 	int ret;
-	mm_segment_t seg;
 
 	if (uss_ptr) {
 		compat_stack_t uss32;
-
-		memset(&uss, 0, sizeof(stack_t));
 		if (copy_from_user(&uss32, uss_ptr, sizeof(compat_stack_t)))
 			return -EFAULT;
 		uss.ss_sp = compat_ptr(uss32.ss_sp);
 		uss.ss_flags = uss32.ss_flags;
 		uss.ss_size = uss32.ss_size;
 	}
-	seg = get_fs();
-	set_fs(KERNEL_DS);
-	ret = do_sigaltstack((stack_t __force __user *) (uss_ptr ? &uss : NULL),
-			     (stack_t __force __user *) &uoss,
+	ret = do_sigaltstack(uss_ptr ? &uss : NULL, &uoss,
 			     compat_user_stack_pointer());
-	set_fs(seg);
 	if (ret >= 0 && uoss_ptr)  {
-		if (!access_ok(VERIFY_WRITE, uoss_ptr, sizeof(compat_stack_t)) ||
-		    __put_user(ptr_to_compat(uoss.ss_sp), &uoss_ptr->ss_sp) ||
-		    __put_user(uoss.ss_flags, &uoss_ptr->ss_flags) ||
-		    __put_user(uoss.ss_size, &uoss_ptr->ss_size))
+		compat_stack_t old;
+		memset(&old, 0, sizeof(old));
+		old.ss_sp = ptr_to_compat(uoss.ss_sp);
+		old.ss_flags = uoss.ss_flags;
+		old.ss_size = uoss.ss_size;
+		if (copy_to_user(uoss_ptr, &old, sizeof(compat_stack_t)))
 			ret = -EFAULT;
 	}
 	return ret;

commit de4d195308ad589626571dbe5789cebf9695a204
Merge: dc9edaab90de 20652ed6e44f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 10 09:50:55 2017 -0700

    Merge branch 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull RCU updates from Ingo Molnar:
     "The main changes are:
    
       - Debloat RCU headers
    
       - Parallelize SRCU callback handling (plus overlapping patches)
    
       - Improve the performance of Tree SRCU on a CPU-hotplug stress test
    
       - Documentation updates
    
       - Miscellaneous fixes"
    
    * 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (74 commits)
      rcu: Open-code the rcu_cblist_n_lazy_cbs() function
      rcu: Open-code the rcu_cblist_n_cbs() function
      rcu: Open-code the rcu_cblist_empty() function
      rcu: Separately compile large rcu_segcblist functions
      srcu: Debloat the <linux/rcu_segcblist.h> header
      srcu: Adjust default auto-expediting holdoff
      srcu: Specify auto-expedite holdoff time
      srcu: Expedite first synchronize_srcu() when idle
      srcu: Expedited grace periods with reduced memory contention
      srcu: Make rcutorture writer stalls print SRCU GP state
      srcu: Exact tracking of srcu_data structures containing callbacks
      srcu: Make SRCU be built by default
      srcu: Fix Kconfig botch when SRCU not selected
      rcu: Make non-preemptive schedule be Tasks RCU quiescent state
      srcu: Expedite srcu_schedule_cbs_snp() callback invocation
      srcu: Parallelize callback handling
      kvm: Move srcu_struct fields to end of struct kvm
      rcu: Fix typo in PER_RCU_NODE_PERIOD header comment
      rcu: Use true/false in assignment to bool
      rcu: Use bool value directly
      ...

commit 6c478ae9204b489f6228e4b535c6ac72851e06d8
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Apr 17 22:10:04 2017 -0500

    signal: Make kill_proc_info static
    
    There are no users outside of signal.c so make the function static so
    the compiler and other developers have that information.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 7e59ebc2c25e..a8c54f384553 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1318,7 +1318,7 @@ int kill_pid_info(int sig, struct siginfo *info, struct pid *pid)
 	}
 }
 
-int kill_proc_info(int sig, struct siginfo *info, pid_t pid)
+static int kill_proc_info(int sig, struct siginfo *info, pid_t pid)
 {
 	int error;
 	rcu_read_lock();

commit 5f0d5a3ae7cff0d7fa943c199c3a2e44f23e1fac
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed Jan 18 02:53:44 2017 -0800

    mm: Rename SLAB_DESTROY_BY_RCU to SLAB_TYPESAFE_BY_RCU
    
    A group of Linux kernel hackers reported chasing a bug that resulted
    from their assumption that SLAB_DESTROY_BY_RCU provided an existence
    guarantee, that is, that no block from such a slab would be reallocated
    during an RCU read-side critical section.  Of course, that is not the
    case.  Instead, SLAB_DESTROY_BY_RCU only prevents freeing of an entire
    slab of blocks.
    
    However, there is a phrase for this, namely "type safety".  This commit
    therefore renames SLAB_DESTROY_BY_RCU to SLAB_TYPESAFE_BY_RCU in order
    to avoid future instances of this sort of confusion.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: Pekka Enberg <penberg@kernel.org>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: <linux-mm@kvack.org>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    [ paulmck: Add comments mentioning the old name, as requested by Eric
      Dumazet, in order to help people familiar with the old name find
      the new one. ]
    Acked-by: David Rientjes <rientjes@google.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 7e59ebc2c25e..6df5f72158e4 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1237,7 +1237,7 @@ struct sighand_struct *__lock_task_sighand(struct task_struct *tsk,
 		}
 		/*
 		 * This sighand can be already freed and even reused, but
-		 * we rely on SLAB_DESTROY_BY_RCU and sighand_ctor() which
+		 * we rely on SLAB_TYPESAFE_BY_RCU and sighand_ctor() which
 		 * initializes ->siglock: this slab can't go away, it has
 		 * the same object type, ->siglock can't be reinitialized.
 		 *

commit 32ef5517c298042ed58408545f475df43afe1f24
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Feb 5 11:48:36 2017 +0100

    sched/headers: Prepare to move cputime functionality from <linux/sched.h> into <linux/sched/cputime.h>
    
    Introduce a trivial, mostly empty <linux/sched/cputime.h> header
    to prepare for the moving of cputime functionality out of sched.h.
    
    Update all code that relies on these facilities.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2008aa999976..7e59ebc2c25e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -18,6 +18,7 @@
 #include <linux/sched/debug.h>
 #include <linux/sched/task.h>
 #include <linux/sched/task_stack.h>
+#include <linux/sched/cputime.h>
 #include <linux/fs.h>
 #include <linux/tty.h>
 #include <linux/binfmts.h>

commit 589ee62844e042b0b7d19ef57fb4cff77f3ca294
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Feb 4 00:16:44 2017 +0100

    sched/headers: Prepare to remove the <linux/mm_types.h> dependency from <linux/sched.h>
    
    Update code that relied on sched.h including various MM types for them.
    
    This will allow us to remove the <linux/mm_types.h> include from <linux/sched.h>.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index e6d470a5f75a..2008aa999976 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -13,7 +13,7 @@
 #include <linux/slab.h>
 #include <linux/export.h>
 #include <linux/init.h>
-#include <linux/sched.h>
+#include <linux/sched/mm.h>
 #include <linux/sched/user.h>
 #include <linux/sched/debug.h>
 #include <linux/sched/task.h>

commit 68db0cf10678630d286f4bbbbdfa102951a35faa
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:37 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/task_stack.h>
    
    We are going to split <linux/sched/task_stack.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/task_stack.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 25d099fd80f7..e6d470a5f75a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -17,6 +17,7 @@
 #include <linux/sched/user.h>
 #include <linux/sched/debug.h>
 #include <linux/sched/task.h>
+#include <linux/sched/task_stack.h>
 #include <linux/fs.h>
 #include <linux/tty.h>
 #include <linux/binfmts.h>

commit 299300258d1bc4e997b7db340a2e06636757fe2e
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:36 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/task.h>
    
    We are going to split <linux/sched/task.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/task.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 15092fd8c7b1..25d099fd80f7 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -16,6 +16,7 @@
 #include <linux/sched.h>
 #include <linux/sched/user.h>
 #include <linux/sched/debug.h>
+#include <linux/sched/task.h>
 #include <linux/fs.h>
 #include <linux/tty.h>
 #include <linux/binfmts.h>

commit b17b01533b719e9949e437abf66436a875739b40
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:35 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/debug.h>
    
    We are going to split <linux/sched/debug.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/debug.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 762fcf64f0c3..15092fd8c7b1 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -15,6 +15,7 @@
 #include <linux/init.h>
 #include <linux/sched.h>
 #include <linux/sched/user.h>
+#include <linux/sched/debug.h>
 #include <linux/fs.h>
 #include <linux/tty.h>
 #include <linux/binfmts.h>

commit 8703e8a465b1e9cadc3680b4b1248f5987e54518
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:30 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/user.h>
    
    We are going to split <linux/sched/user.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/user.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index bae358532d0a..762fcf64f0c3 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -14,6 +14,7 @@
 #include <linux/export.h>
 #include <linux/init.h>
 #include <linux/sched.h>
+#include <linux/sched/user.h>
 #include <linux/fs.h>
 #include <linux/tty.h>
 #include <linux/binfmts.h>

commit 780de9dd2720debc14c501dab4dc80d1f75ad50e
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Feb 2 11:50:56 2017 +0100

    sched/headers, cgroups: Remove the threadgroup_change_*() wrappery
    
    threadgroup_change_begin()/end() is a pointless wrapper around
    cgroup_threadgroup_change_begin()/end(), minus a might_sleep()
    in the !CONFIG_CGROUPS=y case.
    
    Remove the wrappery, move the might_sleep() (the down_read()
    already has a might_sleep() check).
    
    This debloats <linux/sched.h> a bit and simplifies this API.
    
    Update all call sites.
    
    No change in functionality.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 214a8feeb771..bae358532d0a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2395,11 +2395,11 @@ void exit_signals(struct task_struct *tsk)
 	 * @tsk is about to have PF_EXITING set - lock out users which
 	 * expect stable threadgroup.
 	 */
-	threadgroup_change_begin(tsk);
+	cgroup_threadgroup_change_begin(tsk);
 
 	if (thread_group_empty(tsk) || signal_group_exit(tsk->signal)) {
 		tsk->flags |= PF_EXITING;
-		threadgroup_change_end(tsk);
+		cgroup_threadgroup_change_end(tsk);
 		return;
 	}
 
@@ -2410,7 +2410,7 @@ void exit_signals(struct task_struct *tsk)
 	 */
 	tsk->flags |= PF_EXITING;
 
-	threadgroup_change_end(tsk);
+	cgroup_threadgroup_change_end(tsk);
 
 	if (!signal_pending(tsk))
 		goto out;

commit 441398d378f29a5ad6d0fcda07918e54e4961800
Author: Stas Sergeev <stsp@list.ru>
Date:   Mon Feb 27 14:27:25 2017 -0800

    sigaltstack: support SS_AUTODISARM for CONFIG_COMPAT
    
    Currently SS_AUTODISARM is not supported in compatibility mode, but does
    not return -EINVAL either.  This makes dosemu built with -m32 on x86_64
    to crash.  Also the kernel's sigaltstack selftest fails if compiled with
    -m32.
    
    This patch adds the needed support.
    
    Link: http://lkml.kernel.org/r/20170205101213.8163-2-stsp@list.ru
    Signed-off-by: Stas Sergeev <stsp@users.sourceforge.net>
    Cc: Milosz Tanski <milosz@adfin.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Nicolas Pitre <nicolas.pitre@linaro.org>
    Cc: Waiman Long <Waiman.Long@hpe.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Dmitry Safonov <dsafonov@virtuozzo.com>
    Cc: Wang Xiaoqiang <wangxq10@lzu.edu.cn>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 13f9def8b24a..214a8feeb771 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3239,10 +3239,17 @@ int compat_restore_altstack(const compat_stack_t __user *uss)
 
 int __compat_save_altstack(compat_stack_t __user *uss, unsigned long sp)
 {
+	int err;
 	struct task_struct *t = current;
-	return  __put_user(ptr_to_compat((void __user *)t->sas_ss_sp), &uss->ss_sp) |
-		__put_user(sas_ss_flags(sp), &uss->ss_flags) |
+	err = __put_user(ptr_to_compat((void __user *)t->sas_ss_sp),
+			 &uss->ss_sp) |
+		__put_user(t->sas_ss_flags, &uss->ss_flags) |
 		__put_user(t->sas_ss_size, &uss->ss_size);
+	if (err)
+		return err;
+	if (t->sas_ss_flags & SS_AUTODISARM)
+		sas_ss_reset(t);
+	return 0;
 }
 #endif
 

commit bde8285e5cf78417afda79f53bbc26ef801a27e7
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Jan 31 04:09:31 2017 +0100

    signal: Convert obsolete cputime type to nsecs
    
    Use the new nsec based cputime accessors as part of the whole cputime
    conversion from cputime_t to nsecs.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1485832191-26889-16-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index b63522193076..13f9def8b24a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1581,7 +1581,7 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 	unsigned long flags;
 	struct sighand_struct *psig;
 	bool autoreap = false;
-	cputime_t utime, stime;
+	u64 utime, stime;
 
 	BUG_ON(sig == -1);
 
@@ -1619,9 +1619,9 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 				       task_uid(tsk));
 	rcu_read_unlock();
 
-	task_cputime_t(tsk, &utime, &stime);
-	info.si_utime = cputime_to_clock_t(utime + nsecs_to_cputime(tsk->signal->utime));
-	info.si_stime = cputime_to_clock_t(stime + nsecs_to_cputime(tsk->signal->stime));
+	task_cputime(tsk, &utime, &stime);
+	info.si_utime = nsec_to_clock_t(utime + tsk->signal->utime);
+	info.si_stime = nsec_to_clock_t(stime + tsk->signal->stime);
 
 	info.si_status = tsk->exit_code & 0x7f;
 	if (tsk->exit_code & 0x80)
@@ -1685,7 +1685,7 @@ static void do_notify_parent_cldstop(struct task_struct *tsk,
 	unsigned long flags;
 	struct task_struct *parent;
 	struct sighand_struct *sighand;
-	cputime_t utime, stime;
+	u64 utime, stime;
 
 	if (for_ptracer) {
 		parent = tsk->parent;
@@ -1704,9 +1704,9 @@ static void do_notify_parent_cldstop(struct task_struct *tsk,
 	info.si_uid = from_kuid_munged(task_cred_xxx(parent, user_ns), task_uid(tsk));
 	rcu_read_unlock();
 
-	task_cputime_t(tsk, &utime, &stime);
-	info.si_utime = cputime_to_clock_t(utime);
-	info.si_stime = cputime_to_clock_t(stime);
+	task_cputime(tsk, &utime, &stime);
+	info.si_utime = nsec_to_clock_t(utime);
+	info.si_stime = nsec_to_clock_t(stime);
 
  	info.si_code = why;
  	switch (why) {

commit 5613fda9a503cd6137b120298902a34a1386b2c1
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Jan 31 04:09:23 2017 +0100

    sched/cputime: Convert task/group cputime to nsecs
    
    Now that most cputime readers use the transition API which return the
    task cputime in old style cputime_t, we can safely store the cputime in
    nsecs. This will eventually make cputime statistics less opaque and more
    granular. Back and forth convertions between cputime_t and nsecs in order
    to deal with cputime_t random granularity won't be needed anymore.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1485832191-26889-8-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 218048a837ea..b63522193076 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1620,8 +1620,8 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 	rcu_read_unlock();
 
 	task_cputime_t(tsk, &utime, &stime);
-	info.si_utime = cputime_to_clock_t(utime + tsk->signal->utime);
-	info.si_stime = cputime_to_clock_t(stime + tsk->signal->stime);
+	info.si_utime = cputime_to_clock_t(utime + nsecs_to_cputime(tsk->signal->utime));
+	info.si_stime = cputime_to_clock_t(stime + nsecs_to_cputime(tsk->signal->stime));
 
 	info.si_status = tsk->exit_code & 0x7f;
 	if (tsk->exit_code & 0x80)

commit a1cecf2ba78e0a6de00ff99df34b662728535aa5
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Jan 31 04:09:22 2017 +0100

    sched/cputime: Introduce special task_cputime_t() API to return old-typed cputime
    
    This API returns a task's cputime in cputime_t in order to ease the
    conversion of cputime internals to use nsecs units instead. Blindly
    converting all cputime readers to use this API now will later let us
    convert more smoothly and step by step all these places to use the
    new nsec based cputime.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1485832191-26889-7-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 3603d93a1968..218048a837ea 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1619,7 +1619,7 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 				       task_uid(tsk));
 	rcu_read_unlock();
 
-	task_cputime(tsk, &utime, &stime);
+	task_cputime_t(tsk, &utime, &stime);
 	info.si_utime = cputime_to_clock_t(utime + tsk->signal->utime);
 	info.si_stime = cputime_to_clock_t(stime + tsk->signal->stime);
 
@@ -1704,7 +1704,7 @@ static void do_notify_parent_cldstop(struct task_struct *tsk,
 	info.si_uid = from_kuid_munged(task_cred_xxx(parent, user_ns), task_uid(tsk));
 	rcu_read_unlock();
 
-	task_cputime(tsk, &utime, &stime);
+	task_cputime_t(tsk, &utime, &stime);
 	info.si_utime = cputime_to_clock_t(utime);
 	info.si_stime = cputime_to_clock_t(stime);
 

commit 2d39b3cd34e6d323720d4c61bd714f5ae202c022
Author: Jamie Iles <jamie.iles@oracle.com>
Date:   Tue Jan 10 16:57:54 2017 -0800

    signal: protect SIGNAL_UNKILLABLE from unintentional clearing.
    
    Since commit 00cd5c37afd5 ("ptrace: permit ptracing of /sbin/init") we
    can now trace init processes.  init is initially protected with
    SIGNAL_UNKILLABLE which will prevent fatal signals such as SIGSTOP, but
    there are a number of paths during tracing where SIGNAL_UNKILLABLE can
    be implicitly cleared.
    
    This can result in init becoming stoppable/killable after tracing.  For
    example, running:
    
      while true; do kill -STOP 1; done &
      strace -p 1
    
    and then stopping strace and the kill loop will result in init being
    left in state TASK_STOPPED.  Sending SIGCONT to init will resume it, but
    init will now respond to future SIGSTOP signals rather than ignoring
    them.
    
    Make sure that when setting SIGNAL_STOP_CONTINUED/SIGNAL_STOP_STOPPED
    that we don't clear SIGNAL_UNKILLABLE.
    
    Link: http://lkml.kernel.org/r/20170104122017.25047-1-jamie.iles@oracle.com
    Signed-off-by: Jamie Iles <jamie.iles@oracle.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index ff046b73ff2d..3603d93a1968 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -346,7 +346,7 @@ static bool task_participate_group_stop(struct task_struct *task)
 	 * fresh group stop.  Read comment in do_signal_stop() for details.
 	 */
 	if (!sig->group_stop_count && !(sig->flags & SIGNAL_STOP_STOPPED)) {
-		sig->flags = SIGNAL_STOP_STOPPED;
+		signal_set_stop_flags(sig, SIGNAL_STOP_STOPPED);
 		return true;
 	}
 	return false;
@@ -843,7 +843,7 @@ static bool prepare_signal(int sig, struct task_struct *p, bool force)
 			 * will take ->siglock, notice SIGNAL_CLD_MASK, and
 			 * notify its parent. See get_signal_to_deliver().
 			 */
-			signal->flags = why | SIGNAL_STOP_CONTINUED;
+			signal_set_stop_flags(signal, why | SIGNAL_STOP_CONTINUED);
 			signal->group_stop_count = 0;
 			signal->group_exit_code = 0;
 		}

commit 2456e855354415bfaeb7badaa14e11b3e02c8466
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Dec 25 11:38:40 2016 +0100

    ktime: Get rid of the union
    
    ktime is a union because the initial implementation stored the time in
    scalar nanoseconds on 64 bit machine and in a endianess optimized timespec
    variant for 32bit machines. The Y2038 cleanup removed the timespec variant
    and switched everything to scalar nanoseconds. The union remained, but
    become completely pointless.
    
    Get rid of the union and just keep ktime_t as simple typedef of type s64.
    
    The conversion was done with coccinelle and some manual mopping up.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index f5d4e275345e..ff046b73ff2d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -587,7 +587,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 			struct hrtimer *tmr = &tsk->signal->real_timer;
 
 			if (!hrtimer_is_queued(tmr) &&
-			    tsk->signal->it_real_incr.tv64 != 0) {
+			    tsk->signal->it_real_incr != 0) {
 				hrtimer_forward(tmr, tmr->base->get_time(),
 						tsk->signal->it_real_incr);
 				hrtimer_restart(tmr);
@@ -2766,7 +2766,7 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
 		    const struct timespec *ts)
 {
-	ktime_t *to = NULL, timeout = { .tv64 = KTIME_MAX };
+	ktime_t *to = NULL, timeout = KTIME_MAX;
 	struct task_struct *tsk = current;
 	sigset_t mask = *which;
 	int sig, ret = 0;
@@ -2786,7 +2786,7 @@ int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
 
 	spin_lock_irq(&tsk->sighand->siglock);
 	sig = dequeue_signal(tsk, &mask, info);
-	if (!sig && timeout.tv64) {
+	if (!sig && timeout) {
 		/*
 		 * None ready, temporarily unblock those we're interested
 		 * while we are sleeping in so that we'll be awakened when

commit 7c0f6ba682b9c7632072ffbedf8d328c8f3c42ba
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Dec 24 11:46:01 2016 -0800

    Replace <asm/uaccess.h> with <linux/uaccess.h> globally
    
    This was entirely automated, using the script by Al:
    
      PATT='^[[:blank:]]*#[[:blank:]]*include[[:blank:]]*<asm/uaccess.h>'
      sed -i -e "s!$PATT!#include <linux/uaccess.h>!" \
            $(git grep -l "$PATT"|grep -v ^include/linux/uaccess.h)
    
    to do the replacement at the end of the merge window.
    
    Requested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index ae60996fedff..f5d4e275345e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -39,7 +39,7 @@
 #include <trace/events/signal.h>
 
 #include <asm/param.h>
-#include <asm/uaccess.h>
+#include <linux/uaccess.h>
 #include <asm/unistd.h>
 #include <asm/siginfo.h>
 #include <asm/cacheflush.h>

commit c7be96af89d4b53211862d8599b2430e8900ed92
Author: Waiman Long <Waiman.Long@hpe.com>
Date:   Wed Dec 14 15:04:10 2016 -0800

    signals: avoid unnecessary taking of sighand->siglock
    
    When running certain database workload on a high-end system with many
    CPUs, it was found that spinlock contention in the sigprocmask syscalls
    became a significant portion of the overall CPU cycles as shown below.
    
      9.30%  9.30%  905387  dataserver  /proc/kcore 0x7fff8163f4d2
      [k] _raw_spin_lock_irq
                |
                ---_raw_spin_lock_irq
                   |
                   |--99.34%-- __set_current_blocked
                   |          sigprocmask
                   |          sys_rt_sigprocmask
                   |          system_call_fastpath
                   |          |
                   |          |--50.63%-- __swapcontext
                   |          |          |
                   |          |          |--99.91%-- upsleepgeneric
                   |          |
                   |          |--49.36%-- __setcontext
                   |          |          ktskRun
    
    Looking further into the swapcontext function in glibc, it was found that
    the function always call sigprocmask() without checking if there are
    changes in the signal mask.
    
    A check was added to the __set_current_blocked() function to avoid taking
    the sighand->siglock spinlock if there is no change in the signal mask.
    This will prevent unneeded spinlock contention when many threads are
    trying to call sigprocmask().
    
    With this patch applied, the spinlock contention in sigprocmask() was
    gone.
    
    Link: http://lkml.kernel.org/r/1474979209-11867-1-git-send-email-Waiman.Long@hpe.com
    Signed-off-by: Waiman Long <Waiman.Long@hpe.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Stas Sergeev <stsp@list.ru>
    Cc: Scott J Norton <scott.norton@hpe.com>
    Cc: Douglas Hatch <doug.hatch@hpe.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 29a410780aa9..ae60996fedff 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2491,6 +2491,13 @@ void __set_current_blocked(const sigset_t *newset)
 {
 	struct task_struct *tsk = current;
 
+	/*
+	 * In case the signal mask hasn't changed, there is nothing we need
+	 * to do. The current->blocked shouldn't be modified by other task.
+	 */
+	if (sigequalsets(&tsk->blocked, newset))
+		return;
+
 	spin_lock_irq(&tsk->sighand->siglock);
 	__set_task_blocked(tsk, newset);
 	spin_unlock_irq(&tsk->sighand->siglock);

commit baa73d9e478ff32d62f3f9422822b59dd9a95a21
Author: Nicolas Pitre <nicolas.pitre@linaro.org>
Date:   Fri Nov 11 00:10:10 2016 -0500

    posix-timers: Make them configurable
    
    Some embedded systems have no use for them.  This removes about
    25KB from the kernel binary size when configured out.
    
    Corresponding syscalls are routed to a stub logging the attempt to
    use those syscalls which should be enough of a clue if they were
    disabled without proper consideration. They are: timer_create,
    timer_gettime: timer_getoverrun, timer_settime, timer_delete,
    clock_adjtime, setitimer, getitimer, alarm.
    
    The clock_settime, clock_gettime, clock_getres and clock_nanosleep
    syscalls are replaced by simple wrappers compatible with CLOCK_REALTIME,
    CLOCK_MONOTONIC and CLOCK_BOOTTIME only which should cover the vast
    majority of use cases with very little code.
    
    Signed-off-by: Nicolas Pitre <nico@linaro.org>
    Acked-by: Richard Cochran <richardcochran@gmail.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: John Stultz <john.stultz@linaro.org>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>
    Cc: Paul Bolle <pebolle@tiscali.nl>
    Cc: linux-kbuild@vger.kernel.org
    Cc: netdev@vger.kernel.org
    Cc: Michal Marek <mmarek@suse.com>
    Cc: Edward Cree <ecree@solarflare.com>
    Link: http://lkml.kernel.org/r/1478841010-28605-7-git-send-email-nicolas.pitre@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/signal.c b/kernel/signal.c
index 75761acc77cf..29a410780aa9 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -427,6 +427,7 @@ void flush_signals(struct task_struct *t)
 	spin_unlock_irqrestore(&t->sighand->siglock, flags);
 }
 
+#ifdef CONFIG_POSIX_TIMERS
 static void __flush_itimer_signals(struct sigpending *pending)
 {
 	sigset_t signal, retain;
@@ -460,6 +461,7 @@ void flush_itimer_signals(void)
 	__flush_itimer_signals(&tsk->signal->shared_pending);
 	spin_unlock_irqrestore(&tsk->sighand->siglock, flags);
 }
+#endif
 
 void ignore_signals(struct task_struct *t)
 {
@@ -567,6 +569,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 	if (!signr) {
 		signr = __dequeue_signal(&tsk->signal->shared_pending,
 					 mask, info);
+#ifdef CONFIG_POSIX_TIMERS
 		/*
 		 * itimer signal ?
 		 *
@@ -590,6 +593,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 				hrtimer_restart(tmr);
 			}
 		}
+#endif
 	}
 
 	recalc_sigpending();
@@ -611,6 +615,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 		 */
 		current->jobctl |= JOBCTL_STOP_DEQUEUED;
 	}
+#ifdef CONFIG_POSIX_TIMERS
 	if ((info->si_code & __SI_MASK) == __SI_TIMER && info->si_sys_private) {
 		/*
 		 * Release the siglock to ensure proper locking order
@@ -622,6 +627,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 		do_schedule_next_timer(info);
 		spin_lock(&tsk->sighand->siglock);
 	}
+#endif
 	return signr;
 }
 

commit 6846351052e685c2d1428e80ead2d7ca3d7ed913
Author: Dmitry Safonov <dsafonov@virtuozzo.com>
Date:   Mon Sep 5 16:33:08 2016 +0300

    x86/signal: Add SA_{X32,IA32}_ABI sa_flags
    
    Introduce new flags that defines which ABI to use on creating sigframe.
    Those flags kernel will set according to sigaction syscall ABI,
    which set handler for the signal being delivered.
    
    So that will drop the dependency on TIF_IA32/TIF_X32 flags on signal deliver.
    Those flags will be used only under CONFIG_COMPAT.
    
    Similar way ARM uses sa_flags to differ in which mode deliver signal
    for 26-bit applications (look at SA_THIRYTWO).
    
    Signed-off-by: Dmitry Safonov <dsafonov@virtuozzo.com>
    Reviewed-by: Andy Lutomirski <luto@kernel.org>
    Cc: 0x7f454c46@gmail.com
    Cc: oleg@redhat.com
    Cc: linux-mm@kvack.org
    Cc: gorcunov@openvz.org
    Cc: xemul@virtuozzo.com
    Link: http://lkml.kernel.org/r/20160905133308.28234-7-dsafonov@virtuozzo.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/signal.c b/kernel/signal.c
index af21afc00d08..75761acc77cf 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3044,6 +3044,11 @@ void kernel_sigaction(int sig, __sighandler_t action)
 }
 EXPORT_SYMBOL(kernel_sigaction);
 
+void __weak sigaction_compat_abi(struct k_sigaction *act,
+		struct k_sigaction *oact)
+{
+}
+
 int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 {
 	struct task_struct *p = current, *t;
@@ -3059,6 +3064,8 @@ int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 	if (oact)
 		*oact = *k;
 
+	sigaction_compat_abi(act, oact);
+
 	if (act) {
 		sigdelsetmask(&act->sa.sa_mask,
 			      sigmask(SIGKILL) | sigmask(SIGSTOP));

commit 2b1ecc3d1a6b10f8fbac7f83d80db30b5a2c2791
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jul 4 09:50:25 2016 +0000

    signals: Use hrtimer for sigtimedwait()
    
    We've converted most timeout related syscalls to hrtimers, but
    sigtimedwait() did not get this treatment.
    
    Convert it so we get a reasonable accuracy and remove the
    user space exposure to the timer wheel properties.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Arjan van de Ven <arjan@infradead.org>
    Cc: Chris Mason <clm@fb.com>
    Cc: Cyril Hrubis <chrubis@suse.cz>
    Cc: George Spelvin <linux@sciencehorizons.net>
    Cc: Josh Triplett <josh@joshtriplett.org>
    Cc: Len Brown <lenb@kernel.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: rt@linutronix.de
    Link: http://lkml.kernel.org/r/20160704094341.787164909@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 96e9bc40667f..af21afc00d08 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2751,23 +2751,18 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
  *  @ts: upper bound on process time suspension
  */
 int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
-			const struct timespec *ts)
+		    const struct timespec *ts)
 {
+	ktime_t *to = NULL, timeout = { .tv64 = KTIME_MAX };
 	struct task_struct *tsk = current;
-	long timeout = MAX_SCHEDULE_TIMEOUT;
 	sigset_t mask = *which;
-	int sig;
+	int sig, ret = 0;
 
 	if (ts) {
 		if (!timespec_valid(ts))
 			return -EINVAL;
-		timeout = timespec_to_jiffies(ts);
-		/*
-		 * We can be close to the next tick, add another one
-		 * to ensure we will wait at least the time asked for.
-		 */
-		if (ts->tv_sec || ts->tv_nsec)
-			timeout++;
+		timeout = timespec_to_ktime(*ts);
+		to = &timeout;
 	}
 
 	/*
@@ -2778,7 +2773,7 @@ int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
 
 	spin_lock_irq(&tsk->sighand->siglock);
 	sig = dequeue_signal(tsk, &mask, info);
-	if (!sig && timeout) {
+	if (!sig && timeout.tv64) {
 		/*
 		 * None ready, temporarily unblock those we're interested
 		 * while we are sleeping in so that we'll be awakened when
@@ -2790,8 +2785,9 @@ int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
 		recalc_sigpending();
 		spin_unlock_irq(&tsk->sighand->siglock);
 
-		timeout = freezable_schedule_timeout_interruptible(timeout);
-
+		__set_current_state(TASK_INTERRUPTIBLE);
+		ret = freezable_schedule_hrtimeout_range(to, tsk->timer_slack_ns,
+							 HRTIMER_MODE_REL);
 		spin_lock_irq(&tsk->sighand->siglock);
 		__set_task_blocked(tsk, &tsk->real_blocked);
 		sigemptyset(&tsk->real_blocked);
@@ -2801,7 +2797,7 @@ int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
 
 	if (sig)
 		return sig;
-	return timeout ? -EINTR : -EAGAIN;
+	return ret ? -EINTR : -EAGAIN;
 }
 
 /**

commit 747800efbe8b98459f48d1d9d742298f8283f8fa
Author: Wang Xiaoqiang <wangxq10@lzu.edu.cn>
Date:   Mon May 23 16:23:59 2016 -0700

    kernel/signal.c: convert printk(KERN_<LEVEL> ...) to pr_<level>(...)
    
    Use pr_<level> instead of printk(KERN_<LEVEL> ).
    
    Signed-off-by: Wang Xiaoqiang <wangxq10@lzu.edu.cn>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index ab122a2cee41..96e9bc40667f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -224,7 +224,7 @@ static inline void print_dropped_signal(int sig)
 	if (!__ratelimit(&ratelimit_state))
 		return;
 
-	printk(KERN_INFO "%s/%d: reached RLIMIT_SIGPENDING, dropped signal %d\n",
+	pr_info("%s/%d: reached RLIMIT_SIGPENDING, dropped signal %d\n",
 				current->comm, current->pid, sig);
 }
 
@@ -1089,10 +1089,10 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 static void print_fatal_signal(int signr)
 {
 	struct pt_regs *regs = signal_pt_regs();
-	printk(KERN_INFO "potentially unexpected fatal signal %d.\n", signr);
+	pr_info("potentially unexpected fatal signal %d.\n", signr);
 
 #if defined(__i386__) && !defined(__arch_um__)
-	printk(KERN_INFO "code at %08lx: ", regs->ip);
+	pr_info("code at %08lx: ", regs->ip);
 	{
 		int i;
 		for (i = 0; i < 16; i++) {
@@ -1100,10 +1100,10 @@ static void print_fatal_signal(int signr)
 
 			if (get_user(insn, (unsigned char *)(regs->ip + i)))
 				break;
-			printk(KERN_CONT "%02x ", insn);
+			pr_cont("%02x ", insn);
 		}
 	}
-	printk(KERN_CONT "\n");
+	pr_cont("\n");
 #endif
 	preempt_disable();
 	show_regs(regs);

commit 0318bc8a919ded355eaa5078689924a15c1bf52a
Author: Andy Lutomirski <luto@kernel.org>
Date:   Tue May 3 10:31:51 2016 -0700

    signals/sigaltstack: Report current flag bits in sigaltstack()
    
    sigaltstack()'s reported previous state uses a somewhat odd
    convention, but the concept of flag bits is new, and we can do the
    flag bits sensibly.  Specifically, let's just report them directly.
    
    This will allow saving and restoring the sigaltstack state using
    sigaltstack() to work correctly.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Amanieu d'Antras <amanieu@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Pavel Emelyanov <xemul@parallels.com>
    Cc: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Sasha Levin <sasha.levin@oracle.com>
    Cc: Shuah Khan <shuahkh@osg.samsung.com>
    Cc: Stas Sergeev <stsp@list.ru>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vladimir Davydov <vdavydov@parallels.com>
    Cc: linux-api@vger.kernel.org
    Link: http://lkml.kernel.org/r/94b291ec9fd47741a9264851e316e158ded0b00d.1462296606.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index bf97ea5775ae..ab122a2cee41 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3099,7 +3099,8 @@ do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long s
 
 	oss.ss_sp = (void __user *) current->sas_ss_sp;
 	oss.ss_size = current->sas_ss_size;
-	oss.ss_flags = sas_ss_flags(sp);
+	oss.ss_flags = sas_ss_flags(sp) |
+		(current->sas_ss_flags & SS_FLAG_BITS);
 
 	if (uss) {
 		void __user *ss_sp;

commit 2a74213838104a41588d86fd5e8d344972891ace
Author: Stas Sergeev <stsp@list.ru>
Date:   Thu Apr 14 23:20:04 2016 +0300

    signals/sigaltstack: Implement SS_AUTODISARM flag
    
    This patch implements the SS_AUTODISARM flag that can be OR-ed with
    SS_ONSTACK when forming ss_flags.
    
    When this flag is set, sigaltstack will be disabled when entering
    the signal handler; more precisely, after saving sas to uc_stack.
    When leaving the signal handler, the sigaltstack is restored by
    uc_stack.
    
    When this flag is used, it is safe to switch from sighandler with
    swapcontext(). Without this flag, the subsequent signal will corrupt
    the state of the switched-away sighandler.
    
    To detect the support of this functionality, one can do:
    
      err = sigaltstack(SS_DISABLE | SS_AUTODISARM);
      if (err && errno == EINVAL)
            unsupported();
    
    Signed-off-by: Stas Sergeev <stsp@list.ru>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Aleksa Sarai <cyphar@cyphar.com>
    Cc: Amanieu d'Antras <amanieu@gmail.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Heinrich Schuchardt <xypron.glpk@gmx.de>
    Cc: Jason Low <jason.low2@hp.com>
    Cc: Josh Triplett <josh@joshtriplett.org>
    Cc: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Palmer Dabbelt <palmer@dabbelt.com>
    Cc: Paul Moore <pmoore@redhat.com>
    Cc: Pavel Emelyanov <xemul@parallels.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Sasha Levin <sasha.levin@oracle.com>
    Cc: Shuah Khan <shuahkh@osg.samsung.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vladimir Davydov <vdavydov@parallels.com>
    Cc: linux-api@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org
    Link: http://lkml.kernel.org/r/1460665206-13646-4-git-send-email-stsp@list.ru
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index b1c6eb4df2a8..bf97ea5775ae 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3137,6 +3137,7 @@ do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long s
 
 		current->sas_ss_sp = (unsigned long) ss_sp;
 		current->sas_ss_size = ss_size;
+		current->sas_ss_flags = ss_flags;
 	}
 
 	error = 0;
@@ -3167,9 +3168,14 @@ int restore_altstack(const stack_t __user *uss)
 int __save_altstack(stack_t __user *uss, unsigned long sp)
 {
 	struct task_struct *t = current;
-	return  __put_user((void __user *)t->sas_ss_sp, &uss->ss_sp) |
-		__put_user(sas_ss_flags(sp), &uss->ss_flags) |
+	int err = __put_user((void __user *)t->sas_ss_sp, &uss->ss_sp) |
+		__put_user(t->sas_ss_flags, &uss->ss_flags) |
 		__put_user(t->sas_ss_size, &uss->ss_size);
+	if (err)
+		return err;
+	if (t->sas_ss_flags & SS_AUTODISARM)
+		sas_ss_reset(t);
+	return 0;
 }
 
 #ifdef CONFIG_COMPAT

commit 407bc16ad1769f5cb8ad9555611cb198187ef4cd
Author: Stas Sergeev <stsp@list.ru>
Date:   Thu Apr 14 23:20:03 2016 +0300

    signals/sigaltstack: Prepare to add new SS_xxx flags
    
    This patch adds SS_FLAG_BITS - the mask that splits sigaltstack
    mode values and bit-flags. Since there is no bit-flags yet, the
    mask is defined to 0. The flags are added by subsequent patches.
    With every new flag, the mask should have the appropriate bit cleared.
    
    This makes sure if some flag is tried on a kernel that doesn't
    support it, the -EINVAL error will be returned, because such a
    flag will be treated as an invalid mode rather than the bit-flag.
    
    That way the existence of the particular features can be probed
    at run-time.
    
    This change was suggested by Andy Lutomirski:
    
      https://lkml.org/lkml/2016/3/6/158
    
    Signed-off-by: Stas Sergeev <stsp@list.ru>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Amanieu d'Antras <amanieu@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Pavel Emelyanov <xemul@parallels.com>
    Cc: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Sasha Levin <sasha.levin@oracle.com>
    Cc: Shuah Khan <shuahkh@osg.samsung.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vladimir Davydov <vdavydov@parallels.com>
    Cc: linux-api@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org
    Link: http://lkml.kernel.org/r/1460665206-13646-3-git-send-email-stsp@list.ru
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index aa9bf00749c1..b1c6eb4df2a8 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3104,7 +3104,8 @@ do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long s
 	if (uss) {
 		void __user *ss_sp;
 		size_t ss_size;
-		int ss_flags;
+		unsigned ss_flags;
+		int ss_mode;
 
 		error = -EFAULT;
 		if (!access_ok(VERIFY_READ, uss, sizeof(*uss)))
@@ -3119,18 +3120,13 @@ do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long s
 		if (on_sig_stack(sp))
 			goto out;
 
+		ss_mode = ss_flags & ~SS_FLAG_BITS;
 		error = -EINVAL;
-		/*
-		 * Note - this code used to test ss_flags incorrectly:
-		 *  	  old code may have been written using ss_flags==0
-		 *	  to mean ss_flags==SS_ONSTACK (as this was the only
-		 *	  way that worked) - this fix preserves that older
-		 *	  mechanism.
-		 */
-		if (ss_flags != SS_DISABLE && ss_flags != SS_ONSTACK && ss_flags != 0)
+		if (ss_mode != SS_DISABLE && ss_mode != SS_ONSTACK &&
+				ss_mode != 0)
 			goto out;
 
-		if (ss_flags == SS_DISABLE) {
+		if (ss_mode == SS_DISABLE) {
 			ss_size = 0;
 			ss_sp = NULL;
 		} else {

commit 41b27154874b3a40d6673052d08c8e9fd0c6404f
Author: Helge Deller <deller@gmx.de>
Date:   Tue Mar 22 14:27:54 2016 -0700

    kernel/signal.c: add compile-time check for __ARCH_SI_PREAMBLE_SIZE
    
    The value of __ARCH_SI_PREAMBLE_SIZE defines the size (including
    padding) of the part of the struct siginfo that is before the union, and
    it is then used to calculate the needed padding (SI_PAD_SIZE) to make
    the size of struct siginfo equal to 128 (SI_MAX_SIZE) bytes.
    
    Depending on the target architecture and word width it equals to either
    3 or 4 times sizeof int.
    
    Since the very beginning we had __ARCH_SI_PREAMBLE_SIZE wrong on the
    parisc architecture for the 64bit kernel build.  It's even more
    frustrating, because it can easily be checked at compile time if the
    value was defined correctly.
    
    This patch adds such a check for the correctness of
    __ARCH_SI_PREAMBLE_SIZE in the hope that it will prevent existing and
    future architectures from running into the same problem.
    
    I refrained from replacing __ARCH_SI_PREAMBLE_SIZE by offsetof() in
    copy_siginfo() in include/asm-generic/siginfo.h, because a) it doesn't
    make any difference and b) it's used in the Documentation/kmemcheck.txt
    example.
    
    I ran this patch through the 0-DAY kernel test infrastructure and only
    the parisc architecture triggered as expected.  That means that this
    patch should be OK for all major architectures.
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index fe8ed298373c..aa9bf00749c1 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3585,6 +3585,10 @@ __weak const char *arch_vma_name(struct vm_area_struct *vma)
 
 void __init signals_init(void)
 {
+	/* If this check fails, the __ARCH_SI_PREAMBLE_SIZE value is wrong! */
+	BUILD_BUG_ON(__ARCH_SI_PREAMBLE_SIZE
+		!= offsetof(struct siginfo, _sifields._pad));
+
 	sigqueue_cachep = KMEM_CACHE(sigqueue, SLAB_PANIC);
 }
 

commit cd0ea35ff5511cde299a61c21a95889b4a71464e
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Fri Feb 12 13:02:12 2016 -0800

    signals, pkeys: Notify userspace about protection key faults
    
    A protection key fault is very similar to any other access error.
    There must be a VMA, etc...  We even want to take the same action
    (SIGSEGV) that we do with a normal access fault.
    
    However, we do need to let userspace know that something is
    different.  We do this the same way what we did with SEGV_BNDERR
    with Memory Protection eXtensions (MPX): define a new SEGV code:
    SEGV_PKUERR.
    
    We add a siginfo field: si_pkey that reveals to userspace which
    protection key was set on the PTE that we faulted on.  There is
    no other easy way for userspace to figure this out.  They could
    parse smaps but that would be a bit cruel.
    
    We share space with in siginfo with _addr_bnd.  #BR faults from
    MPX are completely separate from page faults (#PF) that trigger
    from protection key violations, so we never need both at the same
    time.
    
    Note that _pkey is a 64-bit value.  The current hardware only
    supports 4-bit protection keys.  We do this because there is
    _plenty_ of space in _sigfault and it is possible that future
    processors would support more than 4 bits of protection keys.
    
    The x86 code to actually fill in the siginfo is in the next
    patch.
    
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Amanieu d'Antras <amanieu@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave@sr71.net>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Palmer Dabbelt <palmer@dabbelt.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Sasha Levin <sasha.levin@oracle.com>
    Cc: Vegard Nossum <vegard.nossum@oracle.com>
    Cc: Vladimir Davydov <vdavydov@parallels.com>
    Cc: linux-arch@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/20160212210212.3A9B83AC@viggo.jf.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0508544c8ced..fe8ed298373c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2708,6 +2708,10 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 			err |= __put_user(from->si_lower, &to->si_lower);
 			err |= __put_user(from->si_upper, &to->si_upper);
 		}
+#endif
+#ifdef SEGV_PKUERR
+		if (from->si_signo == SIGSEGV && from->si_code == SEGV_PKUERR)
+			err |= __put_user(from->si_pkey, &to->si_pkey);
 #endif
 		break;
 	case __SI_CHLD:

commit 823dd3224a07f618d652a7743c9603222d019de3
Author: Sasha Levin <sasha.levin@oracle.com>
Date:   Fri Feb 5 15:36:05 2016 -0800

    signals: avoid random wakeups in sigsuspend()
    
    A random wakeup can get us out of sigsuspend() without TIF_SIGPENDING
    being set.
    
    Avoid that by making sure we were signaled, like sys_pause() does.
    
    Signed-off-by: Sasha Levin <sasha.levin@oracle.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index f3f1f7a972fd..0508544c8ced 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3508,8 +3508,10 @@ static int sigsuspend(sigset_t *set)
 	current->saved_sigmask = current->blocked;
 	set_current_blocked(set);
 
-	__set_current_state(TASK_INTERRUPTIBLE);
-	schedule();
+	while (!signal_pending(current)) {
+		__set_current_state(TASK_INTERRUPTIBLE);
+		schedule();
+	}
 	set_restore_sigmask();
 	return -ERESTARTNOHAND;
 }

commit 9d8a765211335cfdad464b90fb19f546af5706ae
Author: Richard Weinberger <richard@nod.at>
Date:   Fri Nov 20 15:57:21 2015 -0800

    kernel/signal.c: unexport sigsuspend()
    
    sigsuspend() is nowhere used except in signal.c itself, so we can mark it
    static do not pollute the global namespace.
    
    But this patch is more than a boring cleanup patch, it fixes a real issue
    on UserModeLinux.  UML has a special console driver to display ttys using
    xterm, or other terminal emulators, on the host side.  Vegard reported
    that sometimes UML is unable to spawn a xterm and he's facing the
    following warning:
    
      WARNING: CPU: 0 PID: 908 at include/linux/thread_info.h:128 sigsuspend+0xab/0xc0()
    
    It turned out that this warning makes absolutely no sense as the UML
    xterm code calls sigsuspend() on the host side, at least it tries.  But
    as the kernel itself offers a sigsuspend() symbol the linker choose this
    one instead of the glibc wrapper.  Interestingly this code used to work
    since ever but always blocked signals on the wrong side.  Some recent
    kernel change made the WARN_ON() trigger and uncovered the bug.
    
    It is a wonderful example of how much works by chance on computers. :-)
    
    Fixes: 68f3f16d9ad0f1 ("new helper: sigsuspend()")
    Signed-off-by: Richard Weinberger <richard@nod.at>
    Reported-by: Vegard Nossum <vegard.nossum@oracle.com>
    Tested-by: Vegard Nossum <vegard.nossum@oracle.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Cc: <stable@vger.kernel.org>    [3.5+]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index c0b01fe24bbd..f3f1f7a972fd 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3503,7 +3503,7 @@ SYSCALL_DEFINE0(pause)
 
 #endif
 
-int sigsuspend(sigset_t *set)
+static int sigsuspend(sigset_t *set)
 {
 	current->saved_sigmask = current->blocked;
 	set_current_blocked(set);

commit 5fa534c987784c4811757a34c425aff3ce3b5037
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Nov 6 16:32:31 2015 -0800

    coredump: ensure all coredumping tasks have SIGNAL_GROUP_COREDUMP
    
    task_will_free_mem() is wrong in many ways, and in particular the
    SIGNAL_GROUP_COREDUMP check is not reliable: a task can participate in the
    coredumping without SIGNAL_GROUP_COREDUMP bit set.
    
    change zap_threads() paths to always set SIGNAL_GROUP_COREDUMP even if
    other CLONE_VM processes can't react to SIGKILL.  Fortunately, at least
    oom-kill case if fine; it kills all tasks sharing the same mm, so it
    should also kill the process which actually dumps the core.
    
    The change in prepare_signal() is not strictly necessary, it just ensures
    that the patch does not bring another subtle behavioural change.  But it
    reminds us that this SIGNAL_GROUP_EXIT/COREDUMP case needs more changes.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Kyle Walker <kwalker@redhat.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Stanislav Kozina <skozina@redhat.com>
    Cc: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index f2cbd4ed5cd4..c0b01fe24bbd 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -788,7 +788,7 @@ static bool prepare_signal(int sig, struct task_struct *p, bool force)
 	sigset_t flush;
 
 	if (signal->flags & (SIGNAL_GROUP_EXIT | SIGNAL_GROUP_COREDUMP)) {
-		if (signal->flags & SIGNAL_GROUP_COREDUMP)
+		if (!(signal->flags & SIGNAL_GROUP_EXIT))
 			return sig == SIGKILL;
 		/*
 		 * The process is in the middle of dying, nothing to do.

commit 2e01fabe67ccaff1d59bda01e60a61f5fb0aa7b6
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Nov 6 16:32:19 2015 -0800

    signals: kill block_all_signals() and unblock_all_signals()
    
    It is hardly possible to enumerate all problems with block_all_signals()
    and unblock_all_signals().  Just for example,
    
    1. block_all_signals(SIGSTOP/etc) simply can't help if the caller is
       multithreaded. Another thread can dequeue the signal and force the
       group stop.
    
    2. Even is the caller is single-threaded, it will "stop" anyway. It
       will not sleep, but it will spin in kernel space until SIGCONT or
       SIGKILL.
    
    And a lot more. In short, this interface doesn't work at all, at least
    the last 10+ years.
    
    Daniel said:
    
      Yeah the only times I played around with the DRM_LOCK stuff was when
      old drivers accidentally deadlocked - my impression is that the entire
      DRM_LOCK thing was never really tested properly ;-) Hence I'm all for
      purging where this leaks out of the drm subsystem.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Acked-by: Dave Airlie <airlied@redhat.com>
    Cc: Richard Weinberger <richard@nod.at>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0f6bbbe77b46..f2cbd4ed5cd4 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -503,41 +503,6 @@ int unhandled_signal(struct task_struct *tsk, int sig)
 	return !tsk->ptrace;
 }
 
-/*
- * Notify the system that a driver wants to block all signals for this
- * process, and wants to be notified if any signals at all were to be
- * sent/acted upon.  If the notifier routine returns non-zero, then the
- * signal will be acted upon after all.  If the notifier routine returns 0,
- * then then signal will be blocked.  Only one block per process is
- * allowed.  priv is a pointer to private data that the notifier routine
- * can use to determine if the signal should be blocked or not.
- */
-void
-block_all_signals(int (*notifier)(void *priv), void *priv, sigset_t *mask)
-{
-	unsigned long flags;
-
-	spin_lock_irqsave(&current->sighand->siglock, flags);
-	current->notifier_mask = mask;
-	current->notifier_data = priv;
-	current->notifier = notifier;
-	spin_unlock_irqrestore(&current->sighand->siglock, flags);
-}
-
-/* Notify the system that blocking has ended. */
-
-void
-unblock_all_signals(void)
-{
-	unsigned long flags;
-
-	spin_lock_irqsave(&current->sighand->siglock, flags);
-	current->notifier = NULL;
-	current->notifier_data = NULL;
-	recalc_sigpending();
-	spin_unlock_irqrestore(&current->sighand->siglock, flags);
-}
-
 static void collect_signal(int sig, struct sigpending *list, siginfo_t *info)
 {
 	struct sigqueue *q, *first = NULL;
@@ -580,19 +545,8 @@ static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,
 {
 	int sig = next_signal(pending, mask);
 
-	if (sig) {
-		if (current->notifier) {
-			if (sigismember(current->notifier_mask, sig)) {
-				if (!(current->notifier)(current->notifier_data)) {
-					clear_thread_flag(TIF_SIGPENDING);
-					return 0;
-				}
-			}
-		}
-
+	if (sig)
 		collect_signal(sig, pending, info);
-	}
-
 	return sig;
 }
 
@@ -2483,9 +2437,6 @@ EXPORT_SYMBOL(force_sig);
 EXPORT_SYMBOL(send_sig);
 EXPORT_SYMBOL(send_sig_info);
 EXPORT_SYMBOL(sigprocmask);
-EXPORT_SYMBOL(block_all_signals);
-EXPORT_SYMBOL(unblock_all_signals);
-
 
 /*
  * System call entry points.

commit 26135022f85105ad725cda103fa069e29e83bd16
Author: Amanieu d'Antras <amanieu@gmail.com>
Date:   Thu Aug 6 15:46:29 2015 -0700

    signal: fix information leak in copy_siginfo_to_user
    
    This function may copy the si_addr_lsb, si_lower and si_upper fields to
    user mode when they haven't been initialized, which can leak kernel
    stack data to user mode.
    
    Just checking the value of si_code is insufficient because the same
    si_code value is shared between multiple signals.  This is solved by
    checking the value of si_signo in addition to si_code.
    
    Signed-off-by: Amanieu d'Antras <amanieu@gmail.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 00524cf6c412..0f6bbbe77b46 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2748,12 +2748,15 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 		 * Other callers might not initialize the si_lsb field,
 		 * so check explicitly for the right codes here.
 		 */
-		if (from->si_code == BUS_MCEERR_AR || from->si_code == BUS_MCEERR_AO)
+		if (from->si_signo == SIGBUS &&
+		    (from->si_code == BUS_MCEERR_AR || from->si_code == BUS_MCEERR_AO))
 			err |= __put_user(from->si_addr_lsb, &to->si_addr_lsb);
 #endif
 #ifdef SEGV_BNDERR
-		err |= __put_user(from->si_lower, &to->si_lower);
-		err |= __put_user(from->si_upper, &to->si_upper);
+		if (from->si_signo == SIGSEGV && from->si_code == SEGV_BNDERR) {
+			err |= __put_user(from->si_lower, &to->si_lower);
+			err |= __put_user(from->si_upper, &to->si_upper);
+		}
 #endif
 		break;
 	case __SI_CHLD:

commit 3c00cb5e68dc719f2fc73a33b1b230aadfcb1309
Author: Amanieu d'Antras <amanieu@gmail.com>
Date:   Thu Aug 6 15:46:26 2015 -0700

    signal: fix information leak in copy_siginfo_from_user32
    
    This function can leak kernel stack data when the user siginfo_t has a
    positive si_code value.  The top 16 bits of si_code descibe which fields
    in the siginfo_t union are active, but they are treated inconsistently
    between copy_siginfo_from_user32, copy_siginfo_to_user32 and
    copy_siginfo_to_user.
    
    copy_siginfo_from_user32 is called from rt_sigqueueinfo and
    rt_tgsigqueueinfo in which the user has full control overthe top 16 bits
    of si_code.
    
    This fixes the following information leaks:
    x86:   8 bytes leaked when sending a signal from a 32-bit process to
           itself. This leak grows to 16 bytes if the process uses x32.
           (si_code = __SI_CHLD)
    x86:   100 bytes leaked when sending a signal from a 32-bit process to
           a 64-bit process. (si_code = -1)
    sparc: 4 bytes leaked when sending a signal from a 32-bit process to a
           64-bit process. (si_code = any)
    
    parsic and s390 have similar bugs, but they are not vulnerable because
    rt_[tg]sigqueueinfo have checks that prevent sending a positive si_code
    to a different process.  These bugs are also fixed for consistency.
    
    Signed-off-by: Amanieu d'Antras <amanieu@gmail.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Chris Metcalf <cmetcalf@ezchip.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 836df8dac6cc..00524cf6c412 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3017,7 +3017,7 @@ COMPAT_SYSCALL_DEFINE3(rt_sigqueueinfo,
 			int, sig,
 			struct compat_siginfo __user *, uinfo)
 {
-	siginfo_t info;
+	siginfo_t info = {};
 	int ret = copy_siginfo_from_user32(&info, uinfo);
 	if (unlikely(ret))
 		return ret;
@@ -3061,7 +3061,7 @@ COMPAT_SYSCALL_DEFINE4(rt_tgsigqueueinfo,
 			int, sig,
 			struct compat_siginfo __user *, uinfo)
 {
-	siginfo_t info;
+	siginfo_t info = {};
 
 	if (copy_siginfo_from_user32(&info, uinfo))
 		return -EFAULT;

commit e22619a29fcdb513b7bc020e84225bb3b5914259
Merge: 78c10e556ed9 b3bddffd35a0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jun 27 13:26:03 2015 -0700

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security
    
    Pull security subsystem updates from James Morris:
     "The main change in this kernel is Casey's generalized LSM stacking
      work, which removes the hard-coding of Capabilities and Yama stacking,
      allowing multiple arbitrary "small" LSMs to be stacked with a default
      monolithic module (e.g.  SELinux, Smack, AppArmor).
    
      See
            https://lwn.net/Articles/636056/
    
      This will allow smaller, simpler LSMs to be incorporated into the
      mainline kernel and arbitrarily stacked by users.  Also, this is a
      useful cleanup of the LSM code in its own right"
    
    * 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security: (38 commits)
      tpm, tpm_crb: fix le64_to_cpu conversions in crb_acpi_add()
      vTPM: set virtual device before passing to ibmvtpm_reset_crq
      tpm_ibmvtpm: remove unneccessary message level.
      ima: update builtin policies
      ima: extend "mask" policy matching support
      ima: add support for new "euid" policy condition
      ima: fix ima_show_template_data_ascii()
      Smack: freeing an error pointer in smk_write_revoke_subj()
      selinux: fix setting of security labels on NFS
      selinux: Remove unused permission definitions
      selinux: enable genfscon labeling for sysfs and pstore files
      selinux: enable per-file labeling for debugfs files.
      selinux: update netlink socket classes
      signals: don't abuse __flush_signals() in selinux_bprm_committed_creds()
      selinux: Print 'sclass' as string when unrecognized netlink message occurs
      Smack: allow multiple labels in onlycap
      Smack: fix seq operations in smackfs
      ima: pass iint to ima_add_violation()
      ima: wrap event related data to the new ima_event_data structure
      integrity: add validity checks for 'path' parameter
      ...

commit 9e7c8f8c62c1e1cda203b5bfaba4575b141e42e7
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Jun 4 16:22:16 2015 -0400

    signals: don't abuse __flush_signals() in selinux_bprm_committed_creds()
    
    selinux_bprm_committed_creds()->__flush_signals() is not right, we
    shouldn't clear TIF_SIGPENDING unconditionally. There can be other
    reasons for signal_pending(): freezing(), JOBCTL_PENDING_MASK, and
    potentially more.
    
    Also change this code to check fatal_signal_pending() rather than
    SIGNAL_GROUP_EXIT, it looks a bit better.
    
    Now we can kill __flush_signals() before it finds another buggy user.
    
    Note: this code looks racy, we can flush a signal which was sent after
    the task SID has been updated.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Paul Moore <pmoore@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index d51c5ddd855c..d4972504f2f1 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -414,21 +414,16 @@ void flush_sigqueue(struct sigpending *queue)
 }
 
 /*
- * Flush all pending signals for a task.
+ * Flush all pending signals for this kthread.
  */
-void __flush_signals(struct task_struct *t)
-{
-	clear_tsk_thread_flag(t, TIF_SIGPENDING);
-	flush_sigqueue(&t->pending);
-	flush_sigqueue(&t->signal->shared_pending);
-}
-
 void flush_signals(struct task_struct *t)
 {
 	unsigned long flags;
 
 	spin_lock_irqsave(&t->sighand->siglock, flags);
-	__flush_signals(t);
+	clear_tsk_thread_flag(t, TIF_SIGPENDING);
+	flush_sigqueue(&t->pending);
+	flush_sigqueue(&t->signal->shared_pending);
 	spin_unlock_irqrestore(&t->sighand->siglock, flags);
 }
 

commit b76808e6808e34e7e78131d2b8cb0535622b8e9f
Author: Palmer Dabbelt <palmer@dabbelt.com>
Date:   Thu Apr 30 21:19:57 2015 -0700

    signals, sched: Change all uses of JOBCTL_* from 'int' to 'long'
    
    c56fb6564dcd ("Fix a misaligned load inside ptrace_attach()") makes
    jobctl an "unsigned long".  It makes sense to have the masks applied
    to it match that type.  This is currently just a cosmetic change, but
    it will prevent the mask from being unexpectedly truncated if we ever
    end up with masks with more bits.
    
    One instance of "signr" is an int, but I left this alone because the
    mask ensures that it will never overflow.
    
    Signed-off-by: Palmer Dabbelt <palmer@dabbelt.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Chris Metcalf <cmetcalf@ezchip.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: bobby.prani@gmail.com
    Cc: oleg@redhat.com
    Cc: paulmck@linux.vnet.ibm.com
    Cc: richard@nod.at
    Cc: vdavydov@parallels.com
    Link: http://lkml.kernel.org/r/1430453997-32459-4-git-send-email-palmer@dabbelt.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index d51c5ddd855c..f19833b5db3c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -245,7 +245,7 @@ static inline void print_dropped_signal(int sig)
  * RETURNS:
  * %true if @mask is set, %false if made noop because @task was dying.
  */
-bool task_set_jobctl_pending(struct task_struct *task, unsigned int mask)
+bool task_set_jobctl_pending(struct task_struct *task, unsigned long mask)
 {
 	BUG_ON(mask & ~(JOBCTL_PENDING_MASK | JOBCTL_STOP_CONSUME |
 			JOBCTL_STOP_SIGMASK | JOBCTL_TRAPPING));
@@ -297,7 +297,7 @@ void task_clear_jobctl_trapping(struct task_struct *task)
  * CONTEXT:
  * Must be called with @task->sighand->siglock held.
  */
-void task_clear_jobctl_pending(struct task_struct *task, unsigned int mask)
+void task_clear_jobctl_pending(struct task_struct *task, unsigned long mask)
 {
 	BUG_ON(mask & ~JOBCTL_PENDING_MASK);
 
@@ -2000,7 +2000,7 @@ static bool do_signal_stop(int signr)
 	struct signal_struct *sig = current->signal;
 
 	if (!(current->jobctl & JOBCTL_STOP_PENDING)) {
-		unsigned int gstop = JOBCTL_STOP_PENDING | JOBCTL_STOP_CONSUME;
+		unsigned long gstop = JOBCTL_STOP_PENDING | JOBCTL_STOP_CONSUME;
 		struct task_struct *t;
 
 		/* signr will be recorded in task->jobctl for retries */

commit 69828dce7af2cb6d08ef5a03de687d422fb7ec1f
Author: Vladimir Davydov <vdavydov@parallels.com>
Date:   Thu Apr 16 12:47:35 2015 -0700

    signal: remove warning about using SI_TKILL in rt_[tg]sigqueueinfo
    
    Sending SI_TKILL from rt_[tg]sigqueueinfo was deprecated, so now we issue
    a warning on the first attempt of doing it.  We use WARN_ON_ONCE, which is
    not informative and, what is worse, taints the kernel, making the trinity
    syscall fuzzer complain false-positively from time to time.
    
    It does not look like we need this warning at all, because the behaviour
    changed quite a long time ago (2.6.39), and if an application relies on
    the old API, it gets EPERM anyway and can issue a warning by itself.
    
    So let us zap the warning in kernel.
    
    Signed-off-by: Vladimir Davydov <vdavydov@parallels.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index a390499943e4..d51c5ddd855c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2992,11 +2992,9 @@ static int do_rt_sigqueueinfo(pid_t pid, int sig, siginfo_t *info)
 	 * Nor can they impersonate a kill()/tgkill(), which adds source info.
 	 */
 	if ((info->si_code >= 0 || info->si_code == SI_TKILL) &&
-	    (task_pid_vnr(current) != pid)) {
-		/* We used to allow any < 0 si_code */
-		WARN_ON_ONCE(info->si_code < 0);
+	    (task_pid_vnr(current) != pid))
 		return -EPERM;
-	}
+
 	info->si_signo = sig;
 
 	/* POSIX.1b doesn't mention process groups.  */
@@ -3041,12 +3039,10 @@ static int do_rt_tgsigqueueinfo(pid_t tgid, pid_t pid, int sig, siginfo_t *info)
 	/* Not even root can pretend to send signals from the kernel.
 	 * Nor can they impersonate a kill()/tgkill(), which adds source info.
 	 */
-	if (((info->si_code >= 0 || info->si_code == SI_TKILL)) &&
-	    (task_pid_vnr(current) != pid)) {
-		/* We used to allow any < 0 si_code */
-		WARN_ON_ONCE(info->si_code < 0);
+	if ((info->si_code >= 0 || info->si_code == SI_TKILL) &&
+	    (task_pid_vnr(current) != pid))
 		return -EPERM;
-	}
+
 	info->si_signo = sig;
 
 	return do_send_specific(tgid, pid, sig, info);

commit 1df0135588ed4e6048c1608ec046e9a38ea91e8e
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Tue Feb 17 13:45:41 2015 -0800

    signal: use current->state helpers
    
    Call __set_current_state() instead of assigning the new state directly.
    These interfaces also aid CONFIG_DEBUG_ATOMIC_SLEEP environments, keeping
    track of who changed the state.
    
    Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 33a52759cc0e..a390499943e4 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3550,7 +3550,7 @@ SYSCALL_DEFINE2(signal, int, sig, __sighandler_t, handler)
 SYSCALL_DEFINE0(pause)
 {
 	while (!signal_pending(current)) {
-		current->state = TASK_INTERRUPTIBLE;
+		__set_current_state(TASK_INTERRUPTIBLE);
 		schedule();
 	}
 	return -ERESTARTNOHAND;
@@ -3563,7 +3563,7 @@ int sigsuspend(sigset_t *set)
 	current->saved_sigmask = current->blocked;
 	set_current_blocked(set);
 
-	current->state = TASK_INTERRUPTIBLE;
+	__set_current_state(TASK_INTERRUPTIBLE);
 	schedule();
 	set_restore_sigmask();
 	return -ERESTARTNOHAND;

commit f56141e3e2d9aabf7e6b89680ab572c2cdbb2a24
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Thu Feb 12 15:01:14 2015 -0800

    all arches, signal: move restart_block to struct task_struct
    
    If an attacker can cause a controlled kernel stack overflow, overwriting
    the restart block is a very juicy exploit target.  This is because the
    restart_block is held in the same memory allocation as the kernel stack.
    
    Moving the restart block to struct task_struct prevents this exploit by
    making the restart_block harder to locate.
    
    Note that there are other fields in thread_info that are also easy
    targets, at least on some architectures.
    
    It's also a decent simplification, since the restart code is more or less
    identical on all architectures.
    
    [james.hogan@imgtec.com: metag: align thread_info::supervisor_stack]
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: David Miller <davem@davemloft.net>
    Acked-by: Richard Weinberger <richard@nod.at>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Haavard Skinnemoen <hskinnemoen@gmail.com>
    Cc: Hans-Christian Egtvedt <egtvedt@samfundet.no>
    Cc: Steven Miao <realmz6@gmail.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Aurelien Jacquiot <a-jacquiot@ti.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: Jesper Nilsson <jesper.nilsson@axis.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Acked-by: Michael Ellerman <mpe@ellerman.id.au> (powerpc)
    Tested-by: Michael Ellerman <mpe@ellerman.id.au> (powerpc)
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Chen Liqin <liqin.linux@gmail.com>
    Cc: Lennox Wu <lennox.wu@gmail.com>
    Cc: Chris Metcalf <cmetcalf@ezchip.com>
    Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: James Hogan <james.hogan@imgtec.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 16a305295256..33a52759cc0e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2501,7 +2501,7 @@ EXPORT_SYMBOL(unblock_all_signals);
  */
 SYSCALL_DEFINE0(restart_syscall)
 {
-	struct restart_block *restart = &current_thread_info()->restart_block;
+	struct restart_block *restart = &current->restart_block;
 	return restart->fn(restart);
 }
 

commit 3eb5b893ebec7325ac9e6b8e4864af89a9ca1ed1
Merge: 9e66645d72d3 9f7789f845cc
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Dec 10 09:34:43 2014 -0800

    Merge branch 'x86-mpx-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 MPX support from Thomas Gleixner:
     "This enables support for x86 MPX.
    
      MPX is a new debug feature for bound checking in user space.  It
      requires kernel support to handle the bound tables and decode the
      bound violating instruction in the trap handler"
    
    * 'x86-mpx-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      asm-generic: Remove asm-generic arch_bprm_mm_init()
      mm: Make arch_unmap()/bprm_mm_init() available to all architectures
      x86: Cleanly separate use of asm-generic/mm_hooks.h
      x86 mpx: Change return type of get_reg_offset()
      fs: Do not include mpx.h in exec.c
      x86, mpx: Add documentation on Intel MPX
      x86, mpx: Cleanup unused bound tables
      x86, mpx: On-demand kernel allocation of bounds tables
      x86, mpx: Decode MPX instruction to get bound violation information
      x86, mpx: Add MPX-specific mmap interface
      x86, mpx: Introduce VM_MPX to indicate that a VMA is MPX specific
      x86, mpx: Add MPX to disabled features
      ia64: Sync struct siginfo with general version
      mips: Sync struct siginfo with general version
      mpx: Extend siginfo structure to include bound violation information
      x86, mpx: Rename cfg_reg_u and status_reg
      x86: mpx: Give bndX registers actual names
      x86: Remove arbitrary instruction size limit in instruction decoder

commit ee1b58d36aa1b5a79eaba11f5c3633c88231da83
Author: Qiaowei Ren <qiaowei.ren@intel.com>
Date:   Fri Nov 14 07:18:19 2014 -0800

    mpx: Extend siginfo structure to include bound violation information
    
    This patch adds new fields about bound violation into siginfo
    structure. si_lower and si_upper are respectively lower bound
    and upper bound when bound violation is caused.
    
    Signed-off-by: Qiaowei Ren <qiaowei.ren@intel.com>
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: linux-mm@kvack.org
    Cc: linux-mips@linux-mips.org
    Cc: Dave Hansen <dave@sr71.net>
    Link: http://lkml.kernel.org/r/20141114151819.1908C900@viggo.jf.intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8f0876f9f6dd..2c403a4c8bee 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2747,6 +2747,10 @@ int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 		 */
 		if (from->si_code == BUS_MCEERR_AR || from->si_code == BUS_MCEERR_AO)
 			err |= __put_user(from->si_addr_lsb, &to->si_addr_lsb);
+#endif
+#ifdef SEGV_BNDERR
+		err |= __put_user(from->si_lower, &to->si_lower);
+		err |= __put_user(from->si_upper, &to->si_upper);
 #endif
 		break;
 	case __SI_CHLD:

commit 392809b25833548ccfc55e61b76c8451a5073216
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Sun Sep 28 23:44:18 2014 +0200

    signal: Document the RCU protection of ->sighand
    
    __cleanup_sighand() frees sighand without RCU grace period. This is
    correct but this looks "obviously buggy" and constantly confuses the
    readers, add the comments to explain how this works.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Steven Rostedt <rostedt@goodmis.org>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Pranith Kumar <bobby.prani@gmail.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 54820984a872..19e35135fc60 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1275,7 +1275,17 @@ struct sighand_struct *__lock_task_sighand(struct task_struct *tsk,
 			local_irq_restore(*flags);
 			break;
 		}
-
+		/*
+		 * This sighand can be already freed and even reused, but
+		 * we rely on SLAB_DESTROY_BY_RCU and sighand_ctor() which
+		 * initializes ->siglock: this slab can't go away, it has
+		 * the same object type, ->siglock can't be reinitialized.
+		 *
+		 * We need to ensure that tsk->sighand is still the same
+		 * after we take the lock, we can race with de_thread() or
+		 * __exit_signal(). In the latter case the next iteration
+		 * must see ->sighand == NULL.
+		 */
 		spin_lock(&sighand->siglock);
 		if (likely(sighand == tsk->sighand)) {
 			rcu_read_unlock();

commit eca1a08986f622c11b75b3b44d561a1f901c9cec
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu Oct 23 11:41:22 2014 -0700

    signal: Exit RCU read-side critical section on each pass through loop
    
    The kill_pid_info() can potentially loop indefinitely if tasks are created
    and deleted sufficiently quickly, and if this happens, this function
    will remain in a single RCU read-side critical section indefinitely.
    This commit therefore exits the RCU read-side critical section on each
    pass through the loop.  Because a race must happen to retry the loop,
    this should have no performance impact in the common case.
    
    Reported-by: Dave Jones <davej@redhat.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Pranith Kumar <bobby.prani@gmail.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8f0876f9f6dd..54820984a872 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1331,23 +1331,21 @@ int kill_pid_info(int sig, struct siginfo *info, struct pid *pid)
 	int error = -ESRCH;
 	struct task_struct *p;
 
-	rcu_read_lock();
-retry:
-	p = pid_task(pid, PIDTYPE_PID);
-	if (p) {
-		error = group_send_sig_info(sig, info, p);
-		if (unlikely(error == -ESRCH))
-			/*
-			 * The task was unhashed in between, try again.
-			 * If it is dead, pid_task() will return NULL,
-			 * if we race with de_thread() it will find the
-			 * new leader.
-			 */
-			goto retry;
-	}
-	rcu_read_unlock();
+	for (;;) {
+		rcu_read_lock();
+		p = pid_task(pid, PIDTYPE_PID);
+		if (p)
+			error = group_send_sig_info(sig, info, p);
+		rcu_read_unlock();
+		if (likely(!p || error != -ESRCH))
+			return error;
 
-	return error;
+		/*
+		 * The task was unhashed in between, try again.  If it
+		 * is dead, pid_task() will return NULL, if we race with
+		 * de_thread() it will find the new leader.
+		 */
+	}
 }
 
 int kill_proc_info(int sig, struct siginfo *info, pid_t pid)

commit 63b12bdb0d21aca527996fb2c547387bfd3e14b8
Merge: ad1f5caf3439 059ade650ae5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Aug 9 09:58:12 2014 -0700

    Merge branch 'signal-cleanup' of git://git.kernel.org/pub/scm/linux/kernel/git/rw/misc
    
    Pull arch signal handling cleanup from Richard Weinberger:
     "This patch series moves all remaining archs to the get_signal(),
      signal_setup_done() and sigsp() functions.
    
      Currently these archs use open coded variants of the said functions.
      Further, unused parameters get removed from get_signal_to_deliver(),
      tracehook_signal_handler() and signal_delivered().
    
      At the end of the day we save around 500 lines of code."
    
    * 'signal-cleanup' of git://git.kernel.org/pub/scm/linux/kernel/git/rw/misc: (43 commits)
      powerpc: Use sigsp()
      openrisc: Use sigsp()
      mn10300: Use sigsp()
      mips: Use sigsp()
      microblaze: Use sigsp()
      metag: Use sigsp()
      m68k: Use sigsp()
      m32r: Use sigsp()
      hexagon: Use sigsp()
      frv: Use sigsp()
      cris: Use sigsp()
      c6x: Use sigsp()
      blackfin: Use sigsp()
      avr32: Use sigsp()
      arm64: Use sigsp()
      arc: Use sigsp()
      sas_ss_flags: Remove nested ternary if
      Rip out get_signal_to_deliver()
      Clean up signal_delivered()
      tracehook_signal_handler: Remove sig, info, ka and regs
      ...

commit 828b1f65d23cf8a68795739f6dd08fc8abd9ee64
Author: Richard Weinberger <richard@nod.at>
Date:   Mon Oct 7 15:26:57 2013 +0200

    Rip out get_signal_to_deliver()
    
    Now we can turn get_signal() to the main function.
    
    Signed-off-by: Richard Weinberger <richard@nod.at>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0d75cf875d44..5c6020040388 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2166,8 +2166,7 @@ static int ptrace_signal(int signr, siginfo_t *info)
 	return signr;
 }
 
-int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
-			  struct pt_regs *regs, void *cookie)
+int get_signal(struct ksignal *ksig)
 {
 	struct sighand_struct *sighand = current->sighand;
 	struct signal_struct *signal = current->signal;
@@ -2237,13 +2236,13 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 			goto relock;
 		}
 
-		signr = dequeue_signal(current, &current->blocked, info);
+		signr = dequeue_signal(current, &current->blocked, &ksig->info);
 
 		if (!signr)
 			break; /* will return 0 */
 
 		if (unlikely(current->ptrace) && signr != SIGKILL) {
-			signr = ptrace_signal(signr, info);
+			signr = ptrace_signal(signr, &ksig->info);
 			if (!signr)
 				continue;
 		}
@@ -2251,13 +2250,13 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		ka = &sighand->action[signr-1];
 
 		/* Trace actually delivered signals. */
-		trace_signal_deliver(signr, info, ka);
+		trace_signal_deliver(signr, &ksig->info, ka);
 
 		if (ka->sa.sa_handler == SIG_IGN) /* Do nothing.  */
 			continue;
 		if (ka->sa.sa_handler != SIG_DFL) {
 			/* Run the handler.  */
-			*return_ka = *ka;
+			ksig->ka = *ka;
 
 			if (ka->sa.sa_flags & SA_ONESHOT)
 				ka->sa.sa_handler = SIG_DFL;
@@ -2307,7 +2306,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 				spin_lock_irq(&sighand->siglock);
 			}
 
-			if (likely(do_signal_stop(info->si_signo))) {
+			if (likely(do_signal_stop(ksig->info.si_signo))) {
 				/* It released the siglock.  */
 				goto relock;
 			}
@@ -2328,7 +2327,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 
 		if (sig_kernel_coredump(signr)) {
 			if (print_fatal_signals)
-				print_fatal_signal(info->si_signo);
+				print_fatal_signal(ksig->info.si_signo);
 			proc_coredump_connector(current);
 			/*
 			 * If it was able to dump core, this kills all
@@ -2338,17 +2337,19 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 			 * first and our do_group_exit call below will use
 			 * that value and ignore the one we pass it.
 			 */
-			do_coredump(info);
+			do_coredump(&ksig->info);
 		}
 
 		/*
 		 * Death signals, no core dump.
 		 */
-		do_group_exit(info->si_signo);
+		do_group_exit(ksig->info.si_signo);
 		/* NOTREACHED */
 	}
 	spin_unlock_irq(&sighand->siglock);
-	return signr;
+
+	ksig->sig = signr;
+	return ksig->sig > 0;
 }
 
 /**

commit 10b1c7ac8bfed429cf3dcb0225482c8dc1485d8e
Author: Richard Weinberger <richard@nod.at>
Date:   Sun Jul 13 13:36:04 2014 +0200

    Clean up signal_delivered()
    
     - Pass a ksignal struct to it
     - Remove unused regs parameter
     - Make it private as it's nowhere outside of kernel/signal.c is used
    
    Signed-off-by: Richard Weinberger <richard@nod.at>

diff --git a/kernel/signal.c b/kernel/signal.c
index c4d47661cc86..0d75cf875d44 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2353,19 +2353,15 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 
 /**
  * signal_delivered - 
- * @sig:		number of signal being delivered
- * @info:		siginfo_t of signal being delivered
- * @ka:			sigaction setting that chose the handler
- * @regs:		user register state
+ * @ksig:		kernel signal struct
  * @stepping:		nonzero if debugger single-step or block-step in use
  *
  * This function should be called when a signal has successfully been
- * delivered. It updates the blocked signals accordingly (@ka->sa.sa_mask
+ * delivered. It updates the blocked signals accordingly (@ksig->ka.sa.sa_mask
  * is always blocked, and the signal itself is blocked unless %SA_NODEFER
- * is set in @ka->sa.sa_flags.  Tracing is notified.
+ * is set in @ksig->ka.sa.sa_flags.  Tracing is notified.
  */
-void signal_delivered(int sig, siginfo_t *info, struct k_sigaction *ka,
-			struct pt_regs *regs, int stepping)
+static void signal_delivered(struct ksignal *ksig, int stepping)
 {
 	sigset_t blocked;
 
@@ -2375,9 +2371,9 @@ void signal_delivered(int sig, siginfo_t *info, struct k_sigaction *ka,
 	   simply clear the restore sigmask flag.  */
 	clear_restore_sigmask();
 
-	sigorsets(&blocked, &current->blocked, &ka->sa.sa_mask);
-	if (!(ka->sa.sa_flags & SA_NODEFER))
-		sigaddset(&blocked, sig);
+	sigorsets(&blocked, &current->blocked, &ksig->ka.sa.sa_mask);
+	if (!(ksig->ka.sa.sa_flags & SA_NODEFER))
+		sigaddset(&blocked, ksig->sig);
 	set_current_blocked(&blocked);
 	tracehook_signal_handler(stepping);
 }
@@ -2387,8 +2383,7 @@ void signal_setup_done(int failed, struct ksignal *ksig, int stepping)
 	if (failed)
 		force_sigsegv(ksig->sig, current);
 	else
-		signal_delivered(ksig->sig, &ksig->info, &ksig->ka,
-			signal_pt_regs(), stepping);
+		signal_delivered(ksig, stepping);
 }
 
 /*

commit df5601f9c3d831b4c478b004a1ed90a18643adbe
Author: Richard Weinberger <richard@nod.at>
Date:   Mon Oct 7 15:37:19 2013 +0200

    tracehook_signal_handler: Remove sig, info, ka and regs
    
    These parameters are nowhere used, so we can remove them.
    
    Signed-off-by: Richard Weinberger <richard@nod.at>

diff --git a/kernel/signal.c b/kernel/signal.c
index a4077e90f19f..c4d47661cc86 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2379,7 +2379,7 @@ void signal_delivered(int sig, siginfo_t *info, struct k_sigaction *ka,
 	if (!(ka->sa.sa_flags & SA_NODEFER))
 		sigaddset(&blocked, sig);
 	set_current_blocked(&blocked);
-	tracehook_signal_handler(sig, info, ka, regs, stepping);
+	tracehook_signal_handler(stepping);
 }
 
 void signal_setup_done(int failed, struct ksignal *ksig, int stepping)

commit c41247e1d4864c863ee25e029dd53acdb2abc000
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon May 5 08:18:30 2014 -0700

    signal: Explain local_irq_save() call
    
    The explicit local_irq_save() in __lock_task_sighand() is needed to avoid
    a potential deadlock condition, as noted in a841796f11c90d53 (signal:
    align __lock_task_sighand() irq disabling and RCU).  However, someone
    reading the code might be forgiven for concluding that this separate
    local_irq_save() was completely unnecessary.  This commit therefore adds
    a comment referencing the shiny new block comment on rcu_read_unlock().
    
    Reported-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Lai Jiangshan <laijs@cn.fujitsu.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index a4077e90f19f..40b76e351e64 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1263,6 +1263,10 @@ struct sighand_struct *__lock_task_sighand(struct task_struct *tsk,
 	struct sighand_struct *sighand;
 
 	for (;;) {
+		/*
+		 * Disable interrupts early to avoid deadlocks.
+		 * See rcu_read_unlock() comment header for details.
+		 */
 		local_irq_save(*flags);
 		rcu_read_lock();
 		sighand = rcu_dereference(tsk->sighand);

commit b4e74264eb0b03f42097fa70a0766312156244a0
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Jun 6 14:37:00 2014 -0700

    signals: introduce kernel_sigaction()
    
    Now that allow_signal() is really trivial we can unify it with
    disallow_signal().  Add the new helper, kernel_sigaction(), and
    reimplement allow_signal/disallow_signal as a trivial wrappers.
    
    This saves one EXPORT_SYMBOL() and the new helper can have more users.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Tejun Heo <tj@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 3ec405132c79..a4077e90f19f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3067,37 +3067,25 @@ COMPAT_SYSCALL_DEFINE4(rt_tgsigqueueinfo,
 #endif
 
 /*
- * Let kernel threads use this to say that they allow a certain signal.
- * Must not be used if kthread was cloned with CLONE_SIGHAND.
+ * For kthreads only, must not be used if cloned with CLONE_SIGHAND
  */
-void allow_signal(int sig)
+void kernel_sigaction(int sig, __sighandler_t action)
 {
-	/*
-	 * Kernel threads handle their own signals. Let the signal code
-	 * know it'll be handled, so that they don't get converted to
-	 * SIGKILL or just silently dropped.
-	 */
 	spin_lock_irq(&current->sighand->siglock);
-	current->sighand->action[(sig)-1].sa.sa_handler = (void __user *)2;
-	spin_unlock_irq(&current->sighand->siglock);
-}
-EXPORT_SYMBOL(allow_signal);
+	current->sighand->action[sig - 1].sa.sa_handler = action;
+	if (action == SIG_IGN) {
+		sigset_t mask;
 
-void disallow_signal(int sig)
-{
-	sigset_t mask;
+		sigemptyset(&mask);
+		sigaddset(&mask, sig);
 
-	sigemptyset(&mask);
-	sigaddset(&mask, sig);
-
-	spin_lock_irq(&current->sighand->siglock);
-	current->sighand->action[(sig)-1].sa.sa_handler = SIG_IGN;
-	flush_sigqueue_mask(&mask, &current->signal->shared_pending);
-	flush_sigqueue_mask(&mask, &current->pending);
-	recalc_sigpending();
+		flush_sigqueue_mask(&mask, &current->signal->shared_pending);
+		flush_sigqueue_mask(&mask, &current->pending);
+		recalc_sigpending();
+	}
 	spin_unlock_irq(&current->sighand->siglock);
 }
-EXPORT_SYMBOL(disallow_signal);
+EXPORT_SYMBOL(kernel_sigaction);
 
 int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 {

commit 580d34e42ad621736a3c53c9c11a2152c18a4068
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Jun 6 14:36:58 2014 -0700

    signals: disallow_signal() should flush the potentially pending signal
    
    disallow_signal() simply sets SIG_IGN, this is not enough and
    recalc_sigpending() is simply pointless because in can never change the
    state of TIF_SIGPENDING.
    
    If we ignore a signal, we also need to do flush_sigqueue_mask() for the
    case when this signal is pending, this way recalc_sigpending() can
    actually clear TIF_SIGPENDING and we do not "leak" the allocated
    siginfo's.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Tejun Heo <tj@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index c64c891ca0a6..3ec405132c79 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3085,8 +3085,15 @@ EXPORT_SYMBOL(allow_signal);
 
 void disallow_signal(int sig)
 {
+	sigset_t mask;
+
+	sigemptyset(&mask);
+	sigaddset(&mask, sig);
+
 	spin_lock_irq(&current->sighand->siglock);
 	current->sighand->action[(sig)-1].sa.sa_handler = SIG_IGN;
+	flush_sigqueue_mask(&mask, &current->signal->shared_pending);
+	flush_sigqueue_mask(&mask, &current->pending);
 	recalc_sigpending();
 	spin_unlock_irq(&current->sighand->siglock);
 }

commit ec5955b8fdc1b0bc62495e13869769be732cc6c3
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Jun 6 14:36:57 2014 -0700

    signals: kill the obsolete sigdelset() and recalc_sigpending() in allow_signal()
    
    allow_signal() does sigdelset(current->blocked) due to historic reason,
    previously it could be called by a daemonize()'ed kthread, and
    daemonize() played with current->blocked.
    
    Now that daemonize() has gone away we can remove sigdelset() and
    recalc_sigpending().  If a user really wants to unblock a signal, it
    must use sigprocmask() or set_current_block() explicitely.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Tejun Heo <tj@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 7d6ff8b18509..c64c891ca0a6 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3072,16 +3072,13 @@ COMPAT_SYSCALL_DEFINE4(rt_tgsigqueueinfo,
  */
 void allow_signal(int sig)
 {
-	spin_lock_irq(&current->sighand->siglock);
-	/* This is only needed for daemonize()'ed kthreads */
-	sigdelset(&current->blocked, sig);
 	/*
 	 * Kernel threads handle their own signals. Let the signal code
 	 * know it'll be handled, so that they don't get converted to
 	 * SIGKILL or just silently dropped.
 	 */
+	spin_lock_irq(&current->sighand->siglock);
 	current->sighand->action[(sig)-1].sa.sa_handler = (void __user *)2;
-	recalc_sigpending();
 	spin_unlock_irq(&current->sighand->siglock);
 }
 EXPORT_SYMBOL(allow_signal);

commit 0341729b4b832e753c5e745c6ba0e797f6198be0
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Jun 6 14:36:53 2014 -0700

    signals: mv {dis,}allow_signal() from sched.h/exit.c to signal.[ch]
    
    Move the declaration/definition of allow_signal/disallow_signal to
    signal.h/signal.c.  The new place is more logical and allows to use the
    static helpers in signal.c (see the next changes).
    
    While at it, make them return void and remove the valid_signal() check.
    Nobody checks the returned value, and in-kernel users must not pass the
    wrong signal number.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Tejun Heo <tj@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index a6d8c3af0ad6..7d6ff8b18509 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3066,6 +3066,35 @@ COMPAT_SYSCALL_DEFINE4(rt_tgsigqueueinfo,
 }
 #endif
 
+/*
+ * Let kernel threads use this to say that they allow a certain signal.
+ * Must not be used if kthread was cloned with CLONE_SIGHAND.
+ */
+void allow_signal(int sig)
+{
+	spin_lock_irq(&current->sighand->siglock);
+	/* This is only needed for daemonize()'ed kthreads */
+	sigdelset(&current->blocked, sig);
+	/*
+	 * Kernel threads handle their own signals. Let the signal code
+	 * know it'll be handled, so that they don't get converted to
+	 * SIGKILL or just silently dropped.
+	 */
+	current->sighand->action[(sig)-1].sa.sa_handler = (void __user *)2;
+	recalc_sigpending();
+	spin_unlock_irq(&current->sighand->siglock);
+}
+EXPORT_SYMBOL(allow_signal);
+
+void disallow_signal(int sig)
+{
+	spin_lock_irq(&current->sighand->siglock);
+	current->sighand->action[(sig)-1].sa.sa_handler = SIG_IGN;
+	recalc_sigpending();
+	spin_unlock_irq(&current->sighand->siglock);
+}
+EXPORT_SYMBOL(disallow_signal);
+
 int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 {
 	struct task_struct *p = current, *t;

commit afe2b0386ac22b6a189a2067b25282cade3fbb4d
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Jun 6 14:36:51 2014 -0700

    signals: cleanup the usage of t/current in do_sigaction()
    
    The usage of "task_struct *t" and "current" in do_sigaction() looks really
    annoying and chaotic.  Initially "t" is used as a cached value of current
    but not consistently, then it is reused as a loop variable and we have to
    use "current" again.
    
    Clean up this mess and also convert the code to use for_each_thread().
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Tejun Heo <tj@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index c088011f873c..a6d8c3af0ad6 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3068,16 +3068,16 @@ COMPAT_SYSCALL_DEFINE4(rt_tgsigqueueinfo,
 
 int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 {
-	struct task_struct *t = current;
+	struct task_struct *p = current, *t;
 	struct k_sigaction *k;
 	sigset_t mask;
 
 	if (!valid_signal(sig) || sig < 1 || (act && sig_kernel_only(sig)))
 		return -EINVAL;
 
-	k = &t->sighand->action[sig-1];
+	k = &p->sighand->action[sig-1];
 
-	spin_lock_irq(&current->sighand->siglock);
+	spin_lock_irq(&p->sighand->siglock);
 	if (oact)
 		*oact = *k;
 
@@ -3096,17 +3096,16 @@ int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 		 *   (for example, SIGCHLD), shall cause the pending signal to
 		 *   be discarded, whether or not it is blocked"
 		 */
-		if (sig_handler_ignored(sig_handler(t, sig), sig)) {
+		if (sig_handler_ignored(sig_handler(p, sig), sig)) {
 			sigemptyset(&mask);
 			sigaddset(&mask, sig);
-			flush_sigqueue_mask(&mask, &t->signal->shared_pending);
-			do {
+			flush_sigqueue_mask(&mask, &p->signal->shared_pending);
+			for_each_thread(p, t)
 				flush_sigqueue_mask(&mask, &t->pending);
-			} while_each_thread(current, t);
 		}
 	}
 
-	spin_unlock_irq(&current->sighand->siglock);
+	spin_unlock_irq(&p->sighand->siglock);
 	return 0;
 }
 

commit c09c144139f227de13330111adcafa1659ebd008
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Jun 6 14:36:50 2014 -0700

    signals: rename rm_from_queue_full() to flush_sigqueue_mask()
    
    "rm_from_queue_full" looks ugly and misleading, especially now that
    rm_from_queue() has gone away.  Rename it to flush_sigqueue_mask(), this
    matches flush_sigqueue() we already have.
    
    Also remove the obsolete comment which explains the difference with
    rm_from_queue() we already killed.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Tejun Heo <tj@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 19316dc3eb0b..c088011f873c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -706,11 +706,8 @@ void signal_wake_up_state(struct task_struct *t, unsigned int state)
  * Returns 1 if any signals were found.
  *
  * All callers must be holding the siglock.
- *
- * This version takes a sigset mask and looks at all signals,
- * not just those in the first mask word.
  */
-static int rm_from_queue_full(sigset_t *mask, struct sigpending *s)
+static int flush_sigqueue_mask(sigset_t *mask, struct sigpending *s)
 {
 	struct sigqueue *q, *n;
 	sigset_t m;
@@ -852,18 +849,18 @@ static bool prepare_signal(int sig, struct task_struct *p, bool force)
 		 * This is a stop signal.  Remove SIGCONT from all queues.
 		 */
 		siginitset(&flush, sigmask(SIGCONT));
-		rm_from_queue_full(&flush, &signal->shared_pending);
+		flush_sigqueue_mask(&flush, &signal->shared_pending);
 		for_each_thread(p, t)
-			rm_from_queue_full(&flush, &t->pending);
+			flush_sigqueue_mask(&flush, &t->pending);
 	} else if (sig == SIGCONT) {
 		unsigned int why;
 		/*
 		 * Remove all stop signals from all queues, wake all threads.
 		 */
 		siginitset(&flush, SIG_KERNEL_STOP_MASK);
-		rm_from_queue_full(&flush, &signal->shared_pending);
+		flush_sigqueue_mask(&flush, &signal->shared_pending);
 		for_each_thread(p, t) {
-			rm_from_queue_full(&flush, &t->pending);
+			flush_sigqueue_mask(&flush, &t->pending);
 			task_clear_jobctl_pending(t, JOBCTL_STOP_PENDING);
 			if (likely(!(t->ptrace & PT_SEIZED)))
 				wake_up_state(t, __TASK_STOPPED);
@@ -3102,9 +3099,9 @@ int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 		if (sig_handler_ignored(sig_handler(t, sig), sig)) {
 			sigemptyset(&mask);
 			sigaddset(&mask, sig);
-			rm_from_queue_full(&mask, &t->signal->shared_pending);
+			flush_sigqueue_mask(&mask, &t->signal->shared_pending);
 			do {
-				rm_from_queue_full(&mask, &t->pending);
+				flush_sigqueue_mask(&mask, &t->pending);
 			} while_each_thread(current, t);
 		}
 	}
@@ -3113,7 +3110,7 @@ int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 	return 0;
 }
 
-static int 
+static int
 do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long sp)
 {
 	stack_t oss;

commit 9490592f2762320ac220f50d4459d9ea7bb797c8
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Jun 6 14:36:48 2014 -0700

    signals: kill rm_from_queue(), change prepare_signal() to use for_each_thread()
    
    rm_from_queue() doesn't make sense.  The only caller, prepare_signal(),
    can use rm_from_queue_full() with the same effect.
    
    While at it, change prepare_signal() to use for_each_thread() instead of
    do/while_each_thread.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Tejun Heo <tj@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 251ca9c9d666..19316dc3eb0b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -728,29 +728,6 @@ static int rm_from_queue_full(sigset_t *mask, struct sigpending *s)
 	}
 	return 1;
 }
-/*
- * Remove signals in mask from the pending set and queue.
- * Returns 1 if any signals were found.
- *
- * All callers must be holding the siglock.
- */
-static int rm_from_queue(unsigned long mask, struct sigpending *s)
-{
-	struct sigqueue *q, *n;
-
-	if (!sigtestsetmask(&s->signal, mask))
-		return 0;
-
-	sigdelsetmask(&s->signal, mask);
-	list_for_each_entry_safe(q, n, &s->list, list) {
-		if (q->info.si_signo < SIGRTMIN &&
-		    (mask & sigmask(q->info.si_signo))) {
-			list_del_init(&q->list);
-			__sigqueue_free(q);
-		}
-	}
-	return 1;
-}
 
 static inline int is_si_special(const struct siginfo *info)
 {
@@ -862,6 +839,7 @@ static bool prepare_signal(int sig, struct task_struct *p, bool force)
 {
 	struct signal_struct *signal = p->signal;
 	struct task_struct *t;
+	sigset_t flush;
 
 	if (signal->flags & (SIGNAL_GROUP_EXIT | SIGNAL_GROUP_COREDUMP)) {
 		if (signal->flags & SIGNAL_GROUP_COREDUMP)
@@ -873,26 +851,25 @@ static bool prepare_signal(int sig, struct task_struct *p, bool force)
 		/*
 		 * This is a stop signal.  Remove SIGCONT from all queues.
 		 */
-		rm_from_queue(sigmask(SIGCONT), &signal->shared_pending);
-		t = p;
-		do {
-			rm_from_queue(sigmask(SIGCONT), &t->pending);
-		} while_each_thread(p, t);
+		siginitset(&flush, sigmask(SIGCONT));
+		rm_from_queue_full(&flush, &signal->shared_pending);
+		for_each_thread(p, t)
+			rm_from_queue_full(&flush, &t->pending);
 	} else if (sig == SIGCONT) {
 		unsigned int why;
 		/*
 		 * Remove all stop signals from all queues, wake all threads.
 		 */
-		rm_from_queue(SIG_KERNEL_STOP_MASK, &signal->shared_pending);
-		t = p;
-		do {
+		siginitset(&flush, SIG_KERNEL_STOP_MASK);
+		rm_from_queue_full(&flush, &signal->shared_pending);
+		for_each_thread(p, t) {
+			rm_from_queue_full(&flush, &t->pending);
 			task_clear_jobctl_pending(t, JOBCTL_STOP_PENDING);
-			rm_from_queue(SIG_KERNEL_STOP_MASK, &t->pending);
 			if (likely(!(t->ptrace & PT_SEIZED)))
 				wake_up_state(t, __TASK_STOPPED);
 			else
 				ptrace_trap_notify(t);
-		} while_each_thread(p, t);
+		}
 
 		/*
 		 * Notify the parent with CLD_CONTINUED if we were stopped.

commit 6114041aa7e79a28cee554450fc4a67442327c7f
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Jun 6 14:36:46 2014 -0700

    signals: s/siginitset/sigemptyset/ in do_sigtimedwait()
    
    Cosmetic, but siginitset(0) looks a bit strange, sigemptyset() is what
    do_sigtimedwait() needs.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Tejun Heo <tj@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9b5453ee5f5e..251ca9c9d666 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2855,7 +2855,7 @@ int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
 
 		spin_lock_irq(&tsk->sighand->siglock);
 		__set_task_blocked(tsk, &tsk->real_blocked);
-		siginitset(&tsk->real_blocked, 0);
+		sigemptyset(&tsk->real_blocked);
 		sig = dequeue_signal(tsk, &mask, info);
 	}
 	spin_unlock_irq(&tsk->sighand->siglock);

commit 650226bd95817d727c9a388752d72ef292c4a668
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Jun 6 14:36:44 2014 -0700

    ptrace: task_clear_jobctl_trapping()->wake_up_bit() needs mb()
    
    __wake_up_bit() checks waitqueue_active() and thus the caller needs mb()
    as wake_up_bit() documents, fix task_clear_jobctl_trapping().
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 6e600aaa2af4..9b5453ee5f5e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -277,6 +277,7 @@ void task_clear_jobctl_trapping(struct task_struct *task)
 {
 	if (unlikely(task->jobctl & JOBCTL_TRAPPING)) {
 		task->jobctl &= ~JOBCTL_TRAPPING;
+		smp_mb();	/* advised by wake_up_bit() */
 		wake_up_bit(&task->jobctl, JOBCTL_TRAPPING_BIT);
 	}
 }

commit f6187769dae48234f3877df3c4d99294cc2254fa
Author: Fabian Frederick <fabf@skynet.be>
Date:   Wed Jun 4 16:11:12 2014 -0700

    sys_sgetmask/sys_ssetmask: add CONFIG_SGETMASK_SYSCALL
    
    sys_sgetmask and sys_ssetmask are obsolete system calls no longer
    supported in libc.
    
    This patch replaces architecture related __ARCH_WANT_SYS_SGETMAX by expert
    mode configuration.That option is enabled by default for those
    architectures.
    
    Signed-off-by: Fabian Frederick <fabf@skynet.be>
    Cc: Steven Miao <realmz6@gmail.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: Jesper Nilsson <jesper.nilsson@axis.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Koichi Yasutake <yasutake.koichi@jp.panasonic.com>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Greg Ungerer <gerg@uclinux.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 6ea13c09ae56..6e600aaa2af4 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3496,7 +3496,7 @@ COMPAT_SYSCALL_DEFINE3(sigaction, int, sig,
 }
 #endif
 
-#ifdef __ARCH_WANT_SYS_SGETMASK
+#ifdef CONFIG_SGETMASK_SYSCALL
 
 /*
  * For backwards compatibility.  Functionality superseded by sigprocmask.
@@ -3517,7 +3517,7 @@ SYSCALL_DEFINE1(ssetmask, int, newmask)
 
 	return old;
 }
-#endif /* __ARCH_WANT_SGETMASK */
+#endif /* CONFIG_SGETMASK_SYSCALL */
 
 #ifdef __ARCH_WANT_SYS_SIGNAL
 /*

commit 52f5684c8e1ec7463192aba8e2916df49807511a
Author: Gideon Israel Dsouza <gidisrael@gmail.com>
Date:   Mon Apr 7 15:39:20 2014 -0700

    kernel: use macros from compiler.h instead of __attribute__((...))
    
    To increase compiler portability there is <linux/compiler.h> which
    provides convenience macros for various gcc constructs.  Eg: __weak for
    __attribute__((weak)).  I've replaced all instances of gcc attributes
    with the right macro in the kernel subsystem.
    
    Signed-off-by: Gideon Israel Dsouza <gidisrael@gmail.com>
    Cc: "Rafael J. Wysocki" <rjw@sisk.pl>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5d4b05a229a6..6ea13c09ae56 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -33,6 +33,8 @@
 #include <linux/uprobes.h>
 #include <linux/compat.h>
 #include <linux/cn_proc.h>
+#include <linux/compiler.h>
+
 #define CREATE_TRACE_POINTS
 #include <trace/events/signal.h>
 
@@ -3618,7 +3620,7 @@ SYSCALL_DEFINE3(sigsuspend, int, unused1, int, unused2, old_sigset_t, mask)
 }
 #endif
 
-__attribute__((weak)) const char *arch_vma_name(struct vm_area_struct *vma)
+__weak const char *arch_vma_name(struct vm_area_struct *vma)
 {
 	return NULL;
 }

commit d4263348f796f29546f90802177865dd4379dd0a
Merge: be873ac782f5 6d0abeca3242
Author: Jiri Kosina <jkosina@suse.cz>
Date:   Thu Feb 20 14:54:28 2014 +0100

    Merge branch 'master' into for-next

commit e227867f12302633737bd2a48a10a9a72c0630cb
Author: Masanari Iida <standby24x7@gmail.com>
Date:   Tue Feb 18 22:54:36 2014 +0900

    treewide: Fix typo in Documentation/DocBook
    
    This patch fix spelling typo in Documentation/DocBook.
    It is because .html and .xml files are generated by make htmldocs,
    I have to fix a typo within the source files.
    
    Signed-off-by: Masanari Iida <standby24x7@gmail.com>
    Acked-by: Randy Dunlap <rdunlap@infradead.org>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/kernel/signal.c b/kernel/signal.c
index 940b30ee9a30..f4812283c6e9 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2382,7 +2382,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
  * @regs:		user register state
  * @stepping:		nonzero if debugger single-step or block-step in use
  *
- * This function should be called when a signal has succesfully been
+ * This function should be called when a signal has successfully been
  * delivered. It updates the blocked signals accordingly (@ka->sa.sa_mask
  * is always blocked, and the signal itself is blocked unless %SA_NODEFER
  * is set in @ka->sa.sa_flags.  Tracing is notified.

commit 8d38f203b46c36626285400b9466b08abecaaa80
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Jan 23 15:55:56 2014 -0800

    kernel/signal.c: change do_signal_stop/do_sigaction to use while_each_thread()
    
    Change do_signal_stop() and do_sigaction() to avoid next_thread() and use
    while_each_thread() instead.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Kees Cook <keescook@chromium.org>
    Reviewed-by: Sameer Nanda <snanda@chromium.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 940b30ee9a30..52f881db1ca0 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2047,8 +2047,8 @@ static bool do_signal_stop(int signr)
 		if (task_set_jobctl_pending(current, signr | gstop))
 			sig->group_stop_count++;
 
-		for (t = next_thread(current); t != current;
-		     t = next_thread(t)) {
+		t = current;
+		while_each_thread(current, t) {
 			/*
 			 * Setting state to TASK_STOPPED for a group
 			 * stop is always done with the siglock held,
@@ -3125,8 +3125,7 @@ int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 			rm_from_queue_full(&mask, &t->signal->shared_pending);
 			do {
 				rm_from_queue_full(&mask, &t->pending);
-				t = next_thread(t);
-			} while (t != current);
+			} while_each_thread(current, t);
 		}
 	}
 

commit ce3959604878c1c693979ec552069dc8bdb5ccde
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Oct 13 17:23:53 2013 -0400

    constify copy_siginfo_to_user{,32}()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index ded28b91fa53..940b30ee9a30 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2723,7 +2723,7 @@ COMPAT_SYSCALL_DEFINE2(rt_sigpending, compat_sigset_t __user *, uset,
 
 #ifndef HAVE_ARCH_COPY_SIGINFO_TO_USER
 
-int copy_siginfo_to_user(siginfo_t __user *to, siginfo_t *from)
+int copy_siginfo_to_user(siginfo_t __user *to, const siginfo_t *from)
 {
 	int err;
 

commit 3ddc5b46a8e90f3c9251338b60191d0a804b0d92
Author: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Date:   Wed Sep 11 14:23:18 2013 -0700

    kernel-wide: fix missing validations on __get/__put/__copy_to/__copy_from_user()
    
    I found the following pattern that leads in to interesting findings:
    
      grep -r "ret.*|=.*__put_user" *
      grep -r "ret.*|=.*__get_user" *
      grep -r "ret.*|=.*__copy" *
    
    The __put_user() calls in compat_ioctl.c, ptrace compat, signal compat,
    since those appear in compat code, we could probably expect the kernel
    addresses not to be reachable in the lower 32-bit range, so I think they
    might not be exploitable.
    
    For the "__get_user" cases, I don't think those are exploitable: the worse
    that can happen is that the kernel will copy kernel memory into in-kernel
    buffers, and will fail immediately afterward.
    
    The alpha csum_partial_copy_from_user() seems to be missing the
    access_ok() check entirely.  The fix is inspired from x86.  This could
    lead to information leak on alpha.  I also noticed that many architectures
    map csum_partial_copy_from_user() to csum_partial_copy_generic(), but I
    wonder if the latter is performing the access checks on every
    architectures.
    
    Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: David Miller <davem@davemloft.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 50e41075ac77..ded28b91fa53 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3394,7 +3394,7 @@ COMPAT_SYSCALL_DEFINE4(rt_sigaction, int, sig,
 		new_ka.sa.sa_restorer = compat_ptr(restorer);
 #endif
 		ret |= copy_from_user(&mask, &act->sa_mask, sizeof(mask));
-		ret |= __get_user(new_ka.sa.sa_flags, &act->sa_flags);
+		ret |= get_user(new_ka.sa.sa_flags, &act->sa_flags);
 		if (ret)
 			return -EFAULT;
 		sigset_from_compat(&new_ka.sa.sa_mask, &mask);
@@ -3406,7 +3406,7 @@ COMPAT_SYSCALL_DEFINE4(rt_sigaction, int, sig,
 		ret = put_user(ptr_to_compat(old_ka.sa.sa_handler), 
 			       &oact->sa_handler);
 		ret |= copy_to_user(&oact->sa_mask, &mask, sizeof(mask));
-		ret |= __put_user(old_ka.sa.sa_flags, &oact->sa_flags);
+		ret |= put_user(old_ka.sa.sa_flags, &oact->sa_flags);
 #ifdef __ARCH_HAS_SA_RESTORER
 		ret |= put_user(ptr_to_compat(old_ka.sa.sa_restorer),
 				&oact->sa_restorer);

commit a2d5f1f5d941593e61071dc78e9de228eda5475f
Author: Colin Cross <ccross@android.com>
Date:   Mon May 6 23:50:20 2013 +0000

    sigtimedwait: use freezable blocking call
    
    Avoid waking up every thread sleeping in a sigtimedwait call during
    suspend and resume by calling a freezable blocking call.  Previous
    patches modified the freezer to avoid sending wakeups to threads
    that are blocked in freezable blocking calls.
    
    This call was selected to be converted to a freezable call because
    it doesn't hold any locks or release any resources when interrupted
    that might be needed by another freezing task or a kernel driver
    during suspend, and is a common site where idle userspace tasks are
    blocked.
    
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Colin Cross <ccross@android.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 113411bfe8b1..50e41075ac77 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2848,7 +2848,7 @@ int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
 		recalc_sigpending();
 		spin_unlock_irq(&tsk->sighand->siglock);
 
-		timeout = schedule_timeout_interruptible(timeout);
+		timeout = freezable_schedule_timeout_interruptible(timeout);
 
 		spin_lock_irq(&tsk->sighand->siglock);
 		__set_task_blocked(tsk, &tsk->real_blocked);

commit 73287a43cc79ca06629a88d1a199cd283f42456a
Merge: 251df49db332 20074f357da4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 1 14:08:52 2013 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking updates from David Miller:
     "Highlights (1721 non-merge commits, this has to be a record of some
      sort):
    
       1) Add 'random' mode to team driver, from Jiri Pirko and Eric
          Dumazet.
    
       2) Make it so that any driver that supports configuration of multiple
          MAC addresses can provide the forwarding database add and del
          calls by providing a default implementation and hooking that up if
          the driver doesn't have an explicit set of handlers.  From Vlad
          Yasevich.
    
       3) Support GSO segmentation over tunnels and other encapsulating
          devices such as VXLAN, from Pravin B Shelar.
    
       4) Support L2 GRE tunnels in the flow dissector, from Michael Dalton.
    
       5) Implement Tail Loss Probe (TLP) detection in TCP, from Nandita
          Dukkipati.
    
       6) In the PHY layer, allow supporting wake-on-lan in situations where
          the PHY registers have to be written for it to be configured.
    
          Use it to support wake-on-lan in mv643xx_eth.
    
          From Michael Stapelberg.
    
       7) Significantly improve firewire IPV6 support, from YOSHIFUJI
          Hideaki.
    
       8) Allow multiple packets to be sent in a single transmission using
          network coding in batman-adv, from Martin Hundebøll.
    
       9) Add support for T5 cxgb4 chips, from Santosh Rastapur.
    
      10) Generalize the VXLAN forwarding tables so that there is more
          flexibility in configurating various aspects of the endpoints.
          From David Stevens.
    
      11) Support RSS and TSO in hardware over GRE tunnels in bxn2x driver,
          from Dmitry Kravkov.
    
      12) Zero copy support in nfnelink_queue, from Eric Dumazet and Pablo
          Neira Ayuso.
    
      13) Start adding networking selftests.
    
      14) In situations of overload on the same AF_PACKET fanout socket, or
          per-cpu packet receive queue, minimize drop by distributing the
          load to other cpus/fanouts.  From Willem de Bruijn and Eric
          Dumazet.
    
      15) Add support for new payload offset BPF instruction, from Daniel
          Borkmann.
    
      16) Convert several drivers over to mdoule_platform_driver(), from
          Sachin Kamat.
    
      17) Provide a minimal BPF JIT image disassembler userspace tool, from
          Daniel Borkmann.
    
      18) Rewrite F-RTO implementation in TCP to match the final
          specification of it in RFC4138 and RFC5682.  From Yuchung Cheng.
    
      19) Provide netlink socket diag of netlink sockets ("Yo dawg, I hear
          you like netlink, so I implemented netlink dumping of netlink
          sockets.") From Andrey Vagin.
    
      20) Remove ugly passing of rtnetlink attributes into rtnl_doit
          functions, from Thomas Graf.
    
      21) Allow userspace to be able to see if a configuration change occurs
          in the middle of an address or device list dump, from Nicolas
          Dichtel.
    
      22) Support RFC3168 ECN protection for ipv6 fragments, from Hannes
          Frederic Sowa.
    
      23) Increase accuracy of packet length used by packet scheduler, from
          Jason Wang.
    
      24) Beginning set of changes to make ipv4/ipv6 fragment handling more
          scalable and less susceptible to overload and locking contention,
          from Jesper Dangaard Brouer.
    
      25) Get rid of using non-type-safe NLMSG_* macros and use nlmsg_*()
          instead.  From Hong Zhiguo.
    
      26) Optimize route usage in IPVS by avoiding reference counting where
          possible, from Julian Anastasov.
    
      27) Convert IPVS schedulers to RCU, also from Julian Anastasov.
    
      28) Support cpu fanouts in xt_NFQUEUE netfilter target, from Holger
          Eitzenberger.
    
      29) Network namespace support for nf_log, ebt_log, xt_LOG, ipt_ULOG,
          nfnetlink_log, and nfnetlink_queue.  From Gao feng.
    
      30) Implement RFC3168 ECN protection, from Hannes Frederic Sowa.
    
      31) Support several new r8169 chips, from Hayes Wang.
    
      32) Support tokenized interface identifiers in ipv6, from Daniel
          Borkmann.
    
      33) Use usbnet_link_change() helper in USB net driver, from Ming Lei.
    
      34) Add 802.1ad vlan offload support, from Patrick McHardy.
    
      35) Support mmap() based netlink communication, also from Patrick
          McHardy.
    
      36) Support HW timestamping in mlx4 driver, from Amir Vadai.
    
      37) Rationalize AF_PACKET packet timestamping when transmitting, from
          Willem de Bruijn and Daniel Borkmann.
    
      38) Bring parity to what's provided by /proc/net/packet socket dumping
          and the info provided by netlink socket dumping of AF_PACKET
          sockets.  From Nicolas Dichtel.
    
      39) Fix peeking beyond zero sized SKBs in AF_UNIX, from Benjamin
          Poirier"
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next: (1722 commits)
      filter: fix va_list build error
      af_unix: fix a fatal race with bit fields
      bnx2x: Prevent memory leak when cnic is absent
      bnx2x: correct reading of speed capabilities
      net: sctp: attribute printl with __printf for gcc fmt checks
      netlink: kconfig: move mmap i/o into netlink kconfig
      netpoll: convert mutex into a semaphore
      netlink: Fix skb ref counting.
      net_sched: act_ipt forward compat with xtables
      mlx4_en: fix a build error on 32bit arches
      Revert "bnx2x: allow nvram test to run when device is down"
      bridge: avoid OOPS if root port not found
      drivers: net: cpsw: fix kernel warn on cpsw irq enable
      sh_eth: use random MAC address if no valid one supplied
      3c509.c: call SET_NETDEV_DEV for all device types (ISA/ISAPnP/EISA)
      tg3: fix to append hardware time stamping flags
      unix/stream: fix peeking with an offset larger than data in queue
      unix/dgram: fix peeking with an offset larger than data in queue
      unix/dgram: peek beyond 0-sized skbs
      openvswitch: Remove unneeded ovs_netdev_get_ifindex()
      ...

commit 403bad72b67d8b3f5a0240af5023adfa48132a65
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Apr 30 15:28:10 2013 -0700

    coredump: only SIGKILL should interrupt the coredumping task
    
    There are 2 well known and ancient problems with coredump/signals, and a
    lot of related bug reports:
    
    - do_coredump() clears TIF_SIGPENDING but of course this can't help
      if, say, SIGCHLD comes after that.
    
      In this case the coredump can fail unexpectedly. See for example
      wait_for_dump_helper()->signal_pending() check but there are other
      reasons.
    
    - At the same time, dumping a huge core on the slow media can take a
      lot of time/resources and there is no way to kill the coredumping
      task reliably. In particular this is not oom_kill-friendly.
    
    This patch tries to fix the 1st problem, and makes the preparation for the
    next changes.
    
    We add the new SIGNAL_GROUP_COREDUMP flag set by zap_threads() to indicate
    that this process dumps the core.  prepare_signal() checks this flag and
    nacks any signal except SIGKILL.
    
    Note that this check tries to be conservative, in the long term we should
    probably treat the SIGNAL_GROUP_EXIT case equally but this needs more
    discussion.  See marc.info/?l=linux-kernel&m=120508897917439
    
    Notes:
            - recalc_sigpending() doesn't check SIGNAL_GROUP_COREDUMP.
              The patch assumes that dump_write/etc paths should never
              call it, but we can change it as well.
    
            - There is another source of TIF_SIGPENDING, freezer. This
              will be addressed separately.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Tested-by: Mandeep Singh Baines <msb@chromium.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Neil Horman <nhorman@redhat.com>
    Cc: "Rafael J. Wysocki" <rjw@sisk.pl>
    Cc: Roland McGrath <roland@hack.frob.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 27ece019bd0a..cede58910f9c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -854,12 +854,14 @@ static void ptrace_trap_notify(struct task_struct *t)
  * Returns true if the signal should be actually delivered, otherwise
  * it should be dropped.
  */
-static int prepare_signal(int sig, struct task_struct *p, bool force)
+static bool prepare_signal(int sig, struct task_struct *p, bool force)
 {
 	struct signal_struct *signal = p->signal;
 	struct task_struct *t;
 
-	if (unlikely(signal->flags & SIGNAL_GROUP_EXIT)) {
+	if (signal->flags & (SIGNAL_GROUP_EXIT | SIGNAL_GROUP_COREDUMP)) {
+		if (signal->flags & SIGNAL_GROUP_COREDUMP)
+			return sig == SIGKILL;
 		/*
 		 * The process is in the middle of dying, nothing to do.
 		 */

commit 681a90ffe829b8ee25d5266d7e69af256c090940
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Tue Apr 30 15:27:19 2013 -0700

    arc, print-fatal-signals: reduce duplicated information
    
    After the recent generic debug info on dump_stack() and friends, arc
    is printing duplicate information on debug dumps.
    
     [ARCLinux]$ ./crash
     crash/50: potentially unexpected fatal signal 11.      <-- [1]
     /sbin/crash, TGID 50                                   <-- [2]
     Pid: 50, comm: crash Not tainted 3.9.0-rc4+ #132       <-- [3]
     ...
    
    Remove them.
    
    [tj@kernel.org: updated patch desc]
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Fengguang Wu <fengguang.wu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Jesper Nilsson <jesper.nilsson@axis.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Mike Frysinger <vapier@gentoo.org>
    Cc: Sam Ravnborg <sam@ravnborg.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 598dc06be421..27ece019bd0a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1160,8 +1160,7 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 static void print_fatal_signal(int signr)
 {
 	struct pt_regs *regs = signal_pt_regs();
-	printk(KERN_INFO "%s/%d: potentially unexpected fatal signal %d.\n",
-		current->comm, task_pid_nr(current), signr);
+	printk(KERN_INFO "potentially unexpected fatal signal %d.\n", signr);
 
 #if defined(__i386__) && !defined(__arch_um__)
 	printk(KERN_INFO "code at %08lx: ", regs->ip);

commit 6e0895c2ea326cc4bb11e8fa2f654628d5754c31
Merge: 55fbbe46e9eb 60d509fa6a9c
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Apr 22 20:32:51 2013 -0400

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Conflicts:
            drivers/net/ethernet/emulex/benet/be_main.c
            drivers/net/ethernet/intel/igb/igb_main.c
            drivers/net/wireless/brcm80211/brcmsmac/mac80211_if.c
            include/net/scm.h
            net/batman-adv/routing.c
            net/ipv4/tcp_input.c
    
    The e{uid,gid} --> {uid,gid} credentials fix conflicted with the
    cleanup in net-next to now pass cred structs around.
    
    The be2net driver had a bug fix in 'net' that overlapped with the VLAN
    interface changes by Patrick McHardy in net-next.
    
    An IGB conflict existed because in 'net' the build_skb() support was
    reverted, and in 'net-next' there was a comment style fix within that
    code.
    
    Several batman-adv conflicts were resolved by making sure that all
    calls to batadv_is_my_mac() are changed to have a new bat_priv first
    argument.
    
    Eric Dumazet's TS ECR fix in TCP in 'net' conflicted with the F-RTO
    rewrite in 'net-next', mostly overlapping changes.
    
    Thanks to Stephen Rothwell and Antonio Quartulli for help with several
    of these merge resolutions.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit b9e146d8eb3b9ecae5086d373b50fa0c1f3e7f0f
Author: Emese Revfy <re.emese@gmail.com>
Date:   Wed Apr 17 15:58:36 2013 -0700

    kernel/signal.c: stop info leak via the tkill and the tgkill syscalls
    
    This fixes a kernel memory contents leak via the tkill and tgkill syscalls
    for compat processes.
    
    This is visible in the siginfo_t->_sifields._rt.si_sigval.sival_ptr field
    when handling signals delivered from tkill.
    
    The place of the infoleak:
    
    int copy_siginfo_to_user32(compat_siginfo_t __user *to, siginfo_t *from)
    {
            ...
            put_user_ex(ptr_to_compat(from->si_ptr), &to->si_ptr);
            ...
    }
    
    Signed-off-by: Emese Revfy <re.emese@gmail.com>
    Reviewed-by: PaX Team <pageexec@freemail.hu>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Serge Hallyn <serge.hallyn@canonical.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index dd72567767d9..598dc06be421 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2948,7 +2948,7 @@ do_send_specific(pid_t tgid, pid_t pid, int sig, struct siginfo *info)
 
 static int do_tkill(pid_t tgid, pid_t pid, int sig)
 {
-	struct siginfo info;
+	struct siginfo info = {};
 
 	info.si_signo = sig;
 	info.si_errno = 0;

commit 2b5faa4c553f90ee2dde1d976b220b1ca9741ef0
Author: Jesper Derehag <jderehag@hotmail.com>
Date:   Tue Mar 19 20:50:05 2013 +0000

    connector: Added coredumping event to the process connector
    
    Process connector can now also detect coredumping events.
    
    Main aim of patch is get notified at start of coredumping, instead of
    having to wait for it to finish and then being notified through EXIT
    event.
    
    Could be used for instance by process-managers that want to get
    notified as soon as possible about process failures, and not
    necessarily beeing notified after coredump, which could be in the
    order of minutes depending on size of coredump, piping and so on.
    
    Signed-off-by: Jesper Derehag <jderehag@hotmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/signal.c b/kernel/signal.c
index dd72567767d9..497330ec2ae9 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -32,6 +32,7 @@
 #include <linux/user_namespace.h>
 #include <linux/uprobes.h>
 #include <linux/compat.h>
+#include <linux/cn_proc.h>
 #define CREATE_TRACE_POINTS
 #include <trace/events/signal.h>
 
@@ -2350,6 +2351,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		if (sig_kernel_coredump(signr)) {
 			if (print_fatal_signals)
 				print_fatal_signal(info->si_signo);
+			proc_coredump_connector(current);
 			/*
 			 * If it was able to dump core, this kills all
 			 * other threads in the group and synchronizes with

commit 522cff142d7d2f9230839c9e1f21a4d8bcc22a4a
Author: Andrew Morton <akpm@linux-foundation.org>
Date:   Wed Mar 13 14:59:34 2013 -0700

    kernel/signal.c: use __ARCH_HAS_SA_RESTORER instead of SA_RESTORER
    
    __ARCH_HAS_SA_RESTORER is the preferred conditional for use in 3.9 and
    later kernels, per Kees.
    
    Cc: Emese Revfy <re.emese@gmail.com>
    Cc: Emese Revfy <re.emese@gmail.com>
    Cc: PaX Team <pageexec@freemail.hu>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Serge Hallyn <serge.hallyn@canonical.com>
    Cc: Julien Tinnes <jln@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 43b0d4a1b7ba..dd72567767d9 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -485,7 +485,7 @@ flush_signal_handlers(struct task_struct *t, int force_default)
 		if (force_default || ka->sa.sa_handler != SIG_IGN)
 			ka->sa.sa_handler = SIG_DFL;
 		ka->sa.sa_flags = 0;
-#ifdef SA_RESTORER
+#ifdef __ARCH_HAS_SA_RESTORER
 		ka->sa.sa_restorer = NULL;
 #endif
 		sigemptyset(&ka->sa.sa_mask);

commit 2ca39528c01a933f6689cd6505ce65bd6d68a530
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Mar 13 14:59:33 2013 -0700

    signal: always clear sa_restorer on execve
    
    When the new signal handlers are set up, the location of sa_restorer is
    not cleared, leaking a parent process's address space location to
    children.  This allows for a potential bypass of the parent's ASLR by
    examining the sa_restorer value returned when calling sigaction().
    
    Based on what should be considered "secret" about addresses, it only
    matters across the exec not the fork (since the VMAs haven't changed
    until the exec).  But since exec sets SIG_DFL and keeps sa_restorer,
    this is where it should be fixed.
    
    Given the few uses of sa_restorer, a "set" function was not written
    since this would be the only use.  Instead, we use
    __ARCH_HAS_SA_RESTORER, as already done in other places.
    
    Example of the leak before applying this patch:
    
      $ cat /proc/$$/maps
      ...
      7fb9f3083000-7fb9f3238000 r-xp 00000000 fd:01 404469 .../libc-2.15.so
      ...
      $ ./leak
      ...
      7f278bc74000-7f278be29000 r-xp 00000000 fd:01 404469 .../libc-2.15.so
      ...
      1 0 (nil) 0x7fb9f30b94a0
      2 4000000 (nil) 0x7f278bcaa4a0
      3 4000000 (nil) 0x7f278bcaa4a0
      4 0 (nil) 0x7fb9f30b94a0
      ...
    
    [akpm@linux-foundation.org: use SA_RESTORER for backportability]
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reported-by: Emese Revfy <re.emese@gmail.com>
    Cc: Emese Revfy <re.emese@gmail.com>
    Cc: PaX Team <pageexec@freemail.hu>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Serge Hallyn <serge.hallyn@canonical.com>
    Cc: Julien Tinnes <jln@google.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index d63c79e7e415..43b0d4a1b7ba 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -485,6 +485,9 @@ flush_signal_handlers(struct task_struct *t, int force_default)
 		if (force_default || ka->sa.sa_handler != SIG_IGN)
 			ka->sa.sa_handler = SIG_DFL;
 		ka->sa.sa_flags = 0;
+#ifdef SA_RESTORER
+		ka->sa.sa_restorer = NULL;
+#endif
 		sigemptyset(&ka->sa.sa_mask);
 		ka++;
 	}

commit 20f22ab42e9c832bde6e9a7ed04cdc73ec737e5b
Author: Randy Dunlap <rdunlap@infradead.org>
Date:   Mon Mar 4 14:32:59 2013 -0800

    signals: fix new kernel-doc warnings
    
    Fix new kernel-doc warnings in kernel/signal.c:
    
      Warning(kernel/signal.c:2689): No description found for parameter 'uset'
      Warning(kernel/signal.c:2689): Excess function parameter 'set' description in 'sys_rt_sigpending'
    
    Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2ec870a4c3c4..d63c79e7e415 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2682,7 +2682,7 @@ static int do_sigpending(void *set, unsigned long sigsetsize)
 /**
  *  sys_rt_sigpending - examine a pending signal that has been raised
  *			while blocked
- *  @set: stores pending signals
+ *  @uset: stores pending signals
  *  @sigsetsize: size of sigset_t type or larger
  */
 SYSCALL_DEFINE2(rt_sigpending, sigset_t __user *, uset, size_t, sigsetsize)

commit 6ec40b423032ca769c96fbf9a080db822821893d
Merge: 8d05b3771da8 db61ec29fd56
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Mar 2 19:32:06 2013 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal
    
    Pull sigprocmask compat fix from Al Viro:
     "generic compat_sys_rt_sigprocmask() had a very dumb braino; I'd spent
      quite a while staring at the offending commit before finally managing
      to spot the idiocy ;-/"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal:
      fix compat_sys_rt_sigprocmask()

commit db61ec29fd56e089007cb7d9a646ea9ddf518c4d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Mar 2 20:39:15 2013 -0500

    fix compat_sys_rt_sigprocmask()
    
    Converting bitmask to 32bit granularity is fine, but we'd better
    _do_ something with the result.  Such as "copy it to userland"...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2a7ae2963185..8d1b785f0dc9 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2653,7 +2653,7 @@ COMPAT_SYSCALL_DEFINE4(rt_sigprocmask, int, how, compat_sigset_t __user *, nset,
 	if (oset) {
 		compat_sigset_t old32;
 		sigset_to_compat(&old32, &old_set);
-		if (copy_to_user(oset, &old_set, sizeof(sigset_t)))
+		if (copy_to_user(oset, &old32, sizeof(compat_sigset_t)))
 			return -EFAULT;
 	}
 	return 0;

commit 5d1fadc1472396d602f0eeb10d37519e2a14e8bc
Author: Valdis Kletnieks <Valdis.Kletnieks@vt.edu>
Date:   Wed Feb 27 17:03:13 2013 -0800

    kernel/signal.c: fix suboptimal printk usage
    
    Several printk's were missing KERN_INFO and KERN_CONT flags.  In
    addition, a printk that was outside a #if/#endif should have been
    inside, which would result in stray blank line on non-x86 boxes.
    
    Signed-off-by: Valdis Kletnieks <valdis.kletnieks@vt.edu>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index c6209135cca4..2676aac4103d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1157,11 +1157,11 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 static void print_fatal_signal(int signr)
 {
 	struct pt_regs *regs = signal_pt_regs();
-	printk("%s/%d: potentially unexpected fatal signal %d.\n",
+	printk(KERN_INFO "%s/%d: potentially unexpected fatal signal %d.\n",
 		current->comm, task_pid_nr(current), signr);
 
 #if defined(__i386__) && !defined(__arch_um__)
-	printk("code at %08lx: ", regs->ip);
+	printk(KERN_INFO "code at %08lx: ", regs->ip);
 	{
 		int i;
 		for (i = 0; i < 16; i++) {
@@ -1169,11 +1169,11 @@ static void print_fatal_signal(int signr)
 
 			if (get_user(insn, (unsigned char *)(regs->ip + i)))
 				break;
-			printk("%02x ", insn);
+			printk(KERN_CONT "%02x ", insn);
 		}
 	}
+	printk(KERN_CONT "\n");
 #endif
-	printk("\n");
 	preempt_disable();
 	show_regs(regs);
 	preempt_enable();

commit 66dd34ad31e5963d72a700ec3f2449291d322921
Author: Andrey Vagin <avagin@openvz.org>
Date:   Wed Feb 27 17:03:12 2013 -0800

    signal: allow to send any siginfo to itself
    
    The idea is simple.  We need to get the siginfo for each signal on
    checkpointing dump, and then return it back on restore.
    
    The first problem is that the kernel doesn't report complete siginfos to
    userspace.  In a signal handler the kernel strips SI_CODE from siginfo.
    When a siginfo is received from signalfd, it has a different format with
    fixed sizes of fields.  The interface of signalfd was extended.  If a
    signalfd is created with the flag SFD_RAW, it returns siginfo in a raw
    format.
    
    rt_sigqueueinfo looks suitable for restoring signals, but it can't send
    siginfo with a positive si_code, because these codes are reserved for
    the kernel.  In the real world each person has right to do anything with
    himself, so I think a process should able to send any siginfo to itself.
    
    This patch:
    
    The kernel prevents sending of siginfo with positive si_code, because
    these codes are reserved for kernel.  I think we can allow a task to
    send such a siginfo to itself.  This operation should not be dangerous.
    
    This functionality is required for restoring signals in
    checkpoint/restart.
    
    Signed-off-by: Andrey Vagin <avagin@openvz.org>
    Cc: Serge Hallyn <serge.hallyn@canonical.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Cc: Pavel Emelyanov <xemul@parallels.com>
    Cc: Cyrill Gorcunov <gorcunov@openvz.org>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2a7ae2963185..c6209135cca4 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2996,7 +2996,8 @@ static int do_rt_sigqueueinfo(pid_t pid, int sig, siginfo_t *info)
 	/* Not even root can pretend to send signals from the kernel.
 	 * Nor can they impersonate a kill()/tgkill(), which adds source info.
 	 */
-	if (info->si_code >= 0 || info->si_code == SI_TKILL) {
+	if ((info->si_code >= 0 || info->si_code == SI_TKILL) &&
+	    (task_pid_vnr(current) != pid)) {
 		/* We used to allow any < 0 si_code */
 		WARN_ON_ONCE(info->si_code < 0);
 		return -EPERM;
@@ -3045,7 +3046,8 @@ static int do_rt_tgsigqueueinfo(pid_t tgid, pid_t pid, int sig, siginfo_t *info)
 	/* Not even root can pretend to send signals from the kernel.
 	 * Nor can they impersonate a kill()/tgkill(), which adds source info.
 	 */
-	if (info->si_code >= 0 || info->si_code == SI_TKILL) {
+	if (((info->si_code >= 0 || info->si_code == SI_TKILL)) &&
+	    (task_pid_vnr(current) != pid)) {
 		/* We used to allow any < 0 si_code */
 		WARN_ON_ONCE(info->si_code < 0);
 		return -EPERM;

commit 9e2d59ad580d590134285f361a0e80f0e98c0207
Merge: 5ce1a70e2f00 235b80226b98
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Feb 23 18:50:11 2013 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal
    
    Pull signal handling cleanups from Al Viro:
     "This is the first pile; another one will come a bit later and will
      contain SYSCALL_DEFINE-related patches.
    
       - a bunch of signal-related syscalls (both native and compat)
         unified.
    
       - a bunch of compat syscalls switched to COMPAT_SYSCALL_DEFINE
         (fixing several potential problems with missing argument
         validation, while we are at it)
    
       - a lot of now-pointless wrappers killed
    
       - a couple of architectures (cris and hexagon) forgot to save
         altstack settings into sigframe, even though they used the
         (uninitialized) values in sigreturn; fixed.
    
       - microblaze fixes for delivery of multiple signals arriving at once
    
       - saner set of helpers for signal delivery introduced, several
         architectures switched to using those."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal: (143 commits)
      x86: convert to ksignal
      sparc: convert to ksignal
      arm: switch to struct ksignal * passing
      alpha: pass k_sigaction and siginfo_t using ksignal pointer
      burying unused conditionals
      make do_sigaltstack() static
      arm64: switch to generic old sigaction() (compat-only)
      arm64: switch to generic compat rt_sigaction()
      arm64: switch compat to generic old sigsuspend
      arm64: switch to generic compat rt_sigqueueinfo()
      arm64: switch to generic compat rt_sigpending()
      arm64: switch to generic compat rt_sigprocmask()
      arm64: switch to generic sigaltstack
      sparc: switch to generic old sigsuspend
      sparc: COMPAT_SYSCALL_DEFINE does all sign-extension as well as SYSCALL_DEFINE
      sparc: kill sign-extending wrappers for native syscalls
      kill sparc32_open()
      sparc: switch to use of generic old sigaction
      sparc: switch sys_compat_rt_sigaction() to COMPAT_SYSCALL_DEFINE
      mips: switch to generic sys_fork() and sys_clone()
      ...

commit d64008a8f30e0b381b292788ec6f3ee509b3bb40
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Nov 25 23:12:10 2012 -0500

    burying unused conditionals
    
    __ARCH_WANT_SYS_RT_SIGACTION,
    __ARCH_WANT_SYS_RT_SIGSUSPEND,
    __ARCH_WANT_COMPAT_SYS_RT_SIGSUSPEND,
    __ARCH_WANT_COMPAT_SYS_SCHED_RR_GET_INTERVAL - not used anymore
    CONFIG_GENERIC_{SIGALTSTACK,COMPAT_RT_SIG{ACTION,QUEUEINFO,PENDING,PROCMASK}} -
    can be assumed always set.

diff --git a/kernel/signal.c b/kernel/signal.c
index 6919050c8156..2b8282bb487c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2623,7 +2623,6 @@ SYSCALL_DEFINE4(rt_sigprocmask, int, how, sigset_t __user *, nset,
 }
 
 #ifdef CONFIG_COMPAT
-#ifdef CONFIG_GENERIC_COMPAT_RT_SIGPROCMASK
 COMPAT_SYSCALL_DEFINE4(rt_sigprocmask, int, how, compat_sigset_t __user *, nset,
 		compat_sigset_t __user *, oset, compat_size_t, sigsetsize)
 {
@@ -2661,7 +2660,6 @@ COMPAT_SYSCALL_DEFINE4(rt_sigprocmask, int, how, compat_sigset_t __user *, nset,
 #endif
 }
 #endif
-#endif
 
 static int do_sigpending(void *set, unsigned long sigsetsize)
 {
@@ -2694,7 +2692,6 @@ SYSCALL_DEFINE2(rt_sigpending, sigset_t __user *, uset, size_t, sigsetsize)
 }
 
 #ifdef CONFIG_COMPAT
-#ifdef CONFIG_GENERIC_COMPAT_RT_SIGPENDING
 COMPAT_SYSCALL_DEFINE2(rt_sigpending, compat_sigset_t __user *, uset,
 		compat_size_t, sigsetsize)
 {
@@ -2714,7 +2711,6 @@ COMPAT_SYSCALL_DEFINE2(rt_sigpending, compat_sigset_t __user *, uset,
 #endif
 }
 #endif
-#endif
 
 #ifndef HAVE_ARCH_COPY_SIGINFO_TO_USER
 
@@ -3024,7 +3020,6 @@ SYSCALL_DEFINE3(rt_sigqueueinfo, pid_t, pid, int, sig,
 }
 
 #ifdef CONFIG_COMPAT
-#ifdef CONFIG_GENERIC_COMPAT_RT_SIGQUEUEINFO
 COMPAT_SYSCALL_DEFINE3(rt_sigqueueinfo,
 			compat_pid_t, pid,
 			int, sig,
@@ -3037,7 +3032,6 @@ COMPAT_SYSCALL_DEFINE3(rt_sigqueueinfo,
 	return do_rt_sigqueueinfo(pid, sig, &info);
 }
 #endif
-#endif
 
 static int do_rt_tgsigqueueinfo(pid_t tgid, pid_t pid, int sig, siginfo_t *info)
 {
@@ -3194,12 +3188,10 @@ do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long s
 out:
 	return error;
 }
-#ifdef CONFIG_GENERIC_SIGALTSTACK
 SYSCALL_DEFINE2(sigaltstack,const stack_t __user *,uss, stack_t __user *,uoss)
 {
 	return do_sigaltstack(uss, uoss, current_user_stack_pointer());
 }
-#endif
 
 int restore_altstack(const stack_t __user *uss)
 {
@@ -3217,7 +3209,6 @@ int __save_altstack(stack_t __user *uss, unsigned long sp)
 }
 
 #ifdef CONFIG_COMPAT
-#ifdef CONFIG_GENERIC_SIGALTSTACK
 COMPAT_SYSCALL_DEFINE2(sigaltstack,
 			const compat_stack_t __user *, uss_ptr,
 			compat_stack_t __user *, uoss_ptr)
@@ -3267,7 +3258,6 @@ int __compat_save_altstack(compat_stack_t __user *uss, unsigned long sp)
 		__put_user(t->sas_ss_size, &uss->ss_size);
 }
 #endif
-#endif
 
 #ifdef __ARCH_WANT_SYS_SIGPENDING
 
@@ -3368,7 +3358,6 @@ SYSCALL_DEFINE4(rt_sigaction, int, sig,
 	return ret;
 }
 #ifdef CONFIG_COMPAT
-#ifdef CONFIG_GENERIC_COMPAT_RT_SIGACTION
 COMPAT_SYSCALL_DEFINE4(rt_sigaction, int, sig,
 		const struct compat_sigaction __user *, act,
 		struct compat_sigaction __user *, oact,
@@ -3415,7 +3404,6 @@ COMPAT_SYSCALL_DEFINE4(rt_sigaction, int, sig,
 	return ret;
 }
 #endif
-#endif
 #endif /* !CONFIG_ODD_RT_SIGACTION */
 
 #ifdef CONFIG_OLD_SIGACTION

commit e9b04b5b67ec628a5e9a312e14b6864f8f73ba12
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Nov 20 11:14:10 2012 -0500

    make do_sigaltstack() static
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 87c09e3061d2..6919050c8156 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3129,7 +3129,7 @@ int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 	return 0;
 }
 
-int 
+static int 
 do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long sp)
 {
 	stack_t oss;

commit b2c77a57e4a0a7877e357dead7ee8acc19944f3e
Merge: c3c186403c6a 6a61671bb2f3
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Feb 5 13:10:33 2013 +0100

    Merge tag 'full-dynticks-cputime-for-mingo' of git://git.kernel.org/pub/scm/linux/kernel/git/frederic/linux-dynticks into sched/core
    
    Pull full-dynticks (user-space execution is undisturbed and
    receives no timer IRQs) preparation changes that convert the
    cputime accounting code to be full-dynticks ready,
    from Frederic Weisbecker:
    
     "This implements the cputime accounting on full dynticks CPUs.
    
      Typical cputime stats infrastructure relies on the timer tick and
      its periodic polling on the CPU to account the amount of time
      spent by the CPUs and the tasks per high level domains such as
      userspace, kernelspace, guest, ...
    
      Now we are preparing to implement full dynticks capability on
      Linux for Real Time and HPC users who want full CPU isolation.
      This feature requires a cputime accounting that doesn't depend
      on the timer tick.
    
      To implement it, this new cputime infrastructure plugs into
      kernel/user/guest boundaries to take snapshots of cputime and
      flush these to the stats when needed. This performs pretty
      much like CONFIG_VIRT_CPU_ACCOUNTING except that context location
      and cputime snaphots are synchronized between write and read
      side such that the latter can safely retrieve the pending tickless
      cputime of a task and add it to its latest cputime snapshot to
      return the correct result to the user."
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit bde208d2e10b8e8cf01cadadf203f5abcf1e4fe2
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Nov 25 01:36:15 2012 -0500

    switch mips to generic rt_sigsuspend(), make it unconditional
    
    mips was the last architecture not using the generic variant.
    Both native and compat variants switched to generic, which is
    made unconditional now.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 775f5552fa0e..87c09e3061d2 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3562,7 +3562,6 @@ int sigsuspend(sigset_t *set)
 	return -ERESTARTNOHAND;
 }
 
-#ifdef __ARCH_WANT_SYS_RT_SIGSUSPEND
 /**
  *  sys_rt_sigsuspend - replace the signal mask for a value with the
  *	@unewset value until a signal is received
@@ -3603,7 +3602,6 @@ COMPAT_SYSCALL_DEFINE2(rt_sigsuspend, compat_sigset_t __user *, unewset, compat_
 #endif
 }
 #endif
-#endif
 
 #ifdef CONFIG_OLD_SIGSUSPEND
 SYSCALL_DEFINE1(sigsuspend, old_sigset_t, mask)

commit 2ce5da17570771330f44ac993b77749debf7954b
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Nov 7 15:11:25 2012 -0500

    new helper: signal_setup_done()
    
    usual "call force_sigsegv or signal_delivered" logics.  Takes
    ksignal instead of separate siginfo/k_sigaction.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 79998f5b0f11..775f5552fa0e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2396,6 +2396,15 @@ void signal_delivered(int sig, siginfo_t *info, struct k_sigaction *ka,
 	tracehook_signal_handler(sig, info, ka, regs, stepping);
 }
 
+void signal_setup_done(int failed, struct ksignal *ksig, int stepping)
+{
+	if (failed)
+		force_sigsegv(ksig->sig, current);
+	else
+		signal_delivered(ksig->sig, &ksig->info, &ksig->ka,
+			signal_pt_regs(), stepping);
+}
+
 /*
  * It could be that complete_signal() picked us to notify about the
  * group-wide signal. Other threads should be notified now to take

commit 495dfbf767553980dbd40a19a96a8ca5fa1be616
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Dec 25 19:09:45 2012 -0500

    generic sys_sigaction() and compat_sys_sigaction()
    
    conditional on OLD_SIGACTION/COMPAT_OLD_SIGACTION
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index f3665f3de660..79998f5b0f11 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3409,6 +3409,84 @@ COMPAT_SYSCALL_DEFINE4(rt_sigaction, int, sig,
 #endif
 #endif /* !CONFIG_ODD_RT_SIGACTION */
 
+#ifdef CONFIG_OLD_SIGACTION
+SYSCALL_DEFINE3(sigaction, int, sig,
+		const struct old_sigaction __user *, act,
+	        struct old_sigaction __user *, oact)
+{
+	struct k_sigaction new_ka, old_ka;
+	int ret;
+
+	if (act) {
+		old_sigset_t mask;
+		if (!access_ok(VERIFY_READ, act, sizeof(*act)) ||
+		    __get_user(new_ka.sa.sa_handler, &act->sa_handler) ||
+		    __get_user(new_ka.sa.sa_restorer, &act->sa_restorer) ||
+		    __get_user(new_ka.sa.sa_flags, &act->sa_flags) ||
+		    __get_user(mask, &act->sa_mask))
+			return -EFAULT;
+#ifdef __ARCH_HAS_KA_RESTORER
+		new_ka.ka_restorer = NULL;
+#endif
+		siginitset(&new_ka.sa.sa_mask, mask);
+	}
+
+	ret = do_sigaction(sig, act ? &new_ka : NULL, oact ? &old_ka : NULL);
+
+	if (!ret && oact) {
+		if (!access_ok(VERIFY_WRITE, oact, sizeof(*oact)) ||
+		    __put_user(old_ka.sa.sa_handler, &oact->sa_handler) ||
+		    __put_user(old_ka.sa.sa_restorer, &oact->sa_restorer) ||
+		    __put_user(old_ka.sa.sa_flags, &oact->sa_flags) ||
+		    __put_user(old_ka.sa.sa_mask.sig[0], &oact->sa_mask))
+			return -EFAULT;
+	}
+
+	return ret;
+}
+#endif
+#ifdef CONFIG_COMPAT_OLD_SIGACTION
+COMPAT_SYSCALL_DEFINE3(sigaction, int, sig,
+		const struct compat_old_sigaction __user *, act,
+	        struct compat_old_sigaction __user *, oact)
+{
+	struct k_sigaction new_ka, old_ka;
+	int ret;
+	compat_old_sigset_t mask;
+	compat_uptr_t handler, restorer;
+
+	if (act) {
+		if (!access_ok(VERIFY_READ, act, sizeof(*act)) ||
+		    __get_user(handler, &act->sa_handler) ||
+		    __get_user(restorer, &act->sa_restorer) ||
+		    __get_user(new_ka.sa.sa_flags, &act->sa_flags) ||
+		    __get_user(mask, &act->sa_mask))
+			return -EFAULT;
+
+#ifdef __ARCH_HAS_KA_RESTORER
+		new_ka.ka_restorer = NULL;
+#endif
+		new_ka.sa.sa_handler = compat_ptr(handler);
+		new_ka.sa.sa_restorer = compat_ptr(restorer);
+		siginitset(&new_ka.sa.sa_mask, mask);
+	}
+
+	ret = do_sigaction(sig, act ? &new_ka : NULL, oact ? &old_ka : NULL);
+
+	if (!ret && oact) {
+		if (!access_ok(VERIFY_WRITE, oact, sizeof(*oact)) ||
+		    __put_user(ptr_to_compat(old_ka.sa.sa_handler),
+			       &oact->sa_handler) ||
+		    __put_user(ptr_to_compat(old_ka.sa.sa_restorer),
+			       &oact->sa_restorer) ||
+		    __put_user(old_ka.sa.sa_flags, &oact->sa_flags) ||
+		    __put_user(old_ka.sa.sa_mask.sig[0], &oact->sa_mask))
+			return -EFAULT;
+	}
+	return ret;
+}
+#endif
+
 #ifdef __ARCH_WANT_SYS_SGETMASK
 
 /*

commit 08d32fe504a7670cab3190c624448695adcf70e4
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Dec 25 18:38:15 2012 -0500

    generic sys_compat_rt_sigaction()
    
    Again, protected by a temporary config symbol (GENERIC_COMPAT_RT_SIGACTION);
    will be gone by the end of series.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5a4aed1244fb..f3665f3de660 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3358,6 +3358,55 @@ SYSCALL_DEFINE4(rt_sigaction, int, sig,
 out:
 	return ret;
 }
+#ifdef CONFIG_COMPAT
+#ifdef CONFIG_GENERIC_COMPAT_RT_SIGACTION
+COMPAT_SYSCALL_DEFINE4(rt_sigaction, int, sig,
+		const struct compat_sigaction __user *, act,
+		struct compat_sigaction __user *, oact,
+		compat_size_t, sigsetsize)
+{
+	struct k_sigaction new_ka, old_ka;
+	compat_sigset_t mask;
+#ifdef __ARCH_HAS_SA_RESTORER
+	compat_uptr_t restorer;
+#endif
+	int ret;
+
+	/* XXX: Don't preclude handling different sized sigset_t's.  */
+	if (sigsetsize != sizeof(compat_sigset_t))
+		return -EINVAL;
+
+	if (act) {
+		compat_uptr_t handler;
+		ret = get_user(handler, &act->sa_handler);
+		new_ka.sa.sa_handler = compat_ptr(handler);
+#ifdef __ARCH_HAS_SA_RESTORER
+		ret |= get_user(restorer, &act->sa_restorer);
+		new_ka.sa.sa_restorer = compat_ptr(restorer);
+#endif
+		ret |= copy_from_user(&mask, &act->sa_mask, sizeof(mask));
+		ret |= __get_user(new_ka.sa.sa_flags, &act->sa_flags);
+		if (ret)
+			return -EFAULT;
+		sigset_from_compat(&new_ka.sa.sa_mask, &mask);
+	}
+
+	ret = do_sigaction(sig, act ? &new_ka : NULL, oact ? &old_ka : NULL);
+	if (!ret && oact) {
+		sigset_to_compat(&mask, &old_ka.sa.sa_mask);
+		ret = put_user(ptr_to_compat(old_ka.sa.sa_handler), 
+			       &oact->sa_handler);
+		ret |= copy_to_user(&oact->sa_mask, &mask, sizeof(mask));
+		ret |= __put_user(old_ka.sa.sa_flags, &oact->sa_flags);
+#ifdef __ARCH_HAS_SA_RESTORER
+		ret |= put_user(ptr_to_compat(old_ka.sa.sa_restorer),
+				&oact->sa_restorer);
+#endif
+	}
+	return ret;
+}
+#endif
+#endif
 #endif /* !CONFIG_ODD_RT_SIGACTION */
 
 #ifdef __ARCH_WANT_SYS_SGETMASK

commit 9aae8fc05d2d130797be436eb7cae29c32710193
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Dec 24 23:12:04 2012 -0500

    switch rt_tgsigqueueinfo to COMPAT_SYSCALL_DEFINE
    
    C ABI violations on sparc, ppc and mips
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 93fd4b83d866..5a4aed1244fb 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3030,7 +3030,7 @@ COMPAT_SYSCALL_DEFINE3(rt_sigqueueinfo,
 #endif
 #endif
 
-long do_rt_tgsigqueueinfo(pid_t tgid, pid_t pid, int sig, siginfo_t *info)
+static int do_rt_tgsigqueueinfo(pid_t tgid, pid_t pid, int sig, siginfo_t *info)
 {
 	/* This is only valid for single tasks */
 	if (pid <= 0 || tgid <= 0)
@@ -3060,6 +3060,21 @@ SYSCALL_DEFINE4(rt_tgsigqueueinfo, pid_t, tgid, pid_t, pid, int, sig,
 	return do_rt_tgsigqueueinfo(tgid, pid, sig, &info);
 }
 
+#ifdef CONFIG_COMPAT
+COMPAT_SYSCALL_DEFINE4(rt_tgsigqueueinfo,
+			compat_pid_t, tgid,
+			compat_pid_t, pid,
+			int, sig,
+			struct compat_siginfo __user *, uinfo)
+{
+	siginfo_t info;
+
+	if (copy_siginfo_from_user32(&info, uinfo))
+		return -EFAULT;
+	return do_rt_tgsigqueueinfo(tgid, pid, sig, &info);
+}
+#endif
+
 int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 {
 	struct task_struct *t = current;

commit 0a0e8cdf734ce723bfc4ca6032ffbc03ce17c642
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Dec 25 16:04:12 2012 -0500

    old sigsuspend variants in kernel/signal.c
    
    conditional on OLD_SIGSUSPEND/OLD_SIGSUSPEND3, depending on which
    variety of that fossil is needed.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 6cd3023cc66b..93fd4b83d866 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3454,6 +3454,23 @@ COMPAT_SYSCALL_DEFINE2(rt_sigsuspend, compat_sigset_t __user *, unewset, compat_
 #endif
 #endif
 
+#ifdef CONFIG_OLD_SIGSUSPEND
+SYSCALL_DEFINE1(sigsuspend, old_sigset_t, mask)
+{
+	sigset_t blocked;
+	siginitset(&blocked, mask);
+	return sigsuspend(&blocked);
+}
+#endif
+#ifdef CONFIG_OLD_SIGSUSPEND3
+SYSCALL_DEFINE3(sigsuspend, int, unused1, int, unused2, old_sigset_t, mask)
+{
+	sigset_t blocked;
+	siginitset(&blocked, mask);
+	return sigsuspend(&blocked);
+}
+#endif
+
 __attribute__((weak)) const char *arch_vma_name(struct vm_area_struct *vma)
 {
 	return NULL;

commit 75907d4d7bc5d79b82d1453d9689efc588de1b43
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Dec 25 15:19:12 2012 -0500

    generic compat_sys_rt_sigqueueinfo()
    
    conditional on GENERIC_COMPAT_RT_SIGQUEUEINFO; by the end of that series
    it will become the same thing as COMPAT and conditional will die out.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 3040c349b0e1..6cd3023cc66b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2983,6 +2983,22 @@ SYSCALL_DEFINE2(tkill, pid_t, pid, int, sig)
 	return do_tkill(0, pid, sig);
 }
 
+static int do_rt_sigqueueinfo(pid_t pid, int sig, siginfo_t *info)
+{
+	/* Not even root can pretend to send signals from the kernel.
+	 * Nor can they impersonate a kill()/tgkill(), which adds source info.
+	 */
+	if (info->si_code >= 0 || info->si_code == SI_TKILL) {
+		/* We used to allow any < 0 si_code */
+		WARN_ON_ONCE(info->si_code < 0);
+		return -EPERM;
+	}
+	info->si_signo = sig;
+
+	/* POSIX.1b doesn't mention process groups.  */
+	return kill_proc_info(sig, info, pid);
+}
+
 /**
  *  sys_rt_sigqueueinfo - send signal information to a signal
  *  @pid: the PID of the thread
@@ -2993,23 +3009,26 @@ SYSCALL_DEFINE3(rt_sigqueueinfo, pid_t, pid, int, sig,
 		siginfo_t __user *, uinfo)
 {
 	siginfo_t info;
-
 	if (copy_from_user(&info, uinfo, sizeof(siginfo_t)))
 		return -EFAULT;
+	return do_rt_sigqueueinfo(pid, sig, &info);
+}
 
-	/* Not even root can pretend to send signals from the kernel.
-	 * Nor can they impersonate a kill()/tgkill(), which adds source info.
-	 */
-	if (info.si_code >= 0 || info.si_code == SI_TKILL) {
-		/* We used to allow any < 0 si_code */
-		WARN_ON_ONCE(info.si_code < 0);
-		return -EPERM;
-	}
-	info.si_signo = sig;
-
-	/* POSIX.1b doesn't mention process groups.  */
-	return kill_proc_info(sig, &info, pid);
+#ifdef CONFIG_COMPAT
+#ifdef CONFIG_GENERIC_COMPAT_RT_SIGQUEUEINFO
+COMPAT_SYSCALL_DEFINE3(rt_sigqueueinfo,
+			compat_pid_t, pid,
+			int, sig,
+			struct compat_siginfo __user *, uinfo)
+{
+	siginfo_t info;
+	int ret = copy_siginfo_from_user32(&info, uinfo);
+	if (unlikely(ret))
+		return ret;
+	return do_rt_sigqueueinfo(pid, sig, &info);
 }
+#endif
+#endif
 
 long do_rt_tgsigqueueinfo(pid_t tgid, pid_t pid, int sig, siginfo_t *info)
 {

commit fe9c1db2cfc363cd30ecfe6480481b280abf8c0a
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Dec 25 14:31:38 2012 -0500

    generic compat_sys_rt_sigpending()
    
    conditional on GENERIC_COMPAT_RT_SIGPENDING; by the end of that series
    it will become the same thing as COMPAT and conditional will die out.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index bce1222b7315..3040c349b0e1 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2654,28 +2654,19 @@ COMPAT_SYSCALL_DEFINE4(rt_sigprocmask, int, how, compat_sigset_t __user *, nset,
 #endif
 #endif
 
-long do_sigpending(void __user *set, unsigned long sigsetsize)
+static int do_sigpending(void *set, unsigned long sigsetsize)
 {
-	long error = -EINVAL;
-	sigset_t pending;
-
 	if (sigsetsize > sizeof(sigset_t))
-		goto out;
+		return -EINVAL;
 
 	spin_lock_irq(&current->sighand->siglock);
-	sigorsets(&pending, &current->pending.signal,
+	sigorsets(set, &current->pending.signal,
 		  &current->signal->shared_pending.signal);
 	spin_unlock_irq(&current->sighand->siglock);
 
 	/* Outside the lock because only this thread touches it.  */
-	sigandsets(&pending, &current->blocked, &pending);
-
-	error = -EFAULT;
-	if (!copy_to_user(set, &pending, sigsetsize))
-		error = 0;
-
-out:
-	return error;
+	sigandsets(set, &current->blocked, set);
+	return 0;
 }
 
 /**
@@ -2684,10 +2675,37 @@ long do_sigpending(void __user *set, unsigned long sigsetsize)
  *  @set: stores pending signals
  *  @sigsetsize: size of sigset_t type or larger
  */
-SYSCALL_DEFINE2(rt_sigpending, sigset_t __user *, set, size_t, sigsetsize)
+SYSCALL_DEFINE2(rt_sigpending, sigset_t __user *, uset, size_t, sigsetsize)
+{
+	sigset_t set;
+	int err = do_sigpending(&set, sigsetsize);
+	if (!err && copy_to_user(uset, &set, sigsetsize))
+		err = -EFAULT;
+	return err;
+}
+
+#ifdef CONFIG_COMPAT
+#ifdef CONFIG_GENERIC_COMPAT_RT_SIGPENDING
+COMPAT_SYSCALL_DEFINE2(rt_sigpending, compat_sigset_t __user *, uset,
+		compat_size_t, sigsetsize)
 {
-	return do_sigpending(set, sigsetsize);
+#ifdef __BIG_ENDIAN
+	sigset_t set;
+	int err = do_sigpending(&set, sigsetsize);
+	if (!err) {
+		compat_sigset_t set32;
+		sigset_to_compat(&set32, &set);
+		/* we can get here only if sigsetsize <= sizeof(set) */
+		if (copy_to_user(uset, &set32, sigsetsize))
+			err = -EFAULT;
+	}
+	return err;
+#else
+	return sys_rt_sigpending((sigset_t __user *)uset, sigsetsize);
+#endif
 }
+#endif
+#endif
 
 #ifndef HAVE_ARCH_COPY_SIGINFO_TO_USER
 
@@ -3216,7 +3234,7 @@ int __compat_save_altstack(compat_stack_t __user *uss, unsigned long sp)
  */
 SYSCALL_DEFINE1(sigpending, old_sigset_t __user *, set)
 {
-	return do_sigpending(set, sizeof(*set));
+	return sys_rt_sigpending((sigset_t __user *)set, sizeof(old_sigset_t)); 
 }
 
 #endif

commit 322a56cb1fcbe228eee5cdb8a9c6df9f797d998c
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Dec 25 13:32:58 2012 -0500

    generic compat_sys_rt_sigprocmask()
    
    conditional on GENERIC_COMPAT_RT_SIGPROCMASK; by the end of that series
    it will become the same thing as COMPAT and conditional will die out.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 4a0934e03d5c..bce1222b7315 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2613,6 +2613,47 @@ SYSCALL_DEFINE4(rt_sigprocmask, int, how, sigset_t __user *, nset,
 	return 0;
 }
 
+#ifdef CONFIG_COMPAT
+#ifdef CONFIG_GENERIC_COMPAT_RT_SIGPROCMASK
+COMPAT_SYSCALL_DEFINE4(rt_sigprocmask, int, how, compat_sigset_t __user *, nset,
+		compat_sigset_t __user *, oset, compat_size_t, sigsetsize)
+{
+#ifdef __BIG_ENDIAN
+	sigset_t old_set = current->blocked;
+
+	/* XXX: Don't preclude handling different sized sigset_t's.  */
+	if (sigsetsize != sizeof(sigset_t))
+		return -EINVAL;
+
+	if (nset) {
+		compat_sigset_t new32;
+		sigset_t new_set;
+		int error;
+		if (copy_from_user(&new32, nset, sizeof(compat_sigset_t)))
+			return -EFAULT;
+
+		sigset_from_compat(&new_set, &new32);
+		sigdelsetmask(&new_set, sigmask(SIGKILL)|sigmask(SIGSTOP));
+
+		error = sigprocmask(how, &new_set, NULL);
+		if (error)
+			return error;
+	}
+	if (oset) {
+		compat_sigset_t old32;
+		sigset_to_compat(&old32, &old_set);
+		if (copy_to_user(oset, &old_set, sizeof(sigset_t)))
+			return -EFAULT;
+	}
+	return 0;
+#else
+	return sys_rt_sigprocmask(how, (sigset_t __user *)nset,
+				  (sigset_t __user *)oset, sigsetsize);
+#endif
+}
+#endif
+#endif
+
 long do_sigpending(void __user *set, unsigned long sigsetsize)
 {
 	long error = -EINVAL;

commit ad4b65a434bdd2ff37d095ab1ccd836203e985ba
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Dec 24 21:43:56 2012 -0500

    consolidate rt_sigsuspend()
    
    * pull compat version alongside with the native one
    * make little-endian compat variant just call the native
    * don't bother with separate conditional for compat (both native and
    compat are going to become unconditional very soon).
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 00cd1ce998be..4a0934e03d5c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3352,7 +3352,29 @@ SYSCALL_DEFINE2(rt_sigsuspend, sigset_t __user *, unewset, size_t, sigsetsize)
 		return -EFAULT;
 	return sigsuspend(&newset);
 }
-#endif /* __ARCH_WANT_SYS_RT_SIGSUSPEND */
+ 
+#ifdef CONFIG_COMPAT
+COMPAT_SYSCALL_DEFINE2(rt_sigsuspend, compat_sigset_t __user *, unewset, compat_size_t, sigsetsize)
+{
+#ifdef __BIG_ENDIAN
+	sigset_t newset;
+	compat_sigset_t newset32;
+
+	/* XXX: Don't preclude handling different sized sigset_t's.  */
+	if (sigsetsize != sizeof(sigset_t))
+		return -EINVAL;
+
+	if (copy_from_user(&newset32, unewset, sizeof(compat_sigset_t)))
+		return -EFAULT;
+	sigset_from_compat(&newset, &newset32);
+	return sigsuspend(&newset);
+#else
+	/* on little-endian bitmaps don't care about granularity */
+	return sys_rt_sigsuspend((sigset_t __user *)unewset, sigsetsize);
+#endif
+}
+#endif
+#endif
 
 __attribute__((weak)) const char *arch_vma_name(struct vm_area_struct *vma)
 {

commit eaca6eae3e0c41d41fcb9d1d70e00934988dff2e
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Nov 25 23:12:10 2012 -0500

    sanitize rt_sigaction() situation a bit
    
            Switch from __ARCH_WANT_SYS_RT_SIGACTION to opposite
    (!CONFIG_ODD_RT_SIGACTION); the only two architectures that
    need it are alpha and sparc.  The reason for use of CONFIG_...
    instead of __ARCH_... is that it's needed only kernel-side
    and doing it that way avoids a mess with include order on many
    architectures.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 53cd5c4d1172..00cd1ce998be 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3231,7 +3231,7 @@ SYSCALL_DEFINE3(sigprocmask, int, how, old_sigset_t __user *, nset,
 }
 #endif /* __ARCH_WANT_SYS_SIGPROCMASK */
 
-#ifdef __ARCH_WANT_SYS_RT_SIGACTION
+#ifndef CONFIG_ODD_RT_SIGACTION
 /**
  *  sys_rt_sigaction - alter an action taken by a process
  *  @sig: signal to be sent
@@ -3265,7 +3265,7 @@ SYSCALL_DEFINE4(rt_sigaction, int, sig,
 out:
 	return ret;
 }
-#endif /* __ARCH_WANT_SYS_RT_SIGACTION */
+#endif /* !CONFIG_ODD_RT_SIGACTION */
 
 #ifdef __ARCH_WANT_SYS_SGETMASK
 

commit 6fac4829ce0ef9b7f24369086ce5f0e9f38d37bc
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Nov 13 14:20:55 2012 +0100

    cputime: Use accessors to read task cputime stats
    
    This is in preparation for the full dynticks feature. While
    remotely reading the cputime of a task running in a full
    dynticks CPU, we'll need to do some extra-computation. This
    way we can account the time it spent tickless in userspace
    since its last cputime snapshot.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Li Zhong <zhong@linux.vnet.ibm.com>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/signal.c b/kernel/signal.c
index 372771e948c2..776a45a3661b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1638,6 +1638,7 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 	unsigned long flags;
 	struct sighand_struct *psig;
 	bool autoreap = false;
+	cputime_t utime, stime;
 
 	BUG_ON(sig == -1);
 
@@ -1675,8 +1676,9 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 				       task_uid(tsk));
 	rcu_read_unlock();
 
-	info.si_utime = cputime_to_clock_t(tsk->utime + tsk->signal->utime);
-	info.si_stime = cputime_to_clock_t(tsk->stime + tsk->signal->stime);
+	task_cputime(tsk, &utime, &stime);
+	info.si_utime = cputime_to_clock_t(utime + tsk->signal->utime);
+	info.si_stime = cputime_to_clock_t(stime + tsk->signal->stime);
 
 	info.si_status = tsk->exit_code & 0x7f;
 	if (tsk->exit_code & 0x80)
@@ -1740,6 +1742,7 @@ static void do_notify_parent_cldstop(struct task_struct *tsk,
 	unsigned long flags;
 	struct task_struct *parent;
 	struct sighand_struct *sighand;
+	cputime_t utime, stime;
 
 	if (for_ptracer) {
 		parent = tsk->parent;
@@ -1758,8 +1761,9 @@ static void do_notify_parent_cldstop(struct task_struct *tsk,
 	info.si_uid = from_kuid_munged(task_cred_xxx(parent, user_ns), task_uid(tsk));
 	rcu_read_unlock();
 
-	info.si_utime = cputime_to_clock_t(tsk->utime);
-	info.si_stime = cputime_to_clock_t(tsk->stime);
+	task_cputime(tsk, &utime, &stime);
+	info.si_utime = cputime_to_clock_t(utime);
+	info.si_stime = cputime_to_clock_t(stime);
 
  	info.si_code = why;
  	switch (why) {

commit 9899d11f654474d2d54ea52ceaa2a1f4db3abd68
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Mon Jan 21 20:48:00 2013 +0100

    ptrace: ensure arch_ptrace/ptrace_request can never race with SIGKILL
    
    putreg() assumes that the tracee is not running and pt_regs_access() can
    safely play with its stack.  However a killed tracee can return from
    ptrace_stop() to the low-level asm code and do RESTORE_REST, this means
    that debugger can actually read/modify the kernel stack until the tracee
    does SAVE_REST again.
    
    set_task_blockstep() can race with SIGKILL too and in some sense this
    race is even worse, the very fact the tracee can be woken up breaks the
    logic.
    
    As Linus suggested we can clear TASK_WAKEKILL around the arch_ptrace()
    call, this ensures that nobody can ever wakeup the tracee while the
    debugger looks at it.  Not only this fixes the mentioned problems, we
    can do some cleanups/simplifications in arch_ptrace() paths.
    
    Probably ptrace_unfreeze_traced() needs more callers, for example it
    makes sense to make the tracee killable for oom-killer before
    access_process_vm().
    
    While at it, add the comment into may_ptrace_stop() to explain why
    ptrace_stop() still can't rely on SIGKILL and signal_pending_state().
    
    Reported-by: Salman Qazi <sqazi@google.com>
    Reported-by: Suleiman Souhlal <suleiman@google.com>
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 6e97aa6fa32c..3d09cf6cde75 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1794,6 +1794,10 @@ static inline int may_ptrace_stop(void)
 	 * If SIGKILL was already sent before the caller unlocked
 	 * ->siglock we must see ->core_state != NULL. Otherwise it
 	 * is safe to enter schedule().
+	 *
+	 * This is almost outdated, a task with the pending SIGKILL can't
+	 * block in TASK_TRACED. But PTRACE_EVENT_EXIT can be reported
+	 * after SIGKILL was already dequeued.
 	 */
 	if (unlikely(current->mm->core_state) &&
 	    unlikely(current->mm == current->parent->mm))
@@ -1919,6 +1923,7 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 		if (gstop_done)
 			do_notify_parent_cldstop(current, false, why);
 
+		/* tasklist protects us from ptrace_freeze_traced() */
 		__set_current_state(TASK_RUNNING);
 		if (clear_code)
 			current->exit_code = 0;

commit 910ffdb18a6408e14febbb6e4b6840fd2c928c82
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Mon Jan 21 20:47:41 2013 +0100

    ptrace: introduce signal_wake_up_state() and ptrace_signal_wake_up()
    
    Cleanup and preparation for the next change.
    
    signal_wake_up(resume => true) is overused. None of ptrace/jctl callers
    actually want to wakeup a TASK_WAKEKILL task, but they can't specify the
    necessary mask.
    
    Turn signal_wake_up() into signal_wake_up_state(state), reintroduce
    signal_wake_up() as a trivial helper, and add ptrace_signal_wake_up()
    which adds __TASK_TRACED.
    
    This way ptrace_signal_wake_up() can work "inside" ptrace_request()
    even if the tracee doesn't have the TASK_WAKEKILL bit set.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 53cd5c4d1172..6e97aa6fa32c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -680,23 +680,17 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
  * No need to set need_resched since signal event passing
  * goes through ->blocked
  */
-void signal_wake_up(struct task_struct *t, int resume)
+void signal_wake_up_state(struct task_struct *t, unsigned int state)
 {
-	unsigned int mask;
-
 	set_tsk_thread_flag(t, TIF_SIGPENDING);
-
 	/*
-	 * For SIGKILL, we want to wake it up in the stopped/traced/killable
+	 * TASK_WAKEKILL also means wake it up in the stopped/traced/killable
 	 * case. We don't check t->state here because there is a race with it
 	 * executing another processor and just now entering stopped state.
 	 * By using wake_up_state, we ensure the process will wake up and
 	 * handle its death signal.
 	 */
-	mask = TASK_INTERRUPTIBLE;
-	if (resume)
-		mask |= TASK_WAKEKILL;
-	if (!wake_up_state(t, mask))
+	if (!wake_up_state(t, state | TASK_INTERRUPTIBLE))
 		kick_process(t);
 }
 
@@ -844,7 +838,7 @@ static void ptrace_trap_notify(struct task_struct *t)
 	assert_spin_locked(&t->sighand->siglock);
 
 	task_set_jobctl_pending(t, JOBCTL_TRAP_NOTIFY);
-	signal_wake_up(t, t->jobctl & JOBCTL_LISTENING);
+	ptrace_signal_wake_up(t, t->jobctl & JOBCTL_LISTENING);
 }
 
 /*

commit 3a142ed962958d3063f648738a3384ab90017100
Merge: edea0d03ee5f b1e0318b8cd4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Jan 20 13:58:48 2013 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal
    
    Pull misc syscall fixes from Al Viro:
    
     - compat syscall fixes (discussed back in December)
    
     - a couple of "make life easier for sigaltstack stuff by reducing
       inter-tree dependencies"
    
     - fix up compiler/asmlinkage calling convention disagreement of
       sys_clone()
    
     - misc
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal:
      sys_clone() needs asmlinkage_protect
      make sure that /linuxrc has std{in,out,err}
      x32: fix sigtimedwait
      x32: fix waitid()
      switch compat_sys_wait4() and compat_sys_waitid() to COMPAT_SYSCALL_DEFINE
      switch compat_sys_sigaltstack() to COMPAT_SYSCALL_DEFINE
      CONFIG_GENERIC_SIGALTSTACK build breakage with asm-generic/syscalls.h
      Ensure that kernel_init_freeable() is not inlined into non __init code

commit 0c4a842349b27d361f1503f6437df303e1b541c9
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Sat Jan 5 19:13:29 2013 +0100

    signals: set_current_blocked() can use __set_current_blocked()
    
    Cleanup.  And I think we need more cleanups, in particular
    __set_current_blocked() and sigprocmask() should die.  Nobody should
    ever block SIGKILL or SIGSTOP.
    
     - Change set_current_blocked() to use __set_current_blocked()
    
     - Change sys_sigprocmask() to use set_current_blocked(), this way it
       should not worry about SIGKILL/SIGSTOP.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9692499c77cf..372771e948c2 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2528,11 +2528,8 @@ static void __set_task_blocked(struct task_struct *tsk, const sigset_t *newset)
  */
 void set_current_blocked(sigset_t *newset)
 {
-	struct task_struct *tsk = current;
 	sigdelsetmask(newset, sigmask(SIGKILL) | sigmask(SIGSTOP));
-	spin_lock_irq(&tsk->sighand->siglock);
-	__set_task_blocked(tsk, newset);
-	spin_unlock_irq(&tsk->sighand->siglock);
+	__set_current_blocked(newset);
 }
 
 void __set_current_blocked(const sigset_t *newset)
@@ -3204,7 +3201,6 @@ SYSCALL_DEFINE3(sigprocmask, int, how, old_sigset_t __user *, nset,
 	if (nset) {
 		if (copy_from_user(&new_set, nset, sizeof(*nset)))
 			return -EFAULT;
-		new_set &= ~(sigmask(SIGKILL) | sigmask(SIGSTOP));
 
 		new_blocked = current->blocked;
 
@@ -3222,7 +3218,7 @@ SYSCALL_DEFINE3(sigprocmask, int, how, old_sigset_t __user *, nset,
 			return -EINVAL;
 		}
 
-		__set_current_blocked(&new_blocked);
+		set_current_blocked(&new_blocked);
 	}
 
 	if (oset) {

commit 5ba53ff648e785445a32ba39112ed07e4cf588d0
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Sat Jan 5 19:13:13 2013 +0100

    signals: sys_ssetmask() uses uninitialized newmask
    
    Commit 77097ae503b1 ("most of set_current_blocked() callers want
    SIGKILL/SIGSTOP removed from set") removed the initialization of newmask
    by accident, causing ltp to complain like this:
    
      ssetmask01    1  TFAIL  :  sgetmask() failed: TEST_ERRNO=???(0): Success
    
    Restore the proper initialization.
    
    Reported-and-tested-by: CAI Qian <caiqian@redhat.com>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: stable@kernel.org   # v3.5+
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 7aaa51d8e5b8..9692499c77cf 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3286,6 +3286,7 @@ SYSCALL_DEFINE1(ssetmask, int, newmask)
 	int old = current->blocked.sig[0];
 	sigset_t newset;
 
+	siginitset(&newset, newmask);
 	set_current_blocked(&newset);
 
 	return old;

commit 90228fc110303549aa1d4d86083bf585df8624c3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Dec 23 03:33:38 2012 -0500

    switch compat_sys_sigaltstack() to COMPAT_SYSCALL_DEFINE
    
    Makes sigaltstack conversion easier to split into per-architecture
    parts.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 7aaa51d8e5b8..00b4a6d4449d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3119,8 +3119,9 @@ int __save_altstack(stack_t __user *uss, unsigned long sp)
 
 #ifdef CONFIG_COMPAT
 #ifdef CONFIG_GENERIC_SIGALTSTACK
-asmlinkage long compat_sys_sigaltstack(const compat_stack_t __user *uss_ptr,
-				       compat_stack_t __user *uoss_ptr)
+COMPAT_SYSCALL_DEFINE2(sigaltstack,
+			const compat_stack_t __user *, uss_ptr,
+			compat_stack_t __user *, uoss_ptr)
 {
 	stack_t uss, uoss;
 	int ret;

commit 54d46ea993744c5408e39ce0cb4851e13cbea716
Merge: f59dc2bb5a50 50ececcfa7d1
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Dec 20 18:05:28 2012 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal
    
    Pull signal handling cleanups from Al Viro:
     "sigaltstack infrastructure + conversion for x86, alpha and um,
      COMPAT_SYSCALL_DEFINE infrastructure.
    
      Note that there are several conflicts between "unify
      SS_ONSTACK/SS_DISABLE definitions" and UAPI patches in mainline;
      resolution is trivial - just remove definitions of SS_ONSTACK and
      SS_DISABLED from arch/*/uapi/asm/signal.h; they are all identical and
      include/uapi/linux/signal.h contains the unified variant."
    
    Fixed up conflicts as per Al.
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal:
      alpha: switch to generic sigaltstack
      new helpers: __save_altstack/__compat_save_altstack, switch x86 and um to those
      generic compat_sys_sigaltstack()
      introduce generic sys_sigaltstack(), switch x86 and um to it
      new helper: compat_user_stack_pointer()
      new helper: restore_altstack()
      unify SS_ONSTACK/SS_DISABLE definitions
      new helper: current_user_stack_pointer()
      missing user_stack_pointer() instances
      Bury the conditionals from kernel_thread/kernel_execve series
      COMPAT_SYSCALL_DEFINE: infrastructure

commit c40702c49faef05ae324f121d8b3e215244ee152
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Nov 20 14:24:26 2012 -0500

    new helpers: __save_altstack/__compat_save_altstack, switch x86 and um to those
    
    note that they are relying on access_ok() already checked by caller.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index aee85bd76b8a..f072513302c3 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3117,6 +3117,14 @@ int restore_altstack(const stack_t __user *uss)
 	return err == -EFAULT ? err : 0;
 }
 
+int __save_altstack(stack_t __user *uss, unsigned long sp)
+{
+	struct task_struct *t = current;
+	return  __put_user((void __user *)t->sas_ss_sp, &uss->ss_sp) |
+		__put_user(sas_ss_flags(sp), &uss->ss_flags) |
+		__put_user(t->sas_ss_size, &uss->ss_size);
+}
+
 #ifdef CONFIG_COMPAT
 #ifdef CONFIG_GENERIC_SIGALTSTACK
 asmlinkage long compat_sys_sigaltstack(const compat_stack_t __user *uss_ptr,
@@ -3158,6 +3166,14 @@ int compat_restore_altstack(const compat_stack_t __user *uss)
 	/* squash all but -EFAULT for now */
 	return err == -EFAULT ? err : 0;
 }
+
+int __compat_save_altstack(compat_stack_t __user *uss, unsigned long sp)
+{
+	struct task_struct *t = current;
+	return  __put_user(ptr_to_compat((void __user *)t->sas_ss_sp), &uss->ss_sp) |
+		__put_user(sas_ss_flags(sp), &uss->ss_flags) |
+		__put_user(t->sas_ss_size, &uss->ss_size);
+}
 #endif
 #endif
 

commit 9026843952adac5b123c7b8dc961e5c15828d9e1
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Dec 14 14:47:53 2012 -0500

    generic compat_sys_sigaltstack()
    
    Again, conditional on CONFIG_GENERIC_SIGALTSTACK
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index f05f4c4150d9..aee85bd76b8a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -31,6 +31,7 @@
 #include <linux/nsproxy.h>
 #include <linux/user_namespace.h>
 #include <linux/uprobes.h>
+#include <linux/compat.h>
 #define CREATE_TRACE_POINTS
 #include <trace/events/signal.h>
 
@@ -3116,6 +3117,50 @@ int restore_altstack(const stack_t __user *uss)
 	return err == -EFAULT ? err : 0;
 }
 
+#ifdef CONFIG_COMPAT
+#ifdef CONFIG_GENERIC_SIGALTSTACK
+asmlinkage long compat_sys_sigaltstack(const compat_stack_t __user *uss_ptr,
+				       compat_stack_t __user *uoss_ptr)
+{
+	stack_t uss, uoss;
+	int ret;
+	mm_segment_t seg;
+
+	if (uss_ptr) {
+		compat_stack_t uss32;
+
+		memset(&uss, 0, sizeof(stack_t));
+		if (copy_from_user(&uss32, uss_ptr, sizeof(compat_stack_t)))
+			return -EFAULT;
+		uss.ss_sp = compat_ptr(uss32.ss_sp);
+		uss.ss_flags = uss32.ss_flags;
+		uss.ss_size = uss32.ss_size;
+	}
+	seg = get_fs();
+	set_fs(KERNEL_DS);
+	ret = do_sigaltstack((stack_t __force __user *) (uss_ptr ? &uss : NULL),
+			     (stack_t __force __user *) &uoss,
+			     compat_user_stack_pointer());
+	set_fs(seg);
+	if (ret >= 0 && uoss_ptr)  {
+		if (!access_ok(VERIFY_WRITE, uoss_ptr, sizeof(compat_stack_t)) ||
+		    __put_user(ptr_to_compat(uoss.ss_sp), &uoss_ptr->ss_sp) ||
+		    __put_user(uoss.ss_flags, &uoss_ptr->ss_flags) ||
+		    __put_user(uoss.ss_size, &uoss_ptr->ss_size))
+			ret = -EFAULT;
+	}
+	return ret;
+}
+
+int compat_restore_altstack(const compat_stack_t __user *uss)
+{
+	int err = compat_sys_sigaltstack(uss, NULL);
+	/* squash all but -EFAULT for now */
+	return err == -EFAULT ? err : 0;
+}
+#endif
+#endif
+
 #ifdef __ARCH_WANT_SYS_SIGPENDING
 
 /**

commit 6bf9adfc90370b695cb111116e15fdc0e1906270
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Dec 14 14:09:47 2012 -0500

    introduce generic sys_sigaltstack(), switch x86 and um to it
    
    Conditional on CONFIG_GENERIC_SIGALTSTACK; architectures that do not
    select it are completely unaffected
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 887f2fefe207..f05f4c4150d9 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3102,6 +3102,12 @@ do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long s
 out:
 	return error;
 }
+#ifdef CONFIG_GENERIC_SIGALTSTACK
+SYSCALL_DEFINE2(sigaltstack,const stack_t __user *,uss, stack_t __user *,uoss)
+{
+	return do_sigaltstack(uss, uoss, current_user_stack_pointer());
+}
+#endif
 
 int restore_altstack(const stack_t __user *uss)
 {

commit 5c49574ffd7ac07eae8c3b065d19e6ebc7e4760f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Nov 18 15:29:16 2012 -0500

    new helper: restore_altstack()
    
    to be used by rt_sigreturn instances
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index e75e4bd2839b..887f2fefe207 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3103,6 +3103,13 @@ do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long s
 	return error;
 }
 
+int restore_altstack(const stack_t __user *uss)
+{
+	int err = do_sigaltstack(uss, NULL, current_user_stack_pointer());
+	/* squash all but EFAULT for now */
+	return err == -EFAULT ? err : 0;
+}
+
 #ifdef __ARCH_WANT_SYS_SIGPENDING
 
 /**

commit 6a2b60b17b3e48a418695a94bd2420f6ab32e519
Merge: 9228ff90387e 98f842e675f9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Dec 17 15:44:47 2012 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull user namespace changes from Eric Biederman:
     "While small this set of changes is very significant with respect to
      containers in general and user namespaces in particular.  The user
      space interface is now complete.
    
      This set of changes adds support for unprivileged users to create user
      namespaces and as a user namespace root to create other namespaces.
      The tyranny of supporting suid root preventing unprivileged users from
      using cool new kernel features is broken.
    
      This set of changes completes the work on setns, adding support for
      the pid, user, mount namespaces.
    
      This set of changes includes a bunch of basic pid namespace
      cleanups/simplifications.  Of particular significance is the rework of
      the pid namespace cleanup so it no longer requires sending out
      tendrils into all kinds of unexpected cleanup paths for operation.  At
      least one case of broken error handling is fixed by this cleanup.
    
      The files under /proc/<pid>/ns/ have been converted from regular files
      to magic symlinks which prevents incorrect caching by the VFS,
      ensuring the files always refer to the namespace the process is
      currently using and ensuring that the ptrace_mayaccess permission
      checks are always applied.
    
      The files under /proc/<pid>/ns/ have been given stable inode numbers
      so it is now possible to see if different processes share the same
      namespaces.
    
      Through the David Miller's net tree are changes to relax many of the
      permission checks in the networking stack to allowing the user
      namespace root to usefully use the networking stack.  Similar changes
      for the mount namespace and the pid namespace are coming through my
      tree.
    
      Two small changes to add user namespace support were commited here adn
      in David Miller's -net tree so that I could complete the work on the
      /proc/<pid>/ns/ files in this tree.
    
      Work remains to make it safe to build user namespaces and 9p, afs,
      ceph, cifs, coda, gfs2, ncpfs, nfs, nfsd, ocfs2, and xfs so the
      Kconfig guard remains in place preventing that user namespaces from
      being built when any of those filesystems are enabled.
    
      Future design work remains to allow root users outside of the initial
      user namespace to mount more than just /proc and /sys."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (38 commits)
      proc: Usable inode numbers for the namespace file descriptors.
      proc: Fix the namespace inode permission checks.
      proc: Generalize proc inode allocation
      userns: Allow unprivilged mounts of proc and sysfs
      userns: For /proc/self/{uid,gid}_map derive the lower userns from the struct file
      procfs: Print task uids and gids in the userns that opened the proc file
      userns: Implement unshare of the user namespace
      userns: Implent proc namespace operations
      userns: Kill task_user_ns
      userns: Make create_new_namespaces take a user_ns parameter
      userns: Allow unprivileged use of setns.
      userns: Allow unprivileged users to create new namespaces
      userns: Allow setting a userns mapping to your current uid.
      userns: Allow chown and setgid preservation
      userns: Allow unprivileged users to create user namespaces.
      userns: Ignore suid and sgid on binaries if the uid or gid can not be mapped
      userns: fix return value on mntns_install() failure
      vfs: Allow unprivileged manipulation of the mount namespace.
      vfs: Only support slave subtrees across different user namespaces
      vfs: Add a user namespace reference from struct mnt_namespace
      ...

commit 9977d9b379cb77e0f67bd6f4563618106e58e11d
Merge: cf4af0122157 541880d9a2c7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Dec 12 12:22:13 2012 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal
    
    Pull big execve/kernel_thread/fork unification series from Al Viro:
     "All architectures are converted to new model.  Quite a bit of that
      stuff is actually shared with architecture trees; in such cases it's
      literally shared branch pulled by both, not a cherry-pick.
    
      A lot of ugliness and black magic is gone (-3KLoC total in this one):
    
       - kernel_thread()/kernel_execve()/sys_execve() redesign.
    
         We don't do syscalls from kernel anymore for either kernel_thread()
         or kernel_execve():
    
         kernel_thread() is essentially clone(2) with callback run before we
         return to userland, the callbacks either never return or do
         successful do_execve() before returning.
    
         kernel_execve() is a wrapper for do_execve() - it doesn't need to
         do transition to user mode anymore.
    
         As a result kernel_thread() and kernel_execve() are
         arch-independent now - they live in kernel/fork.c and fs/exec.c
         resp.  sys_execve() is also in fs/exec.c and it's completely
         architecture-independent.
    
       - daemonize() is gone, along with its parts in fs/*.c
    
       - struct pt_regs * is no longer passed to do_fork/copy_process/
         copy_thread/do_execve/search_binary_handler/->load_binary/do_coredump.
    
       - sys_fork()/sys_vfork()/sys_clone() unified; some architectures
         still need wrappers (ones with callee-saved registers not saved in
         pt_regs on syscall entry), but the main part of those suckers is in
         kernel/fork.c now."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal: (113 commits)
      do_coredump(): get rid of pt_regs argument
      print_fatal_signal(): get rid of pt_regs argument
      ptrace_signal(): get rid of unused arguments
      get rid of ptrace_signal_deliver() arguments
      new helper: signal_pt_regs()
      unify default ptrace_signal_deliver
      flagday: kill pt_regs argument of do_fork()
      death to idle_regs()
      don't pass regs to copy_process()
      flagday: don't pass regs to copy_thread()
      bfin: switch to generic vfork, get rid of pointless wrappers
      xtensa: switch to generic clone()
      openrisc: switch to use of generic fork and clone
      unicore32: switch to generic clone(2)
      score: switch to generic fork/vfork/clone
      c6x: sanitize copy_thread(), get rid of clone(2) wrapper, switch to generic clone()
      take sys_fork/sys_vfork/sys_clone prototypes to linux/syscalls.h
      mn10300: switch to generic fork/vfork/clone
      h8300: switch to generic fork/vfork/clone
      tile: switch to generic clone()
      ...
    
    Conflicts:
            arch/microblaze/include/asm/Kbuild

commit 541880d9a2c7871f6370071d55aa6662d329c51e
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Nov 5 13:11:26 2012 -0500

    do_coredump(): get rid of pt_regs argument
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2e3b5d572808..e75e4bd2839b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2359,7 +2359,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 			 * first and our do_group_exit call below will use
 			 * that value and ignore the one we pass it.
 			 */
-			do_coredump(info, regs);
+			do_coredump(info);
 		}
 
 		/*

commit 4aaefee589f97bb30062bbeeb793bbbf7107a9a7
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Nov 5 13:09:56 2012 -0500

    print_fatal_signal(): get rid of pt_regs argument
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 421d5b6bcdbc..2e3b5d572808 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1159,8 +1159,9 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	return __send_signal(sig, info, t, group, from_ancestor_ns);
 }
 
-static void print_fatal_signal(struct pt_regs *regs, int signr)
+static void print_fatal_signal(int signr)
 {
+	struct pt_regs *regs = signal_pt_regs();
 	printk("%s/%d: potentially unexpected fatal signal %d.\n",
 		current->comm, task_pid_nr(current), signr);
 
@@ -2349,7 +2350,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 
 		if (sig_kernel_coredump(signr)) {
 			if (print_fatal_signals)
-				print_fatal_signal(regs, info->si_signo);
+				print_fatal_signal(info->si_signo);
 			/*
 			 * If it was able to dump core, this kills all
 			 * other threads in the group and synchronizes with

commit 94eb22d5056b5eca10c587bf064e0e6db0ae6161
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Nov 5 13:08:06 2012 -0500

    ptrace_signal(): get rid of unused arguments
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 17d4e17fd614..421d5b6bcdbc 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2138,8 +2138,7 @@ static void do_jobctl_trap(void)
 	}
 }
 
-static int ptrace_signal(int signr, siginfo_t *info,
-			 struct pt_regs *regs, void *cookie)
+static int ptrace_signal(int signr, siginfo_t *info)
 {
 	ptrace_signal_deliver();
 	/*
@@ -2265,8 +2264,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 			break; /* will return 0 */
 
 		if (unlikely(current->ptrace) && signr != SIGKILL) {
-			signr = ptrace_signal(signr, info,
-					      regs, cookie);
+			signr = ptrace_signal(signr, info);
 			if (!signr)
 				continue;
 		}

commit b7f9591c44505ee16ed4561cfeb3642798bdd132
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Nov 5 13:06:22 2012 -0500

    get rid of ptrace_signal_deliver() arguments
    
    the first one is equal to signal_pt_regs(), the second is never used
    (and always NULL, while we are at it).
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0af8868525d6..17d4e17fd614 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2141,7 +2141,7 @@ static void do_jobctl_trap(void)
 static int ptrace_signal(int signr, siginfo_t *info,
 			 struct pt_regs *regs, void *cookie)
 {
-	ptrace_signal_deliver(regs, cookie);
+	ptrace_signal_deliver();
 	/*
 	 * We do not check sig_kernel_stop(signr) but set this marker
 	 * unconditionally because we do not know whether debugger will

commit 17cf22c33e1f1b5e435469c84e43872579497653
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Mar 2 14:51:53 2010 -0800

    pidns: Use task_active_pid_ns where appropriate
    
    The expressions tsk->nsproxy->pid_ns and task_active_pid_ns
    aka ns_of_pid(task_pid(tsk)) should have the same number of
    cache line misses with the practical difference that
    ns_of_pid(task_pid(tsk)) is released later in a processes life.
    
    Furthermore by using task_active_pid_ns it becomes trivial
    to write an unshare implementation for the the pid namespace.
    
    So I have used task_active_pid_ns everywhere I can.
    
    In fork since the pid has not yet been attached to the
    process I use ns_of_pid, to achieve the same effect.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0af8868525d6..b2445d86f226 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1752,7 +1752,7 @@ static void do_notify_parent_cldstop(struct task_struct *tsk,
 	 * see comment in do_notify_parent() about the following 4 lines
 	 */
 	rcu_read_lock();
-	info.si_pid = task_pid_nr_ns(tsk, parent->nsproxy->pid_ns);
+	info.si_pid = task_pid_nr_ns(tsk, task_active_pid_ns(parent));
 	info.si_uid = from_kuid_munged(task_cred_xxx(parent, user_ns), task_uid(tsk));
 	rcu_read_unlock();
 

commit 5d8f72b55c275677865de670fa147ed318191d81
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Oct 26 19:46:06 2012 +0200

    freezer: change ptrace_stop/do_signal_stop to use freezable_schedule()
    
    try_to_freeze_tasks() and cgroup_freezer rely on scheduler locks
    to ensure that a task doing STOPPED/TRACED -> RUNNING transition
    can't escape freezing. This mostly works, but ptrace_stop() does
    not necessarily call schedule(), it can change task->state back to
    RUNNING and check freezing() without any lock/barrier in between.
    
    We could add the necessary barrier, but this patch changes
    ptrace_stop() and do_signal_stop() to use freezable_schedule().
    This fixes the race, freezer_count() and freezer_should_skip()
    carefully avoid the race.
    
    And this simplifies the code, try_to_freeze_tasks/update_if_frozen
    no longer need to use task_is_stopped_or_traced() checks with the
    non trivial assumptions. We can rely on the mechanism which was
    specially designed to mark the sleeping task as "frozen enough".
    
    v2: As Tejun pointed out, we can also change get_signal_to_deliver()
    and move try_to_freeze() up before 'relock' label.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0af8868525d6..5ffb5626e072 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1908,7 +1908,7 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 		preempt_disable();
 		read_unlock(&tasklist_lock);
 		preempt_enable_no_resched();
-		schedule();
+		freezable_schedule();
 	} else {
 		/*
 		 * By the time we got the lock, our tracer went away.
@@ -1929,13 +1929,6 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 		read_unlock(&tasklist_lock);
 	}
 
-	/*
-	 * While in TASK_TRACED, we were considered "frozen enough".
-	 * Now that we woke up, it's crucial if we're supposed to be
-	 * frozen that we freeze now before running anything substantial.
-	 */
-	try_to_freeze();
-
 	/*
 	 * We are back.  Now reacquire the siglock before touching
 	 * last_siginfo, so that we are sure to have synchronized with
@@ -2092,7 +2085,7 @@ static bool do_signal_stop(int signr)
 		}
 
 		/* Now we don't run again until woken by SIGCONT or SIGKILL */
-		schedule();
+		freezable_schedule();
 		return true;
 	} else {
 		/*
@@ -2200,15 +2193,14 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 	if (unlikely(uprobe_deny_signal()))
 		return 0;
 
-relock:
 	/*
-	 * We'll jump back here after any time we were stopped in TASK_STOPPED.
-	 * While in TASK_STOPPED, we were considered "frozen enough".
-	 * Now that we woke up, it's crucial if we're supposed to be
-	 * frozen that we freeze now before running anything substantial.
+	 * Do this once, we can't return to user-mode if freezing() == T.
+	 * do_signal_stop() and ptrace_stop() do freezable_schedule() and
+	 * thus do not need another check after return.
 	 */
 	try_to_freeze();
 
+relock:
 	spin_lock_irq(&sighand->siglock);
 	/*
 	 * Every stopped thread goes here after wakeup. Check to see if

commit 5ab1c309b344880d81494e9eab7fb27682bc6d9d
Author: Denys Vlasenko <vda.linux@googlemail.com>
Date:   Thu Oct 4 17:15:29 2012 -0700

    coredump: pass siginfo_t* to do_coredump() and below, not merely signr
    
    This is a preparatory patch for the introduction of NT_SIGINFO elf note.
    
    With this patch we pass "siginfo_t *siginfo" instead of "int signr" to
    do_coredump() and put it into coredump_params.  It will be used by the
    next patch.  Most changes are simple s/signr/siginfo->si_signo/.
    
    Signed-off-by: Denys Vlasenko <vda.linux@googlemail.com>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Amerigo Wang <amwang@redhat.com>
    Cc: "Jonathan M. Foote" <jmfoote@cert.org>
    Cc: Roland McGrath <roland@hack.frob.com>
    Cc: Pedro Alves <palves@redhat.com>
    Cc: Fengguang Wu <fengguang.wu@intel.com>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2ad3f5904bd7..0af8868525d6 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2360,7 +2360,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 			 * first and our do_group_exit call below will use
 			 * that value and ignore the one we pass it.
 			 */
-			do_coredump(info->si_signo, info->si_signo, regs);
+			do_coredump(info, regs);
 		}
 
 		/*

commit 179899fd5dc780fe3bcd44d0eb7823e3d855c855
Author: Alex Kelly <alex.page.kelly@gmail.com>
Date:   Thu Oct 4 17:15:24 2012 -0700

    coredump: update coredump-related headers
    
    Create a new header file, fs/coredump.h, which contains functions only
    used by the new coredump.c.  It also moves do_coredump to the
    include/linux/coredump.h header file, for consistency.
    
    Signed-off-by: Alex Kelly <alex.page.kelly@gmail.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2c681f11b7d2..2ad3f5904bd7 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -17,6 +17,7 @@
 #include <linux/fs.h>
 #include <linux/tty.h>
 #include <linux/binfmts.h>
+#include <linux/coredump.h>
 #include <linux/security.h>
 #include <linux/syscalls.h>
 #include <linux/ptrace.h>

commit f784e8a7989c0da3062d04bfea3db90f41e8f738
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Sun Aug 26 21:12:17 2012 +0200

    task_work: Simplify the usage in ptrace_notify() and get_signal_to_deliver()
    
    ptrace_notify() and get_signal_to_deliver() do unnecessary things
    before task_work_run():
    
    1. smp_mb__after_clear_bit() is not needed, test_and_clear_bit()
       implies mb().
    
    2. And we do not need the barrier at all, in this case we only
       care about the "synchronous" works added by the task itself.
    
    3. No need to clear TIF_NOTIFY_RESUME, and we should not assume
       task_works is the only user of this flag.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20120826191217.GA4238@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index be4f856d52f8..2c681f11b7d2 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1971,13 +1971,8 @@ static void ptrace_do_notify(int signr, int exit_code, int why)
 void ptrace_notify(int exit_code)
 {
 	BUG_ON((exit_code & (0x7f | ~0xffff)) != SIGTRAP);
-	if (unlikely(current->task_works)) {
-		if (test_and_clear_ti_thread_flag(current_thread_info(),
-						   TIF_NOTIFY_RESUME)) {
-			smp_mb__after_clear_bit();
-			task_work_run();
-		}
-	}
+	if (unlikely(current->task_works))
+		task_work_run();
 
 	spin_lock_irq(&current->sighand->siglock);
 	ptrace_do_notify(SIGTRAP, exit_code, CLD_TRAPPED);
@@ -2198,13 +2193,8 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 	struct signal_struct *signal = current->signal;
 	int signr;
 
-	if (unlikely(current->task_works)) {
-		if (test_and_clear_ti_thread_flag(current_thread_info(),
-						   TIF_NOTIFY_RESUME)) {
-			smp_mb__after_clear_bit();
-			task_work_run();
-		}
-	}
+	if (unlikely(current->task_works))
+		task_work_run();
 
 	if (unlikely(uprobe_deny_signal()))
 		return 0;

commit 7266702805f9d824f92ce5c4069eca65d0f21d28
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Jul 15 14:10:52 2012 +0400

    signal: make sure we don't get stopped with pending task_work
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 677102789cf2..be4f856d52f8 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1971,6 +1971,13 @@ static void ptrace_do_notify(int signr, int exit_code, int why)
 void ptrace_notify(int exit_code)
 {
 	BUG_ON((exit_code & (0x7f | ~0xffff)) != SIGTRAP);
+	if (unlikely(current->task_works)) {
+		if (test_and_clear_ti_thread_flag(current_thread_info(),
+						   TIF_NOTIFY_RESUME)) {
+			smp_mb__after_clear_bit();
+			task_work_run();
+		}
+	}
 
 	spin_lock_irq(&current->sighand->siglock);
 	ptrace_do_notify(SIGTRAP, exit_code, CLD_TRAPPED);
@@ -2191,6 +2198,14 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 	struct signal_struct *signal = current->signal;
 	int signr;
 
+	if (unlikely(current->task_works)) {
+		if (test_and_clear_ti_thread_flag(current_thread_info(),
+						   TIF_NOTIFY_RESUME)) {
+			smp_mb__after_clear_bit();
+			task_work_run();
+		}
+	}
+
 	if (unlikely(uprobe_deny_signal()))
 		return 0;
 

commit efee984c27b67e3ebef40410f35671997441b57c
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Apr 28 02:04:15 2012 -0400

    new helper: signal_delivered()
    
    Does block_sigmask() + tracehook_signal_handler();  called when
    sigframe has been successfully built.  All architectures converted
    to it; block_sigmask() itself is gone now (merged into this one).
    
    I'm still not too happy with the signature, but that's a separate
    story (IMO we need a structure that would contain signal number +
    siginfo + k_sigaction, so that get_signal_to_deliver() would fill one,
    signal_delivered(), handle_signal() and probably setup...frame() -
    take one).
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index df8d721a9e6f..677102789cf2 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2368,17 +2368,20 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 }
 
 /**
- * block_sigmask - add @ka's signal mask to current->blocked
- * @ka: action for @signr
- * @signr: signal that has been successfully delivered
+ * signal_delivered - 
+ * @sig:		number of signal being delivered
+ * @info:		siginfo_t of signal being delivered
+ * @ka:			sigaction setting that chose the handler
+ * @regs:		user register state
+ * @stepping:		nonzero if debugger single-step or block-step in use
  *
  * This function should be called when a signal has succesfully been
- * delivered. It adds the mask of signals for @ka to current->blocked
- * so that they are blocked during the execution of the signal
- * handler. In addition, @signr will be blocked unless %SA_NODEFER is
- * set in @ka->sa.sa_flags.
+ * delivered. It updates the blocked signals accordingly (@ka->sa.sa_mask
+ * is always blocked, and the signal itself is blocked unless %SA_NODEFER
+ * is set in @ka->sa.sa_flags.  Tracing is notified.
  */
-void block_sigmask(struct k_sigaction *ka, int signr)
+void signal_delivered(int sig, siginfo_t *info, struct k_sigaction *ka,
+			struct pt_regs *regs, int stepping)
 {
 	sigset_t blocked;
 
@@ -2390,8 +2393,9 @@ void block_sigmask(struct k_sigaction *ka, int signr)
 
 	sigorsets(&blocked, &current->blocked, &ka->sa.sa_mask);
 	if (!(ka->sa.sa_flags & SA_NODEFER))
-		sigaddset(&blocked, signr);
+		sigaddset(&blocked, sig);
 	set_current_blocked(&blocked);
+	tracehook_signal_handler(sig, info, ka, regs, stepping);
 }
 
 /*

commit 77097ae503b170120ab66dd1d547f8577193f91f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Apr 27 13:58:59 2012 -0400

    most of set_current_blocked() callers want SIGKILL/SIGSTOP removed from set
    
    Only 3 out of 63 do not.  Renamed the current variant to __set_current_blocked(),
    added set_current_blocked() that will exclude unblockable signals, switched
    open-coded instances to it.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index b9be7e0fe41a..df8d721a9e6f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2524,7 +2524,16 @@ static void __set_task_blocked(struct task_struct *tsk, const sigset_t *newset)
  * It is wrong to change ->blocked directly, this helper should be used
  * to ensure the process can't miss a shared signal we are going to block.
  */
-void set_current_blocked(const sigset_t *newset)
+void set_current_blocked(sigset_t *newset)
+{
+	struct task_struct *tsk = current;
+	sigdelsetmask(newset, sigmask(SIGKILL) | sigmask(SIGSTOP));
+	spin_lock_irq(&tsk->sighand->siglock);
+	__set_task_blocked(tsk, newset);
+	spin_unlock_irq(&tsk->sighand->siglock);
+}
+
+void __set_current_blocked(const sigset_t *newset)
 {
 	struct task_struct *tsk = current;
 
@@ -2564,7 +2573,7 @@ int sigprocmask(int how, sigset_t *set, sigset_t *oldset)
 		return -EINVAL;
 	}
 
-	set_current_blocked(&newset);
+	__set_current_blocked(&newset);
 	return 0;
 }
 
@@ -3138,7 +3147,7 @@ SYSCALL_DEFINE3(sigprocmask, int, how, old_sigset_t __user *, nset,
 			return -EINVAL;
 		}
 
-		set_current_blocked(&new_blocked);
+		__set_current_blocked(&new_blocked);
 	}
 
 	if (oset) {
@@ -3202,7 +3211,6 @@ SYSCALL_DEFINE1(ssetmask, int, newmask)
 	int old = current->blocked.sig[0];
 	sigset_t newset;
 
-	siginitset(&newset, newmask & ~(sigmask(SIGKILL) | sigmask(SIGSTOP)));
 	set_current_blocked(&newset);
 
 	return old;
@@ -3243,8 +3251,6 @@ SYSCALL_DEFINE0(pause)
 
 int sigsuspend(sigset_t *set)
 {
-	sigdelsetmask(set, sigmask(SIGKILL)|sigmask(SIGSTOP));
-
 	current->saved_sigmask = current->blocked;
 	set_current_blocked(set);
 

commit a610d6e672d6d3723e8da257ad4a8a288a8f2f89
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon May 21 23:42:15 2012 -0400

    pull clearing RESTORE_SIGMASK into block_sigmask()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 95a9d9d8122b..b9be7e0fe41a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2382,6 +2382,12 @@ void block_sigmask(struct k_sigaction *ka, int signr)
 {
 	sigset_t blocked;
 
+	/* A signal was successfully delivered, and the
+	   saved sigmask was stored on the signal frame,
+	   and will be restored by sigreturn.  So we can
+	   simply clear the restore sigmask flag.  */
+	clear_restore_sigmask();
+
 	sigorsets(&blocked, &current->blocked, &ka->sa.sa_mask);
 	if (!(ka->sa.sa_flags & SA_NODEFER))
 		sigaddset(&blocked, signr);

commit 754421c8cab1a568be844a7069fe04c1cf6391b8
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Apr 26 18:31:00 2012 -0400

    HAVE_RESTORE_SIGMASK is defined on all architectures now
    
    Everyone either defines it in arch thread_info.h or has TIF_RESTORE_SIGMASK
    and picks default set_restore_sigmask() in linux/thread_info.h.  Kill the
    ifdefs, slap #error in linux/thread_info.h to catch breakage when new ones
    get merged.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 08dfbd748cd2..95a9d9d8122b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3235,7 +3235,6 @@ SYSCALL_DEFINE0(pause)
 
 #endif
 
-#ifdef HAVE_SET_RESTORE_SIGMASK
 int sigsuspend(sigset_t *set)
 {
 	sigdelsetmask(set, sigmask(SIGKILL)|sigmask(SIGSTOP));
@@ -3248,7 +3247,6 @@ int sigsuspend(sigset_t *set)
 	set_restore_sigmask();
 	return -ERESTARTNOHAND;
 }
-#endif
 
 #ifdef __ARCH_WANT_SYS_RT_SIGSUSPEND
 /**

commit 3208450488ae724196f1efffc457e4265957c04e
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu May 31 16:26:39 2012 -0700

    pidns: use task_active_pid_ns in do_notify_parent
    
    Using task_active_pid_ns is more robust because it works even after we
    have called exit_namespaces.  This change allows us to have parent
    processes that are zombies.  Normally a zombie parent processes is crazy
    and the last thing you would want to have but in the case of not letting
    the init process of a pid namespace be reaped until all of it's children
    are dead and reaped a zombie parent process is exactly what we want.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Pavel Emelyanov <xemul@parallels.com>
    Cc: Cyrill Gorcunov <gorcunov@openvz.org>
    Cc: Louis Rilling <louis.rilling@kerlabs.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index f7b418217633..08dfbd748cd2 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1656,19 +1656,18 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 	info.si_signo = sig;
 	info.si_errno = 0;
 	/*
-	 * we are under tasklist_lock here so our parent is tied to
-	 * us and cannot exit and release its namespace.
+	 * We are under tasklist_lock here so our parent is tied to
+	 * us and cannot change.
 	 *
-	 * the only it can is to switch its nsproxy with sys_unshare,
-	 * bu uncharing pid namespaces is not allowed, so we'll always
-	 * see relevant namespace
+	 * task_active_pid_ns will always return the same pid namespace
+	 * until a task passes through release_task.
 	 *
 	 * write_lock() currently calls preempt_disable() which is the
 	 * same as rcu_read_lock(), but according to Oleg, this is not
 	 * correct to rely on this
 	 */
 	rcu_read_lock();
-	info.si_pid = task_pid_nr_ns(tsk, tsk->parent->nsproxy->pid_ns);
+	info.si_pid = task_pid_nr_ns(tsk, task_active_pid_ns(tsk->parent));
 	info.si_uid = from_kuid_munged(task_cred_xxx(tsk->parent, user_ns),
 				       task_uid(tsk));
 	rcu_read_unlock();

commit 654443e20dfc0617231f28a07c96a979ee1a0239
Merge: 2c01e7bc46f1 9cba26e66d09
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu May 24 11:39:34 2012 -0700

    Merge branch 'perf-uprobes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull user-space probe instrumentation from Ingo Molnar:
     "The uprobes code originates from SystemTap and has been used for years
      in Fedora and RHEL kernels.  This version is much rewritten, reviews
      from PeterZ, Oleg and myself shaped the end result.
    
      This tree includes uprobes support in 'perf probe' - but SystemTap
      (and other tools) can take advantage of user probe points as well.
    
      Sample usage of uprobes via perf, for example to profile malloc()
      calls without modifying user-space binaries.
    
      First boot a new kernel with CONFIG_UPROBE_EVENT=y enabled.
    
      If you don't know which function you want to probe you can pick one
      from 'perf top' or can get a list all functions that can be probed
      within libc (binaries can be specified as well):
    
            $ perf probe -F -x /lib/libc.so.6
    
      To probe libc's malloc():
    
            $ perf probe -x /lib64/libc.so.6 malloc
            Added new event:
            probe_libc:malloc    (on 0x7eac0)
    
      You can now use it in all perf tools, such as:
    
            perf record -e probe_libc:malloc -aR sleep 1
    
      Make use of it to create a call graph (as the flat profile is going to
      look very boring):
    
            $ perf record -e probe_libc:malloc -gR make
            [ perf record: Woken up 173 times to write data ]
            [ perf record: Captured and wrote 44.190 MB perf.data (~1930712
    
            $ perf report | less
    
              32.03%            git  libc-2.15.so   [.] malloc
                                |
                                --- malloc
    
              29.49%            cc1  libc-2.15.so   [.] malloc
                                |
                                --- malloc
                                   |
                                   |--0.95%-- 0x208eb1000000000
                                   |
                                   |--0.63%-- htab_traverse_noresize
    
              11.04%             as  libc-2.15.so   [.] malloc
                                 |
                                 --- malloc
                                    |
    
               7.15%             ld  libc-2.15.so   [.] malloc
                                 |
                                 --- malloc
                                    |
    
               5.07%             sh  libc-2.15.so   [.] malloc
                                 |
                                 --- malloc
                                    |
               4.99%  python-config  libc-2.15.so   [.] malloc
                      |
                      --- malloc
                         |
               4.54%           make  libc-2.15.so   [.] malloc
                               |
                               --- malloc
                                  |
                                  |--7.34%-- glob
                                  |          |
                                  |          |--93.18%-- 0x41588f
                                  |          |
                                  |           --6.82%-- glob
                                  |                     0x41588f
    
               ...
    
      Or:
    
            $ perf report -g flat | less
    
            # Overhead        Command  Shared Object      Symbol
            # ........  .............  .............  ..........
            #
              32.03%            git  libc-2.15.so   [.] malloc
                      27.19%
                          malloc
    
              29.49%            cc1  libc-2.15.so   [.] malloc
                      24.77%
                          malloc
    
              11.04%             as  libc-2.15.so   [.] malloc
                      11.02%
                          malloc
    
               7.15%             ld  libc-2.15.so   [.] malloc
                       6.57%
                          malloc
    
             ...
    
      The core uprobes design is fairly straightforward: uprobes probe
      points register themselves at (inode:offset) addresses of
      libraries/binaries, after which all existing (or new) vmas that map
      that address will have a software breakpoint injected at that address.
      vmas are COW-ed to preserve original content.  The probe points are
      kept in an rbtree.
    
      If user-space executes the probed inode:offset instruction address
      then an event is generated which can be recovered from the regular
      perf event channels and mmap-ed ring-buffer.
    
      Multiple probes at the same address are supported, they create a
      dynamic callback list of event consumers.
    
      The basic model is further complicated by the XOL speedup: the
      original instruction that is probed is copied (in an architecture
      specific fashion) and executed out of line when the probe triggers.
      The XOL area is a single vma per process, with a fixed number of
      entries (which limits probe execution parallelism).
    
      The API: uprobes are installed/removed via
      /sys/kernel/debug/tracing/uprobe_events, the API is integrated to
      align with the kprobes interface as much as possible, but is separate
      to it.
    
      Injecting a probe point is privileged operation, which can be relaxed
      by setting perf_paranoid to -1.
    
      You can use multiple probes as well and mix them with kprobes and
      regular PMU events or tracepoints, when instrumenting a task."
    
    Fix up trivial conflicts in mm/memory.c due to previous cleanup of
    unmap_single_vma().
    
    * 'perf-uprobes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (21 commits)
      perf probe: Detect probe target when m/x options are absent
      perf probe: Provide perf interface for uprobes
      tracing: Fix kconfig warning due to a typo
      tracing: Provide trace events interface for uprobes
      tracing: Extract out common code for kprobes/uprobes trace events
      tracing: Modify is_delete, is_return from int to bool
      uprobes/core: Decrement uprobe count before the pages are unmapped
      uprobes/core: Make background page replacement logic account for rss_stat counters
      uprobes/core: Optimize probe hits with the help of a counter
      uprobes/core: Allocate XOL slots for uprobes use
      uprobes/core: Handle breakpoint and singlestep exceptions
      uprobes/core: Rename bkpt to swbp
      uprobes/core: Make order of function parameters consistent across functions
      uprobes/core: Make macro names consistent
      uprobes: Update copyright notices
      uprobes/core: Move insn to arch specific structure
      uprobes/core: Remove uprobe_opcode_sz
      uprobes/core: Make instruction tables volatile
      uprobes: Move to kernel/events/
      uprobes/core: Clean up, refactor and improve the code
      ...

commit f9369910a6225b8d4892c3f20ae740a711cd5ace
Merge: 05f144a0d5c2 415d04d08fec
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 23 18:11:45 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal
    
    Pull first series of signal handling cleanups from Al Viro:
     "This is just the first part of the queue (about a half of it);
      assorted fixes all over the place in signal handling.
    
      This one ends with all sigsuspend() implementations switched to
      generic one (->saved_sigmask-based).
    
      With this, a bunch of assorted old buglets are fixed and most of the
      missing bits of NOTIFY_RESUME hookup are in place.  Two more fixes sit
      in arm and um trees respectively, and there's a couple of broken ones
      that need obvious fixes - parisc and avr32 check TIF_NOTIFY_RESUME
      only on one of two codepaths; fixes for that will happen in the next
      series"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal: (55 commits)
      unicore32: if there's no handler we need to restore sigmask, syscall or no syscall
      xtensa: add handling of TIF_NOTIFY_RESUME
      microblaze: drop 'oldset' argument of do_notify_resume()
      microblaze: handle TIF_NOTIFY_RESUME
      score: add handling of NOTIFY_RESUME to do_notify_resume()
      m68k: add TIF_NOTIFY_RESUME and handle it.
      sparc: kill ancient comment in sparc_sigaction()
      h8300: missing checks of __get_user()/__put_user() return values
      frv: missing checks of __get_user()/__put_user() return values
      cris: missing checks of __get_user()/__put_user() return values
      powerpc: missing checks of __get_user()/__put_user() return values
      sh: missing checks of __get_user()/__put_user() return values
      sparc: missing checks of __get_user()/__put_user() return values
      avr32: struct old_sigaction is never used
      m32r: struct old_sigaction is never used
      xtensa: xtensa_sigaction doesn't exist
      alpha: tidy signal delivery up
      score: don't open-code force_sigsegv()
      cris: don't open-code force_sigsegv()
      blackfin: don't open-code force_sigsegv()
      ...

commit 644473e9c60c1ff4f6351fed637a6e5551e3dce7
Merge: fb827ec68446 4b06a81f1dae
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 23 17:42:39 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull user namespace enhancements from Eric Biederman:
     "This is a course correction for the user namespace, so that we can
      reach an inexpensive, maintainable, and reasonably complete
      implementation.
    
      Highlights:
       - Config guards make it impossible to enable the user namespace and
         code that has not been converted to be user namespace safe.
    
       - Use of the new kuid_t type ensures the if you somehow get past the
         config guards the kernel will encounter type errors if you enable
         user namespaces and attempt to compile in code whose permission
         checks have not been updated to be user namespace safe.
    
       - All uids from child user namespaces are mapped into the initial
         user namespace before they are processed.  Removing the need to add
         an additional check to see if the user namespace of the compared
         uids remains the same.
    
       - With the user namespaces compiled out the performance is as good or
         better than it is today.
    
       - For most operations absolutely nothing changes performance or
         operationally with the user namespace enabled.
    
       - The worst case performance I could come up with was timing 1
         billion cache cold stat operations with the user namespace code
         enabled.  This went from 156s to 164s on my laptop (or 156ns to
         164ns per stat operation).
    
       - (uid_t)-1 and (gid_t)-1 are reserved as an internal error value.
         Most uid/gid setting system calls treat these value specially
         anyway so attempting to use -1 as a uid would likely cause
         entertaining failures in userspace.
    
       - If setuid is called with a uid that can not be mapped setuid fails.
         I have looked at sendmail, login, ssh and every other program I
         could think of that would call setuid and they all check for and
         handle the case where setuid fails.
    
       - If stat or a similar system call is called from a context in which
         we can not map a uid we lie and return overflowuid.  The LFS
         experience suggests not lying and returning an error code might be
         better, but the historical precedent with uids is different and I
         can not think of anything that would break by lying about a uid we
         can't map.
    
       - Capabilities are localized to the current user namespace making it
         safe to give the initial user in a user namespace all capabilities.
    
      My git tree covers all of the modifications needed to convert the core
      kernel and enough changes to make a system bootable to runlevel 1."
    
    Fix up trivial conflicts due to nearby independent changes in fs/stat.c
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (46 commits)
      userns:  Silence silly gcc warning.
      cred: use correct cred accessor with regards to rcu read lock
      userns: Convert the move_pages, and migrate_pages permission checks to use uid_eq
      userns: Convert cgroup permission checks to use uid_eq
      userns: Convert tmpfs to use kuid and kgid where appropriate
      userns: Convert sysfs to use kgid/kuid where appropriate
      userns: Convert sysctl permission checks to use kuid and kgids.
      userns: Convert proc to use kuid/kgid where appropriate
      userns: Convert ext4 to user kuid/kgid where appropriate
      userns: Convert ext3 to use kuid/kgid where appropriate
      userns: Convert ext2 to use kuid/kgid where appropriate.
      userns: Convert devpts to use kuid/kgid where appropriate
      userns: Convert binary formats to use kuid/kgid where appropriate
      userns: Add negative depends on entries to avoid building code that is userns unsafe
      userns: signal remove unnecessary map_cred_ns
      userns: Teach inode_capable to understand inodes whose uids map to other namespaces.
      userns: Fail exec for suid and sgid binaries with ids outside our user namespace.
      userns: Convert stat to return values mapped from kuids and kgids
      userns: Convert user specfied uids and gids in chown into kuids and kgid
      userns: Use uid_eq gid_eq helpers when comparing kuids and kgids in the vfs
      ...

commit 68f3f16d9ad0f1e28ab3fd0001ab5798c41f15a3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon May 21 21:42:32 2012 -0400

    new helper: sigsuspend()
    
    guts of saved_sigmask-based sigsuspend/rt_sigsuspend.  Takes
    kernel sigset_t *.
    
    Open-coded instances replaced with calling it.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 17afcaf582d0..3ad220a81619 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3236,6 +3236,21 @@ SYSCALL_DEFINE0(pause)
 
 #endif
 
+#ifdef HAVE_SET_RESTORE_SIGMASK
+int sigsuspend(sigset_t *set)
+{
+	sigdelsetmask(set, sigmask(SIGKILL)|sigmask(SIGSTOP));
+
+	current->saved_sigmask = current->blocked;
+	set_current_blocked(set);
+
+	current->state = TASK_INTERRUPTIBLE;
+	schedule();
+	set_restore_sigmask();
+	return -ERESTARTNOHAND;
+}
+#endif
+
 #ifdef __ARCH_WANT_SYS_RT_SIGSUSPEND
 /**
  *  sys_rt_sigsuspend - replace the signal mask for a value with the
@@ -3253,15 +3268,7 @@ SYSCALL_DEFINE2(rt_sigsuspend, sigset_t __user *, unewset, size_t, sigsetsize)
 
 	if (copy_from_user(&newset, unewset, sizeof(newset)))
 		return -EFAULT;
-	sigdelsetmask(&newset, sigmask(SIGKILL)|sigmask(SIGSTOP));
-
-	current->saved_sigmask = current->blocked;
-	set_current_blocked(&newset);
-
-	current->state = TASK_INTERRUPTIBLE;
-	schedule();
-	set_restore_sigmask();
-	return -ERESTARTNOHAND;
+	return sigsuspend(&newset);
 }
 #endif /* __ARCH_WANT_SYS_RT_SIGSUSPEND */
 

commit 54ba47edac90091d42e5f97516cad56953576a5a
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Mar 13 16:04:35 2012 -0700

    userns: signal remove unnecessary map_cred_ns
    
    map_cred_ns is a light wrapper around from_kuid with the order of the arguments
    reversed.  Replace map_cred_ns with from_kuid and remove map_cred_ns.
    
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index aef629c65c87..833ea5166855 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1019,15 +1019,6 @@ static inline int legacy_queue(struct sigpending *signals, int sig)
 	return (sig < SIGRTMIN) && sigismember(&signals->signal, sig);
 }
 
-/*
- * map the uid in struct cred into user namespace *ns
- */
-static inline uid_t map_cred_ns(const struct cred *cred,
-				struct user_namespace *ns)
-{
-	return from_kuid_munged(ns, cred->uid);
-}
-
 #ifdef CONFIG_USER_NS
 static inline void userns_fixup_signal_uid(struct siginfo *info, struct task_struct *t)
 {
@@ -1677,8 +1668,8 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 	 */
 	rcu_read_lock();
 	info.si_pid = task_pid_nr_ns(tsk, tsk->parent->nsproxy->pid_ns);
-	info.si_uid = map_cred_ns(__task_cred(tsk),
-			task_cred_xxx(tsk->parent, user_ns));
+	info.si_uid = from_kuid_munged(task_cred_xxx(tsk->parent, user_ns),
+				       task_uid(tsk));
 	rcu_read_unlock();
 
 	info.si_utime = cputime_to_clock_t(tsk->utime + tsk->signal->utime);
@@ -1761,8 +1752,7 @@ static void do_notify_parent_cldstop(struct task_struct *tsk,
 	 */
 	rcu_read_lock();
 	info.si_pid = task_pid_nr_ns(tsk, parent->nsproxy->pid_ns);
-	info.si_uid = map_cred_ns(__task_cred(tsk),
-			task_cred_xxx(parent, user_ns));
+	info.si_uid = from_kuid_munged(task_cred_xxx(parent, user_ns), task_uid(tsk));
 	rcu_read_unlock();
 
 	info.si_utime = cputime_to_clock_t(tsk->utime);
@@ -2180,8 +2170,8 @@ static int ptrace_signal(int signr, siginfo_t *info,
 		info->si_code = SI_USER;
 		rcu_read_lock();
 		info->si_pid = task_pid_vnr(current->parent);
-		info->si_uid = map_cred_ns(__task_cred(current->parent),
-				current_user_ns());
+		info->si_uid = from_kuid_munged(current_user_ns(),
+						task_uid(current->parent));
 		rcu_read_unlock();
 	}
 

commit 5af662030e5db1a5560fd917250d5d688a6be586
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Mar 3 20:21:47 2012 -0800

    userns: Convert ptrace, kill, set_priority permission checks to work with kuids and kgids
    
    Update the permission checks to use the new uid_eq and gid_eq helpers
    and remove the now unnecessary user_ns equality comparison.
    
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index d6303277a640..aef629c65c87 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -767,11 +767,10 @@ static int kill_ok_by_cred(struct task_struct *t)
 	const struct cred *cred = current_cred();
 	const struct cred *tcred = __task_cred(t);
 
-	if (cred->user_ns == tcred->user_ns &&
-	    (cred->euid == tcred->suid ||
-	     cred->euid == tcred->uid ||
-	     cred->uid  == tcred->suid ||
-	     cred->uid  == tcred->uid))
+	if (uid_eq(cred->euid, tcred->suid) ||
+	    uid_eq(cred->euid, tcred->uid)  ||
+	    uid_eq(cred->uid,  tcred->suid) ||
+	    uid_eq(cred->uid,  tcred->uid))
 		return 1;
 
 	if (ns_capable(tcred->user_ns, CAP_KILL))
@@ -1389,10 +1388,8 @@ static int kill_as_cred_perm(const struct cred *cred,
 			     struct task_struct *target)
 {
 	const struct cred *pcred = __task_cred(target);
-	if (cred->user_ns != pcred->user_ns)
-		return 0;
-	if (cred->euid != pcred->suid && cred->euid != pcred->uid &&
-	    cred->uid  != pcred->suid && cred->uid  != pcred->uid)
+	if (!uid_eq(cred->euid, pcred->suid) && !uid_eq(cred->euid, pcred->uid) &&
+	    !uid_eq(cred->uid,  pcred->suid) && !uid_eq(cred->uid,  pcred->uid))
 		return 0;
 	return 1;
 }

commit 76b6db010297d4928ab7b7e7c78dd982f413f0a4
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Mar 14 15:24:19 2012 -0700

    userns: Replace user_ns_map_uid and user_ns_map_gid with from_kuid and from_kgid
    
    These function are no longer needed replace them with their more useful equivalents.
    
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2734dc965f69..d6303277a640 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1026,7 +1026,7 @@ static inline int legacy_queue(struct sigpending *signals, int sig)
 static inline uid_t map_cred_ns(const struct cred *cred,
 				struct user_namespace *ns)
 {
-	return user_ns_map_uid(ns, cred, cred->uid);
+	return from_kuid_munged(ns, cred->uid);
 }
 
 #ifdef CONFIG_USER_NS

commit 078de5f706ece36afd73bb4b8283314132d2dfdf
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Feb 8 07:00:08 2012 -0800

    userns: Store uid and gid values in struct cred with kuid_t and kgid_t types
    
    cred.h and a few trivial users of struct cred are changed.  The rest of the users
    of struct cred are left for other patches as there are too many changes to make
    in one go and leave the change reviewable.  If the user namespace is disabled and
    CONFIG_UIDGID_STRICT_TYPE_CHECKS are disabled the code will contiue to compile
    and behave correctly.
    
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index e2c5d84f2dac..2734dc965f69 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1038,8 +1038,10 @@ static inline void userns_fixup_signal_uid(struct siginfo *info, struct task_str
 	if (SI_FROMKERNEL(info))
 		return;
 
-	info->si_uid = user_ns_map_uid(task_cred_xxx(t, user_ns),
-					current_cred(), info->si_uid);
+	rcu_read_lock();
+	info->si_uid = from_kuid_munged(task_cred_xxx(t, user_ns),
+					make_kuid(current_user_ns(), info->si_uid));
+	rcu_read_unlock();
 }
 #else
 static inline void userns_fixup_signal_uid(struct siginfo *info, struct task_struct *t)
@@ -1106,7 +1108,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			q->info.si_code = SI_USER;
 			q->info.si_pid = task_tgid_nr_ns(current,
 							task_active_pid_ns(t));
-			q->info.si_uid = current_uid();
+			q->info.si_uid = from_kuid_munged(current_user_ns(), current_uid());
 			break;
 		case (unsigned long) SEND_SIG_PRIV:
 			q->info.si_signo = sig;
@@ -1973,7 +1975,7 @@ static void ptrace_do_notify(int signr, int exit_code, int why)
 	info.si_signo = signr;
 	info.si_code = exit_code;
 	info.si_pid = task_pid_vnr(current);
-	info.si_uid = current_uid();
+	info.si_uid = from_kuid_munged(current_user_ns(), current_uid());
 
 	/* Let the debugger run.  */
 	ptrace_stop(exit_code, why, 1, &info);
@@ -2828,7 +2830,7 @@ SYSCALL_DEFINE2(kill, pid_t, pid, int, sig)
 	info.si_errno = 0;
 	info.si_code = SI_USER;
 	info.si_pid = task_tgid_vnr(current);
-	info.si_uid = current_uid();
+	info.si_uid = from_kuid_munged(current_user_ns(), current_uid());
 
 	return kill_something_info(sig, &info, pid);
 }
@@ -2871,7 +2873,7 @@ static int do_tkill(pid_t tgid, pid_t pid, int sig)
 	info.si_errno = 0;
 	info.si_code = SI_TKILL;
 	info.si_pid = task_tgid_vnr(current);
-	info.si_uid = current_uid();
+	info.si_uid = from_kuid_munged(current_user_ns(), current_uid());
 
 	return do_send_specific(tgid, pid, sig, &info);
 }

commit 6ac1ef482d7ae0c690f1640bf6eb818ff9a2d91e
Merge: 682968e0c425 a385ec4f11bd
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Apr 14 13:18:27 2012 +0200

    Merge branch 'perf/core' into perf/uprobes
    
    Merge in latest upstream (and the latest perf development tree),
    to prepare for tooling changes, and also to pick up v3.4 MM
    changes that the uprobes code needs to take care of.
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit a0727e8ce513fe6890416da960181ceb10fbfae6
Author: Will Drewry <wad@chromium.org>
Date:   Thu Apr 12 16:48:00 2012 -0500

    signal, x86: add SIGSYS info and make it synchronous.
    
    This change enables SIGSYS, defines _sigfields._sigsys, and adds
    x86 (compat) arch support.  _sigsys defines fields which allow
    a signal handler to receive the triggering system call number,
    the relevant AUDIT_ARCH_* value for that number, and the address
    of the callsite.
    
    SIGSYS is added to the SYNCHRONOUS_MASK because it is desirable for it
    to have setup_frame() called for it. The goal is to ensure that
    ucontext_t reflects the machine state from the time-of-syscall and not
    from another signal handler.
    
    The first consumer of SIGSYS would be seccomp filter.  In particular,
    a filter program could specify a new return value, SECCOMP_RET_TRAP,
    which would result in the system call being denied and the calling
    thread signaled.  This also means that implementing arch-specific
    support can be dependent upon HAVE_ARCH_SECCOMP_FILTER.
    
    Suggested-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Will Drewry <wad@chromium.org>
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Reviewed-by: H. Peter Anvin <hpa@zytor.com>
    Acked-by: Eric Paris <eparis@redhat.com>
    
    v18: - added acked by, rebase
    v17: - rebase and reviewed-by addition
    v14: - rebase/nochanges
    v13: - rebase on to 88ebdda6159ffc15699f204c33feb3e431bf9bdc
    v12: - reworded changelog (oleg@redhat.com)
    v11: - fix dropped words in the change description
         - added fallback copy_siginfo support.
         - added __ARCH_SIGSYS define to allow stepped arch support.
    v10: - first version based on suggestion
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 17afcaf582d0..1a006b5d9d9d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -160,7 +160,7 @@ void recalc_sigpending(void)
 
 #define SYNCHRONOUS_MASK \
 	(sigmask(SIGSEGV) | sigmask(SIGBUS) | sigmask(SIGILL) | \
-	 sigmask(SIGTRAP) | sigmask(SIGFPE))
+	 sigmask(SIGTRAP) | sigmask(SIGFPE) | sigmask(SIGSYS))
 
 int next_signal(struct sigpending *pending, sigset_t *mask)
 {
@@ -2706,6 +2706,13 @@ int copy_siginfo_to_user(siginfo_t __user *to, siginfo_t *from)
 		err |= __put_user(from->si_uid, &to->si_uid);
 		err |= __put_user(from->si_ptr, &to->si_ptr);
 		break;
+#ifdef __ARCH_SIGSYS
+	case __SI_SYS:
+		err |= __put_user(from->si_call_addr, &to->si_call_addr);
+		err |= __put_user(from->si_syscall, &to->si_syscall);
+		err |= __put_user(from->si_arch, &to->si_arch);
+		break;
+#endif
 	default: /* this is just in case for now ... */
 		err |= __put_user(from->si_pid, &to->si_pid);
 		err |= __put_user(from->si_uid, &to->si_uid);

commit c4a4d603796c727b9555867571f89483be9c565e
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Nov 16 23:15:31 2011 -0800

    userns: Use cred->user_ns instead of cred->user->user_ns
    
    Optimize performance and prepare for the removal of the user_ns reference
    from user_struct.  Remove the slow long walk through cred->user->user_ns and
    instead go straight to cred->user_ns.
    
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 17afcaf582d0..e2c5d84f2dac 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -767,14 +767,14 @@ static int kill_ok_by_cred(struct task_struct *t)
 	const struct cred *cred = current_cred();
 	const struct cred *tcred = __task_cred(t);
 
-	if (cred->user->user_ns == tcred->user->user_ns &&
+	if (cred->user_ns == tcred->user_ns &&
 	    (cred->euid == tcred->suid ||
 	     cred->euid == tcred->uid ||
 	     cred->uid  == tcred->suid ||
 	     cred->uid  == tcred->uid))
 		return 1;
 
-	if (ns_capable(tcred->user->user_ns, CAP_KILL))
+	if (ns_capable(tcred->user_ns, CAP_KILL))
 		return 1;
 
 	return 0;

commit 0195c00244dc2e9f522475868fa278c473ba7339
Merge: f21ce8f8447c 141124c02059
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 28 15:58:21 2012 -0700

    Merge tag 'split-asm_system_h-for-linus-20120328' of git://git.kernel.org/pub/scm/linux/kernel/git/dhowells/linux-asm_system
    
    Pull "Disintegrate and delete asm/system.h" from David Howells:
     "Here are a bunch of patches to disintegrate asm/system.h into a set of
      separate bits to relieve the problem of circular inclusion
      dependencies.
    
      I've built all the working defconfigs from all the arches that I can
      and made sure that they don't break.
    
      The reason for these patches is that I recently encountered a circular
      dependency problem that came about when I produced some patches to
      optimise get_order() by rewriting it to use ilog2().
    
      This uses bitops - and on the SH arch asm/bitops.h drags in
      asm-generic/get_order.h by a circuituous route involving asm/system.h.
    
      The main difficulty seems to be asm/system.h.  It holds a number of
      low level bits with no/few dependencies that are commonly used (eg.
      memory barriers) and a number of bits with more dependencies that
      aren't used in many places (eg.  switch_to()).
    
      These patches break asm/system.h up into the following core pieces:
    
        (1) asm/barrier.h
    
            Move memory barriers here.  This already done for MIPS and Alpha.
    
        (2) asm/switch_to.h
    
            Move switch_to() and related stuff here.
    
        (3) asm/exec.h
    
            Move arch_align_stack() here.  Other process execution related bits
            could perhaps go here from asm/processor.h.
    
        (4) asm/cmpxchg.h
    
            Move xchg() and cmpxchg() here as they're full word atomic ops and
            frequently used by atomic_xchg() and atomic_cmpxchg().
    
        (5) asm/bug.h
    
            Move die() and related bits.
    
        (6) asm/auxvec.h
    
            Move AT_VECTOR_SIZE_ARCH here.
    
      Other arch headers are created as needed on a per-arch basis."
    
    Fixed up some conflicts from other header file cleanups and moving code
    around that has happened in the meantime, so David's testing is somewhat
    weakened by that.  We'll find out anything that got broken and fix it..
    
    * tag 'split-asm_system_h-for-linus-20120328' of git://git.kernel.org/pub/scm/linux/kernel/git/dhowells/linux-asm_system: (38 commits)
      Delete all instances of asm/system.h
      Remove all #inclusions of asm/system.h
      Add #includes needed to permit the removal of asm/system.h
      Move all declarations of free_initmem() to linux/mm.h
      Disintegrate asm/system.h for OpenRISC
      Split arch_align_stack() out from asm-generic/system.h
      Split the switch_to() wrapper out of asm-generic/system.h
      Move the asm-generic/system.h xchg() implementation to asm-generic/cmpxchg.h
      Create asm-generic/barrier.h
      Make asm-generic/cmpxchg.h #include asm-generic/cmpxchg-local.h
      Disintegrate asm/system.h for Xtensa
      Disintegrate asm/system.h for Unicore32 [based on ver #3, changed by gxt]
      Disintegrate asm/system.h for Tile
      Disintegrate asm/system.h for Sparc
      Disintegrate asm/system.h for SH
      Disintegrate asm/system.h for Score
      Disintegrate asm/system.h for S390
      Disintegrate asm/system.h for PowerPC
      Disintegrate asm/system.h for PA-RISC
      Disintegrate asm/system.h for MN10300
      ...

commit d550bbd40c0e10aefa05103dadbe0ae42e683707
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:30:03 2012 +0100

    Disintegrate asm/system.h for Sparc
    
    Disintegrate asm/system.h for Sparc.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    cc: sparclinux@vger.kernel.org

diff --git a/kernel/signal.c b/kernel/signal.c
index e76001ccf5cd..5120f1901f36 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -36,6 +36,7 @@
 #include <asm/uaccess.h>
 #include <asm/unistd.h>
 #include <asm/siginfo.h>
+#include <asm/cacheflush.h>
 #include "audit.h"	/* audit_signal_info() */
 
 /*

commit def8cf72562e17ec8316ce0cb5697c7afd6400e3
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Mar 23 15:02:45 2012 -0700

    signal: cosmetic, s/from_ancestor_ns/force/ in prepare_signal() paths
    
    Cosmetic, rename the from_ancestor_ns argument in prepare_signal()
    paths.  After the previous change it doesn't match the reality.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Anton Vorontsov <anton.vorontsov@linaro.org>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: KOSAKI Motohiro <kosaki.motohiro@gmail.com>
    Cc: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2584f5a91fbe..d523da02dd14 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -58,21 +58,20 @@ static int sig_handler_ignored(void __user *handler, int sig)
 		(handler == SIG_DFL && sig_kernel_ignore(sig));
 }
 
-static int sig_task_ignored(struct task_struct *t, int sig,
-		int from_ancestor_ns)
+static int sig_task_ignored(struct task_struct *t, int sig, bool force)
 {
 	void __user *handler;
 
 	handler = sig_handler(t, sig);
 
 	if (unlikely(t->signal->flags & SIGNAL_UNKILLABLE) &&
-			handler == SIG_DFL && !from_ancestor_ns)
+			handler == SIG_DFL && !force)
 		return 1;
 
 	return sig_handler_ignored(handler, sig);
 }
 
-static int sig_ignored(struct task_struct *t, int sig, int from_ancestor_ns)
+static int sig_ignored(struct task_struct *t, int sig, bool force)
 {
 	/*
 	 * Blocked signals are never ignored, since the
@@ -82,7 +81,7 @@ static int sig_ignored(struct task_struct *t, int sig, int from_ancestor_ns)
 	if (sigismember(&t->blocked, sig) || sigismember(&t->real_blocked, sig))
 		return 0;
 
-	if (!sig_task_ignored(t, sig, from_ancestor_ns))
+	if (!sig_task_ignored(t, sig, force))
 		return 0;
 
 	/*
@@ -855,7 +854,7 @@ static void ptrace_trap_notify(struct task_struct *t)
  * Returns true if the signal should be actually delivered, otherwise
  * it should be dropped.
  */
-static int prepare_signal(int sig, struct task_struct *p, int from_ancestor_ns)
+static int prepare_signal(int sig, struct task_struct *p, bool force)
 {
 	struct signal_struct *signal = p->signal;
 	struct task_struct *t;
@@ -915,7 +914,7 @@ static int prepare_signal(int sig, struct task_struct *p, int from_ancestor_ns)
 		}
 	}
 
-	return !sig_ignored(p, sig, from_ancestor_ns);
+	return !sig_ignored(p, sig, force);
 }
 
 /*
@@ -1602,7 +1601,7 @@ int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)
 
 	ret = 1; /* the signal is ignored */
 	result = TRACE_SIGNAL_IGNORED;
-	if (!prepare_signal(sig, t, 0))
+	if (!prepare_signal(sig, t, false))
 		goto out;
 
 	ret = 0;

commit 629d362b9950166c6fac2aa8425db34d824bb043
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Mar 23 15:02:44 2012 -0700

    signal: give SEND_SIG_FORCED more power to beat SIGNAL_UNKILLABLE
    
    force_sig_info() and friends have the special semantics for synchronous
    signals, this interface should not be used if the target is not current.
    And it needs the fixes, in particular the clearing of SIGNAL_UNKILLABLE
    is not exactly right.
    
    However there are callers which have to use force_ exactly because it
    clears SIGNAL_UNKILLABLE and thus it can kill the CLONE_NEWPID tasks,
    although this is almost always is wrong by various reasons.
    
    With this patch SEND_SIG_FORCED ignores SIGNAL_UNKILLABLE, like we do if
    the signal comes from the ancestor namespace.
    
    This makes the naming in prepare_signal() paths insane, fixed by the
    next cleanup.
    
    Note: this only affects SIGKILL/SIGSTOP, but this is enough for
    force_sig() abusers.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Anton Vorontsov <anton.vorontsov@linaro.org>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: KOSAKI Motohiro <kosaki.motohiro@gmail.com>
    Cc: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index e76001ccf5cd..2584f5a91fbe 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1059,7 +1059,8 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	assert_spin_locked(&t->sighand->siglock);
 
 	result = TRACE_SIGNAL_IGNORED;
-	if (!prepare_signal(sig, t, from_ancestor_ns))
+	if (!prepare_signal(sig, t,
+			from_ancestor_ns || (info == SEND_SIG_FORCED)))
 		goto ret;
 
 	pending = group ? &t->signal->shared_pending : &t->pending;

commit b6e238dceed36891cc633167afe7151f1f3d83c5
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Mon Mar 19 17:03:41 2012 +0100

    exit_signal: fix the "parent has changed security domain" logic
    
    exit_notify() changes ->exit_signal if the parent already did exec.
    This doesn't really work, we are not going to send the signal now
    if there is another live thread or the exiting task is traced. The
    parent can exec before the last dies or the tracer detaches.
    
    Move this check into do_notify_parent() which actually sends the
    signal.
    
    The user-visible change is that we do not change ->exit_signal,
    and thus the exiting task is still "clone children" for
    do_wait()->eligible_child(__WCLONE). Hopefully this is fine, the
    current logic is racy anyway.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8511e39813c7..e76001ccf5cd 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1652,6 +1652,15 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 	BUG_ON(!tsk->ptrace &&
 	       (tsk->group_leader != tsk || !thread_group_empty(tsk)));
 
+	if (sig != SIGCHLD) {
+		/*
+		 * This is only possible if parent == real_parent.
+		 * Check if it has changed security domain.
+		 */
+		if (tsk->parent_exec_id != tsk->parent->self_exec_id)
+			sig = SIGCHLD;
+	}
+
 	info.si_signo = sig;
 	info.si_errno = 0;
 	/*

commit 0326f5a94ddea33fa331b2519f4172f4fb387baa
Author: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
Date:   Tue Mar 13 23:30:11 2012 +0530

    uprobes/core: Handle breakpoint and singlestep exceptions
    
    Uprobes uses exception notifiers to get to know if a thread hit
    a breakpoint or a singlestep exception.
    
    When a thread hits a uprobe or is singlestepping post a uprobe
    hit, the uprobe exception notifier sets its TIF_UPROBE bit,
    which will then be checked on its return to userspace path
    (do_notify_resume() ->uprobe_notify_resume()), where the
    consumers handlers are run (in task context) based on the
    defined filters.
    
    Uprobe hits are thread specific and hence we need to maintain
    information about if a task hit a uprobe, what uprobe was hit,
    the slot where the original instruction was copied for xol so
    that it can be singlestepped with appropriate fixups.
    
    In some cases, special care is needed for instructions that are
    executed out of line (xol). These are architecture specific
    artefacts, such as handling RIP relative instructions on x86_64.
    
    Since the instruction at which the uprobe was inserted is
    executed out of line, architecture specific fixups are added so
    that the thread continues normal execution in the presence of a
    uprobe.
    
    Postpone the signals until we execute the probed insn.
    post_xol() path does a recalc_sigpending() before return to
    user-mode, this ensures the signal can't be lost.
    
    Uprobes relies on DIE_DEBUG notification to notify if a
    singlestep is complete.
    
    Adds x86 specific uprobe exception notifiers and appropriate
    hooks needed to determine a uprobe hit and subsequent post
    processing.
    
    Add requisite x86 fixups for xol for uprobes. Specific cases
    needing fixups include relative jumps (x86_64), calls, etc.
    
    Where possible, we check and skip singlestepping the
    breakpointed instructions. For now we skip single byte as well
    as few multibyte nop instructions. However this can be extended
    to other instructions too.
    
    Credits to Oleg Nesterov for suggestions/patches related to
    signal, breakpoint, singlestep handling code.
    
    Signed-off-by: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Ananth N Mavinakayanahalli <ananth@in.ibm.com>
    Cc: Jim Keniston <jkenisto@linux.vnet.ibm.com>
    Cc: Linux-mm <linux-mm@kvack.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Arnaldo Carvalho de Melo <acme@infradead.org>
    Cc: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20120313180011.29771.89027.sendpatchset@srdronam.in.ibm.com
    [ Performed various cleanliness edits ]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8511e39813c7..e93ff0a719a0 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -29,6 +29,7 @@
 #include <linux/pid_namespace.h>
 #include <linux/nsproxy.h>
 #include <linux/user_namespace.h>
+#include <linux/uprobes.h>
 #define CREATE_TRACE_POINTS
 #include <trace/events/signal.h>
 
@@ -2192,6 +2193,9 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 	struct signal_struct *signal = current->signal;
 	int signr;
 
+	if (unlikely(uprobe_deny_signal()))
+		return 0;
+
 relock:
 	/*
 	 * We'll jump back here after any time we were stopped in TASK_STOPPED.

commit 163566f60bfe6a8176650155e2d98649b0dfabf8
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Nov 22 21:37:41 2011 +0100

    tracing: send_sigqueue() needs trace_signal_generate() too
    
    Add trace_signal_generate() into send_sigqueue().
    
    send_sigqueue() is very similar to __send_signal(), just it uses
    the preallocated info. It should do the same wrt tracing.
    
    Reported-by: Seiji Aguchi <saguchi@redhat.com>
    Reviewed-by: Seiji Aguchi <seiji.aguchi@hds.com>
    Acked-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1bd9e86fda1f..8511e39813c7 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1591,7 +1591,7 @@ int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)
 	int sig = q->info.si_signo;
 	struct sigpending *pending;
 	unsigned long flags;
-	int ret;
+	int ret, result;
 
 	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
 
@@ -1600,6 +1600,7 @@ int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)
 		goto ret;
 
 	ret = 1; /* the signal is ignored */
+	result = TRACE_SIGNAL_IGNORED;
 	if (!prepare_signal(sig, t, 0))
 		goto out;
 
@@ -1611,6 +1612,7 @@ int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)
 		 */
 		BUG_ON(q->info.si_code != SI_TIMER);
 		q->info.si_overrun++;
+		result = TRACE_SIGNAL_ALREADY_PENDING;
 		goto out;
 	}
 	q->info.si_overrun = 0;
@@ -1620,7 +1622,9 @@ int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)
 	list_add_tail(&q->list, &pending->list);
 	sigaddset(&pending->signal, sig);
 	complete_signal(sig, t, group);
+	result = TRACE_SIGNAL_DELIVERED;
 out:
+	trace_signal_generate(sig, &q->info, t, group, result);
 	unlock_task_sighand(t, &flags);
 ret:
 	return ret;

commit 6c303d3ab39f0dc69546f179c424ee1124f50906
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Nov 22 21:13:48 2011 +0100

    tracing: let trace_signal_generate() report more info, kill overflow_fail/lose_info
    
    __send_signal()->trace_signal_generate() doesn't report enough info.
    The users want to know was the signal actually delivered or not, and
    they also need the shared/private info.
    
    The patch moves trace_signal_generate() at the end of __send_signal()
    and adds the 2 additional arguments.
    
    This also allows us to kill trace_signal_overflow_fail/lose_info, we
    can simply add the appropriate TRACE_SIGNAL_ "result" codes.
    
    Reported-by: Seiji Aguchi <saguchi@redhat.com>
    Reviewed-by: Seiji Aguchi <seiji.aguchi@hds.com>
    Acked-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index c73c4284160e..1bd9e86fda1f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1054,13 +1054,13 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	struct sigpending *pending;
 	struct sigqueue *q;
 	int override_rlimit;
-
-	trace_signal_generate(sig, info, t);
+	int ret = 0, result;
 
 	assert_spin_locked(&t->sighand->siglock);
 
+	result = TRACE_SIGNAL_IGNORED;
 	if (!prepare_signal(sig, t, from_ancestor_ns))
-		return 0;
+		goto ret;
 
 	pending = group ? &t->signal->shared_pending : &t->pending;
 	/*
@@ -1068,8 +1068,11 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	 * exactly one non-rt signal, so that we can get more
 	 * detailed information about the cause of the signal.
 	 */
+	result = TRACE_SIGNAL_ALREADY_PENDING;
 	if (legacy_queue(pending, sig))
-		return 0;
+		goto ret;
+
+	result = TRACE_SIGNAL_DELIVERED;
 	/*
 	 * fast-pathed signals for kernel-internal things like SIGSTOP
 	 * or SIGKILL.
@@ -1127,14 +1130,15 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			 * signal was rt and sent by user using something
 			 * other than kill().
 			 */
-			trace_signal_overflow_fail(sig, group, info);
-			return -EAGAIN;
+			result = TRACE_SIGNAL_OVERFLOW_FAIL;
+			ret = -EAGAIN;
+			goto ret;
 		} else {
 			/*
 			 * This is a silent loss of information.  We still
 			 * send the signal, but the *info bits are lost.
 			 */
-			trace_signal_lose_info(sig, group, info);
+			result = TRACE_SIGNAL_LOSE_INFO;
 		}
 	}
 
@@ -1142,7 +1146,9 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	signalfd_notify(t, sig);
 	sigaddset(&pending->signal, sig);
 	complete_signal(sig, t, group);
-	return 0;
+ret:
+	trace_signal_generate(sig, info, t, group, result);
+	return ret;
 }
 
 static int send_signal(int sig, struct siginfo *info, struct task_struct *t,

commit 6b550f9495947fc279d12c38feaf98500e8d0646
Author: Serge E. Hallyn <serge@hallyn.com>
Date:   Tue Jan 10 15:11:37 2012 -0800

    user namespace: make signal.c respect user namespaces
    
    ipc/mqueue.c: for __SI_MESQ, convert the uid being sent to recipient's
    user namespace. (new, thanks Oleg)
    
    __send_signal: convert current's uid to the recipient's user namespace
    for any siginfo which is not SI_FROMKERNEL (patch from Oleg, thanks
    again :)
    
    do_notify_parent and do_notify_parent_cldstop: map task's uid to parent's
    user namespace
    
    ptrace_signal maps parent's uid into current's user namespace before
    including in signal to current.  IIUC Oleg has argued that this shouldn't
    matter as the debugger will play with it, but it seems like not converting
    the value currently being set is misleading.
    
    Changelog:
    Sep 20: Inspired by Oleg's suggestion, define map_cred_ns() helper to
            simplify callers and help make clear what we are translating
            (which uid into which namespace).  Passing the target task would
            make callers even easier to read, but we pass in user_ns because
            current_user_ns() != task_cred_xxx(current, user_ns).
    Sep 20: As recommended by Oleg, also put task_pid_vnr() under rcu_read_lock
            in ptrace_signal().
    Sep 23: In send_signal(), detect when (user) signal is coming from an
            ancestor or unrelated user namespace.  Pass that on to __send_signal,
            which sets si_uid to 0 or overflowuid if needed.
    Oct 12: Base on Oleg's fixup_uid() patch.  On top of that, handle all
            SI_FROMKERNEL cases at callers, because we can't assume sender is
            current in those cases.
    Nov 10: (mhelsley) rename fixup_uid to more meaningful usern_fixup_signal_uid
    Nov 10: (akpm) make the !CONFIG_USER_NS case clearer
    
    Signed-off-by: Serge Hallyn <serge.hallyn@canonical.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    From: Serge Hallyn <serge.hallyn@canonical.com>
    Subject: __send_signal: pass q->info, not info, to userns_fixup_signal_uid (v2)
    
    Eric Biederman pointed out that passing info is a bug and could lead to a
    NULL pointer deref to boot.
    
    A collection of signal, securebits, filecaps, cap_bounds, and a few other
    ltp tests passed with this kernel.
    
    Changelog:
        Nov 18: previous patch missed a leading '&'
    
    Signed-off-by: Serge Hallyn <serge.hallyn@canonical.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    From: Dan Carpenter <dan.carpenter@oracle.com>
    Subject: ipc/mqueue: lock() => unlock() typo
    
    There was a double lock typo introduced in b085f4bd6b21 "user namespace:
    make signal.c respect user namespaces"
    
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Matt Helsley <matthltc@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: Serge Hallyn <serge@hallyn.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index d532f1709fbf..c73c4284160e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -28,6 +28,7 @@
 #include <linux/freezer.h>
 #include <linux/pid_namespace.h>
 #include <linux/nsproxy.h>
+#include <linux/user_namespace.h>
 #define CREATE_TRACE_POINTS
 #include <trace/events/signal.h>
 
@@ -1019,6 +1020,34 @@ static inline int legacy_queue(struct sigpending *signals, int sig)
 	return (sig < SIGRTMIN) && sigismember(&signals->signal, sig);
 }
 
+/*
+ * map the uid in struct cred into user namespace *ns
+ */
+static inline uid_t map_cred_ns(const struct cred *cred,
+				struct user_namespace *ns)
+{
+	return user_ns_map_uid(ns, cred, cred->uid);
+}
+
+#ifdef CONFIG_USER_NS
+static inline void userns_fixup_signal_uid(struct siginfo *info, struct task_struct *t)
+{
+	if (current_user_ns() == task_cred_xxx(t, user_ns))
+		return;
+
+	if (SI_FROMKERNEL(info))
+		return;
+
+	info->si_uid = user_ns_map_uid(task_cred_xxx(t, user_ns),
+					current_cred(), info->si_uid);
+}
+#else
+static inline void userns_fixup_signal_uid(struct siginfo *info, struct task_struct *t)
+{
+	return;
+}
+#endif
+
 static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			int group, int from_ancestor_ns)
 {
@@ -1088,6 +1117,9 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 				q->info.si_pid = 0;
 			break;
 		}
+
+		userns_fixup_signal_uid(&q->info, t);
+
 	} else if (!is_si_special(info)) {
 		if (sig >= SIGRTMIN && info->si_code != SI_USER) {
 			/*
@@ -1626,7 +1658,8 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 	 */
 	rcu_read_lock();
 	info.si_pid = task_pid_nr_ns(tsk, tsk->parent->nsproxy->pid_ns);
-	info.si_uid = __task_cred(tsk)->uid;
+	info.si_uid = map_cred_ns(__task_cred(tsk),
+			task_cred_xxx(tsk->parent, user_ns));
 	rcu_read_unlock();
 
 	info.si_utime = cputime_to_clock_t(tsk->utime + tsk->signal->utime);
@@ -1709,7 +1742,8 @@ static void do_notify_parent_cldstop(struct task_struct *tsk,
 	 */
 	rcu_read_lock();
 	info.si_pid = task_pid_nr_ns(tsk, parent->nsproxy->pid_ns);
-	info.si_uid = __task_cred(tsk)->uid;
+	info.si_uid = map_cred_ns(__task_cred(tsk),
+			task_cred_xxx(parent, user_ns));
 	rcu_read_unlock();
 
 	info.si_utime = cputime_to_clock_t(tsk->utime);
@@ -2125,8 +2159,11 @@ static int ptrace_signal(int signr, siginfo_t *info,
 		info->si_signo = signr;
 		info->si_errno = 0;
 		info->si_code = SI_USER;
+		rcu_read_lock();
 		info->si_pid = task_pid_vnr(current->parent);
-		info->si_uid = task_uid(current->parent);
+		info->si_uid = map_cred_ns(__task_cred(current->parent),
+				current_user_ns());
+		rcu_read_unlock();
 	}
 
 	/* If the (new) signal is now blocked, requeue it.  */

commit 5e6292c0f28f03dfdb8ea3d685f0b838a23bfba4
Author: Matt Fleming <matt.fleming@intel.com>
Date:   Tue Jan 10 15:11:17 2012 -0800

    signal: add block_sigmask() for adding sigmask to current->blocked
    
    Abstract the code sequence for adding a signal handler's sa_mask to
    current->blocked because the sequence is identical for all architectures.
    Furthermore, in the past some architectures actually got this code wrong,
    so introduce a wrapper that all architectures can use.
    
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: "David S. Miller" <davem@davemloft.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index bb0efa5705ed..d532f1709fbf 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2318,6 +2318,27 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 	return signr;
 }
 
+/**
+ * block_sigmask - add @ka's signal mask to current->blocked
+ * @ka: action for @signr
+ * @signr: signal that has been successfully delivered
+ *
+ * This function should be called when a signal has succesfully been
+ * delivered. It adds the mask of signals for @ka to current->blocked
+ * so that they are blocked during the execution of the signal
+ * handler. In addition, @signr will be blocked unless %SA_NODEFER is
+ * set in @ka->sa.sa_flags.
+ */
+void block_sigmask(struct k_sigaction *ka, int signr)
+{
+	sigset_t blocked;
+
+	sigorsets(&blocked, &current->blocked, &ka->sa.sa_mask);
+	if (!(ka->sa.sa_flags & SA_NODEFER))
+		sigaddset(&blocked, signr);
+	set_current_blocked(&blocked);
+}
+
 /*
  * It could be that complete_signal() picked us to notify about the
  * group-wide signal. Other threads should be notified now to take

commit db0c2bf69aa095d4a6de7b1145f29fe9a7c0f6a3
Merge: ac69e0928054 0d19ea866562
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 9 12:59:24 2012 -0800

    Merge branch 'for-3.3' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup
    
    * 'for-3.3' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup: (21 commits)
      cgroup: fix to allow mounting a hierarchy by name
      cgroup: move assignement out of condition in cgroup_attach_proc()
      cgroup: Remove task_lock() from cgroup_post_fork()
      cgroup: add sparse annotation to cgroup_iter_start() and cgroup_iter_end()
      cgroup: mark cgroup_rmdir_waitq and cgroup_attach_proc() as static
      cgroup: only need to check oldcgrp==newgrp once
      cgroup: remove redundant get/put of task struct
      cgroup: remove redundant get/put of old css_set from migrate
      cgroup: Remove unnecessary task_lock before fetching css_set on migration
      cgroup: Drop task_lock(parent) on cgroup_fork()
      cgroups: remove redundant get/put of css_set from css_set_check_fetched()
      resource cgroups: remove bogus cast
      cgroup: kill subsys->can_attach_task(), pre_attach() and attach_task()
      cgroup, cpuset: don't use ss->pre_attach()
      cgroup: don't use subsys->can_attach_task() or ->attach_task()
      cgroup: introduce cgroup_taskset and use it in subsys->can_attach(), cancel_attach() and attach()
      cgroup: improve old cgroup handling in cgroup_attach_proc()
      cgroup: always lock threadgroup during migration
      threadgroup: extend threadgroup_lock() to cover exit and exec
      threadgroup: rename signal->threadgroup_fork_lock to ->group_rwsem
      ...
    
    Fix up conflict in kernel/cgroup.c due to commit e0197aae59e5: "cgroups:
    fix a css_set not found bug in cgroup_attach_proc" that already
    mentioned that the bug is fixed (differently) in Tejun's cgroup
    patchset. This one, in other words.

commit 0db49b72bce26341274b74fd968501489a361ae3
Merge: 35b740e4662e 1ac9bc6943ed
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jan 6 08:33:28 2012 -0800

    Merge branch 'sched-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    * 'sched-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (40 commits)
      sched/tracing: Add a new tracepoint for sleeptime
      sched: Disable scheduler warnings during oopses
      sched: Fix cgroup movement of waking process
      sched: Fix cgroup movement of newly created process
      sched: Fix cgroup movement of forking process
      sched: Remove cfs bandwidth period check in tg_set_cfs_period()
      sched: Fix load-balance lock-breaking
      sched: Replace all_pinned with a generic flags field
      sched: Only queue remote wakeups when crossing cache boundaries
      sched: Add missing rcu_dereference() around ->real_parent usage
      [S390] fix cputime overflow in uptime_proc_show
      [S390] cputime: add sparse checking and cleanup
      sched: Mark parent and real_parent as __rcu
      sched, nohz: Fix missing RCU read lock
      sched, nohz: Set the NOHZ_BALANCE_KICK flag for idle load balancer
      sched, nohz: Fix the idle cpu check in nohz_idle_balance
      sched: Use jump_labels for sched_feat
      sched/accounting: Fix parameter passing in task_group_account_field
      sched/accounting: Fix user/system tick double accounting
      sched/accounting: Re-use scheduler statistics for the root cgroup
      ...
    
    Fix up conflicts in
     - arch/ia64/include/asm/cputime.h, include/asm-generic/cputime.h
            usecs_to_cputime64() vs the sparse cleanups
     - kernel/sched/fair.c, kernel/time/tick-sched.c
            scheduler changes in multiple branches

commit 8a88951b5878dc475dcd841cefc767e36397d14e
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Jan 4 17:29:20 2012 +0100

    ptrace: ensure JOBCTL_STOP_SIGMASK is not zero after detach
    
    This is the temporary simple fix for 3.2, we need more changes in this
    area.
    
    1. do_signal_stop() assumes that the running untraced thread in the
       stopped thread group is not possible. This was our goal but it is
       not yet achieved: a stopped-but-resumed tracee can clone the running
       thread which can initiate another group-stop.
    
       Remove WARN_ON_ONCE(!current->ptrace).
    
    2. A new thread always starts with ->jobctl = 0. If it is auto-attached
       and this group is stopped, __ptrace_unlink() sets JOBCTL_STOP_PENDING
       but JOBCTL_STOP_SIGMASK part is zero, this triggers WANR_ON(!signr)
       in do_jobctl_trap() if another debugger attaches.
    
       Change __ptrace_unlink() to set the artificial SIGSTOP for report.
    
       Alternatively we could change ptrace_init_task() to copy signr from
       current, but this means we can copy it for no reason and hide the
       possible similar problems.
    
    Acked-by: Tejun Heo <tj@kernel.org>
    Cc: <stable@kernel.org>         [3.1]
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index b3f78d09a105..206551563cce 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1994,8 +1994,6 @@ static bool do_signal_stop(int signr)
 		 */
 		if (!(sig->flags & SIGNAL_STOP_STOPPED))
 			sig->group_exit_code = signr;
-		else
-			WARN_ON_ONCE(!current->ptrace);
 
 		sig->group_stop_count = 0;
 

commit 648616343cdbe904c585a6c12e323d3b3c72e46f
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Thu Dec 15 14:56:09 2011 +0100

    [S390] cputime: add sparse checking and cleanup
    
    Make cputime_t and cputime64_t nocast to enable sparse checking to
    detect incorrect use of cputime. Drop the cputime macros for simple
    scalar operations. The conversion macros are still needed.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index b3f78d09a105..739ef2bf105c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1629,10 +1629,8 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 	info.si_uid = __task_cred(tsk)->uid;
 	rcu_read_unlock();
 
-	info.si_utime = cputime_to_clock_t(cputime_add(tsk->utime,
-				tsk->signal->utime));
-	info.si_stime = cputime_to_clock_t(cputime_add(tsk->stime,
-				tsk->signal->stime));
+	info.si_utime = cputime_to_clock_t(tsk->utime + tsk->signal->utime);
+	info.si_stime = cputime_to_clock_t(tsk->stime + tsk->signal->stime);
 
 	info.si_status = tsk->exit_code & 0x7f;
 	if (tsk->exit_code & 0x80)

commit 77e4ef99d1c596a31747668e5fd837f77b6349b6
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Dec 12 18:12:21 2011 -0800

    threadgroup: extend threadgroup_lock() to cover exit and exec
    
    threadgroup_lock() protected only protected against new addition to
    the threadgroup, which was inherently somewhat incomplete and
    problematic for its only user cgroup.  On-going migration could race
    against exec and exit leading to interesting problems - the symmetry
    between various attach methods, task exiting during method execution,
    ->exit() racing against attach methods, migrating task switching basic
    properties during exec and so on.
    
    This patch extends threadgroup_lock() such that it protects against
    all three threadgroup altering operations - fork, exit and exec.  For
    exit, threadgroup_change_begin/end() calls are added to exit_signals
    around assertion of PF_EXITING.  For exec, threadgroup_[un]lock() are
    updated to also grab and release cred_guard_mutex.
    
    With this change, threadgroup_lock() guarantees that the target
    threadgroup will remain stable - no new task will be added, no new
    PF_EXITING will be set and exec won't happen.
    
    The next patch will update cgroup so that it can take full advantage
    of this change.
    
    -v2: beefed up comment as suggested by Frederic.
    
    -v3: narrowed scope of protection in exit path as suggested by
         Frederic.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>
    Acked-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Paul Menage <paul@paulmenage.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index b3f78d09a105..399c184bf0ae 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2359,8 +2359,15 @@ void exit_signals(struct task_struct *tsk)
 	int group_stop = 0;
 	sigset_t unblocked;
 
+	/*
+	 * @tsk is about to have PF_EXITING set - lock out users which
+	 * expect stable threadgroup.
+	 */
+	threadgroup_change_begin(tsk);
+
 	if (thread_group_empty(tsk) || signal_group_exit(tsk->signal)) {
 		tsk->flags |= PF_EXITING;
+		threadgroup_change_end(tsk);
 		return;
 	}
 
@@ -2370,6 +2377,9 @@ void exit_signals(struct task_struct *tsk)
 	 * see wants_signal(), do_signal_stop().
 	 */
 	tsk->flags |= PF_EXITING;
+
+	threadgroup_change_end(tsk);
+
 	if (!signal_pending(tsk))
 		goto out;
 

commit 9984de1a5a8a96275fcab818f7419af5a3c86e71
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Mon May 23 14:51:41 2011 -0400

    kernel: Map most files to use export.h instead of module.h
    
    The changed files were only including linux/module.h for the
    EXPORT_SYMBOL infrastructure, and nothing else.  Revector them
    onto the isolated export header for faster compile times.
    
    Nothing to see here but a whole lot of instances of:
    
      -#include <linux/module.h>
      +#include <linux/export.h>
    
    This commit is only changing the kernel dir; next targets
    will probably be mm, fs, the arch dirs, etc.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index d252be2d3de5..b3f78d09a105 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -11,7 +11,7 @@
  */
 
 #include <linux/slab.h>
-#include <linux/module.h>
+#include <linux/export.h>
 #include <linux/init.h>
 #include <linux/sched.h>
 #include <linux/fs.h>

commit d178bc3a708f39cbfefc3fab37032d3f2511b4ec
Author: Serge Hallyn <serge.hallyn@canonical.com>
Date:   Mon Sep 26 10:45:18 2011 -0500

    user namespace: usb: make usb urbs user namespace aware (v2)
    
    Add to the dev_state and alloc_async structures the user namespace
    corresponding to the uid and euid.  Pass these to kill_pid_info_as_uid(),
    which can then implement a proper, user-namespace-aware uid check.
    
    Changelog:
    Sep 20: Per Oleg's suggestion: Instead of caching and passing user namespace,
            uid, and euid each separately, pass a struct cred.
    Sep 26: Address Alan Stern's comments: don't define a struct cred at
            usbdev_open(), and take and put a cred at async_completed() to
            ensure it lasts for the duration of kill_pid_info_as_cred().
    
    Signed-off-by: Serge Hallyn <serge.hallyn@canonical.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Tejun Heo <tj@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

diff --git a/kernel/signal.c b/kernel/signal.c
index 291c9700be75..d252be2d3de5 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1344,13 +1344,24 @@ int kill_proc_info(int sig, struct siginfo *info, pid_t pid)
 	return error;
 }
 
+static int kill_as_cred_perm(const struct cred *cred,
+			     struct task_struct *target)
+{
+	const struct cred *pcred = __task_cred(target);
+	if (cred->user_ns != pcred->user_ns)
+		return 0;
+	if (cred->euid != pcred->suid && cred->euid != pcred->uid &&
+	    cred->uid  != pcred->suid && cred->uid  != pcred->uid)
+		return 0;
+	return 1;
+}
+
 /* like kill_pid_info(), but doesn't use uid/euid of "current" */
-int kill_pid_info_as_uid(int sig, struct siginfo *info, struct pid *pid,
-		      uid_t uid, uid_t euid, u32 secid)
+int kill_pid_info_as_cred(int sig, struct siginfo *info, struct pid *pid,
+			 const struct cred *cred, u32 secid)
 {
 	int ret = -EINVAL;
 	struct task_struct *p;
-	const struct cred *pcred;
 	unsigned long flags;
 
 	if (!valid_signal(sig))
@@ -1362,10 +1373,7 @@ int kill_pid_info_as_uid(int sig, struct siginfo *info, struct pid *pid,
 		ret = -ESRCH;
 		goto out_unlock;
 	}
-	pcred = __task_cred(p);
-	if (si_fromuser(info) &&
-	    euid != pcred->suid && euid != pcred->uid &&
-	    uid  != pcred->suid && uid  != pcred->uid) {
+	if (si_fromuser(info) && !kill_as_cred_perm(cred, p)) {
 		ret = -EPERM;
 		goto out_unlock;
 	}
@@ -1384,7 +1392,7 @@ int kill_pid_info_as_uid(int sig, struct siginfo *info, struct pid *pid,
 	rcu_read_unlock();
 	return ret;
 }
-EXPORT_SYMBOL_GPL(kill_pid_info_as_uid);
+EXPORT_SYMBOL_GPL(kill_pid_info_as_cred);
 
 /*
  * kill_something_info() interprets pid in interesting ways just like kill(2).

commit c1095c6da518b0b64e724f629051fa67655cd8d9
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Jul 27 12:49:44 2011 -0700

    signals: sys_ssetmask/sys_rt_sigsuspend should use set_current_blocked()
    
    sys_ssetmask(), sys_rt_sigsuspend() and compat_sys_rt_sigsuspend()
    change ->blocked directly.  This is not correct, see the changelog in
    e6fa16ab "signal: sigprocmask() should do retarget_shared_pending()"
    
    Change them to use set_current_blocked().
    
    Another change is that now we are doing ->saved_sigmask = ->blocked
    lockless, it doesn't make any sense to do this under ->siglock.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Matt Fleming <matt.fleming@linux.intel.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index d7f70aed1cc0..291c9700be75 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3102,15 +3102,11 @@ SYSCALL_DEFINE0(sgetmask)
 
 SYSCALL_DEFINE1(ssetmask, int, newmask)
 {
-	int old;
-
-	spin_lock_irq(&current->sighand->siglock);
-	old = current->blocked.sig[0];
+	int old = current->blocked.sig[0];
+	sigset_t newset;
 
-	siginitset(&current->blocked, newmask & ~(sigmask(SIGKILL)|
-						  sigmask(SIGSTOP)));
-	recalc_sigpending();
-	spin_unlock_irq(&current->sighand->siglock);
+	siginitset(&newset, newmask & ~(sigmask(SIGKILL) | sigmask(SIGSTOP)));
+	set_current_blocked(&newset);
 
 	return old;
 }
@@ -3167,11 +3163,8 @@ SYSCALL_DEFINE2(rt_sigsuspend, sigset_t __user *, unewset, size_t, sigsetsize)
 		return -EFAULT;
 	sigdelsetmask(&newset, sigmask(SIGKILL)|sigmask(SIGSTOP));
 
-	spin_lock_irq(&current->sighand->siglock);
 	current->saved_sigmask = current->blocked;
-	current->blocked = newset;
-	recalc_sigpending();
-	spin_unlock_irq(&current->sighand->siglock);
+	set_current_blocked(&newset);
 
 	current->state = TASK_INTERRUPTIBLE;
 	schedule();

commit 8209f53d79444747782a28520187abaf689761f2
Merge: 22a3b9771117 eac1b5e57d7a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jul 22 15:06:50 2011 -0700

    Merge branch 'ptrace' of git://git.kernel.org/pub/scm/linux/kernel/git/oleg/misc
    
    * 'ptrace' of git://git.kernel.org/pub/scm/linux/kernel/git/oleg/misc: (39 commits)
      ptrace: do_wait(traced_leader_killed_by_mt_exec) can block forever
      ptrace: fix ptrace_signal() && STOP_DEQUEUED interaction
      connector: add an event for monitoring process tracers
      ptrace: dont send SIGSTOP on auto-attach if PT_SEIZED
      ptrace: mv send-SIGSTOP from do_fork() to ptrace_init_task()
      ptrace_init_task: initialize child->jobctl explicitly
      has_stopped_jobs: s/task_is_stopped/SIGNAL_STOP_STOPPED/
      ptrace: make former thread ID available via PTRACE_GETEVENTMSG after PTRACE_EVENT_EXEC stop
      ptrace: wait_consider_task: s/same_thread_group/ptrace_reparented/
      ptrace: kill real_parent_is_ptracer() in in favor of ptrace_reparented()
      ptrace: ptrace_reparented() should check same_thread_group()
      redefine thread_group_leader() as exit_signal >= 0
      do not change dead_task->exit_signal
      kill task_detached()
      reparent_leader: check EXIT_DEAD instead of task_detached()
      make do_notify_parent() __must_check, update the callers
      __ptrace_detach: avoid task_detached(), check do_notify_parent()
      kill tracehook_notify_death()
      make do_notify_parent() return bool
      ptrace: s/tracehook_tracer_task()/ptrace_parent()/
      ...

commit 8a35241803eeb0e9fd3fe27835d6b2775c73b641
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Jul 21 17:06:53 2011 +0200

    ptrace: fix ptrace_signal() && STOP_DEQUEUED interaction
    
    Simple test-case,
    
            int main(void)
            {
                    int pid, status;
    
                    pid = fork();
                    if (!pid) {
                            pause();
                            assert(0);
                            return 0x23;
                    }
    
                    assert(ptrace(PTRACE_ATTACH, pid, 0,0) == 0);
                    assert(wait(&status) == pid);
                    assert(WIFSTOPPED(status) && WSTOPSIG(status) == SIGSTOP);
    
                    kill(pid, SIGCONT);     // <--- also clears STOP_DEQUEUD
    
                    assert(ptrace(PTRACE_CONT, pid, 0,0) == 0);
                    assert(wait(&status) == pid);
                    assert(WIFSTOPPED(status) && WSTOPSIG(status) == SIGCONT);
    
                    assert(ptrace(PTRACE_CONT, pid, 0, SIGSTOP) == 0);
                    assert(wait(&status) == pid);
                    assert(WIFSTOPPED(status) && WSTOPSIG(status) == SIGSTOP);
    
                    kill(pid, SIGKILL);
                    return 0;
            }
    
    Without the patch it hangs. After the patch SIGSTOP "injected" by the
    tracer is not ignored and stops the tracee.
    
    Note also that if this test-case uses, say, SIGWINCH instead of SIGCONT,
    everything works without the patch. This can't be right, and this is
    confusing.
    
    The problem is that SIGSTOP (or any other sig_kernel_stop() signal) has
    no effect without JOBCTL_STOP_DEQUEUED. This means it is simply ignored
    after PTRACE_CONT unless JOBCTL_STOP_DEQUEUED was set "by accident", say
    it wasn't cleared after initial SIGSTOP sent by PTRACE_ATTACH.
    
    At first glance we could change ptrace_signal() to add STOP_DEQUEUED
    after return from ptrace_stop(), but this is not right in case when the
    tracer does not change the reported SIGSTOP and SIGCONT comes in between.
    This is even more wrong with PT_SEIZED, SIGCONT adds JOBCTL_TRAP_NOTIFY
    which will be "lost" during the TRAP_STOP | TRAP_NOTIFY report.
    
    So lets add STOP_DEQUEUED _before_ we report the signal. It has no effect
    unless sig_kernel_stop() == T after the tracer resumes us, and in the
    latter case the pending STOP_DEQUEUED means no SIGCONT in between, we
    should stop.
    
    Note also that if SIGCONT was sent, PT_SEIZED tracee will correctly
    report PTRACE_EVENT_STOP/SIGTRAP and thus the tracer can notice the fact
    SIGSTOP was cancelled.
    
    Also, move the current->ptrace check from ptrace_signal() to its caller,
    get_signal_to_deliver(), this looks more natural.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0a1bf2c8bdcd..c34f8f899b76 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2084,12 +2084,17 @@ static void do_jobctl_trap(void)
 static int ptrace_signal(int signr, siginfo_t *info,
 			 struct pt_regs *regs, void *cookie)
 {
-	if (!current->ptrace)
-		return signr;
-
 	ptrace_signal_deliver(regs, cookie);
-
-	/* Let the debugger run.  */
+	/*
+	 * We do not check sig_kernel_stop(signr) but set this marker
+	 * unconditionally because we do not know whether debugger will
+	 * change signr. This flag has no meaning unless we are going
+	 * to stop after return from ptrace_stop(). In this case it will
+	 * be checked in do_signal_stop(), we should only stop if it was
+	 * not cleared by SIGCONT while we were sleeping. See also the
+	 * comment in dequeue_signal().
+	 */
+	current->jobctl |= JOBCTL_STOP_DEQUEUED;
 	ptrace_stop(signr, CLD_TRAPPED, 0, info);
 
 	/* We're back.  Did the debugger cancel the sig?  */
@@ -2193,7 +2198,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		if (!signr)
 			break; /* will return 0 */
 
-		if (signr != SIGKILL) {
+		if (unlikely(current->ptrace) && signr != SIGKILL) {
 			signr = ptrace_signal(signr, info,
 					      regs, cookie);
 			if (!signr)

commit a841796f11c90d53dbac773be56b04fbee8af272
Author: Paul E. McKenney <paul.mckenney@linaro.org>
Date:   Tue Jul 19 03:25:36 2011 -0700

    signal: align __lock_task_sighand() irq disabling and RCU
    
    The __lock_task_sighand() function calls rcu_read_lock() with interrupts
    and preemption enabled, but later calls rcu_read_unlock() with interrupts
    disabled.  It is therefore possible that this RCU read-side critical
    section will be preempted and later RCU priority boosted, which means that
    rcu_read_unlock() will call rt_mutex_unlock() in order to deboost itself, but
    with interrupts disabled. This results in lockdep splats, so this commit
    nests the RCU read-side critical section within the interrupt-disabled
    region of code.  This prevents the RCU read-side critical section from
    being preempted, and thus prevents the attempt to deboost with interrupts
    disabled.
    
    It is quite possible that a better long-term fix is to make rt_mutex_unlock()
    disable irqs when acquiring the rt_mutex structure's ->wait_lock.
    
    Signed-off-by: Paul E. McKenney <paul.mckenney@linaro.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index ff7678603328..415d85d6f6c6 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1178,18 +1178,25 @@ struct sighand_struct *__lock_task_sighand(struct task_struct *tsk,
 {
 	struct sighand_struct *sighand;
 
-	rcu_read_lock();
 	for (;;) {
+		local_irq_save(*flags);
+		rcu_read_lock();
 		sighand = rcu_dereference(tsk->sighand);
-		if (unlikely(sighand == NULL))
+		if (unlikely(sighand == NULL)) {
+			rcu_read_unlock();
+			local_irq_restore(*flags);
 			break;
+		}
 
-		spin_lock_irqsave(&sighand->siglock, *flags);
-		if (likely(sighand == tsk->sighand))
+		spin_lock(&sighand->siglock);
+		if (likely(sighand == tsk->sighand)) {
+			rcu_read_unlock();
 			break;
-		spin_unlock_irqrestore(&sighand->siglock, *flags);
+		}
+		spin_unlock(&sighand->siglock);
+		rcu_read_unlock();
+		local_irq_restore(*flags);
 	}
-	rcu_read_unlock();
 
 	return sighand;
 }

commit bb3696da89743d580f869142d0a6e6ba9b7fe89a
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Jun 24 17:34:23 2011 +0200

    ptrace: kill real_parent_is_ptracer() in in favor of ptrace_reparented()
    
    Kill real_parent_is_ptracer() and update the callers to use
    ptrace_reparented(), after the previous patch they do the same.
    
    Remove the unnecessary ->ptrace != 0 check in get_signal_to_deliver(),
    if ptrace_reparented() == T then the task must be ptraced.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 4c4ad34caf77..0a1bf2c8bdcd 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1759,15 +1759,6 @@ static int sigkill_pending(struct task_struct *tsk)
 		sigismember(&tsk->signal->shared_pending.signal, SIGKILL);
 }
 
-/*
- * Test whether the target task of the usual cldstop notification - the
- * real_parent of @child - is in the same group as the ptracer.
- */
-static bool real_parent_is_ptracer(struct task_struct *child)
-{
-	return same_thread_group(child->parent, child->real_parent);
-}
-
 /*
  * This must be called with current->sighand->siglock held.
  *
@@ -1848,7 +1839,7 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 		 * separately unless they're gonna be duplicates.
 		 */
 		do_notify_parent_cldstop(current, true, why);
-		if (gstop_done && !real_parent_is_ptracer(current))
+		if (gstop_done && ptrace_reparented(current))
 			do_notify_parent_cldstop(current, false, why);
 
 		/*
@@ -2154,7 +2145,6 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 	 * the CLD_ si_code into SIGNAL_CLD_MASK bits.
 	 */
 	if (unlikely(signal->flags & SIGNAL_CLD_MASK)) {
-		struct task_struct *leader;
 		int why;
 
 		if (signal->flags & SIGNAL_CLD_CONTINUED)
@@ -2175,13 +2165,11 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		 * a duplicate.
 		 */
 		read_lock(&tasklist_lock);
-
 		do_notify_parent_cldstop(current, false, why);
 
-		leader = current->group_leader;
-		if (leader->ptrace && !real_parent_is_ptracer(leader))
-			do_notify_parent_cldstop(leader, true, why);
-
+		if (ptrace_reparented(current->group_leader))
+			do_notify_parent_cldstop(current->group_leader,
+						true, why);
 		read_unlock(&tasklist_lock);
 
 		goto relock;

commit d4f7c511c1c2a67eb287987cf1ce9554149030e6
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Jun 22 23:10:11 2011 +0200

    do not change dead_task->exit_signal
    
    __ptrace_detach() and do_notify_parent() set task->exit_signal = -1
    to mark the task dead. This is no longer needed, nobody checks
    exit_signal to detect the EXIT_DEAD task.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index d52e82cd62bb..4c4ad34caf77 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1650,7 +1650,6 @@ bool do_notify_parent(struct task_struct *tsk, int sig)
 		 * it, just use SIG_IGN instead).
 		 */
 		autoreap = true;
-		tsk->exit_signal = -1;
 		if (psig->action[SIGCHLD-1].sa.sa_handler == SIG_IGN)
 			sig = 0;
 	}

commit 53c8f9f199b239668e6b1a907735ee323a0d1ccd
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Jun 22 23:08:18 2011 +0200

    make do_notify_parent() return bool
    
    - change do_notify_parent() to return a boolean, true if the task should
      be reaped because its parent ignores SIGCHLD.
    
    - update the only caller which checks the returned value, exit_notify().
    
    This temporary uglifies exit_notify() even more, will be cleanuped by
    the next change.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1550aee34f42..d52e82cd62bb 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1577,15 +1577,15 @@ int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)
  * Let a parent know about the death of a child.
  * For a stopped/continued status change, use do_notify_parent_cldstop instead.
  *
- * Returns -1 if our parent ignored us and so we've switched to
- * self-reaping, or else @sig.
+ * Returns true if our parent ignored us and so we've switched to
+ * self-reaping.
  */
-int do_notify_parent(struct task_struct *tsk, int sig)
+bool do_notify_parent(struct task_struct *tsk, int sig)
 {
 	struct siginfo info;
 	unsigned long flags;
 	struct sighand_struct *psig;
-	int ret = sig;
+	bool autoreap = false;
 
 	BUG_ON(sig == -1);
 
@@ -1649,16 +1649,17 @@ int do_notify_parent(struct task_struct *tsk, int sig)
 		 * is implementation-defined: we do (if you don't want
 		 * it, just use SIG_IGN instead).
 		 */
-		ret = tsk->exit_signal = -1;
+		autoreap = true;
+		tsk->exit_signal = -1;
 		if (psig->action[SIGCHLD-1].sa.sa_handler == SIG_IGN)
-			sig = -1;
+			sig = 0;
 	}
-	if (valid_signal(sig) && sig > 0)
+	if (valid_signal(sig) && sig)
 		__group_send_sig_info(sig, &info, tsk->parent);
 	__wake_up_parent(tsk, tsk->parent);
 	spin_unlock_irqrestore(&psig->siglock, flags);
 
-	return ret;
+	return autoreap;
 }
 
 /**

commit a288eecce5253cc1565d400a52b9b476a157e040
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Jun 17 16:50:37 2011 +0200

    ptrace: kill trivial tracehooks
    
    At this point, tracehooks aren't useful to mainline kernel and mostly
    just add an extra layer of obfuscation.  Although they have comments,
    without actual in-kernel users, it is difficult to tell what are their
    assumptions and they're actually trying to achieve.  To mainline
    kernel, they just aren't worth keeping around.
    
    This patch kills the following trivial tracehooks.
    
    * Ones testing whether task is ptraced.  Replace with ->ptrace test.
    
            tracehook_expect_breakpoints()
            tracehook_consider_ignored_signal()
            tracehook_consider_fatal_signal()
    
    * ptrace_event() wrappers.  Call directly.
    
            tracehook_report_exec()
            tracehook_report_exit()
            tracehook_report_vfork_done()
    
    * ptrace_release_task() wrapper.  Call directly.
    
            tracehook_finish_release_task()
    
    * noop
    
            tracehook_prepare_release_task()
            tracehook_report_death()
    
    This doesn't introduce any behavior change.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0f3370872506..1550aee34f42 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -87,7 +87,7 @@ static int sig_ignored(struct task_struct *t, int sig, int from_ancestor_ns)
 	/*
 	 * Tracers may want to know about even ignored signals.
 	 */
-	return !tracehook_consider_ignored_signal(t, sig);
+	return !t->ptrace;
 }
 
 /*
@@ -493,7 +493,8 @@ int unhandled_signal(struct task_struct *tsk, int sig)
 		return 1;
 	if (handler != SIG_IGN && handler != SIG_DFL)
 		return 0;
-	return !tracehook_consider_fatal_signal(tsk, sig);
+	/* if ptraced, let the tracer determine */
+	return !tsk->ptrace;
 }
 
 /*
@@ -981,8 +982,7 @@ static void complete_signal(int sig, struct task_struct *p, int group)
 	if (sig_fatal(p, sig) &&
 	    !(signal->flags & (SIGNAL_UNKILLABLE | SIGNAL_GROUP_EXIT)) &&
 	    !sigismember(&t->real_blocked, sig) &&
-	    (sig == SIGKILL ||
-	     !tracehook_consider_fatal_signal(t, sig))) {
+	    (sig == SIGKILL || !t->ptrace)) {
 		/*
 		 * This signal will be fatal to the whole group.
 		 */

commit d21142ece414ce1088cfcae760689aa60d6fee80
Author: Tejun Heo <tj@kernel.org>
Date:   Fri Jun 17 16:50:34 2011 +0200

    ptrace: kill task_ptrace()
    
    task_ptrace(task) simply dereferences task->ptrace and isn't even used
    consistently only adding confusion.  Kill it and directly access
    ->ptrace instead.
    
    This doesn't introduce any behavior change.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 97e575a3387e..0f3370872506 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1592,7 +1592,7 @@ int do_notify_parent(struct task_struct *tsk, int sig)
  	/* do_notify_parent_cldstop should have been called instead.  */
  	BUG_ON(task_is_stopped_or_traced(tsk));
 
-	BUG_ON(!task_ptrace(tsk) &&
+	BUG_ON(!tsk->ptrace &&
 	       (tsk->group_leader != tsk || !thread_group_empty(tsk)));
 
 	info.si_signo = sig;
@@ -1631,7 +1631,7 @@ int do_notify_parent(struct task_struct *tsk, int sig)
 
 	psig = tsk->parent->sighand;
 	spin_lock_irqsave(&psig->siglock, flags);
-	if (!task_ptrace(tsk) && sig == SIGCHLD &&
+	if (!tsk->ptrace && sig == SIGCHLD &&
 	    (psig->action[SIGCHLD-1].sa.sa_handler == SIG_IGN ||
 	     (psig->action[SIGCHLD-1].sa.sa_flags & SA_NOCLDWAIT))) {
 		/*
@@ -1731,7 +1731,7 @@ static void do_notify_parent_cldstop(struct task_struct *tsk,
 
 static inline int may_ptrace_stop(void)
 {
-	if (!likely(task_ptrace(current)))
+	if (!likely(current->ptrace))
 		return 0;
 	/*
 	 * Are we in the middle of do_coredump?
@@ -1989,7 +1989,7 @@ static bool do_signal_stop(int signr)
 		if (!(sig->flags & SIGNAL_STOP_STOPPED))
 			sig->group_exit_code = signr;
 		else
-			WARN_ON_ONCE(!task_ptrace(current));
+			WARN_ON_ONCE(!current->ptrace);
 
 		sig->group_stop_count = 0;
 
@@ -2014,7 +2014,7 @@ static bool do_signal_stop(int signr)
 		}
 	}
 
-	if (likely(!task_ptrace(current))) {
+	if (likely(!current->ptrace)) {
 		int notify = 0;
 
 		/*
@@ -2093,7 +2093,7 @@ static void do_jobctl_trap(void)
 static int ptrace_signal(int signr, siginfo_t *info,
 			 struct pt_regs *regs, void *cookie)
 {
-	if (!task_ptrace(current))
+	if (!current->ptrace)
 		return signr;
 
 	ptrace_signal_deliver(regs, cookie);
@@ -2179,7 +2179,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		do_notify_parent_cldstop(current, false, why);
 
 		leader = current->group_leader;
-		if (task_ptrace(leader) && !real_parent_is_ptracer(leader))
+		if (leader->ptrace && !real_parent_is_ptracer(leader))
 			do_notify_parent_cldstop(leader, true, why);
 
 		read_unlock(&tasklist_lock);

commit 544b2c91a9f14f9565af1972203438b7f49afd48
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jun 14 11:20:18 2011 +0200

    ptrace: implement PTRACE_LISTEN
    
    The previous patch implemented async notification for ptrace but it
    only worked while trace is running.  This patch introduces
    PTRACE_LISTEN which is suggested by Oleg Nestrov.
    
    It's allowed iff tracee is in STOP trap and puts tracee into
    quasi-running state - tracee never really runs but wait(2) and
    ptrace(2) consider it to be running.  While ptracer is listening,
    tracee is allowed to re-enter STOP to notify an async event.
    Listening state is cleared on the first notification.  Ptracer can
    also clear it by issuing INTERRUPT - tracee will re-trap into STOP
    with listening state cleared.
    
    This allows ptracer to monitor group stop state without running tracee
    - use INTERRUPT to put tracee into STOP trap, issue LISTEN and then
    wait(2) to wait for the next group stop event.  When it happens,
    PTRACE_GETSIGINFO provides information to determine the current state.
    
    Test program follows.
    
      #define PTRACE_SEIZE          0x4206
      #define PTRACE_INTERRUPT      0x4207
      #define PTRACE_LISTEN         0x4208
    
      #define PTRACE_SEIZE_DEVEL    0x80000000
    
      static const struct timespec ts1s = { .tv_sec = 1 };
    
      int main(int argc, char **argv)
      {
              pid_t tracee, tracer;
              int i;
    
              tracee = fork();
              if (!tracee)
                      while (1)
                              pause();
    
              tracer = fork();
              if (!tracer) {
                      siginfo_t si;
    
                      ptrace(PTRACE_SEIZE, tracee, NULL,
                             (void *)(unsigned long)PTRACE_SEIZE_DEVEL);
                      ptrace(PTRACE_INTERRUPT, tracee, NULL, NULL);
              repeat:
                      waitid(P_PID, tracee, NULL, WSTOPPED);
    
                      ptrace(PTRACE_GETSIGINFO, tracee, NULL, &si);
                      if (!si.si_code) {
                              printf("tracer: SIG %d\n", si.si_signo);
                              ptrace(PTRACE_CONT, tracee, NULL,
                                     (void *)(unsigned long)si.si_signo);
                              goto repeat;
                      }
                      printf("tracer: stopped=%d signo=%d\n",
                             si.si_signo != SIGTRAP, si.si_signo);
                      if (si.si_signo != SIGTRAP)
                              ptrace(PTRACE_LISTEN, tracee, NULL, NULL);
                      else
                              ptrace(PTRACE_CONT, tracee, NULL, NULL);
                      goto repeat;
              }
    
              for (i = 0; i < 3; i++) {
                      nanosleep(&ts1s, NULL);
                      printf("mother: SIGSTOP\n");
                      kill(tracee, SIGSTOP);
                      nanosleep(&ts1s, NULL);
                      printf("mother: SIGCONT\n");
                      kill(tracee, SIGCONT);
              }
              nanosleep(&ts1s, NULL);
    
              kill(tracer, SIGKILL);
              kill(tracee, SIGKILL);
              return 0;
      }
    
    This is identical to the program to test TRAP_NOTIFY except that
    tracee is PTRACE_LISTEN'd instead of PTRACE_CONT'd when group stopped.
    This allows ptracer to monitor when group stop ends without running
    tracee.
    
      # ./test-listen
      tracer: stopped=0 signo=5
      mother: SIGSTOP
      tracer: SIG 19
      tracer: stopped=1 signo=19
      mother: SIGCONT
      tracer: stopped=0 signo=5
      tracer: SIG 18
      mother: SIGSTOP
      tracer: SIG 19
      tracer: stopped=1 signo=19
      mother: SIGCONT
      tracer: stopped=0 signo=5
      tracer: SIG 18
      mother: SIGSTOP
      tracer: SIG 19
      tracer: stopped=1 signo=19
      mother: SIGCONT
      tracer: stopped=0 signo=5
      tracer: SIG 18
    
    -v2: Moved JOBCTL_LISTENING check in wait_task_stopped() into
         task_stopped_code() as suggested by Oleg.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 06177e2b3917..97e575a3387e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -825,9 +825,11 @@ static int check_kill_permission(int sig, struct siginfo *info,
  * TRAP_STOP to notify ptracer of an event.  @t must have been seized by
  * ptracer.
  *
- * If @t is running, STOP trap will be taken.  If already trapped, STOP
- * trap will be eventually taken without returning to userland after the
- * existing traps are finished by PTRACE_CONT.
+ * If @t is running, STOP trap will be taken.  If trapped for STOP and
+ * ptracer is listening for events, tracee is woken up so that it can
+ * re-trap for the new event.  If trapped otherwise, STOP trap will be
+ * eventually taken without returning to userland after the existing traps
+ * are finished by PTRACE_CONT.
  *
  * CONTEXT:
  * Must be called with @task->sighand->siglock held.
@@ -838,7 +840,7 @@ static void ptrace_trap_notify(struct task_struct *t)
 	assert_spin_locked(&t->sighand->siglock);
 
 	task_set_jobctl_pending(t, JOBCTL_TRAP_NOTIFY);
-	signal_wake_up(t, 0);
+	signal_wake_up(t, t->jobctl & JOBCTL_LISTENING);
 }
 
 /*
@@ -1894,6 +1896,9 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 	spin_lock_irq(&current->sighand->siglock);
 	current->last_siginfo = NULL;
 
+	/* LISTENING can be set only during STOP traps, clear it */
+	current->jobctl &= ~JOBCTL_LISTENING;
+
 	/*
 	 * Queued signals ignored us while we were stopped for tracing.
 	 * So check for any that we should take before resuming user mode.

commit fb1d910c178ba0c5bc32d3e5a9e82e05b7aad3cd
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jun 14 11:20:17 2011 +0200

    ptrace: implement TRAP_NOTIFY and use it for group stop events
    
    Currently there's no way for ptracer to find out whether group stop
    finished other than polling with INTERRUPT - GETSIGINFO - CONT
    sequence.  This patch implements group stop notification for ptracer
    using STOP traps.
    
    When group stop state of a seized tracee changes, JOBCTL_TRAP_NOTIFY
    is set, which schedules a STOP trap which is sticky - it isn't cleared
    by other traps and at least one STOP trap will happen eventually.
    STOP trap is synchronization point for event notification and the
    tracer can determine the current group stop state by looking at the
    signal number portion of exit code (si_status from waitid(2) or
    si_code from PTRACE_GETSIGINFO).
    
    Notifications are generated both on start and end of group stops but,
    because group stop participation always happens before STOP trap, this
    doesn't cause an extra trap while tracee is participating in group
    stop.  The symmetry will be useful later.
    
    Note that this notification works iff tracee is not trapped.
    Currently there is no way to be notified of group stop state changes
    while tracee is trapped.  This will be addressed by a later patch.
    
    An example program follows.
    
      #define PTRACE_SEIZE          0x4206
      #define PTRACE_INTERRUPT      0x4207
    
      #define PTRACE_SEIZE_DEVEL    0x80000000
    
      static const struct timespec ts1s = { .tv_sec = 1 };
    
      int main(int argc, char **argv)
      {
              pid_t tracee, tracer;
              int i;
    
              tracee = fork();
              if (!tracee)
                      while (1)
                              pause();
    
              tracer = fork();
              if (!tracer) {
                      siginfo_t si;
    
                      ptrace(PTRACE_SEIZE, tracee, NULL,
                             (void *)(unsigned long)PTRACE_SEIZE_DEVEL);
                      ptrace(PTRACE_INTERRUPT, tracee, NULL, NULL);
              repeat:
                      waitid(P_PID, tracee, NULL, WSTOPPED);
    
                      ptrace(PTRACE_GETSIGINFO, tracee, NULL, &si);
                      if (!si.si_code) {
                              printf("tracer: SIG %d\n", si.si_signo);
                              ptrace(PTRACE_CONT, tracee, NULL,
                                     (void *)(unsigned long)si.si_signo);
                              goto repeat;
                      }
                      printf("tracer: stopped=%d signo=%d\n",
                             si.si_signo != SIGTRAP, si.si_signo);
                      ptrace(PTRACE_CONT, tracee, NULL, NULL);
                      goto repeat;
              }
    
              for (i = 0; i < 3; i++) {
                      nanosleep(&ts1s, NULL);
                      printf("mother: SIGSTOP\n");
                      kill(tracee, SIGSTOP);
                      nanosleep(&ts1s, NULL);
                      printf("mother: SIGCONT\n");
                      kill(tracee, SIGCONT);
              }
              nanosleep(&ts1s, NULL);
    
              kill(tracer, SIGKILL);
              kill(tracee, SIGKILL);
              return 0;
      }
    
    In the above program, tracer keeps tracee running and gets
    notification of each group stop state changes.
    
      # ./test-notify
      tracer: stopped=0 signo=5
      mother: SIGSTOP
      tracer: SIG 19
      tracer: stopped=1 signo=19
      mother: SIGCONT
      tracer: stopped=0 signo=5
      tracer: SIG 18
      mother: SIGSTOP
      tracer: SIG 19
      tracer: stopped=1 signo=19
      mother: SIGCONT
      tracer: stopped=0 signo=5
      tracer: SIG 18
      mother: SIGSTOP
      tracer: SIG 19
      tracer: stopped=1 signo=19
      mother: SIGCONT
      tracer: stopped=0 signo=5
      tracer: SIG 18
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 589292f38530..06177e2b3917 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -817,6 +817,30 @@ static int check_kill_permission(int sig, struct siginfo *info,
 	return security_task_kill(t, info, sig, 0);
 }
 
+/**
+ * ptrace_trap_notify - schedule trap to notify ptracer
+ * @t: tracee wanting to notify tracer
+ *
+ * This function schedules sticky ptrace trap which is cleared on the next
+ * TRAP_STOP to notify ptracer of an event.  @t must have been seized by
+ * ptracer.
+ *
+ * If @t is running, STOP trap will be taken.  If already trapped, STOP
+ * trap will be eventually taken without returning to userland after the
+ * existing traps are finished by PTRACE_CONT.
+ *
+ * CONTEXT:
+ * Must be called with @task->sighand->siglock held.
+ */
+static void ptrace_trap_notify(struct task_struct *t)
+{
+	WARN_ON_ONCE(!(t->ptrace & PT_SEIZED));
+	assert_spin_locked(&t->sighand->siglock);
+
+	task_set_jobctl_pending(t, JOBCTL_TRAP_NOTIFY);
+	signal_wake_up(t, 0);
+}
+
 /*
  * Handle magic process-wide effects of stop/continue signals. Unlike
  * the signal actions, these happen immediately at signal-generation
@@ -855,7 +879,10 @@ static int prepare_signal(int sig, struct task_struct *p, int from_ancestor_ns)
 		do {
 			task_clear_jobctl_pending(t, JOBCTL_STOP_PENDING);
 			rm_from_queue(SIG_KERNEL_STOP_MASK, &t->pending);
-			wake_up_state(t, __TASK_STOPPED);
+			if (likely(!(t->ptrace & PT_SEIZED)))
+				wake_up_state(t, __TASK_STOPPED);
+			else
+				ptrace_trap_notify(t);
 		} while_each_thread(p, t);
 
 		/*
@@ -1797,8 +1824,10 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 	if (why == CLD_STOPPED && (current->jobctl & JOBCTL_STOP_PENDING))
 		gstop_done = task_participate_group_stop(current);
 
-	/* any trap clears pending STOP trap */
+	/* any trap clears pending STOP trap, STOP trap clears NOTIFY */
 	task_clear_jobctl_pending(current, JOBCTL_TRAP_STOP);
+	if (info && info->si_code >> 8 == PTRACE_EVENT_STOP)
+		task_clear_jobctl_pending(current, JOBCTL_TRAP_NOTIFY);
 
 	/* entering a trap, clear TRAPPING */
 	task_clear_jobctl_trapping(current);
@@ -1972,7 +2001,10 @@ static bool do_signal_stop(int signr)
 			if (!task_is_stopped(t) &&
 			    task_set_jobctl_pending(t, signr | gstop)) {
 				sig->group_stop_count++;
-				signal_wake_up(t, 0);
+				if (likely(!(t->ptrace & PT_SEIZED)))
+					signal_wake_up(t, 0);
+				else
+					ptrace_trap_notify(t);
 			}
 		}
 	}

commit 3544d72a0e10d0aa1c1bd59ed77a53a59cdc12f7
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jun 14 11:20:15 2011 +0200

    ptrace: implement PTRACE_SEIZE
    
    PTRACE_ATTACH implicitly issues SIGSTOP on attach which has side
    effects on tracee signal and job control states.  This patch
    implements a new ptrace request PTRACE_SEIZE which attaches a tracee
    without trapping it or affecting its signal and job control states.
    
    The usage is the same with PTRACE_ATTACH but it takes PTRACE_SEIZE_*
    flags in @data.  Currently, the only defined flag is
    PTRACE_SEIZE_DEVEL which is a temporary flag to enable PTRACE_SEIZE.
    PTRACE_SEIZE will change ptrace behaviors outside of attach itself.
    The changes will be implemented gradually and the DEVEL flag is to
    prevent programs which expect full SEIZE behavior from using it before
    all the behavior modifications are complete while allowing unit
    testing.  The flag will be removed once SEIZE behaviors are completely
    implemented.
    
    * PTRACE_SEIZE, unlike ATTACH, doesn't force tracee to trap.  After
      attaching tracee continues to run unless a trap condition occurs.
    
    * PTRACE_SEIZE doesn't affect signal or group stop state.
    
    * If PTRACE_SEIZE'd, group stop uses PTRACE_EVENT_STOP trap which uses
      exit_code of (signr | PTRACE_EVENT_STOP << 8) where signr is one of
      the stopping signals if group stop is in effect or SIGTRAP
      otherwise, and returns usual trap siginfo on PTRACE_GETSIGINFO
      instead of NULL.
    
    Seizing sets PT_SEIZED in ->ptrace of the tracee.  This flag will be
    used to determine whether new SEIZE behaviors should be enabled.
    
    Test program follows.
    
      #define PTRACE_SEIZE          0x4206
      #define PTRACE_SEIZE_DEVEL    0x80000000
    
      static const struct timespec ts100ms = { .tv_nsec = 100000000 };
      static const struct timespec ts1s = { .tv_sec = 1 };
      static const struct timespec ts3s = { .tv_sec = 3 };
    
      int main(int argc, char **argv)
      {
              pid_t tracee;
    
              tracee = fork();
              if (tracee == 0) {
                      nanosleep(&ts100ms, NULL);
                      while (1) {
                              printf("tracee: alive\n");
                              nanosleep(&ts1s, NULL);
                      }
              }
    
              if (argc > 1)
                      kill(tracee, SIGSTOP);
    
              nanosleep(&ts100ms, NULL);
    
              ptrace(PTRACE_SEIZE, tracee, NULL,
                     (void *)(unsigned long)PTRACE_SEIZE_DEVEL);
              if (argc > 1) {
                      waitid(P_PID, tracee, NULL, WSTOPPED);
                      ptrace(PTRACE_CONT, tracee, NULL, NULL);
              }
              nanosleep(&ts3s, NULL);
              printf("tracer: exiting\n");
              return 0;
      }
    
    When the above program is called w/o argument, tracee is seized while
    running and remains running.  When tracer exits, tracee continues to
    run and print out messages.
    
      # ./test-seize-simple
      tracee: alive
      tracee: alive
      tracee: alive
      tracer: exiting
      tracee: alive
      tracee: alive
    
    When called with an argument, tracee is seized from stopped state and
    continued, and returns to stopped state when tracer exits.
    
      # ./test-seize
      tracee: alive
      tracee: alive
      tracee: alive
      tracer: exiting
      # ps -el|grep test-seize
      1 T     0  4720     1  0  80   0 -   941 signal ttyS0    00:00:00 test-seize
    
    -v2: SEIZE doesn't schedule TRAP_STOP and leaves tracee running as Jan
         suggested.
    
    -v3: PTRACE_EVENT_STOP traps now report group stop state by signr.  If
         group stop is in effect the stop signal number is returned as
         part of exit_code; otherwise, SIGTRAP.  This was suggested by
         Denys and Oleg.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Jan Kratochvil <jan.kratochvil@redhat.com>
    Cc: Denys Vlasenko <vda.linux@googlemail.com>
    Cc: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index b5f55ca1f43f..589292f38530 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1873,21 +1873,26 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 	recalc_sigpending_tsk(current);
 }
 
-void ptrace_notify(int exit_code)
+static void ptrace_do_notify(int signr, int exit_code, int why)
 {
 	siginfo_t info;
 
-	BUG_ON((exit_code & (0x7f | ~0xffff)) != SIGTRAP);
-
 	memset(&info, 0, sizeof info);
-	info.si_signo = SIGTRAP;
+	info.si_signo = signr;
 	info.si_code = exit_code;
 	info.si_pid = task_pid_vnr(current);
 	info.si_uid = current_uid();
 
 	/* Let the debugger run.  */
+	ptrace_stop(exit_code, why, 1, &info);
+}
+
+void ptrace_notify(int exit_code)
+{
+	BUG_ON((exit_code & (0x7f | ~0xffff)) != SIGTRAP);
+
 	spin_lock_irq(&current->sighand->siglock);
-	ptrace_stop(exit_code, CLD_TRAPPED, 1, &info);
+	ptrace_do_notify(SIGTRAP, exit_code, CLD_TRAPPED);
 	spin_unlock_irq(&current->sighand->siglock);
 }
 
@@ -2017,7 +2022,13 @@ static bool do_signal_stop(int signr)
 /**
  * do_jobctl_trap - take care of ptrace jobctl traps
  *
- * It is currently used only to trap for group stop while ptraced.
+ * When PT_SEIZED, it's used for both group stop and explicit
+ * SEIZE/INTERRUPT traps.  Both generate PTRACE_EVENT_STOP trap with
+ * accompanying siginfo.  If stopped, lower eight bits of exit_code contain
+ * the stop signal; otherwise, %SIGTRAP.
+ *
+ * When !PT_SEIZED, it's used only for group stop trap with stop signal
+ * number as exit_code and no siginfo.
  *
  * CONTEXT:
  * Must be called with @current->sighand->siglock held, which may be
@@ -2025,11 +2036,21 @@ static bool do_signal_stop(int signr)
  */
 static void do_jobctl_trap(void)
 {
+	struct signal_struct *signal = current->signal;
 	int signr = current->jobctl & JOBCTL_STOP_SIGMASK;
 
-	WARN_ON_ONCE(!signr);
-	ptrace_stop(signr, CLD_STOPPED, 0, NULL);
-	current->exit_code = 0;
+	if (current->ptrace & PT_SEIZED) {
+		if (!signal->group_stop_count &&
+		    !(signal->flags & SIGNAL_STOP_STOPPED))
+			signr = SIGTRAP;
+		WARN_ON_ONCE(!signr);
+		ptrace_do_notify(signr, signr | (PTRACE_EVENT_STOP << 8),
+				 CLD_STOPPED);
+	} else {
+		WARN_ON_ONCE(!signr);
+		ptrace_stop(signr, CLD_STOPPED, 0, NULL);
+		current->exit_code = 0;
+	}
 }
 
 static int ptrace_signal(int signr, siginfo_t *info,

commit 73ddff2bee159ffb580bd24faf625cd5e628f5ec
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jun 14 11:20:14 2011 +0200

    job control: introduce JOBCTL_TRAP_STOP and use it for group stop trap
    
    do_signal_stop() implemented both normal group stop and trap for group
    stop while ptraced.  This approach has been enough but scheduled
    changes require trap mechanism which can be used in more generic
    manner and using group stop trap for generic trap site simplifies both
    userland visible interface and implementation.
    
    This patch adds a new jobctl flag - JOBCTL_TRAP_STOP.  When set, it
    triggers a trap site, which behaves like group stop trap, in
    get_signal_to_deliver() after checking for pending signals.  While
    ptraced, do_signal_stop() doesn't stop itself.  It initiates group
    stop if requested and schedules JOBCTL_TRAP_STOP and returns.  The
    caller - get_signal_to_deliver() - is responsible for checking whether
    TRAP_STOP is pending afterwards and handling it.
    
    ptrace_attach() is updated to use JOBCTL_TRAP_STOP instead of
    JOBCTL_STOP_PENDING and __ptrace_unlink() to clear all pending trap
    bits and TRAPPING so that TRAP_STOP and future trap bits don't linger
    after detach.
    
    While at it, add proper function comment to do_signal_stop() and make
    it return bool.
    
    -v2: __ptrace_unlink() updated to clear JOBCTL_TRAP_MASK and TRAPPING
         instead of JOBCTL_PENDING_MASK.  This avoids accidentally
         clearing JOBCTL_STOP_CONSUME.  Spotted by Oleg.
    
    -v3: do_signal_stop() updated to return %false without dropping
         siglock while ptraced and TRAP_STOP check moved inside for(;;)
         loop after group stop participation.  This avoids unnecessary
         relocking and also will help avoiding unnecessary traps by
         consuming group stop before handling pending traps.
    
    -v4: Jobctl trap handling moved into a separate function -
         do_jobctl_trap().
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index c99b8b5c0be7..b5f55ca1f43f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -266,7 +266,7 @@ bool task_set_jobctl_pending(struct task_struct *task, unsigned int mask)
  * CONTEXT:
  * Must be called with @task->sighand->siglock held.
  */
-static void task_clear_jobctl_trapping(struct task_struct *task)
+void task_clear_jobctl_trapping(struct task_struct *task)
 {
 	if (unlikely(task->jobctl & JOBCTL_TRAPPING)) {
 		task->jobctl &= ~JOBCTL_TRAPPING;
@@ -1790,13 +1790,16 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 	/*
 	 * If @why is CLD_STOPPED, we're trapping to participate in a group
 	 * stop.  Do the bookkeeping.  Note that if SIGCONT was delievered
-	 * while siglock was released for the arch hook, PENDING could be
-	 * clear now.  We act as if SIGCONT is received after TASK_TRACED
-	 * is entered - ignore it.
+	 * across siglock relocks since INTERRUPT was scheduled, PENDING
+	 * could be clear now.  We act as if SIGCONT is received after
+	 * TASK_TRACED is entered - ignore it.
 	 */
 	if (why == CLD_STOPPED && (current->jobctl & JOBCTL_STOP_PENDING))
 		gstop_done = task_participate_group_stop(current);
 
+	/* any trap clears pending STOP trap */
+	task_clear_jobctl_pending(current, JOBCTL_TRAP_STOP);
+
 	/* entering a trap, clear TRAPPING */
 	task_clear_jobctl_trapping(current);
 
@@ -1888,13 +1891,30 @@ void ptrace_notify(int exit_code)
 	spin_unlock_irq(&current->sighand->siglock);
 }
 
-/*
- * This performs the stopping for SIGSTOP and other stop signals.
- * We have to stop all threads in the thread group.
- * Returns non-zero if we've actually stopped and released the siglock.
- * Returns zero if we didn't stop and still hold the siglock.
+/**
+ * do_signal_stop - handle group stop for SIGSTOP and other stop signals
+ * @signr: signr causing group stop if initiating
+ *
+ * If %JOBCTL_STOP_PENDING is not set yet, initiate group stop with @signr
+ * and participate in it.  If already set, participate in the existing
+ * group stop.  If participated in a group stop (and thus slept), %true is
+ * returned with siglock released.
+ *
+ * If ptraced, this function doesn't handle stop itself.  Instead,
+ * %JOBCTL_TRAP_STOP is scheduled and %false is returned with siglock
+ * untouched.  The caller must ensure that INTERRUPT trap handling takes
+ * places afterwards.
+ *
+ * CONTEXT:
+ * Must be called with @current->sighand->siglock held, which is released
+ * on %true return.
+ *
+ * RETURNS:
+ * %false if group stop is already cancelled or ptrace trap is scheduled.
+ * %true if participated in group stop.
  */
-static int do_signal_stop(int signr)
+static bool do_signal_stop(int signr)
+	__releases(&current->sighand->siglock)
 {
 	struct signal_struct *sig = current->signal;
 
@@ -1907,7 +1927,7 @@ static int do_signal_stop(int signr)
 
 		if (!likely(current->jobctl & JOBCTL_STOP_DEQUEUED) ||
 		    unlikely(signal_group_exit(sig)))
-			return 0;
+			return false;
 		/*
 		 * There is no group stop already in progress.  We must
 		 * initiate one now.
@@ -1951,7 +1971,7 @@ static int do_signal_stop(int signr)
 			}
 		}
 	}
-retry:
+
 	if (likely(!task_ptrace(current))) {
 		int notify = 0;
 
@@ -1983,27 +2003,33 @@ static int do_signal_stop(int signr)
 
 		/* Now we don't run again until woken by SIGCONT or SIGKILL */
 		schedule();
-
-		spin_lock_irq(&current->sighand->siglock);
+		return true;
 	} else {
-		ptrace_stop(current->jobctl & JOBCTL_STOP_SIGMASK,
-			    CLD_STOPPED, 0, NULL);
-		current->exit_code = 0;
-	}
-
-	/*
-	 * JOBCTL_STOP_PENDING could be set if another group stop has
-	 * started since being woken up or ptrace wants us to transit
-	 * between TASK_STOPPED and TRACED.  Retry group stop.
-	 */
-	if (current->jobctl & JOBCTL_STOP_PENDING) {
-		WARN_ON_ONCE(!(current->jobctl & JOBCTL_STOP_SIGMASK));
-		goto retry;
+		/*
+		 * While ptraced, group stop is handled by STOP trap.
+		 * Schedule it and let the caller deal with it.
+		 */
+		task_set_jobctl_pending(current, JOBCTL_TRAP_STOP);
+		return false;
 	}
+}
 
-	spin_unlock_irq(&current->sighand->siglock);
+/**
+ * do_jobctl_trap - take care of ptrace jobctl traps
+ *
+ * It is currently used only to trap for group stop while ptraced.
+ *
+ * CONTEXT:
+ * Must be called with @current->sighand->siglock held, which may be
+ * released and re-acquired before returning with intervening sleep.
+ */
+static void do_jobctl_trap(void)
+{
+	int signr = current->jobctl & JOBCTL_STOP_SIGMASK;
 
-	return 1;
+	WARN_ON_ONCE(!signr);
+	ptrace_stop(signr, CLD_STOPPED, 0, NULL);
+	current->exit_code = 0;
 }
 
 static int ptrace_signal(int signr, siginfo_t *info,
@@ -2110,6 +2136,12 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		    do_signal_stop(0))
 			goto relock;
 
+		if (unlikely(current->jobctl & JOBCTL_TRAP_MASK)) {
+			do_jobctl_trap();
+			spin_unlock_irq(&sighand->siglock);
+			goto relock;
+		}
+
 		signr = dequeue_signal(current, &current->blocked, info);
 
 		if (!signr)

commit ada9c93312f7ec49514c68c211595ce2601cebae
Author: Randy Dunlap <randy.dunlap@oracle.com>
Date:   Tue Jun 14 15:50:11 2011 -0700

    signal.c: fix kernel-doc notation
    
    Fix kernel-doc warnings in signal.c:
    
      Warning(kernel/signal.c:2374): No description found for parameter 'nset'
      Warning(kernel/signal.c:2374): Excess function parameter 'set' description in 'sys_rt_sigprocmask'
    
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 86c32b884f8e..ff7678603328 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2365,7 +2365,7 @@ int sigprocmask(int how, sigset_t *set, sigset_t *oldset)
 /**
  *  sys_rt_sigprocmask - change the list of currently blocked signals
  *  @how: whether to add, remove, or set signals
- *  @set: stores pending signals
+ *  @nset: stores pending signals
  *  @oset: previous value of signal mask if non-null
  *  @sigsetsize: size of sigset_t type
  */

commit dd1d6772692316fe35094085c5e4d9a370ad3462
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jun 2 11:14:00 2011 +0200

    signal: remove three noop tracehooks
    
    Remove the following three noop tracehooks in signals.c.
    
    * tracehook_force_sigpending()
    * tracehook_get_signal()
    * tracehook_finish_jctl()
    
    The code area is about to be updated and these hooks don't do anything
    other than obfuscating the logic.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 172a4c79f12c..c99b8b5c0be7 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -150,9 +150,7 @@ void recalc_sigpending_and_wake(struct task_struct *t)
 
 void recalc_sigpending(void)
 {
-	if (unlikely(tracehook_force_sigpending()))
-		set_thread_flag(TIF_SIGPENDING);
-	else if (!recalc_sigpending_tsk(current) && !freezing(current))
+	if (!recalc_sigpending_tsk(current) && !freezing(current))
 		clear_thread_flag(TIF_SIGPENDING);
 
 }
@@ -2005,8 +2003,6 @@ static int do_signal_stop(int signr)
 
 	spin_unlock_irq(&current->sighand->siglock);
 
-	tracehook_finish_jctl();
-
 	return 1;
 }
 
@@ -2109,37 +2105,25 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 
 	for (;;) {
 		struct k_sigaction *ka;
-		/*
-		 * Tracing can induce an artificial signal and choose sigaction.
-		 * The return value in @signr determines the default action,
-		 * but @info->si_signo is the signal number we will report.
-		 */
-		signr = tracehook_get_signal(current, regs, info, return_ka);
-		if (unlikely(signr < 0))
+
+		if (unlikely(current->jobctl & JOBCTL_STOP_PENDING) &&
+		    do_signal_stop(0))
 			goto relock;
-		if (unlikely(signr != 0))
-			ka = return_ka;
-		else {
-			if (unlikely(current->jobctl & JOBCTL_STOP_PENDING) &&
-			    do_signal_stop(0))
-				goto relock;
 
-			signr = dequeue_signal(current, &current->blocked,
-					       info);
+		signr = dequeue_signal(current, &current->blocked, info);
 
-			if (!signr)
-				break; /* will return 0 */
+		if (!signr)
+			break; /* will return 0 */
 
-			if (signr != SIGKILL) {
-				signr = ptrace_signal(signr, info,
-						      regs, cookie);
-				if (!signr)
-					continue;
-			}
-
-			ka = &sighand->action[signr-1];
+		if (signr != SIGKILL) {
+			signr = ptrace_signal(signr, info,
+					      regs, cookie);
+			if (!signr)
+				continue;
 		}
 
+		ka = &sighand->action[signr-1];
+
 		/* Trace actually delivered signals. */
 		trace_signal_deliver(signr, info, ka);
 

commit 62c124ff3bcdb414af635c2bf822c9e4f2a5abfa
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jun 2 11:14:00 2011 +0200

    ptrace: use bit_waitqueue for TRAPPING instead of wait_chldexit
    
    ptracer->signal->wait_chldexit was used to wait for TRAPPING; however,
    ->wait_chldexit was already complicated with waker-side filtering
    without adding TRAPPING wait on top of it.  Also, it unnecessarily
    made TRAPPING clearing depend on the current ptrace relationship - if
    the ptracee is detached, wakeup is lost.
    
    There is no reason to use signal->wait_chldexit here.  We're just
    waiting for JOBCTL_TRAPPING bit to clear and given the relatively
    infrequent use of ptrace, bit_waitqueue can serve it perfectly.
    
    This patch makes JOBCTL_TRAPPING wait use bit_waitqueue instead of
    signal->wait_chldexit.
    
    -v2: Use JOBCTL_*_BIT macros instead of ilog2() as suggested by Linus.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9ab91c516c3f..172a4c79f12c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -272,8 +272,7 @@ static void task_clear_jobctl_trapping(struct task_struct *task)
 {
 	if (unlikely(task->jobctl & JOBCTL_TRAPPING)) {
 		task->jobctl &= ~JOBCTL_TRAPPING;
-		__wake_up_sync_key(&task->parent->signal->wait_chldexit,
-				   TASK_UNINTERRUPTIBLE, 1, task);
+		wake_up_bit(&task->jobctl, JOBCTL_TRAPPING_BIT);
 	}
 }
 

commit 7dd3db54e77d21eb95e145f19ba53f68250d0e73
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jun 2 11:14:00 2011 +0200

    job control: introduce task_set_jobctl_pending()
    
    task->jobctl currently hosts JOBCTL_STOP_PENDING and will host TRAP
    pending bits too.  Setting pending conditions on a dying task may make
    the task unkillable.  Currently, each setting site is responsible for
    checking for the condition but with to-be-added job control traps this
    becomes too fragile.
    
    This patch adds task_set_jobctl_pending() which should be used when
    setting task->jobctl bits to schedule a stop or trap.  The function
    performs the followings to ease setting pending bits.
    
    * Sanity checks.
    
    * If fatal signal is pending or PF_EXITING is set, no bit is set.
    
    * STOP_SIGMASK is automatically cleared if new value is being set.
    
    do_signal_stop() and ptrace_attach() are updated to use
    task_set_jobctl_pending() instead of setting STOP_PENDING explicitly.
    The surrounding structures around setting are changed to fit
    task_set_jobctl_pending() better but there should be no userland
    visible behavior difference.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 637a171b65b6..9ab91c516c3f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -223,6 +223,39 @@ static inline void print_dropped_signal(int sig)
 				current->comm, current->pid, sig);
 }
 
+/**
+ * task_set_jobctl_pending - set jobctl pending bits
+ * @task: target task
+ * @mask: pending bits to set
+ *
+ * Clear @mask from @task->jobctl.  @mask must be subset of
+ * %JOBCTL_PENDING_MASK | %JOBCTL_STOP_CONSUME | %JOBCTL_STOP_SIGMASK |
+ * %JOBCTL_TRAPPING.  If stop signo is being set, the existing signo is
+ * cleared.  If @task is already being killed or exiting, this function
+ * becomes noop.
+ *
+ * CONTEXT:
+ * Must be called with @task->sighand->siglock held.
+ *
+ * RETURNS:
+ * %true if @mask is set, %false if made noop because @task was dying.
+ */
+bool task_set_jobctl_pending(struct task_struct *task, unsigned int mask)
+{
+	BUG_ON(mask & ~(JOBCTL_PENDING_MASK | JOBCTL_STOP_CONSUME |
+			JOBCTL_STOP_SIGMASK | JOBCTL_TRAPPING));
+	BUG_ON((mask & JOBCTL_TRAPPING) && !(mask & JOBCTL_PENDING_MASK));
+
+	if (unlikely(fatal_signal_pending(task) || (task->flags & PF_EXITING)))
+		return false;
+
+	if (mask & JOBCTL_STOP_SIGMASK)
+		task->jobctl &= ~JOBCTL_STOP_SIGMASK;
+
+	task->jobctl |= mask;
+	return true;
+}
+
 /**
  * task_clear_jobctl_trapping - clear jobctl trapping bit
  * @task: target task
@@ -1902,19 +1935,20 @@ static int do_signal_stop(int signr)
 		else
 			WARN_ON_ONCE(!task_ptrace(current));
 
-		current->jobctl &= ~JOBCTL_STOP_SIGMASK;
-		current->jobctl |= signr | gstop;
-		sig->group_stop_count = 1;
+		sig->group_stop_count = 0;
+
+		if (task_set_jobctl_pending(current, signr | gstop))
+			sig->group_stop_count++;
+
 		for (t = next_thread(current); t != current;
 		     t = next_thread(t)) {
-			t->jobctl &= ~JOBCTL_STOP_SIGMASK;
 			/*
 			 * Setting state to TASK_STOPPED for a group
 			 * stop is always done with the siglock held,
 			 * so this check has no races.
 			 */
-			if (!(t->flags & PF_EXITING) && !task_is_stopped(t)) {
-				t->jobctl |= signr | gstop;
+			if (!task_is_stopped(t) &&
+			    task_set_jobctl_pending(t, signr | gstop)) {
 				sig->group_stop_count++;
 				signal_wake_up(t, 0);
 			}

commit 6dfca32984237a8a011b5bf367e53341a265b2a4
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jun 2 11:14:00 2011 +0200

    job control: make task_clear_jobctl_pending() clear TRAPPING automatically
    
    JOBCTL_TRAPPING indicates that ptracer is waiting for tracee to
    (re)transit into TRACED.  task_clear_jobctl_pending() must be called
    when either tracee enters TRACED or the transition is cancelled for
    some reason.  The former is achieved by explicitly calling
    task_clear_jobctl_pending() in ptrace_stop() and the latter by calling
    it at the end of do_signal_stop().
    
    Calling task_clear_jobctl_trapping() at the end of do_signal_stop()
    limits the scope TRAPPING can be used and is fragile in that seemingly
    unrelated changes to tracee's control flow can lead to stuck TRAPPING.
    
    We already have task_clear_jobctl_pending() calls on those cancelling
    events to clear JOBCTL_STOP_PENDING.  Cancellations can be handled by
    making those call sites use JOBCTL_PENDING_MASK instead and updating
    task_clear_jobctl_pending() such that task_clear_jobctl_trapping() is
    called automatically if no stop/trap is pending.
    
    This patch makes the above changes and removes the fallback
    task_clear_jobctl_trapping() call from do_signal_stop().
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 288d952fa3b8..637a171b65b6 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -253,6 +253,9 @@ static void task_clear_jobctl_trapping(struct task_struct *task)
  * %JOBCTL_PENDING_MASK.  If %JOBCTL_STOP_PENDING is being cleared, other
  * STOP bits are cleared together.
  *
+ * If clearing of @mask leaves no stop or trap pending, this function calls
+ * task_clear_jobctl_trapping().
+ *
  * CONTEXT:
  * Must be called with @task->sighand->siglock held.
  */
@@ -264,6 +267,9 @@ void task_clear_jobctl_pending(struct task_struct *task, unsigned int mask)
 		mask |= JOBCTL_STOP_CONSUME | JOBCTL_STOP_DEQUEUED;
 
 	task->jobctl &= ~mask;
+
+	if (!(task->jobctl & JOBCTL_PENDING_MASK))
+		task_clear_jobctl_trapping(task);
 }
 
 /**
@@ -933,7 +939,7 @@ static void complete_signal(int sig, struct task_struct *p, int group)
 			signal->group_stop_count = 0;
 			t = p;
 			do {
-				task_clear_jobctl_pending(t, JOBCTL_STOP_PENDING);
+				task_clear_jobctl_pending(t, JOBCTL_PENDING_MASK);
 				sigaddset(&t->pending.signal, SIGKILL);
 				signal_wake_up(t, 1);
 			} while_each_thread(p, t);
@@ -1168,7 +1174,7 @@ int zap_other_threads(struct task_struct *p)
 	p->signal->group_stop_count = 0;
 
 	while_each_thread(p, t) {
-		task_clear_jobctl_pending(t, JOBCTL_STOP_PENDING);
+		task_clear_jobctl_pending(t, JOBCTL_PENDING_MASK);
 		count++;
 
 		/* Don't bother with already dead threads */
@@ -1964,9 +1970,6 @@ static int do_signal_stop(int signr)
 		goto retry;
 	}
 
-	/* PTRACE_ATTACH might have raced with task killing, clear trapping */
-	task_clear_jobctl_trapping(current);
-
 	spin_unlock_irq(&current->sighand->siglock);
 
 	tracehook_finish_jctl();

commit 3759a0d94c18764247b66511d1038f2b93aa95de
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jun 2 11:14:00 2011 +0200

    job control: introduce JOBCTL_PENDING_MASK and task_clear_jobctl_pending()
    
    This patch introduces JOBCTL_PENDING_MASK and replaces
    task_clear_jobctl_stop_pending() with task_clear_jobctl_pending()
    which takes an extra @mask argument.
    
    JOBCTL_PENDING_MASK is currently equal to JOBCTL_STOP_PENDING but
    future patches will add more bits.  recalc_sigpending_tsk() is updated
    to use JOBCTL_PENDING_MASK instead.
    
    task_clear_jobctl_pending() takes @mask which in subset of
    JOBCTL_PENDING_MASK and clears the relevant jobctl bits.  If
    JOBCTL_STOP_PENDING is set, other STOP bits are cleared together.  All
    task_clear_jobctl_stop_pending() users are updated to call
    task_clear_jobctl_pending() with JOBCTL_STOP_PENDING which is
    functionally identical to task_clear_jobctl_stop_pending().
    
    This patch doesn't cause any functional change.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 62a6c3bb9f0d..288d952fa3b8 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -124,7 +124,7 @@ static inline int has_pending_signals(sigset_t *signal, sigset_t *blocked)
 
 static int recalc_sigpending_tsk(struct task_struct *t)
 {
-	if ((t->jobctl & JOBCTL_STOP_PENDING) ||
+	if ((t->jobctl & JOBCTL_PENDING_MASK) ||
 	    PENDING(&t->pending, &t->blocked) ||
 	    PENDING(&t->signal->shared_pending, &t->blocked)) {
 		set_tsk_thread_flag(t, TIF_SIGPENDING);
@@ -245,18 +245,25 @@ static void task_clear_jobctl_trapping(struct task_struct *task)
 }
 
 /**
- * task_clear_jobctl_stop_pending - clear pending group stop
+ * task_clear_jobctl_pending - clear jobctl pending bits
  * @task: target task
+ * @mask: pending bits to clear
  *
- * Clear group stop states for @task.
+ * Clear @mask from @task->jobctl.  @mask must be subset of
+ * %JOBCTL_PENDING_MASK.  If %JOBCTL_STOP_PENDING is being cleared, other
+ * STOP bits are cleared together.
  *
  * CONTEXT:
  * Must be called with @task->sighand->siglock held.
  */
-void task_clear_jobctl_stop_pending(struct task_struct *task)
+void task_clear_jobctl_pending(struct task_struct *task, unsigned int mask)
 {
-	task->jobctl &= ~(JOBCTL_STOP_PENDING | JOBCTL_STOP_CONSUME |
-			  JOBCTL_STOP_DEQUEUED);
+	BUG_ON(mask & ~JOBCTL_PENDING_MASK);
+
+	if (mask & JOBCTL_STOP_PENDING)
+		mask |= JOBCTL_STOP_CONSUME | JOBCTL_STOP_DEQUEUED;
+
+	task->jobctl &= ~mask;
 }
 
 /**
@@ -282,7 +289,7 @@ static bool task_participate_group_stop(struct task_struct *task)
 
 	WARN_ON_ONCE(!(task->jobctl & JOBCTL_STOP_PENDING));
 
-	task_clear_jobctl_stop_pending(task);
+	task_clear_jobctl_pending(task, JOBCTL_STOP_PENDING);
 
 	if (!consume)
 		return false;
@@ -810,7 +817,7 @@ static int prepare_signal(int sig, struct task_struct *p, int from_ancestor_ns)
 		rm_from_queue(SIG_KERNEL_STOP_MASK, &signal->shared_pending);
 		t = p;
 		do {
-			task_clear_jobctl_stop_pending(t);
+			task_clear_jobctl_pending(t, JOBCTL_STOP_PENDING);
 			rm_from_queue(SIG_KERNEL_STOP_MASK, &t->pending);
 			wake_up_state(t, __TASK_STOPPED);
 		} while_each_thread(p, t);
@@ -926,7 +933,7 @@ static void complete_signal(int sig, struct task_struct *p, int group)
 			signal->group_stop_count = 0;
 			t = p;
 			do {
-				task_clear_jobctl_stop_pending(t);
+				task_clear_jobctl_pending(t, JOBCTL_STOP_PENDING);
 				sigaddset(&t->pending.signal, SIGKILL);
 				signal_wake_up(t, 1);
 			} while_each_thread(p, t);
@@ -1161,7 +1168,7 @@ int zap_other_threads(struct task_struct *p)
 	p->signal->group_stop_count = 0;
 
 	while_each_thread(p, t) {
-		task_clear_jobctl_stop_pending(t);
+		task_clear_jobctl_pending(t, JOBCTL_STOP_PENDING);
 		count++;
 
 		/* Don't bother with already dead threads */

commit 81be24b8cdeb69e62f9d1b6b425fd9ffdd37f581
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jun 2 11:13:59 2011 +0200

    ptrace: relocate set_current_state(TASK_TRACED) in ptrace_stop()
    
    In ptrace_stop(), after arch hook is done, the task state and jobctl
    bits are updated while holding siglock.  The ordering requirement
    there is that TASK_TRACED is set before JOBCTL_TRAPPING is cleared to
    prevent ptracer waiting on TRAPPING doesn't end up waking up TRACED is
    actually set and sees TASK_RUNNING in wait(2).
    
    Move set_current_state(TASK_TRACED) to the top of the block and
    reorganize comments.  This makes the ordering more obvious
    (TASK_TRACED before other updates) and helps future updates to group
    stop participation.
    
    This patch doesn't cause any functional change.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index ab6851c06461..62a6c3bb9f0d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1732,6 +1732,18 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 			return;
 	}
 
+	/*
+	 * We're committing to trapping.  TRACED should be visible before
+	 * TRAPPING is cleared; otherwise, the tracer might fail do_wait().
+	 * Also, transition to TRACED and updates to ->jobctl should be
+	 * atomic with respect to siglock and should be done after the arch
+	 * hook as siglock is released and regrabbed across it.
+	 */
+	set_current_state(TASK_TRACED);
+
+	current->last_siginfo = info;
+	current->exit_code = exit_code;
+
 	/*
 	 * If @why is CLD_STOPPED, we're trapping to participate in a group
 	 * stop.  Do the bookkeeping.  Note that if SIGCONT was delievered
@@ -1742,21 +1754,7 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 	if (why == CLD_STOPPED && (current->jobctl & JOBCTL_STOP_PENDING))
 		gstop_done = task_participate_group_stop(current);
 
-	current->last_siginfo = info;
-	current->exit_code = exit_code;
-
-	/*
-	 * TRACED should be visible before TRAPPING is cleared; otherwise,
-	 * the tracer might fail do_wait().
-	 */
-	set_current_state(TASK_TRACED);
-
-	/*
-	 * We're committing to trapping.  Clearing JOBCTL_TRAPPING and
-	 * transition to TASK_TRACED should be atomic with respect to
-	 * siglock.  This should be done after the arch hook as siglock is
-	 * released and regrabbed across it.
-	 */
+	/* entering a trap, clear TRAPPING */
 	task_clear_jobctl_trapping(current);
 
 	spin_unlock_irq(&current->sighand->siglock);

commit a8f072c1d624a627b67f2ace2f0c25d856ef4e54
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Jun 2 11:13:59 2011 +0200

    job control: rename signal->group_stop and flags to jobctl and update them
    
    signal->group_stop currently hosts mostly group stop related flags;
    however, it's gonna be used for wider purposes and the GROUP_STOP_
    flag prefix becomes confusing.  Rename signal->group_stop to
    signal->jobctl and rename all GROUP_STOP_* flags to JOBCTL_*.
    
    Bit position macros JOBCTL_*_BIT are defined and JOBCTL_* flags are
    defined in terms of them to allow using bitops later.
    
    While at it, reassign JOBCTL_TRAPPING to bit 22 to better accomodate
    future additions.
    
    This doesn't cause any functional change.
    
    -v2: JOBCTL_*_BIT macros added as suggested by Linus.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 86c32b884f8e..ab6851c06461 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -124,7 +124,7 @@ static inline int has_pending_signals(sigset_t *signal, sigset_t *blocked)
 
 static int recalc_sigpending_tsk(struct task_struct *t)
 {
-	if ((t->group_stop & GROUP_STOP_PENDING) ||
+	if ((t->jobctl & JOBCTL_STOP_PENDING) ||
 	    PENDING(&t->pending, &t->blocked) ||
 	    PENDING(&t->signal->shared_pending, &t->blocked)) {
 		set_tsk_thread_flag(t, TIF_SIGPENDING);
@@ -224,27 +224,28 @@ static inline void print_dropped_signal(int sig)
 }
 
 /**
- * task_clear_group_stop_trapping - clear group stop trapping bit
+ * task_clear_jobctl_trapping - clear jobctl trapping bit
  * @task: target task
  *
- * If GROUP_STOP_TRAPPING is set, a ptracer is waiting for us.  Clear it
- * and wake up the ptracer.  Note that we don't need any further locking.
- * @task->siglock guarantees that @task->parent points to the ptracer.
+ * If JOBCTL_TRAPPING is set, a ptracer is waiting for us to enter TRACED.
+ * Clear it and wake up the ptracer.  Note that we don't need any further
+ * locking.  @task->siglock guarantees that @task->parent points to the
+ * ptracer.
  *
  * CONTEXT:
  * Must be called with @task->sighand->siglock held.
  */
-static void task_clear_group_stop_trapping(struct task_struct *task)
+static void task_clear_jobctl_trapping(struct task_struct *task)
 {
-	if (unlikely(task->group_stop & GROUP_STOP_TRAPPING)) {
-		task->group_stop &= ~GROUP_STOP_TRAPPING;
+	if (unlikely(task->jobctl & JOBCTL_TRAPPING)) {
+		task->jobctl &= ~JOBCTL_TRAPPING;
 		__wake_up_sync_key(&task->parent->signal->wait_chldexit,
 				   TASK_UNINTERRUPTIBLE, 1, task);
 	}
 }
 
 /**
- * task_clear_group_stop_pending - clear pending group stop
+ * task_clear_jobctl_stop_pending - clear pending group stop
  * @task: target task
  *
  * Clear group stop states for @task.
@@ -252,19 +253,19 @@ static void task_clear_group_stop_trapping(struct task_struct *task)
  * CONTEXT:
  * Must be called with @task->sighand->siglock held.
  */
-void task_clear_group_stop_pending(struct task_struct *task)
+void task_clear_jobctl_stop_pending(struct task_struct *task)
 {
-	task->group_stop &= ~(GROUP_STOP_PENDING | GROUP_STOP_CONSUME |
-			      GROUP_STOP_DEQUEUED);
+	task->jobctl &= ~(JOBCTL_STOP_PENDING | JOBCTL_STOP_CONSUME |
+			  JOBCTL_STOP_DEQUEUED);
 }
 
 /**
  * task_participate_group_stop - participate in a group stop
  * @task: task participating in a group stop
  *
- * @task has GROUP_STOP_PENDING set and is participating in a group stop.
+ * @task has %JOBCTL_STOP_PENDING set and is participating in a group stop.
  * Group stop states are cleared and the group stop count is consumed if
- * %GROUP_STOP_CONSUME was set.  If the consumption completes the group
+ * %JOBCTL_STOP_CONSUME was set.  If the consumption completes the group
  * stop, the appropriate %SIGNAL_* flags are set.
  *
  * CONTEXT:
@@ -277,11 +278,11 @@ void task_clear_group_stop_pending(struct task_struct *task)
 static bool task_participate_group_stop(struct task_struct *task)
 {
 	struct signal_struct *sig = task->signal;
-	bool consume = task->group_stop & GROUP_STOP_CONSUME;
+	bool consume = task->jobctl & JOBCTL_STOP_CONSUME;
 
-	WARN_ON_ONCE(!(task->group_stop & GROUP_STOP_PENDING));
+	WARN_ON_ONCE(!(task->jobctl & JOBCTL_STOP_PENDING));
 
-	task_clear_group_stop_pending(task);
+	task_clear_jobctl_stop_pending(task);
 
 	if (!consume)
 		return false;
@@ -604,7 +605,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 		 * is to alert stop-signal processing code when another
 		 * processor has come along and cleared the flag.
 		 */
-		current->group_stop |= GROUP_STOP_DEQUEUED;
+		current->jobctl |= JOBCTL_STOP_DEQUEUED;
 	}
 	if ((info->si_code & __SI_MASK) == __SI_TIMER && info->si_sys_private) {
 		/*
@@ -809,7 +810,7 @@ static int prepare_signal(int sig, struct task_struct *p, int from_ancestor_ns)
 		rm_from_queue(SIG_KERNEL_STOP_MASK, &signal->shared_pending);
 		t = p;
 		do {
-			task_clear_group_stop_pending(t);
+			task_clear_jobctl_stop_pending(t);
 			rm_from_queue(SIG_KERNEL_STOP_MASK, &t->pending);
 			wake_up_state(t, __TASK_STOPPED);
 		} while_each_thread(p, t);
@@ -925,7 +926,7 @@ static void complete_signal(int sig, struct task_struct *p, int group)
 			signal->group_stop_count = 0;
 			t = p;
 			do {
-				task_clear_group_stop_pending(t);
+				task_clear_jobctl_stop_pending(t);
 				sigaddset(&t->pending.signal, SIGKILL);
 				signal_wake_up(t, 1);
 			} while_each_thread(p, t);
@@ -1160,7 +1161,7 @@ int zap_other_threads(struct task_struct *p)
 	p->signal->group_stop_count = 0;
 
 	while_each_thread(p, t) {
-		task_clear_group_stop_pending(t);
+		task_clear_jobctl_stop_pending(t);
 		count++;
 
 		/* Don't bother with already dead threads */
@@ -1738,7 +1739,7 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 	 * clear now.  We act as if SIGCONT is received after TASK_TRACED
 	 * is entered - ignore it.
 	 */
-	if (why == CLD_STOPPED && (current->group_stop & GROUP_STOP_PENDING))
+	if (why == CLD_STOPPED && (current->jobctl & JOBCTL_STOP_PENDING))
 		gstop_done = task_participate_group_stop(current);
 
 	current->last_siginfo = info;
@@ -1751,12 +1752,12 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 	set_current_state(TASK_TRACED);
 
 	/*
-	 * We're committing to trapping.  Clearing GROUP_STOP_TRAPPING and
+	 * We're committing to trapping.  Clearing JOBCTL_TRAPPING and
 	 * transition to TASK_TRACED should be atomic with respect to
-	 * siglock.  This hsould be done after the arch hook as siglock is
+	 * siglock.  This should be done after the arch hook as siglock is
 	 * released and regrabbed across it.
 	 */
-	task_clear_group_stop_trapping(current);
+	task_clear_jobctl_trapping(current);
 
 	spin_unlock_irq(&current->sighand->siglock);
 	read_lock(&tasklist_lock);
@@ -1792,9 +1793,9 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 		 *
 		 * If @gstop_done, the ptracer went away between group stop
 		 * completion and here.  During detach, it would have set
-		 * GROUP_STOP_PENDING on us and we'll re-enter TASK_STOPPED
-		 * in do_signal_stop() on return, so notifying the real
-		 * parent of the group stop completion is enough.
+		 * JOBCTL_STOP_PENDING on us and we'll re-enter
+		 * TASK_STOPPED in do_signal_stop() on return, so notifying
+		 * the real parent of the group stop completion is enough.
 		 */
 		if (gstop_done)
 			do_notify_parent_cldstop(current, false, why);
@@ -1856,14 +1857,14 @@ static int do_signal_stop(int signr)
 {
 	struct signal_struct *sig = current->signal;
 
-	if (!(current->group_stop & GROUP_STOP_PENDING)) {
-		unsigned int gstop = GROUP_STOP_PENDING | GROUP_STOP_CONSUME;
+	if (!(current->jobctl & JOBCTL_STOP_PENDING)) {
+		unsigned int gstop = JOBCTL_STOP_PENDING | JOBCTL_STOP_CONSUME;
 		struct task_struct *t;
 
-		/* signr will be recorded in task->group_stop for retries */
-		WARN_ON_ONCE(signr & ~GROUP_STOP_SIGMASK);
+		/* signr will be recorded in task->jobctl for retries */
+		WARN_ON_ONCE(signr & ~JOBCTL_STOP_SIGMASK);
 
-		if (!likely(current->group_stop & GROUP_STOP_DEQUEUED) ||
+		if (!likely(current->jobctl & JOBCTL_STOP_DEQUEUED) ||
 		    unlikely(signal_group_exit(sig)))
 			return 0;
 		/*
@@ -1890,19 +1891,19 @@ static int do_signal_stop(int signr)
 		else
 			WARN_ON_ONCE(!task_ptrace(current));
 
-		current->group_stop &= ~GROUP_STOP_SIGMASK;
-		current->group_stop |= signr | gstop;
+		current->jobctl &= ~JOBCTL_STOP_SIGMASK;
+		current->jobctl |= signr | gstop;
 		sig->group_stop_count = 1;
 		for (t = next_thread(current); t != current;
 		     t = next_thread(t)) {
-			t->group_stop &= ~GROUP_STOP_SIGMASK;
+			t->jobctl &= ~JOBCTL_STOP_SIGMASK;
 			/*
 			 * Setting state to TASK_STOPPED for a group
 			 * stop is always done with the siglock held,
 			 * so this check has no races.
 			 */
 			if (!(t->flags & PF_EXITING) && !task_is_stopped(t)) {
-				t->group_stop |= signr | gstop;
+				t->jobctl |= signr | gstop;
 				sig->group_stop_count++;
 				signal_wake_up(t, 0);
 			}
@@ -1943,23 +1944,23 @@ static int do_signal_stop(int signr)
 
 		spin_lock_irq(&current->sighand->siglock);
 	} else {
-		ptrace_stop(current->group_stop & GROUP_STOP_SIGMASK,
+		ptrace_stop(current->jobctl & JOBCTL_STOP_SIGMASK,
 			    CLD_STOPPED, 0, NULL);
 		current->exit_code = 0;
 	}
 
 	/*
-	 * GROUP_STOP_PENDING could be set if another group stop has
+	 * JOBCTL_STOP_PENDING could be set if another group stop has
 	 * started since being woken up or ptrace wants us to transit
 	 * between TASK_STOPPED and TRACED.  Retry group stop.
 	 */
-	if (current->group_stop & GROUP_STOP_PENDING) {
-		WARN_ON_ONCE(!(current->group_stop & GROUP_STOP_SIGMASK));
+	if (current->jobctl & JOBCTL_STOP_PENDING) {
+		WARN_ON_ONCE(!(current->jobctl & JOBCTL_STOP_SIGMASK));
 		goto retry;
 	}
 
 	/* PTRACE_ATTACH might have raced with task killing, clear trapping */
-	task_clear_group_stop_trapping(current);
+	task_clear_jobctl_trapping(current);
 
 	spin_unlock_irq(&current->sighand->siglock);
 
@@ -2078,8 +2079,8 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		if (unlikely(signr != 0))
 			ka = return_ka;
 		else {
-			if (unlikely(current->group_stop &
-				     GROUP_STOP_PENDING) && do_signal_stop(0))
+			if (unlikely(current->jobctl & JOBCTL_STOP_PENDING) &&
+			    do_signal_stop(0))
 				goto relock;
 
 			signr = dequeue_signal(current, &current->blocked,
@@ -2253,7 +2254,7 @@ void exit_signals(struct task_struct *tsk)
 	signotset(&unblocked);
 	retarget_shared_pending(tsk, &unblocked);
 
-	if (unlikely(tsk->group_stop & GROUP_STOP_PENDING) &&
+	if (unlikely(tsk->jobctl & JOBCTL_STOP_PENDING) &&
 	    task_participate_group_stop(tsk))
 		group_stop = CLD_STOPPED;
 out:

commit d92fcf0552a15891b25c343cee340d295e24109c
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed May 25 19:22:27 2011 +0200

    signal: sys_pause() should check signal_pending()
    
    ERESTART* is always wrong without TIF_SIGPENDING. Teach sys_pause()
    to handle the spurious wakeup correctly.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index ad5e818baacc..86c32b884f8e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -3023,8 +3023,10 @@ SYSCALL_DEFINE2(signal, int, sig, __sighandler_t, handler)
 
 SYSCALL_DEFINE0(pause)
 {
-	current->state = TASK_INTERRUPTIBLE;
-	schedule();
+	while (!signal_pending(current)) {
+		current->state = TASK_INTERRUPTIBLE;
+		schedule();
+	}
 	return -ERESTARTNOHAND;
 }
 

commit 3ed4c0583daa34dedb568b26ff99e5a7b58db612
Merge: ad9471752eba bd715d9a4f13
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 20 13:33:21 2011 -0700

    Merge branch 'ptrace' of git://git.kernel.org/pub/scm/linux/kernel/git/oleg/misc
    
    * 'ptrace' of git://git.kernel.org/pub/scm/linux/kernel/git/oleg/misc: (41 commits)
      signal: trivial, fix the "timespec declared inside parameter list" warning
      job control: reorganize wait_task_stopped()
      ptrace: fix signal->wait_chldexit usage in task_clear_group_stop_trapping()
      signal: sys_sigprocmask() needs retarget_shared_pending()
      signal: cleanup sys_sigprocmask()
      signal: rename signandsets() to sigandnsets()
      signal: do_sigtimedwait() needs retarget_shared_pending()
      signal: introduce do_sigtimedwait() to factor out compat/native code
      signal: sys_rt_sigtimedwait: simplify the timeout logic
      signal: cleanup sys_rt_sigprocmask()
      x86: signal: sys_rt_sigreturn() should use set_current_blocked()
      x86: signal: handle_signal() should use set_current_blocked()
      signal: sigprocmask() should do retarget_shared_pending()
      signal: sigprocmask: narrow the scope of ->siglock
      signal: retarget_shared_pending: optimize while_each_thread() loop
      signal: retarget_shared_pending: consider shared/unblocked signals only
      signal: introduce retarget_shared_pending()
      ptrace: ptrace_check_attach() should not do s/STOPPED/TRACED/
      signal: Turn SIGNAL_STOP_DEQUEUED into GROUP_STOP_DEQUEUED
      signal: do_signal_stop: Remove the unneeded task_clear_group_stop_pending()
      ...

commit 40ae717d1e78d982bd469b2013a4cbf4ec1ca434
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 6 11:52:22 2011 +0200

    ptrace: fix signal->wait_chldexit usage in task_clear_group_stop_trapping()
    
    GROUP_STOP_TRAPPING waiting mechanism piggybacks on
    signal->wait_chldexit which is primarily used to implement waiting for
    wait(2) and friends.  When do_wait() waits on signal->wait_chldexit,
    it uses a custom wake up callback, child_wait_callback(), which
    expects the child task which is waking up the parent to be passed in
    as @key to filter out spurious wakeups.
    
    task_clear_group_stop_trapping() used __wake_up_sync() which uses NULL
    @key causing the following oops if the parent was doing do_wait().
    
      BUG: unable to handle kernel NULL pointer dereference at 00000000000002d8
      IP: [<ffffffff810499f9>] child_wait_callback+0x29/0x80
      PGD 1d899067 PUD 1e418067 PMD 0
      Oops: 0000 [#1] PREEMPT SMP
      last sysfs file: /sys/devices/pci0000:00/0000:00:03.0/local_cpus
      CPU 2
      Modules linked in:
    
      Pid: 4498, comm: test-continued Not tainted 2.6.39-rc6-work+ #32 Bochs Bochs
      RIP: 0010:[<ffffffff810499f9>]  [<ffffffff810499f9>] child_wait_callback+0x29/0x80
      RSP: 0000:ffff88001b889bf8  EFLAGS: 00010046
      RAX: 0000000000000000 RBX: ffff88001fab3af8 RCX: 0000000000000000
      RDX: 0000000000000001 RSI: 0000000000000002 RDI: ffff88001d91df20
      RBP: ffff88001b889c08 R08: 0000000000000000 R09: 0000000000000000
      R10: 0000000000000000 R11: 0000000000000001 R12: 0000000000000000
      R13: ffff88001fb70550 R14: 0000000000000000 R15: 0000000000000001
      FS:  00007f26ccae4700(0000) GS:ffff88001fd00000(0000) knlGS:0000000000000000
      CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
      CR2: 00000000000002d8 CR3: 000000001b8ac000 CR4: 00000000000006e0
      DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
      DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
      Process test-continued (pid: 4498, threadinfo ffff88001b888000, task ffff88001fb88000)
      Stack:
       ffff88001b889c18 ffff88001fb70538 ffff88001b889c58 ffffffff810312f9
       0000000000000001 0000000200000001 ffff88001b889c58 ffff88001fb70518
       0000000000000002 0000000000000082 0000000000000001 0000000000000000
      Call Trace:
       [<ffffffff810312f9>] __wake_up_common+0x59/0x90
       [<ffffffff81035263>] __wake_up_sync_key+0x53/0x80
       [<ffffffff810352a0>] __wake_up_sync+0x10/0x20
       [<ffffffff8105a984>] task_clear_jobctl_trapping+0x44/0x50
       [<ffffffff8105bcbc>] ptrace_stop+0x7c/0x290
       [<ffffffff8105c20a>] do_signal_stop+0x28a/0x2d0
       [<ffffffff8105d27f>] get_signal_to_deliver+0x14f/0x5a0
       [<ffffffff81002175>] do_signal+0x75/0x7b0
       [<ffffffff8100292d>] do_notify_resume+0x5d/0x70
       [<ffffffff8182e36a>] retint_signal+0x46/0x8c
      Code: 00 00 55 48 89 e5 53 48 83 ec 08 0f 1f 44 00 00 8b 47 d8 83 f8 03 74 3a 85 c0 49 89 c8 75 23 89 c0 48 8b 5f e0 4c 8d 0c 40 31 c0 <4b> 39 9c c8 d8 02 00 00 74 1d 48 83 c4 08 5b c9 c3 66 0f 1f 44
    
    Fix it by using __wake_up_sync_key() and passing in the child as @key.
    
    I still think it's a mistake to piggyback on wait_chldexit for this.
    Given the relative low frequency of ptrace use, we would be much
    better off leaving already complex wait_chldexit alone and using bit
    waitqueue.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index b87780ef7d28..35c5f4b05344 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -238,8 +238,8 @@ static void task_clear_group_stop_trapping(struct task_struct *task)
 {
 	if (unlikely(task->group_stop & GROUP_STOP_TRAPPING)) {
 		task->group_stop &= ~GROUP_STOP_TRAPPING;
-		__wake_up_sync(&task->parent->signal->wait_chldexit,
-			       TASK_UNINTERRUPTIBLE, 1);
+		__wake_up_sync_key(&task->parent->signal->wait_chldexit,
+				   TASK_UNINTERRUPTIBLE, 1, task);
 	}
 }
 

commit 2e4f7c7769a0b8b6b3e88b0436c6c634f146a4ef
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Mon May 9 13:48:56 2011 +0200

    signal: sys_sigprocmask() needs retarget_shared_pending()
    
    sys_sigprocmask() changes current->blocked by hand. Convert this code
    to use set_current_blocked().
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index c0af959b8530..b87780ef7d28 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2900,7 +2900,7 @@ SYSCALL_DEFINE3(sigprocmask, int, how, old_sigset_t __user *, nset,
 		old_sigset_t __user *, oset)
 {
 	old_sigset_t old_set, new_set;
-	int error;
+	sigset_t new_blocked;
 
 	old_set = current->blocked.sig[0];
 
@@ -2909,27 +2909,23 @@ SYSCALL_DEFINE3(sigprocmask, int, how, old_sigset_t __user *, nset,
 			return -EFAULT;
 		new_set &= ~(sigmask(SIGKILL) | sigmask(SIGSTOP));
 
-		error = 0;
-		spin_lock_irq(&current->sighand->siglock);
+		new_blocked = current->blocked;
+
 		switch (how) {
-		default:
-			error = -EINVAL;
-			break;
 		case SIG_BLOCK:
-			sigaddsetmask(&current->blocked, new_set);
+			sigaddsetmask(&new_blocked, new_set);
 			break;
 		case SIG_UNBLOCK:
-			sigdelsetmask(&current->blocked, new_set);
+			sigdelsetmask(&new_blocked, new_set);
 			break;
 		case SIG_SETMASK:
-			current->blocked.sig[0] = new_set;
+			new_blocked.sig[0] = new_set;
 			break;
+		default:
+			return -EINVAL;
 		}
 
-		recalc_sigpending();
-		spin_unlock_irq(&current->sighand->siglock);
-		if (error)
-			return error;
+		set_current_blocked(&new_blocked);
 	}
 
 	if (oset) {

commit b013c399245a88a73aaa031279f0c4d7cea7fe68
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Apr 28 11:36:20 2011 +0200

    signal: cleanup sys_sigprocmask()
    
    Cleanup. Remove the unneeded goto's, we can simply read blocked.sig[0]
    unconditionally and then copy-to-user it if oset != NULL.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Matt Fleming <matt.fleming@linux.intel.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index e7ee4e642c5a..c0af959b8530 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2889,29 +2889,28 @@ SYSCALL_DEFINE1(sigpending, old_sigset_t __user *, set)
 /**
  *  sys_sigprocmask - examine and change blocked signals
  *  @how: whether to add, remove, or set signals
- *  @set: signals to add or remove (if non-null)
+ *  @nset: signals to add or remove (if non-null)
  *  @oset: previous value of signal mask if non-null
  *
  * Some platforms have their own version with special arguments;
  * others support only sys_rt_sigprocmask.
  */
 
-SYSCALL_DEFINE3(sigprocmask, int, how, old_sigset_t __user *, set,
+SYSCALL_DEFINE3(sigprocmask, int, how, old_sigset_t __user *, nset,
 		old_sigset_t __user *, oset)
 {
-	int error;
 	old_sigset_t old_set, new_set;
+	int error;
 
-	if (set) {
-		error = -EFAULT;
-		if (copy_from_user(&new_set, set, sizeof(*set)))
-			goto out;
-		new_set &= ~(sigmask(SIGKILL) | sigmask(SIGSTOP));
+	old_set = current->blocked.sig[0];
 
-		spin_lock_irq(&current->sighand->siglock);
-		old_set = current->blocked.sig[0];
+	if (nset) {
+		if (copy_from_user(&new_set, nset, sizeof(*nset)))
+			return -EFAULT;
+		new_set &= ~(sigmask(SIGKILL) | sigmask(SIGSTOP));
 
 		error = 0;
+		spin_lock_irq(&current->sighand->siglock);
 		switch (how) {
 		default:
 			error = -EINVAL;
@@ -2930,19 +2929,15 @@ SYSCALL_DEFINE3(sigprocmask, int, how, old_sigset_t __user *, set,
 		recalc_sigpending();
 		spin_unlock_irq(&current->sighand->siglock);
 		if (error)
-			goto out;
-		if (oset)
-			goto set_old;
-	} else if (oset) {
-		old_set = current->blocked.sig[0];
-	set_old:
-		error = -EFAULT;
+			return error;
+	}
+
+	if (oset) {
 		if (copy_to_user(oset, &old_set, sizeof(*oset)))
-			goto out;
+			return -EFAULT;
 	}
-	error = 0;
-out:
-	return error;
+
+	return 0;
 }
 #endif /* __ARCH_WANT_SYS_SIGPROCMASK */
 

commit 702a5073fdb71eb29cd4912575289fb5044c1894
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Apr 27 22:01:27 2011 +0200

    signal: rename signandsets() to sigandnsets()
    
    As Tejun and Linus pointed out, "nand" is the wrong name for "x & ~y",
    it should be "andn". Rename signandsets() as suggested.
    
    Suggested-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 4d97e11d7672..e7ee4e642c5a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -669,7 +669,7 @@ static int rm_from_queue_full(sigset_t *mask, struct sigpending *s)
 	if (sigisemptyset(&m))
 		return 0;
 
-	signandsets(&s->signal, &s->signal, mask);
+	sigandnsets(&s->signal, &s->signal, mask);
 	list_for_each_entry_safe(q, n, &s->list, list) {
 		if (sigismember(mask, q->info.si_signo)) {
 			list_del_init(&q->list);
@@ -2304,7 +2304,7 @@ static void __set_task_blocked(struct task_struct *tsk, const sigset_t *newset)
 	if (signal_pending(tsk) && !thread_group_empty(tsk)) {
 		sigset_t newblocked;
 		/* A set of now blocked but previously unblocked signals. */
-		signandsets(&newblocked, newset, &current->blocked);
+		sigandnsets(&newblocked, newset, &current->blocked);
 		retarget_shared_pending(tsk, &newblocked);
 	}
 	tsk->blocked = *newset;
@@ -2349,7 +2349,7 @@ int sigprocmask(int how, sigset_t *set, sigset_t *oldset)
 		sigorsets(&newset, &tsk->blocked, set);
 		break;
 	case SIG_UNBLOCK:
-		signandsets(&newset, &tsk->blocked, set);
+		sigandnsets(&newset, &tsk->blocked, set);
 		break;
 	case SIG_SETMASK:
 		newset = *set;

commit b182801ab35f7a0afb3cdf8ba5df464d04206b46
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Apr 27 21:56:14 2011 +0200

    signal: do_sigtimedwait() needs retarget_shared_pending()
    
    do_sigtimedwait() changes current->blocked and thus it needs
    set_current_blocked()->retarget_shared_pending().
    
    We could use set_current_blocked() directly. It is fine to change
    ->real_blocked from all-zeroes to ->blocked and vice versa lockless,
    but this is not immediately clear, looks racy, and needs a huge
    comment to explain why this is correct.
    
    To keep the things simple this patch adds the new static helper,
    __set_task_blocked() which should be called with ->siglock held. This
    way we can change both ->real_blocked and ->blocked atomically under
    ->siglock as the current code does. This is more understandable.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Matt Fleming <matt.fleming@linux.intel.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1ab89f677424..4d97e11d7672 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2299,6 +2299,18 @@ long do_no_restart_syscall(struct restart_block *param)
 	return -EINTR;
 }
 
+static void __set_task_blocked(struct task_struct *tsk, const sigset_t *newset)
+{
+	if (signal_pending(tsk) && !thread_group_empty(tsk)) {
+		sigset_t newblocked;
+		/* A set of now blocked but previously unblocked signals. */
+		signandsets(&newblocked, newset, &current->blocked);
+		retarget_shared_pending(tsk, &newblocked);
+	}
+	tsk->blocked = *newset;
+	recalc_sigpending();
+}
+
 /**
  * set_current_blocked - change current->blocked mask
  * @newset: new mask
@@ -2311,14 +2323,7 @@ void set_current_blocked(const sigset_t *newset)
 	struct task_struct *tsk = current;
 
 	spin_lock_irq(&tsk->sighand->siglock);
-	if (signal_pending(tsk) && !thread_group_empty(tsk)) {
-		sigset_t newblocked;
-		/* A set of now blocked but previously unblocked signals. */
-		signandsets(&newblocked, newset, &current->blocked);
-		retarget_shared_pending(tsk, &newblocked);
-	}
-	tsk->blocked = *newset;
-	recalc_sigpending();
+	__set_task_blocked(tsk, newset);
 	spin_unlock_irq(&tsk->sighand->siglock);
 }
 
@@ -2541,7 +2546,8 @@ int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
 		/*
 		 * None ready, temporarily unblock those we're interested
 		 * while we are sleeping in so that we'll be awakened when
-		 * they arrive.
+		 * they arrive. Unblocking is always fine, we can avoid
+		 * set_current_blocked().
 		 */
 		tsk->real_blocked = tsk->blocked;
 		sigandsets(&tsk->blocked, &tsk->blocked, &mask);
@@ -2551,10 +2557,9 @@ int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
 		timeout = schedule_timeout_interruptible(timeout);
 
 		spin_lock_irq(&tsk->sighand->siglock);
-		sig = dequeue_signal(tsk, &mask, info);
-		tsk->blocked = tsk->real_blocked;
+		__set_task_blocked(tsk, &tsk->real_blocked);
 		siginitset(&tsk->real_blocked, 0);
-		recalc_sigpending();
+		sig = dequeue_signal(tsk, &mask, info);
 	}
 	spin_unlock_irq(&tsk->sighand->siglock);
 

commit 943df1485a8ff0e600729e082e568ece04d4de9e
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Apr 27 21:44:14 2011 +0200

    signal: introduce do_sigtimedwait() to factor out compat/native code
    
    Factor out the common code in sys_rt_sigtimedwait/compat_sys_rt_sigtimedwait
    to the new helper, do_sigtimedwait().
    
    Add the comment to document the extra tick we add to timespec_to_jiffies(ts),
    thanks to Linus who explained this to me.
    
    Perhaps it would be better to move compat_sys_rt_sigtimedwait() into
    signal.c under CONFIG_COMPAT, then we can make do_sigtimedwait() static.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Matt Fleming <matt.fleming@linux.intel.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index c734619554f6..1ab89f677424 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2503,6 +2503,66 @@ int copy_siginfo_to_user(siginfo_t __user *to, siginfo_t *from)
 
 #endif
 
+/**
+ *  do_sigtimedwait - wait for queued signals specified in @which
+ *  @which: queued signals to wait for
+ *  @info: if non-null, the signal's siginfo is returned here
+ *  @ts: upper bound on process time suspension
+ */
+int do_sigtimedwait(const sigset_t *which, siginfo_t *info,
+			const struct timespec *ts)
+{
+	struct task_struct *tsk = current;
+	long timeout = MAX_SCHEDULE_TIMEOUT;
+	sigset_t mask = *which;
+	int sig;
+
+	if (ts) {
+		if (!timespec_valid(ts))
+			return -EINVAL;
+		timeout = timespec_to_jiffies(ts);
+		/*
+		 * We can be close to the next tick, add another one
+		 * to ensure we will wait at least the time asked for.
+		 */
+		if (ts->tv_sec || ts->tv_nsec)
+			timeout++;
+	}
+
+	/*
+	 * Invert the set of allowed signals to get those we want to block.
+	 */
+	sigdelsetmask(&mask, sigmask(SIGKILL) | sigmask(SIGSTOP));
+	signotset(&mask);
+
+	spin_lock_irq(&tsk->sighand->siglock);
+	sig = dequeue_signal(tsk, &mask, info);
+	if (!sig && timeout) {
+		/*
+		 * None ready, temporarily unblock those we're interested
+		 * while we are sleeping in so that we'll be awakened when
+		 * they arrive.
+		 */
+		tsk->real_blocked = tsk->blocked;
+		sigandsets(&tsk->blocked, &tsk->blocked, &mask);
+		recalc_sigpending();
+		spin_unlock_irq(&tsk->sighand->siglock);
+
+		timeout = schedule_timeout_interruptible(timeout);
+
+		spin_lock_irq(&tsk->sighand->siglock);
+		sig = dequeue_signal(tsk, &mask, info);
+		tsk->blocked = tsk->real_blocked;
+		siginitset(&tsk->real_blocked, 0);
+		recalc_sigpending();
+	}
+	spin_unlock_irq(&tsk->sighand->siglock);
+
+	if (sig)
+		return sig;
+	return timeout ? -EINTR : -EAGAIN;
+}
+
 /**
  *  sys_rt_sigtimedwait - synchronously wait for queued signals specified
  *			in @uthese
@@ -2515,11 +2575,10 @@ SYSCALL_DEFINE4(rt_sigtimedwait, const sigset_t __user *, uthese,
 		siginfo_t __user *, uinfo, const struct timespec __user *, uts,
 		size_t, sigsetsize)
 {
-	int ret, sig;
 	sigset_t these;
 	struct timespec ts;
 	siginfo_t info;
-	long timeout;
+	int ret;
 
 	/* XXX: Don't preclude handling different sized sigset_t's.  */
 	if (sigsetsize != sizeof(sigset_t))
@@ -2528,55 +2587,16 @@ SYSCALL_DEFINE4(rt_sigtimedwait, const sigset_t __user *, uthese,
 	if (copy_from_user(&these, uthese, sizeof(these)))
 		return -EFAULT;
 
-	/*
-	 * Invert the set of allowed signals to get those we
-	 * want to block.
-	 */
-	sigdelsetmask(&these, sigmask(SIGKILL)|sigmask(SIGSTOP));
-	signotset(&these);
-
-	timeout = MAX_SCHEDULE_TIMEOUT;
 	if (uts) {
 		if (copy_from_user(&ts, uts, sizeof(ts)))
 			return -EFAULT;
-		if (!timespec_valid(&ts))
-			return -EINVAL;
-		timeout = timespec_to_jiffies(&ts) + (ts.tv_sec || ts.tv_nsec);
 	}
 
-	spin_lock_irq(&current->sighand->siglock);
-	sig = dequeue_signal(current, &these, &info);
-	if (!sig && timeout) {
-		/*
-		 * None ready -- temporarily unblock those we're
-		 * interested while we are sleeping in so that we'll
-		 * be awakened when they arrive.
-		 */
-		current->real_blocked = current->blocked;
-		sigandsets(&current->blocked, &current->blocked, &these);
-		recalc_sigpending();
-		spin_unlock_irq(&current->sighand->siglock);
-
-		timeout = schedule_timeout_interruptible(timeout);
-
-		spin_lock_irq(&current->sighand->siglock);
-		sig = dequeue_signal(current, &these, &info);
-		current->blocked = current->real_blocked;
-		siginitset(&current->real_blocked, 0);
-		recalc_sigpending();
-	}
-	spin_unlock_irq(&current->sighand->siglock);
+	ret = do_sigtimedwait(&these, &info, uts ? &ts : NULL);
 
-	if (sig) {
-		ret = sig;
-		if (uinfo) {
-			if (copy_siginfo_to_user(uinfo, &info))
-				ret = -EFAULT;
-		}
-	} else {
-		ret = -EAGAIN;
-		if (timeout)
-			ret = -EINTR;
+	if (ret > 0 && uinfo) {
+		if (copy_siginfo_to_user(uinfo, &info))
+			ret = -EFAULT;
 	}
 
 	return ret;

commit fe0faa005d43bc44c357631d51c273806086caa4
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Apr 27 21:24:19 2011 +0200

    signal: sys_rt_sigtimedwait: simplify the timeout logic
    
    No functional changes, cleanup compat_sys_rt_sigtimedwait() and
    sys_rt_sigtimedwait().
    
    Calculate the timeout before we take ->siglock, this simplifies and
    lessens the code. Use timespec_valid() to check the timespec.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Matt Fleming <matt.fleming@linux.intel.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index bb9200070ea0..c734619554f6 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2519,7 +2519,7 @@ SYSCALL_DEFINE4(rt_sigtimedwait, const sigset_t __user *, uthese,
 	sigset_t these;
 	struct timespec ts;
 	siginfo_t info;
-	long timeout = 0;
+	long timeout;
 
 	/* XXX: Don't preclude handling different sized sigset_t's.  */
 	if (sigsetsize != sizeof(sigset_t))
@@ -2535,41 +2535,35 @@ SYSCALL_DEFINE4(rt_sigtimedwait, const sigset_t __user *, uthese,
 	sigdelsetmask(&these, sigmask(SIGKILL)|sigmask(SIGSTOP));
 	signotset(&these);
 
+	timeout = MAX_SCHEDULE_TIMEOUT;
 	if (uts) {
 		if (copy_from_user(&ts, uts, sizeof(ts)))
 			return -EFAULT;
-		if (ts.tv_nsec >= 1000000000L || ts.tv_nsec < 0
-		    || ts.tv_sec < 0)
+		if (!timespec_valid(&ts))
 			return -EINVAL;
+		timeout = timespec_to_jiffies(&ts) + (ts.tv_sec || ts.tv_nsec);
 	}
 
 	spin_lock_irq(&current->sighand->siglock);
 	sig = dequeue_signal(current, &these, &info);
-	if (!sig) {
-		timeout = MAX_SCHEDULE_TIMEOUT;
-		if (uts)
-			timeout = (timespec_to_jiffies(&ts)
-				   + (ts.tv_sec || ts.tv_nsec));
+	if (!sig && timeout) {
+		/*
+		 * None ready -- temporarily unblock those we're
+		 * interested while we are sleeping in so that we'll
+		 * be awakened when they arrive.
+		 */
+		current->real_blocked = current->blocked;
+		sigandsets(&current->blocked, &current->blocked, &these);
+		recalc_sigpending();
+		spin_unlock_irq(&current->sighand->siglock);
 
-		if (timeout) {
-			/*
-			 * None ready -- temporarily unblock those we're
-			 * interested while we are sleeping in so that we'll
-			 * be awakened when they arrive.
-			 */
-			current->real_blocked = current->blocked;
-			sigandsets(&current->blocked, &current->blocked, &these);
-			recalc_sigpending();
-			spin_unlock_irq(&current->sighand->siglock);
-
-			timeout = schedule_timeout_interruptible(timeout);
-
-			spin_lock_irq(&current->sighand->siglock);
-			sig = dequeue_signal(current, &these, &info);
-			current->blocked = current->real_blocked;
-			siginitset(&current->real_blocked, 0);
-			recalc_sigpending();
-		}
+		timeout = schedule_timeout_interruptible(timeout);
+
+		spin_lock_irq(&current->sighand->siglock);
+		sig = dequeue_signal(current, &these, &info);
+		current->blocked = current->real_blocked;
+		siginitset(&current->real_blocked, 0);
+		recalc_sigpending();
 	}
 	spin_unlock_irq(&current->sighand->siglock);
 

commit bb7efee2ca63b08795ffb3cda96fc89d2e641b79
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Apr 27 21:18:10 2011 +0200

    signal: cleanup sys_rt_sigprocmask()
    
    sys_rt_sigprocmask() looks unnecessarily complicated, simplify it.
    We can just read current->blocked lockless unconditionally before
    anything else and then copy-to-user it if needed.  At worst we
    copy 4 words on mips.
    
    We could copy-to-user the old mask first and simplify the code even
    more, but the patch tries to keep the current behaviour: we change
    current->block even if copy_to_user(oset) fails.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Matt Fleming <matt.fleming@linux.intel.com>
    Acked-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8aa3a2e226af..bb9200070ea0 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2364,40 +2364,34 @@ int sigprocmask(int how, sigset_t *set, sigset_t *oldset)
  *  @oset: previous value of signal mask if non-null
  *  @sigsetsize: size of sigset_t type
  */
-SYSCALL_DEFINE4(rt_sigprocmask, int, how, sigset_t __user *, set,
+SYSCALL_DEFINE4(rt_sigprocmask, int, how, sigset_t __user *, nset,
 		sigset_t __user *, oset, size_t, sigsetsize)
 {
-	int error = -EINVAL;
 	sigset_t old_set, new_set;
+	int error;
 
 	/* XXX: Don't preclude handling different sized sigset_t's.  */
 	if (sigsetsize != sizeof(sigset_t))
-		goto out;
+		return -EINVAL;
 
-	if (set) {
-		error = -EFAULT;
-		if (copy_from_user(&new_set, set, sizeof(*set)))
-			goto out;
+	old_set = current->blocked;
+
+	if (nset) {
+		if (copy_from_user(&new_set, nset, sizeof(sigset_t)))
+			return -EFAULT;
 		sigdelsetmask(&new_set, sigmask(SIGKILL)|sigmask(SIGSTOP));
 
-		error = sigprocmask(how, &new_set, &old_set);
+		error = sigprocmask(how, &new_set, NULL);
 		if (error)
-			goto out;
-		if (oset)
-			goto set_old;
-	} else if (oset) {
-		spin_lock_irq(&current->sighand->siglock);
-		old_set = current->blocked;
-		spin_unlock_irq(&current->sighand->siglock);
+			return error;
+	}
 
-	set_old:
-		error = -EFAULT;
-		if (copy_to_user(oset, &old_set, sizeof(*oset)))
-			goto out;
+	if (oset) {
+		if (copy_to_user(oset, &old_set, sizeof(sigset_t)))
+			return -EFAULT;
 	}
-	error = 0;
-out:
-	return error;
+
+	return 0;
 }
 
 long do_sigpending(void __user *set, unsigned long sigsetsize)

commit e6fa16ab9c1e9b344428e6fea4d29e3cc4b28fb0
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Apr 27 20:59:41 2011 +0200

    signal: sigprocmask() should do retarget_shared_pending()
    
    In short, almost every changing of current->blocked is wrong, or at least
    can lead to the unexpected results.
    
    For example. Two threads T1 and T2, T1 sleeps in sigtimedwait/pause/etc.
    kill(tgid, SIG) can pick T2 for TIF_SIGPENDING. If T2 calls sigprocmask()
    and blocks SIG before it notices the pending signal, nobody else can handle
    this pending shared signal.
    
    I am not sure this is bug, but at least this looks strange imho. T1 should
    not sleep forever, there is a signal which should wake it up.
    
    This patch moves the code which actually changes ->blocked into the new
    helper, set_current_blocked() and changes this code to call
    retarget_shared_pending() as exit_signals() does. We should only care about
    the signals we just blocked, we use "newset & ~current->blocked" as a mask.
    
    We do not check !sigisemptyset(newblocked), retarget_shared_pending() is
    cheap unless mask & shared_pending.
    
    Note: for this particular case we could simply change sigprocmask() to
    return -EINTR if signal_pending(), but then we should change other callers
    and, more importantly, if we need this fix then set_current_blocked() will
    have more callers and some of them can't restart. See the next patch as a
    random example.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Matt Fleming <matt.fleming@linux.intel.com>
    Acked-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index e8308e3238c1..8aa3a2e226af 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2299,6 +2299,29 @@ long do_no_restart_syscall(struct restart_block *param)
 	return -EINTR;
 }
 
+/**
+ * set_current_blocked - change current->blocked mask
+ * @newset: new mask
+ *
+ * It is wrong to change ->blocked directly, this helper should be used
+ * to ensure the process can't miss a shared signal we are going to block.
+ */
+void set_current_blocked(const sigset_t *newset)
+{
+	struct task_struct *tsk = current;
+
+	spin_lock_irq(&tsk->sighand->siglock);
+	if (signal_pending(tsk) && !thread_group_empty(tsk)) {
+		sigset_t newblocked;
+		/* A set of now blocked but previously unblocked signals. */
+		signandsets(&newblocked, newset, &current->blocked);
+		retarget_shared_pending(tsk, &newblocked);
+	}
+	tsk->blocked = *newset;
+	recalc_sigpending();
+	spin_unlock_irq(&tsk->sighand->siglock);
+}
+
 /*
  * This is also useful for kernel threads that want to temporarily
  * (or permanently) block certain signals.
@@ -2330,11 +2353,7 @@ int sigprocmask(int how, sigset_t *set, sigset_t *oldset)
 		return -EINVAL;
 	}
 
-	spin_lock_irq(&tsk->sighand->siglock);
-	tsk->blocked = newset;
-	recalc_sigpending();
-	spin_unlock_irq(&tsk->sighand->siglock);
-
+	set_current_blocked(&newset);
 	return 0;
 }
 

commit 73ef4aeb61b53fce464a7e24ef03a26f98b2f617
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Apr 27 19:54:20 2011 +0200

    signal: sigprocmask: narrow the scope of ->siglock
    
    No functional changes, preparation to simplify the review of the next change.
    
    1. We can read current->block lockless, nobody else can ever change this mask.
    
    2. Calculate the resulting sigset_t outside of ->siglock into the temporary
       variable, then take ->siglock and change ->blocked.
    
    Also, kill the stale comment about BKL.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Matt Fleming <matt.fleming@linux.intel.com>
    Acked-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 707736e64e0e..e8308e3238c1 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2299,12 +2299,6 @@ long do_no_restart_syscall(struct restart_block *param)
 	return -EINTR;
 }
 
-/*
- * We don't need to get the kernel lock - this is all local to this
- * particular thread.. (and that's good, because this is _heavily_
- * used by various programs)
- */
-
 /*
  * This is also useful for kernel threads that want to temporarily
  * (or permanently) block certain signals.
@@ -2315,30 +2309,33 @@ long do_no_restart_syscall(struct restart_block *param)
  */
 int sigprocmask(int how, sigset_t *set, sigset_t *oldset)
 {
-	int error;
+	struct task_struct *tsk = current;
+	sigset_t newset;
 
-	spin_lock_irq(&current->sighand->siglock);
+	/* Lockless, only current can change ->blocked, never from irq */
 	if (oldset)
-		*oldset = current->blocked;
+		*oldset = tsk->blocked;
 
-	error = 0;
 	switch (how) {
 	case SIG_BLOCK:
-		sigorsets(&current->blocked, &current->blocked, set);
+		sigorsets(&newset, &tsk->blocked, set);
 		break;
 	case SIG_UNBLOCK:
-		signandsets(&current->blocked, &current->blocked, set);
+		signandsets(&newset, &tsk->blocked, set);
 		break;
 	case SIG_SETMASK:
-		current->blocked = *set;
+		newset = *set;
 		break;
 	default:
-		error = -EINVAL;
+		return -EINVAL;
 	}
+
+	spin_lock_irq(&tsk->sighand->siglock);
+	tsk->blocked = newset;
 	recalc_sigpending();
-	spin_unlock_irq(&current->sighand->siglock);
+	spin_unlock_irq(&tsk->sighand->siglock);
 
-	return error;
+	return 0;
 }
 
 /**

commit fec9993db093acfc3999a364e31f8adae41fcb28
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Apr 27 19:50:21 2011 +0200

    signal: retarget_shared_pending: optimize while_each_thread() loop
    
    retarget_shared_pending() blindly does recalc_sigpending_and_wake() for
    every sub-thread, this is suboptimal. We can check t->blocked and stop
    looping once every bit in shared_pending has the new target.
    
    Note: we do not take task_is_stopped_or_traced(t) into account, we are
    not trying to speed up the signal delivery or to avoid the unnecessary
    (but harmless) signal_wake_up(0) in this unlikely case.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Matt Fleming <matt.fleming@linux.intel.com>
    Acked-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 06214b55dc5e..707736e64e0e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2200,8 +2200,8 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 
 /*
  * It could be that complete_signal() picked us to notify about the
- * group-wide signal. Another thread should be notified now to take
- * the signal since we will not.
+ * group-wide signal. Other threads should be notified now to take
+ * the shared signals in @which since we will not.
  */
 static void retarget_shared_pending(struct task_struct *tsk, sigset_t *which)
 {
@@ -2214,8 +2214,19 @@ static void retarget_shared_pending(struct task_struct *tsk, sigset_t *which)
 
 	t = tsk;
 	while_each_thread(tsk, t) {
-		if (!signal_pending(t) && !(t->flags & PF_EXITING))
-			recalc_sigpending_and_wake(t);
+		if (t->flags & PF_EXITING)
+			continue;
+
+		if (!has_pending_signals(&retarget, &t->blocked))
+			continue;
+		/* Remove the signals this thread can handle. */
+		sigandsets(&retarget, &retarget, &t->blocked);
+
+		if (!signal_pending(t))
+			signal_wake_up(t, 0);
+
+		if (sigisemptyset(&retarget))
+			break;
 	}
 }
 

commit f646e227b88a164a841d6b6dd969d8a45272dd83
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Apr 27 19:18:39 2011 +0200

    signal: retarget_shared_pending: consider shared/unblocked signals only
    
    exit_signals() checks signal_pending() before retarget_shared_pending() but
    this is suboptimal. We can avoid the while_each_thread() loop in case when
    there are no shared signals visible to us.
    
    Add the "shared_pending.signal & ~blocked" check. We don't use tsk->blocked
    directly but pass ~blocked as an argument, this is needed for the next patch.
    
    Note: we can optimize this more. while_each_thread(t) can check t->blocked
    into account and stop after every pending signal has the new target, see the
    next patch.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Matt Fleming <matt.fleming@linux.intel.com>
    Acked-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5341e2141904..06214b55dc5e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2203,10 +2203,15 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
  * group-wide signal. Another thread should be notified now to take
  * the signal since we will not.
  */
-static void retarget_shared_pending(struct task_struct *tsk)
+static void retarget_shared_pending(struct task_struct *tsk, sigset_t *which)
 {
+	sigset_t retarget;
 	struct task_struct *t;
 
+	sigandsets(&retarget, &tsk->signal->shared_pending.signal, which);
+	if (sigisemptyset(&retarget))
+		return;
+
 	t = tsk;
 	while_each_thread(tsk, t) {
 		if (!signal_pending(t) && !(t->flags & PF_EXITING))
@@ -2217,6 +2222,7 @@ static void retarget_shared_pending(struct task_struct *tsk)
 void exit_signals(struct task_struct *tsk)
 {
 	int group_stop = 0;
+	sigset_t unblocked;
 
 	if (thread_group_empty(tsk) || signal_group_exit(tsk->signal)) {
 		tsk->flags |= PF_EXITING;
@@ -2232,7 +2238,9 @@ void exit_signals(struct task_struct *tsk)
 	if (!signal_pending(tsk))
 		goto out;
 
-	retarget_shared_pending(tsk);
+	unblocked = tsk->blocked;
+	signotset(&unblocked);
+	retarget_shared_pending(tsk, &unblocked);
 
 	if (unlikely(tsk->group_stop & GROUP_STOP_PENDING) &&
 	    task_participate_group_stop(tsk))

commit 0edceb7bcd82802f721f3c94eed9b3e2869d3740
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Apr 27 19:17:37 2011 +0200

    signal: introduce retarget_shared_pending()
    
    No functional changes. Move the notify-other-threads code from exit_signals()
    to the new helper, retarget_shared_pending().
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Matt Fleming <matt.fleming@linux.intel.com>
    Acked-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index c15e9792b088..5341e2141904 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2198,10 +2198,25 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 	return signr;
 }
 
+/*
+ * It could be that complete_signal() picked us to notify about the
+ * group-wide signal. Another thread should be notified now to take
+ * the signal since we will not.
+ */
+static void retarget_shared_pending(struct task_struct *tsk)
+{
+	struct task_struct *t;
+
+	t = tsk;
+	while_each_thread(tsk, t) {
+		if (!signal_pending(t) && !(t->flags & PF_EXITING))
+			recalc_sigpending_and_wake(t);
+	}
+}
+
 void exit_signals(struct task_struct *tsk)
 {
 	int group_stop = 0;
-	struct task_struct *t;
 
 	if (thread_group_empty(tsk) || signal_group_exit(tsk->signal)) {
 		tsk->flags |= PF_EXITING;
@@ -2217,14 +2232,7 @@ void exit_signals(struct task_struct *tsk)
 	if (!signal_pending(tsk))
 		goto out;
 
-	/*
-	 * It could be that __group_complete_signal() choose us to
-	 * notify about group-wide signal. Another thread should be
-	 * woken now to take the signal since we will not.
-	 */
-	for (t = tsk; (t = next_thread(t)) != tsk; )
-		if (!signal_pending(t) && !(t->flags & PF_EXITING))
-			recalc_sigpending_and_wake(t);
+	retarget_shared_pending(tsk);
 
 	if (unlikely(tsk->group_stop & GROUP_STOP_PENDING) &&
 	    task_participate_group_stop(tsk))

commit f9fa0bc1fabe1d861e46d80ecbe7e85da359195c
Author: Randy Dunlap <randy.dunlap@oracle.com>
Date:   Fri Apr 8 10:53:46 2011 -0700

    signal.c: fix erroneous syscall kernel-doc
    
    Fix erroneous syscall kernel-doc comments in kernel/signal.c.
    
    Reported-by: Matt Fleming <matt@console-pimps.org>
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 29e233fd7a0f..7165af5f1b11 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2711,8 +2711,8 @@ SYSCALL_DEFINE3(sigprocmask, int, how, old_sigset_t __user *, set,
 /**
  *  sys_rt_sigaction - alter an action taken by a process
  *  @sig: signal to be sent
- *  @act: the thread group ID of the thread
- *  @oact: the PID of the thread
+ *  @act: new sigaction
+ *  @oact: used to save the previous sigaction
  *  @sigsetsize: size of sigset_t type
  */
 SYSCALL_DEFINE4(rt_sigaction, int, sig,

commit e46bc9b6fd65bc9f406a4211fbf95683cc9c2937
Merge: 2b9accbee563 321fb561971b
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Apr 7 20:44:11 2011 +0200

    Merge branch 'ptrace' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/misc into ptrace

commit 42933bac11e811f02200c944d8562a15f8ec4ff0
Merge: 2b9accbee563 25985edcedea
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Apr 7 11:14:49 2011 -0700

    Merge branch 'for-linus2' of git://git.profusion.mobi/users/lucas/linux-2.6
    
    * 'for-linus2' of git://git.profusion.mobi/users/lucas/linux-2.6:
      Fix common misspellings

commit 41c57892a2895865afc89ff1a21f91a0f1506f66
Author: Randy Dunlap <randy.dunlap@oracle.com>
Date:   Mon Apr 4 15:00:26 2011 -0700

    kernel/signal.c: add kernel-doc notation to syscalls
    
    Add kernel-doc to syscalls in signal.c.
    
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 3ab90e8b6ecf..dc17929ab78a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2075,6 +2075,9 @@ EXPORT_SYMBOL(unblock_all_signals);
  * System call entry points.
  */
 
+/**
+ *  sys_restart_syscall - restart a system call
+ */
 SYSCALL_DEFINE0(restart_syscall)
 {
 	struct restart_block *restart = &current_thread_info()->restart_block;
@@ -2128,6 +2131,13 @@ int sigprocmask(int how, sigset_t *set, sigset_t *oldset)
 	return error;
 }
 
+/**
+ *  sys_rt_sigprocmask - change the list of currently blocked signals
+ *  @how: whether to add, remove, or set signals
+ *  @set: stores pending signals
+ *  @oset: previous value of signal mask if non-null
+ *  @sigsetsize: size of sigset_t type
+ */
 SYSCALL_DEFINE4(rt_sigprocmask, int, how, sigset_t __user *, set,
 		sigset_t __user *, oset, size_t, sigsetsize)
 {
@@ -2188,6 +2198,12 @@ long do_sigpending(void __user *set, unsigned long sigsetsize)
 	return error;
 }
 
+/**
+ *  sys_rt_sigpending - examine a pending signal that has been raised
+ *			while blocked
+ *  @set: stores pending signals
+ *  @sigsetsize: size of sigset_t type or larger
+ */
 SYSCALL_DEFINE2(rt_sigpending, sigset_t __user *, set, size_t, sigsetsize)
 {
 	return do_sigpending(set, sigsetsize);
@@ -2267,6 +2283,14 @@ int copy_siginfo_to_user(siginfo_t __user *to, siginfo_t *from)
 
 #endif
 
+/**
+ *  sys_rt_sigtimedwait - synchronously wait for queued signals specified
+ *			in @uthese
+ *  @uthese: queued signals to wait for
+ *  @uinfo: if non-null, the signal's siginfo is returned here
+ *  @uts: upper bound on process time suspension
+ *  @sigsetsize: size of sigset_t type
+ */
 SYSCALL_DEFINE4(rt_sigtimedwait, const sigset_t __user *, uthese,
 		siginfo_t __user *, uinfo, const struct timespec __user *, uts,
 		size_t, sigsetsize)
@@ -2344,6 +2368,11 @@ SYSCALL_DEFINE4(rt_sigtimedwait, const sigset_t __user *, uthese,
 	return ret;
 }
 
+/**
+ *  sys_kill - send a signal to a process
+ *  @pid: the PID of the process
+ *  @sig: signal to be sent
+ */
 SYSCALL_DEFINE2(kill, pid_t, pid, int, sig)
 {
 	struct siginfo info;
@@ -2419,7 +2448,11 @@ SYSCALL_DEFINE3(tgkill, pid_t, tgid, pid_t, pid, int, sig)
 	return do_tkill(tgid, pid, sig);
 }
 
-/*
+/**
+ *  sys_tkill - send signal to one specific task
+ *  @pid: the PID of the task
+ *  @sig: signal to be sent
+ *
  *  Send a signal to only one task, even if it's a CLONE_THREAD task.
  */
 SYSCALL_DEFINE2(tkill, pid_t, pid, int, sig)
@@ -2431,6 +2464,12 @@ SYSCALL_DEFINE2(tkill, pid_t, pid, int, sig)
 	return do_tkill(0, pid, sig);
 }
 
+/**
+ *  sys_rt_sigqueueinfo - send signal information to a signal
+ *  @pid: the PID of the thread
+ *  @sig: signal to be sent
+ *  @uinfo: signal info to be sent
+ */
 SYSCALL_DEFINE3(rt_sigqueueinfo, pid_t, pid, int, sig,
 		siginfo_t __user *, uinfo)
 {
@@ -2596,6 +2635,10 @@ do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long s
 
 #ifdef __ARCH_WANT_SYS_SIGPENDING
 
+/**
+ *  sys_sigpending - examine pending signals
+ *  @set: where mask of pending signal is returned
+ */
 SYSCALL_DEFINE1(sigpending, old_sigset_t __user *, set)
 {
 	return do_sigpending(set, sizeof(*set));
@@ -2604,7 +2647,12 @@ SYSCALL_DEFINE1(sigpending, old_sigset_t __user *, set)
 #endif
 
 #ifdef __ARCH_WANT_SYS_SIGPROCMASK
-/*
+/**
+ *  sys_sigprocmask - examine and change blocked signals
+ *  @how: whether to add, remove, or set signals
+ *  @set: signals to add or remove (if non-null)
+ *  @oset: previous value of signal mask if non-null
+ *
  * Some platforms have their own version with special arguments;
  * others support only sys_rt_sigprocmask.
  */
@@ -2660,6 +2708,13 @@ SYSCALL_DEFINE3(sigprocmask, int, how, old_sigset_t __user *, set,
 #endif /* __ARCH_WANT_SYS_SIGPROCMASK */
 
 #ifdef __ARCH_WANT_SYS_RT_SIGACTION
+/**
+ *  sys_rt_sigaction - alter an action taken by a process
+ *  @sig: signal to be sent
+ *  @act: the thread group ID of the thread
+ *  @oact: the PID of the thread
+ *  @sigsetsize: size of sigset_t type
+ */
 SYSCALL_DEFINE4(rt_sigaction, int, sig,
 		const struct sigaction __user *, act,
 		struct sigaction __user *, oact,
@@ -2746,6 +2801,12 @@ SYSCALL_DEFINE0(pause)
 #endif
 
 #ifdef __ARCH_WANT_SYS_RT_SIGSUSPEND
+/**
+ *  sys_rt_sigsuspend - replace the signal mask for a value with the
+ *	@unewset value until a signal is received
+ *  @unewset: new signal mask value
+ *  @sigsetsize: size of sigset_t type
+ */
 SYSCALL_DEFINE2(rt_sigsuspend, sigset_t __user *, unewset, size_t, sigsetsize)
 {
 	sigset_t newset;

commit 5aba085ededa6c5a1ff465e2aebc3e8eb00a7567
Author: Randy Dunlap <randy.dunlap@oracle.com>
Date:   Mon Apr 4 14:59:31 2011 -0700

    kernel/signal.c: fix typos and coding style
    
    General coding style and comment fixes; no code changes:
    
     - Use multi-line-comment coding style.
     - Put some function signatures completely on one line.
     - Hyphenate some words.
     - Spell Posix as POSIX.
     - Correct typos & spellos in some comments.
     - Drop trailing whitespace.
     - End sentences with periods.
    
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1186cf7fac77..3ab90e8b6ecf 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -226,7 +226,7 @@ static inline void print_dropped_signal(int sig)
 /*
  * allocate a new signal queue record
  * - this may be called without locks if and only if t == current, otherwise an
- *   appopriate lock must be held to stop the target task from exiting
+ *   appropriate lock must be held to stop the target task from exiting
  */
 static struct sigqueue *
 __sigqueue_alloc(int sig, struct task_struct *t, gfp_t flags, int override_rlimit)
@@ -375,15 +375,15 @@ int unhandled_signal(struct task_struct *tsk, int sig)
 	return !tracehook_consider_fatal_signal(tsk, sig);
 }
 
-
-/* Notify the system that a driver wants to block all signals for this
+/*
+ * Notify the system that a driver wants to block all signals for this
  * process, and wants to be notified if any signals at all were to be
  * sent/acted upon.  If the notifier routine returns non-zero, then the
  * signal will be acted upon after all.  If the notifier routine returns 0,
  * then then signal will be blocked.  Only one block per process is
  * allowed.  priv is a pointer to private data that the notifier routine
- * can use to determine if the signal should be blocked or not.  */
-
+ * can use to determine if the signal should be blocked or not.
+ */
 void
 block_all_signals(int (*notifier)(void *priv), void *priv, sigset_t *mask)
 {
@@ -434,9 +434,10 @@ static void collect_signal(int sig, struct sigpending *list, siginfo_t *info)
 		copy_siginfo(info, &first->info);
 		__sigqueue_free(first);
 	} else {
-		/* Ok, it wasn't in the queue.  This must be
-		   a fast-pathed signal or we must have been
-		   out of queue space.  So zero out the info.
+		/*
+		 * Ok, it wasn't in the queue.  This must be
+		 * a fast-pathed signal or we must have been
+		 * out of queue space.  So zero out the info.
 		 */
 		info->si_signo = sig;
 		info->si_errno = 0;
@@ -468,7 +469,7 @@ static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,
 }
 
 /*
- * Dequeue a signal and return the element to the caller, which is 
+ * Dequeue a signal and return the element to the caller, which is
  * expected to free it.
  *
  * All callers have to hold the siglock.
@@ -490,7 +491,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 		 * itimers are process shared and we restart periodic
 		 * itimers in the signal delivery path to prevent DoS
 		 * attacks in the high resolution timer case. This is
-		 * compliant with the old way of self restarting
+		 * compliant with the old way of self-restarting
 		 * itimers, as the SIGALRM is a legacy signal and only
 		 * queued once. Changing the restart behaviour to
 		 * restart the timer in the signal dequeue path is
@@ -923,14 +924,15 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	if (info == SEND_SIG_FORCED)
 		goto out_set;
 
-	/* Real-time signals must be queued if sent by sigqueue, or
-	   some other real-time mechanism.  It is implementation
-	   defined whether kill() does so.  We attempt to do so, on
-	   the principle of least surprise, but since kill is not
-	   allowed to fail with EAGAIN when low on memory we just
-	   make sure at least one signal gets delivered and don't
-	   pass on the info struct.  */
-
+	/*
+	 * Real-time signals must be queued if sent by sigqueue, or
+	 * some other real-time mechanism.  It is implementation
+	 * defined whether kill() does so.  We attempt to do so, on
+	 * the principle of least surprise, but since kill is not
+	 * allowed to fail with EAGAIN when low on memory we just
+	 * make sure at least one signal gets delivered and don't
+	 * pass on the info struct.
+	 */
 	if (sig < SIGRTMIN)
 		override_rlimit = (is_si_special(info) || info->si_code >= 0);
 	else
@@ -1201,8 +1203,7 @@ int kill_pid_info(int sig, struct siginfo *info, struct pid *pid)
 	return error;
 }
 
-int
-kill_proc_info(int sig, struct siginfo *info, pid_t pid)
+int kill_proc_info(int sig, struct siginfo *info, pid_t pid)
 {
 	int error;
 	rcu_read_lock();
@@ -1299,8 +1300,7 @@ static int kill_something_info(int sig, struct siginfo *info, pid_t pid)
  * These are for backward compatibility with the rest of the kernel source.
  */
 
-int
-send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
+int send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 {
 	/*
 	 * Make sure legacy kernel users don't send in bad values
@@ -1368,7 +1368,7 @@ EXPORT_SYMBOL(kill_pid);
  * These functions support sending signals using preallocated sigqueue
  * structures.  This is needed "because realtime applications cannot
  * afford to lose notifications of asynchronous events, like timer
- * expirations or I/O completions".  In the case of Posix Timers
+ * expirations or I/O completions".  In the case of POSIX Timers
  * we allocate the sigqueue structure from the timer_create.  If this
  * allocation fails we are able to report the failure to the application
  * with an EAGAIN error.
@@ -1553,7 +1553,7 @@ static void do_notify_parent_cldstop(struct task_struct *tsk, int why)
 	info.si_signo = SIGCHLD;
 	info.si_errno = 0;
 	/*
-	 * see comment in do_notify_parent() abot the following 3 lines
+	 * see comment in do_notify_parent() about the following 4 lines
 	 */
 	rcu_read_lock();
 	info.si_pid = task_pid_nr_ns(tsk, parent->nsproxy->pid_ns);
@@ -1611,7 +1611,7 @@ static inline int may_ptrace_stop(void)
 }
 
 /*
- * Return nonzero if there is a SIGKILL that should be waking us up.
+ * Return non-zero if there is a SIGKILL that should be waking us up.
  * Called with the siglock held.
  */
 static int sigkill_pending(struct task_struct *tsk)
@@ -1735,7 +1735,7 @@ void ptrace_notify(int exit_code)
 /*
  * This performs the stopping for SIGSTOP and other stop signals.
  * We have to stop all threads in the thread group.
- * Returns nonzero if we've actually stopped and released the siglock.
+ * Returns non-zero if we've actually stopped and released the siglock.
  * Returns zero if we didn't stop and still hold the siglock.
  */
 static int do_signal_stop(int signr)
@@ -1823,10 +1823,12 @@ static int ptrace_signal(int signr, siginfo_t *info,
 
 	current->exit_code = 0;
 
-	/* Update the siginfo structure if the signal has
-	   changed.  If the debugger wanted something
-	   specific in the siginfo structure then it should
-	   have updated *info via PTRACE_SETSIGINFO.  */
+	/*
+	 * Update the siginfo structure if the signal has
+	 * changed.  If the debugger wanted something
+	 * specific in the siginfo structure then it should
+	 * have updated *info via PTRACE_SETSIGINFO.
+	 */
 	if (signr != info->si_signo) {
 		info->si_signo = signr;
 		info->si_errno = 0;
@@ -2034,7 +2036,8 @@ void exit_signals(struct task_struct *tsk)
 	if (!signal_pending(tsk))
 		goto out;
 
-	/* It could be that __group_complete_signal() choose us to
+	/*
+	 * It could be that __group_complete_signal() choose us to
 	 * notify about group-wide signal. Another thread should be
 	 * woken now to take the signal since we will not.
 	 */
@@ -2183,7 +2186,7 @@ long do_sigpending(void __user *set, unsigned long sigsetsize)
 
 out:
 	return error;
-}	
+}
 
 SYSCALL_DEFINE2(rt_sigpending, sigset_t __user *, set, size_t, sigsetsize)
 {
@@ -2233,9 +2236,9 @@ int copy_siginfo_to_user(siginfo_t __user *to, siginfo_t *from)
 		err |= __put_user(from->si_trapno, &to->si_trapno);
 #endif
 #ifdef BUS_MCEERR_AO
-		/* 
+		/*
 		 * Other callers might not initialize the si_lsb field,
-	 	 * so check explicitely for the right codes here.
+		 * so check explicitly for the right codes here.
 		 */
 		if (from->si_code == BUS_MCEERR_AR || from->si_code == BUS_MCEERR_AO)
 			err |= __put_user(from->si_addr_lsb, &to->si_addr_lsb);
@@ -2280,7 +2283,7 @@ SYSCALL_DEFINE4(rt_sigtimedwait, const sigset_t __user *, uthese,
 
 	if (copy_from_user(&these, uthese, sizeof(these)))
 		return -EFAULT;
-		
+
 	/*
 	 * Invert the set of allowed signals to get those we
 	 * want to block.
@@ -2305,9 +2308,11 @@ SYSCALL_DEFINE4(rt_sigtimedwait, const sigset_t __user *, uthese,
 				   + (ts.tv_sec || ts.tv_nsec));
 
 		if (timeout) {
-			/* None ready -- temporarily unblock those we're
+			/*
+			 * None ready -- temporarily unblock those we're
 			 * interested while we are sleeping in so that we'll
-			 * be awakened when they arrive.  */
+			 * be awakened when they arrive.
+			 */
 			current->real_blocked = current->blocked;
 			sigandsets(&current->blocked, &current->blocked, &these);
 			recalc_sigpending();
@@ -2553,12 +2558,11 @@ do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long s
 
 		error = -EINVAL;
 		/*
-		 *
-		 * Note - this code used to test ss_flags incorrectly
+		 * Note - this code used to test ss_flags incorrectly:
 		 *  	  old code may have been written using ss_flags==0
 		 *	  to mean ss_flags==SS_ONSTACK (as this was the only
 		 *	  way that worked) - this fix preserves that older
-		 *	  mechanism
+		 *	  mechanism.
 		 */
 		if (ss_flags != SS_DISABLE && ss_flags != SS_ONSTACK && ss_flags != 0)
 			goto out;
@@ -2600,8 +2604,10 @@ SYSCALL_DEFINE1(sigpending, old_sigset_t __user *, set)
 #endif
 
 #ifdef __ARCH_WANT_SYS_SIGPROCMASK
-/* Some platforms have their own version with special arguments others
-   support only sys_rt_sigprocmask.  */
+/*
+ * Some platforms have their own version with special arguments;
+ * others support only sys_rt_sigprocmask.
+ */
 
 SYSCALL_DEFINE3(sigprocmask, int, how, old_sigset_t __user *, set,
 		old_sigset_t __user *, oset)

commit ee77f075921730b2b465880f9fd4367003bdab39
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Apr 1 20:12:38 2011 +0200

    signal: Turn SIGNAL_STOP_DEQUEUED into GROUP_STOP_DEQUEUED
    
    This patch moves SIGNAL_STOP_DEQUEUED from signal_struct->flags to
    task_struct->group_stop, and thus makes it per-thread.
    
    Like SIGNAL_STOP_DEQUEUED, GROUP_STOP_DEQUEUED can be false-positive
    after return from get_signal_to_deliver(), this is fine. The only
    purpose of this bit is: we can drop ->siglock after __dequeue_signal()
    returns the sig_kernel_stop() signal and before we call
    do_signal_stop(), in this case we must not miss SIGCONT if it comes in
    between.
    
    But, unlike SIGNAL_STOP_DEQUEUED, GROUP_STOP_DEQUEUED can not be
    false-positive in do_signal_stop() if multiple threads dequeue the
    sig_kernel_stop() signal at the same time.
    
    Consider two threads T1 and T2, SIGTTIN has a hanlder.
    
            - T1 dequeues SIGTSTP and sets SIGNAL_STOP_DEQUEUED, then
              it drops ->siglock
    
            - SIGCONT comes and clears SIGNAL_STOP_DEQUEUED, SIGTSTP
              should be cancelled.
    
            - T2 dequeues SIGTTIN and sets SIGNAL_STOP_DEQUEUED again.
              Since we have a handler we should not stop, T2 returns
              to usermode to run the handler.
    
            - T1 continues, calls do_signal_stop() and wrongly starts
              the group stop because SIGNAL_STOP_DEQUEUED was restored
              in between.
    
    With or without this change:
    
            - we need to do something with ptrace_signal() which can
              return SIGSTOP, but this needs another discussion
    
            - SIGSTOP can be lost if it races with the mt exec, will
              be fixed later.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index e9abc69dc0d8..4f7312b49b2d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -254,7 +254,8 @@ static void task_clear_group_stop_trapping(struct task_struct *task)
  */
 void task_clear_group_stop_pending(struct task_struct *task)
 {
-	task->group_stop &= ~(GROUP_STOP_PENDING | GROUP_STOP_CONSUME);
+	task->group_stop &= ~(GROUP_STOP_PENDING | GROUP_STOP_CONSUME |
+			      GROUP_STOP_DEQUEUED);
 }
 
 /**
@@ -602,7 +603,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 		 * is to alert stop-signal processing code when another
 		 * processor has come along and cleared the flag.
 		 */
-		tsk->signal->flags |= SIGNAL_STOP_DEQUEUED;
+		current->group_stop |= GROUP_STOP_DEQUEUED;
 	}
 	if ((info->si_code & __SI_MASK) == __SI_TIMER && info->si_sys_private) {
 		/*
@@ -821,13 +822,6 @@ static int prepare_signal(int sig, struct task_struct *p, int from_ancestor_ns)
 			signal->flags = why | SIGNAL_STOP_CONTINUED;
 			signal->group_stop_count = 0;
 			signal->group_exit_code = 0;
-		} else {
-			/*
-			 * We are not stopped, but there could be a stop
-			 * signal in the middle of being processed after
-			 * being removed from the queue.  Clear that too.
-			 */
-			signal->flags &= ~SIGNAL_STOP_DEQUEUED;
 		}
 	}
 
@@ -1855,7 +1849,7 @@ static int do_signal_stop(int signr)
 		/* signr will be recorded in task->group_stop for retries */
 		WARN_ON_ONCE(signr & ~GROUP_STOP_SIGMASK);
 
-		if (!likely(sig->flags & SIGNAL_STOP_DEQUEUED) ||
+		if (!likely(current->group_stop & GROUP_STOP_DEQUEUED) ||
 		    unlikely(signal_group_exit(sig)))
 			return 0;
 		/*

commit 780006eac2fe7f4d2582da16a096e5a44c4767ff
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Apr 1 20:12:16 2011 +0200

    signal: do_signal_stop: Remove the unneeded task_clear_group_stop_pending()
    
    PF_EXITING or TASK_STOPPED has already called task_participate_group_stop()
    and cleared its ->group_stop. No need to do task_clear_group_stop_pending()
    when we start the new group stop.
    
    Add a small comment to explain the !task_is_stopped() check. Note that this
    check is not exactly right and it can lead to unnecessary stop later if the
    thread is TASK_PTRACED. What we need is task_participated_in_group_stop(),
    this will be solved later.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 38ea9e2f1831..e9abc69dc0d8 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1866,7 +1866,8 @@ static int do_signal_stop(int signr)
 		 * still in effect and then receive a stop signal and
 		 * initiate another group stop.  This deviates from the
 		 * usual behavior as two consecutive stop signals can't
-		 * cause two group stops when !ptraced.
+		 * cause two group stops when !ptraced.  That is why we
+		 * also check !task_is_stopped(t) below.
 		 *
 		 * The condition can be distinguished by testing whether
 		 * SIGNAL_STOP_STOPPED is already set.  Don't generate
@@ -1896,8 +1897,6 @@ static int do_signal_stop(int signr)
 				t->group_stop |= signr | gstop;
 				sig->group_stop_count++;
 				signal_wake_up(t, 0);
-			} else {
-				task_clear_group_stop_pending(t);
 			}
 		}
 	}

commit 1deac632fc3dcff33a6df3e82ef10c738ac13fe6
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Apr 1 20:11:50 2011 +0200

    signal: prepare_signal(SIGCONT) shouldn't play with TIF_SIGPENDING
    
    prepare_signal(SIGCONT) should never set TIF_SIGPENDING or wake up
    the TASK_INTERRUPTIBLE threads. We are going to call complete_signal()
    which should pick the right thread correctly. All we need is to wake
    up the TASK_STOPPED threads.
    
    If the task was stopped, it can't return to usermode without taking
    ->siglock. Otherwise we don't care, and the spurious TIF_SIGPENDING
    can't be useful.
    
    The comment says:
    
            * If there is a handler for SIGCONT, we must make
            * sure that no thread returns to user mode before
            * we post the signal
    
    It is not clear what this means. Probably, "when there's only a single
    thread" and this continues to be true. Otherwise, even if this SIGCONT
    is not private, with or without this change only one thread can dequeue
    SIGCONT, other threads can happily return to user mode before before
    that thread handles this signal.
    
    Note also that wake_up_state(t, __TASK_STOPPED) can't race with the task
    which changes its state, TASK_STOPPED state is protected by ->siglock as
    well.
    
    In short: when it comes to signal delivery, SIGCONT is the normal signal
    and does not need any special support.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index f799a054f292..38ea9e2f1831 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -788,37 +788,14 @@ static int prepare_signal(int sig, struct task_struct *p, int from_ancestor_ns)
 	} else if (sig == SIGCONT) {
 		unsigned int why;
 		/*
-		 * Remove all stop signals from all queues,
-		 * and wake all threads.
+		 * Remove all stop signals from all queues, wake all threads.
 		 */
 		rm_from_queue(SIG_KERNEL_STOP_MASK, &signal->shared_pending);
 		t = p;
 		do {
-			unsigned int state;
-
 			task_clear_group_stop_pending(t);
-
 			rm_from_queue(SIG_KERNEL_STOP_MASK, &t->pending);
-			/*
-			 * If there is a handler for SIGCONT, we must make
-			 * sure that no thread returns to user mode before
-			 * we post the signal, in case it was the only
-			 * thread eligible to run the signal handler--then
-			 * it must not do anything between resuming and
-			 * running the handler.  With the TIF_SIGPENDING
-			 * flag set, the thread will pause and acquire the
-			 * siglock that we hold now and until we've queued
-			 * the pending signal.
-			 *
-			 * Wake up the stopped thread _after_ setting
-			 * TIF_SIGPENDING
-			 */
-			state = __TASK_STOPPED;
-			if (sig_user_defined(t, SIGCONT) && !sigismember(&t->blocked, SIGCONT)) {
-				set_tsk_thread_flag(t, TIF_SIGPENDING);
-				state |= TASK_INTERRUPTIBLE;
-			}
-			wake_up_state(t, state);
+			wake_up_state(t, __TASK_STOPPED);
 		} while_each_thread(p, t);
 
 		/*

commit 25985edcedea6396277003854657b5f3cb31a628
Author: Lucas De Marchi <lucas.demarchi@profusion.mobi>
Date:   Wed Mar 30 22:57:33 2011 -0300

    Fix common misspellings
    
    Fixes generated by 'codespell' and manually reviewed.
    
    Signed-off-by: Lucas De Marchi <lucas.demarchi@profusion.mobi>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1186cf7fac77..f486d10f3b8e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1885,7 +1885,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 	for (;;) {
 		struct k_sigaction *ka;
 		/*
-		 * Tracing can induce an artifical signal and choose sigaction.
+		 * Tracing can induce an artificial signal and choose sigaction.
 		 * The return value in @signr determines the default action,
 		 * but @info->si_signo is the signal number we will report.
 		 */

commit 243b422af9ea9af4ead07a8ad54c90d4f9b6081a
Author: Roland Dreier <roland@purestorage.com>
Date:   Mon Mar 28 14:13:35 2011 -0700

    Relax si_code check in rt_sigqueueinfo and rt_tgsigqueueinfo
    
    Commit da48524eb206 ("Prevent rt_sigqueueinfo and rt_tgsigqueueinfo
    from spoofing the signal code") made the check on si_code too strict.
    There are several legitimate places where glibc wants to queue a
    negative si_code different from SI_QUEUE:
    
     - This was first noticed with glibc's aio implementation, which wants
       to queue a signal with si_code SI_ASYNCIO; the current kernel
       causes glibc's tst-aio4 test to fail because rt_sigqueueinfo()
       fails with EPERM.
    
     - Further examination of the glibc source shows that getaddrinfo_a()
       wants to use SI_ASYNCNL (which the kernel does not even define).
       The timer_create() fallback code wants to queue signals with SI_TIMER.
    
    As suggested by Oleg Nesterov <oleg@redhat.com>, loosen the check to
    forbid only the problematic SI_TKILL case.
    
    Reported-by: Klaus Dittrich <kladit@arcor.de>
    Acked-by: Julien Tinnes <jln@google.com>
    Cc: <stable@kernel.org>
    Signed-off-by: Roland Dreier <roland@purestorage.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 324eff5468ad..1186cf7fac77 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2437,7 +2437,7 @@ SYSCALL_DEFINE3(rt_sigqueueinfo, pid_t, pid, int, sig,
 	/* Not even root can pretend to send signals from the kernel.
 	 * Nor can they impersonate a kill()/tgkill(), which adds source info.
 	 */
-	if (info.si_code != SI_QUEUE) {
+	if (info.si_code >= 0 || info.si_code == SI_TKILL) {
 		/* We used to allow any < 0 si_code */
 		WARN_ON_ONCE(info.si_code < 0);
 		return -EPERM;
@@ -2457,7 +2457,7 @@ long do_rt_tgsigqueueinfo(pid_t tgid, pid_t pid, int sig, siginfo_t *info)
 	/* Not even root can pretend to send signals from the kernel.
 	 * Nor can they impersonate a kill()/tgkill(), which adds source info.
 	 */
-	if (info->si_code != SI_QUEUE) {
+	if (info->si_code >= 0 || info->si_code == SI_TKILL) {
 		/* We used to allow any < 0 si_code */
 		WARN_ON_ONCE(info->si_code < 0);
 		return -EPERM;

commit 39fd33933b0209e4b6254743f2cede07c5ad4c52
Author: Serge E. Hallyn <serge@hallyn.com>
Date:   Wed Mar 23 16:43:19 2011 -0700

    userns: allow killing tasks in your own or child userns
    
    Changelog:
            Dec  8: Fixed bug in my check_kill_permission pointed out by
                    Eric Biederman.
            Dec 13: Apply Eric's suggestion to pass target task into kill_ok_by_cred()
                    for clarity
            Dec 31: address comment by Eric Biederman:
                    don't need cred/tcred in check_kill_permission.
            Jan  1: use const cred struct.
            Jan 11: Per Bastian Blank's advice, clean up kill_ok_by_cred().
            Feb 16: kill_ok_by_cred: fix bad parentheses
            Feb 23: per akpm, let compiler inline kill_ok_by_cred
    
    Signed-off-by: Serge E. Hallyn <serge.hallyn@canonical.com>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: Daniel Lezcano <daniel.lezcano@free.fr>
    Acked-by: David Howells <dhowells@redhat.com>
    Cc: James Morris <jmorris@namei.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 31751868de88..324eff5468ad 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -635,6 +635,27 @@ static inline bool si_fromuser(const struct siginfo *info)
 		(!is_si_special(info) && SI_FROMUSER(info));
 }
 
+/*
+ * called with RCU read lock from check_kill_permission()
+ */
+static int kill_ok_by_cred(struct task_struct *t)
+{
+	const struct cred *cred = current_cred();
+	const struct cred *tcred = __task_cred(t);
+
+	if (cred->user->user_ns == tcred->user->user_ns &&
+	    (cred->euid == tcred->suid ||
+	     cred->euid == tcred->uid ||
+	     cred->uid  == tcred->suid ||
+	     cred->uid  == tcred->uid))
+		return 1;
+
+	if (ns_capable(tcred->user->user_ns, CAP_KILL))
+		return 1;
+
+	return 0;
+}
+
 /*
  * Bad permissions for sending the signal
  * - the caller must hold the RCU read lock
@@ -642,7 +663,6 @@ static inline bool si_fromuser(const struct siginfo *info)
 static int check_kill_permission(int sig, struct siginfo *info,
 				 struct task_struct *t)
 {
-	const struct cred *cred, *tcred;
 	struct pid *sid;
 	int error;
 
@@ -656,14 +676,8 @@ static int check_kill_permission(int sig, struct siginfo *info,
 	if (error)
 		return error;
 
-	cred = current_cred();
-	tcred = __task_cred(t);
 	if (!same_thread_group(current, t) &&
-	    (cred->euid ^ tcred->suid) &&
-	    (cred->euid ^ tcred->uid) &&
-	    (cred->uid  ^ tcred->suid) &&
-	    (cred->uid  ^ tcred->uid) &&
-	    !capable(CAP_KILL)) {
+	    !kill_ok_by_cred(t)) {
 		switch (sig) {
 		case SIGCONT:
 			sid = task_session(t);

commit 244056f9dbbc6dc4126a301c745fa3dd67d8af3c
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 23 10:37:01 2011 +0100

    job control: Don't send duplicate job control stop notification while ptraced
    
    Just as group_exit_code shouldn't be generated when a PTRACE_CONT'd
    task re-enters job control stop, notifiction for the event should be
    suppressed too.  The logic is the same as the group_exit_code
    generation suppression in do_signal_stop(), if SIGNAL_STOP_STOPPED is
    already set, the task is re-entering job control stop without
    intervening SIGCONT and the notifications should be suppressed.
    
    Test case follows.
    
      #include <stdio.h>
      #include <unistd.h>
      #include <signal.h>
      #include <time.h>
      #include <sys/ptrace.h>
      #include <sys/wait.h>
    
      static const struct timespec ts100ms = { .tv_nsec = 100000000 };
      static pid_t tracee, tracer;
    
      static const char *pid_who(pid_t pid)
      {
              return pid == tracee ? "tracee" : (pid == tracer ? "tracer" : "mommy ");
      }
    
      static void sigchld_sigaction(int signo, siginfo_t *si, void *ucxt)
      {
              printf("%s: SIG status=%02d code=%02d (%s)\n",
                     pid_who(getpid()), si->si_status, si->si_code,
                     pid_who(si->si_pid));
      }
    
      int main(void)
      {
              const struct sigaction chld_sa = { .sa_sigaction = sigchld_sigaction,
                                                 .sa_flags = SA_SIGINFO|SA_RESTART };
              siginfo_t si;
    
              sigaction(SIGCHLD, &chld_sa, NULL);
    
              tracee = fork();
              if (!tracee) {
                      tracee = getpid();
                      while (1)
                              pause();
              }
    
              kill(tracee, SIGSTOP);
              waitid(P_PID, tracee, &si, WSTOPPED);
    
              tracer = fork();
              if (!tracer) {
                      tracer = getpid();
                      ptrace(PTRACE_ATTACH, tracee, NULL, NULL);
                      waitid(P_PID, tracee, &si, WSTOPPED);
                      ptrace(PTRACE_CONT, tracee, NULL, (void *)(long)si.si_status);
                      waitid(P_PID, tracee, &si, WSTOPPED);
                      ptrace(PTRACE_CONT, tracee, NULL, (void *)(long)si.si_status);
                      waitid(P_PID, tracee, &si, WSTOPPED);
                      printf("tracer: detaching\n");
                      ptrace(PTRACE_DETACH, tracee, NULL, NULL);
                      return 0;
              }
    
              while (1)
                      pause();
              return 0;
      }
    
    Before the patch, the parent gets the second notification for the
    tracee after the tracer detaches.  si_status is zero because
    group_exit_code is not set by the group stop completion which
    triggered this notification.
    
      mommy : SIG status=19 code=05 (tracee)
      tracer: SIG status=00 code=05 (tracee)
      tracer: SIG status=19 code=04 (tracee)
      tracer: SIG status=00 code=05 (tracee)
      tracer: detaching
      mommy : SIG status=00 code=05 (tracee)
      mommy : SIG status=00 code=01 (tracer)
      ^C
    
    After the patch, the duplicate notification is gone.
    
      mommy : SIG status=19 code=05 (tracee)
      tracer: SIG status=00 code=05 (tracee)
      tracer: SIG status=19 code=04 (tracee)
      tracer: SIG status=00 code=05 (tracee)
      tracer: detaching
      mommy : SIG status=00 code=01 (tracer)
      ^C
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index f65403da4101..f799a054f292 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -268,6 +268,10 @@ void task_clear_group_stop_pending(struct task_struct *task)
  *
  * CONTEXT:
  * Must be called with @task->sighand->siglock held.
+ *
+ * RETURNS:
+ * %true if group stop completion should be notified to the parent, %false
+ * otherwise.
  */
 static bool task_participate_group_stop(struct task_struct *task)
 {
@@ -284,7 +288,11 @@ static bool task_participate_group_stop(struct task_struct *task)
 	if (!WARN_ON_ONCE(sig->group_stop_count == 0))
 		sig->group_stop_count--;
 
-	if (!sig->group_stop_count) {
+	/*
+	 * Tell the caller to notify completion iff we are entering into a
+	 * fresh group stop.  Read comment in do_signal_stop() for details.
+	 */
+	if (!sig->group_stop_count && !(sig->flags & SIGNAL_STOP_STOPPED)) {
 		sig->flags = SIGNAL_STOP_STOPPED;
 		return true;
 	}

commit ceb6bd67f9b9db765e1c29405f26e8460391badd
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 23 10:37:01 2011 +0100

    job control: Notify the real parent of job control events regardless of ptrace
    
    With recent changes, job control and ptrace stopped states are
    properly separated and accessible to the real parent and the ptracer
    respectively; however, notifications of job control stopped/continued
    events to the real parent while ptraced are still missing.
    
    A ptracee participates in group stop in ptrace_stop() but the
    completion isn't notified.  If participation results in completion of
    group stop, notify the real parent of the event.  The ptrace and group
    stops are separate and can be handled as such.
    
    However, when the real parent and the ptracer are in the same thread
    group, only the ptrace stop event is visible through wait(2) and the
    duplicate notifications are different from the current behavior and
    are confusing.  Suppress group stop notification in such cases.
    
    The continued state is shared between the real parent and the ptracer
    but is only meaningful to the real parent.  Always notify the real
    parent and notify the ptracer too for backward compatibility.  Similar
    to stop notification, if the real parent is the ptracer, suppress a
    duplicate notification.
    
    Test case follows.
    
      #include <stdio.h>
      #include <unistd.h>
      #include <time.h>
      #include <errno.h>
      #include <sys/types.h>
      #include <sys/ptrace.h>
      #include <sys/wait.h>
    
      int main(void)
      {
              const struct timespec ts100ms = { .tv_nsec = 100000000 };
              pid_t tracee, tracer;
              siginfo_t si;
              int i;
    
              tracee = fork();
              if (tracee == 0) {
                      while (1) {
                              printf("tracee: SIGSTOP\n");
                              raise(SIGSTOP);
                              nanosleep(&ts100ms, NULL);
                              printf("tracee: SIGCONT\n");
                              raise(SIGCONT);
                              nanosleep(&ts100ms, NULL);
                      }
              }
    
              waitid(P_PID, tracee, &si, WSTOPPED | WNOHANG | WNOWAIT);
    
              tracer = fork();
              if (tracer == 0) {
                      nanosleep(&ts100ms, NULL);
                      ptrace(PTRACE_ATTACH, tracee, NULL, NULL);
    
                      for (i = 0; i < 11; i++) {
                              si.si_pid = 0;
                              waitid(P_PID, tracee, &si, WSTOPPED);
                              if (si.si_pid && si.si_code == CLD_TRAPPED)
                                      ptrace(PTRACE_CONT, tracee, NULL,
                                             (void *)(long)si.si_status);
                      }
                      printf("tracer: EXITING\n");
                      return 0;
              }
    
              while (1) {
                      si.si_pid = 0;
                      waitid(P_PID, tracee, &si, WSTOPPED | WCONTINUED | WEXITED);
                      if (si.si_pid)
                              printf("mommy : WAIT status=%02d code=%02d\n",
                                     si.si_status, si.si_code);
              }
              return 0;
      }
    
    Before this patch, while ptraced, the real parent doesn't get
    notifications for job control events, so although it can access those
    events, the later waitid(2) call never wakes up.
    
      tracee: SIGSTOP
      mommy : WAIT status=19 code=05
      tracee: SIGCONT
      tracee: SIGSTOP
      tracee: SIGCONT
      tracee: SIGSTOP
      tracee: SIGCONT
      tracee: SIGSTOP
      tracer: EXITING
      mommy : WAIT status=19 code=05
      ^C
    
    After this patch, it works as expected.
    
      tracee: SIGSTOP
      mommy : WAIT status=19 code=05
      tracee: SIGCONT
      mommy : WAIT status=18 code=06
      tracee: SIGSTOP
      mommy : WAIT status=19 code=05
      tracee: SIGCONT
      mommy : WAIT status=18 code=06
      tracee: SIGSTOP
      mommy : WAIT status=19 code=05
      tracee: SIGCONT
      mommy : WAIT status=18 code=06
      tracee: SIGSTOP
      tracer: EXITING
      mommy : WAIT status=19 code=05
      ^C
    
    -v2: Oleg pointed out that
    
         * Group stop notification to the real parent should also happen
           when ptracer detach races with ptrace_stop().
    
         * real_parent_is_ptracer() should be testing thread group
           equality not the task itself as wait(2) and stop/cont
           notifications are normally thread-group wide.
    
         Both issues are fixed accordingly.
    
    -v3: real_parent_is_ptracer() updated to test child->real_parent
         instead of child->group_leader->real_parent per Oleg's
         suggestion.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9f10b246fd46..f65403da4101 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1693,6 +1693,15 @@ static int sigkill_pending(struct task_struct *tsk)
 		sigismember(&tsk->signal->shared_pending.signal, SIGKILL);
 }
 
+/*
+ * Test whether the target task of the usual cldstop notification - the
+ * real_parent of @child - is in the same group as the ptracer.
+ */
+static bool real_parent_is_ptracer(struct task_struct *child)
+{
+	return same_thread_group(child->parent, child->real_parent);
+}
+
 /*
  * This must be called with current->sighand->siglock held.
  *
@@ -1708,6 +1717,8 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 	__releases(&current->sighand->siglock)
 	__acquires(&current->sighand->siglock)
 {
+	bool gstop_done = false;
+
 	if (arch_ptrace_stop_needed(exit_code, info)) {
 		/*
 		 * The arch code has something special to do before a
@@ -1735,7 +1746,7 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 	 * is entered - ignore it.
 	 */
 	if (why == CLD_STOPPED && (current->group_stop & GROUP_STOP_PENDING))
-		task_participate_group_stop(current);
+		gstop_done = task_participate_group_stop(current);
 
 	current->last_siginfo = info;
 	current->exit_code = exit_code;
@@ -1757,7 +1768,20 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 	spin_unlock_irq(&current->sighand->siglock);
 	read_lock(&tasklist_lock);
 	if (may_ptrace_stop()) {
-		do_notify_parent_cldstop(current, task_ptrace(current), why);
+		/*
+		 * Notify parents of the stop.
+		 *
+		 * While ptraced, there are two parents - the ptracer and
+		 * the real_parent of the group_leader.  The ptracer should
+		 * know about every stop while the real parent is only
+		 * interested in the completion of group stop.  The states
+		 * for the two don't interact with each other.  Notify
+		 * separately unless they're gonna be duplicates.
+		 */
+		do_notify_parent_cldstop(current, true, why);
+		if (gstop_done && !real_parent_is_ptracer(current))
+			do_notify_parent_cldstop(current, false, why);
+
 		/*
 		 * Don't want to allow preemption here, because
 		 * sys_ptrace() needs this task to be inactive.
@@ -1772,7 +1796,16 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 		/*
 		 * By the time we got the lock, our tracer went away.
 		 * Don't drop the lock yet, another tracer may come.
+		 *
+		 * If @gstop_done, the ptracer went away between group stop
+		 * completion and here.  During detach, it would have set
+		 * GROUP_STOP_PENDING on us and we'll re-enter TASK_STOPPED
+		 * in do_signal_stop() on return, so notifying the real
+		 * parent of the group stop completion is enough.
 		 */
+		if (gstop_done)
+			do_notify_parent_cldstop(current, false, why);
+
 		__set_current_state(TASK_RUNNING);
 		if (clear_code)
 			current->exit_code = 0;
@@ -2017,10 +2050,24 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 
 		spin_unlock_irq(&sighand->siglock);
 
+		/*
+		 * Notify the parent that we're continuing.  This event is
+		 * always per-process and doesn't make whole lot of sense
+		 * for ptracers, who shouldn't consume the state via
+		 * wait(2) either, but, for backward compatibility, notify
+		 * the ptracer of the group leader too unless it's gonna be
+		 * a duplicate.
+		 */
 		read_lock(&tasklist_lock);
+
+		do_notify_parent_cldstop(current, false, why);
+
 		leader = current->group_leader;
-		do_notify_parent_cldstop(leader, task_ptrace(leader), why);
+		if (task_ptrace(leader) && !real_parent_is_ptracer(leader))
+			do_notify_parent_cldstop(leader, true, why);
+
 		read_unlock(&tasklist_lock);
+
 		goto relock;
 	}
 

commit 62bcf9d992ecc19ea4f37ff57ee0b3333e3e843e
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 23 10:37:01 2011 +0100

    job control: Job control stop notifications should always go to the real parent
    
    The stopped notifications in do_signal_stop() and exit_signals() are
    always for the completion of job control.  The one in do_signal_stop()
    may be delivered to the ptracer if PTRACE_ATTACH races with
    notification and the one in exit_signals() if task exits while
    ptraced.
    
    In both cases, the notifications are meaningless and confusing to the
    ptracer as it never accesses the group stop state while the real
    parent would miss notifications for the events it is watching.
    
    Make sure these notifications always go to the real parent by calling
    do_notify_parent_cld_stop() with %false @for_ptrace.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 69d60540a680..9f10b246fd46 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1898,10 +1898,18 @@ static int do_signal_stop(int signr)
 		__set_current_state(TASK_STOPPED);
 		spin_unlock_irq(&current->sighand->siglock);
 
+		/*
+		 * Notify the parent of the group stop completion.  Because
+		 * we're not holding either the siglock or tasklist_lock
+		 * here, ptracer may attach inbetween; however, this is for
+		 * group stop and should always be delivered to the real
+		 * parent of the group leader.  The new ptracer will get
+		 * its notification when this task transitions into
+		 * TASK_TRACED.
+		 */
 		if (notify) {
 			read_lock(&tasklist_lock);
-			do_notify_parent_cldstop(current, task_ptrace(current),
-						 notify);
+			do_notify_parent_cldstop(current, false, notify);
 			read_unlock(&tasklist_lock);
 		}
 
@@ -2182,9 +2190,13 @@ void exit_signals(struct task_struct *tsk)
 out:
 	spin_unlock_irq(&tsk->sighand->siglock);
 
+	/*
+	 * If group stop has completed, deliver the notification.  This
+	 * should always go to the real parent of the group leader.
+	 */
 	if (unlikely(group_stop)) {
 		read_lock(&tasklist_lock);
-		do_notify_parent_cldstop(tsk, task_ptrace(tsk), group_stop);
+		do_notify_parent_cldstop(tsk, false, group_stop);
 		read_unlock(&tasklist_lock);
 	}
 }

commit 75b95953a56969a990e6ce154b260be83818fe71
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 23 10:37:01 2011 +0100

    job control: Add @for_ptrace to do_notify_parent_cldstop()
    
    Currently, do_notify_parent_cldstop() determines whether the
    notification is for the real parent or ptracer.  Move the decision to
    the caller by adding @for_ptrace parameter to
    do_notify_parent_cldstop().  All the callers are updated to pass
    task_ptrace(target_task), so this patch doesn't cause any behavior
    difference.
    
    While at it, add function comment to do_notify_parent_cldstop().
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2f2c8f6ee01f..69d60540a680 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1595,16 +1595,30 @@ int do_notify_parent(struct task_struct *tsk, int sig)
 	return ret;
 }
 
-static void do_notify_parent_cldstop(struct task_struct *tsk, int why)
+/**
+ * do_notify_parent_cldstop - notify parent of stopped/continued state change
+ * @tsk: task reporting the state change
+ * @for_ptracer: the notification is for ptracer
+ * @why: CLD_{CONTINUED|STOPPED|TRAPPED} to report
+ *
+ * Notify @tsk's parent that the stopped/continued state has changed.  If
+ * @for_ptracer is %false, @tsk's group leader notifies to its real parent.
+ * If %true, @tsk reports to @tsk->parent which should be the ptracer.
+ *
+ * CONTEXT:
+ * Must be called with tasklist_lock at least read locked.
+ */
+static void do_notify_parent_cldstop(struct task_struct *tsk,
+				     bool for_ptracer, int why)
 {
 	struct siginfo info;
 	unsigned long flags;
 	struct task_struct *parent;
 	struct sighand_struct *sighand;
 
-	if (task_ptrace(tsk))
+	if (for_ptracer) {
 		parent = tsk->parent;
-	else {
+	} else {
 		tsk = tsk->group_leader;
 		parent = tsk->real_parent;
 	}
@@ -1743,7 +1757,7 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 	spin_unlock_irq(&current->sighand->siglock);
 	read_lock(&tasklist_lock);
 	if (may_ptrace_stop()) {
-		do_notify_parent_cldstop(current, why);
+		do_notify_parent_cldstop(current, task_ptrace(current), why);
 		/*
 		 * Don't want to allow preemption here, because
 		 * sys_ptrace() needs this task to be inactive.
@@ -1886,7 +1900,8 @@ static int do_signal_stop(int signr)
 
 		if (notify) {
 			read_lock(&tasklist_lock);
-			do_notify_parent_cldstop(current, notify);
+			do_notify_parent_cldstop(current, task_ptrace(current),
+						 notify);
 			read_unlock(&tasklist_lock);
 		}
 
@@ -1982,6 +1997,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 	 * the CLD_ si_code into SIGNAL_CLD_MASK bits.
 	 */
 	if (unlikely(signal->flags & SIGNAL_CLD_MASK)) {
+		struct task_struct *leader;
 		int why;
 
 		if (signal->flags & SIGNAL_CLD_CONTINUED)
@@ -1994,7 +2010,8 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		spin_unlock_irq(&sighand->siglock);
 
 		read_lock(&tasklist_lock);
-		do_notify_parent_cldstop(current->group_leader, why);
+		leader = current->group_leader;
+		do_notify_parent_cldstop(leader, task_ptrace(leader), why);
 		read_unlock(&tasklist_lock);
 		goto relock;
 	}
@@ -2167,7 +2184,7 @@ void exit_signals(struct task_struct *tsk)
 
 	if (unlikely(group_stop)) {
 		read_lock(&tasklist_lock);
-		do_notify_parent_cldstop(tsk, group_stop);
+		do_notify_parent_cldstop(tsk, task_ptrace(tsk), group_stop);
 		read_unlock(&tasklist_lock);
 	}
 }

commit 408a37de6c95832a4880a88a742f89f0cc554d06
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 23 10:37:01 2011 +0100

    job control: Don't set group_stop exit_code if re-entering job control stop
    
    While ptraced, a task may be resumed while the containing process is
    still job control stopped.  If the task receives another stop signal
    in this state, it will still initiate group stop, which generates
    group_exit_code, which the real parent would be able to see once the
    ptracer detaches.
    
    In this scenario, the real parent may see two consecutive CLD_STOPPED
    events from two stop signals without intervening SIGCONT, which
    normally is impossible.
    
    Test case follows.
    
      #include <stdio.h>
      #include <unistd.h>
      #include <sys/ptrace.h>
      #include <sys/wait.h>
    
      int main(void)
      {
              pid_t tracee;
              siginfo_t si;
    
              tracee = fork();
              if (!tracee)
                      while (1)
                              pause();
    
              kill(tracee, SIGSTOP);
              waitid(P_PID, tracee, &si, WSTOPPED);
    
              if (!fork()) {
                      ptrace(PTRACE_ATTACH, tracee, NULL, NULL);
                      waitid(P_PID, tracee, &si, WSTOPPED);
                      ptrace(PTRACE_CONT, tracee, NULL, (void *)(long)si.si_status);
                      waitid(P_PID, tracee, &si, WSTOPPED);
                      ptrace(PTRACE_CONT, tracee, NULL, (void *)(long)si.si_status);
                      waitid(P_PID, tracee, &si, WSTOPPED);
                      ptrace(PTRACE_DETACH, tracee, NULL, NULL);
                      return 0;
              }
    
              while (1) {
                      si.si_pid = 0;
                      waitid(P_PID, tracee, &si, WSTOPPED | WNOHANG);
                      if (si.si_pid)
                              printf("st=%02d c=%02d\n", si.si_status, si.si_code);
              }
              return 0;
      }
    
    Before the patch, the latter waitid() in polling mode reports the
    second stopped event generated by the implied SIGSTOP of
    PTRACE_ATTACH.
    
      st=19 c=05
      ^C
    
    After the patch, the second event is not reported.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1e199919ae09..2f2c8f6ee01f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1827,10 +1827,27 @@ static int do_signal_stop(int signr)
 		    unlikely(signal_group_exit(sig)))
 			return 0;
 		/*
-		 * There is no group stop already in progress.
-		 * We must initiate one now.
+		 * There is no group stop already in progress.  We must
+		 * initiate one now.
+		 *
+		 * While ptraced, a task may be resumed while group stop is
+		 * still in effect and then receive a stop signal and
+		 * initiate another group stop.  This deviates from the
+		 * usual behavior as two consecutive stop signals can't
+		 * cause two group stops when !ptraced.
+		 *
+		 * The condition can be distinguished by testing whether
+		 * SIGNAL_STOP_STOPPED is already set.  Don't generate
+		 * group_exit_code in such case.
+		 *
+		 * This is not necessary for SIGNAL_STOP_CONTINUED because
+		 * an intervening stop signal is required to cause two
+		 * continued events regardless of ptrace.
 		 */
-		sig->group_exit_code = signr;
+		if (!(sig->flags & SIGNAL_STOP_STOPPED))
+			sig->group_exit_code = signr;
+		else
+			WARN_ON_ONCE(!task_ptrace(current));
 
 		current->group_stop &= ~GROUP_STOP_SIGMASK;
 		current->group_stop |= signr | gstop;

commit d79fdd6d96f46fabb779d86332e3677c6f5c2a4f
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 23 10:37:00 2011 +0100

    ptrace: Clean transitions between TASK_STOPPED and TRACED
    
    Currently, if the task is STOPPED on ptrace attach, it's left alone
    and the state is silently changed to TRACED on the next ptrace call.
    The behavior breaks the assumption that arch_ptrace_stop() is called
    before any task is poked by ptrace and is ugly in that a task
    manipulates the state of another task directly.
    
    With GROUP_STOP_PENDING, the transitions between TASK_STOPPED and
    TRACED can be made clean.  The tracer can use the flag to tell the
    tracee to retry stop on attach and detach.  On retry, the tracee will
    enter the desired state in the correct way.  The lower 16bits of
    task->group_stop is used to remember the signal number which caused
    the last group stop.  This is used while retrying for ptrace attach as
    the original group_exit_code could have been consumed with wait(2) by
    then.
    
    As the real parent may wait(2) and consume the group_exit_code
    anytime, the group_exit_code needs to be saved separately so that it
    can be used when switching from regular sleep to ptrace_stop().  This
    is recorded in the lower 16bits of task->group_stop.
    
    If a task is already stopped and there's no intervening SIGCONT, a
    ptrace request immediately following a successful PTRACE_ATTACH should
    always succeed even if the tracer doesn't wait(2) for attach
    completion; however, with this change, the tracee might still be
    TASK_RUNNING trying to enter TASK_TRACED which would cause the
    following request to fail with -ESRCH.
    
    This intermediate state is hidden from the ptracer by setting
    GROUP_STOP_TRAPPING on attach and making ptrace_check_attach() wait
    for it to clear on its signal->wait_chldexit.  Completing the
    transition or getting killed clears TRAPPING and wakes up the tracer.
    
    Note that the STOPPED -> RUNNING -> TRACED transition is still visible
    to other threads which are in the same group as the ptracer and the
    reverse transition is visible to all.  Please read the comments for
    details.
    
    Oleg:
    
    * Spotted a race condition where a task may retry group stop without
      proper bookkeeping.  Fixed by redoing bookkeeping on retry.
    
    * Spotted that the transition is visible to userland in several
      different ways.  Most are fixed with GROUP_STOP_TRAPPING.  Unhandled
      corner case is documented.
    
    * Pointed out not setting GROUP_STOP_SIGMASK on an already stopped
      task would result in more consistent behavior.
    
    * Pointed out that calling ptrace_stop() from do_signal_stop() in
      TASK_STOPPED can race with group stop start logic and then confuse
      the TRAPPING wait in ptrace_check_attach().  ptrace_stop() is now
      called with TASK_RUNNING.
    
    * Suggested using signal->wait_chldexit instead of bit wait.
    
    * Spotted a race condition between TRACED transition and clearing of
      TRAPPING.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Jan Kratochvil <jan.kratochvil@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 418776c41d24..1e199919ae09 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -223,6 +223,26 @@ static inline void print_dropped_signal(int sig)
 				current->comm, current->pid, sig);
 }
 
+/**
+ * task_clear_group_stop_trapping - clear group stop trapping bit
+ * @task: target task
+ *
+ * If GROUP_STOP_TRAPPING is set, a ptracer is waiting for us.  Clear it
+ * and wake up the ptracer.  Note that we don't need any further locking.
+ * @task->siglock guarantees that @task->parent points to the ptracer.
+ *
+ * CONTEXT:
+ * Must be called with @task->sighand->siglock held.
+ */
+static void task_clear_group_stop_trapping(struct task_struct *task)
+{
+	if (unlikely(task->group_stop & GROUP_STOP_TRAPPING)) {
+		task->group_stop &= ~GROUP_STOP_TRAPPING;
+		__wake_up_sync(&task->parent->signal->wait_chldexit,
+			       TASK_UNINTERRUPTIBLE, 1);
+	}
+}
+
 /**
  * task_clear_group_stop_pending - clear pending group stop
  * @task: target task
@@ -1706,8 +1726,20 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 	current->last_siginfo = info;
 	current->exit_code = exit_code;
 
-	/* Let the debugger run.  */
-	__set_current_state(TASK_TRACED);
+	/*
+	 * TRACED should be visible before TRAPPING is cleared; otherwise,
+	 * the tracer might fail do_wait().
+	 */
+	set_current_state(TASK_TRACED);
+
+	/*
+	 * We're committing to trapping.  Clearing GROUP_STOP_TRAPPING and
+	 * transition to TASK_TRACED should be atomic with respect to
+	 * siglock.  This hsould be done after the arch hook as siglock is
+	 * released and regrabbed across it.
+	 */
+	task_clear_group_stop_trapping(current);
+
 	spin_unlock_irq(&current->sighand->siglock);
 	read_lock(&tasklist_lock);
 	if (may_ptrace_stop()) {
@@ -1788,6 +1820,9 @@ static int do_signal_stop(int signr)
 		unsigned int gstop = GROUP_STOP_PENDING | GROUP_STOP_CONSUME;
 		struct task_struct *t;
 
+		/* signr will be recorded in task->group_stop for retries */
+		WARN_ON_ONCE(signr & ~GROUP_STOP_SIGMASK);
+
 		if (!likely(sig->flags & SIGNAL_STOP_DEQUEUED) ||
 		    unlikely(signal_group_exit(sig)))
 			return 0;
@@ -1797,25 +1832,27 @@ static int do_signal_stop(int signr)
 		 */
 		sig->group_exit_code = signr;
 
-		current->group_stop = gstop;
+		current->group_stop &= ~GROUP_STOP_SIGMASK;
+		current->group_stop |= signr | gstop;
 		sig->group_stop_count = 1;
-		for (t = next_thread(current); t != current; t = next_thread(t))
+		for (t = next_thread(current); t != current;
+		     t = next_thread(t)) {
+			t->group_stop &= ~GROUP_STOP_SIGMASK;
 			/*
 			 * Setting state to TASK_STOPPED for a group
 			 * stop is always done with the siglock held,
 			 * so this check has no races.
 			 */
 			if (!(t->flags & PF_EXITING) && !task_is_stopped(t)) {
-				t->group_stop = gstop;
+				t->group_stop |= signr | gstop;
 				sig->group_stop_count++;
 				signal_wake_up(t, 0);
-			} else
+			} else {
 				task_clear_group_stop_pending(t);
+			}
+		}
 	}
-
-	current->exit_code = sig->group_exit_code;
-	__set_current_state(TASK_STOPPED);
-
+retry:
 	if (likely(!task_ptrace(current))) {
 		int notify = 0;
 
@@ -1827,6 +1864,7 @@ static int do_signal_stop(int signr)
 		if (task_participate_group_stop(current))
 			notify = CLD_STOPPED;
 
+		__set_current_state(TASK_STOPPED);
 		spin_unlock_irq(&current->sighand->siglock);
 
 		if (notify) {
@@ -1839,13 +1877,28 @@ static int do_signal_stop(int signr)
 		schedule();
 
 		spin_lock_irq(&current->sighand->siglock);
-	} else
-		ptrace_stop(current->exit_code, CLD_STOPPED, 0, NULL);
+	} else {
+		ptrace_stop(current->group_stop & GROUP_STOP_SIGMASK,
+			    CLD_STOPPED, 0, NULL);
+		current->exit_code = 0;
+	}
+
+	/*
+	 * GROUP_STOP_PENDING could be set if another group stop has
+	 * started since being woken up or ptrace wants us to transit
+	 * between TASK_STOPPED and TRACED.  Retry group stop.
+	 */
+	if (current->group_stop & GROUP_STOP_PENDING) {
+		WARN_ON_ONCE(!(current->group_stop & GROUP_STOP_SIGMASK));
+		goto retry;
+	}
+
+	/* PTRACE_ATTACH might have raced with task killing, clear trapping */
+	task_clear_group_stop_trapping(current);
 
 	spin_unlock_irq(&current->sighand->siglock);
 
 	tracehook_finish_jctl();
-	current->exit_code = 0;
 
 	return 1;
 }

commit 5224fa3660ad3881d2f2ad726d22614117963f10
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 23 10:37:00 2011 +0100

    ptrace: Make do_signal_stop() use ptrace_stop() if the task is being ptraced
    
    A ptraced task would still stop at do_signal_stop() when it's stopping
    for stop signals and do_signal_stop() behaves the same whether the
    task is ptraced or not.  However, in addition to stopping,
    ptrace_stop() also does ptrace specific stuff like calling
    architecture specific callbacks, so this behavior makes the code more
    fragile and difficult to understand.
    
    This patch makes do_signal_stop() test whether the task is ptraced and
    use ptrace_stop() if so.  This renders tracehook_notify_jctl() rather
    pointless as the ptrace notification is now handled by ptrace_stop()
    regardless of the return value from the tracehook.  It probably is a
    good idea to update it.
    
    This doesn't solve the whole problem as tasks already in stopped state
    would stay in the regular stop when ptrace attached.  That part will
    be handled by the next patch.
    
    Oleg pointed out that this makes a userland-visible change.  Before,
    SIGCONT would be able to wake up a task in group stop even if the task
    is ptraced if the tracer hasn't issued another ptrace command
    afterwards (as the next ptrace commands transitions the state into
    TASK_TRACED which ignores SIGCONT wakeups).  With this and the next
    patch, SIGCONT may race with the transition into TASK_TRACED and is
    ignored if the tracee already entered TASK_TRACED.
    
    Another userland visible change of this and the next patch is that the
    ptracee's state would now be TASK_TRACED where it used to be
    TASK_STOPPED, which is visible via fs/proc.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Jan Kratochvil <jan.kratochvil@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9f36dd2e8d5a..418776c41d24 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1783,7 +1783,6 @@ void ptrace_notify(int exit_code)
 static int do_signal_stop(int signr)
 {
 	struct signal_struct *sig = current->signal;
-	int notify = 0;
 
 	if (!(current->group_stop & GROUP_STOP_PENDING)) {
 		unsigned int gstop = GROUP_STOP_PENDING | GROUP_STOP_CONSUME;
@@ -1813,29 +1812,37 @@ static int do_signal_stop(int signr)
 			} else
 				task_clear_group_stop_pending(t);
 	}
-	/*
-	 * If there are no other threads in the group, or if there is
-	 * a group stop in progress and we are the last to stop, report
-	 * to the parent.  When ptraced, every thread reports itself.
-	 */
-	if (task_participate_group_stop(current))
-		notify = CLD_STOPPED;
-	if (task_ptrace(current))
-		notify = CLD_STOPPED;
 
 	current->exit_code = sig->group_exit_code;
 	__set_current_state(TASK_STOPPED);
 
-	spin_unlock_irq(&current->sighand->siglock);
+	if (likely(!task_ptrace(current))) {
+		int notify = 0;
 
-	if (notify) {
-		read_lock(&tasklist_lock);
-		do_notify_parent_cldstop(current, notify);
-		read_unlock(&tasklist_lock);
-	}
+		/*
+		 * If there are no other threads in the group, or if there
+		 * is a group stop in progress and we are the last to stop,
+		 * report to the parent.
+		 */
+		if (task_participate_group_stop(current))
+			notify = CLD_STOPPED;
 
-	/* Now we don't run again until woken by SIGCONT or SIGKILL */
-	schedule();
+		spin_unlock_irq(&current->sighand->siglock);
+
+		if (notify) {
+			read_lock(&tasklist_lock);
+			do_notify_parent_cldstop(current, notify);
+			read_unlock(&tasklist_lock);
+		}
+
+		/* Now we don't run again until woken by SIGCONT or SIGKILL */
+		schedule();
+
+		spin_lock_irq(&current->sighand->siglock);
+	} else
+		ptrace_stop(current->exit_code, CLD_STOPPED, 0, NULL);
+
+	spin_unlock_irq(&current->sighand->siglock);
 
 	tracehook_finish_jctl();
 	current->exit_code = 0;

commit 0ae8ce1c8c5b9007ce6bfc83ec2aa0dfce5bbed3
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 23 10:37:00 2011 +0100

    ptrace: Participate in group stop from ptrace_stop() iff the task is trapping for group stop
    
    Currently, ptrace_stop() unconditionally participates in group stop
    bookkeeping.  This is unnecessary and inaccurate.  Make it only
    participate if the task is trapping for group stop - ie. if @why is
    CLD_STOPPED.  As ptrace_stop() currently is not used when trapping for
    group stop, this equals to disabling group stop participation from
    ptrace_stop().
    
    A visible behavior change is increased likelihood of delayed group
    stop completion if the thread group contains one or more ptraced
    tasks.
    
    This is to preapre for further cleanup of the interaction between
    group stop and ptrace.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index a2e7a6527d24..9f36dd2e8d5a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1694,10 +1694,13 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 	}
 
 	/*
-	 * If there is a group stop in progress,
-	 * we must participate in the bookkeeping.
+	 * If @why is CLD_STOPPED, we're trapping to participate in a group
+	 * stop.  Do the bookkeeping.  Note that if SIGCONT was delievered
+	 * while siglock was released for the arch hook, PENDING could be
+	 * clear now.  We act as if SIGCONT is received after TASK_TRACED
+	 * is entered - ignore it.
 	 */
-	if (current->group_stop & GROUP_STOP_PENDING)
+	if (why == CLD_STOPPED && (current->group_stop & GROUP_STOP_PENDING))
 		task_participate_group_stop(current);
 
 	current->last_siginfo = info;

commit 39efa3ef3a376a4e53de2f82fc91182459d34200
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 23 10:37:00 2011 +0100

    signal: Use GROUP_STOP_PENDING to stop once for a single group stop
    
    Currently task->signal->group_stop_count is used to decide whether to
    stop for group stop.  However, if there is a task in the group which
    is taking a long time to stop, other tasks which are continued by
    ptrace would repeatedly stop for the same group stop until the group
    stop is complete.
    
    Conversely, if a ptraced task is in TASK_TRACED state, the debugger
    won't get notified of group stops which is inconsistent compared to
    the ptraced task in any other state.
    
    This patch introduces GROUP_STOP_PENDING which tracks whether a task
    is yet to stop for the group stop in progress.  The flag is set when a
    group stop starts and cleared when the task stops the first time for
    the group stop, and consulted whenever whether the task should
    participate in a group stop needs to be determined.  Note that now
    tasks in TASK_TRACED also participate in group stop.
    
    This results in the following behavior changes.
    
    * For a single group stop, a ptracer would see at most one stop
      reported.
    
    * A ptracee in TASK_TRACED now also participates in group stop and the
      tracer would get the notification.  However, as a ptraced task could
      be in TASK_STOPPED state or any ptrace trap could consume group
      stop, the notification may still be missing.  These will be
      addressed with further patches.
    
    * A ptracee may start a group stop while one is still in progress if
      the tracer let it continue with stop signal delivery.  Group stop
      code handles this correctly.
    
    Oleg:
    
    * Spotted that a task might skip signal check even when its
      GROUP_STOP_PENDING is set.  Fixed by updating
      recalc_sigpending_tsk() to check GROUP_STOP_PENDING instead of
      group_stop_count.
    
    * Pointed out that task->group_stop should be cleared whenever
      task->signal->group_stop_count is cleared.  Fixed accordingly.
    
    * Pointed out the behavior inconsistency between TASK_TRACED and
      RUNNING and the last behavior change.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index ecb20089eaff..a2e7a6527d24 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -124,7 +124,7 @@ static inline int has_pending_signals(sigset_t *signal, sigset_t *blocked)
 
 static int recalc_sigpending_tsk(struct task_struct *t)
 {
-	if (t->signal->group_stop_count > 0 ||
+	if ((t->group_stop & GROUP_STOP_PENDING) ||
 	    PENDING(&t->pending, &t->blocked) ||
 	    PENDING(&t->signal->shared_pending, &t->blocked)) {
 		set_tsk_thread_flag(t, TIF_SIGPENDING);
@@ -232,19 +232,19 @@ static inline void print_dropped_signal(int sig)
  * CONTEXT:
  * Must be called with @task->sighand->siglock held.
  */
-static void task_clear_group_stop_pending(struct task_struct *task)
+void task_clear_group_stop_pending(struct task_struct *task)
 {
-	task->group_stop &= ~GROUP_STOP_CONSUME;
+	task->group_stop &= ~(GROUP_STOP_PENDING | GROUP_STOP_CONSUME);
 }
 
 /**
  * task_participate_group_stop - participate in a group stop
  * @task: task participating in a group stop
  *
- * @task is participating in a group stop.  Group stop states are cleared
- * and the group stop count is consumed if %GROUP_STOP_CONSUME was set.  If
- * the consumption completes the group stop, the appropriate %SIGNAL_*
- * flags are set.
+ * @task has GROUP_STOP_PENDING set and is participating in a group stop.
+ * Group stop states are cleared and the group stop count is consumed if
+ * %GROUP_STOP_CONSUME was set.  If the consumption completes the group
+ * stop, the appropriate %SIGNAL_* flags are set.
  *
  * CONTEXT:
  * Must be called with @task->sighand->siglock held.
@@ -254,6 +254,8 @@ static bool task_participate_group_stop(struct task_struct *task)
 	struct signal_struct *sig = task->signal;
 	bool consume = task->group_stop & GROUP_STOP_CONSUME;
 
+	WARN_ON_ONCE(!(task->group_stop & GROUP_STOP_PENDING));
+
 	task_clear_group_stop_pending(task);
 
 	if (!consume)
@@ -765,6 +767,9 @@ static int prepare_signal(int sig, struct task_struct *p, int from_ancestor_ns)
 		t = p;
 		do {
 			unsigned int state;
+
+			task_clear_group_stop_pending(t);
+
 			rm_from_queue(SIG_KERNEL_STOP_MASK, &t->pending);
 			/*
 			 * If there is a handler for SIGCONT, we must make
@@ -906,6 +911,7 @@ static void complete_signal(int sig, struct task_struct *p, int group)
 			signal->group_stop_count = 0;
 			t = p;
 			do {
+				task_clear_group_stop_pending(t);
 				sigaddset(&t->pending.signal, SIGKILL);
 				signal_wake_up(t, 1);
 			} while_each_thread(p, t);
@@ -1139,6 +1145,7 @@ int zap_other_threads(struct task_struct *p)
 	p->signal->group_stop_count = 0;
 
 	while_each_thread(p, t) {
+		task_clear_group_stop_pending(t);
 		count++;
 
 		/* Don't bother with already dead threads */
@@ -1690,7 +1697,7 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 	 * If there is a group stop in progress,
 	 * we must participate in the bookkeeping.
 	 */
-	if (current->signal->group_stop_count > 0)
+	if (current->group_stop & GROUP_STOP_PENDING)
 		task_participate_group_stop(current);
 
 	current->last_siginfo = info;
@@ -1775,8 +1782,8 @@ static int do_signal_stop(int signr)
 	struct signal_struct *sig = current->signal;
 	int notify = 0;
 
-	if (!sig->group_stop_count) {
-		unsigned int gstop = GROUP_STOP_CONSUME;
+	if (!(current->group_stop & GROUP_STOP_PENDING)) {
+		unsigned int gstop = GROUP_STOP_PENDING | GROUP_STOP_CONSUME;
 		struct task_struct *t;
 
 		if (!likely(sig->flags & SIGNAL_STOP_DEQUEUED) ||
@@ -1796,8 +1803,7 @@ static int do_signal_stop(int signr)
 			 * stop is always done with the siglock held,
 			 * so this check has no races.
 			 */
-			if (!(t->flags & PF_EXITING) &&
-			    !task_is_stopped_or_traced(t)) {
+			if (!(t->flags & PF_EXITING) && !task_is_stopped(t)) {
 				t->group_stop = gstop;
 				sig->group_stop_count++;
 				signal_wake_up(t, 0);
@@ -1926,8 +1932,8 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		if (unlikely(signr != 0))
 			ka = return_ka;
 		else {
-			if (unlikely(signal->group_stop_count > 0) &&
-			    do_signal_stop(0))
+			if (unlikely(current->group_stop &
+				     GROUP_STOP_PENDING) && do_signal_stop(0))
 				goto relock;
 
 			signr = dequeue_signal(current, &current->blocked,
@@ -2073,7 +2079,7 @@ void exit_signals(struct task_struct *tsk)
 		if (!signal_pending(t) && !(t->flags & PF_EXITING))
 			recalc_sigpending_and_wake(t);
 
-	if (unlikely(tsk->signal->group_stop_count) &&
+	if (unlikely(tsk->group_stop & GROUP_STOP_PENDING) &&
 	    task_participate_group_stop(tsk))
 		group_stop = CLD_STOPPED;
 out:

commit e5c1902e9260a0075ea52cb5ef627a8d9aaede89
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 23 10:37:00 2011 +0100

    signal: Fix premature completion of group stop when interfered by ptrace
    
    task->signal->group_stop_count is used to track the progress of group
    stop.  It's initialized to the number of tasks which need to stop for
    group stop to finish and each stopping or trapping task decrements.
    However, each task doesn't keep track of whether it decremented the
    counter or not and if woken up before the group stop is complete and
    stops again, it can decrement the counter multiple times.
    
    Please consider the following example code.
    
     static void *worker(void *arg)
     {
             while (1) ;
             return NULL;
     }
    
     int main(void)
     {
             pthread_t thread;
             pid_t pid;
             int i;
    
             pid = fork();
             if (!pid) {
                     for (i = 0; i < 5; i++)
                             pthread_create(&thread, NULL, worker, NULL);
                     while (1) ;
                     return 0;
             }
    
             ptrace(PTRACE_ATTACH, pid, NULL, NULL);
             while (1) {
                     waitid(P_PID, pid, NULL, WSTOPPED);
                     ptrace(PTRACE_SINGLESTEP, pid, NULL, (void *)(long)SIGSTOP);
             }
             return 0;
     }
    
    The child creates five threads and the parent continuously traps the
    first thread and whenever the child gets a signal, SIGSTOP is
    delivered.  If an external process sends SIGSTOP to the child, all
    other threads in the process should reliably stop.  However, due to
    the above bug, the first thread will often end up consuming
    group_stop_count multiple times and SIGSTOP often ends up stopping
    none or part of the other four threads.
    
    This patch adds a new field task->group_stop which is protected by
    siglock and uses GROUP_STOP_CONSUME flag to track which task is still
    to consume group_stop_count to fix this bug.
    
    task_clear_group_stop_pending() and task_participate_group_stop() are
    added to help manipulating group stop states.  As ptrace_stop() now
    also uses task_participate_group_stop(), it will set
    SIGNAL_STOP_STOPPED if it completes a group stop.
    
    There still are many issues regarding the interaction between group
    stop and ptrace.  Patches to address them will follow.
    
    - Oleg spotted duplicate GROUP_STOP_CONSUME.  Dropped.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 95ac42dc3bcb..ecb20089eaff 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -223,6 +223,52 @@ static inline void print_dropped_signal(int sig)
 				current->comm, current->pid, sig);
 }
 
+/**
+ * task_clear_group_stop_pending - clear pending group stop
+ * @task: target task
+ *
+ * Clear group stop states for @task.
+ *
+ * CONTEXT:
+ * Must be called with @task->sighand->siglock held.
+ */
+static void task_clear_group_stop_pending(struct task_struct *task)
+{
+	task->group_stop &= ~GROUP_STOP_CONSUME;
+}
+
+/**
+ * task_participate_group_stop - participate in a group stop
+ * @task: task participating in a group stop
+ *
+ * @task is participating in a group stop.  Group stop states are cleared
+ * and the group stop count is consumed if %GROUP_STOP_CONSUME was set.  If
+ * the consumption completes the group stop, the appropriate %SIGNAL_*
+ * flags are set.
+ *
+ * CONTEXT:
+ * Must be called with @task->sighand->siglock held.
+ */
+static bool task_participate_group_stop(struct task_struct *task)
+{
+	struct signal_struct *sig = task->signal;
+	bool consume = task->group_stop & GROUP_STOP_CONSUME;
+
+	task_clear_group_stop_pending(task);
+
+	if (!consume)
+		return false;
+
+	if (!WARN_ON_ONCE(sig->group_stop_count == 0))
+		sig->group_stop_count--;
+
+	if (!sig->group_stop_count) {
+		sig->flags = SIGNAL_STOP_STOPPED;
+		return true;
+	}
+	return false;
+}
+
 /*
  * allocate a new signal queue record
  * - this may be called without locks if and only if t == current, otherwise an
@@ -1645,7 +1691,7 @@ static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 	 * we must participate in the bookkeeping.
 	 */
 	if (current->signal->group_stop_count > 0)
-		--current->signal->group_stop_count;
+		task_participate_group_stop(current);
 
 	current->last_siginfo = info;
 	current->exit_code = exit_code;
@@ -1730,6 +1776,7 @@ static int do_signal_stop(int signr)
 	int notify = 0;
 
 	if (!sig->group_stop_count) {
+		unsigned int gstop = GROUP_STOP_CONSUME;
 		struct task_struct *t;
 
 		if (!likely(sig->flags & SIGNAL_STOP_DEQUEUED) ||
@@ -1741,6 +1788,7 @@ static int do_signal_stop(int signr)
 		 */
 		sig->group_exit_code = signr;
 
+		current->group_stop = gstop;
 		sig->group_stop_count = 1;
 		for (t = next_thread(current); t != current; t = next_thread(t))
 			/*
@@ -1750,19 +1798,19 @@ static int do_signal_stop(int signr)
 			 */
 			if (!(t->flags & PF_EXITING) &&
 			    !task_is_stopped_or_traced(t)) {
+				t->group_stop = gstop;
 				sig->group_stop_count++;
 				signal_wake_up(t, 0);
-			}
+			} else
+				task_clear_group_stop_pending(t);
 	}
 	/*
 	 * If there are no other threads in the group, or if there is
 	 * a group stop in progress and we are the last to stop, report
 	 * to the parent.  When ptraced, every thread reports itself.
 	 */
-	if (!--sig->group_stop_count) {
-		sig->flags = SIGNAL_STOP_STOPPED;
+	if (task_participate_group_stop(current))
 		notify = CLD_STOPPED;
-	}
 	if (task_ptrace(current))
 		notify = CLD_STOPPED;
 
@@ -2026,10 +2074,8 @@ void exit_signals(struct task_struct *tsk)
 			recalc_sigpending_and_wake(t);
 
 	if (unlikely(tsk->signal->group_stop_count) &&
-			!--tsk->signal->group_stop_count) {
-		tsk->signal->flags = SIGNAL_STOP_STOPPED;
+	    task_participate_group_stop(tsk))
 		group_stop = CLD_STOPPED;
-	}
 out:
 	spin_unlock_irq(&tsk->sighand->siglock);
 

commit fe1bc6a0954611b806f9e158eb0817cf8ba21660
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 23 10:37:00 2011 +0100

    ptrace: Add @why to ptrace_stop()
    
    To prepare for cleanup of the interaction between group stop and
    ptrace, add @why to ptrace_stop().  Existing users are updated such
    that there is no behavior change.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Roland McGrath <roland@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 03d874e1058f..95ac42dc3bcb 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1617,7 +1617,7 @@ static int sigkill_pending(struct task_struct *tsk)
  * If we actually decide not to stop at all because the tracer
  * is gone, we keep current->exit_code unless clear_code.
  */
-static void ptrace_stop(int exit_code, int clear_code, siginfo_t *info)
+static void ptrace_stop(int exit_code, int why, int clear_code, siginfo_t *info)
 	__releases(&current->sighand->siglock)
 	__acquires(&current->sighand->siglock)
 {
@@ -1655,7 +1655,7 @@ static void ptrace_stop(int exit_code, int clear_code, siginfo_t *info)
 	spin_unlock_irq(&current->sighand->siglock);
 	read_lock(&tasklist_lock);
 	if (may_ptrace_stop()) {
-		do_notify_parent_cldstop(current, CLD_TRAPPED);
+		do_notify_parent_cldstop(current, why);
 		/*
 		 * Don't want to allow preemption here, because
 		 * sys_ptrace() needs this task to be inactive.
@@ -1714,7 +1714,7 @@ void ptrace_notify(int exit_code)
 
 	/* Let the debugger run.  */
 	spin_lock_irq(&current->sighand->siglock);
-	ptrace_stop(exit_code, 1, &info);
+	ptrace_stop(exit_code, CLD_TRAPPED, 1, &info);
 	spin_unlock_irq(&current->sighand->siglock);
 }
 
@@ -1795,7 +1795,7 @@ static int ptrace_signal(int signr, siginfo_t *info,
 	ptrace_signal_deliver(regs, cookie);
 
 	/* Let the debugger run.  */
-	ptrace_stop(signr, 0, info);
+	ptrace_stop(signr, CLD_TRAPPED, 0, info);
 
 	/* We're back.  Did the debugger cancel the sig?  */
 	signr = current->exit_code;

commit edf2ed153bcae52de70db00a98b0e81a5668e563
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 23 10:37:00 2011 +0100

    ptrace: Kill tracehook_notify_jctl()
    
    tracehook_notify_jctl() aids in determining whether and what to report
    to the parent when a task is stopped or continued.  The function also
    adds an extra requirement that siglock may be released across it,
    which is currently unused and quite difficult to satisfy in
    well-defined manner.
    
    As job control and the notifications are about to receive major
    overhaul, remove the tracehook and open code it.  If ever necessary,
    let's factor it out after the overhaul.
    
    * Oleg spotted incorrect CLD_CONTINUED/STOPPED selection when ptraced.
      Fixed.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index f4db76986ec1..03d874e1058f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1727,7 +1727,7 @@ void ptrace_notify(int exit_code)
 static int do_signal_stop(int signr)
 {
 	struct signal_struct *sig = current->signal;
-	int notify;
+	int notify = 0;
 
 	if (!sig->group_stop_count) {
 		struct task_struct *t;
@@ -1759,19 +1759,16 @@ static int do_signal_stop(int signr)
 	 * a group stop in progress and we are the last to stop, report
 	 * to the parent.  When ptraced, every thread reports itself.
 	 */
-	notify = sig->group_stop_count == 1 ? CLD_STOPPED : 0;
-	notify = tracehook_notify_jctl(notify, CLD_STOPPED);
-	/*
-	 * tracehook_notify_jctl() can drop and reacquire siglock, so
-	 * we keep ->group_stop_count != 0 before the call. If SIGCONT
-	 * or SIGKILL comes in between ->group_stop_count == 0.
-	 */
-	if (sig->group_stop_count) {
-		if (!--sig->group_stop_count)
-			sig->flags = SIGNAL_STOP_STOPPED;
-		current->exit_code = sig->group_exit_code;
-		__set_current_state(TASK_STOPPED);
+	if (!--sig->group_stop_count) {
+		sig->flags = SIGNAL_STOP_STOPPED;
+		notify = CLD_STOPPED;
 	}
+	if (task_ptrace(current))
+		notify = CLD_STOPPED;
+
+	current->exit_code = sig->group_exit_code;
+	__set_current_state(TASK_STOPPED);
+
 	spin_unlock_irq(&current->sighand->siglock);
 
 	if (notify) {
@@ -1860,14 +1857,11 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 
 		signal->flags &= ~SIGNAL_CLD_MASK;
 
-		why = tracehook_notify_jctl(why, CLD_CONTINUED);
 		spin_unlock_irq(&sighand->siglock);
 
-		if (why) {
-			read_lock(&tasklist_lock);
-			do_notify_parent_cldstop(current->group_leader, why);
-			read_unlock(&tasklist_lock);
-		}
+		read_lock(&tasklist_lock);
+		do_notify_parent_cldstop(current->group_leader, why);
+		read_unlock(&tasklist_lock);
 		goto relock;
 	}
 
@@ -2034,7 +2028,7 @@ void exit_signals(struct task_struct *tsk)
 	if (unlikely(tsk->signal->group_stop_count) &&
 			!--tsk->signal->group_stop_count) {
 		tsk->signal->flags = SIGNAL_STOP_STOPPED;
-		group_stop = tracehook_notify_jctl(CLD_STOPPED, CLD_STOPPED);
+		group_stop = CLD_STOPPED;
 	}
 out:
 	spin_unlock_irq(&tsk->sighand->siglock);

commit 71db5eb99c960e9c30e4b3ed04103c513b6251b5
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 23 10:37:00 2011 +0100

    signal: Remove superflous try_to_freeze() loop in do_signal_stop()
    
    do_signal_stop() is used only by get_signal_to_deliver() and after a
    successful signal stop, it always calls try_to_freeze(), so the
    try_to_freeze() loop around schedule() in do_signal_stop() is
    superflous and confusing.  Remove it.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Rafael J. Wysocki <rjw@sisk.pl>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Roland McGrath <roland@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index e26274abf3a9..f4db76986ec1 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1781,9 +1781,7 @@ static int do_signal_stop(int signr)
 	}
 
 	/* Now we don't run again until woken by SIGCONT or SIGKILL */
-	do {
-		schedule();
-	} while (try_to_freeze());
+	schedule();
 
 	tracehook_finish_jctl();
 	current->exit_code = 0;

commit c672af35d54992b88d3c48133bd62cc3386fb2f9
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 23 10:36:59 2011 +0100

    signal: Fix SIGCONT notification code
    
    After a task receives SIGCONT, its parent is notified via SIGCHLD with
    its siginfo describing what the notified event is.  If SIGCONT is
    received while the child process is stopped, the code should be
    CLD_CONTINUED.  If SIGCONT is recieved while the child process is in
    the process of being stopped, it should be CLD_STOPPED.  Which code to
    use is determined in prepare_signal() and recorded in signal->flags
    using SIGNAL_CLD_CONTINUED|STOP flags.
    
    get_signal_deliver() should test these flags and then notify
    accoringly; however, it incorrectly tested SIGNAL_STOP_CONTINUED
    instead of SIGNAL_CLD_CONTINUED, thus incorrectly notifying
    CLD_CONTINUED if the signal is delivered before the task is wait(2)ed
    and CLD_STOPPED if the state was fetched already.
    
    Fix it by testing SIGNAL_CLD_CONTINUED.  While at it, uncompress the
    ?: test into if/else clause for better readability.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Roland McGrath <roland@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 31751868de88..e26274abf3a9 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1853,8 +1853,13 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 	 * the CLD_ si_code into SIGNAL_CLD_MASK bits.
 	 */
 	if (unlikely(signal->flags & SIGNAL_CLD_MASK)) {
-		int why = (signal->flags & SIGNAL_STOP_CONTINUED)
-				? CLD_CONTINUED : CLD_STOPPED;
+		int why;
+
+		if (signal->flags & SIGNAL_CLD_CONTINUED)
+			why = CLD_CONTINUED;
+		else
+			why = CLD_STOPPED;
+
 		signal->flags &= ~SIGNAL_CLD_MASK;
 
 		why = tracehook_notify_jctl(why, CLD_CONTINUED);

commit da48524eb20662618854bb3df2db01fc65f3070c
Author: Julien Tinnes <jln@google.com>
Date:   Fri Mar 18 15:05:21 2011 -0700

    Prevent rt_sigqueueinfo and rt_tgsigqueueinfo from spoofing the signal code
    
    Userland should be able to trust the pid and uid of the sender of a
    signal if the si_code is SI_TKILL.
    
    Unfortunately, the kernel has historically allowed sigqueueinfo() to
    send any si_code at all (as long as it was negative - to distinguish it
    from kernel-generated signals like SIGILL etc), so it could spoof a
    SI_TKILL with incorrect siginfo values.
    
    Happily, it looks like glibc has always set si_code to the appropriate
    SI_QUEUE, so there are probably no actual user code that ever uses
    anything but the appropriate SI_QUEUE flag.
    
    So just tighten the check for si_code (we used to allow any negative
    value), and add a (one-time) warning in case there are binaries out
    there that might depend on using other si_code values.
    
    Signed-off-by: Julien Tinnes <jln@google.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 4e3cff10fdce..31751868de88 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2421,9 +2421,13 @@ SYSCALL_DEFINE3(rt_sigqueueinfo, pid_t, pid, int, sig,
 		return -EFAULT;
 
 	/* Not even root can pretend to send signals from the kernel.
-	   Nor can they impersonate a kill(), which adds source info.  */
-	if (info.si_code >= 0)
+	 * Nor can they impersonate a kill()/tgkill(), which adds source info.
+	 */
+	if (info.si_code != SI_QUEUE) {
+		/* We used to allow any < 0 si_code */
+		WARN_ON_ONCE(info.si_code < 0);
 		return -EPERM;
+	}
 	info.si_signo = sig;
 
 	/* POSIX.1b doesn't mention process groups.  */
@@ -2437,9 +2441,13 @@ long do_rt_tgsigqueueinfo(pid_t tgid, pid_t pid, int sig, siginfo_t *info)
 		return -EINVAL;
 
 	/* Not even root can pretend to send signals from the kernel.
-	   Nor can they impersonate a kill(), which adds source info.  */
-	if (info->si_code >= 0)
+	 * Nor can they impersonate a kill()/tgkill(), which adds source info.
+	 */
+	if (info->si_code != SI_QUEUE) {
+		/* We used to allow any < 0 si_code */
+		WARN_ON_ONCE(info->si_code < 0);
 		return -EPERM;
+	}
 	info->si_signo = sig;
 
 	return do_send_specific(tgid, pid, sig, info);

commit b84011508360d6885a9d95a235ec77d56f133377
Author: Namhyung Kim <namhyung@gmail.com>
Date:   Wed Oct 27 15:34:07 2010 -0700

    signals: annotate lock context change on ptrace_stop()
    
    ptrace_stop() releases and regrabs current->sighand->siglock but was
    missing proper annotation.  Add it.
    
    Signed-off-by: Namhyung Kim <namhyung@gmail.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index e921409b85a9..4e3cff10fdce 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1618,6 +1618,8 @@ static int sigkill_pending(struct task_struct *tsk)
  * is gone, we keep current->exit_code unless clear_code.
  */
 static void ptrace_stop(int exit_code, int clear_code, siginfo_t *info)
+	__releases(&current->sighand->siglock)
+	__acquires(&current->sighand->siglock)
 {
 	if (arch_ptrace_stop_needed(exit_code, info)) {
 		/*

commit b8ed374e202e23caaf9bd77dcadc9de6447faaa8
Author: Namhyung Kim <namhyung@gmail.com>
Date:   Wed Oct 27 15:34:06 2010 -0700

    signals: annotate lock_task_sighand()
    
    lock_task_sighand() grabs sighand->siglock in case of returning non-NULL
    but unlock_task_sighand() releases it unconditionally.  This leads sparse
    to complain about the lock context imbalance.  Rename and wrap
    lock_task_sighand() using __cond_lock() macro to make sparse happy.
    
    Suggested-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: Namhyung Kim <namhyung@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 919562c3d6b7..e921409b85a9 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1105,7 +1105,8 @@ int zap_other_threads(struct task_struct *p)
 	return count;
 }
 
-struct sighand_struct *lock_task_sighand(struct task_struct *tsk, unsigned long *flags)
+struct sighand_struct *__lock_task_sighand(struct task_struct *tsk,
+					   unsigned long *flags)
 {
 	struct sighand_struct *sighand;
 

commit a337fdac7a5622d1e6547f4b476c14dfe5a2c892
Author: Andi Kleen <ak@linux.intel.com>
Date:   Mon Sep 27 20:32:19 2010 +0200

    HWPOISON: Copy si_addr_lsb to user
    
    The original hwpoison code added a new siginfo field si_addr_lsb to
    pass the granuality of the fault address to user space. Unfortunately
    this field was never copied to user space. Fix this here.
    
    I added explicit checks for the MCEERR codes to avoid having
    to patch all potential callers to initialize the field.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index bded65187780..919562c3d6b7 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2214,6 +2214,14 @@ int copy_siginfo_to_user(siginfo_t __user *to, siginfo_t *from)
 		err |= __put_user(from->si_addr, &to->si_addr);
 #ifdef __ARCH_SI_TRAPNO
 		err |= __put_user(from->si_trapno, &to->si_trapno);
+#endif
+#ifdef BUS_MCEERR_AO
+		/* 
+		 * Other callers might not initialize the si_lsb field,
+	 	 * so check explicitely for the right codes here.
+		 */
+		if (from->si_code == BUS_MCEERR_AR || from->si_code == BUS_MCEERR_AO)
+			err |= __put_user(from->si_addr_lsb, &to->si_addr_lsb);
 #endif
 		break;
 	case __SI_CHLD:

commit 694f690d27dadccc8cb9d90532e76593b61fe098
Author: David Howells <dhowells@redhat.com>
Date:   Wed Aug 4 16:59:14 2010 +0100

    CRED: Fix RCU warning due to previous patch fixing __task_cred()'s checks
    
    Commit 8f92054e7ca1 ("CRED: Fix __task_cred()'s lockdep check and banner
    comment") fixed the lockdep checks on __task_cred().  This has shown up
    a place in the signalling code where a lock should be held - namely that
    check_kill_permission() requires its callers to hold the RCU lock.
    
    Fix group_send_sig_info() to get the RCU read lock around its call to
    check_kill_permission().
    
    Without this patch, the following warning can occur:
    
      ===================================================
      [ INFO: suspicious rcu_dereference_check() usage. ]
      ---------------------------------------------------
      kernel/signal.c:660 invoked rcu_dereference_check() without protection!
      ...
    
    Reported-by: Tetsuo Handa <penguin-kernel@i-love.sakura.ne.jp>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 906ae5a1779c..bded65187780 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -637,7 +637,7 @@ static inline bool si_fromuser(const struct siginfo *info)
 
 /*
  * Bad permissions for sending the signal
- * - the caller must hold at least the RCU read lock
+ * - the caller must hold the RCU read lock
  */
 static int check_kill_permission(int sig, struct siginfo *info,
 				 struct task_struct *t)
@@ -1127,11 +1127,14 @@ struct sighand_struct *lock_task_sighand(struct task_struct *tsk, unsigned long
 
 /*
  * send signal info to all the members of a group
- * - the caller must hold the RCU read lock at least
  */
 int group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 {
-	int ret = check_kill_permission(sig, info, p);
+	int ret;
+
+	rcu_read_lock();
+	ret = check_kill_permission(sig, info, p);
+	rcu_read_unlock();
 
 	if (!ret && sig)
 		ret = do_send_sig_info(sig, info, p, true);

commit 09faef11df8c559a23e2405d123cb2683733a79a
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed May 26 14:43:11 2010 -0700

    exit: change zap_other_threads() to count sub-threads
    
    Change zap_other_threads() to return the number of other sub-threads found
    on ->thread_group list.
    
    Other changes are cosmetic:
    
            - change the code to use while_each_thread() helper
    
            - remove the obsolete comment about SIGKILL/SIGSTOP
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Cc: Veaceslav Falico <vfalico@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2ee9573ed11f..906ae5a1779c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1085,23 +1085,24 @@ force_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 /*
  * Nuke all other threads in the group.
  */
-void zap_other_threads(struct task_struct *p)
+int zap_other_threads(struct task_struct *p)
 {
-	struct task_struct *t;
+	struct task_struct *t = p;
+	int count = 0;
 
 	p->signal->group_stop_count = 0;
 
-	for (t = next_thread(p); t != p; t = next_thread(t)) {
-		/*
-		 * Don't bother with already dead threads
-		 */
+	while_each_thread(p, t) {
+		count++;
+
+		/* Don't bother with already dead threads */
 		if (t->exit_state)
 			continue;
-
-		/* SIGKILL will be handled before any pending SIGSTOP */
 		sigaddset(&t->pending.signal, SIGKILL);
 		signal_wake_up(t, 1);
 	}
+
+	return count;
 }
 
 struct sighand_struct *lock_task_sighand(struct task_struct *tsk, unsigned long *flags)

commit 065add3941bdca54fe04ed3471a96bce9af88793
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed May 26 14:42:54 2010 -0700

    signals: check_kill_permission(): don't check creds if same_thread_group()
    
    Andrew Tridgell reports that aio_read(SIGEV_SIGNAL) can fail if the
    notification from the helper thread races with setresuid(), see
    http://samba.org/~tridge/junkcode/aio_uid.c
    
    This happens because check_kill_permission() doesn't permit sending a
    signal to the task with the different cred->xids.  But there is not any
    security reason to check ->cred's when the task sends a signal (private or
    group-wide) to its sub-thread.  Whatever we do, any thread can bypass all
    security checks and send SIGKILL to all threads, or it can block a signal
    SIG and do kill(gettid(), SIG) to deliver this signal to another
    sub-thread.  Not to mention that CLONE_THREAD implies CLONE_VM.
    
    Change check_kill_permission() to avoid the credentials check when the
    sender and the target are from the same thread group.
    
    Also, move "cred = current_cred()" down to avoid calling get_current()
    twice.
    
    Note: David Howells pointed out we could relax this even more, the
    CLONE_SIGHAND (without CLONE_THREAD) case probably does not need
    these checks too.
    
    Roland said:
    : The glibc (libpthread) that does set*id across threads has
    : been in use for a while (2.3.4?), probably in distro's using kernels as old
    : or older than any active -stable streams.  In the race in question, this
    : kernel bug is breaking valid POSIX application expectations.
    
    Reported-by: Andrew Tridgell <tridge@samba.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Cc: Eric Paris <eparis@parisplace.org>
    Cc: Jakub Jelinek <jakub@redhat.com>
    Cc: James Morris <jmorris@namei.org>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Cc: <stable@kernel.org>         [all kernel versions]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 825a3f24ad76..2ee9573ed11f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -642,7 +642,7 @@ static inline bool si_fromuser(const struct siginfo *info)
 static int check_kill_permission(int sig, struct siginfo *info,
 				 struct task_struct *t)
 {
-	const struct cred *cred = current_cred(), *tcred;
+	const struct cred *cred, *tcred;
 	struct pid *sid;
 	int error;
 
@@ -656,8 +656,10 @@ static int check_kill_permission(int sig, struct siginfo *info,
 	if (error)
 		return error;
 
+	cred = current_cred();
 	tcred = __task_cred(t);
-	if ((cred->euid ^ tcred->suid) &&
+	if (!same_thread_group(current, t) &&
+	    (cred->euid ^ tcred->suid) &&
 	    (cred->euid ^ tcred->uid) &&
 	    (cred->uid  ^ tcred->suid) &&
 	    (cred->uid  ^ tcred->uid) &&

commit 67fc4e0cb931d6b4ccf21248e4199b154478ecea
Author: Jason Wessel <jason.wessel@windriver.com>
Date:   Thu May 20 21:04:21 2010 -0500

    kdb: core for kgdb back end (2 of 2)
    
    This patch contains the hooks and instrumentation into kernel which
    live outside the kernel/debug directory, which the kdb core
    will call to run commands like lsmod, dmesg, bt etc...
    
    CC: linux-arch@vger.kernel.org
    Signed-off-by: Jason Wessel <jason.wessel@windriver.com>
    Signed-off-by: Martin Hicks <mort@sgi.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index dbd7fe073c55..825a3f24ad76 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2735,3 +2735,43 @@ void __init signals_init(void)
 {
 	sigqueue_cachep = KMEM_CACHE(sigqueue, SLAB_PANIC);
 }
+
+#ifdef CONFIG_KGDB_KDB
+#include <linux/kdb.h>
+/*
+ * kdb_send_sig_info - Allows kdb to send signals without exposing
+ * signal internals.  This function checks if the required locks are
+ * available before calling the main signal code, to avoid kdb
+ * deadlocks.
+ */
+void
+kdb_send_sig_info(struct task_struct *t, struct siginfo *info)
+{
+	static struct task_struct *kdb_prev_t;
+	int sig, new_t;
+	if (!spin_trylock(&t->sighand->siglock)) {
+		kdb_printf("Can't do kill command now.\n"
+			   "The sigmask lock is held somewhere else in "
+			   "kernel, try again later\n");
+		return;
+	}
+	spin_unlock(&t->sighand->siglock);
+	new_t = kdb_prev_t != t;
+	kdb_prev_t = t;
+	if (t->state != TASK_RUNNING && new_t) {
+		kdb_printf("Process is not RUNNING, sending a signal from "
+			   "kdb risks deadlock\n"
+			   "on the run queue locks. "
+			   "The signal has _not_ been sent.\n"
+			   "Reissue the kill command if you want to risk "
+			   "the deadlock.\n");
+		return;
+	}
+	sig = info->si_signo;
+	if (send_sig_info(sig, info, t))
+		kdb_printf("Fail to deliver Signal %d to process %d.\n",
+			   sig, t->pid);
+	else
+		kdb_printf("Signal %d is sent to process %d.\n", sig, t->pid);
+}
+#endif	/* CONFIG_KGDB_KDB */

commit 78d7d407b62a021e6d2e8dc24c0b90e390ab58a1
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Fri Mar 5 13:42:54 2010 -0800

    kernel core: use helpers for rlimits
    
    Make sure compiler won't do weird things with limits.  E.g.  fetching them
    twice may return 2 different values after writable limits are implemented.
    
    I.e.  either use rlimit helpers added in commit 3e10e716abf3 ("resource:
    add helpers for fetching rlimits") or ACCESS_ONCE if not applicable.
    
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: john stultz <johnstul@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5bb9baffa4f1..dbd7fe073c55 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -245,7 +245,7 @@ __sigqueue_alloc(int sig, struct task_struct *t, gfp_t flags, int override_rlimi
 
 	if (override_rlimit ||
 	    atomic_read(&user->sigpending) <=
-			t->signal->rlim[RLIMIT_SIGPENDING].rlim_cur) {
+			task_rlimit(t, RLIMIT_SIGPENDING)) {
 		q = kmem_cache_alloc(sigqueue_cachep, flags);
 	} else {
 		print_dropped_signal(sig);

commit a27341cd5fcb7cf2d2d4726e9f324009f7162c00
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Mar 2 08:36:46 2010 -0800

    Prioritize synchronous signals over 'normal' signals
    
    This makes sure that we pick the synchronous signals caused by a
    processor fault over any pending regular asynchronous signals sent to
    use by [t]kill().
    
    This is not strictly required semantics, but it makes it _much_ easier
    for programs like Wine that expect to find the fault information in the
    signal stack.
    
    Without this, if a non-synchronous signal gets picked first, the delayed
    asynchronous signal will have its signal context pointing to the new
    signal invocation, rather than the instruction that caused the SIGSEGV
    or SIGBUS in the first place.
    
    This is not all that pretty, and we're discussing making the synchronous
    signals more explicit rather than have these kinds of implicit
    preferences of SIGSEGV and friends.  See for example
    
            http://bugzilla.kernel.org/show_bug.cgi?id=15395
    
    for some of the discussion.  But in the meantime this is a simple and
    fairly straightforward work-around, and the whole
    
            if (x & Y)
                    x &= Y;
    
    thing can be compiled into (and gcc does do it) just three instructions:
    
            movq    %rdx, %rax
            andl    $Y, %eax
            cmovne  %rax, %rdx
    
    so it is at least a simple solution to a subtle issue.
    
    Reported-and-tested-by: Pavel Vilim <wylda@volny.cz>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 934ae5e687b9..5bb9baffa4f1 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -159,6 +159,10 @@ void recalc_sigpending(void)
 
 /* Given the mask, find the first available signal that should be serviced. */
 
+#define SYNCHRONOUS_MASK \
+	(sigmask(SIGSEGV) | sigmask(SIGBUS) | sigmask(SIGILL) | \
+	 sigmask(SIGTRAP) | sigmask(SIGFPE))
+
 int next_signal(struct sigpending *pending, sigset_t *mask)
 {
 	unsigned long i, *s, *m, x;
@@ -166,26 +170,39 @@ int next_signal(struct sigpending *pending, sigset_t *mask)
 
 	s = pending->signal.sig;
 	m = mask->sig;
+
+	/*
+	 * Handle the first word specially: it contains the
+	 * synchronous signals that need to be dequeued first.
+	 */
+	x = *s &~ *m;
+	if (x) {
+		if (x & SYNCHRONOUS_MASK)
+			x &= SYNCHRONOUS_MASK;
+		sig = ffz(~x) + 1;
+		return sig;
+	}
+
 	switch (_NSIG_WORDS) {
 	default:
-		for (i = 0; i < _NSIG_WORDS; ++i, ++s, ++m)
-			if ((x = *s &~ *m) != 0) {
-				sig = ffz(~x) + i*_NSIG_BPW + 1;
-				break;
-			}
+		for (i = 1; i < _NSIG_WORDS; ++i) {
+			x = *++s &~ *++m;
+			if (!x)
+				continue;
+			sig = ffz(~x) + i*_NSIG_BPW + 1;
+			break;
+		}
 		break;
 
-	case 2: if ((x = s[0] &~ m[0]) != 0)
-			sig = 1;
-		else if ((x = s[1] &~ m[1]) != 0)
-			sig = _NSIG_BPW + 1;
-		else
+	case 2:
+		x = s[1] &~ m[1];
+		if (!x)
 			break;
-		sig += ffz(~x);
+		sig = ffz(~x) + _NSIG_BPW + 1;
 		break;
 
-	case 1: if ((x = *s &~ *m) != 0)
-			sig = ffz(~x) + 1;
+	case 1:
+		/* Nothing to do */
 		break;
 	}
 

commit b45c6e76bc2c72f6426c14bed64fdcbc9bf37cb0
Author: Andi Kleen <andi@firstfloor.org>
Date:   Fri Jan 8 14:42:52 2010 -0800

    kernel/signal.c: fix kernel information leak with print-fatal-signals=1
    
    When print-fatal-signals is enabled it's possible to dump any memory
    reachable by the kernel to the log by simply jumping to that address from
    user space.
    
    Or crash the system if there's some hardware with read side effects.
    
    The fatal signals handler will dump 16 bytes at the execution address,
    which is fully controlled by ring 3.
    
    In addition when something jumps to a unmapped address there will be up to
    16 additional useless page faults, which might be potentially slow (and at
    least is not very efficient)
    
    Fortunately this option is off by default and only there on i386.
    
    But fix it by checking for kernel addresses and also stopping when there's
    a page fault.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index d09692b40376..934ae5e687b9 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -979,7 +979,8 @@ static void print_fatal_signal(struct pt_regs *regs, int signr)
 		for (i = 0; i < 16; i++) {
 			unsigned char insn;
 
-			__get_user(insn, (unsigned char *)(regs->ip + i));
+			if (get_user(insn, (unsigned char *)(regs->ip + i)))
+				break;
 			printk("%02x ", insn);
 		}
 	}

commit 10e5453ffa0d04a2eda3cda3f55b88cb9c04595f
Merge: 3cd312c3e887 d4581a239a40
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Dec 19 09:47:34 2009 -0800

    Merge branch 'core-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'core-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      sys: Fix missing rcu protection for __task_cred() access
      signals: Fix more rcu assumptions
      signal: Fix racy access to __task_cred in kill_pid_info_as_uid()

commit 1be53963b0519bd3681749a9bed8b83aeb005cca
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Dec 15 16:47:26 2009 -0800

    signals: check ->group_stop_count after tracehook_get_signal()
    
    Move the call to do_signal_stop() down, after tracehook call.  This makes
    ->group_stop_count condition visible to tracers before do_signal_stop()
    will participate in this group-stop.
    
    Currently the patch has no effect, tracehook_get_signal() always returns 0.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 4a9d763f8922..1814e68e4de3 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1840,11 +1840,6 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 
 	for (;;) {
 		struct k_sigaction *ka;
-
-		if (unlikely(signal->group_stop_count > 0) &&
-		    do_signal_stop(0))
-			goto relock;
-
 		/*
 		 * Tracing can induce an artifical signal and choose sigaction.
 		 * The return value in @signr determines the default action,
@@ -1856,6 +1851,10 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		if (unlikely(signr != 0))
 			ka = return_ka;
 		else {
+			if (unlikely(signal->group_stop_count > 0) &&
+			    do_signal_stop(0))
+				goto relock;
+
 			signr = dequeue_signal(current, &current->blocked,
 					       info);
 

commit ad09750b51150ca87531b8790a379214a974c167
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Dec 15 16:47:25 2009 -0800

    signals: kill force_sig_specific()
    
    Kill force_sig_specific(), this trivial wrapper has no callers.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index d7c7f3cd4da8..4a9d763f8922 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1062,12 +1062,6 @@ force_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 	return ret;
 }
 
-void
-force_sig_specific(int sig, struct task_struct *t)
-{
-	force_sig_info(sig, SEND_SIG_FORCED, t);
-}
-
 /*
  * Nuke all other threads in the group.
  */

commit 7486e5d9fc773cb67c29381567bed5236fc9573c
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Dec 15 16:47:24 2009 -0800

    signals: cosmetic, collect_signal: use SI_USER
    
    Trivial, s/0/SI_USER/ in collect_signal() for grep.
    
    This is a bit confusing, we don't know the source of this signal.
    But we don't care, and "info->si_code = 0" is imho worse.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index b65879d4e08f..d7c7f3cd4da8 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -423,7 +423,7 @@ static void collect_signal(int sig, struct sigpending *list, siginfo_t *info)
 		 */
 		info->si_signo = sig;
 		info->si_errno = 0;
-		info->si_code = 0;
+		info->si_code = SI_USER;
 		info->si_pid = 0;
 		info->si_uid = 0;
 	}

commit dd34200adc01c5217ef09b55905b5c2312d65535
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Dec 15 16:47:24 2009 -0800

    signals: send_signal: use si_fromuser() to detect from_ancestor_ns
    
    Change send_signal() to use si_fromuser().  From now SEND_SIG_NOINFO
    triggers the "from_ancestor_ns" check.
    
    This fixes reparent_thread()->group_send_sig_info(pdeath_signal)
    behaviour, before this patch send_signal() does not detect the
    cross-namespace case when the child of the dying parent belongs to the
    sub-namespace.
    
    This patch can affect the behaviour of send_sig(), kill_pgrp() and
    kill_pid() when the caller sends the signal to the sub-namespace with
    "priv == 0" but surprisingly all callers seem to use them correctly,
    including disassociate_ctty(on_exit).
    
    Except: drivers/staging/comedi/drivers/addi-data/*.c incorrectly use
    send_sig(priv => 0).  But his is minor and should be fixed anyway.
    
    Reported-by: Daniel Lezcano <dlezcano@fr.ibm.com>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>
    Reviewed-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index a0ba428954b6..b65879d4e08f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -960,9 +960,8 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	int from_ancestor_ns = 0;
 
 #ifdef CONFIG_PID_NS
-	if (!is_si_special(info) && SI_FROMUSER(info) &&
-			task_pid_nr_ns(current, task_active_pid_ns(t)) <= 0)
-		from_ancestor_ns = 1;
+	from_ancestor_ns = si_fromuser(info) &&
+			   !task_pid_nr_ns(current, task_active_pid_ns(t));
 #endif
 
 	return __send_signal(sig, info, t, group, from_ancestor_ns);

commit 614c517d7c00af1b26ded20646b329397d6f51a1
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Dec 15 16:47:22 2009 -0800

    signals: SEND_SIG_NOINFO should be considered as SI_FROMUSER()
    
    No changes in compiled code. The patch adds the new helper, si_fromuser()
    and changes check_kill_permission() to use this helper.
    
    The real effect of this patch is that from now we "officially" consider
    SEND_SIG_NOINFO signal as "from user-space" signals. This is already true
    if we look at the code which uses SEND_SIG_NOINFO, except __send_signal()
    has another opinion - see the next patch.
    
    The naming of these special SEND_SIG_XXX siginfo's is really bad
    imho.  From __send_signal()'s pov they mean
    
            SEND_SIG_NOINFO         from user
            SEND_SIG_PRIV           from kernel
            SEND_SIG_FORCED         no info
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>
    Reviewed-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 6b982f2cf524..a0ba428954b6 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -607,6 +607,17 @@ static int rm_from_queue(unsigned long mask, struct sigpending *s)
 	return 1;
 }
 
+static inline int is_si_special(const struct siginfo *info)
+{
+	return info <= SEND_SIG_FORCED;
+}
+
+static inline bool si_fromuser(const struct siginfo *info)
+{
+	return info == SEND_SIG_NOINFO ||
+		(!is_si_special(info) && SI_FROMUSER(info));
+}
+
 /*
  * Bad permissions for sending the signal
  * - the caller must hold at least the RCU read lock
@@ -621,7 +632,7 @@ static int check_kill_permission(int sig, struct siginfo *info,
 	if (!valid_signal(sig))
 		return -EINVAL;
 
-	if (info != SEND_SIG_NOINFO && (is_si_special(info) || SI_FROMKERNEL(info)))
+	if (!si_fromuser(info))
 		return 0;
 
 	error = audit_signal_info(sig, t); /* Let audit system see the signal */
@@ -1186,8 +1197,7 @@ int kill_pid_info_as_uid(int sig, struct siginfo *info, struct pid *pid,
 		goto out_unlock;
 	}
 	pcred = __task_cred(p);
-	if ((info == SEND_SIG_NOINFO ||
-	     (!is_si_special(info) && SI_FROMUSER(info))) &&
+	if (si_fromuser(info) &&
 	    euid != pcred->suid && euid != pcred->uid &&
 	    uid  != pcred->suid && uid  != pcred->uid) {
 		ret = -EPERM;

commit 7cf7db8df0b78076eafa4ead47559344ca7b7a43
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Dec 10 00:53:21 2009 +0000

    signals: Fix more rcu assumptions
    
    1) Remove the misleading comment in __sigqueue_alloc() which claims
       that holding a spinlock is equivalent to rcu_read_lock().
    
    2) Add a rcu_read_lock/unlock around the __task_cred() access
       in __sigqueue_alloc()
    
    This needs to be revisited to remove the remaining users of
    read_lock(&tasklist_lock) but that's outside the scope of this patch.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    LKML-Reference: <20091210004703.269843657@linutronix.de>

diff --git a/kernel/signal.c b/kernel/signal.c
index 73316568a69c..f67545f9394c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -218,13 +218,13 @@ __sigqueue_alloc(int sig, struct task_struct *t, gfp_t flags, int override_rlimi
 	struct user_struct *user;
 
 	/*
-	 * We won't get problems with the target's UID changing under us
-	 * because changing it requires RCU be used, and if t != current, the
-	 * caller must be holding the RCU readlock (by way of a spinlock) and
-	 * we use RCU protection here
+	 * Protect access to @t credentials. This can go away when all
+	 * callers hold rcu read lock.
 	 */
+	rcu_read_lock();
 	user = get_uid(__task_cred(t)->user);
 	atomic_inc(&user->sigpending);
+	rcu_read_unlock();
 
 	if (override_rlimit ||
 	    atomic_read(&user->sigpending) <=

commit 14d8c9f3c09e7fd7b9af80904289fe204f5b93c6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Dec 10 00:53:17 2009 +0000

    signal: Fix racy access to __task_cred in kill_pid_info_as_uid()
    
    kill_pid_info_as_uid() accesses __task_cred() without being in a RCU
    read side critical section. tasklist_lock is not protecting that when
    CONFIG_TREE_PREEMPT_RCU=y.
    
    Convert the whole tasklist_lock section to rcu and use
    lock_task_sighand to prevent the exit race.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    LKML-Reference: <20091210004703.232302055@linutronix.de>
    Acked-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 6b982f2cf524..73316568a69c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1175,11 +1175,12 @@ int kill_pid_info_as_uid(int sig, struct siginfo *info, struct pid *pid,
 	int ret = -EINVAL;
 	struct task_struct *p;
 	const struct cred *pcred;
+	unsigned long flags;
 
 	if (!valid_signal(sig))
 		return ret;
 
-	read_lock(&tasklist_lock);
+	rcu_read_lock();
 	p = pid_task(pid, PIDTYPE_PID);
 	if (!p) {
 		ret = -ESRCH;
@@ -1196,14 +1197,16 @@ int kill_pid_info_as_uid(int sig, struct siginfo *info, struct pid *pid,
 	ret = security_task_kill(p, info, sig, secid);
 	if (ret)
 		goto out_unlock;
-	if (sig && p->sighand) {
-		unsigned long flags;
-		spin_lock_irqsave(&p->sighand->siglock, flags);
-		ret = __send_signal(sig, info, p, 1, 0);
-		spin_unlock_irqrestore(&p->sighand->siglock, flags);
+
+	if (sig) {
+		if (lock_task_sighand(p, &flags)) {
+			ret = __send_signal(sig, info, p, 1, 0);
+			unlock_task_sighand(p, &flags);
+		} else
+			ret = -ESRCH;
 	}
 out_unlock:
-	read_unlock(&tasklist_lock);
+	rcu_read_unlock();
 	return ret;
 }
 EXPORT_SYMBOL_GPL(kill_pid_info_as_uid);

commit c3fa27d1367fac63ac8533d6f20ea851d0d70a10
Merge: 96fa2b508d2d d103d01e4b19
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Dec 5 15:30:21 2009 -0800

    Merge branch 'perf-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'perf-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (470 commits)
      x86: Fix comments of register/stack access functions
      perf tools: Replace %m with %a in sscanf
      hw-breakpoints: Keep track of user disabled breakpoints
      tracing/syscalls: Make syscall events print callbacks static
      tracing: Add DEFINE_EVENT(), DEFINE_SINGLE_EVENT() support to docbook
      perf: Don't free perf_mmap_data until work has been done
      perf_event: Fix compile error
      perf tools: Fix _GNU_SOURCE macro related strndup() build error
      trace_syscalls: Remove unused syscall_name_to_nr()
      trace_syscalls: Simplify syscall profile
      trace_syscalls: Remove duplicate init_enter_##sname()
      trace_syscalls: Add syscall_nr field to struct syscall_metadata
      trace_syscalls: Remove enter_id exit_id
      trace_syscalls: Set event_enter_##sname->data to its metadata
      trace_syscalls: Remove unused event_syscall_enter and event_syscall_exit
      perf_event: Initialize data.period in perf_swevent_hrtimer()
      perf probe: Simplify event naming
      perf probe: Add --list option for listing current probe events
      perf probe: Add argv_split() from lib/argv_split.c
      perf probe: Move probe event utility functions to probe-event.c
      ...

commit ba005e1f417295d28cd1563ab82bc33af07fb16a
Author: Masami Hiramatsu <mhiramat@redhat.com>
Date:   Tue Nov 24 16:56:58 2009 -0500

    tracepoint: Add signal loss events
    
    Add signal_overflow_fail and signal_lose_info tracepoints
    for signal-lost events.
    
    Changes in v3:
     - Add docbook style comments
    
    Changes in v2:
     - Use siginfo string macro
    
    Suggested-by: Roland McGrath <roland@redhat.com>
    Reviewed-by: Jason Baron <jbaron@redhat.com>
    Signed-off-by: Masami Hiramatsu <mhiramat@redhat.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Cc: systemtap <systemtap@sources.redhat.com>
    Cc: DLE <dle-develop@lists.sourceforge.net>
    Cc: Oleg Nesterov <oleg@redhat.com>
    LKML-Reference: <20091124215658.30449.9934.stgit@dhcp-100-2-132.bos.redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/signal.c b/kernel/signal.c
index 349d44937406..93e72e5feae6 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -897,12 +897,21 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			break;
 		}
 	} else if (!is_si_special(info)) {
-		if (sig >= SIGRTMIN && info->si_code != SI_USER)
-		/*
-		 * Queue overflow, abort.  We may abort if the signal was rt
-		 * and sent by user using something other than kill().
-		 */
+		if (sig >= SIGRTMIN && info->si_code != SI_USER) {
+			/*
+			 * Queue overflow, abort.  We may abort if the
+			 * signal was rt and sent by user using something
+			 * other than kill().
+			 */
+			trace_signal_overflow_fail(sig, group, info);
 			return -EAGAIN;
+		} else {
+			/*
+			 * This is a silent loss of information.  We still
+			 * send the signal, but the *info bits are lost.
+			 */
+			trace_signal_lose_info(sig, group, info);
+		}
 	}
 
 out_set:

commit f9d4257e01d266e67420cc99d456b6d4c8464f54
Author: Masami Hiramatsu <mhiramat@redhat.com>
Date:   Tue Nov 24 16:56:51 2009 -0500

    tracepoint: Add signal deliver event
    
    Add a tracepoint where a process gets a signal. This tracepoint
    shows signal-number, sa-handler and sa-flag.
    
    Changes in v3:
     - Add docbook style comments
    
    Changes in v2:
     - Add siginfo argument
     - Fix comment
    
    Signed-off-by: Masami Hiramatsu <mhiramat@redhat.com>
    Reviewed-by: Jason Baron <jbaron@redhat.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Cc: systemtap <systemtap@sources.redhat.com>
    Cc: DLE <dle-develop@lists.sourceforge.net>
    Cc: Oleg Nesterov <oleg@redhat.com>
    LKML-Reference: <20091124215651.30449.20926.stgit@dhcp-100-2-132.bos.redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/signal.c b/kernel/signal.c
index a1e0cc6b32c3..349d44937406 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1840,6 +1840,9 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 			ka = &sighand->action[signr-1];
 		}
 
+		/* Trace actually delivered signals. */
+		trace_signal_deliver(signr, info, ka);
+
 		if (ka->sa.sa_handler == SIG_IGN) /* Do nothing.  */
 			continue;
 		if (ka->sa.sa_handler != SIG_DFL) {

commit d1eb650ff4130972fa21462fa49cd35a2865403b
Author: Masami Hiramatsu <mhiramat@redhat.com>
Date:   Tue Nov 24 16:56:45 2009 -0500

    tracepoint: Move signal sending tracepoint to events/signal.h
    
    Move signal sending event to events/signal.h. This patch also
    renames sched_signal_send event to signal_generate.
    
    Changes in v4:
     - Fix a typo of task_struct pointer.
    
    Changes in v3:
     - Add docbook style comments
    
    Changes in v2:
     - Add siginfo argument
     - Add siginfo storing macro
    
    Signed-off-by: Masami Hiramatsu <mhiramat@redhat.com>
    Reviewed-by: Jason Baron <jbaron@redhat.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Cc: systemtap <systemtap@sources.redhat.com>
    Cc: DLE <dle-develop@lists.sourceforge.net>
    Cc: Oleg Nesterov <oleg@redhat.com>
    LKML-Reference: <20091124215645.30449.60208.stgit@dhcp-100-2-132.bos.redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/signal.c b/kernel/signal.c
index 6705320784fd..a1e0cc6b32c3 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -27,7 +27,8 @@
 #include <linux/freezer.h>
 #include <linux/pid_namespace.h>
 #include <linux/nsproxy.h>
-#include <trace/events/sched.h>
+#define CREATE_TRACE_POINTS
+#include <trace/events/signal.h>
 
 #include <asm/param.h>
 #include <asm/uaccess.h>
@@ -834,7 +835,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	struct sigqueue *q;
 	int override_rlimit;
 
-	trace_sched_signal_send(sig, t);
+	trace_signal_generate(sig, info, t);
 
 	assert_spin_locked(&t->sighand->siglock);
 

commit f84d49b218b7d4c6cba2e0b41f24bd4045403962
Author: Naohiro Ooiwa <nooiwa@miraclelinux.com>
Date:   Mon Nov 9 00:46:42 2009 +0900

    signal: Print warning message when dropping signals
    
    When the system has too many timers or too many aggregate
    queued signals, the EAGAIN error is returned to application
    from kernel, including timer_create() [POSIX.1b].
    
    It means that the app exceeded the limit of pending signals,
    but in general application writers do not expect this
    outcome and the current silent failure can cause rare app
    failures under very high load.
    
    This patch adds a new message when we reach the limit
    and if print_fatal_signals is enabled:
    
        task/1234: reached RLIMIT_SIGPENDING, dropping signal
    
    If you see this message and your system behaved unexpectedly,
    you can run following command to lift the limit:
    
       # ulimit -i unlimited
    
    With help from Hiroshi Shimamoto <h-shimamoto@ct.jp.nec.com>.
    
    Signed-off-by: Naohiro Ooiwa <nooiwa@miraclelinux.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Hiroshi Shimamoto <h-shimamoto@ct.jp.nec.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: oleg@redhat.com
    LKML-Reference: <4AF6E7E2.9080406@miraclelinux.com>
    [ Modified a few small details, gave surrounding code some love. ]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/signal.c b/kernel/signal.c
index 6705320784fd..fe08008133da 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -22,6 +22,7 @@
 #include <linux/ptrace.h>
 #include <linux/signal.h>
 #include <linux/signalfd.h>
+#include <linux/ratelimit.h>
 #include <linux/tracehook.h>
 #include <linux/capability.h>
 #include <linux/freezer.h>
@@ -41,6 +42,8 @@
 
 static struct kmem_cache *sigqueue_cachep;
 
+int print_fatal_signals __read_mostly;
+
 static void __user *sig_handler(struct task_struct *t, int sig)
 {
 	return t->sighand->action[sig - 1].sa.sa_handler;
@@ -159,7 +162,7 @@ int next_signal(struct sigpending *pending, sigset_t *mask)
 {
 	unsigned long i, *s, *m, x;
 	int sig = 0;
-	
+
 	s = pending->signal.sig;
 	m = mask->sig;
 	switch (_NSIG_WORDS) {
@@ -184,17 +187,31 @@ int next_signal(struct sigpending *pending, sigset_t *mask)
 			sig = ffz(~x) + 1;
 		break;
 	}
-	
+
 	return sig;
 }
 
+static inline void print_dropped_signal(int sig)
+{
+	static DEFINE_RATELIMIT_STATE(ratelimit_state, 5 * HZ, 10);
+
+	if (!print_fatal_signals)
+		return;
+
+	if (!__ratelimit(&ratelimit_state))
+		return;
+
+	printk(KERN_INFO "%s/%d: reached RLIMIT_SIGPENDING, dropped signal %d\n",
+				current->comm, current->pid, sig);
+}
+
 /*
  * allocate a new signal queue record
  * - this may be called without locks if and only if t == current, otherwise an
  *   appopriate lock must be held to stop the target task from exiting
  */
-static struct sigqueue *__sigqueue_alloc(struct task_struct *t, gfp_t flags,
-					 int override_rlimit)
+static struct sigqueue *
+__sigqueue_alloc(int sig, struct task_struct *t, gfp_t flags, int override_rlimit)
 {
 	struct sigqueue *q = NULL;
 	struct user_struct *user;
@@ -207,10 +224,15 @@ static struct sigqueue *__sigqueue_alloc(struct task_struct *t, gfp_t flags,
 	 */
 	user = get_uid(__task_cred(t)->user);
 	atomic_inc(&user->sigpending);
+
 	if (override_rlimit ||
 	    atomic_read(&user->sigpending) <=
-			t->signal->rlim[RLIMIT_SIGPENDING].rlim_cur)
+			t->signal->rlim[RLIMIT_SIGPENDING].rlim_cur) {
 		q = kmem_cache_alloc(sigqueue_cachep, flags);
+	} else {
+		print_dropped_signal(sig);
+	}
+
 	if (unlikely(q == NULL)) {
 		atomic_dec(&user->sigpending);
 		free_uid(user);
@@ -869,7 +891,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	else
 		override_rlimit = 0;
 
-	q = __sigqueue_alloc(t, GFP_ATOMIC | __GFP_NOTRACK_FALSE_POSITIVE,
+	q = __sigqueue_alloc(sig, t, GFP_ATOMIC | __GFP_NOTRACK_FALSE_POSITIVE,
 		override_rlimit);
 	if (q) {
 		list_add_tail(&q->list, &pending->list);
@@ -925,8 +947,6 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	return __send_signal(sig, info, t, group, from_ancestor_ns);
 }
 
-int print_fatal_signals;
-
 static void print_fatal_signal(struct pt_regs *regs, int signr)
 {
 	printk("%s/%d: potentially unexpected fatal signal %d.\n",
@@ -1293,19 +1313,19 @@ EXPORT_SYMBOL(kill_pid);
  * These functions support sending signals using preallocated sigqueue
  * structures.  This is needed "because realtime applications cannot
  * afford to lose notifications of asynchronous events, like timer
- * expirations or I/O completions".  In the case of Posix Timers 
+ * expirations or I/O completions".  In the case of Posix Timers
  * we allocate the sigqueue structure from the timer_create.  If this
  * allocation fails we are able to report the failure to the application
  * with an EAGAIN error.
  */
- 
 struct sigqueue *sigqueue_alloc(void)
 {
-	struct sigqueue *q;
+	struct sigqueue *q = __sigqueue_alloc(-1, current, GFP_KERNEL, 0);
 
-	if ((q = __sigqueue_alloc(current, GFP_KERNEL, 0)))
+	if (q)
 		q->flags |= SIGQUEUE_PREALLOC;
-	return(q);
+
+	return q;
 }
 
 void sigqueue_free(struct sigqueue *q)

commit d9588725e52650e82989707f8fd2feb67ad2dc8e
Author: Roland McGrath <roland@redhat.com>
Date:   Wed Sep 23 15:57:04 2009 -0700

    signals: inline __fatal_signal_pending
    
    __fatal_signal_pending inlines to one instruction on x86, probably two
    instructions on other machines.  It takes two longer x86 instructions just
    to call it and test its return value, not to mention the function itself.
    
    On my random x86_64 config, this saved 70 bytes of text (59 of those being
    __fatal_signal_pending itself).
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index c6d7a24a86a1..6705320784fd 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1050,12 +1050,6 @@ void zap_other_threads(struct task_struct *p)
 	}
 }
 
-int __fatal_signal_pending(struct task_struct *tsk)
-{
-	return sigismember(&tsk->pending.signal, SIGKILL);
-}
-EXPORT_SYMBOL(__fatal_signal_pending);
-
 struct sighand_struct *lock_task_sighand(struct task_struct *tsk, unsigned long *flags)
 {
 	struct sighand_struct *sighand;

commit 4a30debfb778240a4b1767d4b0c5a5b25ab97160
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Sep 23 15:57:00 2009 -0700

    signals: introduce do_send_sig_info() helper
    
    Introduce do_send_sig_info() and convert group_send_sig_info(),
    send_sig_info(), do_send_specific() to use this helper.
    
    Hopefully it will have more users soon, it allows to specify
    specific/group behaviour via "bool group" argument.
    
    Shaves 80 bytes from .text.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: stephane eranian <eranian@googlemail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5d3b3f8f219b..c6d7a24a86a1 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -971,6 +971,20 @@ specific_send_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 	return send_signal(sig, info, t, 0);
 }
 
+int do_send_sig_info(int sig, struct siginfo *info, struct task_struct *p,
+			bool group)
+{
+	unsigned long flags;
+	int ret = -ESRCH;
+
+	if (lock_task_sighand(p, &flags)) {
+		ret = send_signal(sig, info, p, group);
+		unlock_task_sighand(p, &flags);
+	}
+
+	return ret;
+}
+
 /*
  * Force a signal that the process can't ignore: if necessary
  * we unblock the signal and change any SIG_IGN to SIG_DFL.
@@ -1068,18 +1082,10 @@ struct sighand_struct *lock_task_sighand(struct task_struct *tsk, unsigned long
  */
 int group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 {
-	unsigned long flags;
-	int ret;
-
-	ret = check_kill_permission(sig, info, p);
+	int ret = check_kill_permission(sig, info, p);
 
-	if (!ret && sig) {
-		ret = -ESRCH;
-		if (lock_task_sighand(p, &flags)) {
-			ret = __group_send_sig_info(sig, info, p);
-			unlock_task_sighand(p, &flags);
-		}
-	}
+	if (!ret && sig)
+		ret = do_send_sig_info(sig, info, p, true);
 
 	return ret;
 }
@@ -1224,15 +1230,9 @@ static int kill_something_info(int sig, struct siginfo *info, pid_t pid)
  * These are for backward compatibility with the rest of the kernel source.
  */
 
-/*
- * The caller must ensure the task can't exit.
- */
 int
 send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 {
-	int ret;
-	unsigned long flags;
-
 	/*
 	 * Make sure legacy kernel users don't send in bad values
 	 * (normal paths check this in check_kill_permission).
@@ -1240,10 +1240,7 @@ send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 	if (!valid_signal(sig))
 		return -EINVAL;
 
-	spin_lock_irqsave(&p->sighand->siglock, flags);
-	ret = specific_send_sig_info(sig, info, p);
-	spin_unlock_irqrestore(&p->sighand->siglock, flags);
-	return ret;
+	return do_send_sig_info(sig, info, p, false);
 }
 
 #define __si_special(priv) \
@@ -2278,7 +2275,6 @@ static int
 do_send_specific(pid_t tgid, pid_t pid, int sig, struct siginfo *info)
 {
 	struct task_struct *p;
-	unsigned long flags;
 	int error = -ESRCH;
 
 	rcu_read_lock();
@@ -2288,14 +2284,16 @@ do_send_specific(pid_t tgid, pid_t pid, int sig, struct siginfo *info)
 		/*
 		 * The null signal is a permissions and process existence
 		 * probe.  No signal is actually delivered.
-		 *
-		 * If lock_task_sighand() fails we pretend the task dies
-		 * after receiving the signal. The window is tiny, and the
-		 * signal is private anyway.
 		 */
-		if (!error && sig && lock_task_sighand(p, &flags)) {
-			error = specific_send_sig_info(sig, info, p);
-			unlock_task_sighand(p, &flags);
+		if (!error && sig) {
+			error = do_send_sig_info(sig, info, p, false);
+			/*
+			 * If lock_task_sighand() failed we pretend the task
+			 * dies after receiving the signal. The window is tiny,
+			 * and the signal is private anyway.
+			 */
+			if (unlikely(error == -ESRCH))
+				error = 0;
 		}
 	}
 	rcu_read_unlock();

commit ae6d2ed7bb3877ff35b9569402025f40ea2e1803
Author: Roland McGrath <roland@redhat.com>
Date:   Wed Sep 23 15:56:53 2009 -0700

    signals: tracehook_notify_jctl change
    
    This changes tracehook_notify_jctl() so it's called with the siglock held,
    and changes its argument and return value definition.  These clean-ups
    make it a better fit for what new tracing hooks need to check.
    
    Tracing needs the siglock here, held from the time TASK_STOPPED was set,
    to avoid potential SIGCONT races if it wants to allow any blocking in its
    tracing hooks.
    
    This also folds the finish_stop() function into its caller
    do_signal_stop().  The function is short, called only once and only
    unconditionally.  It aids readability to fold it in.
    
    [oleg@redhat.com: do not call tracehook_notify_jctl() in TASK_STOPPED state]
    [oleg@redhat.com: introduce tracehook_finish_jctl() helper]
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 534ea81cde47..5d3b3f8f219b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -705,7 +705,7 @@ static int prepare_signal(int sig, struct task_struct *p, int from_ancestor_ns)
 
 		if (why) {
 			/*
-			 * The first thread which returns from finish_stop()
+			 * The first thread which returns from do_signal_stop()
 			 * will take ->siglock, notice SIGNAL_CLD_MASK, and
 			 * notify its parent. See get_signal_to_deliver().
 			 */
@@ -1664,29 +1664,6 @@ void ptrace_notify(int exit_code)
 	spin_unlock_irq(&current->sighand->siglock);
 }
 
-static void
-finish_stop(int stop_count)
-{
-	/*
-	 * If there are no other threads in the group, or if there is
-	 * a group stop in progress and we are the last to stop,
-	 * report to the parent.  When ptraced, every thread reports itself.
-	 */
-	if (tracehook_notify_jctl(stop_count == 0, CLD_STOPPED)) {
-		read_lock(&tasklist_lock);
-		do_notify_parent_cldstop(current, CLD_STOPPED);
-		read_unlock(&tasklist_lock);
-	}
-
-	do {
-		schedule();
-	} while (try_to_freeze());
-	/*
-	 * Now we don't run again until continued.
-	 */
-	current->exit_code = 0;
-}
-
 /*
  * This performs the stopping for SIGSTOP and other stop signals.
  * We have to stop all threads in the thread group.
@@ -1696,15 +1673,9 @@ finish_stop(int stop_count)
 static int do_signal_stop(int signr)
 {
 	struct signal_struct *sig = current->signal;
-	int stop_count;
+	int notify;
 
-	if (sig->group_stop_count > 0) {
-		/*
-		 * There is a group stop in progress.  We don't need to
-		 * start another one.
-		 */
-		stop_count = --sig->group_stop_count;
-	} else {
+	if (!sig->group_stop_count) {
 		struct task_struct *t;
 
 		if (!likely(sig->flags & SIGNAL_STOP_DEQUEUED) ||
@@ -1716,7 +1687,7 @@ static int do_signal_stop(int signr)
 		 */
 		sig->group_exit_code = signr;
 
-		stop_count = 0;
+		sig->group_stop_count = 1;
 		for (t = next_thread(current); t != current; t = next_thread(t))
 			/*
 			 * Setting state to TASK_STOPPED for a group
@@ -1725,19 +1696,44 @@ static int do_signal_stop(int signr)
 			 */
 			if (!(t->flags & PF_EXITING) &&
 			    !task_is_stopped_or_traced(t)) {
-				stop_count++;
+				sig->group_stop_count++;
 				signal_wake_up(t, 0);
 			}
-		sig->group_stop_count = stop_count;
 	}
+	/*
+	 * If there are no other threads in the group, or if there is
+	 * a group stop in progress and we are the last to stop, report
+	 * to the parent.  When ptraced, every thread reports itself.
+	 */
+	notify = sig->group_stop_count == 1 ? CLD_STOPPED : 0;
+	notify = tracehook_notify_jctl(notify, CLD_STOPPED);
+	/*
+	 * tracehook_notify_jctl() can drop and reacquire siglock, so
+	 * we keep ->group_stop_count != 0 before the call. If SIGCONT
+	 * or SIGKILL comes in between ->group_stop_count == 0.
+	 */
+	if (sig->group_stop_count) {
+		if (!--sig->group_stop_count)
+			sig->flags = SIGNAL_STOP_STOPPED;
+		current->exit_code = sig->group_exit_code;
+		__set_current_state(TASK_STOPPED);
+	}
+	spin_unlock_irq(&current->sighand->siglock);
 
-	if (stop_count == 0)
-		sig->flags = SIGNAL_STOP_STOPPED;
-	current->exit_code = sig->group_exit_code;
-	__set_current_state(TASK_STOPPED);
+	if (notify) {
+		read_lock(&tasklist_lock);
+		do_notify_parent_cldstop(current, notify);
+		read_unlock(&tasklist_lock);
+	}
+
+	/* Now we don't run again until woken by SIGCONT or SIGKILL */
+	do {
+		schedule();
+	} while (try_to_freeze());
+
+	tracehook_finish_jctl();
+	current->exit_code = 0;
 
-	spin_unlock_irq(&current->sighand->siglock);
-	finish_stop(stop_count);
 	return 1;
 }
 
@@ -1806,14 +1802,15 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		int why = (signal->flags & SIGNAL_STOP_CONTINUED)
 				? CLD_CONTINUED : CLD_STOPPED;
 		signal->flags &= ~SIGNAL_CLD_MASK;
-		spin_unlock_irq(&sighand->siglock);
 
-		if (unlikely(!tracehook_notify_jctl(1, why)))
-			goto relock;
+		why = tracehook_notify_jctl(why, CLD_CONTINUED);
+		spin_unlock_irq(&sighand->siglock);
 
-		read_lock(&tasklist_lock);
-		do_notify_parent_cldstop(current->group_leader, why);
-		read_unlock(&tasklist_lock);
+		if (why) {
+			read_lock(&tasklist_lock);
+			do_notify_parent_cldstop(current->group_leader, why);
+			read_unlock(&tasklist_lock);
+		}
 		goto relock;
 	}
 
@@ -1978,14 +1975,14 @@ void exit_signals(struct task_struct *tsk)
 	if (unlikely(tsk->signal->group_stop_count) &&
 			!--tsk->signal->group_stop_count) {
 		tsk->signal->flags = SIGNAL_STOP_STOPPED;
-		group_stop = 1;
+		group_stop = tracehook_notify_jctl(CLD_STOPPED, CLD_STOPPED);
 	}
 out:
 	spin_unlock_irq(&tsk->sighand->siglock);
 
-	if (unlikely(group_stop) && tracehook_notify_jctl(1, CLD_STOPPED)) {
+	if (unlikely(group_stop)) {
 		read_lock(&tasklist_lock);
-		do_notify_parent_cldstop(tsk, CLD_STOPPED);
+		do_notify_parent_cldstop(tsk, group_stop);
 		read_unlock(&tasklist_lock);
 	}
 }

commit a7f0765edfd53aed09cb7b0e15863688b39447de
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Sep 23 15:56:44 2009 -0700

    ptrace: __ptrace_detach: do __wake_up_parent() if we reap the tracee
    
    The bug is old, it wasn't cause by recent changes.
    
    Test case:
    
            static void *tfunc(void *arg)
            {
                    int pid = (long)arg;
    
                    assert(ptrace(PTRACE_ATTACH, pid, NULL, NULL) == 0);
                    kill(pid, SIGKILL);
    
                    sleep(1);
                    return NULL;
            }
    
            int main(void)
            {
                    pthread_t th;
                    long pid = fork();
    
                    if (!pid)
                            pause();
    
                    signal(SIGCHLD, SIG_IGN);
                    assert(pthread_create(&th, NULL, tfunc, (void*)pid) == 0);
    
                    int r = waitpid(-1, NULL, __WNOTHREAD);
                    printf("waitpid: %d %m\n", r);
    
                    return 0;
            }
    
    Before the patch this program hangs, after this patch waitpid() correctly
    fails with errno == -ECHILD.
    
    The problem is, __ptrace_detach() reaps the EXIT_ZOMBIE tracee if its
    ->real_parent is our sub-thread and we ignore SIGCHLD.  But in this case
    we should wake up other threads which can sleep in do_wait().
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Vitaly Mayatskikh <vmayatsk@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 64c5deeaca5d..534ea81cde47 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1382,15 +1382,6 @@ int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)
 	return ret;
 }
 
-/*
- * Wake up any threads in the parent blocked in wait* syscalls.
- */
-static inline void __wake_up_parent(struct task_struct *p,
-				    struct task_struct *parent)
-{
-	wake_up_interruptible_sync(&parent->signal->wait_chldexit);
-}
-
 /*
  * Let a parent know about the death of a child.
  * For a stopped/continued status change, use do_notify_parent_cldstop instead.

commit 0dd8486b5cfe8048e0613334659d9252ecd1b08a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Aug 1 11:18:56 2009 -0700

    do_sigaltstack: small cleanups
    
    The previous commit ("do_sigaltstack: avoid copying 'stack_t' as a
    structure to user space") fixed a real bug.  This one just cleans up the
    copy from user space to that gcc can generate better code for it (and so
    that it looks the same as the later copy back to user space).
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index f268372c0cc0..64c5deeaca5d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2464,10 +2464,12 @@ do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long s
 		int ss_flags;
 
 		error = -EFAULT;
-		if (!access_ok(VERIFY_READ, uss, sizeof(*uss))
-		    || __get_user(ss_sp, &uss->ss_sp)
-		    || __get_user(ss_flags, &uss->ss_flags)
-		    || __get_user(ss_size, &uss->ss_size))
+		if (!access_ok(VERIFY_READ, uss, sizeof(*uss)))
+			goto out;
+		error = __get_user(ss_sp, &uss->ss_sp) |
+			__get_user(ss_flags, &uss->ss_flags) |
+			__get_user(ss_size, &uss->ss_size);
+		if (error)
 			goto out;
 
 		error = -EPERM;

commit 0083fc2c50e6c5127c2802ad323adf8143ab7856
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Aug 1 10:34:56 2009 -0700

    do_sigaltstack: avoid copying 'stack_t' as a structure to user space
    
    Ulrich Drepper correctly points out that there is generally padding in
    the structure on 64-bit hosts, and that copying the structure from
    kernel to user space can leak information from the kernel stack in those
    padding bytes.
    
    Avoid the whole issue by just copying the three members one by one
    instead, which also means that the function also can avoid the need for
    a stack frame.  This also happens to match how we copy the new structure
    from user space, so it all even makes sense.
    
    [ The obvious solution of adding a memset() generates horrid code, gcc
      does really stupid things. ]
    
    Reported-by: Ulrich Drepper <drepper@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index ccf1ceedaebe..f268372c0cc0 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2454,11 +2454,9 @@ do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long s
 	stack_t oss;
 	int error;
 
-	if (uoss) {
-		oss.ss_sp = (void __user *) current->sas_ss_sp;
-		oss.ss_size = current->sas_ss_size;
-		oss.ss_flags = sas_ss_flags(sp);
-	}
+	oss.ss_sp = (void __user *) current->sas_ss_sp;
+	oss.ss_size = current->sas_ss_size;
+	oss.ss_flags = sas_ss_flags(sp);
 
 	if (uss) {
 		void __user *ss_sp;
@@ -2501,13 +2499,16 @@ do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long s
 		current->sas_ss_size = ss_size;
 	}
 
+	error = 0;
 	if (uoss) {
 		error = -EFAULT;
-		if (copy_to_user(uoss, &oss, sizeof(oss)))
+		if (!access_ok(VERIFY_WRITE, uoss, sizeof(*uoss)))
 			goto out;
+		error = __put_user(oss.ss_sp, &uoss->ss_sp) |
+			__put_user(oss.ss_size, &uoss->ss_size) |
+			__put_user(oss.ss_flags, &uoss->ss_flags);
 	}
 
-	error = 0;
 out:
 	return error;
 }

commit d92656633b8352c6d4b14afcb7beb154d76e7aa6
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Jun 17 16:27:35 2009 -0700

    ptrace: do_notify_parent_cldstop: fix the wrong ->nsproxy usage
    
    If the non-traced sub-thread calls do_notify_parent_cldstop(), we send the
    notification to group_leader->real_parent and we report group_leader's
    pid.
    
    But, if group_leader is traced we use the wrong ->parent->nsproxy->pid_ns,
    the tracer and parent can live in different namespaces.  Change the code
    to use "parent" instead of tsk->parent.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Acked-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 09ccc1c0e1f8..ccf1ceedaebe 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1499,7 +1499,7 @@ static void do_notify_parent_cldstop(struct task_struct *tsk, int why)
 	 * see comment in do_notify_parent() abot the following 3 lines
 	 */
 	rcu_read_lock();
-	info.si_pid = task_pid_nr_ns(tsk, tsk->parent->nsproxy->pid_ns);
+	info.si_pid = task_pid_nr_ns(tsk, parent->nsproxy->pid_ns);
 	info.si_uid = __task_cred(tsk)->uid;
 	rcu_read_unlock();
 

commit 5cb11446892833e50970fb2277a9f7563b0a8bd3
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Jun 17 16:27:30 2009 -0700

    ptrace: do not use task->ptrace directly in core kernel
    
    No functional changes.
    
    - Nobody except ptrace.c & co should use ptrace flags directly, we have
      task_ptrace() for that.
    
    - No need to specially check PT_PTRACED, we must not have other PT_ bits
      set without PT_PTRACED. And no need to know this flag exists.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index d81f4952eebb..09ccc1c0e1f8 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1410,7 +1410,7 @@ int do_notify_parent(struct task_struct *tsk, int sig)
  	/* do_notify_parent_cldstop should have been called instead.  */
  	BUG_ON(task_is_stopped_or_traced(tsk));
 
-	BUG_ON(!tsk->ptrace &&
+	BUG_ON(!task_ptrace(tsk) &&
 	       (tsk->group_leader != tsk || !thread_group_empty(tsk)));
 
 	info.si_signo = sig;
@@ -1449,7 +1449,7 @@ int do_notify_parent(struct task_struct *tsk, int sig)
 
 	psig = tsk->parent->sighand;
 	spin_lock_irqsave(&psig->siglock, flags);
-	if (!tsk->ptrace && sig == SIGCHLD &&
+	if (!task_ptrace(tsk) && sig == SIGCHLD &&
 	    (psig->action[SIGCHLD-1].sa.sa_handler == SIG_IGN ||
 	     (psig->action[SIGCHLD-1].sa.sa_flags & SA_NOCLDWAIT))) {
 		/*
@@ -1486,7 +1486,7 @@ static void do_notify_parent_cldstop(struct task_struct *tsk, int why)
 	struct task_struct *parent;
 	struct sighand_struct *sighand;
 
-	if (tsk->ptrace & PT_PTRACED)
+	if (task_ptrace(tsk))
 		parent = tsk->parent;
 	else {
 		tsk = tsk->group_leader;
@@ -1535,7 +1535,7 @@ static void do_notify_parent_cldstop(struct task_struct *tsk, int why)
 
 static inline int may_ptrace_stop(void)
 {
-	if (!likely(current->ptrace & PT_PTRACED))
+	if (!likely(task_ptrace(current)))
 		return 0;
 	/*
 	 * Are we in the middle of do_coredump?
@@ -1753,7 +1753,7 @@ static int do_signal_stop(int signr)
 static int ptrace_signal(int signr, siginfo_t *info,
 			 struct pt_regs *regs, void *cookie)
 {
-	if (!(current->ptrace & PT_PTRACED))
+	if (!task_ptrace(current))
 		return signr;
 
 	ptrace_signal_deliver(regs, cookie);

commit 7a0aeb14e18ad59394bd9bbc6e57fb345819e748
Author: Vegard Nossum <vegard.nossum@gmail.com>
Date:   Sat May 16 11:28:33 2009 +0200

    signal: fix __send_signal() false positive kmemcheck warning
    
    This false positive is due to field padding in struct sigqueue. When
    this dynamically allocated structure is copied to the stack (in arch-
    specific delivery code), kmemcheck sees a read from the padding, which
    is, naturally, uninitialized.
    
    Hide the false positive using the __GFP_NOTRACK_FALSE_POSITIVE flag.
    Also made the rlimit override code a bit clearer by introducing a new
    variable.
    
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Vegard Nossum <vegard.nossum@gmail.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 809a228019ad..d81f4952eebb 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -832,6 +832,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 {
 	struct sigpending *pending;
 	struct sigqueue *q;
+	int override_rlimit;
 
 	trace_sched_signal_send(sig, t);
 
@@ -863,9 +864,13 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	   make sure at least one signal gets delivered and don't
 	   pass on the info struct.  */
 
-	q = __sigqueue_alloc(t, GFP_ATOMIC, (sig < SIGRTMIN &&
-					     (is_si_special(info) ||
-					      info->si_code >= 0)));
+	if (sig < SIGRTMIN)
+		override_rlimit = (is_si_special(info) || info->si_code >= 0);
+	else
+		override_rlimit = 0;
+
+	q = __sigqueue_alloc(t, GFP_ATOMIC | __GFP_NOTRACK_FALSE_POSITIVE,
+		override_rlimit);
 	if (q) {
 		list_add_tail(&q->list, &pending->list);
 		switch ((unsigned long) info) {

commit 3296ca27f50ecbd71db1d808c7a72d311027f919
Merge: e893123c7378 73fbad283cfb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 11 10:01:41 2009 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/security-testing-2.6
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/security-testing-2.6: (44 commits)
      nommu: Provide mmap_min_addr definition.
      TOMOYO: Add description of lists and structures.
      TOMOYO: Remove unused field.
      integrity: ima audit dentry_open failure
      TOMOYO: Remove unused parameter.
      security: use mmap_min_addr indepedently of security models
      TOMOYO: Simplify policy reader.
      TOMOYO: Remove redundant markers.
      SELinux: define audit permissions for audit tree netlink messages
      TOMOYO: Remove unused mutex.
      tomoyo: avoid get+put of task_struct
      smack: Remove redundant initialization.
      integrity: nfsd imbalance bug fix
      rootplug: Remove redundant initialization.
      smack: do not beyond ARRAY_SIZE of data
      integrity: move ima_counts_get
      integrity: path_check update
      IMA: Add __init notation to ima functions
      IMA: Minimal IMA policy and boot param for TCB IMA policy
      selinux: remove obsolete read buffer limit from sel_read_bool
      ...

commit 862366118026a358882eefc70238dbcc3db37aac
Merge: 57eee9ae7bbc 511b01bdf64a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jun 10 19:53:40 2009 -0700

    Merge branch 'tracing-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'tracing-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (244 commits)
      Revert "x86, bts: reenable ptrace branch trace support"
      tracing: do not translate event helper macros in print format
      ftrace/documentation: fix typo in function grapher name
      tracing/events: convert block trace points to TRACE_EVENT(), fix !CONFIG_BLOCK
      tracing: add protection around module events unload
      tracing: add trace_seq_vprint interface
      tracing: fix the block trace points print size
      tracing/events: convert block trace points to TRACE_EVENT()
      ring-buffer: fix ret in rb_add_time_stamp
      ring-buffer: pass in lockdep class key for reader_lock
      tracing: add annotation to what type of stack trace is recorded
      tracing: fix multiple use of __print_flags and __print_symbolic
      tracing/events: fix output format of user stack
      tracing/events: fix output format of kernel stack
      tracing/trace_stack: fix the number of entries in the header
      ring-buffer: discard timestamps that are at the start of the buffer
      ring-buffer: try to discard unneeded timestamps
      ring-buffer: fix bug in ring_buffer_discard_commit
      ftrace: do not profile functions when disabled
      tracing: make trace pipe recognize latency format flag
      ...

commit d254117099d711f215e62427f55dfb8ebd5ad011
Merge: 07ff7a0b187f 8c9ed899b44c
Author: James Morris <jmorris@namei.org>
Date:   Fri May 8 17:56:47 2009 +1000

    Merge branch 'master' into next

commit 62ab4505e3efaf67784f84059e0fb9cedb1728ea
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Apr 4 21:01:06 2009 +0000

    signals: implement sys_rt_tgsigqueueinfo
    
    sys_kill has the per thread counterpart sys_tgkill. sigqueueinfo is
    missing a thread directed counterpart. Such an interface is important
    for migrating applications from other OSes which have the per thread
    delivery implemented.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Acked-by: Ulrich Drepper <drepper@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 56d27acad87e..f79b3b9f8375 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2369,6 +2369,32 @@ SYSCALL_DEFINE3(rt_sigqueueinfo, pid_t, pid, int, sig,
 	return kill_proc_info(sig, &info, pid);
 }
 
+long do_rt_tgsigqueueinfo(pid_t tgid, pid_t pid, int sig, siginfo_t *info)
+{
+	/* This is only valid for single tasks */
+	if (pid <= 0 || tgid <= 0)
+		return -EINVAL;
+
+	/* Not even root can pretend to send signals from the kernel.
+	   Nor can they impersonate a kill(), which adds source info.  */
+	if (info->si_code >= 0)
+		return -EPERM;
+	info->si_signo = sig;
+
+	return do_send_specific(tgid, pid, sig, info);
+}
+
+SYSCALL_DEFINE4(rt_tgsigqueueinfo, pid_t, tgid, pid_t, pid, int, sig,
+		siginfo_t __user *, uinfo)
+{
+	siginfo_t info;
+
+	if (copy_from_user(&info, uinfo, sizeof(siginfo_t)))
+		return -EFAULT;
+
+	return do_rt_tgsigqueueinfo(tgid, pid, sig, &info);
+}
+
 int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 {
 	struct task_struct *t = current;

commit 30b4ae8a4498543863501f707879b7220b649602
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Apr 4 21:01:01 2009 +0000

    signals: split do_tkill
    
    Split out the code from do_tkill to make it reusable by the follow up
    patch which implements sys_rt_tgsigqueueinfo
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index d8034737db4c..56d27acad87e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2278,24 +2278,17 @@ SYSCALL_DEFINE2(kill, pid_t, pid, int, sig)
 	return kill_something_info(sig, &info, pid);
 }
 
-static int do_tkill(pid_t tgid, pid_t pid, int sig)
+static int
+do_send_specific(pid_t tgid, pid_t pid, int sig, struct siginfo *info)
 {
-	int error;
-	struct siginfo info;
 	struct task_struct *p;
 	unsigned long flags;
-
-	error = -ESRCH;
-	info.si_signo = sig;
-	info.si_errno = 0;
-	info.si_code = SI_TKILL;
-	info.si_pid = task_tgid_vnr(current);
-	info.si_uid = current_uid();
+	int error = -ESRCH;
 
 	rcu_read_lock();
 	p = find_task_by_vpid(pid);
 	if (p && (tgid <= 0 || task_tgid_vnr(p) == tgid)) {
-		error = check_kill_permission(sig, &info, p);
+		error = check_kill_permission(sig, info, p);
 		/*
 		 * The null signal is a permissions and process existence
 		 * probe.  No signal is actually delivered.
@@ -2305,7 +2298,7 @@ static int do_tkill(pid_t tgid, pid_t pid, int sig)
 		 * signal is private anyway.
 		 */
 		if (!error && sig && lock_task_sighand(p, &flags)) {
-			error = specific_send_sig_info(sig, &info, p);
+			error = specific_send_sig_info(sig, info, p);
 			unlock_task_sighand(p, &flags);
 		}
 	}
@@ -2314,6 +2307,19 @@ static int do_tkill(pid_t tgid, pid_t pid, int sig)
 	return error;
 }
 
+static int do_tkill(pid_t tgid, pid_t pid, int sig)
+{
+	struct siginfo info;
+
+	info.si_signo = sig;
+	info.si_errno = 0;
+	info.si_code = SI_TKILL;
+	info.si_pid = task_tgid_vnr(current);
+	info.si_uid = current_uid();
+
+	return do_send_specific(tgid, pid, sig, &info);
+}
+
 /**
  *  sys_tgkill - send signal to one specific thread
  *  @tgid: the thread group ID of the thread

commit 3bcac0263f0b45e67a64034ebcb69eb9abb742f4
Author: David Howells <dhowells@redhat.com>
Date:   Wed Apr 29 13:45:05 2009 +0100

    SELinux: Don't flush inherited SIGKILL during execve()
    
    Don't flush inherited SIGKILL during execve() in SELinux's post cred commit
    hook.  This isn't really a security problem: if the SIGKILL came before the
    credentials were changed, then we were right to receive it at the time, and
    should honour it; if it came after the creds were changed, then we definitely
    should honour it; and in any case, all that will happen is that the process
    will be scrapped before it ever returns to userspace.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1c8814481a11..f93efec14ff5 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -238,14 +238,19 @@ void flush_sigqueue(struct sigpending *queue)
 /*
  * Flush all pending signals for a task.
  */
+void __flush_signals(struct task_struct *t)
+{
+	clear_tsk_thread_flag(t, TIF_SIGPENDING);
+	flush_sigqueue(&t->pending);
+	flush_sigqueue(&t->signal->shared_pending);
+}
+
 void flush_signals(struct task_struct *t)
 {
 	unsigned long flags;
 
 	spin_lock_irqsave(&t->sighand->siglock, flags);
-	clear_tsk_thread_flag(t, TIF_SIGPENDING);
-	flush_sigqueue(&t->pending);
-	flush_sigqueue(&t->signal->shared_pending);
+	__flush_signals(t);
 	spin_unlock_irqrestore(&t->sighand->siglock, flags);
 }
 

commit ad8d75fff811a6a230f7f43b05a6483099349533
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Tue Apr 14 19:39:12 2009 -0400

    tracing/events: move trace point headers into include/trace/events
    
    Impact: clean up
    
    Create a sub directory in include/trace called events to keep the
    trace point headers in their own separate directory. Only headers that
    declare trace points should be defined in this directory.
    
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Cc: Zhao Lei <zhaolei@cn.fujitsu.com>
    Cc: Eduard - Gabriel Munteanu <eduard.munteanu@linux360.ro>
    Cc: Pekka Enberg <penberg@cs.helsinki.fi>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1d5703ff003c..94ec0a4dde0f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -27,7 +27,7 @@
 #include <linux/freezer.h>
 #include <linux/pid_namespace.h>
 #include <linux/nsproxy.h>
-#include <trace/sched.h>
+#include <trace/events/sched.h>
 
 #include <asm/param.h>
 #include <asm/uaccess.h>

commit a8d154b009168337494fbf345671bab74d3e4b8b
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Fri Apr 10 09:36:00 2009 -0400

    tracing: create automated trace defines
    
    This patch lowers the number of places a developer must modify to add
    new tracepoints. The current method to add a new tracepoint
    into an existing system is to write the trace point macro in the
    trace header with one of the macros TRACE_EVENT, TRACE_FORMAT or
    DECLARE_TRACE, then they must add the same named item into the C file
    with the macro DEFINE_TRACE(name) and then add the trace point.
    
    This change cuts out the needing to add the DEFINE_TRACE(name).
    Every file that uses the tracepoint must still include the trace/<type>.h
    file, but the one C file must also add a define before the including
    of that file.
    
     #define CREATE_TRACE_POINTS
     #include <trace/mytrace.h>
    
    This will cause the trace/mytrace.h file to also produce the C code
    necessary to implement the trace point.
    
    Note, if more than one trace/<type>.h is used to create the C code
    it is best to list them all together.
    
     #define CREATE_TRACE_POINTS
     #include <trace/foo.h>
     #include <trace/bar.h>
     #include <trace/fido.h>
    
    Thanks to Mathieu Desnoyers and Christoph Hellwig for coming up with
    the cleaner solution of the define above the includes over my first
    design to have the C code include a "special" header.
    
    This patch converts sched, irq and lockdep and skb to use this new
    method.
    
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Cc: Zhao Lei <zhaolei@cn.fujitsu.com>
    Cc: Eduard - Gabriel Munteanu <eduard.munteanu@linux360.ro>
    Cc: Pekka Enberg <penberg@cs.helsinki.fi>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index d8034737db4c..1d5703ff003c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -41,8 +41,6 @@
 
 static struct kmem_cache *sigqueue_cachep;
 
-DEFINE_TRACE(sched_signal_send);
-
 static void __user *sig_handler(struct task_struct *t, int sig)
 {
 	return t->sighand->action[sig - 1].sa.sa_handler;

commit 6588c1e3ff01418acafd938db0740e3477dc8cb7
Author: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
Date:   Thu Apr 2 16:58:09 2009 -0700

    signals: SI_USER: Masquerade si_pid when crossing pid ns boundary
    
    When sending a signal to a descendant namespace, set ->si_pid to 0 since
    the sender does not have a pid in the receiver's namespace.
    
    Note:
            - If rt_sigqueueinfo() sets si_code to SI_USER when sending a
              signal across a pid namespace boundary, the value in ->si_pid
              will be cleared to 0.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Daniel Lezcano <daniel.lezcano@free.fr>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index ba3da25f0eea..d8034737db4c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -883,6 +883,8 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			break;
 		default:
 			copy_siginfo(&q->info, info);
+			if (from_ancestor_ns)
+				q->info.si_pid = 0;
 			break;
 		}
 	} else if (!is_si_special(info)) {

commit b3bfa0cba867f23365b81658b47efd906830879b
Author: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
Date:   Thu Apr 2 16:58:08 2009 -0700

    signals: protect cinit from blocked fatal signals
    
    Normally SIG_DFL signals to global and container-init are dropped early.
    But if a signal is blocked when it is posted, we cannot drop the signal
    since the receiver may install a handler before unblocking the signal.
    Once this signal is queued however, the receiver container-init has no way
    of knowing if the signal was sent from an ancestor or descendant
    namespace.  This patch ensures that contianer-init drops all SIG_DFL
    signals in get_signal_to_deliver() except SIGKILL/SIGSTOP.
    
    If SIGSTOP/SIGKILL originate from a descendant of container-init they are
    never queued (i.e dropped in sig_ignored() in an earler patch).
    
    If SIGSTOP/SIGKILL originate from parent namespace, the signal is queued
    and container-init processes the signal.
    
    IOW, if get_signal_to_deliver() sees a sig_kernel_only() signal for global
    or container-init, the signal must have been generated internally or must
    have come from an ancestor ns and we process the signal.
    
    Further, the signal_group_exit() check was needed to cover the case of a
    multi-threaded init sending SIGKILL to other threads when doing an exit()
    or exec().  But since the new sig_kernel_only() check covers the SIGKILL,
    the signal_group_exit() check is no longer needed and can be removed.
    
    Finally, now that we have all pieces in place, set SIGNAL_UNKILLABLE for
    container-inits.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Daniel Lezcano <daniel.lezcano@free.fr>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index fb19aae2363b..ba3da25f0eea 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1870,9 +1870,16 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 
 		/*
 		 * Global init gets no signals it doesn't want.
+		 * Container-init gets no signals it doesn't want from same
+		 * container.
+		 *
+		 * Note that if global/container-init sees a sig_kernel_only()
+		 * signal here, the signal must have been generated internally
+		 * or must have come from an ancestor namespace. In either
+		 * case, the signal cannot be dropped.
 		 */
 		if (unlikely(signal->flags & SIGNAL_UNKILLABLE) &&
-		    !signal_group_exit(signal))
+				!sig_kernel_only(signr))
 			continue;
 
 		if (sig_kernel_stop(signr)) {

commit 921cf9f63089c7442d44083477620132f4cea066
Author: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
Date:   Thu Apr 2 16:58:05 2009 -0700

    signals: protect cinit from unblocked SIG_DFL signals
    
    Drop early any SIG_DFL or SIG_IGN signals to container-init from within
    the same container.  But queue SIGSTOP and SIGKILL to the container-init
    if they are from an ancestor container.
    
    Blocked, fatal signals (i.e when SIG_DFL is to terminate) from within the
    container can still terminate the container-init.  That will be addressed
    in the next patch.
    
    Note:   To be bisect-safe, SIGNAL_UNKILLABLE will be set for container-inits
            in a follow-on patch. Until then, this patch is just a preparatory
            step.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Daniel Lezcano <daniel.lezcano@free.fr>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 7b6de962a1af..fb19aae2363b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -55,20 +55,21 @@ static int sig_handler_ignored(void __user *handler, int sig)
 		(handler == SIG_DFL && sig_kernel_ignore(sig));
 }
 
-static int sig_task_ignored(struct task_struct *t, int sig)
+static int sig_task_ignored(struct task_struct *t, int sig,
+		int from_ancestor_ns)
 {
 	void __user *handler;
 
 	handler = sig_handler(t, sig);
 
 	if (unlikely(t->signal->flags & SIGNAL_UNKILLABLE) &&
-			handler == SIG_DFL)
+			handler == SIG_DFL && !from_ancestor_ns)
 		return 1;
 
 	return sig_handler_ignored(handler, sig);
 }
 
-static int sig_ignored(struct task_struct *t, int sig)
+static int sig_ignored(struct task_struct *t, int sig, int from_ancestor_ns)
 {
 	/*
 	 * Blocked signals are never ignored, since the
@@ -78,7 +79,7 @@ static int sig_ignored(struct task_struct *t, int sig)
 	if (sigismember(&t->blocked, sig) || sigismember(&t->real_blocked, sig))
 		return 0;
 
-	if (!sig_task_ignored(t, sig))
+	if (!sig_task_ignored(t, sig, from_ancestor_ns))
 		return 0;
 
 	/*
@@ -634,7 +635,7 @@ static int check_kill_permission(int sig, struct siginfo *info,
  * Returns true if the signal should be actually delivered, otherwise
  * it should be dropped.
  */
-static int prepare_signal(int sig, struct task_struct *p)
+static int prepare_signal(int sig, struct task_struct *p, int from_ancestor_ns)
 {
 	struct signal_struct *signal = p->signal;
 	struct task_struct *t;
@@ -718,7 +719,7 @@ static int prepare_signal(int sig, struct task_struct *p)
 		}
 	}
 
-	return !sig_ignored(p, sig);
+	return !sig_ignored(p, sig, from_ancestor_ns);
 }
 
 /*
@@ -832,7 +833,8 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	trace_sched_signal_send(sig, t);
 
 	assert_spin_locked(&t->sighand->siglock);
-	if (!prepare_signal(sig, t))
+
+	if (!prepare_signal(sig, t, from_ancestor_ns))
 		return 0;
 
 	pending = group ? &t->signal->shared_pending : &t->pending;
@@ -902,7 +904,15 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
 static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			int group)
 {
-	return __send_signal(sig, info, t, group, 0);
+	int from_ancestor_ns = 0;
+
+#ifdef CONFIG_PID_NS
+	if (!is_si_special(info) && SI_FROMUSER(info) &&
+			task_pid_nr_ns(current, task_active_pid_ns(t)) <= 0)
+		from_ancestor_ns = 1;
+#endif
+
+	return __send_signal(sig, info, t, group, from_ancestor_ns);
 }
 
 int print_fatal_signals;
@@ -1336,7 +1346,7 @@ int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)
 		goto ret;
 
 	ret = 1; /* the signal is ignored */
-	if (!prepare_signal(sig, t))
+	if (!prepare_signal(sig, t, 0))
 		goto out;
 
 	ret = 0;

commit 7978b567d31555fc828b8f945c605ad29e117b22
Author: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
Date:   Thu Apr 2 16:58:04 2009 -0700

    signals: add from_ancestor_ns parameter to send_signal()
    
    send_signal() (or its helper) needs to determine the pid namespace of the
    sender.  But a signal sent via kill_pid_info_as_uid() comes from within
    the kernel and send_signal() does not need to determine the pid namespace
    of the sender.  So define a helper for send_signal() which takes an
    additional parameter, 'from_ancestor_ns' and have kill_pid_info_as_uid()
    use that helper directly.
    
    The 'from_ancestor_ns' parameter will be used in a follow-on patch.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Daniel Lezcano <daniel.lezcano@free.fr>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8bf7a40e5c71..7b6de962a1af 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -823,8 +823,8 @@ static inline int legacy_queue(struct sigpending *signals, int sig)
 	return (sig < SIGRTMIN) && sigismember(&signals->signal, sig);
 }
 
-static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
-			int group)
+static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,
+			int group, int from_ancestor_ns)
 {
 	struct sigpending *pending;
 	struct sigqueue *q;
@@ -899,6 +899,12 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	return 0;
 }
 
+static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
+			int group)
+{
+	return __send_signal(sig, info, t, group, 0);
+}
+
 int print_fatal_signals;
 
 static void print_fatal_signal(struct pt_regs *regs, int signr)
@@ -1143,7 +1149,7 @@ int kill_pid_info_as_uid(int sig, struct siginfo *info, struct pid *pid,
 	if (sig && p->sighand) {
 		unsigned long flags;
 		spin_lock_irqsave(&p->sighand->siglock, flags);
-		ret = __group_send_sig_info(sig, info, p);
+		ret = __send_signal(sig, info, p, 1, 0);
 		spin_unlock_irqrestore(&p->sighand->siglock, flags);
 	}
 out_unlock:

commit f008faff0e2777c8b3fe853891b774ca465938d8
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Apr 2 16:58:02 2009 -0700

    signals: protect init from unwanted signals more
    
    (This is a modified version of the patch submitted by Oleg Nesterov
    http://lkml.org/lkml/2008/11/18/249 and tries to address comments that
    came up in that discussion)
    
    init ignores the SIG_DFL signals but we queue them anyway, including
    SIGKILL.  This is mostly OK, the signal will be dropped silently when
    dequeued, but the pending SIGKILL has 2 bad implications:
    
            - it implies fatal_signal_pending(), so we confuse things
              like wait_for_completion_killable/lock_page_killable.
    
            - for the sub-namespace inits, the pending SIGKILL can
              mask (legacy_queue) the subsequent SIGKILL from the
              parent namespace which must kill cinit reliably.
              (preparation, cinits don't have SIGNAL_UNKILLABLE yet)
    
    The patch can't help when init is ptraced, but ptracing of init is not
    "safe" anyway.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Daniel Lezcano <daniel.lezcano@free.fr>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 92a1ab004498..8bf7a40e5c71 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -55,10 +55,21 @@ static int sig_handler_ignored(void __user *handler, int sig)
 		(handler == SIG_DFL && sig_kernel_ignore(sig));
 }
 
-static int sig_ignored(struct task_struct *t, int sig)
+static int sig_task_ignored(struct task_struct *t, int sig)
 {
 	void __user *handler;
 
+	handler = sig_handler(t, sig);
+
+	if (unlikely(t->signal->flags & SIGNAL_UNKILLABLE) &&
+			handler == SIG_DFL)
+		return 1;
+
+	return sig_handler_ignored(handler, sig);
+}
+
+static int sig_ignored(struct task_struct *t, int sig)
+{
 	/*
 	 * Blocked signals are never ignored, since the
 	 * signal handler may change by the time it is
@@ -67,8 +78,7 @@ static int sig_ignored(struct task_struct *t, int sig)
 	if (sigismember(&t->blocked, sig) || sigismember(&t->real_blocked, sig))
 		return 0;
 
-	handler = sig_handler(t, sig);
-	if (!sig_handler_ignored(handler, sig))
+	if (!sig_task_ignored(t, sig))
 		return 0;
 
 	/*

commit 43918f2bf4806675943416d539d9d5e4d585ebff
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Apr 2 16:58:00 2009 -0700

    signals: remove 'handler' parameter to tracehook functions
    
    Container-init must behave like global-init to processes within the
    container and hence it must be immune to unhandled fatal signals from
    within the container (i.e SIG_DFL signals that terminate the process).
    
    But the same container-init must behave like a normal process to processes
    in ancestor namespaces and so if it receives the same fatal signal from a
    process in ancestor namespace, the signal must be processed.
    
    Implementing these semantics requires that send_signal() determine pid
    namespace of the sender but since signals can originate from workqueues/
    interrupt-handlers, determining pid namespace of sender may not always be
    possible or safe.
    
    This patchset implements the design/simplified semantics suggested by
    Oleg Nesterov.  The simplified semantics for container-init are:
    
            - container-init must never be terminated by a signal from a
              descendant process.
    
            - container-init must never be immune to SIGKILL from an ancestor
              namespace (so a process in parent namespace must always be able
              to terminate a descendant container).
    
            - container-init may be immune to unhandled fatal signals (like
              SIGUSR1) even if they are from ancestor namespace. SIGKILL/SIGSTOP
              are the only reliable signals to a container-init from ancestor
              namespace.
    
    This patch:
    
    Based on an earlier patch submitted by Oleg Nesterov and comments from
    Roland McGrath (http://lkml.org/lkml/2008/11/19/258).
    
    The handler parameter is currently unused in the tracehook functions.
    Besides, the tracehook functions are called with siglock held, so the
    functions can check the handler if they later need to.
    
    Removing the parameter simiplifies changes to sig_ignored() in a follow-on
    patch.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Daniel Lezcano <daniel.lezcano@free.fr>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1c8814481a11..92a1ab004498 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -74,7 +74,7 @@ static int sig_ignored(struct task_struct *t, int sig)
 	/*
 	 * Tracers may want to know about even ignored signals.
 	 */
-	return !tracehook_consider_ignored_signal(t, sig, handler);
+	return !tracehook_consider_ignored_signal(t, sig);
 }
 
 /*
@@ -318,7 +318,7 @@ int unhandled_signal(struct task_struct *tsk, int sig)
 		return 1;
 	if (handler != SIG_IGN && handler != SIG_DFL)
 		return 0;
-	return !tracehook_consider_fatal_signal(tsk, sig, handler);
+	return !tracehook_consider_fatal_signal(tsk, sig);
 }
 
 
@@ -777,7 +777,7 @@ static void complete_signal(int sig, struct task_struct *p, int group)
 	    !(signal->flags & (SIGNAL_UNKILLABLE | SIGNAL_GROUP_EXIT)) &&
 	    !sigismember(&t->real_blocked, sig) &&
 	    (sig == SIGKILL ||
-	     !tracehook_consider_fatal_signal(t, sig, SIG_DFL))) {
+	     !tracehook_consider_fatal_signal(t, sig))) {
 		/*
 		 * This signal will be fatal to the whole group.
 		 */

commit 53da1d9456fe7f87a920a78fdbdcf1225d197cb7
Author: Miklos Szeredi <mszeredi@suse.cz>
Date:   Mon Mar 23 16:07:24 2009 +0100

    fix ptrace slowness
    
    This patch fixes bug #12208:
    
      Bug-Entry       : http://bugzilla.kernel.org/show_bug.cgi?id=12208
      Subject         : uml is very slow on 2.6.28 host
    
    This turned out to be not a scheduler regression, but an already
    existing problem in ptrace being triggered by subtle scheduler
    changes.
    
    The problem is this:
    
     - task A is ptracing task B
     - task B stops on a trace event
     - task A is woken up and preempts task B
     - task A calls ptrace on task B, which does ptrace_check_attach()
     - this calls wait_task_inactive(), which sees that task B is still on the runq
     - task A goes to sleep for a jiffy
     - ...
    
    Since UML does lots of the above sequences, those jiffies quickly add
    up to make it slow as hell.
    
    This patch solves this by not rescheduling in read_unlock() after
    ptrace_stop() has woken up the tracer.
    
    Thanks to Oleg Nesterov and Ingo Molnar for the feedback.
    
    Signed-off-by: Miklos Szeredi <mszeredi@suse.cz>
    CC: stable@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2a74fe87c0dd..1c8814481a11 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1575,7 +1575,15 @@ static void ptrace_stop(int exit_code, int clear_code, siginfo_t *info)
 	read_lock(&tasklist_lock);
 	if (may_ptrace_stop()) {
 		do_notify_parent_cldstop(current, CLD_TRAPPED);
+		/*
+		 * Don't want to allow preemption here, because
+		 * sys_ptrace() needs this task to be inactive.
+		 *
+		 * XXX: implement read_unlock_no_resched().
+		 */
+		preempt_disable();
 		read_unlock(&tasklist_lock);
+		preempt_enable_no_resched();
 		schedule();
 	} else {
 		/*

commit 32bd671d6cbeda60dc73be77fa2b9037d9a9bfa0
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Thu Feb 5 12:24:15 2009 +0100

    signal: re-add dead task accumulation stats.
    
    We're going to split the process wide cpu accounting into two parts:
    
     - clocks; which can take all the time they want since they run
               from user context.
    
     - timers; which need constant time tracing but can affort the overhead
               because they're default off -- and rare.
    
    The clock readout will go back to a full sum of the thread group, for this
    we need to re-add the exit stats that were removed in the initial itimer
    rework (f06febc9: timers: fix itimer/many thread hang).
    
    Furthermore, since that full sum can be rather slow for large thread groups
    and we have the complete dead task stats, revert the do_notify_parent time
    computation.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/signal.c b/kernel/signal.c
index b6b36768b758..2a74fe87c0dd 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1367,7 +1367,6 @@ int do_notify_parent(struct task_struct *tsk, int sig)
 	struct siginfo info;
 	unsigned long flags;
 	struct sighand_struct *psig;
-	struct task_cputime cputime;
 	int ret = sig;
 
 	BUG_ON(sig == -1);
@@ -1397,9 +1396,10 @@ int do_notify_parent(struct task_struct *tsk, int sig)
 	info.si_uid = __task_cred(tsk)->uid;
 	rcu_read_unlock();
 
-	thread_group_cputime(tsk, &cputime);
-	info.si_utime = cputime_to_jiffies(cputime.utime);
-	info.si_stime = cputime_to_jiffies(cputime.stime);
+	info.si_utime = cputime_to_clock_t(cputime_add(tsk->utime,
+				tsk->signal->utime));
+	info.si_stime = cputime_to_clock_t(cputime_add(tsk->stime,
+				tsk->signal->stime));
 
 	info.si_status = tsk->exit_code & 0x7f;
 	if (tsk->exit_code & 0x80)

commit 3a9f84d354ce1e19956083c8e691727dea33bd5a
Author: Ed Swierk <eswierk@aristanetworks.com>
Date:   Mon Jan 26 15:33:31 2009 -0800

    signals, debug: fix BUG: using smp_processor_id() in preemptible code in print_fatal_signal()
    
    With print-fatal-signals=1 on a kernel with CONFIG_PREEMPT=y, sending an
    unexpected signal to a process causes a BUG: using smp_processor_id() in
    preemptible code.
    
    get_signal_to_deliver() releases the siglock before calling
    print_fatal_signal(), which calls show_regs(), which calls
    smp_processor_id(), which is not supposed to be called from a
    preemptible thread.
    
    Make sure show_regs() runs with preemption disabled.
    
    Signed-off-by: Ed Swierk <eswierk@aristanetworks.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/signal.c b/kernel/signal.c
index e73759783dc8..b6b36768b758 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -909,7 +909,9 @@ static void print_fatal_signal(struct pt_regs *regs, int signr)
 	}
 #endif
 	printk("\n");
+	preempt_disable();
 	show_regs(regs);
+	preempt_enable();
 }
 
 static int __init setup_print_fatal_signals(char *str)

commit d4e82042c4cfa87a7d51710b71f568fe80132551
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed Jan 14 14:14:34 2009 +0100

    [CVE-2009-0029] System call wrappers part 32
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index e2333929611a..e73759783dc8 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2491,11 +2491,10 @@ SYSCALL_DEFINE3(sigprocmask, int, how, old_sigset_t __user *, set,
 #endif /* __ARCH_WANT_SYS_SIGPROCMASK */
 
 #ifdef __ARCH_WANT_SYS_RT_SIGACTION
-asmlinkage long
-sys_rt_sigaction(int sig,
-		 const struct sigaction __user *act,
-		 struct sigaction __user *oact,
-		 size_t sigsetsize)
+SYSCALL_DEFINE4(rt_sigaction, int, sig,
+		const struct sigaction __user *, act,
+		struct sigaction __user *, oact,
+		size_t, sigsetsize)
 {
 	struct k_sigaction new_sa, old_sa;
 	int ret = -EINVAL;
@@ -2578,7 +2577,7 @@ SYSCALL_DEFINE0(pause)
 #endif
 
 #ifdef __ARCH_WANT_SYS_RT_SIGSUSPEND
-asmlinkage long sys_rt_sigsuspend(sigset_t __user *unewset, size_t sigsetsize)
+SYSCALL_DEFINE2(rt_sigsuspend, sigset_t __user *, unewset, size_t, sigsetsize)
 {
 	sigset_t newset;
 

commit a5f8fa9e9ba5ef3305e147f41ad6e1e84ac1f0bd
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed Jan 14 14:14:11 2009 +0100

    [CVE-2009-0029] System call wrappers part 09
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 278cc8737f17..e2333929611a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2279,7 +2279,7 @@ static int do_tkill(pid_t tgid, pid_t pid, int sig)
  *  exists but it's not belonging to the target process anymore. This
  *  method solves the problem of threads exiting and PIDs getting reused.
  */
-asmlinkage long sys_tgkill(pid_t tgid, pid_t pid, int sig)
+SYSCALL_DEFINE3(tgkill, pid_t, tgid, pid_t, pid, int, sig)
 {
 	/* This is only valid for single tasks */
 	if (pid <= 0 || tgid <= 0)
@@ -2291,8 +2291,7 @@ asmlinkage long sys_tgkill(pid_t tgid, pid_t pid, int sig)
 /*
  *  Send a signal to only one task, even if it's a CLONE_THREAD task.
  */
-asmlinkage long
-sys_tkill(pid_t pid, int sig)
+SYSCALL_DEFINE2(tkill, pid_t, pid, int, sig)
 {
 	/* This is only valid for single tasks */
 	if (pid <= 0)
@@ -2301,8 +2300,8 @@ sys_tkill(pid_t pid, int sig)
 	return do_tkill(0, pid, sig);
 }
 
-asmlinkage long
-sys_rt_sigqueueinfo(pid_t pid, int sig, siginfo_t __user *uinfo)
+SYSCALL_DEFINE3(rt_sigqueueinfo, pid_t, pid, int, sig,
+		siginfo_t __user *, uinfo)
 {
 	siginfo_t info;
 
@@ -2526,15 +2525,13 @@ sys_rt_sigaction(int sig,
 /*
  * For backwards compatibility.  Functionality superseded by sigprocmask.
  */
-asmlinkage long
-sys_sgetmask(void)
+SYSCALL_DEFINE0(sgetmask)
 {
 	/* SMP safe */
 	return current->blocked.sig[0];
 }
 
-asmlinkage long
-sys_ssetmask(int newmask)
+SYSCALL_DEFINE1(ssetmask, int, newmask)
 {
 	int old;
 
@@ -2554,8 +2551,7 @@ sys_ssetmask(int newmask)
 /*
  * For backwards compatibility.  Functionality superseded by sigaction.
  */
-asmlinkage long
-sys_signal(int sig, __sighandler_t handler)
+SYSCALL_DEFINE2(signal, int, sig, __sighandler_t, handler)
 {
 	struct k_sigaction new_sa, old_sa;
 	int ret;
@@ -2572,8 +2568,7 @@ sys_signal(int sig, __sighandler_t handler)
 
 #ifdef __ARCH_WANT_SYS_PAUSE
 
-asmlinkage long
-sys_pause(void)
+SYSCALL_DEFINE0(pause)
 {
 	current->state = TASK_INTERRUPTIBLE;
 	schedule();

commit 17da2bd90abf428523de0fb98f7075e00e3ed42e
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed Jan 14 14:14:10 2009 +0100

    [CVE-2009-0029] System call wrappers part 08
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 41f32e08615e..278cc8737f17 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2014,8 +2014,8 @@ int sigprocmask(int how, sigset_t *set, sigset_t *oldset)
 	return error;
 }
 
-asmlinkage long
-sys_rt_sigprocmask(int how, sigset_t __user *set, sigset_t __user *oset, size_t sigsetsize)
+SYSCALL_DEFINE4(rt_sigprocmask, int, how, sigset_t __user *, set,
+		sigset_t __user *, oset, size_t, sigsetsize)
 {
 	int error = -EINVAL;
 	sigset_t old_set, new_set;
@@ -2074,8 +2074,7 @@ long do_sigpending(void __user *set, unsigned long sigsetsize)
 	return error;
 }	
 
-asmlinkage long
-sys_rt_sigpending(sigset_t __user *set, size_t sigsetsize)
+SYSCALL_DEFINE2(rt_sigpending, sigset_t __user *, set, size_t, sigsetsize)
 {
 	return do_sigpending(set, sigsetsize);
 }
@@ -2146,11 +2145,9 @@ int copy_siginfo_to_user(siginfo_t __user *to, siginfo_t *from)
 
 #endif
 
-asmlinkage long
-sys_rt_sigtimedwait(const sigset_t __user *uthese,
-		    siginfo_t __user *uinfo,
-		    const struct timespec __user *uts,
-		    size_t sigsetsize)
+SYSCALL_DEFINE4(rt_sigtimedwait, const sigset_t __user *, uthese,
+		siginfo_t __user *, uinfo, const struct timespec __user *, uts,
+		size_t, sigsetsize)
 {
 	int ret, sig;
 	sigset_t these;
@@ -2223,8 +2220,7 @@ sys_rt_sigtimedwait(const sigset_t __user *uthese,
 	return ret;
 }
 
-asmlinkage long
-sys_kill(pid_t pid, int sig)
+SYSCALL_DEFINE2(kill, pid_t, pid, int, sig)
 {
 	struct siginfo info;
 

commit 754fe8d297bfae7b77f7ce866e2fb0c5fb186506
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed Jan 14 14:14:09 2009 +0100

    [CVE-2009-0029] System call wrappers part 07
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 3fe08eaa5dea..41f32e08615e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1961,7 +1961,7 @@ EXPORT_SYMBOL(unblock_all_signals);
  * System call entry points.
  */
 
-asmlinkage long sys_restart_syscall(void)
+SYSCALL_DEFINE0(restart_syscall)
 {
 	struct restart_block *restart = &current_thread_info()->restart_block;
 	return restart->fn(restart);

commit b290ebe2c46d01b742b948ce03f09e8a3efb9a92
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed Jan 14 14:14:06 2009 +0100

    [CVE-2009-0029] System call wrappers part 04
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 856a5479d49d..3fe08eaa5dea 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2434,8 +2434,7 @@ do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long s
 
 #ifdef __ARCH_WANT_SYS_SIGPENDING
 
-asmlinkage long
-sys_sigpending(old_sigset_t __user *set)
+SYSCALL_DEFINE1(sigpending, old_sigset_t __user *, set)
 {
 	return do_sigpending(set, sizeof(*set));
 }
@@ -2446,8 +2445,8 @@ sys_sigpending(old_sigset_t __user *set)
 /* Some platforms have their own version with special arguments others
    support only sys_rt_sigprocmask.  */
 
-asmlinkage long
-sys_sigprocmask(int how, old_sigset_t __user *set, old_sigset_t __user *oset)
+SYSCALL_DEFINE3(sigprocmask, int, how, old_sigset_t __user *, set,
+		old_sigset_t __user *, oset)
 {
 	int error;
 	old_sigset_t old_set, new_set;

commit 2ed7c03ec17779afb4fcfa3b8c61df61bd4879ba
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed Jan 14 14:13:54 2009 +0100

    [CVE-2009-0029] Convert all system calls to return a long
    
    Convert all system calls to return a long. This should be a NOP since all
    converted types should have the same size anyway.
    With the exception of sys_exit_group which returned void. But that doesn't
    matter since the system call doesn't return.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index 3152ac3b62e2..856a5479d49d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2559,7 +2559,7 @@ sys_ssetmask(int newmask)
 /*
  * For backwards compatibility.  Functionality superseded by sigaction.
  */
-asmlinkage unsigned long
+asmlinkage long
 sys_signal(int sig, __sighandler_t handler)
 {
 	struct k_sigaction new_sa, old_sa;

commit 9cd4fd10437dda6b520cb1410b28f36967a34de8
Author: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
Date:   Tue Jan 6 14:42:46 2009 -0800

    SEND_SIG_NOINFO: set si_pid to tgid instead of pid
    
    POSIX requires the si_pid to be the process id of the sender, so ->si_pid
    should really be set to 'tgid'.  This change does have following changes
    in behavior:
    
            - When sending pdeath_signal on re-parent to a sub-thread, ->si_pid
              cannot be used to identify the thread that did the re-parent since
              it will now show the tgid instead of thread id.
    
            - A multi-threaded application that expects to find the specific
              thread that encountered a SIGPIPE using the ->si_pid will now
              break.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Acked-By: Roland McGrath <roland@redhat.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 31db63b3f88b..3152ac3b62e2 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -858,7 +858,7 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			q->info.si_signo = sig;
 			q->info.si_errno = 0;
 			q->info.si_code = SI_USER;
-			q->info.si_pid = task_pid_nr_ns(current,
+			q->info.si_pid = task_tgid_nr_ns(current,
 							task_active_pid_ns(t));
 			q->info.si_uid = current_uid();
 			break;

commit 09bca05c90c639f57aae057e0c28f287e61f5a07
Author: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
Date:   Tue Jan 6 14:42:45 2009 -0800

    SEND_SIG_NOINFO: masquerade si_pid when crossing pid-ns boundary
    
    For SEND_SIG_NOINFO, si_pid is currently set to the pid of sender
    in sender's active pid namespace. But if the receiver is in a
    Eg: when parent sends the 'pdeath_signal' to a child that is in
    a descendant pid namespace, we should set si_pid 0.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Acked-By: Roland McGrath <roland@redhat.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8e95855ff3cf..31db63b3f88b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -858,7 +858,8 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			q->info.si_signo = sig;
 			q->info.si_errno = 0;
 			q->info.si_code = SI_USER;
-			q->info.si_pid = task_pid_vnr(current);
+			q->info.si_pid = task_pid_nr_ns(current,
+							task_active_pid_ns(t));
 			q->info.si_uid = current_uid();
 			break;
 		case (unsigned long) SEND_SIG_PRIV:

commit b0f4b285d7ed174804658539129a834270f4829a
Merge: be9c5ae4eeec 5250d329e38c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Dec 28 12:21:10 2008 -0800

    Merge branch 'tracing-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'tracing-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (241 commits)
      sched, trace: update trace_sched_wakeup()
      tracing/ftrace: don't trace on early stage of a secondary cpu boot, v3
      Revert "x86: disable X86_PTRACE_BTS"
      ring-buffer: prevent false positive warning
      ring-buffer: fix dangling commit race
      ftrace: enable format arguments checking
      x86, bts: memory accounting
      x86, bts: add fork and exit handling
      ftrace: introduce tracing_reset_online_cpus() helper
      tracing: fix warnings in kernel/trace/trace_sched_switch.c
      tracing: fix warning in kernel/trace/trace.c
      tracing/ring-buffer: remove unused ring_buffer size
      trace: fix task state printout
      ftrace: add not to regex on filtering functions
      trace: better use of stack_trace_enabled for boot up code
      trace: add a way to enable or disable the stack tracer
      x86: entry_64 - introduce FTRACE_ frame macro v2
      tracing/ftrace: add the printk-msg-only option
      tracing/ftrace: use preempt_enable_no_resched_notrace in ring_buffer_time_stamp()
      x86, bts: correctly report invalid bts records
      ...
    
    Fixed up trivial conflict in scripts/recordmcount.pl due to SH bits
    being already partly merged by the SH merge.

commit 7e066fb870fcd1025ec3ba7bbde5d541094f4ce1
Author: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
Date:   Fri Nov 14 17:47:47 2008 -0500

    tracepoints: add DECLARE_TRACE() and DEFINE_TRACE()
    
    Impact: API *CHANGE*. Must update all tracepoint users.
    
    Add DEFINE_TRACE() to tracepoints to let them declare the tracepoint
    structure in a single spot for all the kernel. It helps reducing memory
    consumption, especially when declaring a lot of tracepoints, e.g. for
    kmalloc tracing.
    
    *API CHANGE WARNING*: now, DECLARE_TRACE() must be used in headers for
    tracepoint declarations rather than DEFINE_TRACE(). This is the sane way
    to do it. The name previously used was misleading.
    
    Updates scheduler instrumentation to follow this API change.
    
    Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/signal.c b/kernel/signal.c
index 4530fc654455..e9afe63da24b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -41,6 +41,8 @@
 
 static struct kmem_cache *sigqueue_cachep;
 
+DEFINE_TRACE(sched_signal_send);
+
 static void __user *sig_handler(struct task_struct *t, int sig)
 {
 	return t->sighand->action[sig - 1].sa.sa_handler;

commit d84f4f992cbd76e8f39c488cf0c5d123843923b1
Author: David Howells <dhowells@redhat.com>
Date:   Fri Nov 14 10:39:23 2008 +1100

    CRED: Inaugurate COW credentials
    
    Inaugurate copy-on-write credentials management.  This uses RCU to manage the
    credentials pointer in the task_struct with respect to accesses by other tasks.
    A process may only modify its own credentials, and so does not need locking to
    access or modify its own credentials.
    
    A mutex (cred_replace_mutex) is added to the task_struct to control the effect
    of PTRACE_ATTACHED on credential calculations, particularly with respect to
    execve().
    
    With this patch, the contents of an active credentials struct may not be
    changed directly; rather a new set of credentials must be prepared, modified
    and committed using something like the following sequence of events:
    
            struct cred *new = prepare_creds();
            int ret = blah(new);
            if (ret < 0) {
                    abort_creds(new);
                    return ret;
            }
            return commit_creds(new);
    
    There are some exceptions to this rule: the keyrings pointed to by the active
    credentials may be instantiated - keyrings violate the COW rule as managing
    COW keyrings is tricky, given that it is possible for a task to directly alter
    the keys in a keyring in use by another task.
    
    To help enforce this, various pointers to sets of credentials, such as those in
    the task_struct, are declared const.  The purpose of this is compile-time
    discouragement of altering credentials through those pointers.  Once a set of
    credentials has been made public through one of these pointers, it may not be
    modified, except under special circumstances:
    
      (1) Its reference count may incremented and decremented.
    
      (2) The keyrings to which it points may be modified, but not replaced.
    
    The only safe way to modify anything else is to create a replacement and commit
    using the functions described in Documentation/credentials.txt (which will be
    added by a later patch).
    
    This patch and the preceding patches have been tested with the LTP SELinux
    testsuite.
    
    This patch makes several logical sets of alteration:
    
     (1) execve().
    
         This now prepares and commits credentials in various places in the
         security code rather than altering the current creds directly.
    
     (2) Temporary credential overrides.
    
         do_coredump() and sys_faccessat() now prepare their own credentials and
         temporarily override the ones currently on the acting thread, whilst
         preventing interference from other threads by holding cred_replace_mutex
         on the thread being dumped.
    
         This will be replaced in a future patch by something that hands down the
         credentials directly to the functions being called, rather than altering
         the task's objective credentials.
    
     (3) LSM interface.
    
         A number of functions have been changed, added or removed:
    
         (*) security_capset_check(), ->capset_check()
         (*) security_capset_set(), ->capset_set()
    
             Removed in favour of security_capset().
    
         (*) security_capset(), ->capset()
    
             New.  This is passed a pointer to the new creds, a pointer to the old
             creds and the proposed capability sets.  It should fill in the new
             creds or return an error.  All pointers, barring the pointer to the
             new creds, are now const.
    
         (*) security_bprm_apply_creds(), ->bprm_apply_creds()
    
             Changed; now returns a value, which will cause the process to be
             killed if it's an error.
    
         (*) security_task_alloc(), ->task_alloc_security()
    
             Removed in favour of security_prepare_creds().
    
         (*) security_cred_free(), ->cred_free()
    
             New.  Free security data attached to cred->security.
    
         (*) security_prepare_creds(), ->cred_prepare()
    
             New. Duplicate any security data attached to cred->security.
    
         (*) security_commit_creds(), ->cred_commit()
    
             New. Apply any security effects for the upcoming installation of new
             security by commit_creds().
    
         (*) security_task_post_setuid(), ->task_post_setuid()
    
             Removed in favour of security_task_fix_setuid().
    
         (*) security_task_fix_setuid(), ->task_fix_setuid()
    
             Fix up the proposed new credentials for setuid().  This is used by
             cap_set_fix_setuid() to implicitly adjust capabilities in line with
             setuid() changes.  Changes are made to the new credentials, rather
             than the task itself as in security_task_post_setuid().
    
         (*) security_task_reparent_to_init(), ->task_reparent_to_init()
    
             Removed.  Instead the task being reparented to init is referred
             directly to init's credentials.
    
             NOTE!  This results in the loss of some state: SELinux's osid no
             longer records the sid of the thread that forked it.
    
         (*) security_key_alloc(), ->key_alloc()
         (*) security_key_permission(), ->key_permission()
    
             Changed.  These now take cred pointers rather than task pointers to
             refer to the security context.
    
     (4) sys_capset().
    
         This has been simplified and uses less locking.  The LSM functions it
         calls have been merged.
    
     (5) reparent_to_kthreadd().
    
         This gives the current thread the same credentials as init by simply using
         commit_thread() to point that way.
    
     (6) __sigqueue_alloc() and switch_uid()
    
         __sigqueue_alloc() can't stop the target task from changing its creds
         beneath it, so this function gets a reference to the currently applicable
         user_struct which it then passes into the sigqueue struct it returns if
         successful.
    
         switch_uid() is now called from commit_creds(), and possibly should be
         folded into that.  commit_creds() should take care of protecting
         __sigqueue_alloc().
    
     (7) [sg]et[ug]id() and co and [sg]et_current_groups.
    
         The set functions now all use prepare_creds(), commit_creds() and
         abort_creds() to build and check a new set of credentials before applying
         it.
    
         security_task_set[ug]id() is called inside the prepared section.  This
         guarantees that nothing else will affect the creds until we've finished.
    
         The calling of set_dumpable() has been moved into commit_creds().
    
         Much of the functionality of set_user() has been moved into
         commit_creds().
    
         The get functions all simply access the data directly.
    
     (8) security_task_prctl() and cap_task_prctl().
    
         security_task_prctl() has been modified to return -ENOSYS if it doesn't
         want to handle a function, or otherwise return the return value directly
         rather than through an argument.
    
         Additionally, cap_task_prctl() now prepares a new set of credentials, even
         if it doesn't end up using it.
    
     (9) Keyrings.
    
         A number of changes have been made to the keyrings code:
    
         (a) switch_uid_keyring(), copy_keys(), exit_keys() and suid_keys() have
             all been dropped and built in to the credentials functions directly.
             They may want separating out again later.
    
         (b) key_alloc() and search_process_keyrings() now take a cred pointer
             rather than a task pointer to specify the security context.
    
         (c) copy_creds() gives a new thread within the same thread group a new
             thread keyring if its parent had one, otherwise it discards the thread
             keyring.
    
         (d) The authorisation key now points directly to the credentials to extend
             the search into rather pointing to the task that carries them.
    
         (e) Installing thread, process or session keyrings causes a new set of
             credentials to be created, even though it's not strictly necessary for
             process or session keyrings (they're shared).
    
    (10) Usermode helper.
    
         The usermode helper code now carries a cred struct pointer in its
         subprocess_info struct instead of a new session keyring pointer.  This set
         of credentials is derived from init_cred and installed on the new process
         after it has been cloned.
    
         call_usermodehelper_setup() allocates the new credentials and
         call_usermodehelper_freeinfo() discards them if they haven't been used.  A
         special cred function (prepare_usermodeinfo_creds()) is provided
         specifically for call_usermodehelper_setup() to call.
    
         call_usermodehelper_setkeys() adjusts the credentials to sport the
         supplied keyring as the new session keyring.
    
    (11) SELinux.
    
         SELinux has a number of changes, in addition to those to support the LSM
         interface changes mentioned above:
    
         (a) selinux_setprocattr() no longer does its check for whether the
             current ptracer can access processes with the new SID inside the lock
             that covers getting the ptracer's SID.  Whilst this lock ensures that
             the check is done with the ptracer pinned, the result is only valid
             until the lock is released, so there's no point doing it inside the
             lock.
    
    (12) is_single_threaded().
    
         This function has been extracted from selinux_setprocattr() and put into
         a file of its own in the lib/ directory as join_session_keyring() now
         wants to use it too.
    
         The code in SELinux just checked to see whether a task shared mm_structs
         with other tasks (CLONE_VM), but that isn't good enough.  We really want
         to know if they're part of the same thread group (CLONE_THREAD).
    
    (13) nfsd.
    
         The NFS server daemon now has to use the COW credentials to set the
         credentials it is going to use.  It really needs to pass the credentials
         down to the functions it calls, but it can't do that until other patches
         in this series have been applied.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: James Morris <jmorris@namei.org>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 84989124bafb..2a64304ed54b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -180,7 +180,7 @@ int next_signal(struct sigpending *pending, sigset_t *mask)
 /*
  * allocate a new signal queue record
  * - this may be called without locks if and only if t == current, otherwise an
- *   appopriate lock must be held to protect t's user_struct
+ *   appopriate lock must be held to stop the target task from exiting
  */
 static struct sigqueue *__sigqueue_alloc(struct task_struct *t, gfp_t flags,
 					 int override_rlimit)
@@ -194,7 +194,7 @@ static struct sigqueue *__sigqueue_alloc(struct task_struct *t, gfp_t flags,
 	 * caller must be holding the RCU readlock (by way of a spinlock) and
 	 * we use RCU protection here
 	 */
-	user = __task_cred(t)->user;
+	user = get_uid(__task_cred(t)->user);
 	atomic_inc(&user->sigpending);
 	if (override_rlimit ||
 	    atomic_read(&user->sigpending) <=
@@ -202,12 +202,14 @@ static struct sigqueue *__sigqueue_alloc(struct task_struct *t, gfp_t flags,
 		q = kmem_cache_alloc(sigqueue_cachep, flags);
 	if (unlikely(q == NULL)) {
 		atomic_dec(&user->sigpending);
+		free_uid(user);
 	} else {
 		INIT_LIST_HEAD(&q->list);
 		q->flags = 0;
-		q->user = get_uid(user);
+		q->user = user;
 	}
-	return(q);
+
+	return q;
 }
 
 static void __sigqueue_free(struct sigqueue *q)

commit c69e8d9c01db2adc503464993c358901c9af9de4
Author: David Howells <dhowells@redhat.com>
Date:   Fri Nov 14 10:39:19 2008 +1100

    CRED: Use RCU to access another task's creds and to release a task's own creds
    
    Use RCU to access another task's creds and to release a task's own creds.
    This means that it will be possible for the credentials of a task to be
    replaced without another task (a) requiring a full lock to read them, and (b)
    seeing deallocated memory.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: James Morris <jmorris@namei.org>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 80e8a6489f97..84989124bafb 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -177,6 +177,11 @@ int next_signal(struct sigpending *pending, sigset_t *mask)
 	return sig;
 }
 
+/*
+ * allocate a new signal queue record
+ * - this may be called without locks if and only if t == current, otherwise an
+ *   appopriate lock must be held to protect t's user_struct
+ */
 static struct sigqueue *__sigqueue_alloc(struct task_struct *t, gfp_t flags,
 					 int override_rlimit)
 {
@@ -184,11 +189,12 @@ static struct sigqueue *__sigqueue_alloc(struct task_struct *t, gfp_t flags,
 	struct user_struct *user;
 
 	/*
-	 * In order to avoid problems with "switch_user()", we want to make
-	 * sure that the compiler doesn't re-load "t->user"
+	 * We won't get problems with the target's UID changing under us
+	 * because changing it requires RCU be used, and if t != current, the
+	 * caller must be holding the RCU readlock (by way of a spinlock) and
+	 * we use RCU protection here
 	 */
-	user = t->cred->user;
-	barrier();
+	user = __task_cred(t)->user;
 	atomic_inc(&user->sigpending);
 	if (override_rlimit ||
 	    atomic_read(&user->sigpending) <=
@@ -562,12 +568,13 @@ static int rm_from_queue(unsigned long mask, struct sigpending *s)
 
 /*
  * Bad permissions for sending the signal
+ * - the caller must hold at least the RCU read lock
  */
 static int check_kill_permission(int sig, struct siginfo *info,
 				 struct task_struct *t)
 {
+	const struct cred *cred = current_cred(), *tcred;
 	struct pid *sid;
-	uid_t uid, euid;
 	int error;
 
 	if (!valid_signal(sig))
@@ -580,10 +587,11 @@ static int check_kill_permission(int sig, struct siginfo *info,
 	if (error)
 		return error;
 
-	uid = current_uid();
-	euid = current_euid();
-	if ((euid ^ t->cred->suid) && (euid ^ t->cred->uid) &&
-	    (uid  ^ t->cred->suid) && (uid  ^ t->cred->uid) &&
+	tcred = __task_cred(t);
+	if ((cred->euid ^ tcred->suid) &&
+	    (cred->euid ^ tcred->uid) &&
+	    (cred->uid  ^ tcred->suid) &&
+	    (cred->uid  ^ tcred->uid) &&
 	    !capable(CAP_KILL)) {
 		switch (sig) {
 		case SIGCONT:
@@ -1011,6 +1019,10 @@ struct sighand_struct *lock_task_sighand(struct task_struct *tsk, unsigned long
 	return sighand;
 }
 
+/*
+ * send signal info to all the members of a group
+ * - the caller must hold the RCU read lock at least
+ */
 int group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 {
 	unsigned long flags;
@@ -1032,8 +1044,8 @@ int group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 /*
  * __kill_pgrp_info() sends a signal to a process group: this is what the tty
  * control characters do (^C, ^Z etc)
+ * - the caller must hold at least a readlock on tasklist_lock
  */
-
 int __kill_pgrp_info(int sig, struct siginfo *info, struct pid *pgrp)
 {
 	struct task_struct *p = NULL;
@@ -1089,6 +1101,7 @@ int kill_pid_info_as_uid(int sig, struct siginfo *info, struct pid *pid,
 {
 	int ret = -EINVAL;
 	struct task_struct *p;
+	const struct cred *pcred;
 
 	if (!valid_signal(sig))
 		return ret;
@@ -1099,9 +1112,11 @@ int kill_pid_info_as_uid(int sig, struct siginfo *info, struct pid *pid,
 		ret = -ESRCH;
 		goto out_unlock;
 	}
-	if ((info == SEND_SIG_NOINFO || (!is_si_special(info) && SI_FROMUSER(info)))
-	    && (euid != p->cred->suid) && (euid != p->cred->uid)
-	    && (uid != p->cred->suid) && (uid != p->cred->uid)) {
+	pcred = __task_cred(p);
+	if ((info == SEND_SIG_NOINFO ||
+	     (!is_si_special(info) && SI_FROMUSER(info))) &&
+	    euid != pcred->suid && euid != pcred->uid &&
+	    uid  != pcred->suid && uid  != pcred->uid) {
 		ret = -EPERM;
 		goto out_unlock;
 	}
@@ -1372,10 +1387,9 @@ int do_notify_parent(struct task_struct *tsk, int sig)
 	 */
 	rcu_read_lock();
 	info.si_pid = task_pid_nr_ns(tsk, tsk->parent->nsproxy->pid_ns);
+	info.si_uid = __task_cred(tsk)->uid;
 	rcu_read_unlock();
 
-	info.si_uid = tsk->cred->uid;
-
 	thread_group_cputime(tsk, &cputime);
 	info.si_utime = cputime_to_jiffies(cputime.utime);
 	info.si_stime = cputime_to_jiffies(cputime.stime);
@@ -1443,10 +1457,9 @@ static void do_notify_parent_cldstop(struct task_struct *tsk, int why)
 	 */
 	rcu_read_lock();
 	info.si_pid = task_pid_nr_ns(tsk, tsk->parent->nsproxy->pid_ns);
+	info.si_uid = __task_cred(tsk)->uid;
 	rcu_read_unlock();
 
-	info.si_uid = tsk->cred->uid;
-
 	info.si_utime = cputime_to_clock_t(tsk->utime);
 	info.si_stime = cputime_to_clock_t(tsk->stime);
 
@@ -1713,7 +1726,7 @@ static int ptrace_signal(int signr, siginfo_t *info,
 		info->si_errno = 0;
 		info->si_code = SI_USER;
 		info->si_pid = task_pid_vnr(current->parent);
-		info->si_uid = current->parent->cred->uid;
+		info->si_uid = task_uid(current->parent);
 	}
 
 	/* If the (new) signal is now blocked, requeue it.  */

commit b6dff3ec5e116e3af6f537d4caedcad6b9e5082a
Author: David Howells <dhowells@redhat.com>
Date:   Fri Nov 14 10:39:16 2008 +1100

    CRED: Separate task security context from task_struct
    
    Separate the task security context from task_struct.  At this point, the
    security data is temporarily embedded in the task_struct with two pointers
    pointing to it.
    
    Note that the Alpha arch is altered as it refers to (E)UID and (E)GID in
    entry.S via asm-offsets.
    
    With comment fixes Signed-off-by: Marc Dionne <marc.c.dionne@gmail.com>
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: James Morris <jmorris@namei.org>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 167b535fe1a9..80e8a6489f97 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -187,7 +187,7 @@ static struct sigqueue *__sigqueue_alloc(struct task_struct *t, gfp_t flags,
 	 * In order to avoid problems with "switch_user()", we want to make
 	 * sure that the compiler doesn't re-load "t->user"
 	 */
-	user = t->user;
+	user = t->cred->user;
 	barrier();
 	atomic_inc(&user->sigpending);
 	if (override_rlimit ||
@@ -582,8 +582,8 @@ static int check_kill_permission(int sig, struct siginfo *info,
 
 	uid = current_uid();
 	euid = current_euid();
-	if ((euid ^ t->suid) && (euid ^ t->uid) &&
-	    (uid  ^ t->suid) && (uid  ^ t->uid) &&
+	if ((euid ^ t->cred->suid) && (euid ^ t->cred->uid) &&
+	    (uid  ^ t->cred->suid) && (uid  ^ t->cred->uid) &&
 	    !capable(CAP_KILL)) {
 		switch (sig) {
 		case SIGCONT:
@@ -1100,8 +1100,8 @@ int kill_pid_info_as_uid(int sig, struct siginfo *info, struct pid *pid,
 		goto out_unlock;
 	}
 	if ((info == SEND_SIG_NOINFO || (!is_si_special(info) && SI_FROMUSER(info)))
-	    && (euid != p->suid) && (euid != p->uid)
-	    && (uid != p->suid) && (uid != p->uid)) {
+	    && (euid != p->cred->suid) && (euid != p->cred->uid)
+	    && (uid != p->cred->suid) && (uid != p->cred->uid)) {
 		ret = -EPERM;
 		goto out_unlock;
 	}
@@ -1374,7 +1374,7 @@ int do_notify_parent(struct task_struct *tsk, int sig)
 	info.si_pid = task_pid_nr_ns(tsk, tsk->parent->nsproxy->pid_ns);
 	rcu_read_unlock();
 
-	info.si_uid = tsk->uid;
+	info.si_uid = tsk->cred->uid;
 
 	thread_group_cputime(tsk, &cputime);
 	info.si_utime = cputime_to_jiffies(cputime.utime);
@@ -1445,7 +1445,7 @@ static void do_notify_parent_cldstop(struct task_struct *tsk, int why)
 	info.si_pid = task_pid_nr_ns(tsk, tsk->parent->nsproxy->pid_ns);
 	rcu_read_unlock();
 
-	info.si_uid = tsk->uid;
+	info.si_uid = tsk->cred->uid;
 
 	info.si_utime = cputime_to_clock_t(tsk->utime);
 	info.si_stime = cputime_to_clock_t(tsk->stime);
@@ -1713,7 +1713,7 @@ static int ptrace_signal(int signr, siginfo_t *info,
 		info->si_errno = 0;
 		info->si_code = SI_USER;
 		info->si_pid = task_pid_vnr(current->parent);
-		info->si_uid = current->parent->uid;
+		info->si_uid = current->parent->cred->uid;
 	}
 
 	/* If the (new) signal is now blocked, requeue it.  */

commit 76aac0e9a17742e60d408be1a706e9aaad370891
Author: David Howells <dhowells@redhat.com>
Date:   Fri Nov 14 10:39:12 2008 +1100

    CRED: Wrap task credential accesses in the core kernel
    
    Wrap access to task credentials so that they can be separated more easily from
    the task_struct during the introduction of COW creds.
    
    Change most current->(|e|s|fs)[ug]id to current_(|e|s|fs)[ug]id().
    
    Change some task->e?[ug]id to task_e?[ug]id().  In some places it makes more
    sense to use RCU directly rather than a convenient wrapper; these will be
    addressed by later patches.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Reviewed-by: James Morris <jmorris@namei.org>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: linux-audit@redhat.com
    Cc: containers@lists.linux-foundation.org
    Cc: linux-mm@kvack.org
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 4530fc654455..167b535fe1a9 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -567,6 +567,7 @@ static int check_kill_permission(int sig, struct siginfo *info,
 				 struct task_struct *t)
 {
 	struct pid *sid;
+	uid_t uid, euid;
 	int error;
 
 	if (!valid_signal(sig))
@@ -579,8 +580,10 @@ static int check_kill_permission(int sig, struct siginfo *info,
 	if (error)
 		return error;
 
-	if ((current->euid ^ t->suid) && (current->euid ^ t->uid) &&
-	    (current->uid  ^ t->suid) && (current->uid  ^ t->uid) &&
+	uid = current_uid();
+	euid = current_euid();
+	if ((euid ^ t->suid) && (euid ^ t->uid) &&
+	    (uid  ^ t->suid) && (uid  ^ t->uid) &&
 	    !capable(CAP_KILL)) {
 		switch (sig) {
 		case SIGCONT:
@@ -844,7 +847,7 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			q->info.si_errno = 0;
 			q->info.si_code = SI_USER;
 			q->info.si_pid = task_pid_vnr(current);
-			q->info.si_uid = current->uid;
+			q->info.si_uid = current_uid();
 			break;
 		case (unsigned long) SEND_SIG_PRIV:
 			q->info.si_signo = sig;
@@ -1598,7 +1601,7 @@ void ptrace_notify(int exit_code)
 	info.si_signo = SIGTRAP;
 	info.si_code = exit_code;
 	info.si_pid = task_pid_vnr(current);
-	info.si_uid = current->uid;
+	info.si_uid = current_uid();
 
 	/* Let the debugger run.  */
 	spin_lock_irq(&current->sighand->siglock);
@@ -2211,7 +2214,7 @@ sys_kill(pid_t pid, int sig)
 	info.si_errno = 0;
 	info.si_code = SI_USER;
 	info.si_pid = task_tgid_vnr(current);
-	info.si_uid = current->uid;
+	info.si_uid = current_uid();
 
 	return kill_something_info(sig, &info, pid);
 }
@@ -2228,7 +2231,7 @@ static int do_tkill(pid_t tgid, pid_t pid, int sig)
 	info.si_errno = 0;
 	info.si_code = SI_TKILL;
 	info.si_pid = task_tgid_vnr(current);
-	info.si_uid = current->uid;
+	info.si_uid = current_uid();
 
 	rcu_read_lock();
 	p = find_task_by_vpid(pid);

commit d25141a818383b3c3b09f065698c544a7a0ec6e7
Author: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
Date:   Wed Oct 29 14:01:11 2008 -0700

    'kill sig -1' must only apply to caller's namespace
    
    Currently "kill <sig> -1" kills processes in all namespaces and breaks the
    isolation of namespaces.  Earlier attempt to fix this was discussed at:
    
            http://lkml.org/lkml/2008/7/23/148
    
    As suggested by Oleg Nesterov in that thread, use "task_pid_vnr() > 1"
    check since task_pid_vnr() returns 0 if process is outside the caller's
    namespace.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Acked-by: Eric W. Biederman <ebiederm@xmission.com>
    Tested-by: Daniel Hokka Zakrisson <daniel@hozac.com>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 105217da5c82..4530fc654455 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1144,7 +1144,8 @@ static int kill_something_info(int sig, struct siginfo *info, pid_t pid)
 		struct task_struct * p;
 
 		for_each_process(p) {
-			if (p->pid > 1 && !same_thread_group(p, current)) {
+			if (task_pid_vnr(p) > 1 &&
+					!same_thread_group(p, current)) {
 				int err = group_send_sig_info(sig, info, p);
 				++count;
 				if (err != -EPERM)

commit 92b29b86fe2e183d44eb467e5e74a5f718ef2e43
Merge: b9d7ccf56be1 98d9c66ab074
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Oct 20 13:35:07 2008 -0700

    Merge branch 'tracing-v28-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'tracing-v28-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (131 commits)
      tracing/fastboot: improve help text
      tracing/stacktrace: improve help text
      tracing/fastboot: fix initcalls disposition in bootgraph.pl
      tracing/fastboot: fix bootgraph.pl initcall name regexp
      tracing/fastboot: fix issues and improve output of bootgraph.pl
      tracepoints: synchronize unregister static inline
      tracepoints: tracepoint_synchronize_unregister()
      ftrace: make ftrace_test_p6nop disassembler-friendly
      markers: fix synchronize marker unregister static inline
      tracing/fastboot: add better resolution to initcall debug/tracing
      trace: add build-time check to avoid overrunning hex buffer
      ftrace: fix hex output mode of ftrace
      tracing/fastboot: fix initcalls disposition in bootgraph.pl
      tracing/fastboot: fix printk format typo in boot tracer
      ftrace: return an error when setting a nonexistent tracer
      ftrace: make some tracers reentrant
      ring-buffer: make reentrant
      ring-buffer: move page indexes into page headers
      tracing/fastboot: only trace non-module initcalls
      ftrace: move pc counter in irqtrace
      ...
    
    Manually fix conflicts:
     - init/main.c: initcall tracing
     - kernel/module.c: verbose level vs tracepoints
     - scripts/bootgraph.pl: fallout from cherry-picking commits.

commit 0a16b6075843325dc402edf80c1662838b929aff
Author: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
Date:   Fri Jul 18 12:16:17 2008 -0400

    tracing, sched: LTTng instrumentation - scheduler
    
    Instrument the scheduler activity (sched_switch, migration, wakeups,
    wait for a task, signal delivery) and process/thread
    creation/destruction (fork, exit, kthread stop). Actually, kthread
    creation is not instrumented in this patch because it is architecture
    dependent. It allows to connect tracers such as ftrace which detects
    scheduling latencies, good/bad scheduler decisions. Tools like LTTng can
    export this scheduler information along with instrumentation of the rest
    of the kernel activity to perform post-mortem analysis on the scheduler
    activity.
    
    About the performance impact of tracepoints (which is comparable to
    markers), even without immediate values optimizations, tests done by
    Hideo Aoki on ia64 show no regression. His test case was using hackbench
    on a kernel where scheduler instrumentation (about 5 events in code
    scheduler code) was added. See the "Tracepoints" patch header for
    performance result detail.
    
    Changelog :
    
    - Change instrumentation location and parameter to match ftrace
      instrumentation, previously done with kernel markers.
    
    [ mingo@elte.hu: conflict resolutions ]
    Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
    Acked-by: 'Peter Zijlstra' <peterz@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/signal.c b/kernel/signal.c
index e661b01d340f..bf40ecc87b26 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -27,6 +27,7 @@
 #include <linux/freezer.h>
 #include <linux/pid_namespace.h>
 #include <linux/nsproxy.h>
+#include <trace/sched.h>
 
 #include <asm/param.h>
 #include <asm/uaccess.h>
@@ -803,6 +804,8 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	struct sigpending *pending;
 	struct sigqueue *q;
 
+	trace_sched_signal_send(sig, t);
+
 	assert_spin_locked(&t->sighand->siglock);
 	if (!prepare_signal(sig, t))
 		return 0;

commit f06febc96ba8e0af80bcc3eaec0a109e88275fac
Author: Frank Mayhar <fmayhar@google.com>
Date:   Fri Sep 12 09:54:39 2008 -0700

    timers: fix itimer/many thread hang
    
    Overview
    
    This patch reworks the handling of POSIX CPU timers, including the
    ITIMER_PROF, ITIMER_VIRT timers and rlimit handling.  It was put together
    with the help of Roland McGrath, the owner and original writer of this code.
    
    The problem we ran into, and the reason for this rework, has to do with using
    a profiling timer in a process with a large number of threads.  It appears
    that the performance of the old implementation of run_posix_cpu_timers() was
    at least O(n*3) (where "n" is the number of threads in a process) or worse.
    Everything is fine with an increasing number of threads until the time taken
    for that routine to run becomes the same as or greater than the tick time, at
    which point things degrade rather quickly.
    
    This patch fixes bug 9906, "Weird hang with NPTL and SIGPROF."
    
    Code Changes
    
    This rework corrects the implementation of run_posix_cpu_timers() to make it
    run in constant time for a particular machine.  (Performance may vary between
    one machine and another depending upon whether the kernel is built as single-
    or multiprocessor and, in the latter case, depending upon the number of
    running processors.)  To do this, at each tick we now update fields in
    signal_struct as well as task_struct.  The run_posix_cpu_timers() function
    uses those fields to make its decisions.
    
    We define a new structure, "task_cputime," to contain user, system and
    scheduler times and use these in appropriate places:
    
    struct task_cputime {
            cputime_t utime;
            cputime_t stime;
            unsigned long long sum_exec_runtime;
    };
    
    This is included in the structure "thread_group_cputime," which is a new
    substructure of signal_struct and which varies for uniprocessor versus
    multiprocessor kernels.  For uniprocessor kernels, it uses "task_cputime" as
    a simple substructure, while for multiprocessor kernels it is a pointer:
    
    struct thread_group_cputime {
            struct task_cputime totals;
    };
    
    struct thread_group_cputime {
            struct task_cputime *totals;
    };
    
    We also add a new task_cputime substructure directly to signal_struct, to
    cache the earliest expiration of process-wide timers, and task_cputime also
    replaces the it_*_expires fields of task_struct (used for earliest expiration
    of thread timers).  The "thread_group_cputime" structure contains process-wide
    timers that are updated via account_user_time() and friends.  In the non-SMP
    case the structure is a simple aggregator; unfortunately in the SMP case that
    simplicity was not achievable due to cache-line contention between CPUs (in
    one measured case performance was actually _worse_ on a 16-cpu system than
    the same test on a 4-cpu system, due to this contention).  For SMP, the
    thread_group_cputime counters are maintained as a per-cpu structure allocated
    using alloc_percpu().  The timer functions update only the timer field in
    the structure corresponding to the running CPU, obtained using per_cpu_ptr().
    
    We define a set of inline functions in sched.h that we use to maintain the
    thread_group_cputime structure and hide the differences between UP and SMP
    implementations from the rest of the kernel.  The thread_group_cputime_init()
    function initializes the thread_group_cputime structure for the given task.
    The thread_group_cputime_alloc() is a no-op for UP; for SMP it calls the
    out-of-line function thread_group_cputime_alloc_smp() to allocate and fill
    in the per-cpu structures and fields.  The thread_group_cputime_free()
    function, also a no-op for UP, in SMP frees the per-cpu structures.  The
    thread_group_cputime_clone_thread() function (also a UP no-op) for SMP calls
    thread_group_cputime_alloc() if the per-cpu structures haven't yet been
    allocated.  The thread_group_cputime() function fills the task_cputime
    structure it is passed with the contents of the thread_group_cputime fields;
    in UP it's that simple but in SMP it must also safely check that tsk->signal
    is non-NULL (if it is it just uses the appropriate fields of task_struct) and,
    if so, sums the per-cpu values for each online CPU.  Finally, the three
    functions account_group_user_time(), account_group_system_time() and
    account_group_exec_runtime() are used by timer functions to update the
    respective fields of the thread_group_cputime structure.
    
    Non-SMP operation is trivial and will not be mentioned further.
    
    The per-cpu structure is always allocated when a task creates its first new
    thread, via a call to thread_group_cputime_clone_thread() from copy_signal().
    It is freed at process exit via a call to thread_group_cputime_free() from
    cleanup_signal().
    
    All functions that formerly summed utime/stime/sum_sched_runtime values from
    from all threads in the thread group now use thread_group_cputime() to
    snapshot the values in the thread_group_cputime structure or the values in
    the task structure itself if the per-cpu structure hasn't been allocated.
    
    Finally, the code in kernel/posix-cpu-timers.c has changed quite a bit.
    The run_posix_cpu_timers() function has been split into a fast path and a
    slow path; the former safely checks whether there are any expired thread
    timers and, if not, just returns, while the slow path does the heavy lifting.
    With the dedicated thread group fields, timers are no longer "rebalanced" and
    the process_timer_rebalance() function and related code has gone away.  All
    summing loops are gone and all code that used them now uses the
    thread_group_cputime() inline.  When process-wide timers are set, the new
    task_cputime structure in signal_struct is used to cache the earliest
    expiration; this is checked in the fast path.
    
    Performance
    
    The fix appears not to add significant overhead to existing operations.  It
    generally performs the same as the current code except in two cases, one in
    which it performs slightly worse (Case 5 below) and one in which it performs
    very significantly better (Case 2 below).  Overall it's a wash except in those
    two cases.
    
    I've since done somewhat more involved testing on a dual-core Opteron system.
    
    Case 1: With no itimer running, for a test with 100,000 threads, the fixed
            kernel took 1428.5 seconds, 513 seconds more than the unfixed system,
            all of which was spent in the system.  There were twice as many
            voluntary context switches with the fix as without it.
    
    Case 2: With an itimer running at .01 second ticks and 4000 threads (the most
            an unmodified kernel can handle), the fixed kernel ran the test in
            eight percent of the time (5.8 seconds as opposed to 70 seconds) and
            had better tick accuracy (.012 seconds per tick as opposed to .023
            seconds per tick).
    
    Case 3: A 4000-thread test with an initial timer tick of .01 second and an
            interval of 10,000 seconds (i.e. a timer that ticks only once) had
            very nearly the same performance in both cases:  6.3 seconds elapsed
            for the fixed kernel versus 5.5 seconds for the unfixed kernel.
    
    With fewer threads (eight in these tests), the Case 1 test ran in essentially
    the same time on both the modified and unmodified kernels (5.2 seconds versus
    5.8 seconds).  The Case 2 test ran in about the same time as well, 5.9 seconds
    versus 5.4 seconds but again with much better tick accuracy, .013 seconds per
    tick versus .025 seconds per tick for the unmodified kernel.
    
    Since the fix affected the rlimit code, I also tested soft and hard CPU limits.
    
    Case 4: With a hard CPU limit of 20 seconds and eight threads (and an itimer
            running), the modified kernel was very slightly favored in that while
            it killed the process in 19.997 seconds of CPU time (5.002 seconds of
            wall time), only .003 seconds of that was system time, the rest was
            user time.  The unmodified kernel killed the process in 20.001 seconds
            of CPU (5.014 seconds of wall time) of which .016 seconds was system
            time.  Really, though, the results were too close to call.  The results
            were essentially the same with no itimer running.
    
    Case 5: With a soft limit of 20 seconds and a hard limit of 2000 seconds
            (where the hard limit would never be reached) and an itimer running,
            the modified kernel exhibited worse tick accuracy than the unmodified
            kernel: .050 seconds/tick versus .028 seconds/tick.  Otherwise,
            performance was almost indistinguishable.  With no itimer running this
            test exhibited virtually identical behavior and times in both cases.
    
    In times past I did some limited performance testing.  those results are below.
    
    On a four-cpu Opteron system without this fix, a sixteen-thread test executed
    in 3569.991 seconds, of which user was 3568.435s and system was 1.556s.  On
    the same system with the fix, user and elapsed time were about the same, but
    system time dropped to 0.007 seconds.  Performance with eight, four and one
    thread were comparable.  Interestingly, the timer ticks with the fix seemed
    more accurate:  The sixteen-thread test with the fix received 149543 ticks
    for 0.024 seconds per tick, while the same test without the fix received 58720
    for 0.061 seconds per tick.  Both cases were configured for an interval of
    0.01 seconds.  Again, the other tests were comparable.  Each thread in this
    test computed the primes up to 25,000,000.
    
    I also did a test with a large number of threads, 100,000 threads, which is
    impossible without the fix.  In this case each thread computed the primes only
    up to 10,000 (to make the runtime manageable).  System time dominated, at
    1546.968 seconds out of a total 2176.906 seconds (giving a user time of
    629.938s).  It received 147651 ticks for 0.015 seconds per tick, still quite
    accurate.  There is obviously no comparable test without the fix.
    
    Signed-off-by: Frank Mayhar <fmayhar@google.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Alexey Dobriyan <adobriyan@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/signal.c b/kernel/signal.c
index e661b01d340f..6eea5826d618 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1338,6 +1338,7 @@ int do_notify_parent(struct task_struct *tsk, int sig)
 	struct siginfo info;
 	unsigned long flags;
 	struct sighand_struct *psig;
+	struct task_cputime cputime;
 	int ret = sig;
 
 	BUG_ON(sig == -1);
@@ -1368,10 +1369,9 @@ int do_notify_parent(struct task_struct *tsk, int sig)
 
 	info.si_uid = tsk->uid;
 
-	info.si_utime = cputime_to_clock_t(cputime_add(tsk->utime,
-						       tsk->signal->utime));
-	info.si_stime = cputime_to_clock_t(cputime_add(tsk->stime,
-						       tsk->signal->stime));
+	thread_group_cputime(tsk, &cputime);
+	info.si_utime = cputime_to_jiffies(cputime.utime);
+	info.si_stime = cputime_to_jiffies(cputime.stime);
 
 	info.si_status = tsk->exit_code & 0x7f;
 	if (tsk->exit_code & 0x80)

commit 1b04624f93bb1c4f9495b8476d1dd0200af019e2
Author: Roland McGrath <roland@redhat.com>
Date:   Tue Aug 19 20:37:07 2008 -0700

    tracehook: fix SA_NOCLDWAIT
    
    I outwitted myself again in commit 2b2a1ff64afbadac842bbc58c5166962cf4f7664,
    and broke the SA_NOCLDWAIT behavior so it leaks zombies.  This fixes it.
    
    Reported-by: Andi Kleen <andi@firstfloor.org>
    Signed-off-by: Roland McGrath <roland@redhat.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index c539f60c6f41..e661b01d340f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1338,6 +1338,7 @@ int do_notify_parent(struct task_struct *tsk, int sig)
 	struct siginfo info;
 	unsigned long flags;
 	struct sighand_struct *psig;
+	int ret = sig;
 
 	BUG_ON(sig == -1);
 
@@ -1402,7 +1403,7 @@ int do_notify_parent(struct task_struct *tsk, int sig)
 		 * is implementation-defined: we do (if you don't want
 		 * it, just use SIG_IGN instead).
 		 */
-		tsk->exit_signal = -1;
+		ret = tsk->exit_signal = -1;
 		if (psig->action[SIGCHLD-1].sa.sa_handler == SIG_IGN)
 			sig = -1;
 	}
@@ -1411,7 +1412,7 @@ int do_notify_parent(struct task_struct *tsk, int sig)
 	__wake_up_parent(tsk, tsk->parent);
 	spin_unlock_irqrestore(&psig->siglock, flags);
 
-	return sig;
+	return ret;
 }
 
 static void do_notify_parent_cldstop(struct task_struct *tsk, int why)

commit 67a077dca4e648a662e32cbeaaba8094d2e30229
Merge: 9b4d0bab32e1 2106b531eaa2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Aug 11 16:46:11 2008 -0700

    Merge branch 'timers-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'timers-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      posix-timers: fix posix_timer_event() vs dequeue_signal() race
      posix-timers: do_schedule_next_timer: fix the setting of ->si_overrun

commit 2106b531eaa2edd0c2dfa735a0556c08c7ba3c86
Merge: e338125b8a88 ba661292a2bc
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Jul 27 23:15:26 2008 +0200

    Merge branch 'timers/urgent' of ssh://master.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip into timers/urgent

commit b787f7ba677840da16a2228c16571ce8a1fcb799
Author: Roland McGrath <roland@redhat.com>
Date:   Fri Jul 25 19:45:55 2008 -0700

    tracehook: force signal_pending()
    
    This defines a new hook tracehook_force_sigpending() that lets tracing
    code decide to force TIF_SIGPENDING on in recalc_sigpending().
    
    This is not used yet, so it compiles away to nothing for now.  It lays the
    groundwork for new tracing code that can interrupt a task synthetically
    without actually sending a signal.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0e862d3130ff..954f77d7e3bc 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -134,7 +134,9 @@ void recalc_sigpending_and_wake(struct task_struct *t)
 
 void recalc_sigpending(void)
 {
-	if (!recalc_sigpending_tsk(current) && !freezing(current))
+	if (unlikely(tracehook_force_sigpending()))
+		set_thread_flag(TIF_SIGPENDING);
+	else if (!recalc_sigpending_tsk(current) && !freezing(current))
 		clear_thread_flag(TIF_SIGPENDING);
 
 }

commit 2b2a1ff64afbadac842bbc58c5166962cf4f7664
Author: Roland McGrath <roland@redhat.com>
Date:   Fri Jul 25 19:45:54 2008 -0700

    tracehook: death
    
    This moves the ptrace logic in task death (exit_notify) into tracehook.h
    inlines.  Some code is rearranged slightly to make things nicer.  There is
    no change, only cleanup.
    
    There is one hook called with the tasklist_lock write-locked, as ptrace
    needs.  There is also a new hook called after exit_state changes and
    without locks.  This is a better place for tracing work to be in the
    future, since it doesn't delay the whole system with locking.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index e9e699f4b1bd..0e862d3130ff 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1326,9 +1326,11 @@ static inline void __wake_up_parent(struct task_struct *p,
 /*
  * Let a parent know about the death of a child.
  * For a stopped/continued status change, use do_notify_parent_cldstop instead.
+ *
+ * Returns -1 if our parent ignored us and so we've switched to
+ * self-reaping, or else @sig.
  */
-
-void do_notify_parent(struct task_struct *tsk, int sig)
+int do_notify_parent(struct task_struct *tsk, int sig)
 {
 	struct siginfo info;
 	unsigned long flags;
@@ -1399,12 +1401,14 @@ void do_notify_parent(struct task_struct *tsk, int sig)
 		 */
 		tsk->exit_signal = -1;
 		if (psig->action[SIGCHLD-1].sa.sa_handler == SIG_IGN)
-			sig = 0;
+			sig = -1;
 	}
 	if (valid_signal(sig) && sig > 0)
 		__group_send_sig_info(sig, &info, tsk->parent);
 	__wake_up_parent(tsk, tsk->parent);
 	spin_unlock_irqrestore(&psig->siglock, flags);
+
+	return sig;
 }
 
 static void do_notify_parent_cldstop(struct task_struct *tsk, int why)

commit fa00b80b3c41a845b3d56f866fb40a2e98754c51
Author: Roland McGrath <roland@redhat.com>
Date:   Fri Jul 25 19:45:54 2008 -0700

    tracehook: job control
    
    This defines the tracehook_notify_jctl() hook to formalize the ptrace
    effects on the job control notifications.  There is no change, only
    cleanup.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 10b31ecdd9c8..e9e699f4b1bd 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -596,9 +596,6 @@ static int check_kill_permission(int sig, struct siginfo *info,
 	return security_task_kill(t, info, sig, 0);
 }
 
-/* forward decl */
-static void do_notify_parent_cldstop(struct task_struct *tsk, int why);
-
 /*
  * Handle magic process-wide effects of stop/continue signals. Unlike
  * the signal actions, these happen immediately at signal-generation
@@ -1605,7 +1602,7 @@ finish_stop(int stop_count)
 	 * a group stop in progress and we are the last to stop,
 	 * report to the parent.  When ptraced, every thread reports itself.
 	 */
-	if (stop_count == 0 || (current->ptrace & PT_PTRACED)) {
+	if (tracehook_notify_jctl(stop_count == 0, CLD_STOPPED)) {
 		read_lock(&tasklist_lock);
 		do_notify_parent_cldstop(current, CLD_STOPPED);
 		read_unlock(&tasklist_lock);
@@ -1741,6 +1738,9 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		signal->flags &= ~SIGNAL_CLD_MASK;
 		spin_unlock_irq(&sighand->siglock);
 
+		if (unlikely(!tracehook_notify_jctl(1, why)))
+			goto relock;
+
 		read_lock(&tasklist_lock);
 		do_notify_parent_cldstop(current->group_leader, why);
 		read_unlock(&tasklist_lock);
@@ -1906,7 +1906,7 @@ void exit_signals(struct task_struct *tsk)
 out:
 	spin_unlock_irq(&tsk->sighand->siglock);
 
-	if (unlikely(group_stop)) {
+	if (unlikely(group_stop) && tracehook_notify_jctl(1, CLD_STOPPED)) {
 		read_lock(&tasklist_lock);
 		do_notify_parent_cldstop(tsk, CLD_STOPPED);
 		read_unlock(&tasklist_lock);

commit 7bcf6a2ca5f639b038c48711ebe6c4eca2036641
Author: Roland McGrath <roland@redhat.com>
Date:   Fri Jul 25 19:45:53 2008 -0700

    tracehook: get_signal_to_deliver
    
    This defines the tracehook_get_signal() hook to allow tracing code to slip
    in before normal signal dequeuing.  This lays the groundwork for new
    tracing features that can inject synthetic signals outside the normal
    queue or control the disposition of delivered signals.  The calling
    convention lets tracehook_get_signal() decide both exactly what will
    happen and what signal number to report in the handler/exit.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1a942ce32ba0..10b31ecdd9c8 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1754,17 +1754,33 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		    do_signal_stop(0))
 			goto relock;
 
-		signr = dequeue_signal(current, &current->blocked, info);
-		if (!signr)
-			break; /* will return 0 */
+		/*
+		 * Tracing can induce an artifical signal and choose sigaction.
+		 * The return value in @signr determines the default action,
+		 * but @info->si_signo is the signal number we will report.
+		 */
+		signr = tracehook_get_signal(current, regs, info, return_ka);
+		if (unlikely(signr < 0))
+			goto relock;
+		if (unlikely(signr != 0))
+			ka = return_ka;
+		else {
+			signr = dequeue_signal(current, &current->blocked,
+					       info);
 
-		if (signr != SIGKILL) {
-			signr = ptrace_signal(signr, info, regs, cookie);
 			if (!signr)
-				continue;
+				break; /* will return 0 */
+
+			if (signr != SIGKILL) {
+				signr = ptrace_signal(signr, info,
+						      regs, cookie);
+				if (!signr)
+					continue;
+			}
+
+			ka = &sighand->action[signr-1];
 		}
 
-		ka = &sighand->action[signr-1];
 		if (ka->sa.sa_handler == SIG_IGN) /* Do nothing.  */
 			continue;
 		if (ka->sa.sa_handler != SIG_DFL) {
@@ -1812,7 +1828,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 				spin_lock_irq(&sighand->siglock);
 			}
 
-			if (likely(do_signal_stop(signr))) {
+			if (likely(do_signal_stop(info->si_signo))) {
 				/* It released the siglock.  */
 				goto relock;
 			}
@@ -1833,7 +1849,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 
 		if (sig_kernel_coredump(signr)) {
 			if (print_fatal_signals)
-				print_fatal_signal(regs, signr);
+				print_fatal_signal(regs, info->si_signo);
 			/*
 			 * If it was able to dump core, this kills all
 			 * other threads in the group and synchronizes with
@@ -1842,13 +1858,13 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 			 * first and our do_group_exit call below will use
 			 * that value and ignore the one we pass it.
 			 */
-			do_coredump((long)signr, signr, regs);
+			do_coredump(info->si_signo, info->si_signo, regs);
 		}
 
 		/*
 		 * Death signals, no core dump.
 		 */
-		do_group_exit(signr);
+		do_group_exit(info->si_signo);
 		/* NOTREACHED */
 	}
 	spin_unlock_irq(&sighand->siglock);

commit 445a91d2fe3667fb8fc251433645f686933cf56a
Author: Roland McGrath <roland@redhat.com>
Date:   Fri Jul 25 19:45:52 2008 -0700

    tracehook: tracehook_consider_fatal_signal
    
    This defines tracehook_consider_fatal_signal() has a fine-grained hook for
    deciding to skip the special cases for a fatal signal, as ptrace does.
    There is no change, only cleanup.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9efd1cee6d0b..1a942ce32ba0 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -300,12 +300,12 @@ flush_signal_handlers(struct task_struct *t, int force_default)
 
 int unhandled_signal(struct task_struct *tsk, int sig)
 {
+	void __user *handler = tsk->sighand->action[sig-1].sa.sa_handler;
 	if (is_global_init(tsk))
 		return 1;
-	if (tsk->ptrace & PT_PTRACED)
+	if (handler != SIG_IGN && handler != SIG_DFL)
 		return 0;
-	return (tsk->sighand->action[sig-1].sa.sa_handler == SIG_IGN) ||
-		(tsk->sighand->action[sig-1].sa.sa_handler == SIG_DFL);
+	return !tracehook_consider_fatal_signal(tsk, sig, handler);
 }
 
 
@@ -761,7 +761,8 @@ static void complete_signal(int sig, struct task_struct *p, int group)
 	if (sig_fatal(p, sig) &&
 	    !(signal->flags & (SIGNAL_UNKILLABLE | SIGNAL_GROUP_EXIT)) &&
 	    !sigismember(&t->real_blocked, sig) &&
-	    (sig == SIGKILL || !(t->ptrace & PT_PTRACED))) {
+	    (sig == SIGKILL ||
+	     !tracehook_consider_fatal_signal(t, sig, SIG_DFL))) {
 		/*
 		 * This signal will be fatal to the whole group.
 		 */

commit 35de254dc60f91004b3b5ebb1fc7b2c3093d6032
Author: Roland McGrath <roland@redhat.com>
Date:   Fri Jul 25 19:45:51 2008 -0700

    tracehook: tracehook_consider_ignored_signal
    
    This defines tracehook_consider_ignored_signal() has a fine-grained hook
    for deciding to prevent the normal short-circuit of sending an ignored
    signal, as ptrace does.  There is no change, only cleanup.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8715c18b27b9..9efd1cee6d0b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -22,6 +22,7 @@
 #include <linux/ptrace.h>
 #include <linux/signal.h>
 #include <linux/signalfd.h>
+#include <linux/tracehook.h>
 #include <linux/capability.h>
 #include <linux/freezer.h>
 #include <linux/pid_namespace.h>
@@ -39,24 +40,21 @@
 
 static struct kmem_cache *sigqueue_cachep;
 
-static int __sig_ignored(struct task_struct *t, int sig)
+static void __user *sig_handler(struct task_struct *t, int sig)
 {
-	void __user *handler;
+	return t->sighand->action[sig - 1].sa.sa_handler;
+}
 
+static int sig_handler_ignored(void __user *handler, int sig)
+{
 	/* Is it explicitly or implicitly ignored? */
-
-	handler = t->sighand->action[sig - 1].sa.sa_handler;
 	return handler == SIG_IGN ||
 		(handler == SIG_DFL && sig_kernel_ignore(sig));
 }
 
 static int sig_ignored(struct task_struct *t, int sig)
 {
-	/*
-	 * Tracers always want to know about signals..
-	 */
-	if (t->ptrace & PT_PTRACED)
-		return 0;
+	void __user *handler;
 
 	/*
 	 * Blocked signals are never ignored, since the
@@ -66,7 +64,14 @@ static int sig_ignored(struct task_struct *t, int sig)
 	if (sigismember(&t->blocked, sig) || sigismember(&t->real_blocked, sig))
 		return 0;
 
-	return __sig_ignored(t, sig);
+	handler = sig_handler(t, sig);
+	if (!sig_handler_ignored(handler, sig))
+		return 0;
+
+	/*
+	 * Tracers may want to know about even ignored signals.
+	 */
+	return !tracehook_consider_ignored_signal(t, sig, handler);
 }
 
 /*
@@ -2298,7 +2303,7 @@ int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 		 *   (for example, SIGCHLD), shall cause the pending signal to
 		 *   be discarded, whether or not it is blocked"
 		 */
-		if (__sig_ignored(t, sig)) {
+		if (sig_handler_ignored(sig_handler(t, sig), sig)) {
 			sigemptyset(&mask);
 			sigaddset(&mask, sig);
 			rm_from_queue_full(&mask, &t->signal->shared_pending);

commit ff1188646c6870f336e910fb894eeed74f50471f
Author: Roland McGrath <roland@redhat.com>
Date:   Fri Jul 25 19:45:45 2008 -0700

    tracehook: unexport ptrace_notify
    
    The ptrace_notify() function should not be called by any modules.  It was
    only ever exported to be called by binfmt exec functions.  But that is no
    longer necessary since fs/exec.c deals with that generically now.  There
    should be no calls to ptrace_notify() from outside the core kernel.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 82c3545596c5..8715c18b27b9 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1895,7 +1895,6 @@ EXPORT_SYMBOL(recalc_sigpending);
 EXPORT_SYMBOL_GPL(dequeue_signal);
 EXPORT_SYMBOL(flush_signals);
 EXPORT_SYMBOL(force_sig);
-EXPORT_SYMBOL(ptrace_notify);
 EXPORT_SYMBOL(send_sig);
 EXPORT_SYMBOL(send_sig_info);
 EXPORT_SYMBOL(sigprocmask);

commit 19b0cfcca41dd772065671ad0584e1cea0f3fd13
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Fri Jul 25 01:48:35 2008 -0700

    pidns: remove now unused kill_proc function
    
    This function operated on a pid_t to kill a task, which is no longer valid
    in a containerized system.
    
    It has finally lost all its users and we can safely remove it from the
    tree.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5c7b7eaa0dc6..82c3545596c5 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1228,17 +1228,6 @@ int kill_pid(struct pid *pid, int sig, int priv)
 }
 EXPORT_SYMBOL(kill_pid);
 
-int
-kill_proc(pid_t pid, int sig, int priv)
-{
-	int ret;
-
-	rcu_read_lock();
-	ret = kill_pid_info(sig, __si_special(priv), find_pid(pid));
-	rcu_read_unlock();
-	return ret;
-}
-
 /*
  * These functions support sending signals using preallocated sigqueue
  * structures.  This is needed "because realtime applications cannot
@@ -1906,7 +1895,6 @@ EXPORT_SYMBOL(recalc_sigpending);
 EXPORT_SYMBOL_GPL(dequeue_signal);
 EXPORT_SYMBOL(flush_signals);
 EXPORT_SYMBOL(force_sig);
-EXPORT_SYMBOL(kill_proc);
 EXPORT_SYMBOL(ptrace_notify);
 EXPORT_SYMBOL(send_sig);
 EXPORT_SYMBOL(send_sig_info);

commit 999d9fc1670bc082928b93b11d1f2e0e417d973c
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Jul 25 01:47:41 2008 -0700

    coredump: move mm->core_waiters into struct core_state
    
    Move mm->core_waiters into "struct core_state" allocated on stack.  This
    shrinks mm_struct a little bit and allows further changes.
    
    This patch mostly does s/core_waiters/core_state.  The only essential
    change is that coredump_wait() must clear mm->core_state before return.
    
    The coredump_wait()'s path is uglified and .text grows by 30 bytes, this
    is fixed by the next patch.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 39c1706edf03..5c7b7eaa0dc6 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1480,10 +1480,10 @@ static inline int may_ptrace_stop(void)
 	 * is a deadlock situation, and pointless because our tracer
 	 * is dead so don't allow us to stop.
 	 * If SIGKILL was already sent before the caller unlocked
-	 * ->siglock we must see ->core_waiters != 0. Otherwise it
+	 * ->siglock we must see ->core_state != NULL. Otherwise it
 	 * is safe to enter schedule().
 	 */
-	if (unlikely(current->mm->core_waiters) &&
+	if (unlikely(current->mm->core_state) &&
 	    unlikely(current->mm == current->parent->mm))
 		return 0;
 

commit 3d749b9e676b26584a47e75c235aa6f69d0697ae
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Jul 25 01:47:37 2008 -0700

    ptrace: simplify ptrace_stop()->sigkill_pending() path
    
    1. SIGKILL can't be blocked, remove this check from sigkill_pending().
    
    2. When ptrace_stop() sees sigkill_pending() == T, it can just return.
       Kill "int killed" and simplify the code. This also is more correct,
       the tracer shouldn't see us in TASK_TRACED if we are not going to
       stop.
    
    I strongly believe this code needs further changes.  We should do the "was
    this task killed" check unconditionally, currently it depends on
    arch_ptrace_stop_needed().  On the other hand, sigkill_pending() isn't
    very clever.  If the task was killed tkill(SIGKILL), the signal can be
    already dequeued if the caller is do_exit().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index fdab7b363fa7..39c1706edf03 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1496,9 +1496,8 @@ static inline int may_ptrace_stop(void)
  */
 static int sigkill_pending(struct task_struct *tsk)
 {
-	return ((sigismember(&tsk->pending.signal, SIGKILL) ||
-		 sigismember(&tsk->signal->shared_pending.signal, SIGKILL)) &&
-		!unlikely(sigismember(&tsk->blocked, SIGKILL)));
+	return	sigismember(&tsk->pending.signal, SIGKILL) ||
+		sigismember(&tsk->signal->shared_pending.signal, SIGKILL);
 }
 
 /*
@@ -1514,8 +1513,6 @@ static int sigkill_pending(struct task_struct *tsk)
  */
 static void ptrace_stop(int exit_code, int clear_code, siginfo_t *info)
 {
-	int killed = 0;
-
 	if (arch_ptrace_stop_needed(exit_code, info)) {
 		/*
 		 * The arch code has something special to do before a
@@ -1531,7 +1528,8 @@ static void ptrace_stop(int exit_code, int clear_code, siginfo_t *info)
 		spin_unlock_irq(&current->sighand->siglock);
 		arch_ptrace_stop(exit_code, info);
 		spin_lock_irq(&current->sighand->siglock);
-		killed = sigkill_pending(current);
+		if (sigkill_pending(current))
+			return;
 	}
 
 	/*
@@ -1548,7 +1546,7 @@ static void ptrace_stop(int exit_code, int clear_code, siginfo_t *info)
 	__set_current_state(TASK_TRACED);
 	spin_unlock_irq(&current->sighand->siglock);
 	read_lock(&tasklist_lock);
-	if (!unlikely(killed) && may_ptrace_stop()) {
+	if (may_ptrace_stop()) {
 		do_notify_parent_cldstop(current, CLD_TRAPPED);
 		read_unlock(&tasklist_lock);
 		schedule();

commit bc64efd220dcd4449aef8dd2564d73127b583b09
Author: Gustavo Fernando Padovan <gustavo@las.ic.unicamp.br>
Date:   Fri Jul 25 01:47:33 2008 -0700

    kernel/signal.c: change vars pid and tgid types to pid_t
    
    Change the type of pid and tgid variables from int to the POSIX type
    pid_t.
    
    Signed-off-by: Gustavo F. Padovan <gustavo@las.ic.unicamp.br>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index ba60eeeb63aa..fdab7b363fa7 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1116,7 +1116,7 @@ EXPORT_SYMBOL_GPL(kill_pid_info_as_uid);
  * is probably wrong.  Should make it like BSD or SYSV.
  */
 
-static int kill_something_info(int sig, struct siginfo *info, int pid)
+static int kill_something_info(int sig, struct siginfo *info, pid_t pid)
 {
 	int ret;
 
@@ -2184,7 +2184,7 @@ sys_rt_sigtimedwait(const sigset_t __user *uthese,
 }
 
 asmlinkage long
-sys_kill(int pid, int sig)
+sys_kill(pid_t pid, int sig)
 {
 	struct siginfo info;
 
@@ -2197,7 +2197,7 @@ sys_kill(int pid, int sig)
 	return kill_something_info(sig, &info, pid);
 }
 
-static int do_tkill(int tgid, int pid, int sig)
+static int do_tkill(pid_t tgid, pid_t pid, int sig)
 {
 	int error;
 	struct siginfo info;
@@ -2243,7 +2243,7 @@ static int do_tkill(int tgid, int pid, int sig)
  *  exists but it's not belonging to the target process anymore. This
  *  method solves the problem of threads exiting and PIDs getting reused.
  */
-asmlinkage long sys_tgkill(int tgid, int pid, int sig)
+asmlinkage long sys_tgkill(pid_t tgid, pid_t pid, int sig)
 {
 	/* This is only valid for single tasks */
 	if (pid <= 0 || tgid <= 0)
@@ -2256,7 +2256,7 @@ asmlinkage long sys_tgkill(int tgid, int pid, int sig)
  *  Send a signal to only one task, even if it's a CLONE_THREAD task.
  */
 asmlinkage long
-sys_tkill(int pid, int sig)
+sys_tkill(pid_t pid, int sig)
 {
 	/* This is only valid for single tasks */
 	if (pid <= 0)
@@ -2266,7 +2266,7 @@ sys_tkill(int pid, int sig)
 }
 
 asmlinkage long
-sys_rt_sigqueueinfo(int pid, int sig, siginfo_t __user *uinfo)
+sys_rt_sigqueueinfo(pid_t pid, int sig, siginfo_t __user *uinfo)
 {
 	siginfo_t info;
 

commit d8878ba3f05ae5bbfad5a6e72e5121c0ea35f989
Author: Michael Kerrisk <mtk.manpages@googlemail.com>
Date:   Fri Jul 25 01:47:32 2008 -0700

    signals: make siginfo_t si_utime + si_sstime report times in USER_HZ, not HZ
    
    In the switch to configurable HZ in 2.6, the treatment of the si_utime and
    si_stime fields that are exposed to userland via the siginfo structure
    looks to have been botched.  As things stand, these fields report times in
    units of HZ, so that userland gets information that varies depending on
    the HZ that the kernel was configured with.  This patch changes the
    reported values to use USER_HZ units.
    
    Signed-off-by: Michael Kerrisk <mtk.manpages@gmail.com>
    Acked-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0514da573f22..ba60eeeb63aa 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1370,10 +1370,9 @@ void do_notify_parent(struct task_struct *tsk, int sig)
 
 	info.si_uid = tsk->uid;
 
-	/* FIXME: find out whether or not this is supposed to be c*time. */
-	info.si_utime = cputime_to_jiffies(cputime_add(tsk->utime,
+	info.si_utime = cputime_to_clock_t(cputime_add(tsk->utime,
 						       tsk->signal->utime));
-	info.si_stime = cputime_to_jiffies(cputime_add(tsk->stime,
+	info.si_stime = cputime_to_clock_t(cputime_add(tsk->stime,
 						       tsk->signal->stime));
 
 	info.si_status = tsk->exit_code & 0x7f;
@@ -1441,9 +1440,8 @@ static void do_notify_parent_cldstop(struct task_struct *tsk, int why)
 
 	info.si_uid = tsk->uid;
 
-	/* FIXME: find out whether or not this is supposed to be c*time. */
-	info.si_utime = cputime_to_jiffies(tsk->utime);
-	info.si_stime = cputime_to_jiffies(tsk->stime);
+	info.si_utime = cputime_to_clock_t(tsk->utime);
+	info.si_stime = cputime_to_clock_t(tsk->stime);
 
  	info.si_code = why;
  	switch (why) {

commit 2b201a9eddf509e8e935b45e573648e36f4b623f
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Jul 25 01:47:31 2008 -0700

    signals: do_signal_stop: kill the SIGNAL_UNKILLABLE check
    
    fae5fa44f1fd079ffbed8e0add929dd7bbd1347f changed do_signal_stop() to check
    SIGNAL_UNKILLABLE, this wasn't needed.  If signal_group_exit() == F, the
    signal sent to SIGNAL_UNKILLABLE task must be already filtered out by the
    caller, get_signal_to_deliver().  And if signal_group_exit() == T we are
    not going to stop.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 15f901a26ec7..0514da573f22 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1649,8 +1649,7 @@ static int do_signal_stop(int signr)
 	} else {
 		struct task_struct *t;
 
-		if (unlikely((sig->flags & (SIGNAL_STOP_DEQUEUED | SIGNAL_UNKILLABLE))
-					 != SIGNAL_STOP_DEQUEUED) ||
+		if (!likely(sig->flags & SIGNAL_STOP_DEQUEUED) ||
 		    unlikely(signal_group_exit(sig)))
 			return 0;
 		/*

commit 92413d771e7123304fb4b9efd2a00cccc946e383
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Jul 25 01:47:30 2008 -0700

    signals: dequeue_signal: don't check SIGNAL_GROUP_EXIT when setting SIGNAL_STOP_DEQUEUED
    
    dequeue_signal() checks SIGNAL_GROUP_EXIT before setting
    SIGNAL_STOP_DEQUEUED.  This was added by
    788e05a67c343fa22f2ae1d3ca264e7f15c25eaf a long ago to avoid the
    coredump/SIGSTOP race.
    
    Since then the related code was changed, and now this subtle check is both
    incomplete and unneeded at the same time.  It is incomplete because
    nowadays exec() doesn't set SIGNAL_GROUP_EXIT, so in fact we should check
    signal_group_exit() to avoid a similar race.  Fortunately, we doesn't need
    the check at all.  The only function which relies on SIGNAL_STOP_DEQUEUED
    is do_signal_stop(), and it ignores this flag if signal_group_exit() == T,
    this covers the SIGNAL_GROUP_EXIT case.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index fea236fe0b50..15f901a26ec7 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -454,8 +454,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 		 * is to alert stop-signal processing code when another
 		 * processor has come along and cleared the flag.
 		 */
-		if (!(tsk->signal->flags & SIGNAL_GROUP_EXIT))
-			tsk->signal->flags |= SIGNAL_STOP_DEQUEUED;
+		tsk->signal->flags |= SIGNAL_STOP_DEQUEUED;
 	}
 	if ((info->si_code & __SI_MASK) == __SI_TIMER && info->si_sys_private) {
 		/*

commit 100360f03077663b7bef3af44805b6cf700c3bee
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Jul 25 01:47:29 2008 -0700

    signals: change collect_signal() to return void
    
    With the recent changes collect_signal() always returns true.  Change it
    to return void and update the single caller.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 50ad439377b2..fea236fe0b50 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -338,7 +338,7 @@ unblock_all_signals(void)
 	spin_unlock_irqrestore(&current->sighand->siglock, flags);
 }
 
-static int collect_signal(int sig, struct sigpending *list, siginfo_t *info)
+static void collect_signal(int sig, struct sigpending *list, siginfo_t *info)
 {
 	struct sigqueue *q, *first = NULL;
 
@@ -372,7 +372,6 @@ static int collect_signal(int sig, struct sigpending *list, siginfo_t *info)
 		info->si_pid = 0;
 		info->si_uid = 0;
 	}
-	return 1;
 }
 
 static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,
@@ -390,8 +389,7 @@ static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,
 			}
 		}
 
-		if (!collect_signal(sig, pending, info))
-			sig = 0;
+		collect_signal(sig, pending, info);
 	}
 
 	return sig;

commit d4434207616980885205c605697868c0f07e4378
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Jul 25 01:47:28 2008 -0700

    signals: collect_signal: simplify the "still_pending" logic
    
    Factor out sigdelset() calls and remove the "still_pending" variable.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index c5b9aabb1550..50ad439377b2 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -341,7 +341,6 @@ unblock_all_signals(void)
 static int collect_signal(int sig, struct sigpending *list, siginfo_t *info)
 {
 	struct sigqueue *q, *first = NULL;
-	int still_pending = 0;
 
 	/*
 	 * Collect the siginfo appropriate to this signal.  Check if
@@ -349,26 +348,24 @@ static int collect_signal(int sig, struct sigpending *list, siginfo_t *info)
 	*/
 	list_for_each_entry(q, &list->list, list) {
 		if (q->info.si_signo == sig) {
-			if (first) {
-				still_pending = 1;
-				break;
-			}
+			if (first)
+				goto still_pending;
 			first = q;
 		}
 	}
+
+	sigdelset(&list->signal, sig);
+
 	if (first) {
+still_pending:
 		list_del_init(&first->list);
 		copy_siginfo(info, &first->info);
 		__sigqueue_free(first);
-		if (!still_pending)
-			sigdelset(&list->signal, sig);
 	} else {
-
 		/* Ok, it wasn't in the queue.  This must be
 		   a fast-pathed signal or we must have been
 		   out of queue space.  So zero out the info.
 		 */
-		sigdelset(&list->signal, sig);
 		info->si_signo = sig;
 		info->si_errno = 0;
 		info->si_code = 0;

commit 6715ca451cfff1c9ce4b33ad9918a1dacf43997c
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Jul 25 01:47:27 2008 -0700

    signals: collect_signal: remove the unneeded sigismember() check
    
    collect_signal() checks sigismember(&list->signal, sig), this is not
    needed.  This "sig" was just found by next_signal(), so it must be valid.
    
    We have a (completely broken) call to ->notifier in between, but it must
    not play with sigpending->signal bits or unlock ->siglock.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 6c0958e52ea7..c5b9aabb1550 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -343,9 +343,6 @@ static int collect_signal(int sig, struct sigpending *list, siginfo_t *info)
 	struct sigqueue *q, *first = NULL;
 	int still_pending = 0;
 
-	if (unlikely(!sigismember(&list->signal, sig)))
-		return 0;
-
 	/*
 	 * Collect the siginfo appropriate to this signal.  Check if
 	 * there is another siginfo for the same signal.

commit ba661292a2bc6ddd305a212b0526e5dc22195fe7
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Jul 23 20:52:05 2008 +0400

    posix-timers: fix posix_timer_event() vs dequeue_signal() race
    
    The bug was reported and analysed by Mark McLoughlin <markmc@redhat.com>,
    the patch is based on his and Roland's suggestions.
    
    posix_timer_event() always rewrites the pre-allocated siginfo before sending
    the signal. Most of the written info is the same all the time, but memset(0)
    is very wrong. If ->sigq is queued we can race with collect_signal() which
    can fail to find this siginfo looking at .si_signo, or copy_siginfo() can
    copy the wrong .si_code/si_tid/etc.
    
    In short, sys_timer_settime() can in fact stop the active timer, or the user
    can receive the siginfo with the wrong .si_xxx values.
    
    Move "memset(->info, 0)" from posix_timer_event() to alloc_posix_timer(),
    change send_sigqueue() to set .si_overrun = 0 when ->sigq is not queued.
    It would be nice to move the whole sigq->info initialization from send to
    create path, but this is not easy to do without uglifying timer_create()
    further.
    
    As Roland rightly pointed out, we need more cleanups/fixes here, see the
    "FIXME" comment in the patch. Hopefully this patch makes sense anyway, and
    it can mask the most bad implications.
    
    Reported-by: Mark McLoughlin <markmc@redhat.com>
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Mark McLoughlin <markmc@redhat.com>
    Cc: Oliver Pinter <oliver.pntr@gmail.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: stable@kernel.org
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    
     kernel/posix-timers.c |   17 +++++++++++++----
     kernel/signal.c       |    1 +
     2 files changed, 14 insertions(+), 4 deletions(-)

diff --git a/kernel/signal.c b/kernel/signal.c
index 72bb4f51f963..13fab9838354 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1280,6 +1280,7 @@ int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)
 		q->info.si_overrun++;
 		goto out;
 	}
+	q->info.si_overrun = 0;
 
 	signalfd_notify(t, sig);
 	pending = group ? &t->signal->shared_pending : &t->pending;

commit cbaffba12ce08beb3e80bfda148ee0fa14aac188
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon May 26 20:55:42 2008 +0400

    posix timers: discard SI_TIMER signals on exec
    
    Based on Roland's patch. This approach was suggested by Austin Clements
    from the very beginning, and then by Linus.
    
    As Austin pointed out, the execing task can be killed by SI_TIMER signal
    because exec flushes the signal handlers, but doesn't discard the pending
    signals generated by posix timers. Perhaps not a bug, but people find this
    surprising. See http://bugzilla.kernel.org/show_bug.cgi?id=10460
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Austin Clements <amdragon+kernelbugzilla@mit.edu>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2955f6c4f36e..6c0958e52ea7 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -231,6 +231,40 @@ void flush_signals(struct task_struct *t)
 	spin_unlock_irqrestore(&t->sighand->siglock, flags);
 }
 
+static void __flush_itimer_signals(struct sigpending *pending)
+{
+	sigset_t signal, retain;
+	struct sigqueue *q, *n;
+
+	signal = pending->signal;
+	sigemptyset(&retain);
+
+	list_for_each_entry_safe(q, n, &pending->list, list) {
+		int sig = q->info.si_signo;
+
+		if (likely(q->info.si_code != SI_TIMER)) {
+			sigaddset(&retain, sig);
+		} else {
+			sigdelset(&signal, sig);
+			list_del_init(&q->list);
+			__sigqueue_free(q);
+		}
+	}
+
+	sigorsets(&pending->signal, &signal, &retain);
+}
+
+void flush_itimer_signals(void)
+{
+	struct task_struct *tsk = current;
+	unsigned long flags;
+
+	spin_lock_irqsave(&tsk->sighand->siglock, flags);
+	__flush_itimer_signals(&tsk->pending);
+	__flush_itimer_signals(&tsk->signal->shared_pending);
+	spin_unlock_irqrestore(&tsk->sighand->siglock, flags);
+}
+
 void ignore_signals(struct task_struct *t)
 {
 	int i;

commit c8e85b4f4b9ee23bf0e79bdeb3da274a0f9c663f
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon May 26 20:55:42 2008 +0400

    posix timers: sigqueue_free: don't free sigqueue if it is queued
    
    Currently sigqueue_free() removes sigqueue from list, but doesn't cancel the
    pending signal. This is not consistent, the task should either receive the
    "full" signal along with siginfo_t, or it shouldn't receive the signal at all.
    
    Change sigqueue_free() to clear SIGQUEUE_PREALLOC but leave sigqueue on list
    if it is queued.
    
    This is a user-visible change. If the signal is blocked, it stays queued
    after sys_timer_delete() until unblocked with the "stale" si_code/si_value,
    and of course it is still counted wrt RLIMIT_SIGPENDING which also limits
    the number of posix timers.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Austin Clements <amdragon+kernelbugzilla@mit.edu>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 12ffea7c201d..2955f6c4f36e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1240,18 +1240,22 @@ void sigqueue_free(struct sigqueue *q)
 
 	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
 	/*
-	 * If the signal is still pending remove it from the
-	 * pending queue. We must hold ->siglock while testing
-	 * q->list to serialize with collect_signal() or with
+	 * We must hold ->siglock while testing q->list
+	 * to serialize with collect_signal() or with
 	 * __exit_signal()->flush_sigqueue().
 	 */
 	spin_lock_irqsave(lock, flags);
+	q->flags &= ~SIGQUEUE_PREALLOC;
+	/*
+	 * If it is queued it will be freed when dequeued,
+	 * like the "regular" sigqueue.
+	 */
 	if (!list_empty(&q->list))
-		list_del_init(&q->list);
+		q = NULL;
 	spin_unlock_irqrestore(lock, flags);
 
-	q->flags &= ~SIGQUEUE_PREALLOC;
-	__sigqueue_free(q);
+	if (q)
+		__sigqueue_free(q);
 }
 
 int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)

commit da7978b0348d497688541e2d2f5739aa2a2c334f
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri May 23 13:04:41 2008 -0700

    signals: fix sigqueue_free() vs __exit_signal() race
    
    __exit_signal() does flush_sigqueue(tsk->pending) outside of ->siglock.
    This can race with another thread doing sigqueue_free(), we can free the
    same SIGQUEUE_PREALLOC sigqueue twice or corrupt the pending->list.
    
    Note that even sys_exit_group() can trigger this race, not only
    sys_timer_delete().
    
    Move the callsite of flush_sigqueue(tsk->pending) under ->siglock.
    
    This patch doesn't touch flush_sigqueue(->shared_pending) below, it is
    called when there are no other threads which can play with signals, and
    sigqueue_free() can't be used outside of our thread group.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 72bb4f51f963..12ffea7c201d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1242,7 +1242,8 @@ void sigqueue_free(struct sigqueue *q)
 	/*
 	 * If the signal is still pending remove it from the
 	 * pending queue. We must hold ->siglock while testing
-	 * q->list to serialize with collect_signal().
+	 * q->list to serialize with collect_signal() or with
+	 * __exit_signal()->flush_sigqueue().
 	 */
 	spin_lock_irqsave(lock, flags);
 	if (!list_empty(&q->list))

commit 4e4c22c71144c1b2e22c257ec6cf08ccb5be1165
Author: Roland McGrath <roland@redhat.com>
Date:   Wed Apr 30 00:53:06 2008 -0700

    signals: add set_restore_sigmask
    
    This adds the set_restore_sigmask() inline in <linux/thread_info.h> and
    replaces every set_thread_flag(TIF_RESTORE_SIGMASK) with a call to it.  No
    change, but abstracts the details of the flag protocol from all the calls.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9ac737e53df1..72bb4f51f963 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2541,7 +2541,7 @@ asmlinkage long sys_rt_sigsuspend(sigset_t __user *unewset, size_t sigsetsize)
 
 	current->state = TASK_INTERRUPTIBLE;
 	schedule();
-	set_thread_flag(TIF_RESTORE_SIGMASK);
+	set_restore_sigmask();
 	return -ERESTARTNOHAND;
 }
 #endif /* __ARCH_WANT_SYS_RT_SIGSUSPEND */

commit 80fe728d593e3a048a56610de932919f7d6d968a
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:53:05 2008 -0700

    signals: allow the kernel to actually kill /sbin/init
    
    Currently the buggy /sbin/init hangs if SIGSEGV/etc happens.  The kernel sends
    the signal, init dequeues it and ignores, returns from the exception, repeats
    the faulting instruction, and so on forever.
    
    Imho, such a behaviour is not good.  I think that the explicit loud death of
    the buggy /sbin/init is better than the silent hang.
    
    Change force_sig_info() to clear SIGNAL_UNKILLABLE when the task should be
    really killed.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 646a8765696a..9ac737e53df1 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -892,7 +892,8 @@ specific_send_sig_info(int sig, struct siginfo *info, struct task_struct *t)
  * since we do not want to have a signal handler that was blocked
  * be invoked when user space had explicitly blocked it.
  *
- * We don't want to have recursive SIGSEGV's etc, for example.
+ * We don't want to have recursive SIGSEGV's etc, for example,
+ * that is why we also clear SIGNAL_UNKILLABLE.
  */
 int
 force_sig_info(int sig, struct siginfo *info, struct task_struct *t)
@@ -912,6 +913,8 @@ force_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 			recalc_sigpending_and_wake(t);
 		}
 	}
+	if (action->sa.sa_handler == SIG_DFL)
+		t->signal->flags &= ~SIGNAL_UNKILLABLE;
 	ret = specific_send_sig_info(sig, info, t);
 	spin_unlock_irqrestore(&t->sighand->siglock, flags);
 

commit fae5fa44f1fd079ffbed8e0add929dd7bbd1347f
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:53:03 2008 -0700

    signals: fix /sbin/init protection from unwanted signals
    
    The global init has a lot of long standing problems with the unhandled fatal
    signals.
    
            - The "is_global_init(current)" check in get_signal_to_deliver()
              protects only the main thread. Sub-thread can dequee the fatal
              signal and shutdown the whole thread group except the main thread.
              If it dequeues SIGSTOP /sbin/init will be stopped, this is not
              right too. Note that we can't use is_global_init(->group_leader),
              this breaks exec and this can't solve other problems we have.
    
            - Even if afterwards ignored, the fatal signals sets SIGNAL_GROUP_EXIT
              on delivery. This breaks exec, has other bad implications, and this
              is just wrong.
    
    Introduce the new SIGNAL_UNKILLABLE flag to fix these problems.  It also helps
    to solve some other problems addressed by the subsequent patches.
    
    Currently we use this flag for the global init only, but it could also be used
    by kthreads and (perhaps) by the sub-namespace inits.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 02ef3548aeb0..646a8765696a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -728,7 +728,8 @@ static void complete_signal(int sig, struct task_struct *p, int group)
 	 * Found a killable thread.  If the signal will be fatal,
 	 * then start taking the whole group down immediately.
 	 */
-	if (sig_fatal(p, sig) && !(signal->flags & SIGNAL_GROUP_EXIT) &&
+	if (sig_fatal(p, sig) &&
+	    !(signal->flags & (SIGNAL_UNKILLABLE | SIGNAL_GROUP_EXIT)) &&
 	    !sigismember(&t->real_blocked, sig) &&
 	    (sig == SIGKILL || !(t->ptrace & PT_PTRACED))) {
 		/*
@@ -1615,7 +1616,8 @@ static int do_signal_stop(int signr)
 	} else {
 		struct task_struct *t;
 
-		if (!likely(sig->flags & SIGNAL_STOP_DEQUEUED) ||
+		if (unlikely((sig->flags & (SIGNAL_STOP_DEQUEUED | SIGNAL_UNKILLABLE))
+					 != SIGNAL_STOP_DEQUEUED) ||
 		    unlikely(signal_group_exit(sig)))
 			return 0;
 		/*
@@ -1761,7 +1763,8 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		/*
 		 * Global init gets no signals it doesn't want.
 		 */
-		if (is_global_init(current))
+		if (unlikely(signal->flags & SIGNAL_UNKILLABLE) &&
+		    !signal_group_exit(signal))
 			continue;
 
 		if (sig_kernel_stop(signr)) {

commit 193191035ad6268db9f561e81e3474b8be89a5ba
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:53:02 2008 -0700

    signals: check_kill_permission: remove tasklist_lock
    
    Now that task_session() can't return a false NULL, check_kill_permission()
    doesn't need tasklist_lock.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 24be82c0aae3..02ef3548aeb0 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -551,9 +551,7 @@ static int check_kill_permission(int sig, struct siginfo *info,
 	    !capable(CAP_KILL)) {
 		switch (sig) {
 		case SIGCONT:
-			read_lock(&tasklist_lock);
 			sid = task_session(t);
-			read_unlock(&tasklist_lock);
 			/*
 			 * We don't return the error if sid == NULL. The
 			 * task was unhashed, the caller must notice this.

commit 2e2ba22ea4fd4bb85f0fa37c521066db6775cbef
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:53:01 2008 -0700

    signals: check_kill_permission: check session under tasklist_lock
    
    This wasn't documented, but as Atsushi Tsuji pointed out
    check_kill_permission() needs tasklist_lock for task_session_nr().  I missed
    this fact when removed tasklist from the callers.
    
    Change check_kill_permission() to take tasklist_lock for the SIGCONT case.
    Re-order security checks so that we take tasklist_lock only if/when it is
    actually needed.  This is a minimal fix for now, tasklist will be removed
    later.
    
    Also change the code to use task_session() instead of task_session_nr().
    
    Also, remove the SIGCONT check from cap_task_kill(), it is bogus (and the
    whole function is bogus.  Serge, Eric, why it is still alive?).
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Atsushi Tsuji <a-tsuji@bk.jp.nec.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 251cc13720bd..24be82c0aae3 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -533,6 +533,7 @@ static int rm_from_queue(unsigned long mask, struct sigpending *s)
 static int check_kill_permission(int sig, struct siginfo *info,
 				 struct task_struct *t)
 {
+	struct pid *sid;
 	int error;
 
 	if (!valid_signal(sig))
@@ -545,11 +546,24 @@ static int check_kill_permission(int sig, struct siginfo *info,
 	if (error)
 		return error;
 
-	if (((sig != SIGCONT) || (task_session_nr(current) != task_session_nr(t)))
-	    && (current->euid ^ t->suid) && (current->euid ^ t->uid)
-	    && (current->uid ^ t->suid) && (current->uid ^ t->uid)
-	    && !capable(CAP_KILL))
-		return -EPERM;
+	if ((current->euid ^ t->suid) && (current->euid ^ t->uid) &&
+	    (current->uid  ^ t->suid) && (current->uid  ^ t->uid) &&
+	    !capable(CAP_KILL)) {
+		switch (sig) {
+		case SIGCONT:
+			read_lock(&tasklist_lock);
+			sid = task_session(t);
+			read_unlock(&tasklist_lock);
+			/*
+			 * We don't return the error if sid == NULL. The
+			 * task was unhashed, the caller must notice this.
+			 */
+			if (!sid || sid == task_session(current))
+				break;
+		default:
+			return -EPERM;
+		}
+	}
 
 	return security_task_kill(t, info, sig, 0);
 }

commit 53c30337f2c61aff6eecf2a446e839641172f9bd
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:53:00 2008 -0700

    signals: send_signal: be paranoid about signalfd_notify()
    
    send_signal() shouldn't call signalfd_notify() if it then fails with -EAGAIN.
    Harmless, just a paranoid cleanup.
    
    Also remove the comment.  It is obsolete, signalfd_notify() was simplified and
    does a simple wakeup.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Davide Libenzi <davidel@xmailserver.org>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8423867f7d8f..251cc13720bd 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -772,13 +772,6 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	 */
 	if (legacy_queue(pending, sig))
 		return 0;
-
-	/*
-	 * Deliver the signal to listening signalfds. This must be called
-	 * with the sighand lock held.
-	 */
-	signalfd_notify(t, sig);
-
 	/*
 	 * fast-pathed signals for kernel-internal things like SIGSTOP
 	 * or SIGKILL.
@@ -828,6 +821,7 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	}
 
 out_set:
+	signalfd_notify(t, sig);
 	sigaddset(&pending->signal, sig);
 	complete_signal(sig, t, group);
 	return 0;

commit 021e1ae3d85a76ce962a300c96813f04ae50c87c
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:53:00 2008 -0700

    signals: document CLD_CONTINUED notification mechanics
    
    A couple of small comments about how CLD_CONTINUED notification works.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 359c4de7c772..8423867f7d8f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -633,6 +633,11 @@ static int prepare_signal(int sig, struct task_struct *p)
 			why |= SIGNAL_CLD_STOPPED;
 
 		if (why) {
+			/*
+			 * The first thread which returns from finish_stop()
+			 * will take ->siglock, notice SIGNAL_CLD_MASK, and
+			 * notify its parent. See get_signal_to_deliver().
+			 */
 			signal->flags = why | SIGNAL_STOP_CONTINUED;
 			signal->group_stop_count = 0;
 			signal->group_exit_code = 0;
@@ -1694,7 +1699,11 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 	try_to_freeze();
 
 	spin_lock_irq(&sighand->siglock);
-
+	/*
+	 * Every stopped thread goes here after wakeup. Check to see if
+	 * we should notify the parent, prepare_signal(SIGCONT) encodes
+	 * the CLD_ si_code into SIGNAL_CLD_MASK bits.
+	 */
 	if (unlikely(signal->flags & SIGNAL_CLD_MASK)) {
 		int why = (signal->flags & SIGNAL_STOP_CONTINUED)
 				? CLD_CONTINUED : CLD_STOPPED;

commit 7e695a5ef5c1c768d7feb75cc61e42f13d763623
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:59 2008 -0700

    signals: fold sig_ignored() into handle_stop_signal()
    
    Rename handle_stop_signal() to prepare_signal(), make it return a boolean, and
    move the callsites of sig_ignored() into it.
    
    No functional changes for now.  But it would be nice to factor out the "should
    we drop this signal" checks as much as possible, before we try to fix the bugs
    with the sub-namespace init's signals (actually the global /sbin/init has some
    problems with signals too).
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0db1d93c4d68..359c4de7c772 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -558,24 +558,25 @@ static int check_kill_permission(int sig, struct siginfo *info,
 static void do_notify_parent_cldstop(struct task_struct *tsk, int why);
 
 /*
- * Handle magic process-wide effects of stop/continue signals.
- * Unlike the signal actions, these happen immediately at signal-generation
+ * Handle magic process-wide effects of stop/continue signals. Unlike
+ * the signal actions, these happen immediately at signal-generation
  * time regardless of blocking, ignoring, or handling.  This does the
  * actual continuing for SIGCONT, but not the actual stopping for stop
- * signals.  The process stop is done as a signal action for SIG_DFL.
+ * signals. The process stop is done as a signal action for SIG_DFL.
+ *
+ * Returns true if the signal should be actually delivered, otherwise
+ * it should be dropped.
  */
-static void handle_stop_signal(int sig, struct task_struct *p)
+static int prepare_signal(int sig, struct task_struct *p)
 {
 	struct signal_struct *signal = p->signal;
 	struct task_struct *t;
 
-	if (signal->flags & SIGNAL_GROUP_EXIT)
+	if (unlikely(signal->flags & SIGNAL_GROUP_EXIT)) {
 		/*
-		 * The process is in the middle of dying already.
+		 * The process is in the middle of dying, nothing to do.
 		 */
-		return;
-
-	if (sig_kernel_stop(sig)) {
+	} else if (sig_kernel_stop(sig)) {
 		/*
 		 * This is a stop signal.  Remove SIGCONT from all queues.
 		 */
@@ -644,6 +645,8 @@ static void handle_stop_signal(int sig, struct task_struct *p)
 			signal->flags &= ~SIGNAL_STOP_DEQUEUED;
 		}
 	}
+
+	return !sig_ignored(p, sig);
 }
 
 /*
@@ -753,7 +756,8 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	struct sigqueue *q;
 
 	assert_spin_locked(&t->sighand->siglock);
-	handle_stop_signal(sig, t);
+	if (!prepare_signal(sig, t))
+		return 0;
 
 	pending = group ? &t->signal->shared_pending : &t->pending;
 	/*
@@ -761,7 +765,7 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	 * exactly one non-rt signal, so that we can get more
 	 * detailed information about the cause of the signal.
 	 */
-	if (sig_ignored(t, sig) || legacy_queue(pending, sig))
+	if (legacy_queue(pending, sig))
 		return 0;
 
 	/*
@@ -1247,10 +1251,8 @@ int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)
 	if (!likely(lock_task_sighand(t, &flags)))
 		goto ret;
 
-	handle_stop_signal(sig, t);
-
-	ret = 1;
-	if (sig_ignored(t, sig))
+	ret = 1; /* the signal is ignored */
+	if (!prepare_signal(sig, t))
 		goto out;
 
 	ret = 0;

commit 2dce81bff28dceb2153c901883a56f278d91db65
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:58 2008 -0700

    signals: cleanup the usage of print_fatal_signal()
    
    Move the callsite of print_fatal_signal() down, under "if
    (sig_kernel_coredump(signr))", so we don't need to check signr != SIGKILL.
    
    We are only interested in the sig_kernel_coredump() signals anyway, and due to
    the previous changes we almost never can see other fatal signals here except
    SIGKILL.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0a873279393c..0db1d93c4d68 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1787,9 +1787,10 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		 * Anything else is fatal, maybe with a core dump.
 		 */
 		current->flags |= PF_SIGNALED;
-		if ((signr != SIGKILL) && print_fatal_signals)
-			print_fatal_signal(regs, signr);
+
 		if (sig_kernel_coredump(signr)) {
+			if (print_fatal_signals)
+				print_fatal_signal(regs, signr);
 			/*
 			 * If it was able to dump core, this kills all
 			 * other threads in the group and synchronizes with

commit 34c8f07b9ac499a807918eda377193a55f64f8df
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:58 2008 -0700

    signals: handle_stop_signal: don't worry about SIGKILL
    
    handle_stop_signal() clears SIGNAL_STOP_DEQUEUED when sig == SIGKILL.  Remove
    this nasty special case.  It was needed to prevent the race with group stop
    and exit caused by thread-specific SIGKILL.  Now that we use complete_signal()
    for private signals too this is not needed, complete_signal() will notice
    SIGKILL and abort the soon-to-begin group stop.
    
    Except: the target thread is dead (has PF_EXITING).  But in that case we
    should not just clear SIGNAL_STOP_DEQUEUED and nothing more.  We should either
    kill the whole thread group, or silently ignore the signal.
    
    I suspect we are not right wrt zombie leaders, but this is another issue which
    and should be fixed separately.  Note that this check can't abort the group
    stop if it was already started/finished, this check only adds a subtle side
    effect if we race with the thread which has already dequeued sig_kernel_stop()
    signal and temporary released ->siglock.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index d52a1fe921fa..0a873279393c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -643,12 +643,6 @@ static void handle_stop_signal(int sig, struct task_struct *p)
 			 */
 			signal->flags &= ~SIGNAL_STOP_DEQUEUED;
 		}
-	} else if (sig == SIGKILL) {
-		/*
-		 * Make sure that any pending stop signal already dequeued
-		 * is undone by the wakeup for SIGKILL.
-		 */
-		signal->flags &= ~SIGNAL_STOP_DEQUEUED;
 	}
 }
 

commit ac5c215383f43a106ba4ef298126bf78c126f5e9
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:57 2008 -0700

    signals: join send_sigqueue() with send_group_sigqueue()
    
    We export send_sigqueue() and send_group_sigqueue() for the only user,
    posix_timer_event().  This is a bit silly, because both are just trivial
    helpers on top of do_send_sigqueue() and because the we pass the unused
    .si_signo parameter.
    
    Kill them both, rename do_send_sigqueue() to send_sigqueue(), and export it.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 367c6662b12f..d52a1fe921fa 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1240,8 +1240,7 @@ void sigqueue_free(struct sigqueue *q)
 	__sigqueue_free(q);
 }
 
-static int do_send_sigqueue(struct sigqueue *q, struct task_struct *t,
-				int group)
+int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)
 {
 	int sig = q->info.si_signo;
 	struct sigpending *pending;
@@ -1266,7 +1265,6 @@ static int do_send_sigqueue(struct sigqueue *q, struct task_struct *t,
 		 * If an SI_TIMER entry is already queue just increment
 		 * the overrun count.
 		 */
-
 		BUG_ON(q->info.si_code != SI_TIMER);
 		q->info.si_overrun++;
 		goto out;
@@ -1283,17 +1281,6 @@ static int do_send_sigqueue(struct sigqueue *q, struct task_struct *t,
 	return ret;
 }
 
-int send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
-{
-	return do_send_sigqueue(q, p, 0);
-}
-
-int
-send_group_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
-{
-	return do_send_sigqueue(q, p, 1);
-}
-
 /*
  * Wake up any threads in the parent blocked in wait* syscalls.
  */

commit e62e6650e99a3dffcd0bf0d063cd818fbc13fa95
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:56 2008 -0700

    signals: unify send_sigqueue/send_group_sigqueue completely
    
    Suggested by Pavel Emelyanov.
    
    send_sigqueue/send_group_sigqueue are only differ in how they lock ->siglock.
    Unify them.  send_group_sigqueue() uses spin_lock() because it knows the task
    can't exit, but in that case lock_task_sighand() can't fail and doesn't hurt.
    
    Note that the "sig" argument is ignored, it is always equal to ->si_signo.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 87424f7a4f3d..367c6662b12f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1240,14 +1240,27 @@ void sigqueue_free(struct sigqueue *q)
 	__sigqueue_free(q);
 }
 
-static int do_send_sigqueue(int sig, struct sigqueue *q, struct task_struct *t,
+static int do_send_sigqueue(struct sigqueue *q, struct task_struct *t,
 				int group)
 {
+	int sig = q->info.si_signo;
 	struct sigpending *pending;
+	unsigned long flags;
+	int ret;
 
 	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
+
+	ret = -1;
+	if (!likely(lock_task_sighand(t, &flags)))
+		goto ret;
+
 	handle_stop_signal(sig, t);
 
+	ret = 1;
+	if (sig_ignored(t, sig))
+		goto out;
+
+	ret = 0;
 	if (unlikely(!list_empty(&q->list))) {
 		/*
 		 * If an SI_TIMER entry is already queue just increment
@@ -1256,58 +1269,29 @@ static int do_send_sigqueue(int sig, struct sigqueue *q, struct task_struct *t,
 
 		BUG_ON(q->info.si_code != SI_TIMER);
 		q->info.si_overrun++;
-		return 0;
+		goto out;
 	}
 
-	if (sig_ignored(t, sig))
-		return 1;
-
 	signalfd_notify(t, sig);
 	pending = group ? &t->signal->shared_pending : &t->pending;
 	list_add_tail(&q->list, &pending->list);
 	sigaddset(&pending->signal, sig);
 	complete_signal(sig, t, group);
-
-	return 0;
+out:
+	unlock_task_sighand(t, &flags);
+ret:
+	return ret;
 }
 
 int send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 {
-	unsigned long flags;
-	int ret = -1;
-
-	/*
-	 * The rcu based delayed sighand destroy makes it possible to
-	 * run this without tasklist lock held. The task struct itself
-	 * cannot go away as create_timer did get_task_struct().
-	 *
-	 * We return -1, when the task is marked exiting, so
-	 * posix_timer_event can redirect it to the group leader
-	 */
-	if (!likely(lock_task_sighand(p, &flags)))
-		goto out_err;
-
-	ret = do_send_sigqueue(sig, q, p, 0);
-
-	unlock_task_sighand(p, &flags);
-out_err:
-	return ret;
+	return do_send_sigqueue(q, p, 0);
 }
 
 int
 send_group_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 {
-	unsigned long flags;
-	int ret;
-
-	/* Since it_lock is held, p->sighand cannot be NULL. */
-	spin_lock_irqsave(&p->sighand->siglock, flags);
-
-	ret = do_send_sigqueue(sig, q, p, 1);
-
-	spin_unlock_irqrestore(&p->sighand->siglock, flags);
-
-	return ret;
+	return do_send_sigqueue(q, p, 1);
 }
 
 /*

commit 4cd4b6d4e0372075f846feb85aea016cbdbfec4c
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Wed Apr 30 00:52:55 2008 -0700

    signals: fold complete_signal() into send_signal/do_send_sigqueue
    
    Factor out complete_signal() callsites.  This change completely unifies the
    helpers sending the specific/group signals.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index fc1cb03c241c..87424f7a4f3d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -826,7 +826,8 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 
 out_set:
 	sigaddset(&pending->signal, sig);
-	return 1;
+	complete_signal(sig, t, group);
+	return 0;
 }
 
 int print_fatal_signals;
@@ -861,17 +862,16 @@ static int __init setup_print_fatal_signals(char *str)
 
 __setup("print-fatal-signals=", setup_print_fatal_signals);
 
+int
+__group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
+{
+	return send_signal(sig, info, p, 1);
+}
+
 static int
 specific_send_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 {
-	int ret;
-
-	ret = send_signal(sig, info, t, 0);
-	if (ret <= 0)
-		return ret;
-
-	complete_signal(sig, t, 0);
-	return 0;
+	return send_signal(sig, info, t, 0);
 }
 
 /*
@@ -914,24 +914,6 @@ force_sig_specific(int sig, struct task_struct *t)
 	force_sig_info(sig, SEND_SIG_FORCED, t);
 }
 
-int
-__group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
-{
-	int ret;
-
-	/*
-	 * Put this signal on the shared-pending queue, or fail with EAGAIN.
-	 * We always use the shared queue for process-wide signals,
-	 * to avoid several races.
-	 */
-	ret = send_signal(sig, info, p, 1);
-	if (ret <= 0)
-		return ret;
-
-	complete_signal(sig, p, 1);
-	return 0;
-}
-
 /*
  * Nuke all other threads in the group.
  */
@@ -1263,6 +1245,7 @@ static int do_send_sigqueue(int sig, struct sigqueue *q, struct task_struct *t,
 {
 	struct sigpending *pending;
 
+	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
 	handle_stop_signal(sig, t);
 
 	if (unlikely(!list_empty(&q->list))) {
@@ -1283,6 +1266,7 @@ static int do_send_sigqueue(int sig, struct sigqueue *q, struct task_struct *t,
 	pending = group ? &t->signal->shared_pending : &t->pending;
 	list_add_tail(&q->list, &pending->list);
 	sigaddset(&pending->signal, sig);
+	complete_signal(sig, t, group);
 
 	return 0;
 }
@@ -1292,8 +1276,6 @@ int send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 	unsigned long flags;
 	int ret = -1;
 
-	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
-
 	/*
 	 * The rcu based delayed sighand destroy makes it possible to
 	 * run this without tasklist lock held. The task struct itself
@@ -1307,8 +1289,6 @@ int send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 
 	ret = do_send_sigqueue(sig, q, p, 0);
 
-	complete_signal(sig, p, 0);
-
 	unlock_task_sighand(p, &flags);
 out_err:
 	return ret;
@@ -1320,15 +1300,11 @@ send_group_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 	unsigned long flags;
 	int ret;
 
-	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
-
 	/* Since it_lock is held, p->sighand cannot be NULL. */
 	spin_lock_irqsave(&p->sighand->siglock, flags);
 
 	ret = do_send_sigqueue(sig, q, p, 1);
 
-	complete_signal(sig, p, 1);
-
 	spin_unlock_irqrestore(&p->sighand->siglock, flags);
 
 	return ret;

commit 5fcd835bf8c2cde06404559b1904e2f1dfcb4567
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:55 2008 -0700

    signals: use __group_complete_signal() for the specific signals too
    
    Based on Pavel Emelyanov's suggestion.
    
    Rename __group_complete_signal() to complete_signal() and use it to process
    the specific signals too.  To do this we simply add the "int group" argument.
    
    This allows us to greatly simply the signal-sending code and adds a useful
    behaviour change.  We can avoid the unneeded wakeups for the private signals
    because wants_signal() is more clever than sigismember(blocked), but more
    importantly we now take into account the fatal specific signals too.
    
    The latter allows us to kill some subtle checks in handle_stop_signal() and
    makes the specific/group signal's behaviour more consistent.  For example,
    currently sigtimedwait(FATAL_SIGNAL) behaves differently depending on was the
    signal sent by kill() or tkill() if the signal was not blocked.
    
    And.  This allows us to tweak/fix the behaviour when the specific signal is
    sent to the dying/dead ->group_leader.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index f2fc3a9ea8fc..fc1cb03c241c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -673,8 +673,7 @@ static inline int wants_signal(int sig, struct task_struct *p)
 	return task_curr(p) || !signal_pending(p);
 }
 
-static void
-__group_complete_signal(int sig, struct task_struct *p)
+static void complete_signal(int sig, struct task_struct *p, int group)
 {
 	struct signal_struct *signal = p->signal;
 	struct task_struct *t;
@@ -687,7 +686,7 @@ __group_complete_signal(int sig, struct task_struct *p)
 	 */
 	if (wants_signal(sig, p))
 		t = p;
-	else if (thread_group_empty(p))
+	else if (!group || thread_group_empty(p))
 		/*
 		 * There is just one thread and it does not need to be woken.
 		 * It will dequeue unblocked signals before it runs again.
@@ -871,8 +870,7 @@ specific_send_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 	if (ret <= 0)
 		return ret;
 
-	if (!sigismember(&t->blocked, sig))
-		signal_wake_up(t, sig == SIGKILL);
+	complete_signal(sig, t, 0);
 	return 0;
 }
 
@@ -930,7 +928,7 @@ __group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 	if (ret <= 0)
 		return ret;
 
-	__group_complete_signal(sig, p);
+	complete_signal(sig, p, 1);
 	return 0;
 }
 
@@ -1309,8 +1307,7 @@ int send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 
 	ret = do_send_sigqueue(sig, q, p, 0);
 
-	if (!sigismember(&p->blocked, sig))
-		signal_wake_up(p, sig == SIGKILL);
+	complete_signal(sig, p, 0);
 
 	unlock_task_sighand(p, &flags);
 out_err:
@@ -1330,7 +1327,7 @@ send_group_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 
 	ret = do_send_sigqueue(sig, q, p, 1);
 
-	__group_complete_signal(sig, p);
+	complete_signal(sig, p, 1);
 
 	spin_unlock_irqrestore(&p->sighand->siglock, flags);
 

commit 2ca3515aa57224edf0151e05a8c9f21a76bf5957
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:54 2008 -0700

    signals: change send_signal/do_send_sigqueue to take "boolean group" parameter
    
    send_signal() is used either with ->pending or with ->signal->shared_pending.
    Change it to take "int group" instead, this argument will be re-used later.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 3479a118ba1c..f2fc3a9ea8fc 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -754,18 +754,21 @@ static inline int legacy_queue(struct sigpending *signals, int sig)
 }
 
 static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
-			struct sigpending *signals)
+			int group)
 {
+	struct sigpending *pending;
 	struct sigqueue *q;
 
 	assert_spin_locked(&t->sighand->siglock);
 	handle_stop_signal(sig, t);
+
+	pending = group ? &t->signal->shared_pending : &t->pending;
 	/*
 	 * Short-circuit ignored signals and support queuing
 	 * exactly one non-rt signal, so that we can get more
 	 * detailed information about the cause of the signal.
 	 */
-	if (sig_ignored(t, sig) || legacy_queue(signals, sig))
+	if (sig_ignored(t, sig) || legacy_queue(pending, sig))
 		return 0;
 
 	/*
@@ -793,7 +796,7 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 					     (is_si_special(info) ||
 					      info->si_code >= 0)));
 	if (q) {
-		list_add_tail(&q->list, &signals->list);
+		list_add_tail(&q->list, &pending->list);
 		switch ((unsigned long) info) {
 		case (unsigned long) SEND_SIG_NOINFO:
 			q->info.si_signo = sig;
@@ -823,7 +826,7 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	}
 
 out_set:
-	sigaddset(&signals->signal, sig);
+	sigaddset(&pending->signal, sig);
 	return 1;
 }
 
@@ -864,7 +867,7 @@ specific_send_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 {
 	int ret;
 
-	ret = send_signal(sig, info, t, &t->pending);
+	ret = send_signal(sig, info, t, 0);
 	if (ret <= 0)
 		return ret;
 
@@ -923,7 +926,7 @@ __group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 	 * We always use the shared queue for process-wide signals,
 	 * to avoid several races.
 	 */
-	ret = send_signal(sig, info, p, &p->signal->shared_pending);
+	ret = send_signal(sig, info, p, 1);
 	if (ret <= 0)
 		return ret;
 
@@ -1258,8 +1261,10 @@ void sigqueue_free(struct sigqueue *q)
 }
 
 static int do_send_sigqueue(int sig, struct sigqueue *q, struct task_struct *t,
-				struct sigpending *pending)
+				int group)
 {
+	struct sigpending *pending;
+
 	handle_stop_signal(sig, t);
 
 	if (unlikely(!list_empty(&q->list))) {
@@ -1277,8 +1282,10 @@ static int do_send_sigqueue(int sig, struct sigqueue *q, struct task_struct *t,
 		return 1;
 
 	signalfd_notify(t, sig);
+	pending = group ? &t->signal->shared_pending : &t->pending;
 	list_add_tail(&q->list, &pending->list);
 	sigaddset(&pending->signal, sig);
+
 	return 0;
 }
 
@@ -1300,7 +1307,7 @@ int send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 	if (!likely(lock_task_sighand(p, &flags)))
 		goto out_err;
 
-	ret = do_send_sigqueue(sig, q, p, &p->pending);
+	ret = do_send_sigqueue(sig, q, p, 0);
 
 	if (!sigismember(&p->blocked, sig))
 		signal_wake_up(p, sig == SIGKILL);
@@ -1321,7 +1328,7 @@ send_group_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 	/* Since it_lock is held, p->sighand cannot be NULL. */
 	spin_lock_irqsave(&p->sighand->siglock, flags);
 
-	ret = do_send_sigqueue(sig, q, p, &p->signal->shared_pending);
+	ret = do_send_sigqueue(sig, q, p, 1);
 
 	__group_complete_signal(sig, p);
 

commit 71f11dc025055cb2ef9226424f26b3287efadd26
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:53 2008 -0700

    signals: move the definition of __group_complete_signal() up
    
    Move the unchanged definition of __group_complete_signal() so that send_signal
    can see it.  To simplify the reading of the next patches.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0298bd3d431b..3479a118ba1c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -652,6 +652,102 @@ static void handle_stop_signal(int sig, struct task_struct *p)
 	}
 }
 
+/*
+ * Test if P wants to take SIG.  After we've checked all threads with this,
+ * it's equivalent to finding no threads not blocking SIG.  Any threads not
+ * blocking SIG were ruled out because they are not running and already
+ * have pending signals.  Such threads will dequeue from the shared queue
+ * as soon as they're available, so putting the signal on the shared queue
+ * will be equivalent to sending it to one such thread.
+ */
+static inline int wants_signal(int sig, struct task_struct *p)
+{
+	if (sigismember(&p->blocked, sig))
+		return 0;
+	if (p->flags & PF_EXITING)
+		return 0;
+	if (sig == SIGKILL)
+		return 1;
+	if (task_is_stopped_or_traced(p))
+		return 0;
+	return task_curr(p) || !signal_pending(p);
+}
+
+static void
+__group_complete_signal(int sig, struct task_struct *p)
+{
+	struct signal_struct *signal = p->signal;
+	struct task_struct *t;
+
+	/*
+	 * Now find a thread we can wake up to take the signal off the queue.
+	 *
+	 * If the main thread wants the signal, it gets first crack.
+	 * Probably the least surprising to the average bear.
+	 */
+	if (wants_signal(sig, p))
+		t = p;
+	else if (thread_group_empty(p))
+		/*
+		 * There is just one thread and it does not need to be woken.
+		 * It will dequeue unblocked signals before it runs again.
+		 */
+		return;
+	else {
+		/*
+		 * Otherwise try to find a suitable thread.
+		 */
+		t = signal->curr_target;
+		while (!wants_signal(sig, t)) {
+			t = next_thread(t);
+			if (t == signal->curr_target)
+				/*
+				 * No thread needs to be woken.
+				 * Any eligible threads will see
+				 * the signal in the queue soon.
+				 */
+				return;
+		}
+		signal->curr_target = t;
+	}
+
+	/*
+	 * Found a killable thread.  If the signal will be fatal,
+	 * then start taking the whole group down immediately.
+	 */
+	if (sig_fatal(p, sig) && !(signal->flags & SIGNAL_GROUP_EXIT) &&
+	    !sigismember(&t->real_blocked, sig) &&
+	    (sig == SIGKILL || !(t->ptrace & PT_PTRACED))) {
+		/*
+		 * This signal will be fatal to the whole group.
+		 */
+		if (!sig_kernel_coredump(sig)) {
+			/*
+			 * Start a group exit and wake everybody up.
+			 * This way we don't have other threads
+			 * running and doing things after a slower
+			 * thread has the fatal signal pending.
+			 */
+			signal->flags = SIGNAL_GROUP_EXIT;
+			signal->group_exit_code = sig;
+			signal->group_stop_count = 0;
+			t = p;
+			do {
+				sigaddset(&t->pending.signal, SIGKILL);
+				signal_wake_up(t, 1);
+			} while_each_thread(p, t);
+			return;
+		}
+	}
+
+	/*
+	 * The signal is already in the shared-pending queue.
+	 * Tell the chosen thread to wake up and dequeue it.
+	 */
+	signal_wake_up(t, sig == SIGKILL);
+	return;
+}
+
 static inline int legacy_queue(struct sigpending *signals, int sig)
 {
 	return (sig < SIGRTMIN) && sigismember(&signals->signal, sig);
@@ -817,102 +913,6 @@ force_sig_specific(int sig, struct task_struct *t)
 	force_sig_info(sig, SEND_SIG_FORCED, t);
 }
 
-/*
- * Test if P wants to take SIG.  After we've checked all threads with this,
- * it's equivalent to finding no threads not blocking SIG.  Any threads not
- * blocking SIG were ruled out because they are not running and already
- * have pending signals.  Such threads will dequeue from the shared queue
- * as soon as they're available, so putting the signal on the shared queue
- * will be equivalent to sending it to one such thread.
- */
-static inline int wants_signal(int sig, struct task_struct *p)
-{
-	if (sigismember(&p->blocked, sig))
-		return 0;
-	if (p->flags & PF_EXITING)
-		return 0;
-	if (sig == SIGKILL)
-		return 1;
-	if (task_is_stopped_or_traced(p))
-		return 0;
-	return task_curr(p) || !signal_pending(p);
-}
-
-static void
-__group_complete_signal(int sig, struct task_struct *p)
-{
-	struct signal_struct *signal = p->signal;
-	struct task_struct *t;
-
-	/*
-	 * Now find a thread we can wake up to take the signal off the queue.
-	 *
-	 * If the main thread wants the signal, it gets first crack.
-	 * Probably the least surprising to the average bear.
-	 */
-	if (wants_signal(sig, p))
-		t = p;
-	else if (thread_group_empty(p))
-		/*
-		 * There is just one thread and it does not need to be woken.
-		 * It will dequeue unblocked signals before it runs again.
-		 */
-		return;
-	else {
-		/*
-		 * Otherwise try to find a suitable thread.
-		 */
-		t = signal->curr_target;
-		while (!wants_signal(sig, t)) {
-			t = next_thread(t);
-			if (t == signal->curr_target)
-				/*
-				 * No thread needs to be woken.
-				 * Any eligible threads will see
-				 * the signal in the queue soon.
-				 */
-				return;
-		}
-		signal->curr_target = t;
-	}
-
-	/*
-	 * Found a killable thread.  If the signal will be fatal,
-	 * then start taking the whole group down immediately.
-	 */
-	if (sig_fatal(p, sig) && !(signal->flags & SIGNAL_GROUP_EXIT) &&
-	    !sigismember(&t->real_blocked, sig) &&
-	    (sig == SIGKILL || !(t->ptrace & PT_PTRACED))) {
-		/*
-		 * This signal will be fatal to the whole group.
-		 */
-		if (!sig_kernel_coredump(sig)) {
-			/*
-			 * Start a group exit and wake everybody up.
-			 * This way we don't have other threads
-			 * running and doing things after a slower
-			 * thread has the fatal signal pending.
-			 */
-			signal->flags = SIGNAL_GROUP_EXIT;
-			signal->group_exit_code = sig;
-			signal->group_stop_count = 0;
-			t = p;
-			do {
-				sigaddset(&t->pending.signal, SIGKILL);
-				signal_wake_up(t, 1);
-			} while_each_thread(p, t);
-			return;
-		}
-	}
-
-	/*
-	 * The signal is already in the shared-pending queue.
-	 * Tell the chosen thread to wake up and dequeue it.
-	 */
-	signal_wake_up(t, sig == SIGKILL);
-	return;
-}
-
 int
 __group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 {

commit db51aeccd7097ce19a522a4c5ff91c320f870e2b
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:52 2008 -0700

    signals: microoptimize the usage of ->curr_target
    
    Suggested by Roland McGrath.
    
    Initialize signal->curr_target in copy_signal().  This way ->curr_target is
    never == NULL, we can kill the check in __group_complete_signal's hot path.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 17859f0d8411..0298bd3d431b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -863,10 +863,6 @@ __group_complete_signal(int sig, struct task_struct *p)
 		 * Otherwise try to find a suitable thread.
 		 */
 		t = signal->curr_target;
-		if (t == NULL)
-			/* restart balancing at this thread */
-			t = signal->curr_target = p;
-
 		while (!wants_signal(sig, t)) {
 			t = next_thread(t);
 			if (t == signal->curr_target)

commit 08d2c30ce98d274137f12b0a9b9c74137455922c
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:51 2008 -0700

    signals: send_sig_info: don't take tasklist_lock
    
    The comment in send_sig_info() is wrong, tasklist_lock can't help.
    
    The caller must ensure the task can't go away, otherwise ->sighand can be NULL
    even before we take the lock.
    
    p->sighand could be changed by exec(), but I can't imagine how it is possible
    to prevent exit(), but not exec().
    
    Since the things seem to work, I assume all callers are correct.  However,
    drm_vbl_send_signals() looks broken.  block_all_signals() which is solely used
    by drm is definitely broken.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 13371d17358d..17859f0d8411 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1138,8 +1138,7 @@ static int kill_something_info(int sig, struct siginfo *info, int pid)
  */
 
 /*
- * These two are the most common entry points.  They send a signal
- * just to the specific thread.
+ * The caller must ensure the task can't exit.
  */
 int
 send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
@@ -1154,17 +1153,9 @@ send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 	if (!valid_signal(sig))
 		return -EINVAL;
 
-	/*
-	 * We need the tasklist lock even for the specific
-	 * thread case (when we don't need to follow the group
-	 * lists) in order to avoid races with "p->sighand"
-	 * going away or changing from under us.
-	 */
-	read_lock(&tasklist_lock);  
 	spin_lock_irqsave(&p->sighand->siglock, flags);
 	ret = specific_send_sig_info(sig, info, p);
 	spin_unlock_irqrestore(&p->sighand->siglock, flags);
-	read_unlock(&tasklist_lock);
 	return ret;
 }
 

commit 3547ff3aefbe092ca35506c60c02e2d17a4f2199
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:51 2008 -0700

    signals: do_tkill: don't use tasklist_lock
    
    Convert do_tkill() to use rcu_read_lock() + lock_task_sighand() to avoid
    taking tasklist lock.
    
    Note that we don't return an error if lock_task_sighand() fails, we pretend
    the task dies after receiving the signal.  Otherwise, we should fight with the
    nasty races with mt-exec without having any advantage.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index b3dedf1f9323..13371d17358d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2219,6 +2219,7 @@ static int do_tkill(int tgid, int pid, int sig)
 	int error;
 	struct siginfo info;
 	struct task_struct *p;
+	unsigned long flags;
 
 	error = -ESRCH;
 	info.si_signo = sig;
@@ -2227,21 +2228,24 @@ static int do_tkill(int tgid, int pid, int sig)
 	info.si_pid = task_tgid_vnr(current);
 	info.si_uid = current->uid;
 
-	read_lock(&tasklist_lock);
+	rcu_read_lock();
 	p = find_task_by_vpid(pid);
 	if (p && (tgid <= 0 || task_tgid_vnr(p) == tgid)) {
 		error = check_kill_permission(sig, &info, p);
 		/*
 		 * The null signal is a permissions and process existence
 		 * probe.  No signal is actually delivered.
+		 *
+		 * If lock_task_sighand() fails we pretend the task dies
+		 * after receiving the signal. The window is tiny, and the
+		 * signal is private anyway.
 		 */
-		if (!error && sig && p->sighand) {
-			spin_lock_irq(&p->sighand->siglock);
+		if (!error && sig && lock_task_sighand(p, &flags)) {
 			error = specific_send_sig_info(sig, &info, p);
-			spin_unlock_irq(&p->sighand->siglock);
+			unlock_task_sighand(p, &flags);
 		}
 	}
-	read_unlock(&tasklist_lock);
+	rcu_read_unlock();
 
 	return error;
 }

commit 6e65acba7ca8169e38ab55d62d52f29a75fb141f
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:50 2008 -0700

    signals: move handle_stop_signal() into send_signal()
    
    Move handle_stop_signal() into send_signal().  This factors out a couple of
    callsites and allows us to do further unifications.
    
    Also, with this change specific_send_sig_info() does handle_stop_signal().
    Not that this is really important, we never send STOP/CONT via send_sig() and
    friends, but still this looks more consistent.
    
    The only (afaics) special case is get_signal_to_deliver().  If the traced task
    dequeues SIGCONT, it can re-send it to itself after ptrace_stop() if the
    signal was blocked by debugger.  In that case handle_stop_signal() is
    unnecessary, but hopefully not a problem.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index db442c59219e..b3dedf1f9323 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -660,8 +660,10 @@ static inline int legacy_queue(struct sigpending *signals, int sig)
 static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			struct sigpending *signals)
 {
-	struct sigqueue * q = NULL;
+	struct sigqueue *q;
 
+	assert_spin_locked(&t->sighand->siglock);
+	handle_stop_signal(sig, t);
 	/*
 	 * Short-circuit ignored signals and support queuing
 	 * exactly one non-rt signal, so that we can get more
@@ -766,9 +768,6 @@ specific_send_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 {
 	int ret;
 
-	BUG_ON(!irqs_disabled());
-	assert_spin_locked(&t->sighand->siglock);
-
 	ret = send_signal(sig, info, t, &t->pending);
 	if (ret <= 0)
 		return ret;
@@ -923,9 +922,6 @@ __group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 {
 	int ret;
 
-	assert_spin_locked(&p->sighand->siglock);
-	handle_stop_signal(sig, p);
-
 	/*
 	 * Put this signal on the shared-pending queue, or fail with EAGAIN.
 	 * We always use the shared queue for process-wide signals,
@@ -2241,7 +2237,6 @@ static int do_tkill(int tgid, int pid, int sig)
 		 */
 		if (!error && sig && p->sighand) {
 			spin_lock_irq(&p->sighand->siglock);
-			handle_stop_signal(sig, p);
 			error = specific_send_sig_info(sig, &info, p);
 			spin_unlock_irq(&p->sighand->siglock);
 		}

commit c99fcf28b87d8cab592db7571e3164f5cb54c5b3
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:49 2008 -0700

    signals: send_group_sigqueue: don't take tasklist_lock
    
    handle_stop_signal() was changed, now send_group_sigqueue() doesn't need
    tasklist_lock.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2a06f2441805..db442c59219e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1335,7 +1335,6 @@ send_group_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 
 	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
 
-	read_lock(&tasklist_lock);
 	/* Since it_lock is held, p->sighand cannot be NULL. */
 	spin_lock_irqsave(&p->sighand->siglock, flags);
 
@@ -1344,7 +1343,7 @@ send_group_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 	__group_complete_signal(sig, p);
 
 	spin_unlock_irqrestore(&p->sighand->siglock, flags);
-	read_unlock(&tasklist_lock);
+
 	return ret;
 }
 

commit f8c5b5c06f63fe9aaebefbf9f0b79909066b1b6c
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:49 2008 -0700

    signals: __group_complete_signal: cache the value of p->signal
    
    Cosmetic, cache p->signal to make the code a bit more readable.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8259262eaa60..2a06f2441805 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -842,6 +842,7 @@ static inline int wants_signal(int sig, struct task_struct *p)
 static void
 __group_complete_signal(int sig, struct task_struct *p)
 {
+	struct signal_struct *signal = p->signal;
 	struct task_struct *t;
 
 	/*
@@ -862,14 +863,14 @@ __group_complete_signal(int sig, struct task_struct *p)
 		/*
 		 * Otherwise try to find a suitable thread.
 		 */
-		t = p->signal->curr_target;
+		t = signal->curr_target;
 		if (t == NULL)
 			/* restart balancing at this thread */
-			t = p->signal->curr_target = p;
+			t = signal->curr_target = p;
 
 		while (!wants_signal(sig, t)) {
 			t = next_thread(t);
-			if (t == p->signal->curr_target)
+			if (t == signal->curr_target)
 				/*
 				 * No thread needs to be woken.
 				 * Any eligible threads will see
@@ -877,14 +878,14 @@ __group_complete_signal(int sig, struct task_struct *p)
 				 */
 				return;
 		}
-		p->signal->curr_target = t;
+		signal->curr_target = t;
 	}
 
 	/*
 	 * Found a killable thread.  If the signal will be fatal,
 	 * then start taking the whole group down immediately.
 	 */
-	if (sig_fatal(p, sig) && !(p->signal->flags & SIGNAL_GROUP_EXIT) &&
+	if (sig_fatal(p, sig) && !(signal->flags & SIGNAL_GROUP_EXIT) &&
 	    !sigismember(&t->real_blocked, sig) &&
 	    (sig == SIGKILL || !(t->ptrace & PT_PTRACED))) {
 		/*
@@ -897,9 +898,9 @@ __group_complete_signal(int sig, struct task_struct *p)
 			 * running and doing things after a slower
 			 * thread has the fatal signal pending.
 			 */
-			p->signal->flags = SIGNAL_GROUP_EXIT;
-			p->signal->group_exit_code = sig;
-			p->signal->group_stop_count = 0;
+			signal->flags = SIGNAL_GROUP_EXIT;
+			signal->group_exit_code = sig;
+			signal->group_stop_count = 0;
 			t = p;
 			do {
 				sigaddset(&t->pending.signal, SIGKILL);

commit 5fc894bb4fb1de8373d1d5fb6db19204a16859e8
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:48 2008 -0700

    signals: send_sigqueue: don't forget about handle_stop_signal()
    
    send_group_sigqueue() calls handle_stop_signal(), send_sigqueue() doesn't.
    This is not consistent and in fact I'd say this is (minor) bug.
    
    Move handle_stop_signal() from send_group_sigqueue() to do_send_sigqueue(),
    the latter is called by send_sigqueue() too.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0a8b0aece80d..8259262eaa60 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1274,8 +1274,10 @@ void sigqueue_free(struct sigqueue *q)
 }
 
 static int do_send_sigqueue(int sig, struct sigqueue *q, struct task_struct *t,
-		struct sigpending *pending)
+				struct sigpending *pending)
 {
+	handle_stop_signal(sig, t);
+
 	if (unlikely(!list_empty(&q->list))) {
 		/*
 		 * If an SI_TIMER entry is already queue just increment
@@ -1335,7 +1337,6 @@ send_group_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 	read_lock(&tasklist_lock);
 	/* Since it_lock is held, p->sighand cannot be NULL. */
 	spin_lock_irqsave(&p->sighand->siglock, flags);
-	handle_stop_signal(sig, p);
 
 	ret = do_send_sigqueue(sig, q, p, &p->signal->shared_pending);
 

commit 5c193e8871b76f3bf8ed1e31f7af7c70890ebc4f
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:48 2008 -0700

    signals: send_sigqueue: don't take rcu lock
    
    lock_task_sighand() was changed, send_sigqueue() doesn't need rcu_read_lock()
    any longer.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index f92e6298930c..0a8b0aece80d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1311,8 +1311,6 @@ int send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 	 * We return -1, when the task is marked exiting, so
 	 * posix_timer_event can redirect it to the group leader
 	 */
-	rcu_read_lock();
-
 	if (!likely(lock_task_sighand(p, &flags)))
 		goto out_err;
 
@@ -1323,8 +1321,6 @@ int send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 
 	unlock_task_sighand(p, &flags);
 out_err:
-	rcu_read_unlock();
-
 	return ret;
 }
 

commit f6b76d4fb0039e077824be85ed4ac94e96beef86
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:47 2008 -0700

    get_signal_to_deliver: use the cached ->signal/sighand values
    
    Cache the values of current->signal/sighand.  Shrinks .text a bit and makes
    the code more readable.  Also, remove "sigset_t *mask", it is pointless
    because in fact we save the constant offset.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index b266fa46402a..f92e6298930c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1753,8 +1753,9 @@ static int ptrace_signal(int signr, siginfo_t *info,
 int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 			  struct pt_regs *regs, void *cookie)
 {
-	sigset_t *mask = &current->blocked;
-	int signr = 0;
+	struct sighand_struct *sighand = current->sighand;
+	struct signal_struct *signal = current->signal;
+	int signr;
 
 relock:
 	/*
@@ -1765,13 +1766,13 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 	 */
 	try_to_freeze();
 
-	spin_lock_irq(&current->sighand->siglock);
+	spin_lock_irq(&sighand->siglock);
 
-	if (unlikely(current->signal->flags & SIGNAL_CLD_MASK)) {
-		int why = (current->signal->flags & SIGNAL_STOP_CONTINUED)
+	if (unlikely(signal->flags & SIGNAL_CLD_MASK)) {
+		int why = (signal->flags & SIGNAL_STOP_CONTINUED)
 				? CLD_CONTINUED : CLD_STOPPED;
-		current->signal->flags &= ~SIGNAL_CLD_MASK;
-		spin_unlock_irq(&current->sighand->siglock);
+		signal->flags &= ~SIGNAL_CLD_MASK;
+		spin_unlock_irq(&sighand->siglock);
 
 		read_lock(&tasklist_lock);
 		do_notify_parent_cldstop(current->group_leader, why);
@@ -1782,12 +1783,11 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 	for (;;) {
 		struct k_sigaction *ka;
 
-		if (unlikely(current->signal->group_stop_count > 0) &&
+		if (unlikely(signal->group_stop_count > 0) &&
 		    do_signal_stop(0))
 			goto relock;
 
-		signr = dequeue_signal(current, mask, info);
-
+		signr = dequeue_signal(current, &current->blocked, info);
 		if (!signr)
 			break; /* will return 0 */
 
@@ -1797,7 +1797,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 				continue;
 		}
 
-		ka = &current->sighand->action[signr-1];
+		ka = &sighand->action[signr-1];
 		if (ka->sa.sa_handler == SIG_IGN) /* Do nothing.  */
 			continue;
 		if (ka->sa.sa_handler != SIG_DFL) {
@@ -1834,14 +1834,14 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 			 * We need to check for that and bail out if necessary.
 			 */
 			if (signr != SIGSTOP) {
-				spin_unlock_irq(&current->sighand->siglock);
+				spin_unlock_irq(&sighand->siglock);
 
 				/* signals can be posted during this window */
 
 				if (is_current_pgrp_orphaned())
 					goto relock;
 
-				spin_lock_irq(&current->sighand->siglock);
+				spin_lock_irq(&sighand->siglock);
 			}
 
 			if (likely(do_signal_stop(signr))) {
@@ -1856,7 +1856,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 			continue;
 		}
 
-		spin_unlock_irq(&current->sighand->siglock);
+		spin_unlock_irq(&sighand->siglock);
 
 		/*
 		 * Anything else is fatal, maybe with a core dump.
@@ -1882,7 +1882,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		do_group_exit(signr);
 		/* NOTREACHED */
 	}
-	spin_unlock_irq(&current->sighand->siglock);
+	spin_unlock_irq(&sighand->siglock);
 	return signr;
 }
 

commit ad16a4606939ce1bedb79c87e412467be803e990
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:46 2008 -0700

    handle_stop_signal: use the cached p->signal value
    
    Cache the value of p->signal, and change the code to use while_each_thread()
    helper.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index dee8cc927a63..b266fa46402a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -566,9 +566,10 @@ static void do_notify_parent_cldstop(struct task_struct *tsk, int why);
  */
 static void handle_stop_signal(int sig, struct task_struct *p)
 {
+	struct signal_struct *signal = p->signal;
 	struct task_struct *t;
 
-	if (p->signal->flags & SIGNAL_GROUP_EXIT)
+	if (signal->flags & SIGNAL_GROUP_EXIT)
 		/*
 		 * The process is in the middle of dying already.
 		 */
@@ -578,19 +579,18 @@ static void handle_stop_signal(int sig, struct task_struct *p)
 		/*
 		 * This is a stop signal.  Remove SIGCONT from all queues.
 		 */
-		rm_from_queue(sigmask(SIGCONT), &p->signal->shared_pending);
+		rm_from_queue(sigmask(SIGCONT), &signal->shared_pending);
 		t = p;
 		do {
 			rm_from_queue(sigmask(SIGCONT), &t->pending);
-			t = next_thread(t);
-		} while (t != p);
+		} while_each_thread(p, t);
 	} else if (sig == SIGCONT) {
 		unsigned int why;
 		/*
 		 * Remove all stop signals from all queues,
 		 * and wake all threads.
 		 */
-		rm_from_queue(SIG_KERNEL_STOP_MASK, &p->signal->shared_pending);
+		rm_from_queue(SIG_KERNEL_STOP_MASK, &signal->shared_pending);
 		t = p;
 		do {
 			unsigned int state;
@@ -615,9 +615,7 @@ static void handle_stop_signal(int sig, struct task_struct *p)
 				state |= TASK_INTERRUPTIBLE;
 			}
 			wake_up_state(t, state);
-
-			t = next_thread(t);
-		} while (t != p);
+		} while_each_thread(p, t);
 
 		/*
 		 * Notify the parent with CLD_CONTINUED if we were stopped.
@@ -628,29 +626,29 @@ static void handle_stop_signal(int sig, struct task_struct *p)
 		 * CLD_CONTINUED was dropped.
 		 */
 		why = 0;
-		if (p->signal->flags & SIGNAL_STOP_STOPPED)
+		if (signal->flags & SIGNAL_STOP_STOPPED)
 			why |= SIGNAL_CLD_CONTINUED;
-		else if (p->signal->group_stop_count)
+		else if (signal->group_stop_count)
 			why |= SIGNAL_CLD_STOPPED;
 
 		if (why) {
-			p->signal->flags = why | SIGNAL_STOP_CONTINUED;
-			p->signal->group_stop_count = 0;
-			p->signal->group_exit_code = 0;
+			signal->flags = why | SIGNAL_STOP_CONTINUED;
+			signal->group_stop_count = 0;
+			signal->group_exit_code = 0;
 		} else {
 			/*
 			 * We are not stopped, but there could be a stop
 			 * signal in the middle of being processed after
 			 * being removed from the queue.  Clear that too.
 			 */
-			p->signal->flags &= ~SIGNAL_STOP_DEQUEUED;
+			signal->flags &= ~SIGNAL_STOP_DEQUEUED;
 		}
 	} else if (sig == SIGKILL) {
 		/*
 		 * Make sure that any pending stop signal already dequeued
 		 * is undone by the wakeup for SIGKILL.
 		 */
-		p->signal->flags &= ~SIGNAL_STOP_DEQUEUED;
+		signal->flags &= ~SIGNAL_STOP_DEQUEUED;
 	}
 }
 

commit fc321d2e60d6f4eee17206612d0b50519f526daf
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:46 2008 -0700

    handle_stop_signal: unify partial/full stop handling
    
    Now that handle_stop_signal() doesn't drop ->siglock, we can't see both
    ->group_stop_count && SIGNAL_STOP_STOPPED.  Merge two "if" branches.
    
    As Roland pointed out, we never actually needed 2 do_notify_parent_cldstop()
    calls.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index ce53ab19c21d..dee8cc927a63 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -585,33 +585,16 @@ static void handle_stop_signal(int sig, struct task_struct *p)
 			t = next_thread(t);
 		} while (t != p);
 	} else if (sig == SIGCONT) {
+		unsigned int why;
 		/*
 		 * Remove all stop signals from all queues,
 		 * and wake all threads.
 		 */
-		if (unlikely(p->signal->group_stop_count > 0)) {
-			/*
-			 * There was a group stop in progress.  We'll
-			 * pretend it finished before we got here.  We are
-			 * obliged to report it to the parent: if the
-			 * SIGSTOP happened "after" this SIGCONT, then it
-			 * would have cleared this pending SIGCONT.  If it
-			 * happened "before" this SIGCONT, then the parent
-			 * got the SIGCHLD about the stop finishing before
-			 * the continue happened.  We do the notification
-			 * now, and it's as if the stop had finished and
-			 * the SIGCHLD was pending on entry to this kill.
-			 */
-			p->signal->group_stop_count = 0;
-			p->signal->flags = SIGNAL_STOP_CONTINUED |
-						SIGNAL_CLD_STOPPED;
-		}
 		rm_from_queue(SIG_KERNEL_STOP_MASK, &p->signal->shared_pending);
 		t = p;
 		do {
 			unsigned int state;
 			rm_from_queue(SIG_KERNEL_STOP_MASK, &t->pending);
-			
 			/*
 			 * If there is a handler for SIGCONT, we must make
 			 * sure that no thread returns to user mode before
@@ -621,7 +604,7 @@ static void handle_stop_signal(int sig, struct task_struct *p)
 			 * running the handler.  With the TIF_SIGPENDING
 			 * flag set, the thread will pause and acquire the
 			 * siglock that we hold now and until we've queued
-			 * the pending signal. 
+			 * the pending signal.
 			 *
 			 * Wake up the stopped thread _after_ setting
 			 * TIF_SIGPENDING
@@ -636,13 +619,23 @@ static void handle_stop_signal(int sig, struct task_struct *p)
 			t = next_thread(t);
 		} while (t != p);
 
-		if (p->signal->flags & SIGNAL_STOP_STOPPED) {
-			/*
-			 * We were in fact stopped, and are now continued.
-			 * Notify the parent with CLD_CONTINUED.
-			 */
-			p->signal->flags = SIGNAL_STOP_CONTINUED |
-						SIGNAL_CLD_CONTINUED;
+		/*
+		 * Notify the parent with CLD_CONTINUED if we were stopped.
+		 *
+		 * If we were in the middle of a group stop, we pretend it
+		 * was already finished, and then continued. Since SIGCHLD
+		 * doesn't queue we report only CLD_STOPPED, as if the next
+		 * CLD_CONTINUED was dropped.
+		 */
+		why = 0;
+		if (p->signal->flags & SIGNAL_STOP_STOPPED)
+			why |= SIGNAL_CLD_CONTINUED;
+		else if (p->signal->group_stop_count)
+			why |= SIGNAL_CLD_STOPPED;
+
+		if (why) {
+			p->signal->flags = why | SIGNAL_STOP_CONTINUED;
+			p->signal->group_stop_count = 0;
 			p->signal->group_exit_code = 0;
 		} else {
 			/*

commit 6ca25b551309eb1b1b41f83414a92f7472e0b23d
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:45 2008 -0700

    kill_pid_info: don't take now unneeded tasklist_lock
    
    Previously handle_stop_signal(SIGCONT) could drop ->siglock.  That is why
    kill_pid_info(SIGCONT) takes tasklist_lock to make sure the target task can't
    go away after unlock.  Not needed now.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 115c04f3f143..ce53ab19c21d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1039,9 +1039,6 @@ int kill_pid_info(int sig, struct siginfo *info, struct pid *pid)
 	struct task_struct *p;
 
 	rcu_read_lock();
-	if (unlikely(sig_needs_tasklist(sig)))
-		read_lock(&tasklist_lock);
-
 retry:
 	p = pid_task(pid, PIDTYPE_PID);
 	if (p) {
@@ -1055,10 +1052,8 @@ int kill_pid_info(int sig, struct siginfo *info, struct pid *pid)
 			 */
 			goto retry;
 	}
-
-	if (unlikely(sig_needs_tasklist(sig)))
-		read_unlock(&tasklist_lock);
 	rcu_read_unlock();
+
 	return error;
 }
 

commit e442055193e4584218006e616c9bdce0c5e9ae5c
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:44 2008 -0700

    signals: re-assign CLD_CONTINUED notification from the sender to reciever
    
    Based on discussion with Jiri and Roland.
    
    In short: currently handle_stop_signal(SIGCONT, p) sends the notification to
    p->parent, with this patch p itself notifies its parent when it becomes
    running.
    
    handle_stop_signal(SIGCONT) has to drop ->siglock temporary in order to notify
    the parent with do_notify_parent_cldstop().  This leads to multiple problems:
    
            - as Jiri Kosina pointed out, the stopped task can resume without
              actually seeing SIGCONT which may have a handler.
    
            - we race with another sig_kernel_stop() signal which may come in
              that window.
    
            - we race with sig_fatal() signals which may set SIGNAL_GROUP_EXIT
              in that window.
    
            - we can't avoid taking tasklist_lock() while sending SIGCONT.
    
    With this patch handle_stop_signal() just sets the new SIGNAL_CLD_CONTINUED
    flag in p->signal->flags and returns.  The notification is sent by the first
    task which returns from finish_stop() (there should be at least one) or any
    other signalled thread from get_signal_to_deliver().
    
    This is a user-visible change.  Say, currently kill(SIGCONT, stopped_child)
    can't return without seeing SIGCHLD, with this patch SIGCHLD can be delayed
    unpredictably.  Another difference is that if the child is ptraced by another
    process, CLD_CONTINUED may be delivered to ->real_parent after ptrace_detach()
    while currently it always goes to the tracer which doesn't actually need this
    notification.  Hopefully not a problem.
    
    The patch asks for the futher obvious cleanups, I'll send them separately.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 91d57f89f5a5..115c04f3f143 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -603,10 +603,8 @@ static void handle_stop_signal(int sig, struct task_struct *p)
 			 * the SIGCHLD was pending on entry to this kill.
 			 */
 			p->signal->group_stop_count = 0;
-			p->signal->flags = SIGNAL_STOP_CONTINUED;
-			spin_unlock(&p->sighand->siglock);
-			do_notify_parent_cldstop(p, CLD_STOPPED);
-			spin_lock(&p->sighand->siglock);
+			p->signal->flags = SIGNAL_STOP_CONTINUED |
+						SIGNAL_CLD_STOPPED;
 		}
 		rm_from_queue(SIG_KERNEL_STOP_MASK, &p->signal->shared_pending);
 		t = p;
@@ -643,25 +641,23 @@ static void handle_stop_signal(int sig, struct task_struct *p)
 			 * We were in fact stopped, and are now continued.
 			 * Notify the parent with CLD_CONTINUED.
 			 */
-			p->signal->flags = SIGNAL_STOP_CONTINUED;
+			p->signal->flags = SIGNAL_STOP_CONTINUED |
+						SIGNAL_CLD_CONTINUED;
 			p->signal->group_exit_code = 0;
-			spin_unlock(&p->sighand->siglock);
-			do_notify_parent_cldstop(p, CLD_CONTINUED);
-			spin_lock(&p->sighand->siglock);
 		} else {
 			/*
 			 * We are not stopped, but there could be a stop
 			 * signal in the middle of being processed after
 			 * being removed from the queue.  Clear that too.
 			 */
-			p->signal->flags = 0;
+			p->signal->flags &= ~SIGNAL_STOP_DEQUEUED;
 		}
 	} else if (sig == SIGKILL) {
 		/*
 		 * Make sure that any pending stop signal already dequeued
 		 * is undone by the wakeup for SIGKILL.
 		 */
-		p->signal->flags = 0;
+		p->signal->flags &= ~SIGNAL_STOP_DEQUEUED;
 	}
 }
 
@@ -1784,6 +1780,19 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 	try_to_freeze();
 
 	spin_lock_irq(&current->sighand->siglock);
+
+	if (unlikely(current->signal->flags & SIGNAL_CLD_MASK)) {
+		int why = (current->signal->flags & SIGNAL_STOP_CONTINUED)
+				? CLD_CONTINUED : CLD_STOPPED;
+		current->signal->flags &= ~SIGNAL_CLD_MASK;
+		spin_unlock_irq(&current->sighand->siglock);
+
+		read_lock(&tasklist_lock);
+		do_notify_parent_cldstop(current->group_leader, why);
+		read_unlock(&tasklist_lock);
+		goto relock;
+	}
+
 	for (;;) {
 		struct k_sigaction *ka;
 

commit 3b5e9e53c6f31b5a5a0f5c43707503c62bdefa46
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:42 2008 -0700

    signals: cleanup security_task_kill() usage/implementation
    
    Every implementation of ->task_kill() does nothing when the signal comes from
    the kernel.  This is correct, but means that check_kill_permission() should
    call security_task_kill() only for SI_FROMUSER() case, and we can remove the
    same check from ->task_kill() implementations.
    
    (sadly, check_kill_permission() is the last user of signal->session/__session
     but we can't s/task_session_nr/task_session/ here).
    
    NOTE: Eric W.  Biederman pointed out cap_task_kill() should die, and I think
    he is very right.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Casey Schaufler <casey@schaufler-ca.com>
    Cc: David Quigley <dpquigl@tycho.nsa.gov>
    Cc: Eric Paris <eparis@redhat.com>
    Cc: Harald Welte <laforge@gnumonks.org>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index f9a52c721274..91d57f89f5a5 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -533,22 +533,23 @@ static int rm_from_queue(unsigned long mask, struct sigpending *s)
 static int check_kill_permission(int sig, struct siginfo *info,
 				 struct task_struct *t)
 {
-	int error = -EINVAL;
+	int error;
+
 	if (!valid_signal(sig))
-		return error;
+		return -EINVAL;
 
-	if (info == SEND_SIG_NOINFO || (!is_si_special(info) && SI_FROMUSER(info))) {
-		error = audit_signal_info(sig, t); /* Let audit system see the signal */
-		if (error)
-			return error;
-		error = -EPERM;
-		if (((sig != SIGCONT) ||
-			(task_session_nr(current) != task_session_nr(t)))
-		    && (current->euid ^ t->suid) && (current->euid ^ t->uid)
-		    && (current->uid ^ t->suid) && (current->uid ^ t->uid)
-		    && !capable(CAP_KILL))
+	if (info != SEND_SIG_NOINFO && (is_si_special(info) || SI_FROMKERNEL(info)))
+		return 0;
+
+	error = audit_signal_info(sig, t); /* Let audit system see the signal */
+	if (error)
 		return error;
-	}
+
+	if (((sig != SIGCONT) || (task_session_nr(current) != task_session_nr(t)))
+	    && (current->euid ^ t->suid) && (current->euid ^ t->uid)
+	    && (current->uid ^ t->suid) && (current->uid ^ t->uid)
+	    && !capable(CAP_KILL))
+		return -EPERM;
 
 	return security_task_kill(t, info, sig, 0);
 }

commit 9e3bd6c3fb2334be171e69b432039cd18bce4458
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Wed Apr 30 00:52:41 2008 -0700

    signals: consolidate send_sigqueue and send_group_sigqueue
    
    Both functions do the same thing after proper locking, but with
    different sigpending structs, so move the common code into a helper.
    
    After this we have 4 places that look very similar: send_sigqueue: calls
    do_send_sigqueue and signal_wakeup send_group_sigqueue: calls
    do_send_sigqueue and __group_complete_signal __group_send_sig_info:
    calls send_signal and __group_complete_signal specific_send_sig_info:
    calls send_signal and signal_wakeup
    
    Besides, send_signal performs actions similar to do_send_sigqueue's
    and __group_complete_signal - to signal_wakeup.
    
    It looks like they can be consolidated gracefully.
    
    Oleg said:
    
      Personally, I think this change is very good.  But send_sigqueue() and
      send_group_sigqueue() have a very subtle difference which I was never able
      to understand.
    
      Let's suppose that sigqueue is already queued, and the signal is ignored
      (the latter means we should re-schedule cpu timer or handle overrruns).  In
      that case send_sigqueue() returns 0, but send_group_sigqueue() returns 1.
    
      I think this is not the problem (in fact, I think this patch makes the
      behaviour more correct), but I hope Thomas can take a look and confirm.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 6610a95506b3..f9a52c721274 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1290,10 +1290,33 @@ void sigqueue_free(struct sigqueue *q)
 	__sigqueue_free(q);
 }
 
+static int do_send_sigqueue(int sig, struct sigqueue *q, struct task_struct *t,
+		struct sigpending *pending)
+{
+	if (unlikely(!list_empty(&q->list))) {
+		/*
+		 * If an SI_TIMER entry is already queue just increment
+		 * the overrun count.
+		 */
+
+		BUG_ON(q->info.si_code != SI_TIMER);
+		q->info.si_overrun++;
+		return 0;
+	}
+
+	if (sig_ignored(t, sig))
+		return 1;
+
+	signalfd_notify(t, sig);
+	list_add_tail(&q->list, &pending->list);
+	sigaddset(&pending->signal, sig);
+	return 0;
+}
+
 int send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 {
 	unsigned long flags;
-	int ret = 0;
+	int ret = -1;
 
 	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
 
@@ -1307,37 +1330,14 @@ int send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 	 */
 	rcu_read_lock();
 
-	if (!likely(lock_task_sighand(p, &flags))) {
-		ret = -1;
+	if (!likely(lock_task_sighand(p, &flags)))
 		goto out_err;
-	}
 
-	if (unlikely(!list_empty(&q->list))) {
-		/*
-		 * If an SI_TIMER entry is already queue just increment
-		 * the overrun count.
-		 */
-		BUG_ON(q->info.si_code != SI_TIMER);
-		q->info.si_overrun++;
-		goto out;
-	}
-	/* Short-circuit ignored signals.  */
-	if (sig_ignored(p, sig)) {
-		ret = 1;
-		goto out;
-	}
-	/*
-	 * Deliver the signal to listening signalfds. This must be called
-	 * with the sighand lock held.
-	 */
-	signalfd_notify(p, sig);
+	ret = do_send_sigqueue(sig, q, p, &p->pending);
 
-	list_add_tail(&q->list, &p->pending.list);
-	sigaddset(&p->pending.signal, sig);
 	if (!sigismember(&p->blocked, sig))
 		signal_wake_up(p, sig == SIGKILL);
 
-out:
 	unlock_task_sighand(p, &flags);
 out_err:
 	rcu_read_unlock();
@@ -1349,7 +1349,7 @@ int
 send_group_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 {
 	unsigned long flags;
-	int ret = 0;
+	int ret;
 
 	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
 
@@ -1358,38 +1358,10 @@ send_group_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 	spin_lock_irqsave(&p->sighand->siglock, flags);
 	handle_stop_signal(sig, p);
 
-	/* Short-circuit ignored signals.  */
-	if (sig_ignored(p, sig)) {
-		ret = 1;
-		goto out;
-	}
-
-	if (unlikely(!list_empty(&q->list))) {
-		/*
-		 * If an SI_TIMER entry is already queue just increment
-		 * the overrun count.  Other uses should not try to
-		 * send the signal multiple times.
-		 */
-		BUG_ON(q->info.si_code != SI_TIMER);
-		q->info.si_overrun++;
-		goto out;
-	} 
-	/*
-	 * Deliver the signal to listening signalfds. This must be called
-	 * with the sighand lock held.
-	 */
-	signalfd_notify(p, sig);
-
-	/*
-	 * Put this signal on the shared-pending queue.
-	 * We always use the shared queue for process-wide signals,
-	 * to avoid several races.
-	 */
-	list_add_tail(&q->list, &p->signal->shared_pending.list);
-	sigaddset(&p->signal->shared_pending.signal, sig);
+	ret = do_send_sigqueue(sig, q, p, &p->signal->shared_pending);
 
 	__group_complete_signal(sig, p);
-out:
+
 	spin_unlock_irqrestore(&p->sighand->siglock, flags);
 	read_unlock(&tasklist_lock);
 	return ret;

commit c5363d03637885310f1101b95cbbd26d067b4c8d
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Wed Apr 30 00:52:40 2008 -0700

    signals: clean dequeue_signal from excess checks and assignments
    
    The signr variable may be declared without initialization - it is set ro the
    return value from __dequeue_signal() right at the function beginning.
    
    Besides, after recalc_sigpending() two checks for signr to be not 0 may be
    merged into one.  Both if-s become easier to read.
    
    Thanks to Oleg for pointing out mistakes in the first version of this patch.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 24ee53b7f60c..6610a95506b3 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -377,7 +377,7 @@ static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,
  */
 int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 {
-	int signr = 0;
+	int signr;
 
 	/* We only dequeue private signals from ourselves, we don't let
 	 * signalfd steal them
@@ -410,8 +410,12 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 			}
 		}
 	}
+
 	recalc_sigpending();
-	if (signr && unlikely(sig_kernel_stop(signr))) {
+	if (!signr)
+		return 0;
+
+	if (unlikely(sig_kernel_stop(signr))) {
 		/*
 		 * Set a marker that we have dequeued a stop signal.  Our
 		 * caller might release the siglock and then the pending
@@ -427,9 +431,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 		if (!(tsk->signal->flags & SIGNAL_GROUP_EXIT))
 			tsk->signal->flags |= SIGNAL_STOP_DEQUEUED;
 	}
-	if (signr &&
-	     ((info->si_code & __SI_MASK) == __SI_TIMER) &&
-	     info->si_sys_private) {
+	if ((info->si_code & __SI_MASK) == __SI_TIMER && info->si_sys_private) {
 		/*
 		 * Release the siglock to ensure proper locking order
 		 * of timer locks outside of siglocks.  Note, we leave

commit 93585eeaf3d42d608cd7232e7420c93fb676bba1
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Wed Apr 30 00:52:39 2008 -0700

    signals: consolidate checks for whether or not to ignore a signal
    
    Both sig_ignored() and do_sigaction() check for signr to be explicitly or
    implicitly ignored.  Introduce a helper for them.
    
    This patch is aimed to help handling signals by pid namespace's init, and was
    derived from one of Oleg's patches
    https://lists.linux-foundation.org/pipermail/containers/2007-December/009308.html
    so, if he doesn't mind, he should be considered as an author.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 4a45bac2c632..24ee53b7f60c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -39,11 +39,19 @@
 
 static struct kmem_cache *sigqueue_cachep;
 
+static int __sig_ignored(struct task_struct *t, int sig)
+{
+	void __user *handler;
+
+	/* Is it explicitly or implicitly ignored? */
+
+	handler = t->sighand->action[sig - 1].sa.sa_handler;
+	return handler == SIG_IGN ||
+		(handler == SIG_DFL && sig_kernel_ignore(sig));
+}
 
 static int sig_ignored(struct task_struct *t, int sig)
 {
-	void __user * handler;
-
 	/*
 	 * Tracers always want to know about signals..
 	 */
@@ -58,10 +66,7 @@ static int sig_ignored(struct task_struct *t, int sig)
 	if (sigismember(&t->blocked, sig) || sigismember(&t->real_blocked, sig))
 		return 0;
 
-	/* Is it explicitly or implicitly ignored? */
-	handler = t->sighand->action[sig-1].sa.sa_handler;
-	return   handler == SIG_IGN ||
-		(handler == SIG_DFL && sig_kernel_ignore(sig));
+	return __sig_ignored(t, sig);
 }
 
 /*
@@ -2331,13 +2336,14 @@ sys_rt_sigqueueinfo(int pid, int sig, siginfo_t __user *uinfo)
 
 int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 {
+	struct task_struct *t = current;
 	struct k_sigaction *k;
 	sigset_t mask;
 
 	if (!valid_signal(sig) || sig < 1 || (act && sig_kernel_only(sig)))
 		return -EINVAL;
 
-	k = &current->sighand->action[sig-1];
+	k = &t->sighand->action[sig-1];
 
 	spin_lock_irq(&current->sighand->siglock);
 	if (oact)
@@ -2358,9 +2364,7 @@ int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 		 *   (for example, SIGCHLD), shall cause the pending signal to
 		 *   be discarded, whether or not it is blocked"
 		 */
-		if (act->sa.sa_handler == SIG_IGN ||
-		   (act->sa.sa_handler == SIG_DFL && sig_kernel_ignore(sig))) {
-			struct task_struct *t = current;
+		if (__sig_ignored(t, sig)) {
 			sigemptyset(&mask);
 			sigaddset(&mask, sig);
 			rm_from_queue_full(&mask, &t->signal->shared_pending);

commit 1406f2d321bae5ac5ff729dcb773336d9c05ec74
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:37 2008 -0700

    lock_task_sighand: add rcu lock/unlock
    
    Most of the callers of lock_task_sighand() doesn't actually need rcu_lock().
    lock_task_sighand() needs it only to safely play with tsk->sighand, it can
    take the lock itself.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 29aca40be33f..4a45bac2c632 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -971,13 +971,11 @@ int __fatal_signal_pending(struct task_struct *tsk)
 }
 EXPORT_SYMBOL(__fatal_signal_pending);
 
-/*
- * Must be called under rcu_read_lock() or with tasklist_lock read-held.
- */
 struct sighand_struct *lock_task_sighand(struct task_struct *tsk, unsigned long *flags)
 {
 	struct sighand_struct *sighand;
 
+	rcu_read_lock();
 	for (;;) {
 		sighand = rcu_dereference(tsk->sighand);
 		if (unlikely(sighand == NULL))
@@ -988,6 +986,7 @@ struct sighand_struct *lock_task_sighand(struct task_struct *tsk, unsigned long
 			break;
 		spin_unlock_irqrestore(&sighand->siglock, *flags);
 	}
+	rcu_read_unlock();
 
 	return sighand;
 }

commit 573cf9ad72c13750e86c91de43477e9dfb440523
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:52:36 2008 -0700

    signals: do_signal_stop(): use signal_group_exit()
    
    do_signal_stop() needs signal_group_exit() but checks sig->group_exit_task.
     This (optimization) is correct, SIGNAL_STOP_DEQUEUED and SIGNAL_GROUP_EXIT
    are mutually exclusive, but looks confusing.  Use signal_group_exit(), this
    is not fastpath, the code clarity is more important.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index fb8ffd468854..29aca40be33f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1717,7 +1717,7 @@ static int do_signal_stop(int signr)
 		struct task_struct *t;
 
 		if (!likely(sig->flags & SIGNAL_STOP_DEQUEUED) ||
-		    unlikely(sig->group_exit_task))
+		    unlikely(signal_group_exit(sig)))
 			return 0;
 		/*
 		 * There is no group stop already in progress.

commit 2acb024d5524eda305523c1d6061fe5ef1949165
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Wed Apr 30 00:52:35 2008 -0700

    signals: consolidate checking for ignored/legacy signals
    
    Two callers for send_signal() - the specific_send_sig_info and the
    __group_send_sig_info - both check for sig to be ignored or already queued.
    
    Move these checks into send_signal() and make it return 1 to indicate that the
    signal is dropped, but there's no error in this.
    
    Besides, merge comments and spell-check them.
    
    [oleg@tv-sign.ru: simplifications]
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 772aa011dad8..fb8ffd468854 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -667,6 +667,14 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 {
 	struct sigqueue * q = NULL;
 
+	/*
+	 * Short-circuit ignored signals and support queuing
+	 * exactly one non-rt signal, so that we can get more
+	 * detailed information about the cause of the signal.
+	 */
+	if (sig_ignored(t, sig) || legacy_queue(signals, sig))
+		return 0;
+
 	/*
 	 * Deliver the signal to listening signalfds. This must be called
 	 * with the sighand lock held.
@@ -723,7 +731,7 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 
 out_set:
 	sigaddset(&signals->signal, sig);
-	return 0;
+	return 1;
 }
 
 int print_fatal_signals;
@@ -761,26 +769,18 @@ __setup("print-fatal-signals=", setup_print_fatal_signals);
 static int
 specific_send_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 {
-	int ret = 0;
+	int ret;
 
 	BUG_ON(!irqs_disabled());
 	assert_spin_locked(&t->sighand->siglock);
 
-	/* Short-circuit ignored signals.  */
-	if (sig_ignored(t, sig))
-		goto out;
-
-	/* Support queueing exactly one non-rt signal, so that we
-	   can get more detailed information about the cause of
-	   the signal. */
-	if (legacy_queue(&t->pending, sig))
-		goto out;
-
 	ret = send_signal(sig, info, t, &t->pending);
-	if (!ret && !sigismember(&t->blocked, sig))
+	if (ret <= 0)
+		return ret;
+
+	if (!sigismember(&t->blocked, sig))
 		signal_wake_up(t, sig == SIGKILL);
-out:
-	return ret;
+	return 0;
 }
 
 /*
@@ -925,26 +925,18 @@ __group_complete_signal(int sig, struct task_struct *p)
 int
 __group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 {
-	int ret = 0;
+	int ret;
 
 	assert_spin_locked(&p->sighand->siglock);
 	handle_stop_signal(sig, p);
 
-	/* Short-circuit ignored signals.  */
-	if (sig_ignored(p, sig))
-		return ret;
-
-	if (legacy_queue(&p->signal->shared_pending, sig))
-		/* This is a non-RT signal and we already have one queued.  */
-		return ret;
-
 	/*
 	 * Put this signal on the shared-pending queue, or fail with EAGAIN.
 	 * We always use the shared queue for process-wide signals,
 	 * to avoid several races.
 	 */
 	ret = send_signal(sig, info, p, &p->signal->shared_pending);
-	if (unlikely(ret))
+	if (ret <= 0)
 		return ret;
 
 	__group_complete_signal(sig, p);

commit af7fff9c13d56657dc328c75590f401c99bcecd9
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Wed Apr 30 00:52:34 2008 -0700

    signals: turn LEGACY_QUEUE macro into static inline function
    
    This makes the code more readable, due to less brackets and small letters in
    name.
    
    I also move it above the send_signal() as a preparation for the 3rd patch.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index f5f3b8a61bee..772aa011dad8 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -657,6 +657,11 @@ static void handle_stop_signal(int sig, struct task_struct *p)
 	}
 }
 
+static inline int legacy_queue(struct sigpending *signals, int sig)
+{
+	return (sig < SIGRTMIN) && sigismember(&signals->signal, sig);
+}
+
 static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			struct sigpending *signals)
 {
@@ -721,9 +726,6 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	return 0;
 }
 
-#define LEGACY_QUEUE(sigptr, sig) \
-	(((sig) < SIGRTMIN) && sigismember(&(sigptr)->signal, (sig)))
-
 int print_fatal_signals;
 
 static void print_fatal_signal(struct pt_regs *regs, int signr)
@@ -771,7 +773,7 @@ specific_send_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 	/* Support queueing exactly one non-rt signal, so that we
 	   can get more detailed information about the cause of
 	   the signal. */
-	if (LEGACY_QUEUE(&t->pending, sig))
+	if (legacy_queue(&t->pending, sig))
 		goto out;
 
 	ret = send_signal(sig, info, t, &t->pending);
@@ -932,7 +934,7 @@ __group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 	if (sig_ignored(p, sig))
 		return ret;
 
-	if (LEGACY_QUEUE(&p->signal->shared_pending, sig))
+	if (legacy_queue(&p->signal->shared_pending, sig))
 		/* This is a non-RT signal and we already have one queued.  */
 		return ret;
 

commit e1401c6bbb289d154eb0d0c292cc9f8259e4af73
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Wed Apr 30 00:52:34 2008 -0700

    signals: remove unused variable from send_signal()
    
    This function doesn't change the ret's value and thus always returns 0, with a
    single exception of returning -EAGAIN explicitly.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 64ad0ed15992..f5f3b8a61bee 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -661,7 +661,6 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			struct sigpending *signals)
 {
 	struct sigqueue * q = NULL;
-	int ret = 0;
 
 	/*
 	 * Deliver the signal to listening signalfds. This must be called
@@ -719,7 +718,7 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 
 out_set:
 	sigaddset(&signals->signal, sig);
-	return ret;
+	return 0;
 }
 
 #define LEGACY_QUEUE(sigptr, sig) \

commit f5264481c8049673e2cc8c7aca410931f571ba2d
Author: Pavel Machek <pavel@suse.cz>
Date:   Mon Apr 21 22:15:06 2008 +0000

    trivial: small cleanups
    
    These are small cleanups all over the tree.
    
    Trivial style and comment changes to
      fs/select.c, kernel/signal.c, kernel/stop_machine.c & mm/pdflush.c
    
    Signed-off-by: Pavel Machek <pavel@suse.cz>
    Signed-off-by: Jesper Juhl <jesper.juhl@gmail.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index cc8303cd093d..64ad0ed15992 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -220,7 +220,7 @@ void flush_signals(struct task_struct *t)
 	unsigned long flags;
 
 	spin_lock_irqsave(&t->sighand->siglock, flags);
-	clear_tsk_thread_flag(t,TIF_SIGPENDING);
+	clear_tsk_thread_flag(t, TIF_SIGPENDING);
 	flush_sigqueue(&t->pending);
 	flush_sigqueue(&t->signal->shared_pending);
 	spin_unlock_irqrestore(&t->sighand->siglock, flags);
@@ -424,7 +424,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 	}
 	if (signr &&
 	     ((info->si_code & __SI_MASK) == __SI_TIMER) &&
-	     info->si_sys_private){
+	     info->si_sys_private) {
 		/*
 		 * Release the siglock to ensure proper locking order
 		 * of timer locks outside of siglocks.  Note, we leave

commit 18c98b65279c00c3c983a4525161207f1aa6a04b
Author: Roland McGrath <roland@redhat.com>
Date:   Thu Apr 17 18:44:38 2008 -0700

    ptrace_signal subroutine
    
    This breaks out the ptrace handling from get_signal_to_deliver into a
    new subroutine.  The actual code there doesn't change, and it gets
    inlined into nearly identical compiled code.  This makes the function
    substantially shorter and thus easier to read, and it nicely isolates
    the ptrace magic.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Acked-by: Kyle McMartin <kyle@mcmartin.ca>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 6af1210092c3..cc8303cd093d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1757,6 +1757,45 @@ static int do_signal_stop(int signr)
 	return 1;
 }
 
+static int ptrace_signal(int signr, siginfo_t *info,
+			 struct pt_regs *regs, void *cookie)
+{
+	if (!(current->ptrace & PT_PTRACED))
+		return signr;
+
+	ptrace_signal_deliver(regs, cookie);
+
+	/* Let the debugger run.  */
+	ptrace_stop(signr, 0, info);
+
+	/* We're back.  Did the debugger cancel the sig?  */
+	signr = current->exit_code;
+	if (signr == 0)
+		return signr;
+
+	current->exit_code = 0;
+
+	/* Update the siginfo structure if the signal has
+	   changed.  If the debugger wanted something
+	   specific in the siginfo structure then it should
+	   have updated *info via PTRACE_SETSIGINFO.  */
+	if (signr != info->si_signo) {
+		info->si_signo = signr;
+		info->si_errno = 0;
+		info->si_code = SI_USER;
+		info->si_pid = task_pid_vnr(current->parent);
+		info->si_uid = current->parent->uid;
+	}
+
+	/* If the (new) signal is now blocked, requeue it.  */
+	if (sigismember(&current->blocked, signr)) {
+		specific_send_sig_info(signr, info, current);
+		signr = 0;
+	}
+
+	return signr;
+}
+
 int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 			  struct pt_regs *regs, void *cookie)
 {
@@ -1785,36 +1824,10 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		if (!signr)
 			break; /* will return 0 */
 
-		if ((current->ptrace & PT_PTRACED) && signr != SIGKILL) {
-			ptrace_signal_deliver(regs, cookie);
-
-			/* Let the debugger run.  */
-			ptrace_stop(signr, 0, info);
-
-			/* We're back.  Did the debugger cancel the sig?  */
-			signr = current->exit_code;
-			if (signr == 0)
-				continue;
-
-			current->exit_code = 0;
-
-			/* Update the siginfo structure if the signal has
-			   changed.  If the debugger wanted something
-			   specific in the siginfo structure then it should
-			   have updated *info via PTRACE_SETSIGINFO.  */
-			if (signr != info->si_signo) {
-				info->si_signo = signr;
-				info->si_errno = 0;
-				info->si_code = SI_USER;
-				info->si_pid = task_pid_vnr(current->parent);
-				info->si_uid = current->parent->uid;
-			}
-
-			/* If the (new) signal is now blocked, requeue it.  */
-			if (sigismember(&current->blocked, signr)) {
-				specific_send_sig_info(signr, info, current);
+		if (signr != SIGKILL) {
+			signr = ptrace_signal(signr, info, regs, cookie);
+			if (!signr)
 				continue;
-			}
 		}
 
 		ka = &current->sighand->action[signr-1];

commit 13b1c3d4b49bd83d861c775ca2db54e1692a1b07
Author: Roland McGrath <roland@redhat.com>
Date:   Mon Mar 3 20:22:05 2008 -0800

    freezer vs stopped or traced
    
    This changes the "freezer" code used by suspend/hibernate in its treatment
    of tasks in TASK_STOPPED (job control stop) and TASK_TRACED (ptrace) states.
    
    As I understand it, the intent of the "freezer" is to hold all tasks
    from doing anything significant.  For this purpose, TASK_STOPPED and
    TASK_TRACED are "frozen enough".  It's possible the tasks might resume
    from ptrace calls (if the tracer were unfrozen) or from signals
    (including ones that could come via timer interrupts, etc).  But this
    doesn't matter as long as they quickly block again while "freezing" is
    in effect.  Some minor adjustments to the signal.c code make sure that
    try_to_freeze() very shortly follows all wakeups from both kinds of
    stop.  This lets the freezer code safely leave stopped tasks unmolested.
    
    Changing this fixes the longstanding bug of seeing after resuming from
    suspend/hibernate your shell report "[1] Stopped" and the like for all
    your jobs stopped by ^Z et al, as if you had freshly fg'd and ^Z'd them.
    It also removes from the freezer the arcane special case treatment for
    ptrace'd tasks, which relied on intimate knowledge of ptrace internals.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 84917fe507f7..6af1210092c3 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1623,7 +1623,6 @@ static void ptrace_stop(int exit_code, int clear_code, siginfo_t *info)
 	/* Let the debugger run.  */
 	__set_current_state(TASK_TRACED);
 	spin_unlock_irq(&current->sighand->siglock);
-	try_to_freeze();
 	read_lock(&tasklist_lock);
 	if (!unlikely(killed) && may_ptrace_stop()) {
 		do_notify_parent_cldstop(current, CLD_TRAPPED);
@@ -1640,6 +1639,13 @@ static void ptrace_stop(int exit_code, int clear_code, siginfo_t *info)
 		read_unlock(&tasklist_lock);
 	}
 
+	/*
+	 * While in TASK_TRACED, we were considered "frozen enough".
+	 * Now that we woke up, it's crucial if we're supposed to be
+	 * frozen that we freeze now before running anything substantial.
+	 */
+	try_to_freeze();
+
 	/*
 	 * We are back.  Now reacquire the siglock before touching
 	 * last_siginfo, so that we are sure to have synchronized with
@@ -1757,9 +1763,15 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 	sigset_t *mask = &current->blocked;
 	int signr = 0;
 
+relock:
+	/*
+	 * We'll jump back here after any time we were stopped in TASK_STOPPED.
+	 * While in TASK_STOPPED, we were considered "frozen enough".
+	 * Now that we woke up, it's crucial if we're supposed to be
+	 * frozen that we freeze now before running anything substantial.
+	 */
 	try_to_freeze();
 
-relock:
 	spin_lock_irq(&current->sighand->siglock);
 	for (;;) {
 		struct k_sigaction *ka;

commit b5606c2d4447e80b1d72406af4e78af1eda611d4
Author: Harvey Harrison <harvey.harrison@gmail.com>
Date:   Wed Feb 13 15:03:16 2008 -0800

    remove final fastcall users
    
    fastcall always expands to empty, remove it.
    
    Signed-off-by: Harvey Harrison <harvey.harrison@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2c1f08defac2..84917fe507f7 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -972,7 +972,7 @@ void zap_other_threads(struct task_struct *p)
 	}
 }
 
-int fastcall __fatal_signal_pending(struct task_struct *tsk)
+int __fatal_signal_pending(struct task_struct *tsk)
 {
 	return sigismember(&tsk->pending.signal, SIGKILL);
 }

commit 146a505d498c36de98ec161d791dd50beca7f9a3
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Fri Feb 8 04:19:22 2008 -0800

    Get rid of the kill_pgrp_info() function
    
    There's only one caller left - the kill_pgrp one - so merge these two
    functions and forget the kill_pgrp_info one.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Reviewed-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index a805c7417cd0..2c1f08defac2 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1018,7 +1018,7 @@ int group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 }
 
 /*
- * kill_pgrp_info() sends a signal to a process group: this is what the tty
+ * __kill_pgrp_info() sends a signal to a process group: this is what the tty
  * control characters do (^C, ^Z etc)
  */
 
@@ -1037,17 +1037,6 @@ int __kill_pgrp_info(int sig, struct siginfo *info, struct pid *pgrp)
 	return success ? 0 : retval;
 }
 
-int kill_pgrp_info(int sig, struct siginfo *info, struct pid *pgrp)
-{
-	int retval;
-
-	read_lock(&tasklist_lock);
-	retval = __kill_pgrp_info(sig, info, pgrp);
-	read_unlock(&tasklist_lock);
-
-	return retval;
-}
-
 int kill_pid_info(int sig, struct siginfo *info, struct pid *pid)
 {
 	int error = -ESRCH;
@@ -1236,7 +1225,13 @@ force_sigsegv(int sig, struct task_struct *p)
 
 int kill_pgrp(struct pid *pid, int sig, int priv)
 {
-	return kill_pgrp_info(sig, __si_special(priv), pid);
+	int ret;
+
+	read_lock(&tasklist_lock);
+	ret = __kill_pgrp_info(sig, __si_special(priv), pid);
+	read_unlock(&tasklist_lock);
+
+	return ret;
 }
 EXPORT_SYMBOL(kill_pgrp);
 

commit d5df763b81946a405837b80874516dfc2a8f7ebf
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Fri Feb 8 04:19:22 2008 -0800

    Clean up the kill_something_info
    
    This is the first step (of two) in removing the kill_pgrp_info.
    
    All the users of this function are in kernel/signal.c, but all they need is to
    call __kill_pgrp_info() with the tasklist_lock read-locked.
    
    Fortunately, one of its users is the kill_something_info(), which already
    needs this lock in one of its branches, so clean these branches up and call
    the __kill_pgrp_info() directly.
    
    Based on Oleg's view of how this function should look.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index cc45a6b69134..a805c7417cd0 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1134,14 +1134,22 @@ EXPORT_SYMBOL_GPL(kill_pid_info_as_uid);
 static int kill_something_info(int sig, struct siginfo *info, int pid)
 {
 	int ret;
-	rcu_read_lock();
-	if (!pid) {
-		ret = kill_pgrp_info(sig, info, task_pgrp(current));
-	} else if (pid == -1) {
+
+	if (pid > 0) {
+		rcu_read_lock();
+		ret = kill_pid_info(sig, info, find_vpid(pid));
+		rcu_read_unlock();
+		return ret;
+	}
+
+	read_lock(&tasklist_lock);
+	if (pid != -1) {
+		ret = __kill_pgrp_info(sig, info,
+				pid ? find_vpid(-pid) : task_pgrp(current));
+	} else {
 		int retval = 0, count = 0;
 		struct task_struct * p;
 
-		read_lock(&tasklist_lock);
 		for_each_process(p) {
 			if (p->pid > 1 && !same_thread_group(p, current)) {
 				int err = group_send_sig_info(sig, info, p);
@@ -1150,14 +1158,10 @@ static int kill_something_info(int sig, struct siginfo *info, int pid)
 					retval = err;
 			}
 		}
-		read_unlock(&tasklist_lock);
 		ret = count ? retval : -ESRCH;
-	} else if (pid < 0) {
-		ret = kill_pgrp_info(sig, info, find_vpid(-pid));
-	} else {
-		ret = kill_pid_info(sig, info, find_vpid(pid));
 	}
-	rcu_read_unlock();
+	read_unlock(&tasklist_lock);
+
 	return ret;
 }
 

commit fea9d175545b38cb3e84569400419eb81bc90fa3
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Feb 8 04:19:19 2008 -0800

    ITIMER_REAL: convert to use struct pid
    
    signal_struct->tsk points to the ->group_leader and thus we have the nasty
    code in de_thread() which has to change it and restart ->real_timer if the
    leader is changed.
    
    Use "struct pid *leader_pid" instead.  This also allows us to kill now
    unneeded send_group_sig_info().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Davide Libenzi <davidel@xmailserver.org>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Acked-by: Roland McGrath <roland@redhat.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index b0b43a4ad8dd..cc45a6b69134 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1205,20 +1205,6 @@ send_sig(int sig, struct task_struct *p, int priv)
 	return send_sig_info(sig, __si_special(priv), p);
 }
 
-/*
- * This is the entry point for "process-wide" signals.
- * They will go to an appropriate thread in the thread group.
- */
-int
-send_group_sig_info(int sig, struct siginfo *info, struct task_struct *p)
-{
-	int ret;
-	read_lock(&tasklist_lock);
-	ret = group_send_sig_info(sig, info, p);
-	read_unlock(&tasklist_lock);
-	return ret;
-}
-
 void
 force_sig(int sig, struct task_struct *p)
 {

commit d36174bc2bce0372693a9cfbdef8b2689c9982cb
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Feb 8 04:19:18 2008 -0800

    uglify kill_pid_info() to fix kill() vs exec() race
    
    kill_pid_info()->pid_task() could be the old leader of the execing process.
    In that case it is possible that the leader will be released before we take
    siglock. This means that kill_pid_info() (and thus sys_kill()) can return a
    false -ESRCH.
    
    Change the code to retry when lock_task_sighand() fails. The endless loop is
    not possible, __exit_signal() both clears ->sighand and does detach_pid().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Davide Libenzi <davidel@xmailserver.org>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 3d3adb94561d..b0b43a4ad8dd 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1050,17 +1050,26 @@ int kill_pgrp_info(int sig, struct siginfo *info, struct pid *pgrp)
 
 int kill_pid_info(int sig, struct siginfo *info, struct pid *pid)
 {
-	int error;
+	int error = -ESRCH;
 	struct task_struct *p;
 
 	rcu_read_lock();
 	if (unlikely(sig_needs_tasklist(sig)))
 		read_lock(&tasklist_lock);
 
+retry:
 	p = pid_task(pid, PIDTYPE_PID);
-	error = -ESRCH;
-	if (p)
+	if (p) {
 		error = group_send_sig_info(sig, info, p);
+		if (unlikely(error == -ESRCH))
+			/*
+			 * The task was unhashed in between, try again.
+			 * If it is dead, pid_task() will return NULL,
+			 * if we race with de_thread() it will find the
+			 * new leader.
+			 */
+			goto retry;
+	}
 
 	if (unlikely(sig_needs_tasklist(sig)))
 		read_unlock(&tasklist_lock);

commit 5dee1707dfbfc55eb7569b9ae5abaf932bd4c377
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Feb 8 04:19:13 2008 -0800

    move the related code from exit_notify() to exit_signals()
    
    The previous bugfix was not optimal, we shouldn't care about group stop
    when we are the only thread or the group stop is in progress.  In that case
    nothing special is needed, just set PF_EXITING and return.
    
    Also, take the related "TIF_SIGPENDING re-targeting" code from exit_notify().
    
    So, from the performance POV the only difference is that we don't trust
    !signal_pending() until we take ->siglock.  But this in fact fixes another
    ___pure___ theoretical minor race.  __group_complete_signal() finds the
    task without PF_EXITING and chooses it as the target for signal_wake_up().
    But nothing prevents this task from exiting in between without noticing the
    pending signal and thus unpredictably delaying the actual delivery.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Davide Libenzi <davidel@xmailserver.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 209eec11eef5..3d3adb94561d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1903,19 +1903,36 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 void exit_signals(struct task_struct *tsk)
 {
 	int group_stop = 0;
+	struct task_struct *t;
 
-	spin_lock_irq(&tsk->sighand->siglock);
-	if (unlikely(tsk->signal->group_stop_count) &&
-			!--tsk->signal->group_stop_count) {
-		tsk->signal->flags = SIGNAL_STOP_STOPPED;
-		group_stop = 1;
+	if (thread_group_empty(tsk) || signal_group_exit(tsk->signal)) {
+		tsk->flags |= PF_EXITING;
+		return;
 	}
 
+	spin_lock_irq(&tsk->sighand->siglock);
 	/*
 	 * From now this task is not visible for group-wide signals,
 	 * see wants_signal(), do_signal_stop().
 	 */
 	tsk->flags |= PF_EXITING;
+	if (!signal_pending(tsk))
+		goto out;
+
+	/* It could be that __group_complete_signal() choose us to
+	 * notify about group-wide signal. Another thread should be
+	 * woken now to take the signal since we will not.
+	 */
+	for (t = tsk; (t = next_thread(t)) != tsk; )
+		if (!signal_pending(t) && !(t->flags & PF_EXITING))
+			recalc_sigpending_and_wake(t);
+
+	if (unlikely(tsk->signal->group_stop_count) &&
+			!--tsk->signal->group_stop_count) {
+		tsk->signal->flags = SIGNAL_STOP_STOPPED;
+		group_stop = 1;
+	}
+out:
 	spin_unlock_irq(&tsk->sighand->siglock);
 
 	if (unlikely(group_stop)) {

commit d12619b5ff5664623524aef796514d1946ea3b4a
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Feb 8 04:19:12 2008 -0800

    fix group stop with exit race
    
    do_signal_stop() counts all sub-thread and sets ->group_stop_count
    accordingly.  Every thread should decrement ->group_stop_count and stop,
    the last one should notify the parent.
    
    However a sub-thread can exit before it notices the signal_pending(), or it
    may be somewhere in do_exit() already.  In that case the group stop never
    finishes properly.
    
    Note: this is a minimal fix, we can add some optimizations later.  Say we
    can return quickly if thread_group_empty().  Also, we can move some signal
    related code from exit_notify() to exit_signals().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Davide Libenzi <davidel@xmailserver.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 3fca710a5cd7..209eec11eef5 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1739,7 +1739,7 @@ static int do_signal_stop(int signr)
 			 * stop is always done with the siglock held,
 			 * so this check has no races.
 			 */
-			if (!t->exit_state &&
+			if (!(t->flags & PF_EXITING) &&
 			    !task_is_stopped_or_traced(t)) {
 				stop_count++;
 				signal_wake_up(t, 0);
@@ -1900,6 +1900,31 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 	return signr;
 }
 
+void exit_signals(struct task_struct *tsk)
+{
+	int group_stop = 0;
+
+	spin_lock_irq(&tsk->sighand->siglock);
+	if (unlikely(tsk->signal->group_stop_count) &&
+			!--tsk->signal->group_stop_count) {
+		tsk->signal->flags = SIGNAL_STOP_STOPPED;
+		group_stop = 1;
+	}
+
+	/*
+	 * From now this task is not visible for group-wide signals,
+	 * see wants_signal(), do_signal_stop().
+	 */
+	tsk->flags |= PF_EXITING;
+	spin_unlock_irq(&tsk->sighand->siglock);
+
+	if (unlikely(group_stop)) {
+		read_lock(&tasklist_lock);
+		do_notify_parent_cldstop(tsk, CLD_STOPPED);
+		read_unlock(&tasklist_lock);
+	}
+}
+
 EXPORT_SYMBOL(recalc_sigpending);
 EXPORT_SYMBOL_GPL(dequeue_signal);
 EXPORT_SYMBOL(flush_signals);

commit 20686a309aa98c518adbbd9b57cdbb1804143deb
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Feb 8 04:19:03 2008 -0800

    ptrace_stop: fix racy nonstop_code setting
    
    If the tracer is gone and we are not going to stop, ptrace_stop() sets
    ->exit_code = nostop_code.  However, the tracer could actually clear the
    exit code before detaching.  In that case get_signal_to_deliver() "resends"
    the signal which was cancelled by the debugger.  For example, it is
    possible that a quick PTRACE_ATTACH + PTRACE_DETACH can leave the tracee in
    STOPPED state.
    
    Change the behaviour of ptrace_stop().  If the caller is ptrace notify(),
    we should always clear ->exit_code.  If the caller is
    get_signal_to_deliver(), we should not touch it at all.  To do so, change
    the nonstop_code parameter to "bool clear_code" and change the callers
    accordingly.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 678bffa437c1..3fca710a5cd7 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1591,10 +1591,10 @@ static int sigkill_pending(struct task_struct *tsk)
  * That makes it a way to test a stopped process for
  * being ptrace-stopped vs being job-control-stopped.
  *
- * If we actually decide not to stop at all because the tracer is gone,
- * we leave nostop_code in current->exit_code.
+ * If we actually decide not to stop at all because the tracer
+ * is gone, we keep current->exit_code unless clear_code.
  */
-static void ptrace_stop(int exit_code, int nostop_code, siginfo_t *info)
+static void ptrace_stop(int exit_code, int clear_code, siginfo_t *info)
 {
 	int killed = 0;
 
@@ -1641,7 +1641,8 @@ static void ptrace_stop(int exit_code, int nostop_code, siginfo_t *info)
 		 * Don't drop the lock yet, another tracer may come.
 		 */
 		__set_current_state(TASK_RUNNING);
-		current->exit_code = nostop_code;
+		if (clear_code)
+			current->exit_code = 0;
 		read_unlock(&tasklist_lock);
 	}
 
@@ -1675,7 +1676,7 @@ void ptrace_notify(int exit_code)
 
 	/* Let the debugger run.  */
 	spin_lock_irq(&current->sighand->siglock);
-	ptrace_stop(exit_code, 0, &info);
+	ptrace_stop(exit_code, 1, &info);
 	spin_unlock_irq(&current->sighand->siglock);
 }
 
@@ -1782,7 +1783,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 			ptrace_signal_deliver(regs, cookie);
 
 			/* Let the debugger run.  */
-			ptrace_stop(signr, signr, info);
+			ptrace_stop(signr, 0, info);
 
 			/* We're back.  Did the debugger cancel the sig?  */
 			signr = current->exit_code;

commit 6405f7f4675884b671bee66678e1c2859bdb0e56
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Feb 8 04:19:00 2008 -0800

    ptrace_stop: fix the race with ptrace detach+attach
    
    If the tracer went away (may_ptrace_stop() failed), ptrace_stop() drops
    tasklist and then changes the ->state from TASK_TRACED to TASK_RUNNING.
    
    This can fool another tracer which attaches to us in between.  Change the
    ->state under tasklist_lock to ensure that ptrace_check_attach() can't wrongly
    succeed.  Also, remove the unnecessary mb().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 6d6d1ab39e7e..678bffa437c1 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1638,11 +1638,11 @@ static void ptrace_stop(int exit_code, int nostop_code, siginfo_t *info)
 	} else {
 		/*
 		 * By the time we got the lock, our tracer went away.
-		 * Don't stop here.
+		 * Don't drop the lock yet, another tracer may come.
 		 */
-		read_unlock(&tasklist_lock);
-		set_current_state(TASK_RUNNING);
+		__set_current_state(TASK_RUNNING);
 		current->exit_code = nostop_code;
+		read_unlock(&tasklist_lock);
 	}
 
 	/*

commit 6b39c7bfbd1436836c0fb34c5b437fda1a7a3dd4
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Feb 8 04:18:58 2008 -0800

    kill PT_ATTACHED
    
    Since the patch
    
            "Fix ptrace_attach()/ptrace_traceme()/de_thread() race"
            commit f5b40e363ad6041a96e3da32281d8faa191597b9
    
    we set PT_ATTACHED and change child->parent "atomically" wrt task_list lock.
    
    This means we can remove the checks like "PT_ATTACHED && ->parent != ptracer"
    which were needed to catch the "ptrace attach is in progress" case.  We can
    also remove the flag itself since nobody else uses it.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Roland McGrath <roland@redhat.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5d30ff561847..6d6d1ab39e7e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1556,11 +1556,6 @@ static inline int may_ptrace_stop(void)
 {
 	if (!likely(current->ptrace & PT_PTRACED))
 		return 0;
-
-	if (unlikely(current->parent == current->real_parent &&
-		    (current->ptrace & PT_ATTACHED)))
-		return 0;
-
 	/*
 	 * Are we in the middle of do_coredump?
 	 * If so and our tracer is also part of the coredump stopping

commit 1a669c2f16d478cb7f4452e5fb8d09320831f4a1
Author: Roland McGrath <roland@redhat.com>
Date:   Wed Feb 6 01:37:37 2008 -0800

    Add arch_ptrace_stop
    
    This adds support to allow asm/ptrace.h to define two new macros,
    arch_ptrace_stop_needed and arch_ptrace_stop.  These control special
    machine-specific actions to be done before a ptrace stop.  The new code
    compiles away to nothing when the new macros are not defined.  This is the
    case on all machines to begin with.
    
    On ia64, these macros will be defined to solve the long-standing issue of
    ptrace vs register backing store.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Cc: Petr Tesarik <ptesarik@suse.cz>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Matthew Wilcox <willy@debian.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index e46971560fcb..5d30ff561847 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1577,6 +1577,17 @@ static inline int may_ptrace_stop(void)
 	return 1;
 }
 
+/*
+ * Return nonzero if there is a SIGKILL that should be waking us up.
+ * Called with the siglock held.
+ */
+static int sigkill_pending(struct task_struct *tsk)
+{
+	return ((sigismember(&tsk->pending.signal, SIGKILL) ||
+		 sigismember(&tsk->signal->shared_pending.signal, SIGKILL)) &&
+		!unlikely(sigismember(&tsk->blocked, SIGKILL)));
+}
+
 /*
  * This must be called with current->sighand->siglock held.
  *
@@ -1590,6 +1601,26 @@ static inline int may_ptrace_stop(void)
  */
 static void ptrace_stop(int exit_code, int nostop_code, siginfo_t *info)
 {
+	int killed = 0;
+
+	if (arch_ptrace_stop_needed(exit_code, info)) {
+		/*
+		 * The arch code has something special to do before a
+		 * ptrace stop.  This is allowed to block, e.g. for faults
+		 * on user stack pages.  We can't keep the siglock while
+		 * calling arch_ptrace_stop, so we must release it now.
+		 * To preserve proper semantics, we must do this before
+		 * any signal bookkeeping like checking group_stop_count.
+		 * Meanwhile, a SIGKILL could come in before we retake the
+		 * siglock.  That must prevent us from sleeping in TASK_TRACED.
+		 * So after regaining the lock, we must check for SIGKILL.
+		 */
+		spin_unlock_irq(&current->sighand->siglock);
+		arch_ptrace_stop(exit_code, info);
+		spin_lock_irq(&current->sighand->siglock);
+		killed = sigkill_pending(current);
+	}
+
 	/*
 	 * If there is a group stop in progress,
 	 * we must participate in the bookkeeping.
@@ -1605,7 +1636,7 @@ static void ptrace_stop(int exit_code, int nostop_code, siginfo_t *info)
 	spin_unlock_irq(&current->sighand->siglock);
 	try_to_freeze();
 	read_lock(&tasklist_lock);
-	if (may_ptrace_stop()) {
+	if (!unlikely(killed) && may_ptrace_stop()) {
 		do_notify_parent_cldstop(current, CLD_TRAPPED);
 		read_unlock(&tasklist_lock);
 		schedule();

commit d9ae90ac4bdce769ddb27c2e24c3351a30c3daf8
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Feb 6 01:36:13 2008 -0800

    use __set_task_state() for TRACED/STOPPED tasks
    
    1. It is much easier to grep for ->state change if __set_task_state() is used
       instead of the direct assignment.
    
    2. ptrace_stop() and handle_group_stop() use set_task_state() which adds the
       unneeded mb() (btw even if we use mb() it is still possible that do_wait()
       sees the new ->state but not ->exit_code, but this is ok).
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 6a5f97cd337a..e46971560fcb 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1601,7 +1601,7 @@ static void ptrace_stop(int exit_code, int nostop_code, siginfo_t *info)
 	current->exit_code = exit_code;
 
 	/* Let the debugger run.  */
-	set_current_state(TASK_TRACED);
+	__set_current_state(TASK_TRACED);
 	spin_unlock_irq(&current->sighand->siglock);
 	try_to_freeze();
 	read_lock(&tasklist_lock);

commit ed5d2cac114202fe2978a9cbcab8f5032796d538
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon Feb 4 22:27:24 2008 -0800

    exec: rework the group exit and fix the race with kill
    
    As Roland pointed out, we have the very old problem with exec.  de_thread()
    sets SIGNAL_GROUP_EXIT, kills other threads, changes ->group_leader and then
    clears signal->flags.  All signals (even fatal ones) sent in this window
    (which is not too small) will be lost.
    
    With this patch exec doesn't abuse SIGNAL_GROUP_EXIT.  signal_group_exit(),
    the new helper, should be used to detect exit_group() or exec() in progress.
    It can have more users, but this patch does only strictly necessary changes.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Davide Libenzi <davidel@xmailserver.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Robin Holt <holt@sgi.com>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1117b28488c2..6a5f97cd337a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -957,7 +957,6 @@ void zap_other_threads(struct task_struct *p)
 {
 	struct task_struct *t;
 
-	p->signal->flags = SIGNAL_GROUP_EXIT;
 	p->signal->group_stop_count = 0;
 
 	for (t = next_thread(p); t != p; t = next_thread(t)) {
@@ -1697,7 +1696,8 @@ static int do_signal_stop(int signr)
 	} else {
 		struct task_struct *t;
 
-		if (!likely(sig->flags & SIGNAL_STOP_DEQUEUED))
+		if (!likely(sig->flags & SIGNAL_STOP_DEQUEUED) ||
+		    unlikely(sig->group_exit_task))
 			return 0;
 		/*
 		 * There is no group stop already in progress.

commit f558b7e408026eb3c6afcd0e8fc1f7fe31195a6a
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon Feb 4 22:27:24 2008 -0800

    remove handle_group_stop() in favor of do_signal_stop()
    
    Every time we set SIGNAL_GROUP_EXIT or clear SIGNAL_STOP_DEQUEUED we also
    reset ->group_stop_count.
    
    This means that the SIGNAL_GROUP_EXIT check in handle_group_stop() is not
    needed, and do_signal_stop() should check SIGNAL_STOP_DEQUEUED only when
    ->group_stop_count == 0. With these changes handle_group_stop() becomes the
    subset of do_signal_stop(), we can kill it and use do_signal_stop() instead.
    
    Also, a preparation for the next patch.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Davide Libenzi <davidel@xmailserver.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Robin Holt <holt@sgi.com>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index ea90c34e9348..1117b28488c2 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1688,9 +1688,6 @@ static int do_signal_stop(int signr)
 	struct signal_struct *sig = current->signal;
 	int stop_count;
 
-	if (!likely(sig->flags & SIGNAL_STOP_DEQUEUED))
-		return 0;
-
 	if (sig->group_stop_count > 0) {
 		/*
 		 * There is a group stop in progress.  We don't need to
@@ -1698,12 +1695,14 @@ static int do_signal_stop(int signr)
 		 */
 		stop_count = --sig->group_stop_count;
 	} else {
+		struct task_struct *t;
+
+		if (!likely(sig->flags & SIGNAL_STOP_DEQUEUED))
+			return 0;
 		/*
 		 * There is no group stop already in progress.
 		 * We must initiate one now.
 		 */
-		struct task_struct *t;
-
 		sig->group_exit_code = signr;
 
 		stop_count = 0;
@@ -1731,38 +1730,6 @@ static int do_signal_stop(int signr)
 	return 1;
 }
 
-/*
- * Do appropriate magic when group_stop_count > 0.
- * We return nonzero if we stopped, after releasing the siglock.
- * We return zero if we still hold the siglock and should look
- * for another signal without checking group_stop_count again.
- */
-static int handle_group_stop(void)
-{
-	int stop_count;
-
-	if (current->signal->flags & SIGNAL_GROUP_EXIT)
-		/*
-		 * Group stop is so another thread can do a core dump,
-		 * or else we are racing against a death signal.
-		 * Just punt the stop so we can get the next signal.
-		 */
-		return 0;
-
-	/*
-	 * There is a group stop in progress.  We stop
-	 * without any associated signal being in our queue.
-	 */
-	stop_count = --current->signal->group_stop_count;
-	if (stop_count == 0)
-		current->signal->flags = SIGNAL_STOP_STOPPED;
-	current->exit_code = current->signal->group_exit_code;
-	set_current_state(TASK_STOPPED);
-	spin_unlock_irq(&current->sighand->siglock);
-	finish_stop(stop_count);
-	return 1;
-}
-
 int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 			  struct pt_regs *regs, void *cookie)
 {
@@ -1777,7 +1744,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		struct k_sigaction *ka;
 
 		if (unlikely(current->signal->group_stop_count > 0) &&
-		    handle_group_stop())
+		    do_signal_stop(0))
 			goto relock;
 
 		signr = dequeue_signal(current, mask, info);

commit 198466b41d11dd062fb26ee0376080458d7bfcaf
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon Feb 4 22:27:23 2008 -0800

    __group_complete_signal(): fix coredump with group stop race
    
    When __group_complete_signal() sees sig_kernel_coredump() signal, it starts
    the group stop, but sets ->group_exit_task = t in a hope that "t" will
    actually dequeue this signal and invoke do_coredump().  However, by the
    time "t" enters get_signal_to_deliver() it is possible that the signal was
    blocked/ignored or we have another pending !SIG_KERNEL_COREDUMP_MASK signal
    which will be dequeued first.  This means the task could be stopped but not
    killed.
    
    Remove this code from __group_complete_signal().  Note also this patch
    removes the bogus signal_wake_up(t, 1).  This thread can't be
    STOPPED/TRACED, note the corresponding check in wants_signal().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Davide Libenzi <davidel@xmailserver.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Robin Holt <holt@sgi.com>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 4333b6dbb424..ea90c34e9348 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -911,27 +911,6 @@ __group_complete_signal(int sig, struct task_struct *p)
 			} while_each_thread(p, t);
 			return;
 		}
-
-		/*
-		 * There will be a core dump.  We make all threads other
-		 * than the chosen one go into a group stop so that nothing
-		 * happens until it gets scheduled, takes the signal off
-		 * the shared queue, and does the core dump.  This is a
-		 * little more complicated than strictly necessary, but it
-		 * keeps the signal state that winds up in the core dump
-		 * unchanged from the death state, e.g. which thread had
-		 * the core-dump signal unblocked.
-		 */
-		rm_from_queue(SIG_KERNEL_STOP_MASK, &t->pending);
-		rm_from_queue(SIG_KERNEL_STOP_MASK, &p->signal->shared_pending);
-		p->signal->group_stop_count = 0;
-		p->signal->group_exit_task = t;
-		p = t;
-		do {
-			p->signal->group_stop_count++;
-			signal_wake_up(t, t == p);
-		} while_each_thread(p, t);
-		return;
 	}
 
 	/*
@@ -1762,15 +1741,6 @@ static int handle_group_stop(void)
 {
 	int stop_count;
 
-	if (current->signal->group_exit_task == current) {
-		/*
-		 * Group stop is so we can do a core dump,
-		 * We are the initiating thread, so get on with it.
-		 */
-		current->signal->group_exit_task = NULL;
-		return 0;
-	}
-
 	if (current->signal->flags & SIGNAL_GROUP_EXIT)
 		/*
 		 * Group stop is so another thread can do a core dump,

commit 13f09b95a82c46ed608d057b22e0dd18ebfff22a
Author: Trond Myklebust <Trond.Myklebust@netapp.com>
Date:   Thu Jan 31 20:40:29 2008 -0500

    Ensure that we export __fatal_signal_pending()
    
    It may be used by the modules nfs.ko and sunrpc.ko
    
    Signed-off-by: Trond Myklebust <Trond.Myklebust@netapp.com>
    [ Made it a regular export rather than GPL-only  - Linus ]
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8054dd4e2d76..4333b6dbb424 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -998,6 +998,7 @@ int fastcall __fatal_signal_pending(struct task_struct *tsk)
 {
 	return sigismember(&tsk->pending.signal, SIGKILL);
 }
+EXPORT_SYMBOL(__fatal_signal_pending);
 
 /*
  * Must be called under rcu_read_lock() or with tasklist_lock read-held.

commit 75659ca0c10992dcb39258518368a0f6f56e935d
Merge: fbdde7bd274d 2dfe485a2c8a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Feb 1 11:45:47 2008 +1100

    Merge branch 'task_killable' of git://git.kernel.org/pub/scm/linux/kernel/git/willy/misc
    
    * 'task_killable' of git://git.kernel.org/pub/scm/linux/kernel/git/willy/misc: (22 commits)
      Remove commented-out code copied from NFS
      NFS: Switch from intr mount option to TASK_KILLABLE
      Add wait_for_completion_killable
      Add wait_event_killable
      Add schedule_timeout_killable
      Use mutex_lock_killable in vfs_readdir
      Add mutex_lock_killable
      Use lock_page_killable
      Add lock_page_killable
      Add fatal_signal_pending
      Add TASK_WAKEKILL
      exit: Use task_is_*
      signal: Use task_is_*
      sched: Use task_contributes_to_load, TASK_ALL and TASK_NORMAL
      ptrace: Use task_is_*
      power: Use task_is_*
      wait: Use TASK_NORMAL
      proc/base.c: Use task_is_*
      proc/array.c: Use TASK_REPORT
      perfmon: Use task_is_*
      ...
    
    Fixed up conflicts in NFS/sunrpc manually..

commit 65ea5b0349903585bfed9720fa06f5edb4f1cd25
Author: H. Peter Anvin <hpa@zytor.com>
Date:   Wed Jan 30 13:30:56 2008 +0100

    x86: rename the struct pt_regs members for 32/64-bit consistency
    
    We have a lot of code which differs only by the naming of specific
    members of structures that contain registers.  In order to enable
    additional unifications, this patch drops the e- or r- size prefix
    from the register names in struct pt_regs, and drops the x- prefixes
    for segment registers on the 32-bit side.
    
    This patch also performs the equivalent renames in some additional
    places that might be candidates for unification in the future.
    
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/signal.c b/kernel/signal.c
index afa4f781f924..bf49ce6f016b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -733,13 +733,13 @@ static void print_fatal_signal(struct pt_regs *regs, int signr)
 		current->comm, task_pid_nr(current), signr);
 
 #if defined(__i386__) && !defined(__arch_um__)
-	printk("code at %08lx: ", regs->eip);
+	printk("code at %08lx: ", regs->ip);
 	{
 		int i;
 		for (i = 0; i < 16; i++) {
 			unsigned char insn;
 
-			__get_user(insn, (unsigned char *)(regs->eip + i));
+			__get_user(insn, (unsigned char *)(regs->ip + i));
 			printk("%02x ", insn);
 		}
 	}

commit f776d12dd16da1b0cd55a1240002c1b31f315d5d
Author: Matthew Wilcox <matthew@wil.cx>
Date:   Thu Dec 6 11:15:50 2007 -0500

    Add fatal_signal_pending
    
    Like signal_pending, but it's only true for signals which are fatal to
    this process
    
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index fd4797f30628..657aa16d97cb 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -994,6 +994,11 @@ void zap_other_threads(struct task_struct *p)
 	}
 }
 
+int fastcall __fatal_signal_pending(struct task_struct *tsk)
+{
+	return sigismember(&tsk->pending.signal, SIGKILL);
+}
+
 /*
  * Must be called under rcu_read_lock() or with tasklist_lock read-held.
  */

commit f021a3c2b14d0dd082c2cee890c204d9e1dee52b
Author: Matthew Wilcox <matthew@wil.cx>
Date:   Thu Dec 6 11:13:16 2007 -0500

    Add TASK_WAKEKILL
    
    Set TASK_WAKEKILL for TASK_STOPPED and TASK_TRACED, add TASK_KILLABLE and
    use TASK_WAKEKILL in signal_wake_up()
    
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index c5a401aa715c..fd4797f30628 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -456,15 +456,15 @@ void signal_wake_up(struct task_struct *t, int resume)
 	set_tsk_thread_flag(t, TIF_SIGPENDING);
 
 	/*
-	 * For SIGKILL, we want to wake it up in the stopped/traced case.
-	 * We don't check t->state here because there is a race with it
+	 * For SIGKILL, we want to wake it up in the stopped/traced/killable
+	 * case. We don't check t->state here because there is a race with it
 	 * executing another processor and just now entering stopped state.
 	 * By using wake_up_state, we ensure the process will wake up and
 	 * handle its death signal.
 	 */
 	mask = TASK_INTERRUPTIBLE;
 	if (resume)
-		mask |= TASK_STOPPED | TASK_TRACED;
+		mask |= TASK_WAKEKILL;
 	if (!wake_up_state(t, mask))
 		kick_process(t);
 }
@@ -620,7 +620,7 @@ static void handle_stop_signal(int sig, struct task_struct *p)
 			 * Wake up the stopped thread _after_ setting
 			 * TIF_SIGPENDING
 			 */
-			state = TASK_STOPPED;
+			state = __TASK_STOPPED;
 			if (sig_user_defined(t, SIGCONT) && !sigismember(&t->blocked, SIGCONT)) {
 				set_tsk_thread_flag(t, TIF_SIGPENDING);
 				state |= TASK_INTERRUPTIBLE;

commit e1abb39c60971590b6580c0d3a12119dcbad9c50
Author: Matthew Wilcox <matthew@wil.cx>
Date:   Thu Dec 6 11:07:35 2007 -0500

    signal: Use task_is_*
    
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>

diff --git a/kernel/signal.c b/kernel/signal.c
index afa4f781f924..c5a401aa715c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -838,7 +838,7 @@ static inline int wants_signal(int sig, struct task_struct *p)
 		return 0;
 	if (sig == SIGKILL)
 		return 1;
-	if (p->state & (TASK_STOPPED | TASK_TRACED))
+	if (task_is_stopped_or_traced(p))
 		return 0;
 	return task_curr(p) || !signal_pending(p);
 }
@@ -1441,7 +1441,7 @@ void do_notify_parent(struct task_struct *tsk, int sig)
 	BUG_ON(sig == -1);
 
  	/* do_notify_parent_cldstop should have been called instead.  */
- 	BUG_ON(tsk->state & (TASK_STOPPED|TASK_TRACED));
+ 	BUG_ON(task_is_stopped_or_traced(tsk));
 
 	BUG_ON(!tsk->ptrace &&
 	       (tsk->group_leader != tsk || !thread_group_empty(tsk)));
@@ -1729,7 +1729,7 @@ static int do_signal_stop(int signr)
 			 * so this check has no races.
 			 */
 			if (!t->exit_state &&
-			    !(t->state & (TASK_STOPPED|TASK_TRACED))) {
+			    !task_is_stopped_or_traced(t)) {
 				stop_count++;
 				signal_wake_up(t, 0);
 			}

commit 325d22df7b19e0116aff3391d3a03f73d0634ded
Author: Roland McGrath <roland@redhat.com>
Date:   Mon Nov 12 15:41:55 2007 -0800

    sigwait eats blocked default-ignore signals
    
    While a signal is blocked, it must be posted even if its action is
    SIG_IGN or is SIG_DFL with the default action to ignore.  This works
    right most of the time, but is broken when a sigwait (rt_sigtimedwait)
    is in progress.  This changes the early-discard check to respect
    real_blocked.  ~blocked is the set to check for "should wake up now",
    but ~(blocked|real_blocked) is the set for "blocked" semantics as
    defined by POSIX.
    
    This fixes bugzilla entry 9347, see
    
            http://bugzilla.kernel.org/show_bug.cgi?id=9347
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 909a0cc6bc70..afa4f781f924 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -55,7 +55,7 @@ static int sig_ignored(struct task_struct *t, int sig)
 	 * signal handler may change by the time it is
 	 * unblocked.
 	 */
-	if (sigismember(&t->blocked, sig))
+	if (sigismember(&t->blocked, sig) || sigismember(&t->real_blocked, sig))
 		return 0;
 
 	/* Is it explicitly or implicitly ignored? */

commit cc5f916e90a811dd8f809b4d17409f98e74b237c
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Mon Oct 29 14:37:12 2007 -0700

    Freezer: do not allow freezing processes to clear TIF_SIGPENDING
    
    Do not allow processes to clear their TIF_SIGPENDING if TIF_FREEZE is set,
    so that they will not race with the freezer (like mysqld does, for example).
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Acked-by: Nigel Cunningham <nigel@suspend2.net>
    Acked-by: Pavel Machek <pavel@ucw.cz>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 4537bdda1ebf..909a0cc6bc70 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -124,7 +124,7 @@ void recalc_sigpending_and_wake(struct task_struct *t)
 
 void recalc_sigpending(void)
 {
-	if (!recalc_sigpending_tsk(current))
+	if (!recalc_sigpending_tsk(current) && !freezing(current))
 		clear_thread_flag(TIF_SIGPENDING);
 
 }

commit ca5cd877ae699e758e6f26efc11b01bf6631d427
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Mon Oct 29 04:31:16 2007 +0000

    x86 merge fallout: uml
    
    Don't undef __i386__/__x86_64__ in uml anymore, make sure that (few) places
    that required adjusting the ifdefs got those.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 12006308c7eb..4537bdda1ebf 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -732,7 +732,7 @@ static void print_fatal_signal(struct pt_regs *regs, int signr)
 	printk("%s/%d: potentially unexpected fatal signal %d.\n",
 		current->comm, task_pid_nr(current), signr);
 
-#ifdef __i386__
+#if defined(__i386__) && !defined(__arch_um__)
 	printk("code at %08lx: ", regs->eip);
 	{
 		int i;

commit ba25f9dcc4ea6e30839fcab5a5516f2176d5bfed
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Oct 18 23:40:40 2007 -0700

    Use helpers to obtain task pid in printks
    
    The task_struct->pid member is going to be deprecated, so start
    using the helpers (task_pid_nr/task_pid_vnr/task_pid_nr_ns) in
    the kernel.
    
    The first thing to start with is the pid, printed to dmesg - in
    this case we may safely use task_pid_nr(). Besides, printks produce
    more (much more) than a half of all the explicit pid usage.
    
    [akpm@linux-foundation.org: git-drm went and changed lots of stuff]
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Dave Airlie <airlied@linux.ie>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 08364e75bb58..12006308c7eb 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -730,7 +730,7 @@ int print_fatal_signals;
 static void print_fatal_signal(struct pt_regs *regs, int signr)
 {
 	printk("%s/%d: potentially unexpected fatal signal %d.\n",
-		current->comm, current->pid, signr);
+		current->comm, task_pid_nr(current), signr);
 
 #ifdef __i386__
 	printk("code at %08lx: ", regs->eip);

commit bac0abd6174e427404dd197cdbefece31e97329b
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Oct 18 23:40:18 2007 -0700

    Isolate some explicit usage of task->tgid
    
    With pid namespaces this field is now dangerous to use explicitly, so hide
    it behind the helpers.
    
    Also the pid and pgrp fields o task_struct and signal_struct are to be
    deprecated.  Unfortunately this patch cannot be sent right now as this
    leads to tons of warnings, so start isolating them, and deprecate later.
    
    Actually the p->tgid == pid has to be changed to has_group_leader_pid(),
    but Oleg pointed out that in case of posix cpu timers this is the same, and
    thread_group_leader() is more preferable.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Acked-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 783b33a0af06..08364e75bb58 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1150,7 +1150,7 @@ static int kill_something_info(int sig, struct siginfo *info, int pid)
 
 		read_lock(&tasklist_lock);
 		for_each_process(p) {
-			if (p->pid > 1 && p->tgid != current->tgid) {
+			if (p->pid > 1 && !same_thread_group(p, current)) {
 				int err = group_send_sig_info(sig, info, p);
 				++count;
 				if (err != -EPERM)

commit 228ebcbe634a30aec35132ea4375721bcc41bec0
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Oct 18 23:40:16 2007 -0700

    Uninline find_task_by_xxx set of functions
    
    The find_task_by_something is a set of macros are used to find task by pid
    depending on what kind of pid is proposed - global or virtual one.  All of
    them are wrappers above the most generic one - find_task_by_pid_type_ns() -
    and just substitute some args for it.
    
    It turned out, that dereferencing the current->nsproxy->pid_ns construction
    and pushing one more argument on the stack inline cause kernel text size to
    grow.
    
    This patch moves all this stuff out-of-line into kernel/pid.c.  Together
    with the next patch it saves a bit less than 400 bytes from the .text
    section.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Paul Menage <menage@google.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index d809cdd6c0f1..783b33a0af06 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2237,7 +2237,7 @@ static int do_tkill(int tgid, int pid, int sig)
 	info.si_uid = current->uid;
 
 	read_lock(&tasklist_lock);
-	p = find_task_by_pid_ns(pid, current->nsproxy->pid_ns);
+	p = find_task_by_vpid(pid);
 	if (p && (tgid <= 0 || task_tgid_vnr(p) == tgid)) {
 		error = check_kill_permission(sig, &info, p);
 		/*

commit b488893a390edfe027bae7a46e9af8083e740668
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Oct 18 23:40:14 2007 -0700

    pid namespaces: changes to show virtual ids to user
    
    This is the largest patch in the set. Make all (I hope) the places where
    the pid is shown to or get from user operate on the virtual pids.
    
    The idea is:
     - all in-kernel data structures must store either struct pid itself
       or the pid's global nr, obtained with pid_nr() call;
     - when seeking the task from kernel code with the stored id one
       should use find_task_by_pid() call that works with global pids;
     - when showing pid's numerical value to the user the virtual one
       should be used, but however when one shows task's pid outside this
       task's namespace the global one is to be used;
     - when getting the pid from userspace one need to consider this as
       the virtual one and use appropriate task/pid-searching functions.
    
    [akpm@linux-foundation.org: build fix]
    [akpm@linux-foundation.org: nuther build fix]
    [akpm@linux-foundation.org: yet nuther build fix]
    [akpm@linux-foundation.org: remove unneeded casts]
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: Alexey Dobriyan <adobriyan@openvz.org>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Paul Menage <menage@google.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 98923882ba57..d809cdd6c0f1 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -694,7 +694,7 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			q->info.si_signo = sig;
 			q->info.si_errno = 0;
 			q->info.si_code = SI_USER;
-			q->info.si_pid = current->pid;
+			q->info.si_pid = task_pid_vnr(current);
 			q->info.si_uid = current->uid;
 			break;
 		case (unsigned long) SEND_SIG_PRIV:
@@ -1089,7 +1089,7 @@ kill_proc_info(int sig, struct siginfo *info, pid_t pid)
 {
 	int error;
 	rcu_read_lock();
-	error = kill_pid_info(sig, info, find_pid(pid));
+	error = kill_pid_info(sig, info, find_vpid(pid));
 	rcu_read_unlock();
 	return error;
 }
@@ -1160,9 +1160,9 @@ static int kill_something_info(int sig, struct siginfo *info, int pid)
 		read_unlock(&tasklist_lock);
 		ret = count ? retval : -ESRCH;
 	} else if (pid < 0) {
-		ret = kill_pgrp_info(sig, info, find_pid(-pid));
+		ret = kill_pgrp_info(sig, info, find_vpid(-pid));
 	} else {
-		ret = kill_pid_info(sig, info, find_pid(pid));
+		ret = kill_pid_info(sig, info, find_vpid(pid));
 	}
 	rcu_read_unlock();
 	return ret;
@@ -1266,7 +1266,12 @@ EXPORT_SYMBOL(kill_pid);
 int
 kill_proc(pid_t pid, int sig, int priv)
 {
-	return kill_proc_info(sig, __si_special(priv), pid);
+	int ret;
+
+	rcu_read_lock();
+	ret = kill_pid_info(sig, __si_special(priv), find_pid(pid));
+	rcu_read_unlock();
+	return ret;
 }
 
 /*
@@ -1443,7 +1448,22 @@ void do_notify_parent(struct task_struct *tsk, int sig)
 
 	info.si_signo = sig;
 	info.si_errno = 0;
-	info.si_pid = tsk->pid;
+	/*
+	 * we are under tasklist_lock here so our parent is tied to
+	 * us and cannot exit and release its namespace.
+	 *
+	 * the only it can is to switch its nsproxy with sys_unshare,
+	 * bu uncharing pid namespaces is not allowed, so we'll always
+	 * see relevant namespace
+	 *
+	 * write_lock() currently calls preempt_disable() which is the
+	 * same as rcu_read_lock(), but according to Oleg, this is not
+	 * correct to rely on this
+	 */
+	rcu_read_lock();
+	info.si_pid = task_pid_nr_ns(tsk, tsk->parent->nsproxy->pid_ns);
+	rcu_read_unlock();
+
 	info.si_uid = tsk->uid;
 
 	/* FIXME: find out whether or not this is supposed to be c*time. */
@@ -1508,7 +1528,13 @@ static void do_notify_parent_cldstop(struct task_struct *tsk, int why)
 
 	info.si_signo = SIGCHLD;
 	info.si_errno = 0;
-	info.si_pid = tsk->pid;
+	/*
+	 * see comment in do_notify_parent() abot the following 3 lines
+	 */
+	rcu_read_lock();
+	info.si_pid = task_pid_nr_ns(tsk, tsk->parent->nsproxy->pid_ns);
+	rcu_read_unlock();
+
 	info.si_uid = tsk->uid;
 
 	/* FIXME: find out whether or not this is supposed to be c*time. */
@@ -1634,7 +1660,7 @@ void ptrace_notify(int exit_code)
 	memset(&info, 0, sizeof info);
 	info.si_signo = SIGTRAP;
 	info.si_code = exit_code;
-	info.si_pid = current->pid;
+	info.si_pid = task_pid_vnr(current);
 	info.si_uid = current->uid;
 
 	/* Let the debugger run.  */
@@ -1804,7 +1830,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 				info->si_signo = signr;
 				info->si_errno = 0;
 				info->si_code = SI_USER;
-				info->si_pid = current->parent->pid;
+				info->si_pid = task_pid_vnr(current->parent);
 				info->si_uid = current->parent->uid;
 			}
 
@@ -2191,7 +2217,7 @@ sys_kill(int pid, int sig)
 	info.si_signo = sig;
 	info.si_errno = 0;
 	info.si_code = SI_USER;
-	info.si_pid = current->tgid;
+	info.si_pid = task_tgid_vnr(current);
 	info.si_uid = current->uid;
 
 	return kill_something_info(sig, &info, pid);
@@ -2207,12 +2233,12 @@ static int do_tkill(int tgid, int pid, int sig)
 	info.si_signo = sig;
 	info.si_errno = 0;
 	info.si_code = SI_TKILL;
-	info.si_pid = current->tgid;
+	info.si_pid = task_tgid_vnr(current);
 	info.si_uid = current->uid;
 
 	read_lock(&tasklist_lock);
-	p = find_task_by_pid(pid);
-	if (p && (tgid <= 0 || p->tgid == tgid)) {
+	p = find_task_by_pid_ns(pid, current->nsproxy->pid_ns);
+	if (p && (tgid <= 0 || task_tgid_vnr(p) == tgid)) {
 		error = check_kill_permission(sig, &info, p);
 		/*
 		 * The null signal is a permissions and process existence

commit 0fbc26a6cfab9f377e82e28225f2c0c6b4661e5c
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Thu Oct 18 23:40:13 2007 -0700

    pid namespaces: allow signalling cgroup-init
    
    Only the global-init process must be special - any other cgroup-init
    process must be killable to prevent run-away processes in the system.
    
    TODO:   Ideally we should allow killing the cgroup-init only from parent
            cgroup and prevent it being killed from within the cgroup.
            But that is a more complex change and will be addressed by a follow-on
            patch. For now allow the cgroup-init to be terminated by any process
            with sufficient privileges.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Acked-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Paul Menage <menage@google.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8214ffad54bc..98923882ba57 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1835,11 +1835,9 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 			continue;
 
 		/*
-		 * Init of a pid space gets no signals it doesn't want from
-		 * within that pid space. It can of course get signals from
-		 * its parent pid space.
+		 * Global init gets no signals it doesn't want.
 		 */
-		if (current == task_child_reaper(current))
+		if (is_global_init(current))
 			continue;
 
 		if (sig_kernel_stop(signr)) {

commit b460cbc581a53cc088ceba80608021dd49c63c43
Author: Serge E. Hallyn <serue@us.ibm.com>
Date:   Thu Oct 18 23:39:52 2007 -0700

    pid namespaces: define is_global_init() and is_container_init()
    
    is_init() is an ambiguous name for the pid==1 check.  Split it into
    is_global_init() and is_container_init().
    
    A cgroup init has it's tsk->pid == 1.
    
    A global init also has it's tsk->pid == 1 and it's active pid namespace
    is the init_pid_ns.  But rather than check the active pid namespace,
    compare the task structure with 'init_pid_ns.child_reaper', which is
    initialized during boot to the /sbin/init process and never changes.
    
    Changelog:
    
            2.6.22-rc4-mm2-pidns1:
            - Use 'init_pid_ns.child_reaper' to determine if a given task is the
              global init (/sbin/init) process. This would improve performance
              and remove dependence on the task_pid().
    
            2.6.21-mm2-pidns2:
    
            - [Sukadev Bhattiprolu] Changed is_container_init() calls in {powerpc,
              ppc,avr32}/traps.c for the _exception() call to is_global_init().
              This way, we kill only the cgroup if the cgroup's init has a
              bug rather than force a kernel panic.
    
    [akpm@linux-foundation.org: fix comment]
    [sukadev@us.ibm.com: Use is_global_init() in arch/m32r/mm/fault.c]
    [bunk@stusta.de: kernel/pid.c: remove unused exports]
    [sukadev@us.ibm.com: Fix capability.c to work with threaded init]
    Signed-off-by: Serge E. Hallyn <serue@us.ibm.com>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Acked-by: Pavel Emelianov <xemul@openvz.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Herbert Poetzel <herbert@13thfloor.at>
    Cc: Kirill Korotaev <dev@sw.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0a6d3726cb80..8214ffad54bc 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -256,7 +256,7 @@ flush_signal_handlers(struct task_struct *t, int force_default)
 
 int unhandled_signal(struct task_struct *tsk, int sig)
 {
-	if (is_init(tsk))
+	if (is_global_init(tsk))
 		return 1;
 	if (tsk->ptrace & PT_PTRACED)
 		return 0;

commit 88f21d818255bc61c002478d21caf52f8a9b8def
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Thu Oct 18 23:39:50 2007 -0700

    pid namespaces: rename child_reaper() function
    
    Rename the child_reaper() function to task_child_reaper() to be similar to
    other task_* functions and to distinguish the function from 'struct
    pid_namspace.child_reaper'.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Pavel Emelianov <xemul@openvz.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: Herbert Poetzel <herbert@13thfloor.at>
    Cc: Kirill Korotaev <dev@sw.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 15c6940ab046..0a6d3726cb80 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1839,7 +1839,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		 * within that pid space. It can of course get signals from
 		 * its parent pid space.
 		 */
-		if (current == child_reaper(current))
+		if (current == task_child_reaper(current))
 			continue;
 
 		if (sig_kernel_stop(signr)) {

commit a47afb0f9d794d525a372c8d69902147cc88222a
Author: Pavel Emelianov <xemul@openvz.org>
Date:   Thu Oct 18 23:39:46 2007 -0700

    pid namespaces: round up the API
    
    The set of functions process_session, task_session, process_group and
    task_pgrp is confusing, as the names can be mixed with each other when looking
    at the code for a long time.
    
    The proposals are to
    * equip the functions that return the integer with _nr suffix to
      represent that fact,
    * and to make all functions work with task (not process) by making
      the common prefix of the same name.
    
    For monotony the routines signal_session() and set_signal_session() are
    replaced with task_session_nr() and set_task_session(), especially since they
    are only used with the explicit task->signal dereference.
    
    Signed-off-by: Pavel Emelianov <xemul@openvz.org>
    Acked-by: Serge E. Hallyn <serue@us.ibm.com>
    Cc: Kirill Korotaev <dev@openvz.org>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index e4f059cd9867..15c6940ab046 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -536,7 +536,7 @@ static int check_kill_permission(int sig, struct siginfo *info,
 			return error;
 		error = -EPERM;
 		if (((sig != SIGCONT) ||
-			(process_session(current) != process_session(t)))
+			(task_session_nr(current) != task_session_nr(t)))
 		    && (current->euid ^ t->suid) && (current->euid ^ t->uid)
 		    && (current->uid ^ t->suid) && (current->uid ^ t->uid)
 		    && !capable(CAP_KILL))

commit d5d8c5976d6adeddb8208c240460411e2198b393
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Thu Oct 18 03:04:46 2007 -0700

    freezer: do not send signals to kernel threads
    
    The freezer should not send signals to kernel threads, since that may lead to
    subtle problems.  In particular, commit
    b74d0deb968e1f85942f17080eace015ce3c332c has changed recalc_sigpending_tsk()
    so that it doesn't clear TIF_SIGPENDING.  For this reason, if the freezer
    continues to send fake signals to kernel threads and the freezing of kernel
    threads fails, some of them may be running with TIF_SIGPENDING set forever.
    
    Accordingly, recalc_sigpending_tsk() shouldn't set the task's TIF_SIGPENDING
    flag if TIF_FREEZE is set.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Nigel Cunningham <nigel@nigel.suspend2.net>
    Cc: Pavel Machek <pavel@ucw.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2124ffadcfde..e4f059cd9867 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -99,7 +99,6 @@ static inline int has_pending_signals(sigset_t *signal, sigset_t *blocked)
 static int recalc_sigpending_tsk(struct task_struct *t)
 {
 	if (t->signal->group_stop_count > 0 ||
-	    (freezing(t)) ||
 	    PENDING(&t->pending, &t->blocked) ||
 	    PENDING(&t->signal->shared_pending, &t->blocked)) {
 		set_tsk_thread_flag(t, TIF_SIGPENDING);

commit 13fbcb731220341537131b32cf01b1e70df7206d
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Oct 16 23:27:24 2007 -0700

    do_sigaction: don't worry about signal_pending()
    
    do_sigaction() returns -ERESTARTNOINTR if signal_pending(). The comment says:
    
            * If there might be a fatal signal pending on multiple
            * threads, make sure we take it before changing the action.
    
    I think this is not needed. We should only worry about SIGNAL_GROUP_EXIT case,
    bit it implies a pending SIGKILL which can't be cleared by do_sigaction.
    
    Kill this special case.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 90e2efad33ae..2124ffadcfde 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2294,15 +2294,6 @@ int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 	k = &current->sighand->action[sig-1];
 
 	spin_lock_irq(&current->sighand->siglock);
-	if (signal_pending(current)) {
-		/*
-		 * If there might be a fatal signal pending on multiple
-		 * threads, make sure we take it before changing the action.
-		 */
-		spin_unlock_irq(&current->sighand->siglock);
-		return -ERESTARTNOINTR;
-	}
-
 	if (oact)
 		*oact = *k;
 

commit 18442cf28af81378cf8996d264b368bba47cf846
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Oct 16 23:27:00 2007 -0700

    __group_complete_signal: eliminate unneeded wakeup of ->group_exit_task
    
    Cleanup.  __group_complete_signal() wakes up ->group_exit_task twice.  The
    second wakeup's state includes TASK_UNINTERRUPTIBLE, which is not very
    appropriate.
    
    Change the code to pass the "correct" argument to signal_wake_up() and kill
    now unneeded wake_up_process().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index b7aa492e16ad..90e2efad33ae 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -909,8 +909,7 @@ __group_complete_signal(int sig, struct task_struct *p)
 			do {
 				sigaddset(&t->pending.signal, SIGKILL);
 				signal_wake_up(t, 1);
-				t = next_thread(t);
-			} while (t != p);
+			} while_each_thread(p, t);
 			return;
 		}
 
@@ -928,13 +927,11 @@ __group_complete_signal(int sig, struct task_struct *p)
 		rm_from_queue(SIG_KERNEL_STOP_MASK, &p->signal->shared_pending);
 		p->signal->group_stop_count = 0;
 		p->signal->group_exit_task = t;
-		t = p;
+		p = t;
 		do {
 			p->signal->group_stop_count++;
-			signal_wake_up(t, 0);
-			t = next_thread(t);
-		} while (t != p);
-		wake_up_process(p->signal->group_exit_task);
+			signal_wake_up(t, t == p);
+		} while_each_thread(p, t);
 		return;
 	}
 

commit ebca4cda1133775111e8b09f7124a7e5e391926d
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Oct 16 23:26:59 2007 -0700

    zap_other_threads: don't optimize thread_group_empty() case
    
    Nowadays thread_group_empty() and next_thread() are simple list operations,
    this optimization doesn't make sense: we are doing exactly same check one
    line below.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2f7736ff7418..b7aa492e16ad 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -985,9 +985,6 @@ void zap_other_threads(struct task_struct *p)
 	p->signal->flags = SIGNAL_GROUP_EXIT;
 	p->signal->group_stop_count = 0;
 
-	if (thread_group_empty(p))
-		return;
-
 	for (t = next_thread(p); t != p; t = next_thread(t)) {
 		/*
 		 * Don't bother with already dead threads

commit 045f902de5a6eb5927c0f092c38be7a381f634f0
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Oct 16 23:26:47 2007 -0700

    do_sigaction: remove now unneeded recalc_sigpending()
    
    With the recent changes, do_sigaction()->recalc_sigpending_and_wake() can
    never clear TIF_SIGPENDING. Instead, it can set this flag and wake up the
    thread without any reason. Harmless, but unneeded and wastes CPU.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Roland McGrath <roland@redhat.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 792952381092..2f7736ff7418 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2335,7 +2335,6 @@ int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 			rm_from_queue_full(&mask, &t->signal->shared_pending);
 			do {
 				rm_from_queue_full(&mask, &t->pending);
-				recalc_sigpending_and_wake(t);
 				t = next_thread(t);
 			} while (t != current);
 		}

commit 291041e935e6d0513f2b7e4a300aa9f02ec1d925
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Sun Oct 7 00:24:36 2007 -0700

    fix bogus reporting of signals by audit
    
    Async signals should not be reported as sent by current in audit log.  As
    it is, we call audit_signal_info() too early in check_kill_permission().
    Note that check_kill_permission() has that test already - it needs to know
    if it should apply current-based permission checks.  So the solution is to
    move the call of audit_signal_info() between those.
    
    Bogosity in question is easily reproduced - add a rule watching for e.g.
    kill(2) from specific process (so that audit_signal_info() would not
    short-circuit to nothing), say load_policy, watch the bogus OBJ_PID entry
    in audit logs claiming that write(2) on selinuxfs file issued by
    load_policy(8) had somehow managed to send a signal to syslogd...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Acked-by: Steve Grubb <sgrubb@redhat.com>
    Acked-by: Eric Paris <eparis@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9fb91a32edda..792952381092 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -531,18 +531,18 @@ static int check_kill_permission(int sig, struct siginfo *info,
 	if (!valid_signal(sig))
 		return error;
 
-	error = audit_signal_info(sig, t); /* Let audit system see the signal */
-	if (error)
-		return error;
-
-	error = -EPERM;
-	if ((info == SEND_SIG_NOINFO || (!is_si_special(info) && SI_FROMUSER(info)))
-	    && ((sig != SIGCONT) ||
-		(process_session(current) != process_session(t)))
-	    && (current->euid ^ t->suid) && (current->euid ^ t->uid)
-	    && (current->uid ^ t->suid) && (current->uid ^ t->uid)
-	    && !capable(CAP_KILL))
+	if (info == SEND_SIG_NOINFO || (!is_si_special(info) && SI_FROMUSER(info))) {
+		error = audit_signal_info(sig, t); /* Let audit system see the signal */
+		if (error)
+			return error;
+		error = -EPERM;
+		if (((sig != SIGCONT) ||
+			(process_session(current) != process_session(t)))
+		    && (current->euid ^ t->suid) && (current->euid ^ t->uid)
+		    && (current->uid ^ t->suid) && (current->uid ^ t->uid)
+		    && !capable(CAP_KILL))
 		return error;
+	}
 
 	return security_task_kill(t, info, sig, 0);
 }

commit b8fceee17a310f189188599a8fa5e9beaff57eb0
Author: Davide Libenzi <davidel@xmailserver.org>
Date:   Thu Sep 20 12:40:16 2007 -0700

    signalfd simplification
    
    This simplifies signalfd code, by avoiding it to remain attached to the
    sighand during its lifetime.
    
    In this way, the signalfd remain attached to the sighand only during
    poll(2) (and select and epoll) and read(2).  This also allows to remove
    all the custom "tsk == current" checks in kernel/signal.c, since
    dequeue_signal() will only be called by "current".
    
    I think this is also what Ben was suggesting time ago.
    
    The external effect of this, is that a thread can extract only its own
    private signals and the group ones.  I think this is an acceptable
    behaviour, in that those are the signals the thread would be able to
    fetch w/out signalfd.
    
    Signed-off-by: Davide Libenzi <davidel@xmailserver.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 3169bed0b4d0..9fb91a32edda 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -378,8 +378,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 	/* We only dequeue private signals from ourselves, we don't let
 	 * signalfd steal them
 	 */
-	if (likely(tsk == current))
-		signr = __dequeue_signal(&tsk->pending, mask, info);
+	signr = __dequeue_signal(&tsk->pending, mask, info);
 	if (!signr) {
 		signr = __dequeue_signal(&tsk->signal->shared_pending,
 					 mask, info);
@@ -407,8 +406,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 			}
 		}
 	}
-	if (likely(tsk == current))
-		recalc_sigpending();
+	recalc_sigpending();
 	if (signr && unlikely(sig_kernel_stop(signr))) {
 		/*
 		 * Set a marker that we have dequeued a stop signal.  Our
@@ -425,7 +423,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 		if (!(tsk->signal->flags & SIGNAL_GROUP_EXIT))
 			tsk->signal->flags |= SIGNAL_STOP_DEQUEUED;
 	}
-	if (signr && likely(tsk == current) &&
+	if (signr &&
 	     ((info->si_code & __SI_MASK) == __SI_TIMER) &&
 	     info->si_sys_private){
 		/*

commit 60187d2708caa870f0825d753df1612ea688eb9e
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Thu Aug 30 23:56:35 2007 -0700

    sigqueue_free: fix the race with collect_signal()
    
    Spotted by taoyue <yue.tao@windriver.com> and Jeremy Katz <jeremy.katz@windriver.com>.
    
    collect_signal:                         sigqueue_free:
    
            list_del_init(&first->list);
                                                    if (!list_empty(&q->list)) {
                                                            // not taken
                                                    }
                                                    q->flags &= ~SIGQUEUE_PREALLOC;
    
            __sigqueue_free(first);                 __sigqueue_free(q);
    
    Now, __sigqueue_free() is called twice on the same "struct sigqueue" with the
    obviously bad implications.
    
    In particular, this double free breaks the array_cache->avail logic, so the
    same sigqueue could be "allocated" twice, and the bug can manifest itself via
    the "impossible" BUG_ON(!SIGQUEUE_PREALLOC) in sigqueue_free/send_sigqueue.
    
    Hopefully this can explain these mysterious bug-reports, see
    
            http://marc.info/?t=118766926500003
            http://marc.info/?t=118466273000005
    
    Alexey Dobriyan reports this patch makes the difference for the testcase, but
    nobody has an access to the application which opened the problems originally.
    
    Also, this patch removes tasklist lock/unlock, ->siglock is enough.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: taoyue <yue.tao@windriver.com>
    Cc: Jeremy Katz <jeremy.katz@windriver.com>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Alexey Dobriyan <adobriyan@sw.ru>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index ad63109e413c..3169bed0b4d0 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1300,20 +1300,19 @@ struct sigqueue *sigqueue_alloc(void)
 void sigqueue_free(struct sigqueue *q)
 {
 	unsigned long flags;
+	spinlock_t *lock = &current->sighand->siglock;
+
 	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
 	/*
 	 * If the signal is still pending remove it from the
-	 * pending queue.
+	 * pending queue. We must hold ->siglock while testing
+	 * q->list to serialize with collect_signal().
 	 */
-	if (unlikely(!list_empty(&q->list))) {
-		spinlock_t *lock = &current->sighand->siglock;
-		read_lock(&tasklist_lock);
-		spin_lock_irqsave(lock, flags);
-		if (!list_empty(&q->list))
-			list_del_init(&q->list);
-		spin_unlock_irqrestore(lock, flags);
-		read_unlock(&tasklist_lock);
-	}
+	spin_lock_irqsave(lock, flags);
+	if (!list_empty(&q->list))
+		list_del_init(&q->list);
+	spin_unlock_irqrestore(lock, flags);
+
 	q->flags &= ~SIGQUEUE_PREALLOC;
 	__sigqueue_free(q);
 }

commit 834d216e1f804560bd1421c511ad168d7c24b01d
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Aug 22 14:01:42 2007 -0700

    signalfd: fix interaction with posix-timers
    
    dequeue_signal:
    
            if (__SI_TIMER) {
                    spin_unlock(&tsk->sighand->siglock);
                    do_schedule_next_timer(info);
                    spin_lock(&tsk->sighand->siglock);
            }
    
    Unless tsk == curent, this is absolutely unsafe: nothing prevents tsk from
    exiting. If signalfd was passed to another process, do_schedule_next_timer()
    is just wrong.
    
    Add yet another "tsk == current" check into dequeue_signal().
    
    This patch fixes an oopsable bug, but breaks the scheduling of posix timers
    if the shared __SI_TIMER signal was fetched via signalfd attached to another
    sub-thread. Mostly fixed by the next patch.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Davide Libenzi <davidel@xmailserver.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Michael Kerrisk <mtk-manpages@gmx.net>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index b27c01a66448..ad63109e413c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -378,7 +378,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 	/* We only dequeue private signals from ourselves, we don't let
 	 * signalfd steal them
 	 */
-	if (tsk == current)
+	if (likely(tsk == current))
 		signr = __dequeue_signal(&tsk->pending, mask, info);
 	if (!signr) {
 		signr = __dequeue_signal(&tsk->signal->shared_pending,
@@ -425,7 +425,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 		if (!(tsk->signal->flags & SIGNAL_GROUP_EXIT))
 			tsk->signal->flags |= SIGNAL_STOP_DEQUEUED;
 	}
-	if ( signr &&
+	if (signr && likely(tsk == current) &&
 	     ((info->si_code & __SI_MASK) == __SI_TIMER) &&
 	     info->si_sys_private){
 		/*

commit 247284481ca40288bd120cf0707681c3bdbee78f
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Sat Aug 4 01:04:41 2007 +0400

    Kill some obsolete sub-thread-ptrace stuff
    
    There is a couple of subtle checks which were needed to handle ptracing from
    the same thread group. This was deprecated a long ago, imho this code just
    complicates the understanding.
    
    And, the "->parent->signal->flags & SIGNAL_GROUP_EXIT" check in exit_notify()
    is not right. SIGNAL_GROUP_EXIT can mean exec(), not exit_group(). This means
    ptracer can lose a ptraced zombie on exec(). Minor problem, but still the bug.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index ef8156a6aad5..b27c01a66448 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1561,10 +1561,6 @@ static inline int may_ptrace_stop(void)
 		    (current->ptrace & PT_ATTACHED)))
 		return 0;
 
-	if (unlikely(current->signal == current->parent->signal) &&
-	    unlikely(current->signal->flags & SIGNAL_GROUP_EXIT))
-		return 0;
-
 	/*
 	 * Are we in the middle of do_coredump?
 	 * If so and our tracer is also part of the coredump stopping

commit abd4f7505bafdd6c5319fe3cb5caf9af6104e17a
Author: Masoud Asgharifard Sharbiani <masouds@google.com>
Date:   Sun Jul 22 11:12:28 2007 +0200

    x86: i386-show-unhandled-signals-v3
    
    This patch makes the i386 behave the same way that x86_64 does when a
    segfault happens.  A line gets printed to the kernel log so that tools
    that need to check for failures can behave more uniformly between
    debug.show_unhandled_signals sysctl variable to 0 (or by doing echo 0 >
    /proc/sys/debug/exception-trace)
    
    Also, all of the lines being printed are now using printk_ratelimit() to
    deny the ability of DoS from a local user with a program like the
    following:
    
    main()
    {
           while (1)
                   if (!fork()) *(int *)0 = 0;
    }
    
    This new revision also includes the fix that Andrew did which got rid of
    new sysctl that was added to the system in earlier versions of this.
    Also, 'show-unhandled-signals' sysctl has been renamed back to the old
    'exception-trace' to avoid breakage of people's scripts.
    
    AK: Enabling by default for i386 will be likely controversal, but let's see what happens
    AK: Really folks, before complaining just fix your segfaults
    AK: I bet this will find a lot of silent issues
    
    Signed-off-by: Masoud Sharbiani <masouds@google.com>
    Signed-off-by: Andi Kleen <ak@suse.de>
    [ Personally, I've found the complaints useful on x86-64, so I'm all for
      this. That said, I wonder if we could do it more prettily..   -Linus ]
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 39d122753bac..ef8156a6aad5 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -255,6 +255,16 @@ flush_signal_handlers(struct task_struct *t, int force_default)
 	}
 }
 
+int unhandled_signal(struct task_struct *tsk, int sig)
+{
+	if (is_init(tsk))
+		return 1;
+	if (tsk->ptrace & PT_PTRACED)
+		return 0;
+	return (tsk->sighand->action[sig-1].sa.sa_handler == SIG_IGN) ||
+		(tsk->sighand->action[sig-1].sa.sa_handler == SIG_DFL);
+}
+
 
 /* Notify the system that a driver wants to block all signals for this
  * process, and wants to be notified if any signals at all were to be

commit 45807a1df9f51d28d0ff0c6bcf900c210411d7c9
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Jul 15 23:40:10 2007 -0700

    vdso: print fatal signals
    
    Add the print-fatal-signals=1 boot option and the
    /proc/sys/kernel/print-fatal-signals runtime switch.
    
    This feature prints some minimal information about userspace segfaults to
    the kernel console.  This is useful to find early bootup bugs where
    userspace debugging is very hard.
    
    Defaults to off.
    
    [akpm@linux-foundation.org: Don't add new sysctl numbers]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Arjan van de Ven <arjan@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index f9405609774e..39d122753bac 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -718,6 +718,37 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 #define LEGACY_QUEUE(sigptr, sig) \
 	(((sig) < SIGRTMIN) && sigismember(&(sigptr)->signal, (sig)))
 
+int print_fatal_signals;
+
+static void print_fatal_signal(struct pt_regs *regs, int signr)
+{
+	printk("%s/%d: potentially unexpected fatal signal %d.\n",
+		current->comm, current->pid, signr);
+
+#ifdef __i386__
+	printk("code at %08lx: ", regs->eip);
+	{
+		int i;
+		for (i = 0; i < 16; i++) {
+			unsigned char insn;
+
+			__get_user(insn, (unsigned char *)(regs->eip + i));
+			printk("%02x ", insn);
+		}
+	}
+#endif
+	printk("\n");
+	show_regs(regs);
+}
+
+static int __init setup_print_fatal_signals(char *str)
+{
+	get_option (&str, &print_fatal_signals);
+
+	return 1;
+}
+
+__setup("print-fatal-signals=", setup_print_fatal_signals);
 
 static int
 specific_send_sig_info(int sig, struct siginfo *info, struct task_struct *t)
@@ -1855,6 +1886,8 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		 * Anything else is fatal, maybe with a core dump.
 		 */
 		current->flags |= PF_SIGNALED;
+		if ((signr != SIGKILL) && print_fatal_signals)
+			print_fatal_signal(regs, signr);
 		if (sig_kernel_coredump(signr)) {
 			/*
 			 * If it was able to dump core, this kills all

commit caec4e8dc85e0644ec24aeb36285e1ba02da58cc
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Jun 12 08:16:18 2007 +1000

    Fix signalfd interaction with thread-private signals
    
    Don't let signalfd dequeue private signals off other threads (in the
    case of things like SIGILL or SIGSEGV, trying to do so would result
    in undefined behaviour on who actually gets the signal, since they
    are force unblocked).
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Acked-by: Davide Libenzi <davidel@xmailserver.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index fe590e00db8d..f9405609774e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -363,7 +363,13 @@ static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,
  */
 int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 {
-	int signr = __dequeue_signal(&tsk->pending, mask, info);
+	int signr = 0;
+
+	/* We only dequeue private signals from ourselves, we don't let
+	 * signalfd steal them
+	 */
+	if (tsk == current)
+		signr = __dequeue_signal(&tsk->pending, mask, info);
 	if (!signr) {
 		signr = __dequeue_signal(&tsk->signal->shared_pending,
 					 mask, info);

commit b74d0deb968e1f85942f17080eace015ce3c332c
Author: Roland McGrath <roland@redhat.com>
Date:   Wed Jun 6 03:59:00 2007 -0700

    Restrict clearing TIF_SIGPENDING
    
    This patch should get a few birds.  It prevents sigaction calls from
    clearing TIF_SIGPENDING in other threads, which could leak -ERESTART*.
    And It fixes ptrace_stop not to clear it, which done at the syscall exit
    stop could leak -ERESTART*.  It probably removes the harm from signalfd,
    at least assuming it never calls dequeue_signal on kernel threads that
    might have used block_all_signals.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Satoru Takeuchi <takeuchi_satoru@jp.fujitsu.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index acdfc0549c6f..fe590e00db8d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -105,7 +105,11 @@ static int recalc_sigpending_tsk(struct task_struct *t)
 		set_tsk_thread_flag(t, TIF_SIGPENDING);
 		return 1;
 	}
-	clear_tsk_thread_flag(t, TIF_SIGPENDING);
+	/*
+	 * We must never clear the flag in another thread, or in current
+	 * when it's possible the current syscall is returning -ERESTART*.
+	 * So we don't clear it here, and only callers who know they should do.
+	 */
 	return 0;
 }
 
@@ -121,7 +125,9 @@ void recalc_sigpending_and_wake(struct task_struct *t)
 
 void recalc_sigpending(void)
 {
-	recalc_sigpending_tsk(current);
+	if (!recalc_sigpending_tsk(current))
+		clear_thread_flag(TIF_SIGPENDING);
+
 }
 
 /* Given the mask, find the first available signal that should be serviced. */
@@ -385,7 +391,8 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 			}
 		}
 	}
-	recalc_sigpending_tsk(tsk);
+	if (likely(tsk == current))
+		recalc_sigpending();
 	if (signr && unlikely(sig_kernel_stop(signr))) {
 		/*
 		 * Set a marker that we have dequeued a stop signal.  Our
@@ -1580,8 +1587,9 @@ static void ptrace_stop(int exit_code, int nostop_code, siginfo_t *info)
 	/*
 	 * Queued signals ignored us while we were stopped for tracing.
 	 * So check for any that we should take before resuming user mode.
+	 * This sets TIF_SIGPENDING, but never clears it.
 	 */
-	recalc_sigpending();
+	recalc_sigpending_tsk(current);
 }
 
 void ptrace_notify(int exit_code)

commit 7bb44adef39ad3bda2be40bb34686bc56bd563a5
Author: Roland McGrath <roland@redhat.com>
Date:   Wed May 23 13:57:44 2007 -0700

    recalc_sigpending_tsk fixes
    
    Steve Hawkes discovered a problem where recalc_sigpending_tsk was called in
    do_sigaction but no signal_wake_up call was made, preventing later signals
    from waking up blocked threads with TIF_SIGPENDING already set.
    
    In fact, the few other calls to recalc_sigpending_tsk outside the signals
    code are also subject to this problem in other race conditions.
    
    This change makes recalc_sigpending_tsk private to the signals code.  It
    changes the outside calls, as well as do_sigaction, to use the new
    recalc_sigpending_and_wake instead.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Cc: <Steve.Hawkes@motorola.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 364fc95bf97c..acdfc0549c6f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -96,15 +96,27 @@ static inline int has_pending_signals(sigset_t *signal, sigset_t *blocked)
 
 #define PENDING(p,b) has_pending_signals(&(p)->signal, (b))
 
-fastcall void recalc_sigpending_tsk(struct task_struct *t)
+static int recalc_sigpending_tsk(struct task_struct *t)
 {
 	if (t->signal->group_stop_count > 0 ||
 	    (freezing(t)) ||
 	    PENDING(&t->pending, &t->blocked) ||
-	    PENDING(&t->signal->shared_pending, &t->blocked))
+	    PENDING(&t->signal->shared_pending, &t->blocked)) {
 		set_tsk_thread_flag(t, TIF_SIGPENDING);
-	else
-		clear_tsk_thread_flag(t, TIF_SIGPENDING);
+		return 1;
+	}
+	clear_tsk_thread_flag(t, TIF_SIGPENDING);
+	return 0;
+}
+
+/*
+ * After recalculating TIF_SIGPENDING, we need to make sure the task wakes up.
+ * This is superfluous when called on current, the wakeup is a harmless no-op.
+ */
+void recalc_sigpending_and_wake(struct task_struct *t)
+{
+	if (recalc_sigpending_tsk(t))
+		signal_wake_up(t, 0);
 }
 
 void recalc_sigpending(void)
@@ -744,7 +756,7 @@ force_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 		action->sa.sa_handler = SIG_DFL;
 		if (blocked) {
 			sigdelset(&t->blocked, sig);
-			recalc_sigpending_tsk(t);
+			recalc_sigpending_and_wake(t);
 		}
 	}
 	ret = specific_send_sig_info(sig, info, t);
@@ -2273,7 +2285,7 @@ int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 			rm_from_queue_full(&mask, &t->signal->shared_pending);
 			do {
 				rm_from_queue_full(&mask, &t->pending);
-				recalc_sigpending_tsk(t);
+				recalc_sigpending_and_wake(t);
 				t = next_thread(t);
 			} while (t != current);
 		}

commit 853da0022023c046e0a5ccc51d427745f0c94de7
Merge: 5884c40668a9 0a4ff8c2598b
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Fri May 11 09:57:16 2007 -0700

    Merge branch 'audit.b38' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/audit-current
    
    * 'audit.b38' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/audit-current:
      [PATCH] Abnormal End of Processes
      [PATCH] match audit name data
      [PATCH] complete message queue auditing
      [PATCH] audit inode for all xattr syscalls
      [PATCH] initialize name osid
      [PATCH] audit signal recipients
      [PATCH] add SIGNAL syscall class (v3)
      [PATCH] auditing ptrace

commit fba2afaaec790dc5ab4ae8827972f342211bbb86
Author: Davide Libenzi <davidel@xmailserver.org>
Date:   Thu May 10 22:23:13 2007 -0700

    signal/timer/event: signalfd core
    
    This patch series implements the new signalfd() system call.
    
    I took part of the original Linus code (and you know how badly it can be
    broken :), and I added even more breakage ;) Signals are fetched from the same
    signal queue used by the process, so signalfd will compete with standard
    kernel delivery in dequeue_signal().  If you want to reliably fetch signals on
    the signalfd file, you need to block them with sigprocmask(SIG_BLOCK).  This
    seems to be working fine on my Dual Opteron machine.  I made a quick test
    program for it:
    
    http://www.xmailserver.org/signafd-test.c
    
    The signalfd() system call implements signal delivery into a file descriptor
    receiver.  The signalfd file descriptor if created with the following API:
    
    int signalfd(int ufd, const sigset_t *mask, size_t masksize);
    
    The "ufd" parameter allows to change an existing signalfd sigmask, w/out going
    to close/create cycle (Linus idea).  Use "ufd" == -1 if you want a brand new
    signalfd file.
    
    The "mask" allows to specify the signal mask of signals that we are interested
    in.  The "masksize" parameter is the size of "mask".
    
    The signalfd fd supports the poll(2) and read(2) system calls.  The poll(2)
    will return POLLIN when signals are available to be dequeued.  As a direct
    consequence of supporting the Linux poll subsystem, the signalfd fd can use
    used together with epoll(2) too.
    
    The read(2) system call will return a "struct signalfd_siginfo" structure in
    the userspace supplied buffer.  The return value is the number of bytes copied
    in the supplied buffer, or -1 in case of error.  The read(2) call can also
    return 0, in case the sighand structure to which the signalfd was attached,
    has been orphaned.  The O_NONBLOCK flag is also supported, and read(2) will
    return -EAGAIN in case no signal is available.
    
    If the size of the buffer passed to read(2) is lower than sizeof(struct
    signalfd_siginfo), -EINVAL is returned.  A read from the signalfd can also
    return -ERESTARTSYS in case a signal hits the process.  The format of the
    struct signalfd_siginfo is, and the valid fields depends of the (->code &
    __SI_MASK) value, in the same way a struct siginfo would:
    
    struct signalfd_siginfo {
            __u32 signo;    /* si_signo */
            __s32 err;      /* si_errno */
            __s32 code;     /* si_code */
            __u32 pid;      /* si_pid */
            __u32 uid;      /* si_uid */
            __s32 fd;       /* si_fd */
            __u32 tid;      /* si_fd */
            __u32 band;     /* si_band */
            __u32 overrun;  /* si_overrun */
            __u32 trapno;   /* si_trapno */
            __s32 status;   /* si_status */
            __s32 svint;    /* si_int */
            __u64 svptr;    /* si_ptr */
            __u64 utime;    /* si_utime */
            __u64 stime;    /* si_stime */
            __u64 addr;     /* si_addr */
    };
    
    [akpm@linux-foundation.org: fix signalfd_copyinfo() on i386]
    Signed-off-by: Davide Libenzi <davidel@xmailserver.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2ac3a668d9dd..34b7d6abce8f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -21,6 +21,7 @@
 #include <linux/syscalls.h>
 #include <linux/ptrace.h>
 #include <linux/signal.h>
+#include <linux/signalfd.h>
 #include <linux/capability.h>
 #include <linux/freezer.h>
 #include <linux/pid_namespace.h>
@@ -113,8 +114,7 @@ void recalc_sigpending(void)
 
 /* Given the mask, find the first available signal that should be serviced. */
 
-static int
-next_signal(struct sigpending *pending, sigset_t *mask)
+int next_signal(struct sigpending *pending, sigset_t *mask)
 {
 	unsigned long i, *s, *m, x;
 	int sig = 0;
@@ -629,6 +629,12 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	struct sigqueue * q = NULL;
 	int ret = 0;
 
+	/*
+	 * Deliver the signal to listening signalfds. This must be called
+	 * with the sighand lock held.
+	 */
+	signalfd_notify(t, sig);
+
 	/*
 	 * fast-pathed signals for kernel-internal things like SIGSTOP
 	 * or SIGKILL.
@@ -1280,6 +1286,11 @@ int send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 		ret = 1;
 		goto out;
 	}
+	/*
+	 * Deliver the signal to listening signalfds. This must be called
+	 * with the sighand lock held.
+	 */
+	signalfd_notify(p, sig);
 
 	list_add_tail(&q->list, &p->pending.list);
 	sigaddset(&p->pending.signal, sig);
@@ -1323,6 +1334,11 @@ send_group_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 		q->info.si_overrun++;
 		goto out;
 	} 
+	/*
+	 * Deliver the signal to listening signalfds. This must be called
+	 * with the sighand lock held.
+	 */
+	signalfd_notify(p, sig);
 
 	/*
 	 * Put this signal on the shared-pending queue.
@@ -1983,6 +1999,8 @@ int copy_siginfo_to_user(siginfo_t __user *to, siginfo_t *from)
 	/*
 	 * If you change siginfo_t structure, please be sure
 	 * this code is fixed accordingly.
+	 * Please remember to update the signalfd_copyinfo() function
+	 * inside fs/signalfd.c too, in case siginfo_t changes.
 	 * It should never copy any pad contained in the structure
 	 * to avoid security leaks, but must copy the generic
 	 * 3 ints plus the relevant union member.

commit e54dc2431d740a79a6bd013babade99d71b1714f
Author: Amy Griffis <amy.griffis@hp.com>
Date:   Thu Mar 29 18:01:04 2007 -0400

    [PATCH] audit signal recipients
    
    When auditing syscalls that send signals, log the pid and security
    context for each target process. Optimize the data collection by
    adding a counter for signal-related rules, and avoiding allocating an
    aux struct unless we have more than one target process. For process
    groups, collect pid/context data in blocks of 16. Move the
    audit_signal_info() hook up in check_kill_permission() so we audit
    attempts where permission is denied.
    
    Signed-off-by: Amy Griffis <amy.griffis@hp.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2ac3a668d9dd..c43a3f19d477 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -497,6 +497,11 @@ static int check_kill_permission(int sig, struct siginfo *info,
 	int error = -EINVAL;
 	if (!valid_signal(sig))
 		return error;
+
+	error = audit_signal_info(sig, t); /* Let audit system see the signal */
+	if (error)
+		return error;
+
 	error = -EPERM;
 	if ((info == SEND_SIG_NOINFO || (!is_si_special(info) && SI_FROMUSER(info)))
 	    && ((sig != SIGCONT) ||
@@ -506,10 +511,7 @@ static int check_kill_permission(int sig, struct siginfo *info,
 	    && !capable(CAP_KILL))
 		return error;
 
-	error = security_task_kill(t, info, sig, 0);
-	if (!error)
-		audit_signal_info(sig, t); /* Let audit system see the signal */
-	return error;
+	return security_task_kill(t, info, sig, 0);
 }
 
 /* forward decl */

commit 10ab825bdef8df510f99c703a5a2d9b13a4e31a5
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed May 9 02:34:37 2007 -0700

    change kernel threads to ignore signals instead of blocking them
    
    Currently kernel threads use sigprocmask(SIG_BLOCK) to protect against
    signals.  This doesn't prevent the signal delivery, this only blocks
    signal_wake_up().  Every "killall -33 kthreadd" means a "struct siginfo"
    leak.
    
    Change kthreadd_setup() to set all handlers to SIG_IGN instead of blocking
    them (make a new helper ignore_signals() for that).  If the kernel thread
    needs some signal, it should use allow_signal() anyway, and in that case it
    should not use CLONE_SIGHAND.
    
    Note that we can't change daemonize() (should die!) in the same way,
    because it can be used along with CLONE_SIGHAND.  This means that
    allow_signal() still should unblock the signal to work correctly with
    daemonize()ed threads.
    
    However, disallow_signal() doesn't block the signal any longer but ignores
    it.
    
    NOTE: with or without this patch the kernel threads are not protected from
    handle_stop_signal(), this seems harmless, but not good.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 23ae6d62fc41..2ac3a668d9dd 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -209,6 +209,16 @@ void flush_signals(struct task_struct *t)
 	spin_unlock_irqrestore(&t->sighand->siglock, flags);
 }
 
+void ignore_signals(struct task_struct *t)
+{
+	int i;
+
+	for (i = 0; i < _NSIG; ++i)
+		t->sighand->action[i].sa.sa_handler = SIG_IGN;
+
+	flush_signals(t);
+}
+
 /*
  * Flush all handlers for a task.
  */

commit a4798833d26b293fd18b7bf102991426aa0b56fd
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed May 9 02:34:21 2007 -0700

    zap_other_threads: remove unneeded ->exit_signal change
    
    We already depend on fact that all sub-threads have ->exit_signal == -1, no
    need to set it in zap_other_threads().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 4c8f49eadf7d..23ae6d62fc41 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -913,17 +913,6 @@ void zap_other_threads(struct task_struct *p)
 		if (t->exit_state)
 			continue;
 
-		/*
-		 * We don't want to notify the parent, since we are
-		 * killed as part of a thread group due to another
-		 * thread doing an execve() or similar. So set the
-		 * exit signal to -1 to allow immediate reaping of
-		 * the process.  But don't detach the thread group
-		 * leader.
-		 */
-		if (t != p->group_leader)
-			t->exit_signal = -1;
-
 		/* SIGKILL will be handled before any pending SIGSTOP */
 		sigaddset(&t->pending.signal, SIGKILL);
 		signal_wake_up(t, 1);

commit 55c0d1f83e481dd6c77f52f7dcfeb043b8b740fa
Author: Roland McGrath <roland@redhat.com>
Date:   Wed May 9 02:33:37 2007 -0700

    Move sig_kernel_* et al macros to linux/signal.h
    
    This patch moves the sig_kernel_* and related macros from kernel/signal.c
    to linux/signal.h, and cleans them up slightly.  I need the sig_kernel_*
    macros for default signal behavior in the utrace code, and want to avoid
    duplication or overhead to share the knowledge.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1368e67c8482..4c8f49eadf7d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -38,125 +38,6 @@
 
 static struct kmem_cache *sigqueue_cachep;
 
-/*
- * In POSIX a signal is sent either to a specific thread (Linux task)
- * or to the process as a whole (Linux thread group).  How the signal
- * is sent determines whether it's to one thread or the whole group,
- * which determines which signal mask(s) are involved in blocking it
- * from being delivered until later.  When the signal is delivered,
- * either it's caught or ignored by a user handler or it has a default
- * effect that applies to the whole thread group (POSIX process).
- *
- * The possible effects an unblocked signal set to SIG_DFL can have are:
- *   ignore	- Nothing Happens
- *   terminate	- kill the process, i.e. all threads in the group,
- * 		  similar to exit_group.  The group leader (only) reports
- *		  WIFSIGNALED status to its parent.
- *   coredump	- write a core dump file describing all threads using
- *		  the same mm and then kill all those threads
- *   stop 	- stop all the threads in the group, i.e. TASK_STOPPED state
- *
- * SIGKILL and SIGSTOP cannot be caught, blocked, or ignored.
- * Other signals when not blocked and set to SIG_DFL behaves as follows.
- * The job control signals also have other special effects.
- *
- *	+--------------------+------------------+
- *	|  POSIX signal      |  default action  |
- *	+--------------------+------------------+
- *	|  SIGHUP            |  terminate	|
- *	|  SIGINT            |	terminate	|
- *	|  SIGQUIT           |	coredump 	|
- *	|  SIGILL            |	coredump 	|
- *	|  SIGTRAP           |	coredump 	|
- *	|  SIGABRT/SIGIOT    |	coredump 	|
- *	|  SIGBUS            |	coredump 	|
- *	|  SIGFPE            |	coredump 	|
- *	|  SIGKILL           |	terminate(+)	|
- *	|  SIGUSR1           |	terminate	|
- *	|  SIGSEGV           |	coredump 	|
- *	|  SIGUSR2           |	terminate	|
- *	|  SIGPIPE           |	terminate	|
- *	|  SIGALRM           |	terminate	|
- *	|  SIGTERM           |	terminate	|
- *	|  SIGCHLD           |	ignore   	|
- *	|  SIGCONT           |	ignore(*)	|
- *	|  SIGSTOP           |	stop(*)(+)  	|
- *	|  SIGTSTP           |	stop(*)  	|
- *	|  SIGTTIN           |	stop(*)  	|
- *	|  SIGTTOU           |	stop(*)  	|
- *	|  SIGURG            |	ignore   	|
- *	|  SIGXCPU           |	coredump 	|
- *	|  SIGXFSZ           |	coredump 	|
- *	|  SIGVTALRM         |	terminate	|
- *	|  SIGPROF           |	terminate	|
- *	|  SIGPOLL/SIGIO     |	terminate	|
- *	|  SIGSYS/SIGUNUSED  |	coredump 	|
- *	|  SIGSTKFLT         |	terminate	|
- *	|  SIGWINCH          |	ignore   	|
- *	|  SIGPWR            |	terminate	|
- *	|  SIGRTMIN-SIGRTMAX |	terminate       |
- *	+--------------------+------------------+
- *	|  non-POSIX signal  |  default action  |
- *	+--------------------+------------------+
- *	|  SIGEMT            |  coredump	|
- *	+--------------------+------------------+
- *
- * (+) For SIGKILL and SIGSTOP the action is "always", not just "default".
- * (*) Special job control effects:
- * When SIGCONT is sent, it resumes the process (all threads in the group)
- * from TASK_STOPPED state and also clears any pending/queued stop signals
- * (any of those marked with "stop(*)").  This happens regardless of blocking,
- * catching, or ignoring SIGCONT.  When any stop signal is sent, it clears
- * any pending/queued SIGCONT signals; this happens regardless of blocking,
- * catching, or ignored the stop signal, though (except for SIGSTOP) the
- * default action of stopping the process may happen later or never.
- */
-
-#ifdef SIGEMT
-#define M_SIGEMT	M(SIGEMT)
-#else
-#define M_SIGEMT	0
-#endif
-
-#if SIGRTMIN > BITS_PER_LONG
-#define M(sig) (1ULL << ((sig)-1))
-#else
-#define M(sig) (1UL << ((sig)-1))
-#endif
-#define T(sig, mask) (M(sig) & (mask))
-
-#define SIG_KERNEL_ONLY_MASK (\
-	M(SIGKILL)   |  M(SIGSTOP)                                   )
-
-#define SIG_KERNEL_STOP_MASK (\
-	M(SIGSTOP)   |  M(SIGTSTP)   |  M(SIGTTIN)   |  M(SIGTTOU)   )
-
-#define SIG_KERNEL_COREDUMP_MASK (\
-        M(SIGQUIT)   |  M(SIGILL)    |  M(SIGTRAP)   |  M(SIGABRT)   | \
-        M(SIGFPE)    |  M(SIGSEGV)   |  M(SIGBUS)    |  M(SIGSYS)    | \
-        M(SIGXCPU)   |  M(SIGXFSZ)   |  M_SIGEMT                     )
-
-#define SIG_KERNEL_IGNORE_MASK (\
-        M(SIGCONT)   |  M(SIGCHLD)   |  M(SIGWINCH)  |  M(SIGURG)    )
-
-#define sig_kernel_only(sig) \
-		(((sig) < SIGRTMIN)  && T(sig, SIG_KERNEL_ONLY_MASK))
-#define sig_kernel_coredump(sig) \
-		(((sig) < SIGRTMIN)  && T(sig, SIG_KERNEL_COREDUMP_MASK))
-#define sig_kernel_ignore(sig) \
-		(((sig) < SIGRTMIN)  && T(sig, SIG_KERNEL_IGNORE_MASK))
-#define sig_kernel_stop(sig) \
-		(((sig) < SIGRTMIN)  && T(sig, SIG_KERNEL_STOP_MASK))
-
-#define sig_needs_tasklist(sig)	((sig) == SIGCONT)
-
-#define sig_user_defined(t, signr) \
-	(((t)->sighand->action[(signr)-1].sa.sa_handler != SIG_DFL) &&	\
-	 ((t)->sighand->action[(signr)-1].sa.sa_handler != SIG_IGN))
-
-#define sig_fatal(t, signr) \
-	(!T(signr, SIG_KERNEL_IGNORE_MASK|SIG_KERNEL_STOP_MASK) && \
-	 (t)->sighand->action[(signr)-1].sa.sa_handler == SIG_DFL)
 
 static int sig_ignored(struct task_struct *t, int sig)
 {

commit e63340ae6b6205fef26b40a75673d1c9c0c8bb90
Author: Randy Dunlap <randy.dunlap@oracle.com>
Date:   Tue May 8 00:28:08 2007 -0700

    header cleaning: don't include smp_lock.h when not used
    
    Remove includes of <linux/smp_lock.h> where it is not used/needed.
    Suggested by Al Viro.
    
    Builds cleanly on x86_64, i386, alpha, ia64, powerpc, sparc,
    sparc64, and arm (all 59 defconfigs).
    
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2b4087d545a3..1368e67c8482 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -12,7 +12,6 @@
 
 #include <linux/slab.h>
 #include <linux/module.h>
-#include <linux/smp_lock.h>
 #include <linux/init.h>
 #include <linux/sched.h>
 #include <linux/fs.h>

commit 0a31bd5f2bbb6473ef9d24f0063ca91cfa678b64
Author: Christoph Lameter <clameter@sgi.com>
Date:   Sun May 6 14:49:57 2007 -0700

    KMEM_CACHE(): simplify slab cache creation
    
    This patch provides a new macro
    
    KMEM_CACHE(<struct>, <flags>)
    
    to simplify slab creation. KMEM_CACHE creates a slab with the name of the
    struct, with the size of the struct and with the alignment of the struct.
    Additional slab flags may be specified if necessary.
    
    Example
    
    struct test_slab {
            int a,b,c;
            struct list_head;
    } __cacheline_aligned_in_smp;
    
    test_slab_cache = KMEM_CACHE(test_slab, SLAB_PANIC)
    
    will create a new slab named "test_slab" of the size sizeof(struct
    test_slab) and aligned to the alignment of test slab.  If it fails then we
    panic.
    
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 3670225ecbc0..2b4087d545a3 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2636,9 +2636,5 @@ __attribute__((weak)) const char *arch_vma_name(struct vm_area_struct *vma)
 
 void __init signals_init(void)
 {
-	sigqueue_cachep =
-		kmem_cache_create("sigqueue",
-				  sizeof(struct sigqueue),
-				  __alignof__(struct sigqueue),
-				  SLAB_PANIC, NULL, NULL);
+	sigqueue_cachep = KMEM_CACHE(sigqueue, SLAB_PANIC);
 }

commit b0138a6cb7923a997d278b47c176778534d1095b
Merge: 6572d6d7d0f9 1055a8af093f
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Mon Feb 26 12:48:06 2007 -0800

    Merge master.kernel.org:/pub/scm/linux/kernel/git/kyle/parisc-2.6
    
    * master.kernel.org:/pub/scm/linux/kernel/git/kyle/parisc-2.6: (78 commits)
      [PARISC] Use symbolic last syscall in __NR_Linux_syscalls
      [PARISC] Add missing statfs64 and fstatfs64 syscalls
      Revert "[PARISC] Optimize TLB flush on SMP systems"
      [PARISC] Compat signal fixes for 64-bit parisc
      [PARISC] Reorder syscalls to match unistd.h
      Revert "[PATCH] make kernel/signal.c:kill_proc_info() static"
      [PARISC] fix sys_rt_sigqueueinfo
      [PARISC] fix section mismatch warnings in harmony sound driver
      [PARISC] do not export get_register/set_register
      [PARISC] add ENTRY()/ENDPROC() and simplify assembly of HP/UX emulation code
      [PARISC] convert to use CONFIG_64BIT instead of __LP64__
      [PARISC] use CONFIG_64BIT instead of __LP64__
      [PARISC] add ASM_EXCEPTIONTABLE_ENTRY() macro
      [PARISC] more ENTRY(), ENDPROC(), END() conversions
      [PARISC] fix ENTRY() and ENDPROC() for 64bit-parisc
      [PARISC] Fixes /proc/cpuinfo cache output on B160L
      [PARISC] implement standard ENTRY(), END() and ENDPROC()
      [PARISC] kill ENTRY_SYS_CPUS
      [PARISC] clean up debugging printks in smp.c
      [PARISC] factor syscall_restart code out of do_signal
      ...
    
    Fix conflict in include/linux/sched.h due to kill_proc_info() being made
    publicly available to PARISC again.

commit c3de4b38153a201cfc8561abb093a1b482fd3abb
Author: Matthew Wilcox <matthew@wil.cx>
Date:   Fri Feb 9 08:11:47 2007 -0700

    Revert "[PATCH] make kernel/signal.c:kill_proc_info() static"
    
    This reverts commit d3228a887cae75ef2b8b1211c31c539bef5a5698.
    DeBunk this code.  We need it for compat_sys_rt_sigqueueinfo.
    
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5630255d2e2a..8a04869402fb 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1137,7 +1137,8 @@ int kill_pid_info(int sig, struct siginfo *info, struct pid *pid)
 	return error;
 }
 
-static int kill_proc_info(int sig, struct siginfo *info, pid_t pid)
+int
+kill_proc_info(int sig, struct siginfo *info, pid_t pid)
 {
 	int error;
 	rcu_read_lock();

commit 8bfd9a7a229b5f3d3eda5d7d45c2eebec5b4ba16
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Feb 16 01:28:12 2007 -0800

    [PATCH] hrtimers: prevent possible itimer DoS
    
    Fix potential setitimer DoS with high-res timers by pushing itimer rearm
    processing to process context.
    
    [Fixes from: Ingo Molnar <mingo@elte.hu>]
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Cc: john stultz <johnstul@us.ibm.com>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8072e568bbe0..e2a7d4bf7d57 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -456,26 +456,50 @@ static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,
 int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 {
 	int signr = __dequeue_signal(&tsk->pending, mask, info);
-	if (!signr)
+	if (!signr) {
 		signr = __dequeue_signal(&tsk->signal->shared_pending,
 					 mask, info);
+		/*
+		 * itimer signal ?
+		 *
+		 * itimers are process shared and we restart periodic
+		 * itimers in the signal delivery path to prevent DoS
+		 * attacks in the high resolution timer case. This is
+		 * compliant with the old way of self restarting
+		 * itimers, as the SIGALRM is a legacy signal and only
+		 * queued once. Changing the restart behaviour to
+		 * restart the timer in the signal dequeue path is
+		 * reducing the timer noise on heavy loaded !highres
+		 * systems too.
+		 */
+		if (unlikely(signr == SIGALRM)) {
+			struct hrtimer *tmr = &tsk->signal->real_timer;
+
+			if (!hrtimer_is_queued(tmr) &&
+			    tsk->signal->it_real_incr.tv64 != 0) {
+				hrtimer_forward(tmr, tmr->base->get_time(),
+						tsk->signal->it_real_incr);
+				hrtimer_restart(tmr);
+			}
+		}
+	}
 	recalc_sigpending_tsk(tsk);
- 	if (signr && unlikely(sig_kernel_stop(signr))) {
- 		/*
- 		 * Set a marker that we have dequeued a stop signal.  Our
- 		 * caller might release the siglock and then the pending
- 		 * stop signal it is about to process is no longer in the
- 		 * pending bitmasks, but must still be cleared by a SIGCONT
- 		 * (and overruled by a SIGKILL).  So those cases clear this
- 		 * shared flag after we've set it.  Note that this flag may
- 		 * remain set after the signal we return is ignored or
- 		 * handled.  That doesn't matter because its only purpose
- 		 * is to alert stop-signal processing code when another
- 		 * processor has come along and cleared the flag.
- 		 */
- 		if (!(tsk->signal->flags & SIGNAL_GROUP_EXIT))
- 			tsk->signal->flags |= SIGNAL_STOP_DEQUEUED;
- 	}
+	if (signr && unlikely(sig_kernel_stop(signr))) {
+		/*
+		 * Set a marker that we have dequeued a stop signal.  Our
+		 * caller might release the siglock and then the pending
+		 * stop signal it is about to process is no longer in the
+		 * pending bitmasks, but must still be cleared by a SIGCONT
+		 * (and overruled by a SIGKILL).  So those cases clear this
+		 * shared flag after we've set it.  Note that this flag may
+		 * remain set after the signal we return is ignored or
+		 * handled.  That doesn't matter because its only purpose
+		 * is to alert stop-signal processing code when another
+		 * processor has come along and cleared the flag.
+		 */
+		if (!(tsk->signal->flags & SIGNAL_GROUP_EXIT))
+			tsk->signal->flags |= SIGNAL_STOP_DEQUEUED;
+	}
 	if ( signr &&
 	     ((info->si_code & __SI_MASK) == __SI_TIMER) &&
 	     info->si_sys_private){

commit 27b0b2f44adffe0193a695bb528a83b550b8e54b
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Feb 12 00:53:02 2007 -0800

    [PATCH] pid: remove the now unused kill_pg kill_pg_info and __kill_pg_info
    
    Now that I have changed all of the in-tree users remove the old version of
    these functions.  This should make it clear to any out of tree users that they
    should be using kill_pgrp kill_pgrp_info or __kill_pgrp_info instead.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index a9b679ed795c..8072e568bbe0 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1096,26 +1096,6 @@ int kill_pgrp_info(int sig, struct siginfo *info, struct pid *pgrp)
 	return retval;
 }
 
-int __kill_pg_info(int sig, struct siginfo *info, pid_t pgrp)
-{
-	if (pgrp <= 0)
-		return -EINVAL;
-
-	return __kill_pgrp_info(sig, info, find_pid(pgrp));
-}
-
-int
-kill_pg_info(int sig, struct siginfo *info, pid_t pgrp)
-{
-	int retval;
-
-	read_lock(&tasklist_lock);
-	retval = __kill_pg_info(sig, info, pgrp);
-	read_unlock(&tasklist_lock);
-
-	return retval;
-}
-
 int kill_pid_info(int sig, struct siginfo *info, struct pid *pid)
 {
 	int error;
@@ -1314,12 +1294,6 @@ int kill_pid(struct pid *pid, int sig, int priv)
 }
 EXPORT_SYMBOL(kill_pid);
 
-int
-kill_pg(pid_t pgrp, int sig, int priv)
-{
-	return kill_pg_info(sig, __si_special(priv), pgrp);
-}
-
 int
 kill_proc(pid_t pid, int sig, int priv)
 {
@@ -1959,7 +1933,6 @@ EXPORT_SYMBOL(recalc_sigpending);
 EXPORT_SYMBOL_GPL(dequeue_signal);
 EXPORT_SYMBOL(flush_signals);
 EXPORT_SYMBOL(force_sig);
-EXPORT_SYMBOL(kill_pg);
 EXPORT_SYMBOL(kill_proc);
 EXPORT_SYMBOL(ptrace_notify);
 EXPORT_SYMBOL(send_sig);

commit 3e7cd6c413c9e6fbb5e1ee2acdadb4ababd2d474
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Feb 12 00:52:58 2007 -0800

    [PATCH] pid: replace is_orphaned_pgrp with is_current_pgrp_orphaned
    
    Every call to is_orphaned_pgrp passed in process_group(current) which is racy
    with respect to another thread changing our process group.  It didn't bite us
    because we were dealing with integers and the worse we would get would be a
    stale answer.
    
    In switching the checks to use struct pid to be a little more efficient and
    prepare the way for pid namespaces this race became apparent.
    
    So I simplified the calls to the more specialized is_current_pgrp_orphaned so
    I didn't have to worry about making logic changes to avoid the race.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index de66def71644..a9b679ed795c 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1909,7 +1909,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 
 				/* signals can be posted during this window */
 
-				if (is_orphaned_pgrp(process_group(current)))
+				if (is_current_pgrp_orphaned())
 					goto relock;
 
 				spin_lock_irq(&current->sighand->siglock);

commit 8d42db189ca99703f0f4f91c477cb54808c8eaaa
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Feb 12 00:52:55 2007 -0800

    [PATCH] signal: rewrite kill_something_info so it uses newer helpers
    
    The goal is to remove users of the old signal helper functions so they can be
    removed.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 228fdb5c01d1..de66def71644 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1191,8 +1191,10 @@ EXPORT_SYMBOL_GPL(kill_pid_info_as_uid);
 
 static int kill_something_info(int sig, struct siginfo *info, int pid)
 {
+	int ret;
+	rcu_read_lock();
 	if (!pid) {
-		return kill_pg_info(sig, info, process_group(current));
+		ret = kill_pgrp_info(sig, info, task_pgrp(current));
 	} else if (pid == -1) {
 		int retval = 0, count = 0;
 		struct task_struct * p;
@@ -1207,12 +1209,14 @@ static int kill_something_info(int sig, struct siginfo *info, int pid)
 			}
 		}
 		read_unlock(&tasklist_lock);
-		return count ? retval : -ESRCH;
+		ret = count ? retval : -ESRCH;
 	} else if (pid < 0) {
-		return kill_pg_info(sig, info, -pid);
+		ret = kill_pgrp_info(sig, info, find_pid(-pid));
 	} else {
-		return kill_proc_info(sig, info, pid);
+		ret = kill_pid_info(sig, info, find_pid(pid));
 	}
+	rcu_read_unlock();
+	return ret;
 }
 
 /*

commit 72fd4a35a824331d7a0f4168d7576502d95d34b3
Author: Robert P. J. Day <rpjday@mindspring.com>
Date:   Sat Feb 10 01:45:59 2007 -0800

    [PATCH] Numerous fixes to kernel-doc info in source files.
    
    A variety of (mostly) innocuous fixes to the embedded kernel-doc content in
    source files, including:
    
      * make multi-line initial descriptions single line
      * denote some function names, constants and structs as such
      * change erroneous opening '/*' to '/**' in a few places
      * reword some text for clarity
    
    Signed-off-by: Robert P. J. Day <rpjday@mindspring.com>
    Cc: "Randy.Dunlap" <rdunlap@xenotime.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index ea4632bd40a0..228fdb5c01d1 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2282,7 +2282,7 @@ static int do_tkill(int tgid, int pid, int sig)
  *  @pid: the PID of the thread
  *  @sig: signal to be sent
  *
- *  This syscall also checks the tgid and returns -ESRCH even if the PID
+ *  This syscall also checks the @tgid and returns -ESRCH even if the PID
  *  exists but it's not belonging to the target process anymore. This
  *  method solves the problem of threads exiting and PIDs getting reused.
  */

commit 0c12b51712ced2c0d89a8ec3d546ed810f86d33e
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Sat Feb 10 01:44:56 2007 -0800

    [PATCH] kill_pid_info: kill acquired_tasklist_lock
    
    Kill acquired_tasklist_lock, sig_needs_tasklist() is very cheap nowadays.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5630255d2e2a..ea4632bd40a0 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1119,19 +1119,18 @@ kill_pg_info(int sig, struct siginfo *info, pid_t pgrp)
 int kill_pid_info(int sig, struct siginfo *info, struct pid *pid)
 {
 	int error;
-	int acquired_tasklist_lock = 0;
 	struct task_struct *p;
 
 	rcu_read_lock();
-	if (unlikely(sig_needs_tasklist(sig))) {
+	if (unlikely(sig_needs_tasklist(sig)))
 		read_lock(&tasklist_lock);
-		acquired_tasklist_lock = 1;
-	}
+
 	p = pid_task(pid, PIDTYPE_PID);
 	error = -ESRCH;
 	if (p)
 		error = group_send_sig_info(sig, info, p);
-	if (unlikely(acquired_tasklist_lock))
+
+	if (unlikely(sig_needs_tasklist(sig)))
 		read_unlock(&tasklist_lock);
 	rcu_read_unlock();
 	return error;

commit 3df494a32b936aef76d893f5065f962ebd9b9437
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Wed Dec 13 00:34:28 2006 -0800

    [PATCH] PM: Fix freezing of stopped tasks
    
    Currently, if a task is stopped (ie.  it's in the TASK_STOPPED state), it
    is considered by the freezer as unfreezeable.  However, there may be a race
    between the freezer and the delivery of the continuation signal to the task
    resulting in the task running after we have finished freezing the other
    tasks.  This, in turn, may lead to undesirable effects up to and including
    data corruption.
    
    To prevent this from happening we first need to make the freezer consider
    stopped tasks as freezeable.  For this purpose we need to make freezeable()
    stop returning 0 for these tasks and we need to force them to enter the
    refrigerator.  However, if there's no continuation signal in the meantime,
    the stopped tasks should remain stopped after all processes have been
    thawed, so we need to send an additional SIGSTOP to each of them before
    waking it up.
    
    Also, a stopped task that has just been woken up should first check if
    there's a freezing request for it and go to the refrigerator if that's the
    case.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Acked-by: Pavel Machek <pavel@ucw.cz>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1921ffdc5e77..5630255d2e2a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1705,7 +1705,9 @@ finish_stop(int stop_count)
 		read_unlock(&tasklist_lock);
 	}
 
-	schedule();
+	do {
+		schedule();
+	} while (try_to_freeze());
 	/*
 	 * Now we don't run again until continued.
 	 */

commit 84d737866e2babdeab0c6b18ea155c6a649663b8
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Fri Dec 8 02:38:01 2006 -0800

    [PATCH] add child reaper to pid_namespace
    
    Add a per pid_namespace child-reaper.  This is needed so processes are reaped
    within the same pid space and do not spill over to the parent pid space.  Its
    also needed so containers preserve existing semantic that pid == 1 would reap
    orphaned children.
    
    This is based on Eric Biederman's patch: http://lkml.org/lkml/2006/2/6/285
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Signed-off-by: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Kirill Korotaev <dev@openvz.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9eac4db60eda..1921ffdc5e77 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -24,6 +24,9 @@
 #include <linux/signal.h>
 #include <linux/capability.h>
 #include <linux/freezer.h>
+#include <linux/pid_namespace.h>
+#include <linux/nsproxy.h>
+
 #include <asm/param.h>
 #include <asm/uaccess.h>
 #include <asm/unistd.h>
@@ -1877,8 +1880,12 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 		if (sig_kernel_ignore(signr)) /* Default is nothing. */
 			continue;
 
-		/* Init gets no signals it doesn't want.  */
-		if (current == child_reaper)
+		/*
+		 * Init of a pid space gets no signals it doesn't want from
+		 * within that pid space. It can of course get signals from
+		 * its parent pid space.
+		 */
+		if (current == child_reaper(current))
 			continue;
 
 		if (sig_kernel_stop(signr)) {

commit 937949d9edbf4049bd41af6c9f92c26280584564
Author: Cedric Le Goater <clg@fr.ibm.com>
Date:   Fri Dec 8 02:37:54 2006 -0800

    [PATCH] add process_session() helper routine
    
    Replace occurences of task->signal->session by a new process_session() helper
    routine.
    
    It will be useful for pid namespaces to abstract the session pid number.
    
    Signed-off-by: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Kirill Korotaev <dev@openvz.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index ec81defde339..9eac4db60eda 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -583,7 +583,7 @@ static int check_kill_permission(int sig, struct siginfo *info,
 	error = -EPERM;
 	if ((info == SEND_SIG_NOINFO || (!is_si_special(info) && SI_FROMUSER(info)))
 	    && ((sig != SIGCONT) ||
-		(current->signal->session != t->signal->session))
+		(process_session(current) != process_session(t)))
 	    && (current->euid ^ t->suid) && (current->euid ^ t->uid)
 	    && (current->uid ^ t->suid) && (current->uid ^ t->uid)
 	    && !capable(CAP_KILL))

commit d3228a887cae75ef2b8b1211c31c539bef5a5698
Author: Adrian Bunk <bunk@stusta.de>
Date:   Wed Dec 6 20:38:22 2006 -0800

    [PATCH] make kernel/signal.c:kill_proc_info() static
    
    Signed-off-by: Adrian Bunk <bunk@stusta.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index bc972d7e6319..ec81defde339 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1134,8 +1134,7 @@ int kill_pid_info(int sig, struct siginfo *info, struct pid *pid)
 	return error;
 }
 
-int
-kill_proc_info(int sig, struct siginfo *info, pid_t pid)
+static int kill_proc_info(int sig, struct siginfo *info, pid_t pid)
 {
 	int error;
 	rcu_read_lock();

commit 7dfb71030f7636a0d65200158113c37764552f93
Author: Nigel Cunningham <ncunningham@linuxmail.org>
Date:   Wed Dec 6 20:34:23 2006 -0800

    [PATCH] Add include/linux/freezer.h and move definitions from sched.h
    
    Move process freezing functions from include/linux/sched.h to freezer.h, so
    that modifications to the freezer or the kernel configuration don't require
    recompiling just about everything.
    
    [akpm@osdl.org: fix ueagle driver]
    Signed-off-by: Nigel Cunningham <nigel@suspend2.net>
    Cc: "Rafael J. Wysocki" <rjw@sisk.pl>
    Cc: Pavel Machek <pavel@ucw.cz>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8e19d2785486..bc972d7e6319 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -23,6 +23,7 @@
 #include <linux/ptrace.h>
 #include <linux/signal.h>
 #include <linux/capability.h>
+#include <linux/freezer.h>
 #include <asm/param.h>
 #include <asm/uaccess.h>
 #include <asm/unistd.h>

commit e18b890bb0881bbab6f4f1a6cd20d9c60d66b003
Author: Christoph Lameter <clameter@sgi.com>
Date:   Wed Dec 6 20:33:20 2006 -0800

    [PATCH] slab: remove kmem_cache_t
    
    Replace all uses of kmem_cache_t with struct kmem_cache.
    
    The patch was generated using the following script:
    
            #!/bin/sh
            #
            # Replace one string by another in all the kernel sources.
            #
    
            set -e
    
            for file in `find * -name "*.c" -o -name "*.h"|xargs grep -l $1`; do
                    quilt add $file
                    sed -e "1,\$s/$1/$2/g" $file >/tmp/$$
                    mv /tmp/$$ $file
                    quilt refresh
            done
    
    The script was run like this
    
            sh replace kmem_cache_t "struct kmem_cache"
    
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index df18c167a2a7..8e19d2785486 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -33,7 +33,7 @@
  * SLAB caches for signal bits.
  */
 
-static kmem_cache_t *sigqueue_cachep;
+static struct kmem_cache *sigqueue_cachep;
 
 /*
  * In POSIX a signal is sent either to a specific thread (Linux task)

commit 10b1fbdb0a0ca91847a534ad26d0bc250c25b74f
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Sat Nov 4 13:03:00 2006 -0800

    Make sure "user->sigpending" count is in sync
    
    The previous commit (45c18b0bb579b5c1b89f8c99f1b6ffa4c586ba08, aka "Fix
    unlikely (but possible) race condition on task->user access") fixed a
    potential oops due to __sigqueue_alloc() getting its "user" pointer out
    of sync with switch_user(), and accessing a user pointer that had been
    de-allocated on another CPU.
    
    It still left another (much less serious) problem, where a concurrent
    __sigqueue_alloc and swich_user could cause sigqueue_alloc to do signal
    pending reference counting for a _different_ user than the one it then
    actually ended up using.  No oops, but we'd end up with the wrong signal
    accounting.
    
    Another case of Oleg's eagle-eyes picking up the problem.
    
    This is trivially fixed by just making sure we load whichever "user"
    structure we decide to use (it doesn't matter _which_ one we pick, we
    just need to pick one) just once.
    
    Acked-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Andrew Morton <akpm@osdl.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 7ed8d5304bec..df18c167a2a7 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -267,18 +267,25 @@ static struct sigqueue *__sigqueue_alloc(struct task_struct *t, gfp_t flags,
 					 int override_rlimit)
 {
 	struct sigqueue *q = NULL;
+	struct user_struct *user;
 
-	atomic_inc(&t->user->sigpending);
+	/*
+	 * In order to avoid problems with "switch_user()", we want to make
+	 * sure that the compiler doesn't re-load "t->user"
+	 */
+	user = t->user;
+	barrier();
+	atomic_inc(&user->sigpending);
 	if (override_rlimit ||
-	    atomic_read(&t->user->sigpending) <=
+	    atomic_read(&user->sigpending) <=
 			t->signal->rlim[RLIMIT_SIGPENDING].rlim_cur)
 		q = kmem_cache_alloc(sigqueue_cachep, flags);
 	if (unlikely(q == NULL)) {
-		atomic_dec(&t->user->sigpending);
+		atomic_dec(&user->sigpending);
 	} else {
 		INIT_LIST_HEAD(&q->list);
 		q->flags = 0;
-		q->user = get_uid(t->user);
+		q->user = get_uid(user);
 	}
 	return(q);
 }

commit 2425c08b37244005ff221efe4957d8aaff18609c
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Oct 2 02:17:28 2006 -0700

    [PATCH] usb: fixup usb so it uses struct pid
    
    The problem with remembering a user space process by its pid is that it is
    possible that the process will exit, pid wrap around will occur.
    Converting to a struct pid avoid that problem, and paves the way for
    implementing a pid namespace.
    
    Also since usb is the only user of kill_proc_info_as_uid rename
    kill_proc_info_as_uid to kill_pid_info_as_uid and have the new version take
    a struct pid.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Acked-by: Greg Kroah-Hartman <gregkh@suse.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5230ddcb1757..7ed8d5304bec 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1136,8 +1136,8 @@ kill_proc_info(int sig, struct siginfo *info, pid_t pid)
 	return error;
 }
 
-/* like kill_proc_info(), but doesn't use uid/euid of "current" */
-int kill_proc_info_as_uid(int sig, struct siginfo *info, pid_t pid,
+/* like kill_pid_info(), but doesn't use uid/euid of "current" */
+int kill_pid_info_as_uid(int sig, struct siginfo *info, struct pid *pid,
 		      uid_t uid, uid_t euid, u32 secid)
 {
 	int ret = -EINVAL;
@@ -1147,7 +1147,7 @@ int kill_proc_info_as_uid(int sig, struct siginfo *info, pid_t pid,
 		return ret;
 
 	read_lock(&tasklist_lock);
-	p = find_task_by_pid(pid);
+	p = pid_task(pid, PIDTYPE_PID);
 	if (!p) {
 		ret = -ESRCH;
 		goto out_unlock;
@@ -1171,7 +1171,7 @@ int kill_proc_info_as_uid(int sig, struct siginfo *info, pid_t pid,
 	read_unlock(&tasklist_lock);
 	return ret;
 }
-EXPORT_SYMBOL_GPL(kill_proc_info_as_uid);
+EXPORT_SYMBOL_GPL(kill_pid_info_as_uid);
 
 /*
  * kill_something_info() interprets pid in interesting ways just like kill(2).

commit c4b92fc112f7be5cce308128236ff75cc98535c3
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Oct 2 02:17:10 2006 -0700

    [PATCH] pid: implement signal functions that take a struct pid *
    
    Currently the signal functions all either take a task or a pid_t argument.
    This patch implements variants that take a struct pid *.  After all of the
    users have been update it is my intention to remove the variants that take a
    pid_t as using pid_t can be more work (an extra hash table lookup) and
    difficult to get right in the presence of multiple pid namespaces.
    
    There are two kinds of functions introduced in this patch.  The are the
    general use functions kill_pgrp and kill_pid which take a priv argument that
    is ultimately used to create the appropriate siginfo information, Then there
    are _kill_pgrp_info, kill_pgrp_info, kill_pid_info the internal implementation
    helpers that take an explicit siginfo.
    
    The distinction is made because filling out an explcit siginfo is tricky, and
    will be even more tricky when pid namespaces are introduced.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index fb5da6d19f14..5230ddcb1757 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1055,28 +1055,44 @@ int group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 }
 
 /*
- * kill_pg_info() sends a signal to a process group: this is what the tty
+ * kill_pgrp_info() sends a signal to a process group: this is what the tty
  * control characters do (^C, ^Z etc)
  */
 
-int __kill_pg_info(int sig, struct siginfo *info, pid_t pgrp)
+int __kill_pgrp_info(int sig, struct siginfo *info, struct pid *pgrp)
 {
 	struct task_struct *p = NULL;
 	int retval, success;
 
-	if (pgrp <= 0)
-		return -EINVAL;
-
 	success = 0;
 	retval = -ESRCH;
-	do_each_task_pid(pgrp, PIDTYPE_PGID, p) {
+	do_each_pid_task(pgrp, PIDTYPE_PGID, p) {
 		int err = group_send_sig_info(sig, info, p);
 		success |= !err;
 		retval = err;
-	} while_each_task_pid(pgrp, PIDTYPE_PGID, p);
+	} while_each_pid_task(pgrp, PIDTYPE_PGID, p);
 	return success ? 0 : retval;
 }
 
+int kill_pgrp_info(int sig, struct siginfo *info, struct pid *pgrp)
+{
+	int retval;
+
+	read_lock(&tasklist_lock);
+	retval = __kill_pgrp_info(sig, info, pgrp);
+	read_unlock(&tasklist_lock);
+
+	return retval;
+}
+
+int __kill_pg_info(int sig, struct siginfo *info, pid_t pgrp)
+{
+	if (pgrp <= 0)
+		return -EINVAL;
+
+	return __kill_pgrp_info(sig, info, find_pid(pgrp));
+}
+
 int
 kill_pg_info(int sig, struct siginfo *info, pid_t pgrp)
 {
@@ -1089,8 +1105,7 @@ kill_pg_info(int sig, struct siginfo *info, pid_t pgrp)
 	return retval;
 }
 
-int
-kill_proc_info(int sig, struct siginfo *info, pid_t pid)
+int kill_pid_info(int sig, struct siginfo *info, struct pid *pid)
 {
 	int error;
 	int acquired_tasklist_lock = 0;
@@ -1101,7 +1116,7 @@ kill_proc_info(int sig, struct siginfo *info, pid_t pid)
 		read_lock(&tasklist_lock);
 		acquired_tasklist_lock = 1;
 	}
-	p = find_task_by_pid(pid);
+	p = pid_task(pid, PIDTYPE_PID);
 	error = -ESRCH;
 	if (p)
 		error = group_send_sig_info(sig, info, p);
@@ -1111,6 +1126,16 @@ kill_proc_info(int sig, struct siginfo *info, pid_t pid)
 	return error;
 }
 
+int
+kill_proc_info(int sig, struct siginfo *info, pid_t pid)
+{
+	int error;
+	rcu_read_lock();
+	error = kill_pid_info(sig, info, find_pid(pid));
+	rcu_read_unlock();
+	return error;
+}
+
 /* like kill_proc_info(), but doesn't use uid/euid of "current" */
 int kill_proc_info_as_uid(int sig, struct siginfo *info, pid_t pid,
 		      uid_t uid, uid_t euid, u32 secid)
@@ -1264,6 +1289,18 @@ force_sigsegv(int sig, struct task_struct *p)
 	return 0;
 }
 
+int kill_pgrp(struct pid *pid, int sig, int priv)
+{
+	return kill_pgrp_info(sig, __si_special(priv), pid);
+}
+EXPORT_SYMBOL(kill_pgrp);
+
+int kill_pid(struct pid *pid, int sig, int priv)
+{
+	return kill_pid_info(sig, __si_special(priv), pid);
+}
+EXPORT_SYMBOL(kill_pid);
+
 int
 kill_pg(pid_t pgrp, int sig, int priv)
 {

commit 27d91e07f9b863fa94491ffafe250580f0c2ce78
Author: Roland McGrath <roland@redhat.com>
Date:   Fri Sep 29 02:00:31 2006 -0700

    [PATCH] __dequeue_signal() cleanup
    
    This tightens up __dequeue_signal a little.  It also avoids doing
    recalc_sigpending twice in a row, instead doing it once in dequeue_signal.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 05853a7337e3..fb5da6d19f14 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -417,9 +417,8 @@ static int collect_signal(int sig, struct sigpending *list, siginfo_t *info)
 static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,
 			siginfo_t *info)
 {
-	int sig = 0;
+	int sig = next_signal(pending, mask);
 
-	sig = next_signal(pending, mask);
 	if (sig) {
 		if (current->notifier) {
 			if (sigismember(current->notifier_mask, sig)) {
@@ -432,9 +431,7 @@ static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,
 
 		if (!collect_signal(sig, pending, info))
 			sig = 0;
-				
 	}
-	recalc_sigpending();
 
 	return sig;
 }
@@ -451,6 +448,7 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
 	if (!signr)
 		signr = __dequeue_signal(&tsk->signal->shared_pending,
 					 mask, info);
+	recalc_sigpending_tsk(tsk);
  	if (signr && unlikely(sig_kernel_stop(signr))) {
  		/*
  		 * Set a marker that we have dequeued a stop signal.  Our

commit f269fdd1829acc5e53bf57b145003e5733133f2b
Author: David Howells <dhowells@redhat.com>
Date:   Wed Sep 27 01:50:23 2006 -0700

    [PATCH] NOMMU: move the fallback arch_vma_name() to a sensible place
    
    Move the fallback arch_vma_name() to a sensible place (kernel/signal.c).
    
    Currently it's in fs/proc/task_mmu.c, a file that is dependent on both
    CONFIG_PROC_FS and CONFIG_MMU being enabled, but it's used from
    kernel/signal.c from where it is called unconditionally.
    
    [akpm@osdl.org: build fix]
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index bfdb5686fa3e..05853a7337e3 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2577,6 +2577,11 @@ asmlinkage long sys_rt_sigsuspend(sigset_t __user *unewset, size_t sigsetsize)
 }
 #endif /* __ARCH_WANT_SYS_RT_SIGSUSPEND */
 
+__attribute__((weak)) const char *arch_vma_name(struct vm_area_struct *vma)
+{
+	return NULL;
+}
+
 void __init signals_init(void)
 {
 	sigqueue_cachep =

commit ae74c3b69a08e1de20cb681ec959f3a48af0006a
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Wed Aug 2 20:17:49 2006 -0700

    Fix force_sig_info() semantics after cleanups
    
    Suresh points out that commit b0423a0d9cc836b2c3d796623cd19236bfedfe63
    broke the semantics of a synchronous signal like SIGSEGV occurring
    recursively inside its own handler handler (or, indeed, any other
    context when the signal was blocked).
    
    That was unintentional, and this fixes things up by reinstating the old
    semantics, but without reverting the cleanups.
    
    Cc: Paul E. McKenney <paulmck@us.ibm.com>
    Acked-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 7fe874d12fae..bfdb5686fa3e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -791,22 +791,31 @@ specific_send_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 /*
  * Force a signal that the process can't ignore: if necessary
  * we unblock the signal and change any SIG_IGN to SIG_DFL.
+ *
+ * Note: If we unblock the signal, we always reset it to SIG_DFL,
+ * since we do not want to have a signal handler that was blocked
+ * be invoked when user space had explicitly blocked it.
+ *
+ * We don't want to have recursive SIGSEGV's etc, for example.
  */
-
 int
 force_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 {
 	unsigned long int flags;
-	int ret;
+	int ret, blocked, ignored;
+	struct k_sigaction *action;
 
 	spin_lock_irqsave(&t->sighand->siglock, flags);
-	if (t->sighand->action[sig-1].sa.sa_handler == SIG_IGN) {
-		t->sighand->action[sig-1].sa.sa_handler = SIG_DFL;
-	}
-	if (sigismember(&t->blocked, sig)) {
-		sigdelset(&t->blocked, sig);
+	action = &t->sighand->action[sig-1];
+	ignored = action->sa.sa_handler == SIG_IGN;
+	blocked = sigismember(&t->blocked, sig);
+	if (blocked || ignored) {
+		action->sa.sa_handler = SIG_DFL;
+		if (blocked) {
+			sigdelset(&t->blocked, sig);
+			recalc_sigpending_tsk(t);
+		}
 	}
-	recalc_sigpending_tsk(t);
 	ret = specific_send_sig_info(sig, info, t);
 	spin_unlock_irqrestore(&t->sighand->siglock, flags);
 

commit 22a3e233ca08a2ddc949ba1ae8f6e16ec7ef1a13
Merge: 39302175c26d 6ab3d5624e17
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Fri Jun 30 15:39:30 2006 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/bunk/trivial
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/bunk/trivial:
      Remove obsolete #include <linux/config.h>
      remove obsolete swsusp_encrypt
      arch/arm26/Kconfig typos
      Documentation/IPMI typos
      Kconfig: Typos in net/sched/Kconfig
      v9fs: do not include linux/version.h
      Documentation/DocBook/mtdnand.tmpl: typo fixes
      typo fixes: specfic -> specific
      typo fixes in Documentation/networking/pktgen.txt
      typo fixes: occuring -> occurring
      typo fixes: infomation -> information
      typo fixes: disadvantadge -> disadvantage
      typo fixes: aquire -> acquire
      typo fixes: mecanism -> mechanism
      typo fixes: bandwith -> bandwidth
      fix a typo in the RTC_CLASS help text
      smb is no longer maintained
    
    Manually merged trivial conflict in arch/um/kernel/vmlinux.lds.S

commit 8f95dc58d0505516f5cc212a966aea2f2cdb5e44
Author: David Quigley <dpquigl@tycho.nsa.gov>
Date:   Fri Jun 30 01:55:47 2006 -0700

    [PATCH] SELinux: add security hook call to kill_proc_info_as_uid
    
    This patch adds a call to the extended security_task_kill hook introduced by
    the prior patch to the kill_proc_info_as_uid function so that these signals
    can be properly mediated by security modules.  It also updates the existing
    hook call in check_kill_permission.
    
    Signed-off-by: David Quigley <dpquigl@tycho.nsa.gov>
    Signed-off-by: James Morris <jmorris@namei.org>
    Cc: Stephen Smalley <sds@tycho.nsa.gov>
    Cc: Chris Wright <chrisw@sous-sol.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 52adf53929f6..477d11adf3d1 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -584,7 +584,7 @@ static int check_kill_permission(int sig, struct siginfo *info,
 	    && !capable(CAP_KILL))
 		return error;
 
-	error = security_task_kill(t, info, sig);
+	error = security_task_kill(t, info, sig, 0);
 	if (!error)
 		audit_signal_info(sig, t); /* Let audit system see the signal */
 	return error;
@@ -1107,7 +1107,7 @@ kill_proc_info(int sig, struct siginfo *info, pid_t pid)
 
 /* like kill_proc_info(), but doesn't use uid/euid of "current" */
 int kill_proc_info_as_uid(int sig, struct siginfo *info, pid_t pid,
-		      uid_t uid, uid_t euid)
+		      uid_t uid, uid_t euid, u32 secid)
 {
 	int ret = -EINVAL;
 	struct task_struct *p;
@@ -1127,6 +1127,9 @@ int kill_proc_info_as_uid(int sig, struct siginfo *info, pid_t pid,
 		ret = -EPERM;
 		goto out_unlock;
 	}
+	ret = security_task_kill(p, info, sig, secid);
+	if (ret)
+		goto out_unlock;
 	if (sig && p->sighand) {
 		unsigned long flags;
 		spin_lock_irqsave(&p->sighand->siglock, flags);

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: Jörn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: Jörn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/kernel/signal.c b/kernel/signal.c
index 52adf53929f6..ecb610d0dc61 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -10,7 +10,6 @@
  *		to allow signals to be sent reliably.
  */
 
-#include <linux/config.h>
 #include <linux/slab.h>
 #include <linux/module.h>
 #include <linux/smp_lock.h>

commit d5f70c00ad24cd1158d3678b44ff969b4c971d49
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon Jun 26 00:26:07 2006 -0700

    [PATCH] coredump: kill ptrace related stuff
    
    With this patch zap_process() sets SIGNAL_GROUP_EXIT while sending SIGKILL to
    the thread group.  This means that a TASK_TRACED task
    
            1. Will be awakened by signal_wake_up(1)
    
            2. Can't sleep again via ptrace_notify()
    
            3. Can't go to do_signal_stop() after return
               from ptrace_stop() in get_signal_to_deliver()
    
    So we can remove all ptrace related stuff from coredump path.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1b3c921737e2..52adf53929f6 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1531,6 +1531,35 @@ static void do_notify_parent_cldstop(struct task_struct *tsk, int why)
 	spin_unlock_irqrestore(&sighand->siglock, flags);
 }
 
+static inline int may_ptrace_stop(void)
+{
+	if (!likely(current->ptrace & PT_PTRACED))
+		return 0;
+
+	if (unlikely(current->parent == current->real_parent &&
+		    (current->ptrace & PT_ATTACHED)))
+		return 0;
+
+	if (unlikely(current->signal == current->parent->signal) &&
+	    unlikely(current->signal->flags & SIGNAL_GROUP_EXIT))
+		return 0;
+
+	/*
+	 * Are we in the middle of do_coredump?
+	 * If so and our tracer is also part of the coredump stopping
+	 * is a deadlock situation, and pointless because our tracer
+	 * is dead so don't allow us to stop.
+	 * If SIGKILL was already sent before the caller unlocked
+	 * ->siglock we must see ->core_waiters != 0. Otherwise it
+	 * is safe to enter schedule().
+	 */
+	if (unlikely(current->mm->core_waiters) &&
+	    unlikely(current->mm == current->parent->mm))
+		return 0;
+
+	return 1;
+}
+
 /*
  * This must be called with current->sighand->siglock held.
  *
@@ -1559,11 +1588,7 @@ static void ptrace_stop(int exit_code, int nostop_code, siginfo_t *info)
 	spin_unlock_irq(&current->sighand->siglock);
 	try_to_freeze();
 	read_lock(&tasklist_lock);
-	if (likely(current->ptrace & PT_PTRACED) &&
-	    likely(current->parent != current->real_parent ||
-		   !(current->ptrace & PT_ATTACHED)) &&
-	    (likely(current->parent->signal != current->signal) ||
-	     !unlikely(current->signal->flags & SIGNAL_GROUP_EXIT))) {
+	if (may_ptrace_stop()) {
 		do_notify_parent_cldstop(current, CLD_TRAPPED);
 		read_unlock(&tasklist_lock);
 		schedule();

commit e1396065e0489f98b35021b97907ab4edbfb24e1
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu May 25 10:19:47 2006 -0400

    [PATCH] collect sid of those who send signals to auditd
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/signal.c b/kernel/signal.c
index e5f8aea78ffe..1b3c921737e2 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -23,12 +23,12 @@
 #include <linux/syscalls.h>
 #include <linux/ptrace.h>
 #include <linux/signal.h>
-#include <linux/audit.h>
 #include <linux/capability.h>
 #include <asm/param.h>
 #include <asm/uaccess.h>
 #include <asm/unistd.h>
 #include <asm/siginfo.h>
+#include "audit.h"	/* audit_signal_info() */
 
 /*
  * SLAB caches for signal bits.

commit e57a5059846e55d82b86d96dde40e988598601b3
Author: Roland McGrath <roland@redhat.com>
Date:   Wed Apr 12 16:30:20 2006 -0700

    [PATCH] fix non-leader exec under ptrace
    
    This reverts most of commit 30e0fca6c1d7d26f3f2daa4dd2b12c51dadc778a.
    It broke the case of non-leader MT exec when ptraced.
    I think the bug it was intended to fix was already addressed by commit
    788e05a67c343fa22f2ae1d3ca264e7f15c25eaf.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Acked-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index b14f895027c3..e5f8aea78ffe 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1754,9 +1754,9 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 			/* Let the debugger run.  */
 			ptrace_stop(signr, signr, info);
 
-			/* We're back.  Did the debugger cancel the sig or group_exit? */
+			/* We're back.  Did the debugger cancel the sig?  */
 			signr = current->exit_code;
-			if (signr == 0 || current->signal->flags & SIGNAL_GROUP_EXIT)
+			if (signr == 0)
 				continue;
 
 			current->exit_code = 0;

commit a145410dccdb44f81d3b56763ef9b6f721f4e47c
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Apr 11 22:18:58 2006 +0400

    [PATCH] __group_complete_signal: remove bogus BUG_ON
    
    Commit e56d090310d7625ecb43a1eeebd479f04affb48b
    
       [PATCH] RCU signal handling
    
    made this BUG_ON() unsafe. This code runs under ->siglock,
    while switch_exec_pids() takes tasklist_lock.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5ccaac505e8d..b14f895027c3 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -868,7 +868,6 @@ __group_complete_signal(int sig, struct task_struct *p)
 		if (t == NULL)
 			/* restart balancing at this thread */
 			t = p->signal->curr_target = p;
-		BUG_ON(t->tgid != p->tgid);
 
 		while (!wants_signal(sig, t)) {
 			t = next_thread(t);

commit fda8bd78a15950b9b01a1c1477a9095cb08c27c1
Author: Eric Sesterhenn <snakebyte@gmx.de>
Date:   Sun Apr 2 13:44:47 2006 +0200

    BUG_ON() Conversion in kernel/signal.c
    
    this changes if() BUG(); constructs to BUG_ON() which is
    cleaner, contains unlikely() and can better optimized away.
    
    Signed-off-by: Eric Sesterhenn <snakebyte@gmx.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/kernel/signal.c b/kernel/signal.c
index 92025b108791..5ccaac505e8d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -769,8 +769,7 @@ specific_send_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 {
 	int ret = 0;
 
-	if (!irqs_disabled())
-		BUG();
+	BUG_ON(!irqs_disabled());
 	assert_spin_locked(&t->sighand->siglock);
 
 	/* Short-circuit ignored signals.  */
@@ -1384,8 +1383,7 @@ send_group_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 		 * the overrun count.  Other uses should not try to
 		 * send the signal multiple times.
 		 */
-		if (q->info.si_code != SI_TIMER)
-			BUG();
+		BUG_ON(q->info.si_code != SI_TIMER);
 		q->info.si_overrun++;
 		goto out;
 	} 

commit 85b6bce3658a823aa169586fe71ffba0f12ccc71
Author: Pavel Machek <pavel@suse.cz>
Date:   Fri Mar 31 02:30:06 2006 -0800

    [PATCH] Fix suspend with traced tasks
    
    strace /bin/bash misbehaves after resume; this fixes it.
    
    (akpm: it's scary calling refrigerator() in state TASK_TRACED, but it seems to
    do the right thing).
    
    Signed-off-by: Pavel Machek <pavel@suse.cz>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 4922928d91f6..92025b108791 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1560,6 +1560,7 @@ static void ptrace_stop(int exit_code, int nostop_code, siginfo_t *info)
 	/* Let the debugger run.  */
 	set_current_state(TASK_TRACED);
 	spin_unlock_irq(&current->sighand->siglock);
+	try_to_freeze();
 	read_lock(&tasklist_lock);
 	if (likely(current->ptrace & PT_PTRACED) &&
 	    likely(current->parent != current->real_parent ||

commit 547679087bc60277d11b11631d826895762c4505
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:11:30 2006 -0800

    [PATCH] send_sigqueue: simplify and fix the race
    
    send_sigqueue() checks PF_EXITING, then locks p->sighand->siglock.  This is
    unsafe: 'p' can exit in between and set ->sighand = NULL.  The race is
    theoretical, the window is tiny and irqs are disabled by the caller, so I
    don't think we need the fix for -stable tree.
    
    Convert send_sigqueue() to use lock_task_sighand() helper.
    
    Also, delete 'p->flags & PF_EXITING' re-check, it is unneeded and the
    comment is wrong.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 0528a959daa9..4922928d91f6 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1309,12 +1309,10 @@ void sigqueue_free(struct sigqueue *q)
 	__sigqueue_free(q);
 }
 
-int
-send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
+int send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 {
 	unsigned long flags;
 	int ret = 0;
-	struct sighand_struct *sh;
 
 	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
 
@@ -1328,48 +1326,17 @@ send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 	 */
 	rcu_read_lock();
 
-	if (unlikely(p->flags & PF_EXITING)) {
+	if (!likely(lock_task_sighand(p, &flags))) {
 		ret = -1;
 		goto out_err;
 	}
 
-retry:
-	sh = rcu_dereference(p->sighand);
-
-	spin_lock_irqsave(&sh->siglock, flags);
-	if (p->sighand != sh) {
-		/* We raced with exec() in a multithreaded process... */
-		spin_unlock_irqrestore(&sh->siglock, flags);
-		goto retry;
-	}
-
-	/*
-	 * We do the check here again to handle the following scenario:
-	 *
-	 * CPU 0		CPU 1
-	 * send_sigqueue
-	 * check PF_EXITING
-	 * interrupt		exit code running
-	 *			__exit_signal
-	 *			lock sighand->siglock
-	 *			unlock sighand->siglock
-	 * lock sh->siglock
-	 * add(tsk->pending) 	flush_sigqueue(tsk->pending)
-	 *
-	 */
-
-	if (unlikely(p->flags & PF_EXITING)) {
-		ret = -1;
-		goto out;
-	}
-
 	if (unlikely(!list_empty(&q->list))) {
 		/*
 		 * If an SI_TIMER entry is already queue just increment
 		 * the overrun count.
 		 */
-		if (q->info.si_code != SI_TIMER)
-			BUG();
+		BUG_ON(q->info.si_code != SI_TIMER);
 		q->info.si_overrun++;
 		goto out;
 	}
@@ -1385,7 +1352,7 @@ send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 		signal_wake_up(p, sig == SIGKILL);
 
 out:
-	spin_unlock_irqrestore(&sh->siglock, flags);
+	unlock_task_sighand(p, &flags);
 out_err:
 	rcu_read_unlock();
 

commit a1d5e21e3e388fb2c16463d007e788b1e41b74f1
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:11:29 2006 -0800

    [PATCH] do_notify_parent_cldstop: remove 'to_self' param
    
    The previous patch has changed callsites of do_notify_parent_cldstop() so that
    to_self == (->ptrace & PT_PTRACED) always (as it should be).  We can remove
    this parameter now.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: john stultz <johnstul@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 24d5059ab0a9..0528a959daa9 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -591,9 +591,7 @@ static int check_kill_permission(int sig, struct siginfo *info,
 }
 
 /* forward decl */
-static void do_notify_parent_cldstop(struct task_struct *tsk,
-				     int to_self,
-				     int why);
+static void do_notify_parent_cldstop(struct task_struct *tsk, int why);
 
 /*
  * Handle magic process-wide effects of stop/continue signals.
@@ -643,7 +641,7 @@ static void handle_stop_signal(int sig, struct task_struct *p)
 			p->signal->group_stop_count = 0;
 			p->signal->flags = SIGNAL_STOP_CONTINUED;
 			spin_unlock(&p->sighand->siglock);
-			do_notify_parent_cldstop(p, (p->ptrace & PT_PTRACED), CLD_STOPPED);
+			do_notify_parent_cldstop(p, CLD_STOPPED);
 			spin_lock(&p->sighand->siglock);
 		}
 		rm_from_queue(SIG_KERNEL_STOP_MASK, &p->signal->shared_pending);
@@ -684,7 +682,7 @@ static void handle_stop_signal(int sig, struct task_struct *p)
 			p->signal->flags = SIGNAL_STOP_CONTINUED;
 			p->signal->group_exit_code = 0;
 			spin_unlock(&p->sighand->siglock);
-			do_notify_parent_cldstop(p, (p->ptrace & PT_PTRACED), CLD_CONTINUED);
+			do_notify_parent_cldstop(p, CLD_CONTINUED);
 			spin_lock(&p->sighand->siglock);
 		} else {
 			/*
@@ -1519,14 +1517,14 @@ void do_notify_parent(struct task_struct *tsk, int sig)
 	spin_unlock_irqrestore(&psig->siglock, flags);
 }
 
-static void do_notify_parent_cldstop(struct task_struct *tsk, int to_self, int why)
+static void do_notify_parent_cldstop(struct task_struct *tsk, int why)
 {
 	struct siginfo info;
 	unsigned long flags;
 	struct task_struct *parent;
 	struct sighand_struct *sighand;
 
-	if (to_self)
+	if (tsk->ptrace & PT_PTRACED)
 		parent = tsk->parent;
 	else {
 		tsk = tsk->group_leader;
@@ -1601,7 +1599,7 @@ static void ptrace_stop(int exit_code, int nostop_code, siginfo_t *info)
 		   !(current->ptrace & PT_ATTACHED)) &&
 	    (likely(current->parent->signal != current->signal) ||
 	     !unlikely(current->signal->flags & SIGNAL_GROUP_EXIT))) {
-		do_notify_parent_cldstop(current, 1, CLD_TRAPPED);
+		do_notify_parent_cldstop(current, CLD_TRAPPED);
 		read_unlock(&tasklist_lock);
 		schedule();
 	} else {
@@ -1650,25 +1648,17 @@ void ptrace_notify(int exit_code)
 static void
 finish_stop(int stop_count)
 {
-	int to_self;
-
 	/*
 	 * If there are no other threads in the group, or if there is
 	 * a group stop in progress and we are the last to stop,
 	 * report to the parent.  When ptraced, every thread reports itself.
 	 */
-	if (current->ptrace & PT_PTRACED)
-		to_self = 1;
-	else if (stop_count == 0)
-		to_self = 0;
-	else
-		goto out;
-
-	read_lock(&tasklist_lock);
-	do_notify_parent_cldstop(current, to_self, CLD_STOPPED);
-	read_unlock(&tasklist_lock);
+	if (stop_count == 0 || (current->ptrace & PT_PTRACED)) {
+		read_lock(&tasklist_lock);
+		do_notify_parent_cldstop(current, CLD_STOPPED);
+		read_unlock(&tasklist_lock);
+	}
 
-out:
 	schedule();
 	/*
 	 * Now we don't run again until continued.

commit 883606a7c9e84e206f96c38f88c4bd66df72f51e
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:11:28 2006 -0800

    [PATCH] finish_stop: don't check stop_count < 0
    
    Remove an obscure 'stop_count < 0' check in finish_stop().  The previous patch
    made this case impossible.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: john stultz <johnstul@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index efba39626e66..24d5059ab0a9 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1657,7 +1657,7 @@ finish_stop(int stop_count)
 	 * a group stop in progress and we are the last to stop,
 	 * report to the parent.  When ptraced, every thread reports itself.
 	 */
-	if (stop_count < 0 || (current->ptrace & PT_PTRACED))
+	if (current->ptrace & PT_PTRACED)
 		to_self = 1;
 	else if (stop_count == 0)
 		to_self = 0;

commit dac27f4a09c274db048e80d2511102e540ac9e3a
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:11:28 2006 -0800

    [PATCH] simplify do_signal_stop()
    
    do_signal_stop() considers 'thread_group_empty()' as a special case.
    This was needed to avoid taking tasklist_lock. Since this lock is
    unneeded any longer, we can remove this special case and simplify
    the code even more.
    
    Also, before this patch, finish_stop() was called with stop_count == -1
    for 'thread_group_empty()' case. This is not strictly wrong, but confusing
    and unneeded.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: john stultz <johnstul@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 2dfaa5076c31..efba39626e66 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1685,8 +1685,7 @@ finish_stop(int stop_count)
 static int do_signal_stop(int signr)
 {
 	struct signal_struct *sig = current->signal;
-	struct sighand_struct *sighand = current->sighand;
-	int stop_count = -1;
+	int stop_count;
 
 	if (!likely(sig->flags & SIGNAL_STOP_DEQUEUED))
 		return 0;
@@ -1696,30 +1695,14 @@ static int do_signal_stop(int signr)
 		 * There is a group stop in progress.  We don't need to
 		 * start another one.
 		 */
-		signr = sig->group_exit_code;
 		stop_count = --sig->group_stop_count;
-		current->exit_code = signr;
-		set_current_state(TASK_STOPPED);
-		if (stop_count == 0)
-			sig->flags = SIGNAL_STOP_STOPPED;
-	}
-	else if (thread_group_empty(current)) {
-		/*
-		 * Lock must be held through transition to stopped state.
-		 */
-		current->exit_code = current->signal->group_exit_code = signr;
-		set_current_state(TASK_STOPPED);
-		sig->flags = SIGNAL_STOP_STOPPED;
-	}
-	else {
+	} else {
 		/*
-		 * (sig->group_stop_count == 0)
 		 * There is no group stop already in progress.
 		 * We must initiate one now.
 		 */
 		struct task_struct *t;
 
-		current->exit_code = signr;
 		sig->group_exit_code = signr;
 
 		stop_count = 0;
@@ -1735,13 +1718,14 @@ static int do_signal_stop(int signr)
 				signal_wake_up(t, 0);
 			}
 		sig->group_stop_count = stop_count;
-
-		set_current_state(TASK_STOPPED);
-		if (stop_count == 0)
-			sig->flags = SIGNAL_STOP_STOPPED;
 	}
 
-	spin_unlock_irq(&sighand->siglock);
+	if (stop_count == 0)
+		sig->flags = SIGNAL_STOP_STOPPED;
+	current->exit_code = sig->group_exit_code;
+	__set_current_state(TASK_STOPPED);
+
+	spin_unlock_irq(&current->sighand->siglock);
 	finish_stop(stop_count);
 	return 1;
 }

commit 88531f725bd52e37a7be726860e4ff3f09031d89
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:11:24 2006 -0800

    [PATCH] do_sigaction: don't take tasklist_lock
    
    do_sigaction() does not need tasklist_lock anymore, we can simplify the code.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index e3bdec914626..2dfaa5076c31 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2301,8 +2301,7 @@ sys_rt_sigqueueinfo(int pid, int sig, siginfo_t __user *uinfo)
 	return kill_proc_info(sig, &info, pid);
 }
 
-int
-do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
+int do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 {
 	struct k_sigaction *k;
 	sigset_t mask;
@@ -2328,6 +2327,7 @@ do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 	if (act) {
 		sigdelsetmask(&act->sa.sa_mask,
 			      sigmask(SIGKILL) | sigmask(SIGSTOP));
+		*k = *act;
 		/*
 		 * POSIX 3.3.1.3:
 		 *  "Setting a signal action to SIG_IGN for a signal that is
@@ -2340,19 +2340,8 @@ do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 		 *   be discarded, whether or not it is blocked"
 		 */
 		if (act->sa.sa_handler == SIG_IGN ||
-		    (act->sa.sa_handler == SIG_DFL &&
-		     sig_kernel_ignore(sig))) {
-			/*
-			 * This is a fairly rare case, so we only take the
-			 * tasklist_lock once we're sure we'll need it.
-			 * Now we must do this little unlock and relock
-			 * dance to maintain the lock hierarchy.
-			 */
+		   (act->sa.sa_handler == SIG_DFL && sig_kernel_ignore(sig))) {
 			struct task_struct *t = current;
-			spin_unlock_irq(&t->sighand->siglock);
-			read_lock(&tasklist_lock);
-			spin_lock_irq(&t->sighand->siglock);
-			*k = *act;
 			sigemptyset(&mask);
 			sigaddset(&mask, sig);
 			rm_from_queue_full(&mask, &t->signal->shared_pending);
@@ -2361,12 +2350,7 @@ do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 				recalc_sigpending_tsk(t);
 				t = next_thread(t);
 			} while (t != current);
-			spin_unlock_irq(&current->sighand->siglock);
-			read_unlock(&tasklist_lock);
-			return 0;
 		}
-
-		*k = *act;
 	}
 
 	spin_unlock_irq(&current->sighand->siglock);

commit a122b341b74c08020f6521b615acca6a692aac79
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:11:22 2006 -0800

    [PATCH] do_signal_stop: don't take tasklist_lock
    
    do_signal_stop() does not need tasklist_lock anymore.  So it does not need to
    do misc re-checks, and we can simplify the code.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index e99ec2f891a0..e3bdec914626 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1682,8 +1682,7 @@ finish_stop(int stop_count)
  * Returns nonzero if we've actually stopped and released the siglock.
  * Returns zero if we didn't stop and still hold the siglock.
  */
-static int
-do_signal_stop(int signr)
+static int do_signal_stop(int signr)
 {
 	struct signal_struct *sig = current->signal;
 	struct sighand_struct *sighand = current->sighand;
@@ -1703,7 +1702,6 @@ do_signal_stop(int signr)
 		set_current_state(TASK_STOPPED);
 		if (stop_count == 0)
 			sig->flags = SIGNAL_STOP_STOPPED;
-		spin_unlock_irq(&sighand->siglock);
 	}
 	else if (thread_group_empty(current)) {
 		/*
@@ -1712,71 +1710,38 @@ do_signal_stop(int signr)
 		current->exit_code = current->signal->group_exit_code = signr;
 		set_current_state(TASK_STOPPED);
 		sig->flags = SIGNAL_STOP_STOPPED;
-		spin_unlock_irq(&sighand->siglock);
 	}
 	else {
 		/*
+		 * (sig->group_stop_count == 0)
 		 * There is no group stop already in progress.
-		 * We must initiate one now, but that requires
-		 * dropping siglock to get both the tasklist lock
-		 * and siglock again in the proper order.  Note that
-		 * this allows an intervening SIGCONT to be posted.
-		 * We need to check for that and bail out if necessary.
+		 * We must initiate one now.
 		 */
 		struct task_struct *t;
 
-		spin_unlock_irq(&sighand->siglock);
-
-		/* signals can be posted during this window */
-
-		read_lock(&tasklist_lock);
-		spin_lock_irq(&sighand->siglock);
+		current->exit_code = signr;
+		sig->group_exit_code = signr;
 
-		if (!likely(sig->flags & SIGNAL_STOP_DEQUEUED)) {
+		stop_count = 0;
+		for (t = next_thread(current); t != current; t = next_thread(t))
 			/*
-			 * Another stop or continue happened while we
-			 * didn't have the lock.  We can just swallow this
-			 * signal now.  If we raced with a SIGCONT, that
-			 * should have just cleared it now.  If we raced
-			 * with another processor delivering a stop signal,
-			 * then the SIGCONT that wakes us up should clear it.
+			 * Setting state to TASK_STOPPED for a group
+			 * stop is always done with the siglock held,
+			 * so this check has no races.
 			 */
-			read_unlock(&tasklist_lock);
-			return 0;
-		}
-
-		if (sig->group_stop_count == 0) {
-			sig->group_exit_code = signr;
-			stop_count = 0;
-			for (t = next_thread(current); t != current;
-			     t = next_thread(t))
-				/*
-				 * Setting state to TASK_STOPPED for a group
-				 * stop is always done with the siglock held,
-				 * so this check has no races.
-				 */
-				if (!t->exit_state &&
-				    !(t->state & (TASK_STOPPED|TASK_TRACED))) {
-					stop_count++;
-					signal_wake_up(t, 0);
-				}
-			sig->group_stop_count = stop_count;
-		}
-		else {
-			/* A race with another thread while unlocked.  */
-			signr = sig->group_exit_code;
-			stop_count = --sig->group_stop_count;
-		}
+			if (!t->exit_state &&
+			    !(t->state & (TASK_STOPPED|TASK_TRACED))) {
+				stop_count++;
+				signal_wake_up(t, 0);
+			}
+		sig->group_stop_count = stop_count;
 
-		current->exit_code = signr;
 		set_current_state(TASK_STOPPED);
 		if (stop_count == 0)
 			sig->flags = SIGNAL_STOP_STOPPED;
-
-		spin_unlock_irq(&sighand->siglock);
-		read_unlock(&tasklist_lock);
 	}
 
+	spin_unlock_irq(&sighand->siglock);
 	finish_stop(stop_count);
 	return 1;
 }

commit 6108ccd3e2f3012d5eec582e0af4d75e693824da
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:11:22 2006 -0800

    [PATCH] relax sig_needs_tasklist()
    
    handle_stop_signal() does not need tasklist_lock for SIG_KERNEL_STOP_MASK
    signals anymore.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 6ea49f742a2f..e99ec2f891a0 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -146,8 +146,7 @@ static kmem_cache_t *sigqueue_cachep;
 #define sig_kernel_stop(sig) \
 		(((sig) < SIGRTMIN)  && T(sig, SIG_KERNEL_STOP_MASK))
 
-#define sig_needs_tasklist(sig) \
-		(((sig) < SIGRTMIN)  && T(sig, SIG_KERNEL_STOP_MASK | M(SIGCONT)))
+#define sig_needs_tasklist(sig)	((sig) == SIGCONT)
 
 #define sig_user_defined(t, signr) \
 	(((t)->sighand->action[(signr)-1].sa.sa_handler != SIG_DFL) &&	\

commit 6a14c5c9da0b4c34b5be783403c54f0396fcfe77
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:11:18 2006 -0800

    [PATCH] move __exit_signal() to kernel/exit.c
    
    __exit_signal() is private to release_task() now.  I think it is better to
    make it static in kernel/exit.c and export flush_sigqueue() instead - this
    function is much more simple and straightforward.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index b29c868bd5ee..6ea49f742a2f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -22,7 +22,6 @@
 #include <linux/security.h>
 #include <linux/syscalls.h>
 #include <linux/ptrace.h>
-#include <linux/posix-timers.h>
 #include <linux/signal.h>
 #include <linux/audit.h>
 #include <linux/capability.h>
@@ -295,7 +294,7 @@ static void __sigqueue_free(struct sigqueue *q)
 	kmem_cache_free(sigqueue_cachep, q);
 }
 
-static void flush_sigqueue(struct sigpending *queue)
+void flush_sigqueue(struct sigpending *queue)
 {
 	struct sigqueue *q;
 
@@ -321,68 +320,6 @@ void flush_signals(struct task_struct *t)
 	spin_unlock_irqrestore(&t->sighand->siglock, flags);
 }
 
-/*
- * This function expects the tasklist_lock write-locked.
- */
-void __exit_signal(struct task_struct *tsk)
-{
-	struct signal_struct *sig = tsk->signal;
-	struct sighand_struct *sighand;
-
-	BUG_ON(!sig);
-	BUG_ON(!atomic_read(&sig->count));
-
-	rcu_read_lock();
-	sighand = rcu_dereference(tsk->sighand);
-	spin_lock(&sighand->siglock);
-
-	posix_cpu_timers_exit(tsk);
-	if (atomic_dec_and_test(&sig->count))
-		posix_cpu_timers_exit_group(tsk);
-	else {
-		/*
-		 * If there is any task waiting for the group exit
-		 * then notify it:
-		 */
-		if (sig->group_exit_task && atomic_read(&sig->count) == sig->notify_count) {
-			wake_up_process(sig->group_exit_task);
-			sig->group_exit_task = NULL;
-		}
-		if (tsk == sig->curr_target)
-			sig->curr_target = next_thread(tsk);
-		/*
-		 * Accumulate here the counters for all threads but the
-		 * group leader as they die, so they can be added into
-		 * the process-wide totals when those are taken.
-		 * The group leader stays around as a zombie as long
-		 * as there are other threads.  When it gets reaped,
-		 * the exit.c code will add its counts into these totals.
-		 * We won't ever get here for the group leader, since it
-		 * will have been the last reference on the signal_struct.
-		 */
-		sig->utime = cputime_add(sig->utime, tsk->utime);
-		sig->stime = cputime_add(sig->stime, tsk->stime);
-		sig->min_flt += tsk->min_flt;
-		sig->maj_flt += tsk->maj_flt;
-		sig->nvcsw += tsk->nvcsw;
-		sig->nivcsw += tsk->nivcsw;
-		sig->sched_time += tsk->sched_time;
-		sig = NULL; /* Marker for below. */
-	}
-
-	tsk->signal = NULL;
-	cleanup_sighand(tsk);
-	spin_unlock(&sighand->siglock);
-	rcu_read_unlock();
-
-	clear_tsk_thread_flag(tsk,TIF_SIGPENDING);
-	flush_sigqueue(&tsk->pending);
-	if (sig) {
-		flush_sigqueue(&sig->shared_pending);
-		__cleanup_signal(sig);
-	}
-}
-
 /*
  * Flush all handlers for a task.
  */

commit c81addc9d3a0ebff2155e0cd86f90820ab97147e
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:11:17 2006 -0800

    [PATCH] rename __exit_sighand to cleanup_sighand
    
    Cosmetic, rename __exit_sighand to cleanup_sighand and move it close to
    copy_sighand().
    
    This matches copy_signal/cleanup_signal naming, and I think it is easier to
    follow.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: "Paul E. McKenney" <paulmck@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index ca1fa854e469..b29c868bd5ee 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -310,9 +310,7 @@ static void flush_sigqueue(struct sigpending *queue)
 /*
  * Flush all pending signals for a task.
  */
-
-void
-flush_signals(struct task_struct *t)
+void flush_signals(struct task_struct *t)
 {
 	unsigned long flags;
 
@@ -323,19 +321,6 @@ flush_signals(struct task_struct *t)
 	spin_unlock_irqrestore(&t->sighand->siglock, flags);
 }
 
-/*
- * This function expects the tasklist_lock write-locked.
- */
-void __exit_sighand(struct task_struct *tsk)
-{
-	struct sighand_struct * sighand = tsk->sighand;
-
-	/* Ok, we're done with the signal handlers */
-	tsk->sighand = NULL;
-	if (atomic_dec_and_test(&sighand->count))
-		kmem_cache_free(sighand_cachep, sighand);
-}
-
 /*
  * This function expects the tasklist_lock write-locked.
  */
@@ -386,7 +371,7 @@ void __exit_signal(struct task_struct *tsk)
 	}
 
 	tsk->signal = NULL;
-	__exit_sighand(tsk);
+	cleanup_sighand(tsk);
 	spin_unlock(&sighand->siglock);
 	rcu_read_unlock();
 

commit 29ff471234d53c7235db287bc52f91884c2977c6
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:11:17 2006 -0800

    [PATCH] cleanup __exit_signal()
    
    This patch factors out duplicated code under 'if' branches.  Also, BUG_ON()
    conversions and whitespace cleanups.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: "Paul E. McKenney" <paulmck@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 54e9ef673e68..ca1fa854e469 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -341,24 +341,20 @@ void __exit_sighand(struct task_struct *tsk)
  */
 void __exit_signal(struct task_struct *tsk)
 {
-	struct signal_struct * sig = tsk->signal;
-	struct sighand_struct * sighand;
+	struct signal_struct *sig = tsk->signal;
+	struct sighand_struct *sighand;
+
+	BUG_ON(!sig);
+	BUG_ON(!atomic_read(&sig->count));
 
-	if (!sig)
-		BUG();
-	if (!atomic_read(&sig->count))
-		BUG();
 	rcu_read_lock();
 	sighand = rcu_dereference(tsk->sighand);
 	spin_lock(&sighand->siglock);
+
 	posix_cpu_timers_exit(tsk);
-	if (atomic_dec_and_test(&sig->count)) {
+	if (atomic_dec_and_test(&sig->count))
 		posix_cpu_timers_exit_group(tsk);
-		tsk->signal = NULL;
-		__exit_sighand(tsk);
-		spin_unlock(&sighand->siglock);
-		flush_sigqueue(&sig->shared_pending);
-	} else {
+	else {
 		/*
 		 * If there is any task waiting for the group exit
 		 * then notify it:
@@ -369,7 +365,6 @@ void __exit_signal(struct task_struct *tsk)
 		}
 		if (tsk == sig->curr_target)
 			sig->curr_target = next_thread(tsk);
-		tsk->signal = NULL;
 		/*
 		 * Accumulate here the counters for all threads but the
 		 * group leader as they die, so they can be added into
@@ -387,14 +382,18 @@ void __exit_signal(struct task_struct *tsk)
 		sig->nvcsw += tsk->nvcsw;
 		sig->nivcsw += tsk->nivcsw;
 		sig->sched_time += tsk->sched_time;
-		__exit_sighand(tsk);
-		spin_unlock(&sighand->siglock);
-		sig = NULL;	/* Marker for below.  */
+		sig = NULL; /* Marker for below. */
 	}
+
+	tsk->signal = NULL;
+	__exit_sighand(tsk);
+	spin_unlock(&sighand->siglock);
 	rcu_read_unlock();
+
 	clear_tsk_thread_flag(tsk,TIF_SIGPENDING);
 	flush_sigqueue(&tsk->pending);
 	if (sig) {
+		flush_sigqueue(&sig->shared_pending);
 		__cleanup_signal(sig);
 	}
 }

commit 6b3934ef52712ece50605dfc72e55d00c580831a
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:11:16 2006 -0800

    [PATCH] copy_process: cleanup bad_fork_cleanup_signal
    
    __exit_signal() does important cleanups atomically under ->siglock.  It is
    also called from copy_process's error path.  This is not good, for example we
    can't move __unhash_process() under ->siglock for that reason.
    
    We should not mix these 2 paths, just look at ugly 'if (p->sighand)' under
    'bad_fork_cleanup_sighand:' label.  For copy_process() case it is sufficient
    to just backout copy_signal(), nothing more.
    
    Again, nobody can see this task yet.  For CLONE_THREAD case we just decrement
    signal->count, otherwise nobody can see this ->signal and we can free it
    lockless.
    
    This patch assumes it is safe to do exit_thread_group_keys() without
    tasklist_lock.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1d7f4463c32d..54e9ef673e68 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -395,23 +395,10 @@ void __exit_signal(struct task_struct *tsk)
 	clear_tsk_thread_flag(tsk,TIF_SIGPENDING);
 	flush_sigqueue(&tsk->pending);
 	if (sig) {
-		/*
-		 * We are cleaning up the signal_struct here.
-		 */
-		exit_thread_group_keys(sig);
-		kmem_cache_free(signal_cachep, sig);
+		__cleanup_signal(sig);
 	}
 }
 
-void exit_signal(struct task_struct *tsk)
-{
-	atomic_dec(&tsk->signal->live);
-
-	write_lock_irq(&tasklist_lock);
-	__exit_signal(tsk);
-	write_unlock_irq(&tasklist_lock);
-}
-
 /*
  * Flush all handlers for a task.
  */

commit 7001510d0cbf51ad202dd2d0744f54104285cbb9
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:11:14 2006 -0800

    [PATCH] copy_process: cleanup bad_fork_cleanup_sighand
    
    The only caller of exit_sighand(tsk) is copy_process's error path.  We can
    call __exit_sighand() directly and kill exit_sighand().
    
    This 'tsk' was not yet registered in pid_hash[] or init_task.tasks, it has no
    external references, nobody can see it, and
    
            IF (clone_flags & CLONE_SIGHAND)
                    At least 'current' has a reference to ->sighand, this
                    means atomic_dec_and_test(sighand->count) can't be true.
    
            ELSE
                    Nobody can see this ->sighand, this means we can free it
                    without any locking.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: "Paul E. McKenney" <paulmck@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index c5b65aa4c2bc..1d7f4463c32d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -336,20 +336,6 @@ void __exit_sighand(struct task_struct *tsk)
 		kmem_cache_free(sighand_cachep, sighand);
 }
 
-void exit_sighand(struct task_struct *tsk)
-{
-	write_lock_irq(&tasklist_lock);
-	rcu_read_lock();
-	if (tsk->sighand != NULL) {
-		struct sighand_struct *sighand = rcu_dereference(tsk->sighand);
-		spin_lock(&sighand->siglock);
-		__exit_sighand(tsk);
-		spin_unlock(&sighand->siglock);
-	}
-	rcu_read_unlock();
-	write_unlock_irq(&tasklist_lock);
-}
-
 /*
  * This function expects the tasklist_lock write-locked.
  */

commit a9e88e84b5245da0a1dadb6ccca70ae84e93ccf6
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:11:14 2006 -0800

    [PATCH] introduce sig_needs_tasklist() helper
    
    In my opinion this patch cleans up the code.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 819fa49aa70a..c5b65aa4c2bc 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -147,6 +147,9 @@ static kmem_cache_t *sigqueue_cachep;
 #define sig_kernel_stop(sig) \
 		(((sig) < SIGRTMIN)  && T(sig, SIG_KERNEL_STOP_MASK))
 
+#define sig_needs_tasklist(sig) \
+		(((sig) < SIGRTMIN)  && T(sig, SIG_KERNEL_STOP_MASK | M(SIGCONT)))
+
 #define sig_user_defined(t, signr) \
 	(((t)->sighand->action[(signr)-1].sa.sa_handler != SIG_DFL) &&	\
 	 ((t)->sighand->action[(signr)-1].sa.sa_handler != SIG_IGN))
@@ -1199,7 +1202,7 @@ kill_proc_info(int sig, struct siginfo *info, pid_t pid)
 	struct task_struct *p;
 
 	rcu_read_lock();
-	if (unlikely(sig_kernel_stop(sig) || sig == SIGCONT)) {
+	if (unlikely(sig_needs_tasklist(sig))) {
 		read_lock(&tasklist_lock);
 		acquired_tasklist_lock = 1;
 	}

commit f63ee72e0fb82e504a0489490babc7612c7cd6c2
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:11:13 2006 -0800

    [PATCH] introduce lock_task_sighand() helper
    
    Add lock_task_sighand() helper and converts group_send_sig_info() to use
    it.  Hopefully we will have more users soon.
    
    This patch also removes '!sighand->count' and '!p->usage' checks, I think
    they both are bogus, racy and unneeded (but probably it makes sense to
    restore them as BUG_ON()s).
    
    ->sighand is cleared and it's ->count is decremented in release_task() with
    sighand->siglock held, so it is a bug to have '!p->usage || !->count' after
    we already locked and verified it is the same.  On the other hand, an
    already dead task without ->sighand can have a non-zero ->usage due to
    ptrace, for example.
    
    If we read the stale value of ->sighand we must see the change after
    spin_lock(), because that change was done while holding that same old
    ->sighand.siglock.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index b0b1ca9daa33..819fa49aa70a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1120,27 +1120,37 @@ void zap_other_threads(struct task_struct *p)
 /*
  * Must be called under rcu_read_lock() or with tasklist_lock read-held.
  */
+struct sighand_struct *lock_task_sighand(struct task_struct *tsk, unsigned long *flags)
+{
+	struct sighand_struct *sighand;
+
+	for (;;) {
+		sighand = rcu_dereference(tsk->sighand);
+		if (unlikely(sighand == NULL))
+			break;
+
+		spin_lock_irqsave(&sighand->siglock, *flags);
+		if (likely(sighand == tsk->sighand))
+			break;
+		spin_unlock_irqrestore(&sighand->siglock, *flags);
+	}
+
+	return sighand;
+}
+
 int group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 {
 	unsigned long flags;
-	struct sighand_struct *sp;
 	int ret;
 
-retry:
 	ret = check_kill_permission(sig, info, p);
-	if (!ret && sig && (sp = rcu_dereference(p->sighand))) {
-		spin_lock_irqsave(&sp->siglock, flags);
-		if (p->sighand != sp) {
-			spin_unlock_irqrestore(&sp->siglock, flags);
-			goto retry;
-		}
-		if ((atomic_read(&sp->count) == 0) ||
-				(atomic_read(&p->usage) == 0)) {
-			spin_unlock_irqrestore(&sp->siglock, flags);
-			return -ESRCH;
+
+	if (!ret && sig) {
+		ret = -ESRCH;
+		if (lock_task_sighand(p, &flags)) {
+			ret = __group_send_sig_info(sig, info, p);
+			unlock_task_sighand(p, &flags);
 		}
-		ret = __group_send_sig_info(sig, info, p);
-		spin_unlock_irqrestore(&sp->siglock, flags);
 	}
 
 	return ret;

commit aa1757f90bea3f598b6e5d04d922a6a60200f1da
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:11:12 2006 -0800

    [PATCH] convert sighand_cache to use SLAB_DESTROY_BY_RCU
    
    This patch borrows a clever Hugh's 'struct anon_vma' trick.
    
    Without tasklist_lock held we can't trust task->sighand until we locked it
    and re-checked that it is still the same.
    
    But this means we don't need to defer 'kmem_cache_free(sighand)'.  We can
    return the memory to slab immediately, all we need is to be sure that
    sighand->siglock can't dissapear inside rcu protected section.
    
    To do so we need to initialize ->siglock inside ctor function,
    SLAB_DESTROY_BY_RCU does the rest.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index dc8f91bf9f89..b0b1ca9daa33 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -330,7 +330,7 @@ void __exit_sighand(struct task_struct *tsk)
 	/* Ok, we're done with the signal handlers */
 	tsk->sighand = NULL;
 	if (atomic_dec_and_test(&sighand->count))
-		sighand_free(sighand);
+		kmem_cache_free(sighand_cachep, sighand);
 }
 
 void exit_sighand(struct task_struct *tsk)

commit fef23e7fbb11a0a78cd61935f7056bc2b237995a
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Mar 28 16:10:58 2006 -0800

    [PATCH] exec: allow init to exec from any thread.
    
    After looking at the problem of init calling exec some more I figured out
    an easy way to make the code work.
    
    The actual symptom without out this patch is that all threads will die
    except pid == 1, and the thread calling exec.  The thread calling exec will
    wait forever for pid == 1 to die.
    
    Since pid == 1 does not install a handler for SIGKILL it will never die.
    
    This modifies the tests for init from current->pid == 1 to the equivalent
    current == child_reaper.  And then it causes exec in the ugly case to
    modify child_reaper.
    
    The only weird symptom is that you wind up with an init process that
    doesn't have the oldest start time on the box.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 75f7341b0c39..dc8f91bf9f89 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1990,7 +1990,7 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 			continue;
 
 		/* Init gets no signals it doesn't want.  */
-		if (current->pid == 1)
+		if (current == child_reaper)
 			continue;
 
 		if (sig_kernel_stop(signr)) {

commit a26fd335b481e0bd14f4e7d1f5e7bb1138b1731f
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Thu Mar 23 03:00:49 2006 -0800

    [PATCH] sigprocmask: kill unneeded temp var
    
    Cleanup, remove unneeded double copying of current->blocked.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index dfb09ba5c013..75f7341b0c39 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2101,10 +2101,11 @@ long do_no_restart_syscall(struct restart_block *param)
 int sigprocmask(int how, sigset_t *set, sigset_t *oldset)
 {
 	int error;
-	sigset_t old_block;
 
 	spin_lock_irq(&current->sighand->siglock);
-	old_block = current->blocked;
+	if (oldset)
+		*oldset = current->blocked;
+
 	error = 0;
 	switch (how) {
 	case SIG_BLOCK:
@@ -2121,8 +2122,7 @@ int sigprocmask(int how, sigset_t *set, sigset_t *oldset)
 	}
 	recalc_sigpending();
 	spin_unlock_irq(&current->sighand->siglock);
-	if (oldset)
-		*oldset = old_block;
+
 	return error;
 }
 

commit fc558a7496bfab3d29a68953b07a95883fdcfbb1
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Thu Mar 23 03:00:05 2006 -0800

    [PATCH] swsusp: finally solve mysqld problem
    
    This patch from Pavel moves userland freeze signals handling into more logical
    place.  It now hits even with mysqld running.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Signed-off-by: Pavel Machek <pavel@suse.cz>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index ea154104a00b..dfb09ba5c013 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1922,6 +1922,8 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 	sigset_t *mask = &current->blocked;
 	int signr = 0;
 
+	try_to_freeze();
+
 relock:
 	spin_lock_irq(&current->sighand->siglock);
 	for (;;) {
@@ -2307,7 +2309,6 @@ sys_rt_sigtimedwait(const sigset_t __user *uthese,
 
 			timeout = schedule_timeout_interruptible(timeout);
 
-			try_to_freeze();
 			spin_lock_irq(&current->sighand->siglock);
 			sig = dequeue_signal(current, &these, &info);
 			current->blocked = current->real_blocked;

commit 9ac95f2f90e022c16d293d7978faddf7e779a1a9
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Thu Feb 9 22:41:50 2006 +0300

    [PATCH] do_sigaction: cleanup ->sa_mask manipulation
    
    Clear unblockable signals beforehand.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 01a1e7f7acf7..ea154104a00b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2430,7 +2430,7 @@ sys_rt_sigqueueinfo(int pid, int sig, siginfo_t __user *uinfo)
 }
 
 int
-do_sigaction(int sig, const struct k_sigaction *act, struct k_sigaction *oact)
+do_sigaction(int sig, struct k_sigaction *act, struct k_sigaction *oact)
 {
 	struct k_sigaction *k;
 	sigset_t mask;
@@ -2454,6 +2454,8 @@ do_sigaction(int sig, const struct k_sigaction *act, struct k_sigaction *oact)
 		*oact = *k;
 
 	if (act) {
+		sigdelsetmask(&act->sa.sa_mask,
+			      sigmask(SIGKILL) | sigmask(SIGSTOP));
 		/*
 		 * POSIX 3.3.1.3:
 		 *  "Setting a signal action to SIG_IGN for a signal that is
@@ -2479,8 +2481,6 @@ do_sigaction(int sig, const struct k_sigaction *act, struct k_sigaction *oact)
 			read_lock(&tasklist_lock);
 			spin_lock_irq(&t->sighand->siglock);
 			*k = *act;
-			sigdelsetmask(&k->sa.sa_mask,
-				      sigmask(SIGKILL) | sigmask(SIGSTOP));
 			sigemptyset(&mask);
 			sigaddset(&mask, sig);
 			rm_from_queue_full(&mask, &t->signal->shared_pending);
@@ -2495,8 +2495,6 @@ do_sigaction(int sig, const struct k_sigaction *act, struct k_sigaction *oact)
 		}
 
 		*k = *act;
-		sigdelsetmask(&k->sa.sa_mask,
-			      sigmask(SIGKILL) | sigmask(SIGSTOP));
 	}
 
 	spin_unlock_irq(&current->sighand->siglock);

commit c70d3d703ad94727dab2a3664aeee33d71e00715
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Thu Feb 9 22:41:41 2006 +0300

    [PATCH] sys_signal: initialize ->sa_mask
    
    Pointed out by Linus Torvalds.
    
    sys_signal() forgets to initialize ->sa_mask.
    
    ( I suspect arch/ia64/ia32/ia32_signal.c:sys32_signal()
      also needs this fix )
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index b373fc2420da..01a1e7f7acf7 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2702,6 +2702,7 @@ sys_signal(int sig, __sighandler_t handler)
 
 	new_sa.sa.sa_handler = handler;
 	new_sa.sa.sa_flags = SA_ONESHOT | SA_NOMASK;
+	sigemptyset(&new_sa.sa.sa_mask);
 
 	ret = do_sigaction(sig, &new_sa, &old_sa);
 

commit 514a01b880d28a3029d9e35de72ad8d2f95b31d0
Author: Andrew Morton <akpm@osdl.org>
Date:   Fri Feb 3 03:04:41 2006 -0800

    [PATCH] uninline __sigqueue_free()
    
    Five callsites.  I dunno how all this crap got back in there :(
    
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index d3efafd8109a..b373fc2420da 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -283,7 +283,7 @@ static struct sigqueue *__sigqueue_alloc(struct task_struct *t, gfp_t flags,
 	return(q);
 }
 
-static inline void __sigqueue_free(struct sigqueue *q)
+static void __sigqueue_free(struct sigqueue *q)
 {
 	if (q->flags & SIGQUEUE_PREALLOC)
 		return;

commit 150256d8aadb3a337c31efa9e175cbd25bf06b06
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Wed Jan 18 17:43:57 2006 -0800

    [PATCH] Generic sys_rt_sigsuspend()
    
    The TIF_RESTORE_SIGMASK flag allows us to have a generic implementation of
    sys_rt_sigsuspend() instead of duplicating it for each architecture.  This
    provides such an implementation and makes arch/powerpc use it.
    
    It also tidies up the ppc32 sys_sigsuspend() to use TIF_RESTORE_SIGMASK.
    
    Signed-off-by: David Woodhouse <dwmw2@infradead.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5dafbd36d62e..d3efafd8109a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2721,6 +2721,32 @@ sys_pause(void)
 
 #endif
 
+#ifdef __ARCH_WANT_SYS_RT_SIGSUSPEND
+asmlinkage long sys_rt_sigsuspend(sigset_t __user *unewset, size_t sigsetsize)
+{
+	sigset_t newset;
+
+	/* XXX: Don't preclude handling different sized sigset_t's.  */
+	if (sigsetsize != sizeof(sigset_t))
+		return -EINVAL;
+
+	if (copy_from_user(&newset, unewset, sizeof(newset)))
+		return -EFAULT;
+	sigdelsetmask(&newset, sigmask(SIGKILL)|sigmask(SIGSTOP));
+
+	spin_lock_irq(&current->sighand->siglock);
+	current->saved_sigmask = current->blocked;
+	current->blocked = newset;
+	recalc_sigpending();
+	spin_unlock_irq(&current->sighand->siglock);
+
+	current->state = TASK_INTERRUPTIBLE;
+	schedule();
+	set_thread_flag(TIF_RESTORE_SIGMASK);
+	return -ERESTARTNOHAND;
+}
+#endif /* __ARCH_WANT_SYS_RT_SIGSUSPEND */
+
 void __init signals_init(void)
 {
 	sigqueue_cachep =

commit 858119e159384308a5dde67776691a2ebf70df0f
Author: Arjan van de Ven <arjan@infradead.org>
Date:   Sat Jan 14 13:20:43 2006 -0800

    [PATCH] Unlinline a bunch of other functions
    
    Remove the "inline" keyword from a bunch of big functions in the kernel with
    the goal of shrinking it by 30kb to 40kb
    
    Signed-off-by: Arjan van de Ven <arjan@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: Jeff Garzik <jgarzik@pobox.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1da2e74beb97..5dafbd36d62e 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -476,7 +476,7 @@ unblock_all_signals(void)
 	spin_unlock_irqrestore(&current->sighand->siglock, flags);
 }
 
-static inline int collect_signal(int sig, struct sigpending *list, siginfo_t *info)
+static int collect_signal(int sig, struct sigpending *list, siginfo_t *info)
 {
 	struct sigqueue *q, *first = NULL;
 	int still_pending = 0;
@@ -1881,7 +1881,7 @@ do_signal_stop(int signr)
  * We return zero if we still hold the siglock and should look
  * for another signal without checking group_stop_count again.
  */
-static inline int handle_group_stop(void)
+static int handle_group_stop(void)
 {
 	int stop_count;
 

commit c59ede7b78db329949d9cdcd7064e22d357560ef
Author: Randy.Dunlap <rdunlap@xenotime.net>
Date:   Wed Jan 11 12:17:46 2006 -0800

    [PATCH] move capable() to capability.h
    
    - Move capable() from sched.h to capability.h;
    
    - Use <linux/capability.h> where capable() is used
            (in include/, block/, ipc/, kernel/, a few drivers/,
            mm/, security/, & sound/;
            many more drivers/ to go)
    
    Signed-off-by: Randy Dunlap <rdunlap@xenotime.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 08aa5b263f36..1da2e74beb97 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -25,6 +25,7 @@
 #include <linux/posix-timers.h>
 #include <linux/signal.h>
 #include <linux/audit.h>
+#include <linux/capability.h>
 #include <asm/param.h>
 #include <asm/uaccess.h>
 #include <asm/unistd.h>

commit 86174cdcb44c095ffd2e3ca69caa56244cf701d5
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Sun Jan 8 01:03:28 2006 -0800

    [PATCH] remove unneeded sig->curr_target recalculation
    
    This patch removes unneeded sig->curr_target recalculation under 'if
    (atomic_dec_and_test(&sig->count))' in __exit_signal().
    
    When sig->count == 0 the signal can't be sent to this task and
    next_thread(tsk) == tsk anyway.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 114cf9209bcd..08aa5b263f36 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -364,8 +364,6 @@ void __exit_signal(struct task_struct *tsk)
 	posix_cpu_timers_exit(tsk);
 	if (atomic_dec_and_test(&sig->count)) {
 		posix_cpu_timers_exit_group(tsk);
-		if (tsk == sig->curr_target)
-			sig->curr_target = next_thread(tsk);
 		tsk->signal = NULL;
 		__exit_sighand(tsk);
 		spin_unlock(&sighand->siglock);

commit 0811af28ce49fab963e3e6b8abcf8c460f971cd4
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Sun Jan 8 01:03:09 2006 -0800

    [PATCH] kill_proc_info_as_uid: don't use hardcoded constants
    
    Use symbolic names instead of hardcoded constants.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Harald Welte <laforge@gnumonks.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index e20724af9b36..114cf9209bcd 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1220,8 +1220,7 @@ int kill_proc_info_as_uid(int sig, struct siginfo *info, pid_t pid,
 		ret = -ESRCH;
 		goto out_unlock;
 	}
-	if ((!info || ((unsigned long)info != 1 &&
-			(unsigned long)info != 2 && SI_FROMUSER(info)))
+	if ((info == SEND_SIG_NOINFO || (!is_si_special(info) && SI_FROMUSER(info)))
 	    && (euid != p->suid) && (euid != p->uid)
 	    && (uid != p->suid) && (uid != p->uid)) {
 		ret = -EPERM;

commit 71fabd5e4835309b4feca6209122ce56c595c461
Author: George Anzinger <george@mvista.com>
Date:   Sun Jan 8 01:02:48 2006 -0800

    [PATCH] sigaction should clear all signals on SIG_IGN, not just < 32
    
    While rooting aroung in the signal code trying to understand how to fix the
    SIG_IGN ploy (set sig handler to SIG_IGN and flood system with high speed
    repeating timers) I came across what, I think, is a problem in sigaction()
    in that when processing a SIG_IGN request it flushes signals from 1 to
    SIGRTMIN and leaves the rest.  Attempt to fix this.
    
    Signed-off-by: George Anzinger <george@mvista.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Linus Torvalds <torvalds@osdl.org>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9b6fda5e87f1..e20724af9b36 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -620,6 +620,33 @@ void signal_wake_up(struct task_struct *t, int resume)
 		kick_process(t);
 }
 
+/*
+ * Remove signals in mask from the pending set and queue.
+ * Returns 1 if any signals were found.
+ *
+ * All callers must be holding the siglock.
+ *
+ * This version takes a sigset mask and looks at all signals,
+ * not just those in the first mask word.
+ */
+static int rm_from_queue_full(sigset_t *mask, struct sigpending *s)
+{
+	struct sigqueue *q, *n;
+	sigset_t m;
+
+	sigandsets(&m, mask, &s->signal);
+	if (sigisemptyset(&m))
+		return 0;
+
+	signandsets(&s->signal, &s->signal, mask);
+	list_for_each_entry_safe(q, n, &s->list, list) {
+		if (sigismember(mask, q->info.si_signo)) {
+			list_del_init(&q->list);
+			__sigqueue_free(q);
+		}
+	}
+	return 1;
+}
 /*
  * Remove signals in mask from the pending set and queue.
  * Returns 1 if any signals were found.
@@ -2408,6 +2435,7 @@ int
 do_sigaction(int sig, const struct k_sigaction *act, struct k_sigaction *oact)
 {
 	struct k_sigaction *k;
+	sigset_t mask;
 
 	if (!valid_signal(sig) || sig < 1 || (act && sig_kernel_only(sig)))
 		return -EINVAL;
@@ -2455,9 +2483,11 @@ do_sigaction(int sig, const struct k_sigaction *act, struct k_sigaction *oact)
 			*k = *act;
 			sigdelsetmask(&k->sa.sa_mask,
 				      sigmask(SIGKILL) | sigmask(SIGSTOP));
-			rm_from_queue(sigmask(sig), &t->signal->shared_pending);
+			sigemptyset(&mask);
+			sigaddset(&mask, sig);
+			rm_from_queue_full(&mask, &t->signal->shared_pending);
 			do {
-				rm_from_queue(sigmask(sig), &t->pending);
+				rm_from_queue_full(&mask, &t->pending);
 				recalc_sigpending_tsk(t);
 				t = next_thread(t);
 			} while (t != current);

commit 2d89c929078588aa9b9c674ef03ee9aa816b59b8
Author: Paul E. McKenney <paulmck@us.ibm.com>
Date:   Sun Jan 8 01:01:38 2006 -0800

    [PATCH] Simpler signal-exit concurrency handling
    
    Some simplification in checking signal delivery against concurrent exit.
    Instead of using get_task_struct_rcu(), which increments the task_struct
    reference count, check the reference count after acquiring sighand lock.
    
    Signed-off-by: "Paul E. McKenney" <paulmck@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 64737c72dadd..9b6fda5e87f1 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1102,18 +1102,19 @@ int group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 
 retry:
 	ret = check_kill_permission(sig, info, p);
-	if (!ret && sig && (sp = p->sighand)) {
-		if (!get_task_struct_rcu(p))
-			return -ESRCH;
+	if (!ret && sig && (sp = rcu_dereference(p->sighand))) {
 		spin_lock_irqsave(&sp->siglock, flags);
 		if (p->sighand != sp) {
 			spin_unlock_irqrestore(&sp->siglock, flags);
-			put_task_struct(p);
 			goto retry;
 		}
+		if ((atomic_read(&sp->count) == 0) ||
+				(atomic_read(&p->usage) == 0)) {
+			spin_unlock_irqrestore(&sp->siglock, flags);
+			return -ESRCH;
+		}
 		ret = __group_send_sig_info(sig, info, p);
 		spin_unlock_irqrestore(&sp->siglock, flags);
-		put_task_struct(p);
 	}
 
 	return ret;

commit e56d090310d7625ecb43a1eeebd479f04affb48b
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Jan 8 01:01:37 2006 -0800

    [PATCH] RCU signal handling
    
    RCU tasklist_lock and RCU signal handling: send signals RCU-read-locked
    instead of tasklist_lock read-locked.  This is a scalability improvement on
    SMP and a preemption-latency improvement under PREEMPT_RCU.
    
    Signed-off-by: Paul E. McKenney <paulmck@us.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: William Irwin <wli@holomorphy.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index d7611f189ef7..64737c72dadd 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -329,13 +329,20 @@ void __exit_sighand(struct task_struct *tsk)
 	/* Ok, we're done with the signal handlers */
 	tsk->sighand = NULL;
 	if (atomic_dec_and_test(&sighand->count))
-		kmem_cache_free(sighand_cachep, sighand);
+		sighand_free(sighand);
 }
 
 void exit_sighand(struct task_struct *tsk)
 {
 	write_lock_irq(&tasklist_lock);
-	__exit_sighand(tsk);
+	rcu_read_lock();
+	if (tsk->sighand != NULL) {
+		struct sighand_struct *sighand = rcu_dereference(tsk->sighand);
+		spin_lock(&sighand->siglock);
+		__exit_sighand(tsk);
+		spin_unlock(&sighand->siglock);
+	}
+	rcu_read_unlock();
 	write_unlock_irq(&tasklist_lock);
 }
 
@@ -345,12 +352,14 @@ void exit_sighand(struct task_struct *tsk)
 void __exit_signal(struct task_struct *tsk)
 {
 	struct signal_struct * sig = tsk->signal;
-	struct sighand_struct * sighand = tsk->sighand;
+	struct sighand_struct * sighand;
 
 	if (!sig)
 		BUG();
 	if (!atomic_read(&sig->count))
 		BUG();
+	rcu_read_lock();
+	sighand = rcu_dereference(tsk->sighand);
 	spin_lock(&sighand->siglock);
 	posix_cpu_timers_exit(tsk);
 	if (atomic_dec_and_test(&sig->count)) {
@@ -358,6 +367,7 @@ void __exit_signal(struct task_struct *tsk)
 		if (tsk == sig->curr_target)
 			sig->curr_target = next_thread(tsk);
 		tsk->signal = NULL;
+		__exit_sighand(tsk);
 		spin_unlock(&sighand->siglock);
 		flush_sigqueue(&sig->shared_pending);
 	} else {
@@ -389,9 +399,11 @@ void __exit_signal(struct task_struct *tsk)
 		sig->nvcsw += tsk->nvcsw;
 		sig->nivcsw += tsk->nivcsw;
 		sig->sched_time += tsk->sched_time;
+		__exit_sighand(tsk);
 		spin_unlock(&sighand->siglock);
 		sig = NULL;	/* Marker for below.  */
 	}
+	rcu_read_unlock();
 	clear_tsk_thread_flag(tsk,TIF_SIGPENDING);
 	flush_sigqueue(&tsk->pending);
 	if (sig) {
@@ -1080,18 +1092,28 @@ void zap_other_threads(struct task_struct *p)
 }
 
 /*
- * Must be called with the tasklist_lock held for reading!
+ * Must be called under rcu_read_lock() or with tasklist_lock read-held.
  */
 int group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 {
 	unsigned long flags;
+	struct sighand_struct *sp;
 	int ret;
 
+retry:
 	ret = check_kill_permission(sig, info, p);
-	if (!ret && sig && p->sighand) {
-		spin_lock_irqsave(&p->sighand->siglock, flags);
+	if (!ret && sig && (sp = p->sighand)) {
+		if (!get_task_struct_rcu(p))
+			return -ESRCH;
+		spin_lock_irqsave(&sp->siglock, flags);
+		if (p->sighand != sp) {
+			spin_unlock_irqrestore(&sp->siglock, flags);
+			put_task_struct(p);
+			goto retry;
+		}
 		ret = __group_send_sig_info(sig, info, p);
-		spin_unlock_irqrestore(&p->sighand->siglock, flags);
+		spin_unlock_irqrestore(&sp->siglock, flags);
+		put_task_struct(p);
 	}
 
 	return ret;
@@ -1136,14 +1158,21 @@ int
 kill_proc_info(int sig, struct siginfo *info, pid_t pid)
 {
 	int error;
+	int acquired_tasklist_lock = 0;
 	struct task_struct *p;
 
-	read_lock(&tasklist_lock);
+	rcu_read_lock();
+	if (unlikely(sig_kernel_stop(sig) || sig == SIGCONT)) {
+		read_lock(&tasklist_lock);
+		acquired_tasklist_lock = 1;
+	}
 	p = find_task_by_pid(pid);
 	error = -ESRCH;
 	if (p)
 		error = group_send_sig_info(sig, info, p);
-	read_unlock(&tasklist_lock);
+	if (unlikely(acquired_tasklist_lock))
+		read_unlock(&tasklist_lock);
+	rcu_read_unlock();
 	return error;
 }
 
@@ -1355,16 +1384,54 @@ send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 {
 	unsigned long flags;
 	int ret = 0;
+	struct sighand_struct *sh;
 
 	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
-	read_lock(&tasklist_lock);
+
+	/*
+	 * The rcu based delayed sighand destroy makes it possible to
+	 * run this without tasklist lock held. The task struct itself
+	 * cannot go away as create_timer did get_task_struct().
+	 *
+	 * We return -1, when the task is marked exiting, so
+	 * posix_timer_event can redirect it to the group leader
+	 */
+	rcu_read_lock();
 
 	if (unlikely(p->flags & PF_EXITING)) {
 		ret = -1;
 		goto out_err;
 	}
 
-	spin_lock_irqsave(&p->sighand->siglock, flags);
+retry:
+	sh = rcu_dereference(p->sighand);
+
+	spin_lock_irqsave(&sh->siglock, flags);
+	if (p->sighand != sh) {
+		/* We raced with exec() in a multithreaded process... */
+		spin_unlock_irqrestore(&sh->siglock, flags);
+		goto retry;
+	}
+
+	/*
+	 * We do the check here again to handle the following scenario:
+	 *
+	 * CPU 0		CPU 1
+	 * send_sigqueue
+	 * check PF_EXITING
+	 * interrupt		exit code running
+	 *			__exit_signal
+	 *			lock sighand->siglock
+	 *			unlock sighand->siglock
+	 * lock sh->siglock
+	 * add(tsk->pending) 	flush_sigqueue(tsk->pending)
+	 *
+	 */
+
+	if (unlikely(p->flags & PF_EXITING)) {
+		ret = -1;
+		goto out;
+	}
 
 	if (unlikely(!list_empty(&q->list))) {
 		/*
@@ -1388,9 +1455,9 @@ send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 		signal_wake_up(p, sig == SIGKILL);
 
 out:
-	spin_unlock_irqrestore(&p->sighand->siglock, flags);
+	spin_unlock_irqrestore(&sh->siglock, flags);
 out_err:
-	read_unlock(&tasklist_lock);
+	rcu_read_unlock();
 
 	return ret;
 }
@@ -1402,7 +1469,9 @@ send_group_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 	int ret = 0;
 
 	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
+
 	read_lock(&tasklist_lock);
+	/* Since it_lock is held, p->sighand cannot be NULL. */
 	spin_lock_irqsave(&p->sighand->siglock, flags);
 	handle_stop_signal(sig, p);
 
@@ -1436,7 +1505,7 @@ send_group_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 out:
 	spin_unlock_irqrestore(&p->sighand->siglock, flags);
 	read_unlock(&tasklist_lock);
-	return(ret);
+	return ret;
 }
 
 /*

commit b17b0421d70f5b85a791afe145a16d5ca5f849aa
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Sun Nov 13 16:07:14 2005 -0800

    [PATCH] signal handling: revert sigkill priority fix
    
    This patch reverts commit c33880aaddbbab1ccf36f4457ed1090621f2e39a since
    it's not needed anymore. As pointed out by Roland McGrath the real fix
    is to deliver all signals before returning to user space.
    See http://www.ussg.iu.edu/hypermail/linux/kernel/0509.2/0683.html
    A fix for s390 has been merged.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Linus Torvalds <torvalds@osdl.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 80789a59b4db..d7611f189ef7 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -513,16 +513,7 @@ static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,
 {
 	int sig = 0;
 
-	/* SIGKILL must have priority, otherwise it is quite easy
-	 * to create an unkillable process, sending sig < SIGKILL
-	 * to self */
-	if (unlikely(sigismember(&pending->signal, SIGKILL))) {
-		if (!sigismember(mask, SIGKILL))
-			sig = SIGKILL;
-	}
-
-	if (likely(!sig))
-		sig = next_signal(pending, mask);
+	sig = next_signal(pending, mask);
 	if (sig) {
 		if (current->notifier) {
 			if (sigismember(current->notifier_mask, sig)) {

commit 7ed0175a462c4c30f6df6fac1cccac058f997739
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Thu Nov 10 17:22:18 2005 +0300

    [PATCH] Don't auto-reap traced children
    
    If a task is being traced we never auto-reap it even if it might look
    like its parent doesn't care. The tracer obviously _does_ care.
    
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1bf3c39d6109..80789a59b4db 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1499,7 +1499,7 @@ void do_notify_parent(struct task_struct *tsk, int sig)
 
 	psig = tsk->parent->sighand;
 	spin_lock_irqsave(&psig->siglock, flags);
-	if (sig == SIGCHLD &&
+	if (!tsk->ptrace && sig == SIGCHLD &&
 	    (psig->action[SIGCHLD-1].sa.sa_handler == SIG_IGN ||
 	     (psig->action[SIGCHLD-1].sa.sa_flags & SA_NOCLDWAIT))) {
 		/*

commit b0423a0d9cc836b2c3d796623cd19236bfedfe63
Author: Paul E. McKenney <paulmck@us.ibm.com>
Date:   Sun Oct 30 15:03:46 2005 -0800

    [PATCH] Remove duplicate code in signal.c
    
    Combine a bit of redundant code between force_sig_info() and
    force_sig_specific().
    
    Signed-off-by: paulmck@us.ibm.com
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1d8f84c5c6ee..1bf3c39d6109 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -879,11 +879,13 @@ force_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 	int ret;
 
 	spin_lock_irqsave(&t->sighand->siglock, flags);
-	if (sigismember(&t->blocked, sig) || t->sighand->action[sig-1].sa.sa_handler == SIG_IGN) {
+	if (t->sighand->action[sig-1].sa.sa_handler == SIG_IGN) {
 		t->sighand->action[sig-1].sa.sa_handler = SIG_DFL;
+	}
+	if (sigismember(&t->blocked, sig)) {
 		sigdelset(&t->blocked, sig);
-		recalc_sigpending_tsk(t);
 	}
+	recalc_sigpending_tsk(t);
 	ret = specific_send_sig_info(sig, info, t);
 	spin_unlock_irqrestore(&t->sighand->siglock, flags);
 
@@ -893,15 +895,7 @@ force_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 void
 force_sig_specific(int sig, struct task_struct *t)
 {
-	unsigned long int flags;
-
-	spin_lock_irqsave(&t->sighand->siglock, flags);
-	if (t->sighand->action[sig-1].sa.sa_handler == SIG_IGN)
-		t->sighand->action[sig-1].sa.sa_handler = SIG_DFL;
-	sigdelset(&t->blocked, sig);
-	recalc_sigpending_tsk(t);
-	specific_send_sig_info(sig, SEND_SIG_FORCED, t);
-	spin_unlock_irqrestore(&t->sighand->siglock, flags);
+	force_sig_info(sig, SEND_SIG_FORCED, t);
 }
 
 /*

commit ae6866c377943de73e2c95398ff0120516f167ce
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Sun Oct 30 15:03:46 2005 -0800

    [PATCH] remove unneeded SI_TIMER checks
    
    This patch removes checks for ->si_code == SI_TIMER from send_signal,
    specific_send_sig_info, __group_send_sig_info.
    
    I think posix-timers.c used these functions some time ago, now it sends
    signals via send_{,group_}sigqueue, so these hooks are unneeded.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 27533b90c347..1d8f84c5c6ee 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -830,12 +830,6 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 		 * and sent by user using something other than kill().
 		 */
 			return -EAGAIN;
-		if (info->si_code == SI_TIMER)
-			/*
-			 * Set up a return to indicate that we dropped 
-			 * the signal.
-			 */
-			ret = info->si_sys_private;
 	}
 
 out_set:
@@ -856,12 +850,6 @@ specific_send_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 		BUG();
 	assert_spin_locked(&t->sighand->siglock);
 
-	if (!is_si_special(info) && (info->si_code == SI_TIMER))
-		/*
-		 * Set up a return to indicate that we dropped the signal.
-		 */
-		ret = info->si_sys_private;
-
 	/* Short-circuit ignored signals.  */
 	if (sig_ignored(t, sig))
 		goto out;
@@ -1048,12 +1036,6 @@ __group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 	assert_spin_locked(&p->sighand->siglock);
 	handle_stop_signal(sig, p);
 
-	if (!is_si_special(info) && (info->si_code == SI_TIMER))
-		/*
-		 * Set up a return to indicate that we dropped the signal.
-		 */
-		ret = info->si_sys_private;
-
 	/* Short-circuit ignored signals.  */
 	if (sig_ignored(p, sig))
 		return ret;

commit 621d31219d9a788bda924a0613048053f3f5f211
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Sun Oct 30 15:03:45 2005 -0800

    [PATCH] cleanup the usage of SEND_SIG_xxx constants
    
    This patch simplifies some checks for magic siginfo values.  It should not
    change the behaviour in any way.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1f7b2aaa4a39..27533b90c347 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -651,9 +651,7 @@ static int check_kill_permission(int sig, struct siginfo *info,
 	if (!valid_signal(sig))
 		return error;
 	error = -EPERM;
-	if ((info == SEND_SIG_NOINFO ||
-			(info != SEND_SIG_PRIV && info != SEND_SIG_FORCED
-				&& SI_FROMUSER(info)))
+	if ((info == SEND_SIG_NOINFO || (!is_si_special(info) && SI_FROMUSER(info)))
 	    && ((sig != SIGCONT) ||
 		(current->signal->session != t->signal->session))
 	    && (current->euid ^ t->suid) && (current->euid ^ t->uid)
@@ -802,7 +800,7 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	   pass on the info struct.  */
 
 	q = __sigqueue_alloc(t, GFP_ATOMIC, (sig < SIGRTMIN &&
-					     (info < SEND_SIG_FORCED ||
+					     (is_si_special(info) ||
 					      info->si_code >= 0)));
 	if (q) {
 		list_add_tail(&q->list, &signals->list);
@@ -825,16 +823,14 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			copy_siginfo(&q->info, info);
 			break;
 		}
-	} else {
-		if (sig >= SIGRTMIN
-		   && info != SEND_SIG_NOINFO && info != SEND_SIG_PRIV
-		   && info->si_code != SI_USER)
+	} else if (!is_si_special(info)) {
+		if (sig >= SIGRTMIN && info->si_code != SI_USER)
 		/*
 		 * Queue overflow, abort.  We may abort if the signal was rt
 		 * and sent by user using something other than kill().
 		 */
 			return -EAGAIN;
-		if ((info > SEND_SIG_PRIV) && (info->si_code == SI_TIMER))
+		if (info->si_code == SI_TIMER)
 			/*
 			 * Set up a return to indicate that we dropped 
 			 * the signal.
@@ -860,7 +856,7 @@ specific_send_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 		BUG();
 	assert_spin_locked(&t->sighand->siglock);
 
-	if ((info > SEND_SIG_FORCED) && (info->si_code == SI_TIMER))
+	if (!is_si_special(info) && (info->si_code == SI_TIMER))
 		/*
 		 * Set up a return to indicate that we dropped the signal.
 		 */
@@ -1052,7 +1048,7 @@ __group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 	assert_spin_locked(&p->sighand->siglock);
 	handle_stop_signal(sig, p);
 
-	if ((info > SEND_SIG_FORCED) && (info->si_code == SI_TIMER))
+	if (!is_si_special(info) && (info->si_code == SI_TIMER))
 		/*
 		 * Set up a return to indicate that we dropped the signal.
 		 */

commit b67a1b9e4bf878aa5d4b6b44cb5a251a2f425f0d
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Sun Oct 30 15:03:44 2005 -0800

    [PATCH] remove hardcoded SEND_SIG_xxx constants
    
    This patch replaces hardcoded SEND_SIG_xxx constants with
    their symbolic names.
    
    No changes in affected .o files.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 9d1512dcf176..1f7b2aaa4a39 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -651,8 +651,9 @@ static int check_kill_permission(int sig, struct siginfo *info,
 	if (!valid_signal(sig))
 		return error;
 	error = -EPERM;
-	if ((!info || ((unsigned long)info != 1 &&
-			(unsigned long)info != 2 && SI_FROMUSER(info)))
+	if ((info == SEND_SIG_NOINFO ||
+			(info != SEND_SIG_PRIV && info != SEND_SIG_FORCED
+				&& SI_FROMUSER(info)))
 	    && ((sig != SIGCONT) ||
 		(current->signal->session != t->signal->session))
 	    && (current->euid ^ t->suid) && (current->euid ^ t->uid)
@@ -789,7 +790,7 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	 * fast-pathed signals for kernel-internal things like SIGSTOP
 	 * or SIGKILL.
 	 */
-	if ((unsigned long)info == 2)
+	if (info == SEND_SIG_FORCED)
 		goto out_set;
 
 	/* Real-time signals must be queued if sent by sigqueue, or
@@ -801,19 +802,19 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 	   pass on the info struct.  */
 
 	q = __sigqueue_alloc(t, GFP_ATOMIC, (sig < SIGRTMIN &&
-					     ((unsigned long) info < 2 ||
+					     (info < SEND_SIG_FORCED ||
 					      info->si_code >= 0)));
 	if (q) {
 		list_add_tail(&q->list, &signals->list);
 		switch ((unsigned long) info) {
-		case 0:
+		case (unsigned long) SEND_SIG_NOINFO:
 			q->info.si_signo = sig;
 			q->info.si_errno = 0;
 			q->info.si_code = SI_USER;
 			q->info.si_pid = current->pid;
 			q->info.si_uid = current->uid;
 			break;
-		case 1:
+		case (unsigned long) SEND_SIG_PRIV:
 			q->info.si_signo = sig;
 			q->info.si_errno = 0;
 			q->info.si_code = SI_KERNEL;
@@ -825,14 +826,15 @@ static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
 			break;
 		}
 	} else {
-		if (sig >= SIGRTMIN && info && (unsigned long)info != 1
+		if (sig >= SIGRTMIN
+		   && info != SEND_SIG_NOINFO && info != SEND_SIG_PRIV
 		   && info->si_code != SI_USER)
 		/*
 		 * Queue overflow, abort.  We may abort if the signal was rt
 		 * and sent by user using something other than kill().
 		 */
 			return -EAGAIN;
-		if (((unsigned long)info > 1) && (info->si_code == SI_TIMER))
+		if ((info > SEND_SIG_PRIV) && (info->si_code == SI_TIMER))
 			/*
 			 * Set up a return to indicate that we dropped 
 			 * the signal.
@@ -858,7 +860,7 @@ specific_send_sig_info(int sig, struct siginfo *info, struct task_struct *t)
 		BUG();
 	assert_spin_locked(&t->sighand->siglock);
 
-	if (((unsigned long)info > 2) && (info->si_code == SI_TIMER))
+	if ((info > SEND_SIG_FORCED) && (info->si_code == SI_TIMER))
 		/*
 		 * Set up a return to indicate that we dropped the signal.
 		 */
@@ -914,7 +916,7 @@ force_sig_specific(int sig, struct task_struct *t)
 		t->sighand->action[sig-1].sa.sa_handler = SIG_DFL;
 	sigdelset(&t->blocked, sig);
 	recalc_sigpending_tsk(t);
-	specific_send_sig_info(sig, (void *)2, t);
+	specific_send_sig_info(sig, SEND_SIG_FORCED, t);
 	spin_unlock_irqrestore(&t->sighand->siglock, flags);
 }
 
@@ -1050,7 +1052,7 @@ __group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 	assert_spin_locked(&p->sighand->siglock);
 	handle_stop_signal(sig, p);
 
-	if (((unsigned long)info > 2) && (info->si_code == SI_TIMER))
+	if ((info > SEND_SIG_FORCED) && (info->si_code == SI_TIMER))
 		/*
 		 * Set up a return to indicate that we dropped the signal.
 		 */
@@ -1285,10 +1287,13 @@ send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 	return ret;
 }
 
+#define __si_special(priv) \
+	((priv) ? SEND_SIG_PRIV : SEND_SIG_NOINFO)
+
 int
 send_sig(int sig, struct task_struct *p, int priv)
 {
-	return send_sig_info(sig, (void*)(long)(priv != 0), p);
+	return send_sig_info(sig, __si_special(priv), p);
 }
 
 /*
@@ -1308,7 +1313,7 @@ send_group_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 void
 force_sig(int sig, struct task_struct *p)
 {
-	force_sig_info(sig, (void*)1L, p);
+	force_sig_info(sig, SEND_SIG_PRIV, p);
 }
 
 /*
@@ -1333,13 +1338,13 @@ force_sigsegv(int sig, struct task_struct *p)
 int
 kill_pg(pid_t pgrp, int sig, int priv)
 {
-	return kill_pg_info(sig, (void *)(long)(priv != 0), pgrp);
+	return kill_pg_info(sig, __si_special(priv), pgrp);
 }
 
 int
 kill_proc(pid_t pid, int sig, int priv)
 {
-	return kill_proc_info(sig, (void *)(long)(priv != 0), pid);
+	return kill_proc_info(sig, __si_special(priv), pid);
 }
 
 /*

commit 30e0fca6c1d7d26f3f2daa4dd2b12c51dadc778a
Author: Andrea Arcangeli <andrea@suse.de>
Date:   Sun Oct 30 15:02:38 2005 -0800

    [PATCH] ptrace/coredump/exit_group deadlock
    
    I could seldom reproduce a deadlock with a task not killable in T state
    (TASK_STOPPED, not TASK_TRACED) by attaching a NPTL threaded program to
    gdb, by segfaulting the task and triggering a core dump while some other
    task is executing exit_group and while one task is in ptrace_attached
    TASK_STOPPED state (not TASK_TRACED yet).  This originated from a gdb
    bugreport (the fact gdb was segfaulting the task wasn't a kernel bug), but
    I just incidentally noticed the gdb bug triggered a real kernel bug as
    well.
    
    Most threads hangs in exit_mm because the core_dumping is still going, the
    core dumping hangs because the stopped task doesn't exit, the stopped task
    can't wakeup because it has SIGNAL_GROUP_EXIT set, hence the deadlock.
    
    To me it seems that the problem is that the force_sig_specific(SIGKILL) in
    zap_threads is a noop if the task has PF_PTRACED set (like in this case
    because gdb is attached).  The __ptrace_unlink does nothing because the
    signal->flags is set to SIGNAL_GROUP_EXIT|SIGNAL_STOP_DEQUEUED (verified).
    
    The above info also shows that the stopped task hit a race and got the stop
    signal (presumably by the ptrace_attach, only the attach, state is still
    TASK_STOPPED and gdb hangs waiting the core before it can set it to
    TASK_TRACED) after one of the thread invoked the core dump (it's the core
    dump that sets signal->flags to SIGNAL_GROUP_EXIT).
    
    So beside the fact nobody would wakeup the task in __ptrace_unlink (the
    state is _not_ TASK_TRACED), there's a secondary problem in the signal
    handling code, where a task should ignore the ptrace-sigstops as long as
    SIGNAL_GROUP_EXIT is set (or the wakeup in __ptrace_unlink path wouldn't be
    enough).
    
    So I attempted to make this patch that seems to fix the problem.  There
    were various ways to fix it, perhaps you prefer a different one, I just
    opted to the one that looked safer to me.
    
    I also removed the clearing of the stopped bits from the zap_other_threads
    (zap_other_threads was safe unlike zap_threads).  I don't like useless
    code, this whole NPTL signal/ptrace thing is already unreadable enough and
    full of corner cases without confusing useless code into it to make it even
    less readable.  And if this code is really needed, then you may want to
    explain why it's not being done in the other paths that sets
    SIGNAL_GROUP_EXIT at least.
    
    Even after this patch I still wonder who serializes the read of
    p->ptrace in zap_threads.
    
    Patch is called ptrace-core_dump-exit_group-deadlock-1.
    
    This was the trace I've got:
    
    test          T ffff81003e8118c0     0 14305      1         14311 14309 (NOTLB)
    ffff810058ccdde8 0000000000000082 000001f4000037e1 ffff810000000013
           00000000000000f8 ffff81003e811b00 ffff81003e8118c0 ffff810011362100
           0000000000000012 ffff810017ca4180
    Call Trace:<ffffffff801317ed>{try_to_wake_up+893} <ffffffff80141677>{finish_stop+87}
           <ffffffff8014367f>{get_signal_to_deliver+1359} <ffffffff8010d3ad>{do_signal+157}
           <ffffffff8013deee>{ptrace_check_attach+222} <ffffffff80111575>{sys_ptrace+2293}
           <ffffffff80131810>{default_wake_function+0} <ffffffff80196399>{sys_ioctl+73}
           <ffffffff8010dd27>{sysret_signal+28} <ffffffff8010e00f>{ptregscall_common+103}
    
    test          D ffff810011362100     0 14309      1         14305 14312 (NOTLB)
    ffff810053c81cf8 0000000000000082 0000000000000286 0000000000000001
           0000000000000195 ffff810011362340 ffff810011362100 ffff81002e338040
           ffff810001e0ca80 0000000000000001
    Call Trace:<ffffffff801317ed>{try_to_wake_up+893} <ffffffff8044677d>{wait_for_completion+173}
           <ffffffff80131810>{default_wake_function+0} <ffffffff80137435>{exit_mm+149}
           <ffffffff801381af>{do_exit+479} <ffffffff80138d0c>{do_group_exit+252}
           <ffffffff801436db>{get_signal_to_deliver+1451} <ffffffff8010d3ad>{do_signal+157}
           <ffffffff8013deee>{ptrace_check_attach+222} <ffffffff80140850>{specific_send_sig_info+2
    
           <ffffffff8014208a>{force_sig_info+186} <ffffffff804479a0>{do_int3+112}
           <ffffffff8010e308>{retint_signal+61}
    test          D ffff81002e338040     0 14311      1         14716 14305 (NOTLB)
    ffff81005ca8dcf8 0000000000000082 0000000000000286 0000000000000001
           0000000000000120 ffff81002e338280 ffff81002e338040 ffff8100481cb740
           ffff810001e0ca80 0000000000000001
    Call Trace:<ffffffff801317ed>{try_to_wake_up+893} <ffffffff8044677d>{wait_for_completion+173}
           <ffffffff80131810>{default_wake_function+0} <ffffffff80137435>{exit_mm+149}
           <ffffffff801381af>{do_exit+479} <ffffffff80142d0e>{__dequeue_signal+558}
           <ffffffff80138d0c>{do_group_exit+252} <ffffffff801436db>{get_signal_to_deliver+1451}
           <ffffffff8010d3ad>{do_signal+157} <ffffffff8013deee>{ptrace_check_attach+222}
           <ffffffff80140850>{specific_send_sig_info+208} <ffffffff8014208a>{force_sig_info+186}
           <ffffffff804479a0>{do_int3+112} <ffffffff8010e308>{retint_signal+61}
    
    test          D ffff810017ca4180     0 14312      1         14309 13882 (NOTLB)
    ffff81005d15fcb8 0000000000000082 ffff81005d15fc58 ffffffff80130816
           0000000000000897 ffff810017ca43c0 ffff810017ca4180 ffff81003e8118c0
           0000000000000082 ffffffff801317ed
    Call Trace:<ffffffff80130816>{activate_task+150} <ffffffff801317ed>{try_to_wake_up+893}
           <ffffffff8044677d>{wait_for_completion+173} <ffffffff80131810>{default_wake_function+0}
           <ffffffff8018cdc3>{do_coredump+819} <ffffffff80445f52>{thread_return+82}
           <ffffffff801436d4>{get_signal_to_deliver+1444} <ffffffff8010d3ad>{do_signal+157}
           <ffffffff8013deee>{ptrace_check_attach+222} <ffffffff80140850>{specific_send_sig_info+2
    
           <ffffffff804472e5>{_spin_unlock_irqrestore+5} <ffffffff8014208a>{force_sig_info+186}
           <ffffffff804476ff>{do_general_protection+159} <ffffffff8010e308>{retint_signal+61}
    
    Signed-off-by: Andrea Arcangeli <andrea@suse.de>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Linus Torvalds <torvalds@osdl.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 1d905ec74bde..9d1512dcf176 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1108,8 +1108,8 @@ void zap_other_threads(struct task_struct *p)
 		if (t != p->group_leader)
 			t->exit_signal = -1;
 
+		/* SIGKILL will be handled before any pending SIGSTOP */
 		sigaddset(&t->pending.signal, SIGKILL);
-		rm_from_queue(SIG_KERNEL_STOP_MASK, &t->pending);
 		signal_wake_up(t, 1);
 	}
 }
@@ -1879,9 +1879,9 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 			/* Let the debugger run.  */
 			ptrace_stop(signr, signr, info);
 
-			/* We're back.  Did the debugger cancel the sig?  */
+			/* We're back.  Did the debugger cancel the sig or group_exit? */
 			signr = current->exit_code;
-			if (signr == 0)
+			if (signr == 0 || current->signal->flags & SIGNAL_GROUP_EXIT)
 				continue;
 
 			current->exit_code = 0;

commit 6dd69f1061bfdeca230509b173438e0731bff767
Author: Vadim Lobanov <vlobanov@speakeasy.net>
Date:   Sun Oct 30 15:02:18 2005 -0800

    [PATCH] Unify sys_tkill() and sys_tgkill()
    
    The majority of the sys_tkill() and sys_tgkill() function code is
    duplicated between the two of them.  This patch pulls the duplication out
    into a separate function -- do_tkill() -- and lets sys_tkill() and
    sys_tgkill() be simple wrappers around it.  This should make it easier to
    maintain in light of future changes.
    
    Signed-off-by: Vadim Lobanov <vlobanov@speakeasy.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8d6e64dfa5c6..1d905ec74bde 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2283,26 +2283,13 @@ sys_kill(int pid, int sig)
 	return kill_something_info(sig, &info, pid);
 }
 
-/**
- *  sys_tgkill - send signal to one specific thread
- *  @tgid: the thread group ID of the thread
- *  @pid: the PID of the thread
- *  @sig: signal to be sent
- *
- *  This syscall also checks the tgid and returns -ESRCH even if the PID
- *  exists but it's not belonging to the target process anymore. This
- *  method solves the problem of threads exiting and PIDs getting reused.
- */
-asmlinkage long sys_tgkill(int tgid, int pid, int sig)
+static int do_tkill(int tgid, int pid, int sig)
 {
-	struct siginfo info;
 	int error;
+	struct siginfo info;
 	struct task_struct *p;
 
-	/* This is only valid for single tasks */
-	if (pid <= 0 || tgid <= 0)
-		return -EINVAL;
-
+	error = -ESRCH;
 	info.si_signo = sig;
 	info.si_errno = 0;
 	info.si_code = SI_TKILL;
@@ -2311,8 +2298,7 @@ asmlinkage long sys_tgkill(int tgid, int pid, int sig)
 
 	read_lock(&tasklist_lock);
 	p = find_task_by_pid(pid);
-	error = -ESRCH;
-	if (p && (p->tgid == tgid)) {
+	if (p && (tgid <= 0 || p->tgid == tgid)) {
 		error = check_kill_permission(sig, &info, p);
 		/*
 		 * The null signal is a permissions and process existence
@@ -2326,47 +2312,40 @@ asmlinkage long sys_tgkill(int tgid, int pid, int sig)
 		}
 	}
 	read_unlock(&tasklist_lock);
+
 	return error;
 }
 
+/**
+ *  sys_tgkill - send signal to one specific thread
+ *  @tgid: the thread group ID of the thread
+ *  @pid: the PID of the thread
+ *  @sig: signal to be sent
+ *
+ *  This syscall also checks the tgid and returns -ESRCH even if the PID
+ *  exists but it's not belonging to the target process anymore. This
+ *  method solves the problem of threads exiting and PIDs getting reused.
+ */
+asmlinkage long sys_tgkill(int tgid, int pid, int sig)
+{
+	/* This is only valid for single tasks */
+	if (pid <= 0 || tgid <= 0)
+		return -EINVAL;
+
+	return do_tkill(tgid, pid, sig);
+}
+
 /*
  *  Send a signal to only one task, even if it's a CLONE_THREAD task.
  */
 asmlinkage long
 sys_tkill(int pid, int sig)
 {
-	struct siginfo info;
-	int error;
-	struct task_struct *p;
-
 	/* This is only valid for single tasks */
 	if (pid <= 0)
 		return -EINVAL;
 
-	info.si_signo = sig;
-	info.si_errno = 0;
-	info.si_code = SI_TKILL;
-	info.si_pid = current->tgid;
-	info.si_uid = current->uid;
-
-	read_lock(&tasklist_lock);
-	p = find_task_by_pid(pid);
-	error = -ESRCH;
-	if (p) {
-		error = check_kill_permission(sig, &info, p);
-		/*
-		 * The null signal is a permissions and process existence
-		 * probe.  No signal is actually delivered.
-		 */
-		if (!error && sig && p->sighand) {
-			spin_lock_irq(&p->sighand->siglock);
-			handle_stop_signal(sig, p);
-			error = specific_send_sig_info(sig, &info, p);
-			spin_unlock_irq(&p->sighand->siglock);
-		}
-	}
-	read_unlock(&tasklist_lock);
-	return error;
+	return do_tkill(0, pid, sig);
 }
 
 asmlinkage long

commit 19a4fcb531659f2f7d18b5d04cee039176e9540d
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Sun Oct 30 15:02:17 2005 -0800

    [PATCH] kill sigqueue->lock
    
    This lock is used in sigqueue_free(), but it is always equal to
    current->sighand->siglock, so we don't need to keep it in the struct
    sigqueue.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 6904bbbfe116..8d6e64dfa5c6 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -277,7 +277,6 @@ static struct sigqueue *__sigqueue_alloc(struct task_struct *t, gfp_t flags,
 	} else {
 		INIT_LIST_HEAD(&q->list);
 		q->flags = 0;
-		q->lock = NULL;
 		q->user = get_uid(t->user);
 	}
 	return(q);
@@ -1371,11 +1370,12 @@ void sigqueue_free(struct sigqueue *q)
 	 * pending queue.
 	 */
 	if (unlikely(!list_empty(&q->list))) {
-		read_lock(&tasklist_lock);  
-		spin_lock_irqsave(q->lock, flags);
+		spinlock_t *lock = &current->sighand->siglock;
+		read_lock(&tasklist_lock);
+		spin_lock_irqsave(lock, flags);
 		if (!list_empty(&q->list))
 			list_del_init(&q->list);
-		spin_unlock_irqrestore(q->lock, flags);
+		spin_unlock_irqrestore(lock, flags);
 		read_unlock(&tasklist_lock);
 	}
 	q->flags &= ~SIGQUEUE_PREALLOC;
@@ -1414,7 +1414,6 @@ send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 		goto out;
 	}
 
-	q->lock = &p->sighand->siglock;
 	list_add_tail(&q->list, &p->pending.list);
 	sigaddset(&p->pending.signal, sig);
 	if (!sigismember(&p->blocked, sig))
@@ -1462,7 +1461,6 @@ send_group_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 	 * We always use the shared queue for process-wide signals,
 	 * to avoid several races.
 	 */
-	q->lock = &p->sighand->siglock;
 	list_add_tail(&q->list, &p->signal->shared_pending.list);
 	sigaddset(&p->signal->shared_pending.signal, sig);
 

commit 8d027de54c77d38eedc9b331c7a2a39807d34691
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Sat Oct 29 19:37:40 2005 +0400

    [PATCH] fix ->signal->live leak in copy_process()
    
    exit_signal() (called from copy_process's error path) should decrement
    ->signal->live, otherwise forking process will miss 'group_dead' in
    do_exit().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index f2b96b08fb44..6904bbbfe116 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -406,6 +406,8 @@ void __exit_signal(struct task_struct *tsk)
 
 void exit_signal(struct task_struct *tsk)
 {
+	atomic_dec(&tsk->signal->live);
+
 	write_lock_irq(&tasklist_lock);
 	__exit_signal(tsk);
 	write_unlock_irq(&tasklist_lock);

commit 25f407f0b668f5e4ebd5d13e1fb4306ba6427ead
Author: Roland McGrath <roland@redhat.com>
Date:   Fri Oct 21 15:03:29 2005 -0700

    [PATCH] Call exit_itimers from do_exit, not __exit_signal
    
    When I originally moved exit_itimers into __exit_signal, that was the only
    place where we could reliably know it was the last thread in the group
    dying, without races.  Since then we've gotten the signal_struct.live
    counter, and do_exit can reliably do group-wide cleanup work.
    
    This patch moves the call to do_exit, where it's made without locks.  This
    avoids the deadlock issues that the old __exit_signal code's comment talks
    about, and the one that Oleg found recently with process CPU timers.
    
    [ This replaces e03d13e985d48ac4885382c9e3b1510c78bd047f, which is why
      it was just reverted. ]
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 50c992643771..f2b96b08fb44 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -397,20 +397,8 @@ void __exit_signal(struct task_struct *tsk)
 	flush_sigqueue(&tsk->pending);
 	if (sig) {
 		/*
-		 * We are cleaning up the signal_struct here.  We delayed
-		 * calling exit_itimers until after flush_sigqueue, just in
-		 * case our thread-local pending queue contained a queued
-		 * timer signal that would have been cleared in
-		 * exit_itimers.  When that called sigqueue_free, it would
-		 * attempt to re-take the tasklist_lock and deadlock.  This
-		 * can never happen if we ensure that all queues the
-		 * timer's signal might be queued on have been flushed
-		 * first.  The shared_pending queue, and our own pending
-		 * queue are the only queues the timer could be on, since
-		 * there are no other threads left in the group and timer
-		 * signals are constrained to threads inside the group.
+		 * We are cleaning up the signal_struct here.
 		 */
-		exit_itimers(sig);
 		exit_thread_group_keys(sig);
 		kmem_cache_free(signal_cachep, sig);
 	}

commit 46113830a18847cff8da73005e57bc49c2f95a56
Author: Harald Welte <laforge@gnumonks.org>
Date:   Mon Oct 10 19:44:29 2005 +0200

    [PATCH] Fix signal sending in usbdevio on async URB completion
    
    If a process issues an URB from userspace and (starts to) terminate
    before the URB comes back, we run into the issue described above.  This
    is because the urb saves a pointer to "current" when it is posted to the
    device, but there's no guarantee that this pointer is still valid
    afterwards.
    
    In fact, there are three separate issues:
    
    1) the pointer to "current" can become invalid, since the task could be
       completely gone when the URB completion comes back from the device.
    
    2) Even if the saved task pointer is still pointing to a valid task_struct,
       task_struct->sighand could have gone meanwhile.
    
    3) Even if the process is perfectly fine, permissions may have changed,
       and we can no longer send it a signal.
    
    So what we do instead, is to save the PID and uid's of the process, and
    introduce a new kill_proc_info_as_uid() function.
    
    Signed-off-by: Harald Welte <laforge@gnumonks.org>
    [ Fixed up types and added symbol exports ]
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index cba193ceda0d..50c992643771 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1193,6 +1193,40 @@ kill_proc_info(int sig, struct siginfo *info, pid_t pid)
 	return error;
 }
 
+/* like kill_proc_info(), but doesn't use uid/euid of "current" */
+int kill_proc_info_as_uid(int sig, struct siginfo *info, pid_t pid,
+		      uid_t uid, uid_t euid)
+{
+	int ret = -EINVAL;
+	struct task_struct *p;
+
+	if (!valid_signal(sig))
+		return ret;
+
+	read_lock(&tasklist_lock);
+	p = find_task_by_pid(pid);
+	if (!p) {
+		ret = -ESRCH;
+		goto out_unlock;
+	}
+	if ((!info || ((unsigned long)info != 1 &&
+			(unsigned long)info != 2 && SI_FROMUSER(info)))
+	    && (euid != p->suid) && (euid != p->uid)
+	    && (uid != p->suid) && (uid != p->uid)) {
+		ret = -EPERM;
+		goto out_unlock;
+	}
+	if (sig && p->sighand) {
+		unsigned long flags;
+		spin_lock_irqsave(&p->sighand->siglock, flags);
+		ret = __group_send_sig_info(sig, info, p);
+		spin_unlock_irqrestore(&p->sighand->siglock, flags);
+	}
+out_unlock:
+	read_unlock(&tasklist_lock);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(kill_proc_info_as_uid);
 
 /*
  * kill_something_info() interprets pid in interesting ways just like kill(2).

commit dd0fc66fb33cd610bc1a5db8a5e232d34879b4d7
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Fri Oct 7 07:46:04 2005 +0100

    [PATCH] gfp flags annotations - part 1
    
     - added typedef unsigned int __nocast gfp_t;
    
     - replaced __nocast uses for gfp flags with gfp_t - it gives exactly
       the same warnings as far as sparse is concerned, doesn't change
       generated code (from gcc point of view we replaced unsigned int with
       typedef) and documents what's going on far better.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index c135f5aa2c2d..cba193ceda0d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -262,7 +262,7 @@ next_signal(struct sigpending *pending, sigset_t *mask)
 	return sig;
 }
 
-static struct sigqueue *__sigqueue_alloc(struct task_struct *t, unsigned int __nocast flags,
+static struct sigqueue *__sigqueue_alloc(struct task_struct *t, gfp_t flags,
 					 int override_rlimit)
 {
 	struct sigqueue *q = NULL;

commit 788e05a67c343fa22f2ae1d3ca264e7f15c25eaf
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Fri Oct 7 17:46:19 2005 +0400

    [PATCH] fix do_coredump() vs SIGSTOP race
    
    Let's suppose we have 2 threads in thread group:
            A - does coredump
            B - has pending SIGSTOP
    
    thread A                                                thread B
    
    do_coredump:                                            get_signal_to_deliver:
    
      lock(->sighand)
      ->signal->flags = SIGNAL_GROUP_EXIT
      unlock(->sighand)
    
                                                            lock(->sighand)
                                                            signr = dequeue_signal()
                                                                    ->signal->flags |= SIGNAL_STOP_DEQUEUED
                                                                    return SIGSTOP;
    
                                                            do_signal_stop:
                                                                unlock(->sighand)
    
      coredump_wait:
    
          zap_threads:
              lock(tasklist_lock)
              send SIGKILL to B
                  // signal_wake_up() does nothing
              unlock(tasklist_lock)
    
                                                                lock(tasklist_lock)
                                                                lock(->sighand)
                                                                re-check sig->flags & SIGNAL_STOP_DEQUEUED, yes
                                                                set_current_state(TASK_STOPPED);
                                                                finish_stop:
                                                                    schedule();
                                                                        // ->state == TASK_STOPPED
    
          wait_for_completion(&startup_done)
             // waits for complete() from B,
             // ->state == TASK_UNINTERRUPTIBLE
    
    We can't wake up 'B' in any way:
    
            SIGCONT will be ignored because handle_stop_signal() sees
            ->signal->flags & SIGNAL_GROUP_EXIT.
    
            sys_kill(SIGKILL)->__group_complete_signal() will choose
            uninterruptible 'A', so it can't help.
    
            sys_tkill(B, SIGKILL) will be ignored by specific_send_sig_info()
            because B already has pending SIGKILL.
    
    This scenario is not possbile if 'A' does do_group_exit(), because
    it sets sig->flags = SIGNAL_GROUP_EXIT and delivers SIGKILL to
    subthreads atomically, holding both tasklist_lock and sighand->lock.
    That means that do_signal_stop() will notice !SIGNAL_STOP_DEQUEUED
    after re-locking ->sighand. And it is not possible to any other
    thread to re-add SIGNAL_STOP_DEQUEUED later, because dequeue_signal()
    can only return SIGKILL.
    
    I think it is better to change do_coredump() to do sigaddset(SIGKILL)
    and signal_wake_up() under sighand->lock, but this patch is much
    simpler.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 619b027e92b5..c135f5aa2c2d 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -578,7 +578,8 @@ int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
  		 * is to alert stop-signal processing code when another
  		 * processor has come along and cleared the flag.
  		 */
- 		tsk->signal->flags |= SIGNAL_STOP_DEQUEUED;
+ 		if (!(tsk->signal->flags & SIGNAL_GROUP_EXIT))
+ 			tsk->signal->flags |= SIGNAL_STOP_DEQUEUED;
  	}
 	if ( signr &&
 	     ((info->si_code & __SI_MASK) == __SI_TIMER) &&

commit 5acbc5cb507e6c381b70093b1081854708e82b16
Author: Roland McGrath <roland@redhat.com>
Date:   Thu Sep 29 14:54:42 2005 -0700

    [PATCH] Fix task state testing properly in do_signal_stop()
    
    Any tests using < TASK_STOPPED or the like are left over from the time
    when the TASK_ZOMBIE and TASK_DEAD bits were in the same word, and it
    served to check for "stopped or dead".  I think this one in
    do_signal_stop is the only such case.  It has been buggy ever since
    exit_state was separated, and isn't testing the exit_state value.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 5a274705ba19..619b027e92b5 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1763,7 +1763,8 @@ do_signal_stop(int signr)
 				 * stop is always done with the siglock held,
 				 * so this check has no races.
 				 */
-				if (t->state < TASK_STOPPED) {
+				if (!t->exit_state &&
+				    !(t->state & (TASK_STOPPED|TASK_TRACED))) {
 					stop_count++;
 					signal_wake_up(t, 0);
 				}

commit 188a1eafa03aaa5e5fe6f53e637e704cd2c31c7c
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Fri Sep 23 13:22:21 2005 -0700

    Make sure SIGKILL gets proper respect
    
    Bhavesh P. Davda <bhavesh@avaya.com> noticed that SIGKILL wouldn't
    properly kill a process under just the right cicumstances: a stopped
    task that already had another signal queued would get the SIGKILL
    queued onto the shared queue, and there it would remain until SIGCONT.
    
    This simplifies the signal acceptance logic, and fixes the bug in the
    process.
    
    Losely based on an earlier patch by Bhavesh.
    
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index b92c3c9f8b9a..5a274705ba19 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -936,34 +936,31 @@ force_sig_specific(int sig, struct task_struct *t)
  * as soon as they're available, so putting the signal on the shared queue
  * will be equivalent to sending it to one such thread.
  */
-#define wants_signal(sig, p, mask) 			\
-	(!sigismember(&(p)->blocked, sig)		\
-	 && !((p)->state & mask)			\
-	 && !((p)->flags & PF_EXITING)			\
-	 && (task_curr(p) || !signal_pending(p)))
-
+static inline int wants_signal(int sig, struct task_struct *p)
+{
+	if (sigismember(&p->blocked, sig))
+		return 0;
+	if (p->flags & PF_EXITING)
+		return 0;
+	if (sig == SIGKILL)
+		return 1;
+	if (p->state & (TASK_STOPPED | TASK_TRACED))
+		return 0;
+	return task_curr(p) || !signal_pending(p);
+}
 
 static void
 __group_complete_signal(int sig, struct task_struct *p)
 {
-	unsigned int mask;
 	struct task_struct *t;
 
-	/*
-	 * Don't bother traced and stopped tasks (but
-	 * SIGKILL will punch through that).
-	 */
-	mask = TASK_STOPPED | TASK_TRACED;
-	if (sig == SIGKILL)
-		mask = 0;
-
 	/*
 	 * Now find a thread we can wake up to take the signal off the queue.
 	 *
 	 * If the main thread wants the signal, it gets first crack.
 	 * Probably the least surprising to the average bear.
 	 */
-	if (wants_signal(sig, p, mask))
+	if (wants_signal(sig, p))
 		t = p;
 	else if (thread_group_empty(p))
 		/*
@@ -981,7 +978,7 @@ __group_complete_signal(int sig, struct task_struct *p)
 			t = p->signal->curr_target = p;
 		BUG_ON(t->tgid != p->tgid);
 
-		while (!wants_signal(sig, t, mask)) {
+		while (!wants_signal(sig, t)) {
 			t = next_thread(t);
 			if (t == p->signal->curr_target)
 				/*

commit 75bcc8c5e1de78616b04ef9f317a293a7c1c163c
Author: Nishanth Aravamudan <nacc@us.ibm.com>
Date:   Sat Sep 10 00:27:24 2005 -0700

    [PATCH] kernel: fix-up schedule_timeout() usage
    
    Use schedule_timeout_{,un}interruptible() instead of
    set_current_state()/schedule_timeout() to reduce kernel size.
    
    Signed-off-by: Nishanth Aravamudan <nacc@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 4980a073237f..b92c3c9f8b9a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -2221,8 +2221,7 @@ sys_rt_sigtimedwait(const sigset_t __user *uthese,
 			recalc_sigpending();
 			spin_unlock_irq(&current->sighand->siglock);
 
-			current->state = TASK_INTERRUPTIBLE;
-			timeout = schedule_timeout(timeout);
+			timeout = schedule_timeout_interruptible(timeout);
 
 			try_to_freeze();
 			spin_lock_irq(&current->sighand->siglock);

commit e752dd6cc66a3e6a11396928998baf390cc00420
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Sep 6 15:17:42 2005 -0700

    [PATCH] fix send_sigqueue() vs thread exit race
    
    posix_timer_event() first checks that the thread (SIGEV_THREAD_ID case)
    does not have PF_EXITING flag, then it calls send_sigqueue() which locks
    task list.  But if the thread exits in between the kernel will oops
    (->sighand == NULL after __exit_sighand).
    
    This patch moves the PF_EXITING check into the send_sigqueue(), it must be
    done atomically under tasklist_lock.  When send_sigqueue() detects exiting
    thread it returns -1.  In that case posix_timer_event will send the signal
    to thread group.
    
    Also, this patch fixes task_struct use-after-free in posix_timer_event.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 56e33df2b67f..4980a073237f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1366,16 +1366,16 @@ send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 	unsigned long flags;
 	int ret = 0;
 
-	/*
-	 * We need the tasklist lock even for the specific
-	 * thread case (when we don't need to follow the group
-	 * lists) in order to avoid races with "p->sighand"
-	 * going away or changing from under us.
-	 */
 	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
-	read_lock(&tasklist_lock);  
+	read_lock(&tasklist_lock);
+
+	if (unlikely(p->flags & PF_EXITING)) {
+		ret = -1;
+		goto out_err;
+	}
+
 	spin_lock_irqsave(&p->sighand->siglock, flags);
-	
+
 	if (unlikely(!list_empty(&q->list))) {
 		/*
 		 * If an SI_TIMER entry is already queue just increment
@@ -1385,7 +1385,7 @@ send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 			BUG();
 		q->info.si_overrun++;
 		goto out;
-	} 
+	}
 	/* Short-circuit ignored signals.  */
 	if (sig_ignored(p, sig)) {
 		ret = 1;
@@ -1400,8 +1400,10 @@ send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
 
 out:
 	spin_unlock_irqrestore(&p->sighand->siglock, flags);
+out_err:
 	read_unlock(&tasklist_lock);
-	return(ret);
+
+	return ret;
 }
 
 int

commit bc505a478d3fffcfb269b72f64df4510305cfe81
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Sep 6 15:17:32 2005 -0700

    [PATCH] do_notify_parent_cldstop() cleanup
    
    This patch simplifies the usage of do_notify_parent_cldstop(), it lessens
    the source and .text size slightly, and makes the code (in my opinion) a
    bit more readable.
    
    I am sending this patch now because I'm afraid Paul will touch
    do_notify_parent_cldstop() really soon, It's better to cleanup first.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index d282fea81138..56e33df2b67f 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -678,7 +678,7 @@ static int check_kill_permission(int sig, struct siginfo *info,
 
 /* forward decl */
 static void do_notify_parent_cldstop(struct task_struct *tsk,
-				     struct task_struct *parent,
+				     int to_self,
 				     int why);
 
 /*
@@ -729,14 +729,7 @@ static void handle_stop_signal(int sig, struct task_struct *p)
 			p->signal->group_stop_count = 0;
 			p->signal->flags = SIGNAL_STOP_CONTINUED;
 			spin_unlock(&p->sighand->siglock);
-			if (p->ptrace & PT_PTRACED)
-				do_notify_parent_cldstop(p, p->parent,
-							 CLD_STOPPED);
-			else
-				do_notify_parent_cldstop(
-					p->group_leader,
-					p->group_leader->real_parent,
-							 CLD_STOPPED);
+			do_notify_parent_cldstop(p, (p->ptrace & PT_PTRACED), CLD_STOPPED);
 			spin_lock(&p->sighand->siglock);
 		}
 		rm_from_queue(SIG_KERNEL_STOP_MASK, &p->signal->shared_pending);
@@ -777,14 +770,7 @@ static void handle_stop_signal(int sig, struct task_struct *p)
 			p->signal->flags = SIGNAL_STOP_CONTINUED;
 			p->signal->group_exit_code = 0;
 			spin_unlock(&p->sighand->siglock);
-			if (p->ptrace & PT_PTRACED)
-				do_notify_parent_cldstop(p, p->parent,
-							 CLD_CONTINUED);
-			else
-				do_notify_parent_cldstop(
-					p->group_leader,
-					p->group_leader->real_parent,
-							 CLD_CONTINUED);
+			do_notify_parent_cldstop(p, (p->ptrace & PT_PTRACED), CLD_CONTINUED);
 			spin_lock(&p->sighand->siglock);
 		} else {
 			/*
@@ -1542,14 +1528,20 @@ void do_notify_parent(struct task_struct *tsk, int sig)
 	spin_unlock_irqrestore(&psig->siglock, flags);
 }
 
-static void
-do_notify_parent_cldstop(struct task_struct *tsk, struct task_struct *parent,
-			 int why)
+static void do_notify_parent_cldstop(struct task_struct *tsk, int to_self, int why)
 {
 	struct siginfo info;
 	unsigned long flags;
+	struct task_struct *parent;
 	struct sighand_struct *sighand;
 
+	if (to_self)
+		parent = tsk->parent;
+	else {
+		tsk = tsk->group_leader;
+		parent = tsk->real_parent;
+	}
+
 	info.si_signo = SIGCHLD;
 	info.si_errno = 0;
 	info.si_pid = tsk->pid;
@@ -1618,8 +1610,7 @@ static void ptrace_stop(int exit_code, int nostop_code, siginfo_t *info)
 		   !(current->ptrace & PT_ATTACHED)) &&
 	    (likely(current->parent->signal != current->signal) ||
 	     !unlikely(current->signal->flags & SIGNAL_GROUP_EXIT))) {
-		do_notify_parent_cldstop(current, current->parent,
-					 CLD_TRAPPED);
+		do_notify_parent_cldstop(current, 1, CLD_TRAPPED);
 		read_unlock(&tasklist_lock);
 		schedule();
 	} else {
@@ -1668,25 +1659,25 @@ void ptrace_notify(int exit_code)
 static void
 finish_stop(int stop_count)
 {
+	int to_self;
+
 	/*
 	 * If there are no other threads in the group, or if there is
 	 * a group stop in progress and we are the last to stop,
 	 * report to the parent.  When ptraced, every thread reports itself.
 	 */
-	if (stop_count < 0 || (current->ptrace & PT_PTRACED)) {
-		read_lock(&tasklist_lock);
-		do_notify_parent_cldstop(current, current->parent,
-					 CLD_STOPPED);
-		read_unlock(&tasklist_lock);
-	}
-	else if (stop_count == 0) {
-		read_lock(&tasklist_lock);
-		do_notify_parent_cldstop(current->group_leader,
-					 current->group_leader->real_parent,
-					 CLD_STOPPED);
-		read_unlock(&tasklist_lock);
-	}
+	if (stop_count < 0 || (current->ptrace & PT_PTRACED))
+		to_self = 1;
+	else if (stop_count == 0)
+		to_self = 0;
+	else
+		goto out;
 
+	read_lock(&tasklist_lock);
+	do_notify_parent_cldstop(current, to_self, CLD_STOPPED);
+	read_unlock(&tasklist_lock);
+
+out:
 	schedule();
 	/*
 	 * Now we don't run again until continued.

commit dd12f48d4e8774415b528d3991ae47c28f26e1ac
Author: Bhavesh P. Davda <bhavesh@avaya.com>
Date:   Wed Aug 17 12:26:33 2005 -0600

    [PATCH] NPTL signal delivery deadlock fix
    
    This bug is quite subtle and only happens in a very interesting
    situation where a real-time threaded process is in the middle of a
    coredump when someone whacks it with a SIGKILL.  However, this deadlock
    leaves the system pretty hosed and you have to reboot to recover.
    
    Not good for real-time priority-preemption applications like our
    telephony application, with 90+ real-time (SCHED_FIFO and SCHED_RR)
    processes, many of them multi-threaded, interacting with each other for
    high volume call processing.
    
    Acked-by: Roland McGrath <roland@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index ca1186eef938..d282fea81138 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -692,7 +692,7 @@ static void handle_stop_signal(int sig, struct task_struct *p)
 {
 	struct task_struct *t;
 
-	if (p->flags & SIGNAL_GROUP_EXIT)
+	if (p->signal->flags & SIGNAL_GROUP_EXIT)
 		/*
 		 * The process is in the middle of dying already.
 		 */

commit 3e1d1d28d99dabe63c64f7f40f1ca1d646de1f73
Author: Christoph Lameter <christoph@lameter.com>
Date:   Fri Jun 24 23:13:50 2005 -0700

    [PATCH] Cleanup patch for process freezing
    
    1. Establish a simple API for process freezing defined in linux/include/sched.h:
    
       frozen(process)              Check for frozen process
       freezing(process)            Check if a process is being frozen
       freeze(process)              Tell a process to freeze (go to refrigerator)
       thaw_process(process)        Restart process
       frozen_process(process)      Process is frozen now
    
    2. Remove all references to PF_FREEZE and PF_FROZEN from all
       kernel sources except sched.h
    
    3. Fix numerous locations where try_to_freeze is manually done by a driver
    
    4. Remove the argument that is no longer necessary from two function calls.
    
    5. Some whitespace cleanup
    
    6. Clear potential race in refrigerator (provides an open window of PF_FREEZE
       cleared before setting PF_FROZEN, recalc_sigpending does not check
       PF_FROZEN).
    
    This patch does not address the problem of freeze_processes() violating the rule
    that a task may only modify its own flags by setting PF_FREEZE. This is not clean
    in an SMP environment. freeze(process) is therefore not SMP safe!
    
    Signed-off-by: Christoph Lameter <christoph@lameter.com>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index d1258729a5f9..ca1186eef938 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -213,7 +213,7 @@ static inline int has_pending_signals(sigset_t *signal, sigset_t *blocked)
 fastcall void recalc_sigpending_tsk(struct task_struct *t)
 {
 	if (t->signal->group_stop_count > 0 ||
-	    (t->flags & PF_FREEZE) ||
+	    (freezing(t)) ||
 	    PENDING(&t->pending, &t->blocked) ||
 	    PENDING(&t->signal->shared_pending, &t->blocked))
 		set_tsk_thread_flag(t, TIF_SIGPENDING);
@@ -2231,8 +2231,7 @@ sys_rt_sigtimedwait(const sigset_t __user *uthese,
 			current->state = TASK_INTERRUPTIBLE;
 			timeout = schedule_timeout(timeout);
 
-			if (current->flags & PF_FREEZE)
-				refrigerator(PF_FREEZE);
+			try_to_freeze();
 			spin_lock_irq(&current->sighand->siglock);
 			sig = dequeue_signal(current, &these, &info);
 			current->blocked = current->real_blocked;

commit 4fea2838aa00b9e59efde974dcdb455608192811
Author: Kirill Korotaev <dev@sw.ru>
Date:   Thu Jun 23 00:09:51 2005 -0700

    [PATCH] Software suspend and recalc sigpending bug fix
    
    This patch fixes recalc_sigpending() to work correctly with tasks which are
    being freezed.
    
    The problem is that freeze_processes() sets PF_FREEZE and TIF_SIGPENDING
    flags on tasks, but recalc_sigpending() called from e.g.
    sys_rt_sigtimedwait or any other kernel place will clear TIF_SIGPENDING due
    to no pending signals queued and the tasks won't be freezed until it
    recieves a real signal or freezed_processes() fail due to timeout.
    
    Signed-Off-By: Kirill Korotaev <dev@sw.ru>
    Signed-Off-By: Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index c89821b69ae3..d1258729a5f9 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -213,6 +213,7 @@ static inline int has_pending_signals(sigset_t *signal, sigset_t *blocked)
 fastcall void recalc_sigpending_tsk(struct task_struct *t)
 {
 	if (t->signal->group_stop_count > 0 ||
+	    (t->flags & PF_FREEZE) ||
 	    PENDING(&t->pending, &t->blocked) ||
 	    PENDING(&t->signal->shared_pending, &t->blocked))
 		set_tsk_thread_flag(t, TIF_SIGPENDING);

commit 1c3f45ab2f7f879ea482501c83899505c31f7539
Merge: 4bcff1b37e7c e0d6d71440a3
Author: David Woodhouse <dwmw2@shinybook.infradead.org>
Date:   Thu Jun 2 16:39:11 2005 +0100

    Merge with master.kernel.org:/pub/scm/linux/kernel/git/torvalds/linux-2.6.git

commit c33880aaddbbab1ccf36f4457ed1090621f2e39a
Author: Kirill Korotaev <dev@sw.ru>
Date:   Tue May 24 19:29:47 2005 -0700

    [PATCH] sigkill priority fix
    
    If SIGKILL does not have priority, we cannot instantly kill task before it
    makes some unexpected job.  It can be critical, but we were unable to
    reproduce this easily until Heiko Carstens <Heiko.Carstens@de.ibm.com>
    reported this problem on LKML.
    
    Signed-Off-By: Kirill Korotaev <dev@sw.ru>
    Signed-Off-By: Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8f3debc77c5b..b3c24c732c5a 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -522,7 +522,16 @@ static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,
 {
 	int sig = 0;
 
-	sig = next_signal(pending, mask);
+	/* SIGKILL must have priority, otherwise it is quite easy
+	 * to create an unkillable process, sending sig < SIGKILL
+	 * to self */
+	if (unlikely(sigismember(&pending->signal, SIGKILL))) {
+		if (!sigismember(mask, SIGKILL))
+			sig = SIGKILL;
+	}
+
+	if (likely(!sig))
+		sig = next_signal(pending, mask);
 	if (sig) {
 		if (current->notifier) {
 			if (sigismember(current->notifier_mask, sig)) {

commit c2f0c7c356dc9ae15419f00c725a2fcc58eeff58
Author: Steve Grubb <sgrubb@redhat.com>
Date:   Fri May 6 12:38:39 2005 +0100

    The attached patch addresses the problem with getting the audit daemon
    shutdown credential information. It creates a new message type
    AUDIT_TERM_INFO, which is used by the audit daemon to query who issued the
    shutdown.
    
    It requires the placement of a hook function that gathers the information. The
    hook is after the DAC & MAC checks and before the function returns. Racing
    threads could overwrite the uid & pid - but they would have to be root and
    have policy that allows signalling the audit daemon. That should be a
    manageable risk.
    
    The userspace component will be released later in audit 0.7.2. When it
    receives the TERM signal, it queries the kernel for shutdown information.
    When it receives it, it writes the message and exits. The message looks
    like this:
    
    type=DAEMON msg=auditd(1114551182.000) auditd normal halt, sending pid=2650
    uid=525, auditd pid=1685
    
    Signed-off-by: Steve Grubb <sgrubb@redhat.com>
    Signed-off-by: David Woodhouse <dwmw2@infradead.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index 8f3debc77c5b..293e189d8bc3 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -24,6 +24,7 @@
 #include <linux/ptrace.h>
 #include <linux/posix-timers.h>
 #include <linux/signal.h>
+#include <linux/audit.h>
 #include <asm/param.h>
 #include <asm/uaccess.h>
 #include <asm/unistd.h>
@@ -658,7 +659,11 @@ static int check_kill_permission(int sig, struct siginfo *info,
 	    && (current->uid ^ t->suid) && (current->uid ^ t->uid)
 	    && !capable(CAP_KILL))
 		return error;
-	return security_task_kill(t, info, sig);
+
+	error = security_task_kill(t, info, sig);
+	if (!error)
+		audit_signal_info(sig, t); /* Let audit system see the signal */
+	return error;
 }
 
 /* forward decl */

commit 7ed20e1ad521b5f5df61bf6559ae60738e393741
Author: Jesper Juhl <juhl-lkml@dif.dk>
Date:   Sun May 1 08:59:14 2005 -0700

    [PATCH] convert that currently tests _NSIG directly to use valid_signal()
    
    Convert most of the current code that uses _NSIG directly to instead use
    valid_signal().  This avoids gcc -W warnings and off-by-one errors.
    
    Signed-off-by: Jesper Juhl <juhl-lkml@dif.dk>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index e6567d7f2b62..8f3debc77c5b 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -23,6 +23,7 @@
 #include <linux/syscalls.h>
 #include <linux/ptrace.h>
 #include <linux/posix-timers.h>
+#include <linux/signal.h>
 #include <asm/param.h>
 #include <asm/uaccess.h>
 #include <asm/unistd.h>
@@ -646,7 +647,7 @@ static int check_kill_permission(int sig, struct siginfo *info,
 				 struct task_struct *t)
 {
 	int error = -EINVAL;
-	if (sig < 0 || sig > _NSIG)
+	if (!valid_signal(sig))
 		return error;
 	error = -EPERM;
 	if ((!info || ((unsigned long)info != 1 &&
@@ -1245,7 +1246,7 @@ send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
 	 * Make sure legacy kernel users don't send in bad values
 	 * (normal paths check this in check_kill_permission).
 	 */
-	if (sig < 0 || sig > _NSIG)
+	if (!valid_signal(sig))
 		return -EINVAL;
 
 	/*
@@ -1520,7 +1521,7 @@ void do_notify_parent(struct task_struct *tsk, int sig)
 		if (psig->action[SIGCHLD-1].sa.sa_handler == SIG_IGN)
 			sig = 0;
 	}
-	if (sig > 0 && sig <= _NSIG)
+	if (valid_signal(sig) && sig > 0)
 		__group_send_sig_info(sig, &info, tsk->parent);
 	__wake_up_parent(tsk, tsk->parent);
 	spin_unlock_irqrestore(&psig->siglock, flags);
@@ -2364,7 +2365,7 @@ do_sigaction(int sig, const struct k_sigaction *act, struct k_sigaction *oact)
 {
 	struct k_sigaction *k;
 
-	if (sig < 1 || sig > _NSIG || (act && sig_kernel_only(sig)))
+	if (!valid_signal(sig) || sig < 1 || (act && sig_kernel_only(sig)))
 		return -EINVAL;
 
 	k = &current->sighand->action[sig-1];

commit 6cae60feb6709dea4cb94da93d4d2ea039aee59d
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Apr 16 15:25:47 2005 -0700

    [PATCH] kill #ifndef HAVE_ARCH_GET_SIGNAL_TO_DELIVER in signal.c
    
    Now that no architectures defines HAVE_ARCH_GET_SIGNAL_TO_DELIVER anymore
    this can go away.  It was a transitional hack only.
    
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/signal.c b/kernel/signal.c
index f00a1d610f0b..e6567d7f2b62 100644
--- a/kernel/signal.c
+++ b/kernel/signal.c
@@ -1649,8 +1649,6 @@ void ptrace_notify(int exit_code)
 	spin_unlock_irq(&current->sighand->siglock);
 }
 
-#ifndef HAVE_ARCH_GET_SIGNAL_TO_DELIVER
-
 static void
 finish_stop(int stop_count)
 {
@@ -1962,8 +1960,6 @@ int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
 	return signr;
 }
 
-#endif
-
 EXPORT_SYMBOL(recalc_sigpending);
 EXPORT_SYMBOL_GPL(dequeue_signal);
 EXPORT_SYMBOL(flush_signals);

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/kernel/signal.c b/kernel/signal.c
new file mode 100644
index 000000000000..f00a1d610f0b
--- /dev/null
+++ b/kernel/signal.c
@@ -0,0 +1,2662 @@
+/*
+ *  linux/kernel/signal.c
+ *
+ *  Copyright (C) 1991, 1992  Linus Torvalds
+ *
+ *  1997-11-02  Modified for POSIX.1b signals by Richard Henderson
+ *
+ *  2003-06-02  Jim Houston - Concurrent Computer Corp.
+ *		Changes to use preallocated sigqueue structures
+ *		to allow signals to be sent reliably.
+ */
+
+#include <linux/config.h>
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/smp_lock.h>
+#include <linux/init.h>
+#include <linux/sched.h>
+#include <linux/fs.h>
+#include <linux/tty.h>
+#include <linux/binfmts.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/ptrace.h>
+#include <linux/posix-timers.h>
+#include <asm/param.h>
+#include <asm/uaccess.h>
+#include <asm/unistd.h>
+#include <asm/siginfo.h>
+
+/*
+ * SLAB caches for signal bits.
+ */
+
+static kmem_cache_t *sigqueue_cachep;
+
+/*
+ * In POSIX a signal is sent either to a specific thread (Linux task)
+ * or to the process as a whole (Linux thread group).  How the signal
+ * is sent determines whether it's to one thread or the whole group,
+ * which determines which signal mask(s) are involved in blocking it
+ * from being delivered until later.  When the signal is delivered,
+ * either it's caught or ignored by a user handler or it has a default
+ * effect that applies to the whole thread group (POSIX process).
+ *
+ * The possible effects an unblocked signal set to SIG_DFL can have are:
+ *   ignore	- Nothing Happens
+ *   terminate	- kill the process, i.e. all threads in the group,
+ * 		  similar to exit_group.  The group leader (only) reports
+ *		  WIFSIGNALED status to its parent.
+ *   coredump	- write a core dump file describing all threads using
+ *		  the same mm and then kill all those threads
+ *   stop 	- stop all the threads in the group, i.e. TASK_STOPPED state
+ *
+ * SIGKILL and SIGSTOP cannot be caught, blocked, or ignored.
+ * Other signals when not blocked and set to SIG_DFL behaves as follows.
+ * The job control signals also have other special effects.
+ *
+ *	+--------------------+------------------+
+ *	|  POSIX signal      |  default action  |
+ *	+--------------------+------------------+
+ *	|  SIGHUP            |  terminate	|
+ *	|  SIGINT            |	terminate	|
+ *	|  SIGQUIT           |	coredump 	|
+ *	|  SIGILL            |	coredump 	|
+ *	|  SIGTRAP           |	coredump 	|
+ *	|  SIGABRT/SIGIOT    |	coredump 	|
+ *	|  SIGBUS            |	coredump 	|
+ *	|  SIGFPE            |	coredump 	|
+ *	|  SIGKILL           |	terminate(+)	|
+ *	|  SIGUSR1           |	terminate	|
+ *	|  SIGSEGV           |	coredump 	|
+ *	|  SIGUSR2           |	terminate	|
+ *	|  SIGPIPE           |	terminate	|
+ *	|  SIGALRM           |	terminate	|
+ *	|  SIGTERM           |	terminate	|
+ *	|  SIGCHLD           |	ignore   	|
+ *	|  SIGCONT           |	ignore(*)	|
+ *	|  SIGSTOP           |	stop(*)(+)  	|
+ *	|  SIGTSTP           |	stop(*)  	|
+ *	|  SIGTTIN           |	stop(*)  	|
+ *	|  SIGTTOU           |	stop(*)  	|
+ *	|  SIGURG            |	ignore   	|
+ *	|  SIGXCPU           |	coredump 	|
+ *	|  SIGXFSZ           |	coredump 	|
+ *	|  SIGVTALRM         |	terminate	|
+ *	|  SIGPROF           |	terminate	|
+ *	|  SIGPOLL/SIGIO     |	terminate	|
+ *	|  SIGSYS/SIGUNUSED  |	coredump 	|
+ *	|  SIGSTKFLT         |	terminate	|
+ *	|  SIGWINCH          |	ignore   	|
+ *	|  SIGPWR            |	terminate	|
+ *	|  SIGRTMIN-SIGRTMAX |	terminate       |
+ *	+--------------------+------------------+
+ *	|  non-POSIX signal  |  default action  |
+ *	+--------------------+------------------+
+ *	|  SIGEMT            |  coredump	|
+ *	+--------------------+------------------+
+ *
+ * (+) For SIGKILL and SIGSTOP the action is "always", not just "default".
+ * (*) Special job control effects:
+ * When SIGCONT is sent, it resumes the process (all threads in the group)
+ * from TASK_STOPPED state and also clears any pending/queued stop signals
+ * (any of those marked with "stop(*)").  This happens regardless of blocking,
+ * catching, or ignoring SIGCONT.  When any stop signal is sent, it clears
+ * any pending/queued SIGCONT signals; this happens regardless of blocking,
+ * catching, or ignored the stop signal, though (except for SIGSTOP) the
+ * default action of stopping the process may happen later or never.
+ */
+
+#ifdef SIGEMT
+#define M_SIGEMT	M(SIGEMT)
+#else
+#define M_SIGEMT	0
+#endif
+
+#if SIGRTMIN > BITS_PER_LONG
+#define M(sig) (1ULL << ((sig)-1))
+#else
+#define M(sig) (1UL << ((sig)-1))
+#endif
+#define T(sig, mask) (M(sig) & (mask))
+
+#define SIG_KERNEL_ONLY_MASK (\
+	M(SIGKILL)   |  M(SIGSTOP)                                   )
+
+#define SIG_KERNEL_STOP_MASK (\
+	M(SIGSTOP)   |  M(SIGTSTP)   |  M(SIGTTIN)   |  M(SIGTTOU)   )
+
+#define SIG_KERNEL_COREDUMP_MASK (\
+        M(SIGQUIT)   |  M(SIGILL)    |  M(SIGTRAP)   |  M(SIGABRT)   | \
+        M(SIGFPE)    |  M(SIGSEGV)   |  M(SIGBUS)    |  M(SIGSYS)    | \
+        M(SIGXCPU)   |  M(SIGXFSZ)   |  M_SIGEMT                     )
+
+#define SIG_KERNEL_IGNORE_MASK (\
+        M(SIGCONT)   |  M(SIGCHLD)   |  M(SIGWINCH)  |  M(SIGURG)    )
+
+#define sig_kernel_only(sig) \
+		(((sig) < SIGRTMIN)  && T(sig, SIG_KERNEL_ONLY_MASK))
+#define sig_kernel_coredump(sig) \
+		(((sig) < SIGRTMIN)  && T(sig, SIG_KERNEL_COREDUMP_MASK))
+#define sig_kernel_ignore(sig) \
+		(((sig) < SIGRTMIN)  && T(sig, SIG_KERNEL_IGNORE_MASK))
+#define sig_kernel_stop(sig) \
+		(((sig) < SIGRTMIN)  && T(sig, SIG_KERNEL_STOP_MASK))
+
+#define sig_user_defined(t, signr) \
+	(((t)->sighand->action[(signr)-1].sa.sa_handler != SIG_DFL) &&	\
+	 ((t)->sighand->action[(signr)-1].sa.sa_handler != SIG_IGN))
+
+#define sig_fatal(t, signr) \
+	(!T(signr, SIG_KERNEL_IGNORE_MASK|SIG_KERNEL_STOP_MASK) && \
+	 (t)->sighand->action[(signr)-1].sa.sa_handler == SIG_DFL)
+
+static int sig_ignored(struct task_struct *t, int sig)
+{
+	void __user * handler;
+
+	/*
+	 * Tracers always want to know about signals..
+	 */
+	if (t->ptrace & PT_PTRACED)
+		return 0;
+
+	/*
+	 * Blocked signals are never ignored, since the
+	 * signal handler may change by the time it is
+	 * unblocked.
+	 */
+	if (sigismember(&t->blocked, sig))
+		return 0;
+
+	/* Is it explicitly or implicitly ignored? */
+	handler = t->sighand->action[sig-1].sa.sa_handler;
+	return   handler == SIG_IGN ||
+		(handler == SIG_DFL && sig_kernel_ignore(sig));
+}
+
+/*
+ * Re-calculate pending state from the set of locally pending
+ * signals, globally pending signals, and blocked signals.
+ */
+static inline int has_pending_signals(sigset_t *signal, sigset_t *blocked)
+{
+	unsigned long ready;
+	long i;
+
+	switch (_NSIG_WORDS) {
+	default:
+		for (i = _NSIG_WORDS, ready = 0; --i >= 0 ;)
+			ready |= signal->sig[i] &~ blocked->sig[i];
+		break;
+
+	case 4: ready  = signal->sig[3] &~ blocked->sig[3];
+		ready |= signal->sig[2] &~ blocked->sig[2];
+		ready |= signal->sig[1] &~ blocked->sig[1];
+		ready |= signal->sig[0] &~ blocked->sig[0];
+		break;
+
+	case 2: ready  = signal->sig[1] &~ blocked->sig[1];
+		ready |= signal->sig[0] &~ blocked->sig[0];
+		break;
+
+	case 1: ready  = signal->sig[0] &~ blocked->sig[0];
+	}
+	return ready !=	0;
+}
+
+#define PENDING(p,b) has_pending_signals(&(p)->signal, (b))
+
+fastcall void recalc_sigpending_tsk(struct task_struct *t)
+{
+	if (t->signal->group_stop_count > 0 ||
+	    PENDING(&t->pending, &t->blocked) ||
+	    PENDING(&t->signal->shared_pending, &t->blocked))
+		set_tsk_thread_flag(t, TIF_SIGPENDING);
+	else
+		clear_tsk_thread_flag(t, TIF_SIGPENDING);
+}
+
+void recalc_sigpending(void)
+{
+	recalc_sigpending_tsk(current);
+}
+
+/* Given the mask, find the first available signal that should be serviced. */
+
+static int
+next_signal(struct sigpending *pending, sigset_t *mask)
+{
+	unsigned long i, *s, *m, x;
+	int sig = 0;
+	
+	s = pending->signal.sig;
+	m = mask->sig;
+	switch (_NSIG_WORDS) {
+	default:
+		for (i = 0; i < _NSIG_WORDS; ++i, ++s, ++m)
+			if ((x = *s &~ *m) != 0) {
+				sig = ffz(~x) + i*_NSIG_BPW + 1;
+				break;
+			}
+		break;
+
+	case 2: if ((x = s[0] &~ m[0]) != 0)
+			sig = 1;
+		else if ((x = s[1] &~ m[1]) != 0)
+			sig = _NSIG_BPW + 1;
+		else
+			break;
+		sig += ffz(~x);
+		break;
+
+	case 1: if ((x = *s &~ *m) != 0)
+			sig = ffz(~x) + 1;
+		break;
+	}
+	
+	return sig;
+}
+
+static struct sigqueue *__sigqueue_alloc(struct task_struct *t, unsigned int __nocast flags,
+					 int override_rlimit)
+{
+	struct sigqueue *q = NULL;
+
+	atomic_inc(&t->user->sigpending);
+	if (override_rlimit ||
+	    atomic_read(&t->user->sigpending) <=
+			t->signal->rlim[RLIMIT_SIGPENDING].rlim_cur)
+		q = kmem_cache_alloc(sigqueue_cachep, flags);
+	if (unlikely(q == NULL)) {
+		atomic_dec(&t->user->sigpending);
+	} else {
+		INIT_LIST_HEAD(&q->list);
+		q->flags = 0;
+		q->lock = NULL;
+		q->user = get_uid(t->user);
+	}
+	return(q);
+}
+
+static inline void __sigqueue_free(struct sigqueue *q)
+{
+	if (q->flags & SIGQUEUE_PREALLOC)
+		return;
+	atomic_dec(&q->user->sigpending);
+	free_uid(q->user);
+	kmem_cache_free(sigqueue_cachep, q);
+}
+
+static void flush_sigqueue(struct sigpending *queue)
+{
+	struct sigqueue *q;
+
+	sigemptyset(&queue->signal);
+	while (!list_empty(&queue->list)) {
+		q = list_entry(queue->list.next, struct sigqueue , list);
+		list_del_init(&q->list);
+		__sigqueue_free(q);
+	}
+}
+
+/*
+ * Flush all pending signals for a task.
+ */
+
+void
+flush_signals(struct task_struct *t)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&t->sighand->siglock, flags);
+	clear_tsk_thread_flag(t,TIF_SIGPENDING);
+	flush_sigqueue(&t->pending);
+	flush_sigqueue(&t->signal->shared_pending);
+	spin_unlock_irqrestore(&t->sighand->siglock, flags);
+}
+
+/*
+ * This function expects the tasklist_lock write-locked.
+ */
+void __exit_sighand(struct task_struct *tsk)
+{
+	struct sighand_struct * sighand = tsk->sighand;
+
+	/* Ok, we're done with the signal handlers */
+	tsk->sighand = NULL;
+	if (atomic_dec_and_test(&sighand->count))
+		kmem_cache_free(sighand_cachep, sighand);
+}
+
+void exit_sighand(struct task_struct *tsk)
+{
+	write_lock_irq(&tasklist_lock);
+	__exit_sighand(tsk);
+	write_unlock_irq(&tasklist_lock);
+}
+
+/*
+ * This function expects the tasklist_lock write-locked.
+ */
+void __exit_signal(struct task_struct *tsk)
+{
+	struct signal_struct * sig = tsk->signal;
+	struct sighand_struct * sighand = tsk->sighand;
+
+	if (!sig)
+		BUG();
+	if (!atomic_read(&sig->count))
+		BUG();
+	spin_lock(&sighand->siglock);
+	posix_cpu_timers_exit(tsk);
+	if (atomic_dec_and_test(&sig->count)) {
+		posix_cpu_timers_exit_group(tsk);
+		if (tsk == sig->curr_target)
+			sig->curr_target = next_thread(tsk);
+		tsk->signal = NULL;
+		spin_unlock(&sighand->siglock);
+		flush_sigqueue(&sig->shared_pending);
+	} else {
+		/*
+		 * If there is any task waiting for the group exit
+		 * then notify it:
+		 */
+		if (sig->group_exit_task && atomic_read(&sig->count) == sig->notify_count) {
+			wake_up_process(sig->group_exit_task);
+			sig->group_exit_task = NULL;
+		}
+		if (tsk == sig->curr_target)
+			sig->curr_target = next_thread(tsk);
+		tsk->signal = NULL;
+		/*
+		 * Accumulate here the counters for all threads but the
+		 * group leader as they die, so they can be added into
+		 * the process-wide totals when those are taken.
+		 * The group leader stays around as a zombie as long
+		 * as there are other threads.  When it gets reaped,
+		 * the exit.c code will add its counts into these totals.
+		 * We won't ever get here for the group leader, since it
+		 * will have been the last reference on the signal_struct.
+		 */
+		sig->utime = cputime_add(sig->utime, tsk->utime);
+		sig->stime = cputime_add(sig->stime, tsk->stime);
+		sig->min_flt += tsk->min_flt;
+		sig->maj_flt += tsk->maj_flt;
+		sig->nvcsw += tsk->nvcsw;
+		sig->nivcsw += tsk->nivcsw;
+		sig->sched_time += tsk->sched_time;
+		spin_unlock(&sighand->siglock);
+		sig = NULL;	/* Marker for below.  */
+	}
+	clear_tsk_thread_flag(tsk,TIF_SIGPENDING);
+	flush_sigqueue(&tsk->pending);
+	if (sig) {
+		/*
+		 * We are cleaning up the signal_struct here.  We delayed
+		 * calling exit_itimers until after flush_sigqueue, just in
+		 * case our thread-local pending queue contained a queued
+		 * timer signal that would have been cleared in
+		 * exit_itimers.  When that called sigqueue_free, it would
+		 * attempt to re-take the tasklist_lock and deadlock.  This
+		 * can never happen if we ensure that all queues the
+		 * timer's signal might be queued on have been flushed
+		 * first.  The shared_pending queue, and our own pending
+		 * queue are the only queues the timer could be on, since
+		 * there are no other threads left in the group and timer
+		 * signals are constrained to threads inside the group.
+		 */
+		exit_itimers(sig);
+		exit_thread_group_keys(sig);
+		kmem_cache_free(signal_cachep, sig);
+	}
+}
+
+void exit_signal(struct task_struct *tsk)
+{
+	write_lock_irq(&tasklist_lock);
+	__exit_signal(tsk);
+	write_unlock_irq(&tasklist_lock);
+}
+
+/*
+ * Flush all handlers for a task.
+ */
+
+void
+flush_signal_handlers(struct task_struct *t, int force_default)
+{
+	int i;
+	struct k_sigaction *ka = &t->sighand->action[0];
+	for (i = _NSIG ; i != 0 ; i--) {
+		if (force_default || ka->sa.sa_handler != SIG_IGN)
+			ka->sa.sa_handler = SIG_DFL;
+		ka->sa.sa_flags = 0;
+		sigemptyset(&ka->sa.sa_mask);
+		ka++;
+	}
+}
+
+
+/* Notify the system that a driver wants to block all signals for this
+ * process, and wants to be notified if any signals at all were to be
+ * sent/acted upon.  If the notifier routine returns non-zero, then the
+ * signal will be acted upon after all.  If the notifier routine returns 0,
+ * then then signal will be blocked.  Only one block per process is
+ * allowed.  priv is a pointer to private data that the notifier routine
+ * can use to determine if the signal should be blocked or not.  */
+
+void
+block_all_signals(int (*notifier)(void *priv), void *priv, sigset_t *mask)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&current->sighand->siglock, flags);
+	current->notifier_mask = mask;
+	current->notifier_data = priv;
+	current->notifier = notifier;
+	spin_unlock_irqrestore(&current->sighand->siglock, flags);
+}
+
+/* Notify the system that blocking has ended. */
+
+void
+unblock_all_signals(void)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&current->sighand->siglock, flags);
+	current->notifier = NULL;
+	current->notifier_data = NULL;
+	recalc_sigpending();
+	spin_unlock_irqrestore(&current->sighand->siglock, flags);
+}
+
+static inline int collect_signal(int sig, struct sigpending *list, siginfo_t *info)
+{
+	struct sigqueue *q, *first = NULL;
+	int still_pending = 0;
+
+	if (unlikely(!sigismember(&list->signal, sig)))
+		return 0;
+
+	/*
+	 * Collect the siginfo appropriate to this signal.  Check if
+	 * there is another siginfo for the same signal.
+	*/
+	list_for_each_entry(q, &list->list, list) {
+		if (q->info.si_signo == sig) {
+			if (first) {
+				still_pending = 1;
+				break;
+			}
+			first = q;
+		}
+	}
+	if (first) {
+		list_del_init(&first->list);
+		copy_siginfo(info, &first->info);
+		__sigqueue_free(first);
+		if (!still_pending)
+			sigdelset(&list->signal, sig);
+	} else {
+
+		/* Ok, it wasn't in the queue.  This must be
+		   a fast-pathed signal or we must have been
+		   out of queue space.  So zero out the info.
+		 */
+		sigdelset(&list->signal, sig);
+		info->si_signo = sig;
+		info->si_errno = 0;
+		info->si_code = 0;
+		info->si_pid = 0;
+		info->si_uid = 0;
+	}
+	return 1;
+}
+
+static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,
+			siginfo_t *info)
+{
+	int sig = 0;
+
+	sig = next_signal(pending, mask);
+	if (sig) {
+		if (current->notifier) {
+			if (sigismember(current->notifier_mask, sig)) {
+				if (!(current->notifier)(current->notifier_data)) {
+					clear_thread_flag(TIF_SIGPENDING);
+					return 0;
+				}
+			}
+		}
+
+		if (!collect_signal(sig, pending, info))
+			sig = 0;
+				
+	}
+	recalc_sigpending();
+
+	return sig;
+}
+
+/*
+ * Dequeue a signal and return the element to the caller, which is 
+ * expected to free it.
+ *
+ * All callers have to hold the siglock.
+ */
+int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
+{
+	int signr = __dequeue_signal(&tsk->pending, mask, info);
+	if (!signr)
+		signr = __dequeue_signal(&tsk->signal->shared_pending,
+					 mask, info);
+ 	if (signr && unlikely(sig_kernel_stop(signr))) {
+ 		/*
+ 		 * Set a marker that we have dequeued a stop signal.  Our
+ 		 * caller might release the siglock and then the pending
+ 		 * stop signal it is about to process is no longer in the
+ 		 * pending bitmasks, but must still be cleared by a SIGCONT
+ 		 * (and overruled by a SIGKILL).  So those cases clear this
+ 		 * shared flag after we've set it.  Note that this flag may
+ 		 * remain set after the signal we return is ignored or
+ 		 * handled.  That doesn't matter because its only purpose
+ 		 * is to alert stop-signal processing code when another
+ 		 * processor has come along and cleared the flag.
+ 		 */
+ 		tsk->signal->flags |= SIGNAL_STOP_DEQUEUED;
+ 	}
+	if ( signr &&
+	     ((info->si_code & __SI_MASK) == __SI_TIMER) &&
+	     info->si_sys_private){
+		/*
+		 * Release the siglock to ensure proper locking order
+		 * of timer locks outside of siglocks.  Note, we leave
+		 * irqs disabled here, since the posix-timers code is
+		 * about to disable them again anyway.
+		 */
+		spin_unlock(&tsk->sighand->siglock);
+		do_schedule_next_timer(info);
+		spin_lock(&tsk->sighand->siglock);
+	}
+	return signr;
+}
+
+/*
+ * Tell a process that it has a new active signal..
+ *
+ * NOTE! we rely on the previous spin_lock to
+ * lock interrupts for us! We can only be called with
+ * "siglock" held, and the local interrupt must
+ * have been disabled when that got acquired!
+ *
+ * No need to set need_resched since signal event passing
+ * goes through ->blocked
+ */
+void signal_wake_up(struct task_struct *t, int resume)
+{
+	unsigned int mask;
+
+	set_tsk_thread_flag(t, TIF_SIGPENDING);
+
+	/*
+	 * For SIGKILL, we want to wake it up in the stopped/traced case.
+	 * We don't check t->state here because there is a race with it
+	 * executing another processor and just now entering stopped state.
+	 * By using wake_up_state, we ensure the process will wake up and
+	 * handle its death signal.
+	 */
+	mask = TASK_INTERRUPTIBLE;
+	if (resume)
+		mask |= TASK_STOPPED | TASK_TRACED;
+	if (!wake_up_state(t, mask))
+		kick_process(t);
+}
+
+/*
+ * Remove signals in mask from the pending set and queue.
+ * Returns 1 if any signals were found.
+ *
+ * All callers must be holding the siglock.
+ */
+static int rm_from_queue(unsigned long mask, struct sigpending *s)
+{
+	struct sigqueue *q, *n;
+
+	if (!sigtestsetmask(&s->signal, mask))
+		return 0;
+
+	sigdelsetmask(&s->signal, mask);
+	list_for_each_entry_safe(q, n, &s->list, list) {
+		if (q->info.si_signo < SIGRTMIN &&
+		    (mask & sigmask(q->info.si_signo))) {
+			list_del_init(&q->list);
+			__sigqueue_free(q);
+		}
+	}
+	return 1;
+}
+
+/*
+ * Bad permissions for sending the signal
+ */
+static int check_kill_permission(int sig, struct siginfo *info,
+				 struct task_struct *t)
+{
+	int error = -EINVAL;
+	if (sig < 0 || sig > _NSIG)
+		return error;
+	error = -EPERM;
+	if ((!info || ((unsigned long)info != 1 &&
+			(unsigned long)info != 2 && SI_FROMUSER(info)))
+	    && ((sig != SIGCONT) ||
+		(current->signal->session != t->signal->session))
+	    && (current->euid ^ t->suid) && (current->euid ^ t->uid)
+	    && (current->uid ^ t->suid) && (current->uid ^ t->uid)
+	    && !capable(CAP_KILL))
+		return error;
+	return security_task_kill(t, info, sig);
+}
+
+/* forward decl */
+static void do_notify_parent_cldstop(struct task_struct *tsk,
+				     struct task_struct *parent,
+				     int why);
+
+/*
+ * Handle magic process-wide effects of stop/continue signals.
+ * Unlike the signal actions, these happen immediately at signal-generation
+ * time regardless of blocking, ignoring, or handling.  This does the
+ * actual continuing for SIGCONT, but not the actual stopping for stop
+ * signals.  The process stop is done as a signal action for SIG_DFL.
+ */
+static void handle_stop_signal(int sig, struct task_struct *p)
+{
+	struct task_struct *t;
+
+	if (p->flags & SIGNAL_GROUP_EXIT)
+		/*
+		 * The process is in the middle of dying already.
+		 */
+		return;
+
+	if (sig_kernel_stop(sig)) {
+		/*
+		 * This is a stop signal.  Remove SIGCONT from all queues.
+		 */
+		rm_from_queue(sigmask(SIGCONT), &p->signal->shared_pending);
+		t = p;
+		do {
+			rm_from_queue(sigmask(SIGCONT), &t->pending);
+			t = next_thread(t);
+		} while (t != p);
+	} else if (sig == SIGCONT) {
+		/*
+		 * Remove all stop signals from all queues,
+		 * and wake all threads.
+		 */
+		if (unlikely(p->signal->group_stop_count > 0)) {
+			/*
+			 * There was a group stop in progress.  We'll
+			 * pretend it finished before we got here.  We are
+			 * obliged to report it to the parent: if the
+			 * SIGSTOP happened "after" this SIGCONT, then it
+			 * would have cleared this pending SIGCONT.  If it
+			 * happened "before" this SIGCONT, then the parent
+			 * got the SIGCHLD about the stop finishing before
+			 * the continue happened.  We do the notification
+			 * now, and it's as if the stop had finished and
+			 * the SIGCHLD was pending on entry to this kill.
+			 */
+			p->signal->group_stop_count = 0;
+			p->signal->flags = SIGNAL_STOP_CONTINUED;
+			spin_unlock(&p->sighand->siglock);
+			if (p->ptrace & PT_PTRACED)
+				do_notify_parent_cldstop(p, p->parent,
+							 CLD_STOPPED);
+			else
+				do_notify_parent_cldstop(
+					p->group_leader,
+					p->group_leader->real_parent,
+							 CLD_STOPPED);
+			spin_lock(&p->sighand->siglock);
+		}
+		rm_from_queue(SIG_KERNEL_STOP_MASK, &p->signal->shared_pending);
+		t = p;
+		do {
+			unsigned int state;
+			rm_from_queue(SIG_KERNEL_STOP_MASK, &t->pending);
+			
+			/*
+			 * If there is a handler for SIGCONT, we must make
+			 * sure that no thread returns to user mode before
+			 * we post the signal, in case it was the only
+			 * thread eligible to run the signal handler--then
+			 * it must not do anything between resuming and
+			 * running the handler.  With the TIF_SIGPENDING
+			 * flag set, the thread will pause and acquire the
+			 * siglock that we hold now and until we've queued
+			 * the pending signal. 
+			 *
+			 * Wake up the stopped thread _after_ setting
+			 * TIF_SIGPENDING
+			 */
+			state = TASK_STOPPED;
+			if (sig_user_defined(t, SIGCONT) && !sigismember(&t->blocked, SIGCONT)) {
+				set_tsk_thread_flag(t, TIF_SIGPENDING);
+				state |= TASK_INTERRUPTIBLE;
+			}
+			wake_up_state(t, state);
+
+			t = next_thread(t);
+		} while (t != p);
+
+		if (p->signal->flags & SIGNAL_STOP_STOPPED) {
+			/*
+			 * We were in fact stopped, and are now continued.
+			 * Notify the parent with CLD_CONTINUED.
+			 */
+			p->signal->flags = SIGNAL_STOP_CONTINUED;
+			p->signal->group_exit_code = 0;
+			spin_unlock(&p->sighand->siglock);
+			if (p->ptrace & PT_PTRACED)
+				do_notify_parent_cldstop(p, p->parent,
+							 CLD_CONTINUED);
+			else
+				do_notify_parent_cldstop(
+					p->group_leader,
+					p->group_leader->real_parent,
+							 CLD_CONTINUED);
+			spin_lock(&p->sighand->siglock);
+		} else {
+			/*
+			 * We are not stopped, but there could be a stop
+			 * signal in the middle of being processed after
+			 * being removed from the queue.  Clear that too.
+			 */
+			p->signal->flags = 0;
+		}
+	} else if (sig == SIGKILL) {
+		/*
+		 * Make sure that any pending stop signal already dequeued
+		 * is undone by the wakeup for SIGKILL.
+		 */
+		p->signal->flags = 0;
+	}
+}
+
+static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
+			struct sigpending *signals)
+{
+	struct sigqueue * q = NULL;
+	int ret = 0;
+
+	/*
+	 * fast-pathed signals for kernel-internal things like SIGSTOP
+	 * or SIGKILL.
+	 */
+	if ((unsigned long)info == 2)
+		goto out_set;
+
+	/* Real-time signals must be queued if sent by sigqueue, or
+	   some other real-time mechanism.  It is implementation
+	   defined whether kill() does so.  We attempt to do so, on
+	   the principle of least surprise, but since kill is not
+	   allowed to fail with EAGAIN when low on memory we just
+	   make sure at least one signal gets delivered and don't
+	   pass on the info struct.  */
+
+	q = __sigqueue_alloc(t, GFP_ATOMIC, (sig < SIGRTMIN &&
+					     ((unsigned long) info < 2 ||
+					      info->si_code >= 0)));
+	if (q) {
+		list_add_tail(&q->list, &signals->list);
+		switch ((unsigned long) info) {
+		case 0:
+			q->info.si_signo = sig;
+			q->info.si_errno = 0;
+			q->info.si_code = SI_USER;
+			q->info.si_pid = current->pid;
+			q->info.si_uid = current->uid;
+			break;
+		case 1:
+			q->info.si_signo = sig;
+			q->info.si_errno = 0;
+			q->info.si_code = SI_KERNEL;
+			q->info.si_pid = 0;
+			q->info.si_uid = 0;
+			break;
+		default:
+			copy_siginfo(&q->info, info);
+			break;
+		}
+	} else {
+		if (sig >= SIGRTMIN && info && (unsigned long)info != 1
+		   && info->si_code != SI_USER)
+		/*
+		 * Queue overflow, abort.  We may abort if the signal was rt
+		 * and sent by user using something other than kill().
+		 */
+			return -EAGAIN;
+		if (((unsigned long)info > 1) && (info->si_code == SI_TIMER))
+			/*
+			 * Set up a return to indicate that we dropped 
+			 * the signal.
+			 */
+			ret = info->si_sys_private;
+	}
+
+out_set:
+	sigaddset(&signals->signal, sig);
+	return ret;
+}
+
+#define LEGACY_QUEUE(sigptr, sig) \
+	(((sig) < SIGRTMIN) && sigismember(&(sigptr)->signal, (sig)))
+
+
+static int
+specific_send_sig_info(int sig, struct siginfo *info, struct task_struct *t)
+{
+	int ret = 0;
+
+	if (!irqs_disabled())
+		BUG();
+	assert_spin_locked(&t->sighand->siglock);
+
+	if (((unsigned long)info > 2) && (info->si_code == SI_TIMER))
+		/*
+		 * Set up a return to indicate that we dropped the signal.
+		 */
+		ret = info->si_sys_private;
+
+	/* Short-circuit ignored signals.  */
+	if (sig_ignored(t, sig))
+		goto out;
+
+	/* Support queueing exactly one non-rt signal, so that we
+	   can get more detailed information about the cause of
+	   the signal. */
+	if (LEGACY_QUEUE(&t->pending, sig))
+		goto out;
+
+	ret = send_signal(sig, info, t, &t->pending);
+	if (!ret && !sigismember(&t->blocked, sig))
+		signal_wake_up(t, sig == SIGKILL);
+out:
+	return ret;
+}
+
+/*
+ * Force a signal that the process can't ignore: if necessary
+ * we unblock the signal and change any SIG_IGN to SIG_DFL.
+ */
+
+int
+force_sig_info(int sig, struct siginfo *info, struct task_struct *t)
+{
+	unsigned long int flags;
+	int ret;
+
+	spin_lock_irqsave(&t->sighand->siglock, flags);
+	if (sigismember(&t->blocked, sig) || t->sighand->action[sig-1].sa.sa_handler == SIG_IGN) {
+		t->sighand->action[sig-1].sa.sa_handler = SIG_DFL;
+		sigdelset(&t->blocked, sig);
+		recalc_sigpending_tsk(t);
+	}
+	ret = specific_send_sig_info(sig, info, t);
+	spin_unlock_irqrestore(&t->sighand->siglock, flags);
+
+	return ret;
+}
+
+void
+force_sig_specific(int sig, struct task_struct *t)
+{
+	unsigned long int flags;
+
+	spin_lock_irqsave(&t->sighand->siglock, flags);
+	if (t->sighand->action[sig-1].sa.sa_handler == SIG_IGN)
+		t->sighand->action[sig-1].sa.sa_handler = SIG_DFL;
+	sigdelset(&t->blocked, sig);
+	recalc_sigpending_tsk(t);
+	specific_send_sig_info(sig, (void *)2, t);
+	spin_unlock_irqrestore(&t->sighand->siglock, flags);
+}
+
+/*
+ * Test if P wants to take SIG.  After we've checked all threads with this,
+ * it's equivalent to finding no threads not blocking SIG.  Any threads not
+ * blocking SIG were ruled out because they are not running and already
+ * have pending signals.  Such threads will dequeue from the shared queue
+ * as soon as they're available, so putting the signal on the shared queue
+ * will be equivalent to sending it to one such thread.
+ */
+#define wants_signal(sig, p, mask) 			\
+	(!sigismember(&(p)->blocked, sig)		\
+	 && !((p)->state & mask)			\
+	 && !((p)->flags & PF_EXITING)			\
+	 && (task_curr(p) || !signal_pending(p)))
+
+
+static void
+__group_complete_signal(int sig, struct task_struct *p)
+{
+	unsigned int mask;
+	struct task_struct *t;
+
+	/*
+	 * Don't bother traced and stopped tasks (but
+	 * SIGKILL will punch through that).
+	 */
+	mask = TASK_STOPPED | TASK_TRACED;
+	if (sig == SIGKILL)
+		mask = 0;
+
+	/*
+	 * Now find a thread we can wake up to take the signal off the queue.
+	 *
+	 * If the main thread wants the signal, it gets first crack.
+	 * Probably the least surprising to the average bear.
+	 */
+	if (wants_signal(sig, p, mask))
+		t = p;
+	else if (thread_group_empty(p))
+		/*
+		 * There is just one thread and it does not need to be woken.
+		 * It will dequeue unblocked signals before it runs again.
+		 */
+		return;
+	else {
+		/*
+		 * Otherwise try to find a suitable thread.
+		 */
+		t = p->signal->curr_target;
+		if (t == NULL)
+			/* restart balancing at this thread */
+			t = p->signal->curr_target = p;
+		BUG_ON(t->tgid != p->tgid);
+
+		while (!wants_signal(sig, t, mask)) {
+			t = next_thread(t);
+			if (t == p->signal->curr_target)
+				/*
+				 * No thread needs to be woken.
+				 * Any eligible threads will see
+				 * the signal in the queue soon.
+				 */
+				return;
+		}
+		p->signal->curr_target = t;
+	}
+
+	/*
+	 * Found a killable thread.  If the signal will be fatal,
+	 * then start taking the whole group down immediately.
+	 */
+	if (sig_fatal(p, sig) && !(p->signal->flags & SIGNAL_GROUP_EXIT) &&
+	    !sigismember(&t->real_blocked, sig) &&
+	    (sig == SIGKILL || !(t->ptrace & PT_PTRACED))) {
+		/*
+		 * This signal will be fatal to the whole group.
+		 */
+		if (!sig_kernel_coredump(sig)) {
+			/*
+			 * Start a group exit and wake everybody up.
+			 * This way we don't have other threads
+			 * running and doing things after a slower
+			 * thread has the fatal signal pending.
+			 */
+			p->signal->flags = SIGNAL_GROUP_EXIT;
+			p->signal->group_exit_code = sig;
+			p->signal->group_stop_count = 0;
+			t = p;
+			do {
+				sigaddset(&t->pending.signal, SIGKILL);
+				signal_wake_up(t, 1);
+				t = next_thread(t);
+			} while (t != p);
+			return;
+		}
+
+		/*
+		 * There will be a core dump.  We make all threads other
+		 * than the chosen one go into a group stop so that nothing
+		 * happens until it gets scheduled, takes the signal off
+		 * the shared queue, and does the core dump.  This is a
+		 * little more complicated than strictly necessary, but it
+		 * keeps the signal state that winds up in the core dump
+		 * unchanged from the death state, e.g. which thread had
+		 * the core-dump signal unblocked.
+		 */
+		rm_from_queue(SIG_KERNEL_STOP_MASK, &t->pending);
+		rm_from_queue(SIG_KERNEL_STOP_MASK, &p->signal->shared_pending);
+		p->signal->group_stop_count = 0;
+		p->signal->group_exit_task = t;
+		t = p;
+		do {
+			p->signal->group_stop_count++;
+			signal_wake_up(t, 0);
+			t = next_thread(t);
+		} while (t != p);
+		wake_up_process(p->signal->group_exit_task);
+		return;
+	}
+
+	/*
+	 * The signal is already in the shared-pending queue.
+	 * Tell the chosen thread to wake up and dequeue it.
+	 */
+	signal_wake_up(t, sig == SIGKILL);
+	return;
+}
+
+int
+__group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
+{
+	int ret = 0;
+
+	assert_spin_locked(&p->sighand->siglock);
+	handle_stop_signal(sig, p);
+
+	if (((unsigned long)info > 2) && (info->si_code == SI_TIMER))
+		/*
+		 * Set up a return to indicate that we dropped the signal.
+		 */
+		ret = info->si_sys_private;
+
+	/* Short-circuit ignored signals.  */
+	if (sig_ignored(p, sig))
+		return ret;
+
+	if (LEGACY_QUEUE(&p->signal->shared_pending, sig))
+		/* This is a non-RT signal and we already have one queued.  */
+		return ret;
+
+	/*
+	 * Put this signal on the shared-pending queue, or fail with EAGAIN.
+	 * We always use the shared queue for process-wide signals,
+	 * to avoid several races.
+	 */
+	ret = send_signal(sig, info, p, &p->signal->shared_pending);
+	if (unlikely(ret))
+		return ret;
+
+	__group_complete_signal(sig, p);
+	return 0;
+}
+
+/*
+ * Nuke all other threads in the group.
+ */
+void zap_other_threads(struct task_struct *p)
+{
+	struct task_struct *t;
+
+	p->signal->flags = SIGNAL_GROUP_EXIT;
+	p->signal->group_stop_count = 0;
+
+	if (thread_group_empty(p))
+		return;
+
+	for (t = next_thread(p); t != p; t = next_thread(t)) {
+		/*
+		 * Don't bother with already dead threads
+		 */
+		if (t->exit_state)
+			continue;
+
+		/*
+		 * We don't want to notify the parent, since we are
+		 * killed as part of a thread group due to another
+		 * thread doing an execve() or similar. So set the
+		 * exit signal to -1 to allow immediate reaping of
+		 * the process.  But don't detach the thread group
+		 * leader.
+		 */
+		if (t != p->group_leader)
+			t->exit_signal = -1;
+
+		sigaddset(&t->pending.signal, SIGKILL);
+		rm_from_queue(SIG_KERNEL_STOP_MASK, &t->pending);
+		signal_wake_up(t, 1);
+	}
+}
+
+/*
+ * Must be called with the tasklist_lock held for reading!
+ */
+int group_send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
+{
+	unsigned long flags;
+	int ret;
+
+	ret = check_kill_permission(sig, info, p);
+	if (!ret && sig && p->sighand) {
+		spin_lock_irqsave(&p->sighand->siglock, flags);
+		ret = __group_send_sig_info(sig, info, p);
+		spin_unlock_irqrestore(&p->sighand->siglock, flags);
+	}
+
+	return ret;
+}
+
+/*
+ * kill_pg_info() sends a signal to a process group: this is what the tty
+ * control characters do (^C, ^Z etc)
+ */
+
+int __kill_pg_info(int sig, struct siginfo *info, pid_t pgrp)
+{
+	struct task_struct *p = NULL;
+	int retval, success;
+
+	if (pgrp <= 0)
+		return -EINVAL;
+
+	success = 0;
+	retval = -ESRCH;
+	do_each_task_pid(pgrp, PIDTYPE_PGID, p) {
+		int err = group_send_sig_info(sig, info, p);
+		success |= !err;
+		retval = err;
+	} while_each_task_pid(pgrp, PIDTYPE_PGID, p);
+	return success ? 0 : retval;
+}
+
+int
+kill_pg_info(int sig, struct siginfo *info, pid_t pgrp)
+{
+	int retval;
+
+	read_lock(&tasklist_lock);
+	retval = __kill_pg_info(sig, info, pgrp);
+	read_unlock(&tasklist_lock);
+
+	return retval;
+}
+
+int
+kill_proc_info(int sig, struct siginfo *info, pid_t pid)
+{
+	int error;
+	struct task_struct *p;
+
+	read_lock(&tasklist_lock);
+	p = find_task_by_pid(pid);
+	error = -ESRCH;
+	if (p)
+		error = group_send_sig_info(sig, info, p);
+	read_unlock(&tasklist_lock);
+	return error;
+}
+
+
+/*
+ * kill_something_info() interprets pid in interesting ways just like kill(2).
+ *
+ * POSIX specifies that kill(-1,sig) is unspecified, but what we have
+ * is probably wrong.  Should make it like BSD or SYSV.
+ */
+
+static int kill_something_info(int sig, struct siginfo *info, int pid)
+{
+	if (!pid) {
+		return kill_pg_info(sig, info, process_group(current));
+	} else if (pid == -1) {
+		int retval = 0, count = 0;
+		struct task_struct * p;
+
+		read_lock(&tasklist_lock);
+		for_each_process(p) {
+			if (p->pid > 1 && p->tgid != current->tgid) {
+				int err = group_send_sig_info(sig, info, p);
+				++count;
+				if (err != -EPERM)
+					retval = err;
+			}
+		}
+		read_unlock(&tasklist_lock);
+		return count ? retval : -ESRCH;
+	} else if (pid < 0) {
+		return kill_pg_info(sig, info, -pid);
+	} else {
+		return kill_proc_info(sig, info, pid);
+	}
+}
+
+/*
+ * These are for backward compatibility with the rest of the kernel source.
+ */
+
+/*
+ * These two are the most common entry points.  They send a signal
+ * just to the specific thread.
+ */
+int
+send_sig_info(int sig, struct siginfo *info, struct task_struct *p)
+{
+	int ret;
+	unsigned long flags;
+
+	/*
+	 * Make sure legacy kernel users don't send in bad values
+	 * (normal paths check this in check_kill_permission).
+	 */
+	if (sig < 0 || sig > _NSIG)
+		return -EINVAL;
+
+	/*
+	 * We need the tasklist lock even for the specific
+	 * thread case (when we don't need to follow the group
+	 * lists) in order to avoid races with "p->sighand"
+	 * going away or changing from under us.
+	 */
+	read_lock(&tasklist_lock);  
+	spin_lock_irqsave(&p->sighand->siglock, flags);
+	ret = specific_send_sig_info(sig, info, p);
+	spin_unlock_irqrestore(&p->sighand->siglock, flags);
+	read_unlock(&tasklist_lock);
+	return ret;
+}
+
+int
+send_sig(int sig, struct task_struct *p, int priv)
+{
+	return send_sig_info(sig, (void*)(long)(priv != 0), p);
+}
+
+/*
+ * This is the entry point for "process-wide" signals.
+ * They will go to an appropriate thread in the thread group.
+ */
+int
+send_group_sig_info(int sig, struct siginfo *info, struct task_struct *p)
+{
+	int ret;
+	read_lock(&tasklist_lock);
+	ret = group_send_sig_info(sig, info, p);
+	read_unlock(&tasklist_lock);
+	return ret;
+}
+
+void
+force_sig(int sig, struct task_struct *p)
+{
+	force_sig_info(sig, (void*)1L, p);
+}
+
+/*
+ * When things go south during signal handling, we
+ * will force a SIGSEGV. And if the signal that caused
+ * the problem was already a SIGSEGV, we'll want to
+ * make sure we don't even try to deliver the signal..
+ */
+int
+force_sigsegv(int sig, struct task_struct *p)
+{
+	if (sig == SIGSEGV) {
+		unsigned long flags;
+		spin_lock_irqsave(&p->sighand->siglock, flags);
+		p->sighand->action[sig - 1].sa.sa_handler = SIG_DFL;
+		spin_unlock_irqrestore(&p->sighand->siglock, flags);
+	}
+	force_sig(SIGSEGV, p);
+	return 0;
+}
+
+int
+kill_pg(pid_t pgrp, int sig, int priv)
+{
+	return kill_pg_info(sig, (void *)(long)(priv != 0), pgrp);
+}
+
+int
+kill_proc(pid_t pid, int sig, int priv)
+{
+	return kill_proc_info(sig, (void *)(long)(priv != 0), pid);
+}
+
+/*
+ * These functions support sending signals using preallocated sigqueue
+ * structures.  This is needed "because realtime applications cannot
+ * afford to lose notifications of asynchronous events, like timer
+ * expirations or I/O completions".  In the case of Posix Timers 
+ * we allocate the sigqueue structure from the timer_create.  If this
+ * allocation fails we are able to report the failure to the application
+ * with an EAGAIN error.
+ */
+ 
+struct sigqueue *sigqueue_alloc(void)
+{
+	struct sigqueue *q;
+
+	if ((q = __sigqueue_alloc(current, GFP_KERNEL, 0)))
+		q->flags |= SIGQUEUE_PREALLOC;
+	return(q);
+}
+
+void sigqueue_free(struct sigqueue *q)
+{
+	unsigned long flags;
+	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
+	/*
+	 * If the signal is still pending remove it from the
+	 * pending queue.
+	 */
+	if (unlikely(!list_empty(&q->list))) {
+		read_lock(&tasklist_lock);  
+		spin_lock_irqsave(q->lock, flags);
+		if (!list_empty(&q->list))
+			list_del_init(&q->list);
+		spin_unlock_irqrestore(q->lock, flags);
+		read_unlock(&tasklist_lock);
+	}
+	q->flags &= ~SIGQUEUE_PREALLOC;
+	__sigqueue_free(q);
+}
+
+int
+send_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
+{
+	unsigned long flags;
+	int ret = 0;
+
+	/*
+	 * We need the tasklist lock even for the specific
+	 * thread case (when we don't need to follow the group
+	 * lists) in order to avoid races with "p->sighand"
+	 * going away or changing from under us.
+	 */
+	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
+	read_lock(&tasklist_lock);  
+	spin_lock_irqsave(&p->sighand->siglock, flags);
+	
+	if (unlikely(!list_empty(&q->list))) {
+		/*
+		 * If an SI_TIMER entry is already queue just increment
+		 * the overrun count.
+		 */
+		if (q->info.si_code != SI_TIMER)
+			BUG();
+		q->info.si_overrun++;
+		goto out;
+	} 
+	/* Short-circuit ignored signals.  */
+	if (sig_ignored(p, sig)) {
+		ret = 1;
+		goto out;
+	}
+
+	q->lock = &p->sighand->siglock;
+	list_add_tail(&q->list, &p->pending.list);
+	sigaddset(&p->pending.signal, sig);
+	if (!sigismember(&p->blocked, sig))
+		signal_wake_up(p, sig == SIGKILL);
+
+out:
+	spin_unlock_irqrestore(&p->sighand->siglock, flags);
+	read_unlock(&tasklist_lock);
+	return(ret);
+}
+
+int
+send_group_sigqueue(int sig, struct sigqueue *q, struct task_struct *p)
+{
+	unsigned long flags;
+	int ret = 0;
+
+	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));
+	read_lock(&tasklist_lock);
+	spin_lock_irqsave(&p->sighand->siglock, flags);
+	handle_stop_signal(sig, p);
+
+	/* Short-circuit ignored signals.  */
+	if (sig_ignored(p, sig)) {
+		ret = 1;
+		goto out;
+	}
+
+	if (unlikely(!list_empty(&q->list))) {
+		/*
+		 * If an SI_TIMER entry is already queue just increment
+		 * the overrun count.  Other uses should not try to
+		 * send the signal multiple times.
+		 */
+		if (q->info.si_code != SI_TIMER)
+			BUG();
+		q->info.si_overrun++;
+		goto out;
+	} 
+
+	/*
+	 * Put this signal on the shared-pending queue.
+	 * We always use the shared queue for process-wide signals,
+	 * to avoid several races.
+	 */
+	q->lock = &p->sighand->siglock;
+	list_add_tail(&q->list, &p->signal->shared_pending.list);
+	sigaddset(&p->signal->shared_pending.signal, sig);
+
+	__group_complete_signal(sig, p);
+out:
+	spin_unlock_irqrestore(&p->sighand->siglock, flags);
+	read_unlock(&tasklist_lock);
+	return(ret);
+}
+
+/*
+ * Wake up any threads in the parent blocked in wait* syscalls.
+ */
+static inline void __wake_up_parent(struct task_struct *p,
+				    struct task_struct *parent)
+{
+	wake_up_interruptible_sync(&parent->signal->wait_chldexit);
+}
+
+/*
+ * Let a parent know about the death of a child.
+ * For a stopped/continued status change, use do_notify_parent_cldstop instead.
+ */
+
+void do_notify_parent(struct task_struct *tsk, int sig)
+{
+	struct siginfo info;
+	unsigned long flags;
+	struct sighand_struct *psig;
+
+	BUG_ON(sig == -1);
+
+ 	/* do_notify_parent_cldstop should have been called instead.  */
+ 	BUG_ON(tsk->state & (TASK_STOPPED|TASK_TRACED));
+
+	BUG_ON(!tsk->ptrace &&
+	       (tsk->group_leader != tsk || !thread_group_empty(tsk)));
+
+	info.si_signo = sig;
+	info.si_errno = 0;
+	info.si_pid = tsk->pid;
+	info.si_uid = tsk->uid;
+
+	/* FIXME: find out whether or not this is supposed to be c*time. */
+	info.si_utime = cputime_to_jiffies(cputime_add(tsk->utime,
+						       tsk->signal->utime));
+	info.si_stime = cputime_to_jiffies(cputime_add(tsk->stime,
+						       tsk->signal->stime));
+
+	info.si_status = tsk->exit_code & 0x7f;
+	if (tsk->exit_code & 0x80)
+		info.si_code = CLD_DUMPED;
+	else if (tsk->exit_code & 0x7f)
+		info.si_code = CLD_KILLED;
+	else {
+		info.si_code = CLD_EXITED;
+		info.si_status = tsk->exit_code >> 8;
+	}
+
+	psig = tsk->parent->sighand;
+	spin_lock_irqsave(&psig->siglock, flags);
+	if (sig == SIGCHLD &&
+	    (psig->action[SIGCHLD-1].sa.sa_handler == SIG_IGN ||
+	     (psig->action[SIGCHLD-1].sa.sa_flags & SA_NOCLDWAIT))) {
+		/*
+		 * We are exiting and our parent doesn't care.  POSIX.1
+		 * defines special semantics for setting SIGCHLD to SIG_IGN
+		 * or setting the SA_NOCLDWAIT flag: we should be reaped
+		 * automatically and not left for our parent's wait4 call.
+		 * Rather than having the parent do it as a magic kind of
+		 * signal handler, we just set this to tell do_exit that we
+		 * can be cleaned up without becoming a zombie.  Note that
+		 * we still call __wake_up_parent in this case, because a
+		 * blocked sys_wait4 might now return -ECHILD.
+		 *
+		 * Whether we send SIGCHLD or not for SA_NOCLDWAIT
+		 * is implementation-defined: we do (if you don't want
+		 * it, just use SIG_IGN instead).
+		 */
+		tsk->exit_signal = -1;
+		if (psig->action[SIGCHLD-1].sa.sa_handler == SIG_IGN)
+			sig = 0;
+	}
+	if (sig > 0 && sig <= _NSIG)
+		__group_send_sig_info(sig, &info, tsk->parent);
+	__wake_up_parent(tsk, tsk->parent);
+	spin_unlock_irqrestore(&psig->siglock, flags);
+}
+
+static void
+do_notify_parent_cldstop(struct task_struct *tsk, struct task_struct *parent,
+			 int why)
+{
+	struct siginfo info;
+	unsigned long flags;
+	struct sighand_struct *sighand;
+
+	info.si_signo = SIGCHLD;
+	info.si_errno = 0;
+	info.si_pid = tsk->pid;
+	info.si_uid = tsk->uid;
+
+	/* FIXME: find out whether or not this is supposed to be c*time. */
+	info.si_utime = cputime_to_jiffies(tsk->utime);
+	info.si_stime = cputime_to_jiffies(tsk->stime);
+
+ 	info.si_code = why;
+ 	switch (why) {
+ 	case CLD_CONTINUED:
+ 		info.si_status = SIGCONT;
+ 		break;
+ 	case CLD_STOPPED:
+ 		info.si_status = tsk->signal->group_exit_code & 0x7f;
+ 		break;
+ 	case CLD_TRAPPED:
+ 		info.si_status = tsk->exit_code & 0x7f;
+ 		break;
+ 	default:
+ 		BUG();
+ 	}
+
+	sighand = parent->sighand;
+	spin_lock_irqsave(&sighand->siglock, flags);
+	if (sighand->action[SIGCHLD-1].sa.sa_handler != SIG_IGN &&
+	    !(sighand->action[SIGCHLD-1].sa.sa_flags & SA_NOCLDSTOP))
+		__group_send_sig_info(SIGCHLD, &info, parent);
+	/*
+	 * Even if SIGCHLD is not generated, we must wake up wait4 calls.
+	 */
+	__wake_up_parent(tsk, parent);
+	spin_unlock_irqrestore(&sighand->siglock, flags);
+}
+
+/*
+ * This must be called with current->sighand->siglock held.
+ *
+ * This should be the path for all ptrace stops.
+ * We always set current->last_siginfo while stopped here.
+ * That makes it a way to test a stopped process for
+ * being ptrace-stopped vs being job-control-stopped.
+ *
+ * If we actually decide not to stop at all because the tracer is gone,
+ * we leave nostop_code in current->exit_code.
+ */
+static void ptrace_stop(int exit_code, int nostop_code, siginfo_t *info)
+{
+	/*
+	 * If there is a group stop in progress,
+	 * we must participate in the bookkeeping.
+	 */
+	if (current->signal->group_stop_count > 0)
+		--current->signal->group_stop_count;
+
+	current->last_siginfo = info;
+	current->exit_code = exit_code;
+
+	/* Let the debugger run.  */
+	set_current_state(TASK_TRACED);
+	spin_unlock_irq(&current->sighand->siglock);
+	read_lock(&tasklist_lock);
+	if (likely(current->ptrace & PT_PTRACED) &&
+	    likely(current->parent != current->real_parent ||
+		   !(current->ptrace & PT_ATTACHED)) &&
+	    (likely(current->parent->signal != current->signal) ||
+	     !unlikely(current->signal->flags & SIGNAL_GROUP_EXIT))) {
+		do_notify_parent_cldstop(current, current->parent,
+					 CLD_TRAPPED);
+		read_unlock(&tasklist_lock);
+		schedule();
+	} else {
+		/*
+		 * By the time we got the lock, our tracer went away.
+		 * Don't stop here.
+		 */
+		read_unlock(&tasklist_lock);
+		set_current_state(TASK_RUNNING);
+		current->exit_code = nostop_code;
+	}
+
+	/*
+	 * We are back.  Now reacquire the siglock before touching
+	 * last_siginfo, so that we are sure to have synchronized with
+	 * any signal-sending on another CPU that wants to examine it.
+	 */
+	spin_lock_irq(&current->sighand->siglock);
+	current->last_siginfo = NULL;
+
+	/*
+	 * Queued signals ignored us while we were stopped for tracing.
+	 * So check for any that we should take before resuming user mode.
+	 */
+	recalc_sigpending();
+}
+
+void ptrace_notify(int exit_code)
+{
+	siginfo_t info;
+
+	BUG_ON((exit_code & (0x7f | ~0xffff)) != SIGTRAP);
+
+	memset(&info, 0, sizeof info);
+	info.si_signo = SIGTRAP;
+	info.si_code = exit_code;
+	info.si_pid = current->pid;
+	info.si_uid = current->uid;
+
+	/* Let the debugger run.  */
+	spin_lock_irq(&current->sighand->siglock);
+	ptrace_stop(exit_code, 0, &info);
+	spin_unlock_irq(&current->sighand->siglock);
+}
+
+#ifndef HAVE_ARCH_GET_SIGNAL_TO_DELIVER
+
+static void
+finish_stop(int stop_count)
+{
+	/*
+	 * If there are no other threads in the group, or if there is
+	 * a group stop in progress and we are the last to stop,
+	 * report to the parent.  When ptraced, every thread reports itself.
+	 */
+	if (stop_count < 0 || (current->ptrace & PT_PTRACED)) {
+		read_lock(&tasklist_lock);
+		do_notify_parent_cldstop(current, current->parent,
+					 CLD_STOPPED);
+		read_unlock(&tasklist_lock);
+	}
+	else if (stop_count == 0) {
+		read_lock(&tasklist_lock);
+		do_notify_parent_cldstop(current->group_leader,
+					 current->group_leader->real_parent,
+					 CLD_STOPPED);
+		read_unlock(&tasklist_lock);
+	}
+
+	schedule();
+	/*
+	 * Now we don't run again until continued.
+	 */
+	current->exit_code = 0;
+}
+
+/*
+ * This performs the stopping for SIGSTOP and other stop signals.
+ * We have to stop all threads in the thread group.
+ * Returns nonzero if we've actually stopped and released the siglock.
+ * Returns zero if we didn't stop and still hold the siglock.
+ */
+static int
+do_signal_stop(int signr)
+{
+	struct signal_struct *sig = current->signal;
+	struct sighand_struct *sighand = current->sighand;
+	int stop_count = -1;
+
+	if (!likely(sig->flags & SIGNAL_STOP_DEQUEUED))
+		return 0;
+
+	if (sig->group_stop_count > 0) {
+		/*
+		 * There is a group stop in progress.  We don't need to
+		 * start another one.
+		 */
+		signr = sig->group_exit_code;
+		stop_count = --sig->group_stop_count;
+		current->exit_code = signr;
+		set_current_state(TASK_STOPPED);
+		if (stop_count == 0)
+			sig->flags = SIGNAL_STOP_STOPPED;
+		spin_unlock_irq(&sighand->siglock);
+	}
+	else if (thread_group_empty(current)) {
+		/*
+		 * Lock must be held through transition to stopped state.
+		 */
+		current->exit_code = current->signal->group_exit_code = signr;
+		set_current_state(TASK_STOPPED);
+		sig->flags = SIGNAL_STOP_STOPPED;
+		spin_unlock_irq(&sighand->siglock);
+	}
+	else {
+		/*
+		 * There is no group stop already in progress.
+		 * We must initiate one now, but that requires
+		 * dropping siglock to get both the tasklist lock
+		 * and siglock again in the proper order.  Note that
+		 * this allows an intervening SIGCONT to be posted.
+		 * We need to check for that and bail out if necessary.
+		 */
+		struct task_struct *t;
+
+		spin_unlock_irq(&sighand->siglock);
+
+		/* signals can be posted during this window */
+
+		read_lock(&tasklist_lock);
+		spin_lock_irq(&sighand->siglock);
+
+		if (!likely(sig->flags & SIGNAL_STOP_DEQUEUED)) {
+			/*
+			 * Another stop or continue happened while we
+			 * didn't have the lock.  We can just swallow this
+			 * signal now.  If we raced with a SIGCONT, that
+			 * should have just cleared it now.  If we raced
+			 * with another processor delivering a stop signal,
+			 * then the SIGCONT that wakes us up should clear it.
+			 */
+			read_unlock(&tasklist_lock);
+			return 0;
+		}
+
+		if (sig->group_stop_count == 0) {
+			sig->group_exit_code = signr;
+			stop_count = 0;
+			for (t = next_thread(current); t != current;
+			     t = next_thread(t))
+				/*
+				 * Setting state to TASK_STOPPED for a group
+				 * stop is always done with the siglock held,
+				 * so this check has no races.
+				 */
+				if (t->state < TASK_STOPPED) {
+					stop_count++;
+					signal_wake_up(t, 0);
+				}
+			sig->group_stop_count = stop_count;
+		}
+		else {
+			/* A race with another thread while unlocked.  */
+			signr = sig->group_exit_code;
+			stop_count = --sig->group_stop_count;
+		}
+
+		current->exit_code = signr;
+		set_current_state(TASK_STOPPED);
+		if (stop_count == 0)
+			sig->flags = SIGNAL_STOP_STOPPED;
+
+		spin_unlock_irq(&sighand->siglock);
+		read_unlock(&tasklist_lock);
+	}
+
+	finish_stop(stop_count);
+	return 1;
+}
+
+/*
+ * Do appropriate magic when group_stop_count > 0.
+ * We return nonzero if we stopped, after releasing the siglock.
+ * We return zero if we still hold the siglock and should look
+ * for another signal without checking group_stop_count again.
+ */
+static inline int handle_group_stop(void)
+{
+	int stop_count;
+
+	if (current->signal->group_exit_task == current) {
+		/*
+		 * Group stop is so we can do a core dump,
+		 * We are the initiating thread, so get on with it.
+		 */
+		current->signal->group_exit_task = NULL;
+		return 0;
+	}
+
+	if (current->signal->flags & SIGNAL_GROUP_EXIT)
+		/*
+		 * Group stop is so another thread can do a core dump,
+		 * or else we are racing against a death signal.
+		 * Just punt the stop so we can get the next signal.
+		 */
+		return 0;
+
+	/*
+	 * There is a group stop in progress.  We stop
+	 * without any associated signal being in our queue.
+	 */
+	stop_count = --current->signal->group_stop_count;
+	if (stop_count == 0)
+		current->signal->flags = SIGNAL_STOP_STOPPED;
+	current->exit_code = current->signal->group_exit_code;
+	set_current_state(TASK_STOPPED);
+	spin_unlock_irq(&current->sighand->siglock);
+	finish_stop(stop_count);
+	return 1;
+}
+
+int get_signal_to_deliver(siginfo_t *info, struct k_sigaction *return_ka,
+			  struct pt_regs *regs, void *cookie)
+{
+	sigset_t *mask = &current->blocked;
+	int signr = 0;
+
+relock:
+	spin_lock_irq(&current->sighand->siglock);
+	for (;;) {
+		struct k_sigaction *ka;
+
+		if (unlikely(current->signal->group_stop_count > 0) &&
+		    handle_group_stop())
+			goto relock;
+
+		signr = dequeue_signal(current, mask, info);
+
+		if (!signr)
+			break; /* will return 0 */
+
+		if ((current->ptrace & PT_PTRACED) && signr != SIGKILL) {
+			ptrace_signal_deliver(regs, cookie);
+
+			/* Let the debugger run.  */
+			ptrace_stop(signr, signr, info);
+
+			/* We're back.  Did the debugger cancel the sig?  */
+			signr = current->exit_code;
+			if (signr == 0)
+				continue;
+
+			current->exit_code = 0;
+
+			/* Update the siginfo structure if the signal has
+			   changed.  If the debugger wanted something
+			   specific in the siginfo structure then it should
+			   have updated *info via PTRACE_SETSIGINFO.  */
+			if (signr != info->si_signo) {
+				info->si_signo = signr;
+				info->si_errno = 0;
+				info->si_code = SI_USER;
+				info->si_pid = current->parent->pid;
+				info->si_uid = current->parent->uid;
+			}
+
+			/* If the (new) signal is now blocked, requeue it.  */
+			if (sigismember(&current->blocked, signr)) {
+				specific_send_sig_info(signr, info, current);
+				continue;
+			}
+		}
+
+		ka = &current->sighand->action[signr-1];
+		if (ka->sa.sa_handler == SIG_IGN) /* Do nothing.  */
+			continue;
+		if (ka->sa.sa_handler != SIG_DFL) {
+			/* Run the handler.  */
+			*return_ka = *ka;
+
+			if (ka->sa.sa_flags & SA_ONESHOT)
+				ka->sa.sa_handler = SIG_DFL;
+
+			break; /* will return non-zero "signr" value */
+		}
+
+		/*
+		 * Now we are doing the default action for this signal.
+		 */
+		if (sig_kernel_ignore(signr)) /* Default is nothing. */
+			continue;
+
+		/* Init gets no signals it doesn't want.  */
+		if (current->pid == 1)
+			continue;
+
+		if (sig_kernel_stop(signr)) {
+			/*
+			 * The default action is to stop all threads in
+			 * the thread group.  The job control signals
+			 * do nothing in an orphaned pgrp, but SIGSTOP
+			 * always works.  Note that siglock needs to be
+			 * dropped during the call to is_orphaned_pgrp()
+			 * because of lock ordering with tasklist_lock.
+			 * This allows an intervening SIGCONT to be posted.
+			 * We need to check for that and bail out if necessary.
+			 */
+			if (signr != SIGSTOP) {
+				spin_unlock_irq(&current->sighand->siglock);
+
+				/* signals can be posted during this window */
+
+				if (is_orphaned_pgrp(process_group(current)))
+					goto relock;
+
+				spin_lock_irq(&current->sighand->siglock);
+			}
+
+			if (likely(do_signal_stop(signr))) {
+				/* It released the siglock.  */
+				goto relock;
+			}
+
+			/*
+			 * We didn't actually stop, due to a race
+			 * with SIGCONT or something like that.
+			 */
+			continue;
+		}
+
+		spin_unlock_irq(&current->sighand->siglock);
+
+		/*
+		 * Anything else is fatal, maybe with a core dump.
+		 */
+		current->flags |= PF_SIGNALED;
+		if (sig_kernel_coredump(signr)) {
+			/*
+			 * If it was able to dump core, this kills all
+			 * other threads in the group and synchronizes with
+			 * their demise.  If we lost the race with another
+			 * thread getting here, it set group_exit_code
+			 * first and our do_group_exit call below will use
+			 * that value and ignore the one we pass it.
+			 */
+			do_coredump((long)signr, signr, regs);
+		}
+
+		/*
+		 * Death signals, no core dump.
+		 */
+		do_group_exit(signr);
+		/* NOTREACHED */
+	}
+	spin_unlock_irq(&current->sighand->siglock);
+	return signr;
+}
+
+#endif
+
+EXPORT_SYMBOL(recalc_sigpending);
+EXPORT_SYMBOL_GPL(dequeue_signal);
+EXPORT_SYMBOL(flush_signals);
+EXPORT_SYMBOL(force_sig);
+EXPORT_SYMBOL(kill_pg);
+EXPORT_SYMBOL(kill_proc);
+EXPORT_SYMBOL(ptrace_notify);
+EXPORT_SYMBOL(send_sig);
+EXPORT_SYMBOL(send_sig_info);
+EXPORT_SYMBOL(sigprocmask);
+EXPORT_SYMBOL(block_all_signals);
+EXPORT_SYMBOL(unblock_all_signals);
+
+
+/*
+ * System call entry points.
+ */
+
+asmlinkage long sys_restart_syscall(void)
+{
+	struct restart_block *restart = &current_thread_info()->restart_block;
+	return restart->fn(restart);
+}
+
+long do_no_restart_syscall(struct restart_block *param)
+{
+	return -EINTR;
+}
+
+/*
+ * We don't need to get the kernel lock - this is all local to this
+ * particular thread.. (and that's good, because this is _heavily_
+ * used by various programs)
+ */
+
+/*
+ * This is also useful for kernel threads that want to temporarily
+ * (or permanently) block certain signals.
+ *
+ * NOTE! Unlike the user-mode sys_sigprocmask(), the kernel
+ * interface happily blocks "unblockable" signals like SIGKILL
+ * and friends.
+ */
+int sigprocmask(int how, sigset_t *set, sigset_t *oldset)
+{
+	int error;
+	sigset_t old_block;
+
+	spin_lock_irq(&current->sighand->siglock);
+	old_block = current->blocked;
+	error = 0;
+	switch (how) {
+	case SIG_BLOCK:
+		sigorsets(&current->blocked, &current->blocked, set);
+		break;
+	case SIG_UNBLOCK:
+		signandsets(&current->blocked, &current->blocked, set);
+		break;
+	case SIG_SETMASK:
+		current->blocked = *set;
+		break;
+	default:
+		error = -EINVAL;
+	}
+	recalc_sigpending();
+	spin_unlock_irq(&current->sighand->siglock);
+	if (oldset)
+		*oldset = old_block;
+	return error;
+}
+
+asmlinkage long
+sys_rt_sigprocmask(int how, sigset_t __user *set, sigset_t __user *oset, size_t sigsetsize)
+{
+	int error = -EINVAL;
+	sigset_t old_set, new_set;
+
+	/* XXX: Don't preclude handling different sized sigset_t's.  */
+	if (sigsetsize != sizeof(sigset_t))
+		goto out;
+
+	if (set) {
+		error = -EFAULT;
+		if (copy_from_user(&new_set, set, sizeof(*set)))
+			goto out;
+		sigdelsetmask(&new_set, sigmask(SIGKILL)|sigmask(SIGSTOP));
+
+		error = sigprocmask(how, &new_set, &old_set);
+		if (error)
+			goto out;
+		if (oset)
+			goto set_old;
+	} else if (oset) {
+		spin_lock_irq(&current->sighand->siglock);
+		old_set = current->blocked;
+		spin_unlock_irq(&current->sighand->siglock);
+
+	set_old:
+		error = -EFAULT;
+		if (copy_to_user(oset, &old_set, sizeof(*oset)))
+			goto out;
+	}
+	error = 0;
+out:
+	return error;
+}
+
+long do_sigpending(void __user *set, unsigned long sigsetsize)
+{
+	long error = -EINVAL;
+	sigset_t pending;
+
+	if (sigsetsize > sizeof(sigset_t))
+		goto out;
+
+	spin_lock_irq(&current->sighand->siglock);
+	sigorsets(&pending, &current->pending.signal,
+		  &current->signal->shared_pending.signal);
+	spin_unlock_irq(&current->sighand->siglock);
+
+	/* Outside the lock because only this thread touches it.  */
+	sigandsets(&pending, &current->blocked, &pending);
+
+	error = -EFAULT;
+	if (!copy_to_user(set, &pending, sigsetsize))
+		error = 0;
+
+out:
+	return error;
+}	
+
+asmlinkage long
+sys_rt_sigpending(sigset_t __user *set, size_t sigsetsize)
+{
+	return do_sigpending(set, sigsetsize);
+}
+
+#ifndef HAVE_ARCH_COPY_SIGINFO_TO_USER
+
+int copy_siginfo_to_user(siginfo_t __user *to, siginfo_t *from)
+{
+	int err;
+
+	if (!access_ok (VERIFY_WRITE, to, sizeof(siginfo_t)))
+		return -EFAULT;
+	if (from->si_code < 0)
+		return __copy_to_user(to, from, sizeof(siginfo_t))
+			? -EFAULT : 0;
+	/*
+	 * If you change siginfo_t structure, please be sure
+	 * this code is fixed accordingly.
+	 * It should never copy any pad contained in the structure
+	 * to avoid security leaks, but must copy the generic
+	 * 3 ints plus the relevant union member.
+	 */
+	err = __put_user(from->si_signo, &to->si_signo);
+	err |= __put_user(from->si_errno, &to->si_errno);
+	err |= __put_user((short)from->si_code, &to->si_code);
+	switch (from->si_code & __SI_MASK) {
+	case __SI_KILL:
+		err |= __put_user(from->si_pid, &to->si_pid);
+		err |= __put_user(from->si_uid, &to->si_uid);
+		break;
+	case __SI_TIMER:
+		 err |= __put_user(from->si_tid, &to->si_tid);
+		 err |= __put_user(from->si_overrun, &to->si_overrun);
+		 err |= __put_user(from->si_ptr, &to->si_ptr);
+		break;
+	case __SI_POLL:
+		err |= __put_user(from->si_band, &to->si_band);
+		err |= __put_user(from->si_fd, &to->si_fd);
+		break;
+	case __SI_FAULT:
+		err |= __put_user(from->si_addr, &to->si_addr);
+#ifdef __ARCH_SI_TRAPNO
+		err |= __put_user(from->si_trapno, &to->si_trapno);
+#endif
+		break;
+	case __SI_CHLD:
+		err |= __put_user(from->si_pid, &to->si_pid);
+		err |= __put_user(from->si_uid, &to->si_uid);
+		err |= __put_user(from->si_status, &to->si_status);
+		err |= __put_user(from->si_utime, &to->si_utime);
+		err |= __put_user(from->si_stime, &to->si_stime);
+		break;
+	case __SI_RT: /* This is not generated by the kernel as of now. */
+	case __SI_MESGQ: /* But this is */
+		err |= __put_user(from->si_pid, &to->si_pid);
+		err |= __put_user(from->si_uid, &to->si_uid);
+		err |= __put_user(from->si_ptr, &to->si_ptr);
+		break;
+	default: /* this is just in case for now ... */
+		err |= __put_user(from->si_pid, &to->si_pid);
+		err |= __put_user(from->si_uid, &to->si_uid);
+		break;
+	}
+	return err;
+}
+
+#endif
+
+asmlinkage long
+sys_rt_sigtimedwait(const sigset_t __user *uthese,
+		    siginfo_t __user *uinfo,
+		    const struct timespec __user *uts,
+		    size_t sigsetsize)
+{
+	int ret, sig;
+	sigset_t these;
+	struct timespec ts;
+	siginfo_t info;
+	long timeout = 0;
+
+	/* XXX: Don't preclude handling different sized sigset_t's.  */
+	if (sigsetsize != sizeof(sigset_t))
+		return -EINVAL;
+
+	if (copy_from_user(&these, uthese, sizeof(these)))
+		return -EFAULT;
+		
+	/*
+	 * Invert the set of allowed signals to get those we
+	 * want to block.
+	 */
+	sigdelsetmask(&these, sigmask(SIGKILL)|sigmask(SIGSTOP));
+	signotset(&these);
+
+	if (uts) {
+		if (copy_from_user(&ts, uts, sizeof(ts)))
+			return -EFAULT;
+		if (ts.tv_nsec >= 1000000000L || ts.tv_nsec < 0
+		    || ts.tv_sec < 0)
+			return -EINVAL;
+	}
+
+	spin_lock_irq(&current->sighand->siglock);
+	sig = dequeue_signal(current, &these, &info);
+	if (!sig) {
+		timeout = MAX_SCHEDULE_TIMEOUT;
+		if (uts)
+			timeout = (timespec_to_jiffies(&ts)
+				   + (ts.tv_sec || ts.tv_nsec));
+
+		if (timeout) {
+			/* None ready -- temporarily unblock those we're
+			 * interested while we are sleeping in so that we'll
+			 * be awakened when they arrive.  */
+			current->real_blocked = current->blocked;
+			sigandsets(&current->blocked, &current->blocked, &these);
+			recalc_sigpending();
+			spin_unlock_irq(&current->sighand->siglock);
+
+			current->state = TASK_INTERRUPTIBLE;
+			timeout = schedule_timeout(timeout);
+
+			if (current->flags & PF_FREEZE)
+				refrigerator(PF_FREEZE);
+			spin_lock_irq(&current->sighand->siglock);
+			sig = dequeue_signal(current, &these, &info);
+			current->blocked = current->real_blocked;
+			siginitset(&current->real_blocked, 0);
+			recalc_sigpending();
+		}
+	}
+	spin_unlock_irq(&current->sighand->siglock);
+
+	if (sig) {
+		ret = sig;
+		if (uinfo) {
+			if (copy_siginfo_to_user(uinfo, &info))
+				ret = -EFAULT;
+		}
+	} else {
+		ret = -EAGAIN;
+		if (timeout)
+			ret = -EINTR;
+	}
+
+	return ret;
+}
+
+asmlinkage long
+sys_kill(int pid, int sig)
+{
+	struct siginfo info;
+
+	info.si_signo = sig;
+	info.si_errno = 0;
+	info.si_code = SI_USER;
+	info.si_pid = current->tgid;
+	info.si_uid = current->uid;
+
+	return kill_something_info(sig, &info, pid);
+}
+
+/**
+ *  sys_tgkill - send signal to one specific thread
+ *  @tgid: the thread group ID of the thread
+ *  @pid: the PID of the thread
+ *  @sig: signal to be sent
+ *
+ *  This syscall also checks the tgid and returns -ESRCH even if the PID
+ *  exists but it's not belonging to the target process anymore. This
+ *  method solves the problem of threads exiting and PIDs getting reused.
+ */
+asmlinkage long sys_tgkill(int tgid, int pid, int sig)
+{
+	struct siginfo info;
+	int error;
+	struct task_struct *p;
+
+	/* This is only valid for single tasks */
+	if (pid <= 0 || tgid <= 0)
+		return -EINVAL;
+
+	info.si_signo = sig;
+	info.si_errno = 0;
+	info.si_code = SI_TKILL;
+	info.si_pid = current->tgid;
+	info.si_uid = current->uid;
+
+	read_lock(&tasklist_lock);
+	p = find_task_by_pid(pid);
+	error = -ESRCH;
+	if (p && (p->tgid == tgid)) {
+		error = check_kill_permission(sig, &info, p);
+		/*
+		 * The null signal is a permissions and process existence
+		 * probe.  No signal is actually delivered.
+		 */
+		if (!error && sig && p->sighand) {
+			spin_lock_irq(&p->sighand->siglock);
+			handle_stop_signal(sig, p);
+			error = specific_send_sig_info(sig, &info, p);
+			spin_unlock_irq(&p->sighand->siglock);
+		}
+	}
+	read_unlock(&tasklist_lock);
+	return error;
+}
+
+/*
+ *  Send a signal to only one task, even if it's a CLONE_THREAD task.
+ */
+asmlinkage long
+sys_tkill(int pid, int sig)
+{
+	struct siginfo info;
+	int error;
+	struct task_struct *p;
+
+	/* This is only valid for single tasks */
+	if (pid <= 0)
+		return -EINVAL;
+
+	info.si_signo = sig;
+	info.si_errno = 0;
+	info.si_code = SI_TKILL;
+	info.si_pid = current->tgid;
+	info.si_uid = current->uid;
+
+	read_lock(&tasklist_lock);
+	p = find_task_by_pid(pid);
+	error = -ESRCH;
+	if (p) {
+		error = check_kill_permission(sig, &info, p);
+		/*
+		 * The null signal is a permissions and process existence
+		 * probe.  No signal is actually delivered.
+		 */
+		if (!error && sig && p->sighand) {
+			spin_lock_irq(&p->sighand->siglock);
+			handle_stop_signal(sig, p);
+			error = specific_send_sig_info(sig, &info, p);
+			spin_unlock_irq(&p->sighand->siglock);
+		}
+	}
+	read_unlock(&tasklist_lock);
+	return error;
+}
+
+asmlinkage long
+sys_rt_sigqueueinfo(int pid, int sig, siginfo_t __user *uinfo)
+{
+	siginfo_t info;
+
+	if (copy_from_user(&info, uinfo, sizeof(siginfo_t)))
+		return -EFAULT;
+
+	/* Not even root can pretend to send signals from the kernel.
+	   Nor can they impersonate a kill(), which adds source info.  */
+	if (info.si_code >= 0)
+		return -EPERM;
+	info.si_signo = sig;
+
+	/* POSIX.1b doesn't mention process groups.  */
+	return kill_proc_info(sig, &info, pid);
+}
+
+int
+do_sigaction(int sig, const struct k_sigaction *act, struct k_sigaction *oact)
+{
+	struct k_sigaction *k;
+
+	if (sig < 1 || sig > _NSIG || (act && sig_kernel_only(sig)))
+		return -EINVAL;
+
+	k = &current->sighand->action[sig-1];
+
+	spin_lock_irq(&current->sighand->siglock);
+	if (signal_pending(current)) {
+		/*
+		 * If there might be a fatal signal pending on multiple
+		 * threads, make sure we take it before changing the action.
+		 */
+		spin_unlock_irq(&current->sighand->siglock);
+		return -ERESTARTNOINTR;
+	}
+
+	if (oact)
+		*oact = *k;
+
+	if (act) {
+		/*
+		 * POSIX 3.3.1.3:
+		 *  "Setting a signal action to SIG_IGN for a signal that is
+		 *   pending shall cause the pending signal to be discarded,
+		 *   whether or not it is blocked."
+		 *
+		 *  "Setting a signal action to SIG_DFL for a signal that is
+		 *   pending and whose default action is to ignore the signal
+		 *   (for example, SIGCHLD), shall cause the pending signal to
+		 *   be discarded, whether or not it is blocked"
+		 */
+		if (act->sa.sa_handler == SIG_IGN ||
+		    (act->sa.sa_handler == SIG_DFL &&
+		     sig_kernel_ignore(sig))) {
+			/*
+			 * This is a fairly rare case, so we only take the
+			 * tasklist_lock once we're sure we'll need it.
+			 * Now we must do this little unlock and relock
+			 * dance to maintain the lock hierarchy.
+			 */
+			struct task_struct *t = current;
+			spin_unlock_irq(&t->sighand->siglock);
+			read_lock(&tasklist_lock);
+			spin_lock_irq(&t->sighand->siglock);
+			*k = *act;
+			sigdelsetmask(&k->sa.sa_mask,
+				      sigmask(SIGKILL) | sigmask(SIGSTOP));
+			rm_from_queue(sigmask(sig), &t->signal->shared_pending);
+			do {
+				rm_from_queue(sigmask(sig), &t->pending);
+				recalc_sigpending_tsk(t);
+				t = next_thread(t);
+			} while (t != current);
+			spin_unlock_irq(&current->sighand->siglock);
+			read_unlock(&tasklist_lock);
+			return 0;
+		}
+
+		*k = *act;
+		sigdelsetmask(&k->sa.sa_mask,
+			      sigmask(SIGKILL) | sigmask(SIGSTOP));
+	}
+
+	spin_unlock_irq(&current->sighand->siglock);
+	return 0;
+}
+
+int 
+do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long sp)
+{
+	stack_t oss;
+	int error;
+
+	if (uoss) {
+		oss.ss_sp = (void __user *) current->sas_ss_sp;
+		oss.ss_size = current->sas_ss_size;
+		oss.ss_flags = sas_ss_flags(sp);
+	}
+
+	if (uss) {
+		void __user *ss_sp;
+		size_t ss_size;
+		int ss_flags;
+
+		error = -EFAULT;
+		if (!access_ok(VERIFY_READ, uss, sizeof(*uss))
+		    || __get_user(ss_sp, &uss->ss_sp)
+		    || __get_user(ss_flags, &uss->ss_flags)
+		    || __get_user(ss_size, &uss->ss_size))
+			goto out;
+
+		error = -EPERM;
+		if (on_sig_stack(sp))
+			goto out;
+
+		error = -EINVAL;
+		/*
+		 *
+		 * Note - this code used to test ss_flags incorrectly
+		 *  	  old code may have been written using ss_flags==0
+		 *	  to mean ss_flags==SS_ONSTACK (as this was the only
+		 *	  way that worked) - this fix preserves that older
+		 *	  mechanism
+		 */
+		if (ss_flags != SS_DISABLE && ss_flags != SS_ONSTACK && ss_flags != 0)
+			goto out;
+
+		if (ss_flags == SS_DISABLE) {
+			ss_size = 0;
+			ss_sp = NULL;
+		} else {
+			error = -ENOMEM;
+			if (ss_size < MINSIGSTKSZ)
+				goto out;
+		}
+
+		current->sas_ss_sp = (unsigned long) ss_sp;
+		current->sas_ss_size = ss_size;
+	}
+
+	if (uoss) {
+		error = -EFAULT;
+		if (copy_to_user(uoss, &oss, sizeof(oss)))
+			goto out;
+	}
+
+	error = 0;
+out:
+	return error;
+}
+
+#ifdef __ARCH_WANT_SYS_SIGPENDING
+
+asmlinkage long
+sys_sigpending(old_sigset_t __user *set)
+{
+	return do_sigpending(set, sizeof(*set));
+}
+
+#endif
+
+#ifdef __ARCH_WANT_SYS_SIGPROCMASK
+/* Some platforms have their own version with special arguments others
+   support only sys_rt_sigprocmask.  */
+
+asmlinkage long
+sys_sigprocmask(int how, old_sigset_t __user *set, old_sigset_t __user *oset)
+{
+	int error;
+	old_sigset_t old_set, new_set;
+
+	if (set) {
+		error = -EFAULT;
+		if (copy_from_user(&new_set, set, sizeof(*set)))
+			goto out;
+		new_set &= ~(sigmask(SIGKILL) | sigmask(SIGSTOP));
+
+		spin_lock_irq(&current->sighand->siglock);
+		old_set = current->blocked.sig[0];
+
+		error = 0;
+		switch (how) {
+		default:
+			error = -EINVAL;
+			break;
+		case SIG_BLOCK:
+			sigaddsetmask(&current->blocked, new_set);
+			break;
+		case SIG_UNBLOCK:
+			sigdelsetmask(&current->blocked, new_set);
+			break;
+		case SIG_SETMASK:
+			current->blocked.sig[0] = new_set;
+			break;
+		}
+
+		recalc_sigpending();
+		spin_unlock_irq(&current->sighand->siglock);
+		if (error)
+			goto out;
+		if (oset)
+			goto set_old;
+	} else if (oset) {
+		old_set = current->blocked.sig[0];
+	set_old:
+		error = -EFAULT;
+		if (copy_to_user(oset, &old_set, sizeof(*oset)))
+			goto out;
+	}
+	error = 0;
+out:
+	return error;
+}
+#endif /* __ARCH_WANT_SYS_SIGPROCMASK */
+
+#ifdef __ARCH_WANT_SYS_RT_SIGACTION
+asmlinkage long
+sys_rt_sigaction(int sig,
+		 const struct sigaction __user *act,
+		 struct sigaction __user *oact,
+		 size_t sigsetsize)
+{
+	struct k_sigaction new_sa, old_sa;
+	int ret = -EINVAL;
+
+	/* XXX: Don't preclude handling different sized sigset_t's.  */
+	if (sigsetsize != sizeof(sigset_t))
+		goto out;
+
+	if (act) {
+		if (copy_from_user(&new_sa.sa, act, sizeof(new_sa.sa)))
+			return -EFAULT;
+	}
+
+	ret = do_sigaction(sig, act ? &new_sa : NULL, oact ? &old_sa : NULL);
+
+	if (!ret && oact) {
+		if (copy_to_user(oact, &old_sa.sa, sizeof(old_sa.sa)))
+			return -EFAULT;
+	}
+out:
+	return ret;
+}
+#endif /* __ARCH_WANT_SYS_RT_SIGACTION */
+
+#ifdef __ARCH_WANT_SYS_SGETMASK
+
+/*
+ * For backwards compatibility.  Functionality superseded by sigprocmask.
+ */
+asmlinkage long
+sys_sgetmask(void)
+{
+	/* SMP safe */
+	return current->blocked.sig[0];
+}
+
+asmlinkage long
+sys_ssetmask(int newmask)
+{
+	int old;
+
+	spin_lock_irq(&current->sighand->siglock);
+	old = current->blocked.sig[0];
+
+	siginitset(&current->blocked, newmask & ~(sigmask(SIGKILL)|
+						  sigmask(SIGSTOP)));
+	recalc_sigpending();
+	spin_unlock_irq(&current->sighand->siglock);
+
+	return old;
+}
+#endif /* __ARCH_WANT_SGETMASK */
+
+#ifdef __ARCH_WANT_SYS_SIGNAL
+/*
+ * For backwards compatibility.  Functionality superseded by sigaction.
+ */
+asmlinkage unsigned long
+sys_signal(int sig, __sighandler_t handler)
+{
+	struct k_sigaction new_sa, old_sa;
+	int ret;
+
+	new_sa.sa.sa_handler = handler;
+	new_sa.sa.sa_flags = SA_ONESHOT | SA_NOMASK;
+
+	ret = do_sigaction(sig, &new_sa, &old_sa);
+
+	return ret ? ret : (unsigned long)old_sa.sa.sa_handler;
+}
+#endif /* __ARCH_WANT_SYS_SIGNAL */
+
+#ifdef __ARCH_WANT_SYS_PAUSE
+
+asmlinkage long
+sys_pause(void)
+{
+	current->state = TASK_INTERRUPTIBLE;
+	schedule();
+	return -ERESTARTNOHAND;
+}
+
+#endif
+
+void __init signals_init(void)
+{
+	sigqueue_cachep =
+		kmem_cache_create("sigqueue",
+				  sizeof(struct sigqueue),
+				  __alignof__(struct sigqueue),
+				  SLAB_PANIC, NULL, NULL);
+}
