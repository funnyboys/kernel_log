commit 63174f61dfaef58dc0e813eaf6602636794f8942
Author: Nathan Chancellor <natechancellor@gmail.com>
Date:   Mon Apr 6 20:09:27 2020 -0700

    kernel/extable.c: use address-of operator on section symbols
    
    Clang warns:
    
    ../kernel/extable.c:37:52: warning: array comparison always evaluates to
    a constant [-Wtautological-compare]
            if (main_extable_sort_needed && __stop___ex_table > __start___ex_table) {
                                                              ^
    1 warning generated.
    
    These are not true arrays, they are linker defined symbols, which are just
    addresses.  Using the address of operator silences the warning and does
    not change the resulting assembly with either clang/ld.lld or gcc/ld
    (tested with diff + objdump -Dr).
    
    Suggested-by: Nick Desaulniers <ndesaulniers@google.com>
    Signed-off-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Link: https://github.com/ClangBuiltLinux/linux/issues/892
    Link: http://lkml.kernel.org/r/20200219202036.45702-1-natechancellor@gmail.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index 7681f87e89dd..b0ea5eb0c3b4 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -34,7 +34,8 @@ u32 __initdata __visible main_extable_sort_needed = 1;
 /* Sort the kernel's built-in exception table */
 void __init sort_main_extable(void)
 {
-	if (main_extable_sort_needed && __stop___ex_table > __start___ex_table) {
+	if (main_extable_sort_needed &&
+	    &__stop___ex_table > &__start___ex_table) {
 		pr_notice("Sorting __ex_table...\n");
 		sort_extable(__start___ex_table, __stop___ex_table);
 	}

commit 7ac88eba185b4d0e06a71678e54bc092edcd3af3
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Thu Mar 12 20:56:07 2020 +0100

    bpf: Remove bpf_image tree
    
    Now that we have all the objects (bpf_prog, bpf_trampoline,
    bpf_dispatcher) linked in bpf_tree, there's no need to have
    separate bpf_image tree for images.
    
    Reverting the bpf_image tree together with struct bpf_image,
    because it's no longer needed.
    
    Also removing bpf_image_alloc function and adding the original
    bpf_jit_alloc_exec_page interface instead.
    
    The kernel_text_address function can now rely only on is_bpf_text_address,
    because it checks the bpf_tree that contains all the objects.
    
    Keeping bpf_image_ksym_add and bpf_image_ksym_del because they are
    useful wrappers with perf's ksymbol interface calls.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/bpf/20200312195610.346362-13-jolsa@kernel.org
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index a0024f27d3a1..7681f87e89dd 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -149,8 +149,6 @@ int kernel_text_address(unsigned long addr)
 		goto out;
 	if (is_bpf_text_address(addr))
 		goto out;
-	if (is_bpf_image_address(addr))
-		goto out;
 	ret = 0;
 out:
 	if (no_rcu)

commit e9b4e606c2289d6610113253922bb8c9ac7f68b0
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Thu Jan 23 17:15:07 2020 +0100

    bpf: Allow to resolve bpf trampoline and dispatcher in unwind
    
    When unwinding the stack we need to identify each address
    to successfully continue. Adding latch tree to keep trampolines
    for quick lookup during the unwind.
    
    The patch uses first 48 bytes for latch tree node, leaving 4048
    bytes from the rest of the page for trampoline or dispatcher
    generated code.
    
    It's still enough not to affect trampoline and dispatcher progs
    maximum counts.
    
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/bpf/20200123161508.915203-3-jolsa@kernel.org

diff --git a/kernel/extable.c b/kernel/extable.c
index f6920a11e28a..a0024f27d3a1 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -131,8 +131,9 @@ int kernel_text_address(unsigned long addr)
 	 * triggers a stack trace, or a WARN() that happens during
 	 * coming back from idle, or cpu on or offlining.
 	 *
-	 * is_module_text_address() as well as the kprobe slots
-	 * and is_bpf_text_address() require RCU to be watching.
+	 * is_module_text_address() as well as the kprobe slots,
+	 * is_bpf_text_address() and is_bpf_image_address require
+	 * RCU to be watching.
 	 */
 	no_rcu = !rcu_is_watching();
 
@@ -148,6 +149,8 @@ int kernel_text_address(unsigned long addr)
 		goto out;
 	if (is_bpf_text_address(addr))
 		goto out;
+	if (is_bpf_image_address(addr))
+		goto out;
 	ret = 0;
 out:
 	if (no_rcu)

commit 3dec541b2e632d630fe7142ed44f0b3702ef1f8c
Author: Alexei Starovoitov <ast@kernel.org>
Date:   Tue Oct 15 20:25:03 2019 -0700

    bpf: Add support for BTF pointers to x86 JIT
    
    Pointer to BTF object is a pointer to kernel object or NULL.
    Such pointers can only be used by BPF_LDX instructions.
    The verifier changed their opcode from LDX|MEM|size
    to LDX|PROBE_MEM|size to make JITing easier.
    The number of entries in extable is the number of BPF_LDX insns
    that access kernel memory via "pointer to BTF type".
    Only these load instructions can fault.
    Since x86 extable is relative it has to be allocated in the same
    memory region as JITed code.
    Allocate it prior to last pass of JITing and let the last pass populate it.
    Pointer to extable in bpf_prog_aux is necessary to make page fault
    handling fast.
    Page fault handling is done in two steps:
    1. bpf_prog_kallsyms_find() finds BPF program that page faulted.
       It's done by walking rb tree.
    2. then extable for given bpf program is binary searched.
    This process is similar to how page faulting is done for kernel modules.
    The exception handler skips over faulting x86 instruction and
    initializes destination register with zero. This mimics exact
    behavior of bpf_probe_read (when probe_kernel_read faults dest is zeroed).
    
    JITs for other architectures can add support in similar way.
    Until then they will reject unknown opcode and fallback to interpreter.
    
    Since extable should be aligned and placed near JITed code
    make bpf_jit_binary_alloc() return 4 byte aligned image offset,
    so that extable aligning formula in bpf_int_jit_compile() doesn't need
    to rely on internal implementation of bpf_jit_binary_alloc().
    On x86 gcc defaults to 16-byte alignment for regular kernel functions
    due to better performance. JITed code may be aligned to 16 in the future,
    but it will use 4 in the meantime.
    
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Andrii Nakryiko <andriin@fb.com>
    Acked-by: Martin KaFai Lau <kafai@fb.com>
    Link: https://lore.kernel.org/bpf/20191016032505.2089704-10-ast@kernel.org

diff --git a/kernel/extable.c b/kernel/extable.c
index f6c9406eec7d..f6920a11e28a 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -56,6 +56,8 @@ const struct exception_table_entry *search_exception_tables(unsigned long addr)
 	e = search_kernel_exception_table(addr);
 	if (!e)
 		e = search_module_extables(addr);
+	if (!e)
+		e = search_bpf_extables(addr);
 	return e;
 }
 

commit 49ec9177b8ec9c081850744468811e708a7c9841
Author: Santosh Sivaraj <santosh@fossix.org>
Date:   Tue Aug 20 13:43:49 2019 +0530

    extable: Add function to search only kernel exception table
    
    Certain architecture specific operating modes (e.g., in powerpc machine
    check handler that is unable to access vmalloc memory), the
    search_exception_tables cannot be called because it also searches the
    module exception tables if entry is not found in the kernel exception
    table.
    
    Signed-off-by: Santosh Sivaraj <santosh@fossix.org>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190820081352.8641-5-santosh@fossix.org

diff --git a/kernel/extable.c b/kernel/extable.c
index e23cce6e6092..f6c9406eec7d 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -40,13 +40,20 @@ void __init sort_main_extable(void)
 	}
 }
 
+/* Given an address, look for it in the kernel exception table */
+const
+struct exception_table_entry *search_kernel_exception_table(unsigned long addr)
+{
+	return search_extable(__start___ex_table,
+			      __stop___ex_table - __start___ex_table, addr);
+}
+
 /* Given an address, look for it in the exception tables. */
 const struct exception_table_entry *search_exception_tables(unsigned long addr)
 {
 	const struct exception_table_entry *e;
 
-	e = search_extable(__start___ex_table,
-			   __stop___ex_table - __start___ex_table, addr);
+	e = search_kernel_exception_table(addr);
 	if (!e)
 		e = search_module_extables(addr);
 	return e;

commit 1a59d1b8e05ea6ab45f7e18897de1ef0e6bc3da6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:05 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 156
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version this program is distributed in the
      hope that it will be useful but without any warranty without even
      the implied warranty of merchantability or fitness for a particular
      purpose see the gnu general public license for more details you
      should have received a copy of the gnu general public license along
      with this program if not write to the free software foundation inc
      59 temple place suite 330 boston ma 02111 1307 usa
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 1334 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Richard Fontana <rfontana@redhat.com>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070033.113240726@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index 6a5b61ebc66c..e23cce6e6092 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -1,19 +1,7 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /* Rewritten by Rusty Russell, on the backs of many others...
    Copyright (C) 2001 Rusty Russell, 2002 Rusty Russell IBM.
 
-    This program is free software; you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation; either version 2 of the License, or
-    (at your option) any later version.
-
-    This program is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with this program; if not, write to the Free Software
-    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
 */
 #include <linux/ftrace.h>
 #include <linux/memory.h>

commit 9fbcc57aa16424ef84cb54e0d9db3221763de88a
Author: Josh Poimboeuf <jpoimboe@redhat.com>
Date:   Tue Feb 20 11:37:53 2018 -0600

    extable: Make init_kernel_text() global
    
    Convert init_kernel_text() to a global function and use it in a few
    places instead of manually comparing _sinittext and _einittext.
    
    Note that kallsyms.h has a very similar function called
    is_kernel_inittext(), but its end check is inclusive.  I'm not sure
    whether that's intentional behavior, so I didn't touch it.
    
    Suggested-by: Jason Baron <jbaron@akamai.com>
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Acked-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/4335d02be8d45ca7d265d2f174251d0b7ee6c5fd.1519051220.git.jpoimboe@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index a17fdb63dc3e..6a5b61ebc66c 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -64,7 +64,7 @@ const struct exception_table_entry *search_exception_tables(unsigned long addr)
 	return e;
 }
 
-static inline int init_kernel_text(unsigned long addr)
+int init_kernel_text(unsigned long addr)
 {
 	if (addr >= (unsigned long)_sinittext &&
 	    addr < (unsigned long)_einittext)

commit e846d13958066828a9483d862cc8370a72fadbb6
Author: Zhou Chengming <zhouchengming1@huawei.com>
Date:   Thu Nov 2 09:18:21 2017 +0800

    kprobes, x86/alternatives: Use text_mutex to protect smp_alt_modules
    
    We use alternatives_text_reserved() to check if the address is in
    the fixed pieces of alternative reserved, but the problem is that
    we don't hold the smp_alt mutex when call this function. So the list
    traversal may encounter a deleted list_head if another path is doing
    alternatives_smp_module_del().
    
    One solution is that we can hold smp_alt mutex before call this
    function, but the difficult point is that the callers of this
    functions, arch_prepare_kprobe() and arch_prepare_optimized_kprobe(),
    are called inside the text_mutex. So we must hold smp_alt mutex
    before we go into these arch dependent code. But we can't now,
    the smp_alt mutex is the arch dependent part, only x86 has it.
    Maybe we can export another arch dependent callback to solve this.
    
    But there is a simpler way to handle this problem. We can reuse the
    text_mutex to protect smp_alt_modules instead of using another mutex.
    And all the arch dependent checks of kprobes are inside the text_mutex,
    so it's safe now.
    
    Signed-off-by: Zhou Chengming <zhouchengming1@huawei.com>
    Reviewed-by: Masami Hiramatsu <mhiramat@kernel.org>
    Acked-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: bp@suse.de
    Fixes: 2cfa197 "ftrace/alternatives: Introducing *_text_reserved functions"
    Link: http://lkml.kernel.org/r/1509585501-79466-1-git-send-email-zhouchengming1@huawei.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index 9aa1cc41ecf7..a17fdb63dc3e 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -31,6 +31,8 @@
  * mutex protecting text section modification (dynamic code patching).
  * some users need to sleep (allocating memory...) while they hold this lock.
  *
+ * Note: Also protects SMP-alternatives modification on x86.
+ *
  * NOT exported to modules - patching kernel text is a really delicate matter.
  */
 DEFINE_MUTEX(text_mutex);

commit e8cac8b1d10589be45671a5ade0926a639b543b7
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Fri Sep 22 17:36:32 2017 -0400

    extable: Enable RCU if it is not watching in kernel_text_address()
    
    If kernel_text_address() is called when RCU is not watching, it can cause an
    RCU bug because is_module_text_address(), the is_kprobe_*insn_slot()
    and is_bpf_text_address() functions require the use of RCU.
    
    Only enable RCU if it is not currently watching before it calls
    is_module_text_address(). The use of rcu_nmi_enter() is used to enable RCU
    because kernel_text_address() can happen pretty much anywhere (like an NMI),
    and even from within an NMI. It is called via save_stack_trace() that can be
    called by any WARN() or tracing function, which can happen while RCU is not
    watching (for example, going to or coming from idle, or during CPU take down
    or bring up).
    
    Cc: stable@vger.kernel.org
    Fixes: 0be964be0 ("module: Sanitize RCU usage and locking")
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index a7024a494faf..9aa1cc41ecf7 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -119,17 +119,42 @@ int __kernel_text_address(unsigned long addr)
 
 int kernel_text_address(unsigned long addr)
 {
+	bool no_rcu;
+	int ret = 1;
+
 	if (core_kernel_text(addr))
 		return 1;
+
+	/*
+	 * If a stack dump happens while RCU is not watching, then
+	 * RCU needs to be notified that it requires to start
+	 * watching again. This can happen either by tracing that
+	 * triggers a stack trace, or a WARN() that happens during
+	 * coming back from idle, or cpu on or offlining.
+	 *
+	 * is_module_text_address() as well as the kprobe slots
+	 * and is_bpf_text_address() require RCU to be watching.
+	 */
+	no_rcu = !rcu_is_watching();
+
+	/* Treat this like an NMI as it can happen anywhere */
+	if (no_rcu)
+		rcu_nmi_enter();
+
 	if (is_module_text_address(addr))
-		return 1;
+		goto out;
 	if (is_ftrace_trampoline(addr))
-		return 1;
+		goto out;
 	if (is_kprobe_optinsn_slot(addr) || is_kprobe_insn_slot(addr))
-		return 1;
+		goto out;
 	if (is_bpf_text_address(addr))
-		return 1;
-	return 0;
+		goto out;
+	ret = 0;
+out:
+	if (no_rcu)
+		rcu_nmi_exit();
+
+	return ret;
 }
 
 /*

commit 9aadde91b3c035413c806619beb3e3ef6e697953
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Fri Sep 22 17:22:19 2017 -0400

    extable: Consolidate *kernel_text_address() functions
    
    The functionality between kernel_text_address() and _kernel_text_address()
    is the same except that _kernel_text_address() does a little more (that
    function needs a rename, but that can be done another time). Instead of
    having duplicate code in both, simply have _kernel_text_address() calls
    kernel_text_address() instead.
    
    This is marked for stable because there's an RCU bug that can happen if
    one of these functions gets called while RCU is not watching. That fix
    depends on this fix to keep from having to write the fix twice.
    
    Cc: stable@vger.kernel.org
    Fixes: 0be964be0 ("module: Sanitize RCU usage and locking")
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index 38c2412401a1..a7024a494faf 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -102,15 +102,7 @@ int core_kernel_data(unsigned long addr)
 
 int __kernel_text_address(unsigned long addr)
 {
-	if (core_kernel_text(addr))
-		return 1;
-	if (is_module_text_address(addr))
-		return 1;
-	if (is_ftrace_trampoline(addr))
-		return 1;
-	if (is_kprobe_optinsn_slot(addr) || is_kprobe_insn_slot(addr))
-		return 1;
-	if (is_bpf_text_address(addr))
+	if (kernel_text_address(addr))
 		return 1;
 	/*
 	 * There might be init symbols in saved stacktraces.

commit a94c33dd1f677d16c4f1a162b4b3e9eba1b07c24
Author: Thomas Meyer <thomas@m3y3r.de>
Date:   Mon Jul 10 15:51:58 2017 -0700

    lib/extable.c: use bsearch() library function in search_extable()
    
    [thomas@m3y3r.de: v3: fix arch specific implementations]
      Link: http://lkml.kernel.org/r/1497890858.12931.7.camel@m3y3r.de
    Signed-off-by: Thomas Meyer <thomas@m3y3r.de>
    Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index 223df4a328a4..38c2412401a1 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -55,7 +55,8 @@ const struct exception_table_entry *search_exception_tables(unsigned long addr)
 {
 	const struct exception_table_entry *e;
 
-	e = search_extable(__start___ex_table, __stop___ex_table-1, addr);
+	e = search_extable(__start___ex_table,
+			   __stop___ex_table - __start___ex_table, addr);
 	if (!e)
 		e = search_module_extables(addr);
 	return e;

commit c0d80ddab89916273cb97114889d3f337bc370ae
Author: Marcin Nowakowski <marcin.nowakowski@imgtec.com>
Date:   Thu Jul 6 15:35:31 2017 -0700

    kernel/extable.c: mark core_kernel_text notrace
    
    core_kernel_text is used by MIPS in its function graph trace processing,
    so having this method traced leads to an infinite set of recursive calls
    such as:
    
      Call Trace:
         ftrace_return_to_handler+0x50/0x128
         core_kernel_text+0x10/0x1b8
         prepare_ftrace_return+0x6c/0x114
         ftrace_graph_caller+0x20/0x44
         return_to_handler+0x10/0x30
         return_to_handler+0x0/0x30
         return_to_handler+0x0/0x30
         ftrace_ops_no_ops+0x114/0x1bc
         core_kernel_text+0x10/0x1b8
         core_kernel_text+0x10/0x1b8
         core_kernel_text+0x10/0x1b8
         ftrace_ops_no_ops+0x114/0x1bc
         core_kernel_text+0x10/0x1b8
         prepare_ftrace_return+0x6c/0x114
         ftrace_graph_caller+0x20/0x44
         (...)
    
    Mark the function notrace to avoid it being traced.
    
    Link: http://lkml.kernel.org/r/1498028607-6765-1-git-send-email-marcin.nowakowski@imgtec.com
    Signed-off-by: Marcin Nowakowski <marcin.nowakowski@imgtec.com>
    Reviewed-by: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Meyer <thomas@m3y3r.de>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index 0fbdd8582f08..223df4a328a4 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -69,7 +69,7 @@ static inline int init_kernel_text(unsigned long addr)
 	return 0;
 }
 
-int core_kernel_text(unsigned long addr)
+int notrace core_kernel_text(unsigned long addr)
 {
 	if (addr >= (unsigned long)_stext &&
 	    addr < (unsigned long)_etext)

commit 0594729c24d846889408a07057b5cc9e8d931419
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue May 16 20:42:44 2017 +0200

    extable: Adjust system_state checks
    
    To enable smp_processor_id() and might_sleep() debug checks earlier, it's
    required to add system states between SYSTEM_BOOTING and SYSTEM_RUNNING.
    
    Adjust the system_state check in core_kernel_text() to handle the extra
    states, i.e. to cover init text up to the point where the system switches
    to state RUNNING.
    
    Tested-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20170516184735.949992741@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index 2676d7f8baf6..0fbdd8582f08 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -75,7 +75,7 @@ int core_kernel_text(unsigned long addr)
 	    addr < (unsigned long)_etext)
 		return 1;
 
-	if (system_state == SYSTEM_BOOTING &&
+	if (system_state < SYSTEM_RUNNING &&
 	    init_kernel_text(addr))
 		return 1;
 	return 0;

commit 3051bf36c25d5153051704291782f8d44e744d36
Merge: 1e74a2eb1f5c 005c3490e9db
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Feb 22 10:15:09 2017 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking updates from David Miller:
     "Highlights:
    
       1) Support TX_RING in AF_PACKET TPACKET_V3 mode, from Sowmini
          Varadhan.
    
       2) Simplify classifier state on sk_buff in order to shrink it a bit.
          From Willem de Bruijn.
    
       3) Introduce SIPHASH and it's usage for secure sequence numbers and
          syncookies. From Jason A. Donenfeld.
    
       4) Reduce CPU usage for ICMP replies we are going to limit or
          suppress, from Jesper Dangaard Brouer.
    
       5) Introduce Shared Memory Communications socket layer, from Ursula
          Braun.
    
       6) Add RACK loss detection and allow it to actually trigger fast
          recovery instead of just assisting after other algorithms have
          triggered it. From Yuchung Cheng.
    
       7) Add xmit_more and BQL support to mvneta driver, from Simon Guinot.
    
       8) skb_cow_data avoidance in esp4 and esp6, from Steffen Klassert.
    
       9) Export MPLS packet stats via netlink, from Robert Shearman.
    
      10) Significantly improve inet port bind conflict handling, especially
          when an application is restarted and changes it's setting of
          reuseport. From Josef Bacik.
    
      11) Implement TX batching in vhost_net, from Jason Wang.
    
      12) Extend the dummy device so that VF (virtual function) features,
          such as configuration, can be more easily tested. From Phil
          Sutter.
    
      13) Avoid two atomic ops per page on x86 in bnx2x driver, from Eric
          Dumazet.
    
      14) Add new bpf MAP, implementing a longest prefix match trie. From
          Daniel Mack.
    
      15) Packet sample offloading support in mlxsw driver, from Yotam Gigi.
    
      16) Add new aquantia driver, from David VomLehn.
    
      17) Add bpf tracepoints, from Daniel Borkmann.
    
      18) Add support for port mirroring to b53 and bcm_sf2 drivers, from
          Florian Fainelli.
    
      19) Remove custom busy polling in many drivers, it is done in the core
          networking since 4.5 times. From Eric Dumazet.
    
      20) Support XDP adjust_head in virtio_net, from John Fastabend.
    
      21) Fix several major holes in neighbour entry confirmation, from
          Julian Anastasov.
    
      22) Add XDP support to bnxt_en driver, from Michael Chan.
    
      23) VXLAN offloads for enic driver, from Govindarajulu Varadarajan.
    
      24) Add IPVTAP driver (IP-VLAN based tap driver) from Sainath Grandhi.
    
      25) Support GRO in IPSEC protocols, from Steffen Klassert"
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next: (1764 commits)
      Revert "ath10k: Search SMBIOS for OEM board file extension"
      net: socket: fix recvmmsg not returning error from sock_error
      bnxt_en: use eth_hw_addr_random()
      bpf: fix unlocking of jited image when module ronx not set
      arch: add ARCH_HAS_SET_MEMORY config
      net: napi_watchdog() can use napi_schedule_irqoff()
      tcp: Revert "tcp: tcp_probe: use spin_lock_bh()"
      net/hsr: use eth_hw_addr_random()
      net: mvpp2: enable building on 64-bit platforms
      net: mvpp2: switch to build_skb() in the RX path
      net: mvpp2: simplify MVPP2_PRS_RI_* definitions
      net: mvpp2: fix indentation of MVPP2_EXT_GLOBAL_CTRL_DEFAULT
      net: mvpp2: remove unused register definitions
      net: mvpp2: simplify mvpp2_bm_bufs_add()
      net: mvpp2: drop useless fields in mvpp2_bm_pool and related code
      net: mvpp2: remove unused 'tx_skb' field of 'struct mvpp2_tx_queue'
      net: mvpp2: release reference to txq_cpu[] entry after unmapping
      net: mvpp2: handle too large value in mvpp2_rx_time_coal_set()
      net: mvpp2: handle too large value handling in mvpp2_rx_pkts_coal_set()
      net: mvpp2: remove useless arguments in mvpp2_rx_{pkts, time}_coal_set
      ...

commit 6d1c42d9b93e38595ad46eeb4634853ca2755c92
Merge: 0f002fddbe15 90858794c960
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Feb 21 14:28:55 2017 -0800

    Merge tag 'extable-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/paulg/linux
    
    Pull exception table module split from Paul Gortmaker:
     "Final extable.h related changes.
    
      This completes the separation of exception table content from the
      module.h header file. This is achieved with the final commit that
      removes the one line back compatible change that sourced extable.h
      into the module.h file.
    
      The commits are unchanged since January, with the exception of a
      couple Acks that came in for the last two commits a bit later. The
      changes have been in linux-next for quite some time[1] and have got
      widespread arch coverage via toolchains I have and also from
      additional ones the kbuild bot has.
    
      Maintaners of the various arch were Cc'd during the postings to
      lkml[2] and informed that the intention was to take the remaining arch
      specific changes and lump them together with the final two non-arch
      specific changes and submit for this merge window.
    
      The ia64 diffstat stands out and probably warrants a mention. In an
      earlier review, Al Viro made a valid comment that the original header
      separation of content left something to be desired, and that it get
      fixed as a part of this change, hence the larger diffstat"
    
    * tag 'extable-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/paulg/linux: (21 commits)
      module.h: remove extable.h include now users have migrated
      core: migrate exception table users off module.h and onto extable.h
      cris: migrate exception table users off module.h and onto extable.h
      hexagon: migrate exception table users off module.h and onto extable.h
      microblaze: migrate exception table users off module.h and onto extable.h
      unicore32: migrate exception table users off module.h and onto extable.h
      score: migrate exception table users off module.h and onto extable.h
      metag: migrate exception table users off module.h and onto extable.h
      arc: migrate exception table users off module.h and onto extable.h
      nios2: migrate exception table users off module.h and onto extable.h
      sparc: migrate exception table users onto extable.h
      openrisc: migrate exception table users off module.h and onto extable.h
      frv: migrate exception table users off module.h and onto extable.h
      sh: migrate exception table users off module.h and onto extable.h
      xtensa: migrate exception table users off module.h and onto extable.h
      mn10300: migrate exception table users off module.h and onto extable.h
      alpha: migrate exception table users off module.h and onto extable.h
      arm: migrate exception table users off module.h and onto extable.h
      m32r: migrate exception table users off module.h and onto extable.h
      ia64: ensure exception table search users include extable.h
      ...

commit 74451e66d516c55e309e8d89a4a1e7596e46aacd
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Thu Feb 16 22:24:50 2017 +0100

    bpf: make jited programs visible in traces
    
    Long standing issue with JITed programs is that stack traces from
    function tracing check whether a given address is kernel code
    through {__,}kernel_text_address(), which checks for code in core
    kernel, modules and dynamically allocated ftrace trampolines. But
    what is still missing is BPF JITed programs (interpreted programs
    are not an issue as __bpf_prog_run() will be attributed to them),
    thus when a stack trace is triggered, the code walking the stack
    won't see any of the JITed ones. The same for address correlation
    done from user space via reading /proc/kallsyms. This is read by
    tools like perf, but the latter is also useful for permanent live
    tracing with eBPF itself in combination with stack maps when other
    eBPF types are part of the callchain. See offwaketime example on
    dumping stack from a map.
    
    This work tries to tackle that issue by making the addresses and
    symbols known to the kernel. The lookup from *kernel_text_address()
    is implemented through a latched RB tree that can be read under
    RCU in fast-path that is also shared for symbol/size/offset lookup
    for a specific given address in kallsyms. The slow-path iteration
    through all symbols in the seq file done via RCU list, which holds
    a tiny fraction of all exported ksyms, usually below 0.1 percent.
    Function symbols are exported as bpf_prog_<tag>, in order to aide
    debugging and attribution. This facility is currently enabled for
    root-only when bpf_jit_kallsyms is set to 1, and disabled if hardening
    is active in any mode. The rationale behind this is that still a lot
    of systems ship with world read permissions on kallsyms thus addresses
    should not get suddenly exposed for them. If that situation gets
    much better in future, we always have the option to change the
    default on this. Likewise, unprivileged programs are not allowed
    to add entries there either, but that is less of a concern as most
    such programs types relevant in this context are for root-only anyway.
    If enabled, call graphs and stack traces will then show a correct
    attribution; one example is illustrated below, where the trace is
    now visible in tooling such as perf script --kallsyms=/proc/kallsyms
    and friends.
    
    Before:
    
      7fff8166889d bpf_clone_redirect+0x80007f0020ed (/lib/modules/4.9.0-rc8+/build/vmlinux)
             f5d80 __sendmsg_nocancel+0xffff006451f1a007 (/usr/lib64/libc-2.18.so)
    
    After:
    
      7fff816688b7 bpf_clone_redirect+0x80007f002107 (/lib/modules/4.9.0-rc8+/build/vmlinux)
      7fffa0575728 bpf_prog_33c45a467c9e061a+0x8000600020fb (/lib/modules/4.9.0-rc8+/build/vmlinux)
      7fffa07ef1fc cls_bpf_classify+0x8000600020dc (/lib/modules/4.9.0-rc8+/build/vmlinux)
      7fff81678b68 tc_classify+0x80007f002078 (/lib/modules/4.9.0-rc8+/build/vmlinux)
      7fff8164d40b __netif_receive_skb_core+0x80007f0025fb (/lib/modules/4.9.0-rc8+/build/vmlinux)
      7fff8164d718 __netif_receive_skb+0x80007f002018 (/lib/modules/4.9.0-rc8+/build/vmlinux)
      7fff8164e565 process_backlog+0x80007f002095 (/lib/modules/4.9.0-rc8+/build/vmlinux)
      7fff8164dc71 net_rx_action+0x80007f002231 (/lib/modules/4.9.0-rc8+/build/vmlinux)
      7fff81767461 __softirqentry_text_start+0x80007f0020d1 (/lib/modules/4.9.0-rc8+/build/vmlinux)
      7fff817658ac do_softirq_own_stack+0x80007f00201c (/lib/modules/4.9.0-rc8+/build/vmlinux)
      7fff810a2c20 do_softirq+0x80007f002050 (/lib/modules/4.9.0-rc8+/build/vmlinux)
      7fff810a2cb5 __local_bh_enable_ip+0x80007f002085 (/lib/modules/4.9.0-rc8+/build/vmlinux)
      7fff8168d452 ip_finish_output2+0x80007f002152 (/lib/modules/4.9.0-rc8+/build/vmlinux)
      7fff8168ea3d ip_finish_output+0x80007f00217d (/lib/modules/4.9.0-rc8+/build/vmlinux)
      7fff8168f2af ip_output+0x80007f00203f (/lib/modules/4.9.0-rc8+/build/vmlinux)
      [...]
      7fff81005854 do_syscall_64+0x80007f002054 (/lib/modules/4.9.0-rc8+/build/vmlinux)
      7fff817649eb return_from_SYSCALL_64+0x80007f002000 (/lib/modules/4.9.0-rc8+/build/vmlinux)
             f5d80 __sendmsg_nocancel+0xffff01c484812007 (/usr/lib64/libc-2.18.so)
    
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/extable.c b/kernel/extable.c
index e3beec4a2339..bd82117ad424 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -20,6 +20,7 @@
 #include <linux/module.h>
 #include <linux/mutex.h>
 #include <linux/init.h>
+#include <linux/filter.h>
 
 #include <asm/sections.h>
 #include <linux/uaccess.h>
@@ -104,6 +105,8 @@ int __kernel_text_address(unsigned long addr)
 		return 1;
 	if (is_ftrace_trampoline(addr))
 		return 1;
+	if (is_bpf_text_address(addr))
+		return 1;
 	/*
 	 * There might be init symbols in saved stacktraces.
 	 * Give those symbols a chance to be printed in
@@ -123,7 +126,11 @@ int kernel_text_address(unsigned long addr)
 		return 1;
 	if (is_module_text_address(addr))
 		return 1;
-	return is_ftrace_trampoline(addr);
+	if (is_ftrace_trampoline(addr))
+		return 1;
+	if (is_bpf_text_address(addr))
+		return 1;
+	return 0;
 }
 
 /*

commit 8a293be0d6fa0720809db6ac35a0552c51710cd2
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Sat Jul 23 14:01:45 2016 -0400

    core: migrate exception table users off module.h and onto extable.h
    
    These files were including module.h for exception table related
    functions.  We've now separated that content out into its own file
    "extable.h" so now move over to that and where possible, avoid all
    the extra header content in module.h that we don't really need to
    compile these non-modular files.
    
    Note:
       init/main.c still needs module.h for __init_or_module
       kernel/extable.c still needs module.h for is_module_text_address
    
    ...and so we don't get the benefit of removing module.h from the cpp
    feed for these two files, unlike the almost universal 1:1 exchange
    of module.h for extable.h we were able to do in the arch dirs.
    
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Acked-by: Jessica Yu <jeyu@redhat.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/kernel/extable.c b/kernel/extable.c
index e3beec4a2339..b25d9901e431 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -17,6 +17,7 @@
 */
 #include <linux/ftrace.h>
 #include <linux/memory.h>
+#include <linux/extable.h>
 #include <linux/module.h>
 #include <linux/mutex.h>
 #include <linux/init.h>

commit 5b485629ba0d5d027880769ff467c587b24b4bde
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Sun Jan 8 23:58:09 2017 +0900

    kprobes, extable: Identify kprobes trampolines as kernel text area
    
    Improve __kernel_text_address()/kernel_text_address() to return
    true if the given address is on a kprobe's instruction slot
    trampoline.
    
    This can help stacktraces to determine the address is on a
    text area or not.
    
    To implement this atomically in is_kprobe_*_slot(), also change
    the insn_cache page list to an RCU list.
    
    This changes timings a bit (it delays page freeing to the RCU garbage
    collection phase), but none of that is in the hot path.
    
    Note: this change can add small overhead to stack unwinders because
    it adds 2 additional checks to __kernel_text_address(). However, the
    impact should be very small, because kprobe_insn_pages list has 1 entry
    per 256 probes(on x86, on arm/arm64 it will be 1024 probes),
    and kprobe_optinsn_pages has 1 entry per 32 probes(on x86).
    In most use cases, the number of kprobe events may be less
    than 20, which means that is_kprobe_*_slot() will check just one entry.
    
    Tested-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Ananth N Mavinakayanahalli <ananth@linux.vnet.ibm.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andrey Konovalov <andreyknvl@google.com>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/148388747896.6869.6354262871751682264.stgit@devbox
    [ Improved the changelog and coding style. ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index e3beec4a2339..e1359474baa5 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -20,6 +20,7 @@
 #include <linux/module.h>
 #include <linux/mutex.h>
 #include <linux/init.h>
+#include <linux/kprobes.h>
 
 #include <asm/sections.h>
 #include <linux/uaccess.h>
@@ -104,6 +105,8 @@ int __kernel_text_address(unsigned long addr)
 		return 1;
 	if (is_ftrace_trampoline(addr))
 		return 1;
+	if (is_kprobe_optinsn_slot(addr) || is_kprobe_insn_slot(addr))
+		return 1;
 	/*
 	 * There might be init symbols in saved stacktraces.
 	 * Give those symbols a chance to be printed in
@@ -123,7 +126,11 @@ int kernel_text_address(unsigned long addr)
 		return 1;
 	if (is_module_text_address(addr))
 		return 1;
-	return is_ftrace_trampoline(addr);
+	if (is_ftrace_trampoline(addr))
+		return 1;
+	if (is_kprobe_optinsn_slot(addr) || is_kprobe_insn_slot(addr))
+		return 1;
+	return 0;
 }
 
 /*

commit 7c0f6ba682b9c7632072ffbedf8d328c8f3c42ba
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Dec 24 11:46:01 2016 -0800

    Replace <asm/uaccess.h> with <linux/uaccess.h> globally
    
    This was entirely automated, using the script by Al:
    
      PATT='^[[:blank:]]*#[[:blank:]]*include[[:blank:]]*<asm/uaccess.h>'
      sed -i -e "s!$PATT!#include <linux/uaccess.h>!" \
            $(git grep -l "$PATT"|grep -v ^include/linux/uaccess.h)
    
    to do the replacement at the end of the merge window.
    
    Requested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index e820ccee9846..e3beec4a2339 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -22,7 +22,7 @@
 #include <linux/init.h>
 
 #include <asm/sections.h>
-#include <asm/uaccess.h>
+#include <linux/uaccess.h>
 
 /*
  * mutex protecting text section modification (dynamic code patching).

commit 2307e1a3c0780d7b908f6809f34034a04f954806
Author: Wei Yongjun <yongjun_wei@trendmicro.com.cn>
Date:   Wed Sep 9 15:36:06 2015 -0700

    kernel/extable.c: remove duplicated include
    
    Signed-off-by: Wei Yongjun <yongjun_wei@trendmicro.com.cn>
    Acked-by: Steven Rostedt <rostedt@goodmis.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index c98f926277a8..e820ccee9846 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -18,7 +18,6 @@
 #include <linux/ftrace.h>
 #include <linux/memory.h>
 #include <linux/module.h>
-#include <linux/ftrace.h>
 #include <linux/mutex.h>
 #include <linux/init.h>
 

commit aec0be2d6e9f02dbef41ee54854c2e003e55c23e
Author: Steven Rostedt (Red Hat) <rostedt@goodmis.org>
Date:   Tue Nov 18 21:14:11 2014 -0500

    ftrace/x86/extable: Add is_ftrace_trampoline() function
    
    Stack traces that happen from function tracing check if the address
    on the stack is a __kernel_text_address(). That is, is the address
    kernel code. This calls core_kernel_text() which returns true
    if the address is part of the builtin kernel code. It also calls
    is_module_text_address() which returns true if the address belongs
    to module code.
    
    But what is missing is ftrace dynamically allocated trampolines.
    These trampolines are allocated for individual ftrace_ops that
    call the ftrace_ops callback functions directly. But if they do a
    stack trace, the code checking the stack wont detect them as they
    are neither core kernel code nor module address space.
    
    Adding another field to ftrace_ops that also stores the size of
    the trampoline assigned to it we can create a new function called
    is_ftrace_trampoline() that returns true if the address is a
    dynamically allocate ftrace trampoline. Note, it ignores trampolines
    that are not dynamically allocated as they will return true with
    the core_kernel_text() function.
    
    Link: http://lkml.kernel.org/r/20141119034829.497125839@goodmis.org
    
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index d8a6446adbcb..c98f926277a8 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -18,6 +18,7 @@
 #include <linux/ftrace.h>
 #include <linux/memory.h>
 #include <linux/module.h>
+#include <linux/ftrace.h>
 #include <linux/mutex.h>
 #include <linux/init.h>
 
@@ -102,6 +103,8 @@ int __kernel_text_address(unsigned long addr)
 		return 1;
 	if (is_module_text_address(addr))
 		return 1;
+	if (is_ftrace_trampoline(addr))
+		return 1;
 	/*
 	 * There might be init symbols in saved stacktraces.
 	 * Give those symbols a chance to be printed in
@@ -119,7 +122,9 @@ int kernel_text_address(unsigned long addr)
 {
 	if (core_kernel_text(addr))
 		return 1;
-	return is_module_text_address(addr);
+	if (is_module_text_address(addr))
+		return 1;
+	return is_ftrace_trampoline(addr);
 }
 
 /*

commit 00b7103078596a243c16239004e0dc9416910f13
Author: Andi Kleen <ak@linux.intel.com>
Date:   Sat Feb 8 08:52:04 2014 +0100

    asmlinkage: Make main_extable_sort_needed visible
    
    main_extable_sort_needed is used by the build system and needs
    to be a normal ELF symbol. Make it visible so that LTO
    does not remove or mangle it.
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Link: http://lkml.kernel.org/r/1391845930-28580-8-git-send-email-ak@linux.intel.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/kernel/extable.c b/kernel/extable.c
index 763faf037ec1..d8a6446adbcb 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -36,7 +36,7 @@ extern struct exception_table_entry __start___ex_table[];
 extern struct exception_table_entry __stop___ex_table[];
 
 /* Cleared by build time tools if the table is already sorted. */
-u32 __initdata main_extable_sort_needed = 1;
+u32 __initdata __visible main_extable_sort_needed = 1;
 
 /* Sort the kernel's built-in exception table */
 void __init sort_main_extable(void)

commit 5ecbe3c3c690b5ab493c730c317475287a9e8b45
Author: Helge Deller <deller@gmx.de>
Date:   Thu Nov 28 09:16:33 2013 +0100

    kernel/extable: fix address-checks for core_kernel and init areas
    
    The init_kernel_text() and core_kernel_text() functions should not
    include the labels _einittext and _etext when checking if an address is
    inside the .text or .init sections.
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index 832cb28105bb..763faf037ec1 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -61,7 +61,7 @@ const struct exception_table_entry *search_exception_tables(unsigned long addr)
 static inline int init_kernel_text(unsigned long addr)
 {
 	if (addr >= (unsigned long)_sinittext &&
-	    addr <= (unsigned long)_einittext)
+	    addr < (unsigned long)_einittext)
 		return 1;
 	return 0;
 }
@@ -69,7 +69,7 @@ static inline int init_kernel_text(unsigned long addr)
 int core_kernel_text(unsigned long addr)
 {
 	if (addr >= (unsigned long)_stext &&
-	    addr <= (unsigned long)_etext)
+	    addr < (unsigned long)_etext)
 		return 1;
 
 	if (system_state == SYSTEM_BOOTING &&

commit e656a634118285142063527b2cd40c749036de82
Author: Uwe Kleine-König <u.kleine-koenig@pengutronix.de>
Date:   Wed Sep 11 14:23:27 2013 -0700

    extable: skip sorting if the table is empty
    
    At least on ARM no-MMU the extable is empty and so there is nothing to
    sort. So add a check for the table to be empty which effectively only
    changes that the misleading pr_notice is suppressed.
    
    Signed-off-by: Uwe Kleine-König <u.kleine-koenig@pengutronix.de>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: David Daney <david.daney@cavium.com>
    Cc: "H. Peter Anvin" <hpa@linux.intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index 67460b93b1a1..832cb28105bb 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -41,7 +41,7 @@ u32 __initdata main_extable_sort_needed = 1;
 /* Sort the kernel's built-in exception table */
 void __init sort_main_extable(void)
 {
-	if (main_extable_sort_needed) {
+	if (main_extable_sort_needed && __stop___ex_table > __start___ex_table) {
 		pr_notice("Sorting __ex_table...\n");
 		sort_extable(__start___ex_table, __stop___ex_table);
 	}

commit bec1b9e76353ecf05fac6a87f8e4102dfb618cd2
Author: Borislav Petkov <bp@suse.de>
Date:   Mon Apr 15 12:51:49 2013 +0200

    extable: Flip the sorting message
    
    Now that we do sort the __extable at build time, we actually are
    interested only in the case where we still do need to sort it.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: David Daney <david.daney@cavium.com>
    Link: http://lkml.kernel.org/r/1366023109-12098-1-git-send-email-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index fe35a634bf76..67460b93b1a1 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -41,10 +41,10 @@ u32 __initdata main_extable_sort_needed = 1;
 /* Sort the kernel's built-in exception table */
 void __init sort_main_extable(void)
 {
-	if (main_extable_sort_needed)
+	if (main_extable_sort_needed) {
+		pr_notice("Sorting __ex_table...\n");
 		sort_extable(__start___ex_table, __stop___ex_table);
-	else
-		pr_notice("__ex_table already sorted, skipping sort\n");
+	}
 }
 
 /* Given an address, look for it in the exception tables. */

commit d219e2e86a407035303b987e4184ca0b1de53257
Author: David Daney <david.daney@cavium.com>
Date:   Thu Apr 19 14:59:56 2012 -0700

    extable: Skip sorting if sorted at build time.
    
    If the build program sortextable has already sorted the exception
    table, don't sort it again.
    
    Signed-off-by: David Daney <david.daney@cavium.com>
    Link: http://lkml.kernel.org/r/1334872799-14589-3-git-send-email-ddaney.cavm@gmail.com
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/kernel/extable.c b/kernel/extable.c
index 5339705b8241..fe35a634bf76 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -35,10 +35,16 @@ DEFINE_MUTEX(text_mutex);
 extern struct exception_table_entry __start___ex_table[];
 extern struct exception_table_entry __stop___ex_table[];
 
+/* Cleared by build time tools if the table is already sorted. */
+u32 __initdata main_extable_sort_needed = 1;
+
 /* Sort the kernel's built-in exception table */
 void __init sort_main_extable(void)
 {
-	sort_extable(__start___ex_table, __stop___ex_table);
+	if (main_extable_sort_needed)
+		sort_extable(__start___ex_table, __stop___ex_table);
+	else
+		pr_notice("__ex_table already sorted, skipping sort\n");
 }
 
 /* Given an address, look for it in the exception tables. */

commit a2d063ac216c1618bfc2b4d40b7176adffa63511
Author: Steven Rostedt <rostedt@goodmis.org>
Date:   Thu May 19 21:34:58 2011 -0400

    extable, core_kernel_data(): Make sure all archs define _sdata
    
    A new utility function (core_kernel_data()) is used to determine if a
    passed in address is part of core kernel data or not. It may or may not
    return true for RO data, but this utility must work for RW data.
    
    Thus both _sdata and _edata must be defined and continuous,
    without .init sections that may later be freed and replaced by
    volatile memory (memory that can be freed).
    
    This utility function is used to determine if data is safe from
    ever being freed. Thus it should return true for all RW global
    data that is not in a module or has been allocated, or false
    otherwise.
    
    Also change core_kernel_data() back to the more precise _sdata condition
    and document the function.
    
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>
    Acked-by: Ralf Baechle <ralf@linux-mips.org>
    Acked-by: Hirokazu Takata <takata@linux-m32r.org>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Cc: linux-m68k@lists.linux-m68k.org
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: Helge Deller <deller@gmx.de>
    Cc: JamesE.J.Bottomley <jejb@parisc-linux.org>
    Link: http://lkml.kernel.org/r/1305855298.1465.19.camel@gandalf.stny.rr.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    ----
     arch/alpha/kernel/vmlinux.lds.S   |    1 +
     arch/m32r/kernel/vmlinux.lds.S    |    1 +
     arch/m68k/kernel/vmlinux-std.lds  |    2 ++
     arch/m68k/kernel/vmlinux-sun3.lds |    1 +
     arch/mips/kernel/vmlinux.lds.S    |    1 +
     arch/parisc/kernel/vmlinux.lds.S  |    3 +++
     kernel/extable.c                  |   12 +++++++++++-
     7 files changed, 20 insertions(+), 1 deletion(-)

diff --git a/kernel/extable.c b/kernel/extable.c
index d44aac0c3faa..5339705b8241 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -72,9 +72,19 @@ int core_kernel_text(unsigned long addr)
 	return 0;
 }
 
+/**
+ * core_kernel_data - tell if addr points to kernel data
+ * @addr: address to test
+ *
+ * Returns true if @addr passed in is from the core kernel data
+ * section.
+ *
+ * Note: On some archs it may return true for core RODATA, and false
+ *  for others. But will always be true for core RW data.
+ */
 int core_kernel_data(unsigned long addr)
 {
-	if (addr >= (unsigned long)_stext &&
+	if (addr >= (unsigned long)_sdata &&
 	    addr < (unsigned long)_edata)
 		return 1;
 	return 0;

commit c5fc472171ec4f96d06d1ac039d88f9b89bb95db
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri May 20 01:22:14 2011 +0200

    core_kernel_data(): Fix architectures that do not define _sdata
    
    Some architectures such as Alpha do not define _sdata but _data:
    
      kernel/built-in.o: In function `core_kernel_data':
      kernel/extable.c:77: undefined reference to `_sdata'
    
    So expand the scope of the data range to the text addresses too,
    this might be more correct anyway because this way we can
    cover readonly variables as well.
    
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Link: http://lkml.kernel.org/n/tip-i878c8a0e0g0ep4v7i6vxnhz@git.kernel.org
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/extable.c b/kernel/extable.c
index c2d625fcda77..d44aac0c3faa 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -74,7 +74,7 @@ int core_kernel_text(unsigned long addr)
 
 int core_kernel_data(unsigned long addr)
 {
-	if (addr >= (unsigned long)_sdata &&
+	if (addr >= (unsigned long)_stext &&
 	    addr < (unsigned long)_edata)
 		return 1;
 	return 0;

commit cdbe61bfe70440939e457fb4a8d0995eaaed17de
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Thu May 5 21:14:55 2011 -0400

    ftrace: Allow dynamically allocated function tracers
    
    Now that functions may be selected individually, it only makes sense
    that we should allow dynamically allocated trace structures to
    be traced. This will allow perf to allocate a ftrace_ops structure
    at runtime and use it to pick and choose which functions that
    structure will trace.
    
    Note, a dynamically allocated ftrace_ops will always be called
    indirectly instead of being called directly from the mcount in
    entry.S. This is because there's no safe way to prevent mcount
    from being preempted before calling the function, unless we
    modify every entry.S to do so (not likely). Thus, dynamically allocated
    functions will now be called by the ftrace_ops_list_func() that
    loops through the ops that are allocated if there are more than
    one op allocated at a time. This loop is protected with a
    preempt_disable.
    
    To determine if an ftrace_ops structure is allocated or not, a new
    util function was added to the kernel/extable.c called
    core_kernel_data(), which returns 1 if the address is between
    _sdata and _edata.
    
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index 7f8f263f8524..c2d625fcda77 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -72,6 +72,14 @@ int core_kernel_text(unsigned long addr)
 	return 0;
 }
 
+int core_kernel_data(unsigned long addr)
+{
+	if (addr >= (unsigned long)_sdata &&
+	    addr < (unsigned long)_edata)
+		return 1;
+	return 0;
+}
+
 int __kernel_text_address(unsigned long addr)
 {
 	if (core_kernel_text(addr))

commit 714f83d5d9f7c785f622259dad1f4fad12d64664
Merge: 8901e7ffc2fa 645dae969c3b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Apr 5 11:04:19 2009 -0700

    Merge branch 'tracing-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'tracing-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (413 commits)
      tracing, net: fix net tree and tracing tree merge interaction
      tracing, powerpc: fix powerpc tree and tracing tree interaction
      ring-buffer: do not remove reader page from list on ring buffer free
      function-graph: allow unregistering twice
      trace: make argument 'mem' of trace_seq_putmem() const
      tracing: add missing 'extern' keywords to trace_output.h
      tracing: provide trace_seq_reserve()
      blktrace: print out BLK_TN_MESSAGE properly
      blktrace: extract duplidate code
      blktrace: fix memory leak when freeing struct blk_io_trace
      blktrace: fix blk_probes_ref chaos
      blktrace: make classic output more classic
      blktrace: fix off-by-one bug
      blktrace: fix the original blktrace
      blktrace: fix a race when creating blk_tree_root in debugfs
      blktrace: fix timestamp in binary output
      tracing, Text Edit Lock: cleanup
      tracing: filter fix for TRACE_EVENT_FORMAT events
      ftrace: Using FTRACE_WARN_ON() to check "freed record" in ftrace_release()
      x86: kretprobe-booster interrupt emulation code fix
      ...
    
    Fix up trivial conflicts in
     arch/parisc/include/asm/ftrace.h
     include/linux/memory.h
     kernel/extable.c
     kernel/module.c

commit cab4e4c43f92582a2bfc026137b3d8a175bd0360
Merge: 5412b5399e09 49502677e110
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Apr 5 10:30:21 2009 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/rusty/linux-2.6-module-and-param
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/rusty/linux-2.6-module-and-param:
      module: use strstarts()
      strstarts: helper function for !strncmp(str, prefix, strlen(prefix))
      arm: allow usage of string functions in linux/string.h
      module: don't use stop_machine on module load
      module: create a request_module_nowait()
      module: include other structures in module version check
      module: remove the SHF_ALLOC flag on the __versions section.
      module: clarify the force-loading taint message.
      module: Export symbols needed for Ksplice
      Ksplice: Add functions for walking kallsyms symbols
      module: remove module_text_address()
      module: __module_address
      module: Make find_symbol return a struct kernel_symbol
      kernel/module.c: fix an unused goto label
      param: fix charp parameters set via sysfs
    
    Fix trivial conflicts in kernel/extable.c manually.

commit a6e6abd575fcbe6572ebc7a70ad616406d206fa8
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Tue Mar 31 13:05:31 2009 -0600

    module: remove module_text_address()
    
    Impact: Replace and remove risky (non-EXPORTed) API
    
    module_text_address() returns a pointer to the module, which given locking
    improvements in module.c, is useless except to test for NULL:
    
    1) If the module can't go away, use __module_text_address.
    2) Otherwise, just use is_module_text_address().
    
    Cc: linux-mtd@lists.infradead.org
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/kernel/extable.c b/kernel/extable.c
index e136ed8d82ba..384f0da8a03e 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -58,14 +58,14 @@ __notrace_funcgraph int __kernel_text_address(unsigned long addr)
 {
 	if (core_kernel_text(addr))
 		return 1;
-	return __module_text_address(addr) != NULL;
+	return is_module_text_address(addr);
 }
 
 int kernel_text_address(unsigned long addr)
 {
 	if (core_kernel_text(addr))
 		return 1;
-	return module_text_address(addr) != NULL;
+	return is_module_text_address(addr);
 }
 
 /*
@@ -81,5 +81,5 @@ int func_ptr_is_kernel_text(void *ptr)
 	addr = (unsigned long) dereference_function_descriptor(ptr);
 	if (core_kernel_text(addr))
 		return 1;
-	return module_text_address(addr) != NULL;
+	return is_module_text_address(addr);
 }

commit f80d2d7725b04f8225b11b55e43bb2c77c819926
Author: Dmitri Vorobiev <dmitri.vorobiev@movial.com>
Date:   Sun Mar 22 19:11:10 2009 +0200

    tracing, Text Edit Lock: Fix one sparse warning in kernel/extable.c
    
    Impact: cleanup.
    
    The global mutex text_mutex if declared in linux/memory.h, so
    this file needs to be included into kernel/extable.c, where the
    same mutex is defined. This fixes the following sparse warning:
    
     kernel/extable.c:32:1: warning: symbol 'text_mutex' was not declared.
     Should it be static?
    
    Signed-off-by: Dmitri Vorobiev <dmitri.vorobiev@movial.com>
    LKML-Reference: <1237741871-5827-3-git-send-email-dmitri.vorobiev@movial.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/extable.c b/kernel/extable.c
index 25d39b0c3a1b..b54a6017b6b5 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -16,6 +16,7 @@
     Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
 */
 #include <linux/ftrace.h>
+#include <linux/memory.h>
 #include <linux/module.h>
 #include <linux/mutex.h>
 #include <linux/init.h>

commit 505f2b970b2269ce4cb669b3ff4f6479d379cec2
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Mar 20 11:05:04 2009 +0100

    tracing, Text Edit Lock - kprobes architecture independent support, nommu fix
    
    Impact: build fix on SH !CONFIG_MMU
    
    Stephen Rothwell reported this linux-next build failure on the SH
    architecture:
    
      kernel/built-in.o: In function `disable_all_kprobes':
      kernel/kprobes.c:1382: undefined reference to `text_mutex'
      [...]
    
    And observed:
    
    | Introduced by commit 4460fdad85becd569f11501ad5b91814814335ff ("tracing,
    | Text Edit Lock - kprobes architecture independent support") from the
    | tracing tree.  text_mutex is defined in mm/memory.c which is only built
    | if CONFIG_MMU is defined, which is not true for sh allmodconfig.
    
    Move this lock to kernel/extable.c (which is already home to various
    kernel text related routines), which file is always built-in.
    
    Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
    LKML-Reference: <20090320110602.86351a91.sfr@canb.auug.org.au>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/extable.c b/kernel/extable.c
index 0df6253730be..25d39b0c3a1b 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -15,11 +15,21 @@
     along with this program; if not, write to the Free Software
     Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
 */
+#include <linux/ftrace.h>
 #include <linux/module.h>
+#include <linux/mutex.h>
 #include <linux/init.h>
-#include <linux/ftrace.h>
-#include <asm/uaccess.h>
+
 #include <asm/sections.h>
+#include <asm/uaccess.h>
+
+/*
+ * mutex protecting text section modification (dynamic code patching).
+ * some users need to sleep (allocating memory...) while they hold this lock.
+ *
+ * NOT exported to modules - patching kernel text is a really delicate matter.
+ */
+DEFINE_MUTEX(text_mutex);
 
 extern struct exception_table_entry __start___ex_table[];
 extern struct exception_table_entry __stop___ex_table[];

commit 4a44bac1f98223ed77e47bf3b42fcfd10cddd85f
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Mar 19 13:21:44 2009 +0100

    symbols, stacktrace: look up init symbols after module symbols
    
    Impact: fix incomplete stacktraces
    
    I noticed such weird stacktrace entries in lockdep dumps:
    
    [    0.285956] {HARDIRQ-ON-W} state was registered at:
    [    0.285956]   [<ffffffff802bce90>] mark_irqflags+0xbe/0x125
    [    0.285956]   [<ffffffff802bf2fd>] __lock_acquire+0x674/0x82d
    [    0.285956]   [<ffffffff802bf5b2>] lock_acquire+0xfc/0x128
    [    0.285956]   [<ffffffff8135b636>] rt_spin_lock+0xc8/0xd0
    [    0.285956]   [<ffffffffffffffff>] 0xffffffffffffffff
    
    The stacktrace entry is cut off after rt_spin_lock.
    
    After much debugging i found out that stacktrace entries that
    belong to init symbols dont get printed out, due to commit:
    
      a2da405: module: Don't report discarded init pages as kernel text.
    
    The reason is this check added to core_kernel_text():
    
    -       if (addr >= (unsigned long)_sinittext &&
    +       if (system_state == SYSTEM_BOOTING &&
    +           addr >= (unsigned long)_sinittext &&
                addr <= (unsigned long)_einittext)
                    return 1;
    
    This will discard inittext symbols even though their symbol table
    is still present and even though stacktraces done while the system
    was booting up might still be relevant.
    
    To not reintroduce the (not well-specified) bug addressed in that
    commit, first do a module symbols lookup, then a final init-symbols
    lookup.
    
    This will work fine on architectures that have separate address
    spaces for modules (such as x86) - and should not crash any other
    architectures either.
    
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    LKML-Reference: <new-discussion>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/extable.c b/kernel/extable.c
index e136ed8d82ba..c46da6a47036 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -41,6 +41,14 @@ const struct exception_table_entry *search_exception_tables(unsigned long addr)
 	return e;
 }
 
+static inline int init_kernel_text(unsigned long addr)
+{
+	if (addr >= (unsigned long)_sinittext &&
+	    addr <= (unsigned long)_einittext)
+		return 1;
+	return 0;
+}
+
 __notrace_funcgraph int core_kernel_text(unsigned long addr)
 {
 	if (addr >= (unsigned long)_stext &&
@@ -48,8 +56,7 @@ __notrace_funcgraph int core_kernel_text(unsigned long addr)
 		return 1;
 
 	if (system_state == SYSTEM_BOOTING &&
-	    addr >= (unsigned long)_sinittext &&
-	    addr <= (unsigned long)_einittext)
+	    init_kernel_text(addr))
 		return 1;
 	return 0;
 }
@@ -58,7 +65,19 @@ __notrace_funcgraph int __kernel_text_address(unsigned long addr)
 {
 	if (core_kernel_text(addr))
 		return 1;
-	return __module_text_address(addr) != NULL;
+	if (__module_text_address(addr))
+		return 1;
+	/*
+	 * There might be init symbols in saved stacktraces.
+	 * Give those symbols a chance to be printed in
+	 * backtraces (such as lockdep traces).
+	 *
+	 * Since we are after the module-symbols check, there's
+	 * no danger of address overlap:
+	 */
+	if (init_kernel_text(addr))
+		return 1;
+	return 0;
 }
 
 int kernel_text_address(unsigned long addr)

commit 3861a17bcc0af815f684c6178bc9ec2d790c350e
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Sun Feb 8 00:04:02 2009 +0100

    tracing/function-graph-tracer: drop the kernel_text_address check
    
    When the function graph tracer picks a return address, it ensures this address
    is really a kernel text one by calling __kernel_text_address()
    
    Actually this path has never been taken.Its role was more likely to debug the tracer
    on the beginning of its development but this function is wasteful since it is called
    for every traced function.
    
    The fault check is already sufficient.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/extable.c b/kernel/extable.c
index e136ed8d82ba..0df6253730be 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -41,7 +41,7 @@ const struct exception_table_entry *search_exception_tables(unsigned long addr)
 	return e;
 }
 
-__notrace_funcgraph int core_kernel_text(unsigned long addr)
+int core_kernel_text(unsigned long addr)
 {
 	if (addr >= (unsigned long)_stext &&
 	    addr <= (unsigned long)_etext)
@@ -54,7 +54,7 @@ __notrace_funcgraph int core_kernel_text(unsigned long addr)
 	return 0;
 }
 
-__notrace_funcgraph int __kernel_text_address(unsigned long addr)
+int __kernel_text_address(unsigned long addr)
 {
 	if (core_kernel_text(addr))
 		return 1;

commit 5f34fe1cfc1bdd8b4711bbe37421fba4ed0d1ed4
Merge: eca1bf5b4fab 6638101c1124
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 30 16:10:19 2008 -0800

    Merge branch 'core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (63 commits)
      stacktrace: provide save_stack_trace_tsk() weak alias
      rcu: provide RCU options on non-preempt architectures too
      printk: fix discarding message when recursion_bug
      futex: clean up futex_(un)lock_pi fault handling
      "Tree RCU": scalable classic RCU implementation
      futex: rename field in futex_q to clarify single waiter semantics
      x86/swiotlb: add default swiotlb_arch_range_needs_mapping
      x86/swiotlb: add default phys<->bus conversion
      x86: unify pci iommu setup and allow swiotlb to compile for 32 bit
      x86: add swiotlb allocation functions
      swiotlb: consolidate swiotlb info message printing
      swiotlb: support bouncing of HighMem pages
      swiotlb: factor out copy to/from device
      swiotlb: add arch hook to force mapping
      swiotlb: allow architectures to override phys<->bus<->phys conversions
      swiotlb: add comment where we handle the overflow of a dma mask on 32 bit
      rcu: fix rcutorture behavior during reboot
      resources: skip sanity check of busy resources
      swiotlb: move some definitions to header
      swiotlb: allow architectures to override swiotlb pool allocation
      ...
    
    Fix up trivial conflicts in
      arch/x86/kernel/Makefile
      arch/x86/mm/init_32.c
      include/linux/hardirq.h
    as per Ingo's suggestions.

commit 8b96f0119818964e4944fd1c423bf6770027d3ac
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Sat Dec 6 03:40:00 2008 +0100

    tracing/function-graph-tracer: introduce __notrace_funcgraph to filter special functions
    
    Impact: trace more functions
    
    When the function graph tracer is configured, three more files are not
    traced to prevent only four functions to be traced. And this impacts the
    normal function tracer too.
    
    arch/x86/kernel/process_64/32.c:
    
    I had crashes when I let this file traced. After some debugging, I saw
    that the "current" task point was changed inside__swtich_to(), ie:
    "write_pda(pcurrent, next_p);" inside process_64.c Since the tracer store
    the original return address of the function inside current, we had
    crashes. Only __switch_to() has to be excluded from tracing.
    
    kernel/module.c and kernel/extable.c:
    
    Because of a function used internally by the function graph tracer:
    __kernel_text_address()
    
    To let the other functions inside these files to be traced, this patch
    introduces the __notrace_funcgraph function prefix which is __notrace if
    function graph tracer is configured and nothing if not.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/extable.c b/kernel/extable.c
index a26cb2e17023..feb0317cf09a 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -17,6 +17,7 @@
 */
 #include <linux/module.h>
 #include <linux/init.h>
+#include <linux/ftrace.h>
 #include <asm/uaccess.h>
 #include <asm/sections.h>
 
@@ -40,7 +41,7 @@ const struct exception_table_entry *search_exception_tables(unsigned long addr)
 	return e;
 }
 
-int core_kernel_text(unsigned long addr)
+__notrace_funcgraph int core_kernel_text(unsigned long addr)
 {
 	if (addr >= (unsigned long)_stext &&
 	    addr <= (unsigned long)_etext)
@@ -53,7 +54,7 @@ int core_kernel_text(unsigned long addr)
 	return 0;
 }
 
-int __kernel_text_address(unsigned long addr)
+__notrace_funcgraph int __kernel_text_address(unsigned long addr)
 {
 	if (core_kernel_text(addr))
 		return 1;

commit ab7476cf76e560f0efda2a631a70aabe93009025
Author: Arjan van de Ven <arjan@linux.intel.com>
Date:   Fri Aug 15 15:29:38 2008 -0700

    debug: add notifier chain debugging, v2
    
    - unbreak ia64 (and powerpc) where function pointers dont
      point at code but at data (reported by Tony Luck)
    
    [ mingo@elte.hu: various cleanups ]
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/extable.c b/kernel/extable.c
index a26cb2e17023..adf0cc9c02d6 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -66,3 +66,19 @@ int kernel_text_address(unsigned long addr)
 		return 1;
 	return module_text_address(addr) != NULL;
 }
+
+/*
+ * On some architectures (PPC64, IA64) function pointers
+ * are actually only tokens to some data that then holds the
+ * real function address. As a result, to find if a function
+ * pointer is part of the kernel text, we need to do some
+ * special dereferencing first.
+ */
+int func_ptr_is_kernel_text(void *ptr)
+{
+	unsigned long addr;
+	addr = (unsigned long) dereference_function_descriptor(ptr);
+	if (core_kernel_text(addr))
+		return 1;
+	return module_text_address(addr) != NULL;
+}

commit a2da4052f1df6bc77749f84496fe731ab8b458f7
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Tue Jan 29 17:13:17 2008 -0500

    module: Don't report discarded init pages as kernel text.
    
    Current code could cause a bug in symbol_put_addr() if an arch used
    kmalloc module text: we might think the symbol belongs to the core
    kernel.
    
    The downside is that this might make backtraces through (discarded)
    init functions harder to read on some archs, but we already have that
    issue for modules and noone has complained.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/kernel/extable.c b/kernel/extable.c
index 7fe262855317..a26cb2e17023 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -46,7 +46,8 @@ int core_kernel_text(unsigned long addr)
 	    addr <= (unsigned long)_etext)
 		return 1;
 
-	if (addr >= (unsigned long)_sinittext &&
+	if (system_state == SYSTEM_BOOTING &&
+	    addr >= (unsigned long)_sinittext &&
 	    addr <= (unsigned long)_einittext)
 		return 1;
 	return 0;

commit 5e376613899076396d0c97de67ad072587267370
Author: Trent Piepho <xyzzy@speakeasy.org>
Date:   Mon May 15 09:44:06 2006 -0700

    [PATCH] symbol_put_addr() locks kernel
    
    Even since a previous patch:
    
    Fix race between CONFIG_DEBUG_SLABALLOC and modules
    Sun, 27 Jun 2004 17:55:19 +0000 (17:55 +0000)
    http://www.kernel.org/git/?p=linux/kernel/git/torvalds/old-2.6-bkcvs.git;a=commit;h=92b3db26d31cf21b70e3c1eadc56c179506d8fbe
    
    The function symbol_put_addr() will deadlock the kernel.
    
    symbol_put_addr() would acquire modlist_lock, then while holding the lock call
    two functions kernel_text_address() and module_text_address() which also try
    to acquire the same lock.  This deadlocks the kernel of course.
    
    This patch changes symbol_put_addr() to not acquire the modlist_lock, it
    doesn't need it since it never looks at the module list directly.  Also, it
    now uses core_kernel_text() instead of kernel_text_address().  The latter has
    an additional check for addr inside a module, but we don't need to do that
    since we call module_text_address() (the same function kernel_text_address
    uses) ourselves.
    
    Signed-off-by: Trent Piepho <xyzzy@speakeasy.org>
    Cc: Zwane Mwaikambo <zwane@fsmlabs.com>
    Acked-by: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Johannes Stezenbach <js@linuxtv.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/extable.c b/kernel/extable.c
index 7501b531ceed..7fe262855317 100644
--- a/kernel/extable.c
+++ b/kernel/extable.c
@@ -40,7 +40,7 @@ const struct exception_table_entry *search_exception_tables(unsigned long addr)
 	return e;
 }
 
-static int core_kernel_text(unsigned long addr)
+int core_kernel_text(unsigned long addr)
 {
 	if (addr >= (unsigned long)_stext &&
 	    addr <= (unsigned long)_etext)

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/kernel/extable.c b/kernel/extable.c
new file mode 100644
index 000000000000..7501b531ceed
--- /dev/null
+++ b/kernel/extable.c
@@ -0,0 +1,67 @@
+/* Rewritten by Rusty Russell, on the backs of many others...
+   Copyright (C) 2001 Rusty Russell, 2002 Rusty Russell IBM.
+
+    This program is free software; you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation; either version 2 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with this program; if not, write to the Free Software
+    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+*/
+#include <linux/module.h>
+#include <linux/init.h>
+#include <asm/uaccess.h>
+#include <asm/sections.h>
+
+extern struct exception_table_entry __start___ex_table[];
+extern struct exception_table_entry __stop___ex_table[];
+
+/* Sort the kernel's built-in exception table */
+void __init sort_main_extable(void)
+{
+	sort_extable(__start___ex_table, __stop___ex_table);
+}
+
+/* Given an address, look for it in the exception tables. */
+const struct exception_table_entry *search_exception_tables(unsigned long addr)
+{
+	const struct exception_table_entry *e;
+
+	e = search_extable(__start___ex_table, __stop___ex_table-1, addr);
+	if (!e)
+		e = search_module_extables(addr);
+	return e;
+}
+
+static int core_kernel_text(unsigned long addr)
+{
+	if (addr >= (unsigned long)_stext &&
+	    addr <= (unsigned long)_etext)
+		return 1;
+
+	if (addr >= (unsigned long)_sinittext &&
+	    addr <= (unsigned long)_einittext)
+		return 1;
+	return 0;
+}
+
+int __kernel_text_address(unsigned long addr)
+{
+	if (core_kernel_text(addr))
+		return 1;
+	return __module_text_address(addr) != NULL;
+}
+
+int kernel_text_address(unsigned long addr)
+{
+	if (core_kernel_text(addr))
+		return 1;
+	return module_text_address(addr) != NULL;
+}
