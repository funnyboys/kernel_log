commit f736e0f1a55a88cb258b73da77463573739e9ac9
Merge: e2f3ccfa6200 6be7436d2245 e5a971d76d70 33b2b93bd831 3c80b4024579
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Thu May 7 10:18:32 2020 -0700

    Merge branches 'fixes.2020.04.27a', 'kfree_rcu.2020.04.27a', 'rcu-tasks.2020.04.27a', 'stall.2020.04.27a' and 'torture.2020.05.07a' into HEAD
    
    fixes.2020.04.27a:  Miscellaneous fixes.
    kfree_rcu.2020.04.27a:  Changes related to kfree_rcu().
    rcu-tasks.2020.04.27a:  Addition of new RCU-tasks flavors.
    stall.2020.04.27a:  RCU CPU stall-warning updates.
    torture.2020.05.07a:  Torture-test updates.

commit 55b2dcf58700041d6f0b037a98619222c825f004
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Wed Apr 1 19:57:52 2020 -0700

    rcu: Allow rcutorture to starve grace-period kthread
    
    This commit provides an rcutorture.stall_gp_kthread module parameter
    to allow rcutorture to starve the grace-period kthread.  This allows
    testing the code that detects such starvation.
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 00ddc92c5774..cdbc5f98f584 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -454,6 +454,7 @@ void do_trace_rcu_torture_read(const char *rcutorturename,
 			       unsigned long secs,
 			       unsigned long c_old,
 			       unsigned long c);
+void rcu_gp_set_torture_wait(int duration);
 #else
 static inline void rcutorture_get_gp_data(enum rcutorture_type test_type,
 					  int *flags, unsigned long *gp_seq)
@@ -471,6 +472,7 @@ void do_trace_rcu_torture_read(const char *rcutorturename,
 #define do_trace_rcu_torture_read(rcutorturename, rhp, secs, c_old, c) \
 	do { } while (0)
 #endif
+static inline void rcu_gp_set_torture_wait(int duration) { }
 #endif
 
 #if IS_ENABLED(CONFIG_RCU_TORTURE_TEST) || IS_MODULE(CONFIG_RCU_TORTURE_TEST)

commit 7d0c9c50c5a109acd7a5cf589fc5563f9ef7149a
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Thu Mar 19 15:33:12 2020 -0700

    rcu-tasks: Avoid IPIing userspace/idle tasks if kernel is so built
    
    Systems running CPU-bound real-time task do not want IPIs sent to CPUs
    executing nohz_full userspace tasks.  Battery-powered systems don't
    want IPIs sent to idle CPUs in low-power mode.  Unfortunately, RCU tasks
    trace can and will send such IPIs in some cases.
    
    Both of these situations occur only when the target CPU is in RCU
    dyntick-idle mode, in other words, when RCU is not watching the
    target CPU.  This suggests that CPUs in dyntick-idle mode should use
    memory barriers in outermost invocations of rcu_read_lock_trace()
    and rcu_read_unlock_trace(), which would allow the RCU tasks trace
    grace period to directly read out the target CPU's read-side state.
    One challenge is that RCU tasks trace is not targeting a specific
    CPU, but rather a task.  And that task could switch from one CPU to
    another at any time.
    
    This commit therefore uses try_invoke_on_locked_down_task()
    and checks for task_curr() in trc_inspect_reader_notrunning().
    When this condition holds, the target task is running and cannot move.
    If CONFIG_TASKS_TRACE_RCU_READ_MB=y, the new rcu_dynticks_zero_in_eqs()
    function can be used to check if the specified integer (in this case,
    t->trc_reader_nesting) is zero while the target CPU remains in that same
    dyntick-idle sojourn.  If so, the target task is in a quiescent state.
    If not, trc_read_check_handler() must indicate failure so that the
    grace-period kthread can take appropriate action or retry after an
    appropriate delay, as the case may be.
    
    With this change, given CONFIG_TASKS_TRACE_RCU_READ_MB=y, if a given
    CPU remains idle or a given task continues executing in nohz_full mode,
    the RCU tasks trace grace-period kthread will detect this without the
    need to send an IPI.
    
    Suggested-by: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index e1089fdf8626..296f9262d119 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -501,6 +501,7 @@ void srcutorture_get_gp_data(enum rcutorture_type test_type,
 #endif
 
 #ifdef CONFIG_TINY_RCU
+static inline bool rcu_dynticks_zero_in_eqs(int cpu, int *vp) { return false; }
 static inline unsigned long rcu_get_gp_seq(void) { return 0; }
 static inline unsigned long rcu_exp_batches_completed(void) { return 0; }
 static inline unsigned long
@@ -510,6 +511,7 @@ static inline void show_rcu_gp_kthreads(void) { }
 static inline int rcu_get_gp_kthreads_prio(void) { return 0; }
 static inline void rcu_fwd_progress_check(unsigned long j) { }
 #else /* #ifdef CONFIG_TINY_RCU */
+bool rcu_dynticks_zero_in_eqs(int cpu, int *vp);
 unsigned long rcu_get_gp_seq(void);
 unsigned long rcu_exp_batches_completed(void);
 unsigned long srcu_batches_completed(struct srcu_struct *sp);

commit e21408ceec2de5be418efa39feb1e2c00f824a72
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Mon Mar 16 11:01:55 2020 -0700

    rcu-tasks: Add RCU tasks to rcutorture writer stall output
    
    This commit adds state for each RCU-tasks flavor to the rcutorture
    writer stall output.  The initial state is minimal, but you have to
    start somewhere.
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    [ paulmck: Fixes based on feedback from kbuild test robot. ]

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 72903867833e..e1089fdf8626 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -431,6 +431,7 @@ bool rcu_gp_is_expedited(void);  /* Internal RCU use. */
 void rcu_expedite_gp(void);
 void rcu_unexpedite_gp(void);
 void rcupdate_announce_bootup_oddness(void);
+void show_rcu_tasks_gp_kthreads(void);
 void rcu_request_urgent_qs_task(struct task_struct *t);
 #endif /* #else #ifdef CONFIG_TINY_RCU */
 

commit c1a76c0b6abac4e7eb49b5c24a0829f47b70769d
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Tue Mar 10 10:32:30 2020 -0700

    rcutorture: Add torture tests for RCU Tasks Trace
    
    This commit adds the definitions required to torture the tracing flavor
    of RCU tasks.
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index c5746202e124..72903867833e 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -442,6 +442,7 @@ enum rcutorture_type {
 	RCU_FLAVOR,
 	RCU_TASKS_FLAVOR,
 	RCU_TASKS_RUDE_FLAVOR,
+	RCU_TASKS_TRACING_FLAVOR,
 	RCU_TRIVIAL_FLAVOR,
 	SRCU_FLAVOR,
 	INVALID_RCU_FLAVOR

commit 3d6e43c75d6bab212e8bc142585ee36eb8e2e5d9
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Tue Mar 3 15:02:50 2020 -0800

    rcutorture: Add torture tests for RCU Tasks Rude
    
    This commit adds the definitions required to torture the rude flavor of
    RCU tasks.
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 00ddc92c5774..c5746202e124 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -441,6 +441,7 @@ void rcu_request_urgent_qs_task(struct task_struct *t);
 enum rcutorture_type {
 	RCU_FLAVOR,
 	RCU_TASKS_FLAVOR,
+	RCU_TASKS_RUDE_FLAVOR,
 	RCU_TRIVIAL_FLAVOR,
 	SRCU_FLAVOR,
 	INVALID_RCU_FLAVOR

commit aa93ec620be378cce1454286122915533ff8fa48
Merge: 8149b5cbfa15 127e29815b4b 613707929b30 28e09a2e4848 b692dc4adfcf 90ba11ba99e0 710426068dc6 a144935ceaed
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Sat Mar 21 17:15:11 2020 -0700

    Merge branches 'doc.2020.02.27a', 'fixes.2020.03.21a', 'kfree_rcu.2020.02.20a', 'locktorture.2020.02.20a', 'ovld.2020.02.20a', 'rcu-tasks.2020.02.20a', 'srcu.2020.02.20a' and 'torture.2020.02.20a' into HEAD
    
    doc.2020.02.27a: Documentation updates.
    fixes.2020.03.21a: Miscellaneous fixes.
    kfree_rcu.2020.02.20a: Updates to kfree_rcu().
    locktorture.2020.02.20a: Lock torture-test updates.
    ovld.2020.02.20a: Updates to callback-overload handling.
    rcu-tasks.2020.02.20a: RCU-tasks updates.
    srcu.2020.02.20a: SRCU updates.
    torture.2020.02.20a: Torture-test updates.

commit 58c53360b36d2077cbb843e7ad2bf75f0498271c
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Thu Dec 5 11:29:01 2019 -0800

    rcutorture: Allow boottime stall warnings to be suppressed
    
    In normal production, an RCU CPU stall warning at boottime is often
    just as bad as at any other time.  In fact, given the desire for fast
    boot, any sort of long-term stall at boot is a bad idea.  However,
    heavy rcutorture testing on large hyperthreaded systems can generate
    boottime RCU CPU stalls as a matter of course.  This commit therefore
    provides a kernel boot parameter that suppresses reporting of boottime
    RCU CPU stall warnings and similarly of rcutorture writer stalls.
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 05f936ed167a..1779cbf33cd1 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -198,6 +198,13 @@ static inline void debug_rcu_head_unqueue(struct rcu_head *head)
 }
 #endif	/* #else !CONFIG_DEBUG_OBJECTS_RCU_HEAD */
 
+extern int rcu_cpu_stall_suppress_at_boot;
+
+static inline bool rcu_stall_is_suppressed_at_boot(void)
+{
+	return rcu_cpu_stall_suppress_at_boot && !rcu_inkernel_boot_has_ended();
+}
+
 #ifdef CONFIG_RCU_STALL_COMMON
 
 extern int rcu_cpu_stall_ftrace_dump;
@@ -205,6 +212,11 @@ extern int rcu_cpu_stall_suppress;
 extern int rcu_cpu_stall_timeout;
 int rcu_jiffies_till_stall_check(void);
 
+static inline bool rcu_stall_is_suppressed(void)
+{
+	return rcu_stall_is_suppressed_at_boot() || rcu_cpu_stall_suppress;
+}
+
 #define rcu_ftrace_dump_stall_suppress() \
 do { \
 	if (!rcu_cpu_stall_suppress) \
@@ -218,6 +230,11 @@ do { \
 } while (0)
 
 #else /* #endif #ifdef CONFIG_RCU_STALL_COMMON */
+
+static inline bool rcu_stall_is_suppressed(void)
+{
+	return rcu_stall_is_suppressed_at_boot();
+}
 #define rcu_ftrace_dump_stall_suppress()
 #define rcu_ftrace_dump_stall_unsuppress()
 #endif /* #ifdef CONFIG_RCU_STALL_COMMON */

commit 82dd8419e225958f01708cda8a3fc6c3c5356228
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Sun Dec 15 11:38:57 2019 -0800

    rcu: Warn on for_each_leaf_node_cpu_mask() from non-leaf
    
    The for_each_leaf_node_cpu_mask() and for_each_leaf_node_possible_cpu()
    macros must be invoked only on leaf rcu_node structures.  Failing to
    abide by this restriction can result in infinite loops on systems with
    more than 64 CPUs (or for more than 32 CPUs on 32-bit systems).  This
    commit therefore adds WARN_ON_ONCE() calls to make misuse of these two
    macros easier to debug.
    
    Reported-by: Qian Cai <cai@lca.pw>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 05f936ed167a..f6ce173e35f6 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -325,7 +325,8 @@ static inline void rcu_init_levelspread(int *levelspread, const int *levelcnt)
  * Iterate over all possible CPUs in a leaf RCU node.
  */
 #define for_each_leaf_node_possible_cpu(rnp, cpu) \
-	for ((cpu) = cpumask_next((rnp)->grplo - 1, cpu_possible_mask); \
+	for (WARN_ON_ONCE(!rcu_is_leaf_node(rnp)), \
+	     (cpu) = cpumask_next((rnp)->grplo - 1, cpu_possible_mask); \
 	     (cpu) <= rnp->grphi; \
 	     (cpu) = cpumask_next((cpu), cpu_possible_mask))
 
@@ -335,7 +336,8 @@ static inline void rcu_init_levelspread(int *levelspread, const int *levelcnt)
 #define rcu_find_next_bit(rnp, cpu, mask) \
 	((rnp)->grplo + find_next_bit(&(mask), BITS_PER_LONG, (cpu)))
 #define for_each_leaf_node_cpu_mask(rnp, cpu, mask) \
-	for ((cpu) = rcu_find_next_bit((rnp), 0, (mask)); \
+	for (WARN_ON_ONCE(!rcu_is_leaf_node(rnp)), \
+	     (cpu) = rcu_find_next_bit((rnp), 0, (mask)); \
 	     (cpu) <= rnp->grphi; \
 	     (cpu) = rcu_find_next_bit((rnp), (cpu) + 1 - (rnp->grplo), (mask)))
 

commit 0e247386d9ed5ab8b7dad010cf4b183efeb1e47d
Merge: 6e6eca2ee79a df1e849ae455 f6105fc2a9c0 189a6883dcf7 afa47fdfa29f 5b14557b073c b22eb7cefb9d
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Fri Jan 24 10:37:27 2020 -0800

    Merge branches 'doc.2019.12.10a', 'exp.2019.12.09a', 'fixes.2020.01.24a', 'kfree_rcu.2020.01.24a', 'list.2020.01.10a', 'preempt.2020.01.24a' and 'torture.2019.12.09a' into HEAD
    
    doc.2019.12.10a: Documentations updates
    exp.2019.12.09a: Expedited grace-period updates
    fixes.2020.01.24a: Miscellaneous fixes
    kfree_rcu.2020.01.24a: Batch kfree_rcu() work
    list.2020.01.10a: RCU-protected-list updates
    preempt.2020.01.24a: Preemptible RCU updates
    torture.2019.12.09a: Torture-test updates

commit 822175e72995a9ff7eeef4f5cd3f945f2697b67d
Author: Lai Jiangshan <jiangshanlai@gmail.com>
Date:   Tue Oct 15 10:23:56 2019 +0000

    rcu: Fix harmless omission of "CONFIG_" from #if condition
    
    The C preprocessor macros SRCU and TINY_RCU should instead be CONFIG_SRCU
    and CONFIG_TINY_RCU, respectively in the #f in kernel/rcu/rcu.h. But
    there is no harm when "TINY_RCU" is wrongly used, which are always
    non-defined, which makes "!defined(TINY_RCU)" always true, which means
    the code block is always included, and the included code block doesn't
    cause any compilation error so far in CONFIG_TINY_RCU builds.  It is
    also the reason this change should not be taken in -stable.
    
    This commit adds the needed "CONFIG_" prefix to both macros.
    
    Not for -stable.
    
    Signed-off-by: Lai Jiangshan <jiangshanlai@gmail.com>
    Signed-off-by: Lai Jiangshan <laijs@linux.alibaba.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index ab504fbc76ca..473259422547 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -281,7 +281,7 @@ void rcu_test_sync_prims(void);
  */
 extern void resched_cpu(int cpu);
 
-#if defined(SRCU) || !defined(TINY_RCU)
+#if defined(CONFIG_SRCU) || !defined(CONFIG_TINY_RCU)
 
 #include <linux/rcu_node_tree.h>
 
@@ -418,7 +418,7 @@ do {									\
 #define raw_lockdep_assert_held_rcu_node(p)				\
 	lockdep_assert_held(&ACCESS_PRIVATE(p, lock))
 
-#endif /* #if defined(SRCU) || !defined(TINY_RCU) */
+#endif /* #if defined(CONFIG_SRCU) || !defined(CONFIG_TINY_RCU) */
 
 #ifdef CONFIG_SRCU
 void srcu_init(void);

commit 77a40f97030b27b3fc1640a3ed203870f0817f57
Author: Joel Fernandes (Google) <joel@joelfernandes.org>
Date:   Fri Aug 30 12:36:32 2019 -0400

    rcu: Remove kfree_rcu() special casing and lazy-callback handling
    
    This commit removes kfree_rcu() special-casing and the lazy-callback
    handling from Tree RCU.  It moves some of this special casing to Tiny RCU,
    the removal of which will be the subject of later commits.
    
    This results in a nice negative delta.
    
    Suggested-by: Paul E. McKenney <paulmck@linux.ibm.com>
    Signed-off-by: Joel Fernandes (Google) <joel@joelfernandes.org>
    [ paulmck: Add slab.h #include, thanks to kbuild test robot <lkp@intel.com>. ]
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index ab504fbc76ca..c30a1f7dbd15 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -198,33 +198,6 @@ static inline void debug_rcu_head_unqueue(struct rcu_head *head)
 }
 #endif	/* #else !CONFIG_DEBUG_OBJECTS_RCU_HEAD */
 
-void kfree(const void *);
-
-/*
- * Reclaim the specified callback, either by invoking it (non-lazy case)
- * or freeing it directly (lazy case).  Return true if lazy, false otherwise.
- */
-static inline bool __rcu_reclaim(const char *rn, struct rcu_head *head)
-{
-	rcu_callback_t f;
-	unsigned long offset = (unsigned long)head->func;
-
-	rcu_lock_acquire(&rcu_callback_map);
-	if (__is_kfree_rcu_offset(offset)) {
-		trace_rcu_invoke_kfree_callback(rn, head, offset);
-		kfree((void *)head - offset);
-		rcu_lock_release(&rcu_callback_map);
-		return true;
-	} else {
-		trace_rcu_invoke_callback(rn, head);
-		f = head->func;
-		WRITE_ONCE(head->func, (rcu_callback_t)0L);
-		f(head);
-		rcu_lock_release(&rcu_callback_map);
-		return false;
-	}
-}
-
 #ifdef CONFIG_RCU_STALL_COMMON
 
 extern int rcu_cpu_stall_ftrace_dump;

commit b3e627d3d5092a87fc9b9e37e341610cfecfbfdc
Author: Lai Jiangshan <laijs@linux.alibaba.com>
Date:   Tue Oct 15 02:55:57 2019 +0000

    rcu: Make PREEMPT_RCU be a modifier to TREE_RCU
    
    Currently PREEMPT_RCU and TREE_RCU are mutually exclusive Kconfig
    options.  But PREEMPT_RCU actually specifies a kind of TREE_RCU,
    namely a preemptible TREE_RCU. This commit therefore makes PREEMPT_RCU
    be a modifer to the TREE_RCU Kconfig option.  This has the benefit of
    simplifying several of the #if expressions that formerly needed to
    check both, but now need only check one or the other.
    
    Signed-off-by: Lai Jiangshan <laijs@linux.alibaba.com>
    Signed-off-by: Lai Jiangshan <jiangshanlai@gmail.com>
    Reviewed-by: Joel Fernandes (Google) <joel@joelfernandes.org>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index ab504fbc76ca..eabafde2349e 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -454,7 +454,7 @@ enum rcutorture_type {
 	INVALID_RCU_FLAVOR
 };
 
-#if defined(CONFIG_TREE_RCU) || defined(CONFIG_PREEMPT_RCU)
+#if defined(CONFIG_TREE_RCU)
 void rcutorture_get_gp_data(enum rcutorture_type test_type, int *flags,
 			    unsigned long *gp_seq);
 void do_trace_rcu_torture_read(const char *rcutorturename,

commit 8dcdfb7096a304130ab36fbb0f2961deaf863e5a
Merge: b1ec18eae0b6 36b5dae64513 dd7dafd1ad50 a60a5746004d 67d64918a163 c58a80170169
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Wed Oct 30 08:47:13 2019 -0700

    Merge branches 'doc.2019.10.29a', 'fixes.2019.10.30a', 'nohz.2019.10.28a', 'replace.2019.10.30a', 'torture.2019.10.05a' and 'lkmm.2019.10.05a' into HEAD
    
    doc.2019.10.29a: RCU documentation updates.
    fixes.2019.10.30a: RCU miscellaneous fixes.
    nohz.2019.10.28a: RCU NO_HZ and NO_HZ_FULL updates.
    replace.2019.10.30a: Replace rcu_swap_protected() with rcu_replace().
    torture.2019.10.05a: RCU torture-test updates.
    
    lkmm.2019.10.05a: Linux kernel memory model updates.

commit 36b5dae64513b7ce3a0e0f6cb469e0f74bacad45
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Wed Sep 18 10:10:31 2019 -0700

    rcu: Suppress levelspread uninitialized messages
    
    New tools bring new warnings, and with v5.3 comes:
    
    kernel/rcu/srcutree.c: warning: 'levelspread[<U aa0>]' may be used uninitialized in this function [-Wuninitialized]:  => 121:34
    
    This commit suppresses this warning by initializing the full array
    to INT_MIN, which will result in failures should any out-of-bounds
    references appear.
    
    Reported-by: Michael Ellerman <mpe@ellerman.id.au>
    Reported-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Reviewed-by: Geert Uytterhoeven <geert@linux-m68k.org>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 8fd4f82c9b3d..b64c707f6065 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -299,6 +299,8 @@ static inline void rcu_init_levelspread(int *levelspread, const int *levelcnt)
 {
 	int i;
 
+	for (i = 0; i < RCU_NUM_LVLS; i++)
+		levelspread[i] = INT_MIN;
 	if (rcu_fanout_exact) {
 		levelspread[rcu_num_lvls - 1] = rcu_fanout_leaf;
 		for (i = rcu_num_lvls - 2; i >= 0; i--)

commit ac5f636130c2014eb535f30951460b75db6cbe04
Author: Ethan Hansen <1ethanhansen@gmail.com>
Date:   Thu Aug 1 14:00:40 2019 -0700

    rcu: Remove unused function rcutorture_record_progress()
    
    The function rcutorture_record_progress() is declared in rcu.h, but is
    never used.  This commit therefore removes rcutorture_record_progress()
    to clean code.
    
    Signed-off-by: Ethan Hansen <1ethanhansen@gmail.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 8fd4f82c9b3d..aeec70fda82c 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -455,7 +455,6 @@ enum rcutorture_type {
 #if defined(CONFIG_TREE_RCU) || defined(CONFIG_PREEMPT_RCU)
 void rcutorture_get_gp_data(enum rcutorture_type test_type, int *flags,
 			    unsigned long *gp_seq);
-void rcutorture_record_progress(unsigned long vernum);
 void do_trace_rcu_torture_read(const char *rcutorturename,
 			       struct rcu_head *rhp,
 			       unsigned long secs,
@@ -468,7 +467,6 @@ static inline void rcutorture_get_gp_data(enum rcutorture_type test_type,
 	*flags = 0;
 	*gp_seq = 0;
 }
-static inline void rcutorture_record_progress(unsigned long vernum) { }
 #ifdef CONFIG_RCU_TRACE
 void do_trace_rcu_torture_read(const char *rcutorturename,
 			       struct rcu_head *rhp,

commit cdc694b2359d52cd6d0465d5a6263d97c786fb0c
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Thu Jun 13 15:30:49 2019 -0700

    rcu: Add kernel parameter to dump trace after RCU CPU stall warning
    
    This commit adds a rcu_cpu_stall_ftrace_dump kernel boot parameter, that,
    when set, causes the trace buffer to be dumped after an RCU CPU stall
    warning is printed.  This kernel boot parameter is disabled by default,
    maintaining compatibility with previous behavior.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 5290b01de534..8fd4f82c9b3d 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -227,6 +227,7 @@ static inline bool __rcu_reclaim(const char *rn, struct rcu_head *head)
 
 #ifdef CONFIG_RCU_STALL_COMMON
 
+extern int rcu_cpu_stall_ftrace_dump;
 extern int rcu_cpu_stall_suppress;
 extern int rcu_cpu_stall_timeout;
 int rcu_jiffies_till_stall_check(void);

commit c682db558e6eec10a711b0a6bcb8c35fd15f6a39
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Fri Apr 19 07:38:27 2019 -0700

    rcutorture: Add trivial RCU implementation
    
    I have been showing off a trivial RCU implementation for non-preemptive
    environments for some time now:
    
            #define rcu_read_lock()
            #define rcu_read_unlock()
            #define rcu_dereference(p) READ_ONCE(p)
            #define rcu_assign_pointer(p, v) smp_store_release(&(p), (v))
            void synchronize_rcu(void)
            {
            int cpu;
                    for_each_online_cpu(cpu)
                            sched_setaffinity(current->pid, cpumask_of(cpu));
            }
    
    Trivial or not, as the old saying goes, "if it ain't tested, it don't
    work!".  This commit therefore adds a "trivial" flavor to rcutorture
    and a corresponding TRIVIAL test scenario.  This variant does not handle
    CPU hotplug, which is unconditionally enabled on x86 for post-v5.1-rc3
    kernels, which is why the TRIVIAL.boot says "rcutorture.onoff_interval=0".
    This commit actually does handle CONFIG_PREEMPT=y kernels, but only
    because it turns back the Linux-kernel clock in order to provide these
    alternative definitions (or the moral equivalent thereof):
    
            #define rcu_read_lock() preempt_disable()
            #define rcu_read_unlock() preempt_enable()
    
    In CONFIG_PREEMPT=n kernels without debugging, these are equivalent to
    empty macros give or take a compiler barrier.  However, the have been
    successfully tested with actual empty macros as well.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>
    [ paulmck: Fix symbol issue reported by kbuild test robot <lkp@intel.com>. ]
    [ paulmck: Work around sched_setaffinity() issue noted by Andrea Parri. ]
    [ paulmck: Add rcutorture.shuffle_interval=0 to TRIVIAL.boot to fix
      interaction with shuffler task noted by Peter Zijlstra. ]
    Tested-by: Andrea Parri <andrea.parri@amarulasolutions.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 390aab20115e..5290b01de534 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -446,6 +446,7 @@ void rcu_request_urgent_qs_task(struct task_struct *t);
 enum rcutorture_type {
 	RCU_FLAVOR,
 	RCU_TASKS_FLAVOR,
+	RCU_TRIVIAL_FLAVOR,
 	SRCU_FLAVOR,
 	INVALID_RCU_FLAVOR
 };
@@ -479,6 +480,10 @@ void do_trace_rcu_torture_read(const char *rcutorturename,
 #endif
 #endif
 
+#if IS_ENABLED(CONFIG_RCU_TORTURE_TEST) || IS_MODULE(CONFIG_RCU_TORTURE_TEST)
+long rcutorture_sched_setaffinity(pid_t pid, const struct cpumask *in_mask);
+#endif
+
 #ifdef CONFIG_TINY_SRCU
 
 static inline void srcutorture_get_gp_data(enum rcutorture_type test_type,

commit d2d8b146043ae7e250aef1fb312971f6f479d487
Merge: 2bbacd1a9278 693713cbdb3a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 15 16:05:47 2019 -0700

    Merge tag 'trace-v5.2' of git://git.kernel.org/pub/scm/linux/kernel/git/rostedt/linux-trace
    
    Pull tracing updates from Steven Rostedt:
     "The major changes in this tracing update includes:
    
       - Removal of non-DYNAMIC_FTRACE from 32bit x86
    
       - Removal of mcount support from x86
    
       - Emulating a call from int3 on x86_64, fixes live kernel patching
    
       - Consolidated Tracing Error logs file
    
      Minor updates:
    
       - Removal of klp_check_compiler_support()
    
       - kdb ftrace dumping output changes
    
       - Accessing and creating ftrace instances from inside the kernel
    
       - Clean up of #define if macro
    
       - Introduction of TRACE_EVENT_NOP() to disable trace events based on
         config options
    
      And other minor fixes and clean ups"
    
    * tag 'trace-v5.2' of git://git.kernel.org/pub/scm/linux/kernel/git/rostedt/linux-trace: (44 commits)
      x86: Hide the int3_emulate_call/jmp functions from UML
      livepatch: Remove klp_check_compiler_support()
      ftrace/x86: Remove mcount support
      ftrace/x86_32: Remove support for non DYNAMIC_FTRACE
      tracing: Simplify "if" macro code
      tracing: Fix documentation about disabling options using trace_options
      tracing: Replace kzalloc with kcalloc
      tracing: Fix partial reading of trace event's id file
      tracing: Allow RCU to run between postponed startup tests
      tracing: Fix white space issues in parse_pred() function
      tracing: Eliminate const char[] auto variables
      ring-buffer: Fix mispelling of Calculate
      tracing: probeevent: Fix to make the type of $comm string
      tracing: probeevent: Do not accumulate on ret variable
      tracing: uprobes: Re-enable $comm support for uprobe events
      ftrace/x86_64: Emulate call function while updating in breakpoint handler
      x86_64: Allow breakpoints to emulate call instructions
      x86_64: Add gap to int3 to allow for call emulation
      tracing: kdb: Allow ftdump to skip all but the last few entries
      tracing: Add trace_total_entries() / trace_total_entries_cpu()
      ...

commit 4f5fbd78a7b40bab538ae0d316363530da751e42
Author: Yafang Shao <laoar.shao@gmail.com>
Date:   Tue Mar 26 20:13:11 2019 +0800

    rcu: validate arguments for rcu tracepoints
    
    When CONFIG_RCU_TRACE is not set, all these tracepoints are defined as
    do-nothing macro.
    We'd better make those inline functions that take proper arguments.
    
    As RCU_TRACE() is defined as do-nothing marco as well when
    CONFIG_RCU_TRACE is not set, so we can clean it up.
    
    Link: http://lkml.kernel.org/r/1553602391-11926-4-git-send-email-laoar.shao@gmail.com
    
    Reviewed-by: Paul E. McKenney <paulmck@linux.ibm.com>
    Signed-off-by: Yafang Shao <laoar.shao@gmail.com>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index acee72c0b24b..442ace406ac9 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -11,11 +11,6 @@
 #define __LINUX_RCU_H
 
 #include <trace/events/rcu.h>
-#ifdef CONFIG_RCU_TRACE
-#define RCU_TRACE(stmt) stmt
-#else /* #ifdef CONFIG_RCU_TRACE */
-#define RCU_TRACE(stmt)
-#endif /* #else #ifdef CONFIG_RCU_TRACE */
 
 /* Offset to allow distinguishing irq vs. task-based idle entry/exit. */
 #define DYNTICK_IRQ_NONIDLE	((LONG_MAX / 2) + 1)
@@ -216,12 +211,12 @@ static inline bool __rcu_reclaim(const char *rn, struct rcu_head *head)
 
 	rcu_lock_acquire(&rcu_callback_map);
 	if (__is_kfree_rcu_offset(offset)) {
-		RCU_TRACE(trace_rcu_invoke_kfree_callback(rn, head, offset);)
+		trace_rcu_invoke_kfree_callback(rn, head, offset);
 		kfree((void *)head - offset);
 		rcu_lock_release(&rcu_callback_map);
 		return true;
 	} else {
-		RCU_TRACE(trace_rcu_invoke_callback(rn, head);)
+		trace_rcu_invoke_callback(rn, head);
 		f = head->func;
 		WRITE_ONCE(head->func, (rcu_callback_t)0L);
 		f(head);

commit 10462d6f58fb6dbde7563e9343505d98d5bfba3d
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Fri Jan 11 16:10:57 2019 -0800

    rcu: Move RCU CPU stall-warning code out of update.c
    
    The RCU CPU stall-warning code for normal grace periods is currently
    scattered across three files, due to earlier Tiny RCU support for RCU
    CPU stall warnings and for old Kconfig options that have long since
    been retired.  Given that it is hard for the lead RCU maintainer to
    find relevant stall-warning code, it would be good to consolidate it.
    This commit starts this process by moving stall-warning code from
    kernel/rcu/update.c to a new kernel/rcu/tree_stall.h file.
    
    Note that the definitions of rcu_cpu_stall_suppress and
    rcu_cpu_stall_timeout must remain in kernel/rcu/update.h to provide
    compatibility for kernel boot parameter lists.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index acee72c0b24b..4b58c907b4b7 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -233,6 +233,7 @@ static inline bool __rcu_reclaim(const char *rn, struct rcu_head *head)
 #ifdef CONFIG_RCU_STALL_COMMON
 
 extern int rcu_cpu_stall_suppress;
+extern int rcu_cpu_stall_timeout;
 int rcu_jiffies_till_stall_check(void);
 
 #define rcu_ftrace_dump_stall_suppress() \

commit e7ffb4eb9a6d89678e7f62461737899f88dab64e
Merge: 87d1779dc48f 423a86a610ca 6706dae90d85 5a4eb3cb2012 e81baf4cb19a 6684880a8b16
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Sat Feb 9 08:47:52 2019 -0800

    Merge branches 'doc.2019.01.26a', 'fixes.2019.01.26a', 'sil.2019.01.26a', 'spdx.2019.02.09a', 'srcu.2019.01.26a' and 'torture.2019.01.26a' into HEAD
    
    doc.2019.01.26a:  Documentation updates.
    fixes.2019.01.26a:  Miscellaneous fixes.
    sil.2019.01.26a:  Removal of a few more spin_is_locked() instances.
    spdx.2019.02.09a:  Add SPDX identifiers to RCU files
    srcu.2019.01.26a:  SRCU updates.
    torture.2019.01.26a: Torture-test updates.

commit b5b11890de69ec216ab7a10a24fcd1b2d46a2d6e
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Thu Jan 17 10:05:33 2019 -0800

    rcu/rcu.h: Convert to SPDX license identifier
    
    Replace the license boiler plate with a SPDX license identifier.
    While in the area, update an email address.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 75787186bd4f..e672b8f050ac 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -1,23 +1,10 @@
+/* SPDX-License-Identifier: GPL-2.0+ */
 /*
  * Read-Copy Update definitions shared among RCU implementations.
  *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, you can access it online at
- * http://www.gnu.org/licenses/gpl-2.0.html.
- *
  * Copyright IBM Corporation, 2011
  *
- * Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
+ * Author: Paul E. McKenney <paulmck@linux.ibm.com>
  */
 
 #ifndef __LINUX_RCU_H

commit c2d8089de7f0b849af11c271278fe6b904db5df2
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Wed Nov 28 12:47:23 2018 -0800

    rcu: Fix obsolete DYNTICK_IRQ_NONIDLE comment
    
    This commit updates the DYNTICK_IRQ_NONIDLE header comment to remove
    the obsolete commentary about unmatched rcu_irq_{enter,exit}().
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 75787186bd4f..51f1fb21f171 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -30,7 +30,7 @@
 #define RCU_TRACE(stmt)
 #endif /* #else #ifdef CONFIG_RCU_TRACE */
 
-/* Offset to allow for unmatched rcu_irq_{enter,exit}(). */
+/* Offset to allow distinguishing irq vs. task-based idle entry/exit. */
 #define DYNTICK_IRQ_NONIDLE	((LONG_MAX / 2) + 1)
 
 

commit c97058d03329284068e45796df13510e5f940d8b
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Wed Nov 28 16:59:50 2018 -0800

    rcu: Eliminate RCU_BH_FLAVOR and RCU_SCHED_FLAVOR
    
    Now that the RCU flavors have been consolidated, RCU_BH_FLAVOR and
    RCU_SCHED_FLAVOR are no longer used.  This commit therefore saves a
    few lines by removing them.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index a393e24a9195..75787186bd4f 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -462,8 +462,6 @@ void rcu_request_urgent_qs_task(struct task_struct *t);
 
 enum rcutorture_type {
 	RCU_FLAVOR,
-	RCU_BH_FLAVOR,
-	RCU_SCHED_FLAVOR,
 	RCU_TASKS_FLAVOR,
 	SRCU_FLAVOR,
 	INVALID_RCU_FLAVOR

commit e0aff97355575ac6a28a48a4217533a3953095c5
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Mon Oct 1 17:40:54 2018 -0700

    rcutorture: Dump grace-period diagnostics upon forward-progress OOM
    
    This commit adds an OOM notifier during rcutorture forward-progress
    testing.  If this notifier is invoked, it dumps out some grace-period
    state to help debug the forward-progress problem.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 0f0f5ae8c3d4..a393e24a9195 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -526,12 +526,14 @@ srcu_batches_completed(struct srcu_struct *sp) { return 0; }
 static inline void rcu_force_quiescent_state(void) { }
 static inline void show_rcu_gp_kthreads(void) { }
 static inline int rcu_get_gp_kthreads_prio(void) { return 0; }
+static inline void rcu_fwd_progress_check(unsigned long j) { }
 #else /* #ifdef CONFIG_TINY_RCU */
 unsigned long rcu_get_gp_seq(void);
 unsigned long rcu_exp_batches_completed(void);
 unsigned long srcu_batches_completed(struct srcu_struct *sp);
 void show_rcu_gp_kthreads(void);
 int rcu_get_gp_kthreads_prio(void);
+void rcu_fwd_progress_check(unsigned long j);
 void rcu_force_quiescent_state(void);
 extern struct workqueue_struct *rcu_gp_wq;
 extern struct workqueue_struct *rcu_par_gp_wq;

commit 5ab7ab8362fa8a4f7995d65ea05edf71530e8004
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Fri Sep 21 18:08:09 2018 -0700

    rcutorture: Affinity forward-progress test to avoid housekeeping CPUs
    
    This commit affinities the forward-progress tests to avoid hogging a
    housekeeping CPU on the theory that the offloaded callbacks will be
    running on those housekeeping CPUs.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>
    [ paulmck: Fix NULL-pointer issue located by kbuild test robot. ]
    Tested-by: Rong Chen <rong.a.chen@intel.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 2866166863f0..0f0f5ae8c3d4 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -539,8 +539,10 @@ extern struct workqueue_struct *rcu_par_gp_wq;
 
 #ifdef CONFIG_RCU_NOCB_CPU
 bool rcu_is_nocb_cpu(int cpu);
+void rcu_bind_current_to_nocb(void);
 #else
 static inline bool rcu_is_nocb_cpu(int cpu) { return false; }
+static inline void rcu_bind_current_to_nocb(void) { }
 #endif
 
 #endif /* __LINUX_RCU_H */

commit b56ada120921fbb0a4fb2a5bee163717182e7e9e
Merge: 5c3f78ec285b 894d45bbf7e7 4e6ea4ef56f9 7c590fcca66b
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu Aug 30 16:12:53 2018 -0700

    Merge branches 'doc.2018.08.30a', 'dynticks.2018.08.30b', 'srcu.2018.08.30b' and 'torture.2018.08.29a' into HEAD
    
    doc.2018.08.30a: Documentation updates
    dynticks.2018.08.30b: RCU flavor consolidation updates and cleanups
    srcu.2018.08.30b: SRCU updates
    torture.2018.08.29a: Torture-test updates

commit e0fcba9ac02af5aeb1e1c3e842eab987f817c309
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Aug 14 08:45:54 2018 -0700

    srcu: Make call_srcu() available during very early boot
    
    Event tracing is moving to SRCU in order to take advantage of the fact
    that SRCU may be safely used from idle and even offline CPUs.  However,
    event tracing can invoke call_srcu() very early in the boot process,
    even before workqueue_init_early() is invoked (let alone rcu_init()).
    Therefore, call_srcu()'s attempts to queue work fail miserably.
    
    This commit therefore detects this situation, and refrains from attempting
    to queue work before rcu_init() time, but does everything else that it
    would have done, and in addition, adds the srcu_struct to a global list.
    The rcu_init() function now invokes a new srcu_init() function, which
    is empty if CONFIG_SRCU=n.  Otherwise, srcu_init() queues work for
    each srcu_struct on the list.  This all happens early enough in boot
    that there is but a single CPU with interrupts disabled, which allows
    synchronization to be dispensed with.
    
    Of course, the queued work won't actually be invoked until after
    workqueue_init() is invoked, which happens shortly after the scheduler
    is up and running.  This means that although call_srcu() may be invoked
    any time after per-CPU variables have been set up, there is still a very
    narrow window when synchronize_srcu() won't work, and this window
    extends from the time that the scheduler starts until the time that
    workqueue_init() returns.  This can be fixed in a manner similar to
    the fix for synchronize_rcu_expedited() and friends, but until someone
    actually needs to use synchronize_srcu() during this window, this fix
    is added churn for no benefit.
    
    Finally, note that Tree SRCU's new srcu_init() function invokes
    queue_work() rather than the queue_delayed_work() function that is
    invoked post-boot.  The reason is that queue_delayed_work() will (as you
    would expect) post a timer, and timers have not yet been initialized.
    So use of queue_work() avoids the complaints about use of uninitialized
    spinlocks that would otherwise result.  Besides, some delay is already
    provide by the aforementioned fact that the queued work won't actually
    be invoked until after the scheduler is up and running.
    
    Requested-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Tested-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 4d04683c31b2..e1b5aec5ec1c 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -435,6 +435,12 @@ do {									\
 
 #endif /* #if defined(SRCU) || !defined(TINY_RCU) */
 
+#ifdef CONFIG_SRCU
+void srcu_init(void);
+#else /* #ifdef CONFIG_SRCU */
+static inline void srcu_init(void) { }
+#endif /* #else #ifdef CONFIG_SRCU */
+
 #ifdef CONFIG_TINY_RCU
 /* Tiny RCU doesn't expedite, as its purpose in life is instead to be tiny. */
 static inline bool rcu_gp_is_normal(void) { return true; }

commit 74de6960c99d8df0d09fb29a7b014cb9c5571e2b
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Jul 24 15:28:09 2018 -0700

    rcu: Provide functions for determining if call_rcu() has been invoked
    
    This commit adds rcu_head_init() and rcu_head_after_call_rcu() functions
    to help RCU users detect when another CPU has passed the specified
    rcu_head structure and function to call_rcu().  The rcu_head_init()
    should be invoked before making the structure visible to RCU readers,
    and then the rcu_head_after_call_rcu() may be invoked from within
    an RCU read-side critical section on an rcu_head structure that
    was obtained during a traversal of the data structure in question.
    The rcu_head_after_call_rcu() function will return true if the rcu_head
    structure has already been passed (with the specified function) to
    call_rcu(), otherwise it will return false.
    
    If rcu_head_init() has not been invoked on the rcu_head structure
    or if the rcu_head (AKA callback) has already been invoked, then
    rcu_head_after_call_rcu() will do WARN_ON_ONCE().
    
    Reported-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    [ paulmck: Apply neilb naming feedback. ]

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 5dec94509a7e..4c56c1d98fb3 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -224,6 +224,7 @@ void kfree(const void *);
  */
 static inline bool __rcu_reclaim(const char *rn, struct rcu_head *head)
 {
+	rcu_callback_t f;
 	unsigned long offset = (unsigned long)head->func;
 
 	rcu_lock_acquire(&rcu_callback_map);
@@ -234,7 +235,9 @@ static inline bool __rcu_reclaim(const char *rn, struct rcu_head *head)
 		return true;
 	} else {
 		RCU_TRACE(trace_rcu_invoke_callback(rn, head);)
-		head->func(head);
+		f = head->func;
+		WRITE_ONCE(head->func, (rcu_callback_t)0L);
+		f(head);
 		rcu_lock_release(&rcu_callback_map);
 		return false;
 	}

commit 7f87c036fea3c17eb6a6e4f4164c67aeb98710ea
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Sat Jul 7 18:12:26 2018 -0700

    rcu: Clean up flavor-related definitions and comments in rcu.h
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index aa3dc08af4b3..5dec94509a7e 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -176,8 +176,9 @@ static inline unsigned long rcu_seq_diff(unsigned long new, unsigned long old)
 
 /*
  * debug_rcu_head_queue()/debug_rcu_head_unqueue() are used internally
- * by call_rcu() and rcu callback execution, and are therefore not part of the
- * RCU API. Leaving in rcupdate.h because they are used by all RCU flavors.
+ * by call_rcu() and rcu callback execution, and are therefore not part
+ * of the RCU API. These are in rcupdate.h because they are used by all
+ * RCU implementations.
  */
 
 #ifdef CONFIG_DEBUG_OBJECTS_RCU_HEAD
@@ -328,7 +329,7 @@ static inline void rcu_init_levelspread(int *levelspread, const int *levelcnt)
 	}
 }
 
-/* Returns first leaf rcu_node of the specified RCU flavor. */
+/* Returns a pointer to the first leaf rcu_node structure. */
 #define rcu_first_leaf_node() (rcu_state.level[rcu_num_lvls - 1])
 
 /* Is this rcu_node a leaf? */
@@ -339,7 +340,8 @@ static inline void rcu_init_levelspread(int *levelspread, const int *levelcnt)
 
 /*
  * Do a full breadth-first scan of the {s,}rcu_node structures for the
- * specified rcu_state structure.
+ * specified state structure (for SRCU) or the only rcu_state structure
+ * (for RCU).
  */
 #define srcu_for_each_node_breadth_first(sp, rnp) \
 	for ((rnp) = &(sp)->node[0]; \
@@ -348,10 +350,10 @@ static inline void rcu_init_levelspread(int *levelspread, const int *levelcnt)
 	srcu_for_each_node_breadth_first(&rcu_state, rnp)
 
 /*
- * Scan the leaves of the rcu_node hierarchy for the specified rcu_state
- * structure.  Note that if there is a singleton rcu_node tree with but
- * one rcu_node structure, this loop -will- visit the rcu_node structure.
- * It is still a leaf node, even if it is also the root node.
+ * Scan the leaves of the rcu_node hierarchy for the rcu_state structure.
+ * Note that if there is a singleton rcu_node tree with but one rcu_node
+ * structure, this loop -will- visit the rcu_node structure.  It is still
+ * a leaf node, even if it is also the root node.
  */
 #define rcu_for_each_leaf_node(rnp) \
 	for ((rnp) = rcu_first_leaf_node(); \

commit de3875d3023310416d08eaab3c1a8527e9b452bf
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Sat Jul 7 21:43:17 2018 -0700

    rcu: Remove now-unused rcutorture APIs
    
    This commit removes rcu_sched_get_gp_seq(), rcu_bh_get_gp_seq(),
    rcu_exp_batches_completed_sched(), rcu_sched_force_quiescent_state(),
    and rcu_bh_force_quiescent_state(), which are no longer used because
    rcutorture no longer does "rcu_bh" and "rcu_sched" torture types.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 2bb77fddc11f..aa3dc08af4b3 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -509,29 +509,19 @@ void srcutorture_get_gp_data(enum rcutorture_type test_type,
 
 #ifdef CONFIG_TINY_RCU
 static inline unsigned long rcu_get_gp_seq(void) { return 0; }
-static inline unsigned long rcu_bh_get_gp_seq(void) { return 0; }
-static inline unsigned long rcu_sched_get_gp_seq(void) { return 0; }
 static inline unsigned long rcu_exp_batches_completed(void) { return 0; }
-static inline unsigned long rcu_exp_batches_completed_sched(void) { return 0; }
 static inline unsigned long
 srcu_batches_completed(struct srcu_struct *sp) { return 0; }
 static inline void rcu_force_quiescent_state(void) { }
-static inline void rcu_bh_force_quiescent_state(void) { }
-static inline void rcu_sched_force_quiescent_state(void) { }
 static inline void show_rcu_gp_kthreads(void) { }
 static inline int rcu_get_gp_kthreads_prio(void) { return 0; }
 #else /* #ifdef CONFIG_TINY_RCU */
 unsigned long rcu_get_gp_seq(void);
-unsigned long rcu_bh_get_gp_seq(void);
-unsigned long rcu_sched_get_gp_seq(void);
 unsigned long rcu_exp_batches_completed(void);
-unsigned long rcu_exp_batches_completed_sched(void);
 unsigned long srcu_batches_completed(struct srcu_struct *sp);
 void show_rcu_gp_kthreads(void);
 int rcu_get_gp_kthreads_prio(void);
 void rcu_force_quiescent_state(void);
-void rcu_bh_force_quiescent_state(void);
-void rcu_sched_force_quiescent_state(void);
 extern struct workqueue_struct *rcu_gp_wq;
 extern struct workqueue_struct *rcu_par_gp_wq;
 #endif /* #else #ifdef CONFIG_TINY_RCU */

commit aedf4ba984168ab5b96898a03bfdb51d07194776
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed Jul 4 14:33:59 2018 -0700

    rcu: Remove rsp parameter from rcu_node tree accessor macros
    
    There now is only one rcu_state structure in a given build of the Linux
    kernel, so there is no need to pass it as a parameter to RCU's rcu_node
    tree's accessor macros.  This commit therefore removes the rsp parameter
    from those macros in kernel/rcu/rcu.h, and removes some now-unused rsp
    local variables while in the area.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 4d04683c31b2..2bb77fddc11f 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -329,29 +329,23 @@ static inline void rcu_init_levelspread(int *levelspread, const int *levelcnt)
 }
 
 /* Returns first leaf rcu_node of the specified RCU flavor. */
-#define rcu_first_leaf_node(rsp) ((rsp)->level[rcu_num_lvls - 1])
+#define rcu_first_leaf_node() (rcu_state.level[rcu_num_lvls - 1])
 
 /* Is this rcu_node a leaf? */
 #define rcu_is_leaf_node(rnp) ((rnp)->level == rcu_num_lvls - 1)
 
 /* Is this rcu_node the last leaf? */
-#define rcu_is_last_leaf_node(rsp, rnp) ((rnp) == &(rsp)->node[rcu_num_nodes - 1])
+#define rcu_is_last_leaf_node(rnp) ((rnp) == &rcu_state.node[rcu_num_nodes - 1])
 
 /*
- * Do a full breadth-first scan of the rcu_node structures for the
+ * Do a full breadth-first scan of the {s,}rcu_node structures for the
  * specified rcu_state structure.
  */
-#define rcu_for_each_node_breadth_first(rsp, rnp) \
-	for ((rnp) = &(rsp)->node[0]; \
-	     (rnp) < &(rsp)->node[rcu_num_nodes]; (rnp)++)
-
-/*
- * Do a breadth-first scan of the non-leaf rcu_node structures for the
- * specified rcu_state structure.  Note that if there is a singleton
- * rcu_node tree with but one rcu_node structure, this loop is a no-op.
- */
-#define rcu_for_each_nonleaf_node_breadth_first(rsp, rnp) \
-	for ((rnp) = &(rsp)->node[0]; !rcu_is_leaf_node(rsp, rnp); (rnp)++)
+#define srcu_for_each_node_breadth_first(sp, rnp) \
+	for ((rnp) = &(sp)->node[0]; \
+	     (rnp) < &(sp)->node[rcu_num_nodes]; (rnp)++)
+#define rcu_for_each_node_breadth_first(rnp) \
+	srcu_for_each_node_breadth_first(&rcu_state, rnp)
 
 /*
  * Scan the leaves of the rcu_node hierarchy for the specified rcu_state
@@ -359,9 +353,9 @@ static inline void rcu_init_levelspread(int *levelspread, const int *levelcnt)
  * one rcu_node structure, this loop -will- visit the rcu_node structure.
  * It is still a leaf node, even if it is also the root node.
  */
-#define rcu_for_each_leaf_node(rsp, rnp) \
-	for ((rnp) = rcu_first_leaf_node(rsp); \
-	     (rnp) < &(rsp)->node[rcu_num_nodes]; (rnp)++)
+#define rcu_for_each_leaf_node(rnp) \
+	for ((rnp) = rcu_first_leaf_node(); \
+	     (rnp) < &rcu_state.node[rcu_num_nodes]; (rnp)++)
 
 /*
  * Iterate over all possible CPUs in a leaf RCU node.

commit 18952651dae8efcc6d565c97f8fe5629b399cb3e
Merge: c7cd161ecb21 bf5b64355a3c
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu Jul 12 15:42:41 2018 -0700

    Merge branches 'fixes1.2018.07.12b' and 'torture1.2018.07.12b' into HEAD
    
    fixes1.2018.07.12b: Post-gp_seq miscellaneous fixes
    torture1.2018.07.12b: Post-gp_seq torture-test updates

commit 4babd855fd6137f9792117eb73b096c221a49d3c
Author: Joel Fernandes (Google) <joel@joelfernandes.org>
Date:   Tue Jun 19 15:14:18 2018 -0700

    rcutorture: Add support to detect if boost kthread prio is too low
    
    When rcutorture is built in to the kernel, an earlier patch detects
    that and raises the priority of RCU's kthreads to allow rcutorture's
    RCU priority boosting tests to succeed.
    
    However, if rcutorture is built as a module, those priorities must be
    raised manually via the rcutree.kthread_prio kernel boot parameter.
    If this manual step is not taken, rcutorture's RCU priority boosting
    tests will fail due to kthread starvation.  One approach would be to
    raise the default priority, but that risks breaking existing users.
    Another approach would be to allow runtime adjustment of RCU's kthread
    priorities, but that introduces numerous "interesting" race conditions.
    This patch therefore instead detects too-low priorities, and prints a
    message and disables the RCU priority boosting tests in that case.
    
    Signed-off-by: Joel Fernandes (Google) <joel@joelfernandes.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 0453a7d12b3f..bee070979970 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -502,6 +502,7 @@ static inline void rcu_force_quiescent_state(void) { }
 static inline void rcu_bh_force_quiescent_state(void) { }
 static inline void rcu_sched_force_quiescent_state(void) { }
 static inline void show_rcu_gp_kthreads(void) { }
+static inline int rcu_get_gp_kthreads_prio(void) { return 0; }
 #else /* #ifdef CONFIG_TINY_RCU */
 unsigned long rcu_get_gp_seq(void);
 unsigned long rcu_bh_get_gp_seq(void);
@@ -510,6 +511,7 @@ unsigned long rcu_exp_batches_completed(void);
 unsigned long rcu_exp_batches_completed_sched(void);
 unsigned long srcu_batches_completed(struct srcu_struct *sp);
 void show_rcu_gp_kthreads(void);
+int rcu_get_gp_kthreads_prio(void);
 void rcu_force_quiescent_state(void);
 void rcu_bh_force_quiescent_state(void);
 void rcu_sched_force_quiescent_state(void);

commit 6bea2cc5a97b7e9677088b1a93e27edb74ae0e55
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed May 16 15:30:36 2018 -0700

    rcu: Remove rcutorture test version and sequence number
    
    Back when RCU had a debugfs interface, there was a test version and
    sequence number that allowed associating debugfs data with a particular
    test run, where the test run started with modprobe and ended with rmmod,
    which was how tests were run back on the old ABAT system within IBM.
    But rcutorture testing no longer runs on ABAT, and there is no longer an
    RCU debugfs interface, so there is no longer any need for test versions
    and sequence numbers.
    
    This commit therefore removes the rcutorture_record_test_transition()
    and rcutorture_record_progress() functions, and along with them the
    rcutorture_testseq and rcutorture_vernum variables that they update.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index aa215d6355f8..0453a7d12b3f 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -444,7 +444,6 @@ enum rcutorture_type {
 #if defined(CONFIG_TREE_RCU) || defined(CONFIG_PREEMPT_RCU)
 void rcutorture_get_gp_data(enum rcutorture_type test_type, int *flags,
 			    unsigned long *gp_seq);
-void rcutorture_record_test_transition(void);
 void rcutorture_record_progress(unsigned long vernum);
 void do_trace_rcu_torture_read(const char *rcutorturename,
 			       struct rcu_head *rhp,
@@ -458,7 +457,6 @@ static inline void rcutorture_get_gp_data(enum rcutorture_type test_type,
 	*flags = 0;
 	*gp_seq = 0;
 }
-static inline void rcutorture_record_test_transition(void) { }
 static inline void rcutorture_record_progress(unsigned long vernum) { }
 #ifdef CONFIG_RCU_TRACE
 void do_trace_rcu_torture_read(const char *rcutorturename,
@@ -505,8 +503,6 @@ static inline void rcu_bh_force_quiescent_state(void) { }
 static inline void rcu_sched_force_quiescent_state(void) { }
 static inline void show_rcu_gp_kthreads(void) { }
 #else /* #ifdef CONFIG_TINY_RCU */
-extern unsigned long rcutorture_testseq;
-extern unsigned long rcutorture_vernum;
 unsigned long rcu_get_gp_seq(void);
 unsigned long rcu_bh_get_gp_seq(void);
 unsigned long rcu_sched_get_gp_seq(void);

commit 2ee5aca54622aacc196106c623fea4116f1043a6
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Sat Jun 9 01:22:20 2018 -0700

    rcu: Make rcu_seq_diff() more exact
    
    The current implementatation of rcu_seq_diff() follows tradition in
    providing a rough-and-ready approximation of the number of elapsed grace
    periods between the two rcu_seq values.  However, this difference is
    used to flag RCU-failure "near misses", which can be a valuable debugging
    aid, so more exactitude would be an improvement.  This commit therefore
    improves the accuracy of rcu_seq_diff().
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 89f13fffac73..d5e0294b8580 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -158,7 +158,20 @@ static inline bool rcu_seq_new_gp(unsigned long old, unsigned long new)
  */
 static inline unsigned long rcu_seq_diff(unsigned long new, unsigned long old)
 {
-	return (new - old) >> RCU_SEQ_CTR_SHIFT;
+	unsigned long rnd_diff;
+
+	if (old == new)
+		return 0;
+	/*
+	 * Compute the number of grace periods (still shifted up), plus
+	 * one if either of new and old is not an exact grace period.
+	 */
+	rnd_diff = (new & ~RCU_SEQ_STATE_MASK) -
+		   ((old + RCU_SEQ_STATE_MASK) & ~RCU_SEQ_STATE_MASK) +
+		   ((new & RCU_SEQ_STATE_MASK) || (old & RCU_SEQ_STATE_MASK));
+	if (ULONG_CMP_GE(RCU_SEQ_STATE_MASK, rnd_diff))
+		return 1; /* Definitely no grace period has elapsed. */
+	return ((rnd_diff - RCU_SEQ_STATE_MASK - 1) >> RCU_SEQ_CTR_SHIFT) + 2;
 }
 
 /*

commit 0d805a70a652a6eef8d0283e5183879e7acb85ad
Author: Joel Fernandes (Google) <joel@joelfernandes.org>
Date:   Tue May 22 23:38:13 2018 -0700

    rcu: Add comment documenting how rcu_seq_snap works
    
    rcu_seq_snap may be tricky to decipher. Lets document how it works with
    an example to make it easier.
    
    Signed-off-by: Joel Fernandes (Google) <joel@joelfernandes.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    [ paulmck: Shrink comment as suggested by Peter Zijlstra. ]

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index aa215d6355f8..89f13fffac73 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -91,7 +91,17 @@ static inline void rcu_seq_end(unsigned long *sp)
 	WRITE_ONCE(*sp, rcu_seq_endval(sp));
 }
 
-/* Take a snapshot of the update side's sequence number. */
+/*
+ * rcu_seq_snap - Take a snapshot of the update side's sequence number.
+ *
+ * This function returns the earliest value of the grace-period sequence number
+ * that will indicate that a full grace period has elapsed since the current
+ * time.  Once the grace-period sequence number has reached this value, it will
+ * be safe to invoke all callbacks that have been registered prior to the
+ * current time. This value is the current grace-period number plus two to the
+ * power of the number of low-order bits reserved for state, then rounded up to
+ * the next value in which the state bits are all zero.
+ */
 static inline unsigned long rcu_seq_snap(unsigned long *sp)
 {
 	unsigned long s;

commit d72193123c81ae6123d108b3be2096f3f13b25a6
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue May 15 15:24:41 2018 -0700

    rcutorture: Correctly handle grace-period sequence wrap
    
    The new ->gq_seq grace-period sequence numbers must be shifted down,
    which give artifacts when these numbers wrap.  This commit therefore
    enables rcutorture and rcuperf to handle grace-period sequence numbers
    even if they do wrap.  It does this by allowing a special subtraction
    function to be specified, and this function subtracts before shifting.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 1c5cbd9d7c97..aa215d6355f8 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -142,6 +142,15 @@ static inline bool rcu_seq_new_gp(unsigned long old, unsigned long new)
 			    new);
 }
 
+/*
+ * Roughly how many full grace periods have elapsed between the collection
+ * of the two specified grace periods?
+ */
+static inline unsigned long rcu_seq_diff(unsigned long new, unsigned long old)
+{
+	return (new - old) >> RCU_SEQ_CTR_SHIFT;
+}
+
 /*
  * debug_rcu_head_queue()/debug_rcu_head_unqueue() are used internally
  * by call_rcu() and rcu callback execution, and are therefore not part of the

commit 2e3e5e55010105f9d4351f68e15dbc43402a7794
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue May 15 11:53:41 2018 -0700

    rcu: Make rcu_start_this_gp() check for grace period already started
    
    In the old days of ->gpnum and ->completed, the code requesting a new
    grace period checked to see if that grace period had already started,
    bailing early if so.  The new-age ->gp_seq approach instead checks
    whether the grace period has already finished.  A compensating change
    pushed the requested grace period down to the bottom of the tree, thus
    reducing lock contention and even eliminating it in some cases.  But why
    not further reduce contention, especially on large systems, by doing both,
    especially given that the cost of doing both is extremely small?
    
    This commit therefore adds a new rcu_seq_started() function that checks
    whether a specified grace period has already started.  It then uses
    this new function in place of rcu_seq_done() in the rcu_start_this_gp()
    function's funnel locking code.
    
    Reported-by: Joel Fernandes <joel@joelfernandes.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 003671825d62..1c5cbd9d7c97 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -107,6 +107,15 @@ static inline unsigned long rcu_seq_current(unsigned long *sp)
 	return READ_ONCE(*sp);
 }
 
+/*
+ * Given a snapshot from rcu_seq_snap(), determine whether or not the
+ * corresponding update-side operation has started.
+ */
+static inline bool rcu_seq_started(unsigned long *sp, unsigned long s)
+{
+	return ULONG_CMP_LT((s - 1) & ~RCU_SEQ_STATE_MASK, READ_ONCE(*sp));
+}
+
 /*
  * Given a snapshot from rcu_seq_snap(), determine whether or not a
  * full update-side operation has occurred.

commit aebc82644b2c8eafa15e8c481fbafc1b41f4fbf9
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue May 1 06:42:51 2018 -0700

    rcutorture: Convert rcutorture_get_gp_data() to ->gp_seq
    
    SRCU has long used ->srcu_gp_seq, and now RCU uses ->gp_seq.  This
    commit therefore moves the rcutorture_get_gp_data() function from
    a ->gpnum / ->completed pair to ->gp_seq.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 7568a3fd0815..003671825d62 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -425,7 +425,7 @@ enum rcutorture_type {
 
 #if defined(CONFIG_TREE_RCU) || defined(CONFIG_PREEMPT_RCU)
 void rcutorture_get_gp_data(enum rcutorture_type test_type, int *flags,
-			    unsigned long *gpnum, unsigned long *completed);
+			    unsigned long *gp_seq);
 void rcutorture_record_test_transition(void);
 void rcutorture_record_progress(unsigned long vernum);
 void do_trace_rcu_torture_read(const char *rcutorturename,
@@ -435,13 +435,10 @@ void do_trace_rcu_torture_read(const char *rcutorturename,
 			       unsigned long c);
 #else
 static inline void rcutorture_get_gp_data(enum rcutorture_type test_type,
-					  int *flags,
-					  unsigned long *gpnum,
-					  unsigned long *completed)
+					  int *flags, unsigned long *gp_seq)
 {
 	*flags = 0;
-	*gpnum = 0;
-	*completed = 0;
+	*gp_seq = 0;
 }
 static inline void rcutorture_record_test_transition(void) { }
 static inline void rcutorture_record_progress(unsigned long vernum) { }
@@ -461,21 +458,19 @@ void do_trace_rcu_torture_read(const char *rcutorturename,
 
 static inline void srcutorture_get_gp_data(enum rcutorture_type test_type,
 					   struct srcu_struct *sp, int *flags,
-					   unsigned long *gpnum,
-					   unsigned long *completed)
+					   unsigned long *gp_seq)
 {
 	if (test_type != SRCU_FLAVOR)
 		return;
 	*flags = 0;
-	*completed = sp->srcu_idx;
-	*gpnum = *completed;
+	*gp_seq = sp->srcu_idx;
 }
 
 #elif defined(CONFIG_TREE_SRCU)
 
 void srcutorture_get_gp_data(enum rcutorture_type test_type,
 			     struct srcu_struct *sp, int *flags,
-			     unsigned long *gpnum, unsigned long *completed);
+			     unsigned long *gp_seq);
 
 #endif
 

commit 67e14c1e39d2d956300b3d6ad00f7708e3285531
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Fri Apr 27 16:01:46 2018 -0700

    rcu: Move RCU's grace-period-change code to ->gp_seq
    
    This commit moves __note_gp_changes(), note_gp_changes(), and
    __rcu_pending() to ->gp_seq, creating new rcu_seq_completed_gp() and
    rcu_seq_new_gp() functions for this purpose.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    [ paulmck: Reinstate "cpuend: trace as suggested by Joel Fernandes. ]

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index f0907f9f6cd0..7568a3fd0815 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -116,6 +116,23 @@ static inline bool rcu_seq_done(unsigned long *sp, unsigned long s)
 	return ULONG_CMP_GE(READ_ONCE(*sp), s);
 }
 
+/*
+ * Has a grace period completed since the time the old gp_seq was collected?
+ */
+static inline bool rcu_seq_completed_gp(unsigned long old, unsigned long new)
+{
+	return ULONG_CMP_LT(old, new & ~RCU_SEQ_STATE_MASK);
+}
+
+/*
+ * Has a grace period started since the time the old gp_seq was collected?
+ */
+static inline bool rcu_seq_new_gp(unsigned long old, unsigned long new)
+{
+	return ULONG_CMP_LT((old + RCU_SEQ_STATE_MASK) & ~RCU_SEQ_STATE_MASK,
+			    new);
+}
+
 /*
  * debug_rcu_head_queue()/debug_rcu_head_unqueue() are used internally
  * by call_rcu() and rcu callback execution, and are therefore not part of the

commit 17ef2fe97c8c8e754e4a702c42f8e5b0ffadf4dd
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Fri Apr 27 11:39:34 2018 -0700

    rcu: Make rcutorture's batches-completed API use ->gp_seq
    
    The rcutorture test invokes rcu_batches_started(),
    rcu_batches_completed(), rcu_batches_started_bh(),
    rcu_batches_completed_bh(), rcu_batches_started_sched(), and
    rcu_batches_completed_sched() to do grace-period consistency checks,
    and rcuperf uses the _completed variants for statistics.
    These functions use ->gpnum and ->completed.  This commit therefore
    replaces them with rcu_get_gp_seq(), rcu_bh_get_gp_seq(), and
    rcu_sched_get_gp_seq(), adjusting rcutorture and rcuperf to make
    use of them.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index db0870acfdff..f0907f9f6cd0 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -463,12 +463,9 @@ void srcutorture_get_gp_data(enum rcutorture_type test_type,
 #endif
 
 #ifdef CONFIG_TINY_RCU
-static inline unsigned long rcu_batches_started(void) { return 0; }
-static inline unsigned long rcu_batches_started_bh(void) { return 0; }
-static inline unsigned long rcu_batches_started_sched(void) { return 0; }
-static inline unsigned long rcu_batches_completed(void) { return 0; }
-static inline unsigned long rcu_batches_completed_bh(void) { return 0; }
-static inline unsigned long rcu_batches_completed_sched(void) { return 0; }
+static inline unsigned long rcu_get_gp_seq(void) { return 0; }
+static inline unsigned long rcu_bh_get_gp_seq(void) { return 0; }
+static inline unsigned long rcu_sched_get_gp_seq(void) { return 0; }
 static inline unsigned long rcu_exp_batches_completed(void) { return 0; }
 static inline unsigned long rcu_exp_batches_completed_sched(void) { return 0; }
 static inline unsigned long
@@ -480,12 +477,9 @@ static inline void show_rcu_gp_kthreads(void) { }
 #else /* #ifdef CONFIG_TINY_RCU */
 extern unsigned long rcutorture_testseq;
 extern unsigned long rcutorture_vernum;
-unsigned long rcu_batches_started(void);
-unsigned long rcu_batches_started_bh(void);
-unsigned long rcu_batches_started_sched(void);
-unsigned long rcu_batches_completed(void);
-unsigned long rcu_batches_completed_bh(void);
-unsigned long rcu_batches_completed_sched(void);
+unsigned long rcu_get_gp_seq(void);
+unsigned long rcu_bh_get_gp_seq(void);
+unsigned long rcu_sched_get_gp_seq(void);
 unsigned long rcu_exp_batches_completed(void);
 unsigned long rcu_exp_batches_completed_sched(void);
 unsigned long srcu_batches_completed(struct srcu_struct *sp);

commit 5257514d8885b2ebc11bf359ea1527282b47a5fd
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Apr 24 11:03:39 2018 -0700

    rcu: Make expedited grace period use direct call on last leaf
    
    During expedited grace-period initialization, a work item is scheduled
    for each leaf rcu_node structure.  However, that initialization code
    is itself (normally) executing from a workqueue, so one of the leaf
    rcu_node structures could just as well be handled by that pre-existing
    workqueue, and with less overhead.  This commit therefore uses a
    shiny new rcu_is_leaf_node() macro to execute the last leaf rcu_node
    structure's initialization directly from the pre-existing workqueue.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 40cea6735c2d..db0870acfdff 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -276,6 +276,9 @@ static inline void rcu_init_levelspread(int *levelspread, const int *levelcnt)
 /* Is this rcu_node a leaf? */
 #define rcu_is_leaf_node(rnp) ((rnp)->level == rcu_num_lvls - 1)
 
+/* Is this rcu_node the last leaf? */
+#define rcu_is_last_leaf_node(rsp, rnp) ((rnp) == &(rsp)->node[rcu_num_nodes - 1])
+
 /*
  * Do a full breadth-first scan of the rcu_node structures for the
  * specified rcu_state structure.

commit 22df7316ac71dc1ac57415349938737d2a229c59
Merge: 55ebfce0605a 628c08420bc6 c21b8b3ed0eb da1a1e192306
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue May 15 10:33:05 2018 -0700

    Merge branches 'exp.2018.05.15a', 'fixes.2018.05.15a', 'lock.2018.05.15a' and 'torture.2018.05.15a' into HEAD
    
    exp.2018.05.15a: Parallelize expedited grace-period initialization.
    fixes.2018.05.15a: Miscellaneous fixes.
    lock.2018.05.15a: Decrease lock contention on root rcu_node structure,
            which is a step towards merging RCU flavors.
    torture.2018.05.15a: Torture-test updates.

commit 5b4c11d54b1b8d0714702006e00441ada59889a9
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Fri Apr 13 17:11:44 2018 -0700

    rcu: Add leaf-node macros
    
    This commit adds rcu_first_leaf_node() that returns a pointer to
    the first leaf rcu_node structure in the specified RCU flavor and an
    rcu_is_leaf_node() that returns true iff the specified rcu_node structure
    is a leaf.  This commit also uses these macros where appropriate.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Tested-by: Nicholas Piggin <npiggin@gmail.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 7a693e31184a..5b5bb9ee2e20 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -270,6 +270,12 @@ static inline void rcu_init_levelspread(int *levelspread, const int *levelcnt)
 	}
 }
 
+/* Returns first leaf rcu_node of the specified RCU flavor. */
+#define rcu_first_leaf_node(rsp) ((rsp)->level[rcu_num_lvls - 1])
+
+/* Is this rcu_node a leaf? */
+#define rcu_is_leaf_node(rnp) ((rnp)->level == rcu_num_lvls - 1)
+
 /*
  * Do a full breadth-first scan of the rcu_node structures for the
  * specified rcu_state structure.
@@ -284,8 +290,7 @@ static inline void rcu_init_levelspread(int *levelspread, const int *levelcnt)
  * rcu_node tree with but one rcu_node structure, this loop is a no-op.
  */
 #define rcu_for_each_nonleaf_node_breadth_first(rsp, rnp) \
-	for ((rnp) = &(rsp)->node[0]; \
-	     (rnp) < (rsp)->level[rcu_num_lvls - 1]; (rnp)++)
+	for ((rnp) = &(rsp)->node[0]; !rcu_is_leaf_node(rsp, rnp); (rnp)++)
 
 /*
  * Scan the leaves of the rcu_node hierarchy for the specified rcu_state
@@ -294,7 +299,7 @@ static inline void rcu_init_levelspread(int *levelspread, const int *levelcnt)
  * It is still a leaf node, even if it is also the root node.
  */
 #define rcu_for_each_leaf_node(rsp, rnp) \
-	for ((rnp) = (rsp)->level[rcu_num_lvls - 1]; \
+	for ((rnp) = rcu_first_leaf_node(rsp); \
 	     (rnp) < &(rsp)->node[rcu_num_nodes]; (rnp)++)
 
 /*

commit 25f3d7effab632eb10d145f1a5aebf6515a04b98
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu Feb 1 22:05:38 2018 -0800

    rcu: Parallelize expedited grace-period initialization
    
    The latency of RCU expedited grace periods grows with increasing numbers
    of CPUs, eventually failing to be all that expedited.  Much of the growth
    in latency is in the initialization phase, so this commit uses workqueues
    to carry out this initialization concurrently on a rcu_node-by-rcu_node
    basis.
    
    This change makes use of a new rcu_par_gp_wq because flushing a work
    item from another work item running from the same workqueue can result
    in deadlock.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Tested-by: Nicholas Piggin <npiggin@gmail.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 7a693e31184a..976019d6fa06 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -486,6 +486,7 @@ void rcu_force_quiescent_state(void);
 void rcu_bh_force_quiescent_state(void);
 void rcu_sched_force_quiescent_state(void);
 extern struct workqueue_struct *rcu_gp_wq;
+extern struct workqueue_struct *rcu_par_gp_wq;
 #endif /* #else #ifdef CONFIG_TINY_RCU */
 
 #ifdef CONFIG_RCU_NOCB_CPU

commit ad7c946b35ad455417fdd4bc0e17deda4011841b
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Jan 8 14:35:52 2018 -0800

    rcu: Create RCU-specific workqueues with rescuers
    
    RCU's expedited grace periods can participate in out-of-memory deadlocks
    due to all available system_wq kthreads being blocked and there not being
    memory available to create more.  This commit prevents such deadlocks
    by allocating an RCU-specific workqueue_struct at early boot time, and
    providing it with a rescuer to ensure forward progress.  This uses the
    shiny new init_rescuer() function provided by Tejun (but indirectly).
    
    This commit also causes SRCU to use this new RCU-specific
    workqueue_struct.  Note that SRCU's use of workqueues never blocks them
    waiting for readers, so this should be safe from a forward-progress
    viewpoint.  Note that this moves SRCU from system_power_efficient_wq
    to a normal workqueue.  In the unlikely event that this results in
    measurable degradation, a separate power-efficient workqueue will be
    creates for SRCU.
    
    Reported-by: Prateek Sood <prsood@codeaurora.org>
    Reported-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Tejun Heo <tj@kernel.org>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 1c868bcfd705..7a693e31184a 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -485,6 +485,7 @@ void show_rcu_gp_kthreads(void);
 void rcu_force_quiescent_state(void);
 void rcu_bh_force_quiescent_state(void);
 void rcu_sched_force_quiescent_state(void);
+extern struct workqueue_struct *rcu_gp_wq;
 #endif /* #else #ifdef CONFIG_TINY_RCU */
 
 #ifdef CONFIG_RCU_NOCB_CPU

commit 65963d246147c46aafda2b04523d6dbe6c457e7c
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed Jan 31 20:24:15 2018 -0800

    rcu: Make expedited RCU CPU selection avoid unnecessary stores
    
    This commit reworks the first loop in sync_rcu_exp_select_cpus()
    to avoid doing unnecssary stores to other CPUs' rcu_data
    structures.  This speeds up that first loop by roughly a factor of
    two on an old x86 system.  In the case where the system is mostly
    idle, this loop incurs a large fraction of the overhead of the
    synchronize_rcu_expedited().  There is less benefit on busy systems
    because the overhead of the smp_call_function_single() in the second
    loop dominates in that case.
    
    However, it is not unusual to do configuration chances involving
    RCU grace periods (both expedited and normal) while the system is
    mostly idle, so this optimization is worth doing.
    
    While we are in the area, this commit also adds parentheses to arguments
    used by the for_each_leaf_node_possible_cpu() macro.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 507a0802c717..1c868bcfd705 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -301,9 +301,19 @@ static inline void rcu_init_levelspread(int *levelspread, const int *levelcnt)
  * Iterate over all possible CPUs in a leaf RCU node.
  */
 #define for_each_leaf_node_possible_cpu(rnp, cpu) \
-	for ((cpu) = cpumask_next(rnp->grplo - 1, cpu_possible_mask); \
-	     cpu <= rnp->grphi; \
-	     cpu = cpumask_next((cpu), cpu_possible_mask))
+	for ((cpu) = cpumask_next((rnp)->grplo - 1, cpu_possible_mask); \
+	     (cpu) <= rnp->grphi; \
+	     (cpu) = cpumask_next((cpu), cpu_possible_mask))
+
+/*
+ * Iterate over all CPUs in a leaf RCU node's specified mask.
+ */
+#define rcu_find_next_bit(rnp, cpu, mask) \
+	((rnp)->grplo + find_next_bit(&(mask), BITS_PER_LONG, (cpu)))
+#define for_each_leaf_node_cpu_mask(rnp, cpu, mask) \
+	for ((cpu) = rcu_find_next_bit((rnp), 0, (mask)); \
+	     (cpu) <= rnp->grphi; \
+	     (cpu) = rcu_find_next_bit((rnp), (cpu) + 1 - (rnp->grplo), (mask)))
 
 /*
  * Wrappers for the rcu_node::lock acquire and release.

commit 9a414201ae7ea089699a0cbd36533345ca17233b
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed Jan 31 19:23:24 2018 -0800

    rcu: Add more tracing of expedited grace periods
    
    This commit adds more tracing of expedited grace periods to enable
    improved debugging of slowdowns.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 5d13f651cf08..507a0802c717 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -77,12 +77,18 @@ static inline void rcu_seq_start(unsigned long *sp)
 	WARN_ON_ONCE(rcu_seq_state(*sp) != 1);
 }
 
+/* Compute the end-of-grace-period value for the specified sequence number. */
+static inline unsigned long rcu_seq_endval(unsigned long *sp)
+{
+	return (*sp | RCU_SEQ_STATE_MASK) + 1;
+}
+
 /* Adjust sequence number for end of update-side operation. */
 static inline void rcu_seq_end(unsigned long *sp)
 {
 	smp_mb(); /* Ensure update-side operation before counter increment. */
 	WARN_ON_ONCE(!rcu_seq_state(*sp));
-	WRITE_ONCE(*sp, (*sp | RCU_SEQ_STATE_MASK) + 1);
+	WRITE_ONCE(*sp, rcu_seq_endval(sp));
 }
 
 /* Take a snapshot of the update side's sequence number. */

commit a32e01ee689794a26bdfdbaa7e8c334576cee36c
Author: Matthew Wilcox <mawilcox@microsoft.com>
Date:   Wed Jan 17 06:24:30 2018 -0800

    rcu: Use wrapper for lockdep asserts
    
    Commits c0b334c5bfa9 and ea9b0c8a26a2 introduced new sparse warnings
    by accessing rcu_node->lock directly and ignoring the __private
    marker.  Introduce a new wrapper and use it.  Also fix a similar problem
    in srcutree.c introduced by a3883df3935e.
    
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index c90812673d54..5d13f651cf08 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -337,7 +337,7 @@ do {									\
 } while (0)
 
 #define raw_spin_unlock_irqrestore_rcu_node(p, flags)			\
-	raw_spin_unlock_irqrestore(&ACCESS_PRIVATE(p, lock), flags)	\
+	raw_spin_unlock_irqrestore(&ACCESS_PRIVATE(p, lock), flags)
 
 #define raw_spin_trylock_rcu_node(p)					\
 ({									\
@@ -348,6 +348,9 @@ do {									\
 	___locked;							\
 })
 
+#define raw_lockdep_assert_held_rcu_node(p)				\
+	lockdep_assert_held(&ACCESS_PRIVATE(p, lock))
+
 #endif /* #if defined(SRCU) || !defined(TINY_RCU) */
 
 #ifdef CONFIG_TINY_RCU

commit bfbd767d4dba7fb41df0d356eecb7bbd99d0a7ee
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu Jan 11 12:58:53 2018 -0800

    rcu: Consolidate rcu.h #ifdefs
    
    The kernel/rcu/rcu.h file has a pair of consecutive #ifdefs on
    CONFIG_TINY_RCU, so this commit consolidates them, thus saving a few
    lines of code.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 6334f2c1abd0..c90812673d54 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -356,24 +356,20 @@ static inline bool rcu_gp_is_normal(void) { return true; }
 static inline bool rcu_gp_is_expedited(void) { return false; }
 static inline void rcu_expedite_gp(void) { }
 static inline void rcu_unexpedite_gp(void) { }
+static inline void rcu_request_urgent_qs_task(struct task_struct *t) { }
 #else /* #ifdef CONFIG_TINY_RCU */
 bool rcu_gp_is_normal(void);     /* Internal RCU use. */
 bool rcu_gp_is_expedited(void);  /* Internal RCU use. */
 void rcu_expedite_gp(void);
 void rcu_unexpedite_gp(void);
 void rcupdate_announce_bootup_oddness(void);
+void rcu_request_urgent_qs_task(struct task_struct *t);
 #endif /* #else #ifdef CONFIG_TINY_RCU */
 
 #define RCU_SCHEDULER_INACTIVE	0
 #define RCU_SCHEDULER_INIT	1
 #define RCU_SCHEDULER_RUNNING	2
 
-#ifdef CONFIG_TINY_RCU
-static inline void rcu_request_urgent_qs_task(struct task_struct *t) { }
-#else /* #ifdef CONFIG_TINY_RCU */
-void rcu_request_urgent_qs_task(struct task_struct *t);
-#endif /* #else #ifdef CONFIG_TINY_RCU */
-
 enum rcutorture_type {
 	RCU_FLAVOR,
 	RCU_BH_FLAVOR,

commit 84585aa8b6ad24e5bdfba9db4a320a6aeed192ab
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed Oct 4 15:55:16 2017 -0700

    rcu: Shrink ->dynticks_{nmi_,}nesting from long long to long
    
    Because the ->dynticks_nesting field now only contains the process-based
    nesting level instead of a value encoding both the process nesting level
    and the irq "nesting" level, we no longer need a long long, even on
    32-bit systems.  This commit therefore changes both the ->dynticks_nesting
    and ->dynticks_nmi_nesting fields to long.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index afe0559d1867..6334f2c1abd0 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -31,7 +31,7 @@
 #endif /* #else #ifdef CONFIG_RCU_TRACE */
 
 /* Offset to allow for unmatched rcu_irq_{enter,exit}(). */
-#define DYNTICK_IRQ_NONIDLE	((INT_MAX / 2) + 1)
+#define DYNTICK_IRQ_NONIDLE	((LONG_MAX / 2) + 1)
 
 
 /*

commit 51a1fd30f13090be7750fed86cf3728afaf4e394
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Oct 3 14:43:40 2017 -0700

    rcu: Make ->dynticks_nesting be a simple counter
    
    Now that ->dynticks_nesting counts only process-level dyntick-idle
    entry and exit, there is no need for the elaborate segmented counter
    with its guard fields and overflow checking.  This commit therefore
    makes ->dynticks_nesting be a simple counter.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index f4a411964c41..afe0559d1867 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -30,32 +30,7 @@
 #define RCU_TRACE(stmt)
 #endif /* #else #ifdef CONFIG_RCU_TRACE */
 
-/*
- * Process-level increment to ->dynticks_nesting field.  This allows for
- * architectures that use half-interrupts and half-exceptions from
- * process context.
- *
- * DYNTICK_TASK_NEST_MASK defines a field of width DYNTICK_TASK_NEST_WIDTH
- * that counts the number of process-based reasons why RCU cannot
- * consider the corresponding CPU to be idle, and DYNTICK_TASK_NEST_VALUE
- * is the value used to increment or decrement this field.
- *
- * The rest of the bits could in principle be used to count interrupts,
- * but this would mean that a negative-one value in the interrupt
- * field could incorrectly zero out the DYNTICK_TASK_NEST_MASK field.
- * We therefore provide a two-bit guard field defined by DYNTICK_TASK_MASK
- * that is set to DYNTICK_TASK_FLAG upon initial exit from idle.
- * The DYNTICK_TASK_EXIT_IDLE value is thus the combined value used upon
- * initial exit from idle.
- */
-#define DYNTICK_TASK_NEST_WIDTH 7
-#define DYNTICK_TASK_NEST_VALUE ((LLONG_MAX >> DYNTICK_TASK_NEST_WIDTH) + 1)
-#define DYNTICK_TASK_NEST_MASK  (LLONG_MAX - DYNTICK_TASK_NEST_VALUE + 1)
-#define DYNTICK_TASK_FLAG	   ((DYNTICK_TASK_NEST_VALUE / 8) * 2)
-#define DYNTICK_TASK_MASK	   ((DYNTICK_TASK_NEST_VALUE / 8) * 3)
-#define DYNTICK_TASK_EXIT_IDLE	   (DYNTICK_TASK_NEST_VALUE + \
-				    DYNTICK_TASK_FLAG)
-
+/* Offset to allow for unmatched rcu_irq_{enter,exit}(). */
 #define DYNTICK_IRQ_NONIDLE	((INT_MAX / 2) + 1)
 
 

commit 6136d6e48a0138f6be5bb3427dbeb0ba07a546a4
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Oct 3 08:28:04 2017 -0700

    rcu: Clamp ->dynticks_nmi_nesting at eqs entry/exit
    
    In preparation for merging dyntick-idle irq handling into the NMI
    algorithm, clamp ->dynticks_nmi_nesting value to allow for interrupts
    that enter but never leave and vice versa.
    
    It is important that the clamping happen outside of the extended quiescent
    state.  Otherwise, there will be short windows where irqs and NMIs fail
    to convince RCU to start watching.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 59c471de342a..f4a411964c41 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -56,6 +56,8 @@
 #define DYNTICK_TASK_EXIT_IDLE	   (DYNTICK_TASK_NEST_VALUE + \
 				    DYNTICK_TASK_FLAG)
 
+#define DYNTICK_IRQ_NONIDLE	((INT_MAX / 2) + 1)
+
 
 /*
  * Grace-period counter management.

commit f22ce09157239aab08eae99c678ef664f71a9097
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Fri Sep 1 14:40:54 2017 -0700

    rcu: Suppress RCU CPU stall warnings while dumping trace
    
    Currently, RCU emits Suppress RCU CPU stall warnings during its
    automatically initiated ftrace_dump() calls after detecting an error
    condition, which can result in excessively excessive console output
    and lost trace events.  This commit therefore suppresses RCU CPU stall
    warnings across any of these ftrace_dump() calls.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index b8729eb09a5d..59c471de342a 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -203,6 +203,21 @@ static inline bool __rcu_reclaim(const char *rn, struct rcu_head *head)
 extern int rcu_cpu_stall_suppress;
 int rcu_jiffies_till_stall_check(void);
 
+#define rcu_ftrace_dump_stall_suppress() \
+do { \
+	if (!rcu_cpu_stall_suppress) \
+		rcu_cpu_stall_suppress = 3; \
+} while (0)
+
+#define rcu_ftrace_dump_stall_unsuppress() \
+do { \
+	if (rcu_cpu_stall_suppress == 3) \
+		rcu_cpu_stall_suppress = 0; \
+} while (0)
+
+#else /* #endif #ifdef CONFIG_RCU_STALL_COMMON */
+#define rcu_ftrace_dump_stall_suppress()
+#define rcu_ftrace_dump_stall_unsuppress()
 #endif /* #ifdef CONFIG_RCU_STALL_COMMON */
 
 /*
@@ -222,7 +237,9 @@ do { \
 	if (!atomic_read(&___rfd_beenhere) && \
 	    !atomic_xchg(&___rfd_beenhere, 1)) { \
 		tracing_off(); \
+		rcu_ftrace_dump_stall_suppress(); \
 		ftrace_dump(oops_dump_mode); \
+		rcu_ftrace_dump_stall_unsuppress(); \
 	} \
 } while (0)
 

commit 83b6ca1fede773eebcdfb44f5a94eb410d48b886
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu Aug 31 16:47:08 2017 -0700

    rcu: Turn off tracing before dumping trace
    
    Currently, RCU allows tracing to continue when it automatically does
    ftrace_dump() after detecting an error condition, which can result in
    excessively large traces and lost trace events.  This commit therefore
    does a tracing_off() before any of these ftrace_dump() calls.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index e4b43fef89f5..b8729eb09a5d 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -220,8 +220,10 @@ do { \
 	static atomic_t ___rfd_beenhere = ATOMIC_INIT(0); \
 	\
 	if (!atomic_read(&___rfd_beenhere) && \
-	    !atomic_xchg(&___rfd_beenhere, 1)) \
+	    !atomic_xchg(&___rfd_beenhere, 1)) { \
+		tracing_off(); \
 		ftrace_dump(oops_dump_mode); \
+	} \
 } while (0)
 
 void rcu_early_boot_tests(void);

commit 7414fac050d5e0b64554b902f3955eabbebb6cb2
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Jun 12 16:44:19 2017 -0700

    rcu: Move rcu.h to new trivial-function style
    
    This commit saves a few lines in kernel/rcu/rcu.h by moving to single-line
    definitions for trivial functions, instead of the old style where the
    two curly braces each get their own line.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 808b8c85f626..e4b43fef89f5 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -356,22 +356,10 @@ do {									\
 
 #ifdef CONFIG_TINY_RCU
 /* Tiny RCU doesn't expedite, as its purpose in life is instead to be tiny. */
-static inline bool rcu_gp_is_normal(void)  /* Internal RCU use. */
-{
-	return true;
-}
-static inline bool rcu_gp_is_expedited(void)  /* Internal RCU use. */
-{
-	return false;
-}
-
-static inline void rcu_expedite_gp(void)
-{
-}
-
-static inline void rcu_unexpedite_gp(void)
-{
-}
+static inline bool rcu_gp_is_normal(void) { return true; }
+static inline bool rcu_gp_is_expedited(void) { return false; }
+static inline void rcu_expedite_gp(void) { }
+static inline void rcu_unexpedite_gp(void) { }
 #else /* #ifdef CONFIG_TINY_RCU */
 bool rcu_gp_is_normal(void);     /* Internal RCU use. */
 bool rcu_gp_is_expedited(void);  /* Internal RCU use. */
@@ -419,12 +407,8 @@ static inline void rcutorture_get_gp_data(enum rcutorture_type test_type,
 	*gpnum = 0;
 	*completed = 0;
 }
-static inline void rcutorture_record_test_transition(void)
-{
-}
-static inline void rcutorture_record_progress(unsigned long vernum)
-{
-}
+static inline void rcutorture_record_test_transition(void) { }
+static inline void rcutorture_record_progress(unsigned long vernum) { }
 #ifdef CONFIG_RCU_TRACE
 void do_trace_rcu_torture_read(const char *rcutorturename,
 			       struct rcu_head *rhp,
@@ -460,92 +444,20 @@ void srcutorture_get_gp_data(enum rcutorture_type test_type,
 #endif
 
 #ifdef CONFIG_TINY_RCU
-
-/*
- * Return the number of grace periods started.
- */
-static inline unsigned long rcu_batches_started(void)
-{
-	return 0;
-}
-
-/*
- * Return the number of bottom-half grace periods started.
- */
-static inline unsigned long rcu_batches_started_bh(void)
-{
-	return 0;
-}
-
-/*
- * Return the number of sched grace periods started.
- */
-static inline unsigned long rcu_batches_started_sched(void)
-{
-	return 0;
-}
-
-/*
- * Return the number of grace periods completed.
- */
-static inline unsigned long rcu_batches_completed(void)
-{
-	return 0;
-}
-
-/*
- * Return the number of bottom-half grace periods completed.
- */
-static inline unsigned long rcu_batches_completed_bh(void)
-{
-	return 0;
-}
-
-/*
- * Return the number of sched grace periods completed.
- */
-static inline unsigned long rcu_batches_completed_sched(void)
-{
-	return 0;
-}
-
-/*
- * Return the number of expedited grace periods completed.
- */
-static inline unsigned long rcu_exp_batches_completed(void)
-{
-	return 0;
-}
-
-/*
- * Return the number of expedited sched grace periods completed.
- */
-static inline unsigned long rcu_exp_batches_completed_sched(void)
-{
-	return 0;
-}
-
-static inline unsigned long srcu_batches_completed(struct srcu_struct *sp)
-{
-	return 0;
-}
-
-static inline void rcu_force_quiescent_state(void)
-{
-}
-
-static inline void rcu_bh_force_quiescent_state(void)
-{
-}
-
-static inline void rcu_sched_force_quiescent_state(void)
-{
-}
-
-static inline void show_rcu_gp_kthreads(void)
-{
-}
-
+static inline unsigned long rcu_batches_started(void) { return 0; }
+static inline unsigned long rcu_batches_started_bh(void) { return 0; }
+static inline unsigned long rcu_batches_started_sched(void) { return 0; }
+static inline unsigned long rcu_batches_completed(void) { return 0; }
+static inline unsigned long rcu_batches_completed_bh(void) { return 0; }
+static inline unsigned long rcu_batches_completed_sched(void) { return 0; }
+static inline unsigned long rcu_exp_batches_completed(void) { return 0; }
+static inline unsigned long rcu_exp_batches_completed_sched(void) { return 0; }
+static inline unsigned long
+srcu_batches_completed(struct srcu_struct *sp) { return 0; }
+static inline void rcu_force_quiescent_state(void) { }
+static inline void rcu_bh_force_quiescent_state(void) { }
+static inline void rcu_sched_force_quiescent_state(void) { }
+static inline void show_rcu_gp_kthreads(void) { }
 #else /* #ifdef CONFIG_TINY_RCU */
 extern unsigned long rcutorture_testseq;
 extern unsigned long rcutorture_vernum;

commit 44c65ff2e3b0b48250a970183ab53b0602c25764
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon May 15 16:26:34 2017 -0700

    rcu: Eliminate NOCBs CPU-state Kconfig options
    
    The CONFIG_RCU_NOCB_CPU_ALL, CONFIG_RCU_NOCB_CPU_NONE, and
    CONFIG_RCU_NOCB_CPU_ZERO Kconfig options are used only in testing and
    are redundant with the rcu_nocbs= boot parameter.  This commit therefore
    removes these three Kconfig options and adjusts the rcutorture scripts
    to use the boot parameter instead.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index d06c42deee0b..808b8c85f626 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -564,9 +564,7 @@ void rcu_bh_force_quiescent_state(void);
 void rcu_sched_force_quiescent_state(void);
 #endif /* #else #ifdef CONFIG_TINY_RCU */
 
-#if defined(CONFIG_RCU_NOCB_CPU_ALL)
-static inline bool rcu_is_nocb_cpu(int cpu) { return true; }
-#elif defined(CONFIG_RCU_NOCB_CPU)
+#ifdef CONFIG_RCU_NOCB_CPU
 bool rcu_is_nocb_cpu(int cpu);
 #else
 static inline bool rcu_is_nocb_cpu(int cpu) { return false; }

commit bd8cc5a062f41e334596edbe823e2fa0adddd1b7
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon May 15 14:57:01 2017 -0700

    srcu: Remove Classic SRCU
    
    Classic SRCU was only ever intended to be a fallback in case of issues
    with Tree/Tiny SRCU, and the latter two are doing quite well in testing.
    This commit therefore removes Classic SRCU.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 27f871c88e0a..d06c42deee0b 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -457,22 +457,6 @@ void srcutorture_get_gp_data(enum rcutorture_type test_type,
 			     struct srcu_struct *sp, int *flags,
 			     unsigned long *gpnum, unsigned long *completed);
 
-#elif defined(CONFIG_CLASSIC_SRCU)
-
-static inline void srcutorture_get_gp_data(enum rcutorture_type test_type,
-					   struct srcu_struct *sp, int *flags,
-					   unsigned long *gpnum,
-					   unsigned long *completed)
-{
-	if (test_type != SRCU_FLAVOR)
-		return;
-	*flags = 0;
-	*completed = sp->completed;
-	*gpnum = *completed;
-	if (sp->batch_queue.head || sp->batch_check0.head || sp->batch_check1.head)
-		(*gpnum)++;
-}
-
 #endif
 
 #ifdef CONFIG_TINY_RCU

commit 7f0cd6333086ae09962791c31f0d4845a3329df9
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Sun May 14 17:06:30 2017 -0700

    srcu: Fix rcutorture-statistics typo
    
    The function srcutorture_get_gp_data() duplicated the check for
    sp->batch_check0.head instead of also checking sp->batch_check1.head.
    The only effect of this typo would be for rcutorture statistics to
    understate the fraction of time that an SRCU grace period was in flight,
    and only for Classic SRCU.  This commit fixes this typo.
    
    Reported-by: David Binderman <dcb314@hotmail.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index bc55b5716c37..27f871c88e0a 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -469,7 +469,7 @@ static inline void srcutorture_get_gp_data(enum rcutorture_type test_type,
 	*flags = 0;
 	*completed = sp->completed;
 	*gpnum = *completed;
-	if (sp->batch_queue.head || sp->batch_check0.head || sp->batch_check0.head)
+	if (sp->batch_queue.head || sp->batch_check0.head || sp->batch_check1.head)
 		(*gpnum)++;
 }
 

commit 4e4bea7427062ec15df7084f97728e2a44d912e3
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu May 11 15:33:23 2017 -0700

    rcu: Remove typecheck() from RCU locking wrapper functions
    
    Because raw_spin_lock_irqsave() and raw_spin_unlock_irqrestore()
    both do typecheck() on their flags argument, there is no point in
    duplicating this check in raw_spin_lock_irqsave_rcu_node() and
    raw_spin_unlock_irqrestore_rcu_node().  This commit therefore saves
    a few lines by removing this duplicated check.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 2a75beb883c8..bc55b5716c37 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -334,18 +334,14 @@ do {									\
 #define raw_spin_unlock_irq_rcu_node(p)					\
 	raw_spin_unlock_irq(&ACCESS_PRIVATE(p, lock))
 
-#define raw_spin_lock_irqsave_rcu_node(rnp, flags)			\
+#define raw_spin_lock_irqsave_rcu_node(p, flags)			\
 do {									\
-	typecheck(unsigned long, flags);				\
-	raw_spin_lock_irqsave(&ACCESS_PRIVATE(rnp, lock), flags);	\
+	raw_spin_lock_irqsave(&ACCESS_PRIVATE(p, lock), flags);	\
 	smp_mb__after_unlock_lock();					\
 } while (0)
 
-#define raw_spin_unlock_irqrestore_rcu_node(rnp, flags)			\
-do {									\
-	typecheck(unsigned long, flags);				\
-	raw_spin_unlock_irqrestore(&ACCESS_PRIVATE(rnp, lock), flags);	\
-} while (0)
+#define raw_spin_unlock_irqrestore_rcu_node(p, flags)			\
+	raw_spin_unlock_irqrestore(&ACCESS_PRIVATE(p, lock), flags)	\
 
 #define raw_spin_trylock_rcu_node(p)					\
 ({									\

commit 83d40bd3bc3ab3d6b5a4a331f7667d627948a099
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue May 9 13:28:51 2017 -0700

    rcu: Move rnp->lock wrappers for SRCU use
    
    This commit moves the now-generic rnp->lock wrapper macros from
    kernel/rcu/tree.h to kernel/rcu/rcu.h, thus allowing SRCU to use them.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 6a1e85bd2eac..2a75beb883c8 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -303,6 +303,59 @@ static inline void rcu_init_levelspread(int *levelspread, const int *levelcnt)
 	     cpu <= rnp->grphi; \
 	     cpu = cpumask_next((cpu), cpu_possible_mask))
 
+/*
+ * Wrappers for the rcu_node::lock acquire and release.
+ *
+ * Because the rcu_nodes form a tree, the tree traversal locking will observe
+ * different lock values, this in turn means that an UNLOCK of one level
+ * followed by a LOCK of another level does not imply a full memory barrier;
+ * and most importantly transitivity is lost.
+ *
+ * In order to restore full ordering between tree levels, augment the regular
+ * lock acquire functions with smp_mb__after_unlock_lock().
+ *
+ * As ->lock of struct rcu_node is a __private field, therefore one should use
+ * these wrappers rather than directly call raw_spin_{lock,unlock}* on ->lock.
+ */
+#define raw_spin_lock_rcu_node(p)					\
+do {									\
+	raw_spin_lock(&ACCESS_PRIVATE(p, lock));			\
+	smp_mb__after_unlock_lock();					\
+} while (0)
+
+#define raw_spin_unlock_rcu_node(p) raw_spin_unlock(&ACCESS_PRIVATE(p, lock))
+
+#define raw_spin_lock_irq_rcu_node(p)					\
+do {									\
+	raw_spin_lock_irq(&ACCESS_PRIVATE(p, lock));			\
+	smp_mb__after_unlock_lock();					\
+} while (0)
+
+#define raw_spin_unlock_irq_rcu_node(p)					\
+	raw_spin_unlock_irq(&ACCESS_PRIVATE(p, lock))
+
+#define raw_spin_lock_irqsave_rcu_node(rnp, flags)			\
+do {									\
+	typecheck(unsigned long, flags);				\
+	raw_spin_lock_irqsave(&ACCESS_PRIVATE(rnp, lock), flags);	\
+	smp_mb__after_unlock_lock();					\
+} while (0)
+
+#define raw_spin_unlock_irqrestore_rcu_node(rnp, flags)			\
+do {									\
+	typecheck(unsigned long, flags);				\
+	raw_spin_unlock_irqrestore(&ACCESS_PRIVATE(rnp, lock), flags);	\
+} while (0)
+
+#define raw_spin_trylock_rcu_node(p)					\
+({									\
+	bool ___locked = raw_spin_trylock(&ACCESS_PRIVATE(p, lock));	\
+									\
+	if (___locked)							\
+		smp_mb__after_unlock_lock();				\
+	___locked;							\
+})
+
 #endif /* #if defined(SRCU) || !defined(TINY_RCU) */
 
 #ifdef CONFIG_TINY_RCU

commit 2464dd940e23bad227c387a40eec99f7aa02ed96
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu May 4 14:29:16 2017 -0700

    srcu: Apply trivial callback lists to shrink Tiny SRCU
    
    The rcu_segcblist structure provides quite a bit of functionality, and
    Tiny SRCU needs almost none of it.  So this commit replaces Tiny SRCU's
    uses of rcu_segcblist with a simple singly linked list with tail pointer.
    This change significantly reduces Tiny SRCU's memory footprint, more
    than making up for the growth caused by the creation of rcu_segcblist.c
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 74d9fc205313..6a1e85bd2eac 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -398,7 +398,7 @@ static inline void srcutorture_get_gp_data(enum rcutorture_type test_type,
 	if (test_type != SRCU_FLAVOR)
 		return;
 	*flags = 0;
-	*completed = sp->srcu_gp_seq;
+	*completed = sp->srcu_idx;
 	*gpnum = *completed;
 }
 

commit 5a0465e17a18c467b712a816985b7b8dd8d10c16
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu May 4 11:31:04 2017 -0700

    srcu: Shrink srcu.h by moving docbook and private function
    
    The call_srcu() docbook entry is currently in include/linux/srcu.h,
    which causes needless processing for each include point.  This commit
    therefore moves this entry to kernel/rcu/srcutree.c, which the compiler
    reads only once.  In addition, the srcu_batches_completed() function is
    used only within RCU and its torture-test suites.  This commit therefore
    also moves this function's declaration from include/linux/srcutiny.h,
    include/linux/srcutree.h, and include/linux/srcuclassic.h to
    kernel/rcu/rcu.h.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 5b76a5baff2e..74d9fc205313 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -492,6 +492,11 @@ static inline unsigned long rcu_exp_batches_completed_sched(void)
 	return 0;
 }
 
+static inline unsigned long srcu_batches_completed(struct srcu_struct *sp)
+{
+	return 0;
+}
+
 static inline void rcu_force_quiescent_state(void)
 {
 }
@@ -519,6 +524,7 @@ unsigned long rcu_batches_completed_bh(void);
 unsigned long rcu_batches_completed_sched(void);
 unsigned long rcu_exp_batches_completed(void);
 unsigned long rcu_exp_batches_completed_sched(void);
+unsigned long srcu_batches_completed(struct srcu_struct *sp);
 void show_rcu_gp_kthreads(void);
 void rcu_force_quiescent_state(void);
 void rcu_bh_force_quiescent_state(void);

commit fe21a27e8ca0937a5ac298de1f4b46382e9c5c88
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed May 3 13:45:51 2017 -0700

    rcu: Move rcu_request_urgent_qs_task() out of rcutiny.h and rcutree.h
    
    The rcu_request_urgent_qs_task() function is used only within RCU,
    so there is no point in exporting it to the rest of the kernel from
    nclude/linux/rcutiny.h and include/linux/rcutree.h.  This commit therefore
    moves this function to kernel/rcu/rcu.h.
    
    Reported-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index d849b371b32b..5b76a5baff2e 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -335,6 +335,12 @@ void rcupdate_announce_bootup_oddness(void);
 #define RCU_SCHEDULER_INIT	1
 #define RCU_SCHEDULER_RUNNING	2
 
+#ifdef CONFIG_TINY_RCU
+static inline void rcu_request_urgent_qs_task(struct task_struct *t) { }
+#else /* #ifdef CONFIG_TINY_RCU */
+void rcu_request_urgent_qs_task(struct task_struct *t);
+#endif /* #else #ifdef CONFIG_TINY_RCU */
+
 enum rcutorture_type {
 	RCU_FLAVOR,
 	RCU_BH_FLAVOR,

commit e3c8d51e1a58c73a557eb38a9a6afb4f704a3379
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed May 3 13:37:16 2017 -0700

    rcu: Move torture-related functions out of rcutiny.h and rcutree.h
    
    The various functions similar to rcu_batches_started(), the
    function show_rcu_gp_kthreads(), the various functions similar to
    rcu_force_quiescent_state(), and the variables rcutorture_testseq and
    rcutorture_vernum are used only within RCU.  There is therefore no point
    in exporting them to the kernel at large from include/linux/rcutiny.h
    and include/linux/rcutree.h.  This commit therefore moves all of these
    to kernel/rcu/rcu.h.
    
    Reported-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index cdbaa441bdac..d849b371b32b 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -420,6 +420,105 @@ static inline void srcutorture_get_gp_data(enum rcutorture_type test_type,
 
 #endif
 
+#ifdef CONFIG_TINY_RCU
+
+/*
+ * Return the number of grace periods started.
+ */
+static inline unsigned long rcu_batches_started(void)
+{
+	return 0;
+}
+
+/*
+ * Return the number of bottom-half grace periods started.
+ */
+static inline unsigned long rcu_batches_started_bh(void)
+{
+	return 0;
+}
+
+/*
+ * Return the number of sched grace periods started.
+ */
+static inline unsigned long rcu_batches_started_sched(void)
+{
+	return 0;
+}
+
+/*
+ * Return the number of grace periods completed.
+ */
+static inline unsigned long rcu_batches_completed(void)
+{
+	return 0;
+}
+
+/*
+ * Return the number of bottom-half grace periods completed.
+ */
+static inline unsigned long rcu_batches_completed_bh(void)
+{
+	return 0;
+}
+
+/*
+ * Return the number of sched grace periods completed.
+ */
+static inline unsigned long rcu_batches_completed_sched(void)
+{
+	return 0;
+}
+
+/*
+ * Return the number of expedited grace periods completed.
+ */
+static inline unsigned long rcu_exp_batches_completed(void)
+{
+	return 0;
+}
+
+/*
+ * Return the number of expedited sched grace periods completed.
+ */
+static inline unsigned long rcu_exp_batches_completed_sched(void)
+{
+	return 0;
+}
+
+static inline void rcu_force_quiescent_state(void)
+{
+}
+
+static inline void rcu_bh_force_quiescent_state(void)
+{
+}
+
+static inline void rcu_sched_force_quiescent_state(void)
+{
+}
+
+static inline void show_rcu_gp_kthreads(void)
+{
+}
+
+#else /* #ifdef CONFIG_TINY_RCU */
+extern unsigned long rcutorture_testseq;
+extern unsigned long rcutorture_vernum;
+unsigned long rcu_batches_started(void);
+unsigned long rcu_batches_started_bh(void);
+unsigned long rcu_batches_started_sched(void);
+unsigned long rcu_batches_completed(void);
+unsigned long rcu_batches_completed_bh(void);
+unsigned long rcu_batches_completed_sched(void);
+unsigned long rcu_exp_batches_completed(void);
+unsigned long rcu_exp_batches_completed_sched(void);
+void show_rcu_gp_kthreads(void);
+void rcu_force_quiescent_state(void);
+void rcu_bh_force_quiescent_state(void);
+void rcu_sched_force_quiescent_state(void);
+#endif /* #else #ifdef CONFIG_TINY_RCU */
+
 #if defined(CONFIG_RCU_NOCB_CPU_ALL)
 static inline bool rcu_is_nocb_cpu(int cpu) { return true; }
 #elif defined(CONFIG_RCU_NOCB_CPU)

commit b8989b76052eedc99b09322efd6f68816f191a1a
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed May 3 12:28:59 2017 -0700

    rcu: Move rcu_ftrace_dump() from rcupdate.h to rcu.h
    
    The rcu_ftrace_dump() function is used only internally to RCU.  This
    commit therefore moves its declaration from include/linux/rcupdate.h
    to kernel/rcu/rcu.h.
    
    Reported-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 2f344662c568..cdbaa441bdac 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -212,6 +212,18 @@ int rcu_jiffies_till_stall_check(void);
  */
 #define TPS(x)  tracepoint_string(x)
 
+/*
+ * Dump the ftrace buffer, but only one time per callsite per boot.
+ */
+#define rcu_ftrace_dump(oops_dump_mode) \
+do { \
+	static atomic_t ___rfd_beenhere = ATOMIC_INIT(0); \
+	\
+	if (!atomic_read(&___rfd_beenhere) && \
+	    !atomic_xchg(&___rfd_beenhere, 1)) \
+		ftrace_dump(oops_dump_mode); \
+} while (0)
+
 void rcu_early_boot_tests(void);
 void rcu_test_sync_prims(void);
 

commit 3d54f7983f3e6ac9f444fa20970b1abc8f089b79
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed May 3 12:25:50 2017 -0700

    rcu: Move rcu_is_nocb_cpu() from rcupdate.h to rcu.h
    
    The rcu_is_nocb_cpu() function is used only internally to RCU.  This
    commit therefore moves its declaration from include/linux/rcupdate.h
    to kernel/rcu/rcu.h.
    
    Reported-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 17fee2a667d9..2f344662c568 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -408,4 +408,12 @@ static inline void srcutorture_get_gp_data(enum rcutorture_type test_type,
 
 #endif
 
+#if defined(CONFIG_RCU_NOCB_CPU_ALL)
+static inline bool rcu_is_nocb_cpu(int cpu) { return true; }
+#elif defined(CONFIG_RCU_NOCB_CPU)
+bool rcu_is_nocb_cpu(int cpu);
+#else
+static inline bool rcu_is_nocb_cpu(int cpu) { return false; }
+#endif
+
 #endif /* __LINUX_RCU_H */

commit 82118249d0ca4078d56d5e43172ada1567fdf946
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed May 3 11:13:24 2017 -0700

    rcu: Move the RCU_SCHEDULER_ definitions from rcupdate.h
    
    The RCU_SCHEDULER_INACTIVE, RCU_SCHEDULER_INIT, and RCU_SCHEDULER_RUNNING
    definitions are used only within RCU, so this commit moves them from
    include/linux/rcupdate.h to kernel/rcu/rcu.h.
    
    Reported-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index f190fc1c8215..17fee2a667d9 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -319,6 +319,10 @@ void rcu_unexpedite_gp(void);
 void rcupdate_announce_bootup_oddness(void);
 #endif /* #else #ifdef CONFIG_TINY_RCU */
 
+#define RCU_SCHEDULER_INACTIVE	0
+#define RCU_SCHEDULER_INIT	1
+#define RCU_SCHEDULER_RUNNING	2
+
 enum rcutorture_type {
 	RCU_FLAVOR,
 	RCU_BH_FLAVOR,

commit cad7b3897279c869de61dc88133037b941f84233
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed May 3 10:22:57 2017 -0700

    rcu: Move torture-related definitions from rcupdate.h to rcu.h
    
    The include/linux/rcupdate.h file contains a number of definitions that
    are used only to communicate between rcutorture, rcuperf, and the RCU code
    itself.  There is no point in having these definitions exposed globally
    throughout the kernel, so this commit moves them to kernel/rcu/rcu.h.
    This change has the added benefit of shrinking rcupdate.h.
    
    Reported-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index ceb78110db1b..f190fc1c8215 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -319,4 +319,89 @@ void rcu_unexpedite_gp(void);
 void rcupdate_announce_bootup_oddness(void);
 #endif /* #else #ifdef CONFIG_TINY_RCU */
 
+enum rcutorture_type {
+	RCU_FLAVOR,
+	RCU_BH_FLAVOR,
+	RCU_SCHED_FLAVOR,
+	RCU_TASKS_FLAVOR,
+	SRCU_FLAVOR,
+	INVALID_RCU_FLAVOR
+};
+
+#if defined(CONFIG_TREE_RCU) || defined(CONFIG_PREEMPT_RCU)
+void rcutorture_get_gp_data(enum rcutorture_type test_type, int *flags,
+			    unsigned long *gpnum, unsigned long *completed);
+void rcutorture_record_test_transition(void);
+void rcutorture_record_progress(unsigned long vernum);
+void do_trace_rcu_torture_read(const char *rcutorturename,
+			       struct rcu_head *rhp,
+			       unsigned long secs,
+			       unsigned long c_old,
+			       unsigned long c);
+#else
+static inline void rcutorture_get_gp_data(enum rcutorture_type test_type,
+					  int *flags,
+					  unsigned long *gpnum,
+					  unsigned long *completed)
+{
+	*flags = 0;
+	*gpnum = 0;
+	*completed = 0;
+}
+static inline void rcutorture_record_test_transition(void)
+{
+}
+static inline void rcutorture_record_progress(unsigned long vernum)
+{
+}
+#ifdef CONFIG_RCU_TRACE
+void do_trace_rcu_torture_read(const char *rcutorturename,
+			       struct rcu_head *rhp,
+			       unsigned long secs,
+			       unsigned long c_old,
+			       unsigned long c);
+#else
+#define do_trace_rcu_torture_read(rcutorturename, rhp, secs, c_old, c) \
+	do { } while (0)
+#endif
+#endif
+
+#ifdef CONFIG_TINY_SRCU
+
+static inline void srcutorture_get_gp_data(enum rcutorture_type test_type,
+					   struct srcu_struct *sp, int *flags,
+					   unsigned long *gpnum,
+					   unsigned long *completed)
+{
+	if (test_type != SRCU_FLAVOR)
+		return;
+	*flags = 0;
+	*completed = sp->srcu_gp_seq;
+	*gpnum = *completed;
+}
+
+#elif defined(CONFIG_TREE_SRCU)
+
+void srcutorture_get_gp_data(enum rcutorture_type test_type,
+			     struct srcu_struct *sp, int *flags,
+			     unsigned long *gpnum, unsigned long *completed);
+
+#elif defined(CONFIG_CLASSIC_SRCU)
+
+static inline void srcutorture_get_gp_data(enum rcutorture_type test_type,
+					   struct srcu_struct *sp, int *flags,
+					   unsigned long *gpnum,
+					   unsigned long *completed)
+{
+	if (test_type != SRCU_FLAVOR)
+		return;
+	*flags = 0;
+	*completed = sp->completed;
+	*gpnum = *completed;
+	if (sp->batch_queue.head || sp->batch_check0.head || sp->batch_check0.head)
+		(*gpnum)++;
+}
+
+#endif
+
 #endif /* __LINUX_RCU_H */

commit 25c36329a30c8cac090effe1fbae9bb916fa95fe
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed May 3 09:51:55 2017 -0700

    rcu: Move expediting-related access/control out of rcupdate.h
    
    The rcu_gp_is_normal(), rcu_gp_is_expedited(), rcu_expedite_gp(), and
    rcu_unexpedite_gp() functions are intended only for use within the
    RCU implementation itself -- the sysfs access is what should be used
    outside of RCU.  This commit therefore moves the declarations for
    these functions to kernel/rcu/rcu.h, and also includes this file into
    kernel/rcu/rcutorture.c and kernel/rcu/rcuperf.c.  This also has the
    beneficial effect of shrinking rcupdate.c a bit.
    
    Reported-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 73e16ec4054b..ceb78110db1b 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -293,4 +293,30 @@ static inline void rcu_init_levelspread(int *levelspread, const int *levelcnt)
 
 #endif /* #if defined(SRCU) || !defined(TINY_RCU) */
 
+#ifdef CONFIG_TINY_RCU
+/* Tiny RCU doesn't expedite, as its purpose in life is instead to be tiny. */
+static inline bool rcu_gp_is_normal(void)  /* Internal RCU use. */
+{
+	return true;
+}
+static inline bool rcu_gp_is_expedited(void)  /* Internal RCU use. */
+{
+	return false;
+}
+
+static inline void rcu_expedite_gp(void)
+{
+}
+
+static inline void rcu_unexpedite_gp(void)
+{
+}
+#else /* #ifdef CONFIG_TINY_RCU */
+bool rcu_gp_is_normal(void);     /* Internal RCU use. */
+bool rcu_gp_is_expedited(void);  /* Internal RCU use. */
+void rcu_expedite_gp(void);
+void rcu_unexpedite_gp(void);
+void rcupdate_announce_bootup_oddness(void);
+#endif /* #else #ifdef CONFIG_TINY_RCU */
+
 #endif /* __LINUX_RCU_H */

commit 80a7956fe36c2ee40c6ff12c77926d267802b7c8
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed Mar 22 15:26:18 2017 -0700

    srcu: Merge ->srcu_state into ->srcu_gp_seq
    
    Updating ->srcu_state and ->srcu_gp_seq will lead to extremely complex
    race conditions given multiple callback queues, so this commit takes
    advantage of the two-bit state now available in rcu_seq counters to
    store the state in the bottom two bits of ->srcu_gp_seq.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 87a0ac95b551..73e16ec4054b 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -82,6 +82,16 @@ static inline int rcu_seq_state(unsigned long s)
 	return s & RCU_SEQ_STATE_MASK;
 }
 
+/*
+ * Set the state portion of the pointed-to sequence number.
+ * The caller is responsible for preventing conflicting updates.
+ */
+static inline void rcu_seq_set_state(unsigned long *sp, int newstate)
+{
+	WARN_ON_ONCE(newstate & ~RCU_SEQ_STATE_MASK);
+	WRITE_ONCE(*sp, (*sp & ~RCU_SEQ_STATE_MASK) + newstate);
+}
+
 /* Adjust sequence number for start of update-side operation. */
 static inline void rcu_seq_start(unsigned long *sp)
 {

commit f1ec57a462314f3d1cd0c9c8a04979228aa9d38c
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Mar 21 10:35:57 2017 -0700

    srcu: Allow a second bit in rcu_seq for SRCU state
    
    This commit increases the number of reserved bits at the bottom of an
    rcu_seq grace-period counter from one to two, as will be needed to
    accommodate SRCU's three-state grace periods.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index c62df93bfc1b..87a0ac95b551 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -61,7 +61,7 @@
  * Grace-period counter management.
  */
 
-#define RCU_SEQ_CTR_SHIFT	1
+#define RCU_SEQ_CTR_SHIFT	2
 #define RCU_SEQ_STATE_MASK	((1 << RCU_SEQ_CTR_SHIFT) - 1)
 
 /*

commit 031aeee000e895247eafa4233c2d193dd39d4ea2
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Mar 21 07:28:14 2017 -0700

    srcu: Improve rcu_seq grace-period-counter abstraction
    
    The expedited grace-period code contains several open-coded shifts
    know the format of an rcu_seq grace-period counter, which is not
    particularly good style.  This commit therefore creates a new
    rcu_seq_ctr() function that extracts the counter portion of the
    counter, and an rcu_seq_state() function that extracts the low-order
    state bit.  This commit prepares for SRCU callback parallelization,
    which will require two state bits.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 4303b880ac99..c62df93bfc1b 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -61,20 +61,41 @@
  * Grace-period counter management.
  */
 
+#define RCU_SEQ_CTR_SHIFT	1
+#define RCU_SEQ_STATE_MASK	((1 << RCU_SEQ_CTR_SHIFT) - 1)
+
+/*
+ * Return the counter portion of a sequence number previously returned
+ * by rcu_seq_snap() or rcu_seq_current().
+ */
+static inline unsigned long rcu_seq_ctr(unsigned long s)
+{
+	return s >> RCU_SEQ_CTR_SHIFT;
+}
+
+/*
+ * Return the state portion of a sequence number previously returned
+ * by rcu_seq_snap() or rcu_seq_current().
+ */
+static inline int rcu_seq_state(unsigned long s)
+{
+	return s & RCU_SEQ_STATE_MASK;
+}
+
 /* Adjust sequence number for start of update-side operation. */
 static inline void rcu_seq_start(unsigned long *sp)
 {
 	WRITE_ONCE(*sp, *sp + 1);
 	smp_mb(); /* Ensure update-side operation after counter increment. */
-	WARN_ON_ONCE(!(*sp & 0x1));
+	WARN_ON_ONCE(rcu_seq_state(*sp) != 1);
 }
 
 /* Adjust sequence number for end of update-side operation. */
 static inline void rcu_seq_end(unsigned long *sp)
 {
 	smp_mb(); /* Ensure update-side operation before counter increment. */
-	WARN_ON_ONCE(!(*sp & 0x1));
-	WRITE_ONCE(*sp, *sp + 1);
+	WARN_ON_ONCE(!rcu_seq_state(*sp));
+	WRITE_ONCE(*sp, (*sp | RCU_SEQ_STATE_MASK) + 1);
 }
 
 /* Take a snapshot of the update side's sequence number. */
@@ -82,7 +103,7 @@ static inline unsigned long rcu_seq_snap(unsigned long *sp)
 {
 	unsigned long s;
 
-	s = (READ_ONCE(*sp) + 3) & ~0x1;
+	s = (READ_ONCE(*sp) + 2 * RCU_SEQ_STATE_MASK + 1) & ~RCU_SEQ_STATE_MASK;
 	smp_mb(); /* Above access must not bleed into critical section. */
 	return s;
 }

commit e95d68d2127716c7d6fb144bb19ef48ce9f37393
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed Mar 15 13:11:11 2017 -0700

    srcu: Make num_rcu_lvl[] array be external
    
    This commit makes the num_rcu_lvl[] array external so that SRCU can
    make use of it for initializing its upcoming srcu_node tree.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 5c1798ec32f7..4303b880ac99 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -195,6 +195,7 @@ extern void resched_cpu(int cpu);
 #include <linux/rcu_node_tree.h>
 
 extern int rcu_num_lvls;
+extern int num_rcu_lvl[];
 extern int rcu_num_nodes;
 static bool rcu_fanout_exact;
 static int rcu_fanout_leaf;

commit efbe451d46af62369226e42b98dbcd95b6940a63
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed Mar 15 13:07:53 2017 -0700

    srcu: Move rcu_node traversal macros to rcu.h
    
    This commit moves rcu_for_each_node_breadth_first(),
    rcu_for_each_nonleaf_node_breadth_first(), and
    rcu_for_each_leaf_node() from kernel/rcu/tree.h to
    kernel/rcu/rcu.h so that SRCU can access them.
    This commit is code-movement only.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 87326479b39a..5c1798ec32f7 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -224,6 +224,41 @@ static inline void rcu_init_levelspread(int *levelspread, const int *levelcnt)
 	}
 }
 
+/*
+ * Do a full breadth-first scan of the rcu_node structures for the
+ * specified rcu_state structure.
+ */
+#define rcu_for_each_node_breadth_first(rsp, rnp) \
+	for ((rnp) = &(rsp)->node[0]; \
+	     (rnp) < &(rsp)->node[rcu_num_nodes]; (rnp)++)
+
+/*
+ * Do a breadth-first scan of the non-leaf rcu_node structures for the
+ * specified rcu_state structure.  Note that if there is a singleton
+ * rcu_node tree with but one rcu_node structure, this loop is a no-op.
+ */
+#define rcu_for_each_nonleaf_node_breadth_first(rsp, rnp) \
+	for ((rnp) = &(rsp)->node[0]; \
+	     (rnp) < (rsp)->level[rcu_num_lvls - 1]; (rnp)++)
+
+/*
+ * Scan the leaves of the rcu_node hierarchy for the specified rcu_state
+ * structure.  Note that if there is a singleton rcu_node tree with but
+ * one rcu_node structure, this loop -will- visit the rcu_node structure.
+ * It is still a leaf node, even if it is also the root node.
+ */
+#define rcu_for_each_leaf_node(rsp, rnp) \
+	for ((rnp) = (rsp)->level[rcu_num_lvls - 1]; \
+	     (rnp) < &(rsp)->node[rcu_num_nodes]; (rnp)++)
+
+/*
+ * Iterate over all possible CPUs in a leaf RCU node.
+ */
+#define for_each_leaf_node_possible_cpu(rnp, cpu) \
+	for ((cpu) = cpumask_next(rnp->grplo - 1, cpu_possible_mask); \
+	     cpu <= rnp->grphi; \
+	     cpu = cpumask_next((cpu), cpu_possible_mask))
+
 #endif /* #if defined(SRCU) || !defined(TINY_RCU) */
 
 #endif /* __LINUX_RCU_H */

commit 2b34c43cc1671c59bad6dd1682ae3ee4f0919eb7
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Mar 14 14:29:53 2017 -0700

    srcu: Move rcu_init_levelspread() to rcu_tree_node.h
    
    This commit moves the rcu_init_levelspread() function from
    kernel/rcu/tree.c to kernel/rcu/rcu.h so that SRCU can access it.  This is
    another step towards enabling SRCU to create its own combining tree.
    This commit is code-movement only, give or take knock-on adjustments.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index a943b42a9cf7..87326479b39a 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -190,4 +190,40 @@ void rcu_test_sync_prims(void);
  */
 extern void resched_cpu(int cpu);
 
+#if defined(SRCU) || !defined(TINY_RCU)
+
+#include <linux/rcu_node_tree.h>
+
+extern int rcu_num_lvls;
+extern int rcu_num_nodes;
+static bool rcu_fanout_exact;
+static int rcu_fanout_leaf;
+
+/*
+ * Compute the per-level fanout, either using the exact fanout specified
+ * or balancing the tree, depending on the rcu_fanout_exact boot parameter.
+ */
+static inline void rcu_init_levelspread(int *levelspread, const int *levelcnt)
+{
+	int i;
+
+	if (rcu_fanout_exact) {
+		levelspread[rcu_num_lvls - 1] = rcu_fanout_leaf;
+		for (i = rcu_num_lvls - 2; i >= 0; i--)
+			levelspread[i] = RCU_FANOUT;
+	} else {
+		int ccur;
+		int cprv;
+
+		cprv = nr_cpu_ids;
+		for (i = rcu_num_lvls - 1; i >= 0; i--) {
+			ccur = levelcnt[i];
+			levelspread[i] = (cprv + ccur - 1) / ccur;
+			cprv = ccur;
+		}
+	}
+}
+
+#endif /* #if defined(SRCU) || !defined(TINY_RCU) */
+
 #endif /* __LINUX_RCU_H */

commit 8660b7d8a545227fd9ee80508aa82528ea9947d7
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Mar 13 16:48:18 2017 -0700

    srcu: Use rcu_segcblist to track SRCU callbacks
    
    This commit switches SRCU from custom-built callback queues to the new
    rcu_segcblist structure.  This change associates grace-period sequence
    numbers with groups of callbacks, which will be needed for efficient
    processing of per-CPU callbacks.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 0bc1313c49e2..a943b42a9cf7 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -87,6 +87,12 @@ static inline unsigned long rcu_seq_snap(unsigned long *sp)
 	return s;
 }
 
+/* Return the current value the update side's sequence number, no ordering. */
+static inline unsigned long rcu_seq_current(unsigned long *sp)
+{
+	return READ_ONCE(*sp);
+}
+
 /*
  * Given a snapshot from rcu_seq_snap(), determine whether or not a
  * full update-side operation has occurred.

commit f010ed82c7ba8b30f30872800100ad6b6efe2a6a
Author: Dmitry Vyukov <dvyukov@google.com>
Date:   Sun Mar 5 12:17:31 2017 -0800

    rcu: Fix warning in rcu_seq_end()
    
    The rcu_seq_end() function increments seq signifying completion
    of a grace period, after that checks that the seq is even and wakes
    _synchronize_rcu_expedited().  The _synchronize_rcu_expedited() function
    uses wait_event() to wait for even seq.  The problem is that wait_event()
    can return as soon as seq becomes even without waiting for the wakeup.
    In such case the warning in rcu_seq_end() can falsely fire if the next
    expedited grace period starts before the check.
    
    Check that seq has good value before incrementing it.
    
    Signed-off-by: Dmitry Vyukov <dvyukov@google.com>
    Cc: syzkaller@googlegroups.com
    Cc: linux-kernel@vger.kernel.org
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Cc: josh@joshtriplett.org
    Cc: jiangshanlai@gmail.com
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    
    ---
    
    syzkaller-triggered warning:
    
    WARNING: CPU: 0 PID: 4832 at kernel/rcu/tree.c:3533
    rcu_seq_end+0x110/0x140 kernel/rcu/tree.c:3533
    CPU: 0 PID: 4832 Comm: kworker/0:3 Not tainted 4.10.0+ #276
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011
    Workqueue: events wait_rcu_exp_gp
    Call Trace:
     __dump_stack lib/dump_stack.c:15 [inline]
     dump_stack+0x2ee/0x3ef lib/dump_stack.c:51
     panic+0x1fb/0x412 kernel/panic.c:179
     __warn+0x1c4/0x1e0 kernel/panic.c:540
     warn_slowpath_null+0x2c/0x40 kernel/panic.c:583
     rcu_seq_end+0x110/0x140 kernel/rcu/tree.c:3533
     rcu_exp_gp_seq_end kernel/rcu/tree_exp.h:36 [inline]
     rcu_exp_wait_wake+0x8a9/0x1330 kernel/rcu/tree_exp.h:517
     rcu_exp_sel_wait_wake kernel/rcu/tree_exp.h:559 [inline]
     wait_rcu_exp_gp+0x83/0xc0 kernel/rcu/tree_exp.h:570
     process_one_work+0xc06/0x1c20 kernel/workqueue.c:2096
     worker_thread+0x223/0x19c0 kernel/workqueue.c:2230
     kthread+0x326/0x3f0 kernel/kthread.c:227
     ret_from_fork+0x31/0x40 arch/x86/entry/entry_64.S:430
    ---

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 91e0bf31f6ce..0bc1313c49e2 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -73,8 +73,8 @@ static inline void rcu_seq_start(unsigned long *sp)
 static inline void rcu_seq_end(unsigned long *sp)
 {
 	smp_mb(); /* Ensure update-side operation before counter increment. */
+	WARN_ON_ONCE(!(*sp & 0x1));
 	WRITE_ONCE(*sp, *sp + 1);
-	WARN_ON_ONCE(*sp & 0x1);
 }
 
 /* Take a snapshot of the update side's sequence number. */

commit 2e8c28c2dd96c6f1f2d454a4e4b928385841e247
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Feb 20 14:57:17 2017 -0800

    srcu: Move rcu_seq_start() and friends to rcu.h
    
    This commit moves rcu_seq_start(), rcu_seq_end(), rcu_seq_snap(),
    and rcu_seq_done() from kernel/rcu/tree.c to kernel/rcu/rcu.h.
    This will allow SRCU to use these functions, which in turn will
    allow SRCU to move from a single global callback queue to a
    per-CPU callback queue.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 8700a81daf56..91e0bf31f6ce 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -56,6 +56,46 @@
 #define DYNTICK_TASK_EXIT_IDLE	   (DYNTICK_TASK_NEST_VALUE + \
 				    DYNTICK_TASK_FLAG)
 
+
+/*
+ * Grace-period counter management.
+ */
+
+/* Adjust sequence number for start of update-side operation. */
+static inline void rcu_seq_start(unsigned long *sp)
+{
+	WRITE_ONCE(*sp, *sp + 1);
+	smp_mb(); /* Ensure update-side operation after counter increment. */
+	WARN_ON_ONCE(!(*sp & 0x1));
+}
+
+/* Adjust sequence number for end of update-side operation. */
+static inline void rcu_seq_end(unsigned long *sp)
+{
+	smp_mb(); /* Ensure update-side operation before counter increment. */
+	WRITE_ONCE(*sp, *sp + 1);
+	WARN_ON_ONCE(*sp & 0x1);
+}
+
+/* Take a snapshot of the update side's sequence number. */
+static inline unsigned long rcu_seq_snap(unsigned long *sp)
+{
+	unsigned long s;
+
+	s = (READ_ONCE(*sp) + 3) & ~0x1;
+	smp_mb(); /* Above access must not bleed into critical section. */
+	return s;
+}
+
+/*
+ * Given a snapshot from rcu_seq_snap(), determine whether or not a
+ * full update-side operation has occurred.
+ */
+static inline bool rcu_seq_done(unsigned long *sp, unsigned long s)
+{
+	return ULONG_CMP_GE(READ_ONCE(*sp), s);
+}
+
 /*
  * debug_rcu_head_queue()/debug_rcu_head_unqueue() are used internally
  * by call_rcu() and rcu callback execution, and are therefore not part of the

commit dffd06a7566b379be13a831b27a55bf5b0a7dea5
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Jan 23 11:55:43 2017 -0800

    rcu: Semicolon inside RCU_TRACE() for rcu.h
    
    The current use of "RCU_TRACE(statement);" can cause odd bugs, especially
    where "statement" is a local-variable declaration, as it can leave a
    misplaced ";" in the source code.  This commit therefore converts these
    to "RCU_TRACE(statement;)", which avoids the misplaced ";".
    
    Reported-by: Josh Triplett <josh@joshtriplett.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 0d6ff3e471be..8700a81daf56 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -109,12 +109,12 @@ static inline bool __rcu_reclaim(const char *rn, struct rcu_head *head)
 
 	rcu_lock_acquire(&rcu_callback_map);
 	if (__is_kfree_rcu_offset(offset)) {
-		RCU_TRACE(trace_rcu_invoke_kfree_callback(rn, head, offset));
+		RCU_TRACE(trace_rcu_invoke_kfree_callback(rn, head, offset);)
 		kfree((void *)head - offset);
 		rcu_lock_release(&rcu_callback_map);
 		return true;
 	} else {
-		RCU_TRACE(trace_rcu_invoke_callback(rn, head));
+		RCU_TRACE(trace_rcu_invoke_callback(rn, head);)
 		head->func(head);
 		rcu_lock_release(&rcu_callback_map);
 		return false;

commit 52d7e48b86fc108e45a656d8e53e4237993c481d
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Jan 10 02:28:26 2017 -0800

    rcu: Narrow early boot window of illegal synchronous grace periods
    
    The current preemptible RCU implementation goes through three phases
    during bootup.  In the first phase, there is only one CPU that is running
    with preemption disabled, so that a no-op is a synchronous grace period.
    In the second mid-boot phase, the scheduler is running, but RCU has
    not yet gotten its kthreads spawned (and, for expedited grace periods,
    workqueues are not yet running.  During this time, any attempt to do
    a synchronous grace period will hang the system (or complain bitterly,
    depending).  In the third and final phase, RCU is fully operational and
    everything works normally.
    
    This has been OK for some time, but there has recently been some
    synchronous grace periods showing up during the second mid-boot phase.
    This code worked "by accident" for awhile, but started failing as soon
    as expedited RCU grace periods switched over to workqueues in commit
    8b355e3bc140 ("rcu: Drive expedited grace periods from workqueue").
    Note that the code was buggy even before this commit, as it was subject
    to failure on real-time systems that forced all expedited grace periods
    to run as normal grace periods (for example, using the rcu_normal ksysfs
    parameter).  The callchain from the failure case is as follows:
    
    early_amd_iommu_init()
    |-> acpi_put_table(ivrs_base);
    |-> acpi_tb_put_table(table_desc);
    |-> acpi_tb_invalidate_table(table_desc);
    |-> acpi_tb_release_table(...)
    |-> acpi_os_unmap_memory
    |-> acpi_os_unmap_iomem
    |-> acpi_os_map_cleanup
    |-> synchronize_rcu_expedited
    
    The kernel showing this callchain was built with CONFIG_PREEMPT_RCU=y,
    which caused the code to try using workqueues before they were
    initialized, which did not go well.
    
    This commit therefore reworks RCU to permit synchronous grace periods
    to proceed during this mid-boot phase.  This commit is therefore a
    fix to a regression introduced in v4.9, and is therefore being put
    forward post-merge-window in v4.10.
    
    This commit sets a flag from the existing rcu_scheduler_starting()
    function which causes all synchronous grace periods to take the expedited
    path.  The expedited path now checks this flag, using the requesting task
    to drive the expedited grace period forward during the mid-boot phase.
    Finally, this flag is updated by a core_initcall() function named
    rcu_exp_runtime_mode(), which causes the runtime codepaths to be used.
    
    Note that this arrangement assumes that tasks are not sent POSIX signals
    (or anything similar) from the time that the first task is spawned
    through core_initcall() time.
    
    Fixes: 8b355e3bc140 ("rcu: Drive expedited grace periods from workqueue")
    Reported-by: "Zheng, Lv" <lv.zheng@intel.com>
    Reported-by: Borislav Petkov <bp@alien8.de>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Tested-by: Stan Kain <stan.kain@gmail.com>
    Tested-by: Ivan <waffolz@hotmail.com>
    Tested-by: Emanuel Castelo <emanuel.castelo@gmail.com>
    Tested-by: Bruno Pesavento <bpesavento@infinito.it>
    Tested-by: Borislav Petkov <bp@suse.de>
    Tested-by: Frederic Bezies <fredbezies@gmail.com>
    Cc: <stable@vger.kernel.org> # 4.9.0-

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 80adef7d4c3d..0d6ff3e471be 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -136,6 +136,7 @@ int rcu_jiffies_till_stall_check(void);
 #define TPS(x)  tracepoint_string(x)
 
 void rcu_early_boot_tests(void);
+void rcu_test_sync_prims(void);
 
 /*
  * This function really isn't for public consumption, but RCU is special in

commit 5f6130fa52ee0df0b1da4518c5bbef42bcfe7d83
Author: Lai Jiangshan <laijs@cn.fujitsu.com>
Date:   Tue Dec 9 17:53:34 2014 +0800

    tiny_rcu: Directly force QS when call_rcu_[bh|sched]() on idle_task
    
    For RCU in UP, context-switch = QS = GP, thus we can force a
    context-switch when any call_rcu_[bh|sched]() is happened on idle_task.
    After doing so, rcu_idle/irq_enter/exit() are useless, so we can simply
    make these functions empty.
    
    More important, this change does not change the functionality logically.
    Note: raise_softirq(RCU_SOFTIRQ)/rcu_sched_qs() in rcu_idle_enter() and
    outmost rcu_irq_exit() will have to wake up the ksoftirqd
    (due to in_interrupt() == 0).
    
    Before this patch               After this patch:
    call_rcu_sched() in idle;       call_rcu_sched() in idle
                                      set resched
    do other stuffs;                do other stuffs
    outmost rcu_irq_exit()          outmost rcu_irq_exit() (empty function)
      (or rcu_idle_enter())           (or rcu_idle_enter(), also empty function)
                                    start to resched. (see above)
      rcu_sched_qs()                rcu_sched_qs()
        QS,and GP and advance cb      QS,and GP and advance cb
        wake up the ksoftirqd           wake up the ksoftirqd
          set resched
    resched to ksoftirqd (or other) resched to ksoftirqd (or other)
    
    These two code patches are almost the same.
    
    Size changed after patched:
    
    size kernel/rcu/tiny-old.o kernel/rcu/tiny-patched.o
       text    data     bss     dec     hex filename
       3449     206       8    3663     e4f kernel/rcu/tiny-old.o
       2406     144       8    2558     9fe kernel/rcu/tiny-patched.o
    
    Signed-off-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 07bb02eda844..80adef7d4c3d 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -137,4 +137,10 @@ int rcu_jiffies_till_stall_check(void);
 
 void rcu_early_boot_tests(void);
 
+/*
+ * This function really isn't for public consumption, but RCU is special in
+ * that context switches can allow the state machine to make progress.
+ */
+extern void resched_cpu(int cpu);
+
 #endif /* __LINUX_RCU_H */

commit aa23c6fbc50c4f9d8b43682f37fc4580a7851413
Author: Pranith Kumar <bobby.prani@gmail.com>
Date:   Fri Sep 19 11:32:29 2014 -0400

    rcutorture: Add early boot self tests
    
    Add early boot self tests for RCU under CONFIG_PROVE_RCU.
    
    Currently the only test is adding a dummy callback which increments a counter
    which we then later verify after calling rcu_barrier*().
    
    Signed-off-by: Pranith Kumar <bobby.prani@gmail.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index ff1a6de62f17..07bb02eda844 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -135,4 +135,6 @@ int rcu_jiffies_till_stall_check(void);
  */
 #define TPS(x)  tracepoint_string(x)
 
+void rcu_early_boot_tests(void);
+
 #endif /* __LINUX_RCU_H */

commit 406e3e536550bcb87ccbedddcd483776b1828761
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Jun 23 13:48:28 2014 -0700

    rcu: Fix __rcu_reclaim() to use true/false for bool
    
    The __rcu_reclaim() function returned 0/1, which is not proper for a
    function of type bool.  This commit therefore converts to false/true.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Lai Jiangshan <laijs@cn.fujitsu.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index bfda2726ca45..ff1a6de62f17 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -99,6 +99,10 @@ static inline void debug_rcu_head_unqueue(struct rcu_head *head)
 
 void kfree(const void *);
 
+/*
+ * Reclaim the specified callback, either by invoking it (non-lazy case)
+ * or freeing it directly (lazy case).  Return true if lazy, false otherwise.
+ */
 static inline bool __rcu_reclaim(const char *rn, struct rcu_head *head)
 {
 	unsigned long offset = (unsigned long)head->func;
@@ -108,12 +112,12 @@ static inline bool __rcu_reclaim(const char *rn, struct rcu_head *head)
 		RCU_TRACE(trace_rcu_invoke_kfree_callback(rn, head, offset));
 		kfree((void *)head - offset);
 		rcu_lock_release(&rcu_callback_map);
-		return 1;
+		return true;
 	} else {
 		RCU_TRACE(trace_rcu_invoke_callback(rn, head));
 		head->func(head);
 		rcu_lock_release(&rcu_callback_map);
-		return 0;
+		return false;
 	}
 }
 

commit 5cb5c6e18f822b19bd41a2c0f9930c82b3ec0bc9
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Wed Feb 19 14:33:27 2014 -0500

    rcu: Ensure kernel/rcu/rcu.h can be sourced/used stand-alone
    
    The kbuild test bot uncovered an implicit dependence on the
    trace header being present before rcu.h in ia64 allmodconfig
    that looks like this:
    
    In file included from kernel/ksysfs.c:22:0:
    kernel/rcu/rcu.h: In function '__rcu_reclaim':
    kernel/rcu/rcu.h:107:3: error: implicit declaration of function 'trace_rcu_invoke_kfree_callback' [-Werror=implicit-function-declaration]
    kernel/rcu/rcu.h:112:3: error: implicit declaration of function 'trace_rcu_invoke_callback' [-Werror=implicit-function-declaration]
    cc1: some warnings being treated as errors
    
    Looking at other rcu.h users, we can find that they all
    were sourcing the trace header in advance of rcu.h itself,
    as seen in the context of this diff.  There were also some
    inconsistencies as to whether it was or wasn't sourced based
    on the parent tracing Kconfig.
    
    Rather than "fix" it at each use site, and have inconsistent
    use based on whether "#ifdef CONFIG_RCU_TRACE" was used or not,
    lets just source the trace header just once, in the actual consumer
    of it, which is rcu.h itself.  We include it unconditionally, as
    build testing shows us that is a hard requirement for some files.
    
    Reported-by: kbuild test robot <fengguang.wu@intel.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index af2e60a8425d..bfda2726ca45 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -23,6 +23,7 @@
 #ifndef __LINUX_RCU_H
 #define __LINUX_RCU_H
 
+#include <trace/events/rcu.h>
 #ifdef CONFIG_RCU_TRACE
 #define RCU_TRACE(stmt) stmt
 #else /* #ifdef CONFIG_RCU_TRACE */

commit 7a754743185a4b05818e10058fa2fbe4e6969085
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Tue Feb 11 16:10:12 2014 -0500

    rcu: Fix sparse warning for rcu_expedited from kernel/ksysfs.c
    
    This commit fixes the follwoing warning:
    
    kernel/ksysfs.c:143:5: warning: symbol 'rcu_expedited' was not declared. Should it be static?
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    [ paulmck: Moved the declaration to include/linux/rcupdate.h to avoid
               including the RCU-internal rcu.h file outside of RCU. ]
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 1bd787fddcb2..af2e60a8425d 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -116,8 +116,6 @@ static inline bool __rcu_reclaim(const char *rn, struct rcu_head *head)
 	}
 }
 
-extern int rcu_expedited;
-
 #ifdef CONFIG_RCU_STALL_COMMON
 
 extern int rcu_cpu_stall_suppress;

commit 87de1cfdc55b16b794e245b07322340725149d62
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Dec 3 10:02:52 2013 -0800

    rcu: Stop tracking FSF's postal address
    
    All of the RCU source files have the usual GPL header, which contains a
    long-obsolete postal address for FSF.  To avoid the need to track the
    FSF office's movements, this commit substitutes the URL where GPL may
    be found.
    
    Reported-by: Greg KH <gregkh@linuxfoundation.org>
    Reported-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 79c3877e9c5b..1bd787fddcb2 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -12,8 +12,8 @@
  * GNU General Public License for more details.
  *
  * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
+ * along with this program; if not, you can access it online at
+ * http://www.gnu.org/licenses/gpl-2.0.html.
  *
  * Copyright IBM Corporation, 2011
  *

commit bd73a7f5cd434f5aa611c9043490911c32084270
Author: Teodora Baluta <teobaluta@gmail.com>
Date:   Mon Nov 11 17:11:24 2013 +0200

    rcu: Remove "extern" from function declarations in kernel/rcu/rcu.h
    
    Function prototypes don't need to have the "extern" keyword since this
    is the default behavior. Its explicit use is redundant.  This commit
    therefore removes them.
    
    Signed-off-by: Teodora Baluta <teobaluta@gmail.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index a8f981a2d110..79c3877e9c5b 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -96,7 +96,7 @@ static inline void debug_rcu_head_unqueue(struct rcu_head *head)
 }
 #endif	/* #else !CONFIG_DEBUG_OBJECTS_RCU_HEAD */
 
-extern void kfree(const void *);
+void kfree(const void *);
 
 static inline bool __rcu_reclaim(const char *rn, struct rcu_head *head)
 {

commit 24ef659a857c3cba40b64ea51ea4fce8d2fb7bbc
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Oct 28 09:22:24 2013 -0700

    rcu: Provide better diagnostics for blocking in RCU callback functions
    
    Currently blocking in an RCU callback function will result in
    "scheduling while atomic", which could be triggered for any number
    of reasons.  To aid debugging, this patch introduces a rcu_callback_map
    that is used to tie the inappropriate voluntary context switch back
    to the fact that the function is being invoked from within a callback.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
index 7859a0a3951e..a8f981a2d110 100644
--- a/kernel/rcu/rcu.h
+++ b/kernel/rcu/rcu.h
@@ -102,13 +102,16 @@ static inline bool __rcu_reclaim(const char *rn, struct rcu_head *head)
 {
 	unsigned long offset = (unsigned long)head->func;
 
+	rcu_lock_acquire(&rcu_callback_map);
 	if (__is_kfree_rcu_offset(offset)) {
 		RCU_TRACE(trace_rcu_invoke_kfree_callback(rn, head, offset));
 		kfree((void *)head - offset);
+		rcu_lock_release(&rcu_callback_map);
 		return 1;
 	} else {
 		RCU_TRACE(trace_rcu_invoke_callback(rn, head));
 		head->func(head);
+		rcu_lock_release(&rcu_callback_map);
 		return 0;
 	}
 }

commit 4102adab9189c8ea2f0cdd2f88345fd25d2790f1
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Oct 8 20:23:47 2013 -0700

    rcu: Move RCU-related source code to kernel/rcu directory
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/rcu/rcu.h b/kernel/rcu/rcu.h
new file mode 100644
index 000000000000..7859a0a3951e
--- /dev/null
+++ b/kernel/rcu/rcu.h
@@ -0,0 +1,132 @@
+/*
+ * Read-Copy Update definitions shared among RCU implementations.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
+ *
+ * Copyright IBM Corporation, 2011
+ *
+ * Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
+ */
+
+#ifndef __LINUX_RCU_H
+#define __LINUX_RCU_H
+
+#ifdef CONFIG_RCU_TRACE
+#define RCU_TRACE(stmt) stmt
+#else /* #ifdef CONFIG_RCU_TRACE */
+#define RCU_TRACE(stmt)
+#endif /* #else #ifdef CONFIG_RCU_TRACE */
+
+/*
+ * Process-level increment to ->dynticks_nesting field.  This allows for
+ * architectures that use half-interrupts and half-exceptions from
+ * process context.
+ *
+ * DYNTICK_TASK_NEST_MASK defines a field of width DYNTICK_TASK_NEST_WIDTH
+ * that counts the number of process-based reasons why RCU cannot
+ * consider the corresponding CPU to be idle, and DYNTICK_TASK_NEST_VALUE
+ * is the value used to increment or decrement this field.
+ *
+ * The rest of the bits could in principle be used to count interrupts,
+ * but this would mean that a negative-one value in the interrupt
+ * field could incorrectly zero out the DYNTICK_TASK_NEST_MASK field.
+ * We therefore provide a two-bit guard field defined by DYNTICK_TASK_MASK
+ * that is set to DYNTICK_TASK_FLAG upon initial exit from idle.
+ * The DYNTICK_TASK_EXIT_IDLE value is thus the combined value used upon
+ * initial exit from idle.
+ */
+#define DYNTICK_TASK_NEST_WIDTH 7
+#define DYNTICK_TASK_NEST_VALUE ((LLONG_MAX >> DYNTICK_TASK_NEST_WIDTH) + 1)
+#define DYNTICK_TASK_NEST_MASK  (LLONG_MAX - DYNTICK_TASK_NEST_VALUE + 1)
+#define DYNTICK_TASK_FLAG	   ((DYNTICK_TASK_NEST_VALUE / 8) * 2)
+#define DYNTICK_TASK_MASK	   ((DYNTICK_TASK_NEST_VALUE / 8) * 3)
+#define DYNTICK_TASK_EXIT_IDLE	   (DYNTICK_TASK_NEST_VALUE + \
+				    DYNTICK_TASK_FLAG)
+
+/*
+ * debug_rcu_head_queue()/debug_rcu_head_unqueue() are used internally
+ * by call_rcu() and rcu callback execution, and are therefore not part of the
+ * RCU API. Leaving in rcupdate.h because they are used by all RCU flavors.
+ */
+
+#ifdef CONFIG_DEBUG_OBJECTS_RCU_HEAD
+# define STATE_RCU_HEAD_READY	0
+# define STATE_RCU_HEAD_QUEUED	1
+
+extern struct debug_obj_descr rcuhead_debug_descr;
+
+static inline int debug_rcu_head_queue(struct rcu_head *head)
+{
+	int r1;
+
+	r1 = debug_object_activate(head, &rcuhead_debug_descr);
+	debug_object_active_state(head, &rcuhead_debug_descr,
+				  STATE_RCU_HEAD_READY,
+				  STATE_RCU_HEAD_QUEUED);
+	return r1;
+}
+
+static inline void debug_rcu_head_unqueue(struct rcu_head *head)
+{
+	debug_object_active_state(head, &rcuhead_debug_descr,
+				  STATE_RCU_HEAD_QUEUED,
+				  STATE_RCU_HEAD_READY);
+	debug_object_deactivate(head, &rcuhead_debug_descr);
+}
+#else	/* !CONFIG_DEBUG_OBJECTS_RCU_HEAD */
+static inline int debug_rcu_head_queue(struct rcu_head *head)
+{
+	return 0;
+}
+
+static inline void debug_rcu_head_unqueue(struct rcu_head *head)
+{
+}
+#endif	/* #else !CONFIG_DEBUG_OBJECTS_RCU_HEAD */
+
+extern void kfree(const void *);
+
+static inline bool __rcu_reclaim(const char *rn, struct rcu_head *head)
+{
+	unsigned long offset = (unsigned long)head->func;
+
+	if (__is_kfree_rcu_offset(offset)) {
+		RCU_TRACE(trace_rcu_invoke_kfree_callback(rn, head, offset));
+		kfree((void *)head - offset);
+		return 1;
+	} else {
+		RCU_TRACE(trace_rcu_invoke_callback(rn, head));
+		head->func(head);
+		return 0;
+	}
+}
+
+extern int rcu_expedited;
+
+#ifdef CONFIG_RCU_STALL_COMMON
+
+extern int rcu_cpu_stall_suppress;
+int rcu_jiffies_till_stall_check(void);
+
+#endif /* #ifdef CONFIG_RCU_STALL_COMMON */
+
+/*
+ * Strings used in tracepoints need to be exported via the
+ * tracing system such that tools like perf and trace-cmd can
+ * translate the string address pointers to actual text.
+ */
+#define TPS(x)  tracepoint_string(x)
+
+#endif /* __LINUX_RCU_H */
