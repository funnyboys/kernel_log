commit 1dd694a1b72f69a3add938f4b5bfb4cf9914b133
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Apr 21 12:19:04 2020 +0200

    remove the no longer needed pid_alive() check in __task_pid_nr_ns()
    
    Starting from 2c4704756cab ("pids: Move the pgrp and session pid pointers
    from task_struct to signal_struct") __task_pid_nr_ns() doesn't dereference
    task->group_leader, we can remove the pid_alive() check.
    
    pid_nr_ns() has to check pid != NULL anyway, pid_alive() just adds the
    unnecessary confusion.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: Christian Brauner <christian.brauner@ubuntu.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index 6d5d0a5bda82..f1496b757162 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -495,8 +495,7 @@ pid_t __task_pid_nr_ns(struct task_struct *task, enum pid_type type,
 	rcu_read_lock();
 	if (!ns)
 		ns = task_active_pid_ns(current);
-	if (likely(pid_alive(task)))
-		nr = pid_nr_ns(rcu_dereference(*task_pid_ptr(task, type)), ns);
+	nr = pid_nr_ns(rcu_dereference(*task_pid_ptr(task, type)), ns);
 	rcu_read_unlock();
 
 	return nr;

commit 6b03d1304a32dc8450c7516000a0fe07bef7c446
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sun Apr 19 06:35:02 2020 -0500

    proc: Ensure we see the exit of each process tid exactly once
    
    When the thread group leader changes during exec and the old leaders
    thread is reaped proc_flush_pid will flush the dentries for the entire
    process because the leader still has it's original pid.
    
    Fix this by exchanging the pids in an rcu safe manner,
    and wrapping the code to do that up in a helper exchange_tids.
    
    When I removed switch_exec_pids and introduced this behavior
    in d73d65293e3e ("[PATCH] pidhash: kill switch_exec_pids") there
    really was nothing that cared as flushing happened with
    the cached dentry and de_thread flushed both of them on exec.
    
    This lack of fully exchanging pids became a problem a few months later
    when I introduced 48e6484d4902 ("[PATCH] proc: Rewrite the proc dentry
    flush on exit optimization").  Which overlooked the de_thread case
    was no longer swapping pids, and I was looking up proc dentries
    by task->pid.
    
    The current behavior isn't properly a bug as everything in proc will
    continue to work correctly just a little bit less efficiently.  Fix
    this just so there are no little surprise corner cases waiting to bite
    people.
    
    -- Oleg points out this could be an issue in next_tgid in proc where
       has_group_leader_pid is called, and reording some of the assignments
       should fix that.
    
    -- Oleg points out this will break the 10 year old hack in __exit_signal.c
    >       /*
    >        * This can only happen if the caller is de_thread().
    >        * FIXME: this is the temporary hack, we should teach
    >        * posix-cpu-timers to handle this case correctly.
    >        */
    >       if (unlikely(has_group_leader_pid(tsk)))
    >               posix_cpu_timers_exit_group(tsk);
    
    The code in next_tgid has been changed to use PIDTYPE_TGID,
    and the posix cpu timers code has been fixed so it does not
    need the 10 year old hack, so this should be safe to merge
    now.
    
    Link: https://lore.kernel.org/lkml/87h7x3ajll.fsf_-_@x220.int.ebiederm.org/
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Fixes: 48e6484d4902 ("[PATCH] proc: Rewrite the proc dentry flush on exit optimization").
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index c835b844aca7..6d5d0a5bda82 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -363,6 +363,25 @@ void change_pid(struct task_struct *task, enum pid_type type,
 	attach_pid(task, type);
 }
 
+void exchange_tids(struct task_struct *left, struct task_struct *right)
+{
+	struct pid *pid1 = left->thread_pid;
+	struct pid *pid2 = right->thread_pid;
+	struct hlist_head *head1 = &pid1->tasks[PIDTYPE_PID];
+	struct hlist_head *head2 = &pid2->tasks[PIDTYPE_PID];
+
+	/* Swap the single entry tid lists */
+	hlists_swap_heads_rcu(head1, head2);
+
+	/* Swap the per task_struct pid */
+	rcu_assign_pointer(left->thread_pid, pid2);
+	rcu_assign_pointer(right->thread_pid, pid1);
+
+	/* Swap the cached value */
+	WRITE_ONCE(left->pid, pid_nr(pid2));
+	WRITE_ONCE(right->pid, pid_nr(pid1));
+}
+
 /* transfer_pid is an optimization of attach_pid(new), detach_pid(old) */
 void transfer_pid(struct task_struct *old, struct task_struct *new,
 			   enum pid_type type)

commit 87ad46e601340394cd75c1c79b19ca906f82c543
Merge: 75bdc9293dfd 63f818f46af9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Apr 10 12:59:56 2020 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull proc fix from Eric Biederman:
     "A brown paper bag slipped through my proc changes, and syzcaller
      caught it when the code ended up in your tree.
    
      I have opted to fix it the simplest cleanest way I know how, so there
      is no reasonable chance for the bug to repeat"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace:
      proc: Use a dedicated lock in struct pid

commit 63f818f46af9f8b3f17b9695501e8d08959feb60
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Apr 7 09:43:04 2020 -0500

    proc: Use a dedicated lock in struct pid
    
    syzbot wrote:
    > ========================================================
    > WARNING: possible irq lock inversion dependency detected
    > 5.6.0-syzkaller #0 Not tainted
    > --------------------------------------------------------
    > swapper/1/0 just changed the state of lock:
    > ffffffff898090d8 (tasklist_lock){.+.?}-{2:2}, at: send_sigurg+0x9f/0x320 fs/fcntl.c:840
    > but this lock took another, SOFTIRQ-unsafe lock in the past:
    >  (&pid->wait_pidfd){+.+.}-{2:2}
    >
    >
    > and interrupts could create inverse lock ordering between them.
    >
    >
    > other info that might help us debug this:
    >  Possible interrupt unsafe locking scenario:
    >
    >        CPU0                    CPU1
    >        ----                    ----
    >   lock(&pid->wait_pidfd);
    >                                local_irq_disable();
    >                                lock(tasklist_lock);
    >                                lock(&pid->wait_pidfd);
    >   <Interrupt>
    >     lock(tasklist_lock);
    >
    >  *** DEADLOCK ***
    >
    > 4 locks held by swapper/1/0:
    
    The problem is that because wait_pidfd.lock is taken under the tasklist
    lock.  It must always be taken with irqs disabled as tasklist_lock can be
    taken from interrupt context and if wait_pidfd.lock was already taken this
    would create a lock order inversion.
    
    Oleg suggested just disabling irqs where I have added extra calls to
    wait_pidfd.lock.  That should be safe and I think the code will eventually
    do that.  It was rightly pointed out by Christian that sharing the
    wait_pidfd.lock was a premature optimization.
    
    It is also true that my pre-merge window testing was insufficient.  So
    remove the premature optimization and give struct pid a dedicated lock of
    it's own for struct pid things.  I have verified that lockdep sees all 3
    paths where we take the new pid->lock and lockdep does not complain.
    
    It is my current day dream that one day pid->lock can be used to guard the
    task lists as well and then the tasklist_lock won't need to be held to
    deliver signals.  That will require taking pid->lock with irqs disabled.
    
    Acked-by: Christian Brauner <christian.brauner@ubuntu.com>
    Link: https://lore.kernel.org/lkml/00000000000011d66805a25cd73f@google.com/
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Christian Brauner <christian.brauner@ubuntu.com>
    Reported-by: syzbot+343f75cdeea091340956@syzkaller.appspotmail.com
    Reported-by: syzbot+832aabf700bc3ec920b9@syzkaller.appspotmail.com
    Reported-by: syzbot+f675f964019f884dbd0f@syzkaller.appspotmail.com
    Reported-by: syzbot+a9fb1457d720a55d6dc5@syzkaller.appspotmail.com
    Fixes: 7bc3e6e55acf ("proc: Use a list of inodes to flush from proc")
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index efd34874b3d1..517d0855d4cf 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -246,6 +246,7 @@ struct pid *alloc_pid(struct pid_namespace *ns, pid_t *set_tid,
 
 	get_pid_ns(ns);
 	refcount_set(&pid->count, 1);
+	spin_lock_init(&pid->lock);
 	for (type = 0; type < PIDTYPE_MAX; ++type)
 		INIT_HLIST_HEAD(&pid->tasks[type]);
 

commit d987ca1c6b7e22fbd30664111e85cec7aa66000d
Merge: 919dce24701f d1e7fd6462ca
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Apr 2 11:22:17 2020 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull exec/proc updates from Eric Biederman:
     "This contains two significant pieces of work: the work to sort out
      proc_flush_task, and the work to solve a deadlock between strace and
      exec.
    
      Fixing proc_flush_task so that it no longer requires a persistent
      mount makes improvements to proc possible. The removal of the
      persistent mount solves an old regression that that caused the hidepid
      mount option to only work on remount not on mount. The regression was
      found and reported by the Android folks. This further allows Alexey
      Gladkov's work making proc mount options specific to an individual
      mount of proc to move forward.
    
      The work on exec starts solving a long standing issue with exec that
      it takes mutexes of blocking userspace applications, which makes exec
      extremely deadlock prone. For the moment this adds a second mutex with
      a narrower scope that handles all of the easy cases. Which makes the
      tricky cases easy to spot. With a little luck the code to solve those
      deadlocks will be ready by next merge window"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (25 commits)
      signal: Extend exec_id to 64bits
      pidfd: Use new infrastructure to fix deadlocks in execve
      perf: Use new infrastructure to fix deadlocks in execve
      proc: io_accounting: Use new infrastructure to fix deadlocks in execve
      proc: Use new infrastructure to fix deadlocks in execve
      kernel/kcmp.c: Use new infrastructure to fix deadlocks in execve
      kernel: doc: remove outdated comment cred.c
      mm: docs: Fix a comment in process_vm_rw_core
      selftests/ptrace: add test cases for dead-locks
      exec: Fix a deadlock in strace
      exec: Add exec_update_mutex to replace cred_guard_mutex
      exec: Move exec_mmap right after de_thread in flush_old_exec
      exec: Move cleanup of posix timers on exec out of de_thread
      exec: Factor unshare_sighand out of de_thread and call it separately
      exec: Only compute current once in flush_old_exec
      pid: Improve the comment about waiting in zap_pid_ns_processes
      proc: Remove the now unnecessary internal mount of proc
      uml: Create a private mount of proc for mconsole
      uml: Don't consult current to find the proc_mnt in mconsole_proc
      proc: Use a list of inodes to flush from proc
      ...

commit 501f9328bf5c6b5e4863da4b50e0e86792de3aa9
Author: Bernd Edlinger <bernd.edlinger@hotmail.de>
Date:   Sat Mar 21 02:46:16 2020 +0000

    pidfd: Use new infrastructure to fix deadlocks in execve
    
    This changes __pidfd_fget to use the new exec_update_mutex
    instead of cred_guard_mutex.
    
    This should be safe, as the credentials do not change
    before exec_update_mutex is locked.  Therefore whatever
    file access is possible with holding the cred_guard_mutex
    here is also possbile with the exec_update_mutex.
    
    Signed-off-by: Bernd Edlinger <bernd.edlinger@hotmail.de>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index 60820e72634c..efd34874b3d1 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -577,7 +577,7 @@ static struct file *__pidfd_fget(struct task_struct *task, int fd)
 	struct file *file;
 	int ret;
 
-	ret = mutex_lock_killable(&task->signal->cred_guard_mutex);
+	ret = mutex_lock_killable(&task->signal->exec_update_mutex);
 	if (ret)
 		return ERR_PTR(ret);
 
@@ -586,7 +586,7 @@ static struct file *__pidfd_fget(struct task_struct *task, int fd)
 	else
 		file = ERR_PTR(-EPERM);
 
-	mutex_unlock(&task->signal->cred_guard_mutex);
+	mutex_unlock(&task->signal->exec_update_mutex);
 
 	return file ?: ERR_PTR(-EBADF);
 }

commit 10dab84caf400f2f5f8b010ebb0c7c4272ec5093
Author: Christian Brauner <christian.brauner@ubuntu.com>
Date:   Sun Mar 8 14:29:17 2020 +0100

    pid: make ENOMEM return value more obvious
    
    The alloc_pid() codepath used to be simpler. With the introducation of the
    ability to choose specific pids in 49cb2fc42ce4 ("fork: extend clone3() to
    support setting a PID") it got more complex. It hasn't been super obvious
    that ENOMEM is returned when the pid namespace init process/child subreaper
    of the pid namespace has died. As can be seen from multiple attempts to
    improve this see e.g. [1] and most recently [2].
    We regressed returning ENOMEM in [3] and [2] restored it. Let's add a
    comment on top explaining that this is historic and documented behavior and
    cannot easily be changed.
    
    [1]: 35f71bc0a09a ("fork: report pid reservation failure properly")
    [2]: b26ebfe12f34 ("pid: Fix error return value in some cases")
    [3]: 49cb2fc42ce4 ("fork: extend clone3() to support setting a PID")
    Signed-off-by: Christian Brauner <christian.brauner@ubuntu.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index 19645b25b77c..647b4bb457b5 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -247,6 +247,14 @@ struct pid *alloc_pid(struct pid_namespace *ns, pid_t *set_tid,
 		tmp = tmp->parent;
 	}
 
+	/*
+	 * ENOMEM is not the most obvious choice especially for the case
+	 * where the child subreaper has already exited and the pid
+	 * namespace denies the creation of any new processes. But ENOMEM
+	 * is what we have exposed to userspace for a long time and it is
+	 * documented behavior for pid namespaces. So we can't easily
+	 * change it even if there were an error code better suited.
+	 */
 	retval = -ENOMEM;
 
 	if (unlikely(is_child_reaper(pid))) {

commit b26ebfe12f34f372cf041c6f801fa49c3fb382c5
Author: Corey Minyard <cminyard@mvista.com>
Date:   Fri Mar 6 11:23:14 2020 -0600

    pid: Fix error return value in some cases
    
    Recent changes to alloc_pid() allow the pid number to be specified on
    the command line.  If set_tid_size is set, then the code scanning the
    levels will hard-set retval to -EPERM, overriding it's previous -ENOMEM
    value.
    
    After the code scanning the levels, there are error returns that do not
    set retval, assuming it is still set to -ENOMEM.
    
    So set retval back to -ENOMEM after scanning the levels.
    
    Fixes: 49cb2fc42ce4 ("fork: extend clone3() to support setting a PID")
    Signed-off-by: Corey Minyard <cminyard@mvista.com>
    Acked-by: Christian Brauner <christian.brauner@ubuntu.com>
    Cc: Andrei Vagin <avagin@gmail.com>
    Cc: Dmitry Safonov <0x7f454c46@gmail.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Adrian Reber <areber@redhat.com>
    Cc: <stable@vger.kernel.org> # 5.5
    Link: https://lore.kernel.org/r/20200306172314.12232-1-minyard@acm.org
    [christian.brauner@ubuntu.com: fixup commit message]
    Signed-off-by: Christian Brauner <christian.brauner@ubuntu.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index 0f4ecb57214c..19645b25b77c 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -247,6 +247,8 @@ struct pid *alloc_pid(struct pid_namespace *ns, pid_t *set_tid,
 		tmp = tmp->parent;
 	}
 
+	retval = -ENOMEM;
+
 	if (unlikely(is_child_reaper(pid))) {
 		if (pid_ns_prepare_proc(ns))
 			goto out_free;

commit 69879c01a0c3f70e0887cfb4d9ff439814361e46
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Feb 20 08:08:20 2020 -0600

    proc: Remove the now unnecessary internal mount of proc
    
    There remains no more code in the kernel using pids_ns->proc_mnt,
    therefore remove it from the kernel.
    
    The big benefit of this change is that one of the most error prone and
    tricky parts of the pid namespace implementation, maintaining kernel
    mounts of proc is removed.
    
    In addition removing the unnecessary complexity of the kernel mount
    fixes a regression that caused the proc mount options to be ignored.
    Now that the initial mount of proc comes from userspace, those mount
    options are again honored.  This fixes Android's usage of the proc
    hidepid option.
    
    Reported-by: Alistair Strachan <astrachan@google.com>
    Fixes: e94591d0d90c ("proc: Convert proc_mount to use mount_ns.")
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index ca08d6a3aa77..60820e72634c 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -144,9 +144,6 @@ void free_pid(struct pid *pid)
 			/* Handle a fork failure of the first process */
 			WARN_ON(ns->child_reaper);
 			ns->pid_allocated = 0;
-			/* fall through */
-		case 0:
-			schedule_work(&ns->proc_work);
 			break;
 		}
 
@@ -247,11 +244,6 @@ struct pid *alloc_pid(struct pid_namespace *ns, pid_t *set_tid,
 		tmp = tmp->parent;
 	}
 
-	if (unlikely(is_child_reaper(pid))) {
-		if (pid_ns_prepare_proc(ns))
-			goto out_free;
-	}
-
 	get_pid_ns(ns);
 	refcount_set(&pid->count, 1);
 	for (type = 0; type < PIDTYPE_MAX; ++type)

commit 7bc3e6e55acf065500a24621f3b313e7e5998acf
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Feb 19 18:22:26 2020 -0600

    proc: Use a list of inodes to flush from proc
    
    Rework the flushing of proc to use a list of directory inodes that
    need to be flushed.
    
    The list is kept on struct pid not on struct task_struct, as there is
    a fixed connection between proc inodes and pids but at least for the
    case of de_thread the pid of a task_struct changes.
    
    This removes the dependency on proc_mnt which allows for different
    mounts of proc having different mount options even in the same pid
    namespace and this allows for the removal of proc_mnt which will
    trivially the first mount of proc to honor it's mount options.
    
    This flushing remains an optimization.  The functions
    pid_delete_dentry and pid_revalidate ensure that ordinary dcache
    management will not attempt to use dentries past the point their
    respective task has died.  When unused the shrinker will
    eventually be able to remove these dentries.
    
    There is a case in de_thread where proc_flush_pid can be
    called early for a given pid.  Which winds up being
    safe (if suboptimal) as this is just an optiimization.
    
    Only pid directories are put on the list as the other
    per pid files are children of those directories and
    d_invalidate on the directory will get them as well.
    
    So that the pid can be used during flushing it's reference count is
    taken in release_task and dropped in proc_flush_pid.  Further the call
    of proc_flush_pid is moved after the tasklist_lock is released in
    release_task so that it is certain that the pid has already been
    unhashed when flushing it taking place.  This removes a small race
    where a dentry could recreated.
    
    As struct pid is supposed to be small and I need a per pid lock
    I reuse the only lock that currently exists in struct pid the
    the wait_pidfd.lock.
    
    The net result is that this adds all of this functionality
    with just a little extra list management overhead and
    a single extra pointer in struct pid.
    
    v2: Initialize pid->inodes.  I somehow failed to get that
        initialization into the initial version of the patch.  A boot
        failure was reported by "kernel test robot <lkp@intel.com>", and
        failure to initialize that pid->inodes matches all of the reported
        symptoms.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index 0f4ecb57214c..ca08d6a3aa77 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -258,6 +258,7 @@ struct pid *alloc_pid(struct pid_namespace *ns, pid_t *set_tid,
 		INIT_HLIST_HEAD(&pid->tasks[type]);
 
 	init_waitqueue_head(&pid->wait_pidfd);
+	INIT_HLIST_HEAD(&pid->inodes);
 
 	upid = pid->numbers + ns->level;
 	spin_lock_irq(&pidmap_lock);

commit 8649c322f75c96e7ced2fec201e123b2b073bf09
Author: Sargun Dhillon <sargun@sargun.me>
Date:   Tue Jan 7 09:59:25 2020 -0800

    pid: Implement pidfd_getfd syscall
    
    This syscall allows for the retrieval of file descriptors from other
    processes, based on their pidfd. This is possible using ptrace, and
    injection of parasitic code to inject code which leverages SCM_RIGHTS
    to move file descriptors between a tracee and a tracer. Unfortunately,
    ptrace comes with a high cost of requiring the process to be stopped,
    and breaks debuggers. This does not require stopping the process under
    manipulation.
    
    One reason to use this is to allow sandboxers to take actions on file
    descriptors on the behalf of another process. For example, this can be
    combined with seccomp-bpf's user notification to do on-demand fd
    extraction and take privileged actions. One such privileged action
    is binding a socket to a privileged port.
    
    /* prototype */
      /* flags is currently reserved and should be set to 0 */
      int sys_pidfd_getfd(int pidfd, int fd, unsigned int flags);
    
    /* testing */
    Ran self-test suite on x86_64
    
    Signed-off-by: Sargun Dhillon <sargun@sargun.me>
    Acked-by: Christian Brauner <christian.brauner@ubuntu.com>
    Reviewed-by: Arnd Bergmann <arnd@arndb.de>
    Link: https://lore.kernel.org/r/20200107175927.4558-3-sargun@sargun.me
    Signed-off-by: Christian Brauner <christian.brauner@ubuntu.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index 2278e249141d..0f4ecb57214c 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -578,3 +578,93 @@ void __init pid_idr_init(void)
 	init_pid_ns.pid_cachep = KMEM_CACHE(pid,
 			SLAB_HWCACHE_ALIGN | SLAB_PANIC | SLAB_ACCOUNT);
 }
+
+static struct file *__pidfd_fget(struct task_struct *task, int fd)
+{
+	struct file *file;
+	int ret;
+
+	ret = mutex_lock_killable(&task->signal->cred_guard_mutex);
+	if (ret)
+		return ERR_PTR(ret);
+
+	if (ptrace_may_access(task, PTRACE_MODE_ATTACH_REALCREDS))
+		file = fget_task(task, fd);
+	else
+		file = ERR_PTR(-EPERM);
+
+	mutex_unlock(&task->signal->cred_guard_mutex);
+
+	return file ?: ERR_PTR(-EBADF);
+}
+
+static int pidfd_getfd(struct pid *pid, int fd)
+{
+	struct task_struct *task;
+	struct file *file;
+	int ret;
+
+	task = get_pid_task(pid, PIDTYPE_PID);
+	if (!task)
+		return -ESRCH;
+
+	file = __pidfd_fget(task, fd);
+	put_task_struct(task);
+	if (IS_ERR(file))
+		return PTR_ERR(file);
+
+	ret = security_file_receive(file);
+	if (ret) {
+		fput(file);
+		return ret;
+	}
+
+	ret = get_unused_fd_flags(O_CLOEXEC);
+	if (ret < 0)
+		fput(file);
+	else
+		fd_install(ret, file);
+
+	return ret;
+}
+
+/**
+ * sys_pidfd_getfd() - Get a file descriptor from another process
+ *
+ * @pidfd:	the pidfd file descriptor of the process
+ * @fd:		the file descriptor number to get
+ * @flags:	flags on how to get the fd (reserved)
+ *
+ * This syscall gets a copy of a file descriptor from another process
+ * based on the pidfd, and file descriptor number. It requires that
+ * the calling process has the ability to ptrace the process represented
+ * by the pidfd. The process which is having its file descriptor copied
+ * is otherwise unaffected.
+ *
+ * Return: On success, a cloexec file descriptor is returned.
+ *         On error, a negative errno number will be returned.
+ */
+SYSCALL_DEFINE3(pidfd_getfd, int, pidfd, int, fd,
+		unsigned int, flags)
+{
+	struct pid *pid;
+	struct fd f;
+	int ret;
+
+	/* flags is currently unused - make sure it's unset */
+	if (flags)
+		return -EINVAL;
+
+	f = fdget(pidfd);
+	if (!f.file)
+		return -EBADF;
+
+	pid = pidfd_pid(f.file);
+	if (IS_ERR(pid))
+		ret = PTR_ERR(pid);
+	else
+		ret = pidfd_getfd(pid, fd);
+
+	fdput(f);
+	return ret;
+}

commit 49cb2fc42ce4b7a656ee605e30c302efaa39c1a7
Author: Adrian Reber <areber@redhat.com>
Date:   Fri Nov 15 13:36:20 2019 +0100

    fork: extend clone3() to support setting a PID
    
    The main motivation to add set_tid to clone3() is CRIU.
    
    To restore a process with the same PID/TID CRIU currently uses
    /proc/sys/kernel/ns_last_pid. It writes the desired (PID - 1) to
    ns_last_pid and then (quickly) does a clone(). This works most of the
    time, but it is racy. It is also slow as it requires multiple syscalls.
    
    Extending clone3() to support *set_tid makes it possible restore a
    process using CRIU without accessing /proc/sys/kernel/ns_last_pid and
    race free (as long as the desired PID/TID is available).
    
    This clone3() extension places the same restrictions (CAP_SYS_ADMIN)
    on clone3() with *set_tid as they are currently in place for ns_last_pid.
    
    The original version of this change was using a single value for
    set_tid. At the 2019 LPC, after presenting set_tid, it was, however,
    decided to change set_tid to an array to enable setting the PID of a
    process in multiple PID namespaces at the same time. If a process is
    created in a PID namespace it is possible to influence the PID inside
    and outside of the PID namespace. Details also in the corresponding
    selftest.
    
    To create a process with the following PIDs:
    
          PID NS level         Requested PID
            0 (host)              31496
            1                        42
            2                         1
    
    For that example the two newly introduced parameters to struct
    clone_args (set_tid and set_tid_size) would need to be:
    
      set_tid[0] = 1;
      set_tid[1] = 42;
      set_tid[2] = 31496;
      set_tid_size = 3;
    
    If only the PIDs of the two innermost nested PID namespaces should be
    defined it would look like this:
    
      set_tid[0] = 1;
      set_tid[1] = 42;
      set_tid_size = 2;
    
    The PID of the newly created process would then be the next available
    free PID in the PID namespace level 0 (host) and 42 in the PID namespace
    at level 1 and the PID of the process in the innermost PID namespace
    would be 1.
    
    The set_tid array is used to specify the PID of a process starting
    from the innermost nested PID namespaces up to set_tid_size PID namespaces.
    
    set_tid_size cannot be larger then the current PID namespace level.
    
    Signed-off-by: Adrian Reber <areber@redhat.com>
    Reviewed-by: Christian Brauner <christian.brauner@ubuntu.com>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Dmitry Safonov <0x7f454c46@gmail.com>
    Acked-by: Andrei Vagin <avagin@gmail.com>
    Link: https://lore.kernel.org/r/20191115123621.142252-1-areber@redhat.com
    Signed-off-by: Christian Brauner <christian.brauner@ubuntu.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index 7b5f6c963d72..2278e249141d 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -157,7 +157,8 @@ void free_pid(struct pid *pid)
 	call_rcu(&pid->rcu, delayed_put_pid);
 }
 
-struct pid *alloc_pid(struct pid_namespace *ns)
+struct pid *alloc_pid(struct pid_namespace *ns, pid_t *set_tid,
+		      size_t set_tid_size)
 {
 	struct pid *pid;
 	enum pid_type type;
@@ -166,6 +167,17 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	struct upid *upid;
 	int retval = -ENOMEM;
 
+	/*
+	 * set_tid_size contains the size of the set_tid array. Starting at
+	 * the most nested currently active PID namespace it tells alloc_pid()
+	 * which PID to set for a process in that most nested PID namespace
+	 * up to set_tid_size PID namespaces. It does not have to set the PID
+	 * for a process in all nested PID namespaces but set_tid_size must
+	 * never be greater than the current ns->level + 1.
+	 */
+	if (set_tid_size > ns->level + 1)
+		return ERR_PTR(-EINVAL);
+
 	pid = kmem_cache_alloc(ns->pid_cachep, GFP_KERNEL);
 	if (!pid)
 		return ERR_PTR(retval);
@@ -174,24 +186,54 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	pid->level = ns->level;
 
 	for (i = ns->level; i >= 0; i--) {
-		int pid_min = 1;
+		int tid = 0;
+
+		if (set_tid_size) {
+			tid = set_tid[ns->level - i];
+
+			retval = -EINVAL;
+			if (tid < 1 || tid >= pid_max)
+				goto out_free;
+			/*
+			 * Also fail if a PID != 1 is requested and
+			 * no PID 1 exists.
+			 */
+			if (tid != 1 && !tmp->child_reaper)
+				goto out_free;
+			retval = -EPERM;
+			if (!ns_capable(tmp->user_ns, CAP_SYS_ADMIN))
+				goto out_free;
+			set_tid_size--;
+		}
 
 		idr_preload(GFP_KERNEL);
 		spin_lock_irq(&pidmap_lock);
 
-		/*
-		 * init really needs pid 1, but after reaching the maximum
-		 * wrap back to RESERVED_PIDS
-		 */
-		if (idr_get_cursor(&tmp->idr) > RESERVED_PIDS)
-			pid_min = RESERVED_PIDS;
-
-		/*
-		 * Store a null pointer so find_pid_ns does not find
-		 * a partially initialized PID (see below).
-		 */
-		nr = idr_alloc_cyclic(&tmp->idr, NULL, pid_min,
-				      pid_max, GFP_ATOMIC);
+		if (tid) {
+			nr = idr_alloc(&tmp->idr, NULL, tid,
+				       tid + 1, GFP_ATOMIC);
+			/*
+			 * If ENOSPC is returned it means that the PID is
+			 * alreay in use. Return EEXIST in that case.
+			 */
+			if (nr == -ENOSPC)
+				nr = -EEXIST;
+		} else {
+			int pid_min = 1;
+			/*
+			 * init really needs pid 1, but after reaching the
+			 * maximum wrap back to RESERVED_PIDS
+			 */
+			if (idr_get_cursor(&tmp->idr) > RESERVED_PIDS)
+				pid_min = RESERVED_PIDS;
+
+			/*
+			 * Store a null pointer so find_pid_ns does not find
+			 * a partially initialized PID (see below).
+			 */
+			nr = idr_alloc_cyclic(&tmp->idr, NULL, pid_min,
+					      pid_max, GFP_ATOMIC);
+		}
 		spin_unlock_irq(&pidmap_lock);
 		idr_preload_end();
 

commit 1e1d0f0b1a3e3533ea4cd4021eb251e53827c70b
Author: Christian Brauner <christian.brauner@ubuntu.com>
Date:   Thu Oct 17 12:18:32 2019 +0200

    pid: use pid_has_task() in pidfd_open()
    
    Use the new pid_has_task() helper in pidfd_open(). This simplifies the
    code and avoids taking rcu_read_{lock,unlock}() and leads to overall
    nicer code.
    
    Signed-off-by: Christian Brauner <christian.brauner@ubuntu.com>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Link: https://lore.kernel.org/r/20191017101832.5985-5-christian.brauner@ubuntu.com

diff --git a/kernel/pid.c b/kernel/pid.c
index 124d40b239b1..7b5f6c963d72 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -497,7 +497,7 @@ static int pidfd_create(struct pid *pid)
  */
 SYSCALL_DEFINE2(pidfd_open, pid_t, pid, unsigned int, flags)
 {
-	int fd, ret;
+	int fd;
 	struct pid *p;
 
 	if (flags)
@@ -510,13 +510,11 @@ SYSCALL_DEFINE2(pidfd_open, pid_t, pid, unsigned int, flags)
 	if (!p)
 		return -ESRCH;
 
-	ret = 0;
-	rcu_read_lock();
-	if (!pid_task(p, PIDTYPE_TGID))
-		ret = -EINVAL;
-	rcu_read_unlock();
+	if (pid_has_task(p, PIDTYPE_TGID))
+		fd = pidfd_create(p);
+	else
+		fd = -EINVAL;
 
-	fd = ret ?: pidfd_create(p);
 	put_pid(p);
 	return fd;
 }

commit 1d416a113f0c0da7a3608ffe4d44bd8e9c4859fa
Author: Christian Brauner <christian.brauner@ubuntu.com>
Date:   Thu Oct 17 12:18:30 2019 +0200

    pid: use pid_has_task() in __change_pid()
    
    Replace hlist_empty() with the new pid_has_task() helper which is more
    idiomatic, easier to grep for, and unifies how callers perform this
    check.
    
    Signed-off-by: Christian Brauner <christian.brauner@ubuntu.com>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Link: https://lore.kernel.org/r/20191017101832.5985-3-christian.brauner@ubuntu.com

diff --git a/kernel/pid.c b/kernel/pid.c
index 0a9f2e437217..124d40b239b1 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -299,7 +299,7 @@ static void __change_pid(struct task_struct *task, enum pid_type type,
 	*pid_ptr = new;
 
 	for (tmp = PIDTYPE_MAX; --tmp >= 0; )
-		if (!hlist_empty(&pid->tasks[tmp]))
+		if (pid_has_task(pid, tmp))
 			return;
 
 	free_pid(pid);

commit f57e515a1b56325a28a0972c632a623a9c84590c
Author: Joel Fernandes (Google) <joel@joelfernandes.org>
Date:   Tue Jul 16 16:30:06 2019 -0700

    kernel/pid.c: convert struct pid count to refcount_t
    
    struct pid's count is an atomic_t field used as a refcount.  Use
    refcount_t for it which is basically atomic_t but does additional
    checking to prevent use-after-free bugs.
    
    For memory ordering, the only change is with the following:
    
     -      if ((atomic_read(&pid->count) == 1) ||
     -           atomic_dec_and_test(&pid->count)) {
     +      if (refcount_dec_and_test(&pid->count)) {
                    kmem_cache_free(ns->pid_cachep, pid);
    
    Here the change is from: Fully ordered --> RELEASE + ACQUIRE (as per
    refcount-vs-atomic.rst) This ACQUIRE should take care of making sure the
    free happens after the refcount_dec_and_test().
    
    The above hunk also removes atomic_read() since it is not needed for the
    code to work and it is unclear how beneficial it is.  The removal lets
    refcount_dec_and_test() check for cases where get_pid() happened before
    the object was freed.
    
    Link: http://lkml.kernel.org/r/20190701183826.191936-1-joel@joelfernandes.org
    Signed-off-by: Joel Fernandes (Google) <joel@joelfernandes.org>
    Reviewed-by: Andrea Parri <andrea.parri@amarulasolutions.com>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Elena Reshetova <elena.reshetova@intel.com>
    Cc: Jann Horn <jannh@google.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: KJ Tsanaktsidis <ktsanaktsidis@zendesk.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 16263b526560..0a9f2e437217 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -37,14 +37,14 @@
 #include <linux/init_task.h>
 #include <linux/syscalls.h>
 #include <linux/proc_ns.h>
-#include <linux/proc_fs.h>
+#include <linux/refcount.h>
 #include <linux/anon_inodes.h>
 #include <linux/sched/signal.h>
 #include <linux/sched/task.h>
 #include <linux/idr.h>
 
 struct pid init_struct_pid = {
-	.count 		= ATOMIC_INIT(1),
+	.count		= REFCOUNT_INIT(1),
 	.tasks		= {
 		{ .first = NULL },
 		{ .first = NULL },
@@ -108,8 +108,7 @@ void put_pid(struct pid *pid)
 		return;
 
 	ns = pid->numbers[pid->level].ns;
-	if ((atomic_read(&pid->count) == 1) ||
-	     atomic_dec_and_test(&pid->count)) {
+	if (refcount_dec_and_test(&pid->count)) {
 		kmem_cache_free(ns->pid_cachep, pid);
 		put_pid_ns(ns);
 	}
@@ -212,7 +211,7 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	}
 
 	get_pid_ns(ns);
-	atomic_set(&pid->count, 1);
+	refcount_set(&pid->count, 1);
 	for (type = 0; type < PIDTYPE_MAX; ++type)
 		INIT_HLIST_HEAD(&pid->tasks[type]);
 

commit 5450e8a316a64cddcbc15f90733ebc78aa736545
Merge: 29cd581b5949 172bb24a4f48
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 10 22:17:21 2019 -0700

    Merge tag 'pidfd-updates-v5.3' of git://git.kernel.org/pub/scm/linux/kernel/git/brauner/linux
    
    Pull pidfd updates from Christian Brauner:
     "This adds two main features.
    
       - First, it adds polling support for pidfds. This allows process
         managers to know when a (non-parent) process dies in a race-free
         way.
    
         The notification mechanism used follows the same logic that is
         currently used when the parent of a task is notified of a child's
         death. With this patchset it is possible to put pidfds in an
         {e}poll loop and get reliable notifications for process (i.e.
         thread-group) exit.
    
       - The second feature compliments the first one by making it possible
         to retrieve pollable pidfds for processes that were not created
         using CLONE_PIDFD.
    
         A lot of processes get created with traditional PID-based calls
         such as fork() or clone() (without CLONE_PIDFD). For these
         processes a caller can currently not create a pollable pidfd. This
         is a problem for Android's low memory killer (LMK) and service
         managers such as systemd.
    
      Both patchsets are accompanied by selftests.
    
      It's perhaps worth noting that the work done so far and the work done
      in this branch for pidfd_open() and polling support do already see
      some adoption:
    
       - Android is in the process of backporting this work to all their LTS
         kernels [1]
    
       - Service managers make use of pidfd_send_signal but will need to
         wait until we enable waiting on pidfds for full adoption.
    
       - And projects I maintain make use of both pidfd_send_signal and
         CLONE_PIDFD [2] and will use polling support and pidfd_open() too"
    
    [1] https://android-review.googlesource.com/q/topic:%22pidfd+polling+support+4.9+backport%22
        https://android-review.googlesource.com/q/topic:%22pidfd+polling+support+4.14+backport%22
        https://android-review.googlesource.com/q/topic:%22pidfd+polling+support+4.19+backport%22
    
    [2] https://github.com/lxc/lxc/blob/aab6e3eb73c343231cdde775db938994fc6f2803/src/lxc/start.c#L1753
    
    * tag 'pidfd-updates-v5.3' of git://git.kernel.org/pub/scm/linux/kernel/git/brauner/linux:
      tests: add pidfd_open() tests
      arch: wire-up pidfd_open()
      pid: add pidfd_open()
      pidfd: add polling selftests
      pidfd: add polling support

commit 32fcb426ec001cb6d5a4a195091a8486ea77e2df
Author: Christian Brauner <christian@brauner.io>
Date:   Fri May 24 12:43:51 2019 +0200

    pid: add pidfd_open()
    
    This adds the pidfd_open() syscall. It allows a caller to retrieve pollable
    pidfds for a process which did not get created via CLONE_PIDFD, i.e. for a
    process that is created via traditional fork()/clone() calls that is only
    referenced by a PID:
    
    int pidfd = pidfd_open(1234, 0);
    ret = pidfd_send_signal(pidfd, SIGSTOP, NULL, 0);
    
    With the introduction of pidfds through CLONE_PIDFD it is possible to
    created pidfds at process creation time.
    However, a lot of processes get created with traditional PID-based calls
    such as fork() or clone() (without CLONE_PIDFD). For these processes a
    caller can currently not create a pollable pidfd. This is a problem for
    Android's low memory killer (LMK) and service managers such as systemd.
    Both are examples of tools that want to make use of pidfds to get reliable
    notification of process exit for non-parents (pidfd polling) and race-free
    signal sending (pidfd_send_signal()). They intend to switch to this API for
    process supervision/management as soon as possible. Having no way to get
    pollable pidfds from PID-only processes is one of the biggest blockers for
    them in adopting this api. With pidfd_open() making it possible to retrieve
    pidfds for PID-based processes we enable them to adopt this api.
    
    In line with Arnd's recent changes to consolidate syscall numbers across
    architectures, I have added the pidfd_open() syscall to all architectures
    at the same time.
    
    Signed-off-by: Christian Brauner <christian@brauner.io>
    Reviewed-by: David Howells <dhowells@redhat.com>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Joel Fernandes (Google) <joel@joelfernandes.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jann Horn <jannh@google.com>
    Cc: Andy Lutomirsky <luto@kernel.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Aleksa Sarai <cyphar@cyphar.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: linux-api@vger.kernel.org

diff --git a/kernel/pid.c b/kernel/pid.c
index 6ce3a95968f7..8e6f50053364 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -37,6 +37,8 @@
 #include <linux/syscalls.h>
 #include <linux/proc_ns.h>
 #include <linux/proc_fs.h>
+#include <linux/anon_inodes.h>
+#include <linux/sched/signal.h>
 #include <linux/sched/task.h>
 #include <linux/idr.h>
 
@@ -452,6 +454,73 @@ struct pid *find_ge_pid(int nr, struct pid_namespace *ns)
 	return idr_get_next(&ns->idr, &nr);
 }
 
+/**
+ * pidfd_create() - Create a new pid file descriptor.
+ *
+ * @pid:  struct pid that the pidfd will reference
+ *
+ * This creates a new pid file descriptor with the O_CLOEXEC flag set.
+ *
+ * Note, that this function can only be called after the fd table has
+ * been unshared to avoid leaking the pidfd to the new process.
+ *
+ * Return: On success, a cloexec pidfd is returned.
+ *         On error, a negative errno number will be returned.
+ */
+static int pidfd_create(struct pid *pid)
+{
+	int fd;
+
+	fd = anon_inode_getfd("[pidfd]", &pidfd_fops, get_pid(pid),
+			      O_RDWR | O_CLOEXEC);
+	if (fd < 0)
+		put_pid(pid);
+
+	return fd;
+}
+
+/**
+ * pidfd_open() - Open new pid file descriptor.
+ *
+ * @pid:   pid for which to retrieve a pidfd
+ * @flags: flags to pass
+ *
+ * This creates a new pid file descriptor with the O_CLOEXEC flag set for
+ * the process identified by @pid. Currently, the process identified by
+ * @pid must be a thread-group leader. This restriction currently exists
+ * for all aspects of pidfds including pidfd creation (CLONE_PIDFD cannot
+ * be used with CLONE_THREAD) and pidfd polling (only supports thread group
+ * leaders).
+ *
+ * Return: On success, a cloexec pidfd is returned.
+ *         On error, a negative errno number will be returned.
+ */
+SYSCALL_DEFINE2(pidfd_open, pid_t, pid, unsigned int, flags)
+{
+	int fd, ret;
+	struct pid *p;
+
+	if (flags)
+		return -EINVAL;
+
+	if (pid <= 0)
+		return -EINVAL;
+
+	p = find_get_pid(pid);
+	if (!p)
+		return -ESRCH;
+
+	ret = 0;
+	rcu_read_lock();
+	if (!pid_task(p, PIDTYPE_TGID))
+		ret = -EINVAL;
+	rcu_read_unlock();
+
+	fd = ret ?: pidfd_create(p);
+	put_pid(p);
+	return fd;
+}
+
 void __init pid_idr_init(void)
 {
 	/* Verify no one has done anything silly: */

commit b53b0b9d9a613c418057f6cb921c2f40a6f78c24
Author: Joel Fernandes (Google) <joel@joelfernandes.org>
Date:   Tue Apr 30 12:21:53 2019 -0400

    pidfd: add polling support
    
    This patch adds polling support to pidfd.
    
    Android low memory killer (LMK) needs to know when a process dies once
    it is sent the kill signal. It does so by checking for the existence of
    /proc/pid which is both racy and slow. For example, if a PID is reused
    between when LMK sends a kill signal and checks for existence of the
    PID, since the wrong PID is now possibly checked for existence.
    Using the polling support, LMK will be able to get notified when a process
    exists in race-free and fast way, and allows the LMK to do other things
    (such as by polling on other fds) while awaiting the process being killed
    to die.
    
    For notification to polling processes, we follow the same existing
    mechanism in the kernel used when the parent of the task group is to be
    notified of a child's death (do_notify_parent). This is precisely when the
    tasks waiting on a poll of pidfd are also awakened in this patch.
    
    We have decided to include the waitqueue in struct pid for the following
    reasons:
    1. The wait queue has to survive for the lifetime of the poll. Including
       it in task_struct would not be option in this case because the task can
       be reaped and destroyed before the poll returns.
    
    2. By including the struct pid for the waitqueue means that during
       de_thread(), the new thread group leader automatically gets the new
       waitqueue/pid even though its task_struct is different.
    
    Appropriate test cases are added in the second patch to provide coverage of
    all the cases the patch is handling.
    
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Daniel Colascione <dancol@google.com>
    Cc: Jann Horn <jannh@google.com>
    Cc: Tim Murray <timmurray@google.com>
    Cc: Jonathan Kowalski <bl0pbl33p@gmail.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: kernel-team@android.com
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Co-developed-by: Daniel Colascione <dancol@google.com>
    Signed-off-by: Daniel Colascione <dancol@google.com>
    Signed-off-by: Joel Fernandes (Google) <joel@joelfernandes.org>
    Signed-off-by: Christian Brauner <christian@brauner.io>

diff --git a/kernel/pid.c b/kernel/pid.c
index 89548d35eefb..6ce3a95968f7 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -213,6 +213,8 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	for (type = 0; type < PIDTYPE_MAX; ++type)
 		INIT_HLIST_HEAD(&pid->tasks[type]);
 
+	init_waitqueue_head(&pid->wait_pidfd);
+
 	upid = pid->numbers + ns->level;
 	spin_lock_irq(&pidmap_lock);
 	if (!(ns->pid_allocated & PIDNS_ADDING))

commit 457c89965399115e5cd8bf38f9c597293405703d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun May 19 13:08:55 2019 +0100

    treewide: Add SPDX license identifier for missed files
    
    Add SPDX license identifiers to all files which:
    
     - Have no license information of any form
    
     - Have EXPORT_.*_SYMBOL_GPL inside which was used in the
       initial scan/conversion to ignore the file
    
    These files fall under the project license, GPL v2 only. The resulting SPDX
    license identifier is:
    
      GPL-2.0-only
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 89548d35eefb..e5cad0c7d5dd 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * Generic pidhash and scalable, time-bounded PID allocator
  *

commit 1fd402df4586bcc239298081449ce58a78211626
Author: Timmy Li <scuttimmy@gmail.com>
Date:   Tue May 14 15:45:16 2019 -0700

    kernel/pid.c: remove unneeded hash header file
    
    Hash functions are not needed since idr is used now.  Let's remove hash
    header file for cleanup.
    
    Link: http://lkml.kernel.org/r/20190430053319.95913-1-scuttimmy@gmail.com
    Signed-off-by: Timmy Li <scuttimmy@gmail.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Cc: KJ Tsanaktsidis <ktsanaktsidis@zendesk.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 20881598bdfa..89548d35eefb 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -32,7 +32,6 @@
 #include <linux/init.h>
 #include <linux/rculist.h>
 #include <linux/memblock.h>
-#include <linux/hash.h>
 #include <linux/pid_namespace.h>
 #include <linux/init_task.h>
 #include <linux/syscalls.h>

commit 1a80dade010c7a7f4885a4c4c2a7ac22cc7b34df
Author: Matthew Wilcox <willy@infradead.org>
Date:   Fri Dec 28 07:22:26 2018 -0800

    Fix failure path in alloc_pid()
    
    The failure path removes the allocated PIDs from the wrong namespace.
    This could lead to us inadvertently reusing PIDs in the leaf namespace
    and leaking PIDs in parent namespaces.
    
    Fixes: 95846ecf9dac ("pid: replace pid bitmap implementation with IDR API")
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Matthew Wilcox <willy@infradead.org>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index b2f6c506035d..20881598bdfa 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -233,8 +233,10 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 
 out_free:
 	spin_lock_irq(&pidmap_lock);
-	while (++i <= ns->level)
-		idr_remove(&ns->idr, (pid->numbers + i)->nr);
+	while (++i <= ns->level) {
+		upid = pid->numbers + i;
+		idr_remove(&upid->ns->idr, upid->nr);
+	}
 
 	/* On failure to allocate the first pid, reset the state */
 	if (ns->pid_allocated == PIDNS_ADDING)

commit 57c8a661d95dff48dd9c2f2496139082bbaf241a
Author: Mike Rapoport <rppt@linux.vnet.ibm.com>
Date:   Tue Oct 30 15:09:49 2018 -0700

    mm: remove include/linux/bootmem.h
    
    Move remaining definitions and declarations from include/linux/bootmem.h
    into include/linux/memblock.h and remove the redundant header.
    
    The includes were replaced with the semantic patch below and then
    semi-automated removal of duplicated '#include <linux/memblock.h>
    
    @@
    @@
    - #include <linux/bootmem.h>
    + #include <linux/memblock.h>
    
    [sfr@canb.auug.org.au: dma-direct: fix up for the removal of linux/bootmem.h]
      Link: http://lkml.kernel.org/r/20181002185342.133d1680@canb.auug.org.au
    [sfr@canb.auug.org.au: powerpc: fix up for removal of linux/bootmem.h]
      Link: http://lkml.kernel.org/r/20181005161406.73ef8727@canb.auug.org.au
    [sfr@canb.auug.org.au: x86/kaslr, ACPI/NUMA: fix for linux/bootmem.h removal]
      Link: http://lkml.kernel.org/r/20181008190341.5e396491@canb.auug.org.au
    Link: http://lkml.kernel.org/r/1536927045-23536-30-git-send-email-rppt@linux.vnet.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Ley Foon Tan <lftan@altera.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Palmer Dabbelt <palmer@sifive.com>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Serge Semin <fancer.lancer@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index cdf63e53a014..b2f6c506035d 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -31,7 +31,7 @@
 #include <linux/slab.h>
 #include <linux/init.h>
 #include <linux/rculist.h>
-#include <linux/bootmem.h>
+#include <linux/memblock.h>
 #include <linux/hash.h>
 #include <linux/pid_namespace.h>
 #include <linux/init_task.h>

commit f83606f5eb007adc33bc8541ede00590f477bdeb
Author: KJ Tsanaktsidis <ktsanaktsidis@zendesk.com>
Date:   Thu Sep 20 12:22:25 2018 -0700

    fork: report pid exhaustion correctly
    
    Make the clone and fork syscalls return EAGAIN when the limit on the
    number of pids /proc/sys/kernel/pid_max is exceeded.
    
    Currently, when the pid_max limit is exceeded, the kernel will return
    ENOSPC from the fork and clone syscalls.  This is contrary to the
    documented behaviour, which explicitly calls out the pid_max case as one
    where EAGAIN should be returned.  It also leads to really confusing error
    messages in userspace programs which will complain about a lack of disk
    space when they fail to create processes/threads for this reason.
    
    This error is being returned because alloc_pid() uses the idr api to find
    a new pid; when there are none available, idr_alloc_cyclic() returns
    -ENOSPC, and this is being propagated back to userspace.
    
    This behaviour has been broken before, and was explicitly fixed in
    commit 35f71bc0a09a ("fork: report pid reservation failure properly"),
    so I think -EAGAIN is definitely the right thing to return in this case.
    The current behaviour change dates from commit 95846ecf9dac ("pid:
    replace pid bitmap implementation with IDR AIP") and was I believe
    unintentional.
    
    This patch has no impact on the case where allocating a pid fails because
    the child reaper for the namespace is dead; that case will still return
    -ENOMEM.
    
    Link: http://lkml.kernel.org/r/20180903111016.46461-1-ktsanaktsidis@zendesk.com
    Fixes: 95846ecf9dac ("pid: replace pid bitmap implementation with IDR AIP")
    Signed-off-by: KJ Tsanaktsidis <ktsanaktsidis@zendesk.com>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Gargi Sharma <gs051095@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index de1cfc4f75a2..cdf63e53a014 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -195,7 +195,7 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 		idr_preload_end();
 
 		if (nr < 0) {
-			retval = nr;
+			retval = (nr == -ENOSPC) ? -EAGAIN : nr;
 			goto out_free;
 		}
 

commit 6883f81aac6f44e7df70a6af189b3689ff52cbfb
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sun Jun 4 04:32:13 2017 -0500

    pid: Implement PIDTYPE_TGID
    
    Everywhere except in the pid array we distinguish between a tasks pid and
    a tasks tgid (thread group id).  Even in the enumeration we want that
    distinction sometimes so we have added __PIDTYPE_TGID.  With leader_pid
    we almost have an implementation of PIDTYPE_TGID in struct signal_struct.
    
    Add PIDTYPE_TGID as a first class member of the pid_type enumeration and
    into the pids array.  Then remove the __PIDTYPE_TGID special case and the
    leader_pid in signal_struct.
    
    The net size increase is just an extra pointer added to struct pid and
    an extra pair of pointers of an hlist_node added to task_struct.
    
    The effect on code maintenance is the removal of a number of special
    cases today and the potential to remove many more special cases as
    PIDTYPE_TGID gets used to it's fullest.  The long term potential
    is allowing zombie thread group leaders to exit, which will remove
    a lot more special cases in the code.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index f8486d2e2346..de1cfc4f75a2 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -269,8 +269,6 @@ static struct pid **task_pid_ptr(struct task_struct *task, enum pid_type type)
 {
 	return (type == PIDTYPE_PID) ?
 		&task->thread_pid :
-		(type == __PIDTYPE_TGID) ?
-		&task->signal->leader_pid :
 		&task->signal->pids[type];
 }
 

commit 2c4704756cab7cfa031ada4dab361562f0e357c0
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Sep 26 13:06:43 2017 -0500

    pids: Move the pgrp and session pid pointers from task_struct to signal_struct
    
    To access these fields the code always has to go to group leader so
    going to signal struct is no loss and is actually a fundamental simplification.
    
    This saves a little bit of memory by only allocating the pid pointer array
    once instead of once for every thread, and even better this removes a
    few potential races caused by the fact that group_leader can be changed
    by de_thread, while signal_struct can not.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index d0de2b59f86f..f8486d2e2346 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -265,27 +265,35 @@ struct pid *find_vpid(int nr)
 }
 EXPORT_SYMBOL_GPL(find_vpid);
 
+static struct pid **task_pid_ptr(struct task_struct *task, enum pid_type type)
+{
+	return (type == PIDTYPE_PID) ?
+		&task->thread_pid :
+		(type == __PIDTYPE_TGID) ?
+		&task->signal->leader_pid :
+		&task->signal->pids[type];
+}
+
 /*
  * attach_pid() must be called with the tasklist_lock write-held.
  */
 void attach_pid(struct task_struct *task, enum pid_type type)
 {
-	struct pid_link *link = &task->pids[type];
-	hlist_add_head_rcu(&link->node, &link->pid->tasks[type]);
+	struct pid *pid = *task_pid_ptr(task, type);
+	hlist_add_head_rcu(&task->pid_links[type], &pid->tasks[type]);
 }
 
 static void __change_pid(struct task_struct *task, enum pid_type type,
 			struct pid *new)
 {
-	struct pid_link *link;
+	struct pid **pid_ptr = task_pid_ptr(task, type);
 	struct pid *pid;
 	int tmp;
 
-	link = &task->pids[type];
-	pid = link->pid;
+	pid = *pid_ptr;
 
-	hlist_del_rcu(&link->node);
-	link->pid = new;
+	hlist_del_rcu(&task->pid_links[type]);
+	*pid_ptr = new;
 
 	for (tmp = PIDTYPE_MAX; --tmp >= 0; )
 		if (!hlist_empty(&pid->tasks[tmp]))
@@ -310,8 +318,9 @@ void change_pid(struct task_struct *task, enum pid_type type,
 void transfer_pid(struct task_struct *old, struct task_struct *new,
 			   enum pid_type type)
 {
-	new->pids[type].pid = old->pids[type].pid;
-	hlist_replace_rcu(&old->pids[type].node, &new->pids[type].node);
+	if (type == PIDTYPE_PID)
+		new->thread_pid = old->thread_pid;
+	hlist_replace_rcu(&old->pid_links[type], &new->pid_links[type]);
 }
 
 struct task_struct *pid_task(struct pid *pid, enum pid_type type)
@@ -322,7 +331,7 @@ struct task_struct *pid_task(struct pid *pid, enum pid_type type)
 		first = rcu_dereference_check(hlist_first_rcu(&pid->tasks[type]),
 					      lockdep_tasklist_lock_is_held());
 		if (first)
-			result = hlist_entry(first, struct task_struct, pids[(type)].node);
+			result = hlist_entry(first, struct task_struct, pid_links[(type)]);
 	}
 	return result;
 }
@@ -360,9 +369,7 @@ struct pid *get_task_pid(struct task_struct *task, enum pid_type type)
 {
 	struct pid *pid;
 	rcu_read_lock();
-	if (type != PIDTYPE_PID)
-		task = task->group_leader;
-	pid = get_pid(rcu_dereference(task->pids[type].pid));
+	pid = get_pid(rcu_dereference(*task_pid_ptr(task, type)));
 	rcu_read_unlock();
 	return pid;
 }
@@ -420,16 +427,8 @@ pid_t __task_pid_nr_ns(struct task_struct *task, enum pid_type type,
 	rcu_read_lock();
 	if (!ns)
 		ns = task_active_pid_ns(current);
-	if (likely(pid_alive(task))) {
-		struct pid *pid;
-		if (type == PIDTYPE_PID)
-			pid = task_pid(task);
-		else if (type == __PIDTYPE_TGID)
-			pid = task_tgid(task);
-		else
-			pid = rcu_dereference(task->group_leader->pids[type].pid);
-		nr = pid_nr_ns(pid, ns);
-	}
+	if (likely(pid_alive(task)))
+		nr = pid_nr_ns(rcu_dereference(*task_pid_ptr(task, type)), ns);
 	rcu_read_unlock();
 
 	return nr;

commit 7a36094d61bfe9843de5484ff0140227983ac5d5
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Sep 26 12:45:33 2017 -0500

    pids: Compute task_tgid using signal->leader_pid
    
    The cost is the the same and this removes the need
    to worry about complications that come from de_thread
    and group_leader changing.
    
    __task_pid_nr_ns has been updated to take advantage of this change.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index 157fe4b19971..d0de2b59f86f 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -421,13 +421,14 @@ pid_t __task_pid_nr_ns(struct task_struct *task, enum pid_type type,
 	if (!ns)
 		ns = task_active_pid_ns(current);
 	if (likely(pid_alive(task))) {
-		if (type != PIDTYPE_PID) {
-			if (type == __PIDTYPE_TGID)
-				type = PIDTYPE_PID;
-
-			task = task->group_leader;
-		}
-		nr = pid_nr_ns(rcu_dereference(task->pids[type].pid), ns);
+		struct pid *pid;
+		if (type == PIDTYPE_PID)
+			pid = task_pid(task);
+		else if (type == __PIDTYPE_TGID)
+			pid = task_tgid(task);
+		else
+			pid = rcu_dereference(task->group_leader->pids[type].pid);
+		nr = pid_nr_ns(pid, ns);
 	}
 	rcu_read_unlock();
 

commit f6bb2a2c0b81c47282ddb7883f92e65a063c27dd
Author: Matthew Wilcox <mawilcox@microsoft.com>
Date:   Tue Apr 10 16:36:52 2018 -0700

    xarray: add the xa_lock to the radix_tree_root
    
    This results in no change in structure size on 64-bit machines as it
    fits in the padding between the gfp_t and the void *.  32-bit machines
    will grow the structure from 8 to 12 bytes.  Almost all radix trees are
    protected with (at least) a spinlock, so as they are converted from
    radix trees to xarrays, the data structures will shrink again.
    
    Initialising the spinlock requires a name for the benefit of lockdep, so
    RADIX_TREE_INIT() now needs to know the name of the radix tree it's
    initialising, and so do IDR_INIT() and IDA_INIT().
    
    Also add the xa_lock() and xa_unlock() family of wrappers to make it
    easier to use the lock.  If we could rely on -fplan9-extensions in the
    compiler, we could avoid all of this syntactic sugar, but that wasn't
    added until gcc 4.6.
    
    Link: http://lkml.kernel.org/r/20180313132639.17387-8-willy@infradead.org
    Signed-off-by: Matthew Wilcox <mawilcox@microsoft.com>
    Reviewed-by: Jeff Layton <jlayton@kernel.org>
    Cc: Darrick J. Wong <darrick.wong@oracle.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Ryusuke Konishi <konishi.ryusuke@lab.ntt.co.jp>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index ed6c343fe50d..157fe4b19971 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -70,7 +70,7 @@ int pid_max_max = PID_MAX_LIMIT;
  */
 struct pid_namespace init_pid_ns = {
 	.kref = KREF_INIT(2),
-	.idr = IDR_INIT,
+	.idr = IDR_INIT(init_pid_ns.idr),
 	.pid_allocated = PIDNS_ADDING,
 	.level = 0,
 	.child_reaper = &init_task,

commit 2ee0826085d1c0281cb60c1f4bc3e0c27efeedc3
Author: Mike Rapoport <rppt@linux.vnet.ibm.com>
Date:   Tue Feb 6 15:40:17 2018 -0800

    pids: introduce find_get_task_by_vpid() helper
    
    There are several functions that do find_task_by_vpid() followed by
    get_task_struct().  We can use a helper function instead.
    
    Link: http://lkml.kernel.org/r/1509602027-11337-1-git-send-email-rppt@linux.vnet.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 5d30c87e3c42..ed6c343fe50d 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -343,6 +343,19 @@ struct task_struct *find_task_by_vpid(pid_t vnr)
 	return find_task_by_pid_ns(vnr, task_active_pid_ns(current));
 }
 
+struct task_struct *find_get_task_by_vpid(pid_t nr)
+{
+	struct task_struct *task;
+
+	rcu_read_lock();
+	task = find_task_by_vpid(nr);
+	if (task)
+		get_task_struct(task);
+	rcu_read_unlock();
+
+	return task;
+}
+
 struct pid *get_task_pid(struct task_struct *task, enum pid_type type)
 {
 	struct pid *pid;

commit 49f9c3552ccc30f4f98c45d94d7f9b335596913f
Merge: d8a5b80568a9 e1e871aff3de
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 29 09:08:34 2018 -0800

    Merge tag 'init_task-20180117' of git://git.kernel.org/pub/scm/linux/kernel/git/dhowells/linux-fs
    
    Pull init_task initializer cleanups from David Howells:
     "It doesn't seem useful to have the init_task in a header file rather
      than in a normal source file. We could consolidate init_task handling
      instead and expand out various macros.
    
      Here's a series of patches that consolidate init_task handling:
    
       (1) Make THREAD_SIZE available to vmlinux.lds for cris, hexagon and
           openrisc.
    
       (2) Alter the INIT_TASK_DATA linker script macro to set
           init_thread_union and init_stack rather than defining these in C.
    
           Insert init_task and init_thread_into into the init_stack area in
           the linker script as appropriate to the configuration, with
           different section markers so that they end up correctly ordered.
    
           We can then get merge ia64's init_task.c into the main one.
    
           We then have a bunch of single-use INIT_*() macros that seem only
           to be macros because they used to be used per-arch. We can then
           expand these in place of the user and get rid of a few lines and
           a lot of backslashes.
    
       (3) Expand INIT_TASK() in place.
    
       (4) Expand in place various small INIT_*() macros that are defined
           conditionally. Expand them and surround them by #if[n]def/#endif
           in the .c file as it takes fewer lines.
    
       (5) Expand INIT_SIGNALS() and INIT_SIGHAND() in place.
    
       (6) Expand INIT_STRUCT_PID in place.
    
      These macros can then be discarded"
    
    * tag 'init_task-20180117' of git://git.kernel.org/pub/scm/linux/kernel/git/dhowells/linux-fs:
      Expand INIT_STRUCT_PID and remove
      Expand the INIT_SIGNALS and INIT_SIGHAND macros and remove
      Expand various INIT_* macros and remove
      Expand INIT_TASK() in init/init_task.c and remove
      Construct init thread stack in the linker script rather than by union
      openrisc: Make THREAD_SIZE available to vmlinux.lds
      hexagon: Make THREAD_SIZE available to vmlinux.lds
      cris: Make THREAD_SIZE available to vmlinux.lds

commit e1e871aff3ded26348c631b1370e257d401cd22d
Author: David Howells <dhowells@redhat.com>
Date:   Tue Jan 2 15:12:01 2018 +0000

    Expand INIT_STRUCT_PID and remove
    
    Expand INIT_STRUCT_PID in the single place that uses it and then remove it.
    There doesn't seem any point in the macro.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Tested-by: Tony Luck <tony.luck@intel.com>
    Tested-by: Will Deacon <will.deacon@arm.com> (arm64)
    Tested-by: Palmer Dabbelt <palmer@sifive.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/pid.c b/kernel/pid.c
index b13b624e2c49..161af2eda943 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -41,7 +41,19 @@
 #include <linux/sched/task.h>
 #include <linux/idr.h>
 
-struct pid init_struct_pid = INIT_STRUCT_PID;
+struct pid init_struct_pid = {
+	.count 		= ATOMIC_INIT(1),
+	.tasks		= {
+		{ .first = NULL },
+		{ .first = NULL },
+		{ .first = NULL },
+	},
+	.level		= 0,
+	.numbers	= { {
+		.nr		= 0,
+		.ns		= &init_pid_ns,
+	}, }
+};
 
 int pid_max = PID_MAX_DEFAULT;
 

commit c0ee554906c3d6554fbddf95ae664cd9f817082b
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Dec 22 12:37:43 2017 -0600

    pid: Handle failure to allocate the first pid in a pid namespace
    
    With the replacement of the pid bitmap and hashtable with an idr in
    alloc_pid started occassionally failing when allocating the first pid
    in a pid namespace.  Things were not completely reset resulting in
    the first allocated pid getting the number 2 (not 1).  Which
    further resulted in ns->proc_mnt not getting set and eventually
    causing an oops in proc_flush_task.
    
    Oops: 0000 [#1] SMP
    CPU: 2 PID: 6743 Comm: trinity-c117 Not tainted 4.15.0-rc4-think+ #2
    RIP: 0010:proc_flush_task+0x8e/0x1b0
    RSP: 0018:ffffc9000bbffc40 EFLAGS: 00010286
    RAX: 0000000000000001 RBX: 0000000000000001 RCX: 00000000fffffffb
    RDX: 0000000000000000 RSI: ffffc9000bbffc50 RDI: 0000000000000000
    RBP: ffffc9000bbffc63 R08: 0000000000000000 R09: 0000000000000002
    R10: ffffc9000bbffb70 R11: ffffc9000bbffc64 R12: 0000000000000003
    R13: 0000000000000000 R14: 0000000000000003 R15: ffff8804c10d7840
    FS:  00007f7cb8965700(0000) GS:ffff88050a200000(0000) knlGS:0000000000000000
    CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    CR2: 0000000000000000 CR3: 00000003e21ae003 CR4: 00000000001606e0
    DR0: 00007fb1d6c22000 DR1: 0000000000000000 DR2: 0000000000000000
    DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000600
    Call Trace:
     ? release_task+0xaf/0x680
     release_task+0xd2/0x680
     ? wait_consider_task+0xb82/0xce0
     wait_consider_task+0xbe9/0xce0
     ? do_wait+0xe1/0x330
     do_wait+0x151/0x330
     kernel_wait4+0x8d/0x150
     ? task_stopped_code+0x50/0x50
     SYSC_wait4+0x95/0xa0
     ? rcu_read_lock_sched_held+0x6c/0x80
     ? syscall_trace_enter+0x2d7/0x340
     ? do_syscall_64+0x60/0x210
     do_syscall_64+0x60/0x210
     entry_SYSCALL64_slow_path+0x25/0x25
    RIP: 0033:0x7f7cb82603aa
    RSP: 002b:00007ffd60770bc8 EFLAGS: 00000246
     ORIG_RAX: 000000000000003d
    RAX: ffffffffffffffda RBX: 00007f7cb6cd4000 RCX: 00007f7cb82603aa
    RDX: 000000000000000b RSI: 00007ffd60770bd0 RDI: 0000000000007cca
    RBP: 0000000000007cca R08: 00007f7cb8965700 R09: 00007ffd607c7080
    R10: 0000000000000000 R11: 0000000000000246 R12: 0000000000000000
    R13: 00007ffd60770bd0 R14: 00007f7cb6cd4058 R15: 00000000cccccccd
    Code: c1 e2 04 44 8b 60 30 48 8b 40 38 44 8b 34 11 48 c7 c2 60 3a f5 81 44 89 e1 4c 8b 68 58 e8 4b b4 77 00 89 44 24 14 48 8d 74 24 10 <49> 8b 7d 00 e8 b9 6a f9 ff 48 85 c0 74 1a 48 89 c7 48 89 44 24
    RIP: proc_flush_task+0x8e/0x1b0 RSP: ffffc9000bbffc40
    CR2: 0000000000000000
    ---[ end trace 53d67a6481059862 ]---
    
    Improve the quality of the implementation by resetting the place to
    start allocating pids on failure to allocate the first pid.
    
    As improving the quality of the implementation is the goal remove the now
    unnecesarry disable_pid_allocations call when we fail to mount proc.
    
    Fixes: 95846ecf9dac ("pid: replace pid bitmap implementation with IDR API")
    Fixes: 8ef047aaaeb8 ("pid namespaces: make alloc_pid(), free_pid() and put_pid() work with struct upid")
    Reported-by: Dave Jones <davej@codemonkey.org.uk>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index b13b624e2c49..1e8bb6550ec4 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -193,10 +193,8 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	}
 
 	if (unlikely(is_child_reaper(pid))) {
-		if (pid_ns_prepare_proc(ns)) {
-			disable_pid_allocation(ns);
+		if (pid_ns_prepare_proc(ns))
 			goto out_free;
-		}
 	}
 
 	get_pid_ns(ns);
@@ -226,6 +224,10 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	while (++i <= ns->level)
 		idr_remove(&ns->idr, (pid->numbers + i)->nr);
 
+	/* On failure to allocate the first pid, reset the state */
+	if (ns->pid_allocated == PIDNS_ADDING)
+		idr_set_cursor(&ns->idr, 0);
+
 	spin_unlock_irq(&pidmap_lock);
 
 	kmem_cache_free(ns->pid_cachep, pid);

commit e8cfbc245e24887e3c30235f71e9e9405e0cfc39
Author: Gargi Sharma <gs051095@gmail.com>
Date:   Fri Nov 17 15:30:34 2017 -0800

    pid: remove pidhash
    
    pidhash is no longer required as all the information can be looked up
    from idr tree.  nr_hashed represented the number of pids that had been
    hashed.  Since, nr_hashed and PIDNS_HASH_ADDING are no longer relevant,
    it has been renamed to pid_allocated and PIDNS_ADDING respectively.
    
    [gs051095@gmail.com: v6]
      Link: http://lkml.kernel.org/r/1507760379-21662-3-git-send-email-gs051095@gmail.com
    Link: http://lkml.kernel.org/r/1507583624-22146-3-git-send-email-gs051095@gmail.com
    Signed-off-by: Gargi Sharma <gs051095@gmail.com>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Tested-by: Tony Luck <tony.luck@intel.com>      [ia64]
    Cc: Julia Lawall <julia.lawall@lip6.fr>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Pavel Tatashin <pasha.tatashin@oracle.com>
    Cc: Kirill Tkhai <ktkhai@virtuozzo.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 0ce59369632f..b13b624e2c49 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -41,10 +41,6 @@
 #include <linux/sched/task.h>
 #include <linux/idr.h>
 
-#define pid_hashfn(nr, ns)	\
-	hash_long((unsigned long)nr + (unsigned long)ns, pidhash_shift)
-static struct hlist_head *pid_hash;
-static unsigned int pidhash_shift = 4;
 struct pid init_struct_pid = INIT_STRUCT_PID;
 
 int pid_max = PID_MAX_DEFAULT;
@@ -54,7 +50,6 @@ int pid_max = PID_MAX_DEFAULT;
 int pid_max_min = RESERVED_PIDS + 1;
 int pid_max_max = PID_MAX_LIMIT;
 
-
 /*
  * PID-map pages start out as NULL, they get allocated upon
  * first use and are never deallocated. This way a low pid_max
@@ -64,7 +59,7 @@ int pid_max_max = PID_MAX_LIMIT;
 struct pid_namespace init_pid_ns = {
 	.kref = KREF_INIT(2),
 	.idr = IDR_INIT,
-	.nr_hashed = PIDNS_HASH_ADDING,
+	.pid_allocated = PIDNS_ADDING,
 	.level = 0,
 	.child_reaper = &init_task,
 	.user_ns = &init_user_ns,
@@ -123,8 +118,7 @@ void free_pid(struct pid *pid)
 	for (i = 0; i <= pid->level; i++) {
 		struct upid *upid = pid->numbers + i;
 		struct pid_namespace *ns = upid->ns;
-		hlist_del_rcu(&upid->pid_chain);
-		switch (--ns->nr_hashed) {
+		switch (--ns->pid_allocated) {
 		case 2:
 		case 1:
 			/* When all that is left in the pid namespace
@@ -133,10 +127,10 @@ void free_pid(struct pid *pid)
 			 */
 			wake_up_process(ns->child_reaper);
 			break;
-		case PIDNS_HASH_ADDING:
+		case PIDNS_ADDING:
 			/* Handle a fork failure of the first process */
 			WARN_ON(ns->child_reaper);
-			ns->nr_hashed = 0;
+			ns->pid_allocated = 0;
 			/* fall through */
 		case 0:
 			schedule_work(&ns->proc_work);
@@ -212,14 +206,12 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 
 	upid = pid->numbers + ns->level;
 	spin_lock_irq(&pidmap_lock);
-	if (!(ns->nr_hashed & PIDNS_HASH_ADDING))
+	if (!(ns->pid_allocated & PIDNS_ADDING))
 		goto out_unlock;
 	for ( ; upid >= pid->numbers; --upid) {
-		hlist_add_head_rcu(&upid->pid_chain,
-				&pid_hash[pid_hashfn(upid->nr, upid->ns)]);
 		/* Make the PID visible to find_pid_ns. */
 		idr_replace(&upid->ns->idr, pid, upid->nr);
-		upid->ns->nr_hashed++;
+		upid->ns->pid_allocated++;
 	}
 	spin_unlock_irq(&pidmap_lock);
 
@@ -243,21 +235,13 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 void disable_pid_allocation(struct pid_namespace *ns)
 {
 	spin_lock_irq(&pidmap_lock);
-	ns->nr_hashed &= ~PIDNS_HASH_ADDING;
+	ns->pid_allocated &= ~PIDNS_ADDING;
 	spin_unlock_irq(&pidmap_lock);
 }
 
 struct pid *find_pid_ns(int nr, struct pid_namespace *ns)
 {
-	struct upid *pnr;
-
-	hlist_for_each_entry_rcu(pnr,
-			&pid_hash[pid_hashfn(nr, ns)], pid_chain)
-		if (pnr->nr == nr && pnr->ns == ns)
-			return container_of(pnr, struct pid,
-					numbers[ns->level]);
-
-	return NULL;
+	return idr_find(&ns->idr, nr);
 }
 EXPORT_SYMBOL_GPL(find_pid_ns);
 
@@ -413,6 +397,7 @@ pid_t __task_pid_nr_ns(struct task_struct *task, enum pid_type type,
 		if (type != PIDTYPE_PID) {
 			if (type == __PIDTYPE_TGID)
 				type = PIDTYPE_PID;
+
 			task = task->group_leader;
 		}
 		nr = pid_nr_ns(rcu_dereference(task->pids[type].pid), ns);
@@ -439,23 +424,10 @@ struct pid *find_ge_pid(int nr, struct pid_namespace *ns)
 	return idr_get_next(&ns->idr, &nr);
 }
 
-/*
- * The pid hash table is scaled according to the amount of memory in the
- * machine.  From a minimum of 16 slots up to 4096 slots at one gigabyte or
- * more.
- */
-void __init pidhash_init(void)
-{
-	pid_hash = alloc_large_system_hash("PID", sizeof(*pid_hash), 0, 18,
-					   HASH_EARLY | HASH_SMALL | HASH_ZERO,
-					   &pidhash_shift, NULL,
-					   0, 4096);
-}
-
 void __init pid_idr_init(void)
 {
 	/* Verify no one has done anything silly: */
-	BUILD_BUG_ON(PID_MAX_LIMIT >= PIDNS_HASH_ADDING);
+	BUILD_BUG_ON(PID_MAX_LIMIT >= PIDNS_ADDING);
 
 	/* bump default and minimum pid_max based on number of cpus */
 	pid_max = min(pid_max_max, max_t(int, pid_max,

commit 95846ecf9dac5089aed4b144d912225f8ef86ae4
Author: Gargi Sharma <gs051095@gmail.com>
Date:   Fri Nov 17 15:30:30 2017 -0800

    pid: replace pid bitmap implementation with IDR API
    
    Patch series "Replacing PID bitmap implementation with IDR API", v4.
    
    This series replaces kernel bitmap implementation of PID allocation with
    IDR API.  These patches are written to simplify the kernel by replacing
    custom code with calls to generic code.
    
    The following are the stats for pid and pid_namespace object files
    before and after the replacement.  There is a noteworthy change between
    the IDR and bitmap implementation.
    
    Before
       text       data        bss        dec        hex    filename
       8447       3894         64      12405       3075    kernel/pid.o
    After
       text       data        bss        dec        hex    filename
       3397        304          0       3701        e75    kernel/pid.o
    
    Before
       text       data        bss        dec        hex    filename
       5692       1842        192       7726       1e2e    kernel/pid_namespace.o
    After
       text       data        bss        dec        hex    filename
       2854        216         16       3086        c0e    kernel/pid_namespace.o
    
    The following are the stats for ps, pstree and calling readdir on /proc
    for 10,000 processes.
    
    ps:
            With IDR API    With bitmap
    real    0m1.479s        0m2.319s
    user    0m0.070s        0m0.060s
    sys     0m0.289s        0m0.516s
    
    pstree:
            With IDR API    With bitmap
    real    0m1.024s        0m1.794s
    user    0m0.348s        0m0.612s
    sys     0m0.184s        0m0.264s
    
    proc:
            With IDR API    With bitmap
    real    0m0.059s        0m0.074s
    user    0m0.000s        0m0.004s
    sys     0m0.016s        0m0.016s
    
    This patch (of 2):
    
    Replace the current bitmap implementation for Process ID allocation.
    Functions that are no longer required, for example, free_pidmap(),
    alloc_pidmap(), etc.  are removed.  The rest of the functions are
    modified to use the IDR API.  The change was made to make the PID
    allocation less complex by replacing custom code with calls to generic
    API.
    
    [gs051095@gmail.com: v6]
      Link: http://lkml.kernel.org/r/1507760379-21662-2-git-send-email-gs051095@gmail.com
    [avagin@openvz.org: restore the old behaviour of the ns_last_pid sysctl]
      Link: http://lkml.kernel.org/r/20171106183144.16368-1-avagin@openvz.org
    Link: http://lkml.kernel.org/r/1507583624-22146-2-git-send-email-gs051095@gmail.com
    Signed-off-by: Gargi Sharma <gs051095@gmail.com>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Julia Lawall <julia.lawall@lip6.fr>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Pavel Tatashin <pasha.tatashin@oracle.com>
    Cc: Kirill Tkhai <ktkhai@virtuozzo.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 020dedbdf066..0ce59369632f 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -39,6 +39,7 @@
 #include <linux/proc_ns.h>
 #include <linux/proc_fs.h>
 #include <linux/sched/task.h>
+#include <linux/idr.h>
 
 #define pid_hashfn(nr, ns)	\
 	hash_long((unsigned long)nr + (unsigned long)ns, pidhash_shift)
@@ -53,14 +54,6 @@ int pid_max = PID_MAX_DEFAULT;
 int pid_max_min = RESERVED_PIDS + 1;
 int pid_max_max = PID_MAX_LIMIT;
 
-static inline int mk_pid(struct pid_namespace *pid_ns,
-		struct pidmap *map, int off)
-{
-	return (map - pid_ns->pidmap)*BITS_PER_PAGE + off;
-}
-
-#define find_next_offset(map, off)					\
-		find_next_zero_bit((map)->page, BITS_PER_PAGE, off)
 
 /*
  * PID-map pages start out as NULL, they get allocated upon
@@ -70,10 +63,7 @@ static inline int mk_pid(struct pid_namespace *pid_ns,
  */
 struct pid_namespace init_pid_ns = {
 	.kref = KREF_INIT(2),
-	.pidmap = {
-		[ 0 ... PIDMAP_ENTRIES-1] = { ATOMIC_INIT(BITS_PER_PAGE), NULL }
-	},
-	.last_pid = 0,
+	.idr = IDR_INIT,
 	.nr_hashed = PIDNS_HASH_ADDING,
 	.level = 0,
 	.child_reaper = &init_task,
@@ -101,138 +91,6 @@ EXPORT_SYMBOL_GPL(init_pid_ns);
 
 static  __cacheline_aligned_in_smp DEFINE_SPINLOCK(pidmap_lock);
 
-static void free_pidmap(struct upid *upid)
-{
-	int nr = upid->nr;
-	struct pidmap *map = upid->ns->pidmap + nr / BITS_PER_PAGE;
-	int offset = nr & BITS_PER_PAGE_MASK;
-
-	clear_bit(offset, map->page);
-	atomic_inc(&map->nr_free);
-}
-
-/*
- * If we started walking pids at 'base', is 'a' seen before 'b'?
- */
-static int pid_before(int base, int a, int b)
-{
-	/*
-	 * This is the same as saying
-	 *
-	 * (a - base + MAXUINT) % MAXUINT < (b - base + MAXUINT) % MAXUINT
-	 * and that mapping orders 'a' and 'b' with respect to 'base'.
-	 */
-	return (unsigned)(a - base) < (unsigned)(b - base);
-}
-
-/*
- * We might be racing with someone else trying to set pid_ns->last_pid
- * at the pid allocation time (there's also a sysctl for this, but racing
- * with this one is OK, see comment in kernel/pid_namespace.c about it).
- * We want the winner to have the "later" value, because if the
- * "earlier" value prevails, then a pid may get reused immediately.
- *
- * Since pids rollover, it is not sufficient to just pick the bigger
- * value.  We have to consider where we started counting from.
- *
- * 'base' is the value of pid_ns->last_pid that we observed when
- * we started looking for a pid.
- *
- * 'pid' is the pid that we eventually found.
- */
-static void set_last_pid(struct pid_namespace *pid_ns, int base, int pid)
-{
-	int prev;
-	int last_write = base;
-	do {
-		prev = last_write;
-		last_write = cmpxchg(&pid_ns->last_pid, prev, pid);
-	} while ((prev != last_write) && (pid_before(base, last_write, pid)));
-}
-
-static int alloc_pidmap(struct pid_namespace *pid_ns)
-{
-	int i, offset, max_scan, pid, last = pid_ns->last_pid;
-	struct pidmap *map;
-
-	pid = last + 1;
-	if (pid >= pid_max)
-		pid = RESERVED_PIDS;
-	offset = pid & BITS_PER_PAGE_MASK;
-	map = &pid_ns->pidmap[pid/BITS_PER_PAGE];
-	/*
-	 * If last_pid points into the middle of the map->page we
-	 * want to scan this bitmap block twice, the second time
-	 * we start with offset == 0 (or RESERVED_PIDS).
-	 */
-	max_scan = DIV_ROUND_UP(pid_max, BITS_PER_PAGE) - !offset;
-	for (i = 0; i <= max_scan; ++i) {
-		if (unlikely(!map->page)) {
-			void *page = kzalloc(PAGE_SIZE, GFP_KERNEL);
-			/*
-			 * Free the page if someone raced with us
-			 * installing it:
-			 */
-			spin_lock_irq(&pidmap_lock);
-			if (!map->page) {
-				map->page = page;
-				page = NULL;
-			}
-			spin_unlock_irq(&pidmap_lock);
-			kfree(page);
-			if (unlikely(!map->page))
-				return -ENOMEM;
-		}
-		if (likely(atomic_read(&map->nr_free))) {
-			for ( ; ; ) {
-				if (!test_and_set_bit(offset, map->page)) {
-					atomic_dec(&map->nr_free);
-					set_last_pid(pid_ns, last, pid);
-					return pid;
-				}
-				offset = find_next_offset(map, offset);
-				if (offset >= BITS_PER_PAGE)
-					break;
-				pid = mk_pid(pid_ns, map, offset);
-				if (pid >= pid_max)
-					break;
-			}
-		}
-		if (map < &pid_ns->pidmap[(pid_max-1)/BITS_PER_PAGE]) {
-			++map;
-			offset = 0;
-		} else {
-			map = &pid_ns->pidmap[0];
-			offset = RESERVED_PIDS;
-			if (unlikely(last == offset))
-				break;
-		}
-		pid = mk_pid(pid_ns, map, offset);
-	}
-	return -EAGAIN;
-}
-
-int next_pidmap(struct pid_namespace *pid_ns, unsigned int last)
-{
-	int offset;
-	struct pidmap *map, *end;
-
-	if (last >= PID_MAX_LIMIT)
-		return -1;
-
-	offset = (last + 1) & BITS_PER_PAGE_MASK;
-	map = &pid_ns->pidmap[(last + 1)/BITS_PER_PAGE];
-	end = &pid_ns->pidmap[PIDMAP_ENTRIES];
-	for (; map < end; map++, offset = 0) {
-		if (unlikely(!map->page))
-			continue;
-		offset = find_next_bit((map)->page, BITS_PER_PAGE, offset);
-		if (offset < BITS_PER_PAGE)
-			return mk_pid(pid_ns, map, offset);
-	}
-	return -1;
-}
-
 void put_pid(struct pid *pid)
 {
 	struct pid_namespace *ns;
@@ -266,7 +124,7 @@ void free_pid(struct pid *pid)
 		struct upid *upid = pid->numbers + i;
 		struct pid_namespace *ns = upid->ns;
 		hlist_del_rcu(&upid->pid_chain);
-		switch(--ns->nr_hashed) {
+		switch (--ns->nr_hashed) {
 		case 2:
 		case 1:
 			/* When all that is left in the pid namespace
@@ -284,12 +142,11 @@ void free_pid(struct pid *pid)
 			schedule_work(&ns->proc_work);
 			break;
 		}
+
+		idr_remove(&ns->idr, upid->nr);
 	}
 	spin_unlock_irqrestore(&pidmap_lock, flags);
 
-	for (i = 0; i <= pid->level; i++)
-		free_pidmap(pid->numbers + i);
-
 	call_rcu(&pid->rcu, delayed_put_pid);
 }
 
@@ -308,8 +165,29 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 
 	tmp = ns;
 	pid->level = ns->level;
+
 	for (i = ns->level; i >= 0; i--) {
-		nr = alloc_pidmap(tmp);
+		int pid_min = 1;
+
+		idr_preload(GFP_KERNEL);
+		spin_lock_irq(&pidmap_lock);
+
+		/*
+		 * init really needs pid 1, but after reaching the maximum
+		 * wrap back to RESERVED_PIDS
+		 */
+		if (idr_get_cursor(&tmp->idr) > RESERVED_PIDS)
+			pid_min = RESERVED_PIDS;
+
+		/*
+		 * Store a null pointer so find_pid_ns does not find
+		 * a partially initialized PID (see below).
+		 */
+		nr = idr_alloc_cyclic(&tmp->idr, NULL, pid_min,
+				      pid_max, GFP_ATOMIC);
+		spin_unlock_irq(&pidmap_lock);
+		idr_preload_end();
+
 		if (nr < 0) {
 			retval = nr;
 			goto out_free;
@@ -339,6 +217,8 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	for ( ; upid >= pid->numbers; --upid) {
 		hlist_add_head_rcu(&upid->pid_chain,
 				&pid_hash[pid_hashfn(upid->nr, upid->ns)]);
+		/* Make the PID visible to find_pid_ns. */
+		idr_replace(&upid->ns->idr, pid, upid->nr);
 		upid->ns->nr_hashed++;
 	}
 	spin_unlock_irq(&pidmap_lock);
@@ -350,8 +230,11 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	put_pid_ns(ns);
 
 out_free:
+	spin_lock_irq(&pidmap_lock);
 	while (++i <= ns->level)
-		free_pidmap(pid->numbers + i);
+		idr_remove(&ns->idr, (pid->numbers + i)->nr);
+
+	spin_unlock_irq(&pidmap_lock);
 
 	kmem_cache_free(ns->pid_cachep, pid);
 	return ERR_PTR(retval);
@@ -553,16 +436,7 @@ EXPORT_SYMBOL_GPL(task_active_pid_ns);
  */
 struct pid *find_ge_pid(int nr, struct pid_namespace *ns)
 {
-	struct pid *pid;
-
-	do {
-		pid = find_pid_ns(nr, ns);
-		if (pid)
-			break;
-		nr = next_pidmap(ns, nr);
-	} while (nr > 0);
-
-	return pid;
+	return idr_get_next(&ns->idr, &nr);
 }
 
 /*
@@ -578,7 +452,7 @@ void __init pidhash_init(void)
 					   0, 4096);
 }
 
-void __init pidmap_init(void)
+void __init pid_idr_init(void)
 {
 	/* Verify no one has done anything silly: */
 	BUILD_BUG_ON(PID_MAX_LIMIT >= PIDNS_HASH_ADDING);
@@ -590,10 +464,7 @@ void __init pidmap_init(void)
 				PIDS_PER_CPU_MIN * num_possible_cpus());
 	pr_info("pid_max: default: %u minimum: %u\n", pid_max, pid_max_min);
 
-	init_pid_ns.pidmap[0].page = kzalloc(PAGE_SIZE, GFP_KERNEL);
-	/* Reserve PID 0. We never call free_pidmap(0) */
-	set_bit(0, init_pid_ns.pidmap[0].page);
-	atomic_dec(&init_pid_ns.pidmap[0].nr_free);
+	idr_init(&init_pid_ns.idr);
 
 	init_pid_ns.pid_cachep = KMEM_CACHE(pid,
 			SLAB_HWCACHE_ALIGN | SLAB_PANIC | SLAB_ACCOUNT);

commit dd1c1f2f2028a7b851f701fc6a8ebe39dcb95e7c
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Mon Aug 21 17:35:02 2017 +0200

    pids: make task_tgid_nr_ns() safe
    
    This was reported many times, and this was even mentioned in commit
    52ee2dfdd4f5 ("pids: refactor vnr/nr_ns helpers to make them safe") but
    somehow nobody bothered to fix the obvious problem: task_tgid_nr_ns() is
    not safe because task->group_leader points to nowhere after the exiting
    task passes exit_notify(), rcu_read_lock() can not help.
    
    We really need to change __unhash_process() to nullify group_leader,
    parent, and real_parent, but this needs some cleanups.  Until then we
    can turn task_tgid_nr_ns() into another user of __task_pid_nr_ns() and
    fix the problem.
    
    Reported-by: Troy Kensinger <tkensinger@google.com>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index c69c30d827e5..020dedbdf066 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -527,8 +527,11 @@ pid_t __task_pid_nr_ns(struct task_struct *task, enum pid_type type,
 	if (!ns)
 		ns = task_active_pid_ns(current);
 	if (likely(pid_alive(task))) {
-		if (type != PIDTYPE_PID)
+		if (type != PIDTYPE_PID) {
+			if (type == __PIDTYPE_TGID)
+				type = PIDTYPE_PID;
 			task = task->group_leader;
+		}
 		nr = pid_nr_ns(rcu_dereference(task->pids[type].pid), ns);
 	}
 	rcu_read_unlock();
@@ -537,12 +540,6 @@ pid_t __task_pid_nr_ns(struct task_struct *task, enum pid_type type,
 }
 EXPORT_SYMBOL(__task_pid_nr_ns);
 
-pid_t task_tgid_nr_ns(struct task_struct *tsk, struct pid_namespace *ns)
-{
-	return pid_nr_ns(task_tgid(tsk), ns);
-}
-EXPORT_SYMBOL(task_tgid_nr_ns);
-
 struct pid_namespace *task_active_pid_ns(struct task_struct *tsk)
 {
 	return ns_of_pid(task_pid(tsk));

commit 27e37d84e55f47bf28f7072fadf8fa2cbc3d9375
Author: Kefeng Wang <wangkefeng.wang@huawei.com>
Date:   Wed Aug 2 13:31:50 2017 -0700

    pid: kill pidhash_size in pidhash_init()
    
    After commit 3d375d78593c ("mm: update callers to use HASH_ZERO flag"),
    drop unused pidhash_size in pidhash_init().
    
    Link: http://lkml.kernel.org/r/1500389267-49222-1-git-send-email-wangkefeng.wang@huawei.com
    Signed-off-by: Kefeng Wang <wangkefeng.wang@huawei.com>
    Reviewed-by: Pavel Tatashin <Pasha.Tatashin@Oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 731c4e528f4e..c69c30d827e5 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -575,13 +575,10 @@ struct pid *find_ge_pid(int nr, struct pid_namespace *ns)
  */
 void __init pidhash_init(void)
 {
-	unsigned int pidhash_size;
-
 	pid_hash = alloc_large_system_hash("PID", sizeof(*pid_hash), 0, 18,
 					   HASH_EARLY | HASH_SMALL | HASH_ZERO,
 					   &pidhash_shift, NULL,
 					   0, 4096);
-	pidhash_size = 1U << pidhash_shift;
 }
 
 void __init pidmap_init(void)

commit 3d375d78593cd5daeead34ed3279c4ff63dd04f2
Author: Pavel Tatashin <pasha.tatashin@oracle.com>
Date:   Thu Jul 6 15:39:11 2017 -0700

    mm: update callers to use HASH_ZERO flag
    
    Update dcache, inode, pid, mountpoint, and mount hash tables to use
    HASH_ZERO, and remove initialization after allocations.  In case of
    places where HASH_EARLY was used such as in __pv_init_lock_hash the
    zeroed hash table was already assumed, because memblock zeroes the
    memory.
    
    CPU: SPARC M6, Memory: 7T
    Before fix:
      Dentry cache hash table entries: 1073741824
      Inode-cache hash table entries: 536870912
      Mount-cache hash table entries: 16777216
      Mountpoint-cache hash table entries: 16777216
      ftrace: allocating 20414 entries in 40 pages
      Total time: 11.798s
    
    After fix:
      Dentry cache hash table entries: 1073741824
      Inode-cache hash table entries: 536870912
      Mount-cache hash table entries: 16777216
      Mountpoint-cache hash table entries: 16777216
      ftrace: allocating 20414 entries in 40 pages
      Total time: 3.198s
    
    CPU: Intel Xeon E5-2630, Memory: 2.2T:
    Before fix:
      Dentry cache hash table entries: 536870912
      Inode-cache hash table entries: 268435456
      Mount-cache hash table entries: 8388608
      Mountpoint-cache hash table entries: 8388608
      CPU: Physical Processor ID: 0
      Total time: 3.245s
    
    After fix:
      Dentry cache hash table entries: 536870912
      Inode-cache hash table entries: 268435456
      Mount-cache hash table entries: 8388608
      Mountpoint-cache hash table entries: 8388608
      CPU: Physical Processor ID: 0
      Total time: 3.244s
    
    Link: http://lkml.kernel.org/r/1488432825-92126-4-git-send-email-pasha.tatashin@oracle.com
    Signed-off-by: Pavel Tatashin <pasha.tatashin@oracle.com>
    Reviewed-by: Babu Moger <babu.moger@oracle.com>
    Cc: David Miller <davem@davemloft.net>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index fd1cde1e4576..731c4e528f4e 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -575,16 +575,13 @@ struct pid *find_ge_pid(int nr, struct pid_namespace *ns)
  */
 void __init pidhash_init(void)
 {
-	unsigned int i, pidhash_size;
+	unsigned int pidhash_size;
 
 	pid_hash = alloc_large_system_hash("PID", sizeof(*pid_hash), 0, 18,
-					   HASH_EARLY | HASH_SMALL,
+					   HASH_EARLY | HASH_SMALL | HASH_ZERO,
 					   &pidhash_shift, NULL,
 					   0, 4096);
 	pidhash_size = 1U << pidhash_shift;
-
-	for (i = 0; i < pidhash_size; i++)
-		INIT_HLIST_HEAD(&pid_hash[i]);
 }
 
 void __init pidmap_init(void)

commit 8896c23d2ef803f1883fea73117a435925c2b4c4
Author: Kirill Tkhai <ktkhai@virtuozzo.com>
Date:   Mon May 8 15:56:34 2017 -0700

    pidns: disable pid allocation if pid_ns_prepare_proc() is failed in alloc_pid()
    
    alloc_pidmap() advances pid_namespace::last_pid.  When first pid
    allocation fails, then next created process will have pid 2 and
    pid_ns_prepare_proc() won't be called.  So, pid_namespace::proc_mnt will
    never be initialized (not to mention that there won't be a child
    reaper).
    
    I saw crash stack of such case on kernel 3.10:
    
        BUG: unable to handle kernel NULL pointer dereference at (null)
        IP: proc_flush_task+0x8f/0x1b0
        Call Trace:
            release_task+0x3f/0x490
            wait_consider_task.part.10+0x7ff/0xb00
            do_wait+0x11f/0x280
            SyS_wait4+0x7d/0x110
    
    We may fix this by restore of last_pid in 0 or by prohibiting of futher
    allocations.  Since there was a similar issue in Oleg Nesterov's commit
    314a8ad0f18a ("pidns: fix free_pid() to handle the first fork failure").
    and it was fixed via prohibiting allocation, let's follow this way, and
    do the same.
    
    Link: http://lkml.kernel.org/r/149201021004.4863.6762095011554287922.stgit@localhost.localdomain
    Signed-off-by: Kirill Tkhai <ktkhai@virtuozzo.com>
    Acked-by: Cyrill Gorcunov <gorcunov@openvz.org>
    Cc: Andrei Vagin <avagin@virtuozzo.com>
    Cc: Andreas Gruenbacher <agruenba@redhat.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Michael Kerrisk <mtk.manpages@googlemail.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Paul Moore <paul@paul-moore.com>
    Cc: Eric Biederman <ebiederm@xmission.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Serge Hallyn <serge@hallyn.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 0143ac0ddceb..fd1cde1e4576 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -321,8 +321,10 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	}
 
 	if (unlikely(is_child_reaper(pid))) {
-		if (pid_ns_prepare_proc(ns))
+		if (pid_ns_prepare_proc(ns)) {
+			disable_pid_allocation(ns);
 			goto out_free;
+		}
 	}
 
 	get_pid_ns(ns);

commit 299300258d1bc4e997b7db340a2e06636757fe2e
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:36 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/task.h>
    
    We are going to split <linux/sched/task.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/task.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 0291804151b5..0143ac0ddceb 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -38,6 +38,7 @@
 #include <linux/syscalls.h>
 #include <linux/proc_ns.h>
 #include <linux/proc_fs.h>
+#include <linux/sched/task.h>
 
 #define pid_hashfn(nr, ns)	\
 	hash_long((unsigned long)nr + (unsigned long)ns, pidhash_shift)

commit 1e24edca0557dba6486d39d3c24c288475432bcf
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Nov 14 17:12:23 2016 +0100

    locking/atomic, kref: Add KREF_INIT()
    
    Since we need to change the implementation, stop exposing internals.
    
    Provide KREF_INIT() to allow static initialization of struct kref.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index f66162f2359b..0291804151b5 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -68,9 +68,7 @@ static inline int mk_pid(struct pid_namespace *pid_ns,
  * the scheme scales to up to 4 million PIDs, runtime.
  */
 struct pid_namespace init_pid_ns = {
-	.kref = {
-		.refcount       = ATOMIC_INIT(2),
-	},
+	.kref = KREF_INIT(2),
 	.pidmap = {
 		[ 0 ... PIDMAP_ENTRIES-1] = { ATOMIC_INIT(BITS_PER_PAGE), NULL }
 	},

commit 287980e49ffc0f6d911601e7e352a812ed27768e
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Fri May 27 23:23:25 2016 +0200

    remove lots of IS_ERR_VALUE abuses
    
    Most users of IS_ERR_VALUE() in the kernel are wrong, as they
    pass an 'int' into a function that takes an 'unsigned long'
    argument. This happens to work because the type is sign-extended
    on 64-bit architectures before it gets converted into an
    unsigned type.
    
    However, anything that passes an 'unsigned short' or 'unsigned int'
    argument into IS_ERR_VALUE() is guaranteed to be broken, as are
    8-bit integers and types that are wider than 'unsigned long'.
    
    Andrzej Hajda has already fixed a lot of the worst abusers that
    were causing actual bugs, but it would be nice to prevent any
    users that are not passing 'unsigned long' arguments.
    
    This patch changes all users of IS_ERR_VALUE() that I could find
    on 32-bit ARM randconfig builds and x86 allmodconfig. For the
    moment, this doesn't change the definition of IS_ERR_VALUE()
    because there are probably still architecture specific users
    elsewhere.
    
    Almost all the warnings I got are for files that are better off
    using 'if (err)' or 'if (err < 0)'.
    The only legitimate user I could find that we get a warning for
    is the (32-bit only) freescale fman driver, so I did not remove
    the IS_ERR_VALUE() there but changed the type to 'unsigned long'.
    For 9pfs, I just worked around one user whose calling conventions
    are so obscure that I did not dare change the behavior.
    
    I was using this definition for testing:
    
     #define IS_ERR_VALUE(x) ((unsigned long*)NULL == (typeof (x)*)NULL && \
           unlikely((unsigned long long)(x) >= (unsigned long long)(typeof(x))-MAX_ERRNO))
    
    which ends up making all 16-bit or wider types work correctly with
    the most plausible interpretation of what IS_ERR_VALUE() was supposed
    to return according to its users, but also causes a compile-time
    warning for any users that do not pass an 'unsigned long' argument.
    
    I suggested this approach earlier this year, but back then we ended
    up deciding to just fix the users that are obviously broken. After
    the initial warning that caused me to get involved in the discussion
    (fs/gfs2/dir.c) showed up again in the mainline kernel, Linus
    asked me to send the whole thing again.
    
    [ Updated the 9p parts as per Al Viro  - Linus ]
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Cc: Andrzej Hajda <a.hajda@samsung.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Link: https://lkml.org/lkml/2016/1/7/363
    Link: https://lkml.org/lkml/2016/5/27/486
    Acked-by: Srinivas Kandagatla <srinivas.kandagatla@linaro.org> # For nvmem part
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 4d73a834c7e6..f66162f2359b 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -311,7 +311,7 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	pid->level = ns->level;
 	for (i = ns->level; i >= 0; i--) {
 		nr = alloc_pidmap(tmp);
-		if (IS_ERR_VALUE(nr)) {
+		if (nr < 0) {
 			retval = nr;
 			goto out_free;
 		}

commit 7ab85d4a85160ea2ffc96b1255443cbc83be180f
Merge: 29d14f083522 840d6fe7425f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Jan 31 15:44:04 2016 -0800

    Merge branch 'sched-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull scheduler fixes from Thomas Gleixner:
     "Three small fixes in the scheduler/core:
    
       - use after free in the numa code
       - crash in the numa init code
       - a simple spelling fix"
    
    * 'sched-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      pid: Fix spelling in comments
      sched/numa: Fix use-after-free bug in the task_numa_compare
      sched: Fix crash in sched_init_numa()

commit 840d6fe7425ffb6a62d53b2759e01ae6daf90e4e
Author: Zhen Lei <thunder.leizhen@huawei.com>
Date:   Sat Jan 30 10:04:17 2016 +0800

    pid: Fix spelling in comments
    
    Accidentally discovered this typo when I studied this module.
    
    Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
    Cc: Hanjun Guo <guohanjun@huawei.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tianhong Ding <dingtianhong@huawei.com>
    Cc: Xinwei Hu <huxinwei@huawei.com>
    Cc: Zefan Li <lizefan@huawei.com>
    Link: http://lkml.kernel.org/r/1454119457-11272-1-git-send-email-thunder.leizhen@huawei.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 78b3d9f80d44..e793d091f680 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -588,7 +588,7 @@ void __init pidhash_init(void)
 
 void __init pidmap_init(void)
 {
-	/* Veryify no one has done anything silly */
+	/* Verify no one has done anything silly: */
 	BUILD_BUG_ON(PID_MAX_LIMIT >= PIDNS_HASH_ADDING);
 
 	/* bump default and minimum pid_max based on number of cpus */

commit 5d097056c9a017a3b720849efb5432f37acabbac
Author: Vladimir Davydov <vdavydov@virtuozzo.com>
Date:   Thu Jan 14 15:18:21 2016 -0800

    kmemcg: account certain kmem allocations to memcg
    
    Mark those kmem allocations that are known to be easily triggered from
    userspace as __GFP_ACCOUNT/SLAB_ACCOUNT, which makes them accounted to
    memcg.  For the list, see below:
    
     - threadinfo
     - task_struct
     - task_delay_info
     - pid
     - cred
     - mm_struct
     - vm_area_struct and vm_region (nommu)
     - anon_vma and anon_vma_chain
     - signal_struct
     - sighand_struct
     - fs_struct
     - files_struct
     - fdtable and fdtable->full_fds_bits
     - dentry and external_name
     - inode for all filesystems. This is the most tedious part, because
       most filesystems overwrite the alloc_inode method.
    
    The list is far from complete, so feel free to add more objects.
    Nevertheless, it should be close to "account everything" approach and
    keep most workloads within bounds.  Malevolent users will be able to
    breach the limit, but this was possible even with the former "account
    everything" approach (simply because it did not account everything in
    fact).
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Vladimir Davydov <vdavydov@virtuozzo.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Greg Thelen <gthelen@google.com>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: Pekka Enberg <penberg@kernel.org>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 78b3d9f80d44..f4ad91b746f1 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -604,5 +604,5 @@ void __init pidmap_init(void)
 	atomic_dec(&init_pid_ns.pidmap[0].nr_free);
 
 	init_pid_ns.pid_cachep = KMEM_CACHE(pid,
-			SLAB_HWCACHE_ALIGN | SLAB_PANIC);
+			SLAB_HWCACHE_ALIGN | SLAB_PANIC | SLAB_ACCOUNT);
 }

commit 81b1a832d79749058863cffe2c0ed4ef40f6e6ec
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Nov 24 11:39:54 2015 -0800

    pidns: fix NULL dereference in __task_pid_nr_ns()
    
    I got a crash during a "perf top" session that was caused by a race in
    __task_pid_nr_ns() :
    
    pid_nr_ns() was inlined, but apparently compiler chose to read
    task->pids[type].pid twice, and the pid->level dereference crashed
    because we got a NULL pointer at the second read :
    
        if (pid && ns->level <= pid->level) { // CRASH
    
    Just use RCU API properly to solve this race, and not worry about "perf
    top" crashing hosts :(
    
    get_task_pid() can benefit from same fix.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index ca368793808e..78b3d9f80d44 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -467,7 +467,7 @@ struct pid *get_task_pid(struct task_struct *task, enum pid_type type)
 	rcu_read_lock();
 	if (type != PIDTYPE_PID)
 		task = task->group_leader;
-	pid = get_pid(task->pids[type].pid);
+	pid = get_pid(rcu_dereference(task->pids[type].pid));
 	rcu_read_unlock();
 	return pid;
 }
@@ -528,7 +528,7 @@ pid_t __task_pid_nr_ns(struct task_struct *task, enum pid_type type,
 	if (likely(pid_alive(task))) {
 		if (type != PIDTYPE_PID)
 			task = task->group_leader;
-		nr = pid_nr_ns(task->pids[type].pid, ns);
+		nr = pid_nr_ns(rcu_dereference(task->pids[type].pid), ns);
 	}
 	rcu_read_unlock();
 

commit f78f5b90c4ffa559e400c3919a02236101f29f3f
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu Jun 18 15:50:02 2015 -0700

    rcu: Rename rcu_lockdep_assert() to RCU_LOCKDEP_WARN()
    
    This commit renames rcu_lockdep_assert() to RCU_LOCKDEP_WARN() for
    consistency with the WARN() series of macros.  This also requires
    inverting the sense of the conditional, which this commit also does.
    
    Reported-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 4fd07d5b7baf..ca368793808e 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -451,9 +451,8 @@ EXPORT_SYMBOL(pid_task);
  */
 struct task_struct *find_task_by_pid_ns(pid_t nr, struct pid_namespace *ns)
 {
-	rcu_lockdep_assert(rcu_read_lock_held(),
-			   "find_task_by_pid_ns() needs rcu_read_lock()"
-			   " protection");
+	RCU_LOCKDEP_WARN(!rcu_read_lock_held(),
+			 "find_task_by_pid_ns() needs rcu_read_lock() protection");
 	return pid_task(find_pid_ns(nr, ns), PIDTYPE_PID);
 }
 

commit 35f71bc0a09a45924bed268d8ccd0d3407bc476f
Author: Michal Hocko <mhocko@suse.cz>
Date:   Thu Apr 16 12:47:38 2015 -0700

    fork: report pid reservation failure properly
    
    copy_process will report any failure in alloc_pid as ENOMEM currently
    which is misleading because the pid allocation might fail not only when
    the memory is short but also when the pid space is consumed already.
    
    The current man page even mentions this case:
    
    : EAGAIN
    :
    :       A system-imposed limit on the number of threads was encountered.
    :       There are a number of limits that may trigger this error: the
    :       RLIMIT_NPROC soft resource limit (set via setrlimit(2)), which
    :       limits the number of processes and threads for a real user ID, was
    :       reached; the kernel's system-wide limit on the number of processes
    :       and threads, /proc/sys/kernel/threads-max, was reached (see
    :       proc(5)); or the maximum number of PIDs, /proc/sys/kernel/pid_max,
    :       was reached (see proc(5)).
    
    so the current behavior is also incorrect wrt.  documentation.  POSIX man
    page also suggest returing EAGAIN when the process count limit is reached.
    
    This patch simply propagates error code from alloc_pid and makes sure we
    return -EAGAIN due to reservation failure.  This will make behavior of
    fork closer to both our documentation and POSIX.
    
    alloc_pid might alsoo fail when the reaper in the pid namespace is dead
    (the namespace basically disallows all new processes) and there is no
    good error code which would match documented ones. We have traditionally
    returned ENOMEM for this case which is misleading as well but as per
    Eric W. Biederman this behavior is documented in man pid_namespaces(7)
    
    : If the "init" process of a PID namespace terminates, the kernel
    : terminates all of the processes in the namespace via a SIGKILL signal.
    : This behavior reflects the fact that the "init" process is essential for
    : the correct operation of a PID namespace.  In this case, a subsequent
    : fork(2) into this PID namespace will fail with the error ENOMEM; it is
    : not possible to create a new processes in a PID namespace whose "init"
    : process has terminated.
    
    and introducing a new error code would be too risky so let's stick to
    ENOMEM for this case.
    
    Signed-off-by: Michal Hocko <mhocko@suse.cz>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index cd36a5e0d173..4fd07d5b7baf 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -182,7 +182,7 @@ static int alloc_pidmap(struct pid_namespace *pid_ns)
 			spin_unlock_irq(&pidmap_lock);
 			kfree(page);
 			if (unlikely(!map->page))
-				break;
+				return -ENOMEM;
 		}
 		if (likely(atomic_read(&map->nr_free))) {
 			for ( ; ; ) {
@@ -210,7 +210,7 @@ static int alloc_pidmap(struct pid_namespace *pid_ns)
 		}
 		pid = mk_pid(pid_ns, map, offset);
 	}
-	return -1;
+	return -EAGAIN;
 }
 
 int next_pidmap(struct pid_namespace *pid_ns, unsigned int last)
@@ -301,17 +301,20 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	int i, nr;
 	struct pid_namespace *tmp;
 	struct upid *upid;
+	int retval = -ENOMEM;
 
 	pid = kmem_cache_alloc(ns->pid_cachep, GFP_KERNEL);
 	if (!pid)
-		goto out;
+		return ERR_PTR(retval);
 
 	tmp = ns;
 	pid->level = ns->level;
 	for (i = ns->level; i >= 0; i--) {
 		nr = alloc_pidmap(tmp);
-		if (nr < 0)
+		if (IS_ERR_VALUE(nr)) {
+			retval = nr;
 			goto out_free;
+		}
 
 		pid->numbers[i].nr = nr;
 		pid->numbers[i].ns = tmp;
@@ -339,7 +342,6 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	}
 	spin_unlock_irq(&pidmap_lock);
 
-out:
 	return pid;
 
 out_unlock:
@@ -351,8 +353,7 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 		free_pidmap(pid->numbers + i);
 
 	kmem_cache_free(ns->pid_cachep, pid);
-	pid = NULL;
-	goto out;
+	return ERR_PTR(retval);
 }
 
 void disable_pid_allocation(struct pid_namespace *ns)

commit 603ba7e41bf5d405aba22294af5d075d8898176d
Merge: 31f48fc8f226 93fe74b2e2b5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 16 15:53:03 2014 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs pile #2 from Al Viro:
     "Next pile (and there'll be one or two more).
    
      The large piece in this one is getting rid of /proc/*/ns/* weirdness;
      among other things, it allows to (finally) make nameidata completely
      opaque outside of fs/namei.c, making for easier further cleanups in
      there"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      coda_venus_readdir(): use file_inode()
      fs/namei.c: fold link_path_walk() call into path_init()
      path_init(): don't bother with LOOKUP_PARENT in argument
      fs/namei.c: new helper (path_cleanup())
      path_init(): store the "base" pointer to file in nameidata itself
      make default ->i_fop have ->open() fail with ENXIO
      make nameidata completely opaque outside of fs/namei.c
      kill proc_ns completely
      take the targets of /proc/*/ns/* symlinks to separate fs
      bury struct proc_ns in fs/proc
      copy address of proc_ns_ops into ns_common
      new helpers: ns_alloc_inum/ns_free_inum
      make proc_ns_operations work with struct ns_common * instead of void *
      switch the rest of proc_ns_operations to working with &...->ns
      netns: switch ->get()/->put()/->install()/->inum() to working with &net->ns
      make mntns ->get()/->put()/->install()/->inum() work with &mnt_ns->ns
      common object embedded into various struct ....ns

commit 24c037ebf5723d4d9ab0996433cee4f96c292a4d
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Dec 10 15:55:25 2014 -0800

    exit: pidns: alloc_pid() leaks pid_namespace if child_reaper is exiting
    
    alloc_pid() does get_pid_ns() beforehand but forgets to put_pid_ns() if it
    fails because disable_pid_allocation() was called by the exiting
    child_reaper.
    
    We could simply move get_pid_ns() down to successful return, but this fix
    tries to be as trivial as possible.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Aaron Tomlin <atomlin@redhat.com>
    Cc: Pavel Emelyanov <xemul@parallels.com>
    Cc: Serge Hallyn <serge.hallyn@ubuntu.com>
    Cc: Sterling Alexander <stalexan@redhat.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 9b9a26698144..82430c858d69 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -341,6 +341,8 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 
 out_unlock:
 	spin_unlock_irq(&pidmap_lock);
+	put_pid_ns(ns);
+
 out_free:
 	while (++i <= ns->level)
 		free_pidmap(pid->numbers + i);

commit 33c429405a2c8d9e42afb9fee88a63cfb2de1e98
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Nov 1 02:32:53 2014 -0400

    copy address of proc_ns_ops into ns_common
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/pid.c b/kernel/pid.c
index 3650698cf1dc..c17a993a4d2a 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -80,6 +80,9 @@ struct pid_namespace init_pid_ns = {
 	.child_reaper = &init_task,
 	.user_ns = &init_user_ns,
 	.ns.inum = PROC_PID_INIT_INO,
+#ifdef CONFIG_PID_NS
+	.ns.ops = &pidns_operations,
+#endif
 };
 EXPORT_SYMBOL_GPL(init_pid_ns);
 

commit 435d5f4bb2ccba3b791d9ef61d2590e30b8e806e
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Oct 31 22:56:04 2014 -0400

    common object embedded into various struct ....ns
    
    for now - just move corresponding ->proc_inum instances over there
    
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/pid.c b/kernel/pid.c
index 9b9a26698144..3650698cf1dc 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -79,7 +79,7 @@ struct pid_namespace init_pid_ns = {
 	.level = 0,
 	.child_reaper = &init_task,
 	.user_ns = &init_user_ns,
-	.proc_inum = PROC_PID_INIT_INO,
+	.ns.inum = PROC_PID_INIT_INO,
 };
 EXPORT_SYMBOL_GPL(init_pid_ns);
 

commit 314a8ad0f18ac37887896b288939acd8cb17e208
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Mon Sep 30 13:45:27 2013 -0700

    pidns: fix free_pid() to handle the first fork failure
    
    "case 0" in free_pid() assumes that disable_pid_allocation() should
    clear PIDNS_HASH_ADDING before the last pid goes away.
    
    However this doesn't happen if the first fork() fails to create the
    child reaper which should call disable_pid_allocation().
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: "Serge E. Hallyn" <serge@hallyn.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index ebe5e80b10f8..9b9a26698144 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -273,6 +273,11 @@ void free_pid(struct pid *pid)
 			 */
 			wake_up_process(ns->child_reaper);
 			break;
+		case PIDNS_HASH_ADDING:
+			/* Handle a fork failure of the first process */
+			WARN_ON(ns->child_reaper);
+			ns->nr_hashed = 0;
+			/* fall through */
 		case 0:
 			schedule_work(&ns->proc_work);
 			break;

commit a606488513543312805fab2b93070cefe6a3016c
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Aug 29 13:56:50 2013 -0700

    pidns: Fix hang in zap_pid_ns_processes by sending a potentially extra wakeup
    
    Serge Hallyn <serge.hallyn@ubuntu.com> writes:
    
    > Since commit af4b8a83add95ef40716401395b44a1b579965f4 it's been
    > possible to get into a situation where a pidns reaper is
    > <defunct>, reparented to host pid 1, but never reaped.  How to
    > reproduce this is documented at
    >
    > https://bugs.launchpad.net/ubuntu/+source/lxc/+bug/1168526
    > (and see
    > https://bugs.launchpad.net/ubuntu/+source/lxc/+bug/1168526/comments/13)
    > In short, run repeated starts of a container whose init is
    >
    > Process.exit(0);
    >
    > sysrq-t when such a task is playing zombie shows:
    >
    > [  131.132978] init            x ffff88011fc14580     0  2084   2039 0x00000000
    > [  131.132978]  ffff880116e89ea8 0000000000000002 ffff880116e89fd8 0000000000014580
    > [  131.132978]  ffff880116e89fd8 0000000000014580 ffff8801172a0000 ffff8801172a0000
    > [  131.132978]  ffff8801172a0630 ffff88011729fff0 ffff880116e14650 ffff88011729fff0
    > [  131.132978] Call Trace:
    > [  131.132978]  [<ffffffff816f6159>] schedule+0x29/0x70
    > [  131.132978]  [<ffffffff81064591>] do_exit+0x6e1/0xa40
    > [  131.132978]  [<ffffffff81071eae>] ? signal_wake_up_state+0x1e/0x30
    > [  131.132978]  [<ffffffff8106496f>] do_group_exit+0x3f/0xa0
    > [  131.132978]  [<ffffffff810649e4>] SyS_exit_group+0x14/0x20
    > [  131.132978]  [<ffffffff8170102f>] tracesys+0xe1/0xe6
    >
    > Further debugging showed that every time this happened, zap_pid_ns_processes()
    > started with nr_hashed being 3, while we were expecting it to drop to 2.
    > Any time it didn't happen, nr_hashed was 1 or 2.  So the reaper was
    > waiting for nr_hashed to become 2, but free_pid() only wakes the reaper
    > if nr_hashed hits 1.
    
    The issue is that when the task group leader of an init process exits
    before other tasks of the init process when the init process finally
    exits it will be a secondary task sleeping in zap_pid_ns_processes and
    waiting to wake up when the number of hashed pids drops to two.  This
    case waits forever as free_pid only sends a wake up when the number of
    hashed pids drops to 1.
    
    To correct this the simple strategy of sending a possibly unncessary
    wake up when the number of hashed pids drops to 2 is adopted.
    
    Sending one extraneous wake up is relatively harmless, at worst we
    waste a little cpu time in the rare case when a pid namespace
    appropaches exiting.
    
    We can detect the case when the pid namespace drops to just two pids
    hashed race free in free_pid.
    
    Dereferencing pid_ns->child_reaper with the pidmap_lock held is safe
    without out the tasklist_lock because it is guaranteed that the
    detach_pid will be called on the child_reaper before it is freed and
    detach_pid calls __change_pid which calls free_pid which takes the
    pidmap_lock.  __change_pid only calls free_pid if this is the
    last use of the pid.  For a thread that is not the thread group leader
    the threads pid will only ever have one user because a threads pid
    is not allowed to be the pid of a process, of a process group or
    a session.  For a thread that is a thread group leader all of
    the other threads of that process will be reaped before it is allowed
    for the thread group leader to be reaped ensuring there will only
    be one user of the threads pid as a process pid.  Furthermore
    because the thread is the init process of a pid namespace all of the
    other processes in the pid namespace will have also been already freed
    leading to the fact that the pid will not be used as a session pid or
    a process group pid for any other running process.
    
    CC: stable@vger.kernel.org
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Tested-by: Serge Hallyn <serge.hallyn@canonical.com>
    Reported-by: Serge Hallyn <serge.hallyn@ubuntu.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index 66505c1dfc51..ebe5e80b10f8 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -265,6 +265,7 @@ void free_pid(struct pid *pid)
 		struct pid_namespace *ns = upid->ns;
 		hlist_del_rcu(&upid->pid_chain);
 		switch(--ns->nr_hashed) {
+		case 2:
 		case 1:
 			/* When all that is left in the pid namespace
 			 * is the reaper wake up the reaper.  The reaper

commit 8f75af44eed0c81f818b5b345023cebfe5209400
Author: Raphael S. Carvalho <raphael.scarv@gmail.com>
Date:   Wed Jul 3 15:09:02 2013 -0700

    kernel/pid.c: move statement
    
    Move statement to static initilization of init_pid_ns.
    
    Signed-off-by: Raphael S. Carvalho <raphael.scarv@gmail.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 61980cefb1f5..66505c1dfc51 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -75,6 +75,7 @@ struct pid_namespace init_pid_ns = {
 		[ 0 ... PIDMAP_ENTRIES-1] = { ATOMIC_INIT(BITS_PER_PAGE), NULL }
 	},
 	.last_pid = 0,
+	.nr_hashed = PIDNS_HASH_ADDING,
 	.level = 0,
 	.child_reaper = &init_task,
 	.user_ns = &init_user_ns,
@@ -590,7 +591,6 @@ void __init pidmap_init(void)
 	/* Reserve PID 0. We never call free_pidmap(0) */
 	set_bit(0, init_pid_ns.pidmap[0].page);
 	atomic_dec(&init_pid_ns.pidmap[0].nr_free);
-	init_pid_ns.nr_hashed = PIDNS_HASH_ADDING;
 
 	init_pid_ns.pid_cachep = KMEM_CACHE(pid,
 			SLAB_HWCACHE_ALIGN | SLAB_PANIC);

commit 8190773985141f063e1d6dc10200527c655abfb5
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Jul 3 15:08:31 2013 -0700

    kernel/fork.c:copy_process(): don't add the uninitialized child to thread/task/pid lists
    
    copy_process() adds the new child to thread_group/init_task.tasks list and
    then does attach_pid(child, PIDTYPE_PID).  This means that the lockless
    next_thread() or next_task() can see this thread with the wrong pid.  Say,
    "ls /proc/pid/task" can list the same inode twice.
    
    We could move attach_pid(child, PIDTYPE_PID) up, but in this case
    find_task_by_vpid() can find the new thread before it was fully
    initialized.
    
    And this is already true for PIDTYPE_PGID/PIDTYPE_SID, With this patch
    copy_process() initializes child->pids[*].pid first, then calls
    attach_pid() to insert the task into the pid->tasks list.
    
    attach_pid() no longer need the "struct pid*" argument, it is always
    called after pid_link->pid was already set.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Pavel Emelyanov <xemul@parallels.com>
    Cc: Sergey Dyasly <dserrg@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 0db3e791a06d..61980cefb1f5 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -373,14 +373,10 @@ EXPORT_SYMBOL_GPL(find_vpid);
 /*
  * attach_pid() must be called with the tasklist_lock write-held.
  */
-void attach_pid(struct task_struct *task, enum pid_type type,
-		struct pid *pid)
+void attach_pid(struct task_struct *task, enum pid_type type)
 {
-	struct pid_link *link;
-
-	link = &task->pids[type];
-	link->pid = pid;
-	hlist_add_head_rcu(&link->node, &pid->tasks[type]);
+	struct pid_link *link = &task->pids[type];
+	hlist_add_head_rcu(&link->node, &link->pid->tasks[type]);
 }
 
 static void __change_pid(struct task_struct *task, enum pid_type type,
@@ -412,7 +408,7 @@ void change_pid(struct task_struct *task, enum pid_type type,
 		struct pid *pid)
 {
 	__change_pid(task, type, pid);
-	attach_pid(task, type, pid);
+	attach_pid(task, type);
 }
 
 /* transfer_pid is an optimization of attach_pid(new), detach_pid(old) */

commit 20b4fb485227404329e41ad15588afad3df23050
Merge: b9394d8a657c ac3e3c5b1164
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 1 17:51:54 2013 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull VFS updates from Al Viro,
    
    Misc cleanups all over the place, mainly wrt /proc interfaces (switch
    create_proc_entry to proc_create(), get rid of the deprecated
    create_proc_read_entry() in favor of using proc_create_data() and
    seq_file etc).
    
    7kloc removed.
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (204 commits)
      don't bother with deferred freeing of fdtables
      proc: Move non-public stuff from linux/proc_fs.h to fs/proc/internal.h
      proc: Make the PROC_I() and PDE() macros internal to procfs
      proc: Supply a function to remove a proc entry by PDE
      take cgroup_open() and cpuset_open() to fs/proc/base.c
      ppc: Clean up scanlog
      ppc: Clean up rtas_flash driver somewhat
      hostap: proc: Use remove_proc_subtree()
      drm: proc: Use remove_proc_subtree()
      drm: proc: Use minor->index to label things, not PDE->name
      drm: Constify drm_proc_list[]
      zoran: Don't print proc_dir_entry data in debug
      reiserfs: Don't access the proc_dir_entry in r_open(), r_start() r_show()
      proc: Supply an accessor for getting the data from a PDE's parent
      airo: Use remove_proc_subtree()
      rtl8192u: Don't need to save device proc dir PDE
      rtl8187se: Use a dir under /proc/net/r8180/
      proc: Add proc_mkdir_data()
      proc: Move some bits from linux/proc_fs.h to linux/{of.h,signal.h,tty.h}
      proc: Move PDE_NET() to fs/proc/proc_net.c
      ...

commit 0bb80f240520c4148b623161e7856858c021696d
Author: David Howells <dhowells@redhat.com>
Date:   Fri Apr 12 01:50:06 2013 +0100

    proc: Split the namespace stuff out into linux/proc_ns.h
    
    Split the proc namespace stuff out into linux/proc_ns.h.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    cc: netdev@vger.kernel.org
    cc: Serge E. Hallyn <serge.hallyn@ubuntu.com>
    cc: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/pid.c b/kernel/pid.c
index 047dc6264638..686255e2c39e 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -36,6 +36,7 @@
 #include <linux/pid_namespace.h>
 #include <linux/init_task.h>
 #include <linux/syscalls.h>
+#include <linux/proc_ns.h>
 #include <linux/proc_fs.h>
 
 #define pid_hashfn(nr, ns)	\

commit 5cc5445164c16d32bab2912fac28356ab07aa8b4
Author: Raphael S.Carvalho <raphael.scarv@gmail.com>
Date:   Tue Apr 30 15:28:27 2013 -0700

    pid_namespace.c/.h: simplify defines
    
    Move BITS_PER_PAGE from pid_namespace.c to pid_namespace.h, since we can
    simplify the define PID_MAP_ENTRIES by using the BITS_PER_PAGE.
    
    [akpm@linux-foundation.org: kernel/pid.c:54:1: warning: "BITS_PER_PAGE" redefined]
    Signed-off-by: Raphael S.Carvalho <raphael.scarv@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 8147bdf22f36..6283d6412aff 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -51,9 +51,6 @@ int pid_max = PID_MAX_DEFAULT;
 int pid_max_min = RESERVED_PIDS + 1;
 int pid_max_max = PID_MAX_LIMIT;
 
-#define BITS_PER_PAGE		(PAGE_SIZE*8)
-#define BITS_PER_PAGE_MASK	(BITS_PER_PAGE-1)
-
 static inline int mk_pid(struct pid_namespace *pid_ns,
 		struct pidmap *map, int off)
 {

commit 8db049b3d666b3676ff4a976e03c14de302bf9fa
Author: Raphael S. Carvalho <raphael.scarv@gmail.com>
Date:   Tue Apr 30 15:28:26 2013 -0700

    kernel/pid.c: improve flow of a loop inside alloc_pidmap.
    
    find_next_offset() searches for an available "cleaned bit" in the
    respective pid bitmap (page), so returns the offset if found, otherwise
    it returns a value equals to BITS_PER_PAGE.
    
    For example, suppose find_next_offset didn't find any available bit, so
    there's no purpose to call mk_pid (Wasteful Cpu Cycles).
    
    Therefore, I found it could be better to call mk_pid after the checking
    (offset < BITS_PER_PAGE) returned sucessfully! Another point: If (offset
    < BITS_PER_PAGE) results in a "failure", then mk_pid would be called
    again afterwards.
    
    [akpm@linux-foundation.org: simplify code]
    Signed-off-by: Raphael S. Carvalho <raphael.scarv@gmail.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Serge Hallyn <serge.hallyn@canonical.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 047dc6264638..8147bdf22f36 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -183,15 +183,19 @@ static int alloc_pidmap(struct pid_namespace *pid_ns)
 				break;
 		}
 		if (likely(atomic_read(&map->nr_free))) {
-			do {
+			for ( ; ; ) {
 				if (!test_and_set_bit(offset, map->page)) {
 					atomic_dec(&map->nr_free);
 					set_last_pid(pid_ns, last, pid);
 					return pid;
 				}
 				offset = find_next_offset(map, offset);
+				if (offset >= BITS_PER_PAGE)
+					break;
 				pid = mk_pid(pid_ns, map, offset);
-			} while (offset < BITS_PER_PAGE && pid < pid_max);
+				if (pid >= pid_max)
+					break;
+			}
 		}
 		if (map < &pid_ns->pidmap[(pid_max-1)/BITS_PER_PAGE]) {
 			++map;

commit b67bfe0d42cac56c512dd5da4b1b347a23f4b70a
Author: Sasha Levin <sasha.levin@oracle.com>
Date:   Wed Feb 27 17:06:00 2013 -0800

    hlist: drop the node parameter from iterators
    
    I'm not sure why, but the hlist for each entry iterators were conceived
    
            list_for_each_entry(pos, head, member)
    
    The hlist ones were greedy and wanted an extra parameter:
    
            hlist_for_each_entry(tpos, pos, head, member)
    
    Why did they need an extra pos parameter? I'm not quite sure. Not only
    they don't really need it, it also prevents the iterator from looking
    exactly like the list iterator, which is unfortunate.
    
    Besides the semantic patch, there was some manual work required:
    
     - Fix up the actual hlist iterators in linux/list.h
     - Fix up the declaration of other iterators based on the hlist ones.
     - A very small amount of places were using the 'node' parameter, this
     was modified to use 'obj->member' instead.
     - Coccinelle didn't handle the hlist_for_each_entry_safe iterator
     properly, so those had to be fixed up manually.
    
    The semantic patch which is mostly the work of Peter Senna Tschudin is here:
    
    @@
    iterator name hlist_for_each_entry, hlist_for_each_entry_continue, hlist_for_each_entry_from, hlist_for_each_entry_rcu, hlist_for_each_entry_rcu_bh, hlist_for_each_entry_continue_rcu_bh, for_each_busy_worker, ax25_uid_for_each, ax25_for_each, inet_bind_bucket_for_each, sctp_for_each_hentry, sk_for_each, sk_for_each_rcu, sk_for_each_from, sk_for_each_safe, sk_for_each_bound, hlist_for_each_entry_safe, hlist_for_each_entry_continue_rcu, nr_neigh_for_each, nr_neigh_for_each_safe, nr_node_for_each, nr_node_for_each_safe, for_each_gfn_indirect_valid_sp, for_each_gfn_sp, for_each_host;
    
    type T;
    expression a,c,d,e;
    identifier b;
    statement S;
    @@
    
    -T b;
        <+... when != b
    (
    hlist_for_each_entry(a,
    - b,
    c, d) S
    |
    hlist_for_each_entry_continue(a,
    - b,
    c) S
    |
    hlist_for_each_entry_from(a,
    - b,
    c) S
    |
    hlist_for_each_entry_rcu(a,
    - b,
    c, d) S
    |
    hlist_for_each_entry_rcu_bh(a,
    - b,
    c, d) S
    |
    hlist_for_each_entry_continue_rcu_bh(a,
    - b,
    c) S
    |
    for_each_busy_worker(a, c,
    - b,
    d) S
    |
    ax25_uid_for_each(a,
    - b,
    c) S
    |
    ax25_for_each(a,
    - b,
    c) S
    |
    inet_bind_bucket_for_each(a,
    - b,
    c) S
    |
    sctp_for_each_hentry(a,
    - b,
    c) S
    |
    sk_for_each(a,
    - b,
    c) S
    |
    sk_for_each_rcu(a,
    - b,
    c) S
    |
    sk_for_each_from
    -(a, b)
    +(a)
    S
    + sk_for_each_from(a) S
    |
    sk_for_each_safe(a,
    - b,
    c, d) S
    |
    sk_for_each_bound(a,
    - b,
    c) S
    |
    hlist_for_each_entry_safe(a,
    - b,
    c, d, e) S
    |
    hlist_for_each_entry_continue_rcu(a,
    - b,
    c) S
    |
    nr_neigh_for_each(a,
    - b,
    c) S
    |
    nr_neigh_for_each_safe(a,
    - b,
    c, d) S
    |
    nr_node_for_each(a,
    - b,
    c) S
    |
    nr_node_for_each_safe(a,
    - b,
    c, d) S
    |
    - for_each_gfn_sp(a, c, d, b) S
    + for_each_gfn_sp(a, c, d) S
    |
    - for_each_gfn_indirect_valid_sp(a, c, d, b) S
    + for_each_gfn_indirect_valid_sp(a, c, d) S
    |
    for_each_host(a,
    - b,
    c) S
    |
    for_each_host_safe(a,
    - b,
    c, d) S
    |
    for_each_mesh_entry(a,
    - b,
    c, d) S
    )
        ...+>
    
    [akpm@linux-foundation.org: drop bogus change from net/ipv4/raw.c]
    [akpm@linux-foundation.org: drop bogus hunk from net/ipv6/raw.c]
    [akpm@linux-foundation.org: checkpatch fixes]
    [akpm@linux-foundation.org: fix warnings]
    [akpm@linux-foudnation.org: redo intrusive kvm changes]
    Tested-by: Peter Senna Tschudin <peter.senna@gmail.com>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Sasha Levin <sasha.levin@oracle.com>
    Cc: Wu Fengguang <fengguang.wu@intel.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: Gleb Natapov <gleb@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index f2c6a6825098..047dc6264638 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -350,10 +350,9 @@ void disable_pid_allocation(struct pid_namespace *ns)
 
 struct pid *find_pid_ns(int nr, struct pid_namespace *ns)
 {
-	struct hlist_node *elem;
 	struct upid *pnr;
 
-	hlist_for_each_entry_rcu(pnr, elem,
+	hlist_for_each_entry_rcu(pnr,
 			&pid_hash[pid_hashfn(nr, ns)], pid_chain)
 		if (pnr->nr == nr && pnr->ns == ns)
 			return container_of(pnr, struct pid,

commit 6e6668845fe593414a938b7726d6359b5570ac5a
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Feb 12 13:46:23 2013 -0800

    kernel/pid.c: reenable interrupts when alloc_pid() fails because init has exited
    
    We're forgetting to reenable local interrupts on an error path.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Reported-by: Josh Boyer <jwboyer@redhat.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index de9af600006f..f2c6a6825098 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -331,7 +331,7 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	return pid;
 
 out_unlock:
-	spin_unlock(&pidmap_lock);
+	spin_unlock_irq(&pidmap_lock);
 out_free:
 	while (++i <= ns->level)
 		free_pidmap(pid->numbers + i);

commit c876ad7682155958d0c9c27afe9017925c230d64
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Dec 21 20:27:12 2012 -0800

    pidns: Stop pid allocation when init dies
    
    Oleg pointed out that in a pid namespace the sequence.
    - pid 1 becomes a zombie
    - setns(thepidns), fork,...
    - reaping pid 1.
    - The injected processes exiting.
    
    Can lead to processes attempting access their child reaper and
    instead following a stale pointer.
    
    That waitpid for init can return before all of the processes in
    the pid namespace have exited is also unfortunate.
    
    Avoid these problems by disabling the allocation of new pids in a pid
    namespace when init dies, instead of when the last process in a pid
    namespace is reaped.
    
    Pointed-out-by:  Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index 36aa02ff17d6..de9af600006f 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -270,7 +270,6 @@ void free_pid(struct pid *pid)
 			wake_up_process(ns->child_reaper);
 			break;
 		case 0:
-			ns->nr_hashed = -1;
 			schedule_work(&ns->proc_work);
 			break;
 		}
@@ -319,7 +318,7 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 
 	upid = pid->numbers + ns->level;
 	spin_lock_irq(&pidmap_lock);
-	if (ns->nr_hashed < 0)
+	if (!(ns->nr_hashed & PIDNS_HASH_ADDING))
 		goto out_unlock;
 	for ( ; upid >= pid->numbers; --upid) {
 		hlist_add_head_rcu(&upid->pid_chain,
@@ -342,6 +341,13 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	goto out;
 }
 
+void disable_pid_allocation(struct pid_namespace *ns)
+{
+	spin_lock_irq(&pidmap_lock);
+	ns->nr_hashed &= ~PIDNS_HASH_ADDING;
+	spin_unlock_irq(&pidmap_lock);
+}
+
 struct pid *find_pid_ns(int nr, struct pid_namespace *ns)
 {
 	struct hlist_node *elem;
@@ -573,6 +579,9 @@ void __init pidhash_init(void)
 
 void __init pidmap_init(void)
 {
+	/* Veryify no one has done anything silly */
+	BUILD_BUG_ON(PID_MAX_LIMIT >= PIDNS_HASH_ADDING);
+
 	/* bump default and minimum pid_max based on number of cpus */
 	pid_max = min(pid_max_max, max_t(int, pid_max,
 				PIDS_PER_CPU_DEFAULT * num_possible_cpus()));
@@ -584,7 +593,7 @@ void __init pidmap_init(void)
 	/* Reserve PID 0. We never call free_pidmap(0) */
 	set_bit(0, init_pid_ns.pidmap[0].page);
 	atomic_dec(&init_pid_ns.pidmap[0].nr_free);
-	init_pid_ns.nr_hashed = 1;
+	init_pid_ns.nr_hashed = PIDNS_HASH_ADDING;
 
 	init_pid_ns.pid_cachep = KMEM_CACHE(pid,
 			SLAB_HWCACHE_ALIGN | SLAB_PANIC);

commit 848b81415c42ff3dc9a4204749087b015c37ef66
Merge: 992956189de5 6fd59a83b926
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Dec 17 20:58:12 2012 -0800

    Merge branch 'akpm' (Andrew's patch-bomb)
    
    Merge misc patches from Andrew Morton:
     "Incoming:
    
       - lots of misc stuff
    
       - backlight tree updates
    
       - lib/ updates
    
       - Oleg's percpu-rwsem changes
    
       - checkpatch
    
       - rtc
    
       - aoe
    
       - more checkpoint/restart support
    
      I still have a pile of MM stuff pending - Pekka should be merging
      later today after which that is good to go.  A number of other things
      are twiddling thumbs awaiting maintainer merges."
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (180 commits)
      scatterlist: don't BUG when we can trivially return a proper error.
      docs: update documentation about /proc/<pid>/fdinfo/<fd> fanotify output
      fs, fanotify: add @mflags field to fanotify output
      docs: add documentation about /proc/<pid>/fdinfo/<fd> output
      fs, notify: add procfs fdinfo helper
      fs, exportfs: add exportfs_encode_inode_fh() helper
      fs, exportfs: escape nil dereference if no s_export_op present
      fs, epoll: add procfs fdinfo helper
      fs, eventfd: add procfs fdinfo helper
      procfs: add ability to plug in auxiliary fdinfo providers
      tools/testing/selftests/kcmp/kcmp_test.c: print reason for failure in kcmp_test
      breakpoint selftests: print failure status instead of cause make error
      kcmp selftests: print fail status instead of cause make error
      kcmp selftests: make run_tests fix
      mem-hotplug selftests: print failure status instead of cause make error
      cpu-hotplug selftests: print failure status instead of cause make error
      mqueue selftests: print failure status instead of cause make error
      vm selftests: print failure status instead of cause make error
      ubifs: use prandom_bytes
      mtd: nandsim: use prandom_bytes
      ...

commit a5ba911ec3792168530d35e16a8ec3b6fc60bcb5
Author: Gao feng <gaofeng@cn.fujitsu.com>
Date:   Mon Dec 17 16:03:22 2012 -0800

    pidns: remove unused is_container_init()
    
    Since commit 1cdcbec1a337 ("CRED: Neuter sys_capset()")
    is_container_init() has no callers.
    
    Signed-off-by: Gao feng <gaofeng@cn.fujitsu.com>
    Cc: David Howells <dhowells@redhat.com>
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Cc: James Morris <jmorris@namei.org>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index fd996c1ed9f8..a54a1123c7cf 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -81,21 +81,6 @@ struct pid_namespace init_pid_ns = {
 };
 EXPORT_SYMBOL_GPL(init_pid_ns);
 
-int is_container_init(struct task_struct *tsk)
-{
-	int ret = 0;
-	struct pid *pid;
-
-	rcu_read_lock();
-	pid = task_pid(tsk);
-	if (pid != NULL && pid->numbers[pid->level].nr == 1)
-		ret = 1;
-	rcu_read_unlock();
-
-	return ret;
-}
-EXPORT_SYMBOL(is_container_init);
-
 /*
  * Note: disable interrupts while the pidmap_lock is held as an
  * interrupt might come in and do read_lock(&tasklist_lock).

commit 6a2b60b17b3e48a418695a94bd2420f6ab32e519
Merge: 9228ff90387e 98f842e675f9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Dec 17 15:44:47 2012 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull user namespace changes from Eric Biederman:
     "While small this set of changes is very significant with respect to
      containers in general and user namespaces in particular.  The user
      space interface is now complete.
    
      This set of changes adds support for unprivileged users to create user
      namespaces and as a user namespace root to create other namespaces.
      The tyranny of supporting suid root preventing unprivileged users from
      using cool new kernel features is broken.
    
      This set of changes completes the work on setns, adding support for
      the pid, user, mount namespaces.
    
      This set of changes includes a bunch of basic pid namespace
      cleanups/simplifications.  Of particular significance is the rework of
      the pid namespace cleanup so it no longer requires sending out
      tendrils into all kinds of unexpected cleanup paths for operation.  At
      least one case of broken error handling is fixed by this cleanup.
    
      The files under /proc/<pid>/ns/ have been converted from regular files
      to magic symlinks which prevents incorrect caching by the VFS,
      ensuring the files always refer to the namespace the process is
      currently using and ensuring that the ptrace_mayaccess permission
      checks are always applied.
    
      The files under /proc/<pid>/ns/ have been given stable inode numbers
      so it is now possible to see if different processes share the same
      namespaces.
    
      Through the David Miller's net tree are changes to relax many of the
      permission checks in the networking stack to allowing the user
      namespace root to usefully use the networking stack.  Similar changes
      for the mount namespace and the pid namespace are coming through my
      tree.
    
      Two small changes to add user namespace support were commited here adn
      in David Miller's -net tree so that I could complete the work on the
      /proc/<pid>/ns/ files in this tree.
    
      Work remains to make it safe to build user namespaces and 9p, afs,
      ceph, cifs, coda, gfs2, ncpfs, nfs, nfsd, ocfs2, and xfs so the
      Kconfig guard remains in place preventing that user namespaces from
      being built when any of those filesystems are enabled.
    
      Future design work remains to allow root users outside of the initial
      user namespace to mount more than just /proc and /sys."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace: (38 commits)
      proc: Usable inode numbers for the namespace file descriptors.
      proc: Fix the namespace inode permission checks.
      proc: Generalize proc inode allocation
      userns: Allow unprivilged mounts of proc and sysfs
      userns: For /proc/self/{uid,gid}_map derive the lower userns from the struct file
      procfs: Print task uids and gids in the userns that opened the proc file
      userns: Implement unshare of the user namespace
      userns: Implent proc namespace operations
      userns: Kill task_user_ns
      userns: Make create_new_namespaces take a user_ns parameter
      userns: Allow unprivileged use of setns.
      userns: Allow unprivileged users to create new namespaces
      userns: Allow setting a userns mapping to your current uid.
      userns: Allow chown and setgid preservation
      userns: Allow unprivileged users to create user namespaces.
      userns: Ignore suid and sgid on binaries if the uid or gid can not be mapped
      userns: fix return value on mntns_install() failure
      vfs: Allow unprivileged manipulation of the mount namespace.
      vfs: Only support slave subtrees across different user namespaces
      vfs: Add a user namespace reference from struct mnt_namespace
      ...

commit 6d49e352ae9aed3f599041b0c0389aa924815f14
Author: Nadia Yvette Chambers <nyc@holomorphy.com>
Date:   Thu Dec 6 10:39:54 2012 +0100

    propagate name change to comments in kernel source
    
    I've legally changed my name with New York State, the US Social Security
    Administration, et al. This patch propagates the name change and change
    in initials and login to comments in the kernel source as well.
    
    Signed-off-by: Nadia Yvette Chambers <nyc@holomorphy.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/kernel/pid.c b/kernel/pid.c
index aebd4f5aaf41..fd996c1ed9f8 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -1,8 +1,8 @@
 /*
  * Generic pidhash and scalable, time-bounded PID allocator
  *
- * (C) 2002-2003 William Irwin, IBM
- * (C) 2004 William Irwin, Oracle
+ * (C) 2002-2003 Nadia Yvette Chambers, IBM
+ * (C) 2004 Nadia Yvette Chambers, Oracle
  * (C) 2002-2004 Ingo Molnar, Red Hat
  *
  * pid-structures are backing objects for tasks sharing a given ID to chain

commit 98f842e675f96ffac96e6c50315790912b2812be
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Jun 15 10:21:48 2011 -0700

    proc: Usable inode numbers for the namespace file descriptors.
    
    Assign a unique proc inode to each namespace, and use that
    inode number to ensure we only allocate at most one proc
    inode for every namespace in proc.
    
    A single proc inode per namespace allows userspace to test
    to see if two processes are in the same namespace.
    
    This has been a long requested feature and only blocked because
    a naive implementation would put the id in a global space and
    would ultimately require having a namespace for the names of
    namespaces, making migration and certain virtualization tricks
    impossible.
    
    We still don't have per superblock inode numbers for proc, which
    appears necessary for application unaware checkpoint/restart and
    migrations (if the application is using namespace file descriptors)
    but that is now allowd by the design if it becomes important.
    
    I have preallocated the ipc and uts initial proc inode numbers so
    their structures can be statically initialized.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index 6e8da291de49..3026ddae0a34 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -80,6 +80,7 @@ struct pid_namespace init_pid_ns = {
 	.level = 0,
 	.child_reaper = &init_task,
 	.user_ns = &init_user_ns,
+	.proc_inum = PROC_PID_INIT_INO,
 };
 EXPORT_SYMBOL_GPL(init_pid_ns);
 

commit af4b8a83add95ef40716401395b44a1b579965f4
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Aug 1 15:03:42 2012 -0700

    pidns: Wait in zap_pid_ns_processes until pid_ns->nr_hashed == 1
    
    Looking at pid_ns->nr_hashed is a bit simpler and it works for
    disjoint process trees that an unshare or a join of a pid_namespace
    may create.
    
    Acked-by: "Serge E. Hallyn" <serge@hallyn.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index 9c219117af36..6e8da291de49 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -273,10 +273,20 @@ void free_pid(struct pid *pid)
 	spin_lock_irqsave(&pidmap_lock, flags);
 	for (i = 0; i <= pid->level; i++) {
 		struct upid *upid = pid->numbers + i;
+		struct pid_namespace *ns = upid->ns;
 		hlist_del_rcu(&upid->pid_chain);
-		if (--upid->ns->nr_hashed == 0) {
-			upid->ns->nr_hashed = -1;
-			schedule_work(&upid->ns->proc_work);
+		switch(--ns->nr_hashed) {
+		case 1:
+			/* When all that is left in the pid namespace
+			 * is the reaper wake up the reaper.  The reaper
+			 * may be sleeping in zap_pid_ns_processes().
+			 */
+			wake_up_process(ns->child_reaper);
+			break;
+		case 0:
+			ns->nr_hashed = -1;
+			schedule_work(&ns->proc_work);
+			break;
 		}
 	}
 	spin_unlock_irqrestore(&pidmap_lock, flags);

commit 5e1182deb81ae8c68494017c4a8a71811659c870
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Jul 12 18:50:25 2010 -0700

    pidns: Don't allow new processes in a dead pid namespace.
    
    Set nr_hashed to -1 just before we schedule the work to cleanup proc.
    Test nr_hashed just before we hash a new pid and if nr_hashed is < 0
    fail.
    
    This guaranteees that processes never enter a pid namespaces after we
    have cleaned up the state to support processes in a pid namespace.
    
    Currently sending SIGKILL to all of the process in a pid namespace as
    init exists gives us this guarantee but we need something a little
    stronger to support unsharing and joining a pid namespace.
    
    Acked-by: "Serge E. Hallyn" <serge@hallyn.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index e957f8b09136..9c219117af36 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -274,8 +274,10 @@ void free_pid(struct pid *pid)
 	for (i = 0; i <= pid->level; i++) {
 		struct upid *upid = pid->numbers + i;
 		hlist_del_rcu(&upid->pid_chain);
-		if (--upid->ns->nr_hashed == 0)
+		if (--upid->ns->nr_hashed == 0) {
+			upid->ns->nr_hashed = -1;
 			schedule_work(&upid->ns->proc_work);
+		}
 	}
 	spin_unlock_irqrestore(&pidmap_lock, flags);
 
@@ -321,6 +323,8 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 
 	upid = pid->numbers + ns->level;
 	spin_lock_irq(&pidmap_lock);
+	if (ns->nr_hashed < 0)
+		goto out_unlock;
 	for ( ; upid >= pid->numbers; --upid) {
 		hlist_add_head_rcu(&upid->pid_chain,
 				&pid_hash[pid_hashfn(upid->nr, upid->ns)]);
@@ -331,6 +335,8 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 out:
 	return pid;
 
+out_unlock:
+	spin_unlock(&pidmap_lock);
 out_free:
 	while (++i <= ns->level)
 		free_pidmap(pid->numbers + i);

commit 0a01f2cc390e10633a54f72c608cc3fe19a50c3d
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Aug 1 10:33:47 2012 -0700

    pidns: Make the pidns proc mount/umount logic obvious.
    
    Track the number of pids in the proc hash table.  When the number of
    pids goes to 0 schedule work to unmount the kernel mount of proc.
    
    Move the mount of proc into alloc_pid when we allocate the pid for
    init.
    
    Remove the surprising calls of pid_ns_release proc in fork and
    proc_flush_task.  Those code paths really shouldn't know about proc
    namespace implementation details and people have demonstrated several
    times that finding and understanding those code paths is difficult and
    non-obvious.
    
    Because of the call path detach pid is alwasy called with the
    rtnl_lock held free_pid is not allowed to sleep, so the work to
    unmounting proc is moved to a work queue.  This has the side benefit
    of not blocking the entire world waiting for the unnecessary
    rcu_barrier in deactivate_locked_super.
    
    In the process of making the code clear and obvious this fixes a bug
    reported by Gao feng <gaofeng@cn.fujitsu.com> where we would leak a
    mount of proc during clone(CLONE_NEWPID|CLONE_NEWNET) if copy_pid_ns
    succeeded and copy_net_ns failed.
    
    Acked-by: "Serge E. Hallyn" <serge@hallyn.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index 3a5f238c1ca0..e957f8b09136 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -36,6 +36,7 @@
 #include <linux/pid_namespace.h>
 #include <linux/init_task.h>
 #include <linux/syscalls.h>
+#include <linux/proc_fs.h>
 
 #define pid_hashfn(nr, ns)	\
 	hash_long((unsigned long)nr + (unsigned long)ns, pidhash_shift)
@@ -270,8 +271,12 @@ void free_pid(struct pid *pid)
 	unsigned long flags;
 
 	spin_lock_irqsave(&pidmap_lock, flags);
-	for (i = 0; i <= pid->level; i++)
-		hlist_del_rcu(&pid->numbers[i].pid_chain);
+	for (i = 0; i <= pid->level; i++) {
+		struct upid *upid = pid->numbers + i;
+		hlist_del_rcu(&upid->pid_chain);
+		if (--upid->ns->nr_hashed == 0)
+			schedule_work(&upid->ns->proc_work);
+	}
 	spin_unlock_irqrestore(&pidmap_lock, flags);
 
 	for (i = 0; i <= pid->level; i++)
@@ -293,6 +298,7 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 		goto out;
 
 	tmp = ns;
+	pid->level = ns->level;
 	for (i = ns->level; i >= 0; i--) {
 		nr = alloc_pidmap(tmp);
 		if (nr < 0)
@@ -303,17 +309,23 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 		tmp = tmp->parent;
 	}
 
+	if (unlikely(is_child_reaper(pid))) {
+		if (pid_ns_prepare_proc(ns))
+			goto out_free;
+	}
+
 	get_pid_ns(ns);
-	pid->level = ns->level;
 	atomic_set(&pid->count, 1);
 	for (type = 0; type < PIDTYPE_MAX; ++type)
 		INIT_HLIST_HEAD(&pid->tasks[type]);
 
 	upid = pid->numbers + ns->level;
 	spin_lock_irq(&pidmap_lock);
-	for ( ; upid >= pid->numbers; --upid)
+	for ( ; upid >= pid->numbers; --upid) {
 		hlist_add_head_rcu(&upid->pid_chain,
 				&pid_hash[pid_hashfn(upid->nr, upid->ns)]);
+		upid->ns->nr_hashed++;
+	}
 	spin_unlock_irq(&pidmap_lock);
 
 out:
@@ -570,6 +582,7 @@ void __init pidmap_init(void)
 	/* Reserve PID 0. We never call free_pidmap(0) */
 	set_bit(0, init_pid_ns.pidmap[0].page);
 	atomic_dec(&init_pid_ns.pidmap[0].nr_free);
+	init_pid_ns.nr_hashed = 1;
 
 	init_pid_ns.pid_cachep = KMEM_CACHE(pid,
 			SLAB_HWCACHE_ALIGN | SLAB_PANIC);

commit 17cf22c33e1f1b5e435469c84e43872579497653
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Mar 2 14:51:53 2010 -0800

    pidns: Use task_active_pid_ns where appropriate
    
    The expressions tsk->nsproxy->pid_ns and task_active_pid_ns
    aka ns_of_pid(task_pid(tsk)) should have the same number of
    cache line misses with the practical difference that
    ns_of_pid(task_pid(tsk)) is released later in a processes life.
    
    Furthermore by using task_active_pid_ns it becomes trivial
    to write an unshare implementation for the the pid namespace.
    
    So I have used task_active_pid_ns everywhere I can.
    
    In fork since the pid has not yet been attached to the
    process I use ns_of_pid, to achieve the same effect.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index 2a624f1486e1..3a5f238c1ca0 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -345,7 +345,7 @@ EXPORT_SYMBOL_GPL(find_pid_ns);
 
 struct pid *find_vpid(int nr)
 {
-	return find_pid_ns(nr, current->nsproxy->pid_ns);
+	return find_pid_ns(nr, task_active_pid_ns(current));
 }
 EXPORT_SYMBOL_GPL(find_vpid);
 
@@ -429,7 +429,7 @@ struct task_struct *find_task_by_pid_ns(pid_t nr, struct pid_namespace *ns)
 
 struct task_struct *find_task_by_vpid(pid_t vnr)
 {
-	return find_task_by_pid_ns(vnr, current->nsproxy->pid_ns);
+	return find_task_by_pid_ns(vnr, task_active_pid_ns(current));
 }
 
 struct pid *get_task_pid(struct task_struct *task, enum pid_type type)
@@ -484,7 +484,7 @@ EXPORT_SYMBOL_GPL(pid_nr_ns);
 
 pid_t pid_vnr(struct pid *pid)
 {
-	return pid_nr_ns(pid, current->nsproxy->pid_ns);
+	return pid_nr_ns(pid, task_active_pid_ns(current));
 }
 EXPORT_SYMBOL_GPL(pid_vnr);
 
@@ -495,7 +495,7 @@ pid_t __task_pid_nr_ns(struct task_struct *task, enum pid_type type,
 
 	rcu_read_lock();
 	if (!ns)
-		ns = current->nsproxy->pid_ns;
+		ns = task_active_pid_ns(current);
 	if (likely(pid_alive(task))) {
 		if (type != PIDTYPE_PID)
 			task = task->group_leader;

commit 49f4d8b93ccf9454284b6f524b96c66d8d7fbccc
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Aug 2 04:25:10 2012 -0700

    pidns: Capture the user namespace and filter ns_last_pid
    
    - Capture the the user namespace that creates the pid namespace
    - Use that user namespace to test if it is ok to write to
      /proc/sys/kernel/ns_last_pid.
    
    Zhao Hongjiang <zhaohongjiang@huawei.com> noticed I was missing a put_user_ns
    in when destroying a pid_ns.  I have foloded his patch into this one
    so that bisects will work properly.
    
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index aebd4f5aaf41..2a624f1486e1 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -78,6 +78,7 @@ struct pid_namespace init_pid_ns = {
 	.last_pid = 0,
 	.level = 0,
 	.child_reaper = &init_task,
+	.user_ns = &init_user_ns,
 };
 EXPORT_SYMBOL_GPL(init_pid_ns);
 

commit 4f82f45730c68fdaf9b0472495a965188404866e
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu May 24 10:37:59 2012 -0600

    net ip6 flowlabel: Make owner a union of struct pid * and kuid_t
    
    Correct a long standing omission and use struct pid in the owner
    field of struct ip6_flowlabel when the share type is IPV6_FL_S_PROCESS.
    This guarantees we don't have issues when pid wraparound occurs.
    
    Use a kuid_t in the owner field of struct ip6_flowlabel when the
    share type is IPV6_FL_S_USER to add user namespace support.
    
    In /proc/net/ip6_flowlabel capture the current pid namespace when
    opening the file and release the pid namespace when the file is
    closed ensuring we print the pid owner value that is meaning to
    the reader of the file.  Similarly use from_kuid_munged to print
    uid values that are meaningful to the reader of the file.
    
    This requires exporting pid_nr_ns so that ipv6 can continue to built
    as a module.  Yoiks what silliness
    
    Acked-by: David S. Miller <davem@davemloft.net>
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index e86b291ad834..aebd4f5aaf41 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -479,6 +479,7 @@ pid_t pid_nr_ns(struct pid *pid, struct pid_namespace *ns)
 	}
 	return nr;
 }
+EXPORT_SYMBOL_GPL(pid_nr_ns);
 
 pid_t pid_vnr(struct pid *pid)
 {

commit 31fe62b9586643953f0c0c37a6357dafc69034e2
Author: Tim Bird <tim.bird@am.sony.com>
Date:   Wed May 23 13:33:35 2012 +0000

    mm: add a low limit to alloc_large_system_hash
    
    UDP stack needs a minimum hash size value for proper operation and also
    uses alloc_large_system_hash() for proper NUMA distribution of its hash
    tables and automatic sizing depending on available system memory.
    
    On some low memory situations, udp_table_init() must ignore the
    alloc_large_system_hash() result and reallocs a bigger memory area.
    
    As we cannot easily free old hash table, we leak it and kmemleak can
    issue a warning.
    
    This patch adds a low limit parameter to alloc_large_system_hash() to
    solve this problem.
    
    We then specify UDP_HTABLE_SIZE_MIN for UDP/UDPLite hash table
    allocation.
    
    Reported-by: Mark Asselstine <mark.asselstine@windriver.com>
    Reported-by: Tim Bird <tim.bird@am.sony.com>
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/pid.c b/kernel/pid.c
index 9f08dfabaf13..e86b291ad834 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -547,7 +547,8 @@ void __init pidhash_init(void)
 
 	pid_hash = alloc_large_system_hash("PID", sizeof(*pid_hash), 0, 18,
 					   HASH_EARLY | HASH_SMALL,
-					   &pidhash_shift, NULL, 4096);
+					   &pidhash_shift, NULL,
+					   0, 4096);
 	pidhash_size = 1U << pidhash_shift;
 
 	for (i = 0; i < pidhash_size; i++)

commit 074b85175a43a23fdbde60f55feea636e0bf0f85
Author: Dimitri Sivanich <sivanich@sgi.com>
Date:   Wed Feb 8 12:39:07 2012 -0800

    vfs: fix panic in __d_lookup() with high dentry hashtable counts
    
    When the number of dentry cache hash table entries gets too high
    (2147483648 entries), as happens by default on a 16TB system, use of a
    signed integer in the dcache_init() initialization loop prevents the
    dentry_hashtable from getting initialized, causing a panic in
    __d_lookup().  Fix this in dcache_init() and similar areas.
    
    Signed-off-by: Dimitri Sivanich <sivanich@sgi.com>
    Acked-by: David S. Miller <davem@davemloft.net>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/pid.c b/kernel/pid.c
index ce8e00deaccb..9f08dfabaf13 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -543,12 +543,12 @@ struct pid *find_ge_pid(int nr, struct pid_namespace *ns)
  */
 void __init pidhash_init(void)
 {
-	int i, pidhash_size;
+	unsigned int i, pidhash_size;
 
 	pid_hash = alloc_large_system_hash("PID", sizeof(*pid_hash), 0, 18,
 					   HASH_EARLY | HASH_SMALL,
 					   &pidhash_shift, NULL, 4096);
-	pidhash_size = 1 << pidhash_shift;
+	pidhash_size = 1U << pidhash_shift;
 
 	for (i = 0; i < pidhash_size; i++)
 		INIT_HLIST_HEAD(&pid_hash[i]);

commit b8f566b04d3cddd192cfd2418ae6d54ac6353792
Author: Pavel Emelyanov <xemul@parallels.com>
Date:   Thu Jan 12 17:20:27 2012 -0800

    sysctl: add the kernel.ns_last_pid control
    
    The sysctl works on the current task's pid namespace, getting and setting
    its last_pid field.
    
    Writing is allowed for CAP_SYS_ADMIN-capable tasks thus making it possible
    to create a task with desired pid value.  This ability is required badly
    for the checkpoint/restore in userspace.
    
    This approach suits all the parties for now.
    
    Signed-off-by: Pavel Emelyanov <xemul@parallels.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Cyrill Gorcunov <gorcunov@openvz.org>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index fa5f72227e5f..ce8e00deaccb 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -137,7 +137,9 @@ static int pid_before(int base, int a, int b)
 }
 
 /*
- * We might be racing with someone else trying to set pid_ns->last_pid.
+ * We might be racing with someone else trying to set pid_ns->last_pid
+ * at the pid allocation time (there's also a sysctl for this, but racing
+ * with this one is OK, see comment in kernel/pid_namespace.c about it).
  * We want the winner to have the "later" value, because if the
  * "earlier" value prevails, then a pid may get reused immediately.
  *

commit 9984de1a5a8a96275fcab818f7419af5a3c86e71
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Mon May 23 14:51:41 2011 -0400

    kernel: Map most files to use export.h instead of module.h
    
    The changed files were only including linux/module.h for the
    EXPORT_SYMBOL infrastructure, and nothing else.  Revector them
    onto the isolated export header for faster compile times.
    
    Nothing to see here but a whole lot of instances of:
    
      -#include <linux/module.h>
      +#include <linux/export.h>
    
    This commit is only changing the kernel dir; next targets
    will probably be mm, fs, the arch dirs, etc.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index 8cafe7e72ad2..fa5f72227e5f 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -27,7 +27,7 @@
  */
 
 #include <linux/mm.h>
-#include <linux/module.h>
+#include <linux/export.h>
 #include <linux/slab.h>
 #include <linux/init.h>
 #include <linux/rculist.h>

commit b3fbab0571eb09746cc0283648165ec00efc8eb2
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue May 24 08:31:09 2011 -0700

    rcu: Restore checks for blocking in RCU read-side critical sections
    
    Long ago, using TREE_RCU with PREEMPT would result in "scheduling
    while atomic" diagnostics if you blocked in an RCU read-side critical
    section.  However, PREEMPT now implies TREE_PREEMPT_RCU, which defeats
    this diagnostic.  This commit therefore adds a replacement diagnostic
    based on PROVE_RCU.
    
    Because rcu_lockdep_assert() and lockdep_rcu_dereference() are now being
    used for things that have nothing to do with rcu_dereference(), rename
    lockdep_rcu_dereference() to lockdep_rcu_suspicious() and add a third
    argument that is a string indicating what is suspicious.  This third
    argument is passed in from a new third argument to rcu_lockdep_assert().
    Update all calls to rcu_lockdep_assert() to add an informative third
    argument.
    
    Also, add a pair of rcu_lockdep_assert() calls from within
    rcu_note_context_switch(), one complaining if a context switch occurs
    in an RCU-bh read-side critical section and another complaining if a
    context switch occurs in an RCU-sched read-side critical section.
    These are present only if the PROVE_RCU kernel parameter is enabled.
    
    Finally, fix some checkpatch whitespace complaints in lockdep.c.
    
    Again, you must enable PROVE_RCU to see these new diagnostics.  But you
    are enabling PROVE_RCU to check out new RCU uses in any case, aren't you?
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index e432057f3b21..8cafe7e72ad2 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -418,7 +418,9 @@ EXPORT_SYMBOL(pid_task);
  */
 struct task_struct *find_task_by_pid_ns(pid_t nr, struct pid_namespace *ns)
 {
-	rcu_lockdep_assert(rcu_read_lock_held());
+	rcu_lockdep_assert(rcu_read_lock_held(),
+			   "find_task_by_pid_ns() needs rcu_read_lock()"
+			   " protection");
 	return pid_task(find_pid_ns(nr, ns), PIDTYPE_PID);
 }
 

commit d8bf4ca9ca9576548628344c9725edd3786e90b1
Author: Michal Hocko <mhocko@suse.cz>
Date:   Fri Jul 8 14:39:41 2011 +0200

    rcu: treewide: Do not use rcu_read_lock_held when calling rcu_dereference_check
    
    Since ca5ecddf (rcu: define __rcu address space modifier for sparse)
    rcu_dereference_check use rcu_read_lock_held as a part of condition
    automatically so callers do not have to do that as well.
    
    Signed-off-by: Michal Hocko <mhocko@suse.cz>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/kernel/pid.c b/kernel/pid.c
index 57a8346a270e..e432057f3b21 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -405,7 +405,6 @@ struct task_struct *pid_task(struct pid *pid, enum pid_type type)
 	if (pid) {
 		struct hlist_node *first;
 		first = rcu_dereference_check(hlist_first_rcu(&pid->tasks[type]),
-					      rcu_read_lock_held() ||
 					      lockdep_tasklist_lock_is_held());
 		if (first)
 			result = hlist_entry(first, struct task_struct, pids[(type)].node);

commit c78193e9c7bcbf25b8237ad0dec82f805c4ea69b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Apr 18 10:35:30 2011 -0700

    next_pidmap: fix overflow condition
    
    next_pidmap() just quietly accepted whatever 'last' pid that was passed
    in, which is not all that safe when one of the users is /proc.
    
    Admittedly the proc code should do some sanity checking on the range
    (and that will be the next commit), but that doesn't mean that the
    helper functions should just do that pidmap pointer arithmetic without
    checking the range of its arguments.
    
    So clamp 'last' to PID_MAX_LIMIT.  The fact that we then do "last+1"
    doesn't really matter, the for-loop does check against the end of the
    pidmap array properly (it's only the actual pointer arithmetic overflow
    case we need to worry about, and going one bit beyond isn't going to
    overflow).
    
    [ Use PID_MAX_LIMIT rather than pid_max as per Eric Biederman ]
    
    Reported-by: Tavis Ormandy <taviso@cmpxchg8b.com>
    Analyzed-by: Robert wicki <robert@swiecki.net>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 02f221274265..57a8346a270e 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -217,11 +217,14 @@ static int alloc_pidmap(struct pid_namespace *pid_ns)
 	return -1;
 }
 
-int next_pidmap(struct pid_namespace *pid_ns, int last)
+int next_pidmap(struct pid_namespace *pid_ns, unsigned int last)
 {
 	int offset;
 	struct pidmap *map, *end;
 
+	if (last >= PID_MAX_LIMIT)
+		return -1;
+
 	offset = (last + 1) & BITS_PER_PAGE_MASK;
 	map = &pid_ns->pidmap[(last + 1)/BITS_PER_PAGE];
 	end = &pid_ns->pidmap[PIDMAP_ENTRIES];

commit 77c100c83e84316ced2507c5799f79c2c80bc6b9
Author: Rik van Riel <riel@redhat.com>
Date:   Tue Feb 1 09:51:46 2011 -0500

    export pid symbols needed for kvm_vcpu_on_spin
    
    Export the symbols required for a race-free kvm_vcpu_on_spin.
    
    Signed-off-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index 39b65b69584f..02f221274265 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -435,6 +435,7 @@ struct pid *get_task_pid(struct task_struct *task, enum pid_type type)
 	rcu_read_unlock();
 	return pid;
 }
+EXPORT_SYMBOL_GPL(get_task_pid);
 
 struct task_struct *get_pid_task(struct pid *pid, enum pid_type type)
 {
@@ -446,6 +447,7 @@ struct task_struct *get_pid_task(struct pid *pid, enum pid_type type)
 	rcu_read_unlock();
 	return result;
 }
+EXPORT_SYMBOL_GPL(get_pid_task);
 
 struct pid *find_get_pid(pid_t nr)
 {

commit 4221a9918e38b7494cee341dda7b7b4bb8c04bde
Author: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
Date:   Sat Jun 26 01:08:19 2010 +0900

    Add RCU check for find_task_by_vpid().
    
    find_task_by_vpid() says "Must be called under rcu_read_lock().". But due to
    commit 3120438 "rcu: Disable lockdep checking in RCU list-traversal primitives",
    we are currently unable to catch "find_task_by_vpid() with tasklist_lock held
    but RCU lock not held" errors due to the RCU-lockdep checks being
    suppressed in the RCU variants of the struct list_head traversals.
    This commit therefore places an explicit check for being in an RCU
    read-side critical section in find_task_by_pid_ns().
    
      ===================================================
      [ INFO: suspicious rcu_dereference_check() usage. ]
      ---------------------------------------------------
      kernel/pid.c:386 invoked rcu_dereference_check() without protection!
    
      other info that might help us debug this:
    
      rcu_scheduler_active = 1, debug_locks = 1
      1 lock held by rc.sysinit/1102:
       #0:  (tasklist_lock){.+.+..}, at: [<c1048340>] sys_setpgid+0x40/0x160
    
      stack backtrace:
      Pid: 1102, comm: rc.sysinit Not tainted 2.6.35-rc3-dirty #1
      Call Trace:
       [<c105e714>] lockdep_rcu_dereference+0x94/0xb0
       [<c104b4cd>] find_task_by_pid_ns+0x6d/0x70
       [<c104b4e8>] find_task_by_vpid+0x18/0x20
       [<c1048347>] sys_setpgid+0x47/0x160
       [<c1002b50>] sysenter_do_call+0x12/0x36
    
    Commit updated to use a new rcu_lockdep_assert() exported API rather than
    the old internal __do_rcu_dereference().
    
    Signed-off-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 0f90c2f713f1..39b65b69584f 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -416,6 +416,7 @@ EXPORT_SYMBOL(pid_task);
  */
 struct task_struct *find_task_by_pid_ns(pid_t nr, struct pid_namespace *ns)
 {
+	rcu_lockdep_assert(rcu_read_lock_held());
 	return pid_task(find_pid_ns(nr, ns), PIDTYPE_PID);
 }
 

commit 67bdbffd696f29a0b68aa8daa285783a06651583
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Thu Feb 25 16:55:13 2010 +0100

    rculist: avoid __rcu annotations
    
    This avoids warnings from missing __rcu annotations
    in the rculist implementation, making it possible to
    use the same lists in both RCU and non-RCU cases.
    
    We can add rculist annotations later, together with
    lockdep support for rculist, which is missing as well,
    but that may involve changing all the users.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index d55c6fb8d087..0f90c2f713f1 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -401,7 +401,7 @@ struct task_struct *pid_task(struct pid *pid, enum pid_type type)
 	struct task_struct *result = NULL;
 	if (pid) {
 		struct hlist_node *first;
-		first = rcu_dereference_check(pid->tasks[type].first,
+		first = rcu_dereference_check(hlist_first_rcu(&pid->tasks[type]),
 					      rcu_read_lock_held() ||
 					      lockdep_tasklist_lock_is_held());
 		if (first)

commit c52b0b91ba1f4b7ea90e20385c0a6df0ba54aed4
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue Aug 10 18:03:17 2010 -0700

    pids: alloc_pidmap: remove the unnecessary boundary checks
    
    alloc_pidmap() calculates max_scan so that if the initial offset != 0 we
    inspect the first map->page twice.  This is correct, we want to find the
    unused bits < offset in this bitmap block.  Add the comment.
    
    But it doesn't make any sense to stop the find_next_offset() loop when we
    are looking into this map->page for the second time.  We have already
    already checked the bits >= offset during the first attempt, it is fine to
    do this again, no matter if we succeed this time or not.
    
    Remove this hard-to-understand code.  It optimizes the very unlikely case
    when we are going to fail, but slows down the more likely case.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Salman Qazi <sqazi@google.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index fbbd5f6b6f2f..d55c6fb8d087 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -169,7 +169,12 @@ static int alloc_pidmap(struct pid_namespace *pid_ns)
 		pid = RESERVED_PIDS;
 	offset = pid & BITS_PER_PAGE_MASK;
 	map = &pid_ns->pidmap[pid/BITS_PER_PAGE];
-	max_scan = (pid_max + BITS_PER_PAGE - 1)/BITS_PER_PAGE - !offset;
+	/*
+	 * If last_pid points into the middle of the map->page we
+	 * want to scan this bitmap block twice, the second time
+	 * we start with offset == 0 (or RESERVED_PIDS).
+	 */
+	max_scan = DIV_ROUND_UP(pid_max, BITS_PER_PAGE) - !offset;
 	for (i = 0; i <= max_scan; ++i) {
 		if (unlikely(!map->page)) {
 			void *page = kzalloc(PAGE_SIZE, GFP_KERNEL);
@@ -196,15 +201,7 @@ static int alloc_pidmap(struct pid_namespace *pid_ns)
 				}
 				offset = find_next_offset(map, offset);
 				pid = mk_pid(pid_ns, map, offset);
-			/*
-			 * find_next_offset() found a bit, the pid from it
-			 * is in-bounds, and if we fell back to the last
-			 * bitmap block and the final block was the same
-			 * as the starting point, pid is before last_pid.
-			 */
-			} while (offset < BITS_PER_PAGE && pid < pid_max &&
-					(i != max_scan || pid < last ||
-					    !((last+1) & BITS_PER_PAGE_MASK)));
+			} while (offset < BITS_PER_PAGE && pid < pid_max);
 		}
 		if (map < &pid_ns->pidmap[(pid_max-1)/BITS_PER_PAGE]) {
 			++map;

commit 5fdee8c4a5e1800489ce61963208f8cc55e42ea1
Author: Salman <sqazi@google.com>
Date:   Tue Aug 10 18:03:16 2010 -0700

    pids: fix a race in pid generation that causes pids to be reused immediately
    
    A program that repeatedly forks and waits is susceptible to having the
    same pid repeated, especially when it competes with another instance of
    the same program.  This is really bad for bash implementation.
    Furthermore, many shell scripts assume that pid numbers will not be used
    for some length of time.
    
    Race Description:
    
    A                                    B
    
    // pid == offset == n                // pid == offset == n + 1
    test_and_set_bit(offset, map->page)
                                         test_and_set_bit(offset, map->page);
                                         pid_ns->last_pid = pid;
    pid_ns->last_pid = pid;
                                         // pid == n + 1 is freed (wait())
    
                                         // Next fork()...
                                         last = pid_ns->last_pid; // == n
                                         pid = last + 1;
    
    Code to reproduce it (Running multiple instances is more effective):
    
    #include <errno.h>
    #include <sys/types.h>
    #include <sys/wait.h>
    #include <unistd.h>
    #include <stdio.h>
    #include <stdlib.h>
    
    // The distance mod 32768 between two pids, where the first pid is expected
    // to be smaller than the second.
    int PidDistance(pid_t first, pid_t second) {
      return (second + 32768 - first) % 32768;
    }
    
    int main(int argc, char* argv[]) {
      int failed = 0;
      pid_t last_pid = 0;
      int i;
      printf("%d\n", sizeof(pid_t));
      for (i = 0; i < 10000000; ++i) {
        if (i % 32786 == 0)
          printf("Iter: %d\n", i/32768);
        int child_exit_code = i % 256;
        pid_t pid = fork();
        if (pid == -1) {
          fprintf(stderr, "fork failed, iteration %d, errno=%d", i, errno);
          exit(1);
        }
        if (pid == 0) {
          // Child
          exit(child_exit_code);
        } else {
          // Parent
          if (i > 0) {
            int distance = PidDistance(last_pid, pid);
            if (distance == 0 || distance > 30000) {
              fprintf(stderr,
                      "Unexpected pid sequence: previous fork: pid=%d, "
                      "current fork: pid=%d for iteration=%d.\n",
                      last_pid, pid, i);
              failed = 1;
            }
          }
          last_pid = pid;
          int status;
          int reaped = wait(&status);
          if (reaped != pid) {
            fprintf(stderr,
                    "Wait return value: expected pid=%d, "
                    "got %d, iteration %d\n",
                    pid, reaped, i);
            failed = 1;
          } else if (WEXITSTATUS(status) != child_exit_code) {
            fprintf(stderr,
                    "Unexpected exit status %x, iteration %d\n",
                    WEXITSTATUS(status), i);
            failed = 1;
          }
        }
      }
      exit(failed);
    }
    
    Thanks to Ted Tso for the key ideas of this implementation.
    
    Signed-off-by: Salman Qazi <sqazi@google.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index e9fd8c132d26..fbbd5f6b6f2f 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -122,6 +122,43 @@ static void free_pidmap(struct upid *upid)
 	atomic_inc(&map->nr_free);
 }
 
+/*
+ * If we started walking pids at 'base', is 'a' seen before 'b'?
+ */
+static int pid_before(int base, int a, int b)
+{
+	/*
+	 * This is the same as saying
+	 *
+	 * (a - base + MAXUINT) % MAXUINT < (b - base + MAXUINT) % MAXUINT
+	 * and that mapping orders 'a' and 'b' with respect to 'base'.
+	 */
+	return (unsigned)(a - base) < (unsigned)(b - base);
+}
+
+/*
+ * We might be racing with someone else trying to set pid_ns->last_pid.
+ * We want the winner to have the "later" value, because if the
+ * "earlier" value prevails, then a pid may get reused immediately.
+ *
+ * Since pids rollover, it is not sufficient to just pick the bigger
+ * value.  We have to consider where we started counting from.
+ *
+ * 'base' is the value of pid_ns->last_pid that we observed when
+ * we started looking for a pid.
+ *
+ * 'pid' is the pid that we eventually found.
+ */
+static void set_last_pid(struct pid_namespace *pid_ns, int base, int pid)
+{
+	int prev;
+	int last_write = base;
+	do {
+		prev = last_write;
+		last_write = cmpxchg(&pid_ns->last_pid, prev, pid);
+	} while ((prev != last_write) && (pid_before(base, last_write, pid)));
+}
+
 static int alloc_pidmap(struct pid_namespace *pid_ns)
 {
 	int i, offset, max_scan, pid, last = pid_ns->last_pid;
@@ -154,7 +191,7 @@ static int alloc_pidmap(struct pid_namespace *pid_ns)
 			do {
 				if (!test_and_set_bit(offset, map->page)) {
 					atomic_dec(&map->nr_free);
-					pid_ns->last_pid = pid;
+					set_last_pid(pid_ns, last, pid);
 					return pid;
 				}
 				offset = find_next_offset(map, offset);

commit 72680a191b934377430032f93af15ef50aafb3a8
Author: Hedi Berriche <hedi@sgi.com>
Date:   Wed May 26 14:44:06 2010 -0700

    pids: increase pid_max based on num_possible_cpus
    
    On a system with a substantial number of processors, the early default
    pid_max of 32k will not be enough.  A system with 1664 CPU's, there are
    25163 processes started before the login prompt.  It's estimated that with
    2048 CPU's we will pass the 32k limit.  With 4096, we'll reach that limit
    very early during the boot cycle, and processes would stall waiting for an
    available pid.
    
    This patch increases the early maximum number of pids available, and
    increases the minimum number of pids that can be set during runtime.
    
    [akpm@linux-foundation.org: fix warnings]
    Signed-off-by: Hedi Berriche <hedi@sgi.com>
    Signed-off-by: Mike Travis <travis@sgi.com>
    Signed-off-by: Robin Holt <holt@sgi.com>
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Pavel Machek <pavel@ucw.cz>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Cc: Greg KH <gregkh@suse.de>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: John Stoffel <john@stoffel.org>
    Cc: Jack Steiner <steiner@sgi.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index aebb30d9c233..e9fd8c132d26 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -513,6 +513,13 @@ void __init pidhash_init(void)
 
 void __init pidmap_init(void)
 {
+	/* bump default and minimum pid_max based on number of cpus */
+	pid_max = min(pid_max_max, max_t(int, pid_max,
+				PIDS_PER_CPU_DEFAULT * num_possible_cpus()));
+	pid_max_min = max_t(int, pid_max_min,
+				PIDS_PER_CPU_MIN * num_possible_cpus());
+	pr_info("pid_max: default: %u minimum: %u\n", pid_max, pid_max_min);
+
 	init_pid_ns.pidmap[0].page = kzalloc(PAGE_SIZE, GFP_KERNEL);
 	/* Reserve PID 0. We never call free_pidmap(0) */
 	set_bit(0, init_pid_ns.pidmap[0].page);

commit 4e3eaddd142e2142c048c5052a0a9d2604fccfc6
Merge: 8655e7e3ddec b97c4bc16734
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Mar 13 14:43:01 2010 -0800

    Merge branch 'core-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'core-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      locking: Make sparse work with inline spinlocks and rwlocks
      x86/mce: Fix RCU lockdep splats
      rcu: Increase RCU CPU stall timeouts if PROVE_RCU
      ftrace: Replace read_barrier_depends() with rcu_dereference_raw()
      rcu: Suppress RCU lockdep warnings during early boot
      rcu, ftrace: Fix RCU lockdep splat in ftrace_perf_buf_prepare()
      rcu: Suppress __mpol_dup() false positive from RCU lockdep
      rcu: Make rcu_read_lock_sched_held() handle !PREEMPT
      rcu: Add control variables to lockdep_rcu_dereference() diagnostics
      rcu, cgroup: Relax the check in task_subsys_state() as early boot is now handled by lockdep-RCU
      rcu: Use wrapper function instead of exporting tasklist_lock
      sched, rcu: Fix rcu_dereference() for RCU-lockdep
      rcu: Make task_subsys_state() RCU-lockdep checks handle boot-time use
      rcu: Fix holdoff for accelerated GPs for last non-dynticked CPU
      x86/gart: Unexport gart_iommu_aperture
    
    Fix trivial conflicts in kernel/trace/ftrace.c

commit 9728e5d6e6c432ee8487c63ce6e479e2474d9945
Author: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
Date:   Fri Mar 5 13:42:56 2010 -0800

    kernel/pid.c: update comment on find_task_by_pid_ns
    
    tasklist_lock does protect the task and its pid, it can't go away.  The
    problem is that find_pid_ns() itself is unsafe without rcu lock, it can
    race with copy_process()->free_pid(any_pid).
    
    Protecting copy_process()->free_pid(any_pid) with tasklist_lock would make
    it possible to call find_task_by_pid_ns() under tasklist safely, but we
    don't do so because we are trying to get rid of the read_lock sites of
    tasklist_lock.
    
    Signed-off-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: "Paul E. McKenney" <paulmck@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index b08e697cd83f..86b296943e5f 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -376,7 +376,7 @@ struct task_struct *pid_task(struct pid *pid, enum pid_type type)
 EXPORT_SYMBOL(pid_task);
 
 /*
- * Must be called under rcu_read_lock() or with tasklist_lock read-held.
+ * Must be called under rcu_read_lock().
  */
 struct task_struct *find_task_by_pid_ns(pid_t nr, struct pid_namespace *ns)
 {

commit db1466b3e1bd1727375cdbfcbea4bcce2f860f61
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed Mar 3 07:46:56 2010 -0800

    rcu: Use wrapper function instead of exporting tasklist_lock
    
    Lockdep-RCU commit d11c563d exported tasklist_lock, which is not
    a good thing.  This patch instead exports a function that uses
    lockdep to check whether tasklist_lock is held.
    
    Suggested-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: laijs@cn.fujitsu.com
    Cc: dipankar@in.ibm.com
    Cc: mathieu.desnoyers@polymtl.ca
    Cc: josh@joshtriplett.org
    Cc: dvhltc@us.ibm.com
    Cc: niv@us.ibm.com
    Cc: peterz@infradead.org
    Cc: rostedt@goodmis.org
    Cc: Valdis.Kletnieks@vt.edu
    Cc: dhowells@redhat.com
    Cc: Christoph Hellwig <hch@lst.de>
    LKML-Reference: <1267631219-8713-1-git-send-email-paulmck@linux.vnet.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/pid.c b/kernel/pid.c
index b08e697cd83f..b6064405f367 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -367,7 +367,9 @@ struct task_struct *pid_task(struct pid *pid, enum pid_type type)
 	struct task_struct *result = NULL;
 	if (pid) {
 		struct hlist_node *first;
-		first = rcu_dereference_check(pid->tasks[type].first, rcu_read_lock_held() || lockdep_is_held(&tasklist_lock));
+		first = rcu_dereference_check(pid->tasks[type].first,
+					      rcu_read_lock_held() ||
+					      lockdep_tasklist_lock_is_held());
 		if (first)
 			result = hlist_entry(first, struct task_struct, pids[(type)].node);
 	}

commit d11c563dd20ff35da5652c3e1c989d9e10e1d6d0
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Feb 22 17:04:50 2010 -0800

    sched: Use lockdep-based checking on rcu_dereference()
    
    Update the rcu_dereference() usages to take advantage of the new
    lockdep-based checking.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: laijs@cn.fujitsu.com
    Cc: dipankar@in.ibm.com
    Cc: mathieu.desnoyers@polymtl.ca
    Cc: josh@joshtriplett.org
    Cc: dvhltc@us.ibm.com
    Cc: niv@us.ibm.com
    Cc: peterz@infradead.org
    Cc: rostedt@goodmis.org
    Cc: Valdis.Kletnieks@vt.edu
    Cc: dhowells@redhat.com
    LKML-Reference: <1266887105-1528-6-git-send-email-paulmck@linux.vnet.ibm.com>
    [ -v2: fix allmodconfig missing symbol export build failure on x86 ]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/pid.c b/kernel/pid.c
index 2e17c9c92cbe..b08e697cd83f 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -367,7 +367,7 @@ struct task_struct *pid_task(struct pid *pid, enum pid_type type)
 	struct task_struct *result = NULL;
 	if (pid) {
 		struct hlist_node *first;
-		first = rcu_dereference(pid->tasks[type].first);
+		first = rcu_dereference_check(pid->tasks[type].first, rcu_read_lock_held() || lockdep_is_held(&tasklist_lock));
 		if (first)
 			result = hlist_entry(first, struct task_struct, pids[(type)].node);
 	}

commit 417e315247ebc199d357855bb08d2a5264400565
Author: Andr Goddard Rosa <andre.goddard@gmail.com>
Date:   Tue Dec 15 16:47:40 2009 -0800

    pid: reduce code size by using a pointer to iterate over array
    
    It decreases code size by 16 bytes on my gcc 4.4.1 on Core 2:
      text    data     bss     dec     hex filename
      4314    2216       8    6538    198a kernel/pid.o-BEFORE
      4298    2216       8    6522    197a kernel/pid.o-AFTER
    
    Signed-off-by: Andr Goddard Rosa <andre.goddard@gmail.com>
    Cc: Pekka Enberg <penberg@cs.helsinki.fi>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 55fd5900bac8..2e17c9c92cbe 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -269,12 +269,11 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	for (type = 0; type < PIDTYPE_MAX; ++type)
 		INIT_HLIST_HEAD(&pid->tasks[type]);
 
+	upid = pid->numbers + ns->level;
 	spin_lock_irq(&pidmap_lock);
-	for (i = ns->level; i >= 0; i--) {
-		upid = &pid->numbers[i];
+	for ( ; upid >= pid->numbers; --upid)
 		hlist_add_head_rcu(&upid->pid_chain,
 				&pid_hash[pid_hashfn(upid->nr, upid->ns)]);
-	}
 	spin_unlock_irq(&pidmap_lock);
 
 out:

commit 7be6d991bca63bbcdc5bc3b09789f367a3486537
Author: Andr Goddard Rosa <andre.goddard@gmail.com>
Date:   Tue Dec 15 16:47:39 2009 -0800

    pid: tighten pidmap spinlock critical section by removing kfree()
    
    Avoid calling kfree() under pidmap spinlock, calling it afterwards.
    
    Normally kfree() is fast, but sometimes it can be slow, so avoid
    calling it under the spinlock if we can do it.
    
    Signed-off-by: Andr Goddard Rosa <andre.goddard@gmail.com>
    Cc: Pekka Enberg <penberg@cs.helsinki.fi>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index d3f722d20f9c..55fd5900bac8 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -141,11 +141,12 @@ static int alloc_pidmap(struct pid_namespace *pid_ns)
 			 * installing it:
 			 */
 			spin_lock_irq(&pidmap_lock);
-			if (map->page)
-				kfree(page);
-			else
+			if (!map->page) {
 				map->page = page;
+				page = NULL;
+			}
 			spin_unlock_irq(&pidmap_lock);
+			kfree(page);
 			if (unlikely(!map->page))
 				break;
 		}

commit 2c85f51d222ccdd8c401d77a36b723a89156810d
Author: Jan Beulich <JBeulich@novell.com>
Date:   Mon Sep 21 17:03:07 2009 -0700

    mm: also use alloc_large_system_hash() for the PID hash table
    
    This is being done by allowing boot time allocations to specify that they
    may want a sub-page sized amount of memory.
    
    Overall this seems more consistent with the other hash table allocations,
    and allows making two supposedly mm-only variables really mm-only
    (nr_{kernel,all}_pages).
    
    Signed-off-by: Jan Beulich <jbeulich@novell.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 31310b5d3f50..d3f722d20f9c 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -40,7 +40,7 @@
 #define pid_hashfn(nr, ns)	\
 	hash_long((unsigned long)nr + (unsigned long)ns, pidhash_shift)
 static struct hlist_head *pid_hash;
-static int pidhash_shift;
+static unsigned int pidhash_shift = 4;
 struct pid init_struct_pid = INIT_STRUCT_PID;
 
 int pid_max = PID_MAX_DEFAULT;
@@ -499,19 +499,12 @@ struct pid *find_ge_pid(int nr, struct pid_namespace *ns)
 void __init pidhash_init(void)
 {
 	int i, pidhash_size;
-	unsigned long megabytes = nr_kernel_pages >> (20 - PAGE_SHIFT);
 
-	pidhash_shift = max(4, fls(megabytes * 4));
-	pidhash_shift = min(12, pidhash_shift);
+	pid_hash = alloc_large_system_hash("PID", sizeof(*pid_hash), 0, 18,
+					   HASH_EARLY | HASH_SMALL,
+					   &pidhash_shift, NULL, 4096);
 	pidhash_size = 1 << pidhash_shift;
 
-	printk("PID hash table entries: %d (order: %d, %Zd bytes)\n",
-		pidhash_size, pidhash_shift,
-		pidhash_size * sizeof(struct hlist_head));
-
-	pid_hash = alloc_bootmem(pidhash_size *	sizeof(*(pid_hash)));
-	if (!pid_hash)
-		panic("Could not alloc pidhash!\n");
 	for (i = 0; i < pidhash_size; i++)
 		INIT_HLIST_HEAD(&pid_hash[i]);
 }

commit 264ef8a904943ed7d0b04fa958894d7a5c2b2c61
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Tue Jul 7 10:33:01 2009 +0100

    kmemleak: Remove alloc_bootmem annotations introduced in the past
    
    kmemleak_alloc() calls were added in some places where alloc_bootmem was
    called. Since now kmemleak tracks bootmem allocations, these explicit
    calls should be run.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Acked-by: Pekka Enberg <penberg@cs.helsinki.fi>

diff --git a/kernel/pid.c b/kernel/pid.c
index 5fa1db48d8b7..31310b5d3f50 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -36,7 +36,6 @@
 #include <linux/pid_namespace.h>
 #include <linux/init_task.h>
 #include <linux/syscalls.h>
-#include <linux/kmemleak.h>
 
 #define pid_hashfn(nr, ns)	\
 	hash_long((unsigned long)nr + (unsigned long)ns, pidhash_shift)
@@ -513,12 +512,6 @@ void __init pidhash_init(void)
 	pid_hash = alloc_bootmem(pidhash_size *	sizeof(*(pid_hash)));
 	if (!pid_hash)
 		panic("Could not alloc pidhash!\n");
-	/*
-	 * pid_hash contains references to allocated struct pid objects and it
-	 * must be scanned by kmemleak to avoid false positives.
-	 */
-	kmemleak_alloc(pid_hash, pidhash_size *	sizeof(*(pid_hash)), 0,
-		       GFP_KERNEL);
 	for (i = 0; i < pidhash_size; i++)
 		INIT_HLIST_HEAD(&pid_hash[i]);
 }

commit 12de38b186c2af97bf0b4a1f907f766df46b1def
Author: Catalin Marinas <catalin.marinas@arm.com>
Date:   Mon Jun 29 17:13:55 2009 +0100

    kmemleak: Inform kmemleak about pid_hash
    
    Kmemleak does not track alloc_bootmem calls but the pid_hash allocated
    in pidhash_init() would need to be scanned as it contains pointers to
    struct pid objects.
    
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

diff --git a/kernel/pid.c b/kernel/pid.c
index 31310b5d3f50..5fa1db48d8b7 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -36,6 +36,7 @@
 #include <linux/pid_namespace.h>
 #include <linux/init_task.h>
 #include <linux/syscalls.h>
+#include <linux/kmemleak.h>
 
 #define pid_hashfn(nr, ns)	\
 	hash_long((unsigned long)nr + (unsigned long)ns, pidhash_shift)
@@ -512,6 +513,12 @@ void __init pidhash_init(void)
 	pid_hash = alloc_bootmem(pidhash_size *	sizeof(*(pid_hash)));
 	if (!pid_hash)
 		panic("Could not alloc pidhash!\n");
+	/*
+	 * pid_hash contains references to allocated struct pid objects and it
+	 * must be scanned by kmemleak to avoid false positives.
+	 */
+	kmemleak_alloc(pid_hash, pidhash_size *	sizeof(*(pid_hash)), 0,
+		       GFP_KERNEL);
 	for (i = 0; i < pidhash_size; i++)
 		INIT_HLIST_HEAD(&pid_hash[i]);
 }

commit 17f98dcf6010a1cfd25d179fd0ce77d3dc2685c3
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jun 17 16:27:51 2009 -0700

    pids: clean up find_task_by_pid variants
    
    find_task_by_pid_type_ns is only used to implement find_task_by_vpid and
    find_task_by_pid_ns, but both of them pass PIDTYPE_PID as first argument.
    So just fold find_task_by_pid_type_ns into find_task_by_pid_ns and use
    find_task_by_pid_ns to implement find_task_by_vpid.
    
    While we're at it also remove the exports for find_task_by_pid_ns and
    find_task_by_vpid - we don't have any modular callers left as the only
    modular caller of he old pre pid namespace find_task_by_pid (gfs2) was
    switched to pid_task which operates on a struct pid pointer instead of a
    pid_t.  Given the confusion about pid_t values vs namespace that's
    generally the better option anyway and I think we're better of restricting
    modules to do it that way.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index b2e5f78fd281..31310b5d3f50 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -378,26 +378,15 @@ EXPORT_SYMBOL(pid_task);
 /*
  * Must be called under rcu_read_lock() or with tasklist_lock read-held.
  */
-struct task_struct *find_task_by_pid_type_ns(int type, int nr,
-		struct pid_namespace *ns)
+struct task_struct *find_task_by_pid_ns(pid_t nr, struct pid_namespace *ns)
 {
-	return pid_task(find_pid_ns(nr, ns), type);
+	return pid_task(find_pid_ns(nr, ns), PIDTYPE_PID);
 }
 
-EXPORT_SYMBOL(find_task_by_pid_type_ns);
-
 struct task_struct *find_task_by_vpid(pid_t vnr)
 {
-	return find_task_by_pid_type_ns(PIDTYPE_PID, vnr,
-			current->nsproxy->pid_ns);
-}
-EXPORT_SYMBOL(find_task_by_vpid);
-
-struct task_struct *find_task_by_pid_ns(pid_t nr, struct pid_namespace *ns)
-{
-	return find_task_by_pid_type_ns(PIDTYPE_PID, nr, ns);
+	return find_task_by_pid_ns(vnr, current->nsproxy->pid_ns);
 }
-EXPORT_SYMBOL(find_task_by_pid_ns);
 
 struct pid *get_task_pid(struct task_struct *task, enum pid_type type)
 {

commit 52ee2dfdd4f51cf422ea6a96a0846dc94244aa37
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Apr 2 16:58:38 2009 -0700

    pids: refactor vnr/nr_ns helpers to make them safe
    
    Inho, the safety rules for vnr/nr_ns helpers are horrible and buggy.
    
    task_pid_nr_ns(task) needs rcu/tasklist depending on task == current.
    
    As for "special" pids, vnr/nr_ns helpers always need rcu.  However, if
    task != current, they are unsafe even under rcu lock, we can't trust
    task->group_leader without the special checks.
    
    And almost every helper has a callsite which needs a fix.
    
    Also, it is a bit annoying that the implementations of, say,
    task_pgrp_vnr() and task_pgrp_nr_ns() are not "symmetrical".
    
    This patch introduces the new helper, __task_pid_nr_ns(), which is always
    safe to use, and turns all other helpers into the trivial wrappers.
    
    After this I'll send another patch which converts task_tgid_xxx() as well,
    they're are a bit special.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Louis Rilling <Louis.Rilling@kerlabs.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 6628abcc520e..b2e5f78fd281 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -452,11 +452,24 @@ pid_t pid_vnr(struct pid *pid)
 }
 EXPORT_SYMBOL_GPL(pid_vnr);
 
-pid_t task_pid_nr_ns(struct task_struct *tsk, struct pid_namespace *ns)
+pid_t __task_pid_nr_ns(struct task_struct *task, enum pid_type type,
+			struct pid_namespace *ns)
 {
-	return pid_nr_ns(task_pid(tsk), ns);
+	pid_t nr = 0;
+
+	rcu_read_lock();
+	if (!ns)
+		ns = current->nsproxy->pid_ns;
+	if (likely(pid_alive(task))) {
+		if (type != PIDTYPE_PID)
+			task = task->group_leader;
+		nr = pid_nr_ns(task->pids[type].pid, ns);
+	}
+	rcu_read_unlock();
+
+	return nr;
 }
-EXPORT_SYMBOL(task_pid_nr_ns);
+EXPORT_SYMBOL(__task_pid_nr_ns);
 
 pid_t task_tgid_nr_ns(struct task_struct *tsk, struct pid_namespace *ns)
 {
@@ -464,18 +477,6 @@ pid_t task_tgid_nr_ns(struct task_struct *tsk, struct pid_namespace *ns)
 }
 EXPORT_SYMBOL(task_tgid_nr_ns);
 
-pid_t task_pgrp_nr_ns(struct task_struct *tsk, struct pid_namespace *ns)
-{
-	return pid_nr_ns(task_pgrp(tsk), ns);
-}
-EXPORT_SYMBOL(task_pgrp_nr_ns);
-
-pid_t task_session_nr_ns(struct task_struct *tsk, struct pid_namespace *ns)
-{
-	return pid_nr_ns(task_session(tsk), ns);
-}
-EXPORT_SYMBOL(task_session_nr_ns);
-
 struct pid_namespace *task_active_pid_ns(struct task_struct *tsk)
 {
 	return ns_of_pid(task_pid(tsk));

commit 2ae448efc87df6d328f5835969076c7f9fce59c3
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Apr 2 16:58:36 2009 -0700

    pids: improve get_task_pid() to fix the unsafe sys_wait4()->task_pgrp()
    
    sys_wait4() does get_pid(task_pgrp(current)), this is not safe.  We can
    add rcu lock/unlock around, but we already have get_task_pid() which can
    be improved to handle the special pids in more reliable manner.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Louis Rilling <Louis.Rilling@kerlabs.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 1b3586fe753a..6628abcc520e 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -403,6 +403,8 @@ struct pid *get_task_pid(struct task_struct *task, enum pid_type type)
 {
 	struct pid *pid;
 	rcu_read_lock();
+	if (type != PIDTYPE_PID)
+		task = task->group_leader;
 	pid = get_pid(task->pids[type].pid);
 	rcu_read_unlock();
 	return pid;

commit 61bce0f1371cfff497fe85594fd39d1a0b15ebe1
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Jan 7 18:08:49 2009 -0800

    pid: generalize task_active_pid_ns
    
    Currently task_active_pid_ns is not safe to call after a task becomes a
    zombie and exit_task_namespaces is called, as nsproxy becomes NULL.  By
    reading the pid namespace from the pid of the task we can trivially solve
    this problem at the cost of one extra memory read in what should be the
    same cacheline as we read the namespace from.
    
    When moving things around I have made task_active_pid_ns out of line
    because keeping it in pid_namespace.h would require adding includes of
    pid.h and sched.h that I don't think we want.
    
    This change does make task_active_pid_ns unsafe to call during
    copy_process until we attach a pid on the task_struct which seems to be a
    reasonable trade off.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Bastian Blank <bastian@waldi.eu.org>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: Nadia Derbey <Nadia.Derbey@bull.net>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index af9224cdd6c0..1b3586fe753a 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -474,6 +474,12 @@ pid_t task_session_nr_ns(struct task_struct *tsk, struct pid_namespace *ns)
 }
 EXPORT_SYMBOL(task_session_nr_ns);
 
+struct pid_namespace *task_active_pid_ns(struct task_struct *tsk)
+{
+	return ns_of_pid(task_pid(tsk));
+}
+EXPORT_SYMBOL_GPL(task_active_pid_ns);
+
 /*
  * Used by proc to find the first pid that is greater than or equal to nr.
  *

commit 025dfdafe77f20b3890981a394774baab7b9c827
Author: Frederik Schwarzer <schwarzerf@gmail.com>
Date:   Thu Oct 16 19:02:37 2008 +0200

    trivial: fix then -> than typos in comments and documentation
    
    - (better, more, bigger ...) then -> (...) than
    
    Signed-off-by: Frederik Schwarzer <schwarzerf@gmail.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/kernel/pid.c b/kernel/pid.c
index 064e76afa507..af9224cdd6c0 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -475,7 +475,7 @@ pid_t task_session_nr_ns(struct task_struct *tsk, struct pid_namespace *ns)
 EXPORT_SYMBOL(task_session_nr_ns);
 
 /*
- * Used by proc to find the first pid that is greater then or equal to nr.
+ * Used by proc to find the first pid that is greater than or equal to nr.
  *
  * If there is a pid at nr this function is exactly the same as find_pid_ns.
  */

commit e49859e71e0318b564de1546bdc30fab738f9deb
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Fri Jul 25 01:48:36 2008 -0700

    pidns: remove now unused find_pid function.
    
    This one had the only users so far - the kill_proc, which is removed, so
    drop this (invalid in namespaced world) call too.
    
    And of course - erase all references on it from comments.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 753fd90d9ec1..064e76afa507 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -309,12 +309,6 @@ struct pid *find_vpid(int nr)
 }
 EXPORT_SYMBOL_GPL(find_vpid);
 
-struct pid *find_pid(int nr)
-{
-	return find_pid_ns(nr, &init_pid_ns);
-}
-EXPORT_SYMBOL_GPL(find_pid);
-
 /*
  * attach_pid() must be called with the tasklist_lock write-held.
  */
@@ -483,7 +477,7 @@ EXPORT_SYMBOL(task_session_nr_ns);
 /*
  * Used by proc to find the first pid that is greater then or equal to nr.
  *
- * If there is a pid at nr this function is exactly the same as find_pid.
+ * If there is a pid at nr this function is exactly the same as find_pid_ns.
  */
 struct pid *find_ge_pid(int nr, struct pid_namespace *ns)
 {

commit 339caf2a224fc9af0f01686bf287dda32c6efca6
Author: David Sterba <dsterba@suse.cz>
Date:   Fri Jul 25 01:48:31 2008 -0700

    proc: misplaced export of find_get_pid
    
    Move EXPORT_SYMBOL right after the func
    
    Signed-off-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 30bd5d4b2ac7..753fd90d9ec1 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -435,6 +435,7 @@ struct pid *find_get_pid(pid_t nr)
 
 	return pid;
 }
+EXPORT_SYMBOL_GPL(find_get_pid);
 
 pid_t pid_nr_ns(struct pid *pid, struct pid_namespace *ns)
 {
@@ -497,7 +498,6 @@ struct pid *find_ge_pid(int nr, struct pid_namespace *ns)
 
 	return pid;
 }
-EXPORT_SYMBOL_GPL(find_get_pid);
 
 /*
  * The pid hash table is scaled according to the amount of memory in the

commit 82524746c27fa418c250a56dd7606b9d3fc79826
Author: Franck Bui-Huu <fbuihuu@gmail.com>
Date:   Mon May 12 21:21:05 2008 +0200

    rcu: split list.h and move rcu-protected lists into rculist.h
    
    Move rcu-protected lists from list.h into a new header file rculist.h.
    
    This is done because list are a very used primitive structure all over the
    kernel and it's currently impossible to include other header files in this
    list.h without creating some circular dependencies.
    
    For example, list.h implements rcu-protected list and uses rcu_dereference()
    without including rcupdate.h.  It actually compiles because users of
    rcu_dereference() are macros.  Others RCU functions could be used too but
    aren't probably because of this.
    
    Therefore this patch creates rculist.h which includes rcupdates without to
    many changes/troubles.
    
    Signed-off-by: Franck Bui-Huu <fbuihuu@gmail.com>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Josh Triplett <josh@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/pid.c b/kernel/pid.c
index 20d59fa2d493..30bd5d4b2ac7 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -30,6 +30,7 @@
 #include <linux/module.h>
 #include <linux/slab.h>
 #include <linux/init.h>
+#include <linux/rculist.h>
 #include <linux/bootmem.h>
 #include <linux/hash.h>
 #include <linux/pid_namespace.h>

commit 24336eaeecea860b2a82530e07c80bc7e0558b73
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:54:26 2008 -0700

    pids: introduce change_pid() helper
    
    Based on Eric W. Biederman's idea.
    
    Without tasklist_lock held task_session()/task_pgrp() can return NULL if the
    caller races with setprgp()/setsid() which does detach_pid() + attach_pid().
    This can happen even if task == current.
    
    Intoduce the new helper, change_pid(), which should be used instead.  This way
    the caller always sees the special pid != NULL, either old or new.
    
    Also change the prototype of attach_pid(), it always returns 0 and nobody
    check the returned value.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc:  "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index e9a31d362b28..20d59fa2d493 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -317,7 +317,7 @@ EXPORT_SYMBOL_GPL(find_pid);
 /*
  * attach_pid() must be called with the tasklist_lock write-held.
  */
-int attach_pid(struct task_struct *task, enum pid_type type,
+void attach_pid(struct task_struct *task, enum pid_type type,
 		struct pid *pid)
 {
 	struct pid_link *link;
@@ -325,11 +325,10 @@ int attach_pid(struct task_struct *task, enum pid_type type,
 	link = &task->pids[type];
 	link->pid = pid;
 	hlist_add_head_rcu(&link->node, &pid->tasks[type]);
-
-	return 0;
 }
 
-void detach_pid(struct task_struct *task, enum pid_type type)
+static void __change_pid(struct task_struct *task, enum pid_type type,
+			struct pid *new)
 {
 	struct pid_link *link;
 	struct pid *pid;
@@ -339,7 +338,7 @@ void detach_pid(struct task_struct *task, enum pid_type type)
 	pid = link->pid;
 
 	hlist_del_rcu(&link->node);
-	link->pid = NULL;
+	link->pid = new;
 
 	for (tmp = PIDTYPE_MAX; --tmp >= 0; )
 		if (!hlist_empty(&pid->tasks[tmp]))
@@ -348,6 +347,18 @@ void detach_pid(struct task_struct *task, enum pid_type type)
 	free_pid(pid);
 }
 
+void detach_pid(struct task_struct *task, enum pid_type type)
+{
+	__change_pid(task, type, NULL);
+}
+
+void change_pid(struct task_struct *task, enum pid_type type,
+		struct pid *pid)
+{
+	__change_pid(task, type, pid);
+	attach_pid(task, type, pid);
+}
+
 /* transfer_pid is an optimization of attach_pid(new), detach_pid(old) */
 void transfer_pid(struct task_struct *old, struct task_struct *new,
 			   enum pid_type type)

commit 65450cebc6a2efde80ed45514f727e6e4dc1eafd
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:54:25 2008 -0700

    pids: de_thread: don't clear session/pgrp pids for the old leader
    
    Based on Eric W. Biederman's idea.
    
    Unless task == current, without tasklist_lock held task_session()/task_pgrp()
    can return NULL if the caller races with de_thread() which switches the group
    leader.
    
    Change transfer_pid() to not clear old->pids[type].pid for the old leader.
    This means that its .pid can point to "nowhere", but this is already true for
    sub-threads, and the old leader is not group_leader() any longer.  IOW, with
    or without this change we can't trust task's special pids unless it is the
    group leader.
    
    With this change the following code
    
            rcu_read_lock();
            task = find_task_by_xxx();
            do_something(task_pgrp(task), task_session(task));
            rcu_read_unlock();
    
    can't race with exec and hit the NULL pid.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc:  "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index a9ae9f7fb229..e9a31d362b28 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -354,7 +354,6 @@ void transfer_pid(struct task_struct *old, struct task_struct *new,
 {
 	new->pids[type].pid = old->pids[type].pid;
 	hlist_replace_rcu(&old->pids[type].node, &new->pids[type].node);
-	old->pids[type].pid = NULL;
 }
 
 struct task_struct *pid_task(struct pid *pid, enum pid_type type)

commit 5cd204550b1a006f2b0c986b0e0f53220ebfd391
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Wed Apr 30 00:54:24 2008 -0700

    Deprecate find_task_by_pid()
    
    There are some places that are known to operate on tasks'
    global pids only:
    
    * the rest_init() call (called on boot)
    * the kgdb's getthread
    * the create_kthread() (since the kthread is run in init ns)
    
    So use the find_task_by_pid_ns(..., &init_pid_ns) there
    and schedule the find_task_by_pid for removal.
    
    [sukadev@us.ibm.com: Fix warning in kernel/pid.c]
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index b322cdf401bf..a9ae9f7fb229 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -381,12 +381,6 @@ struct task_struct *find_task_by_pid_type_ns(int type, int nr,
 
 EXPORT_SYMBOL(find_task_by_pid_type_ns);
 
-struct task_struct *find_task_by_pid(pid_t nr)
-{
-	return find_task_by_pid_type_ns(PIDTYPE_PID, nr, &init_pid_ns);
-}
-EXPORT_SYMBOL(find_task_by_pid);
-
 struct task_struct *find_task_by_vpid(pid_t vnr)
 {
 	return find_task_by_pid_type_ns(PIDTYPE_PID, vnr,

commit b7127aa4547d8cc8a5b569631e2b6ef613af1bb7
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:54:22 2008 -0700

    free_pidmap: turn it into free_pidmap(struct upid *)
    
    The callers of free_pidmap() pass 2 members of "struct upid", we can just
    pass "struct upid *" instead.  Shaves off 10 bytes from pid.o.
    
    Also, simplify the alloc_pid's "out_free:" error path a little bit.  This
    way it looks more clear which subset of pid->numbers[] we are freeing.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc :Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 477691576b33..b322cdf401bf 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -111,10 +111,11 @@ EXPORT_SYMBOL(is_container_init);
 
 static  __cacheline_aligned_in_smp DEFINE_SPINLOCK(pidmap_lock);
 
-static void free_pidmap(struct pid_namespace *pid_ns, int pid)
+static void free_pidmap(struct upid *upid)
 {
-	struct pidmap *map = pid_ns->pidmap + pid / BITS_PER_PAGE;
-	int offset = pid & BITS_PER_PAGE_MASK;
+	int nr = upid->nr;
+	struct pidmap *map = upid->ns->pidmap + nr / BITS_PER_PAGE;
+	int offset = nr & BITS_PER_PAGE_MASK;
 
 	clear_bit(offset, map->page);
 	atomic_inc(&map->nr_free);
@@ -232,7 +233,7 @@ void free_pid(struct pid *pid)
 	spin_unlock_irqrestore(&pidmap_lock, flags);
 
 	for (i = 0; i <= pid->level; i++)
-		free_pidmap(pid->numbers[i].ns, pid->numbers[i].nr);
+		free_pidmap(pid->numbers + i);
 
 	call_rcu(&pid->rcu, delayed_put_pid);
 }
@@ -278,8 +279,8 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	return pid;
 
 out_free:
-	for (i++; i <= ns->level; i++)
-		free_pidmap(pid->numbers[i].ns, pid->numbers[i].nr);
+	while (++i <= ns->level)
+		free_pidmap(pid->numbers + i);
 
 	kmem_cache_free(ns->pid_cachep, pid);
 	pid = NULL;

commit 7ad5b3a505e68cfdc342933d6e0fc0eaa5e0a4f7
Author: Harvey Harrison <harvey.harrison@gmail.com>
Date:   Fri Feb 8 04:19:53 2008 -0800

    kernel: remove fastcall in kernel/*
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Harvey Harrison <harvey.harrison@gmail.com>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index a32859c4a3cd..477691576b33 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -111,7 +111,7 @@ EXPORT_SYMBOL(is_container_init);
 
 static  __cacheline_aligned_in_smp DEFINE_SPINLOCK(pidmap_lock);
 
-static fastcall void free_pidmap(struct pid_namespace *pid_ns, int pid)
+static void free_pidmap(struct pid_namespace *pid_ns, int pid)
 {
 	struct pidmap *map = pid_ns->pidmap + pid / BITS_PER_PAGE;
 	int offset = pid & BITS_PER_PAGE_MASK;
@@ -198,7 +198,7 @@ int next_pidmap(struct pid_namespace *pid_ns, int last)
 	return -1;
 }
 
-fastcall void put_pid(struct pid *pid)
+void put_pid(struct pid *pid)
 {
 	struct pid_namespace *ns;
 
@@ -220,7 +220,7 @@ static void delayed_put_pid(struct rcu_head *rhp)
 	put_pid(pid);
 }
 
-fastcall void free_pid(struct pid *pid)
+void free_pid(struct pid *pid)
 {
 	/* We can be called with write_lock_irq(&tasklist_lock) held */
 	int i;
@@ -286,7 +286,7 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	goto out;
 }
 
-struct pid * fastcall find_pid_ns(int nr, struct pid_namespace *ns)
+struct pid *find_pid_ns(int nr, struct pid_namespace *ns)
 {
 	struct hlist_node *elem;
 	struct upid *pnr;
@@ -316,7 +316,7 @@ EXPORT_SYMBOL_GPL(find_pid);
 /*
  * attach_pid() must be called with the tasklist_lock write-held.
  */
-int fastcall attach_pid(struct task_struct *task, enum pid_type type,
+int attach_pid(struct task_struct *task, enum pid_type type,
 		struct pid *pid)
 {
 	struct pid_link *link;
@@ -328,7 +328,7 @@ int fastcall attach_pid(struct task_struct *task, enum pid_type type,
 	return 0;
 }
 
-void fastcall detach_pid(struct task_struct *task, enum pid_type type)
+void detach_pid(struct task_struct *task, enum pid_type type)
 {
 	struct pid_link *link;
 	struct pid *pid;
@@ -348,7 +348,7 @@ void fastcall detach_pid(struct task_struct *task, enum pid_type type)
 }
 
 /* transfer_pid is an optimization of attach_pid(new), detach_pid(old) */
-void fastcall transfer_pid(struct task_struct *old, struct task_struct *new,
+void transfer_pid(struct task_struct *old, struct task_struct *new,
 			   enum pid_type type)
 {
 	new->pids[type].pid = old->pids[type].pid;
@@ -356,7 +356,7 @@ void fastcall transfer_pid(struct task_struct *old, struct task_struct *new,
 	old->pids[type].pid = NULL;
 }
 
-struct task_struct * fastcall pid_task(struct pid *pid, enum pid_type type)
+struct task_struct *pid_task(struct pid *pid, enum pid_type type)
 {
 	struct task_struct *result = NULL;
 	if (pid) {
@@ -408,7 +408,7 @@ struct pid *get_task_pid(struct task_struct *task, enum pid_type type)
 	return pid;
 }
 
-struct task_struct *fastcall get_pid_task(struct pid *pid, enum pid_type type)
+struct task_struct *get_pid_task(struct pid *pid, enum pid_type type)
 {
 	struct task_struct *result;
 	rcu_read_lock();

commit 44c4e1b2581f7273ab14ef30b6430618801c57b1
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Feb 8 04:19:15 2008 -0800

    pid: Extend/Fix pid_vnr
    
    pid_vnr returns the user space pid with respect to the pid namespace the
    struct pid was allocated in.  What we want before we return a pid to user
    space is the user space pid with respect to the pid namespace of current.
    
    pid_vnr is a very nice optimization but because it isn't quite what we want
    it is easy to use pid_vnr at times when we aren't certain the struct pid
    was allocated in our pid namespace.
    
    Currently this describes at least tiocgpgrp and tiocgsid in ttyio.c the
    parent process reported in the core dumps and the parent process in
    get_signal_to_deliver.
    
    So unless the performance impact is huge having an interface that does what
    we want instead of always what we want should be much more reliable and
    much less error prone.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Acked-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 939746fb4ce7..a32859c4a3cd 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -443,6 +443,12 @@ pid_t pid_nr_ns(struct pid *pid, struct pid_namespace *ns)
 	return nr;
 }
 
+pid_t pid_vnr(struct pid *pid)
+{
+	return pid_nr_ns(pid, current->nsproxy->pid_ns);
+}
+EXPORT_SYMBOL_GPL(pid_vnr);
+
 pid_t task_pid_nr_ns(struct task_struct *tsk, struct pid_namespace *ns)
 {
 	return pid_nr_ns(task_pid(tsk), ns);

commit 74bd59bb39eb08b4379e2590c5f160748d83f812
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Fri Feb 8 04:18:24 2008 -0800

    namespaces: cleanup the code managed with PID_NS option
    
    Just like with the user namespaces, move the namespace management code into
    the separate .c file and mark the (already existing) PID_NS option as "depend
    on NAMESPACES"
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: Kirill Korotaev <dev@sw.ru>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 3b30bccdfcdc..939746fb4ce7 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -41,7 +41,6 @@
 static struct hlist_head *pid_hash;
 static int pidhash_shift;
 struct pid init_struct_pid = INIT_STRUCT_PID;
-static struct kmem_cache *pid_ns_cachep;
 
 int pid_max = PID_MAX_DEFAULT;
 
@@ -181,7 +180,7 @@ static int alloc_pidmap(struct pid_namespace *pid_ns)
 	return -1;
 }
 
-static int next_pidmap(struct pid_namespace *pid_ns, int last)
+int next_pidmap(struct pid_namespace *pid_ns, int last)
 {
 	int offset;
 	struct pidmap *map, *end;
@@ -488,180 +487,6 @@ struct pid *find_ge_pid(int nr, struct pid_namespace *ns)
 }
 EXPORT_SYMBOL_GPL(find_get_pid);
 
-struct pid_cache {
-	int nr_ids;
-	char name[16];
-	struct kmem_cache *cachep;
-	struct list_head list;
-};
-
-static LIST_HEAD(pid_caches_lh);
-static DEFINE_MUTEX(pid_caches_mutex);
-
-/*
- * creates the kmem cache to allocate pids from.
- * @nr_ids: the number of numerical ids this pid will have to carry
- */
-
-static struct kmem_cache *create_pid_cachep(int nr_ids)
-{
-	struct pid_cache *pcache;
-	struct kmem_cache *cachep;
-
-	mutex_lock(&pid_caches_mutex);
-	list_for_each_entry (pcache, &pid_caches_lh, list)
-		if (pcache->nr_ids == nr_ids)
-			goto out;
-
-	pcache = kmalloc(sizeof(struct pid_cache), GFP_KERNEL);
-	if (pcache == NULL)
-		goto err_alloc;
-
-	snprintf(pcache->name, sizeof(pcache->name), "pid_%d", nr_ids);
-	cachep = kmem_cache_create(pcache->name,
-			sizeof(struct pid) + (nr_ids - 1) * sizeof(struct upid),
-			0, SLAB_HWCACHE_ALIGN, NULL);
-	if (cachep == NULL)
-		goto err_cachep;
-
-	pcache->nr_ids = nr_ids;
-	pcache->cachep = cachep;
-	list_add(&pcache->list, &pid_caches_lh);
-out:
-	mutex_unlock(&pid_caches_mutex);
-	return pcache->cachep;
-
-err_cachep:
-	kfree(pcache);
-err_alloc:
-	mutex_unlock(&pid_caches_mutex);
-	return NULL;
-}
-
-#ifdef CONFIG_PID_NS
-static struct pid_namespace *create_pid_namespace(int level)
-{
-	struct pid_namespace *ns;
-	int i;
-
-	ns = kmem_cache_alloc(pid_ns_cachep, GFP_KERNEL);
-	if (ns == NULL)
-		goto out;
-
-	ns->pidmap[0].page = kzalloc(PAGE_SIZE, GFP_KERNEL);
-	if (!ns->pidmap[0].page)
-		goto out_free;
-
-	ns->pid_cachep = create_pid_cachep(level + 1);
-	if (ns->pid_cachep == NULL)
-		goto out_free_map;
-
-	kref_init(&ns->kref);
-	ns->last_pid = 0;
-	ns->child_reaper = NULL;
-	ns->level = level;
-
-	set_bit(0, ns->pidmap[0].page);
-	atomic_set(&ns->pidmap[0].nr_free, BITS_PER_PAGE - 1);
-
-	for (i = 1; i < PIDMAP_ENTRIES; i++) {
-		ns->pidmap[i].page = 0;
-		atomic_set(&ns->pidmap[i].nr_free, BITS_PER_PAGE);
-	}
-
-	return ns;
-
-out_free_map:
-	kfree(ns->pidmap[0].page);
-out_free:
-	kmem_cache_free(pid_ns_cachep, ns);
-out:
-	return ERR_PTR(-ENOMEM);
-}
-
-static void destroy_pid_namespace(struct pid_namespace *ns)
-{
-	int i;
-
-	for (i = 0; i < PIDMAP_ENTRIES; i++)
-		kfree(ns->pidmap[i].page);
-	kmem_cache_free(pid_ns_cachep, ns);
-}
-
-struct pid_namespace *copy_pid_ns(unsigned long flags, struct pid_namespace *old_ns)
-{
-	struct pid_namespace *new_ns;
-
-	BUG_ON(!old_ns);
-	new_ns = get_pid_ns(old_ns);
-	if (!(flags & CLONE_NEWPID))
-		goto out;
-
-	new_ns = ERR_PTR(-EINVAL);
-	if (flags & CLONE_THREAD)
-		goto out_put;
-
-	new_ns = create_pid_namespace(old_ns->level + 1);
-	if (!IS_ERR(new_ns))
-		new_ns->parent = get_pid_ns(old_ns);
-
-out_put:
-	put_pid_ns(old_ns);
-out:
-	return new_ns;
-}
-
-void free_pid_ns(struct kref *kref)
-{
-	struct pid_namespace *ns, *parent;
-
-	ns = container_of(kref, struct pid_namespace, kref);
-
-	parent = ns->parent;
-	destroy_pid_namespace(ns);
-
-	if (parent != NULL)
-		put_pid_ns(parent);
-}
-#endif /* CONFIG_PID_NS */
-
-void zap_pid_ns_processes(struct pid_namespace *pid_ns)
-{
-	int nr;
-	int rc;
-
-	/*
-	 * The last thread in the cgroup-init thread group is terminating.
-	 * Find remaining pid_ts in the namespace, signal and wait for them
-	 * to exit.
-	 *
-	 * Note:  This signals each threads in the namespace - even those that
-	 * 	  belong to the same thread group, To avoid this, we would have
-	 * 	  to walk the entire tasklist looking a processes in this
-	 * 	  namespace, but that could be unnecessarily expensive if the
-	 * 	  pid namespace has just a few processes. Or we need to
-	 * 	  maintain a tasklist for each pid namespace.
-	 *
-	 */
-	read_lock(&tasklist_lock);
-	nr = next_pidmap(pid_ns, 1);
-	while (nr > 0) {
-		kill_proc_info(SIGKILL, SEND_SIG_PRIV, nr);
-		nr = next_pidmap(pid_ns, nr);
-	}
-	read_unlock(&tasklist_lock);
-
-	do {
-		clear_thread_flag(TIF_SIGPENDING);
-		rc = sys_wait4(-1, NULL, __WALL, NULL);
-	} while (rc != -ECHILD);
-
-
-	/* Child reaper for the pid namespace is going away */
-	pid_ns->child_reaper = NULL;
-	return;
-}
-
 /*
  * The pid hash table is scaled according to the amount of memory in the
  * machine.  From a minimum of 16 slots up to 4096 slots at one gigabyte or
@@ -694,9 +519,6 @@ void __init pidmap_init(void)
 	set_bit(0, init_pid_ns.pidmap[0].page);
 	atomic_dec(&init_pid_ns.pidmap[0].nr_free);
 
-	init_pid_ns.pid_cachep = create_pid_cachep(1);
-	if (init_pid_ns.pid_cachep == NULL)
-		panic("Can't create pid_1 cachep\n");
-
-	pid_ns_cachep = KMEM_CACHE(pid_namespace, SLAB_PANIC);
+	init_pid_ns.pid_cachep = KMEM_CACHE(pid,
+			SLAB_HWCACHE_ALIGN | SLAB_PANIC);
 }

commit eccba068915feece2868c502787037e244db3376
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Feb 7 00:13:21 2008 -0800

    gfs2: make gfs2_glock.gl_owner_pid be a struct pid *
    
    The gl_owner_pid field is used to get the lock owning task by its pid, so make
    it in a proper manner, i.e.  by using the struct pid pointer and pid_task()
    function.
    
    The pid_task() becomes exported for the gfs2 module.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: Steven Whitehouse <swhiteho@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index f815455431bf..3b30bccdfcdc 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -368,6 +368,7 @@ struct task_struct * fastcall pid_task(struct pid *pid, enum pid_type type)
 	}
 	return result;
 }
+EXPORT_SYMBOL(pid_task);
 
 /*
  * Must be called under rcu_read_lock() or with tasklist_lock read-held.

commit 57d5f66b86079efac5c9a7843cce2a9bcbe58fb8
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Nov 14 17:00:13 2007 -0800

    pidns: Place under CONFIG_EXPERIMENTAL
    
    This is my trivial patch to swat innumerable little bugs with a single
    blow.
    
    After some intensive review (my apologies for not having gotten to this
    sooner) what we have looks like a good base to build on with the current
    pid namespace code but it is not complete, and it is still much to simple
    to find issues where the kernel does the wrong thing outside of the initial
    pid namespace.
    
    Until the dust settles and we are certain we have the ABI and the
    implementation is as correct as humanly possible let's keep process ID
    namespaces behind CONFIG_EXPERIMENTAL.
    
    Allowing us the option of fixing any ABI or other bugs we find as long as
    they are minor.
    
    Allowing users of the kernel to avoid those bugs simply by ensuring their
    kernel does not have support for multiple pid namespaces.
    
    [akpm@linux-foundation.org: coding-style cleanups]
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Adrian Bunk <bunk@kernel.org>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Kir Kolyshkin <kir@swsoft.com>
    Cc: Kirill Korotaev <dev@sw.ru>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index d1db36b94674..f815455431bf 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -537,6 +537,7 @@ static struct kmem_cache *create_pid_cachep(int nr_ids)
 	return NULL;
 }
 
+#ifdef CONFIG_PID_NS
 static struct pid_namespace *create_pid_namespace(int level)
 {
 	struct pid_namespace *ns;
@@ -621,6 +622,7 @@ void free_pid_ns(struct kref *kref)
 	if (parent != NULL)
 		put_pid_ns(parent);
 }
+#endif /* CONFIG_PID_NS */
 
 void zap_pid_ns_processes(struct pid_namespace *pid_ns)
 {

commit 2f2a3a46fcafa7a12d61454f67f932dfe7d84c60
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Oct 18 23:40:19 2007 -0700

    Uninline the task_xid_nr_ns() calls
    
    Since these are expanded into call to pid_nr_ns() anyway, it's OK to move
    the whole routine out-of-line.  This is a cheap way to save ~100 bytes from
    vmlinux.  Together with the previous two patches, it saves half-a-kilo from
    the vmlinux.
    
    Un-inline other (currently inlined) functions must be done with additional
    performance testing.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Paul Menage <menage@google.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 8040533d1a04..d1db36b94674 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -443,6 +443,30 @@ pid_t pid_nr_ns(struct pid *pid, struct pid_namespace *ns)
 	return nr;
 }
 
+pid_t task_pid_nr_ns(struct task_struct *tsk, struct pid_namespace *ns)
+{
+	return pid_nr_ns(task_pid(tsk), ns);
+}
+EXPORT_SYMBOL(task_pid_nr_ns);
+
+pid_t task_tgid_nr_ns(struct task_struct *tsk, struct pid_namespace *ns)
+{
+	return pid_nr_ns(task_tgid(tsk), ns);
+}
+EXPORT_SYMBOL(task_tgid_nr_ns);
+
+pid_t task_pgrp_nr_ns(struct task_struct *tsk, struct pid_namespace *ns)
+{
+	return pid_nr_ns(task_pgrp(tsk), ns);
+}
+EXPORT_SYMBOL(task_pgrp_nr_ns);
+
+pid_t task_session_nr_ns(struct task_struct *tsk, struct pid_namespace *ns)
+{
+	return pid_nr_ns(task_session(tsk), ns);
+}
+EXPORT_SYMBOL(task_session_nr_ns);
+
 /*
  * Used by proc to find the first pid that is greater then or equal to nr.
  *

commit 8990571eb573032c1192440febb17132074c5575
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Oct 18 23:40:19 2007 -0700

    Uninline find_pid etc set of functions
    
    The find_pid/_vpid/_pid_ns functions are used to find the struct pid by its
    id, depending on whic id - global or virtual - is used.
    
    The find_vpid() is a macro that pushes the current->nsproxy->pid_ns on the
    stack to call another function - find_pid_ns().  It turned out, that this
    dereference together with the push itself cause the kernel text size to
    grow too much.
    
    Move all these out-of-line.  Together with the previous patch this saves a
    bit less that 400 bytes from .text section.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Paul Menage <menage@google.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index bed9e7f80a50..8040533d1a04 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -302,6 +302,18 @@ struct pid * fastcall find_pid_ns(int nr, struct pid_namespace *ns)
 }
 EXPORT_SYMBOL_GPL(find_pid_ns);
 
+struct pid *find_vpid(int nr)
+{
+	return find_pid_ns(nr, current->nsproxy->pid_ns);
+}
+EXPORT_SYMBOL_GPL(find_vpid);
+
+struct pid *find_pid(int nr)
+{
+	return find_pid_ns(nr, &init_pid_ns);
+}
+EXPORT_SYMBOL_GPL(find_pid);
+
 /*
  * attach_pid() must be called with the tasklist_lock write-held.
  */

commit 19b9b9b54e5f115907efd56be2c3799775a46561
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Oct 18 23:40:17 2007 -0700

    pid namespaces: remove the struct pid unneeded fields
    
    Since we've switched from using pid->nr to pid->upids->nr some
    fields on struct pid are no longer needed
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Paul Menage <menage@google.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 73a60e265f52..bed9e7f80a50 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -263,7 +263,6 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 
 	get_pid_ns(ns);
 	pid->level = ns->level;
-	pid->nr = pid->numbers[0].nr;
 	atomic_set(&pid->count, 1);
 	for (type = 0; type < PIDTYPE_MAX; ++type)
 		INIT_HLIST_HEAD(&pid->tasks[type]);

commit 228ebcbe634a30aec35132ea4375721bcc41bec0
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Oct 18 23:40:16 2007 -0700

    Uninline find_task_by_xxx set of functions
    
    The find_task_by_something is a set of macros are used to find task by pid
    depending on what kind of pid is proposed - global or virtual one.  All of
    them are wrappers above the most generic one - find_task_by_pid_type_ns() -
    and just substitute some args for it.
    
    It turned out, that dereferencing the current->nsproxy->pid_ns construction
    and pushing one more argument on the stack inline cause kernel text size to
    grow.
    
    This patch moves all this stuff out-of-line into kernel/pid.c.  Together
    with the next patch it saves a bit less than 400 bytes from the .text
    section.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Paul Menage <menage@google.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index b3e6d7c41b97..73a60e265f52 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -369,6 +369,25 @@ struct task_struct *find_task_by_pid_type_ns(int type, int nr,
 
 EXPORT_SYMBOL(find_task_by_pid_type_ns);
 
+struct task_struct *find_task_by_pid(pid_t nr)
+{
+	return find_task_by_pid_type_ns(PIDTYPE_PID, nr, &init_pid_ns);
+}
+EXPORT_SYMBOL(find_task_by_pid);
+
+struct task_struct *find_task_by_vpid(pid_t vnr)
+{
+	return find_task_by_pid_type_ns(PIDTYPE_PID, vnr,
+			current->nsproxy->pid_ns);
+}
+EXPORT_SYMBOL(find_task_by_vpid);
+
+struct task_struct *find_task_by_pid_ns(pid_t nr, struct pid_namespace *ns)
+{
+	return find_task_by_pid_type_ns(PIDTYPE_PID, nr, ns);
+}
+EXPORT_SYMBOL(find_task_by_pid_ns);
+
 struct pid *get_task_pid(struct task_struct *task, enum pid_type type)
 {
 	struct pid *pid;

commit 3eb07c8c8adb6f0572baba844ba2d9e501654316
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Thu Oct 18 23:40:13 2007 -0700

    pid namespaces: destroy pid namespace on init's death
    
    Terminate all processes in a namespace when the reaper of the namespace is
    exiting.  We do this by walking the pidmap of the namespace and sending
    SIGKILL to all processes.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Acked-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Paul Menage <menage@google.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index d88b83eb703e..b3e6d7c41b97 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -34,6 +34,7 @@
 #include <linux/hash.h>
 #include <linux/pid_namespace.h>
 #include <linux/init_task.h>
+#include <linux/syscalls.h>
 
 #define pid_hashfn(nr, ns)	\
 	hash_long((unsigned long)nr + (unsigned long)ns, pidhash_shift)
@@ -567,6 +568,43 @@ void free_pid_ns(struct kref *kref)
 		put_pid_ns(parent);
 }
 
+void zap_pid_ns_processes(struct pid_namespace *pid_ns)
+{
+	int nr;
+	int rc;
+
+	/*
+	 * The last thread in the cgroup-init thread group is terminating.
+	 * Find remaining pid_ts in the namespace, signal and wait for them
+	 * to exit.
+	 *
+	 * Note:  This signals each threads in the namespace - even those that
+	 * 	  belong to the same thread group, To avoid this, we would have
+	 * 	  to walk the entire tasklist looking a processes in this
+	 * 	  namespace, but that could be unnecessarily expensive if the
+	 * 	  pid namespace has just a few processes. Or we need to
+	 * 	  maintain a tasklist for each pid namespace.
+	 *
+	 */
+	read_lock(&tasklist_lock);
+	nr = next_pidmap(pid_ns, 1);
+	while (nr > 0) {
+		kill_proc_info(SIGKILL, SEND_SIG_PRIV, nr);
+		nr = next_pidmap(pid_ns, nr);
+	}
+	read_unlock(&tasklist_lock);
+
+	do {
+		clear_thread_flag(TIF_SIGPENDING);
+		rc = sys_wait4(-1, NULL, __WALL, NULL);
+	} while (rc != -ECHILD);
+
+
+	/* Child reaper for the pid namespace is going away */
+	pid_ns->child_reaper = NULL;
+	return;
+}
+
 /*
  * The pid hash table is scaled according to the amount of memory in the
  * machine.  From a minimum of 16 slots up to 4096 slots at one gigabyte or

commit c9c5d92211883e9ae22394d1f157ab0d3a7ec895
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Thu Oct 18 23:40:12 2007 -0700

    pid namespaces: create a slab-cache for 'struct pid_namespace'
    
    This will help fixing memory leaks due to bad reference counting.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Paul Menage <menage@google.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index f76097c60475..d88b83eb703e 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -40,6 +40,7 @@
 static struct hlist_head *pid_hash;
 static int pidhash_shift;
 struct pid init_struct_pid = INIT_STRUCT_PID;
+static struct kmem_cache *pid_ns_cachep;
 
 int pid_max = PID_MAX_DEFAULT;
 
@@ -486,7 +487,7 @@ static struct pid_namespace *create_pid_namespace(int level)
 	struct pid_namespace *ns;
 	int i;
 
-	ns = kmalloc(sizeof(struct pid_namespace), GFP_KERNEL);
+	ns = kmem_cache_alloc(pid_ns_cachep, GFP_KERNEL);
 	if (ns == NULL)
 		goto out;
 
@@ -516,7 +517,7 @@ static struct pid_namespace *create_pid_namespace(int level)
 out_free_map:
 	kfree(ns->pidmap[0].page);
 out_free:
-	kfree(ns);
+	kmem_cache_free(pid_ns_cachep, ns);
 out:
 	return ERR_PTR(-ENOMEM);
 }
@@ -527,7 +528,7 @@ static void destroy_pid_namespace(struct pid_namespace *ns)
 
 	for (i = 0; i < PIDMAP_ENTRIES; i++)
 		kfree(ns->pidmap[i].page);
-	kfree(ns);
+	kmem_cache_free(pid_ns_cachep, ns);
 }
 
 struct pid_namespace *copy_pid_ns(unsigned long flags, struct pid_namespace *old_ns)
@@ -601,4 +602,6 @@ void __init pidmap_init(void)
 	init_pid_ns.pid_cachep = create_pid_cachep(1);
 	if (init_pid_ns.pid_cachep == NULL)
 		panic("Can't create pid_1 cachep\n");
+
+	pid_ns_cachep = KMEM_CACHE(pid_namespace, SLAB_PANIC);
 }

commit 30e49c263e36341b60b735cbef5ca37912549264
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Oct 18 23:40:10 2007 -0700

    pid namespaces: allow cloning of new namespace
    
    When clone() is invoked with CLONE_NEWPID, create a new pid namespace and then
    create a new struct pid for the new process.  Allocate pid_t's for the new
    process in the new pid namespace and all ancestor pid namespaces.  Make the
    newly cloned process the session and process group leader.
    
    Since the active pid namespace is special and expected to be the first entry
    in pid->upid_list, preserve the order of pid namespaces.
    
    The size of 'struct pid' is dependent on the the number of pid namespaces the
    process exists in, so we use multiple pid-caches'.  Only one pid cache is
    created during system startup and this used by processes that exist only in
    init_pid_ns.
    
    When a process clones its pid namespace, we create additional pid caches as
    necessary and use the pid cache to allocate 'struct pids' for that depth.
    
    Note, that with this patch the newly created namespace won't work, since the
    rest of the kernel still uses global pids, but this is to be fixed soon.  Init
    pid namespace still works.
    
    [oleg@tv-sign.ru: merge fix]
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Paul Menage <menage@google.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 4b17acdb862f..f76097c60475 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -18,6 +18,12 @@
  * allocation scenario when all but one out of 1 million PIDs possible are
  * allocated already: the scanning of 32 list entries and at most PAGE_SIZE
  * bytes. The typical fastpath is a single successful setbit. Freeing is O(1).
+ *
+ * Pid namespaces:
+ *    (C) 2007 Pavel Emelyanov <xemul@openvz.org>, OpenVZ, SWsoft Inc.
+ *    (C) 2007 Sukadev Bhattiprolu <sukadev@us.ibm.com>, IBM
+ *     Many thanks to Oleg Nesterov for comments and help
+ *
  */
 
 #include <linux/mm.h>
@@ -456,8 +462,8 @@ static struct kmem_cache *create_pid_cachep(int nr_ids)
 
 	snprintf(pcache->name, sizeof(pcache->name), "pid_%d", nr_ids);
 	cachep = kmem_cache_create(pcache->name,
-			/* FIXME add numerical ids here */
-			sizeof(struct pid), 0, SLAB_HWCACHE_ALIGN, NULL);
+			sizeof(struct pid) + (nr_ids - 1) * sizeof(struct upid),
+			0, SLAB_HWCACHE_ALIGN, NULL);
 	if (cachep == NULL)
 		goto err_cachep;
 
@@ -475,19 +481,89 @@ static struct kmem_cache *create_pid_cachep(int nr_ids)
 	return NULL;
 }
 
+static struct pid_namespace *create_pid_namespace(int level)
+{
+	struct pid_namespace *ns;
+	int i;
+
+	ns = kmalloc(sizeof(struct pid_namespace), GFP_KERNEL);
+	if (ns == NULL)
+		goto out;
+
+	ns->pidmap[0].page = kzalloc(PAGE_SIZE, GFP_KERNEL);
+	if (!ns->pidmap[0].page)
+		goto out_free;
+
+	ns->pid_cachep = create_pid_cachep(level + 1);
+	if (ns->pid_cachep == NULL)
+		goto out_free_map;
+
+	kref_init(&ns->kref);
+	ns->last_pid = 0;
+	ns->child_reaper = NULL;
+	ns->level = level;
+
+	set_bit(0, ns->pidmap[0].page);
+	atomic_set(&ns->pidmap[0].nr_free, BITS_PER_PAGE - 1);
+
+	for (i = 1; i < PIDMAP_ENTRIES; i++) {
+		ns->pidmap[i].page = 0;
+		atomic_set(&ns->pidmap[i].nr_free, BITS_PER_PAGE);
+	}
+
+	return ns;
+
+out_free_map:
+	kfree(ns->pidmap[0].page);
+out_free:
+	kfree(ns);
+out:
+	return ERR_PTR(-ENOMEM);
+}
+
+static void destroy_pid_namespace(struct pid_namespace *ns)
+{
+	int i;
+
+	for (i = 0; i < PIDMAP_ENTRIES; i++)
+		kfree(ns->pidmap[i].page);
+	kfree(ns);
+}
+
 struct pid_namespace *copy_pid_ns(unsigned long flags, struct pid_namespace *old_ns)
 {
+	struct pid_namespace *new_ns;
+
 	BUG_ON(!old_ns);
-	get_pid_ns(old_ns);
-	return old_ns;
+	new_ns = get_pid_ns(old_ns);
+	if (!(flags & CLONE_NEWPID))
+		goto out;
+
+	new_ns = ERR_PTR(-EINVAL);
+	if (flags & CLONE_THREAD)
+		goto out_put;
+
+	new_ns = create_pid_namespace(old_ns->level + 1);
+	if (!IS_ERR(new_ns))
+		new_ns->parent = get_pid_ns(old_ns);
+
+out_put:
+	put_pid_ns(old_ns);
+out:
+	return new_ns;
 }
 
 void free_pid_ns(struct kref *kref)
 {
-	struct pid_namespace *ns;
+	struct pid_namespace *ns, *parent;
 
 	ns = container_of(kref, struct pid_namespace, kref);
-	kfree(ns);
+
+	parent = ns->parent;
+	destroy_pid_namespace(ns);
+
+	if (parent != NULL)
+		put_pid_ns(parent);
 }
 
 /*

commit b461cc03828c743aed6b3855b9ab0d39a9d54ec5
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Oct 18 23:40:09 2007 -0700

    pid namespaces: miscellaneous preparations for pid namespaces
    
    * remove pid.h from pid_namespaces.h;
    * rework is_(cgroup|global)_init;
    * optimize (get|put)_pid_ns for init_pid_ns;
    * declare task_child_reaper to return actual reaper.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Paul Menage <menage@google.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index a2b4cbbdd63d..4b17acdb862f 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -73,10 +73,20 @@ struct pid_namespace init_pid_ns = {
 };
 EXPORT_SYMBOL_GPL(init_pid_ns);
 
-int is_global_init(struct task_struct *tsk)
+int is_container_init(struct task_struct *tsk)
 {
-	return tsk == init_pid_ns.child_reaper;
+	int ret = 0;
+	struct pid *pid;
+
+	rcu_read_lock();
+	pid = task_pid(tsk);
+	if (pid != NULL && pid->numbers[pid->level].nr == 1)
+		ret = 1;
+	rcu_read_unlock();
+
+	return ret;
 }
+EXPORT_SYMBOL(is_container_init);
 
 /*
  * Note: disable interrupts while the pidmap_lock is held as an
@@ -192,8 +202,7 @@ fastcall void put_pid(struct pid *pid)
 	if ((atomic_read(&pid->count) == 1) ||
 	     atomic_dec_and_test(&pid->count)) {
 		kmem_cache_free(ns->pid_cachep, pid);
-		if (ns != &init_pid_ns)
-			put_pid_ns(ns);
+		put_pid_ns(ns);
 	}
 }
 EXPORT_SYMBOL_GPL(put_pid);
@@ -244,9 +253,7 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 		tmp = tmp->parent;
 	}
 
-	if (ns != &init_pid_ns)
-		get_pid_ns(ns);
-
+	get_pid_ns(ns);
 	pid->level = ns->level;
 	pid->nr = pid->numbers[0].nr;
 	atomic_set(&pid->count, 1);

commit 198fe21b0a17fe9c68cb519ecc566534b04f122b
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Oct 18 23:40:06 2007 -0700

    pid namespaces: helpers to find the task by its numerical ids
    
    When searching the task by numerical id on may need to find it using global
    pid (as it is done now in kernel) or by its virtual id, e.g.  when sending a
    signal to a task from one namespace the sender will specify the task's virtual
    id and we should find the task by this value.
    
    [akpm@linux-foundation.org: fix gfs2 linkage]
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Paul Menage <menage@google.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 6eb14841b734..a2b4cbbdd63d 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -71,6 +71,7 @@ struct pid_namespace init_pid_ns = {
 	.level = 0,
 	.child_reaper = &init_task,
 };
+EXPORT_SYMBOL_GPL(init_pid_ns);
 
 int is_global_init(struct task_struct *tsk)
 {
@@ -210,7 +211,8 @@ fastcall void free_pid(struct pid *pid)
 	unsigned long flags;
 
 	spin_lock_irqsave(&pidmap_lock, flags);
-	hlist_del_rcu(&pid->pid_chain);
+	for (i = 0; i <= pid->level; i++)
+		hlist_del_rcu(&pid->numbers[i].pid_chain);
 	spin_unlock_irqrestore(&pidmap_lock, flags);
 
 	for (i = 0; i <= pid->level; i++)
@@ -225,6 +227,7 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	enum pid_type type;
 	int i, nr;
 	struct pid_namespace *tmp;
+	struct upid *upid;
 
 	pid = kmem_cache_alloc(ns->pid_cachep, GFP_KERNEL);
 	if (!pid)
@@ -251,7 +254,11 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 		INIT_HLIST_HEAD(&pid->tasks[type]);
 
 	spin_lock_irq(&pidmap_lock);
-	hlist_add_head_rcu(&pid->pid_chain, &pid_hash[pid_hashfn(pid->nr, ns)]);
+	for (i = ns->level; i >= 0; i--) {
+		upid = &pid->numbers[i];
+		hlist_add_head_rcu(&upid->pid_chain,
+				&pid_hash[pid_hashfn(upid->nr, upid->ns)]);
+	}
 	spin_unlock_irq(&pidmap_lock);
 
 out:
@@ -266,19 +273,20 @@ struct pid *alloc_pid(struct pid_namespace *ns)
 	goto out;
 }
 
-struct pid * fastcall find_pid(int nr)
+struct pid * fastcall find_pid_ns(int nr, struct pid_namespace *ns)
 {
 	struct hlist_node *elem;
-	struct pid *pid;
+	struct upid *pnr;
+
+	hlist_for_each_entry_rcu(pnr, elem,
+			&pid_hash[pid_hashfn(nr, ns)], pid_chain)
+		if (pnr->nr == nr && pnr->ns == ns)
+			return container_of(pnr, struct pid,
+					numbers[ns->level]);
 
-	hlist_for_each_entry_rcu(pid, elem,
-			&pid_hash[pid_hashfn(nr, &init_pid_ns)], pid_chain) {
-		if (pid->nr == nr)
-			return pid;
-	}
 	return NULL;
 }
-EXPORT_SYMBOL_GPL(find_pid);
+EXPORT_SYMBOL_GPL(find_pid_ns);
 
 /*
  * attach_pid() must be called with the tasklist_lock write-held.
@@ -338,12 +346,13 @@ struct task_struct * fastcall pid_task(struct pid *pid, enum pid_type type)
 /*
  * Must be called under rcu_read_lock() or with tasklist_lock read-held.
  */
-struct task_struct *find_task_by_pid_type(int type, int nr)
+struct task_struct *find_task_by_pid_type_ns(int type, int nr,
+		struct pid_namespace *ns)
 {
-	return pid_task(find_pid(nr), type);
+	return pid_task(find_pid_ns(nr, ns), type);
 }
 
-EXPORT_SYMBOL(find_task_by_pid_type);
+EXPORT_SYMBOL(find_task_by_pid_type_ns);
 
 struct pid *get_task_pid(struct task_struct *task, enum pid_type type)
 {
@@ -370,7 +379,7 @@ struct pid *find_get_pid(pid_t nr)
 	struct pid *pid;
 
 	rcu_read_lock();
-	pid = get_pid(find_pid(nr));
+	pid = get_pid(find_vpid(nr));
 	rcu_read_unlock();
 
 	return pid;
@@ -394,15 +403,15 @@ pid_t pid_nr_ns(struct pid *pid, struct pid_namespace *ns)
  *
  * If there is a pid at nr this function is exactly the same as find_pid.
  */
-struct pid *find_ge_pid(int nr)
+struct pid *find_ge_pid(int nr, struct pid_namespace *ns)
 {
 	struct pid *pid;
 
 	do {
-		pid = find_pid(nr);
+		pid = find_pid_ns(nr, ns);
 		if (pid)
 			break;
-		nr = next_pidmap(task_active_pid_ns(current), nr);
+		nr = next_pidmap(ns, nr);
 	} while (nr > 0);
 
 	return pid;

commit 7af5729474b5b8ad385adadab78d6e723e7655a3
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Oct 18 23:40:06 2007 -0700

    pid namespaces: helpers to obtain pid numbers
    
    When showing pid to user or getting the pid numerical id for in-kernel use the
    value of this id may differ depending on the namespace.
    
    This set of helpers is used to get the global pid nr, the virtual (i.e.  seen
    by task in its namespace) nr and the nr as it is seen from the specified
    namespace.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Paul Menage <menage@google.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 8132a6ddfa10..6eb14841b734 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -376,6 +376,19 @@ struct pid *find_get_pid(pid_t nr)
 	return pid;
 }
 
+pid_t pid_nr_ns(struct pid *pid, struct pid_namespace *ns)
+{
+	struct upid *upid;
+	pid_t nr = 0;
+
+	if (pid && ns->level <= pid->level) {
+		upid = &pid->numbers[ns->level];
+		if (upid->ns == ns)
+			nr = upid->nr;
+	}
+	return nr;
+}
+
 /*
  * Used by proc to find the first pid that is greater then or equal to nr.
  *

commit 8ef047aaaeb811247a5639c92e2f2ae1221a28dd
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Oct 18 23:40:05 2007 -0700

    pid namespaces: make alloc_pid(), free_pid() and put_pid() work with struct upid
    
    Each struct upid element of struct pid has to be initialized properly, i.e.
    its nr mst be allocated from appropriate pidmap and ns set to appropriate
    namespace.
    
    When allocating a new pid, we need to know the namespace this pid will live
    in, so the additional argument is added to alloc_pid().
    
    On the other hand, the rest of the kernel still uses the pid->nr and
    pid->pid_chain fields, so these ones are still initialized, but this will be
    removed soon.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Paul Menage <menage@google.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index c7346fb801fc..8132a6ddfa10 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -29,7 +29,8 @@
 #include <linux/pid_namespace.h>
 #include <linux/init_task.h>
 
-#define pid_hashfn(nr) hash_long((unsigned long)nr, pidhash_shift)
+#define pid_hashfn(nr, ns)	\
+	hash_long((unsigned long)nr + (unsigned long)ns, pidhash_shift)
 static struct hlist_head *pid_hash;
 static int pidhash_shift;
 struct pid init_struct_pid = INIT_STRUCT_PID;
@@ -186,11 +187,13 @@ fastcall void put_pid(struct pid *pid)
 	if (!pid)
 		return;
 
-	/* FIXME - this must be the namespace this pid lives in */
-	ns = &init_pid_ns;
+	ns = pid->numbers[pid->level].ns;
 	if ((atomic_read(&pid->count) == 1) ||
-	     atomic_dec_and_test(&pid->count))
+	     atomic_dec_and_test(&pid->count)) {
 		kmem_cache_free(ns->pid_cachep, pid);
+		if (ns != &init_pid_ns)
+			put_pid_ns(ns);
+	}
 }
 EXPORT_SYMBOL_GPL(put_pid);
 
@@ -203,45 +206,61 @@ static void delayed_put_pid(struct rcu_head *rhp)
 fastcall void free_pid(struct pid *pid)
 {
 	/* We can be called with write_lock_irq(&tasklist_lock) held */
+	int i;
 	unsigned long flags;
 
 	spin_lock_irqsave(&pidmap_lock, flags);
 	hlist_del_rcu(&pid->pid_chain);
 	spin_unlock_irqrestore(&pidmap_lock, flags);
 
-	free_pidmap(&init_pid_ns, pid->nr);
+	for (i = 0; i <= pid->level; i++)
+		free_pidmap(pid->numbers[i].ns, pid->numbers[i].nr);
+
 	call_rcu(&pid->rcu, delayed_put_pid);
 }
 
-struct pid *alloc_pid(void)
+struct pid *alloc_pid(struct pid_namespace *ns)
 {
 	struct pid *pid;
 	enum pid_type type;
-	int nr = -1;
-	struct pid_namespace *ns;
+	int i, nr;
+	struct pid_namespace *tmp;
 
-	ns = task_active_pid_ns(current);
 	pid = kmem_cache_alloc(ns->pid_cachep, GFP_KERNEL);
 	if (!pid)
 		goto out;
 
-	nr = alloc_pidmap(ns);
-	if (nr < 0)
-		goto out_free;
+	tmp = ns;
+	for (i = ns->level; i >= 0; i--) {
+		nr = alloc_pidmap(tmp);
+		if (nr < 0)
+			goto out_free;
 
+		pid->numbers[i].nr = nr;
+		pid->numbers[i].ns = tmp;
+		tmp = tmp->parent;
+	}
+
+	if (ns != &init_pid_ns)
+		get_pid_ns(ns);
+
+	pid->level = ns->level;
+	pid->nr = pid->numbers[0].nr;
 	atomic_set(&pid->count, 1);
-	pid->nr = nr;
 	for (type = 0; type < PIDTYPE_MAX; ++type)
 		INIT_HLIST_HEAD(&pid->tasks[type]);
 
 	spin_lock_irq(&pidmap_lock);
-	hlist_add_head_rcu(&pid->pid_chain, &pid_hash[pid_hashfn(pid->nr)]);
+	hlist_add_head_rcu(&pid->pid_chain, &pid_hash[pid_hashfn(pid->nr, ns)]);
 	spin_unlock_irq(&pidmap_lock);
 
 out:
 	return pid;
 
 out_free:
+	for (i++; i <= ns->level; i++)
+		free_pidmap(pid->numbers[i].ns, pid->numbers[i].nr);
+
 	kmem_cache_free(ns->pid_cachep, pid);
 	pid = NULL;
 	goto out;
@@ -253,7 +272,7 @@ struct pid * fastcall find_pid(int nr)
 	struct pid *pid;
 
 	hlist_for_each_entry_rcu(pid, elem,
-			&pid_hash[pid_hashfn(nr)], pid_chain) {
+			&pid_hash[pid_hashfn(nr, &init_pid_ns)], pid_chain) {
 		if (pid->nr == nr)
 			return pid;
 	}

commit faacbfd3a6808bf87d8f353b42eceeaba2c78a47
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Oct 18 23:40:04 2007 -0700

    pid namespaces: add support for pid namespaces hierarchy
    
    Each namespace has a parent and is characterized by its "level".  Level is the
    number of the namespace generation.  E.g.  init namespace has level 0, after
    cloning new one it will have level 1, the next one - 2 and so on and so forth.
     This level is not explicitly limited.
    
    True hierarchy must have some way to find each namespace's children, but it is
    not used in the patches, so this ability is not added (yet).
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Paul Menage <menage@google.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index bb0785109d39..c7346fb801fc 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -67,7 +67,8 @@ struct pid_namespace init_pid_ns = {
 		[ 0 ... PIDMAP_ENTRIES-1] = { ATOMIC_INIT(BITS_PER_PAGE), NULL }
 	},
 	.last_pid = 0,
-	.child_reaper = &init_task
+	.level = 0,
+	.child_reaper = &init_task,
 };
 
 int is_global_init(struct task_struct *tsk)

commit b460cbc581a53cc088ceba80608021dd49c63c43
Author: Serge E. Hallyn <serue@us.ibm.com>
Date:   Thu Oct 18 23:39:52 2007 -0700

    pid namespaces: define is_global_init() and is_container_init()
    
    is_init() is an ambiguous name for the pid==1 check.  Split it into
    is_global_init() and is_container_init().
    
    A cgroup init has it's tsk->pid == 1.
    
    A global init also has it's tsk->pid == 1 and it's active pid namespace
    is the init_pid_ns.  But rather than check the active pid namespace,
    compare the task structure with 'init_pid_ns.child_reaper', which is
    initialized during boot to the /sbin/init process and never changes.
    
    Changelog:
    
            2.6.22-rc4-mm2-pidns1:
            - Use 'init_pid_ns.child_reaper' to determine if a given task is the
              global init (/sbin/init) process. This would improve performance
              and remove dependence on the task_pid().
    
            2.6.21-mm2-pidns2:
    
            - [Sukadev Bhattiprolu] Changed is_container_init() calls in {powerpc,
              ppc,avr32}/traps.c for the _exception() call to is_global_init().
              This way, we kill only the cgroup if the cgroup's init has a
              bug rather than force a kernel panic.
    
    [akpm@linux-foundation.org: fix comment]
    [sukadev@us.ibm.com: Use is_global_init() in arch/m32r/mm/fault.c]
    [bunk@stusta.de: kernel/pid.c: remove unused exports]
    [sukadev@us.ibm.com: Fix capability.c to work with threaded init]
    Signed-off-by: Serge E. Hallyn <serue@us.ibm.com>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Acked-by: Pavel Emelianov <xemul@openvz.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Herbert Poetzel <herbert@13thfloor.at>
    Cc: Kirill Korotaev <dev@sw.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 78c0dbffde65..bb0785109d39 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -70,6 +70,11 @@ struct pid_namespace init_pid_ns = {
 	.child_reaper = &init_task
 };
 
+int is_global_init(struct task_struct *tsk)
+{
+	return tsk == init_pid_ns.child_reaper;
+}
+
 /*
  * Note: disable interrupts while the pidmap_lock is held as an
  * interrupt might come in and do read_lock(&tasklist_lock).

commit 2894d650cd9715d00ca196c711265819ef6ebd2d
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Thu Oct 18 23:39:49 2007 -0700

    pid namespaces: define and use task_active_pid_ns() wrapper
    
    With multiple pid namespaces, a process is known by some pid_t in every
    ancestor pid namespace.  Every time the process forks, the child process also
    gets a pid_t in every ancestor pid namespace.
    
    While a process is visible in >=1 pid namespaces, it can see pid_t's in only
    one pid namespace.  We call this pid namespace it's "active pid namespace",
    and it is always the youngest pid namespace in which the process is known.
    
    This patch defines and uses a wrapper to find the active pid namespace of a
    process.  The implementation of the wrapper will be changed in when support
    for multiple pid namespaces are added.
    
    Changelog:
            2.6.22-rc4-mm2-pidns1:
            - [Pavel Emelianov, Alexey Dobriyan] Back out the change to use
              task_active_pid_ns() in child_reaper() since task->nsproxy
              can be NULL during task exit (so child_reaper() continues to
              use init_pid_ns).
    
              to implement child_reaper() since init_pid_ns.child_reaper to
              implement child_reaper() since tsk->nsproxy can be NULL during exit.
    
            2.6.21-rc6-mm1:
            - Rename task_pid_ns() to task_active_pid_ns() to reflect that a
              process can have multiple pid namespaces.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Acked-by: Pavel Emelianov <xemul@openvz.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: Herbert Poetzel <herbert@13thfloor.at>
    Cc: Kirill Korotaev <dev@sw.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 42de9af8c524..78c0dbffde65 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -214,7 +214,7 @@ struct pid *alloc_pid(void)
 	int nr = -1;
 	struct pid_namespace *ns;
 
-	ns = current->nsproxy->pid_ns;
+	ns = task_active_pid_ns(current);
 	pid = kmem_cache_alloc(ns->pid_cachep, GFP_KERNEL);
 	if (!pid)
 		goto out;
@@ -364,7 +364,7 @@ struct pid *find_ge_pid(int nr)
 		pid = find_pid(nr);
 		if (pid)
 			break;
-		nr = next_pidmap(current->nsproxy->pid_ns, nr);
+		nr = next_pidmap(task_active_pid_ns(current), nr);
 	} while (nr > 0);
 
 	return pid;

commit baf8f0f82dd79e374bf6fa9e996393df2bae3c21
Author: Pavel Emelianov <xemul@openvz.org>
Date:   Thu Oct 18 23:39:48 2007 -0700

    pid namespaces: dynamic kmem cache allocator for pid namespaces
    
    Add kmem_cache to pid_namespace to allocate pids from.
    
    Since both implementations expand the struct pid to carry more numerical
    values each namespace should have separate cache to store pids of different
    sizes.
    
    Each kmem cache is name "pid_<NR>", where <NR> is the number of numerical ids
    on the pid.  Different namespaces with same level of nesting will have same
    caches.
    
    This patch has two FIXMEs that are to be fixed after we reach the consensus
    about the struct pid itself.
    
    The first one is that the namespace to free the pid from in free_pid() must be
    taken from pid.  Now the init_pid_ns is used.
    
    The second FIXME is about the cache allocation.  When we do know how long the
    object will be then we'll have to calculate this size in create_pid_cachep.
    Right now the sizeof(struct pid) value is used.
    
    [akpm@linux-foundation.org: coding-style repair]
    Signed-off-by: Pavel Emelianov <xemul@openvz.org>
    Acked-by: Cedric Le Goater <clg@fr.ibm.com>
    Acked-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Kirill Korotaev <dev@openvz.org>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index c6e3f9ffff87..42de9af8c524 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -32,7 +32,6 @@
 #define pid_hashfn(nr) hash_long((unsigned long)nr, pidhash_shift)
 static struct hlist_head *pid_hash;
 static int pidhash_shift;
-static struct kmem_cache *pid_cachep;
 struct pid init_struct_pid = INIT_STRUCT_PID;
 
 int pid_max = PID_MAX_DEFAULT;
@@ -176,11 +175,16 @@ static int next_pidmap(struct pid_namespace *pid_ns, int last)
 
 fastcall void put_pid(struct pid *pid)
 {
+	struct pid_namespace *ns;
+
 	if (!pid)
 		return;
+
+	/* FIXME - this must be the namespace this pid lives in */
+	ns = &init_pid_ns;
 	if ((atomic_read(&pid->count) == 1) ||
 	     atomic_dec_and_test(&pid->count))
-		kmem_cache_free(pid_cachep, pid);
+		kmem_cache_free(ns->pid_cachep, pid);
 }
 EXPORT_SYMBOL_GPL(put_pid);
 
@@ -208,12 +212,14 @@ struct pid *alloc_pid(void)
 	struct pid *pid;
 	enum pid_type type;
 	int nr = -1;
+	struct pid_namespace *ns;
 
-	pid = kmem_cache_alloc(pid_cachep, GFP_KERNEL);
+	ns = current->nsproxy->pid_ns;
+	pid = kmem_cache_alloc(ns->pid_cachep, GFP_KERNEL);
 	if (!pid)
 		goto out;
 
-	nr = alloc_pidmap(current->nsproxy->pid_ns);
+	nr = alloc_pidmap(ns);
 	if (nr < 0)
 		goto out_free;
 
@@ -230,7 +236,7 @@ struct pid *alloc_pid(void)
 	return pid;
 
 out_free:
-	kmem_cache_free(pid_cachep, pid);
+	kmem_cache_free(ns->pid_cachep, pid);
 	pid = NULL;
 	goto out;
 }
@@ -365,6 +371,56 @@ struct pid *find_ge_pid(int nr)
 }
 EXPORT_SYMBOL_GPL(find_get_pid);
 
+struct pid_cache {
+	int nr_ids;
+	char name[16];
+	struct kmem_cache *cachep;
+	struct list_head list;
+};
+
+static LIST_HEAD(pid_caches_lh);
+static DEFINE_MUTEX(pid_caches_mutex);
+
+/*
+ * creates the kmem cache to allocate pids from.
+ * @nr_ids: the number of numerical ids this pid will have to carry
+ */
+
+static struct kmem_cache *create_pid_cachep(int nr_ids)
+{
+	struct pid_cache *pcache;
+	struct kmem_cache *cachep;
+
+	mutex_lock(&pid_caches_mutex);
+	list_for_each_entry (pcache, &pid_caches_lh, list)
+		if (pcache->nr_ids == nr_ids)
+			goto out;
+
+	pcache = kmalloc(sizeof(struct pid_cache), GFP_KERNEL);
+	if (pcache == NULL)
+		goto err_alloc;
+
+	snprintf(pcache->name, sizeof(pcache->name), "pid_%d", nr_ids);
+	cachep = kmem_cache_create(pcache->name,
+			/* FIXME add numerical ids here */
+			sizeof(struct pid), 0, SLAB_HWCACHE_ALIGN, NULL);
+	if (cachep == NULL)
+		goto err_cachep;
+
+	pcache->nr_ids = nr_ids;
+	pcache->cachep = cachep;
+	list_add(&pcache->list, &pid_caches_lh);
+out:
+	mutex_unlock(&pid_caches_mutex);
+	return pcache->cachep;
+
+err_cachep:
+	kfree(pcache);
+err_alloc:
+	mutex_unlock(&pid_caches_mutex);
+	return NULL;
+}
+
 struct pid_namespace *copy_pid_ns(unsigned long flags, struct pid_namespace *old_ns)
 {
 	BUG_ON(!old_ns);
@@ -412,5 +468,7 @@ void __init pidmap_init(void)
 	set_bit(0, init_pid_ns.pidmap[0].page);
 	atomic_dec(&init_pid_ns.pidmap[0].nr_free);
 
-	pid_cachep = KMEM_CACHE(pid, SLAB_PANIC);
+	init_pid_ns.pid_cachep = create_pid_cachep(1);
+	if (init_pid_ns.pid_cachep == NULL)
+		panic("Can't create pid_1 cachep\n");
 }

commit 213dd266d48af90c1eec8688c1ff31aa34d21de2
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sun Jul 15 23:41:15 2007 -0700

    namespace: ensure clone_flags are always stored in an unsigned long
    
    While working on unshare support for the network namespace I noticed we
    were putting clone flags in an int.  Which is weird because the syscall
    uses unsigned long and we at least need an unsigned to properly hold all of
    the unshare flags.
    
    So to make the code consistent, this patch updates the code to use
    unsigned long instead of int for the clone flags in those places
    where we get it wrong today.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Acked-by: Cedric Le Goater <clg@fr.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index eb66bd2953ab..c6e3f9ffff87 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -365,7 +365,7 @@ struct pid *find_ge_pid(int nr)
 }
 EXPORT_SYMBOL_GPL(find_get_pid);
 
-struct pid_namespace *copy_pid_ns(int flags, struct pid_namespace *old_ns)
+struct pid_namespace *copy_pid_ns(unsigned long flags, struct pid_namespace *old_ns)
 {
 	BUG_ON(!old_ns);
 	get_pid_ns(old_ns);

commit 820e45db2380eb1545fa2bc5d34b8b2f2933faeb
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Thu May 10 22:23:00 2007 -0700

    statically initialize struct pid for swapper
    
    Statically initialize a struct pid for the swapper process (pid_t == 0) and
    attach it to init_task.  This is needed so task_pid(), task_pgrp() and
    task_session() interfaces work on the swapper process also.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: Eric Biederman <ebiederm@xmission.com>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: <containers@lists.osdl.org>
    Acked-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index d76f59326bd4..eb66bd2953ab 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -27,11 +27,13 @@
 #include <linux/bootmem.h>
 #include <linux/hash.h>
 #include <linux/pid_namespace.h>
+#include <linux/init_task.h>
 
 #define pid_hashfn(nr) hash_long((unsigned long)nr, pidhash_shift)
 static struct hlist_head *pid_hash;
 static int pidhash_shift;
 static struct kmem_cache *pid_cachep;
+struct pid init_struct_pid = INIT_STRUCT_PID;
 
 int pid_max = PID_MAX_DEFAULT;
 

commit e713d0dab21a68500720e222fa02567fc7dfb14b
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Thu May 10 22:22:58 2007 -0700

    attach_pid() with struct pid parameter
    
    attach_pid() currently takes a pid_t and then uses find_pid() to find the
    corresponding struct pid.  Sometimes we already have the struct pid.  We can
    then skip find_pid() if attach_pid() were to take a struct pid parameter.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: <containers@lists.osdl.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index d3ad724afa83..d76f59326bd4 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -247,13 +247,16 @@ struct pid * fastcall find_pid(int nr)
 }
 EXPORT_SYMBOL_GPL(find_pid);
 
-int fastcall attach_pid(struct task_struct *task, enum pid_type type, int nr)
+/*
+ * attach_pid() must be called with the tasklist_lock write-held.
+ */
+int fastcall attach_pid(struct task_struct *task, enum pid_type type,
+		struct pid *pid)
 {
 	struct pid_link *link;
-	struct pid *pid;
 
 	link = &task->pids[type];
-	link->pid = pid = find_pid(nr);
+	link->pid = pid;
 	hlist_add_head_rcu(&link->node, &pid->tasks[type]);
 
 	return 0;

commit e3222c4ecc649c4ae568e61dda9349482401b501
Author: Badari Pulavarty <pbadari@us.ibm.com>
Date:   Tue May 8 00:25:21 2007 -0700

    Merge sys_clone()/sys_unshare() nsproxy and namespace handling
    
    sys_clone() and sys_unshare() both makes copies of nsproxy and its associated
    namespaces.  But they have different code paths.
    
    This patch merges all the nsproxy and its associated namespace copy/clone
    handling (as much as possible).  Posted on container list earlier for
    feedback.
    
    - Create a new nsproxy and its associated namespaces and pass it back to
      caller to attach it to right process.
    
    - Changed all copy_*_ns() routines to return a new copy of namespace
      instead of attaching it to task->nsproxy.
    
    - Moved the CAP_SYS_ADMIN checks out of copy_*_ns() routines.
    
    - Removed unnessary !ns checks from copy_*_ns() and added BUG_ON()
      just incase.
    
    - Get rid of all individual unshare_*_ns() routines and make use of
      copy_*_ns() instead.
    
    [akpm@osdl.org: cleanups, warning fix]
    [clg@fr.ibm.com: remove dup_namespaces() declaration]
    [serue@us.ibm.com: fix CONFIG_IPC_NS=n, clone(CLONE_NEWIPC) retval]
    [akpm@linux-foundation.org: fix build with CONFIG_SYSVIPC=n]
    Signed-off-by: Badari Pulavarty <pbadari@us.ibm.com>
    Signed-off-by: Serge Hallyn <serue@us.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: <containers@lists.osdl.org>
    Signed-off-by: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 9c80bc23d6b8..d3ad724afa83 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -360,16 +360,11 @@ struct pid *find_ge_pid(int nr)
 }
 EXPORT_SYMBOL_GPL(find_get_pid);
 
-int copy_pid_ns(int flags, struct task_struct *tsk)
+struct pid_namespace *copy_pid_ns(int flags, struct pid_namespace *old_ns)
 {
-	struct pid_namespace *old_ns = tsk->nsproxy->pid_ns;
-	int err = 0;
-
-	if (!old_ns)
-		return 0;
-
+	BUG_ON(!old_ns);
 	get_pid_ns(old_ns);
-	return err;
+	return old_ns;
 }
 
 void free_pid_ns(struct kref *kref)

commit 0a31bd5f2bbb6473ef9d24f0063ca91cfa678b64
Author: Christoph Lameter <clameter@sgi.com>
Date:   Sun May 6 14:49:57 2007 -0700

    KMEM_CACHE(): simplify slab cache creation
    
    This patch provides a new macro
    
    KMEM_CACHE(<struct>, <flags>)
    
    to simplify slab creation. KMEM_CACHE creates a slab with the name of the
    struct, with the size of the struct and with the alignment of the struct.
    Additional slab flags may be specified if necessary.
    
    Example
    
    struct test_slab {
            int a,b,c;
            struct list_head;
    } __cacheline_aligned_in_smp;
    
    test_slab_cache = KMEM_CACHE(test_slab, SLAB_PANIC)
    
    will create a new slab named "test_slab" of the size sizeof(struct
    test_slab) and aligned to the alignment of test slab.  If it fails then we
    panic.
    
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 78f2aee90f54..9c80bc23d6b8 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -412,7 +412,5 @@ void __init pidmap_init(void)
 	set_bit(0, init_pid_ns.pidmap[0].page);
 	atomic_dec(&init_pid_ns.pidmap[0].nr_free);
 
-	pid_cachep = kmem_cache_create("pid", sizeof(struct pid),
-					__alignof__(struct pid),
-					SLAB_PANIC, NULL, NULL);
+	pid_cachep = KMEM_CACHE(pid, SLAB_PANIC);
 }

commit 0f2452855d86901ba3766826ccb5606ea4e15ab9
Author: Serge E. Hallyn <serue@us.ibm.com>
Date:   Tue Jan 30 15:28:23 2007 -0600

    [PATCH] namespaces: fix task exit disaster
    
    This is based on a patch by Eric W.  Biederman, who pointed out that pid
    namespaces are still fake, and we only have one ever active.
    
    So for the time being, we can modify any code which could access
    tsk->nsproxy->pid_ns during task exit to just use &init_pid_ns instead,
    and move the exit_task_namespaces call in do_exit() back above
    exit_notify(), so that an exiting nfs server has a valid tsk->sighand to
    work with.
    
    Long term, pulling pid_ns out of nsproxy might be the cleanest solution.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    
    [ Eric's patch fixed to take care of free_pid() too ]
    
    Signed-off-by: Serge E. Hallyn <serue@us.ibm.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 2efe9d8d367b..78f2aee90f54 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -197,7 +197,7 @@ fastcall void free_pid(struct pid *pid)
 	hlist_del_rcu(&pid->pid_chain);
 	spin_unlock_irqrestore(&pidmap_lock, flags);
 
-	free_pidmap(current->nsproxy->pid_ns, pid->nr);
+	free_pidmap(&init_pid_ns, pid->nr);
 	call_rcu(&pid->rcu, delayed_put_pid);
 }
 

commit 84d737866e2babdeab0c6b18ea155c6a649663b8
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Fri Dec 8 02:38:01 2006 -0800

    [PATCH] add child reaper to pid_namespace
    
    Add a per pid_namespace child-reaper.  This is needed so processes are reaped
    within the same pid space and do not spill over to the parent pid space.  Its
    also needed so containers preserve existing semantic that pid == 1 would reap
    orphaned children.
    
    This is based on Eric Biederman's patch: http://lkml.org/lkml/2006/2/6/285
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Signed-off-by: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Kirill Korotaev <dev@openvz.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 1d9cc268b499..2efe9d8d367b 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -65,7 +65,8 @@ struct pid_namespace init_pid_ns = {
 	.pidmap = {
 		[ 0 ... PIDMAP_ENTRIES-1] = { ATOMIC_INIT(BITS_PER_PAGE), NULL }
 	},
-	.last_pid = 0
+	.last_pid = 0,
+	.child_reaper = &init_task
 };
 
 /*

commit 6cc1b22a4acef3816eaa5f8c227d93d749b23195
Author: Cedric Le Goater <clg@fr.ibm.com>
Date:   Fri Dec 8 02:38:00 2006 -0800

    [PATCH] use current->nsproxy->pid_ns
    
    Signed-off-by: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Kirill Korotaev <dev@openvz.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 5319b9f2fc5e..1d9cc268b499 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -196,7 +196,7 @@ fastcall void free_pid(struct pid *pid)
 	hlist_del_rcu(&pid->pid_chain);
 	spin_unlock_irqrestore(&pidmap_lock, flags);
 
-	free_pidmap(&init_pid_ns, pid->nr);
+	free_pidmap(current->nsproxy->pid_ns, pid->nr);
 	call_rcu(&pid->rcu, delayed_put_pid);
 }
 
@@ -210,7 +210,7 @@ struct pid *alloc_pid(void)
 	if (!pid)
 		goto out;
 
-	nr = alloc_pidmap(&init_pid_ns);
+	nr = alloc_pidmap(current->nsproxy->pid_ns);
 	if (nr < 0)
 		goto out_free;
 
@@ -352,7 +352,7 @@ struct pid *find_ge_pid(int nr)
 		pid = find_pid(nr);
 		if (pid)
 			break;
-		nr = next_pidmap(&init_pid_ns, nr);
+		nr = next_pidmap(current->nsproxy->pid_ns, nr);
 	} while (nr > 0);
 
 	return pid;

commit 9a575a92db3312a40cdf0b0406d88de88ad9741e
Author: Cedric Le Goater <clg@fr.ibm.com>
Date:   Fri Dec 8 02:37:59 2006 -0800

    [PATCH] to nsproxy
    
    Add the pid namespace framework to the nsproxy object.  The copy of the pid
    namespace only increases the refcount on the global pid namespace,
    init_pid_ns, and unshare is not implemented.
    
    There is no configuration option to activate or deactivate this feature
    because this not relevant for the moment.
    
    Signed-off-by: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Kirill Korotaev <dev@openvz.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 25807e1b98dd..5319b9f2fc5e 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -59,6 +59,9 @@ static inline int mk_pid(struct pid_namespace *pid_ns,
  * the scheme scales to up to 4 million PIDs, runtime.
  */
 struct pid_namespace init_pid_ns = {
+	.kref = {
+		.refcount       = ATOMIC_INIT(2),
+	},
 	.pidmap = {
 		[ 0 ... PIDMAP_ENTRIES-1] = { ATOMIC_INIT(BITS_PER_PAGE), NULL }
 	},
@@ -356,6 +359,26 @@ struct pid *find_ge_pid(int nr)
 }
 EXPORT_SYMBOL_GPL(find_get_pid);
 
+int copy_pid_ns(int flags, struct task_struct *tsk)
+{
+	struct pid_namespace *old_ns = tsk->nsproxy->pid_ns;
+	int err = 0;
+
+	if (!old_ns)
+		return 0;
+
+	get_pid_ns(old_ns);
+	return err;
+}
+
+void free_pid_ns(struct kref *kref)
+{
+	struct pid_namespace *ns;
+
+	ns = container_of(kref, struct pid_namespace, kref);
+	kfree(ns);
+}
+
 /*
  * The pid hash table is scaled according to the amount of memory in the
  * machine.  From a minimum of 16 slots up to 4096 slots at one gigabyte or

commit 61a58c6c238cc81f7742b8cc84212cc55fb57747
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Fri Dec 8 02:37:58 2006 -0800

    [PATCH] rename struct pspace to struct pid_namespace
    
    Rename struct pspace to struct pid_namespace for consistency with other
    namespaces (uts_namespace and ipc_namespace).  Also rename
    include/linux/pspace.h to include/linux/pid_namespace.h and variables from
    pspace to pid_ns.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Signed-off-by: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Kirill Korotaev <dev@openvz.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index a48879b0b921..25807e1b98dd 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -26,7 +26,7 @@
 #include <linux/init.h>
 #include <linux/bootmem.h>
 #include <linux/hash.h>
-#include <linux/pspace.h>
+#include <linux/pid_namespace.h>
 
 #define pid_hashfn(nr) hash_long((unsigned long)nr, pidhash_shift)
 static struct hlist_head *pid_hash;
@@ -43,9 +43,10 @@ int pid_max_max = PID_MAX_LIMIT;
 #define BITS_PER_PAGE		(PAGE_SIZE*8)
 #define BITS_PER_PAGE_MASK	(BITS_PER_PAGE-1)
 
-static inline int mk_pid(struct pspace *pspace, struct pidmap *map, int off)
+static inline int mk_pid(struct pid_namespace *pid_ns,
+		struct pidmap *map, int off)
 {
-	return (map - pspace->pidmap)*BITS_PER_PAGE + off;
+	return (map - pid_ns->pidmap)*BITS_PER_PAGE + off;
 }
 
 #define find_next_offset(map, off)					\
@@ -57,7 +58,7 @@ static inline int mk_pid(struct pspace *pspace, struct pidmap *map, int off)
  * value does not cause lots of bitmaps to be allocated, but
  * the scheme scales to up to 4 million PIDs, runtime.
  */
-struct pspace init_pspace = {
+struct pid_namespace init_pid_ns = {
 	.pidmap = {
 		[ 0 ... PIDMAP_ENTRIES-1] = { ATOMIC_INIT(BITS_PER_PAGE), NULL }
 	},
@@ -80,25 +81,25 @@ struct pspace init_pspace = {
 
 static  __cacheline_aligned_in_smp DEFINE_SPINLOCK(pidmap_lock);
 
-static fastcall void free_pidmap(struct pspace *pspace, int pid)
+static fastcall void free_pidmap(struct pid_namespace *pid_ns, int pid)
 {
-	struct pidmap *map = pspace->pidmap + pid / BITS_PER_PAGE;
+	struct pidmap *map = pid_ns->pidmap + pid / BITS_PER_PAGE;
 	int offset = pid & BITS_PER_PAGE_MASK;
 
 	clear_bit(offset, map->page);
 	atomic_inc(&map->nr_free);
 }
 
-static int alloc_pidmap(struct pspace *pspace)
+static int alloc_pidmap(struct pid_namespace *pid_ns)
 {
-	int i, offset, max_scan, pid, last = pspace->last_pid;
+	int i, offset, max_scan, pid, last = pid_ns->last_pid;
 	struct pidmap *map;
 
 	pid = last + 1;
 	if (pid >= pid_max)
 		pid = RESERVED_PIDS;
 	offset = pid & BITS_PER_PAGE_MASK;
-	map = &pspace->pidmap[pid/BITS_PER_PAGE];
+	map = &pid_ns->pidmap[pid/BITS_PER_PAGE];
 	max_scan = (pid_max + BITS_PER_PAGE - 1)/BITS_PER_PAGE - !offset;
 	for (i = 0; i <= max_scan; ++i) {
 		if (unlikely(!map->page)) {
@@ -120,11 +121,11 @@ static int alloc_pidmap(struct pspace *pspace)
 			do {
 				if (!test_and_set_bit(offset, map->page)) {
 					atomic_dec(&map->nr_free);
-					pspace->last_pid = pid;
+					pid_ns->last_pid = pid;
 					return pid;
 				}
 				offset = find_next_offset(map, offset);
-				pid = mk_pid(pspace, map, offset);
+				pid = mk_pid(pid_ns, map, offset);
 			/*
 			 * find_next_offset() found a bit, the pid from it
 			 * is in-bounds, and if we fell back to the last
@@ -135,34 +136,34 @@ static int alloc_pidmap(struct pspace *pspace)
 					(i != max_scan || pid < last ||
 					    !((last+1) & BITS_PER_PAGE_MASK)));
 		}
-		if (map < &pspace->pidmap[(pid_max-1)/BITS_PER_PAGE]) {
+		if (map < &pid_ns->pidmap[(pid_max-1)/BITS_PER_PAGE]) {
 			++map;
 			offset = 0;
 		} else {
-			map = &pspace->pidmap[0];
+			map = &pid_ns->pidmap[0];
 			offset = RESERVED_PIDS;
 			if (unlikely(last == offset))
 				break;
 		}
-		pid = mk_pid(pspace, map, offset);
+		pid = mk_pid(pid_ns, map, offset);
 	}
 	return -1;
 }
 
-static int next_pidmap(struct pspace *pspace, int last)
+static int next_pidmap(struct pid_namespace *pid_ns, int last)
 {
 	int offset;
 	struct pidmap *map, *end;
 
 	offset = (last + 1) & BITS_PER_PAGE_MASK;
-	map = &pspace->pidmap[(last + 1)/BITS_PER_PAGE];
-	end = &pspace->pidmap[PIDMAP_ENTRIES];
+	map = &pid_ns->pidmap[(last + 1)/BITS_PER_PAGE];
+	end = &pid_ns->pidmap[PIDMAP_ENTRIES];
 	for (; map < end; map++, offset = 0) {
 		if (unlikely(!map->page))
 			continue;
 		offset = find_next_bit((map)->page, BITS_PER_PAGE, offset);
 		if (offset < BITS_PER_PAGE)
-			return mk_pid(pspace, map, offset);
+			return mk_pid(pid_ns, map, offset);
 	}
 	return -1;
 }
@@ -192,7 +193,7 @@ fastcall void free_pid(struct pid *pid)
 	hlist_del_rcu(&pid->pid_chain);
 	spin_unlock_irqrestore(&pidmap_lock, flags);
 
-	free_pidmap(&init_pspace, pid->nr);
+	free_pidmap(&init_pid_ns, pid->nr);
 	call_rcu(&pid->rcu, delayed_put_pid);
 }
 
@@ -206,7 +207,7 @@ struct pid *alloc_pid(void)
 	if (!pid)
 		goto out;
 
-	nr = alloc_pidmap(&init_pspace);
+	nr = alloc_pidmap(&init_pid_ns);
 	if (nr < 0)
 		goto out_free;
 
@@ -348,7 +349,7 @@ struct pid *find_ge_pid(int nr)
 		pid = find_pid(nr);
 		if (pid)
 			break;
-		nr = next_pidmap(&init_pspace, nr);
+		nr = next_pidmap(&init_pid_ns, nr);
 	} while (nr > 0);
 
 	return pid;
@@ -382,10 +383,10 @@ void __init pidhash_init(void)
 
 void __init pidmap_init(void)
 {
-	init_pspace.pidmap[0].page = kzalloc(PAGE_SIZE, GFP_KERNEL);
+	init_pid_ns.pidmap[0].page = kzalloc(PAGE_SIZE, GFP_KERNEL);
 	/* Reserve PID 0. We never call free_pidmap(0) */
-	set_bit(0, init_pspace.pidmap[0].page);
-	atomic_dec(&init_pspace.pidmap[0].nr_free);
+	set_bit(0, init_pid_ns.pidmap[0].page);
+	atomic_dec(&init_pid_ns.pidmap[0].nr_free);
 
 	pid_cachep = kmem_cache_create("pid", sizeof(struct pid),
 					__alignof__(struct pid),

commit e18b890bb0881bbab6f4f1a6cd20d9c60d66b003
Author: Christoph Lameter <clameter@sgi.com>
Date:   Wed Dec 6 20:33:20 2006 -0800

    [PATCH] slab: remove kmem_cache_t
    
    Replace all uses of kmem_cache_t with struct kmem_cache.
    
    The patch was generated using the following script:
    
            #!/bin/sh
            #
            # Replace one string by another in all the kernel sources.
            #
    
            set -e
    
            for file in `find * -name "*.c" -o -name "*.h"|xargs grep -l $1`; do
                    quilt add $file
                    sed -e "1,\$s/$1/$2/g" $file >/tmp/$$
                    mv /tmp/$$ $file
                    quilt refresh
            done
    
    The script was run like this
    
            sh replace kmem_cache_t "struct kmem_cache"
    
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index b914392085f9..a48879b0b921 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -31,7 +31,7 @@
 #define pid_hashfn(nr) hash_long((unsigned long)nr, pidhash_shift)
 static struct hlist_head *pid_hash;
 static int pidhash_shift;
-static kmem_cache_t *pid_cachep;
+static struct kmem_cache *pid_cachep;
 
 int pid_max = PID_MAX_DEFAULT;
 

commit 1a657f78dcc8ea7c53eaa1f2a45ea2315738c15f
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon Oct 2 02:18:59 2006 -0700

    [PATCH] introduce get_task_pid() to fix unsafe get_pid()
    
    proc_pid_make_inode:
    
            ei->pid = get_pid(task_pid(task));
    
    I think this is not safe.  get_pid() can be preempted after checking "pid
    != NULL".  Then the task exits, does detach_pid(), and RCU frees the pid.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index e4779bbb2058..b914392085f9 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -304,6 +304,15 @@ struct task_struct *find_task_by_pid_type(int type, int nr)
 
 EXPORT_SYMBOL(find_task_by_pid_type);
 
+struct pid *get_task_pid(struct task_struct *task, enum pid_type type)
+{
+	struct pid *pid;
+	rcu_read_lock();
+	pid = get_pid(task->pids[type].pid);
+	rcu_read_unlock();
+	return pid;
+}
+
 struct task_struct *fastcall get_pid_task(struct pid *pid, enum pid_type type)
 {
 	struct task_struct *result;

commit f40f50d3bb33b52dfd550ca80be7daaddad21883
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Oct 2 02:17:25 2006 -0700

    [PATCH] Use struct pspace in next_pidmap and find_ge_pid
    
    This updates my proc: readdir race fix (take 3) patch
    to account for the changes made by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    to introduce struct pspace.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 89107b7481af..e4779bbb2058 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -149,19 +149,20 @@ static int alloc_pidmap(struct pspace *pspace)
 	return -1;
 }
 
-static int next_pidmap(int last)
+static int next_pidmap(struct pspace *pspace, int last)
 {
 	int offset;
-	struct pidmap *map;
+	struct pidmap *map, *end;
 
 	offset = (last + 1) & BITS_PER_PAGE_MASK;
-	map = &pidmap_array[(last + 1)/BITS_PER_PAGE];
-	for (; map < &pidmap_array[PIDMAP_ENTRIES]; map++, offset = 0) {
+	map = &pspace->pidmap[(last + 1)/BITS_PER_PAGE];
+	end = &pspace->pidmap[PIDMAP_ENTRIES];
+	for (; map < end; map++, offset = 0) {
 		if (unlikely(!map->page))
 			continue;
 		offset = find_next_bit((map)->page, BITS_PER_PAGE, offset);
 		if (offset < BITS_PER_PAGE)
-			return mk_pid(map, offset);
+			return mk_pid(pspace, map, offset);
 	}
 	return -1;
 }
@@ -338,7 +339,7 @@ struct pid *find_ge_pid(int nr)
 		pid = find_pid(nr);
 		if (pid)
 			break;
-		nr = next_pidmap(nr);
+		nr = next_pidmap(&init_pspace, nr);
 	} while (nr > 0);
 
 	return pid;

commit 3fbc96486459324e182717b03c50c90c880be6ec
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Mon Oct 2 02:17:24 2006 -0700

    [PATCH] Define struct pspace
    
    Define a per-container pid space object.  And create one instance of this
    object, init_pspace, to define the entire pid space.  Subsequent patches
    will provide/use interfaces to create/destroy pid spaces.
    
    Its a subset/rework of Eric Biederman's patch
    http://lkml.org/lkml/2006/2/6/285 .
    
    Signed-off-by: Eric Biederman <ebiederm@xmission.com>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Kirill Korotaev <dev@sw.ru>
    Cc: Andrey Savochkin <saw@sw.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 8234bd08a3cb..89107b7481af 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -34,7 +34,6 @@ static int pidhash_shift;
 static kmem_cache_t *pid_cachep;
 
 int pid_max = PID_MAX_DEFAULT;
-int last_pid;
 
 #define RESERVED_PIDS		300
 
@@ -43,7 +42,12 @@ int pid_max_max = PID_MAX_LIMIT;
 
 #define BITS_PER_PAGE		(PAGE_SIZE*8)
 #define BITS_PER_PAGE_MASK	(BITS_PER_PAGE-1)
-#define mk_pid(map, off)	(((map) - pidmap_array)*BITS_PER_PAGE + (off))
+
+static inline int mk_pid(struct pspace *pspace, struct pidmap *map, int off)
+{
+	return (map - pspace->pidmap)*BITS_PER_PAGE + off;
+}
+
 #define find_next_offset(map, off)					\
 		find_next_zero_bit((map)->page, BITS_PER_PAGE, off)
 
@@ -53,8 +57,12 @@ int pid_max_max = PID_MAX_LIMIT;
  * value does not cause lots of bitmaps to be allocated, but
  * the scheme scales to up to 4 million PIDs, runtime.
  */
-static struct pidmap pidmap_array[PIDMAP_ENTRIES] =
-	 { [ 0 ... PIDMAP_ENTRIES-1 ] = { ATOMIC_INIT(BITS_PER_PAGE), NULL } };
+struct pspace init_pspace = {
+	.pidmap = {
+		[ 0 ... PIDMAP_ENTRIES-1] = { ATOMIC_INIT(BITS_PER_PAGE), NULL }
+	},
+	.last_pid = 0
+};
 
 /*
  * Note: disable interrupts while the pidmap_lock is held as an
@@ -69,40 +77,41 @@ static struct pidmap pidmap_array[PIDMAP_ENTRIES] =
  * irq handlers that take it we can leave the interrupts enabled.
  * For now it is easier to be safe than to prove it can't happen.
  */
+
 static  __cacheline_aligned_in_smp DEFINE_SPINLOCK(pidmap_lock);
 
-static fastcall void free_pidmap(int pid)
+static fastcall void free_pidmap(struct pspace *pspace, int pid)
 {
-	struct pidmap *map = pidmap_array + pid / BITS_PER_PAGE;
+	struct pidmap *map = pspace->pidmap + pid / BITS_PER_PAGE;
 	int offset = pid & BITS_PER_PAGE_MASK;
 
 	clear_bit(offset, map->page);
 	atomic_inc(&map->nr_free);
 }
 
-static int alloc_pidmap(void)
+static int alloc_pidmap(struct pspace *pspace)
 {
-	int i, offset, max_scan, pid, last = last_pid;
+	int i, offset, max_scan, pid, last = pspace->last_pid;
 	struct pidmap *map;
 
 	pid = last + 1;
 	if (pid >= pid_max)
 		pid = RESERVED_PIDS;
 	offset = pid & BITS_PER_PAGE_MASK;
-	map = &pidmap_array[pid/BITS_PER_PAGE];
+	map = &pspace->pidmap[pid/BITS_PER_PAGE];
 	max_scan = (pid_max + BITS_PER_PAGE - 1)/BITS_PER_PAGE - !offset;
 	for (i = 0; i <= max_scan; ++i) {
 		if (unlikely(!map->page)) {
-			unsigned long page = get_zeroed_page(GFP_KERNEL);
+			void *page = kzalloc(PAGE_SIZE, GFP_KERNEL);
 			/*
 			 * Free the page if someone raced with us
 			 * installing it:
 			 */
 			spin_lock_irq(&pidmap_lock);
 			if (map->page)
-				free_page(page);
+				kfree(page);
 			else
-				map->page = (void *)page;
+				map->page = page;
 			spin_unlock_irq(&pidmap_lock);
 			if (unlikely(!map->page))
 				break;
@@ -111,11 +120,11 @@ static int alloc_pidmap(void)
 			do {
 				if (!test_and_set_bit(offset, map->page)) {
 					atomic_dec(&map->nr_free);
-					last_pid = pid;
+					pspace->last_pid = pid;
 					return pid;
 				}
 				offset = find_next_offset(map, offset);
-				pid = mk_pid(map, offset);
+				pid = mk_pid(pspace, map, offset);
 			/*
 			 * find_next_offset() found a bit, the pid from it
 			 * is in-bounds, and if we fell back to the last
@@ -126,16 +135,16 @@ static int alloc_pidmap(void)
 					(i != max_scan || pid < last ||
 					    !((last+1) & BITS_PER_PAGE_MASK)));
 		}
-		if (map < &pidmap_array[(pid_max-1)/BITS_PER_PAGE]) {
+		if (map < &pspace->pidmap[(pid_max-1)/BITS_PER_PAGE]) {
 			++map;
 			offset = 0;
 		} else {
-			map = &pidmap_array[0];
+			map = &pspace->pidmap[0];
 			offset = RESERVED_PIDS;
 			if (unlikely(last == offset))
 				break;
 		}
-		pid = mk_pid(map, offset);
+		pid = mk_pid(pspace, map, offset);
 	}
 	return -1;
 }
@@ -182,7 +191,7 @@ fastcall void free_pid(struct pid *pid)
 	hlist_del_rcu(&pid->pid_chain);
 	spin_unlock_irqrestore(&pidmap_lock, flags);
 
-	free_pidmap(pid->nr);
+	free_pidmap(&init_pspace, pid->nr);
 	call_rcu(&pid->rcu, delayed_put_pid);
 }
 
@@ -196,7 +205,7 @@ struct pid *alloc_pid(void)
 	if (!pid)
 		goto out;
 
-	nr = alloc_pidmap();
+	nr = alloc_pidmap(&init_pspace);
 	if (nr < 0)
 		goto out_free;
 
@@ -363,10 +372,10 @@ void __init pidhash_init(void)
 
 void __init pidmap_init(void)
 {
-	pidmap_array->page = (void *)get_zeroed_page(GFP_KERNEL);
+	init_pspace.pidmap[0].page = kzalloc(PAGE_SIZE, GFP_KERNEL);
 	/* Reserve PID 0. We never call free_pidmap(0) */
-	set_bit(0, pidmap_array->page);
-	atomic_dec(&pidmap_array->nr_free);
+	set_bit(0, init_pspace.pidmap[0].page);
+	atomic_dec(&init_pspace.pidmap[0].nr_free);
 
 	pid_cachep = kmem_cache_create("pid", sizeof(struct pid),
 					__alignof__(struct pid),

commit aa5a6662f93f52605b6c447ba6f7291e92f515c5
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Mon Oct 2 02:17:23 2006 -0700

    [PATCH] Move pidmap to pspace.h
    
    Move struct pidmap and PIDMAP_ENTRIES to a new file, include/linux/pspace.h
    where it will be used in subsequent patches to define pid spaces.
    
    Its a subset of Eric Biederman's patch http://lkml.org/lkml/2006/2/6/285
    
    [akpm@osdl.org: cleanups]
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 373639a10d84..8234bd08a3cb 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -26,6 +26,7 @@
 #include <linux/init.h>
 #include <linux/bootmem.h>
 #include <linux/hash.h>
+#include <linux/pspace.h>
 
 #define pid_hashfn(nr) hash_long((unsigned long)nr, pidhash_shift)
 static struct hlist_head *pid_hash;
@@ -40,7 +41,6 @@ int last_pid;
 int pid_max_min = RESERVED_PIDS + 1;
 int pid_max_max = PID_MAX_LIMIT;
 
-#define PIDMAP_ENTRIES		((PID_MAX_LIMIT + 8*PAGE_SIZE - 1)/PAGE_SIZE/8)
 #define BITS_PER_PAGE		(PAGE_SIZE*8)
 #define BITS_PER_PAGE_MASK	(BITS_PER_PAGE-1)
 #define mk_pid(map, off)	(((map) - pidmap_array)*BITS_PER_PAGE + (off))
@@ -53,11 +53,6 @@ int pid_max_max = PID_MAX_LIMIT;
  * value does not cause lots of bitmaps to be allocated, but
  * the scheme scales to up to 4 million PIDs, runtime.
  */
-struct pidmap {
-	atomic_t nr_free;
-	void *page;
-};
-
 static struct pidmap pidmap_array[PIDMAP_ENTRIES] =
 	 { [ 0 ... PIDMAP_ENTRIES-1 ] = { ATOMIC_INIT(BITS_PER_PAGE), NULL } };
 

commit c88be3eb2e01bbb21c9ccdc3805f0d3546c1898c
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Oct 2 02:17:21 2006 -0700

    [PATCH] pids coding style use struct pidmap in next_pidmap
    
    Use struct pidmap instead of pidmap_t.
    
    This updates my proc: readdir race fix (take 3) patch
    to account for the changes made by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    to kill pidmap_t.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 0a45de2918e2..373639a10d84 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -148,7 +148,7 @@ static int alloc_pidmap(void)
 static int next_pidmap(int last)
 {
 	int offset;
-	pidmap_t *map;
+	struct pidmap *map;
 
 	offset = (last + 1) & BITS_PER_PAGE_MASK;
 	map = &pidmap_array[(last + 1)/BITS_PER_PAGE];

commit 6a1f3b84557774a46af68747c92d8f36382027ae
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Mon Oct 2 02:17:20 2006 -0700

    [PATCH] pids: coding style: use struct pidmap
    
    Use struct pidmap instead of pidmap_t.
    
    Its a subset of Eric Biederman's patch http://lkml.org/lkml/2006/2/6/271.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 5c9037ba42f5..0a45de2918e2 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -53,12 +53,12 @@ int pid_max_max = PID_MAX_LIMIT;
  * value does not cause lots of bitmaps to be allocated, but
  * the scheme scales to up to 4 million PIDs, runtime.
  */
-typedef struct pidmap {
+struct pidmap {
 	atomic_t nr_free;
 	void *page;
-} pidmap_t;
+};
 
-static pidmap_t pidmap_array[PIDMAP_ENTRIES] =
+static struct pidmap pidmap_array[PIDMAP_ENTRIES] =
 	 { [ 0 ... PIDMAP_ENTRIES-1 ] = { ATOMIC_INIT(BITS_PER_PAGE), NULL } };
 
 /*
@@ -78,7 +78,7 @@ static  __cacheline_aligned_in_smp DEFINE_SPINLOCK(pidmap_lock);
 
 static fastcall void free_pidmap(int pid)
 {
-	pidmap_t *map = pidmap_array + pid / BITS_PER_PAGE;
+	struct pidmap *map = pidmap_array + pid / BITS_PER_PAGE;
 	int offset = pid & BITS_PER_PAGE_MASK;
 
 	clear_bit(offset, map->page);
@@ -88,7 +88,7 @@ static fastcall void free_pidmap(int pid)
 static int alloc_pidmap(void)
 {
 	int i, offset, max_scan, pid, last = last_pid;
-	pidmap_t *map;
+	struct pidmap *map;
 
 	pid = last + 1;
 	if (pid >= pid_max)

commit bbf73147e2d46611fbdcbc126f887c614c32350b
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Oct 2 02:17:11 2006 -0700

    [PATCH] pid: export the symbols needed to use struct pid *
    
    pids aren't something that drivers should care about.  However there are a lot
    of helper layers in the kernel that do care, and are built as modules.  Before
    I can convert them to using struct pid instead of pid_t I need to export the
    appropriate symbols so they can continue to be built.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index ed89a732432c..5c9037ba42f5 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -170,6 +170,7 @@ fastcall void put_pid(struct pid *pid)
 	     atomic_dec_and_test(&pid->count))
 		kmem_cache_free(pid_cachep, pid);
 }
+EXPORT_SYMBOL_GPL(put_pid);
 
 static void delayed_put_pid(struct rcu_head *rhp)
 {
@@ -234,6 +235,7 @@ struct pid * fastcall find_pid(int nr)
 	}
 	return NULL;
 }
+EXPORT_SYMBOL_GPL(find_pid);
 
 int fastcall attach_pid(struct task_struct *task, enum pid_type type, int nr)
 {
@@ -337,6 +339,7 @@ struct pid *find_ge_pid(int nr)
 
 	return pid;
 }
+EXPORT_SYMBOL_GPL(find_get_pid);
 
 /*
  * The pid hash table is scaled according to the amount of memory in the

commit 0804ef4b0de7121261f77c565b20a11ac694e877
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Oct 2 02:17:04 2006 -0700

    [PATCH] proc: readdir race fix (take 3)
    
    The problem: An opendir, readdir, closedir sequence can fail to report
    process ids that are continually in use throughout the sequence of system
    calls.  For this race to trigger the process that proc_pid_readdir stops at
    must exit before readdir is called again.
    
    This can cause ps to fail to report processes, and it is in violation of
    posix guarantees and normal application expectations with respect to
    readdir.
    
    Currently there is no way to work around this problem in user space short
    of providing a gargantuan buffer to user space so the directory read all
    happens in on system call.
    
    This patch implements the normal directory semantics for proc, that
    guarantee that a directory entry that is neither created nor destroyed
    while reading the directory entry will be returned.  For directory that are
    either created or destroyed during the readdir you may or may not see them.
     Furthermore you may seek to a directory offset you have previously seen.
    
    These are the guarantee that ext[23] provides and that posix requires, and
    more importantly that user space expects.  Plus it is a simple semantic to
    implement reliable service.  It is just a matter of calling readdir a
    second time if you are wondering if something new has show up.
    
    These better semantics are implemented by scanning through the pids in
    numerical order and by making the file offset a pid plus a fixed offset.
    
    The pid scan happens on the pid bitmap, which when you look at it is
    remarkably efficient for a brute force algorithm.  Given that a typical
    cache line is 64 bytes and thus covers space for 64*8 == 200 pids.  There
    are only 40 cache lines for the entire 32K pid space.  A typical system
    will have 100 pids or more so this is actually fewer cache lines we have to
    look at to scan a linked list, and the worst case of having to scan the
    entire pid bitmap is pretty reasonable.
    
    If we need something more efficient we can go to a more efficient data
    structure for indexing the pids, but for now what we have should be
    sufficient.
    
    In addition this takes no additional locks and is actually less code than
    what we are doing now.
    
    Also another very subtle bug in this area has been fixed.  It is possible
    to catch a task in the middle of de_thread where a thread is assuming the
    thread of it's thread group leader.  This patch carefully handles that case
    so if we hit it we don't fail to return the pid, that is undergoing the
    de_thread dance.
    
    Thanks to KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com> for
    providing the first fix, pointing this out and working on it.
    
    [oleg@tv-sign.ru: fix it]
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Acked-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Jean Delvare <jdelvare@suse.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 8387e8c68193..ed89a732432c 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -145,6 +145,23 @@ static int alloc_pidmap(void)
 	return -1;
 }
 
+static int next_pidmap(int last)
+{
+	int offset;
+	pidmap_t *map;
+
+	offset = (last + 1) & BITS_PER_PAGE_MASK;
+	map = &pidmap_array[(last + 1)/BITS_PER_PAGE];
+	for (; map < &pidmap_array[PIDMAP_ENTRIES]; map++, offset = 0) {
+		if (unlikely(!map->page))
+			continue;
+		offset = find_next_bit((map)->page, BITS_PER_PAGE, offset);
+		if (offset < BITS_PER_PAGE)
+			return mk_pid(map, offset);
+	}
+	return -1;
+}
+
 fastcall void put_pid(struct pid *pid)
 {
 	if (!pid)
@@ -302,6 +319,25 @@ struct pid *find_get_pid(pid_t nr)
 	return pid;
 }
 
+/*
+ * Used by proc to find the first pid that is greater then or equal to nr.
+ *
+ * If there is a pid at nr this function is exactly the same as find_pid.
+ */
+struct pid *find_ge_pid(int nr)
+{
+	struct pid *pid;
+
+	do {
+		pid = find_pid(nr);
+		if (pid)
+			break;
+		nr = next_pidmap(nr);
+	} while (nr > 0);
+
+	return pid;
+}
+
 /*
  * The pid hash table is scaled according to the amount of memory in the
  * machine.  From a minimum of 16 slots up to 4096 slots at one gigabyte or

commit 65800ac77e080cf159d6c1207b6886e18f22bc08
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Sep 27 01:51:11 2006 -0700

    [PATCH] pid: remove temporary debug code in attach_pid
    
    With the patches flying between Oleg and myself somehow this temporary
    debug code got left in pid.c.  It was never intended to make it to the
    stable kernel.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 6db82b68e2f8..8387e8c68193 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -223,9 +223,6 @@ int fastcall attach_pid(struct task_struct *task, enum pid_type type, int nr)
 	struct pid_link *link;
 	struct pid *pid;
 
-	WARN_ON(!task->pid); /* to be removed soon */
-	WARN_ON(!nr); /* to be removed soon */
-
 	link = &task->pids[type];
 	link->pid = pid = find_pid(nr);
 	hlist_add_head_rcu(&link->node, &pid->tasks[type]);

commit c18258c6f0848f97e85287f6271c511a092bb784
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Sep 27 01:51:06 2006 -0700

    [PATCH] pid: Implement transfer_pid and use it to simplify de_thread
    
    In de_thread we move pids from one process to another, a rather ugly case.
    The function transfer_pid makes it clear what we are doing, and makes the
    action atomic.  This is useful we ever want to atomically traverse the
    process group and session lists, in a rcu safe manner.
    
    Even if the atomic properties this change should be a win as transfer_pid
    should be less code to execute than executing both attach_pid and
    detach_pid, and this should make de_thread slightly smaller as only a
    single function call needs to be emitted.  The only downside is that the
    code might be slower to execute as the odds are against transfer_pid being
    in cache.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 93e212f20671..6db82b68e2f8 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -252,6 +252,15 @@ void fastcall detach_pid(struct task_struct *task, enum pid_type type)
 	free_pid(pid);
 }
 
+/* transfer_pid is an optimization of attach_pid(new), detach_pid(old) */
+void fastcall transfer_pid(struct task_struct *old, struct task_struct *new,
+			   enum pid_type type)
+{
+	new->pids[type].pid = old->pids[type].pid;
+	hlist_replace_rcu(&old->pids[type].node, &new->pids[type].node);
+	old->pids[type].pid = NULL;
+}
+
 struct task_struct * fastcall pid_task(struct pid *pid, enum pid_type type)
 {
 	struct task_struct *result = NULL;

commit 36c8b586896f60cb91a4fd526233190b34316baf
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Jul 3 00:25:41 2006 -0700

    [PATCH] sched: cleanup, remove task_t, convert to struct task_struct
    
    cleanup: remove task_t and convert all the uses to struct task_struct. I
    introduced it for the scheduler anno and it was a mistake.
    
    Conversion was mostly scripted, the result was reviewed and all
    secondary whitespace and style impact (if any) was fixed up by hand.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index eeb836b65ca4..93e212f20671 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -218,7 +218,7 @@ struct pid * fastcall find_pid(int nr)
 	return NULL;
 }
 
-int fastcall attach_pid(task_t *task, enum pid_type type, int nr)
+int fastcall attach_pid(struct task_struct *task, enum pid_type type, int nr)
 {
 	struct pid_link *link;
 	struct pid *pid;
@@ -233,7 +233,7 @@ int fastcall attach_pid(task_t *task, enum pid_type type, int nr)
 	return 0;
 }
 
-void fastcall detach_pid(task_t *task, enum pid_type type)
+void fastcall detach_pid(struct task_struct *task, enum pid_type type)
 {
 	struct pid_link *link;
 	struct pid *pid;
@@ -267,7 +267,7 @@ struct task_struct * fastcall pid_task(struct pid *pid, enum pid_type type)
 /*
  * Must be called under rcu_read_lock() or with tasklist_lock read-held.
  */
-task_t *find_task_by_pid_type(int type, int nr)
+struct task_struct *find_task_by_pid_type(int type, int nr)
 {
 	return pid_task(find_pid(nr), type);
 }

commit 92476d7fc0326a409ab1d3864a04093a6be9aca7
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Mar 31 02:31:42 2006 -0800

    [PATCH] pidhash: Refactor the pid hash table
    
    Simplifies the code, reduces the need for 4 pid hash tables, and makes the
    code more capable.
    
    In the discussions I had with Oleg it was felt that to a large extent the
    cleanup itself justified the work.  With struct pid being dynamically
    allocated meant we could create the hash table entry when the pid was
    allocated and free the hash table entry when the pid was freed.  Instead of
    playing with the hash lists when ever a process would attach or detach to a
    process.
    
    For myself the fact that it gave what my previous task_ref patch gave for free
    with simpler code was a big win.  The problem is that if you hold a reference
    to struct task_struct you lock in 10K of low memory.  If you do that in a user
    controllable way like /proc does, with an unprivileged but hostile user space
    application with typical resource limits of 1000 fds and 100 processes I can
    trigger the OOM killer by consuming all of low memory with task structs, on a
    machine wight 1GB of low memory.
    
    If I instead hold a reference to struct pid which holds a pointer to my
    task_struct, I don't suffer from that problem because struct pid is 2 orders
    of magnitude smaller.  In fact struct pid is small enough that most other
    kernel data structures dwarf it, so simply limiting the number of referring
    data structures is enough to prevent exhaustion of low memory.
    
    This splits the current struct pid into two structures, struct pid and struct
    pid_link, and reduces our number of hash tables from PIDTYPE_MAX to just one.
    struct pid_link is the per process linkage into the hash tables and lives in
    struct task_struct.  struct pid is given an indepedent lifetime, and holds
    pointers to each of the pid types.
    
    The independent life of struct pid simplifies attach_pid, and detach_pid,
    because we are always manipulating the list of pids and not the hash table.
    In addition in giving struct pid an indpendent life it makes the concept much
    more powerful.
    
    Kernel data structures can now embed a struct pid * instead of a pid_t and
    not suffer from pid wrap around problems or from keeping unnecessarily
    large amounts of memory allocated.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index a9f2dfd006d2..eeb836b65ca4 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -28,8 +28,9 @@
 #include <linux/hash.h>
 
 #define pid_hashfn(nr) hash_long((unsigned long)nr, pidhash_shift)
-static struct hlist_head *pid_hash[PIDTYPE_MAX];
+static struct hlist_head *pid_hash;
 static int pidhash_shift;
+static kmem_cache_t *pid_cachep;
 
 int pid_max = PID_MAX_DEFAULT;
 int last_pid;
@@ -60,9 +61,22 @@ typedef struct pidmap {
 static pidmap_t pidmap_array[PIDMAP_ENTRIES] =
 	 { [ 0 ... PIDMAP_ENTRIES-1 ] = { ATOMIC_INIT(BITS_PER_PAGE), NULL } };
 
+/*
+ * Note: disable interrupts while the pidmap_lock is held as an
+ * interrupt might come in and do read_lock(&tasklist_lock).
+ *
+ * If we don't disable interrupts there is a nasty deadlock between
+ * detach_pid()->free_pid() and another cpu that does
+ * spin_lock(&pidmap_lock) followed by an interrupt routine that does
+ * read_lock(&tasklist_lock);
+ *
+ * After we clean up the tasklist_lock and know there are no
+ * irq handlers that take it we can leave the interrupts enabled.
+ * For now it is easier to be safe than to prove it can't happen.
+ */
 static  __cacheline_aligned_in_smp DEFINE_SPINLOCK(pidmap_lock);
 
-fastcall void free_pidmap(int pid)
+static fastcall void free_pidmap(int pid)
 {
 	pidmap_t *map = pidmap_array + pid / BITS_PER_PAGE;
 	int offset = pid & BITS_PER_PAGE_MASK;
@@ -71,7 +85,7 @@ fastcall void free_pidmap(int pid)
 	atomic_inc(&map->nr_free);
 }
 
-int alloc_pidmap(void)
+static int alloc_pidmap(void)
 {
 	int i, offset, max_scan, pid, last = last_pid;
 	pidmap_t *map;
@@ -89,12 +103,12 @@ int alloc_pidmap(void)
 			 * Free the page if someone raced with us
 			 * installing it:
 			 */
-			spin_lock(&pidmap_lock);
+			spin_lock_irq(&pidmap_lock);
 			if (map->page)
 				free_page(page);
 			else
 				map->page = (void *)page;
-			spin_unlock(&pidmap_lock);
+			spin_unlock_irq(&pidmap_lock);
 			if (unlikely(!map->page))
 				break;
 		}
@@ -131,13 +145,73 @@ int alloc_pidmap(void)
 	return -1;
 }
 
-struct pid * fastcall find_pid(enum pid_type type, int nr)
+fastcall void put_pid(struct pid *pid)
+{
+	if (!pid)
+		return;
+	if ((atomic_read(&pid->count) == 1) ||
+	     atomic_dec_and_test(&pid->count))
+		kmem_cache_free(pid_cachep, pid);
+}
+
+static void delayed_put_pid(struct rcu_head *rhp)
+{
+	struct pid *pid = container_of(rhp, struct pid, rcu);
+	put_pid(pid);
+}
+
+fastcall void free_pid(struct pid *pid)
+{
+	/* We can be called with write_lock_irq(&tasklist_lock) held */
+	unsigned long flags;
+
+	spin_lock_irqsave(&pidmap_lock, flags);
+	hlist_del_rcu(&pid->pid_chain);
+	spin_unlock_irqrestore(&pidmap_lock, flags);
+
+	free_pidmap(pid->nr);
+	call_rcu(&pid->rcu, delayed_put_pid);
+}
+
+struct pid *alloc_pid(void)
+{
+	struct pid *pid;
+	enum pid_type type;
+	int nr = -1;
+
+	pid = kmem_cache_alloc(pid_cachep, GFP_KERNEL);
+	if (!pid)
+		goto out;
+
+	nr = alloc_pidmap();
+	if (nr < 0)
+		goto out_free;
+
+	atomic_set(&pid->count, 1);
+	pid->nr = nr;
+	for (type = 0; type < PIDTYPE_MAX; ++type)
+		INIT_HLIST_HEAD(&pid->tasks[type]);
+
+	spin_lock_irq(&pidmap_lock);
+	hlist_add_head_rcu(&pid->pid_chain, &pid_hash[pid_hashfn(pid->nr)]);
+	spin_unlock_irq(&pidmap_lock);
+
+out:
+	return pid;
+
+out_free:
+	kmem_cache_free(pid_cachep, pid);
+	pid = NULL;
+	goto out;
+}
+
+struct pid * fastcall find_pid(int nr)
 {
 	struct hlist_node *elem;
 	struct pid *pid;
 
 	hlist_for_each_entry_rcu(pid, elem,
-			&pid_hash[type][pid_hashfn(nr)], pid_chain) {
+			&pid_hash[pid_hashfn(nr)], pid_chain) {
 		if (pid->nr == nr)
 			return pid;
 	}
@@ -146,77 +220,82 @@ struct pid * fastcall find_pid(enum pid_type type, int nr)
 
 int fastcall attach_pid(task_t *task, enum pid_type type, int nr)
 {
-	struct pid *pid, *task_pid;
-
-	task_pid = &task->pids[type];
-	pid = find_pid(type, nr);
-	task_pid->nr = nr;
-	if (pid == NULL) {
-		INIT_LIST_HEAD(&task_pid->pid_list);
-		hlist_add_head_rcu(&task_pid->pid_chain,
-				   &pid_hash[type][pid_hashfn(nr)]);
-	} else {
-		INIT_HLIST_NODE(&task_pid->pid_chain);
-		list_add_tail_rcu(&task_pid->pid_list, &pid->pid_list);
-	}
+	struct pid_link *link;
+	struct pid *pid;
+
+	WARN_ON(!task->pid); /* to be removed soon */
+	WARN_ON(!nr); /* to be removed soon */
+
+	link = &task->pids[type];
+	link->pid = pid = find_pid(nr);
+	hlist_add_head_rcu(&link->node, &pid->tasks[type]);
 
 	return 0;
 }
 
-static fastcall int __detach_pid(task_t *task, enum pid_type type)
+void fastcall detach_pid(task_t *task, enum pid_type type)
 {
-	struct pid *pid, *pid_next;
-	int nr = 0;
+	struct pid_link *link;
+	struct pid *pid;
+	int tmp;
 
-	pid = &task->pids[type];
-	if (!hlist_unhashed(&pid->pid_chain)) {
+	link = &task->pids[type];
+	pid = link->pid;
 
-		if (list_empty(&pid->pid_list)) {
-			nr = pid->nr;
-			hlist_del_rcu(&pid->pid_chain);
-		} else {
-			pid_next = list_entry(pid->pid_list.next,
-						struct pid, pid_list);
-			/* insert next pid from pid_list to hash */
-			hlist_replace_rcu(&pid->pid_chain,
-					  &pid_next->pid_chain);
-		}
-	}
+	hlist_del_rcu(&link->node);
+	link->pid = NULL;
 
-	list_del_rcu(&pid->pid_list);
-	pid->nr = 0;
+	for (tmp = PIDTYPE_MAX; --tmp >= 0; )
+		if (!hlist_empty(&pid->tasks[tmp]))
+			return;
 
-	return nr;
+	free_pid(pid);
 }
 
-void fastcall detach_pid(task_t *task, enum pid_type type)
+struct task_struct * fastcall pid_task(struct pid *pid, enum pid_type type)
 {
-	int tmp, nr;
+	struct task_struct *result = NULL;
+	if (pid) {
+		struct hlist_node *first;
+		first = rcu_dereference(pid->tasks[type].first);
+		if (first)
+			result = hlist_entry(first, struct task_struct, pids[(type)].node);
+	}
+	return result;
+}
 
-	nr = __detach_pid(task, type);
-	if (!nr)
-		return;
+/*
+ * Must be called under rcu_read_lock() or with tasklist_lock read-held.
+ */
+task_t *find_task_by_pid_type(int type, int nr)
+{
+	return pid_task(find_pid(nr), type);
+}
 
-	for (tmp = PIDTYPE_MAX; --tmp >= 0; )
-		if (tmp != type && find_pid(tmp, nr))
-			return;
+EXPORT_SYMBOL(find_task_by_pid_type);
 
-	free_pidmap(nr);
+struct task_struct *fastcall get_pid_task(struct pid *pid, enum pid_type type)
+{
+	struct task_struct *result;
+	rcu_read_lock();
+	result = pid_task(pid, type);
+	if (result)
+		get_task_struct(result);
+	rcu_read_unlock();
+	return result;
 }
 
-task_t *find_task_by_pid_type(int type, int nr)
+struct pid *find_get_pid(pid_t nr)
 {
 	struct pid *pid;
 
-	pid = find_pid(type, nr);
-	if (!pid)
-		return NULL;
+	rcu_read_lock();
+	pid = get_pid(find_pid(nr));
+	rcu_read_unlock();
 
-	return pid_task(&pid->pid_list, type);
+	return pid;
 }
 
-EXPORT_SYMBOL(find_task_by_pid_type);
-
 /*
  * The pid hash table is scaled according to the amount of memory in the
  * machine.  From a minimum of 16 slots up to 4096 slots at one gigabyte or
@@ -224,7 +303,7 @@ EXPORT_SYMBOL(find_task_by_pid_type);
  */
 void __init pidhash_init(void)
 {
-	int i, j, pidhash_size;
+	int i, pidhash_size;
 	unsigned long megabytes = nr_kernel_pages >> (20 - PAGE_SHIFT);
 
 	pidhash_shift = max(4, fls(megabytes * 4));
@@ -233,16 +312,13 @@ void __init pidhash_init(void)
 
 	printk("PID hash table entries: %d (order: %d, %Zd bytes)\n",
 		pidhash_size, pidhash_shift,
-		PIDTYPE_MAX * pidhash_size * sizeof(struct hlist_head));
-
-	for (i = 0; i < PIDTYPE_MAX; i++) {
-		pid_hash[i] = alloc_bootmem(pidhash_size *
-					sizeof(*(pid_hash[i])));
-		if (!pid_hash[i])
-			panic("Could not alloc pidhash!\n");
-		for (j = 0; j < pidhash_size; j++)
-			INIT_HLIST_HEAD(&pid_hash[i][j]);
-	}
+		pidhash_size * sizeof(struct hlist_head));
+
+	pid_hash = alloc_bootmem(pidhash_size *	sizeof(*(pid_hash)));
+	if (!pid_hash)
+		panic("Could not alloc pidhash!\n");
+	for (i = 0; i < pidhash_size; i++)
+		INIT_HLIST_HEAD(&pid_hash[i]);
 }
 
 void __init pidmap_init(void)
@@ -251,4 +327,8 @@ void __init pidmap_init(void)
 	/* Reserve PID 0. We never call free_pidmap(0) */
 	set_bit(0, pidmap_array->page);
 	atomic_dec(&pidmap_array->nr_free);
+
+	pid_cachep = kmem_cache_create("pid", sizeof(struct pid),
+					__alignof__(struct pid),
+					SLAB_PANIC, NULL, NULL);
 }

commit 73b9ebfe126a4a886ee46cbab637374d7024668a
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Mar 28 16:11:07 2006 -0800

    [PATCH] pidhash: don't count idle threads
    
    fork_idle() does unhash_process() just after copy_process().  Contrary,
    boot_cpu's idle thread explicitely registers itself for each pid_type with nr
    = 0.
    
    copy_process() already checks p->pid != 0 before process_counts++, I think we
    can just skip attach_pid() calls and job control inits for idle threads and
    kill unhash_process().  We don't need to cleanup ->proc_dentry in fork_idle()
    because with this patch idle threads are never hashed in
    kernel/pid.c:pid_hash[].
    
    We don't need to hash pid == 0 in pidmap_init().  free_pidmap() is never
    called with pid == 0 arg, so it will never be reused.  So it is still possible
    to use pid == 0 in any PIDTYPE_xxx namespace from kernel/pid.c's POV.
    
    However with this patch we don't hash pid == 0 for PIDTYPE_PID case.  We still
    have have PIDTYPE_PGID/PIDTYPE_SID entries with pid == 0: /sbin/init and
    kernel threads which don't call daemonize().
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 7781d9999058..a9f2dfd006d2 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -247,16 +247,8 @@ void __init pidhash_init(void)
 
 void __init pidmap_init(void)
 {
-	int i;
-
 	pidmap_array->page = (void *)get_zeroed_page(GFP_KERNEL);
+	/* Reserve PID 0. We never call free_pidmap(0) */
 	set_bit(0, pidmap_array->page);
 	atomic_dec(&pidmap_array->nr_free);
-
-	/*
-	 * Allocate PID 0, and hash it via all PID types:
-	 */
-
-	for (i = 0; i < PIDTYPE_MAX; i++)
-		attach_pid(current, i, 0);
 }

commit d73d65293e3e2de7e916a89c8da30be0948afab7
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Mar 28 16:11:03 2006 -0800

    [PATCH] pidhash: kill switch_exec_pids
    
    switch_exec_pids is only called from de_thread by way of exec, and it is
    only called when we are exec'ing from a non thread group leader.
    
    Currently switch_exec_pids gives the leader the pid of the thread and
    unhashes and rehashes all of the process groups.  The leader is already in
    the EXIT_DEAD state so no one cares about it's pids.  The only concern for
    the leader is that __unhash_process called from release_task will function
    correctly.  If we don't touch the leader at all we know that
    __unhash_process will work fine so there is no need to touch the leader.
    
    For the task becomming the thread group leader, we just need to give it the
    pid of the old thread group leader, add it to the task list, and attach it
    to the session and the process group of the thread group.
    
    Currently de_thread is also adding the task to the task list which is just
    silly.
    
    Currently the only leader of __detach_pid besides detach_pid is
    switch_exec_pids because of the ugly extra work that was being
    performed.
    
    So this patch removes switch_exec_pids because it is doing too much, it is
    creating an unnecessary special case in pid.c, duing work duplicated in
    de_thread, and generally obscuring what it is going on.
    
    The necessary work is added to de_thread, and it seems to be a little
    clearer there what is going on.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Kirill Korotaev <dev@sw.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index 1acc07246991..7781d9999058 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -217,36 +217,6 @@ task_t *find_task_by_pid_type(int type, int nr)
 
 EXPORT_SYMBOL(find_task_by_pid_type);
 
-/*
- * This function switches the PIDs if a non-leader thread calls
- * sys_execve() - this must be done without releasing the PID.
- * (which a detach_pid() would eventually do.)
- */
-void switch_exec_pids(task_t *leader, task_t *thread)
-{
-	__detach_pid(leader, PIDTYPE_PID);
-	__detach_pid(leader, PIDTYPE_TGID);
-	__detach_pid(leader, PIDTYPE_PGID);
-	__detach_pid(leader, PIDTYPE_SID);
-
-	__detach_pid(thread, PIDTYPE_PID);
-	__detach_pid(thread, PIDTYPE_TGID);
-
-	leader->pid = leader->tgid = thread->pid;
-	thread->pid = thread->tgid;
-
-	attach_pid(thread, PIDTYPE_PID, thread->pid);
-	attach_pid(thread, PIDTYPE_TGID, thread->tgid);
-	attach_pid(thread, PIDTYPE_PGID, thread->signal->pgrp);
-	attach_pid(thread, PIDTYPE_SID, thread->signal->session);
-	list_add_tail(&thread->tasks, &init_task.tasks);
-
-	attach_pid(leader, PIDTYPE_PID, leader->pid);
-	attach_pid(leader, PIDTYPE_TGID, leader->tgid);
-	attach_pid(leader, PIDTYPE_PGID, leader->signal->pgrp);
-	attach_pid(leader, PIDTYPE_SID, leader->signal->session);
-}
-
 /*
  * The pid hash table is scaled according to the amount of memory in the
  * machine.  From a minimum of 16 slots up to 4096 slots at one gigabyte or

commit e56d090310d7625ecb43a1eeebd479f04affb48b
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Jan 8 01:01:37 2006 -0800

    [PATCH] RCU signal handling
    
    RCU tasklist_lock and RCU signal handling: send signals RCU-read-locked
    instead of tasklist_lock read-locked.  This is a scalability improvement on
    SMP and a preemption-latency improvement under PREEMPT_RCU.
    
    Signed-off-by: Paul E. McKenney <paulmck@us.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: William Irwin <wli@holomorphy.com>
    Cc: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/pid.c b/kernel/pid.c
index edba31c681ac..1acc07246991 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -136,7 +136,7 @@ struct pid * fastcall find_pid(enum pid_type type, int nr)
 	struct hlist_node *elem;
 	struct pid *pid;
 
-	hlist_for_each_entry(pid, elem,
+	hlist_for_each_entry_rcu(pid, elem,
 			&pid_hash[type][pid_hashfn(nr)], pid_chain) {
 		if (pid->nr == nr)
 			return pid;
@@ -150,15 +150,15 @@ int fastcall attach_pid(task_t *task, enum pid_type type, int nr)
 
 	task_pid = &task->pids[type];
 	pid = find_pid(type, nr);
+	task_pid->nr = nr;
 	if (pid == NULL) {
-		hlist_add_head(&task_pid->pid_chain,
-				&pid_hash[type][pid_hashfn(nr)]);
 		INIT_LIST_HEAD(&task_pid->pid_list);
+		hlist_add_head_rcu(&task_pid->pid_chain,
+				   &pid_hash[type][pid_hashfn(nr)]);
 	} else {
 		INIT_HLIST_NODE(&task_pid->pid_chain);
-		list_add_tail(&task_pid->pid_list, &pid->pid_list);
+		list_add_tail_rcu(&task_pid->pid_list, &pid->pid_list);
 	}
-	task_pid->nr = nr;
 
 	return 0;
 }
@@ -170,20 +170,20 @@ static fastcall int __detach_pid(task_t *task, enum pid_type type)
 
 	pid = &task->pids[type];
 	if (!hlist_unhashed(&pid->pid_chain)) {
-		hlist_del(&pid->pid_chain);
 
-		if (list_empty(&pid->pid_list))
+		if (list_empty(&pid->pid_list)) {
 			nr = pid->nr;
-		else {
+			hlist_del_rcu(&pid->pid_chain);
+		} else {
 			pid_next = list_entry(pid->pid_list.next,
 						struct pid, pid_list);
 			/* insert next pid from pid_list to hash */
-			hlist_add_head(&pid_next->pid_chain,
-				&pid_hash[type][pid_hashfn(pid_next->nr)]);
+			hlist_replace_rcu(&pid->pid_chain,
+					  &pid_next->pid_chain);
 		}
 	}
 
-	list_del(&pid->pid_list);
+	list_del_rcu(&pid->pid_list);
 	pid->nr = 0;
 
 	return nr;

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/kernel/pid.c b/kernel/pid.c
new file mode 100644
index 000000000000..edba31c681ac
--- /dev/null
+++ b/kernel/pid.c
@@ -0,0 +1,292 @@
+/*
+ * Generic pidhash and scalable, time-bounded PID allocator
+ *
+ * (C) 2002-2003 William Irwin, IBM
+ * (C) 2004 William Irwin, Oracle
+ * (C) 2002-2004 Ingo Molnar, Red Hat
+ *
+ * pid-structures are backing objects for tasks sharing a given ID to chain
+ * against. There is very little to them aside from hashing them and
+ * parking tasks using given ID's on a list.
+ *
+ * The hash is always changed with the tasklist_lock write-acquired,
+ * and the hash is only accessed with the tasklist_lock at least
+ * read-acquired, so there's no additional SMP locking needed here.
+ *
+ * We have a list of bitmap pages, which bitmaps represent the PID space.
+ * Allocating and freeing PIDs is completely lockless. The worst-case
+ * allocation scenario when all but one out of 1 million PIDs possible are
+ * allocated already: the scanning of 32 list entries and at most PAGE_SIZE
+ * bytes. The typical fastpath is a single successful setbit. Freeing is O(1).
+ */
+
+#include <linux/mm.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/init.h>
+#include <linux/bootmem.h>
+#include <linux/hash.h>
+
+#define pid_hashfn(nr) hash_long((unsigned long)nr, pidhash_shift)
+static struct hlist_head *pid_hash[PIDTYPE_MAX];
+static int pidhash_shift;
+
+int pid_max = PID_MAX_DEFAULT;
+int last_pid;
+
+#define RESERVED_PIDS		300
+
+int pid_max_min = RESERVED_PIDS + 1;
+int pid_max_max = PID_MAX_LIMIT;
+
+#define PIDMAP_ENTRIES		((PID_MAX_LIMIT + 8*PAGE_SIZE - 1)/PAGE_SIZE/8)
+#define BITS_PER_PAGE		(PAGE_SIZE*8)
+#define BITS_PER_PAGE_MASK	(BITS_PER_PAGE-1)
+#define mk_pid(map, off)	(((map) - pidmap_array)*BITS_PER_PAGE + (off))
+#define find_next_offset(map, off)					\
+		find_next_zero_bit((map)->page, BITS_PER_PAGE, off)
+
+/*
+ * PID-map pages start out as NULL, they get allocated upon
+ * first use and are never deallocated. This way a low pid_max
+ * value does not cause lots of bitmaps to be allocated, but
+ * the scheme scales to up to 4 million PIDs, runtime.
+ */
+typedef struct pidmap {
+	atomic_t nr_free;
+	void *page;
+} pidmap_t;
+
+static pidmap_t pidmap_array[PIDMAP_ENTRIES] =
+	 { [ 0 ... PIDMAP_ENTRIES-1 ] = { ATOMIC_INIT(BITS_PER_PAGE), NULL } };
+
+static  __cacheline_aligned_in_smp DEFINE_SPINLOCK(pidmap_lock);
+
+fastcall void free_pidmap(int pid)
+{
+	pidmap_t *map = pidmap_array + pid / BITS_PER_PAGE;
+	int offset = pid & BITS_PER_PAGE_MASK;
+
+	clear_bit(offset, map->page);
+	atomic_inc(&map->nr_free);
+}
+
+int alloc_pidmap(void)
+{
+	int i, offset, max_scan, pid, last = last_pid;
+	pidmap_t *map;
+
+	pid = last + 1;
+	if (pid >= pid_max)
+		pid = RESERVED_PIDS;
+	offset = pid & BITS_PER_PAGE_MASK;
+	map = &pidmap_array[pid/BITS_PER_PAGE];
+	max_scan = (pid_max + BITS_PER_PAGE - 1)/BITS_PER_PAGE - !offset;
+	for (i = 0; i <= max_scan; ++i) {
+		if (unlikely(!map->page)) {
+			unsigned long page = get_zeroed_page(GFP_KERNEL);
+			/*
+			 * Free the page if someone raced with us
+			 * installing it:
+			 */
+			spin_lock(&pidmap_lock);
+			if (map->page)
+				free_page(page);
+			else
+				map->page = (void *)page;
+			spin_unlock(&pidmap_lock);
+			if (unlikely(!map->page))
+				break;
+		}
+		if (likely(atomic_read(&map->nr_free))) {
+			do {
+				if (!test_and_set_bit(offset, map->page)) {
+					atomic_dec(&map->nr_free);
+					last_pid = pid;
+					return pid;
+				}
+				offset = find_next_offset(map, offset);
+				pid = mk_pid(map, offset);
+			/*
+			 * find_next_offset() found a bit, the pid from it
+			 * is in-bounds, and if we fell back to the last
+			 * bitmap block and the final block was the same
+			 * as the starting point, pid is before last_pid.
+			 */
+			} while (offset < BITS_PER_PAGE && pid < pid_max &&
+					(i != max_scan || pid < last ||
+					    !((last+1) & BITS_PER_PAGE_MASK)));
+		}
+		if (map < &pidmap_array[(pid_max-1)/BITS_PER_PAGE]) {
+			++map;
+			offset = 0;
+		} else {
+			map = &pidmap_array[0];
+			offset = RESERVED_PIDS;
+			if (unlikely(last == offset))
+				break;
+		}
+		pid = mk_pid(map, offset);
+	}
+	return -1;
+}
+
+struct pid * fastcall find_pid(enum pid_type type, int nr)
+{
+	struct hlist_node *elem;
+	struct pid *pid;
+
+	hlist_for_each_entry(pid, elem,
+			&pid_hash[type][pid_hashfn(nr)], pid_chain) {
+		if (pid->nr == nr)
+			return pid;
+	}
+	return NULL;
+}
+
+int fastcall attach_pid(task_t *task, enum pid_type type, int nr)
+{
+	struct pid *pid, *task_pid;
+
+	task_pid = &task->pids[type];
+	pid = find_pid(type, nr);
+	if (pid == NULL) {
+		hlist_add_head(&task_pid->pid_chain,
+				&pid_hash[type][pid_hashfn(nr)]);
+		INIT_LIST_HEAD(&task_pid->pid_list);
+	} else {
+		INIT_HLIST_NODE(&task_pid->pid_chain);
+		list_add_tail(&task_pid->pid_list, &pid->pid_list);
+	}
+	task_pid->nr = nr;
+
+	return 0;
+}
+
+static fastcall int __detach_pid(task_t *task, enum pid_type type)
+{
+	struct pid *pid, *pid_next;
+	int nr = 0;
+
+	pid = &task->pids[type];
+	if (!hlist_unhashed(&pid->pid_chain)) {
+		hlist_del(&pid->pid_chain);
+
+		if (list_empty(&pid->pid_list))
+			nr = pid->nr;
+		else {
+			pid_next = list_entry(pid->pid_list.next,
+						struct pid, pid_list);
+			/* insert next pid from pid_list to hash */
+			hlist_add_head(&pid_next->pid_chain,
+				&pid_hash[type][pid_hashfn(pid_next->nr)]);
+		}
+	}
+
+	list_del(&pid->pid_list);
+	pid->nr = 0;
+
+	return nr;
+}
+
+void fastcall detach_pid(task_t *task, enum pid_type type)
+{
+	int tmp, nr;
+
+	nr = __detach_pid(task, type);
+	if (!nr)
+		return;
+
+	for (tmp = PIDTYPE_MAX; --tmp >= 0; )
+		if (tmp != type && find_pid(tmp, nr))
+			return;
+
+	free_pidmap(nr);
+}
+
+task_t *find_task_by_pid_type(int type, int nr)
+{
+	struct pid *pid;
+
+	pid = find_pid(type, nr);
+	if (!pid)
+		return NULL;
+
+	return pid_task(&pid->pid_list, type);
+}
+
+EXPORT_SYMBOL(find_task_by_pid_type);
+
+/*
+ * This function switches the PIDs if a non-leader thread calls
+ * sys_execve() - this must be done without releasing the PID.
+ * (which a detach_pid() would eventually do.)
+ */
+void switch_exec_pids(task_t *leader, task_t *thread)
+{
+	__detach_pid(leader, PIDTYPE_PID);
+	__detach_pid(leader, PIDTYPE_TGID);
+	__detach_pid(leader, PIDTYPE_PGID);
+	__detach_pid(leader, PIDTYPE_SID);
+
+	__detach_pid(thread, PIDTYPE_PID);
+	__detach_pid(thread, PIDTYPE_TGID);
+
+	leader->pid = leader->tgid = thread->pid;
+	thread->pid = thread->tgid;
+
+	attach_pid(thread, PIDTYPE_PID, thread->pid);
+	attach_pid(thread, PIDTYPE_TGID, thread->tgid);
+	attach_pid(thread, PIDTYPE_PGID, thread->signal->pgrp);
+	attach_pid(thread, PIDTYPE_SID, thread->signal->session);
+	list_add_tail(&thread->tasks, &init_task.tasks);
+
+	attach_pid(leader, PIDTYPE_PID, leader->pid);
+	attach_pid(leader, PIDTYPE_TGID, leader->tgid);
+	attach_pid(leader, PIDTYPE_PGID, leader->signal->pgrp);
+	attach_pid(leader, PIDTYPE_SID, leader->signal->session);
+}
+
+/*
+ * The pid hash table is scaled according to the amount of memory in the
+ * machine.  From a minimum of 16 slots up to 4096 slots at one gigabyte or
+ * more.
+ */
+void __init pidhash_init(void)
+{
+	int i, j, pidhash_size;
+	unsigned long megabytes = nr_kernel_pages >> (20 - PAGE_SHIFT);
+
+	pidhash_shift = max(4, fls(megabytes * 4));
+	pidhash_shift = min(12, pidhash_shift);
+	pidhash_size = 1 << pidhash_shift;
+
+	printk("PID hash table entries: %d (order: %d, %Zd bytes)\n",
+		pidhash_size, pidhash_shift,
+		PIDTYPE_MAX * pidhash_size * sizeof(struct hlist_head));
+
+	for (i = 0; i < PIDTYPE_MAX; i++) {
+		pid_hash[i] = alloc_bootmem(pidhash_size *
+					sizeof(*(pid_hash[i])));
+		if (!pid_hash[i])
+			panic("Could not alloc pidhash!\n");
+		for (j = 0; j < pidhash_size; j++)
+			INIT_HLIST_HEAD(&pid_hash[i][j]);
+	}
+}
+
+void __init pidmap_init(void)
+{
+	int i;
+
+	pidmap_array->page = (void *)get_zeroed_page(GFP_KERNEL);
+	set_bit(0, pidmap_array->page);
+	atomic_dec(&pidmap_array->nr_free);
+
+	/*
+	 * Allocate PID 0, and hash it via all PID types:
+	 */
+
+	for (i = 0; i < PIDTYPE_MAX; i++)
+		attach_pid(current, i, 0);
+}
