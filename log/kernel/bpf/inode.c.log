commit 367ec3e4834cbd611401c2c40a23c22c825474f1
Author: Yonghong Song <yhs@fb.com>
Date:   Sat May 9 10:59:06 2020 -0700

    bpf: Create file bpf iterator
    
    To produce a file bpf iterator, the fd must be
    corresponding to a link_fd assocciated with a
    trace/iter program. When the pinned file is
    opened, a seq_file will be generated.
    
    Signed-off-by: Yonghong Song <yhs@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Andrii Nakryiko <andriin@fb.com>
    Link: https://lore.kernel.org/bpf/20200509175906.2475893-1-yhs@fb.com

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 95087d9f4ed3..fb878ba3f22f 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -358,8 +358,11 @@ static int bpf_mkmap(struct dentry *dentry, umode_t mode, void *arg)
 
 static int bpf_mklink(struct dentry *dentry, umode_t mode, void *arg)
 {
+	struct bpf_link *link = arg;
+
 	return bpf_mkobj_ops(dentry, mode, arg, &bpf_link_iops,
-			     &bpffs_obj_fops);
+			     bpf_link_is_iter(link) ?
+			     &bpf_iter_fops : &bpffs_obj_fops);
 }
 
 static struct dentry *

commit 70ed506c3bbcfa846d4636b23051ca79fa4781f7
Author: Andrii Nakryiko <andriin@fb.com>
Date:   Mon Mar 2 20:31:57 2020 -0800

    bpf: Introduce pinnable bpf_link abstraction
    
    Introduce bpf_link abstraction, representing an attachment of BPF program to
    a BPF hook point (e.g., tracepoint, perf event, etc). bpf_link encapsulates
    ownership of attached BPF program, reference counting of a link itself, when
    reference from multiple anonymous inodes, as well as ensures that release
    callback will be called from a process context, so that users can safely take
    mutex locks and sleep.
    
    Additionally, with a new abstraction it's now possible to generalize pinning
    of a link object in BPF FS, allowing to explicitly prevent BPF program
    detachment on process exit by pinning it in a BPF FS and let it open from
    independent other process to keep working with it.
    
    Convert two existing bpf_link-like objects (raw tracepoint and tracing BPF
    program attachments) into utilizing bpf_link framework, making them pinnable
    in BPF FS. More FD-based bpf_links will be added in follow up patches.
    
    Signed-off-by: Andrii Nakryiko <andriin@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/bpf/20200303043159.323675-2-andriin@fb.com

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 5e40e7fccc21..95087d9f4ed3 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -25,6 +25,7 @@ enum bpf_type {
 	BPF_TYPE_UNSPEC	= 0,
 	BPF_TYPE_PROG,
 	BPF_TYPE_MAP,
+	BPF_TYPE_LINK,
 };
 
 static void *bpf_any_get(void *raw, enum bpf_type type)
@@ -36,6 +37,9 @@ static void *bpf_any_get(void *raw, enum bpf_type type)
 	case BPF_TYPE_MAP:
 		bpf_map_inc_with_uref(raw);
 		break;
+	case BPF_TYPE_LINK:
+		bpf_link_inc(raw);
+		break;
 	default:
 		WARN_ON_ONCE(1);
 		break;
@@ -53,6 +57,9 @@ static void bpf_any_put(void *raw, enum bpf_type type)
 	case BPF_TYPE_MAP:
 		bpf_map_put_with_uref(raw);
 		break;
+	case BPF_TYPE_LINK:
+		bpf_link_put(raw);
+		break;
 	default:
 		WARN_ON_ONCE(1);
 		break;
@@ -63,20 +70,32 @@ static void *bpf_fd_probe_obj(u32 ufd, enum bpf_type *type)
 {
 	void *raw;
 
-	*type = BPF_TYPE_MAP;
 	raw = bpf_map_get_with_uref(ufd);
-	if (IS_ERR(raw)) {
+	if (!IS_ERR(raw)) {
+		*type = BPF_TYPE_MAP;
+		return raw;
+	}
+
+	raw = bpf_prog_get(ufd);
+	if (!IS_ERR(raw)) {
 		*type = BPF_TYPE_PROG;
-		raw = bpf_prog_get(ufd);
+		return raw;
 	}
 
-	return raw;
+	raw = bpf_link_get_from_fd(ufd);
+	if (!IS_ERR(raw)) {
+		*type = BPF_TYPE_LINK;
+		return raw;
+	}
+
+	return ERR_PTR(-EINVAL);
 }
 
 static const struct inode_operations bpf_dir_iops;
 
 static const struct inode_operations bpf_prog_iops = { };
 static const struct inode_operations bpf_map_iops  = { };
+static const struct inode_operations bpf_link_iops  = { };
 
 static struct inode *bpf_get_inode(struct super_block *sb,
 				   const struct inode *dir,
@@ -114,6 +133,8 @@ static int bpf_inode_type(const struct inode *inode, enum bpf_type *type)
 		*type = BPF_TYPE_PROG;
 	else if (inode->i_op == &bpf_map_iops)
 		*type = BPF_TYPE_MAP;
+	else if (inode->i_op == &bpf_link_iops)
+		*type = BPF_TYPE_LINK;
 	else
 		return -EACCES;
 
@@ -335,6 +356,12 @@ static int bpf_mkmap(struct dentry *dentry, umode_t mode, void *arg)
 			     &bpffs_map_fops : &bpffs_obj_fops);
 }
 
+static int bpf_mklink(struct dentry *dentry, umode_t mode, void *arg)
+{
+	return bpf_mkobj_ops(dentry, mode, arg, &bpf_link_iops,
+			     &bpffs_obj_fops);
+}
+
 static struct dentry *
 bpf_lookup(struct inode *dir, struct dentry *dentry, unsigned flags)
 {
@@ -411,6 +438,9 @@ static int bpf_obj_do_pin(const char __user *pathname, void *raw,
 	case BPF_TYPE_MAP:
 		ret = vfs_mkobj(dentry, mode, bpf_mkmap, raw);
 		break;
+	case BPF_TYPE_LINK:
+		ret = vfs_mkobj(dentry, mode, bpf_mklink, raw);
+		break;
 	default:
 		ret = -EPERM;
 	}
@@ -487,6 +517,8 @@ int bpf_obj_get_user(const char __user *pathname, int flags)
 		ret = bpf_prog_new_fd(raw);
 	else if (type == BPF_TYPE_MAP)
 		ret = bpf_map_new_fd(raw, f_flags);
+	else if (type == BPF_TYPE_LINK)
+		ret = bpf_link_new_fd(raw);
 	else
 		return -ENOENT;
 
@@ -504,6 +536,8 @@ static struct bpf_prog *__get_prog_inode(struct inode *inode, enum bpf_prog_type
 
 	if (inode->i_op == &bpf_map_iops)
 		return ERR_PTR(-EINVAL);
+	if (inode->i_op == &bpf_link_iops)
+		return ERR_PTR(-EINVAL);
 	if (inode->i_op != &bpf_prog_iops)
 		return ERR_PTR(-EACCES);
 

commit c9d35ee049b40f1d73e890bf88dd55f83b1e9be8
Merge: 236f45329460 f35aa2bc809e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Feb 8 13:26:41 2020 -0800

    Merge branch 'merge.nfs-fs_parse.1' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs file system parameter updates from Al Viro:
     "Saner fs_parser.c guts and data structures. The system-wide registry
      of syntax types (string/enum/int32/oct32/.../etc.) is gone and so is
      the horror switch() in fs_parse() that would have to grow another case
      every time something got added to that system-wide registry.
    
      New syntax types can be added by filesystems easily now, and their
      namespace is that of functions - not of system-wide enum members. IOW,
      they can be shared or kept private and if some turn out to be widely
      useful, we can make them common library helpers, etc., without having
      to do anything whatsoever to fs_parse() itself.
    
      And we already get that kind of requests - the thing that finally
      pushed me into doing that was "oh, and let's add one for timeouts -
      things like 15s or 2h". If some filesystem really wants that, let them
      do it. Without somebody having to play gatekeeper for the variants
      blessed by direct support in fs_parse(), TYVM.
    
      Quite a bit of boilerplate is gone. And IMO the data structures make a
      lot more sense now. -200LoC, while we are at it"
    
    * 'merge.nfs-fs_parse.1' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (25 commits)
      tmpfs: switch to use of invalfc()
      cgroup1: switch to use of errorfc() et.al.
      procfs: switch to use of invalfc()
      hugetlbfs: switch to use of invalfc()
      cramfs: switch to use of errofc() et.al.
      gfs2: switch to use of errorfc() et.al.
      fuse: switch to use errorfc() et.al.
      ceph: use errorfc() and friends instead of spelling the prefix out
      prefix-handling analogues of errorf() and friends
      turn fs_param_is_... into functions
      fs_parse: handle optional arguments sanely
      fs_parse: fold fs_parameter_desc/fs_parameter_spec
      fs_parser: remove fs_parameter_description name field
      add prefix to fs_context->log
      ceph_parse_param(), ceph_parse_mon_ips(): switch to passing fc_log
      new primitive: __fs_parse()
      switch rbd and libceph to p_log-based primitives
      struct p_log, variants of warnf() et.al. taking that one instead
      teach logfc() to handle prefices, give it saner calling conventions
      get rid of cg_invalf()
      ...

commit d7167b149943e38ad610191ecbb0800c78bbced9
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Sep 7 07:23:15 2019 -0400

    fs_parse: fold fs_parameter_desc/fs_parameter_spec
    
    The former contains nothing but a pointer to an array of the latter...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 9608aa48128d..f4b2ef72e265 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -587,15 +587,11 @@ enum {
 	OPT_MODE,
 };
 
-static const struct fs_parameter_spec bpf_param_specs[] = {
+static const struct fs_parameter_spec bpf_fs_parameters[] = {
 	fsparam_u32oct	("mode",			OPT_MODE),
 	{}
 };
 
-static const struct fs_parameter_description bpf_fs_parameters = {
-	.specs		= bpf_param_specs,
-};
-
 struct bpf_mount_opts {
 	umode_t mode;
 };
@@ -606,7 +602,7 @@ static int bpf_parse_param(struct fs_context *fc, struct fs_parameter *param)
 	struct fs_parse_result result;
 	int opt;
 
-	opt = fs_parse(fc, &bpf_fs_parameters, param, &result);
+	opt = fs_parse(fc, bpf_fs_parameters, param, &result);
 	if (opt < 0)
 		/* We might like to report bad mount options here, but
 		 * traditionally we've ignored all mount options, so we'd
@@ -682,7 +678,7 @@ static struct file_system_type bpf_fs_type = {
 	.owner		= THIS_MODULE,
 	.name		= "bpf",
 	.init_fs_context = bpf_init_fs_context,
-	.parameters	= &bpf_fs_parameters,
+	.parameters	= bpf_fs_parameters,
 	.kill_sb	= kill_litter_super,
 };
 

commit 96cafb9ccb153f6a82ff2c9bde68916d9d65501e
Author: Eric Sandeen <sandeen@sandeen.net>
Date:   Fri Dec 6 10:45:01 2019 -0600

    fs_parser: remove fs_parameter_description name field
    
    Unused now.
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index ecf42bec38c0..9608aa48128d 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -593,7 +593,6 @@ static const struct fs_parameter_spec bpf_param_specs[] = {
 };
 
 static const struct fs_parameter_description bpf_fs_parameters = {
-	.name		= "bpf",
 	.specs		= bpf_param_specs,
 };
 

commit 90435a7891a2259b0f74c5a1bc5600d0d64cba8f
Author: Vasily Averin <vvs@virtuozzo.com>
Date:   Sat Jan 25 12:10:02 2020 +0300

    bpf: map_seq_next should always increase position index
    
    If seq_file .next fuction does not change position index,
    read after some lseek can generate an unexpected output.
    
    See also: https://bugzilla.kernel.org/show_bug.cgi?id=206283
    
    v1 -> v2: removed missed increment in end of function
    
    Signed-off-by: Vasily Averin <vvs@virtuozzo.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Link: https://lore.kernel.org/bpf/eca84fdd-c374-a154-d874-6c7b55fc3bc4@virtuozzo.com

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index e11059b99f18..bd2fd8eab470 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -196,6 +196,7 @@ static void *map_seq_next(struct seq_file *m, void *v, loff_t *pos)
 	void *key = map_iter(m)->key;
 	void *prev_key;
 
+	(*pos)++;
 	if (map_iter(m)->done)
 		return NULL;
 
@@ -208,8 +209,6 @@ static void *map_seq_next(struct seq_file *m, void *v, loff_t *pos)
 		map_iter(m)->done = true;
 		return NULL;
 	}
-
-	++(*pos);
 	return key;
 }
 

commit b87121dd3fa0a4d2636c0ad02a3b3fc5161fa26b
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jan 20 23:28:58 2020 +0000

    bpf: don't bother with getname/kern_path - use user_path_at
    
    kernel/bpf/inode.c misuses kern_path...() - it's much simpler (and
    more efficient, on top of that) to use user_path...() counterparts
    rather than bothering with doing getname() manually.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Link: https://lore.kernel.org/bpf/20200120232858.GF8904@ZenIV.linux.org.uk

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index ecf42bec38c0..e11059b99f18 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -380,7 +380,7 @@ static const struct inode_operations bpf_dir_iops = {
 	.unlink		= simple_unlink,
 };
 
-static int bpf_obj_do_pin(const struct filename *pathname, void *raw,
+static int bpf_obj_do_pin(const char __user *pathname, void *raw,
 			  enum bpf_type type)
 {
 	struct dentry *dentry;
@@ -389,7 +389,7 @@ static int bpf_obj_do_pin(const struct filename *pathname, void *raw,
 	umode_t mode;
 	int ret;
 
-	dentry = kern_path_create(AT_FDCWD, pathname->name, &path, 0);
+	dentry = user_path_create(AT_FDCWD, pathname, &path, 0);
 	if (IS_ERR(dentry))
 		return PTR_ERR(dentry);
 
@@ -422,30 +422,22 @@ static int bpf_obj_do_pin(const struct filename *pathname, void *raw,
 
 int bpf_obj_pin_user(u32 ufd, const char __user *pathname)
 {
-	struct filename *pname;
 	enum bpf_type type;
 	void *raw;
 	int ret;
 
-	pname = getname(pathname);
-	if (IS_ERR(pname))
-		return PTR_ERR(pname);
-
 	raw = bpf_fd_probe_obj(ufd, &type);
-	if (IS_ERR(raw)) {
-		ret = PTR_ERR(raw);
-		goto out;
-	}
+	if (IS_ERR(raw))
+		return PTR_ERR(raw);
 
-	ret = bpf_obj_do_pin(pname, raw, type);
+	ret = bpf_obj_do_pin(pathname, raw, type);
 	if (ret != 0)
 		bpf_any_put(raw, type);
-out:
-	putname(pname);
+
 	return ret;
 }
 
-static void *bpf_obj_do_get(const struct filename *pathname,
+static void *bpf_obj_do_get(const char __user *pathname,
 			    enum bpf_type *type, int flags)
 {
 	struct inode *inode;
@@ -453,7 +445,7 @@ static void *bpf_obj_do_get(const struct filename *pathname,
 	void *raw;
 	int ret;
 
-	ret = kern_path(pathname->name, LOOKUP_FOLLOW, &path);
+	ret = user_path_at(AT_FDCWD, pathname, LOOKUP_FOLLOW, &path);
 	if (ret)
 		return ERR_PTR(ret);
 
@@ -480,36 +472,27 @@ static void *bpf_obj_do_get(const struct filename *pathname,
 int bpf_obj_get_user(const char __user *pathname, int flags)
 {
 	enum bpf_type type = BPF_TYPE_UNSPEC;
-	struct filename *pname;
-	int ret = -ENOENT;
 	int f_flags;
 	void *raw;
+	int ret;
 
 	f_flags = bpf_get_file_flag(flags);
 	if (f_flags < 0)
 		return f_flags;
 
-	pname = getname(pathname);
-	if (IS_ERR(pname))
-		return PTR_ERR(pname);
-
-	raw = bpf_obj_do_get(pname, &type, f_flags);
-	if (IS_ERR(raw)) {
-		ret = PTR_ERR(raw);
-		goto out;
-	}
+	raw = bpf_obj_do_get(pathname, &type, f_flags);
+	if (IS_ERR(raw))
+		return PTR_ERR(raw);
 
 	if (type == BPF_TYPE_PROG)
 		ret = bpf_prog_new_fd(raw);
 	else if (type == BPF_TYPE_MAP)
 		ret = bpf_map_new_fd(raw, f_flags);
 	else
-		goto out;
+		return -ENOENT;
 
 	if (ret < 0)
 		bpf_any_put(raw, type);
-out:
-	putname(pname);
 	return ret;
 }
 

commit 85192dbf4de08795afe2b88e52a36fc6abfc3dba
Author: Andrii Nakryiko <andriin@fb.com>
Date:   Sun Nov 17 09:28:03 2019 -0800

    bpf: Convert bpf_prog refcnt to atomic64_t
    
    Similarly to bpf_map's refcnt/usercnt, convert bpf_prog's refcnt to atomic64
    and remove artificial 32k limit. This allows to make bpf_prog's refcounting
    non-failing, simplifying logic of users of bpf_prog_add/bpf_prog_inc.
    
    Validated compilation by running allyesconfig kernel build.
    
    Suggested-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: Andrii Nakryiko <andriin@fb.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Link: https://lore.kernel.org/bpf/20191117172806.2195367-3-andriin@fb.com

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 2f17f24258dc..ecf42bec38c0 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -31,7 +31,7 @@ static void *bpf_any_get(void *raw, enum bpf_type type)
 {
 	switch (type) {
 	case BPF_TYPE_PROG:
-		raw = bpf_prog_inc(raw);
+		bpf_prog_inc(raw);
 		break;
 	case BPF_TYPE_MAP:
 		bpf_map_inc_with_uref(raw);
@@ -534,7 +534,8 @@ static struct bpf_prog *__get_prog_inode(struct inode *inode, enum bpf_prog_type
 	if (!bpf_prog_get_ok(prog, &type, false))
 		return ERR_PTR(-EINVAL);
 
-	return bpf_prog_inc(prog);
+	bpf_prog_inc(prog);
+	return prog;
 }
 
 struct bpf_prog *bpf_prog_get_type_path(const char *name, enum bpf_prog_type type)

commit 1e0bd5a091e5d9e0f1d5b0e6329b87bb1792f784
Author: Andrii Nakryiko <andriin@fb.com>
Date:   Sun Nov 17 09:28:02 2019 -0800

    bpf: Switch bpf_map ref counter to atomic64_t so bpf_map_inc() never fails
    
    92117d8443bc ("bpf: fix refcnt overflow") turned refcounting of bpf_map into
    potentially failing operation, when refcount reaches BPF_MAX_REFCNT limit
    (32k). Due to using 32-bit counter, it's possible in practice to overflow
    refcounter and make it wrap around to 0, causing erroneous map free, while
    there are still references to it, causing use-after-free problems.
    
    But having a failing refcounting operations are problematic in some cases. One
    example is mmap() interface. After establishing initial memory-mapping, user
    is allowed to arbitrarily map/remap/unmap parts of mapped memory, arbitrarily
    splitting it into multiple non-contiguous regions. All this happening without
    any control from the users of mmap subsystem. Rather mmap subsystem sends
    notifications to original creator of memory mapping through open/close
    callbacks, which are optionally specified during initial memory mapping
    creation. These callbacks are used to maintain accurate refcount for bpf_map
    (see next patch in this series). The problem is that open() callback is not
    supposed to fail, because memory-mapped resource is set up and properly
    referenced. This is posing a problem for using memory-mapping with BPF maps.
    
    One solution to this is to maintain separate refcount for just memory-mappings
    and do single bpf_map_inc/bpf_map_put when it goes from/to zero, respectively.
    There are similar use cases in current work on tcp-bpf, necessitating extra
    counter as well. This seems like a rather unfortunate and ugly solution that
    doesn't scale well to various new use cases.
    
    Another approach to solve this is to use non-failing refcount_t type, which
    uses 32-bit counter internally, but, once reaching overflow state at UINT_MAX,
    stays there. This utlimately causes memory leak, but prevents use after free.
    
    But given refcounting is not the most performance-critical operation with BPF
    maps (it's not used from running BPF program code), we can also just switch to
    64-bit counter that can't overflow in practice, potentially disadvantaging
    32-bit platforms a tiny bit. This simplifies semantics and allows above
    described scenarios to not worry about failing refcount increment operation.
    
    In terms of struct bpf_map size, we are still good and use the same amount of
    space:
    
    BEFORE (3 cache lines, 8 bytes of padding at the end):
    struct bpf_map {
            const struct bpf_map_ops  * ops __attribute__((__aligned__(64))); /*     0     8 */
            struct bpf_map *           inner_map_meta;       /*     8     8 */
            void *                     security;             /*    16     8 */
            enum bpf_map_type  map_type;                     /*    24     4 */
            u32                        key_size;             /*    28     4 */
            u32                        value_size;           /*    32     4 */
            u32                        max_entries;          /*    36     4 */
            u32                        map_flags;            /*    40     4 */
            int                        spin_lock_off;        /*    44     4 */
            u32                        id;                   /*    48     4 */
            int                        numa_node;            /*    52     4 */
            u32                        btf_key_type_id;      /*    56     4 */
            u32                        btf_value_type_id;    /*    60     4 */
            /* --- cacheline 1 boundary (64 bytes) --- */
            struct btf *               btf;                  /*    64     8 */
            struct bpf_map_memory memory;                    /*    72    16 */
            bool                       unpriv_array;         /*    88     1 */
            bool                       frozen;               /*    89     1 */
    
            /* XXX 38 bytes hole, try to pack */
    
            /* --- cacheline 2 boundary (128 bytes) --- */
            atomic_t                   refcnt __attribute__((__aligned__(64))); /*   128     4 */
            atomic_t                   usercnt;              /*   132     4 */
            struct work_struct work;                         /*   136    32 */
            char                       name[16];             /*   168    16 */
    
            /* size: 192, cachelines: 3, members: 21 */
            /* sum members: 146, holes: 1, sum holes: 38 */
            /* padding: 8 */
            /* forced alignments: 2, forced holes: 1, sum forced holes: 38 */
    } __attribute__((__aligned__(64)));
    
    AFTER (same 3 cache lines, no extra padding now):
    struct bpf_map {
            const struct bpf_map_ops  * ops __attribute__((__aligned__(64))); /*     0     8 */
            struct bpf_map *           inner_map_meta;       /*     8     8 */
            void *                     security;             /*    16     8 */
            enum bpf_map_type  map_type;                     /*    24     4 */
            u32                        key_size;             /*    28     4 */
            u32                        value_size;           /*    32     4 */
            u32                        max_entries;          /*    36     4 */
            u32                        map_flags;            /*    40     4 */
            int                        spin_lock_off;        /*    44     4 */
            u32                        id;                   /*    48     4 */
            int                        numa_node;            /*    52     4 */
            u32                        btf_key_type_id;      /*    56     4 */
            u32                        btf_value_type_id;    /*    60     4 */
            /* --- cacheline 1 boundary (64 bytes) --- */
            struct btf *               btf;                  /*    64     8 */
            struct bpf_map_memory memory;                    /*    72    16 */
            bool                       unpriv_array;         /*    88     1 */
            bool                       frozen;               /*    89     1 */
    
            /* XXX 38 bytes hole, try to pack */
    
            /* --- cacheline 2 boundary (128 bytes) --- */
            atomic64_t                 refcnt __attribute__((__aligned__(64))); /*   128     8 */
            atomic64_t                 usercnt;              /*   136     8 */
            struct work_struct work;                         /*   144    32 */
            char                       name[16];             /*   176    16 */
    
            /* size: 192, cachelines: 3, members: 21 */
            /* sum members: 154, holes: 1, sum holes: 38 */
            /* forced alignments: 2, forced holes: 1, sum forced holes: 38 */
    } __attribute__((__aligned__(64)));
    
    This patch, while modifying all users of bpf_map_inc, also cleans up its
    interface to match bpf_map_put with separate operations for bpf_map_inc and
    bpf_map_inc_with_uref (to match bpf_map_put and bpf_map_put_with_uref,
    respectively). Also, given there are no users of bpf_map_inc_not_zero
    specifying uref=true, remove uref flag and default to uref=false internally.
    
    Signed-off-by: Andrii Nakryiko <andriin@fb.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Song Liu <songliubraving@fb.com>
    Link: https://lore.kernel.org/bpf/20191117172806.2195367-2-andriin@fb.com

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index a70f7209cda3..2f17f24258dc 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -34,7 +34,7 @@ static void *bpf_any_get(void *raw, enum bpf_type type)
 		raw = bpf_prog_inc(raw);
 		break;
 	case BPF_TYPE_MAP:
-		raw = bpf_map_inc(raw, true);
+		bpf_map_inc_with_uref(raw);
 		break;
 	default:
 		WARN_ON_ONCE(1);

commit d2935de7e4fd3f873976f1872b505584b727574c
Author: David Howells <dhowells@redhat.com>
Date:   Fri Mar 22 14:58:36 2019 +0000

    vfs: Convert bpf to use the new mount API
    
    Convert the bpf filesystem to the new internal mount API as the old
    one will be obsoleted and removed.  This allows greater flexibility in
    communication of mount parameters between userspace, the VFS and the
    filesystem.
    
    See Documentation/filesystems/mount_api.txt for more information.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    cc: Alexei Starovoitov <ast@kernel.org>
    cc: Daniel Borkmann <daniel@iogearbox.net>
    cc: Martin KaFai Lau <kafai@fb.com>
    cc: Song Liu <songliubraving@fb.com>
    cc: Yonghong Song <yhs@fb.com>
    cc: netdev@vger.kernel.org
    cc: bpf@vger.kernel.org
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index cc0d0cf114e3..a70f7209cda3 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -14,8 +14,9 @@
 #include <linux/mount.h>
 #include <linux/namei.h>
 #include <linux/fs.h>
+#include <linux/fs_context.h>
+#include <linux/fs_parser.h>
 #include <linux/kdev_t.h>
-#include <linux/parser.h>
 #include <linux/filter.h>
 #include <linux/bpf.h>
 #include <linux/bpf_trace.h>
@@ -583,58 +584,52 @@ static const struct super_operations bpf_super_ops = {
 
 enum {
 	OPT_MODE,
-	OPT_ERR,
 };
 
-static const match_table_t bpf_mount_tokens = {
-	{ OPT_MODE, "mode=%o" },
-	{ OPT_ERR, NULL },
+static const struct fs_parameter_spec bpf_param_specs[] = {
+	fsparam_u32oct	("mode",			OPT_MODE),
+	{}
+};
+
+static const struct fs_parameter_description bpf_fs_parameters = {
+	.name		= "bpf",
+	.specs		= bpf_param_specs,
 };
 
 struct bpf_mount_opts {
 	umode_t mode;
 };
 
-static int bpf_parse_options(char *data, struct bpf_mount_opts *opts)
+static int bpf_parse_param(struct fs_context *fc, struct fs_parameter *param)
 {
-	substring_t args[MAX_OPT_ARGS];
-	int option, token;
-	char *ptr;
+	struct bpf_mount_opts *opts = fc->fs_private;
+	struct fs_parse_result result;
+	int opt;
 
-	opts->mode = S_IRWXUGO;
-
-	while ((ptr = strsep(&data, ",")) != NULL) {
-		if (!*ptr)
-			continue;
-
-		token = match_token(ptr, bpf_mount_tokens, args);
-		switch (token) {
-		case OPT_MODE:
-			if (match_octal(&args[0], &option))
-				return -EINVAL;
-			opts->mode = option & S_IALLUGO;
-			break;
+	opt = fs_parse(fc, &bpf_fs_parameters, param, &result);
+	if (opt < 0)
 		/* We might like to report bad mount options here, but
 		 * traditionally we've ignored all mount options, so we'd
 		 * better continue to ignore non-existing options for bpf.
 		 */
-		}
+		return opt == -ENOPARAM ? 0 : opt;
+
+	switch (opt) {
+	case OPT_MODE:
+		opts->mode = result.uint_32 & S_IALLUGO;
+		break;
 	}
 
 	return 0;
 }
 
-static int bpf_fill_super(struct super_block *sb, void *data, int silent)
+static int bpf_fill_super(struct super_block *sb, struct fs_context *fc)
 {
 	static const struct tree_descr bpf_rfiles[] = { { "" } };
-	struct bpf_mount_opts opts;
+	struct bpf_mount_opts *opts = fc->fs_private;
 	struct inode *inode;
 	int ret;
 
-	ret = bpf_parse_options(data, &opts);
-	if (ret)
-		return ret;
-
 	ret = simple_fill_super(sb, BPF_FS_MAGIC, bpf_rfiles);
 	if (ret)
 		return ret;
@@ -644,21 +639,50 @@ static int bpf_fill_super(struct super_block *sb, void *data, int silent)
 	inode = sb->s_root->d_inode;
 	inode->i_op = &bpf_dir_iops;
 	inode->i_mode &= ~S_IALLUGO;
-	inode->i_mode |= S_ISVTX | opts.mode;
+	inode->i_mode |= S_ISVTX | opts->mode;
 
 	return 0;
 }
 
-static struct dentry *bpf_mount(struct file_system_type *type, int flags,
-				const char *dev_name, void *data)
+static int bpf_get_tree(struct fs_context *fc)
+{
+	return get_tree_nodev(fc, bpf_fill_super);
+}
+
+static void bpf_free_fc(struct fs_context *fc)
 {
-	return mount_nodev(type, flags, data, bpf_fill_super);
+	kfree(fc->fs_private);
+}
+
+static const struct fs_context_operations bpf_context_ops = {
+	.free		= bpf_free_fc,
+	.parse_param	= bpf_parse_param,
+	.get_tree	= bpf_get_tree,
+};
+
+/*
+ * Set up the filesystem mount context.
+ */
+static int bpf_init_fs_context(struct fs_context *fc)
+{
+	struct bpf_mount_opts *opts;
+
+	opts = kzalloc(sizeof(struct bpf_mount_opts), GFP_KERNEL);
+	if (!opts)
+		return -ENOMEM;
+
+	opts->mode = S_IRWXUGO;
+
+	fc->fs_private = opts;
+	fc->ops = &bpf_context_ops;
+	return 0;
 }
 
 static struct file_system_type bpf_fs_type = {
 	.owner		= THIS_MODULE,
 	.name		= "bpf",
-	.mount		= bpf_mount,
+	.init_fs_context = bpf_init_fs_context,
+	.parameters	= &bpf_fs_parameters,
 	.kill_sb	= kill_litter_super,
 };
 

commit d2912cb15bdda8ba4a5dd73396ad62641af2f520
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 4 10:11:33 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 500
    
    Based on 2 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation #
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 4122 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190604081206.933168790@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 84a80b02db99..cc0d0cf114e3 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * Minimal file system backend for holding eBPF maps and programs,
  * used by bpf(2) object pinning.
@@ -5,10 +6,6 @@
  * Authors:
  *
  *	Daniel Borkmann <daniel@iogearbox.net>
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * version 2 as published by the Free Software Foundation.
  */
 
 #include <linux/init.h>

commit e547ff3f803e779a3898f1f48447b29f43c54085
Author: Chenbo Feng <fengc@google.com>
Date:   Tue May 14 19:42:57 2019 -0700

    bpf: relax inode permission check for retrieving bpf program
    
    For iptable module to load a bpf program from a pinned location, it
    only retrieve a loaded program and cannot change the program content so
    requiring a write permission for it might not be necessary.
    Also when adding or removing an unrelated iptable rule, it might need to
    flush and reload the xt_bpf related rules as well and triggers the inode
    permission check. It might be better to remove the write premission
    check for the inode so we won't need to grant write access to all the
    processes that flush and restore iptables rules.
    
    Signed-off-by: Chenbo Feng <fengc@google.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index bc53e5b20ddc..84a80b02db99 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -518,7 +518,7 @@ int bpf_obj_get_user(const char __user *pathname, int flags)
 static struct bpf_prog *__get_prog_inode(struct inode *inode, enum bpf_prog_type type)
 {
 	struct bpf_prog *prog;
-	int ret = inode_permission(inode, MAY_READ | MAY_WRITE);
+	int ret = inode_permission(inode, MAY_READ);
 	if (ret)
 		return ERR_PTR(ret);
 

commit 524845ff9c473d315468fa3b54054a7e6b2d95cf
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Apr 15 22:31:29 2019 -0400

    bpf: switch to ->free_inode()
    
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Song Liu <songliubraving@fb.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 4a8f390a2b82..bc53e5b20ddc 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -566,9 +566,8 @@ static int bpf_show_options(struct seq_file *m, struct dentry *root)
 	return 0;
 }
 
-static void bpf_destroy_inode_deferred(struct rcu_head *head)
+static void bpf_free_inode(struct inode *inode)
 {
-	struct inode *inode = container_of(head, struct inode, i_rcu);
 	enum bpf_type type;
 
 	if (S_ISLNK(inode->i_mode))
@@ -578,16 +577,11 @@ static void bpf_destroy_inode_deferred(struct rcu_head *head)
 	free_inode_nonrcu(inode);
 }
 
-static void bpf_destroy_inode(struct inode *inode)
-{
-	call_rcu(&inode->i_rcu, bpf_destroy_inode_deferred);
-}
-
 static const struct super_operations bpf_super_ops = {
 	.statfs		= simple_statfs,
 	.drop_inode	= generic_delete_inode,
 	.show_options	= bpf_show_options,
-	.destroy_inode	= bpf_destroy_inode,
+	.free_inode	= bpf_free_inode,
 };
 
 enum {

commit 1da6c4d9140cb7c13e87667dc4e1488d6c8fc10f
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Mon Mar 25 15:54:43 2019 +0100

    bpf: fix use after free in bpf_evict_inode
    
    syzkaller was able to generate the following UAF in bpf:
    
      BUG: KASAN: use-after-free in lookup_last fs/namei.c:2269 [inline]
      BUG: KASAN: use-after-free in path_lookupat.isra.43+0x9f8/0xc00 fs/namei.c:2318
      Read of size 1 at addr ffff8801c4865c47 by task syz-executor2/9423
    
      CPU: 0 PID: 9423 Comm: syz-executor2 Not tainted 4.20.0-rc1-next-20181109+
      #110
      Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS
      Google 01/01/2011
      Call Trace:
        __dump_stack lib/dump_stack.c:77 [inline]
        dump_stack+0x244/0x39d lib/dump_stack.c:113
        print_address_description.cold.7+0x9/0x1ff mm/kasan/report.c:256
        kasan_report_error mm/kasan/report.c:354 [inline]
        kasan_report.cold.8+0x242/0x309 mm/kasan/report.c:412
        __asan_report_load1_noabort+0x14/0x20 mm/kasan/report.c:430
        lookup_last fs/namei.c:2269 [inline]
        path_lookupat.isra.43+0x9f8/0xc00 fs/namei.c:2318
        filename_lookup+0x26a/0x520 fs/namei.c:2348
        user_path_at_empty+0x40/0x50 fs/namei.c:2608
        user_path include/linux/namei.h:62 [inline]
        do_mount+0x180/0x1ff0 fs/namespace.c:2980
        ksys_mount+0x12d/0x140 fs/namespace.c:3258
        __do_sys_mount fs/namespace.c:3272 [inline]
        __se_sys_mount fs/namespace.c:3269 [inline]
        __x64_sys_mount+0xbe/0x150 fs/namespace.c:3269
        do_syscall_64+0x1b9/0x820 arch/x86/entry/common.c:290
        entry_SYSCALL_64_after_hwframe+0x49/0xbe
      RIP: 0033:0x457569
      Code: fd b3 fb ff c3 66 2e 0f 1f 84 00 00 00 00 00 66 90 48 89 f8 48 89 f7
      48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff
      ff 0f 83 cb b3 fb ff c3 66 2e 0f 1f 84 00 00 00 00
      RSP: 002b:00007fde6ed96c78 EFLAGS: 00000246 ORIG_RAX: 00000000000000a5
      RAX: ffffffffffffffda RBX: 0000000000000005 RCX: 0000000000457569
      RDX: 0000000020000040 RSI: 0000000020000000 RDI: 0000000000000000
      RBP: 000000000072bf00 R08: 0000000020000340 R09: 0000000000000000
      R10: 0000000000200000 R11: 0000000000000246 R12: 00007fde6ed976d4
      R13: 00000000004c2c24 R14: 00000000004d4990 R15: 00000000ffffffff
    
      Allocated by task 9424:
        save_stack+0x43/0xd0 mm/kasan/kasan.c:448
        set_track mm/kasan/kasan.c:460 [inline]
        kasan_kmalloc+0xc7/0xe0 mm/kasan/kasan.c:553
        __do_kmalloc mm/slab.c:3722 [inline]
        __kmalloc_track_caller+0x157/0x760 mm/slab.c:3737
        kstrdup+0x39/0x70 mm/util.c:49
        bpf_symlink+0x26/0x140 kernel/bpf/inode.c:356
        vfs_symlink+0x37a/0x5d0 fs/namei.c:4127
        do_symlinkat+0x242/0x2d0 fs/namei.c:4154
        __do_sys_symlink fs/namei.c:4173 [inline]
        __se_sys_symlink fs/namei.c:4171 [inline]
        __x64_sys_symlink+0x59/0x80 fs/namei.c:4171
        do_syscall_64+0x1b9/0x820 arch/x86/entry/common.c:290
        entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
      Freed by task 9425:
        save_stack+0x43/0xd0 mm/kasan/kasan.c:448
        set_track mm/kasan/kasan.c:460 [inline]
        __kasan_slab_free+0x102/0x150 mm/kasan/kasan.c:521
        kasan_slab_free+0xe/0x10 mm/kasan/kasan.c:528
        __cache_free mm/slab.c:3498 [inline]
        kfree+0xcf/0x230 mm/slab.c:3817
        bpf_evict_inode+0x11f/0x150 kernel/bpf/inode.c:565
        evict+0x4b9/0x980 fs/inode.c:558
        iput_final fs/inode.c:1550 [inline]
        iput+0x674/0xa90 fs/inode.c:1576
        do_unlinkat+0x733/0xa30 fs/namei.c:4069
        __do_sys_unlink fs/namei.c:4110 [inline]
        __se_sys_unlink fs/namei.c:4108 [inline]
        __x64_sys_unlink+0x42/0x50 fs/namei.c:4108
        do_syscall_64+0x1b9/0x820 arch/x86/entry/common.c:290
        entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    In this scenario path lookup under RCU is racing with the final
    unlink in case of symlinks. As Linus puts it in his analysis:
    
      [...] We actually RCU-delay the inode freeing itself, but
      when we do the final iput(), the "evict()" function is called
      synchronously. Now, the simple fix would seem to just RCU-delay
      the kfree() of the symlink data in bpf_evict_inode(). Maybe
      that's the right thing to do. [...]
    
    Al suggested to piggy-back on the ->destroy_inode() callback in
    order to implement RCU deferral there which can then kfree() the
    inode->i_link eventually right before putting inode back into
    inode cache. By reusing free_inode_nonrcu() from there we can
    avoid the need for our own inode cache and just reuse generic
    one as we currently do.
    
    And in-fact on top of all this we should just get rid of the
    bpf_evict_inode() entirely. This means truncate_inode_pages_final()
    and clear_inode() will then simply be called by the fs core via
    evict(). Dropping the reference should really only be done when
    inode is unhashed and nothing reachable anymore, so it's better
    also moved into the final ->destroy_inode() callback.
    
    Fixes: 0f98621bef5d ("bpf, inode: add support for symlinks and fix mtime/ctime")
    Reported-by: syzbot+fb731ca573367b7f6564@syzkaller.appspotmail.com
    Reported-by: syzbot+a13e5ead792d6df37818@syzkaller.appspotmail.com
    Reported-by: syzbot+7a8ba368b47fdefca61e@syzkaller.appspotmail.com
    Suggested-by: Al Viro <viro@zeniv.linux.org.uk>
    Analyzed-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Acked-by: Al Viro <viro@zeniv.linux.org.uk>
    Link: https://lore.kernel.org/lkml/0000000000006946d2057bbd0eef@google.com/T/

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 2ada5e21dfa6..4a8f390a2b82 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -554,19 +554,6 @@ struct bpf_prog *bpf_prog_get_type_path(const char *name, enum bpf_prog_type typ
 }
 EXPORT_SYMBOL(bpf_prog_get_type_path);
 
-static void bpf_evict_inode(struct inode *inode)
-{
-	enum bpf_type type;
-
-	truncate_inode_pages_final(&inode->i_data);
-	clear_inode(inode);
-
-	if (S_ISLNK(inode->i_mode))
-		kfree(inode->i_link);
-	if (!bpf_inode_type(inode, &type))
-		bpf_any_put(inode->i_private, type);
-}
-
 /*
  * Display the mount options in /proc/mounts.
  */
@@ -579,11 +566,28 @@ static int bpf_show_options(struct seq_file *m, struct dentry *root)
 	return 0;
 }
 
+static void bpf_destroy_inode_deferred(struct rcu_head *head)
+{
+	struct inode *inode = container_of(head, struct inode, i_rcu);
+	enum bpf_type type;
+
+	if (S_ISLNK(inode->i_mode))
+		kfree(inode->i_link);
+	if (!bpf_inode_type(inode, &type))
+		bpf_any_put(inode->i_private, type);
+	free_inode_nonrcu(inode);
+}
+
+static void bpf_destroy_inode(struct inode *inode)
+{
+	call_rcu(&inode->i_rcu, bpf_destroy_inode_deferred);
+}
+
 static const struct super_operations bpf_super_ops = {
 	.statfs		= simple_statfs,
 	.drop_inode	= generic_delete_inode,
 	.show_options	= bpf_show_options,
-	.evict_inode	= bpf_evict_inode,
+	.destroy_inode	= bpf_destroy_inode,
 };
 
 enum {

commit e8d2bec0457962e8f348a9a3627b398f7fe5c5fc
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Sun Aug 12 01:59:17 2018 +0200

    bpf: decouple btf from seq bpf fs dump and enable more maps
    
    Commit a26ca7c982cb ("bpf: btf: Add pretty print support to
    the basic arraymap") and 699c86d6ec21 ("bpf: btf: add pretty
    print for hash/lru_hash maps") enabled support for BTF and
    dumping via BPF fs for array and hash/lru map. However, both
    can be decoupled from each other such that regular BPF maps
    can be supported for attaching BTF key/value information,
    while not all maps necessarily need to dump via map_seq_show_elem()
    callback.
    
    The basic sanity check which is a prerequisite for all maps
    is that key/value size has to match in any case, and some maps
    can have extra checks via map_check_btf() callback, e.g.
    probing certain types or indicating no support in general. With
    that we can also enable retrieving BTF info for per-cpu map
    types and lpm.
    
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Yonghong Song <yhs@fb.com>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index fc5b103512e7..2ada5e21dfa6 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -334,7 +334,8 @@ static int bpf_mkmap(struct dentry *dentry, umode_t mode, void *arg)
 	struct bpf_map *map = arg;
 
 	return bpf_mkobj_ops(dentry, mode, arg, &bpf_map_iops,
-			     map->btf ? &bpffs_map_fops : &bpffs_obj_fops);
+			     bpf_map_support_seq_show(map) ?
+			     &bpffs_map_fops : &bpffs_obj_fops);
 }
 
 static struct dentry *

commit dc1508a579e682a1e5f1ed0753390e0aa7c23a97
Author: Yonghong Song <yhs@fb.com>
Date:   Thu Aug 9 08:55:19 2018 -0700

    bpf: fix bpffs non-array map seq_show issue
    
    In function map_seq_next() of kernel/bpf/inode.c,
    the first key will be the "0" regardless of the map type.
    This works for array. But for hash type, if it happens
    key "0" is in the map, the bpffs map show will miss
    some items if the key "0" is not the first element of
    the first bucket.
    
    This patch fixed the issue by guaranteeing to get
    the first element, if the seq_show is just started,
    by passing NULL pointer key to map_get_next_key() callback.
    This way, no missing elements will occur for
    bpffs hash table show even if key "0" is in the map.
    
    Fixes: a26ca7c982cb5 ("bpf: btf: Add pretty print support to the basic arraymap")
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Yonghong Song <yhs@fb.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 76efe9a183f5..fc5b103512e7 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -196,19 +196,21 @@ static void *map_seq_next(struct seq_file *m, void *v, loff_t *pos)
 {
 	struct bpf_map *map = seq_file_to_map(m);
 	void *key = map_iter(m)->key;
+	void *prev_key;
 
 	if (map_iter(m)->done)
 		return NULL;
 
 	if (unlikely(v == SEQ_START_TOKEN))
-		goto done;
+		prev_key = NULL;
+	else
+		prev_key = key;
 
-	if (map->ops->map_get_next_key(map, key, key)) {
+	if (map->ops->map_get_next_key(map, prev_key, key)) {
 		map_iter(m)->done = true;
 		return NULL;
 	}
 
-done:
 	++(*pos);
 	return key;
 }

commit b16558579576c8f2781062b638600f68954b1827
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Fri Jun 8 18:10:34 2018 +0200

    bpf: implement dummy fops for bpf objects
    
    syzkaller was able to trigger the following warning in
    do_dentry_open():
    
      WARNING: CPU: 1 PID: 4508 at fs/open.c:778 do_dentry_open+0x4ad/0xe40 fs/open.c:778
      Kernel panic - not syncing: panic_on_warn set ...
    
      CPU: 1 PID: 4508 Comm: syz-executor867 Not tainted 4.17.0+ #90
      Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
      Call Trace:
      [...]
       vfs_open+0x139/0x230 fs/open.c:908
       do_last fs/namei.c:3370 [inline]
       path_openat+0x1717/0x4dc0 fs/namei.c:3511
       do_filp_open+0x249/0x350 fs/namei.c:3545
       do_sys_open+0x56f/0x740 fs/open.c:1101
       __do_sys_openat fs/open.c:1128 [inline]
       __se_sys_openat fs/open.c:1122 [inline]
       __x64_sys_openat+0x9d/0x100 fs/open.c:1122
       do_syscall_64+0x1b1/0x800 arch/x86/entry/common.c:287
       entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    Problem was that prog and map inodes in bpf fs did not
    implement a dummy file open operation that would return an
    error. The patch in do_dentry_open() checks whether f_ops
    are present and if not bails out with an error. While this
    may be fine, we really shouldn't be throwing a warning
    though. Thus follow the model similar to bad_file_ops and
    reject the request unconditionally with -EIO.
    
    Fixes: b2197755b263 ("bpf: add support for persistent maps/progs")
    Reported-by: syzbot+2e7fcab0f56fdbb330b8@syzkaller.appspotmail.com
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index ed13645bd80c..76efe9a183f5 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -295,6 +295,15 @@ static const struct file_operations bpffs_map_fops = {
 	.release	= bpffs_map_release,
 };
 
+static int bpffs_obj_open(struct inode *inode, struct file *file)
+{
+	return -EIO;
+}
+
+static const struct file_operations bpffs_obj_fops = {
+	.open		= bpffs_obj_open,
+};
+
 static int bpf_mkobj_ops(struct dentry *dentry, umode_t mode, void *raw,
 			 const struct inode_operations *iops,
 			 const struct file_operations *fops)
@@ -314,7 +323,8 @@ static int bpf_mkobj_ops(struct dentry *dentry, umode_t mode, void *raw,
 
 static int bpf_mkprog(struct dentry *dentry, umode_t mode, void *arg)
 {
-	return bpf_mkobj_ops(dentry, mode, arg, &bpf_prog_iops, NULL);
+	return bpf_mkobj_ops(dentry, mode, arg, &bpf_prog_iops,
+			     &bpffs_obj_fops);
 }
 
 static int bpf_mkmap(struct dentry *dentry, umode_t mode, void *arg)
@@ -322,7 +332,7 @@ static int bpf_mkmap(struct dentry *dentry, umode_t mode, void *arg)
 	struct bpf_map *map = arg;
 
 	return bpf_mkobj_ops(dentry, mode, arg, &bpf_map_iops,
-			     map->btf ? &bpffs_map_fops : NULL);
+			     map->btf ? &bpffs_map_fops : &bpffs_obj_fops);
 }
 
 static struct dentry *

commit 4d220ed0f8140c478ab7b0a14d96821da639b646
Author: Alexei Starovoitov <ast@kernel.org>
Date:   Sat Apr 28 19:56:37 2018 -0700

    bpf: remove tracepoints from bpf core
    
    tracepoints to bpf core were added as a way to provide introspection
    to bpf programs and maps, but after some time it became clear that
    this approach is inadequate, so prog_id, map_id and corresponding
    get_next_id, get_fd_by_id, get_info_by_fd, prog_query APIs were
    introduced and fully adopted by bpftool and other applications.
    The tracepoints in bpf core started to rot and causing syzbot warnings:
    WARNING: CPU: 0 PID: 3008 at kernel/trace/trace_event_perf.c:274
    Kernel panic - not syncing: panic_on_warn set ...
    perf_trace_bpf_map_keyval+0x260/0xbd0 include/trace/events/bpf.h:228
    trace_bpf_map_update_elem include/trace/events/bpf.h:274 [inline]
    map_update_elem kernel/bpf/syscall.c:597 [inline]
    SYSC_bpf kernel/bpf/syscall.c:1478 [inline]
    Hence this patch deletes tracepoints in bpf core.
    
    Reported-by: Eric Biggers <ebiggers3@gmail.com>
    Reported-by: syzbot <bot+a9dbb3c3e64b62536a4bc5ee7bbd4ca627566188@syzkaller.appspotmail.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index a41343009ccc..ed13645bd80c 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -429,13 +429,6 @@ int bpf_obj_pin_user(u32 ufd, const char __user *pathname)
 	ret = bpf_obj_do_pin(pname, raw, type);
 	if (ret != 0)
 		bpf_any_put(raw, type);
-	if ((trace_bpf_obj_pin_prog_enabled() ||
-	     trace_bpf_obj_pin_map_enabled()) && !ret) {
-		if (type == BPF_TYPE_PROG)
-			trace_bpf_obj_pin_prog(raw, ufd, pname);
-		if (type == BPF_TYPE_MAP)
-			trace_bpf_obj_pin_map(raw, ufd, pname);
-	}
 out:
 	putname(pname);
 	return ret;
@@ -502,15 +495,8 @@ int bpf_obj_get_user(const char __user *pathname, int flags)
 	else
 		goto out;
 
-	if (ret < 0) {
+	if (ret < 0)
 		bpf_any_put(raw, type);
-	} else if (trace_bpf_obj_get_prog_enabled() ||
-		   trace_bpf_obj_get_map_enabled()) {
-		if (type == BPF_TYPE_PROG)
-			trace_bpf_obj_get_prog(raw, ret, pname);
-		if (type == BPF_TYPE_MAP)
-			trace_bpf_obj_get_map(raw, ret, pname);
-	}
 out:
 	putname(pname);
 	return ret;

commit a26ca7c982cb576749cbdd01e8ecde4bf010d60a
Author: Martin KaFai Lau <kafai@fb.com>
Date:   Wed Apr 18 15:56:03 2018 -0700

    bpf: btf: Add pretty print support to the basic arraymap
    
    This patch adds pretty print support to the basic arraymap.
    Support for other bpf maps can be added later.
    
    This patch adds new attrs to the BPF_MAP_CREATE command to allow
    specifying the btf_fd, btf_key_id and btf_value_id.  The
    BPF_MAP_CREATE can then associate the btf to the map if
    the creating map supports BTF.
    
    A BTF supported map needs to implement two new map ops,
    map_seq_show_elem() and map_check_btf().  This patch has
    implemented these new map ops for the basic arraymap.
    
    It also adds file_operations, bpffs_map_fops, to the pinned
    map such that the pinned map can be opened and read.
    After that, the user has an intuitive way to do
    "cat bpffs/pathto/a-pinned-map" instead of getting
    an error.
    
    bpffs_map_fops should not be extended further to support
    other operations.  Other operations (e.g. write/key-lookup...)
    should be realized by the userspace tools (e.g. bpftool) through
    the BPF_OBJ_GET_INFO_BY_FD, map's lookup/update interface...etc.
    Follow up patches will allow the userspace to obtain
    the BTF from a map-fd.
    
    Here is a sample output when reading a pinned arraymap
    with the following map's value:
    
    struct map_value {
            int count_a;
            int count_b;
    };
    
    cat /sys/fs/bpf/pinned_array_map:
    
    0: {1,2}
    1: {3,4}
    2: {5,6}
    ...
    
    Signed-off-by: Martin KaFai Lau <kafai@fb.com>
    Acked-by: Alexei Starovoitov <ast@fb.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index bf6da59ae0d0..a41343009ccc 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -150,8 +150,154 @@ static int bpf_mkdir(struct inode *dir, struct dentry *dentry, umode_t mode)
 	return 0;
 }
 
+struct map_iter {
+	void *key;
+	bool done;
+};
+
+static struct map_iter *map_iter(struct seq_file *m)
+{
+	return m->private;
+}
+
+static struct bpf_map *seq_file_to_map(struct seq_file *m)
+{
+	return file_inode(m->file)->i_private;
+}
+
+static void map_iter_free(struct map_iter *iter)
+{
+	if (iter) {
+		kfree(iter->key);
+		kfree(iter);
+	}
+}
+
+static struct map_iter *map_iter_alloc(struct bpf_map *map)
+{
+	struct map_iter *iter;
+
+	iter = kzalloc(sizeof(*iter), GFP_KERNEL | __GFP_NOWARN);
+	if (!iter)
+		goto error;
+
+	iter->key = kzalloc(map->key_size, GFP_KERNEL | __GFP_NOWARN);
+	if (!iter->key)
+		goto error;
+
+	return iter;
+
+error:
+	map_iter_free(iter);
+	return NULL;
+}
+
+static void *map_seq_next(struct seq_file *m, void *v, loff_t *pos)
+{
+	struct bpf_map *map = seq_file_to_map(m);
+	void *key = map_iter(m)->key;
+
+	if (map_iter(m)->done)
+		return NULL;
+
+	if (unlikely(v == SEQ_START_TOKEN))
+		goto done;
+
+	if (map->ops->map_get_next_key(map, key, key)) {
+		map_iter(m)->done = true;
+		return NULL;
+	}
+
+done:
+	++(*pos);
+	return key;
+}
+
+static void *map_seq_start(struct seq_file *m, loff_t *pos)
+{
+	if (map_iter(m)->done)
+		return NULL;
+
+	return *pos ? map_iter(m)->key : SEQ_START_TOKEN;
+}
+
+static void map_seq_stop(struct seq_file *m, void *v)
+{
+}
+
+static int map_seq_show(struct seq_file *m, void *v)
+{
+	struct bpf_map *map = seq_file_to_map(m);
+	void *key = map_iter(m)->key;
+
+	if (unlikely(v == SEQ_START_TOKEN)) {
+		seq_puts(m, "# WARNING!! The output is for debug purpose only\n");
+		seq_puts(m, "# WARNING!! The output format will change\n");
+	} else {
+		map->ops->map_seq_show_elem(map, key, m);
+	}
+
+	return 0;
+}
+
+static const struct seq_operations bpffs_map_seq_ops = {
+	.start	= map_seq_start,
+	.next	= map_seq_next,
+	.show	= map_seq_show,
+	.stop	= map_seq_stop,
+};
+
+static int bpffs_map_open(struct inode *inode, struct file *file)
+{
+	struct bpf_map *map = inode->i_private;
+	struct map_iter *iter;
+	struct seq_file *m;
+	int err;
+
+	iter = map_iter_alloc(map);
+	if (!iter)
+		return -ENOMEM;
+
+	err = seq_open(file, &bpffs_map_seq_ops);
+	if (err) {
+		map_iter_free(iter);
+		return err;
+	}
+
+	m = file->private_data;
+	m->private = iter;
+
+	return 0;
+}
+
+static int bpffs_map_release(struct inode *inode, struct file *file)
+{
+	struct seq_file *m = file->private_data;
+
+	map_iter_free(map_iter(m));
+
+	return seq_release(inode, file);
+}
+
+/* bpffs_map_fops should only implement the basic
+ * read operation for a BPF map.  The purpose is to
+ * provide a simple user intuitive way to do
+ * "cat bpffs/pathto/a-pinned-map".
+ *
+ * Other operations (e.g. write, lookup...) should be realized by
+ * the userspace tools (e.g. bpftool) through the
+ * BPF_OBJ_GET_INFO_BY_FD and the map's lookup/update
+ * interface.
+ */
+static const struct file_operations bpffs_map_fops = {
+	.open		= bpffs_map_open,
+	.read		= seq_read,
+	.release	= bpffs_map_release,
+};
+
 static int bpf_mkobj_ops(struct dentry *dentry, umode_t mode, void *raw,
-			 const struct inode_operations *iops)
+			 const struct inode_operations *iops,
+			 const struct file_operations *fops)
 {
 	struct inode *dir = dentry->d_parent->d_inode;
 	struct inode *inode = bpf_get_inode(dir->i_sb, dir, mode);
@@ -159,6 +305,7 @@ static int bpf_mkobj_ops(struct dentry *dentry, umode_t mode, void *raw,
 		return PTR_ERR(inode);
 
 	inode->i_op = iops;
+	inode->i_fop = fops;
 	inode->i_private = raw;
 
 	bpf_dentry_finalize(dentry, inode, dir);
@@ -167,12 +314,15 @@ static int bpf_mkobj_ops(struct dentry *dentry, umode_t mode, void *raw,
 
 static int bpf_mkprog(struct dentry *dentry, umode_t mode, void *arg)
 {
-	return bpf_mkobj_ops(dentry, mode, arg, &bpf_prog_iops);
+	return bpf_mkobj_ops(dentry, mode, arg, &bpf_prog_iops, NULL);
 }
 
 static int bpf_mkmap(struct dentry *dentry, umode_t mode, void *arg)
 {
-	return bpf_mkobj_ops(dentry, mode, arg, &bpf_map_iops);
+	struct bpf_map *map = arg;
+
+	return bpf_mkobj_ops(dentry, mode, arg, &bpf_map_iops,
+			     map->btf ? &bpffs_map_fops : NULL);
 }
 
 static struct dentry *

commit 6d8cb045cde681e64a5ed80a2ab70be831a7f9b0
Author: Quentin Monnet <quentin.monnet@netronome.com>
Date:   Thu Mar 8 23:46:33 2018 -0800

    bpf: comment why dots in filenames under BPF virtual FS are not allowed
    
    When pinning a file under the BPF virtual file system (traditionally
    /sys/fs/bpf), using a dot in the name of the location to pin at is not
    allowed. For example, trying to pin at "/sys/fs/bpf/foo.bar" will be
    rejected with -EPERM.
    
    This check was introduced at the same time as the BPF file system
    itself, with commit b2197755b263 ("bpf: add support for persistent
    maps/progs"). At this time, it was checked in a function called
    "bpf_dname_reserved()", which made clear that using a dot was reserved
    for future extensions.
    
    This function disappeared and the check was moved elsewhere with commit
    0c93b7d85d40 ("bpf: reject invalid names right in ->lookup()"), and the
    meaning of the dot ban was lost.
    
    The present commit simply adds a comment in the source to explain to the
    reader that the usage of dots is reserved for future usage.
    
    Signed-off-by: Quentin Monnet <quentin.monnet@netronome.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 81e2f6995adb..bf6da59ae0d0 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -178,6 +178,9 @@ static int bpf_mkmap(struct dentry *dentry, umode_t mode, void *arg)
 static struct dentry *
 bpf_lookup(struct inode *dir, struct dentry *dentry, unsigned flags)
 {
+	/* Dots in names (e.g. "/sys/fs/bpf/foo.bar") are reserved for future
+	 * extensions.
+	 */
 	if (strchr(dentry->d_name.name, '.'))
 		return ERR_PTR(-EPERM);
 

commit 8b0fdf631cf6a31f60a9ed3e1c0f37a9715de807
Merge: 168fe32a072a 36735a6a2b5e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jan 30 18:32:21 2018 -0800

    Merge branch 'work.mqueue' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull mqueue/bpf vfs cleanups from Al Viro:
     "mqueue and bpf go through rather painful and similar contortions to
      create objects in their dentry trees. Provide a primitive for doing
      that without abusing ->mknod(), switch bpf and mqueue to it.
    
      Another mqueue-related thing that has ended up in that branch is
      on-demand creation of internal mount (based upon the work of Giuseppe
      Scrivano)"
    
    * 'work.mqueue' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      mqueue: switch to on-demand creation of internal mount
      tidy do_mq_open() up a bit
      mqueue: clean prepare_open() up
      do_mq_open(): move all work prior to dentry_open() into a helper
      mqueue: fold mq_attr_ok() into mqueue_get_inode()
      move dentry_open() calls up into do_mq_open()
      mqueue: switch to vfs_mkobj(), quit abusing ->d_fsdata
      bpf_obj_do_pin(): switch to vfs_mkobj(), quit abusing ->mknod()
      new primitive: vfs_mkobj()

commit a4a0683fd5e64e029421a465525352f01d57f27a
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Dec 1 17:22:19 2017 -0500

    bpf_obj_do_pin(): switch to vfs_mkobj(), quit abusing ->mknod()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 01aaef1a77c5..2b75faccc771 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -150,39 +150,29 @@ static int bpf_mkdir(struct inode *dir, struct dentry *dentry, umode_t mode)
 	return 0;
 }
 
-static int bpf_mkobj_ops(struct inode *dir, struct dentry *dentry,
-			 umode_t mode, const struct inode_operations *iops)
+static int bpf_mkobj_ops(struct dentry *dentry, umode_t mode, void *raw,
+			 const struct inode_operations *iops)
 {
-	struct inode *inode;
-
-	inode = bpf_get_inode(dir->i_sb, dir, mode | S_IFREG);
+	struct inode *dir = dentry->d_parent->d_inode;
+	struct inode *inode = bpf_get_inode(dir->i_sb, dir, mode);
 	if (IS_ERR(inode))
 		return PTR_ERR(inode);
 
 	inode->i_op = iops;
-	inode->i_private = dentry->d_fsdata;
+	inode->i_private = raw;
 
 	bpf_dentry_finalize(dentry, inode, dir);
 	return 0;
 }
 
-static int bpf_mkobj(struct inode *dir, struct dentry *dentry, umode_t mode,
-		     dev_t devt)
+static int bpf_mkprog(struct dentry *dentry, umode_t mode, void *arg)
 {
-	enum bpf_type type = MINOR(devt);
-
-	if (MAJOR(devt) != UNNAMED_MAJOR || !S_ISREG(mode) ||
-	    dentry->d_fsdata == NULL)
-		return -EPERM;
+	return bpf_mkobj_ops(dentry, mode, arg, &bpf_prog_iops);
+}
 
-	switch (type) {
-	case BPF_TYPE_PROG:
-		return bpf_mkobj_ops(dir, dentry, mode, &bpf_prog_iops);
-	case BPF_TYPE_MAP:
-		return bpf_mkobj_ops(dir, dentry, mode, &bpf_map_iops);
-	default:
-		return -EPERM;
-	}
+static int bpf_mkmap(struct dentry *dentry, umode_t mode, void *arg)
+{
+	return bpf_mkobj_ops(dentry, mode, arg, &bpf_map_iops);
 }
 
 static struct dentry *
@@ -218,7 +208,6 @@ static int bpf_symlink(struct inode *dir, struct dentry *dentry,
 
 static const struct inode_operations bpf_dir_iops = {
 	.lookup		= bpf_lookup,
-	.mknod		= bpf_mkobj,
 	.mkdir		= bpf_mkdir,
 	.symlink	= bpf_symlink,
 	.rmdir		= simple_rmdir,
@@ -234,7 +223,6 @@ static int bpf_obj_do_pin(const struct filename *pathname, void *raw,
 	struct inode *dir;
 	struct path path;
 	umode_t mode;
-	dev_t devt;
 	int ret;
 
 	dentry = kern_path_create(AT_FDCWD, pathname->name, &path, 0);
@@ -242,9 +230,8 @@ static int bpf_obj_do_pin(const struct filename *pathname, void *raw,
 		return PTR_ERR(dentry);
 
 	mode = S_IFREG | ((S_IRUSR | S_IWUSR) & ~current_umask());
-	devt = MKDEV(UNNAMED_MAJOR, type);
 
-	ret = security_path_mknod(&path, dentry, mode, devt);
+	ret = security_path_mknod(&path, dentry, mode, 0);
 	if (ret)
 		goto out;
 
@@ -254,9 +241,16 @@ static int bpf_obj_do_pin(const struct filename *pathname, void *raw,
 		goto out;
 	}
 
-	dentry->d_fsdata = raw;
-	ret = vfs_mknod(dir, dentry, mode, devt);
-	dentry->d_fsdata = NULL;
+	switch (type) {
+	case BPF_TYPE_PROG:
+		ret = vfs_mkobj(dentry, mode, bpf_mkprog, raw);
+		break;
+	case BPF_TYPE_MAP:
+		ret = vfs_mkobj(dentry, mode, bpf_mkmap, raw);
+		break;
+	default:
+		ret = -EPERM;
+	}
 out:
 	done_path_create(&path, dentry);
 	return ret;

commit 040ee69226f8a96b7943645d68f41d5d44b5ff7d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Dec 2 20:20:38 2017 -0500

    fix "netfilter: xt_bpf: Fix XT_BPF_MODE_FD_PINNED mode of 'xt_bpf_info_v1'"
    
    Descriptor table is a shared object; it's not a place where you can
    stick temporary references to files, especially when we don't need
    an opened file at all.
    
    Cc: stable@vger.kernel.org # v4.14
    Fixes: 98589a0998b8 ("netfilter: xt_bpf: Fix XT_BPF_MODE_FD_PINNED mode of 'xt_bpf_info_v1'")
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 01aaef1a77c5..5bb5e49ef4c3 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -368,7 +368,45 @@ int bpf_obj_get_user(const char __user *pathname, int flags)
 	putname(pname);
 	return ret;
 }
-EXPORT_SYMBOL_GPL(bpf_obj_get_user);
+
+static struct bpf_prog *__get_prog_inode(struct inode *inode, enum bpf_prog_type type)
+{
+	struct bpf_prog *prog;
+	int ret = inode_permission(inode, MAY_READ | MAY_WRITE);
+	if (ret)
+		return ERR_PTR(ret);
+
+	if (inode->i_op == &bpf_map_iops)
+		return ERR_PTR(-EINVAL);
+	if (inode->i_op != &bpf_prog_iops)
+		return ERR_PTR(-EACCES);
+
+	prog = inode->i_private;
+
+	ret = security_bpf_prog(prog);
+	if (ret < 0)
+		return ERR_PTR(ret);
+
+	if (!bpf_prog_get_ok(prog, &type, false))
+		return ERR_PTR(-EINVAL);
+
+	return bpf_prog_inc(prog);
+}
+
+struct bpf_prog *bpf_prog_get_type_path(const char *name, enum bpf_prog_type type)
+{
+	struct bpf_prog *prog;
+	struct path path;
+	int ret = kern_path(name, LOOKUP_FOLLOW, &path);
+	if (ret)
+		return ERR_PTR(ret);
+	prog = __get_prog_inode(d_backing_inode(path.dentry), type);
+	if (!IS_ERR(prog))
+		touch_atime(&path);
+	path_put(&path);
+	return prog;
+}
+EXPORT_SYMBOL(bpf_prog_get_type_path);
 
 static void bpf_evict_inode(struct inode *inode)
 {

commit 6e71b04a82248ccf13a94b85cbc674a9fefe53f5
Author: Chenbo Feng <fengc@google.com>
Date:   Wed Oct 18 13:00:22 2017 -0700

    bpf: Add file mode configuration into bpf maps
    
    Introduce the map read/write flags to the eBPF syscalls that returns the
    map fd. The flags is used to set up the file mode when construct a new
    file descriptor for bpf maps. To not break the backward capability, the
    f_flags is set to O_RDWR if the flag passed by syscall is 0. Otherwise
    it should be O_RDONLY or O_WRONLY. When the userspace want to modify or
    read the map content, it will check the file mode to see if it is
    allowed to make the change.
    
    Signed-off-by: Chenbo Feng <fengc@google.com>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index be1dde967208..01aaef1a77c5 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -295,7 +295,7 @@ int bpf_obj_pin_user(u32 ufd, const char __user *pathname)
 }
 
 static void *bpf_obj_do_get(const struct filename *pathname,
-			    enum bpf_type *type)
+			    enum bpf_type *type, int flags)
 {
 	struct inode *inode;
 	struct path path;
@@ -307,7 +307,7 @@ static void *bpf_obj_do_get(const struct filename *pathname,
 		return ERR_PTR(ret);
 
 	inode = d_backing_inode(path.dentry);
-	ret = inode_permission(inode, MAY_WRITE);
+	ret = inode_permission(inode, ACC_MODE(flags));
 	if (ret)
 		goto out;
 
@@ -326,18 +326,23 @@ static void *bpf_obj_do_get(const struct filename *pathname,
 	return ERR_PTR(ret);
 }
 
-int bpf_obj_get_user(const char __user *pathname)
+int bpf_obj_get_user(const char __user *pathname, int flags)
 {
 	enum bpf_type type = BPF_TYPE_UNSPEC;
 	struct filename *pname;
 	int ret = -ENOENT;
+	int f_flags;
 	void *raw;
 
+	f_flags = bpf_get_file_flag(flags);
+	if (f_flags < 0)
+		return f_flags;
+
 	pname = getname(pathname);
 	if (IS_ERR(pname))
 		return PTR_ERR(pname);
 
-	raw = bpf_obj_do_get(pname, &type);
+	raw = bpf_obj_do_get(pname, &type, f_flags);
 	if (IS_ERR(raw)) {
 		ret = PTR_ERR(raw);
 		goto out;
@@ -346,7 +351,7 @@ int bpf_obj_get_user(const char __user *pathname)
 	if (type == BPF_TYPE_PROG)
 		ret = bpf_prog_new_fd(raw);
 	else if (type == BPF_TYPE_MAP)
-		ret = bpf_map_new_fd(raw);
+		ret = bpf_map_new_fd(raw, f_flags);
 	else
 		goto out;
 

commit 98589a0998b8b13c4a8fa1ccb0e62751a019faa5
Author: Shmulik Ladkani <shmulik.ladkani@gmail.com>
Date:   Mon Oct 9 15:27:15 2017 +0300

    netfilter: xt_bpf: Fix XT_BPF_MODE_FD_PINNED mode of 'xt_bpf_info_v1'
    
    Commit 2c16d6033264 ("netfilter: xt_bpf: support ebpf") introduced
    support for attaching an eBPF object by an fd, with the
    'bpf_mt_check_v1' ABI expecting the '.fd' to be specified upon each
    IPT_SO_SET_REPLACE call.
    
    However this breaks subsequent iptables calls:
    
     # iptables -A INPUT -m bpf --object-pinned /sys/fs/bpf/xxx -j ACCEPT
     # iptables -A INPUT -s 5.6.7.8 -j ACCEPT
     iptables: Invalid argument. Run `dmesg' for more information.
    
    That's because iptables works by loading existing rules using
    IPT_SO_GET_ENTRIES to userspace, then issuing IPT_SO_SET_REPLACE with
    the replacement set.
    
    However, the loaded 'xt_bpf_info_v1' has an arbitrary '.fd' number
    (from the initial "iptables -m bpf" invocation) - so when 2nd invocation
    occurs, userspace passes a bogus fd number, which leads to
    'bpf_mt_check_v1' to fail.
    
    One suggested solution [1] was to hack iptables userspace, to perform a
    "entries fixup" immediatley after IPT_SO_GET_ENTRIES, by opening a new,
    process-local fd per every 'xt_bpf_info_v1' entry seen.
    
    However, in [2] both Pablo Neira Ayuso and Willem de Bruijn suggested to
    depricate the xt_bpf_info_v1 ABI dealing with pinned ebpf objects.
    
    This fix changes the XT_BPF_MODE_FD_PINNED behavior to ignore the given
    '.fd' and instead perform an in-kernel lookup for the bpf object given
    the provided '.path'.
    
    It also defines an alias for the XT_BPF_MODE_FD_PINNED mode, named
    XT_BPF_MODE_PATH_PINNED, to better reflect the fact that the user is
    expected to provide the path of the pinned object.
    
    Existing XT_BPF_MODE_FD_ELF behavior (non-pinned fd mode) is preserved.
    
    References: [1] https://marc.info/?l=netfilter-devel&m=150564724607440&w=2
                [2] https://marc.info/?l=netfilter-devel&m=150575727129880&w=2
    
    Reported-by: Rafael Buchbinder <rafi@rbk.ms>
    Signed-off-by: Shmulik Ladkani <shmulik.ladkani@gmail.com>
    Acked-by: Willem de Bruijn <willemb@google.com>
    Acked-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index e833ed914358..be1dde967208 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -363,6 +363,7 @@ int bpf_obj_get_user(const char __user *pathname)
 	putname(pname);
 	return ret;
 }
+EXPORT_SYMBOL_GPL(bpf_obj_get_user);
 
 static void bpf_evict_inode(struct inode *inode)
 {

commit 4cc7c1864bbd4cf80f6bdc8ba3217de5aa5f4688
Author: David Howells <dhowells@redhat.com>
Date:   Wed Jul 5 16:24:49 2017 +0100

    bpf: Implement show_options
    
    Implement the show_options superblock op for bpf as part of a bid to get
    rid of s_options and generic_show_options() to make it easier to implement
    a context-based mount where the mount options can be passed individually
    over a file descriptor.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    cc: Alexei Starovoitov <ast@kernel.org>
    cc: Daniel Borkmann <daniel@iogearbox.net>
    cc: netdev@vger.kernel.org
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 9bbd33497d3d..e833ed914358 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -377,10 +377,22 @@ static void bpf_evict_inode(struct inode *inode)
 		bpf_any_put(inode->i_private, type);
 }
 
+/*
+ * Display the mount options in /proc/mounts.
+ */
+static int bpf_show_options(struct seq_file *m, struct dentry *root)
+{
+	umode_t mode = d_inode(root)->i_mode & S_IALLUGO & ~S_ISVTX;
+
+	if (mode != S_IRWXUGO)
+		seq_printf(m, ",mode=%o", mode);
+	return 0;
+}
+
 static const struct super_operations bpf_super_ops = {
 	.statfs		= simple_statfs,
 	.drop_inode	= generic_delete_inode,
-	.show_options	= generic_show_options,
+	.show_options	= bpf_show_options,
 	.evict_inode	= bpf_evict_inode,
 };
 
@@ -434,8 +446,6 @@ static int bpf_fill_super(struct super_block *sb, void *data, int silent)
 	struct inode *inode;
 	int ret;
 
-	save_mount_options(sb, data);
-
 	ret = bpf_parse_options(data, &opts);
 	if (ret)
 		return ret;

commit cda37124f4e95ad5ccb11394a5802b0972668b32
Author: Eric Biggers <ebiggers@google.com>
Date:   Sat Mar 25 21:15:37 2017 -0700

    fs: constify tree_descr arrays passed to simple_fill_super()
    
    simple_fill_super() is passed an array of tree_descr structures which
    describe the files to create in the filesystem's root directory.  Since
    these arrays are never modified intentionally, they should be 'const' so
    that they are placed in .rodata and benefit from memory protection.
    This patch updates the function signature and all users, and also
    constifies tree_descr.name.
    
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index fddcae801724..9bbd33497d3d 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -429,7 +429,7 @@ static int bpf_parse_options(char *data, struct bpf_mount_opts *opts)
 
 static int bpf_fill_super(struct super_block *sb, void *data, int silent)
 {
-	static struct tree_descr bpf_rfiles[] = { { "" } };
+	static const struct tree_descr bpf_rfiles[] = { { "" } };
 	struct bpf_mount_opts opts;
 	struct inode *inode;
 	int ret;

commit a67edbf4fb6deadcfe57a04a134abed4a5ba3bb5
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Wed Jan 25 02:28:18 2017 +0100

    bpf: add initial bpf tracepoints
    
    This work adds a number of tracepoints to paths that are either
    considered slow-path or exception-like states, where monitoring or
    inspecting them would be desirable.
    
    For bpf(2) syscall, tracepoints have been placed for main commands
    when they succeed. In XDP case, tracepoint is for exceptions, that
    is, f.e. on abnormal BPF program exit such as unknown or XDP_ABORTED
    return code, or when error occurs during XDP_TX action and the packet
    could not be forwarded.
    
    Both have been split into separate event headers, and can be further
    extended. Worst case, if they unexpectedly should get into our way in
    future, they can also removed [1]. Of course, these tracepoints (like
    any other) can be analyzed by eBPF itself, etc. Example output:
    
      # ./perf record -a -e bpf:* sleep 10
      # ./perf script
      sock_example  6197 [005]   283.980322:      bpf:bpf_map_create: map type=ARRAY ufd=4 key=4 val=8 max=256 flags=0
      sock_example  6197 [005]   283.980721:       bpf:bpf_prog_load: prog=a5ea8fa30ea6849c type=SOCKET_FILTER ufd=5
      sock_example  6197 [005]   283.988423:   bpf:bpf_prog_get_type: prog=a5ea8fa30ea6849c type=SOCKET_FILTER
      sock_example  6197 [005]   283.988443: bpf:bpf_map_lookup_elem: map type=ARRAY ufd=4 key=[06 00 00 00] val=[00 00 00 00 00 00 00 00]
      [...]
      sock_example  6197 [005]   288.990868: bpf:bpf_map_lookup_elem: map type=ARRAY ufd=4 key=[01 00 00 00] val=[14 00 00 00 00 00 00 00]
           swapper     0 [005]   289.338243:    bpf:bpf_prog_put_rcu: prog=a5ea8fa30ea6849c type=SOCKET_FILTER
    
      [1] https://lwn.net/Articles/705270/
    
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 0b030c9126d3..fddcae801724 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -21,6 +21,7 @@
 #include <linux/parser.h>
 #include <linux/filter.h>
 #include <linux/bpf.h>
+#include <linux/bpf_trace.h>
 
 enum bpf_type {
 	BPF_TYPE_UNSPEC	= 0,
@@ -281,6 +282,13 @@ int bpf_obj_pin_user(u32 ufd, const char __user *pathname)
 	ret = bpf_obj_do_pin(pname, raw, type);
 	if (ret != 0)
 		bpf_any_put(raw, type);
+	if ((trace_bpf_obj_pin_prog_enabled() ||
+	     trace_bpf_obj_pin_map_enabled()) && !ret) {
+		if (type == BPF_TYPE_PROG)
+			trace_bpf_obj_pin_prog(raw, ufd, pname);
+		if (type == BPF_TYPE_MAP)
+			trace_bpf_obj_pin_map(raw, ufd, pname);
+	}
 out:
 	putname(pname);
 	return ret;
@@ -342,8 +350,15 @@ int bpf_obj_get_user(const char __user *pathname)
 	else
 		goto out;
 
-	if (ret < 0)
+	if (ret < 0) {
 		bpf_any_put(raw, type);
+	} else if (trace_bpf_obj_get_prog_enabled() ||
+		   trace_bpf_obj_get_map_enabled()) {
+		if (type == BPF_TYPE_PROG)
+			trace_bpf_obj_get_prog(raw, ret, pname);
+		if (type == BPF_TYPE_MAP)
+			trace_bpf_obj_get_map(raw, ret, pname);
+	}
 out:
 	putname(pname);
 	return ret;

commit a3af5f80010625a9ffbe8edd4bae615a7516b6bc
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Sat Nov 26 01:28:08 2016 +0100

    bpf: allow for mount options to specify permissions
    
    Since we recently converted the BPF filesystem over to use mount_nodev(),
    we now have the possibility to also hold mount options in sb's s_fs_info.
    This work implements mount options support for specifying permissions on
    the sb's inode, which will be used by tc when it manually needs to mount
    the fs.
    
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 2565809fbb34..0b030c9126d3 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -18,6 +18,7 @@
 #include <linux/namei.h>
 #include <linux/fs.h>
 #include <linux/kdev_t.h>
+#include <linux/parser.h>
 #include <linux/filter.h>
 #include <linux/bpf.h>
 
@@ -364,15 +365,66 @@ static void bpf_evict_inode(struct inode *inode)
 static const struct super_operations bpf_super_ops = {
 	.statfs		= simple_statfs,
 	.drop_inode	= generic_delete_inode,
+	.show_options	= generic_show_options,
 	.evict_inode	= bpf_evict_inode,
 };
 
+enum {
+	OPT_MODE,
+	OPT_ERR,
+};
+
+static const match_table_t bpf_mount_tokens = {
+	{ OPT_MODE, "mode=%o" },
+	{ OPT_ERR, NULL },
+};
+
+struct bpf_mount_opts {
+	umode_t mode;
+};
+
+static int bpf_parse_options(char *data, struct bpf_mount_opts *opts)
+{
+	substring_t args[MAX_OPT_ARGS];
+	int option, token;
+	char *ptr;
+
+	opts->mode = S_IRWXUGO;
+
+	while ((ptr = strsep(&data, ",")) != NULL) {
+		if (!*ptr)
+			continue;
+
+		token = match_token(ptr, bpf_mount_tokens, args);
+		switch (token) {
+		case OPT_MODE:
+			if (match_octal(&args[0], &option))
+				return -EINVAL;
+			opts->mode = option & S_IALLUGO;
+			break;
+		/* We might like to report bad mount options here, but
+		 * traditionally we've ignored all mount options, so we'd
+		 * better continue to ignore non-existing options for bpf.
+		 */
+		}
+	}
+
+	return 0;
+}
+
 static int bpf_fill_super(struct super_block *sb, void *data, int silent)
 {
 	static struct tree_descr bpf_rfiles[] = { { "" } };
+	struct bpf_mount_opts opts;
 	struct inode *inode;
 	int ret;
 
+	save_mount_options(sb, data);
+
+	ret = bpf_parse_options(data, &opts);
+	if (ret)
+		return ret;
+
 	ret = simple_fill_super(sb, BPF_FS_MAGIC, bpf_rfiles);
 	if (ret)
 		return ret;
@@ -382,7 +434,7 @@ static int bpf_fill_super(struct super_block *sb, void *data, int silent)
 	inode = sb->s_root->d_inode;
 	inode->i_op = &bpf_dir_iops;
 	inode->i_mode &= ~S_IALLUGO;
-	inode->i_mode |= S_ISVTX | S_IRWXUGO;
+	inode->i_mode |= S_ISVTX | opts.mode;
 
 	return 0;
 }

commit 0f98621bef5d2b7ad41f6595899660af344f5016
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Sat Oct 29 02:30:46 2016 +0200

    bpf, inode: add support for symlinks and fix mtime/ctime
    
    While commit bb35a6ef7da4 ("bpf, inode: allow for rename and link ops")
    added support for hard links that can be used for prog and map nodes,
    this work adds simple symlink support, which can be used f.e. for
    directories also when unpriviledged and works with cmdline tooling that
    understands S_IFLNK anyway. Since the switch in e27f4a942a0e ("bpf: Use
    mount_nodev not mount_ns to mount the bpf filesystem"), there can be
    various mount instances with mount_nodev() and thus hierarchy can be
    flattened to facilitate object sharing. Thus, we can keep bpf tooling
    also working by repointing paths.
    
    Most of the functionality can be used from vfs library operations. The
    symlink is stored in the inode itself, that is in i_link, which is
    sufficient in our case as opposed to storing it in the page cache.
    While at it, I noticed that bpf_mkdir() and bpf_mkobj() don't update
    the directories mtime and ctime, so add a common helper for it called
    bpf_dentry_finalize() that takes care of it for all cases now.
    
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 1ed8473ec537..2565809fbb34 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -87,6 +87,7 @@ static struct inode *bpf_get_inode(struct super_block *sb,
 	switch (mode & S_IFMT) {
 	case S_IFDIR:
 	case S_IFREG:
+	case S_IFLNK:
 		break;
 	default:
 		return ERR_PTR(-EINVAL);
@@ -119,6 +120,16 @@ static int bpf_inode_type(const struct inode *inode, enum bpf_type *type)
 	return 0;
 }
 
+static void bpf_dentry_finalize(struct dentry *dentry, struct inode *inode,
+				struct inode *dir)
+{
+	d_instantiate(dentry, inode);
+	dget(dentry);
+
+	dir->i_mtime = current_time(dir);
+	dir->i_ctime = dir->i_mtime;
+}
+
 static int bpf_mkdir(struct inode *dir, struct dentry *dentry, umode_t mode)
 {
 	struct inode *inode;
@@ -133,9 +144,7 @@ static int bpf_mkdir(struct inode *dir, struct dentry *dentry, umode_t mode)
 	inc_nlink(inode);
 	inc_nlink(dir);
 
-	d_instantiate(dentry, inode);
-	dget(dentry);
-
+	bpf_dentry_finalize(dentry, inode, dir);
 	return 0;
 }
 
@@ -151,9 +160,7 @@ static int bpf_mkobj_ops(struct inode *dir, struct dentry *dentry,
 	inode->i_op = iops;
 	inode->i_private = dentry->d_fsdata;
 
-	d_instantiate(dentry, inode);
-	dget(dentry);
-
+	bpf_dentry_finalize(dentry, inode, dir);
 	return 0;
 }
 
@@ -181,13 +188,37 @@ bpf_lookup(struct inode *dir, struct dentry *dentry, unsigned flags)
 {
 	if (strchr(dentry->d_name.name, '.'))
 		return ERR_PTR(-EPERM);
+
 	return simple_lookup(dir, dentry, flags);
 }
 
+static int bpf_symlink(struct inode *dir, struct dentry *dentry,
+		       const char *target)
+{
+	char *link = kstrdup(target, GFP_USER | __GFP_NOWARN);
+	struct inode *inode;
+
+	if (!link)
+		return -ENOMEM;
+
+	inode = bpf_get_inode(dir->i_sb, dir, S_IRWXUGO | S_IFLNK);
+	if (IS_ERR(inode)) {
+		kfree(link);
+		return PTR_ERR(inode);
+	}
+
+	inode->i_op = &simple_symlink_inode_operations;
+	inode->i_link = link;
+
+	bpf_dentry_finalize(dentry, inode, dir);
+	return 0;
+}
+
 static const struct inode_operations bpf_dir_iops = {
 	.lookup		= bpf_lookup,
 	.mknod		= bpf_mkobj,
 	.mkdir		= bpf_mkdir,
+	.symlink	= bpf_symlink,
 	.rmdir		= simple_rmdir,
 	.rename		= simple_rename,
 	.link		= simple_link,
@@ -324,6 +355,8 @@ static void bpf_evict_inode(struct inode *inode)
 	truncate_inode_pages_final(&inode->i_data);
 	clear_inode(inode);
 
+	if (S_ISLNK(inode->i_mode))
+		kfree(inode->i_link);
 	if (!bpf_inode_type(inode, &type))
 		bpf_any_put(inode->i_private, type);
 }

commit 078cd8279e659989b103359bb22373cc79445bde
Author: Deepa Dinamani <deepa.kernel@gmail.com>
Date:   Wed Sep 14 07:48:04 2016 -0700

    fs: Replace CURRENT_TIME with current_time() for inode timestamps
    
    CURRENT_TIME macro is not appropriate for filesystems as it
    doesn't use the right granularity for filesystem timestamps.
    Use current_time() instead.
    
    CURRENT_TIME is also not y2038 safe.
    
    This is also in preparation for the patch that transitions
    vfs timestamps to use 64 bit time and hence make them
    y2038 safe. As part of the effort current_time() will be
    extended to do range checks. Hence, it is necessary for all
    file system timestamps to use current_time(). Also,
    current_time() will be transitioned along with vfs to be
    y2038 safe.
    
    Note that whenever a single call to current_time() is used
    to change timestamps in different inodes, it is because they
    share the same time granularity.
    
    Signed-off-by: Deepa Dinamani <deepa.kernel@gmail.com>
    Reviewed-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Felipe Balbi <balbi@kernel.org>
    Acked-by: Steven Whitehouse <swhiteho@redhat.com>
    Acked-by: Ryusuke Konishi <konishi.ryusuke@lab.ntt.co.jp>
    Acked-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 5967b870a895..1ed8473ec537 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -97,7 +97,7 @@ static struct inode *bpf_get_inode(struct super_block *sb,
 		return ERR_PTR(-ENOSPC);
 
 	inode->i_ino = get_next_ino();
-	inode->i_atime = CURRENT_TIME;
+	inode->i_atime = current_time(inode);
 	inode->i_mtime = inode->i_atime;
 	inode->i_ctime = inode->i_atime;
 

commit a536a6e13ecd0d6eb0ffc36c5d56555896617282
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Mon Jul 11 12:51:01 2016 -0400

    bpf: make inode code explicitly non-modular
    
    The Kconfig currently controlling compilation of this code is:
    
    init/Kconfig:config BPF_SYSCALL
    init/Kconfig:   bool "Enable bpf() system call"
    
    ...meaning that it currently is not being built as a module by anyone.
    
    Lets remove the couple traces of modular infrastructure use, so that
    when reading the driver there is no doubt it is builtin-only.
    
    Note that MODULE_ALIAS is a no-op for non-modular code.
    
    We replace module.h with init.h since the file does use __init.
    
    Cc: Alexei Starovoitov <ast@kernel.org>
    Cc: netdev@vger.kernel.org
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Acked-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 318858edb1cd..5967b870a895 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -11,7 +11,7 @@
  * version 2 as published by the Free Software Foundation.
  */
 
-#include <linux/module.h>
+#include <linux/init.h>
 #include <linux/magic.h>
 #include <linux/major.h>
 #include <linux/mount.h>
@@ -367,8 +367,6 @@ static struct file_system_type bpf_fs_type = {
 	.kill_sb	= kill_litter_super,
 };
 
-MODULE_ALIAS_FS("bpf");
-
 static int __init bpf_init(void)
 {
 	int ret;

commit 612bacad78ba6d0a91166fc4487af114bac172a8
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Sun May 22 23:16:18 2016 +0200

    bpf, inode: disallow userns mounts
    
    Follow-up to commit e27f4a942a0e ("bpf: Use mount_nodev not mount_ns
    to mount the bpf filesystem"), which removes the FS_USERNS_MOUNT flag.
    
    The original idea was to have a per mountns instance instead of a
    single global fs instance, but that didn't work out and we had to
    switch to mount_nodev() model. The intent of that middle ground was
    that we avoid users who don't play nice to create endless instances
    of bpf fs which are difficult to control and discover from an admin
    point of view, but at the same time it would have allowed us to be
    more flexible with regard to namespaces.
    
    Therefore, since we now did the switch to mount_nodev() as a fix
    where individual instances are created, we also need to remove userns
    mount flag along with it to avoid running into mentioned situation.
    I don't expect any breakage at this early point in time with removing
    the flag and we can revisit this later should the requirement for
    this come up with future users. This and commit e27f4a942a0e have
    been split to facilitate tracking should any of them run into the
    unlikely case of causing a regression.
    
    Fixes: b2197755b263 ("bpf: add support for persistent maps/progs")
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 04be7021f848..318858edb1cd 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -365,7 +365,6 @@ static struct file_system_type bpf_fs_type = {
 	.name		= "bpf",
 	.mount		= bpf_mount,
 	.kill_sb	= kill_litter_super,
-	.fs_flags	= FS_USERNS_MOUNT,
 };
 
 MODULE_ALIAS_FS("bpf");

commit e27f4a942a0ee4b84567a3c6cfa84f273e55cbb7
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri May 20 17:22:48 2016 -0500

    bpf: Use mount_nodev not mount_ns to mount the bpf filesystem
    
    While reviewing the filesystems that set FS_USERNS_MOUNT I spotted the
    bpf filesystem.  Looking at the code I saw a broken usage of mount_ns
    with current->nsproxy->mnt_ns. As the code does not acquire a
    reference to the mount namespace it can not possibly be correct to
    store the mount namespace on the superblock as it does.
    
    Replace mount_ns with mount_nodev so that each mount of the bpf
    filesystem returns a distinct instance, and the code is not buggy.
    
    In discussion with Hannes Frederic Sowa it was reported that the use
    of mount_ns was an attempt to have one bpf instance per mount
    namespace, in an attempt to keep resources that pin resources from
    hiding.  That intent simply does not work, the vfs is not built to
    allow that kind of behavior.  Which means that the bpf filesystem
    really is buggy both semantically and in it's implemenation as it does
    not nor can it implement the original intent.
    
    This change is userspace visible, but my experience with similar
    filesystems leads me to believe nothing will break with a model of each
    mount of the bpf filesystem is distinct from all others.
    
    Fixes: b2197755b263 ("bpf: add support for persistent maps/progs")
    Cc: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Acked-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 71b75d9c81da..04be7021f848 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -357,7 +357,7 @@ static int bpf_fill_super(struct super_block *sb, void *data, int silent)
 static struct dentry *bpf_mount(struct file_system_type *type, int flags,
 				const char *dev_name, void *data)
 {
-	return mount_ns(type, flags, current->nsproxy->mnt_ns, bpf_fill_super);
+	return mount_nodev(type, flags, data, bpf_fill_super);
 }
 
 static struct file_system_type bpf_fs_type = {

commit 9e17632c0a146891c90a4353a160cfcf71f34b8f
Merge: 69370471d0b2 2c4cb04300fa
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 18 11:51:59 2016 -0700

    Merge branch 'work.misc' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull misc vfs cleanups from Al Viro:
     "Assorted cleanups and fixes all over the place"
    
    * 'work.misc' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      coredump: only charge written data against RLIMIT_CORE
      coredump: get rid of coredump_params->written
      ecryptfs_lookup(): try either only encrypted or plaintext name
      ecryptfs: avoid multiple aliases for directories
      bpf: reject invalid names right in ->lookup()
      __d_alloc(): treat NULL name as QSTR("/", 1)
      mtd: switch ubi_open_volume_path() to vfs_stat()
      mtd: switch open_mtd_by_chdev() to use of vfs_stat()

commit 92117d8443bc5afacc8d5ba82e541946310f106e
Author: Alexei Starovoitov <ast@fb.com>
Date:   Wed Apr 27 18:56:20 2016 -0700

    bpf: fix refcnt overflow
    
    On a system with >32Gbyte of phyiscal memory and infinite RLIMIT_MEMLOCK,
    the malicious application may overflow 32-bit bpf program refcnt.
    It's also possible to overflow map refcnt on 1Tb system.
    Impose 32k hard limit which means that the same bpf program or
    map cannot be shared by more than 32k processes.
    
    Fixes: 1be7f75d1668 ("bpf: enable non-root eBPF programs")
    Reported-by: Jann Horn <jannh@google.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index f2ece3c174a5..8f94ca1860cf 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -31,10 +31,10 @@ static void *bpf_any_get(void *raw, enum bpf_type type)
 {
 	switch (type) {
 	case BPF_TYPE_PROG:
-		atomic_inc(&((struct bpf_prog *)raw)->aux->refcnt);
+		raw = bpf_prog_inc(raw);
 		break;
 	case BPF_TYPE_MAP:
-		bpf_map_inc(raw, true);
+		raw = bpf_map_inc(raw, true);
 		break;
 	default:
 		WARN_ON_ONCE(1);
@@ -297,7 +297,8 @@ static void *bpf_obj_do_get(const struct filename *pathname,
 		goto out;
 
 	raw = bpf_any_get(inode->i_private, *type);
-	touch_atime(&path);
+	if (!IS_ERR(raw))
+		touch_atime(&path);
 
 	path_put(&path);
 	return raw;

commit 0c93b7d85d40b690f04786ea0f18798b73182e4f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Mar 25 12:06:51 2016 -0400

    bpf: reject invalid names right in ->lookup()
    
    ... and other methods won't see them at all
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index f2ece3c174a5..35d21c189bb0 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -119,18 +119,10 @@ static int bpf_inode_type(const struct inode *inode, enum bpf_type *type)
 	return 0;
 }
 
-static bool bpf_dname_reserved(const struct dentry *dentry)
-{
-	return strchr(dentry->d_name.name, '.');
-}
-
 static int bpf_mkdir(struct inode *dir, struct dentry *dentry, umode_t mode)
 {
 	struct inode *inode;
 
-	if (bpf_dname_reserved(dentry))
-		return -EPERM;
-
 	inode = bpf_get_inode(dir->i_sb, dir, mode | S_IFDIR);
 	if (IS_ERR(inode))
 		return PTR_ERR(inode);
@@ -152,9 +144,6 @@ static int bpf_mkobj_ops(struct inode *dir, struct dentry *dentry,
 {
 	struct inode *inode;
 
-	if (bpf_dname_reserved(dentry))
-		return -EPERM;
-
 	inode = bpf_get_inode(dir->i_sb, dir, mode | S_IFREG);
 	if (IS_ERR(inode))
 		return PTR_ERR(inode);
@@ -187,31 +176,21 @@ static int bpf_mkobj(struct inode *dir, struct dentry *dentry, umode_t mode,
 	}
 }
 
-static int bpf_link(struct dentry *old_dentry, struct inode *dir,
-		    struct dentry *new_dentry)
+static struct dentry *
+bpf_lookup(struct inode *dir, struct dentry *dentry, unsigned flags)
 {
-	if (bpf_dname_reserved(new_dentry))
-		return -EPERM;
-
-	return simple_link(old_dentry, dir, new_dentry);
-}
-
-static int bpf_rename(struct inode *old_dir, struct dentry *old_dentry,
-		      struct inode *new_dir, struct dentry *new_dentry)
-{
-	if (bpf_dname_reserved(new_dentry))
-		return -EPERM;
-
-	return simple_rename(old_dir, old_dentry, new_dir, new_dentry);
+	if (strchr(dentry->d_name.name, '.'))
+		return ERR_PTR(-EPERM);
+	return simple_lookup(dir, dentry, flags);
 }
 
 static const struct inode_operations bpf_dir_iops = {
-	.lookup		= simple_lookup,
+	.lookup		= bpf_lookup,
 	.mknod		= bpf_mkobj,
 	.mkdir		= bpf_mkdir,
 	.rmdir		= simple_rmdir,
-	.rename		= bpf_rename,
-	.link		= bpf_link,
+	.rename		= simple_rename,
+	.link		= simple_link,
 	.unlink		= simple_unlink,
 };
 

commit bb35a6ef7da492e7df1fe8772716ff88c172b4cc
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Thu Dec 10 22:33:49 2015 +0100

    bpf, inode: allow for rename and link ops
    
    Add support for renaming and hard links to the fs. Most of this can be
    implemented by using simple library operations under the same constraints
    that we don't use a reserved name like elsewhere. Linking can be useful
    to share/manage things like maps across subsystem users. It works within
    the file system boundary, but is not allowed for directories.
    
    Symbolic links are explicitly not implemented here, as it can be better
    done already by doing bind mounts inside bpf fs to set up shared directories
    f.e. useful when using volumes in docker containers that map a private
    working directory into /sys/fs/bpf/ which contains itself a bind mounted
    path from the host's /sys/fs/bpf/ mount that is shared among multiple
    containers. For single maps instead of whole directory, hard links can
    be easily used to do the same.
    
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index 5a8a797d50b7..f2ece3c174a5 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -187,11 +187,31 @@ static int bpf_mkobj(struct inode *dir, struct dentry *dentry, umode_t mode,
 	}
 }
 
+static int bpf_link(struct dentry *old_dentry, struct inode *dir,
+		    struct dentry *new_dentry)
+{
+	if (bpf_dname_reserved(new_dentry))
+		return -EPERM;
+
+	return simple_link(old_dentry, dir, new_dentry);
+}
+
+static int bpf_rename(struct inode *old_dir, struct dentry *old_dentry,
+		      struct inode *new_dir, struct dentry *new_dentry)
+{
+	if (bpf_dname_reserved(new_dentry))
+		return -EPERM;
+
+	return simple_rename(old_dir, old_dentry, new_dir, new_dentry);
+}
+
 static const struct inode_operations bpf_dir_iops = {
 	.lookup		= simple_lookup,
 	.mknod		= bpf_mkobj,
 	.mkdir		= bpf_mkdir,
 	.rmdir		= simple_rmdir,
+	.rename		= bpf_rename,
+	.link		= bpf_link,
 	.unlink		= simple_unlink,
 };
 

commit c9da161c6517ba12154059d3b965c2cbaf16f90f
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Tue Nov 24 21:28:15 2015 +0100

    bpf: fix clearing on persistent program array maps
    
    Currently, when having map file descriptors pointing to program arrays,
    there's still the issue that we unconditionally flush program array
    contents via bpf_fd_array_map_clear() in bpf_map_release(). This happens
    when such a file descriptor is released and is independent of the map's
    refcount.
    
    Having this flush independent of the refcount is for a reason: there
    can be arbitrary complex dependency chains among tail calls, also circular
    ones (direct or indirect, nesting limit determined during runtime), and
    we need to make sure that the map drops all references to eBPF programs
    it holds, so that the map's refcount can eventually drop to zero and
    initiate its freeing. Btw, a walk of the whole dependency graph would
    not be possible for various reasons, one being complexity and another
    one inconsistency, i.e. new programs can be added to parts of the graph
    at any time, so there's no guaranteed consistent state for the time of
    such a walk.
    
    Now, the program array pinning itself works, but the issue is that each
    derived file descriptor on close would nevertheless call unconditionally
    into bpf_fd_array_map_clear(). Instead, keep track of users and postpone
    this flush until the last reference to a user is dropped. As this only
    concerns a subset of references (f.e. a prog array could hold a program
    that itself has reference on the prog array holding it, etc), we need to
    track them separately.
    
    Short analysis on the refcounting: on map creation time usercnt will be
    one, so there's no change in behaviour for bpf_map_release(), if unpinned.
    If we already fail in map_create(), we are immediately freed, and no
    file descriptor has been made public yet. In bpf_obj_pin_user(), we need
    to probe for a possible map in bpf_fd_probe_obj() already with a usercnt
    reference, so before we drop the reference on the fd with fdput().
    Therefore, if actual pinning fails, we need to drop that reference again
    in bpf_any_put(), otherwise we keep holding it. When last reference
    drops on the inode, the bpf_any_put() in bpf_evict_inode() will take
    care of dropping the usercnt again. In the bpf_obj_get_user() case, the
    bpf_any_get() will grab a reference on the usercnt, still at a time when
    we have the reference on the path. Should we later on fail to grab a new
    file descriptor, bpf_any_put() will drop it, otherwise we hold it until
    bpf_map_release() time.
    
    Joint work with Alexei.
    
    Fixes: b2197755b263 ("bpf: add support for persistent maps/progs")
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
index be6d726e31c9..5a8a797d50b7 100644
--- a/kernel/bpf/inode.c
+++ b/kernel/bpf/inode.c
@@ -34,7 +34,7 @@ static void *bpf_any_get(void *raw, enum bpf_type type)
 		atomic_inc(&((struct bpf_prog *)raw)->aux->refcnt);
 		break;
 	case BPF_TYPE_MAP:
-		atomic_inc(&((struct bpf_map *)raw)->refcnt);
+		bpf_map_inc(raw, true);
 		break;
 	default:
 		WARN_ON_ONCE(1);
@@ -51,7 +51,7 @@ static void bpf_any_put(void *raw, enum bpf_type type)
 		bpf_prog_put(raw);
 		break;
 	case BPF_TYPE_MAP:
-		bpf_map_put(raw);
+		bpf_map_put_with_uref(raw);
 		break;
 	default:
 		WARN_ON_ONCE(1);
@@ -64,7 +64,7 @@ static void *bpf_fd_probe_obj(u32 ufd, enum bpf_type *type)
 	void *raw;
 
 	*type = BPF_TYPE_MAP;
-	raw = bpf_map_get(ufd);
+	raw = bpf_map_get_with_uref(ufd);
 	if (IS_ERR(raw)) {
 		*type = BPF_TYPE_PROG;
 		raw = bpf_prog_get(ufd);

commit b2197755b2633e164a439682fb05a9b5ea48f706
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Thu Oct 29 14:58:09 2015 +0100

    bpf: add support for persistent maps/progs
    
    This work adds support for "persistent" eBPF maps/programs. The term
    "persistent" is to be understood that maps/programs have a facility
    that lets them survive process termination. This is desired by various
    eBPF subsystem users.
    
    Just to name one example: tc classifier/action. Whenever tc parses
    the ELF object, extracts and loads maps/progs into the kernel, these
    file descriptors will be out of reach after the tc instance exits.
    So a subsequent tc invocation won't be able to access/relocate on this
    resource, and therefore maps cannot easily be shared, f.e. between the
    ingress and egress networking data path.
    
    The current workaround is that Unix domain sockets (UDS) need to be
    instrumented in order to pass the created eBPF map/program file
    descriptors to a third party management daemon through UDS' socket
    passing facility. This makes it a bit complicated to deploy shared
    eBPF maps or programs (programs f.e. for tail calls) among various
    processes.
    
    We've been brainstorming on how we could tackle this issue and various
    approches have been tried out so far, which can be read up further in
    the below reference.
    
    The architecture we eventually ended up with is a minimal file system
    that can hold map/prog objects. The file system is a per mount namespace
    singleton, and the default mount point is /sys/fs/bpf/. Any subsequent
    mounts within a given namespace will point to the same instance. The
    file system allows for creating a user-defined directory structure.
    The objects for maps/progs are created/fetched through bpf(2) with
    two new commands (BPF_OBJ_PIN/BPF_OBJ_GET). I.e. a bpf file descriptor
    along with a pathname is being passed to bpf(2) that in turn creates
    (we call it eBPF object pinning) the file system nodes. Only the pathname
    is being passed to bpf(2) for getting a new BPF file descriptor to an
    existing node. The user can use that to access maps and progs later on,
    through bpf(2). Removal of file system nodes is being managed through
    normal VFS functions such as unlink(2), etc. The file system code is
    kept to a very minimum and can be further extended later on.
    
    The next step I'm working on is to add dump eBPF map/prog commands
    to bpf(2), so that a specification from a given file descriptor can
    be retrieved. This can be used by things like CRIU but also applications
    can inspect the meta data after calling BPF_OBJ_GET.
    
    Big thanks also to Alexei and Hannes who significantly contributed
    in the design discussion that eventually let us end up with this
    architecture here.
    
    Reference: https://lkml.org/lkml/2015/10/15/925
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/bpf/inode.c b/kernel/bpf/inode.c
new file mode 100644
index 000000000000..be6d726e31c9
--- /dev/null
+++ b/kernel/bpf/inode.c
@@ -0,0 +1,387 @@
+/*
+ * Minimal file system backend for holding eBPF maps and programs,
+ * used by bpf(2) object pinning.
+ *
+ * Authors:
+ *
+ *	Daniel Borkmann <daniel@iogearbox.net>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * version 2 as published by the Free Software Foundation.
+ */
+
+#include <linux/module.h>
+#include <linux/magic.h>
+#include <linux/major.h>
+#include <linux/mount.h>
+#include <linux/namei.h>
+#include <linux/fs.h>
+#include <linux/kdev_t.h>
+#include <linux/filter.h>
+#include <linux/bpf.h>
+
+enum bpf_type {
+	BPF_TYPE_UNSPEC	= 0,
+	BPF_TYPE_PROG,
+	BPF_TYPE_MAP,
+};
+
+static void *bpf_any_get(void *raw, enum bpf_type type)
+{
+	switch (type) {
+	case BPF_TYPE_PROG:
+		atomic_inc(&((struct bpf_prog *)raw)->aux->refcnt);
+		break;
+	case BPF_TYPE_MAP:
+		atomic_inc(&((struct bpf_map *)raw)->refcnt);
+		break;
+	default:
+		WARN_ON_ONCE(1);
+		break;
+	}
+
+	return raw;
+}
+
+static void bpf_any_put(void *raw, enum bpf_type type)
+{
+	switch (type) {
+	case BPF_TYPE_PROG:
+		bpf_prog_put(raw);
+		break;
+	case BPF_TYPE_MAP:
+		bpf_map_put(raw);
+		break;
+	default:
+		WARN_ON_ONCE(1);
+		break;
+	}
+}
+
+static void *bpf_fd_probe_obj(u32 ufd, enum bpf_type *type)
+{
+	void *raw;
+
+	*type = BPF_TYPE_MAP;
+	raw = bpf_map_get(ufd);
+	if (IS_ERR(raw)) {
+		*type = BPF_TYPE_PROG;
+		raw = bpf_prog_get(ufd);
+	}
+
+	return raw;
+}
+
+static const struct inode_operations bpf_dir_iops;
+
+static const struct inode_operations bpf_prog_iops = { };
+static const struct inode_operations bpf_map_iops  = { };
+
+static struct inode *bpf_get_inode(struct super_block *sb,
+				   const struct inode *dir,
+				   umode_t mode)
+{
+	struct inode *inode;
+
+	switch (mode & S_IFMT) {
+	case S_IFDIR:
+	case S_IFREG:
+		break;
+	default:
+		return ERR_PTR(-EINVAL);
+	}
+
+	inode = new_inode(sb);
+	if (!inode)
+		return ERR_PTR(-ENOSPC);
+
+	inode->i_ino = get_next_ino();
+	inode->i_atime = CURRENT_TIME;
+	inode->i_mtime = inode->i_atime;
+	inode->i_ctime = inode->i_atime;
+
+	inode_init_owner(inode, dir, mode);
+
+	return inode;
+}
+
+static int bpf_inode_type(const struct inode *inode, enum bpf_type *type)
+{
+	*type = BPF_TYPE_UNSPEC;
+	if (inode->i_op == &bpf_prog_iops)
+		*type = BPF_TYPE_PROG;
+	else if (inode->i_op == &bpf_map_iops)
+		*type = BPF_TYPE_MAP;
+	else
+		return -EACCES;
+
+	return 0;
+}
+
+static bool bpf_dname_reserved(const struct dentry *dentry)
+{
+	return strchr(dentry->d_name.name, '.');
+}
+
+static int bpf_mkdir(struct inode *dir, struct dentry *dentry, umode_t mode)
+{
+	struct inode *inode;
+
+	if (bpf_dname_reserved(dentry))
+		return -EPERM;
+
+	inode = bpf_get_inode(dir->i_sb, dir, mode | S_IFDIR);
+	if (IS_ERR(inode))
+		return PTR_ERR(inode);
+
+	inode->i_op = &bpf_dir_iops;
+	inode->i_fop = &simple_dir_operations;
+
+	inc_nlink(inode);
+	inc_nlink(dir);
+
+	d_instantiate(dentry, inode);
+	dget(dentry);
+
+	return 0;
+}
+
+static int bpf_mkobj_ops(struct inode *dir, struct dentry *dentry,
+			 umode_t mode, const struct inode_operations *iops)
+{
+	struct inode *inode;
+
+	if (bpf_dname_reserved(dentry))
+		return -EPERM;
+
+	inode = bpf_get_inode(dir->i_sb, dir, mode | S_IFREG);
+	if (IS_ERR(inode))
+		return PTR_ERR(inode);
+
+	inode->i_op = iops;
+	inode->i_private = dentry->d_fsdata;
+
+	d_instantiate(dentry, inode);
+	dget(dentry);
+
+	return 0;
+}
+
+static int bpf_mkobj(struct inode *dir, struct dentry *dentry, umode_t mode,
+		     dev_t devt)
+{
+	enum bpf_type type = MINOR(devt);
+
+	if (MAJOR(devt) != UNNAMED_MAJOR || !S_ISREG(mode) ||
+	    dentry->d_fsdata == NULL)
+		return -EPERM;
+
+	switch (type) {
+	case BPF_TYPE_PROG:
+		return bpf_mkobj_ops(dir, dentry, mode, &bpf_prog_iops);
+	case BPF_TYPE_MAP:
+		return bpf_mkobj_ops(dir, dentry, mode, &bpf_map_iops);
+	default:
+		return -EPERM;
+	}
+}
+
+static const struct inode_operations bpf_dir_iops = {
+	.lookup		= simple_lookup,
+	.mknod		= bpf_mkobj,
+	.mkdir		= bpf_mkdir,
+	.rmdir		= simple_rmdir,
+	.unlink		= simple_unlink,
+};
+
+static int bpf_obj_do_pin(const struct filename *pathname, void *raw,
+			  enum bpf_type type)
+{
+	struct dentry *dentry;
+	struct inode *dir;
+	struct path path;
+	umode_t mode;
+	dev_t devt;
+	int ret;
+
+	dentry = kern_path_create(AT_FDCWD, pathname->name, &path, 0);
+	if (IS_ERR(dentry))
+		return PTR_ERR(dentry);
+
+	mode = S_IFREG | ((S_IRUSR | S_IWUSR) & ~current_umask());
+	devt = MKDEV(UNNAMED_MAJOR, type);
+
+	ret = security_path_mknod(&path, dentry, mode, devt);
+	if (ret)
+		goto out;
+
+	dir = d_inode(path.dentry);
+	if (dir->i_op != &bpf_dir_iops) {
+		ret = -EPERM;
+		goto out;
+	}
+
+	dentry->d_fsdata = raw;
+	ret = vfs_mknod(dir, dentry, mode, devt);
+	dentry->d_fsdata = NULL;
+out:
+	done_path_create(&path, dentry);
+	return ret;
+}
+
+int bpf_obj_pin_user(u32 ufd, const char __user *pathname)
+{
+	struct filename *pname;
+	enum bpf_type type;
+	void *raw;
+	int ret;
+
+	pname = getname(pathname);
+	if (IS_ERR(pname))
+		return PTR_ERR(pname);
+
+	raw = bpf_fd_probe_obj(ufd, &type);
+	if (IS_ERR(raw)) {
+		ret = PTR_ERR(raw);
+		goto out;
+	}
+
+	ret = bpf_obj_do_pin(pname, raw, type);
+	if (ret != 0)
+		bpf_any_put(raw, type);
+out:
+	putname(pname);
+	return ret;
+}
+
+static void *bpf_obj_do_get(const struct filename *pathname,
+			    enum bpf_type *type)
+{
+	struct inode *inode;
+	struct path path;
+	void *raw;
+	int ret;
+
+	ret = kern_path(pathname->name, LOOKUP_FOLLOW, &path);
+	if (ret)
+		return ERR_PTR(ret);
+
+	inode = d_backing_inode(path.dentry);
+	ret = inode_permission(inode, MAY_WRITE);
+	if (ret)
+		goto out;
+
+	ret = bpf_inode_type(inode, type);
+	if (ret)
+		goto out;
+
+	raw = bpf_any_get(inode->i_private, *type);
+	touch_atime(&path);
+
+	path_put(&path);
+	return raw;
+out:
+	path_put(&path);
+	return ERR_PTR(ret);
+}
+
+int bpf_obj_get_user(const char __user *pathname)
+{
+	enum bpf_type type = BPF_TYPE_UNSPEC;
+	struct filename *pname;
+	int ret = -ENOENT;
+	void *raw;
+
+	pname = getname(pathname);
+	if (IS_ERR(pname))
+		return PTR_ERR(pname);
+
+	raw = bpf_obj_do_get(pname, &type);
+	if (IS_ERR(raw)) {
+		ret = PTR_ERR(raw);
+		goto out;
+	}
+
+	if (type == BPF_TYPE_PROG)
+		ret = bpf_prog_new_fd(raw);
+	else if (type == BPF_TYPE_MAP)
+		ret = bpf_map_new_fd(raw);
+	else
+		goto out;
+
+	if (ret < 0)
+		bpf_any_put(raw, type);
+out:
+	putname(pname);
+	return ret;
+}
+
+static void bpf_evict_inode(struct inode *inode)
+{
+	enum bpf_type type;
+
+	truncate_inode_pages_final(&inode->i_data);
+	clear_inode(inode);
+
+	if (!bpf_inode_type(inode, &type))
+		bpf_any_put(inode->i_private, type);
+}
+
+static const struct super_operations bpf_super_ops = {
+	.statfs		= simple_statfs,
+	.drop_inode	= generic_delete_inode,
+	.evict_inode	= bpf_evict_inode,
+};
+
+static int bpf_fill_super(struct super_block *sb, void *data, int silent)
+{
+	static struct tree_descr bpf_rfiles[] = { { "" } };
+	struct inode *inode;
+	int ret;
+
+	ret = simple_fill_super(sb, BPF_FS_MAGIC, bpf_rfiles);
+	if (ret)
+		return ret;
+
+	sb->s_op = &bpf_super_ops;
+
+	inode = sb->s_root->d_inode;
+	inode->i_op = &bpf_dir_iops;
+	inode->i_mode &= ~S_IALLUGO;
+	inode->i_mode |= S_ISVTX | S_IRWXUGO;
+
+	return 0;
+}
+
+static struct dentry *bpf_mount(struct file_system_type *type, int flags,
+				const char *dev_name, void *data)
+{
+	return mount_ns(type, flags, current->nsproxy->mnt_ns, bpf_fill_super);
+}
+
+static struct file_system_type bpf_fs_type = {
+	.owner		= THIS_MODULE,
+	.name		= "bpf",
+	.mount		= bpf_mount,
+	.kill_sb	= kill_litter_super,
+	.fs_flags	= FS_USERNS_MOUNT,
+};
+
+MODULE_ALIAS_FS("bpf");
+
+static int __init bpf_init(void)
+{
+	int ret;
+
+	ret = sysfs_create_mount_point(fs_kobj, "bpf");
+	if (ret)
+		return ret;
+
+	ret = register_filesystem(&bpf_fs_type);
+	if (ret)
+		sysfs_remove_mount_point(fs_kobj, "bpf");
+
+	return ret;
+}
+fs_initcall(bpf_init);
