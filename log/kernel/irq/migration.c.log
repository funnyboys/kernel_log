commit d340ebd696f921d3ad01b8c0c29dd38f2ad2bf3e
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Jun 6 14:46:59 2018 +0200

    genirq/migration: Avoid out of line call if pending is not set
    
    The upcoming fix for the -EBUSY return from affinity settings requires to
    use the irq_move_irq() functionality even on irq remapped interrupts. To
    avoid the out of line call, move the check for the pending bit into an
    inline helper.
    
    Preparatory change for the real fix. No functional change.
    
    Fixes: dccfe3147b42 ("x86/vector: Simplify vector move cleanup")
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Joerg Roedel <jroedel@suse.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Song Liu <liu.song.a23@gmail.com>
    Cc: Dmitry Safonov <0x7f454c46@gmail.com>
    Cc: stable@vger.kernel.org
    Cc: Mike Travis <mike.travis@hpe.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Tariq Toukan <tariqt@mellanox.com>
    Cc: Dou Liyang <douly.fnst@cn.fujitsu.com>
    Link: https://lkml.kernel.org/r/20180604162224.471925894@linutronix.de

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 8b8cecd18cce..def48589ea48 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -91,7 +91,7 @@ void irq_move_masked_irq(struct irq_data *idata)
 	cpumask_clear(desc->pending_mask);
 }
 
-void irq_move_irq(struct irq_data *idata)
+void __irq_move_irq(struct irq_data *idata)
 {
 	bool masked;
 
@@ -102,9 +102,6 @@ void irq_move_irq(struct irq_data *idata)
 	 */
 	idata = irq_desc_get_irq_data(irq_data_to_desc(idata));
 
-	if (likely(!irqd_is_setaffinity_pending(idata)))
-		return;
-
 	if (unlikely(irqd_irq_disabled(idata)))
 		return;
 

commit a33a5d2d16cb84bea8d5f5510f3a41aa48b5c467
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jun 4 17:33:54 2018 +0200

    genirq/generic_pending: Do not lose pending affinity update
    
    The generic pending interrupt mechanism moves interrupts from the interrupt
    handler on the original target CPU to the new destination CPU. This is
    required for x86 and ia64 due to the way the interrupt delivery and
    acknowledge works if the interrupts are not remapped.
    
    However that update can fail for various reasons. Some of them are valid
    reasons to discard the pending update, but the case, when the previous move
    has not been fully cleaned up is not a legit reason to fail.
    
    Check the return value of irq_do_set_affinity() for -EBUSY, which indicates
    a pending cleanup, and rearm the pending move in the irq dexcriptor so it's
    tried again when the next interrupt arrives.
    
    Fixes: 996c591227d9 ("x86/irq: Plug vector cleanup race")
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Song Liu <songliubraving@fb.com>
    Cc: Joerg Roedel <jroedel@suse.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Song Liu <liu.song.a23@gmail.com>
    Cc: Dmitry Safonov <0x7f454c46@gmail.com>
    Cc: stable@vger.kernel.org
    Cc: Mike Travis <mike.travis@hpe.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Tariq Toukan <tariqt@mellanox.com>
    Link: https://lkml.kernel.org/r/20180604162224.386544292@linutronix.de

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 86ae0eb80b53..8b8cecd18cce 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -38,17 +38,18 @@ bool irq_fixup_move_pending(struct irq_desc *desc, bool force_clear)
 void irq_move_masked_irq(struct irq_data *idata)
 {
 	struct irq_desc *desc = irq_data_to_desc(idata);
-	struct irq_chip *chip = desc->irq_data.chip;
+	struct irq_data *data = &desc->irq_data;
+	struct irq_chip *chip = data->chip;
 
-	if (likely(!irqd_is_setaffinity_pending(&desc->irq_data)))
+	if (likely(!irqd_is_setaffinity_pending(data)))
 		return;
 
-	irqd_clr_move_pending(&desc->irq_data);
+	irqd_clr_move_pending(data);
 
 	/*
 	 * Paranoia: cpu-local interrupts shouldn't be calling in here anyway.
 	 */
-	if (irqd_is_per_cpu(&desc->irq_data)) {
+	if (irqd_is_per_cpu(data)) {
 		WARN_ON(1);
 		return;
 	}
@@ -73,9 +74,20 @@ void irq_move_masked_irq(struct irq_data *idata)
 	 * For correct operation this depends on the caller
 	 * masking the irqs.
 	 */
-	if (cpumask_any_and(desc->pending_mask, cpu_online_mask) < nr_cpu_ids)
-		irq_do_set_affinity(&desc->irq_data, desc->pending_mask, false);
-
+	if (cpumask_any_and(desc->pending_mask, cpu_online_mask) < nr_cpu_ids) {
+		int ret;
+
+		ret = irq_do_set_affinity(data, desc->pending_mask, false);
+		/*
+		 * If the there is a cleanup pending in the underlying
+		 * vector management, reschedule the move for the next
+		 * interrupt. Leave desc->pending_mask intact.
+		 */
+		if (ret == -EBUSY) {
+			irqd_set_move_pending(data);
+			return;
+		}
+	}
 	cpumask_clear(desc->pending_mask);
 }
 

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 6ca054a3f91d..86ae0eb80b53 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 
 #include <linux/irq.h>
 #include <linux/interrupt.h>

commit cdd16365b0bd7c0cd19e2cc768b6bdc8021f32c3
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 20 01:37:19 2017 +0200

    genirq: Provide irq_fixup_move_pending()
    
    If an CPU goes offline, the interrupts are migrated away, but a eventually
    pending interrupt move, which has not yet been made effective is kept
    pending even if the outgoing CPU is the sole target of the pending affinity
    mask. What's worse is, that the pending affinity mask is discarded even if
    it would contain a valid subset of the online CPUs.
    
    Implement a helper function which allows to avoid these issues.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Keith Busch <keith.busch@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Link: http://lkml.kernel.org/r/20170619235444.691345468@linutronix.de

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 37ddb7bda651..6ca054a3f91d 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -4,6 +4,36 @@
 
 #include "internals.h"
 
+/**
+ * irq_fixup_move_pending - Cleanup irq move pending from a dying CPU
+ * @desc:		Interrupt descpriptor to clean up
+ * @force_clear:	If set clear the move pending bit unconditionally.
+ *			If not set, clear it only when the dying CPU is the
+ *			last one in the pending mask.
+ *
+ * Returns true if the pending bit was set and the pending mask contains an
+ * online CPU other than the dying CPU.
+ */
+bool irq_fixup_move_pending(struct irq_desc *desc, bool force_clear)
+{
+	struct irq_data *data = irq_desc_get_irq_data(desc);
+
+	if (!irqd_is_setaffinity_pending(data))
+		return false;
+
+	/*
+	 * The outgoing CPU might be the last online target in a pending
+	 * interrupt move. If that's the case clear the pending move bit.
+	 */
+	if (cpumask_any_and(desc->pending_mask, cpu_online_mask) >= nr_cpu_ids) {
+		irqd_clr_move_pending(data);
+		return false;
+	}
+	if (force_clear)
+		irqd_clr_move_pending(data);
+	return true;
+}
+
 void irq_move_masked_irq(struct irq_data *idata)
 {
 	struct irq_desc *desc = irq_data_to_desc(idata);

commit a614a610ac9b28f195d790d25be72d26f345c53a
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jun 20 12:05:40 2015 +0200

    genirq: Remove bogus restriction in irq_move_mask_irq()
    
    If an interrupt is marked with the no balancing flag, we still allow
    setting the affinity for such an interrupt from the kernel itself, but
    for interrupts which move the affinity from interrupt context via
    irq_move_mask_irq() this runs into a check for the no balancing flag,
    which in turn ends up with an endless storm of stack dumps because the
    move pending flag is not reset.
    
    Allow the move for interrupts which have the no balancing flag set and
    clear the move pending bit before checking for interrupts with the per
    cpu flag set.
    
    Reported-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Jiang Liu <jiang.liu@linux.intel.com>
    Link: http://lkml.kernel.org/r/alpine.DEB.2.11.1506201002570.4107@nanos
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index dd203e276b07..37ddb7bda651 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -12,16 +12,16 @@ void irq_move_masked_irq(struct irq_data *idata)
 	if (likely(!irqd_is_setaffinity_pending(&desc->irq_data)))
 		return;
 
+	irqd_clr_move_pending(&desc->irq_data);
+
 	/*
 	 * Paranoia: cpu-local interrupts shouldn't be calling in here anyway.
 	 */
-	if (!irqd_can_balance(&desc->irq_data)) {
+	if (irqd_is_per_cpu(&desc->irq_data)) {
 		WARN_ON(1);
 		return;
 	}
 
-	irqd_clr_move_pending(&desc->irq_data);
-
 	if (unlikely(cpumask_empty(desc->pending_mask)))
 		return;
 

commit 77ed42f18edd486e9994ccd1f174076309a6343f
Author: Jiang Liu <jiang.liu@linux.intel.com>
Date:   Mon Jun 1 16:05:11 2015 +0800

    genirq: Prevent crash in irq_move_irq()
    
    The functions irq_move_irq() and irq_move_masked_irq() expect that the
    caller passes the top-level irq_data to them when hierarchical
    irqdomains are enabled. But that's not true when called from
    apic_ack_edge(), which results in a null pointer dereference by
    idata->chip->irq_mask(idata).
    
    Instead of fixing callers to passing top-level irq_data, we rather
    change irq_move_irq()/irq_move_masked_irq() to accept any irq_data.
    
    Signed-off-by: Jiang Liu <jiang.liu@linux.intel.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Randy Dunlap <rdunlap@infradead.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Link: http://lkml.kernel.org/r/1433145945-789-3-git-send-email-jiang.liu@linux.intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index ca3f4aaff707..dd203e276b07 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -7,7 +7,7 @@
 void irq_move_masked_irq(struct irq_data *idata)
 {
 	struct irq_desc *desc = irq_data_to_desc(idata);
-	struct irq_chip *chip = idata->chip;
+	struct irq_chip *chip = desc->irq_data.chip;
 
 	if (likely(!irqd_is_setaffinity_pending(&desc->irq_data)))
 		return;
@@ -52,6 +52,13 @@ void irq_move_irq(struct irq_data *idata)
 {
 	bool masked;
 
+	/*
+	 * Get top level irq_data when CONFIG_IRQ_DOMAIN_HIERARCHY is enabled,
+	 * and it should be optimized away when CONFIG_IRQ_DOMAIN_HIERARCHY is
+	 * disabled. So we avoid an "#ifdef CONFIG_IRQ_DOMAIN_HIERARCHY" here.
+	 */
+	idata = irq_desc_get_irq_data(irq_data_to_desc(idata));
+
 	if (likely(!irqd_is_setaffinity_pending(idata)))
 		return;
 

commit 818b0f3bfb236ae66cac3ff38e86b9e47f24b7aa
Author: Jiang Liu <liuj97@gmail.com>
Date:   Fri Mar 30 23:11:34 2012 +0800

    genirq: Introduce irq_do_set_affinity() to reduce duplicated code
    
    All invocations of chip->irq_set_affinity() are doing the same return
    value checks. Let them all use a common function.
    
    [ tglx: removed the silly likely while at it ]
    
    Signed-off-by: Jiang Liu <jiang.liu@huawei.com>
    Cc: Jiang Liu <liuj97@gmail.com>
    Cc: Keping Chen <chenkeping@huawei.com>
    Link: http://lkml.kernel.org/r/1333120296-13563-3-git-send-email-jiang.liu@huawei.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index c3c89751b327..ca3f4aaff707 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -42,17 +42,8 @@ void irq_move_masked_irq(struct irq_data *idata)
 	 * For correct operation this depends on the caller
 	 * masking the irqs.
 	 */
-	if (likely(cpumask_any_and(desc->pending_mask, cpu_online_mask)
-		   < nr_cpu_ids)) {
-		int ret = chip->irq_set_affinity(&desc->irq_data,
-						 desc->pending_mask, false);
-		switch (ret) {
-		case IRQ_SET_MASK_OK:
-			cpumask_copy(desc->irq_data.affinity, desc->pending_mask);
-		case IRQ_SET_MASK_OK_NOCOPY:
-			irq_set_thread_affinity(desc);
-		}
-	}
+	if (cpumask_any_and(desc->pending_mask, cpu_online_mask) < nr_cpu_ids)
+		irq_do_set_affinity(&desc->irq_data, desc->pending_mask, false);
 
 	cpumask_clear(desc->pending_mask);
 }

commit f5cb92ac82d06cb583c1f66666314c5c0a4d7913
Author: Jiang Liu <liuj97@gmail.com>
Date:   Fri Mar 30 23:11:33 2012 +0800

    genirq: Adjust irq thread affinity on IRQ_SET_MASK_OK_NOCOPY return value
    
    irq_move_masked_irq() checks the return code of
    chip->irq_set_affinity() only for 0, but IRQ_SET_MASK_OK_NOCOPY is
    also a valid return code, which is there to avoid a redundant copy of
    the cpumask. But in case of IRQ_SET_MASK_OK_NOCOPY we not only avoid
    the redundant copy, we also fail to adjust the thread affinity of an
    eventually threaded interrupt handler.
    
    Handle IRQ_SET_MASK_OK (==0) and IRQ_SET_MASK_OK_NOCOPY(==1) return
    values correctly by checking the valid return values seperately.
    
    Signed-off-by: Jiang Liu <jiang.liu@huawei.com>
    Cc: Jiang Liu <liuj97@gmail.com>
    Cc: Keping Chen <chenkeping@huawei.com>
    Cc: stable@vger.kernel.org
    Link: http://lkml.kernel.org/r/1333120296-13563-2-git-send-email-jiang.liu@huawei.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 47420908fba0..c3c89751b327 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -43,12 +43,16 @@ void irq_move_masked_irq(struct irq_data *idata)
 	 * masking the irqs.
 	 */
 	if (likely(cpumask_any_and(desc->pending_mask, cpu_online_mask)
-		   < nr_cpu_ids))
-		if (!chip->irq_set_affinity(&desc->irq_data,
-					    desc->pending_mask, false)) {
+		   < nr_cpu_ids)) {
+		int ret = chip->irq_set_affinity(&desc->irq_data,
+						 desc->pending_mask, false);
+		switch (ret) {
+		case IRQ_SET_MASK_OK:
 			cpumask_copy(desc->irq_data.affinity, desc->pending_mask);
+		case IRQ_SET_MASK_OK_NOCOPY:
 			irq_set_thread_affinity(desc);
 		}
+	}
 
 	cpumask_clear(desc->pending_mask);
 }

commit 25985edcedea6396277003854657b5f3cb31a628
Author: Lucas De Marchi <lucas.demarchi@profusion.mobi>
Date:   Wed Mar 30 22:57:33 2011 -0300

    Fix common misspellings
    
    Fixes generated by 'codespell' and manually reviewed.
    
    Signed-off-by: Lucas De Marchi <lucas.demarchi@profusion.mobi>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index bc6194698dfd..47420908fba0 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -35,7 +35,7 @@ void irq_move_masked_irq(struct irq_data *idata)
 	 * do the disable, re-program, enable sequence.
 	 * This is *not* particularly important for level triggered
 	 * but in a edge trigger case, we might be setting rte
-	 * when an active trigger is comming in. This could
+	 * when an active trigger is coming in. This could
 	 * cause some ioapics to mal-function.
 	 * Being paranoid i guess!
 	 *

commit 851d7cf647e0d31668eb5dc496f7698a2f6136b4
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Mar 29 02:51:13 2011 +0200

    genirq: Remove move_*irq leftovers
    
    All users converted to new interface.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index e33d9c8d5089..bc6194698dfd 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -53,11 +53,6 @@ void irq_move_masked_irq(struct irq_data *idata)
 	cpumask_clear(desc->pending_mask);
 }
 
-void move_masked_irq(int irq)
-{
-	irq_move_masked_irq(irq_get_irq_data(irq));
-}
-
 void irq_move_irq(struct irq_data *idata)
 {
 	bool masked;
@@ -80,8 +75,3 @@ void irq_move_irq(struct irq_data *idata)
 	if (!masked)
 		idata->chip->irq_unmask(idata);
 }
-
-void move_native_irq(int irq)
-{
-	irq_move_irq(irq_get_irq_data(irq));
-}

commit a6aeddd1c4e464a2150f97ca2d1c3d68cfbd9296
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Mar 28 20:28:56 2011 +0200

    genirq: Fix typo and remove unused variable
    
    Sigh, I'm overworked.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 5e81d34b08d6..e33d9c8d5089 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -60,7 +60,6 @@ void move_masked_irq(int irq)
 
 void irq_move_irq(struct irq_data *idata)
 {
-	struct irq_desc *desc = irq_data_to_desc(idata);
 	bool masked;
 
 	if (likely(!irqd_is_setaffinity_pending(idata)))

commit 32f4125ebffee4f3c4dbc6a437fc656129eb9e60
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Mar 28 14:10:52 2011 +0200

    genirq: Move INPROGRESS, MASKED and DISABLED state flags to irq_data
    
    We really need these flags for some of the interrupt chips. Move it
    from internal state to irq_data and provide proper accessors.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: David Daney <ddaney@caviumnetworks.com>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index ec4806d4778b..5e81d34b08d6 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -66,7 +66,7 @@ void irq_move_irq(struct irq_data *idata)
 	if (likely(!irqd_is_setaffinity_pending(idata)))
 		return;
 
-	if (unlikely(desc->istate & IRQS_DISABLED))
+	if (unlikely(irqd_irq_disabled(idata)))
 		return;
 
 	/*
@@ -74,7 +74,7 @@ void irq_move_irq(struct irq_data *idata)
 	 * threaded interrupt with ONESHOT set, we can end up with an
 	 * interrupt storm.
 	 */
-	masked = desc->istate & IRQS_MASKED;
+	masked = irqd_irq_masked(idata);
 	if (!masked)
 		idata->chip->irq_mask(idata);
 	irq_move_masked_irq(idata);

commit a439520f8b18917b322f576be04c54aba84bb044
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Feb 4 18:46:16 2011 +0100

    genirq: Implement irq_data based move_*_irq() versions
    
    No need to lookup the irq descriptor when calling from a chip callback
    function which has irq_data already handy.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 7a93c6b88b25..ec4806d4778b 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -4,10 +4,10 @@
 
 #include "internals.h"
 
-void move_masked_irq(int irq)
+void irq_move_masked_irq(struct irq_data *idata)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
-	struct irq_chip *chip = desc->irq_data.chip;
+	struct irq_desc *desc = irq_data_to_desc(idata);
+	struct irq_chip *chip = idata->chip;
 
 	if (likely(!irqd_is_setaffinity_pending(&desc->irq_data)))
 		return;
@@ -53,12 +53,17 @@ void move_masked_irq(int irq)
 	cpumask_clear(desc->pending_mask);
 }
 
-void move_native_irq(int irq)
+void move_masked_irq(int irq)
+{
+	irq_move_masked_irq(irq_get_irq_data(irq));
+}
+
+void irq_move_irq(struct irq_data *idata)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
+	struct irq_desc *desc = irq_data_to_desc(idata);
 	bool masked;
 
-	if (likely(!irqd_is_setaffinity_pending(&desc->irq_data)))
+	if (likely(!irqd_is_setaffinity_pending(idata)))
 		return;
 
 	if (unlikely(desc->istate & IRQS_DISABLED))
@@ -71,8 +76,13 @@ void move_native_irq(int irq)
 	 */
 	masked = desc->istate & IRQS_MASKED;
 	if (!masked)
-		desc->irq_data.chip->irq_mask(&desc->irq_data);
-	move_masked_irq(irq);
+		idata->chip->irq_mask(idata);
+	irq_move_masked_irq(idata);
 	if (!masked)
-		desc->irq_data.chip->irq_unmask(&desc->irq_data);
+		idata->chip->irq_unmask(idata);
+}
+
+void move_native_irq(int irq)
+{
+	irq_move_irq(irq_get_irq_data(irq));
 }

commit a005677b3dd05decdd8880cf3044ae709856f58f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Feb 8 17:11:03 2011 +0100

    genirq: Mirror IRQ_PER_CPU and IRQ_NO_BALANCING in irq_data.state
    
    That's the right data structure to look at for arch code.
    
    Accessor functions are provided.
    
             irqd_is_per_cpu(irqdata);
             irqd_can_balance(irqdata);
    
    Coders who access them directly will be tracked down and slapped with
    stinking trouts.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 24f53caddf47..7a93c6b88b25 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -15,7 +15,7 @@ void move_masked_irq(int irq)
 	/*
 	 * Paranoia: cpu-local interrupts shouldn't be calling in here anyway.
 	 */
-	if (desc->status & (IRQ_PER_CPU | IRQ_NO_BALANCING)) {
+	if (!irqd_can_balance(&desc->irq_data)) {
 		WARN_ON(1);
 		return;
 	}

commit fae581e588e64a0690f3fc995e404fcacaebe772
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Feb 8 16:53:24 2011 +0100

    genirq: Remove CHECK_IRQ_PER_CPU from core code
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 9485ae081dcd..24f53caddf47 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -15,7 +15,7 @@ void move_masked_irq(int irq)
 	/*
 	 * Paranoia: cpu-local interrupts shouldn't be calling in here anyway.
 	 */
-	if (CHECK_IRQ_PER_CPU(desc->status)) {
+	if (desc->status & (IRQ_PER_CPU | IRQ_NO_BALANCING)) {
 		WARN_ON(1);
 		return;
 	}

commit f230b6d5c48f8d12f4dfa1f8b5ab0b0320076d21
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Feb 5 15:20:04 2011 +0100

    genirq: Add IRQ_MOVE_PENDING to irq_data.state
    
    chip implementations need to know about it. Keep status in sync until
    all users are fixed.
    
    Accessor function: irqd_is_setaffinity_pending(irqdata)
    
    Coders who access them directly will be tracked down and slapped with
    stinking trouts.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 6f2f98480354..9485ae081dcd 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -9,7 +9,7 @@ void move_masked_irq(int irq)
 	struct irq_desc *desc = irq_to_desc(irq);
 	struct irq_chip *chip = desc->irq_data.chip;
 
-	if (likely(!(desc->status & IRQ_MOVE_PENDING)))
+	if (likely(!irqd_is_setaffinity_pending(&desc->irq_data)))
 		return;
 
 	/*
@@ -20,7 +20,7 @@ void move_masked_irq(int irq)
 		return;
 	}
 
-	desc->status &= ~IRQ_MOVE_PENDING;
+	irqd_clr_move_pending(&desc->irq_data);
 
 	if (unlikely(cpumask_empty(desc->pending_mask)))
 		return;
@@ -58,7 +58,7 @@ void move_native_irq(int irq)
 	struct irq_desc *desc = irq_to_desc(irq);
 	bool masked;
 
-	if (likely(!(desc->status & IRQ_MOVE_PENDING)))
+	if (likely(!irqd_is_setaffinity_pending(&desc->irq_data)))
 		return;
 
 	if (unlikely(desc->istate & IRQS_DISABLED))

commit 6e40262ea43c4b0e3f435b3a083e4461ef921c17
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Feb 8 12:36:06 2011 +0100

    genirq: Move IRQ_MASKED to core
    
    Keep status in sync until all users are fixed.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 8c68cb8555a7..6f2f98480354 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -69,7 +69,7 @@ void move_native_irq(int irq)
 	 * threaded interrupt with ONESHOT set, we can end up with an
 	 * interrupt storm.
 	 */
-	masked = desc->status & IRQ_MASKED;
+	masked = desc->istate & IRQS_MASKED;
 	if (!masked)
 		desc->irq_data.chip->irq_mask(&desc->irq_data);
 	move_masked_irq(irq);

commit c1594b77e46124bb462f961e536120e471c67446
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Feb 7 22:11:30 2011 +0100

    genirq: Move IRQ_DISABLED to core
    
    Keep status in sync until all abusers are fixed.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 441fd629ff04..8c68cb8555a7 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -61,7 +61,7 @@ void move_native_irq(int irq)
 	if (likely(!(desc->status & IRQ_MOVE_PENDING)))
 		return;
 
-	if (unlikely(desc->status & IRQ_DISABLED))
+	if (unlikely(desc->istate & IRQS_DISABLED))
 		return;
 
 	/*

commit f1a06390d013244e721372b3f9b66e39b6429c71
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jan 28 08:47:15 2011 +0100

    genirq: Prevent irq storm on migration
    
    move_native_irq() masks and unmasks the interrupt line
    unconditionally, but the interrupt line might be masked due to a
    threaded oneshot handler in progress. Unmasking the line in that case
    can lead to interrupt storms. Observed on PREEMPT_RT.
    
    Originally-from: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@kernel.org

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 1d2541940480..441fd629ff04 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -56,6 +56,7 @@ void move_masked_irq(int irq)
 void move_native_irq(int irq)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
+	bool masked;
 
 	if (likely(!(desc->status & IRQ_MOVE_PENDING)))
 		return;
@@ -63,8 +64,15 @@ void move_native_irq(int irq)
 	if (unlikely(desc->status & IRQ_DISABLED))
 		return;
 
-	desc->irq_data.chip->irq_mask(&desc->irq_data);
+	/*
+	 * Be careful vs. already masked interrupts. If this is a
+	 * threaded interrupt with ONESHOT set, we can end up with an
+	 * interrupt storm.
+	 */
+	masked = desc->status & IRQ_MASKED;
+	if (!masked)
+		desc->irq_data.chip->irq_mask(&desc->irq_data);
 	move_masked_irq(irq);
-	desc->irq_data.chip->irq_unmask(&desc->irq_data);
+	if (!masked)
+		desc->irq_data.chip->irq_unmask(&desc->irq_data);
 }
-

commit c96b3b3c448592a0b87ef20306deb8b1fb4878c7
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Sep 27 12:45:41 2010 +0000

    genirq: Provide compat handling for chip->set_affinity()
    
    Wrap the old chip function set_affinity() until the migration is
    complete and the old chip functions are removed.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    LKML-Reference: <20100927121842.732894108@linutronix.de>
    Reviewed-by: H. Peter Anvin <hpa@zytor.com>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 7888e5d5575a..1d2541940480 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -7,6 +7,7 @@
 void move_masked_irq(int irq)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
+	struct irq_chip *chip = desc->irq_data.chip;
 
 	if (likely(!(desc->status & IRQ_MOVE_PENDING)))
 		return;
@@ -24,7 +25,7 @@ void move_masked_irq(int irq)
 	if (unlikely(cpumask_empty(desc->pending_mask)))
 		return;
 
-	if (!desc->irq_data.chip->set_affinity)
+	if (!chip->irq_set_affinity)
 		return;
 
 	assert_raw_spin_locked(&desc->lock);
@@ -43,7 +44,8 @@ void move_masked_irq(int irq)
 	 */
 	if (likely(cpumask_any_and(desc->pending_mask, cpu_online_mask)
 		   < nr_cpu_ids))
-		if (!desc->irq_data.chip->set_affinity(irq, desc->pending_mask)) {
+		if (!chip->irq_set_affinity(&desc->irq_data,
+					    desc->pending_mask, false)) {
 			cpumask_copy(desc->irq_data.affinity, desc->pending_mask);
 			irq_set_thread_affinity(desc);
 		}

commit 0eda58b7f3a30c9a13d83db1cfaab00e1c452055
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Sep 27 12:44:44 2010 +0000

    genirq: Provide compat handling for chip->unmask()
    
    Wrap the old chip function unmask() until the migration is complete
    and the old chip functions are removed.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    LKML-Reference: <20100927121842.043608928@linutronix.de>
    Reviewed-by: H. Peter Anvin <hpa@zytor.com>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index b165ec26b757..7888e5d5575a 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -63,6 +63,6 @@ void move_native_irq(int irq)
 
 	desc->irq_data.chip->irq_mask(&desc->irq_data);
 	move_masked_irq(irq);
-	desc->irq_data.chip->unmask(irq);
+	desc->irq_data.chip->irq_unmask(&desc->irq_data);
 }
 

commit e2c0f8ff0fc26959952fbfa89f732fef928df77f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Sep 27 12:44:42 2010 +0000

    genirq: Provide compat handling for chip->mask()
    
    Wrap the old chip function mask() until the migration is complete and
    the old chip functions are removed.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    LKML-Reference: <20100927121841.940355859@linutronix.de>
    Reviewed-by: H. Peter Anvin <hpa@zytor.com>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index f923c37e651a..b165ec26b757 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -61,7 +61,7 @@ void move_native_irq(int irq)
 	if (unlikely(desc->status & IRQ_DISABLED))
 		return;
 
-	desc->irq_data.chip->mask(irq);
+	desc->irq_data.chip->irq_mask(&desc->irq_data);
 	move_masked_irq(irq);
 	desc->irq_data.chip->unmask(irq);
 }

commit 6b8ff3120c758340505dddf08ad685ebb841d5d5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Oct 1 12:58:38 2010 +0200

    genirq: Convert core code to irq_data
    
    Convert all references in the core code to orq, chip, handler_data,
    chip_data, msi_desc, affinity to irq_data.*
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 241962280836..f923c37e651a 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -24,7 +24,7 @@ void move_masked_irq(int irq)
 	if (unlikely(cpumask_empty(desc->pending_mask)))
 		return;
 
-	if (!desc->chip->set_affinity)
+	if (!desc->irq_data.chip->set_affinity)
 		return;
 
 	assert_raw_spin_locked(&desc->lock);
@@ -43,8 +43,8 @@ void move_masked_irq(int irq)
 	 */
 	if (likely(cpumask_any_and(desc->pending_mask, cpu_online_mask)
 		   < nr_cpu_ids))
-		if (!desc->chip->set_affinity(irq, desc->pending_mask)) {
-			cpumask_copy(desc->affinity, desc->pending_mask);
+		if (!desc->irq_data.chip->set_affinity(irq, desc->pending_mask)) {
+			cpumask_copy(desc->irq_data.affinity, desc->pending_mask);
 			irq_set_thread_affinity(desc);
 		}
 
@@ -61,8 +61,8 @@ void move_native_irq(int irq)
 	if (unlikely(desc->status & IRQ_DISABLED))
 		return;
 
-	desc->chip->mask(irq);
+	desc->irq_data.chip->mask(irq);
 	move_masked_irq(irq);
-	desc->chip->unmask(irq);
+	desc->irq_data.chip->unmask(irq);
 }
 

commit 239007b8440abff689632f50cdf0f2b9e895b534
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Nov 17 16:46:45 2009 +0100

    genirq: Convert irq_desc.lock to raw_spinlock
    
    Convert locks which cannot be sleeping locks in preempt-rt to
    raw_spinlocks.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Acked-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index fcb6c96f2627..241962280836 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -27,7 +27,7 @@ void move_masked_irq(int irq)
 	if (!desc->chip->set_affinity)
 		return;
 
-	assert_spin_locked(&desc->lock);
+	assert_raw_spin_locked(&desc->lock);
 
 	/*
 	 * If there was a valid mask to work with, please

commit 591d2fb02ea80472d846c0b8507007806bdd69cc
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jul 21 11:09:39 2009 +0200

    genirq: Delegate irq affinity setting to the irq thread
    
    irq_set_thread_affinity() calls set_cpus_allowed_ptr() which might
    sleep, but irq_set_thread_affinity() is called with desc->lock held
    and can be called from hard interrupt context as well. The code has
    another bug as it does not hold a ref on the task struct as required
    by set_cpus_allowed_ptr().
    
    Just set the IRQTF_AFFINITY bit in action->thread_flags. The next time
    the thread runs it migrates itself. Solves all of the above problems
    nicely.
    
    Add kerneldoc to irq_set_thread_affinity() while at it.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    LKML-Reference: <new-submission>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index cfe767ca1545..fcb6c96f2627 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -45,7 +45,7 @@ void move_masked_irq(int irq)
 		   < nr_cpu_ids))
 		if (!desc->chip->set_affinity(irq, desc->pending_mask)) {
 			cpumask_copy(desc->affinity, desc->pending_mask);
-			irq_set_thread_affinity(desc, desc->pending_mask);
+			irq_set_thread_affinity(desc);
 		}
 
 	cpumask_clear(desc->pending_mask);

commit 57b150cce8e004ddd36330490a68bfb59b7271e9
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Mon Apr 27 17:59:53 2009 -0700

    irq: only update affinity if ->set_affinity() is sucessfull
    
    irq_set_affinity() and move_masked_irq() try to assign affinity
    before calling chip set_affinity(). Some archs are assigning it
    in ->set_affinity() again.
    
    We do something like:
    
     cpumask_cpy(desc->affinity, mask);
     desc->chip->set_affinity(mask);
    
    But in the failure path, affinity should not be touched - otherwise
    we'll end up with a different affinity mask despite the failure to
    migrate the IRQ.
    
    So try to update the afffinity only if set_affinity returns with 0.
    Also call irq_set_thread_affinity accordingly.
    
    v2: update after "irq, x86: Remove IRQ_DISABLED check in process context IRQ move"
    v3: according to Ingo, change set_affinity() in irq_chip should return int.
    v4: update comments by removing moving irq_desc code.
    
    [ Impact: fix /proc/irq/*/smp_affinity setting corner case bug ]
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    LKML-Reference: <49F65509.60307@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index e05ad9be43b7..cfe767ca1545 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -1,5 +1,8 @@
 
 #include <linux/irq.h>
+#include <linux/interrupt.h>
+
+#include "internals.h"
 
 void move_masked_irq(int irq)
 {
@@ -39,11 +42,12 @@ void move_masked_irq(int irq)
 	 * masking the irqs.
 	 */
 	if (likely(cpumask_any_and(desc->pending_mask, cpu_online_mask)
-		   < nr_cpu_ids)) {
-		cpumask_and(desc->affinity,
-			    desc->pending_mask, cpu_online_mask);
-		desc->chip->set_affinity(irq, desc->affinity);
-	}
+		   < nr_cpu_ids))
+		if (!desc->chip->set_affinity(irq, desc->pending_mask)) {
+			cpumask_copy(desc->affinity, desc->pending_mask);
+			irq_set_thread_affinity(desc, desc->pending_mask);
+		}
+
 	cpumask_clear(desc->pending_mask);
 }
 

commit 7f7ace0cda64c99599c23785f8979a072e118058
Author: Mike Travis <travis@sgi.com>
Date:   Sat Jan 10 21:58:08 2009 -0800

    cpumask: update irq_desc to use cpumask_var_t
    
    Impact: reduce memory usage, use new cpumask API.
    
    Replace the affinity and pending_masks with cpumask_var_t's.  This adds
    to the significant size reduction done with the SPARSE_IRQS changes.
    
    The added functions (init_alloc_desc_masks & init_copy_desc_masks) are
    in the include file so they can be inlined (and optimized out for the
    !CONFIG_CPUMASKS_OFFSTACK case.)  [Naming chosen to be consistent with
    the other init*irq functions, as well as the backwards arg declaration
    of "from, to" instead of the more common "to, from" standard.]
    
    Includes a slight change to the declaration of struct irq_desc to embed
    the pending_mask within ifdef(CONFIG_SMP) to be consistent with other
    references, and some small changes to Xen.
    
    Tested: sparse/non-sparse/cpumask_offstack/non-cpumask_offstack/nonuma/nosmp on x86_64
    
    Signed-off-by: Mike Travis <travis@sgi.com>
    Cc: Chris Wright <chrisw@sous-sol.org>
    Cc: Jeremy Fitzhardinge <jeremy@xensource.com>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Cc: virtualization@lists.osdl.org
    Cc: xen-devel@lists.xensource.com
    Cc: Yinghai Lu <yhlu.kernel@gmail.com>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index bd72329e630c..e05ad9be43b7 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -18,7 +18,7 @@ void move_masked_irq(int irq)
 
 	desc->status &= ~IRQ_MOVE_PENDING;
 
-	if (unlikely(cpumask_empty(&desc->pending_mask)))
+	if (unlikely(cpumask_empty(desc->pending_mask)))
 		return;
 
 	if (!desc->chip->set_affinity)
@@ -38,13 +38,13 @@ void move_masked_irq(int irq)
 	 * For correct operation this depends on the caller
 	 * masking the irqs.
 	 */
-	if (likely(cpumask_any_and(&desc->pending_mask, cpu_online_mask)
+	if (likely(cpumask_any_and(desc->pending_mask, cpu_online_mask)
 		   < nr_cpu_ids)) {
-		cpumask_and(&desc->affinity,
-			    &desc->pending_mask, cpu_online_mask);
-		desc->chip->set_affinity(irq, &desc->affinity);
+		cpumask_and(desc->affinity,
+			    desc->pending_mask, cpu_online_mask);
+		desc->chip->set_affinity(irq, desc->affinity);
 	}
-	cpumask_clear(&desc->pending_mask);
+	cpumask_clear(desc->pending_mask);
 }
 
 void move_native_irq(int irq)

commit 0de26520c7cabf36e1de090ea8092f011a6106ce
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Sat Dec 13 21:20:26 2008 +1030

    cpumask: make irq_set_affinity() take a const struct cpumask
    
    Impact: change existing irq_chip API
    
    Not much point with gentle transition here: the struct irq_chip's
    setaffinity method signature needs to change.
    
    Fortunately, not widely used code, but hits a few architectures.
    
    Note: In irq_select_affinity() I save a temporary in by mangling
    irq_desc[irq].affinity directly.  Ingo, does this break anything?
    
    (Folded in fix from KOSAKI Motohiro)
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Mike Travis <travis@sgi.com>
    Reviewed-by: Grant Grundler <grundler@parisc-linux.org>
    Acked-by: Ingo Molnar <mingo@redhat.com>
    Cc: ralf@linux-mips.org
    Cc: grundler@parisc-linux.org
    Cc: jeremy@xensource.com
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 9db681d95814..bd72329e630c 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -4,7 +4,6 @@
 void move_masked_irq(int irq)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
-	cpumask_t tmp;
 
 	if (likely(!(desc->status & IRQ_MOVE_PENDING)))
 		return;
@@ -19,7 +18,7 @@ void move_masked_irq(int irq)
 
 	desc->status &= ~IRQ_MOVE_PENDING;
 
-	if (unlikely(cpus_empty(desc->pending_mask)))
+	if (unlikely(cpumask_empty(&desc->pending_mask)))
 		return;
 
 	if (!desc->chip->set_affinity)
@@ -27,8 +26,6 @@ void move_masked_irq(int irq)
 
 	assert_spin_locked(&desc->lock);
 
-	cpus_and(tmp, desc->pending_mask, cpu_online_map);
-
 	/*
 	 * If there was a valid mask to work with, please
 	 * do the disable, re-program, enable sequence.
@@ -41,10 +38,13 @@ void move_masked_irq(int irq)
 	 * For correct operation this depends on the caller
 	 * masking the irqs.
 	 */
-	if (likely(!cpus_empty(tmp))) {
-		desc->chip->set_affinity(irq,tmp);
+	if (likely(cpumask_any_and(&desc->pending_mask, cpu_online_mask)
+		   < nr_cpu_ids)) {
+		cpumask_and(&desc->affinity,
+			    &desc->pending_mask, cpu_online_mask);
+		desc->chip->set_affinity(irq, &desc->affinity);
 	}
-	cpus_clear(desc->pending_mask);
+	cpumask_clear(&desc->pending_mask);
 }
 
 void move_native_irq(int irq)

commit f6d87f4bd259cf33e092cd1a8fde05f291c47af1
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Nov 7 13:18:30 2008 +0100

    genirq: keep affinities set from userspace across free/request_irq()
    
    Impact: preserve user-modified affinities on interrupts
    
    Kumar Galak noticed that commit
    18404756765c713a0be4eb1082920c04822ce588 (genirq: Expose default irq
    affinity mask (take 3))
    
    overrides an already set affinity setting across a free /
    request_irq(). Happens e.g. with ifdown/ifup of a network device.
    
    Change the logic to mark the affinities as set and keep them
    intact. This also fixes the unlocked access to irq_desc in
    irq_select_affinity() when called from irq_affinity_proc_write()
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 90b920d3f52b..9db681d95814 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -1,17 +1,6 @@
 
 #include <linux/irq.h>
 
-void set_pending_irq(unsigned int irq, cpumask_t mask)
-{
-	struct irq_desc *desc = irq_to_desc(irq);
-	unsigned long flags;
-
-	spin_lock_irqsave(&desc->lock, flags);
-	desc->status |= IRQ_MOVE_PENDING;
-	desc->pending_mask = mask;
-	spin_unlock_irqrestore(&desc->lock, flags);
-}
-
 void move_masked_irq(int irq)
 {
 	struct irq_desc *desc = irq_to_desc(irq);

commit 08678b0841267c1d00d771fe01548d86043d065e
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Tue Aug 19 20:50:05 2008 -0700

    generic: sparse irqs: use irq_desc() together with dyn_array, instead of irq_desc[]
    
    add CONFIG_HAVE_SPARSE_IRQ to for use condensed array.
    Get rid of irq_desc[] array assumptions.
    
    Preallocate 32 irq_desc, and irq_desc() will try to get more.
    
    ( No change in functionality is expected anywhere, except the odd build
      failure where we missed a code site or where a crossing commit itroduces
      new irq_desc[] usage. )
    
    v2: according to Eric, change get_irq_desc() to irq_desc()
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 77b7acc875c5..90b920d3f52b 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -3,18 +3,18 @@
 
 void set_pending_irq(unsigned int irq, cpumask_t mask)
 {
-	struct irq_desc *desc = irq_desc + irq;
+	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned long flags;
 
 	spin_lock_irqsave(&desc->lock, flags);
 	desc->status |= IRQ_MOVE_PENDING;
-	irq_desc[irq].pending_mask = mask;
+	desc->pending_mask = mask;
 	spin_unlock_irqrestore(&desc->lock, flags);
 }
 
 void move_masked_irq(int irq)
 {
-	struct irq_desc *desc = irq_desc + irq;
+	struct irq_desc *desc = irq_to_desc(irq);
 	cpumask_t tmp;
 
 	if (likely(!(desc->status & IRQ_MOVE_PENDING)))
@@ -30,7 +30,7 @@ void move_masked_irq(int irq)
 
 	desc->status &= ~IRQ_MOVE_PENDING;
 
-	if (unlikely(cpus_empty(irq_desc[irq].pending_mask)))
+	if (unlikely(cpus_empty(desc->pending_mask)))
 		return;
 
 	if (!desc->chip->set_affinity)
@@ -38,7 +38,7 @@ void move_masked_irq(int irq)
 
 	assert_spin_locked(&desc->lock);
 
-	cpus_and(tmp, irq_desc[irq].pending_mask, cpu_online_map);
+	cpus_and(tmp, desc->pending_mask, cpu_online_map);
 
 	/*
 	 * If there was a valid mask to work with, please
@@ -55,12 +55,12 @@ void move_masked_irq(int irq)
 	if (likely(!cpus_empty(tmp))) {
 		desc->chip->set_affinity(irq,tmp);
 	}
-	cpus_clear(irq_desc[irq].pending_mask);
+	cpus_clear(desc->pending_mask);
 }
 
 void move_native_irq(int irq)
 {
-	struct irq_desc *desc = irq_desc + irq;
+	struct irq_desc *desc = irq_to_desc(irq);
 
 	if (likely(!(desc->status & IRQ_MOVE_PENDING)))
 		return;

commit 2a786b452eba900324c29a8fcf5c96d5b1c01000
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Feb 23 04:46:20 2007 -0700

    [PATCH] genirq: Mask irqs when migrating them.
    
    move_native_irqs tries to do the right thing when migrating irqs
    by disabling them.  However disabling them is a software logical
    thing, not a hardware thing.  This has always been a little flaky
    and after Ingo's latest round of changes it is guaranteed to not
    mask the apic.
    
    So this patch fixes move_native_irq to directly call the mask and
    unmask chip methods to guarantee that we mask the irq when we
    are migrating it.  We must do this as it is required by
    all code that call into the path.
    
    Since we don't know the masked status when IRQ_DISABLED is
    set so we will not be able to restore it.   The patch makes the code
    just give up and trying again the next time this routing is called.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Acked-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 4baa3bbcd25a..77b7acc875c5 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -65,12 +65,11 @@ void move_native_irq(int irq)
 	if (likely(!(desc->status & IRQ_MOVE_PENDING)))
 		return;
 
-	if (likely(!(desc->status & IRQ_DISABLED)))
-		desc->chip->disable(irq);
+	if (unlikely(desc->status & IRQ_DISABLED))
+		return;
 
+	desc->chip->mask(irq);
 	move_masked_irq(irq);
-
-	if (likely(!(desc->status & IRQ_DISABLED)))
-		desc->chip->enable(irq);
+	desc->chip->unmask(irq);
 }
 

commit e7b946e98a456077dd6897f726f3d6197bd7e3b9
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Oct 4 02:16:29 2006 -0700

    [PATCH] genirq: irq: add moved_masked_irq
    
    Currently move_native_irq disables and renables the irq we are migrating to
    ensure we don't take that irq when we are actually doing the migration
    operation.  Disabling the irq needs to happen but sometimes doing the work is
    move_native_irq is too late.
    
    On x86 with ioapics the irq move sequences needs to be:
    edge_triggered:
      mask irq.
      move irq.
      unmask irq.
      ack irq.
    level_triggered:
      mask irq.
      ack irq.
      move irq.
      unmask irq.
    
    We can easily perform the edge triggered sequence, with the current defintion
    of move_native_irq.  However the level triggered case does not map well.  For
    that I have added move_masked_irq, to allow me to disable the irqs around both
    the ack and the move.
    
    Q: Why have we not seen this problem earlier?
    
    A: The only symptom I have been able to reproduce is that if we change
       the vector before acknowleding an irq the wrong irq is acknowledged.
       Since we currently are not reprogramming the irq vector during
       migration no problems show up.
    
       We have to mask the irq before we acknowledge the irq or else we could
       hit a window where an irq is asserted just before we acknowledge it.
    
       Edge triggered irqs do not have this problem because acknowledgements
       do not propogate in the same way.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Rajesh Shah <rajesh.shah@intel.com>
    Cc: Andi Kleen <ak@muc.de>
    Cc: "Protasevich, Natalie" <Natalie.Protasevich@UNISYS.com>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 9b234df810d0..4baa3bbcd25a 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -12,7 +12,7 @@ void set_pending_irq(unsigned int irq, cpumask_t mask)
 	spin_unlock_irqrestore(&desc->lock, flags);
 }
 
-void move_native_irq(int irq)
+void move_masked_irq(int irq)
 {
 	struct irq_desc *desc = irq_desc + irq;
 	cpumask_t tmp;
@@ -48,15 +48,29 @@ void move_native_irq(int irq)
 	 * when an active trigger is comming in. This could
 	 * cause some ioapics to mal-function.
 	 * Being paranoid i guess!
+	 *
+	 * For correct operation this depends on the caller
+	 * masking the irqs.
 	 */
 	if (likely(!cpus_empty(tmp))) {
-		if (likely(!(desc->status & IRQ_DISABLED)))
-			desc->chip->disable(irq);
-
 		desc->chip->set_affinity(irq,tmp);
-
-		if (likely(!(desc->status & IRQ_DISABLED)))
-			desc->chip->enable(irq);
 	}
 	cpus_clear(irq_desc[irq].pending_mask);
 }
+
+void move_native_irq(int irq)
+{
+	struct irq_desc *desc = irq_desc + irq;
+
+	if (likely(!(desc->status & IRQ_MOVE_PENDING)))
+		return;
+
+	if (likely(!(desc->status & IRQ_DISABLED)))
+		desc->chip->disable(irq);
+
+	move_masked_irq(irq);
+
+	if (likely(!(desc->status & IRQ_DISABLED)))
+		desc->chip->enable(irq);
+}
+

commit a24ceab4f44f21749aa0b6bd38bee37c775e036f
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Oct 4 02:16:27 2006 -0700

    [PATCH] genirq: irq: convert the move_irq flag from a 32bit word to a single bit
    
    The primary aim of this patchset is to remove maintenances problems caused by
    the irq infrastructure.  The two big issues I address are an artificially
    small cap on the number of irqs, and that MSI assumes vector == irq.  My
    primary focus is on x86_64 but I have touched other architectures where
    necessary to keep them from breaking.
    
    - To increase the number of irqs I modify the code to look at the (cpu,
      vector) pair instead of just looking at the vector.
    
      With a large number of irqs available systems with a large irq count no
      longer need to compress their irq numbers to fit.  Removing a lot of brittle
      special cases.
    
      For acpi guys the result is that irq == gsi.
    
    - Addressing the fact that MSI assumes irq == vector takes a few more
      patches.  But suffice it to say when I am done none of the generic irq code
      even knows what a vector is.
    
    In quick testing on a large Unisys x86_64 machine we stumbled over at least
    one driver that assumed that NR_IRQS could always fit into an 8 bit number.
    This driver is clearly buggy today.  But this has become a class of bugs that
    it is now much easier to hit.
    
    This patch:
    
    This is a minor space optimization.  In practice I don't think this has any
    affect because of our alignment constraints and the other fields but there is
    not point in chewing up an uncessary word and since we already read the flag
    field this should improve the cache hit ratio of the irq handler.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Rajesh Shah <rajesh.shah@intel.com>
    Cc: Andi Kleen <ak@muc.de>
    Cc: "Protasevich, Natalie" <Natalie.Protasevich@UNISYS.com>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index a57ebe9fa6f6..9b234df810d0 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -7,7 +7,7 @@ void set_pending_irq(unsigned int irq, cpumask_t mask)
 	unsigned long flags;
 
 	spin_lock_irqsave(&desc->lock, flags);
-	desc->move_irq = 1;
+	desc->status |= IRQ_MOVE_PENDING;
 	irq_desc[irq].pending_mask = mask;
 	spin_unlock_irqrestore(&desc->lock, flags);
 }
@@ -17,7 +17,7 @@ void move_native_irq(int irq)
 	struct irq_desc *desc = irq_desc + irq;
 	cpumask_t tmp;
 
-	if (likely(!desc->move_irq))
+	if (likely(!(desc->status & IRQ_MOVE_PENDING)))
 		return;
 
 	/*
@@ -28,7 +28,7 @@ void move_native_irq(int irq)
 		return;
 	}
 
-	desc->move_irq = 0;
+	desc->status &= ~IRQ_MOVE_PENDING;
 
 	if (unlikely(cpus_empty(irq_desc[irq].pending_mask)))
 		return;

commit cd916d31cc31273eca8a620fae02b7bf7f577559
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 29 02:24:42 2006 -0700

    [PATCH] genirq: cleanup: merge pending_irq_cpumask[] into irq_desc[]
    
    Consolidation: remove the pending_irq_cpumask[NR_IRQS] array and move it into
    the irq_desc[NR_IRQS].pending_mask field.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index a571c3abb793..a57ebe9fa6f6 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -8,7 +8,7 @@ void set_pending_irq(unsigned int irq, cpumask_t mask)
 
 	spin_lock_irqsave(&desc->lock, flags);
 	desc->move_irq = 1;
-	pending_irq_cpumask[irq] = mask;
+	irq_desc[irq].pending_mask = mask;
 	spin_unlock_irqrestore(&desc->lock, flags);
 }
 
@@ -30,7 +30,7 @@ void move_native_irq(int irq)
 
 	desc->move_irq = 0;
 
-	if (unlikely(cpus_empty(pending_irq_cpumask[irq])))
+	if (unlikely(cpus_empty(irq_desc[irq].pending_mask)))
 		return;
 
 	if (!desc->chip->set_affinity)
@@ -38,7 +38,7 @@ void move_native_irq(int irq)
 
 	assert_spin_locked(&desc->lock);
 
-	cpus_and(tmp, pending_irq_cpumask[irq], cpu_online_map);
+	cpus_and(tmp, irq_desc[irq].pending_mask, cpu_online_map);
 
 	/*
 	 * If there was a valid mask to work with, please
@@ -58,5 +58,5 @@ void move_native_irq(int irq)
 		if (likely(!(desc->status & IRQ_DISABLED)))
 			desc->chip->enable(irq);
 	}
-	cpus_clear(pending_irq_cpumask[irq]);
+	cpus_clear(irq_desc[irq].pending_mask);
 }

commit 34ffdb7233d5847808d2b63ca6761dac3af9c942
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 29 02:24:40 2006 -0700

    [PATCH] genirq: cleanup: reduce irq_desc_t use, mark it obsolete
    
    Cleanup: remove irq_desc_t use from the generic IRQ code, and mark it
    obsolete.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index b4a4354d03d5..a571c3abb793 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -3,7 +3,7 @@
 
 void set_pending_irq(unsigned int irq, cpumask_t mask)
 {
-	irq_desc_t *desc = irq_desc + irq;
+	struct irq_desc *desc = irq_desc + irq;
 	unsigned long flags;
 
 	spin_lock_irqsave(&desc->lock, flags);
@@ -14,8 +14,8 @@ void set_pending_irq(unsigned int irq, cpumask_t mask)
 
 void move_native_irq(int irq)
 {
+	struct irq_desc *desc = irq_desc + irq;
 	cpumask_t tmp;
-	irq_desc_t *desc = irq_desc + irq;
 
 	if (likely(!desc->move_irq))
 		return;

commit a8553acd6c14e827078779c0a0ee1c18f27b2403
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 29 02:24:38 2006 -0700

    [PATCH] genirq: cleanup: remove irq_descp()
    
    Cleanup: remove irq_descp() - explicit use of irq_desc[] is shorter and more
    readable.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index d978c87bca93..b4a4354d03d5 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -15,7 +15,7 @@ void set_pending_irq(unsigned int irq, cpumask_t mask)
 void move_native_irq(int irq)
 {
 	cpumask_t tmp;
-	irq_desc_t *desc = irq_descp(irq);
+	irq_desc_t *desc = irq_desc + irq;
 
 	if (likely(!desc->move_irq))
 		return;

commit d1bef4ed5faf7d9872337b33c4269e45ae1bf960
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 29 02:24:36 2006 -0700

    [PATCH] genirq: rename desc->handler to desc->chip
    
    This patch-queue improves the generic IRQ layer to be truly generic, by adding
    various abstractions and features to it, without impacting existing
    functionality.
    
    While the queue can be best described as "fix and improve everything in the
    generic IRQ layer that we could think of", and thus it consists of many
    smaller features and lots of cleanups, the one feature that stands out most is
    the new 'irq chip' abstraction.
    
    The irq-chip abstraction is about describing and coding and IRQ controller
    driver by mapping its raw hardware capabilities [and quirks, if needed] in a
    straightforward way, without having to think about "IRQ flow"
    (level/edge/etc.) type of details.
    
    This stands in contrast with the current 'irq-type' model of genirq
    architectures, which 'mixes' raw hardware capabilities with 'flow' details.
    The patchset supports both types of irq controller designs at once, and
    converts i386 and x86_64 to the new irq-chip design.
    
    As a bonus side-effect of the irq-chip approach, chained interrupt controllers
    (master/slave PIC constructs, etc.) are now supported by design as well.
    
    The end result of this patchset intends to be simpler architecture-level code
    and more consolidation between architectures.
    
    We reused many bits of code and many concepts from Russell King's ARM IRQ
    layer, the merging of which was one of the motivations for this patchset.
    
    This patch:
    
    rename desc->handler to desc->chip.
    
    Originally i did not want to do this, because it's a big patch.  But having
    both "desc->handler", "desc->handle_irq" and "action->handler" caused a
    large degree of confusion and made the code appear alot less clean than it
    truly is.
    
    I have also attempted a dual approach as well by introducing a
    desc->chip alias - but that just wasnt robust enough and broke
    frequently.
    
    So lets get over with this quickly.  The conversion was done automatically
    via scripts and converts all the code in the kernel.
    
    This renaming patch is the first one amongst the patches, so that the
    remaining patches can stay flexible and can be merged and split up
    without having some big monolithic patch act as a merge barrier.
    
    [akpm@osdl.org: build fix]
    [akpm@osdl.org: another build fix]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index a12d00eb5e7c..d978c87bca93 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -33,7 +33,7 @@ void move_native_irq(int irq)
 	if (unlikely(cpus_empty(pending_irq_cpumask[irq])))
 		return;
 
-	if (!desc->handler->set_affinity)
+	if (!desc->chip->set_affinity)
 		return;
 
 	assert_spin_locked(&desc->lock);
@@ -51,12 +51,12 @@ void move_native_irq(int irq)
 	 */
 	if (likely(!cpus_empty(tmp))) {
 		if (likely(!(desc->status & IRQ_DISABLED)))
-			desc->handler->disable(irq);
+			desc->chip->disable(irq);
 
-		desc->handler->set_affinity(irq,tmp);
+		desc->chip->set_affinity(irq,tmp);
 
 		if (likely(!(desc->status & IRQ_DISABLED)))
-			desc->handler->enable(irq);
+			desc->chip->enable(irq);
 	}
 	cpus_clear(pending_irq_cpumask[irq]);
 }

commit 89d0cf01c0aa9e8241cc3703a359ecd6abf3c28a
Author: Daniel Walker <dwalker@mvista.com>
Date:   Fri Jun 23 02:05:29 2006 -0700

    [PATCH] invert irq/migration.c brach prediction
    
    If you get to that point in the code it means that desc->move_irq is set,
    pending_irq_cpumask[irq] and cpu_online_map should have a value.  Still
    pretty good chance anding those two you'll still have a value.  So these
    two branch predictors should be inverted.
    
    Signed-off-by: Daniel Walker <dwalker@mvista.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 134f9f2e0e39..a12d00eb5e7c 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -30,7 +30,7 @@ void move_native_irq(int irq)
 
 	desc->move_irq = 0;
 
-	if (likely(cpus_empty(pending_irq_cpumask[irq])))
+	if (unlikely(cpus_empty(pending_irq_cpumask[irq])))
 		return;
 
 	if (!desc->handler->set_affinity)
@@ -49,7 +49,7 @@ void move_native_irq(int irq)
 	 * cause some ioapics to mal-function.
 	 * Being paranoid i guess!
 	 */
-	if (unlikely(!cpus_empty(tmp))) {
+	if (likely(!cpus_empty(tmp))) {
 		if (likely(!(desc->status & IRQ_DISABLED)))
 			desc->handler->disable(irq);
 

commit d824e66a9a427faf69c58f98dd7e1c3d1bb51c61
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Apr 10 22:54:04 2006 -0700

    [PATCH] build kernel/irq/migration.c only if CONFIG_GENERIC_PENDING_IRQ is set
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 52a8655fa080..134f9f2e0e39 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -1,6 +1,5 @@
-#include <linux/irq.h>
 
-#if defined(CONFIG_GENERIC_PENDING_IRQ)
+#include <linux/irq.h>
 
 void set_pending_irq(unsigned int irq, cpumask_t mask)
 {
@@ -61,5 +60,3 @@ void move_native_irq(int irq)
 	}
 	cpus_clear(pending_irq_cpumask[irq]);
 }
-
-#endif

commit 501f2499b897ca4be68b1acc7a4bc8cf66f5fd24
Author: Bryan Holty <lgeek@frontiernet.net>
Date:   Sat Mar 25 03:07:37 2006 -0800

    [PATCH] IRQ: prevent enabling of previously disabled interrupt
    
    This fix prevents re-disabling and enabling of a previously disabled
    interrupt.  On an SMP system with irq balancing enabled; If an interrupt is
    disabled from within its own interrupt context with disable_irq_nosync and is
    also earmarked for processor migration, the interrupt is blindly moved to the
    other processor and enabled without regard for its current "enabled" state.
    If there is an interrupt pending, it will unexpectedly invoke the irq handler
    on the new irq owning processor (even though the irq was previously disabled)
    
    The more intuitive fix would be to invoke disable_irq_nosync and
    enable_irq, but since we already have the desc->lock from __do_IRQ, we
    cannot call them directly.  Instead we can use the same logic to disable
    and enable found in disable_irq_nosync and enable_irq, with regards to the
    desc->depth.
    
    This now prevents a disabled interrupt from being re-disabled, and more
    importantly prevents a disabled interrupt from being incorrectly enabled on
    a different processor.
    
    Signed-off-by: Bryan Holty <lgeek@frontiernet.net>
    Cc: Andi Kleen <ak@muc.de>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
index 6bdd03c524c7..52a8655fa080 100644
--- a/kernel/irq/migration.c
+++ b/kernel/irq/migration.c
@@ -18,9 +18,17 @@ void move_native_irq(int irq)
 	cpumask_t tmp;
 	irq_desc_t *desc = irq_descp(irq);
 
-	if (likely (!desc->move_irq))
+	if (likely(!desc->move_irq))
 		return;
 
+	/*
+	 * Paranoia: cpu-local interrupts shouldn't be calling in here anyway.
+	 */
+	if (CHECK_IRQ_PER_CPU(desc->status)) {
+		WARN_ON(1);
+		return;
+	}
+
 	desc->move_irq = 0;
 
 	if (likely(cpus_empty(pending_irq_cpumask[irq])))
@@ -29,7 +37,8 @@ void move_native_irq(int irq)
 	if (!desc->handler->set_affinity)
 		return;
 
-	/* note - we hold the desc->lock */
+	assert_spin_locked(&desc->lock);
+
 	cpus_and(tmp, pending_irq_cpumask[irq], cpu_online_map);
 
 	/*
@@ -42,9 +51,13 @@ void move_native_irq(int irq)
 	 * Being paranoid i guess!
 	 */
 	if (unlikely(!cpus_empty(tmp))) {
-		desc->handler->disable(irq);
+		if (likely(!(desc->status & IRQ_DISABLED)))
+			desc->handler->disable(irq);
+
 		desc->handler->set_affinity(irq,tmp);
-		desc->handler->enable(irq);
+
+		if (likely(!(desc->status & IRQ_DISABLED)))
+			desc->handler->enable(irq);
 	}
 	cpus_clear(pending_irq_cpumask[irq]);
 }

commit c777ac5594f772ac760e02c3ac71d067616b579d
Author: Andrew Morton <akpm@osdl.org>
Date:   Sat Mar 25 03:07:36 2006 -0800

    [PATCH] irq: uninline migration functions
    
    Uninline some massive IRQ migration functions.  Put them in the new
    kernel/irq/migration.c.
    
    Cc: Andi Kleen <ak@muc.de>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/migration.c b/kernel/irq/migration.c
new file mode 100644
index 000000000000..6bdd03c524c7
--- /dev/null
+++ b/kernel/irq/migration.c
@@ -0,0 +1,52 @@
+#include <linux/irq.h>
+
+#if defined(CONFIG_GENERIC_PENDING_IRQ)
+
+void set_pending_irq(unsigned int irq, cpumask_t mask)
+{
+	irq_desc_t *desc = irq_desc + irq;
+	unsigned long flags;
+
+	spin_lock_irqsave(&desc->lock, flags);
+	desc->move_irq = 1;
+	pending_irq_cpumask[irq] = mask;
+	spin_unlock_irqrestore(&desc->lock, flags);
+}
+
+void move_native_irq(int irq)
+{
+	cpumask_t tmp;
+	irq_desc_t *desc = irq_descp(irq);
+
+	if (likely (!desc->move_irq))
+		return;
+
+	desc->move_irq = 0;
+
+	if (likely(cpus_empty(pending_irq_cpumask[irq])))
+		return;
+
+	if (!desc->handler->set_affinity)
+		return;
+
+	/* note - we hold the desc->lock */
+	cpus_and(tmp, pending_irq_cpumask[irq], cpu_online_map);
+
+	/*
+	 * If there was a valid mask to work with, please
+	 * do the disable, re-program, enable sequence.
+	 * This is *not* particularly important for level triggered
+	 * but in a edge trigger case, we might be setting rte
+	 * when an active trigger is comming in. This could
+	 * cause some ioapics to mal-function.
+	 * Being paranoid i guess!
+	 */
+	if (unlikely(!cpus_empty(tmp))) {
+		desc->handler->disable(irq);
+		desc->handler->set_affinity(irq,tmp);
+		desc->handler->enable(irq);
+	}
+	cpus_clear(pending_irq_cpumask[irq]);
+}
+
+#endif
