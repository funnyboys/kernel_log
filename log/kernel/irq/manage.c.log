commit baedb87d1b53532f81b4bd0387f83b05d4f7eb9a
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jul 17 18:00:02 2020 +0200

    genirq/affinity: Handle affinity setting on inactive interrupts correctly
    
    Setting interrupt affinity on inactive interrupts is inconsistent when
    hierarchical irq domains are enabled. The core code should just store the
    affinity and not call into the irq chip driver for inactive interrupts
    because the chip drivers may not be in a state to handle such requests.
    
    X86 has a hacky workaround for that but all other irq chips have not which
    causes problems e.g. on GIC V3 ITS.
    
    Instead of adding more ugly hacks all over the place, solve the problem in
    the core code. If the affinity is set on an inactive interrupt then:
    
        - Store it in the irq descriptors affinity mask
        - Update the effective affinity to reflect that so user space has
          a consistent view
        - Don't call into the irq chip driver
    
    This is the core equivalent of the X86 workaround and works correctly
    because the affinity setting is established in the irq chip when the
    interrupt is activated later on.
    
    Note, that this is only effective when hierarchical irq domains are enabled
    by the architecture. Doing it unconditionally would break legacy irq chip
    implementations.
    
    For hierarchial irq domains this works correctly as none of the drivers can
    have a dependency on affinity setting in inactive state by design.
    
    Remove the X86 workaround as it is not longer required.
    
    Fixes: 02edee152d6e ("x86/apic/vector: Ignore set_affinity call for inactive interrupts")
    Reported-by: Ali Saidi <alisaidi@amazon.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Ali Saidi <alisaidi@amazon.com>
    Cc: stable@vger.kernel.org
    Link: https://lore.kernel.org/r/20200529015501.15771-1-alisaidi@amazon.com
    Link: https://lkml.kernel.org/r/877dv2rv25.fsf@nanos.tec.linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 761911168438..2a9fec53e159 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -195,9 +195,9 @@ void irq_set_thread_affinity(struct irq_desc *desc)
 			set_bit(IRQTF_AFFINITY, &action->thread_flags);
 }
 
+#ifdef CONFIG_GENERIC_IRQ_EFFECTIVE_AFF_MASK
 static void irq_validate_effective_affinity(struct irq_data *data)
 {
-#ifdef CONFIG_GENERIC_IRQ_EFFECTIVE_AFF_MASK
 	const struct cpumask *m = irq_data_get_effective_affinity_mask(data);
 	struct irq_chip *chip = irq_data_get_irq_chip(data);
 
@@ -205,9 +205,19 @@ static void irq_validate_effective_affinity(struct irq_data *data)
 		return;
 	pr_warn_once("irq_chip %s did not update eff. affinity mask of irq %u\n",
 		     chip->name, data->irq);
-#endif
 }
 
+static inline void irq_init_effective_affinity(struct irq_data *data,
+					       const struct cpumask *mask)
+{
+	cpumask_copy(irq_data_get_effective_affinity_mask(data), mask);
+}
+#else
+static inline void irq_validate_effective_affinity(struct irq_data *data) { }
+static inline void irq_init_effective_affinity(struct irq_data *data,
+					       const struct cpumask *mask) { }
+#endif
+
 int irq_do_set_affinity(struct irq_data *data, const struct cpumask *mask,
 			bool force)
 {
@@ -304,6 +314,26 @@ static int irq_try_set_affinity(struct irq_data *data,
 	return ret;
 }
 
+static bool irq_set_affinity_deactivated(struct irq_data *data,
+					 const struct cpumask *mask, bool force)
+{
+	struct irq_desc *desc = irq_data_to_desc(data);
+
+	/*
+	 * If the interrupt is not yet activated, just store the affinity
+	 * mask and do not call the chip driver at all. On activation the
+	 * driver has to make sure anyway that the interrupt is in a
+	 * useable state so startup works.
+	 */
+	if (!IS_ENABLED(CONFIG_IRQ_DOMAIN_HIERARCHY) || irqd_is_activated(data))
+		return false;
+
+	cpumask_copy(desc->irq_common_data.affinity, mask);
+	irq_init_effective_affinity(data, mask);
+	irqd_set(data, IRQD_AFFINITY_SET);
+	return true;
+}
+
 int irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask,
 			    bool force)
 {
@@ -314,6 +344,9 @@ int irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask,
 	if (!chip || !chip->irq_set_affinity)
 		return -EINVAL;
 
+	if (irq_set_affinity_deactivated(data, mask, force))
+		return 0;
+
 	if (irq_can_move_pcntxt(data) && !irqd_is_setaffinity_pending(data)) {
 		ret = irq_try_set_affinity(data, mask, force);
 	} else {

commit 1d0326f352bb094771df17f045bdbadff89a43e6
Author: Marek Vasut <marex@denx.de>
Date:   Thu May 14 02:25:55 2020 +0200

    genirq: Check irq_data_get_irq_chip() return value before use
    
    irq_data_get_irq_chip() can return NULL, however it is expected that this
    never happens. If a buggy driver leads to NULL being returned from
    irq_data_get_irq_chip(), warn about it instead of crashing the machine.
    
    Signed-off-by: Marek Vasut <marex@denx.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    
    To: linux-arm-kernel@lists.infradead.org

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 453a8a0f4804..761911168438 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -2619,6 +2619,8 @@ int __irq_get_irqchip_state(struct irq_data *data, enum irqchip_irq_state which,
 
 	do {
 		chip = irq_data_get_irq_chip(data);
+		if (WARN_ON_ONCE(!chip))
+			return -ENODEV;
 		if (chip->irq_get_irqchip_state)
 			break;
 #ifdef CONFIG_IRQ_DOMAIN_HIERARCHY
@@ -2696,6 +2698,8 @@ int irq_set_irqchip_state(unsigned int irq, enum irqchip_irq_state which,
 
 	do {
 		chip = irq_data_get_irq_chip(data);
+		if (WARN_ON_ONCE(!chip))
+			return -ENODEV;
 		if (chip->irq_set_irqchip_state)
 			break;
 #ifdef CONFIG_IRQ_DOMAIN_HIERARCHY

commit 07d8350ede4c4c29634b26c163a1eecdf39dfcfb
Author: afzal mohammed <afzal.mohd.ma@gmail.com>
Date:   Fri Mar 27 21:41:16 2020 +0530

    genirq: Remove setup_irq() and remove_irq()
    
    Now that all the users of setup_irq() & remove_irq() have been replaced by
    request_irq() & free_irq() respectively, delete them.
    
    Signed-off-by: afzal mohammed <afzal.mohd.ma@gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Linus Walleij <linus.walleij@linaro.org>
    Link: https://lkml.kernel.org/r/0aa8771ada1ac8e1312f6882980c9c08bd023148.1585320721.git.afzal.mohd.ma@gmail.com

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index fe40c658f86f..453a8a0f4804 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1690,34 +1690,6 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	return ret;
 }
 
-/**
- *	setup_irq - setup an interrupt
- *	@irq: Interrupt line to setup
- *	@act: irqaction for the interrupt
- *
- * Used to statically setup interrupts in the early boot process.
- */
-int setup_irq(unsigned int irq, struct irqaction *act)
-{
-	int retval;
-	struct irq_desc *desc = irq_to_desc(irq);
-
-	if (!desc || WARN_ON(irq_settings_is_per_cpu_devid(desc)))
-		return -EINVAL;
-
-	retval = irq_chip_pm_get(&desc->irq_data);
-	if (retval < 0)
-		return retval;
-
-	retval = __setup_irq(irq, desc, act);
-
-	if (retval)
-		irq_chip_pm_put(&desc->irq_data);
-
-	return retval;
-}
-EXPORT_SYMBOL_GPL(setup_irq);
-
 /*
  * Internal function to unregister an irqaction - used to free
  * regular and special interrupts that are part of the architecture.
@@ -1858,22 +1830,6 @@ static struct irqaction *__free_irq(struct irq_desc *desc, void *dev_id)
 	return action;
 }
 
-/**
- *	remove_irq - free an interrupt
- *	@irq: Interrupt line to free
- *	@act: irqaction for the interrupt
- *
- * Used to remove interrupts statically setup by the early boot process.
- */
-void remove_irq(unsigned int irq, struct irqaction *act)
-{
-	struct irq_desc *desc = irq_to_desc(irq);
-
-	if (desc && !WARN_ON(irq_settings_is_per_cpu_devid(desc)))
-		__free_irq(desc, act->dev_id);
-}
-EXPORT_SYMBOL_GPL(remove_irq);
-
 /**
  *	free_irq - free an interrupt allocated with request_irq
  *	@irq: Interrupt line to free

commit df81dfcfd6991d547653d46c051bac195cd182c1
Author: Edward Cree <ecree@solarflare.com>
Date:   Fri Mar 13 20:33:07 2020 +0000

    genirq: Fix reference leaks on irq affinity notifiers
    
    The handling of notify->work did not properly maintain notify->kref in two
     cases:
    1) where the work was already scheduled, another irq_set_affinity_locked()
       would get the ref and (no-op-ly) schedule the work.  Thus when
       irq_affinity_notify() ran, it would drop the original ref but not the
       additional one.
    2) when cancelling the (old) work in irq_set_affinity_notifier(), if there
       was outstanding work a ref had been got for it but was never put.
    Fix both by checking the return values of the work handling functions
     (schedule_work() for (1) and cancel_work_sync() for (2)) and put the
     extra ref if the return value indicates preexisting work.
    
    Fixes: cd7eab44e994 ("genirq: Add IRQ affinity notifiers")
    Fixes: 59c39840f5ab ("genirq: Prevent use-after-free and work list corruption")
    Signed-off-by: Edward Cree <ecree@solarflare.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Ben Hutchings <ben@decadent.org.uk>
    Link: https://lkml.kernel.org/r/24f5983f-2ab5-e83a-44ee-a45b5f9300f5@solarflare.com

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 7eee98c38f25..fe40c658f86f 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -323,7 +323,11 @@ int irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask,
 
 	if (desc->affinity_notify) {
 		kref_get(&desc->affinity_notify->kref);
-		schedule_work(&desc->affinity_notify->work);
+		if (!schedule_work(&desc->affinity_notify->work)) {
+			/* Work was already scheduled, drop our extra ref */
+			kref_put(&desc->affinity_notify->kref,
+				 desc->affinity_notify->release);
+		}
 	}
 	irqd_set(data, IRQD_AFFINITY_SET);
 
@@ -423,7 +427,10 @@ irq_set_affinity_notifier(unsigned int irq, struct irq_affinity_notify *notify)
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 
 	if (old_notify) {
-		cancel_work_sync(&old_notify->work);
+		if (cancel_work_sync(&old_notify->work)) {
+			/* Pending work had a ref, put that one too */
+			kref_put(&old_notify->kref, old_notify->release);
+		}
 		kref_put(&old_notify->kref, old_notify->release);
 	}
 

commit cba6437a1854fde5934098ec3bd0ee83af3129f5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Feb 12 12:19:41 2020 +0100

    genirq/proc: Reject invalid affinity masks (again)
    
    Qian Cai reported that the WARN_ON() in the x86/msi affinity setting code,
    which catches cases where the affinity setting is not done on the CPU which
    is the current target of the interrupt, triggers during CPU hotplug stress
    testing.
    
    It turns out that the warning which was added with the commit addressing
    the MSI affinity race unearthed yet another long standing bug.
    
    If user space writes a bogus affinity mask, i.e. it contains no online CPUs,
    then it calls irq_select_affinity_usr(). This was introduced for ALPHA in
    
      eee45269b0f5 ("[PATCH] Alpha: convert to generic irq framework (generic part)")
    
    and subsequently made available for all architectures in
    
      18404756765c ("genirq: Expose default irq affinity mask (take 3)")
    
    which introduced the circumvention of the affinity setting restrictions for
    interrupt which cannot be moved in process context.
    
    The whole exercise is bogus in various aspects:
    
      1) If the interrupt is already started up then there is absolutely
         no point to honour a bogus interrupt affinity setting from user
         space. The interrupt is already assigned to an online CPU and it
         does not make any sense to reassign it to some other randomly
         chosen online CPU.
    
      2) If the interupt is not yet started up then there is no point
         either. A subsequent startup of the interrupt will invoke
         irq_setup_affinity() anyway which will chose a valid target CPU.
    
    So the only correct solution is to just return -EINVAL in case user space
    wrote an affinity mask which does not contain any online CPUs, except for
    ALPHA which has it's own magic sauce for this.
    
    Fixes: 18404756765c ("genirq: Expose default irq affinity mask (take 3)")
    Reported-by: Qian Cai <cai@lca.pw>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Qian Cai <cai@lca.pw>
    Link: https://lkml.kernel.org/r/878sl8xdbm.fsf@nanos.tec.linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 3089a60ea8f9..7eee98c38f25 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -481,23 +481,9 @@ int irq_setup_affinity(struct irq_desc *desc)
 {
 	return irq_select_affinity(irq_desc_get_irq(desc));
 }
-#endif
+#endif /* CONFIG_AUTO_IRQ_AFFINITY */
+#endif /* CONFIG_SMP */
 
-/*
- * Called when a bogus affinity is set via /proc/irq
- */
-int irq_select_affinity_usr(unsigned int irq)
-{
-	struct irq_desc *desc = irq_to_desc(irq);
-	unsigned long flags;
-	int ret;
-
-	raw_spin_lock_irqsave(&desc->lock, flags);
-	ret = irq_setup_affinity(desc);
-	raw_spin_unlock_irqrestore(&desc->lock, flags);
-	return ret;
-}
-#endif
 
 /**
  *	irq_set_vcpu_affinity - Set vcpu affinity for the interrupt

commit f9f21cea311340f38074ff93a8d89b4a9cae6bcc
Author: Stephen Boyd <swboyd@chromium.org>
Date:   Thu Feb 6 11:15:21 2020 -0800

    genirq: Clarify that irq wake state is orthogonal to enable/disable
    
    There's some confusion around if an irq that's disabled with disable_irq()
    can still wake the system from sleep states such as "suspend to RAM".
    
    Clarify this in the kernel documentation for irq_set_irq_wake() so that
    it's clear that an irq can be disabled and still wake the system if it has
    been marked for wakeup.
    
    Signed-off-by: Stephen Boyd <swboyd@chromium.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Douglas Anderson <dianders@chromium.org>
    Link: https://lkml.kernel.org/r/20200206191521.94559-1-swboyd@chromium.org

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 818b2802d3e7..3089a60ea8f9 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -731,6 +731,13 @@ static int set_irq_wake_real(unsigned int irq, unsigned int on)
  *
  *	Wakeup mode lets this IRQ wake the system from sleep
  *	states like "suspend to RAM".
+ *
+ *	Note: irq enable/disable state is completely orthogonal
+ *	to the enable/disable state of irq wake. An irq can be
+ *	disabled with disable_irq() and still wake the system as
+ *	long as the irq has wake enabled. If this does not hold,
+ *	then the underlying irq chip and the related driver need
+ *	to be investigated.
  */
 int irq_set_irq_wake(unsigned int irq, unsigned int on)
 {

commit 11ea68f553e244851d15793a7fa33a97c46d8271
Author: Ming Lei <ming.lei@redhat.com>
Date:   Mon Jan 20 17:16:25 2020 +0800

    genirq, sched/isolation: Isolate from handling managed interrupts
    
    The affinity of managed interrupts is completely handled in the kernel and
    cannot be changed via the /proc/irq/* interfaces from user space. As the
    kernel tries to spread out interrupts evenly accross CPUs on x86 to prevent
    vector exhaustion, it can happen that a managed interrupt whose affinity
    mask contains both isolated and housekeeping CPUs is routed to an isolated
    CPU. As a consequence IO submitted on a housekeeping CPU causes interrupts
    on the isolated CPU.
    
    Add a new sub-parameter 'managed_irq' for 'isolcpus' and the corresponding
    logic in the interrupt affinity selection code.
    
    The subparameter indicates to the interrupt affinity selection logic that
    it should try to avoid the above scenario.
    
    This isolation is best effort and only effective if the automatically
    assigned interrupt mask of a device queue contains isolated and
    housekeeping CPUs. If housekeeping CPUs are online then such interrupts are
    directed to the housekeeping CPU so that IO submitted on the housekeeping
    CPU cannot disturb the isolated CPU.
    
    If a queue's affinity mask contains only isolated CPUs then this parameter
    has no effect on the interrupt routing decision, though interrupts are only
    happening when tasks running on those isolated CPUs submit IO. IO submitted
    on housekeeping CPUs has no influence on those queues.
    
    If the affinity mask contains both housekeeping and isolated CPUs, but none
    of the contained housekeeping CPUs is online, then the interrupt is also
    routed to an isolated CPU. Interrupts are only delivered when one of the
    isolated CPUs in the affinity mask submits IO. If one of the contained
    housekeeping CPUs comes online, the CPU hotplug logic migrates the
    interrupt automatically back to the upcoming housekeeping CPU. Depending on
    the type of interrupt controller, this can require that at least one
    interrupt is delivered to the isolated CPU in order to complete the
    migration.
    
    [ tglx: Removed unused parameter, added and edited comments/documentation
            and rephrased the changelog so it contains more details. ]
    
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20200120091625.17912-1-ming.lei@redhat.com

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index b6c53ab053d2..818b2802d3e7 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -18,6 +18,7 @@
 #include <linux/sched.h>
 #include <linux/sched/rt.h>
 #include <linux/sched/task.h>
+#include <linux/sched/isolation.h>
 #include <uapi/linux/sched/types.h>
 #include <linux/task_work.h>
 
@@ -217,7 +218,45 @@ int irq_do_set_affinity(struct irq_data *data, const struct cpumask *mask,
 	if (!chip || !chip->irq_set_affinity)
 		return -EINVAL;
 
-	ret = chip->irq_set_affinity(data, mask, force);
+	/*
+	 * If this is a managed interrupt and housekeeping is enabled on
+	 * it check whether the requested affinity mask intersects with
+	 * a housekeeping CPU. If so, then remove the isolated CPUs from
+	 * the mask and just keep the housekeeping CPU(s). This prevents
+	 * the affinity setter from routing the interrupt to an isolated
+	 * CPU to avoid that I/O submitted from a housekeeping CPU causes
+	 * interrupts on an isolated one.
+	 *
+	 * If the masks do not intersect or include online CPU(s) then
+	 * keep the requested mask. The isolated target CPUs are only
+	 * receiving interrupts when the I/O operation was submitted
+	 * directly from them.
+	 *
+	 * If all housekeeping CPUs in the affinity mask are offline, the
+	 * interrupt will be migrated by the CPU hotplug code once a
+	 * housekeeping CPU which belongs to the affinity mask comes
+	 * online.
+	 */
+	if (irqd_affinity_is_managed(data) &&
+	    housekeeping_enabled(HK_FLAG_MANAGED_IRQ)) {
+		const struct cpumask *hk_mask, *prog_mask;
+
+		static DEFINE_RAW_SPINLOCK(tmp_mask_lock);
+		static struct cpumask tmp_mask;
+
+		hk_mask = housekeeping_cpumask(HK_FLAG_MANAGED_IRQ);
+
+		raw_spin_lock(&tmp_mask_lock);
+		cpumask_and(&tmp_mask, mask, hk_mask);
+		if (!cpumask_intersects(&tmp_mask, cpu_online_mask))
+			prog_mask = mask;
+		else
+			prog_mask = &tmp_mask;
+		ret = chip->irq_set_affinity(data, prog_mask, force);
+		raw_spin_unlock(&tmp_mask_lock);
+	} else {
+		ret = chip->irq_set_affinity(data, mask, force);
+	}
 	switch (ret) {
 	case IRQ_SET_MASK_OK:
 	case IRQ_SET_MASK_OK_DONE:

commit 025af39b87dc4dc78de4e861ca8b88a1d5ba89f6
Author: Luca Ceresoli <luca@lucaceresoli.net>
Date:   Tue Nov 5 15:08:54 2019 +0100

    genirq: Show irq name in non-oneshot error message
    
    Requesting a threaded IRQ with handler=NULL and !ONESHOT fails, but the
    error message does not include the IRQ line name, which makes it harder to
    find the offending driver.
    
    Print the IRQ line name to clarify where the error comes from. Use the same
    format as the other pr_err() above in the same function.
    
    Signed-off-by: Luca Ceresoli <luca@lucaceresoli.net>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20191105140854.27893-1-luca@lucaceresoli.net

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 1753486b440c..b6c53ab053d2 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1500,8 +1500,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		 * has. The type flags are unreliable as the
 		 * underlying chip implementation can override them.
 		 */
-		pr_err("Threaded irq requested with handler=NULL and !ONESHOT for irq %d\n",
-		       irq);
+		pr_err("Threaded irq requested with handler=NULL and !ONESHOT for %s (irq %d)\n",
+		       new->name, irq);
 		ret = -EINVAL;
 		goto out_unlock;
 	}

commit a572ba63298d04e2c5178e2abd82d6bd6e5677e7
Merge: 258b16ec9a54 9cc5b7fba579
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 17 11:42:15 2019 -0700

    Merge branch 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull core irq updates from Thomas Gleixner:
     "Updates from the irq departement:
    
       - Update the interrupt spreading code so it handles numa node with
         different CPU counts properly.
    
       - A large overhaul of the ARM GiCv3 driver to support new PPI and SPI
         ranges.
    
       - Conversion of all alloc_fwnode() users to use physical addresses
         instead of virtual addresses so the virtual addresses are not
         leaked. The physical address is sufficient to identify the
         associated interrupt chip.
    
       - Add support for Marvel MMP3, Amlogic Meson SM1 interrupt chips.
    
       - Enforce interrupt threading at compile time if RT is enabled.
    
       - Small updates and improvements all over the place"
    
    * 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (37 commits)
      irqchip/gic-v3-its: Fix LPI release for Multi-MSI devices
      irqchip/uniphier-aidet: Use devm_platform_ioremap_resource()
      irqdomain: Add the missing assignment of domain->fwnode for named fwnode
      irqchip/mmp: Coexist with GIC root IRQ controller
      irqchip/mmp: Mask off interrupts from other cores
      irqchip/mmp: Add missing chained_irq_{enter,exit}()
      irqchip/mmp: Do not use of_address_to_resource() to get mux regs
      irqchip/meson-gpio: Add support for meson sm1 SoCs
      dt-bindings: interrupt-controller: New binding for the meson sm1 SoCs
      genirq/affinity: Remove const qualifier from node_to_cpumask argument
      genirq/affinity: Spread vectors on node according to nr_cpu ratio
      genirq/affinity: Improve __irq_build_affinity_masks()
      irqchip: Remove dev_err() usage after platform_get_irq()
      irqchip: Add include guard to irq-partition-percpu.h
      irqchip/mmp: Do not call irq_set_default_host() on DT platforms
      irqchip/gic-v3-its: Remove the redundant set_bit for lpi_map
      irqchip/gic-v3: Add quirks for HIP06/07 invalid GICD_TYPER erratum 161010803
      irqchip/gic: Skip DT quirks when evaluating IIDR-based quirks
      irqchip/gic-v3: Warn about inconsistent implementations of extended ranges
      irqchip/gic-v3: Add EPPI range support
      ...

commit b6a32bbd8735def2d0d696ba59205d1874b7800f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Aug 16 18:09:23 2019 +0200

    genirq: Force interrupt threading on RT
    
    Switch force_irqthreads from a boot time modifiable variable to a compile
    time constant when CONFIG_PREEMPT_RT is enabled.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20190816160923.12855-1-bigeasy@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index e8f7f179bf77..97de1b7d43af 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -23,7 +23,7 @@
 
 #include "internals.h"
 
-#ifdef CONFIG_IRQ_FORCED_THREADING
+#if defined(CONFIG_IRQ_FORCED_THREADING) && !defined(CONFIG_PREEMPT_RT)
 __read_mostly bool force_irqthreads;
 EXPORT_SYMBOL_GPL(force_irqthreads);
 

commit 7b3c92b85a65c2db1f542265bc98e1f9e3056eba
Author: Matthew Wilcox (Oracle) <willy@infradead.org>
Date:   Thu Jul 4 15:13:23 2019 -0700

    sched/core: Convert get_task_struct() to return the task
    
    Returning the pointer that was passed in allows us to write
    slightly more idiomatic code.  Convert a few users.
    
    Signed-off-by: Matthew Wilcox (Oracle) <willy@infradead.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20190704221323.24290-1-willy@infradead.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index e8f7f179bf77..9d50fbe5531a 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1255,8 +1255,7 @@ setup_irq_thread(struct irqaction *new, unsigned int irq, bool secondary)
 	 * the thread dies to avoid that the interrupt code
 	 * references an already freed task_struct.
 	 */
-	get_task_struct(t);
-	new->thread = t;
+	new->thread = get_task_struct(t);
 	/*
 	 * Tell the thread to set its affinity. This is
 	 * important for shared interrupt handlers as we do

commit 0902d5011cfaabd6a09326299ef77e1c8735fb89
Merge: 927ba67a63c7 f8a8fe61fec8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 8 11:22:57 2019 -0700

    Merge branch 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x96 apic updates from Thomas Gleixner:
     "Updates for the x86 APIC interrupt handling and APIC timer:
    
       - Fix a long standing issue with spurious interrupts which was caused
         by the big vector management rework a few years ago. Robert Hodaszi
         provided finally enough debug data and an excellent initial failure
         analysis which allowed to understand the underlying issues.
    
         This contains a change to the core interrupt management code which
         is required to handle this correctly for the APIC/IO_APIC. The core
         changes are NOOPs for most architectures except ARM64. ARM64 is not
         impacted by the change as confirmed by Marc Zyngier.
    
       - Newer systems allow to disable the PIT clock for power saving
         causing panic in the timer interrupt delivery check of the IO/APIC
         when the HPET timer is not enabled either. While the clock could be
         turned on this would cause an endless whack a mole game to chase
         the proper register in each affected chipset.
    
         These systems provide the relevant frequencies for TSC, CPU and the
         local APIC timer via CPUID and/or MSRs, which allows to avoid the
         PIT/HPET based calibration. As the calibration code is the only
         usage of the legacy timers on modern systems and is skipped anyway
         when the frequencies are known already, there is no point in
         setting up the PIT and actually checking for the interrupt delivery
         via IO/APIC.
    
         To achieve this on a wide variety of platforms, the CPUID/MSR based
         frequency readout has been made more robust, which also allowed to
         remove quite some workarounds which turned out to be not longer
         required. Thanks to Daniel Drake for analysis, patches and
         verification"
    
    * 'x86-apic-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/irq: Seperate unused system vectors from spurious entry again
      x86/irq: Handle spurious interrupt after shutdown gracefully
      x86/ioapic: Implement irq_get_irqchip_state() callback
      genirq: Add optional hardware synchronization for shutdown
      genirq: Fix misleading synchronize_irq() documentation
      genirq: Delay deactivation in free_irq()
      x86/timer: Skip PIT initialization on modern chipsets
      x86/apic: Use non-atomic operations when possible
      x86/apic: Make apic_bsp_setup() static
      x86/tsc: Set LAPIC timer period to crystal clock frequency
      x86/apic: Rename 'lapic_timer_frequency' to 'lapic_timer_period'
      x86/tsc: Use CPUID.0x16 to calculate missing crystal frequency

commit 62e0468650c30f0298822c580f382b16328119f6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jun 28 13:11:51 2019 +0200

    genirq: Add optional hardware synchronization for shutdown
    
    free_irq() ensures that no hardware interrupt handler is executing on a
    different CPU before actually releasing resources and deactivating the
    interrupt completely in a domain hierarchy.
    
    But that does not catch the case where the interrupt is on flight at the
    hardware level but not yet serviced by the target CPU. That creates an
    interesing race condition:
    
       CPU 0                  CPU 1               IRQ CHIP
    
                                                  interrupt is raised
                                                  sent to CPU1
                              Unable to handle
                              immediately
                              (interrupts off,
                               deep idle delay)
       mask()
       ...
       free()
         shutdown()
         synchronize_irq()
         release_resources()
                              do_IRQ()
                                -> resources are not available
    
    That might be harmless and just trigger a spurious interrupt warning, but
    some interrupt chips might get into a wedged state.
    
    Utilize the existing irq_get_irqchip_state() callback for the
    synchronization in free_irq().
    
    synchronize_hardirq() is not using this mechanism as it might actually
    deadlock unter certain conditions, e.g. when called with interrupts
    disabled and the target CPU is the one on which the synchronization is
    invoked. synchronize_irq() uses it because that function cannot be called
    from non preemtible contexts as it might sleep.
    
    No functional change intended and according to Marc the existing GIC
    implementations where the driver supports the callback should be able
    to cope with that core change. Famous last words.
    
    Fixes: 464d12309e1b ("x86/vector: Switch IOAPIC to global reservation mode")
    Reported-by: Robert Hodaszi <Robert.Hodaszi@digi.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Tested-by: Marc Zyngier <marc.zyngier@arm.com>
    Link: https://lkml.kernel.org/r/20190628111440.279463375@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 44fc505815d6..fad61986f35c 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -35,8 +35,9 @@ static int __init setup_forced_irqthreads(char *arg)
 early_param("threadirqs", setup_forced_irqthreads);
 #endif
 
-static void __synchronize_hardirq(struct irq_desc *desc)
+static void __synchronize_hardirq(struct irq_desc *desc, bool sync_chip)
 {
+	struct irq_data *irqd = irq_desc_get_irq_data(desc);
 	bool inprogress;
 
 	do {
@@ -52,6 +53,20 @@ static void __synchronize_hardirq(struct irq_desc *desc)
 		/* Ok, that indicated we're done: double-check carefully. */
 		raw_spin_lock_irqsave(&desc->lock, flags);
 		inprogress = irqd_irq_inprogress(&desc->irq_data);
+
+		/*
+		 * If requested and supported, check at the chip whether it
+		 * is in flight at the hardware level, i.e. already pending
+		 * in a CPU and waiting for service and acknowledge.
+		 */
+		if (!inprogress && sync_chip) {
+			/*
+			 * Ignore the return code. inprogress is only updated
+			 * when the chip supports it.
+			 */
+			__irq_get_irqchip_state(irqd, IRQCHIP_STATE_ACTIVE,
+						&inprogress);
+		}
 		raw_spin_unlock_irqrestore(&desc->lock, flags);
 
 		/* Oops, that failed? */
@@ -74,13 +89,18 @@ static void __synchronize_hardirq(struct irq_desc *desc)
  *	Returns: false if a threaded handler is active.
  *
  *	This function may be called - with care - from IRQ context.
+ *
+ *	It does not check whether there is an interrupt in flight at the
+ *	hardware level, but not serviced yet, as this might deadlock when
+ *	called with interrupts disabled and the target CPU of the interrupt
+ *	is the current CPU.
  */
 bool synchronize_hardirq(unsigned int irq)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 
 	if (desc) {
-		__synchronize_hardirq(desc);
+		__synchronize_hardirq(desc, false);
 		return !atomic_read(&desc->threads_active);
 	}
 
@@ -98,13 +118,17 @@ EXPORT_SYMBOL(synchronize_hardirq);
  *
  *	Can only be called from preemptible code as it might sleep when
  *	an interrupt thread is associated to @irq.
+ *
+ *	It optionally makes sure (when the irq chip supports that method)
+ *	that the interrupt is not pending in any CPU and waiting for
+ *	service.
  */
 void synchronize_irq(unsigned int irq)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 
 	if (desc) {
-		__synchronize_hardirq(desc);
+		__synchronize_hardirq(desc, true);
 		/*
 		 * We made sure that no hardirq handler is
 		 * running. Now verify that no threaded handlers are
@@ -1730,8 +1754,12 @@ static struct irqaction *__free_irq(struct irq_desc *desc, void *dev_id)
 
 	unregister_handler_proc(irq, action);
 
-	/* Make sure it's not being used on another CPU: */
-	synchronize_hardirq(irq);
+	/*
+	 * Make sure it's not being used on another CPU and if the chip
+	 * supports it also make sure that there is no (not yet serviced)
+	 * interrupt in flight at the hardware level.
+	 */
+	__synchronize_hardirq(desc, true);
 
 #ifdef CONFIG_DEBUG_SHIRQ
 	/*
@@ -2589,6 +2617,28 @@ void teardown_percpu_nmi(unsigned int irq)
 	irq_put_desc_unlock(desc, flags);
 }
 
+int __irq_get_irqchip_state(struct irq_data *data, enum irqchip_irq_state which,
+			    bool *state)
+{
+	struct irq_chip *chip;
+	int err = -EINVAL;
+
+	do {
+		chip = irq_data_get_irq_chip(data);
+		if (chip->irq_get_irqchip_state)
+			break;
+#ifdef CONFIG_IRQ_DOMAIN_HIERARCHY
+		data = data->parent_data;
+#else
+		data = NULL;
+#endif
+	} while (data);
+
+	if (data)
+		err = chip->irq_get_irqchip_state(data, which, state);
+	return err;
+}
+
 /**
  *	irq_get_irqchip_state - returns the irqchip state of a interrupt.
  *	@irq: Interrupt line that is forwarded to a VM
@@ -2607,7 +2657,6 @@ int irq_get_irqchip_state(unsigned int irq, enum irqchip_irq_state which,
 {
 	struct irq_desc *desc;
 	struct irq_data *data;
-	struct irq_chip *chip;
 	unsigned long flags;
 	int err = -EINVAL;
 
@@ -2617,19 +2666,7 @@ int irq_get_irqchip_state(unsigned int irq, enum irqchip_irq_state which,
 
 	data = irq_desc_get_irq_data(desc);
 
-	do {
-		chip = irq_data_get_irq_chip(data);
-		if (chip->irq_get_irqchip_state)
-			break;
-#ifdef CONFIG_IRQ_DOMAIN_HIERARCHY
-		data = data->parent_data;
-#else
-		data = NULL;
-#endif
-	} while (data);
-
-	if (data)
-		err = chip->irq_get_irqchip_state(data, which, state);
+	err = __irq_get_irqchip_state(data, which, state);
 
 	irq_put_desc_busunlock(desc, flags);
 	return err;

commit 1d21f2af8571c6a6a44e7c1911780614847b0253
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jun 28 13:11:50 2019 +0200

    genirq: Fix misleading synchronize_irq() documentation
    
    The function might sleep, so it cannot be called from interrupt
    context. Not even with care.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Link: https://lkml.kernel.org/r/20190628111440.189241552@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index dc8b35f2d545..44fc505815d6 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -96,7 +96,8 @@ EXPORT_SYMBOL(synchronize_hardirq);
  *	to complete before returning. If you use this function while
  *	holding a resource the IRQ handler may need you will deadlock.
  *
- *	This function may be called - with care - from IRQ context.
+ *	Can only be called from preemptible code as it might sleep when
+ *	an interrupt thread is associated to @irq.
  */
 void synchronize_irq(unsigned int irq)
 {

commit 4001d8e8762f57d418b66e4e668601791900a1dd
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jun 28 13:11:49 2019 +0200

    genirq: Delay deactivation in free_irq()
    
    When interrupts are shutdown, they are immediately deactivated in the
    irqdomain hierarchy. While this looks obviously correct there is a subtle
    issue:
    
    There might be an interrupt in flight when free_irq() is invoking the
    shutdown. This is properly handled at the irq descriptor / primary handler
    level, but the deactivation might completely disable resources which are
    required to acknowledge the interrupt.
    
    Split the shutdown code and deactivate the interrupt after synchronization
    in free_irq(). Fixup all other usage sites where this is not an issue to
    invoke the combined shutdown_and_deactivate() function instead.
    
    This still might be an issue if the interrupt in flight servicing is
    delayed on a remote CPU beyond the invocation of synchronize_irq(), but
    that cannot be handled at that level and needs to be handled in the
    synchronize_irq() context.
    
    Fixes: f8264e34965a ("irqdomain: Introduce new interfaces to support hierarchy irqdomains")
    Reported-by: Robert Hodaszi <Robert.Hodaszi@digi.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Link: https://lkml.kernel.org/r/20190628111440.098196390@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 53a081392115..dc8b35f2d545 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -13,6 +13,7 @@
 #include <linux/module.h>
 #include <linux/random.h>
 #include <linux/interrupt.h>
+#include <linux/irqdomain.h>
 #include <linux/slab.h>
 #include <linux/sched.h>
 #include <linux/sched/rt.h>
@@ -1699,6 +1700,7 @@ static struct irqaction *__free_irq(struct irq_desc *desc, void *dev_id)
 	/* If this was the last handler, shut down the IRQ line: */
 	if (!desc->action) {
 		irq_settings_clr_disable_unlazy(desc);
+		/* Only shutdown. Deactivate after synchronize_hardirq() */
 		irq_shutdown(desc);
 	}
 
@@ -1768,6 +1770,14 @@ static struct irqaction *__free_irq(struct irq_desc *desc, void *dev_id)
 		 * require it to deallocate resources over the slow bus.
 		 */
 		chip_bus_lock(desc);
+		/*
+		 * There is no interrupt on the fly anymore. Deactivate it
+		 * completely.
+		 */
+		raw_spin_lock_irqsave(&desc->lock, flags);
+		irq_domain_deactivate_irq(&desc->irq_data);
+		raw_spin_unlock_irqrestore(&desc->lock, flags);
+
 		irq_release_resources(desc);
 		chip_bus_sync_unlock(desc);
 		irq_remove_timings(desc);
@@ -1855,7 +1865,7 @@ static const void *__cleanup_nmi(unsigned int irq, struct irq_desc *desc)
 	}
 
 	irq_settings_clr_disable_unlazy(desc);
-	irq_shutdown(desc);
+	irq_shutdown_and_deactivate(desc);
 
 	irq_release_resources(desc);
 

commit 0968621917add2e0d60c8fbc4e24c670cb14319c
Merge: 573de2a6e844 0f46c78391e1
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue May 7 09:18:12 2019 -0700

    Merge tag 'printk-for-5.2' of git://git.kernel.org/pub/scm/linux/kernel/git/pmladek/printk
    
    Pull printk updates from Petr Mladek:
    
     - Allow state reset of printk_once() calls.
    
     - Prevent crashes when dereferencing invalid pointers in vsprintf().
       Only the first byte is checked for simplicity.
    
     - Make vsprintf warnings consistent and inlined.
    
     - Treewide conversion of obsolete %pf, %pF to %ps, %pF printf
       modifiers.
    
     - Some clean up of vsprintf and test_printf code.
    
    * tag 'printk-for-5.2' of git://git.kernel.org/pub/scm/linux/kernel/git/pmladek/printk:
      lib/vsprintf: Make function pointer_string static
      vsprintf: Limit the length of inlined error messages
      vsprintf: Avoid confusion between invalid address and value
      vsprintf: Prevent crash when dereferencing invalid pointers
      vsprintf: Consolidate handling of unknown pointer specifiers
      vsprintf: Factor out %pO handler as kobject_string()
      vsprintf: Factor out %pV handler as va_format()
      vsprintf: Factor out %p[iI] handler as ip_addr_string()
      vsprintf: Do not check address of well-known strings
      vsprintf: Consistent %pK handling for kptr_restrict == 0
      vsprintf: Shuffle restricted_pointer()
      printk: Tie printk_once / printk_deferred_once into .data.once for reset
      treewide: Switch printk users from %pf and %pF to %ps and %pS, respectively
      lib/test_printf: Switch to bitmap_zalloc()

commit d75f773c86a2b8b7278e2c33343b46a4024bc002
Author: Sakari Ailus <sakari.ailus@linux.intel.com>
Date:   Mon Mar 25 21:32:28 2019 +0200

    treewide: Switch printk users from %pf and %pF to %ps and %pS, respectively
    
    %pF and %pf are functionally equivalent to %pS and %ps conversion
    specifiers. The former are deprecated, therefore switch the current users
    to use the preferred variant.
    
    The changes have been produced by the following command:
    
            git grep -l '%p[fF]' | grep -v '^\(tools\|Documentation\)/' | \
            while read i; do perl -i -pe 's/%pf/%ps/g; s/%pF/%pS/g;' $i; done
    
    And verifying the result.
    
    Link: http://lkml.kernel.org/r/20190325193229.23390-1-sakari.ailus@linux.intel.com
    Cc: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: sparclinux@vger.kernel.org
    Cc: linux-um@lists.infradead.org
    Cc: xen-devel@lists.xenproject.org
    Cc: linux-acpi@vger.kernel.org
    Cc: linux-pm@vger.kernel.org
    Cc: drbd-dev@lists.linbit.com
    Cc: linux-block@vger.kernel.org
    Cc: linux-mmc@vger.kernel.org
    Cc: linux-nvdimm@lists.01.org
    Cc: linux-pci@vger.kernel.org
    Cc: linux-scsi@vger.kernel.org
    Cc: linux-btrfs@vger.kernel.org
    Cc: linux-f2fs-devel@lists.sourceforge.net
    Cc: linux-mm@kvack.org
    Cc: ceph-devel@vger.kernel.org
    Cc: netdev@vger.kernel.org
    Signed-off-by: Sakari Ailus <sakari.ailus@linux.intel.com>
    Acked-by: David Sterba <dsterba@suse.com> (for btrfs)
    Acked-by: Mike Rapoport <rppt@linux.ibm.com> (for mm/memblock.c)
    Acked-by: Bjorn Helgaas <bhelgaas@google.com> (for drivers/pci)
    Acked-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Petr Mladek <pmladek@suse.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 9ec34a2a6638..ec43ab2fdfda 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -778,7 +778,7 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned long flags)
 		ret = 0;
 		break;
 	default:
-		pr_err("Setting trigger mode %lu for irq %u failed (%pF)\n",
+		pr_err("Setting trigger mode %lu for irq %u failed (%pS)\n",
 		       flags, irq_desc_get_irq(desc), chip->irq_set_type);
 	}
 	if (unmask)

commit 59c39840f5abf4a71e1810a8da71aaccd6c17d26
Author: Prasad Sodagudi <psodagud@codeaurora.org>
Date:   Sun Mar 24 07:57:04 2019 -0700

    genirq: Prevent use-after-free and work list corruption
    
    When irq_set_affinity_notifier() replaces the notifier, then the
    reference count on the old notifier is dropped which causes it to be
    freed. But nothing ensures that the old notifier is not longer queued
    in the work list. If it is queued this results in a use after free and
    possibly in work list corruption.
    
    Ensure that the work is canceled before the reference is dropped.
    
    Signed-off-by: Prasad Sodagudi <psodagud@codeaurora.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: marc.zyngier@arm.com
    Link: https://lkml.kernel.org/r/1553439424-6529-1-git-send-email-psodagud@codeaurora.org

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 1401afa0d58a..53a081392115 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -357,8 +357,10 @@ irq_set_affinity_notifier(unsigned int irq, struct irq_affinity_notify *notify)
 	desc->affinity_notify = notify;
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 
-	if (old_notify)
+	if (old_notify) {
+		cancel_work_sync(&old_notify->work);
 		kref_put(&old_notify->kref, old_notify->release);
+	}
 
 	return 0;
 }

commit 93417a3fda2060f2a34e3341904024c5b6980d1f
Author: Gustavo A. R. Silva <gustavo@embeddedor.com>
Date:   Thu Feb 28 15:37:14 2019 -0600

    genirq: Mark expected switch case fall-through
    
    In preparation to enabling -Wimplicit-fallthrough, mark switch
    cases where we are expecting to fall through.
    
    With -Wimplicit-fallthrough added to CFLAGS:
    
     kernel/irq/manage.c: In function ‘irq_do_set_affinity’:
     kernel/irq/manage.c:198:3: warning: this statement may fall through [-Wimplicit-fallthrough=]
       cpumask_copy(desc->irq_common_data.affinity, mask);
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     kernel/irq/manage.c:199:2: note: here
       case IRQ_SET_MASK_OK_NOCOPY:
       ^~~~
    
    Annotate it.
    
    Signed-off-by: Gustavo A. R. Silva <gustavo@embeddedor.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Kees Cook <keescook@chromium.org>
    Link: https://lkml.kernel.org/r/20190228213714.GA9246@embeddedor

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 9ec34a2a6638..1401afa0d58a 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -196,6 +196,7 @@ int irq_do_set_affinity(struct irq_data *data, const struct cpumask *mask,
 	case IRQ_SET_MASK_OK:
 	case IRQ_SET_MASK_OK_DONE:
 		cpumask_copy(desc->irq_common_data.affinity, mask);
+		/* fall through */
 	case IRQ_SET_MASK_OK_NOCOPY:
 		irq_validate_effective_affinity(data);
 		irq_set_thread_affinity(desc);

commit a324ca9cad4736252c33c1e28cffe1d87f262d03
Merge: 4e6b26d23dc1 28528fca4908
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Feb 23 10:53:31 2019 +0100

    Merge tag 'irqchip-5.1' of git://git.kernel.org/pub/scm/linux/kernel/git/maz/arm-platforms into irq/core
    
    Pull irqchip updates from Marc Zyngier
    
    - Core pseudo-NMI handling code
    - Allow the default irq domain to be retrieved
    - A new interrupt controller for the Loongson LS1X platform
    - Affinity support for the SiFive PLIC
    - Better support for the iMX irqsteer driver
    - NUMA aware memory allocations for GICv3
    - A handful of other fixes (i8259, GICv3, PLIC)

commit d869f86645fc07dc83b89b68f1a22d91ebe29439
Merge: 030fc443aef6 74e96711e337
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Feb 14 22:26:50 2019 +0100

    Merge branch 'linus' into irq/core
    
    Pick up upstream changes to avoid conflicts for pending patches.

commit a51866946c0aa0b04a554595d38b496e80c76a1b
Author: Julien Thierry <julien.thierry@arm.com>
Date:   Wed Feb 13 10:09:19 2019 +0000

    genirq: Fix wrong name in request_percpu_nmi() description
    
    ready_percpu_nmi() was the previous name of prepare_percpu_nmi(). Update
    request_percpu_nmi() comment with the correct function name.
    
    Signed-off-by: Julien Thierry <julien.thierry@arm.com>
    Reported-by: Li Wei <liwei391@huawei.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0a1ebc004a59..5b570050b9b6 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -2427,8 +2427,8 @@ EXPORT_SYMBOL_GPL(__request_percpu_irq);
  *	@dev_id: A percpu cookie passed back to the handler function
  *
  *	This call allocates interrupt resources for a per CPU NMI. Per CPU NMIs
- *	have to be setup on each CPU by calling ready_percpu_nmi() before being
- *	enabled on the same CPU by using enable_percpu_nmi().
+ *	have to be setup on each CPU by calling prepare_percpu_nmi() before
+ *	being enabled on the same CPU by using enable_percpu_nmi().
  *
  *	Dev_id must be globally unique. It is a per-cpu variable, and
  *	the handler gets called with the interrupted CPU's instance of

commit 4b078c3f1a26487c39363089ba0d5c6b09f2a89f
Author: Julien Thierry <julien.thierry@arm.com>
Date:   Thu Jan 31 14:53:59 2019 +0000

    genirq: Provide NMI management for percpu_devid interrupts
    
    Add support for percpu_devid interrupts treated as NMIs.
    
    Percpu_devid NMIs need to be setup/torn down on each CPU they target.
    
    The same restrictions as for global NMIs still apply for percpu_devid NMIs.
    
    Signed-off-by: Julien Thierry <julien.thierry@arm.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 9472ae987946..0a1ebc004a59 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -2182,6 +2182,11 @@ void enable_percpu_irq(unsigned int irq, unsigned int type)
 }
 EXPORT_SYMBOL_GPL(enable_percpu_irq);
 
+void enable_percpu_nmi(unsigned int irq, unsigned int type)
+{
+	enable_percpu_irq(irq, type);
+}
+
 /**
  * irq_percpu_is_enabled - Check whether the per cpu irq is enabled
  * @irq:	Linux irq number to check for
@@ -2221,6 +2226,11 @@ void disable_percpu_irq(unsigned int irq)
 }
 EXPORT_SYMBOL_GPL(disable_percpu_irq);
 
+void disable_percpu_nmi(unsigned int irq)
+{
+	disable_percpu_irq(irq);
+}
+
 /*
  * Internal function to unregister a percpu irqaction.
  */
@@ -2252,6 +2262,8 @@ static struct irqaction *__free_percpu_irq(unsigned int irq, void __percpu *dev_
 	/* Found it - now remove it from the list of entries: */
 	desc->action = NULL;
 
+	desc->istate &= ~IRQS_NMI;
+
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 
 	unregister_handler_proc(irq, action);
@@ -2305,6 +2317,19 @@ void free_percpu_irq(unsigned int irq, void __percpu *dev_id)
 }
 EXPORT_SYMBOL_GPL(free_percpu_irq);
 
+void free_percpu_nmi(unsigned int irq, void __percpu *dev_id)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+
+	if (!desc || !irq_settings_is_per_cpu_devid(desc))
+		return;
+
+	if (WARN_ON(!(desc->istate & IRQS_NMI)))
+		return;
+
+	kfree(__free_percpu_irq(irq, dev_id));
+}
+
 /**
  *	setup_percpu_irq - setup a per-cpu interrupt
  *	@irq: Interrupt line to setup
@@ -2394,6 +2419,158 @@ int __request_percpu_irq(unsigned int irq, irq_handler_t handler,
 }
 EXPORT_SYMBOL_GPL(__request_percpu_irq);
 
+/**
+ *	request_percpu_nmi - allocate a percpu interrupt line for NMI delivery
+ *	@irq: Interrupt line to allocate
+ *	@handler: Function to be called when the IRQ occurs.
+ *	@name: An ascii name for the claiming device
+ *	@dev_id: A percpu cookie passed back to the handler function
+ *
+ *	This call allocates interrupt resources for a per CPU NMI. Per CPU NMIs
+ *	have to be setup on each CPU by calling ready_percpu_nmi() before being
+ *	enabled on the same CPU by using enable_percpu_nmi().
+ *
+ *	Dev_id must be globally unique. It is a per-cpu variable, and
+ *	the handler gets called with the interrupted CPU's instance of
+ *	that variable.
+ *
+ *	Interrupt lines requested for NMI delivering should have auto enabling
+ *	setting disabled.
+ *
+ *	If the interrupt line cannot be used to deliver NMIs, function
+ *	will fail returning a negative value.
+ */
+int request_percpu_nmi(unsigned int irq, irq_handler_t handler,
+		       const char *name, void __percpu *dev_id)
+{
+	struct irqaction *action;
+	struct irq_desc *desc;
+	unsigned long flags;
+	int retval;
+
+	if (!handler)
+		return -EINVAL;
+
+	desc = irq_to_desc(irq);
+
+	if (!desc || !irq_settings_can_request(desc) ||
+	    !irq_settings_is_per_cpu_devid(desc) ||
+	    irq_settings_can_autoenable(desc) ||
+	    !irq_supports_nmi(desc))
+		return -EINVAL;
+
+	/* The line cannot already be NMI */
+	if (desc->istate & IRQS_NMI)
+		return -EINVAL;
+
+	action = kzalloc(sizeof(struct irqaction), GFP_KERNEL);
+	if (!action)
+		return -ENOMEM;
+
+	action->handler = handler;
+	action->flags = IRQF_PERCPU | IRQF_NO_SUSPEND | IRQF_NO_THREAD
+		| IRQF_NOBALANCING;
+	action->name = name;
+	action->percpu_dev_id = dev_id;
+
+	retval = irq_chip_pm_get(&desc->irq_data);
+	if (retval < 0)
+		goto err_out;
+
+	retval = __setup_irq(irq, desc, action);
+	if (retval)
+		goto err_irq_setup;
+
+	raw_spin_lock_irqsave(&desc->lock, flags);
+	desc->istate |= IRQS_NMI;
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
+
+	return 0;
+
+err_irq_setup:
+	irq_chip_pm_put(&desc->irq_data);
+err_out:
+	kfree(action);
+
+	return retval;
+}
+
+/**
+ *	prepare_percpu_nmi - performs CPU local setup for NMI delivery
+ *	@irq: Interrupt line to prepare for NMI delivery
+ *
+ *	This call prepares an interrupt line to deliver NMI on the current CPU,
+ *	before that interrupt line gets enabled with enable_percpu_nmi().
+ *
+ *	As a CPU local operation, this should be called from non-preemptible
+ *	context.
+ *
+ *	If the interrupt line cannot be used to deliver NMIs, function
+ *	will fail returning a negative value.
+ */
+int prepare_percpu_nmi(unsigned int irq)
+{
+	unsigned long flags;
+	struct irq_desc *desc;
+	int ret = 0;
+
+	WARN_ON(preemptible());
+
+	desc = irq_get_desc_lock(irq, &flags,
+				 IRQ_GET_DESC_CHECK_PERCPU);
+	if (!desc)
+		return -EINVAL;
+
+	if (WARN(!(desc->istate & IRQS_NMI),
+		 KERN_ERR "prepare_percpu_nmi called for a non-NMI interrupt: irq %u\n",
+		 irq)) {
+		ret = -EINVAL;
+		goto out;
+	}
+
+	ret = irq_nmi_setup(desc);
+	if (ret) {
+		pr_err("Failed to setup NMI delivery: irq %u\n", irq);
+		goto out;
+	}
+
+out:
+	irq_put_desc_unlock(desc, flags);
+	return ret;
+}
+
+/**
+ *	teardown_percpu_nmi - undoes NMI setup of IRQ line
+ *	@irq: Interrupt line from which CPU local NMI configuration should be
+ *	      removed
+ *
+ *	This call undoes the setup done by prepare_percpu_nmi().
+ *
+ *	IRQ line should not be enabled for the current CPU.
+ *
+ *	As a CPU local operation, this should be called from non-preemptible
+ *	context.
+ */
+void teardown_percpu_nmi(unsigned int irq)
+{
+	unsigned long flags;
+	struct irq_desc *desc;
+
+	WARN_ON(preemptible());
+
+	desc = irq_get_desc_lock(irq, &flags,
+				 IRQ_GET_DESC_CHECK_PERCPU);
+	if (!desc)
+		return;
+
+	if (WARN_ON(!(desc->istate & IRQS_NMI)))
+		goto out;
+
+	irq_nmi_teardown(desc);
+out:
+	irq_put_desc_unlock(desc, flags);
+}
+
 /**
  *	irq_get_irqchip_state - returns the irqchip state of a interrupt.
  *	@irq: Interrupt line that is forwarded to a VM

commit b525903c254dab2491410f0f23707691b7c2c317
Author: Julien Thierry <julien.thierry@arm.com>
Date:   Thu Jan 31 14:53:58 2019 +0000

    genirq: Provide basic NMI management for interrupt lines
    
    Add functionality to allocate interrupt lines that will deliver IRQs
    as Non-Maskable Interrupts. These allocations are only successful if
    the irqchip provides the necessary support and allows NMI delivery for the
    interrupt line.
    
    Interrupt lines allocated for NMI delivery must be enabled/disabled through
    enable_nmi/disable_nmi_nosync to keep their state consistent.
    
    To treat a PERCPU IRQ as NMI, the interrupt must not be shared nor threaded,
    the irqchip directly managing the IRQ must be the root irqchip and the
    irqchip cannot be behind a slow bus.
    
    Signed-off-by: Julien Thierry <julien.thierry@arm.com>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index a4888ce4667a..9472ae987946 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -341,7 +341,7 @@ irq_set_affinity_notifier(unsigned int irq, struct irq_affinity_notify *notify)
 	/* The release function is promised process context */
 	might_sleep();
 
-	if (!desc)
+	if (!desc || desc->istate & IRQS_NMI)
 		return -EINVAL;
 
 	/* Complete initialisation of *notify */
@@ -550,6 +550,21 @@ bool disable_hardirq(unsigned int irq)
 }
 EXPORT_SYMBOL_GPL(disable_hardirq);
 
+/**
+ *	disable_nmi_nosync - disable an nmi without waiting
+ *	@irq: Interrupt to disable
+ *
+ *	Disable the selected interrupt line. Disables and enables are
+ *	nested.
+ *	The interrupt to disable must have been requested through request_nmi.
+ *	Unlike disable_nmi(), this function does not ensure existing
+ *	instances of the IRQ handler have completed before returning.
+ */
+void disable_nmi_nosync(unsigned int irq)
+{
+	disable_irq_nosync(irq);
+}
+
 void __enable_irq(struct irq_desc *desc)
 {
 	switch (desc->depth) {
@@ -606,6 +621,20 @@ void enable_irq(unsigned int irq)
 }
 EXPORT_SYMBOL(enable_irq);
 
+/**
+ *	enable_nmi - enable handling of an nmi
+ *	@irq: Interrupt to enable
+ *
+ *	The interrupt to enable must have been requested through request_nmi.
+ *	Undoes the effect of one call to disable_nmi(). If this
+ *	matches the last disable, processing of interrupts on this
+ *	IRQ line is re-enabled.
+ */
+void enable_nmi(unsigned int irq)
+{
+	enable_irq(irq);
+}
+
 static int set_irq_wake_real(unsigned int irq, unsigned int on)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
@@ -641,6 +670,12 @@ int irq_set_irq_wake(unsigned int irq, unsigned int on)
 	if (!desc)
 		return -EINVAL;
 
+	/* Don't use NMIs as wake up interrupts please */
+	if (desc->istate & IRQS_NMI) {
+		ret = -EINVAL;
+		goto out_unlock;
+	}
+
 	/* wakeup-capable irqs can be shared between drivers that
 	 * don't need to have the same sleep mode behaviors.
 	 */
@@ -663,6 +698,8 @@ int irq_set_irq_wake(unsigned int irq, unsigned int on)
 				irqd_clear(&desc->irq_data, IRQD_WAKEUP_STATE);
 		}
 	}
+
+out_unlock:
 	irq_put_desc_busunlock(desc, flags);
 	return ret;
 }
@@ -1125,6 +1162,39 @@ static void irq_release_resources(struct irq_desc *desc)
 		c->irq_release_resources(d);
 }
 
+static bool irq_supports_nmi(struct irq_desc *desc)
+{
+	struct irq_data *d = irq_desc_get_irq_data(desc);
+
+#ifdef CONFIG_IRQ_DOMAIN_HIERARCHY
+	/* Only IRQs directly managed by the root irqchip can be set as NMI */
+	if (d->parent_data)
+		return false;
+#endif
+	/* Don't support NMIs for chips behind a slow bus */
+	if (d->chip->irq_bus_lock || d->chip->irq_bus_sync_unlock)
+		return false;
+
+	return d->chip->flags & IRQCHIP_SUPPORTS_NMI;
+}
+
+static int irq_nmi_setup(struct irq_desc *desc)
+{
+	struct irq_data *d = irq_desc_get_irq_data(desc);
+	struct irq_chip *c = d->chip;
+
+	return c->irq_nmi_setup ? c->irq_nmi_setup(d) : -EINVAL;
+}
+
+static void irq_nmi_teardown(struct irq_desc *desc)
+{
+	struct irq_data *d = irq_desc_get_irq_data(desc);
+	struct irq_chip *c = d->chip;
+
+	if (c->irq_nmi_teardown)
+		c->irq_nmi_teardown(d);
+}
+
 static int
 setup_irq_thread(struct irqaction *new, unsigned int irq, bool secondary)
 {
@@ -1299,9 +1369,17 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		 * fields must have IRQF_SHARED set and the bits which
 		 * set the trigger type must match. Also all must
 		 * agree on ONESHOT.
+		 * Interrupt lines used for NMIs cannot be shared.
 		 */
 		unsigned int oldtype;
 
+		if (desc->istate & IRQS_NMI) {
+			pr_err("Invalid attempt to share NMI for %s (irq %d) on irqchip %s.\n",
+				new->name, irq, desc->irq_data.chip->name);
+			ret = -EINVAL;
+			goto out_unlock;
+		}
+
 		/*
 		 * If nobody did set the configuration before, inherit
 		 * the one provided by the requester.
@@ -1753,6 +1831,59 @@ const void *free_irq(unsigned int irq, void *dev_id)
 }
 EXPORT_SYMBOL(free_irq);
 
+/* This function must be called with desc->lock held */
+static const void *__cleanup_nmi(unsigned int irq, struct irq_desc *desc)
+{
+	const char *devname = NULL;
+
+	desc->istate &= ~IRQS_NMI;
+
+	if (!WARN_ON(desc->action == NULL)) {
+		irq_pm_remove_action(desc, desc->action);
+		devname = desc->action->name;
+		unregister_handler_proc(irq, desc->action);
+
+		kfree(desc->action);
+		desc->action = NULL;
+	}
+
+	irq_settings_clr_disable_unlazy(desc);
+	irq_shutdown(desc);
+
+	irq_release_resources(desc);
+
+	irq_chip_pm_put(&desc->irq_data);
+	module_put(desc->owner);
+
+	return devname;
+}
+
+const void *free_nmi(unsigned int irq, void *dev_id)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+	unsigned long flags;
+	const void *devname;
+
+	if (!desc || WARN_ON(!(desc->istate & IRQS_NMI)))
+		return NULL;
+
+	if (WARN_ON(irq_settings_is_per_cpu_devid(desc)))
+		return NULL;
+
+	/* NMI still enabled */
+	if (WARN_ON(desc->depth == 0))
+		disable_nmi_nosync(irq);
+
+	raw_spin_lock_irqsave(&desc->lock, flags);
+
+	irq_nmi_teardown(desc);
+	devname = __cleanup_nmi(irq, desc);
+
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
+
+	return devname;
+}
+
 /**
  *	request_threaded_irq - allocate an interrupt line
  *	@irq: Interrupt line to allocate
@@ -1922,6 +2053,101 @@ int request_any_context_irq(unsigned int irq, irq_handler_t handler,
 }
 EXPORT_SYMBOL_GPL(request_any_context_irq);
 
+/**
+ *	request_nmi - allocate an interrupt line for NMI delivery
+ *	@irq: Interrupt line to allocate
+ *	@handler: Function to be called when the IRQ occurs.
+ *		  Threaded handler for threaded interrupts.
+ *	@irqflags: Interrupt type flags
+ *	@name: An ascii name for the claiming device
+ *	@dev_id: A cookie passed back to the handler function
+ *
+ *	This call allocates interrupt resources and enables the
+ *	interrupt line and IRQ handling. It sets up the IRQ line
+ *	to be handled as an NMI.
+ *
+ *	An interrupt line delivering NMIs cannot be shared and IRQ handling
+ *	cannot be threaded.
+ *
+ *	Interrupt lines requested for NMI delivering must produce per cpu
+ *	interrupts and have auto enabling setting disabled.
+ *
+ *	Dev_id must be globally unique. Normally the address of the
+ *	device data structure is used as the cookie. Since the handler
+ *	receives this value it makes sense to use it.
+ *
+ *	If the interrupt line cannot be used to deliver NMIs, function
+ *	will fail and return a negative value.
+ */
+int request_nmi(unsigned int irq, irq_handler_t handler,
+		unsigned long irqflags, const char *name, void *dev_id)
+{
+	struct irqaction *action;
+	struct irq_desc *desc;
+	unsigned long flags;
+	int retval;
+
+	if (irq == IRQ_NOTCONNECTED)
+		return -ENOTCONN;
+
+	/* NMI cannot be shared, used for Polling */
+	if (irqflags & (IRQF_SHARED | IRQF_COND_SUSPEND | IRQF_IRQPOLL))
+		return -EINVAL;
+
+	if (!(irqflags & IRQF_PERCPU))
+		return -EINVAL;
+
+	if (!handler)
+		return -EINVAL;
+
+	desc = irq_to_desc(irq);
+
+	if (!desc || irq_settings_can_autoenable(desc) ||
+	    !irq_settings_can_request(desc) ||
+	    WARN_ON(irq_settings_is_per_cpu_devid(desc)) ||
+	    !irq_supports_nmi(desc))
+		return -EINVAL;
+
+	action = kzalloc(sizeof(struct irqaction), GFP_KERNEL);
+	if (!action)
+		return -ENOMEM;
+
+	action->handler = handler;
+	action->flags = irqflags | IRQF_NO_THREAD | IRQF_NOBALANCING;
+	action->name = name;
+	action->dev_id = dev_id;
+
+	retval = irq_chip_pm_get(&desc->irq_data);
+	if (retval < 0)
+		goto err_out;
+
+	retval = __setup_irq(irq, desc, action);
+	if (retval)
+		goto err_irq_setup;
+
+	raw_spin_lock_irqsave(&desc->lock, flags);
+
+	/* Setup NMI state */
+	desc->istate |= IRQS_NMI;
+	retval = irq_nmi_setup(desc);
+	if (retval) {
+		__cleanup_nmi(irq, desc);
+		raw_spin_unlock_irqrestore(&desc->lock, flags);
+		return -EINVAL;
+	}
+
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
+
+	return 0;
+
+err_irq_setup:
+	irq_chip_pm_put(&desc->irq_data);
+err_out:
+	kfree(action);
+
+	return retval;
+}
+
 void enable_percpu_irq(unsigned int irq, unsigned int type)
 {
 	unsigned int cpu = smp_processor_id();

commit bddda606ec76550dd63592e32a6e87e7d32583f7
Author: Srinivas Ramana <sramana@codeaurora.org>
Date:   Thu Dec 20 19:05:57 2018 +0530

    genirq: Make sure the initial affinity is not empty
    
    If all CPUs in the irq_default_affinity mask are offline when an interrupt
    is initialized then irq_setup_affinity() can set an empty affinity mask for
    a newly allocated interrupt.
    
    Fix this by falling back to cpu_online_mask in case the resulting affinity
    mask is zero.
    
    Signed-off-by: Srinivas Ramana <sramana@codeaurora.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-arm-msm@vger.kernel.org
    Link: https://lkml.kernel.org/r/1545312957-8504-1-git-send-email-sramana@codeaurora.org

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index a4888ce4667a..84b54a17b95d 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -393,6 +393,9 @@ int irq_setup_affinity(struct irq_desc *desc)
 	}
 
 	cpumask_and(&mask, cpu_online_mask, set);
+	if (cpumask_empty(&mask))
+		cpumask_copy(&mask, cpu_online_mask);
+
 	if (node != NUMA_NO_NODE) {
 		const struct cpumask *nodemask = cpumask_of_node(node);
 

commit 44133f7eaebec227d1381868d642e3c64023520f
Author: Mathieu Malaterre <malat@debian.org>
Date:   Mon Jan 14 21:31:54 2019 +0100

    genirq: Annotate implicit fall through
    
    There is a plan to build the kernel with -Wimplicit-fallthrough. The
    fallthrough in __irq_set_trigger() lacks an annotation. Add it.
    
    Signed-off-by: Mathieu Malaterre <malat@debian.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20190114203154.17125-1-malat@debian.org

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index a4888ce4667a..1ca39dc4538d 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -723,6 +723,7 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned long flags)
 	case IRQ_SET_MASK_OK_DONE:
 		irqd_clear(&desc->irq_data, IRQD_TRIGGER_MASK);
 		irqd_set(&desc->irq_data, flags);
+		/* fall through */
 
 	case IRQ_SET_MASK_OK_NOCOPY:
 		flags = irqd_get_trigger_type(&desc->irq_data);

commit c5f48c0a7aa1a8c82d81cdf27e63aa0a5544c6e6
Author: Ingo Molnar <mingo@kernel.org>
Date:   Mon Dec 3 11:44:51 2018 +0100

    genirq: Fix various typos in comments
    
    Go over the IRQ subsystem source code (including irqchip drivers) and
    fix common typos in comments.
    
    No change in functionality intended.
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jason Cooper <jason@lakedaemon.net>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: linux-kernel@vger.kernel.org

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 9dbdccab3b6a..a4888ce4667a 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -915,7 +915,7 @@ irq_thread_check_affinity(struct irq_desc *desc, struct irqaction *action) { }
 #endif
 
 /*
- * Interrupts which are not explicitely requested as threaded
+ * Interrupts which are not explicitly requested as threaded
  * interrupts rely on the implicit bh/preempt disable of the hard irq
  * context. So we need to disable bh here to avoid deadlocks and other
  * side effects.

commit 746a923b863a1065ef77324e1e43f19b1a3eab5c
Author: Lukas Wunner <lukas@wunner.de>
Date:   Thu Oct 18 15:15:05 2018 +0200

    genirq: Fix race on spurious interrupt detection
    
    Commit 1e77d0a1ed74 ("genirq: Sanitize spurious interrupt detection of
    threaded irqs") made detection of spurious interrupts work for threaded
    handlers by:
    
    a) incrementing a counter every time the thread returns IRQ_HANDLED, and
    b) checking whether that counter has increased every time the thread is
       woken.
    
    However for oneshot interrupts, the commit unmasks the interrupt before
    incrementing the counter.  If another interrupt occurs right after
    unmasking but before the counter is incremented, that interrupt is
    incorrectly considered spurious:
    
    time
     |  irq_thread()
     |    irq_thread_fn()
     |      action->thread_fn()
     |      irq_finalize_oneshot()
     |        unmask_threaded_irq()            /* interrupt is unmasked */
     |
     |                  /* interrupt fires, incorrectly deemed spurious */
     |
     |    atomic_inc(&desc->threads_handled); /* counter is incremented */
     v
    
    This is observed with a hi3110 CAN controller receiving data at high volume
    (from a separate machine sending with "cangen -g 0 -i -x"): The controller
    signals a huge number of interrupts (hundreds of millions per day) and
    every second there are about a dozen which are deemed spurious.
    
    In theory with high CPU load and the presence of higher priority tasks, the
    number of incorrectly detected spurious interrupts might increase beyond
    the 99,900 threshold and cause disablement of the interrupt.
    
    In practice it just increments the spurious interrupt count. But that can
    cause people to waste time investigating it over and over.
    
    Fix it by moving the accounting before the invocation of
    irq_finalize_oneshot().
    
    [ tglx: Folded change log update ]
    
    Fixes: 1e77d0a1ed74 ("genirq: Sanitize spurious interrupt detection of threaded irqs")
    Signed-off-by: Lukas Wunner <lukas@wunner.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Mathias Duckeck <m.duckeck@kunbus.de>
    Cc: Akshay Bhat <akshay.bhat@timesys.com>
    Cc: Casey Fitzpatrick <casey.fitzpatrick@timesys.com>
    Cc: stable@vger.kernel.org # v3.16+
    Link: https://lkml.kernel.org/r/1dfd8bbd16163940648045495e3e9698e63b50ad.1539867047.git.lukas@wunner.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index fb86146037a7..9dbdccab3b6a 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -927,6 +927,9 @@ irq_forced_thread_fn(struct irq_desc *desc, struct irqaction *action)
 
 	local_bh_disable();
 	ret = action->thread_fn(action->irq, action->dev_id);
+	if (ret == IRQ_HANDLED)
+		atomic_inc(&desc->threads_handled);
+
 	irq_finalize_oneshot(desc, action);
 	local_bh_enable();
 	return ret;
@@ -943,6 +946,9 @@ static irqreturn_t irq_thread_fn(struct irq_desc *desc,
 	irqreturn_t ret;
 
 	ret = action->thread_fn(action->irq, action->dev_id);
+	if (ret == IRQ_HANDLED)
+		atomic_inc(&desc->threads_handled);
+
 	irq_finalize_oneshot(desc, action);
 	return ret;
 }
@@ -1020,8 +1026,6 @@ static int irq_thread(void *data)
 		irq_thread_check_affinity(desc, action);
 
 		action_ret = handler_fn(desc, action);
-		if (action_ret == IRQ_HANDLED)
-			atomic_inc(&desc->threads_handled);
 		if (action_ret == IRQ_WAKE_THREAD)
 			irq_wake_secondary(desc, action);
 

commit d0daaeaf60143c02a2ef87f9f0703b63a0a7f8b3
Merge: 400439275d95 9e90c7985229
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Aug 13 10:47:26 2018 -0700

    Merge branch 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull genirq updates from Thomas Gleixner:
     "The irq departement provides:
    
       - A synchronization fix for free_irq() to synchronize just the
         removed interrupt thread on shared interrupt lines.
    
       - Consolidate the multi low level interrupt entry handling and mvoe
         it to the generic code instead of adding yet another copy for
         RISC-V
    
       - Refactoring of the ARM LPI allocator and LPI exposure to the
         hypervisor
    
       - Yet another interrupt chip driver for the JZ4725B SoC
    
       - Speed up for /proc/interrupts as people seem to love reading this
         file with high frequency
    
       - Miscellaneous fixes and updates"
    
    * 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (23 commits)
      irqchip/gic-v3-its: Make its_lock a raw_spin_lock_t
      genirq/irqchip: Remove MULTI_IRQ_HANDLER as it's now obselete
      openrisc: Use the new GENERIC_IRQ_MULTI_HANDLER
      arm64: Use the new GENERIC_IRQ_MULTI_HANDLER
      ARM: Convert to GENERIC_IRQ_MULTI_HANDLER
      irqchip: Port the ARM IRQ drivers to GENERIC_IRQ_MULTI_HANDLER
      irqchip/gic-v3-its: Reduce minimum LPI allocation to 1 for PCI devices
      dt-bindings: irqchip: renesas-irqc: Document r8a77980 support
      dt-bindings: irqchip: renesas-irqc: Document r8a77470 support
      irqchip/ingenic: Add support for the JZ4725B SoC
      irqchip/stm32: Add exti0 translation for stm32mp1
      genirq: Remove redundant NULL pointer check in __free_irq()
      irqchip/gic-v3-its: Honor hypervisor enforced LPI range
      irqchip/gic-v3: Expose GICD_TYPER in the rdist structure
      irqchip/gic-v3-its: Drop chunk allocation compatibility
      irqchip/gic-v3-its: Move minimum LPI requirements to individual busses
      irqchip/gic-v3-its: Use full range of LPIs
      irqchip/gic-v3-its: Refactor LPI allocator
      genirq: Synchronize only with single thread on free_irq()
      genirq: Update code comments wrt recycled thread_mask
      ...

commit d1f0301b3333eef5efbfa1fe0f0edbea01863d5d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Aug 3 14:44:59 2018 +0200

    genirq: Make force irq threading setup more robust
    
    The support of force threading interrupts which are set up with both a
    primary and a threaded handler wreckaged the setup of regular requested
    threaded interrupts (primary handler == NULL).
    
    The reason is that it does not check whether the primary handler is set to
    the default handler which wakes the handler thread. Instead it replaces the
    thread handler with the primary handler as it would do with force threaded
    interrupts which have been requested via request_irq(). So both the primary
    and the thread handler become the same which then triggers the warnon that
    the thread handler tries to wakeup a not configured secondary thread.
    
    Fortunately this only happens when the driver omits the IRQF_ONESHOT flag
    when requesting the threaded interrupt, which is normaly caught by the
    sanity checks when force irq threading is disabled.
    
    Fix it by skipping the force threading setup when a regular threaded
    interrupt is requested. As a consequence the interrupt request which lacks
    the IRQ_ONESHOT flag is rejected correctly instead of silently wreckaging
    it.
    
    Fixes: 2a1d3ab8986d ("genirq: Handle force threading of irqs with primary and thread handler")
    Reported-by: Kurt Kanzenbach <kurt.kanzenbach@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Kurt Kanzenbach <kurt.kanzenbach@linutronix.de>
    Cc: stable@vger.kernel.org

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index daeabd791d58..9a8b7ba9aa88 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1068,6 +1068,13 @@ static int irq_setup_forced_threading(struct irqaction *new)
 	if (new->flags & (IRQF_NO_THREAD | IRQF_PERCPU | IRQF_ONESHOT))
 		return 0;
 
+	/*
+	 * No further action required for interrupts which are requested as
+	 * threaded interrupts already
+	 */
+	if (new->handler == irq_default_primary_handler)
+		return 0;
+
 	new->flags |= IRQF_ONESHOT;
 
 	/*
@@ -1075,7 +1082,7 @@ static int irq_setup_forced_threading(struct irqaction *new)
 	 * thread handler. We force thread them as well by creating a
 	 * secondary action.
 	 */
-	if (new->handler != irq_default_primary_handler && new->thread_fn) {
+	if (new->handler && new->thread_fn) {
 		/* Allocate the secondary action */
 		new->secondary = kzalloc(sizeof(struct irqaction), GFP_KERNEL);
 		if (!new->secondary)

commit d91cfeb0aa79445fcfa9f523a5b57c5e9f4113ec
Author: RAGHU Halharvi <raghuhack78@gmail.com>
Date:   Tue Jul 17 15:50:09 2018 +0530

    genirq: Remove redundant NULL pointer check in __free_irq()
    
    The NULL pointer check in __free_irq() triggers a 'dereference before NULL
    pointer check' warning in static code analysis. It turns out that the check
    is redundant because all callers have a NULL pointer check already.
    
    Remove it.
    
    Signed-off-by: RAGHU Halharvi <raghuhack78@gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20180717102009.7708-1-raghuhack78@gmail.com

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 1f8be33572a7..a66c58f91bff 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1570,9 +1570,6 @@ static struct irqaction *__free_irq(struct irq_desc *desc, void *dev_id)
 
 	WARN(in_interrupt(), "Trying to free IRQ %d from IRQ context!\n", irq);
 
-	if (!desc)
-		return NULL;
-
 	mutex_lock(&desc->request_mutex);
 	chip_bus_lock(desc);
 	raw_spin_lock_irqsave(&desc->lock, flags);

commit 519cc8652b3a1d3d0a02257afbe9573ad644da26
Author: Lukas Wunner <lukas@wunner.de>
Date:   Sun Jun 24 10:35:30 2018 +0200

    genirq: Synchronize only with single thread on free_irq()
    
    When pciehp is converted to threaded IRQ handling, removal of unplugged
    devices below a PCIe hotplug port happens synchronously in the IRQ thread.
    Removal of devices typically entails a call to free_irq() by their drivers.
    
    If those devices share their IRQ with the hotplug port, __free_irq()
    deadlocks because it calls synchronize_irq() to wait for all hard IRQ
    handlers as well as all threads sharing the IRQ to finish.
    
    Actually it's sufficient to wait only for the IRQ thread of the removed
    device, so call synchronize_hardirq() to wait for all hard IRQ handlers to
    finish, but no longer for any threads.  Compensate by rearranging the
    control flow in irq_wait_for_interrupt() such that the device's thread is
    allowed to run one last time after kthread_stop() has been called.
    
    kthread_stop() blocks until the IRQ thread has completed.  On completion
    the IRQ thread clears its oneshot thread_mask bit.  This is safe because
    __free_irq() holds the request_mutex, thereby preventing __setup_irq() from
    handing out the same oneshot thread_mask bit to a newly requested action.
    
    Stack trace for posterity:
        INFO: task irq/17-pciehp:94 blocked for more than 120 seconds.
        schedule+0x28/0x80
        synchronize_irq+0x6e/0xa0
        __free_irq+0x15a/0x2b0
        free_irq+0x33/0x70
        pciehp_release_ctrl+0x98/0xb0
        pcie_port_remove_service+0x2f/0x40
        device_release_driver_internal+0x157/0x220
        bus_remove_device+0xe2/0x150
        device_del+0x124/0x340
        device_unregister+0x16/0x60
        remove_iter+0x1a/0x20
        device_for_each_child+0x4b/0x90
        pcie_port_device_remove+0x1e/0x30
        pci_device_remove+0x36/0xb0
        device_release_driver_internal+0x157/0x220
        pci_stop_bus_device+0x7d/0xa0
        pci_stop_bus_device+0x3d/0xa0
        pci_stop_and_remove_bus_device+0xe/0x20
        pciehp_unconfigure_device+0xb8/0x160
        pciehp_disable_slot+0x84/0x130
        pciehp_ist+0x158/0x190
        irq_thread_fn+0x1b/0x50
        irq_thread+0x143/0x1a0
        kthread+0x111/0x130
    
    Signed-off-by: Lukas Wunner <lukas@wunner.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: Mika Westerberg <mika.westerberg@linux.intel.com>
    Cc: linux-pci@vger.kernel.org
    Link: https://lkml.kernel.org/r/d72b41309f077c8d3bee6cc08ad3662d50b5d22a.1529828292.git.lukas@wunner.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 123a227d3357..1f8be33572a7 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -790,9 +790,19 @@ static irqreturn_t irq_forced_secondary_handler(int irq, void *dev_id)
 
 static int irq_wait_for_interrupt(struct irqaction *action)
 {
-	set_current_state(TASK_INTERRUPTIBLE);
+	for (;;) {
+		set_current_state(TASK_INTERRUPTIBLE);
 
-	while (!kthread_should_stop()) {
+		if (kthread_should_stop()) {
+			/* may need to run one last time */
+			if (test_and_clear_bit(IRQTF_RUNTHREAD,
+					       &action->thread_flags)) {
+				__set_current_state(TASK_RUNNING);
+				return 0;
+			}
+			__set_current_state(TASK_RUNNING);
+			return -1;
+		}
 
 		if (test_and_clear_bit(IRQTF_RUNTHREAD,
 				       &action->thread_flags)) {
@@ -800,10 +810,7 @@ static int irq_wait_for_interrupt(struct irqaction *action)
 			return 0;
 		}
 		schedule();
-		set_current_state(TASK_INTERRUPTIBLE);
 	}
-	__set_current_state(TASK_RUNNING);
-	return -1;
 }
 
 /*
@@ -1024,7 +1031,7 @@ static int irq_thread(void *data)
 	/*
 	 * This is the regular exit path. __free_irq() is stopping the
 	 * thread via kthread_stop() after calling
-	 * synchronize_irq(). So neither IRQTF_RUNTHREAD nor the
+	 * synchronize_hardirq(). So neither IRQTF_RUNTHREAD nor the
 	 * oneshot mask bit can be set.
 	 */
 	task_work_cancel(current, irq_thread_dtor);
@@ -1241,7 +1248,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 	/*
 	 * Protects against a concurrent __free_irq() call which might wait
-	 * for synchronize_irq() to complete without holding the optional
+	 * for synchronize_hardirq() to complete without holding the optional
 	 * chip bus lock and desc->lock. Also protects against handing out
 	 * a recycled oneshot thread_mask bit while it's still in use by
 	 * its previous owner.
@@ -1612,11 +1619,11 @@ static struct irqaction *__free_irq(struct irq_desc *desc, void *dev_id)
 	/*
 	 * Drop bus_lock here so the changes which were done in the chip
 	 * callbacks above are synced out to the irq chips which hang
-	 * behind a slow bus (I2C, SPI) before calling synchronize_irq().
+	 * behind a slow bus (I2C, SPI) before calling synchronize_hardirq().
 	 *
 	 * Aside of that the bus_lock can also be taken from the threaded
 	 * handler in irq_finalize_oneshot() which results in a deadlock
-	 * because synchronize_irq() would wait forever for the thread to
+	 * because kthread_stop() would wait forever for the thread to
 	 * complete, which is blocked on the bus lock.
 	 *
 	 * The still held desc->request_mutex() protects against a
@@ -1628,7 +1635,7 @@ static struct irqaction *__free_irq(struct irq_desc *desc, void *dev_id)
 	unregister_handler_proc(irq, action);
 
 	/* Make sure it's not being used on another CPU: */
-	synchronize_irq(irq);
+	synchronize_hardirq(irq);
 
 #ifdef CONFIG_DEBUG_SHIRQ
 	/*
@@ -1646,6 +1653,12 @@ static struct irqaction *__free_irq(struct irq_desc *desc, void *dev_id)
 	}
 #endif
 
+	/*
+	 * The action has already been removed above, but the thread writes
+	 * its oneshot mask bit when it completes. Though request_mutex is
+	 * held across this which prevents __setup_irq() from handing out
+	 * the same bit to a newly requested action.
+	 */
 	if (action->thread) {
 		kthread_stop(action->thread);
 		put_task_struct(action->thread);

commit 836557bd58e5e65c05c73af9f6ebed885dbfccfc
Author: Lukas Wunner <lukas@wunner.de>
Date:   Sun Jun 24 10:35:18 2018 +0200

    genirq: Update code comments wrt recycled thread_mask
    
    Previously a race existed between __free_irq() and __setup_irq() wherein
    the thread_mask of a just removed action could be handed out to a newly
    added action and the freed irq thread would then tread on the oneshot
    mask bit of the newly added irq thread in irq_finalize_oneshot():
    
    time
     |  __free_irq()
     |    raw_spin_lock_irqsave(&desc->lock, flags);
     |    <remove action from linked list>
     |    raw_spin_unlock_irqrestore(&desc->lock, flags);
     |
     |  __setup_irq()
     |    raw_spin_lock_irqsave(&desc->lock, flags);
     |    <traverse linked list to determine oneshot mask bit>
     |    raw_spin_unlock_irqrestore(&desc->lock, flags);
     |
     |  irq_thread() of freed irq (__free_irq() waits in synchronize_irq())
     |    irq_thread_fn()
     |      irq_finalize_oneshot()
     |        raw_spin_lock_irq(&desc->lock);
     |        desc->threads_oneshot &= ~action->thread_mask;
     |        raw_spin_unlock_irq(&desc->lock);
     v
    
    The race was known at least since 2012 when it was documented in a code
    comment by commit e04268b0effc ("genirq: Remove paranoid warnons and bogus
    fixups"). The race itself is harmless as nothing touches any of the
    potentially freed data after synchronize_irq().
    
    In 2017 the race was close by commit 9114014cf4e6 ("genirq: Add mutex to
    irq desc to serialize request/free_irq()"), apparently inadvertantly so
    because the race is neither mentioned in the commit message nor was the
    code comment updated.  Make up for that.
    
    Signed-off-by: Lukas Wunner <lukas@wunner.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: Mika Westerberg <mika.westerberg@linux.intel.com>
    Cc: linux-pci@vger.kernel.org
    Link: https://lkml.kernel.org/r/32fc25aa35ecef4b2692f57687bb7fc2a57230e2.1529828292.git.lukas@wunner.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 591cfe901162..123a227d3357 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1025,10 +1025,7 @@ static int irq_thread(void *data)
 	 * This is the regular exit path. __free_irq() is stopping the
 	 * thread via kthread_stop() after calling
 	 * synchronize_irq(). So neither IRQTF_RUNTHREAD nor the
-	 * oneshot mask bit can be set. We cannot verify that as we
-	 * cannot touch the oneshot mask at this point anymore as
-	 * __setup_irq() might have given out currents thread_mask
-	 * again.
+	 * oneshot mask bit can be set.
 	 */
 	task_work_cancel(current, irq_thread_dtor);
 	return 0;
@@ -1245,7 +1242,9 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	/*
 	 * Protects against a concurrent __free_irq() call which might wait
 	 * for synchronize_irq() to complete without holding the optional
-	 * chip bus lock and desc->lock.
+	 * chip bus lock and desc->lock. Also protects against handing out
+	 * a recycled oneshot thread_mask bit while it's still in use by
+	 * its previous owner.
 	 */
 	mutex_lock(&desc->request_mutex);
 

commit 0a13ec0bbc42bddf90ab6a444df8aaa67c148b16
Author: Jonathan Neuschäfer <j.neuschaefer@gmx.net>
Date:   Sun Jun 17 14:40:18 2018 +0200

    genirq: Fix editing error in a comment
    
    When the comment was reflowed to a wider format, the "*" snuck in.
    
    Fixes: ae88a23b32fa ("irq: refactor and clean up the free_irq() code flow")
    Signed-off-by: Jonathan Neuschäfer <j.neuschaefer@gmx.net>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20180617124018.25539-1-j.neuschaefer@gmx.net

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index daeabd791d58..591cfe901162 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1638,7 +1638,7 @@ static struct irqaction *__free_irq(struct irq_desc *desc, void *dev_id)
 	 * is so by doing an extra call to the handler ....
 	 *
 	 * ( We do this after actually deregistering it, to make sure that a
-	 *   'real' IRQ doesn't run in * parallel with our fake. )
+	 *   'real' IRQ doesn't run in parallel with our fake. )
 	 */
 	if (action->flags & IRQF_SHARED) {
 		local_irq_save(flags);

commit f4e5b30d809d3882c69f43b5c90779af033d40c4
Merge: a2211de0f979 1d9f3e20a56d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Jun 10 09:44:53 2018 -0700

    Merge branch 'x86-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 updates and fixes from Thomas Gleixner:
    
     - Fix the (late) fallout from the vector management rework causing
       hlist corruption and irq descriptor reference leaks caused by a
       missing sanity check.
    
       The straight forward fix triggered another long standing issue to
       surface. The pre rework code hid the issue due to being way slower,
       but now the chance that user space sees an EBUSY error return when
       updating irq affinities is way higher, though quite a bunch of
       userspace tools do not handle it properly despite the fact that EBUSY
       could be returned for at least 10 years.
    
       It turned out that the EBUSY return can be avoided completely by
       utilizing the existing delayed affinity update mechanism for irq
       remapped scenarios as well. That's a bit more error handling in the
       kernel, but avoids fruitless fingerpointing discussions with tool
       developers.
    
     - Decouple PHYSICAL_MASK from AMD SME as its going to be required for
       the upcoming Intel memory encryption support as well.
    
     - Handle legacy device ACPI detection properly for newer platforms
    
     - Fix the wrong argument ordering in the vector allocation tracepoint
    
     - Simplify the IDT setup code for the APIC=n case
    
     - Use the proper string helpers in the MTRR code
    
     - Remove a stale unused VDSO source file
    
     - Convert the microcode update lock to a raw spinlock as its used in
       atomic context.
    
    * 'x86-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/intel_rdt: Enable CMT and MBM on new Skylake stepping
      x86/apic/vector: Print APIC control bits in debugfs
      genirq/affinity: Defer affinity setting if irq chip is busy
      x86/platform/uv: Use apic_ack_irq()
      x86/ioapic: Use apic_ack_irq()
      irq_remapping: Use apic_ack_irq()
      x86/apic: Provide apic_ack_irq()
      genirq/migration: Avoid out of line call if pending is not set
      genirq/generic_pending: Do not lose pending affinity update
      x86/apic/vector: Prevent hlist corruption and leaks
      x86/vector: Fix the args of vector_alloc tracepoint
      x86/idt: Simplify the idt_setup_apic_and_irq_gates()
      x86/platform/uv: Remove extra parentheses
      x86/mm: Decouple dynamic __PHYSICAL_MASK from AMD SME
      x86: Mark native_set_p4d() as __always_inline
      x86/microcode: Make the late update update_lock a raw lock for RT
      x86/mtrr: Convert to use strncpy_from_user() helper
      x86/mtrr: Convert to use match_string() helper
      x86/vdso: Remove unused file
      x86/i8237: Register device based on FADT legacy boot flag

commit 12f47073a40f6aa75119d8f5df4077b7f334cced
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jun 4 17:33:59 2018 +0200

    genirq/affinity: Defer affinity setting if irq chip is busy
    
    The case that interrupt affinity setting fails with -EBUSY can be handled
    in the kernel completely by using the already available generic pending
    infrastructure.
    
    If a irq_chip::set_affinity() fails with -EBUSY, handle it like the
    interrupts for which irq_chip::set_affinity() can only be invoked from
    interrupt context. Copy the new affinity mask to irq_desc::pending_mask and
    set the affinity pending bit. The next raised interrupt for the affected
    irq will check the pending bit and try to set the new affinity from the
    handler. This avoids that -EBUSY is returned when an affinity change is
    requested from user space and the previous change has not been cleaned
    up. The new affinity will take effect when the next interrupt is raised
    from the device.
    
    Fixes: dccfe3147b42 ("x86/vector: Simplify vector move cleanup")
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Song Liu <songliubraving@fb.com>
    Cc: Joerg Roedel <jroedel@suse.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Song Liu <liu.song.a23@gmail.com>
    Cc: Dmitry Safonov <0x7f454c46@gmail.com>
    Cc: stable@vger.kernel.org
    Cc: Mike Travis <mike.travis@hpe.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Tariq Toukan <tariqt@mellanox.com>
    Link: https://lkml.kernel.org/r/20180604162224.819273597@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index e3336d904f64..facfecfc543c 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -204,6 +204,39 @@ int irq_do_set_affinity(struct irq_data *data, const struct cpumask *mask,
 	return ret;
 }
 
+#ifdef CONFIG_GENERIC_PENDING_IRQ
+static inline int irq_set_affinity_pending(struct irq_data *data,
+					   const struct cpumask *dest)
+{
+	struct irq_desc *desc = irq_data_to_desc(data);
+
+	irqd_set_move_pending(data);
+	irq_copy_pending(desc, dest);
+	return 0;
+}
+#else
+static inline int irq_set_affinity_pending(struct irq_data *data,
+					   const struct cpumask *dest)
+{
+	return -EBUSY;
+}
+#endif
+
+static int irq_try_set_affinity(struct irq_data *data,
+				const struct cpumask *dest, bool force)
+{
+	int ret = irq_do_set_affinity(data, dest, force);
+
+	/*
+	 * In case that the underlying vector management is busy and the
+	 * architecture supports the generic pending mechanism then utilize
+	 * this to avoid returning an error to user space.
+	 */
+	if (ret == -EBUSY && !force)
+		ret = irq_set_affinity_pending(data, dest);
+	return ret;
+}
+
 int irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask,
 			    bool force)
 {
@@ -214,8 +247,8 @@ int irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask,
 	if (!chip || !chip->irq_set_affinity)
 		return -EINVAL;
 
-	if (irq_can_move_pcntxt(data)) {
-		ret = irq_do_set_affinity(data, mask, force);
+	if (irq_can_move_pcntxt(data) && !irqd_is_setaffinity_pending(data)) {
+		ret = irq_try_set_affinity(data, mask, force);
 	} else {
 		irqd_set_move_pending(data);
 		irq_copy_pending(desc, mask);

commit 47b82e88180c3c6db795a43373beab47cb073f7a
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Fri May 4 16:24:46 2018 +0200

    ide: don't enable/disable interrupts in force threaded-IRQ mode
    
    The interrupts are enabled/disabled so the interrupt handler can run
    with enabled interrupts while serving the interrupt and not lose other
    interrupts especially the timer tick.
    If the system runs with force-threaded interrupts then there is no need
    to enable the interrupts.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Acked-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index e3336d904f64..4c2ef8084e32 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -24,6 +24,7 @@
 
 #ifdef CONFIG_IRQ_FORCED_THREADING
 __read_mostly bool force_irqthreads;
+EXPORT_SYMBOL_GPL(force_irqthreads);
 
 static int __init setup_forced_irqthreads(char *arg)
 {

commit 52a65ff5603e685e9b19c2e108b3f0826dc7a86b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Mar 14 22:15:19 2018 +0100

    genirq: Add missing SPDX identifiers
    
    Add SPDX identifiers to files
    
     - which contain an explicit license boiler plate or reference
    
     - which do not contain a license reference and were not updated in the
       initial SPDX conversion because the license was deduced by the scanners
       via EXPORT_SYMBOL_GPL as GPL2.0 only.
    
    [ tglx: Moved adding identifiers from the patch which removes the
            references/boilerplate ]
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Kate Stewart <kstewart@linuxfoundation.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Philippe Ombredanne <pombredanne@nexb.com>
    Link: https://lkml.kernel.org/r/20180314212030.668321222@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 99eb1977e784..e3336d904f64 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * Copyright (C) 1992, 1998-2006 Linus Torvalds, Ingo Molnar
  * Copyright (C) 2005-2006 Thomas Gleixner

commit 99bfce5db9c071800bdc7e9658a68e6d11aeecf6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Mar 14 22:15:16 2018 +0100

    genirq: Cleanup top of file comments
    
    Remove pointless references to the file name itself and condense the
    information so it wastes less space.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Kate Stewart <kstewart@linuxfoundation.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Philippe Ombredanne <pombredanne@nexb.com>
    Link: https://lkml.kernel.org/r/20180314212030.412095827@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index b0aa23b2398e..99eb1977e784 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1,6 +1,4 @@
 /*
- * linux/kernel/irq/manage.c
- *
  * Copyright (C) 1992, 1998-2006 Linus Torvalds, Ingo Molnar
  * Copyright (C) 2005-2006 Thomas Gleixner
  *

commit 83ac4ca943affce56a2c408ddb2f5232f478fb11
Author: Uwe Kleine König <u.kleine-koenig@pengutronix.de>
Date:   Mon Mar 19 11:52:02 2018 +0100

    genirq: Pass desc to __irq_free instead of irq number
    
    Given that irq_to_desc() is a radix_tree_lookup and the reverse
    operation is only a pointer dereference and that all callers of
    __free_irq already have the desc, pass the desc instead of the irq
    number.
    
    Signed-off-by: Uwe Kleine-König <u.kleine-koenig@pengutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: kernel@pengutronix.de
    Link: https://lkml.kernel.org/r/20180319105202.9794-1-u.kleine-koenig@pengutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index d2b3c59f1200..b0aa23b2398e 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1523,9 +1523,9 @@ EXPORT_SYMBOL_GPL(setup_irq);
  * Internal function to unregister an irqaction - used to free
  * regular and special interrupts that are part of the architecture.
  */
-static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
+static struct irqaction *__free_irq(struct irq_desc *desc, void *dev_id)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
+	unsigned irq = desc->irq_data.irq;
 	struct irqaction *action, **action_ptr;
 	unsigned long flags;
 
@@ -1655,7 +1655,7 @@ void remove_irq(unsigned int irq, struct irqaction *act)
 	struct irq_desc *desc = irq_to_desc(irq);
 
 	if (desc && !WARN_ON(irq_settings_is_per_cpu_devid(desc)))
-		__free_irq(irq, act->dev_id);
+		__free_irq(desc, act->dev_id);
 }
 EXPORT_SYMBOL_GPL(remove_irq);
 
@@ -1689,7 +1689,7 @@ const void *free_irq(unsigned int irq, void *dev_id)
 		desc->affinity_notify = NULL;
 #endif
 
-	action = __free_irq(irq, dev_id);
+	action = __free_irq(desc, dev_id);
 
 	if (!action)
 		return NULL;

commit cbf8699996a6e7f2f674b3a2a4cef9f666ff613e
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Feb 16 15:21:20 2018 +0100

    genirq: Let irq thread follow the effective hard irq affinity
    
    In case of threaded interrupts the thread follows the affinity setting of
    the hard interrupt. The related function uses the affinity mask which was
    set by either from user space or via one of the kernel mechanisms. This
    mask can be wider than the resulting effective affinity of the hard
    interrupt. As a consequence the thread might become affine to a completely
    different CPU.
    
    Use the effective interrupt affinity if the architecture supports it, so
    the hard interrupt and the thread stay on the same CPU.
    
    Reported-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0f922729bab9..d2b3c59f1200 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -855,10 +855,14 @@ irq_thread_check_affinity(struct irq_desc *desc, struct irqaction *action)
 	 * This code is triggered unconditionally. Check the affinity
 	 * mask pointer. For CPU_MASK_OFFSTACK=n this is optimized out.
 	 */
-	if (cpumask_available(desc->irq_common_data.affinity))
-		cpumask_copy(mask, desc->irq_common_data.affinity);
-	else
+	if (cpumask_available(desc->irq_common_data.affinity)) {
+		const struct cpumask *m;
+
+		m = irq_data_get_effective_affinity_mask(&desc->irq_data);
+		cpumask_copy(mask, m);
+	} else {
 		valid = false;
+	}
 	raw_spin_unlock_irq(&desc->lock);
 
 	if (valid)

commit 41cc30412d6692c25506bf2d4e65c4364c70c10a
Merge: b29c6ef7bb12 29f411399aaa
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Nov 14 11:23:05 2017 +0100

    Merge tag 'irqchip-4.15-4' of git://git.kernel.org/pub/scm/linux/kernel/git/maz/arm-platforms into irq/urgent
    
    Pull irqchip updates for 4.15, take #4 from Marc Zyngier
    
     - A core irq fix for legacy cases where the irq trigger is not reported
       by firmware
    
     - A couple of GICv3/4 fixes (Kconfig, of-node refcount, error handling)
    
     - Trivial pr_err fixes

commit 670310dfbae0eefe7318ff6a61e29e67a7a7bbce
Merge: 43ff2f4db9d0 ffc661c99f62
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 13 17:33:11 2017 -0800

    Merge branch 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull irq core updates from Thomas Gleixner:
     "A rather large update for the interrupt core code and the irq chip drivers:
    
       - Add a new bitmap matrix allocator and supporting changes, which is
         used to replace the x86 vector allocator which comes with separate
         pull request. This allows to replace the convoluted nested loop
         allocation function in x86 with a facility which supports the
         recently added property of managed interrupts proper and allows to
         switch to a best effort vector reservation scheme, which addresses
         problems with vector exhaustion.
    
       - A large update to the ARM GIC-V3-ITS driver adding support for
         range selectors.
    
       - New interrupt controllers:
           - Meson and Meson8 GPIO
           - BCM7271 L2
           - Socionext EXIU
    
         If you expected that this will stop at some point, I have to
         disappoint you. There are new ones posted already. Sigh!
    
       - STM32 interrupt controller support for new platforms.
    
       - A pile of fixes, cleanups and updates to the MIPS GIC driver
    
       - The usual small fixes, cleanups and updates all over the place.
         Most visible one is to move the irq chip drivers Kconfig switches
         into a separate Kconfig menu"
    
    * 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (70 commits)
      genirq: Fix type of shifting literal 1 in __setup_irq()
      irqdomain: Drop pointless NULL check in virq_debug_show_one
      genirq/proc: Return proper error code when irq_set_affinity() fails
      irq/work: Use llist_for_each_entry_safe
      irqchip: mips-gic: Print warning if inherited GIC base is used
      irqchip/mips-gic: Add pr_fmt and reword pr_* messages
      irqchip/stm32: Move the wakeup on interrupt mask
      irqchip/stm32: Fix initial values
      irqchip/stm32: Add stm32h7 support
      dt-bindings/interrupt-controllers: Add compatible string for stm32h7
      irqchip/stm32: Add multi-bank management
      irqchip/stm32: Select GENERIC_IRQ_CHIP
      irqchip/exiu: Add support for Socionext Synquacer EXIU controller
      dt-bindings: Add description of Socionext EXIU interrupt controller
      irqchip/gic-v3-its: Fix VPE activate callback return value
      irqchip: mips-gic: Make IPI bitmaps static
      irqchip: mips-gic: Share register writes in gic_set_type()
      irqchip: mips-gic: Remove gic_vpes variable
      irqchip: mips-gic: Use num_possible_cpus() to reserve IPIs
      irqchip: mips-gic: Configure EIC when CPUs come online
      ...

commit ffc661c99f621152d5fdcf53f9df0d48c326318b
Author: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Date:   Mon Oct 30 22:35:47 2017 +0100

    genirq: Fix type of shifting literal 1 in __setup_irq()
    
    If ffz() ever returns a value >= 31 then the following shift is undefined
    behaviour because the literal 1 which gets shifted is treated as signed
    integer.
    
    In practice, the bug is probably harmless, since the first undefined shift
    count is 31 which results - ignoring UB - in (int)(0x80000000). This gets
    sign extended so bit 32-63 will be set as well and all subsequent
    __setup_irq() calls would just end up hitting the -EBUSY branch.
    
    However, a sufficiently aggressive optimizer may use the UB of 1<<31
    to decide that doesn't happen, and hence elide the sign-extension
    code, so that subsequent calls can indeed get ffz > 31.
    
    In any case, the right thing to do is to make the literal 1UL.
    
    [ tglx: For this to happen a single interrupt would have to be shared by 32
            devices. Hardware like that does not exist and would have way more
            problems than that. ]
    
    Signed-off-by: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20171030213548.16831-1-linux@rasmusvillemoes.dk

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index c65f282cbc9a..6a1bf9dc7a6a 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1289,7 +1289,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		 * thread_mask assigned. See the loop above which or's
 		 * all existing action->thread_mask bits.
 		 */
-		new->thread_mask = 1 << ffz(thread_mask);
+		new->thread_mask = 1UL << ffz(thread_mask);
 
 	} else if (new->handler == irq_default_primary_handler &&
 		   !(desc->irq_data.chip->flags & IRQCHIP_ONESHOT_SAFE)) {

commit 4f8413a3a799c958f7a10a6310a451e6b8aef5ad
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Thu Nov 9 14:17:59 2017 +0000

    genirq: Track whether the trigger type has been set
    
    When requesting a shared interrupt, we assume that the firmware
    support code (DT or ACPI) has called irqd_set_trigger_type
    already, so that we can retrieve it and check that the requester
    is being reasonnable.
    
    Unfortunately, we still have non-DT, non-ACPI systems around,
    and these guys won't call irqd_set_trigger_type before requesting
    the interrupt. The consequence is that we fail the request that
    would have worked before.
    
    We can either chase all these use cases (boring), or address it
    in core code (easier). Let's have a per-irq_desc flag that
    indicates whether irqd_set_trigger_type has been called, and
    let's just check it when checking for a shared interrupt.
    If it hasn't been set, just take whatever the interrupt
    requester asks.
    
    Fixes: 382bd4de6182 ("genirq: Use irqd_get_trigger_type to compare the trigger type for shared IRQs")
    Cc: stable@vger.kernel.org
    Reported-and-tested-by: Petr Cvek <petrcvekcz@gmail.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index e667912d0e9c..21e04e780be4 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1228,7 +1228,18 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		 * set the trigger type must match. Also all must
 		 * agree on ONESHOT.
 		 */
-		unsigned int oldtype = irqd_get_trigger_type(&desc->irq_data);
+		unsigned int oldtype;
+
+		/*
+		 * If nobody did set the configuration before, inherit
+		 * the one provided by the requester.
+		 */
+		if (irqd_trigger_type_was_set(&desc->irq_data)) {
+			oldtype = irqd_get_trigger_type(&desc->irq_data);
+		} else {
+			oldtype = new->flags & IRQF_TRIGGER_MASK;
+			irqd_set_trigger_type(&desc->irq_data, oldtype);
+		}
 
 		if (!((old->flags & new->flags) & IRQF_SHARED) ||
 		    (oldtype != (new->flags & IRQF_TRIGGER_MASK)) ||

commit 250a53d6fcd86012935d1cf71eb2e3d6e88c412c
Author: Christoffer Dall <cdall@linaro.org>
Date:   Fri Oct 27 10:34:33 2017 +0200

    genirq: Document vcpu_info usage for percpu_devid interrupts
    
    It is currently unclear how to set the VCPU affinity for a percpu_devid
    interrupt , since the Linux irq_data structure describes the state for
    multiple interrupts, one for each physical CPU on the system.  Since
    each such interrupt can be associated with different VCPUs or none at
    all, associating a single VCPU state with such an interrupt does not
    capture the necessary semantics.
    
    The implementers of irq_set_affinity are the Intel and AMD IOMMUs, and
    the ARM GIC irqchip.  The Intel and AMD callers do not appear to use
    percpu_devid interrupts, and the ARM GIC implementation only checks the
    pointer against NULL vs. non-NULL.
    
    Therefore, simply update the function documentation to explain the
    expected use in the context of percpu_devid interrupts, allowing future
    changes or additions to irqchip implementers to do the right thing.
    
    Signed-off-by: Christoffer Dall <cdall@linaro.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: kvm@vger.kernel.org
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Eric Auger <eric.auger@redhat.com>
    Cc: kvmarm@lists.cs.columbia.edu
    Cc: linux-arm-kernel@lists.infradead.org
    Link: https://lkml.kernel.org/r/1509093281-15225-13-git-send-email-cdall@linaro.org

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index e667912d0e9c..c65f282cbc9a 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -381,7 +381,8 @@ int irq_select_affinity_usr(unsigned int irq)
 /**
  *	irq_set_vcpu_affinity - Set vcpu affinity for the interrupt
  *	@irq: interrupt number to set affinity
- *	@vcpu_info: vCPU specific data
+ *	@vcpu_info: vCPU specific data or pointer to a percpu array of vCPU
+ *	            specific data for percpu_devid interrupts
  *
  *	This function uses the vCPU specific data to set the vCPU
  *	affinity for an irq. The vCPU specific data is passed from

commit e43b3b58548051f8809391eb7bec7a27ed3003ea
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Oct 4 21:07:38 2017 +0200

    genirq/cpuhotplug: Enforce affinity setting on startup of managed irqs
    
    Managed interrupts can end up in a stale state on CPU hotplug. If the
    interrupt is not targeting a single CPU, i.e. the affinity mask spawns
    multiple CPUs then the following can happen:
    
    After boot:
    
    dstate:   0x01601200
                IRQD_ACTIVATED
                IRQD_IRQ_STARTED
                IRQD_SINGLE_TARGET
                IRQD_AFFINITY_SET
                IRQD_AFFINITY_MANAGED
    node:     0
    affinity: 24-31
    effectiv: 24
    pending:  0
    
    After offlining CPU 31 - 24
    
    dstate:   0x01a31000
                IRQD_IRQ_DISABLED
                IRQD_IRQ_MASKED
                IRQD_SINGLE_TARGET
                IRQD_AFFINITY_SET
                IRQD_AFFINITY_MANAGED
                IRQD_MANAGED_SHUTDOWN
    node:     0
    affinity: 24-31
    effectiv: 24
    pending:  0
    
    Now CPU 25 gets onlined again, so it should get the effective interrupt
    affinity for this interruopt, but due to the x86 interrupt affinity setter
    restrictions this ends up after restarting the interrupt with:
    
    dstate:   0x01601300
                IRQD_ACTIVATED
                IRQD_IRQ_STARTED
                IRQD_SINGLE_TARGET
                IRQD_AFFINITY_SET
                IRQD_SETAFFINITY_PENDING
                IRQD_AFFINITY_MANAGED
    node:     0
    affinity: 24-31
    effectiv: 24
    pending:  24-31
    
    So the interrupt is still affine to CPU 24, which was the last CPU to go
    offline of that affinity set and the move to an online CPU within 24-31,
    in this case 25, is pending. This mechanism is x86/ia64 specific as those
    architectures cannot move interrupts from thread context and do this when
    an interrupt is actually handled. So the move is set to pending.
    
    Whats worse is that offlining CPU 25 again results in:
    
    dstate:   0x01601300
                IRQD_ACTIVATED
                IRQD_IRQ_STARTED
                IRQD_SINGLE_TARGET
                IRQD_AFFINITY_SET
                IRQD_SETAFFINITY_PENDING
                IRQD_AFFINITY_MANAGED
    node:     0
    affinity: 24-31
    effectiv: 24
    pending:  24-31
    
    This means the interrupt has not been shut down, because the outgoing CPU
    is not in the effective affinity mask, but of course nothing notices that
    the effective affinity mask is pointing at an offline CPU.
    
    In the case of restarting a managed interrupt the move restriction does not
    apply, so the affinity setting can be made unconditional. This needs to be
    done _before_ the interrupt is started up as otherwise the condition for
    moving it from thread context would not longer be fulfilled.
    
    With that change applied onlining CPU 25 after offlining 31-24 results in:
    
    dstate:   0x01600200
                IRQD_ACTIVATED
                IRQD_IRQ_STARTED
                IRQD_SINGLE_TARGET
                IRQD_AFFINITY_MANAGED
    node:     0
    affinity: 24-31
    effectiv: 25
    pending:
    
    And after offlining CPU 25:
    
    dstate:   0x01a30000
                IRQD_IRQ_DISABLED
                IRQD_IRQ_MASKED
                IRQD_SINGLE_TARGET
                IRQD_AFFINITY_MANAGED
                IRQD_MANAGED_SHUTDOWN
    node:     0
    affinity: 24-31
    effectiv: 25
    pending:
    
    which is the correct and expected result.
    
    Fixes: 761ea388e8c4 ("genirq: Handle managed irqs gracefully in irq_startup()")
    Reported-by: YASUAKI ISHIMATSU <yasu.isimatu@gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: axboe@kernel.dk
    Cc: linux-scsi@vger.kernel.org
    Cc: Sumit Saxena <sumit.saxena@broadcom.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: mpe@ellerman.id.au
    Cc: Shivasharan Srikanteshwara <shivasharan.srikanteshwara@broadcom.com>
    Cc: Kashyap Desai <kashyap.desai@broadcom.com>
    Cc: keith.busch@intel.com
    Cc: peterz@infradead.org
    Cc: Hannes Reinecke <hare@suse.de>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/alpine.DEB.2.20.1710042208400.2406@nanos

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index ef89f7246656..4bff6a10ae8e 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -188,6 +188,9 @@ int irq_do_set_affinity(struct irq_data *data, const struct cpumask *mask,
 	struct irq_chip *chip = irq_data_get_irq_chip(data);
 	int ret;
 
+	if (!chip || !chip->irq_set_affinity)
+		return -EINVAL;
+
 	ret = chip->irq_set_affinity(data, mask, force);
 	switch (ret) {
 	case IRQ_SET_MASK_OK:

commit 19e1d4e947cac3b5e08225d15ad7744e691c7376
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Oct 9 12:41:36 2017 +0200

    genirq: Warn when effective affinity is not updated
    
    Emit a one time warning when the effective affinity mask is enabled in
    Kconfig, but the interrupt chip does not update the mask in its
    irq_set_affinity() callback,
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Link: http://lkml.kernel.org/r/alpine.DEB.2.20.1710042208400.2406@nanos

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index d00132b5c325..ef89f7246656 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -168,6 +168,19 @@ void irq_set_thread_affinity(struct irq_desc *desc)
 			set_bit(IRQTF_AFFINITY, &action->thread_flags);
 }
 
+static void irq_validate_effective_affinity(struct irq_data *data)
+{
+#ifdef CONFIG_GENERIC_IRQ_EFFECTIVE_AFF_MASK
+	const struct cpumask *m = irq_data_get_effective_affinity_mask(data);
+	struct irq_chip *chip = irq_data_get_irq_chip(data);
+
+	if (!cpumask_empty(m))
+		return;
+	pr_warn_once("irq_chip %s did not update eff. affinity mask of irq %u\n",
+		     chip->name, data->irq);
+#endif
+}
+
 int irq_do_set_affinity(struct irq_data *data, const struct cpumask *mask,
 			bool force)
 {
@@ -181,6 +194,7 @@ int irq_do_set_affinity(struct irq_data *data, const struct cpumask *mask,
 	case IRQ_SET_MASK_OK_DONE:
 		cpumask_copy(desc->irq_common_data.affinity, mask);
 	case IRQ_SET_MASK_OK_NOCOPY:
+		irq_validate_effective_affinity(data);
 		irq_set_thread_affinity(desc);
 		ret = 0;
 	}

commit c942cee46bba761ce97ee6d4fc71892e064e8628
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Sep 13 23:29:09 2017 +0200

    genirq: Separate activation and startup
    
    Activation of an interrupt and startup are currently a combo
    functionlity. That works so far, but upcoming changes require a strict
    separation because the activation can fail in future.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Juergen Gross <jgross@suse.com>
    Tested-by: Yu Chen <yu.c.chen@intel.com>
    Acked-by: Juergen Gross <jgross@suse.com>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Alok Kataria <akataria@vmware.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Rui Zhang <rui.zhang@intel.com>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Len Brown <lenb@kernel.org>
    Link: https://lkml.kernel.org/r/20170913213152.754334077@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0e8b48315f3c..e667912d0e9c 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -519,7 +519,7 @@ void __enable_irq(struct irq_desc *desc)
 		 * time. If it was already started up, then irq_startup()
 		 * will invoke irq_enable() under the hood.
 		 */
-		irq_startup(desc, IRQ_RESEND, IRQ_START_COND);
+		irq_startup(desc, IRQ_RESEND, IRQ_START_FORCE);
 		break;
 	}
 	default:
@@ -1325,6 +1325,21 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 				goto out_unlock;
 		}
 
+		/*
+		 * Activate the interrupt. That activation must happen
+		 * independently of IRQ_NOAUTOEN. request_irq() can fail
+		 * and the callers are supposed to handle
+		 * that. enable_irq() of an interrupt requested with
+		 * IRQ_NOAUTOEN is not supposed to fail. The activation
+		 * keeps it in shutdown mode, it merily associates
+		 * resources if necessary and if that's not possible it
+		 * fails. Interrupts which are in managed shutdown mode
+		 * will simply ignore that activation request.
+		 */
+		ret = irq_activate(desc);
+		if (ret)
+			goto out_unlock;
+
 		desc->istate &= ~(IRQS_AUTODETECT | IRQS_SPURIOUS_DISABLED | \
 				  IRQS_ONESHOT | IRQS_WAITING);
 		irqd_clear(&desc->irq_data, IRQD_IRQ_INPROGRESS);

commit e0b477941d130576d9daf31160dab6e34335b10a
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Sep 13 23:29:04 2017 +0200

    genirq/debugfs: Show debug information for all irq descriptors
    
    Currently the debugfs shows only information about actively used interrupts
    like /proc/irq/ does. That's fine for most cases, but not helpful when
    internals of allocated, but unused interrupt descriptors have to
    debugged. It's also useful to provide information about all descriptors so
    leaks can be debugged in a simpler way.
    
    Move the debugfs registration to the descriptor allocation code.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Juergen Gross <jgross@suse.com>
    Tested-by: Yu Chen <yu.c.chen@intel.com>
    Acked-by: Juergen Gross <jgross@suse.com>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Alok Kataria <akataria@vmware.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Rui Zhang <rui.zhang@intel.com>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Len Brown <lenb@kernel.org>
    Link: https://lkml.kernel.org/r/20170913213152.355525908@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index d00132b5c325..0e8b48315f3c 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1400,7 +1400,6 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		wake_up_process(new->secondary->thread);
 
 	register_irq_proc(irq, desc);
-	irq_add_debugfs_entry(irq, desc);
 	new->dir = NULL;
 	register_handler_proc(irq, new);
 	return 0;

commit 2827a418ca1b23e432e62c9b3d0e7cf3255dfe88
Author: Alexandru Moise <00moses.alexander00@gmail.com>
Date:   Tue Sep 19 22:04:12 2017 +0200

    genirq: Check __free_irq() return value for NULL
    
    __free_irq() can return a NULL irqaction for example when trying to free
    already-free IRQ, but the callsite unconditionally dereferences the
    returned pointer.
    
    Fix this by adding a check and return NULL.
    
    Signed-off-by: Alexandru Moise <00moses.alexander00@gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20170919200412.GA29985@gmail.com

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 573dc52b0806..d00132b5c325 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1643,6 +1643,10 @@ const void *free_irq(unsigned int irq, void *dev_id)
 #endif
 
 	action = __free_irq(irq, dev_id);
+
+	if (!action)
+		return NULL;
+
 	devname = action->name;
 	kfree(action);
 	return devname;

commit 0abce64a55ae44d39b92f8e672736f4f324e610f
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Fri Jun 23 21:42:57 2017 +0100

    genirq: Let irq_set_vcpu_affinity() iterate over hierarchy
    
    When assigning an interrupt to a vcpu, it is not unlikely that
    the level of the hierarchy implementing irq_set_vcpu_affinity
    is not the top level (think a generic MSI domain on top of a
    virtualization aware interrupt controller).
    
    In such a case, let's iterate over the hierarchy until we find
    an irqchip implementing it.
    
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 1d1a5b945ab4..573dc52b0806 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -400,8 +400,18 @@ int irq_set_vcpu_affinity(unsigned int irq, void *vcpu_info)
 		return -EINVAL;
 
 	data = irq_desc_get_irq_data(desc);
-	chip = irq_data_get_irq_chip(data);
-	if (chip && chip->irq_set_vcpu_affinity)
+	do {
+		chip = irq_data_get_irq_chip(data);
+		if (chip && chip->irq_set_vcpu_affinity)
+			break;
+#ifdef CONFIG_IRQ_DOMAIN_HIERARCHY
+		data = data->parent_data;
+#else
+		data = NULL;
+#endif
+	} while (data);
+
+	if (data)
 		ret = chip->irq_set_vcpu_affinity(data, vcpu_info);
 	irq_put_desc_unlock(desc, flags);
 

commit 19d39a3810e7032f311ef83effdac40339b9d022
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jul 11 23:41:52 2017 +0200

    genirq: Keep chip buslock across irq_request/release_resources()
    
    Moving the irq_request/release_resources() callbacks out of the spinlocked,
    irq disabled and bus locked region, unearthed an interesting abuse of the
    irq_bus_lock/irq_bus_sync_unlock() callbacks.
    
    The OMAP GPIO driver does merily power management inside of them. The
    irq_request_resources() callback of this GPIO irqchip calls a function
    which reads a GPIO register. That read aborts now because the clock of the
    GPIO block is not magically enabled via the irq_bus_lock() callback.
    
    Move the callbacks under the bus lock again to prevent this. In the
    free_irq() path this requires to drop the bus_lock before calling
    synchronize_irq() and reaquiring it before calling the
    irq_release_resources() callback.
    
    The bus lock can't be held because:
    
       1) The data which has been changed between bus_lock/un_lock is cached in
          the irq chip driver private data and needs to go out to the irq chip
          via the slow bus (usually SPI or I2C) before calling
          synchronize_irq().
    
          That's the reason why this bus_lock/unlock magic exists in the first
          place, as you cannot do SPI/I2C transactions while holding desc->lock
          with interrupts disabled.
    
       2) synchronize_irq() will actually deadlock, if there is a handler on
          flight. These chips use threaded handlers for obvious reasons, as
          they allow to do SPI/I2C communication. When the threaded handler
          returns then bus_lock needs to be taken in irq_finalize_oneshot() as
          we need to talk to the actual irq chip once more. After that the
          threaded handler is marked done, which makes synchronize_irq() return.
    
          So if we hold bus_lock accross the synchronize_irq() call, the
          handler cannot mark itself done because it blocks on the bus
          lock. That in turn makes synchronize_irq() wait forever on the
          threaded handler to complete....
    
    Add the missing unlock of desc->request_mutex in the error path of
    __free_irq() and add a bunch of comments to explain the locking and
    protection rules.
    
    Fixes: 46e48e257360 ("genirq: Move irq resource handling out of spinlocked region")
    Reported-and-tested-by: Sebastian Reichel <sebastian.reichel@collabora.co.uk>
    Reported-and-tested-by: Tony Lindgren <tony@atomide.com>
    Reported-by: Pavel Machek <pavel@ucw.cz>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Not-longer-ranted-at-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Linus Walleij <linus.walleij@linaro.org>
    Cc: Grygorii Strashko <grygorii.strashko@ti.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 5624b2dd6b58..1d1a5b945ab4 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1090,6 +1090,16 @@ setup_irq_thread(struct irqaction *new, unsigned int irq, bool secondary)
 /*
  * Internal function to register an irqaction - typically used to
  * allocate special interrupts that are part of the architecture.
+ *
+ * Locking rules:
+ *
+ * desc->request_mutex	Provides serialization against a concurrent free_irq()
+ *   chip_bus_lock	Provides serialization for slow bus operations
+ *     desc->lock	Provides serialization against hard interrupts
+ *
+ * chip_bus_lock and desc->lock are sufficient for all other management and
+ * interrupt related functions. desc->request_mutex solely serializes
+ * request/free_irq().
  */
 static int
 __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
@@ -1167,20 +1177,35 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	if (desc->irq_data.chip->flags & IRQCHIP_ONESHOT_SAFE)
 		new->flags &= ~IRQF_ONESHOT;
 
+	/*
+	 * Protects against a concurrent __free_irq() call which might wait
+	 * for synchronize_irq() to complete without holding the optional
+	 * chip bus lock and desc->lock.
+	 */
 	mutex_lock(&desc->request_mutex);
+
+	/*
+	 * Acquire bus lock as the irq_request_resources() callback below
+	 * might rely on the serialization or the magic power management
+	 * functions which are abusing the irq_bus_lock() callback,
+	 */
+	chip_bus_lock(desc);
+
+	/* First installed action requests resources. */
 	if (!desc->action) {
 		ret = irq_request_resources(desc);
 		if (ret) {
 			pr_err("Failed to request resources for %s (irq %d) on irqchip %s\n",
 			       new->name, irq, desc->irq_data.chip->name);
-			goto out_mutex;
+			goto out_bus_unlock;
 		}
 	}
 
-	chip_bus_lock(desc);
-
 	/*
 	 * The following block of code has to be executed atomically
+	 * protected against a concurrent interrupt and any of the other
+	 * management calls which are not serialized via
+	 * desc->request_mutex or the optional bus lock.
 	 */
 	raw_spin_lock_irqsave(&desc->lock, flags);
 	old_ptr = &desc->action;
@@ -1286,10 +1311,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 			ret = __irq_set_trigger(desc,
 						new->flags & IRQF_TRIGGER_MASK);
 
-			if (ret) {
-				irq_release_resources(desc);
+			if (ret)
 				goto out_unlock;
-			}
 		}
 
 		desc->istate &= ~(IRQS_AUTODETECT | IRQS_SPURIOUS_DISABLED | \
@@ -1385,12 +1408,10 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 out_unlock:
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 
-	chip_bus_sync_unlock(desc);
-
 	if (!desc->action)
 		irq_release_resources(desc);
-
-out_mutex:
+out_bus_unlock:
+	chip_bus_sync_unlock(desc);
 	mutex_unlock(&desc->request_mutex);
 
 out_thread:
@@ -1472,6 +1493,7 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 			WARN(1, "Trying to free already-free IRQ %d\n", irq);
 			raw_spin_unlock_irqrestore(&desc->lock, flags);
 			chip_bus_sync_unlock(desc);
+			mutex_unlock(&desc->request_mutex);
 			return NULL;
 		}
 
@@ -1498,6 +1520,20 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 #endif
 
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
+	/*
+	 * Drop bus_lock here so the changes which were done in the chip
+	 * callbacks above are synced out to the irq chips which hang
+	 * behind a slow bus (I2C, SPI) before calling synchronize_irq().
+	 *
+	 * Aside of that the bus_lock can also be taken from the threaded
+	 * handler in irq_finalize_oneshot() which results in a deadlock
+	 * because synchronize_irq() would wait forever for the thread to
+	 * complete, which is blocked on the bus lock.
+	 *
+	 * The still held desc->request_mutex() protects against a
+	 * concurrent request_irq() of this irq so the release of resources
+	 * and timing data is properly serialized.
+	 */
 	chip_bus_sync_unlock(desc);
 
 	unregister_handler_proc(irq, action);
@@ -1530,8 +1566,15 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 		}
 	}
 
+	/* Last action releases resources */
 	if (!desc->action) {
+		/*
+		 * Reaquire bus lock as irq_release_resources() might
+		 * require it to deallocate resources over the slow bus.
+		 */
+		chip_bus_lock(desc);
 		irq_release_resources(desc);
+		chip_bus_sync_unlock(desc);
 		irq_remove_timings(desc);
 	}
 

commit c80081b9209713e0fe86d3def395a9fc66503c58
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Thu Jul 6 14:29:04 2017 +0200

    genirq: Allow to pass the IRQF_TIMER flag with percpu irq request
    
    The irq timings infrastructure tracks when interrupts occur in order to
    statistically predict te next interrupt event.
    
    There is no point to track timer interrupts and try to predict them because
    the next expiration time is already known. This can be avoided via the
    IRQF_TIMER flag which is passed by timer drivers in request_irq(). It marks
    the interrupt as timer based which alloes to ignore these interrupts in the
    timings code.
    
    Per CPU interrupts which are requested via request_percpu_+irq() have no
    flag argument, so marking per cpu timer interrupts is not possible and they
    get tracked pointlessly.
    
    Add __request_percpu_irq() as a variant of request_percpu_irq() with a
    flags argument and make request_percpu_irq() an inline wrapper passing
    flags = 0.
    
    The flag parameter is restricted to IRQF_TIMER as all other IRQF_ flags
    make no sense for per cpu interrupts.
    
    The next step is to convert all existing users of request_percpu_irq() and
    then remove the wrapper and the underscores.
    
    [ tglx: Massaged changelog ]
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: peterz@infradead.org
    Cc: nicolas.pitre@linaro.org
    Cc: vincent.guittot@linaro.org
    Cc: rafael@kernel.org
    Link: http://lkml.kernel.org/r/1499344144-3964-1-git-send-email-daniel.lezcano@linaro.org

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 91e1f2390752..5624b2dd6b58 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1950,9 +1950,10 @@ int setup_percpu_irq(unsigned int irq, struct irqaction *act)
 }
 
 /**
- *	request_percpu_irq - allocate a percpu interrupt line
+ *	__request_percpu_irq - allocate a percpu interrupt line
  *	@irq: Interrupt line to allocate
  *	@handler: Function to be called when the IRQ occurs.
+ *	@flags: Interrupt type flags (IRQF_TIMER only)
  *	@devname: An ascii name for the claiming device
  *	@dev_id: A percpu cookie passed back to the handler function
  *
@@ -1965,8 +1966,9 @@ int setup_percpu_irq(unsigned int irq, struct irqaction *act)
  *	the handler gets called with the interrupted CPU's instance of
  *	that variable.
  */
-int request_percpu_irq(unsigned int irq, irq_handler_t handler,
-		       const char *devname, void __percpu *dev_id)
+int __request_percpu_irq(unsigned int irq, irq_handler_t handler,
+			 unsigned long flags, const char *devname,
+			 void __percpu *dev_id)
 {
 	struct irqaction *action;
 	struct irq_desc *desc;
@@ -1980,12 +1982,15 @@ int request_percpu_irq(unsigned int irq, irq_handler_t handler,
 	    !irq_settings_is_per_cpu_devid(desc))
 		return -EINVAL;
 
+	if (flags && flags != IRQF_TIMER)
+		return -EINVAL;
+
 	action = kzalloc(sizeof(struct irqaction), GFP_KERNEL);
 	if (!action)
 		return -ENOMEM;
 
 	action->handler = handler;
-	action->flags = IRQF_PERCPU | IRQF_NO_SUSPEND;
+	action->flags = flags | IRQF_PERCPU | IRQF_NO_SUSPEND;
 	action->name = devname;
 	action->percpu_dev_id = dev_id;
 
@@ -2004,7 +2009,7 @@ int request_percpu_irq(unsigned int irq, irq_handler_t handler,
 
 	return retval;
 }
-EXPORT_SYMBOL_GPL(request_percpu_irq);
+EXPORT_SYMBOL_GPL(__request_percpu_irq);
 
 /**
  *	irq_get_irqchip_state - returns the irqchip state of a interrupt.

commit 2343877fbda701599653e63f8dcc318aa1bf15ee
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Jun 29 23:33:39 2017 +0200

    genirq/timings: Move free timings out of spinlocked region
    
    No point to do memory management from a interrupt disabled spin locked
    region.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Heiko Stuebner <heiko@sntech.de>
    Cc: Julia Cartwright <julia@ni.com>
    Cc: Linus Walleij <linus.walleij@linaro.org>
    Cc: Brian Norris <briannorris@chromium.org>
    Cc: Doug Anderson <dianders@chromium.org>
    Cc: linux-rockchip@lists.infradead.org
    Cc: John Keeping <john@metanate.com>
    Cc: linux-gpio@vger.kernel.org
    Link: http://lkml.kernel.org/r/20170629214344.196130646@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 3e693430bfe1..91e1f2390752 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1489,7 +1489,6 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 	if (!desc->action) {
 		irq_settings_clr_disable_unlazy(desc);
 		irq_shutdown(desc);
-		irq_remove_timings(desc);
 	}
 
 #ifdef CONFIG_SMP
@@ -1531,8 +1530,10 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 		}
 	}
 
-	if (!desc->action)
+	if (!desc->action) {
 		irq_release_resources(desc);
+		irq_remove_timings(desc);
+	}
 
 	mutex_unlock(&desc->request_mutex);
 

commit 46e48e257360f0845fe17089713cbad4db611e70
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Jun 29 23:33:38 2017 +0200

    genirq: Move irq resource handling out of spinlocked region
    
    Aside of being conceptually wrong, there is also an actual (hard to
    trigger and mostly theoretical) problem.
    
    CPU0                            CPU1
    free_irq(X)                     interrupt X
                                    spin_lock(desc->lock)
                                    wake irq thread()
                                    spin_unlock(desc->lock)
    spin_lock(desc->lock)
    remove action()
    shutdown_irq()
    release_resources()             thread_handler()
    spin_unlock(desc->lock)           access released resources.
    
    synchronize_irq()
    
    Move the release resources invocation after synchronize_irq() so it's
    guaranteed that the threaded handler has finished.
    
    Move the resource request call out of the desc->lock held region as well,
    so the invocation context is the same for both request and release.
    
    This solves the problems with those functions on RT as well.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Heiko Stuebner <heiko@sntech.de>
    Cc: Julia Cartwright <julia@ni.com>
    Cc: Linus Walleij <linus.walleij@linaro.org>
    Cc: Brian Norris <briannorris@chromium.org>
    Cc: Doug Anderson <dianders@chromium.org>
    Cc: linux-rockchip@lists.infradead.org
    Cc: John Keeping <john@metanate.com>
    Cc: linux-gpio@vger.kernel.org
    Link: http://lkml.kernel.org/r/20170629214344.117028181@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0139908b8d53..3e693430bfe1 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1168,6 +1168,14 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		new->flags &= ~IRQF_ONESHOT;
 
 	mutex_lock(&desc->request_mutex);
+	if (!desc->action) {
+		ret = irq_request_resources(desc);
+		if (ret) {
+			pr_err("Failed to request resources for %s (irq %d) on irqchip %s\n",
+			       new->name, irq, desc->irq_data.chip->name);
+			goto out_mutex;
+		}
+	}
 
 	chip_bus_lock(desc);
 
@@ -1271,13 +1279,6 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	}
 
 	if (!shared) {
-		ret = irq_request_resources(desc);
-		if (ret) {
-			pr_err("Failed to request resources for %s (irq %d) on irqchip %s\n",
-			       new->name, irq, desc->irq_data.chip->name);
-			goto out_unlock;
-		}
-
 		init_waitqueue_head(&desc->wait_for_threads);
 
 		/* Setup the type (level, edge polarity) if configured: */
@@ -1386,6 +1387,10 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 	chip_bus_sync_unlock(desc);
 
+	if (!desc->action)
+		irq_release_resources(desc);
+
+out_mutex:
 	mutex_unlock(&desc->request_mutex);
 
 out_thread:
@@ -1484,7 +1489,6 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 	if (!desc->action) {
 		irq_settings_clr_disable_unlazy(desc);
 		irq_shutdown(desc);
-		irq_release_resources(desc);
 		irq_remove_timings(desc);
 	}
 
@@ -1527,6 +1531,9 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 		}
 	}
 
+	if (!desc->action)
+		irq_release_resources(desc);
+
 	mutex_unlock(&desc->request_mutex);
 
 	irq_chip_pm_put(&desc->irq_data);

commit 9114014cf4e6df0b22d764380ae1fc54f1a7a8b2
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Jun 29 23:33:37 2017 +0200

    genirq: Add mutex to irq desc to serialize request/free_irq()
    
    The irq_request/release_resources() callbacks ar currently invoked under
    desc->lock with interrupts disabled. This is a source of problems on RT and
    conceptually not required.
    
    Add a seperate mutex to struct irq_desc which allows to serialize
    request/free_irq(), which can be used to move the resource functions out of
    the desc->lock held region.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Heiko Stuebner <heiko@sntech.de>
    Cc: Julia Cartwright <julia@ni.com>
    Cc: Linus Walleij <linus.walleij@linaro.org>
    Cc: Brian Norris <briannorris@chromium.org>
    Cc: Doug Anderson <dianders@chromium.org>
    Cc: linux-rockchip@lists.infradead.org
    Cc: John Keeping <john@metanate.com>
    Cc: linux-gpio@vger.kernel.org
    Link: http://lkml.kernel.org/r/20170629214344.039220922@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0934e02fa04e..0139908b8d53 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1167,6 +1167,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	if (desc->irq_data.chip->flags & IRQCHIP_ONESHOT_SAFE)
 		new->flags &= ~IRQF_ONESHOT;
 
+	mutex_lock(&desc->request_mutex);
+
 	chip_bus_lock(desc);
 
 	/*
@@ -1350,6 +1352,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	chip_bus_sync_unlock(desc);
+	mutex_unlock(&desc->request_mutex);
 
 	irq_setup_timings(desc, new);
 
@@ -1383,6 +1386,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 	chip_bus_sync_unlock(desc);
 
+	mutex_unlock(&desc->request_mutex);
+
 out_thread:
 	if (new->thread) {
 		struct task_struct *t = new->thread;
@@ -1446,6 +1451,7 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 	if (!desc)
 		return NULL;
 
+	mutex_lock(&desc->request_mutex);
 	chip_bus_lock(desc);
 	raw_spin_lock_irqsave(&desc->lock, flags);
 
@@ -1521,6 +1527,8 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 		}
 	}
 
+	mutex_unlock(&desc->request_mutex);
+
 	irq_chip_pm_put(&desc->irq_data);
 	module_put(desc->owner);
 	kfree(action->secondary);

commit 3a90795e1e885167209056a1a90be965add30e25
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Jun 29 23:33:36 2017 +0200

    genirq: Move bus locking into __setup_irq()
    
    There is no point in having the irq_bus_lock() protection around all
    callers to __setup_irq().
    
    Move it into __setup_irq(). This is also a preparatory patch for addressing
    the issues with the irq resource callbacks.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Heiko Stuebner <heiko@sntech.de>
    Cc: Julia Cartwright <julia@ni.com>
    Cc: Linus Walleij <linus.walleij@linaro.org>
    Cc: Brian Norris <briannorris@chromium.org>
    Cc: Doug Anderson <dianders@chromium.org>
    Cc: linux-rockchip@lists.infradead.org
    Cc: John Keeping <john@metanate.com>
    Cc: linux-gpio@vger.kernel.org
    Link: http://lkml.kernel.org/r/20170629214343.960949031@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 5c11c1730ba5..0934e02fa04e 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1167,6 +1167,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	if (desc->irq_data.chip->flags & IRQCHIP_ONESHOT_SAFE)
 		new->flags &= ~IRQF_ONESHOT;
 
+	chip_bus_lock(desc);
+
 	/*
 	 * The following block of code has to be executed atomically
 	 */
@@ -1347,6 +1349,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	}
 
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
+	chip_bus_sync_unlock(desc);
 
 	irq_setup_timings(desc, new);
 
@@ -1378,6 +1381,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 out_unlock:
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 
+	chip_bus_sync_unlock(desc);
+
 out_thread:
 	if (new->thread) {
 		struct task_struct *t = new->thread;
@@ -1417,9 +1422,7 @@ int setup_irq(unsigned int irq, struct irqaction *act)
 	if (retval < 0)
 		return retval;
 
-	chip_bus_lock(desc);
 	retval = __setup_irq(irq, desc, act);
-	chip_bus_sync_unlock(desc);
 
 	if (retval)
 		irq_chip_pm_put(&desc->irq_data);
@@ -1674,9 +1677,7 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 		return retval;
 	}
 
-	chip_bus_lock(desc);
 	retval = __setup_irq(irq, desc, action);
-	chip_bus_sync_unlock(desc);
 
 	if (retval) {
 		irq_chip_pm_put(&desc->irq_data);
@@ -1924,9 +1925,7 @@ int setup_percpu_irq(unsigned int irq, struct irqaction *act)
 	if (retval < 0)
 		return retval;
 
-	chip_bus_lock(desc);
 	retval = __setup_irq(irq, desc, act);
-	chip_bus_sync_unlock(desc);
 
 	if (retval)
 		irq_chip_pm_put(&desc->irq_data);
@@ -1980,9 +1979,7 @@ int request_percpu_irq(unsigned int irq, irq_handler_t handler,
 		return retval;
 	}
 
-	chip_bus_lock(desc);
 	retval = __setup_irq(irq, desc, action);
-	chip_bus_sync_unlock(desc);
 
 	if (retval) {
 		irq_chip_pm_put(&desc->irq_data);

commit b2d3d61adb7b73cfe5f82404f7a130a76fc64232
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Fri Jun 23 16:11:07 2017 +0200

    genirq/timings: Add infrastructure to track the interrupt timings
    
    The interrupt framework gives a lot of information about each interrupt. It
    does not keep track of when those interrupts occur though, which is a
    prerequisite for estimating the next interrupt arrival for power management
    purposes.
    
    Add a mechanism to record the timestamp for each interrupt occurrences in a
    per-CPU circular buffer to help with the prediction of the next occurrence
    using a statistical model.
    
    Each CPU can store up to IRQ_TIMINGS_SIZE events <irq, timestamp>, the
    current value of IRQ_TIMINGS_SIZE is 32.
    
    Each event is encoded into a single u64, where the high 48 bits are used
    for the timestamp and the low 16 bits are for the irq number.
    
    A static key is introduced so when the irq prediction is switched off at
    runtime, the overhead is near to zero.
    
    It results in most of the code in internals.h for inline reasons and a very
    few in the new file timings.c. The latter will contain more in the next patch
    which will provide the statistical model for the next event prediction.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Nicolas Pitre <nicolas.pitre@linaro.org>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Vincent Guittot <vincent.guittot@linaro.org>
    Cc: "Rafael J . Wysocki" <rafael@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Link: http://lkml.kernel.org/r/1498227072-5980-1-git-send-email-daniel.lezcano@linaro.org

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 3577c091ac7b..5c11c1730ba5 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1348,6 +1348,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 
+	irq_setup_timings(desc, new);
+
 	/*
 	 * Strictly no need to wake it up, but hung_task complains
 	 * when no hard interrupt wakes the thread up.
@@ -1474,6 +1476,7 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 		irq_settings_clr_disable_unlazy(desc);
 		irq_shutdown(desc);
 		irq_release_resources(desc);
+		irq_remove_timings(desc);
 	}
 
 #ifdef CONFIG_SMP

commit 4cde9c6b826834b861a2b58653ab33150f562064
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 20 01:37:49 2017 +0200

    genirq: Add force argument to irq_startup()
    
    In order to handle managed interrupts gracefully on irq_startup() so they
    won't lose their assigned affinity, it's necessary to allow startups which
    keep the interrupts in managed shutdown state, if none of the assigend CPUs
    is online. This allows drivers to request interrupts w/o the CPUs being
    online, which avoid online/offline churn in drivers.
    
    Add a force argument which can override that decision and let only
    request_irq() and enable_irq() allow the managed shutdown
    handling. enable_irq() is required, because the interrupt might be
    requested with IRQF_NOAUTOEN and enable_irq() invokes irq_startup() which
    would then wreckage the assignment again. All other callers force startup
    and potentially break the assigned affinity.
    
    No functional change as this only adds the function argument.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Keith Busch <keith.busch@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Link: http://lkml.kernel.org/r/20170619235447.112094565@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 7dcf19397c39..3577c091ac7b 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -509,7 +509,7 @@ void __enable_irq(struct irq_desc *desc)
 		 * time. If it was already started up, then irq_startup()
 		 * will invoke irq_enable() under the hood.
 		 */
-		irq_startup(desc, true);
+		irq_startup(desc, IRQ_RESEND, IRQ_START_COND);
 		break;
 	}
 	default:
@@ -1306,7 +1306,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		}
 
 		if (irq_settings_can_autoenable(desc)) {
-			irq_startup(desc, true);
+			irq_startup(desc, IRQ_RESEND, IRQ_START_COND);
 		} else {
 			/*
 			 * Shared interrupts do not go well with disabling

commit 137221df69c6f8a7002f82dc3d95052d34f5667e
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Jun 20 01:37:24 2017 +0200

    genirq: Move pending helpers to internal.h
    
    So that the affinity code can reuse them.
    
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Keith Busch <keith.busch@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20170619235445.109426284@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 1e283073cecc..7dcf19397c39 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -168,34 +168,6 @@ void irq_set_thread_affinity(struct irq_desc *desc)
 			set_bit(IRQTF_AFFINITY, &action->thread_flags);
 }
 
-#ifdef CONFIG_GENERIC_PENDING_IRQ
-static inline bool irq_can_move_pcntxt(struct irq_data *data)
-{
-	return irqd_can_move_in_process_context(data);
-}
-static inline bool irq_move_pending(struct irq_data *data)
-{
-	return irqd_is_setaffinity_pending(data);
-}
-static inline void
-irq_copy_pending(struct irq_desc *desc, const struct cpumask *mask)
-{
-	cpumask_copy(desc->pending_mask, mask);
-}
-static inline void
-irq_get_pending(struct cpumask *mask, struct irq_desc *desc)
-{
-	cpumask_copy(mask, desc->pending_mask);
-}
-#else
-static inline bool irq_can_move_pcntxt(struct irq_data *data) { return true; }
-static inline bool irq_move_pending(struct irq_data *data) { return false; }
-static inline void
-irq_copy_pending(struct irq_desc *desc, const struct cpumask *mask) { }
-static inline void
-irq_get_pending(struct cpumask *mask, struct irq_desc *desc) { }
-#endif
-
 int irq_do_set_affinity(struct irq_data *data, const struct cpumask *mask,
 			bool force)
 {

commit 2e051552df69af6d134c2592d0d6f1ac80f01190
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 20 01:37:23 2017 +0200

    genirq: Move initial affinity setup to irq_startup()
    
    The startup vs. setaffinity ordering of interrupts depends on the
    IRQF_NOAUTOEN flag. Chained interrupts are not getting any affinity
    assignment at all.
    
    A regular interrupt is started up and then the affinity is set. A
    IRQF_NOAUTOEN marked interrupt is not started up, but the affinity is set
    nevertheless.
    
    Move the affinity setup to startup_irq() so the ordering is always the same
    and chained interrupts get the proper default affinity assigned as well.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Keith Busch <keith.busch@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Link: http://lkml.kernel.org/r/20170619235445.020534783@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 907fb791ff63..1e283073cecc 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1327,6 +1327,12 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		if (new->flags & IRQF_ONESHOT)
 			desc->istate |= IRQS_ONESHOT;
 
+		/* Exclude IRQ from balancing if requested */
+		if (new->flags & IRQF_NOBALANCING) {
+			irq_settings_set_no_balancing(desc);
+			irqd_set(&desc->irq_data, IRQD_NO_BALANCING);
+		}
+
 		if (irq_settings_can_autoenable(desc)) {
 			irq_startup(desc, true);
 		} else {
@@ -1341,15 +1347,6 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 			desc->depth = 1;
 		}
 
-		/* Exclude IRQ from balancing if requested */
-		if (new->flags & IRQF_NOBALANCING) {
-			irq_settings_set_no_balancing(desc);
-			irqd_set(&desc->irq_data, IRQD_NO_BALANCING);
-		}
-
-		/* Set default affinity mask once everything is setup */
-		irq_setup_affinity(desc);
-
 	} else if (new->flags & IRQF_TRIGGER_MASK) {
 		unsigned int nmsk = new->flags & IRQF_TRIGGER_MASK;
 		unsigned int omsk = irqd_get_trigger_type(&desc->irq_data);

commit 43564bd97d0e6182bbd43b51b33254c728832551
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 20 01:37:22 2017 +0200

    genirq: Rename setup_affinity() to irq_setup_affinity()
    
    Rename it with a proper irq_ prefix and make it available for other files
    in the core code. Preparatory patch for moving the irq affinity setup
    around.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Keith Busch <keith.busch@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Link: http://lkml.kernel.org/r/20170619235444.928501004@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index e2f20d553d60..907fb791ff63 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -345,7 +345,7 @@ EXPORT_SYMBOL_GPL(irq_set_affinity_notifier);
 /*
  * Generic version of the affinity autoselector.
  */
-static int irq_setup_affinity(struct irq_desc *desc)
+int irq_setup_affinity(struct irq_desc *desc)
 {
 	struct cpumask *set = irq_default_affinity;
 	int ret, node = irq_desc_get_node(desc);
@@ -404,11 +404,6 @@ int irq_select_affinity_usr(unsigned int irq)
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	return ret;
 }
-#else
-static inline int setup_affinity(struct irq_desc *desc)
-{
-	return 0;
-}
 #endif
 
 /**

commit cba4235e6031e9318d68186f6d765c531cbea4e1
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 20 01:37:21 2017 +0200

    genirq: Remove mask argument from setup_affinity()
    
    No point to have this alloc/free dance of cpumasks. Provide a static mask
    for setup_affinity() and protect it proper.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Keith Busch <keith.busch@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Link: http://lkml.kernel.org/r/20170619235444.851571573@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 284f4eb1ffbe..e2f20d553d60 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -345,15 +345,18 @@ EXPORT_SYMBOL_GPL(irq_set_affinity_notifier);
 /*
  * Generic version of the affinity autoselector.
  */
-static int setup_affinity(struct irq_desc *desc, struct cpumask *mask)
+static int irq_setup_affinity(struct irq_desc *desc)
 {
 	struct cpumask *set = irq_default_affinity;
-	int node = irq_desc_get_node(desc);
+	int ret, node = irq_desc_get_node(desc);
+	static DEFINE_RAW_SPINLOCK(mask_lock);
+	static struct cpumask mask;
 
 	/* Excludes PER_CPU and NO_BALANCE interrupts */
 	if (!__irq_can_set_affinity(desc))
 		return 0;
 
+	raw_spin_lock(&mask_lock);
 	/*
 	 * Preserve the managed affinity setting and a userspace affinity
 	 * setup, but make sure that one of the targets is online.
@@ -367,43 +370,42 @@ static int setup_affinity(struct irq_desc *desc, struct cpumask *mask)
 			irqd_clear(&desc->irq_data, IRQD_AFFINITY_SET);
 	}
 
-	cpumask_and(mask, cpu_online_mask, set);
+	cpumask_and(&mask, cpu_online_mask, set);
 	if (node != NUMA_NO_NODE) {
 		const struct cpumask *nodemask = cpumask_of_node(node);
 
 		/* make sure at least one of the cpus in nodemask is online */
-		if (cpumask_intersects(mask, nodemask))
-			cpumask_and(mask, mask, nodemask);
+		if (cpumask_intersects(&mask, nodemask))
+			cpumask_and(&mask, &mask, nodemask);
 	}
-	irq_do_set_affinity(&desc->irq_data, mask, false);
-	return 0;
+	ret = irq_do_set_affinity(&desc->irq_data, &mask, false);
+	raw_spin_unlock(&mask_lock);
+	return ret;
 }
 #else
 /* Wrapper for ALPHA specific affinity selector magic */
-static inline int setup_affinity(struct irq_desc *d, struct cpumask *mask)
+int irq_setup_affinity(struct irq_desc *desc)
 {
-	return irq_select_affinity(irq_desc_get_irq(d));
+	return irq_select_affinity(irq_desc_get_irq(desc));
 }
 #endif
 
 /*
- * Called when affinity is set via /proc/irq
+ * Called when a bogus affinity is set via /proc/irq
  */
-int irq_select_affinity_usr(unsigned int irq, struct cpumask *mask)
+int irq_select_affinity_usr(unsigned int irq)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned long flags;
 	int ret;
 
 	raw_spin_lock_irqsave(&desc->lock, flags);
-	ret = setup_affinity(desc, mask);
+	ret = irq_setup_affinity(desc);
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	return ret;
 }
-
 #else
-static inline int
-setup_affinity(struct irq_desc *desc, struct cpumask *mask)
+static inline int setup_affinity(struct irq_desc *desc)
 {
 	return 0;
 }
@@ -1128,7 +1130,6 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	struct irqaction *old, **old_ptr;
 	unsigned long flags, thread_mask = 0;
 	int ret, nested, shared = 0;
-	cpumask_var_t mask;
 
 	if (!desc)
 		return -EINVAL;
@@ -1187,11 +1188,6 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		}
 	}
 
-	if (!alloc_cpumask_var(&mask, GFP_KERNEL)) {
-		ret = -ENOMEM;
-		goto out_thread;
-	}
-
 	/*
 	 * Drivers are often written to work w/o knowledge about the
 	 * underlying irq chip implementation, so a request for a
@@ -1256,7 +1252,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		 */
 		if (thread_mask == ~0UL) {
 			ret = -EBUSY;
-			goto out_mask;
+			goto out_unlock;
 		}
 		/*
 		 * The thread_mask for the action is or'ed to
@@ -1300,7 +1296,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		pr_err("Threaded irq requested with handler=NULL and !ONESHOT for irq %d\n",
 		       irq);
 		ret = -EINVAL;
-		goto out_mask;
+		goto out_unlock;
 	}
 
 	if (!shared) {
@@ -1308,7 +1304,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		if (ret) {
 			pr_err("Failed to request resources for %s (irq %d) on irqchip %s\n",
 			       new->name, irq, desc->irq_data.chip->name);
-			goto out_mask;
+			goto out_unlock;
 		}
 
 		init_waitqueue_head(&desc->wait_for_threads);
@@ -1320,7 +1316,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 			if (ret) {
 				irq_release_resources(desc);
-				goto out_mask;
+				goto out_unlock;
 			}
 		}
 
@@ -1357,7 +1353,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		}
 
 		/* Set default affinity mask once everything is setup */
-		setup_affinity(desc, mask);
+		irq_setup_affinity(desc);
 
 	} else if (new->flags & IRQF_TRIGGER_MASK) {
 		unsigned int nmsk = new->flags & IRQF_TRIGGER_MASK;
@@ -1401,8 +1397,6 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	irq_add_debugfs_entry(irq, desc);
 	new->dir = NULL;
 	register_handler_proc(irq, new);
-	free_cpumask_var(mask);
-
 	return 0;
 
 mismatch:
@@ -1415,9 +1409,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	}
 	ret = -EBUSY;
 
-out_mask:
+out_unlock:
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
-	free_cpumask_var(mask);
 
 out_thread:
 	if (new->thread) {

commit 087cdfb662ae50e3826e7cd2e54b6519d07b60f0
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 20 01:37:17 2017 +0200

    genirq/debugfs: Add proper debugfs interface
    
    Debugging (hierarchical) interupt domains is tedious as there is no
    information about the hierarchy and no information about states of
    interrupts in the various domain levels.
    
    Add a debugfs directory 'irq' and subdirectories 'domains' and 'irqs'.
    
    The domains directory contains the domain files. The content is information
    about the domain. If the domain is part of a hierarchy then the parent
    domains are printed as well.
    
    # ls /sys/kernel/debug/irq/domains/
    default     INTEL-IR-2      INTEL-IR-MSI-2  IO-APIC-IR-2  PCI-MSI
    DMAR-MSI    INTEL-IR-3      INTEL-IR-MSI-3  IO-APIC-IR-3  unknown-1
    INTEL-IR-0  INTEL-IR-MSI-0  IO-APIC-IR-0    IO-APIC-IR-4  VECTOR
    INTEL-IR-1  INTEL-IR-MSI-1  IO-APIC-IR-1    PCI-HT
    
    # cat /sys/kernel/debug/irq/domains/VECTOR
    name:   VECTOR
     size:   0
     mapped: 216
     flags:  0x00000041
    
    # cat /sys/kernel/debug/irq/domains/IO-APIC-IR-0
    name:   IO-APIC-IR-0
     size:   24
     mapped: 19
     flags:  0x00000041
     parent: INTEL-IR-3
        name:   INTEL-IR-3
         size:   65536
         mapped: 167
         flags:  0x00000041
         parent: VECTOR
            name:   VECTOR
             size:   0
             mapped: 216
             flags:  0x00000041
    
    Unfortunately there is no per cpu information about the VECTOR domain (yet).
    
    The irqs directory contains detailed information about mapped interrupts.
    
    # cat /sys/kernel/debug/irq/irqs/3
    handler:  handle_edge_irq
    status:   0x00004000
    istate:   0x00000000
    ddepth:   1
    wdepth:   0
    dstate:   0x01018000
                IRQD_IRQ_DISABLED
                IRQD_SINGLE_TARGET
                IRQD_MOVE_PCNTXT
    node:     0
    affinity: 0-143
    effectiv: 0
    pending:
    domain:  IO-APIC-IR-0
     hwirq:   0x3
     chip:    IR-IO-APIC
      flags:   0x10
                 IRQCHIP_SKIP_SET_WAKE
     parent:
        domain:  INTEL-IR-3
         hwirq:   0x20000
         chip:    INTEL-IR
          flags:   0x0
         parent:
            domain:  VECTOR
             hwirq:   0x3
             chip:    APIC
              flags:   0x0
    
    This was developed to simplify the debugging of the managed affinity
    changes.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Keith Busch <keith.busch@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Link: http://lkml.kernel.org/r/20170619235444.537566163@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 4c34696ca575..284f4eb1ffbe 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1398,6 +1398,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		wake_up_process(new->secondary->thread);
 
 	register_irq_proc(irq, desc);
+	irq_add_debugfs_entry(irq, desc);
 	new->dir = NULL;
 	register_handler_proc(irq, new);
 	free_cpumask_var(mask);

commit b50fb7c99217922ea36d6e38bae34d84c0587cad
Merge: 04c848d39879 41f1830f5a7a
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 20 22:08:32 2017 +0200

    Merge branch 'linus' into irq/core
    
    Get upstream changes so pending patches won't conflict.

commit fa07ab72cbb0d843429e61bf179308aed6cbe0dd
Author: Heiner Kallweit <hkallweit1@gmail.com>
Date:   Sun Jun 11 00:38:36 2017 +0200

    genirq: Release resources in __setup_irq() error path
    
    In case __irq_set_trigger() fails the resources requested via
    irq_request_resources() are not released.
    
    Add the missing release call into the error handling path.
    
    Fixes: c1bacbae8192 ("genirq: Provide irq_request/release_resources chip callbacks")
    Signed-off-by: Heiner Kallweit <hkallweit1@gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: http://lkml.kernel.org/r/655538f5-cb20-a892-ff15-fbd2dd1fa4ec@gmail.com

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 070be980c37a..425170d4439b 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1312,8 +1312,10 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 			ret = __irq_set_trigger(desc,
 						new->flags & IRQF_TRIGGER_MASK);
 
-			if (ret)
+			if (ret) {
+				irq_release_resources(desc);
 				goto out_mask;
+			}
 		}
 
 		desc->istate &= ~(IRQS_AUTODETECT | IRQS_SPURIOUS_DISABLED | \

commit 04c848d398797a626608ff48804d809ae6687163
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed May 31 11:58:33 2017 +0200

    genirq: Warn when IRQ_NOAUTOEN is used with shared interrupts
    
    Shared interrupts do not go well with disabling auto enable:
    
    1) The sharing interrupt might request it while it's still disabled and
       then wait for interrupts forever.
    
    2) The interrupt might have been requested by the driver sharing the line
       before IRQ_NOAUTOEN has been set. So the driver which expects that
       disabled state after calling request_irq() will not get what it wants.
       Even worse, when it calls enable_irq() later, it will trigger the
       unbalanced enable_irq() warning.
    
    Reported-by: Brian Norris <briannorris@chromium.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: dianders@chromium.org
    Cc: jeffy <jeffy.chen@rock-chips.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: tfiga@chromium.org
    Link: http://lkml.kernel.org/r/20170531100212.210682135@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 57056109f176..49c37f1e71c0 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1334,11 +1334,19 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		if (new->flags & IRQF_ONESHOT)
 			desc->istate |= IRQS_ONESHOT;
 
-		if (irq_settings_can_autoenable(desc))
+		if (irq_settings_can_autoenable(desc)) {
 			irq_startup(desc, true);
-		else
+		} else {
+			/*
+			 * Shared interrupts do not go well with disabling
+			 * auto enable. The sharing interrupt might request
+			 * it while it's still disabled and then wait for
+			 * interrupts forever.
+			 */
+			WARN_ON_ONCE(new->flags & IRQF_SHARED);
 			/* Undo nested disables: */
 			desc->depth = 1;
+		}
 
 		/* Exclude IRQ from balancing if requested */
 		if (new->flags & IRQF_NOBALANCING) {

commit 201d7f47f34bd7cb19161d0426f13b141e381f30
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed May 31 11:58:32 2017 +0200

    genirq: Handle NOAUTOEN interrupt setup proper
    
    If an interrupt is marked NOAUTOEN then request_irq() installs the action,
    but does not enable the interrupt via startup_irq().  The interrupt is
    enabled via enable_irq() later from the driver. enable_irq() calls
    irq_enable().
    
    That means that for interrupts which have a irq_startup() callback this
    callback is never invoked. Neither is irq_domain_activate_irq() invoked for
    such interrupts.
    
    If an interrupt depends on irq_startup() or irq_domain_activate_irq() then
    the enable via irq_enable() is not enough.
    
    Add a status flag IRQD_IRQ_STARTED_UP and use this to select the proper
    mechanism in enable_irq(). Use the flag also to avoid pointless calls into
    the low level functions.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: dianders@chromium.org
    Cc: jeffy <jeffy.chen@rock-chips.com>
    Cc: Brian Norris <briannorris@chromium.org>
    Cc: tfiga@chromium.org
    Link: http://lkml.kernel.org/r/20170531100212.130986205@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 070be980c37a..57056109f176 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -533,9 +533,15 @@ void __enable_irq(struct irq_desc *desc)
 			goto err_out;
 		/* Prevent probing on this irq: */
 		irq_settings_set_noprobe(desc);
-		irq_enable(desc);
-		check_irq_resend(desc);
-		/* fall-through */
+		/*
+		 * Call irq_startup() not irq_enable() here because the
+		 * interrupt might be marked NOAUTOEN. So irq_startup()
+		 * needs to be invoked when it gets enabled the first
+		 * time. If it was already started up, then irq_startup()
+		 * will invoke irq_enable() under the hood.
+		 */
+		irq_startup(desc, true);
+		break;
 	}
 	default:
 		desc->depth--;

commit 857f8640147c9fb43f20e43cbca6452710e1ca5d
Merge: 8f3207c7eab9 3146c8f4de9b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 8 19:03:25 2017 -0700

    Merge tag 'pci-v4.12-changes' of git://git.kernel.org/pub/scm/linux/kernel/git/helgaas/pci
    
    Pull PCI updates from Bjorn Helgaas:
    
     - add framework for supporting PCIe devices in Endpoint mode (Kishon
       Vijay Abraham I)
    
     - use non-postable PCI config space mappings when possible (Lorenzo
       Pieralisi)
    
     - clean up and unify mmap of PCI BARs (David Woodhouse)
    
     - export and unify Function Level Reset support (Christoph Hellwig)
    
     - avoid FLR for Intel 82579 NICs (Sasha Neftin)
    
     - add pci_request_irq() and pci_free_irq() helpers (Christoph Hellwig)
    
     - short-circuit config access failures for disconnected devices (Keith
       Busch)
    
     - remove D3 sleep delay when possible (Adrian Hunter)
    
     - freeze PME scan before suspending devices (Lukas Wunner)
    
     - stop disabling MSI/MSI-X in pci_device_shutdown() (Prarit Bhargava)
    
     - disable boot interrupt quirk for ASUS M2N-LR (Stefan Assmann)
    
     - add arch-specific alignment control to improve device passthrough by
       avoiding multiple BARs in a page (Yongji Xie)
    
     - add sysfs sriov_drivers_autoprobe to control VF driver binding
       (Bodong Wang)
    
     - allow slots below PCI-to-PCIe "reverse bridges" (Bjorn Helgaas)
    
     - fix crashes when unbinding host controllers that don't support
       removal (Brian Norris)
    
     - add driver for MicroSemi Switchtec management interface (Logan
       Gunthorpe)
    
     - add driver for Faraday Technology FTPCI100 host bridge (Linus
       Walleij)
    
     - add i.MX7D support (Andrey Smirnov)
    
     - use generic MSI support for Aardvark (Thomas Petazzoni)
    
     - make Rockchip driver modular (Brian Norris)
    
     - advertise 128-byte Read Completion Boundary support for Rockchip
       (Shawn Lin)
    
     - advertise PCI_EXP_LNKSTA_SLC for Rockchip root port (Shawn Lin)
    
     - convert atomic_t to refcount_t in HV driver (Elena Reshetova)
    
     - add CPU IRQ affinity in HV driver (K. Y. Srinivasan)
    
     - fix PCI bus removal in HV driver (Long Li)
    
     - add support for ThunderX2 DMA alias topology (Jayachandran C)
    
     - add ThunderX pass2.x 2nd node MCFG quirk (Tomasz Nowicki)
    
     - add ITE 8893 bridge DMA alias quirk (Jarod Wilson)
    
     - restrict Cavium ACS quirk only to CN81xx/CN83xx/CN88xx devices
       (Manish Jaggi)
    
    * tag 'pci-v4.12-changes' of git://git.kernel.org/pub/scm/linux/kernel/git/helgaas/pci: (146 commits)
      PCI: Don't allow unbinding host controllers that aren't prepared
      ARM: DRA7: clockdomain: Change the CLKTRCTRL of CM_PCIE_CLKSTCTRL to SW_WKUP
      MAINTAINERS: Add PCI Endpoint maintainer
      Documentation: PCI: Add userguide for PCI endpoint test function
      tools: PCI: Add sample test script to invoke pcitest
      tools: PCI: Add a userspace tool to test PCI endpoint
      Documentation: misc-devices: Add Documentation for pci-endpoint-test driver
      misc: Add host side PCI driver for PCI test function device
      PCI: Add device IDs for DRA74x and DRA72x
      dt-bindings: PCI: dra7xx: Add DT bindings to enable unaligned access
      PCI: dwc: dra7xx: Workaround for errata id i870
      dt-bindings: PCI: dra7xx: Add DT bindings for PCI dra7xx EP mode
      PCI: dwc: dra7xx: Add EP mode support
      PCI: dwc: dra7xx: Facilitate wrapper and MSI interrupts to be enabled independently
      dt-bindings: PCI: Add DT bindings for PCI designware EP mode
      PCI: dwc: designware: Add EP mode support
      Documentation: PCI: Add binding documentation for pci-test endpoint function
      ixgbe: Use pcie_flr() instead of duplicating it
      IB/hfi1: Use pcie_flr() instead of duplicating it
      PCI: imx6: Fix spelling mistake: "contol" -> "control"
      ...

commit 25ce4be72411867e0471908ee9319599035cc624
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Apr 13 09:06:41 2017 +0200

    genirq: Return the IRQ name from free_irq()
    
    This allows callers to get back at them instead of having to store it in
    another variable.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 391cb738b2db..e688e7e06772 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1574,20 +1574,27 @@ EXPORT_SYMBOL_GPL(remove_irq);
  *	have completed.
  *
  *	This function must not be called from interrupt context.
+ *
+ *	Returns the devname argument passed to request_irq.
  */
-void free_irq(unsigned int irq, void *dev_id)
+const void *free_irq(unsigned int irq, void *dev_id)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
+	struct irqaction *action;
+	const char *devname;
 
 	if (!desc || WARN_ON(irq_settings_is_per_cpu_devid(desc)))
-		return;
+		return NULL;
 
 #ifdef CONFIG_SMP
 	if (WARN_ON(desc->affinity_notify))
 		desc->affinity_notify = NULL;
 #endif
 
-	kfree(__free_irq(irq, dev_id));
+	action = __free_irq(irq, dev_id);
+	devname = action->name;
+	kfree(action);
+	return devname;
 }
 EXPORT_SYMBOL(free_irq);
 

commit a7e60e55d73c39df7bcfedb6ccf9b6b1100d960d
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Apr 13 09:06:40 2017 +0200

    genirq: Fix indentation in remove_irq()
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index a4afe5cc5af1..391cb738b2db 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1557,7 +1557,7 @@ void remove_irq(unsigned int irq, struct irqaction *act)
 	struct irq_desc *desc = irq_to_desc(irq);
 
 	if (desc && !WARN_ON(irq_settings_is_per_cpu_devid(desc)))
-	    __free_irq(irq, act->dev_id);
+		__free_irq(irq, act->dev_id);
 }
 EXPORT_SYMBOL_GPL(remove_irq);
 

commit 382bd4de61827dbaaf5fb4fb7b1f4be4a86505e7
Author: Hans de Goede <hdegoede@redhat.com>
Date:   Sat Apr 15 12:08:31 2017 +0200

    genirq: Use irqd_get_trigger_type to compare the trigger type for shared IRQs
    
    When requesting a shared irq with IRQF_TRIGGER_NONE then the irqaction
    flags get filled with the trigger type from the irq_data:
    
            if (!(new->flags & IRQF_TRIGGER_MASK))
                    new->flags |= irqd_get_trigger_type(&desc->irq_data);
    
    On the first setup_irq() the trigger type in irq_data is NONE when the
    above code executes, then the irq is started up for the first time and
    then the actual trigger type gets established, but that's too late to fix
    up new->flags.
    
    When then a second user of the irq requests the irq with IRQF_TRIGGER_NONE
    its irqaction's triggertype gets set to the actual trigger type and the
    following check fails:
    
            if (!((old->flags ^ new->flags) & IRQF_TRIGGER_MASK))
    
    Resulting in the request_irq failing with -EBUSY even though both
    users requested the irq with IRQF_SHARED | IRQF_TRIGGER_NONE
    
    Fix this by comparing the new irqaction's trigger type to the trigger type
    stored in the irq_data which correctly reflects the actual trigger type
    being used for the irq.
    
    Suggested-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Hans de Goede <hdegoede@redhat.com>
    Acked-by: Marc Zyngier <marc.zyngier@arm.com>
    Link: http://lkml.kernel.org/r/20170415100831.17073-1-hdegoede@redhat.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 155e3c3357a1..ae1c90f20381 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1212,8 +1212,10 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		 * set the trigger type must match. Also all must
 		 * agree on ONESHOT.
 		 */
+		unsigned int oldtype = irqd_get_trigger_type(&desc->irq_data);
+
 		if (!((old->flags & new->flags) & IRQF_SHARED) ||
-		    ((old->flags ^ new->flags) & IRQF_TRIGGER_MASK) ||
+		    (oldtype != (new->flags & IRQF_TRIGGER_MASK)) ||
 		    ((old->flags ^ new->flags) & IRQF_ONESHOT))
 			goto mismatch;
 

commit d170fe7dd992b313d4851ae5ab77ee7a51ed8c72
Author: Matthias Kaehlcke <mka@chromium.org>
Date:   Wed Apr 12 11:20:30 2017 -0700

    genirq: Use cpumask_available() for check of cpumask variable
    
    This fixes the following clang warning when CONFIG_CPUMASK_OFFSTACK=n:
    
    kernel/irq/manage.c:839:28: error: address of array
    'desc->irq_common_data.affinity' will always evaluate to 'true'
    [-Werror,-Wpointer-bool-conversion]
    
    Signed-off-by: Matthias Kaehlcke <mka@chromium.org>
    Cc: Grant Grundler <grundler@chromium.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Greg Hackmann <ghackmann@google.com>
    Cc: Michael Davidson <md@google.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Link: http://lkml.kernel.org/r/20170412182030.83657-2-mka@chromium.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index a4afe5cc5af1..155e3c3357a1 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -852,7 +852,7 @@ irq_thread_check_affinity(struct irq_desc *desc, struct irqaction *action)
 	 * This code is triggered unconditionally. Check the affinity
 	 * mask pointer. For CPU_MASK_OFFSTACK=n this is optimized out.
 	 */
-	if (desc->irq_common_data.affinity)
+	if (cpumask_available(desc->irq_common_data.affinity))
 		cpumask_copy(mask, desc->irq_common_data.affinity);
 	else
 		valid = false;

commit 0881e7bd341e2158b314596bcf2059e88e68f04e
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Feb 5 15:30:50 2017 +0100

    sched/headers: Prepare to move the get_task_struct()/put_task_struct() and related APIs from <linux/sched.h> to <linux/sched/task.h>
    
    But first update usage sites with the new header dependency.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 09740952e4de..a4afe5cc5af1 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -17,6 +17,7 @@
 #include <linux/slab.h>
 #include <linux/sched.h>
 #include <linux/sched/rt.h>
+#include <linux/sched/task.h>
 #include <uapi/linux/sched/types.h>
 #include <linux/task_work.h>
 

commit ae7e81c077d60507dcec139e40a6d10cf932cf4b
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 1 18:07:51 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <uapi/linux/sched/types.h>
    
    We are going to move scheduler ABI details to <uapi/linux/sched/types.h>,
    which will be used from a number of .c files.
    
    Create empty placeholder header that maps to <linux/types.h>.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 944d068b6c48..09740952e4de 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -17,6 +17,7 @@
 #include <linux/slab.h>
 #include <linux/sched.h>
 #include <linux/sched/rt.h>
+#include <uapi/linux/sched/types.h>
 #include <linux/task_work.h>
 
 #include "internals.h"

commit 9332ef9dbd172d4ab0a0141df7cb21c696a5ce96
Author: Masahiro Yamada <yamada.masahiro@socionext.com>
Date:   Mon Feb 27 14:28:47 2017 -0800

    scripts/spelling.txt: add "an user" pattern and fix typo instances
    
    Fix typos and add the following to the scripts/spelling.txt:
    
      an user||a user
      an userspace||a userspace
    
    I also added "userspace" to the list since it is a common word in Linux.
    I found some instances for "an userfaultfd", but I did not add it to the
    list.  I felt it is endless to find words that start with "user" such as
    "userland" etc., so must draw a line somewhere.
    
    Link: http://lkml.kernel.org/r/1481573103-11329-4-git-send-email-yamada.masahiro@socionext.com
    Signed-off-by: Masahiro Yamada <yamada.masahiro@socionext.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 6b669593e7eb..944d068b6c48 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -353,7 +353,7 @@ static int setup_affinity(struct irq_desc *desc, struct cpumask *mask)
 		return 0;
 
 	/*
-	 * Preserve the managed affinity setting and an userspace affinity
+	 * Preserve the managed affinity setting and a userspace affinity
 	 * setup, but make sure that one of the targets is online.
 	 */
 	if (irqd_affinity_is_managed(&desc->irq_data) ||

commit 7ee7e87dfb158e79019ea1d5ea1b0e6f2bc93ee4
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Nov 7 19:57:00 2016 +0100

    genirq: Use irq type from irqdata instead of irqdesc
    
    The type flags in the irq descriptor are there for historical reasons and
    only updated via irq_modify_status() or irq_set_type(). Both functions also
    update the type flags in irqdata. __setup_irq() is the only left over user
    of the type flags in the irq descriptor.
    
    If __setup_irq() is called with empty irq type flags, then the type flags
    are retrieved from irqdata. If an interrupt is shared, then the type flags
    are compared with the type flags stored in the irq descriptor.
    
    On x86 the ioapic does not have a irq_set_type() callback because the type
    is defined in the BIOS tables and cannot be changed. The type is stored in
    irqdata at setup time without updating the type data in the irq
    descriptor. As a result the comparison described above fails.
    
    There is no point in updating the irq descriptor flags because the only
    relevant storage is irqdata. Use the type flags from irqdata for both
    retrieval and comparison in __setup_irq() instead.
    
    Aside of that the print out in case of non matching type flags has the old
    and new type flags arguments flipped. Fix that as well.
    
    For correctness sake the flags stored in the irq descriptor should be
    removed, but this is beyond the scope of this bugfix and will be done in a
    later patch.
    
    Fixes: 4b357daed698 ("genirq: Look-up trigger type if not specified by caller")
    Reported-and-tested-by: Mika Westerberg <mika.westerberg@linux.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Jon Hunter <jonathanh@nvidia.com>
    Cc: stable@vger.kernel.org
    Link: http://lkml.kernel.org/r/alpine.DEB.2.20.1611072020360.3501@nanos
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 9c4d30483264..6b669593e7eb 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1341,12 +1341,12 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 	} else if (new->flags & IRQF_TRIGGER_MASK) {
 		unsigned int nmsk = new->flags & IRQF_TRIGGER_MASK;
-		unsigned int omsk = irq_settings_get_trigger_mask(desc);
+		unsigned int omsk = irqd_get_trigger_type(&desc->irq_data);
 
 		if (nmsk != omsk)
 			/* hope the handler works with current  trigger mode */
 			pr_warn("irq %d uses trigger mode %u; requested %u\n",
-				irq, nmsk, omsk);
+				irq, omsk, nmsk);
 	}
 
 	*old_ptr = new;

commit 3118dac501bc0317de099db81618d589503351e1
Author: Sudip Mukherjee <sudipm.mukherjee@gmail.com>
Date:   Thu Oct 6 23:06:43 2016 +0530

    kernel/irq: Export irq_set_parent()
    
    The TPS65217 driver grew interrupt support which uses
    irq_set_parent(). While it's not yet clear why this is used in the first
    place, building the driver as a module fails with:
    
     ERROR: ".irq_set_parent" [drivers/mfd/tps65217.ko] undefined!
    
    The correctness of the driver change is still investigated, but for now
    it's less trouble to export irq_set_parent() than dealing with the build
    wreckage.
    
    [ tglx: Rewrote changelog and made the export GPL ]
    
    Fixes: 6556bdacf646 ("mfd: tps65217: Add support for IRQs")
    Signed-off-by: Sudip Mukherjee <sudip.mukherjee@codethink.co.uk>
    Cc: Sudip Mukherjee <sudipm.mukherjee@gmail.com>
    Cc: Marcin Niestroj <m.niestroj@grinn-global.com>
    Cc: Grygorii Strashko <grygorii.strashko@ti.com>
    Cc: Tony Lindgren <tony@atomide.com>
    Cc: Lee Jones <lee.jones@linaro.org>
    Link: http://lkml.kernel.org/r/1475775403-27207-1-git-send-email-sudipm.mukherjee@gmail.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0c5f1a5db654..9c4d30483264 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -721,6 +721,7 @@ int irq_set_parent(int irq, int parent_irq)
 	irq_put_desc_unlock(desc, flags);
 	return 0;
 }
+EXPORT_SYMBOL_GPL(irq_set_parent);
 #endif
 
 /*

commit 16217dc79dbc599b110dda26d0421df47904bba4
Merge: ecb3f394c5db 723344dd0b2a
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Sep 14 20:53:26 2016 +0200

    Merge tag 'irqchip-4.9-1' of git://git.kernel.org/pub/scm/linux/kernel/git/maz/arm-platforms into irq/core
    
    Merge the first drop of irqchip updates for 4.9 from Marc Zyngier:
    
    - ACPI IORT core code
    - IORT support for the GICv3 ITS
    - A few of GIC cleanups

commit 00b992deaa08495ab958da5950c9ebbba27d0ddc
Author: Alexander Kuleshov <kuleshovmail@gmail.com>
Date:   Tue Jul 19 15:54:08 2016 +0600

    genirq: No need to mask non trigger mode flags before __irq_set_trigger()
    
    Some callers of __irq_set_trigger() masks all flags except trigger mode
    flags. This is unnecessary, ase __irq_set_trigger() already does this
    before usage of flags.
    
    [ tglx: Moved the flag mask and adjusted comment. Removed the hunk in
            enable_percpu_irq() as it is required there ]
    
    Signed-off-by: Alexander Kuleshov <kuleshovmail@gmail.com>
    Link: http://lkml.kernel.org/r/20160719095408.13778-1-kuleshovmail@gmail.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 73a2b786b5e9..4908617dee28 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -669,8 +669,6 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned long flags)
 		return 0;
 	}
 
-	flags &= IRQ_TYPE_SENSE_MASK;
-
 	if (chip->flags & IRQCHIP_SET_TYPE_MASKED) {
 		if (!irqd_irq_masked(&desc->irq_data))
 			mask_irq(desc);
@@ -678,7 +676,8 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned long flags)
 			unmask = 1;
 	}
 
-	/* caller masked out all except trigger mode flags */
+	/* Mask all flags except trigger mode */
+	flags &= IRQ_TYPE_SENSE_MASK;
 	ret = chip->irq_set_type(&desc->irq_data, flags);
 
 	switch (ret) {

commit 4396f46c8c628329bd35ee4b84140b8b001a11eb
Author: Shawn Lin <shawn.lin@rock-chips.com>
Date:   Mon Aug 22 16:21:52 2016 +0800

    genirq: Fix potential memleak when failing to get irq pm
    
    Obviously we should free action here if irq_chip_pm_get failed.
    
    Fixes: be45beb2df69: "genirq: Add runtime power management support for IRQ chips"
    Signed-off-by: Shawn Lin <shawn.lin@rock-chips.com>
    Cc: Jon Hunter <jonathanh@nvidia.com>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Link: http://lkml.kernel.org/r/1471854112-13006-1-git-send-email-shawn.lin@rock-chips.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 73a2b786b5e9..9530fcd27704 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1681,8 +1681,10 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 	action->dev_id = dev_id;
 
 	retval = irq_chip_pm_get(&desc->irq_data);
-	if (retval < 0)
+	if (retval < 0) {
+		kfree(action);
 		return retval;
+	}
 
 	chip_bus_lock(desc);
 	retval = __setup_irq(irq, desc, action);
@@ -1985,8 +1987,10 @@ int request_percpu_irq(unsigned int irq, irq_handler_t handler,
 	action->percpu_dev_id = dev_id;
 
 	retval = irq_chip_pm_get(&desc->irq_data);
-	if (retval < 0)
+	if (retval < 0) {
+		kfree(action);
 		return retval;
+	}
 
 	chip_bus_lock(desc);
 	retval = __setup_irq(irq, desc, action);

commit 8658be133baa92c06b6d832a436d437deb2e2a22
Merge: 4030103b9b2e 5e385a6ef31f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jul 4 12:26:05 2016 +0200

    Merge branch 'irq/for-block' into irq/core
    
    Pull the irq affinity managing code which is in a seperate branch for block
    developers to pull.

commit 06ee6d571f0e350253a8fc3492316b2be007fae2
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jul 4 17:39:24 2016 +0900

    genirq: Add affinity hint to irq allocation
    
    Add an extra argument to the irq(domain) allocation functions, so we can hand
    down affinity hints to the allocator. Thats necessary to implement proper
    support for multiqueue devices.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: linux-block@vger.kernel.org
    Cc: linux-pci@vger.kernel.org
    Cc: linux-nvme@lists.infradead.org
    Cc: axboe@fb.com
    Cc: agordeev@redhat.com
    Link: http://lkml.kernel.org/r/1467621574-8277-4-git-send-email-hch@lst.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 30658e9827f0..ad0aac6d1248 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -353,10 +353,11 @@ static int setup_affinity(struct irq_desc *desc, struct cpumask *mask)
 		return 0;
 
 	/*
-	 * Preserve an userspace affinity setup, but make sure that
-	 * one of the targets is online.
+	 * Preserve the managed affinity setting and an userspace affinity
+	 * setup, but make sure that one of the targets is online.
 	 */
-	if (irqd_has_set(&desc->irq_data, IRQD_AFFINITY_SET)) {
+	if (irqd_affinity_is_managed(&desc->irq_data) ||
+	    irqd_has_set(&desc->irq_data, IRQD_AFFINITY_SET)) {
 		if (cpumask_intersects(desc->irq_common_data.affinity,
 				       cpu_online_mask))
 			set = desc->irq_common_data.affinity;

commit 9c2555835bb3d34dfac52a0be943dcc4bedd650f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jul 4 17:39:23 2016 +0900

    genirq: Introduce IRQD_AFFINITY_MANAGED flag
    
    Interupts marked with this flag are excluded from user space interrupt
    affinity changes. Contrary to the IRQ_NO_BALANCING flag, the kernel internal
    affinity mechanism is not blocked.
    
    This flag will be used for multi-queue device interrupts.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: linux-block@vger.kernel.org
    Cc: linux-pci@vger.kernel.org
    Cc: linux-nvme@lists.infradead.org
    Cc: axboe@fb.com
    Cc: agordeev@redhat.com
    Link: http://lkml.kernel.org/r/1467621574-8277-3-git-send-email-hch@lst.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index ef0bc02c3a70..30658e9827f0 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -115,12 +115,12 @@ EXPORT_SYMBOL(synchronize_irq);
 #ifdef CONFIG_SMP
 cpumask_var_t irq_default_affinity;
 
-static int __irq_can_set_affinity(struct irq_desc *desc)
+static bool __irq_can_set_affinity(struct irq_desc *desc)
 {
 	if (!desc || !irqd_can_balance(&desc->irq_data) ||
 	    !desc->irq_data.chip || !desc->irq_data.chip->irq_set_affinity)
-		return 0;
-	return 1;
+		return false;
+	return true;
 }
 
 /**
@@ -133,6 +133,21 @@ int irq_can_set_affinity(unsigned int irq)
 	return __irq_can_set_affinity(irq_to_desc(irq));
 }
 
+/**
+ * irq_can_set_affinity_usr - Check if affinity of a irq can be set from user space
+ * @irq:	Interrupt to check
+ *
+ * Like irq_can_set_affinity() above, but additionally checks for the
+ * AFFINITY_MANAGED flag.
+ */
+bool irq_can_set_affinity_usr(unsigned int irq)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+
+	return __irq_can_set_affinity(desc) &&
+		!irqd_affinity_is_managed(&desc->irq_data);
+}
+
 /**
  *	irq_set_thread_affinity - Notify irq threads to adjust affinity
  *	@desc:		irq descriptor which has affitnity changed

commit be45beb2df6909d42a6b3b0052601b3eef878fc0
Author: Jon Hunter <jonathanh@nvidia.com>
Date:   Tue Jun 7 16:12:29 2016 +0100

    genirq: Add runtime power management support for IRQ chips
    
    Some IRQ chips may be located in a power domain outside of the CPU
    subsystem and hence will require device specific runtime power
    management. In order to support such IRQ chips, add a pointer for a
    device structure to the irq_chip structure, and if this pointer is
    populated by the IRQ chip driver and CONFIG_PM is selected in the kernel
    configuration, then the pm_runtime_get/put APIs for this chip will be
    called when an IRQ is requested/freed, respectively.
    
    Reviewed-by: Kevin Hilman <khilman@baylibre.com>
    Signed-off-by: Jon Hunter <jonathanh@nvidia.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index f78b0846afb1..00cfc852cca8 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1416,10 +1416,18 @@ int setup_irq(unsigned int irq, struct irqaction *act)
 
 	if (!desc || WARN_ON(irq_settings_is_per_cpu_devid(desc)))
 		return -EINVAL;
+
+	retval = irq_chip_pm_get(&desc->irq_data);
+	if (retval < 0)
+		return retval;
+
 	chip_bus_lock(desc);
 	retval = __setup_irq(irq, desc, act);
 	chip_bus_sync_unlock(desc);
 
+	if (retval)
+		irq_chip_pm_put(&desc->irq_data);
+
 	return retval;
 }
 EXPORT_SYMBOL_GPL(setup_irq);
@@ -1513,6 +1521,7 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 		}
 	}
 
+	irq_chip_pm_put(&desc->irq_data);
 	module_put(desc->owner);
 	kfree(action->secondary);
 	return action;
@@ -1655,11 +1664,16 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 	action->name = devname;
 	action->dev_id = dev_id;
 
+	retval = irq_chip_pm_get(&desc->irq_data);
+	if (retval < 0)
+		return retval;
+
 	chip_bus_lock(desc);
 	retval = __setup_irq(irq, desc, action);
 	chip_bus_sync_unlock(desc);
 
 	if (retval) {
+		irq_chip_pm_put(&desc->irq_data);
 		kfree(action->secondary);
 		kfree(action);
 	}
@@ -1836,6 +1850,7 @@ static struct irqaction *__free_percpu_irq(unsigned int irq, void __percpu *dev_
 
 	unregister_handler_proc(irq, action);
 
+	irq_chip_pm_put(&desc->irq_data);
 	module_put(desc->owner);
 	return action;
 
@@ -1898,10 +1913,18 @@ int setup_percpu_irq(unsigned int irq, struct irqaction *act)
 
 	if (!desc || !irq_settings_is_per_cpu_devid(desc))
 		return -EINVAL;
+
+	retval = irq_chip_pm_get(&desc->irq_data);
+	if (retval < 0)
+		return retval;
+
 	chip_bus_lock(desc);
 	retval = __setup_irq(irq, desc, act);
 	chip_bus_sync_unlock(desc);
 
+	if (retval)
+		irq_chip_pm_put(&desc->irq_data);
+
 	return retval;
 }
 
@@ -1945,12 +1968,18 @@ int request_percpu_irq(unsigned int irq, irq_handler_t handler,
 	action->name = devname;
 	action->percpu_dev_id = dev_id;
 
+	retval = irq_chip_pm_get(&desc->irq_data);
+	if (retval < 0)
+		return retval;
+
 	chip_bus_lock(desc);
 	retval = __setup_irq(irq, desc, action);
 	chip_bus_sync_unlock(desc);
 
-	if (retval)
+	if (retval) {
+		irq_chip_pm_put(&desc->irq_data);
 		kfree(action);
+	}
 
 	return retval;
 }

commit f35ad083783e8ed6ac030f5feb209f864875b413
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Mon Jun 13 10:39:44 2016 +0100

    genirq: Look-up percpu trigger type if not specified by caller
    
    As we now do for non-percpu interrupt, perform a lookup of the
    interrupt trigger if the user doesn't supply one. The difference
    here is that we can only do it at enable time (trigger configuration
    can be per-cpu as well).
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index eaedeb74b49d..f78b0846afb1 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1737,7 +1737,14 @@ void enable_percpu_irq(unsigned int irq, unsigned int type)
 	if (!desc)
 		return;
 
+	/*
+	 * If the trigger type is not specified by the caller, then
+	 * use the default for this interrupt.
+	 */
 	type &= IRQ_TYPE_SENSE_MASK;
+	if (type == IRQ_TYPE_NONE)
+		type = irqd_get_trigger_type(&desc->irq_data);
+
 	if (type != IRQ_TYPE_NONE) {
 		int ret;
 

commit 4b357daed698c95d6b5eacc1c3c4afa206071ba2
Author: Jon Hunter <jonathanh@nvidia.com>
Date:   Tue Jun 7 16:12:27 2016 +0100

    genirq: Look-up trigger type if not specified by caller
    
    For some devices the IRQ trigger type for a device is read from
    firmware, such as device-tree. The IRQ trigger type is typically read
    when the mapping for IRQ is created, which is before the IRQ is
    requested. Hence, the IRQ trigger type is programmed when mapping the
    IRQ and not when requesting the IRQ.
    
    Although this works for most cases, in order to support IRQ chips which
    require runtime power management, which may not be accessible prior
    to requesting the IRQ, it is desirable to look-up the IRQ trigger type
    when it is requested. Therefore, if the IRQ trigger type is not
    specified when __setup_irq() is called, look-up the saved IRQ trigger
    type. This will allow us to defer the programming of the trigger type
    from when the IRQ is mapped to when it is actually requested.
    
    Signed-off-by: Jon Hunter <jonathanh@nvidia.com>
    Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index ef0bc02c3a70..eaedeb74b49d 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1116,6 +1116,13 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 	new->irq = irq;
 
+	/*
+	 * If the trigger type is not specified by the caller,
+	 * then use the default for this interrupt.
+	 */
+	if (!(new->flags & IRQF_TRIGGER_MASK))
+		new->flags |= irqd_get_trigger_type(&desc->irq_data);
+
 	/*
 	 * Check whether the interrupt nests into another interrupt
 	 * thread.

commit 9b5d585d148a19bcadae81fa17ddbe3e22efb9e9
Author: Jon Hunter <jonathanh@nvidia.com>
Date:   Tue May 10 16:14:35 2016 +0100

    genirq: Ensure IRQ descriptor is valid when setting-up the IRQ
    
    In the function, setup_irq(), we don't check that the descriptor
    returned from irq_to_desc() is valid before we start using it. For
    example chip_bus_lock() called from setup_irq(), assumes that the
    descriptor pointer is valid and doesn't check before dereferencing it.
    
    In many other functions including setup/free_percpu_irq() we do check
    that the descriptor returned is not NULL and therefore add the same test
    to setup_irq() to ensure the descriptor returned is valid.
    
    Signed-off-by: Jon Hunter <jonathanh@nvidia.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index cc1cc641d653..ef0bc02c3a70 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1407,7 +1407,7 @@ int setup_irq(unsigned int irq, struct irqaction *act)
 	int retval;
 	struct irq_desc *desc = irq_to_desc(irq);
 
-	if (WARN_ON(irq_settings_is_per_cpu_devid(desc)))
+	if (!desc || WARN_ON(irq_settings_is_per_cpu_devid(desc)))
 		return -EINVAL;
 	chip_bus_lock(desc);
 	retval = __setup_irq(irq, desc, act);

commit a395d6a7e3d6e3d1d316376db0c4c8b5d2995930
Author: Joe Perches <joe@perches.com>
Date:   Tue Mar 22 14:28:09 2016 -0700

    kernel/...: convert pr_warning to pr_warn
    
    Use the more common logging method with the eventual goal of removing
    pr_warning altogether.
    
    Miscellanea:
    
     - Realign arguments
     - Coalesce formats
     - Add missing space between a few coalesced formats
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Acked-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>        [kernel/power/suspend.c]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 64731e84c982..cc1cc641d653 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1322,8 +1322,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 		if (nmsk != omsk)
 			/* hope the handler works with current  trigger mode */
-			pr_warning("irq %d uses trigger mode %u; requested %u\n",
-				   irq, nmsk, omsk);
+			pr_warn("irq %d uses trigger mode %u; requested %u\n",
+				irq, nmsk, omsk);
 	}
 
 	*old_ptr = new;

commit 277edbabf6fece057b14fb6db5e3a34e00f42f42
Merge: 271ecc5253e2 0d571b62dd8e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 16 14:10:53 2016 -0700

    Merge tag 'pm+acpi-4.6-rc1-1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull power management and ACPI updates from Rafael Wysocki:
     "This time the majority of changes go into cpufreq and they are
      significant.
    
      First off, the way CPU frequency updates are triggered is different
      now.  Instead of having to set up and manage a deferrable timer for
      each CPU in the system to evaluate and possibly change its frequency
      periodically, cpufreq governors set up callbacks to be invoked by the
      scheduler on a regular basis (basically on utilization updates).  The
      "old" governors, "ondemand" and "conservative", still do all of their
      work in process context (although that is triggered by the scheduler
      now), but intel_pstate does it all in the callback invoked by the
      scheduler with no need for any additional asynchronous processing.
    
      Of course, this eliminates the overhead related to the management of
      all those timers, but also it allows the cpufreq governor code to be
      simplified quite a bit.  On top of that, the common code and data
      structures used by the "ondemand" and "conservative" governors are
      cleaned up and made more straightforward and some long-standing and
      quite annoying problems are addressed.  In particular, the handling of
      governor sysfs attributes is modified and the related locking becomes
      more fine grained which allows some concurrency problems to be avoided
      (particularly deadlocks with the core cpufreq code).
    
      In principle, the new mechanism for triggering frequency updates
      allows utilization information to be passed from the scheduler to
      cpufreq.  Although the current code doesn't make use of it, in the
      works is a new cpufreq governor that will make decisions based on the
      scheduler's utilization data.  That should allow the scheduler and
      cpufreq to work more closely together in the long run.
    
      In addition to the core and governor changes, cpufreq drivers are
      updated too.  Fixes and optimizations go into intel_pstate, the
      cpufreq-dt driver is updated on top of some modification in the
      Operating Performance Points (OPP) framework and there are fixes and
      other updates in the powernv cpufreq driver.
    
      Apart from the cpufreq updates there is some new ACPICA material,
      including a fix for a problem introduced by previous ACPICA updates,
      and some less significant changes in the ACPI code, like CPPC code
      optimizations, ACPI processor driver cleanups and support for loading
      ACPI tables from initrd.
    
      Also updated are the generic power domains framework, the Intel RAPL
      power capping driver and the turbostat utility and we have a bunch of
      traditional assorted fixes and cleanups.
    
      Specifics:
    
       - Redesign of cpufreq governors and the intel_pstate driver to make
         them use callbacks invoked by the scheduler to trigger CPU
         frequency evaluation instead of using per-CPU deferrable timers for
         that purpose (Rafael Wysocki).
    
       - Reorganization and cleanup of cpufreq governor code to make it more
         straightforward and fix some concurrency problems in it (Rafael
         Wysocki, Viresh Kumar).
    
       - Cleanup and improvements of locking in the cpufreq core (Viresh
         Kumar).
    
       - Assorted cleanups in the cpufreq core (Rafael Wysocki, Viresh
         Kumar, Eric Biggers).
    
       - intel_pstate driver updates including fixes, optimizations and a
         modification to make it enable enable hardware-coordinated P-state
         selection (HWP) by default if supported by the processor (Philippe
         Longepe, Srinivas Pandruvada, Rafael Wysocki, Viresh Kumar, Felipe
         Franciosi).
    
       - Operating Performance Points (OPP) framework updates to improve its
         handling of voltage regulators and device clocks and updates of the
         cpufreq-dt driver on top of that (Viresh Kumar, Jon Hunter).
    
       - Updates of the powernv cpufreq driver to fix initialization and
         cleanup problems in it and correct its worker thread handling with
         respect to CPU offline, new powernv_throttle tracepoint (Shilpasri
         Bhat).
    
       - ACPI cpufreq driver optimization and cleanup (Rafael Wysocki).
    
       - ACPICA updates including one fix for a regression introduced by
         previos changes in the ACPICA code (Bob Moore, Lv Zheng, David Box,
         Colin Ian King).
    
       - Support for installing ACPI tables from initrd (Lv Zheng).
    
       - Optimizations of the ACPI CPPC code (Prashanth Prakash, Ashwin
         Chaugule).
    
       - Support for _HID(ACPI0010) devices (ACPI processor containers) and
         ACPI processor driver cleanups (Sudeep Holla).
    
       - Support for ACPI-based enumeration of the AMBA bus (Graeme Gregory,
         Aleksey Makarov).
    
       - Modification of the ACPI PCI IRQ management code to make it treat
         255 in the Interrupt Line register as "not connected" on x86 (as
         per the specification) and avoid attempts to use that value as a
         valid interrupt vector (Chen Fan).
    
       - ACPI APEI fixes related to resource leaks (Josh Hunt).
    
       - Removal of modularity from a few ACPI drivers (BGRT, GHES,
         intel_pmic_crc) that cannot be built as modules in practice (Paul
         Gortmaker).
    
       - PNP framework update to make it treat ACPI_RESOURCE_TYPE_SERIAL_BUS
         as a valid resource type (Harb Abdulhamid).
    
       - New device ID (future AMD I2C controller) in the ACPI driver for
         AMD SoCs (APD) and in the designware I2C driver (Xiangliang Yu).
    
       - Assorted ACPI cleanups (Colin Ian King, Kaiyen Chang, Oleg Drokin).
    
       - cpuidle menu governor optimization to avoid a square root
         computation in it (Rasmus Villemoes).
    
       - Fix for potential use-after-free in the generic device properties
         framework (Heikki Krogerus).
    
       - Updates of the generic power domains (genpd) framework including
         support for multiple power states of a domain, fixes and debugfs
         output improvements (Axel Haslam, Jon Hunter, Laurent Pinchart,
         Geert Uytterhoeven).
    
       - Intel RAPL power capping driver updates to reduce IPI overhead in
         it (Jacob Pan).
    
       - System suspend/hibernation code cleanups (Eric Biggers, Saurabh
         Sengar).
    
       - Year 2038 fix for the process freezer (Abhilash Jindal).
    
       - turbostat utility updates including new features (decoding of more
         registers and CPUID fields, sub-second intervals support, GFX MHz
         and RC6 printout, --out command line option), fixes (syscall jitter
         detection and workaround, reductioin of the number of syscalls
         made, fixes related to Xeon x200 processors, compiler warning
         fixes) and cleanups (Len Brown, Hubert Chrzaniuk, Chen Yu)"
    
    * tag 'pm+acpi-4.6-rc1-1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm: (182 commits)
      tools/power turbostat: bugfix: TDP MSRs print bits fixing
      tools/power turbostat: correct output for MSR_NHM_SNB_PKG_CST_CFG_CTL dump
      tools/power turbostat: call __cpuid() instead of __get_cpuid()
      tools/power turbostat: indicate SMX and SGX support
      tools/power turbostat: detect and work around syscall jitter
      tools/power turbostat: show GFX%rc6
      tools/power turbostat: show GFXMHz
      tools/power turbostat: show IRQs per CPU
      tools/power turbostat: make fewer systems calls
      tools/power turbostat: fix compiler warnings
      tools/power turbostat: add --out option for saving output in a file
      tools/power turbostat: re-name "%Busy" field to "Busy%"
      tools/power turbostat: Intel Xeon x200: fix turbo-ratio decoding
      tools/power turbostat: Intel Xeon x200: fix erroneous bclk value
      tools/power turbostat: allow sub-sec intervals
      ACPI / APEI: ERST: Fixed leaked resources in erst_init
      ACPI / APEI: Fix leaked resources
      intel_pstate: Do not skip samples partially
      intel_pstate: Remove freq calculation from intel_pstate_calc_busy()
      intel_pstate: Move intel_pstate_calc_busy() into get_target_pstate_use_performance()
      ...

commit e237a5518425155faa508a087f28269f58074b92
Author: Chen Fan <chen.fan.fnst@cn.fujitsu.com>
Date:   Mon Feb 15 12:52:01 2016 +0800

    x86/ACPI/PCI: Recognize that Interrupt Line 255 means "not connected"
    
    Per the x86-specific footnote to PCI spec r3.0, sec 6.2.4, the value 255 in
    the Interrupt Line register means "unknown" or "no connection."
    Previously, when we couldn't derive an IRQ from the _PRT, we fell back to
    using the value from Interrupt Line as an IRQ.  It's questionable whether
    we should do that at all, but the spec clearly suggests we shouldn't do it
    for the value 255 on x86.
    
    Calling request_irq() with IRQ 255 may succeed, but the driver won't
    receive any interrupts.  Or, if IRQ 255 is shared with another device, it
    may succeed, and the driver's ISR will be called at random times when the
    *other* device interrupts.  Or it may fail if another device is using IRQ
    255 with incompatible flags.  What we *want* is for request_irq() to fail
    predictably so the driver can fall back to polling.
    
    On x86, assume 255 in the Interrupt Line means the INTx line is not
    connected.  In that case, set dev->irq to IRQ_NOTCONNECTED so request_irq()
    will fail gracefully with -ENOTCONN.
    
    We found this problem on a system where Secure Boot firmware assigned
    Interrupt Line 255 to an i801_smbus device and another device was already
    using MSI-X IRQ 255.  This was in v3.10, where i801_probe() fails if
    request_irq() fails:
    
      i801_smbus 0000:00:1f.3: enabling device (0140 -> 0143)
      i801_smbus 0000:00:1f.3: can't derive routing for PCI INT C
      i801_smbus 0000:00:1f.3: PCI INT C: no GSI
      genirq: Flags mismatch irq 255. 00000080 (i801_smbus) vs. 00000000 (megasa)
      CPU: 0 PID: 2487 Comm: kworker/0:1 Not tainted 3.10.0-229.el7.x86_64 #1
      Hardware name: FUJITSU PRIMEQUEST 2800E2/D3736, BIOS PRIMEQUEST 2000 Serie5
      Call Trace:
        dump_stack+0x19/0x1b
        __setup_irq+0x54a/0x570
        request_threaded_irq+0xcc/0x170
        i801_probe+0x32f/0x508 [i2c_i801]
        local_pci_probe+0x45/0xa0
      i801_smbus 0000:00:1f.3: Failed to allocate irq 255: -16
      i801_smbus: probe of 0000:00:1f.3 failed with error -16
    
    After aeb8a3d16ae0 ("i2c: i801: Check if interrupts are disabled"),
    i801_probe() will fall back to polling if request_irq() fails.  But we
    still need this patch because request_irq() may succeed or fail depending
    on other devices in the system.  If request_irq() fails, i801_smbus will
    work by falling back to polling, but if it succeeds, i801_smbus won't work
    because it expects interrupts that it may not receive.
    
    Signed-off-by: Chen Fan <chen.fan.fnst@cn.fujitsu.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Bjorn Helgaas <bhelgaas@google.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 841187239adc..e79e60f50bce 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1609,6 +1609,9 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 	struct irq_desc *desc;
 	int retval;
 
+	if (irq == IRQ_NOTCONNECTED)
+		return -ENOTCONN;
+
 	/*
 	 * Sanity-check: shared interrupts must pass in a real dev-ID,
 	 * otherwise we'll have trouble later trying to figure out
@@ -1699,9 +1702,13 @@ EXPORT_SYMBOL(request_threaded_irq);
 int request_any_context_irq(unsigned int irq, irq_handler_t handler,
 			    unsigned long flags, const char *name, void *dev_id)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
+	struct irq_desc *desc;
 	int ret;
 
+	if (irq == IRQ_NOTCONNECTED)
+		return -ENOTCONN;
+
+	desc = irq_to_desc(irq);
 	if (!desc)
 		return -EINVAL;
 

commit f944b5a7aff05a244a6c8cac297819af09a199e4
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Thu Jan 14 10:54:13 2016 +0100

    genirq: Use a common macro to go through the actions list
    
    The irq code browses the list of actions differently to inspect the element
    one by one. Even if it is not a problem, for the sake of consistent code,
    provide a macro similar to for_each_irq_desc in order to have the same loop to
    go through the actions list and use it in the code.
    
    [ tglx: Renamed the macro ]
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Link: http://lkml.kernel.org/r/1452765253-31148-1-git-send-email-daniel.lezcano@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 841187239adc..3ddd2297ee95 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -144,13 +144,11 @@ int irq_can_set_affinity(unsigned int irq)
  */
 void irq_set_thread_affinity(struct irq_desc *desc)
 {
-	struct irqaction *action = desc->action;
+	struct irqaction *action;
 
-	while (action) {
+	for_each_action_of_desc(desc, action)
 		if (action->thread)
 			set_bit(IRQTF_AFFINITY, &action->thread_flags);
-		action = action->next;
-	}
 }
 
 #ifdef CONFIG_GENERIC_PENDING_IRQ
@@ -994,7 +992,7 @@ void irq_wake_thread(unsigned int irq, void *dev_id)
 		return;
 
 	raw_spin_lock_irqsave(&desc->lock, flags);
-	for (action = desc->action; action; action = action->next) {
+	for_each_action_of_desc(desc, action) {
 		if (action->dev_id == dev_id) {
 			if (action->thread)
 				__irq_wake_thread(desc, action);

commit 3d116a66ed9df0271b8d267093b3bfde2be19b3a
Merge: b4cee21ee057 d3b421cd07e4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 11 18:28:06 2016 -0800

    Merge branch 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull irq updates from Thomas Gleixner:
     "The irq department provides:
    
       - Support for MSI to wire bridges and a first user of it
    
       - More ACPI support for ARM/GIC
    
       - A new TS-4800 interrupt controller driver
    
       - RCU based free of interrupt descriptors to support the upcoming
         Intel VMD technology without introducing a locking nightmare
    
       - The usual pile of fixes and updates to drivers and core code"
    
    * 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (41 commits)
      irqchip/omap-intc: Add support for spurious irq handling
      irqchip/zevio: Use irq_data_get_chip_type() helper
      irqchip/omap-intc: Remove duplicate setup for IRQ chip type handler
      irqchip/ts4800: Add TS-4800 interrupt controller
      irqchip/ts4800: Add documentation for TS-4800 interrupt controller
      irq/platform-MSI: Increase the maximum MSIs the MSI framework can support
      irqchip/gicv2m: Miscellaneous fixes for v2m resources and SPI ranges
      irqchip/bcm2836: Make code more readable
      irqchip/bcm2836: Tolerate IRQs while no flag is set in ISR
      irqchip/bcm2836: Add SMP support for the 2836
      irqchip/bcm2836: Fix initialization of the LOCAL_IRQ_CNT timers
      irqchip/gic-v2m: acpi: Introducing GICv2m ACPI support
      irqchip/gic-v2m: Refactor to prepare for ACPI support
      irqdomain: Introduce is_fwnode_irqchip helper
      acpi: pci: Setup MSI domain for ACPI based pci devices
      genirq/msi: Export functions to allow MSI domains in modules
      irqchip/mbigen: Implement the mbigen irq chip operation functions
      irqchip/mbigen: Create irq domain for each mbigen device
      irqchip/mgigen: Add platform device driver for mbigen device
      dt-bindings: Documents the mbigen bindings
      ...

commit abc7e40c81d113ef4bacb556f0a77ca63ac81d85
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Dec 13 18:12:30 2015 +0100

    genirq: Prevent chip buslock deadlock
    
    If a interrupt chip utilizes chip->buslock then free_irq() can
    deadlock in the following way:
    
    CPU0                            CPU1
                                    interrupt(X) (Shared or spurious)
    free_irq(X)                     interrupt_thread(X)
    chip_bus_lock(X)
                                       irq_finalize_oneshot(X)
                                         chip_bus_lock(X)
    synchronize_irq(X)
    
    synchronize_irq() waits for the interrupt thread to complete,
    i.e. forever.
    
    Solution is simple: Drop chip_bus_lock() before calling
    synchronize_irq() as we do with the irq_desc lock. There is nothing to
    be protected after the point where irq_desc lock has been released.
    
    This adds chip_bus_lock/unlock() to the remove_irq() code path, but
    that's actually correct in the case where remove_irq() is called on
    such an interrupt. The current users of remove_irq() are not affected
    as none of those interrupts is on a chip which requires buslock.
    
    Reported-by: Fredrik Markström <fredrik.markstrom@gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0eebaeef317b..6ead200370da 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1434,6 +1434,7 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 	if (!desc)
 		return NULL;
 
+	chip_bus_lock(desc);
 	raw_spin_lock_irqsave(&desc->lock, flags);
 
 	/*
@@ -1447,7 +1448,7 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 		if (!action) {
 			WARN(1, "Trying to free already-free IRQ %d\n", irq);
 			raw_spin_unlock_irqrestore(&desc->lock, flags);
-
+			chip_bus_sync_unlock(desc);
 			return NULL;
 		}
 
@@ -1475,6 +1476,7 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 #endif
 
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
+	chip_bus_sync_unlock(desc);
 
 	unregister_handler_proc(irq, action);
 
@@ -1553,9 +1555,7 @@ void free_irq(unsigned int irq, void *dev_id)
 		desc->affinity_notify = NULL;
 #endif
 
-	chip_bus_lock(desc);
 	kfree(__free_irq(irq, dev_id));
-	chip_bus_sync_unlock(desc);
 }
 EXPORT_SYMBOL(free_irq);
 

commit f0cb32207307e9d7b3ee8117078b7a37f8d0166e
Author: Thomas Petazzoni <thomas.petazzoni@free-electrons.com>
Date:   Tue Oct 20 15:23:51 2015 +0200

    genirq: Implement irq_percpu_is_enabled()
    
    Certain interrupt controller drivers have a register set that does not
    make it easy to save/restore the mask of enabled/disabled interrupts
    at suspend/resume time. At resume time, such drivers rely on the core
    kernel irq subsystem to tell whether such or such interrupt is enabled
    or not, in order to restore the proper state in the interrupt
    controller register.
    
    While the irqd_irq_disabled() provides the relevant information for
    global interrupts, there is no similar function to query the
    enabled/disabled state of a per-CPU interrupt.
    
    Therefore, this commit complements the percpu_irq API with an
    irq_percpu_is_enabled() function.
    
    [ tglx: Simplified the implementation and added kerneldoc ]
    
    Signed-off-by: Thomas Petazzoni <thomas.petazzoni@free-electrons.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: Tawfik Bayouk <tawfik@marvell.com>
    Cc: Nadav Haklai <nadavh@marvell.com>
    Cc: Lior Amsalem <alior@marvell.com>
    Cc: Andrew Lunn <andrew@lunn.ch>
    Cc: Sebastian Hesselbarth <sebastian.hesselbarth@gmail.com>
    Cc: Gregory Clement <gregory.clement@free-electrons.com>
    Cc: Jason Cooper <jason@lakedaemon.net>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Link: http://lkml.kernel.org/r/1445347435-2333-2-git-send-email-thomas.petazzoni@free-electrons.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0eebaeef317b..c84670c373f9 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1743,6 +1743,31 @@ void enable_percpu_irq(unsigned int irq, unsigned int type)
 }
 EXPORT_SYMBOL_GPL(enable_percpu_irq);
 
+/**
+ * irq_percpu_is_enabled - Check whether the per cpu irq is enabled
+ * @irq:	Linux irq number to check for
+ *
+ * Must be called from a non migratable context. Returns the enable
+ * state of a per cpu interrupt on the current cpu.
+ */
+bool irq_percpu_is_enabled(unsigned int irq)
+{
+	unsigned int cpu = smp_processor_id();
+	struct irq_desc *desc;
+	unsigned long flags;
+	bool is_enabled;
+
+	desc = irq_get_desc_lock(irq, &flags, IRQ_GET_DESC_CHECK_PERCPU);
+	if (!desc)
+		return false;
+
+	is_enabled = cpumask_test_cpu(cpu, desc->percpu_enabled);
+	irq_put_desc_unlock(desc, flags);
+
+	return is_enabled;
+}
+EXPORT_SYMBOL_GPL(irq_percpu_is_enabled);
+
 void disable_percpu_irq(unsigned int irq)
 {
 	unsigned int cpu = smp_processor_id();

commit b0f85fa11aefc4f3e03306b4cd47f113bd57dcba
Merge: ccc9d4a6d640 f32bfb9a8ca0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Nov 4 09:41:05 2015 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking updates from David Miller:
    
    Changes of note:
    
     1) Allow to schedule ICMP packets in IPVS, from Alex Gartrell.
    
     2) Provide FIB table ID in ipv4 route dumps just as ipv6 does, from
        David Ahern.
    
     3) Allow the user to ask for the statistics to be filtered out of
        ipv4/ipv6 address netlink dumps.  From Sowmini Varadhan.
    
     4) More work to pass the network namespace context around deep into
        various packet path APIs, starting with the netfilter hooks.  From
        Eric W Biederman.
    
     5) Add layer 2 TX/RX checksum offloading to qeth driver, from Thomas
        Richter.
    
     6) Use usec resolution for SYN/ACK RTTs in TCP, from Yuchung Cheng.
    
     7) Support Very High Throughput in wireless MESH code, from Bob
        Copeland.
    
     8) Allow setting the ageing_time in switchdev/rocker.  From Scott
        Feldman.
    
     9) Properly autoload L2TP type modules, from Stephen Hemminger.
    
    10) Fix and enable offload features by default in 8139cp driver, from
        David Woodhouse.
    
    11) Support both ipv4 and ipv6 sockets in a single vxlan device, from
        Jiri Benc.
    
    12) Fix CWND limiting of thin streams in TCP, from Bendik Rønning
        Opstad.
    
    13) Fix IPSEC flowcache overflows on large systems, from Steffen
        Klassert.
    
    14) Convert bridging to track VLANs using rhashtable entries rather than
        a bitmap.  From Nikolay Aleksandrov.
    
    15) Make TCP listener handling completely lockless, this is a major
        accomplishment.  Incoming request sockets now live in the
        established hash table just like any other socket too.
    
        From Eric Dumazet.
    
    15) Provide more bridging attributes to netlink, from Nikolay
        Aleksandrov.
    
    16) Use hash based algorithm for ipv4 multipath routing, this was very
        long overdue.  From Peter Nørlund.
    
    17) Several y2038 cures, mostly avoiding timespec.  From Arnd Bergmann.
    
    18) Allow non-root execution of EBPF programs, from Alexei Starovoitov.
    
    19) Support SO_INCOMING_CPU as setsockopt, from Eric Dumazet.  This
        influences the port binding selection logic used by SO_REUSEPORT.
    
    20) Add ipv6 support to VRF, from David Ahern.
    
    21) Add support for Mellanox Spectrum switch ASIC, from Jiri Pirko.
    
    22) Add rtl8xxxu Realtek wireless driver, from Jes Sorensen.
    
    23) Implement RACK loss recovery in TCP, from Yuchung Cheng.
    
    24) Support multipath routes in MPLS, from Roopa Prabhu.
    
    25) Fix POLLOUT notification for listening sockets in AF_UNIX, from Eric
        Dumazet.
    
    26) Add new QED Qlogic river, from Yuval Mintz, Manish Chopra, and
        Sudarsana Kalluru.
    
    27) Don't fetch timestamps on AF_UNIX sockets, from Hannes Frederic
        Sowa.
    
    28) Support ipv6 geneve tunnels, from John W Linville.
    
    29) Add flood control support to switchdev layer, from Ido Schimmel.
    
    30) Fix CHECKSUM_PARTIAL handling of potentially fragmented frames, from
        Hannes Frederic Sowa.
    
    31) Support persistent maps and progs in bpf, from Daniel Borkmann.
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next: (1790 commits)
      sh_eth: use DMA barriers
      switchdev: respect SKIP_EOPNOTSUPP flag in case there is no recursion
      net: sched: kill dead code in sch_choke.c
      irda: Delete an unnecessary check before the function call "irlmp_unregister_service"
      net: dsa: mv88e6xxx: include DSA ports in VLANs
      net: dsa: mv88e6xxx: disable SA learning for DSA and CPU ports
      net/core: fix for_each_netdev_feature
      vlan: Invoke driver vlan hooks only if device is present
      arcnet/com20020: add LEDS_CLASS dependency
      bpf, verifier: annotate verbose printer with __printf
      dp83640: Only wait for timestamps for packets with timestamping enabled.
      ptp: Change ptp_class to a proper bitmask
      dp83640: Prune rx timestamp list before reading from it
      dp83640: Delay scheduled work.
      dp83640: Include hash in timestamp/packet matching
      ipv6: fix tunnel error handling
      net/mlx5e: Fix LSO vlan insertion
      net/mlx5e: Re-eanble client vlan TX acceleration
      net/mlx5e: Return error in case mlx5e_set_features() fails
      net/mlx5e: Don't allow more than max supported channels
      ...

commit e9849777d0e27cdd2902805be51da73e7c79578c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Oct 9 23:28:58 2015 +0200

    genirq: Add flag to force mask in disable_irq[_nosync]()
    
    If an irq chip does not implement the irq_disable callback, then we
    use a lazy approach for disabling the interrupt. That means that the
    interrupt is marked disabled, but the interrupt line is not
    immediately masked in the interrupt chip. It only becomes masked if
    the interrupt is raised while it's marked disabled. We use this to avoid
    possibly expensive mask/unmask operations for common case operations.
    
    Unfortunately there are devices which do not allow the interrupt to be
    disabled easily at the device level. They are forced to use
    disable_irq_nosync(). This can result in taking each interrupt twice.
    
    Instead of enforcing the non lazy mode on all interrupts of a irq
    chip, provide a settings flag, which can be set by the driver for that
    particular interrupt line.
    
    Reported-and-tested-by: Duc Dang <dhdang@apm.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Jason Cooper <jason@lakedaemon.net>
    Link: http://lkml.kernel.org/r/alpine.DEB.2.11.1510092348370.6097@nanos

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 312f9cb12805..a71175ff98d5 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1463,6 +1463,7 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 
 	/* If this was the last handler, shut down the IRQ line: */
 	if (!desc->action) {
+		irq_settings_clr_disable_unlazy(desc);
 		irq_shutdown(desc);
 		irq_release_resources(desc);
 	}

commit fcf1ae2f7a044cda9956ec7afb487296afff058e
Author: Feng Wu <feng.wu@intel.com>
Date:   Sat Oct 3 16:20:38 2015 +0800

    genirq: Make irq_set_vcpu_affinity available for CONFIG_SMP=n
    
    irq_set_vcpu_affinity() is needed when CONFIG_SMP=n, so move the
    definition out of "#ifdef CONFIG_SMP"
    
    Suggested-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Feng Wu <feng.wu@intel.com>
    Cc: jiang.liu@linux.intel.com
    Cc: pbonzini@redhat.com
    Link: http://lkml.kernel.org/r/1443860438-144926-1-git-send-email-feng.wu@intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0a63c2b20bdd..312f9cb12805 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -258,37 +258,6 @@ int irq_set_affinity_hint(unsigned int irq, const struct cpumask *m)
 }
 EXPORT_SYMBOL_GPL(irq_set_affinity_hint);
 
-/**
- *	irq_set_vcpu_affinity - Set vcpu affinity for the interrupt
- *	@irq: interrupt number to set affinity
- *	@vcpu_info: vCPU specific data
- *
- *	This function uses the vCPU specific data to set the vCPU
- *	affinity for an irq. The vCPU specific data is passed from
- *	outside, such as KVM. One example code path is as below:
- *	KVM -> IOMMU -> irq_set_vcpu_affinity().
- */
-int irq_set_vcpu_affinity(unsigned int irq, void *vcpu_info)
-{
-	unsigned long flags;
-	struct irq_desc *desc = irq_get_desc_lock(irq, &flags, 0);
-	struct irq_data *data;
-	struct irq_chip *chip;
-	int ret = -ENOSYS;
-
-	if (!desc)
-		return -EINVAL;
-
-	data = irq_desc_get_irq_data(desc);
-	chip = irq_data_get_irq_chip(data);
-	if (chip && chip->irq_set_vcpu_affinity)
-		ret = chip->irq_set_vcpu_affinity(data, vcpu_info);
-	irq_put_desc_unlock(desc, flags);
-
-	return ret;
-}
-EXPORT_SYMBOL_GPL(irq_set_vcpu_affinity);
-
 static void irq_affinity_notify(struct work_struct *work)
 {
 	struct irq_affinity_notify *notify =
@@ -424,6 +393,37 @@ setup_affinity(struct irq_desc *desc, struct cpumask *mask)
 }
 #endif
 
+/**
+ *	irq_set_vcpu_affinity - Set vcpu affinity for the interrupt
+ *	@irq: interrupt number to set affinity
+ *	@vcpu_info: vCPU specific data
+ *
+ *	This function uses the vCPU specific data to set the vCPU
+ *	affinity for an irq. The vCPU specific data is passed from
+ *	outside, such as KVM. One example code path is as below:
+ *	KVM -> IOMMU -> irq_set_vcpu_affinity().
+ */
+int irq_set_vcpu_affinity(unsigned int irq, void *vcpu_info)
+{
+	unsigned long flags;
+	struct irq_desc *desc = irq_get_desc_lock(irq, &flags, 0);
+	struct irq_data *data;
+	struct irq_chip *chip;
+	int ret = -ENOSYS;
+
+	if (!desc)
+		return -EINVAL;
+
+	data = irq_desc_get_irq_data(desc);
+	chip = irq_data_get_irq_chip(data);
+	if (chip && chip->irq_set_vcpu_affinity)
+		ret = chip->irq_set_vcpu_affinity(data, vcpu_info);
+	irq_put_desc_unlock(desc, flags);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(irq_set_vcpu_affinity);
+
 void __disable_irq(struct irq_desc *desc)
 {
 	if (!desc->depth++)

commit aec2e2ad1786eb07814ae60988e0e306cd24a6cc
Author: Maxime Ripard <maxime.ripard@free-electrons.com>
Date:   Fri Sep 25 18:09:33 2015 +0200

    irq: Export per-cpu irq allocation and de-allocation functions
    
    Some drivers might use the per-cpu interrupts and still might be built as a
    module. Export request_percpu_irq an free_percpu_irq to these user, which
    also make it consistent with enable/disable_percpu_irq that were exported.
    
    Reported-by: Willy Tarreau <w@1wt.eu>
    Signed-off-by: Maxime Ripard <maxime.ripard@free-electrons.com>
    Signed-off-by: Gregory CLEMENT <gregory.clement@free-electrons.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index a4360f0f62a5..4c213864ec45 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1761,6 +1761,7 @@ void free_percpu_irq(unsigned int irq, void __percpu *dev_id)
 	kfree(__free_percpu_irq(irq, dev_id));
 	chip_bus_sync_unlock(desc);
 }
+EXPORT_SYMBOL_GPL(free_percpu_irq);
 
 /**
  *	setup_percpu_irq - setup a per-cpu interrupt
@@ -1832,6 +1833,7 @@ int request_percpu_irq(unsigned int irq, irq_handler_t handler,
 
 	return retval;
 }
+EXPORT_SYMBOL_GPL(request_percpu_irq);
 
 /**
  *	irq_get_irqchip_state - returns the irqchip state of a interrupt.

commit a1b7febd725a2cdfc8ac245b7b7437ce4b91aecb
Author: Maxime Ripard <maxime.ripard@free-electrons.com>
Date:   Fri Sep 25 18:09:32 2015 +0200

    genirq: Fix the documentation of request_percpu_irq
    
    The documentation of request_percpu_irq is confusing and suggest that the
    interrupt is not enabled at all, while it is actually enabled on the local
    CPU.
    
    Clarify that.
    
    Signed-off-by: Maxime Ripard <maxime.ripard@free-electrons.com>
    Signed-off-by: Gregory CLEMENT <gregory.clement@free-electrons.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index f9a59f6cabd2..a4360f0f62a5 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1790,9 +1790,10 @@ int setup_percpu_irq(unsigned int irq, struct irqaction *act)
  *	@devname: An ascii name for the claiming device
  *	@dev_id: A percpu cookie passed back to the handler function
  *
- *	This call allocates interrupt resources, but doesn't
- *	automatically enable the interrupt. It has to be done on each
- *	CPU using enable_percpu_irq().
+ *	This call allocates interrupt resources and enables the
+ *	interrupt on the local CPU. If the interrupt is supposed to be
+ *	enabled on other CPUs, it has to be done on each CPU using
+ *	enable_percpu_irq().
  *
  *	Dev_id must be globally unique. It is a per-cpu variable, and
  *	the handler gets called with the interrupted CPU's instance of

commit 2a1d3ab8986d1b2f598ffc42351d94166fa0f022
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Sep 21 11:01:10 2015 +0200

    genirq: Handle force threading of irqs with primary and thread handler
    
    Force threading of interrupts does not really deal with interrupts
    which are requested with a primary and a threaded handler. The current
    policy is to leave them alone and let the primary handler run in
    interrupt context, but we set the ONESHOT flag for those interrupts as
    well.
    
    Kohji Okuno debugged a problem with the SDHCI driver where the
    interrupt thread waits for a hardware interrupt to trigger, which can't
    work well because the hardware interrupt is masked due to the ONESHOT
    flag being set. He proposed to set the ONESHOT flag only if the
    interrupt does not provide a thread handler.
    
    Though that does not work either because these interrupts can be
    shared. So the other interrupt would rightfully get the ONESHOT flag
    set and therefor the same situation would happen again.
    
    To deal with this proper, we need to force thread the primary handler
    of such interrupts as well. That means that the primary interrupt
    handler is treated as any other primary interrupt handler which is not
    marked IRQF_NO_THREAD. The threaded handler becomes a separate thread
    so the SDHCI flow logic can be handled gracefully.
    
    The same issue was reported against 4.1-rt.
    
    Reported-and-tested-by: Kohji Okuno <okuno.kohji@jp.panasonic.com>
    Reported-By: Michal Smucr <msmucr@gmail.com>
    Reported-and-tested-by: Nathan Sullivan <nathan.sullivan@ni.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Link: http://lkml.kernel.org/r/alpine.DEB.2.11.1509211058080.5606@nanos
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index f9a59f6cabd2..0a63c2b20bdd 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -730,6 +730,12 @@ static irqreturn_t irq_nested_primary_handler(int irq, void *dev_id)
 	return IRQ_NONE;
 }
 
+static irqreturn_t irq_forced_secondary_handler(int irq, void *dev_id)
+{
+	WARN(1, "Secondary action handler called for irq %d\n", irq);
+	return IRQ_NONE;
+}
+
 static int irq_wait_for_interrupt(struct irqaction *action)
 {
 	set_current_state(TASK_INTERRUPTIBLE);
@@ -756,7 +762,8 @@ static int irq_wait_for_interrupt(struct irqaction *action)
 static void irq_finalize_oneshot(struct irq_desc *desc,
 				 struct irqaction *action)
 {
-	if (!(desc->istate & IRQS_ONESHOT))
+	if (!(desc->istate & IRQS_ONESHOT) ||
+	    action->handler == irq_forced_secondary_handler)
 		return;
 again:
 	chip_bus_lock(desc);
@@ -910,6 +917,18 @@ static void irq_thread_dtor(struct callback_head *unused)
 	irq_finalize_oneshot(desc, action);
 }
 
+static void irq_wake_secondary(struct irq_desc *desc, struct irqaction *action)
+{
+	struct irqaction *secondary = action->secondary;
+
+	if (WARN_ON_ONCE(!secondary))
+		return;
+
+	raw_spin_lock_irq(&desc->lock);
+	__irq_wake_thread(desc, secondary);
+	raw_spin_unlock_irq(&desc->lock);
+}
+
 /*
  * Interrupt handler thread
  */
@@ -940,6 +959,8 @@ static int irq_thread(void *data)
 		action_ret = handler_fn(desc, action);
 		if (action_ret == IRQ_HANDLED)
 			atomic_inc(&desc->threads_handled);
+		if (action_ret == IRQ_WAKE_THREAD)
+			irq_wake_secondary(desc, action);
 
 		wake_threads_waitq(desc);
 	}
@@ -984,20 +1005,36 @@ void irq_wake_thread(unsigned int irq, void *dev_id)
 }
 EXPORT_SYMBOL_GPL(irq_wake_thread);
 
-static void irq_setup_forced_threading(struct irqaction *new)
+static int irq_setup_forced_threading(struct irqaction *new)
 {
 	if (!force_irqthreads)
-		return;
+		return 0;
 	if (new->flags & (IRQF_NO_THREAD | IRQF_PERCPU | IRQF_ONESHOT))
-		return;
+		return 0;
 
 	new->flags |= IRQF_ONESHOT;
 
-	if (!new->thread_fn) {
-		set_bit(IRQTF_FORCED_THREAD, &new->thread_flags);
-		new->thread_fn = new->handler;
-		new->handler = irq_default_primary_handler;
+	/*
+	 * Handle the case where we have a real primary handler and a
+	 * thread handler. We force thread them as well by creating a
+	 * secondary action.
+	 */
+	if (new->handler != irq_default_primary_handler && new->thread_fn) {
+		/* Allocate the secondary action */
+		new->secondary = kzalloc(sizeof(struct irqaction), GFP_KERNEL);
+		if (!new->secondary)
+			return -ENOMEM;
+		new->secondary->handler = irq_forced_secondary_handler;
+		new->secondary->thread_fn = new->thread_fn;
+		new->secondary->dev_id = new->dev_id;
+		new->secondary->irq = new->irq;
+		new->secondary->name = new->name;
 	}
+	/* Deal with the primary handler */
+	set_bit(IRQTF_FORCED_THREAD, &new->thread_flags);
+	new->thread_fn = new->handler;
+	new->handler = irq_default_primary_handler;
+	return 0;
 }
 
 static int irq_request_resources(struct irq_desc *desc)
@@ -1017,6 +1054,48 @@ static void irq_release_resources(struct irq_desc *desc)
 		c->irq_release_resources(d);
 }
 
+static int
+setup_irq_thread(struct irqaction *new, unsigned int irq, bool secondary)
+{
+	struct task_struct *t;
+	struct sched_param param = {
+		.sched_priority = MAX_USER_RT_PRIO/2,
+	};
+
+	if (!secondary) {
+		t = kthread_create(irq_thread, new, "irq/%d-%s", irq,
+				   new->name);
+	} else {
+		t = kthread_create(irq_thread, new, "irq/%d-s-%s", irq,
+				   new->name);
+		param.sched_priority -= 1;
+	}
+
+	if (IS_ERR(t))
+		return PTR_ERR(t);
+
+	sched_setscheduler_nocheck(t, SCHED_FIFO, &param);
+
+	/*
+	 * We keep the reference to the task struct even if
+	 * the thread dies to avoid that the interrupt code
+	 * references an already freed task_struct.
+	 */
+	get_task_struct(t);
+	new->thread = t;
+	/*
+	 * Tell the thread to set its affinity. This is
+	 * important for shared interrupt handlers as we do
+	 * not invoke setup_affinity() for the secondary
+	 * handlers as everything is already set up. Even for
+	 * interrupts marked with IRQF_NO_BALANCE this is
+	 * correct as we want the thread to move to the cpu(s)
+	 * on which the requesting code placed the interrupt.
+	 */
+	set_bit(IRQTF_AFFINITY, &new->thread_flags);
+	return 0;
+}
+
 /*
  * Internal function to register an irqaction - typically used to
  * allocate special interrupts that are part of the architecture.
@@ -1037,6 +1116,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	if (!try_module_get(desc->owner))
 		return -ENODEV;
 
+	new->irq = irq;
+
 	/*
 	 * Check whether the interrupt nests into another interrupt
 	 * thread.
@@ -1054,8 +1135,11 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		 */
 		new->handler = irq_nested_primary_handler;
 	} else {
-		if (irq_settings_can_thread(desc))
-			irq_setup_forced_threading(new);
+		if (irq_settings_can_thread(desc)) {
+			ret = irq_setup_forced_threading(new);
+			if (ret)
+				goto out_mput;
+		}
 	}
 
 	/*
@@ -1064,37 +1148,14 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	 * thread.
 	 */
 	if (new->thread_fn && !nested) {
-		struct task_struct *t;
-		static const struct sched_param param = {
-			.sched_priority = MAX_USER_RT_PRIO/2,
-		};
-
-		t = kthread_create(irq_thread, new, "irq/%d-%s", irq,
-				   new->name);
-		if (IS_ERR(t)) {
-			ret = PTR_ERR(t);
+		ret = setup_irq_thread(new, irq, false);
+		if (ret)
 			goto out_mput;
+		if (new->secondary) {
+			ret = setup_irq_thread(new->secondary, irq, true);
+			if (ret)
+				goto out_thread;
 		}
-
-		sched_setscheduler_nocheck(t, SCHED_FIFO, &param);
-
-		/*
-		 * We keep the reference to the task struct even if
-		 * the thread dies to avoid that the interrupt code
-		 * references an already freed task_struct.
-		 */
-		get_task_struct(t);
-		new->thread = t;
-		/*
-		 * Tell the thread to set its affinity. This is
-		 * important for shared interrupt handlers as we do
-		 * not invoke setup_affinity() for the secondary
-		 * handlers as everything is already set up. Even for
-		 * interrupts marked with IRQF_NO_BALANCE this is
-		 * correct as we want the thread to move to the cpu(s)
-		 * on which the requesting code placed the interrupt.
-		 */
-		set_bit(IRQTF_AFFINITY, &new->thread_flags);
 	}
 
 	if (!alloc_cpumask_var(&mask, GFP_KERNEL)) {
@@ -1267,7 +1328,6 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 				   irq, nmsk, omsk);
 	}
 
-	new->irq = irq;
 	*old_ptr = new;
 
 	irq_pm_install_action(desc, new);
@@ -1293,6 +1353,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	 */
 	if (new->thread)
 		wake_up_process(new->thread);
+	if (new->secondary)
+		wake_up_process(new->secondary->thread);
 
 	register_irq_proc(irq, desc);
 	new->dir = NULL;
@@ -1323,6 +1385,13 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		kthread_stop(t);
 		put_task_struct(t);
 	}
+	if (new->secondary && new->secondary->thread) {
+		struct task_struct *t = new->secondary->thread;
+
+		new->secondary->thread = NULL;
+		kthread_stop(t);
+		put_task_struct(t);
+	}
 out_mput:
 	module_put(desc->owner);
 	return ret;
@@ -1430,9 +1499,14 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 	if (action->thread) {
 		kthread_stop(action->thread);
 		put_task_struct(action->thread);
+		if (action->secondary && action->secondary->thread) {
+			kthread_stop(action->secondary->thread);
+			put_task_struct(action->secondary->thread);
+		}
 	}
 
 	module_put(desc->owner);
+	kfree(action->secondary);
 	return action;
 }
 
@@ -1576,8 +1650,10 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 	retval = __setup_irq(irq, desc, action);
 	chip_bus_sync_unlock(desc);
 
-	if (retval)
+	if (retval) {
+		kfree(action->secondary);
 		kfree(action);
+	}
 
 #ifdef CONFIG_DEBUG_SHIRQ_FIXME
 	if (!retval && (irqflags & IRQF_SHARED)) {

commit 9df872faa7e1619e9278bec00ceaed2236533530
Author: Jiang Liu <jiang.liu@linux.intel.com>
Date:   Wed Jun 3 11:47:50 2015 +0800

    genirq: Move field 'affinity' from irq_data into irq_common_data
    
    Irq affinity mask is per-irq instead of per irqchip, so move it into
    struct irq_common_data.
    
    Signed-off-by: Jiang Liu <jiang.liu@linux.intel.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Randy Dunlap <rdunlap@infradead.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Jason Cooper <jason@lakedaemon.net>
    Cc: Kevin Cernekee <cernekee@gmail.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Link: http://lkml.kernel.org/r/1433303281-27688-1-git-send-email-jiang.liu@linux.intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index ad1b064f94fe..f9a59f6cabd2 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -192,7 +192,7 @@ int irq_do_set_affinity(struct irq_data *data, const struct cpumask *mask,
 	switch (ret) {
 	case IRQ_SET_MASK_OK:
 	case IRQ_SET_MASK_OK_DONE:
-		cpumask_copy(data->affinity, mask);
+		cpumask_copy(desc->irq_common_data.affinity, mask);
 	case IRQ_SET_MASK_OK_NOCOPY:
 		irq_set_thread_affinity(desc);
 		ret = 0;
@@ -304,7 +304,7 @@ static void irq_affinity_notify(struct work_struct *work)
 	if (irq_move_pending(&desc->irq_data))
 		irq_get_pending(cpumask, desc);
 	else
-		cpumask_copy(cpumask, desc->irq_data.affinity);
+		cpumask_copy(cpumask, desc->irq_common_data.affinity);
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 
 	notify->notify(notify, cpumask);
@@ -375,9 +375,9 @@ static int setup_affinity(struct irq_desc *desc, struct cpumask *mask)
 	 * one of the targets is online.
 	 */
 	if (irqd_has_set(&desc->irq_data, IRQD_AFFINITY_SET)) {
-		if (cpumask_intersects(desc->irq_data.affinity,
+		if (cpumask_intersects(desc->irq_common_data.affinity,
 				       cpu_online_mask))
-			set = desc->irq_data.affinity;
+			set = desc->irq_common_data.affinity;
 		else
 			irqd_clear(&desc->irq_data, IRQD_AFFINITY_SET);
 	}
@@ -829,8 +829,8 @@ irq_thread_check_affinity(struct irq_desc *desc, struct irqaction *action)
 	 * This code is triggered unconditionally. Check the affinity
 	 * mask pointer. For CPU_MASK_OFFSTACK=n this is optimized out.
 	 */
-	if (desc->irq_data.affinity)
-		cpumask_copy(mask, desc->irq_data.affinity);
+	if (desc->irq_common_data.affinity)
+		cpumask_copy(mask, desc->irq_common_data.affinity);
 	else
 		valid = false;
 	raw_spin_unlock_irq(&desc->lock);

commit 1ee4fb3ee1e47f2b3c294ded383a3cd9cc2decd4
Author: Bjorn Andersson <bjorn.andersson@sonymobile.com>
Date:   Wed Jul 22 12:43:04 2015 -0700

    genirq: Export irq_[get|set]_irqchip_state()
    
    Export these functions to be able to build the Qualcomm family A PMIC
    gpio and mpp drivers as modules.
    
    [ tglx: Made them GPL exports ]
    
    Signed-off-by: Bjorn Andersson <bjorn.andersson@sonymobile.com>
    Reviewed-by: Mark Brown <broonie@kernel.org>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: <kernel-build-reports@lists.linaro.org>
    Cc: <linaro-kernel@lists.linaro.org>
    Cc: Srinivas Kandagatla <srinivas.kandagatla@linaro.org>
    Cc: Linus Walleij <linus.walleij@linaro.org>
    Link: http://lkml.kernel.org/r/1437594184-22966-1-git-send-email-bjorn.andersson@sonymobile.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 886f11508c6d..ad1b064f94fe 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1877,6 +1877,7 @@ int irq_get_irqchip_state(unsigned int irq, enum irqchip_irq_state which,
 	irq_put_desc_busunlock(desc, flags);
 	return err;
 }
+EXPORT_SYMBOL_GPL(irq_get_irqchip_state);
 
 /**
  *	irq_set_irqchip_state - set the state of a forwarded interrupt.
@@ -1922,3 +1923,4 @@ int irq_set_irqchip_state(unsigned int irq, enum irqchip_irq_state which,
 	irq_put_desc_busunlock(desc, flags);
 	return err;
 }
+EXPORT_SYMBOL_GPL(irq_set_irqchip_state);

commit a8a98eac7b238beb49b479c164303651d5a37eb6
Author: Jiang Liu <jiang.liu@linux.intel.com>
Date:   Thu Jun 4 12:13:30 2015 +0800

    genirq: Remove the irq argument from setup_affinity()
    
    Unused except for the alpha wrapper, which can retrieve if from the
    irq descriptor.
    
    Signed-off-by: Jiang Liu <jiang.liu@linux.intel.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Randy Dunlap <rdunlap@infradead.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Link: http://lkml.kernel.org/r/1433391238-19471-21-git-send-email-jiang.liu@linux.intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index f5b774223778..886f11508c6d 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -361,8 +361,7 @@ EXPORT_SYMBOL_GPL(irq_set_affinity_notifier);
 /*
  * Generic version of the affinity autoselector.
  */
-static int
-setup_affinity(unsigned int irq, struct irq_desc *desc, struct cpumask *mask)
+static int setup_affinity(struct irq_desc *desc, struct cpumask *mask)
 {
 	struct cpumask *set = irq_default_affinity;
 	int node = irq_desc_get_node(desc);
@@ -395,10 +394,10 @@ setup_affinity(unsigned int irq, struct irq_desc *desc, struct cpumask *mask)
 	return 0;
 }
 #else
-static inline int
-setup_affinity(unsigned int irq, struct irq_desc *d, struct cpumask *mask)
+/* Wrapper for ALPHA specific affinity selector magic */
+static inline int setup_affinity(struct irq_desc *d, struct cpumask *mask)
 {
-	return irq_select_affinity(irq);
+	return irq_select_affinity(irq_desc_get_irq(d));
 }
 #endif
 
@@ -412,14 +411,14 @@ int irq_select_affinity_usr(unsigned int irq, struct cpumask *mask)
 	int ret;
 
 	raw_spin_lock_irqsave(&desc->lock, flags);
-	ret = setup_affinity(irq, desc, mask);
+	ret = setup_affinity(desc, mask);
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	return ret;
 }
 
 #else
 static inline int
-setup_affinity(unsigned int irq, struct irq_desc *desc, struct cpumask *mask)
+setup_affinity(struct irq_desc *desc, struct cpumask *mask)
 {
 	return 0;
 }
@@ -1256,7 +1255,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		}
 
 		/* Set default affinity mask once everything is setup */
-		setup_affinity(irq, desc, mask);
+		setup_affinity(desc, mask);
 
 	} else if (new->flags & IRQF_TRIGGER_MASK) {
 		unsigned int nmsk = new->flags & IRQF_TRIGGER_MASK;

commit e019c249a60fc50319c5897d21d36207c257cc9e
Author: Jiang Liu <jiang.liu@linux.intel.com>
Date:   Tue Jun 23 20:29:34 2015 +0200

    genirq: Provide and use __irq_can_set_affinity()
    
    Provide a irq_desc based variant of irq_can_set_affinity() to avoid a
    redundant lookup for the core code users.
    
    [ tglx: Split out from combo patch ]
    
    Signed-off-by: Jiang Liu <jiang.liu@linux.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index d526ac1eb0d1..f5b774223778 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -115,6 +115,14 @@ EXPORT_SYMBOL(synchronize_irq);
 #ifdef CONFIG_SMP
 cpumask_var_t irq_default_affinity;
 
+static int __irq_can_set_affinity(struct irq_desc *desc)
+{
+	if (!desc || !irqd_can_balance(&desc->irq_data) ||
+	    !desc->irq_data.chip || !desc->irq_data.chip->irq_set_affinity)
+		return 0;
+	return 1;
+}
+
 /**
  *	irq_can_set_affinity - Check if the affinity of a given irq can be set
  *	@irq:		Interrupt to check
@@ -122,13 +130,7 @@ cpumask_var_t irq_default_affinity;
  */
 int irq_can_set_affinity(unsigned int irq)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
-
-	if (!desc || !irqd_can_balance(&desc->irq_data) ||
-	    !desc->irq_data.chip || !desc->irq_data.chip->irq_set_affinity)
-		return 0;
-
-	return 1;
+	return __irq_can_set_affinity(irq_to_desc(irq));
 }
 
 /**
@@ -366,7 +368,7 @@ setup_affinity(unsigned int irq, struct irq_desc *desc, struct cpumask *mask)
 	int node = irq_desc_get_node(desc);
 
 	/* Excludes PER_CPU and NO_BALANCE interrupts */
-	if (!irq_can_set_affinity(irq))
+	if (!__irq_can_set_affinity(desc))
 		return 0;
 
 	/*

commit 79ff1cda320b81dfe5feae0c5da52f029561ce93
Author: Jiang Liu <jiang.liu@linux.intel.com>
Date:   Tue Jun 23 19:52:36 2015 +0200

    genirq: Remove irq argument from __enable/__disable_irq()
    
    Solely used for debug output. Can be retrieved from irq descriptor if
    necessary.
    
    [ tglx: Split out from combo patch ]
    
    Signed-off-by: Jiang Liu <jiang.liu@linux.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0559d9c0f658..d526ac1eb0d1 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -423,7 +423,7 @@ setup_affinity(unsigned int irq, struct irq_desc *desc, struct cpumask *mask)
 }
 #endif
 
-void __disable_irq(struct irq_desc *desc, unsigned int irq)
+void __disable_irq(struct irq_desc *desc)
 {
 	if (!desc->depth++)
 		irq_disable(desc);
@@ -436,7 +436,7 @@ static int __disable_irq_nosync(unsigned int irq)
 
 	if (!desc)
 		return -EINVAL;
-	__disable_irq(desc, irq);
+	__disable_irq(desc);
 	irq_put_desc_busunlock(desc, flags);
 	return 0;
 }
@@ -503,12 +503,13 @@ bool disable_hardirq(unsigned int irq)
 }
 EXPORT_SYMBOL_GPL(disable_hardirq);
 
-void __enable_irq(struct irq_desc *desc, unsigned int irq)
+void __enable_irq(struct irq_desc *desc)
 {
 	switch (desc->depth) {
 	case 0:
  err_out:
-		WARN(1, KERN_WARNING "Unbalanced enable for IRQ %d\n", irq);
+		WARN(1, KERN_WARNING "Unbalanced enable for IRQ %d\n",
+		     irq_desc_get_irq(desc));
 		break;
 	case 1: {
 		if (desc->istate & IRQS_SUSPENDED)
@@ -546,7 +547,7 @@ void enable_irq(unsigned int irq)
 		 KERN_ERR "enable_irq before setup/request_irq: irq %u\n", irq))
 		goto out;
 
-	__enable_irq(desc, irq);
+	__enable_irq(desc);
 out:
 	irq_put_desc_busunlock(desc, flags);
 }
@@ -1280,7 +1281,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	 */
 	if (shared && (desc->istate & IRQS_SPURIOUS_DISABLED)) {
 		desc->istate &= ~IRQS_SPURIOUS_DISABLED;
-		__enable_irq(desc, irq);
+		__enable_irq(desc);
 	}
 
 	raw_spin_unlock_irqrestore(&desc->lock, flags);

commit a1ff541a40e90df05f586bf6b157083b351c4a0c
Author: Jiang Liu <jiang.liu@linux.intel.com>
Date:   Tue Jun 23 19:47:29 2015 +0200

    genirq: Remove irq arg from __irq_set_trigger()
    
    It's only required for debug output and can be retrieved from the irq
    descriptor if necessary.
    
    [ tglx: Split out from combo patch ]
    
    Signed-off-by: Jiang Liu <jiang.liu@linux.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index c2e835d19bca..0559d9c0f658 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -637,8 +637,7 @@ int can_request_irq(unsigned int irq, unsigned long irqflags)
 	return canrequest;
 }
 
-int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
-		      unsigned long flags)
+int __irq_set_trigger(struct irq_desc *desc, unsigned long flags)
 {
 	struct irq_chip *chip = desc->irq_data.chip;
 	int ret, unmask = 0;
@@ -648,7 +647,8 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 		 * IRQF_TRIGGER_* but the PIC does not support multiple
 		 * flow-types?
 		 */
-		pr_debug("No set_type function for IRQ %d (%s)\n", irq,
+		pr_debug("No set_type function for IRQ %d (%s)\n",
+			 irq_desc_get_irq(desc),
 			 chip ? (chip->name ? : "unknown") : "unknown");
 		return 0;
 	}
@@ -685,7 +685,7 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 		break;
 	default:
 		pr_err("Setting trigger mode %lu for irq %u failed (%pF)\n",
-		       flags, irq, chip->irq_set_type);
+		       flags, irq_desc_get_irq(desc), chip->irq_set_type);
 	}
 	if (unmask)
 		unmask_irq(desc);
@@ -1221,8 +1221,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 		/* Setup the type (level, edge polarity) if configured: */
 		if (new->flags & IRQF_TRIGGER_MASK) {
-			ret = __irq_set_trigger(desc, irq,
-					new->flags & IRQF_TRIGGER_MASK);
+			ret = __irq_set_trigger(desc,
+						new->flags & IRQF_TRIGGER_MASK);
 
 			if (ret)
 				goto out_mask;
@@ -1650,7 +1650,7 @@ void enable_percpu_irq(unsigned int irq, unsigned int type)
 	if (type != IRQ_TYPE_NONE) {
 		int ret;
 
-		ret = __irq_set_trigger(desc, irq, type);
+		ret = __irq_set_trigger(desc, type);
 
 		if (ret) {
 			WARN(1, "failed to set type for IRQ%d\n", irq);

commit 0798abeb7eec37dcc20f252c2195fc31c41561f9
Author: Jiang Liu <jiang.liu@linux.intel.com>
Date:   Thu Jun 4 12:13:27 2015 +0800

    genirq: Remove the irq argument from check_irq_resend()
    
    It's only used in the software resend case and can be retrieved from
    irq_desc if necessary.
    
    Signed-off-by: Jiang Liu <jiang.liu@linux.intel.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Randy Dunlap <rdunlap@infradead.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Link: http://lkml.kernel.org/r/1433391238-19471-18-git-send-email-jiang.liu@linux.intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index f9744853b656..c2e835d19bca 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -516,7 +516,7 @@ void __enable_irq(struct irq_desc *desc, unsigned int irq)
 		/* Prevent probing on this irq: */
 		irq_settings_set_noprobe(desc);
 		irq_enable(desc);
-		check_irq_resend(desc, irq);
+		check_irq_resend(desc);
 		/* fall-through */
 	}
 	default:

commit 6783011b48096b9a0c239d0f7645f93070b6eefd
Author: Jiang Liu <jiang.liu@linux.intel.com>
Date:   Mon Jun 1 16:05:13 2015 +0800

    genirq: Introduce helper function irq_data_get_node()
    
    Introduce helper function irq_data_get_node() and variants thereof to
    hide struct irq_data implementation details.
    
    Convert the core code to use them.
    
    Signed-off-by: Jiang Liu <jiang.liu@linux.intel.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Randy Dunlap <rdunlap@infradead.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Jason Cooper <jason@lakedaemon.net>
    Cc: Kevin Cernekee <cernekee@gmail.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Link: http://lkml.kernel.org/r/1433145945-789-5-git-send-email-jiang.liu@linux.intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index b1c7e8f46bfb..f9744853b656 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -363,7 +363,7 @@ static int
 setup_affinity(unsigned int irq, struct irq_desc *desc, struct cpumask *mask)
 {
 	struct cpumask *set = irq_default_affinity;
-	int node = desc->irq_data.node;
+	int node = irq_desc_get_node(desc);
 
 	/* Excludes PER_CPU and NO_BALANCE interrupts */
 	if (!irq_can_set_affinity(irq))

commit 0a4377de305684c883bf90ad21e3cbdeead70f5c
Author: Jiang Liu <jiang.liu@linux.intel.com>
Date:   Tue May 19 17:07:14 2015 +0800

    genirq: Introduce irq_set_vcpu_affinity() to target an interrupt to a VCPU
    
    With Posted-Interrupts support in Intel CPU and IOMMU, an external
    interrupt from assigned-devices could be directly delivered to a
    virtual CPU in a virtual machine. Instead of hacking KVM and Intel
    IOMMU drivers, we propose a platform independent interface to target
    an interrupt to a specific virtual CPU in a virtual machine, or set
    virtual CPU affinity for an interrupt.
    
    By adopting this new interface and the hierarchy irqdomain, we could
    easily support posted-interrupts on Intel platforms, and also provide
    flexible enough interfaces for other platforms to support similar
    features.
    
    Here is the usage scenario for this interface:
    Guest update MSI/MSI-X interrupt configuration
            -->QEMU and KVM handle this
            -->KVM call this interface (passing posted interrupts descriptor
               and guest vector)
            -->irq core will transfer the control to IOMMU
            -->IOMMU will do the real work of updating IRTE (IRTE has new
               format for VT-d Posted-Interrupts)
    
    Signed-off-by: Jiang Liu <jiang.liu@linux.intel.com>
    Signed-off-by: Feng Wu <feng.wu@intel.com>
    Link: http://lkml.kernel.org/r/1432026437-16560-2-git-send-email-feng.wu@intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index e68932bb308e..b1c7e8f46bfb 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -256,6 +256,37 @@ int irq_set_affinity_hint(unsigned int irq, const struct cpumask *m)
 }
 EXPORT_SYMBOL_GPL(irq_set_affinity_hint);
 
+/**
+ *	irq_set_vcpu_affinity - Set vcpu affinity for the interrupt
+ *	@irq: interrupt number to set affinity
+ *	@vcpu_info: vCPU specific data
+ *
+ *	This function uses the vCPU specific data to set the vCPU
+ *	affinity for an irq. The vCPU specific data is passed from
+ *	outside, such as KVM. One example code path is as below:
+ *	KVM -> IOMMU -> irq_set_vcpu_affinity().
+ */
+int irq_set_vcpu_affinity(unsigned int irq, void *vcpu_info)
+{
+	unsigned long flags;
+	struct irq_desc *desc = irq_get_desc_lock(irq, &flags, 0);
+	struct irq_data *data;
+	struct irq_chip *chip;
+	int ret = -ENOSYS;
+
+	if (!desc)
+		return -EINVAL;
+
+	data = irq_desc_get_irq_data(desc);
+	chip = irq_data_get_irq_chip(data);
+	if (chip && chip->irq_set_vcpu_affinity)
+		ret = chip->irq_set_vcpu_affinity(data, vcpu_info);
+	irq_put_desc_unlock(desc, flags);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(irq_set_vcpu_affinity);
+
 static void irq_affinity_notify(struct work_struct *work)
 {
 	struct irq_affinity_notify *notify =

commit 1b7047edfcfb257f69e306c9afbab150cb987717
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Wed Mar 18 11:01:22 2015 +0000

    genirq: Allow the irqchip state of an IRQ to be save/restored
    
    There is a number of cases where a kernel subsystem may want to
    introspect the state of an interrupt at the irqchip level:
    
    - When a peripheral is shared between virtual machines,
      its interrupt state becomes part of the guest's state,
      and must be switched accordingly. KVM on arm/arm64 requires
      this for its guest-visible timer
    - Some GPIO controllers seem to require peeking into the
      interrupt controller they are connected to to report
      their internal state
    
    This seem to be a pattern that is common enough for the core code
    to try and support this without too many horrible hacks. Introduce
    a pair of accessors (irq_get_irqchip_state/irq_set_irqchip_state)
    to retrieve the bits that can be of interest to another subsystem:
    pending, active, and masked.
    
    - irq_get_irqchip_state returns the state of the interrupt according
      to a parameter set to IRQCHIP_STATE_PENDING, IRQCHIP_STATE_ACTIVE,
      IRQCHIP_STATE_MASKED or IRQCHIP_STATE_LINE_LEVEL.
    - irq_set_irqchip_state similarly sets the state of the interrupt.
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Reviewed-by: Bjorn Andersson <bjorn.andersson@sonymobile.com>
    Tested-by: Bjorn Andersson <bjorn.andersson@sonymobile.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: Abhijeet Dharmapurikar <adharmap@codeaurora.org>
    Cc: Stephen Boyd <sboyd@codeaurora.org>
    Cc: Phong Vo <pvo@apm.com>
    Cc: Linus Walleij <linus.walleij@linaro.org>
    Cc: Tin Huynh <tnhuynh@apm.com>
    Cc: Y Vo <yvo@apm.com>
    Cc: Toan Le <toanle@apm.com>
    Cc: Bjorn Andersson <bjorn@kryo.se>
    Cc: Jason Cooper <jason@lakedaemon.net>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Link: http://lkml.kernel.org/r/1426676484-21812-2-git-send-email-marc.zyngier@arm.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index c0a1100d911f..e68932bb308e 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1798,3 +1798,94 @@ int request_percpu_irq(unsigned int irq, irq_handler_t handler,
 
 	return retval;
 }
+
+/**
+ *	irq_get_irqchip_state - returns the irqchip state of a interrupt.
+ *	@irq: Interrupt line that is forwarded to a VM
+ *	@which: One of IRQCHIP_STATE_* the caller wants to know about
+ *	@state: a pointer to a boolean where the state is to be storeed
+ *
+ *	This call snapshots the internal irqchip state of an
+ *	interrupt, returning into @state the bit corresponding to
+ *	stage @which
+ *
+ *	This function should be called with preemption disabled if the
+ *	interrupt controller has per-cpu registers.
+ */
+int irq_get_irqchip_state(unsigned int irq, enum irqchip_irq_state which,
+			  bool *state)
+{
+	struct irq_desc *desc;
+	struct irq_data *data;
+	struct irq_chip *chip;
+	unsigned long flags;
+	int err = -EINVAL;
+
+	desc = irq_get_desc_buslock(irq, &flags, 0);
+	if (!desc)
+		return err;
+
+	data = irq_desc_get_irq_data(desc);
+
+	do {
+		chip = irq_data_get_irq_chip(data);
+		if (chip->irq_get_irqchip_state)
+			break;
+#ifdef CONFIG_IRQ_DOMAIN_HIERARCHY
+		data = data->parent_data;
+#else
+		data = NULL;
+#endif
+	} while (data);
+
+	if (data)
+		err = chip->irq_get_irqchip_state(data, which, state);
+
+	irq_put_desc_busunlock(desc, flags);
+	return err;
+}
+
+/**
+ *	irq_set_irqchip_state - set the state of a forwarded interrupt.
+ *	@irq: Interrupt line that is forwarded to a VM
+ *	@which: State to be restored (one of IRQCHIP_STATE_*)
+ *	@val: Value corresponding to @which
+ *
+ *	This call sets the internal irqchip state of an interrupt,
+ *	depending on the value of @which.
+ *
+ *	This function should be called with preemption disabled if the
+ *	interrupt controller has per-cpu registers.
+ */
+int irq_set_irqchip_state(unsigned int irq, enum irqchip_irq_state which,
+			  bool val)
+{
+	struct irq_desc *desc;
+	struct irq_data *data;
+	struct irq_chip *chip;
+	unsigned long flags;
+	int err = -EINVAL;
+
+	desc = irq_get_desc_buslock(irq, &flags, 0);
+	if (!desc)
+		return err;
+
+	data = irq_desc_get_irq_data(desc);
+
+	do {
+		chip = irq_data_get_irq_chip(data);
+		if (chip->irq_set_irqchip_state)
+			break;
+#ifdef CONFIG_IRQ_DOMAIN_HIERARCHY
+		data = data->parent_data;
+#else
+		data = NULL;
+#endif
+	} while (data);
+
+	if (data)
+		err = chip->irq_set_irqchip_state(data, which, val);
+
+	irq_put_desc_busunlock(desc, flags);
+	return err;
+}

commit 462b69b1e43ceccab68a47d65b1e46520cd0fdc0
Merge: d8bf368d0631 f22e6e847115
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Apr 8 23:26:21 2015 +0200

    Merge branch 'linus' into irq/core to get the GIC updates which
    conflict with pending GIC changes.
    
    Conflicts:
            drivers/usb/isp1760/isp1760-core.c

commit 17f480342026e54000731acaa69bf32787ce46cb
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Fri Feb 27 00:07:55 2015 +0100

    genirq / PM: Add flag for shared NO_SUSPEND interrupt lines
    
    It currently is required that all users of NO_SUSPEND interrupt
    lines pass the IRQF_NO_SUSPEND flag when requesting the IRQ or the
    WARN_ON_ONCE() in irq_pm_install_action() will trigger.  That is
    done to warn about situations in which unprepared interrupt handlers
    may be run unnecessarily for suspended devices and may attempt to
    access those devices by mistake.  However, it may cause drivers
    that have no technical reasons for using IRQF_NO_SUSPEND to set
    that flag just because they happen to share the interrupt line
    with something like a timer.
    
    Moreover, the generic handling of wakeup interrupts introduced by
    commit 9ce7a25849e8 (genirq: Simplify wakeup mechanism) only works
    for IRQs without any NO_SUSPEND users, so the drivers of wakeup
    devices needing to use shared NO_SUSPEND interrupt lines for
    signaling system wakeup generally have to detect wakeup in their
    interrupt handlers.  Thus if they happen to share an interrupt line
    with a NO_SUSPEND user, they also need to request that their
    interrupt handlers be run after suspend_device_irqs().
    
    In both cases the reason for using IRQF_NO_SUSPEND is not because
    the driver in question has a genuine need to run its interrupt
    handler after suspend_device_irqs(), but because it happens to
    share the line with some other NO_SUSPEND user.  Otherwise, the
    driver would do without IRQF_NO_SUSPEND just fine.
    
    To make it possible to specify that condition explicitly, introduce
    a new IRQ action handler flag for shared IRQs, IRQF_COND_SUSPEND,
    that, when set, will indicate to the IRQ core that the interrupt
    user is generally fine with suspending the IRQ, but it also can
    tolerate handler invocations after suspend_device_irqs() and, in
    particular, it is capable of detecting system wakeup and triggering
    it as appropriate from its interrupt handler.
    
    That will allow us to work around a problem with a shared timer
    interrupt line on at91 platforms.
    
    Link: http://marc.info/?l=linux-kernel&m=142252777602084&w=2
    Link: http://marc.info/?t=142252775300011&r=1&w=2
    Link: https://lkml.org/lkml/2014/12/15/552
    Reported-by: Boris Brezillon <boris.brezillon@free-electrons.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Mark Rutland <mark.rutland@arm.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 196a06fbc122..886d09e691d5 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1474,8 +1474,13 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 	 * otherwise we'll have trouble later trying to figure out
 	 * which interrupt is which (messes up the interrupt freeing
 	 * logic etc).
+	 *
+	 * Also IRQF_COND_SUSPEND only makes sense for shared interrupts and
+	 * it cannot be set along with IRQF_NO_SUSPEND.
 	 */
-	if ((irqflags & IRQF_SHARED) && !dev_id)
+	if (((irqflags & IRQF_SHARED) && !dev_id) ||
+	    (!(irqflags & IRQF_SHARED) && (irqflags & IRQF_COND_SUSPEND)) ||
+	    ((irqflags & IRQF_NO_SUSPEND) && (irqflags & IRQF_COND_SUSPEND)))
 		return -EINVAL;
 
 	desc = irq_to_desc(irq);

commit 02cea3958664723a5d2236f0f0058de97c7e4693
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Thu Feb 5 14:06:23 2015 +0100

    genirq: Provide disable_hardirq()
    
    For things like netpoll there is a need to disable an interrupt from
    atomic context. Currently netpoll uses disable_irq() which will
    sleep-wait on threaded handlers and thus forced_irqthreads breaks
    things.
    
    Provide disable_hardirq(), which uses synchronize_hardirq() to only wait
    for active hardirq handlers; also change synchronize_hardirq() to
    return the status of threaded handlers.
    
    This will allow one to try-disable an interrupt from atomic context, or
    in case of request_threaded_irq() to only wait for the hardirq part.
    
    Suggested-by: Sabrina Dubroca <sd@queasysnail.net>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: David Miller <davem@davemloft.net>
    Cc: Eyal Perry <eyalpe@mellanox.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Quentin Lambert <lambert.quentin@gmail.com>
    Cc: Randy Dunlap <rdunlap@infradead.org>
    Cc: Russell King <linux@arm.linux.org.uk>
    Link: http://lkml.kernel.org/r/20150205130623.GH5029@twins.programming.kicks-ass.net
    [ Fixed typos and such. ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 196a06fbc122..03329c2287eb 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -68,14 +68,20 @@ static void __synchronize_hardirq(struct irq_desc *desc)
  *	Do not use this for shutdown scenarios where you must be sure
  *	that all parts (hardirq and threaded handler) have completed.
  *
+ *	Returns: false if a threaded handler is active.
+ *
  *	This function may be called - with care - from IRQ context.
  */
-void synchronize_hardirq(unsigned int irq)
+bool synchronize_hardirq(unsigned int irq)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 
-	if (desc)
+	if (desc) {
 		__synchronize_hardirq(desc);
+		return !atomic_read(&desc->threads_active);
+	}
+
+	return true;
 }
 EXPORT_SYMBOL(synchronize_hardirq);
 
@@ -440,6 +446,32 @@ void disable_irq(unsigned int irq)
 }
 EXPORT_SYMBOL(disable_irq);
 
+/**
+ *	disable_hardirq - disables an irq and waits for hardirq completion
+ *	@irq: Interrupt to disable
+ *
+ *	Disable the selected interrupt line.  Enables and Disables are
+ *	nested.
+ *	This function waits for any pending hard IRQ handlers for this
+ *	interrupt to complete before returning. If you use this function while
+ *	holding a resource the hard IRQ handler may need you will deadlock.
+ *
+ *	When used to optimistically disable an interrupt from atomic context
+ *	the return value must be checked.
+ *
+ *	Returns: false if a threaded handler is active.
+ *
+ *	This function may be called - with care - from IRQ context.
+ */
+bool disable_hardirq(unsigned int irq)
+{
+	if (!__disable_irq_nosync(irq))
+		return synchronize_hardirq(irq);
+
+	return false;
+}
+EXPORT_SYMBOL_GPL(disable_hardirq);
+
 void __enable_irq(struct irq_desc *desc, unsigned int irq)
 {
 	switch (desc->depth) {

commit 4fe7ffb7e17ca6ad9173b8de35f260c9c8fc2f79
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Wed Jan 28 10:57:39 2015 -0800

    genirq: Fix null pointer reference in irq_set_affinity_hint()
    
    The recent set_affinity commit by me introduced some null
    pointer dereferences on driver unload, because some drivers
    call this function with a NULL argument. This fixes the issue
    by just checking for null before setting the affinity mask.
    
    Fixes: e2e64a932556 ("genirq: Set initial affinity in irq_set_affinity_hint()")
    Reported-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    CC: netdev@vger.kernel.org
    Link: http://lkml.kernel.org/r/20150128185739.9689.84588.stgit@jbrandeb-cp2.jf.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index f038e586a4b9..196a06fbc122 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -244,7 +244,8 @@ int irq_set_affinity_hint(unsigned int irq, const struct cpumask *m)
 	desc->affinity_hint = m;
 	irq_put_desc_unlock(desc, flags);
 	/* set the initial affinity to prevent every interrupt being on CPU0 */
-	__irq_set_affinity(irq, m, false);
+	if (m)
+		__irq_set_affinity(irq, m, false);
 	return 0;
 }
 EXPORT_SYMBOL_GPL(irq_set_affinity_hint);

commit e2e64a932556cdfae455497dbe94a8db151fc9fa
Author: Jesse Brandeburg <jesse.brandeburg@intel.com>
Date:   Thu Dec 18 17:22:06 2014 -0800

    genirq: Set initial affinity in irq_set_affinity_hint()
    
    Problem:
    The default behavior of the kernel is somewhat undesirable as all
    requested interrupts end up on CPU0 after registration.  A user can
    run irqbalance daemon, or can manually configure smp_affinity via the
    proc filesystem, but the default affinity of the interrupts for all
    devices is always CPU zero, this can cause performance problems or
    very heavy cpu use of only one core if not noticed and fixed by the
    user.
    
    Solution:
    Enable the setting of the initial affinity directly when the driver
    sets a hint.
    
    This enabling means that kernel drivers can include an initial
    affinity setting for the interrupt, instead of all interrupts starting
    out life on CPU0. Of course if irqbalance is still running then the
    interrupts will get moved as before.
    
    This function is currently called by drivers in block, crypto,
    infiniband, ethernet and scsi trees, but only a handful, so these will
    be the devices affected by this change.
    
    Tested on i40e, and default interrupts were spread across the CPUs
    according to the hint.
    
    drivers/block/mtip32xx/mtip32xx.c:3
    drivers/block/nvme-core.c:2
    drivers/crypto/qat/qat_dh895xcc/adf_isr.c:3
    drivers/infiniband/hw/qib/qib_iba7322.c:2
    drivers/net/ethernet/intel/i40e/i40e_main.c:3
    drivers/net/ethernet/intel/i40evf/i40evf_main.c:3
    drivers/net/ethernet/intel/ixgbe/ixgbe_main.c:3
    drivers/net/ethernet/mellanox/mlx4/en_cq.c:2
    drivers/scsi/hpsa.c:3
    drivers/scsi/lpfc/lpfc_init.c:3
    drivers/scsi/megaraid/megaraid_sas_base.c:8
    drivers/soc/ti/knav_qmss_acc.c:1
    drivers/soc/ti/knav_qmss_queue.c:2
    drivers/virtio/virtio_pci_common.c:2
    
    Signed-off-by: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Cc: netdev@vger.kernel.org
    Link: http://lkml.kernel.org/r/20141219012206.4220.27491.stgit@jbrandeb-cp2.jf.intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 80692373abd6..f038e586a4b9 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -243,6 +243,8 @@ int irq_set_affinity_hint(unsigned int irq, const struct cpumask *m)
 		return -EINVAL;
 	desc->affinity_hint = m;
 	irq_put_desc_unlock(desc, flags);
+	/* set the initial affinity to prevent every interrupt being on CPU0 */
+	__irq_set_affinity(irq, m, false);
 	return 0;
 }
 EXPORT_SYMBOL_GPL(irq_set_affinity_hint);

commit 2cb625478f8cea0f72b565007a35e1eb7882ac3a
Author: Jiang Liu <jiang.liu@linux.intel.com>
Date:   Thu Nov 6 22:20:18 2014 +0800

    genirq: Add IRQ_SET_MASK_OK_DONE to support stacked irqchip
    
    Add IRQ_SET_MASK_OK_DONE in addition to IRQ_SET_MASK_OK and
    IRQ_SET_MASK_OK_NOCOPY to support stacked irqchip. IRQ_SET_MASK_OK_DONE
    is the same as IRQ_SET_MASK_OK to irq core. To stacked irqchip, it means
    that ascendant irqchips have done all the work and no more handling
    needed in descendant irqchips.
    
    Signed-off-by: Jiang Liu <jiang.liu@linux.intel.com>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: Grant Likely <grant.likely@linaro.org>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Yingjoe Chen <yingjoe.chen@mediatek.com>
    Cc: Yijing Wang <wangyijing@huawei.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0a9104b4608b..80692373abd6 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -183,6 +183,7 @@ int irq_do_set_affinity(struct irq_data *data, const struct cpumask *mask,
 	ret = chip->irq_set_affinity(data, mask, force);
 	switch (ret) {
 	case IRQ_SET_MASK_OK:
+	case IRQ_SET_MASK_OK_DONE:
 		cpumask_copy(data->affinity, mask);
 	case IRQ_SET_MASK_OK_NOCOPY:
 		irq_set_thread_affinity(desc);
@@ -600,6 +601,7 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 
 	switch (ret) {
 	case IRQ_SET_MASK_OK:
+	case IRQ_SET_MASK_OK_DONE:
 		irqd_clear(&desc->irq_data, IRQD_TRIGGER_MASK);
 		irqd_set(&desc->irq_data, flags);
 

commit cab303be91dc47942bc25de33dc1140123540800
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Aug 28 11:44:31 2014 +0200

    genirq: Add sanity checks for PM options on shared interrupt lines
    
    Account the IRQF_NO_SUSPEND and IRQF_RESUME_EARLY actions on shared
    interrupt lines and yell loudly if there is a mismatch.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index fa564e8db996..0a9104b4608b 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1200,6 +1200,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	new->irq = irq;
 	*old_ptr = new;
 
+	irq_pm_install_action(desc, new);
+
 	/* Reset broken irq detection when installing new handler */
 	desc->irq_count = 0;
 	desc->irqs_unhandled = 0;
@@ -1318,6 +1320,8 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 	/* Found it - now remove it from the list of entries: */
 	*action_ptr = action->next;
 
+	irq_pm_remove_action(desc, action);
+
 	/* If this was the last handler, shut down the IRQ line: */
 	if (!desc->action) {
 		irq_shutdown(desc);

commit 8df2e02c5c4de9e65ee60153dd9c442356534ad9
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Aug 28 11:49:28 2014 +0200

    genirq: Move suspend/resume logic into irq/pm code
    
    No functional change. Preparatory patch for cleaning up the suspend
    abort functionality. Update the comments while at it.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 3dc6a61bf06a..fa564e8db996 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -382,14 +382,8 @@ setup_affinity(unsigned int irq, struct irq_desc *desc, struct cpumask *mask)
 }
 #endif
 
-void __disable_irq(struct irq_desc *desc, unsigned int irq, bool suspend)
+void __disable_irq(struct irq_desc *desc, unsigned int irq)
 {
-	if (suspend) {
-		if (!desc->action || (desc->action->flags & IRQF_NO_SUSPEND))
-			return;
-		desc->istate |= IRQS_SUSPENDED;
-	}
-
 	if (!desc->depth++)
 		irq_disable(desc);
 }
@@ -401,7 +395,7 @@ static int __disable_irq_nosync(unsigned int irq)
 
 	if (!desc)
 		return -EINVAL;
-	__disable_irq(desc, irq, false);
+	__disable_irq(desc, irq);
 	irq_put_desc_busunlock(desc, flags);
 	return 0;
 }
@@ -442,20 +436,8 @@ void disable_irq(unsigned int irq)
 }
 EXPORT_SYMBOL(disable_irq);
 
-void __enable_irq(struct irq_desc *desc, unsigned int irq, bool resume)
+void __enable_irq(struct irq_desc *desc, unsigned int irq)
 {
-	if (resume) {
-		if (!(desc->istate & IRQS_SUSPENDED)) {
-			if (!desc->action)
-				return;
-			if (!(desc->action->flags & IRQF_FORCE_RESUME))
-				return;
-			/* Pretend that it got disabled ! */
-			desc->depth++;
-		}
-		desc->istate &= ~IRQS_SUSPENDED;
-	}
-
 	switch (desc->depth) {
 	case 0:
  err_out:
@@ -497,7 +479,7 @@ void enable_irq(unsigned int irq)
 		 KERN_ERR "enable_irq before setup/request_irq: irq %u\n", irq))
 		goto out;
 
-	__enable_irq(desc, irq, false);
+	__enable_irq(desc, irq);
 out:
 	irq_put_desc_busunlock(desc, flags);
 }
@@ -1228,7 +1210,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	 */
 	if (shared && (desc->istate & IRQS_SPURIOUS_DISABLED)) {
 		desc->istate &= ~IRQS_SPURIOUS_DISABLED;
-		__enable_irq(desc, irq, false);
+		__enable_irq(desc, irq);
 	}
 
 	raw_spin_unlock_irqrestore(&desc->lock, flags);

commit 1e77d0a1ed7417d2a5a52a7b8d32aea1833faa6c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Mar 7 14:53:45 2013 +0100

    genirq: Sanitize spurious interrupt detection of threaded irqs
    
    Till reported that the spurious interrupt detection of threaded
    interrupts is broken in two ways:
    
    - note_interrupt() is called for each action thread of a shared
      interrupt line. That's wrong as we are only interested whether none
      of the device drivers felt responsible for the interrupt, but by
      calling multiple times for a single interrupt line we account
      IRQ_NONE even if one of the drivers felt responsible.
    
    - note_interrupt() when called from the thread handler is not
      serialized. That leaves the members of irq_desc which are used for
      the spurious detection unprotected.
    
    To solve this we need to defer the spurious detection of a threaded
    interrupt to the next hardware interrupt context where we have
    implicit serialization.
    
    If note_interrupt is called with action_ret == IRQ_WAKE_THREAD, we
    check whether the previous interrupt requested a deferred check. If
    not, we request a deferred check for the next hardware interrupt and
    return.
    
    If set, we check whether one of the interrupt threads signaled
    success. Depending on this information we feed the result into the
    spurious detector.
    
    If one primary handler of a shared interrupt returns IRQ_HANDLED we
    disable the deferred check of irq threads on the same line, as we have
    found at least one device driver who cared.
    
    Reported-by: Till Straumann <strauman@slac.stanford.edu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Austin Schuh <austin@peloton-tech.com>
    Cc: Oliver Hartkopp <socketcan@hartkopp.net>
    Cc: Wolfgang Grandegger <wg@grandegger.com>
    Cc: Pavel Pisa <pisa@cmp.felk.cvut.cz>
    Cc: Marc Kleine-Budde <mkl@pengutronix.de>
    Cc: linux-can@vger.kernel.org
    Cc: stable@vger.kernel.org
    Link: http://lkml.kernel.org/r/alpine.LFD.2.02.1303071450130.22263@ionos

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index d34131ca372b..3dc6a61bf06a 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -886,8 +886,8 @@ static int irq_thread(void *data)
 		irq_thread_check_affinity(desc, action);
 
 		action_ret = handler_fn(desc, action);
-		if (!noirqdebug)
-			note_interrupt(action->irq, desc, action_ret);
+		if (action_ret == IRQ_HANDLED)
+			atomic_inc(&desc->threads_handled);
 
 		wake_threads_waitq(desc);
 	}

commit 01f8fa4f01d8362358eb90e412bd7ae18a3ec1ad
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Apr 16 14:36:44 2014 +0000

    genirq: Allow forcing cpu affinity of interrupts
    
    The current implementation of irq_set_affinity() refuses rightfully to
    route an interrupt to an offline cpu.
    
    But there is a special case, where this is actually desired. Some of
    the ARM SoCs have per cpu timers which require setting the affinity
    during cpu startup where the cpu is not yet in the online mask.
    
    If we can't do that, then the local timer interrupt for the about to
    become online cpu is routed to some random online cpu.
    
    The developers of the affected machines tried to work around that
    issue, but that results in a massive mess in that timer code.
    
    We have a yet unused argument in the set_affinity callbacks of the irq
    chips, which I added back then for a similar reason. It was never
    required so it got not used. But I'm happy that I never removed it.
    
    That allows us to implement a sane handling of the above scenario. So
    the affected SoC drivers can add the required force handling to their
    interrupt chip, switch the timer code to irq_force_affinity() and
    things just work.
    
    This does not affect any existing user of irq_set_affinity().
    
    Tagged for stable to allow a simple fix of the affected SoC clock
    event drivers.
    
    Reported-and-tested-by: Krzysztof Kozlowski <k.kozlowski@samsung.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Kyungmin Park <kyungmin.park@samsung.com>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
    Cc: Tomasz Figa <t.figa@samsung.com>,
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>,
    Cc: Kukjin Kim <kgene.kim@samsung.com>
    Cc: linux-arm-kernel@lists.infradead.org,
    Cc: stable@vger.kernel.org
    Link: http://lkml.kernel.org/r/20140416143315.717251504@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 2486a4c1a710..d34131ca372b 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -180,7 +180,7 @@ int irq_do_set_affinity(struct irq_data *data, const struct cpumask *mask,
 	struct irq_chip *chip = irq_data_get_irq_chip(data);
 	int ret;
 
-	ret = chip->irq_set_affinity(data, mask, false);
+	ret = chip->irq_set_affinity(data, mask, force);
 	switch (ret) {
 	case IRQ_SET_MASK_OK:
 		cpumask_copy(data->affinity, mask);
@@ -192,7 +192,8 @@ int irq_do_set_affinity(struct irq_data *data, const struct cpumask *mask,
 	return ret;
 }
 
-int __irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask)
+int irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask,
+			    bool force)
 {
 	struct irq_chip *chip = irq_data_get_irq_chip(data);
 	struct irq_desc *desc = irq_data_to_desc(data);
@@ -202,7 +203,7 @@ int __irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask)
 		return -EINVAL;
 
 	if (irq_can_move_pcntxt(data)) {
-		ret = irq_do_set_affinity(data, mask, false);
+		ret = irq_do_set_affinity(data, mask, force);
 	} else {
 		irqd_set_move_pending(data);
 		irq_copy_pending(desc, mask);
@@ -217,13 +218,7 @@ int __irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask)
 	return ret;
 }
 
-/**
- *	irq_set_affinity - Set the irq affinity of a given irq
- *	@irq:		Interrupt to set affinity
- *	@mask:		cpumask
- *
- */
-int irq_set_affinity(unsigned int irq, const struct cpumask *mask)
+int __irq_set_affinity(unsigned int irq, const struct cpumask *mask, bool force)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned long flags;
@@ -233,7 +228,7 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *mask)
 		return -EINVAL;
 
 	raw_spin_lock_irqsave(&desc->lock, flags);
-	ret =  __irq_set_affinity_locked(irq_desc_get_irq_data(desc), mask);
+	ret = irq_set_affinity_locked(irq_desc_get_irq_data(desc), mask, force);
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	return ret;
 }

commit 328a4978df833249b099c9875738d7b72042ffe1
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Mar 13 19:03:51 2014 +0100

    genirq: Add a new IRQCHIP_EOI_THREADED flag
    
    The flag is necessary for interrupt chips which require an ACK/EOI
    after the handler has run. In case of threaded handlers this needs to
    happen after the threaded handler has completed before the unmask of
    the interrupt.
    
    The flag is only unseful in combination with the handle_fasteoi_irq
    flow control handler.
    
    It can be combined with the flag IRQCHIP_EOI_IF_HANDLED, so the EOI is
    not issued when the interrupt is disabled or in progress.
    
    Tested-by: Hans de Goede <hdegoede@redhat.com>
    Reviewed-by: Hans de Goede <hdegoede@redhat.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-sunxi@googlegroups.com
    Cc: Maxime Ripard <maxime.ripard@free-electrons.com>
    Link: http://lkml.kernel.org/r/1394733834-26839-2-git-send-email-hdegoede@redhat.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index de1a8ed29b40..2486a4c1a710 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -748,7 +748,7 @@ static void irq_finalize_oneshot(struct irq_desc *desc,
 
 	if (!desc->threads_oneshot && !irqd_irq_disabled(&desc->irq_data) &&
 	    irqd_irq_masked(&desc->irq_data))
-		unmask_irq(desc);
+		unmask_threaded_irq(desc);
 
 out_unlock:
 	raw_spin_unlock_irq(&desc->lock);

commit ffb12cf002edbc5927079f51bebde428d601f723
Merge: 1a75b8e64571 c1bacbae8192
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Mar 12 16:01:07 2014 +0100

    Merge branch 'irq/for-gpio' into irq/core
    
    Merge the request/release callbacks which are in a separate branch for
    consumption by the gpio folks.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit c1bacbae8192dd2a9ebadd22d793b68054f6c6e5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Mar 8 08:59:58 2014 +0100

    genirq: Provide irq_request/release_resources chip callbacks
    
    For certain irq types, e.g. gpios, it's necessary to request resources
    before starting up the irq.
    
    This might fail so we cannot use the irq_startup() callback because we
    might call the irq_set_type() callback before that which does not make
    sense when the resource is not available. Calling irq_startup() before
    irq_set_type() can lead to spurious interrupts which is not desired
    either.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jean-Jacques Hiblot <jjhiblot@traphandler.com>
    Cc: Grant Likely <grant.likely@linaro.org>
    Cc: linux-arm-kernel@lists.infradead.org
    Reviewed-by: Linus Walleij <linus.walleij@linaro.org>
    Link: http://lkml.kernel.org/r/alpine.DEB.2.02.1403080857160.18573@ionos.tec.linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index d3bf660cb57f..5d35cbe22896 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -896,6 +896,23 @@ static void irq_setup_forced_threading(struct irqaction *new)
 	}
 }
 
+static int irq_request_resources(struct irq_desc *desc)
+{
+	struct irq_data *d = &desc->irq_data;
+	struct irq_chip *c = d->chip;
+
+	return c->irq_request_resources ? c->irq_request_resources(d) : 0;
+}
+
+static void irq_release_resources(struct irq_desc *desc)
+{
+	struct irq_data *d = &desc->irq_data;
+	struct irq_chip *c = d->chip;
+
+	if (c->irq_release_resources)
+		c->irq_release_resources(d);
+}
+
 /*
  * Internal function to register an irqaction - typically used to
  * allocate special interrupts that are part of the architecture.
@@ -1091,6 +1108,13 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	}
 
 	if (!shared) {
+		ret = irq_request_resources(desc);
+		if (ret) {
+			pr_err("Failed to request resources for %s (irq %d) on irqchip %s\n",
+			       new->name, irq, desc->irq_data.chip->name);
+			goto out_mask;
+		}
+
 		init_waitqueue_head(&desc->wait_for_threads);
 
 		/* Setup the type (level, edge polarity) if configured: */
@@ -1261,8 +1285,10 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 	*action_ptr = action->next;
 
 	/* If this was the last handler, shut down the IRQ line: */
-	if (!desc->action)
+	if (!desc->action) {
 		irq_shutdown(desc);
+		irq_release_resources(desc);
+	}
 
 #ifdef CONFIG_SMP
 	/* make sure affinity_hint is cleaned up */

commit c685689fd24d310343ac33942e9a54a974ae9c43
Author: Chuansheng Liu <chuansheng.liu@intel.com>
Date:   Mon Feb 24 11:29:50 2014 +0800

    genirq: Remove racy waitqueue_active check
    
    We hit one rare case below:
    
    T1 calling disable_irq(), but hanging at synchronize_irq()
    always;
    The corresponding irq thread is in sleeping state;
    And all CPUs are in idle state;
    
    After analysis, we found there is one possible scenerio which
    causes T1 is waiting there forever:
    CPU0                                       CPU1
     synchronize_irq()
      wait_event()
        spin_lock()
                                               atomic_dec_and_test(&threads_active)
          insert the __wait into queue
        spin_unlock()
                                               if(waitqueue_active)
        atomic_read(&threads_active)
                                                 wake_up()
    
    Here after inserted the __wait into queue on CPU0, and before
    test if queue is empty on CPU1, there is no barrier, it maybe
    cause it is not visible for CPU1 immediately, although CPU0 has
    updated the queue list.
    It is similar for CPU0 atomic_read() threads_active also.
    
    So we'd need one smp_mb() before waitqueue_active.that, but removing
    the waitqueue_active() check solves it as wel l and it makes
    things simple and clear.
    
    Signed-off-by: Chuansheng Liu <chuansheng.liu@intel.com>
    Cc: Xiaoming Wang <xiaoming.wang@intel.com>
    Link: http://lkml.kernel.org/r/1393212590-32543-1-git-send-email-chuansheng.liu@intel.com
    Cc: stable@vger.kernel.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 481a13c43b17..d3bf660cb57f 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -802,8 +802,7 @@ static irqreturn_t irq_thread_fn(struct irq_desc *desc,
 
 static void wake_threads_waitq(struct irq_desc *desc)
 {
-	if (atomic_dec_and_test(&desc->threads_active) &&
-	    waitqueue_active(&desc->wait_for_threads))
+	if (atomic_dec_and_test(&desc->threads_active))
 		wake_up(&desc->wait_for_threads);
 }
 

commit b04c644e670f79417f1728e6be310cfd8e6a921b
Author: Chuansheng Liu <chuansheng.liu@intel.com>
Date:   Mon Feb 10 16:13:57 2014 +0800

    genirq: Update the a comment typo
    
    Change the comment "chasnge" to "change".
    
    Signed-off-by: Chuansheng Liu <chuansheng.liu@intel.com>
    Link: http://lkml.kernel.org/r/1392020037-5484-2-git-send-email-chuansheng.liu@intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 54eb5c99351b..ada0c548c36a 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -757,7 +757,7 @@ static void irq_finalize_oneshot(struct irq_desc *desc,
 
 #ifdef CONFIG_SMP
 /*
- * Check whether we need to chasnge the affinity of the interrupt thread.
+ * Check whether we need to change the affinity of the interrupt thread.
  */
 static void
 irq_thread_check_affinity(struct irq_desc *desc, struct irqaction *action)

commit a92444c6b2225a9115d661c950cb48a22aeace20
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Feb 15 00:55:19 2014 +0000

    genirq: Provide irq_wake_thread()
    
    In course of the sdhci/sdio discussion with Russell about killing the
    sdio kthread hackery we discovered the need to be able to wake an
    interrupt thread from software.
    
    The rationale for this is, that sdio hardware can lack proper
    interrupt support for certain features. So the driver needs to poll
    the status registers, but at the same time it needs to be woken up by
    an hardware interrupt.
    
    To be able to get rid of the home brewn kthread construct of sdio we
    need a way to wake an irq thread independent of an actual hardware
    interrupt.
    
    Provide an irq_wake_thread() function which wakes up the thread which
    is associated to a given dev_id. This allows sdio to invoke the irq
    thread from the hardware irq handler via the IRQ_WAKE_THREAD return
    value and provides a possibility to wake it via a timer for the
    polling scenarios. That allows to simplify the sdio logic
    significantly.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Chris Ball <chris@printf.net>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20140215003823.772565780@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 274ba9238fb7..54eb5c99351b 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -911,6 +911,33 @@ static int irq_thread(void *data)
 	return 0;
 }
 
+/**
+ *	irq_wake_thread - wake the irq thread for the action identified by dev_id
+ *	@irq:		Interrupt line
+ *	@dev_id:	Device identity for which the thread should be woken
+ *
+ */
+void irq_wake_thread(unsigned int irq, void *dev_id)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+	struct irqaction *action;
+	unsigned long flags;
+
+	if (!desc || WARN_ON(irq_settings_is_per_cpu_devid(desc)))
+		return;
+
+	raw_spin_lock_irqsave(&desc->lock, flags);
+	for (action = desc->action; action; action = action->next) {
+		if (action->dev_id == dev_id) {
+			if (action->thread)
+				__irq_wake_thread(desc, action);
+			break;
+		}
+	}
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
+}
+EXPORT_SYMBOL_GPL(irq_wake_thread);
+
 static void irq_setup_forced_threading(struct irqaction *new)
 {
 	if (!force_irqthreads)

commit 18258f7239a61d8929b8e0c7b6d46c446459074c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Feb 15 00:55:18 2014 +0000

    genirq: Provide synchronize_hardirq()
    
    synchronize_irq() waits for hard irq and threaded handlers to complete
    before returning. For some special cases we only need to make sure
    that the hard interrupt part of the irq line is not in progress when
    we disabled the - possibly shared - interrupt at the device level.
    
    A proper use case for this was provided by Russell. The sdhci driver
    requires some irq triggered functions to be run in thread context. The
    current implementation of the thread context is a sdio private kthread
    construct, which has quite some shortcomings. These can be avoided
    when the thread is directly associated to the device interrupt via the
    generic threaded irq infrastructure.
    
    Though there is a corner case related to run time power management
    where one side disables the device interrupts at the device level and
    needs to make sure, that an already running hard interrupt handler has
    completed before proceeding further. Though that hard interrupt
    handler might wake the associated thread, which in turn can request
    the runtime PM to reenable the device. Using synchronize_irq() leads
    to an immediate deadlock of the irq thread waiting for the PM lock and
    the synchronize_irq() waiting for the irq thread to complete.
    
    Due to the fact that it is sufficient for this case to ensure that no
    hard irq handler is executing a new function which avoids the check
    for the thread is required.
    
    Add a function, which just monitors the hard irq parts and ignores the
    threaded handlers.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Russell King <linux@arm.linux.org.uk>
    Cc: Chris Ball <chris@printf.net>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20140215003823.653236081@linutronix.de

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 481a13c43b17..274ba9238fb7 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -32,24 +32,10 @@ static int __init setup_forced_irqthreads(char *arg)
 early_param("threadirqs", setup_forced_irqthreads);
 #endif
 
-/**
- *	synchronize_irq - wait for pending IRQ handlers (on other CPUs)
- *	@irq: interrupt number to wait for
- *
- *	This function waits for any pending IRQ handlers for this interrupt
- *	to complete before returning. If you use this function while
- *	holding a resource the IRQ handler may need you will deadlock.
- *
- *	This function may be called - with care - from IRQ context.
- */
-void synchronize_irq(unsigned int irq)
+static void __synchronize_hardirq(struct irq_desc *desc)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
 	bool inprogress;
 
-	if (!desc)
-		return;
-
 	do {
 		unsigned long flags;
 
@@ -67,12 +53,56 @@ void synchronize_irq(unsigned int irq)
 
 		/* Oops, that failed? */
 	} while (inprogress);
+}
 
-	/*
-	 * We made sure that no hardirq handler is running. Now verify
-	 * that no threaded handlers are active.
-	 */
-	wait_event(desc->wait_for_threads, !atomic_read(&desc->threads_active));
+/**
+ *	synchronize_hardirq - wait for pending hard IRQ handlers (on other CPUs)
+ *	@irq: interrupt number to wait for
+ *
+ *	This function waits for any pending hard IRQ handlers for this
+ *	interrupt to complete before returning. If you use this
+ *	function while holding a resource the IRQ handler may need you
+ *	will deadlock. It does not take associated threaded handlers
+ *	into account.
+ *
+ *	Do not use this for shutdown scenarios where you must be sure
+ *	that all parts (hardirq and threaded handler) have completed.
+ *
+ *	This function may be called - with care - from IRQ context.
+ */
+void synchronize_hardirq(unsigned int irq)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+
+	if (desc)
+		__synchronize_hardirq(desc);
+}
+EXPORT_SYMBOL(synchronize_hardirq);
+
+/**
+ *	synchronize_irq - wait for pending IRQ handlers (on other CPUs)
+ *	@irq: interrupt number to wait for
+ *
+ *	This function waits for any pending IRQ handlers for this interrupt
+ *	to complete before returning. If you use this function while
+ *	holding a resource the IRQ handler may need you will deadlock.
+ *
+ *	This function may be called - with care - from IRQ context.
+ */
+void synchronize_irq(unsigned int irq)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+
+	if (desc) {
+		__synchronize_hardirq(desc);
+		/*
+		 * We made sure that no hardirq handler is
+		 * running. Now verify that no threaded handlers are
+		 * active.
+		 */
+		wait_event(desc->wait_for_threads,
+			   !atomic_read(&desc->threads_active));
+	}
 }
 EXPORT_SYMBOL(synchronize_irq);
 

commit 9073e1a804c3096eda84ee7cbf11d1f174236c75
Merge: 4937e2a6f939 2bb9936beac2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 15 16:47:22 2013 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/trivial
    
    Pull trivial tree updates from Jiri Kosina:
     "Usual earth-shaking, news-breaking, rocket science pile from
      trivial.git"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/trivial: (23 commits)
      doc: usb: Fix typo in Documentation/usb/gadget_configs.txt
      doc: add missing files to timers/00-INDEX
      timekeeping: Fix some trivial typos in comments
      mm: Fix some trivial typos in comments
      irq: Fix some trivial typos in comments
      NUMA: fix typos in Kconfig help text
      mm: update 00-INDEX
      doc: Documentation/DMA-attributes.txt fix typo
      DRM: comment: `halve' -> `half'
      Docs: Kconfig: `devlopers' -> `developers'
      doc: typo on word accounting in kprobes.c in mutliple architectures
      treewide: fix "usefull" typo
      treewide: fix "distingush" typo
      mm/Kconfig: Grammar s/an/a/
      kexec: Typo s/the/then/
      Documentation/kvm: Update cpuid documentation for steal time and pv eoi
      treewide: Fix common typo in "identify"
      __page_to_pfn: Fix typo in comment
      Correct some typos for word frequency
      clk: fixed-factor: Fix a trivial typo
      ...

commit bbfe65c219c638e19f1da5adab1005b2d68ca810
Author: Thomas Pfaff <tpfaff@pcs.com>
Date:   Fri Oct 11 13:00:40 2013 +0200

    genirq: Set the irq thread policy without checking CAP_SYS_NICE
    
    In commit ee23871389 ("genirq: Set irq thread to RT priority on
    creation") we moved the assigment of the thread's priority from the
    thread's function into __setup_irq(). That function may run in user
    context for instance if the user opens an UART node and then driver
    calls requests in the ->open() callback. That user may not have
    CAP_SYS_NICE and so the irq thread won't run with the SCHED_OTHER
    policy.
    
    This patch uses sched_setscheduler_nocheck() so we omit the CAP_SYS_NICE
    check which is otherwise required for the SCHED_OTHER policy.
    
    [bigeasy: Rewrite the changelog]
    
    Signed-off-by: Thomas Pfaff <tpfaff@pcs.com>
    Cc: Ivo Sieben <meltedpianoman@gmail.com>
    Cc: stable@vger.kernel.org
    Link: http://lkml.kernel.org/r/1381489240-29626-1-git-send-email-bigeasy@linutronix.de
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 514bcfd855a8..3e59f951d42f 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -956,7 +956,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 			goto out_mput;
 		}
 
-		sched_setscheduler(t, SCHED_FIFO, &param);
+		sched_setscheduler_nocheck(t, SCHED_FIFO, &param);
 
 		/*
 		 * We keep the reference to the task struct even if

commit f788e7bf0563bb98b1a6ef5cdc66749ee36934e4
Author: Xie XiuQi <xiexiuqi@huawei.com>
Date:   Fri Oct 18 09:12:04 2013 +0800

    irq: Fix some trivial typos in comments
    
    Signed-off-by: Xie XiuQi <xiexiuqi@huawei.com>
    [jkosina@suse.cz: fix 'explicitly', noticed by Randy Dunlap]
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 514bcfd855a8..2165253220ee 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -786,7 +786,7 @@ irq_forced_thread_fn(struct irq_desc *desc, struct irqaction *action)
 }
 
 /*
- * Interrupts explicitely requested as threaded interupts want to be
+ * Interrupts explicitly requested as threaded interrupts want to be
  * preemtible - many of them need to sleep and wait for slow busses to
  * complete.
  */

commit 2779db8d37d4b542d9ca2575f5f178dbeaca6c86
Author: Ben Hutchings <ben@decadent.org.uk>
Date:   Fri Jun 28 02:40:30 2013 +0100

    genirq: Fix can_request_irq() for IRQs without an action
    
    Commit 02725e7471b8 ('genirq: Use irq_get/put functions'),
    inadvertently changed can_request_irq() to return 0 for IRQs that have
    no action.  This causes pcibios_lookup_irq() to select only IRQs that
    already have an action with IRQF_SHARED set, or to fail if there are
    none.  Change can_request_irq() to return 1 for IRQs that have no
    action (if the first two conditions are met).
    
    Reported-by: Bjarni Ingi Gislason <bjarniig@rhi.hi.is>
    Tested-by: Bjarni Ingi Gislason <bjarniig@rhi.hi.is> (against 3.2)
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Cc: 709647@bugs.debian.org
    Cc: stable@vger.kernel.org # 2.6.39+
    Link: http://bugs.debian.org/709647
    Link: http://lkml.kernel.org/r/1372383630.23847.40.camel@deadeye.wl.decadent.org.uk
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index e16caa81f887..514bcfd855a8 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -555,9 +555,9 @@ int can_request_irq(unsigned int irq, unsigned long irqflags)
 		return 0;
 
 	if (irq_settings_can_request(desc)) {
-		if (desc->action)
-			if (irqflags & desc->action->flags & IRQF_SHARED)
-				canrequest =1;
+		if (!desc->action ||
+		    irqflags & desc->action->flags & IRQF_SHARED)
+			canrequest = 1;
 	}
 	irq_put_desc_unlock(desc, flags);
 	return canrequest;

commit ee23871389d51e07380d23887333622fbe7d3dd9
Author: Ivo Sieben <meltedpianoman@gmail.com>
Date:   Mon Jun 3 12:12:02 2013 +0200

    genirq: Set irq thread to RT priority on creation
    
    When a threaded irq handler is installed the irq thread is initially
    created on normal scheduling priority. Only after the irq thread is
    woken up it sets its priority to RT_FIFO MAX_USER_RT_PRIO/2 itself.
    
    This means that interrupts that occur directly after the irq handler
    is installed will be handled on a normal scheduling priority instead
    of the realtime priority that one would expect.
    
    Fix this by setting the RT priority on creation of the irq_thread.
    
    Signed-off-by: Ivo Sieben <meltedpianoman@gmail.com>
    Cc: Sebastian Andrzej Siewior  <bigeasy@linutronix.de>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Link: http://lkml.kernel.org/r/1370254322-17240-1-git-send-email-meltedpianoman@gmail.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index fa17855ca65a..e16caa81f887 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -840,9 +840,6 @@ static void irq_thread_dtor(struct callback_head *unused)
 static int irq_thread(void *data)
 {
 	struct callback_head on_exit_work;
-	static const struct sched_param param = {
-		.sched_priority = MAX_USER_RT_PRIO/2,
-	};
 	struct irqaction *action = data;
 	struct irq_desc *desc = irq_to_desc(action->irq);
 	irqreturn_t (*handler_fn)(struct irq_desc *desc,
@@ -854,8 +851,6 @@ static int irq_thread(void *data)
 	else
 		handler_fn = irq_thread_fn;
 
-	sched_setscheduler(current, SCHED_FIFO, &param);
-
 	init_task_work(&on_exit_work, irq_thread_dtor);
 	task_work_add(current, &on_exit_work, false);
 
@@ -950,6 +945,9 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	 */
 	if (new->thread_fn && !nested) {
 		struct task_struct *t;
+		static const struct sched_param param = {
+			.sched_priority = MAX_USER_RT_PRIO/2,
+		};
 
 		t = kthread_create(irq_thread, new, "irq/%d-%s", irq,
 				   new->name);
@@ -957,6 +955,9 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 			ret = PTR_ERR(t);
 			goto out_mput;
 		}
+
+		sched_setscheduler(t, SCHED_FIFO, &param);
+
 		/*
 		 * We keep the reference to the task struct even if
 		 * the thread dies to avoid that the interrupt code

commit d652e1eb8e7b739fccbfb503a3da3e9f640fbf3d
Merge: 8f55cea410db 77852fea6e24
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Feb 19 18:19:48 2013 -0800

    Merge branch 'sched-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull scheduler changes from Ingo Molnar:
     "Main changes:
    
       - scheduler side full-dynticks (user-space execution is undisturbed
         and receives no timer IRQs) preparation changes that convert the
         cputime accounting code to be full-dynticks ready, from Frederic
         Weisbecker.
    
       - Initial sched.h split-up changes, by Clark Williams
    
       - select_idle_sibling() performance improvement by Mike Galbraith:
    
            " 1 tbench pair (worst case) in a 10 core + SMT package:
    
              pre   15.22 MB/sec 1 procs
              post 252.01 MB/sec 1 procs "
    
      - sched_rr_get_interval() ABI fix/change.  We think this detail is not
        used by apps (so it's not an ABI in practice), but lets keep it
        under observation.
    
      - misc RT scheduling cleanups, optimizations"
    
    * 'sched-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (24 commits)
      sched/rt: Add <linux/sched/rt.h> header to <linux/init_task.h>
      cputime: Remove irqsave from seqlock readers
      sched, powerpc: Fix sched.h split-up build failure
      cputime: Restore CPU_ACCOUNTING config defaults for PPC64
      sched/rt: Move rt specific bits into new header file
      sched/rt: Add a tuning knob to allow changing SCHED_RR timeslice
      sched: Move sched.h sysctl bits into separate header
      sched: Fix signedness bug in yield_to()
      sched: Fix select_idle_sibling() bouncing cow syndrome
      sched/rt: Further simplify pick_rt_task()
      sched/rt: Do not account zero delta_exec in update_curr_rt()
      cputime: Safely read cputime of full dynticks CPUs
      kvm: Prepare to add generic guest entry/exit callbacks
      cputime: Use accessors to read task cputime stats
      cputime: Allow dynamic switch between tick/virtual based cputime accounting
      cputime: Generic on-demand virtual cputime accounting
      cputime: Move default nsecs_to_cputime() to jiffies based cputime file
      cputime: Librarize per nsecs resolution cputime definitions
      cputime: Avoid multiplication overflow on utime scaling
      context_tracking: Export context state for generic vtime
      ...
    
    Fix up conflict in kernel/context_tracking.c due to comment additions.

commit 36a5df85e9a3c218b73f6cf80098016ca3f0410d
Author: Chris Metcalf <cmetcalf@tilera.com>
Date:   Fri Feb 1 15:04:26 2013 -0500

    genirq: Export enable/disable_percpu_irq()
    
    These functions are used by the tilegx onchip network driver, and it's
    useful to be able to load that driver as a module.
    
    Signed-off-by: Chris Metcalf <cmetcalf@tilera.com>
    Link: http://lkml.kernel.org/r/201302012043.r11KhNZF024371@farm-0021.internal.tilera.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index e49a288fa479..88e7bed62711 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1524,6 +1524,7 @@ void enable_percpu_irq(unsigned int irq, unsigned int type)
 out:
 	irq_put_desc_unlock(desc, flags);
 }
+EXPORT_SYMBOL_GPL(enable_percpu_irq);
 
 void disable_percpu_irq(unsigned int irq)
 {
@@ -1537,6 +1538,7 @@ void disable_percpu_irq(unsigned int irq)
 	irq_percpu_disable(desc, cpu);
 	irq_put_desc_unlock(desc, flags);
 }
+EXPORT_SYMBOL_GPL(disable_percpu_irq);
 
 /*
  * Internal function to unregister a percpu irqaction.

commit 8bd75c77b7c6a3954140dd2e20346aef3efe4a35
Author: Clark Williams <williams@redhat.com>
Date:   Thu Feb 7 09:47:07 2013 -0600

    sched/rt: Move rt specific bits into new header file
    
    Move rt scheduler definitions out of include/linux/sched.h into
    new file include/linux/sched/rt.h
    
    Signed-off-by: Clark Williams <williams@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Link: http://lkml.kernel.org/r/20130207094707.7b9f825f@riff.lan
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index e49a288fa479..02115d9592ec 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -16,6 +16,7 @@
 #include <linux/interrupt.h>
 #include <linux/slab.h>
 #include <linux/sched.h>
+#include <linux/sched/rt.h>
 #include <linux/task_work.h>
 
 #include "internals.h"

commit 19af395d7c0daaafdebd441a162128aaac575912
Author: Alan Cox <alan@linux.intel.com>
Date:   Tue Dec 18 14:21:25 2012 -0800

    irq: tsk->comm is an array
    
    The array check is useless so remove it.
    
    [akpm@linux-foundation.org: remove comment, per David]
    Signed-off-by: Alan Cox <alan@linux.intel.com>
    Cc: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 35c70c9e24d8..e49a288fa479 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -818,7 +818,7 @@ static void irq_thread_dtor(struct callback_head *unused)
 	action = kthread_data(tsk);
 
 	pr_err("exiting task \"%s\" (%d) is an active IRQ thread (irq %d)\n",
-	       tsk->comm ? tsk->comm : "", tsk->pid, action->irq);
+	       tsk->comm, tsk->pid, action->irq);
 
 
 	desc = irq_to_desc(action->irq);

commit 04aa530ec04f61875b99c12721162e2964e3318c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Nov 3 11:52:09 2012 +0100

    genirq: Always force thread affinity
    
    Sankara reported that the genirq core code fails to adjust the
    affinity of an interrupt thread in several cases:
    
     1) On request/setup_irq() the call to setup_affinity() happens before
        the new action is registered, so the new thread is not notified.
    
     2) For secondary shared interrupts nothing notifies the new thread to
        change its affinity.
    
     3) Interrupts which have the IRQ_NO_BALANCE flag set are not moving
        the thread either.
    
    Fix this by setting the thread affinity flag right on thread creation
    time. This ensures that under all circumstances the thread moves to
    the right place. Requires a check in irq_thread_check_affinity for an
    existing affinity mask (CONFIG_CPU_MASK_OFFSTACK=y)
    
    Reported-and-tested-by: Sankara Muthukrishnan <sankara.m@gmail.com>
    Cc: stable@vger.kernel.org
    Link: http://lkml.kernel.org/r/alpine.LFD.2.02.1209041738200.2754@ionos
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 1cbd572f6ad8..35c70c9e24d8 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -732,6 +732,7 @@ static void
 irq_thread_check_affinity(struct irq_desc *desc, struct irqaction *action)
 {
 	cpumask_var_t mask;
+	bool valid = true;
 
 	if (!test_and_clear_bit(IRQTF_AFFINITY, &action->thread_flags))
 		return;
@@ -746,10 +747,18 @@ irq_thread_check_affinity(struct irq_desc *desc, struct irqaction *action)
 	}
 
 	raw_spin_lock_irq(&desc->lock);
-	cpumask_copy(mask, desc->irq_data.affinity);
+	/*
+	 * This code is triggered unconditionally. Check the affinity
+	 * mask pointer. For CPU_MASK_OFFSTACK=n this is optimized out.
+	 */
+	if (desc->irq_data.affinity)
+		cpumask_copy(mask, desc->irq_data.affinity);
+	else
+		valid = false;
 	raw_spin_unlock_irq(&desc->lock);
 
-	set_cpus_allowed_ptr(current, mask);
+	if (valid)
+		set_cpus_allowed_ptr(current, mask);
 	free_cpumask_var(mask);
 }
 #else
@@ -954,6 +963,16 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		 */
 		get_task_struct(t);
 		new->thread = t;
+		/*
+		 * Tell the thread to set its affinity. This is
+		 * important for shared interrupt handlers as we do
+		 * not invoke setup_affinity() for the secondary
+		 * handlers as everything is already set up. Even for
+		 * interrupts marked with IRQF_NO_BALANCE this is
+		 * correct as we want the thread to move to the cpu(s)
+		 * on which the requesting code placed the interrupt.
+		 */
+		set_bit(IRQTF_AFFINITY, &new->thread_flags);
 	}
 
 	if (!alloc_cpumask_var(&mask, GFP_KERNEL)) {

commit f3de44edf376d18773febca6a37800c042bada7d
Author: Sankara Muthukrishnan <sankara.m@gmail.com>
Date:   Wed Oct 31 15:41:23 2012 -0500

    irq: Set CPU affinity right on thread creation
    
    As irq_thread_check_affinity is called ONLY inside the while loop in
    the irq thread, the core affinity is set only when an interrupt
    occurs. This patch sets the core affinity right after the irq thread
    is created and before it waits for interrupts. In real-tiime targets
    that do not typically change the core affinity of irqs during
    run-time, this patch will save additional latency of an irq thread in
    setting the core affinity during the first interrupt occurrence for
    that irq.
    
    Signed-off-by: Sankara S Muthukrishnan <sankara.m@ni.com>
    Acked-by: Steven Rostedt <rostedt@goodmis.org>
    Link: http://lkml.kernel.org/r/CAFQPvXeVZ858WFYimEU5uvLNxLDd6bJMmqWihFmbCf3ntokz0A@mail.gmail.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index d06a396c7ce3..1cbd572f6ad8 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -849,6 +849,8 @@ static int irq_thread(void *data)
 	init_task_work(&on_exit_work, irq_thread_dtor);
 	task_work_add(current, &on_exit_work, false);
 
+	irq_thread_check_affinity(desc, action);
+
 	while (!irq_wait_for_interrupt(action)) {
 		irqreturn_t action_ret;
 

commit 293a7a0a165c4f8327bbcf396cee9ec672727c98
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Oct 16 15:07:49 2012 -0700

    genirq: Provide means to retrigger parent
    
    Attempts to retrigger nested threaded IRQs currently fail because they
    have no primary handler. In order to support retrigger of nested
    IRQs, the parent IRQ needs to be retriggered.
    
    To fix, when an IRQ needs to be resent, if the interrupt has a parent
    IRQ and runs in the context of the parent IRQ, then resend the parent.
    
    Also, handle_nested_irq() needs to clear the replay flag like the
    other handlers, otherwise check_irq_resend() will set it and it will
    never be cleared.  Without clearing, it results in the first resend
    working fine, but check_irq_resend() returning early on subsequent
    resends because the replay flag is still set.
    
    Problem discovered on ARM/OMAP platforms where a nested IRQ that's
    also a wakeup IRQ happens late in suspend and needed to be retriggered
    during the resume process.
    
    [khilman@ti.com: changelog edits, clear IRQS_REPLAY in handle_nested_irq()]
    
    Reported-by: Kevin Hilman <khilman@ti.com>
    Tested-by: Kevin Hilman <khilman@ti.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Link: http://lkml.kernel.org/r/1350425269-11489-1-git-send-email-khilman@deeprootsystems.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 4c69326aa773..d06a396c7ce3 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -616,6 +616,22 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 	return ret;
 }
 
+#ifdef CONFIG_HARDIRQS_SW_RESEND
+int irq_set_parent(int irq, int parent_irq)
+{
+	unsigned long flags;
+	struct irq_desc *desc = irq_get_desc_lock(irq, &flags, 0);
+
+	if (!desc)
+		return -EINVAL;
+
+	desc->parent_irq = parent_irq;
+
+	irq_put_desc_unlock(desc, flags);
+	return 0;
+}
+#endif
+
 /*
  * Default primary interrupt handler for threaded interrupts. Is
  * assigned as primary handler when request_threaded_irq is called

commit 148311d2ade909a79afb85a853c7979eb499563f
Merge: d97e1dcde5e1 dc9b229a58dc
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Aug 3 10:56:44 2012 -0700

    Merge branch 'irq-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull irq fix from Ingo Molnar.
    
    * 'irq-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      genirq: Allow irq chips to mark themself oneshot safe

commit 3e9a97082fa639394e905e1fc4a0a7f719ca7644
Merge: 941c8726e4e7 d2e7c96af1e5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 31 19:07:42 2012 -0700

    Merge tag 'random_for_linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tytso/random
    
    Pull random subsystem patches from Ted Ts'o:
     "This patch series contains a major revamp of how we collect entropy
      from interrupts for /dev/random and /dev/urandom.
    
      The goal is to addresses weaknesses discussed in the paper "Mining
      your Ps and Qs: Detection of Widespread Weak Keys in Network Devices",
      by Nadia Heninger, Zakir Durumeric, Eric Wustrow, J.  Alex Halderman,
      which will be published in the Proceedings of the 21st Usenix Security
      Symposium, August 2012.  (See https://factorable.net for more
      information and an extended version of the paper.)"
    
    Fix up trivial conflicts due to nearby changes in
    drivers/{mfd/ab3100-core.c, usb/gadget/omap_udc.c}
    
    * tag 'random_for_linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tytso/random: (33 commits)
      random: mix in architectural randomness in extract_buf()
      dmi: Feed DMI table to /dev/random driver
      random: Add comment to random_initialize()
      random: final removal of IRQF_SAMPLE_RANDOM
      um: remove IRQF_SAMPLE_RANDOM which is now a no-op
      sparc/ldc: remove IRQF_SAMPLE_RANDOM which is now a no-op
      [ARM] pxa: remove IRQF_SAMPLE_RANDOM which is now a no-op
      board-palmz71: remove IRQF_SAMPLE_RANDOM which is now a no-op
      isp1301_omap: remove IRQF_SAMPLE_RANDOM which is now a no-op
      pxa25x_udc: remove IRQF_SAMPLE_RANDOM which is now a no-op
      omap_udc: remove IRQF_SAMPLE_RANDOM which is now a no-op
      goku_udc: remove IRQF_SAMPLE_RANDOM which was commented out
      uartlite: remove IRQF_SAMPLE_RANDOM which is now a no-op
      drivers: hv: remove IRQF_SAMPLE_RANDOM which is now a no-op
      xen-blkfront: remove IRQF_SAMPLE_RANDOM which is now a no-op
      n2_crypto: remove IRQF_SAMPLE_RANDOM which is now a no-op
      pda_power: remove IRQF_SAMPLE_RANDOM which is now a no-op
      i2c-pmcmsp: remove IRQF_SAMPLE_RANDOM which is now a no-op
      input/serio/hp_sdc.c: remove IRQF_SAMPLE_RANDOM which is now a no-op
      mfd: remove IRQF_SAMPLE_RANDOM which is now a no-op
      ...

commit dc9b229a58dc0dfed34272ff26c6d5fd17c674e0
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jul 13 19:29:45 2012 +0200

    genirq: Allow irq chips to mark themself oneshot safe
    
    Some interrupt chips like MSI are oneshot safe by implementation. For
    those interrupts we can avoid the mask/unmask sequence for threaded
    interrupt handlers.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/alpine.LFD.2.02.1207132056540.32033@ionos
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Avi Kivity <avi@redhat.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: Jan Kiszka <jan.kiszka@web.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 8c548232ba39..2e326d1ebec1 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -959,6 +959,18 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		goto out_thread;
 	}
 
+	/*
+	 * Drivers are often written to work w/o knowledge about the
+	 * underlying irq chip implementation, so a request for a
+	 * threaded irq without a primary hard irq context handler
+	 * requires the ONESHOT flag to be set. Some irq chips like
+	 * MSI based interrupts are per se one shot safe. Check the
+	 * chip flags, so we can avoid the unmask dance at the end of
+	 * the threaded handler for those.
+	 */
+	if (desc->irq_data.chip->flags & IRQCHIP_ONESHOT_SAFE)
+		new->flags &= ~IRQF_ONESHOT;
+
 	/*
 	 * The following block of code has to be executed atomically
 	 */
@@ -1033,7 +1045,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		 */
 		new->thread_mask = 1 << ffz(thread_mask);
 
-	} else if (new->handler == irq_default_primary_handler) {
+	} else if (new->handler == irq_default_primary_handler &&
+		   !(desc->irq_data.chip->flags & IRQCHIP_ONESHOT_SAFE)) {
 		/*
 		 * The interrupt was requested with handler = NULL, so
 		 * we use the default primary handler for it. But it

commit 67d1214551e800f9fe7dc7c47a346d2df0fafed5
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Jun 27 11:07:19 2012 +0400

    merge task_work and rcu_head, get rid of separate allocation for keyring case
    
    task_work and rcu_head are identical now; merge them (calling the result
    struct callback_head, rcu_head #define'd to it), kill separate allocation
    in security/keys since we can just use cred->rcu now.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index d1dd54734ce7..814c9ef6bba1 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -781,7 +781,7 @@ static void wake_threads_waitq(struct irq_desc *desc)
 		wake_up(&desc->wait_for_threads);
 }
 
-static void irq_thread_dtor(struct task_work *unused)
+static void irq_thread_dtor(struct callback_head *unused)
 {
 	struct task_struct *tsk = current;
 	struct irq_desc *desc;
@@ -813,7 +813,7 @@ static void irq_thread_dtor(struct task_work *unused)
  */
 static int irq_thread(void *data)
 {
-	struct task_work on_exit_work;
+	struct callback_head on_exit_work;
 	static const struct sched_param param = {
 		.sched_priority = MAX_USER_RT_PRIO/2,
 	};

commit 41f9d29f09ca0b22c3631e8a39676e74cda9bcc0
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Jun 26 22:10:04 2012 +0400

    trimming task_work: kill ->data
    
    get rid of the only user of ->data; this is _not_ the final variant - in the
    end we'll have task_work and rcu_head identical and just use cred->rcu,
    at which point the separate allocation will be gone completely.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 8c548232ba39..d1dd54734ce7 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -830,7 +830,7 @@ static int irq_thread(void *data)
 
 	sched_setscheduler(current, SCHED_FIFO, &param);
 
-	init_task_work(&on_exit_work, irq_thread_dtor, NULL);
+	init_task_work(&on_exit_work, irq_thread_dtor);
 	task_work_add(current, &on_exit_work, false);
 
 	while (!irq_wait_for_interrupt(action)) {

commit c5857ccf293968348e5eb4ebedc68074de3dcda6
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Sat Jul 14 20:27:52 2012 -0400

    random: remove rand_initialize_irq()
    
    With the new interrupt sampling system, we are no longer using the
    timer_rand_state structure in the irq descriptor, so we can stop
    initializing it now.
    
    [ Merged in fixes from Sedat to find some last missing references to
      rand_initialize_irq() ]
    
    Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Sedat Dilek <sedat.dilek@gmail.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 8c548232ba39..5e42eb119677 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -893,22 +893,6 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		return -ENOSYS;
 	if (!try_module_get(desc->owner))
 		return -ENODEV;
-	/*
-	 * Some drivers like serial.c use request_irq() heavily,
-	 * so we have to be careful not to interfere with a
-	 * running system.
-	 */
-	if (new->flags & IRQF_SAMPLE_RANDOM) {
-		/*
-		 * This function might sleep, we want to call it first,
-		 * outside of the atomic block.
-		 * Yes, this might clear the entropy pool if the wrong
-		 * driver is attempted to be loaded, without actually
-		 * installing a new handler, but is this really a problem,
-		 * only the sysadmin is able to do this.
-		 */
-		rand_initialize_irq(irq);
-	}
 
 	/*
 	 * Check whether the interrupt nests into another interrupt
@@ -1354,7 +1338,6 @@ EXPORT_SYMBOL(free_irq);
  *	Flags:
  *
  *	IRQF_SHARED		Interrupt is shared
- *	IRQF_SAMPLE_RANDOM	The interrupt can be used for entropy
  *	IRQF_TRIGGER_*		Specify active edge(s) or level
  *
  */

commit 9171c670b4915e30360c2aed530b8377fbbcc852
Merge: c22072bdf053 818b0f3bfb23 4a70d2d9909b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jun 4 11:36:51 2012 -0700

    Merge branches 'irq-urgent-for-linus' and 'smp-hotplug-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull irq and smpboot updates from Thomas Gleixner:
     "Just cleanup patches with no functional change and a fix for suspend
      issues."
    
    * 'irq-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      genirq: Introduce irq_do_set_affinity() to reduce duplicated code
      genirq: Add IRQS_PENDING for nested and simple irq
    
    * 'smp-hotplug-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      smpboot, idle: Fix comment mismatch over idle_threads_init()
      smpboot, idle: Optimize calls to smp_processor_id() in idle_threads_init()

commit fb21affa49204acd409328415b49bfe90136653c
Merge: a00b6151a2ae f23ca335462e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu May 31 18:47:30 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal
    
    Pull second pile of signal handling patches from Al Viro:
     "This one is just task_work_add() series + remaining prereqs for it.
    
      There probably will be another pull request from that tree this
      cycle - at least for helpers, to get them out of the way for per-arch
      fixes remaining in the tree."
    
    Fix trivial conflict in kernel/irq/manage.c: the merge of Andrew's pile
    had brought in commit 97fd75b7b8e0 ("kernel/irq/manage.c: use the
    pr_foo() infrastructure to prefix printks") which changed one of the
    pr_err() calls that this merge moves around.
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal:
      keys: kill task_struct->replacement_session_keyring
      keys: kill the dummy key_replace_session_keyring()
      keys: change keyctl_session_to_parent() to use task_work_add()
      genirq: reimplement exit_irq_thread() hook via task_work_add()
      task_work_add: generic process-context callbacks
      avr32: missed _TIF_NOTIFY_RESUME on one of do_notify_resume callers
      parisc: need to check NOTIFY_RESUME when exiting from syscall
      move key_repace_session_keyring() into tracehook_notify_resume()
      TIF_NOTIFY_RESUME is defined on all targets now

commit 97fd75b7b8e0f4e6d3f06b819c89b2555f626fcf
Author: Andrew Morton <akpm@linux-foundation.org>
Date:   Thu May 31 16:26:07 2012 -0700

    kernel/irq/manage.c: use the pr_foo() infrastructure to prefix printks
    
    Use the module-wide pr_fmt() mechanism rather than open-coding "genirq: "
    everywhere.
    
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index bb32326afe87..7c475cd3f6e6 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -7,6 +7,8 @@
  * This file contains driver APIs to the irq subsystem.
  */
 
+#define pr_fmt(fmt) "genirq: " fmt
+
 #include <linux/irq.h>
 #include <linux/kthread.h>
 #include <linux/module.h>
@@ -565,7 +567,7 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 		 * IRQF_TRIGGER_* but the PIC does not support multiple
 		 * flow-types?
 		 */
-		pr_debug("genirq: No set_type function for IRQ %d (%s)\n", irq,
+		pr_debug("No set_type function for IRQ %d (%s)\n", irq,
 			 chip ? (chip->name ? : "unknown") : "unknown");
 		return 0;
 	}
@@ -600,7 +602,7 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 		ret = 0;
 		break;
 	default:
-		pr_err("genirq: Setting trigger mode %lu for irq %u failed (%pF)\n",
+		pr_err("Setting trigger mode %lu for irq %u failed (%pF)\n",
 		       flags, irq, chip->irq_set_type);
 	}
 	if (unmask)
@@ -837,7 +839,7 @@ void exit_irq_thread(void)
 
 	action = kthread_data(tsk);
 
-	pr_err("genirq: exiting task \"%s\" (%d) is an active IRQ thread (irq %d)\n",
+	pr_err("exiting task \"%s\" (%d) is an active IRQ thread (irq %d)\n",
 	       tsk->comm ? tsk->comm : "", tsk->pid, action->irq);
 
 	desc = irq_to_desc(action->irq);
@@ -1044,7 +1046,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		 * has. The type flags are unreliable as the
 		 * underlying chip implementation can override them.
 		 */
-		pr_err("genirq: Threaded irq requested with handler=NULL and !ONESHOT for irq %d\n",
+		pr_err("Threaded irq requested with handler=NULL and !ONESHOT for irq %d\n",
 		       irq);
 		ret = -EINVAL;
 		goto out_mask;
@@ -1095,7 +1097,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 		if (nmsk != omsk)
 			/* hope the handler works with current  trigger mode */
-			pr_warning("genirq: irq %d uses trigger mode %u; requested %u\n",
+			pr_warning("irq %d uses trigger mode %u; requested %u\n",
 				   irq, nmsk, omsk);
 	}
 
@@ -1133,7 +1135,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 mismatch:
 	if (!(new->flags & IRQF_PROBE_SHARED)) {
-		pr_err("genirq: Flags mismatch irq %d. %08x (%s) vs. %08x (%s)\n",
+		pr_err("Flags mismatch irq %d. %08x (%s) vs. %08x (%s)\n",
 		       irq, new->flags, new->name, old->flags, old->name);
 #ifdef CONFIG_DEBUG_SHIRQ
 		dump_stack();

commit 818b0f3bfb236ae66cac3ff38e86b9e47f24b7aa
Author: Jiang Liu <liuj97@gmail.com>
Date:   Fri Mar 30 23:11:34 2012 +0800

    genirq: Introduce irq_do_set_affinity() to reduce duplicated code
    
    All invocations of chip->irq_set_affinity() are doing the same return
    value checks. Let them all use a common function.
    
    [ tglx: removed the silly likely while at it ]
    
    Signed-off-by: Jiang Liu <jiang.liu@huawei.com>
    Cc: Jiang Liu <liuj97@gmail.com>
    Cc: Keping Chen <chenkeping@huawei.com>
    Link: http://lkml.kernel.org/r/1333120296-13563-3-git-send-email-jiang.liu@huawei.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index bb32326afe87..a1b903380bcf 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -139,6 +139,25 @@ static inline void
 irq_get_pending(struct cpumask *mask, struct irq_desc *desc) { }
 #endif
 
+int irq_do_set_affinity(struct irq_data *data, const struct cpumask *mask,
+			bool force)
+{
+	struct irq_desc *desc = irq_data_to_desc(data);
+	struct irq_chip *chip = irq_data_get_irq_chip(data);
+	int ret;
+
+	ret = chip->irq_set_affinity(data, mask, false);
+	switch (ret) {
+	case IRQ_SET_MASK_OK:
+		cpumask_copy(data->affinity, mask);
+	case IRQ_SET_MASK_OK_NOCOPY:
+		irq_set_thread_affinity(desc);
+		ret = 0;
+	}
+
+	return ret;
+}
+
 int __irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask)
 {
 	struct irq_chip *chip = irq_data_get_irq_chip(data);
@@ -149,14 +168,7 @@ int __irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask)
 		return -EINVAL;
 
 	if (irq_can_move_pcntxt(data)) {
-		ret = chip->irq_set_affinity(data, mask, false);
-		switch (ret) {
-		case IRQ_SET_MASK_OK:
-			cpumask_copy(data->affinity, mask);
-		case IRQ_SET_MASK_OK_NOCOPY:
-			irq_set_thread_affinity(desc);
-			ret = 0;
-		}
+		ret = irq_do_set_affinity(data, mask, false);
 	} else {
 		irqd_set_move_pending(data);
 		irq_copy_pending(desc, mask);
@@ -280,9 +292,8 @@ EXPORT_SYMBOL_GPL(irq_set_affinity_notifier);
 static int
 setup_affinity(unsigned int irq, struct irq_desc *desc, struct cpumask *mask)
 {
-	struct irq_chip *chip = irq_desc_get_chip(desc);
 	struct cpumask *set = irq_default_affinity;
-	int ret, node = desc->irq_data.node;
+	int node = desc->irq_data.node;
 
 	/* Excludes PER_CPU and NO_BALANCE interrupts */
 	if (!irq_can_set_affinity(irq))
@@ -308,13 +319,7 @@ setup_affinity(unsigned int irq, struct irq_desc *desc, struct cpumask *mask)
 		if (cpumask_intersects(mask, nodemask))
 			cpumask_and(mask, mask, nodemask);
 	}
-	ret = chip->irq_set_affinity(&desc->irq_data, mask, false);
-	switch (ret) {
-	case IRQ_SET_MASK_OK:
-		cpumask_copy(desc->irq_data.affinity, mask);
-	case IRQ_SET_MASK_OK_NOCOPY:
-		irq_set_thread_affinity(desc);
-	}
+	irq_do_set_affinity(&desc->irq_data, mask, false);
 	return 0;
 }
 #else

commit 4d1d61a6b203d957777d73fcebf19d90b038b5b2
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri May 11 10:59:08 2012 +1000

    genirq: reimplement exit_irq_thread() hook via task_work_add()
    
    exit_irq_thread() and task->irq_thread are needed to handle the unexpected
    (and unlikely) exit of irq-thread.
    
    We can use task_work instead and make this all private to
    kernel/irq/manage.c, cleanup plus micro-optimization.
    
    1. rename exit_irq_thread() to irq_thread_dtor(), make it
       static, and move it up before irq_thread().
    
    2. change irq_thread() to do task_work_add(irq_thread_dtor)
       at the start and task_work_cancel() before return.
    
       tracehook_notify_resume() can never play with kthreads,
       only do_exit()->exit_task_work() can call the callback
       and this is what we want.
    
    3. remove task_struct->irq_thread and the special hook
       in do_exit().
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Alexander Gordeev <agordeev@redhat.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: David Smith <dsmith@redhat.com>
    Cc: "Frank Ch. Eigler" <fche@redhat.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Larry Woodman <lwoodman@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index bb32326afe87..4d1f8f897414 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -14,6 +14,7 @@
 #include <linux/interrupt.h>
 #include <linux/slab.h>
 #include <linux/sched.h>
+#include <linux/task_work.h>
 
 #include "internals.h"
 
@@ -773,11 +774,39 @@ static void wake_threads_waitq(struct irq_desc *desc)
 		wake_up(&desc->wait_for_threads);
 }
 
+static void irq_thread_dtor(struct task_work *unused)
+{
+	struct task_struct *tsk = current;
+	struct irq_desc *desc;
+	struct irqaction *action;
+
+	if (WARN_ON_ONCE(!(current->flags & PF_EXITING)))
+		return;
+
+	action = kthread_data(tsk);
+
+	pr_err("genirq: exiting task \"%s\" (%d) is an active IRQ thread (irq %d)\n",
+	       tsk->comm ? tsk->comm : "", tsk->pid, action->irq);
+
+
+	desc = irq_to_desc(action->irq);
+	/*
+	 * If IRQTF_RUNTHREAD is set, we need to decrement
+	 * desc->threads_active and wake possible waiters.
+	 */
+	if (test_and_clear_bit(IRQTF_RUNTHREAD, &action->thread_flags))
+		wake_threads_waitq(desc);
+
+	/* Prevent a stale desc->threads_oneshot */
+	irq_finalize_oneshot(desc, action);
+}
+
 /*
  * Interrupt handler thread
  */
 static int irq_thread(void *data)
 {
+	struct task_work on_exit_work;
 	static const struct sched_param param = {
 		.sched_priority = MAX_USER_RT_PRIO/2,
 	};
@@ -793,7 +822,9 @@ static int irq_thread(void *data)
 		handler_fn = irq_thread_fn;
 
 	sched_setscheduler(current, SCHED_FIFO, &param);
-	current->irq_thread = 1;
+
+	init_task_work(&on_exit_work, irq_thread_dtor, NULL);
+	task_work_add(current, &on_exit_work, false);
 
 	while (!irq_wait_for_interrupt(action)) {
 		irqreturn_t action_ret;
@@ -815,44 +846,11 @@ static int irq_thread(void *data)
 	 * cannot touch the oneshot mask at this point anymore as
 	 * __setup_irq() might have given out currents thread_mask
 	 * again.
-	 *
-	 * Clear irq_thread. Otherwise exit_irq_thread() would make
-	 * fuzz about an active irq thread going into nirvana.
 	 */
-	current->irq_thread = 0;
+	task_work_cancel(current, irq_thread_dtor);
 	return 0;
 }
 
-/*
- * Called from do_exit()
- */
-void exit_irq_thread(void)
-{
-	struct task_struct *tsk = current;
-	struct irq_desc *desc;
-	struct irqaction *action;
-
-	if (!tsk->irq_thread)
-		return;
-
-	action = kthread_data(tsk);
-
-	pr_err("genirq: exiting task \"%s\" (%d) is an active IRQ thread (irq %d)\n",
-	       tsk->comm ? tsk->comm : "", tsk->pid, action->irq);
-
-	desc = irq_to_desc(action->irq);
-
-	/*
-	 * If IRQTF_RUNTHREAD is set, we need to decrement
-	 * desc->threads_active and wake possible waiters.
-	 */
-	if (test_and_clear_bit(IRQTF_RUNTHREAD, &action->thread_flags))
-		wake_threads_waitq(desc);
-
-	/* Prevent a stale desc->threads_oneshot */
-	irq_finalize_oneshot(desc, action);
-}
-
 static void irq_setup_forced_threading(struct irqaction *new)
 {
 	if (!force_irqthreads)

commit 3a8580f82024e30b31c662aa49346adf7a3bcdb5
Merge: 1d767cae4dbd 2ccf62b36097
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 23 09:01:41 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rw/uml
    
    Pull UML updates from Richard Weinberger:
     "Most changes are bug fixes and cleanups"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rw/uml:
      um: missing checks of __put_user()/__get_user() return values
      um: stub_rt_sigsuspend isn't needed these days anymore
      um/x86: merge (and trim) 32- and 64-bit variants of ptrace.h
      irq: Remove irq_chip->release()
      um: Remove CONFIG_IRQ_RELEASE_METHOD
      um: Remove usage of irq_chip->release()
      um: Implement um_free_irq()
      um: Fix __swp_type()
      um: Implement a custom pte_same() function
      um: Add BUG() to do_ops()'s error path
      um: Remove unused variables
      um: bury unused _TIF_RESTORE_SIGMASK
      um: wrong sigmask saved in case of multiple sigframes
      um: add TIF_NOTIFY_RESUME
      um: ->restart_block.fn needs to be reset on sigreturn

commit 875682648b89a3ebc06176d60dc280f810647839
Author: Richard Weinberger <richard@nod.at>
Date:   Tue Apr 17 22:37:16 2012 +0200

    irq: Remove irq_chip->release()
    
    As it's only user (UML) does no longer need it we can get
    rid of it.
    
    Signed-off-by: Richard Weinberger <richard@nod.at>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 89a3ea82569b..9b7f68a00e5e 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1204,12 +1204,6 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 	/* Found it - now remove it from the list of entries: */
 	*action_ptr = action->next;
 
-	/* Currently used only by UML, might disappear one day: */
-#ifdef CONFIG_IRQ_RELEASE_METHOD
-	if (desc->irq_data.chip->release)
-		desc->irq_data.chip->release(irq, dev_id);
-#endif
-
 	/* If this was the last handler, shut down the IRQ line: */
 	if (!desc->action)
 		irq_shutdown(desc);

commit f5d89470f91f2e67eeaf350c730ae8412c3a98e3
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Apr 19 12:06:13 2012 +0200

    genirq: Be more informative on irq type mismatch
    
    We require that shared interrupts agree on a few flag settings. Right
    now we silently return with an error code without giving any hint why
    we reject it.
    
    Make the printout unconditionally and actually useful by printing the
    flags of the new and the already registered action.
    
    Convert all printks to pr_* and use a proper prefix while at it.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 9a35ace38bb1..585f6381f8e4 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -565,8 +565,8 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 		 * IRQF_TRIGGER_* but the PIC does not support multiple
 		 * flow-types?
 		 */
-		pr_debug("No set_type function for IRQ %d (%s)\n", irq,
-				chip ? (chip->name ? : "unknown") : "unknown");
+		pr_debug("genirq: No set_type function for IRQ %d (%s)\n", irq,
+			 chip ? (chip->name ? : "unknown") : "unknown");
 		return 0;
 	}
 
@@ -600,7 +600,7 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 		ret = 0;
 		break;
 	default:
-		pr_err("setting trigger mode %lu for irq %u failed (%pF)\n",
+		pr_err("genirq: Setting trigger mode %lu for irq %u failed (%pF)\n",
 		       flags, irq, chip->irq_set_type);
 	}
 	if (unmask)
@@ -837,8 +837,7 @@ void exit_irq_thread(void)
 
 	action = kthread_data(tsk);
 
-	printk(KERN_ERR
-	       "exiting task \"%s\" (%d) is an active IRQ thread (irq %d)\n",
+	pr_err("genirq: exiting task \"%s\" (%d) is an active IRQ thread (irq %d)\n",
 	       tsk->comm ? tsk->comm : "", tsk->pid, action->irq);
 
 	desc = irq_to_desc(action->irq);
@@ -878,7 +877,6 @@ static int
 __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 {
 	struct irqaction *old, **old_ptr;
-	const char *old_name = NULL;
 	unsigned long flags, thread_mask = 0;
 	int ret, nested, shared = 0;
 	cpumask_var_t mask;
@@ -972,10 +970,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		 */
 		if (!((old->flags & new->flags) & IRQF_SHARED) ||
 		    ((old->flags ^ new->flags) & IRQF_TRIGGER_MASK) ||
-		    ((old->flags ^ new->flags) & IRQF_ONESHOT)) {
-			old_name = old->name;
+		    ((old->flags ^ new->flags) & IRQF_ONESHOT))
 			goto mismatch;
-		}
 
 		/* All handlers must agree on per-cpuness */
 		if ((old->flags & IRQF_PERCPU) !=
@@ -1099,7 +1095,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 		if (nmsk != omsk)
 			/* hope the handler works with current  trigger mode */
-			pr_warning("IRQ %d uses trigger mode %u; requested %u\n",
+			pr_warning("genirq: irq %d uses trigger mode %u; requested %u\n",
 				   irq, nmsk, omsk);
 	}
 
@@ -1136,14 +1132,13 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	return 0;
 
 mismatch:
-#ifdef CONFIG_DEBUG_SHIRQ
 	if (!(new->flags & IRQF_PROBE_SHARED)) {
-		printk(KERN_ERR "IRQ handler type mismatch for IRQ %d\n", irq);
-		if (old_name)
-			printk(KERN_ERR "current handler: %s\n", old_name);
+		pr_err("genirq: Flags mismatch irq %d. %08x (%s) vs. %08x (%s)\n",
+		       irq, new->flags, new->name, old->flags, old->name);
+#ifdef CONFIG_DEBUG_SHIRQ
 		dump_stack();
-	}
 #endif
+	}
 	ret = -EBUSY;
 
 out_mask:

commit 1c6c69525b40eb76de8adf039409722015927dc3
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Apr 19 10:35:17 2012 +0200

    genirq: Reject bogus threaded irq requests
    
    Requesting a threaded interrupt without a primary handler and without
    IRQF_ONESHOT set is dangerous.
    
    The core will use the default primary handler for it, which merily
    wakes the thread. For a level type interrupt this results in an
    interrupt storm, because the interrupt line is reenabled after the
    primary handler runs. The device has still the line asserted, which
    brings us back into the primary handler.
    
    While this works for edge type interrupts, we play it safe and reject
    unconditionally because we can't say for sure which type this
    interrupt really has. The type flags are unreliable as the underlying
    chip implementation can override them. And we cannot assume that
    developers using that interface know what they are doing.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 89a3ea82569b..9a35ace38bb1 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1031,6 +1031,27 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		 * all existing action->thread_mask bits.
 		 */
 		new->thread_mask = 1 << ffz(thread_mask);
+
+	} else if (new->handler == irq_default_primary_handler) {
+		/*
+		 * The interrupt was requested with handler = NULL, so
+		 * we use the default primary handler for it. But it
+		 * does not have the oneshot flag set. In combination
+		 * with level interrupts this is deadly, because the
+		 * default primary handler just wakes the thread, then
+		 * the irq lines is reenabled, but the device still
+		 * has the level irq asserted. Rinse and repeat....
+		 *
+		 * While this works for edge type interrupts, we play
+		 * it safe and reject unconditionally because we can't
+		 * say for sure which type this interrupt really
+		 * has. The type flags are unreliable as the
+		 * underlying chip implementation can override them.
+		 */
+		pr_err("genirq: Threaded irq requested with handler=NULL and !ONESHOT for irq %d\n",
+		       irq);
+		ret = -EINVAL;
+		goto out_mask;
 	}
 
 	if (!shared) {

commit 241fc640be783f903e74b6d9c68481c01873f758
Author: Prarit Bhargava <prarit@redhat.com>
Date:   Mon Mar 26 15:02:18 2012 -0400

    genirq: Respect NUMA node affinity in setup_irq_irq affinity()
    
    We respect node affinity of devices already in the irq descriptor
    allocation, but we ignore it for the initial interrupt affinity
    setup, so the interrupt might be routed to a different node.
    
    Restrict the default affinity mask to the node on which the irq
    descriptor is allocated.
    
    [ tglx: Massaged changelog ]
    
    Signed-off-by: Prarit Bhargava <prarit@redhat.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: David Rientjes <rientjes@google.com>
    Link: http://lkml.kernel.org/r/1332788538-17425-1-git-send-email-prarit@redhat.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index bf606a53a21c..89a3ea82569b 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -282,7 +282,7 @@ setup_affinity(unsigned int irq, struct irq_desc *desc, struct cpumask *mask)
 {
 	struct irq_chip *chip = irq_desc_get_chip(desc);
 	struct cpumask *set = irq_default_affinity;
-	int ret;
+	int ret, node = desc->irq_data.node;
 
 	/* Excludes PER_CPU and NO_BALANCE interrupts */
 	if (!irq_can_set_affinity(irq))
@@ -301,6 +301,13 @@ setup_affinity(unsigned int irq, struct irq_desc *desc, struct cpumask *mask)
 	}
 
 	cpumask_and(mask, cpu_online_mask, set);
+	if (node != NUMA_NO_NODE) {
+		const struct cpumask *nodemask = cpumask_of_node(node);
+
+		/* make sure at least one of the cpus in nodemask is online */
+		if (cpumask_intersects(mask, nodemask))
+			cpumask_and(mask, mask, nodemask);
+	}
 	ret = chip->irq_set_affinity(&desc->irq_data, mask, false);
 	switch (ret) {
 	case IRQ_SET_MASK_OK:

commit f3f79e38d51f8a419f4c484a86ece4baea35b993
Author: Alexander Gordeev <agordeev@redhat.com>
Date:   Wed Mar 21 17:22:35 2012 +0100

    genirq: Get rid of unneeded force parameter in irq_finalize_oneshot()
    
    The only place irq_finalize_oneshot() is called with force parameter set
    is the threaded handler error exit path. But IRQTF_RUNTHREAD is dropped
    at this point and irq_wake_thread() is not going to set it again,
    since PF_EXITING is set for this thread already. So irq_finalize_oneshot()
    will drop the threads bit in threads_oneshot anyway and hence the force
    parameter is superfluous.
    
    Signed-off-by: Alexander Gordeev <agordeev@redhat.com>
    Link: http://lkml.kernel.org/r/20120321162234.GP24806@dhcp-26-207.brq.redhat.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index b0ccd1ac2d6a..bf606a53a21c 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -645,7 +645,7 @@ static int irq_wait_for_interrupt(struct irqaction *action)
  * is marked MASKED.
  */
 static void irq_finalize_oneshot(struct irq_desc *desc,
-				 struct irqaction *action, bool force)
+				 struct irqaction *action)
 {
 	if (!(desc->istate & IRQS_ONESHOT))
 		return;
@@ -679,7 +679,7 @@ static void irq_finalize_oneshot(struct irq_desc *desc,
 	 * we would clear the threads_oneshot bit of this thread which
 	 * was just set.
 	 */
-	if (!force && test_bit(IRQTF_RUNTHREAD, &action->thread_flags))
+	if (test_bit(IRQTF_RUNTHREAD, &action->thread_flags))
 		goto out_unlock;
 
 	desc->threads_oneshot &= ~action->thread_mask;
@@ -739,7 +739,7 @@ irq_forced_thread_fn(struct irq_desc *desc, struct irqaction *action)
 
 	local_bh_disable();
 	ret = action->thread_fn(action->irq, action->dev_id);
-	irq_finalize_oneshot(desc, action, false);
+	irq_finalize_oneshot(desc, action);
 	local_bh_enable();
 	return ret;
 }
@@ -755,7 +755,7 @@ static irqreturn_t irq_thread_fn(struct irq_desc *desc,
 	irqreturn_t ret;
 
 	ret = action->thread_fn(action->irq, action->dev_id);
-	irq_finalize_oneshot(desc, action, false);
+	irq_finalize_oneshot(desc, action);
 	return ret;
 }
 
@@ -844,7 +844,7 @@ void exit_irq_thread(void)
 		wake_threads_waitq(desc);
 
 	/* Prevent a stale desc->threads_oneshot */
-	irq_finalize_oneshot(desc, action, true);
+	irq_finalize_oneshot(desc, action);
 }
 
 static void irq_setup_forced_threading(struct irqaction *new)

commit e04268b0effc0ceea366c50b3107baad9edadafa
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Mar 15 22:55:21 2012 +0100

    genirq: Remove paranoid warnons and bogus fixups
    
    Alexander pointed out that the warnons in the regular exit path are
    bogus and the thread_mask one actually could be triggered when
    __setup_irq() hands out that thread_mask again after __free_irq()
    dropped irq_desc->lock.
    
    Thinking more about it, neither IRQTF_RUNTHREAD nor the bit in
    thread_mask can be set as this is the regular exit path. We come here
    due to:
            __free_irq()
               remove action from desc
               synchronize_irq()
               kthread_stop()
    
    So synchronize_irq() makes sure that the thread finished running and
    cleaned up both the thread_active count and thread_mask. After that
    point nothing can set IRQTF_RUNTHREAD on this action. So the warnons
    and the cleanups are pointless.
    
    Reported-by: Alexander Gordeev <agordeev@redhat.com>
    Cc: Ido Yariv <ido@wizery.com>
    Link: http://lkml.kernel.org/r/20120315190755.GA6732@dhcp-26-207.brq.redhat.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 453feedbb390..b0ccd1ac2d6a 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -804,17 +804,11 @@ static int irq_thread(void *data)
 	 * This is the regular exit path. __free_irq() is stopping the
 	 * thread via kthread_stop() after calling
 	 * synchronize_irq(). So neither IRQTF_RUNTHREAD nor the
-	 * oneshot mask bit should be set.
+	 * oneshot mask bit can be set. We cannot verify that as we
+	 * cannot touch the oneshot mask at this point anymore as
+	 * __setup_irq() might have given out currents thread_mask
+	 * again.
 	 *
-	 * Verify that this is true.
-	 */
-	if (WARN_ON(test_and_clear_bit(IRQTF_RUNTHREAD, &action->thread_flags)))
-		wake_threads_waitq(desc);
-
-	if (WARN_ON(desc->threads_oneshot & action->thread_mask))
-		irq_finalize_oneshot(desc, action, true);
-
-	/*
 	 * Clear irq_thread. Otherwise exit_irq_thread() would make
 	 * fuzz about an active irq thread going into nirvana.
 	 */

commit 7140ea1980f2fae9c7aaeac5f6b35317e1389ee6
Author: Ido Yariv <ido@wizery.com>
Date:   Fri Dec 2 18:24:12 2011 +0200

    genirq: Flush the irq thread on synchronization
    
    The current implementation does not always flush the threaded handler
    when disabling the irq. In case the irq handler was called, but the
    threaded handler hasn't started running yet, the interrupt will be
    flagged as pending, and the handler will not run. This implementation
    has some issues:
    
    First, if the interrupt is a wake source and flagged as pending, the
    system will not be able to suspend.
    
    Second, when quickly disabling and re-enabling the irq, the threaded
    handler might continue to run after the irq is re-enabled without the
    irq handler being called first. This might be an unexpected behavior.
    
    In addition, it might be counter-intuitive that the threaded handler
    will not be called even though the irq handler was called and returned
    IRQ_WAKE_THREAD.
    
    Fix this by always waiting for the threaded handler to complete in
    synchronize_irq().
    
    [ tglx: Massaged comments, added WARN_ONs and the missing
            IRQTF_RUNTHREAD check in exit_irq_thread() ]
    
    Signed-off-by: Ido Yariv <ido@wizery.com>
    Link: http://lkml.kernel.org/r/1322843052-7166-1-git-send-email-ido@wizery.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 1786cf7dac54..453feedbb390 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -759,6 +759,13 @@ static irqreturn_t irq_thread_fn(struct irq_desc *desc,
 	return ret;
 }
 
+static void wake_threads_waitq(struct irq_desc *desc)
+{
+	if (atomic_dec_and_test(&desc->threads_active) &&
+	    waitqueue_active(&desc->wait_for_threads))
+		wake_up(&desc->wait_for_threads);
+}
+
 /*
  * Interrupt handler thread
  */
@@ -771,7 +778,6 @@ static int irq_thread(void *data)
 	struct irq_desc *desc = irq_to_desc(action->irq);
 	irqreturn_t (*handler_fn)(struct irq_desc *desc,
 			struct irqaction *action);
-	int wake;
 
 	if (force_irqthreads && test_bit(IRQTF_FORCED_THREAD,
 					&action->thread_flags))
@@ -783,39 +789,30 @@ static int irq_thread(void *data)
 	current->irq_thread = 1;
 
 	while (!irq_wait_for_interrupt(action)) {
+		irqreturn_t action_ret;
 
 		irq_thread_check_affinity(desc, action);
 
-		atomic_inc(&desc->threads_active);
+		action_ret = handler_fn(desc, action);
+		if (!noirqdebug)
+			note_interrupt(action->irq, desc, action_ret);
 
-		raw_spin_lock_irq(&desc->lock);
-		if (unlikely(irqd_irq_disabled(&desc->irq_data))) {
-			/*
-			 * CHECKME: We might need a dedicated
-			 * IRQ_THREAD_PENDING flag here, which
-			 * retriggers the thread in check_irq_resend()
-			 * but AFAICT IRQS_PENDING should be fine as it
-			 * retriggers the interrupt itself --- tglx
-			 */
-			desc->istate |= IRQS_PENDING;
-			raw_spin_unlock_irq(&desc->lock);
-		} else {
-			irqreturn_t action_ret;
-
-			raw_spin_unlock_irq(&desc->lock);
-			action_ret = handler_fn(desc, action);
-			if (!noirqdebug)
-				note_interrupt(action->irq, desc, action_ret);
-		}
-
-		wake = atomic_dec_and_test(&desc->threads_active);
-
-		if (wake && waitqueue_active(&desc->wait_for_threads))
-			wake_up(&desc->wait_for_threads);
+		wake_threads_waitq(desc);
 	}
 
-	/* Prevent a stale desc->threads_oneshot */
-	irq_finalize_oneshot(desc, action, true);
+	/*
+	 * This is the regular exit path. __free_irq() is stopping the
+	 * thread via kthread_stop() after calling
+	 * synchronize_irq(). So neither IRQTF_RUNTHREAD nor the
+	 * oneshot mask bit should be set.
+	 *
+	 * Verify that this is true.
+	 */
+	if (WARN_ON(test_and_clear_bit(IRQTF_RUNTHREAD, &action->thread_flags)))
+		wake_threads_waitq(desc);
+
+	if (WARN_ON(desc->threads_oneshot & action->thread_mask))
+		irq_finalize_oneshot(desc, action, true);
 
 	/*
 	 * Clear irq_thread. Otherwise exit_irq_thread() would make
@@ -845,6 +842,13 @@ void exit_irq_thread(void)
 
 	desc = irq_to_desc(action->irq);
 
+	/*
+	 * If IRQTF_RUNTHREAD is set, we need to decrement
+	 * desc->threads_active and wake possible waiters.
+	 */
+	if (test_and_clear_bit(IRQTF_RUNTHREAD, &action->thread_flags))
+		wake_threads_waitq(desc);
+
 	/* Prevent a stale desc->threads_oneshot */
 	irq_finalize_oneshot(desc, action, true);
 }

commit df8d291f28aa1e8437c8f7816328a6516379c71b
Merge: 5234ffb9f74c fde7d9049e55
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Mar 13 16:34:48 2012 +0100

    Merge branch 'linus' into irq/core
    
    Reason: Get upstream fixes integrated before further modifications.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit 5234ffb9f74cfa8993d174782bc861dd9b7b5bfb
Author: Alexander Gordeev <agordeev@redhat.com>
Date:   Fri Mar 9 14:59:59 2012 +0100

    genirq: Get rid of unnecessary IRQTF_DIED flag
    
    Currently IRQTF_DIED flag is set when a IRQ thread handler calls do_exit()
    But also PF_EXITING per process flag gets set when a thread exits. This
    fix eliminates the duplicate by using PF_EXITING flag.
    
    Also, there is a race condition in exit_irq_thread(). In case a thread's
    bit is cleared in desc->threads_oneshot (and the IRQ line gets unmasked),
    but before IRQTF_DIED flag is set, a new interrupt might come in and set
    just cleared bit again, this time forever. This fix throws IRQTF_DIED flag
    away, eliminating the race as a result.
    
    [ tglx: Test THREAD_EXITING first as suggested by Oleg ]
    
    Reported-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Alexander Gordeev <agordeev@redhat.com>
    Link: http://lkml.kernel.org/r/20120309135958.GD2114@dhcp-26-207.brq.redhat.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 3feab4ab6877..a94466db73b2 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -845,17 +845,8 @@ void exit_irq_thread(void)
 
 	desc = irq_to_desc(action->irq);
 
-	/*
-	 * Prevent a stale desc->threads_oneshot. Must be called
-	 * before setting the IRQTF_DIED flag.
-	 */
+	/* Prevent a stale desc->threads_oneshot */
 	irq_finalize_oneshot(desc, action, true);
-
-	/*
-	 * Set the THREAD DIED flag to prevent further wakeups of the
-	 * soon to be gone threaded handler.
-	 */
-	set_bit(IRQTF_DIED, &action->flags);
 }
 
 static void irq_setup_forced_threading(struct irqaction *new)

commit 05d74efa3c72a5c40b0edeb15856c0230126313b
Author: Alexander Gordeev <agordeev@redhat.com>
Date:   Fri Mar 9 14:59:40 2012 +0100

    genirq: No need to check IRQTF_DIED before stopping a thread handler
    
    Since 63706172f332fd3f6e7458ebfb35fa6de9c21dc5 kthread_stop() is not
    afraid of dead kernel threads. So no need to check if a thread is
    alive before stopping it. These checks still were racy.
    
    Reported-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Alexander Gordeev <agordeev@redhat.com>
    Link: http://lkml.kernel.org/r/20120309135939.GC2114@dhcp-26-207.brq.redhat.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0fa3ce998ecb..3feab4ab6877 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1106,8 +1106,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		struct task_struct *t = new->thread;
 
 		new->thread = NULL;
-		if (likely(!test_bit(IRQTF_DIED, &new->thread_flags)))
-			kthread_stop(t);
+		kthread_stop(t);
 		put_task_struct(t);
 	}
 out_mput:
@@ -1217,8 +1216,7 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 #endif
 
 	if (action->thread) {
-		if (!test_bit(IRQTF_DIED, &action->thread_flags))
-			kthread_stop(action->thread);
+		kthread_stop(action->thread);
 		put_task_struct(action->thread);
 	}
 

commit 4bcdf1d0b652bc33d52f2322b77463e4dc58abf8
Author: Alexander Gordeev <agordeev@redhat.com>
Date:   Fri Mar 9 14:59:26 2012 +0100

    genirq: Get rid of unnecessary irqaction field in task_struct
    
    When a new thread handler is created, an irqaction is passed to it as
    data. Not only that irqaction is stored in task_struct by the handler
    for later use, but also a structure associated with the kernel thread
    keeps this value as long as the thread exists.
    
    This fix kicks irqaction out off task_struct. Yes, I introduce new bit
    field. But it allows not only to eliminate the duplicate, but also
    shortens size of task_struct.
    
    Reported-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Alexander Gordeev <agordeev@redhat.com>
    Link: http://lkml.kernel.org/r/20120309135925.GB2114@dhcp-26-207.brq.redhat.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index c0730ad8a117..0fa3ce998ecb 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -780,7 +780,7 @@ static int irq_thread(void *data)
 		handler_fn = irq_thread_fn;
 
 	sched_setscheduler(current, SCHED_FIFO, &param);
-	current->irqaction = action;
+	current->irq_thread = 1;
 
 	while (!irq_wait_for_interrupt(action)) {
 
@@ -818,10 +818,10 @@ static int irq_thread(void *data)
 	irq_finalize_oneshot(desc, action, true);
 
 	/*
-	 * Clear irqaction. Otherwise exit_irq_thread() would make
+	 * Clear irq_thread. Otherwise exit_irq_thread() would make
 	 * fuzz about an active irq thread going into nirvana.
 	 */
-	current->irqaction = NULL;
+	current->irq_thread = 0;
 	return 0;
 }
 
@@ -832,27 +832,30 @@ void exit_irq_thread(void)
 {
 	struct task_struct *tsk = current;
 	struct irq_desc *desc;
+	struct irqaction *action;
 
-	if (!tsk->irqaction)
+	if (!tsk->irq_thread)
 		return;
 
+	action = kthread_data(tsk);
+
 	printk(KERN_ERR
 	       "exiting task \"%s\" (%d) is an active IRQ thread (irq %d)\n",
-	       tsk->comm ? tsk->comm : "", tsk->pid, tsk->irqaction->irq);
+	       tsk->comm ? tsk->comm : "", tsk->pid, action->irq);
 
-	desc = irq_to_desc(tsk->irqaction->irq);
+	desc = irq_to_desc(action->irq);
 
 	/*
 	 * Prevent a stale desc->threads_oneshot. Must be called
 	 * before setting the IRQTF_DIED flag.
 	 */
-	irq_finalize_oneshot(desc, tsk->irqaction, true);
+	irq_finalize_oneshot(desc, action, true);
 
 	/*
 	 * Set the THREAD DIED flag to prevent further wakeups of the
 	 * soon to be gone threaded handler.
 	 */
-	set_bit(IRQTF_DIED, &tsk->irqaction->flags);
+	set_bit(IRQTF_DIED, &action->flags);
 }
 
 static void irq_setup_forced_threading(struct irqaction *new)

commit 540b60e24f3f4781d80e47122f0c4486a03375b8
Author: Alexander Gordeev <agordeev@redhat.com>
Date:   Fri Mar 9 14:59:13 2012 +0100

    genirq: Fix incorrect check for forced IRQ thread handler
    
    We do not want a bitwise AND between boolean operands
    
    Signed-off-by: Alexander Gordeev <agordeev@redhat.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Link: http://lkml.kernel.org/r/20120309135912.GA2114@dhcp-26-207.brq.redhat.com
    Cc: stable@vger.kernel.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index a9a9dbe49fea..c0730ad8a117 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -773,7 +773,7 @@ static int irq_thread(void *data)
 			struct irqaction *action);
 	int wake;
 
-	if (force_irqthreads & test_bit(IRQTF_FORCED_THREAD,
+	if (force_irqthreads && test_bit(IRQTF_FORCED_THREAD,
 					&action->thread_flags))
 		handler_fn = irq_forced_thread_fn;
 	else

commit 52abb700e16a9aa4cbc03f3d7f80206cbbc80680
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Mar 6 23:18:54 2012 +0100

    genirq: Clear action->thread_mask if IRQ_ONESHOT is not set
    
    Xommit ac5637611(genirq: Unmask oneshot irqs when thread was not woken)
    fails to unmask when a !IRQ_ONESHOT threaded handler is handled by
    handle_level_irq.
    
    This happens because thread_mask is or'ed unconditionally in
    irq_wake_thread(), but for !IRQ_ONESHOT interrupts never cleared.  So
    the check for !desc->thread_active fails and keeps the interrupt
    disabled.
    
    Keep the thread_mask zero for !IRQ_ONESHOT interrupts.
    
    Document the thread_mask magic while at it.
    
    Reported-and-tested-by: Sven Joachim <svenjoac@gmx.de>
    Reported-and-tested-by: Stefan Lippers-Hollmann <s.l-h@gmx.de>
    Cc: stable@vger.kernel.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 32313c084442..0f0d4704ddd8 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -985,6 +985,11 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 		/* add new interrupt at end of irq queue */
 		do {
+			/*
+			 * Or all existing action->thread_mask bits,
+			 * so we can find the next zero bit for this
+			 * new action.
+			 */
 			thread_mask |= old->thread_mask;
 			old_ptr = &old->next;
 			old = *old_ptr;
@@ -993,14 +998,41 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	}
 
 	/*
-	 * Setup the thread mask for this irqaction. Unlikely to have
-	 * 32 resp 64 irqs sharing one line, but who knows.
+	 * Setup the thread mask for this irqaction for ONESHOT. For
+	 * !ONESHOT irqs the thread mask is 0 so we can avoid a
+	 * conditional in irq_wake_thread().
 	 */
-	if (new->flags & IRQF_ONESHOT && thread_mask == ~0UL) {
-		ret = -EBUSY;
-		goto out_mask;
+	if (new->flags & IRQF_ONESHOT) {
+		/*
+		 * Unlikely to have 32 resp 64 irqs sharing one line,
+		 * but who knows.
+		 */
+		if (thread_mask == ~0UL) {
+			ret = -EBUSY;
+			goto out_mask;
+		}
+		/*
+		 * The thread_mask for the action is or'ed to
+		 * desc->thread_active to indicate that the
+		 * IRQF_ONESHOT thread handler has been woken, but not
+		 * yet finished. The bit is cleared when a thread
+		 * completes. When all threads of a shared interrupt
+		 * line have completed desc->threads_active becomes
+		 * zero and the interrupt line is unmasked. See
+		 * handle.c:irq_wake_thread() for further information.
+		 *
+		 * If no thread is woken by primary (hard irq context)
+		 * interrupt handlers, then desc->threads_active is
+		 * also checked for zero to unmask the irq line in the
+		 * affected hard irq flow handlers
+		 * (handle_[fasteoi|level]_irq).
+		 *
+		 * The new action gets the first zero bit of
+		 * thread_mask assigned. See the loop above which or's
+		 * all existing action->thread_mask bits.
+		 */
+		new->thread_mask = 1 << ffz(thread_mask);
 	}
-	new->thread_mask = 1 << ffz(thread_mask);
 
 	if (!shared) {
 		init_waitqueue_head(&desc->wait_for_threads);

commit b4bc724e82e80478cba5fe9825b62e71ddf78757
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Feb 8 11:57:52 2012 +0100

    genirq: Handle pending irqs in irq_startup()
    
    An interrupt might be pending when irq_startup() is called, but the
    startup code does not invoke the resend logic. In some cases this
    prevents the device from issuing another interrupt which renders the
    device non functional.
    
    Call the resend function in irq_startup() to keep things going.
    
    Reported-and-tested-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Cc: stable@vger.kernel.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index a9a9dbe49fea..32313c084442 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1027,7 +1027,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 			desc->istate |= IRQS_ONESHOT;
 
 		if (irq_settings_can_autoenable(desc))
-			irq_startup(desc);
+			irq_startup(desc, true);
 		else
 			/* Undo nested disables: */
 			desc->depth = 1;

commit 98793265b429a3f0b3f1750e74d67cd4d740d162
Merge: b4a133da2eac bd1b2a555952
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Jan 8 13:21:22 2012 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/trivial
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jikos/trivial: (53 commits)
      Kconfig: acpi: Fix typo in comment.
      misc latin1 to utf8 conversions
      devres: Fix a typo in devm_kfree comment
      btrfs: free-space-cache.c: remove extra semicolon.
      fat: Spelling s/obsolate/obsolete/g
      SCSI, pmcraid: Fix spelling error in a pmcraid_err() call
      tools/power turbostat: update fields in manpage
      mac80211: drop spelling fix
      types.h: fix comment spelling for 'architectures'
      typo fixes: aera -> area, exntension -> extension
      devices.txt: Fix typo of 'VMware'.
      sis900: Fix enum typo 'sis900_rx_bufer_status'
      decompress_bunzip2: remove invalid vi modeline
      treewide: Fix comment and string typo 'bufer'
      hyper-v: Update MAINTAINERS
      treewide: Fix typos in various parts of the kernel, and fix some comments.
      clockevents: drop unknown Kconfig symbol GENERIC_CLOCKEVENTS_MIGR
      gpio: Kconfig: drop unknown symbol 'CS5535_GPIO'
      leds: Kconfig: Fix typo 'D2NET_V2'
      sound: Kconfig: drop unknown symbol ARCH_CLPS7500
      ...
    
    Fix up trivial conflicts in arch/powerpc/platforms/40x/Kconfig (some new
    kconfig additions, close to removed commented-out old ones)

commit 550acb19269d65f32e9ac4ddb26c2b2070e37f1c
Author: Ido Yariv <ido@wizery.com>
Date:   Thu Dec 1 13:55:08 2011 +0200

    genirq: Fix race condition when stopping the irq thread
    
    In irq_wait_for_interrupt(), the should_stop member is verified before
    setting the task's state to TASK_INTERRUPTIBLE and calling schedule().
    In case kthread_stop sets should_stop and wakes up the process after
    should_stop is checked by the irq thread but before the task's state
    is changed, the irq thread might never exit:
    
    kthread_stop                    irq_wait_for_interrupt
    ------------                    ----------------------
    
                                     ...
    ...                              while (!kthread_should_stop()) {
    kthread->should_stop = 1;
    wake_up_process(k);
    wait_for_completion(&kthread->exited);
    ...
                                         set_current_state(TASK_INTERRUPTIBLE);
    
                                         ...
    
                                         schedule();
                                     }
    
    Fix this by checking if the thread should stop after modifying the
    task's state.
    
    [ tglx: Simplified it a bit ]
    
    Signed-off-by: Ido Yariv <ido@wizery.com>
    Link: http://lkml.kernel.org/r/1322740508-22640-1-git-send-email-ido@wizery.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@kernel.org

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0e2b179bc7b3..1da999f5e746 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -623,8 +623,9 @@ static irqreturn_t irq_nested_primary_handler(int irq, void *dev_id)
 
 static int irq_wait_for_interrupt(struct irqaction *action)
 {
+	set_current_state(TASK_INTERRUPTIBLE);
+
 	while (!kthread_should_stop()) {
-		set_current_state(TASK_INTERRUPTIBLE);
 
 		if (test_and_clear_bit(IRQTF_RUNTHREAD,
 				       &action->thread_flags)) {
@@ -632,7 +633,9 @@ static int irq_wait_for_interrupt(struct irqaction *action)
 			return 0;
 		}
 		schedule();
+		set_current_state(TASK_INTERRUPTIBLE);
 	}
+	__set_current_state(TASK_RUNNING);
 	return -1;
 }
 

commit 2ed0e645f358c26f4f4a7aed56a9488db0020ad1
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Wed Nov 16 12:27:39 2011 +0000

    genirq: Don't allow per cpu interrupts to be suspended
    
    The power management functions related to interrupts do not know
    (yet) about per-cpu interrupts and end up calling the wrong
    low-level methods to enable/disable interrupts.
    
    This leads to all kind of interesting issues (action taken on one
    CPU only, updating a refcount which is not used otherwise...).
    
    The workaround for the time being is simply to flag these interrupts
    with IRQF_NO_SUSPEND. At least on ARM, these interrupts are actually
    dealt with at the architecture level.
    
    Reported-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Tested-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Link: http://lkml.kernel.org/r/1321446459-31409-1-git-send-email-marc.zyngier@arm.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 67ce837ae52c..0e2b179bc7b3 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1596,7 +1596,7 @@ int request_percpu_irq(unsigned int irq, irq_handler_t handler,
 		return -ENOMEM;
 
 	action->handler = handler;
-	action->flags = IRQF_PERCPU;
+	action->flags = IRQF_PERCPU | IRQF_NO_SUSPEND;
 	action->name = devname;
 	action->percpu_dev_id = dev_id;
 

commit 2290c0d06d82faee87b1ab2d9d4f7bf81ef64379
Merge: 4da669a2e3e5 52e4c2a05256
Author: Jiri Kosina <jkosina@suse.cz>
Date:   Sun Nov 13 20:55:35 2011 +0100

    Merge branch 'master' into for-next
    
    Sync with Linus tree to have 157550ff ("mtd: add GPMI-NAND driver
    in the config and Makefile") as I have patch depending on that one.

commit 6d21af4f7d0ab660b24c8635f4ed577f40cd2978
Author: Javi Merino <javi.merino@arm.com>
Date:   Wed Oct 26 10:16:11 2011 +0100

    irq: Fix comment typo ist->is
    
    Signed-off-by: Javi Merino <javi.merino@arm.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 9b956fa20308..3261c4d478a2 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1281,7 +1281,7 @@ EXPORT_SYMBOL(free_irq);
  *	and to set up the interrupt handler in the right order.
  *
  *	If you want to set up a threaded irq handler for your device
- *	then you need to supply @handler and @thread_fn. @handler ist
+ *	then you need to supply @handler and @thread_fn. @handler is
  *	still called in hard interrupt context and has to check
  *	whether the interrupt originates from the device. If yes it
  *	needs to disable the interrupt on the device and return

commit 32cffdde4a3ee6c2d9e0f0a94edecf1a9ce7586b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Oct 4 18:43:57 2011 +0200

    genirq: Fix fatfinered fixup really
    
    Putting the argument inside the quote does not really help.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 2bc86869859e..67ce837ae52c 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1435,7 +1435,7 @@ void enable_percpu_irq(unsigned int irq, unsigned int type)
 		ret = __irq_set_trigger(desc, irq, type);
 
 		if (ret) {
-			WARN(1, "failed to set type for IRQ%d\n, irq");
+			WARN(1, "failed to set type for IRQ%d\n", irq);
 			goto out;
 		}
 	}

commit 1e7c5fd29487ee88cb3abac945bafa60ae026146
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Fri Sep 30 10:48:47 2011 +0100

    genirq: percpu: allow interrupt type to be set at enable time
    
    As request_percpu_irq() doesn't allow for a percpu interrupt to have
    its type configured (it is generally impossible to configure it on all
    CPUs at once), add a 'type' argument to enable_percpu_irq().
    
    This allows some low-level, board specific init code to be switched to
    a generic API.
    
    [ tglx: Added WARN_ON argument ]
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Abhijeet Dharmapurikar <adharmap@codeaurora.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 7b4b156d065c..2bc86869859e 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1419,7 +1419,7 @@ int request_any_context_irq(unsigned int irq, irq_handler_t handler,
 }
 EXPORT_SYMBOL_GPL(request_any_context_irq);
 
-void enable_percpu_irq(unsigned int irq)
+void enable_percpu_irq(unsigned int irq, unsigned int type)
 {
 	unsigned int cpu = smp_processor_id();
 	unsigned long flags;
@@ -1428,7 +1428,20 @@ void enable_percpu_irq(unsigned int irq)
 	if (!desc)
 		return;
 
+	type &= IRQ_TYPE_SENSE_MASK;
+	if (type != IRQ_TYPE_NONE) {
+		int ret;
+
+		ret = __irq_set_trigger(desc, irq, type);
+
+		if (ret) {
+			WARN(1, "failed to set type for IRQ%d\n, irq");
+			goto out;
+		}
+	}
+
 	irq_percpu_enable(desc, cpu);
+out:
 	irq_put_desc_unlock(desc, flags);
 }
 

commit 31d9d9b6d83030f748d013e61502fa5477e2ac0e
Author: Marc Zyngier <marc.zyngier@arm.com>
Date:   Fri Sep 23 17:03:06 2011 +0100

    genirq: Add support for per-cpu dev_id interrupts
    
    The ARM GIC interrupt controller offers per CPU interrupts (PPIs),
    which are usually used to connect local timers to each core. Each CPU
    has its own private interface to the GIC, and only sees the PPIs that
    are directly connect to it.
    
    While these timers are separate devices and have a separate interrupt
    line to a core, they all use the same IRQ number.
    
    For these devices, request_irq() is not the right API as it assumes
    that an IRQ number is visible by a number of CPUs (through the
    affinity setting), but makes it very awkward to express that an IRQ
    number can be handled by all CPUs, and yet be a different interrupt
    line on each CPU, requiring a different dev_id cookie to be passed
    back to the handler.
    
    The *_percpu_irq() functions is designed to overcome these
    limitations, by providing a per-cpu dev_id vector:
    
    int request_percpu_irq(unsigned int irq, irq_handler_t handler,
                       const char *devname, void __percpu *percpu_dev_id);
    void free_percpu_irq(unsigned int, void __percpu *);
    int setup_percpu_irq(unsigned int irq, struct irqaction *new);
    void remove_percpu_irq(unsigned int irq, struct irqaction *act);
    void enable_percpu_irq(unsigned int irq);
    void disable_percpu_irq(unsigned int irq);
    
    The API has a number of limitations:
    - no interrupt sharing
    - no threading
    - common handler across all the CPUs
    
    Once the interrupt is requested using setup_percpu_irq() or
    request_percpu_irq(), it must be enabled by each core that wishes its
    local interrupt to be delivered.
    
    Based on an initial patch by Thomas Gleixner.
    
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Link: http://lkml.kernel.org/r/1316793788-14500-2-git-send-email-marc.zyngier@arm.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 7e1a3ed1e61a..7b4b156d065c 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -195,7 +195,7 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *mask)
 int irq_set_affinity_hint(unsigned int irq, const struct cpumask *m)
 {
 	unsigned long flags;
-	struct irq_desc *desc = irq_get_desc_lock(irq, &flags);
+	struct irq_desc *desc = irq_get_desc_lock(irq, &flags, IRQ_GET_DESC_CHECK_GLOBAL);
 
 	if (!desc)
 		return -EINVAL;
@@ -356,7 +356,7 @@ void __disable_irq(struct irq_desc *desc, unsigned int irq, bool suspend)
 static int __disable_irq_nosync(unsigned int irq)
 {
 	unsigned long flags;
-	struct irq_desc *desc = irq_get_desc_buslock(irq, &flags);
+	struct irq_desc *desc = irq_get_desc_buslock(irq, &flags, IRQ_GET_DESC_CHECK_GLOBAL);
 
 	if (!desc)
 		return -EINVAL;
@@ -448,7 +448,7 @@ void __enable_irq(struct irq_desc *desc, unsigned int irq, bool resume)
 void enable_irq(unsigned int irq)
 {
 	unsigned long flags;
-	struct irq_desc *desc = irq_get_desc_buslock(irq, &flags);
+	struct irq_desc *desc = irq_get_desc_buslock(irq, &flags, IRQ_GET_DESC_CHECK_GLOBAL);
 
 	if (!desc)
 		return;
@@ -491,7 +491,7 @@ static int set_irq_wake_real(unsigned int irq, unsigned int on)
 int irq_set_irq_wake(unsigned int irq, unsigned int on)
 {
 	unsigned long flags;
-	struct irq_desc *desc = irq_get_desc_buslock(irq, &flags);
+	struct irq_desc *desc = irq_get_desc_buslock(irq, &flags, IRQ_GET_DESC_CHECK_GLOBAL);
 	int ret = 0;
 
 	if (!desc)
@@ -532,7 +532,7 @@ EXPORT_SYMBOL(irq_set_irq_wake);
 int can_request_irq(unsigned int irq, unsigned long irqflags)
 {
 	unsigned long flags;
-	struct irq_desc *desc = irq_get_desc_lock(irq, &flags);
+	struct irq_desc *desc = irq_get_desc_lock(irq, &flags, 0);
 	int canrequest = 0;
 
 	if (!desc)
@@ -1121,6 +1121,8 @@ int setup_irq(unsigned int irq, struct irqaction *act)
 	int retval;
 	struct irq_desc *desc = irq_to_desc(irq);
 
+	if (WARN_ON(irq_settings_is_per_cpu_devid(desc)))
+		return -EINVAL;
 	chip_bus_lock(desc);
 	retval = __setup_irq(irq, desc, act);
 	chip_bus_sync_unlock(desc);
@@ -1129,7 +1131,7 @@ int setup_irq(unsigned int irq, struct irqaction *act)
 }
 EXPORT_SYMBOL_GPL(setup_irq);
 
- /*
+/*
  * Internal function to unregister an irqaction - used to free
  * regular and special interrupts that are part of the architecture.
  */
@@ -1227,7 +1229,10 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
  */
 void remove_irq(unsigned int irq, struct irqaction *act)
 {
-	__free_irq(irq, act->dev_id);
+	struct irq_desc *desc = irq_to_desc(irq);
+
+	if (desc && !WARN_ON(irq_settings_is_per_cpu_devid(desc)))
+	    __free_irq(irq, act->dev_id);
 }
 EXPORT_SYMBOL_GPL(remove_irq);
 
@@ -1249,7 +1254,7 @@ void free_irq(unsigned int irq, void *dev_id)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 
-	if (!desc)
+	if (!desc || WARN_ON(irq_settings_is_per_cpu_devid(desc)))
 		return;
 
 #ifdef CONFIG_SMP
@@ -1327,7 +1332,8 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 	if (!desc)
 		return -EINVAL;
 
-	if (!irq_settings_can_request(desc))
+	if (!irq_settings_can_request(desc) ||
+	    WARN_ON(irq_settings_is_per_cpu_devid(desc)))
 		return -EINVAL;
 
 	if (!handler) {
@@ -1412,3 +1418,181 @@ int request_any_context_irq(unsigned int irq, irq_handler_t handler,
 	return !ret ? IRQC_IS_HARDIRQ : ret;
 }
 EXPORT_SYMBOL_GPL(request_any_context_irq);
+
+void enable_percpu_irq(unsigned int irq)
+{
+	unsigned int cpu = smp_processor_id();
+	unsigned long flags;
+	struct irq_desc *desc = irq_get_desc_lock(irq, &flags, IRQ_GET_DESC_CHECK_PERCPU);
+
+	if (!desc)
+		return;
+
+	irq_percpu_enable(desc, cpu);
+	irq_put_desc_unlock(desc, flags);
+}
+
+void disable_percpu_irq(unsigned int irq)
+{
+	unsigned int cpu = smp_processor_id();
+	unsigned long flags;
+	struct irq_desc *desc = irq_get_desc_lock(irq, &flags, IRQ_GET_DESC_CHECK_PERCPU);
+
+	if (!desc)
+		return;
+
+	irq_percpu_disable(desc, cpu);
+	irq_put_desc_unlock(desc, flags);
+}
+
+/*
+ * Internal function to unregister a percpu irqaction.
+ */
+static struct irqaction *__free_percpu_irq(unsigned int irq, void __percpu *dev_id)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+	struct irqaction *action;
+	unsigned long flags;
+
+	WARN(in_interrupt(), "Trying to free IRQ %d from IRQ context!\n", irq);
+
+	if (!desc)
+		return NULL;
+
+	raw_spin_lock_irqsave(&desc->lock, flags);
+
+	action = desc->action;
+	if (!action || action->percpu_dev_id != dev_id) {
+		WARN(1, "Trying to free already-free IRQ %d\n", irq);
+		goto bad;
+	}
+
+	if (!cpumask_empty(desc->percpu_enabled)) {
+		WARN(1, "percpu IRQ %d still enabled on CPU%d!\n",
+		     irq, cpumask_first(desc->percpu_enabled));
+		goto bad;
+	}
+
+	/* Found it - now remove it from the list of entries: */
+	desc->action = NULL;
+
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
+
+	unregister_handler_proc(irq, action);
+
+	module_put(desc->owner);
+	return action;
+
+bad:
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
+	return NULL;
+}
+
+/**
+ *	remove_percpu_irq - free a per-cpu interrupt
+ *	@irq: Interrupt line to free
+ *	@act: irqaction for the interrupt
+ *
+ * Used to remove interrupts statically setup by the early boot process.
+ */
+void remove_percpu_irq(unsigned int irq, struct irqaction *act)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+
+	if (desc && irq_settings_is_per_cpu_devid(desc))
+	    __free_percpu_irq(irq, act->percpu_dev_id);
+}
+
+/**
+ *	free_percpu_irq - free an interrupt allocated with request_percpu_irq
+ *	@irq: Interrupt line to free
+ *	@dev_id: Device identity to free
+ *
+ *	Remove a percpu interrupt handler. The handler is removed, but
+ *	the interrupt line is not disabled. This must be done on each
+ *	CPU before calling this function. The function does not return
+ *	until any executing interrupts for this IRQ have completed.
+ *
+ *	This function must not be called from interrupt context.
+ */
+void free_percpu_irq(unsigned int irq, void __percpu *dev_id)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+
+	if (!desc || !irq_settings_is_per_cpu_devid(desc))
+		return;
+
+	chip_bus_lock(desc);
+	kfree(__free_percpu_irq(irq, dev_id));
+	chip_bus_sync_unlock(desc);
+}
+
+/**
+ *	setup_percpu_irq - setup a per-cpu interrupt
+ *	@irq: Interrupt line to setup
+ *	@act: irqaction for the interrupt
+ *
+ * Used to statically setup per-cpu interrupts in the early boot process.
+ */
+int setup_percpu_irq(unsigned int irq, struct irqaction *act)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+	int retval;
+
+	if (!desc || !irq_settings_is_per_cpu_devid(desc))
+		return -EINVAL;
+	chip_bus_lock(desc);
+	retval = __setup_irq(irq, desc, act);
+	chip_bus_sync_unlock(desc);
+
+	return retval;
+}
+
+/**
+ *	request_percpu_irq - allocate a percpu interrupt line
+ *	@irq: Interrupt line to allocate
+ *	@handler: Function to be called when the IRQ occurs.
+ *	@devname: An ascii name for the claiming device
+ *	@dev_id: A percpu cookie passed back to the handler function
+ *
+ *	This call allocates interrupt resources, but doesn't
+ *	automatically enable the interrupt. It has to be done on each
+ *	CPU using enable_percpu_irq().
+ *
+ *	Dev_id must be globally unique. It is a per-cpu variable, and
+ *	the handler gets called with the interrupted CPU's instance of
+ *	that variable.
+ */
+int request_percpu_irq(unsigned int irq, irq_handler_t handler,
+		       const char *devname, void __percpu *dev_id)
+{
+	struct irqaction *action;
+	struct irq_desc *desc;
+	int retval;
+
+	if (!dev_id)
+		return -EINVAL;
+
+	desc = irq_to_desc(irq);
+	if (!desc || !irq_settings_can_request(desc) ||
+	    !irq_settings_is_per_cpu_devid(desc))
+		return -EINVAL;
+
+	action = kzalloc(sizeof(struct irqaction), GFP_KERNEL);
+	if (!action)
+		return -ENOMEM;
+
+	action->handler = handler;
+	action->flags = IRQF_PERCPU;
+	action->name = devname;
+	action->percpu_dev_id = dev_id;
+
+	chip_bus_lock(desc);
+	retval = __setup_irq(irq, desc, action);
+	chip_bus_sync_unlock(desc);
+
+	if (retval)
+		kfree(action);
+
+	return retval;
+}

commit 60f96b41f71d2a13d1c0a457b8b77958f77142d1
Author: Santosh Shilimkar <santosh.shilimkar@ti.com>
Date:   Fri Sep 9 13:59:35 2011 +0530

    genirq: Add IRQCHIP_SKIP_SET_WAKE flag
    
    Some irq chips need the irq_set_wake() functionality, but do not
    require a irq_set_wake() callback. Instead of forcing an empty
    callback to be implemented add a flag which notes this fact. Check for
    the flag in set_irq_wake_real() and return success when set.
    
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 9b956fa20308..7e1a3ed1e61a 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -467,6 +467,9 @@ static int set_irq_wake_real(unsigned int irq, unsigned int on)
 	struct irq_desc *desc = irq_to_desc(irq);
 	int ret = -ENXIO;
 
+	if (irq_desc_get_chip(desc)->flags &  IRQCHIP_SKIP_SET_WAKE)
+		return 0;
+
 	if (desc->irq_data.chip->irq_set_wake)
 		ret = desc->irq_data.chip->irq_set_wake(&desc->irq_data, on);
 

commit 69dd3d8e29e294caaf63eb5e8a72d250279f9e5f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Aug 23 10:36:51 2011 -0700

    Revert "irq: Always set IRQF_ONESHOT if no primary handler is specified"
    
    This reverts commit f3637a5f2e2eb391ff5757bc83fb5de8f9726464.
    
    It turns out that this breaks several drivers, one example being OMAP
    boards which use the on-board OMAP UARTs and the omap-serial driver that
    will not boot to userspace after the commit.
    
    Paul Walmsley reports that enabling CONFIG_DEBUG_SHIRQ reveals 'IRQ
    handler type mismatch' errors:
    
      IRQ handler type mismatch for IRQ 74
      current handler: serial idle
      ...
    
    and the reason is that setting IRQF_ONESHOT will now result in those
    interrupt handlers having different IRQF flags, and thus being
    unsharable.  So the commit log in the reverted commit:
    
                                "Since it is required for those users and
        there is no difference for others it makes sense to add this flag
        unconditionally."
    
    is simply not true: there may not be any difference from a "actions at
    irq time", but there is a *big* difference wrt this flag testing irq
    management (see __setup_irq() in kernel/irq/manage.c).
    
    One solution may be to stop verifying IRQF_ONESHOT in __setup_irq(), but
    right now the safe course of action is to revert the change.  Let's
    revisit this in a later merge window.
    
    Reported-by: Paul Walmsley <paul@pwsan.com>
    Cc: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Requested-by: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 2e9425889fa8..9b956fa20308 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1331,7 +1331,6 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 		if (!thread_fn)
 			return -EINVAL;
 		handler = irq_default_primary_handler;
-		irqflags |= IRQF_ONESHOT;
 	}
 
 	action = kzalloc(sizeof(struct irqaction), GFP_KERNEL);

commit b6873807a7143b7d6d8b06809295e559d07d7deb
Author: Sebastian Andrzej Siewior <sebastian@breakpoint.cc>
Date:   Mon Jul 11 12:17:31 2011 +0200

    irq: Track the owner of irq descriptor
    
    Interrupt descriptors can be allocated from modules. The interrupts
    are used by other modules, but we have no refcount on the module which
    provides the interrupts and there is no way to establish one on the
    device level as the interrupt using module is agnostic to the fact
    that the interrupt is provided by a module rather than by some builtin
    interrupt controller.
    
    To prevent removal of the interrupt providing module, we can track the
    owner of the interrupt descriptor, which also provides the relevant
    irq chip functions in the irq descriptor.
    
    request/setup_irq() can now acquire a refcount on the owner module to
    prevent unloading. free_irq() drops the refcount.
    
    Signed-off-by: Sebastian Andrzej Siewior <sebastian@breakpoint.cc>
    Link: http://lkml.kernel.org/r/20110711101731.GA13804@Chamillionaire.breakpoint.cc
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 3f9cd4799da7..2e9425889fa8 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -883,6 +883,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 	if (desc->irq_data.chip == &no_irq_chip)
 		return -ENOSYS;
+	if (!try_module_get(desc->owner))
+		return -ENODEV;
 	/*
 	 * Some drivers like serial.c use request_irq() heavily,
 	 * so we have to be careful not to interfere with a
@@ -906,8 +908,10 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	 */
 	nested = irq_settings_is_nested_thread(desc);
 	if (nested) {
-		if (!new->thread_fn)
-			return -EINVAL;
+		if (!new->thread_fn) {
+			ret = -EINVAL;
+			goto out_mput;
+		}
 		/*
 		 * Replace the primary handler which was provided from
 		 * the driver for non nested interrupt handling by the
@@ -929,8 +933,10 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 		t = kthread_create(irq_thread, new, "irq/%d-%s", irq,
 				   new->name);
-		if (IS_ERR(t))
-			return PTR_ERR(t);
+		if (IS_ERR(t)) {
+			ret = PTR_ERR(t);
+			goto out_mput;
+		}
 		/*
 		 * We keep the reference to the task struct even if
 		 * the thread dies to avoid that the interrupt code
@@ -1095,6 +1101,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 			kthread_stop(t);
 		put_task_struct(t);
 	}
+out_mput:
+	module_put(desc->owner);
 	return ret;
 }
 
@@ -1203,6 +1211,7 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 		put_task_struct(action->thread);
 	}
 
+	module_put(desc->owner);
 	return action;
 }
 

commit f3637a5f2e2eb391ff5757bc83fb5de8f9726464
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Thu Jul 7 22:32:17 2011 +0200

    irq: Always set IRQF_ONESHOT if no primary handler is specified
    
    If no primary handler is specified then a default one is assigned
    which always returns IRQ_WAKE_THREAD. This handler requires the
    IRQF_ONESHOT flag on LEVEL / EIO typed irqs because the source of
    interrupt is not disabled. Since it is required for those users and
    there is no difference for others it makes sense to add this flag
    unconditionally.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Link: http://lkml.kernel.org/r/1310070737-18514-1-git-send-email-bigeasy@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0a7840aeb0fb..3f9cd4799da7 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1322,6 +1322,7 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 		if (!thread_fn)
 			return -EINVAL;
 		handler = irq_default_primary_handler;
+		irqflags |= IRQF_ONESHOT;
 	}
 
 	action = kzalloc(sizeof(struct irqaction), GFP_KERNEL);

commit 13863a66c9c8a663665445cf05d68de96ff31830
Author: Jesper Juhl <jj@chaosbits.net>
Date:   Thu Jun 9 23:14:58 2011 +0200

    genirq: Prevent potential NULL dereference in irq_set_irq_wake()
    
    In kernel/irq/manage.c::irq_set_irq_wake() we call
    irq_get_desc_buslock() which may return NULL, but the code
    dereferences the result unconditionally.
    
    irq_set_irq_wake() has lots of callers - I checked a few and I couldn't
    find anything that guarantees that they won't call it with some input that
    will cause irq_get_desc_buslock() to return NULL, so I think it's a good
    thing to test and -EINVAL was the most sane error code in this situation
    that I could think of.
    
    Not all callers test the return value of irq_set_irq_wake(), but those
    that do take != 0 to mean error as far as I can see, so they should be
    fine. I guess those that don't test actually should, but that's a
    different issue.
    
    Signed-off-by: Jesper Juhl <jj@chaosbits.net>
    Link: http://lkml.kernel.org/r/alpine.LNX.2.00.1106092300360.17868@swampdragon.chaosbits.net
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index d64bafb1afd0..0a7840aeb0fb 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -491,6 +491,9 @@ int irq_set_irq_wake(unsigned int irq, unsigned int on)
 	struct irq_desc *desc = irq_get_desc_buslock(irq, &flags);
 	int ret = 0;
 
+	if (!desc)
+		return -EINVAL;
+
 	/* wakeup-capable irqs can be shared between drivers that
 	 * don't need to have the same sleep mode behaviors.
 	 */

commit 3a43e05f4d0600e906fa09f4a65d749288c44592
Author: Sebastian Andrzej Siewior <sebastian@breakpoint.cc>
Date:   Tue May 31 08:56:11 2011 +0200

    irq: Handle spurios irq detection for threaded irqs
    
    The detection of spurios interrupts is currently limited to first level
    handler. In force-threaded mode we never notice if the threaded irq does
    not feel responsible.
    This patch catches the return value of the threaded handler and forwards
    it to the spurious detector. If the primary handler returns only
    IRQ_WAKE_THREAD then the spourious detector ignores it because it gets
    called again from the threaded handler.
    
    [ tglx: Report the erroneous return value early and bail out ]
    
    Signed-off-by: Sebastian Andrzej Siewior <sebastian@breakpoint.cc>
    Link: http://lkml.kernel.org/r/1306824972-27067-2-git-send-email-sebastian@breakpoint.cc
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index f7ce0021e1c4..d64bafb1afd0 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -723,13 +723,16 @@ irq_thread_check_affinity(struct irq_desc *desc, struct irqaction *action) { }
  * context. So we need to disable bh here to avoid deadlocks and other
  * side effects.
  */
-static void
+static irqreturn_t
 irq_forced_thread_fn(struct irq_desc *desc, struct irqaction *action)
 {
+	irqreturn_t ret;
+
 	local_bh_disable();
-	action->thread_fn(action->irq, action->dev_id);
+	ret = action->thread_fn(action->irq, action->dev_id);
 	irq_finalize_oneshot(desc, action, false);
 	local_bh_enable();
+	return ret;
 }
 
 /*
@@ -737,10 +740,14 @@ irq_forced_thread_fn(struct irq_desc *desc, struct irqaction *action)
  * preemtible - many of them need to sleep and wait for slow busses to
  * complete.
  */
-static void irq_thread_fn(struct irq_desc *desc, struct irqaction *action)
+static irqreturn_t irq_thread_fn(struct irq_desc *desc,
+		struct irqaction *action)
 {
-	action->thread_fn(action->irq, action->dev_id);
+	irqreturn_t ret;
+
+	ret = action->thread_fn(action->irq, action->dev_id);
 	irq_finalize_oneshot(desc, action, false);
+	return ret;
 }
 
 /*
@@ -753,7 +760,8 @@ static int irq_thread(void *data)
 	};
 	struct irqaction *action = data;
 	struct irq_desc *desc = irq_to_desc(action->irq);
-	void (*handler_fn)(struct irq_desc *desc, struct irqaction *action);
+	irqreturn_t (*handler_fn)(struct irq_desc *desc,
+			struct irqaction *action);
 	int wake;
 
 	if (force_irqthreads & test_bit(IRQTF_FORCED_THREAD,
@@ -783,8 +791,12 @@ static int irq_thread(void *data)
 			desc->istate |= IRQS_PENDING;
 			raw_spin_unlock_irq(&desc->lock);
 		} else {
+			irqreturn_t action_ret;
+
 			raw_spin_unlock_irq(&desc->lock);
-			handler_fn(desc, action);
+			action_ret = handler_fn(desc, action);
+			if (!noirqdebug)
+				note_interrupt(action->irq, desc, action_ret);
 		}
 
 		wake = atomic_dec_and_test(&desc->threads_active);

commit 7f1b1244e159a8490d7fb13667c6cb7e1e75046b
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Thu Apr 7 06:01:44 2011 +0900

    genirq: Support per-IRQ thread disabling.
    
    This adds support for disabling threading on a per-IRQ basis via the IRQ
    status instead of the IRQ flow, which is necessary for interrupts that
    don't follow the natural IRQ flow channels, such as those that are
    virtually created.
    
    The new APIs added are simply:
    
            irq_set_thread()
            irq_set_nothread()
    
    which follow the rest of the IRQ status routines.
    
    Chained handlers also have IRQ_NOTHREAD set on them automatically, making
    the lack of threading explicit rather than implicit. Subsequently, the
    nothread flag can be viewed through the standard genirq debugging
    facilities.
    
    [ tglx: Fixed cleanup fallout ]
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>
    Link: http://lkml.kernel.org/r/%3C20110406210135.GF18426%40linux-sh.org%3E
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 07c1611f3899..f7ce0021e1c4 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -900,7 +900,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		 */
 		new->handler = irq_nested_primary_handler;
 	} else {
-		irq_setup_forced_threading(new);
+		if (irq_settings_can_thread(desc))
+			irq_setup_forced_threading(new);
 	}
 
 	/*

commit 4f5058c3b71ed5930bb2b478c4d5dbc799dd9ad1
Author: Xiaotian Feng <dfeng@redhat.com>
Date:   Sat Apr 2 19:39:35 2011 +0800

    genirq: Fix cpumask leak in __setup_irq()
    
    The allocated cpumask should be freed in __setup_irq().
    
    Signed-off-by: Xiaotian Feng <dfeng@redhat.com>
    LKML-Reference: <1301744375-6812-1-git-send-email-dfeng@redhat.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 12a80fdae11c..07c1611f3899 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1051,6 +1051,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	register_irq_proc(irq, desc);
 	new->dir = NULL;
 	register_handler_proc(irq, new);
+	free_cpumask_var(mask);
 
 	return 0;
 

commit 0c6f8a8b917ad361319c8ace3e9f28e69bfdb4c1
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Mar 28 13:32:20 2011 +0200

    genirq: Remove compat code
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index b3bf54f7d977..12a80fdae11c 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -166,7 +166,6 @@ int __irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask)
 		kref_get(&desc->affinity_notify->kref);
 		schedule_work(&desc->affinity_notify->work);
 	}
-	irq_compat_set_affinity(desc);
 	irqd_set(data, IRQD_AFFINITY_SET);
 
 	return ret;
@@ -297,10 +296,8 @@ setup_affinity(unsigned int irq, struct irq_desc *desc, struct cpumask *mask)
 		if (cpumask_intersects(desc->irq_data.affinity,
 				       cpu_online_mask))
 			set = desc->irq_data.affinity;
-		else {
-			irq_compat_clr_affinity(desc);
+		else
 			irqd_clear(&desc->irq_data, IRQD_AFFINITY_SET);
-		}
 	}
 
 	cpumask_and(mask, cpu_online_mask, set);
@@ -587,8 +584,6 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 			irqd_set(&desc->irq_data, IRQD_LEVEL);
 		}
 
-		if (chip != desc->irq_data.chip)
-			irq_chip_set_defaults(desc->irq_data.chip);
 		ret = 0;
 		break;
 	default:
@@ -785,7 +780,6 @@ static int irq_thread(void *data)
 			 * but AFAICT IRQS_PENDING should be fine as it
 			 * retriggers the interrupt itself --- tglx
 			 */
-			irq_compat_set_pending(desc);
 			desc->istate |= IRQS_PENDING;
 			raw_spin_unlock_irq(&desc->lock);
 		} else {
@@ -981,8 +975,6 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	new->thread_mask = 1 << ffz(thread_mask);
 
 	if (!shared) {
-		irq_chip_set_defaults(desc->irq_data.chip);
-
 		init_waitqueue_head(&desc->wait_for_threads);
 
 		/* Setup the type (level, edge polarity) if configured: */

commit cd22c0e44b105aecd78e5f9e77abab3a1b8dc00c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Mar 29 11:36:05 2011 +0200

    genirq: Fix harmless typo
    
    The late night fixup missed to convert the data type from irq_desc to
    irq_data, which results in a harmless but annoying warning.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index acf540768b8f..b3bf54f7d977 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -132,7 +132,7 @@ irq_get_pending(struct cpumask *mask, struct irq_desc *desc)
 }
 #else
 static inline bool irq_can_move_pcntxt(struct irq_data *data) { return true; }
-static inline bool irq_move_pending(struct irq_desc *data) { return false; }
+static inline bool irq_move_pending(struct irq_data *data) { return false; }
 static inline void
 irq_copy_pending(struct irq_desc *desc, const struct cpumask *mask) { }
 static inline void

commit 0ef5ca1e1f0de71300142b8f730f26ded6a0c2f3
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Mar 28 21:59:37 2011 +0200

    genirq; Fix cleanup fallout
    
    I missed the CONFIG_GENERIC_PENDING_IRQ dependency in the affinity
    related functions and the IRQ_LEVEL propagation into irq_data
    state. Did not pop up on my main test platforms. :(
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: David Daney <ddaney@caviumnetworks.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 805c6a0ce780..acf540768b8f 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -112,13 +112,13 @@ void irq_set_thread_affinity(struct irq_desc *desc)
 }
 
 #ifdef CONFIG_GENERIC_PENDING_IRQ
-static inline bool irq_can_move_pcntxt(struct irq_desc *desc)
+static inline bool irq_can_move_pcntxt(struct irq_data *data)
 {
-	return irq_settings_can_move_pcntxt(desc);
+	return irqd_can_move_in_process_context(data);
 }
-static inline bool irq_move_pending(struct irq_desc *desc)
+static inline bool irq_move_pending(struct irq_data *data)
 {
-	return irqd_is_setaffinity_pending(&desc->irq_data);
+	return irqd_is_setaffinity_pending(data);
 }
 static inline void
 irq_copy_pending(struct irq_desc *desc, const struct cpumask *mask)
@@ -131,8 +131,8 @@ irq_get_pending(struct cpumask *mask, struct irq_desc *desc)
 	cpumask_copy(mask, desc->pending_mask);
 }
 #else
-static inline bool irq_can_move_pcntxt(struct irq_desc *desc) { return true; }
-static inline bool irq_move_pending(struct irq_desc *desc) { return false; }
+static inline bool irq_can_move_pcntxt(struct irq_data *data) { return true; }
+static inline bool irq_move_pending(struct irq_desc *data) { return false; }
 static inline void
 irq_copy_pending(struct irq_desc *desc, const struct cpumask *mask) { }
 static inline void
@@ -148,7 +148,7 @@ int __irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask)
 	if (!chip || !chip->irq_set_affinity)
 		return -EINVAL;
 
-	if (irqd_can_move_in_process_context(data)) {
+	if (irq_can_move_pcntxt(data)) {
 		ret = chip->irq_set_affinity(data, mask, false);
 		switch (ret) {
 		case IRQ_SET_MASK_OK:
@@ -218,7 +218,7 @@ static void irq_affinity_notify(struct work_struct *work)
 		goto out;
 
 	raw_spin_lock_irqsave(&desc->lock, flags);
-	if (irq_move_pending(desc))
+	if (irq_move_pending(&desc->irq_data))
 		irq_get_pending(cpumask, desc);
 	else
 		cpumask_copy(cpumask, desc->irq_data.affinity);

commit 30398bf6c684a77274dbdabf7efc1f24e4a99028
Author: Randy Dunlap <randy.dunlap@oracle.com>
Date:   Fri Mar 18 09:33:56 2011 -0700

    genirq: Fix new kernel-doc warnings
    
    Fix new irq-related kernel-doc warnings in 2.6.38:
    
    Warning(kernel/irq/manage.c:149): No description found for parameter 'mask'
    Warning(kernel/irq/manage.c:149): Excess function parameter 'cpumask' description in 'irq_set_affinity'
    Warning(include/linux/irq.h:161): No description found for parameter 'state_use_accessors'
    Warning(include/linux/irq.h:161): Excess struct/union/enum/typedef member 'state_use_accessor' description in 'irq_data'
    
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    LKML-Reference: <20110318093356.b939558d.randy.dunlap@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 6e8acb755993..805c6a0ce780 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -175,7 +175,7 @@ int __irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask)
 /**
  *	irq_set_affinity - Set the irq affinity of a given irq
  *	@irq:		Interrupt to set affinity
- *	@cpumask:	cpumask
+ *	@mask:		cpumask
  *
  */
 int irq_set_affinity(unsigned int irq, const struct cpumask *mask)

commit 32f4125ebffee4f3c4dbc6a437fc656129eb9e60
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Mar 28 14:10:52 2011 +0200

    genirq: Move INPROGRESS, MASKED and DISABLED state flags to irq_data
    
    We really need these flags for some of the interrupt chips. Move it
    from internal state to irq_data and provide proper accessors.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: David Daney <ddaney@caviumnetworks.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 3d151fd762ad..6e8acb755993 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -41,7 +41,7 @@ early_param("threadirqs", setup_forced_irqthreads);
 void synchronize_irq(unsigned int irq)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
-	unsigned int state;
+	bool inprogress;
 
 	if (!desc)
 		return;
@@ -53,16 +53,16 @@ void synchronize_irq(unsigned int irq)
 		 * Wait until we're out of the critical section.  This might
 		 * give the wrong answer due to the lack of memory barriers.
 		 */
-		while (desc->istate & IRQS_INPROGRESS)
+		while (irqd_irq_inprogress(&desc->irq_data))
 			cpu_relax();
 
 		/* Ok, that indicated we're done: double-check carefully. */
 		raw_spin_lock_irqsave(&desc->lock, flags);
-		state = desc->istate;
+		inprogress = irqd_irq_inprogress(&desc->irq_data);
 		raw_spin_unlock_irqrestore(&desc->lock, flags);
 
 		/* Oops, that failed? */
-	} while (state & IRQS_INPROGRESS);
+	} while (inprogress);
 
 	/*
 	 * We made sure that no hardirq handler is running. Now verify
@@ -563,9 +563,9 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 	flags &= IRQ_TYPE_SENSE_MASK;
 
 	if (chip->flags & IRQCHIP_SET_TYPE_MASKED) {
-		if (!(desc->istate & IRQS_MASKED))
+		if (!irqd_irq_masked(&desc->irq_data))
 			mask_irq(desc);
-		if (!(desc->istate & IRQS_DISABLED))
+		if (!irqd_irq_disabled(&desc->irq_data))
 			unmask = 1;
 	}
 
@@ -663,7 +663,7 @@ static void irq_finalize_oneshot(struct irq_desc *desc,
 	 * irq_wake_thread(). See the comment there which explains the
 	 * serialization.
 	 */
-	if (unlikely(desc->istate & IRQS_INPROGRESS)) {
+	if (unlikely(irqd_irq_inprogress(&desc->irq_data))) {
 		raw_spin_unlock_irq(&desc->lock);
 		chip_bus_sync_unlock(desc);
 		cpu_relax();
@@ -680,12 +680,10 @@ static void irq_finalize_oneshot(struct irq_desc *desc,
 
 	desc->threads_oneshot &= ~action->thread_mask;
 
-	if (!desc->threads_oneshot && !(desc->istate & IRQS_DISABLED) &&
-	    (desc->istate & IRQS_MASKED)) {
-		irq_compat_clr_masked(desc);
-		desc->istate &= ~IRQS_MASKED;
-		desc->irq_data.chip->irq_unmask(&desc->irq_data);
-	}
+	if (!desc->threads_oneshot && !irqd_irq_disabled(&desc->irq_data) &&
+	    irqd_irq_masked(&desc->irq_data))
+		unmask_irq(desc);
+
 out_unlock:
 	raw_spin_unlock_irq(&desc->lock);
 	chip_bus_sync_unlock(desc);
@@ -779,7 +777,7 @@ static int irq_thread(void *data)
 		atomic_inc(&desc->threads_active);
 
 		raw_spin_lock_irq(&desc->lock);
-		if (unlikely(desc->istate & IRQS_DISABLED)) {
+		if (unlikely(irqd_irq_disabled(&desc->irq_data))) {
 			/*
 			 * CHECKME: We might need a dedicated
 			 * IRQ_THREAD_PENDING flag here, which
@@ -997,8 +995,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		}
 
 		desc->istate &= ~(IRQS_AUTODETECT | IRQS_SPURIOUS_DISABLED | \
-				  IRQS_INPROGRESS | IRQS_ONESHOT | \
-				  IRQS_WAITING);
+				  IRQS_ONESHOT | IRQS_WAITING);
+		irqd_clear(&desc->irq_data, IRQD_IRQ_INPROGRESS);
 
 		if (new->flags & IRQF_PERCPU) {
 			irqd_set(&desc->irq_data, IRQD_PER_CPU);

commit c2d0c555c22242c3a76e366074c4d83ef9fa3b8c
Author: David Daney <ddaney@caviumnetworks.com>
Date:   Fri Mar 25 12:38:50 2011 -0700

    genirq: Split irq_set_affinity() so it can be called with lock held.
    
    The .irq_cpu_online() and .irq_cpu_offline() functions may need to
    adjust affinity, but they are called with the descriptor lock held.
    Create __irq_set_affinity_locked() which is called with the lock held.
    Make irq_set_affinity() just a wrapper that acquires the lock.
    
    [ tglx: Changed the argument to irq_data, added a !desc check and
            moved the !irq_set_affinity check where it belongs ]
    
    Signed-off-by: David Daney <ddaney@caviumnetworks.com>
    Cc: linux-mips@linux-mips.org
    Cc: ralf@linux-mips.org
    LKML-Reference: <1301081931-11240-4-git-send-email-ddaney@caviumnetworks.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0a2aa73e536c..3d151fd762ad 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -139,35 +139,26 @@ static inline void
 irq_get_pending(struct cpumask *mask, struct irq_desc *desc) { }
 #endif
 
-/**
- *	irq_set_affinity - Set the irq affinity of a given irq
- *	@irq:		Interrupt to set affinity
- *	@cpumask:	cpumask
- *
- */
-int irq_set_affinity(unsigned int irq, const struct cpumask *mask)
+int __irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
-	struct irq_chip *chip = desc->irq_data.chip;
-	unsigned long flags;
+	struct irq_chip *chip = irq_data_get_irq_chip(data);
+	struct irq_desc *desc = irq_data_to_desc(data);
 	int ret = 0;
 
-	if (!chip->irq_set_affinity)
+	if (!chip || !chip->irq_set_affinity)
 		return -EINVAL;
 
-	raw_spin_lock_irqsave(&desc->lock, flags);
-
-	if (irq_can_move_pcntxt(desc)) {
-		ret = chip->irq_set_affinity(&desc->irq_data, mask, false);
+	if (irqd_can_move_in_process_context(data)) {
+		ret = chip->irq_set_affinity(data, mask, false);
 		switch (ret) {
 		case IRQ_SET_MASK_OK:
-			cpumask_copy(desc->irq_data.affinity, mask);
+			cpumask_copy(data->affinity, mask);
 		case IRQ_SET_MASK_OK_NOCOPY:
 			irq_set_thread_affinity(desc);
 			ret = 0;
 		}
 	} else {
-		irqd_set_move_pending(&desc->irq_data);
+		irqd_set_move_pending(data);
 		irq_copy_pending(desc, mask);
 	}
 
@@ -176,7 +167,28 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *mask)
 		schedule_work(&desc->affinity_notify->work);
 	}
 	irq_compat_set_affinity(desc);
-	irqd_set(&desc->irq_data, IRQD_AFFINITY_SET);
+	irqd_set(data, IRQD_AFFINITY_SET);
+
+	return ret;
+}
+
+/**
+ *	irq_set_affinity - Set the irq affinity of a given irq
+ *	@irq:		Interrupt to set affinity
+ *	@cpumask:	cpumask
+ *
+ */
+int irq_set_affinity(unsigned int irq, const struct cpumask *mask)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+	unsigned long flags;
+	int ret;
+
+	if (!desc)
+		return -EINVAL;
+
+	raw_spin_lock_irqsave(&desc->lock, flags);
+	ret =  __irq_set_affinity_locked(irq_desc_get_irq_data(desc), mask);
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	return ret;
 }

commit 1c389795c15d349c2c7b23baf927e16e86ca3ae8
Author: Dan Carpenter <error27@gmail.com>
Date:   Thu Mar 17 14:43:07 2011 +0300

    genirq: Fix incorrect unlock in __setup_irq()
    
    goto out_thread is called before we take the lock. It causes a gcc
    warning: "kernel/irq/manage.c:858: warning: ‘flags’ may be used
    uninitialized in this function"
    
    [ tglx: Moved unlock before free_cpumask_var() ]
    
    Signed-off-by: Dan Carpenter <error27@gmail.com>
    LKML-Reference: <20110317114307.GJ2008@bicker>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index acd599a43bfb..0a2aa73e536c 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1064,10 +1064,10 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	ret = -EBUSY;
 
 out_mask:
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	free_cpumask_var(mask);
 
 out_thread:
-	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	if (new->thread) {
 		struct task_struct *t = new->thread;
 

commit 8d32a307e4faa8b123dc8a9cd56d1a7525f69ad3
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Feb 23 23:52:23 2011 +0000

    genirq: Provide forced interrupt threading
    
    Add a commandline parameter "threadirqs" which forces all interrupts except
    those marked IRQF_NO_THREAD to run threaded. That's mostly a debug option to
    allow retrieving better debug data from crashing interrupt handlers. If
    "threadirqs" is not enabled on the kernel command line, then there is no
    impact in the interrupt hotpath.
    
    Architecture code needs to select CONFIG_IRQ_FORCED_THREADING after
    marking the interrupts which cant be threaded IRQF_NO_THREAD. All
    interrupts which have IRQF_TIMER set are implict marked
    IRQF_NO_THREAD. Also all PER_CPU interrupts are excluded.
    
    Forced threading hard interrupts also forces all soft interrupt
    handling into thread context.
    
    When enabled it might slow down things a bit, but for debugging problems in
    interrupt code it's a reasonable penalty as it does not immediately
    crash and burn the machine when an interrupt handler is buggy.
    
    Some test results on a Core2Duo machine:
    
    Cache cold run of:
     # time git grep irq_desc
    
          non-threaded       threaded
     real 1m18.741s          1m19.061s
     user 0m1.874s           0m1.757s
     sys  0m5.843s           0m5.427s
    
     # iperf -c server
    non-threaded
    [  3]  0.0-10.0 sec  1.09 GBytes   933 Mbits/sec
    [  3]  0.0-10.0 sec  1.09 GBytes   934 Mbits/sec
    [  3]  0.0-10.0 sec  1.09 GBytes   933 Mbits/sec
    threaded
    [  3]  0.0-10.0 sec  1.09 GBytes   939 Mbits/sec
    [  3]  0.0-10.0 sec  1.09 GBytes   934 Mbits/sec
    [  3]  0.0-10.0 sec  1.09 GBytes   937 Mbits/sec
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    LKML-Reference: <20110223234956.772668648@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 58c861367300..acd599a43bfb 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -17,6 +17,17 @@
 
 #include "internals.h"
 
+#ifdef CONFIG_IRQ_FORCED_THREADING
+__read_mostly bool force_irqthreads;
+
+static int __init setup_forced_irqthreads(char *arg)
+{
+	force_irqthreads = true;
+	return 0;
+}
+early_param("threadirqs", setup_forced_irqthreads);
+#endif
+
 /**
  *	synchronize_irq - wait for pending IRQ handlers (on other CPUs)
  *	@irq: interrupt number to wait for
@@ -701,6 +712,32 @@ static inline void
 irq_thread_check_affinity(struct irq_desc *desc, struct irqaction *action) { }
 #endif
 
+/*
+ * Interrupts which are not explicitely requested as threaded
+ * interrupts rely on the implicit bh/preempt disable of the hard irq
+ * context. So we need to disable bh here to avoid deadlocks and other
+ * side effects.
+ */
+static void
+irq_forced_thread_fn(struct irq_desc *desc, struct irqaction *action)
+{
+	local_bh_disable();
+	action->thread_fn(action->irq, action->dev_id);
+	irq_finalize_oneshot(desc, action, false);
+	local_bh_enable();
+}
+
+/*
+ * Interrupts explicitely requested as threaded interupts want to be
+ * preemtible - many of them need to sleep and wait for slow busses to
+ * complete.
+ */
+static void irq_thread_fn(struct irq_desc *desc, struct irqaction *action)
+{
+	action->thread_fn(action->irq, action->dev_id);
+	irq_finalize_oneshot(desc, action, false);
+}
+
 /*
  * Interrupt handler thread
  */
@@ -711,8 +748,15 @@ static int irq_thread(void *data)
 	};
 	struct irqaction *action = data;
 	struct irq_desc *desc = irq_to_desc(action->irq);
+	void (*handler_fn)(struct irq_desc *desc, struct irqaction *action);
 	int wake;
 
+	if (force_irqthreads & test_bit(IRQTF_FORCED_THREAD,
+					&action->thread_flags))
+		handler_fn = irq_forced_thread_fn;
+	else
+		handler_fn = irq_thread_fn;
+
 	sched_setscheduler(current, SCHED_FIFO, &param);
 	current->irqaction = action;
 
@@ -736,10 +780,7 @@ static int irq_thread(void *data)
 			raw_spin_unlock_irq(&desc->lock);
 		} else {
 			raw_spin_unlock_irq(&desc->lock);
-
-			action->thread_fn(action->irq, action->dev_id);
-
-			irq_finalize_oneshot(desc, action, false);
+			handler_fn(desc, action);
 		}
 
 		wake = atomic_dec_and_test(&desc->threads_active);
@@ -789,6 +830,22 @@ void exit_irq_thread(void)
 	set_bit(IRQTF_DIED, &tsk->irqaction->flags);
 }
 
+static void irq_setup_forced_threading(struct irqaction *new)
+{
+	if (!force_irqthreads)
+		return;
+	if (new->flags & (IRQF_NO_THREAD | IRQF_PERCPU | IRQF_ONESHOT))
+		return;
+
+	new->flags |= IRQF_ONESHOT;
+
+	if (!new->thread_fn) {
+		set_bit(IRQTF_FORCED_THREAD, &new->thread_flags);
+		new->thread_fn = new->handler;
+		new->handler = irq_default_primary_handler;
+	}
+}
+
 /*
  * Internal function to register an irqaction - typically used to
  * allocate special interrupts that are part of the architecture.
@@ -838,6 +895,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		 * dummy function which warns when called.
 		 */
 		new->handler = irq_nested_primary_handler;
+	} else {
+		irq_setup_forced_threading(new);
 	}
 
 	/*

commit 9d591edd02a245305b1b9379e4c5571bad4d2774
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Feb 23 23:52:16 2011 +0000

    genirq: Allow shared oneshot interrupts
    
    Support ONESHOT on shared interrupts, if all drivers agree on it.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    LKML-Reference: <20110223234956.483640430@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 2301de19ac7d..58c861367300 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -824,10 +824,6 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		rand_initialize_irq(irq);
 	}
 
-	/* Oneshot interrupts are not allowed with shared */
-	if ((new->flags & IRQF_ONESHOT) && (new->flags & IRQF_SHARED))
-		return -EINVAL;
-
 	/*
 	 * Check whether the interrupt nests into another interrupt
 	 * thread.
@@ -881,10 +877,12 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		 * Can't share interrupts unless both agree to and are
 		 * the same type (level, edge, polarity). So both flag
 		 * fields must have IRQF_SHARED set and the bits which
-		 * set the trigger type must match.
+		 * set the trigger type must match. Also all must
+		 * agree on ONESHOT.
 		 */
 		if (!((old->flags & new->flags) & IRQF_SHARED) ||
-		    ((old->flags ^ new->flags) & IRQF_TRIGGER_MASK)) {
+		    ((old->flags ^ new->flags) & IRQF_TRIGGER_MASK) ||
+		    ((old->flags ^ new->flags) & IRQF_ONESHOT)) {
 			old_name = old->name;
 			goto mismatch;
 		}

commit b5faba21a6805c33b40e258d36f57997ee1de131
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Feb 23 23:52:13 2011 +0000

    genirq: Prepare the handling of shared oneshot interrupts
    
    For level type interrupts we need to track how many threads are on
    flight to avoid useless interrupt storms when not all thread handlers
    have finished yet. Keep track of the woken threads and only unmask
    when there are no more threads in flight.
    
    Yes, I'm lazy and using a bitfield. But not only because I'm lazy, the
    main reason is that it's way simpler than using a refcount. A refcount
    based solution would need to keep track of various things like
    crashing the irq thread, spurious interrupts coming in,
    disables/enables, free_irq() and some more. The bitfield keeps the
    tracking simple and makes things just work. It's also nicely confined
    to the thread code pathes and does not require additional checks all
    over the place.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    LKML-Reference: <20110223234956.388095876@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 01f8a9519e63..2301de19ac7d 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -617,8 +617,11 @@ static int irq_wait_for_interrupt(struct irqaction *action)
  * handler finished. unmask if the interrupt has not been disabled and
  * is marked MASKED.
  */
-static void irq_finalize_oneshot(unsigned int irq, struct irq_desc *desc)
+static void irq_finalize_oneshot(struct irq_desc *desc,
+				 struct irqaction *action, bool force)
 {
+	if (!(desc->istate & IRQS_ONESHOT))
+		return;
 again:
 	chip_bus_lock(desc);
 	raw_spin_lock_irq(&desc->lock);
@@ -631,6 +634,11 @@ static void irq_finalize_oneshot(unsigned int irq, struct irq_desc *desc)
 	 * on the other CPU. If we unmask the irq line then the
 	 * interrupt can come in again and masks the line, leaves due
 	 * to IRQS_INPROGRESS and the irq line is masked forever.
+	 *
+	 * This also serializes the state of shared oneshot handlers
+	 * versus "desc->threads_onehsot |= action->thread_mask;" in
+	 * irq_wake_thread(). See the comment there which explains the
+	 * serialization.
 	 */
 	if (unlikely(desc->istate & IRQS_INPROGRESS)) {
 		raw_spin_unlock_irq(&desc->lock);
@@ -639,11 +647,23 @@ static void irq_finalize_oneshot(unsigned int irq, struct irq_desc *desc)
 		goto again;
 	}
 
-	if (!(desc->istate & IRQS_DISABLED) && (desc->istate & IRQS_MASKED)) {
+	/*
+	 * Now check again, whether the thread should run. Otherwise
+	 * we would clear the threads_oneshot bit of this thread which
+	 * was just set.
+	 */
+	if (!force && test_bit(IRQTF_RUNTHREAD, &action->thread_flags))
+		goto out_unlock;
+
+	desc->threads_oneshot &= ~action->thread_mask;
+
+	if (!desc->threads_oneshot && !(desc->istate & IRQS_DISABLED) &&
+	    (desc->istate & IRQS_MASKED)) {
 		irq_compat_clr_masked(desc);
 		desc->istate &= ~IRQS_MASKED;
 		desc->irq_data.chip->irq_unmask(&desc->irq_data);
 	}
+out_unlock:
 	raw_spin_unlock_irq(&desc->lock);
 	chip_bus_sync_unlock(desc);
 }
@@ -691,7 +711,7 @@ static int irq_thread(void *data)
 	};
 	struct irqaction *action = data;
 	struct irq_desc *desc = irq_to_desc(action->irq);
-	int wake, oneshot = desc->istate & IRQS_ONESHOT;
+	int wake;
 
 	sched_setscheduler(current, SCHED_FIFO, &param);
 	current->irqaction = action;
@@ -719,8 +739,7 @@ static int irq_thread(void *data)
 
 			action->thread_fn(action->irq, action->dev_id);
 
-			if (oneshot)
-				irq_finalize_oneshot(action->irq, desc);
+			irq_finalize_oneshot(desc, action, false);
 		}
 
 		wake = atomic_dec_and_test(&desc->threads_active);
@@ -729,6 +748,9 @@ static int irq_thread(void *data)
 			wake_up(&desc->wait_for_threads);
 	}
 
+	/* Prevent a stale desc->threads_oneshot */
+	irq_finalize_oneshot(desc, action, true);
+
 	/*
 	 * Clear irqaction. Otherwise exit_irq_thread() would make
 	 * fuzz about an active irq thread going into nirvana.
@@ -743,6 +765,7 @@ static int irq_thread(void *data)
 void exit_irq_thread(void)
 {
 	struct task_struct *tsk = current;
+	struct irq_desc *desc;
 
 	if (!tsk->irqaction)
 		return;
@@ -751,6 +774,14 @@ void exit_irq_thread(void)
 	       "exiting task \"%s\" (%d) is an active IRQ thread (irq %d)\n",
 	       tsk->comm ? tsk->comm : "", tsk->pid, tsk->irqaction->irq);
 
+	desc = irq_to_desc(tsk->irqaction->irq);
+
+	/*
+	 * Prevent a stale desc->threads_oneshot. Must be called
+	 * before setting the IRQTF_DIED flag.
+	 */
+	irq_finalize_oneshot(desc, tsk->irqaction, true);
+
 	/*
 	 * Set the THREAD DIED flag to prevent further wakeups of the
 	 * soon to be gone threaded handler.
@@ -767,7 +798,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 {
 	struct irqaction *old, **old_ptr;
 	const char *old_name = NULL;
-	unsigned long flags;
+	unsigned long flags, thread_mask = 0;
 	int ret, nested, shared = 0;
 	cpumask_var_t mask;
 
@@ -865,12 +896,23 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 		/* add new interrupt at end of irq queue */
 		do {
+			thread_mask |= old->thread_mask;
 			old_ptr = &old->next;
 			old = *old_ptr;
 		} while (old);
 		shared = 1;
 	}
 
+	/*
+	 * Setup the thread mask for this irqaction. Unlikely to have
+	 * 32 resp 64 irqs sharing one line, but who knows.
+	 */
+	if (new->flags & IRQF_ONESHOT && thread_mask == ~0UL) {
+		ret = -EBUSY;
+		goto out_mask;
+	}
+	new->thread_mask = 1 << ffz(thread_mask);
+
 	if (!shared) {
 		irq_chip_set_defaults(desc->irq_data.chip);
 

commit 8fff39e06987492da3d4a0b9ec7cdbd245b6762b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Feb 21 14:19:42 2011 +0100

    genirq: Add missing break in __irq_set_trigger()
    
    The switch case in __irq_set_trigger() lacks a break, which emits a
    pr_err unconditionally on success.
    
    Reported-by: Lars-Peter Clausen <lars@metafoo.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 6cca1956c503..01f8a9519e63 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -567,6 +567,7 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 		if (chip != desc->irq_data.chip)
 			irq_chip_set_defaults(desc->irq_data.chip);
 		ret = 0;
+		break;
 	default:
 		pr_err("setting trigger mode %lu for irq %u failed (%pF)\n",
 		       flags, irq, chip->irq_set_type);

commit 02725e7471b8dd58fa96f6604bdb5dde45405a2e
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Feb 12 10:37:36 2011 +0100

    genirq: Use irq_get/put functions
    
    Convert the management functions to use the common irq_get/put
    function.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 99395a24f432..6cca1956c503 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -172,16 +172,13 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *mask)
 
 int irq_set_affinity_hint(unsigned int irq, const struct cpumask *m)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned long flags;
+	struct irq_desc *desc = irq_get_desc_lock(irq, &flags);
 
 	if (!desc)
 		return -EINVAL;
-
-	raw_spin_lock_irqsave(&desc->lock, flags);
 	desc->affinity_hint = m;
-	raw_spin_unlock_irqrestore(&desc->lock, flags);
-
+	irq_put_desc_unlock(desc, flags);
 	return 0;
 }
 EXPORT_SYMBOL_GPL(irq_set_affinity_hint);
@@ -336,6 +333,18 @@ void __disable_irq(struct irq_desc *desc, unsigned int irq, bool suspend)
 		irq_disable(desc);
 }
 
+static int __disable_irq_nosync(unsigned int irq)
+{
+	unsigned long flags;
+	struct irq_desc *desc = irq_get_desc_buslock(irq, &flags);
+
+	if (!desc)
+		return -EINVAL;
+	__disable_irq(desc, irq, false);
+	irq_put_desc_busunlock(desc, flags);
+	return 0;
+}
+
 /**
  *	disable_irq_nosync - disable an irq without waiting
  *	@irq: Interrupt to disable
@@ -349,17 +358,7 @@ void __disable_irq(struct irq_desc *desc, unsigned int irq, bool suspend)
  */
 void disable_irq_nosync(unsigned int irq)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
-	unsigned long flags;
-
-	if (!desc)
-		return;
-
-	chip_bus_lock(desc);
-	raw_spin_lock_irqsave(&desc->lock, flags);
-	__disable_irq(desc, irq, false);
-	raw_spin_unlock_irqrestore(&desc->lock, flags);
-	chip_bus_sync_unlock(desc);
+	__disable_irq_nosync(irq);
 }
 EXPORT_SYMBOL(disable_irq_nosync);
 
@@ -377,13 +376,7 @@ EXPORT_SYMBOL(disable_irq_nosync);
  */
 void disable_irq(unsigned int irq)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
-
-	if (!desc)
-		return;
-
-	disable_irq_nosync(irq);
-	if (desc->action)
+	if (!__disable_irq_nosync(irq))
 		synchronize_irq(irq);
 }
 EXPORT_SYMBOL(disable_irq);
@@ -434,21 +427,18 @@ void __enable_irq(struct irq_desc *desc, unsigned int irq, bool resume)
  */
 void enable_irq(unsigned int irq)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned long flags;
+	struct irq_desc *desc = irq_get_desc_buslock(irq, &flags);
 
 	if (!desc)
 		return;
-
 	if (WARN(!desc->irq_data.chip,
 		 KERN_ERR "enable_irq before setup/request_irq: irq %u\n", irq))
-		return;
+		goto out;
 
-	chip_bus_lock(desc);
-	raw_spin_lock_irqsave(&desc->lock, flags);
 	__enable_irq(desc, irq, false);
-	raw_spin_unlock_irqrestore(&desc->lock, flags);
-	chip_bus_sync_unlock(desc);
+out:
+	irq_put_desc_busunlock(desc, flags);
 }
 EXPORT_SYMBOL(enable_irq);
 
@@ -477,15 +467,13 @@ static int set_irq_wake_real(unsigned int irq, unsigned int on)
  */
 int irq_set_irq_wake(unsigned int irq, unsigned int on)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned long flags;
+	struct irq_desc *desc = irq_get_desc_buslock(irq, &flags);
 	int ret = 0;
 
 	/* wakeup-capable irqs can be shared between drivers that
 	 * don't need to have the same sleep mode behaviors.
 	 */
-	chip_bus_lock(desc);
-	raw_spin_lock_irqsave(&desc->lock, flags);
 	if (on) {
 		if (desc->wake_depth++ == 0) {
 			ret = set_irq_wake_real(irq, on);
@@ -505,9 +493,7 @@ int irq_set_irq_wake(unsigned int irq, unsigned int on)
 				irqd_clear(&desc->irq_data, IRQD_WAKEUP_STATE);
 		}
 	}
-
-	raw_spin_unlock_irqrestore(&desc->lock, flags);
-	chip_bus_sync_unlock(desc);
+	irq_put_desc_busunlock(desc, flags);
 	return ret;
 }
 EXPORT_SYMBOL(irq_set_irq_wake);
@@ -519,25 +505,20 @@ EXPORT_SYMBOL(irq_set_irq_wake);
  */
 int can_request_irq(unsigned int irq, unsigned long irqflags)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
-	struct irqaction *action;
 	unsigned long flags;
+	struct irq_desc *desc = irq_get_desc_lock(irq, &flags);
+	int canrequest = 0;
 
 	if (!desc)
 		return 0;
 
-	if (!irq_settings_can_request(desc))
-		return 0;
-
-	raw_spin_lock_irqsave(&desc->lock, flags);
-	action = desc->action;
-	if (action)
-		if (irqflags & action->flags & IRQF_SHARED)
-			action = NULL;
-
-	raw_spin_unlock_irqrestore(&desc->lock, flags);
-
-	return !action;
+	if (irq_settings_can_request(desc)) {
+		if (desc->action)
+			if (irqflags & desc->action->flags & IRQF_SHARED)
+				canrequest =1;
+	}
+	irq_put_desc_unlock(desc, flags);
+	return canrequest;
 }
 
 int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,

commit 091738a266fc74329ae186f22ff2b3f01319112d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Feb 14 20:16:43 2011 +0100

    genirq: Remove real old transition functions
    
    These transition helpers are stale for years now. Remove them.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index ea6add6036b1..99395a24f432 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -540,17 +540,6 @@ int can_request_irq(unsigned int irq, unsigned long irqflags)
 	return !action;
 }
 
-void compat_irq_chip_set_default_handler(struct irq_desc *desc)
-{
-	/*
-	 * If the architecture still has not overriden
-	 * the flow handler then zap the default. This
-	 * should catch incorrect flow-type setting.
-	 */
-	if (desc->handle_irq == &handle_bad_irq)
-		desc->handle_irq = NULL;
-}
-
 int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 		      unsigned long flags)
 {
@@ -912,8 +901,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 			if (ret)
 				goto out_mask;
-		} else
-			compat_irq_chip_set_default_handler(desc);
+		}
 
 		desc->istate &= ~(IRQS_AUTODETECT | IRQS_SPURIOUS_DISABLED | \
 				  IRQS_INPROGRESS | IRQS_ONESHOT | \

commit 7f94226f03299f1ca32f118f02f2a0295e0e5e93
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Feb 10 19:46:26 2011 +0100

    genirq: Move wakeup state to irq_data
    
    Some irq_chips need to know the state of wakeup mode for
    setting the trigger type etc. Reflect it in irq_data state.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 50809c79c7ad..ea6add6036b1 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -492,7 +492,7 @@ int irq_set_irq_wake(unsigned int irq, unsigned int on)
 			if (ret)
 				desc->wake_depth = 0;
 			else
-				desc->istate |= IRQS_WAKEUP;
+				irqd_set(&desc->irq_data, IRQD_WAKEUP_STATE);
 		}
 	} else {
 		if (desc->wake_depth == 0) {
@@ -502,7 +502,7 @@ int irq_set_irq_wake(unsigned int irq, unsigned int on)
 			if (ret)
 				desc->wake_depth = 1;
 			else
-				desc->istate &= ~IRQS_WAKEUP;
+				irqd_clear(&desc->irq_data, IRQD_WAKEUP_STATE);
 		}
 	}
 

commit d4d5e08960844a062da8387ee5f16ca7a33200d0
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Feb 10 13:16:14 2011 +0100

    genirq: Add IRQCHIP_SET_TYPE_MASKED flag
    
    irq_chips, which require to mask the chip before changing the trigger
    type should set this flag. So the core takes care of it and the
    requirement for looking into desc->status in the chip goes away.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Linus Walleij <linus.walleij@stericsson.com>
    Cc: Lars-Peter Clausen <lars@metafoo.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index b5de828e58d9..50809c79c7ad 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -554,8 +554,8 @@ void compat_irq_chip_set_default_handler(struct irq_desc *desc)
 int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 		      unsigned long flags)
 {
-	int ret;
 	struct irq_chip *chip = desc->irq_data.chip;
+	int ret, unmask = 0;
 
 	if (!chip || !chip->irq_set_type) {
 		/*
@@ -568,6 +568,14 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 	}
 
 	flags &= IRQ_TYPE_SENSE_MASK;
+
+	if (chip->flags & IRQCHIP_SET_TYPE_MASKED) {
+		if (!(desc->istate & IRQS_MASKED))
+			mask_irq(desc);
+		if (!(desc->istate & IRQS_DISABLED))
+			unmask = 1;
+	}
+
 	/* caller masked out all except trigger mode flags */
 	ret = chip->irq_set_type(&desc->irq_data, flags);
 
@@ -588,11 +596,13 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 
 		if (chip != desc->irq_data.chip)
 			irq_chip_set_defaults(desc->irq_data.chip);
-		return 0;
+		ret = 0;
 	default:
 		pr_err("setting trigger mode %lu for irq %u failed (%pF)\n",
 		       flags, irq, chip->irq_set_type);
 	}
+	if (unmask)
+		unmask_irq(desc);
 	return ret;
 }
 
@@ -669,7 +679,7 @@ static void irq_finalize_oneshot(unsigned int irq, struct irq_desc *desc)
 
 #ifdef CONFIG_SMP
 /*
- * Check whether we need to change the affinity of the interrupt thread.
+ * Check whether we need to chasnge the affinity of the interrupt thread.
  */
 static void
 irq_thread_check_affinity(struct irq_desc *desc, struct irqaction *action)

commit 1ccb4e612f68ceefb888c2c6c1def6294ea8666d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Feb 9 14:44:17 2011 +0100

    genirq: Wrap the remaning IRQ_* flags
    
    Use wrappers to keep them away from the core code.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 9ae758ed8e66..b5de828e58d9 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -103,7 +103,7 @@ void irq_set_thread_affinity(struct irq_desc *desc)
 #ifdef CONFIG_GENERIC_PENDING_IRQ
 static inline bool irq_can_move_pcntxt(struct irq_desc *desc)
 {
-	return desc->status & IRQ_MOVE_PCNTXT;
+	return irq_settings_can_move_pcntxt(desc);
 }
 static inline bool irq_move_pending(struct irq_desc *desc)
 {
@@ -411,7 +411,7 @@ void __enable_irq(struct irq_desc *desc, unsigned int irq, bool resume)
 		if (desc->istate & IRQS_SUSPENDED)
 			goto err_out;
 		/* Prevent probing on this irq: */
-		desc->status |= IRQ_NOPROBE;
+		irq_settings_set_noprobe(desc);
 		irq_enable(desc);
 		check_irq_resend(desc, irq);
 		/* fall-through */
@@ -526,7 +526,7 @@ int can_request_irq(unsigned int irq, unsigned long irqflags)
 	if (!desc)
 		return 0;
 
-	if (desc->status & IRQ_NOREQUEST)
+	if (!irq_settings_can_request(desc))
 		return 0;
 
 	raw_spin_lock_irqsave(&desc->lock, flags);
@@ -820,7 +820,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	 * Check whether the interrupt nests into another interrupt
 	 * thread.
 	 */
-	nested = desc->status & IRQ_NESTED_THREAD;
+	nested = irq_settings_is_nested_thread(desc);
 	if (nested) {
 		if (!new->thread_fn)
 			return -EINVAL;
@@ -917,7 +917,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		if (new->flags & IRQF_ONESHOT)
 			desc->istate |= IRQS_ONESHOT;
 
-		if (!(desc->status & IRQ_NOAUTOEN))
+		if (irq_settings_can_autoenable(desc))
 			irq_startup(desc);
 		else
 			/* Undo nested disables: */
@@ -1217,7 +1217,7 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 	if (!desc)
 		return -EINVAL;
 
-	if (desc->status & IRQ_NOREQUEST)
+	if (!irq_settings_can_request(desc))
 		return -EINVAL;
 
 	if (!handler) {
@@ -1292,7 +1292,7 @@ int request_any_context_irq(unsigned int irq, irq_handler_t handler,
 	if (!desc)
 		return -EINVAL;
 
-	if (desc->status & IRQ_NESTED_THREAD) {
+	if (irq_settings_is_nested_thread(desc)) {
 		ret = request_threaded_irq(irq, NULL, handler,
 					   flags, name, dev_id);
 		return !ret ? IRQC_IS_NESTED : ret;

commit 876dbd4cc1b35c1a4cb96a2be1d43ea0eabce3b4
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Feb 8 17:28:12 2011 +0100

    genirq: Mirror irq trigger type bits in irq_data.state
    
    That's the data structure chip functions get provided. Also allow them
    to signal the core code that they updated the flags in irq_data.state
    by returning IRQ_SET_MASK_OK_NOCOPY. The default is unchanged.
    
    The type bits should be accessed via:
    
    val = irqd_get_trigger_type(irqdata);
    and
    irqd_set_trigger_type(irqdata, val);
    
    Coders who access them directly will be tracked down and slapped with
    stinking trouts.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 8246afc81956..9ae758ed8e66 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -567,23 +567,32 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 		return 0;
 	}
 
+	flags &= IRQ_TYPE_SENSE_MASK;
 	/* caller masked out all except trigger mode flags */
 	ret = chip->irq_set_type(&desc->irq_data, flags);
 
-	if (ret)
-		pr_err("setting trigger mode %lu for irq %u failed (%pF)\n",
-		       flags, irq, chip->irq_set_type);
-	else {
-		if (flags & (IRQ_TYPE_LEVEL_LOW | IRQ_TYPE_LEVEL_HIGH))
-			flags |= IRQ_LEVEL;
-		/* note that IRQF_TRIGGER_MASK == IRQ_TYPE_SENSE_MASK */
-		desc->status &= ~(IRQ_LEVEL | IRQ_TYPE_SENSE_MASK);
-		desc->status |= flags;
+	switch (ret) {
+	case IRQ_SET_MASK_OK:
+		irqd_clear(&desc->irq_data, IRQD_TRIGGER_MASK);
+		irqd_set(&desc->irq_data, flags);
+
+	case IRQ_SET_MASK_OK_NOCOPY:
+		flags = irqd_get_trigger_type(&desc->irq_data);
+		irq_settings_set_trigger_mask(desc, flags);
+		irqd_clear(&desc->irq_data, IRQD_LEVEL);
+		irq_settings_clr_level(desc);
+		if (flags & IRQ_TYPE_LEVEL_MASK) {
+			irq_settings_set_level(desc);
+			irqd_set(&desc->irq_data, IRQD_LEVEL);
+		}
 
 		if (chip != desc->irq_data.chip)
 			irq_chip_set_defaults(desc->irq_data.chip);
+		return 0;
+	default:
+		pr_err("setting trigger mode %lu for irq %u failed (%pF)\n",
+		       flags, irq, chip->irq_set_type);
 	}
-
 	return ret;
 }
 
@@ -923,13 +932,14 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		/* Set default affinity mask once everything is setup */
 		setup_affinity(irq, desc, mask);
 
-	} else if ((new->flags & IRQF_TRIGGER_MASK)
-			&& (new->flags & IRQF_TRIGGER_MASK)
-				!= (desc->status & IRQ_TYPE_SENSE_MASK)) {
-		/* hope the handler works with the actual trigger mode... */
-		pr_warning("IRQ %d uses trigger mode %d; requested %d\n",
-				irq, (int)(desc->status & IRQ_TYPE_SENSE_MASK),
-				(int)(new->flags & IRQF_TRIGGER_MASK));
+	} else if (new->flags & IRQF_TRIGGER_MASK) {
+		unsigned int nmsk = new->flags & IRQF_TRIGGER_MASK;
+		unsigned int omsk = irq_settings_get_trigger_mask(desc);
+
+		if (nmsk != omsk)
+			/* hope the handler works with current  trigger mode */
+			pr_warning("IRQ %d uses trigger mode %u; requested %u\n",
+				   irq, nmsk, omsk);
 	}
 
 	new->irq = irq;

commit 2bdd10558c8d93009cb6c32ce9e30800fbb08add
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Feb 8 17:22:00 2011 +0100

    genirq: Move IRQ_AFFINITY_SET to core
    
    Keep status in sync until last abuser is gone.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 550ae97a0040..8246afc81956 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -164,7 +164,8 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *mask)
 		kref_get(&desc->affinity_notify->kref);
 		schedule_work(&desc->affinity_notify->work);
 	}
-	desc->status |= IRQ_AFFINITY_SET;
+	irq_compat_set_affinity(desc);
+	irqd_set(&desc->irq_data, IRQD_AFFINITY_SET);
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	return ret;
 }
@@ -272,12 +273,14 @@ setup_affinity(unsigned int irq, struct irq_desc *desc, struct cpumask *mask)
 	 * Preserve an userspace affinity setup, but make sure that
 	 * one of the targets is online.
 	 */
-	if (desc->status & (IRQ_AFFINITY_SET)) {
+	if (irqd_has_set(&desc->irq_data, IRQD_AFFINITY_SET)) {
 		if (cpumask_intersects(desc->irq_data.affinity,
 				       cpu_online_mask))
 			set = desc->irq_data.affinity;
-		else
-			desc->status &= ~IRQ_AFFINITY_SET;
+		else {
+			irq_compat_clr_affinity(desc);
+			irqd_clear(&desc->irq_data, IRQD_AFFINITY_SET);
+		}
 	}
 
 	cpumask_and(mask, cpu_online_mask, set);

commit bce43032ad79fae0ce5b6174ce1321e643ceb54b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Feb 10 22:37:41 2011 +0100

    genirq: Reuse existing can set affinty check
    
    Add a !desc check while at it.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 84a0a9c22226..550ae97a0040 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -73,8 +73,8 @@ int irq_can_set_affinity(unsigned int irq)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 
-	if (!irqd_can_balance(&desc->irq_data) || !desc->irq_data.chip ||
-	    !desc->irq_data.chip->irq_set_affinity)
+	if (!desc || !irqd_can_balance(&desc->irq_data) ||
+	    !desc->irq_data.chip || !desc->irq_data.chip->irq_set_affinity)
 		return 0;
 
 	return 1;

commit a005677b3dd05decdd8880cf3044ae709856f58f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Feb 8 17:11:03 2011 +0100

    genirq: Mirror IRQ_PER_CPU and IRQ_NO_BALANCING in irq_data.state
    
    That's the right data structure to look at for arch code.
    
    Accessor functions are provided.
    
             irqd_is_per_cpu(irqdata);
             irqd_can_balance(irqdata);
    
    Coders who access them directly will be tracked down and slapped with
    stinking trouts.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index f1cfa271ba70..84a0a9c22226 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -73,8 +73,8 @@ int irq_can_set_affinity(unsigned int irq)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 
-	if ((desc->status & (IRQ_PER_CPU | IRQ_NO_BALANCING)) ||
-	    !desc->irq_data.chip || !desc->irq_data.chip->irq_set_affinity)
+	if (!irqd_can_balance(&desc->irq_data) || !desc->irq_data.chip ||
+	    !desc->irq_data.chip->irq_set_affinity)
 		return 0;
 
 	return 1;
@@ -897,8 +897,10 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 				  IRQS_INPROGRESS | IRQS_ONESHOT | \
 				  IRQS_WAITING);
 
-		if (new->flags & IRQF_PERCPU)
-			desc->status |= IRQ_PER_CPU;
+		if (new->flags & IRQF_PERCPU) {
+			irqd_set(&desc->irq_data, IRQD_PER_CPU);
+			irq_settings_set_per_cpu(desc);
+		}
 
 		if (new->flags & IRQF_ONESHOT)
 			desc->istate |= IRQS_ONESHOT;
@@ -910,8 +912,10 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 			desc->depth = 1;
 
 		/* Exclude IRQ from balancing if requested */
-		if (new->flags & IRQF_NOBALANCING)
-			desc->status |= IRQ_NO_BALANCING;
+		if (new->flags & IRQF_NOBALANCING) {
+			irq_settings_set_no_balancing(desc);
+			irqd_set(&desc->irq_data, IRQD_NO_BALANCING);
+		}
 
 		/* Set default affinity mask once everything is setup */
 		setup_affinity(irq, desc, mask);

commit fae581e588e64a0690f3fc995e404fcacaebe772
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Feb 8 16:53:24 2011 +0100

    genirq: Remove CHECK_IRQ_PER_CPU from core code
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 056aa49698b4..f1cfa271ba70 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -73,8 +73,8 @@ int irq_can_set_affinity(unsigned int irq)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 
-	if (CHECK_IRQ_PER_CPU(desc->status) || !desc->irq_data.chip ||
-	    !desc->irq_data.chip->irq_set_affinity)
+	if ((desc->status & (IRQ_PER_CPU | IRQ_NO_BALANCING)) ||
+	    !desc->irq_data.chip || !desc->irq_data.chip->irq_set_affinity)
 		return 0;
 
 	return 1;

commit 6a58fb3bad099076f36f0f30f44507bc3275cdb6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Feb 8 15:40:05 2011 +0100

    genirq: Remove CONFIG_IRQ_PER_CPU
    
    The saving of this switch is minimal versus the ifdef mess it
    creates. Simple enable PER_CPU unconditionally and remove the config
    switch.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 9a99c471d470..056aa49698b4 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -865,12 +865,10 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 			goto mismatch;
 		}
 
-#if defined(CONFIG_IRQ_PER_CPU)
 		/* All handlers must agree on per-cpuness */
 		if ((old->flags & IRQF_PERCPU) !=
 		    (new->flags & IRQF_PERCPU))
 			goto mismatch;
-#endif
 
 		/* add new interrupt at end of irq queue */
 		do {
@@ -894,15 +892,14 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 				goto out_mask;
 		} else
 			compat_irq_chip_set_default_handler(desc);
-#if defined(CONFIG_IRQ_PER_CPU)
-		if (new->flags & IRQF_PERCPU)
-			desc->status |= IRQ_PER_CPU;
-#endif
 
 		desc->istate &= ~(IRQS_AUTODETECT | IRQS_SPURIOUS_DISABLED | \
 				  IRQS_INPROGRESS | IRQS_ONESHOT | \
 				  IRQS_WAITING);
 
+		if (new->flags & IRQF_PERCPU)
+			desc->status |= IRQ_PER_CPU;
+
 		if (new->flags & IRQF_ONESHOT)
 			desc->istate |= IRQS_ONESHOT;
 

commit f230b6d5c48f8d12f4dfa1f8b5ab0b0320076d21
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Feb 5 15:20:04 2011 +0100

    genirq: Add IRQ_MOVE_PENDING to irq_data.state
    
    chip implementations need to know about it. Keep status in sync until
    all users are fixed.
    
    Accessor function: irqd_is_setaffinity_pending(irqdata)
    
    Coders who access them directly will be tracked down and slapped with
    stinking trouts.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index ccc9389909ff..9a99c471d470 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -107,7 +107,7 @@ static inline bool irq_can_move_pcntxt(struct irq_desc *desc)
 }
 static inline bool irq_move_pending(struct irq_desc *desc)
 {
-	return desc->status & IRQ_MOVE_PENDING;
+	return irqd_is_setaffinity_pending(&desc->irq_data);
 }
 static inline void
 irq_copy_pending(struct irq_desc *desc, const struct cpumask *mask)
@@ -156,7 +156,7 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *mask)
 			ret = 0;
 		}
 	} else {
-		desc->status |= IRQ_MOVE_PENDING;
+		irqd_set_move_pending(&desc->irq_data);
 		irq_copy_pending(desc, mask);
 	}
 

commit 6d2cd17fde1fc3e93302815f049f255bb2b3123e
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Feb 8 14:34:18 2011 +0100

    genirq: Move IRQ_WAKEUP to core
    
    No users outside of core.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index b912de4ff4de..ccc9389909ff 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -489,7 +489,7 @@ int irq_set_irq_wake(unsigned int irq, unsigned int on)
 			if (ret)
 				desc->wake_depth = 0;
 			else
-				desc->status |= IRQ_WAKEUP;
+				desc->istate |= IRQS_WAKEUP;
 		}
 	} else {
 		if (desc->wake_depth == 0) {
@@ -499,7 +499,7 @@ int irq_set_irq_wake(unsigned int irq, unsigned int on)
 			if (ret)
 				desc->wake_depth = 1;
 			else
-				desc->status &= ~IRQ_WAKEUP;
+				desc->istate &= ~IRQS_WAKEUP;
 		}
 	}
 

commit c531e8361f1968d664e6e97fbd3bfa4cf0e62e42
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Feb 8 12:44:58 2011 +0100

    genirq: Move IRQ_SUSPENDED to core
    
    No users outside of core.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 83fd20194e5b..b912de4ff4de 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -326,7 +326,7 @@ void __disable_irq(struct irq_desc *desc, unsigned int irq, bool suspend)
 	if (suspend) {
 		if (!desc->action || (desc->action->flags & IRQF_NO_SUSPEND))
 			return;
-		desc->status |= IRQ_SUSPENDED;
+		desc->istate |= IRQS_SUSPENDED;
 	}
 
 	if (!desc->depth++)
@@ -388,7 +388,7 @@ EXPORT_SYMBOL(disable_irq);
 void __enable_irq(struct irq_desc *desc, unsigned int irq, bool resume)
 {
 	if (resume) {
-		if (!(desc->status & IRQ_SUSPENDED)) {
+		if (!(desc->istate & IRQS_SUSPENDED)) {
 			if (!desc->action)
 				return;
 			if (!(desc->action->flags & IRQF_FORCE_RESUME))
@@ -396,7 +396,7 @@ void __enable_irq(struct irq_desc *desc, unsigned int irq, bool resume)
 			/* Pretend that it got disabled ! */
 			desc->depth++;
 		}
-		desc->status &= ~IRQ_SUSPENDED;
+		desc->istate &= ~IRQS_SUSPENDED;
 	}
 
 	switch (desc->depth) {
@@ -405,7 +405,7 @@ void __enable_irq(struct irq_desc *desc, unsigned int irq, bool resume)
 		WARN(1, KERN_WARNING "Unbalanced enable for IRQ %d\n", irq);
 		break;
 	case 1: {
-		if (desc->status & IRQ_SUSPENDED)
+		if (desc->istate & IRQS_SUSPENDED)
 			goto err_out;
 		/* Prevent probing on this irq: */
 		desc->status |= IRQ_NOPROBE;

commit 6e40262ea43c4b0e3f435b3a083e4461ef921c17
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Feb 8 12:36:06 2011 +0100

    genirq: Move IRQ_MASKED to core
    
    Keep status in sync until all users are fixed.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index ac060814a787..83fd20194e5b 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -646,8 +646,9 @@ static void irq_finalize_oneshot(unsigned int irq, struct irq_desc *desc)
 		goto again;
 	}
 
-	if (!(desc->istate & IRQS_DISABLED) && (desc->status & IRQ_MASKED)) {
-		desc->status &= ~IRQ_MASKED;
+	if (!(desc->istate & IRQS_DISABLED) && (desc->istate & IRQS_MASKED)) {
+		irq_compat_clr_masked(desc);
+		desc->istate &= ~IRQS_MASKED;
 		desc->irq_data.chip->irq_unmask(&desc->irq_data);
 	}
 	raw_spin_unlock_irq(&desc->lock);

commit 2a0d6fb335d4428285dab2d254911748e6040807
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Feb 8 12:17:57 2011 +0100

    genirq: Move IRQ_PENDING flag to core
    
    Keep status in sync until all users are fixed.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 77ff275b54cf..ac060814a787 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -714,10 +714,11 @@ static int irq_thread(void *data)
 			 * CHECKME: We might need a dedicated
 			 * IRQ_THREAD_PENDING flag here, which
 			 * retriggers the thread in check_irq_resend()
-			 * but AFAICT IRQ_PENDING should be fine as it
+			 * but AFAICT IRQS_PENDING should be fine as it
 			 * retriggers the interrupt itself --- tglx
 			 */
-			desc->status |= IRQ_PENDING;
+			irq_compat_set_pending(desc);
+			desc->istate |= IRQS_PENDING;
 			raw_spin_unlock_irq(&desc->lock);
 		} else {
 			raw_spin_unlock_irq(&desc->lock);

commit c1594b77e46124bb462f961e536120e471c67446
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Feb 7 22:11:30 2011 +0100

    genirq: Move IRQ_DISABLED to core
    
    Keep status in sync until all abusers are fixed.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 7971df53d6a9..77ff275b54cf 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -646,7 +646,7 @@ static void irq_finalize_oneshot(unsigned int irq, struct irq_desc *desc)
 		goto again;
 	}
 
-	if (!(desc->status & IRQ_DISABLED) && (desc->status & IRQ_MASKED)) {
+	if (!(desc->istate & IRQS_DISABLED) && (desc->status & IRQ_MASKED)) {
 		desc->status &= ~IRQ_MASKED;
 		desc->irq_data.chip->irq_unmask(&desc->irq_data);
 	}
@@ -709,7 +709,7 @@ static int irq_thread(void *data)
 		atomic_inc(&desc->threads_active);
 
 		raw_spin_lock_irq(&desc->lock);
-		if (unlikely(desc->status & IRQ_DISABLED)) {
+		if (unlikely(desc->istate & IRQS_DISABLED)) {
 			/*
 			 * CHECKME: We might need a dedicated
 			 * IRQ_THREAD_PENDING flag here, which

commit 163ef3091195f514a06f064b12914597d2644c55
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Feb 8 11:39:15 2011 +0100

    genirq: Move IRQ_REPLAY and IRQ_WAITING to core
    
    No users outside of core.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index aca4208a03ac..7971df53d6a9 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -897,9 +897,9 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 			desc->status |= IRQ_PER_CPU;
 #endif
 
-		desc->status &= ~IRQ_WAITING;
 		desc->istate &= ~(IRQS_AUTODETECT | IRQS_SPURIOUS_DISABLED | \
-				  IRQS_INPROGRESS | IRQS_ONESHOT);
+				  IRQS_INPROGRESS | IRQS_ONESHOT | \
+				  IRQS_WAITING);
 
 		if (new->flags & IRQF_ONESHOT)
 			desc->istate |= IRQS_ONESHOT;

commit 3d67baec7f1b01fc289ac1a2f1a7e6d5e43391c6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Feb 7 21:02:10 2011 +0100

    genirq: Move IRQ_ONESHOT to core
    
    No users outside of core.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 7e5a50825088..aca4208a03ac 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -697,7 +697,7 @@ static int irq_thread(void *data)
 	};
 	struct irqaction *action = data;
 	struct irq_desc *desc = irq_to_desc(action->irq);
-	int wake, oneshot = desc->status & IRQ_ONESHOT;
+	int wake, oneshot = desc->istate & IRQS_ONESHOT;
 
 	sched_setscheduler(current, SCHED_FIFO, &param);
 	current->irqaction = action;
@@ -897,12 +897,12 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 			desc->status |= IRQ_PER_CPU;
 #endif
 
-		desc->status &= ~(IRQ_WAITING | IRQ_ONESHOT);
+		desc->status &= ~IRQ_WAITING;
 		desc->istate &= ~(IRQS_AUTODETECT | IRQS_SPURIOUS_DISABLED | \
-				  IRQS_INPROGRESS);
+				  IRQS_INPROGRESS | IRQS_ONESHOT);
 
 		if (new->flags & IRQF_ONESHOT)
-			desc->status |= IRQ_ONESHOT;
+			desc->istate |= IRQS_ONESHOT;
 
 		if (!(desc->status & IRQ_NOAUTOEN))
 			irq_startup(desc);

commit 009b4c3b8ad584b3462734127a5bec680d5d6af4
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Feb 7 21:48:49 2011 +0100

    genirq: Add IRQ_INPROGRESS to core
    
    We need to maintain the flag for now in both fields status and istate.
    Add a CONFIG_GENERIC_HARDIRQS_NO_COMPAT switch to allow testing w/o
    the status one. Wrap the access to status IRQ_INPROGRESS in a inline
    which can be turned of with CONFIG_GENERIC_HARDIRQS_NO_COMPAT along
    with the define.
    
    There is no reason that anything outside of core looks at this. That
    needs some modifications, but we'll get there.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 5b918ffa46af..7e5a50825088 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -30,7 +30,7 @@
 void synchronize_irq(unsigned int irq)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
-	unsigned int status;
+	unsigned int state;
 
 	if (!desc)
 		return;
@@ -42,16 +42,16 @@ void synchronize_irq(unsigned int irq)
 		 * Wait until we're out of the critical section.  This might
 		 * give the wrong answer due to the lack of memory barriers.
 		 */
-		while (desc->status & IRQ_INPROGRESS)
+		while (desc->istate & IRQS_INPROGRESS)
 			cpu_relax();
 
 		/* Ok, that indicated we're done: double-check carefully. */
 		raw_spin_lock_irqsave(&desc->lock, flags);
-		status = desc->status;
+		state = desc->istate;
 		raw_spin_unlock_irqrestore(&desc->lock, flags);
 
 		/* Oops, that failed? */
-	} while (status & IRQ_INPROGRESS);
+	} while (state & IRQS_INPROGRESS);
 
 	/*
 	 * We made sure that no hardirq handler is running. Now verify
@@ -637,9 +637,9 @@ static void irq_finalize_oneshot(unsigned int irq, struct irq_desc *desc)
 	 * The thread is faster done than the hard interrupt handler
 	 * on the other CPU. If we unmask the irq line then the
 	 * interrupt can come in again and masks the line, leaves due
-	 * to IRQ_INPROGRESS and the irq line is masked forever.
+	 * to IRQS_INPROGRESS and the irq line is masked forever.
 	 */
-	if (unlikely(desc->status & IRQ_INPROGRESS)) {
+	if (unlikely(desc->istate & IRQS_INPROGRESS)) {
 		raw_spin_unlock_irq(&desc->lock);
 		chip_bus_sync_unlock(desc);
 		cpu_relax();
@@ -897,8 +897,9 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 			desc->status |= IRQ_PER_CPU;
 #endif
 
-		desc->status &= ~(IRQ_WAITING | IRQ_ONESHOT | IRQ_INPROGRESS);
-		desc->istate &= ~(IRQS_AUTODETECT | IRQS_SPURIOUS_DISABLED);
+		desc->status &= ~(IRQ_WAITING | IRQ_ONESHOT);
+		desc->istate &= ~(IRQS_AUTODETECT | IRQS_SPURIOUS_DISABLED | \
+				  IRQS_INPROGRESS);
 
 		if (new->flags & IRQF_ONESHOT)
 			desc->status |= IRQ_ONESHOT;

commit 7acdd53e5b2c55b6f7e3427e85e2f91fa814a4f9
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Feb 7 20:40:54 2011 +0100

    genirq: Move IRQ_SPURIOUS_DISABLED to core state
    
    No users outside.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index abe852c9449d..5b918ffa46af 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -897,9 +897,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 			desc->status |= IRQ_PER_CPU;
 #endif
 
-		desc->status &= ~(IRQ_WAITING | IRQ_ONESHOT |
-				  IRQ_INPROGRESS | IRQ_SPURIOUS_DISABLED);
-		desc->istate &= ~IRQS_AUTODETECT;
+		desc->status &= ~(IRQ_WAITING | IRQ_ONESHOT | IRQ_INPROGRESS);
+		desc->istate &= ~(IRQS_AUTODETECT | IRQS_SPURIOUS_DISABLED);
 
 		if (new->flags & IRQF_ONESHOT)
 			desc->status |= IRQ_ONESHOT;
@@ -937,8 +936,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	 * Check whether we disabled the irq via the spurious handler
 	 * before. Reenable it and give it another chance.
 	 */
-	if (shared && (desc->status & IRQ_SPURIOUS_DISABLED)) {
-		desc->status &= ~IRQ_SPURIOUS_DISABLED;
+	if (shared && (desc->istate & IRQS_SPURIOUS_DISABLED)) {
+		desc->istate &= ~IRQS_SPURIOUS_DISABLED;
 		__enable_irq(desc, irq, false);
 	}
 

commit bd062e7667ac173afef57fbfe9327f3b914a9d4c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Feb 7 20:25:25 2011 +0100

    genirq: Move IRQ_AUTODETECT to internal state
    
    No users outside of core
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index dd4e5c21b9e7..abe852c9449d 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -897,8 +897,9 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 			desc->status |= IRQ_PER_CPU;
 #endif
 
-		desc->status &= ~(IRQ_AUTODETECT | IRQ_WAITING | IRQ_ONESHOT |
+		desc->status &= ~(IRQ_WAITING | IRQ_ONESHOT |
 				  IRQ_INPROGRESS | IRQ_SPURIOUS_DISABLED);
+		desc->istate &= ~IRQS_AUTODETECT;
 
 		if (new->flags & IRQF_ONESHOT)
 			desc->status |= IRQ_ONESHOT;

commit 35e857cbeb24e75c6f9a9312ac30454eee8c5950
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Feb 10 12:20:23 2011 +0100

    genirq: Fixup core code namespace fallout
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 78a566a9b39f..dd4e5c21b9e7 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -260,7 +260,7 @@ EXPORT_SYMBOL_GPL(irq_set_affinity_notifier);
 static int
 setup_affinity(unsigned int irq, struct irq_desc *desc, struct cpumask *mask)
 {
-	struct irq_chip *chip = get_irq_desc_chip(desc);
+	struct irq_chip *chip = irq_desc_get_chip(desc);
 	struct cpumask *set = irq_default_affinity;
 	int ret;
 

commit 3aae994fb0f43f6d94a31c33536a83869504abdf
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Feb 4 10:17:52 2011 +0100

    genirq: Consolidate IRQ_DISABLED
    
    Handle IRQ_DISABLED consistent.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 2a6c6ee11a3f..78a566a9b39f 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -329,10 +329,8 @@ void __disable_irq(struct irq_desc *desc, unsigned int irq, bool suspend)
 		desc->status |= IRQ_SUSPENDED;
 	}
 
-	if (!desc->depth++) {
-		desc->status |= IRQ_DISABLED;
+	if (!desc->depth++)
 		irq_disable(desc);
-	}
 }
 
 /**
@@ -407,12 +405,11 @@ void __enable_irq(struct irq_desc *desc, unsigned int irq, bool resume)
 		WARN(1, KERN_WARNING "Unbalanced enable for IRQ %d\n", irq);
 		break;
 	case 1: {
-		unsigned int status = desc->status & ~IRQ_DISABLED;
-
 		if (desc->status & IRQ_SUSPENDED)
 			goto err_out;
 		/* Prevent probing on this irq: */
-		desc->status = status | IRQ_NOPROBE;
+		desc->status |= IRQ_NOPROBE;
+		irq_enable(desc);
 		check_irq_resend(desc, irq);
 		/* fall-through */
 	}

commit 50f7c0327513d5acefbe26fd33498af18d1ffac5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Feb 3 13:23:54 2011 +0100

    genirq: Remove default magic
    
    Now that everything uses the wrappers, we can remove the default
    functions. None of those functions is performance critical.
    
    That makes the IRQ_MASKED flag tracking fully consistent.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 007802399697..2a6c6ee11a3f 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -440,8 +440,8 @@ void enable_irq(unsigned int irq)
 	if (!desc)
 		return;
 
-	if (WARN(!desc->irq_data.chip || !desc->irq_data.chip->irq_enable,
-	    KERN_ERR "enable_irq before setup/request_irq: irq %u\n", irq))
+	if (WARN(!desc->irq_data.chip,
+		 KERN_ERR "enable_irq before setup/request_irq: irq %u\n", irq))
 		return;
 
 	chip_bus_lock(desc);

commit 87923470c712dff00b101ffb6b6fbc27bd7a6df5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Feb 3 12:27:44 2011 +0100

    genirq: Consolidate disable/enable
    
    Create irq_disable/enable and use them to keep the flags consistent.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 9c562477e28b..007802399697 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -331,7 +331,7 @@ void __disable_irq(struct irq_desc *desc, unsigned int irq, bool suspend)
 
 	if (!desc->depth++) {
 		desc->status |= IRQ_DISABLED;
-		desc->irq_data.chip->irq_disable(&desc->irq_data);
+		irq_disable(desc);
 	}
 }
 

commit 4699923861513671d3f6ade8efb4e56a9a7ecadf
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Feb 2 21:41:14 2011 +0000

    genirq: Consolidate startup/shutdown of interrupts
    
    Aside of duplicated code some of the startup/shutdown sites do not
    handle the MASKED/DISABLED flags and the depth field at all. Move that
    to a helper function and take care of it there.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    LKML-Reference: <20110202212551.787481468@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 30bc8de40905..9c562477e28b 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -906,11 +906,9 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		if (new->flags & IRQF_ONESHOT)
 			desc->status |= IRQ_ONESHOT;
 
-		if (!(desc->status & IRQ_NOAUTOEN)) {
-			desc->depth = 0;
-			desc->status &= ~IRQ_DISABLED;
-			desc->irq_data.chip->irq_startup(&desc->irq_data);
-		} else
+		if (!(desc->status & IRQ_NOAUTOEN))
+			irq_startup(desc);
+		else
 			/* Undo nested disables: */
 			desc->depth = 1;
 
@@ -1055,10 +1053,8 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 #endif
 
 	/* If this was the last handler, shut down the IRQ line: */
-	if (!desc->action) {
-		desc->status |= IRQ_DISABLED;
-		desc->irq_data.chip->irq_shutdown(&desc->irq_data);
-	}
+	if (!desc->action)
+		irq_shutdown(desc);
 
 #ifdef CONFIG_SMP
 	/* make sure affinity_hint is cleaned up */

commit 3b56f0585fd4c02d047dc406668cb40159b2d340
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Feb 2 21:41:12 2011 +0000

    genirq: Remove bogus conditional
    
    The if (chip->irq_shutdown) check will always evaluate to true, as we
    fill in chip->irq_shutdown with default_shutdown in
    irq_chip_set_defaults() if the chip does not provide its own function.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    LKML-Reference: <20110202212551.667607458@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 33a6ee0ac68f..30bc8de40905 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1057,10 +1057,7 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 	/* If this was the last handler, shut down the IRQ line: */
 	if (!desc->action) {
 		desc->status |= IRQ_DISABLED;
-		if (desc->irq_data.chip->irq_shutdown)
-			desc->irq_data.chip->irq_shutdown(&desc->irq_data);
-		else
-			desc->irq_data.chip->irq_disable(&desc->irq_data);
+		desc->irq_data.chip->irq_shutdown(&desc->irq_data);
 	}
 
 #ifdef CONFIG_SMP

commit 2b879eaf095878430c38cbd95e5c0fc4ce65ad8e
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Feb 14 11:25:02 2011 +0100

    genirq: Remove redundant thread affinity setting
    
    Thread affinity is already set by setup_affinity().
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index dc95d53df510..33a6ee0ac68f 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -309,8 +309,6 @@ int irq_select_affinity_usr(unsigned int irq, struct cpumask *mask)
 
 	raw_spin_lock_irqsave(&desc->lock, flags);
 	ret = setup_affinity(irq, desc, mask);
-	if (!ret)
-		irq_set_thread_affinity(desc);
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	return ret;
 }

commit 3b8249e759c701c4a82f99d957be651a7657bf6f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Feb 7 16:02:20 2011 +0100

    genirq: Do not copy affinity before set
    
    While rumaging through arch code I found that there are a few
    workarounds which deal with the fact that the initial affinity setting
    from request_irq() copies the mask into irq_data->affinity before the
    chip code is called. In the normal path we unconditionally copy the
    mask when the chip code returns 0.
    
    Copy after the code is called and add a return code
    IRQ_SET_MASK_OK_NOCOPY for the chip functions, which prevents the
    copy. That way we see the real mask when the chip function decided to
    truncate it further as some arches do. IRQ_SET_MASK_OK is 0, which is
    the current behaviour.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index ade65bfb466d..dc95d53df510 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -148,9 +148,12 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *mask)
 
 	if (irq_can_move_pcntxt(desc)) {
 		ret = chip->irq_set_affinity(&desc->irq_data, mask, false);
-		if (!ret) {
+		switch (ret) {
+		case IRQ_SET_MASK_OK:
 			cpumask_copy(desc->irq_data.affinity, mask);
+		case IRQ_SET_MASK_OK_NOCOPY:
 			irq_set_thread_affinity(desc);
+			ret = 0;
 		}
 	} else {
 		desc->status |= IRQ_MOVE_PENDING;
@@ -254,9 +257,12 @@ EXPORT_SYMBOL_GPL(irq_set_affinity_notifier);
 /*
  * Generic version of the affinity autoselector.
  */
-static int setup_affinity(unsigned int irq, struct irq_desc *desc)
+static int
+setup_affinity(unsigned int irq, struct irq_desc *desc, struct cpumask *mask)
 {
+	struct irq_chip *chip = get_irq_desc_chip(desc);
 	struct cpumask *set = irq_default_affinity;
+	int ret;
 
 	/* Excludes PER_CPU and NO_BALANCE interrupts */
 	if (!irq_can_set_affinity(irq))
@@ -273,13 +279,20 @@ static int setup_affinity(unsigned int irq, struct irq_desc *desc)
 		else
 			desc->status &= ~IRQ_AFFINITY_SET;
 	}
-	cpumask_and(desc->irq_data.affinity, cpu_online_mask, set);
-	desc->irq_data.chip->irq_set_affinity(&desc->irq_data, desc->irq_data.affinity, false);
 
+	cpumask_and(mask, cpu_online_mask, set);
+	ret = chip->irq_set_affinity(&desc->irq_data, mask, false);
+	switch (ret) {
+	case IRQ_SET_MASK_OK:
+		cpumask_copy(desc->irq_data.affinity, mask);
+	case IRQ_SET_MASK_OK_NOCOPY:
+		irq_set_thread_affinity(desc);
+	}
 	return 0;
 }
 #else
-static inline int setup_affinity(unsigned int irq, struct irq_desc *d)
+static inline int
+setup_affinity(unsigned int irq, struct irq_desc *d, struct cpumask *mask)
 {
 	return irq_select_affinity(irq);
 }
@@ -288,23 +301,23 @@ static inline int setup_affinity(unsigned int irq, struct irq_desc *d)
 /*
  * Called when affinity is set via /proc/irq
  */
-int irq_select_affinity_usr(unsigned int irq)
+int irq_select_affinity_usr(unsigned int irq, struct cpumask *mask)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned long flags;
 	int ret;
 
 	raw_spin_lock_irqsave(&desc->lock, flags);
-	ret = setup_affinity(irq, desc);
+	ret = setup_affinity(irq, desc, mask);
 	if (!ret)
 		irq_set_thread_affinity(desc);
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
-
 	return ret;
 }
 
 #else
-static inline int setup_affinity(unsigned int irq, struct irq_desc *desc)
+static inline int
+setup_affinity(unsigned int irq, struct irq_desc *desc, struct cpumask *mask)
 {
 	return 0;
 }
@@ -765,8 +778,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	struct irqaction *old, **old_ptr;
 	const char *old_name = NULL;
 	unsigned long flags;
-	int nested, shared = 0;
-	int ret;
+	int ret, nested, shared = 0;
+	cpumask_var_t mask;
 
 	if (!desc)
 		return -EINVAL;
@@ -831,6 +844,11 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		new->thread = t;
 	}
 
+	if (!alloc_cpumask_var(&mask, GFP_KERNEL)) {
+		ret = -ENOMEM;
+		goto out_thread;
+	}
+
 	/*
 	 * The following block of code has to be executed atomically
 	 */
@@ -876,7 +894,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 					new->flags & IRQF_TRIGGER_MASK);
 
 			if (ret)
-				goto out_thread;
+				goto out_mask;
 		} else
 			compat_irq_chip_set_default_handler(desc);
 #if defined(CONFIG_IRQ_PER_CPU)
@@ -903,7 +921,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 			desc->status |= IRQ_NO_BALANCING;
 
 		/* Set default affinity mask once everything is setup */
-		setup_affinity(irq, desc);
+		setup_affinity(irq, desc, mask);
 
 	} else if ((new->flags & IRQF_TRIGGER_MASK)
 			&& (new->flags & IRQF_TRIGGER_MASK)
@@ -956,6 +974,9 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 #endif
 	ret = -EBUSY;
 
+out_mask:
+	free_cpumask_var(mask);
+
 out_thread:
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	if (new->thread) {

commit 569bda8df11effa03e618729293c7961696abb10
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Feb 7 17:05:08 2011 +0100

    genirq: Always apply cpu online mask
    
    If the affinity had been set by the user, then a later request_irq()
    will honour that setting. But online cpus can have changed. So apply
    the online mask and for this case as well.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 591c927b135c..ade65bfb466d 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -256,6 +256,8 @@ EXPORT_SYMBOL_GPL(irq_set_affinity_notifier);
  */
 static int setup_affinity(unsigned int irq, struct irq_desc *desc)
 {
+	struct cpumask *set = irq_default_affinity;
+
 	/* Excludes PER_CPU and NO_BALANCE interrupts */
 	if (!irq_can_set_affinity(irq))
 		return 0;
@@ -265,15 +267,13 @@ static int setup_affinity(unsigned int irq, struct irq_desc *desc)
 	 * one of the targets is online.
 	 */
 	if (desc->status & (IRQ_AFFINITY_SET)) {
-		if (cpumask_any_and(desc->irq_data.affinity, cpu_online_mask)
-		    < nr_cpu_ids)
-			goto set_affinity;
+		if (cpumask_intersects(desc->irq_data.affinity,
+				       cpu_online_mask))
+			set = desc->irq_data.affinity;
 		else
 			desc->status &= ~IRQ_AFFINITY_SET;
 	}
-
-	cpumask_and(desc->irq_data.affinity, cpu_online_mask, irq_default_affinity);
-set_affinity:
+	cpumask_and(desc->irq_data.affinity, cpu_online_mask, set);
 	desc->irq_data.chip->irq_set_affinity(&desc->irq_data, desc->irq_data.affinity, false);
 
 	return 0;

commit b008207cbd0d5ce606a1a2ac52826e0ab37d0b99
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Feb 7 17:30:50 2011 +0100

    genirq: Rremove redundant check
    
    IRQ_NO_BALANCING is already checked in irq_can_set_affinity() above,
    no need to check it again.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 99f3e9a3780c..591c927b135c 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -256,6 +256,7 @@ EXPORT_SYMBOL_GPL(irq_set_affinity_notifier);
  */
 static int setup_affinity(unsigned int irq, struct irq_desc *desc)
 {
+	/* Excludes PER_CPU and NO_BALANCE interrupts */
 	if (!irq_can_set_affinity(irq))
 		return 0;
 
@@ -263,7 +264,7 @@ static int setup_affinity(unsigned int irq, struct irq_desc *desc)
 	 * Preserve an userspace affinity setup, but make sure that
 	 * one of the targets is online.
 	 */
-	if (desc->status & (IRQ_AFFINITY_SET | IRQ_NO_BALANCING)) {
+	if (desc->status & (IRQ_AFFINITY_SET)) {
 		if (cpumask_any_and(desc->irq_data.affinity, cpu_online_mask)
 		    < nr_cpu_ids)
 			goto set_affinity;

commit 1fa46f1f070961783661ae640cd2f6b2557f3885
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Feb 7 16:46:58 2011 +0100

    genirq: Simplify affinity related code
    
    There is lot of #ifdef CONFIG_GENERIC_PENDING_IRQ along with
    duplicated code in the irq core. Move the #ifdeffery into one place
    and cleanup the code so it's readable. No functional change.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index b1b4da9446e6..99f3e9a3780c 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -100,47 +100,70 @@ void irq_set_thread_affinity(struct irq_desc *desc)
 	}
 }
 
+#ifdef CONFIG_GENERIC_PENDING_IRQ
+static inline bool irq_can_move_pcntxt(struct irq_desc *desc)
+{
+	return desc->status & IRQ_MOVE_PCNTXT;
+}
+static inline bool irq_move_pending(struct irq_desc *desc)
+{
+	return desc->status & IRQ_MOVE_PENDING;
+}
+static inline void
+irq_copy_pending(struct irq_desc *desc, const struct cpumask *mask)
+{
+	cpumask_copy(desc->pending_mask, mask);
+}
+static inline void
+irq_get_pending(struct cpumask *mask, struct irq_desc *desc)
+{
+	cpumask_copy(mask, desc->pending_mask);
+}
+#else
+static inline bool irq_can_move_pcntxt(struct irq_desc *desc) { return true; }
+static inline bool irq_move_pending(struct irq_desc *desc) { return false; }
+static inline void
+irq_copy_pending(struct irq_desc *desc, const struct cpumask *mask) { }
+static inline void
+irq_get_pending(struct cpumask *mask, struct irq_desc *desc) { }
+#endif
+
 /**
  *	irq_set_affinity - Set the irq affinity of a given irq
  *	@irq:		Interrupt to set affinity
  *	@cpumask:	cpumask
  *
  */
-int irq_set_affinity(unsigned int irq, const struct cpumask *cpumask)
+int irq_set_affinity(unsigned int irq, const struct cpumask *mask)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 	struct irq_chip *chip = desc->irq_data.chip;
 	unsigned long flags;
+	int ret = 0;
 
 	if (!chip->irq_set_affinity)
 		return -EINVAL;
 
 	raw_spin_lock_irqsave(&desc->lock, flags);
 
-#ifdef CONFIG_GENERIC_PENDING_IRQ
-	if (desc->status & IRQ_MOVE_PCNTXT) {
-		if (!chip->irq_set_affinity(&desc->irq_data, cpumask, false)) {
-			cpumask_copy(desc->irq_data.affinity, cpumask);
+	if (irq_can_move_pcntxt(desc)) {
+		ret = chip->irq_set_affinity(&desc->irq_data, mask, false);
+		if (!ret) {
+			cpumask_copy(desc->irq_data.affinity, mask);
 			irq_set_thread_affinity(desc);
 		}
-	}
-	else {
+	} else {
 		desc->status |= IRQ_MOVE_PENDING;
-		cpumask_copy(desc->pending_mask, cpumask);
+		irq_copy_pending(desc, mask);
 	}
-#else
-	if (!chip->irq_set_affinity(&desc->irq_data, cpumask, false)) {
-		cpumask_copy(desc->irq_data.affinity, cpumask);
-		irq_set_thread_affinity(desc);
-	}
-#endif
+
 	if (desc->affinity_notify) {
 		kref_get(&desc->affinity_notify->kref);
 		schedule_work(&desc->affinity_notify->work);
 	}
 	desc->status |= IRQ_AFFINITY_SET;
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
-	return 0;
+	return ret;
 }
 
 int irq_set_affinity_hint(unsigned int irq, const struct cpumask *m)
@@ -167,18 +190,13 @@ static void irq_affinity_notify(struct work_struct *work)
 	cpumask_var_t cpumask;
 	unsigned long flags;
 
-	if (!desc)
-		goto out;
-
-	if (!alloc_cpumask_var(&cpumask, GFP_KERNEL))
+	if (!desc || !alloc_cpumask_var(&cpumask, GFP_KERNEL))
 		goto out;
 
 	raw_spin_lock_irqsave(&desc->lock, flags);
-#ifdef CONFIG_GENERIC_PENDING_IRQ
-	if (desc->status & IRQ_MOVE_PENDING)
-		cpumask_copy(cpumask, desc->pending_mask);
+	if (irq_move_pending(desc))
+		irq_get_pending(cpumask, desc);
 	else
-#endif
 		cpumask_copy(cpumask, desc->irq_data.affinity);
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 

commit a0cd9ca2b907d7ee26575e7b63ac92dad768a75e
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Feb 10 11:36:33 2011 +0100

    genirq: Namespace cleanup
    
    The irq namespace has become quite convoluted. My bad.  Clean it up
    and deprecate the old functions. All new functions follow the scheme:
    
    irq number based:
        irq_set/get/xxx/_xxx(unsigned int irq, ...)
    
    irq_data based:
             irq_data_set/get/xxx/_xxx(struct irq_data *d, ....)
    
    irq_desc based:
             irq_desc_get_xxx(struct irq_desc *desc)
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index a400db220cf3..b1b4da9446e6 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -434,7 +434,7 @@ static int set_irq_wake_real(unsigned int irq, unsigned int on)
 }
 
 /**
- *	set_irq_wake - control irq power management wakeup
+ *	irq_set_irq_wake - control irq power management wakeup
  *	@irq:	interrupt to control
  *	@on:	enable/disable power management wakeup
  *
@@ -445,7 +445,7 @@ static int set_irq_wake_real(unsigned int irq, unsigned int on)
  *	Wakeup mode lets this IRQ wake the system from sleep
  *	states like "suspend to RAM".
  */
-int set_irq_wake(unsigned int irq, unsigned int on)
+int irq_set_irq_wake(unsigned int irq, unsigned int on)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned long flags;
@@ -480,7 +480,7 @@ int set_irq_wake(unsigned int irq, unsigned int on)
 	chip_bus_sync_unlock(desc);
 	return ret;
 }
-EXPORT_SYMBOL(set_irq_wake);
+EXPORT_SYMBOL(irq_set_irq_wake);
 
 /*
  * Internal function that tells the architecture code whether a

commit 43abe43ce0619d744c7a5bb15cce075e532b53b7
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Feb 12 12:10:49 2011 +0100

    genirq: Add missing buslock to set_irq_type(), set_irq_wake()
    
    chips behind a slow bus cannot update the chip under desc->lock, but
    we miss the chip_buslock/chip_bus_sync_unlock() calls around the set
    type and set wake functions.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index ba84307fbf24..a400db220cf3 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -454,6 +454,7 @@ int set_irq_wake(unsigned int irq, unsigned int on)
 	/* wakeup-capable irqs can be shared between drivers that
 	 * don't need to have the same sleep mode behaviors.
 	 */
+	chip_bus_lock(desc);
 	raw_spin_lock_irqsave(&desc->lock, flags);
 	if (on) {
 		if (desc->wake_depth++ == 0) {
@@ -476,6 +477,7 @@ int set_irq_wake(unsigned int irq, unsigned int on)
 	}
 
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
+	chip_bus_sync_unlock(desc);
 	return ret;
 }
 EXPORT_SYMBOL(set_irq_wake);

commit 218502bfe674f570205367b9094048207b04ba15
Merge: 51327ada7142 6d83f94db95c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Feb 19 12:56:36 2011 +0100

    Merge branch 'irq/urgent' into irq/core
    
    Reason: Further patches are conflicting with mainline fixes
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit 6d83f94db95cfe65d2a6359cccdf61cf087c2598
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Feb 18 23:27:23 2011 +0100

    genirq: Disable the SHIRQ_DEBUG call in request_threaded_irq for now
    
    With CONFIG_SHIRQ_DEBUG=y we call a newly installed interrupt handler
    in request_threaded_irq().
    
    The original implementation (commit a304e1b8) called the handler
    _BEFORE_ it was installed, but that caused problems with handlers
    calling disable_irq_nosync(). See commit 377bf1e4.
    
    It's braindead in the first place to call disable_irq_nosync in shared
    handlers, but ....
    
    Moving this call after we installed the handler looks innocent, but it
    is very subtle broken on SMP.
    
    Interrupt handlers rely on the fact, that the irq core prevents
    reentrancy.
    
    Now this debug call violates that promise because we run the handler
    w/o the IRQ_INPROGRESS protection - which we cannot apply here because
    that would result in a possibly forever masked interrupt line.
    
    A concurrent real hardware interrupt on a different CPU results in
    handler reentrancy and can lead to complete wreckage, which was
    unfortunately observed in reality and took a fricking long time to
    debug.
    
    Leave the code here for now. We want this debug feature, but that's
    not easy to fix. We really should get rid of those
    disable_irq_nosync() abusers and remove that function completely.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Anton Vorontsov <avorontsov@ru.mvista.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Arjan van de Ven <arjan@infradead.org>
    Cc: stable@kernel.org # .28 -> .37

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0caa59f747dd..9033c1c70828 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1100,7 +1100,7 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 	if (retval)
 		kfree(action);
 
-#ifdef CONFIG_DEBUG_SHIRQ
+#ifdef CONFIG_DEBUG_SHIRQ_FIXME
 	if (!retval && (irqflags & IRQF_SHARED)) {
 		/*
 		 * It's a shared IRQ -- the driver ought to be prepared for it

commit 51327ada7142ab520ed610a42572d1f4cbfbb2dc
Merge: 44951a60ff88 986c011ddbb3
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Feb 11 00:26:54 2011 +0100

    Merge branch 'irq/for-mips' into irq/core
    
    Reason: irq/for-mips is provided for mips to make core independent
            progress. Merge it into irq/core to avoid conflicts
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit 986c011ddbb3ed44b35e1bfd67f6aa60b293b495
Author: David Daney <ddaney@caviumnetworks.com>
Date:   Wed Feb 9 16:04:25 2011 -0800

    genirq: Call bus_lock/unlock functions in setup_irq()
    
    irq_chips that supply .irq_bus_lock/.irq_bus_sync_unlock functions,
    expect that the other chip methods will be called inside of calls to
    the pair.  If this expectation is not met, things tend to not work.
    
    Make setup_irq() call chip_bus_lock()/chip_bus_sync_unlock() too.
    
    For the vast majority of irq_chips, this will be a NOP as most don't
    have these bus lock functions.
    
    [ tglx: No we don't want to call that in __setup_irq(). Way too many
            error exit pathes. ]
    
    Signed-off-by: David Daney <ddaney@caviumnetworks.com>
    LKML-Reference: <1297296265-18680-1-git-send-email-ddaney@caviumnetworks.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0caa59f747dd..a00bf2cd67ed 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -871,9 +871,14 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
  */
 int setup_irq(unsigned int irq, struct irqaction *act)
 {
+	int retval;
 	struct irq_desc *desc = irq_to_desc(irq);
 
-	return __setup_irq(irq, desc, act);
+	chip_bus_lock(desc);
+	retval = __setup_irq(irq, desc, act);
+	chip_bus_sync_unlock(desc);
+
+	return retval;
 }
 EXPORT_SYMBOL_GPL(setup_irq);
 

commit c9a443cdf7726ce8b78c3177c6ae601ce37292fc
Merge: 285c1a2c3a5f dc5f219e8829
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Feb 8 16:38:00 2011 +0100

    Merge branch 'irq/for-xen' into irq/core
    
    irq/for-xen contains new functionality to avoid Xen private irq
    hackery. That branch has a single irq commit and is pulled by Xen to
    base their new features on.
    
    Merge it into irq/core as other patches modify the same code.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit dc5f219e88294b93009eef946251251ffffb6d60
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Feb 4 13:19:20 2011 +0100

    genirq: Add IRQF_FORCE_RESUME
    
    Xen needs to reenable interrupts which are marked IRQF_NO_SUSPEND in the
    resume path. Add a flag to force the reenabling in the resume code.
    
    Tested-and-acked-by: Ian Campbell <Ian.Campbell@eu.citrix.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0caa59f747dd..b4198ee8cfdf 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -282,8 +282,17 @@ EXPORT_SYMBOL(disable_irq);
 
 void __enable_irq(struct irq_desc *desc, unsigned int irq, bool resume)
 {
-	if (resume)
+	if (resume) {
+		if (!(desc->status & IRQ_SUSPENDED)) {
+			if (!desc->action)
+				return;
+			if (!(desc->action->flags & IRQF_FORCE_RESUME))
+				return;
+			/* Pretend that it got disabled ! */
+			desc->depth++;
+		}
 		desc->status &= ~IRQ_SUSPENDED;
+	}
 
 	switch (desc->depth) {
 	case 0:

commit 1fb0ef31f428f345a7c3666f8e7444a563edd537
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jan 31 08:57:41 2011 +0100

    genirq: Fix affinity notifier fallout
    
    The new code of commit cd7eab44e(genirq: Add IRQ affinity notifiers)
    references irq_desc.affinity which fails to compile with
    CONFIG_GENERIC_HARDIRQS_NO_DEPRECATED=y.
    
    Use irq_desc.irq_data.affinity instead.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ben Hutchings <bhutchings@solarflare.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0587c5ceaed8..538fce2db51c 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -179,7 +179,7 @@ static void irq_affinity_notify(struct work_struct *work)
 		cpumask_copy(cpumask, desc->pending_mask);
 	else
 #endif
-		cpumask_copy(cpumask, desc->affinity);
+		cpumask_copy(cpumask, desc->irq_data.affinity);
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 
 	notify->notify(notify, cpumask);

commit cd7eab44e9946c28d595abe3e9a43e945bc49141
Author: Ben Hutchings <bhutchings@solarflare.com>
Date:   Wed Jan 19 21:01:44 2011 +0000

    genirq: Add IRQ affinity notifiers
    
    When initiating I/O on a multiqueue and multi-IRQ device, we may want
    to select a queue for which the response will be handled on the same
    or a nearby CPU.  This requires a reverse-map of IRQ affinity.  Add a
    notification mechanism to support this.
    
    This is based closely on work by Thomas Gleixner <tglx@linutronix.de>.
    
    Signed-off-by: Ben Hutchings <bhutchings@solarflare.com>
    Cc: linux-net-drivers@solarflare.com
    Cc: Tom Herbert <therbert@google.com>
    Cc: David Miller <davem@davemloft.net>
    LKML-Reference: <1295470904.11126.84.camel@bwh-desktop>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0caa59f747dd..0587c5ceaed8 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -134,6 +134,10 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *cpumask)
 		irq_set_thread_affinity(desc);
 	}
 #endif
+	if (desc->affinity_notify) {
+		kref_get(&desc->affinity_notify->kref);
+		schedule_work(&desc->affinity_notify->work);
+	}
 	desc->status |= IRQ_AFFINITY_SET;
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	return 0;
@@ -155,6 +159,79 @@ int irq_set_affinity_hint(unsigned int irq, const struct cpumask *m)
 }
 EXPORT_SYMBOL_GPL(irq_set_affinity_hint);
 
+static void irq_affinity_notify(struct work_struct *work)
+{
+	struct irq_affinity_notify *notify =
+		container_of(work, struct irq_affinity_notify, work);
+	struct irq_desc *desc = irq_to_desc(notify->irq);
+	cpumask_var_t cpumask;
+	unsigned long flags;
+
+	if (!desc)
+		goto out;
+
+	if (!alloc_cpumask_var(&cpumask, GFP_KERNEL))
+		goto out;
+
+	raw_spin_lock_irqsave(&desc->lock, flags);
+#ifdef CONFIG_GENERIC_PENDING_IRQ
+	if (desc->status & IRQ_MOVE_PENDING)
+		cpumask_copy(cpumask, desc->pending_mask);
+	else
+#endif
+		cpumask_copy(cpumask, desc->affinity);
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
+
+	notify->notify(notify, cpumask);
+
+	free_cpumask_var(cpumask);
+out:
+	kref_put(&notify->kref, notify->release);
+}
+
+/**
+ *	irq_set_affinity_notifier - control notification of IRQ affinity changes
+ *	@irq:		Interrupt for which to enable/disable notification
+ *	@notify:	Context for notification, or %NULL to disable
+ *			notification.  Function pointers must be initialised;
+ *			the other fields will be initialised by this function.
+ *
+ *	Must be called in process context.  Notification may only be enabled
+ *	after the IRQ is allocated and must be disabled before the IRQ is
+ *	freed using free_irq().
+ */
+int
+irq_set_affinity_notifier(unsigned int irq, struct irq_affinity_notify *notify)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+	struct irq_affinity_notify *old_notify;
+	unsigned long flags;
+
+	/* The release function is promised process context */
+	might_sleep();
+
+	if (!desc)
+		return -EINVAL;
+
+	/* Complete initialisation of *notify */
+	if (notify) {
+		notify->irq = irq;
+		kref_init(&notify->kref);
+		INIT_WORK(&notify->work, irq_affinity_notify);
+	}
+
+	raw_spin_lock_irqsave(&desc->lock, flags);
+	old_notify = desc->affinity_notify;
+	desc->affinity_notify = notify;
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
+
+	if (old_notify)
+		kref_put(&old_notify->kref, old_notify->release);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(irq_set_affinity_notifier);
+
 #ifndef CONFIG_AUTO_IRQ_AFFINITY
 /*
  * Generic version of the affinity autoselector.
@@ -1004,6 +1081,11 @@ void free_irq(unsigned int irq, void *dev_id)
 	if (!desc)
 		return;
 
+#ifdef CONFIG_SMP
+	if (WARN_ON(desc->affinity_notify))
+		desc->affinity_notify = NULL;
+#endif
+
 	chip_bus_lock(desc);
 	kfree(__free_irq(irq, dev_id));
 	chip_bus_sync_unlock(desc);

commit c9b5f501ef1580faa30c40c644b7691870462201
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Fri Jan 7 13:41:40 2011 +0100

    sched: Constify function scope static struct sched_param usage
    
    Function-scope statics are discouraged because they are
    easily overlooked and can cause subtle bugs/races due to
    their global (non-SMP safe) nature.
    
    Linus noticed that we did this for sched_param - at minimum
    make the const.
    
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    LKML-Reference: Message-ID: <AANLkTinotRxScOHEb0HgFgSpGPkq_6jKTv5CfvnQM=ee@mail.gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 91a5fa25054e..0caa59f747dd 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -577,7 +577,7 @@ irq_thread_check_affinity(struct irq_desc *desc, struct irqaction *action) { }
  */
 static int irq_thread(void *data)
 {
-	static struct sched_param param = {
+	static const struct sched_param param = {
 		.sched_priority = MAX_USER_RT_PRIO/2,
 	};
 	struct irqaction *action = data;

commit 92fd4d4d67b945c0766416284d4ab236b31542c4
Merge: fe7de49f9d4e e53beacd23d9
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Nov 18 13:22:14 2010 +0100

    Merge commit 'v2.6.37-rc2' into sched/core
    
    Merge reason: Move to a .37-rc base.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit fe7de49f9d4e53f24ec9ef762a503f70b562341c
Author: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Date:   Wed Oct 20 16:01:12 2010 -0700

    sched: Make sched_param argument static in sched_setscheduler() callers
    
    Andrew Morton pointed out almost all sched_setscheduler() callers are
    using fixed parameters and can be converted to static.  It reduces runtime
    memory use a little.
    
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Reported-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: James Morris <jmorris@namei.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 644e8d5fa367..850f030fa0c2 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -573,7 +573,9 @@ irq_thread_check_affinity(struct irq_desc *desc, struct irqaction *action) { }
  */
 static int irq_thread(void *data)
 {
-	struct sched_param param = { .sched_priority = MAX_USER_RT_PRIO/2, };
+	static struct sched_param param = {
+		.sched_priority = MAX_USER_RT_PRIO/2,
+	};
 	struct irqaction *action = data;
 	struct irq_desc *desc = irq_to_desc(action->irq);
 	int wake, oneshot = desc->status & IRQ_ONESHOT;

commit 2656c36699677238edc9ec1fea79039f1fddbcb6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Oct 22 14:47:57 2010 +0200

    genirq: Warn if enable_irq is called before irq is set up
    
    The recent changes in the genirq core unearthed a bug in arch/um which
    called enable_irq() before the interrupt was set up.
    
    Warn and return instead of crashing the machine with a NULL pointer
    dereference.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Richard Weinberger <richard@nod.at>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 644e8d5fa367..5f92acc5f952 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -324,6 +324,10 @@ void enable_irq(unsigned int irq)
 	if (!desc)
 		return;
 
+	if (WARN(!desc->irq_data.chip || !desc->irq_data.chip->irq_enable,
+	    KERN_ERR "enable_irq before setup/request_irq: irq %u\n", irq))
+		return;
+
 	chip_bus_lock(desc);
 	raw_spin_lock_irqsave(&desc->lock, flags);
 	__enable_irq(desc, irq, false);

commit 2f7e99bb9be6a2d8d7b808dc86037710cc8b7bf1
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Sep 27 12:45:50 2010 +0000

    genirq: Provide compat handling for chip->set_wake()
    
    Wrap the old chip function set_wake() until the migration is complete
    and the old chip functions are removed.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    LKML-Reference: <20100927121842.927527393@linutronix.de>
    Reviewed-by: H. Peter Anvin <hpa@zytor.com>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 3618362b3d8d..644e8d5fa367 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -337,8 +337,8 @@ static int set_irq_wake_real(unsigned int irq, unsigned int on)
 	struct irq_desc *desc = irq_to_desc(irq);
 	int ret = -ENXIO;
 
-	if (desc->irq_data.chip->set_wake)
-		ret = desc->irq_data.chip->set_wake(irq, on);
+	if (desc->irq_data.chip->irq_set_wake)
+		ret = desc->irq_data.chip->irq_set_wake(&desc->irq_data, on);
 
 	return ret;
 }

commit b2ba2c30033c10cca2454f8b44bf98f5249e61c6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Sep 27 12:45:47 2010 +0000

    genirq: Provide compat handling for chip->set_type()
    
    Wrap the old chip function set_type() until the migration is complete
    and the old chip functions are removed.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    LKML-Reference: <20100927121842.832261548@linutronix.de>
    Reviewed-by: H. Peter Anvin <hpa@zytor.com>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 305a60ff756b..3618362b3d8d 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -430,12 +430,12 @@ void compat_irq_chip_set_default_handler(struct irq_desc *desc)
 }
 
 int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
-		unsigned long flags)
+		      unsigned long flags)
 {
 	int ret;
 	struct irq_chip *chip = desc->irq_data.chip;
 
-	if (!chip || !chip->set_type) {
+	if (!chip || !chip->irq_set_type) {
 		/*
 		 * IRQF_TRIGGER_* but the PIC does not support multiple
 		 * flow-types?
@@ -446,11 +446,11 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 	}
 
 	/* caller masked out all except trigger mode flags */
-	ret = chip->set_type(irq, flags);
+	ret = chip->irq_set_type(&desc->irq_data, flags);
 
 	if (ret)
-		pr_err("setting trigger mode %d for irq %u failed (%pF)\n",
-				(int)flags, irq, chip->set_type);
+		pr_err("setting trigger mode %lu for irq %u failed (%pF)\n",
+		       flags, irq, chip->irq_set_type);
 	else {
 		if (flags & (IRQ_TYPE_LEVEL_LOW | IRQ_TYPE_LEVEL_HIGH))
 			flags |= IRQ_LEVEL;

commit c96b3b3c448592a0b87ef20306deb8b1fb4878c7
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Sep 27 12:45:41 2010 +0000

    genirq: Provide compat handling for chip->set_affinity()
    
    Wrap the old chip function set_affinity() until the migration is
    complete and the old chip functions are removed.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    LKML-Reference: <20100927121842.732894108@linutronix.de>
    Reviewed-by: H. Peter Anvin <hpa@zytor.com>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 31d7678e0269..305a60ff756b 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -74,7 +74,7 @@ int irq_can_set_affinity(unsigned int irq)
 	struct irq_desc *desc = irq_to_desc(irq);
 
 	if (CHECK_IRQ_PER_CPU(desc->status) || !desc->irq_data.chip ||
-	    !desc->irq_data.chip->set_affinity)
+	    !desc->irq_data.chip->irq_set_affinity)
 		return 0;
 
 	return 1;
@@ -109,16 +109,17 @@ void irq_set_thread_affinity(struct irq_desc *desc)
 int irq_set_affinity(unsigned int irq, const struct cpumask *cpumask)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
+	struct irq_chip *chip = desc->irq_data.chip;
 	unsigned long flags;
 
-	if (!desc->irq_data.chip->set_affinity)
+	if (!chip->irq_set_affinity)
 		return -EINVAL;
 
 	raw_spin_lock_irqsave(&desc->lock, flags);
 
 #ifdef CONFIG_GENERIC_PENDING_IRQ
 	if (desc->status & IRQ_MOVE_PCNTXT) {
-		if (!desc->irq_data.chip->set_affinity(irq, cpumask)) {
+		if (!chip->irq_set_affinity(&desc->irq_data, cpumask, false)) {
 			cpumask_copy(desc->irq_data.affinity, cpumask);
 			irq_set_thread_affinity(desc);
 		}
@@ -128,7 +129,7 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *cpumask)
 		cpumask_copy(desc->pending_mask, cpumask);
 	}
 #else
-	if (!desc->irq_data.chip->set_affinity(irq, cpumask)) {
+	if (!chip->irq_set_affinity(&desc->irq_data, cpumask, false)) {
 		cpumask_copy(desc->irq_data.affinity, cpumask);
 		irq_set_thread_affinity(desc);
 	}
@@ -177,7 +178,7 @@ static int setup_affinity(unsigned int irq, struct irq_desc *desc)
 
 	cpumask_and(desc->irq_data.affinity, cpu_online_mask, irq_default_affinity);
 set_affinity:
-	desc->irq_data.chip->set_affinity(irq, desc->irq_data.affinity);
+	desc->irq_data.chip->irq_set_affinity(&desc->irq_data, desc->irq_data.affinity, false);
 
 	return 0;
 }

commit 37e12df709f09eac17314d79a52190ac46746e33
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Sep 27 12:45:38 2010 +0000

    genirq: Provide compat handling for chip->startup()
    
    Wrap the old chip function startup() until the migration is complete and
    the old chip functions are removed.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    LKML-Reference: <20100927121842.635152961@linutronix.de>
    Reviewed-by: H. Peter Anvin <hpa@zytor.com>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index f3f36f6af9a1..31d7678e0269 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -779,7 +779,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		if (!(desc->status & IRQ_NOAUTOEN)) {
 			desc->depth = 0;
 			desc->status &= ~IRQ_DISABLED;
-			desc->irq_data.chip->startup(irq);
+			desc->irq_data.chip->irq_startup(&desc->irq_data);
 		} else
 			/* Undo nested disables: */
 			desc->depth = 1;

commit bc310dda41be6439364c8f3b9fe7c9d743d22b1c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Sep 27 12:45:02 2010 +0000

    genirq: Provide compat handling for chip->disable()/shutdown()
    
    Wrap the old chip functions disable() and shutdown() until the
    migration is complete and the old chip functions are removed.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    LKML-Reference: <20100927121842.532070631@linutronix.de>
    Reviewed-by: H. Peter Anvin <hpa@zytor.com>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index b3986bce64ff..f3f36f6af9a1 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -223,7 +223,7 @@ void __disable_irq(struct irq_desc *desc, unsigned int irq, bool suspend)
 
 	if (!desc->depth++) {
 		desc->status |= IRQ_DISABLED;
-		desc->irq_data.chip->disable(irq);
+		desc->irq_data.chip->irq_disable(&desc->irq_data);
 	}
 }
 
@@ -919,10 +919,10 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 	/* If this was the last handler, shut down the IRQ line: */
 	if (!desc->action) {
 		desc->status |= IRQ_DISABLED;
-		if (desc->irq_data.chip->shutdown)
-			desc->irq_data.chip->shutdown(irq);
+		if (desc->irq_data.chip->irq_shutdown)
+			desc->irq_data.chip->irq_shutdown(&desc->irq_data);
 		else
-			desc->irq_data.chip->disable(irq);
+			desc->irq_data.chip->irq_disable(&desc->irq_data);
 	}
 
 #ifdef CONFIG_SMP

commit 0eda58b7f3a30c9a13d83db1cfaab00e1c452055
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Sep 27 12:44:44 2010 +0000

    genirq: Provide compat handling for chip->unmask()
    
    Wrap the old chip function unmask() until the migration is complete
    and the old chip functions are removed.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    LKML-Reference: <20100927121842.043608928@linutronix.de>
    Reviewed-by: H. Peter Anvin <hpa@zytor.com>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index dfb02ff7d2ef..b3986bce64ff 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -528,7 +528,7 @@ static void irq_finalize_oneshot(unsigned int irq, struct irq_desc *desc)
 
 	if (!(desc->status & IRQ_DISABLED) && (desc->status & IRQ_MASKED)) {
 		desc->status &= ~IRQ_MASKED;
-		desc->irq_data.chip->unmask(irq);
+		desc->irq_data.chip->irq_unmask(&desc->irq_data);
 	}
 	raw_spin_unlock_irq(&desc->lock);
 	chip_bus_sync_unlock(desc);

commit 3876ec9ef3775d062345b3760d3271ecb8cd3fea
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Sep 27 12:44:35 2010 +0000

    genirq: Provide compat handling for bus_lock/bus_sync_unlock
    
    Wrap the old chip functions for bus_lock/bus_sync_unlock until the
    migration is complete and the old chip functions are removed.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    LKML-Reference: <20100927121841.842536121@linutronix.de>
    Reviewed-by: H. Peter Anvin <hpa@zytor.com>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 4dfb19521d9f..dfb02ff7d2ef 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -246,11 +246,11 @@ void disable_irq_nosync(unsigned int irq)
 	if (!desc)
 		return;
 
-	chip_bus_lock(irq, desc);
+	chip_bus_lock(desc);
 	raw_spin_lock_irqsave(&desc->lock, flags);
 	__disable_irq(desc, irq, false);
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
-	chip_bus_sync_unlock(irq, desc);
+	chip_bus_sync_unlock(desc);
 }
 EXPORT_SYMBOL(disable_irq_nosync);
 
@@ -323,11 +323,11 @@ void enable_irq(unsigned int irq)
 	if (!desc)
 		return;
 
-	chip_bus_lock(irq, desc);
+	chip_bus_lock(desc);
 	raw_spin_lock_irqsave(&desc->lock, flags);
 	__enable_irq(desc, irq, false);
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
-	chip_bus_sync_unlock(irq, desc);
+	chip_bus_sync_unlock(desc);
 }
 EXPORT_SYMBOL(enable_irq);
 
@@ -507,7 +507,7 @@ static int irq_wait_for_interrupt(struct irqaction *action)
 static void irq_finalize_oneshot(unsigned int irq, struct irq_desc *desc)
 {
 again:
-	chip_bus_lock(irq, desc);
+	chip_bus_lock(desc);
 	raw_spin_lock_irq(&desc->lock);
 
 	/*
@@ -521,7 +521,7 @@ static void irq_finalize_oneshot(unsigned int irq, struct irq_desc *desc)
 	 */
 	if (unlikely(desc->status & IRQ_INPROGRESS)) {
 		raw_spin_unlock_irq(&desc->lock);
-		chip_bus_sync_unlock(irq, desc);
+		chip_bus_sync_unlock(desc);
 		cpu_relax();
 		goto again;
 	}
@@ -531,7 +531,7 @@ static void irq_finalize_oneshot(unsigned int irq, struct irq_desc *desc)
 		desc->irq_data.chip->unmask(irq);
 	}
 	raw_spin_unlock_irq(&desc->lock);
-	chip_bus_sync_unlock(irq, desc);
+	chip_bus_sync_unlock(desc);
 }
 
 #ifdef CONFIG_SMP
@@ -997,9 +997,9 @@ void free_irq(unsigned int irq, void *dev_id)
 	if (!desc)
 		return;
 
-	chip_bus_lock(irq, desc);
+	chip_bus_lock(desc);
 	kfree(__free_irq(irq, dev_id));
-	chip_bus_sync_unlock(irq, desc);
+	chip_bus_sync_unlock(desc);
 }
 EXPORT_SYMBOL(free_irq);
 
@@ -1086,9 +1086,9 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 	action->name = devname;
 	action->dev_id = dev_id;
 
-	chip_bus_lock(irq, desc);
+	chip_bus_lock(desc);
 	retval = __setup_irq(irq, desc, action);
-	chip_bus_sync_unlock(irq, desc);
+	chip_bus_sync_unlock(desc);
 
 	if (retval)
 		kfree(action);

commit 6b8ff3120c758340505dddf08ad685ebb841d5d5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Oct 1 12:58:38 2010 +0200

    genirq: Convert core code to irq_data
    
    Convert all references in the core code to orq, chip, handler_data,
    chip_data, msi_desc, affinity to irq_data.*
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index c3003e9d91a3..4dfb19521d9f 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -73,8 +73,8 @@ int irq_can_set_affinity(unsigned int irq)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 
-	if (CHECK_IRQ_PER_CPU(desc->status) || !desc->chip ||
-	    !desc->chip->set_affinity)
+	if (CHECK_IRQ_PER_CPU(desc->status) || !desc->irq_data.chip ||
+	    !desc->irq_data.chip->set_affinity)
 		return 0;
 
 	return 1;
@@ -111,15 +111,15 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *cpumask)
 	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned long flags;
 
-	if (!desc->chip->set_affinity)
+	if (!desc->irq_data.chip->set_affinity)
 		return -EINVAL;
 
 	raw_spin_lock_irqsave(&desc->lock, flags);
 
 #ifdef CONFIG_GENERIC_PENDING_IRQ
 	if (desc->status & IRQ_MOVE_PCNTXT) {
-		if (!desc->chip->set_affinity(irq, cpumask)) {
-			cpumask_copy(desc->affinity, cpumask);
+		if (!desc->irq_data.chip->set_affinity(irq, cpumask)) {
+			cpumask_copy(desc->irq_data.affinity, cpumask);
 			irq_set_thread_affinity(desc);
 		}
 	}
@@ -128,8 +128,8 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *cpumask)
 		cpumask_copy(desc->pending_mask, cpumask);
 	}
 #else
-	if (!desc->chip->set_affinity(irq, cpumask)) {
-		cpumask_copy(desc->affinity, cpumask);
+	if (!desc->irq_data.chip->set_affinity(irq, cpumask)) {
+		cpumask_copy(desc->irq_data.affinity, cpumask);
 		irq_set_thread_affinity(desc);
 	}
 #endif
@@ -168,16 +168,16 @@ static int setup_affinity(unsigned int irq, struct irq_desc *desc)
 	 * one of the targets is online.
 	 */
 	if (desc->status & (IRQ_AFFINITY_SET | IRQ_NO_BALANCING)) {
-		if (cpumask_any_and(desc->affinity, cpu_online_mask)
+		if (cpumask_any_and(desc->irq_data.affinity, cpu_online_mask)
 		    < nr_cpu_ids)
 			goto set_affinity;
 		else
 			desc->status &= ~IRQ_AFFINITY_SET;
 	}
 
-	cpumask_and(desc->affinity, cpu_online_mask, irq_default_affinity);
+	cpumask_and(desc->irq_data.affinity, cpu_online_mask, irq_default_affinity);
 set_affinity:
-	desc->chip->set_affinity(irq, desc->affinity);
+	desc->irq_data.chip->set_affinity(irq, desc->irq_data.affinity);
 
 	return 0;
 }
@@ -223,7 +223,7 @@ void __disable_irq(struct irq_desc *desc, unsigned int irq, bool suspend)
 
 	if (!desc->depth++) {
 		desc->status |= IRQ_DISABLED;
-		desc->chip->disable(irq);
+		desc->irq_data.chip->disable(irq);
 	}
 }
 
@@ -313,7 +313,7 @@ void __enable_irq(struct irq_desc *desc, unsigned int irq, bool resume)
  *	IRQ line is re-enabled.
  *
  *	This function may be called from IRQ context only when
- *	desc->chip->bus_lock and desc->chip->bus_sync_unlock are NULL !
+ *	desc->irq_data.chip->bus_lock and desc->chip->bus_sync_unlock are NULL !
  */
 void enable_irq(unsigned int irq)
 {
@@ -336,8 +336,8 @@ static int set_irq_wake_real(unsigned int irq, unsigned int on)
 	struct irq_desc *desc = irq_to_desc(irq);
 	int ret = -ENXIO;
 
-	if (desc->chip->set_wake)
-		ret = desc->chip->set_wake(irq, on);
+	if (desc->irq_data.chip->set_wake)
+		ret = desc->irq_data.chip->set_wake(irq, on);
 
 	return ret;
 }
@@ -432,7 +432,7 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 		unsigned long flags)
 {
 	int ret;
-	struct irq_chip *chip = desc->chip;
+	struct irq_chip *chip = desc->irq_data.chip;
 
 	if (!chip || !chip->set_type) {
 		/*
@@ -457,8 +457,8 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 		desc->status &= ~(IRQ_LEVEL | IRQ_TYPE_SENSE_MASK);
 		desc->status |= flags;
 
-		if (chip != desc->chip)
-			irq_chip_set_defaults(desc->chip);
+		if (chip != desc->irq_data.chip)
+			irq_chip_set_defaults(desc->irq_data.chip);
 	}
 
 	return ret;
@@ -528,7 +528,7 @@ static void irq_finalize_oneshot(unsigned int irq, struct irq_desc *desc)
 
 	if (!(desc->status & IRQ_DISABLED) && (desc->status & IRQ_MASKED)) {
 		desc->status &= ~IRQ_MASKED;
-		desc->chip->unmask(irq);
+		desc->irq_data.chip->unmask(irq);
 	}
 	raw_spin_unlock_irq(&desc->lock);
 	chip_bus_sync_unlock(irq, desc);
@@ -556,7 +556,7 @@ irq_thread_check_affinity(struct irq_desc *desc, struct irqaction *action)
 	}
 
 	raw_spin_lock_irq(&desc->lock);
-	cpumask_copy(mask, desc->affinity);
+	cpumask_copy(mask, desc->irq_data.affinity);
 	raw_spin_unlock_irq(&desc->lock);
 
 	set_cpus_allowed_ptr(current, mask);
@@ -657,7 +657,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	if (!desc)
 		return -EINVAL;
 
-	if (desc->chip == &no_irq_chip)
+	if (desc->irq_data.chip == &no_irq_chip)
 		return -ENOSYS;
 	/*
 	 * Some drivers like serial.c use request_irq() heavily,
@@ -752,7 +752,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	}
 
 	if (!shared) {
-		irq_chip_set_defaults(desc->chip);
+		irq_chip_set_defaults(desc->irq_data.chip);
 
 		init_waitqueue_head(&desc->wait_for_threads);
 
@@ -779,7 +779,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		if (!(desc->status & IRQ_NOAUTOEN)) {
 			desc->depth = 0;
 			desc->status &= ~IRQ_DISABLED;
-			desc->chip->startup(irq);
+			desc->irq_data.chip->startup(irq);
 		} else
 			/* Undo nested disables: */
 			desc->depth = 1;
@@ -912,17 +912,17 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 
 	/* Currently used only by UML, might disappear one day: */
 #ifdef CONFIG_IRQ_RELEASE_METHOD
-	if (desc->chip->release)
-		desc->chip->release(irq, dev_id);
+	if (desc->irq_data.chip->release)
+		desc->irq_data.chip->release(irq, dev_id);
 #endif
 
 	/* If this was the last handler, shut down the IRQ line: */
 	if (!desc->action) {
 		desc->status |= IRQ_DISABLED;
-		if (desc->chip->shutdown)
-			desc->chip->shutdown(irq);
+		if (desc->irq_data.chip->shutdown)
+			desc->irq_data.chip->shutdown(irq);
 		else
-			desc->chip->disable(irq);
+			desc->irq_data.chip->disable(irq);
 	}
 
 #ifdef CONFIG_SMP

commit 685fd0b4ea3f0f1d5385610b0d5b57775a8d5842
Author: Ian Campbell <ian.campbell@citrix.com>
Date:   Thu Jul 29 11:16:32 2010 +0100

    irq: Add new IRQ flag IRQF_NO_SUSPEND
    
    A small number of users of IRQF_TIMER are using it for the implied no
    suspend behaviour on interrupts which are not timer interrupts.
    
    Therefore add a new IRQF_NO_SUSPEND flag, rename IRQF_TIMER to
    __IRQF_TIMER and redefine IRQF_TIMER in terms of these new flags.
    
    Signed-off-by: Ian Campbell <ian.campbell@citrix.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Dmitry Torokhov <dmitry.torokhov@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Grant Likely <grant.likely@secretlab.ca>
    Cc: xen-devel@lists.xensource.com
    Cc: linux-input@vger.kernel.org
    Cc: linuxppc-dev@ozlabs.org
    Cc: devicetree-discuss@lists.ozlabs.org
    LKML-Reference: <1280398595-29708-1-git-send-email-ian.campbell@citrix.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index e1497481fe8a..c3003e9d91a3 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -216,7 +216,7 @@ static inline int setup_affinity(unsigned int irq, struct irq_desc *desc)
 void __disable_irq(struct irq_desc *desc, unsigned int irq, bool suspend)
 {
 	if (suspend) {
-		if (!desc->action || (desc->action->flags & IRQF_TIMER))
+		if (!desc->action || (desc->action->flags & IRQF_NO_SUSPEND))
 			return;
 		desc->status |= IRQ_SUSPENDED;
 	}

commit 4673247562e39a17e09440fa1400819522ccd446
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jun 7 17:53:51 2010 +0200

    genirq: Deal with desc->set_type() changing desc->chip
    
    The set_type() function can change the chip implementation when the
    trigger mode changes. That might result in using an non-initialized
    irq chip when called from __setup_irq() or when called via
    set_irq_type() on an already enabled irq.
    
    The set_irq_type() function should not be called on an enabled irq,
    but because we forgot to put a check into it, we have a bunch of users
    which grew the habit of doing that and it never blew up as the
    function is serialized via desc->lock against all users of desc->chip
    and they never hit the non-initialized irq chip issue.
    
    The easy fix for the __setup_irq() issue would be to move the
    irq_chip_set_defaults(desc->chip) call after the trigger setting to
    make sure that a chip change is covered.
    
    But as we have already users, which do the type setting after
    request_irq(), the safe fix for now is to call irq_chip_set_defaults()
    from __irq_set_trigger() when desc->set_type() changed the irq chip.
    
    It needs a deeper analysis whether we should refuse to change the chip
    on an already enabled irq, but that'd be a large scale change to fix
    all the existing users. So that's neither stable nor 2.6.35 material.
    
    Reported-by: Esben Haabendal <eha@doredevelopment.dk>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: linuxppc-dev <linuxppc-dev@ozlabs.org>
    Cc: stable@kernel.org

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 3164ba7ce151..e1497481fe8a 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -456,6 +456,9 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 		/* note that IRQF_TRIGGER_MASK == IRQ_TYPE_SENSE_MASK */
 		desc->status &= ~(IRQ_LEVEL | IRQ_TYPE_SENSE_MASK);
 		desc->status |= flags;
+
+		if (chip != desc->chip)
+			irq_chip_set_defaults(desc->chip);
 	}
 
 	return ret;

commit e7a297b0d7d6049bd4e423ac1e17da31e4c401b8
Author: Peter P Waskiewicz Jr <peter.p.waskiewicz.jr@intel.com>
Date:   Fri Apr 30 14:44:50 2010 -0700

    genirq: Add CPU mask affinity hint
    
    This patch adds a cpumask affinity hint to the irq_desc structure,
    along with a registration function and a read-only proc entry for each
    interrupt.
    
    This affinity_hint handle for each interrupt can be used by underlying
    drivers that need a better mechanism to control interrupt affinity.
    The underlying driver can register a cpumask for the interrupt, which
    will allow the driver to provide the CPU mask for the interrupt to
    anything that requests it.  The intent is to extend the userspace
    daemon, irqbalance, to help hint to it a preferred CPU mask to balance
    the interrupt into.
    
    [ tglx: Fixed compile warnings, added WARN_ON, made SMP only ]
    
    Signed-off-by: Peter P Waskiewicz Jr <peter.p.waskiewicz.jr@intel.com>
    Cc: davem@davemloft.net
    Cc: arjan@linux.jf.intel.com
    Cc: bhutchings@solarflare.com
    LKML-Reference: <20100430214445.3992.41647.stgit@ppwaskie-hc2.jf.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 444d5a81a209..3164ba7ce151 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -138,6 +138,22 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *cpumask)
 	return 0;
 }
 
+int irq_set_affinity_hint(unsigned int irq, const struct cpumask *m)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+	unsigned long flags;
+
+	if (!desc)
+		return -EINVAL;
+
+	raw_spin_lock_irqsave(&desc->lock, flags);
+	desc->affinity_hint = m;
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(irq_set_affinity_hint);
+
 #ifndef CONFIG_AUTO_IRQ_AFFINITY
 /*
  * Generic version of the affinity autoselector.
@@ -906,6 +922,12 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 			desc->chip->disable(irq);
 	}
 
+#ifdef CONFIG_SMP
+	/* make sure affinity_hint is cleaned up */
+	if (WARN_ON_ONCE(desc->affinity_hint))
+		desc->affinity_hint = NULL;
+#endif
+
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 
 	unregister_handler_proc(irq, action);

commit 6932bf37bed45ce8ed531928b1b0f98162fe6df6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Mar 26 00:06:55 2010 +0000

    genirq: Remove IRQF_DISABLED from core code
    
    Remove all code which is related to IRQF_DISABLED from the core kernel
    code. IRQF_DISABLED still exists as a flag, but becomes a NOOP and
    will be removed after a grace period. That way we can easily revert to
    the previous behaviour by just restoring the core code.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: David Miller <davem@davemloft.net>
    Cc: Greg Kroah-Hartman <gregkh@suse.de>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Linus Torvalds <torvalds@osdl.org>
    LKML-Reference: <20100326000405.991244690@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 84f32278ff1f..444d5a81a209 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -757,16 +757,6 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		if (new->flags & IRQF_ONESHOT)
 			desc->status |= IRQ_ONESHOT;
 
-		/*
-		 * Force MSI interrupts to run with interrupts
-		 * disabled. The multi vector cards can cause stack
-		 * overflows due to nested interrupts when enough of
-		 * them are directed to a core and fire at the same
-		 * time.
-		 */
-		if (desc->msi_desc)
-			new->flags |= IRQF_DISABLED;
-
 		if (!(desc->status & IRQ_NOAUTOEN)) {
 			desc->depth = 0;
 			desc->status &= ~IRQ_DISABLED;
@@ -1027,7 +1017,6 @@ EXPORT_SYMBOL(free_irq);
  *	Flags:
  *
  *	IRQF_SHARED		Interrupt is shared
- *	IRQF_DISABLED	Disable local interrupts while processing
  *	IRQF_SAMPLE_RANDOM	The interrupt can be used for entropy
  *	IRQF_TRIGGER_*		Specify active edge(s) or level
  *
@@ -1040,25 +1029,6 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 	struct irq_desc *desc;
 	int retval;
 
-	/*
-	 * handle_IRQ_event() always ignores IRQF_DISABLED except for
-	 * the _first_ irqaction (sigh).  That can cause oopsing, but
-	 * the behavior is classified as "will not fix" so we need to
-	 * start nudging drivers away from using that idiom.
-	 */
-	if ((irqflags & (IRQF_SHARED|IRQF_DISABLED)) ==
-					(IRQF_SHARED|IRQF_DISABLED)) {
-		pr_warning(
-		  "IRQ %d/%s: IRQF_DISABLED is not guaranteed on shared IRQs\n",
-			irq, devname);
-	}
-
-#ifdef CONFIG_LOCKDEP
-	/*
-	 * Lockdep wants atomic interrupt handlers:
-	 */
-	irqflags |= IRQF_DISABLED;
-#endif
 	/*
 	 * Sanity-check: shared interrupts must pass in a real dev-ID,
 	 * otherwise we'll have trouble later trying to figure out

commit ae731f8d0785ccd3380f511bae888933b6562e45
Author: Marc Zyngier <maz@misterjones.org>
Date:   Mon Mar 15 22:56:33 2010 +0000

    genirq: Introduce request_any_context_irq()
    
    Now that we enjoy threaded interrupts, we're starting to see irq_chip
    implementations (wm831x, pca953x) that make use of threaded interrupts
    for the controller, and nested interrupts for the client interrupt. It
    all works very well, with one drawback:
    
    Drivers requesting an IRQ must now know whether the handler will
    run in a thread context or not, and call request_threaded_irq() or
    request_irq() accordingly.
    
    The problem is that the requesting driver sometimes doesn't know
    about the nature of the interrupt, specially when the interrupt
    controller is a discrete chip (typically a GPIO expander connected
    over I2C) that can be connected to a wide variety of otherwise perfectly
    supported hardware.
    
    This patch introduces the request_any_context_irq() function that mostly
    mimics the usual request_irq(), except that it checks whether the irq
    level is configured as nested or not, and calls the right backend.
    On success, it also returns either IRQC_IS_HARDIRQ or IRQC_IS_NESTED.
    
    [ tglx: Made return value an enum, simplified code and made the export
            of request_any_context_irq GPL ]
    
    Signed-off-by: Marc Zyngier <maz@misterjones.org>
    Cc: <joachim.eastwood@jotron.com>
    LKML-Reference: <927ea285bd0c68934ddae1a47e44a9ba@localhost>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 704e488730a5..84f32278ff1f 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1120,3 +1120,40 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 	return retval;
 }
 EXPORT_SYMBOL(request_threaded_irq);
+
+/**
+ *	request_any_context_irq - allocate an interrupt line
+ *	@irq: Interrupt line to allocate
+ *	@handler: Function to be called when the IRQ occurs.
+ *		  Threaded handler for threaded interrupts.
+ *	@flags: Interrupt type flags
+ *	@name: An ascii name for the claiming device
+ *	@dev_id: A cookie passed back to the handler function
+ *
+ *	This call allocates interrupt resources and enables the
+ *	interrupt line and IRQ handling. It selects either a
+ *	hardirq or threaded handling method depending on the
+ *	context.
+ *
+ *	On failure, it returns a negative value. On success,
+ *	it returns either IRQC_IS_HARDIRQ or IRQC_IS_NESTED.
+ */
+int request_any_context_irq(unsigned int irq, irq_handler_t handler,
+			    unsigned long flags, const char *name, void *dev_id)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+	int ret;
+
+	if (!desc)
+		return -EINVAL;
+
+	if (desc->status & IRQ_NESTED_THREAD) {
+		ret = request_threaded_irq(irq, NULL, handler,
+					   flags, name, dev_id);
+		return !ret ? IRQC_IS_NESTED : ret;
+	}
+
+	ret = request_irq(irq, handler, flags, name, dev_id);
+	return !ret ? IRQC_IS_HARDIRQ : ret;
+}
+EXPORT_SYMBOL_GPL(request_any_context_irq);

commit 753649dbc49345a73a2454c770a3f2d54d11aec6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Mar 31 13:30:19 2010 +0200

    genirq: Force MSI irq handlers to run with interrupts disabled
    
    Network folks reported that directing all MSI-X vectors of their multi
    queue NICs to a single core can cause interrupt stack overflows when
    enough interrupts fire at the same time.
    
    This is caused by the fact that we run interrupt handlers by default
    with interrupts enabled unless the driver reuqests the interrupt with
    the IRQF_DISABLED set. The NIC handlers do not set this flag, so
    simultaneous interrupts can nest unlimited and cause the stack
    overflow.
    
    The only safe counter measure is to run the interrupt handlers with
    interrupts disabled. We can't switch to this mode in general right
    now, but it is safe to do so for MSI interrupts.
    
    Force IRQF_DISABLED for MSI interrupt handlers.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Linus Torvalds <torvalds@osdl.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Cc: David Miller <davem@davemloft.net>
    Cc: Greg Kroah-Hartman <gregkh@suse.de>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: stable@kernel.org

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 398fda155f6e..704e488730a5 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -757,6 +757,16 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		if (new->flags & IRQF_ONESHOT)
 			desc->status |= IRQ_ONESHOT;
 
+		/*
+		 * Force MSI interrupts to run with interrupts
+		 * disabled. The multi vector cards can cause stack
+		 * overflows due to nested interrupts when enough of
+		 * them are directed to a core and fire at the same
+		 * time.
+		 */
+		if (desc->msi_desc)
+			new->flags |= IRQF_DISABLED;
+
 		if (!(desc->status & IRQ_NOAUTOEN)) {
 			desc->depth = 0;
 			desc->status &= ~IRQ_DISABLED;

commit cc8c3b78433222e5dbc1fdfcfdde29e1743f181a
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Mar 23 22:40:53 2010 +0100

    genirq: Protect access to irq_desc->action in can_request_irq()
    
    can_request_irq() accesses and dereferences irq_desc->action w/o
    holding irq_desc->lock. So action can be freed on another CPU before
    it's dereferenced. Unlikely, but ...
    
    Protect it with desc->lock.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 69a3d7b9414c..398fda155f6e 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -382,6 +382,7 @@ int can_request_irq(unsigned int irq, unsigned long irqflags)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 	struct irqaction *action;
+	unsigned long flags;
 
 	if (!desc)
 		return 0;
@@ -389,11 +390,14 @@ int can_request_irq(unsigned int irq, unsigned long irqflags)
 	if (desc->status & IRQ_NOREQUEST)
 		return 0;
 
+	raw_spin_lock_irqsave(&desc->lock, flags);
 	action = desc->action;
 	if (action)
 		if (irqflags & action->flags & IRQF_SHARED)
 			action = NULL;
 
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
+
 	return !action;
 }
 

commit 0b1adaa031a55e44f5dd942f234bf09d28e8a0d6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Mar 9 19:45:54 2010 +0100

    genirq: Prevent oneshot irq thread race
    
    Lars-Peter pointed out that the oneshot threaded interrupt handler
    code has the following race:
    
     CPU0                            CPU1
     hande_level_irq(irq X)
       mask_ack_irq(irq X)
       handle_IRQ_event(irq X)
         wake_up(thread_handler)
                                     thread handler(irq X) runs
                                     finalize_oneshot(irq X)
                                      does not unmask due to
                                      !(desc->status & IRQ_MASKED)
    
     return from irq
     does not unmask due to
     (desc->status & IRQ_ONESHOT)
    
    This leaves the interrupt line masked forever.
    
    The reason for this is the inconsistent handling of the IRQ_MASKED
    flag. Instead of setting it in the mask function the oneshot support
    sets the flag after waking up the irq thread.
    
    The solution for this is to set/clear the IRQ_MASKED status whenever
    we mask/unmask an interrupt line. That's the easy part, but that
    cleanup opens another race:
    
     CPU0                            CPU1
     hande_level_irq(irq)
       mask_ack_irq(irq)
       handle_IRQ_event(irq)
         wake_up(thread_handler)
                                     thread handler(irq) runs
                                     finalize_oneshot_irq(irq)
                                      unmask(irq)
         irq triggers again
         handle_level_irq(irq)
           mask_ack_irq(irq)
         return from irq due to IRQ_INPROGRESS
    
     return from irq
     does not unmask due to
     (desc->status & IRQ_ONESHOT)
    
    This requires that we synchronize finalize_oneshot_irq() with the
    primary handler. If IRQ_INPROGESS is set we wait until the primary
    handler on the other CPU has returned before unmasking the interrupt
    line again.
    
    We probably have never seen that problem because it does not happen on
    UP and on SMP the irqbalancer protects us by pinning the primary
    handler and the thread to the same CPU.
    
    Reported-by: Lars-Peter Clausen <lars@metafoo.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@kernel.org

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index eb6078ca60c7..69a3d7b9414c 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -483,8 +483,26 @@ static int irq_wait_for_interrupt(struct irqaction *action)
  */
 static void irq_finalize_oneshot(unsigned int irq, struct irq_desc *desc)
 {
+again:
 	chip_bus_lock(irq, desc);
 	raw_spin_lock_irq(&desc->lock);
+
+	/*
+	 * Implausible though it may be we need to protect us against
+	 * the following scenario:
+	 *
+	 * The thread is faster done than the hard interrupt handler
+	 * on the other CPU. If we unmask the irq line then the
+	 * interrupt can come in again and masks the line, leaves due
+	 * to IRQ_INPROGRESS and the irq line is masked forever.
+	 */
+	if (unlikely(desc->status & IRQ_INPROGRESS)) {
+		raw_spin_unlock_irq(&desc->lock);
+		chip_bus_sync_unlock(irq, desc);
+		cpu_relax();
+		goto again;
+	}
+
 	if (!(desc->status & IRQ_DISABLED) && (desc->status & IRQ_MASKED)) {
 		desc->status &= ~IRQ_MASKED;
 		desc->chip->unmask(irq);

commit 239007b8440abff689632f50cdf0f2b9e895b534
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Nov 17 16:46:45 2009 +0100

    genirq: Convert irq_desc.lock to raw_spinlock
    
    Convert locks which cannot be sleeping locks in preempt-rt to
    raw_spinlocks.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Acked-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 7305b297d1eb..eb6078ca60c7 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -46,9 +46,9 @@ void synchronize_irq(unsigned int irq)
 			cpu_relax();
 
 		/* Ok, that indicated we're done: double-check carefully. */
-		spin_lock_irqsave(&desc->lock, flags);
+		raw_spin_lock_irqsave(&desc->lock, flags);
 		status = desc->status;
-		spin_unlock_irqrestore(&desc->lock, flags);
+		raw_spin_unlock_irqrestore(&desc->lock, flags);
 
 		/* Oops, that failed? */
 	} while (status & IRQ_INPROGRESS);
@@ -114,7 +114,7 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *cpumask)
 	if (!desc->chip->set_affinity)
 		return -EINVAL;
 
-	spin_lock_irqsave(&desc->lock, flags);
+	raw_spin_lock_irqsave(&desc->lock, flags);
 
 #ifdef CONFIG_GENERIC_PENDING_IRQ
 	if (desc->status & IRQ_MOVE_PCNTXT) {
@@ -134,7 +134,7 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *cpumask)
 	}
 #endif
 	desc->status |= IRQ_AFFINITY_SET;
-	spin_unlock_irqrestore(&desc->lock, flags);
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	return 0;
 }
 
@@ -181,11 +181,11 @@ int irq_select_affinity_usr(unsigned int irq)
 	unsigned long flags;
 	int ret;
 
-	spin_lock_irqsave(&desc->lock, flags);
+	raw_spin_lock_irqsave(&desc->lock, flags);
 	ret = setup_affinity(irq, desc);
 	if (!ret)
 		irq_set_thread_affinity(desc);
-	spin_unlock_irqrestore(&desc->lock, flags);
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
 
 	return ret;
 }
@@ -231,9 +231,9 @@ void disable_irq_nosync(unsigned int irq)
 		return;
 
 	chip_bus_lock(irq, desc);
-	spin_lock_irqsave(&desc->lock, flags);
+	raw_spin_lock_irqsave(&desc->lock, flags);
 	__disable_irq(desc, irq, false);
-	spin_unlock_irqrestore(&desc->lock, flags);
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	chip_bus_sync_unlock(irq, desc);
 }
 EXPORT_SYMBOL(disable_irq_nosync);
@@ -308,9 +308,9 @@ void enable_irq(unsigned int irq)
 		return;
 
 	chip_bus_lock(irq, desc);
-	spin_lock_irqsave(&desc->lock, flags);
+	raw_spin_lock_irqsave(&desc->lock, flags);
 	__enable_irq(desc, irq, false);
-	spin_unlock_irqrestore(&desc->lock, flags);
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	chip_bus_sync_unlock(irq, desc);
 }
 EXPORT_SYMBOL(enable_irq);
@@ -347,7 +347,7 @@ int set_irq_wake(unsigned int irq, unsigned int on)
 	/* wakeup-capable irqs can be shared between drivers that
 	 * don't need to have the same sleep mode behaviors.
 	 */
-	spin_lock_irqsave(&desc->lock, flags);
+	raw_spin_lock_irqsave(&desc->lock, flags);
 	if (on) {
 		if (desc->wake_depth++ == 0) {
 			ret = set_irq_wake_real(irq, on);
@@ -368,7 +368,7 @@ int set_irq_wake(unsigned int irq, unsigned int on)
 		}
 	}
 
-	spin_unlock_irqrestore(&desc->lock, flags);
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	return ret;
 }
 EXPORT_SYMBOL(set_irq_wake);
@@ -484,12 +484,12 @@ static int irq_wait_for_interrupt(struct irqaction *action)
 static void irq_finalize_oneshot(unsigned int irq, struct irq_desc *desc)
 {
 	chip_bus_lock(irq, desc);
-	spin_lock_irq(&desc->lock);
+	raw_spin_lock_irq(&desc->lock);
 	if (!(desc->status & IRQ_DISABLED) && (desc->status & IRQ_MASKED)) {
 		desc->status &= ~IRQ_MASKED;
 		desc->chip->unmask(irq);
 	}
-	spin_unlock_irq(&desc->lock);
+	raw_spin_unlock_irq(&desc->lock);
 	chip_bus_sync_unlock(irq, desc);
 }
 
@@ -514,9 +514,9 @@ irq_thread_check_affinity(struct irq_desc *desc, struct irqaction *action)
 		return;
 	}
 
-	spin_lock_irq(&desc->lock);
+	raw_spin_lock_irq(&desc->lock);
 	cpumask_copy(mask, desc->affinity);
-	spin_unlock_irq(&desc->lock);
+	raw_spin_unlock_irq(&desc->lock);
 
 	set_cpus_allowed_ptr(current, mask);
 	free_cpumask_var(mask);
@@ -545,7 +545,7 @@ static int irq_thread(void *data)
 
 		atomic_inc(&desc->threads_active);
 
-		spin_lock_irq(&desc->lock);
+		raw_spin_lock_irq(&desc->lock);
 		if (unlikely(desc->status & IRQ_DISABLED)) {
 			/*
 			 * CHECKME: We might need a dedicated
@@ -555,9 +555,9 @@ static int irq_thread(void *data)
 			 * retriggers the interrupt itself --- tglx
 			 */
 			desc->status |= IRQ_PENDING;
-			spin_unlock_irq(&desc->lock);
+			raw_spin_unlock_irq(&desc->lock);
 		} else {
-			spin_unlock_irq(&desc->lock);
+			raw_spin_unlock_irq(&desc->lock);
 
 			action->thread_fn(action->irq, action->dev_id);
 
@@ -679,7 +679,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	/*
 	 * The following block of code has to be executed atomically
 	 */
-	spin_lock_irqsave(&desc->lock, flags);
+	raw_spin_lock_irqsave(&desc->lock, flags);
 	old_ptr = &desc->action;
 	old = *old_ptr;
 	if (old) {
@@ -775,7 +775,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		__enable_irq(desc, irq, false);
 	}
 
-	spin_unlock_irqrestore(&desc->lock, flags);
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
 
 	/*
 	 * Strictly no need to wake it up, but hung_task complains
@@ -802,7 +802,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	ret = -EBUSY;
 
 out_thread:
-	spin_unlock_irqrestore(&desc->lock, flags);
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	if (new->thread) {
 		struct task_struct *t = new->thread;
 
@@ -844,7 +844,7 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 	if (!desc)
 		return NULL;
 
-	spin_lock_irqsave(&desc->lock, flags);
+	raw_spin_lock_irqsave(&desc->lock, flags);
 
 	/*
 	 * There can be multiple actions per IRQ descriptor, find the right
@@ -856,7 +856,7 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 
 		if (!action) {
 			WARN(1, "Trying to free already-free IRQ %d\n", irq);
-			spin_unlock_irqrestore(&desc->lock, flags);
+			raw_spin_unlock_irqrestore(&desc->lock, flags);
 
 			return NULL;
 		}
@@ -884,7 +884,7 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 			desc->chip->disable(irq);
 	}
 
-	spin_unlock_irqrestore(&desc->lock, flags);
+	raw_spin_unlock_irqrestore(&desc->lock, flags);
 
 	unregister_handler_proc(irq, action);
 

commit 2b876f95d03e226394b5d360c86127cbefaf614b
Merge: fbf07eac7bf2 c95b4502ad7f 6ce51c431019
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 8 19:30:19 2009 -0800

    Merge branches 'timers-for-linus-ntp' and 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'timers-for-linus-ntp' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      ntp: Provide compability defines (You say MOD_NANO, I say ADJ_NANO)
    
    * 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      genirq: do not execute DEBUG_SHIRQ when irq setup failed

commit d90a7e86401ffea2163a4337f3a47f3909c4e255
Merge: 12a499612e1f 4dbc9ca219b0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Sep 11 13:21:31 2009 -0700

    Merge branch 'irq-threaded-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'irq-threaded-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      genirq: Do not mask oneshot edge type interrupts
      genirq: Support nested threaded irq handling
      genirq: Add buslock support
      genirq: Add oneshot support

commit 69ab849439b506cd8dd2879527fdb64d95dd5211
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Aug 17 14:07:16 2009 +0200

    genirq: Wake up irq thread after action has been installed
    
    The wake_up_process() of the new irq thread in __setup_irq() is too
    early as the irqaction is not yet fully initialized especially
    action->irq is not yet set. The interrupt thread might dereference the
    wrong irq descriptor.
    
    Move the wakeup after the action is installed and action->irq has been
    set.
    
    Reported-by: Michael Buesch <mb@bu3sch.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Michael Buesch <mb@bu3sch.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index d222515a5a06..0ec9ed831737 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -607,7 +607,6 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		 */
 		get_task_struct(t);
 		new->thread = t;
-		wake_up_process(t);
 	}
 
 	/*
@@ -690,6 +689,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 				(int)(new->flags & IRQF_TRIGGER_MASK));
 	}
 
+	new->irq = irq;
 	*old_ptr = new;
 
 	/* Reset broken irq detection when installing new handler */
@@ -707,7 +707,13 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 	spin_unlock_irqrestore(&desc->lock, flags);
 
-	new->irq = irq;
+	/*
+	 * Strictly no need to wake it up, but hung_task complains
+	 * when no hard interrupt wakes the thread up.
+	 */
+	if (new->thread)
+		wake_up_process(new->thread);
+
 	register_irq_proc(irq, desc);
 	new->dir = NULL;
 	register_handler_proc(irq, new);

commit 399b5da29b9f851eb7b96e2882097127f003e87c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Aug 13 13:21:38 2009 +0200

    genirq: Support nested threaded irq handling
    
    Interrupt chips which are behind a slow bus (i2c, spi ...) and
    demultiplex other interrupt sources need to run their interrupt
    handler in a thread.
    
    The demultiplexed interrupt handlers need to run in thread context as
    well and need to finish before the demux handler thread can reenable
    the interrupt line. So the easiest way is to run the sub device
    handlers in the context of the demultiplexing handler thread.
    
    To avoid that a separate thread is created for the subdevices the
    function set_nested_irq_thread() is provided which sets the
    IRQ_NESTED_THREAD flag in the interrupt descriptor.
    
    A driver which calls request_threaded_irq() must not be aware of the
    fact that the threaded handler is called in the context of the
    demultiplexing handler thread. The setup code checks the
    IRQ_NESTED_THREAD flag which was set from the irq chip setup code and
    does not setup a separate thread for the interrupt. The primary
    function which is provided by the device driver is replaced by an
    internal dummy function which warns when it is called.
    
    For the demultiplexing handler a helper function handle_nested_irq()
    is provided which calls the demux interrupt thread function in the
    context of the caller and does the proper interrupt accounting and
    takes the interrupt disabled status of the demultiplexed subdevice
    into account.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Mark Brown <broonie@opensource.wolfsonmicro.com>
    Cc: Dmitry Torokhov <dmitry.torokhov@gmail.com>
    Cc: Trilok Soni <soni.trilok@gmail.com>
    Cc: Pavel Machek <pavel@ucw.cz>
    Cc: Brian Swetland <swetland@google.com>
    Cc: Joonyoung Shim <jy0922.shim@samsung.com>
    Cc: m.szyprowski@samsung.com
    Cc: t.fujak@samsung.com
    Cc: kyungmin.park@samsung.com,
    Cc: David Brownell <david-b@pacbell.net>
    Cc: Daniel Ribeiro <drwyrm@gmail.com>
    Cc: arve@android.com
    Cc: Barry Song <21cnbao@gmail.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 0a3fd5b524c9..e485cea04bf1 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -451,6 +451,16 @@ static irqreturn_t irq_default_primary_handler(int irq, void *dev_id)
 	return IRQ_WAKE_THREAD;
 }
 
+/*
+ * Primary handler for nested threaded interrupts. Should never be
+ * called.
+ */
+static irqreturn_t irq_nested_primary_handler(int irq, void *dev_id)
+{
+	WARN(1, "Primary handler called for nested irq %d\n", irq);
+	return IRQ_NONE;
+}
+
 static int irq_wait_for_interrupt(struct irqaction *action)
 {
 	while (!kthread_should_stop()) {
@@ -600,7 +610,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	struct irqaction *old, **old_ptr;
 	const char *old_name = NULL;
 	unsigned long flags;
-	int shared = 0;
+	int nested, shared = 0;
 	int ret;
 
 	if (!desc)
@@ -630,9 +640,27 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		return -EINVAL;
 
 	/*
-	 * Threaded handler ?
+	 * Check whether the interrupt nests into another interrupt
+	 * thread.
+	 */
+	nested = desc->status & IRQ_NESTED_THREAD;
+	if (nested) {
+		if (!new->thread_fn)
+			return -EINVAL;
+		/*
+		 * Replace the primary handler which was provided from
+		 * the driver for non nested interrupt handling by the
+		 * dummy function which warns when called.
+		 */
+		new->handler = irq_nested_primary_handler;
+	}
+
+	/*
+	 * Create a handler thread when a thread function is supplied
+	 * and the interrupt does not nest into another interrupt
+	 * thread.
 	 */
-	if (new->thread_fn) {
+	if (new->thread_fn && !nested) {
 		struct task_struct *t;
 
 		t = kthread_create(irq_thread, new, "irq/%d-%s", irq,

commit 70aedd24d20e75198f5a0b11750faabbb56924e2
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Aug 13 12:17:48 2009 +0200

    genirq: Add buslock support
    
    Some interrupt chips are connected to a "slow" bus (i2c, spi ...). The
    bus access needs to sleep and therefor cannot be called in atomic
    contexts.
    
    Some of the generic interrupt management functions like disable_irq(),
    enable_irq() ... call interrupt chip functions with the irq_desc->lock
    held and interrupts disabled. This does not work for such devices.
    
    Provide a separate synchronization mechanism for such interrupt
    chips. The irq_chip structure is extended by two optional functions
    (bus_lock and bus_sync_and_unlock).
    
    The idea is to serialize the bus access for those operations in the
    core code so that drivers which are behind that bus operated interrupt
    controller do not have to worry about it and just can use the normal
    interfaces. To achieve this we add two function pointers to the
    irq_chip: bus_lock and bus_sync_unlock.
    
    bus_lock() is called to serialize access to the interrupt controller
    bus.
    
    Now the core code can issue chip->mask/unmask ... commands without
    changing the fast path code at all. The chip implementation merily
    stores that information in a chip private data structure and
    returns. No bus interaction as these functions are called from atomic
    context.
    
    After that bus_sync_unlock() is called outside the atomic context. Now
    the chip implementation issues the bus commands, waits for completion
    and unlocks the interrupt controller bus.
    
    The irq_chip implementation as pseudo code:
    
    struct irq_chip_data {
           struct mutex   mutex;
           unsigned int   irq_offset;
           unsigned long  mask;
           unsigned long  mask_status;
    }
    
    static void bus_lock(unsigned int irq)
    {
            struct irq_chip_data *data = get_irq_desc_chip_data(irq);
    
            mutex_lock(&data->mutex);
    }
    
    static void mask(unsigned int irq)
    {
            struct irq_chip_data *data = get_irq_desc_chip_data(irq);
    
            irq -= data->irq_offset;
            data->mask |= (1 << irq);
    }
    
    static void unmask(unsigned int irq)
    {
            struct irq_chip_data *data = get_irq_desc_chip_data(irq);
    
            irq -= data->irq_offset;
            data->mask &= ~(1 << irq);
    }
    
    static void bus_sync_unlock(unsigned int irq)
    {
            struct irq_chip_data *data = get_irq_desc_chip_data(irq);
    
            if (data->mask != data->mask_status) {
                    do_bus_magic_to_set_mask(data->mask);
                    data->mask_status = data->mask;
            }
            mutex_unlock(&data->mutex);
    }
    
    The device drivers can use request_threaded_irq, free_irq, disable_irq
    and enable_irq as usual with the only restriction that the calls need
    to come from non atomic context.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Mark Brown <broonie@opensource.wolfsonmicro.com>
    Cc: Dmitry Torokhov <dmitry.torokhov@gmail.com>
    Cc: Trilok Soni <soni.trilok@gmail.com>
    Cc: Pavel Machek <pavel@ucw.cz>
    Cc: Brian Swetland <swetland@google.com>
    Cc: Joonyoung Shim <jy0922.shim@samsung.com>
    Cc: m.szyprowski@samsung.com
    Cc: t.fujak@samsung.com
    Cc: kyungmin.park@samsung.com,
    Cc: David Brownell <david-b@pacbell.net>
    Cc: Daniel Ribeiro <drwyrm@gmail.com>
    Cc: arve@android.com
    Cc: Barry Song <21cnbao@gmail.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index d7f7b5fd2476..0a3fd5b524c9 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -230,9 +230,11 @@ void disable_irq_nosync(unsigned int irq)
 	if (!desc)
 		return;
 
+	chip_bus_lock(irq, desc);
 	spin_lock_irqsave(&desc->lock, flags);
 	__disable_irq(desc, irq, false);
 	spin_unlock_irqrestore(&desc->lock, flags);
+	chip_bus_sync_unlock(irq, desc);
 }
 EXPORT_SYMBOL(disable_irq_nosync);
 
@@ -294,7 +296,8 @@ void __enable_irq(struct irq_desc *desc, unsigned int irq, bool resume)
  *	matches the last disable, processing of interrupts on this
  *	IRQ line is re-enabled.
  *
- *	This function may be called from IRQ context.
+ *	This function may be called from IRQ context only when
+ *	desc->chip->bus_lock and desc->chip->bus_sync_unlock are NULL !
  */
 void enable_irq(unsigned int irq)
 {
@@ -304,9 +307,11 @@ void enable_irq(unsigned int irq)
 	if (!desc)
 		return;
 
+	chip_bus_lock(irq, desc);
 	spin_lock_irqsave(&desc->lock, flags);
 	__enable_irq(desc, irq, false);
 	spin_unlock_irqrestore(&desc->lock, flags);
+	chip_bus_sync_unlock(irq, desc);
 }
 EXPORT_SYMBOL(enable_irq);
 
@@ -468,12 +473,14 @@ static int irq_wait_for_interrupt(struct irqaction *action)
  */
 static void irq_finalize_oneshot(unsigned int irq, struct irq_desc *desc)
 {
+	chip_bus_lock(irq, desc);
 	spin_lock_irq(&desc->lock);
 	if (!(desc->status & IRQ_DISABLED) && (desc->status & IRQ_MASKED)) {
 		desc->status &= ~IRQ_MASKED;
 		desc->chip->unmask(irq);
 	}
 	spin_unlock_irq(&desc->lock);
+	chip_bus_sync_unlock(irq, desc);
 }
 
 #ifdef CONFIG_SMP
@@ -904,7 +911,14 @@ EXPORT_SYMBOL_GPL(remove_irq);
  */
 void free_irq(unsigned int irq, void *dev_id)
 {
+	struct irq_desc *desc = irq_to_desc(irq);
+
+	if (!desc)
+		return;
+
+	chip_bus_lock(irq, desc);
 	kfree(__free_irq(irq, dev_id));
+	chip_bus_sync_unlock(irq, desc);
 }
 EXPORT_SYMBOL(free_irq);
 
@@ -1011,7 +1025,10 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 	action->name = devname;
 	action->dev_id = dev_id;
 
+	chip_bus_lock(irq, desc);
 	retval = __setup_irq(irq, desc, action);
+	chip_bus_sync_unlock(irq, desc);
+
 	if (retval)
 		kfree(action);
 

commit b25c340c195447afb1860da580fe2a85a6b652c5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Aug 13 12:17:22 2009 +0200

    genirq: Add oneshot support
    
    For threaded interrupt handlers we expect the hard interrupt handler
    part to mask the interrupt on the originating device. The interrupt
    line itself is reenabled after the hard interrupt handler has
    executed.
    
    This requires access to the originating device from hard interrupt
    context which is not always possible. There are devices which can only
    be accessed via a bus (i2c, spi, ...). The bus access requires thread
    context. For such devices we need to keep the interrupt line masked
    until the threaded handler has executed.
    
    Add a new flag IRQF_ONESHOT which allows drivers to request that the
    interrupt is not unmasked after the hard interrupt context handler has
    been executed and the thread has been woken. The interrupt line is
    unmasked after the thread handler function has been executed.
    
    Note that for now IRQF_ONESHOT cannot be used with IRQF_SHARED to
    avoid complex accounting mechanisms.
    
    For oneshot interrupts the primary handler simply returns
    IRQ_WAKE_THREAD and does nothing else. A generic implementation
    irq_default_primary_handler() is provided to avoid useless copies all
    over the place. It is automatically installed when
    request_threaded_irq() is called with handler=NULL and
    thread_fn!=NULL.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Mark Brown <broonie@opensource.wolfsonmicro.com>
    Cc: Dmitry Torokhov <dmitry.torokhov@gmail.com>
    Cc: Trilok Soni <soni.trilok@gmail.com>
    Cc: Pavel Machek <pavel@ucw.cz>
    Cc: Brian Swetland <swetland@google.com>
    Cc: Joonyoung Shim <jy0922.shim@samsung.com>
    Cc: m.szyprowski@samsung.com
    Cc: t.fujak@samsung.com
    Cc: kyungmin.park@samsung.com,
    Cc: David Brownell <david-b@pacbell.net>
    Cc: Daniel Ribeiro <drwyrm@gmail.com>
    Cc: arve@android.com
    Cc: Barry Song <21cnbao@gmail.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index d222515a5a06..d7f7b5fd2476 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -436,6 +436,16 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 	return ret;
 }
 
+/*
+ * Default primary interrupt handler for threaded interrupts. Is
+ * assigned as primary handler when request_threaded_irq is called
+ * with handler == NULL. Useful for oneshot interrupts.
+ */
+static irqreturn_t irq_default_primary_handler(int irq, void *dev_id)
+{
+	return IRQ_WAKE_THREAD;
+}
+
 static int irq_wait_for_interrupt(struct irqaction *action)
 {
 	while (!kthread_should_stop()) {
@@ -451,6 +461,21 @@ static int irq_wait_for_interrupt(struct irqaction *action)
 	return -1;
 }
 
+/*
+ * Oneshot interrupts keep the irq line masked until the threaded
+ * handler finished. unmask if the interrupt has not been disabled and
+ * is marked MASKED.
+ */
+static void irq_finalize_oneshot(unsigned int irq, struct irq_desc *desc)
+{
+	spin_lock_irq(&desc->lock);
+	if (!(desc->status & IRQ_DISABLED) && (desc->status & IRQ_MASKED)) {
+		desc->status &= ~IRQ_MASKED;
+		desc->chip->unmask(irq);
+	}
+	spin_unlock_irq(&desc->lock);
+}
+
 #ifdef CONFIG_SMP
 /*
  * Check whether we need to change the affinity of the interrupt thread.
@@ -492,7 +517,7 @@ static int irq_thread(void *data)
 	struct sched_param param = { .sched_priority = MAX_USER_RT_PRIO/2, };
 	struct irqaction *action = data;
 	struct irq_desc *desc = irq_to_desc(action->irq);
-	int wake;
+	int wake, oneshot = desc->status & IRQ_ONESHOT;
 
 	sched_setscheduler(current, SCHED_FIFO, &param);
 	current->irqaction = action;
@@ -518,6 +543,9 @@ static int irq_thread(void *data)
 			spin_unlock_irq(&desc->lock);
 
 			action->thread_fn(action->irq, action->dev_id);
+
+			if (oneshot)
+				irq_finalize_oneshot(action->irq, desc);
 		}
 
 		wake = atomic_dec_and_test(&desc->threads_active);
@@ -590,6 +618,10 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		rand_initialize_irq(irq);
 	}
 
+	/* Oneshot interrupts are not allowed with shared */
+	if ((new->flags & IRQF_ONESHOT) && (new->flags & IRQF_SHARED))
+		return -EINVAL;
+
 	/*
 	 * Threaded handler ?
 	 */
@@ -663,9 +695,12 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 			desc->status |= IRQ_PER_CPU;
 #endif
 
-		desc->status &= ~(IRQ_AUTODETECT | IRQ_WAITING |
+		desc->status &= ~(IRQ_AUTODETECT | IRQ_WAITING | IRQ_ONESHOT |
 				  IRQ_INPROGRESS | IRQ_SPURIOUS_DISABLED);
 
+		if (new->flags & IRQF_ONESHOT)
+			desc->status |= IRQ_ONESHOT;
+
 		if (!(desc->status & IRQ_NOAUTOEN)) {
 			desc->depth = 0;
 			desc->status &= ~IRQ_DISABLED;
@@ -878,6 +913,8 @@ EXPORT_SYMBOL(free_irq);
  *	@irq: Interrupt line to allocate
  *	@handler: Function to be called when the IRQ occurs.
  *		  Primary handler for threaded interrupts
+ *		  If NULL and thread_fn != NULL the default
+ *		  primary handler is installed
  *	@thread_fn: Function called from the irq handler thread
  *		    If NULL, no irq thread is created
  *	@irqflags: Interrupt type flags
@@ -957,8 +994,12 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 
 	if (desc->status & IRQ_NOREQUEST)
 		return -EINVAL;
-	if (!handler)
-		return -EINVAL;
+
+	if (!handler) {
+		if (!thread_fn)
+			return -EINVAL;
+		handler = irq_default_primary_handler;
+	}
 
 	action = kzalloc(sizeof(struct irqaction), GFP_KERNEL);
 	if (!action)

commit 2d860ad76f4ee4d2eba0fe3797c8d7cdce432cc0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Aug 13 13:05:10 2009 -0700

    genirq: prevent wakeup of freed irq thread
    
    free_irq() can remove an irqaction while the corresponding interrupt
    is in progress, but free_irq() sets action->thread to NULL
    unconditionally, which might lead to a NULL pointer dereference in
    handle_IRQ_event() when the hard interrupt context tries to wake up
    the handler thread.
    
    Prevent this by moving the thread stop after synchronize_irq(). No
    need to set action->thread to NULL either as action is going to be
    freed anyway.
    
    This fixes a boot crash reported against preempt-rt which uses the
    mainline irq threads code to implement full irq threading.
    
    [ tglx: removed local irqthread variable ]
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 61c679db4687..d222515a5a06 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -761,7 +761,6 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 	struct irqaction *action, **action_ptr;
-	struct task_struct *irqthread;
 	unsigned long flags;
 
 	WARN(in_interrupt(), "Trying to free IRQ %d from IRQ context!\n", irq);
@@ -809,9 +808,6 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 			desc->chip->disable(irq);
 	}
 
-	irqthread = action->thread;
-	action->thread = NULL;
-
 	spin_unlock_irqrestore(&desc->lock, flags);
 
 	unregister_handler_proc(irq, action);
@@ -819,12 +815,6 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 	/* Make sure it's not being used on another CPU: */
 	synchronize_irq(irq);
 
-	if (irqthread) {
-		if (!test_bit(IRQTF_DIED, &action->thread_flags))
-			kthread_stop(irqthread);
-		put_task_struct(irqthread);
-	}
-
 #ifdef CONFIG_DEBUG_SHIRQ
 	/*
 	 * It's a shared IRQ -- the driver ought to be prepared for an IRQ
@@ -840,6 +830,13 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 		local_irq_restore(flags);
 	}
 #endif
+
+	if (action->thread) {
+		if (!test_bit(IRQTF_DIED, &action->thread_flags))
+			kthread_stop(action->thread);
+		put_task_struct(action->thread);
+	}
+
 	return action;
 }
 

commit 61f3826133dc07142935fb5712fc738e19eb5575
Author: Bruno Premont <bonbons@linux-vserver.org>
Date:   Wed Jul 22 22:22:32 2009 +0200

    genirq: Fix UP compile failure caused by irq_thread_check_affinity
    
    Since genirq: Delegate irq affinity setting to the irq thread
    (591d2fb02ea80472d846c0b8507007806bdd69cc) compilation with
    CONFIG_SMP=n fails with following error:
    
    /usr/src/linux-2.6/kernel/irq/manage.c:
       In function 'irq_thread_check_affinity':
    /usr/src/linux-2.6/kernel/irq/manage.c:475:
       error: 'struct irq_desc' has no member named 'affinity'
    make[4]: *** [kernel/irq/manage.o] Error 1
    
    That commit adds a new function irq_thread_check_affinity() which
    uses struct irq_desc.affinity which is only available for CONFIG_SMP=y.
    Move that function under #ifdef CONFIG_SMP.
    
    [ tglx@brownpaperbag: compile and boot tested on UP and SMP ]
    
    Signed-off-by: Bruno Premont <bonbons@linux-vserver.org>
    LKML-Reference: <20090722222232.2eb3e1c4@neptune.home>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index f0de36f13a44..61c679db4687 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -451,6 +451,7 @@ static int irq_wait_for_interrupt(struct irqaction *action)
 	return -1;
 }
 
+#ifdef CONFIG_SMP
 /*
  * Check whether we need to change the affinity of the interrupt thread.
  */
@@ -478,6 +479,10 @@ irq_thread_check_affinity(struct irq_desc *desc, struct irqaction *action)
 	set_cpus_allowed_ptr(current, mask);
 	free_cpumask_var(mask);
 }
+#else
+static inline void
+irq_thread_check_affinity(struct irq_desc *desc, struct irqaction *action) { }
+#endif
 
 /*
  * Interrupt handler thread

commit 591d2fb02ea80472d846c0b8507007806bdd69cc
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jul 21 11:09:39 2009 +0200

    genirq: Delegate irq affinity setting to the irq thread
    
    irq_set_thread_affinity() calls set_cpus_allowed_ptr() which might
    sleep, but irq_set_thread_affinity() is called with desc->lock held
    and can be called from hard interrupt context as well. The code has
    another bug as it does not hold a ref on the task struct as required
    by set_cpus_allowed_ptr().
    
    Just set the IRQTF_AFFINITY bit in action->thread_flags. The next time
    the thread runs it migrates itself. Solves all of the above problems
    nicely.
    
    Add kerneldoc to irq_set_thread_affinity() while at it.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    LKML-Reference: <new-submission>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 50da67672901..f0de36f13a44 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -80,14 +80,22 @@ int irq_can_set_affinity(unsigned int irq)
 	return 1;
 }
 
-void
-irq_set_thread_affinity(struct irq_desc *desc, const struct cpumask *cpumask)
+/**
+ *	irq_set_thread_affinity - Notify irq threads to adjust affinity
+ *	@desc:		irq descriptor which has affitnity changed
+ *
+ *	We just set IRQTF_AFFINITY and delegate the affinity setting
+ *	to the interrupt thread itself. We can not call
+ *	set_cpus_allowed_ptr() here as we hold desc->lock and this
+ *	code can be called from hard interrupt context.
+ */
+void irq_set_thread_affinity(struct irq_desc *desc)
 {
 	struct irqaction *action = desc->action;
 
 	while (action) {
 		if (action->thread)
-			set_cpus_allowed_ptr(action->thread, cpumask);
+			set_bit(IRQTF_AFFINITY, &action->thread_flags);
 		action = action->next;
 	}
 }
@@ -112,7 +120,7 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *cpumask)
 	if (desc->status & IRQ_MOVE_PCNTXT) {
 		if (!desc->chip->set_affinity(irq, cpumask)) {
 			cpumask_copy(desc->affinity, cpumask);
-			irq_set_thread_affinity(desc, cpumask);
+			irq_set_thread_affinity(desc);
 		}
 	}
 	else {
@@ -122,7 +130,7 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *cpumask)
 #else
 	if (!desc->chip->set_affinity(irq, cpumask)) {
 		cpumask_copy(desc->affinity, cpumask);
-		irq_set_thread_affinity(desc, cpumask);
+		irq_set_thread_affinity(desc);
 	}
 #endif
 	desc->status |= IRQ_AFFINITY_SET;
@@ -176,7 +184,7 @@ int irq_select_affinity_usr(unsigned int irq)
 	spin_lock_irqsave(&desc->lock, flags);
 	ret = setup_affinity(irq, desc);
 	if (!ret)
-		irq_set_thread_affinity(desc, desc->affinity);
+		irq_set_thread_affinity(desc);
 	spin_unlock_irqrestore(&desc->lock, flags);
 
 	return ret;
@@ -443,6 +451,34 @@ static int irq_wait_for_interrupt(struct irqaction *action)
 	return -1;
 }
 
+/*
+ * Check whether we need to change the affinity of the interrupt thread.
+ */
+static void
+irq_thread_check_affinity(struct irq_desc *desc, struct irqaction *action)
+{
+	cpumask_var_t mask;
+
+	if (!test_and_clear_bit(IRQTF_AFFINITY, &action->thread_flags))
+		return;
+
+	/*
+	 * In case we are out of memory we set IRQTF_AFFINITY again and
+	 * try again next time
+	 */
+	if (!alloc_cpumask_var(&mask, GFP_KERNEL)) {
+		set_bit(IRQTF_AFFINITY, &action->thread_flags);
+		return;
+	}
+
+	spin_lock_irq(&desc->lock);
+	cpumask_copy(mask, desc->affinity);
+	spin_unlock_irq(&desc->lock);
+
+	set_cpus_allowed_ptr(current, mask);
+	free_cpumask_var(mask);
+}
+
 /*
  * Interrupt handler thread
  */
@@ -458,6 +494,8 @@ static int irq_thread(void *data)
 
 	while (!irq_wait_for_interrupt(action)) {
 
+		irq_thread_check_affinity(desc, action);
+
 		atomic_inc(&desc->threads_active);
 
 		spin_lock_irq(&desc->lock);

commit 2453d6ff6ffc5f0d496b7b14f509a26f99bf115e
Merge: 12e24f34cb0d ab33dcff40d7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jun 20 11:30:01 2009 -0700

    Merge branch 'irq-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'irq-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      genirq, irq.h: Fix kernel-doc warnings
      genirq: fix comment to say IRQ_WAKE_THREAD

commit 39a2eddb9b62959dc55c6978b5eaeb3dd57c5ff2
Author: Steven Rostedt <rostedt@goodmis.org>
Date:   Tue May 12 14:35:54 2009 -0400

    genirq: fix comment to say IRQ_WAKE_THREAD
    
    Trying to implement a driver to use threaded irqs, I was confused when the
    return value to use that was described in the comment above
    request_threaded_irq was not defined.
    
    Turns out that the enum is IRQ_WAKE_THREAD where as the comment said
    IRQ_THREAD_WAKE.
    
    [Impact: do not confuse developers with wrong comments ]
    
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>
    LKML-Reference: <alpine.DEB.2.00.0905121431020.13338@gandalf.stny.rr.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 2734eca59243..eb47f8b80557 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -851,7 +851,7 @@ EXPORT_SYMBOL(free_irq);
  *	still called in hard interrupt context and has to check
  *	whether the interrupt originates from the device. If yes it
  *	needs to disable the interrupt on the device and return
- *	IRQ_THREAD_WAKE which will wake up the handler thread and run
+ *	IRQ_WAKE_THREAD which will wake up the handler thread and run
  *	@thread_fn. This split handler design is necessary to support
  *	shared interrupts.
  *

commit 57b150cce8e004ddd36330490a68bfb59b7271e9
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Mon Apr 27 17:59:53 2009 -0700

    irq: only update affinity if ->set_affinity() is sucessfull
    
    irq_set_affinity() and move_masked_irq() try to assign affinity
    before calling chip set_affinity(). Some archs are assigning it
    in ->set_affinity() again.
    
    We do something like:
    
     cpumask_cpy(desc->affinity, mask);
     desc->chip->set_affinity(mask);
    
    But in the failure path, affinity should not be touched - otherwise
    we'll end up with a different affinity mask despite the failure to
    migrate the IRQ.
    
    So try to update the afffinity only if set_affinity returns with 0.
    Also call irq_set_thread_affinity accordingly.
    
    v2: update after "irq, x86: Remove IRQ_DISABLED check in process context IRQ move"
    v3: according to Ingo, change set_affinity() in irq_chip should return int.
    v4: update comments by removing moving irq_desc code.
    
    [ Impact: fix /proc/irq/*/smp_affinity setting corner case bug ]
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    LKML-Reference: <49F65509.60307@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 2734eca59243..aaf5c9d05770 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -80,7 +80,7 @@ int irq_can_set_affinity(unsigned int irq)
 	return 1;
 }
 
-static void
+void
 irq_set_thread_affinity(struct irq_desc *desc, const struct cpumask *cpumask)
 {
 	struct irqaction *action = desc->action;
@@ -109,17 +109,22 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *cpumask)
 	spin_lock_irqsave(&desc->lock, flags);
 
 #ifdef CONFIG_GENERIC_PENDING_IRQ
-	if (desc->status & IRQ_MOVE_PCNTXT)
-		desc->chip->set_affinity(irq, cpumask);
+	if (desc->status & IRQ_MOVE_PCNTXT) {
+		if (!desc->chip->set_affinity(irq, cpumask)) {
+			cpumask_copy(desc->affinity, cpumask);
+			irq_set_thread_affinity(desc, cpumask);
+		}
+	}
 	else {
 		desc->status |= IRQ_MOVE_PENDING;
 		cpumask_copy(desc->pending_mask, cpumask);
 	}
 #else
-	cpumask_copy(desc->affinity, cpumask);
-	desc->chip->set_affinity(irq, cpumask);
+	if (!desc->chip->set_affinity(irq, cpumask)) {
+		cpumask_copy(desc->affinity, cpumask);
+		irq_set_thread_affinity(desc, cpumask);
+	}
 #endif
-	irq_set_thread_affinity(desc, cpumask);
 	desc->status |= IRQ_AFFINITY_SET;
 	spin_unlock_irqrestore(&desc->lock, flags);
 	return 0;

commit 6ce51c431019310ca03371355a4366c4649fa349
Author: Luis Henriques <henrix@sapo.pt>
Date:   Wed Apr 1 18:06:35 2009 +0100

    genirq: do not execute DEBUG_SHIRQ when irq setup failed
    
    When requesting an IRQ, the DEBUG_SHIRQ code executes a fake IRQ just to make
    sure the driver is ready to receive an IRQ immediately.  The problem was that
    this fake IRQ was being executed even if interrupt line failed to be allocated
    by __setup_irq.
    
    Signed-off-by: Luis Henriques <henrix@sapo.pt>
    LKML-Reference: <20090401170635.GA4392@hades.domain.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    [ fixed bug pointed out by a warning reported by Stephen Rothwell ]
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 1516ab77355c..8c68d5b95d48 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -768,7 +768,7 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 		kfree(action);
 
 #ifdef CONFIG_DEBUG_SHIRQ
-	if (irqflags & IRQF_SHARED) {
+	if (!retval && (irqflags & IRQF_SHARED)) {
 		/*
 		 * It's a shared IRQ -- the driver ought to be prepared for it
 		 * to happen immediately, so let's make sure....

commit 6ec3cfeca04622e3d80c9270191cd7f5f88214af
Author: Pallipadi, Venkatesh <venkatesh.pallipadi@intel.com>
Date:   Mon Apr 13 15:20:58 2009 -0700

    x86, irq: Remove IRQ_DISABLED check in process context IRQ move
    
    As discussed in the thread here:
    
      http://marc.info/?l=linux-kernel&m=123964468521142&w=2
    
    Eric W. Biederman observed:
    
    > It looks like some additional bugs have slipped in since last I looked.
    >
    > set_irq_affinity does this:
    > ifdef CONFIG_GENERIC_PENDING_IRQ
    >        if (desc->status & IRQ_MOVE_PCNTXT || desc->status & IRQ_DISABLED) {
    >                cpumask_copy(desc->affinity, cpumask);
    >                desc->chip->set_affinity(irq, cpumask);
    >        } else {
    >                desc->status |= IRQ_MOVE_PENDING;
    >                cpumask_copy(desc->pending_mask, cpumask);
    >        }
    > #else
    >
    > That IRQ_DISABLED case is a software state and as such it has nothing to
    > do with how safe it is to move an irq in process context.
    
    [...]
    
    >
    > The only reason we migrate MSIs in interrupt context today is that there
    > wasn't infrastructure for support migration both in interrupt context
    > and outside of it.
    
    Yes. The idea here was to force the MSI migration to happen in process
    context. One of the patches in the series did
    
            disable_irq(dev->irq);
            irq_set_affinity(dev->irq, cpumask_of(dev->cpu));
            enable_irq(dev->irq);
    
    with the above patch adding irq/manage code check for interrupt disabled
    and moving the interrupt in process context.
    
    IIRC, there was no IRQ_MOVE_PCNTXT when we were developing this HPET
    code and we ended up having this ugly hack. IRQ_MOVE_PCNTXT was there
    when we eventually submitted the patch upstream. But, looks like I did a
    blind rebasing instead of using IRQ_MOVE_PCNTXT in hpet MSI code.
    
    Below patch fixes this. i.e., revert commit 932775a4ab622e3c99bd59f14cc
    and add PCNTXT to HPET MSI setup. Also removes copying of desc->affinity
    in generic code as set_affinity routines are doing it internally.
    
    Reported-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: "Li Shaohua" <shaohua.li@intel.com>
    Cc: Gary Hade <garyhade@us.ibm.com>
    Cc: "lcm@us.ibm.com" <lcm@us.ibm.com>
    Cc: suresh.b.siddha@intel.com
    LKML-Reference: <20090413222058.GB8211@linux-os.sc.intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 7e2e7dd4cd2f..2734eca59243 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -109,10 +109,9 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *cpumask)
 	spin_lock_irqsave(&desc->lock, flags);
 
 #ifdef CONFIG_GENERIC_PENDING_IRQ
-	if (desc->status & IRQ_MOVE_PCNTXT || desc->status & IRQ_DISABLED) {
-		cpumask_copy(desc->affinity, cpumask);
+	if (desc->status & IRQ_MOVE_PCNTXT)
 		desc->chip->set_affinity(irq, cpumask);
-	} else {
+	else {
 		desc->status |= IRQ_MOVE_PENDING;
 		cpumask_copy(desc->pending_mask, cpumask);
 	}

commit 9efe21cb82b5dbe3b0b2ae4de4eccc64ecb94e95
Merge: de18836e447c 0221c81b1b8e
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Apr 6 01:41:22 2009 +0200

    Merge branch 'linus' into irq/threaded
    
    Conflicts:
            include/linux/irq.h
            kernel/irq/handle.c

commit 0a0c5168df270a50e3518e4f12bddb31f8f5f38f
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Mon Mar 16 22:33:49 2009 +0100

    PM: Introduce functions for suspending and resuming device interrupts
    
    Introduce helper functions allowing us to prevent device drivers from
    getting any interrupts (without disabling interrupts on the CPU)
    during suspend (or hibernation) and to make them start to receive
    interrupts again during the subsequent resume.  These functions make it
    possible to keep timer interrupts enabled while the "late" suspend and
    "early" resume callbacks provided by device drivers are being
    executed.  In turn, this allows device drivers' "late" suspend and
    "early" resume callbacks to sleep, execute ACPI callbacks etc.
    
    The functions introduced here will be used to rework the handling of
    interrupts during suspend (hibernation) and resume.  Namely,
    interrupts will only be disabled on the CPU right before suspending
    sysdevs, while device drivers will be prevented from receiving
    interrupts, with the help of the new helper function, before their
    "late" suspend callbacks run (and analogously during resume).
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Acked-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 6458e99984c0..1516ab77355c 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -162,6 +162,20 @@ static inline int setup_affinity(unsigned int irq, struct irq_desc *desc)
 }
 #endif
 
+void __disable_irq(struct irq_desc *desc, unsigned int irq, bool suspend)
+{
+	if (suspend) {
+		if (!desc->action || (desc->action->flags & IRQF_TIMER))
+			return;
+		desc->status |= IRQ_SUSPENDED;
+	}
+
+	if (!desc->depth++) {
+		desc->status |= IRQ_DISABLED;
+		desc->chip->disable(irq);
+	}
+}
+
 /**
  *	disable_irq_nosync - disable an irq without waiting
  *	@irq: Interrupt to disable
@@ -182,10 +196,7 @@ void disable_irq_nosync(unsigned int irq)
 		return;
 
 	spin_lock_irqsave(&desc->lock, flags);
-	if (!desc->depth++) {
-		desc->status |= IRQ_DISABLED;
-		desc->chip->disable(irq);
-	}
+	__disable_irq(desc, irq, false);
 	spin_unlock_irqrestore(&desc->lock, flags);
 }
 EXPORT_SYMBOL(disable_irq_nosync);
@@ -215,15 +226,21 @@ void disable_irq(unsigned int irq)
 }
 EXPORT_SYMBOL(disable_irq);
 
-static void __enable_irq(struct irq_desc *desc, unsigned int irq)
+void __enable_irq(struct irq_desc *desc, unsigned int irq, bool resume)
 {
+	if (resume)
+		desc->status &= ~IRQ_SUSPENDED;
+
 	switch (desc->depth) {
 	case 0:
+ err_out:
 		WARN(1, KERN_WARNING "Unbalanced enable for IRQ %d\n", irq);
 		break;
 	case 1: {
 		unsigned int status = desc->status & ~IRQ_DISABLED;
 
+		if (desc->status & IRQ_SUSPENDED)
+			goto err_out;
 		/* Prevent probing on this irq: */
 		desc->status = status | IRQ_NOPROBE;
 		check_irq_resend(desc, irq);
@@ -253,7 +270,7 @@ void enable_irq(unsigned int irq)
 		return;
 
 	spin_lock_irqsave(&desc->lock, flags);
-	__enable_irq(desc, irq);
+	__enable_irq(desc, irq, false);
 	spin_unlock_irqrestore(&desc->lock, flags);
 }
 EXPORT_SYMBOL(enable_irq);
@@ -511,7 +528,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	 */
 	if (shared && (desc->status & IRQ_SPURIOUS_DISABLED)) {
 		desc->status &= ~IRQ_SPURIOUS_DISABLED;
-		__enable_irq(desc, irq);
+		__enable_irq(desc, irq, false);
 	}
 
 	spin_unlock_irqrestore(&desc->lock, flags);

commit 6e15cf04860074ad032e88c306bea656bbdd0f22
Merge: be0ea69674ed 60db56422043
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Mar 26 21:39:17 2009 +0100

    Merge branch 'core/percpu' into percpu-cpumask-x86-for-linus-2
    
    Conflicts:
            arch/parisc/kernel/irq.c
            arch/x86/include/asm/fixmap_64.h
            arch/x86/include/asm/setup.h
            kernel/irq/handle.c
    
    Semantic merge:
            arch/x86/include/asm/fixmap.h
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit f48fe81e5b032914183e9a17052313720c2cac56
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Mar 24 11:46:22 2009 +0100

    genirq: threaded irq handlers review fixups
    
    Delta patch to address the review comments.
    
          - Implement warning when IRQ_WAKE_THREAD is requested and no
            thread handler installed
          - coding style fixes
    
    Pointed-out-by: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index a4c1ab86cd25..a3eb7baf1e46 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -407,20 +407,17 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 	return ret;
 }
 
-static inline int irq_thread_should_run(struct irqaction *action)
-{
-	return test_and_clear_bit(IRQTF_RUNTHREAD, &action->thread_flags);
-}
-
 static int irq_wait_for_interrupt(struct irqaction *action)
 {
 	while (!kthread_should_stop()) {
 		set_current_state(TASK_INTERRUPTIBLE);
-		if (irq_thread_should_run(action)) {
+
+		if (test_and_clear_bit(IRQTF_RUNTHREAD,
+				       &action->thread_flags)) {
 			__set_current_state(TASK_RUNNING);
 			return 0;
-		} else
-			schedule();
+		}
+		schedule();
 	}
 	return -1;
 }
@@ -820,8 +817,8 @@ EXPORT_SYMBOL(free_irq);
  *	@irq: Interrupt line to allocate
  *	@handler: Function to be called when the IRQ occurs.
  *		  Primary handler for threaded interrupts
- *      @thread_fn: Function called from the irq handler thread
- *                  If NULL, no irq thread is created
+ *	@thread_fn: Function called from the irq handler thread
+ *		    If NULL, no irq thread is created
  *	@irqflags: Interrupt type flags
  *	@devname: An ascii name for the claiming device
  *	@dev_id: A cookie passed back to the handler function

commit 3aa551c9b4c40018f0e261a178e3d25478dc04a9
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Mar 23 18:28:15 2009 +0100

    genirq: add threaded interrupt handler support
    
    Add support for threaded interrupt handlers:
    
    A device driver can request that its main interrupt handler runs in a
    thread. To achive this the device driver requests the interrupt with
    request_threaded_irq() and provides additionally to the handler a
    thread function. The handler function is called in hard interrupt
    context and needs to check whether the interrupt originated from the
    device. If the interrupt originated from the device then the handler
    can either return IRQ_HANDLED or IRQ_WAKE_THREAD. IRQ_HANDLED is
    returned when no further action is required. IRQ_WAKE_THREAD causes
    the genirq code to invoke the threaded (main) handler. When
    IRQ_WAKE_THREAD is returned handler must have disabled the interrupt
    on the device level. This is mandatory for shared interrupt handlers,
    but we need to do it as well for obscure x86 hardware where disabling
    an interrupt on the IO_APIC level redirects the interrupt to the
    legacy PIC interrupt lines.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 6458e99984c0..a4c1ab86cd25 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -8,16 +8,15 @@
  */
 
 #include <linux/irq.h>
+#include <linux/kthread.h>
 #include <linux/module.h>
 #include <linux/random.h>
 #include <linux/interrupt.h>
 #include <linux/slab.h>
+#include <linux/sched.h>
 
 #include "internals.h"
 
-#if defined(CONFIG_SMP) && defined(CONFIG_GENERIC_HARDIRQS)
-cpumask_var_t irq_default_affinity;
-
 /**
  *	synchronize_irq - wait for pending IRQ handlers (on other CPUs)
  *	@irq: interrupt number to wait for
@@ -53,9 +52,18 @@ void synchronize_irq(unsigned int irq)
 
 		/* Oops, that failed? */
 	} while (status & IRQ_INPROGRESS);
+
+	/*
+	 * We made sure that no hardirq handler is running. Now verify
+	 * that no threaded handlers are active.
+	 */
+	wait_event(desc->wait_for_threads, !atomic_read(&desc->threads_active));
 }
 EXPORT_SYMBOL(synchronize_irq);
 
+#ifdef CONFIG_SMP
+cpumask_var_t irq_default_affinity;
+
 /**
  *	irq_can_set_affinity - Check if the affinity of a given irq can be set
  *	@irq:		Interrupt to check
@@ -72,6 +80,18 @@ int irq_can_set_affinity(unsigned int irq)
 	return 1;
 }
 
+static void
+irq_set_thread_affinity(struct irq_desc *desc, const struct cpumask *cpumask)
+{
+	struct irqaction *action = desc->action;
+
+	while (action) {
+		if (action->thread)
+			set_cpus_allowed_ptr(action->thread, cpumask);
+		action = action->next;
+	}
+}
+
 /**
  *	irq_set_affinity - Set the irq affinity of a given irq
  *	@irq:		Interrupt to set affinity
@@ -100,6 +120,7 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *cpumask)
 	cpumask_copy(desc->affinity, cpumask);
 	desc->chip->set_affinity(irq, cpumask);
 #endif
+	irq_set_thread_affinity(desc, cpumask);
 	desc->status |= IRQ_AFFINITY_SET;
 	spin_unlock_irqrestore(&desc->lock, flags);
 	return 0;
@@ -150,6 +171,8 @@ int irq_select_affinity_usr(unsigned int irq)
 
 	spin_lock_irqsave(&desc->lock, flags);
 	ret = setup_affinity(irq, desc);
+	if (!ret)
+		irq_set_thread_affinity(desc, desc->affinity);
 	spin_unlock_irqrestore(&desc->lock, flags);
 
 	return ret;
@@ -384,6 +407,93 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 	return ret;
 }
 
+static inline int irq_thread_should_run(struct irqaction *action)
+{
+	return test_and_clear_bit(IRQTF_RUNTHREAD, &action->thread_flags);
+}
+
+static int irq_wait_for_interrupt(struct irqaction *action)
+{
+	while (!kthread_should_stop()) {
+		set_current_state(TASK_INTERRUPTIBLE);
+		if (irq_thread_should_run(action)) {
+			__set_current_state(TASK_RUNNING);
+			return 0;
+		} else
+			schedule();
+	}
+	return -1;
+}
+
+/*
+ * Interrupt handler thread
+ */
+static int irq_thread(void *data)
+{
+	struct sched_param param = { .sched_priority = MAX_USER_RT_PRIO/2, };
+	struct irqaction *action = data;
+	struct irq_desc *desc = irq_to_desc(action->irq);
+	int wake;
+
+	sched_setscheduler(current, SCHED_FIFO, &param);
+	current->irqaction = action;
+
+	while (!irq_wait_for_interrupt(action)) {
+
+		atomic_inc(&desc->threads_active);
+
+		spin_lock_irq(&desc->lock);
+		if (unlikely(desc->status & IRQ_DISABLED)) {
+			/*
+			 * CHECKME: We might need a dedicated
+			 * IRQ_THREAD_PENDING flag here, which
+			 * retriggers the thread in check_irq_resend()
+			 * but AFAICT IRQ_PENDING should be fine as it
+			 * retriggers the interrupt itself --- tglx
+			 */
+			desc->status |= IRQ_PENDING;
+			spin_unlock_irq(&desc->lock);
+		} else {
+			spin_unlock_irq(&desc->lock);
+
+			action->thread_fn(action->irq, action->dev_id);
+		}
+
+		wake = atomic_dec_and_test(&desc->threads_active);
+
+		if (wake && waitqueue_active(&desc->wait_for_threads))
+			wake_up(&desc->wait_for_threads);
+	}
+
+	/*
+	 * Clear irqaction. Otherwise exit_irq_thread() would make
+	 * fuzz about an active irq thread going into nirvana.
+	 */
+	current->irqaction = NULL;
+	return 0;
+}
+
+/*
+ * Called from do_exit()
+ */
+void exit_irq_thread(void)
+{
+	struct task_struct *tsk = current;
+
+	if (!tsk->irqaction)
+		return;
+
+	printk(KERN_ERR
+	       "exiting task \"%s\" (%d) is an active IRQ thread (irq %d)\n",
+	       tsk->comm ? tsk->comm : "", tsk->pid, tsk->irqaction->irq);
+
+	/*
+	 * Set the THREAD DIED flag to prevent further wakeups of the
+	 * soon to be gone threaded handler.
+	 */
+	set_bit(IRQTF_DIED, &tsk->irqaction->flags);
+}
+
 /*
  * Internal function to register an irqaction - typically used to
  * allocate special interrupts that are part of the architecture.
@@ -419,6 +529,26 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		rand_initialize_irq(irq);
 	}
 
+	/*
+	 * Threaded handler ?
+	 */
+	if (new->thread_fn) {
+		struct task_struct *t;
+
+		t = kthread_create(irq_thread, new, "irq/%d-%s", irq,
+				   new->name);
+		if (IS_ERR(t))
+			return PTR_ERR(t);
+		/*
+		 * We keep the reference to the task struct even if
+		 * the thread dies to avoid that the interrupt code
+		 * references an already freed task_struct.
+		 */
+		get_task_struct(t);
+		new->thread = t;
+		wake_up_process(t);
+	}
+
 	/*
 	 * The following block of code has to be executed atomically
 	 */
@@ -456,15 +586,15 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	if (!shared) {
 		irq_chip_set_defaults(desc->chip);
 
+		init_waitqueue_head(&desc->wait_for_threads);
+
 		/* Setup the type (level, edge polarity) if configured: */
 		if (new->flags & IRQF_TRIGGER_MASK) {
 			ret = __irq_set_trigger(desc, irq,
 					new->flags & IRQF_TRIGGER_MASK);
 
-			if (ret) {
-				spin_unlock_irqrestore(&desc->lock, flags);
-				return ret;
-			}
+			if (ret)
+				goto out_thread;
 		} else
 			compat_irq_chip_set_default_handler(desc);
 #if defined(CONFIG_IRQ_PER_CPU)
@@ -532,8 +662,19 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		dump_stack();
 	}
 #endif
+	ret = -EBUSY;
+
+out_thread:
 	spin_unlock_irqrestore(&desc->lock, flags);
-	return -EBUSY;
+	if (new->thread) {
+		struct task_struct *t = new->thread;
+
+		new->thread = NULL;
+		if (likely(!test_bit(IRQTF_DIED, &new->thread_flags)))
+			kthread_stop(t);
+		put_task_struct(t);
+	}
+	return ret;
 }
 
 /**
@@ -559,6 +700,7 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 	struct irqaction *action, **action_ptr;
+	struct task_struct *irqthread;
 	unsigned long flags;
 
 	WARN(in_interrupt(), "Trying to free IRQ %d from IRQ context!\n", irq);
@@ -605,6 +747,10 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 		else
 			desc->chip->disable(irq);
 	}
+
+	irqthread = action->thread;
+	action->thread = NULL;
+
 	spin_unlock_irqrestore(&desc->lock, flags);
 
 	unregister_handler_proc(irq, action);
@@ -612,6 +758,12 @@ static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 	/* Make sure it's not being used on another CPU: */
 	synchronize_irq(irq);
 
+	if (irqthread) {
+		if (!test_bit(IRQTF_DIED, &action->thread_flags))
+			kthread_stop(irqthread);
+		put_task_struct(irqthread);
+	}
+
 #ifdef CONFIG_DEBUG_SHIRQ
 	/*
 	 * It's a shared IRQ -- the driver ought to be prepared for an IRQ
@@ -664,9 +816,12 @@ void free_irq(unsigned int irq, void *dev_id)
 EXPORT_SYMBOL(free_irq);
 
 /**
- *	request_irq - allocate an interrupt line
+ *	request_threaded_irq - allocate an interrupt line
  *	@irq: Interrupt line to allocate
- *	@handler: Function to be called when the IRQ occurs
+ *	@handler: Function to be called when the IRQ occurs.
+ *		  Primary handler for threaded interrupts
+ *      @thread_fn: Function called from the irq handler thread
+ *                  If NULL, no irq thread is created
  *	@irqflags: Interrupt type flags
  *	@devname: An ascii name for the claiming device
  *	@dev_id: A cookie passed back to the handler function
@@ -678,6 +833,15 @@ EXPORT_SYMBOL(free_irq);
  *	raises, you must take care both to initialise your hardware
  *	and to set up the interrupt handler in the right order.
  *
+ *	If you want to set up a threaded irq handler for your device
+ *	then you need to supply @handler and @thread_fn. @handler ist
+ *	still called in hard interrupt context and has to check
+ *	whether the interrupt originates from the device. If yes it
+ *	needs to disable the interrupt on the device and return
+ *	IRQ_THREAD_WAKE which will wake up the handler thread and run
+ *	@thread_fn. This split handler design is necessary to support
+ *	shared interrupts.
+ *
  *	Dev_id must be globally unique. Normally the address of the
  *	device data structure is used as the cookie. Since the handler
  *	receives this value it makes sense to use it.
@@ -693,8 +857,9 @@ EXPORT_SYMBOL(free_irq);
  *	IRQF_TRIGGER_*		Specify active edge(s) or level
  *
  */
-int request_irq(unsigned int irq, irq_handler_t handler,
-		unsigned long irqflags, const char *devname, void *dev_id)
+int request_threaded_irq(unsigned int irq, irq_handler_t handler,
+			 irq_handler_t thread_fn, unsigned long irqflags,
+			 const char *devname, void *dev_id)
 {
 	struct irqaction *action;
 	struct irq_desc *desc;
@@ -742,6 +907,7 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 		return -ENOMEM;
 
 	action->handler = handler;
+	action->thread_fn = thread_fn;
 	action->flags = irqflags;
 	action->name = devname;
 	action->dev_id = dev_id;
@@ -771,4 +937,4 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 #endif
 	return retval;
 }
-EXPORT_SYMBOL(request_irq);
+EXPORT_SYMBOL(request_threaded_irq);

commit 80c5520811d3805adcb15c570ea5e2d489fa5d0b
Merge: b3e3b302cf6d 8c083f081d00
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Mar 23 14:50:03 2009 +0100

    Merge branch 'cpus4096' into irq/threaded
    
    Conflicts:
            arch/parisc/kernel/irq.c
            kernel/irq/handle.c
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit edb35028e40515beb2f94808aff8b3e71fb9f35a
Merge: 8f8573ae9f5d cb065c06b6cc 5bee17f18b59
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Mar 16 09:20:13 2009 +0100

    Merge branches 'irq/genirq' and 'linus' into irq/core

commit 4553573277906901f62f73c0432b332c53de5e2c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Feb 22 23:00:32 2009 +0100

    genirq: use kzalloc instead of explicit zero initialization
    
    Impact: simplification
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Peter Zijlstra <peterz@infradead.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 4600f877c292..8a22039a90ba 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -737,15 +737,13 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 	if (!handler)
 		return -EINVAL;
 
-	action = kmalloc(sizeof(struct irqaction), GFP_KERNEL);
+	action = kzalloc(sizeof(struct irqaction), GFP_KERNEL);
 	if (!action)
 		return -ENOMEM;
 
 	action->handler = handler;
 	action->flags = irqflags;
-	cpus_clear(action->mask);
 	action->name = devname;
-	action->next = NULL;
 	action->dev_id = dev_id;
 
 	retval = __setup_irq(irq, desc, action);

commit c8e2aeef0b8ac9fb8821b8b3734c031579d0b77a
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Mar 9 20:26:23 2009 +0100

    genirq: remove redundant if condition
    
    Impact: cleanup
    
    The code is only compiled if CONFIG_GENERIC_HARDIRQS=y so another
    check for this define in the code is redundant. Remove it.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index e28db0f656ac..4600f877c292 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -15,7 +15,7 @@
 
 #include "internals.h"
 
-#if defined(CONFIG_SMP) && defined(CONFIG_GENERIC_HARDIRQS)
+#ifdef CONFIG_SMP
 cpumask_var_t irq_default_affinity;
 
 /**

commit eb53b4e8fef10ccccb49a6dbb5e19ca84ba5a305
Author: Magnus Damm <damm@igel.co.jp>
Date:   Thu Mar 12 21:05:59 2009 +0900

    irq: export remove_irq() and setup_irq() symbols
    
    Export the setup_irq() and remove_irq() symbols.
    
    I'd like to export these functions since I have timer
    code that needs to use setup_irq() early on (too early
    for request_irq()), and the same code can also be
    compiled as a module.
    
    Signed-off-by: Magnus Damm <damm@igel.co.jp>
    LKML-Reference: <20090312120559.2926.82371.sendpatchset@rx1.opensource.se>
    [ changed to _GPL as these are special APIs deep inside the irq layer. ]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index fc16570c9b46..e28db0f656ac 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -549,6 +549,7 @@ int setup_irq(unsigned int irq, struct irqaction *act)
 
 	return __setup_irq(irq, desc, act);
 }
+EXPORT_SYMBOL_GPL(setup_irq);
 
  /*
  * Internal function to unregister an irqaction - used to free
@@ -640,6 +641,7 @@ void remove_irq(unsigned int irq, struct irqaction *act)
 {
 	__free_irq(irq, act->dev_id);
 }
+EXPORT_SYMBOL_GPL(remove_irq);
 
 /**
  *	free_irq - free an interrupt allocated with request_irq

commit cbf94f06824780183e4bba165c7c29d5c7bd9a51
Author: Magnus Damm <damm@igel.co.jp>
Date:   Thu Mar 12 21:05:51 2009 +0900

    irq: match remove_irq() args with setup_irq()
    
    Modify remove_irq() to match setup_irq().
    
    Signed-off-by: Magnus Damm <damm@igel.co.jp>
    LKML-Reference: <20090312120551.2926.43942.sendpatchset@rx1.opensource.se>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 8b069a7046e9..fc16570c9b46 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -550,15 +550,11 @@ int setup_irq(unsigned int irq, struct irqaction *act)
 	return __setup_irq(irq, desc, act);
 }
 
-/**
- *	remove_irq - free an interrupt
- *	@irq: Interrupt line to free
- *	@dev_id: Device identity to free
- *
- * Used to remove interrupts statically setup by the early boot process.
+ /*
+ * Internal function to unregister an irqaction - used to free
+ * regular and special interrupts that are part of the architecture.
  */
-
-struct irqaction *remove_irq(unsigned int irq, void *dev_id)
+static struct irqaction *__free_irq(unsigned int irq, void *dev_id)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 	struct irqaction *action, **action_ptr;
@@ -633,6 +629,18 @@ struct irqaction *remove_irq(unsigned int irq, void *dev_id)
 	return action;
 }
 
+/**
+ *	remove_irq - free an interrupt
+ *	@irq: Interrupt line to free
+ *	@act: irqaction for the interrupt
+ *
+ * Used to remove interrupts statically setup by the early boot process.
+ */
+void remove_irq(unsigned int irq, struct irqaction *act)
+{
+	__free_irq(irq, act->dev_id);
+}
+
 /**
  *	free_irq - free an interrupt allocated with request_irq
  *	@irq: Interrupt line to free
@@ -649,7 +657,7 @@ struct irqaction *remove_irq(unsigned int irq, void *dev_id)
  */
 void free_irq(unsigned int irq, void *dev_id)
 {
-	kfree(remove_irq(irq, dev_id));
+	kfree(__free_irq(irq, dev_id));
 }
 EXPORT_SYMBOL(free_irq);
 

commit f21cfb258df6dd3ea0b3e56d75c7e994edb81b35
Author: Magnus Damm <damm@igel.co.jp>
Date:   Thu Mar 12 21:05:42 2009 +0900

    irq: add remove_irq() for freeing of setup_irq() irqs
    
    Impact: add new API
    
    This patch adds a remove_irq() function for releasing
    interrupts requested with setup_irq().
    
    Without this patch we have no way of releasing such
    interrupts since free_irq() today tries to kfree()
    the irqaction passed with setup_irq().
    
    Signed-off-by: Magnus Damm <damm@igel.co.jp>
    LKML-Reference: <20090312120542.2926.56609.sendpatchset@rx1.opensource.se>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 52ee17135092..8b069a7046e9 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -551,20 +551,14 @@ int setup_irq(unsigned int irq, struct irqaction *act)
 }
 
 /**
- *	free_irq - free an interrupt
+ *	remove_irq - free an interrupt
  *	@irq: Interrupt line to free
  *	@dev_id: Device identity to free
  *
- *	Remove an interrupt handler. The handler is removed and if the
- *	interrupt line is no longer in use by any driver it is disabled.
- *	On a shared IRQ the caller must ensure the interrupt is disabled
- *	on the card it drives before calling this function. The function
- *	does not return until any executing interrupts for this IRQ
- *	have completed.
- *
- *	This function must not be called from interrupt context.
+ * Used to remove interrupts statically setup by the early boot process.
  */
-void free_irq(unsigned int irq, void *dev_id)
+
+struct irqaction *remove_irq(unsigned int irq, void *dev_id)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 	struct irqaction *action, **action_ptr;
@@ -573,7 +567,7 @@ void free_irq(unsigned int irq, void *dev_id)
 	WARN(in_interrupt(), "Trying to free IRQ %d from IRQ context!\n", irq);
 
 	if (!desc)
-		return;
+		return NULL;
 
 	spin_lock_irqsave(&desc->lock, flags);
 
@@ -589,7 +583,7 @@ void free_irq(unsigned int irq, void *dev_id)
 			WARN(1, "Trying to free already-free IRQ %d\n", irq);
 			spin_unlock_irqrestore(&desc->lock, flags);
 
-			return;
+			return NULL;
 		}
 
 		if (action->dev_id == dev_id)
@@ -636,7 +630,26 @@ void free_irq(unsigned int irq, void *dev_id)
 		local_irq_restore(flags);
 	}
 #endif
-	kfree(action);
+	return action;
+}
+
+/**
+ *	free_irq - free an interrupt allocated with request_irq
+ *	@irq: Interrupt line to free
+ *	@dev_id: Device identity to free
+ *
+ *	Remove an interrupt handler. The handler is removed and if the
+ *	interrupt line is no longer in use by any driver it is disabled.
+ *	On a shared IRQ the caller must ensure the interrupt is disabled
+ *	on the card it drives before calling this function. The function
+ *	does not return until any executing interrupts for this IRQ
+ *	have completed.
+ *
+ *	This function must not be called from interrupt context.
+ */
+void free_irq(unsigned int irq, void *dev_id)
+{
+	kfree(remove_irq(irq, dev_id));
 }
 EXPORT_SYMBOL(free_irq);
 

commit c02368a9d059322f913a58111eade87a656fefd5
Merge: f17c75453b2d 778ef1e6cbb0
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Mar 2 22:08:56 2009 +0100

    Merge branch 'linus' into irq/genirq

commit f17c75453b2d195eba0a90d9f16a3ba88c85b3b4
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Feb 17 20:43:37 2009 +0100

    irq: name 'p' variables a bit better
    
    'p' stands for pointer - make it clear in setup_irq() and free_irq()
    what kind of pointer it is.
    
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index de5a765e88ab..c589305210d7 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -399,7 +399,7 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 static int
 __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 {
-	struct irqaction *old, **p;
+	struct irqaction *old, **old_ptr;
 	const char *old_name = NULL;
 	unsigned long flags;
 	int shared = 0;
@@ -431,8 +431,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 	 * The following block of code has to be executed atomically
 	 */
 	spin_lock_irqsave(&desc->lock, flags);
-	p = &desc->action;
-	old = *p;
+	old_ptr = &desc->action;
+	old = *old_ptr;
 	if (old) {
 		/*
 		 * Can't share interrupts unless both agree to and are
@@ -455,8 +455,8 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 
 		/* add new interrupt at end of irq queue */
 		do {
-			p = &old->next;
-			old = *p;
+			old_ptr = &old->next;
+			old = *old_ptr;
 		} while (old);
 		shared = 1;
 	}
@@ -507,7 +507,7 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 				(int)(new->flags & IRQF_TRIGGER_MASK));
 	}
 
-	*p = new;
+	*old_ptr = new;
 
 	/* Reset broken irq detection when installing new handler */
 	desc->irq_count = 0;
@@ -575,7 +575,7 @@ int setup_irq(unsigned int irq, struct irqaction *act)
 void free_irq(unsigned int irq, void *dev_id)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
-	struct irqaction *action, **p;
+	struct irqaction *action, **action_ptr;
 	unsigned long flags;
 
 	WARN(in_interrupt(), "Trying to free IRQ %d from IRQ context!\n", irq);
@@ -589,9 +589,9 @@ void free_irq(unsigned int irq, void *dev_id)
 	 * There can be multiple actions per IRQ descriptor, find the right
 	 * one based on the dev_id:
 	 */
-	p = &desc->action;
+	action_ptr = &desc->action;
 	for (;;) {
-		action = *p;
+		action = *action_ptr;
 
 		if (!action) {
 			WARN(1, "Trying to free already-free IRQ %d\n", irq);
@@ -602,11 +602,11 @@ void free_irq(unsigned int irq, void *dev_id)
 
 		if (action->dev_id == dev_id)
 			break;
-		p = &action->next;
+		action_ptr = &action->next;
 	}
 
 	/* Found it - now remove it from the list of entries: */
-	*p = action->next;
+	*action_ptr = action->next;
 
 	/* Currently used only by UML, might disappear one day: */
 #ifdef CONFIG_IRQ_RELEASE_METHOD

commit 8316e38100c70cd1443ac90074eccdd033aa218d
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Feb 17 20:28:29 2009 +0100

    irq: further clean up the free_irq() code flow
    
    Linus noticed that the 'pp' variable can be eliminated
    altogether, and the loop can be cleaned up further.
    
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 7a954b860c07..de5a765e88ab 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -575,7 +575,7 @@ int setup_irq(unsigned int irq, struct irqaction *act)
 void free_irq(unsigned int irq, void *dev_id)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
-	struct irqaction *action, **p, **pp;
+	struct irqaction *action, **p;
 	unsigned long flags;
 
 	WARN(in_interrupt(), "Trying to free IRQ %d from IRQ context!\n", irq);
@@ -592,7 +592,6 @@ void free_irq(unsigned int irq, void *dev_id)
 	p = &desc->action;
 	for (;;) {
 		action = *p;
-		pp = p;
 
 		if (!action) {
 			WARN(1, "Trying to free already-free IRQ %d\n", irq);
@@ -601,15 +600,13 @@ void free_irq(unsigned int irq, void *dev_id)
 			return;
 		}
 
+		if (action->dev_id == dev_id)
+			break;
 		p = &action->next;
-		if (action->dev_id != dev_id)
-			continue;
-
-		break;
 	}
 
 	/* Found it - now remove it from the list of entries: */
-	*pp = action->next;
+	*p = action->next;
 
 	/* Currently used only by UML, might disappear one day: */
 #ifdef CONFIG_IRQ_RELEASE_METHOD

commit ae88a23b32fa7e0dc9fa7ce735966e68eb41b0bc
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Feb 15 11:29:50 2009 +0100

    irq: refactor and clean up the free_irq() code flow
    
    Impact: cleanup
    
    - separate out the loop from the actual freeing logic, this wins us
      two indentation levels allowing a number of followup prettifications
    
    - turn the WARN_ON() into a more informative WARN().
    
    - clean up the comments and the code flow some more
    
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 8f4bc61f0df9..7a954b860c07 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -575,72 +575,79 @@ int setup_irq(unsigned int irq, struct irqaction *act)
 void free_irq(unsigned int irq, void *dev_id)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
-	struct irqaction **p;
+	struct irqaction *action, **p, **pp;
 	unsigned long flags;
 
-	WARN_ON(in_interrupt());
+	WARN(in_interrupt(), "Trying to free IRQ %d from IRQ context!\n", irq);
 
 	if (!desc)
 		return;
 
 	spin_lock_irqsave(&desc->lock, flags);
+
+	/*
+	 * There can be multiple actions per IRQ descriptor, find the right
+	 * one based on the dev_id:
+	 */
 	p = &desc->action;
 	for (;;) {
-		struct irqaction *action = *p;
+		action = *p;
+		pp = p;
+
+		if (!action) {
+			WARN(1, "Trying to free already-free IRQ %d\n", irq);
+			spin_unlock_irqrestore(&desc->lock, flags);
+
+			return;
+		}
 
-		if (action) {
-			struct irqaction **pp = p;
+		p = &action->next;
+		if (action->dev_id != dev_id)
+			continue;
 
-			p = &action->next;
-			if (action->dev_id != dev_id)
-				continue;
+		break;
+	}
 
-			/* Found it - now remove it from the list of entries */
-			*pp = action->next;
+	/* Found it - now remove it from the list of entries: */
+	*pp = action->next;
 
-			/* Currently used only by UML, might disappear one day.*/
+	/* Currently used only by UML, might disappear one day: */
 #ifdef CONFIG_IRQ_RELEASE_METHOD
-			if (desc->chip->release)
-				desc->chip->release(irq, dev_id);
+	if (desc->chip->release)
+		desc->chip->release(irq, dev_id);
 #endif
 
-			if (!desc->action) {
-				desc->status |= IRQ_DISABLED;
-				if (desc->chip->shutdown)
-					desc->chip->shutdown(irq);
-				else
-					desc->chip->disable(irq);
-			}
-			spin_unlock_irqrestore(&desc->lock, flags);
-			unregister_handler_proc(irq, action);
+	/* If this was the last handler, shut down the IRQ line: */
+	if (!desc->action) {
+		desc->status |= IRQ_DISABLED;
+		if (desc->chip->shutdown)
+			desc->chip->shutdown(irq);
+		else
+			desc->chip->disable(irq);
+	}
+	spin_unlock_irqrestore(&desc->lock, flags);
+
+	unregister_handler_proc(irq, action);
+
+	/* Make sure it's not being used on another CPU: */
+	synchronize_irq(irq);
 
-			/* Make sure it's not being used on another CPU */
-			synchronize_irq(irq);
-#ifdef CONFIG_DEBUG_SHIRQ
-			/*
-			 * It's a shared IRQ -- the driver ought to be
-			 * prepared for it to happen even now it's
-			 * being freed, so let's make sure....  We do
-			 * this after actually deregistering it, to
-			 * make sure that a 'real' IRQ doesn't run in
-			 * parallel with our fake
-			 */
-			if (action->flags & IRQF_SHARED) {
-				local_irq_save(flags);
-				action->handler(irq, dev_id);
-				local_irq_restore(flags);
-			}
-#endif
-			kfree(action);
-			return;
-		}
-		printk(KERN_ERR "Trying to free already-free IRQ %d\n", irq);
 #ifdef CONFIG_DEBUG_SHIRQ
-		dump_stack();
-#endif
-		spin_unlock_irqrestore(&desc->lock, flags);
-		return;
+	/*
+	 * It's a shared IRQ -- the driver ought to be prepared for an IRQ
+	 * event to happen even now it's being freed, so let's make sure that
+	 * is so by doing an extra call to the handler ....
+	 *
+	 * ( We do this after actually deregistering it, to make sure that a
+	 *   'real' IRQ doesn't run in * parallel with our fake. )
+	 */
+	if (action->flags & IRQF_SHARED) {
+		local_irq_save(flags);
+		action->handler(irq, dev_id);
+		local_irq_restore(flags);
 	}
+#endif
+	kfree(action);
 }
 EXPORT_SYMBOL(free_irq);
 

commit 327ec5699c29454322d0136375f717f509c145b6
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Feb 15 11:21:37 2009 +0100

    irq: clean up manage.c
    
    - make printk message git-greppable
    - fix a few style details
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 1c5055069170..8f4bc61f0df9 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -397,7 +397,7 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
  * allocate special interrupts that are part of the architecture.
  */
 static int
-__setup_irq(unsigned int irq, struct irq_desc * desc, struct irqaction *new)
+__setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 {
 	struct irqaction *old, **p;
 	const char *old_name = NULL;
@@ -687,11 +687,12 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 	 * the behavior is classified as "will not fix" so we need to
 	 * start nudging drivers away from using that idiom.
 	 */
-	if ((irqflags & (IRQF_SHARED|IRQF_DISABLED))
-			== (IRQF_SHARED|IRQF_DISABLED))
-		pr_warning("IRQ %d/%s: IRQF_DISABLED is not "
-				"guaranteed on shared IRQs\n",
-				irq, devname);
+	if ((irqflags & (IRQF_SHARED|IRQF_DISABLED)) ==
+					(IRQF_SHARED|IRQF_DISABLED)) {
+		pr_warning(
+		  "IRQ %d/%s: IRQF_DISABLED is not guaranteed on shared IRQs\n",
+			irq, devname);
+	}
 
 #ifdef CONFIG_LOCKDEP
 	/*

commit 8f8573ae9f5deefada6f5d64d0a52c9b39c730c7
Merge: 37bed90094fd 0e43785c57fe 005bf0e6fa0e 548c8933801c
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Feb 13 11:57:18 2009 +0100

    Merge branches 'irq/genirq', 'irq/sparseirq' and 'irq/urgent' into irq/core

commit 0e43785c57fee50fbc00ea0378e941efb61fa0c2
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Fri Feb 13 04:38:04 2009 +0100

    irq: use GFP_KERNEL for action allocation in request_irq()
    
    request_irq() calls into proc code via __setup_irq() which is not safe
    in an atomic context, so request_irq() can itself use the more
    reliable GFP_KERNEL allocation for the action descriptor.
    
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index cd0cd8dcb345..1c5055069170 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -717,7 +717,7 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 	if (!handler)
 		return -EINVAL;
 
-	action = kmalloc(sizeof(struct irqaction), GFP_ATOMIC);
+	action = kmalloc(sizeof(struct irqaction), GFP_KERNEL);
 	if (!action)
 		return -ENOMEM;
 

commit 548c8933801c9ee347b6f1bad2491e4286a4f3a2
Author: Hannes Eder <hannes@hanneseder.net>
Date:   Sun Feb 8 20:24:47 2009 +0100

    kernel/irq: fix sparse warning: make symbol static
    
    While being at it make every occurrence of 'do_irq_select_affinity'
    have the same signature in terms of signedness of the first argument.
    
    Fix this sparse warning:
      kernel/irq/manage.c:112:5: warning: symbol 'do_irq_select_affinity' was not declared. Should it be static?
    
    Also rename do_irq_select_affinity() to setup_affinity() - shorter name
    and clearer naming.
    
    Signed-off-by: Hannes Eder <hannes@hanneseder.net>
    Acked-by: Matthew Wilcox <matthew@wil.cx>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 291f03664552..38008b80bd59 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -109,7 +109,7 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *cpumask)
 /*
  * Generic version of the affinity autoselector.
  */
-int do_irq_select_affinity(unsigned int irq, struct irq_desc *desc)
+static int setup_affinity(unsigned int irq, struct irq_desc *desc)
 {
 	if (!irq_can_set_affinity(irq))
 		return 0;
@@ -133,7 +133,7 @@ int do_irq_select_affinity(unsigned int irq, struct irq_desc *desc)
 	return 0;
 }
 #else
-static inline int do_irq_select_affinity(unsigned int irq, struct irq_desc *d)
+static inline int setup_affinity(unsigned int irq, struct irq_desc *d)
 {
 	return irq_select_affinity(irq);
 }
@@ -149,14 +149,14 @@ int irq_select_affinity_usr(unsigned int irq)
 	int ret;
 
 	spin_lock_irqsave(&desc->lock, flags);
-	ret = do_irq_select_affinity(irq, desc);
+	ret = setup_affinity(irq, desc);
 	spin_unlock_irqrestore(&desc->lock, flags);
 
 	return ret;
 }
 
 #else
-static inline int do_irq_select_affinity(int irq, struct irq_desc *desc)
+static inline int setup_affinity(unsigned int irq, struct irq_desc *desc)
 {
 	return 0;
 }
@@ -488,7 +488,7 @@ __setup_irq(unsigned int irq, struct irq_desc * desc, struct irqaction *new)
 			desc->status |= IRQ_NO_BALANCING;
 
 		/* Set default affinity mask once everything is setup */
-		do_irq_select_affinity(irq, desc);
+		setup_affinity(irq, desc);
 
 	} else if ((new->flags & IRQF_TRIGGER_MASK)
 			&& (new->flags & IRQF_TRIGGER_MASK)

commit c43e0e46adf79c321ed3fbf0351e1005fb8a2413
Merge: dba3d36b2f08 f2257b70b0f9
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Jan 30 18:23:30 2009 +0100

    Merge branch 'linus' into core/percpu
    
    Conflicts:
            kernel/irq/handle.c

commit 6a385db5ce7f1fd2c68ec511e44587b67dab8fca
Merge: 18e352e4a734 4369f1fb7cd4
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Jan 28 23:12:55 2009 +0100

    Merge branch 'core/percpu' into x86/core
    
    Conflicts:
            kernel/irq/handle.c

commit 97179fd46da7ddedd18e95388130ed3e06c5a0c7
Author: David Daney <ddaney@caviumnetworks.com>
Date:   Tue Jan 27 09:53:22 2009 -0800

    cpumask fallout: Initialize irq_default_affinity earlier
    
    Move the initialization of irq_default_affinity to early_irq_init as
    core_initcall is too late.
    
    irq_default_affinity can be used in init_IRQ and potentially timer and
    SMP init as well.  All of these happen before core_initcall.  Moving
    the initialization to early_irq_init ensures that it is initialized
    before it is used.
    
    Signed-off-by: David Daney <ddaney@caviumnetworks.com>
    Acked-by: Mike Travis <travis@sgi.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 618a64f1915a..291f03664552 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -18,14 +18,6 @@
 #if defined(CONFIG_SMP) && defined(CONFIG_GENERIC_HARDIRQS)
 cpumask_var_t irq_default_affinity;
 
-static int init_irq_default_affinity(void)
-{
-	alloc_cpumask_var(&irq_default_affinity, GFP_KERNEL);
-	cpumask_setall(irq_default_affinity);
-	return 0;
-}
-core_initcall(init_irq_default_affinity);
-
 /**
  *	synchronize_irq - wait for pending IRQ handlers (on other CPUs)
  *	@irq: interrupt number to wait for

commit 1267a8df209c7453d65acbdd56e3588954bf890b
Author: David Daney <ddaney@caviumnetworks.com>
Date:   Tue Jan 27 09:53:21 2009 -0800

    Make irq_*_affinity depend on CONFIG_GENERIC_HARDIRQS too.
    
    In interrupt.h these functions are declared only if
    CONFIG_GENERIC_HARDIRQS is set.  We should define them under identical
    conditions.
    
    Signed-off-by: David Daney <ddaney@caviumnetworks.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index cd0cd8dcb345..618a64f1915a 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -15,7 +15,7 @@
 
 #include "internals.h"
 
-#ifdef CONFIG_SMP
+#if defined(CONFIG_SMP) && defined(CONFIG_GENERIC_HARDIRQS)
 cpumask_var_t irq_default_affinity;
 
 static int init_irq_default_affinity(void)

commit 7f7ace0cda64c99599c23785f8979a072e118058
Author: Mike Travis <travis@sgi.com>
Date:   Sat Jan 10 21:58:08 2009 -0800

    cpumask: update irq_desc to use cpumask_var_t
    
    Impact: reduce memory usage, use new cpumask API.
    
    Replace the affinity and pending_masks with cpumask_var_t's.  This adds
    to the significant size reduction done with the SPARSE_IRQS changes.
    
    The added functions (init_alloc_desc_masks & init_copy_desc_masks) are
    in the include file so they can be inlined (and optimized out for the
    !CONFIG_CPUMASKS_OFFSTACK case.)  [Naming chosen to be consistent with
    the other init*irq functions, as well as the backwards arg declaration
    of "from, to" instead of the more common "to, from" standard.]
    
    Includes a slight change to the declaration of struct irq_desc to embed
    the pending_mask within ifdef(CONFIG_SMP) to be consistent with other
    references, and some small changes to Xen.
    
    Tested: sparse/non-sparse/cpumask_offstack/non-cpumask_offstack/nonuma/nosmp on x86_64
    
    Signed-off-by: Mike Travis <travis@sgi.com>
    Cc: Chris Wright <chrisw@sous-sol.org>
    Cc: Jeremy Fitzhardinge <jeremy@xensource.com>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Cc: virtualization@lists.osdl.org
    Cc: xen-devel@lists.xensource.com
    Cc: Yinghai Lu <yhlu.kernel@gmail.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index cd0cd8dcb345..b98739af4558 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -98,14 +98,14 @@ int irq_set_affinity(unsigned int irq, const struct cpumask *cpumask)
 
 #ifdef CONFIG_GENERIC_PENDING_IRQ
 	if (desc->status & IRQ_MOVE_PCNTXT || desc->status & IRQ_DISABLED) {
-		cpumask_copy(&desc->affinity, cpumask);
+		cpumask_copy(desc->affinity, cpumask);
 		desc->chip->set_affinity(irq, cpumask);
 	} else {
 		desc->status |= IRQ_MOVE_PENDING;
-		cpumask_copy(&desc->pending_mask, cpumask);
+		cpumask_copy(desc->pending_mask, cpumask);
 	}
 #else
-	cpumask_copy(&desc->affinity, cpumask);
+	cpumask_copy(desc->affinity, cpumask);
 	desc->chip->set_affinity(irq, cpumask);
 #endif
 	desc->status |= IRQ_AFFINITY_SET;
@@ -127,16 +127,16 @@ int do_irq_select_affinity(unsigned int irq, struct irq_desc *desc)
 	 * one of the targets is online.
 	 */
 	if (desc->status & (IRQ_AFFINITY_SET | IRQ_NO_BALANCING)) {
-		if (cpumask_any_and(&desc->affinity, cpu_online_mask)
+		if (cpumask_any_and(desc->affinity, cpu_online_mask)
 		    < nr_cpu_ids)
 			goto set_affinity;
 		else
 			desc->status &= ~IRQ_AFFINITY_SET;
 	}
 
-	cpumask_and(&desc->affinity, cpu_online_mask, irq_default_affinity);
+	cpumask_and(desc->affinity, cpu_online_mask, irq_default_affinity);
 set_affinity:
-	desc->chip->set_affinity(irq, &desc->affinity);
+	desc->chip->set_affinity(irq, desc->affinity);
 
 	return 0;
 }

commit d036e67b40f52bdd95392390108defbac7e53837
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Thu Jan 1 10:12:26 2009 +1030

    cpumask: convert kernel/irq
    
    Impact: Reduce stack usage, use new cpumask API.  ALPHA mod!
    
    Main change is that irq_default_affinity becomes a cpumask_var_t, so
    treat it as a pointer (this effects alpha).
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 61c4a9b62165..cd0cd8dcb345 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -16,8 +16,15 @@
 #include "internals.h"
 
 #ifdef CONFIG_SMP
+cpumask_var_t irq_default_affinity;
 
-cpumask_t irq_default_affinity = CPU_MASK_ALL;
+static int init_irq_default_affinity(void)
+{
+	alloc_cpumask_var(&irq_default_affinity, GFP_KERNEL);
+	cpumask_setall(irq_default_affinity);
+	return 0;
+}
+core_initcall(init_irq_default_affinity);
 
 /**
  *	synchronize_irq - wait for pending IRQ handlers (on other CPUs)
@@ -127,7 +134,7 @@ int do_irq_select_affinity(unsigned int irq, struct irq_desc *desc)
 			desc->status &= ~IRQ_AFFINITY_SET;
 	}
 
-	cpumask_and(&desc->affinity, cpu_online_mask, &irq_default_affinity);
+	cpumask_and(&desc->affinity, cpu_online_mask, irq_default_affinity);
 set_affinity:
 	desc->chip->set_affinity(irq, &desc->affinity);
 

commit 2ca1a615835d9f4990f42102ab1f2ef434e7e89c
Merge: e12f0102ac81 6a94cb73064c
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Wed Dec 31 23:05:57 2008 +1030

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux-2.6
    
    Conflicts:
    
            arch/x86/kernel/io_apic.c

commit 179475a3b46f86e2d06f83e2312218ac3f0cf3a7
Merge: bb758e9637e5 860cf8894b32
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 30 16:20:19 2008 -0800

    Merge branch 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86, sparseirq: clean up Kconfig entry
      x86: turn CONFIG_SPARSE_IRQ off by default
      sparseirq: fix numa_migrate_irq_desc dependency and comments
      sparseirq: add kernel-doc notation for new member in irq_desc, -v2
      locking, irq: enclose irq_desc_lock_class in CONFIG_LOCKDEP
      sparseirq, xen: make sure irq_desc is allocated for interrupts
      sparseirq: fix !SMP building, #2
      x86, sparseirq: move irq_desc according to smp_affinity, v7
      proc: enclose desc variable of show_stat() in CONFIG_SPARSE_IRQ
      sparse irqs: add irqnr.h to the user headers list
      sparse irqs: handle !GENIRQ platforms
      sparseirq: fix !SMP && !PCI_MSI && !HT_IRQ build
      sparseirq: fix Alpha build failure
      sparseirq: fix typo in !CONFIG_IO_APIC case
      x86, MSI: pass irq_cfg and irq_desc
      x86: MSI start irq numbering from nr_irqs_gsi
      x86: use NR_IRQS_LEGACY
      sparse irq_desc[] array: core kernel and x86 changes
      genirq: record IRQ_LEVEL in irq_desc[]
      irq.h: remove padding from irq_desc on 64bits

commit 0de26520c7cabf36e1de090ea8092f011a6106ce
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Sat Dec 13 21:20:26 2008 +1030

    cpumask: make irq_set_affinity() take a const struct cpumask
    
    Impact: change existing irq_chip API
    
    Not much point with gentle transition here: the struct irq_chip's
    setaffinity method signature needs to change.
    
    Fortunately, not widely used code, but hits a few architectures.
    
    Note: In irq_select_affinity() I save a temporary in by mangling
    irq_desc[irq].affinity directly.  Ingo, does this break anything?
    
    (Folded in fix from KOSAKI Motohiro)
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Mike Travis <travis@sgi.com>
    Reviewed-by: Grant Grundler <grundler@parisc-linux.org>
    Acked-by: Ingo Molnar <mingo@redhat.com>
    Cc: ralf@linux-mips.org
    Cc: grundler@parisc-linux.org
    Cc: jeremy@xensource.com
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 801addda3c43..10ad2f87ed9a 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -79,7 +79,7 @@ int irq_can_set_affinity(unsigned int irq)
  *	@cpumask:	cpumask
  *
  */
-int irq_set_affinity(unsigned int irq, cpumask_t cpumask)
+int irq_set_affinity(unsigned int irq, const struct cpumask *cpumask)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned long flags;
@@ -91,14 +91,14 @@ int irq_set_affinity(unsigned int irq, cpumask_t cpumask)
 
 #ifdef CONFIG_GENERIC_PENDING_IRQ
 	if (desc->status & IRQ_MOVE_PCNTXT || desc->status & IRQ_DISABLED) {
-		desc->affinity = cpumask;
+		cpumask_copy(&desc->affinity, cpumask);
 		desc->chip->set_affinity(irq, cpumask);
 	} else {
 		desc->status |= IRQ_MOVE_PENDING;
-		desc->pending_mask = cpumask;
+		cpumask_copy(&desc->pending_mask, cpumask);
 	}
 #else
-	desc->affinity = cpumask;
+	cpumask_copy(&desc->affinity, cpumask);
 	desc->chip->set_affinity(irq, cpumask);
 #endif
 	desc->status |= IRQ_AFFINITY_SET;
@@ -112,26 +112,24 @@ int irq_set_affinity(unsigned int irq, cpumask_t cpumask)
  */
 int do_irq_select_affinity(unsigned int irq, struct irq_desc *desc)
 {
-	cpumask_t mask;
-
 	if (!irq_can_set_affinity(irq))
 		return 0;
 
-	cpus_and(mask, cpu_online_map, irq_default_affinity);
-
 	/*
 	 * Preserve an userspace affinity setup, but make sure that
 	 * one of the targets is online.
 	 */
 	if (desc->status & (IRQ_AFFINITY_SET | IRQ_NO_BALANCING)) {
-		if (cpus_intersects(desc->affinity, cpu_online_map))
-			mask = desc->affinity;
+		if (cpumask_any_and(&desc->affinity, cpu_online_mask)
+		    < nr_cpu_ids)
+			goto set_affinity;
 		else
 			desc->status &= ~IRQ_AFFINITY_SET;
 	}
 
-	desc->affinity = mask;
-	desc->chip->set_affinity(irq, mask);
+	cpumask_and(&desc->affinity, cpu_online_mask, &irq_default_affinity);
+set_affinity:
+	desc->chip->set_affinity(irq, &desc->affinity);
 
 	return 0;
 }

commit cb9c34e6d090d376b77becaa5d29a65dec7f4272
Merge: 470c66239ef0 061e41fdb504
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Dec 4 08:52:14 2008 +0100

    Merge commit 'v2.6.28-rc7' into core/locking

commit 470c66239ef0336429b35345f3f615d47341e13b
Author: David Brownell <dbrownell@users.sourceforge.net>
Date:   Mon Dec 1 14:31:37 2008 -0800

    genirq: warn when IRQF_DISABLED may be ignored
    
    Impact: emit new warning
    
    We periodically waste time tracking down problems from the genirq
    framework not respecting IRQF_DISABLED for some shared IRQ cases.  Linus
    views this as "will not fix", but we're still left with the bugs caused by
    this misbehavior.
    
    This patch adds a nag message in request_irq(), so that drivers can fix
    their IRQ handlers to avoid this problem.
    
    Note that developers will never see the relevant bugs when they run with
    LOCKDEP, so it's no wonder these bugs are hard to find.  (That also means
    LOCKDEP is overlooking some IRQ-related bugs involving IRQ handlers that
    don't set IRQF_DISABLED...)
    
    Signed-off-by: David Brownell <dbrownell@users.sourceforge.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index c498a1b8c621..7fd891c3a33d 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -635,6 +635,18 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 	struct irq_desc *desc;
 	int retval;
 
+	/*
+	 * handle_IRQ_event() always ignores IRQF_DISABLED except for
+	 * the _first_ irqaction (sigh).  That can cause oopsing, but
+	 * the behavior is classified as "will not fix" so we need to
+	 * start nudging drivers away from using that idiom.
+	 */
+	if ((irqflags & (IRQF_SHARED|IRQF_DISABLED))
+			== (IRQF_SHARED|IRQF_DISABLED))
+		pr_warning("IRQ %d/%s: IRQF_DISABLED is not "
+				"guaranteed on shared IRQs\n",
+				irq, devname);
+
 #ifdef CONFIG_LOCKDEP
 	/*
 	 * Lockdep wants atomic interrupt handlers:

commit f2b662da8d6bd44673537f3f64220afefdca369f
Author: David Brownell <dbrownell@users.sourceforge.net>
Date:   Mon Dec 1 14:31:38 2008 -0800

    genirq: record IRQ_LEVEL in irq_desc[]
    
    Impact: fix __irq_set_trigger() for IRQ_LEVEL
    
    When recording the irq trigger type, let's also make sure
    that IRQ_LEVEL gets set correctly.
    
    Signed-off-by: David Brownell <dbrownell@users.sourceforge.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 801addda3c43..46953a06f4a8 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -370,16 +370,18 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 		return 0;
 	}
 
-	ret = chip->set_type(irq, flags & IRQF_TRIGGER_MASK);
+	/* caller masked out all except trigger mode flags */
+	ret = chip->set_type(irq, flags);
 
 	if (ret)
 		pr_err("setting trigger mode %d for irq %u failed (%pF)\n",
-				(int)(flags & IRQF_TRIGGER_MASK),
-				irq, chip->set_type);
+				(int)flags, irq, chip->set_type);
 	else {
+		if (flags & (IRQ_TYPE_LEVEL_LOW | IRQ_TYPE_LEVEL_HIGH))
+			flags |= IRQ_LEVEL;
 		/* note that IRQF_TRIGGER_MASK == IRQ_TYPE_SENSE_MASK */
-		desc->status &= ~IRQ_TYPE_SENSE_MASK;
-		desc->status |= flags & IRQ_TYPE_SENSE_MASK;
+		desc->status &= ~(IRQ_LEVEL | IRQ_TYPE_SENSE_MASK);
+		desc->status |= flags;
 	}
 
 	return ret;
@@ -459,7 +461,8 @@ __setup_irq(unsigned int irq, struct irq_desc * desc, struct irqaction *new)
 
 		/* Setup the type (level, edge polarity) if configured: */
 		if (new->flags & IRQF_TRIGGER_MASK) {
-			ret = __irq_set_trigger(desc, irq, new->flags);
+			ret = __irq_set_trigger(desc, irq,
+					new->flags & IRQF_TRIGGER_MASK);
 
 			if (ret) {
 				spin_unlock_irqrestore(&desc->lock, flags);

commit 3ff68a6a106c362a6811d3e51bced58e6fc87de7
Author: Mark Nelson <markn@au1.ibm.com>
Date:   Thu Nov 13 21:37:41 2008 +1100

    genirq: __irq_set_trigger: change pr_warning to pr_debug
    
    Commit 0c5d1eb77a8be917b638344a22afe1398236482b (genirq: record trigger
    type) caused powerpc platforms that had no set_type() function in their
    struct irq_chip to spew out warnings about "No set_type function for
    IRQ...". This warning isn't necessarily justified though because the
    generic powerpc platform code calls set_irq_type() (which in turn calls
    __irq_set_trigger) with information from the device tree to establish
    the interrupt mappings, regardless of whether the PIC can actually set
    a type.
    
    A platform's irq_chip might not have a set_type function for a variety
    of reasons, for example: the platform may have the type essentially
    hard-coded, or as in the case for Cell interrupts are just messages
    past around that have no real concept of type, or the platform
    could even have a virtual PIC as on the PS3.
    
    Signed-off-by: Mark Nelson <markn@au1.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 435861284e4c..801addda3c43 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -365,7 +365,7 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 		 * IRQF_TRIGGER_* but the PIC does not support multiple
 		 * flow-types?
 		 */
-		pr_warning("No set_type function for IRQ %d (%s)\n", irq,
+		pr_debug("No set_type function for IRQ %d (%s)\n", irq,
 				chip ? (chip->name ? : "unknown") : "unknown");
 		return 0;
 	}

commit f131e2436ddbac2527bb2d6297a823aae4b024f8
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sat Nov 8 09:57:40 2008 +0100

    irq: fix typo
    
    Impact: build fix
    
    fix build failure on UP.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 948a22a2c013..435861284e4c 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -159,7 +159,7 @@ int irq_select_affinity_usr(unsigned int irq)
 }
 
 #else
-static inline int do_select_irq_affinity(int irq, struct irq_desc *desc)
+static inline int do_irq_select_affinity(int irq, struct irq_desc *desc)
 {
 	return 0;
 }

commit 612e3684c1b7752d2890510e4f90115fd1eb2afb
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Nov 7 13:58:46 2008 +0100

    genirq: fix the affinity setting in setup_irq
    
    The affinity setting in setup irq is called before the NO_BALANCING
    flag is checked and might therefore override affinity settings from the
    calling code with the default setting.
    
    Move the NO_BALANCING flag check before the call to the affinity
    setting.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 634a2a955104..948a22a2c013 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -123,7 +123,7 @@ int do_irq_select_affinity(unsigned int irq, struct irq_desc *desc)
 	 * Preserve an userspace affinity setup, but make sure that
 	 * one of the targets is online.
 	 */
-	if (desc->status & IRQ_AFFINITY_SET) {
+	if (desc->status & (IRQ_AFFINITY_SET | IRQ_NO_BALANCING)) {
 		if (cpus_intersects(desc->affinity, cpu_online_map))
 			mask = desc->affinity;
 		else
@@ -483,6 +483,10 @@ __setup_irq(unsigned int irq, struct irq_desc * desc, struct irqaction *new)
 			/* Undo nested disables: */
 			desc->depth = 1;
 
+		/* Exclude IRQ from balancing if requested */
+		if (new->flags & IRQF_NOBALANCING)
+			desc->status |= IRQ_NO_BALANCING;
+
 		/* Set default affinity mask once everything is setup */
 		do_irq_select_affinity(irq, desc);
 
@@ -497,10 +501,6 @@ __setup_irq(unsigned int irq, struct irq_desc * desc, struct irqaction *new)
 
 	*p = new;
 
-	/* Exclude IRQ from balancing */
-	if (new->flags & IRQF_NOBALANCING)
-		desc->status |= IRQ_NO_BALANCING;
-
 	/* Reset broken irq detection when installing new handler */
 	desc->irq_count = 0;
 	desc->irqs_unhandled = 0;

commit f6d87f4bd259cf33e092cd1a8fde05f291c47af1
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Nov 7 13:18:30 2008 +0100

    genirq: keep affinities set from userspace across free/request_irq()
    
    Impact: preserve user-modified affinities on interrupts
    
    Kumar Galak noticed that commit
    18404756765c713a0be4eb1082920c04822ce588 (genirq: Expose default irq
    affinity mask (take 3))
    
    overrides an already set affinity setting across a free /
    request_irq(). Happens e.g. with ifdown/ifup of a network device.
    
    Change the logic to mark the affinities as set and keep them
    intact. This also fixes the unlocked access to irq_desc in
    irq_select_affinity() when called from irq_affinity_proc_write()
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index c498a1b8c621..634a2a955104 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -82,24 +82,27 @@ int irq_can_set_affinity(unsigned int irq)
 int irq_set_affinity(unsigned int irq, cpumask_t cpumask)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
+	unsigned long flags;
 
 	if (!desc->chip->set_affinity)
 		return -EINVAL;
 
+	spin_lock_irqsave(&desc->lock, flags);
+
 #ifdef CONFIG_GENERIC_PENDING_IRQ
 	if (desc->status & IRQ_MOVE_PCNTXT || desc->status & IRQ_DISABLED) {
-		unsigned long flags;
-
-		spin_lock_irqsave(&desc->lock, flags);
 		desc->affinity = cpumask;
 		desc->chip->set_affinity(irq, cpumask);
-		spin_unlock_irqrestore(&desc->lock, flags);
-	} else
-		set_pending_irq(irq, cpumask);
+	} else {
+		desc->status |= IRQ_MOVE_PENDING;
+		desc->pending_mask = cpumask;
+	}
 #else
 	desc->affinity = cpumask;
 	desc->chip->set_affinity(irq, cpumask);
 #endif
+	desc->status |= IRQ_AFFINITY_SET;
+	spin_unlock_irqrestore(&desc->lock, flags);
 	return 0;
 }
 
@@ -107,24 +110,59 @@ int irq_set_affinity(unsigned int irq, cpumask_t cpumask)
 /*
  * Generic version of the affinity autoselector.
  */
-int irq_select_affinity(unsigned int irq)
+int do_irq_select_affinity(unsigned int irq, struct irq_desc *desc)
 {
 	cpumask_t mask;
-	struct irq_desc *desc;
 
 	if (!irq_can_set_affinity(irq))
 		return 0;
 
 	cpus_and(mask, cpu_online_map, irq_default_affinity);
 
-	desc = irq_to_desc(irq);
+	/*
+	 * Preserve an userspace affinity setup, but make sure that
+	 * one of the targets is online.
+	 */
+	if (desc->status & IRQ_AFFINITY_SET) {
+		if (cpus_intersects(desc->affinity, cpu_online_map))
+			mask = desc->affinity;
+		else
+			desc->status &= ~IRQ_AFFINITY_SET;
+	}
+
 	desc->affinity = mask;
 	desc->chip->set_affinity(irq, mask);
 
 	return 0;
 }
+#else
+static inline int do_irq_select_affinity(unsigned int irq, struct irq_desc *d)
+{
+	return irq_select_affinity(irq);
+}
 #endif
 
+/*
+ * Called when affinity is set via /proc/irq
+ */
+int irq_select_affinity_usr(unsigned int irq)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+	unsigned long flags;
+	int ret;
+
+	spin_lock_irqsave(&desc->lock, flags);
+	ret = do_irq_select_affinity(irq, desc);
+	spin_unlock_irqrestore(&desc->lock, flags);
+
+	return ret;
+}
+
+#else
+static inline int do_select_irq_affinity(int irq, struct irq_desc *desc)
+{
+	return 0;
+}
 #endif
 
 /**
@@ -446,7 +484,7 @@ __setup_irq(unsigned int irq, struct irq_desc * desc, struct irqaction *new)
 			desc->depth = 1;
 
 		/* Set default affinity mask once everything is setup */
-		irq_select_affinity(irq);
+		do_irq_select_affinity(irq, desc);
 
 	} else if ((new->flags & IRQF_TRIGGER_MASK)
 			&& (new->flags & IRQF_TRIGGER_MASK)

commit d3c60047bdb03199b93497ac40bd531315d43a86
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Oct 16 09:55:00 2008 +0200

    genirq: cleanup the sparseirq modifications
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index ad2ce72c83c4..c498a1b8c621 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -140,10 +140,9 @@ int irq_select_affinity(unsigned int irq)
  */
 void disable_irq_nosync(unsigned int irq)
 {
-	struct irq_desc *desc;
+	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned long flags;
 
-	desc = irq_to_desc(irq);
 	if (!desc)
 		return;
 
@@ -170,9 +169,8 @@ EXPORT_SYMBOL(disable_irq_nosync);
  */
 void disable_irq(unsigned int irq)
 {
-	struct irq_desc *desc;
+	struct irq_desc *desc = irq_to_desc(irq);
 
-	desc = irq_to_desc(irq);
 	if (!desc)
 		return;
 
@@ -213,10 +211,9 @@ static void __enable_irq(struct irq_desc *desc, unsigned int irq)
  */
 void enable_irq(unsigned int irq)
 {
-	struct irq_desc *desc;
+	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned long flags;
 
-	desc = irq_to_desc(irq);
 	if (!desc)
 		return;
 
@@ -291,10 +288,9 @@ EXPORT_SYMBOL(set_irq_wake);
  */
 int can_request_irq(unsigned int irq, unsigned long irqflags)
 {
-	struct irq_desc *desc;
+	struct irq_desc *desc = irq_to_desc(irq);
 	struct irqaction *action;
 
-	desc = irq_to_desc(irq);
 	if (!desc)
 		return 0;
 
@@ -355,16 +351,15 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
  * Internal function to register an irqaction - typically used to
  * allocate special interrupts that are part of the architecture.
  */
-int setup_irq(unsigned int irq, struct irqaction *new)
+static int
+__setup_irq(unsigned int irq, struct irq_desc * desc, struct irqaction *new)
 {
-	struct irq_desc *desc;
 	struct irqaction *old, **p;
 	const char *old_name = NULL;
 	unsigned long flags;
 	int shared = 0;
 	int ret;
 
-	desc = irq_to_desc(irq);
 	if (!desc)
 		return -EINVAL;
 
@@ -503,6 +498,20 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 	return -EBUSY;
 }
 
+/**
+ *	setup_irq - setup an interrupt
+ *	@irq: Interrupt line to setup
+ *	@act: irqaction for the interrupt
+ *
+ * Used to statically setup interrupts in the early boot process.
+ */
+int setup_irq(unsigned int irq, struct irqaction *act)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+
+	return __setup_irq(irq, desc, act);
+}
+
 /**
  *	free_irq - free an interrupt
  *	@irq: Interrupt line to free
@@ -519,13 +528,12 @@ int setup_irq(unsigned int irq, struct irqaction *new)
  */
 void free_irq(unsigned int irq, void *dev_id)
 {
-	struct irq_desc *desc;
+	struct irq_desc *desc = irq_to_desc(irq);
 	struct irqaction **p;
 	unsigned long flags;
 
 	WARN_ON(in_interrupt());
 
-	desc = irq_to_desc(irq);
 	if (!desc)
 		return;
 
@@ -624,8 +632,8 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 		unsigned long irqflags, const char *devname, void *dev_id)
 {
 	struct irqaction *action;
-	int retval;
 	struct irq_desc *desc;
+	int retval;
 
 #ifdef CONFIG_LOCKDEP
 	/*
@@ -662,7 +670,7 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 	action->next = NULL;
 	action->dev_id = dev_id;
 
-	retval = setup_irq(irq, action);
+	retval = __setup_irq(irq, desc, action);
 	if (retval)
 		kfree(action);
 

commit 932775a4ab622e3c99bd59f14cc7d96722f79501
Author: venkatesh.pallipadi@intel.com <venkatesh.pallipadi@intel.com>
Date:   Fri Sep 5 18:02:15 2008 -0700

    x86: HPET_MSI change IRQ affinity in process context when it is disabled
    
    Change the IRQ affinity in the process context when the IRQ is disabled.
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Shaohua Li <shaohua.li@intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index ddc956861a58..ad2ce72c83c4 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -87,10 +87,11 @@ int irq_set_affinity(unsigned int irq, cpumask_t cpumask)
 		return -EINVAL;
 
 #ifdef CONFIG_GENERIC_PENDING_IRQ
-	if (desc->status & IRQ_MOVE_PCNTXT) {
+	if (desc->status & IRQ_MOVE_PCNTXT || desc->status & IRQ_DISABLED) {
 		unsigned long flags;
 
 		spin_lock_irqsave(&desc->lock, flags);
+		desc->affinity = cpumask;
 		desc->chip->set_affinity(irq, cpumask);
 		spin_unlock_irqrestore(&desc->lock, flags);
 	} else

commit 8b8e8c1bf7275eca859fe551dfa484134eaf013b
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Tue Aug 19 20:50:23 2008 -0700

    x86: remove irqbalance in kernel for 32 bit
    
    This has been deprecated for years, the user space irqbalanced utility
    works better with numa, has configurable policies, etc...
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmai.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 6df49218632a..ddc956861a58 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -86,8 +86,6 @@ int irq_set_affinity(unsigned int irq, cpumask_t cpumask)
 	if (!desc->chip->set_affinity)
 		return -EINVAL;
 
-	set_balance_irq_affinity(irq, cpumask);
-
 #ifdef CONFIG_GENERIC_PENDING_IRQ
 	if (desc->status & IRQ_MOVE_PCNTXT) {
 		unsigned long flags;
@@ -122,7 +120,6 @@ int irq_select_affinity(unsigned int irq)
 	desc->affinity = mask;
 	desc->chip->set_affinity(irq, mask);
 
-	set_balance_irq_affinity(irq, mask);
 	return 0;
 }
 #endif

commit cb5bc83225a86ca53bbb889ed8439e4fd6cf44ac
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Tue Aug 19 20:50:17 2008 -0700

    x86_64: rename irq_desc/irq_desc_alloc
    
    change names:
    
              irq_desc() ==> irq_desc_alloc
            __irq_desc() ==> irq_desc
    
    Also split a few of the uses in lowlevel x86 code.
    
    v2: need to check if desc is null in smp_irq_move_cleanup
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index c0b4d4df6de2..6df49218632a 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -31,7 +31,7 @@ cpumask_t irq_default_affinity = CPU_MASK_ALL;
  */
 void synchronize_irq(unsigned int irq)
 {
-	struct irq_desc *desc = __irq_to_desc(irq);
+	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned int status;
 
 	if (!desc)
@@ -145,7 +145,7 @@ void disable_irq_nosync(unsigned int irq)
 	struct irq_desc *desc;
 	unsigned long flags;
 
-	desc = __irq_to_desc(irq);
+	desc = irq_to_desc(irq);
 	if (!desc)
 		return;
 
@@ -174,7 +174,7 @@ void disable_irq(unsigned int irq)
 {
 	struct irq_desc *desc;
 
-	desc = __irq_to_desc(irq);
+	desc = irq_to_desc(irq);
 	if (!desc)
 		return;
 
@@ -218,7 +218,7 @@ void enable_irq(unsigned int irq)
 	struct irq_desc *desc;
 	unsigned long flags;
 
-	desc = __irq_to_desc(irq);
+	desc = irq_to_desc(irq);
 	if (!desc)
 		return;
 
@@ -296,7 +296,7 @@ int can_request_irq(unsigned int irq, unsigned long irqflags)
 	struct irq_desc *desc;
 	struct irqaction *action;
 
-	desc = __irq_to_desc(irq);
+	desc = irq_to_desc(irq);
 	if (!desc)
 		return 0;
 
@@ -366,7 +366,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 	int shared = 0;
 	int ret;
 
-	desc = __irq_to_desc(irq);
+	desc = irq_to_desc(irq);
 	if (!desc)
 		return -EINVAL;
 
@@ -527,7 +527,7 @@ void free_irq(unsigned int irq, void *dev_id)
 
 	WARN_ON(in_interrupt());
 
-	desc = __irq_to_desc(irq);
+	desc = irq_to_desc(irq);
 	if (!desc)
 		return;
 
@@ -644,7 +644,7 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 	if ((irqflags & IRQF_SHARED) && !dev_id)
 		return -EINVAL;
 
-	desc = __irq_to_desc(irq);
+	desc = irq_to_desc(irq);
 	if (!desc)
 		return -EINVAL;
 

commit 7d94f7ca401dd7f445fda9a971a48aa5427b3e55
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Tue Aug 19 20:50:14 2008 -0700

    irq: remove >= nr_irqs checking with config_have_sparse_irq
    
    remove irq limit checks - nr_irqs is dynamic and we expand anytime.
    
    v2: fix checking about result irq_cfg_without_new, so could use msi again
    v3: use irq_desc_without_new to check irq is valid
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 5070f55fdc16..c0b4d4df6de2 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -31,10 +31,10 @@ cpumask_t irq_default_affinity = CPU_MASK_ALL;
  */
 void synchronize_irq(unsigned int irq)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
+	struct irq_desc *desc = __irq_to_desc(irq);
 	unsigned int status;
 
-	if (irq >= nr_irqs)
+	if (!desc)
 		return;
 
 	do {
@@ -142,10 +142,11 @@ int irq_select_affinity(unsigned int irq)
  */
 void disable_irq_nosync(unsigned int irq)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
+	struct irq_desc *desc;
 	unsigned long flags;
 
-	if (irq >= nr_irqs)
+	desc = __irq_to_desc(irq);
+	if (!desc)
 		return;
 
 	spin_lock_irqsave(&desc->lock, flags);
@@ -171,9 +172,10 @@ EXPORT_SYMBOL(disable_irq_nosync);
  */
 void disable_irq(unsigned int irq)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
+	struct irq_desc *desc;
 
-	if (irq >= nr_irqs)
+	desc = __irq_to_desc(irq);
+	if (!desc)
 		return;
 
 	disable_irq_nosync(irq);
@@ -213,10 +215,11 @@ static void __enable_irq(struct irq_desc *desc, unsigned int irq)
  */
 void enable_irq(unsigned int irq)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
+	struct irq_desc *desc;
 	unsigned long flags;
 
-	if (irq >= nr_irqs)
+	desc = __irq_to_desc(irq);
+	if (!desc)
 		return;
 
 	spin_lock_irqsave(&desc->lock, flags);
@@ -290,10 +293,14 @@ EXPORT_SYMBOL(set_irq_wake);
  */
 int can_request_irq(unsigned int irq, unsigned long irqflags)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
+	struct irq_desc *desc;
 	struct irqaction *action;
 
-	if (irq >= nr_irqs || desc->status & IRQ_NOREQUEST)
+	desc = __irq_to_desc(irq);
+	if (!desc)
+		return 0;
+
+	if (desc->status & IRQ_NOREQUEST)
 		return 0;
 
 	action = desc->action;
@@ -352,14 +359,15 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
  */
 int setup_irq(unsigned int irq, struct irqaction *new)
 {
-	struct irq_desc *desc = irq_to_desc(irq);
+	struct irq_desc *desc;
 	struct irqaction *old, **p;
 	const char *old_name = NULL;
 	unsigned long flags;
 	int shared = 0;
 	int ret;
 
-	if (irq >= nr_irqs)
+	desc = __irq_to_desc(irq);
+	if (!desc)
 		return -EINVAL;
 
 	if (desc->chip == &no_irq_chip)
@@ -518,10 +526,11 @@ void free_irq(unsigned int irq, void *dev_id)
 	unsigned long flags;
 
 	WARN_ON(in_interrupt());
-	if (irq >= nr_irqs)
+
+	desc = __irq_to_desc(irq);
+	if (!desc)
 		return;
 
-	desc = irq_to_desc(irq);
 	spin_lock_irqsave(&desc->lock, flags);
 	p = &desc->action;
 	for (;;) {
@@ -634,9 +643,11 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 	 */
 	if ((irqflags & IRQF_SHARED) && !dev_id)
 		return -EINVAL;
-	if (irq >= nr_irqs)
+
+	desc = __irq_to_desc(irq);
+	if (!desc)
 		return -EINVAL;
-	desc = irq_to_desc(irq);
+
 	if (desc->status & IRQ_NOREQUEST)
 		return -EINVAL;
 	if (!handler)

commit 2c6927a38f65b53b62f86158fba29a068c4e8b6a
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Tue Aug 19 20:50:11 2008 -0700

    irq: replace loop with nr_irqs with for_each_irq_desc
    
    There are a handful of loops that go from 0 to nr_irqs and use
    get_irq_desc() on them. These would allocate all the irq_desc
    entries, regardless of the need for them.
    
    Use the smarter for_each_irq_desc() iterator that will only iterate
    over the present ones.
    
    v2: make sure arch without GENERIC_HARDIRQS work too
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index b5943e9f95aa..5070f55fdc16 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -478,7 +478,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 	spin_unlock_irqrestore(&desc->lock, flags);
 
 	new->irq = irq;
-	register_irq_proc(irq);
+	register_irq_proc(irq, desc);
 	new->dir = NULL;
 	register_handler_proc(irq, new);
 

commit 08678b0841267c1d00d771fe01548d86043d065e
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Tue Aug 19 20:50:05 2008 -0700

    generic: sparse irqs: use irq_desc() together with dyn_array, instead of irq_desc[]
    
    add CONFIG_HAVE_SPARSE_IRQ to for use condensed array.
    Get rid of irq_desc[] array assumptions.
    
    Preallocate 32 irq_desc, and irq_desc() will try to get more.
    
    ( No change in functionality is expected anywhere, except the odd build
      failure where we missed a code site or where a crossing commit itroduces
      new irq_desc[] usage. )
    
    v2: according to Eric, change get_irq_desc() to irq_desc()
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index d5a4333d8f1f..b5943e9f95aa 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -31,7 +31,7 @@ cpumask_t irq_default_affinity = CPU_MASK_ALL;
  */
 void synchronize_irq(unsigned int irq)
 {
-	struct irq_desc *desc = irq_desc + irq;
+	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned int status;
 
 	if (irq >= nr_irqs)
@@ -64,7 +64,7 @@ EXPORT_SYMBOL(synchronize_irq);
  */
 int irq_can_set_affinity(unsigned int irq)
 {
-	struct irq_desc *desc = irq_desc + irq;
+	struct irq_desc *desc = irq_to_desc(irq);
 
 	if (CHECK_IRQ_PER_CPU(desc->status) || !desc->chip ||
 	    !desc->chip->set_affinity)
@@ -81,7 +81,7 @@ int irq_can_set_affinity(unsigned int irq)
  */
 int irq_set_affinity(unsigned int irq, cpumask_t cpumask)
 {
-	struct irq_desc *desc = irq_desc + irq;
+	struct irq_desc *desc = irq_to_desc(irq);
 
 	if (!desc->chip->set_affinity)
 		return -EINVAL;
@@ -111,14 +111,16 @@ int irq_set_affinity(unsigned int irq, cpumask_t cpumask)
 int irq_select_affinity(unsigned int irq)
 {
 	cpumask_t mask;
+	struct irq_desc *desc;
 
 	if (!irq_can_set_affinity(irq))
 		return 0;
 
 	cpus_and(mask, cpu_online_map, irq_default_affinity);
 
-	irq_desc[irq].affinity = mask;
-	irq_desc[irq].chip->set_affinity(irq, mask);
+	desc = irq_to_desc(irq);
+	desc->affinity = mask;
+	desc->chip->set_affinity(irq, mask);
 
 	set_balance_irq_affinity(irq, mask);
 	return 0;
@@ -140,7 +142,7 @@ int irq_select_affinity(unsigned int irq)
  */
 void disable_irq_nosync(unsigned int irq)
 {
-	struct irq_desc *desc = irq_desc + irq;
+	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned long flags;
 
 	if (irq >= nr_irqs)
@@ -169,7 +171,7 @@ EXPORT_SYMBOL(disable_irq_nosync);
  */
 void disable_irq(unsigned int irq)
 {
-	struct irq_desc *desc = irq_desc + irq;
+	struct irq_desc *desc = irq_to_desc(irq);
 
 	if (irq >= nr_irqs)
 		return;
@@ -211,7 +213,7 @@ static void __enable_irq(struct irq_desc *desc, unsigned int irq)
  */
 void enable_irq(unsigned int irq)
 {
-	struct irq_desc *desc = irq_desc + irq;
+	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned long flags;
 
 	if (irq >= nr_irqs)
@@ -225,7 +227,7 @@ EXPORT_SYMBOL(enable_irq);
 
 static int set_irq_wake_real(unsigned int irq, unsigned int on)
 {
-	struct irq_desc *desc = irq_desc + irq;
+	struct irq_desc *desc = irq_to_desc(irq);
 	int ret = -ENXIO;
 
 	if (desc->chip->set_wake)
@@ -248,7 +250,7 @@ static int set_irq_wake_real(unsigned int irq, unsigned int on)
  */
 int set_irq_wake(unsigned int irq, unsigned int on)
 {
-	struct irq_desc *desc = irq_desc + irq;
+	struct irq_desc *desc = irq_to_desc(irq);
 	unsigned long flags;
 	int ret = 0;
 
@@ -288,12 +290,13 @@ EXPORT_SYMBOL(set_irq_wake);
  */
 int can_request_irq(unsigned int irq, unsigned long irqflags)
 {
+	struct irq_desc *desc = irq_to_desc(irq);
 	struct irqaction *action;
 
-	if (irq >= nr_irqs || irq_desc[irq].status & IRQ_NOREQUEST)
+	if (irq >= nr_irqs || desc->status & IRQ_NOREQUEST)
 		return 0;
 
-	action = irq_desc[irq].action;
+	action = desc->action;
 	if (action)
 		if (irqflags & action->flags & IRQF_SHARED)
 			action = NULL;
@@ -349,7 +352,7 @@ int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
  */
 int setup_irq(unsigned int irq, struct irqaction *new)
 {
-	struct irq_desc *desc = irq_desc + irq;
+	struct irq_desc *desc = irq_to_desc(irq);
 	struct irqaction *old, **p;
 	const char *old_name = NULL;
 	unsigned long flags;
@@ -518,7 +521,7 @@ void free_irq(unsigned int irq, void *dev_id)
 	if (irq >= nr_irqs)
 		return;
 
-	desc = irq_desc + irq;
+	desc = irq_to_desc(irq);
 	spin_lock_irqsave(&desc->lock, flags);
 	p = &desc->action;
 	for (;;) {
@@ -615,6 +618,7 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 {
 	struct irqaction *action;
 	int retval;
+	struct irq_desc *desc;
 
 #ifdef CONFIG_LOCKDEP
 	/*
@@ -632,7 +636,8 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 		return -EINVAL;
 	if (irq >= nr_irqs)
 		return -EINVAL;
-	if (irq_desc[irq].status & IRQ_NOREQUEST)
+	desc = irq_to_desc(irq);
+	if (desc->status & IRQ_NOREQUEST)
 		return -EINVAL;
 	if (!handler)
 		return -EINVAL;

commit 85c0f90978bf50596dbd23854648020f1f9b5bfd
Author: Yinghai Lu <yhlu.kernel@gmail.com>
Date:   Tue Aug 19 20:49:47 2008 -0700

    irq: introduce nr_irqs
    
    at this point nr_irqs is equal NR_IRQS
    
    convert a few easy users from NR_IRQS to dynamic nr_irqs.
    
    v2: according to Eric, we need to take care of arch without generic_hardirqs
    
    Signed-off-by: Yinghai Lu <yhlu.kernel@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index d363f32dba7d..d5a4333d8f1f 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -34,7 +34,7 @@ void synchronize_irq(unsigned int irq)
 	struct irq_desc *desc = irq_desc + irq;
 	unsigned int status;
 
-	if (irq >= NR_IRQS)
+	if (irq >= nr_irqs)
 		return;
 
 	do {
@@ -143,7 +143,7 @@ void disable_irq_nosync(unsigned int irq)
 	struct irq_desc *desc = irq_desc + irq;
 	unsigned long flags;
 
-	if (irq >= NR_IRQS)
+	if (irq >= nr_irqs)
 		return;
 
 	spin_lock_irqsave(&desc->lock, flags);
@@ -171,7 +171,7 @@ void disable_irq(unsigned int irq)
 {
 	struct irq_desc *desc = irq_desc + irq;
 
-	if (irq >= NR_IRQS)
+	if (irq >= nr_irqs)
 		return;
 
 	disable_irq_nosync(irq);
@@ -214,7 +214,7 @@ void enable_irq(unsigned int irq)
 	struct irq_desc *desc = irq_desc + irq;
 	unsigned long flags;
 
-	if (irq >= NR_IRQS)
+	if (irq >= nr_irqs)
 		return;
 
 	spin_lock_irqsave(&desc->lock, flags);
@@ -290,7 +290,7 @@ int can_request_irq(unsigned int irq, unsigned long irqflags)
 {
 	struct irqaction *action;
 
-	if (irq >= NR_IRQS || irq_desc[irq].status & IRQ_NOREQUEST)
+	if (irq >= nr_irqs || irq_desc[irq].status & IRQ_NOREQUEST)
 		return 0;
 
 	action = irq_desc[irq].action;
@@ -356,7 +356,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 	int shared = 0;
 	int ret;
 
-	if (irq >= NR_IRQS)
+	if (irq >= nr_irqs)
 		return -EINVAL;
 
 	if (desc->chip == &no_irq_chip)
@@ -515,7 +515,7 @@ void free_irq(unsigned int irq, void *dev_id)
 	unsigned long flags;
 
 	WARN_ON(in_interrupt());
-	if (irq >= NR_IRQS)
+	if (irq >= nr_irqs)
 		return;
 
 	desc = irq_desc + irq;
@@ -630,7 +630,7 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 	 */
 	if ((irqflags & IRQF_SHARED) && !dev_id)
 		return -EINVAL;
-	if (irq >= NR_IRQS)
+	if (irq >= nr_irqs)
 		return -EINVAL;
 	if (irq_desc[irq].status & IRQ_NOREQUEST)
 		return -EINVAL;

commit 5fef06e8c8c52aa7170dbbb068aa996d83738d38
Merge: 0c5d1eb77a8b 278429cff880
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Oct 16 16:51:32 2008 +0200

    Merge branch 'linus' into genirq

commit 0c5d1eb77a8be917b638344a22afe1398236482b
Author: David Brownell <dbrownell@users.sourceforge.net>
Date:   Wed Oct 1 14:46:18 2008 -0700

    genirq: record trigger type
    
    Genirq hasn't previously recorded the trigger type used by any given IRQ,
    although some irq_chip support has done so.  That data can be useful when
    troubleshooting.  This patch records it in the relevant irq_desc.status
    bits, and improves consistency between the two driver-visible calls
    affected:
    
     - Make set_irq_type() usage match request_irq() usage:
        * IRQ_TYPE_NONE should be a NOP; succeed, so irq_chip methods
          won't have to handle that case any more (many do it wrong).
        * IRQ_TYPE_PROBE is ignored; any buggy out-of-tree callers
          might need to switch over to the real IRQ probing code.
        * emit the same diagnostics (from shared utility code)
    
     - Their kerneldoc now reflects usage:
        * request_irq() flags include IRQF_TRIGGER_* to specify
          active edge(s)/level ... docs previously omitted that
        * set_irq_type() is declared in <linux/irq.h> so callers
          should use the (bit-equivalent) IRQ_TYPE_* symbols there
    
    Also: adds a warning about shared IRQs that don't end up using the
    requested trigger mode; and fix an unrelated "sparse" warning.
    
    Signed-off-by: David Brownell <dbrownell@users.sourceforge.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index d62f69ba7453..e59157b591f8 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -216,7 +216,7 @@ void enable_irq(unsigned int irq)
 }
 EXPORT_SYMBOL(enable_irq);
 
-int set_irq_wake_real(unsigned int irq, unsigned int on)
+static int set_irq_wake_real(unsigned int irq, unsigned int on)
 {
 	struct irq_desc *desc = irq_desc + irq;
 	int ret = -ENXIO;
@@ -305,10 +305,11 @@ void compat_irq_chip_set_default_handler(struct irq_desc *desc)
 		desc->handle_irq = NULL;
 }
 
-static int __irq_set_trigger(struct irq_chip *chip, unsigned int irq,
+int __irq_set_trigger(struct irq_desc *desc, unsigned int irq,
 		unsigned long flags)
 {
 	int ret;
+	struct irq_chip *chip = desc->chip;
 
 	if (!chip || !chip->set_type) {
 		/*
@@ -326,6 +327,11 @@ static int __irq_set_trigger(struct irq_chip *chip, unsigned int irq,
 		pr_err("setting trigger mode %d for irq %u failed (%pF)\n",
 				(int)(flags & IRQF_TRIGGER_MASK),
 				irq, chip->set_type);
+	else {
+		/* note that IRQF_TRIGGER_MASK == IRQ_TYPE_SENSE_MASK */
+		desc->status &= ~IRQ_TYPE_SENSE_MASK;
+		desc->status |= flags & IRQ_TYPE_SENSE_MASK;
+	}
 
 	return ret;
 }
@@ -404,7 +410,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 
 		/* Setup the type (level, edge polarity) if configured: */
 		if (new->flags & IRQF_TRIGGER_MASK) {
-			ret = __irq_set_trigger(desc->chip, irq, new->flags);
+			ret = __irq_set_trigger(desc, irq, new->flags);
 
 			if (ret) {
 				spin_unlock_irqrestore(&desc->lock, flags);
@@ -430,6 +436,14 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 
 		/* Set default affinity mask once everything is setup */
 		irq_select_affinity(irq);
+
+	} else if ((new->flags & IRQF_TRIGGER_MASK)
+			&& (new->flags & IRQF_TRIGGER_MASK)
+				!= (desc->status & IRQ_TYPE_SENSE_MASK)) {
+		/* hope the handler works with the actual trigger mode... */
+		pr_warning("IRQ %d uses trigger mode %d; requested %d\n",
+				irq, (int)(desc->status & IRQ_TYPE_SENSE_MASK),
+				(int)(new->flags & IRQF_TRIGGER_MASK));
 	}
 
 	*p = new;
@@ -586,6 +600,7 @@ EXPORT_SYMBOL(free_irq);
  *	IRQF_SHARED		Interrupt is shared
  *	IRQF_DISABLED	Disable local interrupts while processing
  *	IRQF_SAMPLE_RANDOM	The interrupt can be used for entropy
+ *	IRQF_TRIGGER_*		Specify active edge(s) or level
  *
  */
 int request_irq(unsigned int irq, irq_handler_t handler,

commit d6d5aeb661fc14655c417f3582ae7ec52985d2a8
Merge: 7e6e178ab154 94aca1dac6f6
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Oct 2 10:21:26 2008 +0200

    Merge commit 'v2.6.27-rc8' into genirq

commit 7e6e178ab1548c8d894a77593e757acf4510b8ba
Author: Pawel MOLL <pawel.moll@st.com>
Date:   Mon Sep 1 10:12:11 2008 +0100

    genirq: irq_chip->startup() usage in setup_irq and set_irq_chained handler
    
    This patch clarifies usage of irq_chip->startup() callback:
    
    1. The "if (startup) startup(); else enabled();" code in setup_irq()
       is unnecessary, as startup() falls back to enabled() via
       default callbacks, set by irq_chip_set_defaults().
    
    2. When using set_irq_chained_handler() the startup() was never called,
       which is not good at all... Fixed. And again - when startup() is not
       defined the call will fall back to enable() than to unmask() via
       default callbacks.
    
    Signed-off-by: Pawel Moll <pawel.moll@st.com>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index ae1b684e048c..9aa3e7b81389 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -397,10 +397,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 		if (!(desc->status & IRQ_NOAUTOEN)) {
 			desc->depth = 0;
 			desc->status &= ~IRQ_DISABLED;
-			if (desc->chip->startup)
-				desc->chip->startup(irq);
-			else
-				desc->chip->enable(irq);
+			desc->chip->startup(irq);
 		} else
 			/* Undo nested disables: */
 			desc->depth = 1;

commit 377bf1e4ac2d894791733270604594c7c851ef83
Author: Anton Vorontsov <avorontsov@ru.mvista.com>
Date:   Thu Aug 21 22:58:28 2008 +0400

    genirq: fix irq_desc->depth handling with DEBUG_SHIRQ
    
    When DEBUG_SHIRQ is selected, a spurious IRQ is issued before
    the setup_irq() initializes the desc->depth. An IRQ handler may
    call disable_irq_nosync(), but then setup_irq() will overwrite
    desc->depth, and upon enable_irq() we'll catch this WARN:
    
    ------------[ cut here ]------------
    Badness at kernel/irq/manage.c:180
    NIP: c0061ab8 LR: c0061f10 CTR: 00000000
    REGS: cf83be50 TRAP: 0700   Not tainted  (2.6.27-rc3-23450-g74919b0)
    MSR: 00021032 <ME,IR,DR>  CR: 22042022  XER: 20000000
    TASK = cf829100[5] 'events/0' THREAD: cf83a000
    GPR00: c0061f10 cf83bf00 cf829100 c038e674 00000016 00000000 cf83bef8 00000038
    GPR08: c0298910 00000000 c0310d28 cf83a000 00000c9c 1001a1a8 0fffe000 00800000
    GPR16: ffffffff 00000000 007fff00 00000000 007ffeb0 c03320a0 c031095c c0310924
    GPR24: cf8292ec cf807190 cf83a000 00009032 c038e6a4 c038e674 cf99b1cc c038e674
    NIP [c0061ab8] __enable_irq+0x20/0x80
    LR [c0061f10] enable_irq+0x50/0x70
    Call Trace:
    [cf83bf00] [c038e674] irq_desc+0x630/0x9000 (unreliable)
    [cf83bf10] [c0061f10] enable_irq+0x50/0x70
    [cf83bf30] [c01abe94] phy_change+0x68/0x108
    [cf83bf50] [c0046394] run_workqueue+0xc4/0x16c
    [cf83bf90] [c0046834] worker_thread+0x74/0xd4
    [cf83bfd0] [c004ab7c] kthread+0x48/0x84
    [cf83bff0] [c00135e0] kernel_thread+0x44/0x60
    Instruction dump:
    4e800020 3d20c031 38a94214 4bffffcc 9421fff0 7c0802a6 93e1000c 7c7f1b78
    90010014 8123001c 2f890000 409e001c <0fe00000> 80010014 83e1000c 38210010
    
    That trace corresponds to this line:
    WARN(1, KERN_WARNING "Unbalanced enable for IRQ %d\n", irq);
    
    The patch fixes the problem by moving the SHIRQ code below the
    setup_irq().
    
    Unfortunately we can't easily move the SHIRQ code inside the
    setup_irq(), since it grabs a spinlock, so to prvent a 'real'
    IRQ from interfere us we should disable that IRQ.
    
    p.s. The driver in question is drivers/net/phy/phy.c.
    
    Signed-off-by: Anton Vorontsov <avorontsov@ru.mvista.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 77a51be36010..ae1b684e048c 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -596,26 +596,29 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 	action->next = NULL;
 	action->dev_id = dev_id;
 
+	retval = setup_irq(irq, action);
+	if (retval)
+		kfree(action);
+
 #ifdef CONFIG_DEBUG_SHIRQ
 	if (irqflags & IRQF_SHARED) {
 		/*
 		 * It's a shared IRQ -- the driver ought to be prepared for it
 		 * to happen immediately, so let's make sure....
-		 * We do this before actually registering it, to make sure that
-		 * a 'real' IRQ doesn't run in parallel with our fake
+		 * We disable the irq to make sure that a 'real' IRQ doesn't
+		 * run in parallel with our fake.
 		 */
 		unsigned long flags;
 
+		disable_irq(irq);
 		local_irq_save(flags);
+
 		handler(irq, dev_id);
+
 		local_irq_restore(flags);
+		enable_irq(irq);
 	}
 #endif
-
-	retval = setup_irq(irq, action);
-	if (retval)
-		kfree(action);
-
 	return retval;
 }
 EXPORT_SYMBOL(request_irq);

commit 51ca3c679194e7435c25b8e77b0a73c597e41ae9
Merge: b55793f7528c b635acec48bc
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Aug 14 14:58:01 2008 +0200

    Merge branch 'linus' into x86/core
    
    Conflicts:
            arch/x86/kernel/genapic_64.c
            include/asm-x86/kvm_host.h
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit c69ad71bcdecbaab82cfacb1dc967bd7fd967a3b
Author: David Brownell <dbrownell@users.sourceforge.net>
Date:   Tue Aug 5 13:01:14 2008 -0700

    genirq: better warning on irqchip->set_type() failure
    
    While I'm glad to finally see the hole fixed whereby passing an invalid
    IRQ trigger type to request_irq() would be ignored, the current diagnostic
    isn't quite useful.  Fixed by also listing the trigger type which was
    rejected.
    
    Signed-off-by: David Brownell <dbrownell@users.sourceforge.net>
    Acked-by: Uwe Kleine-König <Uwe.Kleine-Koenig@digi.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 152abfd3589f..0314074fa232 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -323,7 +323,8 @@ static int __irq_set_trigger(struct irq_chip *chip, unsigned int irq,
 	ret = chip->set_type(irq, flags & IRQF_TRIGGER_MASK);
 
 	if (ret)
-		pr_err("setting flow type for irq %u failed (%pF)\n",
+		pr_err("setting trigger mode %d for irq %u failed (%pF)\n",
+				(int)(flags & IRQF_TRIGGER_MASK),
 				irq, chip->set_type);
 
 	return ret;

commit 15dd859cacf312f606f54502d1f66537a1e5c78c
Merge: b2d9d33412b9 6e86841d05f3
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Jul 30 19:33:48 2008 +0200

    Merge commit 'v2.6.27-rc1' into x86/core
    
    Conflicts:
    
            include/asm-x86/dma-mapping.h
            include/asm-x86/namei.h
            include/asm-x86/uaccess.h
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit b8c512f6190e313df69060bae4a161c5c044e272
Author: Arjan van de Ven <arjan@linux.intel.com>
Date:   Fri Jul 25 19:45:36 2008 -0700

    Use WARN() in kernel/irq/manage.c
    
    Replace a printk+WARN_ON() by a WARN(); this increases the chance of the
    string making it into the bugreport (ie: it goes inside the
    ---[ cut here ]--- section)
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index f8914b92b664..152abfd3589f 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -177,8 +177,7 @@ static void __enable_irq(struct irq_desc *desc, unsigned int irq)
 {
 	switch (desc->depth) {
 	case 0:
-		printk(KERN_WARNING "Unbalanced enable for IRQ %d\n", irq);
-		WARN_ON(1);
+		WARN(1, KERN_WARNING "Unbalanced enable for IRQ %d\n", irq);
 		break;
 	case 1: {
 		unsigned int status = desc->status & ~IRQ_DISABLED;

commit 6dec3a10a7a6093af10cef7ac56021150afd6451
Merge: 29308333fbe2 10a010f6953b
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sat Jul 26 16:29:23 2008 +0200

    Merge branch 'x86/x2apic' into x86/core
    
    Conflicts:
    
            include/asm-x86/i8259.h
            include/asm-x86/msidef.h
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 7a2c477069fbd32f91598f05334003979b987a39
Author: Arjan van de Ven <arjan@linux.intel.com>
Date:   Fri Jul 25 01:45:54 2008 -0700

    kernel/irq/manage.c: replace a printk + WARN_ON() to a WARN()
    
    Replace a printk+WARN_ON() by a WARN(); this increases the chance of the
    string making it into the bugreport (ie: it goes inside the
    ---[ cut here ]--- section)
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 5bc6e5ecc493..f8914b92b664 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -260,9 +260,7 @@ int set_irq_wake(unsigned int irq, unsigned int on)
 		}
 	} else {
 		if (desc->wake_depth == 0) {
-			printk(KERN_WARNING "Unbalanced IRQ %d "
-					"wake disable\n", irq);
-			WARN_ON(1);
+			WARN(1, "Unbalanced IRQ %d wake disable\n", irq);
 		} else if (--desc->wake_depth == 0) {
 			ret = set_irq_wake_real(irq, on);
 			if (ret)

commit 10a010f6953b5a14ba2f0be40a4fce1bea220875
Merge: 510b37258dfd fb2e405fc1fc
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Jul 25 13:08:16 2008 +0200

    Merge branch 'linus' into x86/x2apic
    
    Conflicts:
    
            drivers/pci/dmar.c
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 82736f4d1d2b7063b829cc93171a6e5aea8a9c49
Author: Uwe Kleine-König <Uwe.Kleine-Koenig@digi.com>
Date:   Wed Jul 23 21:28:54 2008 -0700

    generic irqs: handle failure of irqchip->set_type in setup_irq
    
    set_type returns an int indicating success or failure, but up to now
    setup_irq ignores that.
    
    In my case this resulted in a machine hang:
    
    gpio-keys requested IRQF_TRIGGER_RISING | IRQF_TRIGGER_FALLING, but
    arm/ns9xxx can only trigger on one direction so set_type didn't touch
    the configuration which happens do default to a level sensitiveness and
    returned -EINVAL.  setup_irq ignored that and unmasked the irq.  This
    resulted in an endless triggering of the gpio-key interrupt service
    routine which effectively killed the machine.
    
    With this patch applied setup_irq propagates the error to the caller.
    
    Note that before in the case
    
            chip && !chip->set_type && !chip->name
    
    a NULL pointer was feed to printk.  This is fixed, too.
    
    Signed-off-by: Uwe Kleine-König <Uwe.Kleine-Koenig@digi.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 3cfc0fefb5ee..5bc6e5ecc493 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -308,6 +308,30 @@ void compat_irq_chip_set_default_handler(struct irq_desc *desc)
 		desc->handle_irq = NULL;
 }
 
+static int __irq_set_trigger(struct irq_chip *chip, unsigned int irq,
+		unsigned long flags)
+{
+	int ret;
+
+	if (!chip || !chip->set_type) {
+		/*
+		 * IRQF_TRIGGER_* but the PIC does not support multiple
+		 * flow-types?
+		 */
+		pr_warning("No set_type function for IRQ %d (%s)\n", irq,
+				chip ? (chip->name ? : "unknown") : "unknown");
+		return 0;
+	}
+
+	ret = chip->set_type(irq, flags & IRQF_TRIGGER_MASK);
+
+	if (ret)
+		pr_err("setting flow type for irq %u failed (%pF)\n",
+				irq, chip->set_type);
+
+	return ret;
+}
+
 /*
  * Internal function to register an irqaction - typically used to
  * allocate special interrupts that are part of the architecture.
@@ -319,6 +343,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 	const char *old_name = NULL;
 	unsigned long flags;
 	int shared = 0;
+	int ret;
 
 	if (irq >= NR_IRQS)
 		return -EINVAL;
@@ -376,35 +401,23 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 		shared = 1;
 	}
 
-	*p = new;
-
-	/* Exclude IRQ from balancing */
-	if (new->flags & IRQF_NOBALANCING)
-		desc->status |= IRQ_NO_BALANCING;
-
 	if (!shared) {
 		irq_chip_set_defaults(desc->chip);
 
-#if defined(CONFIG_IRQ_PER_CPU)
-		if (new->flags & IRQF_PERCPU)
-			desc->status |= IRQ_PER_CPU;
-#endif
-
 		/* Setup the type (level, edge polarity) if configured: */
 		if (new->flags & IRQF_TRIGGER_MASK) {
-			if (desc->chip->set_type)
-				desc->chip->set_type(irq,
-						new->flags & IRQF_TRIGGER_MASK);
-			else
-				/*
-				 * IRQF_TRIGGER_* but the PIC does not support
-				 * multiple flow-types?
-				 */
-				printk(KERN_WARNING "No IRQF_TRIGGER set_type "
-				       "function for IRQ %d (%s)\n", irq,
-				       desc->chip->name);
+			ret = __irq_set_trigger(desc->chip, irq, new->flags);
+
+			if (ret) {
+				spin_unlock_irqrestore(&desc->lock, flags);
+				return ret;
+			}
 		} else
 			compat_irq_chip_set_default_handler(desc);
+#if defined(CONFIG_IRQ_PER_CPU)
+		if (new->flags & IRQF_PERCPU)
+			desc->status |= IRQ_PER_CPU;
+#endif
 
 		desc->status &= ~(IRQ_AUTODETECT | IRQ_WAITING |
 				  IRQ_INPROGRESS | IRQ_SPURIOUS_DISABLED);
@@ -423,6 +436,13 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 		/* Set default affinity mask once everything is setup */
 		irq_select_affinity(irq);
 	}
+
+	*p = new;
+
+	/* Exclude IRQ from balancing */
+	if (new->flags & IRQF_NOBALANCING)
+		desc->status |= IRQ_NO_BALANCING;
+
 	/* Reset broken irq detection when installing new handler */
 	desc->irq_count = 0;
 	desc->irqs_unhandled = 0;

commit 2db873211ba47ef704c301f9ecf4a33413a0b649
Author: Uwe Kleine-König <Uwe.Kleine-Koenig@digi.com>
Date:   Wed Jul 23 14:42:25 2008 +0200

    set_irq_wake: fix return code and wake status tracking
    
    Since 15a647eba94c3da27ccc666bea72e7cca06b2d19 set_irq_wake returned -ENXIO
    if another device had it already enabled.  Zero is the right value to
    return in this case.  Moreover the change to desc->status was not reverted
    if desc->chip->set_wake returned an error.
    
    Signed-off-by: Uwe Kleine-König <Uwe.Kleine-Koenig@digi.com>
    Acked-by: David Brownell <dbrownell@users.sourceforge.net>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 77a51be36010..3cfc0fefb5ee 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -217,6 +217,17 @@ void enable_irq(unsigned int irq)
 }
 EXPORT_SYMBOL(enable_irq);
 
+int set_irq_wake_real(unsigned int irq, unsigned int on)
+{
+	struct irq_desc *desc = irq_desc + irq;
+	int ret = -ENXIO;
+
+	if (desc->chip->set_wake)
+		ret = desc->chip->set_wake(irq, on);
+
+	return ret;
+}
+
 /**
  *	set_irq_wake - control irq power management wakeup
  *	@irq:	interrupt to control
@@ -233,30 +244,34 @@ int set_irq_wake(unsigned int irq, unsigned int on)
 {
 	struct irq_desc *desc = irq_desc + irq;
 	unsigned long flags;
-	int ret = -ENXIO;
-	int (*set_wake)(unsigned, unsigned) = desc->chip->set_wake;
+	int ret = 0;
 
 	/* wakeup-capable irqs can be shared between drivers that
 	 * don't need to have the same sleep mode behaviors.
 	 */
 	spin_lock_irqsave(&desc->lock, flags);
 	if (on) {
-		if (desc->wake_depth++ == 0)
-			desc->status |= IRQ_WAKEUP;
-		else
-			set_wake = NULL;
+		if (desc->wake_depth++ == 0) {
+			ret = set_irq_wake_real(irq, on);
+			if (ret)
+				desc->wake_depth = 0;
+			else
+				desc->status |= IRQ_WAKEUP;
+		}
 	} else {
 		if (desc->wake_depth == 0) {
 			printk(KERN_WARNING "Unbalanced IRQ %d "
 					"wake disable\n", irq);
 			WARN_ON(1);
-		} else if (--desc->wake_depth == 0)
-			desc->status &= ~IRQ_WAKEUP;
-		else
-			set_wake = NULL;
+		} else if (--desc->wake_depth == 0) {
+			ret = set_irq_wake_real(irq, on);
+			if (ret)
+				desc->wake_depth = 1;
+			else
+				desc->status &= ~IRQ_WAKEUP;
+		}
 	}
-	if (set_wake)
-		ret = desc->chip->set_wake(irq, on);
+
 	spin_unlock_irqrestore(&desc->lock, flags);
 	return ret;
 }

commit a208f37a465e222218974ab20a31b42b7b4893b2
Merge: 511d9d341836 5b664cb235e9
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Jul 18 22:50:34 2008 +0200

    Merge branch 'linus' into x86/x2apic

commit 72b1e22dfcad1daca6906148fd956ffe404bb0bc
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Thu Jul 10 11:16:45 2008 -0700

    x64, x2apic/intr-remap: generic irq migration support from process context
    
    Generic infrastructure for migrating the irq from the process context in the
    presence of CONFIG_GENERIC_PENDING_IRQ.
    
    This will be used later for migrating irq in the presence of
    interrupt-remapping.
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: akpm@linux-foundation.org
    Cc: arjan@linux.intel.com
    Cc: andi@firstfloor.org
    Cc: ebiederm@xmission.com
    Cc: jbarnes@virtuousgeek.org
    Cc: steiner@sgi.com
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 46d6611a33bb..628b5572a7c2 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -87,7 +87,14 @@ int irq_set_affinity(unsigned int irq, cpumask_t cpumask)
 	set_balance_irq_affinity(irq, cpumask);
 
 #ifdef CONFIG_GENERIC_PENDING_IRQ
-	set_pending_irq(irq, cpumask);
+	if (desc->status & IRQ_MOVE_PCNTXT) {
+		unsigned long flags;
+
+		spin_lock_irqsave(&desc->lock, flags);
+		desc->chip->set_affinity(irq, cpumask);
+		spin_unlock_irqrestore(&desc->lock, flags);
+	} else
+		set_pending_irq(irq, cpumask);
 #else
 	desc->affinity = cpumask;
 	desc->chip->set_affinity(irq, cpumask);

commit 48627d8d23c34106c1365563604739a50343edaf
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Jul 10 07:01:13 2008 +0200

    genirq: remove extraneous checks in manage.c
    
    In http://bugzilla.kernel.org/show_bug.cgi?id=9580 it was pointed out
    that the desc->chip checks are extraneous. In fact these are left
    overs from early development and can be removed safely.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 469814e9b9ee..77a51be36010 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -377,7 +377,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 
 		/* Setup the type (level, edge polarity) if configured: */
 		if (new->flags & IRQF_TRIGGER_MASK) {
-			if (desc->chip && desc->chip->set_type)
+			if (desc->chip->set_type)
 				desc->chip->set_type(irq,
 						new->flags & IRQF_TRIGGER_MASK);
 			else
@@ -387,8 +387,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 				 */
 				printk(KERN_WARNING "No IRQF_TRIGGER set_type "
 				       "function for IRQ %d (%s)\n", irq,
-				       desc->chip ? desc->chip->name :
-				       "unknown");
+				       desc->chip->name);
 		} else
 			compat_irq_chip_set_default_handler(desc);
 

commit 18404756765c713a0be4eb1082920c04822ce588
Author: Max Krasnyansky <maxk@qualcomm.com>
Date:   Thu May 29 11:02:52 2008 -0700

    genirq: Expose default irq affinity mask (take 3)
    
    Current IRQ affinity interface does not provide a way to set affinity
    for the IRQs that will be allocated/activated in the future.
    This patch creates /proc/irq/default_smp_affinity that lets users set
    default affinity mask for the newly allocated IRQs. Changing the default
    does not affect affinity masks for the currently active IRQs, they
    have to be changed explicitly.
    
    Updated based on Paul J's comments and added some more documentation.
    
    Signed-off-by: Max Krasnyansky <maxk@qualcomm.com>
    Cc: pj@sgi.com
    Cc: a.p.zijlstra@chello.nl
    Cc: tglx@linutronix.de
    Cc: rdunlap@xenotime.net
    Cc: mingo@elte.hu
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 46d6611a33bb..469814e9b9ee 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -17,6 +17,8 @@
 
 #ifdef CONFIG_SMP
 
+cpumask_t irq_default_affinity = CPU_MASK_ALL;
+
 /**
  *	synchronize_irq - wait for pending IRQ handlers (on other CPUs)
  *	@irq: interrupt number to wait for
@@ -95,6 +97,27 @@ int irq_set_affinity(unsigned int irq, cpumask_t cpumask)
 	return 0;
 }
 
+#ifndef CONFIG_AUTO_IRQ_AFFINITY
+/*
+ * Generic version of the affinity autoselector.
+ */
+int irq_select_affinity(unsigned int irq)
+{
+	cpumask_t mask;
+
+	if (!irq_can_set_affinity(irq))
+		return 0;
+
+	cpus_and(mask, cpu_online_map, irq_default_affinity);
+
+	irq_desc[irq].affinity = mask;
+	irq_desc[irq].chip->set_affinity(irq, mask);
+
+	set_balance_irq_affinity(irq, mask);
+	return 0;
+}
+#endif
+
 #endif
 
 /**
@@ -382,6 +405,9 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 		} else
 			/* Undo nested disables: */
 			desc->depth = 1;
+
+		/* Set default affinity mask once everything is setup */
+		irq_select_affinity(irq);
 	}
 	/* Reset broken irq detection when installing new handler */
 	desc->irq_count = 0;
@@ -571,8 +597,6 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 	action->next = NULL;
 	action->dev_id = dev_id;
 
-	select_smp_affinity(irq);
-
 #ifdef CONFIG_DEBUG_SHIRQ
 	if (irqflags & IRQF_SHARED) {
 		/*

commit 1adb0850a1254333d81e64121c80af100c6d6e06
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Apr 28 17:01:56 2008 +0200

    genirq: reenable a nobody cared disabled irq when a new driver arrives
    
    Uwe Kleine-Koenig has some strange hardware where one of the shared
    interrupts can be asserted during boot before the appropriate driver
    loads. Requesting the shared irq line from another driver result in a
    spurious interrupt storm which finally disables the interrupt line.
    
    I have seen similar behaviour on resume before (the hardware does not
    work anymore so I can not verify).
    
    Change the spurious disable logic to increment the disable depth and
    mark the interrupt with an extra flag which allows us to reenable the
    interrupt when a new driver arrives which requests the same irq
    line. In the worst case this will disable the irq again via the
    spurious trap, but there is a decent chance that the new driver is the
    one which can handle the already asserted interrupt and makes the box
    usable again.
    
    Eric Biederman said further: This case also happens on a regular basis
    in kdump kernels where we deliberately don't shutdown the hardware
    before starting the new kernel.  This patch should reduce the need for
    using irqpoll in that situation by a small amount.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-and-Acked-by: Uwe Kleine-König <Uwe.Kleine-Koenig@digi.com>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 46e4ad1723f0..46d6611a33bb 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -150,6 +150,26 @@ void disable_irq(unsigned int irq)
 }
 EXPORT_SYMBOL(disable_irq);
 
+static void __enable_irq(struct irq_desc *desc, unsigned int irq)
+{
+	switch (desc->depth) {
+	case 0:
+		printk(KERN_WARNING "Unbalanced enable for IRQ %d\n", irq);
+		WARN_ON(1);
+		break;
+	case 1: {
+		unsigned int status = desc->status & ~IRQ_DISABLED;
+
+		/* Prevent probing on this irq: */
+		desc->status = status | IRQ_NOPROBE;
+		check_irq_resend(desc, irq);
+		/* fall-through */
+	}
+	default:
+		desc->depth--;
+	}
+}
+
 /**
  *	enable_irq - enable handling of an irq
  *	@irq: Interrupt to enable
@@ -169,22 +189,7 @@ void enable_irq(unsigned int irq)
 		return;
 
 	spin_lock_irqsave(&desc->lock, flags);
-	switch (desc->depth) {
-	case 0:
-		printk(KERN_WARNING "Unbalanced enable for IRQ %d\n", irq);
-		WARN_ON(1);
-		break;
-	case 1: {
-		unsigned int status = desc->status & ~IRQ_DISABLED;
-
-		/* Prevent probing on this irq: */
-		desc->status = status | IRQ_NOPROBE;
-		check_irq_resend(desc, irq);
-		/* fall-through */
-	}
-	default:
-		desc->depth--;
-	}
+	__enable_irq(desc, irq);
 	spin_unlock_irqrestore(&desc->lock, flags);
 }
 EXPORT_SYMBOL(enable_irq);
@@ -365,7 +370,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 			compat_irq_chip_set_default_handler(desc);
 
 		desc->status &= ~(IRQ_AUTODETECT | IRQ_WAITING |
-				  IRQ_INPROGRESS);
+				  IRQ_INPROGRESS | IRQ_SPURIOUS_DISABLED);
 
 		if (!(desc->status & IRQ_NOAUTOEN)) {
 			desc->depth = 0;
@@ -381,6 +386,16 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 	/* Reset broken irq detection when installing new handler */
 	desc->irq_count = 0;
 	desc->irqs_unhandled = 0;
+
+	/*
+	 * Check whether we disabled the irq via the spurious handler
+	 * before. Reenable it and give it another chance.
+	 */
+	if (shared && (desc->status & IRQ_SPURIOUS_DISABLED)) {
+		desc->status &= ~IRQ_SPURIOUS_DISABLED;
+		__enable_irq(desc, irq);
+	}
+
 	spin_unlock_irqrestore(&desc->lock, flags);
 
 	new->irq = irq;

commit 1aeb272cf09f9e2cbc62163b9f37a9b4d1c7e81d
Author: Robert P. J. Day <rpjday@crashcourse.ca>
Date:   Tue Apr 29 00:59:25 2008 -0700

    kernel: explicitly include required header files under kernel/
    
    Following an experimental deletion of the unnecessary directive
    
     #include <linux/slab.h>
    
    from the header file <linux/percpu.h>, these files under kernel/ were exposed
    as needing to include one of <linux/slab.h> or <linux/gfp.h>, so explicit
    includes were added where necessary.
    
    Signed-off-by: Robert P. J. Day <rpjday@crashcourse.ca>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 438a01464287..46e4ad1723f0 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -11,6 +11,7 @@
 #include <linux/module.h>
 #include <linux/random.h>
 #include <linux/interrupt.h>
+#include <linux/slab.h>
 
 #include "internals.h"
 

commit 70edcd77a0d6d0f8731c826764f5eb6732f521e9
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Jan 30 13:33:24 2008 +0100

    genirq: stackdump after the "Trying to free already-free IRQ" message
    
    these bugs are harder to find than they seem, a stackdump helps.
    
    make it dependent on CONFIG_DEBUG_SHIRQ so that people can turn it off
    if it annoys them.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 1f314221d534..438a01464287 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -479,6 +479,9 @@ void free_irq(unsigned int irq, void *dev_id)
 			return;
 		}
 		printk(KERN_ERR "Trying to free already-free IRQ %d\n", irq);
+#ifdef CONFIG_DEBUG_SHIRQ
+		dump_stack();
+#endif
 		spin_unlock_irqrestore(&desc->lock, flags);
 		return;
 	}

commit a98ce5c6feead6bfedefabd46cb3d7f5be148d9a
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Oct 23 11:26:25 2007 +0800

    Fix synchronize_irq races with IRQ handler
    
    As it is some callers of synchronize_irq rely on memory barriers
    to provide synchronisation against the IRQ handlers.  For example,
    the tg3 driver does
    
            tp->irq_sync = 1;
            smp_mb();
            synchronize_irq();
    
    and then in the IRQ handler:
    
            if (!tp->irq_sync)
                    netif_rx_schedule(dev, &tp->napi);
    
    Unfortunately memory barriers only work well when they come in
    pairs.  Because we don't actually have memory barriers on the
    IRQ path, the memory barrier before the synchronize_irq() doesn't
    actually protect us.
    
    In particular, synchronize_irq() may return followed by the
    result of netif_rx_schedule being made visible.
    
    This patch (mostly written by Linus) fixes this by using spin
    locks instead of memory barries on the synchronize_irq() path.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 80eab7a04205..1f314221d534 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -29,12 +29,28 @@
 void synchronize_irq(unsigned int irq)
 {
 	struct irq_desc *desc = irq_desc + irq;
+	unsigned int status;
 
 	if (irq >= NR_IRQS)
 		return;
 
-	while (desc->status & IRQ_INPROGRESS)
-		cpu_relax();
+	do {
+		unsigned long flags;
+
+		/*
+		 * Wait until we're out of the critical section.  This might
+		 * give the wrong answer due to the lack of memory barriers.
+		 */
+		while (desc->status & IRQ_INPROGRESS)
+			cpu_relax();
+
+		/* Ok, that indicated we're done: double-check carefully. */
+		spin_lock_irqsave(&desc->lock, flags);
+		status = desc->status;
+		spin_unlock_irqrestore(&desc->lock, flags);
+
+		/* Oops, that failed? */
+	} while (status & IRQ_INPROGRESS);
 }
 EXPORT_SYMBOL(synchronize_irq);
 

commit 1d99493b3a68e40e56459ea3565d4402fb6e5f3a
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Tue Oct 16 23:26:29 2007 -0700

    Fix CONFIG_DEBUG_SHIRQ trigger on free_irq()
    
    Andy Gospodarek pointed out that because we return in the middle of the
    free_irq() function, we never actually do call the IRQ handler that just
    got deregistered. This should fix it, although I expect Andrew will want
    to convert those 'return's to 'break'. That's a separate change though.
    
    Signed-off-by: David Woodhouse <dwmw2@infradead.org>
    Cc: Andy Gospodarek <andy@greyhouse.net>
    Cc: Fernando Luis Vzquez Cao <fernando@oss.ntt.co.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 7230d914eaa2..80eab7a04205 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -405,7 +405,6 @@ void free_irq(unsigned int irq, void *dev_id)
 	struct irq_desc *desc;
 	struct irqaction **p;
 	unsigned long flags;
-	irqreturn_t (*handler)(int, void *) = NULL;
 
 	WARN_ON(in_interrupt());
 	if (irq >= NR_IRQS)
@@ -445,8 +444,21 @@ void free_irq(unsigned int irq, void *dev_id)
 
 			/* Make sure it's not being used on another CPU */
 			synchronize_irq(irq);
-			if (action->flags & IRQF_SHARED)
-				handler = action->handler;
+#ifdef CONFIG_DEBUG_SHIRQ
+			/*
+			 * It's a shared IRQ -- the driver ought to be
+			 * prepared for it to happen even now it's
+			 * being freed, so let's make sure....  We do
+			 * this after actually deregistering it, to
+			 * make sure that a 'real' IRQ doesn't run in
+			 * parallel with our fake
+			 */
+			if (action->flags & IRQF_SHARED) {
+				local_irq_save(flags);
+				action->handler(irq, dev_id);
+				local_irq_restore(flags);
+			}
+#endif
 			kfree(action);
 			return;
 		}
@@ -454,19 +466,6 @@ void free_irq(unsigned int irq, void *dev_id)
 		spin_unlock_irqrestore(&desc->lock, flags);
 		return;
 	}
-#ifdef CONFIG_DEBUG_SHIRQ
-	if (handler) {
-		/*
-		 * It's a shared IRQ -- the driver ought to be prepared for it
-		 * to happen even now it's being freed, so let's make sure....
-		 * We do this after actually deregistering it, to make sure that
-		 * a 'real' IRQ doesn't run in parallel with our fake
-		 */
-		local_irq_save(flags);
-		handler(irq, dev_id);
-		local_irq_restore(flags);
-	}
-#endif
 }
 EXPORT_SYMBOL(free_irq);
 

commit 59845b1ffd9121e5ef474ea5f27405fd7a83c85b
Author: Jarek Poplawski <jarkao2@o2.pl>
Date:   Thu Aug 30 23:56:34 2007 -0700

    request_irq: fix DEBUG_SHIRQ handling
    
    Mariusz Kozlowski reported lockdep's warning:
    
    > =================================
    > [ INFO: inconsistent lock state ]
    > 2.6.23-rc2-mm1 #7
    > ---------------------------------
    > inconsistent {in-hardirq-W} -> {hardirq-on-W} usage.
    > ifconfig/5492 [HC0[0]:SC0[0]:HE1:SE1] takes:
    >  (&tp->lock){+...}, at: [<de8706e0>] rtl8139_interrupt+0x27/0x46b [8139too]
    > {in-hardirq-W} state was registered at:
    >   [<c0138eeb>] __lock_acquire+0x949/0x11ac
    >   [<c01397e7>] lock_acquire+0x99/0xb2
    >   [<c0452ff3>] _spin_lock+0x35/0x42
    >   [<de8706e0>] rtl8139_interrupt+0x27/0x46b [8139too]
    >   [<c0147a5d>] handle_IRQ_event+0x28/0x59
    >   [<c01493ca>] handle_level_irq+0xad/0x10b
    >   [<c0105a13>] do_IRQ+0x93/0xd0
    >   [<c010441e>] common_interrupt+0x2e/0x34
    ...
    > other info that might help us debug this:
    > 1 lock held by ifconfig/5492:
    >  #0:  (rtnl_mutex){--..}, at: [<c0451778>] mutex_lock+0x1c/0x1f
    >
    > stack backtrace:
    ...
    >  [<c0452ff3>] _spin_lock+0x35/0x42
    >  [<de8706e0>] rtl8139_interrupt+0x27/0x46b [8139too]
    >  [<c01480fd>] free_irq+0x11b/0x146
    >  [<de871d59>] rtl8139_close+0x8a/0x14a [8139too]
    >  [<c03bde63>] dev_close+0x57/0x74
    ...
    
    This shows that a driver's irq handler was running both in hard interrupt
    and process contexts with irqs enabled. The latter was done during
    free_irq() call and was possible only with CONFIG_DEBUG_SHIRQ enabled.
    This was fixed by another patch.
    
    But similar problem is possible with request_irq(): any locks taken from
    irq handler could be vulnerable - especially with soft interrupts. This
    patch fixes it by disabling local interrupts during handler's run. (It
    seems, disabling softirqs should be enough, but it needs more checking
    on possible races or other special cases).
    
    Reported-by: Mariusz Kozlowski <m.kozlowski@tuxland.pl>
    Signed-off-by: Jarek Poplawski <jarkao2@o2.pl>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 853aefbd184b..7230d914eaa2 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -547,14 +547,11 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 		 * We do this before actually registering it, to make sure that
 		 * a 'real' IRQ doesn't run in parallel with our fake
 		 */
-		if (irqflags & IRQF_DISABLED) {
-			unsigned long flags;
+		unsigned long flags;
 
-			local_irq_save(flags);
-			handler(irq, dev_id);
-			local_irq_restore(flags);
-		} else
-			handler(irq, dev_id);
+		local_irq_save(flags);
+		handler(irq, dev_id);
+		local_irq_restore(flags);
 	}
 #endif
 

commit 8b7f07155f8ee1536da2f9590f1aa9383afefb6b
Author: Andrew Morton <akpm@linux-foundation.org>
Date:   Wed Aug 22 14:01:20 2007 -0700

    free_irq(): fix DEBUG_SHIRQ handling
    
    If we're going to run the handler from free_irq() then we must do it with
    local irq's disabled.  Otherwise lockdep complains that the handler is taking
    irq-safe spinlocks in a non-irq-safe fashion.
    
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 203a518b6f14..853aefbd184b 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -462,7 +462,9 @@ void free_irq(unsigned int irq, void *dev_id)
 		 * We do this after actually deregistering it, to make sure that
 		 * a 'real' IRQ doesn't run in parallel with our fake
 		 */
+		local_irq_save(flags);
 		handler(irq, dev_id);
+		local_irq_restore(flags);
 	}
 #endif
 }

commit f75d222b836f7febfab0954c7612b23059d748cb
Author: Ahmed S. Darwish <darwish.07@gmail.com>
Date:   Tue May 8 00:27:55 2007 -0700

    IRQ: check for PERCPU flag only when adding first irqaction
    
    An irqaction structure won't be added to an IRQ descriptor irqaction list if
    it doesn't agree with other irqactions on the IRQF_PERCPU flag.  Don't check
    for this flag to change IRQ descriptor `status' for every irqaction added to
    the list, Doing the check only for the first irqaction added is enough.
    
    Signed-off-by: Ahmed S. Darwish <darwish.07@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 5597c157442a..203a518b6f14 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -317,10 +317,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 	}
 
 	*p = new;
-#if defined(CONFIG_IRQ_PER_CPU)
-	if (new->flags & IRQF_PERCPU)
-		desc->status |= IRQ_PER_CPU;
-#endif
+
 	/* Exclude IRQ from balancing */
 	if (new->flags & IRQF_NOBALANCING)
 		desc->status |= IRQ_NO_BALANCING;
@@ -328,6 +325,11 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 	if (!shared) {
 		irq_chip_set_defaults(desc->chip);
 
+#if defined(CONFIG_IRQ_PER_CPU)
+		if (new->flags & IRQF_PERCPU)
+			desc->status |= IRQ_PER_CPU;
+#endif
+
 		/* Setup the type (level, edge polarity) if configured: */
 		if (new->flags & IRQF_TRIGGER_MASK) {
 			if (desc->chip && desc->chip->set_type)

commit 771ee3b04eaac6184312825eb600b4c598f027a5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Feb 16 01:27:25 2007 -0800

    [PATCH] Add a function to handle interrupt affinity setting
    
    Provide funtions to:
     - check, whether an interrupt can set the affinity
     - pin the interrupt to a given cpu
    
    Necessary for the ability to setup clocksources more flexible (e.g.  use the
    different HPET channels per CPU)
    
    [akpm@osdl.org: alpha build fix]
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Cc: john stultz <johnstul@us.ibm.com>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index cd790ad0ae57..5597c157442a 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -38,6 +38,46 @@ void synchronize_irq(unsigned int irq)
 }
 EXPORT_SYMBOL(synchronize_irq);
 
+/**
+ *	irq_can_set_affinity - Check if the affinity of a given irq can be set
+ *	@irq:		Interrupt to check
+ *
+ */
+int irq_can_set_affinity(unsigned int irq)
+{
+	struct irq_desc *desc = irq_desc + irq;
+
+	if (CHECK_IRQ_PER_CPU(desc->status) || !desc->chip ||
+	    !desc->chip->set_affinity)
+		return 0;
+
+	return 1;
+}
+
+/**
+ *	irq_set_affinity - Set the irq affinity of a given irq
+ *	@irq:		Interrupt to set affinity
+ *	@cpumask:	cpumask
+ *
+ */
+int irq_set_affinity(unsigned int irq, cpumask_t cpumask)
+{
+	struct irq_desc *desc = irq_desc + irq;
+
+	if (!desc->chip->set_affinity)
+		return -EINVAL;
+
+	set_balance_irq_affinity(irq, cpumask);
+
+#ifdef CONFIG_GENERIC_PENDING_IRQ
+	set_pending_irq(irq, cpumask);
+#else
+	desc->affinity = cpumask;
+	desc->chip->set_affinity(irq, cpumask);
+#endif
+	return 0;
+}
+
 #endif
 
 /**

commit 950f4427c2ddc921164088a20f01304cf231437c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Feb 16 01:27:24 2007 -0800

    [PATCH] Add irq flag to disable balancing for an interrupt
    
    Add a flag so we can prevent the irq balancing of an interrupt.  Move the
    bits, so we have room for more :)
    
    Necessary for the ability to setup clocksources more flexible (e.g.  use the
    different HPET channels per CPU)
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Cc: john stultz <johnstul@us.ibm.com>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index acc5d9fe462b..cd790ad0ae57 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -281,6 +281,10 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 	if (new->flags & IRQF_PERCPU)
 		desc->status |= IRQ_PER_CPU;
 #endif
+	/* Exclude IRQ from balancing */
+	if (new->flags & IRQF_NOBALANCING)
+		desc->status |= IRQ_NO_BALANCING;
+
 	if (!shared) {
 		irq_chip_set_defaults(desc->chip);
 

commit 38515e908ba3a9c467ad3bf347b9bce69216df94
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Feb 14 00:33:16 2007 -0800

    [PATCH] Scheduled removal of SA_xxx interrupt flags fixups
    
    The obsolete SA_xxx interrupt flags have been used despite the scheduled
    removal.  Fixup the remaining users.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Jeff Garzik <jeff@garzik.org>
    Cc: Wim Van Sebroeck <wim@iguana.be>
    Cc: Roland Dreier <rolandd@cisco.com>
    Cc: Alessandro Zummo <a.zummo@towertech.it>
    Cc: James Bottomley <James.Bottomley@steeleye.com>
    Cc: Greg KH <greg@kroah.com>
    Cc: Dave Airlie <airlied@linux.ie>
    Cc: James Simmons <jsimmons@infradead.org>
    Cc: "Antonino A. Daplas" <adaplas@pol.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 7c85d69188ef..acc5d9fe462b 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -461,7 +461,7 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 	/*
 	 * Lockdep wants atomic interrupt handlers:
 	 */
-	irqflags |= SA_INTERRUPT;
+	irqflags |= IRQF_DISABLED;
 #endif
 	/*
 	 * Sanity-check: shared interrupts must pass in a real dev-ID,

commit 3f0504471536a2b6978b9a99ed1c222950fff07a
Author: Alan Cox <alan@lxorguk.ukuu.org.uk>
Date:   Mon Feb 12 00:52:04 2007 -0800

    [PATCH] kernel: shut up the IRQ mismatch messages
    
    The problem is various drivers legally validly and sensibly try to claim
    IRQs but the kernel insists on vomiting forth a giant irrelevant debugging
    spew when the types clash.
    
    Edit kernel/irq/manage.c go down to mismatch: in setup_irq() and ifdef out
    the if clause that checks for mismatches.  It'll then just do the right
    thing and work sanely.
    
    For the current -mm kernel this will do the trick (and moves it into shared
    irq debugging as in debug mode the info spew is useful).  I've had a
    variant of this in my private tree for some time as I got fed up on the
    mess on boxes where old legacy IRQs get reused.
    
    Signed-off-by: Alan Cox <alan@redhat.com>
    Cc: Arjan van de Ven <arjan@infradead.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 400b12a63649..7c85d69188ef 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -328,12 +328,14 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 	return 0;
 
 mismatch:
+#ifdef CONFIG_DEBUG_SHIRQ
 	if (!(new->flags & IRQF_PROBE_SHARED)) {
 		printk(KERN_ERR "IRQ handler type mismatch for IRQ %d\n", irq);
 		if (old_name)
 			printk(KERN_ERR "current handler: %s\n", old_name);
 		dump_stack();
 	}
+#endif
 	spin_unlock_irqrestore(&desc->lock, flags);
 	return -EBUSY;
 }

commit a304e1b82808904c561b7b149b467e338c53fcce
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Mon Feb 12 00:52:00 2007 -0800

    [PATCH] Debug shared irqs
    
    Drivers registering IRQ handlers with SA_SHIRQ really ought to be able to
    handle an interrupt happening before request_irq() returns.  They also
    ought to be able to handle an interrupt happening during the start of their
    call to free_irq().  Let's test that hypothesis....
    
    [bunk@stusta.de: Kconfig fixes]
    Signed-off-by: David Woodhouse <dwmw2@infradead.org>
    Cc: Arjan van de Ven <arjan@infradead.org>
    Signed-off-by: Jesper Juhl <jesper.juhl@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 8b961adc3bd2..400b12a63649 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -357,6 +357,7 @@ void free_irq(unsigned int irq, void *dev_id)
 	struct irq_desc *desc;
 	struct irqaction **p;
 	unsigned long flags;
+	irqreturn_t (*handler)(int, void *) = NULL;
 
 	WARN_ON(in_interrupt());
 	if (irq >= NR_IRQS)
@@ -396,6 +397,8 @@ void free_irq(unsigned int irq, void *dev_id)
 
 			/* Make sure it's not being used on another CPU */
 			synchronize_irq(irq);
+			if (action->flags & IRQF_SHARED)
+				handler = action->handler;
 			kfree(action);
 			return;
 		}
@@ -403,6 +406,17 @@ void free_irq(unsigned int irq, void *dev_id)
 		spin_unlock_irqrestore(&desc->lock, flags);
 		return;
 	}
+#ifdef CONFIG_DEBUG_SHIRQ
+	if (handler) {
+		/*
+		 * It's a shared IRQ -- the driver ought to be prepared for it
+		 * to happen even now it's being freed, so let's make sure....
+		 * We do this after actually deregistering it, to make sure that
+		 * a 'real' IRQ doesn't run in parallel with our fake
+		 */
+		handler(irq, dev_id);
+	}
+#endif
 }
 EXPORT_SYMBOL(free_irq);
 
@@ -475,6 +489,25 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 
 	select_smp_affinity(irq);
 
+#ifdef CONFIG_DEBUG_SHIRQ
+	if (irqflags & IRQF_SHARED) {
+		/*
+		 * It's a shared IRQ -- the driver ought to be prepared for it
+		 * to happen immediately, so let's make sure....
+		 * We do this before actually registering it, to make sure that
+		 * a 'real' IRQ doesn't run in parallel with our fake
+		 */
+		if (irqflags & IRQF_DISABLED) {
+			unsigned long flags;
+
+			local_irq_save(flags);
+			handler(irq, dev_id);
+			local_irq_restore(flags);
+		} else
+			handler(irq, dev_id);
+	}
+#endif
+
 	retval = setup_irq(irq, action);
 	if (retval)
 		kfree(action);

commit 5ea8176994003483a18c8fed580901e2125f8a83
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Sun Feb 11 15:41:31 2007 +0000

    [PATCH] sort the devres mess out
    
    * Split the implementation-agnostic stuff in separate files.
    * Make sure that targets using non-default request_irq() pull
      kernel/irq/devres.o
    * Introduce new symbols (HAS_IOPORT and HAS_IOMEM) defaulting to positive;
      allow architectures to turn them off (we needed these symbols anyway for
      dependencies of quite a few drivers).
    * protect the ioport-related parts of lib/devres.o with CONFIG_HAS_IOPORT.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index c4b7ed1cebf7..8b961adc3bd2 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -482,89 +482,3 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 	return retval;
 }
 EXPORT_SYMBOL(request_irq);
-
-/*
- * Device resource management aware IRQ request/free implementation.
- */
-struct irq_devres {
-	unsigned int irq;
-	void *dev_id;
-};
-
-static void devm_irq_release(struct device *dev, void *res)
-{
-	struct irq_devres *this = res;
-
-	free_irq(this->irq, this->dev_id);
-}
-
-static int devm_irq_match(struct device *dev, void *res, void *data)
-{
-	struct irq_devres *this = res, *match = data;
-
-	return this->irq == match->irq && this->dev_id == match->dev_id;
-}
-
-/**
- *	devm_request_irq - allocate an interrupt line for a managed device
- *	@dev: device to request interrupt for
- *	@irq: Interrupt line to allocate
- *	@handler: Function to be called when the IRQ occurs
- *	@irqflags: Interrupt type flags
- *	@devname: An ascii name for the claiming device
- *	@dev_id: A cookie passed back to the handler function
- *
- *	Except for the extra @dev argument, this function takes the
- *	same arguments and performs the same function as
- *	request_irq().  IRQs requested with this function will be
- *	automatically freed on driver detach.
- *
- *	If an IRQ allocated with this function needs to be freed
- *	separately, dev_free_irq() must be used.
- */
-int devm_request_irq(struct device *dev, unsigned int irq,
-		     irq_handler_t handler, unsigned long irqflags,
-		     const char *devname, void *dev_id)
-{
-	struct irq_devres *dr;
-	int rc;
-
-	dr = devres_alloc(devm_irq_release, sizeof(struct irq_devres),
-			  GFP_KERNEL);
-	if (!dr)
-		return -ENOMEM;
-
-	rc = request_irq(irq, handler, irqflags, devname, dev_id);
-	if (rc) {
-		kfree(dr);
-		return rc;
-	}
-
-	dr->irq = irq;
-	dr->dev_id = dev_id;
-	devres_add(dev, dr);
-
-	return 0;
-}
-EXPORT_SYMBOL(devm_request_irq);
-
-/**
- *	devm_free_irq - free an interrupt
- *	@dev: device to free interrupt for
- *	@irq: Interrupt line to free
- *	@dev_id: Device identity to free
- *
- *	Except for the extra @dev argument, this function takes the
- *	same arguments and performs the same function as free_irq().
- *	This function instead of free_irq() should be used to manually
- *	free IRQs allocated with dev_request_irq().
- */
-void devm_free_irq(struct device *dev, unsigned int irq, void *dev_id)
-{
-	struct irq_devres match_data = { irq, dev_id };
-
-	free_irq(irq, dev_id);
-	WARN_ON(devres_destroy(dev, devm_irq_release, devm_irq_match,
-			       &match_data));
-}
-EXPORT_SYMBOL(devm_free_irq);

commit 9ac7849e35f705830f7b016ff272b0ff1f7ff759
Author: Tejun Heo <htejun@gmail.com>
Date:   Sat Jan 20 16:00:26 2007 +0900

    devres: device resource management
    
    Implement device resource management, in short, devres.  A device
    driver can allocate arbirary size of devres data which is associated
    with a release function.  On driver detach, release function is
    invoked on the devres data, then, devres data is freed.
    
    devreses are typed by associated release functions.  Some devreses are
    better represented by single instance of the type while others need
    multiple instances sharing the same release function.  Both usages are
    supported.
    
    devreses can be grouped using devres group such that a device driver
    can easily release acquired resources halfway through initialization
    or selectively release resources (e.g. resources for port 1 out of 4
    ports).
    
    This patch adds devres core including documentation and the following
    managed interfaces.
    
    * alloc/free    : devm_kzalloc(), devm_kzfree()
    * IO region     : devm_request_region(), devm_release_region()
    * IRQ           : devm_request_irq(), devm_free_irq()
    * DMA           : dmam_alloc_coherent(), dmam_free_coherent(),
                      dmam_declare_coherent_memory(), dmam_pool_create(),
                      dmam_pool_destroy()
    * PCI           : pcim_enable_device(), pcim_pin_device(), pci_is_managed()
    * iomap         : devm_ioport_map(), devm_ioport_unmap(), devm_ioremap(),
                      devm_ioremap_nocache(), devm_iounmap(), pcim_iomap_table(),
                      pcim_iomap(), pcim_iounmap()
    
    Signed-off-by: Tejun Heo <htejun@gmail.com>
    Signed-off-by: Jeff Garzik <jeff@garzik.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 8b961adc3bd2..c4b7ed1cebf7 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -482,3 +482,89 @@ int request_irq(unsigned int irq, irq_handler_t handler,
 	return retval;
 }
 EXPORT_SYMBOL(request_irq);
+
+/*
+ * Device resource management aware IRQ request/free implementation.
+ */
+struct irq_devres {
+	unsigned int irq;
+	void *dev_id;
+};
+
+static void devm_irq_release(struct device *dev, void *res)
+{
+	struct irq_devres *this = res;
+
+	free_irq(this->irq, this->dev_id);
+}
+
+static int devm_irq_match(struct device *dev, void *res, void *data)
+{
+	struct irq_devres *this = res, *match = data;
+
+	return this->irq == match->irq && this->dev_id == match->dev_id;
+}
+
+/**
+ *	devm_request_irq - allocate an interrupt line for a managed device
+ *	@dev: device to request interrupt for
+ *	@irq: Interrupt line to allocate
+ *	@handler: Function to be called when the IRQ occurs
+ *	@irqflags: Interrupt type flags
+ *	@devname: An ascii name for the claiming device
+ *	@dev_id: A cookie passed back to the handler function
+ *
+ *	Except for the extra @dev argument, this function takes the
+ *	same arguments and performs the same function as
+ *	request_irq().  IRQs requested with this function will be
+ *	automatically freed on driver detach.
+ *
+ *	If an IRQ allocated with this function needs to be freed
+ *	separately, dev_free_irq() must be used.
+ */
+int devm_request_irq(struct device *dev, unsigned int irq,
+		     irq_handler_t handler, unsigned long irqflags,
+		     const char *devname, void *dev_id)
+{
+	struct irq_devres *dr;
+	int rc;
+
+	dr = devres_alloc(devm_irq_release, sizeof(struct irq_devres),
+			  GFP_KERNEL);
+	if (!dr)
+		return -ENOMEM;
+
+	rc = request_irq(irq, handler, irqflags, devname, dev_id);
+	if (rc) {
+		kfree(dr);
+		return rc;
+	}
+
+	dr->irq = irq;
+	dr->dev_id = dev_id;
+	devres_add(dev, dr);
+
+	return 0;
+}
+EXPORT_SYMBOL(devm_request_irq);
+
+/**
+ *	devm_free_irq - free an interrupt
+ *	@dev: device to free interrupt for
+ *	@irq: Interrupt line to free
+ *	@dev_id: Device identity to free
+ *
+ *	Except for the extra @dev argument, this function takes the
+ *	same arguments and performs the same function as free_irq().
+ *	This function instead of free_irq() should be used to manually
+ *	free IRQs allocated with dev_request_irq().
+ */
+void devm_free_irq(struct device *dev, unsigned int irq, void *dev_id)
+{
+	struct irq_devres match_data = { irq, dev_id };
+
+	free_irq(irq, dev_id);
+	WARN_ON(devres_destroy(dev, devm_irq_release, devm_irq_match,
+			       &match_data));
+}
+EXPORT_SYMBOL(devm_free_irq);

commit 8528b0f1de1101c6002036fd53638fb21111d0ea
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Tue Jan 23 14:16:31 2007 -0800

    Clear spurious irq stat information when adding irq handler
    
    Any newly added irq handler may obviously make any old spurious irq
    status invalid, since the new handler may well be the thing that is
    supposed to handle any interrupts that came in.
    
    So just clear the statistics when adding handlers.
    
    Pointed-out-by: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index b385878c6e80..8b961adc3bd2 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -315,6 +315,9 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 			/* Undo nested disables: */
 			desc->depth = 1;
 	}
+	/* Reset broken irq detection when installing new handler */
+	desc->irq_count = 0;
+	desc->irqs_unhandled = 0;
 	spin_unlock_irqrestore(&desc->lock, flags);
 
 	new->irq = irq;

commit 8b126b77536186eef69d408eb7959ce7f558f251
Author: Andrew Morton <akpm@osdl.org>
Date:   Tue Nov 14 02:03:23 2006 -0800

    [PATCH] setup_irq(): better mismatch debugging
    
    When we get a mismatch between handlers on the same IRQ, all we get is "IRQ
    handler type mismatch for IRQ n".  Let's print the name of the
    presently-registered handler with which we got the mismatch.
    
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 6879202afe9a..b385878c6e80 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -216,6 +216,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 {
 	struct irq_desc *desc = irq_desc + irq;
 	struct irqaction *old, **p;
+	const char *old_name = NULL;
 	unsigned long flags;
 	int shared = 0;
 
@@ -255,8 +256,10 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 		 * set the trigger type must match.
 		 */
 		if (!((old->flags & new->flags) & IRQF_SHARED) ||
-		    ((old->flags ^ new->flags) & IRQF_TRIGGER_MASK))
+		    ((old->flags ^ new->flags) & IRQF_TRIGGER_MASK)) {
+			old_name = old->name;
 			goto mismatch;
+		}
 
 #if defined(CONFIG_IRQ_PER_CPU)
 		/* All handlers must agree on per-cpuness */
@@ -322,11 +325,13 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 	return 0;
 
 mismatch:
-	spin_unlock_irqrestore(&desc->lock, flags);
 	if (!(new->flags & IRQF_PROBE_SHARED)) {
 		printk(KERN_ERR "IRQ handler type mismatch for IRQ %d\n", irq);
+		if (old_name)
+			printk(KERN_ERR "current handler: %s\n", old_name);
 		dump_stack();
 	}
+	spin_unlock_irqrestore(&desc->lock, flags);
 	return -EBUSY;
 }
 

commit da482792a6d1a3fbaaa25fae867b343fb4db3246
Author: David Howells <dhowells@redhat.com>
Date:   Thu Oct 5 13:06:34 2006 +0100

    IRQ: Typedef the IRQ handler function type
    
    Typedef the IRQ handler function type.
    
    Signed-Off-By: David Howells <dhowells@redhat.com>
    (cherry picked from 1356d1e5fd256997e3d3dce0777ab787d0515c7a commit)

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 92be519eff26..6879202afe9a 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -427,8 +427,7 @@ EXPORT_SYMBOL(free_irq);
  *	IRQF_SAMPLE_RANDOM	The interrupt can be used for entropy
  *
  */
-int request_irq(unsigned int irq,
-		irqreturn_t (*handler)(int, void *, struct pt_regs *),
+int request_irq(unsigned int irq, irq_handler_t handler,
 		unsigned long irqflags, const char *devname, void *dev_id)
 {
 	struct irqaction *action;
@@ -475,4 +474,3 @@ int request_irq(unsigned int irq,
 	return retval;
 }
 EXPORT_SYMBOL(request_irq);
-

commit 15a647eba94c3da27ccc666bea72e7cca06b2d19
Author: David Brownell <david-b@pacbell.net>
Date:   Sun Jul 30 03:03:08 2006 -0700

    [PATCH] genirq: {en,dis}able_irq_wake() need refcounting too
    
    IRQs need refcounting and a state flag to track whether the the IRQ should
    be enabled or disabled as a "normal IRQ" source after a series of calls to
    {en,dis}able_irq().  For shared IRQs, the IRQ must be enabled so long as at
    least one driver needs it active.
    
    Likewise, IRQs need the same support to track whether the IRQ should be
    enabled or disabled as a "wakeup event" source after a series of calls to
    {en,dis}able_irq_wake().  For shared IRQs, the IRQ must be enabled as a
    wakeup source during sleep so long as at least one driver needs it.  But
    right now they _don't have_ that refcounting ...  which means sharing a
    wakeup-capable IRQ can't work correctly in some configurations.
    
    This patch adds the refcount and flag mechanisms to set_irq_wake() -- which
    is what {en,dis}able_irq_wake() call -- and minimal documentation of what
    the irq wake mechanism does.
    
    Drivers relying on the older (broken) "toggle" semantics will trigger a
    warning; that'll be a handful of drivers on ARM systems.
    
    Signed-off-by: David Brownell <dbrownell@users.sourceforge.net>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 4e461438e48b..92be519eff26 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -137,16 +137,40 @@ EXPORT_SYMBOL(enable_irq);
  *	@irq:	interrupt to control
  *	@on:	enable/disable power management wakeup
  *
- *	Enable/disable power management wakeup mode
+ *	Enable/disable power management wakeup mode, which is
+ *	disabled by default.  Enables and disables must match,
+ *	just as they match for non-wakeup mode support.
+ *
+ *	Wakeup mode lets this IRQ wake the system from sleep
+ *	states like "suspend to RAM".
  */
 int set_irq_wake(unsigned int irq, unsigned int on)
 {
 	struct irq_desc *desc = irq_desc + irq;
 	unsigned long flags;
 	int ret = -ENXIO;
+	int (*set_wake)(unsigned, unsigned) = desc->chip->set_wake;
 
+	/* wakeup-capable irqs can be shared between drivers that
+	 * don't need to have the same sleep mode behaviors.
+	 */
 	spin_lock_irqsave(&desc->lock, flags);
-	if (desc->chip->set_wake)
+	if (on) {
+		if (desc->wake_depth++ == 0)
+			desc->status |= IRQ_WAKEUP;
+		else
+			set_wake = NULL;
+	} else {
+		if (desc->wake_depth == 0) {
+			printk(KERN_WARNING "Unbalanced IRQ %d "
+					"wake disable\n", irq);
+			WARN_ON(1);
+		} else if (--desc->wake_depth == 0)
+			desc->status &= ~IRQ_WAKEUP;
+		else
+			set_wake = NULL;
+	}
+	if (set_wake)
 		ret = desc->chip->set_wake(irq, on);
 	spin_unlock_irqrestore(&desc->lock, flags);
 	return ret;

commit fbb9ce9530fd9b66096d5187fa6a115d16d9746c
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Jul 3 00:24:50 2006 -0700

    [PATCH] lockdep: core
    
    Do 'make oldconfig' and accept all the defaults for new config options -
    reboot into the kernel and if everything goes well it should boot up fine and
    you should have /proc/lockdep and /proc/lockdep_stats files.
    
    Typically if the lock validator finds some problem it will print out
    voluminous debug output that begins with "BUG: ..." and which syslog output
    can be used by kernel developers to figure out the precise locking scenario.
    
    What does the lock validator do?  It "observes" and maps all locking rules as
    they occur dynamically (as triggered by the kernel's natural use of spinlocks,
    rwlocks, mutexes and rwsems).  Whenever the lock validator subsystem detects a
    new locking scenario, it validates this new rule against the existing set of
    rules.  If this new rule is consistent with the existing set of rules then the
    new rule is added transparently and the kernel continues as normal.  If the
    new rule could create a deadlock scenario then this condition is printed out.
    
    When determining validity of locking, all possible "deadlock scenarios" are
    considered: assuming arbitrary number of CPUs, arbitrary irq context and task
    context constellations, running arbitrary combinations of all the existing
    locking scenarios.  In a typical system this means millions of separate
    scenarios.  This is why we call it a "locking correctness" validator - for all
    rules that are observed the lock validator proves it with mathematical
    certainty that a deadlock could not occur (assuming that the lock validator
    implementation itself is correct and its internal data structures are not
    corrupted by some other kernel subsystem).  [see more details and conditionals
    of this statement in include/linux/lockdep.h and
    Documentation/lockdep-design.txt]
    
    Furthermore, this "all possible scenarios" property of the validator also
    enables the finding of complex, highly unlikely multi-CPU multi-context races
    via single single-context rules, increasing the likelyhood of finding bugs
    drastically.  In practical terms: the lock validator already found a bug in
    the upstream kernel that could only occur on systems with 3 or more CPUs, and
    which needed 3 very unlikely code sequences to occur at once on the 3 CPUs.
    That bug was found and reported on a single-CPU system (!).  So in essence a
    race will be found "piecemail-wise", triggering all the necessary components
    for the race, without having to reproduce the race scenario itself!  In its
    short existence the lock validator found and reported many bugs before they
    actually caused a real deadlock.
    
    To further increase the efficiency of the validator, the mapping is not per
    "lock instance", but per "lock-class".  For example, all struct inode objects
    in the kernel have inode->inotify_mutex.  If there are 10,000 inodes cached,
    then there are 10,000 lock objects.  But ->inotify_mutex is a single "lock
    type", and all locking activities that occur against ->inotify_mutex are
    "unified" into this single lock-class.  The advantage of the lock-class
    approach is that all historical ->inotify_mutex uses are mapped into a single
    (and as narrow as possible) set of locking rules - regardless of how many
    different tasks or inode structures it took to build this set of rules.  The
    set of rules persist during the lifetime of the kernel.
    
    To see the rough magnitude of checking that the lock validator does, here's a
    portion of /proc/lockdep_stats, fresh after bootup:
    
     lock-classes:                            694 [max: 2048]
     direct dependencies:                  1598 [max: 8192]
     indirect dependencies:               17896
     all direct dependencies:             16206
     dependency chains:                    1910 [max: 8192]
     in-hardirq chains:                      17
     in-softirq chains:                     105
     in-process chains:                    1065
     stack-trace entries:                 38761 [max: 131072]
     combined max dependencies:         2033928
     hardirq-safe locks:                     24
     hardirq-unsafe locks:                  176
     softirq-safe locks:                     53
     softirq-unsafe locks:                  137
     irq-safe locks:                         59
     irq-unsafe locks:                      176
    
    The lock validator has observed 1598 actual single-thread locking patterns,
    and has validated all possible 2033928 distinct locking scenarios.
    
    More details about the design of the lock validator can be found in
    Documentation/lockdep-design.txt, which can also found at:
    
       http://redhat.com/~mingo/lockdep-patches/lockdep-design.txt
    
    [bunk@stusta.de: cleanups]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index c911c6ec4dd6..4e461438e48b 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -410,6 +410,12 @@ int request_irq(unsigned int irq,
 	struct irqaction *action;
 	int retval;
 
+#ifdef CONFIG_LOCKDEP
+	/*
+	 * Lockdep wants atomic interrupt handlers:
+	 */
+	irqflags |= SA_INTERRUPT;
+#endif
 	/*
 	 * Sanity-check: shared interrupts must pass in a real dev-ID,
 	 * otherwise we'll have trouble later trying to figure out

commit 284c66806eb6df7f5c66d298681f1abe81a5a9ab
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Jul 3 02:20:32 2006 +0200

    [PATCH] genirq:fixup missing SA_PERCPU replacement
    
    The irqflags consolidation converted SA_PERCPU_IRQ to IRQF_PERCPU but
    did not define the new constant.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index fede5fa351df..c911c6ec4dd6 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -234,7 +234,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 		    ((old->flags ^ new->flags) & IRQF_TRIGGER_MASK))
 			goto mismatch;
 
-#if defined(CONFIG_IRQ_PER_CPU) && defined(IRQF_PERCPU)
+#if defined(CONFIG_IRQ_PER_CPU)
 		/* All handlers must agree on per-cpuness */
 		if ((old->flags & IRQF_PERCPU) !=
 		    (new->flags & IRQF_PERCPU))
@@ -250,7 +250,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 	}
 
 	*p = new;
-#if defined(CONFIG_IRQ_PER_CPU) && defined(IRQF_PERCPU)
+#if defined(CONFIG_IRQ_PER_CPU)
 	if (new->flags & IRQF_PERCPU)
 		desc->status |= IRQ_PER_CPU;
 #endif

commit 3cca53b02a5bab0f407b1add2f84c22c20243a79
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 1 19:29:31 2006 -0700

    [PATCH] irq-flags: generic irq: Use the new IRQF_ constants
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index fcce5181e453..fede5fa351df 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -167,7 +167,7 @@ int can_request_irq(unsigned int irq, unsigned long irqflags)
 
 	action = irq_desc[irq].action;
 	if (action)
-		if (irqflags & action->flags & SA_SHIRQ)
+		if (irqflags & action->flags & IRQF_SHARED)
 			action = NULL;
 
 	return !action;
@@ -205,7 +205,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 	 * so we have to be careful not to interfere with a
 	 * running system.
 	 */
-	if (new->flags & SA_SAMPLE_RANDOM) {
+	if (new->flags & IRQF_SAMPLE_RANDOM) {
 		/*
 		 * This function might sleep, we want to call it first,
 		 * outside of the atomic block.
@@ -227,17 +227,17 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 		/*
 		 * Can't share interrupts unless both agree to and are
 		 * the same type (level, edge, polarity). So both flag
-		 * fields must have SA_SHIRQ set and the bits which
+		 * fields must have IRQF_SHARED set and the bits which
 		 * set the trigger type must match.
 		 */
-		if (!((old->flags & new->flags) & SA_SHIRQ) ||
-		    ((old->flags ^ new->flags) & SA_TRIGGER_MASK))
+		if (!((old->flags & new->flags) & IRQF_SHARED) ||
+		    ((old->flags ^ new->flags) & IRQF_TRIGGER_MASK))
 			goto mismatch;
 
-#if defined(CONFIG_IRQ_PER_CPU) && defined(SA_PERCPU_IRQ)
+#if defined(CONFIG_IRQ_PER_CPU) && defined(IRQF_PERCPU)
 		/* All handlers must agree on per-cpuness */
-		if ((old->flags & SA_PERCPU_IRQ) !=
-		    (new->flags & SA_PERCPU_IRQ))
+		if ((old->flags & IRQF_PERCPU) !=
+		    (new->flags & IRQF_PERCPU))
 			goto mismatch;
 #endif
 
@@ -250,24 +250,24 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 	}
 
 	*p = new;
-#if defined(CONFIG_IRQ_PER_CPU) && defined(SA_PERCPU_IRQ)
-	if (new->flags & SA_PERCPU_IRQ)
+#if defined(CONFIG_IRQ_PER_CPU) && defined(IRQF_PERCPU)
+	if (new->flags & IRQF_PERCPU)
 		desc->status |= IRQ_PER_CPU;
 #endif
 	if (!shared) {
 		irq_chip_set_defaults(desc->chip);
 
 		/* Setup the type (level, edge polarity) if configured: */
-		if (new->flags & SA_TRIGGER_MASK) {
+		if (new->flags & IRQF_TRIGGER_MASK) {
 			if (desc->chip && desc->chip->set_type)
 				desc->chip->set_type(irq,
-						new->flags & SA_TRIGGER_MASK);
+						new->flags & IRQF_TRIGGER_MASK);
 			else
 				/*
-				 * SA_TRIGGER_* but the PIC does not support
+				 * IRQF_TRIGGER_* but the PIC does not support
 				 * multiple flow-types?
 				 */
-				printk(KERN_WARNING "No SA_TRIGGER set_type "
+				printk(KERN_WARNING "No IRQF_TRIGGER set_type "
 				       "function for IRQ %d (%s)\n", irq,
 				       desc->chip ? desc->chip->name :
 				       "unknown");
@@ -299,7 +299,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 
 mismatch:
 	spin_unlock_irqrestore(&desc->lock, flags);
-	if (!(new->flags & SA_PROBEIRQ)) {
+	if (!(new->flags & IRQF_PROBE_SHARED)) {
 		printk(KERN_ERR "IRQ handler type mismatch for IRQ %d\n", irq);
 		dump_stack();
 	}
@@ -398,9 +398,9 @@ EXPORT_SYMBOL(free_irq);
  *
  *	Flags:
  *
- *	SA_SHIRQ		Interrupt is shared
- *	SA_INTERRUPT		Disable local interrupts while processing
- *	SA_SAMPLE_RANDOM	The interrupt can be used for entropy
+ *	IRQF_SHARED		Interrupt is shared
+ *	IRQF_DISABLED	Disable local interrupts while processing
+ *	IRQF_SAMPLE_RANDOM	The interrupt can be used for entropy
  *
  */
 int request_irq(unsigned int irq,
@@ -416,7 +416,7 @@ int request_irq(unsigned int irq,
 	 * which interrupt is which (messes up the interrupt freeing
 	 * logic etc).
 	 */
-	if ((irqflags & SA_SHIRQ) && !dev_id)
+	if ((irqflags & IRQF_SHARED) && !dev_id)
 		return -EINVAL;
 	if (irq >= NR_IRQS)
 		return -EINVAL;

commit e8c4b9d003e72199a705fb5a40fcd2487fa16933
Author: Bjorn Helgaas <bjorn.helgaas@hp.com>
Date:   Sat Jul 1 04:35:45 2006 -0700

    [PATCH] IRQ: warning message cleanup
    
    Make warnings more consistent.
    
    Signed-off-by: Bjorn Helgaas <bjorn.helgaas@hp.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index e3a122931e1a..fcce5181e453 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -114,7 +114,7 @@ void enable_irq(unsigned int irq)
 	spin_lock_irqsave(&desc->lock, flags);
 	switch (desc->depth) {
 	case 0:
-		printk(KERN_WARNING "Unablanced enable_irq(%d)\n", irq);
+		printk(KERN_WARNING "Unbalanced enable for IRQ %d\n", irq);
 		WARN_ON(1);
 		break;
 	case 1: {
@@ -267,9 +267,10 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 				 * SA_TRIGGER_* but the PIC does not support
 				 * multiple flow-types?
 				 */
-				printk(KERN_WARNING "setup_irq(%d) SA_TRIGGER"
-				       "set. No set_type function available\n",
-				       irq);
+				printk(KERN_WARNING "No SA_TRIGGER set_type "
+				       "function for IRQ %d (%s)\n", irq,
+				       desc->chip ? desc->chip->name :
+				       "unknown");
 		} else
 			compat_irq_chip_set_default_handler(desc);
 
@@ -299,7 +300,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 mismatch:
 	spin_unlock_irqrestore(&desc->lock, flags);
 	if (!(new->flags & SA_PROBEIRQ)) {
-		printk(KERN_ERR "%s: irq handler mismatch\n", __FUNCTION__);
+		printk(KERN_ERR "IRQ handler type mismatch for IRQ %d\n", irq);
 		dump_stack();
 	}
 	return -EBUSY;
@@ -366,7 +367,7 @@ void free_irq(unsigned int irq, void *dev_id)
 			kfree(action);
 			return;
 		}
-		printk(KERN_ERR "Trying to free free IRQ%d\n", irq);
+		printk(KERN_ERR "Trying to free already-free IRQ %d\n", irq);
 		spin_unlock_irqrestore(&desc->lock, flags);
 		return;
 	}

commit 17311c03c3e2c16d64d9e8cb2a3f45be2e2f8d3b
Author: Bjorn Helgaas <bjorn.helgaas@hp.com>
Date:   Sat Jul 1 04:35:44 2006 -0700

    [PATCH] IRQ: Use SA_PERCPU_IRQ, not IRQ_PER_CPU, for irqaction.flags
    
    IRQ_PER_CPU is a bit in the struct irq_desc "status" field, not in the
    struct irqaction "flags", so the previous code checked the wrong bit.
    
    SA_PERCPU_IRQ is only used by drivers/char/mmtimer.c for SGI ia64 boxes.
    
    Signed-off-by: Bjorn Helgaas <bjorn.helgaas@hp.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index b7117e81ac56..e3a122931e1a 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -236,7 +236,8 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 
 #if defined(CONFIG_IRQ_PER_CPU) && defined(SA_PERCPU_IRQ)
 		/* All handlers must agree on per-cpuness */
-		if ((old->flags & IRQ_PER_CPU) != (new->flags & IRQ_PER_CPU))
+		if ((old->flags & SA_PERCPU_IRQ) !=
+		    (new->flags & SA_PERCPU_IRQ))
 			goto mismatch;
 #endif
 

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: Jörn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: Jörn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 9eb1d518ee1c..b7117e81ac56 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -7,7 +7,6 @@
  * This file contains driver APIs to the irq subsystem.
  */
 
-#include <linux/config.h>
 #include <linux/irq.h>
 #include <linux/module.h>
 #include <linux/random.h>

commit f1c2662cbc6a0a9772655649bdf579803d33470b
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 29 02:24:57 2006 -0700

    [PATCH] genirq: cleanup: no_irq_type -> no_irq_chip rename
    
    Rename no_irq_type to no_irq_chip.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 627d401c2979..9eb1d518ee1c 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -199,7 +199,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 	if (irq >= NR_IRQS)
 		return -EINVAL;
 
-	if (desc->chip == &no_irq_type)
+	if (desc->chip == &no_irq_chip)
 		return -ENOSYS;
 	/*
 	 * Some drivers like serial.c use request_irq() heavily,

commit e76de9f8eb67b7acc1cc6f28c4be8583adf0a90c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Jun 29 02:24:56 2006 -0700

    [PATCH] genirq: add SA_TRIGGER support
    
    Enable drivers to request an IRQ with a given irq-flow (trigger/polarity)
    setting.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 3ed7aee84865..627d401c2979 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -225,8 +225,14 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 	p = &desc->action;
 	old = *p;
 	if (old) {
-		/* Can't share interrupts unless both agree to */
-		if (!(old->flags & new->flags & SA_SHIRQ))
+		/*
+		 * Can't share interrupts unless both agree to and are
+		 * the same type (level, edge, polarity). So both flag
+		 * fields must have SA_SHIRQ set and the bits which
+		 * set the trigger type must match.
+		 */
+		if (!((old->flags & new->flags) & SA_SHIRQ) ||
+		    ((old->flags ^ new->flags) & SA_TRIGGER_MASK))
 			goto mismatch;
 
 #if defined(CONFIG_IRQ_PER_CPU) && defined(SA_PERCPU_IRQ)
@@ -250,7 +256,22 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 #endif
 	if (!shared) {
 		irq_chip_set_defaults(desc->chip);
-		compat_irq_chip_set_default_handler(desc);
+
+		/* Setup the type (level, edge polarity) if configured: */
+		if (new->flags & SA_TRIGGER_MASK) {
+			if (desc->chip && desc->chip->set_type)
+				desc->chip->set_type(irq,
+						new->flags & SA_TRIGGER_MASK);
+			else
+				/*
+				 * SA_TRIGGER_* but the PIC does not support
+				 * multiple flow-types?
+				 */
+				printk(KERN_WARNING "setup_irq(%d) SA_TRIGGER"
+				       "set. No set_type function available\n",
+				       irq);
+		} else
+			compat_irq_chip_set_default_handler(desc);
 
 		desc->status &= ~(IRQ_AUTODETECT | IRQ_WAITING |
 				  IRQ_INPROGRESS);
@@ -262,7 +283,9 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 				desc->chip->startup(irq);
 			else
 				desc->chip->enable(irq);
-		}
+		} else
+			/* Undo nested disables: */
+			desc->depth = 1;
 	}
 	spin_unlock_irqrestore(&desc->lock, flags);
 

commit ba9a2331bae5da8f65be3722b9e2d210f1987857
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Jun 29 02:24:55 2006 -0700

    [PATCH] genirq: add irq-wake (power-management) support
    
    Enable platforms to set the irq-wake (power-management) properties of an IRQ.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index b61784ee78b2..3ed7aee84865 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -133,6 +133,27 @@ void enable_irq(unsigned int irq)
 }
 EXPORT_SYMBOL(enable_irq);
 
+/**
+ *	set_irq_wake - control irq power management wakeup
+ *	@irq:	interrupt to control
+ *	@on:	enable/disable power management wakeup
+ *
+ *	Enable/disable power management wakeup mode
+ */
+int set_irq_wake(unsigned int irq, unsigned int on)
+{
+	struct irq_desc *desc = irq_desc + irq;
+	unsigned long flags;
+	int ret = -ENXIO;
+
+	spin_lock_irqsave(&desc->lock, flags);
+	if (desc->chip->set_wake)
+		ret = desc->chip->set_wake(irq, on);
+	spin_unlock_irqrestore(&desc->lock, flags);
+	return ret;
+}
+EXPORT_SYMBOL(set_irq_wake);
+
 /*
  * Internal function that tells the architecture code whether a
  * particular irq has been exclusively allocated or is available

commit 6a6de9ef5850d063c3d3fb50784bfe3a6d0712c6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Jun 29 02:24:51 2006 -0700

    [PATCH] genirq: core
    
    Core genirq support: add the irq-chip and irq-flow abstractions.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 1a2e7663096a..b61784ee78b2 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -153,6 +153,17 @@ int can_request_irq(unsigned int irq, unsigned long irqflags)
 	return !action;
 }
 
+void compat_irq_chip_set_default_handler(struct irq_desc *desc)
+{
+	/*
+	 * If the architecture still has not overriden
+	 * the flow handler then zap the default. This
+	 * should catch incorrect flow-type setting.
+	 */
+	if (desc->handle_irq == &handle_bad_irq)
+		desc->handle_irq = NULL;
+}
+
 /*
  * Internal function to register an irqaction - typically used to
  * allocate special interrupts that are part of the architecture.
@@ -217,6 +228,9 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 		desc->status |= IRQ_PER_CPU;
 #endif
 	if (!shared) {
+		irq_chip_set_defaults(desc->chip);
+		compat_irq_chip_set_default_handler(desc);
+
 		desc->status &= ~(IRQ_AUTODETECT | IRQ_WAITING |
 				  IRQ_INPROGRESS);
 

commit a34db9b28a1c63317e1d6f1080a12d711579e7d0
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 29 02:24:50 2006 -0700

    [PATCH] genirq: update copyrights
    
    Update/add copyrights in the generic IRQ code.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 9ea18879fb62..1a2e7663096a 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1,7 +1,8 @@
 /*
  * linux/kernel/irq/manage.c
  *
- * Copyright (C) 1992, 1998-2004 Linus Torvalds, Ingo Molnar
+ * Copyright (C) 1992, 1998-2006 Linus Torvalds, Ingo Molnar
+ * Copyright (C) 2005-2006 Thomas Gleixner
  *
  * This file contains driver APIs to the irq subsystem.
  */

commit 94d39e1f6e8132ea982a1d61acbe0423d3d14365
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Jun 29 02:24:50 2006 -0700

    [PATCH] genirq: add IRQ_NOAUTOEN support
    
    Enable platforms to disable the automatic enabling of freshly set up irqs.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index cae900a849c4..9ea18879fb62 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -216,13 +216,17 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 		desc->status |= IRQ_PER_CPU;
 #endif
 	if (!shared) {
-		desc->depth = 0;
-		desc->status &= ~(IRQ_DISABLED | IRQ_AUTODETECT |
-				  IRQ_WAITING | IRQ_INPROGRESS);
-		if (desc->chip->startup)
-			desc->chip->startup(irq);
-		else
-			desc->chip->enable(irq);
+		desc->status &= ~(IRQ_AUTODETECT | IRQ_WAITING |
+				  IRQ_INPROGRESS);
+
+		if (!(desc->status & IRQ_NOAUTOEN)) {
+			desc->depth = 0;
+			desc->status &= ~IRQ_DISABLED;
+			if (desc->chip->startup)
+				desc->chip->startup(irq);
+			else
+				desc->chip->enable(irq);
+		}
 	}
 	spin_unlock_irqrestore(&desc->lock, flags);
 

commit 6550c775cb5ee94c132d93d84de3bb23f0abf37b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Jun 29 02:24:49 2006 -0700

    [PATCH] genirq: add IRQ_NOREQUEST support
    
    Enable platforms to disable request_irq() for certain interrupts.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 90a944a7fadc..cae900a849c4 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -141,7 +141,7 @@ int can_request_irq(unsigned int irq, unsigned long irqflags)
 {
 	struct irqaction *action;
 
-	if (irq >= NR_IRQS)
+	if (irq >= NR_IRQS || irq_desc[irq].status & IRQ_NOREQUEST)
 		return 0;
 
 	action = irq_desc[irq].action;
@@ -356,6 +356,8 @@ int request_irq(unsigned int irq,
 		return -EINVAL;
 	if (irq >= NR_IRQS)
 		return -EINVAL;
+	if (irq_desc[irq].status & IRQ_NOREQUEST)
+		return -EINVAL;
 	if (!handler)
 		return -EINVAL;
 

commit 3418d72404e35eb19e7995cbf3e7a76ba8fefbce
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Jun 29 02:24:49 2006 -0700

    [PATCH] genirq: add IRQ_NOPROBE support
    
    Introduce IRQ_NOPROBE: enables platforms to control chip-probing.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index cffde4843897..90a944a7fadc 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -118,6 +118,10 @@ void enable_irq(unsigned int irq)
 		WARN_ON(1);
 		break;
 	case 1: {
+		unsigned int status = desc->status & ~IRQ_DISABLED;
+
+		/* Prevent probing on this irq: */
+		desc->status = status | IRQ_NOPROBE;
 		check_irq_resend(desc, irq);
 		/* fall-through */
 	}

commit a4633adcdbc15ac51afcd0e1395de58cee27cf92
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Jun 29 02:24:48 2006 -0700

    [PATCH] genirq: add genirq sw IRQ-retrigger
    
    Enable platforms that do not have a hardware-assisted hardirq-resend mechanism
    to resend them via a softirq-driven IRQ emulation mechanism.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 19b438e09f12..cffde4843897 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -118,15 +118,7 @@ void enable_irq(unsigned int irq)
 		WARN_ON(1);
 		break;
 	case 1: {
-		unsigned int status = desc->status & ~IRQ_DISABLED;
-
-		desc->status = status;
-		if ((status & (IRQ_PENDING | IRQ_REPLAY)) == IRQ_PENDING) {
-			desc->status = status | IRQ_REPLAY;
-			if (desc->chip && desc->chip->retrigger)
-				desc->chip->retrigger(irq);
-		}
-		desc->chip->enable(irq);
+		check_irq_resend(desc, irq);
 		/* fall-through */
 	}
 	default:

commit c0ad90a32fb60f4129d0e24dfd5fd7128e2e09f2
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 29 02:24:44 2006 -0700

    [PATCH] genirq: add ->retrigger() irq op to consolidate hw_irq_resend()
    
    Add ->retrigger() irq op to consolidate hw_irq_resend() implementations.
    (Most architectures had it defined to NOP anyway.)
    
    NOTE: ia64 needs testing. i386 and x86_64 tested.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 76c8eda67295..19b438e09f12 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -123,7 +123,8 @@ void enable_irq(unsigned int irq)
 		desc->status = status;
 		if ((status & (IRQ_PENDING | IRQ_REPLAY)) == IRQ_PENDING) {
 			desc->status = status | IRQ_REPLAY;
-			hw_resend_irq(desc->chip,irq);
+			if (desc->chip && desc->chip->retrigger)
+				desc->chip->retrigger(irq);
 		}
 		desc->chip->enable(irq);
 		/* fall-through */

commit 096c8131c573ed37939dc3f1440221c92c87e74b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Jun 29 02:24:44 2006 -0700

    [PATCH] genirq: debug: better debug printout in enable_irq()
    
    Make enable_irq() debug printouts user-readable.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 8389d1817fe8..76c8eda67295 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -114,6 +114,7 @@ void enable_irq(unsigned int irq)
 	spin_lock_irqsave(&desc->lock, flags);
 	switch (desc->depth) {
 	case 0:
+		printk(KERN_WARNING "Unablanced enable_irq(%d)\n", irq);
 		WARN_ON(1);
 		break;
 	case 1: {

commit 0d7012a968d006e277eb0fe20edd7a9b5563c2b7
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 29 02:24:43 2006 -0700

    [PATCH] genirq: cleanup: turn ARCH_HAS_IRQ_PER_CPU into CONFIG_IRQ_PER_CPU
    
    Cleanup: change ARCH_HAS_IRQ_PER_CPU into a Kconfig method.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index ca9b5d36abe8..8389d1817fe8 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -198,7 +198,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 		if (!(old->flags & new->flags & SA_SHIRQ))
 			goto mismatch;
 
-#if defined(ARCH_HAS_IRQ_PER_CPU) && defined(SA_PERCPU_IRQ)
+#if defined(CONFIG_IRQ_PER_CPU) && defined(SA_PERCPU_IRQ)
 		/* All handlers must agree on per-cpuness */
 		if ((old->flags & IRQ_PER_CPU) != (new->flags & IRQ_PER_CPU))
 			goto mismatch;
@@ -213,7 +213,7 @@ int setup_irq(unsigned int irq, struct irqaction *new)
 	}
 
 	*p = new;
-#if defined(ARCH_HAS_IRQ_PER_CPU) && defined(SA_PERCPU_IRQ)
+#if defined(CONFIG_IRQ_PER_CPU) && defined(SA_PERCPU_IRQ)
 	if (new->flags & SA_PERCPU_IRQ)
 		desc->status |= IRQ_PER_CPU;
 #endif

commit cd916d31cc31273eca8a620fae02b7bf7f577559
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 29 02:24:42 2006 -0700

    [PATCH] genirq: cleanup: merge pending_irq_cpumask[] into irq_desc[]
    
    Consolidation: remove the pending_irq_cpumask[NR_IRQS] array and move it into
    the irq_desc[NR_IRQS].pending_mask field.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 6a6f1d3dd399..ca9b5d36abe8 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -16,10 +16,6 @@
 
 #ifdef CONFIG_SMP
 
-#if defined (CONFIG_GENERIC_PENDING_IRQ) || defined (CONFIG_IRQBALANCE)
-cpumask_t __cacheline_aligned pending_irq_cpumask[NR_IRQS];
-#endif
-
 /**
  *	synchronize_irq - wait for pending IRQ handlers (on other CPUs)
  *	@irq: interrupt number to wait for

commit 34ffdb7233d5847808d2b63ca6761dac3af9c942
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 29 02:24:40 2006 -0700

    [PATCH] genirq: cleanup: reduce irq_desc_t use, mark it obsolete
    
    Cleanup: remove irq_desc_t use from the generic IRQ code, and mark it
    obsolete.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 261906ebdf04..6a6f1d3dd399 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -57,7 +57,7 @@ EXPORT_SYMBOL(synchronize_irq);
  */
 void disable_irq_nosync(unsigned int irq)
 {
-	irq_desc_t *desc = irq_desc + irq;
+	struct irq_desc *desc = irq_desc + irq;
 	unsigned long flags;
 
 	if (irq >= NR_IRQS)
@@ -86,7 +86,7 @@ EXPORT_SYMBOL(disable_irq_nosync);
  */
 void disable_irq(unsigned int irq)
 {
-	irq_desc_t *desc = irq_desc + irq;
+	struct irq_desc *desc = irq_desc + irq;
 
 	if (irq >= NR_IRQS)
 		return;
@@ -109,7 +109,7 @@ EXPORT_SYMBOL(disable_irq);
  */
 void enable_irq(unsigned int irq)
 {
-	irq_desc_t *desc = irq_desc + irq;
+	struct irq_desc *desc = irq_desc + irq;
 	unsigned long flags;
 
 	if (irq >= NR_IRQS)

commit 06fcb0c6fb3aae9570a32ac3b72a8222563baa69
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 29 02:24:40 2006 -0700

    [PATCH] genirq: cleanup: misc code cleanups
    
    Assorted code cleanups to the generic IRQ code.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index c53662edc73d..261906ebdf04 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -40,7 +40,6 @@ void synchronize_irq(unsigned int irq)
 	while (desc->status & IRQ_INPROGRESS)
 		cpu_relax();
 }
-
 EXPORT_SYMBOL(synchronize_irq);
 
 #endif
@@ -71,7 +70,6 @@ void disable_irq_nosync(unsigned int irq)
 	}
 	spin_unlock_irqrestore(&desc->lock, flags);
 }
-
 EXPORT_SYMBOL(disable_irq_nosync);
 
 /**
@@ -97,7 +95,6 @@ void disable_irq(unsigned int irq)
 	if (desc->action)
 		synchronize_irq(irq);
 }
-
 EXPORT_SYMBOL(disable_irq);
 
 /**
@@ -139,7 +136,6 @@ void enable_irq(unsigned int irq)
 	}
 	spin_unlock_irqrestore(&desc->lock, flags);
 }
-
 EXPORT_SYMBOL(enable_irq);
 
 /*
@@ -166,7 +162,7 @@ int can_request_irq(unsigned int irq, unsigned long irqflags)
  * Internal function to register an irqaction - typically used to
  * allocate special interrupts that are part of the architecture.
  */
-int setup_irq(unsigned int irq, struct irqaction * new)
+int setup_irq(unsigned int irq, struct irqaction *new)
 {
 	struct irq_desc *desc = irq_desc + irq;
 	struct irqaction *old, **p;
@@ -198,9 +194,10 @@ int setup_irq(unsigned int irq, struct irqaction * new)
 	/*
 	 * The following block of code has to be executed atomically
 	 */
-	spin_lock_irqsave(&desc->lock,flags);
+	spin_lock_irqsave(&desc->lock, flags);
 	p = &desc->action;
-	if ((old = *p) != NULL) {
+	old = *p;
+	if (old) {
 		/* Can't share interrupts unless both agree to */
 		if (!(old->flags & new->flags & SA_SHIRQ))
 			goto mismatch;
@@ -233,7 +230,7 @@ int setup_irq(unsigned int irq, struct irqaction * new)
 		else
 			desc->chip->enable(irq);
 	}
-	spin_unlock_irqrestore(&desc->lock,flags);
+	spin_unlock_irqrestore(&desc->lock, flags);
 
 	new->irq = irq;
 	register_irq_proc(irq);
@@ -276,10 +273,10 @@ void free_irq(unsigned int irq, void *dev_id)
 		return;
 
 	desc = irq_desc + irq;
-	spin_lock_irqsave(&desc->lock,flags);
+	spin_lock_irqsave(&desc->lock, flags);
 	p = &desc->action;
 	for (;;) {
-		struct irqaction * action = *p;
+		struct irqaction *action = *p;
 
 		if (action) {
 			struct irqaction **pp = p;
@@ -304,7 +301,7 @@ void free_irq(unsigned int irq, void *dev_id)
 				else
 					desc->chip->disable(irq);
 			}
-			spin_unlock_irqrestore(&desc->lock,flags);
+			spin_unlock_irqrestore(&desc->lock, flags);
 			unregister_handler_proc(irq, action);
 
 			/* Make sure it's not being used on another CPU */
@@ -312,12 +309,11 @@ void free_irq(unsigned int irq, void *dev_id)
 			kfree(action);
 			return;
 		}
-		printk(KERN_ERR "Trying to free free IRQ%d\n",irq);
-		spin_unlock_irqrestore(&desc->lock,flags);
+		printk(KERN_ERR "Trying to free free IRQ%d\n", irq);
+		spin_unlock_irqrestore(&desc->lock, flags);
 		return;
 	}
 }
-
 EXPORT_SYMBOL(free_irq);
 
 /**
@@ -351,9 +347,9 @@ EXPORT_SYMBOL(free_irq);
  */
 int request_irq(unsigned int irq,
 		irqreturn_t (*handler)(int, void *, struct pt_regs *),
-		unsigned long irqflags, const char * devname, void *dev_id)
+		unsigned long irqflags, const char *devname, void *dev_id)
 {
-	struct irqaction * action;
+	struct irqaction *action;
 	int retval;
 
 	/*
@@ -388,6 +384,5 @@ int request_irq(unsigned int irq,
 
 	return retval;
 }
-
 EXPORT_SYMBOL(request_irq);
 

commit a53da52fd743fd637637572838c0a7af23a2d038
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 29 02:24:38 2006 -0700

    [PATCH] genirq: cleanup: merge irq_affinity[] into irq_desc[]
    
    Consolidation: remove the irq_affinity[NR_IRQS] array and move it into the
    irq_desc[NR_IRQS].affinity field.
    
    [akpm@osdl.org: sparc64 build fix]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 31ee1f3bfcf9..c53662edc73d 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -16,8 +16,6 @@
 
 #ifdef CONFIG_SMP
 
-cpumask_t irq_affinity[NR_IRQS] = { [0 ... NR_IRQS-1] = CPU_MASK_ALL };
-
 #if defined (CONFIG_GENERIC_PENDING_IRQ) || defined (CONFIG_IRQBALANCE)
 cpumask_t __cacheline_aligned pending_irq_cpumask[NR_IRQS];
 #endif

commit d1bef4ed5faf7d9872337b33c4269e45ae1bf960
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 29 02:24:36 2006 -0700

    [PATCH] genirq: rename desc->handler to desc->chip
    
    This patch-queue improves the generic IRQ layer to be truly generic, by adding
    various abstractions and features to it, without impacting existing
    functionality.
    
    While the queue can be best described as "fix and improve everything in the
    generic IRQ layer that we could think of", and thus it consists of many
    smaller features and lots of cleanups, the one feature that stands out most is
    the new 'irq chip' abstraction.
    
    The irq-chip abstraction is about describing and coding and IRQ controller
    driver by mapping its raw hardware capabilities [and quirks, if needed] in a
    straightforward way, without having to think about "IRQ flow"
    (level/edge/etc.) type of details.
    
    This stands in contrast with the current 'irq-type' model of genirq
    architectures, which 'mixes' raw hardware capabilities with 'flow' details.
    The patchset supports both types of irq controller designs at once, and
    converts i386 and x86_64 to the new irq-chip design.
    
    As a bonus side-effect of the irq-chip approach, chained interrupt controllers
    (master/slave PIC constructs, etc.) are now supported by design as well.
    
    The end result of this patchset intends to be simpler architecture-level code
    and more consolidation between architectures.
    
    We reused many bits of code and many concepts from Russell King's ARM IRQ
    layer, the merging of which was one of the motivations for this patchset.
    
    This patch:
    
    rename desc->handler to desc->chip.
    
    Originally i did not want to do this, because it's a big patch.  But having
    both "desc->handler", "desc->handle_irq" and "action->handler" caused a
    large degree of confusion and made the code appear alot less clean than it
    truly is.
    
    I have also attempted a dual approach as well by introducing a
    desc->chip alias - but that just wasnt robust enough and broke
    frequently.
    
    So lets get over with this quickly.  The conversion was done automatically
    via scripts and converts all the code in the kernel.
    
    This renaming patch is the first one amongst the patches, so that the
    remaining patches can stay flexible and can be merged and split up
    without having some big monolithic patch act as a merge barrier.
    
    [akpm@osdl.org: build fix]
    [akpm@osdl.org: another build fix]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 1279e3499534..31ee1f3bfcf9 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -69,7 +69,7 @@ void disable_irq_nosync(unsigned int irq)
 	spin_lock_irqsave(&desc->lock, flags);
 	if (!desc->depth++) {
 		desc->status |= IRQ_DISABLED;
-		desc->handler->disable(irq);
+		desc->chip->disable(irq);
 	}
 	spin_unlock_irqrestore(&desc->lock, flags);
 }
@@ -131,9 +131,9 @@ void enable_irq(unsigned int irq)
 		desc->status = status;
 		if ((status & (IRQ_PENDING | IRQ_REPLAY)) == IRQ_PENDING) {
 			desc->status = status | IRQ_REPLAY;
-			hw_resend_irq(desc->handler,irq);
+			hw_resend_irq(desc->chip,irq);
 		}
-		desc->handler->enable(irq);
+		desc->chip->enable(irq);
 		/* fall-through */
 	}
 	default:
@@ -178,7 +178,7 @@ int setup_irq(unsigned int irq, struct irqaction * new)
 	if (irq >= NR_IRQS)
 		return -EINVAL;
 
-	if (desc->handler == &no_irq_type)
+	if (desc->chip == &no_irq_type)
 		return -ENOSYS;
 	/*
 	 * Some drivers like serial.c use request_irq() heavily,
@@ -230,10 +230,10 @@ int setup_irq(unsigned int irq, struct irqaction * new)
 		desc->depth = 0;
 		desc->status &= ~(IRQ_DISABLED | IRQ_AUTODETECT |
 				  IRQ_WAITING | IRQ_INPROGRESS);
-		if (desc->handler->startup)
-			desc->handler->startup(irq);
+		if (desc->chip->startup)
+			desc->chip->startup(irq);
 		else
-			desc->handler->enable(irq);
+			desc->chip->enable(irq);
 	}
 	spin_unlock_irqrestore(&desc->lock,flags);
 
@@ -295,16 +295,16 @@ void free_irq(unsigned int irq, void *dev_id)
 
 			/* Currently used only by UML, might disappear one day.*/
 #ifdef CONFIG_IRQ_RELEASE_METHOD
-			if (desc->handler->release)
-				desc->handler->release(irq, dev_id);
+			if (desc->chip->release)
+				desc->chip->release(irq, dev_id);
 #endif
 
 			if (!desc->action) {
 				desc->status |= IRQ_DISABLED;
-				if (desc->handler->shutdown)
-					desc->handler->shutdown(irq);
+				if (desc->chip->shutdown)
+					desc->chip->shutdown(irq);
 				else
-					desc->handler->disable(irq);
+					desc->chip->disable(irq);
 			}
 			spin_unlock_irqrestore(&desc->lock,flags);
 			unregister_handler_proc(irq, action);

commit 13e87ec68641fd54f3fa04eef3419d034ed2115a
Author: Andrew Morton <akpm@osdl.org>
Date:   Thu Apr 27 18:39:18 2006 -0700

    [PATCH] request_irq(): remove warnings from irq probing
    
    - Add new SA_PROBEIRQ which suppresses the new sharing-mismatch warning.
      Some drivers like to use request_irq() to find an unused interrupt slot.
    
    - Use it in i82365.c
    
    - Kill unused SA_PROBE.
    
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index ac766ad573e8..1279e3499534 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -246,8 +246,10 @@ int setup_irq(unsigned int irq, struct irqaction * new)
 
 mismatch:
 	spin_unlock_irqrestore(&desc->lock, flags);
-	printk(KERN_ERR "%s: irq handler mismatch\n", __FUNCTION__);
-	dump_stack();
+	if (!(new->flags & SA_PROBEIRQ)) {
+		printk(KERN_ERR "%s: irq handler mismatch\n", __FUNCTION__);
+		dump_stack();
+	}
 	return -EBUSY;
 }
 

commit cd7b24bb1891a10ee25168a912ff2304a9571d23
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Mar 26 01:36:54 2006 -0800

    [PATCH] warn if free_irq() is called from IRQ context
    
    Warn if free_irq() is called in IRQ context - free_irq() can execute /proc
    VFS work, which must not be done in IRQ context.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 6edfcef291e8..ac766ad573e8 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -271,6 +271,7 @@ void free_irq(unsigned int irq, void *dev_id)
 	struct irqaction **p;
 	unsigned long flags;
 
+	WARN_ON(in_interrupt());
 	if (irq >= NR_IRQS)
 		return;
 

commit f5163427453bc6ca2dd497eeb3e7a30d1c74b487
Author: Dimitri Sivanich <sivanich@sgi.com>
Date:   Sat Mar 25 03:08:23 2006 -0800

    [PATCH] Add SA_PERCPU_IRQ flag support
    
    Add support for SA_PERCPU_IRQ (only mmtimer.c uses this at this stage).
    
    Signed-off-by: Dimitri Sivanich <sivanich@sgi.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 97d5559997d2..6edfcef291e8 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -204,10 +204,14 @@ int setup_irq(unsigned int irq, struct irqaction * new)
 	p = &desc->action;
 	if ((old = *p) != NULL) {
 		/* Can't share interrupts unless both agree to */
-		if (!(old->flags & new->flags & SA_SHIRQ)) {
-			spin_unlock_irqrestore(&desc->lock,flags);
-			return -EBUSY;
-		}
+		if (!(old->flags & new->flags & SA_SHIRQ))
+			goto mismatch;
+
+#if defined(ARCH_HAS_IRQ_PER_CPU) && defined(SA_PERCPU_IRQ)
+		/* All handlers must agree on per-cpuness */
+		if ((old->flags & IRQ_PER_CPU) != (new->flags & IRQ_PER_CPU))
+			goto mismatch;
+#endif
 
 		/* add new interrupt at end of irq queue */
 		do {
@@ -218,7 +222,10 @@ int setup_irq(unsigned int irq, struct irqaction * new)
 	}
 
 	*p = new;
-
+#if defined(ARCH_HAS_IRQ_PER_CPU) && defined(SA_PERCPU_IRQ)
+	if (new->flags & SA_PERCPU_IRQ)
+		desc->status |= IRQ_PER_CPU;
+#endif
 	if (!shared) {
 		desc->depth = 0;
 		desc->status &= ~(IRQ_DISABLED | IRQ_AUTODETECT |
@@ -236,6 +243,12 @@ int setup_irq(unsigned int irq, struct irqaction * new)
 	register_handler_proc(irq, new);
 
 	return 0;
+
+mismatch:
+	spin_unlock_irqrestore(&desc->lock, flags);
+	printk(KERN_ERR "%s: irq handler mismatch\n", __FUNCTION__);
+	dump_stack();
+	return -EBUSY;
 }
 
 /**

commit eee45269b0f5979c70bc151c6c2f4e5f4f5ababe
Author: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
Date:   Fri Jan 6 00:12:21 2006 -0800

    [PATCH] Alpha: convert to generic irq framework (generic part)
    
    Thanks to Christoph for doing most of the work.
    
    This allows automatic SMP IRQ affinity assignment other than default "all
    interrupts on all CPUs" which is rather expensive.  This might be useful if
    the hardware can be programmed to distribute interrupts among different
    CPUs, like Alpha does.
    
    Signed-off-by: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Richard Henderson <rth@twiddle.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 81c49a4d679e..97d5559997d2 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -366,6 +366,8 @@ int request_irq(unsigned int irq,
 	action->next = NULL;
 	action->dev_id = dev_id;
 
+	select_smp_affinity(irq);
+
 	retval = setup_irq(irq, action);
 	if (retval)
 		kfree(action);

commit c2b5a251b9feca727661f1a3278cafb1de4c80f3
Author: Matthew Wilcox <matthew@wil.cx>
Date:   Thu Nov 3 07:51:18 2005 -0700

    [PATCH] Check the irq number is within bounds
    
    Most of the functions already check. Do the ones that didn't.
    
    Signed-off-by: Matthew Wilcox <matthew@wil.cx>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 3bd7226d15fa..81c49a4d679e 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -36,6 +36,9 @@ void synchronize_irq(unsigned int irq)
 {
 	struct irq_desc *desc = irq_desc + irq;
 
+	if (irq >= NR_IRQS)
+		return;
+
 	while (desc->status & IRQ_INPROGRESS)
 		cpu_relax();
 }
@@ -60,6 +63,9 @@ void disable_irq_nosync(unsigned int irq)
 	irq_desc_t *desc = irq_desc + irq;
 	unsigned long flags;
 
+	if (irq >= NR_IRQS)
+		return;
+
 	spin_lock_irqsave(&desc->lock, flags);
 	if (!desc->depth++) {
 		desc->status |= IRQ_DISABLED;
@@ -86,6 +92,9 @@ void disable_irq(unsigned int irq)
 {
 	irq_desc_t *desc = irq_desc + irq;
 
+	if (irq >= NR_IRQS)
+		return;
+
 	disable_irq_nosync(irq);
 	if (desc->action)
 		synchronize_irq(irq);
@@ -108,6 +117,9 @@ void enable_irq(unsigned int irq)
 	irq_desc_t *desc = irq_desc + irq;
 	unsigned long flags;
 
+	if (irq >= NR_IRQS)
+		return;
+
 	spin_lock_irqsave(&desc->lock, flags);
 	switch (desc->depth) {
 	case 0:
@@ -163,6 +175,9 @@ int setup_irq(unsigned int irq, struct irqaction * new)
 	unsigned long flags;
 	int shared = 0;
 
+	if (irq >= NR_IRQS)
+		return -EINVAL;
+
 	if (desc->handler == &no_irq_type)
 		return -ENOSYS;
 	/*

commit 1e5d533142c1c178a31d4cc81837eb078f9269bc
Author: Randy Dunlap <rdunlap@xenotime.net>
Date:   Mon Nov 7 01:01:06 2005 -0800

    [PATCH] more kernel-doc cleanups, additions
    
    Various core kernel-doc cleanups:
    - add missing function parameters in ipc, irq/manage, kernel/sys,
      kernel/sysctl, and mm/slab;
    - move description to just above function for kernel_restart()
    
    Signed-off-by: Randy Dunlap <rdunlap@xenotime.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 1cfdb08ddf20..3bd7226d15fa 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -24,6 +24,7 @@ cpumask_t __cacheline_aligned pending_irq_cpumask[NR_IRQS];
 
 /**
  *	synchronize_irq - wait for pending IRQ handlers (on other CPUs)
+ *	@irq: interrupt number to wait for
  *
  *	This function waits for any pending IRQ handlers for this interrupt
  *	to complete before returning. If you use this function while

commit 54d5d42404e7705cf3804593189e963350d470e5
Author: Ashok Raj <ashok.raj@intel.com>
Date:   Tue Sep 6 15:16:15 2005 -0700

    [PATCH] x86/x86_64: deferred handling of writes to /proc/irqxx/smp_affinity
    
    When handling writes to /proc/irq, current code is re-programming rte
    entries directly. This is not recommended and could potentially cause
    chipset's to lockup, or cause missing interrupts.
    
    CONFIG_IRQ_BALANCE does this correctly, where it re-programs only when the
    interrupt is pending. The same needs to be done for /proc/irq handling as well.
    Otherwise user space irq balancers are really not doing the right thing.
    
    - Changed pending_irq_balance_cpumask to pending_irq_migrate_cpumask for
      lack of a generic name.
    - added move_irq out of IRQ_BALANCE, and added this same to X86_64
    - Added new proc handler for write, so we can do deferred write at irq
      handling time.
    - Display of /proc/irq/XX/smp_affinity used to display CPU_MASKALL, instead
      it now shows only active cpu masks, or exactly what was set.
    - Provided a common move_irq implementation, instead of duplicating
      when using generic irq framework.
    
    Tested on i386/x86_64 and ia64 with CONFIG_PCI_MSI turned on and off.
    Tested UP builds as well.
    
    MSI testing: tbd: I have cards, need to look for a x-over cable, although I
    did test an earlier version of this patch.  Will test in a couple days.
    
    Signed-off-by: Ashok Raj <ashok.raj@intel.com>
    Acked-by: Zwane Mwaikambo <zwane@holomorphy.com>
    Grudgingly-acked-by: Andi Kleen <ak@muc.de>
    Signed-off-by: Coywolf Qi Hunt <coywolf@lovecn.org>
    Signed-off-by: Ashok Raj <ashok.raj@intel.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index ac6700985705..1cfdb08ddf20 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -18,6 +18,10 @@
 
 cpumask_t irq_affinity[NR_IRQS] = { [0 ... NR_IRQS-1] = CPU_MASK_ALL };
 
+#if defined (CONFIG_GENERIC_PENDING_IRQ) || defined (CONFIG_IRQBALANCE)
+cpumask_t __cacheline_aligned pending_irq_cpumask[NR_IRQS];
+#endif
+
 /**
  *	synchronize_irq - wait for pending IRQ handlers (on other CPUs)
  *

commit b77d6adc922b8bbf8b16b67f567958c42962cf88
Author: Paolo 'Blaisorblade' Giarrusso <blaisorblade@yahoo.it>
Date:   Tue Jun 21 17:16:24 2005 -0700

    [PATCH] uml: make hw_controller_type->release exist only for archs needing it
    
    With Chris Wedgwood <cw@f00f.org>
    
    As suggested by Chris, we can make the "just added" method ->release
    conditional to UML only (better: to archs requesting it, i.e.  only UML
    currently), so that other archs don't get this unneeded crud, and if UML
    won't need it any more we can kill this.
    
    Signed-off-by: Paolo 'Blaisorblade' Giarrusso <blaisorblade@yahoo.it>
    CC: Ingo Molnar <mingo@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 5fde8177eedf..ac6700985705 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -6,6 +6,7 @@
  * This file contains driver APIs to the irq subsystem.
  */
 
+#include <linux/config.h>
 #include <linux/irq.h>
 #include <linux/module.h>
 #include <linux/random.h>
@@ -256,8 +257,11 @@ void free_irq(unsigned int irq, void *dev_id)
 			/* Found it - now remove it from the list of entries */
 			*pp = action->next;
 
+			/* Currently used only by UML, might disappear one day.*/
+#ifdef CONFIG_IRQ_RELEASE_METHOD
 			if (desc->handler->release)
 				desc->handler->release(irq, dev_id);
+#endif
 
 			if (!desc->action) {
 				desc->status |= IRQ_DISABLED;

commit dbce706e2550253c5ab6043f4f5dfde0cd02470f
Author: Paolo 'Blaisorblade' Giarrusso <blaisorblade@yahoo.it>
Date:   Tue Jun 21 17:16:19 2005 -0700

    [PATCH] uml: add and use generic hw_controller_type->release
    
    With Chris Wedgwood <cw@f00f.org>
    
    Currently UML must explicitly call the UML-specific
    free_irq_by_irq_and_dev() for each free_irq call it's done.
    
    This is needed because ->shutdown and/or ->disable are only called when the
    last "action" for that irq is removed.
    
    Instead, for UML shared IRQs (UML IRQs are very often, if not always,
    shared), for each dev_id some setup is done, which must be cleared on the
    release of that fd.  For instance, for each open console a new instance
    (i.e.  new dev_id) of the same IRQ is requested().
    
    Exactly, a fd is stored in an array (pollfds), which is after read by a
    host thread and passed to poll().  Each event registered by poll() triggers
    an interrupt.  So, for each free_irq() we must remove the corresponding
    host fd from the table, which we do via this -release() method.
    
    In this patch we add an appropriate hook for this, and remove all uses of
    it by pointing the hook to the said procedure; this is safe to do since the
    said procedure.
    
    Also some cosmetic improvements are included.
    
    This is heavily based on some work by Chris Wedgwood, which however didn't
    get the patch merged for something I'd call a "misunderstanding" (the need
    for this patch wasn't cleanly explained, thus adding the generic hook was
    felt as undesirable).
    
    Signed-off-by: Paolo 'Blaisorblade' Giarrusso <blaisorblade@yahoo.it>
    CC: Ingo Molnar <mingo@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 5202e4c4a5b6..5fde8177eedf 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -255,6 +255,10 @@ void free_irq(unsigned int irq, void *dev_id)
 
 			/* Found it - now remove it from the list of entries */
 			*pp = action->next;
+
+			if (desc->handler->release)
+				desc->handler->release(irq, dev_id);
+
 			if (!desc->action) {
 				desc->status |= IRQ_DISABLED;
 				if (desc->handler->shutdown)

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
new file mode 100644
index 000000000000..5202e4c4a5b6
--- /dev/null
+++ b/kernel/irq/manage.c
@@ -0,0 +1,349 @@
+/*
+ * linux/kernel/irq/manage.c
+ *
+ * Copyright (C) 1992, 1998-2004 Linus Torvalds, Ingo Molnar
+ *
+ * This file contains driver APIs to the irq subsystem.
+ */
+
+#include <linux/irq.h>
+#include <linux/module.h>
+#include <linux/random.h>
+#include <linux/interrupt.h>
+
+#include "internals.h"
+
+#ifdef CONFIG_SMP
+
+cpumask_t irq_affinity[NR_IRQS] = { [0 ... NR_IRQS-1] = CPU_MASK_ALL };
+
+/**
+ *	synchronize_irq - wait for pending IRQ handlers (on other CPUs)
+ *
+ *	This function waits for any pending IRQ handlers for this interrupt
+ *	to complete before returning. If you use this function while
+ *	holding a resource the IRQ handler may need you will deadlock.
+ *
+ *	This function may be called - with care - from IRQ context.
+ */
+void synchronize_irq(unsigned int irq)
+{
+	struct irq_desc *desc = irq_desc + irq;
+
+	while (desc->status & IRQ_INPROGRESS)
+		cpu_relax();
+}
+
+EXPORT_SYMBOL(synchronize_irq);
+
+#endif
+
+/**
+ *	disable_irq_nosync - disable an irq without waiting
+ *	@irq: Interrupt to disable
+ *
+ *	Disable the selected interrupt line.  Disables and Enables are
+ *	nested.
+ *	Unlike disable_irq(), this function does not ensure existing
+ *	instances of the IRQ handler have completed before returning.
+ *
+ *	This function may be called from IRQ context.
+ */
+void disable_irq_nosync(unsigned int irq)
+{
+	irq_desc_t *desc = irq_desc + irq;
+	unsigned long flags;
+
+	spin_lock_irqsave(&desc->lock, flags);
+	if (!desc->depth++) {
+		desc->status |= IRQ_DISABLED;
+		desc->handler->disable(irq);
+	}
+	spin_unlock_irqrestore(&desc->lock, flags);
+}
+
+EXPORT_SYMBOL(disable_irq_nosync);
+
+/**
+ *	disable_irq - disable an irq and wait for completion
+ *	@irq: Interrupt to disable
+ *
+ *	Disable the selected interrupt line.  Enables and Disables are
+ *	nested.
+ *	This function waits for any pending IRQ handlers for this interrupt
+ *	to complete before returning. If you use this function while
+ *	holding a resource the IRQ handler may need you will deadlock.
+ *
+ *	This function may be called - with care - from IRQ context.
+ */
+void disable_irq(unsigned int irq)
+{
+	irq_desc_t *desc = irq_desc + irq;
+
+	disable_irq_nosync(irq);
+	if (desc->action)
+		synchronize_irq(irq);
+}
+
+EXPORT_SYMBOL(disable_irq);
+
+/**
+ *	enable_irq - enable handling of an irq
+ *	@irq: Interrupt to enable
+ *
+ *	Undoes the effect of one call to disable_irq().  If this
+ *	matches the last disable, processing of interrupts on this
+ *	IRQ line is re-enabled.
+ *
+ *	This function may be called from IRQ context.
+ */
+void enable_irq(unsigned int irq)
+{
+	irq_desc_t *desc = irq_desc + irq;
+	unsigned long flags;
+
+	spin_lock_irqsave(&desc->lock, flags);
+	switch (desc->depth) {
+	case 0:
+		WARN_ON(1);
+		break;
+	case 1: {
+		unsigned int status = desc->status & ~IRQ_DISABLED;
+
+		desc->status = status;
+		if ((status & (IRQ_PENDING | IRQ_REPLAY)) == IRQ_PENDING) {
+			desc->status = status | IRQ_REPLAY;
+			hw_resend_irq(desc->handler,irq);
+		}
+		desc->handler->enable(irq);
+		/* fall-through */
+	}
+	default:
+		desc->depth--;
+	}
+	spin_unlock_irqrestore(&desc->lock, flags);
+}
+
+EXPORT_SYMBOL(enable_irq);
+
+/*
+ * Internal function that tells the architecture code whether a
+ * particular irq has been exclusively allocated or is available
+ * for driver use.
+ */
+int can_request_irq(unsigned int irq, unsigned long irqflags)
+{
+	struct irqaction *action;
+
+	if (irq >= NR_IRQS)
+		return 0;
+
+	action = irq_desc[irq].action;
+	if (action)
+		if (irqflags & action->flags & SA_SHIRQ)
+			action = NULL;
+
+	return !action;
+}
+
+/*
+ * Internal function to register an irqaction - typically used to
+ * allocate special interrupts that are part of the architecture.
+ */
+int setup_irq(unsigned int irq, struct irqaction * new)
+{
+	struct irq_desc *desc = irq_desc + irq;
+	struct irqaction *old, **p;
+	unsigned long flags;
+	int shared = 0;
+
+	if (desc->handler == &no_irq_type)
+		return -ENOSYS;
+	/*
+	 * Some drivers like serial.c use request_irq() heavily,
+	 * so we have to be careful not to interfere with a
+	 * running system.
+	 */
+	if (new->flags & SA_SAMPLE_RANDOM) {
+		/*
+		 * This function might sleep, we want to call it first,
+		 * outside of the atomic block.
+		 * Yes, this might clear the entropy pool if the wrong
+		 * driver is attempted to be loaded, without actually
+		 * installing a new handler, but is this really a problem,
+		 * only the sysadmin is able to do this.
+		 */
+		rand_initialize_irq(irq);
+	}
+
+	/*
+	 * The following block of code has to be executed atomically
+	 */
+	spin_lock_irqsave(&desc->lock,flags);
+	p = &desc->action;
+	if ((old = *p) != NULL) {
+		/* Can't share interrupts unless both agree to */
+		if (!(old->flags & new->flags & SA_SHIRQ)) {
+			spin_unlock_irqrestore(&desc->lock,flags);
+			return -EBUSY;
+		}
+
+		/* add new interrupt at end of irq queue */
+		do {
+			p = &old->next;
+			old = *p;
+		} while (old);
+		shared = 1;
+	}
+
+	*p = new;
+
+	if (!shared) {
+		desc->depth = 0;
+		desc->status &= ~(IRQ_DISABLED | IRQ_AUTODETECT |
+				  IRQ_WAITING | IRQ_INPROGRESS);
+		if (desc->handler->startup)
+			desc->handler->startup(irq);
+		else
+			desc->handler->enable(irq);
+	}
+	spin_unlock_irqrestore(&desc->lock,flags);
+
+	new->irq = irq;
+	register_irq_proc(irq);
+	new->dir = NULL;
+	register_handler_proc(irq, new);
+
+	return 0;
+}
+
+/**
+ *	free_irq - free an interrupt
+ *	@irq: Interrupt line to free
+ *	@dev_id: Device identity to free
+ *
+ *	Remove an interrupt handler. The handler is removed and if the
+ *	interrupt line is no longer in use by any driver it is disabled.
+ *	On a shared IRQ the caller must ensure the interrupt is disabled
+ *	on the card it drives before calling this function. The function
+ *	does not return until any executing interrupts for this IRQ
+ *	have completed.
+ *
+ *	This function must not be called from interrupt context.
+ */
+void free_irq(unsigned int irq, void *dev_id)
+{
+	struct irq_desc *desc;
+	struct irqaction **p;
+	unsigned long flags;
+
+	if (irq >= NR_IRQS)
+		return;
+
+	desc = irq_desc + irq;
+	spin_lock_irqsave(&desc->lock,flags);
+	p = &desc->action;
+	for (;;) {
+		struct irqaction * action = *p;
+
+		if (action) {
+			struct irqaction **pp = p;
+
+			p = &action->next;
+			if (action->dev_id != dev_id)
+				continue;
+
+			/* Found it - now remove it from the list of entries */
+			*pp = action->next;
+			if (!desc->action) {
+				desc->status |= IRQ_DISABLED;
+				if (desc->handler->shutdown)
+					desc->handler->shutdown(irq);
+				else
+					desc->handler->disable(irq);
+			}
+			spin_unlock_irqrestore(&desc->lock,flags);
+			unregister_handler_proc(irq, action);
+
+			/* Make sure it's not being used on another CPU */
+			synchronize_irq(irq);
+			kfree(action);
+			return;
+		}
+		printk(KERN_ERR "Trying to free free IRQ%d\n",irq);
+		spin_unlock_irqrestore(&desc->lock,flags);
+		return;
+	}
+}
+
+EXPORT_SYMBOL(free_irq);
+
+/**
+ *	request_irq - allocate an interrupt line
+ *	@irq: Interrupt line to allocate
+ *	@handler: Function to be called when the IRQ occurs
+ *	@irqflags: Interrupt type flags
+ *	@devname: An ascii name for the claiming device
+ *	@dev_id: A cookie passed back to the handler function
+ *
+ *	This call allocates interrupt resources and enables the
+ *	interrupt line and IRQ handling. From the point this
+ *	call is made your handler function may be invoked. Since
+ *	your handler function must clear any interrupt the board
+ *	raises, you must take care both to initialise your hardware
+ *	and to set up the interrupt handler in the right order.
+ *
+ *	Dev_id must be globally unique. Normally the address of the
+ *	device data structure is used as the cookie. Since the handler
+ *	receives this value it makes sense to use it.
+ *
+ *	If your interrupt is shared you must pass a non NULL dev_id
+ *	as this is required when freeing the interrupt.
+ *
+ *	Flags:
+ *
+ *	SA_SHIRQ		Interrupt is shared
+ *	SA_INTERRUPT		Disable local interrupts while processing
+ *	SA_SAMPLE_RANDOM	The interrupt can be used for entropy
+ *
+ */
+int request_irq(unsigned int irq,
+		irqreturn_t (*handler)(int, void *, struct pt_regs *),
+		unsigned long irqflags, const char * devname, void *dev_id)
+{
+	struct irqaction * action;
+	int retval;
+
+	/*
+	 * Sanity-check: shared interrupts must pass in a real dev-ID,
+	 * otherwise we'll have trouble later trying to figure out
+	 * which interrupt is which (messes up the interrupt freeing
+	 * logic etc).
+	 */
+	if ((irqflags & SA_SHIRQ) && !dev_id)
+		return -EINVAL;
+	if (irq >= NR_IRQS)
+		return -EINVAL;
+	if (!handler)
+		return -EINVAL;
+
+	action = kmalloc(sizeof(struct irqaction), GFP_ATOMIC);
+	if (!action)
+		return -ENOMEM;
+
+	action->handler = handler;
+	action->flags = irqflags;
+	cpus_clear(action->mask);
+	action->name = devname;
+	action->next = NULL;
+	action->dev_id = dev_id;
+
+	retval = setup_irq(irq, action);
+	if (retval)
+		kfree(action);
+
+	return retval;
+}
+
+EXPORT_SYMBOL(request_irq);
+
