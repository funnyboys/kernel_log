commit 1e474b28e78897d0d170fab3b28ba683149cb9ea
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Wed Feb 5 06:34:09 2020 -0800

    smp/up: Make smp_call_function_single() match SMP semantics
    
    In CONFIG_SMP=y kernels, smp_call_function_single() returns -ENXIO when
    invoked for a non-existent CPU.  In contrast, in CONFIG_SMP=n kernels,
    a splat is emitted and smp_call_function_single() otherwise silently
    ignores its "cpu" argument, instead pretending that the caller intended
    to have something happen on CPU 0.  Given that there is now code that
    expects smp_call_function_single() to return an error if a bad CPU was
    specified, this difference in semantics needs to be addressed.
    
    Bring the semantics of the CONFIG_SMP=n version of
    smp_call_function_single() into alignment with its CONFIG_SMP=y
    counterpart.
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/20200205143409.GA7021@paulmck-ThinkPad-P72

diff --git a/kernel/up.c b/kernel/up.c
index 53144d056252..c6f323dcd45b 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -14,7 +14,8 @@ int smp_call_function_single(int cpu, void (*func) (void *info), void *info,
 {
 	unsigned long flags;
 
-	WARN_ON(cpu != 0);
+	if (cpu != 0)
+		return -ENXIO;
 
 	local_irq_save(flags);
 	func(info);

commit cb923159bbb8cc8fe09c19a3435ee11fd546f3d3
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Fri Jan 17 10:01:37 2020 +0100

    smp: Remove allocation mask from on_each_cpu_cond.*()
    
    The allocation mask is no longer used by on_each_cpu_cond() and
    on_each_cpu_cond_mask() and can be removed.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lore.kernel.org/r/20200117090137.1205765-4-bigeasy@linutronix.de

diff --git a/kernel/up.c b/kernel/up.c
index 5c0d4f2bece2..53144d056252 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -69,8 +69,7 @@ EXPORT_SYMBOL(on_each_cpu_mask);
  * same condtions in UP and SMP.
  */
 void on_each_cpu_cond_mask(smp_cond_func_t cond_func, smp_call_func_t func,
-			   void *info, bool wait, gfp_t gfp_flags,
-			   const struct cpumask *mask)
+			   void *info, bool wait, const struct cpumask *mask)
 {
 	unsigned long flags;
 
@@ -85,9 +84,9 @@ void on_each_cpu_cond_mask(smp_cond_func_t cond_func, smp_call_func_t func,
 EXPORT_SYMBOL(on_each_cpu_cond_mask);
 
 void on_each_cpu_cond(smp_cond_func_t cond_func, smp_call_func_t func,
-		      void *info, bool wait, gfp_t gfp_flags)
+		      void *info, bool wait)
 {
-	on_each_cpu_cond_mask(cond_func, func, info, wait, gfp_flags, NULL);
+	on_each_cpu_cond_mask(cond_func, func, info, wait, NULL);
 }
 EXPORT_SYMBOL(on_each_cpu_cond);
 

commit 5671d814dbd204b4ecc705045b5f1a647bff6f3b
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Fri Jan 17 10:01:35 2020 +0100

    smp: Use smp_cond_func_t as type for the conditional function
    
    Use a typdef for the conditional function instead defining it each time in
    the function prototype.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lore.kernel.org/r/20200117090137.1205765-2-bigeasy@linutronix.de

diff --git a/kernel/up.c b/kernel/up.c
index 862b460ab97a..5c0d4f2bece2 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -68,9 +68,9 @@ EXPORT_SYMBOL(on_each_cpu_mask);
  * Preemption is disabled here to make sure the cond_func is called under the
  * same condtions in UP and SMP.
  */
-void on_each_cpu_cond_mask(bool (*cond_func)(int cpu, void *info),
-			   smp_call_func_t func, void *info, bool wait,
-			   gfp_t gfp_flags, const struct cpumask *mask)
+void on_each_cpu_cond_mask(smp_cond_func_t cond_func, smp_call_func_t func,
+			   void *info, bool wait, gfp_t gfp_flags,
+			   const struct cpumask *mask)
 {
 	unsigned long flags;
 
@@ -84,9 +84,8 @@ void on_each_cpu_cond_mask(bool (*cond_func)(int cpu, void *info),
 }
 EXPORT_SYMBOL(on_each_cpu_cond_mask);
 
-void on_each_cpu_cond(bool (*cond_func)(int cpu, void *info),
-		      smp_call_func_t func, void *info, bool wait,
-		      gfp_t gfp_flags)
+void on_each_cpu_cond(smp_cond_func_t cond_func, smp_call_func_t func,
+		      void *info, bool wait, gfp_t gfp_flags)
 {
 	on_each_cpu_cond_mask(cond_func, func, info, wait, gfp_flags, NULL);
 }

commit caa759323c73676b3e48c8d9c86093c88b4aba97
Author: Nadav Amit <namit@vmware.com>
Date:   Wed Jun 12 23:48:05 2019 -0700

    smp: Remove smp_call_function() and on_each_cpu() return values
    
    The return value is fixed. Remove it and amend the callers.
    
    [ tglx: Fixup arm/bL_switcher and powerpc/rtas ]
    
    Signed-off-by: Nadav Amit <namit@vmware.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Link: https://lkml.kernel.org/r/20190613064813.8102-2-namit@vmware.com

diff --git a/kernel/up.c b/kernel/up.c
index 483c9962c999..862b460ab97a 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -35,14 +35,13 @@ int smp_call_function_single_async(int cpu, call_single_data_t *csd)
 }
 EXPORT_SYMBOL(smp_call_function_single_async);
 
-int on_each_cpu(smp_call_func_t func, void *info, int wait)
+void on_each_cpu(smp_call_func_t func, void *info, int wait)
 {
 	unsigned long flags;
 
 	local_irq_save(flags);
 	func(info);
 	local_irq_restore(flags);
-	return 0;
 }
 EXPORT_SYMBOL(on_each_cpu);
 

commit 457c89965399115e5cd8bf38f9c597293405703d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun May 19 13:08:55 2019 +0100

    treewide: Add SPDX license identifier for missed files
    
    Add SPDX license identifiers to all files which:
    
     - Have no license information of any form
    
     - Have EXPORT_.*_SYMBOL_GPL inside which was used in the
       initial scan/conversion to ignore the file
    
    These files fall under the project license, GPL v2 only. The resulting SPDX
    license identifier is:
    
      GPL-2.0-only
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/kernel/up.c b/kernel/up.c
index ff536f9cc8a2..483c9962c999 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * Uniprocessor-only support functions.  The counterpart to kernel/smp.c
  */

commit 7d49b28a80b830c3ca876d33bedc58d62a78e16f
Author: Rik van Riel <riel@surriel.com>
Date:   Tue Sep 25 23:58:41 2018 -0400

    smp,cpumask: introduce on_each_cpu_cond_mask
    
    Introduce a variant of on_each_cpu_cond that iterates only over the
    CPUs in a cpumask, in order to avoid making callbacks for every single
    CPU in the system when we only need to test a subset.
    
    Cc: npiggin@gmail.com
    Cc: mingo@kernel.org
    Cc: will.deacon@arm.com
    Cc: songliubraving@fb.com
    Cc: kernel-team@fb.com
    Cc: hpa@zytor.com
    Cc: luto@kernel.org
    Signed-off-by: Rik van Riel <riel@surriel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20180926035844.1420-5-riel@surriel.com

diff --git a/kernel/up.c b/kernel/up.c
index 42c46bf3e0a5..ff536f9cc8a2 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -68,9 +68,9 @@ EXPORT_SYMBOL(on_each_cpu_mask);
  * Preemption is disabled here to make sure the cond_func is called under the
  * same condtions in UP and SMP.
  */
-void on_each_cpu_cond(bool (*cond_func)(int cpu, void *info),
-		      smp_call_func_t func, void *info, bool wait,
-		      gfp_t gfp_flags)
+void on_each_cpu_cond_mask(bool (*cond_func)(int cpu, void *info),
+			   smp_call_func_t func, void *info, bool wait,
+			   gfp_t gfp_flags, const struct cpumask *mask)
 {
 	unsigned long flags;
 
@@ -82,6 +82,14 @@ void on_each_cpu_cond(bool (*cond_func)(int cpu, void *info),
 	}
 	preempt_enable();
 }
+EXPORT_SYMBOL(on_each_cpu_cond_mask);
+
+void on_each_cpu_cond(bool (*cond_func)(int cpu, void *info),
+		      smp_call_func_t func, void *info, bool wait,
+		      gfp_t gfp_flags)
+{
+	on_each_cpu_cond_mask(cond_func, func, info, wait, gfp_flags, NULL);
+}
 EXPORT_SYMBOL(on_each_cpu_cond);
 
 int smp_call_on_cpu(unsigned int cpu, int (*func)(void *), void *par, bool phys)

commit 966a967116e699762dbf4af7f9e0d1955c25aa37
Author: Ying Huang <ying.huang@intel.com>
Date:   Tue Aug 8 12:30:00 2017 +0800

    smp: Avoid using two cache lines for struct call_single_data
    
    struct call_single_data is used in IPIs to transfer information between
    CPUs.  Its size is bigger than sizeof(unsigned long) and less than
    cache line size.  Currently it is not allocated with any explicit alignment
    requirements.  This makes it possible for allocated call_single_data to
    cross two cache lines, which results in double the number of the cache lines
    that need to be transferred among CPUs.
    
    This can be fixed by requiring call_single_data to be aligned with the
    size of call_single_data. Currently the size of call_single_data is the
    power of 2.  If we add new fields to call_single_data, we may need to
    add padding to make sure the size of new definition is the power of 2
    as well.
    
    Fortunately, this is enforced by GCC, which will report bad sizes.
    
    To set alignment requirements of call_single_data to the size of
    call_single_data, a struct definition and a typedef is used.
    
    To test the effect of the patch, I used the vm-scalability multiple
    thread swap test case (swap-w-seq-mt).  The test will create multiple
    threads and each thread will eat memory until all RAM and part of swap
    is used, so that huge number of IPIs are triggered when unmapping
    memory.  In the test, the throughput of memory writing improves ~5%
    compared with misaligned call_single_data, because of faster IPIs.
    
    Suggested-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Huang, Ying <ying.huang@intel.com>
    [ Add call_single_data_t and align with size of call_single_data. ]
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Aaron Lu <aaron.lu@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/87bmnqd6lz.fsf@yhuang-mobile.sh.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/up.c b/kernel/up.c
index ee81ac9af4ca..42c46bf3e0a5 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -23,7 +23,7 @@ int smp_call_function_single(int cpu, void (*func) (void *info), void *info,
 }
 EXPORT_SYMBOL(smp_call_function_single);
 
-int smp_call_function_single_async(int cpu, struct call_single_data *csd)
+int smp_call_function_single_async(int cpu, call_single_data_t *csd)
 {
 	unsigned long flags;
 

commit df8ce9d78a4e7fbe7ddfd8ccee3ecaaa0013e883
Author: Juergen Gross <jgross@suse.com>
Date:   Mon Aug 29 08:48:44 2016 +0200

    smp: Add function to execute a function synchronously on a CPU
    
    On some hardware models (e.g. Dell Studio 1555 laptop) some hardware
    related functions (e.g. SMIs) are to be executed on physical CPU 0
    only. Instead of open coding such a functionality multiple times in
    the kernel add a service function for this purpose. This will enable
    the possibility to take special measures in virtualized environments
    like Xen, too.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Douglas_Warzecha@dell.com
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: akataria@vmware.com
    Cc: boris.ostrovsky@oracle.com
    Cc: chrisw@sous-sol.org
    Cc: david.vrabel@citrix.com
    Cc: hpa@zytor.com
    Cc: jdelvare@suse.com
    Cc: jeremy@goop.org
    Cc: linux@roeck-us.net
    Cc: pali.rohar@gmail.com
    Cc: rusty@rustcorp.com.au
    Cc: virtualization@lists.linux-foundation.org
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/1472453327-19050-4-git-send-email-jgross@suse.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/up.c b/kernel/up.c
index 3ccee2bd13ba..ee81ac9af4ca 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -83,3 +83,20 @@ void on_each_cpu_cond(bool (*cond_func)(int cpu, void *info),
 	preempt_enable();
 }
 EXPORT_SYMBOL(on_each_cpu_cond);
+
+int smp_call_on_cpu(unsigned int cpu, int (*func)(void *), void *par, bool phys)
+{
+	int ret;
+
+	if (cpu != 0)
+		return -ENXIO;
+
+	if (phys)
+		hypervisor_pin_vcpu(0);
+	ret = func(par);
+	if (phys)
+		hypervisor_pin_vcpu(-1);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(smp_call_on_cpu);

commit 47ae4b05d0fa2f2a998ebaf34d2dcbffca56a9db
Author: Juergen Gross <jgross@suse.com>
Date:   Mon Aug 29 08:48:43 2016 +0200

    virt, sched: Add generic vCPU pinning support
    
    Add generic virtualization support for pinning the current vCPU to a
    specified physical CPU. As this operation isn't performance critical
    (a very limited set of operations like BIOS calls and SMIs is expected
    to need this) just add a hypervisor specific indirection.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Douglas_Warzecha@dell.com
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: akataria@vmware.com
    Cc: boris.ostrovsky@oracle.com
    Cc: chrisw@sous-sol.org
    Cc: david.vrabel@citrix.com
    Cc: hpa@zytor.com
    Cc: jdelvare@suse.com
    Cc: jeremy@goop.org
    Cc: linux@roeck-us.net
    Cc: pali.rohar@gmail.com
    Cc: rusty@rustcorp.com.au
    Cc: virtualization@lists.linux-foundation.org
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/1472453327-19050-3-git-send-email-jgross@suse.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/up.c b/kernel/up.c
index 1760bf3d1463..3ccee2bd13ba 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -6,6 +6,7 @@
 #include <linux/kernel.h>
 #include <linux/export.h>
 #include <linux/smp.h>
+#include <linux/hypervisor.h>
 
 int smp_call_function_single(int cpu, void (*func) (void *info), void *info,
 				int wait)

commit c46fff2a3b29794b35d717b5680a27f31a6a6bc0
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Mon Feb 24 16:40:02 2014 +0100

    smp: Rename __smp_call_function_single() to smp_call_function_single_async()
    
    The name __smp_call_function_single() doesn't tell much about the
    properties of this function, especially when compared to
    smp_call_function_single().
    
    The comments above the implementation are also misleading. The main
    point of this function is actually not to be able to embed the csd
    in an object. This is actually a requirement that result from the
    purpose of this function which is to raise an IPI asynchronously.
    
    As such it can be called with interrupts disabled. And this feature
    comes at the cost of the caller who then needs to serialize the
    IPIs on this csd.
    
    Lets rename the function and enhance the comments so that they reflect
    these properties.
    
    Suggested-by: Christoph Hellwig <hch@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Jens Axboe <axboe@fb.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/kernel/up.c b/kernel/up.c
index 4e199d4cef8e..1760bf3d1463 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -22,7 +22,7 @@ int smp_call_function_single(int cpu, void (*func) (void *info), void *info,
 }
 EXPORT_SYMBOL(smp_call_function_single);
 
-int __smp_call_function_single(int cpu, struct call_single_data *csd)
+int smp_call_function_single_async(int cpu, struct call_single_data *csd)
 {
 	unsigned long flags;
 
@@ -31,7 +31,7 @@ int __smp_call_function_single(int cpu, struct call_single_data *csd)
 	local_irq_restore(flags);
 	return 0;
 }
-EXPORT_SYMBOL(__smp_call_function_single);
+EXPORT_SYMBOL(smp_call_function_single_async);
 
 int on_each_cpu(smp_call_func_t func, void *info, int wait)
 {

commit fce8ad1568c57e7f334018dec4fa1744c926c135
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Mon Feb 24 16:40:01 2014 +0100

    smp: Remove wait argument from __smp_call_function_single()
    
    The main point of calling __smp_call_function_single() is to send
    an IPI in a pure asynchronous way. By embedding a csd in an object,
    a caller can send the IPI without waiting for a previous one to complete
    as is required by smp_call_function_single() for example. As such,
    sending this kind of IPI can be safe even when irqs are disabled.
    
    This flexibility comes at the expense of the caller who then needs to
    synchronize the csd lifecycle by himself and make sure that IPIs on a
    single csd are serialized.
    
    This is how __smp_call_function_single() works when wait = 0 and this
    usecase is relevant.
    
    Now there don't seem to be any usecase with wait = 1 that can't be
    covered by smp_call_function_single() instead, which is safer. Lets look
    at the two possible scenario:
    
    1) The user calls __smp_call_function_single(wait = 1) on a csd embedded
       in an object. It looks like a nice and convenient pattern at the first
       sight because we can then retrieve the object from the IPI handler easily.
    
       But actually it is a waste of memory space in the object since the csd
       can be allocated from the stack by smp_call_function_single(wait = 1)
       and the object can be passed an the IPI argument.
    
       Besides that, embedding the csd in an object is more error prone
       because the caller must take care of the serialization of the IPIs
       for this csd.
    
    2) The user calls __smp_call_function_single(wait = 1) on a csd that
       is allocated on the stack. It's ok but smp_call_function_single()
       can do it as well and it already takes care of the allocation on the
       stack. Again it's more simple and less error prone.
    
    Therefore, using the underscore prepend API version with wait = 1
    is a bad pattern and a sign that the caller can do safer and more
    simple.
    
    There was a single user of that which has just been converted.
    So lets remove this option to discourage further users.
    
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Jens Axboe <axboe@fb.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/kernel/up.c b/kernel/up.c
index cdf03d16840e..4e199d4cef8e 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -22,8 +22,7 @@ int smp_call_function_single(int cpu, void (*func) (void *info), void *info,
 }
 EXPORT_SYMBOL(smp_call_function_single);
 
-int __smp_call_function_single(int cpu, struct call_single_data *csd,
-			       int wait)
+int __smp_call_function_single(int cpu, struct call_single_data *csd)
 {
 	unsigned long flags;
 

commit 08eed44c7249d381a099bc55577e55c6bb533160
Author: Jan Kara <jack@suse.cz>
Date:   Mon Feb 24 16:39:57 2014 +0100

    smp: Teach __smp_call_function_single() to check for offline cpus
    
    Align __smp_call_function_single() with smp_call_function_single() so
    that it also checks whether requested cpu is still online.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jens Axboe <axboe@fb.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/kernel/up.c b/kernel/up.c
index 509403e3fbc6..cdf03d16840e 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -22,14 +22,15 @@ int smp_call_function_single(int cpu, void (*func) (void *info), void *info,
 }
 EXPORT_SYMBOL(smp_call_function_single);
 
-void __smp_call_function_single(int cpu, struct call_single_data *csd,
-				int wait)
+int __smp_call_function_single(int cpu, struct call_single_data *csd,
+			       int wait)
 {
 	unsigned long flags;
 
 	local_irq_save(flags);
 	csd->func(csd->info);
 	local_irq_restore(flags);
+	return 0;
 }
 EXPORT_SYMBOL(__smp_call_function_single);
 

commit 40c01e8bd5575e32633192513e09eac7155d6926
Author: Christoph Hellwig <hch@infradead.org>
Date:   Thu Nov 14 14:32:08 2013 -0800

    kernel: provide a __smp_call_function_single stub for !CONFIG_SMP
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/up.c b/kernel/up.c
index 630d72bf7e41..509403e3fbc6 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -22,6 +22,17 @@ int smp_call_function_single(int cpu, void (*func) (void *info), void *info,
 }
 EXPORT_SYMBOL(smp_call_function_single);
 
+void __smp_call_function_single(int cpu, struct call_single_data *csd,
+				int wait)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+	csd->func(csd->info);
+	local_irq_restore(flags);
+}
+EXPORT_SYMBOL(__smp_call_function_single);
+
 int on_each_cpu(smp_call_func_t func, void *info, int wait)
 {
 	unsigned long flags;

commit bff2dc42bcafdd75c0296987747f782965d691a0
Author: David Daney <david.daney@cavium.com>
Date:   Wed Sep 11 14:23:26 2013 -0700

    smp.h: move !SMP version of on_each_cpu() out-of-line
    
    All of the other non-trivial !SMP versions of functions in smp.h are
    out-of-line in up.c.  Move on_each_cpu() there as well.
    
    This allows us to get rid of the #include <linux/irqflags.h>.  The
    drawback is that this makes both the x86_64 and i386 defconfig !SMP
    kernels about 200 bytes larger each.
    
    Signed-off-by: David Daney <david.daney@cavium.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/up.c b/kernel/up.c
index b1cf036255f3..630d72bf7e41 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -22,6 +22,17 @@ int smp_call_function_single(int cpu, void (*func) (void *info), void *info,
 }
 EXPORT_SYMBOL(smp_call_function_single);
 
+int on_each_cpu(smp_call_func_t func, void *info, int wait)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+	func(info);
+	local_irq_restore(flags);
+	return 0;
+}
+EXPORT_SYMBOL(on_each_cpu);
+
 /*
  * Note we still need to test the mask even for UP
  * because we actually can get an empty mask from

commit 081192b25c2d4620b5f5838620624d3daee94b66
Author: David Daney <david.daney@cavium.com>
Date:   Wed Sep 11 14:23:25 2013 -0700

    up.c: use local_irq_{save,restore}() in smp_call_function_single.
    
    The SMP version of this function doesn't unconditionally enable irqs, so
    neither should this !SMP version.  There are no know problems caused by
    this, but we make the change for consistency's sake.
    
    Signed-off-by: David Daney <david.daney@cavium.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/up.c b/kernel/up.c
index 144e57255234..b1cf036255f3 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -10,11 +10,13 @@
 int smp_call_function_single(int cpu, void (*func) (void *info), void *info,
 				int wait)
 {
+	unsigned long flags;
+
 	WARN_ON(cpu != 0);
 
-	local_irq_disable();
-	(func)(info);
-	local_irq_enable();
+	local_irq_save(flags);
+	func(info);
+	local_irq_restore(flags);
 
 	return 0;
 }

commit fa688207c9db48b64ab6538abc3fcdf26110b9ec
Author: David Daney <david.daney@cavium.com>
Date:   Wed Sep 11 14:23:24 2013 -0700

    smp: quit unconditionally enabling irq in on_each_cpu_mask and on_each_cpu_cond
    
    As in commit f21afc25f9ed ("smp.h: Use local_irq_{save,restore}() in
    !SMP version of on_each_cpu()"), we don't want to enable irqs if they
    are not already enabled.  There are currently no known problematical
    callers of these functions, but since it is a known failure pattern, we
    preemptively fix them.
    
    Since they are not trivial functions, make them non-inline by moving
    them to up.c.  This also makes it so we don't have to fix #include
    dependancies for preempt_{disable,enable}.
    
    Signed-off-by: David Daney <david.daney@cavium.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/up.c b/kernel/up.c
index c54c75e9faf7..144e57255234 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -19,3 +19,42 @@ int smp_call_function_single(int cpu, void (*func) (void *info), void *info,
 	return 0;
 }
 EXPORT_SYMBOL(smp_call_function_single);
+
+/*
+ * Note we still need to test the mask even for UP
+ * because we actually can get an empty mask from
+ * code that on SMP might call us without the local
+ * CPU in the mask.
+ */
+void on_each_cpu_mask(const struct cpumask *mask,
+		      smp_call_func_t func, void *info, bool wait)
+{
+	unsigned long flags;
+
+	if (cpumask_test_cpu(0, mask)) {
+		local_irq_save(flags);
+		func(info);
+		local_irq_restore(flags);
+	}
+}
+EXPORT_SYMBOL(on_each_cpu_mask);
+
+/*
+ * Preemption is disabled here to make sure the cond_func is called under the
+ * same condtions in UP and SMP.
+ */
+void on_each_cpu_cond(bool (*cond_func)(int cpu, void *info),
+		      smp_call_func_t func, void *info, bool wait,
+		      gfp_t gfp_flags)
+{
+	unsigned long flags;
+
+	preempt_disable();
+	if (cond_func(0, info)) {
+		local_irq_save(flags);
+		func(info);
+		local_irq_restore(flags);
+	}
+	preempt_enable();
+}
+EXPORT_SYMBOL(on_each_cpu_cond);

commit 9984de1a5a8a96275fcab818f7419af5a3c86e71
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Mon May 23 14:51:41 2011 -0400

    kernel: Map most files to use export.h instead of module.h
    
    The changed files were only including linux/module.h for the
    EXPORT_SYMBOL infrastructure, and nothing else.  Revector them
    onto the isolated export header for faster compile times.
    
    Nothing to see here but a whole lot of instances of:
    
      -#include <linux/module.h>
      +#include <linux/export.h>
    
    This commit is only changing the kernel dir; next targets
    will probably be mm, fs, the arch dirs, etc.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/kernel/up.c b/kernel/up.c
index 1ff27a28bb7d..c54c75e9faf7 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -4,7 +4,7 @@
 
 #include <linux/interrupt.h>
 #include <linux/kernel.h>
-#include <linux/module.h>
+#include <linux/export.h>
 #include <linux/smp.h>
 
 int smp_call_function_single(int cpu, void (*func) (void *info), void *info,

commit 6e96281412f2f757abe623e08a9577e2bbd3402f
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Jan 12 16:04:37 2009 +0100

    smp_call_function_single(): be slightly less stupid, fix #2
    
    fix m68k build failure:
    
     tip/kernel/up.c: In function 'smp_call_function_single':
     tip/kernel/up.c:16: error: dereferencing pointer to incomplete type
     make[2]: *** [kernel/up.o] Error 1
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/up.c b/kernel/up.c
index c04b9dcfcebe..1ff27a28bb7d 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -2,6 +2,7 @@
  * Uniprocessor-only support functions.  The counterpart to kernel/smp.c
  */
 
+#include <linux/interrupt.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/smp.h>

commit 93423b8665f43a0c7a006a1d5be048b99db56d32
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Jan 11 05:15:21 2009 +0100

    smp_call_function_single(): be slightly less stupid, fix
    
    Impact: build fix on Alpha
    
     kernel/up.c: In function 'smp_call_function_single':
     kernel/up.c:12: error: 'cpuid' undeclared (first use in this function)
     kernel/up.c:12: error: (Each undeclared identifier is reported only once
     kernel/up.c:12: error: for each function it appears in.)
    
    The typo didnt show up on x86 because 'cpuid' happens to be a
    function address as well ...
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/up.c b/kernel/up.c
index ce62cc9e9f71..c04b9dcfcebe 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -9,10 +9,12 @@
 int smp_call_function_single(int cpu, void (*func) (void *info), void *info,
 				int wait)
 {
-	WARN_ON(cpuid != 0);
+	WARN_ON(cpu != 0);
+
 	local_irq_disable();
 	(func)(info);
 	local_irq_enable();
+
 	return 0;
 }
 EXPORT_SYMBOL(smp_call_function_single);

commit 53ce3d9564908794ae7dd32969089b57df5fc098
Author: Andrew Morton <akpm@linux-foundation.org>
Date:   Fri Jan 9 12:27:08 2009 -0800

    smp_call_function_single(): be slightly less stupid
    
    If you do
    
            smp_call_function_single(expression-with-side-effects, ...)
    
    then expression-with-side-effects never gets evaluated on UP builds.
    
    As always, implementing it in C is the correct thing to do.
    
    While we're there, uninline it for size and possible header dependency
    reasons.
    
    And create a new kernel/up.c, as a place in which to put
    uniprocessor-specific code and storage.  It should mirror kernel/smp.c.
    
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/up.c b/kernel/up.c
new file mode 100644
index 000000000000..ce62cc9e9f71
--- /dev/null
+++ b/kernel/up.c
@@ -0,0 +1,18 @@
+/*
+ * Uniprocessor-only support functions.  The counterpart to kernel/smp.c
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/smp.h>
+
+int smp_call_function_single(int cpu, void (*func) (void *info), void *info,
+				int wait)
+{
+	WARN_ON(cpuid != 0);
+	local_irq_disable();
+	(func)(info);
+	local_irq_enable();
+	return 0;
+}
+EXPORT_SYMBOL(smp_call_function_single);
