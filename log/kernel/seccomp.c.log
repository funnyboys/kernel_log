commit 32927393dc1ccd60fb2bdc05b9e8e88753761469
Author: Christoph Hellwig <hch@lst.de>
Date:   Fri Apr 24 08:43:38 2020 +0200

    sysctl: pass kernel pointers to ->proc_handler
    
    Instead of having all the sysctl handlers deal with user pointers, which
    is rather hairy in terms of the BPF interaction, copy the input to and
    from  userspace in common code.  This also means that the strings are
    always NUL-terminated by the common code, making the API a little bit
    safer.
    
    As most handler just pass through the data to one of the common handlers
    a lot of the changes are mechnical.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Andrey Ignatov <rdna@fb.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 55a6184f5990..d653d8426de9 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -1776,7 +1776,7 @@ static void audit_actions_logged(u32 actions_logged, u32 old_actions_logged,
 }
 
 static int seccomp_actions_logged_handler(struct ctl_table *ro_table, int write,
-					  void __user *buffer, size_t *lenp,
+					  void *buffer, size_t *lenp,
 					  loff_t *ppos)
 {
 	int ret;

commit 29d9f30d4ce6c7a38745a54a8cddface10013490
Merge: 56a451b78067 7f80ccfe9968
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Mar 31 17:29:33 2020 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net-next
    
    Pull networking updates from David Miller:
     "Highlights:
    
       1) Fix the iwlwifi regression, from Johannes Berg.
    
       2) Support BSS coloring and 802.11 encapsulation offloading in
          hardware, from John Crispin.
    
       3) Fix some potential Spectre issues in qtnfmac, from Sergey
          Matyukevich.
    
       4) Add TTL decrement action to openvswitch, from Matteo Croce.
    
       5) Allow paralleization through flow_action setup by not taking the
          RTNL mutex, from Vlad Buslov.
    
       6) A lot of zero-length array to flexible-array conversions, from
          Gustavo A. R. Silva.
    
       7) Align XDP statistics names across several drivers for consistency,
          from Lorenzo Bianconi.
    
       8) Add various pieces of infrastructure for offloading conntrack, and
          make use of it in mlx5 driver, from Paul Blakey.
    
       9) Allow using listening sockets in BPF sockmap, from Jakub Sitnicki.
    
      10) Lots of parallelization improvements during configuration changes
          in mlxsw driver, from Ido Schimmel.
    
      11) Add support to devlink for generic packet traps, which report
          packets dropped during ACL processing. And use them in mlxsw
          driver. From Jiri Pirko.
    
      12) Support bcmgenet on ACPI, from Jeremy Linton.
    
      13) Make BPF compatible with RT, from Thomas Gleixnet, Alexei
          Starovoitov, and your's truly.
    
      14) Support XDP meta-data in virtio_net, from Yuya Kusakabe.
    
      15) Fix sysfs permissions when network devices change namespaces, from
          Christian Brauner.
    
      16) Add a flags element to ethtool_ops so that drivers can more simply
          indicate which coalescing parameters they actually support, and
          therefore the generic layer can validate the user's ethtool
          request. Use this in all drivers, from Jakub Kicinski.
    
      17) Offload FIFO qdisc in mlxsw, from Petr Machata.
    
      18) Support UDP sockets in sockmap, from Lorenz Bauer.
    
      19) Fix stretch ACK bugs in several TCP congestion control modules,
          from Pengcheng Yang.
    
      20) Support virtual functiosn in octeontx2 driver, from Tomasz
          Duszynski.
    
      21) Add region operations for devlink and use it in ice driver to dump
          NVM contents, from Jacob Keller.
    
      22) Add support for hw offload of MACSEC, from Antoine Tenart.
    
      23) Add support for BPF programs that can be attached to LSM hooks,
          from KP Singh.
    
      24) Support for multiple paths, path managers, and counters in MPTCP.
          From Peter Krystad, Paolo Abeni, Florian Westphal, Davide Caratti,
          and others.
    
      25) More progress on adding the netlink interface to ethtool, from
          Michal Kubecek"
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net-next: (2121 commits)
      net: ipv6: rpl_iptunnel: Fix potential memory leak in rpl_do_srh_inline
      cxgb4/chcr: nic-tls stats in ethtool
      net: dsa: fix oops while probing Marvell DSA switches
      net/bpfilter: remove superfluous testing message
      net: macb: Fix handling of fixed-link node
      net: dsa: ksz: Select KSZ protocol tag
      netdevsim: dev: Fix memory leak in nsim_dev_take_snapshot_write
      net: stmmac: add EHL 2.5Gbps PCI info and PCI ID
      net: stmmac: add EHL PSE0 & PSE1 1Gbps PCI info and PCI ID
      net: stmmac: create dwmac-intel.c to contain all Intel platform
      net: dsa: bcm_sf2: Support specifying VLAN tag egress rule
      net: dsa: bcm_sf2: Add support for matching VLAN TCI
      net: dsa: bcm_sf2: Move writing of CFP_DATA(5) into slicing functions
      net: dsa: bcm_sf2: Check earlier for FLOW_EXT and FLOW_MAC_EXT
      net: dsa: bcm_sf2: Disable learning for ASP port
      net: dsa: b53: Deny enslaving port 7 for 7278 into a bridge
      net: dsa: b53: Prevent tagged VLAN on port 7 for 7278
      net: dsa: b53: Restore VLAN entries upon (re)configuration
      net: dsa: bcm_sf2: Fix overflow checks
      hv_netvsc: Remove unnecessary round_up for recv_completion_cnt
      ...

commit 3db81afd99494a33f1c3839103f0429c8f30cb9d
Author: Sven Schnelle <svens@linux.ibm.com>
Date:   Tue Mar 10 13:33:32 2020 +0100

    seccomp: Add missing compat_ioctl for notify
    
    Executing the seccomp_bpf testsuite under a 64-bit kernel with 32-bit
    userland (both s390 and x86) doesn't work because there's no compat_ioctl
    handler defined. Add the handler.
    
    Signed-off-by: Sven Schnelle <svens@linux.ibm.com>
    Fixes: 6a21cc50f0c7 ("seccomp: add a return code to trap to userspace")
    Cc: stable@vger.kernel.org
    Link: https://lore.kernel.org/r/20200310123332.42255-1-svens@linux.ibm.com
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 29022c1bbe18..ec5c606bc3a1 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -1225,6 +1225,7 @@ static const struct file_operations seccomp_notify_ops = {
 	.poll = seccomp_notify_poll,
 	.release = seccomp_notify_release,
 	.unlocked_ioctl = seccomp_notify_ioctl,
+	.compat_ioctl = seccomp_notify_ioctl,
 };
 
 static struct file *init_listener(struct seccomp_filter *filter)

commit 51891498f2da78ee64dfad88fa53c9e85fb50abf
Author: Tycho Andersen <tycho@tycho.ws>
Date:   Wed Mar 4 11:05:17 2020 -0700

    seccomp: allow TSYNC and USER_NOTIF together
    
    The restriction introduced in 7a0df7fbc145 ("seccomp: Make NEW_LISTENER and
    TSYNC flags exclusive") is mostly artificial: there is enough information
    in a seccomp user notification to tell which thread triggered a
    notification. The reason it was introduced is because TSYNC makes the
    syscall return a thread-id on failure, and NEW_LISTENER returns an fd, and
    there's no way to distinguish between these two cases (well, I suppose the
    caller could check all fds it has, then do the syscall, and if the return
    value was an fd that already existed, then it must be a thread id, but
    bleh).
    
    Matthew would like to use these two flags together in the Chrome sandbox
    which wants to use TSYNC for video drivers and NEW_LISTENER to proxy
    syscalls.
    
    So, let's fix this ugliness by adding another flag, TSYNC_ESRCH, which
    tells the kernel to just return -ESRCH on a TSYNC error. This way,
    NEW_LISTENER (and any subsequent seccomp() commands that want to return
    positive values) don't conflict with each other.
    
    Suggested-by: Matthew Denton <mpdenton@google.com>
    Signed-off-by: Tycho Andersen <tycho@tycho.ws>
    Link: https://lore.kernel.org/r/20200304180517.23867-1-tycho@tycho.ws
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index b6ea3dcb57bf..29022c1bbe18 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -528,8 +528,12 @@ static long seccomp_attach_filter(unsigned int flags,
 		int ret;
 
 		ret = seccomp_can_sync_threads();
-		if (ret)
-			return ret;
+		if (ret) {
+			if (flags & SECCOMP_FILTER_FLAG_TSYNC_ESRCH)
+				return -ESRCH;
+			else
+				return ret;
+		}
 	}
 
 	/* Set log flag, if present. */
@@ -1288,10 +1292,12 @@ static long seccomp_set_mode_filter(unsigned int flags,
 	 * In the successful case, NEW_LISTENER returns the new listener fd.
 	 * But in the failure case, TSYNC returns the thread that died. If you
 	 * combine these two flags, there's no way to tell whether something
-	 * succeeded or failed. So, let's disallow this combination.
+	 * succeeded or failed. So, let's disallow this combination if the user
+	 * has not explicitly requested no errors from TSYNC.
 	 */
 	if ((flags & SECCOMP_FILTER_FLAG_TSYNC) &&
-	    (flags & SECCOMP_FILTER_FLAG_NEW_LISTENER))
+	    (flags & SECCOMP_FILTER_FLAG_NEW_LISTENER) &&
+	    ((flags & SECCOMP_FILTER_FLAG_TSYNC_ESRCH) == 0))
 		return -EINVAL;
 
 	/* Prepare the new filter before holding any locks. */

commit 3d9f773cf2876c01a505b9fe27270901d464e90a
Author: David Miller <davem@davemloft.net>
Date:   Mon Feb 24 15:01:43 2020 +0100

    bpf: Use bpf_prog_run_pin_on_cpu() at simple call sites.
    
    All of these cases are strictly of the form:
    
            preempt_disable();
            BPF_PROG_RUN(...);
            preempt_enable();
    
    Replace this with bpf_prog_run_pin_on_cpu() which wraps BPF_PROG_RUN()
    with:
    
            migrate_disable();
            BPF_PROG_RUN(...);
            migrate_enable();
    
    On non RT enabled kernels this maps to preempt_disable/enable() and on RT
    enabled kernels this solely prevents migration, which is sufficient as
    there is no requirement to prevent reentrancy to any BPF program from a
    preempting task. The only requirement is that the program stays on the same
    CPU.
    
    Therefore, this is a trivially correct transformation.
    
    The seccomp loop does not need protection over the loop. It only needs
    protection per BPF filter program
    
    [ tglx: Converted to bpf_prog_run_pin_on_cpu() ]
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/bpf/20200224145643.691493094@linutronix.de

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index b6ea3dcb57bf..787041eb011b 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -268,16 +268,14 @@ static u32 seccomp_run_filters(const struct seccomp_data *sd,
 	 * All filters in the list are evaluated and the lowest BPF return
 	 * value always takes priority (ignoring the DATA).
 	 */
-	preempt_disable();
 	for (; f; f = f->prev) {
-		u32 cur_ret = BPF_PROG_RUN(f->prog, sd);
+		u32 cur_ret = bpf_prog_run_pin_on_cpu(f->prog, sd);
 
 		if (ACTION_ONLY(cur_ret) < ACTION_ONLY(ret)) {
 			ret = cur_ret;
 			*match = f;
 		}
 	}
-	preempt_enable();
 	return ret;
 }
 #endif /* CONFIG_SECCOMP_FILTER */

commit 2882d53c9c6f3b8311d225062522f03772cf0179
Author: Sargun Dhillon <sargun@sargun.me>
Date:   Sat Dec 28 22:24:50 2019 -0800

    seccomp: Check that seccomp_notif is zeroed out by the user
    
    This patch is a small change in enforcement of the uapi for
    SECCOMP_IOCTL_NOTIF_RECV ioctl. Specifically, the datastructure which
    is passed (seccomp_notif) must be zeroed out. Previously any of its
    members could be set to nonsense values, and we would ignore it.
    
    This ensures all fields are set to their zero value.
    
    Signed-off-by: Sargun Dhillon <sargun@sargun.me>
    Reviewed-by: Christian Brauner <christian.brauner@ubuntu.com>
    Reviewed-by: Aleksa Sarai <cyphar@cyphar.com>
    Acked-by: Tycho Andersen <tycho@tycho.ws>
    Link: https://lore.kernel.org/r/20191229062451.9467-2-sargun@sargun.me
    Fixes: 6a21cc50f0c7 ("seccomp: add a return code to trap to userspace")
    Cc: stable@vger.kernel.org
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 12d2227e5786..b6ea3dcb57bf 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -1026,6 +1026,13 @@ static long seccomp_notify_recv(struct seccomp_filter *filter,
 	struct seccomp_notif unotif;
 	ssize_t ret;
 
+	/* Verify that we're not given garbage to keep struct extensible. */
+	ret = check_zeroed_user(buf, sizeof(unotif));
+	if (ret < 0)
+		return ret;
+	if (!ret)
+		return -EINVAL;
+
 	memset(&unotif, 0, sizeof(unotif));
 
 	ret = down_interruptible(&filter->notif->request);

commit fb3c5386b382d4097476ce9647260fc89b34afdb
Author: Christian Brauner <christian.brauner@ubuntu.com>
Date:   Fri Sep 20 10:30:05 2019 +0200

    seccomp: add SECCOMP_USER_NOTIF_FLAG_CONTINUE
    
    This allows the seccomp notifier to continue a syscall. A positive
    discussion about this feature was triggered by a post to the
    ksummit-discuss mailing list (cf. [3]) and took place during KSummit
    (cf. [1]) and again at the containers/checkpoint-restore
    micro-conference at Linux Plumbers.
    
    Recently we landed seccomp support for SECCOMP_RET_USER_NOTIF (cf. [4])
    which enables a process (watchee) to retrieve an fd for its seccomp
    filter. This fd can then be handed to another (usually more privileged)
    process (watcher). The watcher will then be able to receive seccomp
    messages about the syscalls having been performed by the watchee.
    
    This feature is heavily used in some userspace workloads. For example,
    it is currently used to intercept mknod() syscalls in user namespaces
    aka in containers.
    The mknod() syscall can be easily filtered based on dev_t. This allows
    us to only intercept a very specific subset of mknod() syscalls.
    Furthermore, mknod() is not possible in user namespaces toto coelo and
    so intercepting and denying syscalls that are not in the whitelist on
    accident is not a big deal. The watchee won't notice a difference.
    
    In contrast to mknod(), a lot of other syscall we intercept (e.g.
    setxattr()) cannot be easily filtered like mknod() because they have
    pointer arguments. Additionally, some of them might actually succeed in
    user namespaces (e.g. setxattr() for all "user.*" xattrs). Since we
    currently cannot tell seccomp to continue from a user notifier we are
    stuck with performing all of the syscalls in lieu of the container. This
    is a huge security liability since it is extremely difficult to
    correctly assume all of the necessary privileges of the calling task
    such that the syscall can be successfully emulated without escaping
    other additional security restrictions (think missing CAP_MKNOD for
    mknod(), or MS_NODEV on a filesystem etc.). This can be solved by
    telling seccomp to resume the syscall.
    
    One thing that came up in the discussion was the problem that another
    thread could change the memory after userspace has decided to let the
    syscall continue which is a well known TOCTOU with seccomp which is
    present in other ways already.
    The discussion showed that this feature is already very useful for any
    syscall without pointer arguments. For any accidentally intercepted
    non-pointer syscall it is safe to continue.
    For syscalls with pointer arguments there is a race but for any cautious
    userspace and the main usec cases the race doesn't matter. The notifier
    is intended to be used in a scenario where a more privileged watcher
    supervises the syscalls of lesser privileged watchee to allow it to get
    around kernel-enforced limitations by performing the syscall for it
    whenever deemed save by the watcher. Hence, if a user tricks the watcher
    into allowing a syscall they will either get a deny based on
    kernel-enforced restrictions later or they will have changed the
    arguments in such a way that they manage to perform a syscall with
    arguments that they would've been allowed to do anyway.
    In general, it is good to point out again, that the notifier fd was not
    intended to allow userspace to implement a security policy but rather to
    work around kernel security mechanisms in cases where the watcher knows
    that a given action is safe to perform.
    
    /* References */
    [1]: https://linuxplumbersconf.org/event/4/contributions/560
    [2]: https://linuxplumbersconf.org/event/4/contributions/477
    [3]: https://lore.kernel.org/r/20190719093538.dhyopljyr5ns33qx@brauner.io
    [4]: commit 6a21cc50f0c7 ("seccomp: add a return code to trap to userspace")
    
    Co-developed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Christian Brauner <christian.brauner@ubuntu.com>
    Reviewed-by: Tycho Andersen <tycho@tycho.ws>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Will Drewry <wad@chromium.org>
    CC: Tyler Hicks <tyhicks@canonical.com>
    Link: https://lore.kernel.org/r/20190920083007.11475-2-christian.brauner@ubuntu.com
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index dba52a7db5e8..12d2227e5786 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -75,6 +75,7 @@ struct seccomp_knotif {
 	/* The return values, only valid when in SECCOMP_NOTIFY_REPLIED */
 	int error;
 	long val;
+	u32 flags;
 
 	/* Signals when this has entered SECCOMP_NOTIFY_REPLIED */
 	struct completion ready;
@@ -732,11 +733,12 @@ static u64 seccomp_next_notify_id(struct seccomp_filter *filter)
 	return filter->notif->next_id++;
 }
 
-static void seccomp_do_user_notification(int this_syscall,
-					 struct seccomp_filter *match,
-					 const struct seccomp_data *sd)
+static int seccomp_do_user_notification(int this_syscall,
+					struct seccomp_filter *match,
+					const struct seccomp_data *sd)
 {
 	int err;
+	u32 flags = 0;
 	long ret = 0;
 	struct seccomp_knotif n = {};
 
@@ -764,6 +766,7 @@ static void seccomp_do_user_notification(int this_syscall,
 	if (err == 0) {
 		ret = n.val;
 		err = n.error;
+		flags = n.flags;
 	}
 
 	/*
@@ -780,8 +783,14 @@ static void seccomp_do_user_notification(int this_syscall,
 		list_del(&n.list);
 out:
 	mutex_unlock(&match->notify_lock);
+
+	/* Userspace requests to continue the syscall. */
+	if (flags & SECCOMP_USER_NOTIF_FLAG_CONTINUE)
+		return 0;
+
 	syscall_set_return_value(current, task_pt_regs(current),
 				 err, ret);
+	return -1;
 }
 
 static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
@@ -867,8 +876,10 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 		return 0;
 
 	case SECCOMP_RET_USER_NOTIF:
-		seccomp_do_user_notification(this_syscall, match, sd);
-		goto skip;
+		if (seccomp_do_user_notification(this_syscall, match, sd))
+			goto skip;
+
+		return 0;
 
 	case SECCOMP_RET_LOG:
 		seccomp_log(this_syscall, 0, action, true);
@@ -1087,7 +1098,11 @@ static long seccomp_notify_send(struct seccomp_filter *filter,
 	if (copy_from_user(&resp, buf, sizeof(resp)))
 		return -EFAULT;
 
-	if (resp.flags)
+	if (resp.flags & ~SECCOMP_USER_NOTIF_FLAG_CONTINUE)
+		return -EINVAL;
+
+	if ((resp.flags & SECCOMP_USER_NOTIF_FLAG_CONTINUE) &&
+	    (resp.error || resp.val))
 		return -EINVAL;
 
 	ret = mutex_lock_interruptible(&filter->notify_lock);
@@ -1116,6 +1131,7 @@ static long seccomp_notify_send(struct seccomp_filter *filter,
 	knotif->state = SECCOMP_NOTIFY_REPLIED;
 	knotif->error = resp.error;
 	knotif->val = resp.val;
+	knotif->flags = resp.flags;
 	complete(&knotif->ready);
 out:
 	mutex_unlock(&filter->notify_lock);

commit a89e9b8abf82725e4ac96100e07c8104dbe8a240
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed May 15 10:11:09 2019 -0500

    signal: Remove the signal number and task parameters from force_sig_info
    
    force_sig_info always delivers to the current task and the signal
    parameter always matches info.si_signo.  So remove those parameters to
    make it a simpler less error prone interface, and to make it clear
    that none of the callers are doing anything clever.
    
    This guarantees that force_sig_info will not grow any new buggy
    callers that attempt to call force_sig on a non-current task, or that
    pass an signal number that does not match info.si_signo.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 811b4a86cdf6..dba52a7db5e8 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -609,7 +609,7 @@ static void seccomp_send_sigsys(int syscall, int reason)
 {
 	struct kernel_siginfo info;
 	seccomp_init_siginfo(&info, syscall, reason);
-	force_sig_info(SIGSYS, &info, current);
+	force_sig_info(&info);
 }
 #endif	/* CONFIG_SECCOMP_FILTER */
 

commit 02aff8db6438ce29371fd9cd54c57213f4bb4536
Merge: f72dae20891d 70c4cf17e445
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue May 7 19:06:04 2019 -0700

    Merge tag 'audit-pr-20190507' of git://git.kernel.org/pub/scm/linux/kernel/git/pcmoore/audit
    
    Pull audit updates from Paul Moore:
     "We've got a reasonably broad set of audit patches for the v5.2 merge
      window, the highlights are below:
    
       - The biggest change, and the source of all the arch/* changes, is
         the patchset from Dmitry to help enable some of the work he is
         doing around PTRACE_GET_SYSCALL_INFO.
    
         To be honest, including this in the audit tree is a bit of a
         stretch, but it does help move audit a little further along towards
         proper syscall auditing for all arches, and everyone else seemed to
         agree that audit was a "good" spot for this to land (or maybe they
         just didn't want to merge it? dunno.).
    
       - We can now audit time/NTP adjustments.
    
       - We continue the work to connect associated audit records into a
         single event"
    
    * tag 'audit-pr-20190507' of git://git.kernel.org/pub/scm/linux/kernel/git/pcmoore/audit: (21 commits)
      audit: fix a memory leak bug
      ntp: Audit NTP parameters adjustment
      timekeeping: Audit clock adjustments
      audit: purge unnecessary list_empty calls
      audit: link integrity evm_write_xattrs record to syscall event
      syscall_get_arch: add "struct task_struct *" argument
      unicore32: define syscall_get_arch()
      Move EM_UNICORE to uapi/linux/elf-em.h
      nios2: define syscall_get_arch()
      nds32: define syscall_get_arch()
      Move EM_NDS32 to uapi/linux/elf-em.h
      m68k: define syscall_get_arch()
      hexagon: define syscall_get_arch()
      Move EM_HEXAGON to uapi/linux/elf-em.h
      h8300: define syscall_get_arch()
      c6x: define syscall_get_arch()
      arc: define syscall_get_arch()
      Move EM_ARCOMPACT and EM_ARCV2 to uapi/linux/elf-em.h
      audit: Make audit_log_cap and audit_copy_inode static
      audit: connect LOGIN record to its syscall record
      ...

commit 78ee8b1b9b2fa1b51c51c42f3cffa0e12ad5f0ab
Merge: 9bff9dfc513b 6beff00b79ca
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue May 7 08:39:54 2019 -0700

    Merge branch 'next-general' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security
    
    Pull security subsystem updates from James Morris:
     "Just a few bugfixes and documentation updates"
    
    * 'next-general' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security:
      seccomp: fix up grammar in comment
      Revert "security: inode: fix a missing check for securityfs_create_file"
      Yama: mark function as static
      security: inode: fix a missing check for securityfs_create_file
      keys: safe concurrent user->{session,uid}_keyring access
      security: don't use RCU accessors for cred->session_keyring
      Yama: mark local symbols as static
      LSM: lsm_hooks.h: fix documentation format
      LSM: fix documentation for the shm_* hooks
      LSM: fix documentation for the sem_* hooks
      LSM: fix documentation for the msg_queue_* hooks
      LSM: fix documentation for the audit_* hooks
      LSM: fix documentation for the path_chmod hook
      LSM: fix documentation for the socket_getpeersec_dgram hook
      LSM: fix documentation for the task_setscheduler hook
      LSM: fix documentation for the socket_post_create hook
      LSM: fix documentation for the syslog hook
      LSM: fix documentation for sb_copy_data hook

commit 83a50840e72a5a964b4704fcdc2fbb2d771015ab
Merge: 80871482fd5c 7a0df7fbc145
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Apr 29 13:24:34 2019 -0700

    Merge tag 'seccomp-v5.1-rc8' of git://git.kernel.org/pub/scm/linux/kernel/git/kees/linux
    
    Pull seccomp fixes from Kees Cook:
     "Syzbot found a use-after-free bug in seccomp due to flags that should
      not be allowed to be used together.
    
      Tycho fixed this, I updated the self-tests, and the syzkaller PoC has
      been running for several days without triggering KASan (before this
      fix, it would reproduce). These patches have also been in -next for
      almost a week, just to be sure.
    
       - Add logic for making some seccomp flags exclusive (Tycho)
    
       - Update selftests for exclusivity testing (Kees)"
    
    * tag 'seccomp-v5.1-rc8' of git://git.kernel.org/pub/scm/linux/kernel/git/kees/linux:
      seccomp: Make NEW_LISTENER and TSYNC flags exclusive
      selftests/seccomp: Prepare for exclusive seccomp flags

commit 7a0df7fbc14505e2e2be19ed08654a09e1ed5bf6
Author: Tycho Andersen <tycho@tycho.ws>
Date:   Wed Mar 6 13:14:13 2019 -0700

    seccomp: Make NEW_LISTENER and TSYNC flags exclusive
    
    As the comment notes, the return codes for TSYNC and NEW_LISTENER
    conflict, because they both return positive values, one in the case of
    success and one in the case of error. So, let's disallow both of these
    flags together.
    
    While this is technically a userspace break, all the users I know
    of are still waiting on me to land this feature in libseccomp, so I
    think it'll be safe. Also, at present my use case doesn't require
    TSYNC at all, so this isn't a big deal to disallow. If someone
    wanted to support this, a path forward would be to add a new flag like
    TSYNC_AND_LISTENER_YES_I_UNDERSTAND_THAT_TSYNC_WILL_JUST_RETURN_EAGAIN,
    but the use cases are so different I don't see it really happening.
    
    Finally, it's worth noting that this does actually fix a UAF issue: at the
    end of seccomp_set_mode_filter(), we have:
    
            if (flags & SECCOMP_FILTER_FLAG_NEW_LISTENER) {
                    if (ret < 0) {
                            listener_f->private_data = NULL;
                            fput(listener_f);
                            put_unused_fd(listener);
                    } else {
                            fd_install(listener, listener_f);
                            ret = listener;
                    }
            }
    out_free:
            seccomp_filter_free(prepared);
    
    But if ret > 0 because TSYNC raced, we'll install the listener fd and then
    free the filter out from underneath it, causing a UAF when the task closes
    it or dies. This patch also switches the condition to be simply if (ret),
    so that if someone does add the flag mentioned above, they won't have to
    remember to fix this too.
    
    Reported-by: syzbot+b562969adb2e04af3442@syzkaller.appspotmail.com
    Fixes: 6a21cc50f0c7 ("seccomp: add a return code to trap to userspace")
    CC: stable@vger.kernel.org # v5.0+
    Signed-off-by: Tycho Andersen <tycho@tycho.ws>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Acked-by: James Morris <jamorris@linux.microsoft.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 54a0347ca812..4b51d9cbcf06 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -502,7 +502,10 @@ seccomp_prepare_user_filter(const char __user *user_filter)
  *
  * Caller must be holding current->sighand->siglock lock.
  *
- * Returns 0 on success, -ve on error.
+ * Returns 0 on success, -ve on error, or
+ *   - in TSYNC mode: the pid of a thread which was either not in the correct
+ *     seccomp mode or did not have an ancestral seccomp filter
+ *   - in NEW_LISTENER mode: the fd of the new listener
  */
 static long seccomp_attach_filter(unsigned int flags,
 				  struct seccomp_filter *filter)
@@ -1258,6 +1261,16 @@ static long seccomp_set_mode_filter(unsigned int flags,
 	if (flags & ~SECCOMP_FILTER_FLAG_MASK)
 		return -EINVAL;
 
+	/*
+	 * In the successful case, NEW_LISTENER returns the new listener fd.
+	 * But in the failure case, TSYNC returns the thread that died. If you
+	 * combine these two flags, there's no way to tell whether something
+	 * succeeded or failed. So, let's disallow this combination.
+	 */
+	if ((flags & SECCOMP_FILTER_FLAG_TSYNC) &&
+	    (flags & SECCOMP_FILTER_FLAG_NEW_LISTENER))
+		return -EINVAL;
+
 	/* Prepare the new filter before holding any locks. */
 	prepared = seccomp_prepare_user_filter(filter);
 	if (IS_ERR(prepared))
@@ -1304,7 +1317,7 @@ static long seccomp_set_mode_filter(unsigned int flags,
 		mutex_unlock(&current->signal->cred_guard_mutex);
 out_put_fd:
 	if (flags & SECCOMP_FILTER_FLAG_NEW_LISTENER) {
-		if (ret < 0) {
+		if (ret) {
 			listener_f->private_data = NULL;
 			fput(listener_f);
 			put_unused_fd(listener);

commit 6beff00b79ca0b5caf0ce6fb8e11f57311bd95f8
Author: Tycho Andersen <tycho@tycho.ws>
Date:   Wed Mar 6 13:14:12 2019 -0700

    seccomp: fix up grammar in comment
    
    This sentence is kind of a train wreck anyway, but at least dropping the
    extra pronoun helps somewhat.
    
    Signed-off-by: Tycho Andersen <tycho@tycho.ws>
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: James Morris <jamorris@linux.microsoft.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 54a0347ca812..503d02896c5d 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -331,7 +331,7 @@ static int is_ancestor(struct seccomp_filter *parent,
  * Expects sighand and cred_guard_mutex locks to be held.
  *
  * Returns 0 on success, -ve on error, or the pid of a thread which was
- * either not in the correct seccomp mode or it did not have an ancestral
+ * either not in the correct seccomp mode or did not have an ancestral
  * seccomp filter.
  */
 static inline pid_t seccomp_can_sync_threads(void)

commit b35f549df1d7520d37ba1e6d4a8d4df6bd52d136
Author: Steven Rostedt (Red Hat) <rostedt@goodmis.org>
Date:   Mon Nov 7 16:26:37 2016 -0500

    syscalls: Remove start and number from syscall_get_arguments() args
    
    At Linux Plumbers, Andy Lutomirski approached me and pointed out that the
    function call syscall_get_arguments() implemented in x86 was horribly
    written and not optimized for the standard case of passing in 0 and 6 for
    the starting index and the number of system calls to get. When looking at
    all the users of this function, I discovered that all instances pass in only
    0 and 6 for these arguments. Instead of having this function handle
    different cases that are never used, simply rewrite it to return the first 6
    arguments of a system call.
    
    This should help out the performance of tracing system calls by ptrace,
    ftrace and perf.
    
    Link: http://lkml.kernel.org/r/20161107213233.754809394@goodmis.org
    
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Dominik Brodowski <linux@dominikbrodowski.net>
    Cc: Dave Martin <dave.martin@arm.com>
    Cc: "Dmitry V. Levin" <ldv@altlinux.org>
    Cc: x86@kernel.org
    Cc: linux-snps-arc@lists.infradead.org
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-c6x-dev@linux-c6x.org
    Cc: uclinux-h8-devel@lists.sourceforge.jp
    Cc: linux-hexagon@vger.kernel.org
    Cc: linux-ia64@vger.kernel.org
    Cc: linux-mips@vger.kernel.org
    Cc: nios2-dev@lists.rocketboards.org
    Cc: openrisc@lists.librecores.org
    Cc: linux-parisc@vger.kernel.org
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: linux-riscv@lists.infradead.org
    Cc: linux-s390@vger.kernel.org
    Cc: linux-sh@vger.kernel.org
    Cc: sparclinux@vger.kernel.org
    Cc: linux-um@lists.infradead.org
    Cc: linux-xtensa@linux-xtensa.org
    Cc: linux-arch@vger.kernel.org
    Acked-by: Paul Burton <paul.burton@mips.com> # MIPS parts
    Acked-by: Max Filippov <jcmvbkbc@gmail.com> # For xtensa changes
    Acked-by: Will Deacon <will.deacon@arm.com> # For the arm64 bits
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de> # for x86
    Reviewed-by: Dmitry V. Levin <ldv@altlinux.org>
    Reported-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 54a0347ca812..df27e499956a 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -149,7 +149,7 @@ static void populate_seccomp_data(struct seccomp_data *sd)
 
 	sd->nr = syscall_get_nr(task, regs);
 	sd->arch = syscall_get_arch();
-	syscall_get_arguments(task, regs, 0, 6, args);
+	syscall_get_arguments(task, regs, args);
 	sd->args[0] = args[0];
 	sd->args[1] = args[1];
 	sd->args[2] = args[2];

commit 16add411645cff83360086e102daa67b25f1e39a
Author: Dmitry V. Levin <ldv@altlinux.org>
Date:   Mon Mar 18 02:30:18 2019 +0300

    syscall_get_arch: add "struct task_struct *" argument
    
    This argument is required to extend the generic ptrace API with
    PTRACE_GET_SYSCALL_INFO request: syscall_get_arch() is going
    to be called from ptrace_request() along with syscall_get_nr(),
    syscall_get_arguments(), syscall_get_error(), and
    syscall_get_return_value() functions with a tracee as their argument.
    
    The primary intent is that the triple (audit_arch, syscall_nr, arg1..arg6)
    should describe what system call is being called and what its arguments
    are.
    
    Reverts: 5e937a9ae913 ("syscall_get_arch: remove useless function arguments")
    Reverts: 1002d94d3076 ("syscall.h: fix doc text for syscall_get_arch()")
    Reviewed-by: Andy Lutomirski <luto@kernel.org> # for x86
    Reviewed-by: Palmer Dabbelt <palmer@sifive.com>
    Acked-by: Paul Moore <paul@paul-moore.com>
    Acked-by: Paul Burton <paul.burton@mips.com> # MIPS parts
    Acked-by: Michael Ellerman <mpe@ellerman.id.au> (powerpc)
    Acked-by: Kees Cook <keescook@chromium.org> # seccomp parts
    Acked-by: Mark Salter <msalter@redhat.com> # for the c6x bit
    Cc: Elvira Khabirova <lineprinter@altlinux.org>
    Cc: Eugene Syromyatnikov <esyr@redhat.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: x86@kernel.org
    Cc: linux-alpha@vger.kernel.org
    Cc: linux-snps-arc@lists.infradead.org
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-c6x-dev@linux-c6x.org
    Cc: uclinux-h8-devel@lists.sourceforge.jp
    Cc: linux-hexagon@vger.kernel.org
    Cc: linux-ia64@vger.kernel.org
    Cc: linux-m68k@lists.linux-m68k.org
    Cc: linux-mips@vger.kernel.org
    Cc: nios2-dev@lists.rocketboards.org
    Cc: openrisc@lists.librecores.org
    Cc: linux-parisc@vger.kernel.org
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: linux-riscv@lists.infradead.org
    Cc: linux-s390@vger.kernel.org
    Cc: linux-sh@vger.kernel.org
    Cc: sparclinux@vger.kernel.org
    Cc: linux-um@lists.infradead.org
    Cc: linux-xtensa@linux-xtensa.org
    Cc: linux-arch@vger.kernel.org
    Cc: linux-audit@redhat.com
    Signed-off-by: Dmitry V. Levin <ldv@altlinux.org>
    Signed-off-by: Paul Moore <paul@paul-moore.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 54a0347ca812..36f36ab00f48 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -148,7 +148,7 @@ static void populate_seccomp_data(struct seccomp_data *sd)
 	unsigned long args[6];
 
 	sd->nr = syscall_get_nr(task, regs);
-	sd->arch = syscall_get_arch();
+	sd->arch = syscall_get_arch(task);
 	syscall_get_arguments(task, regs, 0, 6, args);
 	sd->args[0] = args[0];
 	sd->args[1] = args[1];
@@ -591,7 +591,7 @@ static void seccomp_init_siginfo(kernel_siginfo_t *info, int syscall, int reason
 	info->si_code = SYS_SECCOMP;
 	info->si_call_addr = (void __user *)KSTK_EIP(current);
 	info->si_errno = reason;
-	info->si_arch = syscall_get_arch();
+	info->si_arch = syscall_get_arch(current);
 	info->si_syscall = syscall;
 }
 

commit ae5906ceee038ea29ff5162d1bcd18fb50af8b94
Merge: 1fc1cd8399ab 468e91cecb32
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 7 11:44:01 2019 -0800

    Merge branch 'next-general' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security
    
    Pull security subsystem updates from James Morris:
    
     - Extend LSM stacking to allow sharing of cred, file, ipc, inode, and
       task blobs. This paves the way for more full-featured LSMs to be
       merged, and is specifically aimed at LandLock and SARA LSMs. This
       work is from Casey and Kees.
    
     - There's a new LSM from Micah Morton: "SafeSetID gates the setid
       family of syscalls to restrict UID/GID transitions from a given
       UID/GID to only those approved by a system-wide whitelist." This
       feature is currently shipping in ChromeOS.
    
    * 'next-general' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security: (62 commits)
      keys: fix missing __user in KEYCTL_PKEY_QUERY
      LSM: Update list of SECURITYFS users in Kconfig
      LSM: Ignore "security=" when "lsm=" is specified
      LSM: Update function documentation for cap_capable
      security: mark expected switch fall-throughs and add a missing break
      tomoyo: Bump version.
      LSM: fix return value check in safesetid_init_securityfs()
      LSM: SafeSetID: add selftest
      LSM: SafeSetID: remove unused include
      LSM: SafeSetID: 'depend' on CONFIG_SECURITY
      LSM: Add 'name' field for SafeSetID in DEFINE_LSM
      LSM: add SafeSetID module that gates setid calls
      LSM: add SafeSetID module that gates setid calls
      tomoyo: Allow multiple use_group lines.
      tomoyo: Coding style fix.
      tomoyo: Swicth from cred->security to task_struct->security.
      security: keys: annotate implicit fall throughs
      security: keys: annotate implicit fall throughs
      security: keys: annotate implicit fall through
      capabilities:: annotate implicit fall through
      ...

commit e80d02dd763093f70c3000ef34253a6d426becf6
Author: Alexei Starovoitov <ast@kernel.org>
Date:   Thu Feb 21 10:40:14 2019 -0800

    seccomp, bpf: disable preemption before calling into bpf prog
    
    All BPF programs must be called with preemption disabled.
    
    Fixes: 568f196756ad ("bpf: check that BPF programs run with preemption disabled")
    Reported-by: syzbot+8bf19ee2aa580de7a2a7@syzkaller.appspotmail.com
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index e815781ed751..a43c601ac252 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -267,6 +267,7 @@ static u32 seccomp_run_filters(const struct seccomp_data *sd,
 	 * All filters in the list are evaluated and the lowest BPF return
 	 * value always takes priority (ignoring the DATA).
 	 */
+	preempt_disable();
 	for (; f; f = f->prev) {
 		u32 cur_ret = BPF_PROG_RUN(f->prog, sd);
 
@@ -275,6 +276,7 @@ static u32 seccomp_run_filters(const struct seccomp_data *sd,
 			*match = f;
 		}
 	}
+	preempt_enable();
 	return ret;
 }
 #endif /* CONFIG_SECCOMP_FILTER */

commit 9624d5c9c7ff6836bbf9f9b230fd1fcf3d56f91a
Merge: 3e8c73671244 49a57857aeea
Author: James Morris <james.morris@microsoft.com>
Date:   Tue Jan 22 14:33:10 2019 -0800

    Merge tag 'v5.0-rc3' into next-general
    
    Sync to Linux 5.0-rc3 to pull in the VFS changes which impacted a lot
    of the LSM code.

commit a811dc61559e0c8003f1086c2a4dc8e4d5ae4cb8
Author: Tycho Andersen <tycho@tycho.ws>
Date:   Sat Jan 12 11:24:20 2019 -0700

    seccomp: fix UAF in user-trap code
    
    On the failure path, we do an fput() of the listener fd if the filter fails
    to install (e.g. because of a TSYNC race that's lost, or if the thread is
    killed, etc.). fput() doesn't actually release the fd, it just ads it to a
    work queue. Then the thread proceeds to free the filter, even though the
    listener struct file has a reference to it.
    
    To fix this, on the failure path let's set the private data to null, so we
    know in ->release() to ignore the filter.
    
    Reported-by: syzbot+981c26489b2d1c6316ba@syzkaller.appspotmail.com
    Fixes: 6a21cc50f0c7 ("seccomp: add a return code to trap to userspace")
    Signed-off-by: Tycho Andersen <tycho@tycho.ws>
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: James Morris <james.morris@microsoft.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index d7f538847b84..e815781ed751 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -976,6 +976,9 @@ static int seccomp_notify_release(struct inode *inode, struct file *file)
 	struct seccomp_filter *filter = file->private_data;
 	struct seccomp_knotif *knotif;
 
+	if (!filter)
+		return 0;
+
 	mutex_lock(&filter->notify_lock);
 
 	/*
@@ -1300,6 +1303,7 @@ static long seccomp_set_mode_filter(unsigned int flags,
 out_put_fd:
 	if (flags & SECCOMP_FILTER_FLAG_NEW_LISTENER) {
 		if (ret < 0) {
+			listener_f->private_data = NULL;
 			fput(listener_f);
 			put_unused_fd(listener);
 		} else {

commit c1a85a00ea66cb6f0bd0f14e47c28c2b0999799f
Author: Micah Morton <mortonm@chromium.org>
Date:   Mon Jan 7 16:10:53 2019 -0800

    LSM: generalize flag passing to security_capable
    
    This patch provides a general mechanism for passing flags to the
    security_capable LSM hook. It replaces the specific 'audit' flag that is
    used to tell security_capable whether it should log an audit message for
    the given capability check. The reason for generalizing this flag
    passing is so we can add an additional flag that signifies whether
    security_capable is being called by a setid syscall (which is needed by
    the proposed SafeSetID LSM).
    
    Signed-off-by: Micah Morton <mortonm@chromium.org>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: James Morris <james.morris@microsoft.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index d7f538847b84..38a77800def6 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -443,8 +443,8 @@ static struct seccomp_filter *seccomp_prepare_filter(struct sock_fprog *fprog)
 	 * behavior of privileged children.
 	 */
 	if (!task_no_new_privs(current) &&
-	    security_capable_noaudit(current_cred(), current_user_ns(),
-				     CAP_SYS_ADMIN) != 0)
+	    security_capable(current_cred(), current_user_ns(),
+				     CAP_SYS_ADMIN, CAP_OPT_NOAUDIT) != 0)
 		return ERR_PTR(-EACCES);
 
 	/* Allocate a new seccomp_filter */

commit 319deec7db6c0aab276d2447f778e7cffed24c7c
Author: Tycho Andersen <tycho@tycho.ws>
Date:   Wed Dec 12 19:46:54 2018 -0700

    seccomp: fix poor type promotion
    
    sparse complains,
    
    kernel/seccomp.c:1172:13: warning: incorrect type in assignment (different base types)
    kernel/seccomp.c:1172:13:    expected restricted __poll_t [usertype] ret
    kernel/seccomp.c:1172:13:    got int
    kernel/seccomp.c:1173:13: warning: restricted __poll_t degrades to integer
    
    Instead of assigning this to ret, since we don't use this anywhere, let's
    just test it against 0 directly.
    
    Signed-off-by: Tycho Andersen <tycho@tycho.ws>
    Reported-by: 0day robot <lkp@intel.com>
    Fixes: 6a21cc50f0c7 ("seccomp: add a return code to trap to userspace")
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 15b6be97fc09..d7f538847b84 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -1169,8 +1169,7 @@ static __poll_t seccomp_notify_poll(struct file *file,
 
 	poll_wait(file, &filter->notif->wqh, poll_tab);
 
-	ret = mutex_lock_interruptible(&filter->notify_lock);
-	if (ret < 0)
+	if (mutex_lock_interruptible(&filter->notify_lock) < 0)
 		return EPOLLERR;
 
 	list_for_each_entry(cur, &filter->notif->notifications, list) {

commit 6a21cc50f0c7f87dae5259f6cfefe024412313f6
Author: Tycho Andersen <tycho@tycho.ws>
Date:   Sun Dec 9 11:24:13 2018 -0700

    seccomp: add a return code to trap to userspace
    
    This patch introduces a means for syscalls matched in seccomp to notify
    some other task that a particular filter has been triggered.
    
    The motivation for this is primarily for use with containers. For example,
    if a container does an init_module(), we obviously don't want to load this
    untrusted code, which may be compiled for the wrong version of the kernel
    anyway. Instead, we could parse the module image, figure out which module
    the container is trying to load and load it on the host.
    
    As another example, containers cannot mount() in general since various
    filesystems assume a trusted image. However, if an orchestrator knows that
    e.g. a particular block device has not been exposed to a container for
    writing, it want to allow the container to mount that block device (that
    is, handle the mount for it).
    
    This patch adds functionality that is already possible via at least two
    other means that I know about, both of which involve ptrace(): first, one
    could ptrace attach, and then iterate through syscalls via PTRACE_SYSCALL.
    Unfortunately this is slow, so a faster version would be to install a
    filter that does SECCOMP_RET_TRACE, which triggers a PTRACE_EVENT_SECCOMP.
    Since ptrace allows only one tracer, if the container runtime is that
    tracer, users inside the container (or outside) trying to debug it will not
    be able to use ptrace, which is annoying. It also means that older
    distributions based on Upstart cannot boot inside containers using ptrace,
    since upstart itself uses ptrace to monitor services while starting.
    
    The actual implementation of this is fairly small, although getting the
    synchronization right was/is slightly complex.
    
    Finally, it's worth noting that the classic seccomp TOCTOU of reading
    memory data from the task still applies here, but can be avoided with
    careful design of the userspace handler: if the userspace handler reads all
    of the task memory that is necessary before applying its security policy,
    the tracee's subsequent memory edits will not be read by the tracer.
    
    Signed-off-by: Tycho Andersen <tycho@tycho.ws>
    CC: Kees Cook <keescook@chromium.org>
    CC: Andy Lutomirski <luto@amacapital.net>
    CC: Oleg Nesterov <oleg@redhat.com>
    CC: Eric W. Biederman <ebiederm@xmission.com>
    CC: "Serge E. Hallyn" <serge@hallyn.com>
    Acked-by: Serge Hallyn <serge@hallyn.com>
    CC: Christian Brauner <christian@brauner.io>
    CC: Tyler Hicks <tyhicks@canonical.com>
    CC: Akihiro Suda <suda.akihiro@lab.ntt.co.jp>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 393e029f778a..15b6be97fc09 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -33,12 +33,74 @@
 #endif
 
 #ifdef CONFIG_SECCOMP_FILTER
+#include <linux/file.h>
 #include <linux/filter.h>
 #include <linux/pid.h>
 #include <linux/ptrace.h>
 #include <linux/security.h>
 #include <linux/tracehook.h>
 #include <linux/uaccess.h>
+#include <linux/anon_inodes.h>
+
+enum notify_state {
+	SECCOMP_NOTIFY_INIT,
+	SECCOMP_NOTIFY_SENT,
+	SECCOMP_NOTIFY_REPLIED,
+};
+
+struct seccomp_knotif {
+	/* The struct pid of the task whose filter triggered the notification */
+	struct task_struct *task;
+
+	/* The "cookie" for this request; this is unique for this filter. */
+	u64 id;
+
+	/*
+	 * The seccomp data. This pointer is valid the entire time this
+	 * notification is active, since it comes from __seccomp_filter which
+	 * eclipses the entire lifecycle here.
+	 */
+	const struct seccomp_data *data;
+
+	/*
+	 * Notification states. When SECCOMP_RET_USER_NOTIF is returned, a
+	 * struct seccomp_knotif is created and starts out in INIT. Once the
+	 * handler reads the notification off of an FD, it transitions to SENT.
+	 * If a signal is received the state transitions back to INIT and
+	 * another message is sent. When the userspace handler replies, state
+	 * transitions to REPLIED.
+	 */
+	enum notify_state state;
+
+	/* The return values, only valid when in SECCOMP_NOTIFY_REPLIED */
+	int error;
+	long val;
+
+	/* Signals when this has entered SECCOMP_NOTIFY_REPLIED */
+	struct completion ready;
+
+	struct list_head list;
+};
+
+/**
+ * struct notification - container for seccomp userspace notifications. Since
+ * most seccomp filters will not have notification listeners attached and this
+ * structure is fairly large, we store the notification-specific stuff in a
+ * separate structure.
+ *
+ * @request: A semaphore that users of this notification can wait on for
+ *           changes. Actual reads and writes are still controlled with
+ *           filter->notify_lock.
+ * @next_id: The id of the next request.
+ * @notifications: A list of struct seccomp_knotif elements.
+ * @wqh: A wait queue for poll.
+ */
+struct notification {
+	struct semaphore request;
+	u64 next_id;
+	struct list_head notifications;
+	wait_queue_head_t wqh;
+};
 
 /**
  * struct seccomp_filter - container for seccomp BPF programs
@@ -50,6 +112,8 @@
  * @log: true if all actions except for SECCOMP_RET_ALLOW should be logged
  * @prev: points to a previously installed, or inherited, filter
  * @prog: the BPF program to evaluate
+ * @notif: the struct that holds all notification related information
+ * @notify_lock: A lock for all notification-related accesses.
  *
  * seccomp_filter objects are organized in a tree linked via the @prev
  * pointer.  For any task, it appears to be a singly-linked list starting
@@ -66,6 +130,8 @@ struct seccomp_filter {
 	bool log;
 	struct seccomp_filter *prev;
 	struct bpf_prog *prog;
+	struct notification *notif;
+	struct mutex notify_lock;
 };
 
 /* Limit any path through the tree to 256KB worth of instructions. */
@@ -386,6 +452,7 @@ static struct seccomp_filter *seccomp_prepare_filter(struct sock_fprog *fprog)
 	if (!sfilter)
 		return ERR_PTR(-ENOMEM);
 
+	mutex_init(&sfilter->notify_lock);
 	ret = bpf_prog_create_from_user(&sfilter->prog, fprog,
 					seccomp_check_filter, save_orig);
 	if (ret < 0) {
@@ -479,7 +546,6 @@ static long seccomp_attach_filter(unsigned int flags,
 
 static void __get_seccomp_filter(struct seccomp_filter *filter)
 {
-	/* Reference count is bounded by the number of total processes. */
 	refcount_inc(&filter->usage);
 }
 
@@ -550,11 +616,13 @@ static void seccomp_send_sigsys(int syscall, int reason)
 #define SECCOMP_LOG_TRACE		(1 << 4)
 #define SECCOMP_LOG_LOG			(1 << 5)
 #define SECCOMP_LOG_ALLOW		(1 << 6)
+#define SECCOMP_LOG_USER_NOTIF		(1 << 7)
 
 static u32 seccomp_actions_logged = SECCOMP_LOG_KILL_PROCESS |
 				    SECCOMP_LOG_KILL_THREAD  |
 				    SECCOMP_LOG_TRAP  |
 				    SECCOMP_LOG_ERRNO |
+				    SECCOMP_LOG_USER_NOTIF |
 				    SECCOMP_LOG_TRACE |
 				    SECCOMP_LOG_LOG;
 
@@ -575,6 +643,9 @@ static inline void seccomp_log(unsigned long syscall, long signr, u32 action,
 	case SECCOMP_RET_TRACE:
 		log = requested && seccomp_actions_logged & SECCOMP_LOG_TRACE;
 		break;
+	case SECCOMP_RET_USER_NOTIF:
+		log = requested && seccomp_actions_logged & SECCOMP_LOG_USER_NOTIF;
+		break;
 	case SECCOMP_RET_LOG:
 		log = seccomp_actions_logged & SECCOMP_LOG_LOG;
 		break;
@@ -646,6 +717,68 @@ void secure_computing_strict(int this_syscall)
 #else
 
 #ifdef CONFIG_SECCOMP_FILTER
+static u64 seccomp_next_notify_id(struct seccomp_filter *filter)
+{
+	/*
+	 * Note: overflow is ok here, the id just needs to be unique per
+	 * filter.
+	 */
+	lockdep_assert_held(&filter->notify_lock);
+	return filter->notif->next_id++;
+}
+
+static void seccomp_do_user_notification(int this_syscall,
+					 struct seccomp_filter *match,
+					 const struct seccomp_data *sd)
+{
+	int err;
+	long ret = 0;
+	struct seccomp_knotif n = {};
+
+	mutex_lock(&match->notify_lock);
+	err = -ENOSYS;
+	if (!match->notif)
+		goto out;
+
+	n.task = current;
+	n.state = SECCOMP_NOTIFY_INIT;
+	n.data = sd;
+	n.id = seccomp_next_notify_id(match);
+	init_completion(&n.ready);
+	list_add(&n.list, &match->notif->notifications);
+
+	up(&match->notif->request);
+	wake_up_poll(&match->notif->wqh, EPOLLIN | EPOLLRDNORM);
+	mutex_unlock(&match->notify_lock);
+
+	/*
+	 * This is where we wait for a reply from userspace.
+	 */
+	err = wait_for_completion_interruptible(&n.ready);
+	mutex_lock(&match->notify_lock);
+	if (err == 0) {
+		ret = n.val;
+		err = n.error;
+	}
+
+	/*
+	 * Note that it's possible the listener died in between the time when
+	 * we were notified of a respons (or a signal) and when we were able to
+	 * re-acquire the lock, so only delete from the list if the
+	 * notification actually exists.
+	 *
+	 * Also note that this test is only valid because there's no way to
+	 * *reattach* to a notifier right now. If one is added, we'll need to
+	 * keep track of the notif itself and make sure they match here.
+	 */
+	if (match->notif)
+		list_del(&n.list);
+out:
+	mutex_unlock(&match->notify_lock);
+	syscall_set_return_value(current, task_pt_regs(current),
+				 err, ret);
+}
+
 static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 			    const bool recheck_after_trace)
 {
@@ -728,6 +861,10 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 
 		return 0;
 
+	case SECCOMP_RET_USER_NOTIF:
+		seccomp_do_user_notification(this_syscall, match, sd);
+		goto skip;
+
 	case SECCOMP_RET_LOG:
 		seccomp_log(this_syscall, 0, action, true);
 		return 0;
@@ -834,6 +971,263 @@ static long seccomp_set_mode_strict(void)
 }
 
 #ifdef CONFIG_SECCOMP_FILTER
+static int seccomp_notify_release(struct inode *inode, struct file *file)
+{
+	struct seccomp_filter *filter = file->private_data;
+	struct seccomp_knotif *knotif;
+
+	mutex_lock(&filter->notify_lock);
+
+	/*
+	 * If this file is being closed because e.g. the task who owned it
+	 * died, let's wake everyone up who was waiting on us.
+	 */
+	list_for_each_entry(knotif, &filter->notif->notifications, list) {
+		if (knotif->state == SECCOMP_NOTIFY_REPLIED)
+			continue;
+
+		knotif->state = SECCOMP_NOTIFY_REPLIED;
+		knotif->error = -ENOSYS;
+		knotif->val = 0;
+
+		complete(&knotif->ready);
+	}
+
+	kfree(filter->notif);
+	filter->notif = NULL;
+	mutex_unlock(&filter->notify_lock);
+	__put_seccomp_filter(filter);
+	return 0;
+}
+
+static long seccomp_notify_recv(struct seccomp_filter *filter,
+				void __user *buf)
+{
+	struct seccomp_knotif *knotif = NULL, *cur;
+	struct seccomp_notif unotif;
+	ssize_t ret;
+
+	memset(&unotif, 0, sizeof(unotif));
+
+	ret = down_interruptible(&filter->notif->request);
+	if (ret < 0)
+		return ret;
+
+	mutex_lock(&filter->notify_lock);
+	list_for_each_entry(cur, &filter->notif->notifications, list) {
+		if (cur->state == SECCOMP_NOTIFY_INIT) {
+			knotif = cur;
+			break;
+		}
+	}
+
+	/*
+	 * If we didn't find a notification, it could be that the task was
+	 * interrupted by a fatal signal between the time we were woken and
+	 * when we were able to acquire the rw lock.
+	 */
+	if (!knotif) {
+		ret = -ENOENT;
+		goto out;
+	}
+
+	unotif.id = knotif->id;
+	unotif.pid = task_pid_vnr(knotif->task);
+	unotif.data = *(knotif->data);
+
+	knotif->state = SECCOMP_NOTIFY_SENT;
+	wake_up_poll(&filter->notif->wqh, EPOLLOUT | EPOLLWRNORM);
+	ret = 0;
+out:
+	mutex_unlock(&filter->notify_lock);
+
+	if (ret == 0 && copy_to_user(buf, &unotif, sizeof(unotif))) {
+		ret = -EFAULT;
+
+		/*
+		 * Userspace screwed up. To make sure that we keep this
+		 * notification alive, let's reset it back to INIT. It
+		 * may have died when we released the lock, so we need to make
+		 * sure it's still around.
+		 */
+		knotif = NULL;
+		mutex_lock(&filter->notify_lock);
+		list_for_each_entry(cur, &filter->notif->notifications, list) {
+			if (cur->id == unotif.id) {
+				knotif = cur;
+				break;
+			}
+		}
+
+		if (knotif) {
+			knotif->state = SECCOMP_NOTIFY_INIT;
+			up(&filter->notif->request);
+		}
+		mutex_unlock(&filter->notify_lock);
+	}
+
+	return ret;
+}
+
+static long seccomp_notify_send(struct seccomp_filter *filter,
+				void __user *buf)
+{
+	struct seccomp_notif_resp resp = {};
+	struct seccomp_knotif *knotif = NULL, *cur;
+	long ret;
+
+	if (copy_from_user(&resp, buf, sizeof(resp)))
+		return -EFAULT;
+
+	if (resp.flags)
+		return -EINVAL;
+
+	ret = mutex_lock_interruptible(&filter->notify_lock);
+	if (ret < 0)
+		return ret;
+
+	list_for_each_entry(cur, &filter->notif->notifications, list) {
+		if (cur->id == resp.id) {
+			knotif = cur;
+			break;
+		}
+	}
+
+	if (!knotif) {
+		ret = -ENOENT;
+		goto out;
+	}
+
+	/* Allow exactly one reply. */
+	if (knotif->state != SECCOMP_NOTIFY_SENT) {
+		ret = -EINPROGRESS;
+		goto out;
+	}
+
+	ret = 0;
+	knotif->state = SECCOMP_NOTIFY_REPLIED;
+	knotif->error = resp.error;
+	knotif->val = resp.val;
+	complete(&knotif->ready);
+out:
+	mutex_unlock(&filter->notify_lock);
+	return ret;
+}
+
+static long seccomp_notify_id_valid(struct seccomp_filter *filter,
+				    void __user *buf)
+{
+	struct seccomp_knotif *knotif = NULL;
+	u64 id;
+	long ret;
+
+	if (copy_from_user(&id, buf, sizeof(id)))
+		return -EFAULT;
+
+	ret = mutex_lock_interruptible(&filter->notify_lock);
+	if (ret < 0)
+		return ret;
+
+	ret = -ENOENT;
+	list_for_each_entry(knotif, &filter->notif->notifications, list) {
+		if (knotif->id == id) {
+			if (knotif->state == SECCOMP_NOTIFY_SENT)
+				ret = 0;
+			goto out;
+		}
+	}
+
+out:
+	mutex_unlock(&filter->notify_lock);
+	return ret;
+}
+
+static long seccomp_notify_ioctl(struct file *file, unsigned int cmd,
+				 unsigned long arg)
+{
+	struct seccomp_filter *filter = file->private_data;
+	void __user *buf = (void __user *)arg;
+
+	switch (cmd) {
+	case SECCOMP_IOCTL_NOTIF_RECV:
+		return seccomp_notify_recv(filter, buf);
+	case SECCOMP_IOCTL_NOTIF_SEND:
+		return seccomp_notify_send(filter, buf);
+	case SECCOMP_IOCTL_NOTIF_ID_VALID:
+		return seccomp_notify_id_valid(filter, buf);
+	default:
+		return -EINVAL;
+	}
+}
+
+static __poll_t seccomp_notify_poll(struct file *file,
+				    struct poll_table_struct *poll_tab)
+{
+	struct seccomp_filter *filter = file->private_data;
+	__poll_t ret = 0;
+	struct seccomp_knotif *cur;
+
+	poll_wait(file, &filter->notif->wqh, poll_tab);
+
+	ret = mutex_lock_interruptible(&filter->notify_lock);
+	if (ret < 0)
+		return EPOLLERR;
+
+	list_for_each_entry(cur, &filter->notif->notifications, list) {
+		if (cur->state == SECCOMP_NOTIFY_INIT)
+			ret |= EPOLLIN | EPOLLRDNORM;
+		if (cur->state == SECCOMP_NOTIFY_SENT)
+			ret |= EPOLLOUT | EPOLLWRNORM;
+		if ((ret & EPOLLIN) && (ret & EPOLLOUT))
+			break;
+	}
+
+	mutex_unlock(&filter->notify_lock);
+
+	return ret;
+}
+
+static const struct file_operations seccomp_notify_ops = {
+	.poll = seccomp_notify_poll,
+	.release = seccomp_notify_release,
+	.unlocked_ioctl = seccomp_notify_ioctl,
+};
+
+static struct file *init_listener(struct seccomp_filter *filter)
+{
+	struct file *ret = ERR_PTR(-EBUSY);
+	struct seccomp_filter *cur;
+
+	for (cur = current->seccomp.filter; cur; cur = cur->prev) {
+		if (cur->notif)
+			goto out;
+	}
+
+	ret = ERR_PTR(-ENOMEM);
+	filter->notif = kzalloc(sizeof(*(filter->notif)), GFP_KERNEL);
+	if (!filter->notif)
+		goto out;
+
+	sema_init(&filter->notif->request, 0);
+	filter->notif->next_id = get_random_u64();
+	INIT_LIST_HEAD(&filter->notif->notifications);
+	init_waitqueue_head(&filter->notif->wqh);
+
+	ret = anon_inode_getfile("seccomp notify", &seccomp_notify_ops,
+				 filter, O_RDWR);
+	if (IS_ERR(ret))
+		goto out_notif;
+
+	/* The file has a reference to it now */
+	__get_seccomp_filter(filter);
+
+out_notif:
+	if (IS_ERR(ret))
+		kfree(filter->notif);
+out:
+	return ret;
+}
+
 /**
  * seccomp_set_mode_filter: internal function for setting seccomp filter
  * @flags:  flags to change filter behavior
@@ -853,6 +1247,8 @@ static long seccomp_set_mode_filter(unsigned int flags,
 	const unsigned long seccomp_mode = SECCOMP_MODE_FILTER;
 	struct seccomp_filter *prepared = NULL;
 	long ret = -EINVAL;
+	int listener = -1;
+	struct file *listener_f = NULL;
 
 	/* Validate flags. */
 	if (flags & ~SECCOMP_FILTER_FLAG_MASK)
@@ -863,13 +1259,28 @@ static long seccomp_set_mode_filter(unsigned int flags,
 	if (IS_ERR(prepared))
 		return PTR_ERR(prepared);
 
+	if (flags & SECCOMP_FILTER_FLAG_NEW_LISTENER) {
+		listener = get_unused_fd_flags(O_CLOEXEC);
+		if (listener < 0) {
+			ret = listener;
+			goto out_free;
+		}
+
+		listener_f = init_listener(prepared);
+		if (IS_ERR(listener_f)) {
+			put_unused_fd(listener);
+			ret = PTR_ERR(listener_f);
+			goto out_free;
+		}
+	}
+
 	/*
 	 * Make sure we cannot change seccomp or nnp state via TSYNC
 	 * while another thread is in the middle of calling exec.
 	 */
 	if (flags & SECCOMP_FILTER_FLAG_TSYNC &&
 	    mutex_lock_killable(&current->signal->cred_guard_mutex))
-		goto out_free;
+		goto out_put_fd;
 
 	spin_lock_irq(&current->sighand->siglock);
 
@@ -887,6 +1298,16 @@ static long seccomp_set_mode_filter(unsigned int flags,
 	spin_unlock_irq(&current->sighand->siglock);
 	if (flags & SECCOMP_FILTER_FLAG_TSYNC)
 		mutex_unlock(&current->signal->cred_guard_mutex);
+out_put_fd:
+	if (flags & SECCOMP_FILTER_FLAG_NEW_LISTENER) {
+		if (ret < 0) {
+			fput(listener_f);
+			put_unused_fd(listener);
+		} else {
+			fd_install(listener, listener_f);
+			ret = listener;
+		}
+	}
 out_free:
 	seccomp_filter_free(prepared);
 	return ret;
@@ -911,6 +1332,7 @@ static long seccomp_get_action_avail(const char __user *uaction)
 	case SECCOMP_RET_KILL_THREAD:
 	case SECCOMP_RET_TRAP:
 	case SECCOMP_RET_ERRNO:
+	case SECCOMP_RET_USER_NOTIF:
 	case SECCOMP_RET_TRACE:
 	case SECCOMP_RET_LOG:
 	case SECCOMP_RET_ALLOW:
@@ -922,6 +1344,20 @@ static long seccomp_get_action_avail(const char __user *uaction)
 	return 0;
 }
 
+static long seccomp_get_notif_sizes(void __user *usizes)
+{
+	struct seccomp_notif_sizes sizes = {
+		.seccomp_notif = sizeof(struct seccomp_notif),
+		.seccomp_notif_resp = sizeof(struct seccomp_notif_resp),
+		.seccomp_data = sizeof(struct seccomp_data),
+	};
+
+	if (copy_to_user(usizes, &sizes, sizeof(sizes)))
+		return -EFAULT;
+
+	return 0;
+}
+
 /* Common entry point for both prctl and syscall. */
 static long do_seccomp(unsigned int op, unsigned int flags,
 		       void __user *uargs)
@@ -938,6 +1374,11 @@ static long do_seccomp(unsigned int op, unsigned int flags,
 			return -EINVAL;
 
 		return seccomp_get_action_avail(uargs);
+	case SECCOMP_GET_NOTIF_SIZES:
+		if (flags != 0)
+			return -EINVAL;
+
+		return seccomp_get_notif_sizes(uargs);
 	default:
 		return -EINVAL;
 	}
@@ -1111,6 +1552,7 @@ long seccomp_get_metadata(struct task_struct *task,
 #define SECCOMP_RET_KILL_THREAD_NAME	"kill_thread"
 #define SECCOMP_RET_TRAP_NAME		"trap"
 #define SECCOMP_RET_ERRNO_NAME		"errno"
+#define SECCOMP_RET_USER_NOTIF_NAME	"user_notif"
 #define SECCOMP_RET_TRACE_NAME		"trace"
 #define SECCOMP_RET_LOG_NAME		"log"
 #define SECCOMP_RET_ALLOW_NAME		"allow"
@@ -1120,6 +1562,7 @@ static const char seccomp_actions_avail[] =
 				SECCOMP_RET_KILL_THREAD_NAME	" "
 				SECCOMP_RET_TRAP_NAME		" "
 				SECCOMP_RET_ERRNO_NAME		" "
+				SECCOMP_RET_USER_NOTIF_NAME     " "
 				SECCOMP_RET_TRACE_NAME		" "
 				SECCOMP_RET_LOG_NAME		" "
 				SECCOMP_RET_ALLOW_NAME;
@@ -1134,6 +1577,7 @@ static const struct seccomp_log_name seccomp_log_names[] = {
 	{ SECCOMP_LOG_KILL_THREAD, SECCOMP_RET_KILL_THREAD_NAME },
 	{ SECCOMP_LOG_TRAP, SECCOMP_RET_TRAP_NAME },
 	{ SECCOMP_LOG_ERRNO, SECCOMP_RET_ERRNO_NAME },
+	{ SECCOMP_LOG_USER_NOTIF, SECCOMP_RET_USER_NOTIF_NAME },
 	{ SECCOMP_LOG_TRACE, SECCOMP_RET_TRACE_NAME },
 	{ SECCOMP_LOG_LOG, SECCOMP_RET_LOG_NAME },
 	{ SECCOMP_LOG_ALLOW, SECCOMP_RET_ALLOW_NAME },

commit a5662e4d81c4d4b08140c625d0f3c50b15786252
Author: Tycho Andersen <tycho@tycho.ws>
Date:   Sun Dec 9 11:24:12 2018 -0700

    seccomp: switch system call argument type to void *
    
    The const qualifier causes problems for any code that wants to write to the
    third argument of the seccomp syscall, as we will do in a future patch in
    this series.
    
    The third argument to the seccomp syscall is documented as void *, so
    rather than just dropping the const, let's switch everything to use void *
    as well.
    
    I believe this is safe because of 1. the documentation above, 2. there's no
    real type information exported about syscalls anywhere besides the man
    pages.
    
    Signed-off-by: Tycho Andersen <tycho@tycho.ws>
    CC: Kees Cook <keescook@chromium.org>
    CC: Andy Lutomirski <luto@amacapital.net>
    CC: Oleg Nesterov <oleg@redhat.com>
    CC: Eric W. Biederman <ebiederm@xmission.com>
    CC: "Serge E. Hallyn" <serge@hallyn.com>
    Acked-by: Serge Hallyn <serge@hallyn.com>
    CC: Christian Brauner <christian@brauner.io>
    CC: Tyler Hicks <tyhicks@canonical.com>
    CC: Akihiro Suda <suda.akihiro@lab.ntt.co.jp>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 96afc32e041d..393e029f778a 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -924,7 +924,7 @@ static long seccomp_get_action_avail(const char __user *uaction)
 
 /* Common entry point for both prctl and syscall. */
 static long do_seccomp(unsigned int op, unsigned int flags,
-		       const char __user *uargs)
+		       void __user *uargs)
 {
 	switch (op) {
 	case SECCOMP_SET_MODE_STRICT:
@@ -944,7 +944,7 @@ static long do_seccomp(unsigned int op, unsigned int flags,
 }
 
 SYSCALL_DEFINE3(seccomp, unsigned int, op, unsigned int, flags,
-			 const char __user *, uargs)
+			 void __user *, uargs)
 {
 	return do_seccomp(op, flags, uargs);
 }
@@ -956,10 +956,10 @@ SYSCALL_DEFINE3(seccomp, unsigned int, op, unsigned int, flags,
  *
  * Returns 0 on success or -EINVAL on failure.
  */
-long prctl_set_seccomp(unsigned long seccomp_mode, char __user *filter)
+long prctl_set_seccomp(unsigned long seccomp_mode, void __user *filter)
 {
 	unsigned int op;
-	char __user *uargs;
+	void __user *uargs;
 
 	switch (seccomp_mode) {
 	case SECCOMP_MODE_STRICT:

commit db5113911abaa7eb20cf115d4339959c1aecea95
Author: Tycho Andersen <tycho@tycho.ws>
Date:   Sun Dec 9 11:24:11 2018 -0700

    seccomp: hoist struct seccomp_data recalculation higher
    
    In the next patch, we're going to use the sd pointer passed to
    __seccomp_filter() as the data to pass to userspace. Except that in some
    cases (__seccomp_filter(SECCOMP_RET_TRACE), emulate_vsyscall(), every time
    seccomp is inovked on power, etc.) the sd pointer will be NULL in order to
    force seccomp to recompute the register data. Previously this recomputation
    happened one level lower, in seccomp_run_filters(); this patch just moves
    it up a level higher to __seccomp_filter().
    
    Thanks Oleg for spotting this.
    
    Signed-off-by: Tycho Andersen <tycho@tycho.ws>
    CC: Kees Cook <keescook@chromium.org>
    CC: Andy Lutomirski <luto@amacapital.net>
    CC: Oleg Nesterov <oleg@redhat.com>
    CC: Eric W. Biederman <ebiederm@xmission.com>
    CC: "Serge E. Hallyn" <serge@hallyn.com>
    Acked-by: Serge Hallyn <serge@hallyn.com>
    CC: Christian Brauner <christian@brauner.io>
    CC: Tyler Hicks <tyhicks@canonical.com>
    CC: Akihiro Suda <suda.akihiro@lab.ntt.co.jp>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index f2ae2324c232..96afc32e041d 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -188,7 +188,6 @@ static int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)
 static u32 seccomp_run_filters(const struct seccomp_data *sd,
 			       struct seccomp_filter **match)
 {
-	struct seccomp_data sd_local;
 	u32 ret = SECCOMP_RET_ALLOW;
 	/* Make sure cross-thread synced filter points somewhere sane. */
 	struct seccomp_filter *f =
@@ -198,11 +197,6 @@ static u32 seccomp_run_filters(const struct seccomp_data *sd,
 	if (WARN_ON(f == NULL))
 		return SECCOMP_RET_KILL_PROCESS;
 
-	if (!sd) {
-		populate_seccomp_data(&sd_local);
-		sd = &sd_local;
-	}
-
 	/*
 	 * All filters in the list are evaluated and the lowest BPF return
 	 * value always takes priority (ignoring the DATA).
@@ -658,6 +652,7 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 	u32 filter_ret, action;
 	struct seccomp_filter *match = NULL;
 	int data;
+	struct seccomp_data sd_local;
 
 	/*
 	 * Make sure that any changes to mode from another thread have
@@ -665,6 +660,11 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 	 */
 	rmb();
 
+	if (!sd) {
+		populate_seccomp_data(&sd_local);
+		sd = &sd_local;
+	}
+
 	filter_ret = seccomp_run_filters(sd, &match);
 	data = filter_ret & SECCOMP_RET_DATA;
 	action = filter_ret & SECCOMP_RET_ACTION_FULL;

commit 638820d8da8ededd6dc609beaef02d5396599c03
Merge: d5e4d81da4d4 3f6caaf5ff33
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Oct 24 11:49:35 2018 +0100

    Merge branch 'next-general' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security
    
    Pull security subsystem updates from James Morris:
     "In this patchset, there are a couple of minor updates, as well as some
      reworking of the LSM initialization code from Kees Cook (these prepare
      the way for ordered stackable LSMs, but are a valuable cleanup on
      their own)"
    
    * 'next-general' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security:
      LSM: Don't ignore initialization failures
      LSM: Provide init debugging infrastructure
      LSM: Record LSM name in struct lsm_info
      LSM: Convert security_initcall() into DEFINE_LSM()
      vmlinux.lds.h: Move LSM_TABLE into INIT_DATA
      LSM: Convert from initcall to struct lsm_info
      LSM: Remove initcall tracing
      LSM: Rename .security_initcall section to .lsm_info
      vmlinux.lds.h: Avoid copy/paste of security_init section
      LSM: Correctly announce start of LSM initialization
      security: fix LSM description location
      keys: Fix the use of the C++ keyword "private" in uapi/linux/keyctl.h
      seccomp: remove unnecessary unlikely()
      security: tomoyo: Fix obsolete function
      security/capabilities: remove check for -EINVAL

commit ae7795bc6187a15ec51cf258abae656a625f9980
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Sep 25 11:27:20 2018 +0200

    signal: Distinguish between kernel_siginfo and siginfo
    
    Linus recently observed that if we did not worry about the padding
    member in struct siginfo it is only about 48 bytes, and 48 bytes is
    much nicer than 128 bytes for allocating on the stack and copying
    around in the kernel.
    
    The obvious thing of only adding the padding when userspace is
    including siginfo.h won't work as there are sigframe definitions in
    the kernel that embed struct siginfo.
    
    So split siginfo in two; kernel_siginfo and siginfo.  Keeping the
    traditional name for the userspace definition.  While the version that
    is used internally to the kernel and ultimately will not be padded to
    128 bytes is called kernel_siginfo.
    
    The definition of struct kernel_siginfo I have put in include/signal_types.h
    
    A set of buildtime checks has been added to verify the two structures have
    the same field offsets.
    
    To make it easy to verify the change kernel_siginfo retains the same
    size as siginfo.  The reduction in size comes in a following change.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index fd023ac24e10..4d7809cdd27d 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -522,7 +522,7 @@ void put_seccomp_filter(struct task_struct *tsk)
 	__put_seccomp_filter(tsk->seccomp.filter);
 }
 
-static void seccomp_init_siginfo(siginfo_t *info, int syscall, int reason)
+static void seccomp_init_siginfo(kernel_siginfo_t *info, int syscall, int reason)
 {
 	clear_siginfo(info);
 	info->si_signo = SIGSYS;
@@ -542,7 +542,7 @@ static void seccomp_init_siginfo(siginfo_t *info, int syscall, int reason)
  */
 static void seccomp_send_sigsys(int syscall, int reason)
 {
-	struct siginfo info;
+	struct kernel_siginfo info;
 	seccomp_init_siginfo(&info, syscall, reason);
 	force_sig_info(SIGSYS, &info, current);
 }
@@ -747,7 +747,7 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 		/* Dump core only if this is the last remaining thread. */
 		if (action == SECCOMP_RET_KILL_PROCESS ||
 		    get_nr_threads(current) == 1) {
-			siginfo_t info;
+			kernel_siginfo_t info;
 
 			/* Show the original registers in the dump. */
 			syscall_rollback(current, task_pt_regs(current));

commit 0d42d73a37ff91028785e42a6bf12fc020a277c1
Author: Igor Stoppa <igor.stoppa@gmail.com>
Date:   Wed Sep 5 23:34:43 2018 +0300

    seccomp: remove unnecessary unlikely()
    
    WARN_ON() already contains an unlikely(), so it's not necessary to wrap it
    into another.
    
    Signed-off-by: Igor Stoppa <igor.stoppa@huawei.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: linux-security-module@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: James Morris <james.morris@microsoft.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index fd023ac24e10..5a2a9af4663e 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -195,7 +195,7 @@ static u32 seccomp_run_filters(const struct seccomp_data *sd,
 			READ_ONCE(current->seccomp.filter);
 
 	/* Ensure unexpected behavior doesn't result in failing open. */
-	if (unlikely(WARN_ON(f == NULL)))
+	if (WARN_ON(f == NULL))
 		return SECCOMP_RET_KILL_PROCESS;
 
 	if (!sd) {
@@ -297,7 +297,7 @@ static inline pid_t seccomp_can_sync_threads(void)
 		/* Return the first thread that cannot be synchronized. */
 		failed = task_pid_vnr(thread);
 		/* If the pid cannot be resolved, then return -ESRCH */
-		if (unlikely(WARN_ON(failed == 0)))
+		if (WARN_ON(failed == 0))
 			failed = -ESRCH;
 		return failed;
 	}

commit 8b5c6a3a49d9ebc7dc288870b9c56c4f946035d8
Merge: 8b70543e9af0 5b71388663c0
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jun 6 16:34:00 2018 -0700

    Merge tag 'audit-pr-20180605' of git://git.kernel.org/pub/scm/linux/kernel/git/pcmoore/audit
    
    Pull audit updates from Paul Moore:
     "Another reasonable chunk of audit changes for v4.18, thirteen patches
      in total.
    
      The thirteen patches can mostly be broken down into one of four
      categories: general bug fixes, accessor functions for audit state
      stored in the task_struct, negative filter matches on executable
      names, and extending the (relatively) new seccomp logging knobs to the
      audit subsystem.
    
      The main driver for the accessor functions from Richard are the
      changes we're working on to associate audit events with containers,
      but I think they have some standalone value too so I figured it would
      be good to get them in now.
    
      The seccomp/audit patches from Tyler apply the seccomp logging
      improvements from a few releases ago to audit's seccomp logging;
      starting with this patchset the changes in
      /proc/sys/kernel/seccomp/actions_logged should apply to both the
      standard kernel logging and audit.
    
      As usual, everything passes the audit-testsuite and it happens to
      merge cleanly with your tree"
    
    [ Heh, except it had trivial merge conflicts with the SELinux tree that
      also came in from Paul   - Linus ]
    
    * tag 'audit-pr-20180605' of git://git.kernel.org/pub/scm/linux/kernel/git/pcmoore/audit:
      audit: Fix wrong task in comparison of session ID
      audit: use existing session info function
      audit: normalize loginuid read access
      audit: use new audit_context access funciton for seccomp_actions_logged
      audit: use inline function to set audit context
      audit: use inline function to get audit context
      audit: convert sessionid unset to a macro
      seccomp: Don't special case audited processes when logging
      seccomp: Audit attempts to modify the actions_logged sysctl
      seccomp: Configurable separator for the actions_logged string
      seccomp: Separate read and write code for actions_logged sysctl
      audit: allow not equal op for audit by executable
      audit: add syscall information to FEATURE_CHANGE records

commit 326bee0286d7f6b0d780f5b75a35ea9fe489a802
Author: Tyler Hicks <tyhicks@canonical.com>
Date:   Fri May 4 01:08:15 2018 +0000

    seccomp: Don't special case audited processes when logging
    
    Seccomp logging for "handled" actions such as RET_TRAP, RET_TRACE, or
    RET_ERRNO can be very noisy for processes that are being audited. This
    patch modifies the seccomp logging behavior to treat processes that are
    being inspected via the audit subsystem the same as processes that
    aren't under inspection. Handled actions will no longer be logged just
    because the process is being inspected. Since v4.14, applications have
    the ability to request logging of handled actions by using the
    SECCOMP_FILTER_FLAG_LOG flag when loading seccomp filters.
    
    With this patch, the logic for deciding if an action will be logged is:
    
      if action == RET_ALLOW:
        do not log
      else if action not in actions_logged:
        do not log
      else if action == RET_KILL:
        log
      else if action == RET_LOG:
        log
      else if filter-requests-logging:
        log
      else:
        do not log
    
    Reported-by: Steve Grubb <sgrubb@redhat.com>
    Signed-off-by: Tyler Hicks <tyhicks@canonical.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Paul Moore <paul@paul-moore.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index f5630d1a88fe..5386749cdd21 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -584,18 +584,15 @@ static inline void seccomp_log(unsigned long syscall, long signr, u32 action,
 	}
 
 	/*
-	 * Force an audit message to be emitted when the action is RET_KILL_*,
-	 * RET_LOG, or the FILTER_FLAG_LOG bit was set and the action is
-	 * allowed to be logged by the admin.
+	 * Emit an audit message when the action is RET_KILL_*, RET_LOG, or the
+	 * FILTER_FLAG_LOG bit was set. The admin has the ability to silence
+	 * any action from being logged by removing the action name from the
+	 * seccomp_actions_logged sysctl.
 	 */
-	if (log)
-		return __audit_seccomp(syscall, signr, action);
+	if (!log)
+		return;
 
-	/*
-	 * Let the audit subsystem decide if the action should be audited based
-	 * on whether the current task itself is being audited.
-	 */
-	return audit_seccomp(syscall, signr, action);
+	audit_seccomp(syscall, signr, action);
 }
 
 /*

commit ea6eca778500b0aaf6e5f10dac4d2cd745c2a50b
Author: Tyler Hicks <tyhicks@canonical.com>
Date:   Fri May 4 01:08:14 2018 +0000

    seccomp: Audit attempts to modify the actions_logged sysctl
    
    The decision to log a seccomp action will always be subject to the
    value of the kernel.seccomp.actions_logged sysctl, even for processes
    that are being inspected via the audit subsystem, in an upcoming patch.
    Therefore, we need to emit an audit record on attempts at writing to the
    actions_logged sysctl when auditing is enabled.
    
    This patch updates the write handler for the actions_logged sysctl to
    emit an audit record on attempts to write to the sysctl. Successful
    writes to the sysctl will result in a record that includes a normalized
    list of logged actions in the "actions" field and a "res" field equal to
    1. Unsuccessful writes to the sysctl will result in a record that
    doesn't include the "actions" field and has a "res" field equal to 0.
    
    Not all unsuccessful writes to the sysctl are audited. For example, an
    audit record will not be emitted if an unprivileged process attempts to
    open the sysctl file for reading since that access control check is not
    part of the sysctl's write handler.
    
    Below are some example audit records when writing various strings to the
    actions_logged sysctl.
    
    Writing "not-a-real-action", when the kernel.seccomp.actions_logged
    sysctl previously was "kill_process kill_thread trap errno trace log",
    emits this audit record:
    
     type=CONFIG_CHANGE msg=audit(1525392371.454:120): op=seccomp-logging
     actions=? old-actions=kill_process,kill_thread,trap,errno,trace,log
     res=0
    
    If you then write "kill_process kill_thread errno trace log", this audit
    record is emitted:
    
     type=CONFIG_CHANGE msg=audit(1525392401.645:126): op=seccomp-logging
     actions=kill_process,kill_thread,errno,trace,log
     old-actions=kill_process,kill_thread,trap,errno,trace,log res=1
    
    If you then write "log log errno trace kill_process kill_thread", which
    is unordered and contains the log action twice, it results in the same
    actions value as the previous record:
    
     type=CONFIG_CHANGE msg=audit(1525392436.354:132): op=seccomp-logging
     actions=kill_process,kill_thread,errno,trace,log
     old-actions=kill_process,kill_thread,errno,trace,log res=1
    
    If you then write an empty string to the sysctl, this audit record is
    emitted:
    
     type=CONFIG_CHANGE msg=audit(1525392494.413:138): op=seccomp-logging
     actions=(none) old-actions=kill_process,kill_thread,errno,trace,log
     res=1
    
    No audit records are generated when reading the actions_logged sysctl.
    
    Suggested-by: Steve Grubb <sgrubb@redhat.com>
    Signed-off-by: Tyler Hicks <tyhicks@canonical.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Paul Moore <paul@paul-moore.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index b36ac1e0cd0e..f5630d1a88fe 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -1219,11 +1219,10 @@ static int read_actions_logged(struct ctl_table *ro_table, void __user *buffer,
 }
 
 static int write_actions_logged(struct ctl_table *ro_table, void __user *buffer,
-				size_t *lenp, loff_t *ppos)
+				size_t *lenp, loff_t *ppos, u32 *actions_logged)
 {
 	char names[sizeof(seccomp_actions_avail)];
 	struct ctl_table table;
-	u32 actions_logged;
 	int ret;
 
 	if (!capable(CAP_SYS_ADMIN))
@@ -1238,24 +1237,65 @@ static int write_actions_logged(struct ctl_table *ro_table, void __user *buffer,
 	if (ret)
 		return ret;
 
-	if (!seccomp_actions_logged_from_names(&actions_logged, table.data))
+	if (!seccomp_actions_logged_from_names(actions_logged, table.data))
 		return -EINVAL;
 
-	if (actions_logged & SECCOMP_LOG_ALLOW)
+	if (*actions_logged & SECCOMP_LOG_ALLOW)
 		return -EINVAL;
 
-	seccomp_actions_logged = actions_logged;
+	seccomp_actions_logged = *actions_logged;
 	return 0;
 }
 
+static void audit_actions_logged(u32 actions_logged, u32 old_actions_logged,
+				 int ret)
+{
+	char names[sizeof(seccomp_actions_avail)];
+	char old_names[sizeof(seccomp_actions_avail)];
+	const char *new = names;
+	const char *old = old_names;
+
+	if (!audit_enabled)
+		return;
+
+	memset(names, 0, sizeof(names));
+	memset(old_names, 0, sizeof(old_names));
+
+	if (ret)
+		new = "?";
+	else if (!actions_logged)
+		new = "(none)";
+	else if (!seccomp_names_from_actions_logged(names, sizeof(names),
+						    actions_logged, ","))
+		new = "?";
+
+	if (!old_actions_logged)
+		old = "(none)";
+	else if (!seccomp_names_from_actions_logged(old_names,
+						    sizeof(old_names),
+						    old_actions_logged, ","))
+		old = "?";
+
+	return audit_seccomp_actions_logged(new, old, !ret);
+}
+
 static int seccomp_actions_logged_handler(struct ctl_table *ro_table, int write,
 					  void __user *buffer, size_t *lenp,
 					  loff_t *ppos)
 {
-	if (write)
-		return write_actions_logged(ro_table, buffer, lenp, ppos);
-	else
-		return read_actions_logged(ro_table, buffer, lenp, ppos);
+	int ret;
+
+	if (write) {
+		u32 actions_logged = 0;
+		u32 old_actions_logged = seccomp_actions_logged;
+
+		ret = write_actions_logged(ro_table, buffer, lenp, ppos,
+					   &actions_logged);
+		audit_actions_logged(actions_logged, old_actions_logged, ret);
+	} else
+		ret = read_actions_logged(ro_table, buffer, lenp, ppos);
+
+	return ret;
 }
 
 static struct ctl_path seccomp_sysctl_path[] = {

commit beb44acaf000c97d6c89de581f377df5757857f3
Author: Tyler Hicks <tyhicks@canonical.com>
Date:   Fri May 4 01:08:13 2018 +0000

    seccomp: Configurable separator for the actions_logged string
    
    The function that converts a bitmask of seccomp actions that are
    allowed to be logged is currently only used for constructing the display
    string for the kernel.seccomp.actions_logged sysctl. That string wants a
    space character to be used for the separator between actions.
    
    A future patch will make use of the same function for building a string
    that will be sent to the audit subsystem for tracking modifications to
    the kernel.seccomp.actions_logged sysctl. That string will need to use a
    comma as a separator. This patch allows the separator character to be
    configurable to meet both needs.
    
    Signed-off-by: Tyler Hicks <tyhicks@canonical.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Paul Moore <paul@paul-moore.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index f4afe6790e4c..b36ac1e0cd0e 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -1135,10 +1135,11 @@ static const struct seccomp_log_name seccomp_log_names[] = {
 };
 
 static bool seccomp_names_from_actions_logged(char *names, size_t size,
-					      u32 actions_logged)
+					      u32 actions_logged,
+					      const char *sep)
 {
 	const struct seccomp_log_name *cur;
-	bool append_space = false;
+	bool append_sep = false;
 
 	for (cur = seccomp_log_names; cur->name && size; cur++) {
 		ssize_t ret;
@@ -1146,15 +1147,15 @@ static bool seccomp_names_from_actions_logged(char *names, size_t size,
 		if (!(actions_logged & cur->log))
 			continue;
 
-		if (append_space) {
-			ret = strscpy(names, " ", size);
+		if (append_sep) {
+			ret = strscpy(names, sep, size);
 			if (ret < 0)
 				return false;
 
 			names += ret;
 			size -= ret;
 		} else
-			append_space = true;
+			append_sep = true;
 
 		ret = strscpy(names, cur->name, size);
 		if (ret < 0)
@@ -1208,7 +1209,7 @@ static int read_actions_logged(struct ctl_table *ro_table, void __user *buffer,
 	memset(names, 0, sizeof(names));
 
 	if (!seccomp_names_from_actions_logged(names, sizeof(names),
-					       seccomp_actions_logged))
+					       seccomp_actions_logged, " "))
 		return -EINVAL;
 
 	table = *ro_table;

commit d013db029491b49e1459d5a55ecd9ec1be1447ca
Author: Tyler Hicks <tyhicks@canonical.com>
Date:   Fri May 4 01:08:12 2018 +0000

    seccomp: Separate read and write code for actions_logged sysctl
    
    Break the read and write paths of the kernel.seccomp.actions_logged
    sysctl into separate functions to maintain readability. An upcoming
    change will need to audit writes, but not reads, of this sysctl which
    would introduce too many conditional code paths on whether or not the
    'write' parameter evaluates to true.
    
    Signed-off-by: Tyler Hicks <tyhicks@canonical.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Paul Moore <paul@paul-moore.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index dc77548167ef..f4afe6790e4c 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -1199,48 +1199,64 @@ static bool seccomp_actions_logged_from_names(u32 *actions_logged, char *names)
 	return true;
 }
 
-static int seccomp_actions_logged_handler(struct ctl_table *ro_table, int write,
-					  void __user *buffer, size_t *lenp,
-					  loff_t *ppos)
+static int read_actions_logged(struct ctl_table *ro_table, void __user *buffer,
+			       size_t *lenp, loff_t *ppos)
 {
 	char names[sizeof(seccomp_actions_avail)];
 	struct ctl_table table;
+
+	memset(names, 0, sizeof(names));
+
+	if (!seccomp_names_from_actions_logged(names, sizeof(names),
+					       seccomp_actions_logged))
+		return -EINVAL;
+
+	table = *ro_table;
+	table.data = names;
+	table.maxlen = sizeof(names);
+	return proc_dostring(&table, 0, buffer, lenp, ppos);
+}
+
+static int write_actions_logged(struct ctl_table *ro_table, void __user *buffer,
+				size_t *lenp, loff_t *ppos)
+{
+	char names[sizeof(seccomp_actions_avail)];
+	struct ctl_table table;
+	u32 actions_logged;
 	int ret;
 
-	if (write && !capable(CAP_SYS_ADMIN))
+	if (!capable(CAP_SYS_ADMIN))
 		return -EPERM;
 
 	memset(names, 0, sizeof(names));
 
-	if (!write) {
-		if (!seccomp_names_from_actions_logged(names, sizeof(names),
-						       seccomp_actions_logged))
-			return -EINVAL;
-	}
-
 	table = *ro_table;
 	table.data = names;
 	table.maxlen = sizeof(names);
-	ret = proc_dostring(&table, write, buffer, lenp, ppos);
+	ret = proc_dostring(&table, 1, buffer, lenp, ppos);
 	if (ret)
 		return ret;
 
-	if (write) {
-		u32 actions_logged;
-
-		if (!seccomp_actions_logged_from_names(&actions_logged,
-						       table.data))
-			return -EINVAL;
-
-		if (actions_logged & SECCOMP_LOG_ALLOW)
-			return -EINVAL;
+	if (!seccomp_actions_logged_from_names(&actions_logged, table.data))
+		return -EINVAL;
 
-		seccomp_actions_logged = actions_logged;
-	}
+	if (actions_logged & SECCOMP_LOG_ALLOW)
+		return -EINVAL;
 
+	seccomp_actions_logged = actions_logged;
 	return 0;
 }
 
+static int seccomp_actions_logged_handler(struct ctl_table *ro_table, int write,
+					  void __user *buffer, size_t *lenp,
+					  loff_t *ppos)
+{
+	if (write)
+		return write_actions_logged(ro_table, buffer, lenp, ppos);
+	else
+		return read_actions_logged(ro_table, buffer, lenp, ppos);
+}
+
 static struct ctl_path seccomp_sysctl_path[] = {
 	{ .procname = "kernel", },
 	{ .procname = "seccomp", },

commit 8bf37d8c067bb7eb8e7c381bdadf9bd89182b6bc
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri May 4 15:12:06 2018 +0200

    seccomp: Move speculation migitation control to arch code
    
    The migitation control is simpler to implement in architecture code as it
    avoids the extra function call to check the mode. Aside of that having an
    explicit seccomp enabled mode in the architecture mitigations would require
    even more workarounds.
    
    Move it into architecture code and provide a weak function in the seccomp
    code. Remove the 'which' argument as this allows the architecture to decide
    which mitigations are relevant for seccomp.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 53eb946120c1..e691d9a6c58d 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -229,18 +229,7 @@ static inline bool seccomp_may_assign_mode(unsigned long seccomp_mode)
 	return true;
 }
 
-/*
- * If a given speculation mitigation is opt-in (prctl()-controlled),
- * select it, by disabling speculation (enabling mitigation).
- */
-static inline void spec_mitigate(struct task_struct *task,
-				 unsigned long which)
-{
-	int state = arch_prctl_spec_ctrl_get(task, which);
-
-	if (state > 0 && (state & PR_SPEC_PRCTL))
-		arch_prctl_spec_ctrl_set(task, which, PR_SPEC_FORCE_DISABLE);
-}
+void __weak arch_seccomp_spec_mitigate(struct task_struct *task) { }
 
 static inline void seccomp_assign_mode(struct task_struct *task,
 				       unsigned long seccomp_mode,
@@ -256,7 +245,7 @@ static inline void seccomp_assign_mode(struct task_struct *task,
 	smp_mb__before_atomic();
 	/* Assume default seccomp processes want spec flaw mitigation. */
 	if ((flags & SECCOMP_FILTER_FLAG_SPEC_ALLOW) == 0)
-		spec_mitigate(task, PR_SPEC_STORE_BYPASS);
+		arch_seccomp_spec_mitigate(task);
 	set_tsk_thread_flag(task, TIF_SECCOMP);
 }
 

commit 00a02d0c502a06d15e07b857f8ff921e3e402675
Author: Kees Cook <keescook@chromium.org>
Date:   Thu May 3 14:56:12 2018 -0700

    seccomp: Add filter flag to opt-out of SSB mitigation
    
    If a seccomp user is not interested in Speculative Store Bypass mitigation
    by default, it can set the new SECCOMP_FILTER_FLAG_SPEC_ALLOW flag when
    adding filters.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 2c819d65e15f..53eb946120c1 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -243,7 +243,8 @@ static inline void spec_mitigate(struct task_struct *task,
 }
 
 static inline void seccomp_assign_mode(struct task_struct *task,
-				       unsigned long seccomp_mode)
+				       unsigned long seccomp_mode,
+				       unsigned long flags)
 {
 	assert_spin_locked(&task->sighand->siglock);
 
@@ -253,8 +254,9 @@ static inline void seccomp_assign_mode(struct task_struct *task,
 	 * filter) is set.
 	 */
 	smp_mb__before_atomic();
-	/* Assume seccomp processes want speculation flaw mitigation. */
-	spec_mitigate(task, PR_SPEC_STORE_BYPASS);
+	/* Assume default seccomp processes want spec flaw mitigation. */
+	if ((flags & SECCOMP_FILTER_FLAG_SPEC_ALLOW) == 0)
+		spec_mitigate(task, PR_SPEC_STORE_BYPASS);
 	set_tsk_thread_flag(task, TIF_SECCOMP);
 }
 
@@ -322,7 +324,7 @@ static inline pid_t seccomp_can_sync_threads(void)
  * without dropping the locks.
  *
  */
-static inline void seccomp_sync_threads(void)
+static inline void seccomp_sync_threads(unsigned long flags)
 {
 	struct task_struct *thread, *caller;
 
@@ -363,7 +365,8 @@ static inline void seccomp_sync_threads(void)
 		 * allow one thread to transition the other.
 		 */
 		if (thread->seccomp.mode == SECCOMP_MODE_DISABLED)
-			seccomp_assign_mode(thread, SECCOMP_MODE_FILTER);
+			seccomp_assign_mode(thread, SECCOMP_MODE_FILTER,
+					    flags);
 	}
 }
 
@@ -486,7 +489,7 @@ static long seccomp_attach_filter(unsigned int flags,
 
 	/* Now that the new filter is in place, synchronize to all threads. */
 	if (flags & SECCOMP_FILTER_FLAG_TSYNC)
-		seccomp_sync_threads();
+		seccomp_sync_threads(flags);
 
 	return 0;
 }
@@ -835,7 +838,7 @@ static long seccomp_set_mode_strict(void)
 #ifdef TIF_NOTSC
 	disable_TSC();
 #endif
-	seccomp_assign_mode(current, seccomp_mode);
+	seccomp_assign_mode(current, seccomp_mode, 0);
 	ret = 0;
 
 out:
@@ -893,7 +896,7 @@ static long seccomp_set_mode_filter(unsigned int flags,
 	/* Do not free the successfully attached filter. */
 	prepared = NULL;
 
-	seccomp_assign_mode(current, seccomp_mode);
+	seccomp_assign_mode(current, seccomp_mode, flags);
 out:
 	spin_unlock_irq(&current->sighand->siglock);
 	if (flags & SECCOMP_FILTER_FLAG_TSYNC)

commit b849a812f7eb92e96d1c8239b06581b2cfd8b275
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri May 4 09:40:03 2018 +0200

    seccomp: Use PR_SPEC_FORCE_DISABLE
    
    Use PR_SPEC_FORCE_DISABLE in seccomp() because seccomp does not allow to
    widen restrictions.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 9f34533046aa..2c819d65e15f 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -239,7 +239,7 @@ static inline void spec_mitigate(struct task_struct *task,
 	int state = arch_prctl_spec_ctrl_get(task, which);
 
 	if (state > 0 && (state & PR_SPEC_PRCTL))
-		arch_prctl_spec_ctrl_set(task, which, PR_SPEC_DISABLE);
+		arch_prctl_spec_ctrl_set(task, which, PR_SPEC_FORCE_DISABLE);
 }
 
 static inline void seccomp_assign_mode(struct task_struct *task,

commit 5c3070890d06ff82eecb808d02d2ca39169533ef
Author: Kees Cook <keescook@chromium.org>
Date:   Tue May 1 15:07:31 2018 -0700

    seccomp: Enable speculation flaw mitigations
    
    When speculation flaw mitigations are opt-in (via prctl), using seccomp
    will automatically opt-in to these protections, since using seccomp
    indicates at least some level of sandboxing is desired.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index dc77548167ef..9f34533046aa 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -19,6 +19,8 @@
 #include <linux/compat.h>
 #include <linux/coredump.h>
 #include <linux/kmemleak.h>
+#include <linux/nospec.h>
+#include <linux/prctl.h>
 #include <linux/sched.h>
 #include <linux/sched/task_stack.h>
 #include <linux/seccomp.h>
@@ -227,6 +229,19 @@ static inline bool seccomp_may_assign_mode(unsigned long seccomp_mode)
 	return true;
 }
 
+/*
+ * If a given speculation mitigation is opt-in (prctl()-controlled),
+ * select it, by disabling speculation (enabling mitigation).
+ */
+static inline void spec_mitigate(struct task_struct *task,
+				 unsigned long which)
+{
+	int state = arch_prctl_spec_ctrl_get(task, which);
+
+	if (state > 0 && (state & PR_SPEC_PRCTL))
+		arch_prctl_spec_ctrl_set(task, which, PR_SPEC_DISABLE);
+}
+
 static inline void seccomp_assign_mode(struct task_struct *task,
 				       unsigned long seccomp_mode)
 {
@@ -238,6 +253,8 @@ static inline void seccomp_assign_mode(struct task_struct *task,
 	 * filter) is set.
 	 */
 	smp_mb__before_atomic();
+	/* Assume seccomp processes want speculation flaw mitigation. */
+	spec_mitigate(task, PR_SPEC_STORE_BYPASS);
 	set_tsk_thread_flag(task, TIF_SECCOMP);
 }
 

commit 645ae5c51e85d7dbb25177866d5016a89d5243ad
Merge: af3e79d29555 d057dc4e35e1
Author: James Morris <jmorris@namei.org>
Date:   Thu Feb 22 10:50:24 2018 -0800

    Merge tag 'seccomp-v4.16-rc3' of https://git.kernel.org/pub/scm/linux/kernel/git/kees/linux into fixes-v4.16-rc3
    
    - Fix seccomp GET_METADATA to deal with field sizes correctly (Tycho Andersen)
    - Add selftest to make sure GET_METADATA doesn't regress (Tycho Andersen)

commit 63bb0045b98ae821e56e27c2250e14bb0ae663e5
Author: Tycho Andersen <tycho@tycho.ws>
Date:   Tue Feb 20 19:47:46 2018 -0700

    ptrace, seccomp: tweak get_metadata behavior slightly
    
    Previously if users passed a small size for the input structure size, they
    would get get odd behavior. It doesn't make sense to pass a structure
    smaller than at least filter_off size, so let's just give -EINVAL in this
    case.
    
    This changes userspace visible behavior, but was only introduced in commit
    26500475ac1b ("ptrace, seccomp: add support for retrieving seccomp
    metadata") in 4.16-rc2, so should be safe to change if merged before then.
    
    Reported-by: Eugene Syromiatnikov <esyr@redhat.com>
    Signed-off-by: Tycho Andersen <tycho@tycho.ws>
    CC: Kees Cook <keescook@chromium.org>
    CC: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 61bd9dc260c8..1245b2338fff 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -1076,14 +1076,16 @@ long seccomp_get_metadata(struct task_struct *task,
 
 	size = min_t(unsigned long, size, sizeof(kmd));
 
-	if (copy_from_user(&kmd, data, size))
+	if (size < sizeof(kmd.filter_off))
+		return -EINVAL;
+
+	if (copy_from_user(&kmd.filter_off, data, sizeof(kmd.filter_off)))
 		return -EFAULT;
 
 	filter = get_nth_filter(task, kmd.filter_off);
 	if (IS_ERR(filter))
 		return PTR_ERR(filter);
 
-	memset(&kmd, 0, sizeof(kmd));
 	if (filter->log)
 		kmd.flags |= SECCOMP_FILTER_FLAG_LOG;
 

commit 3dbc4f548519f9882676843b4fcdb4e61668baf8
Merge: ae0cb7be35fe 26025bf58b9f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jan 31 13:44:45 2018 -0800

    Merge branch 'next-seccomp' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security
    
    Pull seccomp updates from James Morris:
     "Add support for retrieving seccomp metadata"
    
    * 'next-seccomp' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security:
      ptrace, seccomp: add support for retrieving seccomp metadata
      seccomp: hoist out filter resolving logic

commit 3b10db2b06e2f6191aabb14babe28dcaa657a947
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Aug 18 19:56:27 2017 -0500

    signal: Replace memset(info,...) with clear_siginfo for clarity
    
    The function clear_siginfo is just a nice wrapper around memset so
    this results in no functional change.  This change makes mistakes
    a little more difficult and it makes it clearer what is going on.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 5f0dfb2abb8d..3153c9ea51bf 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -515,7 +515,7 @@ void put_seccomp_filter(struct task_struct *tsk)
 
 static void seccomp_init_siginfo(siginfo_t *info, int syscall, int reason)
 {
-	memset(info, 0, sizeof(*info));
+	clear_siginfo(info);
 	info->si_signo = SIGSYS;
 	info->si_code = SYS_SECCOMP;
 	info->si_call_addr = (void __user *)KSTK_EIP(current);

commit 26500475ac1b499d8636ff281311d633909f5d20
Author: Tycho Andersen <tycho@docker.com>
Date:   Wed Oct 11 09:39:21 2017 -0600

    ptrace, seccomp: add support for retrieving seccomp metadata
    
    With the new SECCOMP_FILTER_FLAG_LOG, we need to be able to extract these
    flags for checkpoint restore, since they describe the state of a filter.
    
    So, let's add PTRACE_SECCOMP_GET_METADATA, similar to ..._GET_FILTER, which
    returns the metadata of the nth filter (right now, just the flags).
    Hopefully this will be future proof, and new per-filter metadata can be
    added to this struct.
    
    Signed-off-by: Tycho Andersen <tycho@docker.com>
    CC: Kees Cook <keescook@chromium.org>
    CC: Andy Lutomirski <luto@amacapital.net>
    CC: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 99bddaf79076..61bd9dc260c8 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -1061,6 +1061,39 @@ long seccomp_get_filter(struct task_struct *task, unsigned long filter_off,
 	__put_seccomp_filter(filter);
 	return ret;
 }
+
+long seccomp_get_metadata(struct task_struct *task,
+			  unsigned long size, void __user *data)
+{
+	long ret;
+	struct seccomp_filter *filter;
+	struct seccomp_metadata kmd = {};
+
+	if (!capable(CAP_SYS_ADMIN) ||
+	    current->seccomp.mode != SECCOMP_MODE_DISABLED) {
+		return -EACCES;
+	}
+
+	size = min_t(unsigned long, size, sizeof(kmd));
+
+	if (copy_from_user(&kmd, data, size))
+		return -EFAULT;
+
+	filter = get_nth_filter(task, kmd.filter_off);
+	if (IS_ERR(filter))
+		return PTR_ERR(filter);
+
+	memset(&kmd, 0, sizeof(kmd));
+	if (filter->log)
+		kmd.flags |= SECCOMP_FILTER_FLAG_LOG;
+
+	ret = size;
+	if (copy_to_user(data, &kmd, size))
+		ret = -EFAULT;
+
+	__put_seccomp_filter(filter);
+	return ret;
+}
 #endif
 
 #ifdef CONFIG_SYSCTL

commit f06eae831f0c1fc5b982ea200daf552810e1dd55
Author: Tycho Andersen <tycho@docker.com>
Date:   Wed Oct 11 09:39:20 2017 -0600

    seccomp: hoist out filter resolving logic
    
    Hoist out the nth filter resolving logic that ptrace uses into a new
    function. We'll use this in the next patch to implement the new
    PTRACE_SECCOMP_GET_FILTER_FLAGS command.
    
    Signed-off-by: Tycho Andersen <tycho@docker.com>
    CC: Kees Cook <keescook@chromium.org>
    CC: Andy Lutomirski <luto@amacapital.net>
    CC: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 5f0dfb2abb8d..99bddaf79076 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -978,49 +978,68 @@ long prctl_set_seccomp(unsigned long seccomp_mode, char __user *filter)
 }
 
 #if defined(CONFIG_SECCOMP_FILTER) && defined(CONFIG_CHECKPOINT_RESTORE)
-long seccomp_get_filter(struct task_struct *task, unsigned long filter_off,
-			void __user *data)
+static struct seccomp_filter *get_nth_filter(struct task_struct *task,
+					     unsigned long filter_off)
 {
-	struct seccomp_filter *filter;
-	struct sock_fprog_kern *fprog;
-	long ret;
-	unsigned long count = 0;
-
-	if (!capable(CAP_SYS_ADMIN) ||
-	    current->seccomp.mode != SECCOMP_MODE_DISABLED) {
-		return -EACCES;
-	}
+	struct seccomp_filter *orig, *filter;
+	unsigned long count;
 
+	/*
+	 * Note: this is only correct because the caller should be the (ptrace)
+	 * tracer of the task, otherwise lock_task_sighand is needed.
+	 */
 	spin_lock_irq(&task->sighand->siglock);
+
 	if (task->seccomp.mode != SECCOMP_MODE_FILTER) {
-		ret = -EINVAL;
-		goto out;
+		spin_unlock_irq(&task->sighand->siglock);
+		return ERR_PTR(-EINVAL);
 	}
 
-	filter = task->seccomp.filter;
-	while (filter) {
-		filter = filter->prev;
+	orig = task->seccomp.filter;
+	__get_seccomp_filter(orig);
+	spin_unlock_irq(&task->sighand->siglock);
+
+	count = 0;
+	for (filter = orig; filter; filter = filter->prev)
 		count++;
-	}
 
 	if (filter_off >= count) {
-		ret = -ENOENT;
+		filter = ERR_PTR(-ENOENT);
 		goto out;
 	}
-	count -= filter_off;
 
-	filter = task->seccomp.filter;
-	while (filter && count > 1) {
-		filter = filter->prev;
+	count -= filter_off;
+	for (filter = orig; filter && count > 1; filter = filter->prev)
 		count--;
-	}
 
 	if (WARN_ON(count != 1 || !filter)) {
-		/* The filter tree shouldn't shrink while we're using it. */
-		ret = -ENOENT;
+		filter = ERR_PTR(-ENOENT);
 		goto out;
 	}
 
+	__get_seccomp_filter(filter);
+
+out:
+	__put_seccomp_filter(orig);
+	return filter;
+}
+
+long seccomp_get_filter(struct task_struct *task, unsigned long filter_off,
+			void __user *data)
+{
+	struct seccomp_filter *filter;
+	struct sock_fprog_kern *fprog;
+	long ret;
+
+	if (!capable(CAP_SYS_ADMIN) ||
+	    current->seccomp.mode != SECCOMP_MODE_DISABLED) {
+		return -EACCES;
+	}
+
+	filter = get_nth_filter(task, filter_off);
+	if (IS_ERR(filter))
+		return PTR_ERR(filter);
+
 	fprog = filter->prog->orig_prog;
 	if (!fprog) {
 		/* This must be a new non-cBPF filter, since we save
@@ -1035,17 +1054,11 @@ long seccomp_get_filter(struct task_struct *task, unsigned long filter_off,
 	if (!data)
 		goto out;
 
-	__get_seccomp_filter(filter);
-	spin_unlock_irq(&task->sighand->siglock);
-
 	if (copy_to_user(data, fprog->filter, bpf_classic_proglen(fprog)))
 		ret = -EFAULT;
 
-	__put_seccomp_filter(filter);
-	return ret;
-
 out:
-	spin_unlock_irq(&task->sighand->siglock);
+	__put_seccomp_filter(filter);
 	return ret;
 }
 #endif

commit 8c5db92a705d9e2c986adec475980d1120fa07b4
Merge: ca5d376e1707 e4880bc5dfb1
Author: Ingo Molnar <mingo@kernel.org>
Date:   Tue Nov 7 10:32:44 2017 +0100

    Merge branch 'linus' into locking/core, to resolve conflicts
    
    Conflicts:
            include/linux/compiler-clang.h
            include/linux/compiler-gcc.h
            include/linux/compiler-intel.h
            include/uapi/linux/stddef.h
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 0ae832e13b97..418a1c045933 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * linux/kernel/seccomp.c
  *

commit 506458efaf153c1ea480591c5602a5a3ba5a3b76
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Oct 24 11:22:48 2017 +0100

    locking/barriers: Convert users of lockless_dereference() to READ_ONCE()
    
    READ_ONCE() now has an implicit smp_read_barrier_depends() call, so it
    can be used instead of lockless_dereference() without any change in
    semantics.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1508840570-22169-4-git-send-email-will.deacon@arm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 0ae832e13b97..8ac79355915b 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -189,7 +189,7 @@ static u32 seccomp_run_filters(const struct seccomp_data *sd,
 	u32 ret = SECCOMP_RET_ALLOW;
 	/* Make sure cross-thread synced filter points somewhere sane. */
 	struct seccomp_filter *f =
-			lockless_dereference(current->seccomp.filter);
+			READ_ONCE(current->seccomp.filter);
 
 	/* Ensure unexpected behavior doesn't result in failing open. */
 	if (unlikely(WARN_ON(f == NULL)))

commit 084f5601c357e4ee59cf0712200d3f5c4710ba40
Author: Colin Ian King <colin.king@canonical.com>
Date:   Fri Sep 29 14:26:48 2017 +0100

    seccomp: make function __get_seccomp_filter static
    
    The function __get_seccomp_filter is local to the source and does
    not need to be in global scope, so make it static.
    
    Cleans up sparse warning:
    symbol '__get_seccomp_filter' was not declared. Should it be static?
    
    Signed-off-by: Colin Ian King <colin.king@canonical.com>
    Fixes: 66a733ea6b61 ("seccomp: fix the usage of get/put_seccomp_filter() in seccomp_get_filter()")
    Cc: stable@vger.kernel.org
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index bb3a38005b9c..0ae832e13b97 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -473,7 +473,7 @@ static long seccomp_attach_filter(unsigned int flags,
 	return 0;
 }
 
-void __get_seccomp_filter(struct seccomp_filter *filter)
+static void __get_seccomp_filter(struct seccomp_filter *filter)
 {
 	/* Reference count is bounded by the number of total processes. */
 	refcount_inc(&filter->usage);

commit 66a733ea6b611aecf0119514d2dddab5f9d6c01e
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Sep 27 09:25:30 2017 -0600

    seccomp: fix the usage of get/put_seccomp_filter() in seccomp_get_filter()
    
    As Chris explains, get_seccomp_filter() and put_seccomp_filter() can end
    up using different filters. Once we drop ->siglock it is possible for
    task->seccomp.filter to have been replaced by SECCOMP_FILTER_FLAG_TSYNC.
    
    Fixes: f8e529ed941b ("seccomp, ptrace: add support for dumping seccomp filters")
    Reported-by: Chris Salls <chrissalls5@gmail.com>
    Cc: stable@vger.kernel.org # needs s/refcount_/atomic_/ for v4.12 and earlier
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    [tycho: add __get_seccomp_filter vs. open coding refcount_inc()]
    Signed-off-by: Tycho Andersen <tycho@docker.com>
    [kees: tweak commit log]
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index c24579dfa7a1..bb3a38005b9c 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -473,14 +473,19 @@ static long seccomp_attach_filter(unsigned int flags,
 	return 0;
 }
 
+void __get_seccomp_filter(struct seccomp_filter *filter)
+{
+	/* Reference count is bounded by the number of total processes. */
+	refcount_inc(&filter->usage);
+}
+
 /* get_seccomp_filter - increments the reference count of the filter on @tsk */
 void get_seccomp_filter(struct task_struct *tsk)
 {
 	struct seccomp_filter *orig = tsk->seccomp.filter;
 	if (!orig)
 		return;
-	/* Reference count is bounded by the number of total processes. */
-	refcount_inc(&orig->usage);
+	__get_seccomp_filter(orig);
 }
 
 static inline void seccomp_filter_free(struct seccomp_filter *filter)
@@ -491,10 +496,8 @@ static inline void seccomp_filter_free(struct seccomp_filter *filter)
 	}
 }
 
-/* put_seccomp_filter - decrements the ref count of tsk->seccomp.filter */
-void put_seccomp_filter(struct task_struct *tsk)
+static void __put_seccomp_filter(struct seccomp_filter *orig)
 {
-	struct seccomp_filter *orig = tsk->seccomp.filter;
 	/* Clean up single-reference branches iteratively. */
 	while (orig && refcount_dec_and_test(&orig->usage)) {
 		struct seccomp_filter *freeme = orig;
@@ -503,6 +506,12 @@ void put_seccomp_filter(struct task_struct *tsk)
 	}
 }
 
+/* put_seccomp_filter - decrements the ref count of tsk->seccomp.filter */
+void put_seccomp_filter(struct task_struct *tsk)
+{
+	__put_seccomp_filter(tsk->seccomp.filter);
+}
+
 static void seccomp_init_siginfo(siginfo_t *info, int syscall, int reason)
 {
 	memset(info, 0, sizeof(*info));
@@ -1025,13 +1034,13 @@ long seccomp_get_filter(struct task_struct *task, unsigned long filter_off,
 	if (!data)
 		goto out;
 
-	get_seccomp_filter(task);
+	__get_seccomp_filter(filter);
 	spin_unlock_irq(&task->sighand->siglock);
 
 	if (copy_to_user(data, fprog->filter, bpf_classic_proglen(fprog)))
 		ret = -EFAULT;
 
-	put_seccomp_filter(task);
+	__put_seccomp_filter(filter);
 	return ret;
 
 out:

commit 0466bdb99e8744bc9befa8d62a317f0fd7fd7421
Author: Kees Cook <keescook@chromium.org>
Date:   Fri Aug 11 13:12:11 2017 -0700

    seccomp: Implement SECCOMP_RET_KILL_PROCESS action
    
    Right now, SECCOMP_RET_KILL_THREAD (ne SECCOMP_RET_KILL) kills the
    current thread. There have been a few requests for this to kill the entire
    process (the thread group). This cannot be just changed (discovered when
    adding coredump support since coredumping kills the entire process)
    because there are userspace programs depending on the thread-kill
    behavior.
    
    Instead, implement SECCOMP_RET_KILL_PROCESS, which is 0x80000000, and can
    be processed as "-1" by the kernel, below the existing RET_KILL that is
    ABI-set to "0". For userspace, SECCOMP_RET_ACTION_FULL is added to expand
    the mask to the signed bit. Old userspace using the SECCOMP_RET_ACTION
    mask will see SECCOMP_RET_KILL_PROCESS as 0 still, but this would only
    be visible when examining the siginfo in a core dump from a RET_KILL_*,
    where it will think it was thread-killed instead of process-killed.
    
    Attempts to introduce this behavior via other ways (filter flags,
    seccomp struct flags, masked RET_DATA bits) all come with weird
    side-effects and baggage. This change preserves the central behavioral
    expectations of the seccomp filter engine without putting too great
    a burden on changes needed in userspace to use the new action.
    
    The new action is discoverable by userspace through either the new
    actions_avail sysctl or through the SECCOMP_GET_ACTION_AVAIL seccomp
    operation. If used without checking for availability, old kernels
    will treat RET_KILL_PROCESS as RET_KILL_THREAD (since the old mask
    will produce RET_KILL_THREAD).
    
    Cc: Paul Moore <paul@paul-moore.com>
    Cc: Fabricio Voznika <fvoznika@google.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 5c7299b9d953..c24579dfa7a1 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -181,6 +181,7 @@ static int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)
  *
  * Returns valid seccomp BPF response codes.
  */
+#define ACTION_ONLY(ret) ((s32)((ret) & (SECCOMP_RET_ACTION_FULL)))
 static u32 seccomp_run_filters(const struct seccomp_data *sd,
 			       struct seccomp_filter **match)
 {
@@ -206,7 +207,7 @@ static u32 seccomp_run_filters(const struct seccomp_data *sd,
 	for (; f; f = f->prev) {
 		u32 cur_ret = BPF_PROG_RUN(f->prog, sd);
 
-		if ((cur_ret & SECCOMP_RET_ACTION) < (ret & SECCOMP_RET_ACTION)) {
+		if (ACTION_ONLY(cur_ret) < ACTION_ONLY(ret)) {
 			ret = cur_ret;
 			*match = f;
 		}
@@ -650,7 +651,7 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 
 	filter_ret = seccomp_run_filters(sd, &match);
 	data = filter_ret & SECCOMP_RET_DATA;
-	action = filter_ret & SECCOMP_RET_ACTION;
+	action = filter_ret & SECCOMP_RET_ACTION_FULL;
 
 	switch (action) {
 	case SECCOMP_RET_ERRNO:
@@ -890,6 +891,7 @@ static long seccomp_get_action_avail(const char __user *uaction)
 		return -EFAULT;
 
 	switch (action) {
+	case SECCOMP_RET_KILL_PROCESS:
 	case SECCOMP_RET_KILL_THREAD:
 	case SECCOMP_RET_TRAP:
 	case SECCOMP_RET_ERRNO:
@@ -1041,6 +1043,7 @@ long seccomp_get_filter(struct task_struct *task, unsigned long filter_off,
 #ifdef CONFIG_SYSCTL
 
 /* Human readable action names for friendly sysctl interaction */
+#define SECCOMP_RET_KILL_PROCESS_NAME	"kill_process"
 #define SECCOMP_RET_KILL_THREAD_NAME	"kill_thread"
 #define SECCOMP_RET_TRAP_NAME		"trap"
 #define SECCOMP_RET_ERRNO_NAME		"errno"
@@ -1049,6 +1052,7 @@ long seccomp_get_filter(struct task_struct *task, unsigned long filter_off,
 #define SECCOMP_RET_ALLOW_NAME		"allow"
 
 static const char seccomp_actions_avail[] =
+				SECCOMP_RET_KILL_PROCESS_NAME	" "
 				SECCOMP_RET_KILL_THREAD_NAME	" "
 				SECCOMP_RET_TRAP_NAME		" "
 				SECCOMP_RET_ERRNO_NAME		" "
@@ -1062,6 +1066,7 @@ struct seccomp_log_name {
 };
 
 static const struct seccomp_log_name seccomp_log_names[] = {
+	{ SECCOMP_LOG_KILL_PROCESS, SECCOMP_RET_KILL_PROCESS_NAME },
 	{ SECCOMP_LOG_KILL_THREAD, SECCOMP_RET_KILL_THREAD_NAME },
 	{ SECCOMP_LOG_TRAP, SECCOMP_RET_TRAP_NAME },
 	{ SECCOMP_LOG_ERRNO, SECCOMP_RET_ERRNO_NAME },

commit 4d3b0b05aae9ee9ce0970dc4cc0fb3fad5e85945
Author: Kees Cook <keescook@chromium.org>
Date:   Fri Aug 11 13:01:39 2017 -0700

    seccomp: Introduce SECCOMP_RET_KILL_PROCESS
    
    This introduces the BPF return value for SECCOMP_RET_KILL_PROCESS to kill
    an entire process. This cannot yet be reached by seccomp, but it changes
    the default-kill behavior (for unknown return values) from kill-thread to
    kill-process.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 95ac54cff00f..5c7299b9d953 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -192,7 +192,7 @@ static u32 seccomp_run_filters(const struct seccomp_data *sd,
 
 	/* Ensure unexpected behavior doesn't result in failing open. */
 	if (unlikely(WARN_ON(f == NULL)))
-		return SECCOMP_RET_KILL_THREAD;
+		return SECCOMP_RET_KILL_PROCESS;
 
 	if (!sd) {
 		populate_seccomp_data(&sd_local);
@@ -529,14 +529,16 @@ static void seccomp_send_sigsys(int syscall, int reason)
 #endif	/* CONFIG_SECCOMP_FILTER */
 
 /* For use with seccomp_actions_logged */
-#define SECCOMP_LOG_KILL_THREAD		(1 << 0)
+#define SECCOMP_LOG_KILL_PROCESS	(1 << 0)
+#define SECCOMP_LOG_KILL_THREAD		(1 << 1)
 #define SECCOMP_LOG_TRAP		(1 << 2)
 #define SECCOMP_LOG_ERRNO		(1 << 3)
 #define SECCOMP_LOG_TRACE		(1 << 4)
 #define SECCOMP_LOG_LOG			(1 << 5)
 #define SECCOMP_LOG_ALLOW		(1 << 6)
 
-static u32 seccomp_actions_logged = SECCOMP_LOG_KILL_THREAD |
+static u32 seccomp_actions_logged = SECCOMP_LOG_KILL_PROCESS |
+				    SECCOMP_LOG_KILL_THREAD  |
 				    SECCOMP_LOG_TRAP  |
 				    SECCOMP_LOG_ERRNO |
 				    SECCOMP_LOG_TRACE |
@@ -563,8 +565,11 @@ static inline void seccomp_log(unsigned long syscall, long signr, u32 action,
 		log = seccomp_actions_logged & SECCOMP_LOG_LOG;
 		break;
 	case SECCOMP_RET_KILL_THREAD:
-	default:
 		log = seccomp_actions_logged & SECCOMP_LOG_KILL_THREAD;
+		break;
+	case SECCOMP_RET_KILL_PROCESS:
+	default:
+		log = seccomp_actions_logged & SECCOMP_LOG_KILL_PROCESS;
 	}
 
 	/*
@@ -719,10 +724,12 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 		return 0;
 
 	case SECCOMP_RET_KILL_THREAD:
+	case SECCOMP_RET_KILL_PROCESS:
 	default:
 		seccomp_log(this_syscall, SIGSYS, action, true);
 		/* Dump core only if this is the last remaining thread. */
-		if (get_nr_threads(current) == 1) {
+		if (action == SECCOMP_RET_KILL_PROCESS ||
+		    get_nr_threads(current) == 1) {
 			siginfo_t info;
 
 			/* Show the original registers in the dump. */
@@ -731,7 +738,10 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 			seccomp_init_siginfo(&info, this_syscall, data);
 			do_coredump(&info);
 		}
-		do_exit(SIGSYS);
+		if (action == SECCOMP_RET_KILL_PROCESS)
+			do_group_exit(SIGSYS);
+		else
+			do_exit(SIGSYS);
 	}
 
 	unreachable();

commit fd76875ca289a3d4722f266fd2d5532a27083903
Author: Kees Cook <keescook@chromium.org>
Date:   Fri Aug 11 12:53:18 2017 -0700

    seccomp: Rename SECCOMP_RET_KILL to SECCOMP_RET_KILL_THREAD
    
    In preparation for adding SECCOMP_RET_KILL_PROCESS, rename SECCOMP_RET_KILL
    to the more accurate SECCOMP_RET_KILL_THREAD.
    
    The existing selftest values are intentionally left as SECCOMP_RET_KILL
    just to be sure we're exercising the alias.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 59cde2ed3b92..95ac54cff00f 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -192,7 +192,7 @@ static u32 seccomp_run_filters(const struct seccomp_data *sd,
 
 	/* Ensure unexpected behavior doesn't result in failing open. */
 	if (unlikely(WARN_ON(f == NULL)))
-		return SECCOMP_RET_KILL;
+		return SECCOMP_RET_KILL_THREAD;
 
 	if (!sd) {
 		populate_seccomp_data(&sd_local);
@@ -529,15 +529,17 @@ static void seccomp_send_sigsys(int syscall, int reason)
 #endif	/* CONFIG_SECCOMP_FILTER */
 
 /* For use with seccomp_actions_logged */
-#define SECCOMP_LOG_KILL		(1 << 0)
+#define SECCOMP_LOG_KILL_THREAD		(1 << 0)
 #define SECCOMP_LOG_TRAP		(1 << 2)
 #define SECCOMP_LOG_ERRNO		(1 << 3)
 #define SECCOMP_LOG_TRACE		(1 << 4)
 #define SECCOMP_LOG_LOG			(1 << 5)
 #define SECCOMP_LOG_ALLOW		(1 << 6)
 
-static u32 seccomp_actions_logged = SECCOMP_LOG_KILL  | SECCOMP_LOG_TRAP  |
-				    SECCOMP_LOG_ERRNO | SECCOMP_LOG_TRACE |
+static u32 seccomp_actions_logged = SECCOMP_LOG_KILL_THREAD |
+				    SECCOMP_LOG_TRAP  |
+				    SECCOMP_LOG_ERRNO |
+				    SECCOMP_LOG_TRACE |
 				    SECCOMP_LOG_LOG;
 
 static inline void seccomp_log(unsigned long syscall, long signr, u32 action,
@@ -560,13 +562,13 @@ static inline void seccomp_log(unsigned long syscall, long signr, u32 action,
 	case SECCOMP_RET_LOG:
 		log = seccomp_actions_logged & SECCOMP_LOG_LOG;
 		break;
-	case SECCOMP_RET_KILL:
+	case SECCOMP_RET_KILL_THREAD:
 	default:
-		log = seccomp_actions_logged & SECCOMP_LOG_KILL;
+		log = seccomp_actions_logged & SECCOMP_LOG_KILL_THREAD;
 	}
 
 	/*
-	 * Force an audit message to be emitted when the action is RET_KILL,
+	 * Force an audit message to be emitted when the action is RET_KILL_*,
 	 * RET_LOG, or the FILTER_FLAG_LOG bit was set and the action is
 	 * allowed to be logged by the admin.
 	 */
@@ -605,7 +607,7 @@ static void __secure_computing_strict(int this_syscall)
 #ifdef SECCOMP_DEBUG
 	dump_stack();
 #endif
-	seccomp_log(this_syscall, SIGKILL, SECCOMP_RET_KILL, true);
+	seccomp_log(this_syscall, SIGKILL, SECCOMP_RET_KILL_THREAD, true);
 	do_exit(SIGKILL);
 }
 
@@ -716,7 +718,7 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 		 */
 		return 0;
 
-	case SECCOMP_RET_KILL:
+	case SECCOMP_RET_KILL_THREAD:
 	default:
 		seccomp_log(this_syscall, SIGSYS, action, true);
 		/* Dump core only if this is the last remaining thread. */
@@ -878,7 +880,7 @@ static long seccomp_get_action_avail(const char __user *uaction)
 		return -EFAULT;
 
 	switch (action) {
-	case SECCOMP_RET_KILL:
+	case SECCOMP_RET_KILL_THREAD:
 	case SECCOMP_RET_TRAP:
 	case SECCOMP_RET_ERRNO:
 	case SECCOMP_RET_TRACE:
@@ -1029,19 +1031,20 @@ long seccomp_get_filter(struct task_struct *task, unsigned long filter_off,
 #ifdef CONFIG_SYSCTL
 
 /* Human readable action names for friendly sysctl interaction */
-#define SECCOMP_RET_KILL_NAME		"kill"
+#define SECCOMP_RET_KILL_THREAD_NAME	"kill_thread"
 #define SECCOMP_RET_TRAP_NAME		"trap"
 #define SECCOMP_RET_ERRNO_NAME		"errno"
 #define SECCOMP_RET_TRACE_NAME		"trace"
 #define SECCOMP_RET_LOG_NAME		"log"
 #define SECCOMP_RET_ALLOW_NAME		"allow"
 
-static const char seccomp_actions_avail[] = SECCOMP_RET_KILL_NAME	" "
-					    SECCOMP_RET_TRAP_NAME	" "
-					    SECCOMP_RET_ERRNO_NAME	" "
-					    SECCOMP_RET_TRACE_NAME	" "
-					    SECCOMP_RET_LOG_NAME	" "
-					    SECCOMP_RET_ALLOW_NAME;
+static const char seccomp_actions_avail[] =
+				SECCOMP_RET_KILL_THREAD_NAME	" "
+				SECCOMP_RET_TRAP_NAME		" "
+				SECCOMP_RET_ERRNO_NAME		" "
+				SECCOMP_RET_TRACE_NAME		" "
+				SECCOMP_RET_LOG_NAME		" "
+				SECCOMP_RET_ALLOW_NAME;
 
 struct seccomp_log_name {
 	u32		log;
@@ -1049,7 +1052,7 @@ struct seccomp_log_name {
 };
 
 static const struct seccomp_log_name seccomp_log_names[] = {
-	{ SECCOMP_LOG_KILL, SECCOMP_RET_KILL_NAME },
+	{ SECCOMP_LOG_KILL_THREAD, SECCOMP_RET_KILL_THREAD_NAME },
 	{ SECCOMP_LOG_TRAP, SECCOMP_RET_TRAP_NAME },
 	{ SECCOMP_LOG_ERRNO, SECCOMP_RET_ERRNO_NAME },
 	{ SECCOMP_LOG_TRACE, SECCOMP_RET_TRACE_NAME },

commit 59f5cf44a38284eb9e76270c786fb6cc62ef8ac4
Author: Tyler Hicks <tyhicks@canonical.com>
Date:   Fri Aug 11 04:33:57 2017 +0000

    seccomp: Action to log before allowing
    
    Add a new action, SECCOMP_RET_LOG, that logs a syscall before allowing
    the syscall. At the implementation level, this action is identical to
    the existing SECCOMP_RET_ALLOW action. However, it can be very useful when
    initially developing a seccomp filter for an application. The developer
    can set the default action to be SECCOMP_RET_LOG, maybe mark any
    obviously needed syscalls with SECCOMP_RET_ALLOW, and then put the
    application through its paces. A list of syscalls that triggered the
    default action (SECCOMP_RET_LOG) can be easily gleaned from the logs and
    that list can be used to build the syscall whitelist. Finally, the
    developer can change the default action to the desired value.
    
    This provides a more friendly experience than seeing the application get
    killed, then updating the filter and rebuilding the app, seeing the
    application get killed due to a different syscall, then updating the
    filter and rebuilding the app, etc.
    
    The functionality is similar to what's supported by the various LSMs.
    SELinux has permissive mode, AppArmor has complain mode, SMACK has
    bring-up mode, etc.
    
    SECCOMP_RET_LOG is given a lower value than SECCOMP_RET_ALLOW as allow
    while logging is slightly more restrictive than quietly allowing.
    
    Unfortunately, the tests added for SECCOMP_RET_LOG are not capable of
    inspecting the audit log to verify that the syscall was logged.
    
    With this patch, the logic for deciding if an action will be logged is:
    
    if action == RET_ALLOW:
      do not log
    else if action == RET_KILL && RET_KILL in actions_logged:
      log
    else if action == RET_LOG && RET_LOG in actions_logged:
      log
    else if filter-requests-logging && action in actions_logged:
      log
    else if audit_enabled && process-is-being-audited:
      log
    else:
      do not log
    
    Signed-off-by: Tyler Hicks <tyhicks@canonical.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index ed9fde418fc4..59cde2ed3b92 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -533,10 +533,12 @@ static void seccomp_send_sigsys(int syscall, int reason)
 #define SECCOMP_LOG_TRAP		(1 << 2)
 #define SECCOMP_LOG_ERRNO		(1 << 3)
 #define SECCOMP_LOG_TRACE		(1 << 4)
-#define SECCOMP_LOG_ALLOW		(1 << 5)
+#define SECCOMP_LOG_LOG			(1 << 5)
+#define SECCOMP_LOG_ALLOW		(1 << 6)
 
 static u32 seccomp_actions_logged = SECCOMP_LOG_KILL  | SECCOMP_LOG_TRAP  |
-				    SECCOMP_LOG_ERRNO | SECCOMP_LOG_TRACE;
+				    SECCOMP_LOG_ERRNO | SECCOMP_LOG_TRACE |
+				    SECCOMP_LOG_LOG;
 
 static inline void seccomp_log(unsigned long syscall, long signr, u32 action,
 			       bool requested)
@@ -555,15 +557,18 @@ static inline void seccomp_log(unsigned long syscall, long signr, u32 action,
 	case SECCOMP_RET_TRACE:
 		log = requested && seccomp_actions_logged & SECCOMP_LOG_TRACE;
 		break;
+	case SECCOMP_RET_LOG:
+		log = seccomp_actions_logged & SECCOMP_LOG_LOG;
+		break;
 	case SECCOMP_RET_KILL:
 	default:
 		log = seccomp_actions_logged & SECCOMP_LOG_KILL;
 	}
 
 	/*
-	 * Force an audit message to be emitted when the action is RET_KILL or
-	 * the FILTER_FLAG_LOG bit was set and the action is allowed to be
-	 * logged by the admin.
+	 * Force an audit message to be emitted when the action is RET_KILL,
+	 * RET_LOG, or the FILTER_FLAG_LOG bit was set and the action is
+	 * allowed to be logged by the admin.
 	 */
 	if (log)
 		return __audit_seccomp(syscall, signr, action);
@@ -699,6 +704,10 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 
 		return 0;
 
+	case SECCOMP_RET_LOG:
+		seccomp_log(this_syscall, 0, action, true);
+		return 0;
+
 	case SECCOMP_RET_ALLOW:
 		/*
 		 * Note that the "match" filter will always be NULL for
@@ -873,6 +882,7 @@ static long seccomp_get_action_avail(const char __user *uaction)
 	case SECCOMP_RET_TRAP:
 	case SECCOMP_RET_ERRNO:
 	case SECCOMP_RET_TRACE:
+	case SECCOMP_RET_LOG:
 	case SECCOMP_RET_ALLOW:
 		break;
 	default:
@@ -1023,12 +1033,14 @@ long seccomp_get_filter(struct task_struct *task, unsigned long filter_off,
 #define SECCOMP_RET_TRAP_NAME		"trap"
 #define SECCOMP_RET_ERRNO_NAME		"errno"
 #define SECCOMP_RET_TRACE_NAME		"trace"
+#define SECCOMP_RET_LOG_NAME		"log"
 #define SECCOMP_RET_ALLOW_NAME		"allow"
 
 static const char seccomp_actions_avail[] = SECCOMP_RET_KILL_NAME	" "
 					    SECCOMP_RET_TRAP_NAME	" "
 					    SECCOMP_RET_ERRNO_NAME	" "
 					    SECCOMP_RET_TRACE_NAME	" "
+					    SECCOMP_RET_LOG_NAME	" "
 					    SECCOMP_RET_ALLOW_NAME;
 
 struct seccomp_log_name {
@@ -1041,6 +1053,7 @@ static const struct seccomp_log_name seccomp_log_names[] = {
 	{ SECCOMP_LOG_TRAP, SECCOMP_RET_TRAP_NAME },
 	{ SECCOMP_LOG_ERRNO, SECCOMP_RET_ERRNO_NAME },
 	{ SECCOMP_LOG_TRACE, SECCOMP_RET_TRACE_NAME },
+	{ SECCOMP_LOG_LOG, SECCOMP_RET_LOG_NAME },
 	{ SECCOMP_LOG_ALLOW, SECCOMP_RET_ALLOW_NAME },
 	{ }
 };

commit e66a39977985b1e69e17c4042cb290768eca9b02
Author: Tyler Hicks <tyhicks@canonical.com>
Date:   Fri Aug 11 04:33:56 2017 +0000

    seccomp: Filter flag to log all actions except SECCOMP_RET_ALLOW
    
    Add a new filter flag, SECCOMP_FILTER_FLAG_LOG, that enables logging for
    all actions except for SECCOMP_RET_ALLOW for the given filter.
    
    SECCOMP_RET_KILL actions are always logged, when "kill" is in the
    actions_logged sysctl, and SECCOMP_RET_ALLOW actions are never logged,
    regardless of this flag.
    
    This flag can be used to create noisy filters that result in all
    non-allowed actions to be logged. A process may have one noisy filter,
    which is loaded with this flag, as well as a quiet filter that's not
    loaded with this flag. This allows for the actions in a set of filters
    to be selectively conveyed to the admin.
    
    Since a system could have a large number of allocated seccomp_filter
    structs, struct packing was taken in consideration. On 64 bit x86, the
    new log member takes up one byte of an existing four byte hole in the
    struct. On 32 bit x86, the new log member creates a new four byte hole
    (unavoidable) and consumes one of those bytes.
    
    Unfortunately, the tests added for SECCOMP_FILTER_FLAG_LOG are not
    capable of inspecting the audit log to verify that the actions taken in
    the filter were logged.
    
    With this patch, the logic for deciding if an action will be logged is:
    
    if action == RET_ALLOW:
      do not log
    else if action == RET_KILL && RET_KILL in actions_logged:
      log
    else if filter-requests-logging && action in actions_logged:
      log
    else if audit_enabled && process-is-being-audited:
      log
    else:
      do not log
    
    Signed-off-by: Tyler Hicks <tyhicks@canonical.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 54357e361aea..ed9fde418fc4 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -44,6 +44,7 @@
  *         get/put helpers should be used when accessing an instance
  *         outside of a lifetime-guarded section.  In general, this
  *         is only needed for handling filters shared across tasks.
+ * @log: true if all actions except for SECCOMP_RET_ALLOW should be logged
  * @prev: points to a previously installed, or inherited, filter
  * @prog: the BPF program to evaluate
  *
@@ -59,6 +60,7 @@
  */
 struct seccomp_filter {
 	refcount_t usage;
+	bool log;
 	struct seccomp_filter *prev;
 	struct bpf_prog *prog;
 };
@@ -452,6 +454,10 @@ static long seccomp_attach_filter(unsigned int flags,
 			return ret;
 	}
 
+	/* Set log flag, if present. */
+	if (flags & SECCOMP_FILTER_FLAG_LOG)
+		filter->log = true;
+
 	/*
 	 * If there is an existing filter, make it the prev and don't drop its
 	 * task reference.
@@ -532,15 +538,22 @@ static void seccomp_send_sigsys(int syscall, int reason)
 static u32 seccomp_actions_logged = SECCOMP_LOG_KILL  | SECCOMP_LOG_TRAP  |
 				    SECCOMP_LOG_ERRNO | SECCOMP_LOG_TRACE;
 
-static inline void seccomp_log(unsigned long syscall, long signr, u32 action)
+static inline void seccomp_log(unsigned long syscall, long signr, u32 action,
+			       bool requested)
 {
 	bool log = false;
 
 	switch (action) {
 	case SECCOMP_RET_ALLOW:
+		break;
 	case SECCOMP_RET_TRAP:
+		log = requested && seccomp_actions_logged & SECCOMP_LOG_TRAP;
+		break;
 	case SECCOMP_RET_ERRNO:
+		log = requested && seccomp_actions_logged & SECCOMP_LOG_ERRNO;
+		break;
 	case SECCOMP_RET_TRACE:
+		log = requested && seccomp_actions_logged & SECCOMP_LOG_TRACE;
 		break;
 	case SECCOMP_RET_KILL:
 	default:
@@ -548,8 +561,9 @@ static inline void seccomp_log(unsigned long syscall, long signr, u32 action)
 	}
 
 	/*
-	 * Force an audit message to be emitted when the action is RET_KILL and
-	 * the action is allowed to be logged by the admin.
+	 * Force an audit message to be emitted when the action is RET_KILL or
+	 * the FILTER_FLAG_LOG bit was set and the action is allowed to be
+	 * logged by the admin.
 	 */
 	if (log)
 		return __audit_seccomp(syscall, signr, action);
@@ -586,7 +600,7 @@ static void __secure_computing_strict(int this_syscall)
 #ifdef SECCOMP_DEBUG
 	dump_stack();
 #endif
-	seccomp_log(this_syscall, SIGKILL, SECCOMP_RET_KILL);
+	seccomp_log(this_syscall, SIGKILL, SECCOMP_RET_KILL, true);
 	do_exit(SIGKILL);
 }
 
@@ -695,7 +709,7 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 
 	case SECCOMP_RET_KILL:
 	default:
-		seccomp_log(this_syscall, SIGSYS, action);
+		seccomp_log(this_syscall, SIGSYS, action, true);
 		/* Dump core only if this is the last remaining thread. */
 		if (get_nr_threads(current) == 1) {
 			siginfo_t info;
@@ -712,7 +726,7 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 	unreachable();
 
 skip:
-	seccomp_log(this_syscall, 0, action);
+	seccomp_log(this_syscall, 0, action, match ? match->log : false);
 	return -1;
 }
 #else

commit 0ddec0fc8900201c0897b87b762b7c420436662f
Author: Tyler Hicks <tyhicks@canonical.com>
Date:   Fri Aug 11 04:33:54 2017 +0000

    seccomp: Sysctl to configure actions that are allowed to be logged
    
    Adminstrators can write to this sysctl to set the seccomp actions that
    are allowed to be logged. Any actions not found in this sysctl will not
    be logged.
    
    For example, all SECCOMP_RET_KILL, SECCOMP_RET_TRAP, and
    SECCOMP_RET_ERRNO actions would be loggable if "kill trap errno" were
    written to the sysctl. SECCOMP_RET_TRACE actions would not be logged
    since its string representation ("trace") wasn't present in the sysctl
    value.
    
    The path to the sysctl is:
    
     /proc/sys/kernel/seccomp/actions_logged
    
    The actions_avail sysctl can be read to discover the valid action names
    that can be written to the actions_logged sysctl with the exception of
    "allow". SECCOMP_RET_ALLOW actions cannot be configured for logging.
    
    The default setting for the sysctl is to allow all actions to be logged
    except SECCOMP_RET_ALLOW. While only SECCOMP_RET_KILL actions are
    currently logged, an upcoming patch will allow applications to request
    additional actions to be logged.
    
    There's one important exception to this sysctl. If a task is
    specifically being audited, meaning that an audit context has been
    allocated for the task, seccomp will log all actions other than
    SECCOMP_RET_ALLOW despite the value of actions_logged. This exception
    preserves the existing auditing behavior of tasks with an allocated
    audit context.
    
    With this patch, the logic for deciding if an action will be logged is:
    
    if action == RET_ALLOW:
      do not log
    else if action == RET_KILL && RET_KILL in actions_logged:
      log
    else if audit_enabled && task-is-being-audited:
      log
    else:
      do not log
    
    Signed-off-by: Tyler Hicks <tyhicks@canonical.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 7a6089f66fed..54357e361aea 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -522,6 +522,45 @@ static void seccomp_send_sigsys(int syscall, int reason)
 }
 #endif	/* CONFIG_SECCOMP_FILTER */
 
+/* For use with seccomp_actions_logged */
+#define SECCOMP_LOG_KILL		(1 << 0)
+#define SECCOMP_LOG_TRAP		(1 << 2)
+#define SECCOMP_LOG_ERRNO		(1 << 3)
+#define SECCOMP_LOG_TRACE		(1 << 4)
+#define SECCOMP_LOG_ALLOW		(1 << 5)
+
+static u32 seccomp_actions_logged = SECCOMP_LOG_KILL  | SECCOMP_LOG_TRAP  |
+				    SECCOMP_LOG_ERRNO | SECCOMP_LOG_TRACE;
+
+static inline void seccomp_log(unsigned long syscall, long signr, u32 action)
+{
+	bool log = false;
+
+	switch (action) {
+	case SECCOMP_RET_ALLOW:
+	case SECCOMP_RET_TRAP:
+	case SECCOMP_RET_ERRNO:
+	case SECCOMP_RET_TRACE:
+		break;
+	case SECCOMP_RET_KILL:
+	default:
+		log = seccomp_actions_logged & SECCOMP_LOG_KILL;
+	}
+
+	/*
+	 * Force an audit message to be emitted when the action is RET_KILL and
+	 * the action is allowed to be logged by the admin.
+	 */
+	if (log)
+		return __audit_seccomp(syscall, signr, action);
+
+	/*
+	 * Let the audit subsystem decide if the action should be audited based
+	 * on whether the current task itself is being audited.
+	 */
+	return audit_seccomp(syscall, signr, action);
+}
+
 /*
  * Secure computing mode 1 allows only read/write/exit/sigreturn.
  * To be fully secure this must be combined with rlimit
@@ -547,7 +586,7 @@ static void __secure_computing_strict(int this_syscall)
 #ifdef SECCOMP_DEBUG
 	dump_stack();
 #endif
-	audit_seccomp(this_syscall, SIGKILL, SECCOMP_RET_KILL);
+	seccomp_log(this_syscall, SIGKILL, SECCOMP_RET_KILL);
 	do_exit(SIGKILL);
 }
 
@@ -656,7 +695,7 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 
 	case SECCOMP_RET_KILL:
 	default:
-		audit_seccomp(this_syscall, SIGSYS, action);
+		seccomp_log(this_syscall, SIGSYS, action);
 		/* Dump core only if this is the last remaining thread. */
 		if (get_nr_threads(current) == 1) {
 			siginfo_t info;
@@ -673,7 +712,7 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 	unreachable();
 
 skip:
-	audit_seccomp(this_syscall, 0, action);
+	seccomp_log(this_syscall, 0, action);
 	return -1;
 }
 #else
@@ -978,6 +1017,127 @@ static const char seccomp_actions_avail[] = SECCOMP_RET_KILL_NAME	" "
 					    SECCOMP_RET_TRACE_NAME	" "
 					    SECCOMP_RET_ALLOW_NAME;
 
+struct seccomp_log_name {
+	u32		log;
+	const char	*name;
+};
+
+static const struct seccomp_log_name seccomp_log_names[] = {
+	{ SECCOMP_LOG_KILL, SECCOMP_RET_KILL_NAME },
+	{ SECCOMP_LOG_TRAP, SECCOMP_RET_TRAP_NAME },
+	{ SECCOMP_LOG_ERRNO, SECCOMP_RET_ERRNO_NAME },
+	{ SECCOMP_LOG_TRACE, SECCOMP_RET_TRACE_NAME },
+	{ SECCOMP_LOG_ALLOW, SECCOMP_RET_ALLOW_NAME },
+	{ }
+};
+
+static bool seccomp_names_from_actions_logged(char *names, size_t size,
+					      u32 actions_logged)
+{
+	const struct seccomp_log_name *cur;
+	bool append_space = false;
+
+	for (cur = seccomp_log_names; cur->name && size; cur++) {
+		ssize_t ret;
+
+		if (!(actions_logged & cur->log))
+			continue;
+
+		if (append_space) {
+			ret = strscpy(names, " ", size);
+			if (ret < 0)
+				return false;
+
+			names += ret;
+			size -= ret;
+		} else
+			append_space = true;
+
+		ret = strscpy(names, cur->name, size);
+		if (ret < 0)
+			return false;
+
+		names += ret;
+		size -= ret;
+	}
+
+	return true;
+}
+
+static bool seccomp_action_logged_from_name(u32 *action_logged,
+					    const char *name)
+{
+	const struct seccomp_log_name *cur;
+
+	for (cur = seccomp_log_names; cur->name; cur++) {
+		if (!strcmp(cur->name, name)) {
+			*action_logged = cur->log;
+			return true;
+		}
+	}
+
+	return false;
+}
+
+static bool seccomp_actions_logged_from_names(u32 *actions_logged, char *names)
+{
+	char *name;
+
+	*actions_logged = 0;
+	while ((name = strsep(&names, " ")) && *name) {
+		u32 action_logged = 0;
+
+		if (!seccomp_action_logged_from_name(&action_logged, name))
+			return false;
+
+		*actions_logged |= action_logged;
+	}
+
+	return true;
+}
+
+static int seccomp_actions_logged_handler(struct ctl_table *ro_table, int write,
+					  void __user *buffer, size_t *lenp,
+					  loff_t *ppos)
+{
+	char names[sizeof(seccomp_actions_avail)];
+	struct ctl_table table;
+	int ret;
+
+	if (write && !capable(CAP_SYS_ADMIN))
+		return -EPERM;
+
+	memset(names, 0, sizeof(names));
+
+	if (!write) {
+		if (!seccomp_names_from_actions_logged(names, sizeof(names),
+						       seccomp_actions_logged))
+			return -EINVAL;
+	}
+
+	table = *ro_table;
+	table.data = names;
+	table.maxlen = sizeof(names);
+	ret = proc_dostring(&table, write, buffer, lenp, ppos);
+	if (ret)
+		return ret;
+
+	if (write) {
+		u32 actions_logged;
+
+		if (!seccomp_actions_logged_from_names(&actions_logged,
+						       table.data))
+			return -EINVAL;
+
+		if (actions_logged & SECCOMP_LOG_ALLOW)
+			return -EINVAL;
+
+		seccomp_actions_logged = actions_logged;
+	}
+
+	return 0;
+}
+
 static struct ctl_path seccomp_sysctl_path[] = {
 	{ .procname = "kernel", },
 	{ .procname = "seccomp", },
@@ -992,6 +1152,11 @@ static struct ctl_table seccomp_sysctl_table[] = {
 		.mode		= 0444,
 		.proc_handler	= proc_dostring,
 	},
+	{
+		.procname	= "actions_logged",
+		.mode		= 0644,
+		.proc_handler	= seccomp_actions_logged_handler,
+	},
 	{ }
 };
 

commit d612b1fd8010d0d67b5287fe146b8b55bcbb8655
Author: Tyler Hicks <tyhicks@canonical.com>
Date:   Fri Aug 11 04:33:53 2017 +0000

    seccomp: Operation for checking if an action is available
    
    Userspace code that needs to check if the kernel supports a given action
    may not be able to use the /proc/sys/kernel/seccomp/actions_avail
    sysctl. The process may be running in a sandbox and, therefore,
    sufficient filesystem access may not be available. This patch adds an
    operation to the seccomp(2) syscall that allows userspace code to ask
    the kernel if a given action is available.
    
    If the action is supported by the kernel, 0 is returned. If the action
    is not supported by the kernel, -1 is returned with errno set to
    -EOPNOTSUPP. If this check is attempted on a kernel that doesn't support
    this new operation, -1 is returned with errno set to -EINVAL meaning
    that userspace code will have the ability to differentiate between the
    two error cases.
    
    Signed-off-by: Tyler Hicks <tyhicks@canonical.com>
    Suggested-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 5f19f41e4e50..7a6089f66fed 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -808,6 +808,27 @@ static inline long seccomp_set_mode_filter(unsigned int flags,
 }
 #endif
 
+static long seccomp_get_action_avail(const char __user *uaction)
+{
+	u32 action;
+
+	if (copy_from_user(&action, uaction, sizeof(action)))
+		return -EFAULT;
+
+	switch (action) {
+	case SECCOMP_RET_KILL:
+	case SECCOMP_RET_TRAP:
+	case SECCOMP_RET_ERRNO:
+	case SECCOMP_RET_TRACE:
+	case SECCOMP_RET_ALLOW:
+		break;
+	default:
+		return -EOPNOTSUPP;
+	}
+
+	return 0;
+}
+
 /* Common entry point for both prctl and syscall. */
 static long do_seccomp(unsigned int op, unsigned int flags,
 		       const char __user *uargs)
@@ -819,6 +840,11 @@ static long do_seccomp(unsigned int op, unsigned int flags,
 		return seccomp_set_mode_strict();
 	case SECCOMP_SET_MODE_FILTER:
 		return seccomp_set_mode_filter(flags, uargs);
+	case SECCOMP_GET_ACTION_AVAIL:
+		if (flags != 0)
+			return -EINVAL;
+
+		return seccomp_get_action_avail(uargs);
 	default:
 		return -EINVAL;
 	}

commit 8e5f1ad116df6b0de65eac458d5e7c318d1c05af
Author: Tyler Hicks <tyhicks@canonical.com>
Date:   Fri Aug 11 04:33:52 2017 +0000

    seccomp: Sysctl to display available actions
    
    This patch creates a read-only sysctl containing an ordered list of
    seccomp actions that the kernel supports. The ordering, from left to
    right, is the lowest action value (kill) to the highest action value
    (allow). Currently, a read of the sysctl file would return "kill trap
    errno trace allow". The contents of this sysctl file can be useful for
    userspace code as well as the system administrator.
    
    The path to the sysctl is:
    
      /proc/sys/kernel/seccomp/actions_avail
    
    libseccomp and other userspace code can easily determine which actions
    the current kernel supports. The set of actions supported by the current
    kernel may be different than the set of action macros found in kernel
    headers that were installed where the userspace code was built.
    
    In addition, this sysctl will allow system administrators to know which
    actions are supported by the kernel and make it easier to configure
    exactly what seccomp logs through the audit subsystem. Support for this
    level of logging configuration will come in a future patch.
    
    Signed-off-by: Tyler Hicks <tyhicks@canonical.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 1f3347fc2605..5f19f41e4e50 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -17,11 +17,13 @@
 #include <linux/audit.h>
 #include <linux/compat.h>
 #include <linux/coredump.h>
+#include <linux/kmemleak.h>
 #include <linux/sched.h>
 #include <linux/sched/task_stack.h>
 #include <linux/seccomp.h>
 #include <linux/slab.h>
 #include <linux/syscalls.h>
+#include <linux/sysctl.h>
 
 #ifdef CONFIG_HAVE_ARCH_SECCOMP_FILTER
 #include <asm/syscall.h>
@@ -934,3 +936,52 @@ long seccomp_get_filter(struct task_struct *task, unsigned long filter_off,
 	return ret;
 }
 #endif
+
+#ifdef CONFIG_SYSCTL
+
+/* Human readable action names for friendly sysctl interaction */
+#define SECCOMP_RET_KILL_NAME		"kill"
+#define SECCOMP_RET_TRAP_NAME		"trap"
+#define SECCOMP_RET_ERRNO_NAME		"errno"
+#define SECCOMP_RET_TRACE_NAME		"trace"
+#define SECCOMP_RET_ALLOW_NAME		"allow"
+
+static const char seccomp_actions_avail[] = SECCOMP_RET_KILL_NAME	" "
+					    SECCOMP_RET_TRAP_NAME	" "
+					    SECCOMP_RET_ERRNO_NAME	" "
+					    SECCOMP_RET_TRACE_NAME	" "
+					    SECCOMP_RET_ALLOW_NAME;
+
+static struct ctl_path seccomp_sysctl_path[] = {
+	{ .procname = "kernel", },
+	{ .procname = "seccomp", },
+	{ }
+};
+
+static struct ctl_table seccomp_sysctl_table[] = {
+	{
+		.procname	= "actions_avail",
+		.data		= (void *) &seccomp_actions_avail,
+		.maxlen		= sizeof(seccomp_actions_avail),
+		.mode		= 0444,
+		.proc_handler	= proc_dostring,
+	},
+	{ }
+};
+
+static int __init seccomp_sysctl_init(void)
+{
+	struct ctl_table_header *hdr;
+
+	hdr = register_sysctl_paths(seccomp_sysctl_path, seccomp_sysctl_table);
+	if (!hdr)
+		pr_warn("seccomp: sysctl registration failed\n");
+	else
+		kmemleak_not_leak(hdr);
+
+	return 0;
+}
+
+device_initcall(seccomp_sysctl_init)
+
+#endif /* CONFIG_SYSCTL */

commit deb4de8b31bc5bf21efb6ac31150a01a631cd647
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Aug 2 15:00:40 2017 -0700

    seccomp: Provide matching filter for introspection
    
    Both the upcoming logging improvements and changes to RET_KILL will need
    to know which filter a given seccomp return value originated from. In
    order to delay logic processing of result until after the seccomp loop,
    this adds a single pointer assignment on matches. This will allow both
    log and RET_KILL logic to work off the filter rather than doing more
    expensive tests inside the time-critical run_filters loop.
    
    Running tight cycles of getpid() with filters attached shows no measurable
    difference in speed.
    
    Suggested-by: Tyler Hicks <tyhicks@canonical.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Tyler Hicks <tyhicks@canonical.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 98b59b5db90b..1f3347fc2605 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -171,10 +171,14 @@ static int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)
 /**
  * seccomp_run_filters - evaluates all seccomp filters against @sd
  * @sd: optional seccomp data to be passed to filters
+ * @match: stores struct seccomp_filter that resulted in the return value,
+ *         unless filter returned SECCOMP_RET_ALLOW, in which case it will
+ *         be unchanged.
  *
  * Returns valid seccomp BPF response codes.
  */
-static u32 seccomp_run_filters(const struct seccomp_data *sd)
+static u32 seccomp_run_filters(const struct seccomp_data *sd,
+			       struct seccomp_filter **match)
 {
 	struct seccomp_data sd_local;
 	u32 ret = SECCOMP_RET_ALLOW;
@@ -198,8 +202,10 @@ static u32 seccomp_run_filters(const struct seccomp_data *sd)
 	for (; f; f = f->prev) {
 		u32 cur_ret = BPF_PROG_RUN(f->prog, sd);
 
-		if ((cur_ret & SECCOMP_RET_ACTION) < (ret & SECCOMP_RET_ACTION))
+		if ((cur_ret & SECCOMP_RET_ACTION) < (ret & SECCOMP_RET_ACTION)) {
 			ret = cur_ret;
+			*match = f;
+		}
 	}
 	return ret;
 }
@@ -566,6 +572,7 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 			    const bool recheck_after_trace)
 {
 	u32 filter_ret, action;
+	struct seccomp_filter *match = NULL;
 	int data;
 
 	/*
@@ -574,7 +581,7 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 	 */
 	rmb();
 
-	filter_ret = seccomp_run_filters(sd);
+	filter_ret = seccomp_run_filters(sd, &match);
 	data = filter_ret & SECCOMP_RET_DATA;
 	action = filter_ret & SECCOMP_RET_ACTION;
 
@@ -638,6 +645,11 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 		return 0;
 
 	case SECCOMP_RET_ALLOW:
+		/*
+		 * Note that the "match" filter will always be NULL for
+		 * this action since SECCOMP_RET_ALLOW is the starting
+		 * state in seccomp_run_filters().
+		 */
 		return 0;
 
 	case SECCOMP_RET_KILL:

commit 0b5fa2290637a3235898d18dc0e7a136783f1bd2
Author: Kees Cook <keescook@chromium.org>
Date:   Mon Jun 26 09:24:00 2017 -0700

    seccomp: Switch from atomic_t to recount_t
    
    This switches the seccomp usage tracking from atomic_t to refcount_t to
    gain refcount overflow protections.
    
    Cc: Elena Reshetova <elena.reshetova@intel.com>
    Cc: David Windsor <dwindsor@gmail.com>
    Cc: Hans Liljestrand <hans.liljestrand@aalto.fi>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index fce83885b7ef..98b59b5db90b 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -13,7 +13,7 @@
  *        of Berkeley Packet Filters/Linux Socket Filters.
  */
 
-#include <linux/atomic.h>
+#include <linux/refcount.h>
 #include <linux/audit.h>
 #include <linux/compat.h>
 #include <linux/coredump.h>
@@ -56,7 +56,7 @@
  * to a task_struct (other than @usage).
  */
 struct seccomp_filter {
-	atomic_t usage;
+	refcount_t usage;
 	struct seccomp_filter *prev;
 	struct bpf_prog *prog;
 };
@@ -378,7 +378,7 @@ static struct seccomp_filter *seccomp_prepare_filter(struct sock_fprog *fprog)
 		return ERR_PTR(ret);
 	}
 
-	atomic_set(&sfilter->usage, 1);
+	refcount_set(&sfilter->usage, 1);
 
 	return sfilter;
 }
@@ -465,7 +465,7 @@ void get_seccomp_filter(struct task_struct *tsk)
 	if (!orig)
 		return;
 	/* Reference count is bounded by the number of total processes. */
-	atomic_inc(&orig->usage);
+	refcount_inc(&orig->usage);
 }
 
 static inline void seccomp_filter_free(struct seccomp_filter *filter)
@@ -481,7 +481,7 @@ void put_seccomp_filter(struct task_struct *tsk)
 {
 	struct seccomp_filter *orig = tsk->seccomp.filter;
 	/* Clean up single-reference branches iteratively. */
-	while (orig && atomic_dec_and_test(&orig->usage)) {
+	while (orig && refcount_dec_and_test(&orig->usage)) {
 		struct seccomp_filter *freeme = orig;
 		orig = orig->prev;
 		seccomp_filter_free(freeme);

commit 131b63515932d18a3b1a60db3958f3c0dd5462bc
Author: Kees Cook <keescook@chromium.org>
Date:   Thu Feb 23 09:24:24 2017 -0800

    seccomp: Clean up core dump logic
    
    This just cleans up the core dumping logic to avoid the braces around
    the RET_KILL case.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 65f61077ad50..fce83885b7ef 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -641,11 +641,12 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 		return 0;
 
 	case SECCOMP_RET_KILL:
-	default: {
-		siginfo_t info;
+	default:
 		audit_seccomp(this_syscall, SIGSYS, action);
 		/* Dump core only if this is the last remaining thread. */
 		if (get_nr_threads(current) == 1) {
+			siginfo_t info;
+
 			/* Show the original registers in the dump. */
 			syscall_rollback(current, task_pt_regs(current));
 			/* Trigger a manual coredump since do_exit skips it. */
@@ -654,7 +655,6 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 		}
 		do_exit(SIGSYS);
 	}
-	}
 
 	unreachable();
 

commit 68db0cf10678630d286f4bbbbdfa102951a35faa
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:37 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/task_stack.h>
    
    We are going to split <linux/sched/task_stack.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/task_stack.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index e15185c28de5..65f61077ad50 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -18,6 +18,7 @@
 #include <linux/compat.h>
 #include <linux/coredump.h>
 #include <linux/sched.h>
+#include <linux/sched/task_stack.h>
 #include <linux/seccomp.h>
 #include <linux/slab.h>
 #include <linux/syscalls.h>

commit d7276e321ff8a53106a59c85ca46d03e34288893
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Feb 7 15:18:51 2017 -0800

    seccomp: Only dump core when single-threaded
    
    The SECCOMP_RET_KILL filter return code has always killed the current
    thread, not the entire process. Changing this as a side-effect of dumping
    core isn't a safe thing to do (a few test suites have already flagged this
    behavioral change). Instead, restore the RET_KILL semantics, but still
    dump core when a RET_KILL delivers SIGSYS to a single-threaded process.
    
    Fixes: b25e67161c29 ("seccomp: dump core when using SECCOMP_RET_KILL")
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Acked-by: Andrei Vagin <avagin@virtuozzo.com>
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index f8f88ebcb3ba..e15185c28de5 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -643,11 +643,14 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 	default: {
 		siginfo_t info;
 		audit_seccomp(this_syscall, SIGSYS, action);
-		/* Show the original registers in the dump. */
-		syscall_rollback(current, task_pt_regs(current));
-		/* Trigger a manual coredump since do_exit skips it. */
-		seccomp_init_siginfo(&info, this_syscall, data);
-		do_coredump(&info);
+		/* Dump core only if this is the last remaining thread. */
+		if (get_nr_threads(current) == 1) {
+			/* Show the original registers in the dump. */
+			syscall_rollback(current, task_pt_regs(current));
+			/* Trigger a manual coredump since do_exit skips it. */
+			seccomp_init_siginfo(&info, this_syscall, data);
+			do_coredump(&info);
+		}
 		do_exit(SIGSYS);
 	}
 	}

commit b25e67161c295c98acda92123b2dd1e7d8642901
Author: Mike Frysinger <vapier@chromium.org>
Date:   Thu Jan 19 22:28:57 2017 -0600

    seccomp: dump core when using SECCOMP_RET_KILL
    
    The SECCOMP_RET_KILL mode is documented as immediately killing the
    process as if a SIGSYS had been sent and not caught (similar to a
    SIGKILL).  However, a SIGSYS is documented as triggering a coredump
    which does not happen today.
    
    This has the advantage of being able to more easily debug a process
    that fails a seccomp filter.  Today, most apps need to recompile and
    change their filter in order to get detailed info out, or manually run
    things through strace, or enable detailed kernel auditing.  Now we get
    coredumps that fit into existing system-wide crash reporting setups.
    
    From a security pov, this shouldn't be a problem.  Unhandled signals
    can already be sent externally which trigger a coredump independent of
    the status of the seccomp filter.  The act of dumping core itself does
    not cause change in execution of the program.
    
    URL: https://crbug.com/676357
    Signed-off-by: Mike Frysinger <vapier@chromium.org>
    Acked-by: Jorge Lucangeli Obes <jorgelo@chromium.org>
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index f7ce79a46050..f8f88ebcb3ba 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -16,6 +16,7 @@
 #include <linux/atomic.h>
 #include <linux/audit.h>
 #include <linux/compat.h>
+#include <linux/coredump.h>
 #include <linux/sched.h>
 #include <linux/seccomp.h>
 #include <linux/slab.h>
@@ -486,6 +487,17 @@ void put_seccomp_filter(struct task_struct *tsk)
 	}
 }
 
+static void seccomp_init_siginfo(siginfo_t *info, int syscall, int reason)
+{
+	memset(info, 0, sizeof(*info));
+	info->si_signo = SIGSYS;
+	info->si_code = SYS_SECCOMP;
+	info->si_call_addr = (void __user *)KSTK_EIP(current);
+	info->si_errno = reason;
+	info->si_arch = syscall_get_arch();
+	info->si_syscall = syscall;
+}
+
 /**
  * seccomp_send_sigsys - signals the task to allow in-process syscall emulation
  * @syscall: syscall number to send to userland
@@ -496,13 +508,7 @@ void put_seccomp_filter(struct task_struct *tsk)
 static void seccomp_send_sigsys(int syscall, int reason)
 {
 	struct siginfo info;
-	memset(&info, 0, sizeof(info));
-	info.si_signo = SIGSYS;
-	info.si_code = SYS_SECCOMP;
-	info.si_call_addr = (void __user *)KSTK_EIP(current);
-	info.si_errno = reason;
-	info.si_arch = syscall_get_arch();
-	info.si_syscall = syscall;
+	seccomp_init_siginfo(&info, syscall, reason);
 	force_sig_info(SIGSYS, &info, current);
 }
 #endif	/* CONFIG_SECCOMP_FILTER */
@@ -634,10 +640,17 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 		return 0;
 
 	case SECCOMP_RET_KILL:
-	default:
+	default: {
+		siginfo_t info;
 		audit_seccomp(this_syscall, SIGSYS, action);
+		/* Show the original registers in the dump. */
+		syscall_rollback(current, task_pt_regs(current));
+		/* Trigger a manual coredump since do_exit skips it. */
+		seccomp_init_siginfo(&info, this_syscall, data);
+		do_coredump(&info);
 		do_exit(SIGSYS);
 	}
+	}
 
 	unreachable();
 

commit 683b96f4d1d132fcefa4a0bd11916649800d7361
Merge: 0f1d6dfe03ca 50523a29d900
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Dec 14 13:57:44 2016 -0800

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security
    
    Pull security subsystem updates from James Morris:
     "Generally pretty quiet for this release. Highlights:
    
      Yama:
       - allow ptrace access for original parent after re-parenting
    
      TPM:
       - add documentation
       - many bugfixes & cleanups
       - define a generic open() method for ascii & bios measurements
    
      Integrity:
       - Harden against malformed xattrs
    
      SELinux:
       - bugfixes & cleanups
    
      Smack:
       - Remove unnecessary smack_known_invalid label
       - Do not apply star label in smack_setprocattr hook
       - parse mnt opts after privileges check (fixes unpriv DoS vuln)"
    
    * 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security: (56 commits)
      Yama: allow access for the current ptrace parent
      tpm: adjust return value of tpm_read_log
      tpm: vtpm_proxy: conditionally call tpm_chip_unregister
      tpm: Fix handling of missing event log
      tpm: Check the bios_dir entry for NULL before accessing it
      tpm: return -ENODEV if np is not set
      tpm: cleanup of printk error messages
      tpm: replace of_find_node_by_name() with dev of_node property
      tpm: redefine read_log() to handle ACPI/OF at runtime
      tpm: fix the missing .owner in tpm_bios_measurements_ops
      tpm: have event log use the tpm_chip
      tpm: drop tpm1_chip_register(/unregister)
      tpm: replace dynamically allocated bios_dir with a static array
      tpm: replace symbolic permission with octal for securityfs files
      char: tpm: fix kerneldoc tpm2_unseal_trusted name typo
      tpm_tis: Allow tpm_tis to be bound using DT
      tpm, tpm_vtpm_proxy: add kdoc comments for VTPM_PROXY_IOC_NEW_DEV
      tpm: Only call pm_runtime_get_sync if device has a parent
      tpm: define a generic open() method for ascii & bios measurements
      Documentation: tpm: add the Physical TPM device tree binding documentation
      ...

commit 88575199cc65de99a156888629a68180c830eff2
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Sat Nov 26 01:28:04 2016 +0100

    bpf: drop unnecessary context cast from BPF_PROG_RUN
    
    Since long already bpf_func is not only about struct sk_buff * as
    input anymore. Make it generic as void *, so that callers don't
    need to cast for it each time they call BPF_PROG_RUN().
    
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 0db7c8a2afe2..bff9c774987a 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -195,7 +195,7 @@ static u32 seccomp_run_filters(const struct seccomp_data *sd)
 	 * value always takes priority (ignoring the DATA).
 	 */
 	for (; f; f = f->prev) {
-		u32 cur_ret = BPF_PROG_RUN(f->prog, (void *)sd);
+		u32 cur_ret = BPF_PROG_RUN(f->prog, sd);
 
 		if ((cur_ret & SECCOMP_RET_ACTION) < (ret & SECCOMP_RET_ACTION))
 			ret = cur_ret;

commit 285fdfc5d9959a2104021b6bbdec39b8c26e99ef
Author: Mickal Salan <mic@digikod.net>
Date:   Tue Sep 20 19:39:47 2016 +0200

    seccomp: Fix documentation
    
    Fix struct seccomp_filter and seccomp_run_filters() signatures.
    
    Signed-off-by: Mickal Salan <mic@digikod.net>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: James Morris <jmorris@namei.org>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Will Drewry <wad@chromium.org>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 0db7c8a2afe2..494cba230ca0 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -41,8 +41,7 @@
  *         outside of a lifetime-guarded section.  In general, this
  *         is only needed for handling filters shared across tasks.
  * @prev: points to a previously installed, or inherited, filter
- * @len: the number of instructions in the program
- * @insnsi: the BPF program instructions to evaluate
+ * @prog: the BPF program to evaluate
  *
  * seccomp_filter objects are organized in a tree linked via the @prev
  * pointer.  For any task, it appears to be a singly-linked list starting
@@ -168,8 +167,8 @@ static int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)
 }
 
 /**
- * seccomp_run_filters - evaluates all seccomp filters against @syscall
- * @syscall: number of the current system call
+ * seccomp_run_filters - evaluates all seccomp filters against @sd
+ * @sd: optional seccomp data to be passed to filters
  *
  * Returns valid seccomp BPF response codes.
  */

commit 485a252a5559b45d7df04c819ec91177c62c270b
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Aug 10 16:28:09 2016 -0700

    seccomp: Fix tracer exit notifications during fatal signals
    
    This fixes a ptrace vs fatal pending signals bug as manifested in
    seccomp now that seccomp was reordered to happen after ptrace. The
    short version is that seccomp should not attempt to call do_exit()
    while fatal signals are pending under a tracer. The existing code was
    trying to be as defensively paranoid as possible, but it now ends up
    confusing ptrace. Instead, the syscall can just be skipped (which solves
    the original concern that the do_exit() was addressing) and normal signal
    handling, tracer notification, and process death can happen.
    
    Paraphrasing from the original bug report:
    
    If a tracee task is in a PTRACE_EVENT_SECCOMP trap, or has been resumed
    after such a trap but not yet been scheduled, and another task in the
    thread-group calls exit_group(), then the tracee task exits without the
    ptracer receiving a PTRACE_EVENT_EXIT notification. Test case here:
    https://gist.github.com/khuey/3c43ac247c72cef8c956ca73281c9be7
    
    The bug happens because when __seccomp_filter() detects
    fatal_signal_pending(), it calls do_exit() without dequeuing the fatal
    signal. When do_exit() sends the PTRACE_EVENT_EXIT notification and
    that task is descheduled, __schedule() notices that there is a fatal
    signal pending and changes its state from TASK_TRACED to TASK_RUNNING.
    That prevents the ptracer's waitpid() from returning the ptrace event.
    A more detailed analysis is here:
    https://github.com/mozilla/rr/issues/1762#issuecomment-237396255.
    
    Reported-by: Robert O'Callahan <robert@ocallahan.org>
    Reported-by: Kyle Huey <khuey@kylehuey.com>
    Tested-by: Kyle Huey <khuey@kylehuey.com>
    Fixes: 93e35efb8de4 ("x86/ptrace: run seccomp after ptrace")
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: James Morris <james.l.morris@oracle.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index ef6c6c3f9d8a..0db7c8a2afe2 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -605,12 +605,16 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
 		ptrace_event(PTRACE_EVENT_SECCOMP, data);
 		/*
 		 * The delivery of a fatal signal during event
-		 * notification may silently skip tracer notification.
-		 * Terminating the task now avoids executing a system
-		 * call that may not be intended.
+		 * notification may silently skip tracer notification,
+		 * which could leave us with a potentially unmodified
+		 * syscall that the tracer would have liked to have
+		 * changed. Since the process is about to die, we just
+		 * force the syscall to be skipped and let the signal
+		 * kill the process and correctly handle any tracer exit
+		 * notifications.
 		 */
 		if (fatal_signal_pending(current))
-			do_exit(SIGSYS);
+			goto skip;
 		/* Check if the tracer forced the syscall to be skipped. */
 		this_syscall = syscall_get_nr(current, task_pt_regs(current));
 		if (this_syscall < 0)

commit 97f2645f358b411ba2afb22e5966753f0ad92916
Author: Masahiro Yamada <yamada.masahiro@socionext.com>
Date:   Wed Aug 3 13:45:50 2016 -0700

    tree-wide: replace config_enabled() with IS_ENABLED()
    
    The use of config_enabled() against config options is ambiguous.  In
    practical terms, config_enabled() is equivalent to IS_BUILTIN(), but the
    author might have used it for the meaning of IS_ENABLED().  Using
    IS_ENABLED(), IS_BUILTIN(), IS_MODULE() etc.  makes the intention
    clearer.
    
    This commit replaces config_enabled() with IS_ENABLED() where possible.
    This commit is only touching bool config options.
    
    I noticed two cases where config_enabled() is used against a tristate
    option:
    
     - config_enabled(CONFIG_HWMON)
      [ drivers/net/wireless/ath/ath10k/thermal.c ]
    
     - config_enabled(CONFIG_BACKLIGHT_CLASS_DEVICE)
      [ drivers/gpu/drm/gma500/opregion.c ]
    
    I did not touch them because they should be converted to IS_BUILTIN()
    in order to keep the logic, but I was not sure it was the authors'
    intention.
    
    Link: http://lkml.kernel.org/r/1465215656-20569-1-git-send-email-yamada.masahiro@socionext.com
    Signed-off-by: Masahiro Yamada <yamada.masahiro@socionext.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Stas Sergeev <stsp@list.ru>
    Cc: Matt Redfearn <matt.redfearn@imgtec.com>
    Cc: Joshua Kinard <kumba@gentoo.org>
    Cc: Jiri Slaby <jslaby@suse.com>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Markos Chandras <markos.chandras@imgtec.com>
    Cc: "Dmitry V. Levin" <ldv@altlinux.org>
    Cc: yu-cheng yu <yu-cheng.yu@intel.com>
    Cc: James Hogan <james.hogan@imgtec.com>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Johannes Berg <johannes@sipsolutions.net>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Will Drewry <wad@chromium.org>
    Cc: Nikolay Martynov <mar.kolya@gmail.com>
    Cc: Huacai Chen <chenhc@lemote.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Leonid Yegoshin <Leonid.Yegoshin@imgtec.com>
    Cc: Rafal Milecki <zajec5@gmail.com>
    Cc: James Cowgill <James.Cowgill@imgtec.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Alex Smith <alex.smith@imgtec.com>
    Cc: Adam Buchbinder <adam.buchbinder@gmail.com>
    Cc: Qais Yousef <qais.yousef@imgtec.com>
    Cc: Jiang Liu <jiang.liu@linux.intel.com>
    Cc: Mikko Rapeli <mikko.rapeli@iki.fi>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Brian Norris <computersforpeace@gmail.com>
    Cc: Hidehiro Kawai <hidehiro.kawai.ez@hitachi.com>
    Cc: "Luis R. Rodriguez" <mcgrof@do-not-panic.com>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
    Cc: Roland McGrath <roland@hack.frob.com>
    Cc: Paul Burton <paul.burton@imgtec.com>
    Cc: Kalle Valo <kvalo@qca.qualcomm.com>
    Cc: Viresh Kumar <viresh.kumar@linaro.org>
    Cc: Tony Wu <tung7970@gmail.com>
    Cc: Huaitong Han <huaitong.han@intel.com>
    Cc: Sumit Semwal <sumit.semwal@linaro.org>
    Cc: Alexei Starovoitov <ast@kernel.org>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: Jason Cooper <jason@lakedaemon.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Andrea Gelmini <andrea.gelmini@gelma.net>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Rabin Vincent <rabin@rab.in>
    Cc: "Maciej W. Rozycki" <macro@imgtec.com>
    Cc: David Daney <david.daney@cavium.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 54d15eb2b701..ef6c6c3f9d8a 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -347,7 +347,7 @@ static struct seccomp_filter *seccomp_prepare_filter(struct sock_fprog *fprog)
 {
 	struct seccomp_filter *sfilter;
 	int ret;
-	const bool save_orig = config_enabled(CONFIG_CHECKPOINT_RESTORE);
+	const bool save_orig = IS_ENABLED(CONFIG_CHECKPOINT_RESTORE);
 
 	if (fprog->len == 0 || fprog->len > BPF_MAXINSNS)
 		return ERR_PTR(-EINVAL);
@@ -542,7 +542,7 @@ void secure_computing_strict(int this_syscall)
 {
 	int mode = current->seccomp.mode;
 
-	if (config_enabled(CONFIG_CHECKPOINT_RESTORE) &&
+	if (IS_ENABLED(CONFIG_CHECKPOINT_RESTORE) &&
 	    unlikely(current->ptrace & PT_SUSPEND_SECCOMP))
 		return;
 
@@ -655,7 +655,7 @@ int __secure_computing(const struct seccomp_data *sd)
 	int mode = current->seccomp.mode;
 	int this_syscall;
 
-	if (config_enabled(CONFIG_CHECKPOINT_RESTORE) &&
+	if (IS_ENABLED(CONFIG_CHECKPOINT_RESTORE) &&
 	    unlikely(current->ptrace & PT_SUSPEND_SECCOMP))
 		return 0;
 

commit ce6526e8afa4b6ad0ab134a4cc50c9c863319637
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Jun 1 19:29:15 2016 -0700

    seccomp: recheck the syscall after RET_TRACE
    
    When RET_TRACE triggers, a tracer may change a syscall into something that
    should be filtered by seccomp. This re-runs seccomp after a trace event
    to make sure things continue to pass.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Cc: Andy Lutomirski <luto@kernel.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 14a37d71b612..54d15eb2b701 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -556,7 +556,8 @@ void secure_computing_strict(int this_syscall)
 #else
 
 #ifdef CONFIG_SECCOMP_FILTER
-static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd)
+static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
+			    const bool recheck_after_trace)
 {
 	u32 filter_ret, action;
 	int data;
@@ -588,6 +589,10 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd)
 		goto skip;
 
 	case SECCOMP_RET_TRACE:
+		/* We've been put in this state by the ptracer already. */
+		if (recheck_after_trace)
+			return 0;
+
 		/* ENOSYS these calls if there is no tracer attached. */
 		if (!ptrace_event_enabled(current, PTRACE_EVENT_SECCOMP)) {
 			syscall_set_return_value(current,
@@ -611,6 +616,15 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd)
 		if (this_syscall < 0)
 			goto skip;
 
+		/*
+		 * Recheck the syscall, since it may have changed. This
+		 * intentionally uses a NULL struct seccomp_data to force
+		 * a reload of all registers. This does not goto skip since
+		 * a skip would have already been reported.
+		 */
+		if (__seccomp_filter(this_syscall, NULL, true))
+			return -1;
+
 		return 0;
 
 	case SECCOMP_RET_ALLOW:
@@ -629,7 +643,8 @@ static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd)
 	return -1;
 }
 #else
-static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd)
+static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,
+			    const bool recheck_after_trace)
 {
 	BUG();
 }
@@ -652,7 +667,7 @@ int __secure_computing(const struct seccomp_data *sd)
 		__secure_computing_strict(this_syscall);  /* may call do_exit */
 		return 0;
 	case SECCOMP_MODE_FILTER:
-		return __seccomp_filter(this_syscall, sd);
+		return __seccomp_filter(this_syscall, sd, false);
 	default:
 		BUG();
 	}

commit 8112c4f140fa03f9ee68aad2cc79afa7df5418d3
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Jun 1 16:02:17 2016 -0700

    seccomp: remove 2-phase API
    
    Since nothing is using the 2-phase API, and it adds more complexity than
    benefit, remove it.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Cc: Andy Lutomirski <luto@kernel.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 06816290a212..14a37d71b612 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -173,7 +173,7 @@ static int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)
  *
  * Returns valid seccomp BPF response codes.
  */
-static u32 seccomp_run_filters(struct seccomp_data *sd)
+static u32 seccomp_run_filters(const struct seccomp_data *sd)
 {
 	struct seccomp_data sd_local;
 	u32 ret = SECCOMP_RET_ALLOW;
@@ -554,20 +554,9 @@ void secure_computing_strict(int this_syscall)
 		BUG();
 }
 #else
-int __secure_computing(const struct seccomp_data *sd)
-{
-	u32 phase1_result = seccomp_phase1(sd);
-
-	if (likely(phase1_result == SECCOMP_PHASE1_OK))
-		return 0;
-	else if (likely(phase1_result == SECCOMP_PHASE1_SKIP))
-		return -1;
-	else
-		return seccomp_phase2(phase1_result);
-}
 
 #ifdef CONFIG_SECCOMP_FILTER
-static u32 __seccomp_phase1_filter(int this_syscall, struct seccomp_data *sd)
+static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd)
 {
 	u32 filter_ret, action;
 	int data;
@@ -599,10 +588,33 @@ static u32 __seccomp_phase1_filter(int this_syscall, struct seccomp_data *sd)
 		goto skip;
 
 	case SECCOMP_RET_TRACE:
-		return filter_ret;  /* Save the rest for phase 2. */
+		/* ENOSYS these calls if there is no tracer attached. */
+		if (!ptrace_event_enabled(current, PTRACE_EVENT_SECCOMP)) {
+			syscall_set_return_value(current,
+						 task_pt_regs(current),
+						 -ENOSYS, 0);
+			goto skip;
+		}
+
+		/* Allow the BPF to provide the event message */
+		ptrace_event(PTRACE_EVENT_SECCOMP, data);
+		/*
+		 * The delivery of a fatal signal during event
+		 * notification may silently skip tracer notification.
+		 * Terminating the task now avoids executing a system
+		 * call that may not be intended.
+		 */
+		if (fatal_signal_pending(current))
+			do_exit(SIGSYS);
+		/* Check if the tracer forced the syscall to be skipped. */
+		this_syscall = syscall_get_nr(current, task_pt_regs(current));
+		if (this_syscall < 0)
+			goto skip;
+
+		return 0;
 
 	case SECCOMP_RET_ALLOW:
-		return SECCOMP_PHASE1_OK;
+		return 0;
 
 	case SECCOMP_RET_KILL:
 	default:
@@ -614,96 +626,37 @@ static u32 __seccomp_phase1_filter(int this_syscall, struct seccomp_data *sd)
 
 skip:
 	audit_seccomp(this_syscall, 0, action);
-	return SECCOMP_PHASE1_SKIP;
+	return -1;
+}
+#else
+static int __seccomp_filter(int this_syscall, const struct seccomp_data *sd)
+{
+	BUG();
 }
 #endif
 
-/**
- * seccomp_phase1() - run fast path seccomp checks on the current syscall
- * @arg sd: The seccomp_data or NULL
- *
- * This only reads pt_regs via the syscall_xyz helpers.  The only change
- * it will make to pt_regs is via syscall_set_return_value, and it will
- * only do that if it returns SECCOMP_PHASE1_SKIP.
- *
- * If sd is provided, it will not read pt_regs at all.
- *
- * It may also call do_exit or force a signal; these actions must be
- * safe.
- *
- * If it returns SECCOMP_PHASE1_OK, the syscall passes checks and should
- * be processed normally.
- *
- * If it returns SECCOMP_PHASE1_SKIP, then the syscall should not be
- * invoked.  In this case, seccomp_phase1 will have set the return value
- * using syscall_set_return_value.
- *
- * If it returns anything else, then the return value should be passed
- * to seccomp_phase2 from a context in which ptrace hooks are safe.
- */
-u32 seccomp_phase1(struct seccomp_data *sd)
+int __secure_computing(const struct seccomp_data *sd)
 {
 	int mode = current->seccomp.mode;
-	int this_syscall = sd ? sd->nr :
-		syscall_get_nr(current, task_pt_regs(current));
+	int this_syscall;
 
 	if (config_enabled(CONFIG_CHECKPOINT_RESTORE) &&
 	    unlikely(current->ptrace & PT_SUSPEND_SECCOMP))
-		return SECCOMP_PHASE1_OK;
+		return 0;
+
+	this_syscall = sd ? sd->nr :
+		syscall_get_nr(current, task_pt_regs(current));
 
 	switch (mode) {
 	case SECCOMP_MODE_STRICT:
 		__secure_computing_strict(this_syscall);  /* may call do_exit */
-		return SECCOMP_PHASE1_OK;
-#ifdef CONFIG_SECCOMP_FILTER
+		return 0;
 	case SECCOMP_MODE_FILTER:
-		return __seccomp_phase1_filter(this_syscall, sd);
-#endif
+		return __seccomp_filter(this_syscall, sd);
 	default:
 		BUG();
 	}
 }
-
-/**
- * seccomp_phase2() - finish slow path seccomp work for the current syscall
- * @phase1_result: The return value from seccomp_phase1()
- *
- * This must be called from a context in which ptrace hooks can be used.
- *
- * Returns 0 if the syscall should be processed or -1 to skip the syscall.
- */
-int seccomp_phase2(u32 phase1_result)
-{
-	struct pt_regs *regs = task_pt_regs(current);
-	u32 action = phase1_result & SECCOMP_RET_ACTION;
-	int data = phase1_result & SECCOMP_RET_DATA;
-
-	BUG_ON(action != SECCOMP_RET_TRACE);
-
-	audit_seccomp(syscall_get_nr(current, regs), 0, action);
-
-	/* Skip these calls if there is no tracer. */
-	if (!ptrace_event_enabled(current, PTRACE_EVENT_SECCOMP)) {
-		syscall_set_return_value(current, regs,
-					 -ENOSYS, 0);
-		return -1;
-	}
-
-	/* Allow the BPF to provide the event message */
-	ptrace_event(PTRACE_EVENT_SECCOMP, data);
-	/*
-	 * The delivery of a fatal signal during event
-	 * notification may silently skip tracer notification.
-	 * Terminating the task now avoids executing a system
-	 * call that may not be intended.
-	 */
-	if (fatal_signal_pending(current))
-		do_exit(SIGSYS);
-	if (syscall_get_nr(current, regs) < 0)
-		return -1;  /* Explicit request to skip. */
-
-	return 0;
-}
 #endif /* CONFIG_HAVE_ARCH_SECCOMP_FILTER */
 
 long prctl_get_seccomp(void)

commit 2f275de5d1ed7269913ef9b4c64a13952c0a38e8
Author: Andy Lutomirski <luto@kernel.org>
Date:   Fri May 27 12:57:02 2016 -0700

    seccomp: Add a seccomp_data parameter secure_computing()
    
    Currently, if arch code wants to supply seccomp_data directly to
    seccomp (which is generally much faster than having seccomp do it
    using the syscall_get_xyz() API), it has to use the two-phase
    seccomp hooks. Add it to the easy hooks, too.
    
    Cc: linux-arch@vger.kernel.org
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 7002796f14a4..06816290a212 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -554,9 +554,9 @@ void secure_computing_strict(int this_syscall)
 		BUG();
 }
 #else
-int __secure_computing(void)
+int __secure_computing(const struct seccomp_data *sd)
 {
-	u32 phase1_result = seccomp_phase1(NULL);
+	u32 phase1_result = seccomp_phase1(sd);
 
 	if (likely(phase1_result == SECCOMP_PHASE1_OK))
 		return 0;

commit 07b75260ebc2c789724c594d7eaf0194fa47b3be
Merge: 0efacbbaee1e 6e4ad1b41360
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu May 19 10:02:26 2016 -0700

    Merge branch 'upstream' of git://git.linux-mips.org/pub/scm/ralf/upstream-linus
    
    Pull MIPS updates from Ralf Baechle:
     "This is the main pull request for MIPS for 4.7.  Here's the summary of
      the changes:
    
       - ATH79: Support for DTB passuing using the UHI boot protocol
       - ATH79: Remove support for builtin DTB.
       - ATH79: Add zboot debug serial support.
       - ATH79: Add initial support for Dragino MS14 (Dragine 2), Onion Omega
                and DPT-Module.
       - ATH79: Update devicetree clock support for AR9132 and AR9331.
       - ATH79: Cleanup the DT code.
       - ATH79: Support newer SOCs in ath79_ddr_ctrl_init.
       - ATH79: Fix regression in PCI window initialization.
       - BCM47xx: Move SPROM driver to drivers/firmware/
       - BCM63xx: Enable partition parser in defconfig.
       - BMIPS: BMIPS5000 has I cache filing from D cache
       - BMIPS: BMIPS: Add cpu-feature-overrides.h
       - BMIPS: Add Whirlwind support
       - BMIPS: Adjust mips-hpt-frequency for BCM7435
       - BMIPS: Remove maxcpus from BCM97435SVMB DTS
       - BMIPS: Add missing 7038 L1 register cells to BCM7435
       - BMIPS: Various tweaks to initialization code.
       - BMIPS: Enable partition parser in defconfig.
       - BMIPS: Cache tweaks.
       - BMIPS: Add UART, I2C and SATA devices to DT.
       - BMIPS: Add BCM6358 and BCM63268support
       - BMIPS: Add device tree example for BCM6358.
       - BMIPS: Improve Improve BCM6328 and BCM6368 device trees
       - Lantiq: Add support for device tree file from boot loader
       - Lantiq: Allow build with no built-in DT.
       - Loongson 3: Reserve 32MB for RS780E integrated GPU.
       - Loongson 3: Fix build error after ld-version.sh modification
       - Loongson 3: Move chipset ACPI code from drivers to arch.
       - Loongson 3: Speedup irq processing.
       - Loongson 3: Add basic Loongson 3A support.
       - Loongson 3: Set cache flush handlers to nop.
       - Loongson 3: Invalidate special TLBs when needed.
       - Loongson 3: Fast TLB refill handler.
       - MT7620: Fallback strategy for invalid syscfg0.
       - Netlogic: Fix CP0_EBASE redefinition warnings
       - Octeon: Initialization fixes
       - Octeon: Add DTS files for the D-Link DSR-1000N and EdgeRouter Lite
       - Octeon: Enable add Octeon-drivers in cavium_octeon_defconfig
       - Octeon: Correctly handle endian-swapped initramfs images.
       - Octeon: Support CN73xx, CN75xx and CN78xx.
       - Octeon: Remove dead code from cvmx-sysinfo.
       - Octeon: Extend number of supported CPUs past 32.
       - Octeon: Remove some code limiting NR_IRQS to 255.
       - Octeon: Simplify octeon_irq_ciu_gpio_set_type.
       - Octeon: Mark some functions __init in smp.c
       - Octeon: Octeon: Add Octeon III CN7xxx interface detection
       - PIC32: Add serial driver and bindings for it.
       - PIC32: Add PIC32 deadman timer driver and bindings.
       - PIC32: Add PIC32 clock timer driver and bindings.
       - Pistachio: Determine SoC revision during boot
       - Sibyte: Fix Kconfig dependencies of SIBYTE_BUS_WATCHER.
       - Sibyte: Strip redundant comments from bcm1480_regs.h.
       - Panic immediately if panic_on_oops is set.
       - module: fix incorrect IS_ERR_VALUE macro usage.
       - module: Make consistent use of pr_*
       - Remove no longer needed work_on_cpu() call.
       - Remove CONFIG_IPV6_PRIVACY from defconfigs.
       - Fix registers of non-crashing CPUs in dumps.
       - Handle MIPSisms in new vmcore_elf32_check_arch.
       - Select CONFIG_HANDLE_DOMAIN_IRQ and make it work.
       - Allow RIXI to be used on non-R2 or R6 cores.
       - Reserve nosave data for hibernation
       - Fix siginfo.h to use strict POSIX types.
       - Don't unwind user mode with EVA.
       - Fix watchpoint restoration
       - Ptrace watchpoints for R6.
       - Sync icache when it fills from dcache
       - I6400 I-cache fills from dcache.
       - Various MSA fixes.
       - Cleanup MIPS_CPU_* definitions.
       - Signal: Move generic copy_siginfo to signal.h
       - Signal: Fix uapi include in exported asm/siginfo.h
       - Timer fixes for sake of KVM.
       - XPA TLB refill fixes.
       - Treat perf counter feature
       - Update John Crispin's email address
       - Add PIC32 watchdog and bindings.
       - Handle R10000 LL/SC bug in set_pte()
       - cpufreq: Various fixes for Longson1.
       - R6: Fix R2 emulation.
       - mathemu: Cosmetic fix to ADDIUPC emulation, plenty of other small fixes
       - ELF: ABI and FP fixes.
       - Allow for relocatable kernel and use that to support KASLR.
       - Fix CPC_BASE_ADDR mask
       - Plenty fo smp-cps, CM, R6 and M6250 fixes.
       - Make reset_control_ops const.
       - Fix kernel command line handling of leading whitespace.
       - Cleanups to cache handling.
       - Add brcm, bcm6345-l1-intc device tree bindings.
       - Use generic clkdev.h header
       - Remove CLK_IS_ROOT usage.
       - Misc small cleanups.
       - CM: Fix compilation error when !MIPS_CM
       - oprofile: Fix a preemption issue
       - Detect DSP ASE v3 support:1"
    
    * 'upstream' of git://git.linux-mips.org/pub/scm/ralf/upstream-linus: (275 commits)
      MIPS: pic32mzda: fix getting timer clock rate.
      MIPS: ath79: fix regression in PCI window initialization
      MIPS: ath79: make ath79_ddr_ctrl_init() compatible for newer SoCs
      MIPS: Fix VZ probe gas errors with binutils <2.24
      MIPS: perf: Fix I6400 event numbers
      MIPS: DEC: Export `ioasic_ssr_lock' to modules
      MIPS: MSA: Fix a link error on `_init_msa_upper' with older GCC
      MIPS: CM: Fix compilation error when !MIPS_CM
      MIPS: Fix genvdso error on rebuild
      USB: ohci-jz4740: Remove obsolete driver
      MIPS: JZ4740: Probe OHCI platform device via DT
      MIPS: JZ4740: Qi LB60: Remove support for AVT2 variant
      MIPS: pistachio: Determine SoC revision during boot
      MIPS: BMIPS: Adjust mips-hpt-frequency for BCM7435
      mips: mt7620: fallback to SDRAM when syscfg0 does not have a valid value for the memory type
      MIPS: Prevent "restoration" of MSA context in non-MSA kernels
      MIPS: cevt-r4k: Dynamically calculate min_delta_ns
      MIPS: malta-time: Take seconds into account
      MIPS: malta-time: Start GIC count before syncing to RTC
      MIPS: Force CPUs to lose FP context during mode switches
      ...

commit cb4253aa0f77f20be018970dbe5d01d78b930ef9
Author: Matt Redfearn <matt.redfearn@imgtec.com>
Date:   Tue Mar 29 09:35:34 2016 +0100

    secomp: Constify mode1 syscall whitelist
    
    These values are constant and should be marked as such.
    
    Signed-off-by: Matt Redfearn <matt.redfearn@imgtec.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Will Drewry <wad@chromium.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: IMG-MIPSLinuxKerneldevelopers@imgtec.com
    Cc: linux-kernel@vger.kernel.org
    Patchwork: https://patchwork.linux-mips.org/patch/12979/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 737436ebb4fe..a0ffcb1a2bee 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -513,14 +513,14 @@ static void seccomp_send_sigsys(int syscall, int reason)
  * To be fully secure this must be combined with rlimit
  * to limit the stack allocations too.
  */
-static int mode1_syscalls[] = {
+static const int mode1_syscalls[] = {
 	__NR_seccomp_read, __NR_seccomp_write, __NR_seccomp_exit, __NR_seccomp_sigreturn,
 	0, /* null terminated */
 };
 
 static void __secure_computing_strict(int this_syscall)
 {
-	int *syscall_whitelist = mode1_syscalls;
+	const int *syscall_whitelist = mode1_syscalls;
 #ifdef CONFIG_COMPAT
 	if (in_compat_syscall())
 		syscall_whitelist = get_compat_mode1_syscalls();

commit c983f0e8677d5d686ea81de13f9c9ac34f21a2a7
Author: Matt Redfearn <matt.redfearn@imgtec.com>
Date:   Tue Mar 29 09:35:32 2016 +0100

    seccomp: Get compat syscalls from asm-generic header
    
    Move retrieval of compat syscall numbers into inline function defined in
    asm-generic header so that arches may override it.
    
    [ralf@linux-mips.org: Resolve merge conflict.]
    
    Suggested-by: Paul Burton <paul.burton@imgtec.com>
    Signed-off-by: Matt Redfearn <matt.redfearn@imgtec.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: IMG-MIPSLinuxKerneldevelopers@imgtec.com
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Will Drewry <wad@chromium.org>
    Cc: linux-arch@vger.kernel.org
    Cc: linux-kernel@vger.kernel.org
    Patchwork: https://patchwork.linux-mips.org/patch/12978/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index e1e5a354854e..737436ebb4fe 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -518,19 +518,12 @@ static int mode1_syscalls[] = {
 	0, /* null terminated */
 };
 
-#ifdef CONFIG_COMPAT
-static int mode1_syscalls_32[] = {
-	__NR_seccomp_read_32, __NR_seccomp_write_32, __NR_seccomp_exit_32, __NR_seccomp_sigreturn_32,
-	0, /* null terminated */
-};
-#endif
-
 static void __secure_computing_strict(int this_syscall)
 {
 	int *syscall_whitelist = mode1_syscalls;
 #ifdef CONFIG_COMPAT
 	if (in_compat_syscall())
-		syscall_whitelist = mode1_syscalls_32;
+		syscall_whitelist = get_compat_mode1_syscalls();
 #endif
 	do {
 		if (*syscall_whitelist == this_syscall)

commit 470bf1f27a1472264d18c84b324389509f0e30b3
Author: Mickal Salan <mic@digikod.net>
Date:   Thu Mar 24 02:46:33 2016 +0100

    seccomp: Fix comment typo
    
    Drop accidentally repeated word in comment.
    
    Signed-off-by: Mickal Salan <mic@digikod.net>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Will Drewry <wad@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index e1e5a354854e..6c9bb62ed046 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -915,7 +915,7 @@ long seccomp_get_filter(struct task_struct *task, unsigned long filter_off,
 
 	fprog = filter->prog->orig_prog;
 	if (!fprog) {
-		/* This must be a new non-cBPF filter, since we save every
+		/* This must be a new non-cBPF filter, since we save
 		 * every cBPF filter's orig_prog above when
 		 * CONFIG_CHECKPOINT_RESTORE is enabled.
 		 */

commit 5c38065e021bc76f97fc08997f6d7fc7ea3fb7a7
Author: Andy Lutomirski <luto@kernel.org>
Date:   Tue Mar 22 14:24:52 2016 -0700

    seccomp: check in_compat_syscall, not is_compat_task, in strict mode
    
    Seccomp wants to know the syscall bitness, not the caller task bitness,
    when it selects the syscall whitelist.
    
    As far as I know, this makes no difference on any architecture, so it's
    not a security problem.  (It generates identical code everywhere except
    sparc, and, on sparc, the syscall numbering is the same for both ABIs.)
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 15a1795bbba1..e1e5a354854e 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -395,7 +395,7 @@ seccomp_prepare_user_filter(const char __user *user_filter)
 	struct seccomp_filter *filter = ERR_PTR(-EFAULT);
 
 #ifdef CONFIG_COMPAT
-	if (is_compat_task()) {
+	if (in_compat_syscall()) {
 		struct compat_sock_fprog fprog32;
 		if (copy_from_user(&fprog32, user_filter, sizeof(fprog32)))
 			goto out;
@@ -529,7 +529,7 @@ static void __secure_computing_strict(int this_syscall)
 {
 	int *syscall_whitelist = mode1_syscalls;
 #ifdef CONFIG_COMPAT
-	if (is_compat_task())
+	if (in_compat_syscall())
 		syscall_whitelist = mode1_syscalls_32;
 #endif
 	do {

commit 103502a35cfce0710909da874f092cb44823ca03
Author: Jann Horn <jann@thejh.net>
Date:   Sat Dec 26 06:00:48 2015 +0100

    seccomp: always propagate NO_NEW_PRIVS on tsync
    
    Before this patch, a process with some permissive seccomp filter
    that was applied by root without NO_NEW_PRIVS was able to add
    more filters to itself without setting NO_NEW_PRIVS by setting
    the new filter from a throwaway thread with NO_NEW_PRIVS.
    
    Signed-off-by: Jann Horn <jann@thejh.net>
    Cc: stable@vger.kernel.org
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 580ac2d4024f..15a1795bbba1 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -316,24 +316,24 @@ static inline void seccomp_sync_threads(void)
 		put_seccomp_filter(thread);
 		smp_store_release(&thread->seccomp.filter,
 				  caller->seccomp.filter);
+
+		/*
+		 * Don't let an unprivileged task work around
+		 * the no_new_privs restriction by creating
+		 * a thread that sets it up, enters seccomp,
+		 * then dies.
+		 */
+		if (task_no_new_privs(caller))
+			task_set_no_new_privs(thread);
+
 		/*
 		 * Opt the other thread into seccomp if needed.
 		 * As threads are considered to be trust-realm
 		 * equivalent (see ptrace_may_access), it is safe to
 		 * allow one thread to transition the other.
 		 */
-		if (thread->seccomp.mode == SECCOMP_MODE_DISABLED) {
-			/*
-			 * Don't let an unprivileged task work around
-			 * the no_new_privs restriction by creating
-			 * a thread that sets it up, enters seccomp,
-			 * then dies.
-			 */
-			if (task_no_new_privs(caller))
-				task_set_no_new_privs(thread);
-
+		if (thread->seccomp.mode == SECCOMP_MODE_DISABLED)
 			seccomp_assign_mode(thread, SECCOMP_MODE_FILTER);
-		}
 	}
 }
 

commit f8e529ed941ba2bbcbf310b575d968159ce7e895
Author: Tycho Andersen <tycho.andersen@canonical.com>
Date:   Tue Oct 27 09:23:59 2015 +0900

    seccomp, ptrace: add support for dumping seccomp filters
    
    This patch adds support for dumping a process' (classic BPF) seccomp
    filters via ptrace.
    
    PTRACE_SECCOMP_GET_FILTER allows the tracer to dump the user's classic BPF
    seccomp filters. addr should be an integer which represents the ith seccomp
    filter (0 is the most recently installed filter). data should be a struct
    sock_filter * with enough room for the ith filter, or NULL, in which case
    the filter is not saved. The return value for this command is the number of
    BPF instructions the program represents, or negative in the case of errors.
    Command specific errors are ENOENT: which indicates that there is no ith
    filter in this seccomp tree, and EMEDIUMTYPE, which indicates that the ith
    filter was not installed as a classic BPF filter.
    
    A caveat with this approach is that there is no way to get explicitly at
    the heirarchy of seccomp filters, and users need to memcmp() filters to
    decide which are inherited. This means that a task which installs two of
    the same filter can potentially confuse users of this interface.
    
    v2: * make save_orig const
        * check that the orig_prog exists (not necessary right now, but when
           grows eBPF support it will be)
        * s/n/filter_off and make it an unsigned long to match ptrace
        * count "down" the tree instead of "up" when passing a filter offset
    
    v3: * don't take the current task's lock for inspecting its seccomp mode
        * use a 0x42** constant for the ptrace command value
    
    v4: * don't copy to userspace while holding spinlocks
    
    v5: * add another condition to WARN_ON
    
    v6: * rebase on net-next
    
    Signed-off-by: Tycho Andersen <tycho.andersen@canonical.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    CC: Will Drewry <wad@chromium.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    CC: Andy Lutomirski <luto@amacapital.net>
    CC: Pavel Emelyanov <xemul@parallels.com>
    CC: Serge E. Hallyn <serge.hallyn@ubuntu.com>
    CC: Alexei Starovoitov <ast@kernel.org>
    CC: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 06858a74bb9c..580ac2d4024f 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -347,6 +347,7 @@ static struct seccomp_filter *seccomp_prepare_filter(struct sock_fprog *fprog)
 {
 	struct seccomp_filter *sfilter;
 	int ret;
+	const bool save_orig = config_enabled(CONFIG_CHECKPOINT_RESTORE);
 
 	if (fprog->len == 0 || fprog->len > BPF_MAXINSNS)
 		return ERR_PTR(-EINVAL);
@@ -370,7 +371,7 @@ static struct seccomp_filter *seccomp_prepare_filter(struct sock_fprog *fprog)
 		return ERR_PTR(-ENOMEM);
 
 	ret = bpf_prog_create_from_user(&sfilter->prog, fprog,
-					seccomp_check_filter, false);
+					seccomp_check_filter, save_orig);
 	if (ret < 0) {
 		kfree(sfilter);
 		return ERR_PTR(ret);
@@ -867,3 +868,76 @@ long prctl_set_seccomp(unsigned long seccomp_mode, char __user *filter)
 	/* prctl interface doesn't have flags, so they are always zero. */
 	return do_seccomp(op, 0, uargs);
 }
+
+#if defined(CONFIG_SECCOMP_FILTER) && defined(CONFIG_CHECKPOINT_RESTORE)
+long seccomp_get_filter(struct task_struct *task, unsigned long filter_off,
+			void __user *data)
+{
+	struct seccomp_filter *filter;
+	struct sock_fprog_kern *fprog;
+	long ret;
+	unsigned long count = 0;
+
+	if (!capable(CAP_SYS_ADMIN) ||
+	    current->seccomp.mode != SECCOMP_MODE_DISABLED) {
+		return -EACCES;
+	}
+
+	spin_lock_irq(&task->sighand->siglock);
+	if (task->seccomp.mode != SECCOMP_MODE_FILTER) {
+		ret = -EINVAL;
+		goto out;
+	}
+
+	filter = task->seccomp.filter;
+	while (filter) {
+		filter = filter->prev;
+		count++;
+	}
+
+	if (filter_off >= count) {
+		ret = -ENOENT;
+		goto out;
+	}
+	count -= filter_off;
+
+	filter = task->seccomp.filter;
+	while (filter && count > 1) {
+		filter = filter->prev;
+		count--;
+	}
+
+	if (WARN_ON(count != 1 || !filter)) {
+		/* The filter tree shouldn't shrink while we're using it. */
+		ret = -ENOENT;
+		goto out;
+	}
+
+	fprog = filter->prog->orig_prog;
+	if (!fprog) {
+		/* This must be a new non-cBPF filter, since we save every
+		 * every cBPF filter's orig_prog above when
+		 * CONFIG_CHECKPOINT_RESTORE is enabled.
+		 */
+		ret = -EMEDIUMTYPE;
+		goto out;
+	}
+
+	ret = fprog->len;
+	if (!data)
+		goto out;
+
+	get_seccomp_filter(task);
+	spin_unlock_irq(&task->sighand->siglock);
+
+	if (copy_to_user(data, fprog->filter, bpf_classic_proglen(fprog)))
+		ret = -EFAULT;
+
+	put_seccomp_filter(task);
+	return ret;
+
+out:
+	spin_unlock_irq(&task->sighand->siglock);
+	return ret;
+}
+#endif

commit bab18991871545dfbd10c931eb0fe8f7637156a9
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Fri Oct 2 15:17:33 2015 +0200

    bpf, seccomp: prepare for upcoming criu support
    
    The current ongoing effort to dump existing cBPF seccomp filters back
    to user space requires to hold the pre-transformed instructions like
    we do in case of socket filters from sk_attach_filter() side, so they
    can be reloaded in original form at a later point in time by utilities
    such as criu.
    
    To prepare for this, simply extend the bpf_prog_create_from_user()
    API to hold a flag that tells whether we should store the original
    or not. Also, fanout filters could make use of that in future for
    things like diag. While fanout filters already use bpf_prog_destroy(),
    move seccomp over to them as well to handle original programs when
    present.
    
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Tycho Andersen <tycho.andersen@canonical.com>
    Cc: Pavel Emelyanov <xemul@parallels.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Alexei Starovoitov <ast@plumgrid.com>
    Tested-by: Tycho Andersen <tycho.andersen@canonical.com>
    Acked-by: Alexei Starovoitov <ast@plumgrid.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 5bd4779282df..06858a74bb9c 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -370,7 +370,7 @@ static struct seccomp_filter *seccomp_prepare_filter(struct sock_fprog *fprog)
 		return ERR_PTR(-ENOMEM);
 
 	ret = bpf_prog_create_from_user(&sfilter->prog, fprog,
-					seccomp_check_filter);
+					seccomp_check_filter, false);
 	if (ret < 0) {
 		kfree(sfilter);
 		return ERR_PTR(ret);
@@ -469,7 +469,7 @@ void get_seccomp_filter(struct task_struct *tsk)
 static inline void seccomp_filter_free(struct seccomp_filter *filter)
 {
 	if (filter) {
-		bpf_prog_free(filter->prog);
+		bpf_prog_destroy(filter->prog);
 		kfree(filter);
 	}
 }

commit fe6c59dc17908effd4e2caa666795b9ad984005b
Merge: 52721d9d3334 221272f97ca5
Author: James Morris <james.l.morris@oracle.com>
Date:   Mon Jul 20 17:19:19 2015 +1000

    Merge tag 'seccomp-next' of git://git.kernel.org/pub/scm/linux/kernel/git/kees/linux into next

commit 221272f97ca528048a577a3ff23d7774286ca5fd
Author: Kees Cook <keescook@chromium.org>
Date:   Mon Jun 15 15:29:16 2015 -0700

    seccomp: swap hard-coded zeros to defined name
    
    For clarity, if CONFIG_SECCOMP isn't defined, seccomp_mode() is returning
    "disabled". This makes that more clear, along with another 0-use, and
    results in no operational change.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 645e42d6fa4d..383bd6caca81 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -594,7 +594,7 @@ void secure_computing_strict(int this_syscall)
 	    unlikely(current->ptrace & PT_SUSPEND_SECCOMP))
 		return;
 
-	if (mode == 0)
+	if (mode == SECCOMP_MODE_DISABLED)
 		return;
 	else if (mode == SECCOMP_MODE_STRICT)
 		__secure_computing_strict(this_syscall);

commit 13c4a90119d28cfcb6b5bdd820c233b86c2b0237
Author: Tycho Andersen <tycho.andersen@canonical.com>
Date:   Sat Jun 13 09:02:48 2015 -0600

    seccomp: add ptrace options for suspend/resume
    
    This patch is the first step in enabling checkpoint/restore of processes
    with seccomp enabled.
    
    One of the things CRIU does while dumping tasks is inject code into them
    via ptrace to collect information that is only available to the process
    itself. However, if we are in a seccomp mode where these processes are
    prohibited from making these syscalls, then what CRIU does kills the task.
    
    This patch adds a new ptrace option, PTRACE_O_SUSPEND_SECCOMP, that enables
    a task from the init user namespace which has CAP_SYS_ADMIN and no seccomp
    filters to disable (and re-enable) seccomp filters for another task so that
    they can be successfully dumped (and restored). We restrict the set of
    processes that can disable seccomp through ptrace because although today
    ptrace can be used to bypass seccomp, there is some discussion of closing
    this loophole in the future and we would like this patch to not depend on
    that behavior and be future proofed for when it is removed.
    
    Note that seccomp can be suspended before any filters are actually
    installed; this behavior is useful on criu restore, so that we can suspend
    seccomp, restore the filters, unmap our restore code from the restored
    process' address space, and then resume the task by detaching and have the
    filters resumed as well.
    
    v2 changes:
    
    * require that the tracer have no seccomp filters installed
    * drop TIF_NOTSC manipulation from the patch
    * change from ptrace command to a ptrace option and use this ptrace option
      as the flag to check. This means that as soon as the tracer
      detaches/dies, seccomp is re-enabled and as a corrollary that one can not
      disable seccomp across PTRACE_ATTACHs.
    
    v3 changes:
    
    * get rid of various #ifdefs everywhere
    * report more sensible errors when PTRACE_O_SUSPEND_SECCOMP is incorrectly
      used
    
    v4 changes:
    
    * get rid of may_suspend_seccomp() in favor of a capable() check in ptrace
      directly
    
    v5 changes:
    
    * check that seccomp is not enabled (or suspended) on the tracer
    
    Signed-off-by: Tycho Andersen <tycho.andersen@canonical.com>
    CC: Will Drewry <wad@chromium.org>
    CC: Roland McGrath <roland@hack.frob.com>
    CC: Pavel Emelyanov <xemul@parallels.com>
    CC: Serge E. Hallyn <serge.hallyn@ubuntu.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Andy Lutomirski <luto@amacapital.net>
    [kees: access seccomp.mode through seccomp_mode() instead]
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 980fd26da22e..645e42d6fa4d 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -590,6 +590,10 @@ void secure_computing_strict(int this_syscall)
 {
 	int mode = current->seccomp.mode;
 
+	if (config_enabled(CONFIG_CHECKPOINT_RESTORE) &&
+	    unlikely(current->ptrace & PT_SUSPEND_SECCOMP))
+		return;
+
 	if (mode == 0)
 		return;
 	else if (mode == SECCOMP_MODE_STRICT)
@@ -691,6 +695,10 @@ u32 seccomp_phase1(struct seccomp_data *sd)
 	int this_syscall = sd ? sd->nr :
 		syscall_get_nr(current, task_pt_regs(current));
 
+	if (config_enabled(CONFIG_CHECKPOINT_RESTORE) &&
+	    unlikely(current->ptrace & PT_SUSPEND_SECCOMP))
+		return SECCOMP_PHASE1_OK;
+
 	switch (mode) {
 	case SECCOMP_MODE_STRICT:
 		__secure_computing_strict(this_syscall);  /* may call do_exit */

commit 8225d3853f34f6cf9caff15d8c385a528e0d7cb1
Author: Pranith Kumar <bobby.prani@gmail.com>
Date:   Fri Nov 21 10:06:01 2014 -0500

    seccomp: Replace smp_read_barrier_depends() with lockless_dereference()
    
    Recently lockless_dereference() was added which can be used in place of
    hard-coding smp_read_barrier_depends(). The following PATCH makes the change.
    
    Signed-off-by: Pranith Kumar <bobby.prani@gmail.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 4f44028943e6..980fd26da22e 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -175,17 +175,16 @@ static int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)
  */
 static u32 seccomp_run_filters(struct seccomp_data *sd)
 {
-	struct seccomp_filter *f = ACCESS_ONCE(current->seccomp.filter);
 	struct seccomp_data sd_local;
 	u32 ret = SECCOMP_RET_ALLOW;
+	/* Make sure cross-thread synced filter points somewhere sane. */
+	struct seccomp_filter *f =
+			lockless_dereference(current->seccomp.filter);
 
 	/* Ensure unexpected behavior doesn't result in failing open. */
 	if (unlikely(WARN_ON(f == NULL)))
 		return SECCOMP_RET_KILL;
 
-	/* Make sure cross-thread synced filter points somewhere sane. */
-	smp_read_barrier_depends();
-
 	if (!sd) {
 		populate_seccomp_data(&sd_local);
 		sd = &sd_local;

commit ac67eb2c5347bd9976308c0e0cf1d9e7ca690342
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Wed May 6 16:12:30 2015 +0200

    seccomp, filter: add and use bpf_prog_create_from_user from seccomp
    
    Seccomp has always been a special candidate when it comes to preparation
    of its filters in seccomp_prepare_filter(). Due to the extra checks and
    filter rewrite it partially duplicates code and has BPF internals exposed.
    
    This patch adds a generic API inside the BPF code code that seccomp can use
    and thus keep it's filter preparation code minimal and better maintainable.
    The other side-effect is that now classic JITs can add seccomp support as
    well by only providing a BPF_LDX | BPF_W | BPF_ABS translation.
    
    Tested with seccomp and BPF test suites.
    
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Nicolas Schichan <nschichan@freebox.fr>
    Cc: Alexei Starovoitov <ast@plumgrid.com>
    Cc: Kees Cook <keescook@chromium.org>
    Acked-by: Alexei Starovoitov <ast@plumgrid.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 93d40f7f3683..245df6b32b81 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -346,15 +346,13 @@ static inline void seccomp_sync_threads(void)
  */
 static struct seccomp_filter *seccomp_prepare_filter(struct sock_fprog *fprog)
 {
-	struct seccomp_filter *filter;
-	struct bpf_prog *prog;
-	unsigned long fsize;
+	struct seccomp_filter *sfilter;
+	int ret;
 
 	if (fprog->len == 0 || fprog->len > BPF_MAXINSNS)
 		return ERR_PTR(-EINVAL);
 
 	BUG_ON(INT_MAX / fprog->len < sizeof(struct sock_filter));
-	fsize = bpf_classic_proglen(fprog);
 
 	/*
 	 * Installing a seccomp filter requires that the task has
@@ -367,37 +365,21 @@ static struct seccomp_filter *seccomp_prepare_filter(struct sock_fprog *fprog)
 				     CAP_SYS_ADMIN) != 0)
 		return ERR_PTR(-EACCES);
 
-	prog = bpf_prog_alloc(bpf_prog_size(fprog->len), 0);
-	if (!prog)
-		return ERR_PTR(-ENOMEM);
-
-	/* Copy the instructions from fprog. */
-	if (copy_from_user(prog->insns, fprog->filter, fsize)) {
-		__bpf_prog_free(prog);
-		return ERR_PTR(-EFAULT);
-	}
-
-	prog->len = fprog->len;
-
-	/* bpf_prepare_filter() already takes care of freeing
-	 * memory in case something goes wrong.
-	 */
-	prog = bpf_prepare_filter(prog, seccomp_check_filter);
-	if (IS_ERR(prog))
-		return ERR_CAST(prog);
-
 	/* Allocate a new seccomp_filter */
-	filter = kzalloc(sizeof(struct seccomp_filter),
-			 GFP_KERNEL|__GFP_NOWARN);
-	if (!filter) {
-		bpf_prog_destroy(prog);
+	sfilter = kzalloc(sizeof(*sfilter), GFP_KERNEL | __GFP_NOWARN);
+	if (!sfilter)
 		return ERR_PTR(-ENOMEM);
+
+	ret = bpf_prog_create_from_user(&sfilter->prog, fprog,
+					seccomp_check_filter);
+	if (ret < 0) {
+		kfree(sfilter);
+		return ERR_PTR(ret);
 	}
 
-	filter->prog = prog;
-	atomic_set(&filter->usage, 1);
+	atomic_set(&sfilter->usage, 1);
 
-	return filter;
+	return sfilter;
 }
 
 /**

commit d9e12f42e58da475379b9080708b94f2095904af
Author: Nicolas Schichan <nschichan@freebox.fr>
Date:   Wed May 6 16:12:28 2015 +0200

    seccomp: simplify seccomp_prepare_filter and reuse bpf_prepare_filter
    
    Remove the calls to bpf_check_classic(), bpf_convert_filter() and
    bpf_migrate_runtime() and let bpf_prepare_filter() take care of that
    instead.
    
    seccomp_check_filter() is passed to bpf_prepare_filter() so that it
    gets called from there, after bpf_check_classic().
    
    We can now remove exposure of two internal classic BPF functions
    previously used by seccomp. The export of bpf_check_classic() symbol,
    previously known as sk_chk_filter(), was there since pre git times,
    and no in-tree module was using it, therefore remove it.
    
    Joint work with Daniel Borkmann.
    
    Signed-off-by: Nicolas Schichan <nschichan@freebox.fr>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Alexei Starovoitov <ast@plumgrid.com>
    Cc: Kees Cook <keescook@chromium.org>
    Acked-by: Alexei Starovoitov <ast@plumgrid.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 4f44028943e6..93d40f7f3683 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -347,15 +347,14 @@ static inline void seccomp_sync_threads(void)
 static struct seccomp_filter *seccomp_prepare_filter(struct sock_fprog *fprog)
 {
 	struct seccomp_filter *filter;
-	unsigned long fp_size;
-	struct sock_filter *fp;
-	int new_len;
-	long ret;
+	struct bpf_prog *prog;
+	unsigned long fsize;
 
 	if (fprog->len == 0 || fprog->len > BPF_MAXINSNS)
 		return ERR_PTR(-EINVAL);
+
 	BUG_ON(INT_MAX / fprog->len < sizeof(struct sock_filter));
-	fp_size = fprog->len * sizeof(struct sock_filter);
+	fsize = bpf_classic_proglen(fprog);
 
 	/*
 	 * Installing a seccomp filter requires that the task has
@@ -368,60 +367,37 @@ static struct seccomp_filter *seccomp_prepare_filter(struct sock_fprog *fprog)
 				     CAP_SYS_ADMIN) != 0)
 		return ERR_PTR(-EACCES);
 
-	fp = kzalloc(fp_size, GFP_KERNEL|__GFP_NOWARN);
-	if (!fp)
+	prog = bpf_prog_alloc(bpf_prog_size(fprog->len), 0);
+	if (!prog)
 		return ERR_PTR(-ENOMEM);
 
 	/* Copy the instructions from fprog. */
-	ret = -EFAULT;
-	if (copy_from_user(fp, fprog->filter, fp_size))
-		goto free_prog;
-
-	/* Check and rewrite the fprog via the skb checker */
-	ret = bpf_check_classic(fp, fprog->len);
-	if (ret)
-		goto free_prog;
+	if (copy_from_user(prog->insns, fprog->filter, fsize)) {
+		__bpf_prog_free(prog);
+		return ERR_PTR(-EFAULT);
+	}
 
-	/* Check and rewrite the fprog for seccomp use */
-	ret = seccomp_check_filter(fp, fprog->len);
-	if (ret)
-		goto free_prog;
+	prog->len = fprog->len;
 
-	/* Convert 'sock_filter' insns to 'bpf_insn' insns */
-	ret = bpf_convert_filter(fp, fprog->len, NULL, &new_len);
-	if (ret)
-		goto free_prog;
+	/* bpf_prepare_filter() already takes care of freeing
+	 * memory in case something goes wrong.
+	 */
+	prog = bpf_prepare_filter(prog, seccomp_check_filter);
+	if (IS_ERR(prog))
+		return ERR_CAST(prog);
 
 	/* Allocate a new seccomp_filter */
-	ret = -ENOMEM;
 	filter = kzalloc(sizeof(struct seccomp_filter),
 			 GFP_KERNEL|__GFP_NOWARN);
-	if (!filter)
-		goto free_prog;
-
-	filter->prog = bpf_prog_alloc(bpf_prog_size(new_len), __GFP_NOWARN);
-	if (!filter->prog)
-		goto free_filter;
-
-	ret = bpf_convert_filter(fp, fprog->len, filter->prog->insnsi, &new_len);
-	if (ret)
-		goto free_filter_prog;
+	if (!filter) {
+		bpf_prog_destroy(prog);
+		return ERR_PTR(-ENOMEM);
+	}
 
-	kfree(fp);
+	filter->prog = prog;
 	atomic_set(&filter->usage, 1);
-	filter->prog->len = new_len;
-
-	bpf_prog_select_runtime(filter->prog);
 
 	return filter;
-
-free_filter_prog:
-	__bpf_prog_free(filter->prog);
-free_filter:
-	kfree(filter);
-free_prog:
-	kfree(fp);
-	return ERR_PTR(ret);
 }
 
 /**

commit 580c57f1076872ebc2427f898b927944ce170f2d
Author: Kees Cook <keescook@chromium.org>
Date:   Tue Feb 17 13:48:00 2015 -0800

    seccomp: cap SECCOMP_RET_ERRNO data to MAX_ERRNO
    
    The value resulting from the SECCOMP_RET_DATA mask could exceed MAX_ERRNO
    when setting errno during a SECCOMP_RET_ERRNO filter action.  This makes
    sure we have a reliable value being set, so that an invalid errno will not
    be ignored by userspace.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reported-by: Dmitry V. Levin <ldv@altlinux.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Will Drewry <wad@chromium.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 4ef9687ac115..4f44028943e6 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -629,7 +629,9 @@ static u32 __seccomp_phase1_filter(int this_syscall, struct seccomp_data *sd)
 
 	switch (action) {
 	case SECCOMP_RET_ERRNO:
-		/* Set the low-order 16-bits as a errno. */
+		/* Set low-order bits as an errno, capped at MAX_ERRNO. */
+		if (data > MAX_ERRNO)
+			data = MAX_ERRNO;
 		syscall_set_return_value(current, task_pt_regs(current),
 					 -data, 0);
 		goto skip;

commit ba1a96fc7ddcaf0c8d4a6752f6a70f080bc307ac
Merge: f1bfbd984b4e 1dcf74f6edfc
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Oct 14 02:27:06 2014 +0200

    Merge branch 'x86-seccomp-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 seccomp changes from Ingo Molnar:
     "This tree includes x86 seccomp filter speedups and related preparatory
      work, which touches core seccomp facilities as well.
    
      The main idea is to split seccomp into two phases, to be able to enter
      a simple fast path for syscalls with ptrace side effects.
    
      There's no substantial user-visible (and ABI) effects expected from
      this, except a change in how we emit a better audit record for
      SECCOMP_RET_TRACE events"
    
    * 'x86-seccomp-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86_64, entry: Use split-phase syscall_trace_enter for 64-bit syscalls
      x86_64, entry: Treat regs->ax the same in fastpath and slowpath syscalls
      x86: Split syscall_trace_enter into two phases
      x86, entry: Only call user_exit if TIF_NOHZ
      x86, x32, audit: Fix x32's AUDIT_ARCH wrt audit
      seccomp: Document two-phase seccomp and arch-provided seccomp_data
      seccomp: Allow arch code to provide seccomp_data
      seccomp: Refactor the filter callback and the API
      seccomp,x86,arm,mips,s390: Remove nr parameter from secure_computing

commit 60a3b2253c413cf601783b070507d7dd6620c954
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Tue Sep 2 22:53:44 2014 +0200

    net: bpf: make eBPF interpreter images read-only
    
    With eBPF getting more extended and exposure to user space is on it's way,
    hardening the memory range the interpreter uses to steer its command flow
    seems appropriate.  This patch moves the to be interpreted bytecode to
    read-only pages.
    
    In case we execute a corrupted BPF interpreter image for some reason e.g.
    caused by an attacker which got past a verifier stage, it would not only
    provide arbitrary read/write memory access but arbitrary function calls
    as well. After setting up the BPF interpreter image, its contents do not
    change until destruction time, thus we can setup the image on immutable
    made pages in order to mitigate modifications to that code. The idea
    is derived from commit 314beb9bcabf ("x86: bpf_jit_comp: secure bpf jit
    against spraying attacks").
    
    This is possible because bpf_prog is not part of sk_filter anymore.
    After setup bpf_prog cannot be altered during its life-time. This prevents
    any modifications to the entire bpf_prog structure (incl. function/JIT
    image pointer).
    
    Every eBPF program (including classic BPF that are migrated) have to call
    bpf_prog_select_runtime() to select either interpreter or a JIT image
    as a last setup step, and they all are being freed via bpf_prog_free(),
    including non-JIT. Therefore, we can easily integrate this into the
    eBPF life-time, plus since we directly allocate a bpf_prog, we have no
    performance penalty.
    
    Tested with seccomp and test_bpf testsuite in JIT/non-JIT mode and manual
    inspection of kernel_page_tables.  Brad Spengler proposed the same idea
    via Twitter during development of this patch.
    
    Joint work with Hannes Frederic Sowa.
    
    Suggested-by: Brad Spengler <spender@grsecurity.net>
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Cc: Alexei Starovoitov <ast@plumgrid.com>
    Cc: Kees Cook <keescook@chromium.org>
    Acked-by: Alexei Starovoitov <ast@plumgrid.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 44eb005c6695..84922befea84 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -395,16 +395,15 @@ static struct seccomp_filter *seccomp_prepare_filter(struct sock_fprog *fprog)
 	if (!filter)
 		goto free_prog;
 
-	filter->prog = kzalloc(bpf_prog_size(new_len),
-			       GFP_KERNEL|__GFP_NOWARN);
+	filter->prog = bpf_prog_alloc(bpf_prog_size(new_len), __GFP_NOWARN);
 	if (!filter->prog)
 		goto free_filter;
 
 	ret = bpf_convert_filter(fp, fprog->len, filter->prog->insnsi, &new_len);
 	if (ret)
 		goto free_filter_prog;
-	kfree(fp);
 
+	kfree(fp);
 	atomic_set(&filter->usage, 1);
 	filter->prog->len = new_len;
 
@@ -413,7 +412,7 @@ static struct seccomp_filter *seccomp_prepare_filter(struct sock_fprog *fprog)
 	return filter;
 
 free_filter_prog:
-	kfree(filter->prog);
+	__bpf_prog_free(filter->prog);
 free_filter:
 	kfree(filter);
 free_prog:

commit d39bd00deabe57420f2a3669eb71b0e0c4997184
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Mon Jul 21 18:49:16 2014 -0700

    seccomp: Allow arch code to provide seccomp_data
    
    populate_seccomp_data is expensive: it works by inspecting
    task_pt_regs and various other bits to piece together all the
    information, and it's does so in multiple partially redundant steps.
    
    Arch-specific code in the syscall entry path can do much better.
    
    Admittedly this adds a bit of additional room for error, but the
    speedup should be worth it.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 6c8528ce9df9..1285cb205d49 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -173,10 +173,10 @@ static int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)
  *
  * Returns valid seccomp BPF response codes.
  */
-static u32 seccomp_run_filters(void)
+static u32 seccomp_run_filters(struct seccomp_data *sd)
 {
 	struct seccomp_filter *f = ACCESS_ONCE(current->seccomp.filter);
-	struct seccomp_data sd;
+	struct seccomp_data sd_local;
 	u32 ret = SECCOMP_RET_ALLOW;
 
 	/* Ensure unexpected behavior doesn't result in failing open. */
@@ -186,14 +186,17 @@ static u32 seccomp_run_filters(void)
 	/* Make sure cross-thread synced filter points somewhere sane. */
 	smp_read_barrier_depends();
 
-	populate_seccomp_data(&sd);
+	if (!sd) {
+		populate_seccomp_data(&sd_local);
+		sd = &sd_local;
+	}
 
 	/*
 	 * All filters in the list are evaluated and the lowest BPF return
 	 * value always takes priority (ignoring the DATA).
 	 */
 	for (; f; f = f->prev) {
-		u32 cur_ret = BPF_PROG_RUN(f->prog, (void *)&sd);
+		u32 cur_ret = BPF_PROG_RUN(f->prog, (void *)sd);
 
 		if ((cur_ret & SECCOMP_RET_ACTION) < (ret & SECCOMP_RET_ACTION))
 			ret = cur_ret;
@@ -599,7 +602,7 @@ void secure_computing_strict(int this_syscall)
 #else
 int __secure_computing(void)
 {
-	u32 phase1_result = seccomp_phase1();
+	u32 phase1_result = seccomp_phase1(NULL);
 
 	if (likely(phase1_result == SECCOMP_PHASE1_OK))
 		return 0;
@@ -610,7 +613,7 @@ int __secure_computing(void)
 }
 
 #ifdef CONFIG_SECCOMP_FILTER
-static u32 __seccomp_phase1_filter(int this_syscall, struct pt_regs *regs)
+static u32 __seccomp_phase1_filter(int this_syscall, struct seccomp_data *sd)
 {
 	u32 filter_ret, action;
 	int data;
@@ -621,20 +624,20 @@ static u32 __seccomp_phase1_filter(int this_syscall, struct pt_regs *regs)
 	 */
 	rmb();
 
-	filter_ret = seccomp_run_filters();
+	filter_ret = seccomp_run_filters(sd);
 	data = filter_ret & SECCOMP_RET_DATA;
 	action = filter_ret & SECCOMP_RET_ACTION;
 
 	switch (action) {
 	case SECCOMP_RET_ERRNO:
 		/* Set the low-order 16-bits as a errno. */
-		syscall_set_return_value(current, regs,
+		syscall_set_return_value(current, task_pt_regs(current),
 					 -data, 0);
 		goto skip;
 
 	case SECCOMP_RET_TRAP:
 		/* Show the handler the original registers. */
-		syscall_rollback(current, regs);
+		syscall_rollback(current, task_pt_regs(current));
 		/* Let the filter pass back 16 bits of data. */
 		seccomp_send_sigsys(this_syscall, data);
 		goto skip;
@@ -661,11 +664,14 @@ static u32 __seccomp_phase1_filter(int this_syscall, struct pt_regs *regs)
 
 /**
  * seccomp_phase1() - run fast path seccomp checks on the current syscall
+ * @arg sd: The seccomp_data or NULL
  *
  * This only reads pt_regs via the syscall_xyz helpers.  The only change
  * it will make to pt_regs is via syscall_set_return_value, and it will
  * only do that if it returns SECCOMP_PHASE1_SKIP.
  *
+ * If sd is provided, it will not read pt_regs at all.
+ *
  * It may also call do_exit or force a signal; these actions must be
  * safe.
  *
@@ -679,11 +685,11 @@ static u32 __seccomp_phase1_filter(int this_syscall, struct pt_regs *regs)
  * If it returns anything else, then the return value should be passed
  * to seccomp_phase2 from a context in which ptrace hooks are safe.
  */
-u32 seccomp_phase1(void)
+u32 seccomp_phase1(struct seccomp_data *sd)
 {
 	int mode = current->seccomp.mode;
-	struct pt_regs *regs = task_pt_regs(current);
-	int this_syscall = syscall_get_nr(current, regs);
+	int this_syscall = sd ? sd->nr :
+		syscall_get_nr(current, task_pt_regs(current));
 
 	switch (mode) {
 	case SECCOMP_MODE_STRICT:
@@ -691,7 +697,7 @@ u32 seccomp_phase1(void)
 		return SECCOMP_PHASE1_OK;
 #ifdef CONFIG_SECCOMP_FILTER
 	case SECCOMP_MODE_FILTER:
-		return __seccomp_phase1_filter(this_syscall, regs);
+		return __seccomp_phase1_filter(this_syscall, sd);
 #endif
 	default:
 		BUG();

commit 13aa72f0fd0a9f98a41cefb662487269e2f1ad65
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Mon Jul 21 18:49:15 2014 -0700

    seccomp: Refactor the filter callback and the API
    
    The reason I did this is to add a seccomp API that will be usable
    for an x86 fast path.  The x86 entry code needs to use a rather
    expensive slow path for a syscall that might be visible to things
    like ptrace.  By splitting seccomp into two phases, we can check
    whether we need the slow path and then use the fast path in if the
    filter allows the syscall or just returns some errno.
    
    As a side effect, I think the new code is much easier to understand
    than the old code.
    
    This has one user-visible effect: the audit record written for
    SECCOMP_RET_TRACE is now a simple indication that SECCOMP_RET_TRACE
    happened.  It used to depend in a complicated way on what the tracer
    did.  I couldn't make much sense of it.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 5e738e0dd2e9..6c8528ce9df9 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -21,8 +21,6 @@
 #include <linux/slab.h>
 #include <linux/syscalls.h>
 
-/* #define SECCOMP_DEBUG 1 */
-
 #ifdef CONFIG_HAVE_ARCH_SECCOMP_FILTER
 #include <asm/syscall.h>
 #endif
@@ -601,10 +599,21 @@ void secure_computing_strict(int this_syscall)
 #else
 int __secure_computing(void)
 {
-	struct pt_regs *regs = task_pt_regs(current);
-	int this_syscall = syscall_get_nr(current, regs);
-	int exit_sig = 0;
-	u32 ret;
+	u32 phase1_result = seccomp_phase1();
+
+	if (likely(phase1_result == SECCOMP_PHASE1_OK))
+		return 0;
+	else if (likely(phase1_result == SECCOMP_PHASE1_SKIP))
+		return -1;
+	else
+		return seccomp_phase2(phase1_result);
+}
+
+#ifdef CONFIG_SECCOMP_FILTER
+static u32 __seccomp_phase1_filter(int this_syscall, struct pt_regs *regs)
+{
+	u32 filter_ret, action;
+	int data;
 
 	/*
 	 * Make sure that any changes to mode from another thread have
@@ -612,73 +621,122 @@ int __secure_computing(void)
 	 */
 	rmb();
 
-	switch (current->seccomp.mode) {
+	filter_ret = seccomp_run_filters();
+	data = filter_ret & SECCOMP_RET_DATA;
+	action = filter_ret & SECCOMP_RET_ACTION;
+
+	switch (action) {
+	case SECCOMP_RET_ERRNO:
+		/* Set the low-order 16-bits as a errno. */
+		syscall_set_return_value(current, regs,
+					 -data, 0);
+		goto skip;
+
+	case SECCOMP_RET_TRAP:
+		/* Show the handler the original registers. */
+		syscall_rollback(current, regs);
+		/* Let the filter pass back 16 bits of data. */
+		seccomp_send_sigsys(this_syscall, data);
+		goto skip;
+
+	case SECCOMP_RET_TRACE:
+		return filter_ret;  /* Save the rest for phase 2. */
+
+	case SECCOMP_RET_ALLOW:
+		return SECCOMP_PHASE1_OK;
+
+	case SECCOMP_RET_KILL:
+	default:
+		audit_seccomp(this_syscall, SIGSYS, action);
+		do_exit(SIGSYS);
+	}
+
+	unreachable();
+
+skip:
+	audit_seccomp(this_syscall, 0, action);
+	return SECCOMP_PHASE1_SKIP;
+}
+#endif
+
+/**
+ * seccomp_phase1() - run fast path seccomp checks on the current syscall
+ *
+ * This only reads pt_regs via the syscall_xyz helpers.  The only change
+ * it will make to pt_regs is via syscall_set_return_value, and it will
+ * only do that if it returns SECCOMP_PHASE1_SKIP.
+ *
+ * It may also call do_exit or force a signal; these actions must be
+ * safe.
+ *
+ * If it returns SECCOMP_PHASE1_OK, the syscall passes checks and should
+ * be processed normally.
+ *
+ * If it returns SECCOMP_PHASE1_SKIP, then the syscall should not be
+ * invoked.  In this case, seccomp_phase1 will have set the return value
+ * using syscall_set_return_value.
+ *
+ * If it returns anything else, then the return value should be passed
+ * to seccomp_phase2 from a context in which ptrace hooks are safe.
+ */
+u32 seccomp_phase1(void)
+{
+	int mode = current->seccomp.mode;
+	struct pt_regs *regs = task_pt_regs(current);
+	int this_syscall = syscall_get_nr(current, regs);
+
+	switch (mode) {
 	case SECCOMP_MODE_STRICT:
-		__secure_computing_strict(this_syscall);
-		return 0;
+		__secure_computing_strict(this_syscall);  /* may call do_exit */
+		return SECCOMP_PHASE1_OK;
 #ifdef CONFIG_SECCOMP_FILTER
-	case SECCOMP_MODE_FILTER: {
-		int data;
-		ret = seccomp_run_filters();
-		data = ret & SECCOMP_RET_DATA;
-		ret &= SECCOMP_RET_ACTION;
-		switch (ret) {
-		case SECCOMP_RET_ERRNO:
-			/* Set the low-order 16-bits as a errno. */
-			syscall_set_return_value(current, regs,
-						 -data, 0);
-			goto skip;
-		case SECCOMP_RET_TRAP:
-			/* Show the handler the original registers. */
-			syscall_rollback(current, regs);
-			/* Let the filter pass back 16 bits of data. */
-			seccomp_send_sigsys(this_syscall, data);
-			goto skip;
-		case SECCOMP_RET_TRACE:
-			/* Skip these calls if there is no tracer. */
-			if (!ptrace_event_enabled(current, PTRACE_EVENT_SECCOMP)) {
-				syscall_set_return_value(current, regs,
-							 -ENOSYS, 0);
-				goto skip;
-			}
-			/* Allow the BPF to provide the event message */
-			ptrace_event(PTRACE_EVENT_SECCOMP, data);
-			/*
-			 * The delivery of a fatal signal during event
-			 * notification may silently skip tracer notification.
-			 * Terminating the task now avoids executing a system
-			 * call that may not be intended.
-			 */
-			if (fatal_signal_pending(current))
-				break;
-			if (syscall_get_nr(current, regs) < 0)
-				goto skip;  /* Explicit request to skip. */
-
-			return 0;
-		case SECCOMP_RET_ALLOW:
-			return 0;
-		case SECCOMP_RET_KILL:
-		default:
-			break;
-		}
-		exit_sig = SIGSYS;
-		break;
-	}
+	case SECCOMP_MODE_FILTER:
+		return __seccomp_phase1_filter(this_syscall, regs);
 #endif
 	default:
 		BUG();
 	}
+}
 
-#ifdef SECCOMP_DEBUG
-	dump_stack();
-#endif
-	audit_seccomp(this_syscall, exit_sig, ret);
-	do_exit(exit_sig);
-#ifdef CONFIG_SECCOMP_FILTER
-skip:
-	audit_seccomp(this_syscall, exit_sig, ret);
-	return -1;
-#endif
+/**
+ * seccomp_phase2() - finish slow path seccomp work for the current syscall
+ * @phase1_result: The return value from seccomp_phase1()
+ *
+ * This must be called from a context in which ptrace hooks can be used.
+ *
+ * Returns 0 if the syscall should be processed or -1 to skip the syscall.
+ */
+int seccomp_phase2(u32 phase1_result)
+{
+	struct pt_regs *regs = task_pt_regs(current);
+	u32 action = phase1_result & SECCOMP_RET_ACTION;
+	int data = phase1_result & SECCOMP_RET_DATA;
+
+	BUG_ON(action != SECCOMP_RET_TRACE);
+
+	audit_seccomp(syscall_get_nr(current, regs), 0, action);
+
+	/* Skip these calls if there is no tracer. */
+	if (!ptrace_event_enabled(current, PTRACE_EVENT_SECCOMP)) {
+		syscall_set_return_value(current, regs,
+					 -ENOSYS, 0);
+		return -1;
+	}
+
+	/* Allow the BPF to provide the event message */
+	ptrace_event(PTRACE_EVENT_SECCOMP, data);
+	/*
+	 * The delivery of a fatal signal during event
+	 * notification may silently skip tracer notification.
+	 * Terminating the task now avoids executing a system
+	 * call that may not be intended.
+	 */
+	if (fatal_signal_pending(current))
+		do_exit(SIGSYS);
+	if (syscall_get_nr(current, regs) < 0)
+		return -1;  /* Explicit request to skip. */
+
+	return 0;
 }
 #endif /* CONFIG_HAVE_ARCH_SECCOMP_FILTER */
 

commit a4412fc9486ec85686c6c7929e7e829f62ae377e
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Mon Jul 21 18:49:14 2014 -0700

    seccomp,x86,arm,mips,s390: Remove nr parameter from secure_computing
    
    The secure_computing function took a syscall number parameter, but
    it only paid any attention to that parameter if seccomp mode 1 was
    enabled.  Rather than coming up with a kludge to get the parameter
    to work in mode 2, just remove the parameter.
    
    To avoid churn in arches that don't have seccomp filters (and may
    not even support syscall_get_nr right now), this leaves the
    parameter in secure_computing_strict, which is now a real function.
    
    For ARM, this is a bit ugly due to the fact that ARM conditionally
    supports seccomp filters.  Fixing that would probably only be a
    couple of lines of code, but it should be coordinated with the audit
    maintainers.
    
    This will be a slight slowdown on some arches.  The right fix is to
    pass in all of seccomp_data instead of trying to make just the
    syscall nr part be fast.
    
    This is a prerequisite for making two-phase seccomp work cleanly.
    
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: linux-mips@linux-mips.org
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: linux-s390@vger.kernel.org
    Cc: x86@kernel.org
    Cc: Kees Cook <keescook@chromium.org>
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 44eb005c6695..5e738e0dd2e9 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -23,8 +23,11 @@
 
 /* #define SECCOMP_DEBUG 1 */
 
-#ifdef CONFIG_SECCOMP_FILTER
+#ifdef CONFIG_HAVE_ARCH_SECCOMP_FILTER
 #include <asm/syscall.h>
+#endif
+
+#ifdef CONFIG_SECCOMP_FILTER
 #include <linux/filter.h>
 #include <linux/pid.h>
 #include <linux/ptrace.h>
@@ -172,7 +175,7 @@ static int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)
  *
  * Returns valid seccomp BPF response codes.
  */
-static u32 seccomp_run_filters(int syscall)
+static u32 seccomp_run_filters(void)
 {
 	struct seccomp_filter *f = ACCESS_ONCE(current->seccomp.filter);
 	struct seccomp_data sd;
@@ -564,10 +567,43 @@ static int mode1_syscalls_32[] = {
 };
 #endif
 
-int __secure_computing(int this_syscall)
+static void __secure_computing_strict(int this_syscall)
+{
+	int *syscall_whitelist = mode1_syscalls;
+#ifdef CONFIG_COMPAT
+	if (is_compat_task())
+		syscall_whitelist = mode1_syscalls_32;
+#endif
+	do {
+		if (*syscall_whitelist == this_syscall)
+			return;
+	} while (*++syscall_whitelist);
+
+#ifdef SECCOMP_DEBUG
+	dump_stack();
+#endif
+	audit_seccomp(this_syscall, SIGKILL, SECCOMP_RET_KILL);
+	do_exit(SIGKILL);
+}
+
+#ifndef CONFIG_HAVE_ARCH_SECCOMP_FILTER
+void secure_computing_strict(int this_syscall)
+{
+	int mode = current->seccomp.mode;
+
+	if (mode == 0)
+		return;
+	else if (mode == SECCOMP_MODE_STRICT)
+		__secure_computing_strict(this_syscall);
+	else
+		BUG();
+}
+#else
+int __secure_computing(void)
 {
+	struct pt_regs *regs = task_pt_regs(current);
+	int this_syscall = syscall_get_nr(current, regs);
 	int exit_sig = 0;
-	int *syscall;
 	u32 ret;
 
 	/*
@@ -578,23 +614,12 @@ int __secure_computing(int this_syscall)
 
 	switch (current->seccomp.mode) {
 	case SECCOMP_MODE_STRICT:
-		syscall = mode1_syscalls;
-#ifdef CONFIG_COMPAT
-		if (is_compat_task())
-			syscall = mode1_syscalls_32;
-#endif
-		do {
-			if (*syscall == this_syscall)
-				return 0;
-		} while (*++syscall);
-		exit_sig = SIGKILL;
-		ret = SECCOMP_RET_KILL;
-		break;
+		__secure_computing_strict(this_syscall);
+		return 0;
 #ifdef CONFIG_SECCOMP_FILTER
 	case SECCOMP_MODE_FILTER: {
 		int data;
-		struct pt_regs *regs = task_pt_regs(current);
-		ret = seccomp_run_filters(this_syscall);
+		ret = seccomp_run_filters();
 		data = ret & SECCOMP_RET_DATA;
 		ret &= SECCOMP_RET_ACTION;
 		switch (ret) {
@@ -652,9 +677,10 @@ int __secure_computing(int this_syscall)
 #ifdef CONFIG_SECCOMP_FILTER
 skip:
 	audit_seccomp(this_syscall, exit_sig, ret);
-#endif
 	return -1;
+#endif
 }
+#endif /* CONFIG_HAVE_ARCH_SECCOMP_FILTER */
 
 long prctl_get_seccomp(void)
 {

commit 69f6a34bdeea4fec50bb90619bc9602973119572
Author: Guenter Roeck <linux@roeck-us.net>
Date:   Sun Aug 10 20:50:30 2014 -0700

    seccomp: Replace BUG(!spin_is_locked()) with assert_spin_lock
    
    Current upstream kernel hangs with mips and powerpc targets in
    uniprocessor mode if SECCOMP is configured.
    
    Bisect points to commit dbd952127d11 ("seccomp: introduce writer locking").
    Turns out that code such as
            BUG_ON(!spin_is_locked(&list_lock));
    can not be used in uniprocessor mode because spin_is_locked() always
    returns false in this configuration, and that assert_spin_locked()
    exists for that very purpose and must be used instead.
    
    Fixes: dbd952127d11 ("seccomp: introduce writer locking")
    Cc: Kees Cook <keescook@chromium.org>
    Signed-off-by: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 25b0043f4755..44eb005c6695 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -203,7 +203,7 @@ static u32 seccomp_run_filters(int syscall)
 
 static inline bool seccomp_may_assign_mode(unsigned long seccomp_mode)
 {
-	BUG_ON(!spin_is_locked(&current->sighand->siglock));
+	assert_spin_locked(&current->sighand->siglock);
 
 	if (current->seccomp.mode && current->seccomp.mode != seccomp_mode)
 		return false;
@@ -214,7 +214,7 @@ static inline bool seccomp_may_assign_mode(unsigned long seccomp_mode)
 static inline void seccomp_assign_mode(struct task_struct *task,
 				       unsigned long seccomp_mode)
 {
-	BUG_ON(!spin_is_locked(&task->sighand->siglock));
+	assert_spin_locked(&task->sighand->siglock);
 
 	task->seccomp.mode = seccomp_mode;
 	/*
@@ -253,7 +253,7 @@ static inline pid_t seccomp_can_sync_threads(void)
 	struct task_struct *thread, *caller;
 
 	BUG_ON(!mutex_is_locked(&current->signal->cred_guard_mutex));
-	BUG_ON(!spin_is_locked(&current->sighand->siglock));
+	assert_spin_locked(&current->sighand->siglock);
 
 	/* Validate all threads being eligible for synchronization. */
 	caller = current;
@@ -294,7 +294,7 @@ static inline void seccomp_sync_threads(void)
 	struct task_struct *thread, *caller;
 
 	BUG_ON(!mutex_is_locked(&current->signal->cred_guard_mutex));
-	BUG_ON(!spin_is_locked(&current->sighand->siglock));
+	assert_spin_locked(&current->sighand->siglock);
 
 	/* Synchronize all threads. */
 	caller = current;
@@ -464,7 +464,7 @@ static long seccomp_attach_filter(unsigned int flags,
 	unsigned long total_insns;
 	struct seccomp_filter *walker;
 
-	BUG_ON(!spin_is_locked(&current->sighand->siglock));
+	assert_spin_locked(&current->sighand->siglock);
 
 	/* Validate resulting filter length. */
 	total_insns = filter->prog->len;

commit ae045e2455429c418a418a3376301a9e5753a0a8
Merge: f4f142ed4ef8 d247b6ab3ce6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Aug 6 09:38:14 2014 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking updates from David Miller:
     "Highlights:
    
       1) Steady transitioning of the BPF instructure to a generic spot so
          all kernel subsystems can make use of it, from Alexei Starovoitov.
    
       2) SFC driver supports busy polling, from Alexandre Rames.
    
       3) Take advantage of hash table in UDP multicast delivery, from David
          Held.
    
       4) Lighten locking, in particular by getting rid of the LRU lists, in
          inet frag handling.  From Florian Westphal.
    
       5) Add support for various RFC6458 control messages in SCTP, from
          Geir Ola Vaagland.
    
       6) Allow to filter bridge forwarding database dumps by device, from
          Jamal Hadi Salim.
    
       7) virtio-net also now supports busy polling, from Jason Wang.
    
       8) Some low level optimization tweaks in pktgen from Jesper Dangaard
          Brouer.
    
       9) Add support for ipv6 address generation modes, so that userland
          can have some input into the process.  From Jiri Pirko.
    
      10) Consolidate common TCP connection request code in ipv4 and ipv6,
          from Octavian Purdila.
    
      11) New ARP packet logger in netfilter, from Pablo Neira Ayuso.
    
      12) Generic resizable RCU hash table, with intial users in netlink and
          nftables.  From Thomas Graf.
    
      13) Maintain a name assignment type so that userspace can see where a
          network device name came from (enumerated by kernel, assigned
          explicitly by userspace, etc.) From Tom Gundersen.
    
      14) Automatic flow label generation on transmit in ipv6, from Tom
          Herbert.
    
      15) New packet timestamping facilities from Willem de Bruijn, meant to
          assist in measuring latencies going into/out-of the packet
          scheduler, latency from TCP data transmission to ACK, etc"
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next: (1536 commits)
      cxgb4 : Disable recursive mailbox commands when enabling vi
      net: reduce USB network driver config options.
      tg3: Modify tg3_tso_bug() to handle multiple TX rings
      amd-xgbe: Perform phy connect/disconnect at dev open/stop
      amd-xgbe: Use dma_set_mask_and_coherent to set DMA mask
      net: sun4i-emac: fix memory leak on bad packet
      sctp: fix possible seqlock seadlock in sctp_packet_transmit()
      Revert "net: phy: Set the driver when registering an MDIO bus device"
      cxgb4vf: Turn off SGE RX/TX Callback Timers and interrupts in PCI shutdown routine
      team: Simplify return path of team_newlink
      bridge: Update outdated comment on promiscuous mode
      net-timestamp: ACK timestamp for bytestreams
      net-timestamp: TCP timestamping
      net-timestamp: SCHED timestamp on entering packet scheduler
      net-timestamp: add key to disambiguate concurrent datagrams
      net-timestamp: move timestamp flags out of sk_flags
      net-timestamp: extend SCM_TIMESTAMPING ancillary data struct
      cxgb4i : Move stray CPL definitions to cxgb4 driver
      tcp: reduce spurious retransmits due to transient SACK reneging
      qlcnic: Initialize dcbnl_ops before register_netdev
      ...

commit 7ae457c1e5b45a1b826fad9d62b32191d2bdcfdb
Author: Alexei Starovoitov <ast@plumgrid.com>
Date:   Wed Jul 30 20:34:16 2014 -0700

    net: filter: split 'struct sk_filter' into socket and bpf parts
    
    clean up names related to socket filtering and bpf in the following way:
    - everything that deals with sockets keeps 'sk_*' prefix
    - everything that is pure BPF is changed to 'bpf_*' prefix
    
    split 'struct sk_filter' into
    struct sk_filter {
            atomic_t        refcnt;
            struct rcu_head rcu;
            struct bpf_prog *prog;
    };
    and
    struct bpf_prog {
            u32                     jited:1,
                                    len:31;
            struct sock_fprog_kern  *orig_prog;
            unsigned int            (*bpf_func)(const struct sk_buff *skb,
                                                const struct bpf_insn *filter);
            union {
                    struct sock_filter      insns[0];
                    struct bpf_insn         insnsi[0];
                    struct work_struct      work;
            };
    };
    so that 'struct bpf_prog' can be used independent of sockets and cleans up
    'unattached' bpf use cases
    
    split SK_RUN_FILTER macro into:
        SK_RUN_FILTER to be used with 'struct sk_filter *' and
        BPF_PROG_RUN to be used with 'struct bpf_prog *'
    
    __sk_filter_release(struct sk_filter *) gains
    __bpf_prog_release(struct bpf_prog *) helper function
    
    also perform related renames for the functions that work
    with 'struct bpf_prog *', since they're on the same lines:
    
    sk_filter_size -> bpf_prog_size
    sk_filter_select_runtime -> bpf_prog_select_runtime
    sk_filter_free -> bpf_prog_free
    sk_unattached_filter_create -> bpf_prog_create
    sk_unattached_filter_destroy -> bpf_prog_destroy
    sk_store_orig_filter -> bpf_prog_store_orig_filter
    sk_release_orig_filter -> bpf_release_orig_filter
    __sk_migrate_filter -> bpf_migrate_filter
    __sk_prepare_filter -> bpf_prepare_filter
    
    API for attaching classic BPF to a socket stays the same:
    sk_attach_filter(prog, struct sock *)/sk_detach_filter(struct sock *)
    and SK_RUN_FILTER(struct sk_filter *, ctx) to execute a program
    which is used by sockets, tun, af_packet
    
    API for 'unattached' BPF programs becomes:
    bpf_prog_create(struct bpf_prog **)/bpf_prog_destroy(struct bpf_prog *)
    and BPF_PROG_RUN(struct bpf_prog *, ctx) to execute a program
    which is used by isdn, ppp, team, seccomp, ptp, xt_bpf, cls_bpf, test_bpf
    
    Signed-off-by: Alexei Starovoitov <ast@plumgrid.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 33a3a97e2b58..2f3fa2cc2eac 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -54,7 +54,7 @@
 struct seccomp_filter {
 	atomic_t usage;
 	struct seccomp_filter *prev;
-	struct sk_filter *prog;
+	struct bpf_prog *prog;
 };
 
 /* Limit any path through the tree to 256KB worth of instructions. */
@@ -187,7 +187,7 @@ static u32 seccomp_run_filters(int syscall)
 	 * value always takes priority (ignoring the DATA).
 	 */
 	for (f = current->seccomp.filter; f; f = f->prev) {
-		u32 cur_ret = SK_RUN_FILTER(f->prog, (void *)&sd);
+		u32 cur_ret = BPF_PROG_RUN(f->prog, (void *)&sd);
 
 		if ((cur_ret & SECCOMP_RET_ACTION) < (ret & SECCOMP_RET_ACTION))
 			ret = cur_ret;
@@ -260,7 +260,7 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 	if (!filter)
 		goto free_prog;
 
-	filter->prog = kzalloc(sk_filter_size(new_len),
+	filter->prog = kzalloc(bpf_prog_size(new_len),
 			       GFP_KERNEL|__GFP_NOWARN);
 	if (!filter->prog)
 		goto free_filter;
@@ -273,7 +273,7 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 	atomic_set(&filter->usage, 1);
 	filter->prog->len = new_len;
 
-	sk_filter_select_runtime(filter->prog);
+	bpf_prog_select_runtime(filter->prog);
 
 	/*
 	 * If there is an existing filter, make it the prev and don't drop its
@@ -337,7 +337,7 @@ void put_seccomp_filter(struct task_struct *tsk)
 	while (orig && atomic_dec_and_test(&orig->usage)) {
 		struct seccomp_filter *freeme = orig;
 		orig = orig->prev;
-		sk_filter_free(freeme->prog);
+		bpf_prog_free(freeme->prog);
 		kfree(freeme);
 	}
 }

commit 8fb575ca396bc31d9fa99c26336e2432b41d1bfc
Author: Alexei Starovoitov <ast@plumgrid.com>
Date:   Wed Jul 30 20:34:15 2014 -0700

    net: filter: rename sk_convert_filter() -> bpf_convert_filter()
    
    to indicate that this function is converting classic BPF into eBPF
    and not related to sockets
    
    Signed-off-by: Alexei Starovoitov <ast@plumgrid.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index f4a77d23f209..33a3a97e2b58 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -249,7 +249,7 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 		goto free_prog;
 
 	/* Convert 'sock_filter' insns to 'bpf_insn' insns */
-	ret = sk_convert_filter(fp, fprog->len, NULL, &new_len);
+	ret = bpf_convert_filter(fp, fprog->len, NULL, &new_len);
 	if (ret)
 		goto free_prog;
 
@@ -265,7 +265,7 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 	if (!filter->prog)
 		goto free_filter;
 
-	ret = sk_convert_filter(fp, fprog->len, filter->prog->insnsi, &new_len);
+	ret = bpf_convert_filter(fp, fprog->len, filter->prog->insnsi, &new_len);
 	if (ret)
 		goto free_filter_prog;
 	kfree(fp);

commit 4df95ff488eb796aab9566652c250330179def17
Author: Alexei Starovoitov <ast@plumgrid.com>
Date:   Wed Jul 30 20:34:14 2014 -0700

    net: filter: rename sk_chk_filter() -> bpf_check_classic()
    
    trivial rename to indicate that this functions performs classic BPF checking
    
    Signed-off-by: Alexei Starovoitov <ast@plumgrid.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 565743db5384..f4a77d23f209 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -87,7 +87,7 @@ static void populate_seccomp_data(struct seccomp_data *sd)
  *	@filter: filter to verify
  *	@flen: length of filter
  *
- * Takes a previously checked filter (by sk_chk_filter) and
+ * Takes a previously checked filter (by bpf_check_classic) and
  * redirects all filter code that loads struct sk_buff data
  * and related data through seccomp_bpf_load.  It also
  * enforces length and alignment checking of those loads.
@@ -239,7 +239,7 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 		goto free_prog;
 
 	/* Check and rewrite the fprog via the skb checker */
-	ret = sk_chk_filter(fp, fprog->len);
+	ret = bpf_check_classic(fp, fprog->len);
 	if (ret)
 		goto free_prog;
 

commit 2695fb552cbef1029aa025a98acb80cc51d66de5
Author: Alexei Starovoitov <ast@plumgrid.com>
Date:   Thu Jul 24 16:38:21 2014 -0700

    net: filter: rename 'struct sock_filter_int' into 'struct bpf_insn'
    
    eBPF is used by socket filtering, seccomp and soon by tracing and
    exposed to userspace, therefore 'sock_filter_int' name is not accurate.
    Rename it to 'bpf_insn'
    
    Signed-off-by: Alexei Starovoitov <ast@plumgrid.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 301bbc24739c..565743db5384 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -248,7 +248,7 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 	if (ret)
 		goto free_prog;
 
-	/* Convert 'sock_filter' insns to 'sock_filter_int' insns */
+	/* Convert 'sock_filter' insns to 'bpf_insn' insns */
 	ret = sk_convert_filter(fp, fprog->len, NULL, &new_len);
 	if (ret)
 		goto free_prog;

commit c2e1f2e30daa551db3c670c0ccfeab20a540b9e1
Author: Kees Cook <keescook@chromium.org>
Date:   Thu Jun 5 00:23:17 2014 -0700

    seccomp: implement SECCOMP_FILTER_FLAG_TSYNC
    
    Applying restrictive seccomp filter programs to large or diverse
    codebases often requires handling threads which may be started early in
    the process lifetime (e.g., by code that is linked in). While it is
    possible to apply permissive programs prior to process start up, it is
    difficult to further restrict the kernel ABI to those threads after that
    point.
    
    This change adds a new seccomp syscall flag to SECCOMP_SET_MODE_FILTER for
    synchronizing thread group seccomp filters at filter installation time.
    
    When calling seccomp(SECCOMP_SET_MODE_FILTER, SECCOMP_FILTER_FLAG_TSYNC,
    filter) an attempt will be made to synchronize all threads in current's
    threadgroup to its new seccomp filter program. This is possible iff all
    threads are using a filter that is an ancestor to the filter current is
    attempting to synchronize to. NULL filters (where the task is running as
    SECCOMP_MODE_NONE) are also treated as ancestors allowing threads to be
    transitioned into SECCOMP_MODE_FILTER. If prctrl(PR_SET_NO_NEW_PRIVS,
    ...) has been set on the calling thread, no_new_privs will be set for
    all synchronized threads too. On success, 0 is returned. On failure,
    the pid of one of the failing threads will be returned and no filters
    will have been applied.
    
    The race conditions against another thread are:
    - requesting TSYNC (already handled by sighand lock)
    - performing a clone (already handled by sighand lock)
    - changing its filter (already handled by sighand lock)
    - calling exec (handled by cred_guard_mutex)
    The clone case is assisted by the fact that new threads will have their
    seccomp state duplicated from their parent before appearing on the tasklist.
    
    Holding cred_guard_mutex means that seccomp filters cannot be assigned
    while in the middle of another thread's exec (potentially bypassing
    no_new_privs or similar). The call to de_thread() may kill threads waiting
    for the mutex.
    
    Changes across threads to the filter pointer includes a barrier.
    
    Based on patches by Will Drewry.
    
    Suggested-by: Julien Tinnes <jln@chromium.org>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Andy Lutomirski <luto@amacapital.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 9065d2c79c56..74f460179171 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -26,6 +26,7 @@
 #ifdef CONFIG_SECCOMP_FILTER
 #include <asm/syscall.h>
 #include <linux/filter.h>
+#include <linux/pid.h>
 #include <linux/ptrace.h>
 #include <linux/security.h>
 #include <linux/tracehook.h>
@@ -225,6 +226,114 @@ static inline void seccomp_assign_mode(struct task_struct *task,
 }
 
 #ifdef CONFIG_SECCOMP_FILTER
+/* Returns 1 if the parent is an ancestor of the child. */
+static int is_ancestor(struct seccomp_filter *parent,
+		       struct seccomp_filter *child)
+{
+	/* NULL is the root ancestor. */
+	if (parent == NULL)
+		return 1;
+	for (; child; child = child->prev)
+		if (child == parent)
+			return 1;
+	return 0;
+}
+
+/**
+ * seccomp_can_sync_threads: checks if all threads can be synchronized
+ *
+ * Expects sighand and cred_guard_mutex locks to be held.
+ *
+ * Returns 0 on success, -ve on error, or the pid of a thread which was
+ * either not in the correct seccomp mode or it did not have an ancestral
+ * seccomp filter.
+ */
+static inline pid_t seccomp_can_sync_threads(void)
+{
+	struct task_struct *thread, *caller;
+
+	BUG_ON(!mutex_is_locked(&current->signal->cred_guard_mutex));
+	BUG_ON(!spin_is_locked(&current->sighand->siglock));
+
+	/* Validate all threads being eligible for synchronization. */
+	caller = current;
+	for_each_thread(caller, thread) {
+		pid_t failed;
+
+		/* Skip current, since it is initiating the sync. */
+		if (thread == caller)
+			continue;
+
+		if (thread->seccomp.mode == SECCOMP_MODE_DISABLED ||
+		    (thread->seccomp.mode == SECCOMP_MODE_FILTER &&
+		     is_ancestor(thread->seccomp.filter,
+				 caller->seccomp.filter)))
+			continue;
+
+		/* Return the first thread that cannot be synchronized. */
+		failed = task_pid_vnr(thread);
+		/* If the pid cannot be resolved, then return -ESRCH */
+		if (unlikely(WARN_ON(failed == 0)))
+			failed = -ESRCH;
+		return failed;
+	}
+
+	return 0;
+}
+
+/**
+ * seccomp_sync_threads: sets all threads to use current's filter
+ *
+ * Expects sighand and cred_guard_mutex locks to be held, and for
+ * seccomp_can_sync_threads() to have returned success already
+ * without dropping the locks.
+ *
+ */
+static inline void seccomp_sync_threads(void)
+{
+	struct task_struct *thread, *caller;
+
+	BUG_ON(!mutex_is_locked(&current->signal->cred_guard_mutex));
+	BUG_ON(!spin_is_locked(&current->sighand->siglock));
+
+	/* Synchronize all threads. */
+	caller = current;
+	for_each_thread(caller, thread) {
+		/* Skip current, since it needs no changes. */
+		if (thread == caller)
+			continue;
+
+		/* Get a task reference for the new leaf node. */
+		get_seccomp_filter(caller);
+		/*
+		 * Drop the task reference to the shared ancestor since
+		 * current's path will hold a reference.  (This also
+		 * allows a put before the assignment.)
+		 */
+		put_seccomp_filter(thread);
+		smp_store_release(&thread->seccomp.filter,
+				  caller->seccomp.filter);
+		/*
+		 * Opt the other thread into seccomp if needed.
+		 * As threads are considered to be trust-realm
+		 * equivalent (see ptrace_may_access), it is safe to
+		 * allow one thread to transition the other.
+		 */
+		if (thread->seccomp.mode == SECCOMP_MODE_DISABLED) {
+			/*
+			 * Don't let an unprivileged task work around
+			 * the no_new_privs restriction by creating
+			 * a thread that sets it up, enters seccomp,
+			 * then dies.
+			 */
+			if (task_no_new_privs(caller))
+				task_set_no_new_privs(thread);
+
+			seccomp_assign_mode(thread, SECCOMP_MODE_FILTER);
+		}
+	}
+}
+
 /**
  * seccomp_prepare_filter: Prepares a seccomp filter for use.
  * @fprog: BPF program to install
@@ -364,6 +473,15 @@ static long seccomp_attach_filter(unsigned int flags,
 	if (total_insns > MAX_INSNS_PER_PATH)
 		return -ENOMEM;
 
+	/* If thread sync has been requested, check that it is possible. */
+	if (flags & SECCOMP_FILTER_FLAG_TSYNC) {
+		int ret;
+
+		ret = seccomp_can_sync_threads();
+		if (ret)
+			return ret;
+	}
+
 	/*
 	 * If there is an existing filter, make it the prev and don't drop its
 	 * task reference.
@@ -371,6 +489,10 @@ static long seccomp_attach_filter(unsigned int flags,
 	filter->prev = current->seccomp.filter;
 	current->seccomp.filter = filter;
 
+	/* Now that the new filter is in place, synchronize to all threads. */
+	if (flags & SECCOMP_FILTER_FLAG_TSYNC)
+		seccomp_sync_threads();
+
 	return 0;
 }
 
@@ -590,7 +712,7 @@ static long seccomp_set_mode_filter(unsigned int flags,
 	long ret = -EINVAL;
 
 	/* Validate flags. */
-	if (flags != 0)
+	if (flags & ~SECCOMP_FILTER_FLAG_MASK)
 		return -EINVAL;
 
 	/* Prepare the new filter before holding any locks. */
@@ -598,6 +720,14 @@ static long seccomp_set_mode_filter(unsigned int flags,
 	if (IS_ERR(prepared))
 		return PTR_ERR(prepared);
 
+	/*
+	 * Make sure we cannot change seccomp or nnp state via TSYNC
+	 * while another thread is in the middle of calling exec.
+	 */
+	if (flags & SECCOMP_FILTER_FLAG_TSYNC &&
+	    mutex_lock_killable(&current->signal->cred_guard_mutex))
+		goto out_free;
+
 	spin_lock_irq(&current->sighand->siglock);
 
 	if (!seccomp_may_assign_mode(seccomp_mode))
@@ -612,6 +742,9 @@ static long seccomp_set_mode_filter(unsigned int flags,
 	seccomp_assign_mode(current, seccomp_mode);
 out:
 	spin_unlock_irq(&current->sighand->siglock);
+	if (flags & SECCOMP_FILTER_FLAG_TSYNC)
+		mutex_unlock(&current->signal->cred_guard_mutex);
+out_free:
 	seccomp_filter_free(prepared);
 	return ret;
 }

commit 3ba2530cc06eb4aee4f1f754f43d781e8a12ee09
Author: Kees Cook <keescook@chromium.org>
Date:   Fri Jun 27 15:01:35 2014 -0700

    seccomp: allow mode setting across threads
    
    This changes the mode setting helper to allow threads to change the
    seccomp mode from another thread. We must maintain barriers to keep
    TIF_SECCOMP synchronized with the rest of the seccomp state.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Andy Lutomirski <luto@amacapital.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index d5543e787e4e..9065d2c79c56 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -173,21 +173,24 @@ static int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)
  */
 static u32 seccomp_run_filters(int syscall)
 {
-	struct seccomp_filter *f;
+	struct seccomp_filter *f = ACCESS_ONCE(current->seccomp.filter);
 	struct seccomp_data sd;
 	u32 ret = SECCOMP_RET_ALLOW;
 
 	/* Ensure unexpected behavior doesn't result in failing open. */
-	if (WARN_ON(current->seccomp.filter == NULL))
+	if (unlikely(WARN_ON(f == NULL)))
 		return SECCOMP_RET_KILL;
 
+	/* Make sure cross-thread synced filter points somewhere sane. */
+	smp_read_barrier_depends();
+
 	populate_seccomp_data(&sd);
 
 	/*
 	 * All filters in the list are evaluated and the lowest BPF return
 	 * value always takes priority (ignoring the DATA).
 	 */
-	for (f = current->seccomp.filter; f; f = f->prev) {
+	for (; f; f = f->prev) {
 		u32 cur_ret = SK_RUN_FILTER(f->prog, (void *)&sd);
 
 		if ((cur_ret & SECCOMP_RET_ACTION) < (ret & SECCOMP_RET_ACTION))
@@ -207,12 +210,18 @@ static inline bool seccomp_may_assign_mode(unsigned long seccomp_mode)
 	return true;
 }
 
-static inline void seccomp_assign_mode(unsigned long seccomp_mode)
+static inline void seccomp_assign_mode(struct task_struct *task,
+				       unsigned long seccomp_mode)
 {
-	BUG_ON(!spin_is_locked(&current->sighand->siglock));
+	BUG_ON(!spin_is_locked(&task->sighand->siglock));
 
-	current->seccomp.mode = seccomp_mode;
-	set_tsk_thread_flag(current, TIF_SECCOMP);
+	task->seccomp.mode = seccomp_mode;
+	/*
+	 * Make sure TIF_SECCOMP cannot be set before the mode (and
+	 * filter) is set.
+	 */
+	smp_mb__before_atomic();
+	set_tsk_thread_flag(task, TIF_SECCOMP);
 }
 
 #ifdef CONFIG_SECCOMP_FILTER
@@ -435,12 +444,17 @@ static int mode1_syscalls_32[] = {
 
 int __secure_computing(int this_syscall)
 {
-	int mode = current->seccomp.mode;
 	int exit_sig = 0;
 	int *syscall;
 	u32 ret;
 
-	switch (mode) {
+	/*
+	 * Make sure that any changes to mode from another thread have
+	 * been seen after TIF_SECCOMP was seen.
+	 */
+	rmb();
+
+	switch (current->seccomp.mode) {
 	case SECCOMP_MODE_STRICT:
 		syscall = mode1_syscalls;
 #ifdef CONFIG_COMPAT
@@ -545,7 +559,7 @@ static long seccomp_set_mode_strict(void)
 #ifdef TIF_NOTSC
 	disable_TSC();
 #endif
-	seccomp_assign_mode(seccomp_mode);
+	seccomp_assign_mode(current, seccomp_mode);
 	ret = 0;
 
 out:
@@ -595,7 +609,7 @@ static long seccomp_set_mode_filter(unsigned int flags,
 	/* Do not free the successfully attached filter. */
 	prepared = NULL;
 
-	seccomp_assign_mode(seccomp_mode);
+	seccomp_assign_mode(current, seccomp_mode);
 out:
 	spin_unlock_irq(&current->sighand->siglock);
 	seccomp_filter_free(prepared);

commit dbd952127d11bb44a4ea30b08cc60531b6a23d71
Author: Kees Cook <keescook@chromium.org>
Date:   Fri Jun 27 15:18:48 2014 -0700

    seccomp: introduce writer locking
    
    Normally, task_struct.seccomp.filter is only ever read or modified by
    the task that owns it (current). This property aids in fast access
    during system call filtering as read access is lockless.
    
    Updating the pointer from another task, however, opens up race
    conditions. To allow cross-thread filter pointer updates, writes to the
    seccomp fields are now protected by the sighand spinlock (which is shared
    by all threads in the thread group). Read access remains lockless because
    pointer updates themselves are atomic.  However, writes (or cloning)
    often entail additional checking (like maximum instruction counts)
    which require locking to perform safely.
    
    In the case of cloning threads, the child is invisible to the system
    until it enters the task list. To make sure a child can't be cloned from
    a thread and left in a prior state, seccomp duplication is additionally
    moved under the sighand lock. Then parent and child are certain have
    the same seccomp state when they exit the lock.
    
    Based on patches by Will Drewry and David Drysdale.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Andy Lutomirski <luto@amacapital.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 58125160417c..d5543e787e4e 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -199,6 +199,8 @@ static u32 seccomp_run_filters(int syscall)
 
 static inline bool seccomp_may_assign_mode(unsigned long seccomp_mode)
 {
+	BUG_ON(!spin_is_locked(&current->sighand->siglock));
+
 	if (current->seccomp.mode && current->seccomp.mode != seccomp_mode)
 		return false;
 
@@ -207,6 +209,8 @@ static inline bool seccomp_may_assign_mode(unsigned long seccomp_mode)
 
 static inline void seccomp_assign_mode(unsigned long seccomp_mode)
 {
+	BUG_ON(!spin_is_locked(&current->sighand->siglock));
+
 	current->seccomp.mode = seccomp_mode;
 	set_tsk_thread_flag(current, TIF_SECCOMP);
 }
@@ -332,6 +336,8 @@ seccomp_prepare_user_filter(const char __user *user_filter)
  * @flags:  flags to change filter behavior
  * @filter: seccomp filter to add to the current process
  *
+ * Caller must be holding current->sighand->siglock lock.
+ *
  * Returns 0 on success, -ve on error.
  */
 static long seccomp_attach_filter(unsigned int flags,
@@ -340,6 +346,8 @@ static long seccomp_attach_filter(unsigned int flags,
 	unsigned long total_insns;
 	struct seccomp_filter *walker;
 
+	BUG_ON(!spin_is_locked(&current->sighand->siglock));
+
 	/* Validate resulting filter length. */
 	total_insns = filter->prog->len;
 	for (walker = current->seccomp.filter; walker; walker = walker->prev)
@@ -529,6 +537,8 @@ static long seccomp_set_mode_strict(void)
 	const unsigned long seccomp_mode = SECCOMP_MODE_STRICT;
 	long ret = -EINVAL;
 
+	spin_lock_irq(&current->sighand->siglock);
+
 	if (!seccomp_may_assign_mode(seccomp_mode))
 		goto out;
 
@@ -539,6 +549,7 @@ static long seccomp_set_mode_strict(void)
 	ret = 0;
 
 out:
+	spin_unlock_irq(&current->sighand->siglock);
 
 	return ret;
 }
@@ -566,13 +577,15 @@ static long seccomp_set_mode_filter(unsigned int flags,
 
 	/* Validate flags. */
 	if (flags != 0)
-		goto out;
+		return -EINVAL;
 
 	/* Prepare the new filter before holding any locks. */
 	prepared = seccomp_prepare_user_filter(filter);
 	if (IS_ERR(prepared))
 		return PTR_ERR(prepared);
 
+	spin_lock_irq(&current->sighand->siglock);
+
 	if (!seccomp_may_assign_mode(seccomp_mode))
 		goto out;
 
@@ -584,6 +597,7 @@ static long seccomp_set_mode_filter(unsigned int flags,
 
 	seccomp_assign_mode(seccomp_mode);
 out:
+	spin_unlock_irq(&current->sighand->siglock);
 	seccomp_filter_free(prepared);
 	return ret;
 }

commit c8bee430dc52cfca6c1aab27752a89275d78d50f
Author: Kees Cook <keescook@chromium.org>
Date:   Fri Jun 27 15:16:33 2014 -0700

    seccomp: split filter prep from check and apply
    
    In preparation for adding seccomp locking, move filter creation away
    from where it is checked and applied. This will allow for locking where
    no memory allocation is happening. The validation, filter attachment,
    and seccomp mode setting can all happen under the future locks.
    
    For extreme defensiveness, I've added a BUG_ON check for the calculated
    size of the buffer allocation in case BPF_MAXINSN ever changes, which
    shouldn't ever happen. The compiler should actually optimize out this
    check since the test above it makes it impossible.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Andy Lutomirski <luto@amacapital.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index d2596136b0d1..58125160417c 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -18,6 +18,7 @@
 #include <linux/compat.h>
 #include <linux/sched.h>
 #include <linux/seccomp.h>
+#include <linux/slab.h>
 #include <linux/syscalls.h>
 
 /* #define SECCOMP_DEBUG 1 */
@@ -27,7 +28,6 @@
 #include <linux/filter.h>
 #include <linux/ptrace.h>
 #include <linux/security.h>
-#include <linux/slab.h>
 #include <linux/tracehook.h>
 #include <linux/uaccess.h>
 
@@ -213,27 +213,23 @@ static inline void seccomp_assign_mode(unsigned long seccomp_mode)
 
 #ifdef CONFIG_SECCOMP_FILTER
 /**
- * seccomp_attach_filter: Attaches a seccomp filter to current.
+ * seccomp_prepare_filter: Prepares a seccomp filter for use.
  * @fprog: BPF program to install
  *
- * Returns 0 on success or an errno on failure.
+ * Returns filter on success or an ERR_PTR on failure.
  */
-static long seccomp_attach_filter(struct sock_fprog *fprog)
+static struct seccomp_filter *seccomp_prepare_filter(struct sock_fprog *fprog)
 {
 	struct seccomp_filter *filter;
-	unsigned long fp_size = fprog->len * sizeof(struct sock_filter);
-	unsigned long total_insns = fprog->len;
+	unsigned long fp_size;
 	struct sock_filter *fp;
 	int new_len;
 	long ret;
 
 	if (fprog->len == 0 || fprog->len > BPF_MAXINSNS)
-		return -EINVAL;
-
-	for (filter = current->seccomp.filter; filter; filter = filter->prev)
-		total_insns += filter->prog->len + 4;  /* include a 4 instr penalty */
-	if (total_insns > MAX_INSNS_PER_PATH)
-		return -ENOMEM;
+		return ERR_PTR(-EINVAL);
+	BUG_ON(INT_MAX / fprog->len < sizeof(struct sock_filter));
+	fp_size = fprog->len * sizeof(struct sock_filter);
 
 	/*
 	 * Installing a seccomp filter requires that the task has
@@ -244,11 +240,11 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 	if (!task_no_new_privs(current) &&
 	    security_capable_noaudit(current_cred(), current_user_ns(),
 				     CAP_SYS_ADMIN) != 0)
-		return -EACCES;
+		return ERR_PTR(-EACCES);
 
 	fp = kzalloc(fp_size, GFP_KERNEL|__GFP_NOWARN);
 	if (!fp)
-		return -ENOMEM;
+		return ERR_PTR(-ENOMEM);
 
 	/* Copy the instructions from fprog. */
 	ret = -EFAULT;
@@ -292,13 +288,7 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 
 	sk_filter_select_runtime(filter->prog);
 
-	/*
-	 * If there is an existing filter, make it the prev and don't drop its
-	 * task reference.
-	 */
-	filter->prev = current->seccomp.filter;
-	current->seccomp.filter = filter;
-	return 0;
+	return filter;
 
 free_filter_prog:
 	kfree(filter->prog);
@@ -306,19 +296,20 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 	kfree(filter);
 free_prog:
 	kfree(fp);
-	return ret;
+	return ERR_PTR(ret);
 }
 
 /**
- * seccomp_attach_user_filter - attaches a user-supplied sock_fprog
+ * seccomp_prepare_user_filter - prepares a user-supplied sock_fprog
  * @user_filter: pointer to the user data containing a sock_fprog.
  *
  * Returns 0 on success and non-zero otherwise.
  */
-static long seccomp_attach_user_filter(const char __user *user_filter)
+static struct seccomp_filter *
+seccomp_prepare_user_filter(const char __user *user_filter)
 {
 	struct sock_fprog fprog;
-	long ret = -EFAULT;
+	struct seccomp_filter *filter = ERR_PTR(-EFAULT);
 
 #ifdef CONFIG_COMPAT
 	if (is_compat_task()) {
@@ -331,9 +322,39 @@ static long seccomp_attach_user_filter(const char __user *user_filter)
 #endif
 	if (copy_from_user(&fprog, user_filter, sizeof(fprog)))
 		goto out;
-	ret = seccomp_attach_filter(&fprog);
+	filter = seccomp_prepare_filter(&fprog);
 out:
-	return ret;
+	return filter;
+}
+
+/**
+ * seccomp_attach_filter: validate and attach filter
+ * @flags:  flags to change filter behavior
+ * @filter: seccomp filter to add to the current process
+ *
+ * Returns 0 on success, -ve on error.
+ */
+static long seccomp_attach_filter(unsigned int flags,
+				  struct seccomp_filter *filter)
+{
+	unsigned long total_insns;
+	struct seccomp_filter *walker;
+
+	/* Validate resulting filter length. */
+	total_insns = filter->prog->len;
+	for (walker = current->seccomp.filter; walker; walker = walker->prev)
+		total_insns += walker->prog->len + 4;  /* 4 instr penalty */
+	if (total_insns > MAX_INSNS_PER_PATH)
+		return -ENOMEM;
+
+	/*
+	 * If there is an existing filter, make it the prev and don't drop its
+	 * task reference.
+	 */
+	filter->prev = current->seccomp.filter;
+	current->seccomp.filter = filter;
+
+	return 0;
 }
 
 /* get_seccomp_filter - increments the reference count of the filter on @tsk */
@@ -346,6 +367,14 @@ void get_seccomp_filter(struct task_struct *tsk)
 	atomic_inc(&orig->usage);
 }
 
+static inline void seccomp_filter_free(struct seccomp_filter *filter)
+{
+	if (filter) {
+		sk_filter_free(filter->prog);
+		kfree(filter);
+	}
+}
+
 /* put_seccomp_filter - decrements the ref count of tsk->seccomp.filter */
 void put_seccomp_filter(struct task_struct *tsk)
 {
@@ -354,8 +383,7 @@ void put_seccomp_filter(struct task_struct *tsk)
 	while (orig && atomic_dec_and_test(&orig->usage)) {
 		struct seccomp_filter *freeme = orig;
 		orig = orig->prev;
-		sk_filter_free(freeme->prog);
-		kfree(freeme);
+		seccomp_filter_free(freeme);
 	}
 }
 
@@ -533,21 +561,30 @@ static long seccomp_set_mode_filter(unsigned int flags,
 				    const char __user *filter)
 {
 	const unsigned long seccomp_mode = SECCOMP_MODE_FILTER;
+	struct seccomp_filter *prepared = NULL;
 	long ret = -EINVAL;
 
 	/* Validate flags. */
 	if (flags != 0)
 		goto out;
 
+	/* Prepare the new filter before holding any locks. */
+	prepared = seccomp_prepare_user_filter(filter);
+	if (IS_ERR(prepared))
+		return PTR_ERR(prepared);
+
 	if (!seccomp_may_assign_mode(seccomp_mode))
 		goto out;
 
-	ret = seccomp_attach_user_filter(filter);
+	ret = seccomp_attach_filter(flags, prepared);
 	if (ret)
 		goto out;
+	/* Do not free the successfully attached filter. */
+	prepared = NULL;
 
 	seccomp_assign_mode(seccomp_mode);
 out:
+	seccomp_filter_free(prepared);
 	return ret;
 }
 #else

commit 1d4457f99928a968767f6405b4a1f50845aa15fd
Author: Kees Cook <keescook@chromium.org>
Date:   Wed May 21 15:23:46 2014 -0700

    sched: move no_new_privs into new atomic flags
    
    Since seccomp transitions between threads requires updates to the
    no_new_privs flag to be atomic, the flag must be part of an atomic flag
    set. This moves the nnp flag into a separate task field, and introduces
    accessors.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Andy Lutomirski <luto@amacapital.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index f0652578af75..d2596136b0d1 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -241,7 +241,7 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 	 * This avoids scenarios where unprivileged tasks can affect the
 	 * behavior of privileged children.
 	 */
-	if (!current->no_new_privs &&
+	if (!task_no_new_privs(current) &&
 	    security_capable_noaudit(current_cred(), current_user_ns(),
 				     CAP_SYS_ADMIN) != 0)
 		return -EACCES;

commit 48dc92b9fc3926844257316e75ba11eb5c742b2c
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Jun 25 16:08:24 2014 -0700

    seccomp: add "seccomp" syscall
    
    This adds the new "seccomp" syscall with both an "operation" and "flags"
    parameter for future expansion. The third argument is a pointer value,
    used with the SECCOMP_SET_MODE_FILTER operation. Currently, flags must
    be 0. This is functionally equivalent to prctl(PR_SET_SECCOMP, ...).
    
    In addition to the TSYNC flag later in this patch series, there is a
    non-zero chance that this syscall could be used for configuring a fixed
    argument area for seccomp-tracer-aware processes to pass syscall arguments
    in the future. Hence, the use of "seccomp" not simply "seccomp_add_filter"
    for this syscall. Additionally, this syscall uses operation, flags,
    and user pointer for arguments because strictly passing arguments via
    a user pointer would mean seccomp itself would be unable to trivially
    filter the seccomp syscall itself.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Andy Lutomirski <luto@amacapital.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 05cac2c2eca1..f0652578af75 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -18,6 +18,7 @@
 #include <linux/compat.h>
 #include <linux/sched.h>
 #include <linux/seccomp.h>
+#include <linux/syscalls.h>
 
 /* #define SECCOMP_DEBUG 1 */
 
@@ -314,7 +315,7 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
  *
  * Returns 0 on success and non-zero otherwise.
  */
-static long seccomp_attach_user_filter(char __user *user_filter)
+static long seccomp_attach_user_filter(const char __user *user_filter)
 {
 	struct sock_fprog fprog;
 	long ret = -EFAULT;
@@ -517,6 +518,7 @@ static long seccomp_set_mode_strict(void)
 #ifdef CONFIG_SECCOMP_FILTER
 /**
  * seccomp_set_mode_filter: internal function for setting seccomp filter
+ * @flags:  flags to change filter behavior
  * @filter: struct sock_fprog containing filter
  *
  * This function may be called repeatedly to install additional filters.
@@ -527,11 +529,16 @@ static long seccomp_set_mode_strict(void)
  *
  * Returns 0 on success or -EINVAL on failure.
  */
-static long seccomp_set_mode_filter(char __user *filter)
+static long seccomp_set_mode_filter(unsigned int flags,
+				    const char __user *filter)
 {
 	const unsigned long seccomp_mode = SECCOMP_MODE_FILTER;
 	long ret = -EINVAL;
 
+	/* Validate flags. */
+	if (flags != 0)
+		goto out;
+
 	if (!seccomp_may_assign_mode(seccomp_mode))
 		goto out;
 
@@ -544,12 +551,35 @@ static long seccomp_set_mode_filter(char __user *filter)
 	return ret;
 }
 #else
-static inline long seccomp_set_mode_filter(char __user *filter)
+static inline long seccomp_set_mode_filter(unsigned int flags,
+					   const char __user *filter)
 {
 	return -EINVAL;
 }
 #endif
 
+/* Common entry point for both prctl and syscall. */
+static long do_seccomp(unsigned int op, unsigned int flags,
+		       const char __user *uargs)
+{
+	switch (op) {
+	case SECCOMP_SET_MODE_STRICT:
+		if (flags != 0 || uargs != NULL)
+			return -EINVAL;
+		return seccomp_set_mode_strict();
+	case SECCOMP_SET_MODE_FILTER:
+		return seccomp_set_mode_filter(flags, uargs);
+	default:
+		return -EINVAL;
+	}
+}
+
+SYSCALL_DEFINE3(seccomp, unsigned int, op, unsigned int, flags,
+			 const char __user *, uargs)
+{
+	return do_seccomp(op, flags, uargs);
+}
+
 /**
  * prctl_set_seccomp: configures current->seccomp.mode
  * @seccomp_mode: requested mode to use
@@ -559,12 +589,27 @@ static inline long seccomp_set_mode_filter(char __user *filter)
  */
 long prctl_set_seccomp(unsigned long seccomp_mode, char __user *filter)
 {
+	unsigned int op;
+	char __user *uargs;
+
 	switch (seccomp_mode) {
 	case SECCOMP_MODE_STRICT:
-		return seccomp_set_mode_strict();
+		op = SECCOMP_SET_MODE_STRICT;
+		/*
+		 * Setting strict mode through prctl always ignored filter,
+		 * so make sure it is always NULL here to pass the internal
+		 * check in do_seccomp().
+		 */
+		uargs = NULL;
+		break;
 	case SECCOMP_MODE_FILTER:
-		return seccomp_set_mode_filter(filter);
+		op = SECCOMP_SET_MODE_FILTER;
+		uargs = filter;
+		break;
 	default:
 		return -EINVAL;
 	}
+
+	/* prctl interface doesn't have flags, so they are always zero. */
+	return do_seccomp(op, 0, uargs);
 }

commit 3b23dd12846215eff4afb073366b80c0c4d7543e
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Jun 25 15:55:25 2014 -0700

    seccomp: split mode setting routines
    
    Separates the two mode setting paths to make things more readable with
    fewer #ifdefs within function bodies.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Andy Lutomirski <luto@amacapital.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 9df7def86c3b..05cac2c2eca1 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -489,48 +489,66 @@ long prctl_get_seccomp(void)
 }
 
 /**
- * seccomp_set_mode: internal function for setting seccomp mode
- * @seccomp_mode: requested mode to use
- * @filter: optional struct sock_fprog for use with SECCOMP_MODE_FILTER
- *
- * This function may be called repeatedly with a @seccomp_mode of
- * SECCOMP_MODE_FILTER to install additional filters.  Every filter
- * successfully installed will be evaluated (in reverse order) for each system
- * call the task makes.
+ * seccomp_set_mode_strict: internal function for setting strict seccomp
  *
  * Once current->seccomp.mode is non-zero, it may not be changed.
  *
  * Returns 0 on success or -EINVAL on failure.
  */
-static long seccomp_set_mode(unsigned long seccomp_mode, char __user *filter)
+static long seccomp_set_mode_strict(void)
 {
+	const unsigned long seccomp_mode = SECCOMP_MODE_STRICT;
 	long ret = -EINVAL;
 
 	if (!seccomp_may_assign_mode(seccomp_mode))
 		goto out;
 
-	switch (seccomp_mode) {
-	case SECCOMP_MODE_STRICT:
-		ret = 0;
 #ifdef TIF_NOTSC
-		disable_TSC();
+	disable_TSC();
 #endif
-		break;
+	seccomp_assign_mode(seccomp_mode);
+	ret = 0;
+
+out:
+
+	return ret;
+}
+
 #ifdef CONFIG_SECCOMP_FILTER
-	case SECCOMP_MODE_FILTER:
-		ret = seccomp_attach_user_filter(filter);
-		if (ret)
-			goto out;
-		break;
-#endif
-	default:
+/**
+ * seccomp_set_mode_filter: internal function for setting seccomp filter
+ * @filter: struct sock_fprog containing filter
+ *
+ * This function may be called repeatedly to install additional filters.
+ * Every filter successfully installed will be evaluated (in reverse order)
+ * for each system call the task makes.
+ *
+ * Once current->seccomp.mode is non-zero, it may not be changed.
+ *
+ * Returns 0 on success or -EINVAL on failure.
+ */
+static long seccomp_set_mode_filter(char __user *filter)
+{
+	const unsigned long seccomp_mode = SECCOMP_MODE_FILTER;
+	long ret = -EINVAL;
+
+	if (!seccomp_may_assign_mode(seccomp_mode))
+		goto out;
+
+	ret = seccomp_attach_user_filter(filter);
+	if (ret)
 		goto out;
-	}
 
 	seccomp_assign_mode(seccomp_mode);
 out:
 	return ret;
 }
+#else
+static inline long seccomp_set_mode_filter(char __user *filter)
+{
+	return -EINVAL;
+}
+#endif
 
 /**
  * prctl_set_seccomp: configures current->seccomp.mode
@@ -541,5 +559,12 @@ static long seccomp_set_mode(unsigned long seccomp_mode, char __user *filter)
  */
 long prctl_set_seccomp(unsigned long seccomp_mode, char __user *filter)
 {
-	return seccomp_set_mode(seccomp_mode, filter);
+	switch (seccomp_mode) {
+	case SECCOMP_MODE_STRICT:
+		return seccomp_set_mode_strict();
+	case SECCOMP_MODE_FILTER:
+		return seccomp_set_mode_filter(filter);
+	default:
+		return -EINVAL;
+	}
 }

commit 1f41b450416e689b9b7c8bfb750a98604f687a9b
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Jun 25 15:38:02 2014 -0700

    seccomp: extract check/assign mode helpers
    
    To support splitting mode 1 from mode 2, extract the mode checking and
    assignment logic into common functions.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Andy Lutomirski <luto@amacapital.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index afb916c7e890..9df7def86c3b 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -194,7 +194,23 @@ static u32 seccomp_run_filters(int syscall)
 	}
 	return ret;
 }
+#endif /* CONFIG_SECCOMP_FILTER */
 
+static inline bool seccomp_may_assign_mode(unsigned long seccomp_mode)
+{
+	if (current->seccomp.mode && current->seccomp.mode != seccomp_mode)
+		return false;
+
+	return true;
+}
+
+static inline void seccomp_assign_mode(unsigned long seccomp_mode)
+{
+	current->seccomp.mode = seccomp_mode;
+	set_tsk_thread_flag(current, TIF_SECCOMP);
+}
+
+#ifdef CONFIG_SECCOMP_FILTER
 /**
  * seccomp_attach_filter: Attaches a seccomp filter to current.
  * @fprog: BPF program to install
@@ -490,8 +506,7 @@ static long seccomp_set_mode(unsigned long seccomp_mode, char __user *filter)
 {
 	long ret = -EINVAL;
 
-	if (current->seccomp.mode &&
-	    current->seccomp.mode != seccomp_mode)
+	if (!seccomp_may_assign_mode(seccomp_mode))
 		goto out;
 
 	switch (seccomp_mode) {
@@ -512,8 +527,7 @@ static long seccomp_set_mode(unsigned long seccomp_mode, char __user *filter)
 		goto out;
 	}
 
-	current->seccomp.mode = seccomp_mode;
-	set_thread_flag(TIF_SECCOMP);
+	seccomp_assign_mode(seccomp_mode);
 out:
 	return ret;
 }

commit d78ab02c2c194257a03355fbb79eb721b381d105
Author: Kees Cook <keescook@chromium.org>
Date:   Wed May 21 15:02:11 2014 -0700

    seccomp: create internal mode-setting function
    
    In preparation for having other callers of the seccomp mode setting
    logic, split the prctl entry point away from the core logic that performs
    seccomp mode setting.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Andy Lutomirski <luto@amacapital.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 301bbc24739c..afb916c7e890 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -473,7 +473,7 @@ long prctl_get_seccomp(void)
 }
 
 /**
- * prctl_set_seccomp: configures current->seccomp.mode
+ * seccomp_set_mode: internal function for setting seccomp mode
  * @seccomp_mode: requested mode to use
  * @filter: optional struct sock_fprog for use with SECCOMP_MODE_FILTER
  *
@@ -486,7 +486,7 @@ long prctl_get_seccomp(void)
  *
  * Returns 0 on success or -EINVAL on failure.
  */
-long prctl_set_seccomp(unsigned long seccomp_mode, char __user *filter)
+static long seccomp_set_mode(unsigned long seccomp_mode, char __user *filter)
 {
 	long ret = -EINVAL;
 
@@ -517,3 +517,15 @@ long prctl_set_seccomp(unsigned long seccomp_mode, char __user *filter)
 out:
 	return ret;
 }
+
+/**
+ * prctl_set_seccomp: configures current->seccomp.mode
+ * @seccomp_mode: requested mode to use
+ * @filter: optional struct sock_fprog for use with SECCOMP_MODE_FILTER
+ *
+ * Returns 0 on success or -EINVAL on failure.
+ */
+long prctl_set_seccomp(unsigned long seccomp_mode, char __user *filter)
+{
+	return seccomp_set_mode(seccomp_mode, filter);
+}

commit f9da455b93f6ba076935b4ef4589f61e529ae046
Merge: 0e04c641b199 e5eca6d41f53
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 12 14:27:40 2014 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking updates from David Miller:
    
     1) Seccomp BPF filters can now be JIT'd, from Alexei Starovoitov.
    
     2) Multiqueue support in xen-netback and xen-netfront, from Andrew J
        Benniston.
    
     3) Allow tweaking of aggregation settings in cdc_ncm driver, from Bjrn
        Mork.
    
     4) BPF now has a "random" opcode, from Chema Gonzalez.
    
     5) Add more BPF documentation and improve test framework, from Daniel
        Borkmann.
    
     6) Support TCP fastopen over ipv6, from Daniel Lee.
    
     7) Add software TSO helper functions and use them to support software
        TSO in mvneta and mv643xx_eth drivers.  From Ezequiel Garcia.
    
     8) Support software TSO in fec driver too, from Nimrod Andy.
    
     9) Add Broadcom SYSTEMPORT driver, from Florian Fainelli.
    
    10) Handle broadcasts more gracefully over macvlan when there are large
        numbers of interfaces configured, from Herbert Xu.
    
    11) Allow more control over fwmark used for non-socket based responses,
        from Lorenzo Colitti.
    
    12) Do TCP congestion window limiting based upon measurements, from Neal
        Cardwell.
    
    13) Support busy polling in SCTP, from Neal Horman.
    
    14) Allow RSS key to be configured via ethtool, from Venkata Duvvuru.
    
    15) Bridge promisc mode handling improvements from Vlad Yasevich.
    
    16) Don't use inetpeer entries to implement ID generation any more, it
        performs poorly, from Eric Dumazet.
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next: (1522 commits)
      rtnetlink: fix userspace API breakage for iproute2 < v3.9.0
      tcp: fixing TLP's FIN recovery
      net: fec: Add software TSO support
      net: fec: Add Scatter/gather support
      net: fec: Increase buffer descriptor entry number
      net: fec: Factorize feature setting
      net: fec: Enable IP header hardware checksum
      net: fec: Factorize the .xmit transmit function
      bridge: fix compile error when compiling without IPv6 support
      bridge: fix smatch warning / potential null pointer dereference
      via-rhine: fix full-duplex with autoneg disable
      bnx2x: Enlarge the dorq threshold for VFs
      bnx2x: Check for UNDI in uncommon branch
      bnx2x: Fix 1G-baseT link
      bnx2x: Fix link for KR with swapped polarity lane
      sctp: Fix sk_ack_backlog wrap-around problem
      net/core: Add VF link state control policy
      net/fsl: xgmac_mdio is dependent on OF_MDIO
      net/fsl: Make xgmac_mdio read error message useful
      net_sched: drr: warn when qdisc is not work conserving
      ...

commit 119ce5c8b99cd6b874cec58c81ce9b56e52160c3
Author: Fabian Frederick <fabf@skynet.be>
Date:   Fri Jun 6 14:37:53 2014 -0700

    kernel/seccomp.c: kernel-doc warning fix
    
    + fix small typo
    
    Signed-off-by: Fabian Frederick <fabf@skynet.be>
    Cc: "David S. Miller" <davem@davemloft.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index b35c21503a36..f6d76bebe69f 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -39,7 +39,7 @@
  *         is only needed for handling filters shared across tasks.
  * @prev: points to a previously installed, or inherited, filter
  * @len: the number of instructions in the program
- * @insns: the BPF program instructions to evaluate
+ * @insnsi: the BPF program instructions to evaluate
  *
  * seccomp_filter objects are organized in a tree linked via the @prev
  * pointer.  For any task, it appears to be a singly-linked list starting
@@ -220,7 +220,7 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 		return -ENOMEM;
 
 	/*
-	 * Installing a seccomp filter requires that the task have
+	 * Installing a seccomp filter requires that the task has
 	 * CAP_SYS_ADMIN in its namespace or be running with no_new_privs.
 	 * This avoids scenarios where unprivileged tasks can affect the
 	 * behavior of privileged children.

commit 3480593131e0b781287dae0139bf7ccee7cba7ff
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Thu May 29 10:22:50 2014 +0200

    net: filter: get rid of BPF_S_* enum
    
    This patch finally allows us to get rid of the BPF_S_* enum.
    Currently, the code performs unnecessary encode and decode
    workarounds in seccomp and filter migration itself when a filter
    is being attached in order to overcome BPF_S_* encoding which
    is not used anymore by the new interpreter resp. JIT compilers.
    
    Keeping it around would mean that also in future we would need
    to extend and maintain this enum and related encoders/decoders.
    We can get rid of all that and save us these operations during
    filter attaching. Naturally, also JIT compilers need to be updated
    by this.
    
    Before JIT conversion is being done, each compiler checks if A
    is being loaded at startup to obtain information if it needs to
    emit instructions to clear A first. Since BPF extensions are a
    subset of BPF_LD | BPF_{W,H,B} | BPF_ABS variants, case statements
    for extensions can be removed at that point. To ease and minimalize
    code changes in the classic JITs, we have introduced bpf_anc_helper().
    
    Tested with test_bpf on x86_64 (JIT, int), s390x (JIT, int),
    arm (JIT, int), i368 (int), ppc64 (JIT, int); for sparc we
    unfortunately didn't have access, but changes are analogous to
    the rest.
    
    Joint work with Alexei Starovoitov.
    
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: Alexei Starovoitov <ast@plumgrid.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Mircea Gherzan <mgherzan@gmail.com>
    Cc: Kees Cook <keescook@chromium.org>
    Acked-by: Chema Gonzalez <chemag@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 1036b6f2fded..44e69483b383 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -103,60 +103,59 @@ static int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)
 		u32 k = ftest->k;
 
 		switch (code) {
-		case BPF_S_LD_W_ABS:
+		case BPF_LD | BPF_W | BPF_ABS:
 			ftest->code = BPF_LDX | BPF_W | BPF_ABS;
 			/* 32-bit aligned and not out of bounds. */
 			if (k >= sizeof(struct seccomp_data) || k & 3)
 				return -EINVAL;
 			continue;
-		case BPF_S_LD_W_LEN:
+		case BPF_LD | BPF_W | BPF_LEN:
 			ftest->code = BPF_LD | BPF_IMM;
 			ftest->k = sizeof(struct seccomp_data);
 			continue;
-		case BPF_S_LDX_W_LEN:
+		case BPF_LDX | BPF_W | BPF_LEN:
 			ftest->code = BPF_LDX | BPF_IMM;
 			ftest->k = sizeof(struct seccomp_data);
 			continue;
 		/* Explicitly include allowed calls. */
-		case BPF_S_RET_K:
-		case BPF_S_RET_A:
-		case BPF_S_ALU_ADD_K:
-		case BPF_S_ALU_ADD_X:
-		case BPF_S_ALU_SUB_K:
-		case BPF_S_ALU_SUB_X:
-		case BPF_S_ALU_MUL_K:
-		case BPF_S_ALU_MUL_X:
-		case BPF_S_ALU_DIV_X:
-		case BPF_S_ALU_AND_K:
-		case BPF_S_ALU_AND_X:
-		case BPF_S_ALU_OR_K:
-		case BPF_S_ALU_OR_X:
-		case BPF_S_ALU_XOR_K:
-		case BPF_S_ALU_XOR_X:
-		case BPF_S_ALU_LSH_K:
-		case BPF_S_ALU_LSH_X:
-		case BPF_S_ALU_RSH_K:
-		case BPF_S_ALU_RSH_X:
-		case BPF_S_ALU_NEG:
-		case BPF_S_LD_IMM:
-		case BPF_S_LDX_IMM:
-		case BPF_S_MISC_TAX:
-		case BPF_S_MISC_TXA:
-		case BPF_S_ALU_DIV_K:
-		case BPF_S_LD_MEM:
-		case BPF_S_LDX_MEM:
-		case BPF_S_ST:
-		case BPF_S_STX:
-		case BPF_S_JMP_JA:
-		case BPF_S_JMP_JEQ_K:
-		case BPF_S_JMP_JEQ_X:
-		case BPF_S_JMP_JGE_K:
-		case BPF_S_JMP_JGE_X:
-		case BPF_S_JMP_JGT_K:
-		case BPF_S_JMP_JGT_X:
-		case BPF_S_JMP_JSET_K:
-		case BPF_S_JMP_JSET_X:
-			sk_decode_filter(ftest, ftest);
+		case BPF_RET | BPF_K:
+		case BPF_RET | BPF_A:
+		case BPF_ALU | BPF_ADD | BPF_K:
+		case BPF_ALU | BPF_ADD | BPF_X:
+		case BPF_ALU | BPF_SUB | BPF_K:
+		case BPF_ALU | BPF_SUB | BPF_X:
+		case BPF_ALU | BPF_MUL | BPF_K:
+		case BPF_ALU | BPF_MUL | BPF_X:
+		case BPF_ALU | BPF_DIV | BPF_K:
+		case BPF_ALU | BPF_DIV | BPF_X:
+		case BPF_ALU | BPF_AND | BPF_K:
+		case BPF_ALU | BPF_AND | BPF_X:
+		case BPF_ALU | BPF_OR | BPF_K:
+		case BPF_ALU | BPF_OR | BPF_X:
+		case BPF_ALU | BPF_XOR | BPF_K:
+		case BPF_ALU | BPF_XOR | BPF_X:
+		case BPF_ALU | BPF_LSH | BPF_K:
+		case BPF_ALU | BPF_LSH | BPF_X:
+		case BPF_ALU | BPF_RSH | BPF_K:
+		case BPF_ALU | BPF_RSH | BPF_X:
+		case BPF_ALU | BPF_NEG:
+		case BPF_LD | BPF_IMM:
+		case BPF_LDX | BPF_IMM:
+		case BPF_MISC | BPF_TAX:
+		case BPF_MISC | BPF_TXA:
+		case BPF_LD | BPF_MEM:
+		case BPF_LDX | BPF_MEM:
+		case BPF_ST:
+		case BPF_STX:
+		case BPF_JMP | BPF_JA:
+		case BPF_JMP | BPF_JEQ | BPF_K:
+		case BPF_JMP | BPF_JEQ | BPF_X:
+		case BPF_JMP | BPF_JGE | BPF_K:
+		case BPF_JMP | BPF_JGE | BPF_X:
+		case BPF_JMP | BPF_JGT | BPF_K:
+		case BPF_JMP | BPF_JGT | BPF_X:
+		case BPF_JMP | BPF_JSET | BPF_K:
+		case BPF_JMP | BPF_JSET | BPF_X:
 			continue;
 		default:
 			return -EINVAL;

commit 5fe821a9dee241fa450703ab7015d970ee0cfb8d
Author: Alexei Starovoitov <ast@plumgrid.com>
Date:   Mon May 19 14:56:14 2014 -0700

    net: filter: cleanup invocation of internal BPF
    
    Kernel API for classic BPF socket filters is:
    
    sk_unattached_filter_create() - validate classic BPF, convert, JIT
    SK_RUN_FILTER() - run it
    sk_unattached_filter_destroy() - destroy socket filter
    
    Cleanup internal BPF kernel API as following:
    
    sk_filter_select_runtime() - final step of internal BPF creation.
      Try to JIT internal BPF program, if JIT is not available select interpreter
    SK_RUN_FILTER() - run it
    sk_filter_free() - free internal BPF program
    
    Disallow direct calls to BPF interpreter. Execution of the BPF program should
    be done with SK_RUN_FILTER() macro.
    
    Example of internal BPF create, run, destroy:
    
      struct sk_filter *fp;
    
      fp = kzalloc(sk_filter_size(prog_len), GFP_KERNEL);
      memcpy(fp->insni, prog, prog_len * sizeof(fp->insni[0]));
      fp->len = prog_len;
    
      sk_filter_select_runtime(fp);
    
      SK_RUN_FILTER(fp, ctx);
    
      sk_filter_free(fp);
    
    Sockets, seccomp, testsuite, tracing are using different ways to populate
    sk_filter, so first steps of program creation are not common.
    
    Signed-off-by: Alexei Starovoitov <ast@plumgrid.com>
    Acked-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 7e02d624cc50..1036b6f2fded 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -273,10 +273,8 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 
 	atomic_set(&filter->usage, 1);
 	filter->prog->len = new_len;
-	filter->prog->bpf_func = (void *)sk_run_filter_int_seccomp;
 
-	/* JIT internal BPF into native HW instructions */
-	bpf_int_jit_compile(filter->prog);
+	sk_filter_select_runtime(filter->prog);
 
 	/*
 	 * If there is an existing filter, make it the prev and don't drop its
@@ -340,7 +338,7 @@ void put_seccomp_filter(struct task_struct *tsk)
 	while (orig && atomic_dec_and_test(&orig->usage)) {
 		struct seccomp_filter *freeme = orig;
 		orig = orig->prev;
-		bpf_jit_free(freeme->prog);
+		sk_filter_free(freeme->prog);
 		kfree(freeme);
 	}
 }

commit 8f577cadf7181243d336be9aba40c1bcc02c4c54
Author: Alexei Starovoitov <ast@plumgrid.com>
Date:   Tue May 13 19:50:47 2014 -0700

    seccomp: JIT compile seccomp filter
    
    Take advantage of internal BPF JIT
    
    05-sim-long_jumps.c of libseccomp was used as micro-benchmark:
    
     seccomp_rule_add_exact(ctx,...
     seccomp_rule_add_exact(ctx,...
    
     rc = seccomp_load(ctx);
    
     for (i = 0; i < 10000000; i++)
        syscall(...);
    
    $ sudo sysctl net.core.bpf_jit_enable=1
    $ time ./bench
    real    0m2.769s
    user    0m1.136s
    sys     0m1.624s
    
    $ sudo sysctl net.core.bpf_jit_enable=0
    $ time ./bench
    real    0m5.825s
    user    0m1.268s
    sys     0m4.548s
    
    Signed-off-by: Alexei Starovoitov <ast@plumgrid.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index b35c21503a36..7e02d624cc50 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -54,8 +54,7 @@
 struct seccomp_filter {
 	atomic_t usage;
 	struct seccomp_filter *prev;
-	unsigned short len;  /* Instruction count */
-	struct sock_filter_int insnsi[];
+	struct sk_filter *prog;
 };
 
 /* Limit any path through the tree to 256KB worth of instructions. */
@@ -189,7 +188,8 @@ static u32 seccomp_run_filters(int syscall)
 	 * value always takes priority (ignoring the DATA).
 	 */
 	for (f = current->seccomp.filter; f; f = f->prev) {
-		u32 cur_ret = sk_run_filter_int_seccomp(&sd, f->insnsi);
+		u32 cur_ret = SK_RUN_FILTER(f->prog, (void *)&sd);
+
 		if ((cur_ret & SECCOMP_RET_ACTION) < (ret & SECCOMP_RET_ACTION))
 			ret = cur_ret;
 	}
@@ -215,7 +215,7 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 		return -EINVAL;
 
 	for (filter = current->seccomp.filter; filter; filter = filter->prev)
-		total_insns += filter->len + 4;  /* include a 4 instr penalty */
+		total_insns += filter->prog->len + 4;  /* include a 4 instr penalty */
 	if (total_insns > MAX_INSNS_PER_PATH)
 		return -ENOMEM;
 
@@ -256,19 +256,27 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 
 	/* Allocate a new seccomp_filter */
 	ret = -ENOMEM;
-	filter = kzalloc(sizeof(struct seccomp_filter) +
-			 sizeof(struct sock_filter_int) * new_len,
+	filter = kzalloc(sizeof(struct seccomp_filter),
 			 GFP_KERNEL|__GFP_NOWARN);
 	if (!filter)
 		goto free_prog;
 
-	ret = sk_convert_filter(fp, fprog->len, filter->insnsi, &new_len);
-	if (ret)
+	filter->prog = kzalloc(sk_filter_size(new_len),
+			       GFP_KERNEL|__GFP_NOWARN);
+	if (!filter->prog)
 		goto free_filter;
+
+	ret = sk_convert_filter(fp, fprog->len, filter->prog->insnsi, &new_len);
+	if (ret)
+		goto free_filter_prog;
 	kfree(fp);
 
 	atomic_set(&filter->usage, 1);
-	filter->len = new_len;
+	filter->prog->len = new_len;
+	filter->prog->bpf_func = (void *)sk_run_filter_int_seccomp;
+
+	/* JIT internal BPF into native HW instructions */
+	bpf_int_jit_compile(filter->prog);
 
 	/*
 	 * If there is an existing filter, make it the prev and don't drop its
@@ -278,6 +286,8 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 	current->seccomp.filter = filter;
 	return 0;
 
+free_filter_prog:
+	kfree(filter->prog);
 free_filter:
 	kfree(filter);
 free_prog:
@@ -330,6 +340,7 @@ void put_seccomp_filter(struct task_struct *tsk)
 	while (orig && atomic_dec_and_test(&orig->usage)) {
 		struct seccomp_filter *freeme = orig;
 		orig = orig->prev;
+		bpf_jit_free(freeme->prog);
 		kfree(freeme);
 	}
 }

commit 0acf07d240a84069c4a6651e6030cf35d30c7159
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Apr 16 10:54:34 2014 -0700

    seccomp: fix memory leak on filter attach
    
    This sets the correct error code when final filter memory is unavailable,
    and frees the raw filter no matter what.
    
    unreferenced object 0xffff8800d6ea4000 (size 512):
      comm "sshd", pid 278, jiffies 4294898315 (age 46.653s)
      hex dump (first 32 bytes):
        21 00 00 00 04 00 00 00 15 00 01 00 3e 00 00 c0  !...........>...
        06 00 00 00 00 00 00 00 21 00 00 00 00 00 00 00  ........!.......
      backtrace:
        [<ffffffff8151414e>] kmemleak_alloc+0x4e/0xb0
        [<ffffffff811a3a40>] __kmalloc+0x280/0x320
        [<ffffffff8110842e>] prctl_set_seccomp+0x11e/0x3b0
        [<ffffffff8107bb6b>] SyS_prctl+0x3bb/0x4a0
        [<ffffffff8152ef2d>] system_call_fastpath+0x1a/0x1f
        [<ffffffffffffffff>] 0xffffffffffffffff
    
    Reported-by: Masami Ichikawa <masami256@gmail.com>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Tested-by: Masami Ichikawa <masami256@gmail.com>
    Acked-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 590c37925084..b35c21503a36 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -255,6 +255,7 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 		goto free_prog;
 
 	/* Allocate a new seccomp_filter */
+	ret = -ENOMEM;
 	filter = kzalloc(sizeof(struct seccomp_filter) +
 			 sizeof(struct sock_filter_int) * new_len,
 			 GFP_KERNEL|__GFP_NOWARN);
@@ -264,6 +265,7 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 	ret = sk_convert_filter(fp, fprog->len, filter->insnsi, &new_len);
 	if (ret)
 		goto free_filter;
+	kfree(fp);
 
 	atomic_set(&filter->usage, 1);
 	filter->len = new_len;

commit 2eac7648321f4a08aa4078504d7727af0af7173b
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Mon Apr 14 21:02:59 2014 +0200

    seccomp: fix populating a0-a5 syscall args in 32-bit x86 BPF
    
    Linus reports that on 32-bit x86 Chromium throws the following seccomp
    resp. audit log messages:
    
      audit: type=1326 audit(1397359304.356:28108): auid=500 uid=500
    gid=500 ses=2 subj=unconfined_u:unconfined_r:chrome_sandbox_t:s0-s0:c0.c1023
    pid=3677 comm="chrome" exe="/opt/google/chrome/chrome" sig=0
    syscall=172 compat=0 ip=0xb2dd9852 code=0x30000
    
      audit: type=1326 audit(1397359304.356:28109): auid=500 uid=500
    gid=500 ses=2 subj=unconfined_u:unconfined_r:chrome_sandbox_t:s0-s0:c0.c1023
    pid=3677 comm="chrome" exe="/opt/google/chrome/chrome" sig=0 syscall=5
    compat=0 ip=0xb2dd9852 code=0x50000
    
    These audit messages are being triggered via audit_seccomp() through
    __secure_computing() in seccomp mode (BPF) filter with seccomp return
    codes 0x30000 (== SECCOMP_RET_TRAP) and 0x50000 (== SECCOMP_RET_ERRNO)
    during filter runtime. Moreover, Linus reports that x86_64 Chromium
    seems fine.
    
    The underlying issue that explains this is that the implementation of
    populate_seccomp_data() is wrong. Our seccomp data structure sd that
    is being shared with user ABI is:
    
      struct seccomp_data {
        int nr;
        __u32 arch;
        __u64 instruction_pointer;
        __u64 args[6];
      };
    
    Therefore, a simple cast to 'unsigned long *' for storing the value of
    the syscall argument via syscall_get_arguments() is just wrong as on
    32-bit x86 (or any other 32bit arch), it would result in storing a0-a5
    at wrong offsets in args[] member, and thus i) could leak stack memory
    to user space and ii) tampers with the logic of seccomp BPF programs
    that read out and check for syscall arguments:
    
      syscall_get_arguments(task, regs, 0, 1, (unsigned long *) &sd->args[0]);
    
    Tested on 32-bit x86 with Google Chrome, unfortunately only via remote
    test machine through slow ssh X forwarding, but it fixes the issue on
    my side. So fix it up by storing args in type correct variables, gcc
    is clever and optimizes the copy away in other cases, e.g. x86_64.
    
    Fixes: bd4cf0ed331a ("net: filter: rework/optimize internal BPF interpreter's instruction set")
    Reported-and-bisected-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: Alexei Starovoitov <ast@plumgrid.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Eric Paris <eparis@redhat.com>
    Cc: James Morris <james.l.morris@oracle.com>
    Cc: Kees Cook <keescook@chromium.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index d8d046c0726a..590c37925084 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -69,18 +69,17 @@ static void populate_seccomp_data(struct seccomp_data *sd)
 {
 	struct task_struct *task = current;
 	struct pt_regs *regs = task_pt_regs(task);
+	unsigned long args[6];
 
 	sd->nr = syscall_get_nr(task, regs);
 	sd->arch = syscall_get_arch();
-
-	/* Unroll syscall_get_args to help gcc on arm. */
-	syscall_get_arguments(task, regs, 0, 1, (unsigned long *) &sd->args[0]);
-	syscall_get_arguments(task, regs, 1, 1, (unsigned long *) &sd->args[1]);
-	syscall_get_arguments(task, regs, 2, 1, (unsigned long *) &sd->args[2]);
-	syscall_get_arguments(task, regs, 3, 1, (unsigned long *) &sd->args[3]);
-	syscall_get_arguments(task, regs, 4, 1, (unsigned long *) &sd->args[4]);
-	syscall_get_arguments(task, regs, 5, 1, (unsigned long *) &sd->args[5]);
-
+	syscall_get_arguments(task, regs, 0, 6, args);
+	sd->args[0] = args[0];
+	sd->args[1] = args[1];
+	sd->args[2] = args[2];
+	sd->args[3] = args[3];
+	sd->args[4] = args[4];
+	sd->args[5] = args[5];
 	sd->instruction_pointer = KSTK_EIP(task);
 }
 

commit 0b747172dce6e0905ab173afbaffebb7a11d89bd
Merge: b7e70ca9c7d7 312103d64d0f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Apr 12 12:38:53 2014 -0700

    Merge git://git.infradead.org/users/eparis/audit
    
    Pull audit updates from Eric Paris.
    
    * git://git.infradead.org/users/eparis/audit: (28 commits)
      AUDIT: make audit_is_compat depend on CONFIG_AUDIT_COMPAT_GENERIC
      audit: renumber AUDIT_FEATURE_CHANGE into the 1300 range
      audit: do not cast audit_rule_data pointers pointlesly
      AUDIT: Allow login in non-init namespaces
      audit: define audit_is_compat in kernel internal header
      kernel: Use RCU_INIT_POINTER(x, NULL) in audit.c
      sched: declare pid_alive as inline
      audit: use uapi/linux/audit.h for AUDIT_ARCH declarations
      syscall_get_arch: remove useless function arguments
      audit: remove stray newline from audit_log_execve_info() audit_panic() call
      audit: remove stray newlines from audit_log_lost messages
      audit: include subject in login records
      audit: remove superfluous new- prefix in AUDIT_LOGIN messages
      audit: allow user processes to log from another PID namespace
      audit: anchor all pid references in the initial pid namespace
      audit: convert PPIDs to the inital PID namespace.
      pid: get pid_t ppid of task in init_pid_ns
      audit: rename the misleading audit_get_context() to audit_take_context()
      audit: Add generic compat syscall support
      audit: Add CONFIG_HAVE_ARCH_AUDITSYSCALL
      ...

commit bea803183e12a1c78a12ec70907174d13d958333
Merge: cd6362befe4c f64410ec6654
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Apr 3 09:26:18 2014 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security
    
    Pull security subsystem updates from James Morris:
     "Apart from reordering the SELinux mmap code to ensure DAC is called
      before MAC, these are minor maintenance updates"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/jmorris/linux-security: (23 commits)
      selinux: correctly label /proc inodes in use before the policy is loaded
      selinux: put the mmap() DAC controls before the MAC controls
      selinux: fix the output of ./scripts/get_maintainer.pl for SELinux
      evm: enable key retention service automatically
      ima: skip memory allocation for empty files
      evm: EVM does not use MD5
      ima: return d_name.name if d_path fails
      integrity: fix checkpatch errors
      ima: fix erroneous removal of security.ima xattr
      security: integrity: Use a more current logging style
      MAINTAINERS: email updates and other misc. changes
      ima: reduce memory usage when a template containing the n field is used
      ima: restore the original behavior for sending data with ima template
      Integrity: Pass commname via get_task_comm()
      fs: move i_readcount
      ima: use static const char array definitions
      security: have cap_dentry_init_security return error
      ima: new helper: file_inode(file)
      kernel: Mark function as static in kernel/seccomp.c
      capability: Use current logging styles
      ...

commit bd4cf0ed331a275e9bf5a49e6d0fd55dffc551b8
Author: Alexei Starovoitov <ast@plumgrid.com>
Date:   Fri Mar 28 18:58:25 2014 +0100

    net: filter: rework/optimize internal BPF interpreter's instruction set
    
    This patch replaces/reworks the kernel-internal BPF interpreter with
    an optimized BPF instruction set format that is modelled closer to
    mimic native instruction sets and is designed to be JITed with one to
    one mapping. Thus, the new interpreter is noticeably faster than the
    current implementation of sk_run_filter(); mainly for two reasons:
    
    1. Fall-through jumps:
    
      BPF jump instructions are forced to go either 'true' or 'false'
      branch which causes branch-miss penalty. The new BPF jump
      instructions have only one branch and fall-through otherwise,
      which fits the CPU branch predictor logic better. `perf stat`
      shows drastic difference for branch-misses between the old and
      new code.
    
    2. Jump-threaded implementation of interpreter vs switch
       statement:
    
      Instead of single table-jump at the top of 'switch' statement,
      gcc will now generate multiple table-jump instructions, which
      helps CPU branch predictor logic.
    
    Note that the verification of filters is still being done through
    sk_chk_filter() in classical BPF format, so filters from user- or
    kernel space are verified in the same way as we do now, and same
    restrictions/constraints hold as well.
    
    We reuse current BPF JIT compilers in a way that this upgrade would
    even be fine as is, but nevertheless allows for a successive upgrade
    of BPF JIT compilers to the new format.
    
    The internal instruction set migration is being done after the
    probing for JIT compilation, so in case JIT compilers are able to
    create a native opcode image, we're going to use that, and in all
    other cases we're doing a follow-up migration of the BPF program's
    instruction set, so that it can be transparently run in the new
    interpreter.
    
    In short, the *internal* format extends BPF in the following way (more
    details can be taken from the appended documentation):
    
      - Number of registers increase from 2 to 10
      - Register width increases from 32-bit to 64-bit
      - Conditional jt/jf targets replaced with jt/fall-through
      - Adds signed > and >= insns
      - 16 4-byte stack slots for register spill-fill replaced
        with up to 512 bytes of multi-use stack space
      - Introduction of bpf_call insn and register passing convention
        for zero overhead calls from/to other kernel functions
      - Adds arithmetic right shift and endianness conversion insns
      - Adds atomic_add insn
      - Old tax/txa insns are replaced with 'mov dst,src' insn
    
    Performance of two BPF filters generated by libpcap resp. bpf_asm
    was measured on x86_64, i386 and arm32 (other libpcap programs
    have similar performance differences):
    
    fprog #1 is taken from Documentation/networking/filter.txt:
    tcpdump -i eth0 port 22 -dd
    
    fprog #2 is taken from 'man tcpdump':
    tcpdump -i eth0 'tcp port 22 and (((ip[2:2] - ((ip[0]&0xf)<<2)) -
       ((tcp[12]&0xf0)>>2)) != 0)' -dd
    
    Raw performance data from BPF micro-benchmark: SK_RUN_FILTER on the
    same SKB (cache-hit) or 10k SKBs (cache-miss); time in ns per call,
    smaller is better:
    
    --x86_64--
             fprog #1  fprog #1   fprog #2  fprog #2
             cache-hit cache-miss cache-hit cache-miss
    old BPF      90       101        192       202
    new BPF      31        71         47        97
    old BPF jit  12        34         17        44
    new BPF jit TBD
    
    --i386--
             fprog #1  fprog #1   fprog #2  fprog #2
             cache-hit cache-miss cache-hit cache-miss
    old BPF     107       136        227       252
    new BPF      40       119         69       172
    
    --arm32--
             fprog #1  fprog #1   fprog #2  fprog #2
             cache-hit cache-miss cache-hit cache-miss
    old BPF     202       300        475       540
    new BPF     180       270        330       470
    old BPF jit  26       182         37       202
    new BPF jit TBD
    
    Thus, without changing any userland BPF filters, applications on
    top of AF_PACKET (or other families) such as libpcap/tcpdump, cls_bpf
    classifier, netfilter's xt_bpf, team driver's load-balancing mode,
    and many more will have better interpreter filtering performance.
    
    While we are replacing the internal BPF interpreter, we also need
    to convert seccomp BPF in the same step to make use of the new
    internal structure since it makes use of lower-level API details
    without being further decoupled through higher-level calls like
    sk_unattached_filter_{create,destroy}(), for example.
    
    Just as for normal socket filtering, also seccomp BPF experiences
    a time-to-verdict speedup:
    
    05-sim-long_jumps.c of libseccomp was used as micro-benchmark:
    
      seccomp_rule_add_exact(ctx,...
      seccomp_rule_add_exact(ctx,...
    
      rc = seccomp_load(ctx);
    
      for (i = 0; i < 10000000; i++)
         syscall(199, 100);
    
    'short filter' has 2 rules
    'large filter' has 200 rules
    
    'short filter' performance is slightly better on x86_64/i386/arm32
    'large filter' is much faster on x86_64 and i386 and shows no
                   difference on arm32
    
    --x86_64-- short filter
    old BPF: 2.7 sec
     39.12%  bench  libc-2.15.so       [.] syscall
      8.10%  bench  [kernel.kallsyms]  [k] sk_run_filter
      6.31%  bench  [kernel.kallsyms]  [k] system_call
      5.59%  bench  [kernel.kallsyms]  [k] trace_hardirqs_on_caller
      4.37%  bench  [kernel.kallsyms]  [k] trace_hardirqs_off_caller
      3.70%  bench  [kernel.kallsyms]  [k] __secure_computing
      3.67%  bench  [kernel.kallsyms]  [k] lock_is_held
      3.03%  bench  [kernel.kallsyms]  [k] seccomp_bpf_load
    new BPF: 2.58 sec
     42.05%  bench  libc-2.15.so       [.] syscall
      6.91%  bench  [kernel.kallsyms]  [k] system_call
      6.25%  bench  [kernel.kallsyms]  [k] trace_hardirqs_on_caller
      6.07%  bench  [kernel.kallsyms]  [k] __secure_computing
      5.08%  bench  [kernel.kallsyms]  [k] sk_run_filter_int_seccomp
    
    --arm32-- short filter
    old BPF: 4.0 sec
     39.92%  bench  [kernel.kallsyms]  [k] vector_swi
     16.60%  bench  [kernel.kallsyms]  [k] sk_run_filter
     14.66%  bench  libc-2.17.so       [.] syscall
      5.42%  bench  [kernel.kallsyms]  [k] seccomp_bpf_load
      5.10%  bench  [kernel.kallsyms]  [k] __secure_computing
    new BPF: 3.7 sec
     35.93%  bench  [kernel.kallsyms]  [k] vector_swi
     21.89%  bench  libc-2.17.so       [.] syscall
     13.45%  bench  [kernel.kallsyms]  [k] sk_run_filter_int_seccomp
      6.25%  bench  [kernel.kallsyms]  [k] __secure_computing
      3.96%  bench  [kernel.kallsyms]  [k] syscall_trace_exit
    
    --x86_64-- large filter
    old BPF: 8.6 seconds
        73.38%    bench  [kernel.kallsyms]  [k] sk_run_filter
        10.70%    bench  libc-2.15.so       [.] syscall
         5.09%    bench  [kernel.kallsyms]  [k] seccomp_bpf_load
         1.97%    bench  [kernel.kallsyms]  [k] system_call
    new BPF: 5.7 seconds
        66.20%    bench  [kernel.kallsyms]  [k] sk_run_filter_int_seccomp
        16.75%    bench  libc-2.15.so       [.] syscall
         3.31%    bench  [kernel.kallsyms]  [k] system_call
         2.88%    bench  [kernel.kallsyms]  [k] __secure_computing
    
    --i386-- large filter
    old BPF: 5.4 sec
    new BPF: 3.8 sec
    
    --arm32-- large filter
    old BPF: 13.5 sec
     73.88%  bench  [kernel.kallsyms]  [k] sk_run_filter
     10.29%  bench  [kernel.kallsyms]  [k] vector_swi
      6.46%  bench  libc-2.17.so       [.] syscall
      2.94%  bench  [kernel.kallsyms]  [k] seccomp_bpf_load
      1.19%  bench  [kernel.kallsyms]  [k] __secure_computing
      0.87%  bench  [kernel.kallsyms]  [k] sys_getuid
    new BPF: 13.5 sec
     76.08%  bench  [kernel.kallsyms]  [k] sk_run_filter_int_seccomp
     10.98%  bench  [kernel.kallsyms]  [k] vector_swi
      5.87%  bench  libc-2.17.so       [.] syscall
      1.77%  bench  [kernel.kallsyms]  [k] __secure_computing
      0.93%  bench  [kernel.kallsyms]  [k] sys_getuid
    
    BPF filters generated by seccomp are very branchy, so the new
    internal BPF performance is better than the old one. Performance
    gains will be even higher when BPF JIT is committed for the
    new structure, which is planned in future work (as successive
    JIT migrations).
    
    BPF has also been stress-tested with trinity's BPF fuzzer.
    
    Joint work with Daniel Borkmann.
    
    Signed-off-by: Alexei Starovoitov <ast@plumgrid.com>
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Cc: Hagen Paul Pfeifer <hagen@jauu.net>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Paul Moore <pmoore@redhat.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: H. Peter Anvin <hpa@linux.intel.com>
    Cc: linux-kernel@vger.kernel.org
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index b7a10048a32c..4f18e754c23e 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -55,60 +55,33 @@ struct seccomp_filter {
 	atomic_t usage;
 	struct seccomp_filter *prev;
 	unsigned short len;  /* Instruction count */
-	struct sock_filter insns[];
+	struct sock_filter_int insnsi[];
 };
 
 /* Limit any path through the tree to 256KB worth of instructions. */
 #define MAX_INSNS_PER_PATH ((1 << 18) / sizeof(struct sock_filter))
 
-/**
- * get_u32 - returns a u32 offset into data
- * @data: a unsigned 64 bit value
- * @index: 0 or 1 to return the first or second 32-bits
- *
- * This inline exists to hide the length of unsigned long.  If a 32-bit
- * unsigned long is passed in, it will be extended and the top 32-bits will be
- * 0. If it is a 64-bit unsigned long, then whatever data is resident will be
- * properly returned.
- *
+/*
  * Endianness is explicitly ignored and left for BPF program authors to manage
  * as per the specific architecture.
  */
-static inline u32 get_u32(u64 data, int index)
+static void populate_seccomp_data(struct seccomp_data *sd)
 {
-	return ((u32 *)&data)[index];
-}
+	struct task_struct *task = current;
+	struct pt_regs *regs = task_pt_regs(task);
 
-/* Helper for bpf_load below. */
-#define BPF_DATA(_name) offsetof(struct seccomp_data, _name)
-/**
- * bpf_load: checks and returns a pointer to the requested offset
- * @off: offset into struct seccomp_data to load from
- *
- * Returns the requested 32-bits of data.
- * seccomp_check_filter() should assure that @off is 32-bit aligned
- * and not out of bounds.  Failure to do so is a BUG.
- */
-u32 seccomp_bpf_load(int off)
-{
-	struct pt_regs *regs = task_pt_regs(current);
-	if (off == BPF_DATA(nr))
-		return syscall_get_nr(current, regs);
-	if (off == BPF_DATA(arch))
-		return syscall_get_arch(current, regs);
-	if (off >= BPF_DATA(args[0]) && off < BPF_DATA(args[6])) {
-		unsigned long value;
-		int arg = (off - BPF_DATA(args[0])) / sizeof(u64);
-		int index = !!(off % sizeof(u64));
-		syscall_get_arguments(current, regs, arg, 1, &value);
-		return get_u32(value, index);
-	}
-	if (off == BPF_DATA(instruction_pointer))
-		return get_u32(KSTK_EIP(current), 0);
-	if (off == BPF_DATA(instruction_pointer) + sizeof(u32))
-		return get_u32(KSTK_EIP(current), 1);
-	/* seccomp_check_filter should make this impossible. */
-	BUG();
+	sd->nr = syscall_get_nr(task, regs);
+	sd->arch = syscall_get_arch(task, regs);
+
+	/* Unroll syscall_get_args to help gcc on arm. */
+	syscall_get_arguments(task, regs, 0, 1, (unsigned long *) &sd->args[0]);
+	syscall_get_arguments(task, regs, 1, 1, (unsigned long *) &sd->args[1]);
+	syscall_get_arguments(task, regs, 2, 1, (unsigned long *) &sd->args[2]);
+	syscall_get_arguments(task, regs, 3, 1, (unsigned long *) &sd->args[3]);
+	syscall_get_arguments(task, regs, 4, 1, (unsigned long *) &sd->args[4]);
+	syscall_get_arguments(task, regs, 5, 1, (unsigned long *) &sd->args[5]);
+
+	sd->instruction_pointer = KSTK_EIP(task);
 }
 
 /**
@@ -133,17 +106,17 @@ static int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)
 
 		switch (code) {
 		case BPF_S_LD_W_ABS:
-			ftest->code = BPF_S_ANC_SECCOMP_LD_W;
+			ftest->code = BPF_LDX | BPF_W | BPF_ABS;
 			/* 32-bit aligned and not out of bounds. */
 			if (k >= sizeof(struct seccomp_data) || k & 3)
 				return -EINVAL;
 			continue;
 		case BPF_S_LD_W_LEN:
-			ftest->code = BPF_S_LD_IMM;
+			ftest->code = BPF_LD | BPF_IMM;
 			ftest->k = sizeof(struct seccomp_data);
 			continue;
 		case BPF_S_LDX_W_LEN:
-			ftest->code = BPF_S_LDX_IMM;
+			ftest->code = BPF_LDX | BPF_IMM;
 			ftest->k = sizeof(struct seccomp_data);
 			continue;
 		/* Explicitly include allowed calls. */
@@ -185,6 +158,7 @@ static int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)
 		case BPF_S_JMP_JGT_X:
 		case BPF_S_JMP_JSET_K:
 		case BPF_S_JMP_JSET_X:
+			sk_decode_filter(ftest, ftest);
 			continue;
 		default:
 			return -EINVAL;
@@ -202,18 +176,21 @@ static int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)
 static u32 seccomp_run_filters(int syscall)
 {
 	struct seccomp_filter *f;
+	struct seccomp_data sd;
 	u32 ret = SECCOMP_RET_ALLOW;
 
 	/* Ensure unexpected behavior doesn't result in failing open. */
 	if (WARN_ON(current->seccomp.filter == NULL))
 		return SECCOMP_RET_KILL;
 
+	populate_seccomp_data(&sd);
+
 	/*
 	 * All filters in the list are evaluated and the lowest BPF return
 	 * value always takes priority (ignoring the DATA).
 	 */
 	for (f = current->seccomp.filter; f; f = f->prev) {
-		u32 cur_ret = sk_run_filter(NULL, f->insns);
+		u32 cur_ret = sk_run_filter_int_seccomp(&sd, f->insnsi);
 		if ((cur_ret & SECCOMP_RET_ACTION) < (ret & SECCOMP_RET_ACTION))
 			ret = cur_ret;
 	}
@@ -231,6 +208,8 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 	struct seccomp_filter *filter;
 	unsigned long fp_size = fprog->len * sizeof(struct sock_filter);
 	unsigned long total_insns = fprog->len;
+	struct sock_filter *fp;
+	int new_len;
 	long ret;
 
 	if (fprog->len == 0 || fprog->len > BPF_MAXINSNS)
@@ -252,28 +231,43 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 				     CAP_SYS_ADMIN) != 0)
 		return -EACCES;
 
-	/* Allocate a new seccomp_filter */
-	filter = kzalloc(sizeof(struct seccomp_filter) + fp_size,
-			 GFP_KERNEL|__GFP_NOWARN);
-	if (!filter)
+	fp = kzalloc(fp_size, GFP_KERNEL|__GFP_NOWARN);
+	if (!fp)
 		return -ENOMEM;
-	atomic_set(&filter->usage, 1);
-	filter->len = fprog->len;
 
 	/* Copy the instructions from fprog. */
 	ret = -EFAULT;
-	if (copy_from_user(filter->insns, fprog->filter, fp_size))
-		goto fail;
+	if (copy_from_user(fp, fprog->filter, fp_size))
+		goto free_prog;
 
 	/* Check and rewrite the fprog via the skb checker */
-	ret = sk_chk_filter(filter->insns, filter->len);
+	ret = sk_chk_filter(fp, fprog->len);
 	if (ret)
-		goto fail;
+		goto free_prog;
 
 	/* Check and rewrite the fprog for seccomp use */
-	ret = seccomp_check_filter(filter->insns, filter->len);
+	ret = seccomp_check_filter(fp, fprog->len);
+	if (ret)
+		goto free_prog;
+
+	/* Convert 'sock_filter' insns to 'sock_filter_int' insns */
+	ret = sk_convert_filter(fp, fprog->len, NULL, &new_len);
+	if (ret)
+		goto free_prog;
+
+	/* Allocate a new seccomp_filter */
+	filter = kzalloc(sizeof(struct seccomp_filter) +
+			 sizeof(struct sock_filter_int) * new_len,
+			 GFP_KERNEL|__GFP_NOWARN);
+	if (!filter)
+		goto free_prog;
+
+	ret = sk_convert_filter(fp, fprog->len, filter->insnsi, &new_len);
 	if (ret)
-		goto fail;
+		goto free_filter;
+
+	atomic_set(&filter->usage, 1);
+	filter->len = new_len;
 
 	/*
 	 * If there is an existing filter, make it the prev and don't drop its
@@ -282,8 +276,11 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
 	filter->prev = current->seccomp.filter;
 	current->seccomp.filter = filter;
 	return 0;
-fail:
+
+free_filter:
 	kfree(filter);
+free_prog:
+	kfree(fp);
 	return ret;
 }
 

commit 5e937a9ae9137899c6641d718bd3820861099a09
Author: Eric Paris <eparis@redhat.com>
Date:   Tue Mar 11 12:48:43 2014 -0400

    syscall_get_arch: remove useless function arguments
    
    Every caller of syscall_get_arch() uses current for the task and no
    implementors of the function need args.  So just get rid of both of
    those things.  Admittedly, since these are inline functions we aren't
    wasting stack space, but it just makes the prototypes better.
    
    Signed-off-by: Eric Paris <eparis@redhat.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-mips@linux-mips.org
    Cc: linux390@de.ibm.com
    Cc: x86@kernel.org
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-s390@vger.kernel.org
    Cc: linux-arch@vger.kernel.org

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index b7a10048a32c..eda2da3df822 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -95,7 +95,7 @@ u32 seccomp_bpf_load(int off)
 	if (off == BPF_DATA(nr))
 		return syscall_get_nr(current, regs);
 	if (off == BPF_DATA(arch))
-		return syscall_get_arch(current, regs);
+		return syscall_get_arch();
 	if (off >= BPF_DATA(args[0]) && off < BPF_DATA(args[6])) {
 		unsigned long value;
 		int arg = (off - BPF_DATA(args[0])) / sizeof(u64);
@@ -351,7 +351,7 @@ static void seccomp_send_sigsys(int syscall, int reason)
 	info.si_code = SYS_SECCOMP;
 	info.si_call_addr = (void __user *)KSTK_EIP(current);
 	info.si_errno = reason;
-	info.si_arch = syscall_get_arch(current, task_pt_regs(current));
+	info.si_arch = syscall_get_arch();
 	info.si_syscall = syscall;
 	force_sig_info(SIGSYS, &info, current);
 }

commit 864f32a52b53341c54a25953afb5b66ed79a7f76
Author: Rashika Kheria <rashika.kheria@gmail.com>
Date:   Thu Feb 27 17:50:19 2014 +0530

    kernel: Mark function as static in kernel/seccomp.c
    
    Mark function as static in kernel/seccomp.c because it is not used
    outside this file.
    
    This eliminates the following warning in kernel/seccomp.c:
    kernel/seccomp.c:296:6: warning: no previous prototype for ?seccomp_attach_user_filter? [-Wmissing-prototypes]
    
    Signed-off-by: Rashika Kheria <rashika.kheria@gmail.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>
    Acked-by: Kees Cook <keescook@chromium.org>
    Acked-by: Will Drewry <wad@chromium.org>
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index b7a10048a32c..0e004a70f63a 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -293,7 +293,7 @@ static long seccomp_attach_filter(struct sock_fprog *fprog)
  *
  * Returns 0 on success and non-zero otherwise.
  */
-long seccomp_attach_user_filter(char __user *user_filter)
+static long seccomp_attach_user_filter(char __user *user_filter)
 {
 	struct sock_fprog fprog;
 	long ret = -EFAULT;

commit d13274794ad28d90ac81643d3d1d18338d948764
Author: Nicolas Schichan <nschichan@freebox.fr>
Date:   Fri Mar 15 18:02:00 2013 +0100

    seccomp: allow BPF_XOR based ALU instructions.
    
    Allow BPF_XOR based ALU instructions.
    
    Signed-off-by: Nicolas Schichan <nschichan@freebox.fr>
    Acked-by: Kees Cook <keescook@chromium.org>
    Acked-by: Will Drewry <wad@chromium.org>
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 5af44b593770..b7a10048a32c 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -160,6 +160,8 @@ static int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)
 		case BPF_S_ALU_AND_X:
 		case BPF_S_ALU_OR_K:
 		case BPF_S_ALU_OR_X:
+		case BPF_S_ALU_XOR_K:
+		case BPF_S_ALU_XOR_X:
 		case BPF_S_ALU_LSH_K:
 		case BPF_S_ALU_LSH_X:
 		case BPF_S_ALU_RSH_K:

commit 87b526d349b04c31d7b3a40b434eb3f825d22305
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Mon Oct 1 11:40:45 2012 -0700

    seccomp: Make syscall skipping and nr changes more consistent
    
    This fixes two issues that could cause incompatibility between
    kernel versions:
    
     - If a tracer uses SECCOMP_RET_TRACE to select a syscall number
       higher than the largest known syscall, emulate the unknown
       vsyscall by returning -ENOSYS.  (This is unlikely to make a
       noticeable difference on x86-64 due to the way the system call
       entry works.)
    
     - On x86-64 with vsyscall=emulate, skipped vsyscalls were buggy.
    
    This updates the documentation accordingly.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Acked-by: Will Drewry <wad@chromium.org>
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index ee376beedaf9..5af44b593770 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -396,25 +396,29 @@ int __secure_computing(int this_syscall)
 #ifdef CONFIG_SECCOMP_FILTER
 	case SECCOMP_MODE_FILTER: {
 		int data;
+		struct pt_regs *regs = task_pt_regs(current);
 		ret = seccomp_run_filters(this_syscall);
 		data = ret & SECCOMP_RET_DATA;
 		ret &= SECCOMP_RET_ACTION;
 		switch (ret) {
 		case SECCOMP_RET_ERRNO:
 			/* Set the low-order 16-bits as a errno. */
-			syscall_set_return_value(current, task_pt_regs(current),
+			syscall_set_return_value(current, regs,
 						 -data, 0);
 			goto skip;
 		case SECCOMP_RET_TRAP:
 			/* Show the handler the original registers. */
-			syscall_rollback(current, task_pt_regs(current));
+			syscall_rollback(current, regs);
 			/* Let the filter pass back 16 bits of data. */
 			seccomp_send_sigsys(this_syscall, data);
 			goto skip;
 		case SECCOMP_RET_TRACE:
 			/* Skip these calls if there is no tracer. */
-			if (!ptrace_event_enabled(current, PTRACE_EVENT_SECCOMP))
+			if (!ptrace_event_enabled(current, PTRACE_EVENT_SECCOMP)) {
+				syscall_set_return_value(current, regs,
+							 -ENOSYS, 0);
 				goto skip;
+			}
 			/* Allow the BPF to provide the event message */
 			ptrace_event(PTRACE_EVENT_SECCOMP, data);
 			/*
@@ -425,6 +429,9 @@ int __secure_computing(int this_syscall)
 			 */
 			if (fatal_signal_pending(current))
 				break;
+			if (syscall_get_nr(current, regs) < 0)
+				goto skip;  /* Explicit request to skip. */
+
 			return 0;
 		case SECCOMP_RET_ALLOW:
 			return 0;

commit 8156b451f37898d3c3652b4e988a4d62ae16eaac
Author: Will Drewry <wad@chromium.org>
Date:   Tue Apr 17 14:48:58 2012 -0500

    seccomp: fix build warnings when there is no CONFIG_SECCOMP_FILTER
    
    If both audit and seccomp filter support are disabled, 'ret' is marked
    as unused.
    
    If just seccomp filter support is disabled, data and skip are considered
    unused.
    
    This change fixes those build warnings.
    
    Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Will Drewry <wad@chromium.org>
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index d9db6ec46bc9..ee376beedaf9 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -377,8 +377,7 @@ int __secure_computing(int this_syscall)
 	int mode = current->seccomp.mode;
 	int exit_sig = 0;
 	int *syscall;
-	u32 ret = SECCOMP_RET_KILL;
-	int data;
+	u32 ret;
 
 	switch (mode) {
 	case SECCOMP_MODE_STRICT:
@@ -392,12 +391,15 @@ int __secure_computing(int this_syscall)
 				return 0;
 		} while (*++syscall);
 		exit_sig = SIGKILL;
+		ret = SECCOMP_RET_KILL;
 		break;
 #ifdef CONFIG_SECCOMP_FILTER
-	case SECCOMP_MODE_FILTER:
+	case SECCOMP_MODE_FILTER: {
+		int data;
 		ret = seccomp_run_filters(this_syscall);
 		data = ret & SECCOMP_RET_DATA;
-		switch (ret & SECCOMP_RET_ACTION) {
+		ret &= SECCOMP_RET_ACTION;
+		switch (ret) {
 		case SECCOMP_RET_ERRNO:
 			/* Set the low-order 16-bits as a errno. */
 			syscall_set_return_value(current, task_pt_regs(current),
@@ -432,6 +434,7 @@ int __secure_computing(int this_syscall)
 		}
 		exit_sig = SIGSYS;
 		break;
+	}
 #endif
 	default:
 		BUG();
@@ -442,8 +445,10 @@ int __secure_computing(int this_syscall)
 #endif
 	audit_seccomp(this_syscall, exit_sig, ret);
 	do_exit(exit_sig);
+#ifdef CONFIG_SECCOMP_FILTER
 skip:
 	audit_seccomp(this_syscall, exit_sig, ret);
+#endif
 	return -1;
 }
 

commit fb0fadf9b213f55ca9368f3edafe51101d5d2deb
Author: Will Drewry <wad@chromium.org>
Date:   Thu Apr 12 16:48:02 2012 -0500

    ptrace,seccomp: Add PTRACE_SECCOMP support
    
    This change adds support for a new ptrace option, PTRACE_O_TRACESECCOMP,
    and a new return value for seccomp BPF programs, SECCOMP_RET_TRACE.
    
    When a tracer specifies the PTRACE_O_TRACESECCOMP ptrace option, the
    tracer will be notified, via PTRACE_EVENT_SECCOMP, for any syscall that
    results in a BPF program returning SECCOMP_RET_TRACE.  The 16-bit
    SECCOMP_RET_DATA mask of the BPF program return value will be passed as
    the ptrace_message and may be retrieved using PTRACE_GETEVENTMSG.
    
    If the subordinate process is not using seccomp filter, then no
    system call notifications will occur even if the option is specified.
    
    If there is no tracer with PTRACE_O_TRACESECCOMP when SECCOMP_RET_TRACE
    is returned, the system call will not be executed and an -ENOSYS errno
    will be returned to userspace.
    
    This change adds a dependency on the system call slow path.  Any future
    efforts to use the system call fast path for seccomp filter will need to
    address this restriction.
    
    Signed-off-by: Will Drewry <wad@chromium.org>
    Acked-by: Eric Paris <eparis@redhat.com>
    
    v18: - rebase
         - comment fatal_signal check
         - acked-by
         - drop secure_computing_int comment
    v17: - ...
    v16: - update PT_TRACE_MASK to 0xbf4 so that STOP isn't clear on SETOPTIONS call (indan@nul.nu)
           [note PT_TRACE_MASK disappears in linux-next]
    v15: - add audit support for non-zero return codes
         - clean up style (indan@nul.nu)
    v14: - rebase/nochanges
    v13: - rebase on to 88ebdda6159ffc15699f204c33feb3e431bf9bdc
           (Brings back a change to ptrace.c and the masks.)
    v12: - rebase to linux-next
         - use ptrace_event and update arch/Kconfig to mention slow-path dependency
         - drop all tracehook changes and inclusion (oleg@redhat.com)
    v11: - invert the logic to just make it a PTRACE_SYSCALL accelerator
           (indan@nul.nu)
    v10: - moved to PTRACE_O_SECCOMP / PT_TRACE_SECCOMP
    v9:  - n/a
    v8:  - guarded PTRACE_SECCOMP use with an ifdef
    v7:  - introduced
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 9c3830692a08..d9db6ec46bc9 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -24,6 +24,7 @@
 #ifdef CONFIG_SECCOMP_FILTER
 #include <asm/syscall.h>
 #include <linux/filter.h>
+#include <linux/ptrace.h>
 #include <linux/security.h>
 #include <linux/slab.h>
 #include <linux/tracehook.h>
@@ -408,6 +409,21 @@ int __secure_computing(int this_syscall)
 			/* Let the filter pass back 16 bits of data. */
 			seccomp_send_sigsys(this_syscall, data);
 			goto skip;
+		case SECCOMP_RET_TRACE:
+			/* Skip these calls if there is no tracer. */
+			if (!ptrace_event_enabled(current, PTRACE_EVENT_SECCOMP))
+				goto skip;
+			/* Allow the BPF to provide the event message */
+			ptrace_event(PTRACE_EVENT_SECCOMP, data);
+			/*
+			 * The delivery of a fatal signal during event
+			 * notification may silently skip tracer notification.
+			 * Terminating the task now avoids executing a system
+			 * call that may not be intended.
+			 */
+			if (fatal_signal_pending(current))
+				break;
+			return 0;
 		case SECCOMP_RET_ALLOW:
 			return 0;
 		case SECCOMP_RET_KILL:

commit bb6ea4301a1109afdacaee576fedbfcd7152fc86
Author: Will Drewry <wad@chromium.org>
Date:   Thu Apr 12 16:48:01 2012 -0500

    seccomp: Add SECCOMP_RET_TRAP
    
    Adds a new return value to seccomp filters that triggers a SIGSYS to be
    delivered with the new SYS_SECCOMP si_code.
    
    This allows in-process system call emulation, including just specifying
    an errno or cleanly dumping core, rather than just dying.
    
    Suggested-by: Markus Gutschke <markus@chromium.org>
    Suggested-by: Julien Tinnes <jln@chromium.org>
    Signed-off-by: Will Drewry <wad@chromium.org>
    Acked-by: Eric Paris <eparis@redhat.com>
    
    v18: - acked-by, rebase
         - don't mention secure_computing_int() anymore
    v15: - use audit_seccomp/skip
         - pad out error spacing; clean up switch (indan@nul.nu)
    v14: - n/a
    v13: - rebase on to 88ebdda6159ffc15699f204c33feb3e431bf9bdc
    v12: - rebase on to linux-next
    v11: - clarify the comment (indan@nul.nu)
         - s/sigtrap/sigsys
    v10: - use SIGSYS, syscall_get_arch, updates arch/Kconfig
           note suggested-by (though original suggestion had other behaviors)
    v9:  - changes to SIGILL
    v8:  - clean up based on changes to dependent patches
    v7:  - introduction
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 5f78fb6d2212..9c3830692a08 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -332,6 +332,26 @@ void put_seccomp_filter(struct task_struct *tsk)
 		kfree(freeme);
 	}
 }
+
+/**
+ * seccomp_send_sigsys - signals the task to allow in-process syscall emulation
+ * @syscall: syscall number to send to userland
+ * @reason: filter-supplied reason code to send to userland (via si_errno)
+ *
+ * Forces a SIGSYS with a code of SYS_SECCOMP and related sigsys info.
+ */
+static void seccomp_send_sigsys(int syscall, int reason)
+{
+	struct siginfo info;
+	memset(&info, 0, sizeof(info));
+	info.si_signo = SIGSYS;
+	info.si_code = SYS_SECCOMP;
+	info.si_call_addr = (void __user *)KSTK_EIP(current);
+	info.si_errno = reason;
+	info.si_arch = syscall_get_arch(current, task_pt_regs(current));
+	info.si_syscall = syscall;
+	force_sig_info(SIGSYS, &info, current);
+}
 #endif	/* CONFIG_SECCOMP_FILTER */
 
 /*
@@ -382,6 +402,12 @@ int __secure_computing(int this_syscall)
 			syscall_set_return_value(current, task_pt_regs(current),
 						 -data, 0);
 			goto skip;
+		case SECCOMP_RET_TRAP:
+			/* Show the handler the original registers. */
+			syscall_rollback(current, task_pt_regs(current));
+			/* Let the filter pass back 16 bits of data. */
+			seccomp_send_sigsys(this_syscall, data);
+			goto skip;
 		case SECCOMP_RET_ALLOW:
 			return 0;
 		case SECCOMP_RET_KILL:

commit acf3b2c71ed20c53dc69826683417703c2a88059
Author: Will Drewry <wad@chromium.org>
Date:   Thu Apr 12 16:47:59 2012 -0500

    seccomp: add SECCOMP_RET_ERRNO
    
    This change adds the SECCOMP_RET_ERRNO as a valid return value from a
    seccomp filter.  Additionally, it makes the first use of the lower
    16-bits for storing a filter-supplied errno.  16-bits is more than
    enough for the errno-base.h calls.
    
    Returning errors instead of immediately terminating processes that
    violate seccomp policy allow for broader use of this functionality
    for kernel attack surface reduction.  For example, a linux container
    could maintain a whitelist of pre-existing system calls but drop
    all new ones with errnos.  This would keep a logically static attack
    surface while providing errnos that may allow for graceful failure
    without the downside of do_exit() on a bad call.
    
    This change also changes the signature of __secure_computing.  It
    appears the only direct caller is the arm entry code and it clobbers
    any possible return value (register) immediately.
    
    Signed-off-by: Will Drewry <wad@chromium.org>
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Acked-by: Eric Paris <eparis@redhat.com>
    
    v18: - fix up comments and rebase
         - fix bad var name which was fixed in later revs
         - remove _int() and just change the __secure_computing signature
    v16-v17: ...
    v15: - use audit_seccomp and add a skip label. (eparis@redhat.com)
         - clean up and pad out return codes (indan@nul.nu)
    v14: - no change/rebase
    v13: - rebase on to 88ebdda6159ffc15699f204c33feb3e431bf9bdc
    v12: - move to WARN_ON if filter is NULL
           (oleg@redhat.com, luto@mit.edu, keescook@chromium.org)
         - return immediately for filter==NULL (keescook@chromium.org)
         - change evaluation to only compare the ACTION so that layered
           errnos don't result in the lowest one being returned.
           (keeschook@chromium.org)
    v11: - check for NULL filter (keescook@chromium.org)
    v10: - change loaders to fn
     v9: - n/a
     v8: - update Kconfig to note new need for syscall_set_return_value.
         - reordered such that TRAP behavior follows on later.
         - made the for loop a little less indent-y
     v7: - introduced
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 0f7c709a523e..5f78fb6d2212 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -199,15 +199,20 @@ static int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)
 static u32 seccomp_run_filters(int syscall)
 {
 	struct seccomp_filter *f;
-	u32 ret = SECCOMP_RET_KILL;
+	u32 ret = SECCOMP_RET_ALLOW;
+
+	/* Ensure unexpected behavior doesn't result in failing open. */
+	if (WARN_ON(current->seccomp.filter == NULL))
+		return SECCOMP_RET_KILL;
+
 	/*
 	 * All filters in the list are evaluated and the lowest BPF return
-	 * value always takes priority.
+	 * value always takes priority (ignoring the DATA).
 	 */
 	for (f = current->seccomp.filter; f; f = f->prev) {
-		ret = sk_run_filter(NULL, f->insns);
-		if (ret != SECCOMP_RET_ALLOW)
-			break;
+		u32 cur_ret = sk_run_filter(NULL, f->insns);
+		if ((cur_ret & SECCOMP_RET_ACTION) < (ret & SECCOMP_RET_ACTION))
+			ret = cur_ret;
 	}
 	return ret;
 }
@@ -346,11 +351,13 @@ static int mode1_syscalls_32[] = {
 };
 #endif
 
-void __secure_computing(int this_syscall)
+int __secure_computing(int this_syscall)
 {
 	int mode = current->seccomp.mode;
 	int exit_sig = 0;
 	int *syscall;
+	u32 ret = SECCOMP_RET_KILL;
+	int data;
 
 	switch (mode) {
 	case SECCOMP_MODE_STRICT:
@@ -361,14 +368,26 @@ void __secure_computing(int this_syscall)
 #endif
 		do {
 			if (*syscall == this_syscall)
-				return;
+				return 0;
 		} while (*++syscall);
 		exit_sig = SIGKILL;
 		break;
 #ifdef CONFIG_SECCOMP_FILTER
 	case SECCOMP_MODE_FILTER:
-		if (seccomp_run_filters(this_syscall) == SECCOMP_RET_ALLOW)
-			return;
+		ret = seccomp_run_filters(this_syscall);
+		data = ret & SECCOMP_RET_DATA;
+		switch (ret & SECCOMP_RET_ACTION) {
+		case SECCOMP_RET_ERRNO:
+			/* Set the low-order 16-bits as a errno. */
+			syscall_set_return_value(current, task_pt_regs(current),
+						 -data, 0);
+			goto skip;
+		case SECCOMP_RET_ALLOW:
+			return 0;
+		case SECCOMP_RET_KILL:
+		default:
+			break;
+		}
 		exit_sig = SIGSYS;
 		break;
 #endif
@@ -379,8 +398,11 @@ void __secure_computing(int this_syscall)
 #ifdef SECCOMP_DEBUG
 	dump_stack();
 #endif
-	audit_seccomp(this_syscall, exit_code, SECCOMP_RET_KILL);
+	audit_seccomp(this_syscall, exit_sig, ret);
 	do_exit(exit_sig);
+skip:
+	audit_seccomp(this_syscall, exit_sig, ret);
+	return -1;
 }
 
 long prctl_get_seccomp(void)

commit 3dc1c1b2d2ed7507ce8a379814ad75745ff97ebe
Author: Kees Cook <keescook@chromium.org>
Date:   Thu Apr 12 16:47:58 2012 -0500

    seccomp: remove duplicated failure logging
    
    This consolidates the seccomp filter error logging path and adds more
    details to the audit log.
    
    Signed-off-by: Will Drewry <wad@chromium.org>
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Acked-by: Eric Paris <eparis@redhat.com>
    
    v18: make compat= permanent in the record
    v15: added a return code to the audit_seccomp path by wad@chromium.org
         (suggested by eparis@redhat.com)
    v*: original by keescook@chromium.org
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 0aeec1960f91..0f7c709a523e 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -60,18 +60,6 @@ struct seccomp_filter {
 /* Limit any path through the tree to 256KB worth of instructions. */
 #define MAX_INSNS_PER_PATH ((1 << 18) / sizeof(struct sock_filter))
 
-static void seccomp_filter_log_failure(int syscall)
-{
-	int compat = 0;
-#ifdef CONFIG_COMPAT
-	compat = is_compat_task();
-#endif
-	pr_info("%s[%d]: %ssystem call %d blocked at 0x%lx\n",
-		current->comm, task_pid_nr(current),
-		(compat ? "compat " : ""),
-		syscall, KSTK_EIP(current));
-}
-
 /**
  * get_u32 - returns a u32 offset into data
  * @data: a unsigned 64 bit value
@@ -381,7 +369,6 @@ void __secure_computing(int this_syscall)
 	case SECCOMP_MODE_FILTER:
 		if (seccomp_run_filters(this_syscall) == SECCOMP_RET_ALLOW)
 			return;
-		seccomp_filter_log_failure(this_syscall);
 		exit_sig = SIGSYS;
 		break;
 #endif
@@ -392,7 +379,7 @@ void __secure_computing(int this_syscall)
 #ifdef SECCOMP_DEBUG
 	dump_stack();
 #endif
-	audit_seccomp(this_syscall);
+	audit_seccomp(this_syscall, exit_code, SECCOMP_RET_KILL);
 	do_exit(exit_sig);
 }
 

commit e2cfabdfd075648216f99c2c03821cf3f47c1727
Author: Will Drewry <wad@chromium.org>
Date:   Thu Apr 12 16:47:57 2012 -0500

    seccomp: add system call filtering using BPF
    
    [This patch depends on luto@mit.edu's no_new_privs patch:
       https://lkml.org/lkml/2012/1/30/264
     The whole series including Andrew's patches can be found here:
       https://github.com/redpig/linux/tree/seccomp
     Complete diff here:
       https://github.com/redpig/linux/compare/1dc65fed...seccomp
    ]
    
    This patch adds support for seccomp mode 2.  Mode 2 introduces the
    ability for unprivileged processes to install system call filtering
    policy expressed in terms of a Berkeley Packet Filter (BPF) program.
    This program will be evaluated in the kernel for each system call
    the task makes and computes a result based on data in the format
    of struct seccomp_data.
    
    A filter program may be installed by calling:
      struct sock_fprog fprog = { ... };
      ...
      prctl(PR_SET_SECCOMP, SECCOMP_MODE_FILTER, &fprog);
    
    The return value of the filter program determines if the system call is
    allowed to proceed or denied.  If the first filter program installed
    allows prctl(2) calls, then the above call may be made repeatedly
    by a task to further reduce its access to the kernel.  All attached
    programs must be evaluated before a system call will be allowed to
    proceed.
    
    Filter programs will be inherited across fork/clone and execve.
    However, if the task attaching the filter is unprivileged
    (!CAP_SYS_ADMIN) the no_new_privs bit will be set on the task.  This
    ensures that unprivileged tasks cannot attach filters that affect
    privileged tasks (e.g., setuid binary).
    
    There are a number of benefits to this approach. A few of which are
    as follows:
    - BPF has been exposed to userland for a long time
    - BPF optimization (and JIT'ing) are well understood
    - Userland already knows its ABI: system call numbers and desired
      arguments
    - No time-of-check-time-of-use vulnerable data accesses are possible.
    - system call arguments are loaded on access only to minimize copying
      required for system call policy decisions.
    
    Mode 2 support is restricted to architectures that enable
    HAVE_ARCH_SECCOMP_FILTER.  In this patch, the primary dependency is on
    syscall_get_arguments().  The full desired scope of this feature will
    add a few minor additional requirements expressed later in this series.
    Based on discussion, SECCOMP_RET_ERRNO and SECCOMP_RET_TRACE seem to be
    the desired additional functionality.
    
    No architectures are enabled in this patch.
    
    Signed-off-by: Will Drewry <wad@chromium.org>
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Reviewed-by: Indan Zupancic <indan@nul.nu>
    Acked-by: Eric Paris <eparis@redhat.com>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    
    v18: - rebase to v3.4-rc2
         - s/chk/check/ (akpm@linux-foundation.org,jmorris@namei.org)
         - allocate with GFP_KERNEL|__GFP_NOWARN (indan@nul.nu)
         - add a comment for get_u32 regarding endianness (akpm@)
         - fix other typos, style mistakes (akpm@)
         - added acked-by
    v17: - properly guard seccomp filter needed headers (leann@ubuntu.com)
         - tighten return mask to 0x7fff0000
    v16: - no change
    v15: - add a 4 instr penalty when counting a path to account for seccomp_filter
           size (indan@nul.nu)
         - drop the max insns to 256KB (indan@nul.nu)
         - return ENOMEM if the max insns limit has been hit (indan@nul.nu)
         - move IP checks after args (indan@nul.nu)
         - drop !user_filter check (indan@nul.nu)
         - only allow explicit bpf codes (indan@nul.nu)
         - exit_code -> exit_sig
    v14: - put/get_seccomp_filter takes struct task_struct
           (indan@nul.nu,keescook@chromium.org)
         - adds seccomp_chk_filter and drops general bpf_run/chk_filter user
         - add seccomp_bpf_load for use by net/core/filter.c
         - lower max per-process/per-hierarchy: 1MB
         - moved nnp/capability check prior to allocation
           (all of the above: indan@nul.nu)
    v13: - rebase on to 88ebdda6159ffc15699f204c33feb3e431bf9bdc
    v12: - added a maximum instruction count per path (indan@nul.nu,oleg@redhat.com)
         - removed copy_seccomp (keescook@chromium.org,indan@nul.nu)
         - reworded the prctl_set_seccomp comment (indan@nul.nu)
    v11: - reorder struct seccomp_data to allow future args expansion (hpa@zytor.com)
         - style clean up, @compat dropped, compat_sock_fprog32 (indan@nul.nu)
         - do_exit(SIGSYS) (keescook@chromium.org, luto@mit.edu)
         - pare down Kconfig doc reference.
         - extra comment clean up
    v10: - seccomp_data has changed again to be more aesthetically pleasing
           (hpa@zytor.com)
         - calling convention is noted in a new u32 field using syscall_get_arch.
           This allows for cross-calling convention tasks to use seccomp filters.
           (hpa@zytor.com)
         - lots of clean up (thanks, Indan!)
     v9: - n/a
     v8: - use bpf_chk_filter, bpf_run_filter. update load_fns
         - Lots of fixes courtesy of indan@nul.nu:
         -- fix up load behavior, compat fixups, and merge alloc code,
         -- renamed pc and dropped __packed, use bool compat.
         -- Added a hidden CONFIG_SECCOMP_FILTER to synthesize non-arch
            dependencies
     v7:  (massive overhaul thanks to Indan, others)
         - added CONFIG_HAVE_ARCH_SECCOMP_FILTER
         - merged into seccomp.c
         - minimal seccomp_filter.h
         - no config option (part of seccomp)
         - no new prctl
         - doesn't break seccomp on systems without asm/syscall.h
           (works but arg access always fails)
         - dropped seccomp_init_task, extra free functions, ...
         - dropped the no-asm/syscall.h code paths
         - merges with network sk_run_filter and sk_chk_filter
     v6: - fix memory leak on attach compat check failure
         - require no_new_privs || CAP_SYS_ADMIN prior to filter
           installation. (luto@mit.edu)
         - s/seccomp_struct_/seccomp_/ for macros/functions (amwang@redhat.com)
         - cleaned up Kconfig (amwang@redhat.com)
         - on block, note if the call was compat (so the # means something)
     v5: - uses syscall_get_arguments
           (indan@nul.nu,oleg@redhat.com, mcgrathr@chromium.org)
          - uses union-based arg storage with hi/lo struct to
            handle endianness.  Compromises between the two alternate
            proposals to minimize extra arg shuffling and account for
            endianness assuming userspace uses offsetof().
            (mcgrathr@chromium.org, indan@nul.nu)
          - update Kconfig description
          - add include/seccomp_filter.h and add its installation
          - (naive) on-demand syscall argument loading
          - drop seccomp_t (eparis@redhat.com)
     v4:  - adjusted prctl to make room for PR_[SG]ET_NO_NEW_PRIVS
          - now uses current->no_new_privs
            (luto@mit.edu,torvalds@linux-foundation.com)
          - assign names to seccomp modes (rdunlap@xenotime.net)
          - fix style issues (rdunlap@xenotime.net)
          - reworded Kconfig entry (rdunlap@xenotime.net)
     v3:  - macros to inline (oleg@redhat.com)
          - init_task behavior fixed (oleg@redhat.com)
          - drop creator entry and extra NULL check (oleg@redhat.com)
          - alloc returns -EINVAL on bad sizing (serge.hallyn@canonical.com)
          - adds tentative use of "always_unprivileged" as per
            torvalds@linux-foundation.org and luto@mit.edu
     v2:  - (patch 2 only)
    Signed-off-by: James Morris <james.l.morris@oracle.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index e8d76c5895ea..0aeec1960f91 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -3,16 +3,343 @@
  *
  * Copyright 2004-2005  Andrea Arcangeli <andrea@cpushare.com>
  *
- * This defines a simple but solid secure-computing mode.
+ * Copyright (C) 2012 Google, Inc.
+ * Will Drewry <wad@chromium.org>
+ *
+ * This defines a simple but solid secure-computing facility.
+ *
+ * Mode 1 uses a fixed list of allowed system calls.
+ * Mode 2 allows user-defined system call filters in the form
+ *        of Berkeley Packet Filters/Linux Socket Filters.
  */
 
+#include <linux/atomic.h>
 #include <linux/audit.h>
-#include <linux/seccomp.h>
-#include <linux/sched.h>
 #include <linux/compat.h>
+#include <linux/sched.h>
+#include <linux/seccomp.h>
 
 /* #define SECCOMP_DEBUG 1 */
-#define NR_SECCOMP_MODES 1
+
+#ifdef CONFIG_SECCOMP_FILTER
+#include <asm/syscall.h>
+#include <linux/filter.h>
+#include <linux/security.h>
+#include <linux/slab.h>
+#include <linux/tracehook.h>
+#include <linux/uaccess.h>
+
+/**
+ * struct seccomp_filter - container for seccomp BPF programs
+ *
+ * @usage: reference count to manage the object lifetime.
+ *         get/put helpers should be used when accessing an instance
+ *         outside of a lifetime-guarded section.  In general, this
+ *         is only needed for handling filters shared across tasks.
+ * @prev: points to a previously installed, or inherited, filter
+ * @len: the number of instructions in the program
+ * @insns: the BPF program instructions to evaluate
+ *
+ * seccomp_filter objects are organized in a tree linked via the @prev
+ * pointer.  For any task, it appears to be a singly-linked list starting
+ * with current->seccomp.filter, the most recently attached or inherited filter.
+ * However, multiple filters may share a @prev node, by way of fork(), which
+ * results in a unidirectional tree existing in memory.  This is similar to
+ * how namespaces work.
+ *
+ * seccomp_filter objects should never be modified after being attached
+ * to a task_struct (other than @usage).
+ */
+struct seccomp_filter {
+	atomic_t usage;
+	struct seccomp_filter *prev;
+	unsigned short len;  /* Instruction count */
+	struct sock_filter insns[];
+};
+
+/* Limit any path through the tree to 256KB worth of instructions. */
+#define MAX_INSNS_PER_PATH ((1 << 18) / sizeof(struct sock_filter))
+
+static void seccomp_filter_log_failure(int syscall)
+{
+	int compat = 0;
+#ifdef CONFIG_COMPAT
+	compat = is_compat_task();
+#endif
+	pr_info("%s[%d]: %ssystem call %d blocked at 0x%lx\n",
+		current->comm, task_pid_nr(current),
+		(compat ? "compat " : ""),
+		syscall, KSTK_EIP(current));
+}
+
+/**
+ * get_u32 - returns a u32 offset into data
+ * @data: a unsigned 64 bit value
+ * @index: 0 or 1 to return the first or second 32-bits
+ *
+ * This inline exists to hide the length of unsigned long.  If a 32-bit
+ * unsigned long is passed in, it will be extended and the top 32-bits will be
+ * 0. If it is a 64-bit unsigned long, then whatever data is resident will be
+ * properly returned.
+ *
+ * Endianness is explicitly ignored and left for BPF program authors to manage
+ * as per the specific architecture.
+ */
+static inline u32 get_u32(u64 data, int index)
+{
+	return ((u32 *)&data)[index];
+}
+
+/* Helper for bpf_load below. */
+#define BPF_DATA(_name) offsetof(struct seccomp_data, _name)
+/**
+ * bpf_load: checks and returns a pointer to the requested offset
+ * @off: offset into struct seccomp_data to load from
+ *
+ * Returns the requested 32-bits of data.
+ * seccomp_check_filter() should assure that @off is 32-bit aligned
+ * and not out of bounds.  Failure to do so is a BUG.
+ */
+u32 seccomp_bpf_load(int off)
+{
+	struct pt_regs *regs = task_pt_regs(current);
+	if (off == BPF_DATA(nr))
+		return syscall_get_nr(current, regs);
+	if (off == BPF_DATA(arch))
+		return syscall_get_arch(current, regs);
+	if (off >= BPF_DATA(args[0]) && off < BPF_DATA(args[6])) {
+		unsigned long value;
+		int arg = (off - BPF_DATA(args[0])) / sizeof(u64);
+		int index = !!(off % sizeof(u64));
+		syscall_get_arguments(current, regs, arg, 1, &value);
+		return get_u32(value, index);
+	}
+	if (off == BPF_DATA(instruction_pointer))
+		return get_u32(KSTK_EIP(current), 0);
+	if (off == BPF_DATA(instruction_pointer) + sizeof(u32))
+		return get_u32(KSTK_EIP(current), 1);
+	/* seccomp_check_filter should make this impossible. */
+	BUG();
+}
+
+/**
+ *	seccomp_check_filter - verify seccomp filter code
+ *	@filter: filter to verify
+ *	@flen: length of filter
+ *
+ * Takes a previously checked filter (by sk_chk_filter) and
+ * redirects all filter code that loads struct sk_buff data
+ * and related data through seccomp_bpf_load.  It also
+ * enforces length and alignment checking of those loads.
+ *
+ * Returns 0 if the rule set is legal or -EINVAL if not.
+ */
+static int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)
+{
+	int pc;
+	for (pc = 0; pc < flen; pc++) {
+		struct sock_filter *ftest = &filter[pc];
+		u16 code = ftest->code;
+		u32 k = ftest->k;
+
+		switch (code) {
+		case BPF_S_LD_W_ABS:
+			ftest->code = BPF_S_ANC_SECCOMP_LD_W;
+			/* 32-bit aligned and not out of bounds. */
+			if (k >= sizeof(struct seccomp_data) || k & 3)
+				return -EINVAL;
+			continue;
+		case BPF_S_LD_W_LEN:
+			ftest->code = BPF_S_LD_IMM;
+			ftest->k = sizeof(struct seccomp_data);
+			continue;
+		case BPF_S_LDX_W_LEN:
+			ftest->code = BPF_S_LDX_IMM;
+			ftest->k = sizeof(struct seccomp_data);
+			continue;
+		/* Explicitly include allowed calls. */
+		case BPF_S_RET_K:
+		case BPF_S_RET_A:
+		case BPF_S_ALU_ADD_K:
+		case BPF_S_ALU_ADD_X:
+		case BPF_S_ALU_SUB_K:
+		case BPF_S_ALU_SUB_X:
+		case BPF_S_ALU_MUL_K:
+		case BPF_S_ALU_MUL_X:
+		case BPF_S_ALU_DIV_X:
+		case BPF_S_ALU_AND_K:
+		case BPF_S_ALU_AND_X:
+		case BPF_S_ALU_OR_K:
+		case BPF_S_ALU_OR_X:
+		case BPF_S_ALU_LSH_K:
+		case BPF_S_ALU_LSH_X:
+		case BPF_S_ALU_RSH_K:
+		case BPF_S_ALU_RSH_X:
+		case BPF_S_ALU_NEG:
+		case BPF_S_LD_IMM:
+		case BPF_S_LDX_IMM:
+		case BPF_S_MISC_TAX:
+		case BPF_S_MISC_TXA:
+		case BPF_S_ALU_DIV_K:
+		case BPF_S_LD_MEM:
+		case BPF_S_LDX_MEM:
+		case BPF_S_ST:
+		case BPF_S_STX:
+		case BPF_S_JMP_JA:
+		case BPF_S_JMP_JEQ_K:
+		case BPF_S_JMP_JEQ_X:
+		case BPF_S_JMP_JGE_K:
+		case BPF_S_JMP_JGE_X:
+		case BPF_S_JMP_JGT_K:
+		case BPF_S_JMP_JGT_X:
+		case BPF_S_JMP_JSET_K:
+		case BPF_S_JMP_JSET_X:
+			continue;
+		default:
+			return -EINVAL;
+		}
+	}
+	return 0;
+}
+
+/**
+ * seccomp_run_filters - evaluates all seccomp filters against @syscall
+ * @syscall: number of the current system call
+ *
+ * Returns valid seccomp BPF response codes.
+ */
+static u32 seccomp_run_filters(int syscall)
+{
+	struct seccomp_filter *f;
+	u32 ret = SECCOMP_RET_KILL;
+	/*
+	 * All filters in the list are evaluated and the lowest BPF return
+	 * value always takes priority.
+	 */
+	for (f = current->seccomp.filter; f; f = f->prev) {
+		ret = sk_run_filter(NULL, f->insns);
+		if (ret != SECCOMP_RET_ALLOW)
+			break;
+	}
+	return ret;
+}
+
+/**
+ * seccomp_attach_filter: Attaches a seccomp filter to current.
+ * @fprog: BPF program to install
+ *
+ * Returns 0 on success or an errno on failure.
+ */
+static long seccomp_attach_filter(struct sock_fprog *fprog)
+{
+	struct seccomp_filter *filter;
+	unsigned long fp_size = fprog->len * sizeof(struct sock_filter);
+	unsigned long total_insns = fprog->len;
+	long ret;
+
+	if (fprog->len == 0 || fprog->len > BPF_MAXINSNS)
+		return -EINVAL;
+
+	for (filter = current->seccomp.filter; filter; filter = filter->prev)
+		total_insns += filter->len + 4;  /* include a 4 instr penalty */
+	if (total_insns > MAX_INSNS_PER_PATH)
+		return -ENOMEM;
+
+	/*
+	 * Installing a seccomp filter requires that the task have
+	 * CAP_SYS_ADMIN in its namespace or be running with no_new_privs.
+	 * This avoids scenarios where unprivileged tasks can affect the
+	 * behavior of privileged children.
+	 */
+	if (!current->no_new_privs &&
+	    security_capable_noaudit(current_cred(), current_user_ns(),
+				     CAP_SYS_ADMIN) != 0)
+		return -EACCES;
+
+	/* Allocate a new seccomp_filter */
+	filter = kzalloc(sizeof(struct seccomp_filter) + fp_size,
+			 GFP_KERNEL|__GFP_NOWARN);
+	if (!filter)
+		return -ENOMEM;
+	atomic_set(&filter->usage, 1);
+	filter->len = fprog->len;
+
+	/* Copy the instructions from fprog. */
+	ret = -EFAULT;
+	if (copy_from_user(filter->insns, fprog->filter, fp_size))
+		goto fail;
+
+	/* Check and rewrite the fprog via the skb checker */
+	ret = sk_chk_filter(filter->insns, filter->len);
+	if (ret)
+		goto fail;
+
+	/* Check and rewrite the fprog for seccomp use */
+	ret = seccomp_check_filter(filter->insns, filter->len);
+	if (ret)
+		goto fail;
+
+	/*
+	 * If there is an existing filter, make it the prev and don't drop its
+	 * task reference.
+	 */
+	filter->prev = current->seccomp.filter;
+	current->seccomp.filter = filter;
+	return 0;
+fail:
+	kfree(filter);
+	return ret;
+}
+
+/**
+ * seccomp_attach_user_filter - attaches a user-supplied sock_fprog
+ * @user_filter: pointer to the user data containing a sock_fprog.
+ *
+ * Returns 0 on success and non-zero otherwise.
+ */
+long seccomp_attach_user_filter(char __user *user_filter)
+{
+	struct sock_fprog fprog;
+	long ret = -EFAULT;
+
+#ifdef CONFIG_COMPAT
+	if (is_compat_task()) {
+		struct compat_sock_fprog fprog32;
+		if (copy_from_user(&fprog32, user_filter, sizeof(fprog32)))
+			goto out;
+		fprog.len = fprog32.len;
+		fprog.filter = compat_ptr(fprog32.filter);
+	} else /* falls through to the if below. */
+#endif
+	if (copy_from_user(&fprog, user_filter, sizeof(fprog)))
+		goto out;
+	ret = seccomp_attach_filter(&fprog);
+out:
+	return ret;
+}
+
+/* get_seccomp_filter - increments the reference count of the filter on @tsk */
+void get_seccomp_filter(struct task_struct *tsk)
+{
+	struct seccomp_filter *orig = tsk->seccomp.filter;
+	if (!orig)
+		return;
+	/* Reference count is bounded by the number of total processes. */
+	atomic_inc(&orig->usage);
+}
+
+/* put_seccomp_filter - decrements the ref count of tsk->seccomp.filter */
+void put_seccomp_filter(struct task_struct *tsk)
+{
+	struct seccomp_filter *orig = tsk->seccomp.filter;
+	/* Clean up single-reference branches iteratively. */
+	while (orig && atomic_dec_and_test(&orig->usage)) {
+		struct seccomp_filter *freeme = orig;
+		orig = orig->prev;
+		kfree(freeme);
+	}
+}
+#endif	/* CONFIG_SECCOMP_FILTER */
 
 /*
  * Secure computing mode 1 allows only read/write/exit/sigreturn.
@@ -34,10 +361,11 @@ static int mode1_syscalls_32[] = {
 void __secure_computing(int this_syscall)
 {
 	int mode = current->seccomp.mode;
-	int * syscall;
+	int exit_sig = 0;
+	int *syscall;
 
 	switch (mode) {
-	case 1:
+	case SECCOMP_MODE_STRICT:
 		syscall = mode1_syscalls;
 #ifdef CONFIG_COMPAT
 		if (is_compat_task())
@@ -47,7 +375,16 @@ void __secure_computing(int this_syscall)
 			if (*syscall == this_syscall)
 				return;
 		} while (*++syscall);
+		exit_sig = SIGKILL;
 		break;
+#ifdef CONFIG_SECCOMP_FILTER
+	case SECCOMP_MODE_FILTER:
+		if (seccomp_run_filters(this_syscall) == SECCOMP_RET_ALLOW)
+			return;
+		seccomp_filter_log_failure(this_syscall);
+		exit_sig = SIGSYS;
+		break;
+#endif
 	default:
 		BUG();
 	}
@@ -56,7 +393,7 @@ void __secure_computing(int this_syscall)
 	dump_stack();
 #endif
 	audit_seccomp(this_syscall);
-	do_exit(SIGKILL);
+	do_exit(exit_sig);
 }
 
 long prctl_get_seccomp(void)
@@ -64,25 +401,48 @@ long prctl_get_seccomp(void)
 	return current->seccomp.mode;
 }
 
-long prctl_set_seccomp(unsigned long seccomp_mode)
+/**
+ * prctl_set_seccomp: configures current->seccomp.mode
+ * @seccomp_mode: requested mode to use
+ * @filter: optional struct sock_fprog for use with SECCOMP_MODE_FILTER
+ *
+ * This function may be called repeatedly with a @seccomp_mode of
+ * SECCOMP_MODE_FILTER to install additional filters.  Every filter
+ * successfully installed will be evaluated (in reverse order) for each system
+ * call the task makes.
+ *
+ * Once current->seccomp.mode is non-zero, it may not be changed.
+ *
+ * Returns 0 on success or -EINVAL on failure.
+ */
+long prctl_set_seccomp(unsigned long seccomp_mode, char __user *filter)
 {
-	long ret;
+	long ret = -EINVAL;
 
-	/* can set it only once to be even more secure */
-	ret = -EPERM;
-	if (unlikely(current->seccomp.mode))
+	if (current->seccomp.mode &&
+	    current->seccomp.mode != seccomp_mode)
 		goto out;
 
-	ret = -EINVAL;
-	if (seccomp_mode && seccomp_mode <= NR_SECCOMP_MODES) {
-		current->seccomp.mode = seccomp_mode;
-		set_thread_flag(TIF_SECCOMP);
+	switch (seccomp_mode) {
+	case SECCOMP_MODE_STRICT:
+		ret = 0;
 #ifdef TIF_NOTSC
 		disable_TSC();
 #endif
-		ret = 0;
+		break;
+#ifdef CONFIG_SECCOMP_FILTER
+	case SECCOMP_MODE_FILTER:
+		ret = seccomp_attach_user_filter(filter);
+		if (ret)
+			goto out;
+		break;
+#endif
+	default:
+		goto out;
 	}
 
- out:
+	current->seccomp.mode = seccomp_mode;
+	set_thread_flag(TIF_SECCOMP);
+out:
 	return ret;
 }

commit 85e7bac33b8d5edafc4e219c7dfdb3d48e0b4e31
Author: Eric Paris <eparis@redhat.com>
Date:   Tue Jan 3 14:23:05 2012 -0500

    seccomp: audit abnormal end to a process due to seccomp
    
    The audit system likes to collect information about processes that end
    abnormally (SIGSEGV) as this may me useful intrusion detection information.
    This patch adds audit support to collect information when seccomp forces a
    task to exit because of misbehavior in a similar way.
    
    Signed-off-by: Eric Paris <eparis@redhat.com>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 57d4b13b631d..e8d76c5895ea 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -6,6 +6,7 @@
  * This defines a simple but solid secure-computing mode.
  */
 
+#include <linux/audit.h>
 #include <linux/seccomp.h>
 #include <linux/sched.h>
 #include <linux/compat.h>
@@ -54,6 +55,7 @@ void __secure_computing(int this_syscall)
 #ifdef SECCOMP_DEBUG
 	dump_stack();
 #endif
+	audit_seccomp(this_syscall);
 	do_exit(SIGKILL);
 }
 

commit 5b1017404aea6d2e552e991b3fd814d839e9cd67
Author: Roland McGrath <roland@redhat.com>
Date:   Fri Feb 27 23:25:54 2009 -0800

    x86-64: seccomp: fix 32/64 syscall hole
    
    On x86-64, a 32-bit process (TIF_IA32) can switch to 64-bit mode with
    ljmp, and then use the "syscall" instruction to make a 64-bit system
    call.  A 64-bit process make a 32-bit system call with int $0x80.
    
    In both these cases under CONFIG_SECCOMP=y, secure_computing() will use
    the wrong system call number table.  The fix is simple: test TS_COMPAT
    instead of TIF_IA32.  Here is an example exploit:
    
            /* test case for seccomp circumvention on x86-64
    
               There are two failure modes: compile with -m64 or compile with -m32.
    
               The -m64 case is the worst one, because it does "chmod 777 ." (could
               be any chmod call).  The -m32 case demonstrates it was able to do
               stat(), which can glean information but not harm anything directly.
    
               A buggy kernel will let the test do something, print, and exit 1; a
               fixed kernel will make it exit with SIGKILL before it does anything.
            */
    
            #define _GNU_SOURCE
            #include <assert.h>
            #include <inttypes.h>
            #include <stdio.h>
            #include <linux/prctl.h>
            #include <sys/stat.h>
            #include <unistd.h>
            #include <asm/unistd.h>
    
            int
            main (int argc, char **argv)
            {
              char buf[100];
              static const char dot[] = ".";
              long ret;
              unsigned st[24];
    
              if (prctl (PR_SET_SECCOMP, 1, 0, 0, 0) != 0)
                perror ("prctl(PR_SET_SECCOMP) -- not compiled into kernel?");
    
            #ifdef __x86_64__
              assert ((uintptr_t) dot < (1UL << 32));
              asm ("int $0x80 # %0 <- %1(%2 %3)"
                   : "=a" (ret) : "0" (15), "b" (dot), "c" (0777));
              ret = snprintf (buf, sizeof buf,
                              "result %ld (check mode on .!)\n", ret);
            #elif defined __i386__
              asm (".code32\n"
                   "pushl %%cs\n"
                   "pushl $2f\n"
                   "ljmpl $0x33, $1f\n"
                   ".code64\n"
                   "1: syscall # %0 <- %1(%2 %3)\n"
                   "lretl\n"
                   ".code32\n"
                   "2:"
                   : "=a" (ret) : "0" (4), "D" (dot), "S" (&st));
              if (ret == 0)
                ret = snprintf (buf, sizeof buf,
                                "stat . -> st_uid=%u\n", st[7]);
              else
                ret = snprintf (buf, sizeof buf, "result %ld\n", ret);
            #else
            # error "not this one"
            #endif
    
              write (1, buf, ret);
    
              syscall (__NR_exit, 1);
              return 2;
            }
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    [ I don't know if anybody actually uses seccomp, but it's enabled in
      at least both Fedora and SuSE kernels, so maybe somebody is. - Linus ]
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index ad64fcb731f2..57d4b13b631d 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -8,6 +8,7 @@
 
 #include <linux/seccomp.h>
 #include <linux/sched.h>
+#include <linux/compat.h>
 
 /* #define SECCOMP_DEBUG 1 */
 #define NR_SECCOMP_MODES 1
@@ -22,7 +23,7 @@ static int mode1_syscalls[] = {
 	0, /* null terminated */
 };
 
-#ifdef TIF_32BIT
+#ifdef CONFIG_COMPAT
 static int mode1_syscalls_32[] = {
 	__NR_seccomp_read_32, __NR_seccomp_write_32, __NR_seccomp_exit_32, __NR_seccomp_sigreturn_32,
 	0, /* null terminated */
@@ -37,8 +38,8 @@ void __secure_computing(int this_syscall)
 	switch (mode) {
 	case 1:
 		syscall = mode1_syscalls;
-#ifdef TIF_32BIT
-		if (test_thread_flag(TIF_32BIT))
+#ifdef CONFIG_COMPAT
+		if (is_compat_task())
 			syscall = mode1_syscalls_32;
 #endif
 		do {

commit cf99abace7e07dd8491e7093a9a9ef11d48838ed
Author: Andrea Arcangeli <andrea@cpushare.com>
Date:   Sun Jul 15 23:41:33 2007 -0700

    make seccomp zerocost in schedule
    
    This follows a suggestion from Chuck Ebbert on how to make seccomp
    absolutely zerocost in schedule too.  The only remaining footprint of
    seccomp is in terms of the bzImage size that becomes a few bytes (perhaps
    even a few kbytes) larger, measure it if you care in the embedded.
    
    Signed-off-by: Andrea Arcangeli <andrea@cpushare.com>
    Cc: Andi Kleen <ak@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index 1dfa8a509726..ad64fcb731f2 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -74,6 +74,9 @@ long prctl_set_seccomp(unsigned long seccomp_mode)
 	if (seccomp_mode && seccomp_mode <= NR_SECCOMP_MODES) {
 		current->seccomp.mode = seccomp_mode;
 		set_thread_flag(TIF_SECCOMP);
+#ifdef TIF_NOTSC
+		disable_TSC();
+#endif
 		ret = 0;
 	}
 

commit 1d9d02feeee89e9132034d504c9a45eeaf618a3d
Author: Andrea Arcangeli <andrea@cpushare.com>
Date:   Sun Jul 15 23:41:32 2007 -0700

    move seccomp from /proc to a prctl
    
    This reduces the memory footprint and it enforces that only the current
    task can enable seccomp on itself (this is a requirement for a
    strightforward [modulo preempt ;) ] TIF_NOTSC implementation).
    
    Signed-off-by: Andrea Arcangeli <andrea@cpushare.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
index c3391b6020e8..1dfa8a509726 100644
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@ -10,6 +10,7 @@
 #include <linux/sched.h>
 
 /* #define SECCOMP_DEBUG 1 */
+#define NR_SECCOMP_MODES 1
 
 /*
  * Secure computing mode 1 allows only read/write/exit/sigreturn.
@@ -54,3 +55,28 @@ void __secure_computing(int this_syscall)
 #endif
 	do_exit(SIGKILL);
 }
+
+long prctl_get_seccomp(void)
+{
+	return current->seccomp.mode;
+}
+
+long prctl_set_seccomp(unsigned long seccomp_mode)
+{
+	long ret;
+
+	/* can set it only once to be even more secure */
+	ret = -EPERM;
+	if (unlikely(current->seccomp.mode))
+		goto out;
+
+	ret = -EINVAL;
+	if (seccomp_mode && seccomp_mode <= NR_SECCOMP_MODES) {
+		current->seccomp.mode = seccomp_mode;
+		set_thread_flag(TIF_SECCOMP);
+		ret = 0;
+	}
+
+ out:
+	return ret;
+}

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/kernel/seccomp.c b/kernel/seccomp.c
new file mode 100644
index 000000000000..c3391b6020e8
--- /dev/null
+++ b/kernel/seccomp.c
@@ -0,0 +1,56 @@
+/*
+ * linux/kernel/seccomp.c
+ *
+ * Copyright 2004-2005  Andrea Arcangeli <andrea@cpushare.com>
+ *
+ * This defines a simple but solid secure-computing mode.
+ */
+
+#include <linux/seccomp.h>
+#include <linux/sched.h>
+
+/* #define SECCOMP_DEBUG 1 */
+
+/*
+ * Secure computing mode 1 allows only read/write/exit/sigreturn.
+ * To be fully secure this must be combined with rlimit
+ * to limit the stack allocations too.
+ */
+static int mode1_syscalls[] = {
+	__NR_seccomp_read, __NR_seccomp_write, __NR_seccomp_exit, __NR_seccomp_sigreturn,
+	0, /* null terminated */
+};
+
+#ifdef TIF_32BIT
+static int mode1_syscalls_32[] = {
+	__NR_seccomp_read_32, __NR_seccomp_write_32, __NR_seccomp_exit_32, __NR_seccomp_sigreturn_32,
+	0, /* null terminated */
+};
+#endif
+
+void __secure_computing(int this_syscall)
+{
+	int mode = current->seccomp.mode;
+	int * syscall;
+
+	switch (mode) {
+	case 1:
+		syscall = mode1_syscalls;
+#ifdef TIF_32BIT
+		if (test_thread_flag(TIF_32BIT))
+			syscall = mode1_syscalls_32;
+#endif
+		do {
+			if (*syscall == this_syscall)
+				return;
+		} while (*++syscall);
+		break;
+	default:
+		BUG();
+	}
+
+#ifdef SECCOMP_DEBUG
+	dump_stack();
+#endif
+	do_exit(SIGKILL);
+}
