commit 20dc3847cc2fc886ee4eb9112e6e2fad9419b0c7
Author: Sascha Ortmann <sascha.ortmann@stud.uni-hannover.de>
Date:   Thu Jun 18 18:33:01 2020 +0200

    tracing/boottime: Fix kprobe multiple events
    
    Fix boottime kprobe events to report and abort after each failure when
    adding probes.
    
    As an example, when we try to set multiprobe kprobe events in
    bootconfig like this:
    
    ftrace.event.kprobes.vfsevents {
            probes = "vfs_read $arg1 $arg2,,
                     !error! not reported;?", // leads to error
                     "vfs_write $arg1 $arg2"
    }
    
    This will not work as expected. After
    commit da0f1f4167e3af69e ("tracing/boottime: Fix kprobe event API usage"),
    the function trace_boot_add_kprobe_event will not produce any error
    message when adding a probe fails at kprobe_event_gen_cmd_start.
    Furthermore, we continue to add probes when kprobe_event_gen_cmd_end fails
    (and kprobe_event_gen_cmd_start did not fail). In this case the function
    even returns successfully when the last call to kprobe_event_gen_cmd_end
    is successful.
    
    The behaviour of reporting and aborting after failures is not
    consistent.
    
    The function trace_boot_add_kprobe_event now reports each failure and
    stops adding probes immediately.
    
    Link: https://lkml.kernel.org/r/20200618163301.25854-1-sascha.ortmann@stud.uni-hannover.de
    
    Cc: stable@vger.kernel.org
    Cc: linux-kernel@i4.cs.fau.de
    Co-developed-by: Maximilian Werner <maximilian.werner96@gmail.com>
    Fixes: da0f1f4167e3 ("tracing/boottime: Fix kprobe event API usage")
    Acked-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Maximilian Werner <maximilian.werner96@gmail.com>
    Signed-off-by: Sascha Ortmann <sascha.ortmann@stud.uni-hannover.de>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 8b5490cb02bb..fa0fc08c6ef8 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -101,12 +101,16 @@ trace_boot_add_kprobe_event(struct xbc_node *node, const char *event)
 		kprobe_event_cmd_init(&cmd, buf, MAX_BUF_LEN);
 
 		ret = kprobe_event_gen_cmd_start(&cmd, event, val);
-		if (ret)
+		if (ret) {
+			pr_err("Failed to generate probe: %s\n", buf);
 			break;
+		}
 
 		ret = kprobe_event_gen_cmd_end(&cmd);
-		if (ret)
+		if (ret) {
 			pr_err("Failed to add probe: %s\n", buf);
+			break;
+		}
 	}
 
 	return ret;

commit 6c95503c292610ff2898b4271c510c16efdcd4e1
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Sat Jun 20 12:45:54 2020 +0900

    tracing/boot: Fix config dependency for synthedic event
    
    Since commit 726721a51838 ("tracing: Move synthetic events to
    a separate file") decoupled synthetic event from histogram,
    boot-time tracing also has to check CONFIG_SYNTH_EVENT instead
    of CONFIG_HIST_TRIGGERS.
    
    Link: http://lkml.kernel.org/r/159262475441.185015.5300725180746017555.stgit@devnote2
    
    Fixes: 726721a51838 ("tracing: Move synthetic events to a separate file")
    Reviewed-by: Tom Zanussi <zanussi@kernel.org>
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 9de29bb45a27..8b5490cb02bb 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -120,7 +120,7 @@ trace_boot_add_kprobe_event(struct xbc_node *node, const char *event)
 }
 #endif
 
-#ifdef CONFIG_HIST_TRIGGERS
+#ifdef CONFIG_SYNTH_EVENTS
 static int __init
 trace_boot_add_synth_event(struct xbc_node *node, const char *event)
 {

commit da0f1f4167e3af69e1d8b32d6d65195ddd2bfb64
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Sat Apr 25 14:49:17 2020 +0900

    tracing/boottime: Fix kprobe event API usage
    
    Fix boottime kprobe events to use API correctly for
    multiple events.
    
    For example, when we set a multiprobe kprobe events in
    bootconfig like below,
    
      ftrace.event.kprobes.myevent {
            probes = "vfs_read $arg1 $arg2", "vfs_write $arg1 $arg2"
      }
    
    This cause an error;
    
      trace_boot: Failed to add probe: p:kprobes/myevent (null)  vfs_read $arg1 $arg2  vfs_write $arg1 $arg2
    
    This shows the 1st argument becomes NULL and multiprobes
    are merged to 1 probe.
    
    Link: http://lkml.kernel.org/r/158779375766.6082.201939936008972838.stgit@devnote2
    
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: stable@vger.kernel.org
    Fixes: 29a154810546 ("tracing: Change trace_boot to use kprobe_event interface")
    Reviewed-by: Tom Zanussi <zanussi@kernel.org>
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 06d7feb5255f..9de29bb45a27 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -95,24 +95,20 @@ trace_boot_add_kprobe_event(struct xbc_node *node, const char *event)
 	struct xbc_node *anode;
 	char buf[MAX_BUF_LEN];
 	const char *val;
-	int ret;
+	int ret = 0;
 
-	kprobe_event_cmd_init(&cmd, buf, MAX_BUF_LEN);
+	xbc_node_for_each_array_value(node, "probes", anode, val) {
+		kprobe_event_cmd_init(&cmd, buf, MAX_BUF_LEN);
 
-	ret = kprobe_event_gen_cmd_start(&cmd, event, NULL);
-	if (ret)
-		return ret;
+		ret = kprobe_event_gen_cmd_start(&cmd, event, val);
+		if (ret)
+			break;
 
-	xbc_node_for_each_array_value(node, "probes", anode, val) {
-		ret = kprobe_event_add_field(&cmd, val);
+		ret = kprobe_event_gen_cmd_end(&cmd);
 		if (ret)
-			return ret;
+			pr_err("Failed to add probe: %s\n", buf);
 	}
 
-	ret = kprobe_event_gen_cmd_end(&cmd);
-	if (ret)
-		pr_err("Failed to add probe: %s\n", buf);
-
 	return ret;
 }
 #else

commit fdeb1aca2861472b38779be44141757483300827
Author: Tom Zanussi <zanussi@kernel.org>
Date:   Wed Jan 29 12:59:26 2020 -0600

    tracing: Change trace_boot to use synth_event interface
    
    Have trace_boot_add_synth_event() use the synth_event interface.
    
    Also, rename synth_event_run_cmd() to synth_event_run_command() now
    that trace_boot's version is gone.
    
    Link: http://lkml.kernel.org/r/94f1fa0e31846d0bddca916b8663404b20559e34.1580323897.git.zanussi@kernel.org
    
    Acked-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Tom Zanussi <zanussi@kernel.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 2298a70cdda6..06d7feb5255f 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -125,38 +125,31 @@ trace_boot_add_kprobe_event(struct xbc_node *node, const char *event)
 #endif
 
 #ifdef CONFIG_HIST_TRIGGERS
-extern int synth_event_run_command(const char *command);
-
 static int __init
 trace_boot_add_synth_event(struct xbc_node *node, const char *event)
 {
+	struct dynevent_cmd cmd;
 	struct xbc_node *anode;
-	char buf[MAX_BUF_LEN], *q;
+	char buf[MAX_BUF_LEN];
 	const char *p;
-	int len, delta, ret;
+	int ret;
 
-	len = ARRAY_SIZE(buf);
-	delta = snprintf(buf, len, "%s", event);
-	if (delta >= len) {
-		pr_err("Event name is too long: %s\n", event);
-		return -E2BIG;
-	}
-	len -= delta; q = buf + delta;
+	synth_event_cmd_init(&cmd, buf, MAX_BUF_LEN);
+
+	ret = synth_event_gen_cmd_start(&cmd, event, NULL);
+	if (ret)
+		return ret;
 
 	xbc_node_for_each_array_value(node, "fields", anode, p) {
-		delta = snprintf(q, len, " %s;", p);
-		if (delta >= len) {
-			pr_err("fields string is too long: %s\n", p);
-			return -E2BIG;
-		}
-		len -= delta; q += delta;
+		ret = synth_event_add_field_str(&cmd, p);
+		if (ret)
+			return ret;
 	}
 
-	ret = synth_event_run_command(buf);
+	ret = synth_event_gen_cmd_end(&cmd);
 	if (ret < 0)
 		pr_err("Failed to add synthetic event: %s\n", buf);
 
-
 	return ret;
 }
 #else

commit 29a15481054681fa2d450b60a6feea8e6ca6f511
Author: Tom Zanussi <zanussi@kernel.org>
Date:   Wed Jan 29 12:59:30 2020 -0600

    tracing: Change trace_boot to use kprobe_event interface
    
    Have trace_boot_add_kprobe_event() use the kprobe_event interface.
    
    Also, rename kprobe_event_run_cmd() to kprobe_event_run_command() now
    that trace_boot's version is gone.
    
    Link: http://lkml.kernel.org/r/af5429d11291ab1e9a85a0ff944af3b2bcf193c7.1580323897.git.zanussi@kernel.org
    
    Acked-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Tom Zanussi <zanussi@kernel.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 4d37bf5c3742..2298a70cdda6 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -88,37 +88,32 @@ trace_boot_enable_events(struct trace_array *tr, struct xbc_node *node)
 }
 
 #ifdef CONFIG_KPROBE_EVENTS
-extern int trace_kprobe_run_command(const char *command);
-
 static int __init
 trace_boot_add_kprobe_event(struct xbc_node *node, const char *event)
 {
+	struct dynevent_cmd cmd;
 	struct xbc_node *anode;
 	char buf[MAX_BUF_LEN];
 	const char *val;
-	char *p;
-	int len;
+	int ret;
 
-	len = snprintf(buf, ARRAY_SIZE(buf) - 1, "p:kprobes/%s ", event);
-	if (len >= ARRAY_SIZE(buf)) {
-		pr_err("Event name is too long: %s\n", event);
-		return -E2BIG;
-	}
-	p = buf + len;
-	len = ARRAY_SIZE(buf) - len;
+	kprobe_event_cmd_init(&cmd, buf, MAX_BUF_LEN);
+
+	ret = kprobe_event_gen_cmd_start(&cmd, event, NULL);
+	if (ret)
+		return ret;
 
 	xbc_node_for_each_array_value(node, "probes", anode, val) {
-		if (strlcpy(p, val, len) >= len) {
-			pr_err("Probe definition is too long: %s\n", val);
-			return -E2BIG;
-		}
-		if (trace_kprobe_run_command(buf) < 0) {
-			pr_err("Failed to add probe: %s\n", buf);
-			return -EINVAL;
-		}
+		ret = kprobe_event_add_field(&cmd, val);
+		if (ret)
+			return ret;
 	}
 
-	return 0;
+	ret = kprobe_event_gen_cmd_end(&cmd);
+	if (ret)
+		pr_err("Failed to add probe: %s\n", buf);
+
+	return ret;
 }
 #else
 static inline int __init

commit 5c3469cb899abe998299aafb8f16f325d62d2d68
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Wed Jan 29 18:36:44 2020 +0900

    tracing/boot: Move external function declarations to kernel/trace/trace.h
    
    Move external function declarations into kernel/trace/trace.h
    from trace_boot.c for tracing subsystem internal use.
    
    Link: http://lkml.kernel.org/r/158029060405.12381.11944554430359702545.stgit@devnote2
    
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 5aad41961f03..4d37bf5c3742 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -21,13 +21,6 @@
 
 #define MAX_BUF_LEN 256
 
-extern int trace_set_options(struct trace_array *tr, char *option);
-extern int tracing_set_tracer(struct trace_array *tr, const char *buf);
-extern ssize_t tracing_resize_ring_buffer(struct trace_array *tr,
-					  unsigned long size, int cpu_id);
-extern int tracing_set_cpumask(struct trace_array *tr,
-				cpumask_var_t tracing_cpumask_new);
-
 static void __init
 trace_boot_set_instance_options(struct trace_array *tr, struct xbc_node *node)
 {
@@ -76,9 +69,6 @@ trace_boot_set_instance_options(struct trace_array *tr, struct xbc_node *node)
 }
 
 #ifdef CONFIG_EVENT_TRACING
-extern int ftrace_set_clr_event(struct trace_array *tr, char *buf, int set);
-extern int trigger_process_regex(struct trace_event_file *file, char *buff);
-
 static void __init
 trace_boot_enable_events(struct trace_array *tr, struct xbc_node *node)
 {
@@ -252,11 +242,6 @@ trace_boot_init_events(struct trace_array *tr, struct xbc_node *node)
 #endif
 
 #ifdef CONFIG_DYNAMIC_FTRACE
-extern bool ftrace_filter_param __initdata;
-extern int ftrace_set_filter(struct ftrace_ops *ops, unsigned char *buf,
-			     int len, int reset);
-extern int ftrace_set_notrace(struct ftrace_ops *ops, unsigned char *buf,
-			      int len, int reset);
 static void __init
 trace_boot_set_ftrace_filter(struct trace_array *tr, struct xbc_node *node)
 {

commit 76a598ec8c4fde58aab79b9f7c40c33d54eca67b
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Wed Jan 29 18:36:35 2020 +0900

    tracing/boot: Include required headers and sort it alphabetically
    
    Include some required (but currently indirectly included)
    headers and sort it alphabetically.
    
    Link: http://lkml.kernel.org/r/158029059514.12381.6597832266860248781.stgit@devnote2
    
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 2f616cd926b0..5aad41961f03 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -6,9 +6,16 @@
 
 #define pr_fmt(fmt)	"trace_boot: " fmt
 
+#include <linux/bootconfig.h>
+#include <linux/cpumask.h>
 #include <linux/ftrace.h>
 #include <linux/init.h>
-#include <linux/bootconfig.h>
+#include <linux/kernel.h>
+#include <linux/mutex.h>
+#include <linux/string.h>
+#include <linux/slab.h>
+#include <linux/trace.h>
+#include <linux/trace_events.h>
 
 #include "trace.h"
 

commit 28394da25888168df379c40910591b95e8e449f7
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Fri Jan 24 20:47:46 2020 -0500

    tracing: Decrement trace_array when bootconfig creates an instance
    
    The trace_array_get_by_name() creates a ftrace instance and
    trace_array_put() is used to remove the reference. Even though the
    trace_array_get_by_name() creates the instance, it also adds a reference
    count to it, that prevents user space from removing it.
    
    As the bootconfig just creates the instance on boot up, it should still be
    used where it can be deleted by user space after boot. A trace_array_put()
    is required to let that happen.
    
    Also, change the documentation on trace_array_get_by_name() to make this not
    be so confusing.
    
    Link: https://lore.kernel.org/r/20200124205927.76128804@rorschach.local.home
    
    Fixes: 4f712a4d04a4e ("tracing/boot: Add instance node support")
    Acked-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index cd541ac1cbc1..2f616cd926b0 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -327,6 +327,7 @@ trace_boot_init_instances(struct xbc_node *node)
 			continue;
 		}
 		trace_boot_init_one_instance(tr, inode);
+		trace_array_put(tr);
 	}
 }
 

commit 532f49a6f19a153e202b5a174f8556fd50c36dd4
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Fri Jan 17 08:30:07 2020 +0300

    tracing/boot: Fix an IS_ERR() vs NULL bug
    
    The trace_array_get_by_name() function doesn't return error pointers,
    it returns NULL on error.
    
    Link: http://lkml.kernel.org/r/20200117053007.5h2juv272pokqhtq@kili.mountain
    
    Fixes: 4f712a4d04a4 ("tracing/boot: Add instance node support")
    Acked-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index fa9603dc6469..cd541ac1cbc1 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -322,7 +322,7 @@ trace_boot_init_instances(struct xbc_node *node)
 			continue;
 
 		tr = trace_array_get_by_name(p);
-		if (IS_ERR(tr)) {
+		if (!tr) {
 			pr_err("Failed to get trace instance %s\n", p);
 			continue;
 		}

commit fe1efe9252f938f0cc624e4ac817c27bcaef6ed0
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Sat Jan 11 01:07:28 2020 +0900

    tracing/boot: Add function tracer filter options
    
    Add below function-tracer filter options to boot-time tracing.
    
     - ftrace.[instance.INSTANCE.]ftrace.filters
       This will take an array of tracing function filter rules
    
     - ftrace.[instance.INSTANCE.]ftrace.notraces
       This will take an array of NON-tracing function filter rules
    
    Link: http://lkml.kernel.org/r/157867244841.17873.10933616628243103561.stgit@devnote2
    
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 81d923c16a4d..fa9603dc6469 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -244,11 +244,51 @@ trace_boot_init_events(struct trace_array *tr, struct xbc_node *node)
 #define trace_boot_init_events(tr, node) do {} while (0)
 #endif
 
+#ifdef CONFIG_DYNAMIC_FTRACE
+extern bool ftrace_filter_param __initdata;
+extern int ftrace_set_filter(struct ftrace_ops *ops, unsigned char *buf,
+			     int len, int reset);
+extern int ftrace_set_notrace(struct ftrace_ops *ops, unsigned char *buf,
+			      int len, int reset);
+static void __init
+trace_boot_set_ftrace_filter(struct trace_array *tr, struct xbc_node *node)
+{
+	struct xbc_node *anode;
+	const char *p;
+	char *q;
+
+	xbc_node_for_each_array_value(node, "ftrace.filters", anode, p) {
+		q = kstrdup(p, GFP_KERNEL);
+		if (!q)
+			return;
+		if (ftrace_set_filter(tr->ops, q, strlen(q), 0) < 0)
+			pr_err("Failed to add %s to ftrace filter\n", p);
+		else
+			ftrace_filter_param = true;
+		kfree(q);
+	}
+	xbc_node_for_each_array_value(node, "ftrace.notraces", anode, p) {
+		q = kstrdup(p, GFP_KERNEL);
+		if (!q)
+			return;
+		if (ftrace_set_notrace(tr->ops, q, strlen(q), 0) < 0)
+			pr_err("Failed to add %s to ftrace filter\n", p);
+		else
+			ftrace_filter_param = true;
+		kfree(q);
+	}
+}
+#else
+#define trace_boot_set_ftrace_filter(tr, node) do {} while (0)
+#endif
+
 static void __init
 trace_boot_enable_tracer(struct trace_array *tr, struct xbc_node *node)
 {
 	const char *p;
 
+	trace_boot_set_ftrace_filter(tr, node);
+
 	p = xbc_node_find_value(node, "tracer", NULL);
 	if (p && *p != '\0') {
 		if (tracing_set_tracer(tr, p) < 0)

commit 9d15dbbde1048e490f3773e67d7ef7604bab1409
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Sat Jan 11 01:07:16 2020 +0900

    tracing/boot: Add cpu_mask option support
    
    Add ftrace.cpumask option support to boot-time tracing.
    This sets cpumask for each instance.
    
     - ftrace.[instance.INSTANCE.]cpumask = CPUMASK;
       Set the trace cpumask. Note that the CPUMASK should be a string
       which <tracefs>/tracing_cpumask can accepts.
    
    Link: http://lkml.kernel.org/r/157867243625.17873.13613922641273149372.stgit@devnote2
    
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index f5db30d25b0b..81d923c16a4d 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -18,6 +18,8 @@ extern int trace_set_options(struct trace_array *tr, char *option);
 extern int tracing_set_tracer(struct trace_array *tr, const char *buf);
 extern ssize_t tracing_resize_ring_buffer(struct trace_array *tr,
 					  unsigned long size, int cpu_id);
+extern int tracing_set_cpumask(struct trace_array *tr,
+				cpumask_var_t tracing_cpumask_new);
 
 static void __init
 trace_boot_set_instance_options(struct trace_array *tr, struct xbc_node *node)
@@ -52,6 +54,18 @@ trace_boot_set_instance_options(struct trace_array *tr, struct xbc_node *node)
 		if (tracing_resize_ring_buffer(tr, v, RING_BUFFER_ALL_CPUS) < 0)
 			pr_err("Failed to resize trace buffer to %s\n", p);
 	}
+
+	p = xbc_node_find_value(node, "cpumask", NULL);
+	if (p && *p != '\0') {
+		cpumask_var_t new_mask;
+
+		if (alloc_cpumask_var(&new_mask, GFP_KERNEL)) {
+			if (cpumask_parse(p, new_mask) < 0 ||
+			    tracing_set_cpumask(tr, new_mask) < 0)
+				pr_err("Failed to set new CPU mask %s\n", p);
+			free_cpumask_var(new_mask);
+		}
+	}
 }
 
 #ifdef CONFIG_EVENT_TRACING

commit 4f712a4d04a4e49167118b41d8ea96df70a98985
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Sat Jan 11 01:07:04 2020 +0900

    tracing/boot: Add instance node support
    
    Add instance node support to boot-time tracing. User can set
    some options and event nodes under instance node.
    
     - ftrace.instance.INSTANCE[...]
       Add new INSTANCE instance. Some options and event nodes
       are acceptable for instance node.
    
    Link: http://lkml.kernel.org/r/157867242413.17873.9814204526141500278.stgit@devnote2
    
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 3054921b0877..f5db30d25b0b 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -20,7 +20,7 @@ extern ssize_t tracing_resize_ring_buffer(struct trace_array *tr,
 					  unsigned long size, int cpu_id);
 
 static void __init
-trace_boot_set_ftrace_options(struct trace_array *tr, struct xbc_node *node)
+trace_boot_set_instance_options(struct trace_array *tr, struct xbc_node *node)
 {
 	struct xbc_node *anode;
 	const char *p;
@@ -242,6 +242,40 @@ trace_boot_enable_tracer(struct trace_array *tr, struct xbc_node *node)
 	}
 }
 
+static void __init
+trace_boot_init_one_instance(struct trace_array *tr, struct xbc_node *node)
+{
+	trace_boot_set_instance_options(tr, node);
+	trace_boot_init_events(tr, node);
+	trace_boot_enable_events(tr, node);
+	trace_boot_enable_tracer(tr, node);
+}
+
+static void __init
+trace_boot_init_instances(struct xbc_node *node)
+{
+	struct xbc_node *inode;
+	struct trace_array *tr;
+	const char *p;
+
+	node = xbc_node_find_child(node, "instance");
+	if (!node)
+		return;
+
+	xbc_node_for_each_child(node, inode) {
+		p = xbc_node_get_data(inode);
+		if (!p || *p == '\0')
+			continue;
+
+		tr = trace_array_get_by_name(p);
+		if (IS_ERR(tr)) {
+			pr_err("Failed to get trace instance %s\n", p);
+			continue;
+		}
+		trace_boot_init_one_instance(tr, inode);
+	}
+}
+
 static int __init trace_boot_init(void)
 {
 	struct xbc_node *trace_node;
@@ -255,10 +289,9 @@ static int __init trace_boot_init(void)
 	if (!tr)
 		return 0;
 
-	trace_boot_set_ftrace_options(tr, trace_node);
-	trace_boot_init_events(tr, trace_node);
-	trace_boot_enable_events(tr, trace_node);
-	trace_boot_enable_tracer(tr, trace_node);
+	/* Global trace array is also one instance */
+	trace_boot_init_one_instance(tr, trace_node);
+	trace_boot_init_instances(trace_node);
 
 	return 0;
 }

commit 3fbe2d6e1fce255d918b622fb2af22e98364a154
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Sat Jan 11 01:06:52 2020 +0900

    tracing/boot: Add synthetic event support
    
    Add synthetic event node support to boot time tracing.
    The synthetic event is a kind of event node, but the group
    name is "synthetic".
    
     - ftrace.event.synthetic.EVENT.fields = FIELD[, FIELD2...]
       Defines new synthetic event with FIELDs. Each field should be
       "type varname".
    
    The synthetic node requires "fields" string arraies, which defines
    the fields as same as tracing/synth_events interface.
    
    Link: http://lkml.kernel.org/r/157867241236.17873.12411615143321557709.stgit@devnote2
    
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index a11dc60299fb..3054921b0877 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -118,6 +118,50 @@ trace_boot_add_kprobe_event(struct xbc_node *node, const char *event)
 }
 #endif
 
+#ifdef CONFIG_HIST_TRIGGERS
+extern int synth_event_run_command(const char *command);
+
+static int __init
+trace_boot_add_synth_event(struct xbc_node *node, const char *event)
+{
+	struct xbc_node *anode;
+	char buf[MAX_BUF_LEN], *q;
+	const char *p;
+	int len, delta, ret;
+
+	len = ARRAY_SIZE(buf);
+	delta = snprintf(buf, len, "%s", event);
+	if (delta >= len) {
+		pr_err("Event name is too long: %s\n", event);
+		return -E2BIG;
+	}
+	len -= delta; q = buf + delta;
+
+	xbc_node_for_each_array_value(node, "fields", anode, p) {
+		delta = snprintf(q, len, " %s;", p);
+		if (delta >= len) {
+			pr_err("fields string is too long: %s\n", p);
+			return -E2BIG;
+		}
+		len -= delta; q += delta;
+	}
+
+	ret = synth_event_run_command(buf);
+	if (ret < 0)
+		pr_err("Failed to add synthetic event: %s\n", buf);
+
+
+	return ret;
+}
+#else
+static inline int __init
+trace_boot_add_synth_event(struct xbc_node *node, const char *event)
+{
+	pr_err("Synthetic event is not supported.\n");
+	return -ENOTSUPP;
+}
+#endif
+
 static void __init
 trace_boot_init_one_event(struct trace_array *tr, struct xbc_node *gnode,
 			  struct xbc_node *enode)
@@ -133,6 +177,9 @@ trace_boot_init_one_event(struct trace_array *tr, struct xbc_node *gnode,
 	if (!strcmp(group, "kprobes"))
 		if (trace_boot_add_kprobe_event(enode, event) < 0)
 			return;
+	if (!strcmp(group, "synthetic"))
+		if (trace_boot_add_synth_event(enode, event) < 0)
+			return;
 
 	mutex_lock(&event_mutex);
 	file = find_event_file(tr, group, event);

commit 4d655281eb1bb59fad021c0f68afd033f8d0320d
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Sat Jan 11 01:06:41 2020 +0900

    tracing/boot Add kprobe event support
    
    Add kprobe event support on event node to boot-time tracing.
    If the group name of event is "kprobes", the boot-time tracing
    defines new probe event according to "probes" values.
    
     - ftrace.event.kprobes.EVENT.probes = PROBE[, PROBE2...]
       Defines new kprobe event based on PROBEs. It is able to define
       multiple probes on one event, but those must have same type of
       arguments.
    
    For example,
    
     ftrace.events.kprobes.myevent {
            probes = "vfs_read $arg1 $arg2";
            enable;
     }
    
    This will add kprobes:myevent on vfs_read with the 1st and the 2nd
    arguments.
    
    Link: http://lkml.kernel.org/r/157867240104.17873.9712052065426433111.stgit@devnote2
    
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 37524031533e..a11dc60299fb 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -76,6 +76,48 @@ trace_boot_enable_events(struct trace_array *tr, struct xbc_node *node)
 	}
 }
 
+#ifdef CONFIG_KPROBE_EVENTS
+extern int trace_kprobe_run_command(const char *command);
+
+static int __init
+trace_boot_add_kprobe_event(struct xbc_node *node, const char *event)
+{
+	struct xbc_node *anode;
+	char buf[MAX_BUF_LEN];
+	const char *val;
+	char *p;
+	int len;
+
+	len = snprintf(buf, ARRAY_SIZE(buf) - 1, "p:kprobes/%s ", event);
+	if (len >= ARRAY_SIZE(buf)) {
+		pr_err("Event name is too long: %s\n", event);
+		return -E2BIG;
+	}
+	p = buf + len;
+	len = ARRAY_SIZE(buf) - len;
+
+	xbc_node_for_each_array_value(node, "probes", anode, val) {
+		if (strlcpy(p, val, len) >= len) {
+			pr_err("Probe definition is too long: %s\n", val);
+			return -E2BIG;
+		}
+		if (trace_kprobe_run_command(buf) < 0) {
+			pr_err("Failed to add probe: %s\n", buf);
+			return -EINVAL;
+		}
+	}
+
+	return 0;
+}
+#else
+static inline int __init
+trace_boot_add_kprobe_event(struct xbc_node *node, const char *event)
+{
+	pr_err("Kprobe event is not supported.\n");
+	return -ENOTSUPP;
+}
+#endif
+
 static void __init
 trace_boot_init_one_event(struct trace_array *tr, struct xbc_node *gnode,
 			  struct xbc_node *enode)
@@ -88,6 +130,10 @@ trace_boot_init_one_event(struct trace_array *tr, struct xbc_node *gnode,
 	group = xbc_node_get_data(gnode);
 	event = xbc_node_get_data(enode);
 
+	if (!strcmp(group, "kprobes"))
+		if (trace_boot_add_kprobe_event(enode, event) < 0)
+			return;
+
 	mutex_lock(&event_mutex);
 	file = find_event_file(tr, group, event);
 	if (!file) {

commit 81a59555ff1593642824414267e1859024bd0162
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Sat Jan 11 01:06:29 2020 +0900

    tracing/boot: Add per-event settings
    
    Add per-event settings for boottime tracing. User can set filter,
    actions and enable on each event on boot. The event entries are
    under ftrace.event.GROUP.EVENT node (note that the option key
    includes event's group name and event name.) This supports below
    configs.
    
     - ftrace.event.GROUP.EVENT.enable
       Enables GROUP:EVENT tracing.
    
     - ftrace.event.GROUP.EVENT.filter = FILTER
       Set FILTER rule to the GROUP:EVENT.
    
     - ftrace.event.GROUP.EVENT.actions = ACTION[, ACTION2...]
       Set ACTIONs to the GROUP:EVENT.
    
    For example,
    
      ftrace.event.sched.sched_process_exec {
                    filter = "pid < 128"
                    enable
      }
    
    this will enable tracing "sched:sched_process_exec" event
    with "pid < 128" filter.
    
    Link: http://lkml.kernel.org/r/157867238942.17873.11177628789184546198.stgit@devnote2
    
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 4b41310184df..37524031533e 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -56,6 +56,7 @@ trace_boot_set_ftrace_options(struct trace_array *tr, struct xbc_node *node)
 
 #ifdef CONFIG_EVENT_TRACING
 extern int ftrace_set_clr_event(struct trace_array *tr, char *buf, int set);
+extern int trigger_process_regex(struct trace_event_file *file, char *buff);
 
 static void __init
 trace_boot_enable_events(struct trace_array *tr, struct xbc_node *node)
@@ -74,8 +75,66 @@ trace_boot_enable_events(struct trace_array *tr, struct xbc_node *node)
 			pr_err("Failed to enable event: %s\n", p);
 	}
 }
+
+static void __init
+trace_boot_init_one_event(struct trace_array *tr, struct xbc_node *gnode,
+			  struct xbc_node *enode)
+{
+	struct trace_event_file *file;
+	struct xbc_node *anode;
+	char buf[MAX_BUF_LEN];
+	const char *p, *group, *event;
+
+	group = xbc_node_get_data(gnode);
+	event = xbc_node_get_data(enode);
+
+	mutex_lock(&event_mutex);
+	file = find_event_file(tr, group, event);
+	if (!file) {
+		pr_err("Failed to find event: %s:%s\n", group, event);
+		goto out;
+	}
+
+	p = xbc_node_find_value(enode, "filter", NULL);
+	if (p && *p != '\0') {
+		if (strlcpy(buf, p, ARRAY_SIZE(buf)) >= ARRAY_SIZE(buf))
+			pr_err("filter string is too long: %s\n", p);
+		else if (apply_event_filter(file, buf) < 0)
+			pr_err("Failed to apply filter: %s\n", buf);
+	}
+
+	xbc_node_for_each_array_value(enode, "actions", anode, p) {
+		if (strlcpy(buf, p, ARRAY_SIZE(buf)) >= ARRAY_SIZE(buf))
+			pr_err("action string is too long: %s\n", p);
+		else if (trigger_process_regex(file, buf) < 0)
+			pr_err("Failed to apply an action: %s\n", buf);
+	}
+
+	if (xbc_node_find_value(enode, "enable", NULL)) {
+		if (trace_event_enable_disable(file, 1, 0) < 0)
+			pr_err("Failed to enable event node: %s:%s\n",
+				group, event);
+	}
+out:
+	mutex_unlock(&event_mutex);
+}
+
+static void __init
+trace_boot_init_events(struct trace_array *tr, struct xbc_node *node)
+{
+	struct xbc_node *gnode, *enode;
+
+	node = xbc_node_find_child(node, "event");
+	if (!node)
+		return;
+	/* per-event key starts with "event.GROUP.EVENT" */
+	xbc_node_for_each_child(node, gnode)
+		xbc_node_for_each_child(gnode, enode)
+			trace_boot_init_one_event(tr, gnode, enode);
+}
 #else
 #define trace_boot_enable_events(tr, node) do {} while (0)
+#define trace_boot_init_events(tr, node) do {} while (0)
 #endif
 
 static void __init
@@ -104,6 +163,7 @@ static int __init trace_boot_init(void)
 		return 0;
 
 	trace_boot_set_ftrace_options(tr, trace_node);
+	trace_boot_init_events(tr, trace_node);
 	trace_boot_enable_events(tr, trace_node);
 	trace_boot_enable_tracer(tr, trace_node);
 

commit 9c5b9d3d65e485826fb935453f01171b1a337aa8
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Sat Jan 11 01:06:17 2020 +0900

    tracing/boot: Add boot-time tracing
    
    Setup tracing options via extra boot config in addition to kernel
    command line.
    
    This adds following commands support. These are applied to
    the global trace instance.
    
     - ftrace.options = OPT1[,OPT2...]
       Enable given ftrace options.
    
     - ftrace.trace_clock = CLOCK
       Set given CLOCK to ftrace's trace_clock.
    
     - ftrace.buffer_size = SIZE
       Configure ftrace buffer size to SIZE. You can use "KB" or "MB"
       for that SIZE.
    
     - ftrace.events = EVENT[, EVENT2...]
       Enable given events on boot. You can use a wild card in EVENT.
    
     - ftrace.tracer = TRACER
       Set TRACER to current tracer on boot. (e.g. function)
    
    Note that this is NOT replacing the kernel parameters, because
    this boot config based setting is later than that. If you want to
    trace earlier boot events, you still need kernel parameters.
    
    Link: http://lkml.kernel.org/r/157867237723.17873.17494943526320587488.stgit@devnote2
    
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
new file mode 100644
index 000000000000..4b41310184df
--- /dev/null
+++ b/kernel/trace/trace_boot.c
@@ -0,0 +1,113 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * trace_boot.c
+ * Tracing kernel boot-time
+ */
+
+#define pr_fmt(fmt)	"trace_boot: " fmt
+
+#include <linux/ftrace.h>
+#include <linux/init.h>
+#include <linux/bootconfig.h>
+
+#include "trace.h"
+
+#define MAX_BUF_LEN 256
+
+extern int trace_set_options(struct trace_array *tr, char *option);
+extern int tracing_set_tracer(struct trace_array *tr, const char *buf);
+extern ssize_t tracing_resize_ring_buffer(struct trace_array *tr,
+					  unsigned long size, int cpu_id);
+
+static void __init
+trace_boot_set_ftrace_options(struct trace_array *tr, struct xbc_node *node)
+{
+	struct xbc_node *anode;
+	const char *p;
+	char buf[MAX_BUF_LEN];
+	unsigned long v = 0;
+
+	/* Common ftrace options */
+	xbc_node_for_each_array_value(node, "options", anode, p) {
+		if (strlcpy(buf, p, ARRAY_SIZE(buf)) >= ARRAY_SIZE(buf)) {
+			pr_err("String is too long: %s\n", p);
+			continue;
+		}
+
+		if (trace_set_options(tr, buf) < 0)
+			pr_err("Failed to set option: %s\n", buf);
+	}
+
+	p = xbc_node_find_value(node, "trace_clock", NULL);
+	if (p && *p != '\0') {
+		if (tracing_set_clock(tr, p) < 0)
+			pr_err("Failed to set trace clock: %s\n", p);
+	}
+
+	p = xbc_node_find_value(node, "buffer_size", NULL);
+	if (p && *p != '\0') {
+		v = memparse(p, NULL);
+		if (v < PAGE_SIZE)
+			pr_err("Buffer size is too small: %s\n", p);
+		if (tracing_resize_ring_buffer(tr, v, RING_BUFFER_ALL_CPUS) < 0)
+			pr_err("Failed to resize trace buffer to %s\n", p);
+	}
+}
+
+#ifdef CONFIG_EVENT_TRACING
+extern int ftrace_set_clr_event(struct trace_array *tr, char *buf, int set);
+
+static void __init
+trace_boot_enable_events(struct trace_array *tr, struct xbc_node *node)
+{
+	struct xbc_node *anode;
+	char buf[MAX_BUF_LEN];
+	const char *p;
+
+	xbc_node_for_each_array_value(node, "events", anode, p) {
+		if (strlcpy(buf, p, ARRAY_SIZE(buf)) >= ARRAY_SIZE(buf)) {
+			pr_err("String is too long: %s\n", p);
+			continue;
+		}
+
+		if (ftrace_set_clr_event(tr, buf, 1) < 0)
+			pr_err("Failed to enable event: %s\n", p);
+	}
+}
+#else
+#define trace_boot_enable_events(tr, node) do {} while (0)
+#endif
+
+static void __init
+trace_boot_enable_tracer(struct trace_array *tr, struct xbc_node *node)
+{
+	const char *p;
+
+	p = xbc_node_find_value(node, "tracer", NULL);
+	if (p && *p != '\0') {
+		if (tracing_set_tracer(tr, p) < 0)
+			pr_err("Failed to set given tracer: %s\n", p);
+	}
+}
+
+static int __init trace_boot_init(void)
+{
+	struct xbc_node *trace_node;
+	struct trace_array *tr;
+
+	trace_node = xbc_find_node("ftrace");
+	if (!trace_node)
+		return 0;
+
+	tr = top_trace_array();
+	if (!tr)
+		return 0;
+
+	trace_boot_set_ftrace_options(tr, trace_node);
+	trace_boot_enable_events(tr, trace_node);
+	trace_boot_enable_tracer(tr, trace_node);
+
+	return 0;
+}
+
+fs_initcall(trace_boot_init);

commit 30dbb20e68e6f7df974b77d2350ebad5eb6f6c9e
Author: Américo Wang <xiyou.wangcong@gmail.com>
Date:   Wed May 26 18:57:53 2010 +0800

    tracing: Remove boot tracer
    
    The boot tracer is useless. It simply logs the initcalls
    but in fact these initcalls are also logged through printk
    while using the initcall_debug kernel parameter.
    
    Nobody seem to be using it so far. Then just remove it.
    
    Signed-off-by: WANG Cong <xiyou.wangcong@gmail.com>
    Cc: Chase Douglas <chase.douglas@canonical.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    LKML-Reference: <20100526105753.GA5677@cr0.nay.redhat.com>
    [ remove the hooks in main.c, and the headers ]
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
deleted file mode 100644
index c21d5f3956ad..000000000000
--- a/kernel/trace/trace_boot.c
+++ /dev/null
@@ -1,185 +0,0 @@
-/*
- * ring buffer based initcalls tracer
- *
- * Copyright (C) 2008 Frederic Weisbecker <fweisbec@gmail.com>
- *
- */
-
-#include <linux/init.h>
-#include <linux/debugfs.h>
-#include <linux/ftrace.h>
-#include <linux/kallsyms.h>
-#include <linux/time.h>
-
-#include "trace.h"
-#include "trace_output.h"
-
-static struct trace_array *boot_trace;
-static bool pre_initcalls_finished;
-
-/* Tells the boot tracer that the pre_smp_initcalls are finished.
- * So we are ready .
- * It doesn't enable sched events tracing however.
- * You have to call enable_boot_trace to do so.
- */
-void start_boot_trace(void)
-{
-	pre_initcalls_finished = true;
-}
-
-void enable_boot_trace(void)
-{
-	if (boot_trace && pre_initcalls_finished)
-		tracing_start_sched_switch_record();
-}
-
-void disable_boot_trace(void)
-{
-	if (boot_trace && pre_initcalls_finished)
-		tracing_stop_sched_switch_record();
-}
-
-static int boot_trace_init(struct trace_array *tr)
-{
-	boot_trace = tr;
-
-	if (!tr)
-		return 0;
-
-	tracing_reset_online_cpus(tr);
-
-	tracing_sched_switch_assign_trace(tr);
-	return 0;
-}
-
-static enum print_line_t
-initcall_call_print_line(struct trace_iterator *iter)
-{
-	struct trace_entry *entry = iter->ent;
-	struct trace_seq *s = &iter->seq;
-	struct trace_boot_call *field;
-	struct boot_trace_call *call;
-	u64 ts;
-	unsigned long nsec_rem;
-	int ret;
-
-	trace_assign_type(field, entry);
-	call = &field->boot_call;
-	ts = iter->ts;
-	nsec_rem = do_div(ts, NSEC_PER_SEC);
-
-	ret = trace_seq_printf(s, "[%5ld.%09ld] calling  %s @ %i\n",
-			(unsigned long)ts, nsec_rem, call->func, call->caller);
-
-	if (!ret)
-		return TRACE_TYPE_PARTIAL_LINE;
-	else
-		return TRACE_TYPE_HANDLED;
-}
-
-static enum print_line_t
-initcall_ret_print_line(struct trace_iterator *iter)
-{
-	struct trace_entry *entry = iter->ent;
-	struct trace_seq *s = &iter->seq;
-	struct trace_boot_ret *field;
-	struct boot_trace_ret *init_ret;
-	u64 ts;
-	unsigned long nsec_rem;
-	int ret;
-
-	trace_assign_type(field, entry);
-	init_ret = &field->boot_ret;
-	ts = iter->ts;
-	nsec_rem = do_div(ts, NSEC_PER_SEC);
-
-	ret = trace_seq_printf(s, "[%5ld.%09ld] initcall %s "
-			"returned %d after %llu msecs\n",
-			(unsigned long) ts,
-			nsec_rem,
-			init_ret->func, init_ret->result, init_ret->duration);
-
-	if (!ret)
-		return TRACE_TYPE_PARTIAL_LINE;
-	else
-		return TRACE_TYPE_HANDLED;
-}
-
-static enum print_line_t initcall_print_line(struct trace_iterator *iter)
-{
-	struct trace_entry *entry = iter->ent;
-
-	switch (entry->type) {
-	case TRACE_BOOT_CALL:
-		return initcall_call_print_line(iter);
-	case TRACE_BOOT_RET:
-		return initcall_ret_print_line(iter);
-	default:
-		return TRACE_TYPE_UNHANDLED;
-	}
-}
-
-struct tracer boot_tracer __read_mostly =
-{
-	.name		= "initcall",
-	.init		= boot_trace_init,
-	.reset		= tracing_reset_online_cpus,
-	.print_line	= initcall_print_line,
-};
-
-void trace_boot_call(struct boot_trace_call *bt, initcall_t fn)
-{
-	struct ftrace_event_call *call = &event_boot_call;
-	struct ring_buffer_event *event;
-	struct ring_buffer *buffer;
-	struct trace_boot_call *entry;
-	struct trace_array *tr = boot_trace;
-
-	if (!tr || !pre_initcalls_finished)
-		return;
-
-	/* Get its name now since this function could
-	 * disappear because it is in the .init section.
-	 */
-	sprint_symbol(bt->func, (unsigned long)fn);
-	preempt_disable();
-
-	buffer = tr->buffer;
-	event = trace_buffer_lock_reserve(buffer, TRACE_BOOT_CALL,
-					  sizeof(*entry), 0, 0);
-	if (!event)
-		goto out;
-	entry	= ring_buffer_event_data(event);
-	entry->boot_call = *bt;
-	if (!filter_check_discard(call, entry, buffer, event))
-		trace_buffer_unlock_commit(buffer, event, 0, 0);
- out:
-	preempt_enable();
-}
-
-void trace_boot_ret(struct boot_trace_ret *bt, initcall_t fn)
-{
-	struct ftrace_event_call *call = &event_boot_ret;
-	struct ring_buffer_event *event;
-	struct ring_buffer *buffer;
-	struct trace_boot_ret *entry;
-	struct trace_array *tr = boot_trace;
-
-	if (!tr || !pre_initcalls_finished)
-		return;
-
-	sprint_symbol(bt->func, (unsigned long)fn);
-	preempt_disable();
-
-	buffer = tr->buffer;
-	event = trace_buffer_lock_reserve(buffer, TRACE_BOOT_RET,
-					  sizeof(*entry), 0, 0);
-	if (!event)
-		goto out;
-	entry	= ring_buffer_event_data(event);
-	entry->boot_ret = *bt;
-	if (!filter_check_discard(call, entry, buffer, event))
-		trace_buffer_unlock_commit(buffer, event, 0, 0);
- out:
-	preempt_enable();
-}

commit 60ba77022712c7cda0eda286154bae160446b24a
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Sat Sep 12 23:34:04 2009 -0400

    tracing: add filter event logic to special, mmiotrace and boot tracers
    
    Now that the pluging tracers use macros to create the structures and
    automate the exporting of their formats to the format files, they also
    automatically get a filter file.
    
    This patch adds the code to implement the filter logic in the trace
    recordings.
    
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 19bfc75d467e..c21d5f3956ad 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -129,6 +129,7 @@ struct tracer boot_tracer __read_mostly =
 
 void trace_boot_call(struct boot_trace_call *bt, initcall_t fn)
 {
+	struct ftrace_event_call *call = &event_boot_call;
 	struct ring_buffer_event *event;
 	struct ring_buffer *buffer;
 	struct trace_boot_call *entry;
@@ -150,13 +151,15 @@ void trace_boot_call(struct boot_trace_call *bt, initcall_t fn)
 		goto out;
 	entry	= ring_buffer_event_data(event);
 	entry->boot_call = *bt;
-	trace_buffer_unlock_commit(buffer, event, 0, 0);
+	if (!filter_check_discard(call, entry, buffer, event))
+		trace_buffer_unlock_commit(buffer, event, 0, 0);
  out:
 	preempt_enable();
 }
 
 void trace_boot_ret(struct boot_trace_ret *bt, initcall_t fn)
 {
+	struct ftrace_event_call *call = &event_boot_ret;
 	struct ring_buffer_event *event;
 	struct ring_buffer *buffer;
 	struct trace_boot_ret *entry;
@@ -175,7 +178,8 @@ void trace_boot_ret(struct boot_trace_ret *bt, initcall_t fn)
 		goto out;
 	entry	= ring_buffer_event_data(event);
 	entry->boot_ret = *bt;
-	trace_buffer_unlock_commit(buffer, event, 0, 0);
+	if (!filter_check_discard(call, entry, buffer, event))
+		trace_buffer_unlock_commit(buffer, event, 0, 0);
  out:
 	preempt_enable();
 }

commit e77405ad80f53966524b5c31244e13fbbbecbd84
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Wed Sep 2 14:17:06 2009 -0400

    tracing: pass around ring buffer instead of tracer
    
    The latency tracers (irqsoff and wakeup) can swap trace buffers
    on the fly. If an event is happening and has reserved data on one of
    the buffers, and the latency tracer swaps the global buffer with the
    max buffer, the result is that the event may commit the data to the
    wrong buffer.
    
    This patch changes the API to the trace recording to be recieve the
    buffer that was used to reserve a commit. Then this buffer can be passed
    in to the commit.
    
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 863139327816..19bfc75d467e 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -130,6 +130,7 @@ struct tracer boot_tracer __read_mostly =
 void trace_boot_call(struct boot_trace_call *bt, initcall_t fn)
 {
 	struct ring_buffer_event *event;
+	struct ring_buffer *buffer;
 	struct trace_boot_call *entry;
 	struct trace_array *tr = boot_trace;
 
@@ -142,13 +143,14 @@ void trace_boot_call(struct boot_trace_call *bt, initcall_t fn)
 	sprint_symbol(bt->func, (unsigned long)fn);
 	preempt_disable();
 
-	event = trace_buffer_lock_reserve(tr, TRACE_BOOT_CALL,
+	buffer = tr->buffer;
+	event = trace_buffer_lock_reserve(buffer, TRACE_BOOT_CALL,
 					  sizeof(*entry), 0, 0);
 	if (!event)
 		goto out;
 	entry	= ring_buffer_event_data(event);
 	entry->boot_call = *bt;
-	trace_buffer_unlock_commit(tr, event, 0, 0);
+	trace_buffer_unlock_commit(buffer, event, 0, 0);
  out:
 	preempt_enable();
 }
@@ -156,6 +158,7 @@ void trace_boot_call(struct boot_trace_call *bt, initcall_t fn)
 void trace_boot_ret(struct boot_trace_ret *bt, initcall_t fn)
 {
 	struct ring_buffer_event *event;
+	struct ring_buffer *buffer;
 	struct trace_boot_ret *entry;
 	struct trace_array *tr = boot_trace;
 
@@ -165,13 +168,14 @@ void trace_boot_ret(struct boot_trace_ret *bt, initcall_t fn)
 	sprint_symbol(bt->func, (unsigned long)fn);
 	preempt_disable();
 
-	event = trace_buffer_lock_reserve(tr, TRACE_BOOT_RET,
+	buffer = tr->buffer;
+	event = trace_buffer_lock_reserve(buffer, TRACE_BOOT_RET,
 					  sizeof(*entry), 0, 0);
 	if (!event)
 		goto out;
 	entry	= ring_buffer_event_data(event);
 	entry->boot_ret = *bt;
-	trace_buffer_unlock_commit(tr, event, 0, 0);
+	trace_buffer_unlock_commit(buffer, event, 0, 0);
  out:
 	preempt_enable();
 }

commit 76f0d07376388f32698ba51b6090a26b90c1342f
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Fri Sep 4 12:12:39 2009 -0400

    tracing: remove users of tracing_reset
    
    The function tracing_reset is deprecated for outside use of trace.c.
    
    The new function to reset the the buffers is tracing_reset_online_cpus.
    
    The reason for this is that resetting the buffers while the event
    trace points are active can corrupt the buffers, because they may
    be writing at the time of reset. The tracing_reset_online_cpus disables
    writes and waits for current writers to finish.
    
    This patch replaces all users of tracing_reset except for the latency
    tracers. Those changes require more work and will be removed in the
    following patches.
    
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index a29ef23ffb47..863139327816 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -41,14 +41,12 @@ void disable_boot_trace(void)
 
 static int boot_trace_init(struct trace_array *tr)
 {
-	int cpu;
 	boot_trace = tr;
 
 	if (!tr)
 		return 0;
 
-	for_each_cpu(cpu, cpu_possible_mask)
-		tracing_reset(tr, cpu);
+	tracing_reset_online_cpus(tr);
 
 	tracing_sched_switch_assign_trace(tr);
 	return 0;

commit a5dec5573f3c7e63f2f9b5852b9759ea342a5ff9
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Fri Mar 27 14:55:44 2009 +0800

    tracing: use macros to denote usec and nsec per second
    
    Impact: cleanup
    
    Use USEC_PER_SEC and NSEC_PER_SEC instead of 1000000 and 1000000000.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    LKML-Reference: <49CC7870.9000309@cn.fujitsu.com>
    Acked-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 7a30fc4c3642..a29ef23ffb47 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -9,6 +9,7 @@
 #include <linux/debugfs.h>
 #include <linux/ftrace.h>
 #include <linux/kallsyms.h>
+#include <linux/time.h>
 
 #include "trace.h"
 #include "trace_output.h"
@@ -67,7 +68,7 @@ initcall_call_print_line(struct trace_iterator *iter)
 	trace_assign_type(field, entry);
 	call = &field->boot_call;
 	ts = iter->ts;
-	nsec_rem = do_div(ts, 1000000000);
+	nsec_rem = do_div(ts, NSEC_PER_SEC);
 
 	ret = trace_seq_printf(s, "[%5ld.%09ld] calling  %s @ %i\n",
 			(unsigned long)ts, nsec_rem, call->func, call->caller);
@@ -92,7 +93,7 @@ initcall_ret_print_line(struct trace_iterator *iter)
 	trace_assign_type(field, entry);
 	init_ret = &field->boot_ret;
 	ts = iter->ts;
-	nsec_rem = do_div(ts, 1000000000);
+	nsec_rem = do_div(ts, NSEC_PER_SEC);
 
 	ret = trace_seq_printf(s, "[%5ld.%09ld] initcall %s "
 			"returned %d after %llu msecs\n",

commit 51a763dd84253bab1d0a1e68e11a7753d1b702ca
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Feb 5 16:14:13 2009 -0200

    tracing: Introduce trace_buffer_{lock_reserve,unlock_commit}
    
    Impact: new API
    
    These new functions do what previously was being open coded, reducing
    the number of details ftrace plugin writers have to worry about.
    
    It also standardizes the handling of stacktrace, userstacktrace and
    other trace options we may introduce in the future.
    
    With this patch, for instance, the blk tracer (and some others already
    in the tree) can use the "userstacktrace" /d/tracing/trace_options
    facility.
    
    $ codiff /tmp/vmlinux.before /tmp/vmlinux.after
    linux-2.6-tip/kernel/trace/trace.c:
      trace_vprintk              |   -5
      trace_graph_return         |  -22
      trace_graph_entry          |  -26
      trace_function             |  -45
      __ftrace_trace_stack       |  -27
      ftrace_trace_userstack     |  -29
      tracing_sched_switch_trace |  -66
      tracing_stop               |   +1
      trace_seq_to_user          |   -1
      ftrace_trace_special       |  -63
      ftrace_special             |   +1
      tracing_sched_wakeup_trace |  -70
      tracing_reset_online_cpus  |   -1
     13 functions changed, 2 bytes added, 355 bytes removed, diff: -353
    
    linux-2.6-tip/block/blktrace.c:
      __blk_add_trace |  -58
     1 function changed, 58 bytes removed, diff: -58
    
    linux-2.6-tip/kernel/trace/trace.c:
      trace_buffer_lock_reserve  |  +88
      trace_buffer_unlock_commit |  +86
     2 functions changed, 174 bytes added, diff: +174
    
    /tmp/vmlinux.after:
     16 functions changed, 176 bytes added, 413 bytes removed, diff: -237
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Acked-by: Frédéric Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 4e08debf662d..7a30fc4c3642 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -143,17 +143,13 @@ void trace_boot_call(struct boot_trace_call *bt, initcall_t fn)
 	sprint_symbol(bt->func, (unsigned long)fn);
 	preempt_disable();
 
-	event = ring_buffer_lock_reserve(tr->buffer, sizeof(*entry));
+	event = trace_buffer_lock_reserve(tr, TRACE_BOOT_CALL,
+					  sizeof(*entry), 0, 0);
 	if (!event)
 		goto out;
 	entry	= ring_buffer_event_data(event);
-	tracing_generic_entry_update(&entry->ent, 0, 0);
-	entry->ent.type = TRACE_BOOT_CALL;
 	entry->boot_call = *bt;
-	ring_buffer_unlock_commit(tr->buffer, event);
-
-	trace_wake_up();
-
+	trace_buffer_unlock_commit(tr, event, 0, 0);
  out:
 	preempt_enable();
 }
@@ -170,17 +166,13 @@ void trace_boot_ret(struct boot_trace_ret *bt, initcall_t fn)
 	sprint_symbol(bt->func, (unsigned long)fn);
 	preempt_disable();
 
-	event = ring_buffer_lock_reserve(tr->buffer, sizeof(*entry));
+	event = trace_buffer_lock_reserve(tr, TRACE_BOOT_RET,
+					  sizeof(*entry), 0, 0);
 	if (!event)
 		goto out;
 	entry	= ring_buffer_event_data(event);
-	tracing_generic_entry_update(&entry->ent, 0, 0);
-	entry->ent.type = TRACE_BOOT_RET;
 	entry->boot_ret = *bt;
-	ring_buffer_unlock_commit(tr->buffer, event);
-
-	trace_wake_up();
-
+	trace_buffer_unlock_commit(tr, event, 0, 0);
  out:
 	preempt_enable();
 }

commit 0a9877514c4fed10a70720293b37213dd172ee3e
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Feb 5 16:12:56 2009 -0200

    ring_buffer: remove unused flags parameter
    
    Impact: API change, cleanup
    
    >From ring_buffer_{lock_reserve,unlock_commit}.
    
    $ codiff /tmp/vmlinux.before /tmp/vmlinux.after
    linux-2.6-tip/kernel/trace/trace.c:
      trace_vprintk              |  -14
      trace_graph_return         |  -14
      trace_graph_entry          |  -10
      trace_function             |   -8
      __ftrace_trace_stack       |   -8
      ftrace_trace_userstack     |   -8
      tracing_sched_switch_trace |   -8
      ftrace_trace_special       |  -12
      tracing_sched_wakeup_trace |   -8
     9 functions changed, 90 bytes removed, diff: -90
    
    linux-2.6-tip/block/blktrace.c:
      __blk_add_trace |   -1
     1 function changed, 1 bytes removed, diff: -1
    
    /tmp/vmlinux.after:
     10 functions changed, 91 bytes removed, diff: -91
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Acked-by: Frédéric Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 1f07895977a0..4e08debf662d 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -132,7 +132,6 @@ void trace_boot_call(struct boot_trace_call *bt, initcall_t fn)
 {
 	struct ring_buffer_event *event;
 	struct trace_boot_call *entry;
-	unsigned long irq_flags;
 	struct trace_array *tr = boot_trace;
 
 	if (!tr || !pre_initcalls_finished)
@@ -144,15 +143,14 @@ void trace_boot_call(struct boot_trace_call *bt, initcall_t fn)
 	sprint_symbol(bt->func, (unsigned long)fn);
 	preempt_disable();
 
-	event = ring_buffer_lock_reserve(tr->buffer, sizeof(*entry),
-					 &irq_flags);
+	event = ring_buffer_lock_reserve(tr->buffer, sizeof(*entry));
 	if (!event)
 		goto out;
 	entry	= ring_buffer_event_data(event);
 	tracing_generic_entry_update(&entry->ent, 0, 0);
 	entry->ent.type = TRACE_BOOT_CALL;
 	entry->boot_call = *bt;
-	ring_buffer_unlock_commit(tr->buffer, event, irq_flags);
+	ring_buffer_unlock_commit(tr->buffer, event);
 
 	trace_wake_up();
 
@@ -164,7 +162,6 @@ void trace_boot_ret(struct boot_trace_ret *bt, initcall_t fn)
 {
 	struct ring_buffer_event *event;
 	struct trace_boot_ret *entry;
-	unsigned long irq_flags;
 	struct trace_array *tr = boot_trace;
 
 	if (!tr || !pre_initcalls_finished)
@@ -173,15 +170,14 @@ void trace_boot_ret(struct boot_trace_ret *bt, initcall_t fn)
 	sprint_symbol(bt->func, (unsigned long)fn);
 	preempt_disable();
 
-	event = ring_buffer_lock_reserve(tr->buffer, sizeof(*entry),
-					 &irq_flags);
+	event = ring_buffer_lock_reserve(tr->buffer, sizeof(*entry));
 	if (!event)
 		goto out;
 	entry	= ring_buffer_event_data(event);
 	tracing_generic_entry_update(&entry->ent, 0, 0);
 	entry->ent.type = TRACE_BOOT_RET;
 	entry->boot_ret = *bt;
-	ring_buffer_unlock_commit(tr->buffer, event, irq_flags);
+	ring_buffer_unlock_commit(tr->buffer, event);
 
 	trace_wake_up();
 

commit 79fb0768fbd371f3b94d909f51f587b3a24ab272
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Mon Feb 2 21:38:33 2009 -0500

    trace: let boot trace be chosen by command line
    
    Now that we have a working ftrace=<tracer> function, make the boot
    tracer get activated by it. This way we can turn it on or off without
    recompiling the kernel, as well as keeping the selftests on. The
    selftests are disabled whenever a default tracer starts running.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 0e94b3d091f7..1f07895977a0 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -28,13 +28,13 @@ void start_boot_trace(void)
 
 void enable_boot_trace(void)
 {
-	if (pre_initcalls_finished)
+	if (boot_trace && pre_initcalls_finished)
 		tracing_start_sched_switch_record();
 }
 
 void disable_boot_trace(void)
 {
-	if (pre_initcalls_finished)
+	if (boot_trace && pre_initcalls_finished)
 		tracing_stop_sched_switch_record();
 }
 
@@ -43,6 +43,9 @@ static int boot_trace_init(struct trace_array *tr)
 	int cpu;
 	boot_trace = tr;
 
+	if (!tr)
+		return 0;
+
 	for_each_cpu(cpu, cpu_possible_mask)
 		tracing_reset(tr, cpu);
 
@@ -132,7 +135,7 @@ void trace_boot_call(struct boot_trace_call *bt, initcall_t fn)
 	unsigned long irq_flags;
 	struct trace_array *tr = boot_trace;
 
-	if (!pre_initcalls_finished)
+	if (!tr || !pre_initcalls_finished)
 		return;
 
 	/* Get its name now since this function could
@@ -164,7 +167,7 @@ void trace_boot_ret(struct boot_trace_ret *bt, initcall_t fn)
 	unsigned long irq_flags;
 	struct trace_array *tr = boot_trace;
 
-	if (!pre_initcalls_finished)
+	if (!tr || !pre_initcalls_finished)
 		return;
 
 	sprint_symbol(bt->func, (unsigned long)fn);

commit 99793e3dbe39a50d871eedc361659a894601e2bf
Merge: 3e80680208ba a103e2ab7377
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Jan 6 10:18:43 2009 +0100

    Merge branches 'tracing/kmemtrace2' and 'tracing/ftrace' into tracing/urgent

commit 4462344ee9ea9224d026801b877887f2f39774a3
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Thu Jan 1 10:12:23 2009 +1030

    cpumask: convert kernel trace functions further
    
    Impact: Reduce future memory usage, use new cpumask API.
    
    Since the last patch was created and acked, more old cpumask users
    slipped into kernel/trace.
    
    Mostly trivial conversions, except struct trace_iterator's "started"
    member becomes a cpumask_var_t.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 3ccebde28482..366c8c333e13 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -42,7 +42,7 @@ static int boot_trace_init(struct trace_array *tr)
 	int cpu;
 	boot_trace = tr;
 
-	for_each_cpu_mask(cpu, cpu_possible_map)
+	for_each_cpu(cpu, cpu_possible_mask)
 		tracing_reset(tr, cpu);
 
 	tracing_sched_switch_assign_trace(tr);

commit f0868d1e23a8efec33beb3aa688aab7fdb1ae093
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Tue Dec 23 23:24:12 2008 -0500

    ftrace: set up trace event hash infrastructure
    
    Impact: simplify/generalize/refactor trace.c
    
    The trace.c file is becoming more difficult to maintain due to the
    growing number of events. There is several formats that an event may
    be printed. This patch sets up the infrastructure of an event hash to
    allow for events to register how they should be printed.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 3ccebde28482..cb2ff3e297b1 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -11,6 +11,7 @@
 #include <linux/kallsyms.h>
 
 #include "trace.h"
+#include "trace_output.h"
 
 static struct trace_array *boot_trace;
 static bool pre_initcalls_finished;

commit 213cc060797378059a28ebc5c539f3e9a80160bd
Author: Pekka J Enberg <penberg@cs.helsinki.fi>
Date:   Fri Dec 19 12:08:39 2008 +0200

    ftrace: introduce tracing_reset_online_cpus() helper
    
    Impact: cleanup
    
    This patch factors out common code from multiple tracers into a
    tracing_reset_online_cpus() function and converts the tracers to use it.
    
    Signed-off-by: Pekka Enberg <penberg@cs.helsinki.fi>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index a4fa2c57e34e..3ccebde28482 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -37,16 +37,6 @@ void disable_boot_trace(void)
 		tracing_stop_sched_switch_record();
 }
 
-static void reset_boot_trace(struct trace_array *tr)
-{
-	int cpu;
-
-	tr->time_start = ftrace_now(tr->cpu);
-
-	for_each_online_cpu(cpu)
-		tracing_reset(tr, cpu);
-}
-
 static int boot_trace_init(struct trace_array *tr)
 {
 	int cpu;
@@ -130,7 +120,7 @@ struct tracer boot_tracer __read_mostly =
 {
 	.name		= "initcall",
 	.init		= boot_trace_init,
-	.reset		= reset_boot_trace,
+	.reset		= tracing_reset_online_cpus,
 	.print_line	= initcall_print_line,
 };
 

commit 1c80025a49855b12fa09bb6db71820e3367b1369
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Sun Nov 16 05:57:26 2008 +0100

    tracing/ftrace: change the type of the init() callback
    
    Impact: extend the ->init() method with the ability to fail
    
    This bring a way to know if the initialization of a tracer successed.
    A tracer must return 0 on success and a traditional error (ie:
    -ENOMEM) if it fails.
    
    If a tracer fails to init, it is free to print a detailed warn. The
    tracing api will not and switch to a new tracer will just return the
    error from the init callback.
    
    Note: this will be used for the return tracer.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index cb333b7fd113..a4fa2c57e34e 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -47,7 +47,7 @@ static void reset_boot_trace(struct trace_array *tr)
 		tracing_reset(tr, cpu);
 }
 
-static void boot_trace_init(struct trace_array *tr)
+static int boot_trace_init(struct trace_array *tr)
 {
 	int cpu;
 	boot_trace = tr;
@@ -56,6 +56,7 @@ static void boot_trace_init(struct trace_array *tr)
 		tracing_reset(tr, cpu);
 
 	tracing_sched_switch_assign_trace(tr);
+	return 0;
 }
 
 static enum print_line_t

commit 74239072830ef3f1398edeb1bc1076fc330fd4a2
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Nov 11 23:24:42 2008 +0100

    tracing/fastboot: Use the ring-buffer timestamp for initcall entries
    
    Impact: Split the boot tracer entries in two parts: call and return
    
    Now that we are using the sched tracer from the boot tracer, we want
    to use the same timestamp than the ring-buffer to have consistent time
    captures between sched events and initcall events.
    
    So we get rid of the old time capture by the boot tracer and split the
    initcall events in two parts: call and return. This way we have the
    ring buffer timestamp of both.
    
    An example trace:
    
    [   27.904149584] calling  net_ns_init+0x0/0x1c0 @ 1
    [   27.904429624] initcall net_ns_init+0x0/0x1c0 returned 0 after 0 msecs
    [   27.904575926] calling  reboot_init+0x0/0x20 @ 1
    [   27.904655399] initcall reboot_init+0x0/0x20 returned 0 after 0 msecs
    [   27.904800228] calling  sysctl_init+0x0/0x30 @ 1
    [   27.905142914] initcall sysctl_init+0x0/0x30 returned 0 after 0 msecs
    [   27.905287211] calling  ksysfs_init+0x0/0xb0 @ 1
     ##### CPU 0 buffer started ####
                init-1     [000]    27.905395:      1:120:R   + [001]    11:115:S
     ##### CPU 1 buffer started ####
              <idle>-0     [001]    27.905425:      0:140:R ==> [001]    11:115:R
                init-1     [000]    27.905426:      1:120:D ==> [000]     0:140:R
              <idle>-0     [000]    27.905431:      0:140:R   + [000]     4:115:S
              <idle>-0     [000]    27.905451:      0:140:R ==> [000]     4:115:R
         ksoftirqd/0-4     [000]    27.905456:      4:115:S ==> [000]     0:140:R
               udevd-11    [001]    27.905458:     11:115:R   + [001]    14:115:R
              <idle>-0     [000]    27.905459:      0:140:R   + [000]     4:115:S
              <idle>-0     [000]    27.905462:      0:140:R ==> [000]     4:115:R
               udevd-11    [001]    27.905462:     11:115:R ==> [001]    14:115:R
         ksoftirqd/0-4     [000]    27.905467:      4:115:S ==> [000]     0:140:R
              <idle>-0     [000]    27.905470:      0:140:R   + [000]     4:115:S
              <idle>-0     [000]    27.905473:      0:140:R ==> [000]     4:115:R
         ksoftirqd/0-4     [000]    27.905476:      4:115:S ==> [000]     0:140:R
              <idle>-0     [000]    27.905479:      0:140:R   + [000]     4:115:S
              <idle>-0     [000]    27.905482:      0:140:R ==> [000]     4:115:R
         ksoftirqd/0-4     [000]    27.905486:      4:115:S ==> [000]     0:140:R
               udevd-14    [001]    27.905499:     14:120:X ==> [001]    11:115:R
               udevd-11    [001]    27.905506:     11:115:R   + [000]     1:120:D
              <idle>-0     [000]    27.905515:      0:140:R ==> [000]     1:120:R
               udevd-11    [001]    27.905517:     11:115:S ==> [001]     0:140:R
    [   27.905557107] initcall ksysfs_init+0x0/0xb0 returned 0 after 3906 msecs
    [   27.905705736] calling  init_jiffies_clocksource+0x0/0x10 @ 1
    [   27.905779239] initcall init_jiffies_clocksource+0x0/0x10 returned 0 after 0 msecs
    [   27.906769814] calling  pm_init+0x0/0x30 @ 1
    [   27.906853627] initcall pm_init+0x0/0x30 returned 0 after 0 msecs
    [   27.906997803] calling  pm_disk_init+0x0/0x20 @ 1
    [   27.907076946] initcall pm_disk_init+0x0/0x20 returned 0 after 0 msecs
    [   27.907222556] calling  swsusp_header_init+0x0/0x30 @ 1
    [   27.907294325] initcall swsusp_header_init+0x0/0x30 returned 0 after 0 msecs
    [   27.907439620] calling  stop_machine_init+0x0/0x50 @ 1
                init-1     [000]    27.907485:      1:120:R   + [000]     2:115:S
                init-1     [000]    27.907490:      1:120:D ==> [000]     2:115:R
            kthreadd-2     [000]    27.907507:      2:115:R   + [001]    15:115:R
              <idle>-0     [001]    27.907517:      0:140:R ==> [001]    15:115:R
            kthreadd-2     [000]    27.907517:      2:115:D ==> [000]     0:140:R
              <idle>-0     [000]    27.907521:      0:140:R   + [000]     4:115:S
              <idle>-0     [000]    27.907524:      0:140:R ==> [000]     4:115:R
               udevd-15    [001]    27.907527:     15:115:D   + [000]     2:115:D
         ksoftirqd/0-4     [000]    27.907537:      4:115:S ==> [000]     2:115:R
               udevd-15    [001]    27.907537:     15:115:D ==> [001]     0:140:R
            kthreadd-2     [000]    27.907546:      2:115:R   + [000]     1:120:D
            kthreadd-2     [000]    27.907550:      2:115:S ==> [000]     1:120:R
                init-1     [000]    27.907584:      1:120:R   + [000]    15:  0:D
                init-1     [000]    27.907589:      1:120:R   + [000]     2:115:S
                init-1     [000]    27.907593:      1:120:D ==> [000]    15:  0:R
               udevd-15    [000]    27.907601:     15:  0:S ==> [000]     2:115:R
     ##### CPU 0 buffer started ####
            kthreadd-2     [000]    27.907616:      2:115:R   + [001]    16:115:R
     ##### CPU 1 buffer started ####
              <idle>-0     [001]    27.907620:      0:140:R ==> [001]    16:115:R
            kthreadd-2     [000]    27.907621:      2:115:D ==> [000]     0:140:R
               udevd-16    [001]    27.907625:     16:115:D   + [000]     2:115:D
              <idle>-0     [000]    27.907628:      0:140:R   + [000]     4:115:S
               udevd-16    [001]    27.907629:     16:115:D ==> [001]     0:140:R
              <idle>-0     [000]    27.907631:      0:140:R ==> [000]     4:115:R
         ksoftirqd/0-4     [000]    27.907636:      4:115:S ==> [000]     2:115:R
            kthreadd-2     [000]    27.907644:      2:115:R   + [000]     1:120:D
            kthreadd-2     [000]    27.907647:      2:115:S ==> [000]     1:120:R
                init-1     [000]    27.907657:      1:120:R   + [001]    16:  0:D
              <idle>-0     [001]    27.907666:      0:140:R ==> [001]    16:  0:R
    [   27.907703862] initcall stop_machine_init+0x0/0x50 returned 0 after 0 msecs
    [   27.907850704] calling  filelock_init+0x0/0x30 @ 1
    [   27.907926573] initcall filelock_init+0x0/0x30 returned 0 after 0 msecs
    [   27.908071327] calling  init_script_binfmt+0x0/0x10 @ 1
    [   27.908165195] initcall init_script_binfmt+0x0/0x10 returned 0 after 0 msecs
    [   27.908309461] calling  init_elf_binfmt+0x0/0x10 @ 1
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Acked-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 8f71915e8bb4..cb333b7fd113 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -58,35 +58,71 @@ static void boot_trace_init(struct trace_array *tr)
 	tracing_sched_switch_assign_trace(tr);
 }
 
-static enum print_line_t initcall_print_line(struct trace_iterator *iter)
+static enum print_line_t
+initcall_call_print_line(struct trace_iterator *iter)
 {
+	struct trace_entry *entry = iter->ent;
+	struct trace_seq *s = &iter->seq;
+	struct trace_boot_call *field;
+	struct boot_trace_call *call;
+	u64 ts;
+	unsigned long nsec_rem;
 	int ret;
+
+	trace_assign_type(field, entry);
+	call = &field->boot_call;
+	ts = iter->ts;
+	nsec_rem = do_div(ts, 1000000000);
+
+	ret = trace_seq_printf(s, "[%5ld.%09ld] calling  %s @ %i\n",
+			(unsigned long)ts, nsec_rem, call->func, call->caller);
+
+	if (!ret)
+		return TRACE_TYPE_PARTIAL_LINE;
+	else
+		return TRACE_TYPE_HANDLED;
+}
+
+static enum print_line_t
+initcall_ret_print_line(struct trace_iterator *iter)
+{
 	struct trace_entry *entry = iter->ent;
-	struct trace_boot *field = (struct trace_boot *)entry;
-	struct boot_trace *it = &field->initcall;
 	struct trace_seq *s = &iter->seq;
-	struct timespec calltime = ktime_to_timespec(it->calltime);
-	struct timespec rettime = ktime_to_timespec(it->rettime);
-
-	if (entry->type == TRACE_BOOT) {
-		ret = trace_seq_printf(s, "[%5ld.%09ld] calling  %s @ %i\n",
-					  calltime.tv_sec,
-					  calltime.tv_nsec,
-					  it->func, it->caller);
-		if (!ret)
-			return TRACE_TYPE_PARTIAL_LINE;
-
-		ret = trace_seq_printf(s, "[%5ld.%09ld] initcall %s "
-					  "returned %d after %lld msecs\n",
-					  rettime.tv_sec,
-					  rettime.tv_nsec,
-					  it->func, it->result, it->duration);
-
-		if (!ret)
-			return TRACE_TYPE_PARTIAL_LINE;
+	struct trace_boot_ret *field;
+	struct boot_trace_ret *init_ret;
+	u64 ts;
+	unsigned long nsec_rem;
+	int ret;
+
+	trace_assign_type(field, entry);
+	init_ret = &field->boot_ret;
+	ts = iter->ts;
+	nsec_rem = do_div(ts, 1000000000);
+
+	ret = trace_seq_printf(s, "[%5ld.%09ld] initcall %s "
+			"returned %d after %llu msecs\n",
+			(unsigned long) ts,
+			nsec_rem,
+			init_ret->func, init_ret->result, init_ret->duration);
+
+	if (!ret)
+		return TRACE_TYPE_PARTIAL_LINE;
+	else
 		return TRACE_TYPE_HANDLED;
+}
+
+static enum print_line_t initcall_print_line(struct trace_iterator *iter)
+{
+	struct trace_entry *entry = iter->ent;
+
+	switch (entry->type) {
+	case TRACE_BOOT_CALL:
+		return initcall_call_print_line(iter);
+	case TRACE_BOOT_RET:
+		return initcall_ret_print_line(iter);
+	default:
+		return TRACE_TYPE_UNHANDLED;
 	}
-	return TRACE_TYPE_UNHANDLED;
 }
 
 struct tracer boot_tracer __read_mostly =
@@ -97,11 +133,10 @@ struct tracer boot_tracer __read_mostly =
 	.print_line	= initcall_print_line,
 };
 
-void trace_boot(struct boot_trace *it, initcall_t fn)
+void trace_boot_call(struct boot_trace_call *bt, initcall_t fn)
 {
 	struct ring_buffer_event *event;
-	struct trace_boot *entry;
-	struct trace_array_cpu *data;
+	struct trace_boot_call *entry;
 	unsigned long irq_flags;
 	struct trace_array *tr = boot_trace;
 
@@ -111,9 +146,37 @@ void trace_boot(struct boot_trace *it, initcall_t fn)
 	/* Get its name now since this function could
 	 * disappear because it is in the .init section.
 	 */
-	sprint_symbol(it->func, (unsigned long)fn);
+	sprint_symbol(bt->func, (unsigned long)fn);
+	preempt_disable();
+
+	event = ring_buffer_lock_reserve(tr->buffer, sizeof(*entry),
+					 &irq_flags);
+	if (!event)
+		goto out;
+	entry	= ring_buffer_event_data(event);
+	tracing_generic_entry_update(&entry->ent, 0, 0);
+	entry->ent.type = TRACE_BOOT_CALL;
+	entry->boot_call = *bt;
+	ring_buffer_unlock_commit(tr->buffer, event, irq_flags);
+
+	trace_wake_up();
+
+ out:
+	preempt_enable();
+}
+
+void trace_boot_ret(struct boot_trace_ret *bt, initcall_t fn)
+{
+	struct ring_buffer_event *event;
+	struct trace_boot_ret *entry;
+	unsigned long irq_flags;
+	struct trace_array *tr = boot_trace;
+
+	if (!pre_initcalls_finished)
+		return;
+
+	sprint_symbol(bt->func, (unsigned long)fn);
 	preempt_disable();
-	data = tr->data[smp_processor_id()];
 
 	event = ring_buffer_lock_reserve(tr->buffer, sizeof(*entry),
 					 &irq_flags);
@@ -121,8 +184,8 @@ void trace_boot(struct boot_trace *it, initcall_t fn)
 		goto out;
 	entry	= ring_buffer_event_data(event);
 	tracing_generic_entry_update(&entry->ent, 0, 0);
-	entry->ent.type = TRACE_BOOT;
-	entry->initcall = *it;
+	entry->ent.type = TRACE_BOOT_RET;
+	entry->boot_ret = *bt;
 	ring_buffer_unlock_commit(tr->buffer, event, irq_flags);
 
 	trace_wake_up();

commit bbf5b1a0cecb56de6236db8b01c5bfb7ab8ba8b2
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Fri Nov 7 22:36:02 2008 -0500

    ftrace: remove ctrl_update method
    
    Impact: Remove the ctrl_update tracer method
    
    With the new quick start/stop method of tracing, the ctrl_update
    method is out of date.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 0203c1054012..8f71915e8bb4 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -58,14 +58,6 @@ static void boot_trace_init(struct trace_array *tr)
 	tracing_sched_switch_assign_trace(tr);
 }
 
-static void boot_trace_ctrl_update(struct trace_array *tr)
-{
-	if (tr->ctrl)
-		enable_boot_trace();
-	else
-		disable_boot_trace();
-}
-
 static enum print_line_t initcall_print_line(struct trace_iterator *iter)
 {
 	int ret;
@@ -102,7 +94,6 @@ struct tracer boot_tracer __read_mostly =
 	.name		= "initcall",
 	.init		= boot_trace_init,
 	.reset		= reset_boot_trace,
-	.ctrl_update	= boot_trace_ctrl_update,
 	.print_line	= initcall_print_line,
 };
 

commit e168e0516e476070faa9e8e7b23dfcba79b76d82
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Fri Nov 7 22:36:02 2008 -0500

    ftrace: fix sched_switch API
    
    Impact: fix for sched_switch that broke dynamic ftrace startup
    
    The commit: tracing/fastboot: use sched switch tracer from boot tracer
    broke the API of the sched_switch trace. The use of the
    tracing_start/stop_cmdline record is for only recording the cmdline,
    NOT recording the schedule switches themselves.
    
    Seeing that the boot tracer broke the API to do something that it
    wanted, this patch adds a new interface for the API while
    puting back the original interface of the old API.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>
    Acked-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 662cb9198906..0203c1054012 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -28,13 +28,13 @@ void start_boot_trace(void)
 void enable_boot_trace(void)
 {
 	if (pre_initcalls_finished)
-		tracing_start_cmdline_record();
+		tracing_start_sched_switch_record();
 }
 
 void disable_boot_trace(void)
 {
 	if (pre_initcalls_finished)
-		tracing_stop_cmdline_record();
+		tracing_stop_sched_switch_record();
 }
 
 static void reset_boot_trace(struct trace_array *tr)
@@ -55,7 +55,7 @@ static void boot_trace_init(struct trace_array *tr)
 	for_each_cpu_mask(cpu, cpu_possible_map)
 		tracing_reset(tr, cpu);
 
-	tracing_cmdline_assign_trace(tr);
+	tracing_sched_switch_assign_trace(tr);
 }
 
 static void boot_trace_ctrl_update(struct trace_array *tr)

commit 75f5c47da386445ba0c5a8b7e3ca0c906e763369
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Fri Nov 7 22:36:02 2008 -0500

    ftrace: fix boot trace sched startup
    
    Impact: boot tracer startup modified
    
    The boot tracer calls into some of the schedule tracing private functions
    that should not be exported. This patch cleans it up, and makes
    way for further changes in the ftrace infrastructure.
    
    This patch adds a api to assign a tracer array to the schedule
    context switch tracer.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>
    Acked-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index bd5046c9deb7..662cb9198906 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -39,7 +39,12 @@ void disable_boot_trace(void)
 
 static void reset_boot_trace(struct trace_array *tr)
 {
-	sched_switch_trace.reset(tr);
+	int cpu;
+
+	tr->time_start = ftrace_now(tr->cpu);
+
+	for_each_online_cpu(cpu)
+		tracing_reset(tr, cpu);
 }
 
 static void boot_trace_init(struct trace_array *tr)
@@ -50,7 +55,7 @@ static void boot_trace_init(struct trace_array *tr)
 	for_each_cpu_mask(cpu, cpu_possible_map)
 		tracing_reset(tr, cpu);
 
-	sched_switch_trace.init(tr);
+	tracing_cmdline_assign_trace(tr);
 }
 
 static void boot_trace_ctrl_update(struct trace_array *tr)

commit 79a9d461fd521f133f0e66485aa9ed09c21f5191
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Fri Oct 31 13:34:45 2008 +0100

    tracing/ftrace: fix a bug when switch current tracer to sched tracer
    
    Impact: fix boot tracer + sched tracer coupling bug
    
    Fix a bug that made the sched_switch tracer unable to run
    if set as the current_tracer after the boot tracer.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 6bbc8794a6df..bd5046c9deb7 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -37,9 +37,9 @@ void disable_boot_trace(void)
 		tracing_stop_cmdline_record();
 }
 
-void reset_boot_trace(struct trace_array *tr)
+static void reset_boot_trace(struct trace_array *tr)
 {
-	disable_boot_trace();
+	sched_switch_trace.reset(tr);
 }
 
 static void boot_trace_init(struct trace_array *tr)

commit d7ad44b697c9d13e445ddc7d16f736fbac333249
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Fri Oct 31 13:20:08 2008 +0100

    tracing/fastboot: use sched switch tracer from boot tracer
    
    Impact: enhance boot trace output with scheduling events
    
    Use the sched_switch tracer from the boot tracer.
    
    We also can trace schedule events inside the initcalls.
    Sched tracing is disabled after the initcall has finished and
    then reenabled before the next one is started.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index d104d5b46413..6bbc8794a6df 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -27,10 +27,14 @@ void start_boot_trace(void)
 
 void enable_boot_trace(void)
 {
+	if (pre_initcalls_finished)
+		tracing_start_cmdline_record();
 }
 
 void disable_boot_trace(void)
 {
+	if (pre_initcalls_finished)
+		tracing_stop_cmdline_record();
 }
 
 void reset_boot_trace(struct trace_array *tr)
@@ -45,6 +49,8 @@ static void boot_trace_init(struct trace_array *tr)
 
 	for_each_cpu_mask(cpu, cpu_possible_map)
 		tracing_reset(tr, cpu);
+
+	sched_switch_trace.init(tr);
 }
 
 static void boot_trace_ctrl_update(struct trace_array *tr)

commit 71566a0d161edec70361b7f90f6e54af6a6d5d05
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Fri Oct 31 12:57:20 2008 +0100

    tracing/fastboot: Enable boot tracing only during initcalls
    
    Impact: modify boot tracer
    
    We used to disable the initcall tracing at a specified time (IE: end
    of builtin initcalls). But we don't need it anymore. It will be
    stopped when initcalls are finished.
    
    However we want two things:
    
    _Start this tracing only after pre-smp initcalls are finished.
    
    _Since we are planning to trace sched_switches at the same time, we
    want to enable them only during the initcall execution.
    
    For this purpose, this patch introduce two functions to enable/disable
    the sched_switch tracing during boot.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index d0a5e50eeff2..d104d5b46413 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -13,23 +13,29 @@
 #include "trace.h"
 
 static struct trace_array *boot_trace;
-static int trace_boot_enabled;
+static bool pre_initcalls_finished;
 
-
-/* Should be started after do_pre_smp_initcalls() in init/main.c */
+/* Tells the boot tracer that the pre_smp_initcalls are finished.
+ * So we are ready .
+ * It doesn't enable sched events tracing however.
+ * You have to call enable_boot_trace to do so.
+ */
 void start_boot_trace(void)
 {
-	trace_boot_enabled = 1;
+	pre_initcalls_finished = true;
+}
+
+void enable_boot_trace(void)
+{
 }
 
-void stop_boot_trace(void)
+void disable_boot_trace(void)
 {
-	trace_boot_enabled = 0;
 }
 
 void reset_boot_trace(struct trace_array *tr)
 {
-	stop_boot_trace();
+	disable_boot_trace();
 }
 
 static void boot_trace_init(struct trace_array *tr)
@@ -37,8 +43,6 @@ static void boot_trace_init(struct trace_array *tr)
 	int cpu;
 	boot_trace = tr;
 
-	trace_boot_enabled = 0;
-
 	for_each_cpu_mask(cpu, cpu_possible_map)
 		tracing_reset(tr, cpu);
 }
@@ -46,9 +50,9 @@ static void boot_trace_init(struct trace_array *tr)
 static void boot_trace_ctrl_update(struct trace_array *tr)
 {
 	if (tr->ctrl)
-		start_boot_trace();
+		enable_boot_trace();
 	else
-		stop_boot_trace();
+		disable_boot_trace();
 }
 
 static enum print_line_t initcall_print_line(struct trace_iterator *iter)
@@ -99,7 +103,7 @@ void trace_boot(struct boot_trace *it, initcall_t fn)
 	unsigned long irq_flags;
 	struct trace_array *tr = boot_trace;
 
-	if (!trace_boot_enabled)
+	if (!pre_initcalls_finished)
 		return;
 
 	/* Get its name now since this function could

commit 8a5d900cca57115326bc5b9e7f3bac980986c2c8
Author: Arjan van de Ven <arjan@infradead.org>
Date:   Sat Oct 4 13:42:27 2008 -0700

    tracing/fastboot: fix printk format typo in boot tracer
    
    When printing nanoseconds, the right printk format string is %09 not %06...
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Acked-by: Frédéric Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index a7efe3559654..d0a5e50eeff2 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -62,14 +62,14 @@ static enum print_line_t initcall_print_line(struct trace_iterator *iter)
 	struct timespec rettime = ktime_to_timespec(it->rettime);
 
 	if (entry->type == TRACE_BOOT) {
-		ret = trace_seq_printf(s, "[%5ld.%06ld] calling  %s @ %i\n",
+		ret = trace_seq_printf(s, "[%5ld.%09ld] calling  %s @ %i\n",
 					  calltime.tv_sec,
 					  calltime.tv_nsec,
 					  it->func, it->caller);
 		if (!ret)
 			return TRACE_TYPE_PARTIAL_LINE;
 
-		ret = trace_seq_printf(s, "[%5ld.%06ld] initcall %s "
+		ret = trace_seq_printf(s, "[%5ld.%09ld] initcall %s "
 					  "returned %d after %lld msecs\n",
 					  rettime.tv_sec,
 					  rettime.tv_nsec,

commit 097d036a2f25eecc42435c57e010aaf4a2eed2d9
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Fri Oct 3 15:39:21 2008 +0200

    tracing/fastboot: only trace non-module initcalls
    
    At this time, only built-in initcalls interest us.
    We can't really produce a relevant graph if we include
    the modules initcall too.
    
    I had good results after this patch (see svg in attachment).
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index b9dc2c0093ab..a7efe3559654 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -22,11 +22,16 @@ void start_boot_trace(void)
 	trace_boot_enabled = 1;
 }
 
-void stop_boot_trace(struct trace_array *tr)
+void stop_boot_trace(void)
 {
 	trace_boot_enabled = 0;
 }
 
+void reset_boot_trace(struct trace_array *tr)
+{
+	stop_boot_trace();
+}
+
 static void boot_trace_init(struct trace_array *tr)
 {
 	int cpu;
@@ -43,7 +48,7 @@ static void boot_trace_ctrl_update(struct trace_array *tr)
 	if (tr->ctrl)
 		start_boot_trace();
 	else
-		stop_boot_trace(tr);
+		stop_boot_trace();
 }
 
 static enum print_line_t initcall_print_line(struct trace_iterator *iter)
@@ -81,7 +86,7 @@ struct tracer boot_tracer __read_mostly =
 {
 	.name		= "initcall",
 	.init		= boot_trace_init,
-	.reset		= stop_boot_trace,
+	.reset		= reset_boot_trace,
 	.ctrl_update	= boot_trace_ctrl_update,
 	.print_line	= initcall_print_line,
 };

commit 5601020feb0c3010e9e3e0131e9697ac6a06777b
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Oct 2 13:26:05 2008 +0200

    tracing/fastboot: get the initcall name before it disappears
    
    After some initcall traces, some initcall names may be inconsistent.
    That's because these functions will disappear from the .init section
    and also their name from the symbols table.
    
    So we have to copy the name of the function in a buffer large enough
    during the trace appending. It is not costly for the ring_buffer because
    the number of initcall entries is commonly not really large.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 7c15f3e68ba3..b9dc2c0093ab 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -8,6 +8,7 @@
 #include <linux/init.h>
 #include <linux/debugfs.h>
 #include <linux/ftrace.h>
+#include <linux/kallsyms.h>
 
 #include "trace.h"
 
@@ -56,17 +57,19 @@ static enum print_line_t initcall_print_line(struct trace_iterator *iter)
 	struct timespec rettime = ktime_to_timespec(it->rettime);
 
 	if (entry->type == TRACE_BOOT) {
-		ret = trace_seq_printf(s, "[%5ld.%06ld] calling  %pF @ %i\n",
+		ret = trace_seq_printf(s, "[%5ld.%06ld] calling  %s @ %i\n",
 					  calltime.tv_sec,
 					  calltime.tv_nsec,
 					  it->func, it->caller);
 		if (!ret)
 			return TRACE_TYPE_PARTIAL_LINE;
-		ret = trace_seq_printf(s, "[%5ld.%06ld] initcall %pF "
+
+		ret = trace_seq_printf(s, "[%5ld.%06ld] initcall %s "
 					  "returned %d after %lld msecs\n",
 					  rettime.tv_sec,
 					  rettime.tv_nsec,
 					  it->func, it->result, it->duration);
+
 		if (!ret)
 			return TRACE_TYPE_PARTIAL_LINE;
 		return TRACE_TYPE_HANDLED;
@@ -83,8 +86,7 @@ struct tracer boot_tracer __read_mostly =
 	.print_line	= initcall_print_line,
 };
 
-
-void trace_boot(struct boot_trace *it)
+void trace_boot(struct boot_trace *it, initcall_t fn)
 {
 	struct ring_buffer_event *event;
 	struct trace_boot *entry;
@@ -95,6 +97,10 @@ void trace_boot(struct boot_trace *it)
 	if (!trace_boot_enabled)
 		return;
 
+	/* Get its name now since this function could
+	 * disappear because it is in the .init section.
+	 */
+	sprint_symbol(it->func, (unsigned long)fn);
 	preempt_disable();
 	data = tr->data[smp_processor_id()];
 

commit cb5ab74204a6e2579d1119bf1348eb806526b12b
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Oct 2 12:59:20 2008 +0200

    tracing/fastboot: change the printing of boot tracer according to bootgraph.pl
    
    Change the boot tracer printing to make it parsable for
    the scripts/bootgraph.pl script.
    
    We have now to output two lines for each initcall, according to the
    printk in do_one_initcall() in init/main.c
    We need now the call's time and the return's time.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index f2dac6f1cf06..7c15f3e68ba3 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -52,16 +52,24 @@ static enum print_line_t initcall_print_line(struct trace_iterator *iter)
 	struct trace_boot *field = (struct trace_boot *)entry;
 	struct boot_trace *it = &field->initcall;
 	struct trace_seq *s = &iter->seq;
+	struct timespec calltime = ktime_to_timespec(it->calltime);
+	struct timespec rettime = ktime_to_timespec(it->rettime);
 
 	if (entry->type == TRACE_BOOT) {
-		ret = trace_seq_printf(s, "%pF called from %i "
-				       "returned %d after %lld msecs\n",
-				       it->func, it->caller, it->result,
-				       it->duration);
-		if (ret)
-			return TRACE_TYPE_HANDLED;
-		else
+		ret = trace_seq_printf(s, "[%5ld.%06ld] calling  %pF @ %i\n",
+					  calltime.tv_sec,
+					  calltime.tv_nsec,
+					  it->func, it->caller);
+		if (!ret)
 			return TRACE_TYPE_PARTIAL_LINE;
+		ret = trace_seq_printf(s, "[%5ld.%06ld] initcall %pF "
+					  "returned %d after %lld msecs\n",
+					  rettime.tv_sec,
+					  rettime.tv_nsec,
+					  it->func, it->result, it->duration);
+		if (!ret)
+			return TRACE_TYPE_PARTIAL_LINE;
+		return TRACE_TYPE_HANDLED;
 	}
 	return TRACE_TYPE_UNHANDLED;
 }

commit 38697053fa006411224a1790e2adb8216440ab0f
Author: Steven Rostedt <rostedt@goodmis.org>
Date:   Wed Oct 1 13:14:09 2008 -0400

    ftrace: preempt disable over interrupt disable
    
    With the new ring buffer infrastructure in ftrace, I'm trying to make
    ftrace a little more light weight.
    
    This patch converts a lot of the local_irq_save/restore into
    preempt_disable/enable.  The original preempt count in a lot of cases
    has to be sent in as a parameter so that it can be recorded correctly.
    Some places were recording it incorrectly before anyway.
    
    This is also laying the ground work to make ftrace a little bit
    more reentrant, and remove all locking. The function tracers must
    still protect from reentrancy.
    
    Note: All the function tracers must be careful when using preempt_disable.
      It must do the following:
    
      resched = need_resched();
      preempt_disable_notrace();
      [...]
      if (resched)
            preempt_enable_no_resched_notrace();
      else
            preempt_enable_notrace();
    
    The reason is that if this function traces schedule() itself, the
    preempt_enable_notrace() will cause a schedule, which will lead
    us into a recursive failure.
    
    If we needed to reschedule before calling preempt_disable, we
    should have already scheduled. Since we did not, this is most
    likely that we should not and are probably inside a schedule
    function.
    
    If resched was not set, we still need to catch the need resched
    flag being set when preemption was off and the if case at the
    end will catch that for us.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 43bde20b95bd..f2dac6f1cf06 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -95,7 +95,7 @@ void trace_boot(struct boot_trace *it)
 	if (!event)
 		goto out;
 	entry	= ring_buffer_event_data(event);
-	tracing_generic_entry_update(&entry->ent, 0);
+	tracing_generic_entry_update(&entry->ent, 0, 0);
 	entry->ent.type = TRACE_BOOT;
 	entry->initcall = *it;
 	ring_buffer_unlock_commit(tr->buffer, event, irq_flags);

commit 9e9efffb7848fe53c334996819139b431b983ac2
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Mon Sep 29 20:31:58 2008 +0200

    tracing/ftrace: adapt the boot tracer to the new print_line type
    
    This patch adapts the boot tracer to the new type of the
    print_line callback.
    
    It still relays entries it doesn't support to default output
    functions.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Acked-by: Pekka Paalanen <pq@iki.fi>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index fa8cca1be115..43bde20b95bd 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -45,22 +45,25 @@ static void boot_trace_ctrl_update(struct trace_array *tr)
 		stop_boot_trace(tr);
 }
 
-static int initcall_print_line(struct trace_iterator *iter)
+static enum print_line_t initcall_print_line(struct trace_iterator *iter)
 {
-	int ret = 0;
+	int ret;
 	struct trace_entry *entry = iter->ent;
 	struct trace_boot *field = (struct trace_boot *)entry;
 	struct boot_trace *it = &field->initcall;
 	struct trace_seq *s = &iter->seq;
 
-	if (entry->type == TRACE_BOOT)
+	if (entry->type == TRACE_BOOT) {
 		ret = trace_seq_printf(s, "%pF called from %i "
 				       "returned %d after %lld msecs\n",
 				       it->func, it->caller, it->result,
 				       it->duration);
-	if (ret)
-		return 1;
-	return 0;
+		if (ret)
+			return TRACE_TYPE_HANDLED;
+		else
+			return TRACE_TYPE_PARTIAL_LINE;
+	}
+	return TRACE_TYPE_UNHANDLED;
 }
 
 struct tracer boot_tracer __read_mostly =

commit 777e208d40d0953efc6fb4ab58590da3f7d8f02d
Author: Steven Rostedt <rostedt@goodmis.org>
Date:   Mon Sep 29 23:02:42 2008 -0400

    ftrace: take advantage of variable length entries
    
    Now that the underlining ring buffer for ftrace now hold variable length
    entries, we can take advantage of this by only storing the size of the
    actual event into the buffer. This happens to increase the number of
    entries in the buffer dramatically.
    
    We can also get rid of the "trace_cont" operation, but I'm keeping that
    until we have no more users. Some of the ftrace tracers can now change
    their code to adapt to this new feature.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index 3657eec6b87d..fa8cca1be115 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -49,10 +49,11 @@ static int initcall_print_line(struct trace_iterator *iter)
 {
 	int ret = 0;
 	struct trace_entry *entry = iter->ent;
-	struct boot_trace *it = &entry->field.initcall;
+	struct trace_boot *field = (struct trace_boot *)entry;
+	struct boot_trace *it = &field->initcall;
 	struct trace_seq *s = &iter->seq;
 
-	if (iter->ent->type == TRACE_BOOT)
+	if (entry->type == TRACE_BOOT)
 		ret = trace_seq_printf(s, "%pF called from %i "
 				       "returned %d after %lld msecs\n",
 				       it->func, it->caller, it->result,
@@ -75,7 +76,7 @@ struct tracer boot_tracer __read_mostly =
 void trace_boot(struct boot_trace *it)
 {
 	struct ring_buffer_event *event;
-	struct trace_entry *entry;
+	struct trace_boot *entry;
 	struct trace_array_cpu *data;
 	unsigned long irq_flags;
 	struct trace_array *tr = boot_trace;
@@ -91,9 +92,9 @@ void trace_boot(struct boot_trace *it)
 	if (!event)
 		goto out;
 	entry	= ring_buffer_event_data(event);
-	tracing_generic_entry_update(entry, 0);
-	entry->type = TRACE_BOOT;
-	entry->field.initcall = *it;
+	tracing_generic_entry_update(&entry->ent, 0);
+	entry->ent.type = TRACE_BOOT;
+	entry->initcall = *it;
 	ring_buffer_unlock_commit(tr->buffer, event, irq_flags);
 
 	trace_wake_up();

commit 3928a8a2d98081d1bc3c0a84a2d70e29b90ecf1c
Author: Steven Rostedt <rostedt@goodmis.org>
Date:   Mon Sep 29 23:02:41 2008 -0400

    ftrace: make work with new ring buffer
    
    This patch ports ftrace over to the new ring buffer.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index d5c9e2e4a9c4..3657eec6b87d 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -34,7 +34,7 @@ static void boot_trace_init(struct trace_array *tr)
 	trace_boot_enabled = 0;
 
 	for_each_cpu_mask(cpu, cpu_possible_map)
-		tracing_reset(tr->data[cpu]);
+		tracing_reset(tr, cpu);
 }
 
 static void boot_trace_ctrl_update(struct trace_array *tr)
@@ -74,6 +74,7 @@ struct tracer boot_tracer __read_mostly =
 
 void trace_boot(struct boot_trace *it)
 {
+	struct ring_buffer_event *event;
 	struct trace_entry *entry;
 	struct trace_array_cpu *data;
 	unsigned long irq_flags;
@@ -85,17 +86,18 @@ void trace_boot(struct boot_trace *it)
 	preempt_disable();
 	data = tr->data[smp_processor_id()];
 
-	raw_local_irq_save(irq_flags);
-	__raw_spin_lock(&data->lock);
-
-	entry = tracing_get_trace_entry(tr, data);
+	event = ring_buffer_lock_reserve(tr->buffer, sizeof(*entry),
+					 &irq_flags);
+	if (!event)
+		goto out;
+	entry	= ring_buffer_event_data(event);
 	tracing_generic_entry_update(entry, 0);
 	entry->type = TRACE_BOOT;
 	entry->field.initcall = *it;
+	ring_buffer_unlock_commit(tr->buffer, event, irq_flags);
 
-	__raw_spin_unlock(&data->lock);
-	raw_local_irq_restore(irq_flags);
 	trace_wake_up();
 
+ out:
 	preempt_enable();
 }

commit 7c572ac0cf5e8cd8e17f084bc6c253296cc42279
Author: Frédéric Weisbecker <fweisbec@gmail.com>
Date:   Thu Sep 25 13:25:30 2008 +0100

    tracing/ftrace: don't consume unhandled entries by boot tracer
    
    When the boot tracer can't handle an entry output, it returns 1.
    It should return 0 to relay on other output functions.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
index c65ef8ffd6b4..d5c9e2e4a9c4 100644
--- a/kernel/trace/trace_boot.c
+++ b/kernel/trace/trace_boot.c
@@ -47,7 +47,7 @@ static void boot_trace_ctrl_update(struct trace_array *tr)
 
 static int initcall_print_line(struct trace_iterator *iter)
 {
-	int ret = 1;
+	int ret = 0;
 	struct trace_entry *entry = iter->ent;
 	struct boot_trace *it = &entry->field.initcall;
 	struct trace_seq *s = &iter->seq;

commit d13744cd6e3fef373a3fe656ac349b4e7c49ff79
Author: Frédéric Weisbecker <fweisbec@gmail.com>
Date:   Tue Sep 23 11:32:08 2008 +0100

    tracing/ftrace: add the boot tracer
    
    Add the boot/initcall tracer.
    
    It's primary purpose is to be able to trace the initcalls.
    
    It is intended to be used with scripts/bootgraph.pl after some small
    improvements.
    
    Note that it is not active after its init. To avoid tracing (and so
    crashing) before the whole tracing engine init, you have to explicitly
    call start_boot_trace() after do_pre_smp_initcalls() to enable it.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/kernel/trace/trace_boot.c b/kernel/trace/trace_boot.c
new file mode 100644
index 000000000000..c65ef8ffd6b4
--- /dev/null
+++ b/kernel/trace/trace_boot.c
@@ -0,0 +1,101 @@
+/*
+ * ring buffer based initcalls tracer
+ *
+ * Copyright (C) 2008 Frederic Weisbecker <fweisbec@gmail.com>
+ *
+ */
+
+#include <linux/init.h>
+#include <linux/debugfs.h>
+#include <linux/ftrace.h>
+
+#include "trace.h"
+
+static struct trace_array *boot_trace;
+static int trace_boot_enabled;
+
+
+/* Should be started after do_pre_smp_initcalls() in init/main.c */
+void start_boot_trace(void)
+{
+	trace_boot_enabled = 1;
+}
+
+void stop_boot_trace(struct trace_array *tr)
+{
+	trace_boot_enabled = 0;
+}
+
+static void boot_trace_init(struct trace_array *tr)
+{
+	int cpu;
+	boot_trace = tr;
+
+	trace_boot_enabled = 0;
+
+	for_each_cpu_mask(cpu, cpu_possible_map)
+		tracing_reset(tr->data[cpu]);
+}
+
+static void boot_trace_ctrl_update(struct trace_array *tr)
+{
+	if (tr->ctrl)
+		start_boot_trace();
+	else
+		stop_boot_trace(tr);
+}
+
+static int initcall_print_line(struct trace_iterator *iter)
+{
+	int ret = 1;
+	struct trace_entry *entry = iter->ent;
+	struct boot_trace *it = &entry->field.initcall;
+	struct trace_seq *s = &iter->seq;
+
+	if (iter->ent->type == TRACE_BOOT)
+		ret = trace_seq_printf(s, "%pF called from %i "
+				       "returned %d after %lld msecs\n",
+				       it->func, it->caller, it->result,
+				       it->duration);
+	if (ret)
+		return 1;
+	return 0;
+}
+
+struct tracer boot_tracer __read_mostly =
+{
+	.name		= "initcall",
+	.init		= boot_trace_init,
+	.reset		= stop_boot_trace,
+	.ctrl_update	= boot_trace_ctrl_update,
+	.print_line	= initcall_print_line,
+};
+
+
+void trace_boot(struct boot_trace *it)
+{
+	struct trace_entry *entry;
+	struct trace_array_cpu *data;
+	unsigned long irq_flags;
+	struct trace_array *tr = boot_trace;
+
+	if (!trace_boot_enabled)
+		return;
+
+	preempt_disable();
+	data = tr->data[smp_processor_id()];
+
+	raw_local_irq_save(irq_flags);
+	__raw_spin_lock(&data->lock);
+
+	entry = tracing_get_trace_entry(tr, data);
+	tracing_generic_entry_update(entry, 0);
+	entry->type = TRACE_BOOT;
+	entry->field.initcall = *it;
+
+	__raw_spin_unlock(&data->lock);
+	raw_local_irq_restore(irq_flags);
+	trace_wake_up();
+
+	preempt_enable();
+}
