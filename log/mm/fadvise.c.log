commit 9a42823a102eb10dd1cc09930dc7e20042698e23
Author: Matthew Wilcox (Oracle) <willy@infradead.org>
Date:   Mon Jun 1 21:46:10 2020 -0700

    mm: return void from various readahead functions
    
    ondemand_readahead has two callers, neither of which use the return
    value.  That means that both ra_submit and __do_page_cache_readahead()
    can return void, and we don't need to worry that a present page in the
    readahead window causes us to return a smaller nr_pages than we ought to
    have.
    
    Similarly, no caller uses the return value from
    force_page_cache_readahead().
    
    Signed-off-by: Matthew Wilcox (Oracle) <willy@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Dave Chinner <dchinner@redhat.com>
    Reviewed-by: John Hubbard <jhubbard@nvidia.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: William Kucharski <william.kucharski@oracle.com>
    Cc: Chao Yu <yuchao0@huawei.com>
    Cc: Cong Wang <xiyou.wangcong@gmail.com>
    Cc: Darrick J. Wong <darrick.wong@oracle.com>
    Cc: Eric Biggers <ebiggers@google.com>
    Cc: Gao Xiang <gaoxiang25@huawei.com>
    Cc: Jaegeuk Kim <jaegeuk@kernel.org>
    Cc: Joseph Qi <joseph.qi@linux.alibaba.com>
    Cc: Junxiao Bi <junxiao.bi@oracle.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Cc: Miklos Szeredi <mszeredi@redhat.com>
    Link: http://lkml.kernel.org/r/20200414150233.24495-3-willy@infradead.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 3efebfb9952c..0e66f2aaeea3 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -104,10 +104,6 @@ int generic_fadvise(struct file *file, loff_t offset, loff_t len, int advice)
 		if (!nrpages)
 			nrpages = ~0UL;
 
-		/*
-		 * Ignore return value because fadvise() shall return
-		 * success even if filesystem can't retrieve a hint,
-		 */
 		force_page_cache_readahead(mapping, file, start_index, nrpages);
 		break;
 	case POSIX_FADV_NOREUSE:

commit cee9a0c4e84db024d692d6b5c18f65465eb06905
Author: Matthew Wilcox (Oracle) <willy@infradead.org>
Date:   Mon Jun 1 21:46:07 2020 -0700

    mm: move readahead prototypes from mm.h
    
    Patch series "Change readahead API", v11.
    
    This series adds a readahead address_space operation to replace the
    readpages operation.  The key difference is that pages are added to the
    page cache as they are allocated (and then looked up by the filesystem)
    instead of passing them on a list to the readpages operation and having
    the filesystem add them to the page cache.  It's a net reduction in code
    for each implementation, more efficient than walking a list, and solves
    the direct-write vs buffered-read problem reported by yu kuai at
    http://lkml.kernel.org/r/20200116063601.39201-1-yukuai3@huawei.com
    
    The only unconverted filesystems are those which use fscache.  Their
    conversion is pending Dave Howells' rewrite which will make the
    conversion substantially easier.  This should be completed by the end of
    the year.
    
    I want to thank the reviewers/testers; Dave Chinner, John Hubbard, Eric
    Biggers, Johannes Thumshirn, Dave Sterba, Zi Yan, Christoph Hellwig and
    Miklos Szeredi have done a marvellous job of providing constructive
    criticism.
    
    These patches pass an xfstests run on ext4, xfs & btrfs with no
    regressions that I can tell (some of the tests seem a little flaky
    before and remain flaky afterwards).
    
    This patch (of 25):
    
    The readahead code is part of the page cache so should be found in the
    pagemap.h file.  force_page_cache_readahead is only used within mm, so
    move it to mm/internal.h instead.  Remove the parameter names where they
    add no value, and rename the ones which were actively misleading.
    
    Signed-off-by: Matthew Wilcox (Oracle) <willy@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: John Hubbard <jhubbard@nvidia.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: William Kucharski <william.kucharski@oracle.com>
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Cc: Chao Yu <yuchao0@huawei.com>
    Cc: Cong Wang <xiyou.wangcong@gmail.com>
    Cc: Darrick J. Wong <darrick.wong@oracle.com>
    Cc: Dave Chinner <dchinner@redhat.com>
    Cc: Eric Biggers <ebiggers@google.com>
    Cc: Gao Xiang <gaoxiang25@huawei.com>
    Cc: Jaegeuk Kim <jaegeuk@kernel.org>
    Cc: Joseph Qi <joseph.qi@linux.alibaba.com>
    Cc: Junxiao Bi <junxiao.bi@oracle.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: Miklos Szeredi <mszeredi@redhat.com>
    Link: http://lkml.kernel.org/r/20200414150233.24495-1-willy@infradead.org
    Link: http://lkml.kernel.org/r/20200414150233.24495-2-willy@infradead.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 4f17c83db575..3efebfb9952c 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -22,6 +22,8 @@
 
 #include <asm/unistd.h>
 
+#include "internal.h"
+
 /*
  * POSIX_FADV_WILLNEED could set PG_Referenced, and POSIX_FADV_NOREUSE could
  * deactivate the pages and clear PG_Referenced.

commit cf1ea0592dbf109e7e7935b7d5b1a47a1ba04174
Author: Jan Kara <jack@suse.cz>
Date:   Thu Aug 29 09:04:11 2019 -0700

    fs: Export generic_fadvise()
    
    Filesystems will need to call this function from their fadvise handlers.
    
    CC: stable@vger.kernel.org
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 467bcd032037..4f17c83db575 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -27,8 +27,7 @@
  * deactivate the pages and clear PG_Referenced.
  */
 
-static int generic_fadvise(struct file *file, loff_t offset, loff_t len,
-			   int advice)
+int generic_fadvise(struct file *file, loff_t offset, loff_t len, int advice)
 {
 	struct inode *inode;
 	struct address_space *mapping;
@@ -178,6 +177,7 @@ static int generic_fadvise(struct file *file, loff_t offset, loff_t len,
 	}
 	return 0;
 }
+EXPORT_SYMBOL(generic_fadvise);
 
 int vfs_fadvise(struct file *file, loff_t offset, loff_t len, int advice)
 {

commit 3d8f7615319b2bca87a4815e13787439e3339a93
Author: Amir Goldstein <amir73il@gmail.com>
Date:   Wed Aug 29 08:41:29 2018 +0300

    vfs: implement readahead(2) using POSIX_FADV_WILLNEED
    
    The implementation of readahead(2) syscall is identical to that of
    fadvise64(POSIX_FADV_WILLNEED) with a few exceptions:
    1. readahead(2) returns -EINVAL for !mapping->a_ops and fadvise64()
       ignores the request and returns 0.
    2. fadvise64() checks for integer overflow corner case
    3. fadvise64() calls the optional filesystem fadvise() file operation
    
    Unite the two implementations by calling vfs_fadvise() from readahead(2)
    syscall. Check the !mapping->a_ops in readahead(2) syscall to preserve
    documented syscall ABI behaviour.
    
    Suggested-by: Miklos Szeredi <mszeredi@redhat.com>
    Fixes: d1d04ef8572b ("ovl: stack file ops")
    Signed-off-by: Amir Goldstein <amir73il@gmail.com>
    Signed-off-by: Miklos Szeredi <mszeredi@redhat.com>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 2f59bac1cb77..467bcd032037 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -188,6 +188,8 @@ int vfs_fadvise(struct file *file, loff_t offset, loff_t len, int advice)
 }
 EXPORT_SYMBOL(vfs_fadvise);
 
+#ifdef CONFIG_ADVISE_SYSCALLS
+
 int ksys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 {
 	struct fd f = fdget(fd);
@@ -215,3 +217,4 @@ SYSCALL_DEFINE4(fadvise64, int, fd, loff_t, offset, size_t, len, int, advice)
 }
 
 #endif
+#endif

commit 45cd0faae3715e305bc46e23b34c5ed4d185ceb8
Author: Amir Goldstein <amir73il@gmail.com>
Date:   Mon Aug 27 15:56:02 2018 +0300

    vfs: add the fadvise() file operation
    
    This is going to be used by overlayfs and possibly useful
    for other filesystems.
    
    Signed-off-by: Amir Goldstein <amir73il@gmail.com>
    Signed-off-by: Miklos Szeredi <mszeredi@redhat.com>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 2d8376e3c640..2f59bac1cb77 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -27,9 +27,9 @@
  * deactivate the pages and clear PG_Referenced.
  */
 
-int ksys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
+static int generic_fadvise(struct file *file, loff_t offset, loff_t len,
+			   int advice)
 {
-	struct fd f = fdget(fd);
 	struct inode *inode;
 	struct address_space *mapping;
 	struct backing_dev_info *bdi;
@@ -37,22 +37,14 @@ int ksys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 	pgoff_t start_index;
 	pgoff_t end_index;
 	unsigned long nrpages;
-	int ret = 0;
 
-	if (!f.file)
-		return -EBADF;
+	inode = file_inode(file);
+	if (S_ISFIFO(inode->i_mode))
+		return -ESPIPE;
 
-	inode = file_inode(f.file);
-	if (S_ISFIFO(inode->i_mode)) {
-		ret = -ESPIPE;
-		goto out;
-	}
-
-	mapping = f.file->f_mapping;
-	if (!mapping || len < 0) {
-		ret = -EINVAL;
-		goto out;
-	}
+	mapping = file->f_mapping;
+	if (!mapping || len < 0)
+		return -EINVAL;
 
 	bdi = inode_to_bdi(mapping->host);
 
@@ -67,9 +59,9 @@ int ksys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 			/* no bad return value, but ignore advice */
 			break;
 		default:
-			ret = -EINVAL;
+			return -EINVAL;
 		}
-		goto out;
+		return 0;
 	}
 
 	/*
@@ -85,21 +77,21 @@ int ksys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 
 	switch (advice) {
 	case POSIX_FADV_NORMAL:
-		f.file->f_ra.ra_pages = bdi->ra_pages;
-		spin_lock(&f.file->f_lock);
-		f.file->f_mode &= ~FMODE_RANDOM;
-		spin_unlock(&f.file->f_lock);
+		file->f_ra.ra_pages = bdi->ra_pages;
+		spin_lock(&file->f_lock);
+		file->f_mode &= ~FMODE_RANDOM;
+		spin_unlock(&file->f_lock);
 		break;
 	case POSIX_FADV_RANDOM:
-		spin_lock(&f.file->f_lock);
-		f.file->f_mode |= FMODE_RANDOM;
-		spin_unlock(&f.file->f_lock);
+		spin_lock(&file->f_lock);
+		file->f_mode |= FMODE_RANDOM;
+		spin_unlock(&file->f_lock);
 		break;
 	case POSIX_FADV_SEQUENTIAL:
-		f.file->f_ra.ra_pages = bdi->ra_pages * 2;
-		spin_lock(&f.file->f_lock);
-		f.file->f_mode &= ~FMODE_RANDOM;
-		spin_unlock(&f.file->f_lock);
+		file->f_ra.ra_pages = bdi->ra_pages * 2;
+		spin_lock(&file->f_lock);
+		file->f_mode &= ~FMODE_RANDOM;
+		spin_unlock(&file->f_lock);
 		break;
 	case POSIX_FADV_WILLNEED:
 		/* First and last PARTIAL page! */
@@ -115,8 +107,7 @@ int ksys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 		 * Ignore return value because fadvise() shall return
 		 * success even if filesystem can't retrieve a hint,
 		 */
-		force_page_cache_readahead(mapping, f.file, start_index,
-					   nrpages);
+		force_page_cache_readahead(mapping, file, start_index, nrpages);
 		break;
 	case POSIX_FADV_NOREUSE:
 		break;
@@ -183,9 +174,30 @@ int ksys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 		}
 		break;
 	default:
-		ret = -EINVAL;
+		return -EINVAL;
 	}
-out:
+	return 0;
+}
+
+int vfs_fadvise(struct file *file, loff_t offset, loff_t len, int advice)
+{
+	if (file->f_op->fadvise)
+		return file->f_op->fadvise(file, offset, len, advice);
+
+	return generic_fadvise(file, offset, len, advice);
+}
+EXPORT_SYMBOL(vfs_fadvise);
+
+int ksys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
+{
+	struct fd f = fdget(fd);
+	int ret;
+
+	if (!f.file)
+		return -EBADF;
+
+	ret = vfs_fadvise(f.file, offset, len, advice);
+
 	fdput(f);
 	return ret;
 }

commit a718e28f538441a3b6612da9ff226973376cdf0f
Author: Andrey Ryabinin <aryabinin@virtuozzo.com>
Date:   Fri Aug 17 15:46:57 2018 -0700

    mm/fadvise.c: fix signed overflow UBSAN complaint
    
    Signed integer overflow is undefined according to the C standard.  The
    overflow in ksys_fadvise64_64() is deliberate, but since it is signed
    overflow, UBSAN complains:
    
            UBSAN: Undefined behaviour in mm/fadvise.c:76:10
            signed integer overflow:
            4 + 9223372036854775805 cannot be represented in type 'long long int'
    
    Use unsigned types to do math.  Unsigned overflow is defined so UBSAN
    will not complain about it.  This patch doesn't change generated code.
    
    [akpm@linux-foundation.org: add comment explaining the casts]
    Link: http://lkml.kernel.org/r/20180629184453.7614-1-aryabinin@virtuozzo.com
    Signed-off-by: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Reported-by: <icytxw@gmail.com>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index afa41491d324..2d8376e3c640 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -72,8 +72,12 @@ int ksys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 		goto out;
 	}
 
-	/* Careful about overflows. Len == 0 means "as much as possible" */
-	endbyte = offset + len;
+	/*
+	 * Careful about overflows. Len == 0 means "as much as possible".  Use
+	 * unsigned math because signed overflows are undefined and UBSan
+	 * complains.
+	 */
+	endbyte = (u64)offset + (u64)len;
 	if (!len || endbyte < len)
 		endbyte = -1;
 	else

commit 9d5b7c956b09daab955fb2a42447d5d89ff15093
Author: Dominik Brodowski <linux@dominikbrodowski.net>
Date:   Sun Mar 11 11:34:45 2018 +0100

    mm: add ksys_fadvise64_64() helper; remove in-kernel call to sys_fadvise64_64()
    
    Using the ksys_fadvise64_64() helper allows us to avoid the in-kernel
    calls to the sys_fadvise64_64() syscall. The ksys_ prefix denotes that
    this function is meant as a drop-in replacement for the syscall. In
    particular, it uses the same calling convention as ksys_fadvise64_64().
    
    Some compat stubs called sys_fadvise64(), which then just passed through
    the arguments to sys_fadvise64_64(). Get rid of this indirection, and call
    ksys_fadvise64_64() directly.
    
    This patch is part of a series which removes in-kernel calls to syscalls.
    On this basis, the syscall entry path can be streamlined. For details, see
    http://lkml.kernel.org/r/20180325162527.GA17492@light.dominikbrodowski.net
    
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: linux-mm@kvack.org
    Signed-off-by: Dominik Brodowski <linux@dominikbrodowski.net>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 767887f5f3bf..afa41491d324 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -26,7 +26,8 @@
  * POSIX_FADV_WILLNEED could set PG_Referenced, and POSIX_FADV_NOREUSE could
  * deactivate the pages and clear PG_Referenced.
  */
-SYSCALL_DEFINE4(fadvise64_64, int, fd, loff_t, offset, loff_t, len, int, advice)
+
+int ksys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 {
 	struct fd f = fdget(fd);
 	struct inode *inode;
@@ -185,11 +186,16 @@ SYSCALL_DEFINE4(fadvise64_64, int, fd, loff_t, offset, loff_t, len, int, advice)
 	return ret;
 }
 
+SYSCALL_DEFINE4(fadvise64_64, int, fd, loff_t, offset, loff_t, len, int, advice)
+{
+	return ksys_fadvise64_64(fd, offset, len, advice);
+}
+
 #ifdef __ARCH_WANT_SYS_FADVISE64
 
 SYSCALL_DEFINE4(fadvise64, int, fd, loff_t, offset, size_t, len, int, advice)
 {
-	return sys_fadvise64_64(fd, offset, len, advice);
+	return ksys_fadvise64_64(fd, offset, len, advice);
 }
 
 #endif

commit a7ab400d6fe73d0119fdc234e9982a6f80faea9f
Author: shidao.ytt <shidao.ytt@alibaba-inc.com>
Date:   Wed Jan 31 16:19:55 2018 -0800

    mm/fadvise: discard partial page if endbyte is also EOF
    
    During our recent testing with fadvise(FADV_DONTNEED), we find that if
    given offset/length is not page-aligned, the last page will not be
    discarded.  The tool we use is vmtouch (https://hoytech.com/vmtouch/),
    we map a 10KB-sized file into memory and then try to run this tool to
    evict the whole file mapping, but the last single page always remains
    staying in the memory:
    
    $./vmtouch -e test_10K
               Files: 1
         Directories: 0
       Evicted Pages: 3 (12K)
             Elapsed: 2.1e-05 seconds
    
    $./vmtouch test_10K
               Files: 1
         Directories: 0
      Resident Pages: 1/3  4K/12K  33.3%
             Elapsed: 5.5e-05 seconds
    
    However when we test with an older kernel, say 3.10, this problem is
    gone.  So we wonder if this is a regression:
    
    $./vmtouch -e test_10K
               Files: 1
         Directories: 0
       Evicted Pages: 3 (12K)
             Elapsed: 8.2e-05 seconds
    
    $./vmtouch test_10K
               Files: 1
         Directories: 0
      Resident Pages: 0/3  0/12K  0%  <-- partial page also discarded
             Elapsed: 5e-05 seconds
    
    After digging a little bit into this problem, we find it seems not a
    regression.  Not discarding partial page is likely to be on purpose
    according to commit 441c228f817f ("mm: fadvise: document the
    fadvise(FADV_DONTNEED) behaviour for partial pages") written by Mel
    Gorman.  He explained why partial pages should be preserved instead of
    being discarded when using fadvise(FADV_DONTNEED).
    
    However, the interesting part is that the actual code did NOT work as
    the same as it was described, the partial page was still discarded
    anyway, due to a calculation mistake of `end_index' passed to
    invalidate_mapping_pages().  This mistake has not been fixed until
    recently, that's why we fail to reproduce our problem in old kernels.
    The fix is done in commit 18aba41cbf ("mm/fadvise.c: do not discard
    partial pages with POSIX_FADV_DONTNEED") by Oleg Drokin.
    
    Back to the original testing, our problem becomes that there is a
    special case that, if the page-unaligned `endbyte' is also the end of
    file, it is not necessary at all to preserve the last partial page, as
    we all know no one else will use the rest of it.  It should be safe
    enough if we just discard the whole page.  So we add an EOF check in
    this patch.
    
    We also find a poosbile real world issue in mainline kernel.  Assume
    such scenario: A userspace backup application want to backup a huge
    amount of small files (<4k) at once, the developer might (I guess) want
    to use fadvise(FADV_DONTNEED) to save memory.  However, FADV_DONTNEED
    won't really happen since the only page mapped is a partial page, and
    kernel will preserve it.  Our patch also fixes this problem, since we
    know the endbyte is EOF, so we discard it.
    
    Here is a simple reproducer to reproduce and verify each scenario we
    described above:
    
      test_fadvise.c
      ==============================
      #include <sys/mman.h>
      #include <sys/stat.h>
      #include <fcntl.h>
      #include <stdlib.h>
      #include <string.h>
      #include <stdio.h>
      #include <unistd.h>
    
      int main(int argc, char **argv)
      {
            int i, fd, ret, len;
            struct stat buf;
            void *addr;
            unsigned char *vec;
            char *strbuf;
            ssize_t pagesize = getpagesize();
            ssize_t filesize;
    
            fd = open(argv[1], O_RDWR|O_CREAT, S_IRUSR|S_IWUSR);
            if (fd < 0)
                    return -1;
            filesize = strtoul(argv[2], NULL, 10);
    
            strbuf = malloc(filesize);
            memset(strbuf, 42, filesize);
            write(fd, strbuf, filesize);
            free(strbuf);
            fsync(fd);
    
            len = (filesize + pagesize - 1) / pagesize;
            printf("length of pages: %d\n", len);
    
            addr = mmap(NULL, filesize, PROT_READ, MAP_SHARED, fd, 0);
            if (addr == MAP_FAILED)
                    return -1;
    
            ret = posix_fadvise(fd, 0, filesize, POSIX_FADV_DONTNEED);
            if (ret < 0)
                    return -1;
    
            vec = malloc(len);
            ret = mincore(addr, filesize, (void *)vec);
            if (ret < 0)
                    return -1;
    
            for (i = 0; i < len; i++)
                    printf("pages[%d]: %x\n", i, vec[i] & 0x1);
    
            free(vec);
            close(fd);
    
            return 0;
      }
      ==============================
    
    Test 1: running on kernel with commit 18aba41cbf reverted:
    
      [root@caspar ~]# uname -r
      4.15.0-rc6.revert+
      [root@caspar ~]# ./test_fadvise file1 1024
      length of pages: 1
      pages[0]: 0    # <-- partial page discarded
      [root@caspar ~]# ./test_fadvise file2 8192
      length of pages: 2
      pages[0]: 0
      pages[1]: 0
      [root@caspar ~]# ./test_fadvise file3 10240
      length of pages: 3
      pages[0]: 0
      pages[1]: 0
      pages[2]: 0    # <-- partial page discarded
    
    Test 2: running on mainline kernel:
    
      [root@caspar ~]# uname -r
      4.15.0-rc6+
      [root@caspar ~]# ./test_fadvise test1 1024
      length of pages: 1
      pages[0]: 1    # <-- partial and the only page not discarded
      [root@caspar ~]# ./test_fadvise test2 8192
      length of pages: 2
      pages[0]: 0
      pages[1]: 0
      [root@caspar ~]# ./test_fadvise test3 10240
      length of pages: 3
      pages[0]: 0
      pages[1]: 0
      pages[2]: 1    # <-- partial page not discarded
    
    Test 3: running on kernel with this patch:
    
      [root@caspar ~]# uname -r
      4.15.0-rc6.patched+
      [root@caspar ~]# ./test_fadvise test1 1024
      length of pages: 1
      pages[0]: 0    # <-- partial page and EOF, discarded
      [root@caspar ~]# ./test_fadvise test2 8192
      length of pages: 2
      pages[0]: 0
      pages[1]: 0
      [root@caspar ~]# ./test_fadvise test3 10240
      length of pages: 3
      pages[0]: 0
      pages[1]: 0
      pages[2]: 0    # <-- partial page and EOF, discarded
    
    [akpm@linux-foundation.org: tweak code comment]
    Link: http://lkml.kernel.org/r/5222da9ee20e1695eaabb69f631f200d6e6b8876.1515132470.git.jinli.zjl@alibaba-inc.com
    Signed-off-by: shidao.ytt <shidao.ytt@alibaba-inc.com>
    Signed-off-by: Caspar Zhang <jinli.zjl@alibaba-inc.com>
    Reviewed-by: Oliver Yang <zhiche.yy@alibaba-inc.com>
    Cc: Mel Gorman <mgorman@techsingularity.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index ec70d6e4b86d..767887f5f3bf 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -127,7 +127,15 @@ SYSCALL_DEFINE4(fadvise64_64, int, fd, loff_t, offset, loff_t, len, int, advice)
 		 */
 		start_index = (offset+(PAGE_SIZE-1)) >> PAGE_SHIFT;
 		end_index = (endbyte >> PAGE_SHIFT);
-		if ((endbyte & ~PAGE_MASK) != ~PAGE_MASK) {
+		/*
+		 * The page at end_index will be inclusively discarded according
+		 * by invalidate_mapping_pages(), so subtracting 1 from
+		 * end_index means we will skip the last page.  But if endbyte
+		 * is page aligned or is at the end of file, we should not skip
+		 * that page - discarding the last page is safe enough.
+		 */
+		if ((endbyte & ~PAGE_MASK) != ~PAGE_MASK &&
+				endbyte != inode->i_size - 1) {
 			/* First page is tricky as 0 - 1 = -1, but pgoff_t
 			 * is unsigned, so the end_index >= start_index
 			 * check below would be true and we'll discard the whole

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 702f239cd6db..ec70d6e4b86d 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * mm/fadvise.c
  *

commit 3a77d214807c32f900618cee0432feb4f7f99c65
Author: Shakeel Butt <shakeelb@google.com>
Date:   Fri Sep 8 16:13:05 2017 -0700

    mm: fadvise: avoid fadvise for fs without backing device
    
    The fadvise() manpage is silent on fadvise()'s effect on memory-based
    filesystems (shmem, hugetlbfs & ramfs) and pseudo file systems (procfs,
    sysfs, kernfs).  The current implementaion of fadvise is mostly a noop
    for such filesystems except for FADV_DONTNEED which will trigger
    expensive remote LRU cache draining.  This patch makes the noop of
    fadvise() on such file systems very explicit.
    
    However this change has two side effects for ramfs and one for tmpfs.
    First fadvise(FADV_DONTNEED) could remove the unmapped clean zero'ed
    pages of ramfs (allocated through read, readahead & read fault) and
    tmpfs (allocated through read fault).  Also fadvise(FADV_WILLNEED) could
    create such clean zero'ed pages for ramfs.  This change removes those
    possibilities.
    
    One of our generic libraries does fadvise(FADV_DONTNEED).  Recently we
    observed high latency in fadvise() and noticed that the users have
    started using tmpfs files and the latency was due to expensive remote
    LRU cache draining.  For normal tmpfs files (have data written on them),
    fadvise(FADV_DONTNEED) will always trigger the unneeded remote cache
    draining.
    
    Link: http://lkml.kernel.org/r/20170818011023.181465-1-shakeelb@google.com
    Signed-off-by: Shakeel Butt <shakeelb@google.com>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Hillf Danton <hillf.zj@alibaba-inc.com>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Greg Thelen <gthelen@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index a43013112581..702f239cd6db 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -52,7 +52,9 @@ SYSCALL_DEFINE4(fadvise64_64, int, fd, loff_t, offset, loff_t, len, int, advice)
 		goto out;
 	}
 
-	if (IS_DAX(inode)) {
+	bdi = inode_to_bdi(mapping->host);
+
+	if (IS_DAX(inode) || (bdi == &noop_backing_dev_info)) {
 		switch (advice) {
 		case POSIX_FADV_NORMAL:
 		case POSIX_FADV_RANDOM:
@@ -75,8 +77,6 @@ SYSCALL_DEFINE4(fadvise64_64, int, fd, loff_t, offset, loff_t, len, int, advice)
 	else
 		endbyte--;		/* inclusive */
 
-	bdi = inode_to_bdi(mapping->host);
-
 	switch (advice) {
 	case POSIX_FADV_NORMAL:
 		f.file->f_ra.ra_pages = bdi->ra_pages;

commit 4dd72b4a47a5309333c8ddf9ec7df3380dede30d
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Mon Dec 19 16:23:03 2016 -0800

    mm: fadvise: avoid expensive remote LRU cache draining after FADV_DONTNEED
    
    When FADV_DONTNEED cannot drop all pages in the range, it observes that
    some pages might still be on per-cpu LRU caches after recent
    instantiation and so initiates remote calls to all CPUs to flush their
    local caches.  However, in most cases, the fadvise happens from the same
    context that instantiated the pages, and any pre-LRU pages in the
    specified range are most likely sitting on the local CPU's LRU cache,
    and so in many cases this results in unnecessary remote calls, which, in
    a loaded system, can hold up the fadvise() call significantly.
    
    [ I didn't record it in the extreme case we observed at Facebook,
      unfortunately. We had a slow-to-respond system and noticed it
      lru_add_drain_all() leading the profile during fadvise calls. This
      patch came out of thinking about the code and how we commonly call
      FADV_DONTNEED.
    
      FWIW, I wrote a silly directory tree walker/searcher that recurses
      through /usr to read and FADV_DONTNEED each file it finds. On a 2
      socket 40 ht machine, over 1% is spent in lru_add_drain_all(). With
      the patch, that cost is gone; the local drain cost shows at 0.09%. ]
    
    Try to avoid the remote call by flushing the local LRU cache before even
    attempting to invalidate anything.  It's a cheap operation, and the
    local LRU cache is the most likely to hold any pre-LRU pages in the
    specified fadvise range.
    
    Link: http://lkml.kernel.org/r/20161214210017.GA1465@cmpxchg.org
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Acked-by: Mel Gorman <mgorman@suse.de>
    Acked-by: Hillf Danton <hillf.zj@alibaba-inc.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 6c707bfe02fd..a43013112581 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -139,7 +139,20 @@ SYSCALL_DEFINE4(fadvise64_64, int, fd, loff_t, offset, loff_t, len, int, advice)
 		}
 
 		if (end_index >= start_index) {
-			unsigned long count = invalidate_mapping_pages(mapping,
+			unsigned long count;
+
+			/*
+			 * It's common to FADV_DONTNEED right after
+			 * the read or write that instantiates the
+			 * pages, in which case there will be some
+			 * sitting on the local LRU cache. Try to
+			 * avoid the expensive remote drain and the
+			 * second cache tree walk below by flushing
+			 * them out right away.
+			 */
+			lru_add_drain();
+
+			count = invalidate_mapping_pages(mapping,
 						start_index, end_index);
 
 			/*

commit 18aba41cbfbcd138e9f6d8d446427d8b7691c194
Author: Oleg Drokin <green@linuxhacker.ru>
Date:   Wed Jun 8 15:33:59 2016 -0700

    mm/fadvise.c: do not discard partial pages with POSIX_FADV_DONTNEED
    
    I noticed that the logic in the fadvise64_64 syscall is incorrect for
    partial pages.  While first page of the region is correctly skipped if
    it is partial, the last page of the region is mistakenly discarded.
    This leads to problems for applications that read data in
    non-page-aligned chunks discarding already processed data between the
    reads.
    
    A somewhat misguided application that does something like write(XX bytes
    (non-page-alligned)); drop the data it just wrote; repeat gets a
    significant penalty in performance as a result.
    
    Link: http://lkml.kernel.org/r/1464917140-1506698-1-git-send-email-green@linuxhacker.ru
    Signed-off-by: Oleg Drokin <green@linuxhacker.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index b8024fa7101d..6c707bfe02fd 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -126,6 +126,17 @@ SYSCALL_DEFINE4(fadvise64_64, int, fd, loff_t, offset, loff_t, len, int, advice)
 		 */
 		start_index = (offset+(PAGE_SIZE-1)) >> PAGE_SHIFT;
 		end_index = (endbyte >> PAGE_SHIFT);
+		if ((endbyte & ~PAGE_MASK) != ~PAGE_MASK) {
+			/* First page is tricky as 0 - 1 = -1, but pgoff_t
+			 * is unsigned, so the end_index >= start_index
+			 * check below would be true and we'll discard the whole
+			 * file cache which is not what was asked.
+			 */
+			if (end_index == 0)
+				break;
+
+			end_index--;
+		}
 
 		if (end_index >= start_index) {
 			unsigned long count = invalidate_mapping_pages(mapping,

commit 09cbfeaf1a5a67bfb3201e0c83c810cecb2efa5a
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Fri Apr 1 15:29:47 2016 +0300

    mm, fs: get rid of PAGE_CACHE_* and page_cache_{get,release} macros
    
    PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} macros were introduced *long* time
    ago with promise that one day it will be possible to implement page
    cache with bigger chunks than PAGE_SIZE.
    
    This promise never materialized.  And unlikely will.
    
    We have many places where PAGE_CACHE_SIZE assumed to be equal to
    PAGE_SIZE.  And it's constant source of confusion on whether
    PAGE_CACHE_* or PAGE_* constant should be used in a particular case,
    especially on the border between fs and mm.
    
    Global switching to PAGE_CACHE_SIZE != PAGE_SIZE would cause to much
    breakage to be doable.
    
    Let's stop pretending that pages in page cache are special.  They are
    not.
    
    The changes are pretty straight-forward:
    
     - <foo> << (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - <foo> >> (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} -> PAGE_{SIZE,SHIFT,MASK,ALIGN};
    
     - page_cache_get() -> get_page();
    
     - page_cache_release() -> put_page();
    
    This patch contains automated changes generated with coccinelle using
    script below.  For some reason, coccinelle doesn't patch header files.
    I've called spatch for them manually.
    
    The only adjustment after coccinelle is revert of changes to
    PAGE_CAHCE_ALIGN definition: we are going to drop it later.
    
    There are few places in the code where coccinelle didn't reach.  I'll
    fix them manually in a separate patch.  Comments and documentation also
    will be addressed with the separate patch.
    
    virtual patch
    
    @@
    expression E;
    @@
    - E << (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    expression E;
    @@
    - E >> (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    @@
    - PAGE_CACHE_SHIFT
    + PAGE_SHIFT
    
    @@
    @@
    - PAGE_CACHE_SIZE
    + PAGE_SIZE
    
    @@
    @@
    - PAGE_CACHE_MASK
    + PAGE_MASK
    
    @@
    expression E;
    @@
    - PAGE_CACHE_ALIGN(E)
    + PAGE_ALIGN(E)
    
    @@
    expression E;
    @@
    - page_cache_get(E)
    + get_page(E)
    
    @@
    expression E;
    @@
    - page_cache_release(E)
    + put_page(E)
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index b8a5bc66b0c0..b8024fa7101d 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -97,8 +97,8 @@ SYSCALL_DEFINE4(fadvise64_64, int, fd, loff_t, offset, loff_t, len, int, advice)
 		break;
 	case POSIX_FADV_WILLNEED:
 		/* First and last PARTIAL page! */
-		start_index = offset >> PAGE_CACHE_SHIFT;
-		end_index = endbyte >> PAGE_CACHE_SHIFT;
+		start_index = offset >> PAGE_SHIFT;
+		end_index = endbyte >> PAGE_SHIFT;
 
 		/* Careful about overflow on the "+1" */
 		nrpages = end_index - start_index + 1;
@@ -124,8 +124,8 @@ SYSCALL_DEFINE4(fadvise64_64, int, fd, loff_t, offset, loff_t, len, int, advice)
 		 * preserved on the expectation that it is better to preserve
 		 * needed memory than to discard unneeded memory.
 		 */
-		start_index = (offset+(PAGE_CACHE_SIZE-1)) >> PAGE_CACHE_SHIFT;
-		end_index = (endbyte >> PAGE_CACHE_SHIFT);
+		start_index = (offset+(PAGE_SIZE-1)) >> PAGE_SHIFT;
+		end_index = (endbyte >> PAGE_SHIFT);
 
 		if (end_index >= start_index) {
 			unsigned long count = invalidate_mapping_pages(mapping,

commit 703c270887bb5106c4c46a00cc7477d30d5e04f5
Author: Tejun Heo <tj@kernel.org>
Date:   Fri May 22 17:13:44 2015 -0400

    writeback: implement and use inode_congested()
    
    In several places, bdi_congested() and its wrappers are used to
    determine whether more IOs should be issued.  With cgroup writeback
    support, this question can't be answered solely based on the bdi
    (backing_dev_info).  It's dependent on whether the filesystem and bdi
    support cgroup writeback and the blkcg the inode is associated with.
    
    This patch implements inode_congested() and its wrappers which take
    @inode and determines the congestion state considering cgroup
    writeback.  The new functions replace bdi_*congested() calls in places
    where the query is about specific inode and task.
    
    There are several filesystem users which also fit this criteria but
    they should be updated when each filesystem implements cgroup
    writeback support.
    
    v2: Now that a given inode is associated with only one wb, congestion
        state can be determined independent from the asking task.  Drop
        @task.  Spotted by Vivek.  Also, converted to take @inode instead
        of @mapping and renamed to inode_congested().
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 4a3907cf79f8..b8a5bc66b0c0 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -115,7 +115,7 @@ SYSCALL_DEFINE4(fadvise64_64, int, fd, loff_t, offset, loff_t, len, int, advice)
 	case POSIX_FADV_NOREUSE:
 		break;
 	case POSIX_FADV_DONTNEED:
-		if (!bdi_write_congested(bdi))
+		if (!inode_write_congested(mapping->host))
 			__filemap_fdatawrite_range(mapping, offset, endbyte,
 						   WB_SYNC_NONE);
 

commit e748dcd095ddee50e7a7deda2e26247715318a2e
Author: Matthew Wilcox <matthew.r.wilcox@intel.com>
Date:   Mon Feb 16 15:59:12 2015 -0800

    vfs: remove get_xip_mem
    
    All callers of get_xip_mem() are now gone.  Remove checks for it,
    initialisers of it, documentation of it and the only implementation of it.
     Also remove mm/filemap_xip.c as it is now empty.  Also remove
    documentation of the long-gone get_xip_page().
    
    Signed-off-by: Matthew Wilcox <matthew.r.wilcox@intel.com>
    Cc: Andreas Dilger <andreas.dilger@intel.com>
    Cc: Boaz Harrosh <boaz@plexistor.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Cc: Randy Dunlap <rdunlap@infradead.org>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index fac23ecf8d72..4a3907cf79f8 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -28,6 +28,7 @@
 SYSCALL_DEFINE4(fadvise64_64, int, fd, loff_t, offset, loff_t, len, int, advice)
 {
 	struct fd f = fdget(fd);
+	struct inode *inode;
 	struct address_space *mapping;
 	struct backing_dev_info *bdi;
 	loff_t endbyte;			/* inclusive */
@@ -39,7 +40,8 @@ SYSCALL_DEFINE4(fadvise64_64, int, fd, loff_t, offset, loff_t, len, int, advice)
 	if (!f.file)
 		return -EBADF;
 
-	if (S_ISFIFO(file_inode(f.file)->i_mode)) {
+	inode = file_inode(f.file);
+	if (S_ISFIFO(inode->i_mode)) {
 		ret = -ESPIPE;
 		goto out;
 	}
@@ -50,7 +52,7 @@ SYSCALL_DEFINE4(fadvise64_64, int, fd, loff_t, offset, loff_t, len, int, advice)
 		goto out;
 	}
 
-	if (mapping->a_ops->get_xip_mem) {
+	if (IS_DAX(inode)) {
 		switch (advice) {
 		case POSIX_FADV_NORMAL:
 		case POSIX_FADV_RANDOM:

commit de1414a654e66b81b5348dbc5259ecf2fb61655e
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Jan 14 10:42:36 2015 +0100

    fs: export inode_to_bdi and use it in favor of mapping->backing_dev_info
    
    Now that we got rid of the bdi abuse on character devices we can always use
    sb->s_bdi to get at the backing_dev_info for a file, except for the block
    device special case.  Export inode_to_bdi and replace uses of
    mapping->backing_dev_info with it to prepare for the removal of
    mapping->backing_dev_info.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 2ad7adf4f0a4..fac23ecf8d72 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -73,7 +73,7 @@ SYSCALL_DEFINE4(fadvise64_64, int, fd, loff_t, offset, loff_t, len, int, advice)
 	else
 		endbyte--;		/* inclusive */
 
-	bdi = mapping->backing_dev_info;
+	bdi = inode_to_bdi(mapping->host);
 
 	switch (advice) {
 	case POSIX_FADV_NORMAL:
@@ -113,7 +113,7 @@ SYSCALL_DEFINE4(fadvise64_64, int, fd, loff_t, offset, loff_t, len, int, advice)
 	case POSIX_FADV_NOREUSE:
 		break;
 	case POSIX_FADV_DONTNEED:
-		if (!bdi_write_congested(mapping->backing_dev_info))
+		if (!bdi_write_congested(bdi))
 			__filemap_fdatawrite_range(mapping, offset, endbyte,
 						   WB_SYNC_NONE);
 

commit 441c228f817f7597e090d84aca74bdb7c2bd5040
Author: Mel Gorman <mgorman@suse.de>
Date:   Fri Dec 12 16:56:33 2014 -0800

    mm: fadvise: document the fadvise(FADV_DONTNEED) behaviour for partial pages
    
    A random seek IO benchmark appeared to regress because of a change to
    readahead but the real problem was the benchmark.  To ensure the IO
    request accesssed disk, it used fadvise(FADV_DONTNEED) on a block boundary
    (512K) but the hint is ignored by the kernel.  This is correct but not
    necessarily obvious behaviour.  As much as I dislike comment patches, the
    explanation for this behaviour predates current git history.  Clarify why
    it behaves like this in case someone "fixes" fadvise or readahead for the
    wrong reasons.
    
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 3bcfd81db45e..2ad7adf4f0a4 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -117,7 +117,11 @@ SYSCALL_DEFINE4(fadvise64_64, int, fd, loff_t, offset, loff_t, len, int, advice)
 			__filemap_fdatawrite_range(mapping, offset, endbyte,
 						   WB_SYNC_NONE);
 
-		/* First and last FULL page! */
+		/*
+		 * First and last FULL page! Partial pages are deliberately
+		 * preserved on the expectation that it is better to preserve
+		 * needed memory than to discard unneeded memory.
+		 */
 		start_index = (offset+(PAGE_CACHE_SIZE-1)) >> PAGE_CACHE_SHIFT;
 		end_index = (endbyte >> PAGE_CACHE_SHIFT);
 

commit 4a0fd5bf0fd0795af8f1be3b261f5cf146a4cb9b
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jan 21 15:16:58 2013 -0500

    teach SYSCALL_DEFINE<n> how to deal with long long/unsigned long long
    
    ... and convert a bunch of SYSCALL_DEFINE ones to SYSCALL_DEFINE<n>,
    killing the boilerplate crap around them.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 7e092689a12a..3bcfd81db45e 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -25,7 +25,7 @@
  * POSIX_FADV_WILLNEED could set PG_Referenced, and POSIX_FADV_NOREUSE could
  * deactivate the pages and clear PG_Referenced.
  */
-SYSCALL_DEFINE(fadvise64_64)(int fd, loff_t offset, loff_t len, int advice)
+SYSCALL_DEFINE4(fadvise64_64, int, fd, loff_t, offset, loff_t, len, int, advice)
 {
 	struct fd f = fdget(fd);
 	struct address_space *mapping;
@@ -145,26 +145,12 @@ SYSCALL_DEFINE(fadvise64_64)(int fd, loff_t offset, loff_t len, int advice)
 	fdput(f);
 	return ret;
 }
-#ifdef CONFIG_HAVE_SYSCALL_WRAPPERS
-asmlinkage long SyS_fadvise64_64(long fd, loff_t offset, loff_t len, long advice)
-{
-	return SYSC_fadvise64_64((int) fd, offset, len, (int) advice);
-}
-SYSCALL_ALIAS(sys_fadvise64_64, SyS_fadvise64_64);
-#endif
 
 #ifdef __ARCH_WANT_SYS_FADVISE64
 
-SYSCALL_DEFINE(fadvise64)(int fd, loff_t offset, size_t len, int advice)
+SYSCALL_DEFINE4(fadvise64, int, fd, loff_t, offset, size_t, len, int, advice)
 {
 	return sys_fadvise64_64(fd, offset, len, advice);
 }
-#ifdef CONFIG_HAVE_SYSCALL_WRAPPERS
-asmlinkage long SyS_fadvise64(long fd, loff_t offset, long len, long advice)
-{
-	return SYSC_fadvise64((int) fd, offset, (size_t)len, (int)advice);
-}
-SYSCALL_ALIAS(sys_fadvise64, SyS_fadvise64);
-#endif
 
 #endif

commit d895cb1af15c04c522a25c79cc429076987c089b
Merge: 9626357371b5 d3d009cb965e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Feb 26 20:16:07 2013 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs pile (part one) from Al Viro:
     "Assorted stuff - cleaning namei.c up a bit, fixing ->d_name/->d_parent
      locking violations, etc.
    
      The most visible changes here are death of FS_REVAL_DOT (replaced with
      "has ->d_weak_revalidate()") and a new helper getting from struct file
      to inode.  Some bits of preparation to xattr method interface changes.
    
      Misc patches by various people sent this cycle *and* ocfs2 fixes from
      several cycles ago that should've been upstream right then.
    
      PS: the next vfs pile will be xattr stuff."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (46 commits)
      saner proc_get_inode() calling conventions
      proc: avoid extra pde_put() in proc_fill_super()
      fs: change return values from -EACCES to -EPERM
      fs/exec.c: make bprm_mm_init() static
      ocfs2/dlm: use GFP_ATOMIC inside a spin_lock
      ocfs2: fix possible use-after-free with AIO
      ocfs2: Fix oops in ocfs2_fast_symlink_readpage() code path
      get_empty_filp()/alloc_file() leave both ->f_pos and ->f_version zero
      target: writev() on single-element vector is pointless
      export kernel_write(), convert open-coded instances
      fs: encode_fh: return FILEID_INVALID if invalid fid_type
      kill f_vfsmnt
      vfs: kill FS_REVAL_DOT by adding a d_weak_revalidate dentry op
      nfsd: handle vfs_getattr errors in acl protocol
      switch vfs_getattr() to struct path
      default SET_PERSONALITY() in linux/elf.h
      ceph: prepopulate inodes only when request is aborted
      d_hash_and_lookup(): export, switch open-coded instances
      9p: switch v9fs_set_create_acl() to inode+fid, do it before d_instantiate()
      9p: split dropping the acls from v9fs_set_create_acl()
      ...

commit 67d46b296a1ba1477c0df8ff3bc5e0167a0b0732
Author: Mel Gorman <mgorman@suse.de>
Date:   Fri Feb 22 16:35:59 2013 -0800

    mm/fadvise.c: drain all pagevecs if POSIX_FADV_DONTNEED fails to discard all pages
    
    Rob van der Heij reported the following (paraphrased) on private mail.
    
            The scenario is that I want to avoid backups to fill up the page
            cache and purge stuff that is more likely to be used again (this is
            with s390x Linux on z/VM, so I don't give it as much memory that
            we don't care anymore). So I have something with LD_PRELOAD that
            intercepts the close() call (from tar, in this case) and issues
            a posix_fadvise() just before closing the file.
    
            This mostly works, except for small files (less than 14 pages)
            that remains in page cache after the face.
    
    Unfortunately Rob has not had a chance to test this exact patch but the
    test program below should be reproducing the problem he described.
    
    The issue is the per-cpu pagevecs for LRU additions.  If the pages are
    added by one CPU but fadvise() is called on another then the pages
    remain resident as the invalidate_mapping_pages() only drains the local
    pagevecs via its call to pagevec_release().  The user-visible effect is
    that a program that uses fadvise() properly is not obeyed.
    
    A possible fix for this is to put the necessary smarts into
    invalidate_mapping_pages() to globally drain the LRU pagevecs if a
    pagevec page could not be discarded.  The downside with this is that an
    inode cache shrink would send a global IPI and memory pressure
    potentially causing global IPI storms is very undesirable.
    
    Instead, this patch adds a check during fadvise(POSIX_FADV_DONTNEED) to
    check if invalidate_mapping_pages() discarded all the requested pages.
    If a subset of pages are discarded it drains the LRU pagevecs and tries
    again.  If the second attempt fails, it assumes it is due to the pages
    being mapped, locked or dirty and does not care.  With this patch, an
    application using fadvise() correctly will be obeyed but there is a
    downside that a malicious application can force the kernel to send
    global IPIs and increase overhead.
    
    If accepted, I would like this to be considered as a -stable candidate.
    It's not an urgent issue but it's a system call that is not working as
    advertised which is weak.
    
    The following test program demonstrates the problem.  It should never
    report that pages are still resident but will without this patch.  It
    assumes that CPU 0 and 1 exist.
    
    int main() {
            int fd;
            int pagesize = getpagesize();
            ssize_t written = 0, expected;
            char *buf;
            unsigned char *vec;
            int resident, i;
            cpu_set_t set;
    
            /* Prepare a buffer for writing */
            expected = FILESIZE_PAGES * pagesize;
            buf = malloc(expected + 1);
            if (buf == NULL) {
                    printf("ENOMEM\n");
                    exit(EXIT_FAILURE);
            }
            buf[expected] = 0;
            memset(buf, 'a', expected);
    
            /* Prepare the mincore vec */
            vec = malloc(FILESIZE_PAGES);
            if (vec == NULL) {
                    printf("ENOMEM\n");
                    exit(EXIT_FAILURE);
            }
    
            /* Bind ourselves to CPU 0 */
            CPU_ZERO(&set);
            CPU_SET(0, &set);
            if (sched_setaffinity(getpid(), sizeof(set), &set) == -1) {
                    perror("sched_setaffinity");
                    exit(EXIT_FAILURE);
            }
    
            /* open file, unlink and write buffer */
            fd = open("fadvise-test-file", O_CREAT|O_EXCL|O_RDWR);
            if (fd == -1) {
                    perror("open");
                    exit(EXIT_FAILURE);
            }
            unlink("fadvise-test-file");
            while (written < expected) {
                    ssize_t this_write;
                    this_write = write(fd, buf + written, expected - written);
    
                    if (this_write == -1) {
                            perror("write");
                            exit(EXIT_FAILURE);
                    }
    
                    written += this_write;
            }
            free(buf);
    
            /*
             * Force ourselves to another CPU. If fadvise only flushes the local
             * CPUs pagevecs then the fadvise will fail to discard all file pages
             */
            CPU_ZERO(&set);
            CPU_SET(1, &set);
            if (sched_setaffinity(getpid(), sizeof(set), &set) == -1) {
                    perror("sched_setaffinity");
                    exit(EXIT_FAILURE);
            }
    
            /* sync and fadvise to discard the page cache */
            fsync(fd);
            if (posix_fadvise(fd, 0, expected, POSIX_FADV_DONTNEED) == -1) {
                    perror("posix_fadvise");
                    exit(EXIT_FAILURE);
            }
    
            /* map the file and use mincore to see which parts of it are resident */
            buf = mmap(NULL, expected, PROT_READ, MAP_SHARED, fd, 0);
            if (buf == NULL) {
                    perror("mmap");
                    exit(EXIT_FAILURE);
            }
            if (mincore(buf, expected, vec) == -1) {
                    perror("mincore");
                    exit(EXIT_FAILURE);
            }
    
            /* Check residency */
            for (i = 0, resident = 0; i < FILESIZE_PAGES; i++) {
                    if (vec[i])
                            resident++;
            }
            if (resident != 0) {
                    printf("Nr unexpected pages resident: %d\n", resident);
                    exit(EXIT_FAILURE);
            }
    
            munmap(buf, expected);
            close(fd);
            free(vec);
            exit(EXIT_SUCCESS);
    }
    
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Reported-by: Rob van der Heij <rvdheij@gmail.com>
    Tested-by: Rob van der Heij <rvdheij@gmail.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index a47f0f50c89f..909ec558625c 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -17,6 +17,7 @@
 #include <linux/fadvise.h>
 #include <linux/writeback.h>
 #include <linux/syscalls.h>
+#include <linux/swap.h>
 
 #include <asm/unistd.h>
 
@@ -120,9 +121,22 @@ SYSCALL_DEFINE(fadvise64_64)(int fd, loff_t offset, loff_t len, int advice)
 		start_index = (offset+(PAGE_CACHE_SIZE-1)) >> PAGE_CACHE_SHIFT;
 		end_index = (endbyte >> PAGE_CACHE_SHIFT);
 
-		if (end_index >= start_index)
-			invalidate_mapping_pages(mapping, start_index,
+		if (end_index >= start_index) {
+			unsigned long count = invalidate_mapping_pages(mapping,
+						start_index, end_index);
+
+			/*
+			 * If fewer pages were invalidated than expected then
+			 * it is possible that some of the pages were on
+			 * a per-cpu pagevec for a remote CPU. Drain all
+			 * pagevecs and try again.
+			 */
+			if (count < (end_index - start_index + 1)) {
+				lru_add_drain_all();
+				invalidate_mapping_pages(mapping, start_index,
 						end_index);
+			}
+		}
 		break;
 	default:
 		ret = -EINVAL;

commit 496ad9aa8ef448058e36ca7a787c61f2e63f0f54
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Jan 23 17:07:38 2013 -0500

    new helper: file_inode(file)
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index a47f0f50c89f..6deaa6c04636 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -38,7 +38,7 @@ SYSCALL_DEFINE(fadvise64_64)(int fd, loff_t offset, loff_t len, int advice)
 	if (!f.file)
 		return -EBADF;
 
-	if (S_ISFIFO(f.file->f_path.dentry->d_inode->i_mode)) {
+	if (S_ISFIFO(file_inode(f.file)->i_mode)) {
 		ret = -ESPIPE;
 		goto out;
 	}

commit 2903ff019b346ab8d36ebbf54853c3aaf6590608
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Aug 28 12:52:22 2012 -0400

    switch simple cases of fget_light to fdget
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index a83245763cf8..a47f0f50c89f 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -26,8 +26,7 @@
  */
 SYSCALL_DEFINE(fadvise64_64)(int fd, loff_t offset, loff_t len, int advice)
 {
-	int fput_needed;
-	struct file *file = fget_light(fd, &fput_needed);
+	struct fd f = fdget(fd);
 	struct address_space *mapping;
 	struct backing_dev_info *bdi;
 	loff_t endbyte;			/* inclusive */
@@ -36,15 +35,15 @@ SYSCALL_DEFINE(fadvise64_64)(int fd, loff_t offset, loff_t len, int advice)
 	unsigned long nrpages;
 	int ret = 0;
 
-	if (!file)
+	if (!f.file)
 		return -EBADF;
 
-	if (S_ISFIFO(file->f_path.dentry->d_inode->i_mode)) {
+	if (S_ISFIFO(f.file->f_path.dentry->d_inode->i_mode)) {
 		ret = -ESPIPE;
 		goto out;
 	}
 
-	mapping = file->f_mapping;
+	mapping = f.file->f_mapping;
 	if (!mapping || len < 0) {
 		ret = -EINVAL;
 		goto out;
@@ -77,21 +76,21 @@ SYSCALL_DEFINE(fadvise64_64)(int fd, loff_t offset, loff_t len, int advice)
 
 	switch (advice) {
 	case POSIX_FADV_NORMAL:
-		file->f_ra.ra_pages = bdi->ra_pages;
-		spin_lock(&file->f_lock);
-		file->f_mode &= ~FMODE_RANDOM;
-		spin_unlock(&file->f_lock);
+		f.file->f_ra.ra_pages = bdi->ra_pages;
+		spin_lock(&f.file->f_lock);
+		f.file->f_mode &= ~FMODE_RANDOM;
+		spin_unlock(&f.file->f_lock);
 		break;
 	case POSIX_FADV_RANDOM:
-		spin_lock(&file->f_lock);
-		file->f_mode |= FMODE_RANDOM;
-		spin_unlock(&file->f_lock);
+		spin_lock(&f.file->f_lock);
+		f.file->f_mode |= FMODE_RANDOM;
+		spin_unlock(&f.file->f_lock);
 		break;
 	case POSIX_FADV_SEQUENTIAL:
-		file->f_ra.ra_pages = bdi->ra_pages * 2;
-		spin_lock(&file->f_lock);
-		file->f_mode &= ~FMODE_RANDOM;
-		spin_unlock(&file->f_lock);
+		f.file->f_ra.ra_pages = bdi->ra_pages * 2;
+		spin_lock(&f.file->f_lock);
+		f.file->f_mode &= ~FMODE_RANDOM;
+		spin_unlock(&f.file->f_lock);
 		break;
 	case POSIX_FADV_WILLNEED:
 		/* First and last PARTIAL page! */
@@ -107,7 +106,7 @@ SYSCALL_DEFINE(fadvise64_64)(int fd, loff_t offset, loff_t len, int advice)
 		 * Ignore return value because fadvise() shall return
 		 * success even if filesystem can't retrieve a hint,
 		 */
-		force_page_cache_readahead(mapping, file, start_index,
+		force_page_cache_readahead(mapping, f.file, start_index,
 					   nrpages);
 		break;
 	case POSIX_FADV_NOREUSE:
@@ -129,7 +128,7 @@ SYSCALL_DEFINE(fadvise64_64)(int fd, loff_t offset, loff_t len, int advice)
 		ret = -EINVAL;
 	}
 out:
-	fput_light(file, fput_needed);
+	fdput(f);
 	return ret;
 }
 #ifdef CONFIG_HAVE_SYSCALL_WRAPPERS

commit 611443783ada3464c44e9168f6b7de2cb3fed39a
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Aug 26 20:27:09 2012 -0400

    switch fadvise(2) to fget_light()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 9b75a045dbf4..a83245763cf8 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -26,7 +26,8 @@
  */
 SYSCALL_DEFINE(fadvise64_64)(int fd, loff_t offset, loff_t len, int advice)
 {
-	struct file *file = fget(fd);
+	int fput_needed;
+	struct file *file = fget_light(fd, &fput_needed);
 	struct address_space *mapping;
 	struct backing_dev_info *bdi;
 	loff_t endbyte;			/* inclusive */
@@ -128,7 +129,7 @@ SYSCALL_DEFINE(fadvise64_64)(int fd, loff_t offset, loff_t len, int advice)
 		ret = -EINVAL;
 	}
 out:
-	fput(file);
+	fput_light(file, fput_needed);
 	return ret;
 }
 #ifdef CONFIG_HAVE_SYSCALL_WRAPPERS

commit 3d3727cdb07ff17ddc3c551ef8d03d37b60a0372
Author: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Date:   Tue Jul 31 16:42:50 2012 -0700

    mm, fadvise: don't return -EINVAL when filesystem cannot implement fadvise()
    
    Eric Wong reported his test suite failex when /tmp is tmpfs.
    
    https://lkml.org/lkml/2012/2/24/479
    
    Currentlt the input check of POSIX_FADV_WILLNEED has two problems.
    
    - requires a_ops->readpage.  But in fact, force_page_cache_readahead()
      requires that the target filesystem has either ->readpage or ->readpages.
    
    - returns -EINVAL when the filesystem doesn't have ->readpage.  But
      posix says that fadvise is merely a hint.  Thus fadvise() should return
      0 if filesystem has no means of implementing fadvise().  The userland
      application should not know nor care whcih type of filesystem backs the
      TMPDIR directory, as Eric pointed out.  There is nothing which userspace
      can do to solve this error.
    
    So change the return value to 0 when filesytem doesn't support readahead.
    
    [akpm@linux-foundation.org: checkpatch fixes]
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Hillf Danton <dhillf@gmail.com>
    Signed-off-by: Eric Wong <normalperson@yhbt.net>
    Tested-by: Eric Wong <normalperson@yhbt.net>
    Reviewed-by: Wanlong Gao <gaowanlong@cn.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 469491e0af79..9b75a045dbf4 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -93,11 +93,6 @@ SYSCALL_DEFINE(fadvise64_64)(int fd, loff_t offset, loff_t len, int advice)
 		spin_unlock(&file->f_lock);
 		break;
 	case POSIX_FADV_WILLNEED:
-		if (!mapping->a_ops->readpage) {
-			ret = -EINVAL;
-			break;
-		}
-
 		/* First and last PARTIAL page! */
 		start_index = offset >> PAGE_CACHE_SHIFT;
 		end_index = endbyte >> PAGE_CACHE_SHIFT;
@@ -106,12 +101,13 @@ SYSCALL_DEFINE(fadvise64_64)(int fd, loff_t offset, loff_t len, int advice)
 		nrpages = end_index - start_index + 1;
 		if (!nrpages)
 			nrpages = ~0UL;
-		
-		ret = force_page_cache_readahead(mapping, file,
-				start_index,
-				nrpages);
-		if (ret > 0)
-			ret = 0;
+
+		/*
+		 * Ignore return value because fadvise() shall return
+		 * success even if filesystem can't retrieve a hint,
+		 */
+		force_page_cache_readahead(mapping, file, start_index,
+					   nrpages);
 		break;
 	case POSIX_FADV_NOREUSE:
 		break;

commit ad8a1b558e6c76fb53901956d3c8f29b82a4ccfa
Author: Shawn Bohrer <sbohrer@rgmadvisors.com>
Date:   Tue Jan 10 15:07:35 2012 -0800

    fadvise: only initiate writeback for specified range with FADV_DONTNEED
    
    Previously POSIX_FADV_DONTNEED would start writeback for the entire file
    when the bdi was not write congested.  This negatively impacts performance
    if the file contains dirty pages outside of the requested range.  This
    change uses __filemap_fdatawrite_range() to only initiate writeback for
    the requested range.
    
    Signed-off-by: Shawn Bohrer <sbohrer@rgmadvisors.com>
    Acked-by: Johannes Weiner <jweiner@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 8d723c9e8b75..469491e0af79 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -117,7 +117,8 @@ SYSCALL_DEFINE(fadvise64_64)(int fd, loff_t offset, loff_t len, int advice)
 		break;
 	case POSIX_FADV_DONTNEED:
 		if (!bdi_write_congested(mapping->backing_dev_info))
-			filemap_flush(mapping);
+			__filemap_fdatawrite_range(mapping, offset, endbyte,
+						   WB_SYNC_NONE);
 
 		/* First and last FULL page! */
 		start_index = (offset+(PAGE_CACHE_SIZE-1)) >> PAGE_CACHE_SHIFT;

commit 0141450f66c3c12a3aaa869748caa64241885cdf
Author: Wu Fengguang <fengguang.wu@intel.com>
Date:   Fri Mar 5 13:42:03 2010 -0800

    readahead: introduce FMODE_RANDOM for POSIX_FADV_RANDOM
    
    This fixes inefficient page-by-page reads on POSIX_FADV_RANDOM.
    
    POSIX_FADV_RANDOM used to set ra_pages=0, which leads to poor performance:
    a 16K read will be carried out in 4 _sync_ 1-page reads.
    
    In other places, ra_pages==0 means
    - it's ramfs/tmpfs/hugetlbfs/sysfs/configfs
    - some IO error happened
    where multi-page read IO won't help or should be avoided.
    
    POSIX_FADV_RANDOM actually want a different semantics: to disable the
    *heuristic* readahead algorithm, and to use a dumb one which faithfully
    submit read IO for whatever application requests.
    
    So introduce a flag FMODE_RANDOM for POSIX_FADV_RANDOM.
    
    Note that the random hint is not likely to help random reads performance
    noticeably.  And it may be too permissive on huge request size (its IO
    size is not limited by read_ahead_kb).
    
    In Quentin's report (http://lkml.org/lkml/2009/12/24/145), the overall
    (NFS read) performance of the application increased by 313%!
    
    Tested-by: Quentin Barnes <qbarnes+nfs@yahoo-inc.com>
    Signed-off-by: Wu Fengguang <fengguang.wu@intel.com>
    Cc: Nick Piggin <npiggin@suse.de>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Steven Whitehouse <swhiteho@redhat.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Trond Myklebust <Trond.Myklebust@netapp.com>
    Cc: Chuck Lever <chuck.lever@oracle.com>
    Cc: <stable@kernel.org>                 [2.6.33.x]
    Cc: <qbarnes+nfs@yahoo-inc.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index e43359214f6f..8d723c9e8b75 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -77,12 +77,20 @@ SYSCALL_DEFINE(fadvise64_64)(int fd, loff_t offset, loff_t len, int advice)
 	switch (advice) {
 	case POSIX_FADV_NORMAL:
 		file->f_ra.ra_pages = bdi->ra_pages;
+		spin_lock(&file->f_lock);
+		file->f_mode &= ~FMODE_RANDOM;
+		spin_unlock(&file->f_lock);
 		break;
 	case POSIX_FADV_RANDOM:
-		file->f_ra.ra_pages = 0;
+		spin_lock(&file->f_lock);
+		file->f_mode |= FMODE_RANDOM;
+		spin_unlock(&file->f_lock);
 		break;
 	case POSIX_FADV_SEQUENTIAL:
 		file->f_ra.ra_pages = bdi->ra_pages * 2;
+		spin_lock(&file->f_lock);
+		file->f_mode &= ~FMODE_RANDOM;
+		spin_unlock(&file->f_lock);
 		break;
 	case POSIX_FADV_WILLNEED:
 		if (!mapping->a_ops->readpage) {

commit f7e839dd36fd940b0202cfb7d39b2a1b2dc59b1b
Author: Wu Fengguang <fengguang.wu@intel.com>
Date:   Tue Jun 16 15:31:20 2009 -0700

    readahead: move max_sane_readahead() calls into force_page_cache_readahead()
    
    Impact: code simplification.
    
    Cc: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Wu Fengguang <fengguang.wu@intel.com>
    Cc: Ying Han <yinghan@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 54a0f8040afa..e43359214f6f 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -101,7 +101,7 @@ SYSCALL_DEFINE(fadvise64_64)(int fd, loff_t offset, loff_t len, int advice)
 		
 		ret = force_page_cache_readahead(mapping, file,
 				start_index,
-				max_sane_readahead(nrpages));
+				nrpages);
 		if (ret > 0)
 			ret = 0;
 		break;

commit 6673e0c3fbeaed2cd08e2fd4a4aa97382d6fedb0
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed Jan 14 14:14:02 2009 +0100

    [CVE-2009-0029] System call wrapper special cases
    
    System calls with an unsigned long long argument can't be converted with
    the standard wrappers since that would include a cast to long, which in
    turn means that we would lose the upper 32 bit on 32 bit architectures.
    Also semctl can't use the standard wrapper since it has a 'union'
    parameter.
    
    So we handle them as special case and add some extra wrappers instead.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index a1da969bd980..54a0f8040afa 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -24,7 +24,7 @@
  * POSIX_FADV_WILLNEED could set PG_Referenced, and POSIX_FADV_NOREUSE could
  * deactivate the pages and clear PG_Referenced.
  */
-asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
+SYSCALL_DEFINE(fadvise64_64)(int fd, loff_t offset, loff_t len, int advice)
 {
 	struct file *file = fget(fd);
 	struct address_space *mapping;
@@ -126,12 +126,26 @@ asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 	fput(file);
 	return ret;
 }
+#ifdef CONFIG_HAVE_SYSCALL_WRAPPERS
+asmlinkage long SyS_fadvise64_64(long fd, loff_t offset, loff_t len, long advice)
+{
+	return SYSC_fadvise64_64((int) fd, offset, len, (int) advice);
+}
+SYSCALL_ALIAS(sys_fadvise64_64, SyS_fadvise64_64);
+#endif
 
 #ifdef __ARCH_WANT_SYS_FADVISE64
 
-asmlinkage long sys_fadvise64(int fd, loff_t offset, size_t len, int advice)
+SYSCALL_DEFINE(fadvise64)(int fd, loff_t offset, size_t len, int advice)
 {
 	return sys_fadvise64_64(fd, offset, len, advice);
 }
+#ifdef CONFIG_HAVE_SYSCALL_WRAPPERS
+asmlinkage long SyS_fadvise64(long fd, loff_t offset, long len, long advice)
+{
+	return SYSC_fadvise64((int) fd, offset, (size_t)len, (int)advice);
+}
+SYSCALL_ALIAS(sys_fadvise64, SyS_fadvise64);
+#endif
 
 #endif

commit e1f8e87449147ffe5ea3de64a46af7de450ce279
Author: Francois Cami <francois.cami@free.fr>
Date:   Wed Oct 15 22:01:59 2008 -0700

    Remove Andrew Morton's old email accounts
    
    People can use the real name an an index into MAINTAINERS to find the
    current email address.
    
    Signed-off-by: Francois Cami <francois.cami@free.fr>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 343cfdfebd9e..a1da969bd980 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -3,7 +3,7 @@
  *
  * Copyright (C) 2002, Linus Torvalds
  *
- * 11Jan2003	akpm@digeo.com
+ * 11Jan2003	Andrew Morton
  *		Initial version.
  */
 

commit 70688e4dd1647f0ceb502bbd5964fa344c5eb411
Author: Nick Piggin <npiggin@suse.de>
Date:   Mon Apr 28 02:13:02 2008 -0700

    xip: support non-struct page backed memory
    
    Convert XIP to support non-struct page backed memory, using VM_MIXEDMAP for
    the user mappings.
    
    This requires the get_xip_page API to be changed to an address based one.
    Improve the API layering a little bit too, while we're here.
    
    This is required in order to support XIP filesystems on memory that isn't
    backed with struct page (but memory with struct page is still supported too).
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Acked-by: Carsten Otte <cotte@de.ibm.com>
    Cc: Jared Hulbert <jaredeh@gmail.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 3c0f1e99f5e4..343cfdfebd9e 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -49,7 +49,7 @@ asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 		goto out;
 	}
 
-	if (mapping->a_ops->get_xip_page) {
+	if (mapping->a_ops->get_xip_mem) {
 		switch (advice) {
 		case POSIX_FADV_NORMAL:
 		case POSIX_FADV_RANDOM:

commit b5beb1caff4ce063e6e2dc13f23b80eeef4e9782
Author: Masatake YAMATO <yamato@redhat.com>
Date:   Mon Feb 4 22:29:31 2008 -0800

    check ADVICE of fadvise64_64 even if get_xip_page is given
    
    I've written some test programs in ltp project.  During writing I met an
    problem which I cannot solve in user land.  So I wrote a patch for linux
    kernel.  Please, include this patch if acceptable.
    
    The test program tests the 4th parameter of fadvise64_64:
    
        long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice);
    
    My test case calls fadvise64_64 with invalid advice value and checks errno is
    set to EINVAL.  About the advice parameter man page says:
    
        ...
        Permissible values for advice include:
    
               POSIX_FADV_NORMAL
                      ...
               POSIX_FADV_SEQUENTIAL
                      ...
               POSIX_FADV_RANDOM
                      ...
               POSIX_FADV_NOREUSE
                      ...
               POSIX_FADV_WILLNEED
                      ...
               POSIX_FADV_DONTNEED
                      ...
        ERRORS
               ...
               EINVAL An invalid value was specified for advice.
    
    However, I got a bug report that the system call invocations
    in my test case returned 0 unexpectedly.
    
    I've inspected the kernel code:
    
        asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
        {
                struct file *file = fget(fd);
                struct address_space *mapping;
                struct backing_dev_info *bdi;
                loff_t endbyte;                     /* inclusive */
                pgoff_t start_index;
                pgoff_t end_index;
                unsigned long nrpages;
                int ret = 0;
    
                if (!file)
                        return -EBADF;
    
                if (S_ISFIFO(file->f_path.dentry->d_inode->i_mode)) {
                        ret = -ESPIPE;
                        goto out;
                }
    
                mapping = file->f_mapping;
                if (!mapping || len < 0) {
                        ret = -EINVAL;
                        goto out;
                }
    
                if (mapping->a_ops->get_xip_page)
                        /* no bad return value, but ignore advice */
                        goto out;
        ...
        out:
                fput(file);
                return ret;
        }
    
    I found the advice parameter is just ignored in the case
    mapping->a_ops->get_xip_page is given. This behavior is different from
    what is written on the man page. Is this o.k.?
    
    get_xip_page is given if CONFIG_EXT2_FS_XIP is true.
    Anyway I cannot find the easy way to detect get_xip_page
    field is given or CONFIG_EXT2_FS_XIP is true from the
    user space.
    
    I propose the following patch which checks the advice parameter
    even if get_xip_page is given.
    
    Signed-off-by: Masatake YAMATO <yamato@redhat.com>
    Acked-by: Carsten Otte <cotte@de.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 0df4c899e979..3c0f1e99f5e4 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -49,9 +49,21 @@ asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 		goto out;
 	}
 
-	if (mapping->a_ops->get_xip_page)
-		/* no bad return value, but ignore advice */
+	if (mapping->a_ops->get_xip_page) {
+		switch (advice) {
+		case POSIX_FADV_NORMAL:
+		case POSIX_FADV_RANDOM:
+		case POSIX_FADV_SEQUENTIAL:
+		case POSIX_FADV_WILLNEED:
+		case POSIX_FADV_NOREUSE:
+		case POSIX_FADV_DONTNEED:
+			/* no bad return value, but ignore advice */
+			break;
+		default:
+			ret = -EINVAL;
+		}
 		goto out;
+	}
 
 	/* Careful about overflows. Len == 0 means "as much as possible" */
 	endbyte = offset + len;

commit d3ac7f892b7d07d61d0895caa4f6e190e43112f8
Author: Josef "Jeff" Sipek <jsipek@cs.sunysb.edu>
Date:   Fri Dec 8 02:36:44 2006 -0800

    [PATCH] mm: change uses of f_{dentry,vfsmnt} to use f_path
    
    Change all the uses of f_{dentry,vfsmnt} to f_path.{dentry,mnt} in linux/mm/.
    
    Signed-off-by: Josef "Jeff" Sipek <jsipek@cs.sunysb.edu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 168c78a121bb..0df4c899e979 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -38,7 +38,7 @@ asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 	if (!file)
 		return -EBADF;
 
-	if (S_ISFIFO(file->f_dentry->d_inode->i_mode)) {
+	if (S_ISFIFO(file->f_path.dentry->d_inode->i_mode)) {
 		ret = -ESPIPE;
 		goto out;
 	}

commit 60c371bc753495f36d3a71338b46030f7fffce3b
Author: Andrew Morton <akpm@osdl.org>
Date:   Sat Aug 5 12:14:25 2006 -0700

    [PATCH] fadvise() make POSIX_FADV_NOREUSE a no-op
    
    The POSIX_FADV_NOREUSE hint means "the application will use this range of the
    file a single time".  It seems to be intended that the implementation will use
    this hint to perform drop-behind of that part of the file when the application
    gets around to reading or writing it.
    
    However for reasons which aren't obvious (or sane?) I mapped
    POSIX_FADV_NOREUSE onto POSIX_FADV_WILLNEED.  ie: it does readahead.
    
    That's daft.  So for now, make POSIX_FADV_NOREUSE a no-op.
    
    This is a non-back-compatible change.  If someone was using POSIX_FADV_NOREUSE
    to perform readahead, they lose.  The likelihood is low.
    
    If/when we later implement POSIX_FADV_NOREUSE things will get interesting - to
    do it fully we'll need to maintain file offset/length ranges and peform all
    sorts of complex tricks, and managing the lifetime of those ranges' data
    structures will be interesting..
    
    A sensible implementation would probably ignore the file range and would
    simply mark the entire file as needing some form of drop-behind treatment.
    
    Cc: Michael Kerrisk <mtk-manpages@gmx.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 60a5d55e51d9..168c78a121bb 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -73,7 +73,6 @@ asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 		file->f_ra.ra_pages = bdi->ra_pages * 2;
 		break;
 	case POSIX_FADV_WILLNEED:
-	case POSIX_FADV_NOREUSE:
 		if (!mapping->a_ops->readpage) {
 			ret = -EINVAL;
 			break;
@@ -94,6 +93,8 @@ asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 		if (ret > 0)
 			ret = 0;
 		break;
+	case POSIX_FADV_NOREUSE:
+		break;
 	case POSIX_FADV_DONTNEED:
 		if (!bdi_write_congested(mapping->backing_dev_info))
 			filemap_flush(mapping);

commit 8f72e4028a1ff968000cec4a034f45619fbd7ec4
Author: Andrew Morton <akpm@osdl.org>
Date:   Mon Jul 10 04:44:01 2006 -0700

    [PATCH] fadvise: remove dead comments
    
    Cc: "Michael Kerrisk" <mtk-manpages@gmx.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 0a03357a1f8e..60a5d55e51d9 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -23,18 +23,6 @@
 /*
  * POSIX_FADV_WILLNEED could set PG_Referenced, and POSIX_FADV_NOREUSE could
  * deactivate the pages and clear PG_Referenced.
- *
- * LINUX_FADV_ASYNC_WRITE: start async writeout of any dirty pages between file
- * offsets `offset' and `offset+len' inclusive.  Any pages which are currently
- * under writeout are skipped, whether or not they are dirty.
- *
- * LINUX_FADV_WRITE_WAIT: wait upon writeout of any dirty pages between file
- * offsets `offset' and `offset+len'.
- *
- * By combining these two operations the application may do several things:
- *
- * LINUX_FADV_ASYNC_WRITE: push some or all of the dirty pages at the disk.
- *
  */
 asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 {

commit f79e2abb9bd452d97295f34376dedbec9686b986
Author: Andrew Morton <akpm@osdl.org>
Date:   Fri Mar 31 02:30:42 2006 -0800

    [PATCH] sys_sync_file_range()
    
    Remove the recently-added LINUX_FADV_ASYNC_WRITE and LINUX_FADV_WRITE_WAIT
    fadvise() additions, do it in a new sys_sync_file_range() syscall instead.
    Reasons:
    
    - It's more flexible.  Things which would require two or three syscalls with
      fadvise() can be done in a single syscall.
    
    - Using fadvise() in this manner is something not covered by POSIX.
    
    The patch wires up the syscall for x86.
    
    The sycall is implemented in the new fs/sync.c.  The intention is that we can
    move sys_fsync(), sys_fdatasync() and perhaps sys_sync() into there later.
    
    Documentation for the syscall is in fs/sync.c.
    
    A test app (sync_file_range.c) is in
    http://www.zip.com.au/~akpm/linux/patches/stuff/ext3-tools.tar.gz.
    
    The available-to-GPL-modules do_sync_file_range() is for knfsd: "A COMMIT can
    say NFS_DATA_SYNC or NFS_FILE_SYNC.  I can skip the ->fsync call for
    NFS_DATA_SYNC which is hopefully the more common."
    
    Note: the `async' writeout mode SYNC_FILE_RANGE_WRITE will turn synchronous if
    the queue is congested.  This is trivial to fix: add a new flag bit, set
    wbc->nonblocking.  But I'm not sure that we want to expose implementation
    details down to that level.
    
    Note: it's notable that we can sync an fd which wasn't opened for writing.
    Same with fsync() and fdatasync()).
    
    Note: the code takes some care to handle attempts to sync file contents
    outside the 16TB offset on 32-bit machines.  It makes such attempts appear to
    succeed, for best 32-bit/64-bit compatibility.  Perhaps it should make such
    requests fail...
    
    Cc: Nick Piggin <nickpiggin@yahoo.com.au>
    Cc: Michael Kerrisk <mtk-manpages@gmx.net>
    Cc: Ulrich Drepper <drepper@redhat.com>
    Cc: Neil Brown <neilb@cse.unsw.edu.au>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 907c39257ca0..0a03357a1f8e 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -35,17 +35,6 @@
  *
  * LINUX_FADV_ASYNC_WRITE: push some or all of the dirty pages at the disk.
  *
- * LINUX_FADV_WRITE_WAIT, LINUX_FADV_ASYNC_WRITE: push all of the currently
- * dirty pages at the disk.
- *
- * LINUX_FADV_WRITE_WAIT, LINUX_FADV_ASYNC_WRITE, LINUX_FADV_WRITE_WAIT: push
- * all of the currently dirty pages at the disk, wait until they have been
- * written.
- *
- * It should be noted that none of these operations write out the file's
- * metadata.  So unless the application is strictly performing overwrites of
- * already-instantiated disk blocks, there are no guarantees here that the data
- * will be available after a crash.
  */
 asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 {
@@ -129,15 +118,6 @@ asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 			invalidate_mapping_pages(mapping, start_index,
 						end_index);
 		break;
-	case LINUX_FADV_ASYNC_WRITE:
-		ret = __filemap_fdatawrite_range(mapping, offset, endbyte,
-						WB_SYNC_NONE);
-		break;
-	case LINUX_FADV_WRITE_WAIT:
-		ret = wait_on_page_writeback_range(mapping,
-					offset >> PAGE_CACHE_SHIFT,
-					endbyte >> PAGE_CACHE_SHIFT);
-		break;
 	default:
 		ret = -EINVAL;
 	}

commit ebcf28e1c7a295f3321249dd235ad2e45938fdd9
Author: Andrew Morton <akpm@osdl.org>
Date:   Fri Mar 24 03:18:04 2006 -0800

    [PATCH] fadvise(): write commands
    
    Add two new linux-specific fadvise extensions():
    
    LINUX_FADV_ASYNC_WRITE: start async writeout of any dirty pages between file
    offsets `offset' and `offset+len'.  Any pages which are currently under
    writeout are skipped, whether or not they are dirty.
    
    LINUX_FADV_WRITE_WAIT: wait upon writeout of any dirty pages between file
    offsets `offset' and `offset+len'.
    
    By combining these two operations the application may do several things:
    
    LINUX_FADV_ASYNC_WRITE: push some or all of the dirty pages at the disk.
    
    LINUX_FADV_WRITE_WAIT, LINUX_FADV_ASYNC_WRITE: push all of the currently dirty
    pages at the disk.
    
    LINUX_FADV_WRITE_WAIT, LINUX_FADV_ASYNC_WRITE, LINUX_FADV_WRITE_WAIT: push all
    of the currently dirty pages at the disk, wait until they have been written.
    
    It should be noted that none of these operations write out the file's
    metadata.  So unless the application is strictly performing overwrites of
    already-instantiated disk blocks, there are no guarantees here that the data
    will be available after a crash.
    
    To complete this suite of operations I guess we should have a "sync file
    metadata only" operation.  This gives applications access to all the building
    blocks needed for all sorts of sync operations.  But sync-metadata doesn't fit
    well with the fadvise() interface.  Probably it should be a new syscall:
    sys_fmetadatasync().
    
    The patch also diddles with the meaning of `endbyte' in sys_fadvise64_64().
    It is made to represent that last affected byte in the file (ie: it is
    inclusive).  Generally, all these byterange and pagerange functions are
    inclusive so we can easily represent EOF with -1.
    
    As Ulrich notes, these two functions are somewhat abusive of the fadvise()
    concept, which appears to be "set the future policy for this fd".
    
    But these commands are a perfect fit with the fadvise() impementation, and
    several of the existing fadvise() commands are synchronous and don't affect
    future policy either.   I think we can live with the slight incongruity.
    
    Cc: Michael Kerrisk <mtk-manpages@gmx.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index d257c89e7704..907c39257ca0 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -15,6 +15,7 @@
 #include <linux/backing-dev.h>
 #include <linux/pagevec.h>
 #include <linux/fadvise.h>
+#include <linux/writeback.h>
 #include <linux/syscalls.h>
 
 #include <asm/unistd.h>
@@ -22,13 +23,36 @@
 /*
  * POSIX_FADV_WILLNEED could set PG_Referenced, and POSIX_FADV_NOREUSE could
  * deactivate the pages and clear PG_Referenced.
+ *
+ * LINUX_FADV_ASYNC_WRITE: start async writeout of any dirty pages between file
+ * offsets `offset' and `offset+len' inclusive.  Any pages which are currently
+ * under writeout are skipped, whether or not they are dirty.
+ *
+ * LINUX_FADV_WRITE_WAIT: wait upon writeout of any dirty pages between file
+ * offsets `offset' and `offset+len'.
+ *
+ * By combining these two operations the application may do several things:
+ *
+ * LINUX_FADV_ASYNC_WRITE: push some or all of the dirty pages at the disk.
+ *
+ * LINUX_FADV_WRITE_WAIT, LINUX_FADV_ASYNC_WRITE: push all of the currently
+ * dirty pages at the disk.
+ *
+ * LINUX_FADV_WRITE_WAIT, LINUX_FADV_ASYNC_WRITE, LINUX_FADV_WRITE_WAIT: push
+ * all of the currently dirty pages at the disk, wait until they have been
+ * written.
+ *
+ * It should be noted that none of these operations write out the file's
+ * metadata.  So unless the application is strictly performing overwrites of
+ * already-instantiated disk blocks, there are no guarantees here that the data
+ * will be available after a crash.
  */
 asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 {
 	struct file *file = fget(fd);
 	struct address_space *mapping;
 	struct backing_dev_info *bdi;
-	loff_t endbyte;
+	loff_t endbyte;			/* inclusive */
 	pgoff_t start_index;
 	pgoff_t end_index;
 	unsigned long nrpages;
@@ -56,6 +80,8 @@ asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 	endbyte = offset + len;
 	if (!len || endbyte < len)
 		endbyte = -1;
+	else
+		endbyte--;		/* inclusive */
 
 	bdi = mapping->backing_dev_info;
 
@@ -78,7 +104,7 @@ asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 
 		/* First and last PARTIAL page! */
 		start_index = offset >> PAGE_CACHE_SHIFT;
-		end_index = (endbyte-1) >> PAGE_CACHE_SHIFT;
+		end_index = endbyte >> PAGE_CACHE_SHIFT;
 
 		/* Careful about overflow on the "+1" */
 		nrpages = end_index - start_index + 1;
@@ -96,11 +122,21 @@ asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 			filemap_flush(mapping);
 
 		/* First and last FULL page! */
-		start_index = (offset + (PAGE_CACHE_SIZE-1)) >> PAGE_CACHE_SHIFT;
+		start_index = (offset+(PAGE_CACHE_SIZE-1)) >> PAGE_CACHE_SHIFT;
 		end_index = (endbyte >> PAGE_CACHE_SHIFT);
 
-		if (end_index > start_index)
-			invalidate_mapping_pages(mapping, start_index, end_index-1);
+		if (end_index >= start_index)
+			invalidate_mapping_pages(mapping, start_index,
+						end_index);
+		break;
+	case LINUX_FADV_ASYNC_WRITE:
+		ret = __filemap_fdatawrite_range(mapping, offset, endbyte,
+						WB_SYNC_NONE);
+		break;
+	case LINUX_FADV_WRITE_WAIT:
+		ret = wait_on_page_writeback_range(mapping,
+					offset >> PAGE_CACHE_SHIFT,
+					endbyte >> PAGE_CACHE_SHIFT);
 		break;
 	default:
 		ret = -EINVAL;

commit 87ba81dba431232548ce29d5d224115d0c2355ac
Author: Valentine Barshak <vbarshak@ru.mvista.com>
Date:   Sun Jan 8 01:03:44 2006 -0800

    [PATCH] fadvise: return ESPIPE on FIFO/pipe
    
    The patch makes posix_fadvise return ESPIPE on FIFO/pipe in order to be
    fully POSIX-compliant.
    
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 5f19e87bc5af..d257c89e7704 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -37,6 +37,11 @@ asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 	if (!file)
 		return -EBADF;
 
+	if (S_ISFIFO(file->f_dentry->d_inode->i_mode)) {
+		ret = -ESPIPE;
+		goto out;
+	}
+
 	mapping = file->f_mapping;
 	if (!mapping || len < 0) {
 		ret = -EINVAL;

commit fe77ba6f4f97690baa4c756611a07f3cc033f6ae
Author: Carsten Otte <cotte@de.ibm.com>
Date:   Thu Jun 23 22:05:29 2005 -0700

    [PATCH] xip: madvice/fadvice: execute in place
    
    Make sys_madvice/fadvice return sane with xip.
    
    Signed-off-by: Carsten Otte <cotte@de.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/mm/fadvise.c b/mm/fadvise.c
index 57264d74b8bf..5f19e87bc5af 100644
--- a/mm/fadvise.c
+++ b/mm/fadvise.c
@@ -43,6 +43,10 @@ asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
 		goto out;
 	}
 
+	if (mapping->a_ops->get_xip_page)
+		/* no bad return value, but ignore advice */
+		goto out;
+
 	/* Careful about overflows. Len == 0 means "as much as possible" */
 	endbyte = offset + len;
 	if (!len || endbyte < len)

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/mm/fadvise.c b/mm/fadvise.c
new file mode 100644
index 000000000000..57264d74b8bf
--- /dev/null
+++ b/mm/fadvise.c
@@ -0,0 +1,111 @@
+/*
+ * mm/fadvise.c
+ *
+ * Copyright (C) 2002, Linus Torvalds
+ *
+ * 11Jan2003	akpm@digeo.com
+ *		Initial version.
+ */
+
+#include <linux/kernel.h>
+#include <linux/file.h>
+#include <linux/fs.h>
+#include <linux/mm.h>
+#include <linux/pagemap.h>
+#include <linux/backing-dev.h>
+#include <linux/pagevec.h>
+#include <linux/fadvise.h>
+#include <linux/syscalls.h>
+
+#include <asm/unistd.h>
+
+/*
+ * POSIX_FADV_WILLNEED could set PG_Referenced, and POSIX_FADV_NOREUSE could
+ * deactivate the pages and clear PG_Referenced.
+ */
+asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)
+{
+	struct file *file = fget(fd);
+	struct address_space *mapping;
+	struct backing_dev_info *bdi;
+	loff_t endbyte;
+	pgoff_t start_index;
+	pgoff_t end_index;
+	unsigned long nrpages;
+	int ret = 0;
+
+	if (!file)
+		return -EBADF;
+
+	mapping = file->f_mapping;
+	if (!mapping || len < 0) {
+		ret = -EINVAL;
+		goto out;
+	}
+
+	/* Careful about overflows. Len == 0 means "as much as possible" */
+	endbyte = offset + len;
+	if (!len || endbyte < len)
+		endbyte = -1;
+
+	bdi = mapping->backing_dev_info;
+
+	switch (advice) {
+	case POSIX_FADV_NORMAL:
+		file->f_ra.ra_pages = bdi->ra_pages;
+		break;
+	case POSIX_FADV_RANDOM:
+		file->f_ra.ra_pages = 0;
+		break;
+	case POSIX_FADV_SEQUENTIAL:
+		file->f_ra.ra_pages = bdi->ra_pages * 2;
+		break;
+	case POSIX_FADV_WILLNEED:
+	case POSIX_FADV_NOREUSE:
+		if (!mapping->a_ops->readpage) {
+			ret = -EINVAL;
+			break;
+		}
+
+		/* First and last PARTIAL page! */
+		start_index = offset >> PAGE_CACHE_SHIFT;
+		end_index = (endbyte-1) >> PAGE_CACHE_SHIFT;
+
+		/* Careful about overflow on the "+1" */
+		nrpages = end_index - start_index + 1;
+		if (!nrpages)
+			nrpages = ~0UL;
+		
+		ret = force_page_cache_readahead(mapping, file,
+				start_index,
+				max_sane_readahead(nrpages));
+		if (ret > 0)
+			ret = 0;
+		break;
+	case POSIX_FADV_DONTNEED:
+		if (!bdi_write_congested(mapping->backing_dev_info))
+			filemap_flush(mapping);
+
+		/* First and last FULL page! */
+		start_index = (offset + (PAGE_CACHE_SIZE-1)) >> PAGE_CACHE_SHIFT;
+		end_index = (endbyte >> PAGE_CACHE_SHIFT);
+
+		if (end_index > start_index)
+			invalidate_mapping_pages(mapping, start_index, end_index-1);
+		break;
+	default:
+		ret = -EINVAL;
+	}
+out:
+	fput(file);
+	return ret;
+}
+
+#ifdef __ARCH_WANT_SYS_FADVISE64
+
+asmlinkage long sys_fadvise64(int fd, loff_t offset, size_t len, int advice)
+{
+	return sys_fadvise64_64(fd, offset, len, advice);
+}
+
+#endif
