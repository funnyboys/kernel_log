commit e31cf2f4ca422ac9b14ecc4a1295b8977a20f812
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Jun 8 21:32:33 2020 -0700

    mm: don't include asm/pgtable.h if linux/mm.h is already included
    
    Patch series "mm: consolidate definitions of page table accessors", v2.
    
    The low level page table accessors (pXY_index(), pXY_offset()) are
    duplicated across all architectures and sometimes more than once.  For
    instance, we have 31 definition of pgd_offset() for 25 supported
    architectures.
    
    Most of these definitions are actually identical and typically it boils
    down to, e.g.
    
    static inline unsigned long pmd_index(unsigned long address)
    {
            return (address >> PMD_SHIFT) & (PTRS_PER_PMD - 1);
    }
    
    static inline pmd_t *pmd_offset(pud_t *pud, unsigned long address)
    {
            return (pmd_t *)pud_page_vaddr(*pud) + pmd_index(address);
    }
    
    These definitions can be shared among 90% of the arches provided
    XYZ_SHIFT, PTRS_PER_XYZ and xyz_page_vaddr() are defined.
    
    For architectures that really need a custom version there is always
    possibility to override the generic version with the usual ifdefs magic.
    
    These patches introduce include/linux/pgtable.h that replaces
    include/asm-generic/pgtable.h and add the definitions of the page table
    accessors to the new header.
    
    This patch (of 12):
    
    The linux/mm.h header includes <asm/pgtable.h> to allow inlining of the
    functions involving page table manipulations, e.g.  pte_alloc() and
    pmd_alloc().  So, there is no point to explicitly include <asm/pgtable.h>
    in the files that include <linux/mm.h>.
    
    The include statements in such cases are remove with a simple loop:
    
            for f in $(git grep -l "include <linux/mm.h>") ; do
                    sed -i -e '/include <asm\/pgtable.h>/ d' $f
            done
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Mike Rapoport <rppt@kernel.org>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200514170327.31389-1-rppt@kernel.org
    Link: http://lkml.kernel.org/r/20200514170327.31389-2-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 76965be1d40e..e8726f3e3820 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -25,7 +25,6 @@
 #include <linux/psi.h>
 #include <linux/uio.h>
 #include <linux/sched/task.h>
-#include <asm/pgtable.h>
 
 static struct bio *get_swap_bio(gfp_t gfp_flags,
 				struct page *page, bio_end_io_t end_io)

commit 30460e1ea3e62f8457e087db9a309ed1031630da
Author: Carlos Maiolino <cmaiolino@redhat.com>
Date:   Thu Jan 9 14:30:41 2020 +0100

    fs: Enable bmap() function to properly return errors
    
    By now, bmap() will either return the physical block number related to
    the requested file offset or 0 in case of error or the requested offset
    maps into a hole.
    This patch makes the needed changes to enable bmap() to proper return
    errors, using the return value as an error return, and now, a pointer
    must be passed to bmap() to be filled with the mapped physical block.
    
    It will change the behavior of bmap() on return:
    
    - negative value in case of error
    - zero on success or map fell into a hole
    
    In case of a hole, the *block will be zero too
    
    Since this is a prep patch, by now, the only error return is -EINVAL if
    ->bmap doesn't exist.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Carlos Maiolino <cmaiolino@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/mm/page_io.c b/mm/page_io.c
index 3a198deb8bb1..76965be1d40e 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -177,8 +177,9 @@ int generic_swapfile_activate(struct swap_info_struct *sis,
 
 		cond_resched();
 
-		first_block = bmap(inode, probe_block);
-		if (first_block == 0)
+		first_block = probe_block;
+		ret = bmap(inode, &first_block);
+		if (ret || !first_block)
 			goto bad_bmap;
 
 		/*
@@ -193,9 +194,11 @@ int generic_swapfile_activate(struct swap_info_struct *sis,
 					block_in_page++) {
 			sector_t block;
 
-			block = bmap(inode, probe_block + block_in_page);
-			if (block == 0)
+			block = probe_block + block_in_page;
+			ret = bmap(inode, &block);
+			if (ret || !block)
 				goto bad_bmap;
+
 			if (block != first_block + block_in_page) {
 				/* Discontiguity */
 				probe_block++;

commit 937790699be9c8100e5358625e7dfa8b32bd33f2
Author: Minchan Kim <minchan@google.com>
Date:   Sat Nov 30 17:58:29 2019 -0800

    mm/page_io.c: annotate refault stalls from swap_readpage
    
    If a block device supports rw_page operation, it doesn't submit bios so
    the annotation in submit_bio() for refault stall doesn't work.  It
    happens with zram in android, especially swap read path which could
    consume CPU cycle for decompress.  It is also a problem for zswap which
    uses frontswap.
    
    Annotate swap_readpage() to account the synchronous IO overhead to
    prevent underreport memory pressure.
    
    [akpm@linux-foundation.org: add comment, per Johannes]
    Link: http://lkml.kernel.org/r/20191010152134.38545-1-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@google.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Shakeel Butt <shakeelb@google.com>
    Cc: Seth Jennings <sjenning@redhat.com>
    Cc: Dan Streetman <ddstreet@ieee.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 60a66a58b9bf..3a198deb8bb1 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -22,6 +22,7 @@
 #include <linux/writeback.h>
 #include <linux/frontswap.h>
 #include <linux/blkdev.h>
+#include <linux/psi.h>
 #include <linux/uio.h>
 #include <linux/sched/task.h>
 #include <asm/pgtable.h>
@@ -354,10 +355,19 @@ int swap_readpage(struct page *page, bool synchronous)
 	struct swap_info_struct *sis = page_swap_info(page);
 	blk_qc_t qc;
 	struct gendisk *disk;
+	unsigned long pflags;
 
 	VM_BUG_ON_PAGE(!PageSwapCache(page) && !synchronous, page);
 	VM_BUG_ON_PAGE(!PageLocked(page), page);
 	VM_BUG_ON_PAGE(PageUptodate(page), page);
+
+	/*
+	 * Count submission time as memory stall. When the device is congested,
+	 * or the submitting cgroup IO-throttled, submission can be a
+	 * significant part of overall IO time.
+	 */
+	psi_memstall_enter(&pflags);
+
 	if (frontswap_load(page) == 0) {
 		SetPageUptodate(page);
 		unlock_page(page);
@@ -371,7 +381,7 @@ int swap_readpage(struct page *page, bool synchronous)
 		ret = mapping->a_ops->readpage(swap_file, page);
 		if (!ret)
 			count_vm_event(PSWPIN);
-		return ret;
+		goto out;
 	}
 
 	ret = bdev_read_page(sis->bdev, swap_page_sector(page), page);
@@ -382,7 +392,7 @@ int swap_readpage(struct page *page, bool synchronous)
 		}
 
 		count_vm_event(PSWPIN);
-		return 0;
+		goto out;
 	}
 
 	ret = 0;
@@ -418,6 +428,7 @@ int swap_readpage(struct page *page, bool synchronous)
 	bio_put(bio);
 
 out:
+	psi_memstall_leave(&pflags);
 	return ret;
 }
 

commit 5df373e95689b9519b8557da7c5bd0db0856d776
Author: Vinayak Menon <vinmenon@codeaurora.org>
Date:   Fri Nov 15 17:35:00 2019 -0800

    mm/page_io.c: do not free shared swap slots
    
    The following race is observed due to which a processes faulting on a
    swap entry, finds the page neither in swapcache nor swap.  This causes
    zram to give a zero filled page that gets mapped to the process,
    resulting in a user space crash later.
    
    Consider parent and child processes Pa and Pb sharing the same swap slot
    with swap_count 2.  Swap is on zram with SWP_SYNCHRONOUS_IO set.
    Virtual address 'VA' of Pa and Pb points to the shared swap entry.
    
    Pa                                       Pb
    
    fault on VA                              fault on VA
    do_swap_page                             do_swap_page
    lookup_swap_cache fails                  lookup_swap_cache fails
                                             Pb scheduled out
    swapin_readahead (deletes zram entry)
    swap_free (makes swap_count 1)
                                             Pb scheduled in
                                             swap_readpage (swap_count == 1)
                                             Takes SWP_SYNCHRONOUS_IO path
                                             zram enrty absent
                                             zram gives a zero filled page
    
    Fix this by making sure that swap slot is freed only when swap count
    drops down to one.
    
    Link: http://lkml.kernel.org/r/1571743294-14285-1-git-send-email-vinmenon@codeaurora.org
    Fixes: aa8d22a11da9 ("mm: swap: SWP_SYNCHRONOUS_IO: skip swapcache only if swapped page has no other reference")
    Signed-off-by: Vinayak Menon <vinmenon@codeaurora.org>
    Suggested-by: Minchan Kim <minchan@google.com>
    Acked-by: Minchan Kim <minchan@kernel.org>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 24ee600f9131..60a66a58b9bf 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -73,6 +73,7 @@ static void swap_slot_free_notify(struct page *page)
 {
 	struct swap_info_struct *sis;
 	struct gendisk *disk;
+	swp_entry_t entry;
 
 	/*
 	 * There is no guarantee that the page is in swap cache - the software
@@ -104,11 +105,10 @@ static void swap_slot_free_notify(struct page *page)
 	 * we again wish to reclaim it.
 	 */
 	disk = sis->bdev->bd_disk;
-	if (disk->fops->swap_slot_free_notify) {
-		swp_entry_t entry;
+	entry.val = page_private(page);
+	if (disk->fops->swap_slot_free_notify && __swap_count(entry) == 1) {
 		unsigned long offset;
 
-		entry.val = page_private(page);
 		offset = swp_offset(entry);
 
 		SetPageDirty(page);

commit 4efaceb1c5f8136d5fec3f26549d294b8e898bd7
Author: Aaron Lu <ziqian.lzq@antfin.com>
Date:   Thu Jul 11 20:55:41 2019 -0700

    mm, swap: use rbtree for swap_extent
    
    swap_extent is used to map swap page offset to backing device's block
    offset.  For a continuous block range, one swap_extent is used and all
    these swap_extents are managed in a linked list.
    
    These swap_extents are used by map_swap_entry() during swap's read and
    write path.  To find out the backing device's block offset for a page
    offset, the swap_extent list will be traversed linearly, with
    curr_swap_extent being used as a cache to speed up the search.
    
    This works well as long as swap_extents are not huge or when the number
    of processes that access swap device are few, but when the swap device
    has many extents and there are a number of processes accessing the swap
    device concurrently, it can be a problem.  On one of our servers, the
    disk's remaining size is tight:
    
      $df -h
      Filesystem      Size  Used Avail Use% Mounted on
      ... ...
      /dev/nvme0n1p1  1.8T  1.3T  504G  72% /home/t4
    
    When creating a 80G swapfile there, there are as many as 84656 swap
    extents.  The end result is, kernel spends abou 30% time in
    map_swap_entry() and swap throughput is only 70MB/s.
    
    As a comparison, when I used smaller sized swapfile, like 4G whose
    swap_extent dropped to 2000, swap throughput is back to 400-500MB/s and
    map_swap_entry() is about 3%.
    
    One downside of using rbtree for swap_extent is, 'struct rbtree' takes
    24 bytes while 'struct list_head' takes 16 bytes, that's 8 bytes more
    for each swap_extent.  For a swapfile that has 80k swap_extents, that
    means 625KiB more memory consumed.
    
    Test:
    
    Since it's not possible to reboot that server, I can not test this patch
    diretly there.  Instead, I tested it on another server with NVMe disk.
    
    I created a 20G swapfile on an NVMe backed XFS fs.  By default, the
    filesystem is quite clean and the created swapfile has only 2 extents.
    Testing vanilla and this patch shows no obvious performance difference
    when swapfile is not fragmented.
    
    To see the patch's effects, I used some tweaks to manually fragment the
    swapfile by breaking the extent at 1M boundary.  This made the swapfile
    have 20K extents.
    
      nr_task=4
      kernel   swapout(KB/s) map_swap_entry(perf)  swapin(KB/s) map_swap_entry(perf)
      vanilla  165191           90.77%             171798          90.21%
      patched  858993 +420%      2.16%             715827 +317%     0.77%
    
      nr_task=8
      kernel   swapout(KB/s) map_swap_entry(perf)  swapin(KB/s) map_swap_entry(perf)
      vanilla  306783           92.19%             318145          87.76%
      patched  954437 +211%      2.35%            1073741 +237%     1.57%
    
    swapout: the throughput of swap out, in KB/s, higher is better 1st
    map_swap_entry: cpu cycles percent sampled by perf swapin: the
    throughput of swap in, in KB/s, higher is better.  2nd map_swap_entry:
    cpu cycles percent sampled by perf
    
    nr_task=1 doesn't show any difference, this is due to the curr_swap_extent
    can be effectively used to cache the correct swap extent for single task
    workload.
    
    [akpm@linux-foundation.org: s/BUG_ON(1)/BUG()/]
    Link: http://lkml.kernel.org/r/20190523142404.GA181@aaronlu
    Signed-off-by: Aaron Lu <ziqian.lzq@antfin.com>
    Cc: Huang Ying <ying.huang@intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index a39aac2f8c8d..24ee600f9131 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -163,7 +163,7 @@ int generic_swapfile_activate(struct swap_info_struct *sis,
 	blocks_per_page = PAGE_SIZE >> blkbits;
 
 	/*
-	 * Map all the blocks into the extent list.  This code doesn't try
+	 * Map all the blocks into the extent tree.  This code doesn't try
 	 * to be very smart.
 	 */
 	probe_block = 0;

commit 8751853091998cd31e9e5f1e8206280155af8921
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Jul 4 15:14:49 2019 -0700

    swap_readpage(): avoid blk_wake_io_task() if !synchronous
    
    swap_readpage() sets waiter = bio->bi_private even if synchronous = F,
    this means that the caller can get the spurious wakeup after return.
    
    This can be fatal if blk_wake_io_task() does
    set_current_state(TASK_RUNNING) after the caller does
    set_special_state(), in the worst case the kernel can crash in
    do_task_dead().
    
    Link: http://lkml.kernel.org/r/20190704160301.GA5956@redhat.com
    Fixes: 0619317ff8baa2d ("block: add polled wakeup task helper")
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Reported-by: Qian Cai <cai@lca.pw>
    Acked-by: Hugh Dickins <hughd@google.com>
    Reviewed-by: Jens Axboe <axboe@kernel.dk>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 189415852077..a39aac2f8c8d 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -137,8 +137,10 @@ static void end_swap_bio_read(struct bio *bio)
 	unlock_page(page);
 	WRITE_ONCE(bio->bi_private, NULL);
 	bio_put(bio);
-	blk_wake_io_task(waiter);
-	put_task_struct(waiter);
+	if (waiter) {
+		blk_wake_io_task(waiter);
+		put_task_struct(waiter);
+	}
 }
 
 int generic_swapfile_activate(struct swap_info_struct *sis,
@@ -395,11 +397,12 @@ int swap_readpage(struct page *page, bool synchronous)
 	 * Keep this task valid during swap readpage because the oom killer may
 	 * attempt to access it in the page fault retry time check.
 	 */
-	get_task_struct(current);
-	bio->bi_private = current;
 	bio_set_op_attrs(bio, REQ_OP_READ, 0);
-	if (synchronous)
+	if (synchronous) {
 		bio->bi_opf |= REQ_HIPRI;
+		get_task_struct(current);
+		bio->bi_private = current;
+	}
 	count_vm_event(PSWPIN);
 	bio_get(bio);
 	qc = submit_bio(bio);

commit 1a5f439c7c02837d943e528d46501564d4226757
Author: Huang Ying <ying.huang@intel.com>
Date:   Fri Jun 28 12:07:18 2019 -0700

    mm, swap: fix THP swap out
    
    0-Day test system reported some OOM regressions for several THP
    (Transparent Huge Page) swap test cases.  These regressions are bisected
    to 6861428921b5 ("block: always define BIO_MAX_PAGES as 256").  In the
    commit, BIO_MAX_PAGES is set to 256 even when THP swap is enabled.  So the
    bio_alloc(gfp_flags, 512) in get_swap_bio() may fail when swapping out
    THP.  That causes the OOM.
    
    As in the patch description of 6861428921b5 ("block: always define
    BIO_MAX_PAGES as 256"), THP swap should use multi-page bvec to write THP
    to swap space.  So the issue is fixed via doing that in get_swap_bio().
    
    BTW: I remember I have checked the THP swap code when 6861428921b5
    ("block: always define BIO_MAX_PAGES as 256") was merged, and thought the
    THP swap code needn't to be changed.  But apparently, I was wrong.  I
    should have done this at that time.
    
    Link: http://lkml.kernel.org/r/20190624075515.31040-1-ying.huang@intel.com
    Fixes: 6861428921b5 ("block: always define BIO_MAX_PAGES as 256")
    Signed-off-by: "Huang, Ying" <ying.huang@intel.com>
    Reviewed-by: Ming Lei <ming.lei@redhat.com>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Daniel Jordan <daniel.m.jordan@oracle.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 2e8019d0e048..189415852077 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -29,10 +29,9 @@
 static struct bio *get_swap_bio(gfp_t gfp_flags,
 				struct page *page, bio_end_io_t end_io)
 {
-	int i, nr = hpage_nr_pages(page);
 	struct bio *bio;
 
-	bio = bio_alloc(gfp_flags, nr);
+	bio = bio_alloc(gfp_flags, 1);
 	if (bio) {
 		struct block_device *bdev;
 
@@ -41,9 +40,7 @@ static struct bio *get_swap_bio(gfp_t gfp_flags,
 		bio->bi_iter.bi_sector <<= PAGE_SHIFT - 9;
 		bio->bi_end_io = end_io;
 
-		for (i = 0; i < nr; i++)
-			bio_add_page(bio, page + i, PAGE_SIZE, 0);
-		VM_BUG_ON(bio->bi_iter.bi_size != PAGE_SIZE * nr);
+		bio_add_page(bio, page, PAGE_SIZE * hpage_nr_pages(page), 0);
 	}
 	return bio;
 }

commit b685a7350ae76bc0f388e24b36d06a63776c68ee
Author: Jens Axboe <axboe@kernel.dk>
Date:   Thu Jan 3 15:29:15 2019 -0800

    mm/page_io.c: fix polled swap page in
    
    swap_readpage() wants to do polling to bring in pages if asked to, but
    it doesn't mark the bio as being polled.  Additionally, the looping
    around the blk_poll() check isn't correct - if we get a zero return, we
    should call io_schedule(), we can't just assume that the bio has
    completed.  The regular bio->bi_private check should be used for that.
    
    Link: http://lkml.kernel.org/r/e15243a8-2cdf-c32c-ecee-f289377c8ef9@kernel.dk
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index d975fa3f02aa..2e8019d0e048 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -401,6 +401,8 @@ int swap_readpage(struct page *page, bool synchronous)
 	get_task_struct(current);
 	bio->bi_private = current;
 	bio_set_op_attrs(bio, REQ_OP_READ, 0);
+	if (synchronous)
+		bio->bi_opf |= REQ_HIPRI;
 	count_vm_event(PSWPIN);
 	bio_get(bio);
 	qc = submit_bio(bio);
@@ -410,7 +412,7 @@ int swap_readpage(struct page *page, bool synchronous)
 			break;
 
 		if (!blk_poll(disk->queue, qc, true))
-			break;
+			io_schedule();
 	}
 	__set_current_state(TASK_RUNNING);
 	bio_put(bio);

commit 1ac5cd4978794bd060d448acc0305e9fc996ba92
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jan 2 10:46:03 2019 -0800

    block: don't use un-ordered __set_current_state(TASK_UNINTERRUPTIBLE)
    
    This mostly reverts commit 849a370016a5 ("block: avoid ordered task
    state change for polled IO").  It was wrongly claiming that the ordering
    wasn't necessary.  The memory barrier _is_ necessary.
    
    If something is truly polling and not going to sleep, it's the whole
    state setting that is unnecessary, not the memory barrier.  Whenever you
    set your state to a sleeping state, you absolutely need the memory
    barrier.
    
    Note that sometimes the memory barrier can be elsewhere.  For example,
    the ordering might be provided by an external lock, or by setting the
    process state to sleeping before adding yourself to the wait queue list
    that is used for waking up (where the wait queue lock itself will
    guarantee that any wakeup will correctly see the sleeping state).
    
    But none of those cases were true here.
    
    NOTE! Some of the polling paths may indeed be able to drop the state
    setting entirely, at which point the memory barrier also goes away.
    
    (Also note that this doesn't revert the TASK_RUNNING cases: there is no
    race between a wakeup and setting the process state to TASK_RUNNING,
    since the end result doesn't depend on ordering).
    
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 3475733b1926..d975fa3f02aa 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -405,8 +405,7 @@ int swap_readpage(struct page *page, bool synchronous)
 	bio_get(bio);
 	qc = submit_bio(bio);
 	while (synchronous) {
-		__set_current_state(TASK_UNINTERRUPTIBLE);
-
+		set_current_state(TASK_UNINTERRUPTIBLE);
 		if (!READ_ONCE(bio->bi_private))
 			break;
 

commit 6a7f6d86a561473032287c8e4583eac5853c6efa
Author: Dennis Zhou <dennis@kernel.org>
Date:   Wed Dec 5 12:10:33 2018 -0500

    blkcg: associate a blkg for pages being evicted by swap
    
    A prior patch in this series added blkg association to bios issued by
    cgroups. There are two other paths that we want to attribute work back
    to the appropriate cgroup: swap and writeback. Here we modify the way
    swap tags bios to include the blkg. Writeback will be tackle in the next
    patch.
    
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/mm/page_io.c b/mm/page_io.c
index 5bdfd21c1bd9..3475733b1926 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -339,7 +339,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		goto out;
 	}
 	bio->bi_opf = REQ_OP_WRITE | REQ_SWAP | wbc_to_write_flags(wbc);
-	bio_associate_blkcg_from_page(bio, page);
+	bio_associate_blkg_from_page(bio, page);
 	count_swpout_vm_event(page);
 	set_page_writeback(page);
 	unlock_page(page);

commit 0a1b8b87d064a47fad9ec475316002da28559207
Author: Jens Axboe <axboe@kernel.dk>
Date:   Mon Nov 26 08:24:43 2018 -0700

    block: make blk_poll() take a parameter on whether to spin or not
    
    blk_poll() has always kept spinning until it found an IO. This is
    fine for SYNC polling, since we need to find one request we have
    pending, but in preparation for ASYNC polling it can be beneficial
    to just check if we have any entries available or not.
    
    Existing callers are converted to pass in 'spin == true', to retain
    the old behavior.
    
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/mm/page_io.c b/mm/page_io.c
index a7271fa481f6..5bdfd21c1bd9 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -410,7 +410,7 @@ int swap_readpage(struct page *page, bool synchronous)
 		if (!READ_ONCE(bio->bi_private))
 			break;
 
-		if (!blk_poll(disk->queue, qc))
+		if (!blk_poll(disk->queue, qc, true))
 			break;
 	}
 	__set_current_state(TASK_RUNNING);

commit 849a370016a5489c49253338507ee6cc4a08df4b
Author: Jens Axboe <axboe@kernel.dk>
Date:   Fri Nov 16 08:37:34 2018 -0700

    block: avoid ordered task state change for polled IO
    
    For the core poll helper, the task state setting don't need to imply any
    atomics, as it's the current task itself that is being modified and
    we're not going to sleep.
    
    For IRQ driven, the wakeup path have the necessary barriers to not need
    us using the heavy handed version of the task state setting.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/mm/page_io.c b/mm/page_io.c
index 57572ff46016..a7271fa481f6 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -405,7 +405,8 @@ int swap_readpage(struct page *page, bool synchronous)
 	bio_get(bio);
 	qc = submit_bio(bio);
 	while (synchronous) {
-		set_current_state(TASK_UNINTERRUPTIBLE);
+		__set_current_state(TASK_UNINTERRUPTIBLE);
+
 		if (!READ_ONCE(bio->bi_private))
 			break;
 

commit 0619317ff8baa2da9238191ad5167ed3618c16d9
Author: Jens Axboe <axboe@kernel.dk>
Date:   Tue Nov 13 21:16:54 2018 -0700

    block: add polled wakeup task helper
    
    If we're polling for IO on a device that doesn't use interrupts, then
    IO completion loop (and wake of task) is done by submitting task itself.
    If that is the case, then we don't need to enter the wake_up_process()
    function, we can simply mark ourselves as TASK_RUNNING.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/mm/page_io.c b/mm/page_io.c
index d4d1c89bcddd..57572ff46016 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -140,7 +140,7 @@ static void end_swap_bio_read(struct bio *bio)
 	unlock_page(page);
 	WRITE_ONCE(bio->bi_private, NULL);
 	bio_put(bio);
-	wake_up_process(waiter);
+	blk_wake_io_task(waiter);
 	put_task_struct(waiter);
 }
 

commit 5f21585384a4a69b8bfdd2cae7e3648ae805f57d
Merge: fcc37f76a995 9fe5c59ff6a1
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 2 11:25:48 2018 -0700

    Merge tag 'for-linus-20181102' of git://git.kernel.dk/linux-block
    
    Pull block layer fixes from Jens Axboe:
     "The biggest part of this pull request is the revert of the blkcg
      cleanup series. It had one fix earlier for a stacked device issue, but
      another one was reported. Rather than play whack-a-mole with this,
      revert the entire series and try again for the next kernel release.
    
      Apart from that, only small fixes/changes.
    
      Summary:
    
       - Indentation fixup for mtip32xx (Colin Ian King)
    
       - The blkcg cleanup series revert (Dennis Zhou)
    
       - Two NVMe fixes. One fixing a regression in the nvme request
         initialization in this merge window, causing nvme-fc to not work.
         The other is a suspend/resume p2p resource issue (James, Keith)
    
       - Fix sg discard merge, allowing us to merge in cases where we didn't
         before (Jianchao Wang)
    
       - Call rq_qos_exit() after the queue is frozen, preventing a hang
         (Ming)
    
       - Fix brd queue setup, fixing an oops if we fail setting up all
         devices (Ming)"
    
    * tag 'for-linus-20181102' of git://git.kernel.dk/linux-block:
      nvme-pci: fix conflicting p2p resource adds
      nvme-fc: fix request private initialization
      blkcg: revert blkcg cleanups series
      block: brd: associate with queue until adding disk
      block: call rq_qos_exit() after queue is frozen
      mtip32xx: clean an indentation issue, remove extraneous tabs
      block: fix the DISCARD request merge

commit 9931a07d518e86eb58a75e508ed9626f86359303
Merge: e468f5c06b5e 0e9b4a827102
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Nov 1 19:58:52 2018 -0700

    Merge branch 'work.afs' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull AFS updates from Al Viro:
     "AFS series, with some iov_iter bits included"
    
    * 'work.afs' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (26 commits)
      missing bits of "iov_iter: Separate type from direction and use accessor functions"
      afs: Probe multiple fileservers simultaneously
      afs: Fix callback handling
      afs: Eliminate the address pointer from the address list cursor
      afs: Allow dumping of server cursor on operation failure
      afs: Implement YFS support in the fs client
      afs: Expand data structure fields to support YFS
      afs: Get the target vnode in afs_rmdir() and get a callback on it
      afs: Calc callback expiry in op reply delivery
      afs: Fix FS.FetchStatus delivery from updating wrong vnode
      afs: Implement the YFS cache manager service
      afs: Remove callback details from afs_callback_break struct
      afs: Commit the status on a new file/dir/symlink
      afs: Increase to 64-bit volume ID and 96-bit vnode ID for YFS
      afs: Don't invoke the server to read data beyond EOF
      afs: Add a couple of tracepoints to log I/O errors
      afs: Handle EIO from delivery function
      afs: Fix TTL on VL server and address lists
      afs: Implement VL server rotation
      afs: Improve FS server rotation error handling
      ...

commit b5f2954d30c77649bce9c27e7a0a94299d9cfdf8
Author: Dennis Zhou <dennis@kernel.org>
Date:   Thu Nov 1 17:24:10 2018 -0400

    blkcg: revert blkcg cleanups series
    
    This reverts a series committed earlier due to null pointer exception
    bug report in [1]. It seems there are edge case interactions that I did
    not consider and will need some time to understand what causes the
    adverse interactions.
    
    The original series can be found in [2] with a follow up series in [3].
    
    [1] https://www.spinics.net/lists/cgroups/msg20719.html
    [2] https://lore.kernel.org/lkml/20180911184137.35897-1-dennisszhou@gmail.com/
    [3] https://lore.kernel.org/lkml/20181020185612.51587-1-dennis@kernel.org/
    
    This reverts the following commits:
    d459d853c2ed, b2c3fa546705, 101246ec02b5, b3b9f24f5fcc, e2b0989954ae,
    f0fcb3ec89f3, c839e7a03f92, bdc2491708c4, 74b7c02a9bc1, 5bf9a1f3b4ef,
    a7b39b4e961c, 07b05bcc3213, 49f4c2dc2b50, 27e6fa996c53
    
    Signed-off-by: Dennis Zhou <dennis@kernel.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/mm/page_io.c b/mm/page_io.c
index 573d3663d846..aafd19ec1db4 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -339,7 +339,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		goto out;
 	}
 	bio->bi_opf = REQ_OP_WRITE | REQ_SWAP | wbc_to_write_flags(wbc);
-	bio_associate_blkg_from_page(bio, page);
+	bio_associate_blkcg_from_page(bio, page);
 	count_swpout_vm_event(page);
 	set_page_writeback(page);
 	unlock_page(page);

commit bc4ae27d817a4e92071ef67cb6368120cfabe7ec
Author: Omar Sandoval <osandov@fb.com>
Date:   Fri Oct 26 15:10:51 2018 -0700

    mm: split SWP_FILE into SWP_ACTIVATED and SWP_FS
    
    The SWP_FILE flag serves two purposes: to make swap_{read,write}page() go
    through the filesystem, and to make swapoff() call ->swap_deactivate().
    For Btrfs, we want the latter but not the former, so split this flag into
    two.  This makes us always call ->swap_deactivate() if ->swap_activate()
    succeeded, not just if it didn't add any swap extents itself.
    
    This also resolves the issue of the very misleading name of SWP_FILE,
    which is only used for swap files over NFS.
    
    Link: http://lkml.kernel.org/r/6d63d8668c4287a4f6d203d65696e96f80abdfc7.1536704650.git.osandov@fb.com
    Signed-off-by: Omar Sandoval <osandov@fb.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: David Sterba <dsterba@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 573d3663d846..a451ffa9491c 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -283,7 +283,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 	struct swap_info_struct *sis = page_swap_info(page);
 
 	VM_BUG_ON_PAGE(!PageSwapCache(page), page);
-	if (sis->flags & SWP_FILE) {
+	if (sis->flags & SWP_FS) {
 		struct kiocb kiocb;
 		struct file *swap_file = sis->swap_file;
 		struct address_space *mapping = swap_file->f_mapping;
@@ -365,7 +365,7 @@ int swap_readpage(struct page *page, bool synchronous)
 		goto out;
 	}
 
-	if (sis->flags & SWP_FILE) {
+	if (sis->flags & SWP_FS) {
 		struct file *swap_file = sis->swap_file;
 		struct address_space *mapping = swap_file->f_mapping;
 
@@ -423,7 +423,7 @@ int swap_set_page_dirty(struct page *page)
 {
 	struct swap_info_struct *sis = page_swap_info(page);
 
-	if (sis->flags & SWP_FILE) {
+	if (sis->flags & SWP_FS) {
 		struct address_space *mapping = sis->swap_file->f_mapping;
 
 		VM_BUG_ON_PAGE(!PageSwapCache(page), page);

commit aa563d7bca6e882ec2bdae24603c8f016401a144
Author: David Howells <dhowells@redhat.com>
Date:   Sat Oct 20 00:57:56 2018 +0100

    iov_iter: Separate type from direction and use accessor functions
    
    In the iov_iter struct, separate the iterator type from the iterator
    direction and use accessor functions to access them in most places.
    
    Convert a bunch of places to use switch-statements to access them rather
    then chains of bitwise-AND statements.  This makes it easier to add further
    iterator types.  Also, this can be more efficient as to implement a switch
    of small contiguous integers, the compiler can use ~50% fewer compare
    instructions than it has to use bitwise-and instructions.
    
    Further, cease passing the iterator type into the iterator setup function.
    The iterator function can set that itself.  Only the direction is required.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

diff --git a/mm/page_io.c b/mm/page_io.c
index aafd19ec1db4..86de453a60cf 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -294,7 +294,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		};
 		struct iov_iter from;
 
-		iov_iter_bvec(&from, ITER_BVEC | WRITE, &bv, 1, PAGE_SIZE);
+		iov_iter_bvec(&from, WRITE, &bv, 1, PAGE_SIZE);
 		init_sync_kiocb(&kiocb, swap_file);
 		kiocb.ki_pos = page_file_offset(page);
 

commit 74b7c02a9bc124ee3df0d77880ee26db0a325516
Author: Dennis Zhou (Facebook) <dennisszhou@gmail.com>
Date:   Tue Sep 11 14:41:31 2018 -0400

    blkcg: associate a blkg for pages being evicted by swap
    
    A prior patch in this series added blkg association to bios issued by
    cgroups. There are two other paths that we want to attribute work back
    to the appropriate cgroup: swap and writeback. Here we modify the way
    swap tags bios to include the blkg. Writeback will be tackle in the next
    patch.
    
    Signed-off-by: Dennis Zhou <dennisszhou@gmail.com>
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/mm/page_io.c b/mm/page_io.c
index aafd19ec1db4..573d3663d846 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -339,7 +339,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		goto out;
 	}
 	bio->bi_opf = REQ_OP_WRITE | REQ_SWAP | wbc_to_write_flags(wbc);
-	bio_associate_blkcg_from_page(bio, page);
+	bio_associate_blkg_from_page(bio, page);
 	count_swpout_vm_event(page);
 	set_page_writeback(page);
 	unlock_page(page);

commit 0d3bd88d54f513723602b361dccfc71639f50779
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Jul 3 11:14:54 2018 -0400

    swap,blkcg: issue swap io with the appropriate context
    
    For backcharging we need to know who the page belongs to when swapping
    it out.  We don't worry about things that do ->rw_page (zram etc) at the
    moment, we're only worried about pages that actually go to a block
    device.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Acked-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/mm/page_io.c b/mm/page_io.c
index a552cb37e220..aafd19ec1db4 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -339,6 +339,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		goto out;
 	}
 	bio->bi_opf = REQ_OP_WRITE | REQ_SWAP | wbc_to_write_flags(wbc);
+	bio_associate_blkcg_from_page(bio, page);
 	count_swpout_vm_event(page);
 	set_page_writeback(page);
 	unlock_page(page);

commit 0d1e0c7cd5909d6c6aa0957179318e13fcca971a
Author: Josef Bacik <jbacik@fb.com>
Date:   Tue Jul 3 11:14:53 2018 -0400

    blk: introduce REQ_SWAP
    
    Just like REQ_META, it's important to know the IO coming down is swap
    in order to guard against potential IO priority inversion issues with
    cgroups.  Add REQ_SWAP and use it for all swap IO, and add it to our
    bio_issue_as_root_blkg helper.
    
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/mm/page_io.c b/mm/page_io.c
index b41cf9644585..a552cb37e220 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -338,7 +338,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		ret = -ENOMEM;
 		goto out;
 	}
-	bio->bi_opf = REQ_OP_WRITE | wbc_to_write_flags(wbc);
+	bio->bi_opf = REQ_OP_WRITE | REQ_SWAP | wbc_to_write_flags(wbc);
 	count_swpout_vm_event(page);
 	set_page_writeback(page);
 	unlock_page(page);

commit 263663cd3c4fbfc40cb7504c4be2dadbc0992cc1
Author: Ming Lei <ming.lei@redhat.com>
Date:   Mon Dec 18 20:22:04 2017 +0800

    block: convert to bio_first_bvec_all & bio_first_page_all
    
    This patch converts to bio_first_bvec_all() & bio_first_page_all() for
    retrieving the 1st bvec/page, and prepares for supporting multipage bvec.
    
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/mm/page_io.c b/mm/page_io.c
index e93f1a4cacd7..b41cf9644585 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -50,7 +50,7 @@ static struct bio *get_swap_bio(gfp_t gfp_flags,
 
 void end_swap_bio_write(struct bio *bio)
 {
-	struct page *page = bio->bi_io_vec[0].bv_page;
+	struct page *page = bio_first_page_all(bio);
 
 	if (bio->bi_status) {
 		SetPageError(page);
@@ -122,7 +122,7 @@ static void swap_slot_free_notify(struct page *page)
 
 static void end_swap_bio_read(struct bio *bio)
 {
-	struct page *page = bio->bi_io_vec[0].bv_page;
+	struct page *page = bio_first_page_all(bio);
 	struct task_struct *waiter = bio->bi_private;
 
 	if (bio->bi_status) {

commit 0bcac06f27d7528591c27ac2b093ccd71c5d0168
Author: Minchan Kim <minchan@kernel.org>
Date:   Wed Nov 15 17:33:07 2017 -0800

    mm, swap: skip swapcache for swapin of synchronous device
    
    With fast swap storage, the platforms want to use swap more aggressively
    and swap-in is crucial to application latency.
    
    The rw_page() based synchronous devices like zram, pmem and btt are such
    fast storage.  When I profile swapin performance with zram lz4
    decompress test, S/W overhead is more than 70%.  Maybe, it would be
    bigger in nvdimm.
    
    This patch aims to reduce swap-in latency by skipping swapcache if the
    swap device is synchronous device like rw_page based device.  It
    enhances 45% my swapin test(5G sequential swapin, no readahead, from
    2.41sec to 1.64sec).
    
    Link: http://lkml.kernel.org/r/1505886205-9671-5-git-send-email-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Ilya Dryomov <idryomov@gmail.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Huang Ying <ying.huang@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index cd52b9cc169b..e93f1a4cacd7 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -347,7 +347,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 	return ret;
 }
 
-int swap_readpage(struct page *page, bool do_poll)
+int swap_readpage(struct page *page, bool synchronous)
 {
 	struct bio *bio;
 	int ret = 0;
@@ -355,7 +355,7 @@ int swap_readpage(struct page *page, bool do_poll)
 	blk_qc_t qc;
 	struct gendisk *disk;
 
-	VM_BUG_ON_PAGE(!PageSwapCache(page), page);
+	VM_BUG_ON_PAGE(!PageSwapCache(page) && !synchronous, page);
 	VM_BUG_ON_PAGE(!PageLocked(page), page);
 	VM_BUG_ON_PAGE(PageUptodate(page), page);
 	if (frontswap_load(page) == 0) {
@@ -403,7 +403,7 @@ int swap_readpage(struct page *page, bool do_poll)
 	count_vm_event(PSWPIN);
 	bio_get(bio);
 	qc = submit_bio(bio);
-	while (do_poll) {
+	while (synchronous) {
 		set_current_state(TASK_UNINTERRUPTIBLE);
 		if (!READ_ONCE(bio->bi_private))
 			break;

commit e2c5923c349c1738fe8fda980874d93f6fb2e5b6
Merge: abc36be23635 a04b5de5050a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 14 15:32:19 2017 -0800

    Merge branch 'for-4.15/block' of git://git.kernel.dk/linux-block
    
    Pull core block layer updates from Jens Axboe:
     "This is the main pull request for block storage for 4.15-rc1.
    
      Nothing out of the ordinary in here, and no API changes or anything
      like that. Just various new features for drivers, core changes, etc.
      In particular, this pull request contains:
    
       - A patch series from Bart, closing the whole on blk/scsi-mq queue
         quescing.
    
       - A series from Christoph, building towards hidden gendisks (for
         multipath) and ability to move bio chains around.
    
       - NVMe
            - Support for native multipath for NVMe (Christoph).
            - Userspace notifications for AENs (Keith).
            - Command side-effects support (Keith).
            - SGL support (Chaitanya Kulkarni)
            - FC fixes and improvements (James Smart)
            - Lots of fixes and tweaks (Various)
    
       - bcache
            - New maintainer (Michael Lyle)
            - Writeback control improvements (Michael)
            - Various fixes (Coly, Elena, Eric, Liang, et al)
    
       - lightnvm updates, mostly centered around the pblk interface
         (Javier, Hans, and Rakesh).
    
       - Removal of unused bio/bvec kmap atomic interfaces (me, Christoph)
    
       - Writeback series that fix the much discussed hundreds of millions
         of sync-all units. This goes all the way, as discussed previously
         (me).
    
       - Fix for missing wakeup on writeback timer adjustments (Yafang
         Shao).
    
       - Fix laptop mode on blk-mq (me).
    
       - {mq,name} tupple lookup for IO schedulers, allowing us to have
         alias names. This means you can use 'deadline' on both !mq and on
         mq (where it's called mq-deadline). (me).
    
       - blktrace race fix, oopsing on sg load (me).
    
       - blk-mq optimizations (me).
    
       - Obscure waitqueue race fix for kyber (Omar).
    
       - NBD fixes (Josef).
    
       - Disable writeback throttling by default on bfq, like we do on cfq
         (Luca Miccio).
    
       - Series from Ming that enable us to treat flush requests on blk-mq
         like any other request. This is a really nice cleanup.
    
       - Series from Ming that improves merging on blk-mq with schedulers,
         getting us closer to flipping the switch on scsi-mq again.
    
       - BFQ updates (Paolo).
    
       - blk-mq atomic flags memory ordering fixes (Peter Z).
    
       - Loop cgroup support (Shaohua).
    
       - Lots of minor fixes from lots of different folks, both for core and
         driver code"
    
    * 'for-4.15/block' of git://git.kernel.dk/linux-block: (294 commits)
      nvme: fix visibility of "uuid" ns attribute
      blk-mq: fixup some comment typos and lengths
      ide: ide-atapi: fix compile error with defining macro DEBUG
      blk-mq: improve tag waiting setup for non-shared tags
      brd: remove unused brd_mutex
      blk-mq: only run the hardware queue if IO is pending
      block: avoid null pointer dereference on null disk
      fs: guard_bio_eod() needs to consider partitions
      xtensa/simdisk: fix compile error
      nvme: expose subsys attribute to sysfs
      nvme: create 'slaves' and 'holders' entries for hidden controllers
      block: create 'slaves' and 'holders' entries for hidden gendisks
      nvme: also expose the namespace identification sysfs files for mpath nodes
      nvme: implement multipath access to nvme subsystems
      nvme: track shared namespaces
      nvme: introduce a nvme_ns_ids structure
      nvme: track subsystems
      block, nvme: Introduce blk_mq_req_flags_t
      block, scsi: Make SCSI quiesce and resume work reliably
      block: Add the QUEUE_FLAG_PREEMPT_ONLY request queue flag
      ...

commit ea435e1b9392a33deceaea2a16ebaa3397bead93
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Nov 2 21:29:54 2017 +0300

    block: add a poll_fn callback to struct request_queue
    
    That we we can also poll non blk-mq queues.  Mostly needed for
    the NVMe multipath code, but could also be useful elsewhere.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/mm/page_io.c b/mm/page_io.c
index 21502d341a67..ff04de630c46 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -407,7 +407,7 @@ int swap_readpage(struct page *page, bool do_poll)
 		if (!READ_ONCE(bio->bi_private))
 			break;
 
-		if (!blk_mq_poll(disk->queue, qc))
+		if (!blk_poll(disk->queue, qc))
 			break;
 	}
 	__set_current_state(TASK_RUNNING);

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 21502d341a67..5d882de3fbfd 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  *  linux/mm/page_io.c
  *

commit a0725ab0c7536076d5477264420ef420ebb64501
Merge: 3ee31b89d9b1 ef13ecbc134d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 7 11:59:42 2017 -0700

    Merge branch 'for-4.14/block' of git://git.kernel.dk/linux-block
    
    Pull block layer updates from Jens Axboe:
     "This is the first pull request for 4.14, containing most of the code
      changes. It's a quiet series this round, which I think we needed after
      the churn of the last few series. This contains:
    
       - Fix for a registration race in loop, from Anton Volkov.
    
       - Overflow complaint fix from Arnd for DAC960.
    
       - Series of drbd changes from the usual suspects.
    
       - Conversion of the stec/skd driver to blk-mq. From Bart.
    
       - A few BFQ improvements/fixes from Paolo.
    
       - CFQ improvement from Ritesh, allowing idling for group idle.
    
       - A few fixes found by Dan's smatch, courtesy of Dan.
    
       - A warning fixup for a race between changing the IO scheduler and
         device remova. From David Jeffery.
    
       - A few nbd fixes from Josef.
    
       - Support for cgroup info in blktrace, from Shaohua.
    
       - Also from Shaohua, new features in the null_blk driver to allow it
         to actually hold data, among other things.
    
       - Various corner cases and error handling fixes from Weiping Zhang.
    
       - Improvements to the IO stats tracking for blk-mq from me. Can
         drastically improve performance for fast devices and/or big
         machines.
    
       - Series from Christoph removing bi_bdev as being needed for IO
         submission, in preparation for nvme multipathing code.
    
       - Series from Bart, including various cleanups and fixes for switch
         fall through case complaints"
    
    * 'for-4.14/block' of git://git.kernel.dk/linux-block: (162 commits)
      kernfs: checking for IS_ERR() instead of NULL
      drbd: remove BIOSET_NEED_RESCUER flag from drbd_{md_,}io_bio_set
      drbd: Fix allyesconfig build, fix recent commit
      drbd: switch from kmalloc() to kmalloc_array()
      drbd: abort drbd_start_resync if there is no connection
      drbd: move global variables to drbd namespace and make some static
      drbd: rename "usermode_helper" to "drbd_usermode_helper"
      drbd: fix race between handshake and admin disconnect/down
      drbd: fix potential deadlock when trying to detach during handshake
      drbd: A single dot should be put into a sequence.
      drbd: fix rmmod cleanup, remove _all_ debugfs entries
      drbd: Use setup_timer() instead of init_timer() to simplify the code.
      drbd: fix potential get_ldev/put_ldev refcount imbalance during attach
      drbd: new disk-option disable-write-same
      drbd: Fix resource role for newly created resources in events2
      drbd: mark symbols static where possible
      drbd: Send P_NEG_ACK upon write error in protocol != C
      drbd: add explicit plugging when submitting batches
      drbd: change list_for_each_safe to while(list_first_entry_or_null)
      drbd: introduce drbd_recv_header_maybe_unplug
      ...

commit 225311a46411c37e20e73d99f4382f141e12f6f9
Author: Huang Ying <ying.huang@intel.com>
Date:   Wed Sep 6 16:22:30 2017 -0700

    mm: test code to write THP to swap device as a whole
    
    To support delay splitting THP (Transparent Huge Page) after swapped
    out, we need to enhance swap writing code to support to write a THP as a
    whole.  This will improve swap write IO performance.
    
    As Ming Lei <ming.lei@redhat.com> pointed out, this should be based on
    multipage bvec support, which hasn't been merged yet.  So this patch is
    only for testing the functionality of the other patches in the series.
    And will be reimplemented after multipage bvec support is merged.
    
    Link: http://lkml.kernel.org/r/20170724051840.2309-7-ying.huang@intel.com
    Signed-off-by: "Huang, Ying" <ying.huang@intel.com>
    Cc: "Kirill A . Shutemov" <kirill.shutemov@linux.intel.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Ross Zwisler <ross.zwisler@intel.com> [for brd.c, zram_drv.c, pmem.c]
    Cc: Shaohua Li <shli@kernel.org>
    Cc: Vishal L Verma <vishal.l.verma@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 5f61b54ee1f3..20139b90125a 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -28,16 +28,18 @@
 static struct bio *get_swap_bio(gfp_t gfp_flags,
 				struct page *page, bio_end_io_t end_io)
 {
+	int i, nr = hpage_nr_pages(page);
 	struct bio *bio;
 
-	bio = bio_alloc(gfp_flags, 1);
+	bio = bio_alloc(gfp_flags, nr);
 	if (bio) {
 		bio->bi_iter.bi_sector = map_swap_page(page, &bio->bi_bdev);
 		bio->bi_iter.bi_sector <<= PAGE_SHIFT - 9;
 		bio->bi_end_io = end_io;
 
-		bio_add_page(bio, page, PAGE_SIZE, 0);
-		BUG_ON(bio->bi_iter.bi_size != PAGE_SIZE);
+		for (i = 0; i < nr; i++)
+			bio_add_page(bio, page + i, PAGE_SIZE, 0);
+		VM_BUG_ON(bio->bi_iter.bi_size != PAGE_SIZE * nr);
 	}
 	return bio;
 }
@@ -262,6 +264,15 @@ static sector_t swap_page_sector(struct page *page)
 	return (sector_t)__page_file_index(page) << (PAGE_SHIFT - 9);
 }
 
+static inline void count_swpout_vm_event(struct page *page)
+{
+#ifdef CONFIG_TRANSPARENT_HUGEPAGE
+	if (unlikely(PageTransHuge(page)))
+		count_vm_event(THP_SWPOUT);
+#endif
+	count_vm_events(PSWPOUT, hpage_nr_pages(page));
+}
+
 int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		bio_end_io_t end_write_func)
 {
@@ -313,7 +324,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 
 	ret = bdev_write_page(sis->bdev, swap_page_sector(page), page, wbc);
 	if (!ret) {
-		count_vm_event(PSWPOUT);
+		count_swpout_vm_event(page);
 		return 0;
 	}
 
@@ -326,7 +337,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		goto out;
 	}
 	bio->bi_opf = REQ_OP_WRITE | wbc_to_write_flags(wbc);
-	count_vm_event(PSWPOUT);
+	count_swpout_vm_event(page);
 	set_page_writeback(page);
 	unlock_page(page);
 	submit_bio(bio);

commit 74d46992e0d9dee7f1f376de0d56d31614c8a17a
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Aug 23 19:10:32 2017 +0200

    block: replace bi_bdev with a gendisk pointer and partitions index
    
    This way we don't need a block_device structure to submit I/O.  The
    block_device has different life time rules from the gendisk and
    request_queue and is usually only available when the block device node
    is open.  Other callers need to explicitly create one (e.g. the lightnvm
    passthrough code, or the new nvme multipathing code).
    
    For the actual I/O path all that we need is the gendisk, which exists
    once per block device.  But given that the block layer also does
    partition remapping we additionally need a partition index, which is
    used for said remapping in generic_make_request.
    
    Note that all the block drivers generally want request_queue or
    sometimes the gendisk, so this removes a layer of indirection all
    over the stack.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

diff --git a/mm/page_io.c b/mm/page_io.c
index b6c4ac388209..9cf1bc751d79 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -31,7 +31,10 @@ static struct bio *get_swap_bio(gfp_t gfp_flags,
 
 	bio = bio_alloc(gfp_flags, 1);
 	if (bio) {
-		bio->bi_iter.bi_sector = map_swap_page(page, &bio->bi_bdev);
+		struct block_device *bdev;
+
+		bio->bi_iter.bi_sector = map_swap_page(page, &bdev);
+		bio_set_dev(bio, bdev);
 		bio->bi_iter.bi_sector <<= PAGE_SHIFT - 9;
 		bio->bi_end_io = end_io;
 
@@ -57,8 +60,7 @@ void end_swap_bio_write(struct bio *bio)
 		 */
 		set_page_dirty(page);
 		pr_alert("Write-error on swap-device (%u:%u:%llu)\n",
-			 imajor(bio->bi_bdev->bd_inode),
-			 iminor(bio->bi_bdev->bd_inode),
+			 MAJOR(bio_dev(bio)), MINOR(bio_dev(bio)),
 			 (unsigned long long)bio->bi_iter.bi_sector);
 		ClearPageReclaim(page);
 	}
@@ -123,8 +125,7 @@ static void end_swap_bio_read(struct bio *bio)
 		SetPageError(page);
 		ClearPageUptodate(page);
 		pr_alert("Read-error on swap-device (%u:%u:%llu)\n",
-			 imajor(bio->bi_bdev->bd_inode),
-			 iminor(bio->bi_bdev->bd_inode),
+			 MAJOR(bio_dev(bio)), MINOR(bio_dev(bio)),
 			 (unsigned long long)bio->bi_iter.bi_sector);
 		goto out;
 	}
@@ -338,7 +339,7 @@ int swap_readpage(struct page *page, bool do_poll)
 	int ret = 0;
 	struct swap_info_struct *sis = page_swap_info(page);
 	blk_qc_t qc;
-	struct block_device *bdev;
+	struct gendisk *disk;
 
 	VM_BUG_ON_PAGE(!PageSwapCache(page), page);
 	VM_BUG_ON_PAGE(!PageLocked(page), page);
@@ -377,7 +378,7 @@ int swap_readpage(struct page *page, bool do_poll)
 		ret = -ENOMEM;
 		goto out;
 	}
-	bdev = bio->bi_bdev;
+	disk = bio->bi_disk;
 	bio->bi_private = current;
 	bio_set_op_attrs(bio, REQ_OP_READ, 0);
 	count_vm_event(PSWPIN);
@@ -388,7 +389,7 @@ int swap_readpage(struct page *page, bool do_poll)
 		if (!READ_ONCE(bio->bi_private))
 			break;
 
-		if (!blk_mq_poll(bdev_get_queue(bdev), qc))
+		if (!blk_mq_poll(disk->queue, qc))
 			break;
 	}
 	__set_current_state(TASK_RUNNING);

commit b0ba2d0faf6520dd0e534a9410114e043e9ab084
Author: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
Date:   Wed Aug 2 13:32:09 2017 -0700

    mm/page_io.c: fix oops during block io poll in swapin path
    
    When a thread is OOM-killed during swap_readpage() operation, an oops
    occurs because end_swap_bio_read() is calling wake_up_process() based on
    an assumption that the thread which called swap_readpage() is still
    alive.
    
      Out of memory: Kill process 525 (polkitd) score 0 or sacrifice child
      Killed process 525 (polkitd) total-vm:528128kB, anon-rss:0kB, file-rss:4kB, shmem-rss:0kB
      oom_reaper: reaped process 525 (polkitd), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB
      general protection fault: 0000 [#1] SMP DEBUG_PAGEALLOC
      Modules linked in: nf_conntrack_netbios_ns nf_conntrack_broadcast ip6t_rpfilter ipt_REJECT nf_reject_ipv4 ip6t_REJECT nf_reject_ipv6 xt_conntrack ip_set nfnetlink ebtable_nat ebtable_broute bridge stp llc ip6table_nat nf_conntrack_ipv6 nf_defrag_ipv6 nf_nat_ipv6 ip6table_mangle ip6table_raw iptable_nat nf_conntrack_ipv4 nf_defrag_ipv4 nf_nat_ipv4 nf_nat nf_conntrack iptable_mangle iptable_raw ebtable_filter ebtables ip6table_filter ip6_tables iptable_filter coretemp ppdev pcspkr vmw_balloon sg shpchp vmw_vmci parport_pc parport i2c_piix4 ip_tables xfs libcrc32c sd_mod sr_mod cdrom ata_generic pata_acpi vmwgfx ahci libahci drm_kms_helper ata_piix syscopyarea sysfillrect sysimgblt fb_sys_fops mptspi scsi_transport_spi ttm e1000 mptscsih drm mptbase i2c_core libata serio_raw
      CPU: 0 PID: 0 Comm: swapper/0 Not tainted 4.13.0-rc2-next-20170725 #129
      Hardware name: VMware, Inc. VMware Virtual Platform/440BX Desktop Reference Platform, BIOS 6.00 07/31/2013
      task: ffffffffb7c16500 task.stack: ffffffffb7c00000
      RIP: 0010:__lock_acquire+0x151/0x12f0
      Call Trace:
       <IRQ>
       lock_acquire+0x59/0x80
       _raw_spin_lock_irqsave+0x3b/0x4f
       try_to_wake_up+0x3b/0x410
       wake_up_process+0x10/0x20
       end_swap_bio_read+0x6f/0xf0
       bio_endio+0x92/0xb0
       blk_update_request+0x88/0x270
       scsi_end_request+0x32/0x1c0
       scsi_io_completion+0x209/0x680
       scsi_finish_command+0xd4/0x120
       scsi_softirq_done+0x120/0x140
       __blk_mq_complete_request_remote+0xe/0x10
       flush_smp_call_function_queue+0x51/0x120
       generic_smp_call_function_single_interrupt+0xe/0x20
       smp_trace_call_function_single_interrupt+0x22/0x30
       smp_call_function_single_interrupt+0x9/0x10
       call_function_single_interrupt+0xa7/0xb0
       </IRQ>
      RIP: 0010:native_safe_halt+0x6/0x10
       default_idle+0xe/0x20
       arch_cpu_idle+0xa/0x10
       default_idle_call+0x1e/0x30
       do_idle+0x187/0x200
       cpu_startup_entry+0x6e/0x70
       rest_init+0xd0/0xe0
       start_kernel+0x456/0x477
       x86_64_start_reservations+0x24/0x26
       x86_64_start_kernel+0xf7/0x11a
       secondary_startup_64+0xa5/0xa5
      Code: c3 49 81 3f 20 9e 0b b8 41 bc 00 00 00 00 44 0f 45 e2 83 fe 01 0f 87 62 ff ff ff 89 f0 49 8b 44 c7 08 48 85 c0 0f 84 52 ff ff ff <f0> ff 80 98 01 00 00 8b 3d 5a 49 c4 01 45 8b b3 18 0c 00 00 85
      RIP: __lock_acquire+0x151/0x12f0 RSP: ffffa01f39e03c50
      ---[ end trace 6c441db499169b1e ]---
      Kernel panic - not syncing: Fatal exception in interrupt
      Kernel Offset: 0x36000000 from 0xffffffff81000000 (relocation range: 0xffffffff80000000-0xffffffffbfffffff)
      ---[ end Kernel panic - not syncing: Fatal exception in interrupt
    
    Fix it by holding a reference to the thread.
    
    [akpm@linux-foundation.org: add comment]
    Fixes: 23955622ff8d231b ("swap: add block io poll in swapin path")
    Signed-off-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
    Reviewed-by: Shaohua Li <shli@fb.com>
    Cc: Tim Chen <tim.c.chen@intel.com>
    Cc: Huang Ying <ying.huang@intel.com>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index b6c4ac388209..5f61b54ee1f3 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -22,6 +22,7 @@
 #include <linux/frontswap.h>
 #include <linux/blkdev.h>
 #include <linux/uio.h>
+#include <linux/sched/task.h>
 #include <asm/pgtable.h>
 
 static struct bio *get_swap_bio(gfp_t gfp_flags,
@@ -136,6 +137,7 @@ static void end_swap_bio_read(struct bio *bio)
 	WRITE_ONCE(bio->bi_private, NULL);
 	bio_put(bio);
 	wake_up_process(waiter);
+	put_task_struct(waiter);
 }
 
 int generic_swapfile_activate(struct swap_info_struct *sis,
@@ -378,6 +380,11 @@ int swap_readpage(struct page *page, bool do_poll)
 		goto out;
 	}
 	bdev = bio->bi_bdev;
+	/*
+	 * Keep this task valid during swap readpage because the oom killer may
+	 * attempt to access it in the page fault retry time check.
+	 */
+	get_task_struct(current);
 	bio->bi_private = current;
 	bio_set_op_attrs(bio, REQ_OP_READ, 0);
 	count_vm_event(PSWPIN);

commit 23955622ff8d231bcc9650b3d06583f117a6e3ba
Author: Shaohua Li <shli@fb.com>
Date:   Mon Jul 10 15:47:11 2017 -0700

    swap: add block io poll in swapin path
    
    For fast flash disk, async IO could introduce overhead because of
    context switch.  block-mq now supports IO poll, which improves
    performance and latency a lot.  swapin is a good place to use this
    technique, because the task is waiting for the swapin page to continue
    execution.
    
    In my virtual machine, directly read 4k data from a NVMe with iopoll is
    about 60% better than that without poll.  With iopoll support in swapin
    patch, my microbenchmark (a task does random memory write) is about
    10%~25% faster.  CPU utilization increases a lot though, 2x and even 3x
    CPU utilization.  This will depend on disk speed.
    
    While iopoll in swapin isn't intended for all usage cases, it's a win
    for latency sensistive workloads with high speed swap disk.  block layer
    has knob to control poll in runtime.  If poll isn't enabled in block
    layer, there should be no noticeable change in swapin.
    
    I got a chance to run the same test in a NVMe with DRAM as the media.
    In simple fio IO test, blkpoll boosts 50% performance in single thread
    test and ~20% in 8 threads test.  So this is the base line.  In above
    swap test, blkpoll boosts ~27% performance in single thread test.
    blkpoll uses 2x CPU time though.
    
    If we enable hybid polling, the performance gain has very slight drop
    but CPU time is only 50% worse than that without blkpoll.  Also we can
    adjust parameter of hybid poll, with it, the CPU time penality is
    reduced further.  In 8 threads test, blkpoll doesn't help though.  The
    performance is similar to that without blkpoll, but cpu utilization is
    similar too.  There is lock contention in swap path.  The cpu time
    spending on blkpoll isn't high.  So overall, blkpoll swapin isn't worse
    than that without it.
    
    The swapin readahead might read several pages in in the same time and
    form a big IO request.  Since the IO will take longer time, it doesn't
    make sense to do poll, so the patch only does iopoll for single page
    swapin.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Link: http://lkml.kernel.org/r/070c3c3e40b711e7b1390002c991e86a-b5408f0@7511894063d3764ff01ea8111f5a004d7dd700ed078797c204a24e620ddb965c
    Signed-off-by: Shaohua Li <shli@fb.com>
    Cc: Tim Chen <tim.c.chen@intel.com>
    Cc: Huang Ying <ying.huang@intel.com>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 2da71e627812..b6c4ac388209 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -117,6 +117,7 @@ static void swap_slot_free_notify(struct page *page)
 static void end_swap_bio_read(struct bio *bio)
 {
 	struct page *page = bio->bi_io_vec[0].bv_page;
+	struct task_struct *waiter = bio->bi_private;
 
 	if (bio->bi_status) {
 		SetPageError(page);
@@ -132,7 +133,9 @@ static void end_swap_bio_read(struct bio *bio)
 	swap_slot_free_notify(page);
 out:
 	unlock_page(page);
+	WRITE_ONCE(bio->bi_private, NULL);
 	bio_put(bio);
+	wake_up_process(waiter);
 }
 
 int generic_swapfile_activate(struct swap_info_struct *sis,
@@ -329,11 +332,13 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 	return ret;
 }
 
-int swap_readpage(struct page *page)
+int swap_readpage(struct page *page, bool do_poll)
 {
 	struct bio *bio;
 	int ret = 0;
 	struct swap_info_struct *sis = page_swap_info(page);
+	blk_qc_t qc;
+	struct block_device *bdev;
 
 	VM_BUG_ON_PAGE(!PageSwapCache(page), page);
 	VM_BUG_ON_PAGE(!PageLocked(page), page);
@@ -372,9 +377,23 @@ int swap_readpage(struct page *page)
 		ret = -ENOMEM;
 		goto out;
 	}
+	bdev = bio->bi_bdev;
+	bio->bi_private = current;
 	bio_set_op_attrs(bio, REQ_OP_READ, 0);
 	count_vm_event(PSWPIN);
-	submit_bio(bio);
+	bio_get(bio);
+	qc = submit_bio(bio);
+	while (do_poll) {
+		set_current_state(TASK_UNINTERRUPTIBLE);
+		if (!READ_ONCE(bio->bi_private))
+			break;
+
+		if (!blk_mq_poll(bdev_get_queue(bdev), qc))
+			break;
+	}
+	__set_current_state(TASK_RUNNING);
+	bio_put(bio);
+
 out:
 	return ret;
 }

commit 4e4cbee93d56137ebff722be022cae5f70ef84fb
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jun 3 09:38:06 2017 +0200

    block: switch bios to blk_status_t
    
    Replace bi_error with a new bi_status to allow for a clear conversion.
    Note that device mapper overloaded bi_error with a private value, which
    we'll have to keep arround at least for now and thus propagate to a
    proper blk_status_t value.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/mm/page_io.c b/mm/page_io.c
index 23f6d0d3470f..2da71e627812 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -45,7 +45,7 @@ void end_swap_bio_write(struct bio *bio)
 {
 	struct page *page = bio->bi_io_vec[0].bv_page;
 
-	if (bio->bi_error) {
+	if (bio->bi_status) {
 		SetPageError(page);
 		/*
 		 * We failed to write the page out to swap-space.
@@ -118,7 +118,7 @@ static void end_swap_bio_read(struct bio *bio)
 {
 	struct page *page = bio->bi_io_vec[0].bv_page;
 
-	if (bio->bi_error) {
+	if (bio->bi_status) {
 		SetPageError(page);
 		ClearPageUptodate(page);
 		pr_alert("Read-error on swap-device (%u:%u:%llu)\n",

commit 7637241e651ec36e409412869f986dd5f097735f
Author: Jens Axboe <axboe@fb.com>
Date:   Tue Nov 1 10:00:38 2016 -0600

    writeback: add wbc_to_write_flags()
    
    Add wbc_to_write_flags(), which returns the write modifier flags to use,
    based on a struct writeback_control. No functional changes in this
    patch, but it prepares us for factoring other wbc fields for write type.
    
    Signed-off-by: Jens Axboe <axboe@fb.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Christoph Hellwig <hch@lst.de>

diff --git a/mm/page_io.c b/mm/page_io.c
index a2651f58c86a..23f6d0d3470f 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -320,10 +320,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		ret = -ENOMEM;
 		goto out;
 	}
-	if (wbc->sync_mode == WB_SYNC_ALL)
-		bio_set_op_attrs(bio, REQ_OP_WRITE, REQ_SYNC);
-	else
-		bio_set_op_attrs(bio, REQ_OP_WRITE, 0);
+	bio->bi_opf = REQ_OP_WRITE | wbc_to_write_flags(wbc);
 	count_vm_event(PSWPOUT);
 	set_page_writeback(page);
 	unlock_page(page);

commit cc30c5d6461a2813406f7f84d581643781922a82
Author: Andrew Morton <akpm@linux-foundation.org>
Date:   Fri Oct 7 17:00:52 2016 -0700

    mm/page_io.c: replace some BUG_ON()s with VM_BUG_ON_PAGE()
    
    So they are CONFIG_DEBUG_VM-only and more informative.
    
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: Joe Perches <joe@perches.com>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Santosh Shilimkar <santosh.shilimkar@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index eafe5ddc2b54..a2651f58c86a 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -264,7 +264,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 	int ret;
 	struct swap_info_struct *sis = page_swap_info(page);
 
-	BUG_ON(!PageSwapCache(page));
+	VM_BUG_ON_PAGE(!PageSwapCache(page), page);
 	if (sis->flags & SWP_FILE) {
 		struct kiocb kiocb;
 		struct file *swap_file = sis->swap_file;
@@ -338,7 +338,7 @@ int swap_readpage(struct page *page)
 	int ret = 0;
 	struct swap_info_struct *sis = page_swap_info(page);
 
-	BUG_ON(!PageSwapCache(page));
+	VM_BUG_ON_PAGE(!PageSwapCache(page), page);
 	VM_BUG_ON_PAGE(!PageLocked(page), page);
 	VM_BUG_ON_PAGE(PageUptodate(page), page);
 	if (frontswap_load(page) == 0) {
@@ -388,7 +388,8 @@ int swap_set_page_dirty(struct page *page)
 
 	if (sis->flags & SWP_FILE) {
 		struct address_space *mapping = sis->swap_file->f_mapping;
-		BUG_ON(!PageSwapCache(page));
+
+		VM_BUG_ON_PAGE(!PageSwapCache(page), page);
 		return mapping->a_ops->set_page_dirty(page);
 	} else {
 		return __set_page_dirty_no_writeback(page);

commit c8de641b1e9c5489aa6ca57b7836acd68e7563f1
Author: Santosh Shilimkar <santosh.shilimkar@oracle.com>
Date:   Mon Sep 19 14:44:15 2016 -0700

    mm: fix the page_swap_info() BUG_ON check
    
    Commit 62c230bc1790 ("mm: add support for a filesystem to activate
    swap files and use direct_IO for writing swap pages") replaced the
    swap_aops dirty hook from __set_page_dirty_no_writeback() with
    swap_set_page_dirty().
    
    For normal cases without these special SWP flags code path falls back to
    __set_page_dirty_no_writeback() so the behaviour is expected to be the
    same as before.
    
    But swap_set_page_dirty() makes use of the page_swap_info() helper to
    get the swap_info_struct to check for the flags like SWP_FILE,
    SWP_BLKDEV etc as desired for those features.  This helper has
    BUG_ON(!PageSwapCache(page)) which is racy and safe only for the
    set_page_dirty_lock() path.
    
    For the set_page_dirty() path which is often needed for cases to be
    called from irq context, kswapd() can toggle the flag behind the back
    while the call is getting executed when system is low on memory and
    heavy swapping is ongoing.
    
    This ends up with undesired kernel panic.
    
    This patch just moves the check outside the helper to its users
    appropriately to fix kernel panic for the described path.  Couple of
    users of helpers already take care of SwapCache condition so I skipped
    them.
    
    Link: http://lkml.kernel.org/r/1473460718-31013-1-git-send-email-santosh.shilimkar@oracle.com
    Signed-off-by: Santosh Shilimkar <santosh.shilimkar@oracle.com>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Joe Perches <joe@perches.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: <stable@vger.kernel.org>    [4.7.x]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 16bd82fad38c..eafe5ddc2b54 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -264,6 +264,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 	int ret;
 	struct swap_info_struct *sis = page_swap_info(page);
 
+	BUG_ON(!PageSwapCache(page));
 	if (sis->flags & SWP_FILE) {
 		struct kiocb kiocb;
 		struct file *swap_file = sis->swap_file;
@@ -337,6 +338,7 @@ int swap_readpage(struct page *page)
 	int ret = 0;
 	struct swap_info_struct *sis = page_swap_info(page);
 
+	BUG_ON(!PageSwapCache(page));
 	VM_BUG_ON_PAGE(!PageLocked(page), page);
 	VM_BUG_ON_PAGE(PageUptodate(page), page);
 	if (frontswap_load(page) == 0) {
@@ -386,6 +388,7 @@ int swap_set_page_dirty(struct page *page)
 
 	if (sis->flags & SWP_FILE) {
 		struct address_space *mapping = sis->swap_file->f_mapping;
+		BUG_ON(!PageSwapCache(page));
 		return mapping->a_ops->set_page_dirty(page);
 	} else {
 		return __set_page_dirty_no_writeback(page);

commit ba13e83ec334ca8a1c6bec882a6efc98d8bf355d
Author: Jens Axboe <axboe@fb.com>
Date:   Mon Aug 1 09:38:44 2016 -0600

    mm: make __swap_writepage() use bio_set_op_attrs()
    
    Cleaner than manipulating bio->bi_rw flags directly.
    
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/mm/page_io.c b/mm/page_io.c
index fb1fa269d3a0..16bd82fad38c 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -319,9 +319,10 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		ret = -ENOMEM;
 		goto out;
 	}
-	bio_set_op_attrs(bio, REQ_OP_WRITE, 0);
 	if (wbc->sync_mode == WB_SYNC_ALL)
-		bio->bi_rw |= REQ_SYNC;
+		bio_set_op_attrs(bio, REQ_OP_WRITE, REQ_SYNC);
+	else
+		bio_set_op_attrs(bio, REQ_OP_WRITE, 0);
 	count_vm_event(PSWPOUT);
 	set_page_writeback(page);
 	unlock_page(page);

commit 7e4411bfe6dd29713f879717b433304a1992526d
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Thu Jul 28 15:48:47 2016 -0700

    mm: add cond_resched() to generic_swapfile_activate()
    
    generic_swapfile_activate() can take quite long time, it iterates over
    all blocks of a file, so add cond_resched to it.  I observed about 1
    second stalls when activating a swapfile that was almost unfragmented -
    this patch fixes it.
    
    Link: http://lkml.kernel.org/r/alpine.LRH.2.02.1607221710580.4818@file01.intranet.prod.int.rdu2.redhat.com
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index dcc5d3769608..fb1fa269d3a0 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -166,6 +166,8 @@ int generic_swapfile_activate(struct swap_info_struct *sis,
 		unsigned block_in_page;
 		sector_t first_block;
 
+		cond_resched();
+
 		first_block = bmap(inode, probe_block);
 		if (first_block == 0)
 			goto bad_bmap;

commit 95fe6c1a209ef89d9f94dd04a0ad72be1487d5d5
Author: Mike Christie <mchristi@redhat.com>
Date:   Sun Jun 5 14:31:48 2016 -0500

    block, fs, mm, drivers: use bio set/get op accessors
    
    This patch converts the simple bi_rw use cases in the block,
    drivers, mm and fs code to set/get the bio operation using
    bio_set_op_attrs/bio_op
    
    These should be simple one or two liner cases, so I just did them
    in one patch. The next patches handle the more complicated
    cases in a module per patch.
    
    Signed-off-by: Mike Christie <mchristi@redhat.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/mm/page_io.c b/mm/page_io.c
index 5a5fd66d7bd5..dcc5d3769608 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -317,7 +317,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		ret = -ENOMEM;
 		goto out;
 	}
-	bio->bi_rw = WRITE;
+	bio_set_op_attrs(bio, REQ_OP_WRITE, 0);
 	if (wbc->sync_mode == WB_SYNC_ALL)
 		bio->bi_rw |= REQ_SYNC;
 	count_vm_event(PSWPOUT);
@@ -370,7 +370,7 @@ int swap_readpage(struct page *page)
 		ret = -ENOMEM;
 		goto out;
 	}
-	bio->bi_rw = READ;
+	bio_set_op_attrs(bio, REQ_OP_READ, 0);
 	count_vm_event(PSWPIN);
 	submit_bio(bio);
 out:

commit 4e49ea4a3d276365bf7396c9b77b4d1d5923835a
Author: Mike Christie <mchristi@redhat.com>
Date:   Sun Jun 5 14:31:41 2016 -0500

    block/fs/drivers: remove rw argument from submit_bio
    
    This has callers of submit_bio/submit_bio_wait set the bio->bi_rw
    instead of passing it in. This makes that use the same as
    generic_make_request and how we set the other bio fields.
    
    Signed-off-by: Mike Christie <mchristi@redhat.com>
    
    Fixed up fs/ext4/crypto.c
    
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/mm/page_io.c b/mm/page_io.c
index 242dba07545b..5a5fd66d7bd5 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -259,7 +259,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		bio_end_io_t end_write_func)
 {
 	struct bio *bio;
-	int ret, rw = WRITE;
+	int ret;
 	struct swap_info_struct *sis = page_swap_info(page);
 
 	if (sis->flags & SWP_FILE) {
@@ -317,12 +317,13 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		ret = -ENOMEM;
 		goto out;
 	}
+	bio->bi_rw = WRITE;
 	if (wbc->sync_mode == WB_SYNC_ALL)
-		rw |= REQ_SYNC;
+		bio->bi_rw |= REQ_SYNC;
 	count_vm_event(PSWPOUT);
 	set_page_writeback(page);
 	unlock_page(page);
-	submit_bio(rw, bio);
+	submit_bio(bio);
 out:
 	return ret;
 }
@@ -369,8 +370,9 @@ int swap_readpage(struct page *page)
 		ret = -ENOMEM;
 		goto out;
 	}
+	bio->bi_rw = READ;
 	count_vm_event(PSWPIN);
-	submit_bio(READ, bio);
+	submit_bio(bio);
 out:
 	return ret;
 }

commit c2e7b207058d4ff6a9010430763fb561f307eb67
Merge: c52b76185b7a 24368aad47dc
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue May 17 15:05:23 2016 -0700

    Merge branch 'work.preadv2' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs cleanups from Al Viro:
     "More cleanups from Christoph"
    
    * 'work.preadv2' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      nfsd: use RWF_SYNC
      fs: add RWF_DSYNC aand RWF_SYNC
      ceph: use generic_write_sync
      fs: simplify the generic_write_sync prototype
      fs: add IOCB_SYNC and IOCB_DSYNC
      direct-io: remove the offset argument to dio_complete
      direct-io: eliminate the offset argument to ->direct_IO
      xfs: eliminate the pos variable in xfs_file_dio_aio_write
      filemap: remove the pos argument to generic_file_direct_write
      filemap: remove pos variables in generic_file_read_iter

commit c8b8e32d700fe943a935e435ae251364d016c497
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Apr 7 08:51:58 2016 -0700

    direct-io: eliminate the offset argument to ->direct_IO
    
    Including blkdev_direct_IO and dax_do_io.  It has to be ki_pos to actually
    work, so eliminate the superflous argument.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/mm/page_io.c b/mm/page_io.c
index cd92e3d67a32..89275601d399 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -279,7 +279,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 
 		set_page_writeback(page);
 		unlock_page(page);
-		ret = mapping->a_ops->direct_IO(&kiocb, &from, kiocb.ki_pos);
+		ret = mapping->a_ops->direct_IO(&kiocb, &from);
 		if (ret == PAGE_SIZE) {
 			count_vm_event(PSWPOUT);
 			ret = 0;

commit b06bad17c7435b600a1d7a35b56eff25e1d3dbc0
Author: Minchan Kim <minchan@kernel.org>
Date:   Thu Apr 28 16:18:41 2016 -0700

    mm: call swap_slot_free_notify() with page lock held
    
    Kyeongdon reported below error which is BUG_ON(!PageSwapCache(page)) in
    page_swap_info.  The reason is that page_endio in rw_page unlocks the
    page if read I/O is completed so we need to hold a PG_lock again to
    check PageSwapCache.  Otherwise, the page can be removed from swapcache.
    
      Kernel BUG at c00f9040 [verbose debug info unavailable]
      Internal error: Oops - BUG: 0 [#1] PREEMPT SMP ARM
      Modules linked in:
      CPU: 4 PID: 13446 Comm: RenderThread Tainted: G        W 3.10.84-g9f14aec-dirty #73
      task: c3b73200 ti: dd192000 task.ti: dd192000
      PC is at page_swap_info+0x10/0x2c
      LR is at swap_slot_free_notify+0x18/0x6c
      pc : [<c00f9040>]    lr : [<c00f5560>]    psr: 400f0113
      sp : dd193d78  ip : c2deb1e4  fp : da015180
      r10: 00000000  r9 : 000200da  r8 : c120fe08
      r7 : 00000000  r6 : 00000000  r5 : c249a6c0  r4 : = c249a6c0
      r3 : 00000000  r2 : 40080009  r1 : 200f0113  r0 : = c249a6c0
      ..<snip> ..
      Call Trace:
        page_swap_info+0x10/0x2c
        swap_slot_free_notify+0x18/0x6c
        swap_readpage+0x90/0x11c
        read_swap_cache_async+0x134/0x1ac
        swapin_readahead+0x70/0xb0
        handle_pte_fault+0x320/0x6fc
        handle_mm_fault+0xc0/0xf0
        do_page_fault+0x11c/0x36c
        do_DataAbort+0x34/0x118
    
    Fixes: 3f2b1a04f44933f2 ("zram: revive swap_slot_free_notify")
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Tested-by: Kyeongdon Kim <kyeongdon.kim@lge.com>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index cd92e3d67a32..985f23cfa79b 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -353,7 +353,11 @@ int swap_readpage(struct page *page)
 
 	ret = bdev_read_page(sis->bdev, swap_page_sector(page), page);
 	if (!ret) {
-		swap_slot_free_notify(page);
+		if (trylock_page(page)) {
+			swap_slot_free_notify(page);
+			unlock_page(page);
+		}
+
 		count_vm_event(PSWPIN);
 		return 0;
 	}

commit 09cbfeaf1a5a67bfb3201e0c83c810cecb2efa5a
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Fri Apr 1 15:29:47 2016 +0300

    mm, fs: get rid of PAGE_CACHE_* and page_cache_{get,release} macros
    
    PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} macros were introduced *long* time
    ago with promise that one day it will be possible to implement page
    cache with bigger chunks than PAGE_SIZE.
    
    This promise never materialized.  And unlikely will.
    
    We have many places where PAGE_CACHE_SIZE assumed to be equal to
    PAGE_SIZE.  And it's constant source of confusion on whether
    PAGE_CACHE_* or PAGE_* constant should be used in a particular case,
    especially on the border between fs and mm.
    
    Global switching to PAGE_CACHE_SIZE != PAGE_SIZE would cause to much
    breakage to be doable.
    
    Let's stop pretending that pages in page cache are special.  They are
    not.
    
    The changes are pretty straight-forward:
    
     - <foo> << (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - <foo> >> (PAGE_CACHE_SHIFT - PAGE_SHIFT) -> <foo>;
    
     - PAGE_CACHE_{SIZE,SHIFT,MASK,ALIGN} -> PAGE_{SIZE,SHIFT,MASK,ALIGN};
    
     - page_cache_get() -> get_page();
    
     - page_cache_release() -> put_page();
    
    This patch contains automated changes generated with coccinelle using
    script below.  For some reason, coccinelle doesn't patch header files.
    I've called spatch for them manually.
    
    The only adjustment after coccinelle is revert of changes to
    PAGE_CAHCE_ALIGN definition: we are going to drop it later.
    
    There are few places in the code where coccinelle didn't reach.  I'll
    fix them manually in a separate patch.  Comments and documentation also
    will be addressed with the separate patch.
    
    virtual patch
    
    @@
    expression E;
    @@
    - E << (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    expression E;
    @@
    - E >> (PAGE_CACHE_SHIFT - PAGE_SHIFT)
    + E
    
    @@
    @@
    - PAGE_CACHE_SHIFT
    + PAGE_SHIFT
    
    @@
    @@
    - PAGE_CACHE_SIZE
    + PAGE_SIZE
    
    @@
    @@
    - PAGE_CACHE_MASK
    + PAGE_MASK
    
    @@
    expression E;
    @@
    - PAGE_CACHE_ALIGN(E)
    + PAGE_ALIGN(E)
    
    @@
    expression E;
    @@
    - page_cache_get(E)
    + get_page(E)
    
    @@
    expression E;
    @@
    - page_cache_release(E)
    + put_page(E)
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 18aac7819cc9..cd92e3d67a32 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -252,7 +252,7 @@ int swap_writepage(struct page *page, struct writeback_control *wbc)
 
 static sector_t swap_page_sector(struct page *page)
 {
-	return (sector_t)__page_file_index(page) << (PAGE_CACHE_SHIFT - 9);
+	return (sector_t)__page_file_index(page) << (PAGE_SHIFT - 9);
 }
 
 int __swap_writepage(struct page *page, struct writeback_control *wbc,

commit 3f2b1a04f44933f2d6fe0a9bf9a9c1c452df23f7
Author: Minchan Kim <minchan@kernel.org>
Date:   Tue Mar 22 14:24:36 2016 -0700

    zram: revive swap_slot_free_notify
    
    Commit b430e9d1c6d4 ("remove compressed copy from zram in-memory")
    applied swap_slot_free_notify call in *end_swap_bio_read* to remove
    duplicated memory between zram and memory.
    
    However, with the introduction of rw_page in zram: 8c7f01025f7b ("zram:
    implement rw_page operation of zram"), it became void because rw_page
    doesn't need bio.
    
    Memory footprint is really important in embedded platforms which have
    small memory, for example, 512M) recently because it could start to kill
    processes if memory footprint exceeds some threshold by LMK or some
    similar memory management modules.
    
    This patch restores the function for rw_page, thereby eliminating this
    duplication.
    
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Cc: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: karam.lee <karam.lee@lge.com>
    Cc: <sangseok.lee@lge.com>
    Cc: Chan Jeong <chan.jeong@lge.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index ff74e512f029..18aac7819cc9 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -66,6 +66,54 @@ void end_swap_bio_write(struct bio *bio)
 	bio_put(bio);
 }
 
+static void swap_slot_free_notify(struct page *page)
+{
+	struct swap_info_struct *sis;
+	struct gendisk *disk;
+
+	/*
+	 * There is no guarantee that the page is in swap cache - the software
+	 * suspend code (at least) uses end_swap_bio_read() against a non-
+	 * swapcache page.  So we must check PG_swapcache before proceeding with
+	 * this optimization.
+	 */
+	if (unlikely(!PageSwapCache(page)))
+		return;
+
+	sis = page_swap_info(page);
+	if (!(sis->flags & SWP_BLKDEV))
+		return;
+
+	/*
+	 * The swap subsystem performs lazy swap slot freeing,
+	 * expecting that the page will be swapped out again.
+	 * So we can avoid an unnecessary write if the page
+	 * isn't redirtied.
+	 * This is good for real swap storage because we can
+	 * reduce unnecessary I/O and enhance wear-leveling
+	 * if an SSD is used as the as swap device.
+	 * But if in-memory swap device (eg zram) is used,
+	 * this causes a duplicated copy between uncompressed
+	 * data in VM-owned memory and compressed data in
+	 * zram-owned memory.  So let's free zram-owned memory
+	 * and make the VM-owned decompressed page *dirty*,
+	 * so the page should be swapped out somewhere again if
+	 * we again wish to reclaim it.
+	 */
+	disk = sis->bdev->bd_disk;
+	if (disk->fops->swap_slot_free_notify) {
+		swp_entry_t entry;
+		unsigned long offset;
+
+		entry.val = page_private(page);
+		offset = swp_offset(entry);
+
+		SetPageDirty(page);
+		disk->fops->swap_slot_free_notify(sis->bdev,
+				offset);
+	}
+}
+
 static void end_swap_bio_read(struct bio *bio)
 {
 	struct page *page = bio->bi_io_vec[0].bv_page;
@@ -81,49 +129,7 @@ static void end_swap_bio_read(struct bio *bio)
 	}
 
 	SetPageUptodate(page);
-
-	/*
-	 * There is no guarantee that the page is in swap cache - the software
-	 * suspend code (at least) uses end_swap_bio_read() against a non-
-	 * swapcache page.  So we must check PG_swapcache before proceeding with
-	 * this optimization.
-	 */
-	if (likely(PageSwapCache(page))) {
-		struct swap_info_struct *sis;
-
-		sis = page_swap_info(page);
-		if (sis->flags & SWP_BLKDEV) {
-			/*
-			 * The swap subsystem performs lazy swap slot freeing,
-			 * expecting that the page will be swapped out again.
-			 * So we can avoid an unnecessary write if the page
-			 * isn't redirtied.
-			 * This is good for real swap storage because we can
-			 * reduce unnecessary I/O and enhance wear-leveling
-			 * if an SSD is used as the as swap device.
-			 * But if in-memory swap device (eg zram) is used,
-			 * this causes a duplicated copy between uncompressed
-			 * data in VM-owned memory and compressed data in
-			 * zram-owned memory.  So let's free zram-owned memory
-			 * and make the VM-owned decompressed page *dirty*,
-			 * so the page should be swapped out somewhere again if
-			 * we again wish to reclaim it.
-			 */
-			struct gendisk *disk = sis->bdev->bd_disk;
-			if (disk->fops->swap_slot_free_notify) {
-				swp_entry_t entry;
-				unsigned long offset;
-
-				entry.val = page_private(page);
-				offset = swp_offset(entry);
-
-				SetPageDirty(page);
-				disk->fops->swap_slot_free_notify(sis->bdev,
-						offset);
-			}
-		}
-	}
-
+	swap_slot_free_notify(page);
 out:
 	unlock_page(page);
 	bio_put(bio);
@@ -347,6 +353,7 @@ int swap_readpage(struct page *page)
 
 	ret = bdev_read_page(sis->bdev, swap_page_sector(page), page);
 	if (!ret) {
+		swap_slot_free_notify(page);
 		count_vm_event(PSWPIN);
 		return 0;
 	}

commit 1170532bb49f9468aedabdc1d5a560e2521a2bcc
Author: Joe Perches <joe@perches.com>
Date:   Thu Mar 17 14:19:50 2016 -0700

    mm: convert printk(KERN_<LEVEL> to pr_<level>
    
    Most of the mm subsystem uses pr_<level> so make it consistent.
    
    Miscellanea:
    
     - Realign arguments
     - Add missing newline to format
     - kmemleak-test.c has a "kmemleak: " prefix added to the
       "Kmemleak testing" logging message via pr_fmt
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Acked-by: Tejun Heo <tj@kernel.org>     [percpu]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index b995a5ba5e8f..ff74e512f029 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -56,10 +56,10 @@ void end_swap_bio_write(struct bio *bio)
 		 * Also clear PG_reclaim to avoid rotate_reclaimable_page()
 		 */
 		set_page_dirty(page);
-		printk(KERN_ALERT "Write-error on swap-device (%u:%u:%Lu)\n",
-				imajor(bio->bi_bdev->bd_inode),
-				iminor(bio->bi_bdev->bd_inode),
-				(unsigned long long)bio->bi_iter.bi_sector);
+		pr_alert("Write-error on swap-device (%u:%u:%llu)\n",
+			 imajor(bio->bi_bdev->bd_inode),
+			 iminor(bio->bi_bdev->bd_inode),
+			 (unsigned long long)bio->bi_iter.bi_sector);
 		ClearPageReclaim(page);
 	}
 	end_page_writeback(page);
@@ -73,10 +73,10 @@ static void end_swap_bio_read(struct bio *bio)
 	if (bio->bi_error) {
 		SetPageError(page);
 		ClearPageUptodate(page);
-		printk(KERN_ALERT "Read-error on swap-device (%u:%u:%Lu)\n",
-				imajor(bio->bi_bdev->bd_inode),
-				iminor(bio->bi_bdev->bd_inode),
-				(unsigned long long)bio->bi_iter.bi_sector);
+		pr_alert("Read-error on swap-device (%u:%u:%llu)\n",
+			 imajor(bio->bi_bdev->bd_inode),
+			 iminor(bio->bi_bdev->bd_inode),
+			 (unsigned long long)bio->bi_iter.bi_sector);
 		goto out;
 	}
 
@@ -216,7 +216,7 @@ int generic_swapfile_activate(struct swap_info_struct *sis,
 out:
 	return ret;
 bad_bmap:
-	printk(KERN_ERR "swapon: swapfile has holes\n");
+	pr_err("swapon: swapfile has holes\n");
 	ret = -EINVAL;
 	goto out;
 }
@@ -290,8 +290,8 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 			 */
 			set_page_dirty(page);
 			ClearPageReclaim(page);
-			pr_err_ratelimited("Write error on dio swapfile (%Lu)\n",
-				page_file_offset(page));
+			pr_err_ratelimited("Write error on dio swapfile (%llu)\n",
+					   page_file_offset(page));
 		}
 		end_page_writeback(page);
 		return ret;

commit 6cf66b4caf9c71f64a5486cadbd71ab58d0d4307
Author: Kent Overstreet <kent.overstreet@gmail.com>
Date:   Mon Dec 22 12:48:42 2014 +0100

    fs: use helper bio_add_page() instead of open coding on bi_io_vec
    
    Call pre-defined helper bio_add_page() instead of open coding for
    iterating through bi_io_vec[]. Doing that, it's possible to make some
    parts in filesystems and mm/page_io.c simpler than before.
    
    Acked-by: Dave Kleikamp <shaggy@kernel.org>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: linux-fsdevel@vger.kernel.org
    Signed-off-by: Kent Overstreet <kent.overstreet@gmail.com>
    [dpark: add more description in commit message]
    Signed-off-by: Dongsu Park <dpark@posteo.net>
    Signed-off-by: Ming Lin <ming.l@ssi.samsung.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/mm/page_io.c b/mm/page_io.c
index 338ce68942a0..b995a5ba5e8f 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -33,12 +33,10 @@ static struct bio *get_swap_bio(gfp_t gfp_flags,
 	if (bio) {
 		bio->bi_iter.bi_sector = map_swap_page(page, &bio->bi_bdev);
 		bio->bi_iter.bi_sector <<= PAGE_SHIFT - 9;
-		bio->bi_io_vec[0].bv_page = page;
-		bio->bi_io_vec[0].bv_len = PAGE_SIZE;
-		bio->bi_io_vec[0].bv_offset = 0;
-		bio->bi_vcnt = 1;
-		bio->bi_iter.bi_size = PAGE_SIZE;
 		bio->bi_end_io = end_io;
+
+		bio_add_page(bio, page, PAGE_SIZE, 0);
+		BUG_ON(bio->bi_iter.bi_size != PAGE_SIZE);
 	}
 	return bio;
 }

commit 4246a0b63bd8f56a1469b12eafeb875b1041a451
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jul 20 15:29:37 2015 +0200

    block: add a bi_error field to struct bio
    
    Currently we have two different ways to signal an I/O error on a BIO:
    
     (1) by clearing the BIO_UPTODATE flag
     (2) by returning a Linux errno value to the bi_end_io callback
    
    The first one has the drawback of only communicating a single possible
    error (-EIO), and the second one has the drawback of not beeing persistent
    when bios are queued up, and are not passed along from child to parent
    bio in the ever more popular chaining scenario.  Having both mechanisms
    available has the additional drawback of utterly confusing driver authors
    and introducing bugs where various I/O submitters only deal with one of
    them, and the others have to add boilerplate code to deal with both kinds
    of error returns.
    
    So add a new bi_error field to store an errno value directly in struct
    bio and remove the existing mechanisms to clean all this up.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Hannes Reinecke <hare@suse.de>
    Reviewed-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/mm/page_io.c b/mm/page_io.c
index 520baa4b04d7..338ce68942a0 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -43,12 +43,11 @@ static struct bio *get_swap_bio(gfp_t gfp_flags,
 	return bio;
 }
 
-void end_swap_bio_write(struct bio *bio, int err)
+void end_swap_bio_write(struct bio *bio)
 {
-	const int uptodate = test_bit(BIO_UPTODATE, &bio->bi_flags);
 	struct page *page = bio->bi_io_vec[0].bv_page;
 
-	if (!uptodate) {
+	if (bio->bi_error) {
 		SetPageError(page);
 		/*
 		 * We failed to write the page out to swap-space.
@@ -69,12 +68,11 @@ void end_swap_bio_write(struct bio *bio, int err)
 	bio_put(bio);
 }
 
-static void end_swap_bio_read(struct bio *bio, int err)
+static void end_swap_bio_read(struct bio *bio)
 {
-	const int uptodate = test_bit(BIO_UPTODATE, &bio->bi_flags);
 	struct page *page = bio->bi_io_vec[0].bv_page;
 
-	if (!uptodate) {
+	if (bio->bi_error) {
 		SetPageError(page);
 		ClearPageUptodate(page);
 		printk(KERN_ALERT "Read-error on swap-device (%u:%u:%Lu)\n",
@@ -254,7 +252,7 @@ static sector_t swap_page_sector(struct page *page)
 }
 
 int __swap_writepage(struct page *page, struct writeback_control *wbc,
-	void (*end_write_func)(struct bio *, int))
+		bio_end_io_t end_write_func)
 {
 	struct bio *bio;
 	int ret, rw = WRITE;

commit 343df3c79c62b644ce6ff5dff96c9e0be1ecb242
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue May 19 09:23:23 2015 +0200

    suspend: simplify block I/O handling
    
    Stop abusing struct page functionality and the swap end_io handler, and
    instead add a modified version of the blk-lib.c bio_batch helpers.
    
    Also move the block I/O code into swap.c as they are directly tied into
    each other.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Tested-by: Pavel Machek <pavel@ucw.cz>
    Tested-by: Ming Lin <mlin@kernel.org>
    Acked-by: Pavel Machek <pavel@ucw.cz>
    Acked-by: Rafael J. Wysocki <rjw@rjwysocki.net>
    Signed-off-by: Jens Axboe <axboe@fb.com>

diff --git a/mm/page_io.c b/mm/page_io.c
index 6424869e275e..520baa4b04d7 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -69,7 +69,7 @@ void end_swap_bio_write(struct bio *bio, int err)
 	bio_put(bio);
 }
 
-void end_swap_bio_read(struct bio *bio, int err)
+static void end_swap_bio_read(struct bio *bio, int err)
 {
 	const int uptodate = test_bit(BIO_UPTODATE, &bio->bi_flags);
 	struct page *page = bio->bi_io_vec[0].bv_page;

commit 22c6186ecea0be9eff1c399298ad36e94a59995f
Author: Omar Sandoval <osandov@osandov.com>
Date:   Mon Mar 16 04:33:53 2015 -0700

    direct_IO: remove rw from a_ops->direct_IO()
    
    Now that no one is using rw, remove it completely.
    
    Signed-off-by: Omar Sandoval <osandov@osandov.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/mm/page_io.c b/mm/page_io.c
index a96c8562d835..6424869e275e 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -277,9 +277,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 
 		set_page_writeback(page);
 		unlock_page(page);
-		ret = mapping->a_ops->direct_IO(ITER_BVEC | WRITE,
-						&kiocb, &from,
-						kiocb.ki_pos);
+		ret = mapping->a_ops->direct_IO(&kiocb, &from, kiocb.ki_pos);
 		if (ret == PAGE_SIZE) {
 			count_vm_event(PSWPOUT);
 			ret = 0;

commit e2e40f2c1ed433c5e224525c8c862fd32e5d3df2
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun Feb 22 08:58:50 2015 -0800

    fs: move struct kiocb to fs.h
    
    struct kiocb now is a generic I/O container, so move it to fs.h.
    Also do a #include diet for aio.h while we're at it.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/mm/page_io.c b/mm/page_io.c
index 7ef21577856c..a96c8562d835 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -20,8 +20,8 @@
 #include <linux/buffer_head.h>
 #include <linux/writeback.h>
 #include <linux/frontswap.h>
-#include <linux/aio.h>
 #include <linux/blkdev.h>
+#include <linux/uio.h>
 #include <asm/pgtable.h>
 
 static struct bio *get_swap_bio(gfp_t gfp_flags,

commit 66ee59af630fd8d5f4f56fb28162857e629aa0ab
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Feb 11 19:56:46 2015 +0100

    fs: remove ki_nbytes
    
    There is no need to pass the total request length in the kiocb, as
    we already get passed in through the iov_iter argument.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/mm/page_io.c b/mm/page_io.c
index e6045804c8d8..7ef21577856c 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -274,7 +274,6 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		iov_iter_bvec(&from, ITER_BVEC | WRITE, &bv, 1, PAGE_SIZE);
 		init_sync_kiocb(&kiocb, swap_file);
 		kiocb.ki_pos = page_file_offset(page);
-		kiocb.ki_nbytes = PAGE_SIZE;
 
 		set_page_writeback(page);
 		unlock_page(page);

commit 05afcb77eb4713f46e7ebaa3cb54bc465c5d516e
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Jan 23 01:08:07 2015 -0500

    new helper: iov_iter_bvec()
    
    similar to iov_iter_kvec(), for ITER_BVEC ones
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/mm/page_io.c b/mm/page_io.c
index 955db8b0d497..e6045804c8d8 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -269,14 +269,9 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 			.bv_len  = PAGE_SIZE,
 			.bv_offset = 0
 		};
-		struct iov_iter from = {
-			.type = ITER_BVEC | WRITE,
-			.count = PAGE_SIZE,
-			.iov_offset = 0,
-			.nr_segs = 1,
-		};
-		from.bvec = &bv;	/* older gcc versions are broken */
+		struct iov_iter from;
 
+		iov_iter_bvec(&from, ITER_BVEC | WRITE, &bv, 1, PAGE_SIZE);
 		init_sync_kiocb(&kiocb, swap_file);
 		kiocb.ki_pos = page_file_offset(page);
 		kiocb.ki_nbytes = PAGE_SIZE;

commit 05064084e82d057f8d74590c51581650e060fbb8
Author: Al Viro <viro@ZenIV.linux.org.uk>
Date:   Sat Jun 14 07:12:41 2014 +0100

    fix __swap_writepage() compile failure on old gcc versions
    
    Tetsuo Handa wrote:
     "Commit 62a8067a7f35 ("bio_vec-backed iov_iter") introduced an unnamed
      union inside a struct which gcc-4.4.7 cannot handle.  Name the unnamed
       union as u in order to fix build failure"
    
    Let's do this instead: there is only one place in the entire tree that
    steps into this breakage.  Anon structs and unions work in older gcc
    versions; as the matter of fact, we have those in the tree - see e.g.
    struct ieee80211_tx_info in include/net/mac80211.h
    
    What doesn't work is handling their initializers:
    
    struct {
            int a;
            union {
                    int b;
                    char c;
            };
    } x[2] = {{.a = 1, .c = 'a'}, {.a = 0, .b = 1}};
    
    is the obvious syntax for initializer, perfectly fine for C11 and
    handled correctly by gcc-4.7 or later.
    
    Earlier versions, though, break on it - declaration is fine and so's
    access to fields (i.e.  x[0].c = 'a'; would produce the right code), but
    members of the anon structs and unions are not inserted into the right
    namespace.  Tellingly, those older versions will not barf on struct {int
    a; struct {int a;};}; - looks like they just have it hacked up somewhere
    around the handling of .  and -> instead of doing the right thing.
    
    The easiest way to deal with that crap is to turn initialization of
    those fields (in the only place where we have such initializer of
    iov_iter) into plain assignment.
    
    Reported-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
    Reported-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 243a9b76e5ce..955db8b0d497 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -274,8 +274,8 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 			.count = PAGE_SIZE,
 			.iov_offset = 0,
 			.nr_segs = 1,
-			.bvec = &bv
 		};
+		from.bvec = &bv;	/* older gcc versions are broken */
 
 		init_sync_kiocb(&kiocb, swap_file);
 		kiocb.ki_pos = page_file_offset(page);

commit 16b9057804c02e2d351e9c8f606e909b43cbd9e7
Merge: 5c02c392cd23 c2338f2dc7c1
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 12 10:30:18 2014 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs updates from Al Viro:
     "This the bunch that sat in -next + lock_parent() fix.  This is the
      minimal set; there's more pending stuff.
    
      In particular, I really hope to get acct.c fixes merged this cycle -
      we need that to deal sanely with delayed-mntput stuff.  In the next
      pile, hopefully - that series is fairly short and localized
      (kernel/acct.c, fs/super.c and fs/namespace.c).  In this pile: more
      iov_iter work.  Most of prereqs for ->splice_write with sane locking
      order are there and Kent's dio rewrite would also fit nicely on top of
      this pile"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (70 commits)
      lock_parent: don't step on stale ->d_parent of all-but-freed one
      kill generic_file_splice_write()
      ceph: switch to iter_file_splice_write()
      shmem: switch to iter_file_splice_write()
      nfs: switch to iter_splice_write_file()
      fs/splice.c: remove unneeded exports
      ocfs2: switch to iter_file_splice_write()
      ->splice_write() via ->write_iter()
      bio_vec-backed iov_iter
      optimize copy_page_{to,from}_iter()
      bury generic_file_aio_{read,write}
      lustre: get rid of messing with iovecs
      ceph: switch to ->write_iter()
      ceph_sync_direct_write: stop poking into iov_iter guts
      ceph_sync_read: stop poking into iov_iter guts
      new helper: copy_page_from_iter()
      fuse: switch to ->write_iter()
      btrfs: switch to ->write_iter()
      ocfs2: switch to ->write_iter()
      xfs: switch to ->write_iter()
      ...

commit dd6bd0d9c7dbb3951005db4e424abbd37c4ff801
Author: Matthew Wilcox <matthew.r.wilcox@intel.com>
Date:   Wed Jun 4 16:07:48 2014 -0700

    swap: use bdev_read_page() / bdev_write_page()
    
    By calling the device driver to write the page directly, we avoid
    allocating a BIO, which allows us to free memory without allocating
    memory.
    
    [akpm@linux-foundation.org: fix used-uninitialized bug]
    Signed-off-by: Matthew Wilcox <matthew.r.wilcox@intel.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Dheeraj Reddy <dheeraj.reddy@intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 7c59ef681381..58b50d2901fe 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -248,11 +248,16 @@ int swap_writepage(struct page *page, struct writeback_control *wbc)
 	return ret;
 }
 
+static sector_t swap_page_sector(struct page *page)
+{
+	return (sector_t)__page_file_index(page) << (PAGE_CACHE_SHIFT - 9);
+}
+
 int __swap_writepage(struct page *page, struct writeback_control *wbc,
 	void (*end_write_func)(struct bio *, int))
 {
 	struct bio *bio;
-	int ret = 0, rw = WRITE;
+	int ret, rw = WRITE;
 	struct swap_info_struct *sis = page_swap_info(page);
 
 	if (sis->flags & SWP_FILE) {
@@ -297,6 +302,13 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		return ret;
 	}
 
+	ret = bdev_write_page(sis->bdev, swap_page_sector(page), page, wbc);
+	if (!ret) {
+		count_vm_event(PSWPOUT);
+		return 0;
+	}
+
+	ret = 0;
 	bio = get_swap_bio(GFP_NOIO, page, end_write_func);
 	if (bio == NULL) {
 		set_page_dirty(page);
@@ -338,6 +350,13 @@ int swap_readpage(struct page *page)
 		return ret;
 	}
 
+	ret = bdev_read_page(sis->bdev, swap_page_sector(page), page);
+	if (!ret) {
+		count_vm_event(PSWPIN);
+		return 0;
+	}
+
+	ret = 0;
 	bio = get_swap_bio(GFP_KERNEL, page, end_swap_bio_read);
 	if (bio == NULL) {
 		unlock_page(page);

commit 62a8067a7f35dba2de501c9cb00e4cf36da90bc0
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Apr 4 23:12:29 2014 -0400

    bio_vec-backed iov_iter
    
    New variant of iov_iter - ITER_BVEC in iter->type, backed with
    bio_vec array instead of iovec one.  Primitives taught to deal
    with such beasts, __swap_write() switched to using that kind
    of iov_iter.
    
    Note that bio_vec is just a <page, offset, length> triple - there's
    nothing block-specific about it.  I've left the definition where it
    was, but took it from under ifdef CONFIG_BLOCK.
    
    Next target: ->splice_write()...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/mm/page_io.c b/mm/page_io.c
index 313bfedb75d1..33bb38c4aad7 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -259,23 +259,28 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		struct kiocb kiocb;
 		struct file *swap_file = sis->swap_file;
 		struct address_space *mapping = swap_file->f_mapping;
-		struct iovec iov = {
-			.iov_base = kmap(page),
-			.iov_len  = PAGE_SIZE,
+		struct bio_vec bv = {
+			.bv_page = page,
+			.bv_len  = PAGE_SIZE,
+			.bv_offset = 0
+		};
+		struct iov_iter from = {
+			.type = ITER_BVEC | WRITE,
+			.count = PAGE_SIZE,
+			.iov_offset = 0,
+			.nr_segs = 1,
+			.bvec = &bv
 		};
-		struct iov_iter from;
 
 		init_sync_kiocb(&kiocb, swap_file);
 		kiocb.ki_pos = page_file_offset(page);
 		kiocb.ki_nbytes = PAGE_SIZE;
-		iov_iter_init(&from, KERNEL_WRITE, &iov, 1, PAGE_SIZE);
 
 		set_page_writeback(page);
 		unlock_page(page);
-		ret = mapping->a_ops->direct_IO(KERNEL_WRITE,
+		ret = mapping->a_ops->direct_IO(ITER_BVEC | WRITE,
 						&kiocb, &from,
 						kiocb.ki_pos);
-		kunmap(page);
 		if (ret == PAGE_SIZE) {
 			count_vm_event(PSWPOUT);
 			ret = 0;

commit 71d8e532b1549a478e6a6a8a44f309d050294d00
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Mar 5 19:28:09 2014 -0500

    start adding the tag to iov_iter
    
    For now, just use the same thing we pass to ->direct_IO() - it's all
    iovec-based at the moment.  Pass it explicitly to iov_iter_init() and
    account for kvec vs. iovec in there, by the same kludge NFS ->direct_IO()
    uses.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/mm/page_io.c b/mm/page_io.c
index 0ed0644c73db..313bfedb75d1 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -268,7 +268,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		init_sync_kiocb(&kiocb, swap_file);
 		kiocb.ki_pos = page_file_offset(page);
 		kiocb.ki_nbytes = PAGE_SIZE;
-		iov_iter_init(&from, &iov, 1, PAGE_SIZE, 0);
+		iov_iter_init(&from, KERNEL_WRITE, &iov, 1, PAGE_SIZE);
 
 		set_page_writeback(page);
 		unlock_page(page);

commit d8d3d94b80aa1a1c0ca75c58b8abdc7356f38418
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Mar 4 21:27:34 2014 -0500

    pass iov_iter to ->direct_IO()
    
    unmodified, for now
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/mm/page_io.c b/mm/page_io.c
index 7c59ef681381..0ed0644c73db 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -263,16 +263,18 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 			.iov_base = kmap(page),
 			.iov_len  = PAGE_SIZE,
 		};
+		struct iov_iter from;
 
 		init_sync_kiocb(&kiocb, swap_file);
 		kiocb.ki_pos = page_file_offset(page);
 		kiocb.ki_nbytes = PAGE_SIZE;
+		iov_iter_init(&from, &iov, 1, PAGE_SIZE, 0);
 
 		set_page_writeback(page);
 		unlock_page(page);
 		ret = mapping->a_ops->direct_IO(KERNEL_WRITE,
-						&kiocb, &iov,
-						kiocb.ki_pos, 1);
+						&kiocb, &from,
+						kiocb.ki_pos);
 		kunmap(page);
 		if (ret == PAGE_SIZE) {
 			count_vm_event(PSWPOUT);

commit f568849edac8611d603e00bd6cbbcfea09395ae6
Merge: d9894c228b11 675675ada486
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 30 11:19:05 2014 -0800

    Merge branch 'for-3.14/core' of git://git.kernel.dk/linux-block
    
    Pull core block IO changes from Jens Axboe:
     "The major piece in here is the immutable bio_ve series from Kent, the
      rest is fairly minor.  It was supposed to go in last round, but
      various issues pushed it to this release instead.  The pull request
      contains:
    
       - Various smaller blk-mq fixes from different folks.  Nothing major
         here, just minor fixes and cleanups.
    
       - Fix for a memory leak in the error path in the block ioctl code
         from Christian Engelmayer.
    
       - Header export fix from CaiZhiyong.
    
       - Finally the immutable biovec changes from Kent Overstreet.  This
         enables some nice future work on making arbitrarily sized bios
         possible, and splitting more efficient.  Related fixes to immutable
         bio_vecs:
    
            - dm-cache immutable fixup from Mike Snitzer.
            - btrfs immutable fixup from Muthu Kumar.
    
      - bio-integrity fix from Nic Bellinger, which is also going to stable"
    
    * 'for-3.14/core' of git://git.kernel.dk/linux-block: (44 commits)
      xtensa: fixup simdisk driver to work with immutable bio_vecs
      block/blk-mq-cpu.c: use hotcpu_notifier()
      blk-mq: for_each_* macro correctness
      block: Fix memory leak in rw_copy_check_uvector() handling
      bio-integrity: Fix bio_integrity_verify segment start bug
      block: remove unrelated header files and export symbol
      blk-mq: uses page->list incorrectly
      blk-mq: use __smp_call_function_single directly
      btrfs: fix missing increment of bi_remaining
      Revert "block: Warn and free bio if bi_end_io is not set"
      block: Warn and free bio if bi_end_io is not set
      blk-mq: fix initializing request's start time
      block: blk-mq: don't export blk_mq_free_queue()
      block: blk-mq: make blk_sync_queue support mq
      block: blk-mq: support draining mq queue
      dm cache: increment bi_remaining when bi_end_io is restored
      block: fixup for generic bio chaining
      block: Really silence spurious compiler warnings
      block: Silence spurious compiler warnings
      block: Kill bio_pair_split()
      ...

commit 309381feaee564281c3d9e90fbca8963bb7428ad
Author: Sasha Levin <sasha.levin@oracle.com>
Date:   Thu Jan 23 15:52:54 2014 -0800

    mm: dump page when hitting a VM_BUG_ON using VM_BUG_ON_PAGE
    
    Most of the VM_BUG_ON assertions are performed on a page.  Usually, when
    one of these assertions fails we'll get a BUG_ON with a call stack and
    the registers.
    
    I've recently noticed based on the requests to add a small piece of code
    that dumps the page to various VM_BUG_ON sites that the page dump is
    quite useful to people debugging issues in mm.
    
    This patch adds a VM_BUG_ON_PAGE(cond, page) which beyond doing what
    VM_BUG_ON() does, also dumps the page before executing the actual
    BUG_ON.
    
    [akpm@linux-foundation.org: fix up includes]
    Signed-off-by: Sasha Levin <sasha.levin@oracle.com>
    Cc: "Kirill A. Shutemov" <kirill@shutemov.name>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 8c79a4764be0..7247be6114ac 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -320,8 +320,8 @@ int swap_readpage(struct page *page)
 	int ret = 0;
 	struct swap_info_struct *sis = page_swap_info(page);
 
-	VM_BUG_ON(!PageLocked(page));
-	VM_BUG_ON(PageUptodate(page));
+	VM_BUG_ON_PAGE(!PageLocked(page), page);
+	VM_BUG_ON_PAGE(PageUptodate(page), page);
 	if (frontswap_load(page) == 0) {
 		SetPageUptodate(page);
 		unlock_page(page);

commit 4f024f3797c43cb4b73cd2c50cec728842d0e49e
Author: Kent Overstreet <kmo@daterainc.com>
Date:   Fri Oct 11 15:44:27 2013 -0700

    block: Abstract out bvec iterator
    
    Immutable biovecs are going to require an explicit iterator. To
    implement immutable bvecs, a later patch is going to add a bi_bvec_done
    member to this struct; for now, this patch effectively just renames
    things.
    
    Signed-off-by: Kent Overstreet <kmo@daterainc.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: "Ed L. Cashin" <ecashin@coraid.com>
    Cc: Nick Piggin <npiggin@kernel.dk>
    Cc: Lars Ellenberg <drbd-dev@lists.linbit.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Matthew Wilcox <willy@linux.intel.com>
    Cc: Geoff Levand <geoff@infradead.org>
    Cc: Yehuda Sadeh <yehuda@inktank.com>
    Cc: Sage Weil <sage@inktank.com>
    Cc: Alex Elder <elder@inktank.com>
    Cc: ceph-devel@vger.kernel.org
    Cc: Joshua Morris <josh.h.morris@us.ibm.com>
    Cc: Philip Kelleher <pjk1939@linux.vnet.ibm.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: "Michael S. Tsirkin" <mst@redhat.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Neil Brown <neilb@suse.de>
    Cc: Alasdair Kergon <agk@redhat.com>
    Cc: Mike Snitzer <snitzer@redhat.com>
    Cc: dm-devel@redhat.com
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: linux390@de.ibm.com
    Cc: Boaz Harrosh <bharrosh@panasas.com>
    Cc: Benny Halevy <bhalevy@tonian.com>
    Cc: "James E.J. Bottomley" <JBottomley@parallels.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: "Nicholas A. Bellinger" <nab@linux-iscsi.org>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Chris Mason <chris.mason@fusionio.com>
    Cc: "Theodore Ts'o" <tytso@mit.edu>
    Cc: Andreas Dilger <adilger.kernel@dilger.ca>
    Cc: Jaegeuk Kim <jaegeuk.kim@samsung.com>
    Cc: Steven Whitehouse <swhiteho@redhat.com>
    Cc: Dave Kleikamp <shaggy@kernel.org>
    Cc: Joern Engel <joern@logfs.org>
    Cc: Prasad Joshi <prasadjoshi.linux@gmail.com>
    Cc: Trond Myklebust <Trond.Myklebust@netapp.com>
    Cc: KONISHI Ryusuke <konishi.ryusuke@lab.ntt.co.jp>
    Cc: Mark Fasheh <mfasheh@suse.com>
    Cc: Joel Becker <jlbec@evilplan.org>
    Cc: Ben Myers <bpm@sgi.com>
    Cc: xfs@oss.sgi.com
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Len Brown <len.brown@intel.com>
    Cc: Pavel Machek <pavel@ucw.cz>
    Cc: "Rafael J. Wysocki" <rjw@sisk.pl>
    Cc: Herton Ronaldo Krzesinski <herton.krzesinski@canonical.com>
    Cc: Ben Hutchings <ben@decadent.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Guo Chao <yan@linux.vnet.ibm.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Asai Thambi S P <asamymuthupa@micron.com>
    Cc: Selvan Mani <smani@micron.com>
    Cc: Sam Bradshaw <sbradshaw@micron.com>
    Cc: Wei Yongjun <yongjun_wei@trendmicro.com.cn>
    Cc: "Roger Pau Monné" <roger.pau@citrix.com>
    Cc: Jan Beulich <jbeulich@suse.com>
    Cc: Stefano Stabellini <stefano.stabellini@eu.citrix.com>
    Cc: Ian Campbell <Ian.Campbell@citrix.com>
    Cc: Sebastian Ott <sebott@linux.vnet.ibm.com>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Jiang Liu <jiang.liu@huawei.com>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Cc: Jerome Marchand <jmarchand@redhat.com>
    Cc: Joe Perches <joe@perches.com>
    Cc: Peng Tao <tao.peng@emc.com>
    Cc: Andy Adamson <andros@netapp.com>
    Cc: fanchaoting <fanchaoting@cn.fujitsu.com>
    Cc: Jie Liu <jeff.liu@oracle.com>
    Cc: Sunil Mushran <sunil.mushran@gmail.com>
    Cc: "Martin K. Petersen" <martin.petersen@oracle.com>
    Cc: Namjae Jeon <namjae.jeon@samsung.com>
    Cc: Pankaj Kumar <pankaj.km@samsung.com>
    Cc: Dan Magenheimer <dan.magenheimer@oracle.com>
    Cc: Mel Gorman <mgorman@suse.de>6

diff --git a/mm/page_io.c b/mm/page_io.c
index 8c79a4764be0..f14eded987fa 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -31,13 +31,13 @@ static struct bio *get_swap_bio(gfp_t gfp_flags,
 
 	bio = bio_alloc(gfp_flags, 1);
 	if (bio) {
-		bio->bi_sector = map_swap_page(page, &bio->bi_bdev);
-		bio->bi_sector <<= PAGE_SHIFT - 9;
+		bio->bi_iter.bi_sector = map_swap_page(page, &bio->bi_bdev);
+		bio->bi_iter.bi_sector <<= PAGE_SHIFT - 9;
 		bio->bi_io_vec[0].bv_page = page;
 		bio->bi_io_vec[0].bv_len = PAGE_SIZE;
 		bio->bi_io_vec[0].bv_offset = 0;
 		bio->bi_vcnt = 1;
-		bio->bi_size = PAGE_SIZE;
+		bio->bi_iter.bi_size = PAGE_SIZE;
 		bio->bi_end_io = end_io;
 	}
 	return bio;
@@ -62,7 +62,7 @@ void end_swap_bio_write(struct bio *bio, int err)
 		printk(KERN_ALERT "Write-error on swap-device (%u:%u:%Lu)\n",
 				imajor(bio->bi_bdev->bd_inode),
 				iminor(bio->bi_bdev->bd_inode),
-				(unsigned long long)bio->bi_sector);
+				(unsigned long long)bio->bi_iter.bi_sector);
 		ClearPageReclaim(page);
 	}
 	end_page_writeback(page);
@@ -80,7 +80,7 @@ void end_swap_bio_read(struct bio *bio, int err)
 		printk(KERN_ALERT "Read-error on swap-device (%u:%u:%Lu)\n",
 				imajor(bio->bi_bdev->bd_inode),
 				iminor(bio->bi_bdev->bd_inode),
-				(unsigned long long)bio->bi_sector);
+				(unsigned long long)bio->bi_iter.bi_sector);
 		goto out;
 	}
 

commit 73a7075e3f6ec63dc359064eea6fd84f406cf2a5
Author: Kent Overstreet <koverstreet@google.com>
Date:   Thu May 9 15:03:42 2013 -0700

    aio: Kill aio_rw_vect_retry()
    
    This code doesn't serve any purpose anymore, since the aio retry
    infrastructure has been removed.
    
    This change should be safe because aio_read/write are also used for
    synchronous IO, and called from do_sync_read()/do_sync_write() - and
    there's no looping done in the sync case (the read and write syscalls).
    
    Signed-off-by: Kent Overstreet <koverstreet@google.com>
    Cc: Zach Brown <zab@redhat.com>
    Cc: Felipe Balbi <balbi@ti.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Mark Fasheh <mfasheh@suse.com>
    Cc: Joel Becker <jlbec@evilplan.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Asai Thambi S P <asamymuthupa@micron.com>
    Cc: Selvan Mani <smani@micron.com>
    Cc: Sam Bradshaw <sbradshaw@micron.com>
    Cc: Jeff Moyer <jmoyer@redhat.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Benjamin LaHaise <bcrl@kvack.org>
    Signed-off-by: Benjamin LaHaise <bcrl@kvack.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index ba05b64e5d8d..8c79a4764be0 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -266,7 +266,6 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 
 		init_sync_kiocb(&kiocb, swap_file);
 		kiocb.ki_pos = page_file_offset(page);
-		kiocb.ki_left = PAGE_SIZE;
 		kiocb.ki_nbytes = PAGE_SIZE;
 
 		set_page_writeback(page);

commit b430e9d1c6d416306d44dbf3aa3148be7af78abc
Author: Minchan Kim <minchan@kernel.org>
Date:   Wed Jul 3 15:01:24 2013 -0700

    mm: remove compressed copy from zram in-memory
    
    Swap subsystem does lazy swap slot free with expecting the page would be
    swapped out again so we can avoid unnecessary write.
    
    But the problem in in-memory swap(ex, zram) is that it consumes memory
    space until vm_swap_full(ie, used half of all of swap device) condition
    meet.  It could be bad if we use multiple swap device, small in-memory
    swap and big storage swap or in-memory swap alone.
    
    This patch makes swap subsystem free swap slot as soon as swap-read is
    completed and make the swapcache page dirty so the page should be
    written out the swap device to reclaim it.  It means we never lose it.
    
    I tested this patch with kernel compile workload.
    
    1. before
    
       compile time : 9882.42
       zram max wasted space by fragmentation: 13471881 byte
       memory space consumed by zram: 174227456 byte
       the number of slot free notify: 206684
    
    2. after
    
       compile time : 9653.90
       zram max wasted space by fragmentation: 11805932 byte
       memory space consumed by zram: 154001408 byte
       the number of slot free notify: 426972
    
    [akpm@linux-foundation.org: tweak comment text]
    [artem.savkov@gmail.com: fix BUG due to non-swapcache pages in end_swap_bio_read()]
    [akpm@linux-foundation.org: invert unlikely() test, augment comment, 80-col cleanup]
    Signed-off-by: Dan Magenheimer <dan.magenheimer@oracle.com>
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Signed-off-by: Artem Savkov <artem.savkov@gmail.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Seth Jennings <sjenning@linux.vnet.ibm.com>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Cc: Konrad Rzeszutek Wilk <konrad@darnok.org>
    Cc: Shaohua Li <shli@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index a8a3ef45fed7..ba05b64e5d8d 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -21,6 +21,7 @@
 #include <linux/writeback.h>
 #include <linux/frontswap.h>
 #include <linux/aio.h>
+#include <linux/blkdev.h>
 #include <asm/pgtable.h>
 
 static struct bio *get_swap_bio(gfp_t gfp_flags,
@@ -80,9 +81,54 @@ void end_swap_bio_read(struct bio *bio, int err)
 				imajor(bio->bi_bdev->bd_inode),
 				iminor(bio->bi_bdev->bd_inode),
 				(unsigned long long)bio->bi_sector);
-	} else {
-		SetPageUptodate(page);
+		goto out;
 	}
+
+	SetPageUptodate(page);
+
+	/*
+	 * There is no guarantee that the page is in swap cache - the software
+	 * suspend code (at least) uses end_swap_bio_read() against a non-
+	 * swapcache page.  So we must check PG_swapcache before proceeding with
+	 * this optimization.
+	 */
+	if (likely(PageSwapCache(page))) {
+		struct swap_info_struct *sis;
+
+		sis = page_swap_info(page);
+		if (sis->flags & SWP_BLKDEV) {
+			/*
+			 * The swap subsystem performs lazy swap slot freeing,
+			 * expecting that the page will be swapped out again.
+			 * So we can avoid an unnecessary write if the page
+			 * isn't redirtied.
+			 * This is good for real swap storage because we can
+			 * reduce unnecessary I/O and enhance wear-leveling
+			 * if an SSD is used as the as swap device.
+			 * But if in-memory swap device (eg zram) is used,
+			 * this causes a duplicated copy between uncompressed
+			 * data in VM-owned memory and compressed data in
+			 * zram-owned memory.  So let's free zram-owned memory
+			 * and make the VM-owned decompressed page *dirty*,
+			 * so the page should be swapped out somewhere again if
+			 * we again wish to reclaim it.
+			 */
+			struct gendisk *disk = sis->bdev->bd_disk;
+			if (disk->fops->swap_slot_free_notify) {
+				swp_entry_t entry;
+				unsigned long offset;
+
+				entry.val = page_private(page);
+				offset = swp_offset(entry);
+
+				SetPageDirty(page);
+				disk->fops->swap_slot_free_notify(sis->bdev,
+						offset);
+			}
+		}
+	}
+
+out:
 	unlock_page(page);
 	bio_put(bio);
 }

commit 4de13d7aa8f4d02f4dc99d4609575659f92b3c5a
Merge: 5af43c24ca59 b8d4a5bf6a04
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 8 10:13:35 2013 -0700

    Merge branch 'for-3.10/core' of git://git.kernel.dk/linux-block
    
    Pull block core updates from Jens Axboe:
    
     - Major bit is Kents prep work for immutable bio vecs.
    
     - Stable candidate fix for a scheduling-while-atomic in the queue
       bypass operation.
    
     - Fix for the hang on exceeded rq->datalen 32-bit unsigned when merging
       discard bios.
    
     - Tejuns changes to convert the writeback thread pool to the generic
       workqueue mechanism.
    
     - Runtime PM framework, SCSI patches exists on top of these in James'
       tree.
    
     - A few random fixes.
    
    * 'for-3.10/core' of git://git.kernel.dk/linux-block: (40 commits)
      relay: move remove_buf_file inside relay_close_buf
      partitions/efi.c: replace useless kzalloc's by kmalloc's
      fs/block_dev.c: fix iov_shorten() criteria in blkdev_aio_read()
      block: fix max discard sectors limit
      blkcg: fix "scheduling while atomic" in blk_queue_bypass_start
      Documentation: cfq-iosched: update documentation help for cfq tunables
      writeback: expose the bdi_wq workqueue
      writeback: replace custom worker pool implementation with unbound workqueue
      writeback: remove unused bdi_pending_list
      aoe: Fix unitialized var usage
      bio-integrity: Add explicit field for owner of bip_buf
      block: Add an explicit bio flag for bios that own their bvec
      block: Add bio_alloc_pages()
      block: Convert some code to bio_for_each_segment_all()
      block: Add bio_for_each_segment_all()
      bounce: Refactor __blk_queue_bounce to not use bi_io_vec
      raid1: use bio_copy_data()
      pktcdvd: Use bio_reset() in disabled code to kill bi_idx usage
      pktcdvd: use bio_copy_data()
      block: Add bio_copy_data()
      ...

commit a27bb332c04cec8c4afd7912df0dc7890db27560
Author: Kent Overstreet <koverstreet@google.com>
Date:   Tue May 7 16:19:08 2013 -0700

    aio: don't include aio.h in sched.h
    
    Faster kernel compiles by way of fewer unnecessary includes.
    
    [akpm@linux-foundation.org: fix fallout]
    [akpm@linux-foundation.org: fix build]
    Signed-off-by: Kent Overstreet <koverstreet@google.com>
    Cc: Zach Brown <zab@redhat.com>
    Cc: Felipe Balbi <balbi@ti.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Mark Fasheh <mfasheh@suse.com>
    Cc: Joel Becker <jlbec@evilplan.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Asai Thambi S P <asamymuthupa@micron.com>
    Cc: Selvan Mani <smani@micron.com>
    Cc: Sam Bradshaw <sbradshaw@micron.com>
    Cc: Jeff Moyer <jmoyer@redhat.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Benjamin LaHaise <bcrl@kvack.org>
    Reviewed-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index bb5d75274686..06a8842a6ec6 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -20,6 +20,7 @@
 #include <linux/buffer_head.h>
 #include <linux/writeback.h>
 #include <linux/frontswap.h>
+#include <linux/aio.h>
 #include <asm/pgtable.h>
 
 static struct bio *get_swap_bio(gfp_t gfp_flags,

commit 0cdc444a67ccdbd58bfbcba865cb17a9f17a7691
Author: Mel Gorman <mgorman@suse.de>
Date:   Mon Apr 29 15:08:48 2013 -0700

    mm: swap: mark swap pages writeback before queueing for direct IO
    
    As pointed out by Andrew Morton, the swap-over-NFS writeback is not
    setting PageWriteback before it is queued for direct IO.  While swap
    pages do not participate in BDI or process dirty accounting and the IO
    is synchronous, the writeback bit is still required and not setting it
    in this case was an oversight.  swapoff depends on the page writeback to
    synchronoise all pending writes on a swap page before it is reused.
    Swapcache freeing and reuse depend on checking the PageWriteback under
    lock to ensure the page is safe to reuse.
    
    Direct IO handlers and the direct IO handler for NFS do not deal with
    PageWriteback as they are synchronous writes.  In the case of NFS, it
    schedules pages (or a page in the case of swap) for IO and then waits
    synchronously for IO to complete in nfs_direct_write().  It is
    recognised that this is a slowdown from normal swap handling which is
    asynchronous and uses a completion handler.  Shoving PageWriteback
    handling down into direct IO handlers looks like a bad fit to handle the
    swap case although it may have to be dealt with some day if swap is
    converted to use direct IO in general and bmap is finally done away
    with.  At that point it will be necessary to refit asynchronous direct
    IO with completion handlers onto the swap subsystem.
    
    As swapcache currently depends on PageWriteback to protect against
    races, this patch sets PageWriteback under the page lock before queueing
    it for direct IO.  It is cleared when the direct IO handler returns.  IO
    errors are treated similarly to the direct-to-bio case except PageError
    is not set as in the case of swap-over-NFS, it is likely to be a
    transient error.
    
    It was asked what prevents such a page being reclaimed in parallel.
    With this patch applied, such a page will now be skipped (most of the
    time) or blocked until the writeback completes.  Reclaim checks
    PageWriteback under the page lock before calling try_to_free_swap and
    the page lock should prevent the page being requeued for IO before it is
    freed.
    
    This and Jerome's related patch should considered for -stable as far
    back as 3.6 when swap-over-NFS was introduced.
    
    [akpm@linux-foundation.org: use pr_err_ratelimited()]
    [akpm@linux-foundation.org: remove hopefully-unneeded cast in printk]
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Cc: Jerome Marchand <jmarchan@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: <stable@vger.kernel.org>    [3.6+]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index eb3300fa89dc..bb5d75274686 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -223,6 +223,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		kiocb.ki_left = PAGE_SIZE;
 		kiocb.ki_nbytes = PAGE_SIZE;
 
+		set_page_writeback(page);
 		unlock_page(page);
 		ret = mapping->a_ops->direct_IO(KERNEL_WRITE,
 						&kiocb, &iov,
@@ -232,8 +233,22 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 			count_vm_event(PSWPOUT);
 			ret = 0;
 		} else {
+			/*
+			 * In the case of swap-over-nfs, this can be a
+			 * temporary failure if the system has limited
+			 * memory for allocating transmit buffers.
+			 * Mark the page dirty and avoid
+			 * rotate_reclaimable_page but rate-limit the
+			 * messages but do not flag PageError like
+			 * the normal direct-to-bio case as it could
+			 * be temporary.
+			 */
 			set_page_dirty(page);
+			ClearPageReclaim(page);
+			pr_err_ratelimited("Write error on dio swapfile (%Lu)\n",
+				page_file_offset(page));
 		}
+		end_page_writeback(page);
 		return ret;
 	}
 

commit 2d30d31ea3c5be426ce25607b9bd1835acb85e0a
Author: Jerome Marchand <jmarchan@redhat.com>
Date:   Mon Apr 29 15:08:47 2013 -0700

    swap: redirty page if page write fails on swap file
    
    Since commit 62c230bc1790 ("mm: add support for a filesystem to activate
    swap files and use direct_IO for writing swap pages"), swap_writepage()
    calls direct_IO on swap files.  However, in that case the page isn't
    redirtied if I/O fails, and is therefore handled afterwards as if it has
    been successfully written to the swap file, leading to memory corruption
    when the page is eventually swapped back in.
    
    This patch sets the page dirty when direct_IO() fails.  It fixes a
    memory corruption that happened while using swap-over-NFS.
    
    Signed-off-by: Jerome Marchand <jmarchan@redhat.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Acked-by: Mel Gorman <mgorman@suse.de>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: <stable@vger.kernel.org>    [3.6+]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 8e0e5c0e7cdb..eb3300fa89dc 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -231,6 +231,8 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc,
 		if (ret == PAGE_SIZE) {
 			count_vm_event(PSWPOUT);
 			ret = 0;
+		} else {
+			set_page_dirty(page);
 		}
 		return ret;
 	}

commit 1eec6702a80e04416d528846a5ff2122484d95ec
Author: Seth Jennings <sjenning@linux.vnet.ibm.com>
Date:   Mon Apr 29 15:08:35 2013 -0700

    mm: allow for outstanding swap writeback accounting
    
    To prevent flooding the swap device with writebacks, frontswap backends
    need to count and limit the number of outstanding writebacks.  The
    incrementing of the counter can be done before the call to
    __swap_writepage().  However, the caller must receive a notification
    when the writeback completes in order to decrement the counter.
    
    To achieve this functionality, this patch modifies __swap_writepage() to
    take the bio completion callback function as an argument.
    
    end_swap_bio_write(), the normal bio completion function, is also made
    non-static so that code doing the accounting can call it after the
    accounting is done.
    
    There should be no behavioural change to existing code.
    
    Signed-off-by: Seth Jennings <sjenning@linux.vnet.ibm.com>
    Signed-off-by: Bob Liu <bob.liu@oracle.com>
    Acked-by: Minchan Kim <minchan@kernel.org>
    Reviewed-by: Dan Magenheimer <dan.magenheimer@oracle.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 8e6bcf176cfb..8e0e5c0e7cdb 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -42,7 +42,7 @@ static struct bio *get_swap_bio(gfp_t gfp_flags,
 	return bio;
 }
 
-static void end_swap_bio_write(struct bio *bio, int err)
+void end_swap_bio_write(struct bio *bio, int err)
 {
 	const int uptodate = test_bit(BIO_UPTODATE, &bio->bi_flags);
 	struct page *page = bio->bi_io_vec[0].bv_page;
@@ -197,12 +197,13 @@ int swap_writepage(struct page *page, struct writeback_control *wbc)
 		end_page_writeback(page);
 		goto out;
 	}
-	ret = __swap_writepage(page, wbc);
+	ret = __swap_writepage(page, wbc, end_swap_bio_write);
 out:
 	return ret;
 }
 
-int __swap_writepage(struct page *page, struct writeback_control *wbc)
+int __swap_writepage(struct page *page, struct writeback_control *wbc,
+	void (*end_write_func)(struct bio *, int))
 {
 	struct bio *bio;
 	int ret = 0, rw = WRITE;
@@ -234,7 +235,7 @@ int __swap_writepage(struct page *page, struct writeback_control *wbc)
 		return ret;
 	}
 
-	bio = get_swap_bio(GFP_NOIO, page, end_swap_bio_write);
+	bio = get_swap_bio(GFP_NOIO, page, end_write_func);
 	if (bio == NULL) {
 		set_page_dirty(page);
 		unlock_page(page);

commit 2f772e6cadf8ad8fca38927b17e6be028be669f5
Author: Seth Jennings <sjenning@linux.vnet.ibm.com>
Date:   Mon Apr 29 15:08:34 2013 -0700

    mm: break up swap_writepage() for frontswap backends
    
    swap_writepage() is currently where frontswap hooks into the swap write
    path to capture pages with the frontswap_store() function.  However, if
    a frontswap backend wants to "resume" the writeback of a page to the
    swap device, it can't call swap_writepage() as the page will simply
    reenter the backend.
    
    This patch separates swap_writepage() into a top and bottom half, the
    bottom half named __swap_writepage() to allow a frontswap backend, like
    zswap, to resume writeback beyond the frontswap_store() hook.
    
    __add_to_swap_cache() is also made non-static so that the page for which
    writeback is to be resumed can be added to the swap cache.
    
    Signed-off-by: Seth Jennings <sjenning@linux.vnet.ibm.com>
    Signed-off-by: Bob Liu <bob.liu@oracle.com>
    Acked-by: Minchan Kim <minchan@kernel.org>
    Reviewed-by: Dan Magenheimer <dan.magenheimer@oracle.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 78eee32ee486..8e6bcf176cfb 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -185,9 +185,7 @@ int generic_swapfile_activate(struct swap_info_struct *sis,
  */
 int swap_writepage(struct page *page, struct writeback_control *wbc)
 {
-	struct bio *bio;
-	int ret = 0, rw = WRITE;
-	struct swap_info_struct *sis = page_swap_info(page);
+	int ret = 0;
 
 	if (try_to_free_swap(page)) {
 		unlock_page(page);
@@ -199,6 +197,16 @@ int swap_writepage(struct page *page, struct writeback_control *wbc)
 		end_page_writeback(page);
 		goto out;
 	}
+	ret = __swap_writepage(page, wbc);
+out:
+	return ret;
+}
+
+int __swap_writepage(struct page *page, struct writeback_control *wbc)
+{
+	struct bio *bio;
+	int ret = 0, rw = WRITE;
+	struct swap_info_struct *sis = page_swap_info(page);
 
 	if (sis->flags & SWP_FILE) {
 		struct kiocb kiocb;

commit 4f2ac93c175c4922bdddbfec6cad94b32cea0070
Author: Kent Overstreet <koverstreet@google.com>
Date:   Tue Sep 4 15:23:14 2012 -0700

    block: Remove bi_idx references
    
    For immutable bvecs, all bi_idx usage needs to be audited - so here
    we're removing all the unnecessary uses.
    
    Most of these are places where it was being initialized on a bio that
    was just allocated, a few others are conversions to standard macros.
    
    Signed-off-by: Kent Overstreet <koverstreet@google.com>
    CC: Jens Axboe <axboe@kernel.dk>

diff --git a/mm/page_io.c b/mm/page_io.c
index 78eee32ee486..8d3c0c088105 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -35,7 +35,6 @@ static struct bio *get_swap_bio(gfp_t gfp_flags,
 		bio->bi_io_vec[0].bv_len = PAGE_SIZE;
 		bio->bi_io_vec[0].bv_offset = 0;
 		bio->bi_vcnt = 1;
-		bio->bi_idx = 0;
 		bio->bi_size = PAGE_SIZE;
 		bio->bi_end_io = end_io;
 	}

commit 5a178119b0fbe37f7dfb602b37df9cc4b1dc9d71
Author: Mel Gorman <mgorman@suse.de>
Date:   Tue Jul 31 16:45:02 2012 -0700

    mm: add support for direct_IO to highmem pages
    
    The patch "mm: add support for a filesystem to activate swap files and use
    direct_IO for writing swap pages" added support for using direct_IO to
    write swap pages but it is insufficient for highmem pages.
    
    To support highmem pages, this patch kmaps() the page before calling the
    direct_IO() handler.  As direct_IO deals with virtual addresses an
    additional helper is necessary for get_kernel_pages() to lookup the struct
    page for a kmap virtual address.
    
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Acked-by: Rik van Riel <riel@redhat.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Eric B Munson <emunson@mgebm.net>
    Cc: Eric Paris <eparis@redhat.com>
    Cc: James Morris <jmorris@namei.org>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Mike Christie <michaelc@cs.wisc.edu>
    Cc: Neil Brown <neilb@suse.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Sebastian Andrzej Siewior <sebastian@breakpoint.cc>
    Cc: Trond Myklebust <Trond.Myklebust@netapp.com>
    Cc: Xiaotian Feng <dfeng@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 4a379629e31f..78eee32ee486 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -205,7 +205,7 @@ int swap_writepage(struct page *page, struct writeback_control *wbc)
 		struct file *swap_file = sis->swap_file;
 		struct address_space *mapping = swap_file->f_mapping;
 		struct iovec iov = {
-			.iov_base = page_address(page),
+			.iov_base = kmap(page),
 			.iov_len  = PAGE_SIZE,
 		};
 
@@ -218,6 +218,7 @@ int swap_writepage(struct page *page, struct writeback_control *wbc)
 		ret = mapping->a_ops->direct_IO(KERNEL_WRITE,
 						&kiocb, &iov,
 						kiocb.ki_pos, 1);
+		kunmap(page);
 		if (ret == PAGE_SIZE) {
 			count_vm_event(PSWPOUT);
 			ret = 0;

commit a509bc1a9e487d952d9404318f7f990166ab57a7
Author: Mel Gorman <mgorman@suse.de>
Date:   Tue Jul 31 16:44:57 2012 -0700

    mm: swap: implement generic handler for swap_activate
    
    The version of swap_activate introduced is sufficient for swap-over-NFS
    but would not provide enough information to implement a generic handler.
    This patch shuffles things slightly to ensure the same information is
    available for aops->swap_activate() as is available to the core.
    
    No functionality change.
    
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Acked-by: Rik van Riel <riel@redhat.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Eric B Munson <emunson@mgebm.net>
    Cc: Eric Paris <eparis@redhat.com>
    Cc: James Morris <jmorris@namei.org>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Mike Christie <michaelc@cs.wisc.edu>
    Cc: Neil Brown <neilb@suse.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Sebastian Andrzej Siewior <sebastian@breakpoint.cc>
    Cc: Trond Myklebust <Trond.Myklebust@netapp.com>
    Cc: Xiaotian Feng <dfeng@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 307a3e795290..4a379629e31f 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -87,6 +87,98 @@ void end_swap_bio_read(struct bio *bio, int err)
 	bio_put(bio);
 }
 
+int generic_swapfile_activate(struct swap_info_struct *sis,
+				struct file *swap_file,
+				sector_t *span)
+{
+	struct address_space *mapping = swap_file->f_mapping;
+	struct inode *inode = mapping->host;
+	unsigned blocks_per_page;
+	unsigned long page_no;
+	unsigned blkbits;
+	sector_t probe_block;
+	sector_t last_block;
+	sector_t lowest_block = -1;
+	sector_t highest_block = 0;
+	int nr_extents = 0;
+	int ret;
+
+	blkbits = inode->i_blkbits;
+	blocks_per_page = PAGE_SIZE >> blkbits;
+
+	/*
+	 * Map all the blocks into the extent list.  This code doesn't try
+	 * to be very smart.
+	 */
+	probe_block = 0;
+	page_no = 0;
+	last_block = i_size_read(inode) >> blkbits;
+	while ((probe_block + blocks_per_page) <= last_block &&
+			page_no < sis->max) {
+		unsigned block_in_page;
+		sector_t first_block;
+
+		first_block = bmap(inode, probe_block);
+		if (first_block == 0)
+			goto bad_bmap;
+
+		/*
+		 * It must be PAGE_SIZE aligned on-disk
+		 */
+		if (first_block & (blocks_per_page - 1)) {
+			probe_block++;
+			goto reprobe;
+		}
+
+		for (block_in_page = 1; block_in_page < blocks_per_page;
+					block_in_page++) {
+			sector_t block;
+
+			block = bmap(inode, probe_block + block_in_page);
+			if (block == 0)
+				goto bad_bmap;
+			if (block != first_block + block_in_page) {
+				/* Discontiguity */
+				probe_block++;
+				goto reprobe;
+			}
+		}
+
+		first_block >>= (PAGE_SHIFT - blkbits);
+		if (page_no) {	/* exclude the header page */
+			if (first_block < lowest_block)
+				lowest_block = first_block;
+			if (first_block > highest_block)
+				highest_block = first_block;
+		}
+
+		/*
+		 * We found a PAGE_SIZE-length, PAGE_SIZE-aligned run of blocks
+		 */
+		ret = add_swap_extent(sis, page_no, 1, first_block);
+		if (ret < 0)
+			goto out;
+		nr_extents += ret;
+		page_no++;
+		probe_block += blocks_per_page;
+reprobe:
+		continue;
+	}
+	ret = nr_extents;
+	*span = 1 + highest_block - lowest_block;
+	if (page_no == 0)
+		page_no = 1;	/* force Empty message */
+	sis->max = page_no;
+	sis->pages = page_no - 1;
+	sis->highest_bit = page_no - 1;
+out:
+	return ret;
+bad_bmap:
+	printk(KERN_ERR "swapon: swapfile has holes\n");
+	ret = -EINVAL;
+	goto out;
+}
+
 /*
  * We may have stale swap cache pages in memory: notice
  * them here and get rid of the unnecessary final write.

commit 62c230bc1790923a1b35da03596a68a6c9b5b100
Author: Mel Gorman <mgorman@suse.de>
Date:   Tue Jul 31 16:44:55 2012 -0700

    mm: add support for a filesystem to activate swap files and use direct_IO for writing swap pages
    
    Currently swapfiles are managed entirely by the core VM by using ->bmap to
    allocate space and write to the blocks directly.  This effectively ensures
    that the underlying blocks are allocated and avoids the need for the swap
    subsystem to locate what physical blocks store offsets within a file.
    
    If the swap subsystem is to use the filesystem information to locate the
    blocks, it is critical that information such as block groups, block
    bitmaps and the block descriptor table that map the swap file were
    resident in memory.  This patch adds address_space_operations that the VM
    can call when activating or deactivating swap backed by a file.
    
      int swap_activate(struct file *);
      int swap_deactivate(struct file *);
    
    The ->swap_activate() method is used to communicate to the file that the
    VM relies on it, and the address_space should take adequate measures such
    as reserving space in the underlying device, reserving memory for mempools
    and pinning information such as the block descriptor table in memory.  The
    ->swap_deactivate() method is called on sys_swapoff() if ->swap_activate()
    returned success.
    
    After a successful swapfile ->swap_activate, the swapfile is marked
    SWP_FILE and swapper_space.a_ops will proxy to
    sis->swap_file->f_mappings->a_ops using ->direct_io to write swapcache
    pages and ->readpage to read.
    
    It is perfectly possible that direct_IO be used to read the swap pages but
    it is an unnecessary complication.  Similarly, it is possible that
    ->writepage be used instead of direct_io to write the pages but filesystem
    developers have stated that calling writepage from the VM is undesirable
    for a variety of reasons and using direct_IO opens up the possibility of
    writing back batches of swap pages in the future.
    
    [a.p.zijlstra@chello.nl: Original patch]
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Acked-by: Rik van Riel <riel@redhat.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Eric B Munson <emunson@mgebm.net>
    Cc: Eric Paris <eparis@redhat.com>
    Cc: James Morris <jmorris@namei.org>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Mike Christie <michaelc@cs.wisc.edu>
    Cc: Neil Brown <neilb@suse.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Sebastian Andrzej Siewior <sebastian@breakpoint.cc>
    Cc: Trond Myklebust <Trond.Myklebust@netapp.com>
    Cc: Xiaotian Feng <dfeng@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 34f02923744c..307a3e795290 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -17,6 +17,7 @@
 #include <linux/swap.h>
 #include <linux/bio.h>
 #include <linux/swapops.h>
+#include <linux/buffer_head.h>
 #include <linux/writeback.h>
 #include <linux/frontswap.h>
 #include <asm/pgtable.h>
@@ -94,6 +95,7 @@ int swap_writepage(struct page *page, struct writeback_control *wbc)
 {
 	struct bio *bio;
 	int ret = 0, rw = WRITE;
+	struct swap_info_struct *sis = page_swap_info(page);
 
 	if (try_to_free_swap(page)) {
 		unlock_page(page);
@@ -105,6 +107,32 @@ int swap_writepage(struct page *page, struct writeback_control *wbc)
 		end_page_writeback(page);
 		goto out;
 	}
+
+	if (sis->flags & SWP_FILE) {
+		struct kiocb kiocb;
+		struct file *swap_file = sis->swap_file;
+		struct address_space *mapping = swap_file->f_mapping;
+		struct iovec iov = {
+			.iov_base = page_address(page),
+			.iov_len  = PAGE_SIZE,
+		};
+
+		init_sync_kiocb(&kiocb, swap_file);
+		kiocb.ki_pos = page_file_offset(page);
+		kiocb.ki_left = PAGE_SIZE;
+		kiocb.ki_nbytes = PAGE_SIZE;
+
+		unlock_page(page);
+		ret = mapping->a_ops->direct_IO(KERNEL_WRITE,
+						&kiocb, &iov,
+						kiocb.ki_pos, 1);
+		if (ret == PAGE_SIZE) {
+			count_vm_event(PSWPOUT);
+			ret = 0;
+		}
+		return ret;
+	}
+
 	bio = get_swap_bio(GFP_NOIO, page, end_swap_bio_write);
 	if (bio == NULL) {
 		set_page_dirty(page);
@@ -126,6 +154,7 @@ int swap_readpage(struct page *page)
 {
 	struct bio *bio;
 	int ret = 0;
+	struct swap_info_struct *sis = page_swap_info(page);
 
 	VM_BUG_ON(!PageLocked(page));
 	VM_BUG_ON(PageUptodate(page));
@@ -134,6 +163,17 @@ int swap_readpage(struct page *page)
 		unlock_page(page);
 		goto out;
 	}
+
+	if (sis->flags & SWP_FILE) {
+		struct file *swap_file = sis->swap_file;
+		struct address_space *mapping = swap_file->f_mapping;
+
+		ret = mapping->a_ops->readpage(swap_file, page);
+		if (!ret)
+			count_vm_event(PSWPIN);
+		return ret;
+	}
+
 	bio = get_swap_bio(GFP_KERNEL, page, end_swap_bio_read);
 	if (bio == NULL) {
 		unlock_page(page);
@@ -145,3 +185,15 @@ int swap_readpage(struct page *page)
 out:
 	return ret;
 }
+
+int swap_set_page_dirty(struct page *page)
+{
+	struct swap_info_struct *sis = page_swap_info(page);
+
+	if (sis->flags & SWP_FILE) {
+		struct address_space *mapping = sis->swap_file->f_mapping;
+		return mapping->a_ops->set_page_dirty(page);
+	} else {
+		return __set_page_dirty_no_writeback(page);
+	}
+}

commit 165c8aed5bbc6bdddbccae0ba9db451732558ff9
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Tue May 15 11:32:15 2012 -0400

    frontswap: s/put_page/store/g s/get_page/load
    
    Sounds so much more natural.
    
    Suggested-by: Andrea Arcangeli <aarcange@redhat.com>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/mm/page_io.c b/mm/page_io.c
index 651a91259317..34f02923744c 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -99,7 +99,7 @@ int swap_writepage(struct page *page, struct writeback_control *wbc)
 		unlock_page(page);
 		goto out;
 	}
-	if (frontswap_put_page(page) == 0) {
+	if (frontswap_store(page) == 0) {
 		set_page_writeback(page);
 		unlock_page(page);
 		end_page_writeback(page);
@@ -129,7 +129,7 @@ int swap_readpage(struct page *page)
 
 	VM_BUG_ON(!PageLocked(page));
 	VM_BUG_ON(PageUptodate(page));
-	if (frontswap_get_page(page) == 0) {
+	if (frontswap_load(page) == 0) {
 		SetPageUptodate(page);
 		unlock_page(page);
 		goto out;

commit 38b5faf4b178d5279b1fca5d7dadc68881342660
Author: Dan Magenheimer <dan.magenheimer@oracle.com>
Date:   Mon Apr 9 17:08:06 2012 -0600

    mm: frontswap: core swap subsystem hooks and headers
    
    This patch, 2of4, contains the changes to the core swap subsystem.
    This includes:
    
    (1) makes available core swap data structures (swap_lock, swap_list and
    swap_info) that are needed by frontswap.c but we don't need to expose them
    to the dozens of files that include swap.h so we create a new swapfile.h
    just to extern-ify these and modify their declarations to non-static
    
    (2) adds frontswap-related elements to swap_info_struct.  Frontswap_map
    points to vzalloc'ed one-bit-per-swap-page metadata that indicates
    whether the swap page is in frontswap or in the device and frontswap_pages
    counts how many pages are in frontswap.
    
    (3) adds hooks in the swap subsystem and extends try_to_unuse so that
    frontswap_shrink can do a "partial swapoff".
    
    Note that a failed frontswap_map allocation is safe... failure is noted
    by lack of "FS" in the subsequent printk.
    
    ---
    
    [v14: rebase to 3.4-rc2]
    [v10: no change]
    [v9: akpm@linux-foundation.org: mark some statics __read_mostly]
    [v9: akpm@linux-foundation.org: add clarifying comments]
    [v9: akpm@linux-foundation.org: no need to loop repeating try_to_unuse]
    [v9: error27@gmail.com: remove superfluous check for NULL]
    [v8: rebase to 3.0-rc4]
    [v8: kamezawa.hiroyu@jp.fujitsu.com: change counter to atomic_t to avoid races]
    [v8: kamezawa.hiroyu@jp.fujitsu.com: comment to clarify informational counters]
    [v7: rebase to 3.0-rc3]
    [v7: JBeulich@novell.com: add new swap struct elements only if config'd]
    [v6: rebase to 3.0-rc1]
    [v6: lliubbo@gmail.com: fix null pointer deref if vzalloc fails]
    [v6: konrad.wilk@oracl.com: various checks and code clarifications/comments]
    [v5: no change from v4]
    [v4: rebase to 2.6.39]
    Signed-off-by: Dan Magenheimer <dan.magenheimer@oracle.com>
    Reviewed-by: Kamezawa Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Acked-by: Jan Beulich <JBeulich@novell.com>
    Acked-by: Seth Jennings <sjenning@linux.vnet.ibm.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Cc: Matthew Wilcox <matthew@wil.cx>
    Cc: Chris Mason <chris.mason@oracle.com>
    Cc: Rik Riel <riel@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    [v11: Rebased, fixed mm/swapfile.c context change]
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

diff --git a/mm/page_io.c b/mm/page_io.c
index dc76b4d0611e..651a91259317 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -18,6 +18,7 @@
 #include <linux/bio.h>
 #include <linux/swapops.h>
 #include <linux/writeback.h>
+#include <linux/frontswap.h>
 #include <asm/pgtable.h>
 
 static struct bio *get_swap_bio(gfp_t gfp_flags,
@@ -98,6 +99,12 @@ int swap_writepage(struct page *page, struct writeback_control *wbc)
 		unlock_page(page);
 		goto out;
 	}
+	if (frontswap_put_page(page) == 0) {
+		set_page_writeback(page);
+		unlock_page(page);
+		end_page_writeback(page);
+		goto out;
+	}
 	bio = get_swap_bio(GFP_NOIO, page, end_swap_bio_write);
 	if (bio == NULL) {
 		set_page_dirty(page);
@@ -122,6 +129,11 @@ int swap_readpage(struct page *page)
 
 	VM_BUG_ON(!PageLocked(page));
 	VM_BUG_ON(PageUptodate(page));
+	if (frontswap_get_page(page) == 0) {
+		SetPageUptodate(page);
+		unlock_page(page);
+		goto out;
+	}
 	bio = get_swap_bio(GFP_KERNEL, page, end_swap_bio_read);
 	if (bio == NULL) {
 		unlock_page(page);

commit 721a9602e6607417c6bc15b18e97a2f35266c690
Author: Jens Axboe <jaxboe@fusionio.com>
Date:   Wed Mar 9 11:56:30 2011 +0100

    block: kill off REQ_UNPLUG
    
    With the plugging now being explicitly controlled by the
    submitter, callers need not pass down unplugging hints
    to the block layer. If they want to unplug, it's because they
    manually plugged on their own - in which case, they should just
    unplug at will.
    
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/mm/page_io.c b/mm/page_io.c
index 2dee975bf469..dc76b4d0611e 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -106,7 +106,7 @@ int swap_writepage(struct page *page, struct writeback_control *wbc)
 		goto out;
 	}
 	if (wbc->sync_mode == WB_SYNC_ALL)
-		rw |= REQ_SYNC | REQ_UNPLUG;
+		rw |= REQ_SYNC;
 	count_vm_event(PSWPOUT);
 	set_page_writeback(page);
 	unlock_page(page);

commit 7b6d91daee5cac6402186ff224c3af39d79f4a0e
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Aug 7 18:20:39 2010 +0200

    block: unify flags for struct bio and struct request
    
    Remove the current bio flags and reuse the request flags for the bio, too.
    This allows to more easily trace the type of I/O from the filesystem
    down to the block driver.  There were two flags in the bio that were
    missing in the requests:  BIO_RW_UNPLUG and BIO_RW_AHEAD.  Also I've
    renamed two request flags that had a superflous RW in them.
    
    Note that the flags are in bio.h despite having the REQ_ name - as
    blkdev.h includes bio.h that is the only way to go for now.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

diff --git a/mm/page_io.c b/mm/page_io.c
index 31a3b962230a..2dee975bf469 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -106,7 +106,7 @@ int swap_writepage(struct page *page, struct writeback_control *wbc)
 		goto out;
 	}
 	if (wbc->sync_mode == WB_SYNC_ALL)
-		rw |= (1 << BIO_RW_SYNCIO) | (1 << BIO_RW_UNPLUG);
+		rw |= REQ_SYNC | REQ_UNPLUG;
 	count_vm_event(PSWPOUT);
 	set_page_writeback(page);
 	unlock_page(page);

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/mm/page_io.c b/mm/page_io.c
index a19af956ee1b..31a3b962230a 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -12,6 +12,7 @@
 
 #include <linux/mm.h>
 #include <linux/kernel_stat.h>
+#include <linux/gfp.h>
 #include <linux/pagemap.h>
 #include <linux/swap.h>
 #include <linux/bio.h>

commit d4906e1aa516cc965292b43b5a26122dd4344e7e
Author: Lee Schermerhorn <Lee.Schermerhorn@hp.com>
Date:   Mon Dec 14 17:58:49 2009 -0800

    swap: rework map_swap_page() again
    
    Seems that page_io.c doesn't really need to know that page_private(page)
    is the swp_entry 'val'.  Rework map_swap_page() to do what its name says
    and map a page to a page offset in the swap space.
    
    The only other caller of map_swap_page() is internal to mm/swapfile.c and
    it does want to map a swap entry to the 'sector'.  So rename
    map_swap_page() to map_swap_entry(), make it 'static' and and implement
    map_swap_page() as a wrapper around that.
    
    Signed-off-by: Lee Schermerhorn <lee.schermerhorn@hp.com>
    Cc: Hugh Dickins <hugh.dickins@tiscali.co.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index afeed89a0a5d..a19af956ee1b 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -26,9 +26,7 @@ static struct bio *get_swap_bio(gfp_t gfp_flags,
 
 	bio = bio_alloc(gfp_flags, 1);
 	if (bio) {
-		swp_entry_t entry;
-		entry.val = page_private(page);
-		bio->bi_sector = map_swap_page(entry, &bio->bi_bdev);
+		bio->bi_sector = map_swap_page(page, &bio->bi_bdev);
 		bio->bi_sector <<= PAGE_SHIFT - 9;
 		bio->bi_io_vec[0].bv_page = page;
 		bio->bi_io_vec[0].bv_len = PAGE_SIZE;

commit f29ad6a99b596b8169744d107bf088e8be9e8d0d
Author: Hugh Dickins <hugh.dickins@tiscali.co.uk>
Date:   Mon Dec 14 17:58:40 2009 -0800

    swap_info: private to swapfile.c
    
    The swap_info_struct is mostly private to mm/swapfile.c, with only
    one other in-tree user: get_swap_bio().  Adjust its interface to
    map_swap_page(), so that we can then remove get_swap_info_struct().
    
    But there is a popular user out-of-tree, TuxOnIce: so leave the
    declaration of swap_info_struct in linux/swap.h.
    
    Signed-off-by: Hugh Dickins <hugh.dickins@tiscali.co.uk>
    Cc: Nigel Cunningham <ncunningham@crca.org.au>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index c6f3e5071de3..afeed89a0a5d 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -19,20 +19,17 @@
 #include <linux/writeback.h>
 #include <asm/pgtable.h>
 
-static struct bio *get_swap_bio(gfp_t gfp_flags, pgoff_t index,
+static struct bio *get_swap_bio(gfp_t gfp_flags,
 				struct page *page, bio_end_io_t end_io)
 {
 	struct bio *bio;
 
 	bio = bio_alloc(gfp_flags, 1);
 	if (bio) {
-		struct swap_info_struct *sis;
-		swp_entry_t entry = { .val = index, };
-
-		sis = get_swap_info_struct(swp_type(entry));
-		bio->bi_sector = map_swap_page(sis, swp_offset(entry)) *
-					(PAGE_SIZE >> 9);
-		bio->bi_bdev = sis->bdev;
+		swp_entry_t entry;
+		entry.val = page_private(page);
+		bio->bi_sector = map_swap_page(entry, &bio->bi_bdev);
+		bio->bi_sector <<= PAGE_SHIFT - 9;
 		bio->bi_io_vec[0].bv_page = page;
 		bio->bi_io_vec[0].bv_len = PAGE_SIZE;
 		bio->bi_io_vec[0].bv_offset = 0;
@@ -102,8 +99,7 @@ int swap_writepage(struct page *page, struct writeback_control *wbc)
 		unlock_page(page);
 		goto out;
 	}
-	bio = get_swap_bio(GFP_NOIO, page_private(page), page,
-				end_swap_bio_write);
+	bio = get_swap_bio(GFP_NOIO, page, end_swap_bio_write);
 	if (bio == NULL) {
 		set_page_dirty(page);
 		unlock_page(page);
@@ -127,8 +123,7 @@ int swap_readpage(struct page *page)
 
 	VM_BUG_ON(!PageLocked(page));
 	VM_BUG_ON(PageUptodate(page));
-	bio = get_swap_bio(GFP_KERNEL, page_private(page), page,
-				end_swap_bio_read);
+	bio = get_swap_bio(GFP_KERNEL, page, end_swap_bio_read);
 	if (bio == NULL) {
 		unlock_page(page);
 		ret = -ENOMEM;

commit aca8bf323edd31ad462dc98c107c23a5c6022ca2
Author: Minchan Kim <minchan.kim@gmail.com>
Date:   Tue Jun 16 15:33:02 2009 -0700

    mm: remove file argument from swap_readpage()
    
    The file argument resulted from address_space's readpage long time ago.
    
    We don't use it any more.  Let's remove unnecessary argement.
    
    Signed-off-by: Minchan Kim <minchan.kim@gmail.com>
    Acked-by: Hugh Dickins <hugh.dickins@tiscali.co.uk>
    Reviewed-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 3023c475e041..c6f3e5071de3 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -120,7 +120,7 @@ int swap_writepage(struct page *page, struct writeback_control *wbc)
 	return ret;
 }
 
-int swap_readpage(struct file *file, struct page *page)
+int swap_readpage(struct page *page)
 {
 	struct bio *bio;
 	int ret = 0;

commit 93dbb393503d53cd226e5e1f0088fe8f4dbaa2b8
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Mon Feb 16 10:25:40 2009 +0100

    block: fix bad definition of BIO_RW_SYNC
    
    We can't OR shift values, so get rid of BIO_RW_SYNC and use BIO_RW_SYNCIO
    and BIO_RW_UNPLUG explicitly. This brings back the behaviour from before
    213d9417fec62ef4c3675621b9364a667954d4dd.
    
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/mm/page_io.c b/mm/page_io.c
index dc6ce0afbded..3023c475e041 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -111,7 +111,7 @@ int swap_writepage(struct page *page, struct writeback_control *wbc)
 		goto out;
 	}
 	if (wbc->sync_mode == WB_SYNC_ALL)
-		rw |= (1 << BIO_RW_SYNC);
+		rw |= (1 << BIO_RW_SYNCIO) | (1 << BIO_RW_UNPLUG);
 	count_vm_event(PSWPOUT);
 	set_page_writeback(page);
 	unlock_page(page);

commit a2c43eed8334e878702fca713b212ae2a11d84b9
Author: Hugh Dickins <hugh@veritas.com>
Date:   Tue Jan 6 14:39:36 2009 -0800

    mm: try_to_free_swap replaces remove_exclusive_swap_page
    
    remove_exclusive_swap_page(): its problem is in living up to its name.
    
    It doesn't matter if someone else has a reference to the page (raised
    page_count); it doesn't matter if the page is mapped into userspace
    (raised page_mapcount - though that hints it may be worth keeping the
    swap): all that matters is that there be no more references to the swap
    (and no writeback in progress).
    
    swapoff (try_to_unuse) has been removing pages from swapcache for years,
    with no concern for page count or page mapcount, and we used to have a
    comment in lookup_swap_cache() recognizing that: if you go for a page of
    swapcache, you'll get the right page, but it could have been removed from
    swapcache by the time you get page lock.
    
    So, give up asking for exclusivity: get rid of
    remove_exclusive_swap_page(), and remove_exclusive_swap_page_ref() and
    remove_exclusive_swap_page_count() which were spawned for the recent LRU
    work: replace them by the simpler try_to_free_swap() which just checks
    page_swapcount().
    
    Similarly, remove the page_count limitation from free_swap_and_count(),
    but assume that it's worth holding on to the swap if page is mapped and
    swap nowhere near full.  Add a vm_swap_full() test in free_swap_cache()?
    It would be consistent, but I think we probably have enough for now.
    
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Cc: Lee Schermerhorn <lee.schermerhorn@hp.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Nick Piggin <nickpiggin@yahoo.com.au>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Robin Holt <holt@sgi.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index d277a80efa71..dc6ce0afbded 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -98,7 +98,7 @@ int swap_writepage(struct page *page, struct writeback_control *wbc)
 	struct bio *bio;
 	int ret = 0, rw = WRITE;
 
-	if (remove_exclusive_swap_page(page)) {
+	if (try_to_free_swap(page)) {
 		unlock_page(page);
 		goto out;
 	}

commit 51726b1222863852c46ca21ed0115b85d1edfd89
Author: Hugh Dickins <hugh@veritas.com>
Date:   Tue Jan 6 14:39:25 2009 -0800

    mm: replace some BUG_ONs by VM_BUG_ONs
    
    The swap code is over-provisioned with BUG_ONs on assorted page flags,
    mostly dating back to 2.3.  They're good documentation, and guard against
    developer error, but a waste of space on most systems: change them to
    VM_BUG_ONs, conditional on CONFIG_DEBUG_VM.  Just delete the PagePrivate
    ones: they're later, from 2.5.69, but even less interesting now.
    
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Reviewed-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Nick Piggin <nickpiggin@yahoo.com.au>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 065c4480eaf0..d277a80efa71 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -125,8 +125,8 @@ int swap_readpage(struct file *file, struct page *page)
 	struct bio *bio;
 	int ret = 0;
 
-	BUG_ON(!PageLocked(page));
-	BUG_ON(PageUptodate(page));
+	VM_BUG_ON(!PageLocked(page));
+	VM_BUG_ON(PageUptodate(page));
 	bio = get_swap_bio(GFP_KERNEL, page_private(page), page,
 				end_swap_bio_read);
 	if (bio == NULL) {

commit 0ed361dec36945f3116ee1338638ada9a8920905
Author: Nick Piggin <npiggin@suse.de>
Date:   Mon Feb 4 22:29:34 2008 -0800

    mm: fix PageUptodate data race
    
    After running SetPageUptodate, preceeding stores to the page contents to
    actually bring it uptodate may not be ordered with the store to set the
    page uptodate.
    
    Therefore, another CPU which checks PageUptodate is true, then reads the
    page contents can get stale data.
    
    Fix this by having an smp_wmb before SetPageUptodate, and smp_rmb after
    PageUptodate.
    
    Many places that test PageUptodate, do so with the page locked, and this
    would be enough to ensure memory ordering in those places if
    SetPageUptodate were only called while the page is locked.  Unfortunately
    that is not always the case for some filesystems, but it could be an idea
    for the future.
    
    Also bring the handling of anonymous page uptodateness in line with that of
    file backed page management, by marking anon pages as uptodate when they
    _are_ uptodate, rather than when our implementation requires that they be
    marked as such.  Doing allows us to get rid of the smp_wmb's in the page
    copying functions, which were especially added for anonymous pages for an
    analogous memory ordering problem.  Both file and anonymous pages are
    handled with the same barriers.
    
    FAQ:
    Q. Why not do this in flush_dcache_page?
    A. Firstly, flush_dcache_page handles only one side (the smb side) of the
    ordering protocol; we'd still need smp_rmb somewhere. Secondly, hiding away
    memory barriers in a completely unrelated function is nasty; at least in the
    PageUptodate macros, they are located together with (half) the operations
    involved in the ordering. Thirdly, the smp_wmb is only required when first
    bringing the page uptodate, wheras flush_dcache_page should be called each time
    it is written to through the kernel mapping. It is logically the wrong place to
    put it.
    
    Q. Why does this increase my text size / reduce my performance / etc.
    A. Because it is adding the necessary instructions to eliminate the data-race.
    
    Q. Can it be improved?
    A. Yes, eg. if you were to create a rule that all SetPageUptodate operations
    run under the page lock, we could avoid the smp_rmb places where PageUptodate
    is queried under the page lock. Requires audit of all filesystems and at least
    some would need reworking. That's great you're interested, I'm eagerly awaiting
    your patches.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 3b97f6850273..065c4480eaf0 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -126,7 +126,7 @@ int swap_readpage(struct file *file, struct page *page)
 	int ret = 0;
 
 	BUG_ON(!PageLocked(page));
-	ClearPageUptodate(page);
+	BUG_ON(PageUptodate(page));
 	bio = get_swap_bio(GFP_KERNEL, page_private(page), page,
 				end_swap_bio_read);
 	if (bio == NULL) {

commit 6712ecf8f648118c3363c142196418f89a510b90
Author: NeilBrown <neilb@suse.de>
Date:   Thu Sep 27 12:47:43 2007 +0200

    Drop 'size' argument from bio_endio and bi_end_io
    
    As bi_end_io is only called once when the reqeust is complete,
    the 'size' argument is now redundant.  Remove it.
    
    Now there is no need for bio_endio to subtract the size completed
    from bi_size.  So don't do that either.
    
    While we are at it, change bi_end_io to return void.
    
    Signed-off-by: Neil Brown <neilb@suse.de>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/mm/page_io.c b/mm/page_io.c
index dbffec0d78c9..3b97f6850273 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -44,14 +44,11 @@ static struct bio *get_swap_bio(gfp_t gfp_flags, pgoff_t index,
 	return bio;
 }
 
-static int end_swap_bio_write(struct bio *bio, unsigned int bytes_done, int err)
+static void end_swap_bio_write(struct bio *bio, int err)
 {
 	const int uptodate = test_bit(BIO_UPTODATE, &bio->bi_flags);
 	struct page *page = bio->bi_io_vec[0].bv_page;
 
-	if (bio->bi_size)
-		return 1;
-
 	if (!uptodate) {
 		SetPageError(page);
 		/*
@@ -71,17 +68,13 @@ static int end_swap_bio_write(struct bio *bio, unsigned int bytes_done, int err)
 	}
 	end_page_writeback(page);
 	bio_put(bio);
-	return 0;
 }
 
-int end_swap_bio_read(struct bio *bio, unsigned int bytes_done, int err)
+void end_swap_bio_read(struct bio *bio, int err)
 {
 	const int uptodate = test_bit(BIO_UPTODATE, &bio->bi_flags);
 	struct page *page = bio->bi_io_vec[0].bv_page;
 
-	if (bio->bi_size)
-		return 1;
-
 	if (!uptodate) {
 		SetPageError(page);
 		ClearPageUptodate(page);
@@ -94,7 +87,6 @@ int end_swap_bio_read(struct bio *bio, unsigned int bytes_done, int err)
 	}
 	unlock_page(page);
 	bio_put(bio);
-	return 0;
 }
 
 /*

commit 3aef83e0ef1ffb8ea3bea97be46821a45c952173
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Wed Dec 6 20:34:10 2006 -0800

    [PATCH] swsusp: use block device offsets to identify swap locations
    
    Make swsusp use block device offsets instead of swap offsets to identify swap
    locations and make it use the same code paths for writing as well as for
    reading data.
    
    This allows us to use the same code for handling swap files and swap
    partitions and to simplify the code, eg.  by dropping rw_swap_page_sync().
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Cc: Pavel Machek <pavel@ucw.cz>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index d4840ecbf8f9..dbffec0d78c9 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -147,48 +147,3 @@ int swap_readpage(struct file *file, struct page *page)
 out:
 	return ret;
 }
-
-#ifdef CONFIG_SOFTWARE_SUSPEND
-/*
- * A scruffy utility function to read or write an arbitrary swap page
- * and wait on the I/O.  The caller must have a ref on the page.
- *
- * We use end_swap_bio_read() even for writes, because it happens to do what
- * we want.
- */
-int rw_swap_page_sync(int rw, swp_entry_t entry, struct page *page,
-			struct bio **bio_chain)
-{
-	struct bio *bio;
-	int ret = 0;
-	int bio_rw;
-
-	lock_page(page);
-
-	bio = get_swap_bio(GFP_KERNEL, entry.val, page, end_swap_bio_read);
-	if (bio == NULL) {
-		unlock_page(page);
-		ret = -ENOMEM;
-		goto out;
-	}
-
-	bio_rw = rw;
-	if (!bio_chain)
-		bio_rw |= (1 << BIO_RW_SYNC);
-	if (bio_chain)
-		bio_get(bio);
-	submit_bio(bio_rw, bio);
-	if (bio_chain == NULL) {
-		wait_on_page_locked(page);
-
-		if (!PageUptodate(page) || PageError(page))
-			ret = -EIO;
-	}
-	if (bio_chain) {
-		bio->bi_private = *bio_chain;
-		*bio_chain = bio;
-	}
-out:
-	return ret;
-}
-#endif

commit 546e0d271941dd1ff6961e2a1f7eac75f1fc277e
Author: Andrew Morton <akpm@osdl.org>
Date:   Mon Sep 25 23:32:44 2006 -0700

    [PATCH] swsusp: read speedup
    
    Implement async reads for swsusp resuming.
    
    Crufty old PIII testbox:
            15.7 MB/s -> 20.3 MB/s
    
    Sony Vaio:
            14.6 MB/s -> 33.3 MB/s
    
    I didn't implement the post-resume bio_set_pages_dirty().  I don't really
    understand why resume needs to run set_page_dirty() against these pages.
    
    It might be a worry that this code modifies PG_Uptodate, PG_Error and
    PG_Locked against the image pages.  Can this possibly affect the resumed-into
    kernel?  Hopefully not, if we're atomically restoring its mem_map?
    
    Cc: Pavel Machek <pavel@ucw.cz>
    Cc: "Rafael J. Wysocki" <rjw@sisk.pl>
    Cc: Jens Axboe <axboe@suse.de>
    Cc: Laurent Riffard <laurent.riffard@free.fr>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index f46a9862b7ef..d4840ecbf8f9 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -74,7 +74,7 @@ static int end_swap_bio_write(struct bio *bio, unsigned int bytes_done, int err)
 	return 0;
 }
 
-static int end_swap_bio_read(struct bio *bio, unsigned int bytes_done, int err)
+int end_swap_bio_read(struct bio *bio, unsigned int bytes_done, int err)
 {
 	const int uptodate = test_bit(BIO_UPTODATE, &bio->bi_flags);
 	struct page *page = bio->bi_io_vec[0].bv_page;

commit ab954160350c91c77ae03740ef90458c3ad5412c
Author: Andrew Morton <akpm@osdl.org>
Date:   Mon Sep 25 23:32:42 2006 -0700

    [PATCH] swsusp: write speedup
    
    Switch the swsusp writeout code from 4k-at-a-time to 4MB-at-a-time.
    
    Crufty old PIII testbox:
            12.9 MB/s -> 20.9 MB/s
    
    Sony Vaio:
            14.7 MB/s -> 26.5 MB/s
    
    The implementation is crude.  A better one would use larger BIOs, but wouldn't
    gain any performance.
    
    The memcpys will be mostly pipelined with the IO and basically come for free.
    
    The ENOMEM path has not been tested.  It should be.
    
    Cc: Pavel Machek <pavel@ucw.cz>
    Cc: "Rafael J. Wysocki" <rjw@sisk.pl>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index d2f0a5783370..f46a9862b7ef 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -156,10 +156,12 @@ int swap_readpage(struct file *file, struct page *page)
  * We use end_swap_bio_read() even for writes, because it happens to do what
  * we want.
  */
-int rw_swap_page_sync(int rw, swp_entry_t entry, struct page *page)
+int rw_swap_page_sync(int rw, swp_entry_t entry, struct page *page,
+			struct bio **bio_chain)
 {
 	struct bio *bio;
 	int ret = 0;
+	int bio_rw;
 
 	lock_page(page);
 
@@ -170,11 +172,22 @@ int rw_swap_page_sync(int rw, swp_entry_t entry, struct page *page)
 		goto out;
 	}
 
-	submit_bio(rw | (1 << BIO_RW_SYNC), bio);
-	wait_on_page_locked(page);
-
-	if (!PageUptodate(page) || PageError(page))
-		ret = -EIO;
+	bio_rw = rw;
+	if (!bio_chain)
+		bio_rw |= (1 << BIO_RW_SYNC);
+	if (bio_chain)
+		bio_get(bio);
+	submit_bio(bio_rw, bio);
+	if (bio_chain == NULL) {
+		wait_on_page_locked(page);
+
+		if (!PageUptodate(page) || PageError(page))
+			ret = -EIO;
+	}
+	if (bio_chain) {
+		bio->bi_private = *bio_chain;
+		*bio_chain = bio;
+	}
 out:
 	return ret;
 }

commit 6ddab3b9ebebc88bfdd8107c64f12d7e4480c559
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Mon Sep 25 23:31:26 2006 -0700

    [PATCH] mm: swap write failure fixup
    
    Currently we can silently drop data if the write to swap failed.  It
    usually doesn't result in data-corruption because on page-in the process
    will receive SIGBUS (assuming write-failure implies read-failure).
    
    This assumption might or might not be valid.
    
    This patch will avoid the page being discarded after a failed write.  But
    will print a warning the sysadmin _should_ take to heart, if a lot of swap
    space becomes un-writeable, OOM is not far off.
    
    Tested by making the write fail 'randomly' once every 50 writes or so.
    
    [akpm@osdl.org: printk warning fix]
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 88029948d00a..d2f0a5783370 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -52,8 +52,23 @@ static int end_swap_bio_write(struct bio *bio, unsigned int bytes_done, int err)
 	if (bio->bi_size)
 		return 1;
 
-	if (!uptodate)
+	if (!uptodate) {
 		SetPageError(page);
+		/*
+		 * We failed to write the page out to swap-space.
+		 * Re-dirty the page in order to avoid it being reclaimed.
+		 * Also print a dire warning that things will go BAD (tm)
+		 * very quickly.
+		 *
+		 * Also clear PG_reclaim to avoid rotate_reclaimable_page()
+		 */
+		set_page_dirty(page);
+		printk(KERN_ALERT "Write-error on swap-device (%u:%u:%Lu)\n",
+				imajor(bio->bi_bdev->bd_inode),
+				iminor(bio->bi_bdev->bd_inode),
+				(unsigned long long)bio->bi_sector);
+		ClearPageReclaim(page);
+	}
 	end_page_writeback(page);
 	bio_put(bio);
 	return 0;
@@ -70,6 +85,10 @@ static int end_swap_bio_read(struct bio *bio, unsigned int bytes_done, int err)
 	if (!uptodate) {
 		SetPageError(page);
 		ClearPageUptodate(page);
+		printk(KERN_ALERT "Read-error on swap-device (%u:%u:%Lu)\n",
+				imajor(bio->bi_bdev->bd_inode),
+				iminor(bio->bi_bdev->bd_inode),
+				(unsigned long long)bio->bi_sector);
 	} else {
 		SetPageUptodate(page);
 	}

commit f8891e5e1f93a128c3900f82035e8541357896a7
Author: Christoph Lameter <clameter@sgi.com>
Date:   Fri Jun 30 01:55:45 2006 -0700

    [PATCH] Light weight event counters
    
    The remaining counters in page_state after the zoned VM counter patches
    have been applied are all just for show in /proc/vmstat.  They have no
    essential function for the VM.
    
    We use a simple increment of per cpu variables.  In order to avoid the most
    severe races we disable preempt.  Preempt does not prevent the race between
    an increment and an interrupt handler incrementing the same statistics
    counter.  However, that race is exceedingly rare, we may only loose one
    increment or so and there is no requirement (at least not in kernel) that
    the vm event counters have to be accurate.
    
    In the non preempt case this results in a simple increment for each
    counter.  For many architectures this will be reduced by the compiler to a
    single instruction.  This single instruction is atomic for i386 and x86_64.
     And therefore even the rare race condition in an interrupt is avoided for
    both architectures in most cases.
    
    The patchset also adds an off switch for embedded systems that allows a
    building of linux kernels without these counters.
    
    The implementation of these counters is through inline code that hopefully
    results in only a single instruction increment instruction being emitted
    (i386, x86_64) or in the increment being hidden though instruction
    concurrency (EPIC architectures such as ia64 can get that done).
    
    Benefits:
    - VM event counter operations usually reduce to a single inline instruction
      on i386 and x86_64.
    - No interrupt disable, only preempt disable for the preempt case.
      Preempt disable can also be avoided by moving the counter into a spinlock.
    - Handling is similar to zoned VM counters.
    - Simple and easily extendable.
    - Can be omitted to reduce memory use for embedded use.
    
    References:
    
    RFC http://marc.theaimsgroup.com/?l=linux-kernel&m=113512330605497&w=2
    RFC http://marc.theaimsgroup.com/?l=linux-kernel&m=114988082814934&w=2
    local_t http://marc.theaimsgroup.com/?l=linux-kernel&m=114991748606690&w=2
    V2 http://marc.theaimsgroup.com/?t=115014808400007&r=1&w=2
    V3 http://marc.theaimsgroup.com/?l=linux-kernel&m=115024767022346&w=2
    V4 http://marc.theaimsgroup.com/?l=linux-kernel&m=115047968808926&w=2
    
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index bb2b0d53889c..88029948d00a 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -101,7 +101,7 @@ int swap_writepage(struct page *page, struct writeback_control *wbc)
 	}
 	if (wbc->sync_mode == WB_SYNC_ALL)
 		rw |= (1 << BIO_RW_SYNC);
-	inc_page_state(pswpout);
+	count_vm_event(PSWPOUT);
 	set_page_writeback(page);
 	unlock_page(page);
 	submit_bio(rw, bio);
@@ -123,7 +123,7 @@ int swap_readpage(struct file *file, struct page *page)
 		ret = -ENOMEM;
 		goto out;
 	}
-	inc_page_state(pswpin);
+	count_vm_event(PSWPIN);
 	submit_bio(READ, bio);
 out:
 	return ret;

commit 4c21e2f2441dc5fbb957b030333f5a3f2d02dea7
Author: Hugh Dickins <hugh@veritas.com>
Date:   Sat Oct 29 18:16:40 2005 -0700

    [PATCH] mm: split page table lock
    
    Christoph Lameter demonstrated very poor scalability on the SGI 512-way, with
    a many-threaded application which concurrently initializes different parts of
    a large anonymous area.
    
    This patch corrects that, by using a separate spinlock per page table page, to
    guard the page table entries in that page, instead of using the mm's single
    page_table_lock.  (But even then, page_table_lock is still used to guard page
    table allocation, and anon_vma allocation.)
    
    In this implementation, the spinlock is tucked inside the struct page of the
    page table page: with a BUILD_BUG_ON in case it overflows - which it would in
    the case of 32-bit PA-RISC with spinlock debugging enabled.
    
    Splitting the lock is not quite for free: another cacheline access.  Ideally,
    I suppose we would use split ptlock only for multi-threaded processes on
    multi-cpu machines; but deciding that dynamically would have its own costs.
    So for now enable it by config, at some number of cpus - since the Kconfig
    language doesn't support inequalities, let preprocessor compare that with
    NR_CPUS.  But I don't think it's worth being user-configurable: for good
    testing of both split and unsplit configs, split now at 4 cpus, and perhaps
    change that to 8 later.
    
    There is a benefit even for singly threaded processes: kswapd can be attacking
    one part of the mm while another part is busy faulting.
    
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 330e00d6db00..bb2b0d53889c 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -91,7 +91,8 @@ int swap_writepage(struct page *page, struct writeback_control *wbc)
 		unlock_page(page);
 		goto out;
 	}
-	bio = get_swap_bio(GFP_NOIO, page->private, page, end_swap_bio_write);
+	bio = get_swap_bio(GFP_NOIO, page_private(page), page,
+				end_swap_bio_write);
 	if (bio == NULL) {
 		set_page_dirty(page);
 		unlock_page(page);
@@ -115,7 +116,8 @@ int swap_readpage(struct file *file, struct page *page)
 
 	BUG_ON(!PageLocked(page));
 	ClearPageUptodate(page);
-	bio = get_swap_bio(GFP_KERNEL, page->private, page, end_swap_bio_read);
+	bio = get_swap_bio(GFP_KERNEL, page_private(page), page,
+				end_swap_bio_read);
 	if (bio == NULL) {
 		unlock_page(page);
 		ret = -ENOMEM;

commit dd0fc66fb33cd610bc1a5db8a5e232d34879b4d7
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Fri Oct 7 07:46:04 2005 +0100

    [PATCH] gfp flags annotations - part 1
    
     - added typedef unsigned int __nocast gfp_t;
    
     - replaced __nocast uses for gfp flags with gfp_t - it gives exactly
       the same warnings as far as sparse is concerned, doesn't change
       generated code (from gcc point of view we replaced unsigned int with
       typedef) and documents what's going on far better.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 2e605a19ce57..330e00d6db00 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -19,7 +19,7 @@
 #include <linux/writeback.h>
 #include <asm/pgtable.h>
 
-static struct bio *get_swap_bio(unsigned int __nocast gfp_flags, pgoff_t index,
+static struct bio *get_swap_bio(gfp_t gfp_flags, pgoff_t index,
 				struct page *page, bio_end_io_t end_io)
 {
 	struct bio *bio;

commit 648be3188135add682349e86d46d07cc11c8eb57
Author: Pavel Machek <pavel@ucw.cz>
Date:   Sat Jun 25 14:55:09 2005 -0700

    [PATCH] swsusp: kill config_pm_disk
    
    CONFIG_PM_DISK is long gone, but it still managed to survived at few
    places.
    
    Signed-off-by: Pavel Machek <pavel@suse.cz>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/mm/page_io.c b/mm/page_io.c
index 667c76df1ec2..2e605a19ce57 100644
--- a/mm/page_io.c
+++ b/mm/page_io.c
@@ -127,7 +127,7 @@ int swap_readpage(struct file *file, struct page *page)
 	return ret;
 }
 
-#if defined(CONFIG_SOFTWARE_SUSPEND) || defined(CONFIG_PM_DISK)
+#ifdef CONFIG_SOFTWARE_SUSPEND
 /*
  * A scruffy utility function to read or write an arbitrary swap page
  * and wait on the I/O.  The caller must have a ref on the page.

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/mm/page_io.c b/mm/page_io.c
new file mode 100644
index 000000000000..667c76df1ec2
--- /dev/null
+++ b/mm/page_io.c
@@ -0,0 +1,160 @@
+/*
+ *  linux/mm/page_io.c
+ *
+ *  Copyright (C) 1991, 1992, 1993, 1994  Linus Torvalds
+ *
+ *  Swap reorganised 29.12.95, 
+ *  Asynchronous swapping added 30.12.95. Stephen Tweedie
+ *  Removed race in async swapping. 14.4.1996. Bruno Haible
+ *  Add swap of shared pages through the page cache. 20.2.1998. Stephen Tweedie
+ *  Always use brw_page, life becomes simpler. 12 May 1998 Eric Biederman
+ */
+
+#include <linux/mm.h>
+#include <linux/kernel_stat.h>
+#include <linux/pagemap.h>
+#include <linux/swap.h>
+#include <linux/bio.h>
+#include <linux/swapops.h>
+#include <linux/writeback.h>
+#include <asm/pgtable.h>
+
+static struct bio *get_swap_bio(unsigned int __nocast gfp_flags, pgoff_t index,
+				struct page *page, bio_end_io_t end_io)
+{
+	struct bio *bio;
+
+	bio = bio_alloc(gfp_flags, 1);
+	if (bio) {
+		struct swap_info_struct *sis;
+		swp_entry_t entry = { .val = index, };
+
+		sis = get_swap_info_struct(swp_type(entry));
+		bio->bi_sector = map_swap_page(sis, swp_offset(entry)) *
+					(PAGE_SIZE >> 9);
+		bio->bi_bdev = sis->bdev;
+		bio->bi_io_vec[0].bv_page = page;
+		bio->bi_io_vec[0].bv_len = PAGE_SIZE;
+		bio->bi_io_vec[0].bv_offset = 0;
+		bio->bi_vcnt = 1;
+		bio->bi_idx = 0;
+		bio->bi_size = PAGE_SIZE;
+		bio->bi_end_io = end_io;
+	}
+	return bio;
+}
+
+static int end_swap_bio_write(struct bio *bio, unsigned int bytes_done, int err)
+{
+	const int uptodate = test_bit(BIO_UPTODATE, &bio->bi_flags);
+	struct page *page = bio->bi_io_vec[0].bv_page;
+
+	if (bio->bi_size)
+		return 1;
+
+	if (!uptodate)
+		SetPageError(page);
+	end_page_writeback(page);
+	bio_put(bio);
+	return 0;
+}
+
+static int end_swap_bio_read(struct bio *bio, unsigned int bytes_done, int err)
+{
+	const int uptodate = test_bit(BIO_UPTODATE, &bio->bi_flags);
+	struct page *page = bio->bi_io_vec[0].bv_page;
+
+	if (bio->bi_size)
+		return 1;
+
+	if (!uptodate) {
+		SetPageError(page);
+		ClearPageUptodate(page);
+	} else {
+		SetPageUptodate(page);
+	}
+	unlock_page(page);
+	bio_put(bio);
+	return 0;
+}
+
+/*
+ * We may have stale swap cache pages in memory: notice
+ * them here and get rid of the unnecessary final write.
+ */
+int swap_writepage(struct page *page, struct writeback_control *wbc)
+{
+	struct bio *bio;
+	int ret = 0, rw = WRITE;
+
+	if (remove_exclusive_swap_page(page)) {
+		unlock_page(page);
+		goto out;
+	}
+	bio = get_swap_bio(GFP_NOIO, page->private, page, end_swap_bio_write);
+	if (bio == NULL) {
+		set_page_dirty(page);
+		unlock_page(page);
+		ret = -ENOMEM;
+		goto out;
+	}
+	if (wbc->sync_mode == WB_SYNC_ALL)
+		rw |= (1 << BIO_RW_SYNC);
+	inc_page_state(pswpout);
+	set_page_writeback(page);
+	unlock_page(page);
+	submit_bio(rw, bio);
+out:
+	return ret;
+}
+
+int swap_readpage(struct file *file, struct page *page)
+{
+	struct bio *bio;
+	int ret = 0;
+
+	BUG_ON(!PageLocked(page));
+	ClearPageUptodate(page);
+	bio = get_swap_bio(GFP_KERNEL, page->private, page, end_swap_bio_read);
+	if (bio == NULL) {
+		unlock_page(page);
+		ret = -ENOMEM;
+		goto out;
+	}
+	inc_page_state(pswpin);
+	submit_bio(READ, bio);
+out:
+	return ret;
+}
+
+#if defined(CONFIG_SOFTWARE_SUSPEND) || defined(CONFIG_PM_DISK)
+/*
+ * A scruffy utility function to read or write an arbitrary swap page
+ * and wait on the I/O.  The caller must have a ref on the page.
+ *
+ * We use end_swap_bio_read() even for writes, because it happens to do what
+ * we want.
+ */
+int rw_swap_page_sync(int rw, swp_entry_t entry, struct page *page)
+{
+	struct bio *bio;
+	int ret = 0;
+
+	lock_page(page);
+
+	bio = get_swap_bio(GFP_KERNEL, entry.val, page, end_swap_bio_read);
+	if (bio == NULL) {
+		unlock_page(page);
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	submit_bio(rw | (1 << BIO_RW_SYNC), bio);
+	wait_on_page_locked(page);
+
+	if (!PageUptodate(page) || PageError(page))
+		ret = -EIO;
+out:
+	return ret;
+}
+#endif
