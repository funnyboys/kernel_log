commit d8ed45c5dcd455fc5848d47f86883a1b872ac0d0
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Jun 8 21:33:25 2020 -0700

    mmap locking API: use coccinelle to convert mmap_sem rwsem call sites
    
    This change converts the existing mmap_sem rwsem calls to use the new mmap
    locking API instead.
    
    The change is generated using coccinelle with the following rule:
    
    // spatch --sp-file mmap_lock_api.cocci --in-place --include-headers --dir .
    
    @@
    expression mm;
    @@
    (
    -init_rwsem
    +mmap_init_lock
    |
    -down_write
    +mmap_write_lock
    |
    -down_write_killable
    +mmap_write_lock_killable
    |
    -down_write_trylock
    +mmap_write_trylock
    |
    -up_write
    +mmap_write_unlock
    |
    -downgrade_write
    +mmap_write_downgrade
    |
    -down_read
    +mmap_read_lock
    |
    -down_read_killable
    +mmap_read_lock_killable
    |
    -down_read_trylock
    +mmap_read_trylock
    |
    -up_read
    +mmap_read_unlock
    )
    -(&mm->mmap_sem)
    +(mm)
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Daniel Jordan <daniel.m.jordan@oracle.com>
    Reviewed-by: Laurent Dufour <ldufour@linux.ibm.com>
    Reviewed-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Davidlohr Bueso <dbueso@suse.de>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jason Gunthorpe <jgg@ziepe.ca>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: John Hubbard <jhubbard@nvidia.com>
    Cc: Liam Howlett <Liam.Howlett@oracle.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ying Han <yinghan@google.com>
    Link: http://lkml.kernel.org/r/20200520052908.204642-5-walken@google.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 0ba6add05b35..0a6dd94afa21 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1544,7 +1544,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg,
 	if (err)
 		goto out_fput;
 
-	if (down_write_killable(&current->mm->mmap_sem)) {
+	if (mmap_write_lock_killable(current->mm)) {
 		err = -EINTR;
 		goto out_fput;
 	}
@@ -1564,7 +1564,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg,
 	if (IS_ERR_VALUE(addr))
 		err = (long)addr;
 invalid:
-	up_write(&current->mm->mmap_sem);
+	mmap_write_unlock(current->mm);
 	if (populate)
 		mm_populate(addr, populate);
 
@@ -1638,7 +1638,7 @@ long ksys_shmdt(char __user *shmaddr)
 	if (addr & ~PAGE_MASK)
 		return retval;
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (mmap_write_lock_killable(mm))
 		return -EINTR;
 
 	/*
@@ -1726,7 +1726,7 @@ long ksys_shmdt(char __user *shmaddr)
 
 #endif
 
-	up_write(&mm->mmap_sem);
+	mmap_write_unlock(mm);
 	return retval;
 }
 

commit 1cd377baa91844b9f87a2b72eabf7ff783946b5e
Author: Jason Yan <yanaijie@huawei.com>
Date:   Mon Apr 6 20:12:56 2020 -0700

    ipc/shm.c: make compat_ksys_shmctl() static
    
    Fix the following sparse warning:
    
    ipc/shm.c:1335:6: warning: symbol 'compat_ksys_shmctl' was not declared.
    Should it be static?
    
    Reported-by: Hulk Robot <hulkci@huawei.com>
    Signed-off-by: Jason Yan <yanaijie@huawei.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Link: http://lkml.kernel.org/r/20200403063933.24785-1-yanaijie@huawei.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index ce1ca9f7c6e9..0ba6add05b35 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1332,7 +1332,7 @@ static int copy_compat_shmid_from_user(struct shmid64_ds *out, void __user *buf,
 	}
 }
 
-long compat_ksys_shmctl(int shmid, int cmd, void __user *uptr, int version)
+static long compat_ksys_shmctl(int shmid, int cmd, void __user *uptr, int version)
 {
 	struct ipc_namespace *ns;
 	struct shmid64_ds sem64;

commit 275f22148e8720e84b180d9e0cdf8abfd69bac5b
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon Dec 31 22:22:40 2018 +0100

    ipc: rename old-style shmctl/semctl/msgctl syscalls
    
    The behavior of these system calls is slightly different between
    architectures, as determined by the CONFIG_ARCH_WANT_IPC_PARSE_VERSION
    symbol. Most architectures that implement the split IPC syscalls don't set
    that symbol and only get the modern version, but alpha, arm, microblaze,
    mips-n32, mips-n64 and xtensa expect the caller to pass the IPC_64 flag.
    
    For the architectures that so far only implement sys_ipc(), i.e. m68k,
    mips-o32, powerpc, s390, sh, sparc, and x86-32, we want the new behavior
    when adding the split syscalls, so we need to distinguish between the
    two groups of architectures.
    
    The method I picked for this distinction is to have a separate system call
    entry point: sys_old_*ctl() now uses ipc_parse_version, while sys_*ctl()
    does not. The system call tables of the five architectures are changed
    accordingly.
    
    As an additional benefit, we no longer need the configuration specific
    definition for ipc_parse_version(), it always does the same thing now,
    but simply won't get called on architectures with the modern interface.
    
    A small downside is that on architectures that do set
    ARCH_WANT_IPC_PARSE_VERSION, we now have an extra set of entry points
    that are never called. They only add a few bytes of bloat, so it seems
    better to keep them compared to adding yet another Kconfig symbol.
    I considered adding new syscall numbers for the IPC_64 variants for
    consistency, but decided against that for now.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/ipc/shm.c b/ipc/shm.c
index 0842411cb0e9..ce1ca9f7c6e9 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1137,16 +1137,15 @@ static int shmctl_do_lock(struct ipc_namespace *ns, int shmid, int cmd)
 	return err;
 }
 
-long ksys_shmctl(int shmid, int cmd, struct shmid_ds __user *buf)
+static long ksys_shmctl(int shmid, int cmd, struct shmid_ds __user *buf, int version)
 {
-	int err, version;
+	int err;
 	struct ipc_namespace *ns;
 	struct shmid64_ds sem64;
 
 	if (cmd < 0 || shmid < 0)
 		return -EINVAL;
 
-	version = ipc_parse_version(&cmd);
 	ns = current->nsproxy->ipc_ns;
 
 	switch (cmd) {
@@ -1194,8 +1193,22 @@ long ksys_shmctl(int shmid, int cmd, struct shmid_ds __user *buf)
 
 SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 {
-	return ksys_shmctl(shmid, cmd, buf);
+	return ksys_shmctl(shmid, cmd, buf, IPC_64);
+}
+
+#ifdef CONFIG_ARCH_WANT_IPC_PARSE_VERSION
+long ksys_old_shmctl(int shmid, int cmd, struct shmid_ds __user *buf)
+{
+	int version = ipc_parse_version(&cmd);
+
+	return ksys_shmctl(shmid, cmd, buf, version);
+}
+
+SYSCALL_DEFINE3(old_shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
+{
+	return ksys_old_shmctl(shmid, cmd, buf);
 }
+#endif
 
 #ifdef CONFIG_COMPAT
 
@@ -1319,11 +1332,10 @@ static int copy_compat_shmid_from_user(struct shmid64_ds *out, void __user *buf,
 	}
 }
 
-long compat_ksys_shmctl(int shmid, int cmd, void __user *uptr)
+long compat_ksys_shmctl(int shmid, int cmd, void __user *uptr, int version)
 {
 	struct ipc_namespace *ns;
 	struct shmid64_ds sem64;
-	int version = compat_ipc_parse_version(&cmd);
 	int err;
 
 	ns = current->nsproxy->ipc_ns;
@@ -1378,8 +1390,22 @@ long compat_ksys_shmctl(int shmid, int cmd, void __user *uptr)
 
 COMPAT_SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, void __user *, uptr)
 {
-	return compat_ksys_shmctl(shmid, cmd, uptr);
+	return compat_ksys_shmctl(shmid, cmd, uptr, IPC_64);
 }
+
+#ifdef CONFIG_ARCH_WANT_COMPAT_IPC_PARSE_VERSION
+long compat_ksys_old_shmctl(int shmid, int cmd, void __user *uptr)
+{
+	int version = compat_ipc_parse_version(&cmd);
+
+	return compat_ksys_shmctl(shmid, cmd, uptr, version);
+}
+
+COMPAT_SYSCALL_DEFINE3(old_shmctl, int, shmid, int, cmd, void __user *, uptr)
+{
+	return compat_ksys_old_shmctl(shmid, cmd, uptr);
+}
+#endif
 #endif
 
 /*

commit 4dcb9239dad6cee17c538482619a5b659774ee51
Merge: 3acbd2de6bc3 d59e0ba19481
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 25 11:14:36 2018 -0700

    Merge branch 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull timekeeping updates from Thomas Gleixner:
     "The timers and timekeeping departement provides:
    
       - Another large y2038 update with further preparations for providing
         the y2038 safe timespecs closer to the syscalls.
    
       - An overhaul of the SHCMT clocksource driver
    
       - SPDX license identifier updates
    
       - Small cleanups and fixes all over the place"
    
    * 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (31 commits)
      tick/sched : Remove redundant cpu_online() check
      clocksource/drivers/dw_apb: Add reset control
      clocksource: Remove obsolete CLOCKSOURCE_OF_DECLARE
      clocksource/drivers: Unify the names to timer-* format
      clocksource/drivers/sh_cmt: Add R-Car gen3 support
      dt-bindings: timer: renesas: cmt: document R-Car gen3 support
      clocksource/drivers/sh_cmt: Properly line-wrap sh_cmt_of_table[] initializer
      clocksource/drivers/sh_cmt: Fix clocksource width for 32-bit machines
      clocksource/drivers/sh_cmt: Fixup for 64-bit machines
      clocksource/drivers/sh_tmu: Convert to SPDX identifiers
      clocksource/drivers/sh_mtu2: Convert to SPDX identifiers
      clocksource/drivers/sh_cmt: Convert to SPDX identifiers
      clocksource/drivers/renesas-ostm: Convert to SPDX identifiers
      clocksource: Convert to using %pOFn instead of device_node.name
      tick/broadcast: Remove redundant check
      RISC-V: Request newstat syscalls
      y2038: signal: Change rt_sigtimedwait to use __kernel_timespec
      y2038: socket: Change recvmmsg to use __kernel_timespec
      y2038: sched: Change sched_rr_get_interval to use __kernel_timespec
      y2038: utimes: Rework #ifdef guards for compat syscalls
      ...

commit 59cf0a9339ca4b0226e9b4329dfb0a5b8b0b9bc2
Author: Kees Cook <keescook@chromium.org>
Date:   Fri Oct 5 15:51:48 2018 -0700

    ipc/shm.c: use ERR_CAST() for shm_lock() error return
    
    This uses ERR_CAST() instead of an open-coded cast, as it is casting
    across structure pointers, which upsets __randomize_layout:
    
    ipc/shm.c: In function `shm_lock':
    ipc/shm.c:209:9: note: randstruct: casting between randomized structure pointer types (ssa): `struct shmid_kernel' and `struct kern_ipc_perm'
    
      return (void *)ipcp;
             ^~~~~~~~~~~~
    
    Link: http://lkml.kernel.org/r/20180919180722.GA15073@beast
    Fixes: 82061c57ce93 ("ipc: drop ipc_lock()")
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Cc: Davidlohr Bueso <dbueso@suse.de>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 4cd402e4cfeb..1c65fb357395 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -206,7 +206,7 @@ static inline struct shmid_kernel *shm_lock(struct ipc_namespace *ns, int id)
 	 * Callers of shm_lock() must validate the status of the returned ipc
 	 * object pointer and error out as appropriate.
 	 */
-	return (void *)ipcp;
+	return ERR_CAST(ipcp);
 }
 
 static inline void shm_lock_by_ptr(struct shmid_kernel *ipcp)

commit 9c21dae291d1b7763b749dfaef3fb911286c0d98
Author: Davidlohr Bueso <dbueso@suse.de>
Date:   Tue Sep 4 15:46:02 2018 -0700

    ipc/shm: properly return EIDRM in shm_lock()
    
    When getting rid of the general ipc_lock(), this was missed furthermore,
    making the comment around the ipc object validity check bogus.  Under
    EIDRM conditions, callers will in turn not see the error and continue
    with the operation.
    
    Link: http://lkml.kernel.org/r/20180824030920.GD3677@linux-r8p5
    Link: http://lkml.kernel.org/r/20180823024051.GC13343@shao2-debian
    Fixes: 82061c57ce9 ("ipc: drop ipc_lock()")
    Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
    Reported-by: kernel test robot <rong.a.chen@intel.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index b0eb3757ab89..4cd402e4cfeb 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -199,6 +199,7 @@ static inline struct shmid_kernel *shm_lock(struct ipc_namespace *ns, int id)
 	}
 
 	ipc_unlock_object(ipcp);
+	ipcp = ERR_PTR(-EIDRM);
 err:
 	rcu_read_unlock();
 	/*

commit 9afc5eee65ca7d717a99d6fe8f4adfe32a40940a
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Fri Jul 13 12:52:28 2018 +0200

    y2038: globally rename compat_time to old_time32
    
    Christoph Hellwig suggested a slightly different path for handling
    backwards compatibility with the 32-bit time_t based system calls:
    
    Rather than simply reusing the compat_sys_* entry points on 32-bit
    architectures unchanged, we get rid of those entry points and the
    compat_time types by renaming them to something that makes more sense
    on 32-bit architectures (which don't have a compat mode otherwise),
    and then share the entry points under the new name with the 64-bit
    architectures that use them for implementing the compatibility.
    
    The following types and interfaces are renamed here, and moved
    from linux/compat_time.h to linux/time32.h:
    
    old                             new
    ---                             ---
    compat_time_t                   old_time32_t
    struct compat_timeval           struct old_timeval32
    struct compat_timespec          struct old_timespec32
    struct compat_itimerspec        struct old_itimerspec32
    ns_to_compat_timeval()          ns_to_old_timeval32()
    get_compat_itimerspec64()       get_old_itimerspec32()
    put_compat_itimerspec64()       put_old_itimerspec32()
    compat_get_timespec64()         get_old_timespec32()
    compat_put_timespec64()         put_old_timespec32()
    
    As we already have aliases in place, this patch addresses only the
    instances that are relevant to the system call interface in particular,
    not those that occur in device drivers and other modules. Those
    will get handled separately, while providing the 64-bit version
    of the respective interfaces.
    
    I'm not renaming the timex, rusage and itimerval structures, as we are
    still debating what the new interface will look like, and whether we
    will need a replacement at all.
    
    This also doesn't change the names of the syscall entry points, which can
    be done more easily when we actually switch over the 32-bit architectures
    to use them, at that point we need to change COMPAT_SYSCALL_DEFINEx to
    SYSCALL_DEFINEx with a new name, e.g. with a _time32 suffix.
    
    Suggested-by: Christoph Hellwig <hch@infradead.org>
    Link: https://lore.kernel.org/lkml/20180705222110.GA5698@infradead.org/
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/ipc/shm.c b/ipc/shm.c
index b0eb3757ab89..2657692199eb 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1201,9 +1201,9 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 struct compat_shmid_ds {
 	struct compat_ipc_perm shm_perm;
 	int shm_segsz;
-	compat_time_t shm_atime;
-	compat_time_t shm_dtime;
-	compat_time_t shm_ctime;
+	old_time32_t shm_atime;
+	old_time32_t shm_dtime;
+	old_time32_t shm_ctime;
 	compat_ipc_pid_t shm_cpid;
 	compat_ipc_pid_t shm_lpid;
 	unsigned short shm_nattch;

commit 27c331a174614208d0b539019583990967ad9479
Author: Manfred Spraul <manfred@colorfullife.com>
Date:   Tue Aug 21 22:02:00 2018 -0700

    ipc/util.c: further variable name cleanups
    
    The varable names got a mess, thus standardize them again:
    
    id: user space id. Called semid, shmid, msgid if the type is known.
        Most functions use "id" already.
    idx: "index" for the idr lookup
        Right now, some functions use lid, ipc_addid() already uses idx as
        the variable name.
    seq: sequence number, to avoid quick collisions of the user space id
    key: user space key, used for the rhash tree
    
    Link: http://lkml.kernel.org/r/20180712185241.4017-12-manfred@colorfullife.com
    Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: Davidlohr Bueso <dbueso@suse.de>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index c4fb359f1e53..b0eb3757ab89 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -948,7 +948,7 @@ static int shmctl_ipc_info(struct ipc_namespace *ns,
 		shminfo->shmall = ns->shm_ctlall;
 		shminfo->shmmin = SHMMIN;
 		down_read(&shm_ids(ns).rwsem);
-		err = ipc_get_maxid(&shm_ids(ns));
+		err = ipc_get_maxidx(&shm_ids(ns));
 		up_read(&shm_ids(ns).rwsem);
 		if (err < 0)
 			err = 0;
@@ -968,7 +968,7 @@ static int shmctl_shm_info(struct ipc_namespace *ns,
 		shm_info->shm_tot = ns->shm_tot;
 		shm_info->swap_attempts = 0;
 		shm_info->swap_successes = 0;
-		err = ipc_get_maxid(&shm_ids(ns));
+		err = ipc_get_maxidx(&shm_ids(ns));
 		up_read(&shm_ids(ns).rwsem);
 		if (err < 0)
 			err = 0;

commit eae04d25a713304c978d7c45dcab01b0e0811c74
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Tue Aug 21 22:01:56 2018 -0700

    ipc: simplify ipc initialization
    
    Now that we know that rhashtable_init() will not fail, we can get rid of a
    lot of the unnecessary cleanup paths when the call errored out.
    
    [manfred@colorfullife.com: variable name added to util.h to resolve checkpatch warning]
    Link: http://lkml.kernel.org/r/20180712185241.4017-11-manfred@colorfullife.com
    Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
    Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 4c7ae625d996..c4fb359f1e53 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -96,14 +96,14 @@ static void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp);
 static int sysvipc_shm_proc_show(struct seq_file *s, void *it);
 #endif
 
-int shm_init_ns(struct ipc_namespace *ns)
+void shm_init_ns(struct ipc_namespace *ns)
 {
 	ns->shm_ctlmax = SHMMAX;
 	ns->shm_ctlall = SHMALL;
 	ns->shm_ctlmni = SHMMNI;
 	ns->shm_rmid_forced = 0;
 	ns->shm_tot = 0;
-	return ipc_init_ids(&shm_ids(ns));
+	ipc_init_ids(&shm_ids(ns));
 }
 
 /*
@@ -136,9 +136,8 @@ void shm_exit_ns(struct ipc_namespace *ns)
 
 static int __init ipc_ns_init(void)
 {
-	const int err = shm_init_ns(&init_ipc_ns);
-	WARN(err, "ipc: sysv shm_init_ns failed: %d\n", err);
-	return err;
+	shm_init_ns(&init_ipc_ns);
+	return 0;
 }
 
 pure_initcall(ipc_ns_init);

commit 82061c57ce93caa50fd01c11f8eb30ddc4c4bd75
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Tue Aug 21 22:01:41 2018 -0700

    ipc: drop ipc_lock()
    
    ipc/util.c contains multiple functions to get the ipc object pointer given
    an id number.
    
    There are two sets of function: One set verifies the sequence counter part
    of the id number, other functions do not check the sequence counter.
    
    The standard for function names in ipc/util.c is
    - ..._check() functions verify the sequence counter
    - ..._idr() functions do not verify the sequence counter
    
    ipc_lock() is an exception: It does not verify the sequence counter value,
    but this is not obvious from the function name.
    
    Furthermore, shm.c is the only user of this helper.  Thus, we can simply
    move the logic into shm_lock() and get rid of the function altogether.
    
    [manfred@colorfullife.com: most of changelog]
    Link: http://lkml.kernel.org/r/20180712185241.4017-7-manfred@colorfullife.com
    Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
    Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index a413ddf74dac..4c7ae625d996 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -180,16 +180,33 @@ static inline struct shmid_kernel *shm_obtain_object_check(struct ipc_namespace
  */
 static inline struct shmid_kernel *shm_lock(struct ipc_namespace *ns, int id)
 {
-	struct kern_ipc_perm *ipcp = ipc_lock(&shm_ids(ns), id);
+	struct kern_ipc_perm *ipcp;
+
+	rcu_read_lock();
+	ipcp = ipc_obtain_object_idr(&shm_ids(ns), id);
+	if (IS_ERR(ipcp))
+		goto err;
 
+	ipc_lock_object(ipcp);
+	/*
+	 * ipc_rmid() may have already freed the ID while ipc_lock_object()
+	 * was spinning: here verify that the structure is still valid.
+	 * Upon races with RMID, return -EIDRM, thus indicating that
+	 * the ID points to a removed identifier.
+	 */
+	if (ipc_valid_object(ipcp)) {
+		/* return a locked ipc object upon success */
+		return container_of(ipcp, struct shmid_kernel, shm_perm);
+	}
+
+	ipc_unlock_object(ipcp);
+err:
+	rcu_read_unlock();
 	/*
 	 * Callers of shm_lock() must validate the status of the returned ipc
-	 * object pointer (as returned by ipc_lock()), and error out as
-	 * appropriate.
+	 * object pointer and error out as appropriate.
 	 */
-	if (IS_ERR(ipcp))
-		return (void *)ipcp;
-	return container_of(ipcp, struct shmid_kernel, shm_perm);
+	return (void *)ipcp;
 }
 
 static inline void shm_lock_by_ptr(struct shmid_kernel *ipcp)

commit 4241c1a304078569f544d51eeaf8bc270b6e377a
Author: Manfred Spraul <manfred@colorfullife.com>
Date:   Tue Aug 21 22:01:34 2018 -0700

    ipc: rename ipcctl_pre_down_nolock()
    
    Both the comment and the name of ipcctl_pre_down_nolock() are misleading:
    The function must be called while holdling the rw semaphore.
    
    Therefore the patch renames the function to ipcctl_obtain_check(): This
    name matches the other names used in util.c:
    
    - "obtain" function look up a pointer in the idr, without
      acquiring the object lock.
    - The caller is responsible for locking.
    - _check means that the sequence number is checked.
    
    Link: http://lkml.kernel.org/r/20180712185241.4017-5-manfred@colorfullife.com
    Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
    Reviewed-by: Davidlohr Bueso <dbueso@suse.de>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 6e7bd9830549..a413ddf74dac 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -881,7 +881,7 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 	down_write(&shm_ids(ns).rwsem);
 	rcu_read_lock();
 
-	ipcp = ipcctl_pre_down_nolock(ns, &shm_ids(ns), shmid, cmd,
+	ipcp = ipcctl_obtain_check(ns, &shm_ids(ns), shmid, cmd,
 				      &shmid64->shm_perm, 0);
 	if (IS_ERR(ipcp)) {
 		err = PTR_ERR(ipcp);

commit 39cfffd774a2e8818250360a3e028b5eac9d5392
Author: Manfred Spraul <manfred@colorfullife.com>
Date:   Tue Aug 21 22:01:29 2018 -0700

    ipc/util.c: use ipc_rcu_putref() for failues in ipc_addid()
    
    ipc_addid() is impossible to use:
    - for certain failures, the caller must not use ipc_rcu_putref(),
      because the reference counter is not yet initialized.
    - for other failures, the caller must use ipc_rcu_putref(),
      because parallel operations could be ongoing already.
    
    The patch cleans that up, by initializing the refcount early, and by
    modifying all callers.
    
    The issues is related to the finding of
    syzbot+2827ef6b3385deb07eaf@syzkaller.appspotmail.com: syzbot found an
    issue with reading kern_ipc_perm.seq, here both read and write to already
    released memory could happen.
    
    Link: http://lkml.kernel.org/r/20180712185241.4017-4-manfred@colorfullife.com
    Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: Davidlohr Bueso <dbueso@suse.de>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index b3b089315d3b..6e7bd9830549 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -684,6 +684,8 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	if (is_file_hugepages(file) && shp->mlock_user)
 		user_shm_unlock(size, shp->mlock_user);
 	fput(file);
+	ipc_rcu_putref(&shp->shm_perm, shm_rcu_free);
+	return error;
 no_file:
 	call_rcu(&shp->shm_perm.rcu, shm_rcu_free);
 	return error;

commit 615c999cd8a07b7c3c93bbdee89ef705d2ce52e1
Author: Manfred Spraul <manfred@colorfullife.com>
Date:   Tue Aug 21 22:01:21 2018 -0700

    ipc: compute kern_ipc_perm.id under the ipc lock
    
    ipc_addid() initializes kern_ipc_perm.id after having called
    ipc_idr_alloc().
    
    Thus a parallel semctl() or msgctl() that uses e.g.  MSG_STAT may use this
    unitialized value as the return code.
    
    The patch moves all accesses to kern_ipc_perm.id under the spin_lock().
    
    The issues is related to the finding of
    syzbot+2827ef6b3385deb07eaf@syzkaller.appspotmail.com: syzbot found an
    issue with kern_ipc_perm.seq
    
    Link: http://lkml.kernel.org/r/20180712185241.4017-2-manfred@colorfullife.com
    Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
    Reviewed-by: Davidlohr Bueso <dbueso@suse.de>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index b204feb38274..b3b089315d3b 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -962,7 +962,6 @@ static int shmctl_stat(struct ipc_namespace *ns, int shmid,
 			int cmd, struct shmid64_ds *tbuf)
 {
 	struct shmid_kernel *shp;
-	int id = 0;
 	int err;
 
 	memset(tbuf, 0, sizeof(*tbuf));
@@ -974,7 +973,6 @@ static int shmctl_stat(struct ipc_namespace *ns, int shmid,
 			err = PTR_ERR(shp);
 			goto out_unlock;
 		}
-		id = shp->shm_perm.id;
 	} else { /* IPC_STAT */
 		shp = shm_obtain_object_check(ns, shmid);
 		if (IS_ERR(shp)) {
@@ -1024,10 +1022,21 @@ static int shmctl_stat(struct ipc_namespace *ns, int shmid,
 	tbuf->shm_lpid	= pid_vnr(shp->shm_lprid);
 	tbuf->shm_nattch = shp->shm_nattch;
 
-	ipc_unlock_object(&shp->shm_perm);
-	rcu_read_unlock();
-	return id;
+	if (cmd == IPC_STAT) {
+		/*
+		 * As defined in SUS:
+		 * Return 0 on success
+		 */
+		err = 0;
+	} else {
+		/*
+		 * SHM_STAT and SHM_STAT_ANY (both Linux specific)
+		 * Return the full id, including the sequence number
+		 */
+		err = shp->shm_perm.id;
+	}
 
+	ipc_unlock_object(&shp->shm_perm);
 out_unlock:
 	rcu_read_unlock();
 	return err;

commit 9a76aba02a37718242d7cdc294f0a3901928aa57
Merge: 0a957467c5fd 26a1ccc6c117
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Aug 15 15:04:25 2018 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking updates from David Miller:
     "Highlights:
    
       - Gustavo A. R. Silva keeps working on the implicit switch fallthru
         changes.
    
       - Support 802.11ax High-Efficiency wireless in cfg80211 et al, From
         Luca Coelho.
    
       - Re-enable ASPM in r8169, from Kai-Heng Feng.
    
       - Add virtual XFRM interfaces, which avoids all of the limitations of
         existing IPSEC tunnels. From Steffen Klassert.
    
       - Convert GRO over to use a hash table, so that when we have many
         flows active we don't traverse a long list during accumluation.
    
       - Many new self tests for routing, TC, tunnels, etc. Too many
         contributors to mention them all, but I'm really happy to keep
         seeing this stuff.
    
       - Hardware timestamping support for dpaa_eth/fsl-fman from Yangbo Lu.
    
       - Lots of cleanups and fixes in L2TP code from Guillaume Nault.
    
       - Add IPSEC offload support to netdevsim, from Shannon Nelson.
    
       - Add support for slotting with non-uniform distribution to netem
         packet scheduler, from Yousuk Seung.
    
       - Add UDP GSO support to mlx5e, from Boris Pismenny.
    
       - Support offloading of Team LAG in NFP, from John Hurley.
    
       - Allow to configure TX queue selection based upon RX queue, from
         Amritha Nambiar.
    
       - Support ethtool ring size configuration in aquantia, from Anton
         Mikaev.
    
       - Support DSCP and flowlabel per-transport in SCTP, from Xin Long.
    
       - Support list based batching and stack traversal of SKBs, this is
         very exciting work. From Edward Cree.
    
       - Busyloop optimizations in vhost_net, from Toshiaki Makita.
    
       - Introduce the ETF qdisc, which allows time based transmissions. IGB
         can offload this in hardware. From Vinicius Costa Gomes.
    
       - Add parameter support to devlink, from Moshe Shemesh.
    
       - Several multiplication and division optimizations for BPF JIT in
         nfp driver, from Jiong Wang.
    
       - Lots of prepatory work to make more of the packet scheduler layer
         lockless, when possible, from Vlad Buslov.
    
       - Add ACK filter and NAT awareness to sch_cake packet scheduler, from
         Toke Høiland-Jørgensen.
    
       - Support regions and region snapshots in devlink, from Alex Vesker.
    
       - Allow to attach XDP programs to both HW and SW at the same time on
         a given device, with initial support in nfp. From Jakub Kicinski.
    
       - Add TLS RX offload and support in mlx5, from Ilya Lesokhin.
    
       - Use PHYLIB in r8169 driver, from Heiner Kallweit.
    
       - All sorts of changes to support Spectrum 2 in mlxsw driver, from
         Ido Schimmel.
    
       - PTP support in mv88e6xxx DSA driver, from Andrew Lunn.
    
       - Make TCP_USER_TIMEOUT socket option more accurate, from Jon
         Maxwell.
    
       - Support for templates in packet scheduler classifier, from Jiri
         Pirko.
    
       - IPV6 support in RDS, from Ka-Cheong Poon.
    
       - Native tproxy support in nf_tables, from Máté Eckl.
    
       - Maintain IP fragment queue in an rbtree, but optimize properly for
         in-order frags. From Peter Oskolkov.
    
       - Improvde handling of ACKs on hole repairs, from Yuchung Cheng"
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next: (1996 commits)
      bpf: test: fix spelling mistake "REUSEEPORT" -> "REUSEPORT"
      hv/netvsc: Fix NULL dereference at single queue mode fallback
      net: filter: mark expected switch fall-through
      xen-netfront: fix warn message as irq device name has '/'
      cxgb4: Add new T5 PCI device ids 0x50af and 0x50b0
      net: dsa: mv88e6xxx: missing unlock on error path
      rds: fix building with IPV6=m
      inet/connection_sock: prefer _THIS_IP_ to current_text_addr
      net: dsa: mv88e6xxx: bitwise vs logical bug
      net: sock_diag: Fix spectre v1 gadget in __sock_diag_cmd()
      ieee802154: hwsim: using right kind of iteration
      net: hns3: Add vlan filter setting by ethtool command -K
      net: hns3: Set tx ring' tc info when netdev is up
      net: hns3: Remove tx ring BD len register in hns3_enet
      net: hns3: Fix desc num set to default when setting channel
      net: hns3: Fix for phy link issue when using marvell phy driver
      net: hns3: Fix for information of phydev lost problem when down/up
      net: hns3: Fix for command format parsing error in hclge_is_all_function_id_zero
      net: hns3: Add support for serdes loopback selftest
      bnxt_en: take coredump_record structure off stack
      ...

commit a66b4cd1e7163adb327838a3c81faaf6a9330d5a
Merge: b16528466786 5f336e722cc9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Aug 13 19:58:36 2018 -0700

    Merge branch 'work.open3' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs open-related updates from Al Viro:
    
     - "do we need fput() or put_filp()" rules are gone - it's always fput()
       now. We keep track of that state where it belongs - in ->f_mode.
    
     - int *opened mess killed - in finish_open(), in ->atomic_open()
       instances and in fs/namei.c code around do_last()/lookup_open()/atomic_open().
    
     - alloc_file() wrappers with saner calling conventions are introduced
       (alloc_file_clone() and alloc_file_pseudo()); callers converted, with
       much simplification.
    
     - while we are at it, saner calling conventions for path_init() and
       link_path_walk(), simplifying things inside fs/namei.c (both on
       open-related paths and elsewhere).
    
    * 'work.open3' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (40 commits)
      few more cleanups of link_path_walk() callers
      allow link_path_walk() to take ERR_PTR()
      make path_init() unconditionally paired with terminate_walk()
      document alloc_file() changes
      make alloc_file() static
      do_shmat(): grab shp->shm_file earlier, switch to alloc_file_clone()
      new helper: alloc_file_clone()
      create_pipe_files(): switch the first allocation to alloc_file_pseudo()
      anon_inode_getfile(): switch to alloc_file_pseudo()
      hugetlb_file_setup(): switch to alloc_file_pseudo()
      ocxlflash_getfile(): switch to alloc_file_pseudo()
      cxl_getfile(): switch to alloc_file_pseudo()
      ... and switch shmem_file_setup() to alloc_file_pseudo()
      __shmem_file_setup(): reorder allocations
      new wrapper: alloc_file_pseudo()
      kill FILE_{CREATED,OPENED}
      switch atomic_open() and lookup_open() to returning 0 in all success cases
      document ->atomic_open() changes
      ->atomic_open(): return 0 in all success cases
      get rid of 'opened' in path_openat() and the helpers downstream
      ...

commit c1c8626fcebed467184ffd8de0ab5c9f9d9c3594
Merge: d89d41556141 1ffaddd029c8
Author: David S. Miller <davem@davemloft.net>
Date:   Sun Aug 5 13:04:31 2018 -0700

    Merge ra.kernel.org:/pub/scm/linux/kernel/git/davem/net
    
    Lots of overlapping changes, mostly trivial in nature.
    
    The mlxsw conflict was resolving using the example
    resolution at:
    
    https://github.com/jpirko/linux_mlxsw/blob/combined_queue/drivers/net/ethernet/mellanox/mlxsw/core_acl_flex_actions.c
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit eec3636ad198d4ac61e574cb122cb67e9bef5492
Author: Jane Chu <jane.chu@oracle.com>
Date:   Thu Aug 2 15:36:05 2018 -0700

    ipc/shm.c add ->pagesize function to shm_vm_ops
    
    Commit 05ea88608d4e ("mm, hugetlbfs: introduce ->pagesize() to
    vm_operations_struct") adds a new ->pagesize() function to
    hugetlb_vm_ops, intended to cover all hugetlbfs backed files.
    
    With System V shared memory model, if "huge page" is specified, the
    "shared memory" is backed by hugetlbfs files, but the mappings initiated
    via shmget/shmat have their original vm_ops overwritten with shm_vm_ops,
    so we need to add a ->pagesize function to shm_vm_ops.  Otherwise,
    vma_kernel_pagesize() returns PAGE_SIZE given a hugetlbfs backed vma,
    result in below BUG:
    
      fs/hugetlbfs/inode.c
            443             if (unlikely(page_mapped(page))) {
            444                     BUG_ON(truncate_op);
    
    resulting in
    
      hugetlbfs: oracle (4592): Using mlock ulimits for SHM_HUGETLB is deprecated
      ------------[ cut here ]------------
      kernel BUG at fs/hugetlbfs/inode.c:444!
      Modules linked in: nfsv3 rpcsec_gss_krb5 nfsv4 ...
      CPU: 35 PID: 5583 Comm: oracle_5583_sbt Not tainted 4.14.35-1829.el7uek.x86_64 #2
      RIP: 0010:remove_inode_hugepages+0x3db/0x3e2
      ....
      Call Trace:
        hugetlbfs_evict_inode+0x1e/0x3e
        evict+0xdb/0x1af
        iput+0x1a2/0x1f7
        dentry_unlink_inode+0xc6/0xf0
        __dentry_kill+0xd8/0x18d
        dput+0x1b5/0x1ed
        __fput+0x18b/0x216
        ____fput+0xe/0x10
        task_work_run+0x90/0xa7
        exit_to_usermode_loop+0xdd/0x116
        do_syscall_64+0x187/0x1ae
        entry_SYSCALL_64_after_hwframe+0x150/0x0
    
    [jane.chu@oracle.com: relocate comment]
      Link: http://lkml.kernel.org/r/20180731044831.26036-1-jane.chu@oracle.com
    Link: http://lkml.kernel.org/r/20180727211727.5020-1-jane.chu@oracle.com
    Fixes: 05ea88608d4e13 ("mm, hugetlbfs: introduce ->pagesize() to vm_operations_struct")
    Signed-off-by: Jane Chu <jane.chu@oracle.com>
    Suggested-by: Mike Kravetz <mike.kravetz@oracle.com>
    Reviewed-by: Mike Kravetz <mike.kravetz@oracle.com>
    Acked-by: Davidlohr Bueso <dave@stgolabs.net>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Jérôme Glisse <jglisse@redhat.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 051a3e1fb8df..fefa00d310fb 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -427,6 +427,17 @@ static int shm_split(struct vm_area_struct *vma, unsigned long addr)
 	return 0;
 }
 
+static unsigned long shm_pagesize(struct vm_area_struct *vma)
+{
+	struct file *file = vma->vm_file;
+	struct shm_file_data *sfd = shm_file_data(file);
+
+	if (sfd->vm_ops->pagesize)
+		return sfd->vm_ops->pagesize(vma);
+
+	return PAGE_SIZE;
+}
+
 #ifdef CONFIG_NUMA
 static int shm_set_policy(struct vm_area_struct *vma, struct mempolicy *new)
 {
@@ -554,6 +565,7 @@ static const struct vm_operations_struct shm_vm_ops = {
 	.close	= shm_close,	/* callback for when the vm-area is released */
 	.fault	= shm_fault,
 	.split	= shm_split,
+	.pagesize = shm_pagesize,
 #if defined(CONFIG_NUMA)
 	.set_policy = shm_set_policy,
 	.get_policy = shm_get_policy,

commit 4f089acc5f76ab1dff17b5f0be7608671a8441dc
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Jun 17 12:24:00 2018 -0400

    do_shmat(): grab shp->shm_file earlier, switch to alloc_file_clone()
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index c702abd578a7..7c8de9511950 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1354,14 +1354,13 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg,
 	struct shmid_kernel *shp;
 	unsigned long addr = (unsigned long)shmaddr;
 	unsigned long size;
-	struct file *file;
+	struct file *file, *base;
 	int    err;
 	unsigned long flags = MAP_SHARED;
 	unsigned long prot;
 	int acc_mode;
 	struct ipc_namespace *ns;
 	struct shm_file_data *sfd;
-	struct path path;
 	int f_flags;
 	unsigned long populate = 0;
 
@@ -1435,46 +1434,44 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg,
 		goto out_unlock;
 	}
 
-	path = shp->shm_file->f_path;
-	path_get(&path);
+	/*
+	 * We need to take a reference to the real shm file to prevent the
+	 * pointer from becoming stale in cases where the lifetime of the outer
+	 * file extends beyond that of the shm segment.  It's not usually
+	 * possible, but it can happen during remap_file_pages() emulation as
+	 * that unmaps the memory, then does ->mmap() via file reference only.
+	 * We'll deny the ->mmap() if the shm segment was since removed, but to
+	 * detect shm ID reuse we need to compare the file pointers.
+	 */
+	base = get_file(shp->shm_file);
 	shp->shm_nattch++;
-	size = i_size_read(d_inode(path.dentry));
+	size = i_size_read(file_inode(base));
 	ipc_unlock_object(&shp->shm_perm);
 	rcu_read_unlock();
 
 	err = -ENOMEM;
 	sfd = kzalloc(sizeof(*sfd), GFP_KERNEL);
 	if (!sfd) {
-		path_put(&path);
+		fput(base);
 		goto out_nattch;
 	}
 
-	file = alloc_file(&path, f_flags,
-			  is_file_hugepages(shp->shm_file) ?
+	file = alloc_file_clone(base, f_flags,
+			  is_file_hugepages(base) ?
 				&shm_file_operations_huge :
 				&shm_file_operations);
 	err = PTR_ERR(file);
 	if (IS_ERR(file)) {
 		kfree(sfd);
-		path_put(&path);
+		fput(base);
 		goto out_nattch;
 	}
 
-	file->private_data = sfd;
-	file->f_mapping = shp->shm_file->f_mapping;
 	sfd->id = shp->shm_perm.id;
 	sfd->ns = get_ipc_ns(ns);
-	/*
-	 * We need to take a reference to the real shm file to prevent the
-	 * pointer from becoming stale in cases where the lifetime of the outer
-	 * file extends beyond that of the shm segment.  It's not usually
-	 * possible, but it can happen during remap_file_pages() emulation as
-	 * that unmaps the memory, then does ->mmap() via file reference only.
-	 * We'll deny the ->mmap() if the shm segment was since removed, but to
-	 * detect shm ID reuse we need to compare the file pointers.
-	 */
-	sfd->file = get_file(shp->shm_file);
+	sfd->file = base;
 	sfd->vm_ops = NULL;
+	file->private_data = sfd;
 
 	err = security_mmap_file(file, prot, flags);
 	if (err)

commit c9c554f21490bbc96cc554f80024d27d09670480
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Jul 11 14:19:04 2018 -0400

    alloc_file(): switch to passing O_... flags instead of FMODE_... mode
    
    ... so that it could set both ->f_flags and ->f_mode, without callers
    having to set ->f_flags manually.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 051a3e1fb8df..c702abd578a7 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1362,7 +1362,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg,
 	struct ipc_namespace *ns;
 	struct shm_file_data *sfd;
 	struct path path;
-	fmode_t f_mode;
+	int f_flags;
 	unsigned long populate = 0;
 
 	err = -EINVAL;
@@ -1395,11 +1395,11 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg,
 	if (shmflg & SHM_RDONLY) {
 		prot = PROT_READ;
 		acc_mode = S_IRUGO;
-		f_mode = FMODE_READ;
+		f_flags = O_RDONLY;
 	} else {
 		prot = PROT_READ | PROT_WRITE;
 		acc_mode = S_IRUGO | S_IWUGO;
-		f_mode = FMODE_READ | FMODE_WRITE;
+		f_flags = O_RDWR;
 	}
 	if (shmflg & SHM_EXEC) {
 		prot |= PROT_EXEC;
@@ -1449,7 +1449,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg,
 		goto out_nattch;
 	}
 
-	file = alloc_file(&path, f_mode,
+	file = alloc_file(&path, f_flags,
 			  is_file_hugepages(shp->shm_file) ?
 				&shm_file_operations_huge :
 				&shm_file_operations);

commit 0eb71a9da5796851fa87ddc1a534066c0fe54055
Author: NeilBrown <neilb@suse.com>
Date:   Mon Jun 18 12:52:50 2018 +1000

    rhashtable: split rhashtable.h
    
    Due to the use of rhashtables in net namespaces,
    rhashtable.h is included in lots of the kernel,
    so a small changes can required a large recompilation.
    This makes development painful.
    
    This patch splits out rhashtable-types.h which just includes
    the major type declarations, and does not include (non-trivial)
    inline code.  rhashtable.h is no longer included by anything
    in the include/ directory.
    Common include files only include rhashtable-types.h so a large
    recompilation is only triggered when that changes.
    
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/ipc/shm.c b/ipc/shm.c
index 051a3e1fb8df..d4daf78df6da 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -43,6 +43,7 @@
 #include <linux/nsproxy.h>
 #include <linux/mount.h>
 #include <linux/ipc_namespace.h>
+#include <linux/rhashtable.h>
 
 #include <linux/uaccess.h>
 

commit 14f28f5776927be30717986f86b765d49eec392c
Author: Souptick Joarder <jrdr.linux@gmail.com>
Date:   Thu Jun 14 15:27:55 2018 -0700

    ipc: use new return type vm_fault_t
    
    Use new return type vm_fault_t for fault handler.  For now, this is just
    documenting that the function returns a VM_FAULT value rather than an
    errno.  Once all instances are converted, vm_fault_t will become a
    distinct type.
    
    Commit 1c8f422059ae ("mm: change return type to vm_fault_t")
    
    Link: http://lkml.kernel.org/r/20180425043413.GA21467@jordon-HP-15-Notebook-PC
    Signed-off-by: Souptick Joarder <jrdr.linux@gmail.com>
    Reviewed-by: Matthew Wilcox <mawilcox@microsoft.com>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: Davidlohr Bueso <dbueso@suse.de>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 29978ee76c2e..051a3e1fb8df 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -408,7 +408,7 @@ void exit_shm(struct task_struct *task)
 	up_write(&shm_ids(ns).rwsem);
 }
 
-static int shm_fault(struct vm_fault *vmf)
+static vm_fault_t shm_fault(struct vm_fault *vmf)
 {
 	struct file *file = vmf->vma->vm_file;
 	struct shm_file_data *sfd = shm_file_data(file);

commit ba252f16e4433e7599fec986e77722e6d0eed186
Merge: 0bbcce5d1ef3 e27c49291a7f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jun 4 21:02:18 2018 -0700

    Merge branch 'timers-2038-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull time/Y2038 updates from Thomas Gleixner:
    
     - Consolidate SySV IPC UAPI headers
    
     - Convert SySV IPC to the new COMPAT_32BIT_TIME mechanism
    
     - Cleanup the core interfaces and standardize on the ktime_get_* naming
       convention.
    
     - Convert the X86 platform ops to timespec64
    
     - Remove the ugly temporary timespec64 hack
    
    * 'timers-2038-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (22 commits)
      x86: Convert x86_platform_ops to timespec64
      timekeeping: Add more coarse clocktai/boottime interfaces
      timekeeping: Add ktime_get_coarse_with_offset
      timekeeping: Standardize on ktime_get_*() naming
      timekeeping: Clean up ktime_get_real_ts64
      timekeeping: Remove timespec64 hack
      y2038: ipc: Redirect ipc(SEMTIMEDOP, ...) to compat_ksys_semtimedop
      y2038: ipc: Enable COMPAT_32BIT_TIME
      y2038: ipc: Use __kernel_timespec
      y2038: ipc: Report long times to user space
      y2038: ipc: Use ktime_get_real_seconds consistently
      y2038: xtensa: Extend sysvipc data structures
      y2038: powerpc: Extend sysvipc data structures
      y2038: sparc: Extend sysvipc data structures
      y2038: parisc: Extend sysvipc data structures
      y2038: mips: Extend sysvipc data structures
      y2038: arm64: Extend sysvipc compat data structures
      y2038: s390: Remove unneeded ipc uapi header files
      y2038: ia64: Remove unneeded ipc uapi header files
      y2038: alpha: Remove unneeded ipc uapi header files
      ...

commit 8f89c007b6dec16a1793cb88de88fcc02117bbbc
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Fri May 25 14:47:30 2018 -0700

    ipc/shm: fix shmat() nil address after round-down when remapping
    
    shmat()'s SHM_REMAP option forbids passing a nil address for; this is in
    fact the very first thing we check for.  Andrea reported that for
    SHM_RND|SHM_REMAP cases we can end up bypassing the initial addr check,
    but we need to check again if the address was rounded down to nil.  As
    of this patch, such cases will return -EINVAL.
    
    Link: http://lkml.kernel.org/r/20180503204934.kk63josdu6u53fbd@linux-n805
    Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
    Reported-by: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Joe Lawrence <joe.lawrence@redhat.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 930be3aa80cf..d73269381ec7 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1363,9 +1363,17 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg,
 
 	if (addr) {
 		if (addr & (shmlba - 1)) {
-			if (shmflg & SHM_RND)
+			if (shmflg & SHM_RND) {
 				addr &= ~(shmlba - 1);  /* round down */
-			else
+
+				/*
+				 * Ensure that the round-down is non-nil
+				 * when remapping. This can happen for
+				 * cases when addr < shmlba.
+				 */
+				if (!addr && (shmflg & SHM_REMAP))
+					goto out;
+			} else
 #ifndef __ARCH_FORCE_SHMLBA
 				if (addr & ~PAGE_MASK)
 #endif

commit a73ab244f0dad8fffb3291b905f73e2d3eaa7c00
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Fri May 25 14:47:27 2018 -0700

    Revert "ipc/shm: Fix shmat mmap nil-page protection"
    
    Patch series "ipc/shm: shmat() fixes around nil-page".
    
    These patches fix two issues reported[1] a while back by Joe and Andrea
    around how shmat(2) behaves with nil-page.
    
    The first reverts a commit that it was incorrectly thought that mapping
    nil-page (address=0) was a no no with MAP_FIXED.  This is not the case,
    with the exception of SHM_REMAP; which is address in the second patch.
    
    I chose two patches because it is easier to backport and it explicitly
    reverts bogus behaviour.  Both patches ought to be in -stable and ltp
    testcases need updated (the added testcase around the cve can be
    modified to just test for SHM_RND|SHM_REMAP).
    
    [1] lkml.kernel.org/r/20180430172152.nfa564pvgpk3ut7p@linux-n805
    
    This patch (of 2):
    
    Commit 95e91b831f87 ("ipc/shm: Fix shmat mmap nil-page protection")
    worked on the idea that we should not be mapping as root addr=0 and
    MAP_FIXED.  However, it was reported that this scenario is in fact
    valid, thus making the patch both bogus and breaks userspace as well.
    
    For example X11's libint10.so relies on shmat(1, SHM_RND) for lowmem
    initialization[1].
    
    [1] https://cgit.freedesktop.org/xorg/xserver/tree/hw/xfree86/os-support/linux/int10/linux.c#n347
    Link: http://lkml.kernel.org/r/20180503203243.15045-2-dave@stgolabs.net
    Fixes: 95e91b831f87 ("ipc/shm: Fix shmat mmap nil-page protection")
    Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
    Reported-by: Joe Lawrence <joe.lawrence@redhat.com>
    Reported-by: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 3cf48988d68c..930be3aa80cf 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1363,13 +1363,8 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg,
 
 	if (addr) {
 		if (addr & (shmlba - 1)) {
-			/*
-			 * Round down to the nearest multiple of shmlba.
-			 * For sane do_mmap_pgoff() parameters, avoid
-			 * round downs that trigger nil-page and MAP_FIXED.
-			 */
-			if ((shmflg & SHM_RND) && addr >= shmlba)
-				addr &= ~(shmlba - 1);
+			if (shmflg & SHM_RND)
+				addr &= ~(shmlba - 1);  /* round down */
 			else
 #ifndef __ARCH_FORCE_SHMLBA
 				if (addr & ~PAGE_MASK)

commit c2ab975c30f0c3d3efcd69c1f1b2baa831c9374f
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Tue Apr 28 21:39:50 2015 +0200

    y2038: ipc: Report long times to user space
    
    The shmid64_ds/semid64_ds/msqid64_ds data structures have been extended
    to contain extra fields for storing the upper bits of the time stamps,
    this patch does the other half of the job and and fills the new fields on
    32-bit architectures as well as 32-bit tasks running on a 64-bit kernel
    in compat mode.
    
    There should be no change for native 64-bit tasks.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/ipc/shm.c b/ipc/shm.c
index 3cf48988d68c..0075990338f4 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1002,6 +1002,11 @@ static int shmctl_stat(struct ipc_namespace *ns, int shmid,
 	tbuf->shm_atime	= shp->shm_atim;
 	tbuf->shm_dtime	= shp->shm_dtim;
 	tbuf->shm_ctime	= shp->shm_ctim;
+#ifndef CONFIG_64BIT
+	tbuf->shm_atime_high = shp->shm_atim >> 32;
+	tbuf->shm_dtime_high = shp->shm_dtim >> 32;
+	tbuf->shm_ctime_high = shp->shm_ctim >> 32;
+#endif
 	tbuf->shm_cpid	= pid_vnr(shp->shm_cprid);
 	tbuf->shm_lpid	= pid_vnr(shp->shm_lprid);
 	tbuf->shm_nattch = shp->shm_nattch;
@@ -1233,9 +1238,12 @@ static int copy_compat_shmid_to_user(void __user *buf, struct shmid64_ds *in,
 		struct compat_shmid64_ds v;
 		memset(&v, 0, sizeof(v));
 		to_compat_ipc64_perm(&v.shm_perm, &in->shm_perm);
-		v.shm_atime = in->shm_atime;
-		v.shm_dtime = in->shm_dtime;
-		v.shm_ctime = in->shm_ctime;
+		v.shm_atime	 = lower_32_bits(in->shm_atime);
+		v.shm_atime_high = upper_32_bits(in->shm_atime);
+		v.shm_dtime	 = lower_32_bits(in->shm_dtime);
+		v.shm_dtime_high = upper_32_bits(in->shm_dtime);
+		v.shm_ctime	 = lower_32_bits(in->shm_ctime);
+		v.shm_ctime_high = upper_32_bits(in->shm_ctime);
 		v.shm_segsz = in->shm_segsz;
 		v.shm_nattch = in->shm_nattch;
 		v.shm_cpid = in->shm_cpid;

commit 3f05317d9889ab75c7190dcd39491d2a97921984
Author: Eric Biggers <ebiggers@google.com>
Date:   Fri Apr 13 15:35:30 2018 -0700

    ipc/shm: fix use-after-free of shm file via remap_file_pages()
    
    syzbot reported a use-after-free of shm_file_data(file)->file->f_op in
    shm_get_unmapped_area(), called via sys_remap_file_pages().
    
    Unfortunately it couldn't generate a reproducer, but I found a bug which
    I think caused it.  When remap_file_pages() is passed a full System V
    shared memory segment, the memory is first unmapped, then a new map is
    created using the ->vm_file.  Between these steps, the shm ID can be
    removed and reused for a new shm segment.  But, shm_mmap() only checks
    whether the ID is currently valid before calling the underlying file's
    ->mmap(); it doesn't check whether it was reused.  Thus it can use the
    wrong underlying file, one that was already freed.
    
    Fix this by making the "outer" shm file (the one that gets put in
    ->vm_file) hold a reference to the real shm file, and by making
    __shm_open() require that the file associated with the shm ID matches
    the one associated with the "outer" file.
    
    Taking the reference to the real shm file is needed to fully solve the
    problem, since otherwise sfd->file could point to a freed file, which
    then could be reallocated for the reused shm ID, causing the wrong shm
    segment to be mapped (and without the required permission checks).
    
    Commit 1ac0b6dec656 ("ipc/shm: handle removed segments gracefully in
    shm_mmap()") almost fixed this bug, but it didn't go far enough because
    it didn't consider the case where the shm ID is reused.
    
    The following program usually reproduces this bug:
    
            #include <stdlib.h>
            #include <sys/shm.h>
            #include <sys/syscall.h>
            #include <unistd.h>
    
            int main()
            {
                    int is_parent = (fork() != 0);
                    srand(getpid());
                    for (;;) {
                            int id = shmget(0xF00F, 4096, IPC_CREAT|0700);
                            if (is_parent) {
                                    void *addr = shmat(id, NULL, 0);
                                    usleep(rand() % 50);
                                    while (!syscall(__NR_remap_file_pages, addr, 4096, 0, 0, 0));
                            } else {
                                    usleep(rand() % 50);
                                    shmctl(id, IPC_RMID, NULL);
                            }
                    }
            }
    
    It causes the following NULL pointer dereference due to a 'struct file'
    being used while it's being freed.  (I couldn't actually get a KASAN
    use-after-free splat like in the syzbot report.  But I think it's
    possible with this bug; it would just take a more extraordinary race...)
    
            BUG: unable to handle kernel NULL pointer dereference at 0000000000000058
            PGD 0 P4D 0
            Oops: 0000 [#1] SMP NOPTI
            CPU: 9 PID: 258 Comm: syz_ipc Not tainted 4.16.0-05140-gf8cf2f16a7c95 #189
            Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.11.0-20171110_100015-anatol 04/01/2014
            RIP: 0010:d_inode include/linux/dcache.h:519 [inline]
            RIP: 0010:touch_atime+0x25/0xd0 fs/inode.c:1724
            [...]
            Call Trace:
             file_accessed include/linux/fs.h:2063 [inline]
             shmem_mmap+0x25/0x40 mm/shmem.c:2149
             call_mmap include/linux/fs.h:1789 [inline]
             shm_mmap+0x34/0x80 ipc/shm.c:465
             call_mmap include/linux/fs.h:1789 [inline]
             mmap_region+0x309/0x5b0 mm/mmap.c:1712
             do_mmap+0x294/0x4a0 mm/mmap.c:1483
             do_mmap_pgoff include/linux/mm.h:2235 [inline]
             SYSC_remap_file_pages mm/mmap.c:2853 [inline]
             SyS_remap_file_pages+0x232/0x310 mm/mmap.c:2769
             do_syscall_64+0x64/0x1a0 arch/x86/entry/common.c:287
             entry_SYSCALL_64_after_hwframe+0x42/0xb7
    
    [ebiggers@google.com: add comment]
      Link: http://lkml.kernel.org/r/20180410192850.235835-1-ebiggers3@gmail.com
    Link: http://lkml.kernel.org/r/20180409043039.28915-1-ebiggers3@gmail.com
    Reported-by: syzbot+d11f321e7f1923157eac80aa990b446596f46439@syzkaller.appspotmail.com
    Fixes: c8d78c1823f4 ("mm: replace remap_file_pages() syscall with emulation")
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Davidlohr Bueso <dbueso@suse.de>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: "Eric W . Biederman" <ebiederm@xmission.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 5639345dbec9..3cf48988d68c 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -225,6 +225,12 @@ static int __shm_open(struct vm_area_struct *vma)
 	if (IS_ERR(shp))
 		return PTR_ERR(shp);
 
+	if (shp->shm_file != sfd->file) {
+		/* ID was reused */
+		shm_unlock(shp);
+		return -EINVAL;
+	}
+
 	shp->shm_atim = ktime_get_real_seconds();
 	ipc_update_pid(&shp->shm_lprid, task_tgid(current));
 	shp->shm_nattch++;
@@ -455,8 +461,9 @@ static int shm_mmap(struct file *file, struct vm_area_struct *vma)
 	int ret;
 
 	/*
-	 * In case of remap_file_pages() emulation, the file can represent
-	 * removed IPC ID: propogate shm_lock() error to caller.
+	 * In case of remap_file_pages() emulation, the file can represent an
+	 * IPC ID that was removed, and possibly even reused by another shm
+	 * segment already.  Propagate this case as an error to caller.
 	 */
 	ret = __shm_open(vma);
 	if (ret)
@@ -480,6 +487,7 @@ static int shm_release(struct inode *ino, struct file *file)
 	struct shm_file_data *sfd = shm_file_data(file);
 
 	put_ipc_ns(sfd->ns);
+	fput(sfd->file);
 	shm_file_data(file) = NULL;
 	kfree(sfd);
 	return 0;
@@ -1445,7 +1453,16 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg,
 	file->f_mapping = shp->shm_file->f_mapping;
 	sfd->id = shp->shm_perm.id;
 	sfd->ns = get_ipc_ns(ns);
-	sfd->file = shp->shm_file;
+	/*
+	 * We need to take a reference to the real shm file to prevent the
+	 * pointer from becoming stale in cases where the lifetime of the outer
+	 * file extends beyond that of the shm segment.  It's not usually
+	 * possible, but it can happen during remap_file_pages() emulation as
+	 * that unmaps the memory, then does ->mmap() via file reference only.
+	 * We'll deny the ->mmap() if the shm segment was since removed, but to
+	 * detect shm ID reuse we need to compare the file pointers.
+	 */
+	sfd->file = get_file(shp->shm_file);
 	sfd->vm_ops = NULL;
 
 	err = security_mmap_file(file, prot, flags);

commit a61fc2cbdf6a753b7000dd216c62285a68755147
Author: Andrew Morton <akpm@linux-foundation.org>
Date:   Tue Apr 10 16:35:42 2018 -0700

    ipc/shm.c: shm_split(): remove unneeded test for NULL shm_file_data.vm_ops
    
    This was added by the recent "ipc/shm.c: add split function to
    shm_vm_ops", but it is not necessary.
    
    Reviewed-by: Mike Kravetz <mike.kravetz@oracle.com>
    Cc: Laurent Dufour <ldufour@linux.vnet.ibm.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 1a28b6a96449..5639345dbec9 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -415,7 +415,7 @@ static int shm_split(struct vm_area_struct *vma, unsigned long addr)
 	struct file *file = vma->vm_file;
 	struct shm_file_data *sfd = shm_file_data(file);
 
-	if (sfd->vm_ops && sfd->vm_ops->split)
+	if (sfd->vm_ops->split)
 		return sfd->vm_ops->split(vma, addr);
 
 	return 0;

commit c21a6970ae727839a2f300cd8dd957de0d0238c3
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Tue Apr 10 16:35:23 2018 -0700

    ipc/shm: introduce shmctl(SHM_STAT_ANY)
    
    Patch series "sysvipc: introduce STAT_ANY commands", v2.
    
    The following patches adds the discussed (see [1]) new command for shm
    as well as for sems and msq as they are subject to the same
    discrepancies for ipc object permission checks between the syscall and
    via procfs.  These new commands are justified in that (1) we are stuck
    with this semantics as changing syscall and procfs can break userland;
    and (2) some users can benefit from performance (for large amounts of
    shm segments, for example) from not having to parse the procfs
    interface.
    
    Once merged, I will submit the necesary manpage updates.  But I'm thinking
    something like:
    
    : diff --git a/man2/shmctl.2 b/man2/shmctl.2
    : index 7bb503999941..bb00bbe21a57 100644
    : --- a/man2/shmctl.2
    : +++ b/man2/shmctl.2
    : @@ -41,6 +41,7 @@
    :  .\" 2005-04-25, mtk -- noted aberrant Linux behavior w.r.t. new
    :  .\"  attaches to a segment that has already been marked for deletion.
    :  .\" 2005-08-02, mtk: Added IPC_INFO, SHM_INFO, SHM_STAT descriptions.
    : +.\" 2018-02-13, dbueso: Added SHM_STAT_ANY description.
    :  .\"
    :  .TH SHMCTL 2 2017-09-15 "Linux" "Linux Programmer's Manual"
    :  .SH NAME
    : @@ -242,6 +243,18 @@ However, the
    :  argument is not a segment identifier, but instead an index into
    :  the kernel's internal array that maintains information about
    :  all shared memory segments on the system.
    : +.TP
    : +.BR SHM_STAT_ANY " (Linux-specific)"
    : +Return a
    : +.I shmid_ds
    : +structure as for
    : +.BR SHM_STAT .
    : +However, the
    : +.I shm_perm.mode
    : +is not checked for read access for
    : +.IR shmid ,
    : +resembing the behaviour of
    : +/proc/sysvipc/shm.
    :  .PP
    :  The caller can prevent or allow swapping of a shared
    :  memory segment with the following \fIcmd\fP values:
    : @@ -287,7 +300,7 @@ operation returns the index of the highest used entry in the
    :  kernel's internal array recording information about all
    :  shared memory segments.
    :  (This information can be used with repeated
    : -.B SHM_STAT
    : +.B SHM_STAT/SHM_STAT_ANY
    :  operations to obtain information about all shared memory segments
    :  on the system.)
    :  A successful
    : @@ -328,7 +341,7 @@ isn't accessible.
    :  \fIshmid\fP is not a valid identifier, or \fIcmd\fP
    :  is not a valid command.
    :  Or: for a
    : -.B SHM_STAT
    : +.B SHM_STAT/SHM_STAT_ANY
    :  operation, the index value specified in
    :  .I shmid
    :  referred to an array slot that is currently unused.
    
    This patch (of 3):
    
    There is a permission discrepancy when consulting shm ipc object metadata
    between /proc/sysvipc/shm (0444) and the SHM_STAT shmctl command.  The
    later does permission checks for the object vs S_IRUGO.  As such there can
    be cases where EACCESS is returned via syscall but the info is displayed
    anyways in the procfs files.
    
    While this might have security implications via info leaking (albeit no
    writing to the shm metadata), this behavior goes way back and showing all
    the objects regardless of the permissions was most likely an overlook - so
    we are stuck with it.  Furthermore, modifying either the syscall or the
    procfs file can cause userspace programs to break (ie ipcs).  Some
    applications require getting the procfs info (without root privileges) and
    can be rather slow in comparison with a syscall -- up to 500x in some
    reported cases.
    
    This patch introduces a new SHM_STAT_ANY command such that the shm ipc
    object permissions are ignored, and only audited instead.  In addition,
    I've left the lsm security hook checks in place, as if some policy can
    block the call, then the user has no other choice than just parsing the
    procfs file.
    
    [1] https://lkml.org/lkml/2017/12/19/220
    
    Link: http://lkml.kernel.org/r/20180215162458.10059-2-dave@stgolabs.net
    Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Robert Kettler <robert.kettler@outlook.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index acefe44fefef..1a28b6a96449 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -947,14 +947,14 @@ static int shmctl_stat(struct ipc_namespace *ns, int shmid,
 	memset(tbuf, 0, sizeof(*tbuf));
 
 	rcu_read_lock();
-	if (cmd == SHM_STAT) {
+	if (cmd == SHM_STAT || cmd == SHM_STAT_ANY) {
 		shp = shm_obtain_object(ns, shmid);
 		if (IS_ERR(shp)) {
 			err = PTR_ERR(shp);
 			goto out_unlock;
 		}
 		id = shp->shm_perm.id;
-	} else {
+	} else { /* IPC_STAT */
 		shp = shm_obtain_object_check(ns, shmid);
 		if (IS_ERR(shp)) {
 			err = PTR_ERR(shp);
@@ -962,9 +962,20 @@ static int shmctl_stat(struct ipc_namespace *ns, int shmid,
 		}
 	}
 
-	err = -EACCES;
-	if (ipcperms(ns, &shp->shm_perm, S_IRUGO))
-		goto out_unlock;
+	/*
+	 * Semantically SHM_STAT_ANY ought to be identical to
+	 * that functionality provided by the /proc/sysvipc/
+	 * interface. As such, only audit these calls and
+	 * do not do traditional S_IRUGO permission checks on
+	 * the ipc object.
+	 */
+	if (cmd == SHM_STAT_ANY)
+		audit_ipc_obj(&shp->shm_perm);
+	else {
+		err = -EACCES;
+		if (ipcperms(ns, &shp->shm_perm, S_IRUGO))
+			goto out_unlock;
+	}
 
 	err = security_shm_shmctl(&shp->shm_perm, cmd);
 	if (err)
@@ -1104,6 +1115,7 @@ long ksys_shmctl(int shmid, int cmd, struct shmid_ds __user *buf)
 		return err;
 	}
 	case SHM_STAT:
+	case SHM_STAT_ANY:
 	case IPC_STAT: {
 		err = shmctl_stat(ns, shmid, cmd, &sem64);
 		if (err < 0)
@@ -1282,6 +1294,7 @@ long compat_ksys_shmctl(int shmid, int cmd, void __user *uptr)
 		return err;
 	}
 	case IPC_STAT:
+	case SHM_STAT_ANY:
 	case SHM_STAT:
 		err = shmctl_stat(ns, shmid, cmd, &sem64);
 		if (err < 0)

commit 17dec0a949153d9ac00760ba2f5b78cb583e995f
Merge: d92cd810e64a 2236d4d39035
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Apr 3 19:15:32 2018 -0700

    Merge branch 'userns-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace
    
    Pull namespace updates from Eric Biederman:
     "There was a lot of work this cycle fixing bugs that were discovered
      after the merge window and getting everything ready where we can
      reasonably support fully unprivileged fuse. The bug fixes you already
      have and much of the unprivileged fuse work is coming in via other
      trees.
    
      Still left for fully unprivileged fuse is figuring out how to cleanly
      handle .set_acl and .get_acl in the legacy case, and properly handling
      of evm xattrs on unprivileged mounts.
    
      Included in the tree is a cleanup from Alexely that replaced a linked
      list with a statically allocated fix sized array for the pid caches,
      which simplifies and speeds things up.
    
      Then there is are some cleanups and fixes for the ipc namespace. The
      motivation was that in reviewing other code it was discovered that
      access ipc objects from different pid namespaces recorded pids in such
      a way that when asked the wrong pids were returned. In the worst case
      there has been a measured 30% performance impact for sysvipc
      semaphores. Other test cases showed no measurable performance impact.
      Manfred Spraul and Davidlohr Bueso who tend to work on sysvipc
      performance both gave the nod that this is good enough.
    
      Casey Schaufler and James Morris have given their approval to the LSM
      side of the changes.
    
      I simplified the types and the code dealing with sysvipc to pass just
      kern_ipc_perm for all three types of ipc. Which reduced the header
      dependencies throughout the kernel and simplified the lsm code.
    
      Which let me work on the pid fixes without having to worry about
      trivial changes causing complete kernel recompiles"
    
    * 'userns-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/ebiederm/user-namespace:
      ipc/shm: Fix pid freeing.
      ipc/shm: fix up for struct file no longer being available in shm.h
      ipc/smack: Tidy up from the change in type of the ipc security hooks
      ipc: Directly call the security hook in ipc_ops.associate
      ipc/sem: Fix semctl(..., GETPID, ...) between pid namespaces
      ipc/msg: Fix msgctl(..., IPC_STAT, ...) between pid namespaces
      ipc/shm: Fix shmctl(..., IPC_STAT, ...) between pid namespaces.
      ipc/util: Helpers for making the sysvipc operations pid namespace aware
      ipc: Move IPCMNI from include/ipc.h into ipc/util.h
      msg: Move struct msg_queue into ipc/msg.c
      shm: Move struct shmid_kernel into ipc/shm.c
      sem: Move struct sem and struct sem_array into ipc/sem.c
      msg/security: Pass kern_ipc_perm not msg_queue into the msg_queue security hooks
      shm/security: Pass kern_ipc_perm not shmid_kernel into the shm security hooks
      sem/security: Pass kern_ipc_perm not sem_array into the sem security hooks
      pidns: simpler allocation of pid_* caches

commit 642e7fd23353e22290e3d51719fcb658dc252342
Merge: 21035965f60b c9a211951c7c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Apr 2 21:22:12 2018 -0700

    Merge branch 'syscalls-next' of git://git.kernel.org/pub/scm/linux/kernel/git/brodo/linux
    
    Pull removal of in-kernel calls to syscalls from Dominik Brodowski:
     "System calls are interaction points between userspace and the kernel.
      Therefore, system call functions such as sys_xyzzy() or
      compat_sys_xyzzy() should only be called from userspace via the
      syscall table, but not from elsewhere in the kernel.
    
      At least on 64-bit x86, it will likely be a hard requirement from
      v4.17 onwards to not call system call functions in the kernel: It is
      better to use use a different calling convention for system calls
      there, where struct pt_regs is decoded on-the-fly in a syscall wrapper
      which then hands processing over to the actual syscall function. This
      means that only those parameters which are actually needed for a
      specific syscall are passed on during syscall entry, instead of
      filling in six CPU registers with random user space content all the
      time (which may cause serious trouble down the call chain). Those
      x86-specific patches will be pushed through the x86 tree in the near
      future.
    
      Moreover, rules on how data may be accessed may differ between kernel
      data and user data. This is another reason why calling sys_xyzzy() is
      generally a bad idea, and -- at most -- acceptable in arch-specific
      code.
    
      This patchset removes all in-kernel calls to syscall functions in the
      kernel with the exception of arch/. On top of this, it cleans up the
      three places where many syscalls are referenced or prototyped, namely
      kernel/sys_ni.c, include/linux/syscalls.h and include/linux/compat.h"
    
    * 'syscalls-next' of git://git.kernel.org/pub/scm/linux/kernel/git/brodo/linux: (109 commits)
      bpf: whitelist all syscalls for error injection
      kernel/sys_ni: remove {sys_,sys_compat} from cond_syscall definitions
      kernel/sys_ni: sort cond_syscall() entries
      syscalls/x86: auto-create compat_sys_*() prototypes
      syscalls: sort syscall prototypes in include/linux/compat.h
      net: remove compat_sys_*() prototypes from net/compat.h
      syscalls: sort syscall prototypes in include/linux/syscalls.h
      kexec: move sys_kexec_load() prototype to syscalls.h
      x86/sigreturn: use SYSCALL_DEFINE0
      x86: fix sys_sigreturn() return type to be long, not unsigned long
      x86/ioport: add ksys_ioperm() helper; remove in-kernel calls to sys_ioperm()
      mm: add ksys_readahead() helper; remove in-kernel calls to sys_readahead()
      mm: add ksys_mmap_pgoff() helper; remove in-kernel calls to sys_mmap_pgoff()
      mm: add ksys_fadvise64_64() helper; remove in-kernel call to sys_fadvise64_64()
      fs: add ksys_fallocate() wrapper; remove in-kernel calls to sys_fallocate()
      fs: add ksys_p{read,write}64() helpers; remove in-kernel calls to syscalls
      fs: add ksys_truncate() wrapper; remove in-kernel calls to sys_truncate()
      fs: add ksys_sync_file_range helper(); remove in-kernel calls to syscall
      kernel: add ksys_setsid() helper; remove in-kernel call to sys_setsid()
      kernel: add ksys_unshare() helper; remove in-kernel calls to sys_unshare()
      ...

commit c84d0791dfa7fe8f051082c09a558eb3e2d01931
Author: Dominik Brodowski <linux@dominikbrodowski.net>
Date:   Tue Mar 20 20:12:33 2018 +0100

    ipc: add shmctl syscall/compat_syscall wrappers
    
    Provide ksys_shmctl() and compat_ksys_shmctl() wrappers to avoid in-kernel
    calls to these syscalls. The ksys_ prefix denotes that these functions are
    meant as a drop-in replacement for the syscalls. In particular, they use
    the same calling convention as sys_shmctl() and compat_sys_shmctl().
    
    This patch is part of a series which removes in-kernel calls to syscalls.
    On this basis, the syscall entry path can be streamlined. For details, see
    http://lkml.kernel.org/r/20180325162527.GA17492@light.dominikbrodowski.net
    
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Dominik Brodowski <linux@dominikbrodowski.net>

diff --git a/ipc/shm.c b/ipc/shm.c
index e5838e3328dc..0aae3e55bc56 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1045,7 +1045,7 @@ static int shmctl_do_lock(struct ipc_namespace *ns, int shmid, int cmd)
 	return err;
 }
 
-SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
+long ksys_shmctl(int shmid, int cmd, struct shmid_ds __user *buf)
 {
 	int err, version;
 	struct ipc_namespace *ns;
@@ -1099,6 +1099,11 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 	}
 }
 
+SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
+{
+	return ksys_shmctl(shmid, cmd, buf);
+}
+
 #ifdef CONFIG_COMPAT
 
 struct compat_shmid_ds {
@@ -1218,7 +1223,7 @@ static int copy_compat_shmid_from_user(struct shmid64_ds *out, void __user *buf,
 	}
 }
 
-COMPAT_SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, void __user *, uptr)
+long compat_ksys_shmctl(int shmid, int cmd, void __user *uptr)
 {
 	struct ipc_namespace *ns;
 	struct shmid64_ds sem64;
@@ -1273,6 +1278,11 @@ COMPAT_SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, void __user *, uptr)
 	}
 	return err;
 }
+
+COMPAT_SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, void __user *, uptr)
+{
+	return compat_ksys_shmctl(shmid, cmd, uptr);
+}
 #endif
 
 /*

commit da1e2744341542e404c172bcf6a321f509408b14
Author: Dominik Brodowski <linux@dominikbrodowski.net>
Date:   Tue Mar 20 20:09:48 2018 +0100

    ipc: add shmdt syscall wrapper
    
    Provide ksys_shmdt() wrapper to avoid in-kernel calls to this syscall.
    The ksys_ prefix denotes that this function is meant as a drop-in
    replacement for the syscall. In particular, it uses the same calling
    convention as sys_shmdt().
    
    This patch is part of a series which removes in-kernel calls to syscalls.
    On this basis, the syscall entry path can be streamlined. For details, see
    http://lkml.kernel.org/r/20180325162527.GA17492@light.dominikbrodowski.net
    
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Dominik Brodowski <linux@dominikbrodowski.net>

diff --git a/ipc/shm.c b/ipc/shm.c
index 9f3cdb259a51..e5838e3328dc 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1481,7 +1481,7 @@ COMPAT_SYSCALL_DEFINE3(shmat, int, shmid, compat_uptr_t, shmaddr, int, shmflg)
  * detach and kill segment if marked destroyed.
  * The work is done in shm_close.
  */
-SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
+long ksys_shmdt(char __user *shmaddr)
 {
 	struct mm_struct *mm = current->mm;
 	struct vm_area_struct *vma;
@@ -1588,6 +1588,11 @@ SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 	return retval;
 }
 
+SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
+{
+	return ksys_shmdt(shmaddr);
+}
+
 #ifdef CONFIG_PROC_FS
 static int sysvipc_shm_proc_show(struct seq_file *s, void *it)
 {

commit 65749e0bb5e7de876ee43d3f601e32afe17e9248
Author: Dominik Brodowski <linux@dominikbrodowski.net>
Date:   Tue Mar 20 20:07:53 2018 +0100

    ipc: add shmget syscall wrapper
    
    Provide ksys_shmget() wrapper to avoid in-kernel calls to this syscall.
    The ksys_ prefix denotes that this function is meant as a drop-in
    replacement for the syscall. In particular, it uses the same calling
    convention as sys_shmget().
    
    This patch is part of a series which removes in-kernel calls to syscalls.
    On this basis, the syscall entry path can be streamlined. For details, see
    http://lkml.kernel.org/r/20180325162527.GA17492@light.dominikbrodowski.net
    
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Dominik Brodowski <linux@dominikbrodowski.net>

diff --git a/ipc/shm.c b/ipc/shm.c
index 4643865e9171..9f3cdb259a51 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -656,7 +656,7 @@ static inline int shm_more_checks(struct kern_ipc_perm *ipcp,
 	return 0;
 }
 
-SYSCALL_DEFINE3(shmget, key_t, key, size_t, size, int, shmflg)
+long ksys_shmget(key_t key, size_t size, int shmflg)
 {
 	struct ipc_namespace *ns;
 	static const struct ipc_ops shm_ops = {
@@ -675,6 +675,11 @@ SYSCALL_DEFINE3(shmget, key_t, key, size_t, size, int, shmflg)
 	return ipcget(ns, &shm_ids(ns), &shm_ops, &shm_params);
 }
 
+SYSCALL_DEFINE3(shmget, key_t, key, size_t, size, int, shmflg)
+{
+	return ksys_shmget(key, size, shmflg);
+}
+
 static inline unsigned long copy_shmid_to_user(void __user *buf, struct shmid64_ds *in, int version)
 {
 	switch (version) {

commit 3d942ee079b917b24e2a0c5f18d35ac8ec9fee48
Author: Mike Kravetz <mike.kravetz@oracle.com>
Date:   Wed Mar 28 16:01:01 2018 -0700

    ipc/shm.c: add split function to shm_vm_ops
    
    If System V shmget/shmat operations are used to create a hugetlbfs
    backed mapping, it is possible to munmap part of the mapping and split
    the underlying vma such that it is not huge page aligned.  This will
    untimately result in the following BUG:
    
      kernel BUG at /build/linux-jWa1Fv/linux-4.15.0/mm/hugetlb.c:3310!
      Oops: Exception in kernel mode, sig: 5 [#1]
      LE SMP NR_CPUS=2048 NUMA PowerNV
      Modules linked in: kcm nfc af_alg caif_socket caif phonet fcrypt
      CPU: 18 PID: 43243 Comm: trinity-subchil Tainted: G         C  E 4.15.0-10-generic #11-Ubuntu
      NIP:  c00000000036e764 LR: c00000000036ee48 CTR: 0000000000000009
      REGS: c000003fbcdcf810 TRAP: 0700   Tainted: G         C  E (4.15.0-10-generic)
      MSR:  9000000000029033 <SF,HV,EE,ME,IR,DR,RI,LE>  CR: 24002222  XER: 20040000
      CFAR: c00000000036ee44 SOFTE: 1
      NIP __unmap_hugepage_range+0xa4/0x760
      LR __unmap_hugepage_range_final+0x28/0x50
      Call Trace:
        0x7115e4e00000 (unreliable)
        __unmap_hugepage_range_final+0x28/0x50
        unmap_single_vma+0x11c/0x190
        unmap_vmas+0x94/0x140
        exit_mmap+0x9c/0x1d0
        mmput+0xa8/0x1d0
        do_exit+0x360/0xc80
        do_group_exit+0x60/0x100
        SyS_exit_group+0x24/0x30
        system_call+0x58/0x6c
      ---[ end trace ee88f958a1c62605 ]---
    
    This bug was introduced by commit 31383c6865a5 ("mm, hugetlbfs:
    introduce ->split() to vm_operations_struct").  A split function was
    added to vm_operations_struct to determine if a mapping can be split.
    This was mostly for device-dax and hugetlbfs mappings which have
    specific alignment constraints.
    
    Mappings initiated via shmget/shmat have their original vm_ops
    overwritten with shm_vm_ops.  shm_vm_ops functions will call back to the
    original vm_ops if needed.  Add such a split function to shm_vm_ops.
    
    Link: http://lkml.kernel.org/r/20180321161314.7711-1-mike.kravetz@oracle.com
    Fixes: 31383c6865a5 ("mm, hugetlbfs: introduce ->split() to vm_operations_struct")
    Signed-off-by: Mike Kravetz <mike.kravetz@oracle.com>
    Reported-by: Laurent Dufour <ldufour@linux.vnet.ibm.com>
    Reviewed-by: Laurent Dufour <ldufour@linux.vnet.ibm.com>
    Tested-by: Laurent Dufour <ldufour@linux.vnet.ibm.com>
    Reviewed-by: Dan Williams <dan.j.williams@intel.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 4643865e9171..93e0e3a4d009 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -386,6 +386,17 @@ static int shm_fault(struct vm_fault *vmf)
 	return sfd->vm_ops->fault(vmf);
 }
 
+static int shm_split(struct vm_area_struct *vma, unsigned long addr)
+{
+	struct file *file = vma->vm_file;
+	struct shm_file_data *sfd = shm_file_data(file);
+
+	if (sfd->vm_ops && sfd->vm_ops->split)
+		return sfd->vm_ops->split(vma, addr);
+
+	return 0;
+}
+
 #ifdef CONFIG_NUMA
 static int shm_set_policy(struct vm_area_struct *vma, struct mempolicy *new)
 {
@@ -510,6 +521,7 @@ static const struct vm_operations_struct shm_vm_ops = {
 	.open	= shm_open,	/* callback for a new vm-area open */
 	.close	= shm_close,	/* callback for when the vm-area is released */
 	.fault	= shm_fault,
+	.split	= shm_split,
 #if defined(CONFIG_NUMA)
 	.set_policy = shm_set_policy,
 	.get_policy = shm_get_policy,

commit 2236d4d39035b9839944603ec4b65ce71180a9ea
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Mar 28 13:38:55 2018 -0500

    ipc/shm: Fix pid freeing.
    
    The 0day kernel test build report reported an oops:
    >
    >  IP: put_pid+0x22/0x5c
    >  PGD 19efa067 P4D 19efa067 PUD 0
    >  Oops: 0000 [#1]
    >  CPU: 0 PID: 727 Comm: trinity Not tainted 4.16.0-rc2-00010-g98f929b #1
    >  RIP: 0010:put_pid+0x22/0x5c
    >  RSP: 0018:ffff986719f73e48 EFLAGS: 00010202
    >  RAX: 00000006d765f710 RBX: ffff98671a4fa4d0 RCX: ffff986719f73d40
    >  RDX: 000000006f6e6125 RSI: 0000000000000000 RDI: ffffffffa01e6d21
    >  RBP: ffffffffa0955fe0 R08: 0000000000000020 R09: 0000000000000000
    >  R10: 0000000000000078 R11: ffff986719f73e76 R12: 0000000000001000
    >  R13: 00000000ffffffea R14: 0000000054000fb0 R15: 0000000000000000
    >  FS:  00000000028c2880(0000) GS:ffffffffa06ad000(0000) knlGS:0000000000000000
    >  CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    >  CR2: 0000000677846439 CR3: 0000000019fc1005 CR4: 00000000000606b0
    >  Call Trace:
    >   ? ipc_update_pid+0x36/0x3e
    >   ? newseg+0x34c/0x3a6
    >   ? ipcget+0x5d/0x528
    >   ? entry_SYSCALL_64_after_hwframe+0x52/0xb7
    >   ? SyS_shmget+0x5a/0x84
    >   ? do_syscall_64+0x194/0x1b3
    >   ? entry_SYSCALL_64_after_hwframe+0x42/0xb7
    >  Code: ff 05 e7 20 9b 03 58 c9 c3 48 ff 05 85 21 9b 03 48 85 ff 74 4f 8b 47 04 8b 17 48 ff 05 7c 21 9b 03 48 83 c0 03 48 c1 e0 04 ff ca <48> 8b 44 07 08 74 1f 48 ff 05 6c 21 9b 03 ff 0f 0f 94 c2 48 ff
    >  RIP: put_pid+0x22/0x5c RSP: ffff986719f73e48
    >  CR2: 0000000677846439
    >  ---[ end trace ab8c5cb4389d37c5 ]---
    >  Kernel panic - not syncing: Fatal exception
    
    In newseg when changing shm_cprid and shm_lprid from pid_t to struct
    pid* I misread the kvmalloc as kvzalloc and thought shp was
    initialized to 0.  As that is not the case it is not safe to for the
    error handling to address shm_cprid and shm_lprid before they are
    initialized.
    
    Therefore move the cleanup of shm_cprid and shm_lprid from the no_file
    error cleanup path to the no_id error cleanup path.  Ensuring that an
    early error exit won't cause the oops above.
    
    Reported-by: kernel test robot <fengguang.wu@intel.com>
    Reviewed-by: Nagarathnam Muthusamy <nagarathnam.muthusamy@oracle.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/ipc/shm.c b/ipc/shm.c
index 018db3d0e70e..35bdfe76d11b 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -646,12 +646,12 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	return error;
 
 no_id:
+	ipc_update_pid(&shp->shm_cprid, NULL);
+	ipc_update_pid(&shp->shm_lprid, NULL);
 	if (is_file_hugepages(file) && shp->mlock_user)
 		user_shm_unlock(size, shp->mlock_user);
 	fput(file);
 no_file:
-	ipc_update_pid(&shp->shm_cprid, NULL);
-	ipc_update_pid(&shp->shm_lprid, NULL);
 	call_rcu(&shp->shm_perm.rcu, shm_rcu_free);
 	return error;
 }

commit 50ab44b1c5d1b13305ce8acb74c8e50e0dcbaedc
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Mar 23 23:41:55 2018 -0500

    ipc: Directly call the security hook in ipc_ops.associate
    
    After the last round of cleanups the shm, sem, and msg associate
    operations just became trivial wrappers around the appropriate security
    method.  Simplify things further by just calling the security method
    directly.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/ipc/shm.c b/ipc/shm.c
index 932b7e411c6c..018db3d0e70e 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -656,14 +656,6 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	return error;
 }
 
-/*
- * Called with shm_ids.rwsem and ipcp locked.
- */
-static inline int shm_security(struct kern_ipc_perm *ipcp, int shmflg)
-{
-	return security_shm_associate(ipcp, shmflg);
-}
-
 /*
  * Called with shm_ids.rwsem and ipcp locked.
  */
@@ -684,7 +676,7 @@ SYSCALL_DEFINE3(shmget, key_t, key, size_t, size, int, shmflg)
 	struct ipc_namespace *ns;
 	static const struct ipc_ops shm_ops = {
 		.getnew = newseg,
-		.associate = shm_security,
+		.associate = security_shm_associate,
 		.more_checks = shm_more_checks,
 	};
 	struct ipc_params shm_params;

commit 98f929b1bd4d0b7c7a77d0d9776d1b924db2e454
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Mar 23 00:29:57 2018 -0500

    ipc/shm: Fix shmctl(..., IPC_STAT, ...) between pid namespaces.
    
    Today shm_cpid and shm_lpid are remembered in the pid namespace of the
    creator and the processes that last touched a sysvipc shared memory
    segment.   If you have processes in multiple pid namespaces that
    is just wrong, and I don't know how this has been over-looked for
    so long.
    
    As only creation and shared memory attach and shared memory detach
    update the pids I do not expect there to be a repeat of the issues
    when struct pid was attached to each af_unix skb, which in some
    notable cases cut the performance in half.  The problem was threads of
    the same process updating same struct pid from different cpus causing
    the cache line to be highly contended and bounce between cpus.
    
    As creation, attach, and detach are expected to be rare operations for
    sysvipc shared memory segments I do not expect that kind of cache line
    ping pong to cause probems.  In addition because the pid is at a fixed
    location in the structure instead of being dynamic on a skb, the
    reference count of the pid does not need to be updated on each
    operation if the pid is the same.  This ability to simply skip the pid
    reference count changes if the pid is unchanging further reduces the
    likelihood of the a cache line holding a pid reference count
    ping-ponging between cpus.
    
    Fixes: b488893a390e ("pid namespaces: changes to show virtual ids to user")
    Reviewed-by: Nagarathnam Muthusamy <nagarathnam.muthusamy@oracle.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/ipc/shm.c b/ipc/shm.c
index 0565669ebe5c..932b7e411c6c 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -57,8 +57,8 @@ struct shmid_kernel /* private to the kernel */
 	time64_t		shm_atim;
 	time64_t		shm_dtim;
 	time64_t		shm_ctim;
-	pid_t			shm_cprid;
-	pid_t			shm_lprid;
+	struct pid		*shm_cprid;
+	struct pid		*shm_lprid;
 	struct user_struct	*mlock_user;
 
 	/* The task created the shm object.  NULL if the task is dead. */
@@ -226,7 +226,7 @@ static int __shm_open(struct vm_area_struct *vma)
 		return PTR_ERR(shp);
 
 	shp->shm_atim = ktime_get_real_seconds();
-	shp->shm_lprid = task_tgid_vnr(current);
+	ipc_update_pid(&shp->shm_lprid, task_tgid(current));
 	shp->shm_nattch++;
 	shm_unlock(shp);
 	return 0;
@@ -267,6 +267,8 @@ static void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)
 		user_shm_unlock(i_size_read(file_inode(shm_file)),
 				shp->mlock_user);
 	fput(shm_file);
+	ipc_update_pid(&shp->shm_cprid, NULL);
+	ipc_update_pid(&shp->shm_lprid, NULL);
 	ipc_rcu_putref(&shp->shm_perm, shm_rcu_free);
 }
 
@@ -311,7 +313,7 @@ static void shm_close(struct vm_area_struct *vma)
 	if (WARN_ON_ONCE(IS_ERR(shp)))
 		goto done; /* no-op */
 
-	shp->shm_lprid = task_tgid_vnr(current);
+	ipc_update_pid(&shp->shm_lprid, task_tgid(current));
 	shp->shm_dtim = ktime_get_real_seconds();
 	shp->shm_nattch--;
 	if (shm_may_destroy(ns, shp))
@@ -614,8 +616,8 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	if (IS_ERR(file))
 		goto no_file;
 
-	shp->shm_cprid = task_tgid_vnr(current);
-	shp->shm_lprid = 0;
+	shp->shm_cprid = get_pid(task_tgid(current));
+	shp->shm_lprid = NULL;
 	shp->shm_atim = shp->shm_dtim = 0;
 	shp->shm_ctim = ktime_get_real_seconds();
 	shp->shm_segsz = size;
@@ -648,6 +650,8 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 		user_shm_unlock(size, shp->mlock_user);
 	fput(file);
 no_file:
+	ipc_update_pid(&shp->shm_cprid, NULL);
+	ipc_update_pid(&shp->shm_lprid, NULL);
 	call_rcu(&shp->shm_perm.rcu, shm_rcu_free);
 	return error;
 }
@@ -970,8 +974,8 @@ static int shmctl_stat(struct ipc_namespace *ns, int shmid,
 	tbuf->shm_atime	= shp->shm_atim;
 	tbuf->shm_dtime	= shp->shm_dtim;
 	tbuf->shm_ctime	= shp->shm_ctim;
-	tbuf->shm_cpid	= shp->shm_cprid;
-	tbuf->shm_lpid	= shp->shm_lprid;
+	tbuf->shm_cpid	= pid_vnr(shp->shm_cprid);
+	tbuf->shm_lpid	= pid_vnr(shp->shm_lprid);
 	tbuf->shm_nattch = shp->shm_nattch;
 
 	ipc_unlock_object(&shp->shm_perm);
@@ -1605,6 +1609,7 @@ SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 #ifdef CONFIG_PROC_FS
 static int sysvipc_shm_proc_show(struct seq_file *s, void *it)
 {
+	struct pid_namespace *pid_ns = ipc_seq_pid_ns(s);
 	struct user_namespace *user_ns = seq_user_ns(s);
 	struct kern_ipc_perm *ipcp = it;
 	struct shmid_kernel *shp;
@@ -1627,8 +1632,8 @@ static int sysvipc_shm_proc_show(struct seq_file *s, void *it)
 		   shp->shm_perm.id,
 		   shp->shm_perm.mode,
 		   shp->shm_segsz,
-		   shp->shm_cprid,
-		   shp->shm_lprid,
+		   pid_nr_ns(shp->shm_cprid, pid_ns),
+		   pid_nr_ns(shp->shm_lprid, pid_ns),
 		   shp->shm_nattch,
 		   from_kuid_munged(user_ns, shp->shm_perm.uid),
 		   from_kgid_munged(user_ns, shp->shm_perm.gid),

commit a2e102cd3cdd8b7a14e08716510707b15802073f
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Mar 22 21:34:44 2018 -0500

    shm: Move struct shmid_kernel into ipc/shm.c
    
    All of the users are now in ipc/shm.c so make the definition local to
    that file to make code maintenance easier.  AKA to prevent rebuilding
    the entire kernel when struct shmid_kernel changes.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/ipc/shm.c b/ipc/shm.c
index 387a786e7be1..0565669ebe5c 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -48,6 +48,28 @@
 
 #include "util.h"
 
+struct shmid_kernel /* private to the kernel */
+{
+	struct kern_ipc_perm	shm_perm;
+	struct file		*shm_file;
+	unsigned long		shm_nattch;
+	unsigned long		shm_segsz;
+	time64_t		shm_atim;
+	time64_t		shm_dtim;
+	time64_t		shm_ctim;
+	pid_t			shm_cprid;
+	pid_t			shm_lprid;
+	struct user_struct	*mlock_user;
+
+	/* The task created the shm object.  NULL if the task is dead. */
+	struct task_struct	*shm_creator;
+	struct list_head	shm_clist;	/* list by creator */
+} __randomize_layout;
+
+/* shm_mode upper byte flags */
+#define SHM_DEST	01000	/* segment will be destroyed on last detach */
+#define SHM_LOCKED	02000   /* segment will not be swapped */
+
 struct shm_file_data {
 	int id;
 	struct ipc_namespace *ns;

commit 7191adff2a5566efb139c79ea03eda3d0520d44a
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu Mar 22 21:08:27 2018 -0500

    shm/security: Pass kern_ipc_perm not shmid_kernel into the shm security hooks
    
    All of the implementations of security hooks that take shmid_kernel only
    access shm_perm the struct kern_ipc_perm member.  This means the
    dependencies of the shm security hooks can be simplified by passing
    the kern_ipc_perm member of shmid_kernel..
    
    Making this change will allow struct shmid_kernel to become private to ipc/shm.c.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/ipc/shm.c b/ipc/shm.c
index 4643865e9171..387a786e7be1 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -181,7 +181,7 @@ static void shm_rcu_free(struct rcu_head *head)
 							rcu);
 	struct shmid_kernel *shp = container_of(ptr, struct shmid_kernel,
 							shm_perm);
-	security_shm_free(shp);
+	security_shm_free(&shp->shm_perm);
 	kvfree(shp);
 }
 
@@ -554,7 +554,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	shp->mlock_user = NULL;
 
 	shp->shm_perm.security = NULL;
-	error = security_shm_alloc(shp);
+	error = security_shm_alloc(&shp->shm_perm);
 	if (error) {
 		kvfree(shp);
 		return error;
@@ -635,10 +635,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
  */
 static inline int shm_security(struct kern_ipc_perm *ipcp, int shmflg)
 {
-	struct shmid_kernel *shp;
-
-	shp = container_of(ipcp, struct shmid_kernel, shm_perm);
-	return security_shm_associate(shp, shmflg);
+	return security_shm_associate(ipcp, shmflg);
 }
 
 /*
@@ -835,7 +832,7 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 
 	shp = container_of(ipcp, struct shmid_kernel, shm_perm);
 
-	err = security_shm_shmctl(shp, cmd);
+	err = security_shm_shmctl(&shp->shm_perm, cmd);
 	if (err)
 		goto out_unlock1;
 
@@ -934,7 +931,7 @@ static int shmctl_stat(struct ipc_namespace *ns, int shmid,
 	if (ipcperms(ns, &shp->shm_perm, S_IRUGO))
 		goto out_unlock;
 
-	err = security_shm_shmctl(shp, cmd);
+	err = security_shm_shmctl(&shp->shm_perm, cmd);
 	if (err)
 		goto out_unlock;
 
@@ -978,7 +975,7 @@ static int shmctl_do_lock(struct ipc_namespace *ns, int shmid, int cmd)
 	}
 
 	audit_ipc_obj(&(shp->shm_perm));
-	err = security_shm_shmctl(shp, cmd);
+	err = security_shm_shmctl(&shp->shm_perm, cmd);
 	if (err)
 		goto out_unlock1;
 
@@ -1348,7 +1345,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg,
 	if (ipcperms(ns, &shp->shm_perm, acc_mode))
 		goto out_unlock;
 
-	err = security_shm_shmat(shp, shmaddr, shmflg);
+	err = security_shm_shmat(&shp->shm_perm, shmaddr, shmflg);
 	if (err)
 		goto out_unlock;
 

commit 87ad4b0d853e8a65d6002f4e7bd3dce4ae3a52da
Author: Philippe Mikoyan <philippe.mikoyan@skat.systems>
Date:   Tue Feb 6 15:40:49 2018 -0800

    ipc: fix ipc data structures inconsistency
    
    As described in the title, this patch fixes <ipc>id_ds inconsistency when
    <ipc>ctl_stat executes concurrently with some ds-changing function, e.g.
    shmat, msgsnd or whatever.
    
    For instance, if shmctl(IPC_STAT) is running concurrently
    with shmat, following data structure can be returned:
    {... shm_lpid = 0, shm_nattch = 1, ...}
    
    Link: http://lkml.kernel.org/r/20171202153456.6514-1-philippe.mikoyan@skat.systems
    Signed-off-by: Philippe Mikoyan <philippe.mikoyan@skat.systems>
    Reviewed-by: Davidlohr Bueso <dbueso@suse.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 7acda23430aa..4643865e9171 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -909,9 +909,11 @@ static int shmctl_stat(struct ipc_namespace *ns, int shmid,
 			int cmd, struct shmid64_ds *tbuf)
 {
 	struct shmid_kernel *shp;
-	int result;
+	int id = 0;
 	int err;
 
+	memset(tbuf, 0, sizeof(*tbuf));
+
 	rcu_read_lock();
 	if (cmd == SHM_STAT) {
 		shp = shm_obtain_object(ns, shmid);
@@ -919,14 +921,13 @@ static int shmctl_stat(struct ipc_namespace *ns, int shmid,
 			err = PTR_ERR(shp);
 			goto out_unlock;
 		}
-		result = shp->shm_perm.id;
+		id = shp->shm_perm.id;
 	} else {
 		shp = shm_obtain_object_check(ns, shmid);
 		if (IS_ERR(shp)) {
 			err = PTR_ERR(shp);
 			goto out_unlock;
 		}
-		result = 0;
 	}
 
 	err = -EACCES;
@@ -937,7 +938,14 @@ static int shmctl_stat(struct ipc_namespace *ns, int shmid,
 	if (err)
 		goto out_unlock;
 
-	memset(tbuf, 0, sizeof(*tbuf));
+	ipc_lock_object(&shp->shm_perm);
+
+	if (!ipc_valid_object(&shp->shm_perm)) {
+		ipc_unlock_object(&shp->shm_perm);
+		err = -EIDRM;
+		goto out_unlock;
+	}
+
 	kernel_to_ipc64_perm(&shp->shm_perm, &tbuf->shm_perm);
 	tbuf->shm_segsz	= shp->shm_segsz;
 	tbuf->shm_atime	= shp->shm_atim;
@@ -946,8 +954,10 @@ static int shmctl_stat(struct ipc_namespace *ns, int shmid,
 	tbuf->shm_cpid	= shp->shm_cprid;
 	tbuf->shm_lpid	= shp->shm_lprid;
 	tbuf->shm_nattch = shp->shm_nattch;
+
+	ipc_unlock_object(&shp->shm_perm);
 	rcu_read_unlock();
-	return result;
+	return id;
 
 out_unlock:
 	rcu_read_unlock();

commit fa7f578076a8814caa5371e9f4949e408140766d
Merge: 2dcd9c71c1ff d1b069f5febc
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 17 16:56:17 2017 -0800

    Merge branch 'akpm' (patches from Andrew)
    
    Merge more updates from Andrew Morton:
    
     - a bit more MM
    
     - procfs updates
    
     - dynamic-debug fixes
    
     - lib/ updates
    
     - checkpatch
    
     - epoll
    
     - nilfs2
    
     - signals
    
     - rapidio
    
     - PID management cleanup and optimization
    
     - kcov updates
    
     - sysvipc updates
    
     - quite a few misc things all over the place
    
    * emailed patches from Andrew Morton <akpm@linux-foundation.org>: (94 commits)
      EXPERT Kconfig menu: fix broken EXPERT menu
      include/asm-generic/topology.h: remove unused parent_node() macro
      arch/tile/include/asm/topology.h: remove unused parent_node() macro
      arch/sparc/include/asm/topology_64.h: remove unused parent_node() macro
      arch/sh/include/asm/topology.h: remove unused parent_node() macro
      arch/ia64/include/asm/topology.h: remove unused parent_node() macro
      drivers/pcmcia/sa1111_badge4.c: avoid unused function warning
      mm: add infrastructure for get_user_pages_fast() benchmarking
      sysvipc: make get_maxid O(1) again
      sysvipc: properly name ipc_addid() limit parameter
      sysvipc: duplicate lock comments wrt ipc_addid()
      sysvipc: unteach ids->next_id for !CHECKPOINT_RESTORE
      initramfs: use time64_t timestamps
      drivers/watchdog: make use of devm_register_reboot_notifier()
      kernel/reboot.c: add devm_register_reboot_notifier()
      kcov: update documentation
      Makefile: support flag -fsanitizer-coverage=trace-cmp
      kcov: support comparison operands collection
      kcov: remove pointless current != NULL check
      kernel/panic.c: add TAINT_AUX
      ...

commit 39c96a1b96a5991b1c9e79b85a8d74ef93b36026
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Fri Nov 17 15:31:11 2017 -0800

    sysvipc: duplicate lock comments wrt ipc_addid()
    
    The comment in msgqueues when using ipc_addid() is quite useful imo.
    Duplicate it for shm and semaphores.
    
    Link: http://lkml.kernel.org/r/20170831172049.14576-3-dave@stgolabs.net
    Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index bd652755d32c..378c929194ce 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -601,6 +601,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	shp->shm_file = file;
 	shp->shm_creator = current;
 
+	/* ipc_addid() locks shp upon success. */
 	error = ipc_addid(&shm_ids(ns), &shp->shm_perm, ns->shm_ctlmni);
 	if (error < 0)
 		goto no_id;

commit ca5b857cb0f42986520abd9dbb0c2508067342b2
Merge: a0e136e5da98 c02b1a9b41c2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 17 12:54:01 2017 -0800

    Merge branch 'work.misc' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull misc vfs updates from Al Viro:
     "Assorted stuff, really no common topic here"
    
    * 'work.misc' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      vfs: grab the lock instead of blocking in __fd_install during resizing
      vfs: stop clearing close on exec when closing a fd
      include/linux/fs.h: fix comment about struct address_space
      fs: make fiemap work from compat_ioctl
      coda: fix 'kernel memory exposure attempt' in fsync
      pstore: remove unneeded unlikely()
      vfs: remove unneeded unlikely()
      stubs for mount_bdev() and kill_block_super() in !CONFIG_BLOCK case
      make vfs_ustat() static
      do_handle_open() should be static
      elf_fdpic: fix unused variable warning
      fold destroy_super() into __put_super()
      new helper: destroy_unused_super()
      fix address space warnings in ipc/
      acct.h: get rid of detritus

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index badac463e2c8..bd652755d32c 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * linux/ipc/shm.c
  * Copyright (C) 1992, 1993 Krishna Balasubramanian

commit 6aa211e8ce6916d8a0df88b4fbc790e9c78f5d9d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Sep 25 18:37:28 2017 -0700

    fix address space warnings in ipc/
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 1b3adfe3c60e..41706416a3c4 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1193,10 +1193,10 @@ static int copy_compat_shmid_from_user(struct shmid64_ds *out, void __user *buf,
 {
 	memset(out, 0, sizeof(*out));
 	if (version == IPC_64) {
-		struct compat_shmid64_ds *p = buf;
+		struct compat_shmid64_ds __user *p = buf;
 		return get_compat_ipc64_perm(&out->shm_perm, &p->shm_perm);
 	} else {
-		struct compat_shmid_ds *p = buf;
+		struct compat_shmid_ds __user *p = buf;
 		return get_compat_ipc_perm(&out->shm_perm, &p->shm_perm);
 	}
 }

commit b776e4b1a990045a7c70798f1f353c3160c26594
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Sep 25 20:38:45 2017 -0400

    fix a typo in put_compat_shm_info()
    
    "uip" misspelled as "up"; unfortunately, the latter happens to be
    a function and gcc is happy to convert it to void *...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 1e2b1692ba2c..badac463e2c8 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1154,7 +1154,7 @@ static int put_compat_shm_info(struct shm_info *ip,
 	info.shm_swp = ip->shm_swp;
 	info.swap_attempts = ip->swap_attempts;
 	info.swap_successes = ip->swap_successes;
-	return copy_to_user(up, &info, sizeof(info));
+	return copy_to_user(uip, &info, sizeof(info));
 }
 
 static int copy_compat_shmid_to_user(void __user *buf, struct shmid64_ds *in,

commit 58aff0af757356065f33290d96a9cd46dfbcae88
Author: Will Deacon <will.deacon@arm.com>
Date:   Mon Sep 18 17:47:38 2017 +0100

    ipc/shm: Fix order of parameters when calling copy_compat_shmid_to_user
    
    Commit 553f770ef71b ("ipc: move compat shmctl to native") moved the
    compat IPC syscall handling into ipc/shm.c and refactored the struct
    accessors in the process. Unfortunately, the call to
    copy_compat_shmid_to_user when handling a compat {IPC,SHM}_STAT command
    gets the arguments the wrong way round, passing a kernel stack address
    as the user buffer (destination) and the user buffer as the kernel stack
    address (source).
    
    This patch fixes the parameter ordering so the buffers are accessed
    correctly.
    
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 1b3adfe3c60e..1e2b1692ba2c 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1237,7 +1237,7 @@ COMPAT_SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, void __user *, uptr)
 		err = shmctl_stat(ns, shmid, cmd, &sem64);
 		if (err < 0)
 			return err;
-		if (copy_compat_shmid_to_user(&sem64, uptr, version))
+		if (copy_compat_shmid_to_user(uptr, &sem64, version))
 			err = -EFAULT;
 		return err;
 

commit cc73fee0bae2d66594d1fa2df92bbd783aa98e04
Merge: e7cdb60fd28b aaed2dd8a313
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 14 17:37:26 2017 -0700

    Merge branch 'work.ipc' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull ipc compat cleanup and 64-bit time_t from Al Viro:
     "IPC copyin/copyout sanitizing, including 64bit time_t work from Deepa
      Dinamani"
    
    * 'work.ipc' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      utimes: Make utimes y2038 safe
      ipc: shm: Make shmid_kernel timestamps y2038 safe
      ipc: sem: Make sem_array timestamps y2038 safe
      ipc: msg: Make msg_queue timestamps y2038 safe
      ipc: mqueue: Replace timespec with timespec64
      ipc: Make sys_semtimedop() y2038 safe
      get rid of SYSVIPC_COMPAT on ia64
      semtimedop(): move compat to native
      shmat(2): move compat to native
      msgrcv(2), msgsnd(2): move compat to native
      ipc(2): move compat to native
      ipc: make use of compat ipc_perm helpers
      semctl(): move compat to native
      semctl(): separate all layout-dependent copyin/copyout
      msgctl(): move compat to native
      msgctl(): split the actual work from copyin/copyout
      ipc: move compat shmctl to native
      shmctl: split the work from copyin/copyout

commit 0cfb6aee70bddbef6ec796b255f588ce0e126766
Author: Guillaume Knispel <guillaume.knispel@supersonicimagine.com>
Date:   Fri Sep 8 16:17:55 2017 -0700

    ipc: optimize semget/shmget/msgget for lots of keys
    
    ipc_findkey() used to scan all objects to look for the wanted key.  This
    is slow when using a high number of keys.  This change adds an rhashtable
    of kern_ipc_perm objects in ipc_ids, so that one lookup cease to be O(n).
    
    This change gives a 865% improvement of benchmark reaim.jobs_per_min on a
    56 threads Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz with 256G memory [1]
    
    Other (more micro) benchmark results, by the author: On an i5 laptop, the
    following loop executed right after a reboot took, without and with this
    change:
    
        for (int i = 0, k=0x424242; i < KEYS; ++i)
            semget(k++, 1, IPC_CREAT | 0600);
    
                     total       total          max single  max single
       KEYS        without        with        call without   call with
    
          1            3.5         4.9   Âµs            3.5         4.9
         10            7.6         8.6   Âµs            3.7         4.7
         32           16.2        15.9   Âµs            4.3         5.3
        100           72.9        41.8   Âµs            3.7         4.7
       1000        5,630.0       502.0   Âµs             *           *
      10000    1,340,000.0     7,240.0   Âµs             *           *
      31900   17,600,000.0    22,200.0   Âµs             *           *
    
     *: unreliable measure: high variance
    
    The duration for a lookup-only usage was obtained by the same loop once
    the keys are present:
    
                     total       total          max single  max single
       KEYS        without        with        call without   call with
    
          1            2.1         2.5   Âµs            2.1         2.5
         10            4.5         4.8   Âµs            2.2         2.3
         32           13.0        10.8   Âµs            2.3         2.8
        100           82.9        25.1   Âµs             *          2.3
       1000        5,780.0       217.0   Âµs             *           *
      10000    1,470,000.0     2,520.0   Âµs             *           *
      31900   17,400,000.0     7,810.0   Âµs             *           *
    
    Finally, executing each semget() in a new process gave, when still
    summing only the durations of these syscalls:
    
    creation:
                     total       total
       KEYS        without        with
    
          1            3.7         5.0   Âµs
         10           32.9        36.7   Âµs
         32          125.0       109.0   Âµs
        100          523.0       353.0   Âµs
       1000       20,300.0     3,280.0   Âµs
      10000    2,470,000.0    46,700.0   Âµs
      31900   27,800,000.0   219,000.0   Âµs
    
    lookup-only:
                     total       total
       KEYS        without        with
    
          1            2.5         2.7   Âµs
         10           25.4        24.4   Âµs
         32          106.0        72.6   Âµs
        100          591.0       352.0   Âµs
       1000       22,400.0     2,250.0   Âµs
      10000    2,510,000.0    25,700.0   Âµs
      31900   28,200,000.0   115,000.0   Âµs
    
    [1] http://lkml.kernel.org/r/20170814060507.GE23258@yexl-desktop
    
    Link: http://lkml.kernel.org/r/20170815194954.ck32ta2z35yuzpwp@debix
    Signed-off-by: Guillaume Knispel <guillaume.knispel@supersonicimagine.com>
    Reviewed-by: Marc Pardo <marc.pardo@supersonicimagine.com>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: Alexey Dobriyan <adobriyan@gmail.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: "Peter Zijlstra (Intel)" <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Cc: Serge Hallyn <serge@hallyn.com>
    Cc: Andrey Vagin <avagin@openvz.org>
    Cc: Guillaume Knispel <guillaume.knispel@supersonicimagine.com>
    Cc: Marc Pardo <marc.pardo@supersonicimagine.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 8828b4c3a190..8fc97beb5234 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -72,14 +72,14 @@ static void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp);
 static int sysvipc_shm_proc_show(struct seq_file *s, void *it);
 #endif
 
-void shm_init_ns(struct ipc_namespace *ns)
+int shm_init_ns(struct ipc_namespace *ns)
 {
 	ns->shm_ctlmax = SHMMAX;
 	ns->shm_ctlall = SHMALL;
 	ns->shm_ctlmni = SHMMNI;
 	ns->shm_rmid_forced = 0;
 	ns->shm_tot = 0;
-	ipc_init_ids(&shm_ids(ns));
+	return ipc_init_ids(&shm_ids(ns));
 }
 
 /*
@@ -95,7 +95,7 @@ static void do_shm_rmid(struct ipc_namespace *ns, struct kern_ipc_perm *ipcp)
 	if (shp->shm_nattch) {
 		shp->shm_perm.mode |= SHM_DEST;
 		/* Do not find it any more */
-		shp->shm_perm.key = IPC_PRIVATE;
+		ipc_set_key_private(&shm_ids(ns), &shp->shm_perm);
 		shm_unlock(shp);
 	} else
 		shm_destroy(ns, shp);
@@ -106,13 +106,15 @@ void shm_exit_ns(struct ipc_namespace *ns)
 {
 	free_ipcs(ns, &shm_ids(ns), do_shm_rmid);
 	idr_destroy(&ns->ids[IPC_SHM_IDS].ipcs_idr);
+	rhashtable_destroy(&ns->ids[IPC_SHM_IDS].key_ht);
 }
 #endif
 
 static int __init ipc_ns_init(void)
 {
-	shm_init_ns(&init_ipc_ns);
-	return 0;
+	const int err = shm_init_ns(&init_ipc_ns);
+	WARN(err, "ipc: sysv shm_init_ns failed: %d\n", err);
+	return err;
 }
 
 pure_initcall(ipc_ns_init);

commit 7ff2819e8dd5b528887dfbe4ff395f5d2142edff
Author: Deepa Dinamani <deepa.kernel@gmail.com>
Date:   Wed Aug 2 19:51:14 2017 -0700

    ipc: shm: Make shmid_kernel timestamps y2038 safe
    
    time_t is not y2038 safe. Replace all uses of
    time_t by y2038 safe time64_t.
    
    Similarly, replace the calls to get_seconds() with
    y2038 safe ktime_get_real_seconds().
    Note that this preserves fast access on 64 bit systems,
    but 32 bit systems need sequence counters.
    
    The syscall interfaces themselves are not changed as part of
    the patch. They will be part of a different series.
    
    Signed-off-by: Deepa Dinamani <deepa.kernel@gmail.com>
    Reviewed-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 342024de3b9d..f3d6408d6de1 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -200,7 +200,7 @@ static int __shm_open(struct vm_area_struct *vma)
 	if (IS_ERR(shp))
 		return PTR_ERR(shp);
 
-	shp->shm_atim = get_seconds();
+	shp->shm_atim = ktime_get_real_seconds();
 	shp->shm_lprid = task_tgid_vnr(current);
 	shp->shm_nattch++;
 	shm_unlock(shp);
@@ -287,7 +287,7 @@ static void shm_close(struct vm_area_struct *vma)
 		goto done; /* no-op */
 
 	shp->shm_lprid = task_tgid_vnr(current);
-	shp->shm_dtim = get_seconds();
+	shp->shm_dtim = ktime_get_real_seconds();
 	shp->shm_nattch--;
 	if (shm_may_destroy(ns, shp))
 		shm_destroy(ns, shp);
@@ -592,7 +592,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	shp->shm_cprid = task_tgid_vnr(current);
 	shp->shm_lprid = 0;
 	shp->shm_atim = shp->shm_dtim = 0;
-	shp->shm_ctim = get_seconds();
+	shp->shm_ctim = ktime_get_real_seconds();
 	shp->shm_segsz = size;
 	shp->shm_nattch = 0;
 	shp->shm_file = file;
@@ -846,7 +846,7 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 		err = ipc_update_perm(&shmid64->shm_perm, ipcp);
 		if (err)
 			goto out_unlock0;
-		shp->shm_ctim = get_seconds();
+		shp->shm_ctim = ktime_get_real_seconds();
 		break;
 	default:
 		err = -EINVAL;
@@ -1586,7 +1586,7 @@ static int sysvipc_shm_proc_show(struct seq_file *s, void *it)
 
 	seq_printf(s,
 		   "%10d %10d  %4o " SIZE_SPEC " %5u %5u  "
-		   "%5lu %5u %5u %5u %5u %10lu %10lu %10lu "
+		   "%5lu %5u %5u %5u %5u %10llu %10llu %10llu "
 		   SIZE_SPEC " " SIZE_SPEC "\n",
 		   shp->shm_perm.key,
 		   shp->shm_perm.id,

commit ade9f91b32b964e83d294f4973d50083b08ef6fc
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Aug 2 13:32:21 2017 -0700

    ipc: add missing container_of()s for randstruct
    
    When building with the randstruct gcc plugin, the layout of the IPC
    structs will be randomized, which requires any sub-structure accesses to
    use container_of().  The proc display handlers were missing the needed
    container_of()s since the iterator is passing in the top-level struct
    kern_ipc_perm.
    
    This would lead to crashes when running the "lsipc" program after the
    system had IPC registered (e.g. after starting up Gnome):
    
      general protection fault: 0000 [#1] PREEMPT SMP
      ...
      RIP: 0010:shm_add_rss_swap.isra.1+0x13/0xa0
      ...
      Call Trace:
        sysvipc_shm_proc_show+0x5e/0x150
        sysvipc_proc_show+0x1a/0x30
        seq_read+0x2e9/0x3f0
      ...
    
    Link: http://lkml.kernel.org/r/20170730205950.GA55841@beast
    Fixes: 3859a271a003 ("randstruct: Mark various structs for randomization")
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Reported-by: Dominik Brodowski <linux@dominikbrodowski.net>
    Acked-by: Davidlohr Bueso <dave@stgolabs.net>
    Acked-by: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 28a444861a8f..8828b4c3a190 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1380,9 +1380,11 @@ SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 static int sysvipc_shm_proc_show(struct seq_file *s, void *it)
 {
 	struct user_namespace *user_ns = seq_user_ns(s);
-	struct shmid_kernel *shp = it;
+	struct kern_ipc_perm *ipcp = it;
+	struct shmid_kernel *shp;
 	unsigned long rss = 0, swp = 0;
 
+	shp = container_of(ipcp, struct shmid_kernel, shm_perm);
 	shm_add_rss_swap(shp, &rss, &swp);
 
 #if BITS_PER_LONG <= 32

commit a78ee9ed2f828e1960f366bf7ab204e7f19924c7
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Jul 9 10:38:28 2017 -0400

    shmat(2): move compat to native
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 2e31545035a6..342024de3b9d 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1439,6 +1439,25 @@ SYSCALL_DEFINE3(shmat, int, shmid, char __user *, shmaddr, int, shmflg)
 	return (long)ret;
 }
 
+#ifdef CONFIG_COMPAT
+
+#ifndef COMPAT_SHMLBA
+#define COMPAT_SHMLBA	SHMLBA
+#endif
+
+COMPAT_SYSCALL_DEFINE3(shmat, int, shmid, compat_uptr_t, shmaddr, int, shmflg)
+{
+	unsigned long ret;
+	long err;
+
+	err = do_shmat(shmid, compat_ptr(shmaddr), shmflg, &ret, COMPAT_SHMLBA);
+	if (err)
+		return err;
+	force_successful_syscall_return();
+	return (long)ret;
+}
+#endif
+
 /*
  * detach and kill segment if marked destroyed.
  * The work is done in shm_close.

commit 28327fae62b011216026b66299882c53b95b4500
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Jul 9 10:10:32 2017 -0400

    ipc: make use of compat ipc_perm helpers
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 87334ee3acb3..2e31545035a6 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1161,13 +1161,7 @@ static int copy_compat_shmid_to_user(void __user *buf, struct shmid64_ds *in,
 	if (version == IPC_64) {
 		struct compat_shmid64_ds v;
 		memset(&v, 0, sizeof(v));
-		v.shm_perm.key = in->shm_perm.key;
-		v.shm_perm.uid = in->shm_perm.uid;
-		v.shm_perm.gid = in->shm_perm.gid;
-		v.shm_perm.cuid = in->shm_perm.cuid;
-		v.shm_perm.cgid = in->shm_perm.cgid;
-		v.shm_perm.mode = in->shm_perm.mode;
-		v.shm_perm.seq = in->shm_perm.seq;
+		to_compat_ipc64_perm(&v.shm_perm, &in->shm_perm);
 		v.shm_atime = in->shm_atime;
 		v.shm_dtime = in->shm_dtime;
 		v.shm_ctime = in->shm_ctime;
@@ -1179,13 +1173,8 @@ static int copy_compat_shmid_to_user(void __user *buf, struct shmid64_ds *in,
 	} else {
 		struct compat_shmid_ds v;
 		memset(&v, 0, sizeof(v));
+		to_compat_ipc_perm(&v.shm_perm, &in->shm_perm);
 		v.shm_perm.key = in->shm_perm.key;
-		SET_UID(v.shm_perm.uid, in->shm_perm.uid);
-		SET_GID(v.shm_perm.gid, in->shm_perm.gid);
-		SET_UID(v.shm_perm.cuid, in->shm_perm.cuid);
-		SET_GID(v.shm_perm.cgid, in->shm_perm.cgid);
-		v.shm_perm.mode = in->shm_perm.mode;
-		v.shm_perm.seq = in->shm_perm.seq;
 		v.shm_atime = in->shm_atime;
 		v.shm_dtime = in->shm_dtime;
 		v.shm_ctime = in->shm_ctime;
@@ -1203,22 +1192,11 @@ static int copy_compat_shmid_from_user(struct shmid64_ds *out, void __user *buf,
 	memset(out, 0, sizeof(*out));
 	if (version == IPC_64) {
 		struct compat_shmid64_ds *p = buf;
-		struct compat_ipc64_perm v;
-		if (copy_from_user(&v, &p->shm_perm, sizeof(v)))
-			return -EFAULT;
-		out->shm_perm.uid = v.uid;
-		out->shm_perm.gid = v.gid;
-		out->shm_perm.mode = v.mode;
+		return get_compat_ipc64_perm(&out->shm_perm, &p->shm_perm);
 	} else {
 		struct compat_shmid_ds *p = buf;
-		struct compat_ipc_perm v;
-		if (copy_from_user(&v, &p->shm_perm, sizeof(v)))
-			return -EFAULT;
-		out->shm_perm.uid = v.uid;
-		out->shm_perm.gid = v.gid;
-		out->shm_perm.mode = v.mode;
+		return get_compat_ipc_perm(&out->shm_perm, &p->shm_perm);
 	}
-	return 0;
 }
 
 COMPAT_SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, void __user *, uptr)

commit 553f770ef71b27ee053bd241bef0998a15f43467
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Jul 8 22:52:47 2017 -0400

    ipc: move compat shmctl to native
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index b4073c08d0e8..87334ee3acb3 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1030,7 +1030,7 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 {
 	int err, version;
 	struct ipc_namespace *ns;
-	struct shmid64_ds tbuf;
+	struct shmid64_ds sem64;
 
 	if (cmd < 0 || shmid < 0)
 		return -EINVAL;
@@ -1059,18 +1059,19 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 	}
 	case SHM_STAT:
 	case IPC_STAT: {
-		err = shmctl_stat(ns, shmid, cmd, &tbuf);
+		err = shmctl_stat(ns, shmid, cmd, &sem64);
 		if (err < 0)
 			return err;
-		if (copy_shmid_to_user(buf, &tbuf, version))
+		if (copy_shmid_to_user(buf, &sem64, version))
 			err = -EFAULT;
 		return err;
 	}
 	case IPC_SET:
-		if (copy_shmid_from_user(&tbuf, buf, version))
+		if (copy_shmid_from_user(&sem64, buf, version))
 			return -EFAULT;
+		/* fallthru */
 	case IPC_RMID:
-		return shmctl_down(ns, shmid, cmd, &tbuf);
+		return shmctl_down(ns, shmid, cmd, &sem64);
 	case SHM_LOCK:
 	case SHM_UNLOCK:
 		return shmctl_do_lock(ns, shmid, cmd);
@@ -1079,6 +1080,204 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 	}
 }
 
+#ifdef CONFIG_COMPAT
+
+struct compat_shmid_ds {
+	struct compat_ipc_perm shm_perm;
+	int shm_segsz;
+	compat_time_t shm_atime;
+	compat_time_t shm_dtime;
+	compat_time_t shm_ctime;
+	compat_ipc_pid_t shm_cpid;
+	compat_ipc_pid_t shm_lpid;
+	unsigned short shm_nattch;
+	unsigned short shm_unused;
+	compat_uptr_t shm_unused2;
+	compat_uptr_t shm_unused3;
+};
+
+struct compat_shminfo64 {
+	compat_ulong_t shmmax;
+	compat_ulong_t shmmin;
+	compat_ulong_t shmmni;
+	compat_ulong_t shmseg;
+	compat_ulong_t shmall;
+	compat_ulong_t __unused1;
+	compat_ulong_t __unused2;
+	compat_ulong_t __unused3;
+	compat_ulong_t __unused4;
+};
+
+struct compat_shm_info {
+	compat_int_t used_ids;
+	compat_ulong_t shm_tot, shm_rss, shm_swp;
+	compat_ulong_t swap_attempts, swap_successes;
+};
+
+static int copy_compat_shminfo_to_user(void __user *buf, struct shminfo64 *in,
+					int version)
+{
+	if (in->shmmax > INT_MAX)
+		in->shmmax = INT_MAX;
+	if (version == IPC_64) {
+		struct compat_shminfo64 info;
+		memset(&info, 0, sizeof(info));
+		info.shmmax = in->shmmax;
+		info.shmmin = in->shmmin;
+		info.shmmni = in->shmmni;
+		info.shmseg = in->shmseg;
+		info.shmall = in->shmall;
+		return copy_to_user(buf, &info, sizeof(info));
+	} else {
+		struct shminfo info;
+		memset(&info, 0, sizeof(info));
+		info.shmmax = in->shmmax;
+		info.shmmin = in->shmmin;
+		info.shmmni = in->shmmni;
+		info.shmseg = in->shmseg;
+		info.shmall = in->shmall;
+		return copy_to_user(buf, &info, sizeof(info));
+	}
+}
+
+static int put_compat_shm_info(struct shm_info *ip,
+				struct compat_shm_info __user *uip)
+{
+	struct compat_shm_info info;
+
+	memset(&info, 0, sizeof(info));
+	info.used_ids = ip->used_ids;
+	info.shm_tot = ip->shm_tot;
+	info.shm_rss = ip->shm_rss;
+	info.shm_swp = ip->shm_swp;
+	info.swap_attempts = ip->swap_attempts;
+	info.swap_successes = ip->swap_successes;
+	return copy_to_user(up, &info, sizeof(info));
+}
+
+static int copy_compat_shmid_to_user(void __user *buf, struct shmid64_ds *in,
+					int version)
+{
+	if (version == IPC_64) {
+		struct compat_shmid64_ds v;
+		memset(&v, 0, sizeof(v));
+		v.shm_perm.key = in->shm_perm.key;
+		v.shm_perm.uid = in->shm_perm.uid;
+		v.shm_perm.gid = in->shm_perm.gid;
+		v.shm_perm.cuid = in->shm_perm.cuid;
+		v.shm_perm.cgid = in->shm_perm.cgid;
+		v.shm_perm.mode = in->shm_perm.mode;
+		v.shm_perm.seq = in->shm_perm.seq;
+		v.shm_atime = in->shm_atime;
+		v.shm_dtime = in->shm_dtime;
+		v.shm_ctime = in->shm_ctime;
+		v.shm_segsz = in->shm_segsz;
+		v.shm_nattch = in->shm_nattch;
+		v.shm_cpid = in->shm_cpid;
+		v.shm_lpid = in->shm_lpid;
+		return copy_to_user(buf, &v, sizeof(v));
+	} else {
+		struct compat_shmid_ds v;
+		memset(&v, 0, sizeof(v));
+		v.shm_perm.key = in->shm_perm.key;
+		SET_UID(v.shm_perm.uid, in->shm_perm.uid);
+		SET_GID(v.shm_perm.gid, in->shm_perm.gid);
+		SET_UID(v.shm_perm.cuid, in->shm_perm.cuid);
+		SET_GID(v.shm_perm.cgid, in->shm_perm.cgid);
+		v.shm_perm.mode = in->shm_perm.mode;
+		v.shm_perm.seq = in->shm_perm.seq;
+		v.shm_atime = in->shm_atime;
+		v.shm_dtime = in->shm_dtime;
+		v.shm_ctime = in->shm_ctime;
+		v.shm_segsz = in->shm_segsz;
+		v.shm_nattch = in->shm_nattch;
+		v.shm_cpid = in->shm_cpid;
+		v.shm_lpid = in->shm_lpid;
+		return copy_to_user(buf, &v, sizeof(v));
+	}
+}
+
+static int copy_compat_shmid_from_user(struct shmid64_ds *out, void __user *buf,
+					int version)
+{
+	memset(out, 0, sizeof(*out));
+	if (version == IPC_64) {
+		struct compat_shmid64_ds *p = buf;
+		struct compat_ipc64_perm v;
+		if (copy_from_user(&v, &p->shm_perm, sizeof(v)))
+			return -EFAULT;
+		out->shm_perm.uid = v.uid;
+		out->shm_perm.gid = v.gid;
+		out->shm_perm.mode = v.mode;
+	} else {
+		struct compat_shmid_ds *p = buf;
+		struct compat_ipc_perm v;
+		if (copy_from_user(&v, &p->shm_perm, sizeof(v)))
+			return -EFAULT;
+		out->shm_perm.uid = v.uid;
+		out->shm_perm.gid = v.gid;
+		out->shm_perm.mode = v.mode;
+	}
+	return 0;
+}
+
+COMPAT_SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, void __user *, uptr)
+{
+	struct ipc_namespace *ns;
+	struct shmid64_ds sem64;
+	int version = compat_ipc_parse_version(&cmd);
+	int err;
+
+	ns = current->nsproxy->ipc_ns;
+
+	if (cmd < 0 || shmid < 0)
+		return -EINVAL;
+
+	switch (cmd) {
+	case IPC_INFO: {
+		struct shminfo64 shminfo;
+		err = shmctl_ipc_info(ns, &shminfo);
+		if (err < 0)
+			return err;
+		if (copy_compat_shminfo_to_user(uptr, &shminfo, version))
+			err = -EFAULT;
+		return err;
+	}
+	case SHM_INFO: {
+		struct shm_info shm_info;
+		err = shmctl_shm_info(ns, &shm_info);
+		if (err < 0)
+			return err;
+		if (put_compat_shm_info(&shm_info, uptr))
+			err = -EFAULT;
+		return err;
+	}
+	case IPC_STAT:
+	case SHM_STAT:
+		err = shmctl_stat(ns, shmid, cmd, &sem64);
+		if (err < 0)
+			return err;
+		if (copy_compat_shmid_to_user(&sem64, uptr, version))
+			err = -EFAULT;
+		return err;
+
+	case IPC_SET:
+		if (copy_compat_shmid_from_user(&sem64, uptr, version))
+			return -EFAULT;
+		/* fallthru */
+	case IPC_RMID:
+		return shmctl_down(ns, shmid, cmd, &sem64);
+	case SHM_LOCK:
+	case SHM_UNLOCK:
+		return shmctl_do_lock(ns, shmid, cmd);
+		break;
+	default:
+		return -EINVAL;
+	}
+	return err;
+}
+#endif
+
 /*
  * Fix shmaddr, allocate descriptor, map shm, add attach descriptor to lists.
  *

commit 9ba720c18622b250c0abeccbcea1b03531a92277
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Jul 8 20:58:06 2017 -0400

    shmctl: split the work from copyin/copyout
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 28a444861a8f..b4073c08d0e8 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -813,23 +813,17 @@ static void shm_get_stat(struct ipc_namespace *ns, unsigned long *rss,
  * NOTE: no locks must be held, the rwsem is taken inside this function.
  */
 static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
-		       struct shmid_ds __user *buf, int version)
+		       struct shmid64_ds *shmid64)
 {
 	struct kern_ipc_perm *ipcp;
-	struct shmid64_ds shmid64;
 	struct shmid_kernel *shp;
 	int err;
 
-	if (cmd == IPC_SET) {
-		if (copy_shmid_from_user(&shmid64, buf, version))
-			return -EFAULT;
-	}
-
 	down_write(&shm_ids(ns).rwsem);
 	rcu_read_lock();
 
 	ipcp = ipcctl_pre_down_nolock(ns, &shm_ids(ns), shmid, cmd,
-				      &shmid64.shm_perm, 0);
+				      &shmid64->shm_perm, 0);
 	if (IS_ERR(ipcp)) {
 		err = PTR_ERR(ipcp);
 		goto out_unlock1;
@@ -849,7 +843,7 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 		goto out_up;
 	case IPC_SET:
 		ipc_lock_object(&shp->shm_perm);
-		err = ipc_update_perm(&shmid64.shm_perm, ipcp);
+		err = ipc_update_perm(&shmid64->shm_perm, ipcp);
 		if (err)
 			goto out_unlock0;
 		shp->shm_ctim = get_seconds();
@@ -868,212 +862,162 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 	return err;
 }
 
-static int shmctl_nolock(struct ipc_namespace *ns, int shmid,
-			 int cmd, int version, void __user *buf)
+static int shmctl_ipc_info(struct ipc_namespace *ns,
+			   struct shminfo64 *shminfo)
 {
-	int err;
-	struct shmid_kernel *shp;
-
-	/* preliminary security checks for *_INFO */
-	if (cmd == IPC_INFO || cmd == SHM_INFO) {
-		err = security_shm_shmctl(NULL, cmd);
-		if (err)
-			return err;
-	}
-
-	switch (cmd) {
-	case IPC_INFO:
-	{
-		struct shminfo64 shminfo;
-
-		memset(&shminfo, 0, sizeof(shminfo));
-		shminfo.shmmni = shminfo.shmseg = ns->shm_ctlmni;
-		shminfo.shmmax = ns->shm_ctlmax;
-		shminfo.shmall = ns->shm_ctlall;
-
-		shminfo.shmmin = SHMMIN;
-		if (copy_shminfo_to_user(buf, &shminfo, version))
-			return -EFAULT;
-
+	int err = security_shm_shmctl(NULL, IPC_INFO);
+	if (!err) {
+		memset(shminfo, 0, sizeof(*shminfo));
+		shminfo->shmmni = shminfo->shmseg = ns->shm_ctlmni;
+		shminfo->shmmax = ns->shm_ctlmax;
+		shminfo->shmall = ns->shm_ctlall;
+		shminfo->shmmin = SHMMIN;
 		down_read(&shm_ids(ns).rwsem);
 		err = ipc_get_maxid(&shm_ids(ns));
 		up_read(&shm_ids(ns).rwsem);
-
 		if (err < 0)
 			err = 0;
-		goto out;
 	}
-	case SHM_INFO:
-	{
-		struct shm_info shm_info;
+	return err;
+}
 
-		memset(&shm_info, 0, sizeof(shm_info));
+static int shmctl_shm_info(struct ipc_namespace *ns,
+			   struct shm_info *shm_info)
+{
+	int err = security_shm_shmctl(NULL, SHM_INFO);
+	if (!err) {
+		memset(shm_info, 0, sizeof(*shm_info));
 		down_read(&shm_ids(ns).rwsem);
-		shm_info.used_ids = shm_ids(ns).in_use;
-		shm_get_stat(ns, &shm_info.shm_rss, &shm_info.shm_swp);
-		shm_info.shm_tot = ns->shm_tot;
-		shm_info.swap_attempts = 0;
-		shm_info.swap_successes = 0;
+		shm_info->used_ids = shm_ids(ns).in_use;
+		shm_get_stat(ns, &shm_info->shm_rss, &shm_info->shm_swp);
+		shm_info->shm_tot = ns->shm_tot;
+		shm_info->swap_attempts = 0;
+		shm_info->swap_successes = 0;
 		err = ipc_get_maxid(&shm_ids(ns));
 		up_read(&shm_ids(ns).rwsem);
-		if (copy_to_user(buf, &shm_info, sizeof(shm_info))) {
-			err = -EFAULT;
-			goto out;
-		}
-
-		err = err < 0 ? 0 : err;
-		goto out;
+		if (err < 0)
+			err = 0;
 	}
-	case SHM_STAT:
-	case IPC_STAT:
-	{
-		struct shmid64_ds tbuf;
-		int result;
-
-		rcu_read_lock();
-		if (cmd == SHM_STAT) {
-			shp = shm_obtain_object(ns, shmid);
-			if (IS_ERR(shp)) {
-				err = PTR_ERR(shp);
-				goto out_unlock;
-			}
-			result = shp->shm_perm.id;
-		} else {
-			shp = shm_obtain_object_check(ns, shmid);
-			if (IS_ERR(shp)) {
-				err = PTR_ERR(shp);
-				goto out_unlock;
-			}
-			result = 0;
-		}
+	return err;
+}
 
-		err = -EACCES;
-		if (ipcperms(ns, &shp->shm_perm, S_IRUGO))
-			goto out_unlock;
+static int shmctl_stat(struct ipc_namespace *ns, int shmid,
+			int cmd, struct shmid64_ds *tbuf)
+{
+	struct shmid_kernel *shp;
+	int result;
+	int err;
 
-		err = security_shm_shmctl(shp, cmd);
-		if (err)
+	rcu_read_lock();
+	if (cmd == SHM_STAT) {
+		shp = shm_obtain_object(ns, shmid);
+		if (IS_ERR(shp)) {
+			err = PTR_ERR(shp);
 			goto out_unlock;
+		}
+		result = shp->shm_perm.id;
+	} else {
+		shp = shm_obtain_object_check(ns, shmid);
+		if (IS_ERR(shp)) {
+			err = PTR_ERR(shp);
+			goto out_unlock;
+		}
+		result = 0;
+	}
 
-		memset(&tbuf, 0, sizeof(tbuf));
-		kernel_to_ipc64_perm(&shp->shm_perm, &tbuf.shm_perm);
-		tbuf.shm_segsz	= shp->shm_segsz;
-		tbuf.shm_atime	= shp->shm_atim;
-		tbuf.shm_dtime	= shp->shm_dtim;
-		tbuf.shm_ctime	= shp->shm_ctim;
-		tbuf.shm_cpid	= shp->shm_cprid;
-		tbuf.shm_lpid	= shp->shm_lprid;
-		tbuf.shm_nattch	= shp->shm_nattch;
-		rcu_read_unlock();
+	err = -EACCES;
+	if (ipcperms(ns, &shp->shm_perm, S_IRUGO))
+		goto out_unlock;
 
-		if (copy_shmid_to_user(buf, &tbuf, version))
-			err = -EFAULT;
-		else
-			err = result;
-		goto out;
-	}
-	default:
-		return -EINVAL;
-	}
+	err = security_shm_shmctl(shp, cmd);
+	if (err)
+		goto out_unlock;
+
+	memset(tbuf, 0, sizeof(*tbuf));
+	kernel_to_ipc64_perm(&shp->shm_perm, &tbuf->shm_perm);
+	tbuf->shm_segsz	= shp->shm_segsz;
+	tbuf->shm_atime	= shp->shm_atim;
+	tbuf->shm_dtime	= shp->shm_dtim;
+	tbuf->shm_ctime	= shp->shm_ctim;
+	tbuf->shm_cpid	= shp->shm_cprid;
+	tbuf->shm_lpid	= shp->shm_lprid;
+	tbuf->shm_nattch = shp->shm_nattch;
+	rcu_read_unlock();
+	return result;
 
 out_unlock:
 	rcu_read_unlock();
-out:
 	return err;
 }
 
-SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
+static int shmctl_do_lock(struct ipc_namespace *ns, int shmid, int cmd)
 {
 	struct shmid_kernel *shp;
-	int err, version;
-	struct ipc_namespace *ns;
-
-	if (cmd < 0 || shmid < 0)
-		return -EINVAL;
+	struct file *shm_file;
+	int err;
 
-	version = ipc_parse_version(&cmd);
-	ns = current->nsproxy->ipc_ns;
+	rcu_read_lock();
+	shp = shm_obtain_object_check(ns, shmid);
+	if (IS_ERR(shp)) {
+		err = PTR_ERR(shp);
+		goto out_unlock1;
+	}
 
-	switch (cmd) {
-	case IPC_INFO:
-	case SHM_INFO:
-	case SHM_STAT:
-	case IPC_STAT:
-		return shmctl_nolock(ns, shmid, cmd, version, buf);
-	case IPC_RMID:
-	case IPC_SET:
-		return shmctl_down(ns, shmid, cmd, buf, version);
-	case SHM_LOCK:
-	case SHM_UNLOCK:
-	{
-		struct file *shm_file;
+	audit_ipc_obj(&(shp->shm_perm));
+	err = security_shm_shmctl(shp, cmd);
+	if (err)
+		goto out_unlock1;
 
-		rcu_read_lock();
-		shp = shm_obtain_object_check(ns, shmid);
-		if (IS_ERR(shp)) {
-			err = PTR_ERR(shp);
-			goto out_unlock1;
-		}
+	ipc_lock_object(&shp->shm_perm);
 
-		audit_ipc_obj(&(shp->shm_perm));
-		err = security_shm_shmctl(shp, cmd);
-		if (err)
-			goto out_unlock1;
+	/* check if shm_destroy() is tearing down shp */
+	if (!ipc_valid_object(&shp->shm_perm)) {
+		err = -EIDRM;
+		goto out_unlock0;
+	}
 
-		ipc_lock_object(&shp->shm_perm);
+	if (!ns_capable(ns->user_ns, CAP_IPC_LOCK)) {
+		kuid_t euid = current_euid();
 
-		/* check if shm_destroy() is tearing down shp */
-		if (!ipc_valid_object(&shp->shm_perm)) {
-			err = -EIDRM;
+		if (!uid_eq(euid, shp->shm_perm.uid) &&
+		    !uid_eq(euid, shp->shm_perm.cuid)) {
+			err = -EPERM;
 			goto out_unlock0;
 		}
-
-		if (!ns_capable(ns->user_ns, CAP_IPC_LOCK)) {
-			kuid_t euid = current_euid();
-
-			if (!uid_eq(euid, shp->shm_perm.uid) &&
-			    !uid_eq(euid, shp->shm_perm.cuid)) {
-				err = -EPERM;
-				goto out_unlock0;
-			}
-			if (cmd == SHM_LOCK && !rlimit(RLIMIT_MEMLOCK)) {
-				err = -EPERM;
-				goto out_unlock0;
-			}
+		if (cmd == SHM_LOCK && !rlimit(RLIMIT_MEMLOCK)) {
+			err = -EPERM;
+			goto out_unlock0;
 		}
+	}
 
-		shm_file = shp->shm_file;
-		if (is_file_hugepages(shm_file))
-			goto out_unlock0;
+	shm_file = shp->shm_file;
+	if (is_file_hugepages(shm_file))
+		goto out_unlock0;
 
-		if (cmd == SHM_LOCK) {
-			struct user_struct *user = current_user();
+	if (cmd == SHM_LOCK) {
+		struct user_struct *user = current_user();
 
-			err = shmem_lock(shm_file, 1, user);
-			if (!err && !(shp->shm_perm.mode & SHM_LOCKED)) {
-				shp->shm_perm.mode |= SHM_LOCKED;
-				shp->mlock_user = user;
-			}
-			goto out_unlock0;
+		err = shmem_lock(shm_file, 1, user);
+		if (!err && !(shp->shm_perm.mode & SHM_LOCKED)) {
+			shp->shm_perm.mode |= SHM_LOCKED;
+			shp->mlock_user = user;
 		}
+		goto out_unlock0;
+	}
 
-		/* SHM_UNLOCK */
-		if (!(shp->shm_perm.mode & SHM_LOCKED))
-			goto out_unlock0;
-		shmem_lock(shm_file, 0, shp->mlock_user);
-		shp->shm_perm.mode &= ~SHM_LOCKED;
-		shp->mlock_user = NULL;
-		get_file(shm_file);
-		ipc_unlock_object(&shp->shm_perm);
-		rcu_read_unlock();
-		shmem_unlock_mapping(shm_file->f_mapping);
+	/* SHM_UNLOCK */
+	if (!(shp->shm_perm.mode & SHM_LOCKED))
+		goto out_unlock0;
+	shmem_lock(shm_file, 0, shp->mlock_user);
+	shp->shm_perm.mode &= ~SHM_LOCKED;
+	shp->mlock_user = NULL;
+	get_file(shm_file);
+	ipc_unlock_object(&shp->shm_perm);
+	rcu_read_unlock();
+	shmem_unlock_mapping(shm_file->f_mapping);
 
-		fput(shm_file);
-		return err;
-	}
-	default:
-		return -EINVAL;
-	}
+	fput(shm_file);
+	return err;
 
 out_unlock0:
 	ipc_unlock_object(&shp->shm_perm);
@@ -1082,6 +1026,59 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 	return err;
 }
 
+SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
+{
+	int err, version;
+	struct ipc_namespace *ns;
+	struct shmid64_ds tbuf;
+
+	if (cmd < 0 || shmid < 0)
+		return -EINVAL;
+
+	version = ipc_parse_version(&cmd);
+	ns = current->nsproxy->ipc_ns;
+
+	switch (cmd) {
+	case IPC_INFO: {
+		struct shminfo64 shminfo;
+		err = shmctl_ipc_info(ns, &shminfo);
+		if (err < 0)
+			return err;
+		if (copy_shminfo_to_user(buf, &shminfo, version))
+			err = -EFAULT;
+		return err;
+	}
+	case SHM_INFO: {
+		struct shm_info shm_info;
+		err = shmctl_shm_info(ns, &shm_info);
+		if (err < 0)
+			return err;
+		if (copy_to_user(buf, &shm_info, sizeof(shm_info)))
+			err = -EFAULT;
+		return err;
+	}
+	case SHM_STAT:
+	case IPC_STAT: {
+		err = shmctl_stat(ns, shmid, cmd, &tbuf);
+		if (err < 0)
+			return err;
+		if (copy_shmid_to_user(buf, &tbuf, version))
+			err = -EFAULT;
+		return err;
+	}
+	case IPC_SET:
+		if (copy_shmid_from_user(&tbuf, buf, version))
+			return -EFAULT;
+	case IPC_RMID:
+		return shmctl_down(ns, shmid, cmd, &tbuf);
+	case SHM_LOCK:
+	case SHM_UNLOCK:
+		return shmctl_do_lock(ns, shmid, cmd);
+	default:
+		return -EINVAL;
+	}
+}
+
 /*
  * Fix shmaddr, allocate descriptor, map shm, add attach descriptor to lists.
  *

commit 42e618f77dabc82c697915c193d729e9d16e2a75
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Jul 12 14:35:25 2017 -0700

    ipc/shm: remove special shm_alloc/free
    
    There is nothing special about the shm_alloc/free routines any more, so
    remove them to make code more readable.
    
    [manfred@colorfullife.com: Rediff, to continue to keep rcu for free calls after a successful security_shm_alloc()]
    Link: http://lkml.kernel.org/r/20170525185107.12869-18-manfred@colorfullife.com
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index d1988ef821a1..28a444861a8f 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -172,11 +172,6 @@ static inline void shm_lock_by_ptr(struct shmid_kernel *ipcp)
 	ipc_lock_object(&ipcp->shm_perm);
 }
 
-static void __shm_free(struct shmid_kernel *shp)
-{
-	kvfree(shp);
-}
-
 static void shm_rcu_free(struct rcu_head *head)
 {
 	struct kern_ipc_perm *ptr = container_of(head, struct kern_ipc_perm,
@@ -184,7 +179,7 @@ static void shm_rcu_free(struct rcu_head *head)
 	struct shmid_kernel *shp = container_of(ptr, struct shmid_kernel,
 							shm_perm);
 	security_shm_free(shp);
-	__shm_free(shp);
+	kvfree(shp);
 }
 
 static inline void shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *s)
@@ -518,17 +513,6 @@ static const struct vm_operations_struct shm_vm_ops = {
 #endif
 };
 
-static struct shmid_kernel *shm_alloc(void)
-{
-	struct shmid_kernel *shp;
-
-	shp = kvmalloc(sizeof(*shp), GFP_KERNEL);
-	if (unlikely(!shp))
-		return NULL;
-
-	return shp;
-}
-
 /**
  * newseg - Create a new shared memory segment
  * @ns: namespace
@@ -558,8 +542,8 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 			ns->shm_tot + numpages > ns->shm_ctlall)
 		return -ENOSPC;
 
-	shp = shm_alloc();
-	if (!shp)
+	shp = kvmalloc(sizeof(*shp), GFP_KERNEL);
+	if (unlikely(!shp))
 		return -ENOMEM;
 
 	shp->shm_perm.key = key;
@@ -569,7 +553,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	shp->shm_perm.security = NULL;
 	error = security_shm_alloc(shp);
 	if (error) {
-		__shm_free(shp);
+		kvfree(shp);
 		return error;
 	}
 

commit 3d3653f9732c73feb8c4addfc1cbdaa292a399fa
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Jul 12 14:35:22 2017 -0700

    ipc: move atomic_set() to where it is needed
    
    Only after ipc_addid() has succeeded will refcounting be used, so move
    initialization into ipc_addid() and remove from open-coded *_alloc()
    routines.
    
    Link: http://lkml.kernel.org/r/20170525185107.12869-17-manfred@colorfullife.com
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index c5976d318ed1..d1988ef821a1 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -526,8 +526,6 @@ static struct shmid_kernel *shm_alloc(void)
 	if (unlikely(!shp))
 		return NULL;
 
-	atomic_set(&shp->shm_perm.refcount, 1);
-
 	return shp;
 }
 

commit a2642f8770993a1598500bb6a8082b7c32faff8b
Author: Manfred Spraul <manfred@colorfullife.com>
Date:   Wed Jul 12 14:35:16 2017 -0700

    ipc/shm.c: avoid ipc_rcu_putref for failed ipc_addid()
    
    Loosely based on a patch from Kees Cook <keescook@chromium.org>:
     - id and error can be merged
     - if operations before ipc_addid() fail, then use call_rcu() directly.
    
    The difference is that call_rcu is used for failures after
    security_shm_alloc(), to continue to guaranteed an rcu delay for
    security_sem_free().
    
    Link: http://lkml.kernel.org/r/20170525185107.12869-15-manfred@colorfullife.com
    Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 2ac489ef56e4..c5976d318ed1 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -548,7 +548,6 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	size_t numpages = (size + PAGE_SIZE - 1) >> PAGE_SHIFT;
 	struct file *file;
 	char name[13];
-	int id;
 	vm_flags_t acctflag = 0;
 
 	if (size < SHMMIN || size > ns->shm_ctlmax)
@@ -617,11 +616,9 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	shp->shm_file = file;
 	shp->shm_creator = current;
 
-	id = ipc_addid(&shm_ids(ns), &shp->shm_perm, ns->shm_ctlmni);
-	if (id < 0) {
-		error = id;
+	error = ipc_addid(&shm_ids(ns), &shp->shm_perm, ns->shm_ctlmni);
+	if (error < 0)
 		goto no_id;
-	}
 
 	list_add(&shp->shm_clist, &current->sysvshm.shm_clist);
 
@@ -643,7 +640,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 		user_shm_unlock(size, shp->mlock_user);
 	fput(file);
 no_file:
-	ipc_rcu_putref(&shp->shm_perm, shm_rcu_free);
+	call_rcu(&shp->shm_perm.rcu, shm_rcu_free);
 	return error;
 }
 

commit 3e0c24042e5aa55eee817caeca67246df69931e1
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Jul 12 14:35:05 2017 -0700

    ipc/shm: avoid ipc_rcu_alloc()
    
    Instead of using ipc_rcu_alloc() which only performs the refcount bump,
    open code it.  This also allows for shmid_kernel structure layout to be
    randomized in the future.
    
    Link: http://lkml.kernel.org/r/20170525185107.12869-11-manfred@colorfullife.com
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 566c1e193ee1..2ac489ef56e4 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -518,6 +518,19 @@ static const struct vm_operations_struct shm_vm_ops = {
 #endif
 };
 
+static struct shmid_kernel *shm_alloc(void)
+{
+	struct shmid_kernel *shp;
+
+	shp = kvmalloc(sizeof(*shp), GFP_KERNEL);
+	if (unlikely(!shp))
+		return NULL;
+
+	atomic_set(&shp->shm_perm.refcount, 1);
+
+	return shp;
+}
+
 /**
  * newseg - Create a new shared memory segment
  * @ns: namespace
@@ -548,10 +561,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 			ns->shm_tot + numpages > ns->shm_ctlall)
 		return -ENOSPC;
 
-	BUILD_BUG_ON(offsetof(struct shmid_kernel, shm_perm) != 0);
-
-	shp = container_of(ipc_rcu_alloc(sizeof(*shp)), struct shmid_kernel,
-				shm_perm);
+	shp = shm_alloc();
 	if (!shp)
 		return -ENOMEM;
 

commit 66470b18179f8839a62b4c20ffd3903a4025fe90
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Jul 12 14:34:53 2017 -0700

    ipc/shm: do not use ipc_rcu_free()
    
    Avoid using ipc_rcu_free, since it just re-finds the original structure
    pointer.  For the pre-list-init failure path, there is no RCU needed,
    since it was just allocated.  It can be directly freed.
    
    Link: http://lkml.kernel.org/r/20170525185107.12869-7-manfred@colorfullife.com
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 5ef6d31a52c5..566c1e193ee1 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -172,6 +172,11 @@ static inline void shm_lock_by_ptr(struct shmid_kernel *ipcp)
 	ipc_lock_object(&ipcp->shm_perm);
 }
 
+static void __shm_free(struct shmid_kernel *shp)
+{
+	kvfree(shp);
+}
+
 static void shm_rcu_free(struct rcu_head *head)
 {
 	struct kern_ipc_perm *ptr = container_of(head, struct kern_ipc_perm,
@@ -179,7 +184,7 @@ static void shm_rcu_free(struct rcu_head *head)
 	struct shmid_kernel *shp = container_of(ptr, struct shmid_kernel,
 							shm_perm);
 	security_shm_free(shp);
-	ipc_rcu_free(head);
+	__shm_free(shp);
 }
 
 static inline void shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *s)
@@ -557,7 +562,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	shp->shm_perm.security = NULL;
 	error = security_shm_alloc(shp);
 	if (error) {
-		ipc_rcu_putref(&shp->shm_perm, ipc_rcu_free);
+		__shm_free(shp);
 		return error;
 	}
 

commit dba4cdd39e698d8dcdad0656825423052ac90ccd
Author: Manfred Spraul <manfred@colorfullife.com>
Date:   Wed Jul 12 14:34:41 2017 -0700

    ipc: merge ipc_rcu and kern_ipc_perm
    
    ipc has two management structures that exist for every id:
     - struct kern_ipc_perm, it contains e.g. the permissions.
     - struct ipc_rcu, it contains the rcu head for rcu handling and the
       refcount.
    
    The patch merges both structures.
    
    As a bonus, we may save one cacheline, because both structures are
    cacheline aligned.  In addition, it reduces the number of casts, instead
    most codepaths can use container_of.
    
    To simplify code, the ipc_rcu_alloc initializes the allocation to 0.
    
    [manfred@colorfullife.com: really include the memset() into ipc_alloc_rcu()]
      Link: http://lkml.kernel.org/r/564f8612-0601-b267-514f-a9f650ec9b32@colorfullife.com
    Link: http://lkml.kernel.org/r/20170525185107.12869-3-manfred@colorfullife.com
    Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: Kees Cook <keescook@chromium.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index f45c7959b264..5ef6d31a52c5 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -174,9 +174,10 @@ static inline void shm_lock_by_ptr(struct shmid_kernel *ipcp)
 
 static void shm_rcu_free(struct rcu_head *head)
 {
-	struct ipc_rcu *p = container_of(head, struct ipc_rcu, rcu);
-	struct shmid_kernel *shp = ipc_rcu_to_struct(p);
-
+	struct kern_ipc_perm *ptr = container_of(head, struct kern_ipc_perm,
+							rcu);
+	struct shmid_kernel *shp = container_of(ptr, struct shmid_kernel,
+							shm_perm);
 	security_shm_free(shp);
 	ipc_rcu_free(head);
 }
@@ -241,7 +242,7 @@ static void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)
 		user_shm_unlock(i_size_read(file_inode(shm_file)),
 				shp->mlock_user);
 	fput(shm_file);
-	ipc_rcu_putref(shp, shm_rcu_free);
+	ipc_rcu_putref(&shp->shm_perm, shm_rcu_free);
 }
 
 /*
@@ -542,7 +543,10 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 			ns->shm_tot + numpages > ns->shm_ctlall)
 		return -ENOSPC;
 
-	shp = ipc_rcu_alloc(sizeof(*shp));
+	BUILD_BUG_ON(offsetof(struct shmid_kernel, shm_perm) != 0);
+
+	shp = container_of(ipc_rcu_alloc(sizeof(*shp)), struct shmid_kernel,
+				shm_perm);
 	if (!shp)
 		return -ENOMEM;
 
@@ -553,7 +557,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	shp->shm_perm.security = NULL;
 	error = security_shm_alloc(shp);
 	if (error) {
-		ipc_rcu_putref(shp, ipc_rcu_free);
+		ipc_rcu_putref(&shp->shm_perm, ipc_rcu_free);
 		return error;
 	}
 
@@ -624,7 +628,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 		user_shm_unlock(size, shp->mlock_user);
 	fput(file);
 no_file:
-	ipc_rcu_putref(shp, shm_rcu_free);
+	ipc_rcu_putref(&shp->shm_perm, shm_rcu_free);
 	return error;
 }
 

commit 0f41074a65757b46acbdd4293f0de8a70b147406
Author: Jeff Layton <jlayton@redhat.com>
Date:   Wed Jul 5 15:26:50 2017 -0400

    fs: remove call_fsync helper function
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Carlos Maiolino <cmaiolino@redhat.com>
    Signed-off-by: Jeff Layton <jlayton@redhat.com>

diff --git a/ipc/shm.c b/ipc/shm.c
index 34c4344e8d4b..f45c7959b264 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -452,7 +452,7 @@ static int shm_fsync(struct file *file, loff_t start, loff_t end, int datasync)
 
 	if (!sfd->file->f_op->fsync)
 		return -EINVAL;
-	return call_fsync(sfd->file, start, end, datasync);
+	return sfd->file->f_op->fsync(sfd->file, start, end, datasync);
 }
 
 static long shm_fallocate(struct file *file, int mode, loff_t offset,

commit f0cb88026f51a0d8c952cf5e09e1933ef10b50b4
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Mon May 8 15:57:03 2017 -0700

    ipc/shm: some shmat cleanups
    
    Clean up early flag and address some minutia.
    
    Link: http://lkml.kernel.org/r/1486673582-6979-3-git-send-email-dave@stgolabs.net
    Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 481d2a9c298a..34c4344e8d4b 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1095,11 +1095,11 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg,
 	      ulong *raddr, unsigned long shmlba)
 {
 	struct shmid_kernel *shp;
-	unsigned long addr;
+	unsigned long addr = (unsigned long)shmaddr;
 	unsigned long size;
 	struct file *file;
 	int    err;
-	unsigned long flags;
+	unsigned long flags = MAP_SHARED;
 	unsigned long prot;
 	int acc_mode;
 	struct ipc_namespace *ns;
@@ -1111,7 +1111,8 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg,
 	err = -EINVAL;
 	if (shmid < 0)
 		goto out;
-	else if ((addr = (ulong)shmaddr)) {
+
+	if (addr) {
 		if (addr & (shmlba - 1)) {
 			/*
 			 * Round down to the nearest multiple of shmlba.
@@ -1126,13 +1127,10 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg,
 #endif
 					goto out;
 		}
-		flags = MAP_SHARED | MAP_FIXED;
-	} else {
-		if ((shmflg & SHM_REMAP))
-			goto out;
 
-		flags = MAP_SHARED;
-	}
+		flags |= MAP_FIXED;
+	} else if ((shmflg & SHM_REMAP))
+		goto out;
 
 	if (shmflg & SHM_RDONLY) {
 		prot = PROT_READ;

commit 94e877d0fb43bec0540d6a37d49cb4f7f05a5348
Merge: 69fd110eb650 653a7746fa2f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 2 15:20:00 2017 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs pile two from Al Viro:
    
     - orangefs fix
    
     - series of fs/namei.c cleanups from me
    
     - VFS stuff coming from overlayfs tree
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      orangefs: Use RCU for destroy_inode
      vfs: use helper for calling f_op->fsync()
      mm: use helper for calling f_op->mmap()
      vfs: use helpers for calling f_op->{read,write}_iter()
      vfs: pass type instead of fn to do_{loop,iter}_readv_writev()
      vfs: extract common parts of {compat_,}do_readv_writev()
      vfs: wrap write f_ops with file_{start,end}_write()
      vfs: deny copy_file_range() for non regular files
      vfs: deny fallocate() on directory
      vfs: create vfs helper vfs_tmpfile()
      namei.c: split unlazy_walk()
      namei.c: fold the check for DCACHE_OP_REVALIDATE into d_revalidate()
      lookup_fast(): clean up the logics around the fallback to non-rcu mode
      namei: fold unlazy_link() into its sole caller

commit 95e91b831f87ac8e1f8ed50c14d709089b4e01b8
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Mon Feb 27 14:28:24 2017 -0800

    ipc/shm: Fix shmat mmap nil-page protection
    
    The issue is described here, with a nice testcase:
    
        https://bugzilla.kernel.org/show_bug.cgi?id=192931
    
    The problem is that shmat() calls do_mmap_pgoff() with MAP_FIXED, and
    the address rounded down to 0.  For the regular mmap case, the
    protection mentioned above is that the kernel gets to generate the
    address -- arch_get_unmapped_area() will always check for MAP_FIXED and
    return that address.  So by the time we do security_mmap_addr(0) things
    get funky for shmat().
    
    The testcase itself shows that while a regular user crashes, root will
    not have a problem attaching a nil-page.  There are two possible fixes
    to this.  The first, and which this patch does, is to simply allow root
    to crash as well -- this is also regular mmap behavior, ie when hacking
    up the testcase and adding mmap(...  |MAP_FIXED).  While this approach
    is the safer option, the second alternative is to ignore SHM_RND if the
    rounded address is 0, thus only having MAP_SHARED flags.  This makes the
    behavior of shmat() identical to the mmap() case.  The downside of this
    is obviously user visible, but does make sense in that it maintains
    semantics after the round-down wrt 0 address and mmap.
    
    Passes shm related ltp tests.
    
    Link: http://lkml.kernel.org/r/1486050195-18629-1-git-send-email-dave@stgolabs.net
    Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
    Reported-by: Gareth Evans <gareth.evans@contextis.co.uk>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: Michael Kerrisk <mtk.manpages@googlemail.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index d7805acb44fd..06ea9ef7f54a 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1091,8 +1091,8 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
  * "raddr" thing points to kernel space, and there has to be a wrapper around
  * this.
  */
-long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
-	      unsigned long shmlba)
+long do_shmat(int shmid, char __user *shmaddr, int shmflg,
+	      ulong *raddr, unsigned long shmlba)
 {
 	struct shmid_kernel *shp;
 	unsigned long addr;
@@ -1113,8 +1113,13 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 		goto out;
 	else if ((addr = (ulong)shmaddr)) {
 		if (addr & (shmlba - 1)) {
-			if (shmflg & SHM_RND)
-				addr &= ~(shmlba - 1);	   /* round down */
+			/*
+			 * Round down to the nearest multiple of shmlba.
+			 * For sane do_mmap_pgoff() parameters, avoid
+			 * round downs that trigger nil-page and MAP_FIXED.
+			 */
+			if ((shmflg & SHM_RND) && addr >= shmlba)
+				addr &= ~(shmlba - 1);
 			else
 #ifndef __ARCH_FORCE_SHMLBA
 				if (addr & ~PAGE_MASK)

commit 897ab3e0c49e24b62e2d54d165c7afec6bbca65b
Author: Mike Rapoport <rppt@linux.vnet.ibm.com>
Date:   Fri Feb 24 14:58:22 2017 -0800

    userfaultfd: non-cooperative: add event for memory unmaps
    
    When a non-cooperative userfaultfd monitor copies pages in the
    background, it may encounter regions that were already unmapped.
    Addition of UFFD_EVENT_UNMAP allows the uffd monitor to track precisely
    changes in the virtual memory layout.
    
    Since there might be different uffd contexts for the affected VMAs, we
    first should create a temporary representation for the unmap event for
    each uffd context and then notify them one by one to the appropriate
    userfault file descriptors.
    
    The event notification occurs after the mmap_sem has been released.
    
    [arnd@arndb.de: fix nommu build]
      Link: http://lkml.kernel.org/r/20170203165141.3665284-1-arnd@arndb.de
    [mhocko@suse.com: fix nommu build]
      Link: http://lkml.kernel.org/r/20170202091503.GA22823@dhcp22.suse.cz
    Link: http://lkml.kernel.org/r/1485542673-24387-3-git-send-email-rppt@linux.vnet.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Signed-off-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Hillf Danton <hillf.zj@alibaba-inc.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: "Dr. David Alan Gilbert" <dgilbert@redhat.com>
    Cc: Mike Kravetz <mike.kravetz@oracle.com>
    Cc: Pavel Emelyanov <xemul@virtuozzo.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 7f6537b84ef5..d7805acb44fd 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1222,7 +1222,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 			goto invalid;
 	}
 
-	addr = do_mmap_pgoff(file, addr, size, prot, flags, 0, &populate);
+	addr = do_mmap_pgoff(file, addr, size, prot, flags, 0, &populate, NULL);
 	*raddr = addr;
 	err = 0;
 	if (IS_ERR_VALUE(addr))
@@ -1329,7 +1329,7 @@ SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 			 */
 			file = vma->vm_file;
 			size = i_size_read(file_inode(vma->vm_file));
-			do_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start);
+			do_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start, NULL);
 			/*
 			 * We discovered the size of the shm segment, so
 			 * break out of here and fall through to the next
@@ -1356,7 +1356,7 @@ SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 		if ((vma->vm_ops == &shm_vm_ops) &&
 		    ((vma->vm_start - addr)/PAGE_SIZE == vma->vm_pgoff) &&
 		    (vma->vm_file == file))
-			do_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start);
+			do_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start, NULL);
 		vma = next;
 	}
 
@@ -1365,7 +1365,7 @@ SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 	 * given
 	 */
 	if (vma && vma->vm_start == addr && vma->vm_ops == &shm_vm_ops) {
-		do_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start);
+		do_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start, NULL);
 		retval = 0;
 	}
 

commit 11bac80004499ea59f361ef2a5516c84b6eab675
Author: Dave Jiang <dave.jiang@intel.com>
Date:   Fri Feb 24 14:56:41 2017 -0800

    mm, fs: reduce fault, page_mkwrite, and pfn_mkwrite to take only vmf
    
    ->fault(), ->page_mkwrite(), and ->pfn_mkwrite() calls do not need to
    take a vma and vmf parameter when the vma already resides in vmf.
    
    Remove the vma parameter to simplify things.
    
    [arnd@arndb.de: fix ARM build]
      Link: http://lkml.kernel.org/r/20170125223558.1451224-1-arnd@arndb.de
    Link: http://lkml.kernel.org/r/148521301778.19116.10840599906674778980.stgit@djiang5-desk3.ch.intel.com
    Signed-off-by: Dave Jiang <dave.jiang@intel.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Reviewed-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Cc: Darrick J. Wong <darrick.wong@oracle.com>
    Cc: Matthew Wilcox <mawilcox@microsoft.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Jan Kara <jack@suse.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 81203e8ba013..7f6537b84ef5 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -374,12 +374,12 @@ void exit_shm(struct task_struct *task)
 	up_write(&shm_ids(ns).rwsem);
 }
 
-static int shm_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
+static int shm_fault(struct vm_fault *vmf)
 {
-	struct file *file = vma->vm_file;
+	struct file *file = vmf->vma->vm_file;
 	struct shm_file_data *sfd = shm_file_data(file);
 
-	return sfd->vm_ops->fault(vma, vmf);
+	return sfd->vm_ops->fault(vmf);
 }
 
 #ifdef CONFIG_NUMA

commit 0eb8af4916a540c362a2950e5ab54eca32eb7d58
Author: Miklos Szeredi <mszeredi@redhat.com>
Date:   Mon Feb 20 16:51:23 2017 +0100

    vfs: use helper for calling f_op->fsync()
    
    Signed-off-by: Miklos Szeredi <mszeredi@redhat.com>

diff --git a/ipc/shm.c b/ipc/shm.c
index 4329fe3ef594..258aff2e03bb 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -452,7 +452,7 @@ static int shm_fsync(struct file *file, loff_t start, loff_t end, int datasync)
 
 	if (!sfd->file->f_op->fsync)
 		return -EINVAL;
-	return sfd->file->f_op->fsync(sfd->file, start, end, datasync);
+	return call_fsync(sfd->file, start, end, datasync);
 }
 
 static long shm_fallocate(struct file *file, int mode, loff_t offset,

commit f74ac01520c9f6d89bbc3c6931a72f757b742f86
Author: Miklos Szeredi <mszeredi@redhat.com>
Date:   Mon Feb 20 16:51:23 2017 +0100

    mm: use helper for calling f_op->mmap()
    
    Signed-off-by: Miklos Szeredi <mszeredi@redhat.com>

diff --git a/ipc/shm.c b/ipc/shm.c
index 81203e8ba013..4329fe3ef594 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -423,7 +423,7 @@ static int shm_mmap(struct file *file, struct vm_area_struct *vma)
 	if (ret)
 		return ret;
 
-	ret = sfd->file->f_op->mmap(sfd->file, vma);
+	ret = call_mmap(sfd->file, vma);
 	if (ret) {
 		shm_close(vma);
 		return ret;

commit 63980c80e1e99cb324942f3b5e59657025af47c0
Author: Shailesh Pandey <p.shailesh@samsung.com>
Date:   Wed Dec 14 15:06:10 2016 -0800

    ipc/shm.c: coding style fixes
    
    This patch fixes below warnings:
    
      WARNING: Missing a blank line after declarations
      WARNING: Block comments use a trailing */ on a separate line
      ERROR: spaces required around that '=' (ctx:WxV)
    
    Above warnings were reported by checkpatch.pl
    
    Link: http://lkml.kernel.org/r/1478604980-18062-1-git-send-email-p.shailesh@samsung.com
    Signed-off-by: Shailesh Pandey <p.shailesh@samsung.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index dbac8860c721..81203e8ba013 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -89,6 +89,7 @@ void shm_init_ns(struct ipc_namespace *ns)
 static void do_shm_rmid(struct ipc_namespace *ns, struct kern_ipc_perm *ipcp)
 {
 	struct shmid_kernel *shp;
+
 	shp = container_of(ipcp, struct shmid_kernel, shm_perm);
 
 	if (shp->shm_nattch) {
@@ -387,6 +388,7 @@ static int shm_set_policy(struct vm_area_struct *vma, struct mempolicy *new)
 	struct file *file = vma->vm_file;
 	struct shm_file_data *sfd = shm_file_data(file);
 	int err = 0;
+
 	if (sfd->vm_ops->set_policy)
 		err = sfd->vm_ops->set_policy(vma, new);
 	return err;
@@ -417,7 +419,7 @@ static int shm_mmap(struct file *file, struct vm_area_struct *vma)
 	 * In case of remap_file_pages() emulation, the file can represent
 	 * removed IPC ID: propogate shm_lock() error to caller.
 	 */
-	ret =__shm_open(vma);
+	ret = __shm_open(vma);
 	if (ret)
 		return ret;
 
@@ -468,6 +470,7 @@ static unsigned long shm_get_unmapped_area(struct file *file,
 	unsigned long flags)
 {
 	struct shm_file_data *sfd = shm_file_data(file);
+
 	return sfd->file->f_op->get_unmapped_area(sfd->file, addr, len,
 						pgoff, flags);
 }
@@ -766,6 +769,7 @@ static void shm_add_rss_swap(struct shmid_kernel *shp,
 	} else {
 #ifdef CONFIG_SHMEM
 		struct shmem_inode_info *info = SHMEM_I(inode);
+
 		spin_lock_irq(&info->lock);
 		*rss_add += inode->i_mapping->nrpages;
 		*swp_add += info->swapped;
@@ -1028,6 +1032,7 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 
 		if (!ns_capable(ns->user_ns, CAP_IPC_LOCK)) {
 			kuid_t euid = current_euid();
+
 			if (!uid_eq(euid, shp->shm_perm.uid) &&
 			    !uid_eq(euid, shp->shm_perm.cuid)) {
 				err = -EPERM;
@@ -1045,6 +1050,7 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 
 		if (cmd == SHM_LOCK) {
 			struct user_struct *user = current_user();
+
 			err = shmem_lock(shm_file, 1, user);
 			if (!err && !(shp->shm_perm.mode & SHM_LOCKED)) {
 				shp->shm_perm.mode |= SHM_LOCKED;
@@ -1354,9 +1360,10 @@ SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 		vma = next;
 	}
 
-#else /* CONFIG_MMU */
+#else	/* CONFIG_MMU */
 	/* under NOMMU conditions, the exact address to be destroyed must be
-	 * given */
+	 * given
+	 */
 	if (vma && vma->vm_start == addr && vma->vm_ops == &shm_vm_ops) {
 		do_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start);
 		retval = 0;

commit 4595ef88d136134a9470c955575640f5c96344ed
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Tue Jul 26 15:26:29 2016 -0700

    shmem: make shmem_inode_info::lock irq-safe
    
    We are going to need to call shmem_charge() under tree_lock to get
    accoutning right on collapse of small tmpfs pages into a huge one.
    
    The problem is that tree_lock is irq-safe and lockdep is not happy, that
    we take irq-unsafe lock under irq-safe[1].
    
    Let's convert the lock to irq-safe.
    
    [1] https://gist.github.com/kiryl/80c0149e03ed35dfaf26628b8e03cdbc
    
    Link: http://lkml.kernel.org/r/1466021202-61880-34-git-send-email-kirill.shutemov@linux.intel.com
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 7fa5cbebbf19..dbac8860c721 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -766,10 +766,10 @@ static void shm_add_rss_swap(struct shmid_kernel *shp,
 	} else {
 #ifdef CONFIG_SHMEM
 		struct shmem_inode_info *info = SHMEM_I(inode);
-		spin_lock(&info->lock);
+		spin_lock_irq(&info->lock);
 		*rss_add += inode->i_mapping->nrpages;
 		*swp_add += info->swapped;
-		spin_unlock(&info->lock);
+		spin_unlock_irq(&info->lock);
 #else
 		*rss_add += inode->i_mapping->nrpages;
 #endif

commit c01d5b300774d130a24d787825b01eb24e6e20cb
Author: Hugh Dickins <hughd@google.com>
Date:   Tue Jul 26 15:26:15 2016 -0700

    shmem: get_unmapped_area align huge page
    
    Provide a shmem_get_unmapped_area method in file_operations, called at
    mmap time to decide the mapping address.  It could be conditional on
    CONFIG_TRANSPARENT_HUGEPAGE, but save #ifdefs in other places by making
    it unconditional.
    
    shmem_get_unmapped_area() first calls the usual mm->get_unmapped_area
    (which we treat as a black box, highly dependent on architecture and
    config and executable layout).  Lots of conditions, and in most cases it
    just goes with the address that chose; but when our huge stars are
    rightly aligned, yet that did not provide a suitable address, go back to
    ask for a larger arena, within which to align the mapping suitably.
    
    There have to be some direct calls to shmem_get_unmapped_area(), not via
    the file_operations: because of the way shmem_zero_setup() is called to
    create a shmem object late in the mmap sequence, when MAP_SHARED is
    requested with MAP_ANONYMOUS or /dev/zero.  Though this only matters
    when /proc/sys/vm/shmem_huge has been set.
    
    Link: http://lkml.kernel.org/r/1466021202-61880-29-git-send-email-kirill.shutemov@linux.intel.com
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 13282510bc0d..7fa5cbebbf19 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -476,13 +476,15 @@ static const struct file_operations shm_file_operations = {
 	.mmap		= shm_mmap,
 	.fsync		= shm_fsync,
 	.release	= shm_release,
-#ifndef CONFIG_MMU
 	.get_unmapped_area	= shm_get_unmapped_area,
-#endif
 	.llseek		= noop_llseek,
 	.fallocate	= shm_fallocate,
 };
 
+/*
+ * shm_file_operations_huge is now identical to shm_file_operations,
+ * but we keep it distinct for the sake of is_file_shm_hugepages().
+ */
 static const struct file_operations shm_file_operations_huge = {
 	.mmap		= shm_mmap,
 	.fsync		= shm_fsync,

commit 91f4f94ea3f2eabb4cee68149a31e30f84a993dd
Author: Michal Hocko <mhocko@suse.com>
Date:   Mon May 23 16:25:51 2016 -0700

    ipc, shm: make shmem attach/detach wait for mmap_sem killable
    
    shmat and shmdt rely on mmap_sem for write.  If the waiting task gets
    killed by the oom killer it would block oom_reaper from asynchronous
    address space reclaim and reduce the chances of timely OOM resolving.
    Wait for the lock in the killable mode and return with EINTR if the task
    got killed while waiting.
    
    Signed-off-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Davidlohr Bueso <dave@stgolabs.net>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 331fc1b0b3c7..13282510bc0d 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1200,7 +1200,11 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 	if (err)
 		goto out_fput;
 
-	down_write(&current->mm->mmap_sem);
+	if (down_write_killable(&current->mm->mmap_sem)) {
+		err = -EINTR;
+		goto out_fput;
+	}
+
 	if (addr && !(shmflg & SHM_REMAP)) {
 		err = -EINVAL;
 		if (addr + size < addr)
@@ -1271,7 +1275,8 @@ SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 	if (addr & ~PAGE_MASK)
 		return retval;
 
-	down_write(&mm->mmap_sem);
+	if (down_write_killable(&mm->mmap_sem))
+		return -EINTR;
 
 	/*
 	 * This function tries to be smart and unmap shm segments that

commit 1ac0b6dec656f3f78d1c3dd216fad84cb4d0a01e
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Wed Feb 17 13:11:35 2016 -0800

    ipc/shm: handle removed segments gracefully in shm_mmap()
    
    remap_file_pages(2) emulation can reach file which represents removed
    IPC ID as long as a memory segment is mapped.  It breaks expectations of
    IPC subsystem.
    
    Test case (rewritten to be more human readable, originally autogenerated
    by syzkaller[1]):
    
            #define _GNU_SOURCE
            #include <stdlib.h>
            #include <sys/ipc.h>
            #include <sys/mman.h>
            #include <sys/shm.h>
    
            #define PAGE_SIZE 4096
    
            int main()
            {
                    int id;
                    void *p;
    
                    id = shmget(IPC_PRIVATE, 3 * PAGE_SIZE, 0);
                    p = shmat(id, NULL, 0);
                    shmctl(id, IPC_RMID, NULL);
                    remap_file_pages(p, 3 * PAGE_SIZE, 0, 7, 0);
    
                    return 0;
            }
    
    The patch changes shm_mmap() and code around shm_lock() to propagate
    locking error back to caller of shm_mmap().
    
    [1] http://github.com/google/syzkaller
    
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index ed3027d0f277..331fc1b0b3c7 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -156,11 +156,12 @@ static inline struct shmid_kernel *shm_lock(struct ipc_namespace *ns, int id)
 	struct kern_ipc_perm *ipcp = ipc_lock(&shm_ids(ns), id);
 
 	/*
-	 * We raced in the idr lookup or with shm_destroy().  Either way, the
-	 * ID is busted.
+	 * Callers of shm_lock() must validate the status of the returned ipc
+	 * object pointer (as returned by ipc_lock()), and error out as
+	 * appropriate.
 	 */
-	WARN_ON(IS_ERR(ipcp));
-
+	if (IS_ERR(ipcp))
+		return (void *)ipcp;
 	return container_of(ipcp, struct shmid_kernel, shm_perm);
 }
 
@@ -186,18 +187,33 @@ static inline void shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *s)
 }
 
 
-/* This is called by fork, once for every shm attach. */
-static void shm_open(struct vm_area_struct *vma)
+static int __shm_open(struct vm_area_struct *vma)
 {
 	struct file *file = vma->vm_file;
 	struct shm_file_data *sfd = shm_file_data(file);
 	struct shmid_kernel *shp;
 
 	shp = shm_lock(sfd->ns, sfd->id);
+
+	if (IS_ERR(shp))
+		return PTR_ERR(shp);
+
 	shp->shm_atim = get_seconds();
 	shp->shm_lprid = task_tgid_vnr(current);
 	shp->shm_nattch++;
 	shm_unlock(shp);
+	return 0;
+}
+
+/* This is called by fork, once for every shm attach. */
+static void shm_open(struct vm_area_struct *vma)
+{
+	int err = __shm_open(vma);
+	/*
+	 * We raced in the idr lookup or with shm_destroy().
+	 * Either way, the ID is busted.
+	 */
+	WARN_ON_ONCE(err);
 }
 
 /*
@@ -260,6 +276,14 @@ static void shm_close(struct vm_area_struct *vma)
 	down_write(&shm_ids(ns).rwsem);
 	/* remove from the list of attaches of the shm segment */
 	shp = shm_lock(ns, sfd->id);
+
+	/*
+	 * We raced in the idr lookup or with shm_destroy().
+	 * Either way, the ID is busted.
+	 */
+	if (WARN_ON_ONCE(IS_ERR(shp)))
+		goto done; /* no-op */
+
 	shp->shm_lprid = task_tgid_vnr(current);
 	shp->shm_dtim = get_seconds();
 	shp->shm_nattch--;
@@ -267,6 +291,7 @@ static void shm_close(struct vm_area_struct *vma)
 		shm_destroy(ns, shp);
 	else
 		shm_unlock(shp);
+done:
 	up_write(&shm_ids(ns).rwsem);
 }
 
@@ -388,17 +413,25 @@ static int shm_mmap(struct file *file, struct vm_area_struct *vma)
 	struct shm_file_data *sfd = shm_file_data(file);
 	int ret;
 
+	/*
+	 * In case of remap_file_pages() emulation, the file can represent
+	 * removed IPC ID: propogate shm_lock() error to caller.
+	 */
+	ret =__shm_open(vma);
+	if (ret)
+		return ret;
+
 	ret = sfd->file->f_op->mmap(sfd->file, vma);
-	if (ret != 0)
+	if (ret) {
+		shm_close(vma);
 		return ret;
+	}
 	sfd->vm_ops = vma->vm_ops;
 #ifdef CONFIG_MMU
 	WARN_ON(!sfd->vm_ops->fault);
 #endif
 	vma->vm_ops = &shm_vm_ops;
-	shm_open(vma);
-
-	return ret;
+	return 0;
 }
 
 static int shm_release(struct inode *ino, struct file *file)

commit 2954e440be7305134be632a94536b412899490f7
Author: Yaowei Bai <baiyaowei@cmss.chinamobile.com>
Date:   Wed Jan 20 15:01:11 2016 -0800

    ipc/shm.c: is_file_shm_hugepages() can be boolean
    
    Make is_file_shm_hugepages() return bool to improve readability due to
    this particular function only using either one or zero as its return
    value.
    
    No functional change.
    
    Signed-off-by: Yaowei Bai <baiyaowei@cmss.chinamobile.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 41787276e141..ed3027d0f277 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -459,7 +459,7 @@ static const struct file_operations shm_file_operations_huge = {
 	.fallocate	= shm_fallocate,
 };
 
-int is_file_shm_hugepages(struct file *file)
+bool is_file_shm_hugepages(struct file *file)
 {
 	return file->f_op == &shm_file_operations_huge;
 }

commit b9a532277938798b53178d5a66af6e2915cb27cf
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Sep 30 12:48:40 2015 -0400

    Initialize msg/shm IPC objects before doing ipc_addid()
    
    As reported by Dmitry Vyukov, we really shouldn't do ipc_addid() before
    having initialized the IPC object state.  Yes, we initialize the IPC
    object in a locked state, but with all the lockless RCU lookup work,
    that IPC object lock no longer means that the state cannot be seen.
    
    We already did this for the IPC semaphore code (see commit e8577d1f0329:
    "ipc/sem.c: fully initialize sem_array before making it visible") but we
    clearly forgot about msg and shm.
    
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: Davidlohr Bueso <dbueso@suse.de>
    Cc: stable@vger.kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 222131e8e38f..41787276e141 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -551,12 +551,6 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	if (IS_ERR(file))
 		goto no_file;
 
-	id = ipc_addid(&shm_ids(ns), &shp->shm_perm, ns->shm_ctlmni);
-	if (id < 0) {
-		error = id;
-		goto no_id;
-	}
-
 	shp->shm_cprid = task_tgid_vnr(current);
 	shp->shm_lprid = 0;
 	shp->shm_atim = shp->shm_dtim = 0;
@@ -565,6 +559,13 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	shp->shm_nattch = 0;
 	shp->shm_file = file;
 	shp->shm_creator = current;
+
+	id = ipc_addid(&shm_ids(ns), &shp->shm_perm, ns->shm_ctlmni);
+	if (id < 0) {
+		error = id;
+		goto no_id;
+	}
+
 	list_add(&shp->shm_clist, &current->sysvshm.shm_clist);
 
 	/*

commit d0edd8528362c07216498340e928159510595e7b
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Wed Sep 9 15:39:20 2015 -0700

    ipc: convert invalid scenarios to use WARN_ON
    
    Considering Linus' past rants about the (ab)use of BUG in the kernel, I
    took a look at how we deal with such calls in ipc.  Given that any errors
    or corruption in ipc code are most likely contained within the set of
    processes participating in the broken mechanisms, there aren't really many
    strong fatal system failure scenarios that would require a BUG call.
    Also, if something is seriously wrong, ipc might not be the place for such
    a BUG either.
    
    1. For example, recently, a customer hit one of these BUG_ONs in shm
       after failing shm_lock().  A busted ID imho does not merit a BUG_ON,
       and WARN would have been better.
    
    2. MSG_COPY functionality of posix msgrcv(2) for checkpoint/restore.
       I don't see how we can hit this anyway -- at least it should be IS_ERR.
        The 'copy' arg from do_msgrcv is always set by calling prepare_copy()
       first and foremost.  We could also probably drop this check altogether.
        Either way, it does not merit a BUG_ON.
    
    3. No ->fault() callback for the fs getting the corresponding page --
       seems selfish to make the system unusable.
    
    Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 4aef24d91b63..222131e8e38f 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -159,7 +159,7 @@ static inline struct shmid_kernel *shm_lock(struct ipc_namespace *ns, int id)
 	 * We raced in the idr lookup or with shm_destroy().  Either way, the
 	 * ID is busted.
 	 */
-	BUG_ON(IS_ERR(ipcp));
+	WARN_ON(IS_ERR(ipcp));
 
 	return container_of(ipcp, struct shmid_kernel, shm_perm);
 }
@@ -393,7 +393,7 @@ static int shm_mmap(struct file *file, struct vm_area_struct *vma)
 		return ret;
 	sfd->vm_ops = vma->vm_ops;
 #ifdef CONFIG_MMU
-	BUG_ON(!sfd->vm_ops->fault);
+	WARN_ON(!sfd->vm_ops->fault);
 #endif
 	vma->vm_ops = &shm_vm_ops;
 	shm_open(vma);

commit e1832f2923ec92d0e590e496c8890675457f8568
Author: Stephen Smalley <sds@tycho.nsa.gov>
Date:   Thu Aug 6 15:46:55 2015 -0700

    ipc: use private shmem or hugetlbfs inodes for shm segments.
    
    The shm implementation internally uses shmem or hugetlbfs inodes for shm
    segments.  As these inodes are never directly exposed to userspace and
    only accessed through the shm operations which are already hooked by
    security modules, mark the inodes with the S_PRIVATE flag so that inode
    security initialization and permission checking is skipped.
    
    This was motivated by the following lockdep warning:
    
      ======================================================
       [ INFO: possible circular locking dependency detected ]
       4.2.0-0.rc3.git0.1.fc24.x86_64+debug #1 Tainted: G        W
      -------------------------------------------------------
       httpd/1597 is trying to acquire lock:
       (&ids->rwsem){+++++.}, at: shm_close+0x34/0x130
       but task is already holding lock:
       (&mm->mmap_sem){++++++}, at: SyS_shmdt+0x4b/0x180
       which lock already depends on the new lock.
       the existing dependency chain (in reverse order) is:
       -> #3 (&mm->mmap_sem){++++++}:
            lock_acquire+0xc7/0x270
            __might_fault+0x7a/0xa0
            filldir+0x9e/0x130
            xfs_dir2_block_getdents.isra.12+0x198/0x1c0 [xfs]
            xfs_readdir+0x1b4/0x330 [xfs]
            xfs_file_readdir+0x2b/0x30 [xfs]
            iterate_dir+0x97/0x130
            SyS_getdents+0x91/0x120
            entry_SYSCALL_64_fastpath+0x12/0x76
       -> #2 (&xfs_dir_ilock_class){++++.+}:
            lock_acquire+0xc7/0x270
            down_read_nested+0x57/0xa0
            xfs_ilock+0x167/0x350 [xfs]
            xfs_ilock_attr_map_shared+0x38/0x50 [xfs]
            xfs_attr_get+0xbd/0x190 [xfs]
            xfs_xattr_get+0x3d/0x70 [xfs]
            generic_getxattr+0x4f/0x70
            inode_doinit_with_dentry+0x162/0x670
            sb_finish_set_opts+0xd9/0x230
            selinux_set_mnt_opts+0x35c/0x660
            superblock_doinit+0x77/0xf0
            delayed_superblock_init+0x10/0x20
            iterate_supers+0xb3/0x110
            selinux_complete_init+0x2f/0x40
            security_load_policy+0x103/0x600
            sel_write_load+0xc1/0x750
            __vfs_write+0x37/0x100
            vfs_write+0xa9/0x1a0
            SyS_write+0x58/0xd0
            entry_SYSCALL_64_fastpath+0x12/0x76
      ...
    
    Signed-off-by: Stephen Smalley <sds@tycho.nsa.gov>
    Reported-by: Morten Stevens <mstevens@fedoraproject.org>
    Acked-by: Hugh Dickins <hughd@google.com>
    Acked-by: Paul Moore <paul@paul-moore.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Eric Paris <eparis@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 06e5cf2fe019..4aef24d91b63 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -545,7 +545,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 		if  ((shmflg & SHM_NORESERVE) &&
 				sysctl_overcommit_memory != OVERCOMMIT_NEVER)
 			acctflag = VM_NORESERVE;
-		file = shmem_file_setup(name, size, acctflag);
+		file = shmem_kernel_file_setup(name, size, acctflag);
 	}
 	error = PTR_ERR(file);
 	if (IS_ERR(file))

commit 55b7ae50167efc9b1c4f8fb60a99478cd46a82f7
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Tue Jun 30 14:58:42 2015 -0700

    ipc: rename ipc_obtain_object
    
    ...  to ipc_obtain_object_idr, which is more meaningful and makes the code
    slightly easier to follow.
    
    Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index bd9c91f433c1..06e5cf2fe019 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -129,7 +129,7 @@ void __init shm_init(void)
 
 static inline struct shmid_kernel *shm_obtain_object(struct ipc_namespace *ns, int id)
 {
-	struct kern_ipc_perm *ipcp = ipc_obtain_object(&shm_ids(ns), id);
+	struct kern_ipc_perm *ipcp = ipc_obtain_object_idr(&shm_ids(ns), id);
 
 	if (IS_ERR(ipcp))
 		return ERR_CAST(ipcp);

commit c5c8975b2eb4eb7604e8ce4f762987f56d2a96a2
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Tue Jun 30 14:58:36 2015 -0700

    ipc,shm: move BUG_ON check into shm_lock
    
    Upon every shm_lock call, we BUG_ON if an error was returned, indicating
    racing either in idr or in shm_destroy.  Move this logic into the locking.
    
    [akpm@linux-foundation.org: simplify code]
    Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 6d767071c367..bd9c91f433c1 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -155,8 +155,11 @@ static inline struct shmid_kernel *shm_lock(struct ipc_namespace *ns, int id)
 {
 	struct kern_ipc_perm *ipcp = ipc_lock(&shm_ids(ns), id);
 
-	if (IS_ERR(ipcp))
-		return (struct shmid_kernel *)ipcp;
+	/*
+	 * We raced in the idr lookup or with shm_destroy().  Either way, the
+	 * ID is busted.
+	 */
+	BUG_ON(IS_ERR(ipcp));
 
 	return container_of(ipcp, struct shmid_kernel, shm_perm);
 }
@@ -191,7 +194,6 @@ static void shm_open(struct vm_area_struct *vma)
 	struct shmid_kernel *shp;
 
 	shp = shm_lock(sfd->ns, sfd->id);
-	BUG_ON(IS_ERR(shp));
 	shp->shm_atim = get_seconds();
 	shp->shm_lprid = task_tgid_vnr(current);
 	shp->shm_nattch++;
@@ -258,7 +260,6 @@ static void shm_close(struct vm_area_struct *vma)
 	down_write(&shm_ids(ns).rwsem);
 	/* remove from the list of attaches of the shm segment */
 	shp = shm_lock(ns, sfd->id);
-	BUG_ON(IS_ERR(shp));
 	shp->shm_lprid = task_tgid_vnr(current);
 	shp->shm_dtim = get_seconds();
 	shp->shm_nattch--;
@@ -1191,7 +1192,6 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 out_nattch:
 	down_write(&shm_ids(ns).rwsem);
 	shp = shm_lock(ns, shmid);
-	BUG_ON(IS_ERR(shp));
 	shp->shm_nattch--;
 	if (shm_may_destroy(ns, shp))
 		shm_destroy(ns, shp);

commit 9ec3a646fe09970f801ab15e0f1694060b9f19af
Merge: c8b3fd0ce313 3cab989afd8d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Apr 26 15:48:49 2015 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull fourth vfs update from Al Viro:
     "d_inode() annotations from David Howells (sat in for-next since before
      the beginning of merge window) + four assorted fixes"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      RCU pathwalk breakage when running into a symlink overmounting something
      fix I_DIO_WAKEUP definition
      direct-io: only inc/dec inode->i_dio_count for file systems
      fs/9p: fix readdir()
      VFS: assorted d_backing_inode() annotations
      VFS: fs/inode.c helpers: d_inode() annotations
      VFS: fs/cachefiles: d_backing_inode() annotations
      VFS: fs library helpers: d_inode() annotations
      VFS: assorted weird filesystems: d_inode() annotations
      VFS: normal filesystems (and lustre): d_inode() annotations
      VFS: security/: d_inode() annotations
      VFS: security/: d_backing_inode() annotations
      VFS: net/: d_inode() annotations
      VFS: net/unix: d_backing_inode() annotations
      VFS: kernel/: d_inode() annotations
      VFS: audit: d_backing_inode() annotations
      VFS: Fix up some ->d_inode accesses in the chelsio driver
      VFS: Cachefiles should perform fs modifications on the top layer only
      VFS: AF_UNIX sockets should call mknod on the top layer only

commit 7f032d6ef6154868a2a5d5f6b2c3f8587292196c
Author: Joe Perches <joe@perches.com>
Date:   Wed Apr 15 16:17:54 2015 -0700

    ipc: remove use of seq_printf return value
    
    The seq_printf return value, because it's frequently misused,
    will eventually be converted to void.
    
    See: commit 1f33c41c03da ("seq_file: Rename seq_overflow() to
         seq_has_overflowed() and make public")
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 19633b4a2350..d280a74af2ef 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1342,25 +1342,27 @@ static int sysvipc_shm_proc_show(struct seq_file *s, void *it)
 #define SIZE_SPEC "%21lu"
 #endif
 
-	return seq_printf(s,
-			  "%10d %10d  %4o " SIZE_SPEC " %5u %5u  "
-			  "%5lu %5u %5u %5u %5u %10lu %10lu %10lu "
-			  SIZE_SPEC " " SIZE_SPEC "\n",
-			  shp->shm_perm.key,
-			  shp->shm_perm.id,
-			  shp->shm_perm.mode,
-			  shp->shm_segsz,
-			  shp->shm_cprid,
-			  shp->shm_lprid,
-			  shp->shm_nattch,
-			  from_kuid_munged(user_ns, shp->shm_perm.uid),
-			  from_kgid_munged(user_ns, shp->shm_perm.gid),
-			  from_kuid_munged(user_ns, shp->shm_perm.cuid),
-			  from_kgid_munged(user_ns, shp->shm_perm.cgid),
-			  shp->shm_atim,
-			  shp->shm_dtim,
-			  shp->shm_ctim,
-			  rss * PAGE_SIZE,
-			  swp * PAGE_SIZE);
+	seq_printf(s,
+		   "%10d %10d  %4o " SIZE_SPEC " %5u %5u  "
+		   "%5lu %5u %5u %5u %5u %10lu %10lu %10lu "
+		   SIZE_SPEC " " SIZE_SPEC "\n",
+		   shp->shm_perm.key,
+		   shp->shm_perm.id,
+		   shp->shm_perm.mode,
+		   shp->shm_segsz,
+		   shp->shm_cprid,
+		   shp->shm_lprid,
+		   shp->shm_nattch,
+		   from_kuid_munged(user_ns, shp->shm_perm.uid),
+		   from_kgid_munged(user_ns, shp->shm_perm.gid),
+		   from_kuid_munged(user_ns, shp->shm_perm.cuid),
+		   from_kgid_munged(user_ns, shp->shm_perm.cgid),
+		   shp->shm_atim,
+		   shp->shm_dtim,
+		   shp->shm_ctim,
+		   rss * PAGE_SIZE,
+		   swp * PAGE_SIZE);
+
+	return 0;
 }
 #endif

commit 75c3cfa855dcedc84e7964269c9b6baf26137959
Author: David Howells <dhowells@redhat.com>
Date:   Tue Mar 17 22:26:12 2015 +0000

    VFS: assorted weird filesystems: d_inode() annotations
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 19633b4a2350..55e07c980674 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1132,7 +1132,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 	path = shp->shm_file->f_path;
 	path_get(&path);
 	shp->shm_nattch++;
-	size = i_size_read(path.dentry->d_inode);
+	size = i_size_read(d_inode(path.dentry));
 	ipc_unlock_object(&shp->shm_perm);
 	rcu_read_unlock();
 

commit 07a46ed27dc6344de831a450df82336270a157a9
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Fri Dec 12 16:58:22 2014 -0800

    shmdt: use i_size_read() instead of ->i_size
    
    Andrew Morton noted
    
            http://lkml.kernel.org/r/20141104142027.a7a0d010772d84560b445f59@linux-foundation.org
    
    that the shmdt uses inode->i_size outside of i_mutex being held.
    There is one more case in shm.c in shm_destroy().  This converts
    both users over to use i_size_read().
    
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index e5dc7d246f05..19633b4a2350 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -219,7 +219,8 @@ static void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)
 	if (!is_file_hugepages(shm_file))
 		shmem_lock(shm_file, 0, shp->mlock_user);
 	else if (shp->mlock_user)
-		user_shm_unlock(file_inode(shm_file)->i_size, shp->mlock_user);
+		user_shm_unlock(i_size_read(file_inode(shm_file)),
+				shp->mlock_user);
 	fput(shm_file);
 	ipc_rcu_putref(shp, shm_rcu_free);
 }
@@ -1280,7 +1281,7 @@ SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 			 * in the range we are unmapping.
 			 */
 			file = vma->vm_file;
-			size = file_inode(file)->i_size;
+			size = i_size_read(file_inode(vma->vm_file));
 			do_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start);
 			/*
 			 * We discovered the size of the shm segment, so

commit d3c97900b427b8d5a476fdfe484267f09df418d6
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Fri Dec 12 16:58:19 2014 -0800

    ipc/shm.c: fix overly aggressive shmdt() when calls span multiple segments
    
    This is a highly-contrived scenario.  But, a single shmdt() call can be
    induced in to unmapping memory from mulitple shm segments.  Example code
    is here:
    
            http://www.sr71.net/~dave/intel/shmfun.c
    
    The fix is pretty simple: Record the 'struct file' for the first VMA we
    encounter and then stick to it.  Decline to unmap anything not from the
    same file and thus the same segment.
    
    I found this by inspection and the odds of anyone hitting this in practice
    are pretty darn small.
    
    Lightly tested, but it's a pretty small patch.
    
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Reviewed-by: Davidlohr Bueso <dave@stgolabs.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 01454796ba3c..e5dc7d246f05 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1229,6 +1229,7 @@ SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 	int retval = -EINVAL;
 #ifdef CONFIG_MMU
 	loff_t size = 0;
+	struct file *file;
 	struct vm_area_struct *next;
 #endif
 
@@ -1245,7 +1246,8 @@ SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 	 *   started at address shmaddr. It records it's size and then unmaps
 	 *   it.
 	 * - Then it unmaps all shm vmas that started at shmaddr and that
-	 *   are within the initially determined size.
+	 *   are within the initially determined size and that are from the
+	 *   same shm segment from which we determined the size.
 	 * Errors from do_munmap are ignored: the function only fails if
 	 * it's called with invalid parameters or if it's called to unmap
 	 * a part of a vma. Both calls in this function are for full vmas,
@@ -1271,8 +1273,14 @@ SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 		if ((vma->vm_ops == &shm_vm_ops) &&
 			(vma->vm_start - addr)/PAGE_SIZE == vma->vm_pgoff) {
 
-
-			size = file_inode(vma->vm_file)->i_size;
+			/*
+			 * Record the file of the shm segment being
+			 * unmapped.  With mremap(), someone could place
+			 * page from another segment but with equal offsets
+			 * in the range we are unmapping.
+			 */
+			file = vma->vm_file;
+			size = file_inode(file)->i_size;
 			do_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start);
 			/*
 			 * We discovered the size of the shm segment, so
@@ -1298,8 +1306,8 @@ SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 
 		/* finding a matching vma now does not alter retval */
 		if ((vma->vm_ops == &shm_vm_ops) &&
-			(vma->vm_start - addr)/PAGE_SIZE == vma->vm_pgoff)
-
+		    ((vma->vm_start - addr)/PAGE_SIZE == vma->vm_pgoff) &&
+		    (vma->vm_file == file))
 			do_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start);
 		vma = next;
 	}

commit bf77b94c99ad5df0d97a52522fc7a220c0bf44fe
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Mon Oct 13 15:54:12 2014 -0700

    ipc/shm: kill the historical/wrong mm->start_stack check
    
    do_shmat() is the only user of ->start_stack (proc just reports its
    value), and this check looks ugly and wrong.
    
    The reason for this check is not clear at all, and it wrongly assumes that
    the stack can only grow down.
    
    But the main problem is that in general mm->start_stack has nothing to do
    with stack_vma->vm_start.  Not only the application can switch to another
    stack and even unmap this area, setup_arg_pages() expands the stack
    without updating mm->start_stack during exec().  This means that in the
    likely case "addr > start_stack - size - PAGE_SIZE * 5" is simply
    impossible after find_vma_intersection() == F, or the stack can't grow
    anyway because of RLIMIT_STACK.
    
    Many thanks to Hugh for his explanations.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Hugh Dickins <hughd@google.com>
    Cc: Cyrill Gorcunov <gorcunov@gmail.com>
    Cc: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 7fc9f9f3a26b..01454796ba3c 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1172,13 +1172,6 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 
 		if (find_vma_intersection(current->mm, addr, addr + size))
 			goto invalid;
-		/*
-		 * If shm segment goes below stack, make sure there is some
-		 * space left for the stack to grow (at least 4 pages).
-		 */
-		if (addr < current->mm->start_stack &&
-		    addr > current->mm->start_stack - size - PAGE_SIZE * 5)
-			goto invalid;
 	}
 
 	addr = do_mmap_pgoff(file, addr, size, prot, flags, 0, &populate);

commit 83293c0f5a6130bf7d60b7b406f4a4de0cadd3d8
Author: Jack Miller <millerjo@us.ibm.com>
Date:   Fri Aug 8 14:23:21 2014 -0700

    shm: allow exit_shm in parallel if only marking orphans
    
    If shm_rmid_force (the default state) is not set then the shmids are only
    marked as orphaned and does not require any add, delete, or locking of the
    tree structure.
    
    Seperate the sysctl on and off case, and only obtain the read lock.  The
    newly added list head can be deleted under the read lock because we are
    only called with current and will only change the semids allocated by this
    task and not manipulate the list.
    
    This commit assumes that up_read includes a sufficient memory barrier for
    the writes to be seen my others that later obtain a write lock.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Jack Miller <millerjo@us.ibm.com>
    Cc: Davidlohr Bueso <davidlohr@hp.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: Anton Blanchard <anton@samba.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 1fc3a61b443b..7fc9f9f3a26b 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -268,32 +268,6 @@ static void shm_close(struct vm_area_struct *vma)
 	up_write(&shm_ids(ns).rwsem);
 }
 
-/* Called with ns->shm_ids(ns).rwsem locked */
-static void shm_mark_orphan(struct shmid_kernel *shp, struct ipc_namespace *ns)
-{
-	if (WARN_ON(shp->shm_creator != current)) /* Remove me when it works */
-		return;
-
-	/*
-	 * Mark it as orphaned to destroy the segment when
-	 * kernel.shm_rmid_forced is changed.
-	 * It is noop if the following shm_may_destroy() returns true.
-	 */
-	shp->shm_creator = NULL;
-
-	/*
-	 * Don't even try to destroy it.  If shm_rmid_forced=0 and IPC_RMID
-	 * is not set, it shouldn't be deleted here.
-	 */
-	if (!ns->shm_rmid_forced)
-		return;
-
-	if (shm_may_destroy(ns, shp)) {
-		shm_lock_by_ptr(shp);
-		shm_destroy(ns, shp);
-	}
-}
-
 /* Called with ns->shm_ids(ns).rwsem locked */
 static int shm_try_destroy_orphaned(int id, void *p, void *data)
 {
@@ -325,20 +299,49 @@ void shm_destroy_orphaned(struct ipc_namespace *ns)
 	up_write(&shm_ids(ns).rwsem);
 }
 
-
+/* Locking assumes this will only be called with task == current */
 void exit_shm(struct task_struct *task)
 {
 	struct ipc_namespace *ns = task->nsproxy->ipc_ns;
 	struct shmid_kernel *shp, *n;
 
-	if (shm_ids(ns).in_use == 0)
+	if (list_empty(&task->sysvshm.shm_clist))
+		return;
+
+	/*
+	 * If kernel.shm_rmid_forced is not set then only keep track of
+	 * which shmids are orphaned, so that a later set of the sysctl
+	 * can clean them up.
+	 */
+	if (!ns->shm_rmid_forced) {
+		down_read(&shm_ids(ns).rwsem);
+		list_for_each_entry(shp, &task->sysvshm.shm_clist, shm_clist)
+			shp->shm_creator = NULL;
+		/*
+		 * Only under read lock but we are only called on current
+		 * so no entry on the list will be shared.
+		 */
+		list_del(&task->sysvshm.shm_clist);
+		up_read(&shm_ids(ns).rwsem);
 		return;
+	}
 
-	/* Destroy all already created segments, but not mapped yet */
+	/*
+	 * Destroy all already created segments, that were not yet mapped,
+	 * and mark any mapped as orphan to cover the sysctl toggling.
+	 * Destroy is skipped if shm_may_destroy() returns false.
+	 */
 	down_write(&shm_ids(ns).rwsem);
-	list_for_each_entry_safe(shp, n, &task->sysvshm.shm_clist, shm_clist)
-		shm_mark_orphan(shp, ns);
-	/* remove the list head from any segments still attached */
+	list_for_each_entry_safe(shp, n, &task->sysvshm.shm_clist, shm_clist) {
+		shp->shm_creator = NULL;
+
+		if (shm_may_destroy(ns, shp)) {
+			shm_lock_by_ptr(shp);
+			shm_destroy(ns, shp);
+		}
+	}
+
+	/* Remove the list head from any segments still attached. */
 	list_del(&task->sysvshm.shm_clist);
 	up_write(&shm_ids(ns).rwsem);
 }

commit ab602f799159393143d567e5c04b936fec79d6bd
Author: Jack Miller <millerjo@us.ibm.com>
Date:   Fri Aug 8 14:23:19 2014 -0700

    shm: make exit_shm work proportional to task activity
    
    This is small set of patches our team has had kicking around for a few
    versions internally that fixes tasks getting hung on shm_exit when there
    are many threads hammering it at once.
    
    Anton wrote a simple test to cause the issue:
    
      http://ozlabs.org/~anton/junkcode/bust_shm_exit.c
    
    Before applying this patchset, this test code will cause either hanging
    tracebacks or pthread out of memory errors.
    
    After this patchset, it will still produce output like:
    
      root@somehost:~# ./bust_shm_exit 1024 160
      ...
      INFO: rcu_sched detected stalls on CPUs/tasks: {} (detected by 116, t=2111 jiffies, g=241, c=240, q=7113)
      INFO: Stall ended before state dump start
      ...
    
    But the task will continue to run along happily, so we consider this an
    improvement over hanging, even if it's a bit noisy.
    
    This patch (of 3):
    
    exit_shm obtains the ipc_ns shm rwsem for write and holds it while it
    walks every shared memory segment in the namespace.  Thus the amount of
    work is related to the number of shm segments in the namespace not the
    number of segments that might need to be cleaned.
    
    In addition, this occurs after the task has been notified the thread has
    exited, so the number of tasks waiting for the ns shm rwsem can grow
    without bound until memory is exausted.
    
    Add a list to the task struct of all shmids allocated by this task.  Init
    the list head in copy_process.  Use the ns->rwsem for locking.  Add
    segments after id is added, remove before removing from id.
    
    On unshare of NEW_IPCNS orphan any ids as if the task had exited, similar
    to handling of semaphore undo.
    
    I chose a define for the init sequence since its a simple list init,
    otherwise it would require a function call to avoid include loops between
    the semaphore code and the task struct.  Converting the list_del to
    list_del_init for the unshare cases would remove the exit followed by
    init, but I left it blow up if not inited.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Jack Miller <millerjo@us.ibm.com>
    Cc: Davidlohr Bueso <davidlohr@hp.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: Anton Blanchard <anton@samba.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 89fc354156cb..1fc3a61b443b 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -178,6 +178,7 @@ static void shm_rcu_free(struct rcu_head *head)
 
 static inline void shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *s)
 {
+	list_del(&s->shm_clist);
 	ipc_rmid(&shm_ids(ns), &s->shm_perm);
 }
 
@@ -268,14 +269,10 @@ static void shm_close(struct vm_area_struct *vma)
 }
 
 /* Called with ns->shm_ids(ns).rwsem locked */
-static int shm_try_destroy_current(int id, void *p, void *data)
+static void shm_mark_orphan(struct shmid_kernel *shp, struct ipc_namespace *ns)
 {
-	struct ipc_namespace *ns = data;
-	struct kern_ipc_perm *ipcp = p;
-	struct shmid_kernel *shp = container_of(ipcp, struct shmid_kernel, shm_perm);
-
-	if (shp->shm_creator != current)
-		return 0;
+	if (WARN_ON(shp->shm_creator != current)) /* Remove me when it works */
+		return;
 
 	/*
 	 * Mark it as orphaned to destroy the segment when
@@ -289,13 +286,12 @@ static int shm_try_destroy_current(int id, void *p, void *data)
 	 * is not set, it shouldn't be deleted here.
 	 */
 	if (!ns->shm_rmid_forced)
-		return 0;
+		return;
 
 	if (shm_may_destroy(ns, shp)) {
 		shm_lock_by_ptr(shp);
 		shm_destroy(ns, shp);
 	}
-	return 0;
 }
 
 /* Called with ns->shm_ids(ns).rwsem locked */
@@ -333,14 +329,17 @@ void shm_destroy_orphaned(struct ipc_namespace *ns)
 void exit_shm(struct task_struct *task)
 {
 	struct ipc_namespace *ns = task->nsproxy->ipc_ns;
+	struct shmid_kernel *shp, *n;
 
 	if (shm_ids(ns).in_use == 0)
 		return;
 
 	/* Destroy all already created segments, but not mapped yet */
 	down_write(&shm_ids(ns).rwsem);
-	if (shm_ids(ns).in_use)
-		idr_for_each(&shm_ids(ns).ipcs_idr, &shm_try_destroy_current, ns);
+	list_for_each_entry_safe(shp, n, &task->sysvshm.shm_clist, shm_clist)
+		shm_mark_orphan(shp, ns);
+	/* remove the list head from any segments still attached */
+	list_del(&task->sysvshm.shm_clist);
 	up_write(&shm_ids(ns).rwsem);
 }
 
@@ -561,6 +560,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	shp->shm_nattch = 0;
 	shp->shm_file = file;
 	shp->shm_creator = current;
+	list_add(&shp->shm_clist, &current->sysvshm.shm_clist);
 
 	/*
 	 * shmid gets reported as "inode#" in /proc/pid/maps.

commit 1376327ce1f790070ec7128b285e2d8965e760a5
Author: Manfred Spraul <manfred@colorfullife.com>
Date:   Fri Jun 6 14:37:41 2014 -0700

    ipc/shm.c: check for integer overflow during shmget.
    
    SHMMAX is the upper limit for the size of a shared memory segment, counted
    in bytes.  The actual allocation is that size, rounded up to the next full
    page.
    
    Add a check that prevents the creation of segments where the rounded up
    size causes an integer overflow.
    
    Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
    Acked-by: Davidlohr Bueso <davidlohr@hp.com>
    Acked-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Acked-by: Michael Kerrisk <mtk.manpages@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 9e51bf246344..89fc354156cb 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -493,6 +493,9 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	if (size < SHMMIN || size > ns->shm_ctlmax)
 		return -EINVAL;
 
+	if (numpages << PAGE_SHIFT < size)
+		return -ENOSPC;
+
 	if (ns->shm_tot + numpages < ns->shm_tot ||
 			ns->shm_tot + numpages > ns->shm_ctlall)
 		return -ENOSPC;

commit 09c6eb1f651dad601f02435bbd79734954960c42
Author: Manfred Spraul <manfred@colorfullife.com>
Date:   Fri Jun 6 14:37:40 2014 -0700

    ipc/shm.c: check for overflows of shm_tot
    
    shm_tot counts the total number of pages used by shm segments.
    
    If SHMALL is ULONG_MAX (or nearly ULONG_MAX), then the number can
    overflow.  Subsequent calls to shmctl(,SHM_INFO,) would return wrong
    values for shm_tot.
    
    The patch adds a detection for overflows.
    
    Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
    Acked-by: Davidlohr Bueso <davidlohr@hp.com>
    Acked-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Acked-by: Michael Kerrisk <mtk.manpages@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index dda8f1ff3c35..9e51bf246344 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -493,7 +493,8 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	if (size < SHMMIN || size > ns->shm_ctlmax)
 		return -EINVAL;
 
-	if (ns->shm_tot + numpages > ns->shm_ctlall)
+	if (ns->shm_tot + numpages < ns->shm_tot ||
+			ns->shm_tot + numpages > ns->shm_ctlall)
 		return -ENOSPC;
 
 	shp = ipc_rcu_alloc(sizeof(*shp));

commit 247a8ce8229b16d4ffa9f5125fb6583aa749679d
Author: Manfred Spraul <manfred@colorfullife.com>
Date:   Fri Jun 6 14:37:38 2014 -0700

    ipc/shm.c: check for ulong overflows in shmat
    
    The increase of SHMMAX/SHMALL is a 4 patch series.
    
    The change itself is trivial, the only problem are interger overflows.
    The overflows are not new, but if we make huge values the default, then
    the code should be free from overflows.
    
    SHMMAX:
    
    - shmmem_file_setup places a hard limit on the segment size:
      MAX_LFS_FILESIZE.
    
      On 32-bit, the limit is > 1 TB, i.e. 4 GB-1 byte segments are
      possible. Rounded up to full pages the actual allocated size
      is 0. --> must be fixed, patch 3
    
    - shmat:
      - find_vma_intersection does not handle overflows properly.
        --> must be fixed, patch 1
    
      - the rest is fine, do_mmap_pgoff limits mappings to TASK_SIZE
        and checks for overflows (i.e.: map 2 GB, starting from
        addr=2.5GB fails).
    
    SHMALL:
    - after creating 8192 segments size (1L<<63)-1, shm_tot overflows and
      returns 0.  --> must be fixed, patch 2.
    
    Userspace:
    - Obviously, there could be overflows in userspace. There is nothing
      we can do, only use values smaller than ULONG_MAX.
      I ended with "ULONG_MAX - 1L<<24":
    
      - TASK_SIZE cannot be used because it is the size of the current
        task. Could be 4G if it's a 32-bit task on a 64-bit kernel.
    
      - The maximum size is not standardized across archs:
        I found TASK_MAX_SIZE, TASK_SIZE_MAX and TASK_SIZE_64.
    
      - Just in case some arch revives a 4G/4G split, nearly
        ULONG_MAX is a valid segment size.
    
      - Using "0" as a magic value for infinity is even worse, because
        right now 0 means 0, i.e. fail all allocations.
    
    This patch (of 4):
    
    find_vma_intersection() does not work as intended if addr+size overflows.
    The patch adds a manual check before the call to find_vma_intersection.
    
    Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
    Acked-by: Davidlohr Bueso <davidlohr@hp.com>
    Acked-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Acked-by: Michael Kerrisk <mtk.manpages@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 2b64b0d25bba..dda8f1ff3c35 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1160,6 +1160,9 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 	down_write(&current->mm->mmap_sem);
 	if (addr && !(shmflg & SHM_REMAP)) {
 		err = -EINVAL;
+		if (addr + size < addr)
+			goto invalid;
+
 		if (find_vma_intersection(current->mm, addr, addr + size))
 			goto invalid;
 		/*

commit 46c0a8ca3e841b14a1d981e2116eaf2d1c7f2235
Author: Paul McQuade <paulmcquad@gmail.com>
Date:   Fri Jun 6 14:37:37 2014 -0700

    ipc, kernel: clear whitespace
    
    trailing whitespace
    
    Signed-off-by: Paul McQuade <paulmcquad@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index fe49fdd240a8..2b64b0d25bba 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -694,7 +694,7 @@ static inline unsigned long copy_shminfo_to_user(void __user *buf, struct shminf
 		out.shmmin	= in->shmmin;
 		out.shmmni	= in->shmmni;
 		out.shmseg	= in->shmseg;
-		out.shmall	= in->shmall; 
+		out.shmall	= in->shmall;
 
 		return copy_to_user(buf, &out, sizeof(out));
 	    }

commit 7153e402731c3e72331633d1ac15a654768aecac
Author: Paul McQuade <paulmcquad@gmail.com>
Date:   Fri Jun 6 14:37:37 2014 -0700

    ipc, kernel: use Linux headers
    
    Use #include <linux/uaccess.h> instead of <asm/uaccess.h>
    Use #include <linux/types.h> instead of <asm/types.h>
    
    Signed-off-by: Paul McQuade <paulmcquad@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index b54c93f6d117..fe49fdd240a8 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -43,7 +43,7 @@
 #include <linux/mount.h>
 #include <linux/ipc_namespace.h>
 
-#include <asm/uaccess.h>
+#include <linux/uaccess.h>
 
 #include "util.h"
 

commit eb66ec44f867834de054544b09b573de3a7ae456
Author: Mathias Krause <minipli@googlemail.com>
Date:   Fri Jun 6 14:37:36 2014 -0700

    ipc: constify ipc_ops
    
    There is no need to recreate the very same ipc_ops structure on every
    kernel entry for msgget/semget/shmget.  Just declare it static and be
    done with it.  While at it, constify it as we don't modify the structure
    at runtime.
    
    Found in the PaX patch, written by the PaX Team.
    
    Signed-off-by: Mathias Krause <minipli@googlemail.com>
    Cc: PaX Team <pageexec@freemail.hu>
    Cc: Davidlohr Bueso <davidlohr@hp.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 76459616a7fa..b54c93f6d117 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -609,15 +609,15 @@ static inline int shm_more_checks(struct kern_ipc_perm *ipcp,
 SYSCALL_DEFINE3(shmget, key_t, key, size_t, size, int, shmflg)
 {
 	struct ipc_namespace *ns;
-	struct ipc_ops shm_ops;
+	static const struct ipc_ops shm_ops = {
+		.getnew = newseg,
+		.associate = shm_security,
+		.more_checks = shm_more_checks,
+	};
 	struct ipc_params shm_params;
 
 	ns = current->nsproxy->ipc_ns;
 
-	shm_ops.getnew = newseg;
-	shm_ops.associate = shm_security;
-	shm_ops.more_checks = shm_more_checks;
-
 	shm_params.key = key;
 	shm_params.flg = shmflg;
 	shm_params.u.size = size;

commit 8001c85810dd2277d75ae60376e840456afa9b7e
Author: Davidlohr Bueso <davidlohr@hp.com>
Date:   Mon Jan 27 17:07:05 2014 -0800

    ipc: standardize code comments
    
    IPC commenting style is all over the place, *specially* in util.c.  This
    patch orders things a bit.
    
    Signed-off-by: Davidlohr Bueso <davidlohr@hp.com>
    Cc: Aswin Chandramouleeswaran <aswin@hp.com>
    Cc: Rik van Riel <riel@redhat.com>
    Acked-by: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 88c59c1e026c..76459616a7fa 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -477,7 +477,6 @@ static const struct vm_operations_struct shm_vm_ops = {
  *
  * Called with shm_ids.rwsem held as a writer.
  */
-
 static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 {
 	key_t key = params->key;

commit 239521f31d7496a5322ee664ed8bbd1027b98c4b
Author: Manfred Spraul <manfred@colorfullife.com>
Date:   Mon Jan 27 17:07:04 2014 -0800

    ipc: whitespace cleanup
    
    The ipc code does not adhere the typical linux coding style.
    This patch fixes lots of simple whitespace errors.
    
    - mostly autogenerated by
      scripts/checkpatch.pl -f --fix \
            --types=pointer_location,spacing,space_before_tab
    - one manual fixup (keep structure members tab-aligned)
    - removal of additional space_before_tab that were not found by --fix
    
    Tested with some of my msg and sem test apps.
    
    Andrew: Could you include it in -mm and move it towards Linus' tree?
    
    Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
    Suggested-by: Li Bin <huawei.libin@huawei.com>
    Cc: Joe Perches <joe@perches.com>
    Acked-by: Rafael Aquini <aquini@redhat.com>
    Cc: Davidlohr Bueso <davidlohr@hp.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 1bc68f115842..88c59c1e026c 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -67,7 +67,7 @@ static const struct vm_operations_struct shm_vm_ops;
 static int newseg(struct ipc_namespace *, struct ipc_params *);
 static void shm_open(struct vm_area_struct *vma);
 static void shm_close(struct vm_area_struct *vma);
-static void shm_destroy (struct ipc_namespace *ns, struct shmid_kernel *shp);
+static void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp);
 #ifdef CONFIG_PROC_FS
 static int sysvipc_shm_proc_show(struct seq_file *s, void *it);
 #endif
@@ -91,7 +91,7 @@ static void do_shm_rmid(struct ipc_namespace *ns, struct kern_ipc_perm *ipcp)
 	struct shmid_kernel *shp;
 	shp = container_of(ipcp, struct shmid_kernel, shm_perm);
 
-	if (shp->shm_nattch){
+	if (shp->shm_nattch) {
 		shp->shm_perm.mode |= SHM_DEST;
 		/* Do not find it any more */
 		shp->shm_perm.key = IPC_PRIVATE;
@@ -116,7 +116,7 @@ static int __init ipc_ns_init(void)
 
 pure_initcall(ipc_ns_init);
 
-void __init shm_init (void)
+void __init shm_init(void)
 {
 	ipc_init_proc_interface("sysvipc/shm",
 #if BITS_PER_LONG <= 32
@@ -248,7 +248,7 @@ static bool shm_may_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)
  */
 static void shm_close(struct vm_area_struct *vma)
 {
-	struct file * file = vma->vm_file;
+	struct file *file = vma->vm_file;
 	struct shm_file_data *sfd = shm_file_data(file);
 	struct shmid_kernel *shp;
 	struct ipc_namespace *ns = sfd->ns;
@@ -379,7 +379,7 @@ static struct mempolicy *shm_get_policy(struct vm_area_struct *vma,
 }
 #endif
 
-static int shm_mmap(struct file * file, struct vm_area_struct * vma)
+static int shm_mmap(struct file *file, struct vm_area_struct *vma)
 {
 	struct shm_file_data *sfd = shm_file_data(file);
 	int ret;
@@ -486,7 +486,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	int error;
 	struct shmid_kernel *shp;
 	size_t numpages = (size + PAGE_SIZE - 1) >> PAGE_SHIFT;
-	struct file * file;
+	struct file *file;
 	char name[13];
 	int id;
 	vm_flags_t acctflag = 0;
@@ -512,7 +512,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 		return error;
 	}
 
-	sprintf (name, "SYSV%08x", key);
+	sprintf(name, "SYSV%08x", key);
 	if (shmflg & SHM_HUGETLB) {
 		struct hstate *hs;
 		size_t hugesize;
@@ -533,7 +533,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	} else {
 		/*
 		 * Do not allow no accounting for OVERCOMMIT_NEVER, even
-	 	 * if it's asked for.
+		 * if it's asked for.
 		 */
 		if  ((shmflg & SHM_NORESERVE) &&
 				sysctl_overcommit_memory != OVERCOMMIT_NEVER)
@@ -628,7 +628,7 @@ SYSCALL_DEFINE3(shmget, key_t, key, size_t, size, int, shmflg)
 
 static inline unsigned long copy_shmid_to_user(void __user *buf, struct shmid64_ds *in, int version)
 {
-	switch(version) {
+	switch (version) {
 	case IPC_64:
 		return copy_to_user(buf, in, sizeof(*in));
 	case IPC_OLD:
@@ -655,7 +655,7 @@ static inline unsigned long copy_shmid_to_user(void __user *buf, struct shmid64_
 static inline unsigned long
 copy_shmid_from_user(struct shmid64_ds *out, void __user *buf, int version)
 {
-	switch(version) {
+	switch (version) {
 	case IPC_64:
 		if (copy_from_user(out, buf, sizeof(*out)))
 			return -EFAULT;
@@ -680,14 +680,14 @@ copy_shmid_from_user(struct shmid64_ds *out, void __user *buf, int version)
 
 static inline unsigned long copy_shminfo_to_user(void __user *buf, struct shminfo64 *in, int version)
 {
-	switch(version) {
+	switch (version) {
 	case IPC_64:
 		return copy_to_user(buf, in, sizeof(*in));
 	case IPC_OLD:
 	    {
 		struct shminfo out;
 
-		if(in->shmmax > INT_MAX)
+		if (in->shmmax > INT_MAX)
 			out.shmmax = INT_MAX;
 		else
 			out.shmmax = (int)in->shmmax;
@@ -846,14 +846,14 @@ static int shmctl_nolock(struct ipc_namespace *ns, int shmid,
 		shminfo.shmall = ns->shm_ctlall;
 
 		shminfo.shmmin = SHMMIN;
-		if(copy_shminfo_to_user (buf, &shminfo, version))
+		if (copy_shminfo_to_user(buf, &shminfo, version))
 			return -EFAULT;
 
 		down_read(&shm_ids(ns).rwsem);
 		err = ipc_get_maxid(&shm_ids(ns));
 		up_read(&shm_ids(ns).rwsem);
 
-		if(err<0)
+		if (err < 0)
 			err = 0;
 		goto out;
 	}
@@ -864,7 +864,7 @@ static int shmctl_nolock(struct ipc_namespace *ns, int shmid,
 		memset(&shm_info, 0, sizeof(shm_info));
 		down_read(&shm_ids(ns).rwsem);
 		shm_info.used_ids = shm_ids(ns).in_use;
-		shm_get_stat (ns, &shm_info.shm_rss, &shm_info.shm_swp);
+		shm_get_stat(ns, &shm_info.shm_rss, &shm_info.shm_swp);
 		shm_info.shm_tot = ns->shm_tot;
 		shm_info.swap_attempts = 0;
 		shm_info.swap_successes = 0;
@@ -1047,7 +1047,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 	struct shmid_kernel *shp;
 	unsigned long addr;
 	unsigned long size;
-	struct file * file;
+	struct file *file;
 	int    err;
 	unsigned long flags;
 	unsigned long prot;

commit 0f3d2b0135f4bdbfe47a99753923a64efd373d11
Author: Rafael Aquini <aquini@redhat.com>
Date:   Mon Jan 27 17:07:01 2014 -0800

    ipc: introduce ipc_valid_object() helper to sort out IPC_RMID races
    
    After the locking semantics for the SysV IPC API got improved, a couple
    of IPC_RMID race windows were opened because we ended up dropping the
    'kern_ipc_perm.deleted' check performed way down in ipc_lock().  The
    spotted races got sorted out by re-introducing the old test within the
    racy critical sections.
    
    This patch introduces ipc_valid_object() to consolidate the way we cope
    with IPC_RMID races by using the same abstraction across the API
    implementation.
    
    Signed-off-by: Rafael Aquini <aquini@redhat.com>
    Acked-by: Rik van Riel <riel@redhat.com>
    Acked-by: Greg Thelen <gthelen@google.com>
    Reviewed-by: Davidlohr Bueso <davidlohr@hp.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 7a51443a51d6..1bc68f115842 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -975,6 +975,13 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 			goto out_unlock1;
 
 		ipc_lock_object(&shp->shm_perm);
+
+		/* check if shm_destroy() is tearing down shp */
+		if (!ipc_valid_object(&shp->shm_perm)) {
+			err = -EIDRM;
+			goto out_unlock0;
+		}
+
 		if (!ns_capable(ns->user_ns, CAP_IPC_LOCK)) {
 			kuid_t euid = current_euid();
 			if (!uid_eq(euid, shp->shm_perm.uid) &&
@@ -989,13 +996,6 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 		}
 
 		shm_file = shp->shm_file;
-
-		/* check if shm_destroy() is tearing down shp */
-		if (shm_file == NULL) {
-			err = -EIDRM;
-			goto out_unlock0;
-		}
-
 		if (is_file_hugepages(shm_file))
 			goto out_unlock0;
 
@@ -1116,7 +1116,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 	ipc_lock_object(&shp->shm_perm);
 
 	/* check if shm_destroy() is tearing down shp */
-	if (shp->shm_file == NULL) {
+	if (!ipc_valid_object(&shp->shm_perm)) {
 		ipc_unlock_object(&shp->shm_perm);
 		err = -EIDRM;
 		goto out_unlock;

commit 3a72660b07d86d60457ca32080b1ce8c2b628ee2
Author: Jesper Nilsson <jesper.nilsson@axis.com>
Date:   Thu Nov 21 14:32:08 2013 -0800

    ipc,shm: correct error return value in shmctl (SHM_UNLOCK)
    
    Commit 2caacaa82a51 ("ipc,shm: shorten critical region for shmctl")
    restructured the ipc shm to shorten critical region, but introduced a
    path where the return value could be -EPERM, even if the operation
    actually was performed.
    
    Before the commit, the err return value was reset by the return value
    from security_shm_shmctl() after the if (!ns_capable(...)) statement.
    
    Now, we still exit the if statement with err set to -EPERM, and in the
    case of SHM_UNLOCK, it is not reset at all, and used as the return value
    from shmctl.
    
    To fix this, we only set err when errors occur, leaving the fallthrough
    case alone.
    
    Signed-off-by: Jesper Nilsson <jesper.nilsson@axis.com>
    Cc: Davidlohr Bueso <davidlohr@hp.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: <stable@vger.kernel.org>    [3.12.x]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 0bdf21c6814e..7a51443a51d6 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -977,12 +977,15 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 		ipc_lock_object(&shp->shm_perm);
 		if (!ns_capable(ns->user_ns, CAP_IPC_LOCK)) {
 			kuid_t euid = current_euid();
-			err = -EPERM;
 			if (!uid_eq(euid, shp->shm_perm.uid) &&
-			    !uid_eq(euid, shp->shm_perm.cuid))
+			    !uid_eq(euid, shp->shm_perm.cuid)) {
+				err = -EPERM;
 				goto out_unlock0;
-			if (cmd == SHM_LOCK && !rlimit(RLIMIT_MEMLOCK))
+			}
+			if (cmd == SHM_LOCK && !rlimit(RLIMIT_MEMLOCK)) {
+				err = -EPERM;
 				goto out_unlock0;
+			}
 		}
 
 		shm_file = shp->shm_file;

commit a399b29dfbaaaf91162b2dc5a5875dd51bbfa2a1
Author: Greg Thelen <gthelen@google.com>
Date:   Thu Nov 21 14:32:00 2013 -0800

    ipc,shm: fix shm_file deletion races
    
    When IPC_RMID races with other shm operations there's potential for
    use-after-free of the shm object's associated file (shm_file).
    
    Here's the race before this patch:
    
      TASK 1                     TASK 2
      ------                     ------
      shm_rmid()
        ipc_lock_object()
                                 shmctl()
                                 shp = shm_obtain_object_check()
    
        shm_destroy()
          shum_unlock()
          fput(shp->shm_file)
                                 ipc_lock_object()
                                 shmem_lock(shp->shm_file)
                                 <OOPS>
    
    The oops is caused because shm_destroy() calls fput() after dropping the
    ipc_lock.  fput() clears the file's f_inode, f_path.dentry, and
    f_path.mnt, which causes various NULL pointer references in task 2.  I
    reliably see the oops in task 2 if with shmlock, shmu
    
    This patch fixes the races by:
    1) set shm_file=NULL in shm_destroy() while holding ipc_object_lock().
    2) modify at risk operations to check shm_file while holding
       ipc_object_lock().
    
    Example workloads, which each trigger oops...
    
    Workload 1:
      while true; do
        id=$(shmget 1 4096)
        shm_rmid $id &
        shmlock $id &
        wait
      done
    
      The oops stack shows accessing NULL f_inode due to racing fput:
        _raw_spin_lock
        shmem_lock
        SyS_shmctl
    
    Workload 2:
      while true; do
        id=$(shmget 1 4096)
        shmat $id 4096 &
        shm_rmid $id &
        wait
      done
    
      The oops stack is similar to workload 1 due to NULL f_inode:
        touch_atime
        shmem_mmap
        shm_mmap
        mmap_region
        do_mmap_pgoff
        do_shmat
        SyS_shmat
    
    Workload 3:
      while true; do
        id=$(shmget 1 4096)
        shmlock $id
        shm_rmid $id &
        shmunlock $id &
        wait
      done
    
      The oops stack shows second fput tripping on an NULL f_inode.  The
      first fput() completed via from shm_destroy(), but a racing thread did
      a get_file() and queued this fput():
        locks_remove_flock
        __fput
        ____fput
        task_work_run
        do_notify_resume
        int_signal
    
    Fixes: c2c737a0461e ("ipc,shm: shorten critical region for shmat")
    Fixes: 2caacaa82a51 ("ipc,shm: shorten critical region for shmctl")
    Signed-off-by: Greg Thelen <gthelen@google.com>
    Cc: Davidlohr Bueso <davidlohr@hp.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: <stable@vger.kernel.org>  # 3.10.17+ 3.11.6+
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index d69739610fd4..0bdf21c6814e 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -208,15 +208,18 @@ static void shm_open(struct vm_area_struct *vma)
  */
 static void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)
 {
+	struct file *shm_file;
+
+	shm_file = shp->shm_file;
+	shp->shm_file = NULL;
 	ns->shm_tot -= (shp->shm_segsz + PAGE_SIZE - 1) >> PAGE_SHIFT;
 	shm_rmid(ns, shp);
 	shm_unlock(shp);
-	if (!is_file_hugepages(shp->shm_file))
-		shmem_lock(shp->shm_file, 0, shp->mlock_user);
+	if (!is_file_hugepages(shm_file))
+		shmem_lock(shm_file, 0, shp->mlock_user);
 	else if (shp->mlock_user)
-		user_shm_unlock(file_inode(shp->shm_file)->i_size,
-						shp->mlock_user);
-	fput (shp->shm_file);
+		user_shm_unlock(file_inode(shm_file)->i_size, shp->mlock_user);
+	fput(shm_file);
 	ipc_rcu_putref(shp, shm_rcu_free);
 }
 
@@ -983,6 +986,13 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 		}
 
 		shm_file = shp->shm_file;
+
+		/* check if shm_destroy() is tearing down shp */
+		if (shm_file == NULL) {
+			err = -EIDRM;
+			goto out_unlock0;
+		}
+
 		if (is_file_hugepages(shm_file))
 			goto out_unlock0;
 
@@ -1101,6 +1111,14 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 		goto out_unlock;
 
 	ipc_lock_object(&shp->shm_perm);
+
+	/* check if shm_destroy() is tearing down shp */
+	if (shp->shm_file == NULL) {
+		ipc_unlock_object(&shp->shm_perm);
+		err = -EIDRM;
+		goto out_unlock;
+	}
+
 	path = shp->shm_file->f_path;
 	path_get(&path);
 	shp->shm_nattch++;

commit 53dad6d3a8e5ac1af8bacc6ac2134ae1a8b085f1
Author: Davidlohr Bueso <davidlohr@hp.com>
Date:   Mon Sep 23 17:04:45 2013 -0700

    ipc: fix race with LSMs
    
    Currently, IPC mechanisms do security and auditing related checks under
    RCU.  However, since security modules can free the security structure,
    for example, through selinux_[sem,msg_queue,shm]_free_security(), we can
    race if the structure is freed before other tasks are done with it,
    creating a use-after-free condition.  Manfred illustrates this nicely,
    for instance with shared mem and selinux:
    
     -> do_shmat calls rcu_read_lock()
     -> do_shmat calls shm_object_check().
         Checks that the object is still valid - but doesn't acquire any locks.
         Then it returns.
     -> do_shmat calls security_shm_shmat (e.g. selinux_shm_shmat)
     -> selinux_shm_shmat calls ipc_has_perm()
     -> ipc_has_perm accesses ipc_perms->security
    
    shm_close()
     -> shm_close acquires rw_mutex & shm_lock
     -> shm_close calls shm_destroy
     -> shm_destroy calls security_shm_free (e.g. selinux_shm_free_security)
     -> selinux_shm_free_security calls ipc_free_security(&shp->shm_perm)
     -> ipc_free_security calls kfree(ipc_perms->security)
    
    This patch delays the freeing of the security structures after all RCU
    readers are done.  Furthermore it aligns the security life cycle with
    that of the rest of IPC - freeing them based on the reference counter.
    For situations where we need not free security, the current behavior is
    kept.  Linus states:
    
     "... the old behavior was suspect for another reason too: having the
      security blob go away from under a user sounds like it could cause
      various other problems anyway, so I think the old code was at least
      _prone_ to bugs even if it didn't have catastrophic behavior."
    
    I have tested this patch with IPC testcases from LTP on both my
    quad-core laptop and on a 64 core NUMA server.  In both cases selinux is
    enabled, and tests pass for both voluntary and forced preemption models.
    While the mentioned races are theoretical (at least no one as reported
    them), I wanted to make sure that this new logic doesn't break anything
    we weren't aware of.
    
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Davidlohr Bueso <davidlohr@hp.com>
    Acked-by: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 2821cdf93adb..d69739610fd4 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -167,6 +167,15 @@ static inline void shm_lock_by_ptr(struct shmid_kernel *ipcp)
 	ipc_lock_object(&ipcp->shm_perm);
 }
 
+static void shm_rcu_free(struct rcu_head *head)
+{
+	struct ipc_rcu *p = container_of(head, struct ipc_rcu, rcu);
+	struct shmid_kernel *shp = ipc_rcu_to_struct(p);
+
+	security_shm_free(shp);
+	ipc_rcu_free(head);
+}
+
 static inline void shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *s)
 {
 	ipc_rmid(&shm_ids(ns), &s->shm_perm);
@@ -208,8 +217,7 @@ static void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)
 		user_shm_unlock(file_inode(shp->shm_file)->i_size,
 						shp->mlock_user);
 	fput (shp->shm_file);
-	security_shm_free(shp);
-	ipc_rcu_putref(shp);
+	ipc_rcu_putref(shp, shm_rcu_free);
 }
 
 /*
@@ -497,7 +505,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	shp->shm_perm.security = NULL;
 	error = security_shm_alloc(shp);
 	if (error) {
-		ipc_rcu_putref(shp);
+		ipc_rcu_putref(shp, ipc_rcu_free);
 		return error;
 	}
 
@@ -566,8 +574,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 		user_shm_unlock(size, shp->mlock_user);
 	fput(file);
 no_file:
-	security_shm_free(shp);
-	ipc_rcu_putref(shp);
+	ipc_rcu_putref(shp, shm_rcu_free);
 	return error;
 }
 

commit 7a25dd9e042b2b94202a67e5551112f4ac87285a
Author: Davidlohr Bueso <davidlohr.bueso@hp.com>
Date:   Wed Sep 11 14:26:30 2013 -0700

    ipc, shm: drop shm_lock_check
    
    This function was replaced by a the lockless shm_obtain_object_check(),
    and no longer has any users.
    
    Signed-off-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Cc: Sedat Dilek <sedat.dilek@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index a0ed957cefc9..2821cdf93adb 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -167,17 +167,6 @@ static inline void shm_lock_by_ptr(struct shmid_kernel *ipcp)
 	ipc_lock_object(&ipcp->shm_perm);
 }
 
-static inline struct shmid_kernel *shm_lock_check(struct ipc_namespace *ns,
-						int id)
-{
-	struct kern_ipc_perm *ipcp = ipc_lock_check(&shm_ids(ns), id);
-
-	if (IS_ERR(ipcp))
-		return (struct shmid_kernel *)ipcp;
-
-	return container_of(ipcp, struct shmid_kernel, shm_perm);
-}
-
 static inline void shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *s)
 {
 	ipc_rmid(&shm_ids(ns), &s->shm_perm);

commit 530fcd16d87cd2417c472a581ba5a1e501556c86
Author: Davidlohr Bueso <davidlohr.bueso@hp.com>
Date:   Wed Sep 11 14:26:28 2013 -0700

    ipc, shm: guard against non-existant vma in shmdt(2)
    
    When !CONFIG_MMU there's a chance we can derefence a NULL pointer when the
    VM area isn't found - check the return value of find_vma().
    
    Also, remove the redundant -EINVAL return: retval is set to the proper
    return code and *only* changed to 0, when we actually unmap the segments.
    
    Signed-off-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Cc: Sedat Dilek <sedat.dilek@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index cb2cedaa8808..a0ed957cefc9 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1288,8 +1288,7 @@ SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 #else /* CONFIG_MMU */
 	/* under NOMMU conditions, the exact address to be destroyed must be
 	 * given */
-	retval = -EINVAL;
-	if (vma->vm_start == addr && vma->vm_ops == &shm_vm_ops) {
+	if (vma && vma->vm_start == addr && vma->vm_ops == &shm_vm_ops) {
 		do_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start);
 		retval = 0;
 	}

commit d9a605e40b1376eb02b067d7690580255a0df68f
Author: Davidlohr Bueso <davidlohr.bueso@hp.com>
Date:   Wed Sep 11 14:26:24 2013 -0700

    ipc: rename ids->rw_mutex
    
    Since in some situations the lock can be shared for readers, we shouldn't
    be calling it a mutex, rename it to rwsem.
    
    Signed-off-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Tested-by: Sedat Dilek <sedat.dilek@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 28d19f4ece4b..cb2cedaa8808 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -83,8 +83,8 @@ void shm_init_ns(struct ipc_namespace *ns)
 }
 
 /*
- * Called with shm_ids.rw_mutex (writer) and the shp structure locked.
- * Only shm_ids.rw_mutex remains locked on exit.
+ * Called with shm_ids.rwsem (writer) and the shp structure locked.
+ * Only shm_ids.rwsem remains locked on exit.
  */
 static void do_shm_rmid(struct ipc_namespace *ns, struct kern_ipc_perm *ipcp)
 {
@@ -148,7 +148,7 @@ static inline struct shmid_kernel *shm_obtain_object_check(struct ipc_namespace
 }
 
 /*
- * shm_lock_(check_) routines are called in the paths where the rw_mutex
+ * shm_lock_(check_) routines are called in the paths where the rwsem
  * is not necessarily held.
  */
 static inline struct shmid_kernel *shm_lock(struct ipc_namespace *ns, int id)
@@ -205,7 +205,7 @@ static void shm_open(struct vm_area_struct *vma)
  * @ns: namespace
  * @shp: struct to free
  *
- * It has to be called with shp and shm_ids.rw_mutex (writer) locked,
+ * It has to be called with shp and shm_ids.rwsem (writer) locked,
  * but returns with shp unlocked and freed.
  */
 static void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)
@@ -253,7 +253,7 @@ static void shm_close(struct vm_area_struct *vma)
 	struct shmid_kernel *shp;
 	struct ipc_namespace *ns = sfd->ns;
 
-	down_write(&shm_ids(ns).rw_mutex);
+	down_write(&shm_ids(ns).rwsem);
 	/* remove from the list of attaches of the shm segment */
 	shp = shm_lock(ns, sfd->id);
 	BUG_ON(IS_ERR(shp));
@@ -264,10 +264,10 @@ static void shm_close(struct vm_area_struct *vma)
 		shm_destroy(ns, shp);
 	else
 		shm_unlock(shp);
-	up_write(&shm_ids(ns).rw_mutex);
+	up_write(&shm_ids(ns).rwsem);
 }
 
-/* Called with ns->shm_ids(ns).rw_mutex locked */
+/* Called with ns->shm_ids(ns).rwsem locked */
 static int shm_try_destroy_current(int id, void *p, void *data)
 {
 	struct ipc_namespace *ns = data;
@@ -298,7 +298,7 @@ static int shm_try_destroy_current(int id, void *p, void *data)
 	return 0;
 }
 
-/* Called with ns->shm_ids(ns).rw_mutex locked */
+/* Called with ns->shm_ids(ns).rwsem locked */
 static int shm_try_destroy_orphaned(int id, void *p, void *data)
 {
 	struct ipc_namespace *ns = data;
@@ -309,7 +309,7 @@ static int shm_try_destroy_orphaned(int id, void *p, void *data)
 	 * We want to destroy segments without users and with already
 	 * exit'ed originating process.
 	 *
-	 * As shp->* are changed under rw_mutex, it's safe to skip shp locking.
+	 * As shp->* are changed under rwsem, it's safe to skip shp locking.
 	 */
 	if (shp->shm_creator != NULL)
 		return 0;
@@ -323,10 +323,10 @@ static int shm_try_destroy_orphaned(int id, void *p, void *data)
 
 void shm_destroy_orphaned(struct ipc_namespace *ns)
 {
-	down_write(&shm_ids(ns).rw_mutex);
+	down_write(&shm_ids(ns).rwsem);
 	if (shm_ids(ns).in_use)
 		idr_for_each(&shm_ids(ns).ipcs_idr, &shm_try_destroy_orphaned, ns);
-	up_write(&shm_ids(ns).rw_mutex);
+	up_write(&shm_ids(ns).rwsem);
 }
 
 
@@ -338,10 +338,10 @@ void exit_shm(struct task_struct *task)
 		return;
 
 	/* Destroy all already created segments, but not mapped yet */
-	down_write(&shm_ids(ns).rw_mutex);
+	down_write(&shm_ids(ns).rwsem);
 	if (shm_ids(ns).in_use)
 		idr_for_each(&shm_ids(ns).ipcs_idr, &shm_try_destroy_current, ns);
-	up_write(&shm_ids(ns).rw_mutex);
+	up_write(&shm_ids(ns).rwsem);
 }
 
 static int shm_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
@@ -475,7 +475,7 @@ static const struct vm_operations_struct shm_vm_ops = {
  * @ns: namespace
  * @params: ptr to the structure that contains key, size and shmflg
  *
- * Called with shm_ids.rw_mutex held as a writer.
+ * Called with shm_ids.rwsem held as a writer.
  */
 
 static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
@@ -583,7 +583,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 }
 
 /*
- * Called with shm_ids.rw_mutex and ipcp locked.
+ * Called with shm_ids.rwsem and ipcp locked.
  */
 static inline int shm_security(struct kern_ipc_perm *ipcp, int shmflg)
 {
@@ -594,7 +594,7 @@ static inline int shm_security(struct kern_ipc_perm *ipcp, int shmflg)
 }
 
 /*
- * Called with shm_ids.rw_mutex and ipcp locked.
+ * Called with shm_ids.rwsem and ipcp locked.
  */
 static inline int shm_more_checks(struct kern_ipc_perm *ipcp,
 				struct ipc_params *params)
@@ -707,7 +707,7 @@ static inline unsigned long copy_shminfo_to_user(void __user *buf, struct shminf
 
 /*
  * Calculate and add used RSS and swap pages of a shm.
- * Called with shm_ids.rw_mutex held as a reader
+ * Called with shm_ids.rwsem held as a reader
  */
 static void shm_add_rss_swap(struct shmid_kernel *shp,
 	unsigned long *rss_add, unsigned long *swp_add)
@@ -734,7 +734,7 @@ static void shm_add_rss_swap(struct shmid_kernel *shp,
 }
 
 /*
- * Called with shm_ids.rw_mutex held as a reader
+ * Called with shm_ids.rwsem held as a reader
  */
 static void shm_get_stat(struct ipc_namespace *ns, unsigned long *rss,
 		unsigned long *swp)
@@ -763,9 +763,9 @@ static void shm_get_stat(struct ipc_namespace *ns, unsigned long *rss,
 }
 
 /*
- * This function handles some shmctl commands which require the rw_mutex
+ * This function handles some shmctl commands which require the rwsem
  * to be held in write mode.
- * NOTE: no locks must be held, the rw_mutex is taken inside this function.
+ * NOTE: no locks must be held, the rwsem is taken inside this function.
  */
 static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 		       struct shmid_ds __user *buf, int version)
@@ -780,7 +780,7 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 			return -EFAULT;
 	}
 
-	down_write(&shm_ids(ns).rw_mutex);
+	down_write(&shm_ids(ns).rwsem);
 	rcu_read_lock();
 
 	ipcp = ipcctl_pre_down_nolock(ns, &shm_ids(ns), shmid, cmd,
@@ -819,7 +819,7 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 out_unlock1:
 	rcu_read_unlock();
 out_up:
-	up_write(&shm_ids(ns).rw_mutex);
+	up_write(&shm_ids(ns).rwsem);
 	return err;
 }
 
@@ -850,9 +850,9 @@ static int shmctl_nolock(struct ipc_namespace *ns, int shmid,
 		if(copy_shminfo_to_user (buf, &shminfo, version))
 			return -EFAULT;
 
-		down_read(&shm_ids(ns).rw_mutex);
+		down_read(&shm_ids(ns).rwsem);
 		err = ipc_get_maxid(&shm_ids(ns));
-		up_read(&shm_ids(ns).rw_mutex);
+		up_read(&shm_ids(ns).rwsem);
 
 		if(err<0)
 			err = 0;
@@ -863,14 +863,14 @@ static int shmctl_nolock(struct ipc_namespace *ns, int shmid,
 		struct shm_info shm_info;
 
 		memset(&shm_info, 0, sizeof(shm_info));
-		down_read(&shm_ids(ns).rw_mutex);
+		down_read(&shm_ids(ns).rwsem);
 		shm_info.used_ids = shm_ids(ns).in_use;
 		shm_get_stat (ns, &shm_info.shm_rss, &shm_info.shm_swp);
 		shm_info.shm_tot = ns->shm_tot;
 		shm_info.swap_attempts = 0;
 		shm_info.swap_successes = 0;
 		err = ipc_get_maxid(&shm_ids(ns));
-		up_read(&shm_ids(ns).rw_mutex);
+		up_read(&shm_ids(ns).rwsem);
 		if (copy_to_user(buf, &shm_info, sizeof(shm_info))) {
 			err = -EFAULT;
 			goto out;
@@ -1169,7 +1169,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 	fput(file);
 
 out_nattch:
-	down_write(&shm_ids(ns).rw_mutex);
+	down_write(&shm_ids(ns).rwsem);
 	shp = shm_lock(ns, shmid);
 	BUG_ON(IS_ERR(shp));
 	shp->shm_nattch--;
@@ -1177,7 +1177,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 		shm_destroy(ns, shp);
 	else
 		shm_unlock(shp);
-	up_write(&shm_ids(ns).rw_mutex);
+	up_write(&shm_ids(ns).rwsem);
 	return err;
 
 out_unlock:

commit c2c737a0461e61a34676bd0bd1bc1a70a1b4e396
Author: Davidlohr Bueso <davidlohr.bueso@hp.com>
Date:   Wed Sep 11 14:26:23 2013 -0700

    ipc,shm: shorten critical region for shmat
    
    Similar to other system calls, acquire the kern_ipc_perm lock after doing
    the initial permission and security checks.
    
    [sasha.levin@oracle.com: dont leave do_shmat with rcu lock held]
    Signed-off-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Tested-by: Sedat Dilek <sedat.dilek@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Sasha Levin <sasha.levin@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 115dccebc63e..28d19f4ece4b 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -19,6 +19,9 @@
  * namespaces support
  * OpenVZ, SWsoft Inc.
  * Pavel Emelianov <xemul@openvz.org>
+ *
+ * Better ipc lock (kern_ipc_perm.lock) handling
+ * Davidlohr Bueso <davidlohr.bueso@hp.com>, June 2013.
  */
 
 #include <linux/slab.h>
@@ -1086,10 +1089,11 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 	 * additional creator id...
 	 */
 	ns = current->nsproxy->ipc_ns;
-	shp = shm_lock_check(ns, shmid);
+	rcu_read_lock();
+	shp = shm_obtain_object_check(ns, shmid);
 	if (IS_ERR(shp)) {
 		err = PTR_ERR(shp);
-		goto out;
+		goto out_unlock;
 	}
 
 	err = -EACCES;
@@ -1100,11 +1104,13 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 	if (err)
 		goto out_unlock;
 
+	ipc_lock_object(&shp->shm_perm);
 	path = shp->shm_file->f_path;
 	path_get(&path);
 	shp->shm_nattch++;
 	size = i_size_read(path.dentry->d_inode);
-	shm_unlock(shp);
+	ipc_unlock_object(&shp->shm_perm);
+	rcu_read_unlock();
 
 	err = -ENOMEM;
 	sfd = kzalloc(sizeof(*sfd), GFP_KERNEL);
@@ -1175,7 +1181,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 	return err;
 
 out_unlock:
-	shm_unlock(shp);
+	rcu_read_unlock();
 out:
 	return err;
 }

commit f42569b1388b1408b574a5e93a23a663647d4181
Author: Davidlohr Bueso <davidlohr.bueso@hp.com>
Date:   Wed Sep 11 14:26:22 2013 -0700

    ipc,shm: cleanup do_shmat pasta
    
    Clean up some of the messy do_shmat() spaghetti code, getting rid of
    out_free and out_put_dentry labels.  This makes shortening the critical
    region of this function in the next patch a little easier to do and read.
    
    Signed-off-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Tested-by: Sedat Dilek <sedat.dilek@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 8ec381085dec..115dccebc63e 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1108,16 +1108,21 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 
 	err = -ENOMEM;
 	sfd = kzalloc(sizeof(*sfd), GFP_KERNEL);
-	if (!sfd)
-		goto out_put_dentry;
+	if (!sfd) {
+		path_put(&path);
+		goto out_nattch;
+	}
 
 	file = alloc_file(&path, f_mode,
 			  is_file_hugepages(shp->shm_file) ?
 				&shm_file_operations_huge :
 				&shm_file_operations);
 	err = PTR_ERR(file);
-	if (IS_ERR(file))
-		goto out_free;
+	if (IS_ERR(file)) {
+		kfree(sfd);
+		path_put(&path);
+		goto out_nattch;
+	}
 
 	file->private_data = sfd;
 	file->f_mapping = shp->shm_file->f_mapping;
@@ -1143,7 +1148,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 		    addr > current->mm->start_stack - size - PAGE_SIZE * 5)
 			goto invalid;
 	}
-		
+
 	addr = do_mmap_pgoff(file, addr, size, prot, flags, 0, &populate);
 	*raddr = addr;
 	err = 0;
@@ -1167,19 +1172,12 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 	else
 		shm_unlock(shp);
 	up_write(&shm_ids(ns).rw_mutex);
-
-out:
 	return err;
 
 out_unlock:
 	shm_unlock(shp);
-	goto out;
-
-out_free:
-	kfree(sfd);
-out_put_dentry:
-	path_put(&path);
-	goto out_nattch;
+out:
+	return err;
 }
 
 SYSCALL_DEFINE3(shmat, int, shmid, char __user *, shmaddr, int, shmflg)

commit 2caacaa82a51b78fc0c800e206473874094287ed
Author: Davidlohr Bueso <davidlohr.bueso@hp.com>
Date:   Wed Sep 11 14:26:21 2013 -0700

    ipc,shm: shorten critical region for shmctl
    
    With the *_INFO, *_STAT, IPC_RMID and IPC_SET commands already optimized,
    deal with the remaining SHM_LOCK and SHM_UNLOCK commands.  Take the
    shm_perm lock after doing the initial auditing and security checks.  The
    rest of the logic remains unchanged.
    
    Signed-off-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Tested-by: Sedat Dilek <sedat.dilek@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index a493639550d9..8ec381085dec 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -940,10 +940,8 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 	int err, version;
 	struct ipc_namespace *ns;
 
-	if (cmd < 0 || shmid < 0) {
-		err = -EINVAL;
-		goto out;
-	}
+	if (cmd < 0 || shmid < 0)
+		return -EINVAL;
 
 	version = ipc_parse_version(&cmd);
 	ns = current->nsproxy->ipc_ns;
@@ -954,36 +952,40 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 	case SHM_STAT:
 	case IPC_STAT:
 		return shmctl_nolock(ns, shmid, cmd, version, buf);
+	case IPC_RMID:
+	case IPC_SET:
+		return shmctl_down(ns, shmid, cmd, buf, version);
 	case SHM_LOCK:
 	case SHM_UNLOCK:
 	{
 		struct file *shm_file;
 
-		shp = shm_lock_check(ns, shmid);
+		rcu_read_lock();
+		shp = shm_obtain_object_check(ns, shmid);
 		if (IS_ERR(shp)) {
 			err = PTR_ERR(shp);
-			goto out;
+			goto out_unlock1;
 		}
 
 		audit_ipc_obj(&(shp->shm_perm));
+		err = security_shm_shmctl(shp, cmd);
+		if (err)
+			goto out_unlock1;
 
+		ipc_lock_object(&shp->shm_perm);
 		if (!ns_capable(ns->user_ns, CAP_IPC_LOCK)) {
 			kuid_t euid = current_euid();
 			err = -EPERM;
 			if (!uid_eq(euid, shp->shm_perm.uid) &&
 			    !uid_eq(euid, shp->shm_perm.cuid))
-				goto out_unlock;
+				goto out_unlock0;
 			if (cmd == SHM_LOCK && !rlimit(RLIMIT_MEMLOCK))
-				goto out_unlock;
+				goto out_unlock0;
 		}
 
-		err = security_shm_shmctl(shp, cmd);
-		if (err)
-			goto out_unlock;
-
 		shm_file = shp->shm_file;
 		if (is_file_hugepages(shm_file))
-			goto out_unlock;
+			goto out_unlock0;
 
 		if (cmd == SHM_LOCK) {
 			struct user_struct *user = current_user();
@@ -992,32 +994,31 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 				shp->shm_perm.mode |= SHM_LOCKED;
 				shp->mlock_user = user;
 			}
-			goto out_unlock;
+			goto out_unlock0;
 		}
 
 		/* SHM_UNLOCK */
 		if (!(shp->shm_perm.mode & SHM_LOCKED))
-			goto out_unlock;
+			goto out_unlock0;
 		shmem_lock(shm_file, 0, shp->mlock_user);
 		shp->shm_perm.mode &= ~SHM_LOCKED;
 		shp->mlock_user = NULL;
 		get_file(shm_file);
-		shm_unlock(shp);
+		ipc_unlock_object(&shp->shm_perm);
+		rcu_read_unlock();
 		shmem_unlock_mapping(shm_file->f_mapping);
+
 		fput(shm_file);
-		goto out;
-	}
-	case IPC_RMID:
-	case IPC_SET:
-		err = shmctl_down(ns, shmid, cmd, buf, version);
 		return err;
+	}
 	default:
 		return -EINVAL;
 	}
 
-out_unlock:
-	shm_unlock(shp);
-out:
+out_unlock0:
+	ipc_unlock_object(&shp->shm_perm);
+out_unlock1:
+	rcu_read_unlock();
 	return err;
 }
 

commit c97cb9ccab8c85428ec21eff690642ad2ce1fa8a
Author: Davidlohr Bueso <davidlohr.bueso@hp.com>
Date:   Wed Sep 11 14:26:20 2013 -0700

    ipc,shm: make shmctl_nolock lockless
    
    While the INFO cmd doesn't take the ipc lock, the STAT commands do acquire
    it unnecessarily.  We can do the permissions and security checks only
    holding the rcu lock.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Tested-by: Sedat Dilek <sedat.dilek@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 3e123987f054..a493639550d9 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -882,27 +882,31 @@ static int shmctl_nolock(struct ipc_namespace *ns, int shmid,
 		struct shmid64_ds tbuf;
 		int result;
 
+		rcu_read_lock();
 		if (cmd == SHM_STAT) {
-			shp = shm_lock(ns, shmid);
+			shp = shm_obtain_object(ns, shmid);
 			if (IS_ERR(shp)) {
 				err = PTR_ERR(shp);
-				goto out;
+				goto out_unlock;
 			}
 			result = shp->shm_perm.id;
 		} else {
-			shp = shm_lock_check(ns, shmid);
+			shp = shm_obtain_object_check(ns, shmid);
 			if (IS_ERR(shp)) {
 				err = PTR_ERR(shp);
-				goto out;
+				goto out_unlock;
 			}
 			result = 0;
 		}
+
 		err = -EACCES;
 		if (ipcperms(ns, &shp->shm_perm, S_IRUGO))
 			goto out_unlock;
+
 		err = security_shm_shmctl(shp, cmd);
 		if (err)
 			goto out_unlock;
+
 		memset(&tbuf, 0, sizeof(tbuf));
 		kernel_to_ipc64_perm(&shp->shm_perm, &tbuf.shm_perm);
 		tbuf.shm_segsz	= shp->shm_segsz;
@@ -912,8 +916,9 @@ static int shmctl_nolock(struct ipc_namespace *ns, int shmid,
 		tbuf.shm_cpid	= shp->shm_cprid;
 		tbuf.shm_lpid	= shp->shm_lprid;
 		tbuf.shm_nattch	= shp->shm_nattch;
-		shm_unlock(shp);
-		if(copy_shmid_to_user (buf, &tbuf, version))
+		rcu_read_unlock();
+
+		if (copy_shmid_to_user(buf, &tbuf, version))
 			err = -EFAULT;
 		else
 			err = result;
@@ -924,7 +929,7 @@ static int shmctl_nolock(struct ipc_namespace *ns, int shmid,
 	}
 
 out_unlock:
-	shm_unlock(shp);
+	rcu_read_unlock();
 out:
 	return err;
 }

commit 68eccc1dc345539d589ae78ee43b835c1a06a134
Author: Davidlohr Bueso <davidlohr.bueso@hp.com>
Date:   Wed Sep 11 14:26:18 2013 -0700

    ipc,shm: introduce shmctl_nolock
    
    Similar to semctl and msgctl, when calling msgctl, the *_INFO and *_STAT
    commands can be performed without acquiring the ipc object.
    
    Add a shmctl_nolock() function and move the logic of *_INFO and *_STAT out
    of msgctl().  Since we are just moving functionality, this change still
    takes the lock and it will be properly lockless in the next patch.
    
    Signed-off-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Tested-by: Sedat Dilek <sedat.dilek@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 22cffd78dbb1..3e123987f054 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -820,29 +820,24 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 	return err;
 }
 
-SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
+static int shmctl_nolock(struct ipc_namespace *ns, int shmid,
+			 int cmd, int version, void __user *buf)
 {
+	int err;
 	struct shmid_kernel *shp;
-	int err, version;
-	struct ipc_namespace *ns;
 
-	if (cmd < 0 || shmid < 0) {
-		err = -EINVAL;
-		goto out;
+	/* preliminary security checks for *_INFO */
+	if (cmd == IPC_INFO || cmd == SHM_INFO) {
+		err = security_shm_shmctl(NULL, cmd);
+		if (err)
+			return err;
 	}
 
-	version = ipc_parse_version(&cmd);
-	ns = current->nsproxy->ipc_ns;
-
-	switch (cmd) { /* replace with proc interface ? */
+	switch (cmd) {
 	case IPC_INFO:
 	{
 		struct shminfo64 shminfo;
 
-		err = security_shm_shmctl(NULL, cmd);
-		if (err)
-			return err;
-
 		memset(&shminfo, 0, sizeof(shminfo));
 		shminfo.shmmni = shminfo.shmseg = ns->shm_ctlmni;
 		shminfo.shmmax = ns->shm_ctlmax;
@@ -864,10 +859,6 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 	{
 		struct shm_info shm_info;
 
-		err = security_shm_shmctl(NULL, cmd);
-		if (err)
-			return err;
-
 		memset(&shm_info, 0, sizeof(shm_info));
 		down_read(&shm_ids(ns).rw_mutex);
 		shm_info.used_ids = shm_ids(ns).in_use;
@@ -928,6 +919,36 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 			err = result;
 		goto out;
 	}
+	default:
+		return -EINVAL;
+	}
+
+out_unlock:
+	shm_unlock(shp);
+out:
+	return err;
+}
+
+SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
+{
+	struct shmid_kernel *shp;
+	int err, version;
+	struct ipc_namespace *ns;
+
+	if (cmd < 0 || shmid < 0) {
+		err = -EINVAL;
+		goto out;
+	}
+
+	version = ipc_parse_version(&cmd);
+	ns = current->nsproxy->ipc_ns;
+
+	switch (cmd) {
+	case IPC_INFO:
+	case SHM_INFO:
+	case SHM_STAT:
+	case IPC_STAT:
+		return shmctl_nolock(ns, shmid, cmd, version, buf);
 	case SHM_LOCK:
 	case SHM_UNLOCK:
 	{

commit 79ccf0f8c8e04e8b9eda6645ba0f63b0915a3075
Author: Davidlohr Bueso <davidlohr.bueso@hp.com>
Date:   Wed Sep 11 14:26:16 2013 -0700

    ipc,shm: shorten critical region in shmctl_down
    
    Instead of holding the ipc lock for the entire function, use the
    ipcctl_pre_down_nolock and only acquire the lock for specific commands:
    RMID and SET.
    
    Signed-off-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Tested-by: Sedat Dilek <sedat.dilek@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 216ae727a936..22cffd78dbb1 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -780,11 +780,10 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 	down_write(&shm_ids(ns).rw_mutex);
 	rcu_read_lock();
 
-	ipcp = ipcctl_pre_down(ns, &shm_ids(ns), shmid, cmd,
-			       &shmid64.shm_perm, 0);
+	ipcp = ipcctl_pre_down_nolock(ns, &shm_ids(ns), shmid, cmd,
+				      &shmid64.shm_perm, 0);
 	if (IS_ERR(ipcp)) {
 		err = PTR_ERR(ipcp);
-		/* the ipc lock is not held upon failure */
 		goto out_unlock1;
 	}
 
@@ -792,14 +791,16 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 
 	err = security_shm_shmctl(shp, cmd);
 	if (err)
-		goto out_unlock0;
+		goto out_unlock1;
 
 	switch (cmd) {
 	case IPC_RMID:
+		ipc_lock_object(&shp->shm_perm);
 		/* do_shm_rmid unlocks the ipc object and rcu */
 		do_shm_rmid(ns, ipcp);
 		goto out_up;
 	case IPC_SET:
+		ipc_lock_object(&shp->shm_perm);
 		err = ipc_update_perm(&shmid64.shm_perm, ipcp);
 		if (err)
 			goto out_unlock0;
@@ -807,6 +808,7 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 		break;
 	default:
 		err = -EINVAL;
+		goto out_unlock1;
 	}
 
 out_unlock0:

commit 8b8d52ac382b17a19906b930cd69e2edb0aca8ba
Author: Davidlohr Bueso <davidlohr.bueso@hp.com>
Date:   Wed Sep 11 14:26:15 2013 -0700

    ipc,shm: introduce lockless functions to obtain the ipc object
    
    This is the third and final patchset that deals with reducing the amount
    of contention we impose on the ipc lock (kern_ipc_perm.lock).  These
    changes mostly deal with shared memory, previous work has already been
    done for semaphores and message queues:
    
      http://lkml.org/lkml/2013/3/20/546 (sems)
      http://lkml.org/lkml/2013/5/15/584 (mqueues)
    
    With these patches applied, a custom shm microbenchmark stressing shmctl
    doing IPC_STAT with 4 threads a million times, reduces the execution
    time by 50%.  A similar run, this time with IPC_SET, reduces the
    execution time from 3 mins and 35 secs to 27 seconds.
    
    Patches 1-8: replaces blindly taking the ipc lock for a smarter
    combination of rcu and ipc_obtain_object, only acquiring the spinlock
    when updating.
    
    Patch 9: renames the ids rw_mutex to rwsem, which is what it already was.
    
    Patch 10: is a trivial mqueue leftover cleanup
    
    Patch 11: adds a brief lock scheme description, requested by Andrew.
    
    This patch:
    
    Add shm_obtain_object() and shm_obtain_object_check(), which will allow us
    to get the ipc object without acquiring the lock.  Just as with other
    forms of ipc, these functions are basically wrappers around
    ipc_obtain_object*().
    
    Signed-off-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Tested-by: Sedat Dilek <sedat.dilek@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index c6b4ad5ce3b7..216ae727a936 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -124,6 +124,26 @@ void __init shm_init (void)
 				IPC_SHM_IDS, sysvipc_shm_proc_show);
 }
 
+static inline struct shmid_kernel *shm_obtain_object(struct ipc_namespace *ns, int id)
+{
+	struct kern_ipc_perm *ipcp = ipc_obtain_object(&shm_ids(ns), id);
+
+	if (IS_ERR(ipcp))
+		return ERR_CAST(ipcp);
+
+	return container_of(ipcp, struct shmid_kernel, shm_perm);
+}
+
+static inline struct shmid_kernel *shm_obtain_object_check(struct ipc_namespace *ns, int id)
+{
+	struct kern_ipc_perm *ipcp = ipc_obtain_object_check(&shm_ids(ns), id);
+
+	if (IS_ERR(ipcp))
+		return ERR_CAST(ipcp);
+
+	return container_of(ipcp, struct shmid_kernel, shm_perm);
+}
+
 /*
  * shm_lock_(check_) routines are called in the paths where the rw_mutex
  * is not necessarily held.

commit 7b4cc5d8411bd4e9d61d8714f53859740cf830c2
Author: Davidlohr Bueso <davidlohr.bueso@hp.com>
Date:   Mon Jul 8 16:01:12 2013 -0700

    ipc: move locking out of ipcctl_pre_down_nolock
    
    This function currently acquires both the rw_mutex and the rcu lock on
    successful lookups, leaving the callers to explicitly unlock them,
    creating another two level locking situation.
    
    Make the callers (including those that still use ipcctl_pre_down())
    explicitly lock and unlock the rwsem and rcu lock.
    
    Signed-off-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Rik van Riel <riel@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index e7d51072d1c7..c6b4ad5ce3b7 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -757,31 +757,42 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 			return -EFAULT;
 	}
 
+	down_write(&shm_ids(ns).rw_mutex);
+	rcu_read_lock();
+
 	ipcp = ipcctl_pre_down(ns, &shm_ids(ns), shmid, cmd,
 			       &shmid64.shm_perm, 0);
-	if (IS_ERR(ipcp))
-		return PTR_ERR(ipcp);
+	if (IS_ERR(ipcp)) {
+		err = PTR_ERR(ipcp);
+		/* the ipc lock is not held upon failure */
+		goto out_unlock1;
+	}
 
 	shp = container_of(ipcp, struct shmid_kernel, shm_perm);
 
 	err = security_shm_shmctl(shp, cmd);
 	if (err)
-		goto out_unlock;
+		goto out_unlock0;
+
 	switch (cmd) {
 	case IPC_RMID:
+		/* do_shm_rmid unlocks the ipc object and rcu */
 		do_shm_rmid(ns, ipcp);
 		goto out_up;
 	case IPC_SET:
 		err = ipc_update_perm(&shmid64.shm_perm, ipcp);
 		if (err)
-			goto out_unlock;
+			goto out_unlock0;
 		shp->shm_ctim = get_seconds();
 		break;
 	default:
 		err = -EINVAL;
 	}
-out_unlock:
-	shm_unlock(shp);
+
+out_unlock0:
+	ipc_unlock_object(&shp->shm_perm);
+out_unlock1:
+	rcu_read_unlock();
 out_up:
 	up_write(&shm_ids(ns).rw_mutex);
 	return err;

commit cf9d5d78d05bca96df7618dfc3a5ee4414dcae58
Author: Davidlohr Bueso <davidlohr.bueso@hp.com>
Date:   Mon Jul 8 16:01:11 2013 -0700

    ipc: close open coded spin lock calls
    
    Signed-off-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Rik van Riel <riel@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index bd2b14ef1bba..e7d51072d1c7 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -141,7 +141,7 @@ static inline struct shmid_kernel *shm_lock(struct ipc_namespace *ns, int id)
 static inline void shm_lock_by_ptr(struct shmid_kernel *ipcp)
 {
 	rcu_read_lock();
-	spin_lock(&ipcp->shm_perm.lock);
+	ipc_lock_object(&ipcp->shm_perm);
 }
 
 static inline struct shmid_kernel *shm_lock_check(struct ipc_namespace *ns,
@@ -545,7 +545,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	ns->shm_tot += numpages;
 	error = shp->shm_perm.id;
 
-	spin_unlock(&shp->shm_perm.lock);
+	ipc_unlock_object(&shp->shm_perm);
 	rcu_read_unlock();
 	return error;
 

commit dbfcd91f06f0e2d5564b2fd184e9c2a43675f9ab
Author: Davidlohr Bueso <davidlohr.bueso@hp.com>
Date:   Mon Jul 8 16:01:09 2013 -0700

    ipc: move rcu lock out of ipc_addid
    
    This patchset continues the work that began in the sysv ipc semaphore
    scaling series, see
    
      https://lkml.org/lkml/2013/3/20/546
    
    Just like semaphores used to be, sysv shared memory and msg queues also
    abuse the ipc lock, unnecessarily holding it for operations such as
    permission and security checks.
    
    This patchset mostly deals with mqueues, and while shared mem can be
    done in a very similar way, I want to get these patches out in the open
    first.  It also does some pending cleanups, mostly focused on the two
    level locking we have in ipc code, taking care of ipc_addid() and
    ipcctl_pre_down_nolock() - yes there are still functions that need to be
    updated as well.
    
    This patch:
    
    Make all callers explicitly take and release the RCU read lock.
    
    This addresses the two level locking seen in newary(), newseg() and
    newqueue().  For the last two, explicitly unlock the ipc object and the
    rcu lock, instead of calling the custom shm_unlock and msg_unlock
    functions.  The next patch will deal with the open coded locking for
    ->perm.lock
    
    Signed-off-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Rik van Riel <riel@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 85dc001634b1..bd2b14ef1bba 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -535,6 +535,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	shp->shm_nattch = 0;
 	shp->shm_file = file;
 	shp->shm_creator = current;
+
 	/*
 	 * shmid gets reported as "inode#" in /proc/pid/maps.
 	 * proc-ps tools use this. Changing this will break them.
@@ -543,7 +544,9 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 
 	ns->shm_tot += numpages;
 	error = shp->shm_perm.id;
-	shm_unlock(shp);
+
+	spin_unlock(&shp->shm_perm.lock);
+	rcu_read_unlock();
 	return error;
 
 no_id:

commit c103a4dc4a32f53f095b66cd798d648c652f05b4
Author: Andrew Morton <akpm@linux-foundation.org>
Date:   Mon Jul 8 16:01:08 2013 -0700

    ipc/shmc.c: eliminate ugly 80-col tricks
    
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 7e199fa1960f..85dc001634b1 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -491,10 +491,10 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 
 	sprintf (name, "SYSV%08x", key);
 	if (shmflg & SHM_HUGETLB) {
-		struct hstate *hs = hstate_sizelog((shmflg >> SHM_HUGE_SHIFT)
-						& SHM_HUGE_MASK);
+		struct hstate *hs;
 		size_t hugesize;
 
+		hs = hstate_sizelog((shmflg >> SHM_HUGE_SHIFT) & SHM_HUGE_MASK);
 		if (!hs) {
 			error = -EINVAL;
 			goto no_file;

commit 091d0d55b286c9340201b4ed4470be87fc568228
Author: Li Zefan <lizefan@huawei.com>
Date:   Thu May 9 15:08:15 2013 +0800

    shm: fix null pointer deref when userspace specifies invalid hugepage size
    
    Dave reported an oops triggered by trinity:
    
      BUG: unable to handle kernel NULL pointer dereference at 0000000000000008
      IP: newseg+0x10d/0x390
      PGD cf8c1067 PUD cf8c2067 PMD 0
      Oops: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC
      CPU: 2 PID: 7636 Comm: trinity-child2 Not tainted 3.9.0+#67
      ...
      Call Trace:
        ipcget+0x182/0x380
        SyS_shmget+0x5a/0x60
        tracesys+0xdd/0xe2
    
    This bug was introduced by commit af73e4d9506d ("hugetlbfs: fix mmap
    failure in unaligned size request").
    
    Reported-by: Dave Jones <davej@redhat.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Li Zefan <lizfan@huawei.com>
    Reviewed-by: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
    Acked-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 34af1fe34701..7e199fa1960f 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -493,7 +493,13 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	if (shmflg & SHM_HUGETLB) {
 		struct hstate *hs = hstate_sizelog((shmflg >> SHM_HUGE_SHIFT)
 						& SHM_HUGE_MASK);
-		size_t hugesize = ALIGN(size, huge_page_size(hs));
+		size_t hugesize;
+
+		if (!hs) {
+			error = -EINVAL;
+			goto no_file;
+		}
+		hugesize = ALIGN(size, huge_page_size(hs));
 
 		/* hugetlb_file_setup applies strict accounting */
 		if (shmflg & SHM_NORESERVE)

commit af73e4d9506d3b797509f3c030e7dcd554f7d9c4
Author: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
Date:   Tue May 7 16:18:13 2013 -0700

    hugetlbfs: fix mmap failure in unaligned size request
    
    The current kernel returns -EINVAL unless a given mmap length is
    "almost" hugepage aligned.  This is because in sys_mmap_pgoff() the
    given length is passed to vm_mmap_pgoff() as it is without being aligned
    with hugepage boundary.
    
    This is a regression introduced in commit 40716e29243d ("hugetlbfs: fix
    alignment of huge page requests"), where alignment code is pushed into
    hugetlb_file_setup() and the variable len in caller side is not changed.
    
    To fix this, this patch partially reverts that commit, and adds
    alignment code in caller side.  And it also introduces hstate_sizelog()
    in order to get proper hstate to specified hugepage size.
    
    Addresses https://bugzilla.kernel.org/show_bug.cgi?id=56881
    
    [akpm@linux-foundation.org: fix warning when CONFIG_HUGETLB_PAGE=n]
    Signed-off-by: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reported-by: <iceman_dvd@yahoo.com>
    Cc: Steven Truelove <steven.truelove@utoronto.ca>
    Cc: Jianguo Wu <wujianguo@huawei.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 8247c49ec073..34af1fe34701 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -491,10 +491,14 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 
 	sprintf (name, "SYSV%08x", key);
 	if (shmflg & SHM_HUGETLB) {
+		struct hstate *hs = hstate_sizelog((shmflg >> SHM_HUGE_SHIFT)
+						& SHM_HUGE_MASK);
+		size_t hugesize = ALIGN(size, huge_page_size(hs));
+
 		/* hugetlb_file_setup applies strict accounting */
 		if (shmflg & SHM_NORESERVE)
 			acctflag = VM_NORESERVE;
-		file = hugetlb_file_setup(name, 0, size, acctflag,
+		file = hugetlb_file_setup(name, hugesize, acctflag,
 				  &shp->mlock_user, HUGETLB_SHMFS_INODE,
 				(shmflg >> SHM_HUGE_SHIFT) & SHM_HUGE_MASK);
 	} else {

commit d69f3bad4675ac519d41ca2b11e1c00ca115cecd
Author: Robin Holt <holt@sgi.com>
Date:   Tue Apr 30 19:15:54 2013 -0700

    ipc: sysv shared memory limited to 8TiB
    
    Trying to run an application which was trying to put data into half of
    memory using shmget(), we found that having a shmall value below 8EiB-8TiB
    would prevent us from using anything more than 8TiB.  By setting
    kernel.shmall greater than 8EiB-8TiB would make the job work.
    
    In the newseg() function, ns->shm_tot which, at 8TiB is INT_MAX.
    
    ipc/shm.c:
     458 static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
     459 {
    ...
     465         int numpages = (size + PAGE_SIZE -1) >> PAGE_SHIFT;
    ...
     474         if (ns->shm_tot + numpages > ns->shm_ctlall)
     475                 return -ENOSPC;
    
    [akpm@linux-foundation.org: make ipc/shm.c:newseg()'s numpages size_t, not int]
    Signed-off-by: Robin Holt <holt@sgi.com>
    Reported-by: Alex Thorlton <athorlton@sgi.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index cb858df061d3..8247c49ec073 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -462,7 +462,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	size_t size = params->u.size;
 	int error;
 	struct shmid_kernel *shp;
-	int numpages = (size + PAGE_SIZE -1) >> PAGE_SHIFT;
+	size_t numpages = (size + PAGE_SIZE - 1) >> PAGE_SHIFT;
 	struct file * file;
 	char name[13];
 	int id;

commit d895cb1af15c04c522a25c79cc429076987c089b
Merge: 9626357371b5 d3d009cb965e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Feb 26 20:16:07 2013 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs pile (part one) from Al Viro:
     "Assorted stuff - cleaning namei.c up a bit, fixing ->d_name/->d_parent
      locking violations, etc.
    
      The most visible changes here are death of FS_REVAL_DOT (replaced with
      "has ->d_weak_revalidate()") and a new helper getting from struct file
      to inode.  Some bits of preparation to xattr method interface changes.
    
      Misc patches by various people sent this cycle *and* ocfs2 fixes from
      several cycles ago that should've been upstream right then.
    
      PS: the next vfs pile will be xattr stuff."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (46 commits)
      saner proc_get_inode() calling conventions
      proc: avoid extra pde_put() in proc_fill_super()
      fs: change return values from -EACCES to -EPERM
      fs/exec.c: make bprm_mm_init() static
      ocfs2/dlm: use GFP_ATOMIC inside a spin_lock
      ocfs2: fix possible use-after-free with AIO
      ocfs2: Fix oops in ocfs2_fast_symlink_readpage() code path
      get_empty_filp()/alloc_file() leave both ->f_pos and ->f_version zero
      target: writev() on single-element vector is pointless
      export kernel_write(), convert open-coded instances
      fs: encode_fh: return FILEID_INVALID if invalid fid_type
      kill f_vfsmnt
      vfs: kill FS_REVAL_DOT by adding a d_weak_revalidate dentry op
      nfsd: handle vfs_getattr errors in acl protocol
      switch vfs_getattr() to struct path
      default SET_PERSONALITY() in linux/elf.h
      ceph: prepopulate inodes only when request is aborted
      d_hash_and_lookup(): export, switch open-coded instances
      9p: switch v9fs_set_create_acl() to inode+fid, do it before d_instantiate()
      9p: split dropping the acls from v9fs_set_create_acl()
      ...

commit 41badc15cbad0350de34408c1b0c690f9df76d4b
Author: Michel Lespinasse <walken@google.com>
Date:   Fri Feb 22 16:32:47 2013 -0800

    mm: make do_mmap_pgoff return populate as a size in bytes, not as a bool
    
    do_mmap_pgoff() rounds up the desired size to the next PAGE_SIZE
    multiple, however there was no equivalent code in mm_populate(), which
    caused issues.
    
    This could be fixed by introduced the same rounding in mm_populate(),
    however I think it's preferable to make do_mmap_pgoff() return populate
    as a size rather than as a boolean, so we don't have to duplicate the
    size rounding logic in mm_populate().
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Acked-by: Rik van Riel <riel@redhat.com>
    Tested-by: Andy Lutomirski <luto@amacapital.net>
    Cc: Greg Ungerer <gregungerer@westnet.com.au>
    Cc: David Howells <dhowells@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 9f047ba69e62..be3ec9ae454e 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -971,7 +971,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 	struct shm_file_data *sfd;
 	struct path path;
 	fmode_t f_mode;
-	bool populate = false;
+	unsigned long populate = 0;
 
 	err = -EINVAL;
 	if (shmid < 0)
@@ -1078,7 +1078,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 invalid:
 	up_write(&current->mm->mmap_sem);
 	if (populate)
-		mm_populate(addr, size);
+		mm_populate(addr, populate);
 
 out_fput:
 	fput(file);

commit bebeb3d68b24bb4132d452c5707fe321208bcbcd
Author: Michel Lespinasse <walken@google.com>
Date:   Fri Feb 22 16:32:37 2013 -0800

    mm: introduce mm_populate() for populating new vmas
    
    When creating new mappings using the MAP_POPULATE / MAP_LOCKED flags (or
    with MCL_FUTURE in effect), we want to populate the pages within the
    newly created vmas.  This may take a while as we may have to read pages
    from disk, so ideally we want to do this outside of the write-locked
    mmap_sem region.
    
    This change introduces mm_populate(), which is used to defer populating
    such mappings until after the mmap_sem write lock has been released.
    This is implemented as a generalization of the former do_mlock_pages(),
    which accomplished the same task but was using during mlock() /
    mlockall().
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Reported-by: Andy Lutomirski <luto@amacapital.net>
    Acked-by: Rik van Riel <riel@redhat.com>
    Tested-by: Andy Lutomirski <luto@amacapital.net>
    Cc: Greg Ungerer <gregungerer@westnet.com.au>
    Cc: David Howells <dhowells@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 4fa6d8fee730..9f047ba69e62 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -967,11 +967,11 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 	unsigned long flags;
 	unsigned long prot;
 	int acc_mode;
-	unsigned long user_addr;
 	struct ipc_namespace *ns;
 	struct shm_file_data *sfd;
 	struct path path;
 	fmode_t f_mode;
+	bool populate = false;
 
 	err = -EINVAL;
 	if (shmid < 0)
@@ -1070,13 +1070,15 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 			goto invalid;
 	}
 		
-	user_addr = do_mmap_pgoff(file, addr, size, prot, flags, 0);
-	*raddr = user_addr;
+	addr = do_mmap_pgoff(file, addr, size, prot, flags, 0, &populate);
+	*raddr = addr;
 	err = 0;
-	if (IS_ERR_VALUE(user_addr))
-		err = (long)user_addr;
+	if (IS_ERR_VALUE(addr))
+		err = (long)addr;
 invalid:
 	up_write(&current->mm->mmap_sem);
+	if (populate)
+		mm_populate(addr, size);
 
 out_fput:
 	fput(file);

commit 39b652527457452f09b35044fb4f8b3b0eabafdf
Author: Anatol Pomozov <anatol.pomozov@gmail.com>
Date:   Wed Sep 12 20:11:55 2012 -0700

    fs: Preserve error code in get_empty_filp(), part 2
    
    Allocating a file structure in function get_empty_filp() might fail because
    of several reasons:
     - not enough memory for file structures
     - operation is not allowed
     - user is over its limit
    
    Currently the function returns NULL in all cases and we loose the exact
    reason of the error. All callers of get_empty_filp() assume that the function
    can fail with ENFILE only.
    
    Return error through pointer. Change all callers to preserve this error code.
    
    [AV: cleaned up a bit, carved the get_empty_filp() part out into a separate commit
    (things remaining here deal with alloc_file()), removed pipe(2) behaviour change]
    
    Signed-off-by: Anatol Pomozov <anatol.pomozov@gmail.com>
    Reviewed-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 8c9402d298a0..de389e639e7e 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1042,7 +1042,8 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
 			  is_file_hugepages(shp->shm_file) ?
 				&shm_file_operations_huge :
 				&shm_file_operations);
-	if (!file)
+	err = PTR_ERR(file);
+	if (IS_ERR(file))
 		goto out_free;
 
 	file->private_data = sfd;

commit 496ad9aa8ef448058e36ca7a787c61f2e63f0f54
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Jan 23 17:07:38 2013 -0500

    new helper: file_inode(file)
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 4fa6d8fee730..8c9402d298a0 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -193,7 +193,7 @@ static void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)
 	if (!is_file_hugepages(shp->shm_file))
 		shmem_lock(shp->shm_file, 0, shp->mlock_user);
 	else if (shp->mlock_user)
-		user_shm_unlock(shp->shm_file->f_path.dentry->d_inode->i_size,
+		user_shm_unlock(file_inode(shp->shm_file)->i_size,
 						shp->mlock_user);
 	fput (shp->shm_file);
 	security_shm_free(shp);
@@ -529,7 +529,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	 * shmid gets reported as "inode#" in /proc/pid/maps.
 	 * proc-ps tools use this. Changing this will break them.
 	 */
-	file->f_dentry->d_inode->i_ino = shp->shm_perm.id;
+	file_inode(file)->i_ino = shp->shm_perm.id;
 
 	ns->shm_tot += numpages;
 	error = shp->shm_perm.id;
@@ -678,7 +678,7 @@ static void shm_add_rss_swap(struct shmid_kernel *shp,
 {
 	struct inode *inode;
 
-	inode = shp->shm_file->f_path.dentry->d_inode;
+	inode = file_inode(shp->shm_file);
 
 	if (is_file_hugepages(shp->shm_file)) {
 		struct address_space *mapping = inode->i_mapping;
@@ -1173,7 +1173,7 @@ SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 			(vma->vm_start - addr)/PAGE_SIZE == vma->vm_pgoff) {
 
 
-			size = vma->vm_file->f_path.dentry->d_inode->i_size;
+			size = file_inode(vma->vm_file)->i_size;
 			do_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start);
 			/*
 			 * We discovered the size of the shm segment, so

commit 42d7395feb56f0655cd8b68e06fc6063823449f8
Author: Andi Kleen <ak@linux.intel.com>
Date:   Tue Dec 11 16:01:34 2012 -0800

    mm: support more pagesizes for MAP_HUGETLB/SHM_HUGETLB
    
    There was some desire in large applications using MAP_HUGETLB or
    SHM_HUGETLB to use 1GB huge pages on some mappings, and stay with 2MB on
    others.  This is useful together with NUMA policy: use 2MB interleaving
    on some mappings, but 1GB on local mappings.
    
    This patch extends the IPC/SHM syscall interfaces slightly to allow
    specifying the page size.
    
    It borrows some upper bits in the existing flag arguments and allows
    encoding the log of the desired page size in addition to the *_HUGETLB
    flag.  When 0 is specified the default size is used, this makes the
    change fully compatible.
    
    Extending the internal hugetlb code to handle this is straight forward.
    Instead of a single mount it just keeps an array of them and selects the
    right mount based on the specified page size.  When no page size is
    specified it uses the mount of the default page size.
    
    The change is not visible in /proc/mounts because internal mounts don't
    appear there.  It also has very little overhead: the additional mounts
    just consume a super block, but not more memory when not used.
    
    I also exported the new flags to the user headers (they were previously
    under __KERNEL__).  Right now only symbols for x86 and some other
    architecture for 1GB and 2MB are defined.  The interface should already
    work for all other architectures though.  Only architectures that define
    multiple hugetlb sizes actually need it (that is currently x86, tile,
    powerpc).  However tile and powerpc have user configurable hugetlb
    sizes, so it's not easy to add defines.  A program on those
    architectures would need to query sysfs and use the appropiate log2.
    
    [akpm@linux-foundation.org: cleanups]
    [rientjes@google.com: fix build]
    [akpm@linux-foundation.org: checkpatch fixes]
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Acked-by: Rik van Riel <riel@redhat.com>
    Acked-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Hillf Danton <dhillf@gmail.com>
    Signed-off-by: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index dff40c9f73c9..4fa6d8fee730 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -495,7 +495,8 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 		if (shmflg & SHM_NORESERVE)
 			acctflag = VM_NORESERVE;
 		file = hugetlb_file_setup(name, 0, size, acctflag,
-					&shp->mlock_user, HUGETLB_SHMFS_INODE);
+				  &shp->mlock_user, HUGETLB_SHMFS_INODE,
+				(shmflg >> SHM_HUGE_SHIFT) & SHM_HUGE_MASK);
 	} else {
 		/*
 		 * Do not allow no accounting for OVERCOMMIT_NEVER, even

commit 1efdb69b0bb41dec8ee3e2cac0a0f167837d0919
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Feb 7 16:54:11 2012 -0800

    userns: Convert ipc to use kuid and kgid where appropriate
    
    - Store the ipc owner and creator with a kuid
    - Store the ipc group and the crators group with a kgid.
    - Add error handling to ipc_update_perms, allowing it to
      fail if the uids and gids can not be converted to kuids
      or kgids.
    - Modify the proc files to display the ipc creator and
      owner in the user namespace of the opener of the proc file.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

diff --git a/ipc/shm.c b/ipc/shm.c
index 00faa05cf72a..dff40c9f73c9 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -758,7 +758,9 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 		do_shm_rmid(ns, ipcp);
 		goto out_up;
 	case IPC_SET:
-		ipc_update_perm(&shmid64.shm_perm, ipcp);
+		err = ipc_update_perm(&shmid64.shm_perm, ipcp);
+		if (err)
+			goto out_unlock;
 		shp->shm_ctim = get_seconds();
 		break;
 	default:
@@ -893,10 +895,10 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 		audit_ipc_obj(&(shp->shm_perm));
 
 		if (!ns_capable(ns->user_ns, CAP_IPC_LOCK)) {
-			uid_t euid = current_euid();
+			kuid_t euid = current_euid();
 			err = -EPERM;
-			if (euid != shp->shm_perm.uid &&
-			    euid != shp->shm_perm.cuid)
+			if (!uid_eq(euid, shp->shm_perm.uid) &&
+			    !uid_eq(euid, shp->shm_perm.cuid))
 				goto out_unlock;
 			if (cmd == SHM_LOCK && !rlimit(RLIMIT_MEMLOCK))
 				goto out_unlock;
@@ -1220,6 +1222,7 @@ SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 #ifdef CONFIG_PROC_FS
 static int sysvipc_shm_proc_show(struct seq_file *s, void *it)
 {
+	struct user_namespace *user_ns = seq_user_ns(s);
 	struct shmid_kernel *shp = it;
 	unsigned long rss = 0, swp = 0;
 
@@ -1242,10 +1245,10 @@ static int sysvipc_shm_proc_show(struct seq_file *s, void *it)
 			  shp->shm_cprid,
 			  shp->shm_lprid,
 			  shp->shm_nattch,
-			  shp->shm_perm.uid,
-			  shp->shm_perm.gid,
-			  shp->shm_perm.cuid,
-			  shp->shm_perm.cgid,
+			  from_kuid_munged(user_ns, shp->shm_perm.uid),
+			  from_kgid_munged(user_ns, shp->shm_perm.gid),
+			  from_kuid_munged(user_ns, shp->shm_perm.cuid),
+			  from_kgid_munged(user_ns, shp->shm_perm.cgid),
 			  shp->shm_atim,
 			  shp->shm_dtim,
 			  shp->shm_ctim,

commit 079a96ae3871f0ed9083aac2218136ccec5b9877
Author: Will Deacon <will.deacon@arm.com>
Date:   Mon Jul 30 14:42:38 2012 -0700

    ipc: add COMPAT_SHMLBA support
    
    If the SHMLBA definition for a native task differs from the definition for
    a compat task, the do_shmat() function would need to handle both.
    
    This patch introduces COMPAT_SHMLBA, which is used by the compat shmat
    syscall when calling the ipc code and allows architectures such as AArch64
    (where the native SHMLBA is 64k but the compat (AArch32) definition is
    16k) to provide the correct semantics for compat IPC system calls.
    
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 41c1285d697a..00faa05cf72a 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -953,7 +953,8 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
  * "raddr" thing points to kernel space, and there has to be a wrapper around
  * this.
  */
-long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
+long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,
+	      unsigned long shmlba)
 {
 	struct shmid_kernel *shp;
 	unsigned long addr;
@@ -973,9 +974,9 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	if (shmid < 0)
 		goto out;
 	else if ((addr = (ulong)shmaddr)) {
-		if (addr & (SHMLBA-1)) {
+		if (addr & (shmlba - 1)) {
 			if (shmflg & SHM_RND)
-				addr &= ~(SHMLBA-1);	   /* round down */
+				addr &= ~(shmlba - 1);	   /* round down */
 			else
 #ifndef __ARCH_FORCE_SHMLBA
 				if (addr & ~PAGE_MASK)
@@ -1107,7 +1108,7 @@ SYSCALL_DEFINE3(shmat, int, shmid, char __user *, shmaddr, int, shmflg)
 	unsigned long ret;
 	long err;
 
-	err = do_shmat(shmid, shmaddr, shmflg, &ret);
+	err = do_shmat(shmid, shmaddr, shmflg, &ret, SHMLBA);
 	if (err)
 		return err;
 	force_successful_syscall_return();

commit 7d8a45695cc8f9fcdf4121fcbd897ecb63f758e4
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Jun 7 14:21:13 2012 -0700

    ipc: shm: restore MADV_REMOVE functionality on shared memory segments
    
    Commit 17cf28afea2a ("mm/fs: remove truncate_range") removed the
    truncate_range inode operation in favour of the fallocate file
    operation.
    
    When using SYSV IPC shared memory segments, calling madvise with the
    MADV_REMOVE advice on an area of shared memory will attempt to invoke
    the .fallocate function for the shm_file_operations, which is NULL and
    therefore returns -EOPNOTSUPP to userspace.  The previous behaviour
    would inherit the inode_operations from the underlying tmpfs file and
    invoke truncate_range there.
    
    This patch restores the previous behaviour by wrapping the underlying
    fallocate function in shm_fallocate, as we do for fsync.
    
    [hughd@google.com: use -ENOTSUPP in shm_fallocate()]
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Acked-by: Hugh Dickins <hughd@google.com>
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 5e2cbfdab6fc..41c1285d697a 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -393,6 +393,16 @@ static int shm_fsync(struct file *file, loff_t start, loff_t end, int datasync)
 	return sfd->file->f_op->fsync(sfd->file, start, end, datasync);
 }
 
+static long shm_fallocate(struct file *file, int mode, loff_t offset,
+			  loff_t len)
+{
+	struct shm_file_data *sfd = shm_file_data(file);
+
+	if (!sfd->file->f_op->fallocate)
+		return -EOPNOTSUPP;
+	return sfd->file->f_op->fallocate(file, mode, offset, len);
+}
+
 static unsigned long shm_get_unmapped_area(struct file *file,
 	unsigned long addr, unsigned long len, unsigned long pgoff,
 	unsigned long flags)
@@ -410,6 +420,7 @@ static const struct file_operations shm_file_operations = {
 	.get_unmapped_area	= shm_get_unmapped_area,
 #endif
 	.llseek		= noop_llseek,
+	.fallocate	= shm_fallocate,
 };
 
 static const struct file_operations shm_file_operations_huge = {
@@ -418,6 +429,7 @@ static const struct file_operations shm_file_operations_huge = {
 	.release	= shm_release,
 	.get_unmapped_area	= shm_get_unmapped_area,
 	.llseek		= noop_llseek,
+	.fallocate	= shm_fallocate,
 };
 
 int is_file_shm_hugepages(struct file *file)

commit e3fc629d7bb70848fbf479688a66d4e76dff46ac
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed May 30 20:08:42 2012 -0400

    switch aio and shm to do_mmap_pgoff(), make do_mmap() static
    
    after all, 0 bytes and 0 pages is the same thing...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index e3a8063b1768..5e2cbfdab6fc 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1054,7 +1054,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 			goto invalid;
 	}
 		
-	user_addr = do_mmap (file, addr, size, prot, flags, 0);
+	user_addr = do_mmap_pgoff(file, addr, size, prot, flags, 0);
 	*raddr = user_addr;
 	err = 0;
 	if (IS_ERR_VALUE(user_addr))

commit 8b3ec6814c83d76b85bd13badc48552836c24839
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed May 30 17:11:23 2012 -0400

    take security_mmap_file() outside of ->mmap_sem
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 406c5b208193..e3a8063b1768 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1036,6 +1036,10 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	sfd->file = shp->shm_file;
 	sfd->vm_ops = NULL;
 
+	err = security_mmap_file(file, prot, flags);
+	if (err)
+		goto out_fput;
+
 	down_write(&current->mm->mmap_sem);
 	if (addr && !(shmflg & SHM_REMAP)) {
 		err = -EINVAL;
@@ -1058,6 +1062,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 invalid:
 	up_write(&current->mm->mmap_sem);
 
+out_fput:
 	fput(file);
 
 out_nattch:

commit 40716e29243de46720e5773797791466c28904ec
Author: Steven Truelove <steven.truelove@utoronto.ca>
Date:   Wed Mar 21 16:34:14 2012 -0700

    hugetlbfs: fix alignment of huge page requests
    
    When calling shmget() with SHM_HUGETLB, shmget aligns the request size to
    PAGE_SIZE, but this is not sufficient.
    
    Modify hugetlb_file_setup() to align requests to the huge page size, and
    to accept an address argument so that all alignment checks can be
    performed in hugetlb_file_setup(), rather than in its callers.  Change
    newseg() and mmap_pgoff() to match the new prototype and eliminate a now
    redundant alignment check.
    
    [akpm@linux-foundation.org: fix build]
    Signed-off-by: Steven Truelove <steven.truelove@utoronto.ca>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index b76be5bda6c2..406c5b208193 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -482,7 +482,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 		/* hugetlb_file_setup applies strict accounting */
 		if (shmflg & SHM_NORESERVE)
 			acctflag = VM_NORESERVE;
-		file = hugetlb_file_setup(name, size, acctflag,
+		file = hugetlb_file_setup(name, 0, size, acctflag,
 					&shp->mlock_user, HUGETLB_SHMFS_INODE);
 	} else {
 		/*

commit 245132643e1cfcd145bbc86a716c1818371fcb93
Author: Hugh Dickins <hughd@google.com>
Date:   Fri Jan 20 14:34:21 2012 -0800

    SHM_UNLOCK: fix Unevictable pages stranded after swap
    
    Commit cc39c6a9bbde ("mm: account skipped entries to avoid looping in
    find_get_pages") correctly fixed an infinite loop; but left a problem
    that find_get_pages() on shmem would return 0 (appearing to callers to
    mean end of tree) when it meets a run of nr_pages swap entries.
    
    The only uses of find_get_pages() on shmem are via pagevec_lookup(),
    called from invalidate_mapping_pages(), and from shmctl SHM_UNLOCK's
    scan_mapping_unevictable_pages().  The first is already commented, and
    not worth worrying about; but the second can leave pages on the
    Unevictable list after an unusual sequence of swapping and locking.
    
    Fix that by using shmem_find_get_pages_and_swap() (then ignoring the
    swap) instead of pagevec_lookup().
    
    But I don't want to contaminate vmscan.c with shmem internals, nor
    shmem.c with LRU locking.  So move scan_mapping_unevictable_pages() into
    shmem.c, renaming it shmem_unlock_mapping(); and rename
    check_move_unevictable_page() to check_move_unevictable_pages(), looping
    down an array of pages, oftentimes under the same lock.
    
    Leave out the "rotate unevictable list" block: that's a leftover from
    when this was used for /proc/sys/vm/scan_unevictable_pages, whose flawed
    handling involved looking at pages at tail of LRU.
    
    Was there significance to the sequence first ClearPageUnevictable, then
    test page_evictable, then SetPageUnevictable here? I think not, we're
    under LRU lock, and have no barriers between those.
    
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Reviewed-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Minchan Kim <minchan.kim@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Shaohua Li <shaohua.li@intel.com>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: <stable@vger.kernel.org> [back to 3.1 but will need respins]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 854ab58e5f6e..b76be5bda6c2 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -916,7 +916,7 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 		shp->mlock_user = NULL;
 		get_file(shm_file);
 		shm_unlock(shp);
-		scan_mapping_unevictable_pages(shm_file->f_mapping);
+		shmem_unlock_mapping(shm_file->f_mapping);
 		fput(shm_file);
 		goto out;
 	}

commit 85046579bde15e532983438f86b36856e358f417
Author: Hugh Dickins <hughd@google.com>
Date:   Fri Jan 20 14:34:19 2012 -0800

    SHM_UNLOCK: fix long unpreemptible section
    
    scan_mapping_unevictable_pages() is used to make SysV SHM_LOCKed pages
    evictable again once the shared memory is unlocked.  It does this with
    pagevec_lookup()s across the whole object (which might occupy most of
    memory), and takes 300ms to unlock 7GB here.  A cond_resched() every
    PAGEVEC_SIZE pages would be good.
    
    However, KOSAKI-san points out that this is called under shmem.c's
    info->lock, and it's also under shm.c's shm_lock(), both spinlocks.
    There is no strong reason for that: we need to take these pages off the
    unevictable list soonish, but those locks are not required for it.
    
    So move the call to scan_mapping_unevictable_pages() from shmem.c's
    unlock handling up to shm.c's unlock handling.  Remove the recently
    added barrier, not needed now we have spin_unlock() before the scan.
    
    Use get_file(), with subsequent fput(), to make sure we have a reference
    to mapping throughout scan_mapping_unevictable_pages(): that's something
    that was previously guaranteed by the shm_lock().
    
    Remove shmctl's lru_add_drain_all(): we don't fault in pages at SHM_LOCK
    time, and we lazily discover them to be Unevictable later, so it serves
    no purpose for SHM_LOCK; and serves no purpose for SHM_UNLOCK, since
    pages still on pagevec are not marked Unevictable.
    
    The original code avoided redundant rescans by checking VM_LOCKED flag
    at its level: now avoid them by checking shp's SHM_LOCKED.
    
    The original code called scan_mapping_unevictable_pages() on a locked
    area at shm_destroy() time: perhaps we once had accounting cross-checks
    which required that, but not now, so skip the overhead and just let
    inode eviction deal with them.
    
    Put check_move_unevictable_page() and scan_mapping_unevictable_pages()
    under CONFIG_SHMEM (with stub for the TINY case when ramfs is used),
    more as comment than to save space; comment them used for SHM_UNLOCK.
    
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Reviewed-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Minchan Kim <minchan.kim@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Shaohua Li <shaohua.li@intel.com>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michel Lespinasse <walken@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 02ecf2c078fc..854ab58e5f6e 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -870,9 +870,7 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 	case SHM_LOCK:
 	case SHM_UNLOCK:
 	{
-		struct file *uninitialized_var(shm_file);
-
-		lru_add_drain_all();  /* drain pagevecs to lru lists */
+		struct file *shm_file;
 
 		shp = shm_lock_check(ns, shmid);
 		if (IS_ERR(shp)) {
@@ -895,22 +893,31 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 		err = security_shm_shmctl(shp, cmd);
 		if (err)
 			goto out_unlock;
-		
-		if(cmd==SHM_LOCK) {
+
+		shm_file = shp->shm_file;
+		if (is_file_hugepages(shm_file))
+			goto out_unlock;
+
+		if (cmd == SHM_LOCK) {
 			struct user_struct *user = current_user();
-			if (!is_file_hugepages(shp->shm_file)) {
-				err = shmem_lock(shp->shm_file, 1, user);
-				if (!err && !(shp->shm_perm.mode & SHM_LOCKED)){
-					shp->shm_perm.mode |= SHM_LOCKED;
-					shp->mlock_user = user;
-				}
+			err = shmem_lock(shm_file, 1, user);
+			if (!err && !(shp->shm_perm.mode & SHM_LOCKED)) {
+				shp->shm_perm.mode |= SHM_LOCKED;
+				shp->mlock_user = user;
 			}
-		} else if (!is_file_hugepages(shp->shm_file)) {
-			shmem_lock(shp->shm_file, 0, shp->mlock_user);
-			shp->shm_perm.mode &= ~SHM_LOCKED;
-			shp->mlock_user = NULL;
+			goto out_unlock;
 		}
+
+		/* SHM_UNLOCK */
+		if (!(shp->shm_perm.mode & SHM_LOCKED))
+			goto out_unlock;
+		shmem_lock(shm_file, 0, shp->mlock_user);
+		shp->shm_perm.mode &= ~SHM_LOCKED;
+		shp->mlock_user = NULL;
+		get_file(shm_file);
 		shm_unlock(shp);
+		scan_mapping_unevictable_pages(shm_file->f_mapping);
+		fput(shm_file);
 		goto out;
 	}
 	case IPC_RMID:

commit 140d0b2108faebc77c6523296e211e509cb9f5f9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Aug 4 19:35:59 2011 -1000

    Do 'shm_init_ns()' in an early pure_initcall
    
    This isn't really critical any more, since other patches (commit
    298507d4d2cf: "shm: optimize exit_shm()") have caused us to not actually
    need to touch the rw_mutex unless there are actual shm segments
    associated with the namespace, but we really should do tne shm_init_ns()
    earlier than we do now.
    
    This, together with commit 288d5abec831 ("Boot up with usermodehelper
    disabled") will mean that we really do initialize the initial ipc
    namespace data structure before we run any tasks.
    
    Tested-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index b5bae9d945b6..02ecf2c078fc 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -105,9 +105,16 @@ void shm_exit_ns(struct ipc_namespace *ns)
 }
 #endif
 
-void __init shm_init (void)
+static int __init ipc_ns_init(void)
 {
 	shm_init_ns(&init_ipc_ns);
+	return 0;
+}
+
+pure_initcall(ipc_ns_init);
+
+void __init shm_init (void)
+{
 	ipc_init_proc_interface("sysvipc/shm",
 #if BITS_PER_LONG <= 32
 				"       key      shmid perms       size  cpid  lpid nattch   uid   gid  cuid  cgid      atime      dtime      ctime        rss       swap\n",

commit 298507d4d2cff2248e84afcf646b697301294442
Author: Vasiliy Kulikov <segoon@openwall.com>
Date:   Wed Aug 3 22:28:26 2011 +0400

    shm: optimize exit_shm()
    
    We may optimistically check .in_use == 0 without holding the rw_mutex:
    it's the common case, and if it's zero, there certainly won't be any
    segments associated with us.
    
    After taking the lock, the idr_for_each() will do the right thing, so we
    could now drop the re-check inside the lock without any real cost.  But
    it won't hurt.
    
    Signed-off-by: Vasiliy Kulikov <segoon@openwall.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 7efff043ffbf..b5bae9d945b6 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -304,6 +304,9 @@ void exit_shm(struct task_struct *task)
 {
 	struct ipc_namespace *ns = task->nsproxy->ipc_ns;
 
+	if (shm_ids(ns).in_use == 0)
+		return;
+
 	/* Destroy all already created segments, but not mapped yet */
 	down_write(&shm_ids(ns).rw_mutex);
 	if (shm_ids(ns).in_use)

commit 33a30ed4bdccd95ed84a1a20c1fef8ac89788ce5
Author: Vasiliy Kulikov <segoon@openwall.com>
Date:   Wed Aug 3 22:26:55 2011 +0400

    shm: fix wrong tests
    
    Commit 4c677e2eefdb ("shm: optimize locking and ipc_namespace getting")
    introduced a copy-paste bug.  Due to the bug cycle optimizations were
    disabled.
    
    Signed-off-by: Vasiliy Kulikov <segoon@openwall.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 9fb044f3b345..7efff043ffbf 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -294,7 +294,7 @@ static int shm_try_destroy_orphaned(int id, void *p, void *data)
 void shm_destroy_orphaned(struct ipc_namespace *ns)
 {
 	down_write(&shm_ids(ns).rw_mutex);
-	if (&shm_ids(ns).in_use)
+	if (shm_ids(ns).in_use)
 		idr_for_each(&shm_ids(ns).ipcs_idr, &shm_try_destroy_orphaned, ns);
 	up_write(&shm_ids(ns).rw_mutex);
 }
@@ -306,7 +306,7 @@ void exit_shm(struct task_struct *task)
 
 	/* Destroy all already created segments, but not mapped yet */
 	down_write(&shm_ids(ns).rw_mutex);
-	if (&shm_ids(ns).in_use)
+	if (shm_ids(ns).in_use)
 		idr_for_each(&shm_ids(ns).ipcs_idr, &shm_try_destroy_current, ns);
 	up_write(&shm_ids(ns).rw_mutex);
 }

commit 4c677e2eefdba9c5bfc4474e2e91b26ae8458a1d
Author: Vasiliy Kulikov <segoon@openwall.com>
Date:   Fri Jul 29 03:56:40 2011 +0400

    shm: optimize locking and ipc_namespace getting
    
    shm_lock() does a lookup of shm segment in shm_ids(ns).ipcs_idr, which
    is redundant as we already know shmid_kernel address.  An actual lock is
    also not required for reads until we really want to destroy the segment.
    
    exit_shm() and shm_destroy_orphaned() may avoid the loop by checking
    whether there is at least one segment in current ipc_namespace.
    
    The check of nsproxy and ipc_ns against NULL is redundant as exit_shm()
    is called from do_exit() before the call to exit_notify(), so the
    dereferencing current->nsproxy->ipc_ns is guaranteed to be safe.
    
    Reported-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Vasiliy Kulikov <segoon@openwall.com>
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index fdaf8be65b75..9fb044f3b345 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -131,6 +131,12 @@ static inline struct shmid_kernel *shm_lock(struct ipc_namespace *ns, int id)
 	return container_of(ipcp, struct shmid_kernel, shm_perm);
 }
 
+static inline void shm_lock_by_ptr(struct shmid_kernel *ipcp)
+{
+	rcu_read_lock();
+	spin_lock(&ipcp->shm_perm.lock);
+}
+
 static inline struct shmid_kernel *shm_lock_check(struct ipc_namespace *ns,
 						int id)
 {
@@ -231,18 +237,15 @@ static void shm_close(struct vm_area_struct *vma)
 	up_write(&shm_ids(ns).rw_mutex);
 }
 
+/* Called with ns->shm_ids(ns).rw_mutex locked */
 static int shm_try_destroy_current(int id, void *p, void *data)
 {
 	struct ipc_namespace *ns = data;
-	struct shmid_kernel *shp = shm_lock(ns, id);
+	struct kern_ipc_perm *ipcp = p;
+	struct shmid_kernel *shp = container_of(ipcp, struct shmid_kernel, shm_perm);
 
-	if (IS_ERR(shp))
-		return 0;
-
-	if (shp->shm_creator != current) {
-		shm_unlock(shp);
+	if (shp->shm_creator != current)
 		return 0;
-	}
 
 	/*
 	 * Mark it as orphaned to destroy the segment when
@@ -255,64 +258,56 @@ static int shm_try_destroy_current(int id, void *p, void *data)
 	 * Don't even try to destroy it.  If shm_rmid_forced=0 and IPC_RMID
 	 * is not set, it shouldn't be deleted here.
 	 */
-	if (!ns->shm_rmid_forced) {
-		shm_unlock(shp);
+	if (!ns->shm_rmid_forced)
 		return 0;
-	}
 
-	if (shm_may_destroy(ns, shp))
+	if (shm_may_destroy(ns, shp)) {
+		shm_lock_by_ptr(shp);
 		shm_destroy(ns, shp);
-	else
-		shm_unlock(shp);
+	}
 	return 0;
 }
 
+/* Called with ns->shm_ids(ns).rw_mutex locked */
 static int shm_try_destroy_orphaned(int id, void *p, void *data)
 {
 	struct ipc_namespace *ns = data;
-	struct shmid_kernel *shp = shm_lock(ns, id);
-
-	if (IS_ERR(shp))
-		return 0;
+	struct kern_ipc_perm *ipcp = p;
+	struct shmid_kernel *shp = container_of(ipcp, struct shmid_kernel, shm_perm);
 
 	/*
 	 * We want to destroy segments without users and with already
 	 * exit'ed originating process.
+	 *
+	 * As shp->* are changed under rw_mutex, it's safe to skip shp locking.
 	 */
-	if (shp->shm_creator != NULL) {
-		shm_unlock(shp);
+	if (shp->shm_creator != NULL)
 		return 0;
-	}
 
-	if (shm_may_destroy(ns, shp))
+	if (shm_may_destroy(ns, shp)) {
+		shm_lock_by_ptr(shp);
 		shm_destroy(ns, shp);
-	else
-		shm_unlock(shp);
+	}
 	return 0;
 }
 
 void shm_destroy_orphaned(struct ipc_namespace *ns)
 {
 	down_write(&shm_ids(ns).rw_mutex);
-	idr_for_each(&shm_ids(ns).ipcs_idr, &shm_try_destroy_orphaned, ns);
+	if (&shm_ids(ns).in_use)
+		idr_for_each(&shm_ids(ns).ipcs_idr, &shm_try_destroy_orphaned, ns);
 	up_write(&shm_ids(ns).rw_mutex);
 }
 
 
 void exit_shm(struct task_struct *task)
 {
-	struct nsproxy *nsp = task->nsproxy;
-	struct ipc_namespace *ns;
-
-	if (!nsp)
-		return;
-	ns = nsp->ipc_ns;
-	if (!ns)
-		return;
+	struct ipc_namespace *ns = task->nsproxy->ipc_ns;
 
 	/* Destroy all already created segments, but not mapped yet */
 	down_write(&shm_ids(ns).rw_mutex);
-	idr_for_each(&shm_ids(ns).ipcs_idr, &shm_try_destroy_current, ns);
+	if (&shm_ids(ns).in_use)
+		idr_for_each(&shm_ids(ns).ipcs_idr, &shm_try_destroy_current, ns);
 	up_write(&shm_ids(ns).rw_mutex);
 }
 

commit 5774ed014f02120db9a6945a1ecebeb97c2acccb
Author: Vasiliy Kulikov <segoon@openwall.com>
Date:   Fri Jul 29 03:55:31 2011 +0400

    shm: handle separate PID namespaces case
    
    shm_try_destroy_orphaned() and shm_try_destroy_current() didn't handle
    the case of separate PID namespaces, but a single IPC namespace.  If
    there are tasks with the same PID values using the same shmem object,
    the wrong destroy decision could be reached.
    
    On shm segment creation store the pointer to the creator task in
    shmid_kernel->shm_creator field and zero it on task exit.  Then
    use the ->shm_creator insread of shm_cprid in both functions.  As
    shmid_kernel object is already locked at this stage, no additional
    locking is needed.
    
    Signed-off-by: Vasiliy Kulikov <segoon@openwall.com>
    Acked-by: Serge Hallyn <serge.hallyn@canonical.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 3f5b14365f33..fdaf8be65b75 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -239,7 +239,23 @@ static int shm_try_destroy_current(int id, void *p, void *data)
 	if (IS_ERR(shp))
 		return 0;
 
-	if (shp->shm_cprid != task_tgid_vnr(current)) {
+	if (shp->shm_creator != current) {
+		shm_unlock(shp);
+		return 0;
+	}
+
+	/*
+	 * Mark it as orphaned to destroy the segment when
+	 * kernel.shm_rmid_forced is changed.
+	 * It is noop if the following shm_may_destroy() returns true.
+	 */
+	shp->shm_creator = NULL;
+
+	/*
+	 * Don't even try to destroy it.  If shm_rmid_forced=0 and IPC_RMID
+	 * is not set, it shouldn't be deleted here.
+	 */
+	if (!ns->shm_rmid_forced) {
 		shm_unlock(shp);
 		return 0;
 	}
@@ -255,7 +271,6 @@ static int shm_try_destroy_orphaned(int id, void *p, void *data)
 {
 	struct ipc_namespace *ns = data;
 	struct shmid_kernel *shp = shm_lock(ns, id);
-	struct task_struct *task;
 
 	if (IS_ERR(shp))
 		return 0;
@@ -263,11 +278,8 @@ static int shm_try_destroy_orphaned(int id, void *p, void *data)
 	/*
 	 * We want to destroy segments without users and with already
 	 * exit'ed originating process.
-	 *
-	 * XXX: the originating process may exist in another pid namespace.
 	 */
-	task = find_task_by_vpid(shp->shm_cprid);
-	if (task != NULL) {
+	if (shp->shm_creator != NULL) {
 		shm_unlock(shp);
 		return 0;
 	}
@@ -295,7 +307,7 @@ void exit_shm(struct task_struct *task)
 	if (!nsp)
 		return;
 	ns = nsp->ipc_ns;
-	if (!ns || !ns->shm_rmid_forced)
+	if (!ns)
 		return;
 
 	/* Destroy all already created segments, but not mapped yet */
@@ -494,6 +506,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	shp->shm_segsz = size;
 	shp->shm_nattch = 0;
 	shp->shm_file = file;
+	shp->shm_creator = current;
 	/*
 	 * shmid gets reported as "inode#" in /proc/pid/maps.
 	 * proc-ps tools use this. Changing this will break them.

commit b34a6b1da371ed8af1221459a18c67970f7e3d53
Author: Vasiliy Kulikov <segoon@openwall.com>
Date:   Tue Jul 26 16:08:48 2011 -0700

    ipc: introduce shm_rmid_forced sysctl
    
    Add support for the shm_rmid_forced sysctl.  If set to 1, all shared
    memory objects in current ipc namespace will be automatically forced to
    use IPC_RMID.
    
    The POSIX way of handling shmem allows one to create shm objects and
    call shmdt(), leaving shm object associated with no process, thus
    consuming memory not counted via rlimits.
    
    With shm_rmid_forced=1 the shared memory object is counted at least for
    one process, so OOM killer may effectively kill the fat process holding
    the shared memory.
    
    It obviously breaks POSIX - some programs relying on the feature would
    stop working.  So set shm_rmid_forced=1 only if you're sure nobody uses
    "orphaned" memory.  Use shm_rmid_forced=0 by default for compatability
    reasons.
    
    The feature was previously impemented in -ow as a configure option.
    
    [akpm@linux-foundation.org: fix documentation, per Randy]
    [akpm@linux-foundation.org: fix warning]
    [akpm@linux-foundation.org: readability/conventionality tweaks]
    [akpm@linux-foundation.org: fix shm_rmid_forced/shm_forced_rmid confusion, use standard comment layout]
    Signed-off-by: Vasiliy Kulikov <segoon@openwall.com>
    Cc: Randy Dunlap <rdunlap@xenotime.net>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: "Serge E. Hallyn" <serge.hallyn@canonical.com>
    Cc: Daniel Lezcano <daniel.lezcano@free.fr>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Cc: Solar Designer <solar@openwall.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 27884adb1a90..3f5b14365f33 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -74,6 +74,7 @@ void shm_init_ns(struct ipc_namespace *ns)
 	ns->shm_ctlmax = SHMMAX;
 	ns->shm_ctlall = SHMALL;
 	ns->shm_ctlmni = SHMMNI;
+	ns->shm_rmid_forced = 0;
 	ns->shm_tot = 0;
 	ipc_init_ids(&shm_ids(ns));
 }
@@ -186,6 +187,23 @@ static void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)
 	ipc_rcu_putref(shp);
 }
 
+/*
+ * shm_may_destroy - identifies whether shm segment should be destroyed now
+ *
+ * Returns true if and only if there are no active users of the segment and
+ * one of the following is true:
+ *
+ * 1) shmctl(id, IPC_RMID, NULL) was called for this shp
+ *
+ * 2) sysctl kernel.shm_rmid_forced is set to 1.
+ */
+static bool shm_may_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)
+{
+	return (shp->shm_nattch == 0) &&
+	       (ns->shm_rmid_forced ||
+		(shp->shm_perm.mode & SHM_DEST));
+}
+
 /*
  * remove the attach descriptor vma.
  * free memory for segment if it is marked destroyed.
@@ -206,11 +224,83 @@ static void shm_close(struct vm_area_struct *vma)
 	shp->shm_lprid = task_tgid_vnr(current);
 	shp->shm_dtim = get_seconds();
 	shp->shm_nattch--;
-	if(shp->shm_nattch == 0 &&
-	   shp->shm_perm.mode & SHM_DEST)
+	if (shm_may_destroy(ns, shp))
+		shm_destroy(ns, shp);
+	else
+		shm_unlock(shp);
+	up_write(&shm_ids(ns).rw_mutex);
+}
+
+static int shm_try_destroy_current(int id, void *p, void *data)
+{
+	struct ipc_namespace *ns = data;
+	struct shmid_kernel *shp = shm_lock(ns, id);
+
+	if (IS_ERR(shp))
+		return 0;
+
+	if (shp->shm_cprid != task_tgid_vnr(current)) {
+		shm_unlock(shp);
+		return 0;
+	}
+
+	if (shm_may_destroy(ns, shp))
+		shm_destroy(ns, shp);
+	else
+		shm_unlock(shp);
+	return 0;
+}
+
+static int shm_try_destroy_orphaned(int id, void *p, void *data)
+{
+	struct ipc_namespace *ns = data;
+	struct shmid_kernel *shp = shm_lock(ns, id);
+	struct task_struct *task;
+
+	if (IS_ERR(shp))
+		return 0;
+
+	/*
+	 * We want to destroy segments without users and with already
+	 * exit'ed originating process.
+	 *
+	 * XXX: the originating process may exist in another pid namespace.
+	 */
+	task = find_task_by_vpid(shp->shm_cprid);
+	if (task != NULL) {
+		shm_unlock(shp);
+		return 0;
+	}
+
+	if (shm_may_destroy(ns, shp))
 		shm_destroy(ns, shp);
 	else
 		shm_unlock(shp);
+	return 0;
+}
+
+void shm_destroy_orphaned(struct ipc_namespace *ns)
+{
+	down_write(&shm_ids(ns).rw_mutex);
+	idr_for_each(&shm_ids(ns).ipcs_idr, &shm_try_destroy_orphaned, ns);
+	up_write(&shm_ids(ns).rw_mutex);
+}
+
+
+void exit_shm(struct task_struct *task)
+{
+	struct nsproxy *nsp = task->nsproxy;
+	struct ipc_namespace *ns;
+
+	if (!nsp)
+		return;
+	ns = nsp->ipc_ns;
+	if (!ns || !ns->shm_rmid_forced)
+		return;
+
+	/* Destroy all already created segments, but not mapped yet */
+	down_write(&shm_ids(ns).rw_mutex);
+	idr_for_each(&shm_ids(ns).ipcs_idr, &shm_try_destroy_current, ns);
 	up_write(&shm_ids(ns).rw_mutex);
 }
 
@@ -950,8 +1040,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	shp = shm_lock(ns, shmid);
 	BUG_ON(IS_ERR(shp));
 	shp->shm_nattch--;
-	if(shp->shm_nattch == 0 &&
-	   shp->shm_perm.mode & SHM_DEST)
+	if (shm_may_destroy(ns, shp))
 		shm_destroy(ns, shp);
 	else
 		shm_unlock(shp);

commit 02c24a82187d5a628c68edfe71ae60dc135cd178
Author: Josef Bacik <josef@redhat.com>
Date:   Sat Jul 16 20:44:56 2011 -0400

    fs: push i_mutex and filemap_write_and_wait down into ->fsync() handlers
    
    Btrfs needs to be able to control how filemap_write_and_wait_range() is called
    in fsync to make it less of a painful operation, so push down taking i_mutex and
    the calling of filemap_write_and_wait() down into the ->fsync() handlers.  Some
    file systems can drop taking the i_mutex altogether it seems, like ext3 and
    ocfs2.  For correctness sake I just pushed everything down in all cases to make
    sure that we keep the current behavior the same for everybody, and then each
    individual fs maintainer can make up their mind about what to do from there.
    Thanks,
    
    Acked-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Josef Bacik <josef@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index ab3385a21b27..27884adb1a90 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -277,13 +277,13 @@ static int shm_release(struct inode *ino, struct file *file)
 	return 0;
 }
 
-static int shm_fsync(struct file *file, int datasync)
+static int shm_fsync(struct file *file, loff_t start, loff_t end, int datasync)
 {
 	struct shm_file_data *sfd = shm_file_data(file);
 
 	if (!sfd->file->f_op->fsync)
 		return -EINVAL;
-	return sfd->file->f_op->fsync(sfd->file, datasync);
+	return sfd->file->f_op->fsync(sfd->file, start, end, datasync);
 }
 
 static unsigned long shm_get_unmapped_area(struct file *file,

commit ca16d140af91febe25daeb9e032bf8bd46b8c31f
Author: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Date:   Thu May 26 19:16:19 2011 +0900

    mm: don't access vm_flags as 'int'
    
    The type of vma->vm_flags is 'unsigned long'. Neither 'int' nor
    'unsigned int'. This patch fixes such misuse.
    
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    [ Changed to use a typedef - we'll extend it to cover more cases
      later, since there has been discussion about making it a 64-bit
      type..                      - Linus ]
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 729acb7e3148..ab3385a21b27 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -347,7 +347,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	struct file * file;
 	char name[13];
 	int id;
-	int acctflag = 0;
+	vm_flags_t acctflag = 0;
 
 	if (size < SHMMIN || size > ns->shm_ctlmax)
 		return -EINVAL;

commit 25985edcedea6396277003854657b5f3cb31a628
Author: Lucas De Marchi <lucas.demarchi@profusion.mobi>
Date:   Wed Mar 30 22:57:33 2011 -0300

    Fix common misspellings
    
    Fixes generated by 'codespell' and manually reviewed.
    
    Signed-off-by: Lucas De Marchi <lucas.demarchi@profusion.mobi>

diff --git a/ipc/shm.c b/ipc/shm.c
index 8644452f5c4c..729acb7e3148 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1056,7 +1056,7 @@ SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 	/*
 	 * We need look no further than the maximum address a fragment
 	 * could possibly have landed at. Also cast things to loff_t to
-	 * prevent overflows and make comparisions vs. equal-width types.
+	 * prevent overflows and make comparisons vs. equal-width types.
 	 */
 	size = PAGE_ALIGN(size);
 	while (vma && (loff_t)(vma->vm_end - addr) <= size) {

commit b0e77598f87107001a00b8a4ece9c95e4254ccc4
Author: Serge E. Hallyn <serge@hallyn.com>
Date:   Wed Mar 23 16:43:24 2011 -0700

    userns: user namespaces: convert several capable() calls
    
    CAP_IPC_OWNER and CAP_IPC_LOCK can be checked against current_user_ns(),
    because the resource comes from current's own ipc namespace.
    
    setuid/setgid are to uids in own namespace, so again checks can be against
    current_user_ns().
    
    Changelog:
            Jan 11: Use task_ns_capable() in place of sched_capable().
            Jan 11: Use nsown_capable() as suggested by Bastian Blank.
            Jan 11: Clarify (hopefully) some logic in futex and sched.c
            Feb 15: use ns_capable for ipc, not nsown_capable
            Feb 23: let copy_ipcs handle setting ipc_ns->user_ns
            Feb 23: pass ns down rather than taking it from current
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Serge E. Hallyn <serge.hallyn@canonical.com>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Acked-by: Daniel Lezcano <daniel.lezcano@free.fr>
    Acked-by: David Howells <dhowells@redhat.com>
    Cc: James Morris <jmorris@namei.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 7d3bb22a9302..8644452f5c4c 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -623,7 +623,8 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 			return -EFAULT;
 	}
 
-	ipcp = ipcctl_pre_down(&shm_ids(ns), shmid, cmd, &shmid64.shm_perm, 0);
+	ipcp = ipcctl_pre_down(ns, &shm_ids(ns), shmid, cmd,
+			       &shmid64.shm_perm, 0);
 	if (IS_ERR(ipcp))
 		return PTR_ERR(ipcp);
 
@@ -737,7 +738,7 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 			result = 0;
 		}
 		err = -EACCES;
-		if (ipcperms (&shp->shm_perm, S_IRUGO))
+		if (ipcperms(ns, &shp->shm_perm, S_IRUGO))
 			goto out_unlock;
 		err = security_shm_shmctl(shp, cmd);
 		if (err)
@@ -773,7 +774,7 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 
 		audit_ipc_obj(&(shp->shm_perm));
 
-		if (!capable(CAP_IPC_LOCK)) {
+		if (!ns_capable(ns->user_ns, CAP_IPC_LOCK)) {
 			uid_t euid = current_euid();
 			err = -EPERM;
 			if (euid != shp->shm_perm.uid &&
@@ -888,7 +889,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	}
 
 	err = -EACCES;
-	if (ipcperms(&shp->shm_perm, acc_mode))
+	if (ipcperms(ns, &shp->shm_perm, acc_mode))
 		goto out_unlock;
 
 	err = security_shm_shmat(shp, shmaddr, shmflg);

commit 3af54c9bd9e6f14f896aac1bb0e8405ae0bc7a44
Author: Vasiliy Kulikov <segooon@gmail.com>
Date:   Sat Oct 30 18:22:49 2010 +0400

    ipc: shm: fix information leak to userland
    
    The shmid_ds structure is copied to userland with shm_unused{,2,3}
    fields unitialized.  It leads to leaking of contents of kernel stack
    memory.
    
    Signed-off-by: Vasiliy Kulikov <segooon@gmail.com>
    Acked-by: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: stable@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index fd658a1c2b88..7d3bb22a9302 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -479,6 +479,7 @@ static inline unsigned long copy_shmid_to_user(void __user *buf, struct shmid64_
 	    {
 		struct shmid_ds out;
 
+		memset(&out, 0, sizeof(out));
 		ipc64_perm_to_ipc_perm(&in->shm_perm, &out.shm_perm);
 		out.shm_segsz	= in->shm_segsz;
 		out.shm_atime	= in->shm_atime;

commit b795218075a1e1183169abb66a90dcdcf30367f9
Author: Helge Deller <deller@gmx.de>
Date:   Wed Oct 27 15:34:16 2010 -0700

    ipc/shm.c: add RSS and swap size information to /proc/sysvipc/shm
    
    The kernel currently provides no functionality to analyze the RSS and swap
    space usage of each individual sysvipc shared memory segment.
    
    This patch adds this info for each existing shm segment by extending the
    output of /proc/sysvipc/shm by two columns for RSS and swap.
    
    Since shmctl(SHM_INFO) already provides a similiar calculation (it
    currently sums up all RSS/swap info for all segments), I did split out a
    static function which is now used by the /proc/sysvipc/shm output and
    shmctl(SHM_INFO).
    
    SAP products (esp.  the SAP Netweaver ABAP Kernel) uses lots of big shared
    memory segments (we often have Linux systems with >= 16GB shm usage).
    Sometimes we get customer reports about "slow" system responses and while
    looking into their configurations we often find massive swapping activity
    on the system.  With this patch it's now easy to see from the command line
    if and which shm segments gets swapped out (and how much) and can more
    easily give recommendations for system tuning.  Without the patch it's
    currently not possible to do such shm analysis at all.
    
    Also...
    
    Add some spaces in front of the "size" field for 64bit kernels to get the
    columns correct if you cat the contents of the file.  In
    sysvipc_shm_proc_show() the kernel prints the size value in "SPEC_SIZE"
    format, which is defined like this:
    
    #if BITS_PER_LONG <= 32
    #define SIZE_SPEC "%10lu"
    #else
    #define SIZE_SPEC "%21lu"
    #endif
    
    So, if the header is not adjusted, the columns are not correctly aligned.
    I actually tested this on 32- and 64-bit and it seems correct now.
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Acked-by: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 7bc46a9fe1f8..fd658a1c2b88 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -108,7 +108,11 @@ void __init shm_init (void)
 {
 	shm_init_ns(&init_ipc_ns);
 	ipc_init_proc_interface("sysvipc/shm",
-				"       key      shmid perms       size  cpid  lpid nattch   uid   gid  cuid  cgid      atime      dtime      ctime\n",
+#if BITS_PER_LONG <= 32
+				"       key      shmid perms       size  cpid  lpid nattch   uid   gid  cuid  cgid      atime      dtime      ctime        rss       swap\n",
+#else
+				"       key      shmid perms                  size  cpid  lpid nattch   uid   gid  cuid  cgid      atime      dtime      ctime                   rss                  swap\n",
+#endif
 				IPC_SHM_IDS, sysvipc_shm_proc_show);
 }
 
@@ -543,6 +547,34 @@ static inline unsigned long copy_shminfo_to_user(void __user *buf, struct shminf
 	}
 }
 
+/*
+ * Calculate and add used RSS and swap pages of a shm.
+ * Called with shm_ids.rw_mutex held as a reader
+ */
+static void shm_add_rss_swap(struct shmid_kernel *shp,
+	unsigned long *rss_add, unsigned long *swp_add)
+{
+	struct inode *inode;
+
+	inode = shp->shm_file->f_path.dentry->d_inode;
+
+	if (is_file_hugepages(shp->shm_file)) {
+		struct address_space *mapping = inode->i_mapping;
+		struct hstate *h = hstate_file(shp->shm_file);
+		*rss_add += pages_per_huge_page(h) * mapping->nrpages;
+	} else {
+#ifdef CONFIG_SHMEM
+		struct shmem_inode_info *info = SHMEM_I(inode);
+		spin_lock(&info->lock);
+		*rss_add += inode->i_mapping->nrpages;
+		*swp_add += info->swapped;
+		spin_unlock(&info->lock);
+#else
+		*rss_add += inode->i_mapping->nrpages;
+#endif
+	}
+}
+
 /*
  * Called with shm_ids.rw_mutex held as a reader
  */
@@ -560,30 +592,13 @@ static void shm_get_stat(struct ipc_namespace *ns, unsigned long *rss,
 	for (total = 0, next_id = 0; total < in_use; next_id++) {
 		struct kern_ipc_perm *ipc;
 		struct shmid_kernel *shp;
-		struct inode *inode;
 
 		ipc = idr_find(&shm_ids(ns).ipcs_idr, next_id);
 		if (ipc == NULL)
 			continue;
 		shp = container_of(ipc, struct shmid_kernel, shm_perm);
 
-		inode = shp->shm_file->f_path.dentry->d_inode;
-
-		if (is_file_hugepages(shp->shm_file)) {
-			struct address_space *mapping = inode->i_mapping;
-			struct hstate *h = hstate_file(shp->shm_file);
-			*rss += pages_per_huge_page(h) * mapping->nrpages;
-		} else {
-#ifdef CONFIG_SHMEM
-			struct shmem_inode_info *info = SHMEM_I(inode);
-			spin_lock(&info->lock);
-			*rss += inode->i_mapping->nrpages;
-			*swp += info->swapped;
-			spin_unlock(&info->lock);
-#else
-			*rss += inode->i_mapping->nrpages;
-#endif
-		}
+		shm_add_rss_swap(shp, rss, swp);
 
 		total++;
 	}
@@ -1072,6 +1087,9 @@ SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 static int sysvipc_shm_proc_show(struct seq_file *s, void *it)
 {
 	struct shmid_kernel *shp = it;
+	unsigned long rss = 0, swp = 0;
+
+	shm_add_rss_swap(shp, &rss, &swp);
 
 #if BITS_PER_LONG <= 32
 #define SIZE_SPEC "%10lu"
@@ -1081,7 +1099,8 @@ static int sysvipc_shm_proc_show(struct seq_file *s, void *it)
 
 	return seq_printf(s,
 			  "%10d %10d  %4o " SIZE_SPEC " %5u %5u  "
-			  "%5lu %5u %5u %5u %5u %10lu %10lu %10lu\n",
+			  "%5lu %5u %5u %5u %5u %10lu %10lu %10lu "
+			  SIZE_SPEC " " SIZE_SPEC "\n",
 			  shp->shm_perm.key,
 			  shp->shm_perm.id,
 			  shp->shm_perm.mode,
@@ -1095,6 +1114,8 @@ static int sysvipc_shm_proc_show(struct seq_file *s, void *it)
 			  shp->shm_perm.cgid,
 			  shp->shm_atim,
 			  shp->shm_dtim,
-			  shp->shm_ctim);
+			  shp->shm_ctim,
+			  rss * PAGE_SIZE,
+			  swp * PAGE_SIZE);
 }
 #endif

commit 6038f373a3dc1f1c26496e60b6c40b164716f07e
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Sun Aug 15 18:52:59 2010 +0200

    llseek: automatically add .llseek fop
    
    All file_operations should get a .llseek operation so we can make
    nonseekable_open the default for future file operations without a
    .llseek pointer.
    
    The three cases that we can automatically detect are no_llseek, seq_lseek
    and default_llseek. For cases where we can we can automatically prove that
    the file offset is always ignored, we use noop_llseek, which maintains
    the current behavior of not returning an error from a seek.
    
    New drivers should normally not use noop_llseek but instead use no_llseek
    and call nonseekable_open at open time.  Existing drivers can be converted
    to do the same when the maintainer knows for certain that no user code
    relies on calling seek on the device file.
    
    The generated code is often incorrectly indented and right now contains
    comments that clarify for each added line why a specific variant was
    chosen. In the version that gets submitted upstream, the comments will
    be gone and I will manually fix the indentation, because there does not
    seem to be a way to do that using coccinelle.
    
    Some amount of new code is currently sitting in linux-next that should get
    the same modifications, which I will do at the end of the merge window.
    
    Many thanks to Julia Lawall for helping me learn to write a semantic
    patch that does all this.
    
    ===== begin semantic patch =====
    // This adds an llseek= method to all file operations,
    // as a preparation for making no_llseek the default.
    //
    // The rules are
    // - use no_llseek explicitly if we do nonseekable_open
    // - use seq_lseek for sequential files
    // - use default_llseek if we know we access f_pos
    // - use noop_llseek if we know we don't access f_pos,
    //   but we still want to allow users to call lseek
    //
    @ open1 exists @
    identifier nested_open;
    @@
    nested_open(...)
    {
    <+...
    nonseekable_open(...)
    ...+>
    }
    
    @ open exists@
    identifier open_f;
    identifier i, f;
    identifier open1.nested_open;
    @@
    int open_f(struct inode *i, struct file *f)
    {
    <+...
    (
    nonseekable_open(...)
    |
    nested_open(...)
    )
    ...+>
    }
    
    @ read disable optional_qualifier exists @
    identifier read_f;
    identifier f, p, s, off;
    type ssize_t, size_t, loff_t;
    expression E;
    identifier func;
    @@
    ssize_t read_f(struct file *f, char *p, size_t s, loff_t *off)
    {
    <+...
    (
       *off = E
    |
       *off += E
    |
       func(..., off, ...)
    |
       E = *off
    )
    ...+>
    }
    
    @ read_no_fpos disable optional_qualifier exists @
    identifier read_f;
    identifier f, p, s, off;
    type ssize_t, size_t, loff_t;
    @@
    ssize_t read_f(struct file *f, char *p, size_t s, loff_t *off)
    {
    ... when != off
    }
    
    @ write @
    identifier write_f;
    identifier f, p, s, off;
    type ssize_t, size_t, loff_t;
    expression E;
    identifier func;
    @@
    ssize_t write_f(struct file *f, const char *p, size_t s, loff_t *off)
    {
    <+...
    (
      *off = E
    |
      *off += E
    |
      func(..., off, ...)
    |
      E = *off
    )
    ...+>
    }
    
    @ write_no_fpos @
    identifier write_f;
    identifier f, p, s, off;
    type ssize_t, size_t, loff_t;
    @@
    ssize_t write_f(struct file *f, const char *p, size_t s, loff_t *off)
    {
    ... when != off
    }
    
    @ fops0 @
    identifier fops;
    @@
    struct file_operations fops = {
     ...
    };
    
    @ has_llseek depends on fops0 @
    identifier fops0.fops;
    identifier llseek_f;
    @@
    struct file_operations fops = {
    ...
     .llseek = llseek_f,
    ...
    };
    
    @ has_read depends on fops0 @
    identifier fops0.fops;
    identifier read_f;
    @@
    struct file_operations fops = {
    ...
     .read = read_f,
    ...
    };
    
    @ has_write depends on fops0 @
    identifier fops0.fops;
    identifier write_f;
    @@
    struct file_operations fops = {
    ...
     .write = write_f,
    ...
    };
    
    @ has_open depends on fops0 @
    identifier fops0.fops;
    identifier open_f;
    @@
    struct file_operations fops = {
    ...
     .open = open_f,
    ...
    };
    
    // use no_llseek if we call nonseekable_open
    ////////////////////////////////////////////
    @ nonseekable1 depends on !has_llseek && has_open @
    identifier fops0.fops;
    identifier nso ~= "nonseekable_open";
    @@
    struct file_operations fops = {
    ...  .open = nso, ...
    +.llseek = no_llseek, /* nonseekable */
    };
    
    @ nonseekable2 depends on !has_llseek @
    identifier fops0.fops;
    identifier open.open_f;
    @@
    struct file_operations fops = {
    ...  .open = open_f, ...
    +.llseek = no_llseek, /* open uses nonseekable */
    };
    
    // use seq_lseek for sequential files
    /////////////////////////////////////
    @ seq depends on !has_llseek @
    identifier fops0.fops;
    identifier sr ~= "seq_read";
    @@
    struct file_operations fops = {
    ...  .read = sr, ...
    +.llseek = seq_lseek, /* we have seq_read */
    };
    
    // use default_llseek if there is a readdir
    ///////////////////////////////////////////
    @ fops1 depends on !has_llseek && !nonseekable1 && !nonseekable2 && !seq @
    identifier fops0.fops;
    identifier readdir_e;
    @@
    // any other fop is used that changes pos
    struct file_operations fops = {
    ... .readdir = readdir_e, ...
    +.llseek = default_llseek, /* readdir is present */
    };
    
    // use default_llseek if at least one of read/write touches f_pos
    /////////////////////////////////////////////////////////////////
    @ fops2 depends on !fops1 && !has_llseek && !nonseekable1 && !nonseekable2 && !seq @
    identifier fops0.fops;
    identifier read.read_f;
    @@
    // read fops use offset
    struct file_operations fops = {
    ... .read = read_f, ...
    +.llseek = default_llseek, /* read accesses f_pos */
    };
    
    @ fops3 depends on !fops1 && !fops2 && !has_llseek && !nonseekable1 && !nonseekable2 && !seq @
    identifier fops0.fops;
    identifier write.write_f;
    @@
    // write fops use offset
    struct file_operations fops = {
    ... .write = write_f, ...
    +       .llseek = default_llseek, /* write accesses f_pos */
    };
    
    // Use noop_llseek if neither read nor write accesses f_pos
    ///////////////////////////////////////////////////////////
    
    @ fops4 depends on !fops1 && !fops2 && !fops3 && !has_llseek && !nonseekable1 && !nonseekable2 && !seq @
    identifier fops0.fops;
    identifier read_no_fpos.read_f;
    identifier write_no_fpos.write_f;
    @@
    // write fops use offset
    struct file_operations fops = {
    ...
     .write = write_f,
     .read = read_f,
    ...
    +.llseek = noop_llseek, /* read and write both use no f_pos */
    };
    
    @ depends on has_write && !has_read && !fops1 && !fops2 && !has_llseek && !nonseekable1 && !nonseekable2 && !seq @
    identifier fops0.fops;
    identifier write_no_fpos.write_f;
    @@
    struct file_operations fops = {
    ... .write = write_f, ...
    +.llseek = noop_llseek, /* write uses no f_pos */
    };
    
    @ depends on has_read && !has_write && !fops1 && !fops2 && !has_llseek && !nonseekable1 && !nonseekable2 && !seq @
    identifier fops0.fops;
    identifier read_no_fpos.read_f;
    @@
    struct file_operations fops = {
    ... .read = read_f, ...
    +.llseek = noop_llseek, /* read uses no f_pos */
    };
    
    @ depends on !has_read && !has_write && !fops1 && !fops2 && !has_llseek && !nonseekable1 && !nonseekable2 && !seq @
    identifier fops0.fops;
    @@
    struct file_operations fops = {
    ...
    +.llseek = noop_llseek, /* no read or write fn */
    };
    ===== End semantic patch =====
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Cc: Julia Lawall <julia@diku.dk>
    Cc: Christoph Hellwig <hch@infradead.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 52ed77eb9713..7bc46a9fe1f8 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -298,6 +298,7 @@ static const struct file_operations shm_file_operations = {
 #ifndef CONFIG_MMU
 	.get_unmapped_area	= shm_get_unmapped_area,
 #endif
+	.llseek		= noop_llseek,
 };
 
 static const struct file_operations shm_file_operations_huge = {
@@ -305,6 +306,7 @@ static const struct file_operations shm_file_operations_huge = {
 	.fsync		= shm_fsync,
 	.release	= shm_release,
 	.get_unmapped_area	= shm_get_unmapped_area,
+	.llseek		= noop_llseek,
 };
 
 int is_file_shm_hugepages(struct file *file)

commit 7ea8085910ef3dd4f3cad6845aaa2b580d39b115
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed May 26 17:53:25 2010 +0200

    drop unused dentry argument to ->fsync
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 1a314c89f93c..52ed77eb9713 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -273,16 +273,13 @@ static int shm_release(struct inode *ino, struct file *file)
 	return 0;
 }
 
-static int shm_fsync(struct file *file, struct dentry *dentry, int datasync)
+static int shm_fsync(struct file *file, int datasync)
 {
-	int (*fsync) (struct file *, struct dentry *, int datasync);
 	struct shm_file_data *sfd = shm_file_data(file);
-	int ret = -EINVAL;
 
-	fsync = sfd->file->f_op->fsync;
-	if (fsync)
-		ret = fsync(sfd->file, sfd->file->f_path.dentry, datasync);
-	return ret;
+	if (!sfd->file->f_op->fsync)
+		return -EINVAL;
+	return sfd->file->f_op->fsync(sfd->file, datasync);
 }
 
 static unsigned long shm_get_unmapped_area(struct file *file,

commit f1eb1332b8f07e937add24c6fd2ac40b8737a2f4
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Wed Mar 10 15:23:05 2010 -0800

    ipc: use rlimit helpers
    
    Make sure compiler won't do weird things with limits.  E.g.  fetching them
    twice may return 2 different values after writable limits are implemented.
    
    I.e.  either use rlimit helpers added in
    3e10e716abf3c71bdb5d86b8f507f9e72236c9cd ("resource: add helpers for
    fetching rlimits") or ACCESS_ONCE if not applicable.
    
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 23256b855819..1a314c89f93c 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -764,8 +764,7 @@ SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 			if (euid != shp->shm_perm.uid &&
 			    euid != shp->shm_perm.cuid)
 				goto out_unlock;
-			if (cmd == SHM_LOCK &&
-			    !current->signal->rlim[RLIMIT_MEMLOCK].rlim_cur)
+			if (cmd == SHM_LOCK && !rlimit(RLIMIT_MEMLOCK))
 				goto out_unlock;
 		}
 

commit ed5e5894b234ce4793d78078c026915b853e0678
Author: David Howells <dhowells@redhat.com>
Date:   Fri Jan 15 17:01:32 2010 -0800

    nommu: fix SYSV SHM for NOMMU
    
    Commit c4caa778157dbbf04116f0ac2111e389b5cd7a29 ("file
    ->get_unmapped_area() shouldn't duplicate work of get_unmapped_area()")
    broke SYSV SHM for NOMMU by taking away the pointer to
    shm_get_unmapped_area() from shm_file_operations.
    
    Put it back conditionally on CONFIG_MMU=n.
    
    file->f_ops->get_unmapped_area() is used to find out the base address for a
    mapping of a mappable chardev device or mappable memory-based file (such as a
    ramfs file).  It needs to be called prior to file->f_ops->mmap() being called.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Greg Ungerer <gerg@snapgear.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 92fe9236258b..23256b855819 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -298,6 +298,9 @@ static const struct file_operations shm_file_operations = {
 	.mmap		= shm_mmap,
 	.fsync		= shm_fsync,
 	.release	= shm_release,
+#ifndef CONFIG_MMU
+	.get_unmapped_area	= shm_get_unmapped_area,
+#endif
 };
 
 static const struct file_operations shm_file_operations_huge = {

commit bac5e54c29f352d962a2447d22735316b347b9f1
Merge: 529e89430d6c c05c4edd876b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Dec 16 12:04:02 2009 -0800

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6
    
    * 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs-2.6: (38 commits)
      direct I/O fallback sync simplification
      ocfs: stop using do_sync_mapping_range
      cleanup blockdev_direct_IO locking
      make generic_acl slightly more generic
      sanitize xattr handler prototypes
      libfs: move EXPORT_SYMBOL for d_alloc_name
      vfs: force reval of target when following LAST_BIND symlinks (try #7)
      ima: limit imbalance msg
      Untangling ima mess, part 3: kill dead code in ima
      Untangling ima mess, part 2: deal with counters
      Untangling ima mess, part 1: alloc_file()
      O_TRUNC open shouldn't fail after file truncation
      ima: call ima_inode_free ima_inode_free
      IMA: clean up the IMA counts updating code
      ima: only insert at inode creation time
      ima: valid return code from ima_inode_alloc
      fs: move get_empty_filp() deffinition to internal.h
      Sanitize exec_permission_lite()
      Kill cached_lookup() and real_lookup()
      Kill path_lookup_open()
      ...
    
    Trivial conflicts in fs/direct-io.c

commit 0552f879d45cecc35d8e372a591fc5ed863bca58
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Dec 16 04:53:03 2009 -0500

    Untangling ima mess, part 1: alloc_file()
    
    There are 2 groups of alloc_file() callers:
            * ones that are followed by ima_counts_get
            * ones giving non-regular files
    So let's pull that ima_counts_get() into alloc_file();
    it's a no-op in case of non-regular files.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 16e39230aa0d..02620fae8e1f 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -39,7 +39,6 @@
 #include <linux/nsproxy.h>
 #include <linux/mount.h>
 #include <linux/ipc_namespace.h>
-#include <linux/ima.h>
 
 #include <asm/uaccess.h>
 
@@ -895,7 +894,6 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 				&shm_file_operations);
 	if (!file)
 		goto out_free;
-	ima_counts_get(file);
 
 	file->private_data = sfd;
 	file->f_mapping = shp->shm_file->f_mapping;

commit 2c48b9c45579a9b5e3e74694eebf3d2451f3dbd3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Aug 9 00:52:35 2009 +0400

    switch alloc_file() to passing struct path
    
    ... and have the caller grab both mnt and dentry; kill
    leak in infiniband, while we are at it.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 11bec626c228..16e39230aa0d 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -878,8 +878,8 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	if (err)
 		goto out_unlock;
 
-	path.dentry = dget(shp->shm_file->f_path.dentry);
-	path.mnt    = shp->shm_file->f_path.mnt;
+	path = shp->shm_file->f_path;
+	path_get(&path);
 	shp->shm_nattch++;
 	size = i_size_read(path.dentry->d_inode);
 	shm_unlock(shp);
@@ -889,8 +889,8 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	if (!sfd)
 		goto out_put_dentry;
 
-	file = alloc_file(path.mnt, path.dentry, f_mode,
-			is_file_hugepages(shp->shm_file) ?
+	file = alloc_file(&path, f_mode,
+			  is_file_hugepages(shp->shm_file) ?
 				&shm_file_operations_huge :
 				&shm_file_operations);
 	if (!file)
@@ -950,7 +950,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 out_free:
 	kfree(sfd);
 out_put_dentry:
-	dput(path.dentry);
+	path_put(&path);
 	goto out_nattch;
 }
 

commit 7d6feeb287c61aafa88f06345387b1188edf4b86
Author: Serge E. Hallyn <serue@us.ibm.com>
Date:   Tue Dec 15 16:47:27 2009 -0800

    ipc ns: fix memory leak (idr)
    
    We have apparently had a memory leak since
    7ca7e564e049d8b350ec9d958ff25eaa24226352 "ipc: store ipcs into IDRs" in
    2007.  The idr of which 3 exist for each ipc namespace is never freed.
    
    This patch simply frees them when the ipcns is freed.  I don't believe any
    idr_remove() are done from rcu (and could therefore be delayed until after
    this idr_destroy()), so the patch should be safe.  Some quick testing
    showed no harm, and the memory leak fixed.
    
    Caught by kmemleak.
    
    Signed-off-by: Serge E. Hallyn <serue@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 11bec626c228..e9b039f74129 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -101,6 +101,7 @@ static void do_shm_rmid(struct ipc_namespace *ns, struct kern_ipc_perm *ipcp)
 void shm_exit_ns(struct ipc_namespace *ns)
 {
 	free_ipcs(ns, &shm_ids(ns), do_shm_rmid);
+	idr_destroy(&ns->ids[IPC_SHM_IDS].ipcs_idr);
 }
 #endif
 

commit c4caa778157dbbf04116f0ac2111e389b5cd7a29
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Nov 30 08:38:43 2009 -0500

    file ->get_unmapped_area() shouldn't duplicate work of get_unmapped_area()
    
    ... we should call mm ->get_unmapped_area() instead and let our caller
    do the final checks.
    
    Acked-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 464694e0aa4a..11bec626c228 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -290,28 +290,28 @@ static unsigned long shm_get_unmapped_area(struct file *file,
 	unsigned long flags)
 {
 	struct shm_file_data *sfd = shm_file_data(file);
-	return get_unmapped_area(sfd->file, addr, len, pgoff, flags);
-}
-
-int is_file_shm_hugepages(struct file *file)
-{
-	int ret = 0;
-
-	if (file->f_op == &shm_file_operations) {
-		struct shm_file_data *sfd;
-		sfd = shm_file_data(file);
-		ret = is_file_hugepages(sfd->file);
-	}
-	return ret;
+	return sfd->file->f_op->get_unmapped_area(sfd->file, addr, len,
+						pgoff, flags);
 }
 
 static const struct file_operations shm_file_operations = {
 	.mmap		= shm_mmap,
 	.fsync		= shm_fsync,
 	.release	= shm_release,
+};
+
+static const struct file_operations shm_file_operations_huge = {
+	.mmap		= shm_mmap,
+	.fsync		= shm_fsync,
+	.release	= shm_release,
 	.get_unmapped_area	= shm_get_unmapped_area,
 };
 
+int is_file_shm_hugepages(struct file *file)
+{
+	return file->f_op == &shm_file_operations_huge;
+}
+
 static const struct vm_operations_struct shm_vm_ops = {
 	.open	= shm_open,	/* callback for a new vm-area open */
 	.close	= shm_close,	/* callback for when the vm-area is released */
@@ -889,7 +889,10 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	if (!sfd)
 		goto out_put_dentry;
 
-	file = alloc_file(path.mnt, path.dentry, f_mode, &shm_file_operations);
+	file = alloc_file(path.mnt, path.dentry, f_mode,
+			is_file_hugepages(shp->shm_file) ?
+				&shm_file_operations_huge :
+				&shm_file_operations);
 	if (!file)
 		goto out_free;
 	ima_counts_get(file);

commit f0f37e2f77731b3473fa6bd5ee53255d9a9cdb40
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Sun Sep 27 22:29:37 2009 +0400

    const: mark struct vm_struct_operations
    
    * mark struct vm_area_struct::vm_ops as const
    * mark vm_ops in AGP code
    
    But leave TTM code alone, something is fishy there with global vm_ops
    being used.
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 9eb1488b543b..464694e0aa4a 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -55,7 +55,7 @@ struct shm_file_data {
 #define shm_file_data(file) (*((struct shm_file_data **)&(file)->private_data))
 
 static const struct file_operations shm_file_operations;
-static struct vm_operations_struct shm_vm_ops;
+static const struct vm_operations_struct shm_vm_ops;
 
 #define shm_ids(ns)	((ns)->ids[IPC_SHM_IDS])
 
@@ -312,7 +312,7 @@ static const struct file_operations shm_file_operations = {
 	.get_unmapped_area	= shm_get_unmapped_area,
 };
 
-static struct vm_operations_struct shm_vm_ops = {
+static const struct vm_operations_struct shm_vm_ops = {
 	.open	= shm_open,	/* callback for a new vm-area open */
 	.close	= shm_close,	/* callback for when the vm-area is released */
 	.fault	= shm_fault,

commit 6bfde05bf5c9682e255c6a2c669dc80f91af6296
Author: Eric B Munson <ebmunson@us.ibm.com>
Date:   Mon Sep 21 17:03:43 2009 -0700

    hugetlbfs: allow the creation of files suitable for MAP_PRIVATE on the vfs internal mount
    
    This patchset adds a flag to mmap that allows the user to request that an
    anonymous mapping be backed with huge pages.  This mapping will borrow
    functionality from the huge page shm code to create a file on the kernel
    internal mount and use it to approximate an anonymous mapping.  The
    MAP_HUGETLB flag is a modifier to MAP_ANONYMOUS and will not work without
    both flags being preset.
    
    A new flag is necessary because there is no other way to hook into huge
    pages without creating a file on a hugetlbfs mount which wouldn't be
    MAP_ANONYMOUS.
    
    To userspace, this mapping will behave just like an anonymous mapping
    because the file is not accessible outside of the kernel.
    
    This patchset is meant to simplify the programming model.  Presently there
    is a large chunk of boiler platecode, contained in libhugetlbfs, required
    to create private, hugepage backed mappings.  This patch set would allow
    use of hugepages without linking to libhugetlbfs or having hugetblfs
    mounted.
    
    Unification of the VM code would provide these same benefits, but it has
    been resisted each time that it has been suggested for several reasons: it
    would break PAGE_SIZE assumptions across the kernel, it makes page-table
    abstractions really expensive, and it does not provide any benefit on
    architectures that do not support huge pages, incurring fast path
    penalties without providing any benefit on these architectures.
    
    This patch:
    
    There are two means of creating mappings backed by huge pages:
    
            1. mmap() a file created on hugetlbfs
            2. Use shm which creates a file on an internal mount which essentially
               maps it MAP_SHARED
    
    The internal mount is only used for shared mappings but there is very
    little that stops it being used for private mappings. This patch extends
    hugetlbfs_file_setup() to deal with the creation of files that will be
    mapped MAP_PRIVATE on the internal hugetlbfs mount. This extended API is
    used in a subsequent patch to implement the MAP_HUGETLB mmap() flag.
    
    Signed-off-by: Eric Munson <ebmunson@us.ibm.com>
    Acked-by: David Rientjes <rientjes@google.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: Adam Litke <agl@us.ibm.com>
    Cc: David Gibson <david@gibson.dropbear.id.au>
    Cc: Lee Schermerhorn <lee.schermerhorn@hp.com>
    Cc: Nick Piggin <nickpiggin@yahoo.com.au>
    Cc: Hugh Dickins <hugh.dickins@tiscali.co.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 30162a59621a..9eb1488b543b 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -370,7 +370,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 		if (shmflg & SHM_NORESERVE)
 			acctflag = VM_NORESERVE;
 		file = hugetlb_file_setup(name, size, acctflag,
-							&shp->mlock_user);
+					&shp->mlock_user, HUGETLB_SHMFS_INODE);
 	} else {
 		/*
 		 * Do not allow no accounting for OVERCOMMIT_NEVER, even

commit 2195d2818c37bdf263865f1e9effccdd9fc5f9d4
Author: Hugh Dickins <hugh.dickins@tiscali.co.uk>
Date:   Sat Sep 12 12:21:27 2009 +0100

    fix undefined reference to user_shm_unlock
    
    My 353d5c30c666580347515da609dd74a2b8e9b828 "mm: fix hugetlb bug due to
    user_shm_unlock call" broke the CONFIG_SYSVIPC !CONFIG_MMU build of both
    2.6.31 and 2.6.30.6: "undefined reference to `user_shm_unlock'".
    
    gcc didn't understand my comment! so couldn't figure out to optimize
    away user_shm_unlock() from the error path in the hugetlb-less case, as
    it does elsewhere.  Help it to do so, in a language it understands.
    
    Reported-by: Mike Frysinger <vapier@gentoo.org>
    Signed-off-by: Hugh Dickins <hugh.dickins@tiscali.co.uk>
    Cc: stable@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 1bc4701ef4f0..30162a59621a 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -410,7 +410,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	return error;
 
 no_id:
-	if (shp->mlock_user)	/* shmflg & SHM_HUGETLB case */
+	if (is_file_hugepages(file) && shp->mlock_user)
 		user_shm_unlock(size, shp->mlock_user);
 	fput(file);
 no_file:

commit 353d5c30c666580347515da609dd74a2b8e9b828
Author: Hugh Dickins <hugh.dickins@tiscali.co.uk>
Date:   Mon Aug 24 16:30:28 2009 +0100

    mm: fix hugetlb bug due to user_shm_unlock call
    
    2.6.30's commit 8a0bdec194c21c8fdef840989d0d7b742bb5d4bc removed
    user_shm_lock() calls in hugetlb_file_setup() but left the
    user_shm_unlock call in shm_destroy().
    
    In detail:
    Assume that can_do_hugetlb_shm() returns true and hence user_shm_lock()
    is not called in hugetlb_file_setup(). However, user_shm_unlock() is
    called in any case in shm_destroy() and in the following
    atomic_dec_and_lock(&up->__count) in free_uid() is executed and if
    up->__count gets zero, also cleanup_user_struct() is scheduled.
    
    Note that sched_destroy_user() is empty if CONFIG_USER_SCHED is not set.
    However, the ref counter up->__count gets unexpectedly non-positive and
    the corresponding structs are freed even though there are live
    references to them, resulting in a kernel oops after a lots of
    shmget(SHM_HUGETLB)/shmctl(IPC_RMID) cycles and CONFIG_USER_SCHED set.
    
    Hugh changed Stefan's suggested patch: can_do_hugetlb_shm() at the
    time of shm_destroy() may give a different answer from at the time
    of hugetlb_file_setup().  And fixed newseg()'s no_id error path,
    which has missed user_shm_unlock() ever since it came in 2.6.9.
    
    Reported-by: Stefan Huber <shuber2@gmail.com>
    Signed-off-by: Hugh Dickins <hugh.dickins@tiscali.co.uk>
    Tested-by: Stefan Huber <shuber2@gmail.com>
    Cc: stable@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 15dd238e5338..1bc4701ef4f0 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -174,7 +174,7 @@ static void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)
 	shm_unlock(shp);
 	if (!is_file_hugepages(shp->shm_file))
 		shmem_lock(shp->shm_file, 0, shp->mlock_user);
-	else
+	else if (shp->mlock_user)
 		user_shm_unlock(shp->shm_file->f_path.dentry->d_inode->i_size,
 						shp->mlock_user);
 	fput (shp->shm_file);
@@ -369,8 +369,8 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 		/* hugetlb_file_setup applies strict accounting */
 		if (shmflg & SHM_NORESERVE)
 			acctflag = VM_NORESERVE;
-		file = hugetlb_file_setup(name, size, acctflag);
-		shp->mlock_user = current_user();
+		file = hugetlb_file_setup(name, size, acctflag,
+							&shp->mlock_user);
 	} else {
 		/*
 		 * Do not allow no accounting for OVERCOMMIT_NEVER, even
@@ -410,6 +410,8 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	return error;
 
 no_id:
+	if (shp->mlock_user)	/* shmflg & SHM_HUGETLB case */
+		user_shm_unlock(size, shp->mlock_user);
 	fput(file);
 no_file:
 	security_shm_free(shp);

commit 73fbad283cfbbcf02939bdbda31fc4a30e729cca
Merge: 769f3e8c3847 35f2c2f6f6ae
Author: James Morris <jmorris@namei.org>
Date:   Thu Jun 11 11:03:14 2009 +1000

    Merge branch 'next' into for-linus

commit 586c7e6a280580fd94b662bf486f9bb31098d14b
Author: Mike Frysinger <vapier@gentoo.org>
Date:   Tue Jun 9 16:26:23 2009 -0700

    shm: fix unused warnings on nommu
    
    The massive nommu update (8feae131) resulted in these warnings:
    ipc/shm.c: In function `sys_shmdt':
    ipc/shm.c:974: warning: unused variable `size'
    ipc/shm.c:972: warning: unused variable `next'
    
    Signed-off-by: Mike Frysinger <vapier@gentoo.org>
    Cc: David Howells <dhowells@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index faa46da99ebe..425971600485 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -969,10 +969,13 @@ SYSCALL_DEFINE3(shmat, int, shmid, char __user *, shmaddr, int, shmflg)
 SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 {
 	struct mm_struct *mm = current->mm;
-	struct vm_area_struct *vma, *next;
+	struct vm_area_struct *vma;
 	unsigned long addr = (unsigned long)shmaddr;
-	loff_t size = 0;
 	int retval = -EINVAL;
+#ifdef CONFIG_MMU
+	loff_t size = 0;
+	struct vm_area_struct *next;
+#endif
 
 	if (addr & ~PAGE_MASK)
 		return retval;

commit c9d9ac525a0285a5b5ad9c3f9aa8b7c1753e6121
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Tue May 19 13:25:58 2009 -0400

    integrity: move ima_counts_get
    
    Based on discussion on lkml (Andrew Morton and Eric Paris),
    move ima_counts_get down a layer into shmem/hugetlb__file_setup().
    Resolves drm shmem_file_setup() usage case as well.
    
    HD comment:
      I still think you're doing this at the wrong level, but recognize
      that you probably won't be persuaded until a few more users of
      alloc_file() emerge, all wanting your ima_counts_get().
    
      Resolving GEM's shmem_file_setup() is an improvement, so I'll say
    
    Acked-by: Hugh Dickins <hugh.dickins@tiscali.co.uk>
    Signed-off-by: Mimi Zohar <zohar@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 47b464229cd5..560818353599 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -384,7 +384,6 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	error = PTR_ERR(file);
 	if (IS_ERR(file))
 		goto no_file;
-	ima_counts_get(file);
 
 	id = ipc_addid(&shm_ids(ns), &shp->shm_perm, ns->shm_ctlmni);
 	if (id < 0) {

commit b9fc745db833bbf74b4988493b8cd902a84c9415
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Tue May 19 13:25:57 2009 -0400

    integrity: path_check update
    
    - Add support in ima_path_check() for integrity checking without
    incrementing the counts. (Required for nfsd.)
    - rename and export opencount_get to ima_counts_get
    - replace ima_shm_check calls with ima_counts_get
    - export ima_path_check
    
    Signed-off-by: Mimi Zohar <zohar@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index faa46da99ebe..47b464229cd5 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -384,7 +384,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	error = PTR_ERR(file);
 	if (IS_ERR(file))
 		goto no_file;
-	ima_shm_check(file);
+	ima_counts_get(file);
 
 	id = ipc_addid(&shm_ids(ns), &shp->shm_perm, ns->shm_ctlmni);
 	if (id < 0) {
@@ -891,7 +891,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	file = alloc_file(path.mnt, path.dentry, f_mode, &shm_file_operations);
 	if (!file)
 		goto out_free;
-	ima_shm_check(file);
+	ima_counts_get(file);
 
 	file->private_data = sfd;
 	file->f_mapping = shp->shm_file->f_mapping;

commit e562aebc6ccd4385cbbf24debe88ab4bb500c5b4
Author: Tony Battersby <tonyb@cybernetics.com>
Date:   Thu Apr 2 16:58:26 2009 -0700

    ipc: make shm_get_stat() more robust
    
    shm_get_stat() assumes idr_find(&shm_ids(ns).ipcs_idr) returns "struct
    shmid_kernel *"; all other callers assume that it returns "struct
    kern_ipc_perm *".  This works because "struct kern_ipc_perm" is currently
    the first member of "struct shmid_kernel", but it would be better to use
    container_of() to prevent future breakage.
    
    Signed-off-by: Tony Battersby <tonyb@cybernetics.com>
    Cc: Jiri Olsa <olsajiri@gmail.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index f239d87e0d37..faa46da99ebe 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -555,12 +555,14 @@ static void shm_get_stat(struct ipc_namespace *ns, unsigned long *rss,
 	in_use = shm_ids(ns).in_use;
 
 	for (total = 0, next_id = 0; total < in_use; next_id++) {
+		struct kern_ipc_perm *ipc;
 		struct shmid_kernel *shp;
 		struct inode *inode;
 
-		shp = idr_find(&shm_ids(ns).ipcs_idr, next_id);
-		if (shp == NULL)
+		ipc = idr_find(&shm_ids(ns).ipcs_idr, next_id);
+		if (ipc == NULL)
 			continue;
+		shp = container_of(ipc, struct shmid_kernel, shm_perm);
 
 		inode = shp->shm_file->f_path.dentry->d_inode;
 

commit 703a3cd72817e99201cef84a8a7aecc60b2b3581
Merge: df7f54c012b9 8e0ee43bc2c3
Author: James Morris <jmorris@namei.org>
Date:   Tue Mar 24 10:52:46 2009 +1100

    Merge branch 'master' into next

commit 5a6fe125950676015f5108fb71b2a67441755003
Author: Mel Gorman <mel@csn.ul.ie>
Date:   Tue Feb 10 14:02:27 2009 +0000

    Do not account for the address space used by hugetlbfs using VM_ACCOUNT
    
    When overcommit is disabled, the core VM accounts for pages used by anonymous
    shared, private mappings and special mappings. It keeps track of VMAs that
    should be accounted for with VM_ACCOUNT and VMAs that never had a reserve
    with VM_NORESERVE.
    
    Overcommit for hugetlbfs is much riskier than overcommit for base pages
    due to contiguity requirements. It avoids overcommiting on both shared and
    private mappings using reservation counters that are checked and updated
    during mmap(). This ensures (within limits) that hugepages exist in the
    future when faults occurs or it is too easy to applications to be SIGKILLed.
    
    As hugetlbfs makes its own reservations of a different unit to the base page
    size, VM_ACCOUNT should never be set. Even if the units were correct, we would
    double account for the usage in the core VM and hugetlbfs. VM_NORESERVE may
    be set because an application can request no reserves be made for hugetlbfs
    at the risk of getting killed later.
    
    With commit fc8744adc870a8d4366908221508bb113d8b72ee, VM_NORESERVE and
    VM_ACCOUNT are getting unconditionally set for hugetlbfs-backed mappings. This
    breaks the accounting for both the core VM and hugetlbfs, can trigger an
    OOM storm when hugepage pools are too small lockups and corrupted counters
    otherwise are used. This patch brings hugetlbfs more in line with how the
    core VM treats VM_NORESERVE but prevents VM_ACCOUNT being set.
    
    Signed-off-by: Mel Gorman <mel@csn.ul.ie>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index f8f69fad3a27..05d51d2a792c 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -340,6 +340,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	struct file * file;
 	char name[13];
 	int id;
+	int acctflag = 0;
 
 	if (size < SHMMIN || size > ns->shm_ctlmax)
 		return -EINVAL;
@@ -364,11 +365,12 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 
 	sprintf (name, "SYSV%08x", key);
 	if (shmflg & SHM_HUGETLB) {
-		/* hugetlb_file_setup takes care of mlock user accounting */
-		file = hugetlb_file_setup(name, size);
+		/* hugetlb_file_setup applies strict accounting */
+		if (shmflg & SHM_NORESERVE)
+			acctflag = VM_NORESERVE;
+		file = hugetlb_file_setup(name, size, acctflag);
 		shp->mlock_user = current_user();
 	} else {
-		int acctflag = 0;
 		/*
 		 * Do not allow no accounting for OVERCOMMIT_NEVER, even
 	 	 * if it's asked for.

commit cb5629b10d64a8006622ce3a52bc887d91057d69
Merge: 8920d5ad6ba7 f01d1d546abb
Author: James Morris <jmorris@namei.org>
Date:   Fri Feb 6 11:01:45 2009 +1100

    Merge branch 'master' into next
    
    Conflicts:
            fs/namei.c
    
    Manually merged per:
    
    diff --cc fs/namei.c
    index 734f2b5,bbc15c2..0000000
    --- a/fs/namei.c
    +++ b/fs/namei.c
    @@@ -860,9 -848,8 +849,10 @@@ static int __link_path_walk(const char
                    nd->flags |= LOOKUP_CONTINUE;
                    err = exec_permission_lite(inode);
                    if (err == -EAGAIN)
    -                       err = vfs_permission(nd, MAY_EXEC);
    +                       err = inode_permission(nd->path.dentry->d_inode,
    +                                              MAY_EXEC);
     +              if (!err)
     +                      err = ima_path_check(&nd->path, MAY_EXEC);
                    if (err)
                            break;
    
    @@@ -1525,14 -1506,9 +1509,14 @@@ int may_open(struct path *path, int acc
                    flag &= ~O_TRUNC;
            }
    
    -       error = vfs_permission(nd, acc_mode);
    +       error = inode_permission(inode, acc_mode);
            if (error)
                    return error;
     +
    -       error = ima_path_check(&nd->path,
    ++      error = ima_path_check(path,
     +                             acc_mode & (MAY_READ | MAY_WRITE | MAY_EXEC));
     +      if (error)
     +              return error;
            /*
             * An append-only file must be opened in append mode for writing.
             */
    
    Signed-off-by: James Morris <jmorris@namei.org>

commit 1df9f0a73178718969ae47d813b8e7aab2cf073c
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Wed Feb 4 09:07:02 2009 -0500

    Integrity: IMA file free imbalance
    
    The number of calls to ima_path_check()/ima_file_free()
    should be balanced.  An extra call to fput(), indicates
    the file could have been accessed without first being
    measured.
    
    Although f_count is incremented/decremented in places other
    than fget/fput, like fget_light/fput_light and get_file, the
    current task must already hold a file refcnt.  The call to
    __fput() is delayed until the refcnt becomes 0, resulting
    in ima_file_free() flagging any changes.
    
    - add hook to increment opencount for IPC shared memory(SYSV),
      shmat files, and /dev/zero
    - moved NULL iint test in opencount_get()
    
    Signed-off-by: Mimi Zohar <zohar@us.ibm.com>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 38a055758a9b..d39bd7637b1c 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -39,6 +39,7 @@
 #include <linux/nsproxy.h>
 #include <linux/mount.h>
 #include <linux/ipc_namespace.h>
+#include <linux/ima.h>
 
 #include <asm/uaccess.h>
 
@@ -381,6 +382,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	error = PTR_ERR(file);
 	if (IS_ERR(file))
 		goto no_file;
+	ima_shm_check(file);
 
 	id = ipc_addid(&shm_ids(ns), &shp->shm_perm, ns->shm_ctlmni);
 	if (id < 0) {
@@ -888,6 +890,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	file = alloc_file(path.mnt, path.dentry, f_mode, &shm_file_operations);
 	if (!file)
 		goto out_free;
+	ima_shm_check(file);
 
 	file->private_data = sfd;
 	file->f_mapping = shp->shm_file->f_mapping;

commit a68e61e8ff2d46327a37b69056998b47745db6fa
Author: Tony Battersby <tonyb@cybernetics.com>
Date:   Wed Feb 4 15:12:04 2009 -0800

    shm: fix shmctl(SHM_INFO) lockup with !CONFIG_SHMEM
    
    shm_get_stat() assumes that the inode is a "struct shmem_inode_info",
    which is incorrect for !CONFIG_SHMEM (see fs/ramfs/inode.c:
    ramfs_get_inode() vs.  mm/shmem.c: shmem_get_inode()).
    
    This bad assumption can cause shmctl(SHM_INFO) to lockup when
    shm_get_stat() tries to spin_lock(&info->lock).  Users of !CONFIG_SHMEM
    may encounter this lockup simply by invoking the 'ipcs' command.
    
    Reported by Jiri Olsa back in February 2008:
    http://lkml.org/lkml/2008/2/29/74
    
    Signed-off-by: Tony Battersby <tonyb@cybernetics.com>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Reported-by: Jiri Olsa <olsajiri@gmail.com>
    Cc: Hugh Dickins <hugh@veritas.com>
    Cc: <stable@kernel.org>         [2.6.everything]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index c0a021f7f41a..f8f69fad3a27 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -565,11 +565,15 @@ static void shm_get_stat(struct ipc_namespace *ns, unsigned long *rss,
 			struct hstate *h = hstate_file(shp->shm_file);
 			*rss += pages_per_huge_page(h) * mapping->nrpages;
 		} else {
+#ifdef CONFIG_SHMEM
 			struct shmem_inode_info *info = SHMEM_I(inode);
 			spin_lock(&info->lock);
 			*rss += inode->i_mapping->nrpages;
 			*swp += info->swapped;
 			spin_unlock(&info->lock);
+#else
+			*rss += inode->i_mapping->nrpages;
+#endif
 		}
 
 		total++;

commit fc8744adc870a8d4366908221508bb113d8b72ee
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jan 31 15:08:56 2009 -0800

    Stop playing silly games with the VM_ACCOUNT flag
    
    The mmap_region() code would temporarily set the VM_ACCOUNT flag for
    anonymous shared mappings just to inform shmem_zero_setup() that it
    should enable accounting for the resulting shm object.  It would then
    clear the flag after calling ->mmap (for the /dev/zero case) or doing
    shmem_zero_setup() (for the MAP_ANON case).
    
    This just resulted in vma merge issues, but also made for just
    unnecessary confusion.  Use the already-existing VM_NORESERVE flag for
    this instead, and let shmem_{zero|file}_setup() just figure it out from
    that.
    
    This also happens to make it obvious that the new DRI2 GEM layer uses a
    non-reserving backing store for its object allocation - which is quite
    possibly not intentional.  But since I didn't want to change semantics
    in this patch, I left it alone, and just updated the caller to use the
    new flag semantics.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index a9e09ad2263e..c0a021f7f41a 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -368,14 +368,14 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 		file = hugetlb_file_setup(name, size);
 		shp->mlock_user = current_user();
 	} else {
-		int acctflag = VM_ACCOUNT;
+		int acctflag = 0;
 		/*
 		 * Do not allow no accounting for OVERCOMMIT_NEVER, even
 	 	 * if it's asked for.
 		 */
 		if  ((shmflg & SHM_NORESERVE) &&
 				sysctl_overcommit_memory != OVERCOMMIT_NEVER)
-			acctflag = 0;
+			acctflag = VM_NORESERVE;
 		file = shmem_file_setup(name, size, acctflag);
 	}
 	error = PTR_ERR(file);

commit d5460c9974a321a194aded4a8c4daaac68ea8171
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed Jan 14 14:14:27 2009 +0100

    [CVE-2009-0029] System call wrappers part 25
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/ipc/shm.c b/ipc/shm.c
index d0ab5527bf45..a9e09ad2263e 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -440,7 +440,7 @@ static inline int shm_more_checks(struct kern_ipc_perm *ipcp,
 	return 0;
 }
 
-asmlinkage long sys_shmget (key_t key, size_t size, int shmflg)
+SYSCALL_DEFINE3(shmget, key_t, key, size_t, size, int, shmflg)
 {
 	struct ipc_namespace *ns;
 	struct ipc_ops shm_ops;
@@ -621,7 +621,7 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 	return err;
 }
 
-asmlinkage long sys_shmctl(int shmid, int cmd, struct shmid_ds __user *buf)
+SYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)
 {
 	struct shmid_kernel *shp;
 	int err, version;
@@ -939,7 +939,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	goto out_nattch;
 }
 
-asmlinkage long sys_shmat(int shmid, char __user *shmaddr, int shmflg)
+SYSCALL_DEFINE3(shmat, int, shmid, char __user *, shmaddr, int, shmflg)
 {
 	unsigned long ret;
 	long err;
@@ -955,7 +955,7 @@ asmlinkage long sys_shmat(int shmid, char __user *shmaddr, int shmflg)
  * detach and kill segment if marked destroyed.
  * The work is done in shm_close.
  */
-asmlinkage long sys_shmdt(char __user *shmaddr)
+SYSCALL_DEFINE1(shmdt, char __user *, shmaddr)
 {
 	struct mm_struct *mm = current->mm;
 	struct vm_area_struct *vma, *next;

commit 8feae13110d60cc6287afabc2887366b0eb226c2
Author: David Howells <dhowells@redhat.com>
Date:   Thu Jan 8 12:04:47 2009 +0000

    NOMMU: Make VMAs per MM as for MMU-mode linux
    
    Make VMAs per mm_struct as for MMU-mode linux.  This solves two problems:
    
     (1) In SYSV SHM where nattch for a segment does not reflect the number of
         shmat's (and forks) done.
    
     (2) In mmap() where the VMA's vm_mm is set to point to the parent mm by an
         exec'ing process when VM_EXECUTABLE is specified, regardless of the fact
         that a VMA might be shared and already have its vm_mm assigned to another
         process or a dead process.
    
    A new struct (vm_region) is introduced to track a mapped region and to remember
    the circumstances under which it may be shared and the vm_list_struct structure
    is discarded as it's no longer required.
    
    This patch makes the following additional changes:
    
     (1) Regions are now allocated with alloc_pages() rather than kmalloc() and
         with no recourse to __GFP_COMP, so the pages are not composite.  Instead,
         each page has a reference on it held by the region.  Anything else that is
         interested in such a page will have to get a reference on it to retain it.
         When the pages are released due to unmapping, each page is passed to
         put_page() and will be freed when the page usage count reaches zero.
    
     (2) Excess pages are trimmed after an allocation as the allocation must be
         made as a power-of-2 quantity of pages.
    
     (3) VMAs are added to the parent MM's R/B tree and mmap lists.  As an MM may
         end up with overlapping VMAs within the tree, the VMA struct address is
         appended to the sort key.
    
     (4) Non-anonymous VMAs are now added to the backing inode's prio list.
    
     (5) Holes may be punched in anonymous VMAs with munmap(), releasing parts of
         the backing region.  The VMA and region structs will be split if
         necessary.
    
     (6) sys_shmdt() only releases one attachment to a SYSV IPC shared memory
         segment instead of all the attachments at that addresss.  Multiple
         shmat()'s return the same address under NOMMU-mode instead of different
         virtual addresses as under MMU-mode.
    
     (7) Core dumping for ELF-FDPIC requires fewer exceptions for NOMMU-mode.
    
     (8) /proc/maps is now the global list of mapped regions, and may list bits
         that aren't actually mapped anywhere.
    
     (9) /proc/meminfo gains a line (tagged "MmapCopy") that indicates the amount
         of RAM currently allocated by mmap to hold mappable regions that can't be
         mapped directly.  These are copies of the backing device or file if not
         anonymous.
    
    These changes make NOMMU mode more similar to MMU mode.  The downside is that
    NOMMU mode requires some extra memory to track things over NOMMU without this
    patch (VMAs are no longer shared, and there are now region structs).
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Tested-by: Mike Frysinger <vapier.adi@gmail.com>
    Acked-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index b125b560240e..d0ab5527bf45 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -990,6 +990,7 @@ asmlinkage long sys_shmdt(char __user *shmaddr)
 	 */
 	vma = find_vma(mm, addr);
 
+#ifdef CONFIG_MMU
 	while (vma) {
 		next = vma->vm_next;
 
@@ -1034,6 +1035,17 @@ asmlinkage long sys_shmdt(char __user *shmaddr)
 		vma = next;
 	}
 
+#else /* CONFIG_MMU */
+	/* under NOMMU conditions, the exact address to be destroyed must be
+	 * given */
+	retval = -EINVAL;
+	if (vma->vm_start == addr && vma->vm_ops == &shm_vm_ops) {
+		do_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start);
+		retval = 0;
+	}
+
+#endif
+
 	up_write(&mm->mmap_sem);
 	return retval;
 }

commit e8148f7588064e45080bf1120883380a2efe5c9b
Author: WANG Cong <wangcong@zeuux.org>
Date:   Tue Jan 6 14:42:49 2009 -0800

    ipc: clean up ipc/shm.c
    
    Use the macro shm_ids().
    
    Remove useless check for a userspace pointer, because copy_to_user()
    will check it.
    
    Some style cleanups.
    
    Signed-off-by: WANG Cong <wangcong@zeuux.org>
    Cc: Nadia Derbey <Nadia.Derbey@bull.net>
    Cc: Pierre Peiffer <peifferp@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 57dd50046cef..b125b560240e 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -75,7 +75,7 @@ void shm_init_ns(struct ipc_namespace *ns)
 	ns->shm_ctlall = SHMALL;
 	ns->shm_ctlmni = SHMMNI;
 	ns->shm_tot = 0;
-	ipc_init_ids(&ns->ids[IPC_SHM_IDS]);
+	ipc_init_ids(&shm_ids(ns));
 }
 
 /*
@@ -644,7 +644,7 @@ asmlinkage long sys_shmctl(int shmid, int cmd, struct shmid_ds __user *buf)
 		if (err)
 			return err;
 
-		memset(&shminfo,0,sizeof(shminfo));
+		memset(&shminfo, 0, sizeof(shminfo));
 		shminfo.shmmni = shminfo.shmseg = ns->shm_ctlmni;
 		shminfo.shmmax = ns->shm_ctlmax;
 		shminfo.shmall = ns->shm_ctlall;
@@ -669,7 +669,7 @@ asmlinkage long sys_shmctl(int shmid, int cmd, struct shmid_ds __user *buf)
 		if (err)
 			return err;
 
-		memset(&shm_info,0,sizeof(shm_info));
+		memset(&shm_info, 0, sizeof(shm_info));
 		down_read(&shm_ids(ns).rw_mutex);
 		shm_info.used_ids = shm_ids(ns).in_use;
 		shm_get_stat (ns, &shm_info.shm_rss, &shm_info.shm_swp);
@@ -678,7 +678,7 @@ asmlinkage long sys_shmctl(int shmid, int cmd, struct shmid_ds __user *buf)
 		shm_info.swap_successes = 0;
 		err = ipc_get_maxid(&shm_ids(ns));
 		up_read(&shm_ids(ns).rw_mutex);
-		if(copy_to_user (buf, &shm_info, sizeof(shm_info))) {
+		if (copy_to_user(buf, &shm_info, sizeof(shm_info))) {
 			err = -EFAULT;
 			goto out;
 		}
@@ -692,11 +692,6 @@ asmlinkage long sys_shmctl(int shmid, int cmd, struct shmid_ds __user *buf)
 		struct shmid64_ds tbuf;
 		int result;
 
-		if (!buf) {
-			err = -EFAULT;
-			goto out;
-		}
-
 		if (cmd == SHM_STAT) {
 			shp = shm_lock(ns, shmid);
 			if (IS_ERR(shp)) {
@@ -712,7 +707,7 @@ asmlinkage long sys_shmctl(int shmid, int cmd, struct shmid_ds __user *buf)
 			}
 			result = 0;
 		}
-		err=-EACCES;
+		err = -EACCES;
 		if (ipcperms (&shp->shm_perm, S_IRUGO))
 			goto out_unlock;
 		err = security_shm_shmctl(shp, cmd);

commit a33e6751003c5ade603737d828b1519d980ce392
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Dec 10 03:40:06 2008 -0500

    sanitize audit_ipc_obj()
    
    * get rid of allocations
    * make it return void
    * simplify callers
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 38a055758a9b..57dd50046cef 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -747,9 +747,7 @@ asmlinkage long sys_shmctl(int shmid, int cmd, struct shmid_ds __user *buf)
 			goto out;
 		}
 
-		err = audit_ipc_obj(&(shp->shm_perm));
-		if (err)
-			goto out_unlock;
+		audit_ipc_obj(&(shp->shm_perm));
 
 		if (!capable(CAP_IPC_LOCK)) {
 			uid_t euid = current_euid();

commit 86a264abe542cfececb4df129bc45a0338d8cdb9
Author: David Howells <dhowells@redhat.com>
Date:   Fri Nov 14 10:39:18 2008 +1100

    CRED: Wrap current->cred and a few other accessors
    
    Wrap current->cred and a few other accessors to hide their actual
    implementation.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: James Morris <jmorris@namei.org>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 264a9d33c5dd..38a055758a9b 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -366,7 +366,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	if (shmflg & SHM_HUGETLB) {
 		/* hugetlb_file_setup takes care of mlock user accounting */
 		file = hugetlb_file_setup(name, size);
-		shp->mlock_user = current->cred->user;
+		shp->mlock_user = current_user();
 	} else {
 		int acctflag = VM_ACCOUNT;
 		/*
@@ -767,7 +767,7 @@ asmlinkage long sys_shmctl(int shmid, int cmd, struct shmid_ds __user *buf)
 			goto out_unlock;
 		
 		if(cmd==SHM_LOCK) {
-			struct user_struct *user = current->cred->user;
+			struct user_struct *user = current_user();
 			if (!is_file_hugepages(shp->shm_file)) {
 				err = shmem_lock(shp->shm_file, 1, user);
 				if (!err && !(shp->shm_perm.mode & SHM_LOCKED)){

commit b6dff3ec5e116e3af6f537d4caedcad6b9e5082a
Author: David Howells <dhowells@redhat.com>
Date:   Fri Nov 14 10:39:16 2008 +1100

    CRED: Separate task security context from task_struct
    
    Separate the task security context from task_struct.  At this point, the
    security data is temporarily embedded in the task_struct with two pointers
    pointing to it.
    
    Note that the Alpha arch is altered as it refers to (E)UID and (E)GID in
    entry.S via asm-offsets.
    
    With comment fixes Signed-off-by: Marc Dionne <marc.c.dionne@gmail.com>
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: James Morris <jmorris@namei.org>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 0c3debbe32d5..264a9d33c5dd 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -366,7 +366,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	if (shmflg & SHM_HUGETLB) {
 		/* hugetlb_file_setup takes care of mlock user accounting */
 		file = hugetlb_file_setup(name, size);
-		shp->mlock_user = current->user;
+		shp->mlock_user = current->cred->user;
 	} else {
 		int acctflag = VM_ACCOUNT;
 		/*
@@ -767,7 +767,7 @@ asmlinkage long sys_shmctl(int shmid, int cmd, struct shmid_ds __user *buf)
 			goto out_unlock;
 		
 		if(cmd==SHM_LOCK) {
-			struct user_struct * user = current->user;
+			struct user_struct *user = current->cred->user;
 			if (!is_file_hugepages(shp->shm_file)) {
 				err = shmem_lock(shp->shm_file, 1, user);
 				if (!err && !(shp->shm_perm.mode & SHM_LOCKED)){

commit 414c0708d0d60eccf8345c405ac81cf32c43e901
Author: David Howells <dhowells@redhat.com>
Date:   Fri Nov 14 10:39:06 2008 +1100

    CRED: Wrap task credential accesses in the SYSV IPC subsystem
    
    Wrap access to task credentials so that they can be separated more easily from
    the task_struct during the introduction of COW creds.
    
    Change most current->(|e|s|fs)[ug]id to current_(|e|s|fs)[ug]id().
    
    Change some task->e?[ug]id to task_e?[ug]id().  In some places it makes more
    sense to use RCU directly rather than a convenient wrapper; these will be
    addressed by later patches.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Reviewed-by: James Morris <jmorris@namei.org>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 867e5d6a55c2..0c3debbe32d5 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -752,9 +752,10 @@ asmlinkage long sys_shmctl(int shmid, int cmd, struct shmid_ds __user *buf)
 			goto out_unlock;
 
 		if (!capable(CAP_IPC_LOCK)) {
+			uid_t euid = current_euid();
 			err = -EPERM;
-			if (current->euid != shp->shm_perm.uid &&
-			    current->euid != shp->shm_perm.cuid)
+			if (euid != shp->shm_perm.uid &&
+			    euid != shp->shm_perm.cuid)
 				goto out_unlock;
 			if (cmd == SHM_LOCK &&
 			    !current->signal->rlim[RLIMIT_MEMLOCK].rlim_cur)

commit aeb5d727062a0238a2f96c9c380fbd2be4640c6f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Sep 2 15:28:45 2008 -0400

    [PATCH] introduce fmode_t, do annotations
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 0add3fa5f547..867e5d6a55c2 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -817,7 +817,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	struct ipc_namespace *ns;
 	struct shm_file_data *sfd;
 	struct path path;
-	mode_t f_mode;
+	fmode_t f_mode;
 
 	err = -EINVAL;
 	if (shmid < 0)

commit 89e004ea55abe201b29e2d6e35124101f1288ef7
Author: Lee Schermerhorn <Lee.Schermerhorn@hp.com>
Date:   Sat Oct 18 20:26:43 2008 -0700

    SHM_LOCKED pages are unevictable
    
    Shmem segments locked into memory via shmctl(SHM_LOCKED) should not be
    kept on the normal LRU, since scanning them is a waste of time and might
    throw off kswapd's balancing algorithms.  Place them on the unevictable
    LRU list instead.
    
    Use the AS_UNEVICTABLE flag to mark address_space of SHM_LOCKed shared
    memory regions as unevictable.  Then these pages will be culled off the
    normal LRU lists during vmscan.
    
    Add new wrapper function to clear the mapping's unevictable state when/if
    shared memory segment is munlocked.
    
    Add 'scan_mapping_unevictable_page()' to mm/vmscan.c to scan all pages in
    the shmem segment's mapping [struct address_space] for evictability now
    that they're no longer locked.  If so, move them to the appropriate zone
    lru list.
    
    Changes depend on [CONFIG_]UNEVICTABLE_LRU.
    
    [kosaki.motohiro@jp.fujitsu.com: revert shm change]
    Signed-off-by: Lee Schermerhorn <lee.schermerhorn@hp.com>
    Signed-off-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: Kosaki Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index e77ec698cf40..0add3fa5f547 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -737,6 +737,10 @@ asmlinkage long sys_shmctl(int shmid, int cmd, struct shmid_ds __user *buf)
 	case SHM_LOCK:
 	case SHM_UNLOCK:
 	{
+		struct file *uninitialized_var(shm_file);
+
+		lru_add_drain_all();  /* drain pagevecs to lru lists */
+
 		shp = shm_lock_check(ns, shmid);
 		if (IS_ERR(shp)) {
 			err = PTR_ERR(shp);

commit 00c2bf85d8febfcfddde63822043462b026134ff
Author: Nadia Derbey <Nadia.Derbey@bull.net>
Date:   Fri Jul 25 01:48:03 2008 -0700

    ipc: get rid of ipc_lock_down()
    
    Remove the ipc_lock_down() routines: they used to call idr_find() locklessly
    (given that the ipc ids lock was already held), so they are not needed
    anymore.
    
    Signed-off-by: Nadia Derbey <Nadia.Derbey@bull.net>
    Acked-by: "Paul E. McKenney" <paulmck@us.ibm.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: Jim Houston <jim.houston@comcast.net>
    Cc: Pierre Peiffer <peifferp@gmail.com>
    Acked-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index a726aebce7d7..e77ec698cf40 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -111,24 +111,9 @@ void __init shm_init (void)
 				IPC_SHM_IDS, sysvipc_shm_proc_show);
 }
 
-/*
- * shm_lock_(check_)down routines are called in the paths where the rw_mutex
- * is held to protect access to the idr tree.
- */
-static inline struct shmid_kernel *shm_lock_down(struct ipc_namespace *ns,
-						int id)
-{
-	struct kern_ipc_perm *ipcp = ipc_lock_down(&shm_ids(ns), id);
-
-	if (IS_ERR(ipcp))
-		return (struct shmid_kernel *)ipcp;
-
-	return container_of(ipcp, struct shmid_kernel, shm_perm);
-}
-
 /*
  * shm_lock_(check_) routines are called in the paths where the rw_mutex
- * is not held.
+ * is not necessarily held.
  */
 static inline struct shmid_kernel *shm_lock(struct ipc_namespace *ns, int id)
 {
@@ -211,7 +196,7 @@ static void shm_close(struct vm_area_struct *vma)
 
 	down_write(&shm_ids(ns).rw_mutex);
 	/* remove from the list of attaches of the shm segment */
-	shp = shm_lock_down(ns, sfd->id);
+	shp = shm_lock(ns, sfd->id);
 	BUG_ON(IS_ERR(shp));
 	shp->shm_lprid = task_tgid_vnr(current);
 	shp->shm_dtim = get_seconds();
@@ -932,7 +917,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 
 out_nattch:
 	down_write(&shm_ids(ns).rw_mutex);
-	shp = shm_lock_down(ns, shmid);
+	shp = shm_lock(ns, shmid);
 	BUG_ON(IS_ERR(shp));
 	shp->shm_nattch--;
 	if(shp->shm_nattch == 0 &&

commit a5516438959d90b071ff0a484ce4f3f523dc3152
Author: Andi Kleen <ak@suse.de>
Date:   Wed Jul 23 21:27:41 2008 -0700

    hugetlb: modular state for hugetlb page size
    
    The goal of this patchset is to support multiple hugetlb page sizes.  This
    is achieved by introducing a new struct hstate structure, which
    encapsulates the important hugetlb state and constants (eg.  huge page
    size, number of huge pages currently allocated, etc).
    
    The hstate structure is then passed around the code which requires these
    fields, they will do the right thing regardless of the exact hstate they
    are operating on.
    
    This patch adds the hstate structure, with a single global instance of it
    (default_hstate), and does the basic work of converting hugetlb to use the
    hstate.
    
    Future patches will add more hstate structures to allow for different
    hugetlbfs mounts to have different page sizes.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Acked-by: Adam Litke <agl@us.ibm.com>
    Acked-by: Nishanth Aravamudan <nacc@us.ibm.com>
    Signed-off-by: Andi Kleen <ak@suse.de>
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 790240cd067f..a726aebce7d7 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -577,7 +577,8 @@ static void shm_get_stat(struct ipc_namespace *ns, unsigned long *rss,
 
 		if (is_file_hugepages(shp->shm_file)) {
 			struct address_space *mapping = inode->i_mapping;
-			*rss += (HPAGE_SIZE/PAGE_SIZE)*mapping->nrpages;
+			struct hstate *h = hstate_file(shp->shm_file);
+			*rss += pages_per_huge_page(h) * mapping->nrpages;
 		} else {
 			struct shmem_inode_info *info = SHMEM_I(inode);
 			spin_lock(&info->lock);

commit 6c826818ff55eae7702b778b5f8bdf765af3b2af
Author: Paul Menage <menage@google.com>
Date:   Thu Jun 12 15:21:49 2008 -0700

    /proc/sysvipc/shm: fix 32-bit truncation of segment sizes
    
    sysvipc_shm_proc_show() picks between format strings (based on the
    expected maximum length of a SHM segment) in a way that prevents gcc from
    performing format checks on the seq_printf() parameters.  This hid two
    format errors - shp->shm_segsz and shp->shm_nattach are both unsigned
    long, but were being printed as unsigned int and signed int respectively.
    This leads to 32-bit truncation of SHM segment sizes reported in
    /proc/sysvipc/shm.  (And for nattach, but that's less of a problem for
    most users).
    
    This patch makes the format string directly visible to gcc's format
    specifier checker, and fixes the two broken format specifiers.
    
    Signed-off-by: Paul Menage <menage@google.com>
    Cc: Nadia Derbey <Nadia.Derbey@bull.net>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Cc: Pierre Peiffer <peifferp@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index d05f6b564998..790240cd067f 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1058,16 +1058,16 @@ asmlinkage long sys_shmdt(char __user *shmaddr)
 static int sysvipc_shm_proc_show(struct seq_file *s, void *it)
 {
 	struct shmid_kernel *shp = it;
-	char *format;
 
-#define SMALL_STRING "%10d %10d  %4o %10u %5u %5u  %5d %5u %5u %5u %5u %10lu %10lu %10lu\n"
-#define BIG_STRING   "%10d %10d  %4o %21u %5u %5u  %5d %5u %5u %5u %5u %10lu %10lu %10lu\n"
+#if BITS_PER_LONG <= 32
+#define SIZE_SPEC "%10lu"
+#else
+#define SIZE_SPEC "%21lu"
+#endif
 
-	if (sizeof(size_t) <= sizeof(int))
-		format = SMALL_STRING;
-	else
-		format = BIG_STRING;
-	return seq_printf(s, format,
+	return seq_printf(s,
+			  "%10d %10d  %4o " SIZE_SPEC " %5u %5u  "
+			  "%5lu %5u %5u %5u %5u %10lu %10lu %10lu\n",
 			  shp->shm_perm.key,
 			  shp->shm_perm.id,
 			  shp->shm_perm.mode,

commit c592713b3e124ce0719e6af4bc2520424c49cbae
Author: Neil Horman <nhorman@tuxdriver.com>
Date:   Tue Jun 10 08:53:39 2008 -0400

    shm: Remove silly double assignment
    
    Found a silly double assignment of err is do_shmat.  Silly, but good to
    clean up the useless code.
    
    Signed-off-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 554429ade079..d05f6b564998 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -894,8 +894,6 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	if (!sfd)
 		goto out_put_dentry;
 
-	err = -ENOMEM;
-
 	file = alloc_file(path.mnt, path.dentry, f_mode, &shm_file_operations);
 	if (!file)
 		goto out_free;

commit a5f75e7f256f75759ec3d6dbef0ba932f1b397d2
Author: Pierre Peiffer <pierre.peiffer@bull.net>
Date:   Tue Apr 29 01:00:54 2008 -0700

    IPC: consolidate all xxxctl_down() functions
    
    semctl_down(), msgctl_down() and shmctl_down() are used to handle the same set
    of commands for each kind of IPC.  They all start to do the same job (they
    retrieve the ipc and do some permission checks) before handling the commands
    on their own.
    
    This patch proposes to consolidate this by moving these same pieces of code
    into one common function called ipcctl_pre_down().
    
    It simplifies a little these xxxctl_down() functions and increases a little
    the maintainability.
    
    Signed-off-by: Pierre Peiffer <pierre.peiffer@bull.net>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Cc: Nadia Derbey <Nadia.Derbey@bull.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 20e03dfc6adb..554429ade079 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -126,18 +126,6 @@ static inline struct shmid_kernel *shm_lock_down(struct ipc_namespace *ns,
 	return container_of(ipcp, struct shmid_kernel, shm_perm);
 }
 
-static inline struct shmid_kernel *shm_lock_check_down(
-						struct ipc_namespace *ns,
-						int id)
-{
-	struct kern_ipc_perm *ipcp = ipc_lock_check_down(&shm_ids(ns), id);
-
-	if (IS_ERR(ipcp))
-		return (struct shmid_kernel *)ipcp;
-
-	return container_of(ipcp, struct shmid_kernel, shm_perm);
-}
-
 /*
  * shm_lock_(check_) routines are called in the paths where the rw_mutex
  * is not held.
@@ -620,33 +608,11 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 			return -EFAULT;
 	}
 
-	down_write(&shm_ids(ns).rw_mutex);
-	shp = shm_lock_check_down(ns, shmid);
-	if (IS_ERR(shp)) {
-		err = PTR_ERR(shp);
-		goto out_up;
-	}
-
-	ipcp = &shp->shm_perm;
-
-	err = audit_ipc_obj(ipcp);
-	if (err)
-		goto out_unlock;
-
-	if (cmd == IPC_SET) {
-		err = audit_ipc_set_perm(0, shmid64.shm_perm.uid,
-					 shmid64.shm_perm.gid,
-					 shmid64.shm_perm.mode);
-		if (err)
-			goto out_unlock;
-	}
+	ipcp = ipcctl_pre_down(&shm_ids(ns), shmid, cmd, &shmid64.shm_perm, 0);
+	if (IS_ERR(ipcp))
+		return PTR_ERR(ipcp);
 
-	if (current->euid != ipcp->uid &&
-	    current->euid != ipcp->cuid &&
-	    !capable(CAP_SYS_ADMIN)) {
-		err = -EPERM;
-		goto out_unlock;
-	}
+	shp = container_of(ipcp, struct shmid_kernel, shm_perm);
 
 	err = security_shm_shmctl(shp, cmd);
 	if (err)

commit 8f4a3809c18ff3107bdbb1fabe3f4e5d2a928321
Author: Pierre Peiffer <pierre.peiffer@bull.net>
Date:   Tue Apr 29 01:00:51 2008 -0700

    IPC: introduce ipc_update_perm()
    
    The IPC_SET command performs the same permission setting for all IPCs.  This
    patch introduces a common ipc_update_perm() function to update these
    permissions and makes use of it for all IPCs.
    
    Signed-off-by: Pierre Peiffer <pierre.peiffer@bull.net>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Cc: Nadia Derbey <Nadia.Derbey@bull.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 5e296b04bd6b..20e03dfc6adb 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -656,10 +656,7 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 		do_shm_rmid(ns, ipcp);
 		goto out_up;
 	case IPC_SET:
-		ipcp->uid = shmid64.shm_perm.uid;
-		ipcp->gid = shmid64.shm_perm.gid;
-		ipcp->mode = (ipcp->mode & ~S_IRWXUGO)
-			| (shmid64.shm_perm.mode & S_IRWXUGO);
+		ipc_update_perm(&shmid64.shm_perm, ipcp);
 		shp->shm_ctim = get_seconds();
 		break;
 	default:

commit 016d7132f246a05e6e34ccba157fa278a96c45ae
Author: Pierre Peiffer <pierre.peiffer@bull.net>
Date:   Tue Apr 29 01:00:50 2008 -0700

    IPC: get rid of the use *_setbuf structure.
    
    All IPCs make use of an intermetiate *_setbuf structure to handle the IPC_SET
    command.  This is not really needed and, moreover, it complicates a little bit
    the code.
    
    This patch gets rid of the use of it and uses directly the semid64_ds/
    msgid64_ds/shmid64_ds structure.
    
    In addition of removing one struture declaration, it also simplifies and
    improves a little bit the common 64-bits path.
    
    Signed-off-by: Pierre Peiffer <pierre.peiffer@bull.net>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Cc: Nadia Derbey <Nadia.Derbey@bull.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 65a44bcc4ac2..5e296b04bd6b 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -511,28 +511,14 @@ static inline unsigned long copy_shmid_to_user(void __user *buf, struct shmid64_
 	}
 }
 
-struct shm_setbuf {
-	uid_t	uid;
-	gid_t	gid;
-	mode_t	mode;
-};	
-
-static inline unsigned long copy_shmid_from_user(struct shm_setbuf *out, void __user *buf, int version)
+static inline unsigned long
+copy_shmid_from_user(struct shmid64_ds *out, void __user *buf, int version)
 {
 	switch(version) {
 	case IPC_64:
-	    {
-		struct shmid64_ds tbuf;
-
-		if (copy_from_user(&tbuf, buf, sizeof(tbuf)))
+		if (copy_from_user(out, buf, sizeof(*out)))
 			return -EFAULT;
-
-		out->uid	= tbuf.shm_perm.uid;
-		out->gid	= tbuf.shm_perm.gid;
-		out->mode	= tbuf.shm_perm.mode;
-
 		return 0;
-	    }
 	case IPC_OLD:
 	    {
 		struct shmid_ds tbuf_old;
@@ -540,9 +526,9 @@ static inline unsigned long copy_shmid_from_user(struct shm_setbuf *out, void __
 		if (copy_from_user(&tbuf_old, buf, sizeof(tbuf_old)))
 			return -EFAULT;
 
-		out->uid	= tbuf_old.shm_perm.uid;
-		out->gid	= tbuf_old.shm_perm.gid;
-		out->mode	= tbuf_old.shm_perm.mode;
+		out->shm_perm.uid	= tbuf_old.shm_perm.uid;
+		out->shm_perm.gid	= tbuf_old.shm_perm.gid;
+		out->shm_perm.mode	= tbuf_old.shm_perm.mode;
 
 		return 0;
 	    }
@@ -625,12 +611,12 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 		       struct shmid_ds __user *buf, int version)
 {
 	struct kern_ipc_perm *ipcp;
-	struct shm_setbuf setbuf;
+	struct shmid64_ds shmid64;
 	struct shmid_kernel *shp;
 	int err;
 
 	if (cmd == IPC_SET) {
-		if (copy_shmid_from_user(&setbuf, buf, version))
+		if (copy_shmid_from_user(&shmid64, buf, version))
 			return -EFAULT;
 	}
 
@@ -648,8 +634,9 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 		goto out_unlock;
 
 	if (cmd == IPC_SET) {
-		err = audit_ipc_set_perm(0, setbuf.uid,
-					 setbuf.gid, setbuf.mode);
+		err = audit_ipc_set_perm(0, shmid64.shm_perm.uid,
+					 shmid64.shm_perm.gid,
+					 shmid64.shm_perm.mode);
 		if (err)
 			goto out_unlock;
 	}
@@ -669,10 +656,10 @@ static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
 		do_shm_rmid(ns, ipcp);
 		goto out_up;
 	case IPC_SET:
-		ipcp->uid = setbuf.uid;
-		ipcp->gid = setbuf.gid;
+		ipcp->uid = shmid64.shm_perm.uid;
+		ipcp->gid = shmid64.shm_perm.gid;
 		ipcp->mode = (ipcp->mode & ~S_IRWXUGO)
-			| (setbuf.mode & S_IRWXUGO);
+			| (shmid64.shm_perm.mode & S_IRWXUGO);
 		shp->shm_ctim = get_seconds();
 		break;
 	default:

commit 8d4cc8b5c5e5bac526618ee704f3cfdcad954e0c
Author: Pierre Peiffer <pierre.peiffer@bull.net>
Date:   Tue Apr 29 01:00:47 2008 -0700

    IPC/shared memory: introduce shmctl_down
    
    Currently, the way the different commands are handled in sys_shmctl introduces
    some duplicated code.
    
    This patch introduces the shmctl_down function to handle all the commands
    requiring the rwmutex to be taken in write mode (ie IPC_SET and IPC_RMID for
    now).  It is the equivalent function of semctl_down for shared memory.
    
    This removes some duplicated code for handling these both commands and
    harmonizes the way they are handled among all IPCs.
    
    Signed-off-by: Pierre Peiffer <pierre.peiffer@bull.net>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Cc: Nadia Derbey <Nadia.Derbey@bull.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 3e4aff982546..65a44bcc4ac2 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -616,9 +616,77 @@ static void shm_get_stat(struct ipc_namespace *ns, unsigned long *rss,
 	}
 }
 
-asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
+/*
+ * This function handles some shmctl commands which require the rw_mutex
+ * to be held in write mode.
+ * NOTE: no locks must be held, the rw_mutex is taken inside this function.
+ */
+static int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,
+		       struct shmid_ds __user *buf, int version)
 {
+	struct kern_ipc_perm *ipcp;
 	struct shm_setbuf setbuf;
+	struct shmid_kernel *shp;
+	int err;
+
+	if (cmd == IPC_SET) {
+		if (copy_shmid_from_user(&setbuf, buf, version))
+			return -EFAULT;
+	}
+
+	down_write(&shm_ids(ns).rw_mutex);
+	shp = shm_lock_check_down(ns, shmid);
+	if (IS_ERR(shp)) {
+		err = PTR_ERR(shp);
+		goto out_up;
+	}
+
+	ipcp = &shp->shm_perm;
+
+	err = audit_ipc_obj(ipcp);
+	if (err)
+		goto out_unlock;
+
+	if (cmd == IPC_SET) {
+		err = audit_ipc_set_perm(0, setbuf.uid,
+					 setbuf.gid, setbuf.mode);
+		if (err)
+			goto out_unlock;
+	}
+
+	if (current->euid != ipcp->uid &&
+	    current->euid != ipcp->cuid &&
+	    !capable(CAP_SYS_ADMIN)) {
+		err = -EPERM;
+		goto out_unlock;
+	}
+
+	err = security_shm_shmctl(shp, cmd);
+	if (err)
+		goto out_unlock;
+	switch (cmd) {
+	case IPC_RMID:
+		do_shm_rmid(ns, ipcp);
+		goto out_up;
+	case IPC_SET:
+		ipcp->uid = setbuf.uid;
+		ipcp->gid = setbuf.gid;
+		ipcp->mode = (ipcp->mode & ~S_IRWXUGO)
+			| (setbuf.mode & S_IRWXUGO);
+		shp->shm_ctim = get_seconds();
+		break;
+	default:
+		err = -EINVAL;
+	}
+out_unlock:
+	shm_unlock(shp);
+out_up:
+	up_write(&shm_ids(ns).rw_mutex);
+	return err;
+}
+
+asmlinkage long sys_shmctl(int shmid, int cmd, struct shmid_ds __user *buf)
+{
 	struct shmid_kernel *shp;
 	int err, version;
 	struct ipc_namespace *ns;
@@ -775,97 +843,13 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		goto out;
 	}
 	case IPC_RMID:
-	{
-		/*
-		 *	We cannot simply remove the file. The SVID states
-		 *	that the block remains until the last person
-		 *	detaches from it, then is deleted. A shmat() on
-		 *	an RMID segment is legal in older Linux and if 
-		 *	we change it apps break...
-		 *
-		 *	Instead we set a destroyed flag, and then blow
-		 *	the name away when the usage hits zero.
-		 */
-		down_write(&shm_ids(ns).rw_mutex);
-		shp = shm_lock_check_down(ns, shmid);
-		if (IS_ERR(shp)) {
-			err = PTR_ERR(shp);
-			goto out_up;
-		}
-
-		err = audit_ipc_obj(&(shp->shm_perm));
-		if (err)
-			goto out_unlock_up;
-
-		if (current->euid != shp->shm_perm.uid &&
-		    current->euid != shp->shm_perm.cuid && 
-		    !capable(CAP_SYS_ADMIN)) {
-			err=-EPERM;
-			goto out_unlock_up;
-		}
-
-		err = security_shm_shmctl(shp, cmd);
-		if (err)
-			goto out_unlock_up;
-
-		do_shm_rmid(ns, &shp->shm_perm);
-		up_write(&shm_ids(ns).rw_mutex);
-		goto out;
-	}
-
 	case IPC_SET:
-	{
-		if (!buf) {
-			err = -EFAULT;
-			goto out;
-		}
-
-		if (copy_shmid_from_user (&setbuf, buf, version)) {
-			err = -EFAULT;
-			goto out;
-		}
-		down_write(&shm_ids(ns).rw_mutex);
-		shp = shm_lock_check_down(ns, shmid);
-		if (IS_ERR(shp)) {
-			err = PTR_ERR(shp);
-			goto out_up;
-		}
-		err = audit_ipc_obj(&(shp->shm_perm));
-		if (err)
-			goto out_unlock_up;
-		err = audit_ipc_set_perm(0, setbuf.uid, setbuf.gid, setbuf.mode);
-		if (err)
-			goto out_unlock_up;
-		err=-EPERM;
-		if (current->euid != shp->shm_perm.uid &&
-		    current->euid != shp->shm_perm.cuid && 
-		    !capable(CAP_SYS_ADMIN)) {
-			goto out_unlock_up;
-		}
-
-		err = security_shm_shmctl(shp, cmd);
-		if (err)
-			goto out_unlock_up;
-		
-		shp->shm_perm.uid = setbuf.uid;
-		shp->shm_perm.gid = setbuf.gid;
-		shp->shm_perm.mode = (shp->shm_perm.mode & ~S_IRWXUGO)
-			| (setbuf.mode & S_IRWXUGO);
-		shp->shm_ctim = get_seconds();
-		break;
-	}
-
+		err = shmctl_down(ns, shmid, cmd, buf, version);
+		return err;
 	default:
-		err = -EINVAL;
-		goto out;
+		return -EINVAL;
 	}
 
-	err = 0;
-out_unlock_up:
-	shm_unlock(shp);
-out_up:
-	up_write(&shm_ids(ns).rw_mutex);
-	goto out;
 out_unlock:
 	shm_unlock(shp);
 out:

commit 48dea404ed01869313f1908cca8a15774dcd8ee5
Author: Pierre Peiffer <pierre.peiffer@bull.net>
Date:   Tue Apr 29 01:00:35 2008 -0700

    IPC: use ipc_buildid() directly from ipc_addid()
    
    By continuing to consolidate a little the IPC code, each id can be built
    directly in ipc_addid() instead of having it built from each callers of
    ipc_addid()
    
    And I also remove shm_addid() in order to have, as much as possible, the
    same code for shm/sem/msg.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Pierre Peiffer <pierre.peiffer@bull.net>
    Cc: Nadia Derbey <Nadia.Derbey@bull.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index e636910454a9..3e4aff982546 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -60,7 +60,6 @@ static struct vm_operations_struct shm_vm_ops;
 
 #define shm_unlock(shp)			\
 	ipc_unlock(&(shp)->shm_perm)
-#define shm_buildid(id, seq)	ipc_buildid(id, seq)
 
 static int newseg(struct ipc_namespace *, struct ipc_params *);
 static void shm_open(struct vm_area_struct *vma);
@@ -169,12 +168,6 @@ static inline void shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *s)
 	ipc_rmid(&shm_ids(ns), &s->shm_perm);
 }
 
-static inline int shm_addid(struct ipc_namespace *ns, struct shmid_kernel *shp)
-{
-	return ipc_addid(&shm_ids(ns), &shp->shm_perm, ns->shm_ctlmni);
-}
-
-
 
 /* This is called by fork, once for every shm attach. */
 static void shm_open(struct vm_area_struct *vma)
@@ -416,7 +409,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	if (IS_ERR(file))
 		goto no_file;
 
-	id = shm_addid(ns, shp);
+	id = ipc_addid(&shm_ids(ns), &shp->shm_perm, ns->shm_ctlmni);
 	if (id < 0) {
 		error = id;
 		goto no_id;
@@ -428,7 +421,6 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	shp->shm_ctim = get_seconds();
 	shp->shm_segsz = size;
 	shp->shm_nattch = 0;
-	shp->shm_perm.id = shm_buildid(id, shp->shm_perm.seq);
 	shp->shm_file = file;
 	/*
 	 * shmid gets reported as "inode#" in /proc/pid/maps.

commit 52cd3b074050dd664380b5e8cfc85d4a6ed8ad48
Author: Lee Schermerhorn <lee.schermerhorn@hp.com>
Date:   Mon Apr 28 02:13:16 2008 -0700

    mempolicy: rework mempolicy Reference Counting [yet again]
    
    After further discussion with Christoph Lameter, it has become clear that my
    earlier attempts to clean up the mempolicy reference counting were a bit of
    overkill in some areas, resulting in superflous ref/unref in what are usually
    fast paths.  In other areas, further inspection reveals that I botched the
    unref for interleave policies.
    
    A separate patch, suitable for upstream/stable trees, fixes up the known
    errors in the previous attempt to fix reference counting.
    
    This patch reworks the memory policy referencing counting and, one hopes,
    simplifies the code.  Maybe I'll get it right this time.
    
    See the update to the numa_memory_policy.txt document for a discussion of
    memory policy reference counting that motivates this patch.
    
    Summary:
    
    Lookup of mempolicy, based on (vma, address) need only add a reference for
    shared policy, and we need only unref the policy when finished for shared
    policies.  So, this patch backs out all of the unneeded extra reference
    counting added by my previous attempt.  It then unrefs only shared policies
    when we're finished with them, using the mpol_cond_put() [conditional put]
    helper function introduced by this patch.
    
    Note that shmem_swapin() calls read_swap_cache_async() with a dummy vma
    containing just the policy.  read_swap_cache_async() can call alloc_page_vma()
    multiple times, so we can't let alloc_page_vma() unref the shared policy in
    this case.  To avoid this, we make a copy of any non-null shared policy and
    remove the MPOL_F_SHARED flag from the copy.  This copy occurs before reading
    a page [or multiple pages] from swap, so the overhead should not be an issue
    here.
    
    I introduced a new static inline function "mpol_cond_copy()" to copy the
    shared policy to an on-stack policy and remove the flags that would require a
    conditional free.  The current implementation of mpol_cond_copy() assumes that
    the struct mempolicy contains no pointers to dynamically allocated structures
    that must be duplicated or reference counted during copy.
    
    Signed-off-by: Lee Schermerhorn <lee.schermerhorn@hp.com>
    Cc: Christoph Lameter <clameter@sgi.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: Andi Kleen <ak@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 8d1b2c468cc4..e636910454a9 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -271,10 +271,9 @@ static struct mempolicy *shm_get_policy(struct vm_area_struct *vma,
 
 	if (sfd->vm_ops->get_policy)
 		pol = sfd->vm_ops->get_policy(vma, addr);
-	else if (vma->vm_policy) {
+	else if (vma->vm_policy)
 		pol = vma->vm_policy;
-		mpol_get(pol);	/* get_vma_policy() expects this */
-	}
+
 	return pol;
 }
 #endif

commit ae4d8c16aa22775f5731677abb8a82f03cec877e
Author: Lee Schermerhorn <lee.schermerhorn@hp.com>
Date:   Mon Apr 28 02:13:11 2008 -0700

    mempolicy: fixup Fallback for Default Shmem Policy
    
    get_vma_policy() is not handling fallback to task policy correctly when the
    get_policy() vm_op returns NULL.  The NULL overwrites the 'pol' variable that
    was holding the fallback task mempolicy.  So, it was falling back directly to
    system default policy.
    
    Fix get_vma_policy() to use only non-NULL policy returned from the vma
    get_policy op.
    
    shm_get_policy() was falling back to current task's mempolicy if the "backing
    file system" [tmpfs vs hugetlbfs] does not support the get_policy vm_op and
    the vma policy is null.  This is incorrect for show_numa_maps() which is
    likely querying the numa_maps of some task other than current.  Remove this
    fallback.
    
    Signed-off-by: Lee Schermerhorn <lee.schermerhorn@hp.com>
    Cc: Christoph Lameter <clameter@sgi.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: Andi Kleen <ak@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index cc63fae02f06..8d1b2c468cc4 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -274,8 +274,7 @@ static struct mempolicy *shm_get_policy(struct vm_area_struct *vma,
 	else if (vma->vm_policy) {
 		pol = vma->vm_policy;
 		mpol_get(pol);	/* get_vma_policy() expects this */
-	} else
-		pol = current->mempolicy;
+	}
 	return pol;
 }
 #endif

commit 69682d852f5c94ee94e21174b3e8b719626c98db
Author: Lee Schermerhorn <Lee.Schermerhorn@hp.com>
Date:   Mon Mar 10 11:43:45 2008 -0700

    mempolicy: fix reference counting bugs
    
    Address 3 known bugs in the current memory policy reference counting method.
    I have a series of patches to rework the reference counting to reduce overhead
    in the allocation path.  However, that series will require testing in -mm once
    I repost it.
    
    1) alloc_page_vma() does not release the extra reference taken for
       vma/shared mempolicy when the mode == MPOL_INTERLEAVE.  This can result in
       leaking mempolicy structures.  This is probably occurring, but not being
       noticed.
    
       Fix:  add the conditional release of the reference.
    
    2) hugezonelist unconditionally releases a reference on the mempolicy when
       mode == MPOL_INTERLEAVE.  This can result in decrementing the reference
       count for system default policy [should have no ill effect] or premature
       freeing of task policy.  If this occurred, the next allocation using task
       mempolicy would use the freed structure and probably BUG out.
    
       Fix:  add the necessary check to the release.
    
    3) The current reference counting method assumes that vma 'get_policy()'
       methods automatically add an extra reference a non-NULL returned mempolicy.
        This is true for shmem_get_policy() used by tmpfs mappings, including
       regular page shm segments.  However, SHM_HUGETLB shm's, backed by
       hugetlbfs, just use the vma policy without the extra reference.  This
       results in freeing of the vma policy on the first allocation, with reuse of
       the freed mempolicy structure on subsequent allocations.
    
       Fix: Rather than add another condition to the conditional reference
       release, which occur in the allocation path, just add a reference when
       returning the vma policy in shm_get_policy() to match the assumptions.
    
    Signed-off-by: Lee Schermerhorn <lee.schermerhorn@hp.com>
    Cc: Greg KH <greg@kroah.com>
    Cc: Andi Kleen <ak@suse.de>
    Cc: Christoph Lameter <clameter@sgi.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: David Rientjes <rientjes@google.com>
    Cc: <eric.whitney@hp.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index c47e87278a92..cc63fae02f06 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -271,9 +271,10 @@ static struct mempolicy *shm_get_policy(struct vm_area_struct *vma,
 
 	if (sfd->vm_ops->get_policy)
 		pol = sfd->vm_ops->get_policy(vma, addr);
-	else if (vma->vm_policy)
+	else if (vma->vm_policy) {
 		pol = vma->vm_policy;
-	else
+		mpol_get(pol);	/* get_vma_policy() expects this */
+	} else
 		pol = current->mempolicy;
 	return pol;
 }

commit 01b8b07a5d77d22e609267dcae74d15e3e9c5f13
Author: Pierre Peiffer <pierre.peiffer@bull.net>
Date:   Fri Feb 8 04:18:57 2008 -0800

    IPC: consolidate sem_exit_ns(), msg_exit_ns() and shm_exit_ns()
    
    sem_exit_ns(), msg_exit_ns() and shm_exit_ns() are all called when an
    ipc_namespace is released to free all ipcs of each type.  But in fact, they
    do the same thing: they loop around all ipcs to free them individually by
    calling a specific routine.
    
    This patch proposes to consolidate this by introducing a common function,
    free_ipcs(), that do the job.  The specific routine to call on each
    individual ipcs is passed as parameter.  For this, these ipc-specific
    'free' routines are reworked to take a generic 'struct ipc_perm' as
    parameter.
    
    Signed-off-by: Pierre Peiffer <pierre.peiffer@bull.net>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: Nadia Derbey <Nadia.Derbey@bull.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index fe92471e19c7..c47e87278a92 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -83,8 +83,11 @@ void shm_init_ns(struct ipc_namespace *ns)
  * Called with shm_ids.rw_mutex (writer) and the shp structure locked.
  * Only shm_ids.rw_mutex remains locked on exit.
  */
-static void do_shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *shp)
+static void do_shm_rmid(struct ipc_namespace *ns, struct kern_ipc_perm *ipcp)
 {
+	struct shmid_kernel *shp;
+	shp = container_of(ipcp, struct shmid_kernel, shm_perm);
+
 	if (shp->shm_nattch){
 		shp->shm_perm.mode |= SHM_DEST;
 		/* Do not find it any more */
@@ -97,25 +100,7 @@ static void do_shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *shp)
 #ifdef CONFIG_IPC_NS
 void shm_exit_ns(struct ipc_namespace *ns)
 {
-	struct shmid_kernel *shp;
-	struct kern_ipc_perm *perm;
-	int next_id;
-	int total, in_use;
-
-	down_write(&shm_ids(ns).rw_mutex);
-
-	in_use = shm_ids(ns).in_use;
-
-	for (total = 0, next_id = 0; total < in_use; next_id++) {
-		perm = idr_find(&shm_ids(ns).ipcs_idr, next_id);
-		if (perm == NULL)
-			continue;
-		ipc_lock_by_ptr(perm);
-		shp = container_of(perm, struct shmid_kernel, shm_perm);
-		do_shm_rmid(ns, shp);
-		total++;
-	}
-	up_write(&shm_ids(ns).rw_mutex);
+	free_ipcs(ns, &shm_ids(ns), do_shm_rmid);
 }
 #endif
 
@@ -832,7 +817,7 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		if (err)
 			goto out_unlock_up;
 
-		do_shm_rmid(ns, shp);
+		do_shm_rmid(ns, &shp->shm_perm);
 		up_write(&shm_ids(ns).rw_mutex);
 		goto out;
 	}

commit ed2ddbf88c0ddeeae4c78bb306a116dfd867c55c
Author: Pierre Peiffer <pierre.peiffer@bull.net>
Date:   Fri Feb 8 04:18:57 2008 -0800

    IPC: make struct ipc_ids static in ipc_namespace
    
    Each ipc_namespace contains a table of 3 pointers to struct ipc_ids (3 for
    msg, sem and shm, structure used to store all ipcs) These 'struct ipc_ids'
    are dynamically allocated for each icp_namespace as the ipc_namespace
    itself (for the init namespace, they are initialized with pointers to
    static variables instead)
    
    It is so for historical reason: in fact, before the use of idr to store the
    ipcs, the ipcs were stored in tables of variable length, depending of the
    maximum number of ipc allowed.  Now, these 'struct ipc_ids' have a fixed
    size.  As they are allocated in any cases for each new ipc_namespace, there
    is no gain of memory in having them allocated separately of the struct
    ipc_namespace.
    
    This patch proposes to make this table static in the struct ipc_namespace.
    Thus, we can allocate all in once and get rid of all the code needed to
    allocate and free these ipc_ids separately.
    
    Signed-off-by: Pierre Peiffer <pierre.peiffer@bull.net>
    Acked-by: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: Nadia Derbey <Nadia.Derbey@bull.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 07f4b7abc80a..fe92471e19c7 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -56,9 +56,7 @@ struct shm_file_data {
 static const struct file_operations shm_file_operations;
 static struct vm_operations_struct shm_vm_ops;
 
-static struct ipc_ids init_shm_ids;
-
-#define shm_ids(ns)	(*((ns)->ids[IPC_SHM_IDS]))
+#define shm_ids(ns)	((ns)->ids[IPC_SHM_IDS])
 
 #define shm_unlock(shp)			\
 	ipc_unlock(&(shp)->shm_perm)
@@ -72,14 +70,13 @@ static void shm_destroy (struct ipc_namespace *ns, struct shmid_kernel *shp);
 static int sysvipc_shm_proc_show(struct seq_file *s, void *it);
 #endif
 
-static void __shm_init_ns(struct ipc_namespace *ns, struct ipc_ids *ids)
+void shm_init_ns(struct ipc_namespace *ns)
 {
-	ns->ids[IPC_SHM_IDS] = ids;
 	ns->shm_ctlmax = SHMMAX;
 	ns->shm_ctlall = SHMALL;
 	ns->shm_ctlmni = SHMMNI;
 	ns->shm_tot = 0;
-	ipc_init_ids(ids);
+	ipc_init_ids(&ns->ids[IPC_SHM_IDS]);
 }
 
 /*
@@ -98,18 +95,6 @@ static void do_shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *shp)
 }
 
 #ifdef CONFIG_IPC_NS
-int shm_init_ns(struct ipc_namespace *ns)
-{
-	struct ipc_ids *ids;
-
-	ids = kmalloc(sizeof(struct ipc_ids), GFP_KERNEL);
-	if (ids == NULL)
-		return -ENOMEM;
-
-	__shm_init_ns(ns, ids);
-	return 0;
-}
-
 void shm_exit_ns(struct ipc_namespace *ns)
 {
 	struct shmid_kernel *shp;
@@ -131,15 +116,12 @@ void shm_exit_ns(struct ipc_namespace *ns)
 		total++;
 	}
 	up_write(&shm_ids(ns).rw_mutex);
-
-	kfree(ns->ids[IPC_SHM_IDS]);
-	ns->ids[IPC_SHM_IDS] = NULL;
 }
 #endif
 
 void __init shm_init (void)
 {
-	__shm_init_ns(&init_ipc_ns, &init_shm_ids);
+	shm_init_ns(&init_ipc_ns);
 	ipc_init_proc_interface("sysvipc/shm",
 				"       key      shmid perms       size  cpid  lpid nattch   uid   gid  cuid  cgid      atime      dtime      ctime\n",
 				IPC_SHM_IDS, sysvipc_shm_proc_show);

commit ae5e1b22f17983da929a0d0178896269e19da186
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Fri Feb 8 04:18:22 2008 -0800

    namespaces: move the IPC namespace under IPC_NS option
    
    Currently the IPC namespace management code is spread over the ipc/*.c files.
    I moved this code into ipc/namespace.c file which is compiled out when needed.
    
    The linux/ipc_namespace.h file is used to store the prototypes of the
    functions in namespace.c and the stubs for NAMESPACES=n case.  This is done
    so, because the stub for copy_ipc_namespace requires the knowledge of the
    CLONE_NEWIPC flag, which is in sched.h.  But the linux/ipc.h file itself in
    included into many many .c files via the sys.h->sem.h sequence so adding the
    sched.h into it will make all these .c depend on sched.h which is not that
    good.  On the other hand the knowledge about the namespaces stuff is required
    in 4 .c files only.
    
    Besides, this patch compiles out some auxiliary functions from ipc/sem.c,
    msg.c and shm.c files.  It turned out that moving these functions into
    namespaces.c is not that easy because they use many other calls and macros
    from the original file.  Moving them would make this patch complicated.  On
    the other hand all these functions can be consolidated, so I will send a
    separate patch doing this a bit later.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: Kirill Korotaev <dev@sw.ru>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 65c3a294aba5..07f4b7abc80a 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -38,6 +38,7 @@
 #include <linux/rwsem.h>
 #include <linux/nsproxy.h>
 #include <linux/mount.h>
+#include <linux/ipc_namespace.h>
 
 #include <asm/uaccess.h>
 
@@ -96,6 +97,7 @@ static void do_shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *shp)
 		shm_destroy(ns, shp);
 }
 
+#ifdef CONFIG_IPC_NS
 int shm_init_ns(struct ipc_namespace *ns)
 {
 	struct ipc_ids *ids;
@@ -133,6 +135,7 @@ void shm_exit_ns(struct ipc_namespace *ns)
 	kfree(ns->ids[IPC_SHM_IDS]);
 	ns->ids[IPC_SHM_IDS] = NULL;
 }
+#endif
 
 void __init shm_init (void)
 {

commit b1ed88b47f5e18c6efb8041275c16eeead5377df
Author: Pierre Peiffer <pierre.peiffer@bull.net>
Date:   Wed Feb 6 01:36:23 2008 -0800

    IPC: fix error check in all new xxx_lock() and xxx_exit_ns() functions
    
    In the new implementation of the [sem|shm|msg]_lock[_check]() routines, we
    use the return value of ipc_lock() in container_of() without any check.
    But ipc_lock may return a errcode.  The use of this errcode in
    container_of() may alter this errcode, and we don't want this.
    
    And in xxx_exit_ns, the pointer return by idr_find is of type 'struct
    kern_ipc_per'...
    
    Today, the code will work as is because the member used in these
    container_of() is the first member of its container (offset == 0), the
    errcode isn't changed then.  But in the general case, we can't count on
    this assumption and this may lead later to a real bug if we don't correct
    this.
    
    Again, the proposed solution is simple and correct.  But, as pointed by
    Nadia, with this solution, the same check will be done several times (in
    all sub-callers...), what is not very funny/optimal...
    
    Signed-off-by: Pierre Peiffer <pierre.peiffer@bull.net>
    Cc: Nadia Derbey <Nadia.Derbey@bull.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 3818fae625c5..65c3a294aba5 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -111,6 +111,7 @@ int shm_init_ns(struct ipc_namespace *ns)
 void shm_exit_ns(struct ipc_namespace *ns)
 {
 	struct shmid_kernel *shp;
+	struct kern_ipc_perm *perm;
 	int next_id;
 	int total, in_use;
 
@@ -119,10 +120,11 @@ void shm_exit_ns(struct ipc_namespace *ns)
 	in_use = shm_ids(ns).in_use;
 
 	for (total = 0, next_id = 0; total < in_use; next_id++) {
-		shp = idr_find(&shm_ids(ns).ipcs_idr, next_id);
-		if (shp == NULL)
+		perm = idr_find(&shm_ids(ns).ipcs_idr, next_id);
+		if (perm == NULL)
 			continue;
-		ipc_lock_by_ptr(&shp->shm_perm);
+		ipc_lock_by_ptr(perm);
+		shp = container_of(perm, struct shmid_kernel, shm_perm);
 		do_shm_rmid(ns, shp);
 		total++;
 	}
@@ -149,6 +151,9 @@ static inline struct shmid_kernel *shm_lock_down(struct ipc_namespace *ns,
 {
 	struct kern_ipc_perm *ipcp = ipc_lock_down(&shm_ids(ns), id);
 
+	if (IS_ERR(ipcp))
+		return (struct shmid_kernel *)ipcp;
+
 	return container_of(ipcp, struct shmid_kernel, shm_perm);
 }
 
@@ -158,6 +163,9 @@ static inline struct shmid_kernel *shm_lock_check_down(
 {
 	struct kern_ipc_perm *ipcp = ipc_lock_check_down(&shm_ids(ns), id);
 
+	if (IS_ERR(ipcp))
+		return (struct shmid_kernel *)ipcp;
+
 	return container_of(ipcp, struct shmid_kernel, shm_perm);
 }
 
@@ -169,6 +177,9 @@ static inline struct shmid_kernel *shm_lock(struct ipc_namespace *ns, int id)
 {
 	struct kern_ipc_perm *ipcp = ipc_lock(&shm_ids(ns), id);
 
+	if (IS_ERR(ipcp))
+		return (struct shmid_kernel *)ipcp;
+
 	return container_of(ipcp, struct shmid_kernel, shm_perm);
 }
 
@@ -177,6 +188,9 @@ static inline struct shmid_kernel *shm_lock_check(struct ipc_namespace *ns,
 {
 	struct kern_ipc_perm *ipcp = ipc_lock_check(&shm_ids(ns), id);
 
+	if (IS_ERR(ipcp))
+		return (struct shmid_kernel *)ipcp;
+
 	return container_of(ipcp, struct shmid_kernel, shm_perm);
 }
 

commit 283bb7fada7e33a759d8fc9bd7a44532e4ad420e
Author: Pierre Peiffer <Pierre.Peiffer@bull.net>
Date:   Thu Oct 18 23:40:57 2007 -0700

    IPC: fix error case when idr-cache is empty in ipcget()
    
    With the use of idr to store the ipc, the case where the idr cache is
    empty, when idr_get_new is called (this may happen even if we call
    idr_pre_get() before), is not well handled: it lets
    semget()/shmget()/msgget() return ENOSPC when this cache is empty, what 1.
    does not reflect the facts and 2.  does not conform to the man(s).
    
    This patch fixes this by retrying the whole process of allocation in this case.
    
    Signed-off-by: Pierre Peiffer <pierre.peiffer@bull.net>
    Cc: Nadia Derbey <Nadia.Derbey@bull.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 05c97c7513c2..3818fae625c5 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -433,10 +433,11 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	if (IS_ERR(file))
 		goto no_file;
 
-	error = -ENOSPC;
 	id = shm_addid(ns, shp);
-	if(id == -1) 
+	if (id < 0) {
+		error = id;
 		goto no_id;
+	}
 
 	shp->shm_cprid = task_tgid_vnr(current);
 	shp->shm_lprid = 0;

commit 1b531f213661657d6e1c55cf5c97f649d630c227
Author: Nadia Derbey <Nadia.Derbey@bull.net>
Date:   Thu Oct 18 23:40:55 2007 -0700

    ipc: remove unneeded parameters
    
    Remvoe the unneeded parameters from ipc_checkid() and ipc_buildid()
    interfaces.
    
    Signed-off-by: Nadia Derbey <Nadia.Derbey@bull.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index b27d31f3aaba..05c97c7513c2 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -61,8 +61,7 @@ static struct ipc_ids init_shm_ids;
 
 #define shm_unlock(shp)			\
 	ipc_unlock(&(shp)->shm_perm)
-#define shm_buildid(ns, id, seq)	\
-	ipc_buildid(&shm_ids(ns), id, seq)
+#define shm_buildid(id, seq)	ipc_buildid(id, seq)
 
 static int newseg(struct ipc_namespace *, struct ipc_params *);
 static void shm_open(struct vm_area_struct *vma);
@@ -445,7 +444,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	shp->shm_ctim = get_seconds();
 	shp->shm_segsz = size;
 	shp->shm_nattch = 0;
-	shp->shm_perm.id = shm_buildid(ns, id, shp->shm_perm.seq);
+	shp->shm_perm.id = shm_buildid(id, shp->shm_perm.seq);
 	shp->shm_file = file;
 	/*
 	 * shmid gets reported as "inode#" in /proc/pid/maps.

commit 3e148c79938aa39035669c1cfa3ff60722134535
Author: Nadia Derbey <Nadia.Derbey@bull.net>
Date:   Thu Oct 18 23:40:54 2007 -0700

    fix idr_find() locking
    
    This is a patch that fixes the way idr_find() used to be called in ipc_lock():
    in all the paths that don't imply an update of the ipcs idr, it was called
    without the idr tree being locked.
    
    The changes are:
      . in ipc_ids, the mutex has been changed into a reader/writer semaphore.
      . ipc_lock() now takes the mutex as a reader during the idr_find().
      . a new routine ipc_lock_down() has been defined: it doesn't take the
        mutex, assuming that it is being held by the caller. This is the routine
        that is now called in all the update paths.
    
    Signed-off-by: Nadia Derbey <Nadia.Derbey@bull.net>
    Acked-by: Jarek Poplawski <jarkao2@o2.pl>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index f28f2a3163e1..b27d31f3aaba 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -35,7 +35,7 @@
 #include <linux/capability.h>
 #include <linux/ptrace.h>
 #include <linux/seq_file.h>
-#include <linux/mutex.h>
+#include <linux/rwsem.h>
 #include <linux/nsproxy.h>
 #include <linux/mount.h>
 
@@ -83,8 +83,8 @@ static void __shm_init_ns(struct ipc_namespace *ns, struct ipc_ids *ids)
 }
 
 /*
- * Called with shm_ids.mutex and the shp structure locked.
- * Only shm_ids.mutex remains locked on exit.
+ * Called with shm_ids.rw_mutex (writer) and the shp structure locked.
+ * Only shm_ids.rw_mutex remains locked on exit.
  */
 static void do_shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *shp)
 {
@@ -115,7 +115,7 @@ void shm_exit_ns(struct ipc_namespace *ns)
 	int next_id;
 	int total, in_use;
 
-	mutex_lock(&shm_ids(ns).mutex);
+	down_write(&shm_ids(ns).rw_mutex);
 
 	in_use = shm_ids(ns).in_use;
 
@@ -127,7 +127,7 @@ void shm_exit_ns(struct ipc_namespace *ns)
 		do_shm_rmid(ns, shp);
 		total++;
 	}
-	mutex_unlock(&shm_ids(ns).mutex);
+	up_write(&shm_ids(ns).rw_mutex);
 
 	kfree(ns->ids[IPC_SHM_IDS]);
 	ns->ids[IPC_SHM_IDS] = NULL;
@@ -141,6 +141,31 @@ void __init shm_init (void)
 				IPC_SHM_IDS, sysvipc_shm_proc_show);
 }
 
+/*
+ * shm_lock_(check_)down routines are called in the paths where the rw_mutex
+ * is held to protect access to the idr tree.
+ */
+static inline struct shmid_kernel *shm_lock_down(struct ipc_namespace *ns,
+						int id)
+{
+	struct kern_ipc_perm *ipcp = ipc_lock_down(&shm_ids(ns), id);
+
+	return container_of(ipcp, struct shmid_kernel, shm_perm);
+}
+
+static inline struct shmid_kernel *shm_lock_check_down(
+						struct ipc_namespace *ns,
+						int id)
+{
+	struct kern_ipc_perm *ipcp = ipc_lock_check_down(&shm_ids(ns), id);
+
+	return container_of(ipcp, struct shmid_kernel, shm_perm);
+}
+
+/*
+ * shm_lock_(check_) routines are called in the paths where the rw_mutex
+ * is not held.
+ */
 static inline struct shmid_kernel *shm_lock(struct ipc_namespace *ns, int id)
 {
 	struct kern_ipc_perm *ipcp = ipc_lock(&shm_ids(ns), id);
@@ -189,7 +214,7 @@ static void shm_open(struct vm_area_struct *vma)
  * @ns: namespace
  * @shp: struct to free
  *
- * It has to be called with shp and shm_ids.mutex locked,
+ * It has to be called with shp and shm_ids.rw_mutex (writer) locked,
  * but returns with shp unlocked and freed.
  */
 static void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)
@@ -220,9 +245,9 @@ static void shm_close(struct vm_area_struct *vma)
 	struct shmid_kernel *shp;
 	struct ipc_namespace *ns = sfd->ns;
 
-	mutex_lock(&shm_ids(ns).mutex);
+	down_write(&shm_ids(ns).rw_mutex);
 	/* remove from the list of attaches of the shm segment */
-	shp = shm_lock(ns, sfd->id);
+	shp = shm_lock_down(ns, sfd->id);
 	BUG_ON(IS_ERR(shp));
 	shp->shm_lprid = task_tgid_vnr(current);
 	shp->shm_dtim = get_seconds();
@@ -232,7 +257,7 @@ static void shm_close(struct vm_area_struct *vma)
 		shm_destroy(ns, shp);
 	else
 		shm_unlock(shp);
-	mutex_unlock(&shm_ids(ns).mutex);
+	up_write(&shm_ids(ns).rw_mutex);
 }
 
 static int shm_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
@@ -353,7 +378,7 @@ static struct vm_operations_struct shm_vm_ops = {
  * @ns: namespace
  * @params: ptr to the structure that contains key, size and shmflg
  *
- * Called with shm_ids.mutex held
+ * Called with shm_ids.rw_mutex held as a writer.
  */
 
 static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
@@ -442,7 +467,7 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 }
 
 /*
- * Called with shm_ids.mutex and ipcp locked.
+ * Called with shm_ids.rw_mutex and ipcp locked.
  */
 static inline int shm_security(struct kern_ipc_perm *ipcp, int shmflg)
 {
@@ -453,7 +478,7 @@ static inline int shm_security(struct kern_ipc_perm *ipcp, int shmflg)
 }
 
 /*
- * Called with shm_ids.mutex and ipcp locked.
+ * Called with shm_ids.rw_mutex and ipcp locked.
  */
 static inline int shm_more_checks(struct kern_ipc_perm *ipcp,
 				struct ipc_params *params)
@@ -578,7 +603,7 @@ static inline unsigned long copy_shminfo_to_user(void __user *buf, struct shminf
 }
 
 /*
- * Called with shm_ids.mutex held
+ * Called with shm_ids.rw_mutex held as a reader
  */
 static void shm_get_stat(struct ipc_namespace *ns, unsigned long *rss,
 		unsigned long *swp)
@@ -649,9 +674,9 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		if(copy_shminfo_to_user (buf, &shminfo, version))
 			return -EFAULT;
 
-		mutex_lock(&shm_ids(ns).mutex);
+		down_read(&shm_ids(ns).rw_mutex);
 		err = ipc_get_maxid(&shm_ids(ns));
-		mutex_unlock(&shm_ids(ns).mutex);
+		up_read(&shm_ids(ns).rw_mutex);
 
 		if(err<0)
 			err = 0;
@@ -666,14 +691,14 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 			return err;
 
 		memset(&shm_info,0,sizeof(shm_info));
-		mutex_lock(&shm_ids(ns).mutex);
+		down_read(&shm_ids(ns).rw_mutex);
 		shm_info.used_ids = shm_ids(ns).in_use;
 		shm_get_stat (ns, &shm_info.shm_rss, &shm_info.shm_swp);
 		shm_info.shm_tot = ns->shm_tot;
 		shm_info.swap_attempts = 0;
 		shm_info.swap_successes = 0;
 		err = ipc_get_maxid(&shm_ids(ns));
-		mutex_unlock(&shm_ids(ns).mutex);
+		up_read(&shm_ids(ns).rw_mutex);
 		if(copy_to_user (buf, &shm_info, sizeof(shm_info))) {
 			err = -EFAULT;
 			goto out;
@@ -786,8 +811,8 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		 *	Instead we set a destroyed flag, and then blow
 		 *	the name away when the usage hits zero.
 		 */
-		mutex_lock(&shm_ids(ns).mutex);
-		shp = shm_lock_check(ns, shmid);
+		down_write(&shm_ids(ns).rw_mutex);
+		shp = shm_lock_check_down(ns, shmid);
 		if (IS_ERR(shp)) {
 			err = PTR_ERR(shp);
 			goto out_up;
@@ -809,7 +834,7 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 			goto out_unlock_up;
 
 		do_shm_rmid(ns, shp);
-		mutex_unlock(&shm_ids(ns).mutex);
+		up_write(&shm_ids(ns).rw_mutex);
 		goto out;
 	}
 
@@ -824,8 +849,8 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 			err = -EFAULT;
 			goto out;
 		}
-		mutex_lock(&shm_ids(ns).mutex);
-		shp = shm_lock_check(ns, shmid);
+		down_write(&shm_ids(ns).rw_mutex);
+		shp = shm_lock_check_down(ns, shmid);
 		if (IS_ERR(shp)) {
 			err = PTR_ERR(shp);
 			goto out_up;
@@ -864,7 +889,7 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 out_unlock_up:
 	shm_unlock(shp);
 out_up:
-	mutex_unlock(&shm_ids(ns).mutex);
+	up_write(&shm_ids(ns).rw_mutex);
 	goto out;
 out_unlock:
 	shm_unlock(shp);
@@ -998,8 +1023,8 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	fput(file);
 
 out_nattch:
-	mutex_lock(&shm_ids(ns).mutex);
-	shp = shm_lock(ns, shmid);
+	down_write(&shm_ids(ns).rw_mutex);
+	shp = shm_lock_down(ns, shmid);
 	BUG_ON(IS_ERR(shp));
 	shp->shm_nattch--;
 	if(shp->shm_nattch == 0 &&
@@ -1007,7 +1032,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 		shm_destroy(ns, shp);
 	else
 		shm_unlock(shp);
-	mutex_unlock(&shm_ids(ns).mutex);
+	up_write(&shm_ids(ns).rw_mutex);
 
 out:
 	return err;

commit f4566f04854d78acfc74b9acb029744acde9d033
Author: Nadia Derbey <Nadia.Derbey@bull.net>
Date:   Thu Oct 18 23:40:53 2007 -0700

    ipc: fix wrong comments
    
    This patch fixes the wrong / obsolete comments in the ipc code.  Also adds
    a missing lock around ipc_get_maxid() in shm_get_stat().
    
    Signed-off-by: Nadia Derbey <Nadia.Derbey@bull.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index e2de16efe10d..f28f2a3163e1 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -82,6 +82,10 @@ static void __shm_init_ns(struct ipc_namespace *ns, struct ipc_ids *ids)
 	ipc_init_ids(ids);
 }
 
+/*
+ * Called with shm_ids.mutex and the shp structure locked.
+ * Only shm_ids.mutex remains locked on exit.
+ */
 static void do_shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *shp)
 {
 	if (shp->shm_nattch){
@@ -182,6 +186,7 @@ static void shm_open(struct vm_area_struct *vma)
 /*
  * shm_destroy - free the struct shmid_kernel
  *
+ * @ns: namespace
  * @shp: struct to free
  *
  * It has to be called with shp and shm_ids.mutex locked,
@@ -343,6 +348,14 @@ static struct vm_operations_struct shm_vm_ops = {
 #endif
 };
 
+/**
+ * newseg - Create a new shared memory segment
+ * @ns: namespace
+ * @params: ptr to the structure that contains key, size and shmflg
+ *
+ * Called with shm_ids.mutex held
+ */
+
 static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 {
 	key_t key = params->key;
@@ -428,6 +441,9 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	return error;
 }
 
+/*
+ * Called with shm_ids.mutex and ipcp locked.
+ */
 static inline int shm_security(struct kern_ipc_perm *ipcp, int shmflg)
 {
 	struct shmid_kernel *shp;
@@ -436,6 +452,9 @@ static inline int shm_security(struct kern_ipc_perm *ipcp, int shmflg)
 	return security_shm_associate(shp, shmflg);
 }
 
+/*
+ * Called with shm_ids.mutex and ipcp locked.
+ */
 static inline int shm_more_checks(struct kern_ipc_perm *ipcp,
 				struct ipc_params *params)
 {
@@ -558,6 +577,9 @@ static inline unsigned long copy_shminfo_to_user(void __user *buf, struct shminf
 	}
 }
 
+/*
+ * Called with shm_ids.mutex held
+ */
 static void shm_get_stat(struct ipc_namespace *ns, unsigned long *rss,
 		unsigned long *swp)
 {
@@ -573,18 +595,6 @@ static void shm_get_stat(struct ipc_namespace *ns, unsigned long *rss,
 		struct shmid_kernel *shp;
 		struct inode *inode;
 
-		/*
-		 * idr_find() is called via shm_get(), so with shm_ids.mutex
-		 * locked. Since ipc_addid() is also called with
-		 * shm_ids.mutex down, there is no need to add read barriers
-		 * here to gurantee the writes in ipc_addid() are seen in
-		 * order here (for Alpha).
-		 * However idr_find() itself does not necessary require
-		 * ipc_ids.mutex down. So if idr_find() is used by other
-		 * places without ipc_ids.mutex down, then it needs read
-		 * read memory barriers as ipc_lock() does.
-		 */
-
 		shp = idr_find(&shm_ids(ns).ipcs_idr, next_id);
 		if (shp == NULL)
 			continue;
@@ -638,8 +648,11 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		shminfo.shmmin = SHMMIN;
 		if(copy_shminfo_to_user (buf, &shminfo, version))
 			return -EFAULT;
-		/* reading a integer is always atomic */
+
+		mutex_lock(&shm_ids(ns).mutex);
 		err = ipc_get_maxid(&shm_ids(ns));
+		mutex_unlock(&shm_ids(ns).mutex);
+
 		if(err<0)
 			err = 0;
 		goto out;

commit 03f02c7657f7948ab980280c54c9366f962b1474
Author: Nadia Derbey <Nadia.Derbey@bull.net>
Date:   Thu Oct 18 23:40:51 2007 -0700

    Storing ipcs into IDRs
    
    This patch converts casts of struct kern_ipc_perm to
       . struct msg_queue
       . struct sem_array
       . struct shmid_kernel
    into the equivalent container_of() macro. It improves code maintenance
    because the code need not change if kern_ipc_perm is no longer at the
    beginning of the containing struct.
    
    Signed-off-by: Nadia Derbey <Nadia.Derbey@bull.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 8241264941a2..e2de16efe10d 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -139,13 +139,17 @@ void __init shm_init (void)
 
 static inline struct shmid_kernel *shm_lock(struct ipc_namespace *ns, int id)
 {
-	return (struct shmid_kernel *) ipc_lock(&shm_ids(ns), id);
+	struct kern_ipc_perm *ipcp = ipc_lock(&shm_ids(ns), id);
+
+	return container_of(ipcp, struct shmid_kernel, shm_perm);
 }
 
 static inline struct shmid_kernel *shm_lock_check(struct ipc_namespace *ns,
 						int id)
 {
-	return (struct shmid_kernel *) ipc_lock_check(&shm_ids(ns), id);
+	struct kern_ipc_perm *ipcp = ipc_lock_check(&shm_ids(ns), id);
+
+	return container_of(ipcp, struct shmid_kernel, shm_perm);
 }
 
 static inline void shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *s)
@@ -424,14 +428,21 @@ static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 	return error;
 }
 
-static inline int shm_security(void *shp, int shmflg)
+static inline int shm_security(struct kern_ipc_perm *ipcp, int shmflg)
 {
-	return security_shm_associate((struct shmid_kernel *) shp, shmflg);
+	struct shmid_kernel *shp;
+
+	shp = container_of(ipcp, struct shmid_kernel, shm_perm);
+	return security_shm_associate(shp, shmflg);
 }
 
-static inline int shm_more_checks(void *shp, struct ipc_params *params)
+static inline int shm_more_checks(struct kern_ipc_perm *ipcp,
+				struct ipc_params *params)
 {
-	if (((struct shmid_kernel *)shp)->shm_segsz < params->u.size)
+	struct shmid_kernel *shp;
+
+	shp = container_of(ipcp, struct shmid_kernel, shm_perm);
+	if (shp->shm_segsz < params->u.size)
 		return -EINVAL;
 
 	return 0;

commit 023a53557ea0e987b002e9a844242ef0b0aa1eb3
Author: Nadia Derbey <Nadia.Derbey@bull.net>
Date:   Thu Oct 18 23:40:51 2007 -0700

    ipc: integrate ipc_checkid() into ipc_lock()
    
    This patch introduces a new ipc_lock_check() routine interface:
       . each time ipc_checkid() is called, this is done after calling ipc_lock().
         ipc_checkid() is now called from inside ipc_lock_check().
    
    [akpm@linux-foundation.org: build fix]
    [akpm@linux-foundation.org: fix RCU locking]
    Signed-off-by: Nadia Derbey <Nadia.Derbey@bull.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 8cf1cf3d5bec..8241264941a2 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -59,8 +59,6 @@ static struct ipc_ids init_shm_ids;
 
 #define shm_ids(ns)	(*((ns)->ids[IPC_SHM_IDS]))
 
-#define shm_lock(ns, id)		\
-	((struct shmid_kernel*)ipc_lock(&shm_ids(ns),id))
 #define shm_unlock(shp)			\
 	ipc_unlock(&(shp)->shm_perm)
 #define shm_buildid(ns, id, seq)	\
@@ -139,12 +137,15 @@ void __init shm_init (void)
 				IPC_SHM_IDS, sysvipc_shm_proc_show);
 }
 
-static inline int shm_checkid(struct ipc_namespace *ns,
-		struct shmid_kernel *s, int id)
+static inline struct shmid_kernel *shm_lock(struct ipc_namespace *ns, int id)
 {
-	if (ipc_checkid(&shm_ids(ns), &s->shm_perm, id))
-		return -EIDRM;
-	return 0;
+	return (struct shmid_kernel *) ipc_lock(&shm_ids(ns), id);
+}
+
+static inline struct shmid_kernel *shm_lock_check(struct ipc_namespace *ns,
+						int id)
+{
+	return (struct shmid_kernel *) ipc_lock_check(&shm_ids(ns), id);
 }
 
 static inline void shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *s)
@@ -167,7 +168,7 @@ static void shm_open(struct vm_area_struct *vma)
 	struct shmid_kernel *shp;
 
 	shp = shm_lock(sfd->ns, sfd->id);
-	BUG_ON(!shp);
+	BUG_ON(IS_ERR(shp));
 	shp->shm_atim = get_seconds();
 	shp->shm_lprid = task_tgid_vnr(current);
 	shp->shm_nattch++;
@@ -213,7 +214,7 @@ static void shm_close(struct vm_area_struct *vma)
 	mutex_lock(&shm_ids(ns).mutex);
 	/* remove from the list of attaches of the shm segment */
 	shp = shm_lock(ns, sfd->id);
-	BUG_ON(!shp);
+	BUG_ON(IS_ERR(shp));
 	shp->shm_lprid = task_tgid_vnr(current);
 	shp->shm_dtim = get_seconds();
 	shp->shm_nattch--;
@@ -662,17 +663,25 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 	{
 		struct shmid64_ds tbuf;
 		int result;
-		memset(&tbuf, 0, sizeof(tbuf));
-		shp = shm_lock(ns, shmid);
-		if(shp==NULL) {
-			err = -EINVAL;
+
+		if (!buf) {
+			err = -EFAULT;
 			goto out;
-		} else if (cmd == SHM_STAT) {
+		}
+
+		if (cmd == SHM_STAT) {
+			shp = shm_lock(ns, shmid);
+			if (IS_ERR(shp)) {
+				err = PTR_ERR(shp);
+				goto out;
+			}
 			result = shp->shm_perm.id;
 		} else {
-			err = shm_checkid(ns, shp,shmid);
-			if(err)
-				goto out_unlock;
+			shp = shm_lock_check(ns, shmid);
+			if (IS_ERR(shp)) {
+				err = PTR_ERR(shp);
+				goto out;
+			}
 			result = 0;
 		}
 		err=-EACCES;
@@ -681,6 +690,7 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		err = security_shm_shmctl(shp, cmd);
 		if (err)
 			goto out_unlock;
+		memset(&tbuf, 0, sizeof(tbuf));
 		kernel_to_ipc64_perm(&shp->shm_perm, &tbuf.shm_perm);
 		tbuf.shm_segsz	= shp->shm_segsz;
 		tbuf.shm_atime	= shp->shm_atim;
@@ -699,14 +709,11 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 	case SHM_LOCK:
 	case SHM_UNLOCK:
 	{
-		shp = shm_lock(ns, shmid);
-		if(shp==NULL) {
-			err = -EINVAL;
+		shp = shm_lock_check(ns, shmid);
+		if (IS_ERR(shp)) {
+			err = PTR_ERR(shp);
 			goto out;
 		}
-		err = shm_checkid(ns, shp,shmid);
-		if(err)
-			goto out_unlock;
 
 		err = audit_ipc_obj(&(shp->shm_perm));
 		if (err)
@@ -756,13 +763,11 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		 *	the name away when the usage hits zero.
 		 */
 		mutex_lock(&shm_ids(ns).mutex);
-		shp = shm_lock(ns, shmid);
-		err = -EINVAL;
-		if (shp == NULL) 
+		shp = shm_lock_check(ns, shmid);
+		if (IS_ERR(shp)) {
+			err = PTR_ERR(shp);
 			goto out_up;
-		err = shm_checkid(ns, shp, shmid);
-		if(err)
-			goto out_unlock_up;
+		}
 
 		err = audit_ipc_obj(&(shp->shm_perm));
 		if (err)
@@ -786,18 +791,21 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 
 	case IPC_SET:
 	{
+		if (!buf) {
+			err = -EFAULT;
+			goto out;
+		}
+
 		if (copy_shmid_from_user (&setbuf, buf, version)) {
 			err = -EFAULT;
 			goto out;
 		}
 		mutex_lock(&shm_ids(ns).mutex);
-		shp = shm_lock(ns, shmid);
-		err=-EINVAL;
-		if(shp==NULL)
+		shp = shm_lock_check(ns, shmid);
+		if (IS_ERR(shp)) {
+			err = PTR_ERR(shp);
 			goto out_up;
-		err = shm_checkid(ns, shp,shmid);
-		if(err)
-			goto out_unlock_up;
+		}
 		err = audit_ipc_obj(&(shp->shm_perm));
 		if (err)
 			goto out_unlock_up;
@@ -903,13 +911,11 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	 * additional creator id...
 	 */
 	ns = current->nsproxy->ipc_ns;
-	shp = shm_lock(ns, shmid);
-	if(shp == NULL)
+	shp = shm_lock_check(ns, shmid);
+	if (IS_ERR(shp)) {
+		err = PTR_ERR(shp);
 		goto out;
-
-	err = shm_checkid(ns, shp,shmid);
-	if (err)
-		goto out_unlock;
+	}
 
 	err = -EACCES;
 	if (ipcperms(&shp->shm_perm, acc_mode))
@@ -970,7 +976,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 out_nattch:
 	mutex_lock(&shm_ids(ns).mutex);
 	shp = shm_lock(ns, shmid);
-	BUG_ON(!shp);
+	BUG_ON(IS_ERR(shp));
 	shp->shm_nattch--;
 	if(shp->shm_nattch == 0 &&
 	   shp->shm_perm.mode & SHM_DEST)

commit 637c36634029e4e7c81112796dafc32d56355b4a
Author: Nadia Derbey <Nadia.Derbey@bull.net>
Date:   Thu Oct 18 23:40:50 2007 -0700

    ipc: remove the ipc_get() routine
    
    This is a trivial patch that removes the ipc_get() routine: it is replaced
    by a call to idr_find().
    
    Signed-off-by: Nadia Derbey <Nadia.Derbey@bull.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index d20cc25c5bdf..8cf1cf3d5bec 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -63,8 +63,6 @@ static struct ipc_ids init_shm_ids;
 	((struct shmid_kernel*)ipc_lock(&shm_ids(ns),id))
 #define shm_unlock(shp)			\
 	ipc_unlock(&(shp)->shm_perm)
-#define shm_get(ns, id)			\
-	((struct shmid_kernel*)ipc_get(&shm_ids(ns),id))
 #define shm_buildid(ns, id, seq)	\
 	ipc_buildid(&shm_ids(ns), id, seq)
 
@@ -563,7 +561,19 @@ static void shm_get_stat(struct ipc_namespace *ns, unsigned long *rss,
 		struct shmid_kernel *shp;
 		struct inode *inode;
 
-		shp = shm_get(ns, next_id);
+		/*
+		 * idr_find() is called via shm_get(), so with shm_ids.mutex
+		 * locked. Since ipc_addid() is also called with
+		 * shm_ids.mutex down, there is no need to add read barriers
+		 * here to gurantee the writes in ipc_addid() are seen in
+		 * order here (for Alpha).
+		 * However idr_find() itself does not necessary require
+		 * ipc_ids.mutex down. So if idr_find() is used by other
+		 * places without ipc_ids.mutex down, then it needs read
+		 * read memory barriers as ipc_lock() does.
+		 */
+
+		shp = idr_find(&shm_ids(ns).ipcs_idr, next_id);
 		if (shp == NULL)
 			continue;
 

commit 7748dbfaa010b12d5fb9ddf80199534c565c6bce
Author: Nadia Derbey <Nadia.Derbey@bull.net>
Date:   Thu Oct 18 23:40:49 2007 -0700

    ipc: unify the syscalls code
    
    This patch introduces a change into the sys_msgget(), sys_semget() and
    sys_shmget() routines: they now share a common code, which is better for
    maintainability.
    
    Signed-off-by: Nadia Derbey <Nadia.Derbey@bull.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index dcc333239683..d20cc25c5bdf 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -68,8 +68,7 @@ static struct ipc_ids init_shm_ids;
 #define shm_buildid(ns, id, seq)	\
 	ipc_buildid(&shm_ids(ns), id, seq)
 
-static int newseg (struct ipc_namespace *ns, key_t key,
-		int shmflg, size_t size);
+static int newseg(struct ipc_namespace *, struct ipc_params *);
 static void shm_open(struct vm_area_struct *vma);
 static void shm_close(struct vm_area_struct *vma);
 static void shm_destroy (struct ipc_namespace *ns, struct shmid_kernel *shp);
@@ -341,8 +340,11 @@ static struct vm_operations_struct shm_vm_ops = {
 #endif
 };
 
-static int newseg (struct ipc_namespace *ns, key_t key, int shmflg, size_t size)
+static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
 {
+	key_t key = params->key;
+	int shmflg = params->flg;
+	size_t size = params->u.size;
 	int error;
 	struct shmid_kernel *shp;
 	int numpages = (size + PAGE_SIZE -1) >> PAGE_SHIFT;
@@ -423,57 +425,36 @@ static int newseg (struct ipc_namespace *ns, key_t key, int shmflg, size_t size)
 	return error;
 }
 
+static inline int shm_security(void *shp, int shmflg)
+{
+	return security_shm_associate((struct shmid_kernel *) shp, shmflg);
+}
+
+static inline int shm_more_checks(void *shp, struct ipc_params *params)
+{
+	if (((struct shmid_kernel *)shp)->shm_segsz < params->u.size)
+		return -EINVAL;
+
+	return 0;
+}
+
 asmlinkage long sys_shmget (key_t key, size_t size, int shmflg)
 {
-	struct shmid_kernel *shp;
-	int err;
 	struct ipc_namespace *ns;
+	struct ipc_ops shm_ops;
+	struct ipc_params shm_params;
 
 	ns = current->nsproxy->ipc_ns;
 
-	err = idr_pre_get(&shm_ids(ns).ipcs_idr, GFP_KERNEL);
+	shm_ops.getnew = newseg;
+	shm_ops.associate = shm_security;
+	shm_ops.more_checks = shm_more_checks;
 
-	if (key == IPC_PRIVATE) {
-		if (!err)
-			err = -ENOMEM;
-		else {
-			mutex_lock(&shm_ids(ns).mutex);
-			err = newseg(ns, key, shmflg, size);
-			mutex_unlock(&shm_ids(ns).mutex);
-		}
-	} else {
-		mutex_lock(&shm_ids(ns).mutex);
-		shp = (struct shmid_kernel *) ipc_findkey(&shm_ids(ns), key);
-		if (shp == NULL) {
-			if (!(shmflg & IPC_CREAT))
-				err = -ENOENT;
-			else if (!err)
-				err = -ENOMEM;
-			else
-				err = newseg(ns, key, shmflg, size);
-		} else {
-			/* shp has been locked by ipc_findkey() */
-
-			if ((shmflg & IPC_CREAT) && (shmflg & IPC_EXCL))
-				err = -EEXIST;
-			else {
-				if (shp->shm_segsz < size)
-					err = -EINVAL;
-				else if (ipcperms(&shp->shm_perm, shmflg))
-					err = -EACCES;
-				else {
-					err = security_shm_associate(shp,
-								shmflg);
-					if (!err)
-						err = shp->shm_perm.id;
-				}
-			}
-			shm_unlock(shp);
-		}
-		mutex_unlock(&shm_ids(ns).mutex);
-	}
+	shm_params.key = key;
+	shm_params.flg = shmflg;
+	shm_params.u.size = size;
 
-	return err;
+	return ipcget(ns, &shm_ids(ns), &shm_ops, &shm_params);
 }
 
 static inline unsigned long copy_shmid_to_user(void __user *buf, struct shmid64_ds *in, int version)

commit 7ca7e564e049d8b350ec9d958ff25eaa24226352
Author: Nadia Derbey <Nadia.Derbey@bull.net>
Date:   Thu Oct 18 23:40:48 2007 -0700

    ipc: store ipcs into IDRs
    
    This patch introduces ipcs storage into IDRs. The main changes are:
      . This ipc_ids structure is changed: the entries array is changed into a
        root idr structure.
      . The grow_ary() routine is removed: it is not needed anymore when adding
        an ipc structure, since we are now using the IDR facility.
      . The ipc_rmid() routine interface is changed:
           . there is no need for this routine to return the pointer passed in as
             argument: it is now declared as a void
           . since the id is now part of the kern_ipc_perm structure, no need to
             have it as an argument to the routine
    
    Signed-off-by: Nadia Derbey <Nadia.Derbey@bull.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index b9d272900a1e..dcc333239683 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -84,7 +84,7 @@ static void __shm_init_ns(struct ipc_namespace *ns, struct ipc_ids *ids)
 	ns->shm_ctlall = SHMALL;
 	ns->shm_ctlmni = SHMMNI;
 	ns->shm_tot = 0;
-	ipc_init_ids(ids, 1);
+	ipc_init_ids(ids);
 }
 
 static void do_shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *shp)
@@ -112,20 +112,24 @@ int shm_init_ns(struct ipc_namespace *ns)
 
 void shm_exit_ns(struct ipc_namespace *ns)
 {
-	int i;
 	struct shmid_kernel *shp;
+	int next_id;
+	int total, in_use;
 
 	mutex_lock(&shm_ids(ns).mutex);
-	for (i = 0; i <= shm_ids(ns).max_id; i++) {
-		shp = shm_lock(ns, i);
+
+	in_use = shm_ids(ns).in_use;
+
+	for (total = 0, next_id = 0; total < in_use; next_id++) {
+		shp = idr_find(&shm_ids(ns).ipcs_idr, next_id);
 		if (shp == NULL)
 			continue;
-
+		ipc_lock_by_ptr(&shp->shm_perm);
 		do_shm_rmid(ns, shp);
+		total++;
 	}
 	mutex_unlock(&shm_ids(ns).mutex);
 
-	ipc_fini_ids(ns->ids[IPC_SHM_IDS]);
 	kfree(ns->ids[IPC_SHM_IDS]);
 	ns->ids[IPC_SHM_IDS] = NULL;
 }
@@ -146,9 +150,9 @@ static inline int shm_checkid(struct ipc_namespace *ns,
 	return 0;
 }
 
-static inline struct shmid_kernel *shm_rmid(struct ipc_namespace *ns, int id)
+static inline void shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *s)
 {
-	return (struct shmid_kernel *)ipc_rmid(&shm_ids(ns), id);
+	ipc_rmid(&shm_ids(ns), &s->shm_perm);
 }
 
 static inline int shm_addid(struct ipc_namespace *ns, struct shmid_kernel *shp)
@@ -184,7 +188,7 @@ static void shm_open(struct vm_area_struct *vma)
 static void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)
 {
 	ns->shm_tot -= (shp->shm_segsz + PAGE_SIZE - 1) >> PAGE_SHIFT;
-	shm_rmid(ns, shp->id);
+	shm_rmid(ns, shp);
 	shm_unlock(shp);
 	if (!is_file_hugepages(shp->shm_file))
 		shmem_lock(shp->shm_file, 0, shp->mlock_user);
@@ -398,17 +402,18 @@ static int newseg (struct ipc_namespace *ns, key_t key, int shmflg, size_t size)
 	shp->shm_ctim = get_seconds();
 	shp->shm_segsz = size;
 	shp->shm_nattch = 0;
-	shp->id = shm_buildid(ns, id, shp->shm_perm.seq);
+	shp->shm_perm.id = shm_buildid(ns, id, shp->shm_perm.seq);
 	shp->shm_file = file;
 	/*
 	 * shmid gets reported as "inode#" in /proc/pid/maps.
 	 * proc-ps tools use this. Changing this will break them.
 	 */
-	file->f_dentry->d_inode->i_ino = shp->id;
+	file->f_dentry->d_inode->i_ino = shp->shm_perm.id;
 
 	ns->shm_tot += numpages;
+	error = shp->shm_perm.id;
 	shm_unlock(shp);
-	return shp->id;
+	return error;
 
 no_id:
 	fput(file);
@@ -421,37 +426,52 @@ static int newseg (struct ipc_namespace *ns, key_t key, int shmflg, size_t size)
 asmlinkage long sys_shmget (key_t key, size_t size, int shmflg)
 {
 	struct shmid_kernel *shp;
-	int err, id = 0;
+	int err;
 	struct ipc_namespace *ns;
 
 	ns = current->nsproxy->ipc_ns;
 
-	mutex_lock(&shm_ids(ns).mutex);
+	err = idr_pre_get(&shm_ids(ns).ipcs_idr, GFP_KERNEL);
+
 	if (key == IPC_PRIVATE) {
-		err = newseg(ns, key, shmflg, size);
-	} else if ((id = ipc_findkey(&shm_ids(ns), key)) == -1) {
-		if (!(shmflg & IPC_CREAT))
-			err = -ENOENT;
-		else
+		if (!err)
+			err = -ENOMEM;
+		else {
+			mutex_lock(&shm_ids(ns).mutex);
 			err = newseg(ns, key, shmflg, size);
-	} else if ((shmflg & IPC_CREAT) && (shmflg & IPC_EXCL)) {
-		err = -EEXIST;
+			mutex_unlock(&shm_ids(ns).mutex);
+		}
 	} else {
-		shp = shm_lock(ns, id);
-		BUG_ON(shp==NULL);
-		if (shp->shm_segsz < size)
-			err = -EINVAL;
-		else if (ipcperms(&shp->shm_perm, shmflg))
-			err = -EACCES;
-		else {
-			int shmid = shm_buildid(ns, id, shp->shm_perm.seq);
-			err = security_shm_associate(shp, shmflg);
-			if (!err)
-				err = shmid;
+		mutex_lock(&shm_ids(ns).mutex);
+		shp = (struct shmid_kernel *) ipc_findkey(&shm_ids(ns), key);
+		if (shp == NULL) {
+			if (!(shmflg & IPC_CREAT))
+				err = -ENOENT;
+			else if (!err)
+				err = -ENOMEM;
+			else
+				err = newseg(ns, key, shmflg, size);
+		} else {
+			/* shp has been locked by ipc_findkey() */
+
+			if ((shmflg & IPC_CREAT) && (shmflg & IPC_EXCL))
+				err = -EEXIST;
+			else {
+				if (shp->shm_segsz < size)
+					err = -EINVAL;
+				else if (ipcperms(&shp->shm_perm, shmflg))
+					err = -EACCES;
+				else {
+					err = security_shm_associate(shp,
+								shmflg);
+					if (!err)
+						err = shp->shm_perm.id;
+				}
+			}
+			shm_unlock(shp);
 		}
-		shm_unlock(shp);
+		mutex_unlock(&shm_ids(ns).mutex);
 	}
-	mutex_unlock(&shm_ids(ns).mutex);
 
 	return err;
 }
@@ -550,17 +570,20 @@ static inline unsigned long copy_shminfo_to_user(void __user *buf, struct shminf
 static void shm_get_stat(struct ipc_namespace *ns, unsigned long *rss,
 		unsigned long *swp)
 {
-	int i;
+	int next_id;
+	int total, in_use;
 
 	*rss = 0;
 	*swp = 0;
 
-	for (i = 0; i <= shm_ids(ns).max_id; i++) {
+	in_use = shm_ids(ns).in_use;
+
+	for (total = 0, next_id = 0; total < in_use; next_id++) {
 		struct shmid_kernel *shp;
 		struct inode *inode;
 
-		shp = shm_get(ns, i);
-		if(!shp)
+		shp = shm_get(ns, next_id);
+		if (shp == NULL)
 			continue;
 
 		inode = shp->shm_file->f_path.dentry->d_inode;
@@ -575,6 +598,8 @@ static void shm_get_stat(struct ipc_namespace *ns, unsigned long *rss,
 			*swp += info->swapped;
 			spin_unlock(&info->lock);
 		}
+
+		total++;
 	}
 }
 
@@ -611,7 +636,7 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		if(copy_shminfo_to_user (buf, &shminfo, version))
 			return -EFAULT;
 		/* reading a integer is always atomic */
-		err= shm_ids(ns).max_id;
+		err = ipc_get_maxid(&shm_ids(ns));
 		if(err<0)
 			err = 0;
 		goto out;
@@ -631,7 +656,7 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		shm_info.shm_tot = ns->shm_tot;
 		shm_info.swap_attempts = 0;
 		shm_info.swap_successes = 0;
-		err = shm_ids(ns).max_id;
+		err = ipc_get_maxid(&shm_ids(ns));
 		mutex_unlock(&shm_ids(ns).mutex);
 		if(copy_to_user (buf, &shm_info, sizeof(shm_info))) {
 			err = -EFAULT;
@@ -651,11 +676,8 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		if(shp==NULL) {
 			err = -EINVAL;
 			goto out;
-		} else if(cmd==SHM_STAT) {
-			err = -EINVAL;
-			if (shmid > shm_ids(ns).max_id)
-				goto out_unlock;
-			result = shm_buildid(ns, shmid, shp->shm_perm.seq);
+		} else if (cmd == SHM_STAT) {
+			result = shp->shm_perm.id;
 		} else {
 			err = shm_checkid(ns, shp,shmid);
 			if(err)
@@ -925,7 +947,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 
 	file->private_data = sfd;
 	file->f_mapping = shp->shm_file->f_mapping;
-	sfd->id = shp->id;
+	sfd->id = shp->shm_perm.id;
 	sfd->ns = get_ipc_ns(ns);
 	sfd->file = shp->shm_file;
 	sfd->vm_ops = NULL;
@@ -1094,7 +1116,7 @@ static int sysvipc_shm_proc_show(struct seq_file *s, void *it)
 		format = BIG_STRING;
 	return seq_printf(s, format,
 			  shp->shm_perm.key,
-			  shp->id,
+			  shp->shm_perm.id,
 			  shp->shm_perm.mode,
 			  shp->shm_segsz,
 			  shp->shm_cprid,

commit b488893a390edfe027bae7a46e9af8083e740668
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Oct 18 23:40:14 2007 -0700

    pid namespaces: changes to show virtual ids to user
    
    This is the largest patch in the set. Make all (I hope) the places where
    the pid is shown to or get from user operate on the virtual pids.
    
    The idea is:
     - all in-kernel data structures must store either struct pid itself
       or the pid's global nr, obtained with pid_nr() call;
     - when seeking the task from kernel code with the stored id one
       should use find_task_by_pid() call that works with global pids;
     - when showing pid's numerical value to the user the virtual one
       should be used, but however when one shows task's pid outside this
       task's namespace the global one is to be used;
     - when getting the pid from userspace one need to consider this as
       the virtual one and use appropriate task/pid-searching functions.
    
    [akpm@linux-foundation.org: build fix]
    [akpm@linux-foundation.org: nuther build fix]
    [akpm@linux-foundation.org: yet nuther build fix]
    [akpm@linux-foundation.org: remove unneeded casts]
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: Alexey Dobriyan <adobriyan@openvz.org>
    Cc: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Paul Menage <menage@google.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 5fc5cf50cf1b..b9d272900a1e 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -168,7 +168,7 @@ static void shm_open(struct vm_area_struct *vma)
 	shp = shm_lock(sfd->ns, sfd->id);
 	BUG_ON(!shp);
 	shp->shm_atim = get_seconds();
-	shp->shm_lprid = current->tgid;
+	shp->shm_lprid = task_tgid_vnr(current);
 	shp->shm_nattch++;
 	shm_unlock(shp);
 }
@@ -213,7 +213,7 @@ static void shm_close(struct vm_area_struct *vma)
 	/* remove from the list of attaches of the shm segment */
 	shp = shm_lock(ns, sfd->id);
 	BUG_ON(!shp);
-	shp->shm_lprid = current->tgid;
+	shp->shm_lprid = task_tgid_vnr(current);
 	shp->shm_dtim = get_seconds();
 	shp->shm_nattch--;
 	if(shp->shm_nattch == 0 &&
@@ -392,7 +392,7 @@ static int newseg (struct ipc_namespace *ns, key_t key, int shmflg, size_t size)
 	if(id == -1) 
 		goto no_id;
 
-	shp->shm_cprid = current->tgid;
+	shp->shm_cprid = task_tgid_vnr(current);
 	shp->shm_lprid = 0;
 	shp->shm_atim = shp->shm_dtim = 0;
 	shp->shm_ctim = get_seconds();

commit ce8d2cdf3d2b73e346c82e6f0a46da331df6364c
Author: Dave Hansen <haveblue@us.ibm.com>
Date:   Tue Oct 16 23:31:13 2007 -0700

    r/o bind mounts: filesystem helpers for custom 'struct file's
    
    Why do we need r/o bind mounts?
    
    This feature allows a read-only view into a read-write filesystem.  In the
    process of doing that, it also provides infrastructure for keeping track of
    the number of writers to any given mount.
    
    This has a number of uses.  It allows chroots to have parts of filesystems
    writable.  It will be useful for containers in the future because users may
    have root inside a container, but should not be allowed to write to
    somefilesystems.  This also replaces patches that vserver has had out of the
    tree for several years.
    
    It allows security enhancement by making sure that parts of your filesystem
    read-only (such as when you don't trust your FTP server), when you don't want
    to have entire new filesystems mounted, or when you want atime selectively
    updated.  I've been using the following script to test that the feature is
    working as desired.  It takes a directory and makes a regular bind and a r/o
    bind mount of it.  It then performs some normal filesystem operations on the
    three directories, including ones that are expected to fail, like creating a
    file on the r/o mount.
    
    This patch:
    
    Some filesystems forego the vfs and may_open() and create their own 'struct
    file's.
    
    This patch creates a couple of helper functions which can be used by these
    filesystems, and will provide a unified place which the r/o bind mount code
    may patch.
    
    Also, rename an existing, static-scope init_file() to a less generic name.
    
    Signed-off-by: Dave Hansen <haveblue@us.ibm.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index b8884c288ecc..5fc5cf50cf1b 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -907,7 +907,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 		goto out_unlock;
 
 	path.dentry = dget(shp->shm_file->f_path.dentry);
-	path.mnt    = mntget(shp->shm_file->f_path.mnt);
+	path.mnt    = shp->shm_file->f_path.mnt;
 	shp->shm_nattch++;
 	size = i_size_read(path.dentry->d_inode);
 	shm_unlock(shp);
@@ -915,18 +915,16 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	err = -ENOMEM;
 	sfd = kzalloc(sizeof(*sfd), GFP_KERNEL);
 	if (!sfd)
-		goto out_put_path;
+		goto out_put_dentry;
 
 	err = -ENOMEM;
-	file = get_empty_filp();
+
+	file = alloc_file(path.mnt, path.dentry, f_mode, &shm_file_operations);
 	if (!file)
 		goto out_free;
 
-	file->f_op = &shm_file_operations;
 	file->private_data = sfd;
-	file->f_path = path;
 	file->f_mapping = shp->shm_file->f_mapping;
-	file->f_mode = f_mode;
 	sfd->id = shp->id;
 	sfd->ns = get_ipc_ns(ns);
 	sfd->file = shp->shm_file;
@@ -977,9 +975,8 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 
 out_free:
 	kfree(sfd);
-out_put_path:
+out_put_dentry:
 	dput(path.dentry);
-	mntput(path.mnt);
 	goto out_nattch;
 }
 

commit d823e3e7541c39b4dfe9c79dbf052b4c39da2965
Author: Adrian Bunk <bunk@stusta.de>
Date:   Tue Oct 16 23:26:42 2007 -0700

    ipc/shm.c: make 2 functions static
    
    This patch makes two needlessly global functions static.
    
    Signed-off-by: Adrian Bunk <bunk@stusta.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index a86a3a5c8a19..b8884c288ecc 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -233,7 +233,7 @@ static int shm_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
 }
 
 #ifdef CONFIG_NUMA
-int shm_set_policy(struct vm_area_struct *vma, struct mempolicy *new)
+static int shm_set_policy(struct vm_area_struct *vma, struct mempolicy *new)
 {
 	struct file *file = vma->vm_file;
 	struct shm_file_data *sfd = shm_file_data(file);
@@ -243,7 +243,8 @@ int shm_set_policy(struct vm_area_struct *vma, struct mempolicy *new)
 	return err;
 }
 
-struct mempolicy *shm_get_policy(struct vm_area_struct *vma, unsigned long addr)
+static struct mempolicy *shm_get_policy(struct vm_area_struct *vma,
+					unsigned long addr)
 {
 	struct file *file = vma->vm_file;
 	struct shm_file_data *sfd = shm_file_data(file);

commit 7be77e20d59fc3dd3fdde31641e0bc821114d26b
Author: Pavel Emelianov <xemul@openvz.org>
Date:   Tue Jul 31 00:38:48 2007 -0700

    Fix user struct leakage with locked IPC shem segment
    
    When user locks an ipc shmem segmant with SHM_LOCK ctl and the segment is
    already locked the shmem_lock() function returns 0.  After this the
    subsequent code leaks the existing user struct:
    
    == ipc/shm.c: sys_shmctl() ==
         ...
         err = shmem_lock(shp->shm_file, 1, user);
         if (!err) {
              shp->shm_perm.mode |= SHM_LOCKED;
              shp->mlock_user = user;
         }
         ...
    ==
    
    Other results of this are:
    1. the new shp->mlock_user is not get-ed and will point to freed
       memory when the task dies.
    2. the RLIMIT_MEMLOCK is screwed on both user structs.
    
    The exploit looks like this:
    
    ==
        id = shmget(...);
        setresuid(uid, 0, 0);
        shmctl(id, SHM_LOCK, NULL);
        setresuid(uid + 1, 0, 0);
        shmctl(id, SHM_LOCK, NULL);
    ==
    
    My solution is to return 0 to the userspace and do not change the
    segment's user.
    
    Signed-off-by: Pavel Emelianov <xemul@openvz.org>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index d88ac5a07ec7..a86a3a5c8a19 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -716,7 +716,7 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 			struct user_struct * user = current->user;
 			if (!is_file_hugepages(shp->shm_file)) {
 				err = shmem_lock(shp->shm_file, 1, user);
-				if (!err) {
+				if (!err && !(shp->shm_perm.mode & SHM_LOCKED)){
 					shp->shm_perm.mode |= SHM_LOCKED;
 					shp->mlock_user = user;
 				}

commit 2e92a3baee64112fd210a930276bad165b0bd576
Author: David Howells <dhowells@redhat.com>
Date:   Tue Jul 31 00:37:24 2007 -0700

    NOMMU: Fix SYSV IPC SHM
    
    Fix the SYSV IPC SHM to work with the changes applied by the new fault handler
    patches when CONFIG_MMU=n.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Cc: Nick Piggin <nickpiggin@yahoo.com.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index d0259e3ad1c0..d88ac5a07ec7 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -268,7 +268,9 @@ static int shm_mmap(struct file * file, struct vm_area_struct * vma)
 	if (ret != 0)
 		return ret;
 	sfd->vm_ops = vma->vm_ops;
+#ifdef CONFIG_MMU
 	BUG_ON(!sfd->vm_ops->fault);
+#endif
 	vma->vm_ops = &shm_vm_ops;
 	shm_open(vma);
 

commit d0217ac04ca6591841e5665f518e38064f4e65bd
Author: Nick Piggin <npiggin@suse.de>
Date:   Thu Jul 19 01:47:03 2007 -0700

    mm: fault feedback #1
    
    Change ->fault prototype.  We now return an int, which contains
    VM_FAULT_xxx code in the low byte, and FAULT_RET_xxx code in the next byte.
     FAULT_RET_ code tells the VM whether a page was found, whether it has been
    locked, and potentially other things.  This is not quite the way he wanted
    it yet, but that's changed in the next patch (which requires changes to
    arch code).
    
    This means we no longer set VM_CAN_INVALIDATE in the vma in order to say
    that a page is locked which requires filemap_nopage to go away (because we
    can no longer remain backward compatible without that flag), but we were
    going to do that anyway.
    
    struct fault_data is renamed to struct vm_fault as Linus asked. address
    is now a void __user * that we should firmly encourage drivers not to use
    without really good reason.
    
    The page is now returned via a page pointer in the vm_fault struct.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index e2d090348b1e..d0259e3ad1c0 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -224,13 +224,12 @@ static void shm_close(struct vm_area_struct *vma)
 	mutex_unlock(&shm_ids(ns).mutex);
 }
 
-static struct page *shm_fault(struct vm_area_struct *vma,
-					struct fault_data *fdata)
+static int shm_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
 {
 	struct file *file = vma->vm_file;
 	struct shm_file_data *sfd = shm_file_data(file);
 
-	return sfd->vm_ops->fault(vma, fdata);
+	return sfd->vm_ops->fault(vma, vmf);
 }
 
 #ifdef CONFIG_NUMA

commit 54cb8821de07f2ffcd28c380ce9b93d5784b40d7
Author: Nick Piggin <npiggin@suse.de>
Date:   Thu Jul 19 01:46:59 2007 -0700

    mm: merge populate and nopage into fault (fixes nonlinear)
    
    Nonlinear mappings are (AFAIKS) simply a virtual memory concept that encodes
    the virtual address -> file offset differently from linear mappings.
    
    ->populate is a layering violation because the filesystem/pagecache code
    should need to know anything about the virtual memory mapping.  The hitch here
    is that the ->nopage handler didn't pass down enough information (ie.  pgoff).
     But it is more logical to pass pgoff rather than have the ->nopage function
    calculate it itself anyway (because that's a similar layering violation).
    
    Having the populate handler install the pte itself is likewise a nasty thing
    to be doing.
    
    This patch introduces a new fault handler that replaces ->nopage and
    ->populate and (later) ->nopfn.  Most of the old mechanism is still in place
    so there is a lot of duplication and nice cleanups that can be removed if
    everyone switches over.
    
    The rationale for doing this in the first place is that nonlinear mappings are
    subject to the pagefault vs invalidate/truncate race too, and it seemed stupid
    to duplicate the synchronisation logic rather than just consolidate the two.
    
    After this patch, MAP_NONBLOCK no longer sets up ptes for pages present in
    pagecache.  Seems like a fringe functionality anyway.
    
    NOPAGE_REFAULT is removed.  This should be implemented with ->fault, and no
    users have hit mainline yet.
    
    [akpm@linux-foundation.org: cleanup]
    [randy.dunlap@oracle.com: doc. fixes for readahead]
    [akpm@linux-foundation.org: build fix]
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    Cc: Mark Fasheh <mark.fasheh@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 242c3f66493a..e2d090348b1e 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -224,13 +224,13 @@ static void shm_close(struct vm_area_struct *vma)
 	mutex_unlock(&shm_ids(ns).mutex);
 }
 
-static struct page *shm_nopage(struct vm_area_struct *vma,
-			       unsigned long address, int *type)
+static struct page *shm_fault(struct vm_area_struct *vma,
+					struct fault_data *fdata)
 {
 	struct file *file = vma->vm_file;
 	struct shm_file_data *sfd = shm_file_data(file);
 
-	return sfd->vm_ops->nopage(vma, address, type);
+	return sfd->vm_ops->fault(vma, fdata);
 }
 
 #ifdef CONFIG_NUMA
@@ -269,6 +269,7 @@ static int shm_mmap(struct file * file, struct vm_area_struct * vma)
 	if (ret != 0)
 		return ret;
 	sfd->vm_ops = vma->vm_ops;
+	BUG_ON(!sfd->vm_ops->fault);
 	vma->vm_ops = &shm_vm_ops;
 	shm_open(vma);
 
@@ -327,7 +328,7 @@ static const struct file_operations shm_file_operations = {
 static struct vm_operations_struct shm_vm_ops = {
 	.open	= shm_open,	/* callback for a new vm-area open */
 	.close	= shm_close,	/* callback for when the vm-area is released */
-	.nopage	= shm_nopage,
+	.fault	= shm_fault,
 #if defined(CONFIG_NUMA)
 	.set_policy = shm_set_policy,
 	.get_policy = shm_get_policy,

commit 7d69a1f4a72b18876c99c697692b78339d491568
Author: Cedric Le Goater <clg@fr.ibm.com>
Date:   Sun Jul 15 23:40:58 2007 -0700

    remove CONFIG_UTS_NS and CONFIG_IPC_NS
    
    CONFIG_UTS_NS and CONFIG_IPC_NS have very little value as they only
    deactivate the unshare of the uts and ipc namespaces and do not improve
    performance.
    
    Signed-off-by: Cedric Le Goater <clg@fr.ibm.com>
    Acked-by: "Serge E. Hallyn" <serue@us.ibm.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Herbert Poetzl <herbert@13thfloor.at>
    Cc: Pavel Emelianov <xemul@openvz.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 0852f206d895..242c3f66493a 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -77,7 +77,7 @@ static void shm_destroy (struct ipc_namespace *ns, struct shmid_kernel *shp);
 static int sysvipc_shm_proc_show(struct seq_file *s, void *it);
 #endif
 
-static void __ipc_init __shm_init_ns(struct ipc_namespace *ns, struct ipc_ids *ids)
+static void __shm_init_ns(struct ipc_namespace *ns, struct ipc_ids *ids)
 {
 	ns->ids[IPC_SHM_IDS] = ids;
 	ns->shm_ctlmax = SHMMAX;
@@ -98,7 +98,6 @@ static void do_shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *shp)
 		shm_destroy(ns, shp);
 }
 
-#ifdef CONFIG_IPC_NS
 int shm_init_ns(struct ipc_namespace *ns)
 {
 	struct ipc_ids *ids;
@@ -130,7 +129,6 @@ void shm_exit_ns(struct ipc_namespace *ns)
 	kfree(ns->ids[IPC_SHM_IDS]);
 	ns->ids[IPC_SHM_IDS] = NULL;
 }
-#endif
 
 void __init shm_init (void)
 {

commit 9d66586f7723b73c5925c7c7819c260484627851
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Jun 16 10:16:16 2007 -0700

    shm: fix the filename of hugetlb sysv shared memory
    
    Some user space tools need to identify SYSV shared memory when examining
    /proc/<pid>/maps.  To do so they look for a block device with major zero, a
    dentry named SYSV<sysv key>, and having the minor of the internal sysv
    shared memory kernel mount.
    
    To help these tools and to make it easier for people just browsing
    /proc/<pid>/maps this patch modifies hugetlb sysv shared memory to use the
    SYSV<key> dentry naming convention.
    
    User space tools will still have to be aware that hugetlb sysv shared
    memory lives on a different internal kernel mount and so has a different
    block device minor number from the rest of sysv shared memory.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: "Serge E. Hallyn" <serge@hallyn.com>
    Cc: Albert Cahalan <acahalan@gmail.com>
    Cc: Badari Pulavarty <pbadari@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 047b823e6bf0..0852f206d895 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -366,9 +366,10 @@ static int newseg (struct ipc_namespace *ns, key_t key, int shmflg, size_t size)
 		return error;
 	}
 
+	sprintf (name, "SYSV%08x", key);
 	if (shmflg & SHM_HUGETLB) {
-		/* hugetlb_zero_setup takes care of mlock user accounting */
-		file = hugetlb_zero_setup(size);
+		/* hugetlb_file_setup takes care of mlock user accounting */
+		file = hugetlb_file_setup(name, size);
 		shp->mlock_user = current->user;
 	} else {
 		int acctflag = VM_ACCOUNT;
@@ -379,7 +380,6 @@ static int newseg (struct ipc_namespace *ns, key_t key, int shmflg, size_t size)
 		if  ((shmflg & SHM_NORESERVE) &&
 				sysctl_overcommit_memory != OVERCOMMIT_NEVER)
 			acctflag = 0;
-		sprintf (name, "SYSV%08x", key);
 		file = shmem_file_setup(name, size, acctflag);
 	}
 	error = PTR_ERR(file);

commit 22741925d268e8479ef66312749bd8d96ed35365
Author: Adam Litke <agl@us.ibm.com>
Date:   Sat Jun 16 10:16:15 2007 -0700

    hugetlb: fix get_policy for stacked shared memory files
    
    Here's another breakage as a result of shared memory stacked files :(
    
    The NUMA policy for a VMA is determined by checking the following (in the
    order given):
    
    1) vma->vm_ops->get_policy() (if defined)
    2) vma->vm_policy (if defined)
    3) task->mempolicy (if defined)
    4) Fall back to default_policy
    
    By switching to stacked files for shared memory, get_policy() is now always
    set to shm_get_policy which is a wrapper function.  This causes us to stop
    at step 1, which yields NULL for hugetlb instead of task->mempolicy which
    was the previous (and correct) result.
    
    This patch modifies the shm_get_policy() wrapper to maintain steps 1-3 for
    the wrapped vm_ops.
    
    (akpm: the refcounting of mempolicies is busted and this patch does nothing to
    improve it)
    
    Signed-off-by: Adam Litke <agl@us.ibm.com>
    Acked-by: William Irwin <bill.irwin@oracle.com>
    Cc: dean gaudet <dean@arctic.org>
    Cc: Christoph Lameter <clameter@sgi.com>
    Cc: Andi Kleen <ak@suse.de>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 02faa54dbf5a..047b823e6bf0 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -254,8 +254,10 @@ struct mempolicy *shm_get_policy(struct vm_area_struct *vma, unsigned long addr)
 
 	if (sfd->vm_ops->get_policy)
 		pol = sfd->vm_ops->get_policy(vma, addr);
-	else
+	else if (vma->vm_policy)
 		pol = vma->vm_policy;
+	else
+		pol = current->mempolicy;
 	return pol;
 }
 #endif

commit 30475cc12a50816f290828fb7e3cd7036cd622df
Author: Badari Pulavarty <pbadari@us.ibm.com>
Date:   Sat Jun 16 10:15:59 2007 -0700

    Restore shmid as inode# to fix /proc/pid/maps ABI breakage
    
    shmid used to be stored as inode# for shared memory segments. Some of
    the proc-ps tools use this from /proc/pid/maps.  Recent cleanups
    to newseg() changed it.  This patch sets inode number back to shared
    memory id to fix breakage.
    
    Signed-off-by: Badari Pulavarty <pbadari@us.ibm.com>
    Cc: "Albert Cahalan" <acahalan@gmail.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 4fefbad7096d..02faa54dbf5a 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -397,6 +397,11 @@ static int newseg (struct ipc_namespace *ns, key_t key, int shmflg, size_t size)
 	shp->shm_nattch = 0;
 	shp->id = shm_buildid(ns, id, shp->shm_perm.seq);
 	shp->shm_file = file;
+	/*
+	 * shmid gets reported as "inode#" in /proc/pid/maps.
+	 * proc-ps tools use this. Changing this will break them.
+	 */
+	file->f_dentry->d_inode->i_ino = shp->id;
 
 	ns->shm_tot += numpages;
 	shm_unlock(shp);

commit 516dffdcd8827a40532798602830dfcfc672294c
Author: Adam Litke <agl@us.ibm.com>
Date:   Thu Mar 1 15:46:08 2007 -0800

    [PATCH] Fix get_unmapped_area and fsync for hugetlb shm segments
    
    This patch provides the following hugetlb-related fixes to the recent stacked
    shm files changes:
     - Update is_file_hugepages() so it will reconize hugetlb shm segments.
     - get_unmapped_area must be called with the nested file struct to handle
       the sfd->file->f_ops->get_unmapped_area == NULL case.
     - The fsync f_op must be wrapped since it is specified in the hugetlbfs
       f_ops.
    
    This is based on proposed fixes from Eric Biederman that were debugged and
    tested by me.  Without it, attempting to use hugetlb shared memory segments
    on powerpc (and likely ia64) will kill your box.
    
    Signed-off-by: Adam Litke <agl@us.ibm.com>
    Cc: Eric Biederman <ebiederm@xmission.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: William Irwin <bill.irwin@oracle.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 3d0eb7940e9c..4fefbad7096d 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -285,21 +285,41 @@ static int shm_release(struct inode *ino, struct file *file)
 	return 0;
 }
 
-#ifndef CONFIG_MMU
+static int shm_fsync(struct file *file, struct dentry *dentry, int datasync)
+{
+	int (*fsync) (struct file *, struct dentry *, int datasync);
+	struct shm_file_data *sfd = shm_file_data(file);
+	int ret = -EINVAL;
+
+	fsync = sfd->file->f_op->fsync;
+	if (fsync)
+		ret = fsync(sfd->file, sfd->file->f_path.dentry, datasync);
+	return ret;
+}
+
 static unsigned long shm_get_unmapped_area(struct file *file,
 	unsigned long addr, unsigned long len, unsigned long pgoff,
 	unsigned long flags)
 {
 	struct shm_file_data *sfd = shm_file_data(file);
-	return sfd->file->f_op->get_unmapped_area(sfd->file, addr, len, pgoff,
-							flags);
+	return get_unmapped_area(sfd->file, addr, len, pgoff, flags);
+}
+
+int is_file_shm_hugepages(struct file *file)
+{
+	int ret = 0;
+
+	if (file->f_op == &shm_file_operations) {
+		struct shm_file_data *sfd;
+		sfd = shm_file_data(file);
+		ret = is_file_hugepages(sfd->file);
+	}
+	return ret;
 }
-#else
-#define shm_get_unmapped_area NULL
-#endif
 
 static const struct file_operations shm_file_operations = {
 	.mmap		= shm_mmap,
+	.fsync		= shm_fsync,
 	.release	= shm_release,
 	.get_unmapped_area	= shm_get_unmapped_area,
 };

commit de01bad2f5dec2977143aa242e7eba71d11a4363
Author: Adrian Bunk <bunk@stusta.de>
Date:   Wed Feb 28 20:11:01 2007 -0800

    [PATCH] make ipc/shm.c:shm_nopage() static
    
    shm_nopage() can become static.
    
    Signed-off-by: Adrian Bunk <bunk@stusta.de>
    Acked-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index eb57e2254304..3d0eb7940e9c 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -226,8 +226,8 @@ static void shm_close(struct vm_area_struct *vma)
 	mutex_unlock(&shm_ids(ns).mutex);
 }
 
-struct page *shm_nopage(struct vm_area_struct *vma, unsigned long address,
-			int *type)
+static struct page *shm_nopage(struct vm_area_struct *vma,
+			       unsigned long address, int *type)
 {
 	struct file *file = vma->vm_file;
 	struct shm_file_data *sfd = shm_file_data(file);

commit bc56bba8f31bd99f350a5ebfd43d50f411b620c7
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Feb 20 13:57:53 2007 -0800

    [PATCH] shm: make sysv ipc shared memory use stacked files
    
    The current ipc shared memory code runs into several problems because it
    does not quite use files like the rest of the kernel.  With the option of
    backing ipc shared memory with either hugetlbfs or ordinary shared memory
    the problems got worse.  With the added support for ipc namespaces things
    behaved so unexpected that we now have several bad namespace reference
    counting bugs when using what appears at first glance to be a reasonable
    idiom.
    
    So to attack these problems and hopefully make the code more maintainable
    this patch simply uses the files provided by other parts of the kernel and
    builds it's own files out of them.  The shm files are allocated in do_shmat
    and freed when their reference count drops to zero with their last unmap.
    The file and vm operations that we don't want to implement or we don't
    implement completely we just delegate to the operations of our backing
    file.
    
    This means that we now get an accurate shm_nattch count for we have a
    hugetlbfs inode for backing store, and the shm accounting of last attach
    and last detach time work as well.
    
    This means that getting a reference to the ipc namespace when we create the
    file and dropping the referenece in the release method is now safe and
    correct.
    
    This means we no longer need a special case for clearing VM_MAYWRITE
    as our file descriptor now only has write permissions when we have
    requested write access when calling shmat.  Although VM_SHARED is now
    cleared as well which I believe is harmless and is mostly likely a
    minor bug fix.
    
    By using the same set of operations for both the hugetlb case and regular
    shared memory case shmdt is not simplified and made slightly more correct
    as now the test "vma->vm_ops == &shm_vm_ops" is 100% accurate in spotting
    all shared memory regions generated from sysvipc shared memory.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Michal Piotrowski <michal.k.k.piotrowski@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 5bb617f6306e..eb57e2254304 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -37,11 +37,21 @@
 #include <linux/seq_file.h>
 #include <linux/mutex.h>
 #include <linux/nsproxy.h>
+#include <linux/mount.h>
 
 #include <asm/uaccess.h>
 
 #include "util.h"
 
+struct shm_file_data {
+	int id;
+	struct ipc_namespace *ns;
+	struct file *file;
+	const struct vm_operations_struct *vm_ops;
+};
+
+#define shm_file_data(file) (*((struct shm_file_data **)&(file)->private_data))
+
 static const struct file_operations shm_file_operations;
 static struct vm_operations_struct shm_vm_ops;
 
@@ -60,8 +70,8 @@ static struct ipc_ids init_shm_ids;
 
 static int newseg (struct ipc_namespace *ns, key_t key,
 		int shmflg, size_t size);
-static void shm_open (struct vm_area_struct *shmd);
-static void shm_close (struct vm_area_struct *shmd);
+static void shm_open(struct vm_area_struct *vma);
+static void shm_close(struct vm_area_struct *vma);
 static void shm_destroy (struct ipc_namespace *ns, struct shmid_kernel *shp);
 #ifdef CONFIG_PROC_FS
 static int sysvipc_shm_proc_show(struct seq_file *s, void *it);
@@ -150,11 +160,14 @@ static inline int shm_addid(struct ipc_namespace *ns, struct shmid_kernel *shp)
 
 
 
-static inline void shm_inc(struct ipc_namespace *ns, int id)
+/* This is called by fork, once for every shm attach. */
+static void shm_open(struct vm_area_struct *vma)
 {
+	struct file *file = vma->vm_file;
+	struct shm_file_data *sfd = shm_file_data(file);
 	struct shmid_kernel *shp;
 
-	shp = shm_lock(ns, id);
+	shp = shm_lock(sfd->ns, sfd->id);
 	BUG_ON(!shp);
 	shp->shm_atim = get_seconds();
 	shp->shm_lprid = current->tgid;
@@ -162,15 +175,6 @@ static inline void shm_inc(struct ipc_namespace *ns, int id)
 	shm_unlock(shp);
 }
 
-#define shm_file_ns(file) (*((struct ipc_namespace **)&(file)->private_data))
-
-/* This is called by fork, once for every shm attach. */
-static void shm_open(struct vm_area_struct *shmd)
-{
-	shm_inc(shm_file_ns(shmd->vm_file),
-			shmd->vm_file->f_path.dentry->d_inode->i_ino);
-}
-
 /*
  * shm_destroy - free the struct shmid_kernel
  *
@@ -195,23 +199,21 @@ static void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)
 }
 
 /*
- * remove the attach descriptor shmd.
+ * remove the attach descriptor vma.
  * free memory for segment if it is marked destroyed.
  * The descriptor has already been removed from the current->mm->mmap list
  * and will later be kfree()d.
  */
-static void shm_close (struct vm_area_struct *shmd)
+static void shm_close(struct vm_area_struct *vma)
 {
-	struct file * file = shmd->vm_file;
-	int id = file->f_path.dentry->d_inode->i_ino;
+	struct file * file = vma->vm_file;
+	struct shm_file_data *sfd = shm_file_data(file);
 	struct shmid_kernel *shp;
-	struct ipc_namespace *ns;
-
-	ns = shm_file_ns(file);
+	struct ipc_namespace *ns = sfd->ns;
 
 	mutex_lock(&shm_ids(ns).mutex);
 	/* remove from the list of attaches of the shm segment */
-	shp = shm_lock(ns, id);
+	shp = shm_lock(ns, sfd->id);
 	BUG_ON(!shp);
 	shp->shm_lprid = current->tgid;
 	shp->shm_dtim = get_seconds();
@@ -224,46 +226,91 @@ static void shm_close (struct vm_area_struct *shmd)
 	mutex_unlock(&shm_ids(ns).mutex);
 }
 
+struct page *shm_nopage(struct vm_area_struct *vma, unsigned long address,
+			int *type)
+{
+	struct file *file = vma->vm_file;
+	struct shm_file_data *sfd = shm_file_data(file);
+
+	return sfd->vm_ops->nopage(vma, address, type);
+}
+
+#ifdef CONFIG_NUMA
+int shm_set_policy(struct vm_area_struct *vma, struct mempolicy *new)
+{
+	struct file *file = vma->vm_file;
+	struct shm_file_data *sfd = shm_file_data(file);
+	int err = 0;
+	if (sfd->vm_ops->set_policy)
+		err = sfd->vm_ops->set_policy(vma, new);
+	return err;
+}
+
+struct mempolicy *shm_get_policy(struct vm_area_struct *vma, unsigned long addr)
+{
+	struct file *file = vma->vm_file;
+	struct shm_file_data *sfd = shm_file_data(file);
+	struct mempolicy *pol = NULL;
+
+	if (sfd->vm_ops->get_policy)
+		pol = sfd->vm_ops->get_policy(vma, addr);
+	else
+		pol = vma->vm_policy;
+	return pol;
+}
+#endif
+
 static int shm_mmap(struct file * file, struct vm_area_struct * vma)
 {
+	struct shm_file_data *sfd = shm_file_data(file);
 	int ret;
 
-	ret = shmem_mmap(file, vma);
-	if (ret == 0) {
-		vma->vm_ops = &shm_vm_ops;
-		if (!(vma->vm_flags & VM_WRITE))
-			vma->vm_flags &= ~VM_MAYWRITE;
-		shm_inc(shm_file_ns(file), file->f_path.dentry->d_inode->i_ino);
-	}
+	ret = sfd->file->f_op->mmap(sfd->file, vma);
+	if (ret != 0)
+		return ret;
+	sfd->vm_ops = vma->vm_ops;
+	vma->vm_ops = &shm_vm_ops;
+	shm_open(vma);
 
 	return ret;
 }
 
 static int shm_release(struct inode *ino, struct file *file)
 {
-	struct ipc_namespace *ns;
+	struct shm_file_data *sfd = shm_file_data(file);
 
-	ns = shm_file_ns(file);
-	put_ipc_ns(ns);
-	shm_file_ns(file) = NULL;
+	put_ipc_ns(sfd->ns);
+	shm_file_data(file) = NULL;
+	kfree(sfd);
 	return 0;
 }
 
+#ifndef CONFIG_MMU
+static unsigned long shm_get_unmapped_area(struct file *file,
+	unsigned long addr, unsigned long len, unsigned long pgoff,
+	unsigned long flags)
+{
+	struct shm_file_data *sfd = shm_file_data(file);
+	return sfd->file->f_op->get_unmapped_area(sfd->file, addr, len, pgoff,
+							flags);
+}
+#else
+#define shm_get_unmapped_area NULL
+#endif
+
 static const struct file_operations shm_file_operations = {
 	.mmap		= shm_mmap,
 	.release	= shm_release,
-#ifndef CONFIG_MMU
-	.get_unmapped_area = shmem_get_unmapped_area,
-#endif
+	.get_unmapped_area	= shm_get_unmapped_area,
 };
 
 static struct vm_operations_struct shm_vm_ops = {
 	.open	= shm_open,	/* callback for a new vm-area open */
 	.close	= shm_close,	/* callback for when the vm-area is released */
-	.nopage	= shmem_nopage,
-#if defined(CONFIG_NUMA) && defined(CONFIG_SHMEM)
-	.set_policy = shmem_set_policy,
-	.get_policy = shmem_get_policy,
+	.nopage	= shm_nopage,
+#if defined(CONFIG_NUMA)
+	.set_policy = shm_set_policy,
+	.get_policy = shm_get_policy,
 #endif
 };
 
@@ -330,13 +377,6 @@ static int newseg (struct ipc_namespace *ns, key_t key, int shmflg, size_t size)
 	shp->shm_nattch = 0;
 	shp->id = shm_buildid(ns, id, shp->shm_perm.seq);
 	shp->shm_file = file;
-	file->f_path.dentry->d_inode->i_ino = shp->id;
-
-	shm_file_ns(file) = get_ipc_ns(ns);
-
-	/* Hugetlb ops would have already been assigned. */
-	if (!(shmflg & SHM_HUGETLB))
-		file->f_op = &shm_file_operations;
 
 	ns->shm_tot += numpages;
 	shm_unlock(shp);
@@ -607,10 +647,7 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		tbuf.shm_ctime	= shp->shm_ctim;
 		tbuf.shm_cpid	= shp->shm_cprid;
 		tbuf.shm_lpid	= shp->shm_lprid;
-		if (!is_file_hugepages(shp->shm_file))
-			tbuf.shm_nattch	= shp->shm_nattch;
-		else
-			tbuf.shm_nattch = file_count(shp->shm_file) - 1;
+		tbuf.shm_nattch	= shp->shm_nattch;
 		shm_unlock(shp);
 		if(copy_shmid_to_user (buf, &tbuf, version))
 			err = -EFAULT;
@@ -779,13 +816,16 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	unsigned long flags;
 	unsigned long prot;
 	int acc_mode;
-	void *user_addr;
+	unsigned long user_addr;
 	struct ipc_namespace *ns;
+	struct shm_file_data *sfd;
+	struct path path;
+	mode_t f_mode;
 
-	if (shmid < 0) {
-		err = -EINVAL;
+	err = -EINVAL;
+	if (shmid < 0)
 		goto out;
-	} else if ((addr = (ulong)shmaddr)) {
+	else if ((addr = (ulong)shmaddr)) {
 		if (addr & (SHMLBA-1)) {
 			if (shmflg & SHM_RND)
 				addr &= ~(SHMLBA-1);	   /* round down */
@@ -793,12 +833,12 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 #ifndef __ARCH_FORCE_SHMLBA
 				if (addr & ~PAGE_MASK)
 #endif
-					return -EINVAL;
+					goto out;
 		}
 		flags = MAP_SHARED | MAP_FIXED;
 	} else {
 		if ((shmflg & SHM_REMAP))
-			return -EINVAL;
+			goto out;
 
 		flags = MAP_SHARED;
 	}
@@ -806,9 +846,11 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	if (shmflg & SHM_RDONLY) {
 		prot = PROT_READ;
 		acc_mode = S_IRUGO;
+		f_mode = FMODE_READ;
 	} else {
 		prot = PROT_READ | PROT_WRITE;
 		acc_mode = S_IRUGO | S_IWUGO;
+		f_mode = FMODE_READ | FMODE_WRITE;
 	}
 	if (shmflg & SHM_EXEC) {
 		prot |= PROT_EXEC;
@@ -821,35 +863,50 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	 */
 	ns = current->nsproxy->ipc_ns;
 	shp = shm_lock(ns, shmid);
-	if(shp == NULL) {
-		err = -EINVAL;
+	if(shp == NULL)
 		goto out;
-	}
+
 	err = shm_checkid(ns, shp,shmid);
-	if (err) {
-		shm_unlock(shp);
-		goto out;
-	}
-	if (ipcperms(&shp->shm_perm, acc_mode)) {
-		shm_unlock(shp);
-		err = -EACCES;
-		goto out;
-	}
+	if (err)
+		goto out_unlock;
+
+	err = -EACCES;
+	if (ipcperms(&shp->shm_perm, acc_mode))
+		goto out_unlock;
 
 	err = security_shm_shmat(shp, shmaddr, shmflg);
-	if (err) {
-		shm_unlock(shp);
-		return err;
-	}
-		
-	file = shp->shm_file;
-	size = i_size_read(file->f_path.dentry->d_inode);
+	if (err)
+		goto out_unlock;
+
+	path.dentry = dget(shp->shm_file->f_path.dentry);
+	path.mnt    = mntget(shp->shm_file->f_path.mnt);
 	shp->shm_nattch++;
+	size = i_size_read(path.dentry->d_inode);
 	shm_unlock(shp);
 
+	err = -ENOMEM;
+	sfd = kzalloc(sizeof(*sfd), GFP_KERNEL);
+	if (!sfd)
+		goto out_put_path;
+
+	err = -ENOMEM;
+	file = get_empty_filp();
+	if (!file)
+		goto out_free;
+
+	file->f_op = &shm_file_operations;
+	file->private_data = sfd;
+	file->f_path = path;
+	file->f_mapping = shp->shm_file->f_mapping;
+	file->f_mode = f_mode;
+	sfd->id = shp->id;
+	sfd->ns = get_ipc_ns(ns);
+	sfd->file = shp->shm_file;
+	sfd->vm_ops = NULL;
+
 	down_write(&current->mm->mmap_sem);
 	if (addr && !(shmflg & SHM_REMAP)) {
-		user_addr = ERR_PTR(-EINVAL);
+		err = -EINVAL;
 		if (find_vma_intersection(current->mm, addr, addr + size))
 			goto invalid;
 		/*
@@ -861,11 +918,17 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 			goto invalid;
 	}
 		
-	user_addr = (void*) do_mmap (file, addr, size, prot, flags, 0);
-
+	user_addr = do_mmap (file, addr, size, prot, flags, 0);
+	*raddr = user_addr;
+	err = 0;
+	if (IS_ERR_VALUE(user_addr))
+		err = (long)user_addr;
 invalid:
 	up_write(&current->mm->mmap_sem);
 
+	fput(file);
+
+out_nattch:
 	mutex_lock(&shm_ids(ns).mutex);
 	shp = shm_lock(ns, shmid);
 	BUG_ON(!shp);
@@ -877,12 +940,19 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 		shm_unlock(shp);
 	mutex_unlock(&shm_ids(ns).mutex);
 
-	*raddr = (unsigned long) user_addr;
-	err = 0;
-	if (IS_ERR(user_addr))
-		err = PTR_ERR(user_addr);
 out:
 	return err;
+
+out_unlock:
+	shm_unlock(shp);
+	goto out;
+
+out_free:
+	kfree(sfd);
+out_put_path:
+	dput(path.dentry);
+	mntput(path.mnt);
+	goto out_nattch;
 }
 
 asmlinkage long sys_shmat(int shmid, char __user *shmaddr, int shmflg)
@@ -944,7 +1014,7 @@ asmlinkage long sys_shmdt(char __user *shmaddr)
 		 * a fragment created by mprotect() and/or munmap(), or it
 		 * otherwise it starts at this address with no hassles.
 		 */
-		if ((vma->vm_ops == &shm_vm_ops || is_vm_hugetlb_page(vma)) &&
+		if ((vma->vm_ops == &shm_vm_ops) &&
 			(vma->vm_start - addr)/PAGE_SIZE == vma->vm_pgoff) {
 
 
@@ -973,7 +1043,7 @@ asmlinkage long sys_shmdt(char __user *shmaddr)
 		next = vma->vm_next;
 
 		/* finding a matching vma now does not alter retval */
-		if ((vma->vm_ops == &shm_vm_ops || is_vm_hugetlb_page(vma)) &&
+		if ((vma->vm_ops == &shm_vm_ops) &&
 			(vma->vm_start - addr)/PAGE_SIZE == vma->vm_pgoff)
 
 			do_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start);
@@ -1004,7 +1074,7 @@ static int sysvipc_shm_proc_show(struct seq_file *s, void *it)
 			  shp->shm_segsz,
 			  shp->shm_cprid,
 			  shp->shm_lprid,
-			  is_file_hugepages(shp->shm_file) ? (file_count(shp->shm_file) - 1) : shp->shm_nattch,
+			  shp->shm_nattch,
 			  shp->shm_perm.uid,
 			  shp->shm_perm.gid,
 			  shp->shm_perm.cuid,

commit 9a32144e9d7b4e21341174b1a83b82a82353be86
Author: Arjan van de Ven <arjan@linux.intel.com>
Date:   Mon Feb 12 00:55:35 2007 -0800

    [PATCH] mark struct file_operations const 7
    
    Many struct file_operations in the kernel can be "const".  Marking them const
    moves these to the .rodata section, which avoids false sharing with potential
    dirty data.  In addition it'll catch accidental writes at compile time to
    these shared resources.
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index f8e10a25ad7d..5bb617f6306e 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -42,7 +42,7 @@
 
 #include "util.h"
 
-static struct file_operations shm_file_operations;
+static const struct file_operations shm_file_operations;
 static struct vm_operations_struct shm_vm_ops;
 
 static struct ipc_ids init_shm_ids;
@@ -249,7 +249,7 @@ static int shm_release(struct inode *ino, struct file *file)
 	return 0;
 }
 
-static struct file_operations shm_file_operations = {
+static const struct file_operations shm_file_operations = {
 	.mmap		= shm_mmap,
 	.release	= shm_release,
 #ifndef CONFIG_MMU

commit f66d45e99eb7ca91822c3e3f6d7a98843c9626cb
Author: Guy Streeter <guy.streeter@gmail.com>
Date:   Tue Jan 23 12:20:04 2007 -0600

    [PATCH] correct sys_shmget allocation check
    
    As written, sys_shmget will return ENOSPC when one page is still
    available for allocation. This patch corrects the test.
    
    Signed-off-by: Guy Streeter <guy.streeter+lkml@gmail.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    --

diff --git a/ipc/shm.c b/ipc/shm.c
index 6d16bb6de7d2..f8e10a25ad7d 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -279,7 +279,7 @@ static int newseg (struct ipc_namespace *ns, key_t key, int shmflg, size_t size)
 	if (size < SHMMIN || size > ns->shm_ctlmax)
 		return -EINVAL;
 
-	if (ns->shm_tot + numpages >= ns->shm_ctlall)
+	if (ns->shm_tot + numpages > ns->shm_ctlall)
 		return -ENOSPC;
 
 	shp = ipc_rcu_alloc(sizeof(*shp));

commit 6d63079adde80bb549528371e6407f88e9d27bc3
Author: Josef Sipek <jsipek@fsl.cs.sunysb.edu>
Date:   Fri Dec 8 02:37:11 2006 -0800

    [PATCH] struct path: convert ipc
    
    Signed-off-by: Josef Sipek <jsipek@fsl.cs.sunysb.edu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index d1198dd07a1a..6d16bb6de7d2 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -168,7 +168,7 @@ static inline void shm_inc(struct ipc_namespace *ns, int id)
 static void shm_open(struct vm_area_struct *shmd)
 {
 	shm_inc(shm_file_ns(shmd->vm_file),
-			shmd->vm_file->f_dentry->d_inode->i_ino);
+			shmd->vm_file->f_path.dentry->d_inode->i_ino);
 }
 
 /*
@@ -187,7 +187,7 @@ static void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)
 	if (!is_file_hugepages(shp->shm_file))
 		shmem_lock(shp->shm_file, 0, shp->mlock_user);
 	else
-		user_shm_unlock(shp->shm_file->f_dentry->d_inode->i_size,
+		user_shm_unlock(shp->shm_file->f_path.dentry->d_inode->i_size,
 						shp->mlock_user);
 	fput (shp->shm_file);
 	security_shm_free(shp);
@@ -203,7 +203,7 @@ static void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)
 static void shm_close (struct vm_area_struct *shmd)
 {
 	struct file * file = shmd->vm_file;
-	int id = file->f_dentry->d_inode->i_ino;
+	int id = file->f_path.dentry->d_inode->i_ino;
 	struct shmid_kernel *shp;
 	struct ipc_namespace *ns;
 
@@ -233,7 +233,7 @@ static int shm_mmap(struct file * file, struct vm_area_struct * vma)
 		vma->vm_ops = &shm_vm_ops;
 		if (!(vma->vm_flags & VM_WRITE))
 			vma->vm_flags &= ~VM_MAYWRITE;
-		shm_inc(shm_file_ns(file), file->f_dentry->d_inode->i_ino);
+		shm_inc(shm_file_ns(file), file->f_path.dentry->d_inode->i_ino);
 	}
 
 	return ret;
@@ -330,7 +330,7 @@ static int newseg (struct ipc_namespace *ns, key_t key, int shmflg, size_t size)
 	shp->shm_nattch = 0;
 	shp->id = shm_buildid(ns, id, shp->shm_perm.seq);
 	shp->shm_file = file;
-	file->f_dentry->d_inode->i_ino = shp->id;
+	file->f_path.dentry->d_inode->i_ino = shp->id;
 
 	shm_file_ns(file) = get_ipc_ns(ns);
 
@@ -495,7 +495,7 @@ static void shm_get_stat(struct ipc_namespace *ns, unsigned long *rss,
 		if(!shp)
 			continue;
 
-		inode = shp->shm_file->f_dentry->d_inode;
+		inode = shp->shm_file->f_path.dentry->d_inode;
 
 		if (is_file_hugepages(shp->shm_file)) {
 			struct address_space *mapping = inode->i_mapping;
@@ -843,7 +843,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	}
 		
 	file = shp->shm_file;
-	size = i_size_read(file->f_dentry->d_inode);
+	size = i_size_read(file->f_path.dentry->d_inode);
 	shp->shm_nattch++;
 	shm_unlock(shp);
 
@@ -948,7 +948,7 @@ asmlinkage long sys_shmdt(char __user *shmaddr)
 			(vma->vm_start - addr)/PAGE_SIZE == vma->vm_pgoff) {
 
 
-			size = vma->vm_file->f_dentry->d_inode->i_size;
+			size = vma->vm_file->f_path.dentry->d_inode->i_size;
 			do_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start);
 			/*
 			 * We discovered the size of the shm segment, so

commit c7e12b838989b0e432c7a1cdf1e6c6fd936007f6
Author: Pavel Emelianov <xemul@openvz.org>
Date:   Thu Nov 2 22:07:03 2006 -0800

    [PATCH] Fix ipc entries removal
    
    Fix two issuses related to ipc_ids->entries freeing.
    
    1. When freeing ipc namespace we need to free entries allocated
       with ipc_init_ids().
    
    2. When removing old entries in grow_ary() ipc_rcu_putref()
       may be called on entries set to &ids->nullentry earlier in
       ipc_init_ids().
       This is almost impossible without namespaces, but with
       them this situation becomes possible.
    
    Found during OpenVZ testing after obvious leaks in beancounters.
    
    Signed-off-by: Pavel Emelianov <xemul@openvz.org>
    Cc: Kirill Korotaev <dev@openvz.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index bfbd317ec11c..d1198dd07a1a 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -116,6 +116,7 @@ void shm_exit_ns(struct ipc_namespace *ns)
 	}
 	mutex_unlock(&shm_ids(ns).mutex);
 
+	ipc_fini_ids(ns->ids[IPC_SHM_IDS]);
 	kfree(ns->ids[IPC_SHM_IDS]);
 	ns->ids[IPC_SHM_IDS] = NULL;
 }

commit 4e9823111bdc76127b17fc70dc57f584fd7dd34c
Author: Kirill Korotaev <dev@openvz.org>
Date:   Mon Oct 2 02:18:22 2006 -0700

    [PATCH] IPC namespace - shm
    
    IPC namespace support for IPC shm code.
    
    Signed-off-by: Pavel Emelianiov <xemul@openvz.org>
    Signed-off-by: Kirill Korotaev <dev@openvz.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 940b0c9b13aa..bfbd317ec11c 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -15,6 +15,10 @@
  *
  * support for audit of ipc object properties and permission changes
  * Dustin Kirkland <dustin.kirkland@us.ibm.com>
+ *
+ * namespaces support
+ * OpenVZ, SWsoft Inc.
+ * Pavel Emelianov <xemul@openvz.org>
  */
 
 #include <linux/slab.h>
@@ -32,6 +36,7 @@
 #include <linux/ptrace.h>
 #include <linux/seq_file.h>
 #include <linux/mutex.h>
+#include <linux/nsproxy.h>
 
 #include <asm/uaccess.h>
 
@@ -40,59 +45,115 @@
 static struct file_operations shm_file_operations;
 static struct vm_operations_struct shm_vm_ops;
 
-static struct ipc_ids shm_ids;
+static struct ipc_ids init_shm_ids;
+
+#define shm_ids(ns)	(*((ns)->ids[IPC_SHM_IDS]))
 
-#define shm_lock(id)	((struct shmid_kernel*)ipc_lock(&shm_ids,id))
-#define shm_unlock(shp)	ipc_unlock(&(shp)->shm_perm)
-#define shm_get(id)	((struct shmid_kernel*)ipc_get(&shm_ids,id))
-#define shm_buildid(id, seq) \
-	ipc_buildid(&shm_ids, id, seq)
+#define shm_lock(ns, id)		\
+	((struct shmid_kernel*)ipc_lock(&shm_ids(ns),id))
+#define shm_unlock(shp)			\
+	ipc_unlock(&(shp)->shm_perm)
+#define shm_get(ns, id)			\
+	((struct shmid_kernel*)ipc_get(&shm_ids(ns),id))
+#define shm_buildid(ns, id, seq)	\
+	ipc_buildid(&shm_ids(ns), id, seq)
 
-static int newseg (key_t key, int shmflg, size_t size);
+static int newseg (struct ipc_namespace *ns, key_t key,
+		int shmflg, size_t size);
 static void shm_open (struct vm_area_struct *shmd);
 static void shm_close (struct vm_area_struct *shmd);
+static void shm_destroy (struct ipc_namespace *ns, struct shmid_kernel *shp);
 #ifdef CONFIG_PROC_FS
 static int sysvipc_shm_proc_show(struct seq_file *s, void *it);
 #endif
 
-size_t	shm_ctlmax = SHMMAX;
-size_t 	shm_ctlall = SHMALL;
-int 	shm_ctlmni = SHMMNI;
+static void __ipc_init __shm_init_ns(struct ipc_namespace *ns, struct ipc_ids *ids)
+{
+	ns->ids[IPC_SHM_IDS] = ids;
+	ns->shm_ctlmax = SHMMAX;
+	ns->shm_ctlall = SHMALL;
+	ns->shm_ctlmni = SHMMNI;
+	ns->shm_tot = 0;
+	ipc_init_ids(ids, 1);
+}
+
+static void do_shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *shp)
+{
+	if (shp->shm_nattch){
+		shp->shm_perm.mode |= SHM_DEST;
+		/* Do not find it any more */
+		shp->shm_perm.key = IPC_PRIVATE;
+		shm_unlock(shp);
+	} else
+		shm_destroy(ns, shp);
+}
+
+#ifdef CONFIG_IPC_NS
+int shm_init_ns(struct ipc_namespace *ns)
+{
+	struct ipc_ids *ids;
+
+	ids = kmalloc(sizeof(struct ipc_ids), GFP_KERNEL);
+	if (ids == NULL)
+		return -ENOMEM;
 
-static int shm_tot; /* total number of shared memory pages */
+	__shm_init_ns(ns, ids);
+	return 0;
+}
+
+void shm_exit_ns(struct ipc_namespace *ns)
+{
+	int i;
+	struct shmid_kernel *shp;
+
+	mutex_lock(&shm_ids(ns).mutex);
+	for (i = 0; i <= shm_ids(ns).max_id; i++) {
+		shp = shm_lock(ns, i);
+		if (shp == NULL)
+			continue;
+
+		do_shm_rmid(ns, shp);
+	}
+	mutex_unlock(&shm_ids(ns).mutex);
+
+	kfree(ns->ids[IPC_SHM_IDS]);
+	ns->ids[IPC_SHM_IDS] = NULL;
+}
+#endif
 
 void __init shm_init (void)
 {
-	ipc_init_ids(&shm_ids, 1);
+	__shm_init_ns(&init_ipc_ns, &init_shm_ids);
 	ipc_init_proc_interface("sysvipc/shm",
 				"       key      shmid perms       size  cpid  lpid nattch   uid   gid  cuid  cgid      atime      dtime      ctime\n",
-				&shm_ids,
-				sysvipc_shm_proc_show);
+				IPC_SHM_IDS, sysvipc_shm_proc_show);
 }
 
-static inline int shm_checkid(struct shmid_kernel *s, int id)
+static inline int shm_checkid(struct ipc_namespace *ns,
+		struct shmid_kernel *s, int id)
 {
-	if (ipc_checkid(&shm_ids,&s->shm_perm,id))
+	if (ipc_checkid(&shm_ids(ns), &s->shm_perm, id))
 		return -EIDRM;
 	return 0;
 }
 
-static inline struct shmid_kernel *shm_rmid(int id)
+static inline struct shmid_kernel *shm_rmid(struct ipc_namespace *ns, int id)
 {
-	return (struct shmid_kernel *)ipc_rmid(&shm_ids,id);
+	return (struct shmid_kernel *)ipc_rmid(&shm_ids(ns), id);
 }
 
-static inline int shm_addid(struct shmid_kernel *shp)
+static inline int shm_addid(struct ipc_namespace *ns, struct shmid_kernel *shp)
 {
-	return ipc_addid(&shm_ids, &shp->shm_perm, shm_ctlmni);
+	return ipc_addid(&shm_ids(ns), &shp->shm_perm, ns->shm_ctlmni);
 }
 
 
 
-static inline void shm_inc (int id) {
+static inline void shm_inc(struct ipc_namespace *ns, int id)
+{
 	struct shmid_kernel *shp;
 
-	shp = shm_lock(id);
+	shp = shm_lock(ns, id);
 	BUG_ON(!shp);
 	shp->shm_atim = get_seconds();
 	shp->shm_lprid = current->tgid;
@@ -100,10 +161,13 @@ static inline void shm_inc (int id) {
 	shm_unlock(shp);
 }
 
+#define shm_file_ns(file) (*((struct ipc_namespace **)&(file)->private_data))
+
 /* This is called by fork, once for every shm attach. */
-static void shm_open (struct vm_area_struct *shmd)
+static void shm_open(struct vm_area_struct *shmd)
 {
-	shm_inc (shmd->vm_file->f_dentry->d_inode->i_ino);
+	shm_inc(shm_file_ns(shmd->vm_file),
+			shmd->vm_file->f_dentry->d_inode->i_ino);
 }
 
 /*
@@ -114,10 +178,10 @@ static void shm_open (struct vm_area_struct *shmd)
  * It has to be called with shp and shm_ids.mutex locked,
  * but returns with shp unlocked and freed.
  */
-static void shm_destroy (struct shmid_kernel *shp)
+static void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)
 {
-	shm_tot -= (shp->shm_segsz + PAGE_SIZE - 1) >> PAGE_SHIFT;
-	shm_rmid (shp->id);
+	ns->shm_tot -= (shp->shm_segsz + PAGE_SIZE - 1) >> PAGE_SHIFT;
+	shm_rmid(ns, shp->id);
 	shm_unlock(shp);
 	if (!is_file_hugepages(shp->shm_file))
 		shmem_lock(shp->shm_file, 0, shp->mlock_user);
@@ -140,20 +204,23 @@ static void shm_close (struct vm_area_struct *shmd)
 	struct file * file = shmd->vm_file;
 	int id = file->f_dentry->d_inode->i_ino;
 	struct shmid_kernel *shp;
+	struct ipc_namespace *ns;
 
-	mutex_lock(&shm_ids.mutex);
+	ns = shm_file_ns(file);
+
+	mutex_lock(&shm_ids(ns).mutex);
 	/* remove from the list of attaches of the shm segment */
-	shp = shm_lock(id);
+	shp = shm_lock(ns, id);
 	BUG_ON(!shp);
 	shp->shm_lprid = current->tgid;
 	shp->shm_dtim = get_seconds();
 	shp->shm_nattch--;
 	if(shp->shm_nattch == 0 &&
 	   shp->shm_perm.mode & SHM_DEST)
-		shm_destroy (shp);
+		shm_destroy(ns, shp);
 	else
 		shm_unlock(shp);
-	mutex_unlock(&shm_ids.mutex);
+	mutex_unlock(&shm_ids(ns).mutex);
 }
 
 static int shm_mmap(struct file * file, struct vm_area_struct * vma)
@@ -165,14 +232,25 @@ static int shm_mmap(struct file * file, struct vm_area_struct * vma)
 		vma->vm_ops = &shm_vm_ops;
 		if (!(vma->vm_flags & VM_WRITE))
 			vma->vm_flags &= ~VM_MAYWRITE;
-		shm_inc(file->f_dentry->d_inode->i_ino);
+		shm_inc(shm_file_ns(file), file->f_dentry->d_inode->i_ino);
 	}
 
 	return ret;
 }
 
+static int shm_release(struct inode *ino, struct file *file)
+{
+	struct ipc_namespace *ns;
+
+	ns = shm_file_ns(file);
+	put_ipc_ns(ns);
+	shm_file_ns(file) = NULL;
+	return 0;
+}
+
 static struct file_operations shm_file_operations = {
-	.mmap	= shm_mmap,
+	.mmap		= shm_mmap,
+	.release	= shm_release,
 #ifndef CONFIG_MMU
 	.get_unmapped_area = shmem_get_unmapped_area,
 #endif
@@ -188,7 +266,7 @@ static struct vm_operations_struct shm_vm_ops = {
 #endif
 };
 
-static int newseg (key_t key, int shmflg, size_t size)
+static int newseg (struct ipc_namespace *ns, key_t key, int shmflg, size_t size)
 {
 	int error;
 	struct shmid_kernel *shp;
@@ -197,10 +275,10 @@ static int newseg (key_t key, int shmflg, size_t size)
 	char name[13];
 	int id;
 
-	if (size < SHMMIN || size > shm_ctlmax)
+	if (size < SHMMIN || size > ns->shm_ctlmax)
 		return -EINVAL;
 
-	if (shm_tot + numpages >= shm_ctlall)
+	if (ns->shm_tot + numpages >= ns->shm_ctlall)
 		return -ENOSPC;
 
 	shp = ipc_rcu_alloc(sizeof(*shp));
@@ -239,7 +317,7 @@ static int newseg (key_t key, int shmflg, size_t size)
 		goto no_file;
 
 	error = -ENOSPC;
-	id = shm_addid(shp);
+	id = shm_addid(ns, shp);
 	if(id == -1) 
 		goto no_id;
 
@@ -249,15 +327,17 @@ static int newseg (key_t key, int shmflg, size_t size)
 	shp->shm_ctim = get_seconds();
 	shp->shm_segsz = size;
 	shp->shm_nattch = 0;
-	shp->id = shm_buildid(id,shp->shm_perm.seq);
+	shp->id = shm_buildid(ns, id, shp->shm_perm.seq);
 	shp->shm_file = file;
 	file->f_dentry->d_inode->i_ino = shp->id;
 
+	shm_file_ns(file) = get_ipc_ns(ns);
+
 	/* Hugetlb ops would have already been assigned. */
 	if (!(shmflg & SHM_HUGETLB))
 		file->f_op = &shm_file_operations;
 
-	shm_tot += numpages;
+	ns->shm_tot += numpages;
 	shm_unlock(shp);
 	return shp->id;
 
@@ -273,33 +353,36 @@ asmlinkage long sys_shmget (key_t key, size_t size, int shmflg)
 {
 	struct shmid_kernel *shp;
 	int err, id = 0;
+	struct ipc_namespace *ns;
+
+	ns = current->nsproxy->ipc_ns;
 
-	mutex_lock(&shm_ids.mutex);
+	mutex_lock(&shm_ids(ns).mutex);
 	if (key == IPC_PRIVATE) {
-		err = newseg(key, shmflg, size);
-	} else if ((id = ipc_findkey(&shm_ids, key)) == -1) {
+		err = newseg(ns, key, shmflg, size);
+	} else if ((id = ipc_findkey(&shm_ids(ns), key)) == -1) {
 		if (!(shmflg & IPC_CREAT))
 			err = -ENOENT;
 		else
-			err = newseg(key, shmflg, size);
+			err = newseg(ns, key, shmflg, size);
 	} else if ((shmflg & IPC_CREAT) && (shmflg & IPC_EXCL)) {
 		err = -EEXIST;
 	} else {
-		shp = shm_lock(id);
+		shp = shm_lock(ns, id);
 		BUG_ON(shp==NULL);
 		if (shp->shm_segsz < size)
 			err = -EINVAL;
 		else if (ipcperms(&shp->shm_perm, shmflg))
 			err = -EACCES;
 		else {
-			int shmid = shm_buildid(id, shp->shm_perm.seq);
+			int shmid = shm_buildid(ns, id, shp->shm_perm.seq);
 			err = security_shm_associate(shp, shmflg);
 			if (!err)
 				err = shmid;
 		}
 		shm_unlock(shp);
 	}
-	mutex_unlock(&shm_ids.mutex);
+	mutex_unlock(&shm_ids(ns).mutex);
 
 	return err;
 }
@@ -395,18 +478,19 @@ static inline unsigned long copy_shminfo_to_user(void __user *buf, struct shminf
 	}
 }
 
-static void shm_get_stat(unsigned long *rss, unsigned long *swp) 
+static void shm_get_stat(struct ipc_namespace *ns, unsigned long *rss,
+		unsigned long *swp)
 {
 	int i;
 
 	*rss = 0;
 	*swp = 0;
 
-	for (i = 0; i <= shm_ids.max_id; i++) {
+	for (i = 0; i <= shm_ids(ns).max_id; i++) {
 		struct shmid_kernel *shp;
 		struct inode *inode;
 
-		shp = shm_get(i);
+		shp = shm_get(ns, i);
 		if(!shp)
 			continue;
 
@@ -430,6 +514,7 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 	struct shm_setbuf setbuf;
 	struct shmid_kernel *shp;
 	int err, version;
+	struct ipc_namespace *ns;
 
 	if (cmd < 0 || shmid < 0) {
 		err = -EINVAL;
@@ -437,6 +522,7 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 	}
 
 	version = ipc_parse_version(&cmd);
+	ns = current->nsproxy->ipc_ns;
 
 	switch (cmd) { /* replace with proc interface ? */
 	case IPC_INFO:
@@ -448,15 +534,15 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 			return err;
 
 		memset(&shminfo,0,sizeof(shminfo));
-		shminfo.shmmni = shminfo.shmseg = shm_ctlmni;
-		shminfo.shmmax = shm_ctlmax;
-		shminfo.shmall = shm_ctlall;
+		shminfo.shmmni = shminfo.shmseg = ns->shm_ctlmni;
+		shminfo.shmmax = ns->shm_ctlmax;
+		shminfo.shmall = ns->shm_ctlall;
 
 		shminfo.shmmin = SHMMIN;
 		if(copy_shminfo_to_user (buf, &shminfo, version))
 			return -EFAULT;
 		/* reading a integer is always atomic */
-		err= shm_ids.max_id;
+		err= shm_ids(ns).max_id;
 		if(err<0)
 			err = 0;
 		goto out;
@@ -470,14 +556,14 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 			return err;
 
 		memset(&shm_info,0,sizeof(shm_info));
-		mutex_lock(&shm_ids.mutex);
-		shm_info.used_ids = shm_ids.in_use;
-		shm_get_stat (&shm_info.shm_rss, &shm_info.shm_swp);
-		shm_info.shm_tot = shm_tot;
+		mutex_lock(&shm_ids(ns).mutex);
+		shm_info.used_ids = shm_ids(ns).in_use;
+		shm_get_stat (ns, &shm_info.shm_rss, &shm_info.shm_swp);
+		shm_info.shm_tot = ns->shm_tot;
 		shm_info.swap_attempts = 0;
 		shm_info.swap_successes = 0;
-		err = shm_ids.max_id;
-		mutex_unlock(&shm_ids.mutex);
+		err = shm_ids(ns).max_id;
+		mutex_unlock(&shm_ids(ns).mutex);
 		if(copy_to_user (buf, &shm_info, sizeof(shm_info))) {
 			err = -EFAULT;
 			goto out;
@@ -492,17 +578,17 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		struct shmid64_ds tbuf;
 		int result;
 		memset(&tbuf, 0, sizeof(tbuf));
-		shp = shm_lock(shmid);
+		shp = shm_lock(ns, shmid);
 		if(shp==NULL) {
 			err = -EINVAL;
 			goto out;
 		} else if(cmd==SHM_STAT) {
 			err = -EINVAL;
-			if (shmid > shm_ids.max_id)
+			if (shmid > shm_ids(ns).max_id)
 				goto out_unlock;
-			result = shm_buildid(shmid, shp->shm_perm.seq);
+			result = shm_buildid(ns, shmid, shp->shm_perm.seq);
 		} else {
-			err = shm_checkid(shp,shmid);
+			err = shm_checkid(ns, shp,shmid);
 			if(err)
 				goto out_unlock;
 			result = 0;
@@ -534,12 +620,12 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 	case SHM_LOCK:
 	case SHM_UNLOCK:
 	{
-		shp = shm_lock(shmid);
+		shp = shm_lock(ns, shmid);
 		if(shp==NULL) {
 			err = -EINVAL;
 			goto out;
 		}
-		err = shm_checkid(shp,shmid);
+		err = shm_checkid(ns, shp,shmid);
 		if(err)
 			goto out_unlock;
 
@@ -590,12 +676,12 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		 *	Instead we set a destroyed flag, and then blow
 		 *	the name away when the usage hits zero.
 		 */
-		mutex_lock(&shm_ids.mutex);
-		shp = shm_lock(shmid);
+		mutex_lock(&shm_ids(ns).mutex);
+		shp = shm_lock(ns, shmid);
 		err = -EINVAL;
 		if (shp == NULL) 
 			goto out_up;
-		err = shm_checkid(shp, shmid);
+		err = shm_checkid(ns, shp, shmid);
 		if(err)
 			goto out_unlock_up;
 
@@ -614,14 +700,8 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		if (err)
 			goto out_unlock_up;
 
-		if (shp->shm_nattch){
-			shp->shm_perm.mode |= SHM_DEST;
-			/* Do not find it any more */
-			shp->shm_perm.key = IPC_PRIVATE;
-			shm_unlock(shp);
-		} else
-			shm_destroy (shp);
-		mutex_unlock(&shm_ids.mutex);
+		do_shm_rmid(ns, shp);
+		mutex_unlock(&shm_ids(ns).mutex);
 		goto out;
 	}
 
@@ -631,12 +711,12 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 			err = -EFAULT;
 			goto out;
 		}
-		mutex_lock(&shm_ids.mutex);
-		shp = shm_lock(shmid);
+		mutex_lock(&shm_ids(ns).mutex);
+		shp = shm_lock(ns, shmid);
 		err=-EINVAL;
 		if(shp==NULL)
 			goto out_up;
-		err = shm_checkid(shp,shmid);
+		err = shm_checkid(ns, shp,shmid);
 		if(err)
 			goto out_unlock_up;
 		err = audit_ipc_obj(&(shp->shm_perm));
@@ -673,7 +753,7 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 out_unlock_up:
 	shm_unlock(shp);
 out_up:
-	mutex_unlock(&shm_ids.mutex);
+	mutex_unlock(&shm_ids(ns).mutex);
 	goto out;
 out_unlock:
 	shm_unlock(shp);
@@ -699,6 +779,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	unsigned long prot;
 	int acc_mode;
 	void *user_addr;
+	struct ipc_namespace *ns;
 
 	if (shmid < 0) {
 		err = -EINVAL;
@@ -737,12 +818,13 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	 * We cannot rely on the fs check since SYSV IPC does have an
 	 * additional creator id...
 	 */
-	shp = shm_lock(shmid);
+	ns = current->nsproxy->ipc_ns;
+	shp = shm_lock(ns, shmid);
 	if(shp == NULL) {
 		err = -EINVAL;
 		goto out;
 	}
-	err = shm_checkid(shp,shmid);
+	err = shm_checkid(ns, shp,shmid);
 	if (err) {
 		shm_unlock(shp);
 		goto out;
@@ -783,16 +865,16 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 invalid:
 	up_write(&current->mm->mmap_sem);
 
-	mutex_lock(&shm_ids.mutex);
-	shp = shm_lock(shmid);
+	mutex_lock(&shm_ids(ns).mutex);
+	shp = shm_lock(ns, shmid);
 	BUG_ON(!shp);
 	shp->shm_nattch--;
 	if(shp->shm_nattch == 0 &&
 	   shp->shm_perm.mode & SHM_DEST)
-		shm_destroy (shp);
+		shm_destroy(ns, shp);
 	else
 		shm_unlock(shp);
-	mutex_unlock(&shm_ids.mutex);
+	mutex_unlock(&shm_ids(ns).mutex);
 
 	*raddr = (unsigned long) user_addr;
 	err = 0;

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: Jörn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: Jörn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/ipc/shm.c b/ipc/shm.c
index fe7ae73b6981..940b0c9b13aa 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -17,7 +17,6 @@
  * Dustin Kirkland <dustin.kirkland@us.ibm.com>
  */
 
-#include <linux/config.h>
 #include <linux/slab.h>
 #include <linux/mm.h>
 #include <linux/hugetlb.h>

commit 185606fc6a120dbebffa6d06a559c20ec2b20034
Author: Hugh Dickins <hugh@veritas.com>
Date:   Fri Jun 23 02:03:45 2006 -0700

    [PATCH] remove unused o_flags from do_shmat
    
    Remove the unused variable o_flags from do_shmat.
    
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 4f133d24030f..fe7ae73b6981 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -698,7 +698,6 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	int    err;
 	unsigned long flags;
 	unsigned long prot;
-	unsigned long o_flags;
 	int acc_mode;
 	void *user_addr;
 
@@ -725,11 +724,9 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 
 	if (shmflg & SHM_RDONLY) {
 		prot = PROT_READ;
-		o_flags = O_RDONLY;
 		acc_mode = S_IRUGO;
 	} else {
 		prot = PROT_READ | PROT_WRITE;
-		o_flags = O_RDWR;
 		acc_mode = S_IRUGO | S_IWUGO;
 	}
 	if (shmflg & SHM_EXEC) {

commit ac03221a4fdda9bfdabf99bcd129847f20fc1d80
Author: Linda Knippers <linda.knippers@hp.com>
Date:   Tue May 16 22:03:48 2006 -0400

    [PATCH] update of IPC audit record cleanup
    
    The following patch addresses most of the issues with the IPC_SET_PERM
    records as described in:
    https://www.redhat.com/archives/linux-audit/2006-May/msg00010.html
    and addresses the comments I received on the record field names.
    
    To summarize, I made the following changes:
    
    1. Changed sys_msgctl() and semctl_down() so that an IPC_SET_PERM
       record is emitted in the failure case as well as the success case.
       This matches the behavior in sys_shmctl().  I could simplify the
       code in sys_msgctl() and semctl_down() slightly but it would mean
       that in some error cases we could get an IPC_SET_PERM record
       without an IPC record and that seemed odd.
    
    2. No change to the IPC record type, given no feedback on the backward
       compatibility question.
    
    3. Removed the qbytes field from the IPC record.  It wasn't being
       set and when audit_ipc_obj() is called from ipcperms(), the
       information isn't available.  If we want the information in the IPC
       record, more extensive changes will be necessary.  Since it only
       applies to message queues and it isn't really permission related, it
       doesn't seem worth it.
    
    4. Removed the obj field from the IPC_SET_PERM record.  This means that
       the kern_ipc_perm argument is no longer needed.
    
    5. Removed the spaces and renamed the IPC_SET_PERM field names.  Replaced iuid and
       igid fields with ouid and ogid in the IPC record.
    
    I tested this with the lspp.22 kernel on an x86_64 box.  I believe it
    applies cleanly on the latest kernel.
    
    -- ljk
    
    Signed-off-by: Linda Knippers <linda.knippers@hp.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 809896851902..4f133d24030f 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -643,7 +643,7 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		err = audit_ipc_obj(&(shp->shm_perm));
 		if (err)
 			goto out_unlock_up;
-		err = audit_ipc_set_perm(0, setbuf.uid, setbuf.gid, setbuf.mode, &(shp->shm_perm));
+		err = audit_ipc_set_perm(0, setbuf.uid, setbuf.gid, setbuf.mode);
 		if (err)
 			goto out_unlock_up;
 		err=-EPERM;

commit 073115d6b29c7910feaa08241c6484637f5ca958
Author: Steve Grubb <sgrubb@redhat.com>
Date:   Sun Apr 2 17:07:33 2006 -0400

    [PATCH] Rework of IPC auditing
    
    1) The audit_ipc_perms() function has been split into two different
    functions:
            - audit_ipc_obj()
            - audit_ipc_set_perm()
    
    There's a key shift here...  The audit_ipc_obj() collects the uid, gid,
    mode, and SElinux context label of the current ipc object.  This
    audit_ipc_obj() hook is now found in several places.  Most notably, it
    is hooked in ipcperms(), which is called in various places around the
    ipc code permforming a MAC check.  Additionally there are several places
    where *checkid() is used to validate that an operation is being
    performed on a valid object while not necessarily having a nearby
    ipcperms() call.  In these locations, audit_ipc_obj() is called to
    ensure that the information is captured by the audit system.
    
    The audit_set_new_perm() function is called any time the permissions on
    the ipc object changes.  In this case, the NEW permissions are recorded
    (and note that an audit_ipc_obj() call exists just a few lines before
    each instance).
    
    2) Support for an AUDIT_IPC_SET_PERM audit message type.  This allows
    for separate auxiliary audit records for normal operations on an IPC
    object and permissions changes.  Note that the same struct
    audit_aux_data_ipcctl is used and populated, however there are separate
    audit_log_format statements based on the type of the message.  Finally,
    the AUDIT_IPC block of code in audit_free_aux() was extended to handle
    aux messages of this new type.  No more mem leaks I hope ;-)
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 1c2faf62bc73..809896851902 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -13,6 +13,8 @@
  * Shared /dev/zero support, Kanoj Sarcar <kanoj@sgi.com>
  * Move the mm functionality over to mm/shmem.c, Christoph Rohland <cr@sap.com>
  *
+ * support for audit of ipc object properties and permission changes
+ * Dustin Kirkland <dustin.kirkland@us.ibm.com>
  */
 
 #include <linux/config.h>
@@ -542,6 +544,10 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		if(err)
 			goto out_unlock;
 
+		err = audit_ipc_obj(&(shp->shm_perm));
+		if (err)
+			goto out_unlock;
+
 		if (!capable(CAP_IPC_LOCK)) {
 			err = -EPERM;
 			if (current->euid != shp->shm_perm.uid &&
@@ -594,6 +600,10 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		if(err)
 			goto out_unlock_up;
 
+		err = audit_ipc_obj(&(shp->shm_perm));
+		if (err)
+			goto out_unlock_up;
+
 		if (current->euid != shp->shm_perm.uid &&
 		    current->euid != shp->shm_perm.cuid && 
 		    !capable(CAP_SYS_ADMIN)) {
@@ -627,12 +637,15 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		err=-EINVAL;
 		if(shp==NULL)
 			goto out_up;
-		if ((err = audit_ipc_perms(0, setbuf.uid, setbuf.gid,
-					setbuf.mode, &(shp->shm_perm))))
-			goto out_unlock_up;
 		err = shm_checkid(shp,shmid);
 		if(err)
 			goto out_unlock_up;
+		err = audit_ipc_obj(&(shp->shm_perm));
+		if (err)
+			goto out_unlock_up;
+		err = audit_ipc_set_perm(0, setbuf.uid, setbuf.gid, setbuf.mode, &(shp->shm_perm));
+		if (err)
+			goto out_unlock_up;
 		err=-EPERM;
 		if (current->euid != shp->shm_perm.uid &&
 		    current->euid != shp->shm_perm.cuid && 

commit b78b6af66a5fbaf17d7e6bfc32384df5e34408c8
Author: Hugh Dickins <hugh@veritas.com>
Date:   Wed Apr 12 14:34:27 2006 -0700

    [PATCH] shmat: stop mprotect from giving write permission to a readonly attachment (CVE-2006-1524)
    
    I found that all of 2.4 and 2.6 have been letting mprotect give write
    permission to a readonly attachment of shared memory, whether or not IPC
    would give the caller that permission.
    
    SUS says "The behaviour of this function [mprotect] is unspecified if the
    mapping was not established by a call to mmap", but I don't think we can
    interpret that as allowing it to subvert IPC permissions.
    
    I haven't tried 2.2, but the 2.2.26 source looks like it gets it right; and
    the patch below reproduces that behaviour - mprotect cannot be used to add
    write permission to a shared memory segment attached readonly.
    
    This patch is simple, and I'm sure it's what we should have done in 2.4.0:
    if you want to go on to switch write permission on and off with mprotect,
    just don't attach the segment readonly in the first place.
    
    However, we could have accumulated apps which attach readonly (even though
    they would be permitted to attach read/write), and which subsequently use
    mprotect to switch write permission on and off: it's not unreasonable.
    
    I was going to add a second ipcperms check in do_shmat, to check for
    writable when readonly, and if not writable find_vma and clear VM_MAYWRITE.
     But security_ipc_permission might do auditing, and it seems wrong to
    report an attempt for write permission when there has been none.  Or we
    could flag the vma as SHM, note the shmid or shp in vm_private_data, and
    then get mprotect to check.
    
    But the patch below is a lot simpler: I'd rather stick with it, if we can
    convince ourselves somehow that it'll be safe.
    
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

diff --git a/ipc/shm.c b/ipc/shm.c
index 6b0c9af5bbf7..1c2faf62bc73 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -162,6 +162,8 @@ static int shm_mmap(struct file * file, struct vm_area_struct * vma)
 	ret = shmem_mmap(file, vma);
 	if (ret == 0) {
 		vma->vm_ops = &shm_vm_ops;
+		if (!(vma->vm_flags & VM_WRITE))
+			vma->vm_flags &= ~VM_MAYWRITE;
 		shm_inc(file->f_dentry->d_inode->i_ino);
 	}
 

commit 9ba025f10885758975fbbc2292a5b9e7cb8026a8
Author: Eric Sesterhenn <snakebyte@gmx.de>
Date:   Sun Apr 2 13:42:42 2006 +0200

    BUG_ON() Conversion in ipc/shm.c
    
    this changes if() BUG(); constructs to BUG_ON() which is
    cleaner, contains unlikely() and can better optimized away.
    
    Signed-off-by: Eric Sesterhenn <snakebyte@gmx.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/ipc/shm.c b/ipc/shm.c
index f806a2e314e0..6b0c9af5bbf7 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -91,8 +91,8 @@ static inline int shm_addid(struct shmid_kernel *shp)
 static inline void shm_inc (int id) {
 	struct shmid_kernel *shp;
 
-	if(!(shp = shm_lock(id)))
-		BUG();
+	shp = shm_lock(id);
+	BUG_ON(!shp);
 	shp->shm_atim = get_seconds();
 	shp->shm_lprid = current->tgid;
 	shp->shm_nattch++;
@@ -142,8 +142,8 @@ static void shm_close (struct vm_area_struct *shmd)
 
 	mutex_lock(&shm_ids.mutex);
 	/* remove from the list of attaches of the shm segment */
-	if(!(shp = shm_lock(id)))
-		BUG();
+	shp = shm_lock(id);
+	BUG_ON(!shp);
 	shp->shm_lprid = current->tgid;
 	shp->shm_dtim = get_seconds();
 	shp->shm_nattch--;
@@ -283,8 +283,7 @@ asmlinkage long sys_shmget (key_t key, size_t size, int shmflg)
 		err = -EEXIST;
 	} else {
 		shp = shm_lock(id);
-		if(shp==NULL)
-			BUG();
+		BUG_ON(shp==NULL);
 		if (shp->shm_segsz < size)
 			err = -EINVAL;
 		else if (ipcperms(&shp->shm_perm, shmflg))
@@ -774,8 +773,8 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	up_write(&current->mm->mmap_sem);
 
 	mutex_lock(&shm_ids.mutex);
-	if(!(shp = shm_lock(shmid)))
-		BUG();
+	shp = shm_lock(shmid);
+	BUG_ON(!shp);
 	shp->shm_nattch--;
 	if(shp->shm_nattch == 0 &&
 	   shp->shm_perm.mode & SHM_DEST)

commit 5f921ae96f1529a55966f25cd5c70fab11d38be7
Author: Ingo Molnar <mingo@elte.hu>
Date:   Sun Mar 26 01:37:17 2006 -0800

    [PATCH] sem2mutex: ipc, id.sem
    
    Semaphore to mutex conversion.
    
    The conversion was generated via scripts, and the result was validated
    automatically via a script as well.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Lee Schermerhorn <lee.schermerhorn@hp.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 6f9615c09fb2..f806a2e314e0 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -30,6 +30,7 @@
 #include <linux/capability.h>
 #include <linux/ptrace.h>
 #include <linux/seq_file.h>
+#include <linux/mutex.h>
 
 #include <asm/uaccess.h>
 
@@ -109,7 +110,7 @@ static void shm_open (struct vm_area_struct *shmd)
  *
  * @shp: struct to free
  *
- * It has to be called with shp and shm_ids.sem locked,
+ * It has to be called with shp and shm_ids.mutex locked,
  * but returns with shp unlocked and freed.
  */
 static void shm_destroy (struct shmid_kernel *shp)
@@ -139,7 +140,7 @@ static void shm_close (struct vm_area_struct *shmd)
 	int id = file->f_dentry->d_inode->i_ino;
 	struct shmid_kernel *shp;
 
-	down (&shm_ids.sem);
+	mutex_lock(&shm_ids.mutex);
 	/* remove from the list of attaches of the shm segment */
 	if(!(shp = shm_lock(id)))
 		BUG();
@@ -151,7 +152,7 @@ static void shm_close (struct vm_area_struct *shmd)
 		shm_destroy (shp);
 	else
 		shm_unlock(shp);
-	up (&shm_ids.sem);
+	mutex_unlock(&shm_ids.mutex);
 }
 
 static int shm_mmap(struct file * file, struct vm_area_struct * vma)
@@ -270,7 +271,7 @@ asmlinkage long sys_shmget (key_t key, size_t size, int shmflg)
 	struct shmid_kernel *shp;
 	int err, id = 0;
 
-	down(&shm_ids.sem);
+	mutex_lock(&shm_ids.mutex);
 	if (key == IPC_PRIVATE) {
 		err = newseg(key, shmflg, size);
 	} else if ((id = ipc_findkey(&shm_ids, key)) == -1) {
@@ -296,7 +297,7 @@ asmlinkage long sys_shmget (key_t key, size_t size, int shmflg)
 		}
 		shm_unlock(shp);
 	}
-	up(&shm_ids.sem);
+	mutex_unlock(&shm_ids.mutex);
 
 	return err;
 }
@@ -467,14 +468,14 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 			return err;
 
 		memset(&shm_info,0,sizeof(shm_info));
-		down(&shm_ids.sem);
+		mutex_lock(&shm_ids.mutex);
 		shm_info.used_ids = shm_ids.in_use;
 		shm_get_stat (&shm_info.shm_rss, &shm_info.shm_swp);
 		shm_info.shm_tot = shm_tot;
 		shm_info.swap_attempts = 0;
 		shm_info.swap_successes = 0;
 		err = shm_ids.max_id;
-		up(&shm_ids.sem);
+		mutex_unlock(&shm_ids.mutex);
 		if(copy_to_user (buf, &shm_info, sizeof(shm_info))) {
 			err = -EFAULT;
 			goto out;
@@ -583,7 +584,7 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		 *	Instead we set a destroyed flag, and then blow
 		 *	the name away when the usage hits zero.
 		 */
-		down(&shm_ids.sem);
+		mutex_lock(&shm_ids.mutex);
 		shp = shm_lock(shmid);
 		err = -EINVAL;
 		if (shp == NULL) 
@@ -610,7 +611,7 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 			shm_unlock(shp);
 		} else
 			shm_destroy (shp);
-		up(&shm_ids.sem);
+		mutex_unlock(&shm_ids.mutex);
 		goto out;
 	}
 
@@ -620,12 +621,13 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 			err = -EFAULT;
 			goto out;
 		}
-		down(&shm_ids.sem);
+		mutex_lock(&shm_ids.mutex);
 		shp = shm_lock(shmid);
 		err=-EINVAL;
 		if(shp==NULL)
 			goto out_up;
-		if ((err = audit_ipc_perms(0, setbuf.uid, setbuf.gid, setbuf.mode, &(shp->shm_perm))))
+		if ((err = audit_ipc_perms(0, setbuf.uid, setbuf.gid,
+					setbuf.mode, &(shp->shm_perm))))
 			goto out_unlock_up;
 		err = shm_checkid(shp,shmid);
 		if(err)
@@ -658,7 +660,7 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 out_unlock_up:
 	shm_unlock(shp);
 out_up:
-	up(&shm_ids.sem);
+	mutex_unlock(&shm_ids.mutex);
 	goto out;
 out_unlock:
 	shm_unlock(shp);
@@ -771,7 +773,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 invalid:
 	up_write(&current->mm->mmap_sem);
 
-	down (&shm_ids.sem);
+	mutex_lock(&shm_ids.mutex);
 	if(!(shp = shm_lock(shmid)))
 		BUG();
 	shp->shm_nattch--;
@@ -780,7 +782,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 		shm_destroy (shp);
 	else
 		shm_unlock(shp);
-	up (&shm_ids.sem);
+	mutex_unlock(&shm_ids.mutex);
 
 	*raddr = (unsigned long) user_addr;
 	err = 0;

commit 1b9a3917366028cc451a98dd22e3bcd537d4e5c1
Merge: 3661f00e2097 71e1c784b24a
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Sat Mar 25 09:24:53 2006 -0800

    Merge branch 'audit.b3' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/audit-current
    
    * 'audit.b3' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/audit-current: (22 commits)
      [PATCH] fix audit_init failure path
      [PATCH] EXPORT_SYMBOL patch for audit_log, audit_log_start, audit_log_end and audit_format
      [PATCH] sem2mutex: audit_netlink_sem
      [PATCH] simplify audit_free() locking
      [PATCH] Fix audit operators
      [PATCH] promiscuous mode
      [PATCH] Add tty to syscall audit records
      [PATCH] add/remove rule update
      [PATCH] audit string fields interface + consumer
      [PATCH] SE Linux audit events
      [PATCH] Minor cosmetic cleanups to the code moved into auditfilter.c
      [PATCH] Fix audit record filtering with !CONFIG_AUDITSYSCALL
      [PATCH] Fix IA64 success/failure indication in syscall auditing.
      [PATCH] Miscellaneous bug and warning fixes
      [PATCH] Capture selinux subject/object context information.
      [PATCH] Exclude messages by message type
      [PATCH] Collect more inode information during syscall processing.
      [PATCH] Pass dentry, not just name, in fsnotify creation hooks.
      [PATCH] Define new range of userspace messages.
      [PATCH] Filter rule comparators
      ...
    
    Fixed trivial conflict in security/selinux/hooks.c

commit df1e2fb540368d0f9640045235f81923fa63acb7
Author: Hugh Dickins <hugh@veritas.com>
Date:   Fri Mar 24 03:18:06 2006 -0800

    [PATCH] shmdt: check address alignment
    
    SUSv3 says the shmdt() function shall fail with EINVAL if the value of
    shmaddr is not the data segment start address of a shared memory segment:
    our sys_shmdt needs to reject a shmaddr which is not page-aligned.
    
    Does it have the potential to break existing apps?
    
    Hugh says
    
      "sys_shmdt() just does the wrong (unexpected) thing with a misaligned
      address: it'll fail on what you might expect it to succeed on, and only
      succeed on what it should definitely fail on.
    
      "That is, I think it behaves as if shmaddr gets rounded up, when the only
      understandable behaviour would be if it rounded it down.
    
      "Which does mean you'd have to be devious to see anything but EINVAL from
      a misaligned shmaddr there, so it's not terribly important."
    
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 9162123a7b23..16fe2786087d 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -814,6 +814,9 @@ asmlinkage long sys_shmdt(char __user *shmaddr)
 	loff_t size = 0;
 	int retval = -EINVAL;
 
+	if (addr & ~PAGE_MASK)
+		return retval;
+
 	down_write(&mm->mmap_sem);
 
 	/*

commit 8c8570fb8feef2bc166bee75a85748b25cda22d9
Author: Dustin Kirkland <dustin.kirkland@us.ibm.com>
Date:   Thu Nov 3 17:15:16 2005 +0000

    [PATCH] Capture selinux subject/object context information.
    
    This patch extends existing audit records with subject/object context
    information. Audit records associated with filesystem inodes, ipc, and
    tasks now contain SELinux label information in the field "subj" if the
    item is performing the action, or in "obj" if the item is the receiver
    of an action.
    
    These labels are collected via hooks in SELinux and appended to the
    appropriate record in the audit code.
    
    This additional information is required for Common Criteria Labeled
    Security Protection Profile (LSPP).
    
    [AV: fixed kmalloc flags use]
    [folded leak fixes]
    [folded cleanup from akpm (kfree(NULL)]
    [folded audit_inode_context() leak fix]
    [folded akpm's fix for audit_ipc_perm() definition in case of !CONFIG_AUDIT]
    
    Signed-off-by: Dustin Kirkland <dustin.kirkland@us.ibm.com>
    Signed-off-by: David Woodhouse <dwmw2@infradead.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/ipc/shm.c b/ipc/shm.c
index 9162123a7b23..a88c8a02e7f3 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -620,13 +620,13 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 			err = -EFAULT;
 			goto out;
 		}
-		if ((err = audit_ipc_perms(0, setbuf.uid, setbuf.gid, setbuf.mode)))
-			return err;
 		down(&shm_ids.sem);
 		shp = shm_lock(shmid);
 		err=-EINVAL;
 		if(shp==NULL)
 			goto out_up;
+		if ((err = audit_ipc_perms(0, setbuf.uid, setbuf.gid, setbuf.mode, &(shp->shm_perm))))
+			goto out_unlock_up;
 		err = shm_checkid(shp,shmid);
 		if(err)
 			goto out_unlock_up;

commit 8e36709d8cea48a4d341294ce2b46678a2e77159
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Fri Feb 10 01:51:12 2006 -0800

    [PATCH] shmdt cannot detach not-alined shm segment cleanly.
    
    sys_shmdt() can manage shm segments which are covered by multiple vmas.  (This
    can happen when a user uses mprotect() after shmat().)
    
    This works well if shm is aligned to PAGE_SIZE, but if not, the last
    segment cannot be detached.  It is because a comparison in sys_shmdt()
    
            (vma->vm_end - addr) < size
                    addr == return address of shmat()
                    size == shmsize, argments to shmget()
    
    size should be aligned to PAGE_SIZE before being compared with vma->vm_end,
    which is aligned.
    
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Acked-by: Hugh Dickins <hugh@veritas.com>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 4c28d2d8e305..9162123a7b23 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -870,6 +870,7 @@ asmlinkage long sys_shmdt(char __user *shmaddr)
 	 * could possibly have landed at. Also cast things to loff_t to
 	 * prevent overflows and make comparisions vs. equal-width types.
 	 */
+	size = PAGE_ALIGN(size);
 	while (vma && (loff_t)(vma->vm_end - addr) <= size) {
 		next = vma->vm_next;
 

commit c59ede7b78db329949d9cdcd7064e22d357560ef
Author: Randy.Dunlap <rdunlap@xenotime.net>
Date:   Wed Jan 11 12:17:46 2006 -0800

    [PATCH] move capable() to capability.h
    
    - Move capable() from sched.h to capability.h;
    
    - Use <linux/capability.h> where capable() is used
            (in include/, block/, ipc/, kernel/, a few drivers/,
            mm/, security/, & sound/;
            many more drivers/ to go)
    
    Signed-off-by: Randy Dunlap <rdunlap@xenotime.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 0b92e874fc06..4c28d2d8e305 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -27,6 +27,7 @@
 #include <linux/security.h>
 #include <linux/syscalls.h>
 #include <linux/audit.h>
+#include <linux/capability.h>
 #include <linux/ptrace.h>
 #include <linux/seq_file.h>
 

commit b33291c0bcecfa44baa905964eec4b8815dcbcdf
Author: Andrew Morton <akpm@osdl.org>
Date:   Sun Jan 8 01:02:21 2006 -0800

    [PATCH] ipc: expand shm_flags
    
    Unobfsucate this struct member
    
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 0ef4a1cf3e27..0b92e874fc06 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -34,8 +34,6 @@
 
 #include "util.h"
 
-#define shm_flags	shm_perm.mode
-
 static struct file_operations shm_file_operations;
 static struct vm_operations_struct shm_vm_ops;
 
@@ -148,7 +146,7 @@ static void shm_close (struct vm_area_struct *shmd)
 	shp->shm_dtim = get_seconds();
 	shp->shm_nattch--;
 	if(shp->shm_nattch == 0 &&
-	   shp->shm_flags & SHM_DEST)
+	   shp->shm_perm.mode & SHM_DEST)
 		shm_destroy (shp);
 	else
 		shm_unlock(shp);
@@ -205,7 +203,7 @@ static int newseg (key_t key, int shmflg, size_t size)
 		return -ENOMEM;
 
 	shp->shm_perm.key = key;
-	shp->shm_flags = (shmflg & S_IRWXUGO);
+	shp->shm_perm.mode = (shmflg & S_IRWXUGO);
 	shp->mlock_user = NULL;
 
 	shp->shm_perm.security = NULL;
@@ -345,7 +343,7 @@ static inline unsigned long copy_shmid_from_user(struct shm_setbuf *out, void __
 
 		out->uid	= tbuf.shm_perm.uid;
 		out->gid	= tbuf.shm_perm.gid;
-		out->mode	= tbuf.shm_flags;
+		out->mode	= tbuf.shm_perm.mode;
 
 		return 0;
 	    }
@@ -358,7 +356,7 @@ static inline unsigned long copy_shmid_from_user(struct shm_setbuf *out, void __
 
 		out->uid	= tbuf_old.shm_perm.uid;
 		out->gid	= tbuf_old.shm_perm.gid;
-		out->mode	= tbuf_old.shm_flags;
+		out->mode	= tbuf_old.shm_perm.mode;
 
 		return 0;
 	    }
@@ -560,13 +558,13 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 			if (!is_file_hugepages(shp->shm_file)) {
 				err = shmem_lock(shp->shm_file, 1, user);
 				if (!err) {
-					shp->shm_flags |= SHM_LOCKED;
+					shp->shm_perm.mode |= SHM_LOCKED;
 					shp->mlock_user = user;
 				}
 			}
 		} else if (!is_file_hugepages(shp->shm_file)) {
 			shmem_lock(shp->shm_file, 0, shp->mlock_user);
-			shp->shm_flags &= ~SHM_LOCKED;
+			shp->shm_perm.mode &= ~SHM_LOCKED;
 			shp->mlock_user = NULL;
 		}
 		shm_unlock(shp);
@@ -605,7 +603,7 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 			goto out_unlock_up;
 
 		if (shp->shm_nattch){
-			shp->shm_flags |= SHM_DEST;
+			shp->shm_perm.mode |= SHM_DEST;
 			/* Do not find it any more */
 			shp->shm_perm.key = IPC_PRIVATE;
 			shm_unlock(shp);
@@ -644,7 +642,7 @@ asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
 		
 		shp->shm_perm.uid = setbuf.uid;
 		shp->shm_perm.gid = setbuf.gid;
-		shp->shm_flags = (shp->shm_flags & ~S_IRWXUGO)
+		shp->shm_perm.mode = (shp->shm_perm.mode & ~S_IRWXUGO)
 			| (setbuf.mode & S_IRWXUGO);
 		shp->shm_ctim = get_seconds();
 		break;
@@ -777,7 +775,7 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 		BUG();
 	shp->shm_nattch--;
 	if(shp->shm_nattch == 0 &&
-	   shp->shm_flags & SHM_DEST)
+	   shp->shm_perm.mode & SHM_DEST)
 		shm_destroy (shp);
 	else
 		shm_unlock(shp);
@@ -902,7 +900,7 @@ static int sysvipc_shm_proc_show(struct seq_file *s, void *it)
 	return seq_printf(s, format,
 			  shp->shm_perm.key,
 			  shp->id,
-			  shp->shm_flags,
+			  shp->shm_perm.mode,
 			  shp->shm_segsz,
 			  shp->shm_cprid,
 			  shp->shm_lprid,

commit b0e15190ead07056ab0c3844a499ff35e66d27cc
Author: David Howells <dhowells@redhat.com>
Date:   Fri Jan 6 00:11:42 2006 -0800

    [PATCH] NOMMU: Make SYSV IPC SHM use ramfs facilities on NOMMU
    
    The attached patch makes the SYSV IPC shared memory facilities use the new
    ramfs facilities on a no-MMU kernel.
    
    The following changes are made:
    
     (1) There are now shmem_mmap() and shmem_get_unmapped_area() functions to
         allow the IPC SHM facilities to commune with the tiny-shmem and shmem
         code.
    
     (2) ramfs files now need resizing using do_truncate() rather than by modifying
         the inode size directly (see shmem_file_setup()). This causes ramfs to
         attempt to bind a block of pages of sufficient size to the inode.
    
     (3) CONFIG_SYSVIPC is no longer contingent on CONFIG_MMU.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 587d836d80d9..0ef4a1cf3e27 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -157,14 +157,22 @@ static void shm_close (struct vm_area_struct *shmd)
 
 static int shm_mmap(struct file * file, struct vm_area_struct * vma)
 {
-	file_accessed(file);
-	vma->vm_ops = &shm_vm_ops;
-	shm_inc(file->f_dentry->d_inode->i_ino);
-	return 0;
+	int ret;
+
+	ret = shmem_mmap(file, vma);
+	if (ret == 0) {
+		vma->vm_ops = &shm_vm_ops;
+		shm_inc(file->f_dentry->d_inode->i_ino);
+	}
+
+	return ret;
 }
 
 static struct file_operations shm_file_operations = {
-	.mmap	= shm_mmap
+	.mmap	= shm_mmap,
+#ifndef CONFIG_MMU
+	.get_unmapped_area = shmem_get_unmapped_area,
+#endif
 };
 
 static struct vm_operations_struct shm_vm_ops = {

commit bf8f972d3a1daf969cf44f64cc36d53bfd76441f
Author: Badari Pulavarty <pbadari@us.ibm.com>
Date:   Mon Nov 7 00:59:27 2005 -0800

    [PATCH] SHM_NORESERVE flags for shmget()
    
    Add SHM_NORESERVE functionality similar to MAP_NORESERVE for shared memory
    segments.
    
    This is mainly to avoid abuse of OVERCOMMIT_ALWAYS and this flag is ignored
    for OVERCOMMIT_NEVER.
    
    Signed-off-by: Badari Pulavarty <pbadari@us.ibm.com>
    Cc: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index b58c651d31ae..587d836d80d9 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -212,8 +212,16 @@ static int newseg (key_t key, int shmflg, size_t size)
 		file = hugetlb_zero_setup(size);
 		shp->mlock_user = current->user;
 	} else {
+		int acctflag = VM_ACCOUNT;
+		/*
+		 * Do not allow no accounting for OVERCOMMIT_NEVER, even
+	 	 * if it's asked for.
+		 */
+		if  ((shmflg & SHM_NORESERVE) &&
+				sysctl_overcommit_memory != OVERCOMMIT_NEVER)
+			acctflag = 0;
 		sprintf (name, "SYSV%08x", key);
-		file = shmem_file_setup(name, size, VM_ACCOUNT);
+		file = shmem_file_setup(name, size, acctflag);
 	}
 	error = PTR_ERR(file);
 	if (IS_ERR(file))

commit 551110a94aa15890d1709b179c4be1e66ff6db53
Author: Krishnakumar R <rkrishnakumar@gmail.com>
Date:   Sat Oct 29 18:16:45 2005 -0700

    [PATCH] hugetlb: remove repeated code
    
    Clean up some repeated code related to HugeTLB.  hugetlb_zero_setup would
    have already allocated the file->f_op.
    
    Signed-off-by: Krishnakumar. R <rkrishnakumar@gmail.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index dca90489e3b0..b58c651d31ae 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -233,10 +233,11 @@ static int newseg (key_t key, int shmflg, size_t size)
 	shp->id = shm_buildid(id,shp->shm_perm.seq);
 	shp->shm_file = file;
 	file->f_dentry->d_inode->i_ino = shp->id;
-	if (shmflg & SHM_HUGETLB)
-		set_file_hugepages(file);
-	else
+
+	/* Hugetlb ops would have already been assigned. */
+	if (!(shmflg & SHM_HUGETLB))
 		file->f_op = &shm_file_operations;
+
 	shm_tot += numpages;
 	shm_unlock(shp);
 	return shp->id;

commit 19b4946ca9d1e35d4c641dcebe27378de34f3ddd
Author: Mike Waychison <mikew@google.com>
Date:   Tue Sep 6 15:17:10 2005 -0700

    [PATCH] ipc: convert /proc/sysvipc/* to generic seq_file interface
    
    Change the /proc/sysvipc/shm|sem|msg files to use the generic seq_file
    implementation for struct ipc_ids.
    
    Signed-off-by: Mike Waychison <mikew@google.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 1d6cf08d950b..dca90489e3b0 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -23,12 +23,12 @@
 #include <linux/init.h>
 #include <linux/file.h>
 #include <linux/mman.h>
-#include <linux/proc_fs.h>
 #include <linux/shmem_fs.h>
 #include <linux/security.h>
 #include <linux/syscalls.h>
 #include <linux/audit.h>
 #include <linux/ptrace.h>
+#include <linux/seq_file.h>
 
 #include <asm/uaccess.h>
 
@@ -51,7 +51,7 @@ static int newseg (key_t key, int shmflg, size_t size);
 static void shm_open (struct vm_area_struct *shmd);
 static void shm_close (struct vm_area_struct *shmd);
 #ifdef CONFIG_PROC_FS
-static int sysvipc_shm_read_proc(char *buffer, char **start, off_t offset, int length, int *eof, void *data);
+static int sysvipc_shm_proc_show(struct seq_file *s, void *it);
 #endif
 
 size_t	shm_ctlmax = SHMMAX;
@@ -63,9 +63,10 @@ static int shm_tot; /* total number of shared memory pages */
 void __init shm_init (void)
 {
 	ipc_init_ids(&shm_ids, 1);
-#ifdef CONFIG_PROC_FS
-	create_proc_read_entry("sysvipc/shm", 0, NULL, sysvipc_shm_read_proc, NULL);
-#endif
+	ipc_init_proc_interface("sysvipc/shm",
+				"       key      shmid perms       size  cpid  lpid nattch   uid   gid  cuid  cgid      atime      dtime      ctime\n",
+				&shm_ids,
+				sysvipc_shm_proc_show);
 }
 
 static inline int shm_checkid(struct shmid_kernel *s, int id)
@@ -869,63 +870,32 @@ asmlinkage long sys_shmdt(char __user *shmaddr)
 }
 
 #ifdef CONFIG_PROC_FS
-static int sysvipc_shm_read_proc(char *buffer, char **start, off_t offset, int length, int *eof, void *data)
+static int sysvipc_shm_proc_show(struct seq_file *s, void *it)
 {
-	off_t pos = 0;
-	off_t begin = 0;
-	int i, len = 0;
-
-	down(&shm_ids.sem);
-	len += sprintf(buffer, "       key      shmid perms       size  cpid  lpid nattch   uid   gid  cuid  cgid      atime      dtime      ctime\n");
+	struct shmid_kernel *shp = it;
+	char *format;
 
-	for(i = 0; i <= shm_ids.max_id; i++) {
-		struct shmid_kernel* shp;
-
-		shp = shm_lock(i);
-		if(shp!=NULL) {
 #define SMALL_STRING "%10d %10d  %4o %10u %5u %5u  %5d %5u %5u %5u %5u %10lu %10lu %10lu\n"
 #define BIG_STRING   "%10d %10d  %4o %21u %5u %5u  %5d %5u %5u %5u %5u %10lu %10lu %10lu\n"
-			char *format;
 
-			if (sizeof(size_t) <= sizeof(int))
-				format = SMALL_STRING;
-			else
-				format = BIG_STRING;
-			len += sprintf(buffer + len, format,
-				shp->shm_perm.key,
-				shm_buildid(i, shp->shm_perm.seq),
-				shp->shm_flags,
-				shp->shm_segsz,
-				shp->shm_cprid,
-				shp->shm_lprid,
-				is_file_hugepages(shp->shm_file) ? (file_count(shp->shm_file) - 1) : shp->shm_nattch,
-				shp->shm_perm.uid,
-				shp->shm_perm.gid,
-				shp->shm_perm.cuid,
-				shp->shm_perm.cgid,
-				shp->shm_atim,
-				shp->shm_dtim,
-				shp->shm_ctim);
-			shm_unlock(shp);
-
-			pos += len;
-			if(pos < offset) {
-				len = 0;
-				begin = pos;
-			}
-			if(pos > offset + length)
-				goto done;
-		}
-	}
-	*eof = 1;
-done:
-	up(&shm_ids.sem);
-	*start = buffer + (offset - begin);
-	len -= (offset - begin);
-	if(len > length)
-		len = length;
-	if(len < 0)
-		len = 0;
-	return len;
+	if (sizeof(size_t) <= sizeof(int))
+		format = SMALL_STRING;
+	else
+		format = BIG_STRING;
+	return seq_printf(s, format,
+			  shp->shm_perm.key,
+			  shp->id,
+			  shp->shm_flags,
+			  shp->shm_segsz,
+			  shp->shm_cprid,
+			  shp->shm_lprid,
+			  is_file_hugepages(shp->shm_file) ? (file_count(shp->shm_file) - 1) : shp->shm_nattch,
+			  shp->shm_perm.uid,
+			  shp->shm_perm.gid,
+			  shp->shm_perm.cuid,
+			  shp->shm_perm.cgid,
+			  shp->shm_atim,
+			  shp->shm_dtim,
+			  shp->shm_ctim);
 }
 #endif

commit 6ade43fbbcc3c12f0ddba112351d14d6c82ae476
Author: Andrew Morton <akpm@osdl.org>
Date:   Mon Aug 1 21:11:45 2005 -0700

    [PATCH] shm: CONFIG_SHMEM=n build fix
    
    Fix bug found by Grant Coady <lkml@dodo.com.au>'s autobuild setup.
    
    shmem_set_policy() and shmem_get_policy() are macros if !CONFIG_SHMEM, so this
    doesn't work.
    
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index cce022435dbc..1d6cf08d950b 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -170,7 +170,7 @@ static struct vm_operations_struct shm_vm_ops = {
 	.open	= shm_open,	/* callback for a new vm-area open */
 	.close	= shm_close,	/* callback for when the vm-area is released */
 	.nopage	= shmem_nopage,
-#ifdef CONFIG_NUMA
+#if defined(CONFIG_NUMA) && defined(CONFIG_SHMEM)
 	.set_policy = shmem_set_policy,
 	.get_policy = shmem_get_policy,
 #endif

commit 7d87e14c236d6c4cab66d87cf0bc1e0f0375d308
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Sun May 1 08:59:12 2005 -0700

    [PATCH] consolidate sys_shmat
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/ipc/shm.c b/ipc/shm.c
index 06cd5c91056f..cce022435dbc 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -28,6 +28,8 @@
 #include <linux/security.h>
 #include <linux/syscalls.h>
 #include <linux/audit.h>
+#include <linux/ptrace.h>
+
 #include <asm/uaccess.h>
 
 #include "util.h"
@@ -771,6 +773,18 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
 	return err;
 }
 
+asmlinkage long sys_shmat(int shmid, char __user *shmaddr, int shmflg)
+{
+	unsigned long ret;
+	long err;
+
+	err = do_shmat(shmid, shmaddr, shmflg, &ret);
+	if (err)
+		return err;
+	force_successful_syscall_return();
+	return (long)ret;
+}
+
 /*
  * detach and kill segment if marked destroyed.
  * The work is done in shm_close.

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/ipc/shm.c b/ipc/shm.c
new file mode 100644
index 000000000000..06cd5c91056f
--- /dev/null
+++ b/ipc/shm.c
@@ -0,0 +1,917 @@
+/*
+ * linux/ipc/shm.c
+ * Copyright (C) 1992, 1993 Krishna Balasubramanian
+ *	 Many improvements/fixes by Bruno Haible.
+ * Replaced `struct shm_desc' by `struct vm_area_struct', July 1994.
+ * Fixed the shm swap deallocation (shm_unuse()), August 1998 Andrea Arcangeli.
+ *
+ * /proc/sysvipc/shm support (c) 1999 Dragos Acostachioaie <dragos@iname.com>
+ * BIGMEM support, Andrea Arcangeli <andrea@suse.de>
+ * SMP thread shm, Jean-Luc Boyard <jean-luc.boyard@siemens.fr>
+ * HIGHMEM support, Ingo Molnar <mingo@redhat.com>
+ * Make shmmax, shmall, shmmni sysctl'able, Christoph Rohland <cr@sap.com>
+ * Shared /dev/zero support, Kanoj Sarcar <kanoj@sgi.com>
+ * Move the mm functionality over to mm/shmem.c, Christoph Rohland <cr@sap.com>
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/slab.h>
+#include <linux/mm.h>
+#include <linux/hugetlb.h>
+#include <linux/shm.h>
+#include <linux/init.h>
+#include <linux/file.h>
+#include <linux/mman.h>
+#include <linux/proc_fs.h>
+#include <linux/shmem_fs.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/audit.h>
+#include <asm/uaccess.h>
+
+#include "util.h"
+
+#define shm_flags	shm_perm.mode
+
+static struct file_operations shm_file_operations;
+static struct vm_operations_struct shm_vm_ops;
+
+static struct ipc_ids shm_ids;
+
+#define shm_lock(id)	((struct shmid_kernel*)ipc_lock(&shm_ids,id))
+#define shm_unlock(shp)	ipc_unlock(&(shp)->shm_perm)
+#define shm_get(id)	((struct shmid_kernel*)ipc_get(&shm_ids,id))
+#define shm_buildid(id, seq) \
+	ipc_buildid(&shm_ids, id, seq)
+
+static int newseg (key_t key, int shmflg, size_t size);
+static void shm_open (struct vm_area_struct *shmd);
+static void shm_close (struct vm_area_struct *shmd);
+#ifdef CONFIG_PROC_FS
+static int sysvipc_shm_read_proc(char *buffer, char **start, off_t offset, int length, int *eof, void *data);
+#endif
+
+size_t	shm_ctlmax = SHMMAX;
+size_t 	shm_ctlall = SHMALL;
+int 	shm_ctlmni = SHMMNI;
+
+static int shm_tot; /* total number of shared memory pages */
+
+void __init shm_init (void)
+{
+	ipc_init_ids(&shm_ids, 1);
+#ifdef CONFIG_PROC_FS
+	create_proc_read_entry("sysvipc/shm", 0, NULL, sysvipc_shm_read_proc, NULL);
+#endif
+}
+
+static inline int shm_checkid(struct shmid_kernel *s, int id)
+{
+	if (ipc_checkid(&shm_ids,&s->shm_perm,id))
+		return -EIDRM;
+	return 0;
+}
+
+static inline struct shmid_kernel *shm_rmid(int id)
+{
+	return (struct shmid_kernel *)ipc_rmid(&shm_ids,id);
+}
+
+static inline int shm_addid(struct shmid_kernel *shp)
+{
+	return ipc_addid(&shm_ids, &shp->shm_perm, shm_ctlmni);
+}
+
+
+
+static inline void shm_inc (int id) {
+	struct shmid_kernel *shp;
+
+	if(!(shp = shm_lock(id)))
+		BUG();
+	shp->shm_atim = get_seconds();
+	shp->shm_lprid = current->tgid;
+	shp->shm_nattch++;
+	shm_unlock(shp);
+}
+
+/* This is called by fork, once for every shm attach. */
+static void shm_open (struct vm_area_struct *shmd)
+{
+	shm_inc (shmd->vm_file->f_dentry->d_inode->i_ino);
+}
+
+/*
+ * shm_destroy - free the struct shmid_kernel
+ *
+ * @shp: struct to free
+ *
+ * It has to be called with shp and shm_ids.sem locked,
+ * but returns with shp unlocked and freed.
+ */
+static void shm_destroy (struct shmid_kernel *shp)
+{
+	shm_tot -= (shp->shm_segsz + PAGE_SIZE - 1) >> PAGE_SHIFT;
+	shm_rmid (shp->id);
+	shm_unlock(shp);
+	if (!is_file_hugepages(shp->shm_file))
+		shmem_lock(shp->shm_file, 0, shp->mlock_user);
+	else
+		user_shm_unlock(shp->shm_file->f_dentry->d_inode->i_size,
+						shp->mlock_user);
+	fput (shp->shm_file);
+	security_shm_free(shp);
+	ipc_rcu_putref(shp);
+}
+
+/*
+ * remove the attach descriptor shmd.
+ * free memory for segment if it is marked destroyed.
+ * The descriptor has already been removed from the current->mm->mmap list
+ * and will later be kfree()d.
+ */
+static void shm_close (struct vm_area_struct *shmd)
+{
+	struct file * file = shmd->vm_file;
+	int id = file->f_dentry->d_inode->i_ino;
+	struct shmid_kernel *shp;
+
+	down (&shm_ids.sem);
+	/* remove from the list of attaches of the shm segment */
+	if(!(shp = shm_lock(id)))
+		BUG();
+	shp->shm_lprid = current->tgid;
+	shp->shm_dtim = get_seconds();
+	shp->shm_nattch--;
+	if(shp->shm_nattch == 0 &&
+	   shp->shm_flags & SHM_DEST)
+		shm_destroy (shp);
+	else
+		shm_unlock(shp);
+	up (&shm_ids.sem);
+}
+
+static int shm_mmap(struct file * file, struct vm_area_struct * vma)
+{
+	file_accessed(file);
+	vma->vm_ops = &shm_vm_ops;
+	shm_inc(file->f_dentry->d_inode->i_ino);
+	return 0;
+}
+
+static struct file_operations shm_file_operations = {
+	.mmap	= shm_mmap
+};
+
+static struct vm_operations_struct shm_vm_ops = {
+	.open	= shm_open,	/* callback for a new vm-area open */
+	.close	= shm_close,	/* callback for when the vm-area is released */
+	.nopage	= shmem_nopage,
+#ifdef CONFIG_NUMA
+	.set_policy = shmem_set_policy,
+	.get_policy = shmem_get_policy,
+#endif
+};
+
+static int newseg (key_t key, int shmflg, size_t size)
+{
+	int error;
+	struct shmid_kernel *shp;
+	int numpages = (size + PAGE_SIZE -1) >> PAGE_SHIFT;
+	struct file * file;
+	char name[13];
+	int id;
+
+	if (size < SHMMIN || size > shm_ctlmax)
+		return -EINVAL;
+
+	if (shm_tot + numpages >= shm_ctlall)
+		return -ENOSPC;
+
+	shp = ipc_rcu_alloc(sizeof(*shp));
+	if (!shp)
+		return -ENOMEM;
+
+	shp->shm_perm.key = key;
+	shp->shm_flags = (shmflg & S_IRWXUGO);
+	shp->mlock_user = NULL;
+
+	shp->shm_perm.security = NULL;
+	error = security_shm_alloc(shp);
+	if (error) {
+		ipc_rcu_putref(shp);
+		return error;
+	}
+
+	if (shmflg & SHM_HUGETLB) {
+		/* hugetlb_zero_setup takes care of mlock user accounting */
+		file = hugetlb_zero_setup(size);
+		shp->mlock_user = current->user;
+	} else {
+		sprintf (name, "SYSV%08x", key);
+		file = shmem_file_setup(name, size, VM_ACCOUNT);
+	}
+	error = PTR_ERR(file);
+	if (IS_ERR(file))
+		goto no_file;
+
+	error = -ENOSPC;
+	id = shm_addid(shp);
+	if(id == -1) 
+		goto no_id;
+
+	shp->shm_cprid = current->tgid;
+	shp->shm_lprid = 0;
+	shp->shm_atim = shp->shm_dtim = 0;
+	shp->shm_ctim = get_seconds();
+	shp->shm_segsz = size;
+	shp->shm_nattch = 0;
+	shp->id = shm_buildid(id,shp->shm_perm.seq);
+	shp->shm_file = file;
+	file->f_dentry->d_inode->i_ino = shp->id;
+	if (shmflg & SHM_HUGETLB)
+		set_file_hugepages(file);
+	else
+		file->f_op = &shm_file_operations;
+	shm_tot += numpages;
+	shm_unlock(shp);
+	return shp->id;
+
+no_id:
+	fput(file);
+no_file:
+	security_shm_free(shp);
+	ipc_rcu_putref(shp);
+	return error;
+}
+
+asmlinkage long sys_shmget (key_t key, size_t size, int shmflg)
+{
+	struct shmid_kernel *shp;
+	int err, id = 0;
+
+	down(&shm_ids.sem);
+	if (key == IPC_PRIVATE) {
+		err = newseg(key, shmflg, size);
+	} else if ((id = ipc_findkey(&shm_ids, key)) == -1) {
+		if (!(shmflg & IPC_CREAT))
+			err = -ENOENT;
+		else
+			err = newseg(key, shmflg, size);
+	} else if ((shmflg & IPC_CREAT) && (shmflg & IPC_EXCL)) {
+		err = -EEXIST;
+	} else {
+		shp = shm_lock(id);
+		if(shp==NULL)
+			BUG();
+		if (shp->shm_segsz < size)
+			err = -EINVAL;
+		else if (ipcperms(&shp->shm_perm, shmflg))
+			err = -EACCES;
+		else {
+			int shmid = shm_buildid(id, shp->shm_perm.seq);
+			err = security_shm_associate(shp, shmflg);
+			if (!err)
+				err = shmid;
+		}
+		shm_unlock(shp);
+	}
+	up(&shm_ids.sem);
+
+	return err;
+}
+
+static inline unsigned long copy_shmid_to_user(void __user *buf, struct shmid64_ds *in, int version)
+{
+	switch(version) {
+	case IPC_64:
+		return copy_to_user(buf, in, sizeof(*in));
+	case IPC_OLD:
+	    {
+		struct shmid_ds out;
+
+		ipc64_perm_to_ipc_perm(&in->shm_perm, &out.shm_perm);
+		out.shm_segsz	= in->shm_segsz;
+		out.shm_atime	= in->shm_atime;
+		out.shm_dtime	= in->shm_dtime;
+		out.shm_ctime	= in->shm_ctime;
+		out.shm_cpid	= in->shm_cpid;
+		out.shm_lpid	= in->shm_lpid;
+		out.shm_nattch	= in->shm_nattch;
+
+		return copy_to_user(buf, &out, sizeof(out));
+	    }
+	default:
+		return -EINVAL;
+	}
+}
+
+struct shm_setbuf {
+	uid_t	uid;
+	gid_t	gid;
+	mode_t	mode;
+};	
+
+static inline unsigned long copy_shmid_from_user(struct shm_setbuf *out, void __user *buf, int version)
+{
+	switch(version) {
+	case IPC_64:
+	    {
+		struct shmid64_ds tbuf;
+
+		if (copy_from_user(&tbuf, buf, sizeof(tbuf)))
+			return -EFAULT;
+
+		out->uid	= tbuf.shm_perm.uid;
+		out->gid	= tbuf.shm_perm.gid;
+		out->mode	= tbuf.shm_flags;
+
+		return 0;
+	    }
+	case IPC_OLD:
+	    {
+		struct shmid_ds tbuf_old;
+
+		if (copy_from_user(&tbuf_old, buf, sizeof(tbuf_old)))
+			return -EFAULT;
+
+		out->uid	= tbuf_old.shm_perm.uid;
+		out->gid	= tbuf_old.shm_perm.gid;
+		out->mode	= tbuf_old.shm_flags;
+
+		return 0;
+	    }
+	default:
+		return -EINVAL;
+	}
+}
+
+static inline unsigned long copy_shminfo_to_user(void __user *buf, struct shminfo64 *in, int version)
+{
+	switch(version) {
+	case IPC_64:
+		return copy_to_user(buf, in, sizeof(*in));
+	case IPC_OLD:
+	    {
+		struct shminfo out;
+
+		if(in->shmmax > INT_MAX)
+			out.shmmax = INT_MAX;
+		else
+			out.shmmax = (int)in->shmmax;
+
+		out.shmmin	= in->shmmin;
+		out.shmmni	= in->shmmni;
+		out.shmseg	= in->shmseg;
+		out.shmall	= in->shmall; 
+
+		return copy_to_user(buf, &out, sizeof(out));
+	    }
+	default:
+		return -EINVAL;
+	}
+}
+
+static void shm_get_stat(unsigned long *rss, unsigned long *swp) 
+{
+	int i;
+
+	*rss = 0;
+	*swp = 0;
+
+	for (i = 0; i <= shm_ids.max_id; i++) {
+		struct shmid_kernel *shp;
+		struct inode *inode;
+
+		shp = shm_get(i);
+		if(!shp)
+			continue;
+
+		inode = shp->shm_file->f_dentry->d_inode;
+
+		if (is_file_hugepages(shp->shm_file)) {
+			struct address_space *mapping = inode->i_mapping;
+			*rss += (HPAGE_SIZE/PAGE_SIZE)*mapping->nrpages;
+		} else {
+			struct shmem_inode_info *info = SHMEM_I(inode);
+			spin_lock(&info->lock);
+			*rss += inode->i_mapping->nrpages;
+			*swp += info->swapped;
+			spin_unlock(&info->lock);
+		}
+	}
+}
+
+asmlinkage long sys_shmctl (int shmid, int cmd, struct shmid_ds __user *buf)
+{
+	struct shm_setbuf setbuf;
+	struct shmid_kernel *shp;
+	int err, version;
+
+	if (cmd < 0 || shmid < 0) {
+		err = -EINVAL;
+		goto out;
+	}
+
+	version = ipc_parse_version(&cmd);
+
+	switch (cmd) { /* replace with proc interface ? */
+	case IPC_INFO:
+	{
+		struct shminfo64 shminfo;
+
+		err = security_shm_shmctl(NULL, cmd);
+		if (err)
+			return err;
+
+		memset(&shminfo,0,sizeof(shminfo));
+		shminfo.shmmni = shminfo.shmseg = shm_ctlmni;
+		shminfo.shmmax = shm_ctlmax;
+		shminfo.shmall = shm_ctlall;
+
+		shminfo.shmmin = SHMMIN;
+		if(copy_shminfo_to_user (buf, &shminfo, version))
+			return -EFAULT;
+		/* reading a integer is always atomic */
+		err= shm_ids.max_id;
+		if(err<0)
+			err = 0;
+		goto out;
+	}
+	case SHM_INFO:
+	{
+		struct shm_info shm_info;
+
+		err = security_shm_shmctl(NULL, cmd);
+		if (err)
+			return err;
+
+		memset(&shm_info,0,sizeof(shm_info));
+		down(&shm_ids.sem);
+		shm_info.used_ids = shm_ids.in_use;
+		shm_get_stat (&shm_info.shm_rss, &shm_info.shm_swp);
+		shm_info.shm_tot = shm_tot;
+		shm_info.swap_attempts = 0;
+		shm_info.swap_successes = 0;
+		err = shm_ids.max_id;
+		up(&shm_ids.sem);
+		if(copy_to_user (buf, &shm_info, sizeof(shm_info))) {
+			err = -EFAULT;
+			goto out;
+		}
+
+		err = err < 0 ? 0 : err;
+		goto out;
+	}
+	case SHM_STAT:
+	case IPC_STAT:
+	{
+		struct shmid64_ds tbuf;
+		int result;
+		memset(&tbuf, 0, sizeof(tbuf));
+		shp = shm_lock(shmid);
+		if(shp==NULL) {
+			err = -EINVAL;
+			goto out;
+		} else if(cmd==SHM_STAT) {
+			err = -EINVAL;
+			if (shmid > shm_ids.max_id)
+				goto out_unlock;
+			result = shm_buildid(shmid, shp->shm_perm.seq);
+		} else {
+			err = shm_checkid(shp,shmid);
+			if(err)
+				goto out_unlock;
+			result = 0;
+		}
+		err=-EACCES;
+		if (ipcperms (&shp->shm_perm, S_IRUGO))
+			goto out_unlock;
+		err = security_shm_shmctl(shp, cmd);
+		if (err)
+			goto out_unlock;
+		kernel_to_ipc64_perm(&shp->shm_perm, &tbuf.shm_perm);
+		tbuf.shm_segsz	= shp->shm_segsz;
+		tbuf.shm_atime	= shp->shm_atim;
+		tbuf.shm_dtime	= shp->shm_dtim;
+		tbuf.shm_ctime	= shp->shm_ctim;
+		tbuf.shm_cpid	= shp->shm_cprid;
+		tbuf.shm_lpid	= shp->shm_lprid;
+		if (!is_file_hugepages(shp->shm_file))
+			tbuf.shm_nattch	= shp->shm_nattch;
+		else
+			tbuf.shm_nattch = file_count(shp->shm_file) - 1;
+		shm_unlock(shp);
+		if(copy_shmid_to_user (buf, &tbuf, version))
+			err = -EFAULT;
+		else
+			err = result;
+		goto out;
+	}
+	case SHM_LOCK:
+	case SHM_UNLOCK:
+	{
+		shp = shm_lock(shmid);
+		if(shp==NULL) {
+			err = -EINVAL;
+			goto out;
+		}
+		err = shm_checkid(shp,shmid);
+		if(err)
+			goto out_unlock;
+
+		if (!capable(CAP_IPC_LOCK)) {
+			err = -EPERM;
+			if (current->euid != shp->shm_perm.uid &&
+			    current->euid != shp->shm_perm.cuid)
+				goto out_unlock;
+			if (cmd == SHM_LOCK &&
+			    !current->signal->rlim[RLIMIT_MEMLOCK].rlim_cur)
+				goto out_unlock;
+		}
+
+		err = security_shm_shmctl(shp, cmd);
+		if (err)
+			goto out_unlock;
+		
+		if(cmd==SHM_LOCK) {
+			struct user_struct * user = current->user;
+			if (!is_file_hugepages(shp->shm_file)) {
+				err = shmem_lock(shp->shm_file, 1, user);
+				if (!err) {
+					shp->shm_flags |= SHM_LOCKED;
+					shp->mlock_user = user;
+				}
+			}
+		} else if (!is_file_hugepages(shp->shm_file)) {
+			shmem_lock(shp->shm_file, 0, shp->mlock_user);
+			shp->shm_flags &= ~SHM_LOCKED;
+			shp->mlock_user = NULL;
+		}
+		shm_unlock(shp);
+		goto out;
+	}
+	case IPC_RMID:
+	{
+		/*
+		 *	We cannot simply remove the file. The SVID states
+		 *	that the block remains until the last person
+		 *	detaches from it, then is deleted. A shmat() on
+		 *	an RMID segment is legal in older Linux and if 
+		 *	we change it apps break...
+		 *
+		 *	Instead we set a destroyed flag, and then blow
+		 *	the name away when the usage hits zero.
+		 */
+		down(&shm_ids.sem);
+		shp = shm_lock(shmid);
+		err = -EINVAL;
+		if (shp == NULL) 
+			goto out_up;
+		err = shm_checkid(shp, shmid);
+		if(err)
+			goto out_unlock_up;
+
+		if (current->euid != shp->shm_perm.uid &&
+		    current->euid != shp->shm_perm.cuid && 
+		    !capable(CAP_SYS_ADMIN)) {
+			err=-EPERM;
+			goto out_unlock_up;
+		}
+
+		err = security_shm_shmctl(shp, cmd);
+		if (err)
+			goto out_unlock_up;
+
+		if (shp->shm_nattch){
+			shp->shm_flags |= SHM_DEST;
+			/* Do not find it any more */
+			shp->shm_perm.key = IPC_PRIVATE;
+			shm_unlock(shp);
+		} else
+			shm_destroy (shp);
+		up(&shm_ids.sem);
+		goto out;
+	}
+
+	case IPC_SET:
+	{
+		if (copy_shmid_from_user (&setbuf, buf, version)) {
+			err = -EFAULT;
+			goto out;
+		}
+		if ((err = audit_ipc_perms(0, setbuf.uid, setbuf.gid, setbuf.mode)))
+			return err;
+		down(&shm_ids.sem);
+		shp = shm_lock(shmid);
+		err=-EINVAL;
+		if(shp==NULL)
+			goto out_up;
+		err = shm_checkid(shp,shmid);
+		if(err)
+			goto out_unlock_up;
+		err=-EPERM;
+		if (current->euid != shp->shm_perm.uid &&
+		    current->euid != shp->shm_perm.cuid && 
+		    !capable(CAP_SYS_ADMIN)) {
+			goto out_unlock_up;
+		}
+
+		err = security_shm_shmctl(shp, cmd);
+		if (err)
+			goto out_unlock_up;
+		
+		shp->shm_perm.uid = setbuf.uid;
+		shp->shm_perm.gid = setbuf.gid;
+		shp->shm_flags = (shp->shm_flags & ~S_IRWXUGO)
+			| (setbuf.mode & S_IRWXUGO);
+		shp->shm_ctim = get_seconds();
+		break;
+	}
+
+	default:
+		err = -EINVAL;
+		goto out;
+	}
+
+	err = 0;
+out_unlock_up:
+	shm_unlock(shp);
+out_up:
+	up(&shm_ids.sem);
+	goto out;
+out_unlock:
+	shm_unlock(shp);
+out:
+	return err;
+}
+
+/*
+ * Fix shmaddr, allocate descriptor, map shm, add attach descriptor to lists.
+ *
+ * NOTE! Despite the name, this is NOT a direct system call entrypoint. The
+ * "raddr" thing points to kernel space, and there has to be a wrapper around
+ * this.
+ */
+long do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr)
+{
+	struct shmid_kernel *shp;
+	unsigned long addr;
+	unsigned long size;
+	struct file * file;
+	int    err;
+	unsigned long flags;
+	unsigned long prot;
+	unsigned long o_flags;
+	int acc_mode;
+	void *user_addr;
+
+	if (shmid < 0) {
+		err = -EINVAL;
+		goto out;
+	} else if ((addr = (ulong)shmaddr)) {
+		if (addr & (SHMLBA-1)) {
+			if (shmflg & SHM_RND)
+				addr &= ~(SHMLBA-1);	   /* round down */
+			else
+#ifndef __ARCH_FORCE_SHMLBA
+				if (addr & ~PAGE_MASK)
+#endif
+					return -EINVAL;
+		}
+		flags = MAP_SHARED | MAP_FIXED;
+	} else {
+		if ((shmflg & SHM_REMAP))
+			return -EINVAL;
+
+		flags = MAP_SHARED;
+	}
+
+	if (shmflg & SHM_RDONLY) {
+		prot = PROT_READ;
+		o_flags = O_RDONLY;
+		acc_mode = S_IRUGO;
+	} else {
+		prot = PROT_READ | PROT_WRITE;
+		o_flags = O_RDWR;
+		acc_mode = S_IRUGO | S_IWUGO;
+	}
+	if (shmflg & SHM_EXEC) {
+		prot |= PROT_EXEC;
+		acc_mode |= S_IXUGO;
+	}
+
+	/*
+	 * We cannot rely on the fs check since SYSV IPC does have an
+	 * additional creator id...
+	 */
+	shp = shm_lock(shmid);
+	if(shp == NULL) {
+		err = -EINVAL;
+		goto out;
+	}
+	err = shm_checkid(shp,shmid);
+	if (err) {
+		shm_unlock(shp);
+		goto out;
+	}
+	if (ipcperms(&shp->shm_perm, acc_mode)) {
+		shm_unlock(shp);
+		err = -EACCES;
+		goto out;
+	}
+
+	err = security_shm_shmat(shp, shmaddr, shmflg);
+	if (err) {
+		shm_unlock(shp);
+		return err;
+	}
+		
+	file = shp->shm_file;
+	size = i_size_read(file->f_dentry->d_inode);
+	shp->shm_nattch++;
+	shm_unlock(shp);
+
+	down_write(&current->mm->mmap_sem);
+	if (addr && !(shmflg & SHM_REMAP)) {
+		user_addr = ERR_PTR(-EINVAL);
+		if (find_vma_intersection(current->mm, addr, addr + size))
+			goto invalid;
+		/*
+		 * If shm segment goes below stack, make sure there is some
+		 * space left for the stack to grow (at least 4 pages).
+		 */
+		if (addr < current->mm->start_stack &&
+		    addr > current->mm->start_stack - size - PAGE_SIZE * 5)
+			goto invalid;
+	}
+		
+	user_addr = (void*) do_mmap (file, addr, size, prot, flags, 0);
+
+invalid:
+	up_write(&current->mm->mmap_sem);
+
+	down (&shm_ids.sem);
+	if(!(shp = shm_lock(shmid)))
+		BUG();
+	shp->shm_nattch--;
+	if(shp->shm_nattch == 0 &&
+	   shp->shm_flags & SHM_DEST)
+		shm_destroy (shp);
+	else
+		shm_unlock(shp);
+	up (&shm_ids.sem);
+
+	*raddr = (unsigned long) user_addr;
+	err = 0;
+	if (IS_ERR(user_addr))
+		err = PTR_ERR(user_addr);
+out:
+	return err;
+}
+
+/*
+ * detach and kill segment if marked destroyed.
+ * The work is done in shm_close.
+ */
+asmlinkage long sys_shmdt(char __user *shmaddr)
+{
+	struct mm_struct *mm = current->mm;
+	struct vm_area_struct *vma, *next;
+	unsigned long addr = (unsigned long)shmaddr;
+	loff_t size = 0;
+	int retval = -EINVAL;
+
+	down_write(&mm->mmap_sem);
+
+	/*
+	 * This function tries to be smart and unmap shm segments that
+	 * were modified by partial mlock or munmap calls:
+	 * - It first determines the size of the shm segment that should be
+	 *   unmapped: It searches for a vma that is backed by shm and that
+	 *   started at address shmaddr. It records it's size and then unmaps
+	 *   it.
+	 * - Then it unmaps all shm vmas that started at shmaddr and that
+	 *   are within the initially determined size.
+	 * Errors from do_munmap are ignored: the function only fails if
+	 * it's called with invalid parameters or if it's called to unmap
+	 * a part of a vma. Both calls in this function are for full vmas,
+	 * the parameters are directly copied from the vma itself and always
+	 * valid - therefore do_munmap cannot fail. (famous last words?)
+	 */
+	/*
+	 * If it had been mremap()'d, the starting address would not
+	 * match the usual checks anyway. So assume all vma's are
+	 * above the starting address given.
+	 */
+	vma = find_vma(mm, addr);
+
+	while (vma) {
+		next = vma->vm_next;
+
+		/*
+		 * Check if the starting address would match, i.e. it's
+		 * a fragment created by mprotect() and/or munmap(), or it
+		 * otherwise it starts at this address with no hassles.
+		 */
+		if ((vma->vm_ops == &shm_vm_ops || is_vm_hugetlb_page(vma)) &&
+			(vma->vm_start - addr)/PAGE_SIZE == vma->vm_pgoff) {
+
+
+			size = vma->vm_file->f_dentry->d_inode->i_size;
+			do_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start);
+			/*
+			 * We discovered the size of the shm segment, so
+			 * break out of here and fall through to the next
+			 * loop that uses the size information to stop
+			 * searching for matching vma's.
+			 */
+			retval = 0;
+			vma = next;
+			break;
+		}
+		vma = next;
+	}
+
+	/*
+	 * We need look no further than the maximum address a fragment
+	 * could possibly have landed at. Also cast things to loff_t to
+	 * prevent overflows and make comparisions vs. equal-width types.
+	 */
+	while (vma && (loff_t)(vma->vm_end - addr) <= size) {
+		next = vma->vm_next;
+
+		/* finding a matching vma now does not alter retval */
+		if ((vma->vm_ops == &shm_vm_ops || is_vm_hugetlb_page(vma)) &&
+			(vma->vm_start - addr)/PAGE_SIZE == vma->vm_pgoff)
+
+			do_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start);
+		vma = next;
+	}
+
+	up_write(&mm->mmap_sem);
+	return retval;
+}
+
+#ifdef CONFIG_PROC_FS
+static int sysvipc_shm_read_proc(char *buffer, char **start, off_t offset, int length, int *eof, void *data)
+{
+	off_t pos = 0;
+	off_t begin = 0;
+	int i, len = 0;
+
+	down(&shm_ids.sem);
+	len += sprintf(buffer, "       key      shmid perms       size  cpid  lpid nattch   uid   gid  cuid  cgid      atime      dtime      ctime\n");
+
+	for(i = 0; i <= shm_ids.max_id; i++) {
+		struct shmid_kernel* shp;
+
+		shp = shm_lock(i);
+		if(shp!=NULL) {
+#define SMALL_STRING "%10d %10d  %4o %10u %5u %5u  %5d %5u %5u %5u %5u %10lu %10lu %10lu\n"
+#define BIG_STRING   "%10d %10d  %4o %21u %5u %5u  %5d %5u %5u %5u %5u %10lu %10lu %10lu\n"
+			char *format;
+
+			if (sizeof(size_t) <= sizeof(int))
+				format = SMALL_STRING;
+			else
+				format = BIG_STRING;
+			len += sprintf(buffer + len, format,
+				shp->shm_perm.key,
+				shm_buildid(i, shp->shm_perm.seq),
+				shp->shm_flags,
+				shp->shm_segsz,
+				shp->shm_cprid,
+				shp->shm_lprid,
+				is_file_hugepages(shp->shm_file) ? (file_count(shp->shm_file) - 1) : shp->shm_nattch,
+				shp->shm_perm.uid,
+				shp->shm_perm.gid,
+				shp->shm_perm.cuid,
+				shp->shm_perm.cgid,
+				shp->shm_atim,
+				shp->shm_dtim,
+				shp->shm_ctim);
+			shm_unlock(shp);
+
+			pos += len;
+			if(pos < offset) {
+				len = 0;
+				begin = pos;
+			}
+			if(pos > offset + length)
+				goto done;
+		}
+	}
+	*eof = 1;
+done:
+	up(&shm_ids.sem);
+	*start = buffer + (offset - begin);
+	len -= (offset - begin);
+	if(len > length)
+		len = length;
+	if(len < 0)
+		len = 0;
+	return len;
+}
+#endif
