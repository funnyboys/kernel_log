commit d2912cb15bdda8ba4a5dd73396ad62641af2f520
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 4 10:11:33 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 500
    
    Based on 2 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation #
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 4122 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Enrico Weigelt <info@metux.net>
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190604081206.933168790@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/virt/kvm/vfio.c b/virt/kvm/vfio.c
index 524cbd20379f..8fcbc50221c2 100644
--- a/virt/kvm/vfio.c
+++ b/virt/kvm/vfio.c
@@ -1,12 +1,9 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * VFIO-KVM bridge pseudo device
  *
  * Copyright (C) 2013 Red Hat, Inc.  All rights reserved.
  *     Author: Alex Williamson <alex.williamson@redhat.com>
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
  */
 
 #include <linux/errno.h>

commit b12ce36a43f29dbff0bca14c5a51c276aea5662f
Author: Ben Gardon <bgardon@google.com>
Date:   Mon Feb 11 11:02:49 2019 -0800

    kvm: Add memcg accounting to KVM allocations
    
    There are many KVM kernel memory allocations which are tied to the life of
    the VM process and should be charged to the VM process's cgroup. If the
    allocations aren't tied to the process, the OOM killer will not know
    that killing the process will free the associated kernel memory.
    Add __GFP_ACCOUNT flags to many of the allocations which are not yet being
    charged to the VM process's cgroup.
    
    Tested:
            Ran all kvm-unit-tests on a 64 bit Haswell machine, the patch
            introduced no new failures.
            Ran a kernel memory accounting test which creates a VM to touch
            memory and then checks that the kernel memory allocated for the
            process is within certain bounds.
            With this patch we account for much more of the vmalloc and slab memory
            allocated for the VM.
    
    There remain a few allocations which should be charged to the VM's
    cgroup but are not. In they include:
            vcpu->run
            kvm->coalesced_mmio_ring
    There allocations are unaccounted in this patch because they are mapped
    to userspace, and accounting them to a cgroup causes problems. This
    should be addressed in a future patch.
    
    Signed-off-by: Ben Gardon <bgardon@google.com>
    Reviewed-by: Shakeel Butt <shakeelb@google.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/virt/kvm/vfio.c b/virt/kvm/vfio.c
index d99850c462a1..524cbd20379f 100644
--- a/virt/kvm/vfio.c
+++ b/virt/kvm/vfio.c
@@ -219,7 +219,7 @@ static int kvm_vfio_set_group(struct kvm_device *dev, long attr, u64 arg)
 			}
 		}
 
-		kvg = kzalloc(sizeof(*kvg), GFP_KERNEL);
+		kvg = kzalloc(sizeof(*kvg), GFP_KERNEL_ACCOUNT);
 		if (!kvg) {
 			mutex_unlock(&kv->lock);
 			kvm_vfio_group_put_external_user(vfio_group);
@@ -405,7 +405,7 @@ static int kvm_vfio_create(struct kvm_device *dev, u32 type)
 		if (tmp->ops == &kvm_vfio_ops)
 			return -EBUSY;
 
-	kv = kzalloc(sizeof(*kv), GFP_KERNEL);
+	kv = kzalloc(sizeof(*kv), GFP_KERNEL_ACCOUNT);
 	if (!kv)
 		return -ENOMEM;
 

commit 5d6dee80a1e94cc284d03e06d930e60e8d3ecf7d
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Wed Jun 28 13:50:05 2017 -0600

    vfio: New external user group/file match
    
    At the point where the kvm-vfio pseudo device wants to release its
    vfio group reference, we can't always acquire a new reference to make
    that happen.  The group can be in a state where we wouldn't allow a
    new reference to be added.  This new helper function allows a caller
    to match a file to a group to facilitate this.  Given a file and
    group, report if they match.  Thus the caller needs to already have a
    group reference to match to the file.  This allows the deletion of a
    group without acquiring a new reference.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Reviewed-by: Eric Auger <eric.auger@redhat.com>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>
    Tested-by: Eric Auger <eric.auger@redhat.com>
    Cc: stable@vger.kernel.org

diff --git a/virt/kvm/vfio.c b/virt/kvm/vfio.c
index 6e002d0f3191..d99850c462a1 100644
--- a/virt/kvm/vfio.c
+++ b/virt/kvm/vfio.c
@@ -51,6 +51,22 @@ static struct vfio_group *kvm_vfio_group_get_external_user(struct file *filep)
 	return vfio_group;
 }
 
+static bool kvm_vfio_external_group_match_file(struct vfio_group *group,
+					       struct file *filep)
+{
+	bool ret, (*fn)(struct vfio_group *, struct file *);
+
+	fn = symbol_get(vfio_external_group_match_file);
+	if (!fn)
+		return false;
+
+	ret = fn(group, filep);
+
+	symbol_put(vfio_external_group_match_file);
+
+	return ret;
+}
+
 static void kvm_vfio_group_put_external_user(struct vfio_group *vfio_group)
 {
 	void (*fn)(struct vfio_group *);
@@ -231,18 +247,13 @@ static int kvm_vfio_set_group(struct kvm_device *dev, long attr, u64 arg)
 		if (!f.file)
 			return -EBADF;
 
-		vfio_group = kvm_vfio_group_get_external_user(f.file);
-		fdput(f);
-
-		if (IS_ERR(vfio_group))
-			return PTR_ERR(vfio_group);
-
 		ret = -ENOENT;
 
 		mutex_lock(&kv->lock);
 
 		list_for_each_entry(kvg, &kv->group_list, node) {
-			if (kvg->vfio_group != vfio_group)
+			if (!kvm_vfio_external_group_match_file(kvg->vfio_group,
+								f.file))
 				continue;
 
 			list_del(&kvg->node);
@@ -260,7 +271,7 @@ static int kvm_vfio_set_group(struct kvm_device *dev, long attr, u64 arg)
 
 		mutex_unlock(&kv->lock);
 
-		kvm_vfio_group_put_external_user(vfio_group);
+		fdput(f);
 
 		kvm_vfio_update_coherency(dev);
 

commit e323369b2e204da4dc771bbddceef986f4bf85d5
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Wed Jun 28 13:49:52 2017 -0600

    kvm-vfio: Decouple only when we match a group
    
    Unset-KVM and decrement-assignment only when we find the group in our
    list.  Otherwise we can get out of sync if the user triggers this for
    groups that aren't currently on our list.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Reviewed-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Reviewed-by: Eric Auger <eric.auger@redhat.com>
    Tested-by: Eric Auger <eric.auger@redhat.com>
    Acked-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: stable@vger.kernel.org

diff --git a/virt/kvm/vfio.c b/virt/kvm/vfio.c
index 37d9118fd84b..6e002d0f3191 100644
--- a/virt/kvm/vfio.c
+++ b/virt/kvm/vfio.c
@@ -246,21 +246,20 @@ static int kvm_vfio_set_group(struct kvm_device *dev, long attr, u64 arg)
 				continue;
 
 			list_del(&kvg->node);
+			kvm_arch_end_assignment(dev->kvm);
+#ifdef CONFIG_SPAPR_TCE_IOMMU
+			kvm_spapr_tce_release_vfio_group(dev->kvm,
+							 kvg->vfio_group);
+#endif
+			kvm_vfio_group_set_kvm(kvg->vfio_group, NULL);
 			kvm_vfio_group_put_external_user(kvg->vfio_group);
 			kfree(kvg);
 			ret = 0;
 			break;
 		}
 
-		kvm_arch_end_assignment(dev->kvm);
-
 		mutex_unlock(&kv->lock);
 
-#ifdef CONFIG_SPAPR_TCE_IOMMU
-		kvm_spapr_tce_release_vfio_group(dev->kvm, vfio_group);
-#endif
-		kvm_vfio_group_set_kvm(vfio_group, NULL);
-
 		kvm_vfio_group_put_external_user(vfio_group);
 
 		kvm_vfio_update_coherency(dev);

commit 121f80ba68f1a5779a36d7b3247206e60e0a7418
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Wed Mar 22 15:21:56 2017 +1100

    KVM: PPC: VFIO: Add in-kernel acceleration for VFIO
    
    This allows the host kernel to handle H_PUT_TCE, H_PUT_TCE_INDIRECT
    and H_STUFF_TCE requests targeted an IOMMU TCE table used for VFIO
    without passing them to user space which saves time on switching
    to user space and back.
    
    This adds H_PUT_TCE/H_PUT_TCE_INDIRECT/H_STUFF_TCE handlers to KVM.
    KVM tries to handle a TCE request in the real mode, if failed
    it passes the request to the virtual mode to complete the operation.
    If it a virtual mode handler fails, the request is passed to
    the user space; this is not expected to happen though.
    
    To avoid dealing with page use counters (which is tricky in real mode),
    this only accelerates SPAPR TCE IOMMU v2 clients which are required
    to pre-register the userspace memory. The very first TCE request will
    be handled in the VFIO SPAPR TCE driver anyway as the userspace view
    of the TCE table (iommu_table::it_userspace) is not allocated till
    the very first mapping happens and we cannot call vmalloc in real mode.
    
    If we fail to update a hardware IOMMU table unexpected reason, we just
    clear it and move on as there is nothing really we can do about it -
    for example, if we hot plug a VFIO device to a guest, existing TCE tables
    will be mirrored automatically to the hardware and there is no interface
    to report to the guest about possible failures.
    
    This adds new attribute - KVM_DEV_VFIO_GROUP_SET_SPAPR_TCE - to
    the VFIO KVM device. It takes a VFIO group fd and SPAPR TCE table fd
    and associates a physical IOMMU table with the SPAPR TCE table (which
    is a guest view of the hardware IOMMU table). The iommu_table object
    is cached and referenced so we do not have to look up for it in real mode.
    
    This does not implement the UNSET counterpart as there is no use for it -
    once the acceleration is enabled, the existing userspace won't
    disable it unless a VFIO container is destroyed; this adds necessary
    cleanup to the KVM_DEV_VFIO_GROUP_DEL handler.
    
    This advertises the new KVM_CAP_SPAPR_TCE_VFIO capability to the user
    space.
    
    This adds real mode version of WARN_ON_ONCE() as the generic version
    causes problems with rcu_sched. Since we testing what vmalloc_to_phys()
    returns in the code, this also adds a check for already existing
    vmalloc_to_phys() call in kvmppc_rm_h_put_tce_indirect().
    
    This finally makes use of vfio_external_user_iommu_id() which was
    introduced quite some time ago and was considered for removal.
    
    Tests show that this patch increases transmission speed from 220MB/s
    to 750..1020MB/s on 10Gb network (Chelsea CXGB3 10Gb ethernet card).
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/virt/kvm/vfio.c b/virt/kvm/vfio.c
index d32f239eb471..37d9118fd84b 100644
--- a/virt/kvm/vfio.c
+++ b/virt/kvm/vfio.c
@@ -20,6 +20,10 @@
 #include <linux/vfio.h>
 #include "vfio.h"
 
+#ifdef CONFIG_SPAPR_TCE_IOMMU
+#include <asm/kvm_ppc.h>
+#endif
+
 struct kvm_vfio_group {
 	struct list_head node;
 	struct vfio_group *vfio_group;
@@ -89,6 +93,47 @@ static bool kvm_vfio_group_is_coherent(struct vfio_group *vfio_group)
 	return ret > 0;
 }
 
+#ifdef CONFIG_SPAPR_TCE_IOMMU
+static int kvm_vfio_external_user_iommu_id(struct vfio_group *vfio_group)
+{
+	int (*fn)(struct vfio_group *);
+	int ret = -EINVAL;
+
+	fn = symbol_get(vfio_external_user_iommu_id);
+	if (!fn)
+		return ret;
+
+	ret = fn(vfio_group);
+
+	symbol_put(vfio_external_user_iommu_id);
+
+	return ret;
+}
+
+static struct iommu_group *kvm_vfio_group_get_iommu_group(
+		struct vfio_group *group)
+{
+	int group_id = kvm_vfio_external_user_iommu_id(group);
+
+	if (group_id < 0)
+		return NULL;
+
+	return iommu_group_get_by_id(group_id);
+}
+
+static void kvm_spapr_tce_release_vfio_group(struct kvm *kvm,
+		struct vfio_group *vfio_group)
+{
+	struct iommu_group *grp = kvm_vfio_group_get_iommu_group(vfio_group);
+
+	if (WARN_ON_ONCE(!grp))
+		return;
+
+	kvm_spapr_tce_release_iommu_group(kvm, grp);
+	iommu_group_put(grp);
+}
+#endif
+
 /*
  * Groups can use the same or different IOMMU domains.  If the same then
  * adding a new group may change the coherency of groups we've previously
@@ -211,6 +256,9 @@ static int kvm_vfio_set_group(struct kvm_device *dev, long attr, u64 arg)
 
 		mutex_unlock(&kv->lock);
 
+#ifdef CONFIG_SPAPR_TCE_IOMMU
+		kvm_spapr_tce_release_vfio_group(dev->kvm, vfio_group);
+#endif
 		kvm_vfio_group_set_kvm(vfio_group, NULL);
 
 		kvm_vfio_group_put_external_user(vfio_group);
@@ -218,6 +266,57 @@ static int kvm_vfio_set_group(struct kvm_device *dev, long attr, u64 arg)
 		kvm_vfio_update_coherency(dev);
 
 		return ret;
+
+#ifdef CONFIG_SPAPR_TCE_IOMMU
+	case KVM_DEV_VFIO_GROUP_SET_SPAPR_TCE: {
+		struct kvm_vfio_spapr_tce param;
+		struct kvm_vfio *kv = dev->private;
+		struct vfio_group *vfio_group;
+		struct kvm_vfio_group *kvg;
+		struct fd f;
+		struct iommu_group *grp;
+
+		if (copy_from_user(&param, (void __user *)arg,
+				sizeof(struct kvm_vfio_spapr_tce)))
+			return -EFAULT;
+
+		f = fdget(param.groupfd);
+		if (!f.file)
+			return -EBADF;
+
+		vfio_group = kvm_vfio_group_get_external_user(f.file);
+		fdput(f);
+
+		if (IS_ERR(vfio_group))
+			return PTR_ERR(vfio_group);
+
+		grp = kvm_vfio_group_get_iommu_group(vfio_group);
+		if (WARN_ON_ONCE(!grp)) {
+			kvm_vfio_group_put_external_user(vfio_group);
+			return -EIO;
+		}
+
+		ret = -ENOENT;
+
+		mutex_lock(&kv->lock);
+
+		list_for_each_entry(kvg, &kv->group_list, node) {
+			if (kvg->vfio_group != vfio_group)
+				continue;
+
+			ret = kvm_spapr_tce_attach_iommu_group(dev->kvm,
+					param.tablefd, grp);
+			break;
+		}
+
+		mutex_unlock(&kv->lock);
+
+		iommu_group_put(grp);
+		kvm_vfio_group_put_external_user(vfio_group);
+
+		return ret;
+	}
+#endif /* CONFIG_SPAPR_TCE_IOMMU */
 	}
 
 	return -ENXIO;
@@ -242,6 +341,9 @@ static int kvm_vfio_has_attr(struct kvm_device *dev,
 		switch (attr->attr) {
 		case KVM_DEV_VFIO_GROUP_ADD:
 		case KVM_DEV_VFIO_GROUP_DEL:
+#ifdef CONFIG_SPAPR_TCE_IOMMU
+		case KVM_DEV_VFIO_GROUP_SET_SPAPR_TCE:
+#endif
 			return 0;
 		}
 
@@ -257,6 +359,9 @@ static void kvm_vfio_destroy(struct kvm_device *dev)
 	struct kvm_vfio_group *kvg, *tmp;
 
 	list_for_each_entry_safe(kvg, tmp, &kv->group_list, node) {
+#ifdef CONFIG_SPAPR_TCE_IOMMU
+		kvm_spapr_tce_release_vfio_group(dev->kvm, kvg->vfio_group);
+#endif
 		kvm_vfio_group_set_kvm(kvg->vfio_group, NULL);
 		kvm_vfio_group_put_external_user(kvg->vfio_group);
 		list_del(&kvg->node);

commit 2fc1bec15883537cf8b35fd628cca33ca25736a5
Author: Jike Song <jike.song@intel.com>
Date:   Thu Dec 1 13:20:07 2016 +0800

    kvm: set/clear kvm to/from vfio_group when group add/delete
    
    Sometimes users need to be aware when a vfio_group attaches to a
    KVM or detaches from it. KVM already calls get/put method from vfio to
    manipulate the vfio_group reference, it can notify vfio_group in
    a similar way.
    
    Cc: Kirti Wankhede <kwankhede@nvidia.com>
    Cc: Xiao Guangrong <guangrong.xiao@linux.intel.com>
    Signed-off-by: Jike Song <jike.song@intel.com>
    Acked-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>

diff --git a/virt/kvm/vfio.c b/virt/kvm/vfio.c
index 1dd087da6f31..d32f239eb471 100644
--- a/virt/kvm/vfio.c
+++ b/virt/kvm/vfio.c
@@ -60,6 +60,19 @@ static void kvm_vfio_group_put_external_user(struct vfio_group *vfio_group)
 	symbol_put(vfio_group_put_external_user);
 }
 
+static void kvm_vfio_group_set_kvm(struct vfio_group *group, struct kvm *kvm)
+{
+	void (*fn)(struct vfio_group *, struct kvm *);
+
+	fn = symbol_get(vfio_group_set_kvm);
+	if (!fn)
+		return;
+
+	fn(group, kvm);
+
+	symbol_put(vfio_group_set_kvm);
+}
+
 static bool kvm_vfio_group_is_coherent(struct vfio_group *vfio_group)
 {
 	long (*fn)(struct vfio_group *, unsigned long);
@@ -159,6 +172,8 @@ static int kvm_vfio_set_group(struct kvm_device *dev, long attr, u64 arg)
 
 		mutex_unlock(&kv->lock);
 
+		kvm_vfio_group_set_kvm(vfio_group, dev->kvm);
+
 		kvm_vfio_update_coherency(dev);
 
 		return 0;
@@ -196,6 +211,8 @@ static int kvm_vfio_set_group(struct kvm_device *dev, long attr, u64 arg)
 
 		mutex_unlock(&kv->lock);
 
+		kvm_vfio_group_set_kvm(vfio_group, NULL);
+
 		kvm_vfio_group_put_external_user(vfio_group);
 
 		kvm_vfio_update_coherency(dev);
@@ -240,6 +257,7 @@ static void kvm_vfio_destroy(struct kvm_device *dev)
 	struct kvm_vfio_group *kvg, *tmp;
 
 	list_for_each_entry_safe(kvg, tmp, &kv->group_list, node) {
+		kvm_vfio_group_set_kvm(kvg->vfio_group, NULL);
 		kvm_vfio_group_put_external_user(kvg->vfio_group);
 		list_del(&kvg->node);
 		kfree(kvg);

commit 5544eb9b81940647b8fad1f251b37cbe2819ce44
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Tue Jul 7 15:41:58 2015 +0200

    KVM: count number of assigned devices
    
    If there are no assigned devices, the guest PAT are not providing
    any useful information and can be overridden to writeback; VMX
    always does this because it has the "IPAT" bit in its extended
    page table entries, but SVM does not have anything similar.
    Hook into VFIO and legacy device assignment so that they
    provide this information to KVM.
    
    Reviewed-by: Alex Williamson <alex.williamson@redhat.com>
    Tested-by: Joerg Roedel <jroedel@suse.de>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/virt/kvm/vfio.c b/virt/kvm/vfio.c
index 620e37f741b8..1dd087da6f31 100644
--- a/virt/kvm/vfio.c
+++ b/virt/kvm/vfio.c
@@ -155,6 +155,8 @@ static int kvm_vfio_set_group(struct kvm_device *dev, long attr, u64 arg)
 		list_add_tail(&kvg->node, &kv->group_list);
 		kvg->vfio_group = vfio_group;
 
+		kvm_arch_start_assignment(dev->kvm);
+
 		mutex_unlock(&kv->lock);
 
 		kvm_vfio_update_coherency(dev);
@@ -190,6 +192,8 @@ static int kvm_vfio_set_group(struct kvm_device *dev, long attr, u64 arg)
 			break;
 		}
 
+		kvm_arch_end_assignment(dev->kvm);
+
 		mutex_unlock(&kv->lock);
 
 		kvm_vfio_group_put_external_user(vfio_group);
@@ -239,6 +243,7 @@ static void kvm_vfio_destroy(struct kvm_device *dev)
 		kvm_vfio_group_put_external_user(kvg->vfio_group);
 		list_del(&kvg->node);
 		kfree(kvg);
+		kvm_arch_end_assignment(dev->kvm);
 	}
 
 	kvm_vfio_update_coherency(dev);

commit 571ee1b6859869a09ed718d390aac2b9414646a2
Author: Wanpeng Li <wanpeng.li@linux.intel.com>
Date:   Thu Oct 9 18:30:08 2014 +0800

    kvm: vfio: fix unregister kvm_device_ops of vfio
    
    After commit 80ce163 (KVM: VFIO: register kvm_device_ops dynamically),
    kvm_device_ops of vfio can be registered dynamically. Commit 3c3c29fd
    (kvm-vfio: do not use module_init) move the dynamic register invoked by
    kvm_init in order to fix broke unloading of the kvm module. However,
    kvm_device_ops of vfio is unregistered after rmmod kvm-intel module
    which lead to device type collision detection warning after kvm-intel
    module reinsmod.
    
        WARNING: CPU: 1 PID: 10358 at /root/cathy/kvm/arch/x86/kvm/../../../virt/kvm/kvm_main.c:3289 kvm_init+0x234/0x282 [kvm]()
        Modules linked in: kvm_intel(O+) kvm(O) nfsv3 nfs_acl auth_rpcgss oid_registry nfsv4 dns_resolver nfs fscache lockd sunrpc pci_stub bridge stp llc autofs4 8021q cpufreq_ondemand ipv6 joydev microcode pcspkr igb i2c_algo_bit ehci_pci ehci_hcd e1000e i2c_i801 ixgbe ptp pps_core hwmon mdio tpm_tis tpm ipmi_si ipmi_msghandler acpi_cpufreq isci libsas scsi_transport_sas button dm_mirror dm_region_hash dm_log dm_mod [last unloaded: kvm_intel]
        CPU: 1 PID: 10358 Comm: insmod Tainted: G        W  O   3.17.0-rc1 #2
        Hardware name: Intel Corporation S2600CP/S2600CP, BIOS RMLSDP.86I.00.29.D696.1311111329 11/11/2013
         0000000000000cd9 ffff880ff08cfd18 ffffffff814a61d9 0000000000000cd9
         0000000000000000 ffff880ff08cfd58 ffffffff810417b7 ffff880ff08cfd48
         ffffffffa045bcac ffffffffa049c420 0000000000000040 00000000000000ff
        Call Trace:
         [<ffffffff814a61d9>] dump_stack+0x49/0x60
         [<ffffffff810417b7>] warn_slowpath_common+0x7c/0x96
         [<ffffffffa045bcac>] ? kvm_init+0x234/0x282 [kvm]
         [<ffffffff810417e6>] warn_slowpath_null+0x15/0x17
         [<ffffffffa045bcac>] kvm_init+0x234/0x282 [kvm]
         [<ffffffffa016e995>] vmx_init+0x1bf/0x42a [kvm_intel]
         [<ffffffffa016e7d6>] ? vmx_check_processor_compat+0x64/0x64 [kvm_intel]
         [<ffffffff810002ab>] do_one_initcall+0xe3/0x170
         [<ffffffff811168a9>] ? __vunmap+0xad/0xb8
         [<ffffffff8109c58f>] do_init_module+0x2b/0x174
         [<ffffffff8109d414>] load_module+0x43e/0x569
         [<ffffffff8109c6d8>] ? do_init_module+0x174/0x174
         [<ffffffff8109c75a>] ? copy_module_from_user+0x39/0x82
         [<ffffffff8109b7dd>] ? module_sect_show+0x20/0x20
         [<ffffffff8109d65f>] SyS_init_module+0x54/0x81
         [<ffffffff814a9a12>] system_call_fastpath+0x16/0x1b
        ---[ end trace 0626f4a3ddea56f3 ]---
    
    The bug can be reproduced by:
    
        rmmod kvm_intel.ko
        insmod kvm_intel.ko
    
    without rmmod/insmod kvm.ko
    This patch fixes the bug by unregistering kvm_device_ops of vfio when the
    kvm-intel module is removed.
    
    Reported-by: Liu Rongrong <rongrongx.liu@intel.com>
    Fixes: 3c3c29fd0d7cddc32862c350d0700ce69953e3bd
    Signed-off-by: Wanpeng Li <wanpeng.li@linux.intel.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/virt/kvm/vfio.c b/virt/kvm/vfio.c
index 281e7cf2b8e5..620e37f741b8 100644
--- a/virt/kvm/vfio.c
+++ b/virt/kvm/vfio.c
@@ -283,3 +283,8 @@ int kvm_vfio_ops_init(void)
 {
 	return kvm_register_device_ops(&kvm_vfio_ops, KVM_DEV_TYPE_VFIO);
 }
+
+void kvm_vfio_ops_exit(void)
+{
+	kvm_unregister_device_ops(KVM_DEV_TYPE_VFIO);
+}

commit 3c3c29fd0d7cddc32862c350d0700ce69953e3bd
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Wed Sep 24 13:02:46 2014 +0200

    kvm-vfio: do not use module_init
    
    /me got confused between the kernel and QEMU.  In the kernel, you can
    only have one module_init function, and it will prevent unloading the
    module unless you also have the corresponding module_exit function.
    
    So, commit 80ce1639727e (KVM: VFIO: register kvm_device_ops dynamically,
    2014-09-02) broke unloading of the kvm module, by adding a module_init
    function and no module_exit.
    
    Repair it by making kvm_vfio_ops_init weak, and checking it in
    kvm_init.
    
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Gleb Natapov <gleb@kernel.org>
    Cc: Alex Williamson <Alex.Williamson@redhat.com>
    Fixes: 80ce1639727e9d38729c34f162378508c307ca25
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/virt/kvm/vfio.c b/virt/kvm/vfio.c
index bb11b36ee8a2..281e7cf2b8e5 100644
--- a/virt/kvm/vfio.c
+++ b/virt/kvm/vfio.c
@@ -18,6 +18,7 @@
 #include <linux/slab.h>
 #include <linux/uaccess.h>
 #include <linux/vfio.h>
+#include "vfio.h"
 
 struct kvm_vfio_group {
 	struct list_head node;
@@ -278,8 +279,7 @@ static int kvm_vfio_create(struct kvm_device *dev, u32 type)
 	return 0;
 }
 
-static int __init kvm_vfio_ops_init(void)
+int kvm_vfio_ops_init(void)
 {
 	return kvm_register_device_ops(&kvm_vfio_ops, KVM_DEV_TYPE_VFIO);
 }
-module_init(kvm_vfio_ops_init);

commit 80ce1639727e9d38729c34f162378508c307ca25
Author: Will Deacon <will.deacon@arm.com>
Date:   Tue Sep 2 10:27:36 2014 +0100

    KVM: VFIO: register kvm_device_ops dynamically
    
    Now that we have a dynamic means to register kvm_device_ops, use that
    for the VFIO kvm device, instead of relying on the static table.
    
    This is achieved by a module_init call to register the ops with KVM.
    
    Cc: Gleb Natapov <gleb@kernel.org>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Acked-by: Alex Williamson <Alex.Williamson@redhat.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/virt/kvm/vfio.c b/virt/kvm/vfio.c
index ba1a93f935c7..bb11b36ee8a2 100644
--- a/virt/kvm/vfio.c
+++ b/virt/kvm/vfio.c
@@ -246,6 +246,16 @@ static void kvm_vfio_destroy(struct kvm_device *dev)
 	kfree(dev); /* alloc by kvm_ioctl_create_device, free by .destroy */
 }
 
+static int kvm_vfio_create(struct kvm_device *dev, u32 type);
+
+static struct kvm_device_ops kvm_vfio_ops = {
+	.name = "kvm-vfio",
+	.create = kvm_vfio_create,
+	.destroy = kvm_vfio_destroy,
+	.set_attr = kvm_vfio_set_attr,
+	.has_attr = kvm_vfio_has_attr,
+};
+
 static int kvm_vfio_create(struct kvm_device *dev, u32 type)
 {
 	struct kvm_device *tmp;
@@ -268,10 +278,8 @@ static int kvm_vfio_create(struct kvm_device *dev, u32 type)
 	return 0;
 }
 
-struct kvm_device_ops kvm_vfio_ops = {
-	.name = "kvm-vfio",
-	.create = kvm_vfio_create,
-	.destroy = kvm_vfio_destroy,
-	.set_attr = kvm_vfio_set_attr,
-	.has_attr = kvm_vfio_has_attr,
-};
+static int __init kvm_vfio_ops_init(void)
+{
+	return kvm_register_device_ops(&kvm_vfio_ops, KVM_DEV_TYPE_VFIO);
+}
+module_init(kvm_vfio_ops_init);

commit 9d830d47c7a756da6f0b55fa25d51eec0739eb02
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Wed Feb 26 11:38:40 2014 -0700

    kvm/vfio: Support for DMA coherent IOMMUs
    
    VFIO now has support for using the IOMMU_CACHE flag and a mechanism
    for an external user to test the current operating mode of the IOMMU.
    Add support for this to the kvm-vfio pseudo device so that we only
    register noncoherent DMA when necessary.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Cc: Gleb Natapov <gleb@kernel.org>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Acked-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/virt/kvm/vfio.c b/virt/kvm/vfio.c
index b4f9507ae650..ba1a93f935c7 100644
--- a/virt/kvm/vfio.c
+++ b/virt/kvm/vfio.c
@@ -59,6 +59,22 @@ static void kvm_vfio_group_put_external_user(struct vfio_group *vfio_group)
 	symbol_put(vfio_group_put_external_user);
 }
 
+static bool kvm_vfio_group_is_coherent(struct vfio_group *vfio_group)
+{
+	long (*fn)(struct vfio_group *, unsigned long);
+	long ret;
+
+	fn = symbol_get(vfio_external_check_extension);
+	if (!fn)
+		return false;
+
+	ret = fn(vfio_group, VFIO_DMA_CC_IOMMU);
+
+	symbol_put(vfio_external_check_extension);
+
+	return ret > 0;
+}
+
 /*
  * Groups can use the same or different IOMMU domains.  If the same then
  * adding a new group may change the coherency of groups we've previously
@@ -75,13 +91,10 @@ static void kvm_vfio_update_coherency(struct kvm_device *dev)
 	mutex_lock(&kv->lock);
 
 	list_for_each_entry(kvg, &kv->group_list, node) {
-		/*
-		 * TODO: We need an interface to check the coherency of
-		 * the IOMMU domain this group is using.  For now, assume
-		 * it's always noncoherent.
-		 */
-		noncoherent = true;
-		break;
+		if (!kvm_vfio_group_is_coherent(kvg->vfio_group)) {
+			noncoherent = true;
+			break;
+		}
 	}
 
 	if (noncoherent != kv->noncoherent) {

commit e81d1ad32753cdeaef56b9bffe3b8ab7b5c776e5
Author: Paul Bolle <pebolle@tiscali.nl>
Date:   Fri Jan 10 01:28:46 2014 +0100

    kvm: vfio: silence GCC warning
    
    Building vfio.o triggers a GCC warning (when building for 32 bits x86):
        arch/x86/kvm/../../../virt/kvm/vfio.c: In function 'kvm_vfio_set_group':
        arch/x86/kvm/../../../virt/kvm/vfio.c:104:22: warning: cast to pointer from integer of different size [-Wint-to-pointer-cast]
          void __user *argp = (void __user *)arg;
                              ^
    
    Silence this warning by casting arg to unsigned long.
    
    argp's current type, "void __user *", is always casted to "int32_t
    __user *". So its type might as well be changed to "int32_t __user *".
    
    Signed-off-by: Paul Bolle <pebolle@tiscali.nl>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/virt/kvm/vfio.c b/virt/kvm/vfio.c
index ca4260e35037..b4f9507ae650 100644
--- a/virt/kvm/vfio.c
+++ b/virt/kvm/vfio.c
@@ -101,14 +101,14 @@ static int kvm_vfio_set_group(struct kvm_device *dev, long attr, u64 arg)
 	struct kvm_vfio *kv = dev->private;
 	struct vfio_group *vfio_group;
 	struct kvm_vfio_group *kvg;
-	void __user *argp = (void __user *)arg;
+	int32_t __user *argp = (int32_t __user *)(unsigned long)arg;
 	struct fd f;
 	int32_t fd;
 	int ret;
 
 	switch (attr) {
 	case KVM_DEV_VFIO_GROUP_ADD:
-		if (get_user(fd, (int32_t __user *)argp))
+		if (get_user(fd, argp))
 			return -EFAULT;
 
 		f = fdget(fd);
@@ -148,7 +148,7 @@ static int kvm_vfio_set_group(struct kvm_device *dev, long attr, u64 arg)
 		return 0;
 
 	case KVM_DEV_VFIO_GROUP_DEL:
-		if (get_user(fd, (int32_t __user *)argp))
+		if (get_user(fd, argp))
 			return -EFAULT;
 
 		f = fdget(fd);

commit e0f0bbc527f6e9c0261f1d16b2a0b47612b7f235
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Wed Oct 30 11:02:30 2013 -0600

    kvm: Create non-coherent DMA registeration
    
    We currently use some ad-hoc arch variables tied to legacy KVM device
    assignment to manage emulation of instructions that depend on whether
    non-coherent DMA is present.  Create an interface for this, adapting
    legacy KVM device assignment and adding VFIO via the KVM-VFIO device.
    For now we assume that non-coherent DMA is possible any time we have a
    VFIO group.  Eventually an interface can be developed as part of the
    VFIO external user interface to query the coherency of a group.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/virt/kvm/vfio.c b/virt/kvm/vfio.c
index 597c258245ea..ca4260e35037 100644
--- a/virt/kvm/vfio.c
+++ b/virt/kvm/vfio.c
@@ -27,6 +27,7 @@ struct kvm_vfio_group {
 struct kvm_vfio {
 	struct list_head group_list;
 	struct mutex lock;
+	bool noncoherent;
 };
 
 static struct vfio_group *kvm_vfio_group_get_external_user(struct file *filep)
@@ -58,6 +59,43 @@ static void kvm_vfio_group_put_external_user(struct vfio_group *vfio_group)
 	symbol_put(vfio_group_put_external_user);
 }
 
+/*
+ * Groups can use the same or different IOMMU domains.  If the same then
+ * adding a new group may change the coherency of groups we've previously
+ * been told about.  We don't want to care about any of that so we retest
+ * each group and bail as soon as we find one that's noncoherent.  This
+ * means we only ever [un]register_noncoherent_dma once for the whole device.
+ */
+static void kvm_vfio_update_coherency(struct kvm_device *dev)
+{
+	struct kvm_vfio *kv = dev->private;
+	bool noncoherent = false;
+	struct kvm_vfio_group *kvg;
+
+	mutex_lock(&kv->lock);
+
+	list_for_each_entry(kvg, &kv->group_list, node) {
+		/*
+		 * TODO: We need an interface to check the coherency of
+		 * the IOMMU domain this group is using.  For now, assume
+		 * it's always noncoherent.
+		 */
+		noncoherent = true;
+		break;
+	}
+
+	if (noncoherent != kv->noncoherent) {
+		kv->noncoherent = noncoherent;
+
+		if (kv->noncoherent)
+			kvm_arch_register_noncoherent_dma(dev->kvm);
+		else
+			kvm_arch_unregister_noncoherent_dma(dev->kvm);
+	}
+
+	mutex_unlock(&kv->lock);
+}
+
 static int kvm_vfio_set_group(struct kvm_device *dev, long attr, u64 arg)
 {
 	struct kvm_vfio *kv = dev->private;
@@ -105,6 +143,8 @@ static int kvm_vfio_set_group(struct kvm_device *dev, long attr, u64 arg)
 
 		mutex_unlock(&kv->lock);
 
+		kvm_vfio_update_coherency(dev);
+
 		return 0;
 
 	case KVM_DEV_VFIO_GROUP_DEL:
@@ -140,6 +180,8 @@ static int kvm_vfio_set_group(struct kvm_device *dev, long attr, u64 arg)
 
 		kvm_vfio_group_put_external_user(vfio_group);
 
+		kvm_vfio_update_coherency(dev);
+
 		return ret;
 	}
 
@@ -185,6 +227,8 @@ static void kvm_vfio_destroy(struct kvm_device *dev)
 		kfree(kvg);
 	}
 
+	kvm_vfio_update_coherency(dev);
+
 	kfree(kv);
 	kfree(dev); /* alloc by kvm_ioctl_create_device, free by .destroy */
 }

commit ec53500fae421e07c5d035918ca454a429732ef4
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Wed Oct 30 11:02:17 2013 -0600

    kvm: Add VFIO device
    
    So far we've succeeded at making KVM and VFIO mostly unaware of each
    other, but areas are cropping up where a connection beyond eventfds
    and irqfds needs to be made.  This patch introduces a KVM-VFIO device
    that is meant to be a gateway for such interaction.  The user creates
    the device and can add and remove VFIO groups to it via file
    descriptors.  When a group is added, KVM verifies the group is valid
    and gets a reference to it via the VFIO external user interface.
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/virt/kvm/vfio.c b/virt/kvm/vfio.c
new file mode 100644
index 000000000000..597c258245ea
--- /dev/null
+++ b/virt/kvm/vfio.c
@@ -0,0 +1,220 @@
+/*
+ * VFIO-KVM bridge pseudo device
+ *
+ * Copyright (C) 2013 Red Hat, Inc.  All rights reserved.
+ *     Author: Alex Williamson <alex.williamson@redhat.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include <linux/errno.h>
+#include <linux/file.h>
+#include <linux/kvm_host.h>
+#include <linux/list.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/slab.h>
+#include <linux/uaccess.h>
+#include <linux/vfio.h>
+
+struct kvm_vfio_group {
+	struct list_head node;
+	struct vfio_group *vfio_group;
+};
+
+struct kvm_vfio {
+	struct list_head group_list;
+	struct mutex lock;
+};
+
+static struct vfio_group *kvm_vfio_group_get_external_user(struct file *filep)
+{
+	struct vfio_group *vfio_group;
+	struct vfio_group *(*fn)(struct file *);
+
+	fn = symbol_get(vfio_group_get_external_user);
+	if (!fn)
+		return ERR_PTR(-EINVAL);
+
+	vfio_group = fn(filep);
+
+	symbol_put(vfio_group_get_external_user);
+
+	return vfio_group;
+}
+
+static void kvm_vfio_group_put_external_user(struct vfio_group *vfio_group)
+{
+	void (*fn)(struct vfio_group *);
+
+	fn = symbol_get(vfio_group_put_external_user);
+	if (!fn)
+		return;
+
+	fn(vfio_group);
+
+	symbol_put(vfio_group_put_external_user);
+}
+
+static int kvm_vfio_set_group(struct kvm_device *dev, long attr, u64 arg)
+{
+	struct kvm_vfio *kv = dev->private;
+	struct vfio_group *vfio_group;
+	struct kvm_vfio_group *kvg;
+	void __user *argp = (void __user *)arg;
+	struct fd f;
+	int32_t fd;
+	int ret;
+
+	switch (attr) {
+	case KVM_DEV_VFIO_GROUP_ADD:
+		if (get_user(fd, (int32_t __user *)argp))
+			return -EFAULT;
+
+		f = fdget(fd);
+		if (!f.file)
+			return -EBADF;
+
+		vfio_group = kvm_vfio_group_get_external_user(f.file);
+		fdput(f);
+
+		if (IS_ERR(vfio_group))
+			return PTR_ERR(vfio_group);
+
+		mutex_lock(&kv->lock);
+
+		list_for_each_entry(kvg, &kv->group_list, node) {
+			if (kvg->vfio_group == vfio_group) {
+				mutex_unlock(&kv->lock);
+				kvm_vfio_group_put_external_user(vfio_group);
+				return -EEXIST;
+			}
+		}
+
+		kvg = kzalloc(sizeof(*kvg), GFP_KERNEL);
+		if (!kvg) {
+			mutex_unlock(&kv->lock);
+			kvm_vfio_group_put_external_user(vfio_group);
+			return -ENOMEM;
+		}
+
+		list_add_tail(&kvg->node, &kv->group_list);
+		kvg->vfio_group = vfio_group;
+
+		mutex_unlock(&kv->lock);
+
+		return 0;
+
+	case KVM_DEV_VFIO_GROUP_DEL:
+		if (get_user(fd, (int32_t __user *)argp))
+			return -EFAULT;
+
+		f = fdget(fd);
+		if (!f.file)
+			return -EBADF;
+
+		vfio_group = kvm_vfio_group_get_external_user(f.file);
+		fdput(f);
+
+		if (IS_ERR(vfio_group))
+			return PTR_ERR(vfio_group);
+
+		ret = -ENOENT;
+
+		mutex_lock(&kv->lock);
+
+		list_for_each_entry(kvg, &kv->group_list, node) {
+			if (kvg->vfio_group != vfio_group)
+				continue;
+
+			list_del(&kvg->node);
+			kvm_vfio_group_put_external_user(kvg->vfio_group);
+			kfree(kvg);
+			ret = 0;
+			break;
+		}
+
+		mutex_unlock(&kv->lock);
+
+		kvm_vfio_group_put_external_user(vfio_group);
+
+		return ret;
+	}
+
+	return -ENXIO;
+}
+
+static int kvm_vfio_set_attr(struct kvm_device *dev,
+			     struct kvm_device_attr *attr)
+{
+	switch (attr->group) {
+	case KVM_DEV_VFIO_GROUP:
+		return kvm_vfio_set_group(dev, attr->attr, attr->addr);
+	}
+
+	return -ENXIO;
+}
+
+static int kvm_vfio_has_attr(struct kvm_device *dev,
+			     struct kvm_device_attr *attr)
+{
+	switch (attr->group) {
+	case KVM_DEV_VFIO_GROUP:
+		switch (attr->attr) {
+		case KVM_DEV_VFIO_GROUP_ADD:
+		case KVM_DEV_VFIO_GROUP_DEL:
+			return 0;
+		}
+
+		break;
+	}
+
+	return -ENXIO;
+}
+
+static void kvm_vfio_destroy(struct kvm_device *dev)
+{
+	struct kvm_vfio *kv = dev->private;
+	struct kvm_vfio_group *kvg, *tmp;
+
+	list_for_each_entry_safe(kvg, tmp, &kv->group_list, node) {
+		kvm_vfio_group_put_external_user(kvg->vfio_group);
+		list_del(&kvg->node);
+		kfree(kvg);
+	}
+
+	kfree(kv);
+	kfree(dev); /* alloc by kvm_ioctl_create_device, free by .destroy */
+}
+
+static int kvm_vfio_create(struct kvm_device *dev, u32 type)
+{
+	struct kvm_device *tmp;
+	struct kvm_vfio *kv;
+
+	/* Only one VFIO "device" per VM */
+	list_for_each_entry(tmp, &dev->kvm->devices, vm_node)
+		if (tmp->ops == &kvm_vfio_ops)
+			return -EBUSY;
+
+	kv = kzalloc(sizeof(*kv), GFP_KERNEL);
+	if (!kv)
+		return -ENOMEM;
+
+	INIT_LIST_HEAD(&kv->group_list);
+	mutex_init(&kv->lock);
+
+	dev->private = kv;
+
+	return 0;
+}
+
+struct kvm_device_ops kvm_vfio_ops = {
+	.name = "kvm-vfio",
+	.create = kvm_vfio_create,
+	.destroy = kvm_vfio_destroy,
+	.set_attr = kvm_vfio_set_attr,
+	.has_attr = kvm_vfio_has_attr,
+};
