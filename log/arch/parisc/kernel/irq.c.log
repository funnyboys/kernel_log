commit 997ba6573685451c37005a5b74a4baa3c16b5231
Author: afzal mohammed <afzal.mohd.ma@gmail.com>
Date:   Wed Mar 4 06:20:24 2020 +0530

    parisc: Replace setup_irq() by request_irq()
    
    request_irq() is preferred over setup_irq(). Invocations of setup_irq()
    occur after memory allocators are ready.
    
    Per tglx[1], setup_irq() existed in olden days when allocators were not
    ready by the time early interrupts were initialized.
    
    Hence replace setup_irq() by request_irq().
    
    [1] https://lkml.kernel.org/r/alpine.DEB.2.20.1710191609480.1971@nanos
    
    Signed-off-by: afzal mohammed <afzal.mohd.ma@gmail.com>
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index e5fcfb70cc7c..e76c86619949 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -560,33 +560,23 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 	goto out;
 }
 
-static struct irqaction timer_action = {
-	.handler = timer_interrupt,
-	.name = "timer",
-	.flags = IRQF_TIMER | IRQF_PERCPU | IRQF_IRQPOLL,
-};
-
-#ifdef CONFIG_SMP
-static struct irqaction ipi_action = {
-	.handler = ipi_interrupt,
-	.name = "IPI",
-	.flags = IRQF_PERCPU,
-};
-#endif
-
 static void claim_cpu_irqs(void)
 {
+	unsigned long flags = IRQF_TIMER | IRQF_PERCPU | IRQF_IRQPOLL;
 	int i;
+
 	for (i = CPU_IRQ_BASE; i <= CPU_IRQ_MAX; i++) {
 		irq_set_chip_and_handler(i, &cpu_interrupt_type,
 					 handle_percpu_irq);
 	}
 
 	irq_set_handler(TIMER_IRQ, handle_percpu_irq);
-	setup_irq(TIMER_IRQ, &timer_action);
+	if (request_irq(TIMER_IRQ, timer_interrupt, flags, "timer", NULL))
+		pr_err("Failed to register timer interrupt\n");
 #ifdef CONFIG_SMP
 	irq_set_handler(IPI_IRQ, handle_percpu_irq);
-	setup_irq(IPI_IRQ, &ipi_action);
+	if (request_irq(IPI_IRQ, ipi_interrupt, IRQF_PERCPU, "IPI", NULL))
+		pr_err("Failed to register IPI interrupt\n");
 #endif
 }
 

commit de6cc6515a445d5d81cad2dee899a0be1a6317f8
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:02 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 153
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 or at your option any
      later version this program is distributed in the hope that it will
      be useful but without any warranty without even the implied warranty
      of merchantability or fitness for a particular purpose see the gnu
      general public license for more details you should have received a
      copy of the gnu general public license along with this program if
      not write to the free software foundation inc 675 mass ave cambridge
      ma 02139 usa
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 77 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Armijn Hemel <armijn@tjaldur.nl>
    Reviewed-by: Richard Fontana <rfontana@redhat.com>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.837555891@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 23040a67583e..e5fcfb70cc7c 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /* 
  * Code to handle x86 style IRQs plus some generic interrupt stuff.
  *
@@ -6,20 +7,6 @@
  * Copyright (C) 1999 SuSE GmbH (Philipp Rumpf, prumpf@tux.org)
  * Copyright (C) 1999-2000 Grant Grundler
  * Copyright (c) 2005 Matthew Wilcox
- *
- *    This program is free software; you can redistribute it and/or modify
- *    it under the terms of the GNU General Public License as published by
- *    the Free Software Foundation; either version 2, or (at your option)
- *    any later version.
- *
- *    This program is distributed in the hope that it will be useful,
- *    but WITHOUT ANY WARRANTY; without even the implied warranty of
- *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- *    GNU General Public License for more details.
- *
- *    You should have received a copy of the GNU General Public License
- *    along with this program; if not, write to the Free Software
- *    Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
  */
 #include <linux/bitops.h>
 #include <linux/errno.h>

commit f73493eb4aecdd6edd8a749890e6e2dcfa0a7978
Author: Helge Deller <deller@gmx.de>
Date:   Sat Jan 5 00:05:46 2019 +0100

    parisc: Improve initial IRQ to CPU assignment
    
    On parisc, each IRQ can only be handled by one CPU, and currently CPU0
    is choosen as default for handling all IRQs by default.
    With this patch we now assign each requested IRQ to one of the online
    CPUs (and thus distribute the IRQs across all CPUs), even without an
    instance of irqbalance running.
    
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 6f19f364c20a..23040a67583e 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -117,7 +117,10 @@ int cpu_check_affinity(struct irq_data *d, const struct cpumask *dest)
 		return -EINVAL;
 
 	/* whatever mask they set, we just allow one CPU */
-	cpu_dest = cpumask_first_and(dest, cpu_online_mask);
+	cpu_dest = cpumask_next_and(d->irq & (num_online_cpus()-1),
+					dest, cpu_online_mask);
+	if (cpu_dest >= nr_cpu_ids)
+		cpu_dest = cpumask_first_and(dest, cpu_online_mask);
 
 	return cpu_dest;
 }

commit b102f29b2d8603f15071384e88125b8eab5f8faa
Author: Helge Deller <deller@gmx.de>
Date:   Sat Jan 5 20:07:27 2019 +0100

    parisc: Count IPI function call interrupts
    
    Like other platforms, count the number of IPI function call interrupts
    and show it in /proc/interrupts.
    
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index a1369bb54cdb..6f19f364c20a 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -180,6 +180,10 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 		for_each_online_cpu(j)
 			seq_printf(p, "%10u ", irq_stats(j)->irq_resched_count);
 		seq_puts(p, "  Rescheduling interrupts\n");
+		seq_printf(p, "%*s: ", prec, "CAL");
+		for_each_online_cpu(j)
+			seq_printf(p, "%10u ", irq_stats(j)->irq_call_count);
+		seq_puts(p, "  Function call interrupts\n");
 	}
 #endif
 	seq_printf(p, "%*s: ", prec, "UAH");

commit 237a97d61e9c2807071294496762ee25cdde2422
Author: Helge Deller <deller@gmx.de>
Date:   Sat Jan 5 20:04:31 2019 +0100

    parisc: Show rescheduling interrupts on SMP machines only
    
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 0ca254085a66..a1369bb54cdb 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -175,10 +175,12 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 # endif
 #endif
 #ifdef CONFIG_SMP
-	seq_printf(p, "%*s: ", prec, "RES");
-	for_each_online_cpu(j)
-		seq_printf(p, "%10u ", irq_stats(j)->irq_resched_count);
-	seq_puts(p, "  Rescheduling interrupts\n");
+	if (num_online_cpus() > 1) {
+		seq_printf(p, "%*s: ", prec, "RES");
+		for_each_online_cpu(j)
+			seq_printf(p, "%10u ", irq_stats(j)->irq_resched_count);
+		seq_puts(p, "  Rescheduling interrupts\n");
+	}
 #endif
 	seq_printf(p, "%*s: ", prec, "UAH");
 	for_each_online_cpu(j)

commit 8f8201dfed91a43ac38c899c82f81eef3d36afd9
Author: Helge Deller <deller@gmx.de>
Date:   Mon Jul 31 08:38:27 2017 +0200

    parisc: Increase thread and stack size to 32kb
    
    Since kernel 4.11 the thread and irq stacks on parisc randomly overflow
    the default size of 16k. The reason why stack usage suddenly grew is yet
    unknown.
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Cc: stable@vger.kernel.org # 4.11+
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 5404e4086cb9..0ca254085a66 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -380,7 +380,7 @@ static inline int eirr_to_irq(unsigned long eirr)
 /*
  * IRQ STACK - used for irq handler
  */
-#define IRQ_STACK_SIZE      (4096 << 2) /* 16k irq stack size */
+#define IRQ_STACK_SIZE      (4096 << 3) /* 32k irq stack size */
 
 union irq_stack_union {
 	unsigned long stack[IRQ_STACK_SIZE/sizeof(unsigned long)];

commit 5bc64bd246ca00e0bb0b7137afaf586f2f66a911
Author: Helge Deller <deller@gmx.de>
Date:   Sat Jul 8 23:25:14 2017 +0200

    parisc: Disable further stack checks when panic occurs during stack check
    
    Before the irq handler detects a low stack and then panics the kernel, disable
    further stack checks to avoid recursive panics.
    
    Reported-by: John David Anglin <dave.anglin@bell.net>
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index ba5e1c7b1f17..5404e4086cb9 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -413,6 +413,10 @@ static inline void stack_overflow_check(struct pt_regs *regs)
 	if (regs->sr[7])
 		return;
 
+	/* exit if already in panic */
+	if (sysctl_panic_on_stackoverflow < 0)
+		return;
+
 	/* calculate kernel stack usage */
 	stack_usage = sp - stack_start;
 #ifdef CONFIG_IRQSTACKS
@@ -454,8 +458,10 @@ static inline void stack_overflow_check(struct pt_regs *regs)
 #ifdef CONFIG_IRQSTACKS
 panic_check:
 #endif
-	if (sysctl_panic_on_stackoverflow)
+	if (sysctl_panic_on_stackoverflow) {
+		sysctl_panic_on_stackoverflow = -1; /* disable further checks */
 		panic("low stack detected by irq handler - check messages\n");
+	}
 #endif
 }
 

commit b1b4e435e4ef7de77f07bf2a42c8380b960c2d44
Author: Helge Deller <deller@gmx.de>
Date:   Thu Sep 3 22:45:21 2015 +0200

    parisc: Filter out spurious interrupts in PA-RISC irq handler
    
    When detecting a serial port on newer PA-RISC machines (with iosapic) we have a
    long way to go to find the right IRQ line, registering it, then registering the
    serial port and the irq handler for the serial port. During this phase spurious
    interrupts for the serial port may happen which then crashes the kernel because
    the action handler might not have been set up yet.
    
    So, basically it's a race condition between the serial port hardware and the
    CPU which sets up the necessary fields in the irq sructs. The main reason for
    this race is, that we unmask the serial port irqs too early without having set
    up everything properly before (which isn't easily possible because we need the
    IRQ number to register the serial ports).
    
    This patch is a work-around for this problem. It adds checks to the CPU irq
    handler to verify if the IRQ action field has been initialized already. If not,
    we just skip this interrupt (which isn't critical for a serial port at bootup).
    The real fix would probably involve rewriting all PA-RISC specific IRQ code
    (for CPU, IOSAPIC, GSC and EISA) to use IRQ domains with proper parenting of
    the irq chips and proper irq enabling along this line.
    
    This bug has been in the PA-RISC port since the beginning, but the crashes
    happened very rarely with currently used hardware.  But on the latest machine
    which I bought (a C8000 workstation), which uses the fastest CPUs (4 x PA8900,
    1GHz) and which has the largest possible L1 cache size (64MB each), the kernel
    crashed at every boot because of this race. So, without this patch the machine
    would currently be unuseable.
    
    For the record, here is the flow logic:
    1. serial_init_chip() in 8250_gsc.c calls iosapic_serial_irq().
    2. iosapic_serial_irq() calls txn_alloc_irq() to find the irq.
    3. iosapic_serial_irq() calls cpu_claim_irq() to register the CPU irq
    4. cpu_claim_irq() unmasks the CPU irq (which it shouldn't!)
    5. serial_init_chip() then registers the 8250 port.
    Problems:
    - In step 4 the CPU irq shouldn't have been registered yet, but after step 5
    - If serial irq happens between 4 and 5 have finished, the kernel will crash
    
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 413ec3c3f9cc..ba5e1c7b1f17 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -507,8 +507,8 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 	struct pt_regs *old_regs;
 	unsigned long eirr_val;
 	int irq, cpu = smp_processor_id();
-#ifdef CONFIG_SMP
 	struct irq_data *irq_data;
+#ifdef CONFIG_SMP
 	cpumask_t dest;
 #endif
 
@@ -521,8 +521,13 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 		goto set_out;
 	irq = eirr_to_irq(eirr_val);
 
-#ifdef CONFIG_SMP
 	irq_data = irq_get_irq_data(irq);
+
+	/* Filter out spurious interrupts, mostly from serial port at bootup */
+	if (unlikely(!irq_desc_has_action(irq_data_to_desc(irq_data))))
+		goto set_out;
+
+#ifdef CONFIG_SMP
 	cpumask_copy(&dest, irq_data_get_affinity_mask(irq_data));
 	if (irqd_is_per_cpu(irq_data) &&
 	    !cpumask_test_cpu(smp_processor_id(), &dest)) {

commit d2109a12198edf22eb85e475c223eea14b9c3fbe
Author: Jiang Liu <jiang.liu@linux.intel.com>
Date:   Mon Jun 1 16:05:32 2015 +0800

    parisc/irq: Use access helper irq_data_get_affinity_mask()
    
    Use access helper irq_data_get_affinity_mask() to hide implementation
    details of struct irq_desc.
    
    Signed-off-by: Jiang Liu <jiang.liu@linux.intel.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Randy Dunlap <rdunlap@infradead.org>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: James E.J. Bottomley <jejb@parisc-linux.org>
    Cc: Helge Deller <deller@gmx.de>
    Link: http://lkml.kernel.org/r/1433145945-789-24-git-send-email-jiang.liu@linux.intel.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index f3191db6e2e9..413ec3c3f9cc 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -131,7 +131,7 @@ static int cpu_set_affinity_irq(struct irq_data *d, const struct cpumask *dest,
 	if (cpu_dest < 0)
 		return -1;
 
-	cpumask_copy(d->affinity, dest);
+	cpumask_copy(irq_data_get_affinity_mask(d), dest);
 
 	return 0;
 }
@@ -339,7 +339,7 @@ unsigned long txn_affinity_addr(unsigned int irq, int cpu)
 {
 #ifdef CONFIG_SMP
 	struct irq_data *d = irq_get_irq_data(irq);
-	cpumask_copy(d->affinity, cpumask_of(cpu));
+	cpumask_copy(irq_data_get_affinity_mask(d), cpumask_of(cpu));
 #endif
 
 	return per_cpu(cpu_data, cpu).txn_addr;
@@ -508,7 +508,7 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 	unsigned long eirr_val;
 	int irq, cpu = smp_processor_id();
 #ifdef CONFIG_SMP
-	struct irq_desc *desc;
+	struct irq_data *irq_data;
 	cpumask_t dest;
 #endif
 
@@ -522,9 +522,9 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 	irq = eirr_to_irq(eirr_val);
 
 #ifdef CONFIG_SMP
-	desc = irq_to_desc(irq);
-	cpumask_copy(&dest, desc->irq_data.affinity);
-	if (irqd_is_per_cpu(&desc->irq_data) &&
+	irq_data = irq_get_irq_data(irq);
+	cpumask_copy(&dest, irq_data_get_affinity_mask(irq_data));
+	if (irqd_is_per_cpu(irq_data) &&
 	    !cpumask_test_cpu(smp_processor_id(), &dest)) {
 		int cpu = cpumask_first(&dest);
 

commit 409e56f3ef355ef7670b33e3fc6de8d1256a11d3
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Thu Mar 5 10:49:18 2015 +1030

    parisc: fix up obsolete cpu function usage.
    
    Thanks to spatch.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: Helge Deller <deller@gmx.de>
    Cc: linux-parisc@vger.kernel.org

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index cfe056fe7f5c..f3191db6e2e9 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -525,8 +525,8 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 	desc = irq_to_desc(irq);
 	cpumask_copy(&dest, desc->irq_data.affinity);
 	if (irqd_is_per_cpu(&desc->irq_data) &&
-	    !cpu_isset(smp_processor_id(), dest)) {
-		int cpu = first_cpu(dest);
+	    !cpumask_test_cpu(smp_processor_id(), &dest)) {
+		int cpu = cpumask_first(&dest);
 
 		printk(KERN_DEBUG "redirecting irq %d from CPU %d to %d\n",
 		       irq, smp_processor_id(), cpu);

commit 1ed71e59bca79e866c4bebbe1efc0bc18245119d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Mar 4 20:43:40 2014 +0000

    parisc: Validate online cpus in irq_set_affinity() callbacks
    
    The [user space] interface does not filter out offline cpus. It merily
    guarantees that the mask contains at least one online cpu.
    
    So the selector in the irq chip implementation needs to make sure to
    pick only an online cpu because otherwise:
    
         Offline Core 1
         Set affinity to 0xe (is valid due to online mask 0xd)
         cpumask_first will pick core 1, which is offline
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: James E.J. Bottomley <jejb@parisc-linux.org>
    Cc: Helge Deller <deller@gmx.de>
    Cc: linux-parisc@vger.kernel.org
    Link: http://lkml.kernel.org/r/20140304203100.859489993@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 8ceac4785609..cfe056fe7f5c 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -117,7 +117,7 @@ int cpu_check_affinity(struct irq_data *d, const struct cpumask *dest)
 		return -EINVAL;
 
 	/* whatever mask they set, we just allow one CPU */
-	cpu_dest = first_cpu(*dest);
+	cpu_dest = cpumask_first_and(dest, cpu_online_mask);
 
 	return cpu_dest;
 }

commit 1006fae359cc810c16354805c0cffbb6ffee602e
Merge: 70fdcb83db15 5702941eec32
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 12 10:02:59 2013 +0900

    Merge branch 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull IRQ changes from Ingo Molnar:
     "The biggest change this cycle are the softirq/hardirq stack
      interaction and nesting fixes, cleanups and reorganizations from
      Frederic.  This is the longer followup story to the softirq nesting
      fix that is already upstream (commit ded797547548: "irq: Force hardirq
      exit's softirq processing on its own stack")"
    
    * 'irq-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      irqchip: bcm2835: Convert to use IRQCHIP_DECLARE macro
      powerpc: Tell about irq stack coverage
      x86: Tell about irq stack coverage
      irq: Optimize softirq stack selection in irq exit
      irq: Justify the various softirq stack choices
      irq: Improve a bit softirq debugging
      irq: Optimize call to softirq on hardirq exit
      irq: Consolidate do_softirq() arch overriden implementations
      x86/irq: Correct comment about i8259 initialization

commit 6f0c4aa61d30131ceb32f2a9926dd71cc5cd003a
Author: Helge Deller <deller@gmx.de>
Date:   Sun Oct 27 00:26:20 2013 +0200

    parisc: do not count IPI calls twice
    
    The number of IPI calls is already visible as per-cpu IPI irq counters
    in/proc/cpuinfo, so let's drop this additional counting.
    
    This partly reverts:
    cd85d55 parisc: more irq statistics in /proc/interrupts
    
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 2e6443b1e922..501ac8b4dcdf 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -179,10 +179,6 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_resched_count);
 	seq_puts(p, "  Rescheduling interrupts\n");
-	seq_printf(p, "%*s: ", prec, "CAL");
-	for_each_online_cpu(j)
-		seq_printf(p, "%10u ", irq_stats(j)->irq_call_count);
-	seq_puts(p, "  Function call interrupts\n");
 #endif
 	seq_printf(p, "%*s: ", prec, "UAH");
 	for_each_online_cpu(j)

commit 7d65f4a6553203da6a22097821d151fbbe7e4956
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Sep 5 15:49:45 2013 +0200

    irq: Consolidate do_softirq() arch overriden implementations
    
    All arch overriden implementations of do_softirq() share the following
    common code: disable irqs (to avoid races with the pending check),
    check if there are softirqs pending, then execute __do_softirq() on
    a specific stack.
    
    Consolidate the common parts such that archs only worry about the
    stack switch.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@au1.ibm.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul Mackerras <paulus@au1.ibm.com>
    Cc: James Hogan <james.hogan@imgtec.com>
    Cc: James E.J. Bottomley <jejb@parisc-linux.org>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Andrew Morton <akpm@linux-foundation.org>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 2e6443b1e922..ef5927685299 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -499,22 +499,9 @@ static void execute_on_irq_stack(void *func, unsigned long param1)
 	*irq_stack_in_use = 1;
 }
 
-asmlinkage void do_softirq(void)
+void do_softirq_own_stack(void)
 {
-	__u32 pending;
-	unsigned long flags;
-
-	if (in_interrupt())
-		return;
-
-	local_irq_save(flags);
-
-	pending = local_softirq_pending();
-
-	if (pending)
-		execute_on_irq_stack(__do_softirq, 0);
-
-	local_irq_restore(flags);
+	execute_on_irq_stack(__do_softirq, 0);
 }
 #endif /* CONFIG_IRQSTACKS */
 

commit d96b51ec14650b490ab98e738bcc02309396e5bc
Author: Helge Deller <deller@gmx.de>
Date:   Fri May 24 21:27:35 2013 +0000

    parisc: fix irq stack on UP and SMP
    
    The logic to detect if the irq stack was already in use with
    raw_spin_trylock() is wrong, because it will generate a "trylock failure
    on UP" error message with CONFIG_SMP=n and CONFIG_DEBUG_SPINLOCK=y.
    
    arch_spin_trylock() can't be used either since in the CONFIG_SMP=n case
    no atomic protection is given and we are reentrant here. A mutex didn't
    worked either and brings more overhead by turning off interrupts.
    
    So, let's use the fastest path for parisc which is the ldcw instruction.
    
    Counting how often the irq stack was used is pretty useless, so just
    drop this piece of code.
    
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 9c2d953f3de5..2e6443b1e922 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -27,11 +27,11 @@
 #include <linux/interrupt.h>
 #include <linux/kernel_stat.h>
 #include <linux/seq_file.h>
-#include <linux/spinlock.h>
 #include <linux/types.h>
 #include <asm/io.h>
 
 #include <asm/smp.h>
+#include <asm/ldcw.h>
 
 #undef PARISC_IRQ_CR16_COUNTS
 
@@ -172,10 +172,6 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_stack_usage);
 	seq_puts(p, "  Interrupt stack usage\n");
-	seq_printf(p, "%*s: ", prec, "ISC");
-	for_each_online_cpu(j)
-		seq_printf(p, "%10u ", irq_stats(j)->irq_stack_counter);
-	seq_puts(p, "  Interrupt stack usage counter\n");
 # endif
 #endif
 #ifdef CONFIG_SMP
@@ -384,6 +380,24 @@ static inline int eirr_to_irq(unsigned long eirr)
 	return (BITS_PER_LONG - bit) + TIMER_IRQ;
 }
 
+#ifdef CONFIG_IRQSTACKS
+/*
+ * IRQ STACK - used for irq handler
+ */
+#define IRQ_STACK_SIZE      (4096 << 2) /* 16k irq stack size */
+
+union irq_stack_union {
+	unsigned long stack[IRQ_STACK_SIZE/sizeof(unsigned long)];
+	volatile unsigned int slock[4];
+	volatile unsigned int lock[1];
+};
+
+DEFINE_PER_CPU(union irq_stack_union, irq_stack_union) = {
+		.slock = { 1,1,1,1 },
+	};
+#endif
+
+
 int sysctl_panic_on_stackoverflow = 1;
 
 static inline void stack_overflow_check(struct pt_regs *regs)
@@ -450,27 +464,26 @@ static inline void stack_overflow_check(struct pt_regs *regs)
 }
 
 #ifdef CONFIG_IRQSTACKS
-DEFINE_PER_CPU(union irq_stack_union, irq_stack_union) = {
-		.lock = __RAW_SPIN_LOCK_UNLOCKED((irq_stack_union).lock)
-	};
+/* in entry.S: */
+void call_on_stack(unsigned long p1, void *func, unsigned long new_stack);
 
 static void execute_on_irq_stack(void *func, unsigned long param1)
 {
 	union irq_stack_union *union_ptr;
 	unsigned long irq_stack;
-	raw_spinlock_t *irq_stack_in_use;
+	volatile unsigned int *irq_stack_in_use;
 
 	union_ptr = &per_cpu(irq_stack_union, smp_processor_id());
 	irq_stack = (unsigned long) &union_ptr->stack;
-	irq_stack = ALIGN(irq_stack + sizeof(irq_stack_union.lock),
+	irq_stack = ALIGN(irq_stack + sizeof(irq_stack_union.slock),
 			 64); /* align for stack frame usage */
 
 	/* We may be called recursive. If we are already using the irq stack,
 	 * just continue to use it. Use spinlocks to serialize
 	 * the irq stack usage.
 	 */
-	irq_stack_in_use = &union_ptr->lock;
-	if (!raw_spin_trylock(irq_stack_in_use)) {
+	irq_stack_in_use = (volatile unsigned int *)__ldcw_align(union_ptr);
+	if (!__ldcw(irq_stack_in_use)) {
 		void (*direct_call)(unsigned long p1) = func;
 
 		/* We are using the IRQ stack already.
@@ -482,10 +495,8 @@ static void execute_on_irq_stack(void *func, unsigned long param1)
 	/* This is where we switch to the IRQ stack. */
 	call_on_stack(param1, func, irq_stack);
 
-	__inc_irq_stat(irq_stack_counter);
-
 	/* free up irq stack usage. */
-	do_raw_spin_unlock(irq_stack_in_use);
+	*irq_stack_in_use = 1;
 }
 
 asmlinkage void do_softirq(void)

commit d0c3be806a3fe7f4abdb0f7e7287addb55e73f35
Author: Helge Deller <deller@gmx.de>
Date:   Sat May 18 19:35:44 2013 +0000

    parisc: show number of FPE and unaligned access handler calls in /proc/interrupts
    
    Show number of floating point assistant and unaligned access fixup
    handler in /proc/interrupts file.
    
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 55237a70e197..9c2d953f3de5 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -188,6 +188,14 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_call_count);
 	seq_puts(p, "  Function call interrupts\n");
 #endif
+	seq_printf(p, "%*s: ", prec, "UAH");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->irq_unaligned_count);
+	seq_puts(p, "  Unaligned access handler traps\n");
+	seq_printf(p, "%*s: ", prec, "FPA");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->irq_fpassist_count);
+	seq_puts(p, "  Floating point assist traps\n");
 	seq_printf(p, "%*s: ", prec, "TLB");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_tlb_count);

commit 416821d3d68164909b2cbcf398e4ba0797f5f8a2
Author: Helge Deller <deller@gmx.de>
Date:   Fri May 10 21:24:01 2013 +0000

    parisc: implement irq stacks - part 2 (v2)
    
    This patch fixes few build issues which were introduced with the last
    irq stack patch, e.g. the combination of stack overflow check and irq
    stack.
    
    Furthermore we now do proper locking and change the irq bh handler
    to use the irq stack as well.
    
    In /proc/interrupts one now can monitor how huge the irq stack has grown
    and how often it was preferred over the kernel stack.
    
    IRQ stacks are now enabled by default just to make sure that we not
    overflow the kernel stack by accident.
    
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index e255db0bb761..55237a70e197 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -166,22 +166,32 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 	seq_printf(p, "%*s: ", prec, "STK");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->kernel_stack_usage);
-	seq_printf(p, "  Kernel stack usage\n");
+	seq_puts(p, "  Kernel stack usage\n");
+# ifdef CONFIG_IRQSTACKS
+	seq_printf(p, "%*s: ", prec, "IST");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->irq_stack_usage);
+	seq_puts(p, "  Interrupt stack usage\n");
+	seq_printf(p, "%*s: ", prec, "ISC");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->irq_stack_counter);
+	seq_puts(p, "  Interrupt stack usage counter\n");
+# endif
 #endif
 #ifdef CONFIG_SMP
 	seq_printf(p, "%*s: ", prec, "RES");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_resched_count);
-	seq_printf(p, "  Rescheduling interrupts\n");
+	seq_puts(p, "  Rescheduling interrupts\n");
 	seq_printf(p, "%*s: ", prec, "CAL");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_call_count);
-	seq_printf(p, "  Function call interrupts\n");
+	seq_puts(p, "  Function call interrupts\n");
 #endif
 	seq_printf(p, "%*s: ", prec, "TLB");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_tlb_count);
-	seq_printf(p, "  TLB shootdowns\n");
+	seq_puts(p, "  TLB shootdowns\n");
 	return 0;
 }
 
@@ -378,6 +388,7 @@ static inline void stack_overflow_check(struct pt_regs *regs)
 	unsigned long sp = regs->gr[30];
 	unsigned long stack_usage;
 	unsigned int *last_usage;
+	int cpu = smp_processor_id();
 
 	/* if sr7 != 0, we interrupted a userspace process which we do not want
 	 * to check for stack overflow. We will only check the kernel stack. */
@@ -386,7 +397,31 @@ static inline void stack_overflow_check(struct pt_regs *regs)
 
 	/* calculate kernel stack usage */
 	stack_usage = sp - stack_start;
-	last_usage = &per_cpu(irq_stat.kernel_stack_usage, smp_processor_id());
+#ifdef CONFIG_IRQSTACKS
+	if (likely(stack_usage <= THREAD_SIZE))
+		goto check_kernel_stack; /* found kernel stack */
+
+	/* check irq stack usage */
+	stack_start = (unsigned long) &per_cpu(irq_stack_union, cpu).stack;
+	stack_usage = sp - stack_start;
+
+	last_usage = &per_cpu(irq_stat.irq_stack_usage, cpu);
+	if (unlikely(stack_usage > *last_usage))
+		*last_usage = stack_usage;
+
+	if (likely(stack_usage < (IRQ_STACK_SIZE - STACK_MARGIN)))
+		return;
+
+	pr_emerg("stackcheck: %s will most likely overflow irq stack "
+		 "(sp:%lx, stk bottom-top:%lx-%lx)\n",
+		current->comm, sp, stack_start, stack_start + IRQ_STACK_SIZE);
+	goto panic_check;
+
+check_kernel_stack:
+#endif
+
+	/* check kernel stack usage */
+	last_usage = &per_cpu(irq_stat.kernel_stack_usage, cpu);
 
 	if (unlikely(stack_usage > *last_usage))
 		*last_usage = stack_usage;
@@ -398,31 +433,69 @@ static inline void stack_overflow_check(struct pt_regs *regs)
 		 "(sp:%lx, stk bottom-top:%lx-%lx)\n",
 		current->comm, sp, stack_start, stack_start + THREAD_SIZE);
 
+#ifdef CONFIG_IRQSTACKS
+panic_check:
+#endif
 	if (sysctl_panic_on_stackoverflow)
 		panic("low stack detected by irq handler - check messages\n");
 #endif
 }
 
 #ifdef CONFIG_IRQSTACKS
-DEFINE_PER_CPU(union irq_stack_union, irq_stack_union);
+DEFINE_PER_CPU(union irq_stack_union, irq_stack_union) = {
+		.lock = __RAW_SPIN_LOCK_UNLOCKED((irq_stack_union).lock)
+	};
 
 static void execute_on_irq_stack(void *func, unsigned long param1)
 {
-	unsigned long *irq_stack_start;
+	union irq_stack_union *union_ptr;
 	unsigned long irq_stack;
-	int cpu = smp_processor_id();
+	raw_spinlock_t *irq_stack_in_use;
 
-	irq_stack_start = &per_cpu(irq_stack_union, cpu).stack[0];
-	irq_stack = (unsigned long) irq_stack_start;
-	irq_stack = ALIGN(irq_stack, 16); /* align for stack frame usage */
+	union_ptr = &per_cpu(irq_stack_union, smp_processor_id());
+	irq_stack = (unsigned long) &union_ptr->stack;
+	irq_stack = ALIGN(irq_stack + sizeof(irq_stack_union.lock),
+			 64); /* align for stack frame usage */
 
-	BUG_ON(*irq_stack_start); /* report bug if we were called recursive. */
-	*irq_stack_start = 1;
+	/* We may be called recursive. If we are already using the irq stack,
+	 * just continue to use it. Use spinlocks to serialize
+	 * the irq stack usage.
+	 */
+	irq_stack_in_use = &union_ptr->lock;
+	if (!raw_spin_trylock(irq_stack_in_use)) {
+		void (*direct_call)(unsigned long p1) = func;
+
+		/* We are using the IRQ stack already.
+		 * Do direct call on current stack. */
+		direct_call(param1);
+		return;
+	}
 
 	/* This is where we switch to the IRQ stack. */
 	call_on_stack(param1, func, irq_stack);
 
-	*irq_stack_start = 0;
+	__inc_irq_stat(irq_stack_counter);
+
+	/* free up irq stack usage. */
+	do_raw_spin_unlock(irq_stack_in_use);
+}
+
+asmlinkage void do_softirq(void)
+{
+	__u32 pending;
+	unsigned long flags;
+
+	if (in_interrupt())
+		return;
+
+	local_irq_save(flags);
+
+	pending = local_softirq_pending();
+
+	if (pending)
+		execute_on_irq_stack(__do_softirq, 0);
+
+	local_irq_restore(flags);
 }
 #endif /* CONFIG_IRQSTACKS */
 

commit 0fc537d1d655cdae69b489dbba46ad617cfc1373
Author: Helge Deller <deller@gmx.de>
Date:   Tue May 7 21:42:47 2013 +0000

    parisc: tlb flush counting fix for SMP and UP
    
    Fix up build error on UP and show correctly number of function call
    (ipi) irqs.
    
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index a237e32ede19..e255db0bb761 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -175,14 +175,13 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 	seq_printf(p, "  Rescheduling interrupts\n");
 	seq_printf(p, "%*s: ", prec, "CAL");
 	for_each_online_cpu(j)
-		seq_printf(p, "%10u ", irq_stats(j)->irq_call_count -
-					irq_stats(j)->irq_tlb_count);
+		seq_printf(p, "%10u ", irq_stats(j)->irq_call_count);
 	seq_printf(p, "  Function call interrupts\n");
+#endif
 	seq_printf(p, "%*s: ", prec, "TLB");
 	for_each_online_cpu(j)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_tlb_count);
 	seq_printf(p, "  TLB shootdowns\n");
-#endif
 	return 0;
 }
 

commit cd85d5514d5c4d7e78abac923fc032457d0c5091
Author: Helge Deller <deller@gmx.de>
Date:   Mon May 6 19:20:26 2013 +0000

    parisc: more irq statistics in /proc/interrupts
    
    Add framework and initial values for more fine grained statistics in
    /proc/interrupts.
    
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 810f9cf89e48..a237e32ede19 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -152,6 +152,40 @@ static struct irq_chip cpu_interrupt_type = {
 	.irq_retrigger	= NULL,
 };
 
+DEFINE_PER_CPU_SHARED_ALIGNED(irq_cpustat_t, irq_stat);
+#define irq_stats(x)		(&per_cpu(irq_stat, x))
+
+/*
+ * /proc/interrupts printing for arch specific interrupts
+ */
+int arch_show_interrupts(struct seq_file *p, int prec)
+{
+	int j;
+
+#ifdef CONFIG_DEBUG_STACKOVERFLOW
+	seq_printf(p, "%*s: ", prec, "STK");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->kernel_stack_usage);
+	seq_printf(p, "  Kernel stack usage\n");
+#endif
+#ifdef CONFIG_SMP
+	seq_printf(p, "%*s: ", prec, "RES");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->irq_resched_count);
+	seq_printf(p, "  Rescheduling interrupts\n");
+	seq_printf(p, "%*s: ", prec, "CAL");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->irq_call_count -
+					irq_stats(j)->irq_tlb_count);
+	seq_printf(p, "  Function call interrupts\n");
+	seq_printf(p, "%*s: ", prec, "TLB");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->irq_tlb_count);
+	seq_printf(p, "  TLB shootdowns\n");
+#endif
+	return 0;
+}
+
 int show_interrupts(struct seq_file *p, void *v)
 {
 	int i = *(loff_t *) v, j;
@@ -219,6 +253,9 @@ int show_interrupts(struct seq_file *p, void *v)
 		raw_spin_unlock_irqrestore(&desc->lock, flags);
 	}
 
+	if (i == NR_IRQS)
+		arch_show_interrupts(p, 3);
+
 	return 0;
 }
 
@@ -340,13 +377,22 @@ static inline void stack_overflow_check(struct pt_regs *regs)
 	/* Our stack starts directly behind the thread_info struct. */
 	unsigned long stack_start = (unsigned long) current_thread_info();
 	unsigned long sp = regs->gr[30];
+	unsigned long stack_usage;
+	unsigned int *last_usage;
 
 	/* if sr7 != 0, we interrupted a userspace process which we do not want
 	 * to check for stack overflow. We will only check the kernel stack. */
 	if (regs->sr[7])
 		return;
 
-	if (likely((sp - stack_start) < (THREAD_SIZE - STACK_MARGIN)))
+	/* calculate kernel stack usage */
+	stack_usage = sp - stack_start;
+	last_usage = &per_cpu(irq_stat.kernel_stack_usage, smp_processor_id());
+
+	if (unlikely(stack_usage > *last_usage))
+		*last_usage = stack_usage;
+
+	if (likely(stack_usage < (THREAD_SIZE - STACK_MARGIN)))
 		return;
 
 	pr_emerg("stackcheck: %s will most likely overflow kernel stack "

commit 200c880420a2c02a0899120ce52d801fad705b90
Author: Helge Deller <deller@gmx.de>
Date:   Tue May 7 20:25:42 2013 +0000

    parisc: implement irq stacks
    
    Default kernel stack size on parisc is 16k.  During tests we found that the
    kernel stack can easily grow beyond 13k, which leaves 3k left for irq
    processing.
    
    This patch adds the possibility to activate an additional stack of 16k per CPU
    which is being used during irq processing.  This implementation does not yet
    uses this irq stack for the irq bh handler.
    
    The assembler code for call_on_stack was heavily cleaned up by John
    David Anglin.
    
    CC: John David Anglin <dave.anglin@bell.net>
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 61e51ac85659..810f9cf89e48 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -358,6 +358,29 @@ static inline void stack_overflow_check(struct pt_regs *regs)
 #endif
 }
 
+#ifdef CONFIG_IRQSTACKS
+DEFINE_PER_CPU(union irq_stack_union, irq_stack_union);
+
+static void execute_on_irq_stack(void *func, unsigned long param1)
+{
+	unsigned long *irq_stack_start;
+	unsigned long irq_stack;
+	int cpu = smp_processor_id();
+
+	irq_stack_start = &per_cpu(irq_stack_union, cpu).stack[0];
+	irq_stack = (unsigned long) irq_stack_start;
+	irq_stack = ALIGN(irq_stack, 16); /* align for stack frame usage */
+
+	BUG_ON(*irq_stack_start); /* report bug if we were called recursive. */
+	*irq_stack_start = 1;
+
+	/* This is where we switch to the IRQ stack. */
+	call_on_stack(param1, func, irq_stack);
+
+	*irq_stack_start = 0;
+}
+#endif /* CONFIG_IRQSTACKS */
+
 /* ONLY called from entry.S:intr_extint() */
 void do_cpu_irq_mask(struct pt_regs *regs)
 {
@@ -393,7 +416,12 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 	}
 #endif
 	stack_overflow_check(regs);
+
+#ifdef CONFIG_IRQSTACKS
+	execute_on_irq_stack(&generic_handle_irq, irq);
+#else
 	generic_handle_irq(irq);
+#endif /* CONFIG_IRQSTACKS */
 
  out:
 	irq_exit();

commit 9372450cc22d185f708e5cc3557cf991be4b7dc5
Author: Helge Deller <deller@gmx.de>
Date:   Tue May 7 19:28:52 2013 +0000

    parisc: add kernel stack overflow check
    
    Add the CONFIG_DEBUG_STACKOVERFLOW config option to enable checks to
    detect kernel stack overflows.
    
    Stack overflows can not be detected reliable since we do not want to
    introduce too much overhead.
    
    Instead, during irq processing in do_cpu_irq_mask() we check kernel
    stack usage of the interrupted kernel process. Kernel threads can be
    easily detected by checking the value of space register 7 (sr7) which
    is zero when running inside the kernel.
    
    Since THREAD_SIZE is 16k and PAGE_SIZE is 4k, reduce the alignment of
    the init thread to the lower value (PAGE_SIZE) in the kernel
    vmlinux.ld.S linker script.
    
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 8094d3ed3b64..61e51ac85659 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -330,6 +330,34 @@ static inline int eirr_to_irq(unsigned long eirr)
 	return (BITS_PER_LONG - bit) + TIMER_IRQ;
 }
 
+int sysctl_panic_on_stackoverflow = 1;
+
+static inline void stack_overflow_check(struct pt_regs *regs)
+{
+#ifdef CONFIG_DEBUG_STACKOVERFLOW
+	#define STACK_MARGIN	(256*6)
+
+	/* Our stack starts directly behind the thread_info struct. */
+	unsigned long stack_start = (unsigned long) current_thread_info();
+	unsigned long sp = regs->gr[30];
+
+	/* if sr7 != 0, we interrupted a userspace process which we do not want
+	 * to check for stack overflow. We will only check the kernel stack. */
+	if (regs->sr[7])
+		return;
+
+	if (likely((sp - stack_start) < (THREAD_SIZE - STACK_MARGIN)))
+		return;
+
+	pr_emerg("stackcheck: %s will most likely overflow kernel stack "
+		 "(sp:%lx, stk bottom-top:%lx-%lx)\n",
+		current->comm, sp, stack_start, stack_start + THREAD_SIZE);
+
+	if (sysctl_panic_on_stackoverflow)
+		panic("low stack detected by irq handler - check messages\n");
+#endif
+}
+
 /* ONLY called from entry.S:intr_extint() */
 void do_cpu_irq_mask(struct pt_regs *regs)
 {
@@ -364,6 +392,7 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 		goto set_out;
 	}
 #endif
+	stack_overflow_check(regs);
 	generic_handle_irq(irq);
 
  out:
@@ -420,6 +449,4 @@ void __init init_IRQ(void)
 	cpu_eiem = EIEM_MASK(TIMER_IRQ);
 #endif
         set_eiem(cpu_eiem);	/* EIEM : enable all external intr */
-
 }
-

commit b54cb2332e387f29c65f19f3620e5c812c89a328
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Mon Mar 2 10:45:53 2009 +0100

    parisc: remove IRQF_DISABLED
    
    People are playing odd games with IRQF_DISABLED, remove it.
    
    Its not reliable, since shared interrupt lines could disable it for you,
    and its possible and allowed for archs to disable IRQs to limit IRQ nesting.
    
    Therefore, simply mandate that _ALL_ IRQ handlers are run with IRQs disabled.
    
    [ This _should_ not break anything, since we've mandated that IRQ handlers
      _must_ be able to deal with this for a _long_ time ]
    
    IRQ handlers should be fast, no if buts and any other exceptions. We also have
    plenty instrumentation to find any offending IRQ latency sources.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 0299d63cd112..8094d3ed3b64 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -379,14 +379,14 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 static struct irqaction timer_action = {
 	.handler = timer_interrupt,
 	.name = "timer",
-	.flags = IRQF_DISABLED | IRQF_TIMER | IRQF_PERCPU | IRQF_IRQPOLL,
+	.flags = IRQF_TIMER | IRQF_PERCPU | IRQF_IRQPOLL,
 };
 
 #ifdef CONFIG_SMP
 static struct irqaction ipi_action = {
 	.handler = ipi_interrupt,
 	.name = "IPI",
-	.flags = IRQF_DISABLED | IRQF_PERCPU,
+	.flags = IRQF_PERCPU,
 };
 #endif
 

commit cac1f12b9f7409510a5abcf3eaecc2c56b75242a
Author: John David Anglin <dave@hiauly1.hia.nrc.ca>
Date:   Sun Jun 12 01:46:41 2011 +0000

    parisc: don't claim cpu irqs more than once
    
    The CPU irqs (timer and IPI) are not shared and only need to be claimed once.
    A mismatch error occurs if they are claimed more than once.
    
    Signed-off-by: John David Anglin <dave.anglin@nrc-cnrc.gc.ca>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: Helge Deller <deller@gmx.de>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index c0b1affc06a8..0299d63cd112 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -410,11 +410,13 @@ void __init init_IRQ(void)
 {
 	local_irq_disable();	/* PARANOID - should already be disabled */
 	mtctl(~0UL, 23);	/* EIRR : clear all pending external intr */
-	claim_cpu_irqs();
 #ifdef CONFIG_SMP
-	if (!cpu_eiem)
+	if (!cpu_eiem) {
+		claim_cpu_irqs();
 		cpu_eiem = EIEM_MASK(IPI_IRQ) | EIEM_MASK(TIMER_IRQ);
+	}
 #else
+	claim_cpu_irqs();
 	cpu_eiem = EIEM_MASK(TIMER_IRQ);
 #endif
         set_eiem(cpu_eiem);	/* EIEM : enable all external intr */

commit 68f20f43dae770bdb3d93cfb8fbe9679d3568c3b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Mar 28 13:47:54 2011 +0200

    parisc: Use irq_to_desc() in show_interrupts()
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 3d59d52a5dd6..c0b1affc06a8 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -169,10 +169,11 @@ int show_interrupts(struct seq_file *p, void *v)
 	}
 
 	if (i < NR_IRQS) {
+		struct irq_desc *desc = irq_to_desc(i);
 		struct irqaction *action;
 
-		raw_spin_lock_irqsave(&irq_desc[i].lock, flags);
-		action = irq_desc[i].action;
+		raw_spin_lock_irqsave(&desc->lock, flags);
+		action = desc->action;
 		if (!action)
 			goto skip;
 		seq_printf(p, "%3d: ", i);
@@ -183,7 +184,7 @@ int show_interrupts(struct seq_file *p, void *v)
 		seq_printf(p, "%10u ", kstat_irqs(i));
 #endif
 
-		seq_printf(p, " %14s", irq_desc[i].irq_data.chip->name);
+		seq_printf(p, " %14s", irq_desc_get_chip(desc)->name);
 #ifndef PARISC_IRQ_CR16_COUNTS
 		seq_printf(p, "  %s", action->name);
 
@@ -215,7 +216,7 @@ int show_interrupts(struct seq_file *p, void *v)
 
 		seq_putc(p, '\n');
  skip:
-		raw_spin_unlock_irqrestore(&irq_desc[i].lock, flags);
+		raw_spin_unlock_irqrestore(&desc->lock, flags);
 	}
 
 	return 0;
@@ -233,7 +234,7 @@ int show_interrupts(struct seq_file *p, void *v)
 
 int cpu_claim_irq(unsigned int irq, struct irq_chip *type, void *data)
 {
-	if (irq_desc[irq].action)
+	if (irq_has_action(irq))
 		return -EBUSY;
 	if (irq_get_chip(irq) != &cpu_interrupt_type)
 		return -EBUSY;

commit e2f571d294cc5f944539088bed46abae375b75f6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Mar 24 17:41:44 2011 +0100

    parisc: Convert irq namespace
    
    Convert to the new function names. Scripted with coccinelle.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: linux-parisc@vger.kernel.org

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 34bc2afa6a69..3d59d52a5dd6 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -235,13 +235,13 @@ int cpu_claim_irq(unsigned int irq, struct irq_chip *type, void *data)
 {
 	if (irq_desc[irq].action)
 		return -EBUSY;
-	if (get_irq_chip(irq) != &cpu_interrupt_type)
+	if (irq_get_chip(irq) != &cpu_interrupt_type)
 		return -EBUSY;
 
 	/* for iosapic interrupts */
 	if (type) {
-		set_irq_chip_and_handler(irq, type, handle_percpu_irq);
-		set_irq_chip_data(irq, data);
+		irq_set_chip_and_handler(irq, type, handle_percpu_irq);
+		irq_set_chip_data(irq, data);
 		__cpu_unmask_irq(irq);
 	}
 	return 0;
@@ -393,14 +393,14 @@ static void claim_cpu_irqs(void)
 {
 	int i;
 	for (i = CPU_IRQ_BASE; i <= CPU_IRQ_MAX; i++) {
-		set_irq_chip_and_handler(i, &cpu_interrupt_type,
+		irq_set_chip_and_handler(i, &cpu_interrupt_type,
 					 handle_percpu_irq);
 	}
 
-	set_irq_handler(TIMER_IRQ, handle_percpu_irq);
+	irq_set_handler(TIMER_IRQ, handle_percpu_irq);
 	setup_irq(TIMER_IRQ, &timer_action);
 #ifdef CONFIG_SMP
-	set_irq_handler(IPI_IRQ, handle_percpu_irq);
+	irq_set_handler(IPI_IRQ, handle_percpu_irq);
 	setup_irq(IPI_IRQ, &ipi_action);
 #endif
 }

commit 337ce6811bfe474cc449de1f95d2c4f26641f5af
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Mar 24 17:48:47 2011 +0100

    parisc: Convert the final irq bits
    
    1) As promised in the comment, the core does not copy cpumask anymore
       when the arch code returns -EINVAL
    
    2) Get the per cpu information from irq_data
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: linux-parisc@vger.kernel.org

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index cb450e1e79b3..34bc2afa6a69 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -113,13 +113,8 @@ int cpu_check_affinity(struct irq_data *d, const struct cpumask *dest)
 	int cpu_dest;
 
 	/* timer and ipi have to always be received on all CPUs */
-	if (CHECK_IRQ_PER_CPU(irq_to_desc(d->irq)->status)) {
-		/* Bad linux design decision.  The mask has already
-		 * been set; we must reset it. Will fix - tglx
-		 */
-		cpumask_setall(d->affinity);
+	if (irqd_is_per_cpu(d))
 		return -EINVAL;
-	}
 
 	/* whatever mask they set, we just allow one CPU */
 	cpu_dest = first_cpu(*dest);
@@ -357,7 +352,7 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 #ifdef CONFIG_SMP
 	desc = irq_to_desc(irq);
 	cpumask_copy(&dest, desc->irq_data.affinity);
-	if (CHECK_IRQ_PER_CPU(desc->status) &&
+	if (irqd_is_per_cpu(&desc->irq_data) &&
 	    !cpu_isset(smp_processor_id(), dest)) {
 		int cpu = first_cpu(dest);
 

commit 4c4231ea2f794d73bbb50b8d84e00c66a012a607
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Feb 6 20:45:52 2011 +0000

    [PARISC] Convert to new irq_chip functions
    
    Convert all the parisc driver interrupt handlers (dino, eisa, gsc,
    iosapic and superio) as well as the cpu interrupts.  Prepare
    show_interrupts for GENERIC_HARDIRQS_NO_DEPRECATED and finally selects
    that Kconfig option
    
    [jejb: compile and testing fixes]
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 3948f1dd455a..cb450e1e79b3 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -52,9 +52,9 @@ static volatile unsigned long cpu_eiem = 0;
 */
 static DEFINE_PER_CPU(unsigned long, local_ack_eiem) = ~0UL;
 
-static void cpu_mask_irq(unsigned int irq)
+static void cpu_mask_irq(struct irq_data *d)
 {
-	unsigned long eirr_bit = EIEM_MASK(irq);
+	unsigned long eirr_bit = EIEM_MASK(d->irq);
 
 	cpu_eiem &= ~eirr_bit;
 	/* Do nothing on the other CPUs.  If they get this interrupt,
@@ -63,7 +63,7 @@ static void cpu_mask_irq(unsigned int irq)
 	 * then gets disabled */
 }
 
-static void cpu_unmask_irq(unsigned int irq)
+static void __cpu_unmask_irq(unsigned int irq)
 {
 	unsigned long eirr_bit = EIEM_MASK(irq);
 
@@ -75,9 +75,14 @@ static void cpu_unmask_irq(unsigned int irq)
 	smp_send_all_nop();
 }
 
-void cpu_ack_irq(unsigned int irq)
+static void cpu_unmask_irq(struct irq_data *d)
+{
+	__cpu_unmask_irq(d->irq);
+}
+
+void cpu_ack_irq(struct irq_data *d)
 {
-	unsigned long mask = EIEM_MASK(irq);
+	unsigned long mask = EIEM_MASK(d->irq);
 	int cpu = smp_processor_id();
 
 	/* Clear in EIEM so we can no longer process */
@@ -90,9 +95,9 @@ void cpu_ack_irq(unsigned int irq)
 	mtctl(mask, 23);
 }
 
-void cpu_eoi_irq(unsigned int irq)
+void cpu_eoi_irq(struct irq_data *d)
 {
-	unsigned long mask = EIEM_MASK(irq);
+	unsigned long mask = EIEM_MASK(d->irq);
 	int cpu = smp_processor_id();
 
 	/* set it in the eiems---it's no longer in process */
@@ -103,15 +108,16 @@ void cpu_eoi_irq(unsigned int irq)
 }
 
 #ifdef CONFIG_SMP
-int cpu_check_affinity(unsigned int irq, const struct cpumask *dest)
+int cpu_check_affinity(struct irq_data *d, const struct cpumask *dest)
 {
 	int cpu_dest;
 
 	/* timer and ipi have to always be received on all CPUs */
-	if (CHECK_IRQ_PER_CPU(irq_to_desc(irq)->status)) {
+	if (CHECK_IRQ_PER_CPU(irq_to_desc(d->irq)->status)) {
 		/* Bad linux design decision.  The mask has already
-		 * been set; we must reset it */
-		cpumask_setall(irq_desc[irq].affinity);
+		 * been set; we must reset it. Will fix - tglx
+		 */
+		cpumask_setall(d->affinity);
 		return -EINVAL;
 	}
 
@@ -121,33 +127,34 @@ int cpu_check_affinity(unsigned int irq, const struct cpumask *dest)
 	return cpu_dest;
 }
 
-static int cpu_set_affinity_irq(unsigned int irq, const struct cpumask *dest)
+static int cpu_set_affinity_irq(struct irq_data *d, const struct cpumask *dest,
+				bool force)
 {
 	int cpu_dest;
 
-	cpu_dest = cpu_check_affinity(irq, dest);
+	cpu_dest = cpu_check_affinity(d, dest);
 	if (cpu_dest < 0)
 		return -1;
 
-	cpumask_copy(irq_desc[irq].affinity, dest);
+	cpumask_copy(d->affinity, dest);
 
 	return 0;
 }
 #endif
 
 static struct irq_chip cpu_interrupt_type = {
-	.name		= "CPU",
-	.mask		= cpu_mask_irq,
-	.unmask		= cpu_unmask_irq,
-	.ack		= cpu_ack_irq,
-	.eoi		= cpu_eoi_irq,
+	.name			= "CPU",
+	.irq_mask		= cpu_mask_irq,
+	.irq_unmask		= cpu_unmask_irq,
+	.irq_ack		= cpu_ack_irq,
+	.irq_eoi		= cpu_eoi_irq,
 #ifdef CONFIG_SMP
-	.set_affinity	= cpu_set_affinity_irq,
+	.irq_set_affinity	= cpu_set_affinity_irq,
 #endif
 	/* XXX: Needs to be written.  We managed without it so far, but
 	 * we really ought to write it.
 	 */
-	.retrigger	= NULL,
+	.irq_retrigger	= NULL,
 };
 
 int show_interrupts(struct seq_file *p, void *v)
@@ -181,7 +188,7 @@ int show_interrupts(struct seq_file *p, void *v)
 		seq_printf(p, "%10u ", kstat_irqs(i));
 #endif
 
-		seq_printf(p, " %14s", irq_desc[i].chip->name);
+		seq_printf(p, " %14s", irq_desc[i].irq_data.chip->name);
 #ifndef PARISC_IRQ_CR16_COUNTS
 		seq_printf(p, "  %s", action->name);
 
@@ -233,14 +240,14 @@ int cpu_claim_irq(unsigned int irq, struct irq_chip *type, void *data)
 {
 	if (irq_desc[irq].action)
 		return -EBUSY;
-	if (irq_desc[irq].chip != &cpu_interrupt_type)
+	if (get_irq_chip(irq) != &cpu_interrupt_type)
 		return -EBUSY;
 
 	/* for iosapic interrupts */
 	if (type) {
 		set_irq_chip_and_handler(irq, type, handle_percpu_irq);
 		set_irq_chip_data(irq, data);
-		cpu_unmask_irq(irq);
+		__cpu_unmask_irq(irq);
 	}
 	return 0;
 }
@@ -289,7 +296,8 @@ int txn_alloc_irq(unsigned int bits_wide)
 unsigned long txn_affinity_addr(unsigned int irq, int cpu)
 {
 #ifdef CONFIG_SMP
-	cpumask_copy(irq_desc[irq].affinity, cpumask_of(cpu));
+	struct irq_data *d = irq_get_irq_data(irq);
+	cpumask_copy(d->affinity, cpumask_of(cpu));
 #endif
 
 	return per_cpu(cpu_data, cpu).txn_addr;
@@ -333,6 +341,7 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 	unsigned long eirr_val;
 	int irq, cpu = smp_processor_id();
 #ifdef CONFIG_SMP
+	struct irq_desc *desc;
 	cpumask_t dest;
 #endif
 
@@ -346,8 +355,9 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 	irq = eirr_to_irq(eirr_val);
 
 #ifdef CONFIG_SMP
-	cpumask_copy(&dest, irq_desc[irq].affinity);
-	if (CHECK_IRQ_PER_CPU(irq_desc[irq].status) &&
+	desc = irq_to_desc(irq);
+	cpumask_copy(&dest, desc->irq_data.affinity);
+	if (CHECK_IRQ_PER_CPU(desc->status) &&
 	    !cpu_isset(smp_processor_id(), dest)) {
 		int cpu = first_cpu(dest);
 

commit 9804c9eaeacfe78651052c5ddff31099f60ef78c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Feb 7 19:28:01 2011 +0100

    [PARISC] fix per-cpu flag problem in the cpu affinity checkers
    
    The CHECK_IRQ_PER_CPU is wrong, it should be checking
    irq_to_desc(irq)->status not just irq.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@kernel.org
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index d7d94b845dc2..3948f1dd455a 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -108,7 +108,7 @@ int cpu_check_affinity(unsigned int irq, const struct cpumask *dest)
 	int cpu_dest;
 
 	/* timer and ipi have to always be received on all CPUs */
-	if (CHECK_IRQ_PER_CPU(irq)) {
+	if (CHECK_IRQ_PER_CPU(irq_to_desc(irq)->status)) {
 		/* Bad linux design decision.  The mask has already
 		 * been set; we must reset it */
 		cpumask_setall(irq_desc[irq].affinity);

commit 51890613f2bfa70453a5cc22c91c63946dd311cd
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Fri Dec 3 02:01:05 2010 +0000

    parisc: convert the rest of the irq handlers to simple/percpu
    
    The generic conversion eliminates the spurious no_ack and no_end
    routines, converts all the cascaded handlers to handle_simple_irq() and
    makes iosapic use a modified handle_percpu_irq() to become the same as
    the CPU irq's.  This isn't an essential change, but it eliminates the
    mask/unmask overhead of handle_level_irq().
    
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>
    Tested-by: Helge Deller <deller@gmx.de>
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 48aa71106db8..d7d94b845dc2 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -75,9 +75,6 @@ static void cpu_unmask_irq(unsigned int irq)
 	smp_send_all_nop();
 }
 
-void no_ack_irq(unsigned int irq) { }
-void no_end_irq(unsigned int irq) { }
-
 void cpu_ack_irq(unsigned int irq)
 {
 	unsigned long mask = EIEM_MASK(irq);
@@ -241,7 +238,7 @@ int cpu_claim_irq(unsigned int irq, struct irq_chip *type, void *data)
 
 	/* for iosapic interrupts */
 	if (type) {
-		set_irq_chip_and_handler(irq, type, handle_level_irq);
+		set_irq_chip_and_handler(irq, type, handle_percpu_irq);
 		set_irq_chip_data(irq, data);
 		cpu_unmask_irq(irq);
 	}

commit d16cd297d288e48482c3c261db434a2e13bd9f20
Author: James Bottomley <James.Bottomley@HansenPartnership.com>
Date:   Thu Dec 2 23:36:47 2010 +0000

    parisc: fix dino/gsc interrupts
    
    The essential problem we're currently having is that dino (and gsc) is a
    cascaded CPU interrupt.  Under the old __do_IRQ() handler, our CPU
    interrupts basically did an ack followed by an end.  In the new scheme,
    we replaced them with level handlers which do a mask, an ack and then an
    unmask (but no end).  Instead, with the renaming of end to eoi, we
    actually want to call the percpu flow handlers, because they actually
    have all the characteristics we want.
    
    This patch does the conversion and gets my C360 booting again.
    
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 5024f643b3b1..48aa71106db8 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -392,7 +392,7 @@ static void claim_cpu_irqs(void)
 	int i;
 	for (i = CPU_IRQ_BASE; i <= CPU_IRQ_MAX; i++) {
 		set_irq_chip_and_handler(i, &cpu_interrupt_type,
-			handle_level_irq);
+					 handle_percpu_irq);
 	}
 
 	set_irq_handler(TIMER_IRQ, handle_percpu_irq);

commit 7da1272547ebe96982a42292dfc833457708f4da
Author: Kyle McMartin <kyle@dreadnought.i.jkkm.org>
Date:   Thu Oct 14 01:02:23 2010 -0400

    parisc: kill __do_IRQ
    
    Signed-off-by: Kyle McMartin <kyle@redhat.com>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index e873edaf2747..5024f643b3b1 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -418,7 +418,3 @@ void __init init_IRQ(void)
 
 }
 
-void parisc_do_IRQ(unsigned int irq, struct irq_desc *desc)
-{
-	__do_IRQ(irq);
-}

commit f3d4605977f9f30993c670a85f75d8f3853144c5
Author: Kyle McMartin <kyle@dreadnought.i.jkkm.org>
Date:   Thu Oct 14 00:38:27 2010 -0400

    parisc: convert iosapic interrupts to proper flow handlers
    
    Shift the ->end call (cpu eoi) from __do_IRQ into our
    unmask handler. Also nuke some redundant code.
    
    Signed-off-by: Kyle McMartin <kyle@redhat.com>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 13bfa9702fd3..e873edaf2747 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -241,7 +241,7 @@ int cpu_claim_irq(unsigned int irq, struct irq_chip *type, void *data)
 
 	/* for iosapic interrupts */
 	if (type) {
-		set_irq_chip_and_handler(irq, type, parisc_do_IRQ);
+		set_irq_chip_and_handler(irq, type, handle_level_irq);
 		set_irq_chip_data(irq, data);
 		cpu_unmask_irq(irq);
 	}

commit 4d4f681dc43a06167763ec698f5de4f2b3119ad6
Author: Kyle McMartin <kyle@dreadnought.i.jkkm.org>
Date:   Thu Oct 14 00:12:23 2010 -0400

    parisc: convert cpu interrupts to proper flow handlers
    
    Only major change is renaming functions to match the conventions
    expected by the generic irq code.
    
    Signed-off-by: Kyle McMartin <kyle@redhat.com>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 272c29a44f2a..13bfa9702fd3 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -52,7 +52,7 @@ static volatile unsigned long cpu_eiem = 0;
 */
 static DEFINE_PER_CPU(unsigned long, local_ack_eiem) = ~0UL;
 
-static void cpu_disable_irq(unsigned int irq)
+static void cpu_mask_irq(unsigned int irq)
 {
 	unsigned long eirr_bit = EIEM_MASK(irq);
 
@@ -63,7 +63,7 @@ static void cpu_disable_irq(unsigned int irq)
 	 * then gets disabled */
 }
 
-static void cpu_enable_irq(unsigned int irq)
+static void cpu_unmask_irq(unsigned int irq)
 {
 	unsigned long eirr_bit = EIEM_MASK(irq);
 
@@ -75,12 +75,6 @@ static void cpu_enable_irq(unsigned int irq)
 	smp_send_all_nop();
 }
 
-static unsigned int cpu_startup_irq(unsigned int irq)
-{
-	cpu_enable_irq(irq);
-	return 0;
-}
-
 void no_ack_irq(unsigned int irq) { }
 void no_end_irq(unsigned int irq) { }
 
@@ -99,7 +93,7 @@ void cpu_ack_irq(unsigned int irq)
 	mtctl(mask, 23);
 }
 
-void cpu_end_irq(unsigned int irq)
+void cpu_eoi_irq(unsigned int irq)
 {
 	unsigned long mask = EIEM_MASK(irq);
 	int cpu = smp_processor_id();
@@ -146,12 +140,10 @@ static int cpu_set_affinity_irq(unsigned int irq, const struct cpumask *dest)
 
 static struct irq_chip cpu_interrupt_type = {
 	.name		= "CPU",
-	.startup	= cpu_startup_irq,
-	.shutdown	= cpu_disable_irq,
-	.enable		= cpu_enable_irq,
-	.disable	= cpu_disable_irq,
+	.mask		= cpu_mask_irq,
+	.unmask		= cpu_unmask_irq,
 	.ack		= cpu_ack_irq,
-	.eoi		= cpu_end_irq,
+	.eoi		= cpu_eoi_irq,
 #ifdef CONFIG_SMP
 	.set_affinity	= cpu_set_affinity_irq,
 #endif
@@ -251,7 +243,7 @@ int cpu_claim_irq(unsigned int irq, struct irq_chip *type, void *data)
 	if (type) {
 		set_irq_chip_and_handler(irq, type, parisc_do_IRQ);
 		set_irq_chip_data(irq, data);
-		cpu_enable_irq(irq);
+		cpu_unmask_irq(irq);
 	}
 	return 0;
 }
@@ -399,7 +391,8 @@ static void claim_cpu_irqs(void)
 {
 	int i;
 	for (i = CPU_IRQ_BASE; i <= CPU_IRQ_MAX; i++) {
-		set_irq_chip_and_handler(i, &cpu_interrupt_type, parisc_do_IRQ);
+		set_irq_chip_and_handler(i, &cpu_interrupt_type,
+			handle_level_irq);
 	}
 
 	set_irq_handler(TIMER_IRQ, handle_percpu_irq);

commit ba20085c20f1c9e8af546dea6ad0efa421bdef32
Author: Kyle McMartin <kyle@dreadnought.i.jkkm.org>
Date:   Wed Oct 13 21:00:55 2010 -0400

    parisc: lay groundwork for killing __do_IRQ
    
    Use proper accessors and handlers for generic irq cleanups. We just
    call back into __do_IRQ through desc->handler now, and remove the
    explicit calls.
    
    Signed-off-by: Kyle McMartin <kyle@redhat.com>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index efbcee5d2220..272c29a44f2a 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -151,7 +151,7 @@ static struct irq_chip cpu_interrupt_type = {
 	.enable		= cpu_enable_irq,
 	.disable	= cpu_disable_irq,
 	.ack		= cpu_ack_irq,
-	.end		= cpu_end_irq,
+	.eoi		= cpu_end_irq,
 #ifdef CONFIG_SMP
 	.set_affinity	= cpu_set_affinity_irq,
 #endif
@@ -247,10 +247,11 @@ int cpu_claim_irq(unsigned int irq, struct irq_chip *type, void *data)
 	if (irq_desc[irq].chip != &cpu_interrupt_type)
 		return -EBUSY;
 
+	/* for iosapic interrupts */
 	if (type) {
-		irq_desc[irq].chip = type;
-		irq_desc[irq].chip_data = data;
-		cpu_interrupt_type.enable(irq);
+		set_irq_chip_and_handler(irq, type, parisc_do_IRQ);
+		set_irq_chip_data(irq, data);
+		cpu_enable_irq(irq);
 	}
 	return 0;
 }
@@ -368,7 +369,7 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 		goto set_out;
 	}
 #endif
-	__do_IRQ(irq);
+	generic_handle_irq(irq);
 
  out:
 	irq_exit();
@@ -398,14 +399,14 @@ static void claim_cpu_irqs(void)
 {
 	int i;
 	for (i = CPU_IRQ_BASE; i <= CPU_IRQ_MAX; i++) {
-		irq_desc[i].chip = &cpu_interrupt_type;
+		set_irq_chip_and_handler(i, &cpu_interrupt_type, parisc_do_IRQ);
 	}
 
-	irq_desc[TIMER_IRQ].action = &timer_action;
-	irq_desc[TIMER_IRQ].status = IRQ_PER_CPU;
+	set_irq_handler(TIMER_IRQ, handle_percpu_irq);
+	setup_irq(TIMER_IRQ, &timer_action);
 #ifdef CONFIG_SMP
-	irq_desc[IPI_IRQ].action = &ipi_action;
-	irq_desc[IPI_IRQ].status = IRQ_PER_CPU;
+	set_irq_handler(IPI_IRQ, handle_percpu_irq);
+	setup_irq(IPI_IRQ, &ipi_action);
 #endif
 }
 
@@ -423,3 +424,8 @@ void __init init_IRQ(void)
         set_eiem(cpu_eiem);	/* EIEM : enable all external intr */
 
 }
+
+void parisc_do_IRQ(unsigned int irq, struct irq_desc *desc)
+{
+	__do_IRQ(irq);
+}

commit d0608b54740c82b08056b7611e38a3fd73be3564
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Nov 17 22:50:59 2009 +0000

    parisc: Fixup last users of irq_chip->typename
    
    The typename member of struct irq_chip was kept for migration purposes
    and is obsolete since more than 2 years. Fix up the leftovers.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index f47465e8d040..efbcee5d2220 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -145,7 +145,7 @@ static int cpu_set_affinity_irq(unsigned int irq, const struct cpumask *dest)
 #endif
 
 static struct irq_chip cpu_interrupt_type = {
-	.typename	= "CPU",
+	.name		= "CPU",
 	.startup	= cpu_startup_irq,
 	.shutdown	= cpu_disable_irq,
 	.enable		= cpu_enable_irq,
@@ -192,7 +192,7 @@ int show_interrupts(struct seq_file *p, void *v)
 		seq_printf(p, "%10u ", kstat_irqs(i));
 #endif
 
-		seq_printf(p, " %14s", irq_desc[i].chip->typename);
+		seq_printf(p, " %14s", irq_desc[i].chip->name);
 #ifndef PARISC_IRQ_CR16_COUNTS
 		seq_printf(p, "  %s", action->name);
 

commit 239007b8440abff689632f50cdf0f2b9e895b534
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Nov 17 16:46:45 2009 +0100

    genirq: Convert irq_desc.lock to raw_spinlock
    
    Convert locks which cannot be sleeping locks in preempt-rt to
    raw_spinlocks.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Acked-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 2e7610cb33d5..f47465e8d040 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -180,7 +180,7 @@ int show_interrupts(struct seq_file *p, void *v)
 	if (i < NR_IRQS) {
 		struct irqaction *action;
 
-		spin_lock_irqsave(&irq_desc[i].lock, flags);
+		raw_spin_lock_irqsave(&irq_desc[i].lock, flags);
 		action = irq_desc[i].action;
 		if (!action)
 			goto skip;
@@ -224,7 +224,7 @@ int show_interrupts(struct seq_file *p, void *v)
 
 		seq_putc(p, '\n');
  skip:
-		spin_unlock_irqrestore(&irq_desc[i].lock, flags);
+		raw_spin_unlock_irqrestore(&irq_desc[i].lock, flags);
 	}
 
 	return 0;

commit 9609bfec6d869bc0d82ccfb909d5e72b7002d813
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Aug 4 14:54:41 2009 +0200

    parisc: convert to asm-generic/hardirq.h
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 330f536a9324..2e7610cb33d5 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -423,8 +423,3 @@ void __init init_IRQ(void)
         set_eiem(cpu_eiem);	/* EIEM : enable all external intr */
 
 }
-
-void ack_bad_irq(unsigned int irq)
-{
-	printk(KERN_WARNING "unexpected IRQ %d\n", irq);
-}

commit dfe07565021959f0f646e9e775810c1bfbe0f6d6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Jun 10 19:56:04 2009 +0000

    parisc: remove obsolete hw_interrupt_type
    
    The defines and typedefs (hw_interrupt_type, no_irq_type, irq_desc_t) have
    been kept around for migration reasons.  After more than two years it's
    time to remove them finally.
    
    This patch cleans up one of the remaining users.  When all such patches
    hit mainline we can remove the defines and typedefs finally.
    
    Impact: cleanup
    
    Convert the last remaining users to struct irq_chip and remove the
    define.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 639451c50e47..330f536a9324 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -144,7 +144,7 @@ static int cpu_set_affinity_irq(unsigned int irq, const struct cpumask *dest)
 }
 #endif
 
-static struct hw_interrupt_type cpu_interrupt_type = {
+static struct irq_chip cpu_interrupt_type = {
 	.typename	= "CPU",
 	.startup	= cpu_startup_irq,
 	.shutdown	= cpu_disable_irq,

commit 47b4150baa003fb83b93365f3eadd4c373e4fa6c
Author: Helge Deller <deller@gmx.de>
Date:   Sat Jun 6 21:54:28 2009 +0000

    parisc: fix irq compile bugs in arch/parisc/kernel/irq.c
    
    Fix miscompilation in arch/parisc/kernel/irq.c:
    123: warning: passing arg 1 of `cpumask_setall' from incompatible pointer type
    141: warning: passing arg 1 of `cpumask_copy' from incompatible pointer type
    300: warning: passing arg 1 of `cpumask_copy' from incompatible pointer type
    357: warning: passing arg 2 of `cpumask_copy' from incompatible pointer type
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 8007f1e65729..639451c50e47 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -120,7 +120,7 @@ int cpu_check_affinity(unsigned int irq, const struct cpumask *dest)
 	if (CHECK_IRQ_PER_CPU(irq)) {
 		/* Bad linux design decision.  The mask has already
 		 * been set; we must reset it */
-		cpumask_setall(&irq_desc[irq].affinity);
+		cpumask_setall(irq_desc[irq].affinity);
 		return -EINVAL;
 	}
 
@@ -138,7 +138,7 @@ static int cpu_set_affinity_irq(unsigned int irq, const struct cpumask *dest)
 	if (cpu_dest < 0)
 		return -1;
 
-	cpumask_copy(&irq_desc[irq].affinity, dest);
+	cpumask_copy(irq_desc[irq].affinity, dest);
 
 	return 0;
 }
@@ -299,7 +299,7 @@ int txn_alloc_irq(unsigned int bits_wide)
 unsigned long txn_affinity_addr(unsigned int irq, int cpu)
 {
 #ifdef CONFIG_SMP
-	cpumask_copy(&irq_desc[irq].affinity, cpumask_of(cpu));
+	cpumask_copy(irq_desc[irq].affinity, cpumask_of(cpu));
 #endif
 
 	return per_cpu(cpu_data, cpu).txn_addr;
@@ -356,7 +356,7 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 	irq = eirr_to_irq(eirr_val);
 
 #ifdef CONFIG_SMP
-	cpumask_copy(&dest, &irq_desc[irq].affinity);
+	cpumask_copy(&dest, irq_desc[irq].affinity);
 	if (CHECK_IRQ_PER_CPU(irq_desc[irq].status) &&
 	    !cpu_isset(smp_processor_id(), dest)) {
 		int cpu = first_cpu(dest);

commit d5dedd4507d307eb3f35f21b6e16f336fdc0d82a
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Mon Apr 27 17:59:21 2009 -0700

    irq: change ->set_affinity() to return status
    
    according to Ingo, change set_affinity() in irq_chip should return int,
    because that way we can handle failure cases in a much cleaner way, in
    the genirq layer.
    
    v2: fix two typos
    
    [ Impact: extend API ]
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Suresh Siddha <suresh.b.siddha@intel.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: linux-arch@vger.kernel.org
    LKML-Reference: <49F654E9.4070809@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 4ea4229d765c..8007f1e65729 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -130,15 +130,17 @@ int cpu_check_affinity(unsigned int irq, const struct cpumask *dest)
 	return cpu_dest;
 }
 
-static void cpu_set_affinity_irq(unsigned int irq, const struct cpumask *dest)
+static int cpu_set_affinity_irq(unsigned int irq, const struct cpumask *dest)
 {
 	int cpu_dest;
 
 	cpu_dest = cpu_check_affinity(irq, dest);
 	if (cpu_dest < 0)
-		return;
+		return -1;
 
 	cpumask_copy(&irq_desc[irq].affinity, dest);
+
+	return 0;
 }
 #endif
 

commit 7cec2ef4a298605b010f1c80041de884e777ea67
Merge: 91400ac365da 9bc181d8d7cb
Author: Kyle McMartin <kyle@mcmartin.ca>
Date:   Thu Apr 2 01:43:14 2009 +0000

    Merge branch 'rusty-cpumask-parisc' into parisc

commit 6e15cf04860074ad032e88c306bea656bbdd0f22
Merge: be0ea69674ed 60db56422043
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Mar 26 21:39:17 2009 +0100

    Merge branch 'core/percpu' into percpu-cpumask-x86-for-linus-2
    
    Conflicts:
            arch/parisc/kernel/irq.c
            arch/x86/include/asm/fixmap_64.h
            arch/x86/include/asm/setup.h
            kernel/irq/handle.c
    
    Semantic merge:
            arch/x86/include/asm/fixmap.h
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit edb35028e40515beb2f94808aff8b3e71fb9f35a
Merge: 8f8573ae9f5d cb065c06b6cc 5bee17f18b59
Author: Ingo Molnar <mingo@elte.hu>
Date:   Mon Mar 16 09:20:13 2009 +0100

    Merge branches 'irq/genirq' and 'linus' into irq/core

commit bd071e1a371d31db243edc4714ff9e8d1ea1309e
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Mon Mar 16 14:19:37 2009 +1030

    cpumask: prepare for iterators to only go to nr_cpu_ids/nr_cpumask_bits.: parisc
    
    Impact: cleanup, futureproof
    
    In fact, all cpumask ops will only be valid (in general) for bit
    numbers < nr_cpu_ids.  So use that instead of NR_CPUS in various
    places.
    
    This is always safe: no cpu number can be >= nr_cpu_ids, and
    nr_cpu_ids is initialized to NR_CPUS at boot.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Mike Travis <travis@sgi.com>
    Acked-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 29e70e16ede8..103752a8fb94 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -311,12 +311,12 @@ unsigned long txn_alloc_addr(unsigned int virt_irq)
 	next_cpu++; /* assign to "next" CPU we want this bugger on */
 
 	/* validate entry */
-	while ((next_cpu < NR_CPUS) &&
+	while ((next_cpu < nr_cpu_ids) &&
 		(!per_cpu(cpu_data, next_cpu).txn_addr ||
 		 !cpu_online(next_cpu)))
 		next_cpu++;
 
-	if (next_cpu >= NR_CPUS) 
+	if (next_cpu >= nr_cpu_ids) 
 		next_cpu = 0;	/* nothing else, assign monarch */
 
 	return txn_affinity_addr(virt_irq, next_cpu);

commit 8b6649c575e0d8312f62fe643ae43558892da2e1
Author: Kyle McMartin <kyle@shortfin.cabal.ca>
Date:   Mon Feb 16 03:20:54 2009 -0500

    parisc: convert cpu_check_affinity to new cpumask api
    
    cpumask arg to the affinity function is now const, sort
    that out through the irq_desc implementations.
    
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index a572112f5aba..29e70e16ede8 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -112,7 +112,7 @@ void cpu_end_irq(unsigned int irq)
 }
 
 #ifdef CONFIG_SMP
-int cpu_check_affinity(unsigned int irq, cpumask_t *dest)
+int cpu_check_affinity(unsigned int irq, const struct cpumask *dest)
 {
 	int cpu_dest;
 
@@ -126,17 +126,19 @@ int cpu_check_affinity(unsigned int irq, cpumask_t *dest)
 
 	/* whatever mask they set, we just allow one CPU */
 	cpu_dest = first_cpu(*dest);
-	*dest = cpumask_of_cpu(cpu_dest);
 
-	return 0;
+	return cpu_dest;
 }
 
 static void cpu_set_affinity_irq(unsigned int irq, const struct cpumask *dest)
 {
-	if (cpu_check_affinity(irq, dest))
+	int cpu_dest;
+
+	cpu_dest = cpu_check_affinity(irq, dest);
+	if (cpu_dest < 0)
 		return;
 
-	cpumask_copy(&irq_desc[irq].affinity, dest);
+	cpumask_copy(&irq_desc[irq].affinity, &cpumask_of_cpu(cpu_dest));
 }
 #endif
 

commit 7c4be70e6d07582a111a1b66942c8a1d45528dfb
Author: Kyle McMartin <kyle@shortfin.cabal.ca>
Date:   Mon Feb 16 02:53:03 2009 -0500

    parisc: fix use of new cpumask api in irq.c
    
    cpumask api needs to take a pointer to irq_desc[cpu].affinity
    
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 49482806863f..a572112f5aba 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -120,7 +120,7 @@ int cpu_check_affinity(unsigned int irq, cpumask_t *dest)
 	if (CHECK_IRQ_PER_CPU(irq)) {
 		/* Bad linux design decision.  The mask has already
 		 * been set; we must reset it */
-		cpumask_setall(irq_desc[irq].affinity);
+		cpumask_setall(&irq_desc[irq].affinity);
 		return -EINVAL;
 	}
 
@@ -136,7 +136,7 @@ static void cpu_set_affinity_irq(unsigned int irq, const struct cpumask *dest)
 	if (cpu_check_affinity(irq, dest))
 		return;
 
-	cpumask_copy(irq_desc[irq].affinity, dest);
+	cpumask_copy(&irq_desc[irq].affinity, dest);
 }
 #endif
 
@@ -295,7 +295,7 @@ int txn_alloc_irq(unsigned int bits_wide)
 unsigned long txn_affinity_addr(unsigned int irq, int cpu)
 {
 #ifdef CONFIG_SMP
-	cpumask_copy(irq_desc[irq].affinity, cpumask_of(cpu));
+	cpumask_copy(&irq_desc[irq].affinity, cpumask_of(cpu));
 #endif
 
 	return per_cpu(cpu_data, cpu).txn_addr;
@@ -352,7 +352,7 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 	irq = eirr_to_irq(eirr_val);
 
 #ifdef CONFIG_SMP
-	cpumask_copy(&dest, irq_desc[irq].affinity);
+	cpumask_copy(&dest, &irq_desc[irq].affinity);
 	if (CHECK_IRQ_PER_CPU(irq_desc[irq].status) &&
 	    !cpu_isset(smp_processor_id(), dest)) {
 		int cpu = first_cpu(dest);

commit 5a8247ca4c6441cafbb852cb1048d1056734a90c
Author: Mike Travis <travis@sgi.com>
Date:   Tue Jan 13 03:05:25 2009 +0000

    parisc: update parisc for new irq_desc
    
    Impact: cleanup, update to new cpumask API
    
    Irq_desc.affinity and irq_desc.pending_mask are now cpumask_var_t's
    so access to them should be using the new cpumask API.
    
    Signed-off-by: Mike Travis <travis@sgi.com>
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index ac2c822928c7..49482806863f 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -120,7 +120,7 @@ int cpu_check_affinity(unsigned int irq, cpumask_t *dest)
 	if (CHECK_IRQ_PER_CPU(irq)) {
 		/* Bad linux design decision.  The mask has already
 		 * been set; we must reset it */
-		irq_desc[irq].affinity = CPU_MASK_ALL;
+		cpumask_setall(irq_desc[irq].affinity);
 		return -EINVAL;
 	}
 
@@ -136,7 +136,7 @@ static void cpu_set_affinity_irq(unsigned int irq, const struct cpumask *dest)
 	if (cpu_check_affinity(irq, dest))
 		return;
 
-	irq_desc[irq].affinity = *dest;
+	cpumask_copy(irq_desc[irq].affinity, dest);
 }
 #endif
 
@@ -295,7 +295,7 @@ int txn_alloc_irq(unsigned int bits_wide)
 unsigned long txn_affinity_addr(unsigned int irq, int cpu)
 {
 #ifdef CONFIG_SMP
-	irq_desc[irq].affinity = cpumask_of_cpu(cpu);
+	cpumask_copy(irq_desc[irq].affinity, cpumask_of(cpu));
 #endif
 
 	return per_cpu(cpu_data, cpu).txn_addr;
@@ -352,7 +352,7 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 	irq = eirr_to_irq(eirr_val);
 
 #ifdef CONFIG_SMP
-	dest = irq_desc[irq].affinity;
+	cpumask_copy(&dest, irq_desc[irq].affinity);
 	if (CHECK_IRQ_PER_CPU(irq_desc[irq].status) &&
 	    !cpu_isset(smp_processor_id(), dest)) {
 		int cpu = first_cpu(dest);

commit e65e49d0f3714f4a6a42f6f6a19926ba33fcda75
Author: Mike Travis <travis@sgi.com>
Date:   Mon Jan 12 15:27:13 2009 -0800

    irq: update all arches for new irq_desc
    
    Impact: cleanup, update to new cpumask API
    
    Irq_desc.affinity and irq_desc.pending_mask are now cpumask_var_t's
    so access to them should be using the new cpumask API.
    
    Signed-off-by: Mike Travis <travis@sgi.com>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index ac2c822928c7..49482806863f 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -120,7 +120,7 @@ int cpu_check_affinity(unsigned int irq, cpumask_t *dest)
 	if (CHECK_IRQ_PER_CPU(irq)) {
 		/* Bad linux design decision.  The mask has already
 		 * been set; we must reset it */
-		irq_desc[irq].affinity = CPU_MASK_ALL;
+		cpumask_setall(irq_desc[irq].affinity);
 		return -EINVAL;
 	}
 
@@ -136,7 +136,7 @@ static void cpu_set_affinity_irq(unsigned int irq, const struct cpumask *dest)
 	if (cpu_check_affinity(irq, dest))
 		return;
 
-	irq_desc[irq].affinity = *dest;
+	cpumask_copy(irq_desc[irq].affinity, dest);
 }
 #endif
 
@@ -295,7 +295,7 @@ int txn_alloc_irq(unsigned int bits_wide)
 unsigned long txn_affinity_addr(unsigned int irq, int cpu)
 {
 #ifdef CONFIG_SMP
-	irq_desc[irq].affinity = cpumask_of_cpu(cpu);
+	cpumask_copy(irq_desc[irq].affinity, cpumask_of(cpu));
 #endif
 
 	return per_cpu(cpu_data, cpu).txn_addr;
@@ -352,7 +352,7 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 	irq = eirr_to_irq(eirr_val);
 
 #ifdef CONFIG_SMP
-	dest = irq_desc[irq].affinity;
+	cpumask_copy(&dest, irq_desc[irq].affinity);
 	if (CHECK_IRQ_PER_CPU(irq_desc[irq].status) &&
 	    !cpu_isset(smp_processor_id(), dest)) {
 		int cpu = first_cpu(dest);

commit dee4102a9a5882b4f7d5cc165ba29e8cc63cf92e
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Sun Jan 11 00:29:15 2009 -0800

    sparseirq: use kstat_irqs_cpu instead
    
    Impact: build fix
    
    Ingo Molnar wrote:
    
    > tip/arch/blackfin/kernel/irqchip.c: In function 'show_interrupts':
    > tip/arch/blackfin/kernel/irqchip.c:85: error: 'struct kernel_stat' has no member named 'irqs'
    > make[2]: *** [arch/blackfin/kernel/irqchip.o] Error 1
    > make[2]: *** Waiting for unfinished jobs....
    >
    
    So could move kstat_irqs array to irq_desc struct.
    
    (s390, m68k, sparc) are not touched yet, because they don't support genirq
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index ac2c822928c7..704341b0b098 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -183,7 +183,7 @@ int show_interrupts(struct seq_file *p, void *v)
 		seq_printf(p, "%3d: ", i);
 #ifdef CONFIG_SMP
 		for_each_online_cpu(j)
-			seq_printf(p, "%10u ", kstat_cpu(j).irqs[i]);
+			seq_printf(p, "%10u ", kstat_irqs_cpu(i, j));
 #else
 		seq_printf(p, "%10u ", kstat_irqs(i));
 #endif

commit ef017bebd01c1b4e075d649eee0c8c1c79f9ceb9
Author: Helge Deller <deller@gmx.de>
Date:   Wed Dec 31 03:12:10 2008 +0000

    parisc: Replace NR_CPUS in parisc code
    
    parisc: Replace most arrays sized by NR_CPUS with percpu variables.
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 13fc4cd5bfdf..ac2c822928c7 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -298,7 +298,7 @@ unsigned long txn_affinity_addr(unsigned int irq, int cpu)
 	irq_desc[irq].affinity = cpumask_of_cpu(cpu);
 #endif
 
-	return cpu_data[cpu].txn_addr;
+	return per_cpu(cpu_data, cpu).txn_addr;
 }
 
 
@@ -309,8 +309,9 @@ unsigned long txn_alloc_addr(unsigned int virt_irq)
 	next_cpu++; /* assign to "next" CPU we want this bugger on */
 
 	/* validate entry */
-	while ((next_cpu < NR_CPUS) && (!cpu_data[next_cpu].txn_addr || 
-		!cpu_online(next_cpu)))
+	while ((next_cpu < NR_CPUS) &&
+		(!per_cpu(cpu_data, next_cpu).txn_addr ||
+		 !cpu_online(next_cpu)))
 		next_cpu++;
 
 	if (next_cpu >= NR_CPUS) 
@@ -359,7 +360,7 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 		printk(KERN_DEBUG "redirecting irq %d from CPU %d to %d\n",
 		       irq, smp_processor_id(), cpu);
 		gsc_writel(irq + CPU_IRQ_BASE,
-			   cpu_data[cpu].hpa);
+			   per_cpu(cpu_data, cpu).hpa);
 		goto set_out;
 	}
 #endif

commit 7f2347a44d2d5c8edf04d6950f4fb21ac868d256
Author: Helge Deller <deller@gmx.de>
Date:   Wed Dec 31 03:11:31 2008 +0000

    parisc: trivial fixes
    
    trivial fixes:
    - use KERN_WARNING for printk()
    - use BUG_ON() instead of "if (xx) BUG();"
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>
    
    --
    To unsubscribe from this list: send the line "unsubscribe linux-parisc" in
    the body of a message to majordomo@vger.kernel.org
    More majordomo info at  http://vger.kernel.org/majordomo-info.html

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 4cea935e2f99..13fc4cd5bfdf 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -421,5 +421,5 @@ void __init init_IRQ(void)
 
 void ack_bad_irq(unsigned int irq)
 {
-	printk("unexpected IRQ %d\n", irq);
+	printk(KERN_WARNING "unexpected IRQ %d\n", irq);
 }

commit 0de26520c7cabf36e1de090ea8092f011a6106ce
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Sat Dec 13 21:20:26 2008 +1030

    cpumask: make irq_set_affinity() take a const struct cpumask
    
    Impact: change existing irq_chip API
    
    Not much point with gentle transition here: the struct irq_chip's
    setaffinity method signature needs to change.
    
    Fortunately, not widely used code, but hits a few architectures.
    
    Note: In irq_select_affinity() I save a temporary in by mangling
    irq_desc[irq].affinity directly.  Ingo, does this break anything?
    
    (Folded in fix from KOSAKI Motohiro)
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Mike Travis <travis@sgi.com>
    Reviewed-by: Grant Grundler <grundler@parisc-linux.org>
    Acked-by: Ingo Molnar <mingo@redhat.com>
    Cc: ralf@linux-mips.org
    Cc: grundler@parisc-linux.org
    Cc: jeremy@xensource.com
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 23ef950df008..4cea935e2f99 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -131,12 +131,12 @@ int cpu_check_affinity(unsigned int irq, cpumask_t *dest)
 	return 0;
 }
 
-static void cpu_set_affinity_irq(unsigned int irq, cpumask_t dest)
+static void cpu_set_affinity_irq(unsigned int irq, const struct cpumask *dest)
 {
-	if (cpu_check_affinity(irq, &dest))
+	if (cpu_check_affinity(irq, dest))
 		return;
 
-	irq_desc[irq].affinity = dest;
+	irq_desc[irq].affinity = *dest;
 }
 #endif
 

commit 2421ba5b57ddbc3a972b9d6fb884817c39d2fff7
Author: Kyle McMartin <kyle@mako.i.cabal.ca>
Date:   Wed Nov 28 02:17:53 2007 -0500

    [PARISC] timer interrupt should not be IRQ_DISABLED
    
    The timer interrupt had accidentally been marked IRQ_DISABLED since
    IRQ_PER_CPU had been OR-ed in, instead of set. This had been working
    by accident for quite a while.
    
    Commit c642b8391cf8efc3622cc97329a0f46e7cbb70b8 changed the behaviour of
    IRQ_PER_CPU interrupts, which previously weren't checked for IRQ_DISABLED.
    
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 76ce5e3b0050..23ef950df008 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -397,7 +397,7 @@ static void claim_cpu_irqs(void)
 	}
 
 	irq_desc[TIMER_IRQ].action = &timer_action;
-	irq_desc[TIMER_IRQ].status |= IRQ_PER_CPU;
+	irq_desc[TIMER_IRQ].status = IRQ_PER_CPU;
 #ifdef CONFIG_SMP
 	irq_desc[IPI_IRQ].action = &ipi_action;
 	irq_desc[IPI_IRQ].status = IRQ_PER_CPU;

commit 462b529f91b618f4bd144bbc6184f616dfb58a1e
Author: Grant Grundler <grundler@parisc-linux.org>
Date:   Sun Jun 10 16:31:41 2007 -0600

    [PARISC] remove global_ack_eiem
    
    Kudos to Thibaut Varene for spotting the (mis)use of appropriately named
    global_ack_eiem. This took a long time to figure out and both insight
    from myself, Kyle McMartin, and James Bottomley were required to narrow
    down which bit of code could have this race condition.
    
    The symptom was interrupts stopped getting delivered while some workload
    was generating IO interrupts on two different CPUs. One of the interrupt
    sources would get masked off and stay unmasked. Problem was global_ack_eiem
    was accessed with read/modified/write sequence and not protected by
    a spinlock.
    
    PA-RISC doesn't need a global ack flag though. External Interrupts
    are _always_ delivered to a single CPU (except for "global broadcast
    interrupt" which AFAIK currently is not used.) So we don't have to worry
    about any given IRQ vector getting delivered to more than one CPU.
    
    Tested on a500 and rp34xx boxen. rsync to/from gsyprf11 (a500)
    would lock up the box since NIC (tg3) interrupt and SCSI (sym2)
    were on "opposite" CPUs (2 CPU system). Put them on the same CPU
    or apply this patch and 10GB of data would rsync completely.
    
    Please apply the following critical patch.
    
    thanks,
    grant
    
    Signed-off-by: Grant Grundler <grundler@parisc-linux.org>
    Acked-by: Thibaut VARENE <T-Bone@parisc-linux.org>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index c5c9125dacec..76ce5e3b0050 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -46,14 +46,10 @@ extern irqreturn_t ipi_interrupt(int, void *);
 static volatile unsigned long cpu_eiem = 0;
 
 /*
-** ack bitmap ... habitually set to 1, but reset to zero
+** local ACK bitmap ... habitually set to 1, but reset to zero
 ** between ->ack() and ->end() of the interrupt to prevent
 ** re-interruption of a processing interrupt.
 */
-static volatile unsigned long global_ack_eiem = ~0UL;
-/*
-** Local bitmap, same as above but for per-cpu interrupts
-*/
 static DEFINE_PER_CPU(unsigned long, local_ack_eiem) = ~0UL;
 
 static void cpu_disable_irq(unsigned int irq)
@@ -94,13 +90,11 @@ void cpu_ack_irq(unsigned int irq)
 	int cpu = smp_processor_id();
 
 	/* Clear in EIEM so we can no longer process */
-	if (CHECK_IRQ_PER_CPU(irq_desc[irq].status))
-		per_cpu(local_ack_eiem, cpu) &= ~mask;
-	else
-		global_ack_eiem &= ~mask;
+	per_cpu(local_ack_eiem, cpu) &= ~mask;
 
 	/* disable the interrupt */
-	set_eiem(cpu_eiem & global_ack_eiem & per_cpu(local_ack_eiem, cpu));
+	set_eiem(cpu_eiem & per_cpu(local_ack_eiem, cpu));
+
 	/* and now ack it */
 	mtctl(mask, 23);
 }
@@ -111,13 +105,10 @@ void cpu_end_irq(unsigned int irq)
 	int cpu = smp_processor_id();
 
 	/* set it in the eiems---it's no longer in process */
-	if (CHECK_IRQ_PER_CPU(irq_desc[irq].status))
-		per_cpu(local_ack_eiem, cpu) |= mask;
-	else
-		global_ack_eiem |= mask;
+	per_cpu(local_ack_eiem, cpu) |= mask;
 
 	/* enable the interrupt */
-	set_eiem(cpu_eiem & global_ack_eiem & per_cpu(local_ack_eiem, cpu));
+	set_eiem(cpu_eiem & per_cpu(local_ack_eiem, cpu));
 }
 
 #ifdef CONFIG_SMP
@@ -354,8 +345,7 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 	local_irq_disable();
 	irq_enter();
 
-	eirr_val = mfctl(23) & cpu_eiem & global_ack_eiem &
-		per_cpu(local_ack_eiem, cpu);
+	eirr_val = mfctl(23) & cpu_eiem & per_cpu(local_ack_eiem, cpu);
 	if (!eirr_val)
 		goto set_out;
 	irq = eirr_to_irq(eirr_val);
@@ -381,7 +371,7 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 	return;
 
  set_out:
-	set_eiem(cpu_eiem & global_ack_eiem & per_cpu(local_ack_eiem, cpu));
+	set_eiem(cpu_eiem & per_cpu(local_ack_eiem, cpu));
 	goto out;
 }
 

commit 57501c70747fd6d7b14f7863126e5a75d29613b1
Author: Bernhard Walle <bwalle@suse.de>
Date:   Tue May 8 00:35:36 2007 -0700

    Add IRQF_IRQPOLL flag on parisc
    
    Add IRQF_IRQPOLL to the timer interrupt on parisc.
    
    Signed-off-by: Bernhard Walle <bwalle@suse.de>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: Matthew Wilcox <willy@debian.org>
    Cc: Grant Grundler <grundler@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index e9d09b020e86..c5c9125dacec 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -388,7 +388,7 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 static struct irqaction timer_action = {
 	.handler = timer_interrupt,
 	.name = "timer",
-	.flags = IRQF_DISABLED | IRQF_TIMER | IRQF_PERCPU,
+	.flags = IRQF_DISABLED | IRQF_TIMER | IRQF_PERCPU | IRQF_IRQPOLL,
 };
 
 #ifdef CONFIG_SMP

commit 0c2de3c6c481ba6a537f66c06a55bd5be5a2c99d
Author: Kyle McMartin <kyle@parisc-linux.org>
Date:   Sat Dec 30 19:24:37 2006 -0500

    [PARISC] use fls_long in irq.c
    
    
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index b39c5b9aff46..e9d09b020e86 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -336,11 +336,7 @@ unsigned int txn_alloc_data(unsigned int virt_irq)
 
 static inline int eirr_to_irq(unsigned long eirr)
 {
-#ifdef CONFIG_64BIT
-	int bit = fls64(eirr);
-#else
-	int bit = fls(eirr);
-#endif
+	int bit = fls_long(eirr);
 	return (BITS_PER_LONG - bit) + TIMER_IRQ;
 }
 

commit e11e30a063b515e95fb590f1558b5fea21273c63
Author: Matthew Wilcox <matthew@wil.cx>
Date:   Sat Oct 7 05:11:07 2006 -0600

    [PARISC] Use set_irq_regs
    
    Actually set the irq_regs pointer.
    
    Signed-off-by: Matthew Wilcox <matthew@wil.cx>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 2ece7c7939fe..b39c5b9aff46 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -347,12 +347,14 @@ static inline int eirr_to_irq(unsigned long eirr)
 /* ONLY called from entry.S:intr_extint() */
 void do_cpu_irq_mask(struct pt_regs *regs)
 {
+	struct pt_regs *old_regs;
 	unsigned long eirr_val;
 	int irq, cpu = smp_processor_id();
 #ifdef CONFIG_SMP
 	cpumask_t dest;
 #endif
 
+	old_regs = set_irq_regs(regs);
 	local_irq_disable();
 	irq_enter();
 
@@ -379,6 +381,7 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 
  out:
 	irq_exit();
+	set_irq_regs(old_regs);
 	return;
 
  set_out:

commit be577a5220b25e0a6e3fbf96bbfc8b31d63e9ea9
Author: Matthew Wilcox <matthew@wil.cx>
Date:   Fri Oct 6 20:47:23 2006 -0600

    Build fixes for struct pt_regs removal
    
    Signed-off-by: Matthew Wilcox <matthew@wil.cx>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 9bdd0197ceb7..2ece7c7939fe 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -35,8 +35,8 @@
 
 #undef PARISC_IRQ_CR16_COUNTS
 
-extern irqreturn_t timer_interrupt(int, void *, struct pt_regs *);
-extern irqreturn_t ipi_interrupt(int, void *, struct pt_regs *);
+extern irqreturn_t timer_interrupt(int, void *);
+extern irqreturn_t ipi_interrupt(int, void *);
 
 #define EIEM_MASK(irq)       (1UL<<(CPU_IRQ_MAX - irq))
 
@@ -375,7 +375,7 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 		goto set_out;
 	}
 #endif
-	__do_IRQ(irq, regs);
+	__do_IRQ(irq);
 
  out:
 	irq_exit();

commit 7085689ed135f94108e46c372015c6f5cd3372a3
Author: James Bottomley <jejb@parisc-linux.org>
Date:   Sat Sep 9 12:36:25 2006 -0700

    [PARISC] Allow nested interrupts
    
    Our prior mode of operation didn't allow nested interrupts
    because it makes the interrupt code much simpler.  However,
    nested interrupts are better for latency.
    
    This code uses the EIEM register to simulate level interrupts
    and thus achieve nesting.
    
    Signed-off-by: James Bottomley <James.Bottomley@SteelEye.com>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index c53bfeb4bf94..9bdd0197ceb7 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -45,6 +45,17 @@ extern irqreturn_t ipi_interrupt(int, void *, struct pt_regs *);
 */
 static volatile unsigned long cpu_eiem = 0;
 
+/*
+** ack bitmap ... habitually set to 1, but reset to zero
+** between ->ack() and ->end() of the interrupt to prevent
+** re-interruption of a processing interrupt.
+*/
+static volatile unsigned long global_ack_eiem = ~0UL;
+/*
+** Local bitmap, same as above but for per-cpu interrupts
+*/
+static DEFINE_PER_CPU(unsigned long, local_ack_eiem) = ~0UL;
+
 static void cpu_disable_irq(unsigned int irq)
 {
 	unsigned long eirr_bit = EIEM_MASK(irq);
@@ -62,13 +73,6 @@ static void cpu_enable_irq(unsigned int irq)
 
 	cpu_eiem |= eirr_bit;
 
-	/* FIXME: while our interrupts aren't nested, we cannot reset
-	 * the eiem mask if we're already in an interrupt.  Once we
-	 * implement nested interrupts, this can go away
-	 */
-	if (!in_interrupt())
-		set_eiem(cpu_eiem);
-
 	/* This is just a simple NOP IPI.  But what it does is cause
 	 * all the other CPUs to do a set_eiem(cpu_eiem) at the end
 	 * of the interrupt handler */
@@ -84,13 +88,45 @@ static unsigned int cpu_startup_irq(unsigned int irq)
 void no_ack_irq(unsigned int irq) { }
 void no_end_irq(unsigned int irq) { }
 
+void cpu_ack_irq(unsigned int irq)
+{
+	unsigned long mask = EIEM_MASK(irq);
+	int cpu = smp_processor_id();
+
+	/* Clear in EIEM so we can no longer process */
+	if (CHECK_IRQ_PER_CPU(irq_desc[irq].status))
+		per_cpu(local_ack_eiem, cpu) &= ~mask;
+	else
+		global_ack_eiem &= ~mask;
+
+	/* disable the interrupt */
+	set_eiem(cpu_eiem & global_ack_eiem & per_cpu(local_ack_eiem, cpu));
+	/* and now ack it */
+	mtctl(mask, 23);
+}
+
+void cpu_end_irq(unsigned int irq)
+{
+	unsigned long mask = EIEM_MASK(irq);
+	int cpu = smp_processor_id();
+
+	/* set it in the eiems---it's no longer in process */
+	if (CHECK_IRQ_PER_CPU(irq_desc[irq].status))
+		per_cpu(local_ack_eiem, cpu) |= mask;
+	else
+		global_ack_eiem |= mask;
+
+	/* enable the interrupt */
+	set_eiem(cpu_eiem & global_ack_eiem & per_cpu(local_ack_eiem, cpu));
+}
+
 #ifdef CONFIG_SMP
 int cpu_check_affinity(unsigned int irq, cpumask_t *dest)
 {
 	int cpu_dest;
 
 	/* timer and ipi have to always be received on all CPUs */
-	if (irq == TIMER_IRQ || irq == IPI_IRQ) {
+	if (CHECK_IRQ_PER_CPU(irq)) {
 		/* Bad linux design decision.  The mask has already
 		 * been set; we must reset it */
 		irq_desc[irq].affinity = CPU_MASK_ALL;
@@ -119,8 +155,8 @@ static struct hw_interrupt_type cpu_interrupt_type = {
 	.shutdown	= cpu_disable_irq,
 	.enable		= cpu_enable_irq,
 	.disable	= cpu_disable_irq,
-	.ack		= no_ack_irq,
-	.end		= no_end_irq,
+	.ack		= cpu_ack_irq,
+	.end		= cpu_end_irq,
 #ifdef CONFIG_SMP
 	.set_affinity	= cpu_set_affinity_irq,
 #endif
@@ -298,82 +334,69 @@ unsigned int txn_alloc_data(unsigned int virt_irq)
 	return virt_irq - CPU_IRQ_BASE;
 }
 
+static inline int eirr_to_irq(unsigned long eirr)
+{
+#ifdef CONFIG_64BIT
+	int bit = fls64(eirr);
+#else
+	int bit = fls(eirr);
+#endif
+	return (BITS_PER_LONG - bit) + TIMER_IRQ;
+}
+
 /* ONLY called from entry.S:intr_extint() */
 void do_cpu_irq_mask(struct pt_regs *regs)
 {
 	unsigned long eirr_val;
-
-	irq_enter();
-
-	/*
-	 * Don't allow TIMER or IPI nested interrupts.
-	 * Allowing any single interrupt to nest can lead to that CPU
-	 * handling interrupts with all enabled interrupts unmasked.
-	 */
-	set_eiem(0UL);
-
-	/* 1) only process IRQs that are enabled/unmasked (cpu_eiem)
-	 * 2) We loop here on EIRR contents in order to avoid
-	 *    nested interrupts or having to take another interrupt
-	 *    when we could have just handled it right away.
-	 */
-	for (;;) {
-		unsigned long bit = (1UL << (BITS_PER_LONG - 1));
-		unsigned int irq;
-		eirr_val = mfctl(23) & cpu_eiem;
-		if (!eirr_val)
-			break;
-
-		mtctl(eirr_val, 23); /* reset bits we are going to process */
-
-		/* Work our way from MSb to LSb...same order we alloc EIRs */
-		for (irq = TIMER_IRQ; eirr_val && bit; bit>>=1, irq++) {
+	int irq, cpu = smp_processor_id();
 #ifdef CONFIG_SMP
-			cpumask_t dest = irq_desc[irq].affinity;
+	cpumask_t dest;
 #endif
-			if (!(bit & eirr_val))
-				continue;
 
-			/* clear bit in mask - can exit loop sooner */
-			eirr_val &= ~bit;
+	local_irq_disable();
+	irq_enter();
 
-#ifdef CONFIG_SMP
-			/* FIXME: because generic set affinity mucks
-			 * with the affinity before sending it to us
-			 * we can get the situation where the affinity is
-			 * wrong for our CPU type interrupts */
-			if (irq != TIMER_IRQ && irq != IPI_IRQ &&
-			    !cpu_isset(smp_processor_id(), dest)) {
-				int cpu = first_cpu(dest);
-
-				printk(KERN_DEBUG "redirecting irq %d from CPU %d to %d\n",
-				       irq, smp_processor_id(), cpu);
-				gsc_writel(irq + CPU_IRQ_BASE,
-					   cpu_data[cpu].hpa);
-				continue;
-			}
-#endif
+	eirr_val = mfctl(23) & cpu_eiem & global_ack_eiem &
+		per_cpu(local_ack_eiem, cpu);
+	if (!eirr_val)
+		goto set_out;
+	irq = eirr_to_irq(eirr_val);
 
-			__do_IRQ(irq, regs);
-		}
+#ifdef CONFIG_SMP
+	dest = irq_desc[irq].affinity;
+	if (CHECK_IRQ_PER_CPU(irq_desc[irq].status) &&
+	    !cpu_isset(smp_processor_id(), dest)) {
+		int cpu = first_cpu(dest);
+
+		printk(KERN_DEBUG "redirecting irq %d from CPU %d to %d\n",
+		       irq, smp_processor_id(), cpu);
+		gsc_writel(irq + CPU_IRQ_BASE,
+			   cpu_data[cpu].hpa);
+		goto set_out;
 	}
+#endif
+	__do_IRQ(irq, regs);
 
-	set_eiem(cpu_eiem);	/* restore original mask */
+ out:
 	irq_exit();
-}
+	return;
 
+ set_out:
+	set_eiem(cpu_eiem & global_ack_eiem & per_cpu(local_ack_eiem, cpu));
+	goto out;
+}
 
 static struct irqaction timer_action = {
 	.handler = timer_interrupt,
 	.name = "timer",
-	.flags = IRQF_DISABLED,
+	.flags = IRQF_DISABLED | IRQF_TIMER | IRQF_PERCPU,
 };
 
 #ifdef CONFIG_SMP
 static struct irqaction ipi_action = {
 	.handler = ipi_interrupt,
 	.name = "IPI",
-	.flags = IRQF_DISABLED,
+	.flags = IRQF_DISABLED | IRQF_PERCPU,
 };
 #endif
 

commit 5cfe87d3f543d05a84a509d232330261f1b7bccf
Author: Kyle McMartin <kyle@parisc-linux.org>
Date:   Sun Aug 13 22:25:45 2006 -0400

    [PARISC] Fix up parisc irq handling for genirq changes
    
    Clean up enough to get things compiling again in the interim.
    
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 5b8803cc3d69..c53bfeb4bf94 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -209,7 +209,7 @@ int show_interrupts(struct seq_file *p, void *v)
 ** Then use that to get the Transaction address and data.
 */
 
-int cpu_claim_irq(unsigned int irq, struct hw_interrupt_type *type, void *data)
+int cpu_claim_irq(unsigned int irq, struct irq_chip *type, void *data)
 {
 	if (irq_desc[irq].action)
 		return -EBUSY;

commit 733ea869e5756e0fd0333728cc1ed7c42e6ddfc0
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 1 19:29:21 2006 -0700

    [PATCH] irq-flags: PARISC: Use the new IRQF_ constants
    
    Use the new IRQF_ constants and remove the SA_INTERRUPT define
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 52761d96f991..5b8803cc3d69 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -366,14 +366,14 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 static struct irqaction timer_action = {
 	.handler = timer_interrupt,
 	.name = "timer",
-	.flags = SA_INTERRUPT,
+	.flags = IRQF_DISABLED,
 };
 
 #ifdef CONFIG_SMP
 static struct irqaction ipi_action = {
 	.handler = ipi_interrupt,
 	.name = "IPI",
-	.flags = SA_INTERRUPT,
+	.flags = IRQF_DISABLED,
 };
 #endif
 

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: Jörn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: Jörn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 82fe6ba29727..52761d96f991 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -22,7 +22,6 @@
  *    Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
  */
 #include <linux/bitops.h>
-#include <linux/config.h>
 #include <linux/errno.h>
 #include <linux/init.h>
 #include <linux/interrupt.h>

commit c0ad90a32fb60f4129d0e24dfd5fd7128e2e09f2
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 29 02:24:44 2006 -0700

    [PATCH] genirq: add ->retrigger() irq op to consolidate hw_irq_resend()
    
    Add ->retrigger() irq op to consolidate hw_irq_resend() implementations.
    (Most architectures had it defined to NOP anyway.)
    
    NOTE: ia64 needs testing. i386 and x86_64 tested.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index ea6a55e1a0c5..82fe6ba29727 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -125,6 +125,10 @@ static struct hw_interrupt_type cpu_interrupt_type = {
 #ifdef CONFIG_SMP
 	.set_affinity	= cpu_set_affinity_irq,
 #endif
+	/* XXX: Needs to be written.  We managed without it so far, but
+	 * we really ought to write it.
+	 */
+	.retrigger	= NULL,
 };
 
 int show_interrupts(struct seq_file *p, void *v)
@@ -404,13 +408,6 @@ void __init init_IRQ(void)
 
 }
 
-void hw_resend_irq(struct hw_interrupt_type *type, unsigned int irq)
-{
-	/* XXX: Needs to be written.  We managed without it so far, but
-	 * we really ought to write it.
-	 */
-}
-
 void ack_bad_irq(unsigned int irq)
 {
 	printk("unexpected IRQ %d\n", irq);

commit a53da52fd743fd637637572838c0a7af23a2d038
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 29 02:24:38 2006 -0700

    [PATCH] genirq: cleanup: merge irq_affinity[] into irq_desc[]
    
    Consolidation: remove the irq_affinity[NR_IRQS] array and move it into the
    irq_desc[NR_IRQS].affinity field.
    
    [akpm@osdl.org: sparc64 build fix]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 26e69f73fdb0..ea6a55e1a0c5 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -94,7 +94,7 @@ int cpu_check_affinity(unsigned int irq, cpumask_t *dest)
 	if (irq == TIMER_IRQ || irq == IPI_IRQ) {
 		/* Bad linux design decision.  The mask has already
 		 * been set; we must reset it */
-		irq_affinity[irq] = CPU_MASK_ALL;
+		irq_desc[irq].affinity = CPU_MASK_ALL;
 		return -EINVAL;
 	}
 
@@ -110,7 +110,7 @@ static void cpu_set_affinity_irq(unsigned int irq, cpumask_t dest)
 	if (cpu_check_affinity(irq, &dest))
 		return;
 
-	irq_affinity[irq] = dest;
+	irq_desc[irq].affinity = dest;
 }
 #endif
 
@@ -265,7 +265,7 @@ int txn_alloc_irq(unsigned int bits_wide)
 unsigned long txn_affinity_addr(unsigned int irq, int cpu)
 {
 #ifdef CONFIG_SMP
-	irq_affinity[irq] = cpumask_of_cpu(cpu);
+	irq_desc[irq].affinity = cpumask_of_cpu(cpu);
 #endif
 
 	return cpu_data[cpu].txn_addr;
@@ -326,7 +326,7 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 		/* Work our way from MSb to LSb...same order we alloc EIRs */
 		for (irq = TIMER_IRQ; eirr_val && bit; bit>>=1, irq++) {
 #ifdef CONFIG_SMP
-			cpumask_t dest = irq_affinity[irq];
+			cpumask_t dest = irq_desc[irq].affinity;
 #endif
 			if (!(bit & eirr_val))
 				continue;

commit d1bef4ed5faf7d9872337b33c4269e45ae1bf960
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jun 29 02:24:36 2006 -0700

    [PATCH] genirq: rename desc->handler to desc->chip
    
    This patch-queue improves the generic IRQ layer to be truly generic, by adding
    various abstractions and features to it, without impacting existing
    functionality.
    
    While the queue can be best described as "fix and improve everything in the
    generic IRQ layer that we could think of", and thus it consists of many
    smaller features and lots of cleanups, the one feature that stands out most is
    the new 'irq chip' abstraction.
    
    The irq-chip abstraction is about describing and coding and IRQ controller
    driver by mapping its raw hardware capabilities [and quirks, if needed] in a
    straightforward way, without having to think about "IRQ flow"
    (level/edge/etc.) type of details.
    
    This stands in contrast with the current 'irq-type' model of genirq
    architectures, which 'mixes' raw hardware capabilities with 'flow' details.
    The patchset supports both types of irq controller designs at once, and
    converts i386 and x86_64 to the new irq-chip design.
    
    As a bonus side-effect of the irq-chip approach, chained interrupt controllers
    (master/slave PIC constructs, etc.) are now supported by design as well.
    
    The end result of this patchset intends to be simpler architecture-level code
    and more consolidation between architectures.
    
    We reused many bits of code and many concepts from Russell King's ARM IRQ
    layer, the merging of which was one of the motivations for this patchset.
    
    This patch:
    
    rename desc->handler to desc->chip.
    
    Originally i did not want to do this, because it's a big patch.  But having
    both "desc->handler", "desc->handle_irq" and "action->handler" caused a
    large degree of confusion and made the code appear alot less clean than it
    truly is.
    
    I have also attempted a dual approach as well by introducing a
    desc->chip alias - but that just wasnt robust enough and broke
    frequently.
    
    So lets get over with this quickly.  The conversion was done automatically
    via scripts and converts all the code in the kernel.
    
    This renaming patch is the first one amongst the patches, so that the
    remaining patches can stay flexible and can be merged and split up
    without having some big monolithic patch act as a merge barrier.
    
    [akpm@osdl.org: build fix]
    [akpm@osdl.org: another build fix]
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 197936d9359a..26e69f73fdb0 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -158,7 +158,7 @@ int show_interrupts(struct seq_file *p, void *v)
 		seq_printf(p, "%10u ", kstat_irqs(i));
 #endif
 
-		seq_printf(p, " %14s", irq_desc[i].handler->typename);
+		seq_printf(p, " %14s", irq_desc[i].chip->typename);
 #ifndef PARISC_IRQ_CR16_COUNTS
 		seq_printf(p, "  %s", action->name);
 
@@ -210,12 +210,12 @@ int cpu_claim_irq(unsigned int irq, struct hw_interrupt_type *type, void *data)
 {
 	if (irq_desc[irq].action)
 		return -EBUSY;
-	if (irq_desc[irq].handler != &cpu_interrupt_type)
+	if (irq_desc[irq].chip != &cpu_interrupt_type)
 		return -EBUSY;
 
 	if (type) {
-		irq_desc[irq].handler = type;
-		irq_desc[irq].handler_data = data;
+		irq_desc[irq].chip = type;
+		irq_desc[irq].chip_data = data;
 		cpu_interrupt_type.enable(irq);
 	}
 	return 0;
@@ -378,7 +378,7 @@ static void claim_cpu_irqs(void)
 {
 	int i;
 	for (i = CPU_IRQ_BASE; i <= CPU_IRQ_MAX; i++) {
-		irq_desc[i].handler = &cpu_interrupt_type;
+		irq_desc[i].chip = &cpu_interrupt_type;
 	}
 
 	irq_desc[TIMER_IRQ].action = &timer_action;

commit 75be99a8c597aaebf82802109cdfd1249eea951e
Author: Ryan Bradetich <rbrad@parisc-linux.org>
Date:   Thu Nov 17 16:29:50 2005 -0500

    [PARISC] Make redirecting irq messages less noisy
    
    Make the "redirecting irq" message to not display on the console by
    setting the severity to KERN_DEBUG.  The console was basically unusable.
    
    Signed-off-by: Ryan Bradetich <rbrad@parisc-linux.org>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 144fc25b3872..197936d9359a 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -343,7 +343,7 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 			    !cpu_isset(smp_processor_id(), dest)) {
 				int cpu = first_cpu(dest);
 
-				printk("redirecting irq %d from CPU %d to %d\n",
+				printk(KERN_DEBUG "redirecting irq %d from CPU %d to %d\n",
 				       irq, smp_processor_id(), cpu);
 				gsc_writel(irq + CPU_IRQ_BASE,
 					   cpu_data[cpu].hpa);

commit 03afe22f074231196dcf3298f962cfc787ebbc60
Author: Grant Grundler <grundler@parisc-linux.org>
Date:   Thu Nov 17 16:29:16 2005 -0500

    [PARISC] irq_affinityp[] only available for SMP builds
    
    irq_affinityp[] only available for SMP builds, make code that uses
    it conditional on CONFIG_SMP.
    
    Signed-off-by: Grant Grundler <grundler@parisc-linux.org>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 2626405e70c4..144fc25b3872 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -261,13 +261,17 @@ int txn_alloc_irq(unsigned int bits_wide)
 	return -1;
 }
 
+
 unsigned long txn_affinity_addr(unsigned int irq, int cpu)
 {
+#ifdef CONFIG_SMP
 	irq_affinity[irq] = cpumask_of_cpu(cpu);
+#endif
 
 	return cpu_data[cpu].txn_addr;
 }
 
+
 unsigned long txn_alloc_addr(unsigned int virt_irq)
 {
 	static int next_cpu = -1;
@@ -321,14 +325,16 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 
 		/* Work our way from MSb to LSb...same order we alloc EIRs */
 		for (irq = TIMER_IRQ; eirr_val && bit; bit>>=1, irq++) {
+#ifdef CONFIG_SMP
 			cpumask_t dest = irq_affinity[irq];
-
+#endif
 			if (!(bit & eirr_val))
 				continue;
 
 			/* clear bit in mask - can exit loop sooner */
 			eirr_val &= ~bit;
 
+#ifdef CONFIG_SMP
 			/* FIXME: because generic set affinity mucks
 			 * with the affinity before sending it to us
 			 * we can get the situation where the affinity is
@@ -337,12 +343,13 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 			    !cpu_isset(smp_processor_id(), dest)) {
 				int cpu = first_cpu(dest);
 
-				printk("rethrowing irq %d from %d to %d\n",
+				printk("redirecting irq %d from CPU %d to %d\n",
 				       irq, smp_processor_id(), cpu);
 				gsc_writel(irq + CPU_IRQ_BASE,
 					   cpu_data[cpu].hpa);
 				continue;
 			}
+#endif
 
 			__do_IRQ(irq, regs);
 		}

commit c2ab64d09815cc4d48347ee3679658f197455a2a
Author: James Bottomley <jejb@parisc-linux.org>
Date:   Thu Nov 17 16:28:37 2005 -0500

    [PARISC] Add IRQ affinities
    
    This really only adds them for the machines I can check SMP on, which
    is CPU interrupts and IOSAPIC (so not any of the GSC based machines).
    
    With this patch, irqbalanced can be used to maintain irq balancing.
    Unfortunately, irqbalanced is a bit x86 centric, so it doesn't do an
    incredibly good job, but it does work.
    
    Signed-off-by: James Bottomley <jejb@parisc-linux.org>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 865611c15531..2626405e70c4 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -30,6 +30,7 @@
 #include <linux/seq_file.h>
 #include <linux/spinlock.h>
 #include <linux/types.h>
+#include <asm/io.h>
 
 #include <asm/smp.h>
 
@@ -84,6 +85,35 @@ static unsigned int cpu_startup_irq(unsigned int irq)
 void no_ack_irq(unsigned int irq) { }
 void no_end_irq(unsigned int irq) { }
 
+#ifdef CONFIG_SMP
+int cpu_check_affinity(unsigned int irq, cpumask_t *dest)
+{
+	int cpu_dest;
+
+	/* timer and ipi have to always be received on all CPUs */
+	if (irq == TIMER_IRQ || irq == IPI_IRQ) {
+		/* Bad linux design decision.  The mask has already
+		 * been set; we must reset it */
+		irq_affinity[irq] = CPU_MASK_ALL;
+		return -EINVAL;
+	}
+
+	/* whatever mask they set, we just allow one CPU */
+	cpu_dest = first_cpu(*dest);
+	*dest = cpumask_of_cpu(cpu_dest);
+
+	return 0;
+}
+
+static void cpu_set_affinity_irq(unsigned int irq, cpumask_t dest)
+{
+	if (cpu_check_affinity(irq, &dest))
+		return;
+
+	irq_affinity[irq] = dest;
+}
+#endif
+
 static struct hw_interrupt_type cpu_interrupt_type = {
 	.typename	= "CPU",
 	.startup	= cpu_startup_irq,
@@ -92,7 +122,9 @@ static struct hw_interrupt_type cpu_interrupt_type = {
 	.disable	= cpu_disable_irq,
 	.ack		= no_ack_irq,
 	.end		= no_end_irq,
-//	.set_affinity	= cpu_set_affinity_irq,
+#ifdef CONFIG_SMP
+	.set_affinity	= cpu_set_affinity_irq,
+#endif
 };
 
 int show_interrupts(struct seq_file *p, void *v)
@@ -229,6 +261,13 @@ int txn_alloc_irq(unsigned int bits_wide)
 	return -1;
 }
 
+unsigned long txn_affinity_addr(unsigned int irq, int cpu)
+{
+	irq_affinity[irq] = cpumask_of_cpu(cpu);
+
+	return cpu_data[cpu].txn_addr;
+}
+
 unsigned long txn_alloc_addr(unsigned int virt_irq)
 {
 	static int next_cpu = -1;
@@ -243,7 +282,7 @@ unsigned long txn_alloc_addr(unsigned int virt_irq)
 	if (next_cpu >= NR_CPUS) 
 		next_cpu = 0;	/* nothing else, assign monarch */
 
-	return cpu_data[next_cpu].txn_addr;
+	return txn_affinity_addr(virt_irq, next_cpu);
 }
 
 
@@ -282,12 +321,29 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 
 		/* Work our way from MSb to LSb...same order we alloc EIRs */
 		for (irq = TIMER_IRQ; eirr_val && bit; bit>>=1, irq++) {
+			cpumask_t dest = irq_affinity[irq];
+
 			if (!(bit & eirr_val))
 				continue;
 
 			/* clear bit in mask - can exit loop sooner */
 			eirr_val &= ~bit;
 
+			/* FIXME: because generic set affinity mucks
+			 * with the affinity before sending it to us
+			 * we can get the situation where the affinity is
+			 * wrong for our CPU type interrupts */
+			if (irq != TIMER_IRQ && irq != IPI_IRQ &&
+			    !cpu_isset(smp_processor_id(), dest)) {
+				int cpu = first_cpu(dest);
+
+				printk("rethrowing irq %d from %d to %d\n",
+				       irq, smp_processor_id(), cpu);
+				gsc_writel(irq + CPU_IRQ_BASE,
+					   cpu_data[cpu].hpa);
+				continue;
+			}
+
 			__do_IRQ(irq, regs);
 		}
 	}

commit 1d4c452a85503cdb4bca5925cf698b61d3aa43a0
Author: Kyle McMartin <kyle@parisc-linux.org>
Date:   Thu Nov 17 16:27:44 2005 -0500

    [PARISC] Fix uniprocessor build by dummying smp_send_all_nop()
    
    Since irq.c uses smp_send_all_nop, we must define it for UP builds
    as well. Make it a static inline so it gets optimized away. This forces
    irq.c to include <asm/smp.h> though.
    
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 3998c0cb925b..865611c15531 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -31,6 +31,8 @@
 #include <linux/spinlock.h>
 #include <linux/types.h>
 
+#include <asm/smp.h>
+
 #undef PARISC_IRQ_CR16_COUNTS
 
 extern irqreturn_t timer_interrupt(int, void *, struct pt_regs *);

commit d911aed8adf74e1fae88d082b8474b2175b7f1da
Author: James Bottomley <jejb@parisc-linux.org>
Date:   Thu Nov 17 16:27:02 2005 -0500

    [PARISC] Fix our interrupts not to use smp_call_function
    
    Fix our interrupts not to use smp_call_function
    
    On K and D class smp, the generic code calls this under an irq
    spinlock, which causes the WARN_ON() message in smp_call_function()
    (and is also illegal because it could deadlock).
    
    The fix is to use a new scheme based on the IPI_NOP.
    
    Signed-off-by: James Bottomley <jejb@parisc-linux.org>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 21a9c5ad580b..3998c0cb925b 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -43,26 +43,34 @@ extern irqreturn_t ipi_interrupt(int, void *, struct pt_regs *);
 */
 static volatile unsigned long cpu_eiem = 0;
 
-static void cpu_set_eiem(void *info)
-{
-	set_eiem((unsigned long) info);
-}
-
-static inline void cpu_disable_irq(unsigned int irq)
+static void cpu_disable_irq(unsigned int irq)
 {
 	unsigned long eirr_bit = EIEM_MASK(irq);
 
 	cpu_eiem &= ~eirr_bit;
-        on_each_cpu(cpu_set_eiem, (void *) cpu_eiem, 1, 1);
+	/* Do nothing on the other CPUs.  If they get this interrupt,
+	 * The & cpu_eiem in the do_cpu_irq_mask() ensures they won't
+	 * handle it, and the set_eiem() at the bottom will ensure it
+	 * then gets disabled */
 }
 
 static void cpu_enable_irq(unsigned int irq)
 {
 	unsigned long eirr_bit = EIEM_MASK(irq);
 
-	mtctl(eirr_bit, 23);	/* clear EIRR bit before unmasking */
 	cpu_eiem |= eirr_bit;
-        on_each_cpu(cpu_set_eiem, (void *) cpu_eiem, 1, 1);
+
+	/* FIXME: while our interrupts aren't nested, we cannot reset
+	 * the eiem mask if we're already in an interrupt.  Once we
+	 * implement nested interrupts, this can go away
+	 */
+	if (!in_interrupt())
+		set_eiem(cpu_eiem);
+
+	/* This is just a simple NOP IPI.  But what it does is cause
+	 * all the other CPUs to do a set_eiem(cpu_eiem) at the end
+	 * of the interrupt handler */
+	smp_send_all_nop();
 }
 
 static unsigned int cpu_startup_irq(unsigned int irq)

commit 3f902886a81c6d4e6c399760936b645b5c7a7342
Author: Grant Grundler <grundler@parisc-linux.org>
Date:   Thu Nov 17 16:26:20 2005 -0500

    [PARISC] Disable nesting of interrupts
    
    Disable nesting of interrupts - still has holes
    
    The offending sequence starts out like this:
    1) take external interrupt
    2) set_eiem() to only allow TIMER_IRQ; local interrupts still disabled
    3) read the EIRR to get a "list" of pending interrupts
    4) clear EIRR of pending interrupts we intend to handle
    5) call __do_IRQ() to handle IRQ.
    6) handle_IRQ_event() enables local interrupts (I-Bit)
    7) take a timer interrupt
    8) read EIRR to get a new list of pending interrupts
    9) clear EIRR of pending interrupts we just read
    10) handle pending interrupts found in (8)
    11) set_eiem(cpu_eiem) and return
            [ TROUBLE! all enabled CPU IRQs are unmasked. }
    12) handle remaining interrupts pending from (3)
            e.g. call __do_IRQ() -> handle_IRQ_event()..etc
            [ TROUBLE! call to handle_IRQ_event() can now enable *any* IRQ. }
    13) set_eiem(cpu_eiem) and return
    
    The problem is we now get into ugly race conditions with Timer and IPI
    interrupts at this point.  I'm not exactly sure what happens when
    things go wrong (perhaps nest calls to IPI or timer interrupt?).
    But I'm certain it's not good.
    
    This sequence will break sooner if (10) would accidentally leave
    interrupts enabled.
    
    I'm pretty sure the right answer is now to make cpu_eiem
    a per CPU variable since all external interrupts on parisc
    are per CPU. This means we will NOT need to send an IPI to
    every CPU in the system when enabling or disabling an IRQ
    since only one CPU needs to change it's EIEM.
    
    Thanks to James Bottomley for (once again) pointing out the problem.
    
    Signed-off-by: Grant Grundler <grundler@parisc-linux.org>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index f7ae2bcd49a5..21a9c5ad580b 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -250,10 +250,11 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 	irq_enter();
 
 	/*
-	 * Only allow interrupt processing to be interrupted by the
-	 * timer tick
+	 * Don't allow TIMER or IPI nested interrupts.
+	 * Allowing any single interrupt to nest can lead to that CPU
+	 * handling interrupts with all enabled interrupts unmasked.
 	 */
-	set_eiem(EIEM_MASK(TIMER_IRQ));
+	set_eiem(0UL);
 
 	/* 1) only process IRQs that are enabled/unmasked (cpu_eiem)
 	 * 2) We loop here on EIRR contents in order to avoid
@@ -267,9 +268,6 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 		if (!eirr_val)
 			break;
 
-		if (eirr_val & EIEM_MASK(TIMER_IRQ))
-			set_eiem(0);
-
 		mtctl(eirr_val, 23); /* reset bits we are going to process */
 
 		/* Work our way from MSb to LSb...same order we alloc EIRs */
@@ -283,7 +281,8 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 			__do_IRQ(irq, regs);
 		}
 	}
-	set_eiem(cpu_eiem);
+
+	set_eiem(cpu_eiem);	/* restore original mask */
 	irq_exit();
 }
 

commit 9a8b4584065dd241d6c2bf818e349986bd900b8e
Author: James Bottomley <jejb@parisc-linux.org>
Date:   Thu Nov 17 16:24:52 2005 -0500

    [PARISC] Make sure timer and IPI execute with interrupts disabled
    
    Fix a longstanding smp bug
    
    The problem is that both the timer and ipi interrupts are being called
    with interrupts enabled, which isn't what anyone is expecting.
    
    The IPI issue has just started to show up by causing a BUG_ON in the
    slab debugging code.  The timer issue never shows up because there's an
    eiem work around in our irq.c
    
    The fix is to label both these as SA_INTERRUPT which causes the generic
    irq code not to enable interrupts.
    
    I also suspect the smp_call_function timeouts we're seeing might be
    connected with the fact that we disable IPIs when handling any other
    type of interrupt.  I've put a WARN_ON in the code for executing
    smp_call_function() with IPIs disabled.
    
    Signed-off-by: James Bottomley <jejb@parisc-linux.org>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
index 006385dbee66..f7ae2bcd49a5 100644
--- a/arch/parisc/kernel/irq.c
+++ b/arch/parisc/kernel/irq.c
@@ -291,12 +291,14 @@ void do_cpu_irq_mask(struct pt_regs *regs)
 static struct irqaction timer_action = {
 	.handler = timer_interrupt,
 	.name = "timer",
+	.flags = SA_INTERRUPT,
 };
 
 #ifdef CONFIG_SMP
 static struct irqaction ipi_action = {
 	.handler = ipi_interrupt,
 	.name = "IPI",
+	.flags = SA_INTERRUPT,
 };
 #endif
 

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c
new file mode 100644
index 000000000000..006385dbee66
--- /dev/null
+++ b/arch/parisc/kernel/irq.c
@@ -0,0 +1,343 @@
+/* 
+ * Code to handle x86 style IRQs plus some generic interrupt stuff.
+ *
+ * Copyright (C) 1992 Linus Torvalds
+ * Copyright (C) 1994, 1995, 1996, 1997, 1998 Ralf Baechle
+ * Copyright (C) 1999 SuSE GmbH (Philipp Rumpf, prumpf@tux.org)
+ * Copyright (C) 1999-2000 Grant Grundler
+ * Copyright (c) 2005 Matthew Wilcox
+ *
+ *    This program is free software; you can redistribute it and/or modify
+ *    it under the terms of the GNU General Public License as published by
+ *    the Free Software Foundation; either version 2, or (at your option)
+ *    any later version.
+ *
+ *    This program is distributed in the hope that it will be useful,
+ *    but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *    GNU General Public License for more details.
+ *
+ *    You should have received a copy of the GNU General Public License
+ *    along with this program; if not, write to the Free Software
+ *    Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+#include <linux/bitops.h>
+#include <linux/config.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/kernel_stat.h>
+#include <linux/seq_file.h>
+#include <linux/spinlock.h>
+#include <linux/types.h>
+
+#undef PARISC_IRQ_CR16_COUNTS
+
+extern irqreturn_t timer_interrupt(int, void *, struct pt_regs *);
+extern irqreturn_t ipi_interrupt(int, void *, struct pt_regs *);
+
+#define EIEM_MASK(irq)       (1UL<<(CPU_IRQ_MAX - irq))
+
+/* Bits in EIEM correlate with cpu_irq_action[].
+** Numbered *Big Endian*! (ie bit 0 is MSB)
+*/
+static volatile unsigned long cpu_eiem = 0;
+
+static void cpu_set_eiem(void *info)
+{
+	set_eiem((unsigned long) info);
+}
+
+static inline void cpu_disable_irq(unsigned int irq)
+{
+	unsigned long eirr_bit = EIEM_MASK(irq);
+
+	cpu_eiem &= ~eirr_bit;
+        on_each_cpu(cpu_set_eiem, (void *) cpu_eiem, 1, 1);
+}
+
+static void cpu_enable_irq(unsigned int irq)
+{
+	unsigned long eirr_bit = EIEM_MASK(irq);
+
+	mtctl(eirr_bit, 23);	/* clear EIRR bit before unmasking */
+	cpu_eiem |= eirr_bit;
+        on_each_cpu(cpu_set_eiem, (void *) cpu_eiem, 1, 1);
+}
+
+static unsigned int cpu_startup_irq(unsigned int irq)
+{
+	cpu_enable_irq(irq);
+	return 0;
+}
+
+void no_ack_irq(unsigned int irq) { }
+void no_end_irq(unsigned int irq) { }
+
+static struct hw_interrupt_type cpu_interrupt_type = {
+	.typename	= "CPU",
+	.startup	= cpu_startup_irq,
+	.shutdown	= cpu_disable_irq,
+	.enable		= cpu_enable_irq,
+	.disable	= cpu_disable_irq,
+	.ack		= no_ack_irq,
+	.end		= no_end_irq,
+//	.set_affinity	= cpu_set_affinity_irq,
+};
+
+int show_interrupts(struct seq_file *p, void *v)
+{
+	int i = *(loff_t *) v, j;
+	unsigned long flags;
+
+	if (i == 0) {
+		seq_puts(p, "    ");
+		for_each_online_cpu(j)
+			seq_printf(p, "       CPU%d", j);
+
+#ifdef PARISC_IRQ_CR16_COUNTS
+		seq_printf(p, " [min/avg/max] (CPU cycle counts)");
+#endif
+		seq_putc(p, '\n');
+	}
+
+	if (i < NR_IRQS) {
+		struct irqaction *action;
+
+		spin_lock_irqsave(&irq_desc[i].lock, flags);
+		action = irq_desc[i].action;
+		if (!action)
+			goto skip;
+		seq_printf(p, "%3d: ", i);
+#ifdef CONFIG_SMP
+		for_each_online_cpu(j)
+			seq_printf(p, "%10u ", kstat_cpu(j).irqs[i]);
+#else
+		seq_printf(p, "%10u ", kstat_irqs(i));
+#endif
+
+		seq_printf(p, " %14s", irq_desc[i].handler->typename);
+#ifndef PARISC_IRQ_CR16_COUNTS
+		seq_printf(p, "  %s", action->name);
+
+		while ((action = action->next))
+			seq_printf(p, ", %s", action->name);
+#else
+		for ( ;action; action = action->next) {
+			unsigned int k, avg, min, max;
+
+			min = max = action->cr16_hist[0];
+
+			for (avg = k = 0; k < PARISC_CR16_HIST_SIZE; k++) {
+				int hist = action->cr16_hist[k];
+
+				if (hist) {
+					avg += hist;
+				} else
+					break;
+
+				if (hist > max) max = hist;
+				if (hist < min) min = hist;
+			}
+
+			avg /= k;
+			seq_printf(p, " %s[%d/%d/%d]", action->name,
+					min,avg,max);
+		}
+#endif
+
+		seq_putc(p, '\n');
+ skip:
+		spin_unlock_irqrestore(&irq_desc[i].lock, flags);
+	}
+
+	return 0;
+}
+
+
+
+/*
+** The following form a "set": Virtual IRQ, Transaction Address, Trans Data.
+** Respectively, these map to IRQ region+EIRR, Processor HPA, EIRR bit.
+**
+** To use txn_XXX() interfaces, get a Virtual IRQ first.
+** Then use that to get the Transaction address and data.
+*/
+
+int cpu_claim_irq(unsigned int irq, struct hw_interrupt_type *type, void *data)
+{
+	if (irq_desc[irq].action)
+		return -EBUSY;
+	if (irq_desc[irq].handler != &cpu_interrupt_type)
+		return -EBUSY;
+
+	if (type) {
+		irq_desc[irq].handler = type;
+		irq_desc[irq].handler_data = data;
+		cpu_interrupt_type.enable(irq);
+	}
+	return 0;
+}
+
+int txn_claim_irq(int irq)
+{
+	return cpu_claim_irq(irq, NULL, NULL) ? -1 : irq;
+}
+
+/*
+ * The bits_wide parameter accommodates the limitations of the HW/SW which
+ * use these bits:
+ * Legacy PA I/O (GSC/NIO): 5 bits (architected EIM register)
+ * V-class (EPIC):          6 bits
+ * N/L/A-class (iosapic):   8 bits
+ * PCI 2.2 MSI:            16 bits
+ * Some PCI devices:       32 bits (Symbios SCSI/ATM/HyperFabric)
+ *
+ * On the service provider side:
+ * o PA 1.1 (and PA2.0 narrow mode)     5-bits (width of EIR register)
+ * o PA 2.0 wide mode                   6-bits (per processor)
+ * o IA64                               8-bits (0-256 total)
+ *
+ * So a Legacy PA I/O device on a PA 2.0 box can't use all the bits supported
+ * by the processor...and the N/L-class I/O subsystem supports more bits than
+ * PA2.0 has. The first case is the problem.
+ */
+int txn_alloc_irq(unsigned int bits_wide)
+{
+	int irq;
+
+	/* never return irq 0 cause that's the interval timer */
+	for (irq = CPU_IRQ_BASE + 1; irq <= CPU_IRQ_MAX; irq++) {
+		if (cpu_claim_irq(irq, NULL, NULL) < 0)
+			continue;
+		if ((irq - CPU_IRQ_BASE) >= (1 << bits_wide))
+			continue;
+		return irq;
+	}
+
+	/* unlikely, but be prepared */
+	return -1;
+}
+
+unsigned long txn_alloc_addr(unsigned int virt_irq)
+{
+	static int next_cpu = -1;
+
+	next_cpu++; /* assign to "next" CPU we want this bugger on */
+
+	/* validate entry */
+	while ((next_cpu < NR_CPUS) && (!cpu_data[next_cpu].txn_addr || 
+		!cpu_online(next_cpu)))
+		next_cpu++;
+
+	if (next_cpu >= NR_CPUS) 
+		next_cpu = 0;	/* nothing else, assign monarch */
+
+	return cpu_data[next_cpu].txn_addr;
+}
+
+
+unsigned int txn_alloc_data(unsigned int virt_irq)
+{
+	return virt_irq - CPU_IRQ_BASE;
+}
+
+/* ONLY called from entry.S:intr_extint() */
+void do_cpu_irq_mask(struct pt_regs *regs)
+{
+	unsigned long eirr_val;
+
+	irq_enter();
+
+	/*
+	 * Only allow interrupt processing to be interrupted by the
+	 * timer tick
+	 */
+	set_eiem(EIEM_MASK(TIMER_IRQ));
+
+	/* 1) only process IRQs that are enabled/unmasked (cpu_eiem)
+	 * 2) We loop here on EIRR contents in order to avoid
+	 *    nested interrupts or having to take another interrupt
+	 *    when we could have just handled it right away.
+	 */
+	for (;;) {
+		unsigned long bit = (1UL << (BITS_PER_LONG - 1));
+		unsigned int irq;
+		eirr_val = mfctl(23) & cpu_eiem;
+		if (!eirr_val)
+			break;
+
+		if (eirr_val & EIEM_MASK(TIMER_IRQ))
+			set_eiem(0);
+
+		mtctl(eirr_val, 23); /* reset bits we are going to process */
+
+		/* Work our way from MSb to LSb...same order we alloc EIRs */
+		for (irq = TIMER_IRQ; eirr_val && bit; bit>>=1, irq++) {
+			if (!(bit & eirr_val))
+				continue;
+
+			/* clear bit in mask - can exit loop sooner */
+			eirr_val &= ~bit;
+
+			__do_IRQ(irq, regs);
+		}
+	}
+	set_eiem(cpu_eiem);
+	irq_exit();
+}
+
+
+static struct irqaction timer_action = {
+	.handler = timer_interrupt,
+	.name = "timer",
+};
+
+#ifdef CONFIG_SMP
+static struct irqaction ipi_action = {
+	.handler = ipi_interrupt,
+	.name = "IPI",
+};
+#endif
+
+static void claim_cpu_irqs(void)
+{
+	int i;
+	for (i = CPU_IRQ_BASE; i <= CPU_IRQ_MAX; i++) {
+		irq_desc[i].handler = &cpu_interrupt_type;
+	}
+
+	irq_desc[TIMER_IRQ].action = &timer_action;
+	irq_desc[TIMER_IRQ].status |= IRQ_PER_CPU;
+#ifdef CONFIG_SMP
+	irq_desc[IPI_IRQ].action = &ipi_action;
+	irq_desc[IPI_IRQ].status = IRQ_PER_CPU;
+#endif
+}
+
+void __init init_IRQ(void)
+{
+	local_irq_disable();	/* PARANOID - should already be disabled */
+	mtctl(~0UL, 23);	/* EIRR : clear all pending external intr */
+	claim_cpu_irqs();
+#ifdef CONFIG_SMP
+	if (!cpu_eiem)
+		cpu_eiem = EIEM_MASK(IPI_IRQ) | EIEM_MASK(TIMER_IRQ);
+#else
+	cpu_eiem = EIEM_MASK(TIMER_IRQ);
+#endif
+        set_eiem(cpu_eiem);	/* EIEM : enable all external intr */
+
+}
+
+void hw_resend_irq(struct hw_interrupt_type *type, unsigned int irq)
+{
+	/* XXX: Needs to be written.  We managed without it so far, but
+	 * we really ought to write it.
+	 */
+}
+
+void ack_bad_irq(unsigned int irq)
+{
+	printk("unexpected IRQ %d\n", irq);
+}
