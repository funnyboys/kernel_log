commit 34589df6338afc75208cd3f9b612c1ae7738bbd0
Author: Helge Deller <deller@gmx.de>
Date:   Fri May 10 20:55:31 2019 +0200

    parisc: Use __ro_after_init in time.c
    
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index a1e772f909cb..04508158815c 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -40,7 +40,7 @@
 
 #include <linux/timex.h>
 
-static unsigned long clocktick __read_mostly;	/* timer cycles per tick */
+static unsigned long clocktick __ro_after_init;	/* timer cycles per tick */
 
 /*
  * We keep time on PA-RISC Linux by using the Interval Timer which is

commit f76cdd00ef0e39d880139b074e3b247594dff95a
Author: Baolin Wang <baolin.wang@linaro.org>
Date:   Thu Apr 19 14:51:03 2018 +0800

    parisc: time: Convert read_persistent_clock() to read_persistent_clock64()
    
    The read_persistent_clock() uses a timespec, which is not year 2038 safe
    on 32bit systems. On parisc architecture, we have implemented generic
    RTC drivers that can be used to compensate the system suspend time, but
    the RTC time can not represent the nanosecond resolution, so this patch
    just converts to read_persistent_clock64() with timespec64.
    
    Signed-off-by: Baolin Wang <baolin.wang@linaro.org>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index c3830400ca28..a1e772f909cb 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -205,7 +205,7 @@ static int __init rtc_init(void)
 device_initcall(rtc_init);
 #endif
 
-void read_persistent_clock(struct timespec *ts)
+void read_persistent_clock64(struct timespec64 *ts)
 {
 	static struct pdc_tod tod_data;
 	if (pdc_tod_read(&tod_data) == 0) {

commit fbe173e3ffbd897b5a859020d714c0eaf4af2a1a
Merge: 5e630afdcb82 1485991c0246
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Apr 10 10:22:27 2018 -0700

    Merge tag 'rtc-4.17' of git://git.kernel.org/pub/scm/linux/kernel/git/abelloni/linux
    
    Pull RTC updates from Alexandre Belloni:
     "This contains a few series that have been in preparation for a while
      and that will help systems with RTCs that will fail in 2038, 2069 or
      2100.
    
      Subsystem:
       - Add tracepoints
       - Rework of the RTC/nvmem API to allow drivers to discard struct
         nvmem_config after registration
       - New range API, drivers can now expose the useful range of the RTC
       - New offset API the core is now able to add an offset to the RTC
         time, modifying the supported range.
       - Multiple rtc_time64_to_tm fixes
       - Handle time_t overflow on 32 bit platforms in the core instead of
         letting drivers do crazy things.
       - remove rtc_control API
    
      New driver:
       - Intersil ISL12026
    
      Drivers:
       - Drivers exposing the RTC non volatile memory have been converted to
         use nvmem
       - Removed useless time and date validation
       - Removed an indirection pattern that was a cargo cult from ancient
         drivers
       - Removed VLA usage
       - Fixed a possible race condition in probe functions
       - AB8540 support is dropped from ab8500
       - pcf85363 now has alarm support"
    
    * tag 'rtc-4.17' of git://git.kernel.org/pub/scm/linux/kernel/git/abelloni/linux: (128 commits)
      rtc: snvs: Fix usage of snvs_rtc_enable
      rtc: mt7622: fix module autoloading for OF platform drivers
      rtc: isl12022: use true and false for boolean values
      rtc: ab8500: Drop AB8540 support
      rtc: remove a warning during scripts/kernel-doc step
      rtc: 88pm860x: remove artificial limitation
      rtc: 88pm80x: remove artificial limitation
      rtc: st-lpc: remove artificial limitation
      rtc: mrst: remove artificial limitation
      rtc: mv: remove artificial limitation
      rtc: hctosys: Ensure system time doesn't overflow time_t
      parisc: time: stop validating rtc_time in .read_time
      rtc: pcf85063: fix clearing bits in pcf85063_start_clock
      rtc: at91sam9: Set name of regmap_config
      rtc: s5m: Remove VLA usage
      rtc: s5m: Move enum from rtc.h to rtc-s5m.c
      rtc: remove VLA usage
      rtc: Add useful timestamp definitions
      rtc: Add one offset seconds to expand RTC range
      rtc: Factor out the RTC range validation into rtc_valid_range()
      ...

commit f6b1a3a4a72e27234a02d9095080fc811848598c
Author: Alexandre Belloni <alexandre.belloni@bootlin.com>
Date:   Wed Feb 21 22:40:23 2018 +0100

    parisc: time: stop validating rtc_time in .read_time
    
    The RTC core is always calling rtc_valid_tm after the read_time callback.
    It is not necessary to call it just before returning from the callback.
    
    Signed-off-by: Alexandre Belloni <alexandre.belloni@bootlin.com>
    Acked-by: Helge Deller <deller@gmx.de>
    Signed-off-by: Alexandre Belloni <alexandre.belloni@bootlin.com>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 4b8fd6dc22da..f2890bd240f8 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -173,7 +173,7 @@ static int rtc_generic_get_time(struct device *dev, struct rtc_time *tm)
 
 	/* we treat tod_sec as unsigned, so this can work until year 2106 */
 	rtc_time64_to_tm(tod_data.tod_sec, tm);
-	return rtc_valid_tm(tm);
+	return 0;
 }
 
 static int rtc_generic_set_time(struct device *dev, struct rtc_time *tm)

commit 636a415bcc7f4fd020ece8fd5fc648c4cef19c34
Author: Helge Deller <deller@gmx.de>
Date:   Mon Feb 12 21:43:55 2018 +0100

    parisc: Reduce irq overhead when run in qemu
    
    When run under QEMU, calling mfctl(16) creates some overhead because the
    qemu timer has to be scaled and moved into the register. This patch
    reduces the number of calls to mfctl(16) by moving the calls out of the
    loops.
    
    Additionally, increase the minimal time interval to 8000 cycles instead
    of 500 to compensate possible QEMU delays when delivering interrupts.
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Cc: stable@vger.kernel.org # 4.14+

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 68e88e5c0898..f7e684560186 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -76,10 +76,10 @@ irqreturn_t __irq_entry timer_interrupt(int irq, void *dev_id)
 	next_tick = cpuinfo->it_value;
 
 	/* Calculate how many ticks have elapsed. */
+	now = mfctl(16);
 	do {
 		++ticks_elapsed;
 		next_tick += cpt;
-		now = mfctl(16);
 	} while (next_tick - now > cpt);
 
 	/* Store (in CR16 cycles) up to when we are accounting right now. */
@@ -103,16 +103,17 @@ irqreturn_t __irq_entry timer_interrupt(int irq, void *dev_id)
 	 * if one or the other wrapped. If "now" is "bigger" we'll end up
 	 * with a very large unsigned number.
 	 */
-	while (next_tick - mfctl(16) > cpt)
+	now = mfctl(16);
+	while (next_tick - now > cpt)
 		next_tick += cpt;
 
 	/* Program the IT when to deliver the next interrupt.
 	 * Only bottom 32-bits of next_tick are writable in CR16!
 	 * Timer interrupt will be delivered at least a few hundred cycles
-	 * after the IT fires, so if we are too close (<= 500 cycles) to the
+	 * after the IT fires, so if we are too close (<= 8000 cycles) to the
 	 * next cycle, simply skip it.
 	 */
-	if (next_tick - mfctl(16) <= 500)
+	if (next_tick - now <= 8000)
 		next_tick += cpt;
 	mtctl(next_tick, 16);
 

commit 5ffa8518851f1401817c15d2a7eecc0373c26ff9
Author: Helge Deller <deller@gmx.de>
Date:   Fri Jan 12 22:44:00 2018 +0100

    parisc: Use cr16 interval timers unconditionally on qemu
    
    When running on qemu we know that the (emulated) cr16 cpu-internal
    clocks are syncronized. So let's use them unconditionally on qemu.
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Cc: stable@vger.kernel.org # 4.14+

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 4b8fd6dc22da..68e88e5c0898 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -248,7 +248,7 @@ static int __init init_cr16_clocksource(void)
 	 * different sockets, so mark them unstable and lower rating on
 	 * multi-socket SMP systems.
 	 */
-	if (num_online_cpus() > 1) {
+	if (num_online_cpus() > 1 && !running_on_qemu) {
 		int cpu;
 		unsigned long cpu0_loc;
 		cpu0_loc = per_cpu(cpu_data, 0).cpu_loc;

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 8c0105a49839..4b8fd6dc22da 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  *  linux/arch/parisc/kernel/time.c
  *

commit 8642b31ba9eef8a01845146a26682d4869e62513
Author: Helge Deller <deller@gmx.de>
Date:   Wed Oct 18 22:25:00 2017 +0200

    parisc: Fix detection of nonsynchronous cr16 cycle counters
    
    For CPUs which have an unknown or invalid CPU location (physical location)
    assume that their cycle counters aren't syncronized across CPUs.
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Fixes: c8c3735997a3 ("parisc: Enhance detection of synchronous cr16 clocksources")
    Cc: stable@vger.kernel.org # 4.13+
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 2d956aa0a38a..8c0105a49839 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -253,7 +253,10 @@ static int __init init_cr16_clocksource(void)
 		cpu0_loc = per_cpu(cpu_data, 0).cpu_loc;
 
 		for_each_online_cpu(cpu) {
-			if (cpu0_loc == per_cpu(cpu_data, cpu).cpu_loc)
+			if (cpu == 0)
+				continue;
+			if ((cpu0_loc != 0) &&
+			    (cpu0_loc == per_cpu(cpu_data, cpu).cpu_loc))
 				continue;
 
 			clocksource_cr16.name = "cr16_unstable";

commit c8c3735997a3aa184fa81742bb6c4062a26af2f3
Author: Helge Deller <deller@gmx.de>
Date:   Sun Jan 8 11:01:11 2017 +0100

    parisc: Enhance detection of synchronous cr16 clocksources
    
    The cr16 clocks of the physical PARISC CPUs are usually nonsynchronous.
    Nevertheless, it seems that each CPU socket (which holds two cores) of
    PA8800 and PA8900 CPUs (e.g. in a C8000 workstation) is fed by the same
    clock source, which makes the cr16 clocks of each CPU socket syncronous.
    Let's try to detect such situations and mark the cr16 clocksource stable
    on single-socket and single-core machines.
    
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 89421df70160..2d956aa0a38a 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -243,14 +243,30 @@ void __init time_init(void)
 static int __init init_cr16_clocksource(void)
 {
 	/*
-	 * The cr16 interval timers are not syncronized across CPUs, so mark
-	 * them unstable and lower rating on SMP systems.
+	 * The cr16 interval timers are not syncronized across CPUs on
+	 * different sockets, so mark them unstable and lower rating on
+	 * multi-socket SMP systems.
 	 */
 	if (num_online_cpus() > 1) {
-		clocksource_cr16.flags = CLOCK_SOURCE_UNSTABLE;
-		clocksource_cr16.rating = 0;
+		int cpu;
+		unsigned long cpu0_loc;
+		cpu0_loc = per_cpu(cpu_data, 0).cpu_loc;
+
+		for_each_online_cpu(cpu) {
+			if (cpu0_loc == per_cpu(cpu_data, cpu).cpu_loc)
+				continue;
+
+			clocksource_cr16.name = "cr16_unstable";
+			clocksource_cr16.flags = CLOCK_SOURCE_UNSTABLE;
+			clocksource_cr16.rating = 0;
+			break;
+		}
 	}
 
+	/* XXX: We may want to mark sched_clock stable here if cr16 clocks are
+	 *	in sync:
+	 *	(clocksource_cr16.flags == CLOCK_SOURCE_IS_CONTINUOUS) */
+
 	/* register at clocksource framework */
 	clocksource_register_hz(&clocksource_cr16,
 		100 * PAGE0->mem_10msec);

commit e601757102cfd3eeae068f53b3bc1234f3a2b2e9
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 1 16:36:40 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/clock.h>
    
    We are going to split <linux/sched/clock.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and .c files.
    
    Create a trivial placeholder <linux/sched/clock.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 1e22f981cd81..89421df70160 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -14,6 +14,7 @@
 #include <linux/module.h>
 #include <linux/rtc.h>
 #include <linux/sched.h>
+#include <linux/sched/clock.h>
 #include <linux/sched_clock.h>
 #include <linux/kernel.h>
 #include <linux/param.h>

commit 41744213602a206f24adcb4a2b7551db3c700e72
Author: Helge Deller <deller@gmx.de>
Date:   Mon Dec 26 12:46:01 2016 +0100

    parisc: Mark cr16 clocksource unstable on SMP systems
    
    The cr16 interval timer of each CPU is not syncronized to other cr16
    timers in other CPUs in a SMP system. So, delay the registration of the
    cr16 clocksource until all CPUs have been detected and then - if we are
    on a SMP machine - mark the cr16 clocksource as unstable and lower it's
    rating before registering it at the clocksource framework.
    
    This patch fixes the stalled CPU warnings which we have seen since
    introduction of the cr16 clocksource.
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Cc: <stable@vger.kernel.org> # v4.8+

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index da0d9cb63403..1e22f981cd81 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -235,9 +235,26 @@ void __init time_init(void)
 
 	cr16_hz = 100 * PAGE0->mem_10msec;  /* Hz */
 
-	/* register at clocksource framework */
-	clocksource_register_hz(&clocksource_cr16, cr16_hz);
-
 	/* register as sched_clock source */
 	sched_clock_register(read_cr16_sched_clock, BITS_PER_LONG, cr16_hz);
 }
+
+static int __init init_cr16_clocksource(void)
+{
+	/*
+	 * The cr16 interval timers are not syncronized across CPUs, so mark
+	 * them unstable and lower rating on SMP systems.
+	 */
+	if (num_online_cpus() > 1) {
+		clocksource_cr16.flags = CLOCK_SOURCE_UNSTABLE;
+		clocksource_cr16.rating = 0;
+	}
+
+	/* register at clocksource framework */
+	clocksource_register_hz(&clocksource_cr16,
+		100 * PAGE0->mem_10msec);
+
+	return 0;
+}
+
+device_initcall(init_cr16_clocksource);

commit a5a1d1c2914b5316924c7893eb683a5420ebd3be
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Dec 21 20:32:01 2016 +0100

    clocksource: Use a plain u64 instead of cycle_t
    
    There is no point in having an extra type for extra confusion. u64 is
    unambiguous.
    
    Conversion was done with the following coccinelle script:
    
    @rem@
    @@
    -typedef u64 cycle_t;
    
    @fix@
    typedef cycle_t;
    @@
    -cycle_t
    +u64
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: John Stultz <john.stultz@linaro.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 037d81f00520..da0d9cb63403 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -137,7 +137,7 @@ EXPORT_SYMBOL(profile_pc);
 
 /* clock source code */
 
-static cycle_t notrace read_cr16(struct clocksource *cs)
+static u64 notrace read_cr16(struct clocksource *cs)
 {
 	return get_cycles();
 }

commit 7c0f6ba682b9c7632072ffbedf8d328c8f3c42ba
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Dec 24 11:46:01 2016 -0800

    Replace <asm/uaccess.h> with <linux/uaccess.h> globally
    
    This was entirely automated, using the script by Al:
    
      PATT='^[[:blank:]]*#[[:blank:]]*include[[:blank:]]*<asm/uaccess.h>'
      sed -i -e "s!$PATT!#include <linux/uaccess.h>!" \
            $(git grep -l "$PATT"|grep -v ^include/linux/uaccess.h)
    
    to do the replacement at the end of the merge window.
    
    Requested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 4215f5596c8b..037d81f00520 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -28,7 +28,7 @@
 #include <linux/platform_device.h>
 #include <linux/ftrace.h>
 
-#include <asm/uaccess.h>
+#include <linux/uaccess.h>
 #include <asm/io.h>
 #include <asm/irq.h>
 #include <asm/page.h>

commit 160494d381373cfa21208484aea4e5db2d3cb0a8
Author: Helge Deller <deller@gmx.de>
Date:   Tue Dec 20 20:51:10 2016 +0100

    parisc: Optimize timer interrupt function
    
    Restructure the timer interrupt function to better cope with missed timer irqs.
    Optimize the calculation when the next interrupt should happen and skip irqs if
    they would happen too shortly after exit of the irq function.
    
    The update_process_times() call is done anyway at every timer irq, so we can
    safely drop the prof_counter and prof_multiplier variables from the per_cpu
    structure.
    
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 325f30d82b64..4215f5596c8b 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -59,10 +59,9 @@ static unsigned long clocktick __read_mostly;	/* timer cycles per tick */
  */
 irqreturn_t __irq_entry timer_interrupt(int irq, void *dev_id)
 {
-	unsigned long now, now2;
+	unsigned long now;
 	unsigned long next_tick;
-	unsigned long cycles_elapsed, ticks_elapsed = 1;
-	unsigned long cycles_remainder;
+	unsigned long ticks_elapsed = 0;
 	unsigned int cpu = smp_processor_id();
 	struct cpuinfo_parisc *cpuinfo = &per_cpu(cpu_data, cpu);
 
@@ -71,102 +70,49 @@ irqreturn_t __irq_entry timer_interrupt(int irq, void *dev_id)
 
 	profile_tick(CPU_PROFILING);
 
-	/* Initialize next_tick to the expected tick time. */
+	/* Initialize next_tick to the old expected tick time. */
 	next_tick = cpuinfo->it_value;
 
-	/* Get current cycle counter (Control Register 16). */
-	now = mfctl(16);
-
-	cycles_elapsed = now - next_tick;
-
-	if ((cycles_elapsed >> 6) < cpt) {
-		/* use "cheap" math (add/subtract) instead
-		 * of the more expensive div/mul method
-		 */
-		cycles_remainder = cycles_elapsed;
-		while (cycles_remainder > cpt) {
-			cycles_remainder -= cpt;
-			ticks_elapsed++;
-		}
-	} else {
-		/* TODO: Reduce this to one fdiv op */
-		cycles_remainder = cycles_elapsed % cpt;
-		ticks_elapsed += cycles_elapsed / cpt;
-	}
-
-	/* convert from "division remainder" to "remainder of clock tick" */
-	cycles_remainder = cpt - cycles_remainder;
-
-	/* Determine when (in CR16 cycles) next IT interrupt will fire.
-	 * We want IT to fire modulo clocktick even if we miss/skip some.
-	 * But those interrupts don't in fact get delivered that regularly.
-	 */
-	next_tick = now + cycles_remainder;
+	/* Calculate how many ticks have elapsed. */
+	do {
+		++ticks_elapsed;
+		next_tick += cpt;
+		now = mfctl(16);
+	} while (next_tick - now > cpt);
 
+	/* Store (in CR16 cycles) up to when we are accounting right now. */
 	cpuinfo->it_value = next_tick;
 
-	/* Program the IT when to deliver the next interrupt.
-	 * Only bottom 32-bits of next_tick are writable in CR16!
-	 */
-	mtctl(next_tick, 16);
+	/* Go do system house keeping. */
+	if (cpu == 0)
+		xtime_update(ticks_elapsed);
+
+	update_process_times(user_mode(get_irq_regs()));
 
-	/* Skip one clocktick on purpose if we missed next_tick.
+	/* Skip clockticks on purpose if we know we would miss those.
 	 * The new CR16 must be "later" than current CR16 otherwise
 	 * itimer would not fire until CR16 wrapped - e.g 4 seconds
 	 * later on a 1Ghz processor. We'll account for the missed
-	 * tick on the next timer interrupt.
+	 * ticks on the next timer interrupt.
+	 * We want IT to fire modulo clocktick even if we miss/skip some.
+	 * But those interrupts don't in fact get delivered that regularly.
 	 *
 	 * "next_tick - now" will always give the difference regardless
 	 * if one or the other wrapped. If "now" is "bigger" we'll end up
 	 * with a very large unsigned number.
 	 */
-	now2 = mfctl(16);
-	if (next_tick - now2 > cpt)
-		mtctl(next_tick+cpt, 16);
+	while (next_tick - mfctl(16) > cpt)
+		next_tick += cpt;
 
-#if 1
-/*
- * GGG: DEBUG code for how many cycles programming CR16 used.
- */
-	if (unlikely(now2 - now > 0x3000)) 	/* 12K cycles */
-		printk (KERN_CRIT "timer_interrupt(CPU %d): SLOW! 0x%lx cycles!"
-			" cyc %lX rem %lX "
-			" next/now %lX/%lX\n",
-			cpu, now2 - now, cycles_elapsed, cycles_remainder,
-			next_tick, now );
-#endif
-
-	/* Can we differentiate between "early CR16" (aka Scenario 1) and
-	 * "long delay" (aka Scenario 3)? I don't think so.
-	 *
-	 * Timer_interrupt will be delivered at least a few hundred cycles
-	 * after the IT fires. But it's arbitrary how much time passes
-	 * before we call it "late". I've picked one second.
-	 *
-	 * It's important NO printk's are between reading CR16 and
-	 * setting up the next value. May introduce huge variance.
-	 */
-	if (unlikely(ticks_elapsed > HZ)) {
-		/* Scenario 3: very long delay?  bad in any case */
-		printk (KERN_CRIT "timer_interrupt(CPU %d): delayed!"
-			" cycles %lX rem %lX "
-			" next/now %lX/%lX\n",
-			cpu,
-			cycles_elapsed, cycles_remainder,
-			next_tick, now );
-	}
-
-	/* Done mucking with unreliable delivery of interrupts.
-	 * Go do system house keeping.
+	/* Program the IT when to deliver the next interrupt.
+	 * Only bottom 32-bits of next_tick are writable in CR16!
+	 * Timer interrupt will be delivered at least a few hundred cycles
+	 * after the IT fires, so if we are too close (<= 500 cycles) to the
+	 * next cycle, simply skip it.
 	 */
-
-	if (!--cpuinfo->prof_counter) {
-		cpuinfo->prof_counter = cpuinfo->prof_multiplier;
-		update_process_times(user_mode(get_irq_regs()));
-	}
-
-	if (cpu == 0)
-		xtime_update(ticks_elapsed);
+	if (next_tick - mfctl(16) <= 500)
+		next_tick += cpt;
+	mtctl(next_tick, 16);
 
 	return IRQ_HANDLED;
 }

commit 43b1f6abd59063a088416a0df042b36450f91f75
Author: Helge Deller <deller@gmx.de>
Date:   Tue Nov 22 18:08:30 2016 +0100

    parisc: Switch to generic sched_clock implementation
    
    Drop the open-coded sched_clock() function and replace it by the provided
    GENERIC_SCHED_CLOCK implementation.  We have seen quite some hung tasks in the
    past, which seem to be fixed by this patch.
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Cc: <stable@vger.kernel.org> # v4.7+
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 9b63b876a13a..325f30d82b64 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -14,6 +14,7 @@
 #include <linux/module.h>
 #include <linux/rtc.h>
 #include <linux/sched.h>
+#include <linux/sched_clock.h>
 #include <linux/kernel.h>
 #include <linux/param.h>
 #include <linux/string.h>
@@ -39,18 +40,6 @@
 
 static unsigned long clocktick __read_mostly;	/* timer cycles per tick */
 
-#ifndef CONFIG_64BIT
-/*
- * The processor-internal cycle counter (Control Register 16) is used as time
- * source for the sched_clock() function.  This register is 64bit wide on a
- * 64-bit kernel and 32bit on a 32-bit kernel. Since sched_clock() always
- * requires a 64bit counter we emulate on the 32-bit kernel the higher 32bits
- * with a per-cpu variable which we increase every time the counter
- * wraps-around (which happens every ~4 secounds).
- */
-static DEFINE_PER_CPU(unsigned long, cr16_high_32_bits);
-#endif
-
 /*
  * We keep time on PA-RISC Linux by using the Interval Timer which is
  * a pair of registers; one is read-only and one is write-only; both
@@ -121,12 +110,6 @@ irqreturn_t __irq_entry timer_interrupt(int irq, void *dev_id)
 	 */
 	mtctl(next_tick, 16);
 
-#if !defined(CONFIG_64BIT)
-	/* check for overflow on a 32bit kernel (every ~4 seconds). */
-	if (unlikely(next_tick < now))
-		this_cpu_inc(cr16_high_32_bits);
-#endif
-
 	/* Skip one clocktick on purpose if we missed next_tick.
 	 * The new CR16 must be "later" than current CR16 otherwise
 	 * itimer would not fire until CR16 wrapped - e.g 4 seconds
@@ -208,7 +191,7 @@ EXPORT_SYMBOL(profile_pc);
 
 /* clock source code */
 
-static cycle_t read_cr16(struct clocksource *cs)
+static cycle_t notrace read_cr16(struct clocksource *cs)
 {
 	return get_cycles();
 }
@@ -287,26 +270,9 @@ void read_persistent_clock(struct timespec *ts)
 }
 
 
-/*
- * sched_clock() framework
- */
-
-static u32 cyc2ns_mul __read_mostly;
-static u32 cyc2ns_shift __read_mostly;
-
-u64 sched_clock(void)
+static u64 notrace read_cr16_sched_clock(void)
 {
-	u64 now;
-
-	/* Get current cycle counter (Control Register 16). */
-#ifdef CONFIG_64BIT
-	now = mfctl(16);
-#else
-	now = mfctl(16) + (((u64) this_cpu_read(cr16_high_32_bits)) << 32);
-#endif
-
-	/* return the value in ns (cycles_2_ns) */
-	return mul_u64_u32_shr(now, cyc2ns_mul, cyc2ns_shift);
+	return get_cycles();
 }
 
 
@@ -316,17 +282,16 @@ u64 sched_clock(void)
 
 void __init time_init(void)
 {
-	unsigned long current_cr16_khz;
+	unsigned long cr16_hz;
 
-	current_cr16_khz = PAGE0->mem_10msec/10;  /* kHz */
 	clocktick = (100 * PAGE0->mem_10msec) / HZ;
-
-	/* calculate mult/shift values for cr16 */
-	clocks_calc_mult_shift(&cyc2ns_mul, &cyc2ns_shift, current_cr16_khz,
-				NSEC_PER_MSEC, 0);
-
 	start_cpu_itimer();	/* get CPU 0 started */
 
+	cr16_hz = 100 * PAGE0->mem_10msec;  /* Hz */
+
 	/* register at clocksource framework */
-	clocksource_register_khz(&clocksource_cr16, current_cr16_khz);
+	clocksource_register_hz(&clocksource_cr16, cr16_hz);
+
+	/* register as sched_clock source */
+	sched_clock_register(read_cr16_sched_clock, BITS_PER_LONG, cr16_hz);
 }

commit 92420bd0d01f040bbf754e1d090be49ca6a1c8d6
Author: Helge Deller <deller@gmx.de>
Date:   Sat Sep 24 22:22:12 2016 +0200

    parisc: Fix self-detected CPU stall warnings on Mako machines
    
    The config option HAVE_UNSTABLE_SCHED_CLOCK is set automatically when compiling
    for SMP. There is no need to clear the stable-clock flag via
    clear_sched_clock_stable() when starting secondary CPUs, and even worse,
    clearing it triggers wrong self-detected CPU stall warnings on 64bit Mako
    machines.
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Cc: stable@vger.kernel.org # 4.7+

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 4b0b963d52a7..9b63b876a13a 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -226,12 +226,6 @@ void __init start_cpu_itimer(void)
 	unsigned int cpu = smp_processor_id();
 	unsigned long next_tick = mfctl(16) + clocktick;
 
-#if defined(CONFIG_HAVE_UNSTABLE_SCHED_CLOCK) && defined(CONFIG_64BIT)
-	/* With multiple 64bit CPUs online, the cr16's are not syncronized. */
-	if (cpu != 0)
-		clear_sched_clock_stable();
-#endif
-
 	mtctl(next_tick, 16);		/* kick off Interval Timer (CR16) */
 
 	per_cpu(cpu_data, cpu).it_value = next_tick;

commit ae141830b118c3fb5b7eab6fa7c8ab7b7224b0a4
Author: Helge Deller <deller@gmx.de>
Date:   Fri Aug 19 22:39:02 2016 +0200

    parisc: Fix automatic selection of cr16 clocksource
    
    Commit 54b66800907 (parisc: Add native high-resolution sched_clock()
    implementation) added support to use the CPU-internal cr16 counters as reliable
    clocksource with the help of HAVE_UNSTABLE_SCHED_CLOCK.
    
    Sadly the commit missed to remove the hack which prevented cr16 to become the
    default clocksource even on SMP systems.
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Cc: stable@vger.kernel.org # 4.7+

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 505cf1ac5af2..4b0b963d52a7 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -221,18 +221,6 @@ static struct clocksource clocksource_cr16 = {
 	.flags			= CLOCK_SOURCE_IS_CONTINUOUS,
 };
 
-int update_cr16_clocksource(void)
-{
-	/* since the cr16 cycle counters are not synchronized across CPUs,
-	   we'll check if we should switch to a safe clocksource: */
-	if (clocksource_cr16.rating != 0 && num_online_cpus() > 1) {
-		clocksource_change_rating(&clocksource_cr16, 0);
-		return 1;
-	}
-
-	return 0;
-}
-
 void __init start_cpu_itimer(void)
 {
 	unsigned int cpu = smp_processor_id();

commit 6c84239d595dc6ffe39f0f03dae2f64ed200db95
Merge: d4c06c708123 6f367788d633
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Aug 5 09:48:22 2016 -0400

    Merge tag 'rtc-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/abelloni/linux
    
    Pull RTC updates from Alexandre Belloni:
     "RTC for 4.8
    
      Cleanups:
       - huge cleanup of rtc-generic and char/genrtc this allowed to cleanup
         rtc-cmos, rtc-sh, rtc-m68k, rtc-powerpc and rtc-parisc
       - move mn10300 to rtc-cmos
    
      Subsystem:
       - fix wakealarms after hibernate
       - multiples fixes for rctest
       - simplify implementations of .read_alarm
    
      New drivers:
       - Maxim MAX6916
    
      Drivers:
       - ds1307: fix weekday
       - m41t80: add wakeup support
       - pcf85063: add support for PCF85063A variant
       - rv8803: extend i2c fix and other fixes
       - s35390a: fix alarm reading, this fixes instant reboot after
         shutdown for QNAP TS-41x
       - s3c: clock fixes"
    
    * tag 'rtc-4.8' of git://git.kernel.org/pub/scm/linux/kernel/git/abelloni/linux: (65 commits)
      rtc: rv8803: Clear V1F when setting the time
      rtc: rv8803: Stop the clock while setting the time
      rtc: rv8803: Always apply the IÂ²C workaround
      rtc: rv8803: Fix read day of week
      rtc: rv8803: Remove the check for valid time
      rtc: rv8803: Kconfig: Indicate rx8900 support
      rtc: asm9260: remove .owner field for driver
      rtc: at91sam9: Fix missing spin_lock_init()
      rtc: m41t80: add suspend handlers for alarm IRQ
      rtc: m41t80: make it a real error message
      rtc: pcf85063: Add support for the PCF85063A device
      rtc: pcf85063: fix year range
      rtc: hym8563: in .read_alarm set .tm_sec to 0 to signal minute accuracy
      rtc: explicitly set tm_sec = 0 for drivers with minute accurancy
      rtc: s3c: Add s3c_rtc_{enable/disable}_clk in s3c_rtc_setfreq()
      rtc: s3c: Remove unnecessary call to disable already disabled clock
      rtc: abx80x: use devm_add_action_or_reset()
      rtc: m41t80: use devm_add_action_or_reset()
      rtc: fix a typo and reduce three empty lines to one
      rtc: s35390a: improve two comments in .set_alarm
      ...

commit 0032c08833ab7c7861d12eb35da26dce85f3e229
Author: Helge Deller <deller@gmx.de>
Date:   Fri Jun 3 19:22:31 2016 +0200

    parisc: Fix printk time during boot
    
    Avoid showing invalid printk time stamps during boot.
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Reviewed-by: Aaro Koskinen <aaro.koskinen@iki.fi>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 58dd6801f5be..31ec99a5f119 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -309,11 +309,6 @@ void __init time_init(void)
 	clocks_calc_mult_shift(&cyc2ns_mul, &cyc2ns_shift, current_cr16_khz,
 				NSEC_PER_MSEC, 0);
 
-#if defined(CONFIG_HAVE_UNSTABLE_SCHED_CLOCK) && defined(CONFIG_64BIT)
-	/* At bootup only one 64bit CPU is online and cr16 is "stable" */
-	set_sched_clock_stable();
-#endif
-
 	start_cpu_itimer();	/* get CPU 0 started */
 
 	/* register at clocksource framework */

commit ca6da801878635bfb851088e1a4eaa3745720582
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon May 30 20:57:55 2016 +0200

    rtc: parisc: provide rtc_class_ops directly
    
    The rtc-generic driver provides an architecture specific
    wrapper on top of the generic rtc_class_ops abstraction,
    and on pa-risc, that is implemented using an open-coded
    version of rtc_time_to_tm/rtc_tm_to_time.
    
    This changes the parisc rtc-generic device to provide its
    rtc_class_ops directly, using the normal helper functions,
    which makes this y2038 safe (on 32-bit) and simplifies
    the implementation.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Alexandre Belloni <alexandre.belloni@free-electrons.com>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 58dd6801f5be..744878789752 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -12,6 +12,7 @@
  */
 #include <linux/errno.h>
 #include <linux/module.h>
+#include <linux/rtc.h>
 #include <linux/sched.h>
 #include <linux/kernel.h>
 #include <linux/param.h>
@@ -248,14 +249,47 @@ void __init start_cpu_itimer(void)
 	per_cpu(cpu_data, cpu).it_value = next_tick;
 }
 
+#if IS_ENABLED(CONFIG_RTC_DRV_GENERIC)
+static int rtc_generic_get_time(struct device *dev, struct rtc_time *tm)
+{
+	struct pdc_tod tod_data;
+
+	memset(tm, 0, sizeof(*tm));
+	if (pdc_tod_read(&tod_data) < 0)
+		return -EOPNOTSUPP;
+
+	/* we treat tod_sec as unsigned, so this can work until year 2106 */
+	rtc_time64_to_tm(tod_data.tod_sec, tm);
+	return rtc_valid_tm(tm);
+}
+
+static int rtc_generic_set_time(struct device *dev, struct rtc_time *tm)
+{
+	time64_t secs = rtc_tm_to_time64(tm);
+
+	if (pdc_tod_set(secs, 0) < 0)
+		return -EOPNOTSUPP;
+
+	return 0;
+}
+
+static const struct rtc_class_ops rtc_generic_ops = {
+	.read_time = rtc_generic_get_time,
+	.set_time = rtc_generic_set_time,
+};
+
 static int __init rtc_init(void)
 {
 	struct platform_device *pdev;
 
-	pdev = platform_device_register_simple("rtc-generic", -1, NULL, 0);
+	pdev = platform_device_register_data(NULL, "rtc-generic", -1,
+					     &rtc_generic_ops,
+					     sizeof(rtc_generic_ops));
+
 	return PTR_ERR_OR_ZERO(pdev);
 }
 device_initcall(rtc_init);
+#endif
 
 void read_persistent_clock(struct timespec *ts)
 {

commit 54b668009076caddbede8fde513ca2c982590bfe
Author: Helge Deller <deller@gmx.de>
Date:   Wed Apr 20 21:34:15 2016 +0200

    parisc: Add native high-resolution sched_clock() implementation
    
    Add a native implementation for the sched_clock() function which utilizes the
    processor-internal cycle counter (Control Register 16) as high-resolution time
    source.
    
    With this patch we now get much more fine-grained resolutions in various
    in-kernel time measurements (e.g. when viewing the function tracing logs), and
    probably a more accurate scheduling on SMP systems.
    
    There are a few specific implementation details in this patch:
    
    1. On a 32bit kernel we emulate the higher 32bits of the required 64-bit
    resolution of sched_clock() by increasing a per-cpu counter at every
    wrap-around of the 32bit cycle counter.
    
    2. In a SMP system, the cycle counters of the various CPUs are not syncronized
    (similiar to the TSC in a x86_64 system). To cope with this we define
    HAVE_UNSTABLE_SCHED_CLOCK and let the upper layers do the adjustment work.
    
    3. Since we need HAVE_UNSTABLE_SCHED_CLOCK, we need to provide a cmpxchg64()
    function even on a 32-bit kernel.
    
    4. A 64-bit SMP kernel which is started on a UP system will mark the
    sched_clock() implementation as "stable", which means that we don't expect any
    jumps in the returned counter. This is true because we then run only on one
    CPU.
    
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 400acac0a304..58dd6801f5be 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -38,6 +38,18 @@
 
 static unsigned long clocktick __read_mostly;	/* timer cycles per tick */
 
+#ifndef CONFIG_64BIT
+/*
+ * The processor-internal cycle counter (Control Register 16) is used as time
+ * source for the sched_clock() function.  This register is 64bit wide on a
+ * 64-bit kernel and 32bit on a 32-bit kernel. Since sched_clock() always
+ * requires a 64bit counter we emulate on the 32-bit kernel the higher 32bits
+ * with a per-cpu variable which we increase every time the counter
+ * wraps-around (which happens every ~4 secounds).
+ */
+static DEFINE_PER_CPU(unsigned long, cr16_high_32_bits);
+#endif
+
 /*
  * We keep time on PA-RISC Linux by using the Interval Timer which is
  * a pair of registers; one is read-only and one is write-only; both
@@ -108,6 +120,12 @@ irqreturn_t __irq_entry timer_interrupt(int irq, void *dev_id)
 	 */
 	mtctl(next_tick, 16);
 
+#if !defined(CONFIG_64BIT)
+	/* check for overflow on a 32bit kernel (every ~4 seconds). */
+	if (unlikely(next_tick < now))
+		this_cpu_inc(cr16_high_32_bits);
+#endif
+
 	/* Skip one clocktick on purpose if we missed next_tick.
 	 * The new CR16 must be "later" than current CR16 otherwise
 	 * itimer would not fire until CR16 wrapped - e.g 4 seconds
@@ -219,6 +237,12 @@ void __init start_cpu_itimer(void)
 	unsigned int cpu = smp_processor_id();
 	unsigned long next_tick = mfctl(16) + clocktick;
 
+#if defined(CONFIG_HAVE_UNSTABLE_SCHED_CLOCK) && defined(CONFIG_64BIT)
+	/* With multiple 64bit CPUs online, the cr16's are not syncronized. */
+	if (cpu != 0)
+		clear_sched_clock_stable();
+#endif
+
 	mtctl(next_tick, 16);		/* kick off Interval Timer (CR16) */
 
 	per_cpu(cpu_data, cpu).it_value = next_tick;
@@ -246,15 +270,52 @@ void read_persistent_clock(struct timespec *ts)
 	}
 }
 
+
+/*
+ * sched_clock() framework
+ */
+
+static u32 cyc2ns_mul __read_mostly;
+static u32 cyc2ns_shift __read_mostly;
+
+u64 sched_clock(void)
+{
+	u64 now;
+
+	/* Get current cycle counter (Control Register 16). */
+#ifdef CONFIG_64BIT
+	now = mfctl(16);
+#else
+	now = mfctl(16) + (((u64) this_cpu_read(cr16_high_32_bits)) << 32);
+#endif
+
+	/* return the value in ns (cycles_2_ns) */
+	return mul_u64_u32_shr(now, cyc2ns_mul, cyc2ns_shift);
+}
+
+
+/*
+ * timer interrupt and sched_clock() initialization
+ */
+
 void __init time_init(void)
 {
 	unsigned long current_cr16_khz;
 
+	current_cr16_khz = PAGE0->mem_10msec/10;  /* kHz */
 	clocktick = (100 * PAGE0->mem_10msec) / HZ;
 
+	/* calculate mult/shift values for cr16 */
+	clocks_calc_mult_shift(&cyc2ns_mul, &cyc2ns_shift, current_cr16_khz,
+				NSEC_PER_MSEC, 0);
+
+#if defined(CONFIG_HAVE_UNSTABLE_SCHED_CLOCK) && defined(CONFIG_64BIT)
+	/* At bootup only one 64bit CPU is online and cr16 is "stable" */
+	set_sched_clock_stable();
+#endif
+
 	start_cpu_itimer();	/* get CPU 0 started */
 
 	/* register at clocksource framework */
-	current_cr16_khz = PAGE0->mem_10msec/10;  /* kHz */
 	clocksource_register_khz(&clocksource_cr16, current_cr16_khz);
 }

commit 6dc0dcde406bb0e40ad6a6f45f44534d3a094205
Author: Helge Deller <deller@gmx.de>
Date:   Tue Sep 8 17:50:03 2015 +0200

    parisc: Use platform_device_register_simple("rtc-generic")
    
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index cc68a4fbce6a..400acac0a304 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -224,20 +224,14 @@ void __init start_cpu_itimer(void)
 	per_cpu(cpu_data, cpu).it_value = next_tick;
 }
 
-static struct platform_device rtc_generic_dev = {
-	.name = "rtc-generic",
-	.id = -1,
-};
-
 static int __init rtc_init(void)
 {
-	if (platform_device_register(&rtc_generic_dev) < 0)
-		printk(KERN_ERR "unable to register rtc device...\n");
+	struct platform_device *pdev;
 
-	/* not necessarily an error */
-	return 0;
+	pdev = platform_device_register_simple("rtc-generic", -1, NULL, 0);
+	return PTR_ERR_OR_ZERO(pdev);
 }
-module_init(rtc_init);
+device_initcall(rtc_init);
 
 void read_persistent_clock(struct timespec *ts)
 {

commit 72581cecee411be2b2c00226c98e0c20aab337a2
Author: Helge Deller <deller@gmx.de>
Date:   Tue Sep 8 17:49:31 2015 +0200

    parisc: Drop CONFIG_SMP around update_cr16_clocksource()
    
    No need to use CONFIG_SMP around update_cr16_clocksource(). It checks for
    num_online_cpus() beeing greater than 1, which is always 1 in UP builds.
    
    Signed-off-by: Helge Deller <deller@gmx.de>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 70e105d62423..cc68a4fbce6a 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -202,7 +202,6 @@ static struct clocksource clocksource_cr16 = {
 	.flags			= CLOCK_SOURCE_IS_CONTINUOUS,
 };
 
-#ifdef CONFIG_SMP
 int update_cr16_clocksource(void)
 {
 	/* since the cr16 cycle counters are not synchronized across CPUs,
@@ -214,12 +213,6 @@ int update_cr16_clocksource(void)
 
 	return 0;
 }
-#else
-int update_cr16_clocksource(void)
-{
-	return 0; /* no change */
-}
-#endif /*CONFIG_SMP*/
 
 void __init start_cpu_itimer(void)
 {

commit 4a8a0788a36c923a0229beae5e88d9849e359db5
Author: Rolf Eike Beer <eike-kernel@sf-tec.de>
Date:   Thu May 10 23:08:17 2012 +0200

    parisc: move definition of PAGE0 to asm/page.h
    
    This was defined in asm/pdc.h which needs to include asm/page.h for
    __PAGE_OFFSET. This leads to an include loop so that page.h eventually will
    include pdc.h again. While this is no problem because of header guards, it is
    a problem because some symbols may be undefined. Such an error is this:
    
    In file included from include/linux/bitops.h:35:0,
                     from include/asm-generic/getorder.h:7,
                     from arch/parisc/include/asm/page.h:162,
                     from arch/parisc/include/asm/pdc.h:346,
                     from arch/parisc/include/asm/processor.h:16,
                     from arch/parisc/include/asm/spinlock.h:6,
                     from arch/parisc/include/asm/atomic.h:20,
                     from include/linux/atomic.h:4,
                     from include/linux/sysfs.h:20,
                     from include/linux/kobject.h:21,
                     from include/linux/device.h:17,
                     from include/linux/eisa.h:5,
                     from arch/parisc/kernel/pci.c:11:
    arch/parisc/include/asm/bitops.h: In function âset_bitâ:
    arch/parisc/include/asm/bitops.h:82:2: error: implicit declaration of function â_atomic_spin_lock_irqsaveâ [-Werror=implicit-function-declaration]
    arch/parisc/include/asm/bitops.h:84:2: error: implicit declaration of function â_atomic_spin_unlock_irqrestoreâ [-Werror=implicit-function-declaration]
    
    Signed-off-by: Rolf Eike Beer <eike-kernel@sf-tec.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 7c0774397b89..70e105d62423 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -29,6 +29,7 @@
 #include <asm/uaccess.h>
 #include <asm/io.h>
 #include <asm/irq.h>
+#include <asm/page.h>
 #include <asm/param.h>
 #include <asm/pdc.h>
 #include <asm/led.h>

commit 63e496340f07b58925f690451c93171d9b04fe1e
Author: John Stultz <johnstul@us.ibm.com>
Date:   Mon Apr 26 20:23:50 2010 -0700

    clocksource: parisc: Convert to clocksource_register_hz/khz
    
    This converts the parisc clocksources to use clocksource_register_hz/khz
    
    This is untested, so any assistance in testing would be appreciated!
    
    CC: Kyle McMartin <kyle@mcmartin.ca>
    CC: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: John Stultz <johnstul@us.ibm.com>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 45b7389d77aa..7c0774397b89 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -198,8 +198,6 @@ static struct clocksource clocksource_cr16 = {
 	.rating			= 300,
 	.read			= read_cr16,
 	.mask			= CLOCKSOURCE_MASK(BITS_PER_LONG),
-	.mult			= 0, /* to be set */
-	.shift			= 22,
 	.flags			= CLOCK_SOURCE_IS_CONTINUOUS,
 };
 
@@ -270,7 +268,5 @@ void __init time_init(void)
 
 	/* register at clocksource framework */
 	current_cr16_khz = PAGE0->mem_10msec/10;  /* kHz */
-	clocksource_cr16.mult = clocksource_khz2mult(current_cr16_khz,
-						clocksource_cr16.shift);
-	clocksource_register(&clocksource_cr16);
+	clocksource_register_khz(&clocksource_cr16, current_cr16_khz);
 }

commit bb1dfc1cf6c51ca42f7c05029a6f06df9092a0fc
Author: Torben Hohn <torbenh@gmx.de>
Date:   Thu Jan 27 16:00:17 2011 +0100

    parisc: Switch do_timer() to xtime_update()
    
    xtime_update() takes the xtime_lock itself.
    
    Signed-off-by: Torben Hohn <torbenh@gmx.de>
    Cc: hch@infradead.org
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: johnstul@us.ibm.com
    Cc: Helge Deller <deller@gmx.de>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: yong.zhang0@gmail.com
    LKML-Reference: <20110127150017.23248.22559.stgit@localhost>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 05511ccb61d2..45b7389d77aa 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -162,11 +162,8 @@ irqreturn_t __irq_entry timer_interrupt(int irq, void *dev_id)
 		update_process_times(user_mode(get_irq_regs()));
 	}
 
-	if (cpu == 0) {
-		write_seqlock(&xtime_lock);
-		do_timer(ticks_elapsed);
-		write_sequnlock(&xtime_lock);
-	}
+	if (cpu == 0)
+		xtime_update(ticks_elapsed);
 
 	return IRQ_HANDLED;
 }

commit c60185248fd1c7b777f08d3f3337836331da3d17
Author: john stultz <johnstul@us.ibm.com>
Date:   Wed Dec 23 04:14:03 2009 +0000

    parisc: Convert to read/update_persistent_clock
    
    This patch converts the parisc architecture to use the generic
    read_persistent_clock and update_persistent_clock interfaces, reducing
    the amount of arch specific code we have to maintain, and allowing for
    further cleanups in the future.
    
    I have not built or tested this patch, so help from arch maintainers
    would be appreciated.
    
    Signed-off-by: John Stultz <johnstul@us.ibm.com>
    Acked-by: Helge Deller <deller@gmx.de>
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index a79c6f9e7e2c..05511ccb61d2 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -250,9 +250,21 @@ static int __init rtc_init(void)
 }
 module_init(rtc_init);
 
-void __init time_init(void)
+void read_persistent_clock(struct timespec *ts)
 {
 	static struct pdc_tod tod_data;
+	if (pdc_tod_read(&tod_data) == 0) {
+		ts->tv_sec = tod_data.tod_sec;
+		ts->tv_nsec = tod_data.tod_usec * 1000;
+	} else {
+		printk(KERN_ERR "Error reading tod clock\n");
+	        ts->tv_sec = 0;
+		ts->tv_nsec = 0;
+	}
+}
+
+void __init time_init(void)
+{
 	unsigned long current_cr16_khz;
 
 	clocktick = (100 * PAGE0->mem_10msec) / HZ;
@@ -264,19 +276,4 @@ void __init time_init(void)
 	clocksource_cr16.mult = clocksource_khz2mult(current_cr16_khz,
 						clocksource_cr16.shift);
 	clocksource_register(&clocksource_cr16);
-
-	if (pdc_tod_read(&tod_data) == 0) {
-		unsigned long flags;
-
-		write_seqlock_irqsave(&xtime_lock, flags);
-		xtime.tv_sec = tod_data.tod_sec;
-		xtime.tv_nsec = tod_data.tod_usec * 1000;
-		set_normalized_timespec(&wall_to_monotonic,
-		                        -xtime.tv_sec, -xtime.tv_nsec);
-		write_sequnlock_irqrestore(&xtime_lock, flags);
-	} else {
-		printk(KERN_ERR "Error reading tod clock\n");
-	        xtime.tv_sec = 0;
-		xtime.tv_nsec = 0;
-	}
 }

commit 84be31be3727d11b2a91781306b642e801c5a379
Author: Grant Grundler <grundler@parisc-linux.org>
Date:   Mon Jun 1 00:20:23 2009 +0000

    parisc: fix "delay!" timer handling
    
    Rewrote timer_interrupt() to properly handle the "delayed!" case.
    
    If we used floating point math to compute the number of ticks that had
    elapsed since the last timer interrupt, it could take up to 12K cycles
    (emperical!) to handle the interrupt. Existing code assumed it would
    never take more than 8k cycles. We end up programming Interval Timer
    to a value less than "current" cycle counter.  Thus have to wait until
    Interval Timer "wrapped" and would then get the "delayed!" printk that
    I moved below.
    
    Since we don't really know what the upper limit is, I prefer to read
    CR16 again after we've programmed it to make sure we won't have to
    wait for CR16 to wrap.
    
    Further, the printk was between reading CR16 (cycle couner) and writing CR16
    (the interval timer). This would cause us to continue to set the interval
    timer to a value that was "behind" the cycle counter. Rinse and repeat.
    So no printk's between reading CR16 and setting next interval timer.
    
    Tested on A500 (550 Mhz PA8600).
    
    Signed-off-by: Grant Grundler <grundler@parisc-linux.org>
    Tested-by: Kyle McMartin <kyle@mcmartin.ca>
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>
    
    ----
    Kyle, Helge, and other parisc's,
    Please test on 32-bit before committing.
    I think I have it right but recognize I might not.
    
    TODO: I wanted to use "do_div()" in order to get both remainder
    and value back with one division op. That should help with the
    latency alot but can be applied seperately from this patch.
    
    thanks,
    grant

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index d97d07f47a55..a79c6f9e7e2c 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -56,9 +56,9 @@ static unsigned long clocktick __read_mostly;	/* timer cycles per tick */
  */
 irqreturn_t __irq_entry timer_interrupt(int irq, void *dev_id)
 {
-	unsigned long now;
+	unsigned long now, now2;
 	unsigned long next_tick;
-	unsigned long cycles_elapsed, ticks_elapsed;
+	unsigned long cycles_elapsed, ticks_elapsed = 1;
 	unsigned long cycles_remainder;
 	unsigned int cpu = smp_processor_id();
 	struct cpuinfo_parisc *cpuinfo = &per_cpu(cpu_data, cpu);
@@ -71,44 +71,24 @@ irqreturn_t __irq_entry timer_interrupt(int irq, void *dev_id)
 	/* Initialize next_tick to the expected tick time. */
 	next_tick = cpuinfo->it_value;
 
-	/* Get current interval timer.
-	 * CR16 reads as 64 bits in CPU wide mode.
-	 * CR16 reads as 32 bits in CPU narrow mode.
-	 */
+	/* Get current cycle counter (Control Register 16). */
 	now = mfctl(16);
 
 	cycles_elapsed = now - next_tick;
 
-	if ((cycles_elapsed >> 5) < cpt) {
+	if ((cycles_elapsed >> 6) < cpt) {
 		/* use "cheap" math (add/subtract) instead
 		 * of the more expensive div/mul method
 		 */
 		cycles_remainder = cycles_elapsed;
-		ticks_elapsed = 1;
 		while (cycles_remainder > cpt) {
 			cycles_remainder -= cpt;
 			ticks_elapsed++;
 		}
 	} else {
+		/* TODO: Reduce this to one fdiv op */
 		cycles_remainder = cycles_elapsed % cpt;
-		ticks_elapsed = 1 + cycles_elapsed / cpt;
-	}
-
-	/* Can we differentiate between "early CR16" (aka Scenario 1) and
-	 * "long delay" (aka Scenario 3)? I don't think so.
-	 *
-	 * We expected timer_interrupt to be delivered at least a few hundred
-	 * cycles after the IT fires. But it's arbitrary how much time passes
-	 * before we call it "late". I've picked one second.
-	 */
-	if (unlikely(ticks_elapsed > HZ)) {
-		/* Scenario 3: very long delay?  bad in any case */
-		printk (KERN_CRIT "timer_interrupt(CPU %d): delayed!"
-			" cycles %lX rem %lX "
-			" next/now %lX/%lX\n",
-			cpu,
-			cycles_elapsed, cycles_remainder,
-			next_tick, now );
+		ticks_elapsed += cycles_elapsed / cpt;
 	}
 
 	/* convert from "division remainder" to "remainder of clock tick" */
@@ -122,18 +102,56 @@ irqreturn_t __irq_entry timer_interrupt(int irq, void *dev_id)
 
 	cpuinfo->it_value = next_tick;
 
-	/* Skip one clocktick on purpose if we are likely to miss next_tick.
-	 * We want to avoid the new next_tick being less than CR16.
-	 * If that happened, itimer wouldn't fire until CR16 wrapped.
-	 * We'll catch the tick we missed on the tick after that.
+	/* Program the IT when to deliver the next interrupt.
+	 * Only bottom 32-bits of next_tick are writable in CR16!
 	 */
-	if (!(cycles_remainder >> 13))
-		next_tick += cpt;
-
-	/* Program the IT when to deliver the next interrupt. */
-	/* Only bottom 32-bits of next_tick are written to cr16.  */
 	mtctl(next_tick, 16);
 
+	/* Skip one clocktick on purpose if we missed next_tick.
+	 * The new CR16 must be "later" than current CR16 otherwise
+	 * itimer would not fire until CR16 wrapped - e.g 4 seconds
+	 * later on a 1Ghz processor. We'll account for the missed
+	 * tick on the next timer interrupt.
+	 *
+	 * "next_tick - now" will always give the difference regardless
+	 * if one or the other wrapped. If "now" is "bigger" we'll end up
+	 * with a very large unsigned number.
+	 */
+	now2 = mfctl(16);
+	if (next_tick - now2 > cpt)
+		mtctl(next_tick+cpt, 16);
+
+#if 1
+/*
+ * GGG: DEBUG code for how many cycles programming CR16 used.
+ */
+	if (unlikely(now2 - now > 0x3000)) 	/* 12K cycles */
+		printk (KERN_CRIT "timer_interrupt(CPU %d): SLOW! 0x%lx cycles!"
+			" cyc %lX rem %lX "
+			" next/now %lX/%lX\n",
+			cpu, now2 - now, cycles_elapsed, cycles_remainder,
+			next_tick, now );
+#endif
+
+	/* Can we differentiate between "early CR16" (aka Scenario 1) and
+	 * "long delay" (aka Scenario 3)? I don't think so.
+	 *
+	 * Timer_interrupt will be delivered at least a few hundred cycles
+	 * after the IT fires. But it's arbitrary how much time passes
+	 * before we call it "late". I've picked one second.
+	 *
+	 * It's important NO printk's are between reading CR16 and
+	 * setting up the next value. May introduce huge variance.
+	 */
+	if (unlikely(ticks_elapsed > HZ)) {
+		/* Scenario 3: very long delay?  bad in any case */
+		printk (KERN_CRIT "timer_interrupt(CPU %d): delayed!"
+			" cycles %lX rem %lX "
+			" next/now %lX/%lX\n",
+			cpu,
+			cycles_elapsed, cycles_remainder,
+			next_tick, now );
+	}
 
 	/* Done mucking with unreliable delivery of interrupts.
 	 * Go do system house keeping.

commit ebc30a0f67a4d6a9470556f4311478b3b04c2b1f
Author: Coly Li <coly.li@suse.de>
Date:   Thu Apr 30 22:43:46 2009 +0000

    parisc: add parameter to read_cr16()
    
    This patch modifies parameter of au1x_counter1_read() from 'void' to 'struct
    clocksource *cs', which fixes compile warning for incompatible parameter type.
    
    Signed-off-by: Coly Li <coly.li@suse.de>
    Signed-off-by: Helge Deller <deller@gmx.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index d4dd05674c62..d97d07f47a55 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -173,7 +173,7 @@ EXPORT_SYMBOL(profile_pc);
 
 /* clock source code */
 
-static cycle_t read_cr16(void)
+static cycle_t read_cr16(struct clocksource *cs)
 {
 	return get_cycles();
 }

commit 3ba113d14cedcd88105a3b9c90f8ecce829e1095
Merge: bad6a5c08c11 b609308e1415
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Apr 3 09:52:04 2009 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/kyle/parisc-2.6
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/kyle/parisc-2.6: (23 commits)
      parisc: move dereference_function_descriptor to process.c
      parisc: Move kernel Elf_Fdesc define to <asm/elf.h>
      parisc: fix build when ARCH_HAS_KMAP
      parisc: fix "make tar-pkg"
      parisc: drivers: fix warnings
      parisc: select BUG always
      parisc: asm/pdc.h should include asm/page.h
      parisc: led: remove proc_dir_entry::owner
      parisc: fix macro expansion in atomic.h
      parisc: iosapic: fix build breakage
      parisc: oops_enter()/oops_exit() in die()
      parisc: document light weight syscall ABI
      parisc: blink all or loadavg LEDs on oops
      parisc: add ftrace (function and graph tracer) functionality
      parisc: simplify sys_clone()
      parisc: add LATENCYTOP_SUPPORT and CONFIG_STACKTRACE_SUPPORT
      parisc: allow to build with 16k default kernel page size
      parisc: expose 32/64-bit capabilities in cpuinfo
      parisc: use constants instead of numbers in assembly
      parisc: fix usage of 32bit PTE page table entries on 32bit kernels
      ...

commit 3afe6d04626f8de87b15150a30b78df492ab68ee
Author: Geert Uytterhoeven <Geert.Uytterhoeven@sonycom.com>
Date:   Thu Feb 19 16:46:49 2009 +0100

    parisc: rtc: Rename rtc-parisc to rtc-generic
    
    The rtc-parisc driver is not PA-RISC specific at all, as it uses the existing
    (but deprecated) generic RTC infrastructure ([gs]et_rtc_time()).
    Rename the driver from rtc-parisc to rtc-generic.
    
    Signed-off-by: Geert Uytterhoeven <Geert.Uytterhoeven@sonycom.com>
    Acked-by: Alessandro Zummo <a.zummo@towertech.it>
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index e75cae6072c5..86a99d02234f 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -216,14 +216,14 @@ void __init start_cpu_itimer(void)
 	per_cpu(cpu_data, cpu).it_value = next_tick;
 }
 
-static struct platform_device rtc_parisc_dev = {
-	.name = "rtc-parisc",
+static struct platform_device rtc_generic_dev = {
+	.name = "rtc-generic",
 	.id = -1,
 };
 
 static int __init rtc_init(void)
 {
-	if (platform_device_register(&rtc_parisc_dev) < 0)
+	if (platform_device_register(&rtc_generic_dev) < 0)
 		printk(KERN_ERR "unable to register rtc device...\n");
 
 	/* not necessarily an error */

commit cd875d4767f821dabd0feb668623a42e9d48158a
Author: dann frazier <dannf@hp.com>
Date:   Tue Mar 31 15:24:54 2009 -0700

    rtc-parisc: remove unnecessary ret variable
    
    Signed-off-by: dann frazier <dannf@hp.com>
    Cc: Alessandro Zummo <a.zummo@towertech.it>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: Grant Grundler <grundler@parisc-linux.org>
    Cc: Matthew Wilcox <matthew@wil.cx>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index a479d08d5ed3..e75cae6072c5 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -223,10 +223,7 @@ static struct platform_device rtc_parisc_dev = {
 
 static int __init rtc_init(void)
 {
-	int ret;
-
-	ret = platform_device_register(&rtc_parisc_dev);
-	if (ret < 0)
+	if (platform_device_register(&rtc_parisc_dev) < 0)
 		printk(KERN_ERR "unable to register rtc device...\n");
 
 	/* not necessarily an error */

commit d09c091b6a8b2b73381e514d68c73580f2294b03
Author: dann frazier <dannf@hp.com>
Date:   Tue Mar 31 15:24:53 2009 -0700

    rtc-parisc: declare rtc_parisc_dev as static
    
    Signed-off-by: dann frazier <dannf@hp.com>
    Cc: Alessandro Zummo <a.zummo@towertech.it>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: Grant Grundler <grundler@parisc-linux.org>
    Cc: Matthew Wilcox <matthew@wil.cx>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 9d46c43a4152..a479d08d5ed3 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -216,7 +216,7 @@ void __init start_cpu_itimer(void)
 	per_cpu(cpu_data, cpu).it_value = next_tick;
 }
 
-struct platform_device rtc_parisc_dev = {
+static struct platform_device rtc_parisc_dev = {
 	.name = "rtc-parisc",
 	.id = -1,
 };

commit d75f054a2cf0614ff63d534ff21ca8eaab41e713
Author: Helge Deller <deller@gmx.de>
Date:   Mon Feb 9 00:43:36 2009 +0100

    parisc: add ftrace (function and graph tracer) functionality
    
    This patch adds the ftrace debugging functionality to the parisc kernel.
    It will currently only work with 64bit kernels, because the gcc options -pg
    and -ffunction-sections can't be enabled at the same time and -ffunction-sections
    is still needed to be able to link 32bit kernels.
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 9d46c43a4152..badaad9ff139 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -24,6 +24,7 @@
 #include <linux/profile.h>
 #include <linux/clocksource.h>
 #include <linux/platform_device.h>
+#include <linux/ftrace.h>
 
 #include <asm/uaccess.h>
 #include <asm/io.h>
@@ -53,7 +54,7 @@ static unsigned long clocktick __read_mostly;	/* timer cycles per tick */
  * held off for an arbitrarily long period of time by interrupts being
  * disabled, so we may miss one or more ticks.
  */
-irqreturn_t timer_interrupt(int irq, void *dev_id)
+irqreturn_t __irq_entry timer_interrupt(int irq, void *dev_id)
 {
 	unsigned long now;
 	unsigned long next_tick;

commit ef017bebd01c1b4e075d649eee0c8c1c79f9ceb9
Author: Helge Deller <deller@gmx.de>
Date:   Wed Dec 31 03:12:10 2008 +0000

    parisc: Replace NR_CPUS in parisc code
    
    parisc: Replace most arrays sized by NR_CPUS with percpu variables.
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 4d09203bc693..9d46c43a4152 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -60,7 +60,7 @@ irqreturn_t timer_interrupt(int irq, void *dev_id)
 	unsigned long cycles_elapsed, ticks_elapsed;
 	unsigned long cycles_remainder;
 	unsigned int cpu = smp_processor_id();
-	struct cpuinfo_parisc *cpuinfo = &cpu_data[cpu];
+	struct cpuinfo_parisc *cpuinfo = &per_cpu(cpu_data, cpu);
 
 	/* gcc can optimize for "read-only" case with a local clocktick */
 	unsigned long cpt = clocktick;
@@ -213,7 +213,7 @@ void __init start_cpu_itimer(void)
 
 	mtctl(next_tick, 16);		/* kick off Interval Timer (CR16) */
 
-	cpu_data[cpu].it_value = next_tick;
+	per_cpu(cpu_data, cpu).it_value = next_tick;
 }
 
 struct platform_device rtc_parisc_dev = {

commit 9eb1686423756f4dfb0ad8bfb02bb8bf1b89e50a
Author: Kyle McMartin <kyle@mcmartin.ca>
Date:   Wed Sep 10 14:24:07 2008 +0000

    parisc: add rtc platform driver
    
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 24be86bba94d..4d09203bc693 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -23,6 +23,7 @@
 #include <linux/smp.h>
 #include <linux/profile.h>
 #include <linux/clocksource.h>
+#include <linux/platform_device.h>
 
 #include <asm/uaccess.h>
 #include <asm/io.h>
@@ -215,6 +216,24 @@ void __init start_cpu_itimer(void)
 	cpu_data[cpu].it_value = next_tick;
 }
 
+struct platform_device rtc_parisc_dev = {
+	.name = "rtc-parisc",
+	.id = -1,
+};
+
+static int __init rtc_init(void)
+{
+	int ret;
+
+	ret = platform_device_register(&rtc_parisc_dev);
+	if (ret < 0)
+		printk(KERN_ERR "unable to register rtc device...\n");
+
+	/* not necessarily an error */
+	return 0;
+}
+module_init(rtc_init);
+
 void __init time_init(void)
 {
 	static struct pdc_tod tod_data;
@@ -245,4 +264,3 @@ void __init time_init(void)
 		xtime.tv_nsec = 0;
 	}
 }
-

commit 730e844d57693f464c7f9954a0f7102414164c3f
Author: Kyle McMartin <kyle@mcmartin.ca>
Date:   Thu Oct 18 00:03:45 2007 -0700

    [PARISC] Kill pointless variable use in time.c
    
    Clean up a pointless use of a variable in update_cr16_clocksource. It just
    looks silly.
    
    Signed-off-by: Kyle McMartin <kyle@mcmartin.ca>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 8b3062a5c812..24be86bba94d 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -189,16 +189,14 @@ static struct clocksource clocksource_cr16 = {
 #ifdef CONFIG_SMP
 int update_cr16_clocksource(void)
 {
-	int change = 0;
-
 	/* since the cr16 cycle counters are not synchronized across CPUs,
 	   we'll check if we should switch to a safe clocksource: */
 	if (clocksource_cr16.rating != 0 && num_online_cpus() > 1) {
 		clocksource_change_rating(&clocksource_cr16, 0);
-		change = 1;
+		return 1;
 	}
 
-	return change;
+	return 0;
 }
 #else
 int update_cr16_clocksource(void)

commit 7022672e4046fac4699aa5f8ff2a5213b7ec4ff9
Author: Simon Arlott <simon@fire.lp0.eu>
Date:   Fri May 11 20:42:34 2007 +0100

    [PARISC] spelling fixes: arch/parisc/
    
    Spelling fixes in arch/parisc/.
    
    Signed-off-by: Simon Arlott <simon@fire.lp0.eu>
    Acked-by: Grant Grundler <grundler@parisc-linux.org>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 07a991aa9b0c..8b3062a5c812 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -191,7 +191,7 @@ int update_cr16_clocksource(void)
 {
 	int change = 0;
 
-	/* since the cr16 cycle counters are not syncronized across CPUs,
+	/* since the cr16 cycle counters are not synchronized across CPUs,
 	   we'll check if we should switch to a safe clocksource: */
 	if (clocksource_cr16.rating != 0 && num_online_cpus() > 1) {
 		clocksource_change_rating(&clocksource_cr16, 0);

commit 01363220f5d23ef68276db8974e46a502e43d01d
Author: Kyle McMartin <kyle@mako.i.cabal.ca>
Date:   Mon Feb 26 22:21:22 2007 -0500

    [PARISC] clocksource: Move update_cr16_clocksource later in boot
    
    smp_cpus_done is too early for us... before we even do a device
    inventory! Move update_cr16_clocksource into the tail end of
    processor_probe() and stub it out on CONFIG_SMP=n builds.
    
    Verified that clocksource0 is properly updated to use jiffies
    on an SMP build.
    
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 9b14066d693c..07a991aa9b0c 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -200,6 +200,11 @@ int update_cr16_clocksource(void)
 
 	return change;
 }
+#else
+int update_cr16_clocksource(void)
+{
+	return 0; /* no change */
+}
 #endif /*CONFIG_SMP*/
 
 void __init start_cpu_itimer(void)

commit b2a8289a611af409e5621df27227dc3f55ba358b
Author: Kyle McMartin <kyle@mako.i.cabal.ca>
Date:   Mon Feb 26 21:24:56 2007 -0500

    [PARISC] time: clocksource lost update_callback
    
    So move the code to be called by smp_cpus_done, which is
    after we've figured out if there's more than one cpu
    actually present.
    
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index d45f77f62908..9b14066d693c 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -176,8 +176,6 @@ static cycle_t read_cr16(void)
 	return get_cycles();
 }
 
-static int cr16_update_callback(void);
-
 static struct clocksource clocksource_cr16 = {
 	.name			= "cr16",
 	.rating			= 300,
@@ -185,11 +183,11 @@ static struct clocksource clocksource_cr16 = {
 	.mask			= CLOCKSOURCE_MASK(BITS_PER_LONG),
 	.mult			= 0, /* to be set */
 	.shift			= 22,
-	.update_callback	= cr16_update_callback,
 	.flags			= CLOCK_SOURCE_IS_CONTINUOUS,
 };
 
-static int cr16_update_callback(void)
+#ifdef CONFIG_SMP
+int update_cr16_clocksource(void)
 {
 	int change = 0;
 
@@ -202,7 +200,7 @@ static int cr16_update_callback(void)
 
 	return change;
 }
-
+#endif /*CONFIG_SMP*/
 
 void __init start_cpu_itimer(void)
 {

commit 87c8174727c95ab43f5bd2164e78c665c6945e67
Author: Kyle McMartin <kyle@mako.i.cabal.ca>
Date:   Mon Feb 26 20:15:18 2007 -0500

    [PARISC] time: Convert clocksource is_continuous to flag
    
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 5cbc286cd086..d45f77f62908 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -186,7 +186,7 @@ static struct clocksource clocksource_cr16 = {
 	.mult			= 0, /* to be set */
 	.shift			= 22,
 	.update_callback	= cr16_update_callback,
-	.is_continuous		= 1,
+	.flags			= CLOCK_SOURCE_IS_CONTINUOUS,
 };
 
 static int cr16_update_callback(void)

commit 00d1f3c31a415bb3701abbd3a2c2aa44cb97116c
Author: Kyle McMartin <kyle@mako.i.cabal.ca>
Date:   Mon Feb 26 20:10:42 2007 -0500

    [PARISC] clocksource_cr16: Use clocksource_change_rating()
    
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index d1db8e518654..5cbc286cd086 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -196,8 +196,7 @@ static int cr16_update_callback(void)
 	/* since the cr16 cycle counters are not syncronized across CPUs,
 	   we'll check if we should switch to a safe clocksource: */
 	if (clocksource_cr16.rating != 0 && num_online_cpus() > 1) {
-		clocksource_cr16.rating = 0;
-		clocksource_reselect();
+		clocksource_change_rating(&clocksource_cr16, 0);
 		change = 1;
 	}
 

commit b0138a6cb7923a997d278b47c176778534d1095b
Merge: 6572d6d7d0f9 1055a8af093f
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Mon Feb 26 12:48:06 2007 -0800

    Merge master.kernel.org:/pub/scm/linux/kernel/git/kyle/parisc-2.6
    
    * master.kernel.org:/pub/scm/linux/kernel/git/kyle/parisc-2.6: (78 commits)
      [PARISC] Use symbolic last syscall in __NR_Linux_syscalls
      [PARISC] Add missing statfs64 and fstatfs64 syscalls
      Revert "[PARISC] Optimize TLB flush on SMP systems"
      [PARISC] Compat signal fixes for 64-bit parisc
      [PARISC] Reorder syscalls to match unistd.h
      Revert "[PATCH] make kernel/signal.c:kill_proc_info() static"
      [PARISC] fix sys_rt_sigqueueinfo
      [PARISC] fix section mismatch warnings in harmony sound driver
      [PARISC] do not export get_register/set_register
      [PARISC] add ENTRY()/ENDPROC() and simplify assembly of HP/UX emulation code
      [PARISC] convert to use CONFIG_64BIT instead of __LP64__
      [PARISC] use CONFIG_64BIT instead of __LP64__
      [PARISC] add ASM_EXCEPTIONTABLE_ENTRY() macro
      [PARISC] more ENTRY(), ENDPROC(), END() conversions
      [PARISC] fix ENTRY() and ENDPROC() for 64bit-parisc
      [PARISC] Fixes /proc/cpuinfo cache output on B160L
      [PARISC] implement standard ENTRY(), END() and ENDPROC()
      [PARISC] kill ENTRY_SYS_CPUS
      [PARISC] clean up debugging printks in smp.c
      [PARISC] factor syscall_restart code out of do_signal
      ...
    
    Fix conflict in include/linux/sched.h due to kill_proc_info() being made
    publicly available to PARISC again.

commit 6e16d9409e1f08594587855d2a280c391ba985ff
Author: Helge Deller <deller@gmx.de>
Date:   Sun Jan 7 16:07:48 2007 +0100

    [PARISC] Convert soft power switch driver to kthread
    
    And remove it's reference in time.c.
    Allow lcd_print() to take a const char *.
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index c33b6e0f7c47..ccdce6ef67cc 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -148,10 +148,6 @@ irqreturn_t timer_interrupt(int irq, void *dev_id)
 		write_sequnlock(&xtime_lock);
 	}
 
-	/* check soft power switch status */
-	if (cpu == 0 && !atomic_read(&power_tasklet.count))
-		tasklet_schedule(&power_tasklet);
-
 	return IRQ_HANDLED;
 }
 

commit 324c7e6545539d2f7736be930d4833deb32b1b95
Author: Helge Deller <deller@gmx.de>
Date:   Wed Jan 3 19:25:37 2007 +0100

    [PARISC] disable cr16 clocksource when multiple CPUs are online
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index e47e27cea42e..c33b6e0f7c47 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -99,7 +99,7 @@ irqreturn_t timer_interrupt(int irq, void *dev_id)
 	 * cycles after the IT fires. But it's arbitrary how much time passes
 	 * before we call it "late". I've picked one second.
 	 */
-	if (ticks_elapsed > HZ) {
+	if (unlikely(ticks_elapsed > HZ)) {
 		/* Scenario 3: very long delay?  bad in any case */
 		printk (KERN_CRIT "timer_interrupt(CPU %d): delayed!"
 			" cycles %lX rem %lX "
@@ -180,6 +180,8 @@ static cycle_t read_cr16(void)
 	return get_cycles();
 }
 
+static int cr16_update_callback(void);
+
 static struct clocksource clocksource_cr16 = {
 	.name			= "cr16",
 	.rating			= 300,
@@ -187,9 +189,25 @@ static struct clocksource clocksource_cr16 = {
 	.mask			= CLOCKSOURCE_MASK(BITS_PER_LONG),
 	.mult			= 0, /* to be set */
 	.shift			= 22,
+	.update_callback	= cr16_update_callback,
 	.is_continuous		= 1,
 };
 
+static int cr16_update_callback(void)
+{
+	int change = 0;
+
+	/* since the cr16 cycle counters are not syncronized across CPUs,
+	   we'll check if we should switch to a safe clocksource: */
+	if (clocksource_cr16.rating != 0 && num_online_cpus() > 1) {
+		clocksource_cr16.rating = 0;
+		clocksource_reselect();
+		change = 1;
+	}
+
+	return change;
+}
+
 
 /*
  * XXX: We can do better than this.
@@ -225,10 +243,6 @@ void __init time_init(void)
 	current_cr16_khz = PAGE0->mem_10msec/10;  /* kHz */
 	clocksource_cr16.mult = clocksource_khz2mult(current_cr16_khz,
 						clocksource_cr16.shift);
-	/* lower the rating if we already know its unstable: */
-	if (num_online_cpus()>1)
-		clocksource_cr16.rating = 200;
-
 	clocksource_register(&clocksource_cr16);
 
 	if (pdc_tod_read(&tod_data) == 0) {

commit 12df29b64c782133afea8cacc6acdad68a6b7d17
Author: Helge Deller <deller@gmx.de>
Date:   Tue Jan 2 23:54:16 2007 +0100

    [PARISC] GENERIC_TIME patchset for parisc
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index bad7d1eb62b9..e47e27cea42e 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -22,6 +22,7 @@
 #include <linux/init.h>
 #include <linux/smp.h>
 #include <linux/profile.h>
+#include <linux/clocksource.h>
 
 #include <asm/uaccess.h>
 #include <asm/io.h>
@@ -172,121 +173,23 @@ unsigned long profile_pc(struct pt_regs *regs)
 EXPORT_SYMBOL(profile_pc);
 
 
-/*
- * Return the number of micro-seconds that elapsed since the last
- * update to wall time (aka xtime).  The xtime_lock
- * must be at least read-locked when calling this routine.
- */
-static inline unsigned long gettimeoffset (void)
-{
-#ifndef CONFIG_SMP
-	/*
-	 * FIXME: This won't work on smp because jiffies are updated by cpu 0.
-	 *    Once parisc-linux learns the cr16 difference between processors,
-	 *    this could be made to work.
-	 */
-	unsigned long now;
-	unsigned long prev_tick;
-	unsigned long next_tick;
-	unsigned long elapsed_cycles;
-	unsigned long usec;
-	unsigned long cpuid = smp_processor_id();
-	unsigned long cpt = clocktick;
+/* clock source code */
 
-	next_tick = cpu_data[cpuid].it_value;
-	now = mfctl(16);	/* Read the hardware interval timer.  */
-
-	prev_tick = next_tick - cpt;
-
-	/* Assume Scenario 1: "now" is later than prev_tick.  */
-	elapsed_cycles = now - prev_tick;
-
-/* aproximate HZ with shifts. Intended math is "(elapsed/clocktick) > HZ" */
-#if HZ == 1000
-	if (elapsed_cycles > (cpt << 10) )
-#elif HZ == 250
-	if (elapsed_cycles > (cpt << 8) )
-#elif HZ == 100
-	if (elapsed_cycles > (cpt << 7) )
-#else
-#warn WTF is HZ set to anyway?
-	if (elapsed_cycles > (HZ * cpt) )
-#endif
-	{
-		/* Scenario 3: clock ticks are missing. */
-		printk (KERN_CRIT "gettimeoffset(CPU %ld): missing %ld ticks!"
-			" cycles %lX prev/now/next %lX/%lX/%lX  clock %lX\n",
-			cpuid, elapsed_cycles / cpt,
-			elapsed_cycles, prev_tick, now, next_tick, cpt);
-	}
-
-	/* FIXME: Can we improve the precision? Not with PAGE0. */
-	usec = (elapsed_cycles * 10000) / PAGE0->mem_10msec;
-	return usec;
-#else
-	return 0;
-#endif
-}
-
-void
-do_gettimeofday (struct timeval *tv)
+static cycle_t read_cr16(void)
 {
-	unsigned long flags, seq, usec, sec;
-
-	/* Hold xtime_lock and adjust timeval.  */
-	do {
-		seq = read_seqbegin_irqsave(&xtime_lock, flags);
-		usec = gettimeoffset();
-		sec = xtime.tv_sec;
-		usec += (xtime.tv_nsec / 1000);
-	} while (read_seqretry_irqrestore(&xtime_lock, seq, flags));
-
-	/* Move adjusted usec's into sec's.  */
-	while (usec >= USEC_PER_SEC) {
-		usec -= USEC_PER_SEC;
-		++sec;
-	}
-
-	/* Return adjusted result.  */
-	tv->tv_sec = sec;
-	tv->tv_usec = usec;
+	return get_cycles();
 }
 
-EXPORT_SYMBOL(do_gettimeofday);
-
-int
-do_settimeofday (struct timespec *tv)
-{
-	time_t wtm_sec, sec = tv->tv_sec;
-	long wtm_nsec, nsec = tv->tv_nsec;
-
-	if ((unsigned long)tv->tv_nsec >= NSEC_PER_SEC)
-		return -EINVAL;
-
-	write_seqlock_irq(&xtime_lock);
-	{
-		/*
-		 * This is revolting. We need to set "xtime"
-		 * correctly. However, the value in this location is
-		 * the value at the most recent update of wall time.
-		 * Discover what correction gettimeofday would have
-		 * done, and then undo it!
-		 */
-		nsec -= gettimeoffset() * 1000;
+static struct clocksource clocksource_cr16 = {
+	.name			= "cr16",
+	.rating			= 300,
+	.read			= read_cr16,
+	.mask			= CLOCKSOURCE_MASK(BITS_PER_LONG),
+	.mult			= 0, /* to be set */
+	.shift			= 22,
+	.is_continuous		= 1,
+};
 
-		wtm_sec  = wall_to_monotonic.tv_sec + (xtime.tv_sec - sec);
-		wtm_nsec = wall_to_monotonic.tv_nsec + (xtime.tv_nsec - nsec);
-
-		set_normalized_timespec(&xtime, sec, nsec);
-		set_normalized_timespec(&wall_to_monotonic, wtm_sec, wtm_nsec);
-
-		ntp_clear();
-	}
-	write_sequnlock_irq(&xtime_lock);
-	clock_was_set();
-	return 0;
-}
-EXPORT_SYMBOL(do_settimeofday);
 
 /*
  * XXX: We can do better than this.
@@ -312,11 +215,22 @@ void __init start_cpu_itimer(void)
 void __init time_init(void)
 {
 	static struct pdc_tod tod_data;
+	unsigned long current_cr16_khz;
 
 	clocktick = (100 * PAGE0->mem_10msec) / HZ;
 
 	start_cpu_itimer();	/* get CPU 0 started */
 
+	/* register at clocksource framework */
+	current_cr16_khz = PAGE0->mem_10msec/10;  /* kHz */
+	clocksource_cr16.mult = clocksource_khz2mult(current_cr16_khz,
+						clocksource_cr16.shift);
+	/* lower the rating if we already know its unstable: */
+	if (num_online_cpus()>1)
+		clocksource_cr16.rating = 200;
+
+	clocksource_register(&clocksource_cr16);
+
 	if (pdc_tod_read(&tod_data) == 0) {
 		unsigned long flags;
 

commit b035b6de24932ffd4a2b1c6619a2f5711da6920f
Author: Alexey Dobriyan <adobriyan@openvz.org>
Date:   Sat Feb 10 01:45:10 2007 -0800

    [PATCH] Consolidate default sched_clock()
    
    Use attribute(weak).
    
    Signed-off-by: Alexey Dobriyan <adobriyan@openvz.org>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index bad7d1eb62b9..5f1b51af06a9 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -288,17 +288,6 @@ do_settimeofday (struct timespec *tv)
 }
 EXPORT_SYMBOL(do_settimeofday);
 
-/*
- * XXX: We can do better than this.
- * Returns nanoseconds
- */
-
-unsigned long long sched_clock(void)
-{
-	return (unsigned long long)jiffies * (1000000000 / HZ);
-}
-
-
 void __init start_cpu_itimer(void)
 {
 	unsigned int cpu = smp_processor_id();

commit c7753f18711782738936f224aaa421468e87f6ed
Author: Matthew Wilcox <matthew@wil.cx>
Date:   Sat Oct 7 06:01:11 2006 -0600

    [PARISC] More pt_regs removal
    
    Remove pt_regs from ipi_interrupt and timer_interrupt.
    Inline smp_do_timer() into its only caller, and unify the SMP and
    non-SMP paths.  Fixes a profiling bug.
    
    Signed-off-by: Matthew Wilcox <matthew@wil.cx>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 8c9b8a7ef244..bad7d1eb62b9 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -34,10 +34,6 @@
 
 static unsigned long clocktick __read_mostly;	/* timer cycles per tick */
 
-#ifdef CONFIG_SMP
-extern void smp_do_timer(struct pt_regs *regs);
-#endif
-
 /*
  * We keep time on PA-RISC Linux by using the Interval Timer which is
  * a pair of registers; one is read-only and one is write-only; both
@@ -55,13 +51,14 @@ extern void smp_do_timer(struct pt_regs *regs);
  * held off for an arbitrarily long period of time by interrupts being
  * disabled, so we may miss one or more ticks.
  */
-irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
+irqreturn_t timer_interrupt(int irq, void *dev_id)
 {
 	unsigned long now;
 	unsigned long next_tick;
 	unsigned long cycles_elapsed, ticks_elapsed;
 	unsigned long cycles_remainder;
 	unsigned int cpu = smp_processor_id();
+	struct cpuinfo_parisc *cpuinfo = &cpu_data[cpu];
 
 	/* gcc can optimize for "read-only" case with a local clocktick */
 	unsigned long cpt = clocktick;
@@ -69,7 +66,7 @@ irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 	profile_tick(CPU_PROFILING);
 
 	/* Initialize next_tick to the expected tick time. */
-	next_tick = cpu_data[cpu].it_value;
+	next_tick = cpuinfo->it_value;
 
 	/* Get current interval timer.
 	 * CR16 reads as 64 bits in CPU wide mode.
@@ -120,7 +117,7 @@ irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 	 */
 	next_tick = now + cycles_remainder;
 
-	cpu_data[cpu].it_value = next_tick;
+	cpuinfo->it_value = next_tick;
 
 	/* Skip one clocktick on purpose if we are likely to miss next_tick.
 	 * We want to avoid the new next_tick being less than CR16.
@@ -131,18 +128,19 @@ irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 		next_tick += cpt;
 
 	/* Program the IT when to deliver the next interrupt. */
-        /* Only bottom 32-bits of next_tick are written to cr16.  */
+	/* Only bottom 32-bits of next_tick are written to cr16.  */
 	mtctl(next_tick, 16);
 
 
 	/* Done mucking with unreliable delivery of interrupts.
 	 * Go do system house keeping.
 	 */
-#ifdef CONFIG_SMP
-	smp_do_timer(regs);
-#else
-	update_process_times(user_mode(regs));
-#endif
+
+	if (!--cpuinfo->prof_counter) {
+		cpuinfo->prof_counter = cpuinfo->prof_multiplier;
+		update_process_times(user_mode(get_irq_regs()));
+	}
+
 	if (cpu == 0) {
 		write_seqlock(&xtime_lock);
 		do_timer(ticks_elapsed);

commit 09690b18b7b9696bb719b246e77c7af9952da12c
Author: Kyle McMartin <kyle@mako.i.cabal.ca>
Date:   Thu Oct 5 23:45:45 2006 -0400

    [PARISC] Make firmware calls irqsafe-ish...
    
    There's no reason why we shouldn't be using _irqsave instead of
    _irq for any of these calls. fwiw, this fixes the
    "start_kernel(): bug: interrupts were enabled early" message displayed
    on bootup recently.
    
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>
    Signed-off-by: Matthew Wilcox <matthew@wil.cx>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index b44839203e69..8c9b8a7ef244 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -319,13 +319,15 @@ void __init time_init(void)
 
 	start_cpu_itimer();	/* get CPU 0 started */
 
-	if(pdc_tod_read(&tod_data) == 0) {
-		write_seqlock_irq(&xtime_lock);
+	if (pdc_tod_read(&tod_data) == 0) {
+		unsigned long flags;
+
+		write_seqlock_irqsave(&xtime_lock, flags);
 		xtime.tv_sec = tod_data.tod_sec;
 		xtime.tv_nsec = tod_data.tod_usec * 1000;
 		set_normalized_timespec(&wall_to_monotonic,
 		                        -xtime.tv_sec, -xtime.tv_nsec);
-		write_sequnlock_irq(&xtime_lock);
+		write_sequnlock_irqrestore(&xtime_lock, flags);
 	} else {
 		printk(KERN_ERR "Error reading tod clock\n");
 	        xtime.tv_sec = 0;

commit be577a5220b25e0a6e3fbf96bbfc8b31d63e9ea9
Author: Matthew Wilcox <matthew@wil.cx>
Date:   Fri Oct 6 20:47:23 2006 -0600

    Build fixes for struct pt_regs removal
    
    Signed-off-by: Matthew Wilcox <matthew@wil.cx>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 1d58ce0e37ad..b44839203e69 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -66,7 +66,7 @@ irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 	/* gcc can optimize for "read-only" case with a local clocktick */
 	unsigned long cpt = clocktick;
 
-	profile_tick(CPU_PROFILING, regs);
+	profile_tick(CPU_PROFILING);
 
 	/* Initialize next_tick to the expected tick time. */
 	next_tick = cpu_data[cpu].it_value;

commit 1604f31895dcdb42edf6511ce7ef0546ff92c8e5
Author: Matthew Wilcox <matthew@wil.cx>
Date:   Wed Oct 4 15:12:52 2006 -0600

    [PA-RISC] Fix time.c for new do_timer() calling convention
    
    do_timer now wants to know how many ticks have elapsed.  Now that we
    have to calculate that, we can eliminate some of the clever code that
    avoided having to calculate that.  Also add some more documentation.
    I'd like to thank Grant Grundler for helping me with this.
    
    Signed-off-by: Matthew Wilcox <willy@parisc-linux.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index b3496b592a2d..1d58ce0e37ad 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -38,11 +38,28 @@ static unsigned long clocktick __read_mostly;	/* timer cycles per tick */
 extern void smp_do_timer(struct pt_regs *regs);
 #endif
 
+/*
+ * We keep time on PA-RISC Linux by using the Interval Timer which is
+ * a pair of registers; one is read-only and one is write-only; both
+ * accessed through CR16.  The read-only register is 32 or 64 bits wide,
+ * and increments by 1 every CPU clock tick.  The architecture only
+ * guarantees us a rate between 0.5 and 2, but all implementations use a
+ * rate of 1.  The write-only register is 32-bits wide.  When the lowest
+ * 32 bits of the read-only register compare equal to the write-only
+ * register, it raises a maskable external interrupt.  Each processor has
+ * an Interval Timer of its own and they are not synchronised.  
+ *
+ * We want to generate an interrupt every 1/HZ seconds.  So we program
+ * CR16 to interrupt every @clocktick cycles.  The it_value in cpu_data
+ * is programmed with the intended time of the next tick.  We can be
+ * held off for an arbitrarily long period of time by interrupts being
+ * disabled, so we may miss one or more ticks.
+ */
 irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 {
 	unsigned long now;
 	unsigned long next_tick;
-	unsigned long cycles_elapsed;
+	unsigned long cycles_elapsed, ticks_elapsed;
 	unsigned long cycles_remainder;
 	unsigned int cpu = smp_processor_id();
 
@@ -67,11 +84,14 @@ irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 		 * of the more expensive div/mul method
 		 */
 		cycles_remainder = cycles_elapsed;
+		ticks_elapsed = 1;
 		while (cycles_remainder > cpt) {
 			cycles_remainder -= cpt;
+			ticks_elapsed++;
 		}
 	} else {
 		cycles_remainder = cycles_elapsed % cpt;
+		ticks_elapsed = 1 + cycles_elapsed / cpt;
 	}
 
 	/* Can we differentiate between "early CR16" (aka Scenario 1) and
@@ -81,18 +101,7 @@ irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 	 * cycles after the IT fires. But it's arbitrary how much time passes
 	 * before we call it "late". I've picked one second.
 	 */
-/* aproximate HZ with shifts. Intended math is "(elapsed/clocktick) > HZ" */
-#if HZ == 1000
-	if (cycles_elapsed > (cpt << 10) )
-#elif HZ == 250
-	if (cycles_elapsed > (cpt << 8) )
-#elif HZ == 100
-	if (cycles_elapsed > (cpt << 7) )
-#else
-#warn WTF is HZ set to anyway?
-	if (cycles_elapsed > (HZ * cpt) )
-#endif
-	{
+	if (ticks_elapsed > HZ) {
 		/* Scenario 3: very long delay?  bad in any case */
 		printk (KERN_CRIT "timer_interrupt(CPU %d): delayed!"
 			" cycles %lX rem %lX "
@@ -136,7 +145,7 @@ irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 #endif
 	if (cpu == 0) {
 		write_seqlock(&xtime_lock);
-		do_timer(regs);
+		do_timer(ticks_elapsed);
 		write_sequnlock(&xtime_lock);
 	}
 

commit 5f024a251f0b3b179bbc8fc62f3a650e49359db5
Author: Andrew Morton <akpm@osdl.org>
Date:   Sun Oct 1 16:17:13 2006 -0400

    [PARISC] Kill wall_jiffies use
    
    wall_jiffies and jiffies are now equal, so this is a noop...
    
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 9d642d820fe9..b3496b592a2d 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -215,9 +215,6 @@ static inline unsigned long gettimeoffset (void)
 
 	/* FIXME: Can we improve the precision? Not with PAGE0. */
 	usec = (elapsed_cycles * 10000) / PAGE0->mem_10msec;
-
-	/* add in "lost" jiffies */
-	usec += cpt * (jiffies - wall_jiffies);
 	return usec;
 #else
 	return 0;

commit 6e5dc42b5add25c94ce0e95da87122f91b4bfdb3
Author: Grant Grundler <grundler@gsyprf11.external.hp.com>
Date:   Sun Sep 10 12:57:55 2006 -0700

    [PARISC] Further updates to timer_interrupt()
    
    This version (relative to the current tree):
    o eliminates "while (ticks_elapsed)" loop. It's not needed.
    o drop "ticks_elapsed" completely from timer_interrupt().
    o Estimates elapsed cycles (based on HZ) to see which kind of
      math we want to use to calculate "cycles_remainder".
    o Fixes a bug where we would loose a tick if we decided
      we wanted to skip one interrupt.
    
    Signed-off-by: Grant Grundler <grundler@parisc-linux.org>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index c43e847a4b8f..9d642d820fe9 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -43,12 +43,11 @@ irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 	unsigned long now;
 	unsigned long next_tick;
 	unsigned long cycles_elapsed;
-        unsigned long cycles_remainder;
-	unsigned long ticks_elapsed = 1;	/* at least one elapsed */
-	int cpu = smp_processor_id();
+	unsigned long cycles_remainder;
+	unsigned int cpu = smp_processor_id();
 
 	/* gcc can optimize for "read-only" case with a local clocktick */
-	unsigned long local_ct = clocktick;
+	unsigned long cpt = clocktick;
 
 	profile_tick(CPU_PROFILING, regs);
 
@@ -63,28 +62,16 @@ irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 
 	cycles_elapsed = now - next_tick;
 
-	/* Determine how much time elapsed.  */
-	if (now < next_tick) {
-		/* Scenario 2: CR16 wrapped after clock tick.
-		 * 1's complement will give us the "elapse cycles".
-		 *
-		 * This "cr16 wrapped" cruft is primarily for 32-bit kernels.
-		 * So think "unsigned long is u32" when reading the code.
-		 * And yes, of course 64-bit will someday wrap, but only
-	  	 * every 198841 days on a 1GHz machine.
+	if ((cycles_elapsed >> 5) < cpt) {
+		/* use "cheap" math (add/subtract) instead
+		 * of the more expensive div/mul method
 		 */
-		cycles_elapsed = ~cycles_elapsed;   /* off by one cycle - don't care */
-	}
-
-	if (likely(cycles_elapsed < local_ct)) {
-		/* ticks_elapsed = 1 -- We already assumed one tick elapsed. */
 		cycles_remainder = cycles_elapsed;
+		while (cycles_remainder > cpt) {
+			cycles_remainder -= cpt;
+		}
 	} else {
-		/* more than one tick elapsed. Do "expensive" math. */
-		ticks_elapsed += cycles_elapsed / local_ct;
-
-		/* Faster version of "remainder = elapsed % clocktick" */
-		cycles_remainder = cycles_elapsed - (ticks_elapsed * local_ct);
+		cycles_remainder = cycles_elapsed % cpt;
 	}
 
 	/* Can we differentiate between "early CR16" (aka Scenario 1) and
@@ -94,51 +81,65 @@ irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 	 * cycles after the IT fires. But it's arbitrary how much time passes
 	 * before we call it "late". I've picked one second.
 	 */
-	if (ticks_elapsed > HZ) {
+/* aproximate HZ with shifts. Intended math is "(elapsed/clocktick) > HZ" */
+#if HZ == 1000
+	if (cycles_elapsed > (cpt << 10) )
+#elif HZ == 250
+	if (cycles_elapsed > (cpt << 8) )
+#elif HZ == 100
+	if (cycles_elapsed > (cpt << 7) )
+#else
+#warn WTF is HZ set to anyway?
+	if (cycles_elapsed > (HZ * cpt) )
+#endif
+	{
 		/* Scenario 3: very long delay?  bad in any case */
 		printk (KERN_CRIT "timer_interrupt(CPU %d): delayed!"
-			" ticks %ld cycles %lX rem %lX"
+			" cycles %lX rem %lX "
 			" next/now %lX/%lX\n",
 			cpu,
-			ticks_elapsed, cycles_elapsed, cycles_remainder,
+			cycles_elapsed, cycles_remainder,
 			next_tick, now );
 	}
 
+	/* convert from "division remainder" to "remainder of clock tick" */
+	cycles_remainder = cpt - cycles_remainder;
 
 	/* Determine when (in CR16 cycles) next IT interrupt will fire.
 	 * We want IT to fire modulo clocktick even if we miss/skip some.
 	 * But those interrupts don't in fact get delivered that regularly.
 	 */
-	next_tick = now + (local_ct - cycles_remainder);
+	next_tick = now + cycles_remainder;
+
+	cpu_data[cpu].it_value = next_tick;
 
 	/* Skip one clocktick on purpose if we are likely to miss next_tick.
-	 * We'll catch what we missed on the tick after that.
-	 * We should never need 0x1000 cycles to read CR16, calc the
-	 * new next_tick, then write CR16 back. */
-	if (!((local_ct - cycles_remainder) >> 12))
-		next_tick += local_ct;
+	 * We want to avoid the new next_tick being less than CR16.
+	 * If that happened, itimer wouldn't fire until CR16 wrapped.
+	 * We'll catch the tick we missed on the tick after that.
+	 */
+	if (!(cycles_remainder >> 13))
+		next_tick += cpt;
 
 	/* Program the IT when to deliver the next interrupt. */
         /* Only bottom 32-bits of next_tick are written to cr16.  */
-	cpu_data[cpu].it_value = next_tick;
 	mtctl(next_tick, 16);
 
-	/* Now that we are done mucking with unreliable delivery of interrupts,
-	 * go do system house keeping.
+
+	/* Done mucking with unreliable delivery of interrupts.
+	 * Go do system house keeping.
 	 */
-	while (ticks_elapsed--) {
 #ifdef CONFIG_SMP
-		smp_do_timer(regs);
+	smp_do_timer(regs);
 #else
-		update_process_times(user_mode(regs));
+	update_process_times(user_mode(regs));
 #endif
-		if (cpu == 0) {
-			write_seqlock(&xtime_lock);
-			do_timer(1);
-			write_sequnlock(&xtime_lock);
-		}
+	if (cpu == 0) {
+		write_seqlock(&xtime_lock);
+		do_timer(regs);
+		write_sequnlock(&xtime_lock);
 	}
-    
+
 	/* check soft power switch status */
 	if (cpu == 0 && !atomic_read(&power_tasklet.count))
 		tasklet_schedule(&power_tasklet);
@@ -164,14 +165,12 @@ unsigned long profile_pc(struct pt_regs *regs)
 EXPORT_SYMBOL(profile_pc);
 
 
-/*** converted from ia64 ***/
 /*
  * Return the number of micro-seconds that elapsed since the last
  * update to wall time (aka xtime).  The xtime_lock
  * must be at least read-locked when calling this routine.
  */
-static inline unsigned long
-gettimeoffset (void)
+static inline unsigned long gettimeoffset (void)
 {
 #ifndef CONFIG_SMP
 	/*
@@ -185,36 +184,40 @@ gettimeoffset (void)
 	unsigned long elapsed_cycles;
 	unsigned long usec;
 	unsigned long cpuid = smp_processor_id();
-	unsigned long local_ct = clocktick;
+	unsigned long cpt = clocktick;
 
 	next_tick = cpu_data[cpuid].it_value;
 	now = mfctl(16);	/* Read the hardware interval timer.  */
 
-	prev_tick = next_tick - local_ct;
+	prev_tick = next_tick - cpt;
 
 	/* Assume Scenario 1: "now" is later than prev_tick.  */
 	elapsed_cycles = now - prev_tick;
 
-	if (now < prev_tick) {
-		/* Scenario 2: CR16 wrapped!
-		 * ones complement is off-by-one. Don't care.
-		 */
-		elapsed_cycles = ~elapsed_cycles;
-	}
-
-	if (elapsed_cycles > (HZ * local_ct)) {
+/* aproximate HZ with shifts. Intended math is "(elapsed/clocktick) > HZ" */
+#if HZ == 1000
+	if (elapsed_cycles > (cpt << 10) )
+#elif HZ == 250
+	if (elapsed_cycles > (cpt << 8) )
+#elif HZ == 100
+	if (elapsed_cycles > (cpt << 7) )
+#else
+#warn WTF is HZ set to anyway?
+	if (elapsed_cycles > (HZ * cpt) )
+#endif
+	{
 		/* Scenario 3: clock ticks are missing. */
-		printk (KERN_CRIT "gettimeoffset(CPU %d): missing ticks!"
-			"cycles %lX prev/now/next %lX/%lX/%lX  clock %lX\n",
-			cpuid,
-			 elapsed_cycles, prev_tick, now, next_tick, local_ct);
+		printk (KERN_CRIT "gettimeoffset(CPU %ld): missing %ld ticks!"
+			" cycles %lX prev/now/next %lX/%lX/%lX  clock %lX\n",
+			cpuid, elapsed_cycles / cpt,
+			elapsed_cycles, prev_tick, now, next_tick, cpt);
 	}
 
 	/* FIXME: Can we improve the precision? Not with PAGE0. */
 	usec = (elapsed_cycles * 10000) / PAGE0->mem_10msec;
 
 	/* add in "lost" jiffies */
-	usec += local_ct * (jiffies - wall_jiffies);
+	usec += cpt * (jiffies - wall_jiffies);
 	return usec;
 #else
 	return 0;

commit 6b799d9222fef265802b0b6dcc4fb982cc8f55ca
Author: Grant Grundler <grundler@gsyprf11.external.hp.com>
Date:   Mon Sep 4 13:56:11 2006 -0700

    [PARISC] remove halftick and copy clocktick to local var (gcc can optimize usage)
    
    Signed-off-by: Grant Grundler <grundler@parisc-linux.org>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index fd425e1abe66..c43e847a4b8f 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -33,7 +33,6 @@
 #include <linux/timex.h>
 
 static unsigned long clocktick __read_mostly;	/* timer cycles per tick */
-static unsigned long halftick __read_mostly;
 
 #ifdef CONFIG_SMP
 extern void smp_do_timer(struct pt_regs *regs);
@@ -48,6 +47,9 @@ irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 	unsigned long ticks_elapsed = 1;	/* at least one elapsed */
 	int cpu = smp_processor_id();
 
+	/* gcc can optimize for "read-only" case with a local clocktick */
+	unsigned long local_ct = clocktick;
+
 	profile_tick(CPU_PROFILING, regs);
 
 	/* Initialize next_tick to the expected tick time. */
@@ -74,8 +76,16 @@ irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 		cycles_elapsed = ~cycles_elapsed;   /* off by one cycle - don't care */
 	}
 
-	ticks_elapsed += cycles_elapsed / clocktick;
-	cycles_remainder = cycles_elapsed % clocktick;
+	if (likely(cycles_elapsed < local_ct)) {
+		/* ticks_elapsed = 1 -- We already assumed one tick elapsed. */
+		cycles_remainder = cycles_elapsed;
+	} else {
+		/* more than one tick elapsed. Do "expensive" math. */
+		ticks_elapsed += cycles_elapsed / local_ct;
+
+		/* Faster version of "remainder = elapsed % clocktick" */
+		cycles_remainder = cycles_elapsed - (ticks_elapsed * local_ct);
+	}
 
 	/* Can we differentiate between "early CR16" (aka Scenario 1) and
 	 * "long delay" (aka Scenario 3)? I don't think so.
@@ -86,14 +96,12 @@ irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 	 */
 	if (ticks_elapsed > HZ) {
 		/* Scenario 3: very long delay?  bad in any case */
-		printk (KERN_CRIT "timer_interrupt(CPU %d): delayed! run ntpdate"
+		printk (KERN_CRIT "timer_interrupt(CPU %d): delayed!"
 			" ticks %ld cycles %lX rem %lX"
 			" next/now %lX/%lX\n",
 			cpu,
 			ticks_elapsed, cycles_elapsed, cycles_remainder,
 			next_tick, now );
-
-		ticks_elapsed = 1;	/* hack to limit damage in loop below */
 	}
 
 
@@ -101,12 +109,19 @@ irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 	 * We want IT to fire modulo clocktick even if we miss/skip some.
 	 * But those interrupts don't in fact get delivered that regularly.
 	 */
-	next_tick = now + (clocktick - cycles_remainder);
+	next_tick = now + (local_ct - cycles_remainder);
+
+	/* Skip one clocktick on purpose if we are likely to miss next_tick.
+	 * We'll catch what we missed on the tick after that.
+	 * We should never need 0x1000 cycles to read CR16, calc the
+	 * new next_tick, then write CR16 back. */
+	if (!((local_ct - cycles_remainder) >> 12))
+		next_tick += local_ct;
 
 	/* Program the IT when to deliver the next interrupt. */
         /* Only bottom 32-bits of next_tick are written to cr16.  */
-	mtctl(next_tick, 16);
 	cpu_data[cpu].it_value = next_tick;
+	mtctl(next_tick, 16);
 
 	/* Now that we are done mucking with unreliable delivery of interrupts,
 	 * go do system house keeping.
@@ -169,35 +184,37 @@ gettimeoffset (void)
 	unsigned long next_tick;
 	unsigned long elapsed_cycles;
 	unsigned long usec;
+	unsigned long cpuid = smp_processor_id();
+	unsigned long local_ct = clocktick;
 
-	next_tick = cpu_data[smp_processor_id()].it_value;
+	next_tick = cpu_data[cpuid].it_value;
 	now = mfctl(16);	/* Read the hardware interval timer.  */
 
-	prev_tick = next_tick - clocktick;
+	prev_tick = next_tick - local_ct;
 
 	/* Assume Scenario 1: "now" is later than prev_tick.  */
 	elapsed_cycles = now - prev_tick;
 
 	if (now < prev_tick) {
 		/* Scenario 2: CR16 wrapped!
-		 * 1's complement is close enough.
+		 * ones complement is off-by-one. Don't care.
 		 */
 		elapsed_cycles = ~elapsed_cycles;
 	}
 
-	if (elapsed_cycles > (HZ * clocktick)) {
+	if (elapsed_cycles > (HZ * local_ct)) {
 		/* Scenario 3: clock ticks are missing. */
 		printk (KERN_CRIT "gettimeoffset(CPU %d): missing ticks!"
 			"cycles %lX prev/now/next %lX/%lX/%lX  clock %lX\n",
 			cpuid,
-			elapsed_cycles, prev_tick, now, next_tick, clocktick);
+			 elapsed_cycles, prev_tick, now, next_tick, local_ct);
 	}
 
 	/* FIXME: Can we improve the precision? Not with PAGE0. */
 	usec = (elapsed_cycles * 10000) / PAGE0->mem_10msec;
 
 	/* add in "lost" jiffies */
-	usec += clocktick * (jiffies - wall_jiffies);
+	usec += local_ct * (jiffies - wall_jiffies);
 	return usec;
 #else
 	return 0;
@@ -290,7 +307,6 @@ void __init time_init(void)
 	static struct pdc_tod tod_data;
 
 	clocktick = (100 * PAGE0->mem_10msec) / HZ;
-	halftick = clocktick / 2;
 
 	start_cpu_itimer();	/* get CPU 0 started */
 

commit bed583f76e1d5fbb5a6fdf27a0f7b2ae235f7e99
Author: Grant Grundler <grundler@gsyprf11.external.hp.com>
Date:   Fri Sep 8 23:29:22 2006 -0700

    [PARISC] Rewrite timer_interrupt() and gettimeoffset() using "unsigned" math.
    
    It's just a bit easier to follow and timer code is complex enough.
    
    So far, only tested on A500-5x (64-bit SMP), ie: gettimeoffset() code
    hasn't been tested at all.
    
    Signed-off-by: Grant Grundler <grundler@parisc-linux.org>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 47831c2cd093..fd425e1abe66 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -32,8 +32,8 @@
 
 #include <linux/timex.h>
 
-static long clocktick __read_mostly;	/* timer cycles per tick */
-static long halftick __read_mostly;
+static unsigned long clocktick __read_mostly;	/* timer cycles per tick */
+static unsigned long halftick __read_mostly;
 
 #ifdef CONFIG_SMP
 extern void smp_do_timer(struct pt_regs *regs);
@@ -41,34 +41,77 @@ extern void smp_do_timer(struct pt_regs *regs);
 
 irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 {
-	long now;
-	long next_tick;
-	int nticks;
+	unsigned long now;
+	unsigned long next_tick;
+	unsigned long cycles_elapsed;
+        unsigned long cycles_remainder;
+	unsigned long ticks_elapsed = 1;	/* at least one elapsed */
 	int cpu = smp_processor_id();
 
 	profile_tick(CPU_PROFILING, regs);
 
-	now = mfctl(16);
-	/* initialize next_tick to time at last clocktick */
+	/* Initialize next_tick to the expected tick time. */
 	next_tick = cpu_data[cpu].it_value;
 
-	/* since time passes between the interrupt and the mfctl()
-	 * above, it is never true that last_tick + clocktick == now.  If we
-	 * never miss a clocktick, we could set next_tick = last_tick + clocktick
-	 * but maybe we'll miss ticks, hence the loop.
-	 *
-	 * Variables are *signed*.
+	/* Get current interval timer.
+	 * CR16 reads as 64 bits in CPU wide mode.
+	 * CR16 reads as 32 bits in CPU narrow mode.
 	 */
+	now = mfctl(16);
 
-	nticks = 0;
-	while((next_tick - now) < halftick) {
-		next_tick += clocktick;
-		nticks++;
+	cycles_elapsed = now - next_tick;
+
+	/* Determine how much time elapsed.  */
+	if (now < next_tick) {
+		/* Scenario 2: CR16 wrapped after clock tick.
+		 * 1's complement will give us the "elapse cycles".
+		 *
+		 * This "cr16 wrapped" cruft is primarily for 32-bit kernels.
+		 * So think "unsigned long is u32" when reading the code.
+		 * And yes, of course 64-bit will someday wrap, but only
+	  	 * every 198841 days on a 1GHz machine.
+		 */
+		cycles_elapsed = ~cycles_elapsed;   /* off by one cycle - don't care */
 	}
+
+	ticks_elapsed += cycles_elapsed / clocktick;
+	cycles_remainder = cycles_elapsed % clocktick;
+
+	/* Can we differentiate between "early CR16" (aka Scenario 1) and
+	 * "long delay" (aka Scenario 3)? I don't think so.
+	 *
+	 * We expected timer_interrupt to be delivered at least a few hundred
+	 * cycles after the IT fires. But it's arbitrary how much time passes
+	 * before we call it "late". I've picked one second.
+	 */
+	if (ticks_elapsed > HZ) {
+		/* Scenario 3: very long delay?  bad in any case */
+		printk (KERN_CRIT "timer_interrupt(CPU %d): delayed! run ntpdate"
+			" ticks %ld cycles %lX rem %lX"
+			" next/now %lX/%lX\n",
+			cpu,
+			ticks_elapsed, cycles_elapsed, cycles_remainder,
+			next_tick, now );
+
+		ticks_elapsed = 1;	/* hack to limit damage in loop below */
+	}
+
+
+	/* Determine when (in CR16 cycles) next IT interrupt will fire.
+	 * We want IT to fire modulo clocktick even if we miss/skip some.
+	 * But those interrupts don't in fact get delivered that regularly.
+	 */
+	next_tick = now + (clocktick - cycles_remainder);
+
+	/* Program the IT when to deliver the next interrupt. */
+        /* Only bottom 32-bits of next_tick are written to cr16.  */
 	mtctl(next_tick, 16);
 	cpu_data[cpu].it_value = next_tick;
 
-	while (nticks--) {
+	/* Now that we are done mucking with unreliable delivery of interrupts,
+	 * go do system house keeping.
+	 */
+	while (ticks_elapsed--) {
 #ifdef CONFIG_SMP
 		smp_do_timer(regs);
 #else
@@ -121,21 +164,41 @@ gettimeoffset (void)
 	 *    Once parisc-linux learns the cr16 difference between processors,
 	 *    this could be made to work.
 	 */
-	long last_tick;
-	long elapsed_cycles;
+	unsigned long now;
+	unsigned long prev_tick;
+	unsigned long next_tick;
+	unsigned long elapsed_cycles;
+	unsigned long usec;
 
-	/* it_value is the intended time of the next tick */
-	last_tick = cpu_data[smp_processor_id()].it_value;
+	next_tick = cpu_data[smp_processor_id()].it_value;
+	now = mfctl(16);	/* Read the hardware interval timer.  */
 
-	/* Subtract one tick and account for possible difference between
-	 * when we expected the tick and when it actually arrived.
-	 * (aka wall vs real)
-	 */
-	last_tick -= clocktick * (jiffies - wall_jiffies + 1);
-	elapsed_cycles = mfctl(16) - last_tick;
+	prev_tick = next_tick - clocktick;
+
+	/* Assume Scenario 1: "now" is later than prev_tick.  */
+	elapsed_cycles = now - prev_tick;
+
+	if (now < prev_tick) {
+		/* Scenario 2: CR16 wrapped!
+		 * 1's complement is close enough.
+		 */
+		elapsed_cycles = ~elapsed_cycles;
+	}
 
-	/* the precision of this math could be improved */
-	return elapsed_cycles / (PAGE0->mem_10msec / 10000);
+	if (elapsed_cycles > (HZ * clocktick)) {
+		/* Scenario 3: clock ticks are missing. */
+		printk (KERN_CRIT "gettimeoffset(CPU %d): missing ticks!"
+			"cycles %lX prev/now/next %lX/%lX/%lX  clock %lX\n",
+			cpuid,
+			elapsed_cycles, prev_tick, now, next_tick, clocktick);
+	}
+
+	/* FIXME: Can we improve the precision? Not with PAGE0. */
+	usec = (elapsed_cycles * 10000) / PAGE0->mem_10msec;
+
+	/* add in "lost" jiffies */
+	usec += clocktick * (jiffies - wall_jiffies);
+	return usec;
 #else
 	return 0;
 #endif
@@ -146,6 +209,7 @@ do_gettimeofday (struct timeval *tv)
 {
 	unsigned long flags, seq, usec, sec;
 
+	/* Hold xtime_lock and adjust timeval.  */
 	do {
 		seq = read_seqbegin_irqsave(&xtime_lock, flags);
 		usec = gettimeoffset();
@@ -153,25 +217,13 @@ do_gettimeofday (struct timeval *tv)
 		usec += (xtime.tv_nsec / 1000);
 	} while (read_seqretry_irqrestore(&xtime_lock, seq, flags));
 
-	if (unlikely(usec > LONG_MAX)) {
-		/* This can happen if the gettimeoffset adjustment is
-		 * negative and xtime.tv_nsec is smaller than the
-		 * adjustment */
-		printk(KERN_ERR "do_gettimeofday() spurious xtime.tv_nsec of %ld\n", usec);
-		usec += USEC_PER_SEC;
-		--sec;
-		/* This should never happen, it means the negative
-		 * time adjustment was more than a second, so there's
-		 * something seriously wrong */
-		BUG_ON(usec > LONG_MAX);
-	}
-
-
+	/* Move adjusted usec's into sec's.  */
 	while (usec >= USEC_PER_SEC) {
 		usec -= USEC_PER_SEC;
 		++sec;
 	}
 
+	/* Return adjusted result.  */
 	tv->tv_sec = sec;
 	tv->tv_usec = usec;
 }

commit 56f335c89e28c488b1bfea3e5e697fce805c784d
Author: Grant Grundler <grundler@gsyprf11.external.hp.com>
Date:   Sun Sep 3 00:02:16 2006 -0700

    [PARISC] Add new function to start local Interval Timer, start_cpu_itimer()
    
    I couldn't find where the itimer was getting started for slave CPUs.
    CPU 0 (master) itimer was started in time_init() (arch/parisc/kernel/time.c).
    start_cpu_itimer() code was striped from time_init().
    Slaves now start their itimer in smp_cpu_init().
    
    This is a first step towards making gettimeoffset() work for SMP.
    Next step will be to determine the CR16 (cycle counter)
    offsets for each CPU relative to the master (CPU 0).
    
    Signed-off-by: Grant Grundler <grundler@parisc-linux.org>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index ab641d67f551..47831c2cd093 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -223,22 +223,24 @@ unsigned long long sched_clock(void)
 }
 
 
+void __init start_cpu_itimer(void)
+{
+	unsigned int cpu = smp_processor_id();
+	unsigned long next_tick = mfctl(16) + clocktick;
+
+	mtctl(next_tick, 16);		/* kick off Interval Timer (CR16) */
+
+	cpu_data[cpu].it_value = next_tick;
+}
+
 void __init time_init(void)
 {
-	unsigned long next_tick;
 	static struct pdc_tod tod_data;
 
 	clocktick = (100 * PAGE0->mem_10msec) / HZ;
 	halftick = clocktick / 2;
 
-	/* Setup clock interrupt timing */
-
-	next_tick = mfctl(16);
-	next_tick += clocktick;
-	cpu_data[smp_processor_id()].it_value = next_tick;
-
-	/* kick off Itimer (CR16) */
-	mtctl(next_tick, 16);
+	start_cpu_itimer();	/* get CPU 0 started */
 
 	if(pdc_tod_read(&tod_data) == 0) {
 		write_seqlock_irq(&xtime_lock);

commit 8ef386092d7c2891bd7acefb2a87f878f7e9a0d6
Author: Atsushi Nemoto <anemo@mba.ocn.ne.jp>
Date:   Sat Sep 30 23:28:31 2006 -0700

    [PATCH] kill wall_jiffies
    
    With 2.6.18-rc4-mm2, now wall_jiffies will always be the same as jiffies.
    So we can kill wall_jiffies completely.
    
    This is just a cleanup and logically should not change any real behavior
    except for one thing: RTC updating code in (old) ppc and xtensa use a
    condition "jiffies - wall_jiffies == 1".  This condition is never met so I
    suppose it is just a bug.  I just remove that condition only instead of
    kill the whole "if" block.
    
    [heiko.carstens@de.ibm.com: s390 build fix and cleanup]
    Signed-off-by: Atsushi Nemoto <anemo@mba.ocn.ne.jp>
    Cc: Andi Kleen <ak@muc.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Ian Molton <spyro@f2s.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Hirokazu Takata <takata.hirokazu@renesas.com>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Kazumoto Kojima <kkojima@rr.iij4u.or.jp>
    Cc: Richard Curnow <rc@rc0.org.uk>
    Cc: William Lee Irwin III <wli@holomorphy.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Paolo 'Blaisorblade' Giarrusso <blaisorblade@yahoo.it>
    Cc: Miles Bader <uclinux-v850@lsi.nec.co.jp>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 700df10924dd..ab641d67f551 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -32,9 +32,6 @@
 
 #include <linux/timex.h>
 
-/* xtime and wall_jiffies keep wall-clock time */
-extern unsigned long wall_jiffies;
-
 static long clocktick __read_mostly;	/* timer cycles per tick */
 static long halftick __read_mostly;
 
@@ -112,7 +109,7 @@ EXPORT_SYMBOL(profile_pc);
 /*** converted from ia64 ***/
 /*
  * Return the number of micro-seconds that elapsed since the last
- * update to wall time (aka xtime aka wall_jiffies).  The xtime_lock
+ * update to wall time (aka xtime).  The xtime_lock
  * must be at least read-locked when calling this routine.
  */
 static inline unsigned long

commit 3171a0305d62e6627a24bff35af4f997e4988a80
Author: Atsushi Nemoto <anemo@mba.ocn.ne.jp>
Date:   Fri Sep 29 02:00:32 2006 -0700

    [PATCH] simplify update_times (avoid jiffies/jiffies_64 aliasing problem)
    
    Pass ticks to do_timer() and update_times(), and adjust x86_64 and s390
    timer interrupt handler with this change.
    
    Currently update_times() calculates ticks by "jiffies - wall_jiffies", but
    callers of do_timer() should know how many ticks to update.  Passing ticks
    get rid of this redundant calculation.  Also there are another redundancy
    pointed out by Martin Schwidefsky.
    
    This cleanup make a barrier added by
    5aee405c662ca644980c184774277fc6d0769a84 needless.  So this patch removes
    it.
    
    As a bonus, this cleanup make wall_jiffies can be removed easily, since now
    wall_jiffies is always synced with jiffies.  (This patch does not really
    remove wall_jiffies.  It would be another cleanup patch)
    
    Signed-off-by: Atsushi Nemoto <anemo@mba.ocn.ne.jp>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: john stultz <johnstul@us.ibm.com>
    Cc: Andi Kleen <ak@muc.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Acked-by: Russell King <rmk@arm.linux.org.uk>
    Cc: Ian Molton <spyro@f2s.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Hirokazu Takata <takata.hirokazu@renesas.com>
    Acked-by: Ralf Baechle <ralf@linux-mips.org>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Kazumoto Kojima <kkojima@rr.iij4u.or.jp>
    Cc: Richard Curnow <rc@rc0.org.uk>
    Cc: William Lee Irwin III <wli@holomorphy.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Paolo 'Blaisorblade' Giarrusso <blaisorblade@yahoo.it>
    Cc: Miles Bader <uclinux-v850@lsi.nec.co.jp>
    Cc: Chris Zankel <chris@zankel.net>
    Acked-by: "Luck, Tony" <tony.luck@intel.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 5facc9bff4ef..700df10924dd 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -79,7 +79,7 @@ irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 #endif
 		if (cpu == 0) {
 			write_seqlock(&xtime_lock);
-			do_timer(regs);
+			do_timer(1);
 			write_sequnlock(&xtime_lock);
 		}
 	}

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: JÃ¶rn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: JÃ¶rn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index eb35e1c0bb53..5facc9bff4ef 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -10,7 +10,6 @@
  * 1998-12-20  Updated NTP code according to technical memorandum Jan '96
  *             "A Kernel Model for Precision Timekeeping" by Dave Mills
  */
-#include <linux/config.h>
 #include <linux/errno.h>
 #include <linux/module.h>
 #include <linux/sched.h>

commit 61c340166d8c62086b6de00afc7670eea27eb2ab
Author: James Bottomley <jejb@parisc-linux.org>
Date:   Sat Jun 24 16:05:18 2006 +0000

    [PARISC] Fix do_gettimeofday() hang
    
    Apparently gettimeoffset can return small negative values (usually in
    the 100us range).  If xtime.tv_nsec is accidentally less than this,
    though (a fortunately unlikely event) it triggers the loop forever.
    
    I've added a test and correct adjustment for this case.  It has a
    warning printk in there which I'd like to leave for the time being
    just in case this problem implicates some other part of the kernel.
    
    Signed-off-by: James Bottomley <jejb@parisc-linux.org>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 594930bc4bcf..eb35e1c0bb53 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -157,8 +157,22 @@ do_gettimeofday (struct timeval *tv)
 		usec += (xtime.tv_nsec / 1000);
 	} while (read_seqretry_irqrestore(&xtime_lock, seq, flags));
 
-	while (usec >= 1000000) {
-		usec -= 1000000;
+	if (unlikely(usec > LONG_MAX)) {
+		/* This can happen if the gettimeoffset adjustment is
+		 * negative and xtime.tv_nsec is smaller than the
+		 * adjustment */
+		printk(KERN_ERR "do_gettimeofday() spurious xtime.tv_nsec of %ld\n", usec);
+		usec += USEC_PER_SEC;
+		--sec;
+		/* This should never happen, it means the negative
+		 * time adjustment was more than a second, so there's
+		 * something seriously wrong */
+		BUG_ON(usec > LONG_MAX);
+	}
+
+
+	while (usec >= USEC_PER_SEC) {
+		usec -= USEC_PER_SEC;
 		++sec;
 	}
 

commit 8039de10aae3cd4cf0ef0ccebd58aff0e8810df2
Author: Helge Deller <deller@parisc-linux.org>
Date:   Tue Jan 10 20:35:03 2006 -0500

    [PARISC] Add __read_mostly section for parisc
    
    Flag a whole bunch of things as __read_mostly on parisc. Also flag a few
    branches as unlikely() and cleanup a bit of code.
    
    Signed-off-by: Helge Deller <deller@parisc-linux.org>
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index cded25680787..594930bc4bcf 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -36,8 +36,8 @@
 /* xtime and wall_jiffies keep wall-clock time */
 extern unsigned long wall_jiffies;
 
-static long clocktick;	/* timer cycles per tick */
-static long halftick;
+static long clocktick __read_mostly;	/* timer cycles per tick */
+static long halftick __read_mostly;
 
 #ifdef CONFIG_SMP
 extern void smp_do_timer(struct pt_regs *regs);

commit ecea8d19c9f0ebd62ddaa07fc919ff4e4b820d99
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Oct 30 15:03:00 2005 -0800

    [PATCH] jiffies_64 cleanup
    
    Define jiffies_64 in kernel/timer.c rather than having 24 duplicated
    defines in each architecture.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index bc979e1abdec..cded25680787 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -33,10 +33,6 @@
 
 #include <linux/timex.h>
 
-u64 jiffies_64 = INITIAL_JIFFIES;
-
-EXPORT_SYMBOL(jiffies_64);
-
 /* xtime and wall_jiffies keep wall-clock time */
 extern unsigned long wall_jiffies;
 

commit 3499495205a676d85fcc2f3c28e35ec9b43c47e3
Author: Grant Grundler <grundler@parisc-linux.org>
Date:   Fri Oct 21 22:46:18 2005 -0400

    [PARISC] Use work queue in LED/LCD driver instead of tasklet.
    
    2.6.12-rc1-pa6 use work queue in LED/LCD driver instead of tasklet.
    
    Main advantage is it allows use of msleep() in the led_LCD_driver to
    "atomically" perform two MMIO writes (CMD, then DATA).
    Lead to nice cleanup of the main led_work_func() and led_LCD_driver().
    Kudos to David for being persistent.
    
    From: David Pye <dmp@davidmpye.dyndns.org>
    Signed-off-by: Grant Grundler <grundler@parisc-linux.org>
    
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 163cdf39be20..bc979e1abdec 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -89,14 +89,6 @@ irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 		}
 	}
     
-#ifdef CONFIG_CHASSIS_LCD_LED
-	/* Only schedule the led tasklet on cpu 0, and only if it
-	 * is enabled.
-	 */
-	if (cpu == 0 && !atomic_read(&led_tasklet.count))
-		tasklet_schedule(&led_tasklet);
-#endif
-
 	/* check soft power switch status */
 	if (cpu == 0 && !atomic_read(&power_tasklet.count))
 		tasklet_schedule(&power_tasklet);

commit 5cd55b0edee7f979530c86b23728d461ddeb9f3f
Author: Randolph Chung <tausq@parisc-linux.org>
Date:   Fri Oct 21 22:42:18 2005 -0400

    [PARISC] Take into account nullified insn and lock functions for profiling
    
    export profile_pc() symbol - oprofile needs it when built as a module.
    
    Signed-off-by: Grant Grundler <grundler@parisc-linux.org>
    
    Take into account nullified insn and lock functions for profiling
    
    This is needed at the end of functions; it is typical that the return
    branch nullifies the next insn, which is in the next function. This
    causes profiling data to show up against the "wrong" function.
    
    We also count lock times against the locker. This is consistent with
    other architectures.
    
    Signed-off-by: Randolph Chung <tausq@parisc-linux.org>
    
    Signed-off-by: Kyle McMartin <kyle@parisc-linux.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 7ff67f8e9f8c..163cdf39be20 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -104,6 +104,24 @@ irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 	return IRQ_HANDLED;
 }
 
+
+unsigned long profile_pc(struct pt_regs *regs)
+{
+	unsigned long pc = instruction_pointer(regs);
+
+	if (regs->gr[0] & PSW_N)
+		pc -= 4;
+
+#ifdef CONFIG_SMP
+	if (in_lock_functions(pc))
+		pc = regs->gr[2];
+#endif
+
+	return pc;
+}
+EXPORT_SYMBOL(profile_pc);
+
+
 /*** converted from ia64 ***/
 /*
  * Return the number of micro-seconds that elapsed since the last

commit b149ee2233edf08fb59b11e879a2c5941929bcb8
Author: john stultz <johnstul@us.ibm.com>
Date:   Tue Sep 6 15:17:46 2005 -0700

    [PATCH] NTP: ntp-helper functions
    
    This patch cleans up a commonly repeated set of changes to the NTP state
    variables by adding two helper inline functions:
    
    ntp_clear(): Clears the ntp state variables
    
    ntp_synced(): Returns 1 if the system is synced with a time server.
    
    This was compile tested for alpha, arm, i386, x86-64, ppc64, s390, sparc,
    sparc64.
    
    Signed-off-by: John Stultz <johnstul@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
index 6cf7407344ba..7ff67f8e9f8c 100644
--- a/arch/parisc/kernel/time.c
+++ b/arch/parisc/kernel/time.c
@@ -188,10 +188,7 @@ do_settimeofday (struct timespec *tv)
 		set_normalized_timespec(&xtime, sec, nsec);
 		set_normalized_timespec(&wall_to_monotonic, wtm_sec, wtm_nsec);
 
-		time_adjust = 0;		/* stop active adjtime() */
-		time_status |= STA_UNSYNC;
-		time_maxerror = NTP_PHASE_LIMIT;
-		time_esterror = NTP_PHASE_LIMIT;
+		ntp_clear();
 	}
 	write_sequnlock_irq(&xtime_lock);
 	clock_was_set();

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c
new file mode 100644
index 000000000000..6cf7407344ba
--- /dev/null
+++ b/arch/parisc/kernel/time.c
@@ -0,0 +1,243 @@
+/*
+ *  linux/arch/parisc/kernel/time.c
+ *
+ *  Copyright (C) 1991, 1992, 1995  Linus Torvalds
+ *  Modifications for ARM (C) 1994, 1995, 1996,1997 Russell King
+ *  Copyright (C) 1999 SuSE GmbH, (Philipp Rumpf, prumpf@tux.org)
+ *
+ * 1994-07-02  Alan Modra
+ *             fixed set_rtc_mmss, fixed time.year for >= 2000, new mktime
+ * 1998-12-20  Updated NTP code according to technical memorandum Jan '96
+ *             "A Kernel Model for Precision Timekeeping" by Dave Mills
+ */
+#include <linux/config.h>
+#include <linux/errno.h>
+#include <linux/module.h>
+#include <linux/sched.h>
+#include <linux/kernel.h>
+#include <linux/param.h>
+#include <linux/string.h>
+#include <linux/mm.h>
+#include <linux/interrupt.h>
+#include <linux/time.h>
+#include <linux/init.h>
+#include <linux/smp.h>
+#include <linux/profile.h>
+
+#include <asm/uaccess.h>
+#include <asm/io.h>
+#include <asm/irq.h>
+#include <asm/param.h>
+#include <asm/pdc.h>
+#include <asm/led.h>
+
+#include <linux/timex.h>
+
+u64 jiffies_64 = INITIAL_JIFFIES;
+
+EXPORT_SYMBOL(jiffies_64);
+
+/* xtime and wall_jiffies keep wall-clock time */
+extern unsigned long wall_jiffies;
+
+static long clocktick;	/* timer cycles per tick */
+static long halftick;
+
+#ifdef CONFIG_SMP
+extern void smp_do_timer(struct pt_regs *regs);
+#endif
+
+irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
+{
+	long now;
+	long next_tick;
+	int nticks;
+	int cpu = smp_processor_id();
+
+	profile_tick(CPU_PROFILING, regs);
+
+	now = mfctl(16);
+	/* initialize next_tick to time at last clocktick */
+	next_tick = cpu_data[cpu].it_value;
+
+	/* since time passes between the interrupt and the mfctl()
+	 * above, it is never true that last_tick + clocktick == now.  If we
+	 * never miss a clocktick, we could set next_tick = last_tick + clocktick
+	 * but maybe we'll miss ticks, hence the loop.
+	 *
+	 * Variables are *signed*.
+	 */
+
+	nticks = 0;
+	while((next_tick - now) < halftick) {
+		next_tick += clocktick;
+		nticks++;
+	}
+	mtctl(next_tick, 16);
+	cpu_data[cpu].it_value = next_tick;
+
+	while (nticks--) {
+#ifdef CONFIG_SMP
+		smp_do_timer(regs);
+#else
+		update_process_times(user_mode(regs));
+#endif
+		if (cpu == 0) {
+			write_seqlock(&xtime_lock);
+			do_timer(regs);
+			write_sequnlock(&xtime_lock);
+		}
+	}
+    
+#ifdef CONFIG_CHASSIS_LCD_LED
+	/* Only schedule the led tasklet on cpu 0, and only if it
+	 * is enabled.
+	 */
+	if (cpu == 0 && !atomic_read(&led_tasklet.count))
+		tasklet_schedule(&led_tasklet);
+#endif
+
+	/* check soft power switch status */
+	if (cpu == 0 && !atomic_read(&power_tasklet.count))
+		tasklet_schedule(&power_tasklet);
+
+	return IRQ_HANDLED;
+}
+
+/*** converted from ia64 ***/
+/*
+ * Return the number of micro-seconds that elapsed since the last
+ * update to wall time (aka xtime aka wall_jiffies).  The xtime_lock
+ * must be at least read-locked when calling this routine.
+ */
+static inline unsigned long
+gettimeoffset (void)
+{
+#ifndef CONFIG_SMP
+	/*
+	 * FIXME: This won't work on smp because jiffies are updated by cpu 0.
+	 *    Once parisc-linux learns the cr16 difference between processors,
+	 *    this could be made to work.
+	 */
+	long last_tick;
+	long elapsed_cycles;
+
+	/* it_value is the intended time of the next tick */
+	last_tick = cpu_data[smp_processor_id()].it_value;
+
+	/* Subtract one tick and account for possible difference between
+	 * when we expected the tick and when it actually arrived.
+	 * (aka wall vs real)
+	 */
+	last_tick -= clocktick * (jiffies - wall_jiffies + 1);
+	elapsed_cycles = mfctl(16) - last_tick;
+
+	/* the precision of this math could be improved */
+	return elapsed_cycles / (PAGE0->mem_10msec / 10000);
+#else
+	return 0;
+#endif
+}
+
+void
+do_gettimeofday (struct timeval *tv)
+{
+	unsigned long flags, seq, usec, sec;
+
+	do {
+		seq = read_seqbegin_irqsave(&xtime_lock, flags);
+		usec = gettimeoffset();
+		sec = xtime.tv_sec;
+		usec += (xtime.tv_nsec / 1000);
+	} while (read_seqretry_irqrestore(&xtime_lock, seq, flags));
+
+	while (usec >= 1000000) {
+		usec -= 1000000;
+		++sec;
+	}
+
+	tv->tv_sec = sec;
+	tv->tv_usec = usec;
+}
+
+EXPORT_SYMBOL(do_gettimeofday);
+
+int
+do_settimeofday (struct timespec *tv)
+{
+	time_t wtm_sec, sec = tv->tv_sec;
+	long wtm_nsec, nsec = tv->tv_nsec;
+
+	if ((unsigned long)tv->tv_nsec >= NSEC_PER_SEC)
+		return -EINVAL;
+
+	write_seqlock_irq(&xtime_lock);
+	{
+		/*
+		 * This is revolting. We need to set "xtime"
+		 * correctly. However, the value in this location is
+		 * the value at the most recent update of wall time.
+		 * Discover what correction gettimeofday would have
+		 * done, and then undo it!
+		 */
+		nsec -= gettimeoffset() * 1000;
+
+		wtm_sec  = wall_to_monotonic.tv_sec + (xtime.tv_sec - sec);
+		wtm_nsec = wall_to_monotonic.tv_nsec + (xtime.tv_nsec - nsec);
+
+		set_normalized_timespec(&xtime, sec, nsec);
+		set_normalized_timespec(&wall_to_monotonic, wtm_sec, wtm_nsec);
+
+		time_adjust = 0;		/* stop active adjtime() */
+		time_status |= STA_UNSYNC;
+		time_maxerror = NTP_PHASE_LIMIT;
+		time_esterror = NTP_PHASE_LIMIT;
+	}
+	write_sequnlock_irq(&xtime_lock);
+	clock_was_set();
+	return 0;
+}
+EXPORT_SYMBOL(do_settimeofday);
+
+/*
+ * XXX: We can do better than this.
+ * Returns nanoseconds
+ */
+
+unsigned long long sched_clock(void)
+{
+	return (unsigned long long)jiffies * (1000000000 / HZ);
+}
+
+
+void __init time_init(void)
+{
+	unsigned long next_tick;
+	static struct pdc_tod tod_data;
+
+	clocktick = (100 * PAGE0->mem_10msec) / HZ;
+	halftick = clocktick / 2;
+
+	/* Setup clock interrupt timing */
+
+	next_tick = mfctl(16);
+	next_tick += clocktick;
+	cpu_data[smp_processor_id()].it_value = next_tick;
+
+	/* kick off Itimer (CR16) */
+	mtctl(next_tick, 16);
+
+	if(pdc_tod_read(&tod_data) == 0) {
+		write_seqlock_irq(&xtime_lock);
+		xtime.tv_sec = tod_data.tod_sec;
+		xtime.tv_nsec = tod_data.tod_usec * 1000;
+		set_normalized_timespec(&wall_to_monotonic,
+		                        -xtime.tv_sec, -xtime.tv_nsec);
+		write_sequnlock_irq(&xtime_lock);
+	} else {
+		printk(KERN_ERR "Error reading tod clock\n");
+	        xtime.tv_sec = 0;
+		xtime.tv_nsec = 0;
+	}
+}
+
