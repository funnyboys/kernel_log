commit 3e4e28c5a8f01ee4174d639e36ed155ade489a6f
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Jun 8 21:33:51 2020 -0700

    mmap locking API: convert mmap_sem API comments
    
    Convert comments that reference old mmap_sem APIs to reference
    corresponding new mmap locking APIs instead.
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Vlastimil Babka <vbabka@suse.cz>
    Reviewed-by: Davidlohr Bueso <dbueso@suse.de>
    Reviewed-by: Daniel Jordan <daniel.m.jordan@oracle.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jason Gunthorpe <jgg@ziepe.ca>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: John Hubbard <jhubbard@nvidia.com>
    Cc: Laurent Dufour <ldufour@linux.ibm.com>
    Cc: Liam Howlett <Liam.Howlett@oracle.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ying Han <yinghan@google.com>
    Link: http://lkml.kernel.org/r/20200520052908.204642-12-walken@google.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index 650acab0d77d..a94a814ad6ad 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -165,7 +165,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 			flags |= FAULT_FLAG_TRIED;
 
 			/*
-			 * No need to up_read(&mm->mmap_sem) as we would
+			 * No need to mmap_read_unlock(mm) as we would
 			 * have already released it in __lock_page_or_retry
 			 * in mm/filemap.c.
 			 */

commit d8ed45c5dcd455fc5848d47f86883a1b872ac0d0
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Jun 8 21:33:25 2020 -0700

    mmap locking API: use coccinelle to convert mmap_sem rwsem call sites
    
    This change converts the existing mmap_sem rwsem calls to use the new mmap
    locking API instead.
    
    The change is generated using coccinelle with the following rule:
    
    // spatch --sp-file mmap_lock_api.cocci --in-place --include-headers --dir .
    
    @@
    expression mm;
    @@
    (
    -init_rwsem
    +mmap_init_lock
    |
    -down_write
    +mmap_write_lock
    |
    -down_write_killable
    +mmap_write_lock_killable
    |
    -down_write_trylock
    +mmap_write_trylock
    |
    -up_write
    +mmap_write_unlock
    |
    -downgrade_write
    +mmap_write_downgrade
    |
    -down_read
    +mmap_read_lock
    |
    -down_read_killable
    +mmap_read_lock_killable
    |
    -down_read_trylock
    +mmap_read_trylock
    |
    -up_read
    +mmap_read_unlock
    )
    -(&mm->mmap_sem)
    +(mm)
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Daniel Jordan <daniel.m.jordan@oracle.com>
    Reviewed-by: Laurent Dufour <ldufour@linux.ibm.com>
    Reviewed-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Davidlohr Bueso <dbueso@suse.de>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jason Gunthorpe <jgg@ziepe.ca>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: John Hubbard <jhubbard@nvidia.com>
    Cc: Liam Howlett <Liam.Howlett@oracle.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ying Han <yinghan@google.com>
    Link: http://lkml.kernel.org/r/20200520052908.204642-5-walken@google.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index 3bfb5c8ac3c7..650acab0d77d 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -86,7 +86,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 	if (user_mode(regs))
 		flags |= FAULT_FLAG_USER;
 retry:
-	down_read(&mm->mmap_sem);
+	mmap_read_lock(mm);
 
 	vma = find_vma(mm, address);
 	if (!vma)
@@ -174,7 +174,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 		}
 	}
 
-	up_read(&mm->mmap_sem);
+	mmap_read_unlock(mm);
 	return 0;
 
 /*
@@ -182,7 +182,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
  * us unable to handle the page fault gracefully.
  */
 out_of_memory:
-	up_read(&mm->mmap_sem);
+	mmap_read_unlock(mm);
 	if (!user_mode(regs))
 		goto no_context;
 	pagefault_out_of_memory();
@@ -211,6 +211,6 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 	current->thread.faddr = address;
 
 send_sig:
-	up_read(&mm->mmap_sem);
+	mmap_read_unlock(mm);
 	return send_fault_sig(regs);
 }

commit 5093c5872be3a041917828b2b53e9f981d754768
Author: Anshuman Khandual <anshuman.khandual@arm.com>
Date:   Mon Apr 6 20:03:59 2020 -0700

    mm/vma: append unlikely() while testing VMA access permissions
    
    It is unlikely that an inaccessible VMA without required permission flags
    will get a page fault.  Hence lets just append unlikely() directive to
    such checks in order to improve performance while also standardizing it
    across various platforms.
    
    Signed-off-by: Anshuman Khandual <anshuman.khandual@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Paul Burton <paulburton@kernel.org>
    Cc: Mike Rapoport <rppt@linux.ibm.com>
    Link: http://lkml.kernel.org/r/1582525304-32113-1-git-send-email-anshuman.khandual@arm.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index 0c4a21a685d5..3bfb5c8ac3c7 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -125,7 +125,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 		case 1:		/* read, present */
 			goto acc_err;
 		case 0:		/* read, not present */
-			if (!vma_is_accessible(vma))
+			if (unlikely(!vma_is_accessible(vma)))
 				goto acc_err;
 	}
 

commit 3122e80efc0faf4a2accba7a46c7ed795edbfded
Author: Anshuman Khandual <anshuman.khandual@arm.com>
Date:   Mon Apr 6 20:03:47 2020 -0700

    mm/vma: make vma_is_accessible() available for general use
    
    Lets move vma_is_accessible() helper to include/linux/mm.h which makes it
    available for general use.  While here, this replaces all remaining open
    encodings for VMA access check with vma_is_accessible().
    
    Signed-off-by: Anshuman Khandual <anshuman.khandual@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Acked-by: Guo Ren <guoren@kernel.org>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Paul Burton <paulburton@kernel.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: "Aneesh Kumar K.V" <aneesh.kumar@linux.ibm.com>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Nick Piggin <npiggin@gmail.com>
    Cc: Paul Mackerras <paulus@ozlabs.org>
    Cc: Will Deacon <will@kernel.org>
    Link: http://lkml.kernel.org/r/1582520593-30704-3-git-send-email-anshuman.khandual@arm.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index f7afb9897966..0c4a21a685d5 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -125,7 +125,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 		case 1:		/* read, present */
 			goto acc_err;
 		case 0:		/* read, not present */
-			if (!(vma->vm_flags & (VM_READ | VM_EXEC | VM_WRITE)))
+			if (!vma_is_accessible(vma))
 				goto acc_err;
 	}
 

commit 4064b982706375025628094e51d11cf1a958a5d3
Author: Peter Xu <peterx@redhat.com>
Date:   Wed Apr 1 21:08:45 2020 -0700

    mm: allow VM_FAULT_RETRY for multiple times
    
    The idea comes from a discussion between Linus and Andrea [1].
    
    Before this patch we only allow a page fault to retry once.  We achieved
    this by clearing the FAULT_FLAG_ALLOW_RETRY flag when doing
    handle_mm_fault() the second time.  This was majorly used to avoid
    unexpected starvation of the system by looping over forever to handle the
    page fault on a single page.  However that should hardly happen, and after
    all for each code path to return a VM_FAULT_RETRY we'll first wait for a
    condition (during which time we should possibly yield the cpu) to happen
    before VM_FAULT_RETRY is really returned.
    
    This patch removes the restriction by keeping the FAULT_FLAG_ALLOW_RETRY
    flag when we receive VM_FAULT_RETRY.  It means that the page fault handler
    now can retry the page fault for multiple times if necessary without the
    need to generate another page fault event.  Meanwhile we still keep the
    FAULT_FLAG_TRIED flag so page fault handler can still identify whether a
    page fault is the first attempt or not.
    
    Then we'll have these combinations of fault flags (only considering
    ALLOW_RETRY flag and TRIED flag):
    
      - ALLOW_RETRY and !TRIED:  this means the page fault allows to
                                 retry, and this is the first try
    
      - ALLOW_RETRY and TRIED:   this means the page fault allows to
                                 retry, and this is not the first try
    
      - !ALLOW_RETRY and !TRIED: this means the page fault does not allow
                                 to retry at all
    
      - !ALLOW_RETRY and TRIED:  this is forbidden and should never be used
    
    In existing code we have multiple places that has taken special care of
    the first condition above by checking against (fault_flags &
    FAULT_FLAG_ALLOW_RETRY).  This patch introduces a simple helper to detect
    the first retry of a page fault by checking against both (fault_flags &
    FAULT_FLAG_ALLOW_RETRY) and !(fault_flag & FAULT_FLAG_TRIED) because now
    even the 2nd try will have the ALLOW_RETRY set, then use that helper in
    all existing special paths.  One example is in __lock_page_or_retry(), now
    we'll drop the mmap_sem only in the first attempt of page fault and we'll
    keep it in follow up retries, so old locking behavior will be retained.
    
    This will be a nice enhancement for current code [2] at the same time a
    supporting material for the future userfaultfd-writeprotect work, since in
    that work there will always be an explicit userfault writeprotect retry
    for protected pages, and if that cannot resolve the page fault (e.g., when
    userfaultfd-writeprotect is used in conjunction with swapped pages) then
    we'll possibly need a 3rd retry of the page fault.  It might also benefit
    other potential users who will have similar requirement like userfault
    write-protection.
    
    GUP code is not touched yet and will be covered in follow up patch.
    
    Please read the thread below for more information.
    
    [1] https://lore.kernel.org/lkml/20171102193644.GB22686@redhat.com/
    [2] https://lore.kernel.org/lkml/20181230154648.GB9832@redhat.com/
    
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Suggested-by: Andrea Arcangeli <aarcange@redhat.com>
    Signed-off-by: Peter Xu <peterx@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Tested-by: Brian Geffon <bgeffon@google.com>
    Cc: Bobby Powers <bobbypowers@gmail.com>
    Cc: David Hildenbrand <david@redhat.com>
    Cc: Denis Plotnikov <dplotnikov@virtuozzo.com>
    Cc: "Dr . David Alan Gilbert" <dgilbert@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: "Kirill A . Shutemov" <kirill@shutemov.name>
    Cc: Martin Cracauer <cracauer@cons.org>
    Cc: Marty McFadden <mcfadden8@llnl.gov>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Maya Gokhale <gokhale2@llnl.gov>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Mike Kravetz <mike.kravetz@oracle.com>
    Cc: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Link: http://lkml.kernel.org/r/20200220160246.9790-1-peterx@redhat.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index 182799fd9987..f7afb9897966 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -162,9 +162,6 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 		else
 			current->min_flt++;
 		if (fault & VM_FAULT_RETRY) {
-			/* Clear FAULT_FLAG_ALLOW_RETRY to avoid any risk
-			 * of starvation. */
-			flags &= ~FAULT_FLAG_ALLOW_RETRY;
 			flags |= FAULT_FLAG_TRIED;
 
 			/*

commit dde1607248328cdb7570e3a252e8fb76b3411d66
Author: Peter Xu <peterx@redhat.com>
Date:   Wed Apr 1 21:08:37 2020 -0700

    mm: introduce FAULT_FLAG_DEFAULT
    
    Although there're tons of arch-specific page fault handlers, most of them
    are still sharing the same initial value of the page fault flags.  Say,
    merely all of the page fault handlers would allow the fault to be retried,
    and they also allow the fault to respond to SIGKILL.
    
    Let's define a default value for the fault flags to replace those initial
    page fault flags that were copied over.  With this, it'll be far easier to
    introduce new fault flag that can be used by all the architectures instead
    of touching all the archs.
    
    Signed-off-by: Peter Xu <peterx@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Tested-by: Brian Geffon <bgeffon@google.com>
    Reviewed-by: David Hildenbrand <david@redhat.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Bobby Powers <bobbypowers@gmail.com>
    Cc: Denis Plotnikov <dplotnikov@virtuozzo.com>
    Cc: "Dr . David Alan Gilbert" <dgilbert@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: "Kirill A . Shutemov" <kirill@shutemov.name>
    Cc: Martin Cracauer <cracauer@cons.org>
    Cc: Marty McFadden <mcfadden8@llnl.gov>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Maya Gokhale <gokhale2@llnl.gov>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Mike Kravetz <mike.kravetz@oracle.com>
    Cc: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Link: http://lkml.kernel.org/r/20200220160238.9694-1-peterx@redhat.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index a455e202691b..182799fd9987 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -71,7 +71,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 	struct mm_struct *mm = current->mm;
 	struct vm_area_struct * vma;
 	vm_fault_t fault;
-	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
+	unsigned int flags = FAULT_FLAG_DEFAULT;
 
 	pr_debug("do page fault:\nregs->sr=%#x, regs->pc=%#lx, address=%#lx, %ld, %p\n",
 		regs->sr, regs->pc, address, error_code, mm ? mm->pgd : NULL);

commit 4ef873226ceb9c7bf11a922caddc5698a24bcfaf
Author: Peter Xu <peterx@redhat.com>
Date:   Wed Apr 1 21:08:06 2020 -0700

    mm: introduce fault_signal_pending()
    
    For most architectures, we've got a quick path to detect fatal signal
    after a handle_mm_fault().  Introduce a helper for that quick path.
    
    It cleans the current codes a bit so we don't need to duplicate the same
    check across archs.  More importantly, this will be an unified place that
    we handle the signal immediately right after an interrupted page fault, so
    it'll be much easier for us if we want to change the behavior of handling
    signals later on for all the archs.
    
    Note that currently only part of the archs are using this new helper,
    because some archs have their own way to handle signals.  In the follow up
    patches, we'll try to apply this helper to all the rest of archs.
    
    Another note is that the "regs" parameter in the new helper is not used
    yet.  It'll be used very soon.  Now we kept it in this patch only to avoid
    touching all the archs again in the follow up patches.
    
    [peterx@redhat.com: fix sparse warnings]
      Link: http://lkml.kernel.org/r/20200311145921.GD479302@xz-x1
    Signed-off-by: Peter Xu <peterx@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Tested-by: Brian Geffon <bgeffon@google.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Bobby Powers <bobbypowers@gmail.com>
    Cc: David Hildenbrand <david@redhat.com>
    Cc: Denis Plotnikov <dplotnikov@virtuozzo.com>
    Cc: "Dr . David Alan Gilbert" <dgilbert@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: "Kirill A . Shutemov" <kirill@shutemov.name>
    Cc: Martin Cracauer <cracauer@cons.org>
    Cc: Marty McFadden <mcfadden8@llnl.gov>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Maya Gokhale <gokhale2@llnl.gov>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Mike Kravetz <mike.kravetz@oracle.com>
    Cc: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Link: http://lkml.kernel.org/r/20200220155353.8676-4-peterx@redhat.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index e9b1d7585b43..a455e202691b 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -138,7 +138,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 	fault = handle_mm_fault(vma, address, flags);
 	pr_debug("handle_mm_fault returns %x\n", fault);
 
-	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current))
+	if (fault_signal_pending(fault, regs))
 		return 0;
 
 	if (unlikely(fault & VM_FAULT_ERROR)) {

commit 2e1661d2673667d886cd40ad9f414cb6db48d8da
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Thu May 23 11:04:24 2019 -0500

    signal: Remove the task parameter from force_sig_fault
    
    As synchronous exceptions really only make sense against the current
    task (otherwise how are you synchronous) remove the task parameter
    from from force_sig_fault to make it explicit that is what is going
    on.
    
    The two known exceptions that deliver a synchronous exception to a
    stopped ptraced task have already been changed to
    force_sig_fault_to_task.
    
    The callers have been changed with the following emacs regular expression
    (with obvious variations on the architectures that take more arguments)
    to avoid typos:
    
    force_sig_fault[(]\([^,]+\)[,]\([^,]+\)[,]\([^,]+\)[,]\W+current[)]
    ->
    force_sig_fault(\1,\2,\3)
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index 9b6163c05a75..e9b1d7585b43 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -30,13 +30,13 @@ int send_fault_sig(struct pt_regs *regs)
 	pr_debug("send_fault_sig: %p,%d,%d\n", addr, signo, si_code);
 
 	if (user_mode(regs)) {
-		force_sig_fault(signo, si_code, addr, current);
+		force_sig_fault(signo, si_code, addr);
 	} else {
 		if (fixup_exception(regs))
 			return -1;
 
 		//if (signo == SIGBUS)
-		//	force_sig_fault(si_signo, si_code, addr, current);
+		//	force_sig_fault(si_signo, si_code, addr);
 
 		/*
 		 * Oops. The kernel tried to access some bad page. We'll have to

commit 50a7ca3c6fc86955f99fc432fc8a186b968b365b
Author: Souptick Joarder <jrdr.linux@gmail.com>
Date:   Fri Aug 17 15:44:47 2018 -0700

    mm: convert return type of handle_mm_fault() caller to vm_fault_t
    
    Use new return type vm_fault_t for fault handler.  For now, this is just
    documenting that the function returns a VM_FAULT value rather than an
    errno.  Once all instances are converted, vm_fault_t will become a
    distinct type.
    
    Ref-> commit 1c8f422059ae ("mm: change return type to vm_fault_t")
    
    In this patch all the caller of handle_mm_fault() are changed to return
    vm_fault_t type.
    
    Link: http://lkml.kernel.org/r/20180617084810.GA6730@jordon-HP-15-Notebook-PC
    Signed-off-by: Souptick Joarder <jrdr.linux@gmail.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: Ley Foon Tan <lftan@altera.com>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: James E.J. Bottomley <jejb@parisc-linux.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Palmer Dabbelt <palmer@sifive.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: "Levin, Alexander (Sasha Levin)" <alexander.levin@verizon.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index f2ff3779875a..9b6163c05a75 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -70,7 +70,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 {
 	struct mm_struct *mm = current->mm;
 	struct vm_area_struct * vma;
-	int fault;
+	vm_fault_t fault;
 	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
 
 	pr_debug("do page fault:\nregs->sr=%#x, regs->pc=%#lx, address=%#lx, %ld, %p\n",
@@ -136,7 +136,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 	 */
 
 	fault = handle_mm_fault(vma, address, flags);
-	pr_debug("handle_mm_fault returns %d\n", fault);
+	pr_debug("handle_mm_fault returns %x\n", fault);
 
 	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current))
 		return 0;

commit 3c67075d5df21f6bdb1dade1f2ab7e82ef0c0f6a
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Apr 16 11:25:17 2018 -0500

    signal/m68k: Use force_sig_fault where appropriate
    
    Filling in struct siginfo before calling force_sig_info a tedious and
    error prone process, where once in a great while the wrong fields
    are filled out, and siginfo has been inconsistently cleared.
    
    Simplify this process by using the helper force_sig_fault.  Which
    takes as a parameters all of the information it needs, ensures
    all of the fiddly bits of filling in struct siginfo are done properly
    and then calls force_sig_info.
    
    In short about a 5 line reduction in code for every time force_sig_info
    is called, which makes the calling function clearer.
    
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: linux-m68k@lists.linux-m68k.org
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index 03253c4f8e6a..f2ff3779875a 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -21,35 +21,32 @@ extern void die_if_kernel(char *, struct pt_regs *, long);
 
 int send_fault_sig(struct pt_regs *regs)
 {
-	siginfo_t siginfo;
+	int signo, si_code;
+	void __user *addr;
 
-	clear_siginfo(&siginfo);
-	siginfo.si_signo = current->thread.signo;
-	siginfo.si_code = current->thread.code;
-	siginfo.si_addr = (void *)current->thread.faddr;
-	pr_debug("send_fault_sig: %p,%d,%d\n", siginfo.si_addr,
-		 siginfo.si_signo, siginfo.si_code);
+	signo = current->thread.signo;
+	si_code = current->thread.code;
+	addr = (void __user *)current->thread.faddr;
+	pr_debug("send_fault_sig: %p,%d,%d\n", addr, signo, si_code);
 
 	if (user_mode(regs)) {
-		force_sig_info(siginfo.si_signo,
-			       &siginfo, current);
+		force_sig_fault(signo, si_code, addr, current);
 	} else {
 		if (fixup_exception(regs))
 			return -1;
 
-		//if (siginfo.si_signo == SIGBUS)
-		//	force_sig_info(siginfo.si_signo,
-		//		       &siginfo, current);
+		//if (signo == SIGBUS)
+		//	force_sig_fault(si_signo, si_code, addr, current);
 
 		/*
 		 * Oops. The kernel tried to access some bad page. We'll have to
 		 * terminate things with extreme prejudice.
 		 */
-		if ((unsigned long)siginfo.si_addr < PAGE_SIZE)
+		if ((unsigned long)addr < PAGE_SIZE)
 			pr_alert("Unable to handle kernel NULL pointer dereference");
 		else
 			pr_alert("Unable to handle kernel access");
-		pr_cont(" at virtual address %p\n", siginfo.si_addr);
+		pr_cont(" at virtual address %p\n", addr);
 		die_if_kernel("Oops", regs, 0 /*error_code*/);
 		do_exit(SIGKILL);
 	}

commit 5f74972ce69fdc6473f74253283408af75a3be15
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Jan 22 14:58:57 2018 -0600

    signal: Don't use structure initializers for struct siginfo
    
    The siginfo structure has all manners of holes with the result that a
    structure initializer is not guaranteed to initialize all of the bits.
    As we have to copy the structure to userspace don't even try to use
    a structure initializer.  Instead use clear_siginfo followed by initializing
    selected fields.  This gives a guarantee that uninitialized kernel memory
    is not copied to userspace.
    
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index 127d7c1f2090..03253c4f8e6a 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -21,8 +21,9 @@ extern void die_if_kernel(char *, struct pt_regs *, long);
 
 int send_fault_sig(struct pt_regs *regs)
 {
-	siginfo_t siginfo = { 0, 0, 0, };
+	siginfo_t siginfo;
 
+	clear_siginfo(&siginfo);
 	siginfo.si_signo = current->thread.signo;
 	siginfo.si_code = current->thread.code;
 	siginfo.si_addr = (void *)current->thread.faddr;

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index 2795e4ca09d7..127d7c1f2090 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  *  linux/arch/m68k/mm/fault.c
  *

commit 68acfdcb477abdbf875e33e4a950094c8de08f41
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Dec 25 14:33:17 2016 -0500

    m68k: switch to generic extable.h
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index bd66a0b20c6b..2795e4ca09d7 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -32,7 +32,7 @@ int send_fault_sig(struct pt_regs *regs)
 		force_sig_info(siginfo.si_signo,
 			       &siginfo, current);
 	} else {
-		if (handle_kernel_fault(regs))
+		if (fixup_exception(regs))
 			return -1;
 
 		//if (siginfo.si_signo == SIGBUS)

commit dcddffd41d3f1d3bdcc1dce3f1cd142779b6d4c1
Author: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
Date:   Tue Jul 26 15:25:18 2016 -0700

    mm: do not pass mm_struct into handle_mm_fault
    
    We always have vma->vm_mm around.
    
    Link: http://lkml.kernel.org/r/1466021202-61880-8-git-send-email-kirill.shutemov@linux.intel.com
    Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index 6a94cdd0c830..bd66a0b20c6b 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -136,7 +136,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 	 * the fault.
 	 */
 
-	fault = handle_mm_fault(mm, vma, address, flags);
+	fault = handle_mm_fault(vma, address, flags);
 	pr_debug("handle_mm_fault returns %d\n", fault);
 
 	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current))

commit 70ffdb9393a7264a069265edded729078dcf0425
Author: David Hildenbrand <dahi@linux.vnet.ibm.com>
Date:   Mon May 11 17:52:11 2015 +0200

    mm/fault, arch: Use pagefault_disable() to check for disabled pagefaults in the handler
    
    Introduce faulthandler_disabled() and use it to check for irq context and
    disabled pagefaults (via pagefault_disable()) in the pagefault handlers.
    
    Please note that we keep the in_atomic() checks in place - to detect
    whether in irq context (in which case preemption is always properly
    disabled).
    
    In contrast, preempt_disable() should never be used to disable pagefaults.
    With !CONFIG_PREEMPT_COUNT, preempt_disable() doesn't modify the preempt
    counter, and therefore the result of in_atomic() differs.
    We validate that condition by using might_fault() checks when calling
    might_sleep().
    
    Therefore, add a comment to faulthandler_disabled(), describing why this
    is needed.
    
    faulthandler_disabled() and pagefault_disable() are defined in
    linux/uaccess.h, so let's properly add that include to all relevant files.
    
    This patch is based on a patch from Thomas Gleixner.
    
    Reviewed-and-tested-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Hildenbrand <dahi@linux.vnet.ibm.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: David.Laight@ACULAB.COM
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: airlied@linux.ie
    Cc: akpm@linux-foundation.org
    Cc: benh@kernel.crashing.org
    Cc: bigeasy@linutronix.de
    Cc: borntraeger@de.ibm.com
    Cc: daniel.vetter@intel.com
    Cc: heiko.carstens@de.ibm.com
    Cc: herbert@gondor.apana.org.au
    Cc: hocko@suse.cz
    Cc: hughd@google.com
    Cc: mst@redhat.com
    Cc: paulus@samba.org
    Cc: ralf@linux-mips.org
    Cc: schwidefsky@de.ibm.com
    Cc: yang.shi@windriver.com
    Link: http://lkml.kernel.org/r/1431359540-32227-7-git-send-email-dahi@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index b2f04aee46ec..6a94cdd0c830 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -10,10 +10,10 @@
 #include <linux/ptrace.h>
 #include <linux/interrupt.h>
 #include <linux/module.h>
+#include <linux/uaccess.h>
 
 #include <asm/setup.h>
 #include <asm/traps.h>
-#include <asm/uaccess.h>
 #include <asm/pgalloc.h>
 
 extern void die_if_kernel(char *, struct pt_regs *, long);
@@ -81,7 +81,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 	 * If we're in an interrupt or have no user
 	 * context, we must not take the fault..
 	 */
-	if (in_atomic() || !mm)
+	if (faulthandler_disabled() || !mm)
 		goto no_context;
 
 	if (user_mode(regs))

commit 33692f27597fcab536d7cbbcc8f52905133e4aa7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 29 10:51:32 2015 -0800

    vm: add VM_FAULT_SIGSEGV handling support
    
    The core VM already knows about VM_FAULT_SIGBUS, but cannot return a
    "you should SIGSEGV" error, because the SIGSEGV case was generally
    handled by the caller - usually the architecture fault handler.
    
    That results in lots of duplication - all the architecture fault
    handlers end up doing very similar "look up vma, check permissions, do
    retries etc" - but it generally works.  However, there are cases where
    the VM actually wants to SIGSEGV, and applications _expect_ SIGSEGV.
    
    In particular, when accessing the stack guard page, libsigsegv expects a
    SIGSEGV.  And it usually got one, because the stack growth is handled by
    that duplicated architecture fault handler.
    
    However, when the generic VM layer started propagating the error return
    from the stack expansion in commit fee7e49d4514 ("mm: propagate error
    from stack expansion even for guard page"), that now exposed the
    existing VM_FAULT_SIGBUS result to user space.  And user space really
    expected SIGSEGV, not SIGBUS.
    
    To fix that case, we need to add a VM_FAULT_SIGSEGV, and teach all those
    duplicate architecture fault handlers about it.  They all already have
    the code to handle SIGSEGV, so it's about just tying that new return
    value to the existing code, but it's all a bit annoying.
    
    This is the mindless minimal patch to do this.  A more extensive patch
    would be to try to gather up the mostly shared fault handling logic into
    one generic helper routine, and long-term we really should do that
    cleanup.
    
    Just from this patch, you can generally see that most architectures just
    copied (directly or indirectly) the old x86 way of doing things, but in
    the meantime that original x86 model has been improved to hold the VM
    semaphore for shorter times etc and to handle VM_FAULT_RETRY and other
    "newer" things, so it would be a good idea to bring all those
    improvements to the generic case and teach other architectures about
    them too.
    
    Reported-and-tested-by: Takashi Iwai <tiwai@suse.de>
    Tested-by: Jan Engelhardt <jengelh@inai.de>
    Acked-by: Heiko Carstens <heiko.carstens@de.ibm.com> # "s390 still compiles and boots"
    Cc: linux-arch@vger.kernel.org
    Cc: stable@vger.kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index 2bd7487440c4..b2f04aee46ec 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -145,6 +145,8 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 	if (unlikely(fault & VM_FAULT_ERROR)) {
 		if (fault & VM_FAULT_OOM)
 			goto out_of_memory;
+		else if (fault & VM_FAULT_SIGSEGV)
+			goto map_err;
 		else if (fault & VM_FAULT_SIGBUS)
 			goto bus_err;
 		BUG();

commit 8e398f638179d5968df41ad8eff8f27684454dc4
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Tue Dec 10 12:04:16 2013 +0100

    m68k: Convert arch/m68k/mm/fault.c to pr_*()
    
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index c7725f1de05d..2bd7487440c4 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -25,9 +25,8 @@ int send_fault_sig(struct pt_regs *regs)
 	siginfo.si_signo = current->thread.signo;
 	siginfo.si_code = current->thread.code;
 	siginfo.si_addr = (void *)current->thread.faddr;
-#ifdef DEBUG
-	printk("send_fault_sig: %p,%d,%d\n", siginfo.si_addr, siginfo.si_signo, siginfo.si_code);
-#endif
+	pr_debug("send_fault_sig: %p,%d,%d\n", siginfo.si_addr,
+		 siginfo.si_signo, siginfo.si_code);
 
 	if (user_mode(regs)) {
 		force_sig_info(siginfo.si_signo,
@@ -45,10 +44,10 @@ int send_fault_sig(struct pt_regs *regs)
 		 * terminate things with extreme prejudice.
 		 */
 		if ((unsigned long)siginfo.si_addr < PAGE_SIZE)
-			printk(KERN_ALERT "Unable to handle kernel NULL pointer dereference");
+			pr_alert("Unable to handle kernel NULL pointer dereference");
 		else
-			printk(KERN_ALERT "Unable to handle kernel access");
-		printk(" at virtual address %p\n", siginfo.si_addr);
+			pr_alert("Unable to handle kernel access");
+		pr_cont(" at virtual address %p\n", siginfo.si_addr);
 		die_if_kernel("Oops", regs, 0 /*error_code*/);
 		do_exit(SIGKILL);
 	}
@@ -75,10 +74,8 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 	int fault;
 	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
 
-#ifdef DEBUG
-	printk ("do page fault:\nregs->sr=%#x, regs->pc=%#lx, address=%#lx, %ld, %p\n",
+	pr_debug("do page fault:\nregs->sr=%#x, regs->pc=%#lx, address=%#lx, %ld, %p\n",
 		regs->sr, regs->pc, address, error_code, mm ? mm->pgd : NULL);
-#endif
 
 	/*
 	 * If we're in an interrupt or have no user
@@ -117,9 +114,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
  * we can handle it..
  */
 good_area:
-#ifdef DEBUG
-	printk("do_page_fault: good_area\n");
-#endif
+	pr_debug("do_page_fault: good_area\n");
 	switch (error_code & 3) {
 		default:	/* 3: write, present */
 			/* fall through */
@@ -142,9 +137,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 	 */
 
 	fault = handle_mm_fault(mm, vma, address, flags);
-#ifdef DEBUG
-	printk("handle_mm_fault returns %d\n",fault);
-#endif
+	pr_debug("handle_mm_fault returns %d\n", fault);
 
 	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current))
 		return 0;

commit 4e25c0e92f8eaf69bc51d1d523bcb7268e7dd162
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Tue Dec 10 11:35:47 2013 +0100

    m68k/mm: Check for mm != NULL in do_page_fault() debug code
    
    When DEBUG is enabled, do_page_fault() may dereference a NULL pointer,
    causing recursive bus errors.
    
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index eb1d61f68725..c7725f1de05d 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -77,8 +77,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 
 #ifdef DEBUG
 	printk ("do page fault:\nregs->sr=%#x, regs->pc=%#lx, address=%#lx, %ld, %p\n",
-		regs->sr, regs->pc, address, error_code,
-		current->mm->pgd);
+		regs->sr, regs->pc, address, error_code, mm ? mm->pgd : NULL);
 #endif
 
 	/*

commit 759496ba6407c6994d6a5ce3a5e74937d7816208
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Thu Sep 12 15:13:39 2013 -0700

    arch: mm: pass userspace fault flag to generic fault handler
    
    Unlike global OOM handling, memory cgroup code will invoke the OOM killer
    in any OOM situation because it has no way of telling faults occuring in
    kernel context - which could be handled more gracefully - from
    user-triggered faults.
    
    Pass a flag that identifies faults originating in user space from the
    architecture-specific fault handlers to generic code so that memcg OOM
    handling can be improved.
    
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Cc: David Rientjes <rientjes@google.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: azurIt <azurit@pobox.sk>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index a563727806bf..eb1d61f68725 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -88,6 +88,8 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 	if (in_atomic() || !mm)
 		goto no_context;
 
+	if (user_mode(regs))
+		flags |= FAULT_FLAG_USER;
 retry:
 	down_read(&mm->mmap_sem);
 

commit 45cac65b0fcd287ebb877b141d40ba9bbe8e5da7
Author: Shaohua Li <shli@kernel.org>
Date:   Mon Oct 8 16:32:19 2012 -0700

    readahead: fault retry breaks mmap file read random detection
    
    .fault now can retry.  The retry can break state machine of .fault.  In
    filemap_fault, if page is miss, ra->mmap_miss is increased.  In the second
    try, since the page is in page cache now, ra->mmap_miss is decreased.  And
    these are done in one fault, so we can't detect random mmap file access.
    
    Add a new flag to indicate .fault is tried once.  In the second try, skip
    ra->mmap_miss decreasing.  The filemap_fault state machine is ok with it.
    
    I only tested x86, didn't test other archs, but looks the change for other
    archs is obvious, but who knows :)
    
    Signed-off-by: Shaohua Li <shaohua.li@fusionio.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Wu Fengguang <fengguang.wu@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index aeebbb7b30f0..a563727806bf 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -170,6 +170,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 			/* Clear FAULT_FLAG_ALLOW_RETRY to avoid any risk
 			 * of starvation. */
 			flags &= ~FAULT_FLAG_ALLOW_RETRY;
+			flags |= FAULT_FLAG_TRIED;
 
 			/*
 			 * No need to up_read(&mm->mmap_sem) as we would

commit b637a6b16731d806ae2c8b9619a5619a2f283f15
Author: Kautuk Consul <consul.kautuk@gmail.com>
Date:   Sun Mar 25 06:37:48 2012 -0400

    m68k/mm: Port OOM changes to do_page_fault()
    
    Commit d065bd810b6deb67d4897a14bfe21f8eb526ba99
    (mm: retry page fault when blocking on disk transfer) and
    commit 37b23e0525d393d48a7d59f870b3bc061a30ccdb
    (x86,mm: make pagefault killable)
    
    The above commits introduced changes into the x86 pagefault handler
    for making the page fault handler retryable as well as killable.
    
    These changes reduce the mmap_sem hold time, which is crucial
    during OOM killer invocation.
    
    Port these changes to m68k.
    
    Signed-off-by: Kautuk Consul <consul.kautuk@gmail.com>
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index 6b020a8461e7..aeebbb7b30f0 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -72,7 +72,8 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 {
 	struct mm_struct *mm = current->mm;
 	struct vm_area_struct * vma;
-	int write, fault;
+	int fault;
+	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
 
 #ifdef DEBUG
 	printk ("do page fault:\nregs->sr=%#x, regs->pc=%#lx, address=%#lx, %ld, %p\n",
@@ -87,6 +88,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 	if (in_atomic() || !mm)
 		goto no_context;
 
+retry:
 	down_read(&mm->mmap_sem);
 
 	vma = find_vma(mm, address);
@@ -117,14 +119,13 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 #ifdef DEBUG
 	printk("do_page_fault: good_area\n");
 #endif
-	write = 0;
 	switch (error_code & 3) {
 		default:	/* 3: write, present */
 			/* fall through */
 		case 2:		/* write, not present */
 			if (!(vma->vm_flags & VM_WRITE))
 				goto acc_err;
-			write++;
+			flags |= FAULT_FLAG_WRITE;
 			break;
 		case 1:		/* read, present */
 			goto acc_err;
@@ -139,10 +140,14 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 	 * the fault.
 	 */
 
-	fault = handle_mm_fault(mm, vma, address, write ? FAULT_FLAG_WRITE : 0);
+	fault = handle_mm_fault(mm, vma, address, flags);
 #ifdef DEBUG
 	printk("handle_mm_fault returns %d\n",fault);
 #endif
+
+	if ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current))
+		return 0;
+
 	if (unlikely(fault & VM_FAULT_ERROR)) {
 		if (fault & VM_FAULT_OOM)
 			goto out_of_memory;
@@ -150,10 +155,31 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 			goto bus_err;
 		BUG();
 	}
-	if (fault & VM_FAULT_MAJOR)
-		current->maj_flt++;
-	else
-		current->min_flt++;
+
+	/*
+	 * Major/minor page fault accounting is only done on the
+	 * initial attempt. If we go through a retry, it is extremely
+	 * likely that the page will be found in page cache at that point.
+	 */
+	if (flags & FAULT_FLAG_ALLOW_RETRY) {
+		if (fault & VM_FAULT_MAJOR)
+			current->maj_flt++;
+		else
+			current->min_flt++;
+		if (fault & VM_FAULT_RETRY) {
+			/* Clear FAULT_FLAG_ALLOW_RETRY to avoid any risk
+			 * of starvation. */
+			flags &= ~FAULT_FLAG_ALLOW_RETRY;
+
+			/*
+			 * No need to up_read(&mm->mmap_sem) as we would
+			 * have already released it in __lock_page_or_retry
+			 * in mm/filemap.c.
+			 */
+
+			goto retry;
+		}
+	}
 
 	up_read(&mm->mmap_sem);
 	return 0;

commit 803f69144f0d48863c68f9d111b56849c7cef5bb
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:30:02 2012 +0100

    Disintegrate asm/system.h for M68K
    
    Disintegrate asm/system.h for M68K.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Greg Ungerer <gerg@uclinux.org>
    cc: linux-m68k@lists.linux-m68k.org

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index 2db6099784ba..6b020a8461e7 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -13,7 +13,6 @@
 
 #include <asm/setup.h>
 #include <asm/traps.h>
-#include <asm/system.h>
 #include <asm/uaccess.h>
 #include <asm/pgalloc.h>
 

commit dcdf3a293522e6ef09d8b3650ac1ceec56438e5d
Author: Roman Zippel <zippel@linux-m68k.org>
Date:   Tue Nov 18 21:25:17 2008 +0100

    m68k: Add helper function handle_kernel_fault()
    
    Add helper function handle_kernel_fault() in signal.c, so frame_extra_sizes
    can become static, and to avoid future code duplication.
    
    Signed-off-by: Roman Zippel <zippel@linux-m68k.org>
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index a96394a0333d..2db6099784ba 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -18,7 +18,6 @@
 #include <asm/pgalloc.h>
 
 extern void die_if_kernel(char *, struct pt_regs *, long);
-extern const int frame_extra_sizes[]; /* in m68k/kernel/signal.c */
 
 int send_fault_sig(struct pt_regs *regs)
 {
@@ -35,21 +34,8 @@ int send_fault_sig(struct pt_regs *regs)
 		force_sig_info(siginfo.si_signo,
 			       &siginfo, current);
 	} else {
-		const struct exception_table_entry *fixup;
-
-		/* Are we prepared to handle this kernel fault? */
-		if ((fixup = search_exception_tables(regs->pc))) {
-			struct pt_regs *tregs;
-			/* Create a new four word stack frame, discarding the old
-			   one.  */
-			regs->stkadj = frame_extra_sizes[regs->format];
-			tregs =	(struct pt_regs *)((ulong)regs + regs->stkadj);
-			tregs->vector = regs->vector;
-			tregs->format = 0;
-			tregs->pc = fixup->fixup;
-			tregs->sr = regs->sr;
+		if (handle_kernel_fault(regs))
 			return -1;
-		}
 
 		//if (siginfo.si_signo == SIGBUS)
 		//	force_sig_info(siginfo.si_signo,

commit adbf6e6952e80ae42a403442dcae21438cae94b3
Author: Nick Piggin <npiggin@suse.de>
Date:   Fri Apr 23 02:06:20 2010 +1000

    m68k: invoke oom-killer from page fault
    
    As explained in commit 1c0fe6e3bd, we want to call the architecture independent
    oom killer when getting an unexplained OOM from handle_mm_fault, rather than
    simply killing current.
    
    Cc: linux-m68k@lists.linux-m68k.org
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: linux-arch@vger.kernel.org
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Acked-by: David Rientjes <rientjes@google.com>
    [Geert] Kill 2 introduced compiler warnings
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index d0e35cf99fc6..a96394a0333d 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -154,7 +154,6 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 	 * the fault.
 	 */
 
- survive:
 	fault = handle_mm_fault(mm, vma, address, write ? FAULT_FLAG_WRITE : 0);
 #ifdef DEBUG
 	printk("handle_mm_fault returns %d\n",fault);
@@ -180,15 +179,10 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
  */
 out_of_memory:
 	up_read(&mm->mmap_sem);
-	if (is_global_init(current)) {
-		yield();
-		down_read(&mm->mmap_sem);
-		goto survive;
-	}
-
-	printk("VM: killing process %s\n", current->comm);
-	if (user_mode(regs))
-		do_group_exit(SIGKILL);
+	if (!user_mode(regs))
+		goto no_context;
+	pagefault_out_of_memory();
+	return 0;
 
 no_context:
 	current->thread.signo = SIGBUS;

commit d06063cc221fdefcab86589e79ddfdb7c0e14b63
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Apr 10 09:01:23 2009 -0700

    Move FAULT_FLAG_xyz into handle_mm_fault() callers
    
    This allows the callers to now pass down the full set of FAULT_FLAG_xyz
    flags to handle_mm_fault().  All callers have been (mechanically)
    converted to the new calling convention, there's almost certainly room
    for architectures to clean up their code and then add FAULT_FLAG_RETRY
    when that support is added.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index f493f03231d5..d0e35cf99fc6 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -155,7 +155,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 	 */
 
  survive:
-	fault = handle_mm_fault(mm, vma, address, write);
+	fault = handle_mm_fault(mm, vma, address, write ? FAULT_FLAG_WRITE : 0);
 #ifdef DEBUG
 	printk("handle_mm_fault returns %d\n",fault);
 #endif

commit b460cbc581a53cc088ceba80608021dd49c63c43
Author: Serge E. Hallyn <serue@us.ibm.com>
Date:   Thu Oct 18 23:39:52 2007 -0700

    pid namespaces: define is_global_init() and is_container_init()
    
    is_init() is an ambiguous name for the pid==1 check.  Split it into
    is_global_init() and is_container_init().
    
    A cgroup init has it's tsk->pid == 1.
    
    A global init also has it's tsk->pid == 1 and it's active pid namespace
    is the init_pid_ns.  But rather than check the active pid namespace,
    compare the task structure with 'init_pid_ns.child_reaper', which is
    initialized during boot to the /sbin/init process and never changes.
    
    Changelog:
    
            2.6.22-rc4-mm2-pidns1:
            - Use 'init_pid_ns.child_reaper' to determine if a given task is the
              global init (/sbin/init) process. This would improve performance
              and remove dependence on the task_pid().
    
            2.6.21-mm2-pidns2:
    
            - [Sukadev Bhattiprolu] Changed is_container_init() calls in {powerpc,
              ppc,avr32}/traps.c for the _exception() call to is_global_init().
              This way, we kill only the cgroup if the cgroup's init has a
              bug rather than force a kernel panic.
    
    [akpm@linux-foundation.org: fix comment]
    [sukadev@us.ibm.com: Use is_global_init() in arch/m32r/mm/fault.c]
    [bunk@stusta.de: kernel/pid.c: remove unused exports]
    [sukadev@us.ibm.com: Fix capability.c to work with threaded init]
    Signed-off-by: Serge E. Hallyn <serue@us.ibm.com>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Acked-by: Pavel Emelianov <xemul@openvz.org>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Herbert Poetzel <herbert@13thfloor.at>
    Cc: Kirill Korotaev <dev@sw.ru>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index eaa618681159..f493f03231d5 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -180,7 +180,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
  */
 out_of_memory:
 	up_read(&mm->mmap_sem);
-	if (is_init(current)) {
+	if (is_global_init(current)) {
 		yield();
 		down_read(&mm->mmap_sem);
 		goto survive;

commit dcca2bde4f86a14d3291660bede8f1844fe2b3df
Author: Will Schmidt <will_schmidt@vnet.ibm.com>
Date:   Tue Oct 16 01:24:18 2007 -0700

    During VM oom condition, kill all threads in process group
    
    We have had complaints where a threaded application is left in a bad state
    after one of it's threads is killed when we hit a VM: out_of_memory
    condition.
    
    Killing just one of the process threads can leave the application in a bad
    state, whereas killing the entire process group would allow for the
    application to restart, or be otherwise handled, and makes it very obvious
    that something has gone wrong.
    
    This change allows the entire process group to be taken down, rather
    than just the one thread.
    
    Signed-off-by: Will Schmidt <will_schmidt@vnet.ibm.com>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Ian Molton <spyro@f2s.com>
    Cc: Haavard Skinnemoen <hskinnemoen@atmel.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Andi Kleen <ak@suse.de>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Hirokazu Takata <takata@linux-m32r.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: Matthew Wilcox <willy@debian.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Kazumoto Kojima <kkojima@rr.iij4u.or.jp>
    Cc: Richard Curnow <rc@rc0.org.uk>
    Cc: William Lee Irwin III <wli@holomorphy.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Chris Zankel <chris@zankel.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index 578b48f47b9e..eaa618681159 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -188,7 +188,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 
 	printk("VM: killing process %s\n", current->comm);
 	if (user_mode(regs))
-		do_exit(SIGKILL);
+		do_group_exit(SIGKILL);
 
 no_context:
 	current->thread.signo = SIGBUS;

commit 83c54070ee1a2d05c89793884bea1a03f2851ed4
Author: Nick Piggin <npiggin@suse.de>
Date:   Thu Jul 19 01:47:05 2007 -0700

    mm: fault feedback #2
    
    This patch completes Linus's wish that the fault return codes be made into
    bit flags, which I agree makes everything nicer.  This requires requires
    all handle_mm_fault callers to be modified (possibly the modifications
    should go further and do things like fault accounting in handle_mm_fault --
    however that would be for another patch).
    
    [akpm@linux-foundation.org: fix alpha build]
    [akpm@linux-foundation.org: fix s390 build]
    [akpm@linux-foundation.org: fix sparc build]
    [akpm@linux-foundation.org: fix sparc64 build]
    [akpm@linux-foundation.org: fix ia64 build]
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Ian Molton <spyro@f2s.com>
    Cc: Bryan Wu <bryan.wu@analog.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Hirokazu Takata <takata@linux-m32r.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Cc: Greg Ungerer <gerg@uclinux.org>
    Cc: Matthew Wilcox <willy@debian.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Kazumoto Kojima <kkojima@rr.iij4u.or.jp>
    Cc: Richard Curnow <rc@rc0.org.uk>
    Cc: William Lee Irwin III <wli@holomorphy.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Paolo 'Blaisorblade' Giarrusso <blaisorblade@yahoo.it>
    Cc: Miles Bader <uclinux-v850@lsi.nec.co.jp>
    Cc: Chris Zankel <chris@zankel.net>
    Acked-by: Kyle McMartin <kyle@mcmartin.ca>
    Acked-by: Haavard Skinnemoen <hskinnemoen@atmel.com>
    Acked-by: Ralf Baechle <ralf@linux-mips.org>
    Acked-by: Andi Kleen <ak@muc.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    [ Still apparently needs some ARM and PPC loving - Linus ]
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index 2adbeb16e1b8..578b48f47b9e 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -159,18 +159,17 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 #ifdef DEBUG
 	printk("handle_mm_fault returns %d\n",fault);
 #endif
-	switch (fault) {
-	case VM_FAULT_MINOR:
-		current->min_flt++;
-		break;
-	case VM_FAULT_MAJOR:
-		current->maj_flt++;
-		break;
-	case VM_FAULT_SIGBUS:
-		goto bus_err;
-	default:
-		goto out_of_memory;
+	if (unlikely(fault & VM_FAULT_ERROR)) {
+		if (fault & VM_FAULT_OOM)
+			goto out_of_memory;
+		else if (fault & VM_FAULT_SIGBUS)
+			goto bus_err;
+		BUG();
 	}
+	if (fault & VM_FAULT_MAJOR)
+		current->maj_flt++;
+	else
+		current->min_flt++;
 
 	up_read(&mm->mmap_sem);
 	return 0;

commit 6edaf68a87d17570790fd55f0c451a29ec1d6703
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Wed Dec 6 20:32:18 2006 -0800

    [PATCH] mm: arch do_page_fault() vs in_atomic()
    
    In light of the recent pagefault and filemap_copy_from_user work I've gone
    through all the arch pagefault handlers to make sure the inc_preempt_count()
    'feature' works as expected.
    
    Several sections of code (including the new filemap_copy_from_user) rely on
    the fact that faults do not take locks under increased preempt count.
    
    arch/x86_64 - good
    arch/powerpc - good
    arch/cris - fixed
    arch/i386 - good
    arch/parisc - fixed
    arch/sh - good
    arch/sparc - good
    arch/s390 - good
    arch/m68k - fixed
    arch/ppc - good
    arch/alpha - fixed
    arch/mips - good
    arch/sparc64 - good
    arch/ia64 - good
    arch/arm - fixed
    arch/um - good
    arch/avr32 - good
    arch/h8300 - NA
    arch/m32r - good
    arch/v850 - good
    arch/frv - fixed
    arch/m68knommu - NA
    arch/arm26 - fixed
    arch/sh64 - fixed
    arch/xtensa - good
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Acked-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index 911f2ce3f53e..2adbeb16e1b8 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -99,7 +99,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 	 * If we're in an interrupt or have no user
 	 * context, we must not take the fault..
 	 */
-	if (in_interrupt() || !mm)
+	if (in_atomic() || !mm)
 		goto no_context;
 
 	down_read(&mm->mmap_sem);

commit f400e198b2ed26ce55b22a1412ded0896e7516ac
Author: Sukadev Bhattiprolu <sukadev@us.ibm.com>
Date:   Fri Sep 29 02:00:07 2006 -0700

    [PATCH] pidspace: is_init()
    
    This is an updated version of Eric Biederman's is_init() patch.
    (http://lkml.org/lkml/2006/2/6/280).  It applies cleanly to 2.6.18-rc3 and
    replaces a few more instances of ->pid == 1 with is_init().
    
    Further, is_init() checks pid and thus removes dependency on Eric's other
    patches for now.
    
    Eric's original description:
    
            There are a lot of places in the kernel where we test for init
            because we give it special properties.  Most  significantly init
            must not die.  This results in code all over the kernel test
            ->pid == 1.
    
            Introduce is_init to capture this case.
    
            With multiple pid spaces for all of the cases affected we are
            looking for only the first process on the system, not some other
            process that has pid == 1.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@us.ibm.com>
    Cc: Dave Hansen <haveblue@us.ibm.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Cc: Cedric Le Goater <clg@fr.ibm.com>
    Cc: <lxc-devel@lists.sourceforge.net>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index 5e2d87c10c87..911f2ce3f53e 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -181,7 +181,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
  */
 out_of_memory:
 	up_read(&mm->mmap_sem);
-	if (current->pid == 1) {
+	if (is_init(current)) {
 		yield();
 		down_read(&mm->mmap_sem);
 		goto survive;

commit df67b3daea602728b51325a4debaeeb912ee51d1
Author: Jason Baron <jbaron@redhat.com>
Date:   Fri Sep 29 01:58:58 2006 -0700

    [PATCH] make PROT_WRITE imply PROT_READ
    
    Make PROT_WRITE imply PROT_READ for a number of architectures which don't
    support write only in hardware.
    
    While looking at this, I noticed that some architectures which do not
    support write only mappings already take the exact same approach.  For
    example, in arch/alpha/mm/fault.c:
    
    "
            if (cause < 0) {
                    if (!(vma->vm_flags & VM_EXEC))
                            goto bad_area;
            } else if (!cause) {
                    /* Allow reads even for write-only mappings */
                    if (!(vma->vm_flags & (VM_READ | VM_WRITE)))
                            goto bad_area;
            } else {
                    if (!(vma->vm_flags & VM_WRITE))
                            goto bad_area;
            }
    "
    
    Thus, this patch brings other architectures which do not support write only
    mappings in-line and consistent with the rest.  I've verified the patch on
    ia64, x86_64 and x86.
    
    Additional discussion:
    
    Several architectures, including x86, can not support write-only mappings.
    The pte for x86 reserves a single bit for protection and its two states are
    read only or read/write.  Thus, write only is not supported in h/w.
    
    Currently, if i 'mmap' a page write-only, the first read attempt on that page
    creates a page fault and will SEGV.  That check is enforced in
    arch/blah/mm/fault.c.  However, if i first write that page it will fault in
    and the pte will be set to read/write.  Thus, any subsequent reads to the page
    will succeed.  It is this inconsistency in behavior that this patch is
    attempting to address.  Furthermore, if the page is swapped out, and then
    brought back the first read will also cause a SEGV.  Thus, any arbitrary read
    on a page can potentially result in a SEGV.
    
    According to the SuSv3 spec, "if the application requests only PROT_WRITE, the
    implementation may also allow read access." Also as mentioned, some
    archtectures, such as alpha, shown above already take the approach that i am
    suggesting.
    
    The counter-argument to this raised by Arjan, is that the kernel is enforcing
    the write only mapping the best it can given the h/w limitations.  This is
    true, however Alan Cox, and myself would argue that the inconsitency in
    behavior, that is applications can sometimes work/sometimes fails is highly
    undesireable.  If you read through the thread, i think people, came to an
    agreement on the last patch i posted, as nobody has objected to it...
    
    Signed-off-by: Jason Baron <jbaron@redhat.com>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Hugh Dickins <hugh@veritas.com>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Acked-by: Andi Kleen <ak@muc.de>
    Acked-by: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Acked-by: Paul Mundt <lethal@linux-sh.org>
    Cc: Kazumoto Kojima <kkojima@rr.iij4u.or.jp>
    Cc: Ian Molton <spyro@f2s.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index aec15270d334..5e2d87c10c87 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -144,7 +144,7 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 		case 1:		/* read, present */
 			goto acc_err;
 		case 0:		/* read, not present */
-			if (!(vma->vm_flags & (VM_READ | VM_EXEC)))
+			if (!(vma->vm_flags & (VM_READ | VM_EXEC | VM_WRITE)))
 				goto acc_err;
 	}
 

commit 6e346228c76506e07e297744a28464022c6806ad
Author: Linus Torvalds <torvalds@g5.osdl.org>
Date:   Thu Aug 4 08:33:38 2005 -0700

    It wasn't just x86-64 that had hardcoded VM_FAULT_xxx numbers
    
    Fix up arm26, cris, frv, m68k, parisc and sh64 too..

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
index ac48b6d2aff6..aec15270d334 100644
--- a/arch/m68k/mm/fault.c
+++ b/arch/m68k/mm/fault.c
@@ -160,13 +160,13 @@ int do_page_fault(struct pt_regs *regs, unsigned long address,
 	printk("handle_mm_fault returns %d\n",fault);
 #endif
 	switch (fault) {
-	case 1:
+	case VM_FAULT_MINOR:
 		current->min_flt++;
 		break;
-	case 2:
+	case VM_FAULT_MAJOR:
 		current->maj_flt++;
 		break;
-	case 0:
+	case VM_FAULT_SIGBUS:
 		goto bus_err;
 	default:
 		goto out_of_memory;

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/arch/m68k/mm/fault.c b/arch/m68k/mm/fault.c
new file mode 100644
index 000000000000..ac48b6d2aff6
--- /dev/null
+++ b/arch/m68k/mm/fault.c
@@ -0,0 +1,219 @@
+/*
+ *  linux/arch/m68k/mm/fault.c
+ *
+ *  Copyright (C) 1995  Hamish Macdonald
+ */
+
+#include <linux/mman.h>
+#include <linux/mm.h>
+#include <linux/kernel.h>
+#include <linux/ptrace.h>
+#include <linux/interrupt.h>
+#include <linux/module.h>
+
+#include <asm/setup.h>
+#include <asm/traps.h>
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/pgalloc.h>
+
+extern void die_if_kernel(char *, struct pt_regs *, long);
+extern const int frame_extra_sizes[]; /* in m68k/kernel/signal.c */
+
+int send_fault_sig(struct pt_regs *regs)
+{
+	siginfo_t siginfo = { 0, 0, 0, };
+
+	siginfo.si_signo = current->thread.signo;
+	siginfo.si_code = current->thread.code;
+	siginfo.si_addr = (void *)current->thread.faddr;
+#ifdef DEBUG
+	printk("send_fault_sig: %p,%d,%d\n", siginfo.si_addr, siginfo.si_signo, siginfo.si_code);
+#endif
+
+	if (user_mode(regs)) {
+		force_sig_info(siginfo.si_signo,
+			       &siginfo, current);
+	} else {
+		const struct exception_table_entry *fixup;
+
+		/* Are we prepared to handle this kernel fault? */
+		if ((fixup = search_exception_tables(regs->pc))) {
+			struct pt_regs *tregs;
+			/* Create a new four word stack frame, discarding the old
+			   one.  */
+			regs->stkadj = frame_extra_sizes[regs->format];
+			tregs =	(struct pt_regs *)((ulong)regs + regs->stkadj);
+			tregs->vector = regs->vector;
+			tregs->format = 0;
+			tregs->pc = fixup->fixup;
+			tregs->sr = regs->sr;
+			return -1;
+		}
+
+		//if (siginfo.si_signo == SIGBUS)
+		//	force_sig_info(siginfo.si_signo,
+		//		       &siginfo, current);
+
+		/*
+		 * Oops. The kernel tried to access some bad page. We'll have to
+		 * terminate things with extreme prejudice.
+		 */
+		if ((unsigned long)siginfo.si_addr < PAGE_SIZE)
+			printk(KERN_ALERT "Unable to handle kernel NULL pointer dereference");
+		else
+			printk(KERN_ALERT "Unable to handle kernel access");
+		printk(" at virtual address %p\n", siginfo.si_addr);
+		die_if_kernel("Oops", regs, 0 /*error_code*/);
+		do_exit(SIGKILL);
+	}
+
+	return 1;
+}
+
+/*
+ * This routine handles page faults.  It determines the problem, and
+ * then passes it off to one of the appropriate routines.
+ *
+ * error_code:
+ *	bit 0 == 0 means no page found, 1 means protection fault
+ *	bit 1 == 0 means read, 1 means write
+ *
+ * If this routine detects a bad access, it returns 1, otherwise it
+ * returns 0.
+ */
+int do_page_fault(struct pt_regs *regs, unsigned long address,
+			      unsigned long error_code)
+{
+	struct mm_struct *mm = current->mm;
+	struct vm_area_struct * vma;
+	int write, fault;
+
+#ifdef DEBUG
+	printk ("do page fault:\nregs->sr=%#x, regs->pc=%#lx, address=%#lx, %ld, %p\n",
+		regs->sr, regs->pc, address, error_code,
+		current->mm->pgd);
+#endif
+
+	/*
+	 * If we're in an interrupt or have no user
+	 * context, we must not take the fault..
+	 */
+	if (in_interrupt() || !mm)
+		goto no_context;
+
+	down_read(&mm->mmap_sem);
+
+	vma = find_vma(mm, address);
+	if (!vma)
+		goto map_err;
+	if (vma->vm_flags & VM_IO)
+		goto acc_err;
+	if (vma->vm_start <= address)
+		goto good_area;
+	if (!(vma->vm_flags & VM_GROWSDOWN))
+		goto map_err;
+	if (user_mode(regs)) {
+		/* Accessing the stack below usp is always a bug.  The
+		   "+ 256" is there due to some instructions doing
+		   pre-decrement on the stack and that doesn't show up
+		   until later.  */
+		if (address + 256 < rdusp())
+			goto map_err;
+	}
+	if (expand_stack(vma, address))
+		goto map_err;
+
+/*
+ * Ok, we have a good vm_area for this memory access, so
+ * we can handle it..
+ */
+good_area:
+#ifdef DEBUG
+	printk("do_page_fault: good_area\n");
+#endif
+	write = 0;
+	switch (error_code & 3) {
+		default:	/* 3: write, present */
+			/* fall through */
+		case 2:		/* write, not present */
+			if (!(vma->vm_flags & VM_WRITE))
+				goto acc_err;
+			write++;
+			break;
+		case 1:		/* read, present */
+			goto acc_err;
+		case 0:		/* read, not present */
+			if (!(vma->vm_flags & (VM_READ | VM_EXEC)))
+				goto acc_err;
+	}
+
+	/*
+	 * If for any reason at all we couldn't handle the fault,
+	 * make sure we exit gracefully rather than endlessly redo
+	 * the fault.
+	 */
+
+ survive:
+	fault = handle_mm_fault(mm, vma, address, write);
+#ifdef DEBUG
+	printk("handle_mm_fault returns %d\n",fault);
+#endif
+	switch (fault) {
+	case 1:
+		current->min_flt++;
+		break;
+	case 2:
+		current->maj_flt++;
+		break;
+	case 0:
+		goto bus_err;
+	default:
+		goto out_of_memory;
+	}
+
+	up_read(&mm->mmap_sem);
+	return 0;
+
+/*
+ * We ran out of memory, or some other thing happened to us that made
+ * us unable to handle the page fault gracefully.
+ */
+out_of_memory:
+	up_read(&mm->mmap_sem);
+	if (current->pid == 1) {
+		yield();
+		down_read(&mm->mmap_sem);
+		goto survive;
+	}
+
+	printk("VM: killing process %s\n", current->comm);
+	if (user_mode(regs))
+		do_exit(SIGKILL);
+
+no_context:
+	current->thread.signo = SIGBUS;
+	current->thread.faddr = address;
+	return send_fault_sig(regs);
+
+bus_err:
+	current->thread.signo = SIGBUS;
+	current->thread.code = BUS_ADRERR;
+	current->thread.faddr = address;
+	goto send_sig;
+
+map_err:
+	current->thread.signo = SIGSEGV;
+	current->thread.code = SEGV_MAPERR;
+	current->thread.faddr = address;
+	goto send_sig;
+
+acc_err:
+	current->thread.signo = SIGSEGV;
+	current->thread.code = SEGV_ACCERR;
+	current->thread.faddr = address;
+
+send_sig:
+	up_read(&mm->mmap_sem);
+	return send_fault_sig(regs);
+}
