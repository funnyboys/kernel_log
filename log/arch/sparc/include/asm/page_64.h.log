commit c62da0c35d58518ddb26ff641d2485596567fd96
Author: Anshuman Khandual <anshuman.khandual@arm.com>
Date:   Fri Apr 10 14:33:05 2020 -0700

    mm/vma: define a default value for VM_DATA_DEFAULT_FLAGS
    
    There are many platforms with exact same value for VM_DATA_DEFAULT_FLAGS
    This creates a default value for VM_DATA_DEFAULT_FLAGS in line with the
    existing VM_STACK_DEFAULT_FLAGS.  While here, also define some more
    macros with standard VMA access flag combinations that are used
    frequently across many platforms.  Apart from simplification, this
    reduces code duplication as well.
    
    Signed-off-by: Anshuman Khandual <anshuman.khandual@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Vlastimil Babka <vbabka@suse.cz>
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Paul Burton <paulburton@kernel.org>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: "James E.J. Bottomley" <James.Bottomley@HansenPartnership.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Rich Felker <dalias@libc.org>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Chris Zankel <chris@zankel.net>
    Link: http://lkml.kernel.org/r/1583391014-8170-2-git-send-email-anshuman.khandual@arm.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index e80f2d5bf62f..254dffd85fb1 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -158,9 +158,6 @@ extern unsigned long PAGE_OFFSET;
 
 #endif /* !(__ASSEMBLY__) */
 
-#define VM_DATA_DEFAULT_FLAGS	(VM_READ | VM_WRITE | VM_EXEC | \
-				 VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC)
-
 #include <asm-generic/getorder.h>
 
 #endif /* _SPARC64_PAGE_H */

commit 74a04967482faa7144b93dae3b2e913870dd421c
Author: Khalid Aziz <khalid.aziz@oracle.com>
Date:   Fri Feb 23 15:46:41 2018 -0700

    sparc64: Add support for ADI (Application Data Integrity)
    
    ADI is a new feature supported on SPARC M7 and newer processors to allow
    hardware to catch rogue accesses to memory. ADI is supported for data
    fetches only and not instruction fetches. An app can enable ADI on its
    data pages, set version tags on them and use versioned addresses to
    access the data pages. Upper bits of the address contain the version
    tag. On M7 processors, upper four bits (bits 63-60) contain the version
    tag. If a rogue app attempts to access ADI enabled data pages, its
    access is blocked and processor generates an exception. Please see
    Documentation/sparc/adi.txt for further details.
    
    This patch extends mprotect to enable ADI (TSTATE.mcde), enable/disable
    MCD (Memory Corruption Detection) on selected memory ranges, enable
    TTE.mcd in PTEs, return ADI parameters to userspace and save/restore ADI
    version tags on page swap out/in or migration. ADI is not enabled by
    default for any task. A task must explicitly enable ADI on a memory
    range and set version tag for ADI to be effective for the task.
    
    Signed-off-by: Khalid Aziz <khalid.aziz@oracle.com>
    Cc: Khalid Aziz <khalid@gonehiking.org>
    Reviewed-by: Anthony Yznaga <anthony.yznaga@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index c28379b1b0fc..e80f2d5bf62f 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -48,6 +48,12 @@ struct page;
 void clear_user_page(void *addr, unsigned long vaddr, struct page *page);
 #define copy_page(X,Y)	memcpy((void *)(X), (void *)(Y), PAGE_SIZE)
 void copy_user_page(void *to, void *from, unsigned long vaddr, struct page *topage);
+#define __HAVE_ARCH_COPY_USER_HIGHPAGE
+struct vm_area_struct;
+void copy_user_highpage(struct page *to, struct page *from,
+			unsigned long vaddr, struct vm_area_struct *vma);
+#define __HAVE_ARCH_COPY_HIGHPAGE
+void copy_highpage(struct page *to, struct page *from);
 
 /* Unlike sparc32, sparc64's parameter passing API is more
  * sane in that structures which as small enough are passed

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index 8ee1f97589a1..c28379b1b0fc 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _SPARC64_PAGE_H
 #define _SPARC64_PAGE_H
 

commit df7b2155bbe75525531e47c8a67ae4f1dbbae976
Author: Nitin Gupta <nitin.m.gupta@oracle.com>
Date:   Fri Aug 11 16:46:50 2017 -0700

    sparc64: Add 16GB hugepage support
    
    Adds support for 16GB hugepage size. To use this page size
    use kernel parameters as:
    
    default_hugepagesz=16G hugepagesz=16G hugepages=10
    
    Testing:
    
    Tested with the stream benchmark which allocates 48G of
    arrays backed by 16G hugepages and does RW operation on
    them in parallel.
    
    Orabug: 25362942
    
    Cc: Anthony Yznaga <anthony.yznaga@oracle.com>
    Reviewed-by: Bob Picco <bob.picco@oracle.com>
    Signed-off-by: Nitin Gupta <nitin.m.gupta@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index 5961b2d8398a..8ee1f97589a1 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -17,6 +17,7 @@
 
 #define HPAGE_SHIFT		23
 #define REAL_HPAGE_SHIFT	22
+#define HPAGE_16GB_SHIFT	34
 #define HPAGE_2GB_SHIFT		31
 #define HPAGE_256MB_SHIFT	28
 #define HPAGE_64K_SHIFT		16
@@ -28,7 +29,7 @@
 #define HUGETLB_PAGE_ORDER	(HPAGE_SHIFT - PAGE_SHIFT)
 #define HAVE_ARCH_HUGETLB_UNMAPPED_AREA
 #define REAL_HPAGE_PER_HPAGE	(_AC(1,UL) << (HPAGE_SHIFT - REAL_HPAGE_SHIFT))
-#define HUGE_MAX_HSTATE		4
+#define HUGE_MAX_HSTATE		5
 #endif
 
 #ifndef __ASSEMBLY__

commit 4d9fbf539b52810cd2903719b181ed3d3ccd861f
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Aug 10 09:49:15 2017 -0700

    sparc64: Revert 16GB huge page support.
    
    It overflows the amount of space available in the initial .text section
    of trap handler assembler in some configurations, resulting in build
    failures.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index 8ee1f97589a1..5961b2d8398a 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -17,7 +17,6 @@
 
 #define HPAGE_SHIFT		23
 #define REAL_HPAGE_SHIFT	22
-#define HPAGE_16GB_SHIFT	34
 #define HPAGE_2GB_SHIFT		31
 #define HPAGE_256MB_SHIFT	28
 #define HPAGE_64K_SHIFT		16
@@ -29,7 +28,7 @@
 #define HUGETLB_PAGE_ORDER	(HPAGE_SHIFT - PAGE_SHIFT)
 #define HAVE_ARCH_HUGETLB_UNMAPPED_AREA
 #define REAL_HPAGE_PER_HPAGE	(_AC(1,UL) << (HPAGE_SHIFT - REAL_HPAGE_SHIFT))
-#define HUGE_MAX_HSTATE		5
+#define HUGE_MAX_HSTATE		4
 #endif
 
 #ifndef __ASSEMBLY__

commit f10bb00790dd3cf550f7ae6991c4d1a128802c00
Author: Nitin Gupta <nitin.m.gupta@oracle.com>
Date:   Sat Jul 29 11:42:18 2017 -0700

    sparc64: Add 16GB hugepage support
    
    Adds support for 16GB hugepage size. To use this page size
    use kernel parameters as:
    
    default_hugepagesz=16G hugepagesz=16G hugepages=10
    
    Testing:
    
    Tested with the stream benchmark which allocates 48G of
    arrays backed by 16G hugepages and does RW operation on
    them in parallel.
    
    Orabug: 25362942
    
    Signed-off-by: Nitin Gupta <nitin.m.gupta@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index 5961b2d8398a..8ee1f97589a1 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -17,6 +17,7 @@
 
 #define HPAGE_SHIFT		23
 #define REAL_HPAGE_SHIFT	22
+#define HPAGE_16GB_SHIFT	34
 #define HPAGE_2GB_SHIFT		31
 #define HPAGE_256MB_SHIFT	28
 #define HPAGE_64K_SHIFT		16
@@ -28,7 +29,7 @@
 #define HUGETLB_PAGE_ORDER	(HPAGE_SHIFT - PAGE_SHIFT)
 #define HAVE_ARCH_HUGETLB_UNMAPPED_AREA
 #define REAL_HPAGE_PER_HPAGE	(_AC(1,UL) << (HPAGE_SHIFT - REAL_HPAGE_SHIFT))
-#define HUGE_MAX_HSTATE		4
+#define HUGE_MAX_HSTATE		5
 #endif
 
 #ifndef __ASSEMBLY__

commit 85b1da7c47052330af9485a5f5c7e54ede882e65
Author: Nitin Gupta <nitin.m.gupta@oracle.com>
Date:   Thu Mar 9 14:22:23 2017 -0800

    sparc64: Add support for 2G hugepages
    
    Signed-off-by: Nitin Gupta <nitin.m.gupta@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index f294dd42fc7d..5961b2d8398a 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -17,6 +17,7 @@
 
 #define HPAGE_SHIFT		23
 #define REAL_HPAGE_SHIFT	22
+#define HPAGE_2GB_SHIFT		31
 #define HPAGE_256MB_SHIFT	28
 #define HPAGE_64K_SHIFT		16
 #define REAL_HPAGE_SIZE		(_AC(1,UL) << REAL_HPAGE_SHIFT)
@@ -27,7 +28,7 @@
 #define HUGETLB_PAGE_ORDER	(HPAGE_SHIFT - PAGE_SHIFT)
 #define HAVE_ARCH_HUGETLB_UNMAPPED_AREA
 #define REAL_HPAGE_PER_HPAGE	(_AC(1,UL) << (HPAGE_SHIFT - REAL_HPAGE_SHIFT))
-#define HUGE_MAX_HSTATE		3
+#define HUGE_MAX_HSTATE		4
 #endif
 
 #ifndef __ASSEMBLY__

commit dcd1912d21a02534d1f0a9005d5ba3283f164780
Author: Nitin Gupta <nitin.m.gupta@oracle.com>
Date:   Mon Feb 6 12:33:26 2017 -0800

    sparc64: Add 64K page size support
    
    This patch depends on:
    [v6] sparc64: Multi-page size support
    
    - Testing
    
    Tested on Sonoma by running stream benchmark instance which allocated
    48G worth of 64K pages.
    
    boot params: default_hugepagesz=64K hugepagesz=64K hugepages=1310720
    
    Signed-off-by: Nitin Gupta <nitin.m.gupta@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index d76f38d4171b..f294dd42fc7d 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -18,6 +18,7 @@
 #define HPAGE_SHIFT		23
 #define REAL_HPAGE_SHIFT	22
 #define HPAGE_256MB_SHIFT	28
+#define HPAGE_64K_SHIFT		16
 #define REAL_HPAGE_SIZE		(_AC(1,UL) << REAL_HPAGE_SHIFT)
 
 #if defined(CONFIG_HUGETLB_PAGE) || defined(CONFIG_TRANSPARENT_HUGEPAGE)
@@ -26,7 +27,7 @@
 #define HUGETLB_PAGE_ORDER	(HPAGE_SHIFT - PAGE_SHIFT)
 #define HAVE_ARCH_HUGETLB_UNMAPPED_AREA
 #define REAL_HPAGE_PER_HPAGE	(_AC(1,UL) << (HPAGE_SHIFT - REAL_HPAGE_SHIFT))
-#define HUGE_MAX_HSTATE		2
+#define HUGE_MAX_HSTATE		3
 #endif
 
 #ifndef __ASSEMBLY__

commit c7d9f77d33a779ad582d8b2284ba007931ebd894
Author: Nitin Gupta <nitin.m.gupta@oracle.com>
Date:   Wed Feb 1 16:16:36 2017 -0800

    sparc64: Multi-page size support
    
    Add support for using multiple hugepage sizes simultaneously
    on mainline. Currently, support for 256M has been added which
    can be used along with 8M pages.
    
    Page tables are set like this (e.g. for 256M page):
        VA + (8M * x) -> PA + (8M * x) (sz bit = 256M) where x in [0, 31]
    
    and TSB is set similarly:
        VA + (4M * x) -> PA + (4M * x) (sz bit = 256M) where x in [0, 63]
    
    - Testing
    
    Tested on Sonoma (which supports 256M pages) by running stream
    benchmark instances in parallel: one instance uses 8M pages and
    another uses 256M pages, consuming 48G each.
    
    Boot params used:
    
    default_hugepagesz=256M hugepagesz=256M hugepages=300 hugepagesz=8M
    hugepages=10000
    
    Signed-off-by: Nitin Gupta <nitin.m.gupta@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index c1263fc390db..d76f38d4171b 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -17,7 +17,7 @@
 
 #define HPAGE_SHIFT		23
 #define REAL_HPAGE_SHIFT	22
-
+#define HPAGE_256MB_SHIFT	28
 #define REAL_HPAGE_SIZE		(_AC(1,UL) << REAL_HPAGE_SHIFT)
 
 #if defined(CONFIG_HUGETLB_PAGE) || defined(CONFIG_TRANSPARENT_HUGEPAGE)
@@ -26,6 +26,7 @@
 #define HUGETLB_PAGE_ORDER	(HPAGE_SHIFT - PAGE_SHIFT)
 #define HAVE_ARCH_HUGETLB_UNMAPPED_AREA
 #define REAL_HPAGE_PER_HPAGE	(_AC(1,UL) << (HPAGE_SHIFT - REAL_HPAGE_SHIFT))
+#define HUGE_MAX_HSTATE		2
 #endif
 
 #ifndef __ASSEMBLY__

commit 1e953d846ac015fbfcf09c857e8f893924cb629c
Author: Mike Kravetz <mike.kravetz@oracle.com>
Date:   Wed Aug 31 13:48:19 2016 -0700

    sparc64 mm: Fix more TSB sizing issues
    
    Commit af1b1a9b36b8 ("sparc64 mm: Fix base TSB sizing when hugetlb
    pages are used") addressed the difference between hugetlb and THP
    pages when computing TSB sizes.  The following additional issues
    were also discovered while working with the code.
    
    In order to save memory, THP makes use of a huge zero page.  This huge
    zero page does not count against a task's RSS, but it does consume TSB
    entries.  This is similar to hugetlb pages.  Therefore, count huge
    zero page entries in hugetlb_pte_count.
    
    Accounting of THP pages is done in the routine set_pmd_at().
    Unfortunately, this does not catch the case where a THP page is split.
    To handle this case, decrement the count in pmdp_invalidate().
    pmdp_invalidate is only called when splitting a THP.  However, 'sanity
    checks' are added in case it is ever called for other purposes.
    
    A more general issue exists with HPAGE_SIZE accounting.
    hugetlb_pte_count tracks the number of HPAGE_SIZE (8M) pages.  This
    value is used to size the TSB for HPAGE_SIZE pages.  However,
    each HPAGE_SIZE page consists of two REAL_HPAGE_SIZE (4M) pages.
    The TSB contains an entry for each REAL_HPAGE_SIZE page.  Therefore,
    the number of REAL_HPAGE_SIZE pages should be used to size the huge
    page TSB.  A new compile time constant REAL_HPAGE_PER_HPAGE is used
    to multiply hugetlb_pte_count before sizing the TSB.
    
    Changes from V1
    - Fixed build issue if hugetlb or THP not configured
    
    Signed-off-by: Mike Kravetz <mike.kravetz@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index 8c2a8c937540..c1263fc390db 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -25,6 +25,7 @@
 #define HPAGE_MASK		(~(HPAGE_SIZE - 1UL))
 #define HUGETLB_PAGE_ORDER	(HPAGE_SHIFT - PAGE_SHIFT)
 #define HAVE_ARCH_HUGETLB_UNMAPPED_AREA
+#define REAL_HPAGE_PER_HPAGE	(_AC(1,UL) << (HPAGE_SHIFT - REAL_HPAGE_SHIFT))
 #endif
 
 #ifndef __ASSEMBLY__

commit bb4e6e85daa52a9f6210fa06a5ec6269598a202b
Author: David S. Miller <davem@davemloft.net>
Date:   Sat Sep 27 11:05:21 2014 -0700

    sparc64: Adjust vmalloc region size based upon available virtual address bits.
    
    In order to accomodate embedded per-cpu allocation with large numbers
    of cpus and numa nodes, we have to use as much virtual address space
    as possible for the vmalloc region.  Otherwise we can get things like:
    
    PERCPU: max_distance=0x380001c10000 too large for vmalloc space 0xff00000000
    
    So, once we select a value for PAGE_OFFSET, derive the size of the
    vmalloc region based upon that.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Acked-by: Bob Picco <bob.picco@oracle.com>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index 6784a3382826..8c2a8c937540 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -117,7 +117,6 @@ extern unsigned long sparc64_va_hole_bottom;
 
 #include <asm-generic/memory_model.h>
 
-#define PAGE_OFFSET_BY_BITS(X)	(-(_AC(1,UL) << (X)))
 extern unsigned long PAGE_OFFSET;
 
 #endif /* !(__ASSEMBLY__) */

commit 7c0fa0f24bb76ce3d67be7f737b799846a04570f
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Sep 24 21:49:29 2014 -0700

    sparc64: Increase MAX_PHYS_ADDRESS_BITS to 53.
    
    Make sure, at compile time, that the kernel can properly support
    whatever MAX_PHYS_ADDRESS_BITS is defined to.
    
    On M7 chips, use a max_phys_bits value of 49.
    
    Based upon a patch by Bob Picco.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Acked-by: Bob Picco <bob.picco@oracle.com>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index 732ba178a289..6784a3382826 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -122,11 +122,11 @@ extern unsigned long PAGE_OFFSET;
 
 #endif /* !(__ASSEMBLY__) */
 
-/* The maximum number of physical memory address bits we support, this
- * is used to size various tables used to manage kernel TLB misses and
- * also the sparsemem code.
+/* The maximum number of physical memory address bits we support.  The
+ * largest value we can support is whatever "KPGD_SHIFT + KPTE_BITS"
+ * evaluates to.
  */
-#define MAX_PHYS_ADDRESS_BITS	47
+#define MAX_PHYS_ADDRESS_BITS	53
 
 #define ILOG2_4MB		22
 #define ILOG2_256MB		28

commit 0dd5b7b09e13dae32869371e08e1048349fd040c
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Sep 24 20:56:11 2014 -0700

    sparc64: Fix physical memory management regressions with large max_phys_bits.
    
    If max_phys_bits needs to be > 43 (f.e. for T4 chips), things like
    DEBUG_PAGEALLOC stop working because the 3-level page tables only
    can cover up to 43 bits.
    
    Another problem is that when we increased MAX_PHYS_ADDRESS_BITS up to
    47, several statically allocated tables became enormous.
    
    Compounding this is that we will need to support up to 49 bits of
    physical addressing for M7 chips.
    
    The two tables in question are sparc64_valid_addr_bitmap and
    kpte_linear_bitmap.
    
    The first holds a bitmap, with 1 bit for each 4MB chunk of physical
    memory, indicating whether that chunk actually exists in the machine
    and is valid.
    
    The second table is a set of 2-bit values which tell how large of a
    mapping (4MB, 256MB, 2GB, 16GB, respectively) we can use at each 256MB
    chunk of ram in the system.
    
    These tables are huge and take up an enormous amount of the BSS
    section of the sparc64 kernel image.  Specifically, the
    sparc64_valid_addr_bitmap is 4MB, and the kpte_linear_bitmap is 128K.
    
    So let's solve the space wastage and the DEBUG_PAGEALLOC problem
    at the same time, by using the kernel page tables (as designed) to
    manage this information.
    
    We have to keep using large mappings when DEBUG_PAGEALLOC is disabled,
    and we do this by encoding huge PMDs and PUDs.
    
    On a T4-2 with 256GB of ram the kernel page table takes up 16K with
    DEBUG_PAGEALLOC disabled and 256MB with it enabled.  Furthermore, this
    memory is dynamically allocated at run time rather than coded
    statically into the kernel image.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Acked-by: Bob Picco <bob.picco@oracle.com>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index 2211a8036bfa..732ba178a289 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -128,9 +128,6 @@ extern unsigned long PAGE_OFFSET;
  */
 #define MAX_PHYS_ADDRESS_BITS	47
 
-/* These two shift counts are used when indexing sparc64_valid_addr_bitmap
- * and kpte_linear_bitmap.
- */
 #define ILOG2_4MB		22
 #define ILOG2_256MB		28
 

commit 4397bed080598001e88f612deb8b080bb1cc2322
Author: David S. Miller <davem@davemloft.net>
Date:   Fri Sep 26 21:58:33 2014 -0700

    sparc64: Define VA hole at run time, rather than at compile time.
    
    Now that we use 4-level page tables, we can provide up to 53-bits of
    virtual address space to the user.
    
    Adjust the VA hole based upon the capabilities of the cpu type probed.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Acked-by: Bob Picco <bob.picco@oracle.com>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index 09ceb68e72b7..2211a8036bfa 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -102,21 +102,14 @@ typedef unsigned long pgprot_t;
 
 typedef pte_t *pgtable_t;
 
-/* These two values define the virtual address space range in which we
- * must forbid 64-bit user processes from making mappings.  It used to
- * represent precisely the virtual address space hole present in most
- * early sparc64 chips including UltraSPARC-I.  But now it also is
- * further constrained by the limits of our page tables, which is
- * 43-bits of virtual address.
- */
-#define SPARC64_VA_HOLE_TOP	_AC(0xfffffc0000000000,UL)
-#define SPARC64_VA_HOLE_BOTTOM	_AC(0x0000040000000000,UL)
+extern unsigned long sparc64_va_hole_top;
+extern unsigned long sparc64_va_hole_bottom;
 
 /* The next two defines specify the actual exclusion region we
  * enforce, wherein we use a 4GB red zone on each side of the VA hole.
  */
-#define VA_EXCLUDE_START (SPARC64_VA_HOLE_BOTTOM - (1UL << 32UL))
-#define VA_EXCLUDE_END   (SPARC64_VA_HOLE_TOP + (1UL << 32UL))
+#define VA_EXCLUDE_START (sparc64_va_hole_bottom - (1UL << 32UL))
+#define VA_EXCLUDE_END   (sparc64_va_hole_top + (1UL << 32UL))
 
 #define TASK_UNMAPPED_BASE	(test_thread_flag(TIF_32BIT) ? \
 				 _AC(0x0000000070000000,UL) : \

commit ac55c768143aa34cc3789c4820cbb0809a76fd9c
Author: David S. Miller <davem@davemloft.net>
Date:   Fri Sep 26 21:19:46 2014 -0700

    sparc64: Switch to 4-level page tables.
    
    This has become necessary with chips that support more than 43-bits
    of physical addressing.
    
    Based almost entirely upon a patch by Bob Picco.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Acked-by: Bob Picco <bob.picco@oracle.com>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index bf109984a032..09ceb68e72b7 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -57,18 +57,21 @@ void copy_user_page(void *to, void *from, unsigned long vaddr, struct page *topa
 typedef struct { unsigned long pte; } pte_t;
 typedef struct { unsigned long iopte; } iopte_t;
 typedef struct { unsigned long pmd; } pmd_t;
+typedef struct { unsigned long pud; } pud_t;
 typedef struct { unsigned long pgd; } pgd_t;
 typedef struct { unsigned long pgprot; } pgprot_t;
 
 #define pte_val(x)	((x).pte)
 #define iopte_val(x)	((x).iopte)
 #define pmd_val(x)      ((x).pmd)
+#define pud_val(x)      ((x).pud)
 #define pgd_val(x)	((x).pgd)
 #define pgprot_val(x)	((x).pgprot)
 
 #define __pte(x)	((pte_t) { (x) } )
 #define __iopte(x)	((iopte_t) { (x) } )
 #define __pmd(x)        ((pmd_t) { (x) } )
+#define __pud(x)        ((pud_t) { (x) } )
 #define __pgd(x)	((pgd_t) { (x) } )
 #define __pgprot(x)	((pgprot_t) { (x) } )
 
@@ -77,18 +80,21 @@ typedef struct { unsigned long pgprot; } pgprot_t;
 typedef unsigned long pte_t;
 typedef unsigned long iopte_t;
 typedef unsigned long pmd_t;
+typedef unsigned long pud_t;
 typedef unsigned long pgd_t;
 typedef unsigned long pgprot_t;
 
 #define pte_val(x)	(x)
 #define iopte_val(x)	(x)
 #define pmd_val(x)      (x)
+#define pud_val(x)      (x)
 #define pgd_val(x)	(x)
 #define pgprot_val(x)	(x)
 
 #define __pte(x)	(x)
 #define __iopte(x)	(x)
 #define __pmd(x)        (x)
+#define __pud(x)        (x)
 #define __pgd(x)	(x)
 #define __pgprot(x)	(x)
 

commit f05a68653e56ca2f23bccf7e50be69486886f052
Author: Sam Ravnborg <sam@ravnborg.org>
Date:   Fri May 16 23:25:50 2014 +0200

    sparc: drop use of extern for prototypes in arch/sparc/include/asm
    
    Drop extern for all prototypes and adjust alignment of parameters
    as required after the removal.
    In a few rare cases adjust linelength to conform to maximum 80 chars,
    and likewise in a few rare cases adjust alignment of parameters
    to static functions.
    
    Signed-off-by: Sam Ravnborg <sam@ravnborg.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index aac53fcea807..bf109984a032 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -31,17 +31,17 @@
 
 #if defined(CONFIG_HUGETLB_PAGE) || defined(CONFIG_TRANSPARENT_HUGEPAGE)
 struct pt_regs;
-extern void hugetlb_setup(struct pt_regs *regs);
+void hugetlb_setup(struct pt_regs *regs);
 #endif
 
 #define WANT_PAGE_VIRTUAL
 
-extern void _clear_page(void *page);
+void _clear_page(void *page);
 #define clear_page(X)	_clear_page((void *)(X))
 struct page;
-extern void clear_user_page(void *addr, unsigned long vaddr, struct page *page);
+void clear_user_page(void *addr, unsigned long vaddr, struct page *page);
 #define copy_page(X,Y)	memcpy((void *)(X), (void *)(Y), PAGE_SIZE)
-extern void copy_user_page(void *to, void *from, unsigned long vaddr, struct page *topage);
+void copy_user_page(void *to, void *from, unsigned long vaddr, struct page *topage);
 
 /* Unlike sparc32, sparc64's parameter passing API is more
  * sane in that structures which as small enough are passed

commit 2b77933c28f5044629bb19e8045aae65b72b939d
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Sep 25 14:33:16 2013 -0700

    sparc64: Move to 64-bit PGDs and PMDs.
    
    To make the page tables compact, we were using 32-bit PGDs and PMDs.
    We only had to support <= 43 bits of physical addresses so this was
    quite feasible.
    
    In order to support larger physical addresses we have to move to
    64-bit PGDs and PMDs.
    
    Most of the changes are straight-forward:
    
    1) {pgd,pmd}_t --> unsigned long
    
    2) Anything that tries to use plain "unsigned int" types with pgd/pmd
       values needs to be adjusted.  In particular things like "0U" become
       "0UL".
    
    3) {PGDIR,PMD}_BITS decrease by one.
    
    4) In the assembler page table walkers, use "ldxa" instead of "lduwa"
       and adjust the low bit masks to clear out the low 3 bits instead of
       just the low 2 bits during pgd/pmd address formation.
    
    Also, use PTRS_PER_PGD and PTRS_PER_PMD in the sizing of the
    swapper_{pg_dir,low_pmd_dir} arrays.
    
    This patch does not try to take advantage of having 64-bits in the
    PMDs to simplify the hugepage code, that will come in a subsequent
    change.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index 1958bfbe300c..aac53fcea807 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -56,8 +56,8 @@ extern void copy_user_page(void *to, void *from, unsigned long vaddr, struct pag
 /* These are used to make use of C type-checking.. */
 typedef struct { unsigned long pte; } pte_t;
 typedef struct { unsigned long iopte; } iopte_t;
-typedef struct { unsigned int pmd; } pmd_t;
-typedef struct { unsigned int pgd; } pgd_t;
+typedef struct { unsigned long pmd; } pmd_t;
+typedef struct { unsigned long pgd; } pgd_t;
 typedef struct { unsigned long pgprot; } pgprot_t;
 
 #define pte_val(x)	((x).pte)
@@ -76,8 +76,8 @@ typedef struct { unsigned long pgprot; } pgprot_t;
 /* .. while these make it easier on the compiler */
 typedef unsigned long pte_t;
 typedef unsigned long iopte_t;
-typedef unsigned int pmd_t;
-typedef unsigned int pgd_t;
+typedef unsigned long pmd_t;
+typedef unsigned long pgd_t;
 typedef unsigned long pgprot_t;
 
 #define pte_val(x)	(x)
@@ -97,15 +97,18 @@ typedef unsigned long pgprot_t;
 typedef pte_t *pgtable_t;
 
 /* These two values define the virtual address space range in which we
- * must forbid 64-bit user processes from making mappings.  It
- * represents the virtual address space hole present in most early
- * sparc64 chips including UltraSPARC-I.  The next two defines specify
- * the actual exclusion region we enforce, wherein we use a 4GB red
- * zone on each side of the VA hole.
+ * must forbid 64-bit user processes from making mappings.  It used to
+ * represent precisely the virtual address space hole present in most
+ * early sparc64 chips including UltraSPARC-I.  But now it also is
+ * further constrained by the limits of our page tables, which is
+ * 43-bits of virtual address.
  */
-#define SPARC64_VA_HOLE_TOP	_AC(0xfffff80000000000,UL)
-#define SPARC64_VA_HOLE_BOTTOM	_AC(0x0000080000000000,UL)
+#define SPARC64_VA_HOLE_TOP	_AC(0xfffffc0000000000,UL)
+#define SPARC64_VA_HOLE_BOTTOM	_AC(0x0000040000000000,UL)
 
+/* The next two defines specify the actual exclusion region we
+ * enforce, wherein we use a 4GB red zone on each side of the VA hole.
+ */
 #define VA_EXCLUDE_START (SPARC64_VA_HOLE_BOTTOM - (1UL << 32UL))
 #define VA_EXCLUDE_END   (SPARC64_VA_HOLE_TOP + (1UL << 32UL))
 

commit 37b3a8ff3e086cd5c369e77d2383b691b2874cd6
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Sep 25 13:48:49 2013 -0700

    sparc64: Move from 4MB to 8MB huge pages.
    
    The impetus for this is that we would like to move to 64-bit PMDs and
    PGDs, but that would result in only supporting a 42-bit address space
    with the current page table layout.  It'd be nice to support at least
    43-bits.
    
    The reason we'd end up with only 42-bits after making PMDs and PGDs
    64-bit is that we only use half-page sized PTE tables in order to make
    PMDs line up to 4MB, the hardware huge page size we use.
    
    So what we do here is we make huge pages 8MB, and fabricate them using
    4MB hw TLB entries.
    
    Facilitate this by providing a "REAL_HPAGE_SHIFT" which is used in
    places that really need to operate on hardware 4MB pages.
    
    Use full pages (512 entries) for PTE tables, and adjust PMD_SHIFT,
    PGD_SHIFT, and the build time CPP test as needed.  Use a CPP test to
    make sure REAL_HPAGE_SHIFT and the _PAGE_SZHUGE_* we use match up.
    
    This makes the pgtable cache completely unused, so remove the code
    managing it and the state used in mm_context_t.  Now we have less
    spinlocks taken in the page table allocation path.
    
    The technique we use to fabricate the 8MB pages is to transfer bit 22
    from the missing virtual address into the PTEs physical address field.
    That takes care of the transparent huge pages case.
    
    For hugetlb, we fill things in at the PTE level and that code already
    puts the sub huge page physical bits into the PTEs, based upon the
    offset, so there is nothing special we need to do.  It all just works
    out.
    
    So, a small amount of complexity in the THP case, but this code is
    about to get much simpler when we move the 64-bit PMDs as we can move
    away from the fancy 32-bit huge PMD encoding and just put a real PTE
    value in there.
    
    With bug fixes and help from Bob Picco.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index 89e07fd0ac88..1958bfbe300c 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -15,7 +15,10 @@
 #define DCACHE_ALIASING_POSSIBLE
 #endif
 
-#define HPAGE_SHIFT		22
+#define HPAGE_SHIFT		23
+#define REAL_HPAGE_SHIFT	22
+
+#define REAL_HPAGE_SIZE		(_AC(1,UL) << REAL_HPAGE_SHIFT)
 
 #if defined(CONFIG_HUGETLB_PAGE) || defined(CONFIG_TRANSPARENT_HUGEPAGE)
 #define HPAGE_SIZE		(_AC(1,UL) << HPAGE_SHIFT)

commit b2d438348024b75a1ee8b66b85d77f569a5dfed8
Author: David S. Miller <davem@davemloft.net>
Date:   Fri Sep 20 21:50:41 2013 -0700

    sparc64: Make PAGE_OFFSET variable.
    
    Choose PAGE_OFFSET dynamically based upon cpu type.
    
    Original UltraSPARC-I (spitfire) chips only supported a 44-bit
    virtual address space.
    
    Newer chips (T4 and later) support 52-bit virtual addresses
    and up to 47-bits of physical memory space.
    
    Therefore we have to adjust PAGE_SIZE dynamically based upon
    the capabilities of the chip.
    
    Note that this change alone does not allow us to support > 43-bit
    physical memory, to do that we need to re-arrange our page table
    support.  The current encodings of the pmd_t and pgd_t pointers
    restricts us to "32 + 11" == 43 bits.
    
    This change can waste quite a bit of memory for the various tables.
    In particular, a future change should work to size and allocate
    kern_linear_bitmap[] and sparc64_valid_addr_bitmap[] dynamically.
    This isn't easy as we really cannot take a TLB miss when accessing
    kern_linear_bitmap[].  We'd have to lock it into the TLB or similar.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Acked-by: Bob Picco <bob.picco@oracle.com>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index 978ea6d022e9..89e07fd0ac88 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -112,24 +112,16 @@ typedef pte_t *pgtable_t;
 
 #include <asm-generic/memory_model.h>
 
-#endif /* !(__ASSEMBLY__) */
-
-/* We used to stick this into a hard-coded global register (%g4)
- * but that does not make sense anymore.
- */
-#define MAX_SUPPORTED_PA_BITS	43
 #define PAGE_OFFSET_BY_BITS(X)	(-(_AC(1,UL) << (X)))
-#define PAGE_OFFSET		PAGE_OFFSET_BY_BITS(MAX_SUPPORTED_PA_BITS)
+extern unsigned long PAGE_OFFSET;
 
-/* The "virtual" portion of PAGE_OFFSET, used to clip off the non-physical
- * bits of a linear kernel address.
- */
-#define PAGE_OFFSET_VA_BITS	(64 - MAX_SUPPORTED_PA_BITS)
+#endif /* !(__ASSEMBLY__) */
 
-/* The actual number of physical memory address bits we support, this is
- * used to size various tables used to manage kernel TLB misses.
+/* The maximum number of physical memory address bits we support, this
+ * is used to size various tables used to manage kernel TLB misses and
+ * also the sparsemem code.
  */
-#define MAX_PHYS_ADDRESS_BITS	41
+#define MAX_PHYS_ADDRESS_BITS	47
 
 /* These two shift counts are used when indexing sparc64_valid_addr_bitmap
  * and kpte_linear_bitmap.

commit bb7b435388b9f035ecfb16f42b5c6bf428359c63
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Sep 18 15:39:06 2013 -0700

    sparc64: Document the shift counts used to validate linear kernel addresses.
    
    This way we can see exactly what they are derived from, and in particular
    how they would change if we were to use a different PAGE_OFFSET value.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Acked-by: Bob Picco <bob.picco@oracle.com>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index 9dd0f7360822..978ea6d022e9 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -121,6 +121,22 @@ typedef pte_t *pgtable_t;
 #define PAGE_OFFSET_BY_BITS(X)	(-(_AC(1,UL) << (X)))
 #define PAGE_OFFSET		PAGE_OFFSET_BY_BITS(MAX_SUPPORTED_PA_BITS)
 
+/* The "virtual" portion of PAGE_OFFSET, used to clip off the non-physical
+ * bits of a linear kernel address.
+ */
+#define PAGE_OFFSET_VA_BITS	(64 - MAX_SUPPORTED_PA_BITS)
+
+/* The actual number of physical memory address bits we support, this is
+ * used to size various tables used to manage kernel TLB misses.
+ */
+#define MAX_PHYS_ADDRESS_BITS	41
+
+/* These two shift counts are used when indexing sparc64_valid_addr_bitmap
+ * and kpte_linear_bitmap.
+ */
+#define ILOG2_4MB		22
+#define ILOG2_256MB		28
+
 #ifndef __ASSEMBLY__
 
 #define __pa(x)			((unsigned long)(x) - PAGE_OFFSET)

commit e0a45e3580a033669b24b04c3535515d69bb9702
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Sep 18 14:22:34 2013 -0700

    sparc64: Define PAGE_OFFSET in terms of physical address bits.
    
    This makes clearer the implications for a given choosen
    value.
    
    Based upon patches by Bob Picco.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Acked-by: Bob Picco <bob.picco@oracle.com>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index d95931247feb..9dd0f7360822 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -117,7 +117,9 @@ typedef pte_t *pgtable_t;
 /* We used to stick this into a hard-coded global register (%g4)
  * but that does not make sense anymore.
  */
-#define PAGE_OFFSET		_AC(0xFFFFF80000000000,UL)
+#define MAX_SUPPORTED_PA_BITS	43
+#define PAGE_OFFSET_BY_BITS(X)	(-(_AC(1,UL) << (X)))
+#define PAGE_OFFSET		PAGE_OFFSET_BY_BITS(MAX_SUPPORTED_PA_BITS)
 
 #ifndef __ASSEMBLY__
 

commit c920745e6964bd4b9315a17b018d83fad66010d3
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Sep 18 11:58:32 2013 -0700

    sparc64: Clean up 64-bit mmap exclusion defines.
    
    Older UltraSPARC chips had an address space hole due to the MMU only
    supporting 44-bit virtual addresses.
    
    The top end of this hole also has the same value as the current
    definition of PAGE_OFFSET, so this can be confusing.
    
    Consolidate the defines for the userspace mmap exclusion range into
    page_64.h and use them in sys_sparc_64.c and hugetlbpage.c
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Acked-by: Bob Picco <bob.picco@oracle.com>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index e15538899f3d..d95931247feb 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -93,9 +93,22 @@ typedef unsigned long pgprot_t;
 
 typedef pte_t *pgtable_t;
 
+/* These two values define the virtual address space range in which we
+ * must forbid 64-bit user processes from making mappings.  It
+ * represents the virtual address space hole present in most early
+ * sparc64 chips including UltraSPARC-I.  The next two defines specify
+ * the actual exclusion region we enforce, wherein we use a 4GB red
+ * zone on each side of the VA hole.
+ */
+#define SPARC64_VA_HOLE_TOP	_AC(0xfffff80000000000,UL)
+#define SPARC64_VA_HOLE_BOTTOM	_AC(0x0000080000000000,UL)
+
+#define VA_EXCLUDE_START (SPARC64_VA_HOLE_BOTTOM - (1UL << 32UL))
+#define VA_EXCLUDE_END   (SPARC64_VA_HOLE_TOP + (1UL << 32UL))
+
 #define TASK_UNMAPPED_BASE	(test_thread_flag(TIF_32BIT) ? \
-				 (_AC(0x0000000070000000,UL)) : \
-				 (_AC(0xfffff80000000000,UL) + (1UL << 32UL)))
+				 _AC(0x0000000070000000,UL) : \
+				 VA_EXCLUDE_END)
 
 #include <asm-generic/memory_model.h>
 

commit 0fbebed682ff2788dee58e8d7f7dda46e33aa10b
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Feb 19 22:34:10 2013 -0800

    sparc64: Fix tsb_grow() in atomic context.
    
    If our first THP installation for an MM is via the set_pmd_at() done
    during khugepaged's collapsing we'll end up in tsb_grow() trying to do
    a GFP_KERNEL allocation with several locks held.
    
    Simply using GFP_ATOMIC in this situation is not the best option
    because we really can't have this fail, so we'd really like to keep
    this an order 0 GFP_KERNEL allocation if possible.
    
    Also, doing the TSB allocation from khugepaged is a really bad idea
    because we'll allocate it potentially from the wrong NUMA node in that
    context.
    
    So what we do is defer the hugepage TSB allocation until the first TLB
    miss we take on a hugepage.  This is slightly tricky because we have
    to handle two unusual cases:
    
    1) Taking the first hugepage TLB miss in the window trap handler.
       We'll call the winfix_trampoline when that is detected.
    
    2) An initial TSB allocation via TLB miss races with a hugetlb
       fault on another cpu running the same MM.  We handle this by
       unconditionally loading the TSB we see into the current cpu
       even if it's non-NULL at hugetlb_setup time.
    
    Reported-by: Meelis Roos <mroos@ut.ee>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index 4b39f74d6ca0..e15538899f3d 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -27,8 +27,8 @@
 #ifndef __ASSEMBLY__
 
 #if defined(CONFIG_HUGETLB_PAGE) || defined(CONFIG_TRANSPARENT_HUGEPAGE)
-struct mm_struct;
-extern void hugetlb_setup(struct mm_struct *mm);
+struct pt_regs;
+extern void hugetlb_setup(struct pt_regs *regs);
 #endif
 
 #define WANT_PAGE_VIRTUAL

commit 9e695d2ecc8451cc2c1603d60b5c8e7f5581923a
Author: David Miller <davem@davemloft.net>
Date:   Mon Oct 8 16:34:29 2012 -0700

    sparc64: Support transparent huge pages.
    
    This is relatively easy since PMD's now cover exactly 4MB of memory.
    
    Our PMD entries are 32-bits each, so we use a special encoding.  The
    lowest bit, PMD_ISHUGE, determines the interpretation.  This is possible
    because sparc64's page tables are purely software entities so we can use
    whatever encoding scheme we want.  We just have to make the TLB miss
    assembler page table walkers aware of the layout.
    
    set_pmd_at() works much like set_pte_at() but it has to operate in two
    page from a table of non-huge PTEs, so we have to queue up TLB flushes
    based upon what mappings are valid in the PTE table.  In the second regime
    we are going from huge-page to non-huge-page, and in that case we need
    only queue up a single TLB flush to push out the huge page mapping.
    
    We still have 5 bits remaining in the huge PMD encoding so we can very
    likely support any new pieces of THP state tracking that might get added
    in the future.
    
    With lots of help from Johannes Weiner.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Gerald Schaefer <gerald.schaefer@de.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index 087a5c505c69..4b39f74d6ca0 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -17,7 +17,7 @@
 
 #define HPAGE_SHIFT		22
 
-#ifdef CONFIG_HUGETLB_PAGE
+#if defined(CONFIG_HUGETLB_PAGE) || defined(CONFIG_TRANSPARENT_HUGEPAGE)
 #define HPAGE_SIZE		(_AC(1,UL) << HPAGE_SHIFT)
 #define HPAGE_MASK		(~(HPAGE_SIZE - 1UL))
 #define HUGETLB_PAGE_ORDER	(HPAGE_SHIFT - PAGE_SHIFT)
@@ -26,6 +26,11 @@
 
 #ifndef __ASSEMBLY__
 
+#if defined(CONFIG_HUGETLB_PAGE) || defined(CONFIG_TRANSPARENT_HUGEPAGE)
+struct mm_struct;
+extern void hugetlb_setup(struct mm_struct *mm);
+#endif
+
 #define WANT_PAGE_VIRTUAL
 
 extern void _clear_page(void *page);

commit c460bec78d9257a54bcc5f9d5fadf89f8c70dbd1
Author: David Miller <davem@davemloft.net>
Date:   Mon Oct 8 16:34:22 2012 -0700

    sparc64: Eliminate PTE table memory wastage.
    
    We've split up the PTE tables so that they take up half a page instead of
    a full page.  This is in order to facilitate transparent huge page
    support, which works much better if our PMDs cover 4MB instead of 8MB.
    
    What we do is have a one-behind cache for PTE table allocations in the
    mm struct.
    
    This logic triggers only on allocations.  For example, we don't try to
    keep track of free'd up page table blocks in the style that the s390 port
    does.
    
    There were only two slightly annoying aspects to this change:
    
    1) Changing pgtable_t to be a "pte_t *".  There's all of this special
       logic in the TLB free paths that needed adjustments, as did the
       PMD populate interfaces.
    
    2) init_new_context() needs to zap the pointer, since the mm struct
       just gets copied from the parent on fork.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Gerald Schaefer <gerald.schaefer@de.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index b2df9b8b2d46..087a5c505c69 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -86,7 +86,7 @@ typedef unsigned long pgprot_t;
 
 #endif /* (STRICT_MM_TYPECHECKS) */
 
-typedef struct page *pgtable_t;
+typedef pte_t *pgtable_t;
 
 #define TASK_UNMAPPED_BASE	(test_thread_flag(TIF_32BIT) ? \
 				 (_AC(0x0000000070000000,UL)) : \

commit 15b9350a177b9fb23b69e00f78f52890ee338880
Author: David Miller <davem@davemloft.net>
Date:   Mon Oct 8 16:34:19 2012 -0700

    sparc64: Only support 4MB huge pages and 8KB base pages.
    
    Narrowing the scope of the page size configurations will make the
    transparent hugepage changes much simpler.
    
    In the end what we really want to do is have the kernel support multiple
    huge page sizes and use whatever is appropriate as the context dictactes.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Gerald Schaefer <gerald.schaefer@de.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index f0d09b401036..b2df9b8b2d46 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -3,13 +3,7 @@
 
 #include <linux/const.h>
 
-#if defined(CONFIG_SPARC64_PAGE_SIZE_8KB)
 #define PAGE_SHIFT   13
-#elif defined(CONFIG_SPARC64_PAGE_SIZE_64KB)
-#define PAGE_SHIFT   16
-#else
-#error No page size specified in kernel configuration
-#endif
 
 #define PAGE_SIZE    (_AC(1,UL) << PAGE_SHIFT)
 #define PAGE_MASK    (~(PAGE_SIZE-1))
@@ -21,13 +15,7 @@
 #define DCACHE_ALIASING_POSSIBLE
 #endif
 
-#if defined(CONFIG_HUGETLB_PAGE_SIZE_4MB)
 #define HPAGE_SHIFT		22
-#elif defined(CONFIG_HUGETLB_PAGE_SIZE_512K)
-#define HPAGE_SHIFT		19
-#elif defined(CONFIG_HUGETLB_PAGE_SIZE_64K)
-#define HPAGE_SHIFT		16
-#endif
 
 #ifdef CONFIG_HUGETLB_PAGE
 #define HPAGE_SIZE		(_AC(1,UL) << HPAGE_SHIFT)

commit 5b17e1cd8928ae65932758ce6478ac6d3e9a86b2
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed May 13 22:56:30 2009 +0000

    asm-generic: rename page.h and uaccess.h
    
    The current asm-generic/page.h only contains the get_order
    function, and asm-generic/uaccess.h only implements
    unaligned accesses. This renames the file to getorder.h
    and uaccess-unaligned.h to make room for new page.h
    and uaccess.h file that will be usable by all simple
    (e.g. nommu) architectures.
    
    Signed-off-by: Remis Lima Baima <remis.developer@googlemail.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index 4274ed13ddb2..f0d09b401036 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -132,6 +132,6 @@ typedef struct page *pgtable_t;
 #define VM_DATA_DEFAULT_FLAGS	(VM_READ | VM_WRITE | VM_EXEC | \
 				 VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC)
 
-#include <asm-generic/page.h>
+#include <asm-generic/getorder.h>
 
 #endif /* _SPARC64_PAGE_H */

commit b0f1e7962f93a78630161c7c9fc263de43c101ac
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Sep 11 23:36:32 2008 -0700

    sparc64: Define WANT_PAGE_VIRTUAL
    
    As sparse warns, without this struct page pointer subtraction is
    extremely expensive, and this is a pretty common operation in
    fast paths.
    
    With this define struct page becomes 64 bytes which makes for a
    simple subtract and shift, instead of a costly divide or reciprocol
    multiply.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
index b579b910ef51..4274ed13ddb2 100644
--- a/arch/sparc/include/asm/page_64.h
+++ b/arch/sparc/include/asm/page_64.h
@@ -38,6 +38,8 @@
 
 #ifndef __ASSEMBLY__
 
+#define WANT_PAGE_VIRTUAL
+
 extern void _clear_page(void *page);
 #define clear_page(X)	_clear_page((void *)(X))
 struct page;

commit a439fe51a1f8eb087c22dd24d69cebae4a3addac
Author: Sam Ravnborg <sam@ravnborg.org>
Date:   Sun Jul 27 23:00:59 2008 +0200

    sparc, sparc64: use arch/sparc/include
    
    The majority of this patch was created by the following script:
    
    ***
    ASM=arch/sparc/include/asm
    mkdir -p $ASM
    git mv include/asm-sparc64/ftrace.h $ASM
    git rm include/asm-sparc64/*
    git mv include/asm-sparc/* $ASM
    sed -ie 's/asm-sparc64/asm/g' $ASM/*
    sed -ie 's/asm-sparc/asm/g' $ASM/*
    ***
    
    The rest was an update of the top-level Makefile to use sparc
    for header files when sparc64 is being build.
    And a small fixlet to pick up the correct unistd.h from
    sparc64 code.
    
    Signed-off-by: Sam Ravnborg <sam@ravnborg.org>

diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h
new file mode 100644
index 000000000000..b579b910ef51
--- /dev/null
+++ b/arch/sparc/include/asm/page_64.h
@@ -0,0 +1,135 @@
+#ifndef _SPARC64_PAGE_H
+#define _SPARC64_PAGE_H
+
+#include <linux/const.h>
+
+#if defined(CONFIG_SPARC64_PAGE_SIZE_8KB)
+#define PAGE_SHIFT   13
+#elif defined(CONFIG_SPARC64_PAGE_SIZE_64KB)
+#define PAGE_SHIFT   16
+#else
+#error No page size specified in kernel configuration
+#endif
+
+#define PAGE_SIZE    (_AC(1,UL) << PAGE_SHIFT)
+#define PAGE_MASK    (~(PAGE_SIZE-1))
+
+/* Flushing for D-cache alias handling is only needed if
+ * the page size is smaller than 16K.
+ */
+#if PAGE_SHIFT < 14
+#define DCACHE_ALIASING_POSSIBLE
+#endif
+
+#if defined(CONFIG_HUGETLB_PAGE_SIZE_4MB)
+#define HPAGE_SHIFT		22
+#elif defined(CONFIG_HUGETLB_PAGE_SIZE_512K)
+#define HPAGE_SHIFT		19
+#elif defined(CONFIG_HUGETLB_PAGE_SIZE_64K)
+#define HPAGE_SHIFT		16
+#endif
+
+#ifdef CONFIG_HUGETLB_PAGE
+#define HPAGE_SIZE		(_AC(1,UL) << HPAGE_SHIFT)
+#define HPAGE_MASK		(~(HPAGE_SIZE - 1UL))
+#define HUGETLB_PAGE_ORDER	(HPAGE_SHIFT - PAGE_SHIFT)
+#define HAVE_ARCH_HUGETLB_UNMAPPED_AREA
+#endif
+
+#ifndef __ASSEMBLY__
+
+extern void _clear_page(void *page);
+#define clear_page(X)	_clear_page((void *)(X))
+struct page;
+extern void clear_user_page(void *addr, unsigned long vaddr, struct page *page);
+#define copy_page(X,Y)	memcpy((void *)(X), (void *)(Y), PAGE_SIZE)
+extern void copy_user_page(void *to, void *from, unsigned long vaddr, struct page *topage);
+
+/* Unlike sparc32, sparc64's parameter passing API is more
+ * sane in that structures which as small enough are passed
+ * in registers instead of on the stack.  Thus, setting
+ * STRICT_MM_TYPECHECKS does not generate worse code so
+ * let's enable it to get the type checking.
+ */
+
+#define STRICT_MM_TYPECHECKS
+
+#ifdef STRICT_MM_TYPECHECKS
+/* These are used to make use of C type-checking.. */
+typedef struct { unsigned long pte; } pte_t;
+typedef struct { unsigned long iopte; } iopte_t;
+typedef struct { unsigned int pmd; } pmd_t;
+typedef struct { unsigned int pgd; } pgd_t;
+typedef struct { unsigned long pgprot; } pgprot_t;
+
+#define pte_val(x)	((x).pte)
+#define iopte_val(x)	((x).iopte)
+#define pmd_val(x)      ((x).pmd)
+#define pgd_val(x)	((x).pgd)
+#define pgprot_val(x)	((x).pgprot)
+
+#define __pte(x)	((pte_t) { (x) } )
+#define __iopte(x)	((iopte_t) { (x) } )
+#define __pmd(x)        ((pmd_t) { (x) } )
+#define __pgd(x)	((pgd_t) { (x) } )
+#define __pgprot(x)	((pgprot_t) { (x) } )
+
+#else
+/* .. while these make it easier on the compiler */
+typedef unsigned long pte_t;
+typedef unsigned long iopte_t;
+typedef unsigned int pmd_t;
+typedef unsigned int pgd_t;
+typedef unsigned long pgprot_t;
+
+#define pte_val(x)	(x)
+#define iopte_val(x)	(x)
+#define pmd_val(x)      (x)
+#define pgd_val(x)	(x)
+#define pgprot_val(x)	(x)
+
+#define __pte(x)	(x)
+#define __iopte(x)	(x)
+#define __pmd(x)        (x)
+#define __pgd(x)	(x)
+#define __pgprot(x)	(x)
+
+#endif /* (STRICT_MM_TYPECHECKS) */
+
+typedef struct page *pgtable_t;
+
+#define TASK_UNMAPPED_BASE	(test_thread_flag(TIF_32BIT) ? \
+				 (_AC(0x0000000070000000,UL)) : \
+				 (_AC(0xfffff80000000000,UL) + (1UL << 32UL)))
+
+#include <asm-generic/memory_model.h>
+
+#endif /* !(__ASSEMBLY__) */
+
+/* We used to stick this into a hard-coded global register (%g4)
+ * but that does not make sense anymore.
+ */
+#define PAGE_OFFSET		_AC(0xFFFFF80000000000,UL)
+
+#ifndef __ASSEMBLY__
+
+#define __pa(x)			((unsigned long)(x) - PAGE_OFFSET)
+#define __va(x)			((void *)((unsigned long) (x) + PAGE_OFFSET))
+
+#define pfn_to_kaddr(pfn)	__va((pfn) << PAGE_SHIFT)
+
+#define virt_to_page(kaddr)	pfn_to_page(__pa(kaddr)>>PAGE_SHIFT)
+
+#define virt_addr_valid(kaddr)	pfn_valid(__pa(kaddr) >> PAGE_SHIFT)
+
+#define virt_to_phys __pa
+#define phys_to_virt __va
+
+#endif /* !(__ASSEMBLY__) */
+
+#define VM_DATA_DEFAULT_FLAGS	(VM_READ | VM_WRITE | VM_EXEC | \
+				 VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC)
+
+#include <asm-generic/page.h>
+
+#endif /* _SPARC64_PAGE_H */
