commit 736706bee3298208343a76096370e4f6a5c55915
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Mar 4 10:39:05 2019 -0800

    get rid of legacy 'get_ds()' function
    
    Every in-kernel use of this function defined it to KERNEL_DS (either as
    an actual define, or as an inline function).  It's an entirely
    historical artifact, and long long long ago used to actually read the
    segment selector valueof '%ds' on x86.
    
    Which in the kernel is always KERNEL_DS.
    
    Inspired by a patch from Jann Horn that just did this for a very small
    subset of users (the ones in fs/), along with Al who suggested a script.
    I then just took it to the logical extreme and removed all the remaining
    gunk.
    
    Roughly scripted with
    
       git grep -l '(get_ds())' -- :^tools/ | xargs sed -i 's/(get_ds())/(KERNEL_DS)/'
       git grep -lw 'get_ds' -- :^tools/ | xargs sed -i '/^#define get_ds()/d'
    
    plus manual fixups to remove a few unusual usage patterns, the couple of
    inline function cases and to fix up a comment that had become stale.
    
    The 'get_ds()' function remains in an x86 kvm selftest, since in user
    space it actually does something relevant.
    
    Inspired-by: Jann Horn <jannh@google.com>
    Inspired-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index 5153798051fb..d6d8413eca83 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -25,7 +25,6 @@
 #define KERNEL_DS   ((mm_segment_t) { 0 })
 #define USER_DS     ((mm_segment_t) { -1 })
 
-#define get_ds()	(KERNEL_DS)
 #define get_fs()	(current->thread.current_ds)
 #define set_fs(val)	((current->thread.current_ds) = (val))
 

commit 4caf4ebfe4cf0ea262eb9e829bb254a6a6d58acc
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jan 4 09:58:25 2019 -0800

    Fix access_ok() fallout for sparc32 and powerpc
    
    These two architectures actually had an intentional use of the 'type'
    argument to access_ok() just to avoid warnings.
    
    I had actually noticed the powerpc one, but forgot to then fix it up.
    And I missed the sparc32 case entirely.
    
    This is hopefully all of it.
    
    Reported-by: Mathieu Malaterre <malat@debian.org>
    Reported-by: Guenter Roeck <linux@roeck-us.net>
    Fixes: 96d4f267e40f ("Remove 'type' argument from access_ok() function")
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index 69afb856e181..5153798051fb 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -39,8 +39,7 @@
 #define __user_ok(addr, size) ({ (void)(size); (addr) < STACK_TOP; })
 #define __kernel_ok (uaccess_kernel())
 #define __access_ok(addr, size) (__user_ok((addr) & get_fs().seg, (size)))
-#define access_ok(addr, size) \
-	({ (void)(type); __access_ok((unsigned long)(addr), size); })
+#define access_ok(addr, size) __access_ok((unsigned long)(addr), size)
 
 /*
  * The exception table consists of pairs of addresses: the first is the

commit 96d4f267e40f9509e8a66e2b39e8b95655617693
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jan 3 18:57:57 2019 -0800

    Remove 'type' argument from access_ok() function
    
    Nobody has actually used the type (VERIFY_READ vs VERIFY_WRITE) argument
    of the user address range verification function since we got rid of the
    old racy i386-only code to walk page tables by hand.
    
    It existed because the original 80386 would not honor the write protect
    bit when in kernel mode, so you had to do COW by hand before doing any
    user access.  But we haven't supported that in a long time, and these
    days the 'type' argument is a purely historical artifact.
    
    A discussion about extending 'user_access_begin()' to do the range
    checking resulted this patch, because there is no way we're going to
    move the old VERIFY_xyz interface to that model.  And it's best done at
    the end of the merge window when I've done most of my merges, so let's
    just get this done once and for all.
    
    This patch was mostly done with a sed-script, with manual fix-ups for
    the cases that weren't of the trivial 'access_ok(VERIFY_xyz' form.
    
    There were a couple of notable cases:
    
     - csky still had the old "verify_area()" name as an alias.
    
     - the iter_iov code had magical hardcoded knowledge of the actual
       values of VERIFY_{READ,WRITE} (not that they mattered, since nothing
       really used it)
    
     - microblaze used the type argument for a debug printout
    
    but other than those oddities this should be a total no-op patch.
    
    I tried to fix up all architectures, did fairly extensive grepping for
    access_ok() uses, and the changes are trivial, but I may have missed
    something.  Any missed conversion should be trivially fixable, though.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index de71c65b99f0..69afb856e181 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -39,7 +39,7 @@
 #define __user_ok(addr, size) ({ (void)(size); (addr) < STACK_TOP; })
 #define __kernel_ok (uaccess_kernel())
 #define __access_ok(addr, size) (__user_ok((addr) & get_fs().seg, (size)))
-#define access_ok(type, addr, size) \
+#define access_ok(addr, size) \
 	({ (void)(type); __access_ok((unsigned long)(addr), size); })
 
 /*

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index bdb1447aa1bb..de71c65b99f0 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  * uaccess.h: User space memore access functions.
  *

commit 82985258390e85289940d3663344197344e071f2
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Apr 7 17:20:01 2017 -0400

    kill strlen_user()
    
    no callers, no consistent semantics, no sane way to use it...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index 12ebee2d97c7..bdb1447aa1bb 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -277,7 +277,6 @@ static inline unsigned long clear_user(void __user *addr, unsigned long n)
 		return n;
 }
 
-__must_check long strlen_user(const char __user *str);
 __must_check long strnlen_user(const char __user *str, long n);
 
 #endif /* _ASM_UACCESS_H */

commit 31af2f36d50e3b9b2fb7f17aa430c11c91f946c4
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Mar 21 17:04:45 2017 -0400

    sparc: switch to RAW_COPY_USER
    
    ... and drop zeroing in sparc32.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index 93910845733a..12ebee2d97c7 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -235,39 +235,18 @@ int __get_user_bad(void);
 
 unsigned long __copy_user(void __user *to, const void __user *from, unsigned long size);
 
-static inline unsigned long copy_to_user(void __user *to, const void *from, unsigned long n)
+static inline unsigned long raw_copy_to_user(void __user *to, const void *from, unsigned long n)
 {
-	if (n && __access_ok((unsigned long) to, n)) {
-		check_object_size(from, n, true);
-		return __copy_user(to, (__force void __user *) from, n);
-	} else
-		return n;
-}
-
-static inline unsigned long __copy_to_user(void __user *to, const void *from, unsigned long n)
-{
-	check_object_size(from, n, true);
 	return __copy_user(to, (__force void __user *) from, n);
 }
 
-static inline unsigned long copy_from_user(void *to, const void __user *from, unsigned long n)
-{
-	if (n && __access_ok((unsigned long) from, n)) {
-		check_object_size(to, n, false);
-		return __copy_user((__force void __user *) to, from, n);
-	} else {
-		memset(to, 0, n);
-		return n;
-	}
-}
-
-static inline unsigned long __copy_from_user(void *to, const void __user *from, unsigned long n)
+static inline unsigned long raw_copy_from_user(void *to, const void __user *from, unsigned long n)
 {
 	return __copy_user((__force void __user *) to, from, n);
 }
 
-#define __copy_to_user_inatomic __copy_to_user
-#define __copy_from_user_inatomic __copy_from_user
+#define INLINE_COPY_FROM_USER
+#define INLINE_COPY_TO_USER
 
 static inline unsigned long __clear_user(void __user *addr, unsigned long size)
 {

commit 1333eb785614779b2000e547bd32aef85c22ca7a
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Dec 25 20:27:33 2016 -0500

    sparc32: kill __ret_efault()
    
    it's unused on 32bit one as well...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index a59a1e81986d..93910845733a 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -71,8 +71,6 @@ struct exception_table_entry
 /* Returns 0 if exception not found and fixup otherwise.  */
 unsigned long search_extables_range(unsigned long addr, unsigned long *g2);
 
-void __ret_efault(void);
-
 /* Uh, these should become the main single-value transfer routines..
  * They automatically use the right size if we just have the right
  * pointer type..

commit db68ce10c4f0a27c1ff9fa0e789e5c41f8c4ea63
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Mar 20 21:08:07 2017 -0400

    new helper: uaccess_kernel()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index 952d512a64f2..a59a1e81986d 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -36,7 +36,7 @@
  * large size and address near to PAGE_OFFSET - a fault will break his intentions.
  */
 #define __user_ok(addr, size) ({ (void)(size); (addr) < STACK_TOP; })
-#define __kernel_ok (segment_eq(get_fs(), KERNEL_DS))
+#define __kernel_ok (uaccess_kernel())
 #define __access_ok(addr, size) (__user_ok((addr) & get_fs().seg, (size)))
 #define access_ok(type, addr, size) \
 	({ (void)(type); __access_ok((unsigned long)(addr), size); })

commit 444f02c458db00bd6049cc1bfe4254e80f57459e
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Dec 27 18:19:09 2016 -0500

    uaccess: drop pointless ifdefs
    
    None of those file is ever included from uapi stuff, so __KERNEL__
    is always defined.  None of them is ever included from assembler
    (they are only pulled from linux/uaccess.h, which _can't_ be
    included from assembler), so __ASSEMBLY__ is never defined.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index b10f7d626f0e..952d512a64f2 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -7,12 +7,8 @@
 #ifndef _ASM_UACCESS_H
 #define _ASM_UACCESS_H
 
-#ifdef __KERNEL__
 #include <linux/compiler.h>
 #include <linux/string.h>
-#endif
-
-#ifndef __ASSEMBLY__
 
 #include <asm/processor.h>
 
@@ -307,6 +303,4 @@ static inline unsigned long clear_user(void __user *addr, unsigned long n)
 __must_check long strlen_user(const char __user *str);
 __must_check long strnlen_user(const char __user *str, long n);
 
-#endif  /* __ASSEMBLY__ */
-
 #endif /* _ASM_UACCESS_H */

commit af1d5b37d6211c814fac0d5d0b71ec695618054a
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Dec 27 18:14:09 2016 -0500

    uaccess: drop duplicate includes from asm/uaccess.h
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index d8857f5fafad..b10f7d626f0e 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -9,9 +9,7 @@
 
 #ifdef __KERNEL__
 #include <linux/compiler.h>
-#include <linux/sched.h>
 #include <linux/string.h>
-#include <linux/errno.h>
 #endif
 
 #ifndef __ASSEMBLY__

commit 5e6039d8a307d8411422c154f3d446b44fa32b6d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Dec 27 18:00:15 2016 -0500

    uaccess: move VERIFY_{READ,WRITE} definitions to linux/uaccess.h
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index ea55f86d7ccd..d8857f5fafad 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -30,9 +30,6 @@
 #define KERNEL_DS   ((mm_segment_t) { 0 })
 #define USER_DS     ((mm_segment_t) { -1 })
 
-#define VERIFY_READ	0
-#define VERIFY_WRITE	1
-
 #define get_ds()	(KERNEL_DS)
 #define get_fs()	(current->thread.current_ds)
 #define set_fs(val)	((current->thread.current_ds) = (val))

commit 77e5bdf9f7b2d20939c8d807f3e68778d6e1557a
Merge: b8f26e880c81 8630c32275ba
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Sep 14 09:35:05 2016 -0700

    Merge branch 'uaccess-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull uaccess fixes from Al Viro:
     "Fixes for broken uaccess primitives - mostly lack of proper zeroing
      in copy_from_user()/get_user()/__get_user(), but for several
      architectures there's more (broken clear_user() on frv and
      strncpy_from_user() on hexagon)"
    
    * 'uaccess-fixes' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs: (28 commits)
      avr32: fix copy_from_user()
      microblaze: fix __get_user()
      microblaze: fix copy_from_user()
      m32r: fix __get_user()
      blackfin: fix copy_from_user()
      sparc32: fix copy_from_user()
      sh: fix copy_from_user()
      sh64: failing __get_user() should zero
      score: fix copy_from_user() and friends
      score: fix __get_user/get_user
      s390: get_user() should zero on failure
      ppc32: fix copy_from_user()
      parisc: fix copy_from_user()
      openrisc: fix copy_from_user()
      nios2: fix __get_user()
      nios2: copy_from_user() should zero the tail of destination
      mn10300: copy_from_user() should zero on access_ok() failure...
      mn10300: failing __get_user() and get_user() should zero
      mips: copy_from_user() must zero the destination on access_ok() failure
      ARC: uaccess: get_user to zero out dest in cause of fault
      ...

commit 917400cecb4b52b5cde5417348322bb9c8272fa6
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Aug 22 00:23:07 2016 -0400

    sparc32: fix copy_from_user()
    
    Cc: stable@vger.kernel.org
    Acked-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index 341a5a133f48..035c89b7df5d 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -269,8 +269,10 @@ static inline unsigned long copy_from_user(void *to, const void __user *from, un
 		if (!__builtin_constant_p(n))
 			check_object_size(to, n, false);
 		return __copy_user((__force void __user *) to, from, n);
-	} else
+	} else {
+		memset(to, 0, n);
 		return n;
+	}
 }
 
 static inline unsigned long __copy_from_user(void *to, const void __user *from, unsigned long n)

commit 81409e9e28058811c9ea865345e1753f8f677e44
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Aug 31 16:04:21 2016 -0700

    usercopy: fold builtin_const check into inline function
    
    Instead of having each caller of check_object_size() need to remember to
    check for a const size parameter, move the check into check_object_size()
    itself. This actually matches the original implementation in PaX, though
    this commit cleans up the now-redundant builtin_const() calls in the
    various architectures.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index 341a5a133f48..e722c510bb1b 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -249,8 +249,7 @@ unsigned long __copy_user(void __user *to, const void __user *from, unsigned lon
 static inline unsigned long copy_to_user(void __user *to, const void *from, unsigned long n)
 {
 	if (n && __access_ok((unsigned long) to, n)) {
-		if (!__builtin_constant_p(n))
-			check_object_size(from, n, true);
+		check_object_size(from, n, true);
 		return __copy_user(to, (__force void __user *) from, n);
 	} else
 		return n;
@@ -258,16 +257,14 @@ static inline unsigned long copy_to_user(void __user *to, const void *from, unsi
 
 static inline unsigned long __copy_to_user(void __user *to, const void *from, unsigned long n)
 {
-	if (!__builtin_constant_p(n))
-		check_object_size(from, n, true);
+	check_object_size(from, n, true);
 	return __copy_user(to, (__force void __user *) from, n);
 }
 
 static inline unsigned long copy_from_user(void *to, const void __user *from, unsigned long n)
 {
 	if (n && __access_ok((unsigned long) from, n)) {
-		if (!__builtin_constant_p(n))
-			check_object_size(to, n, false);
+		check_object_size(to, n, false);
 		return __copy_user((__force void __user *) to, from, n);
 	} else
 		return n;

commit 9d9208a15800f9f06f102f9aac1e8b323c3b8575
Author: Kees Cook <keescook@chromium.org>
Date:   Thu Jun 23 15:10:13 2016 -0700

    sparc/uaccess: Enable hardened usercopy
    
    Enables CONFIG_HARDENED_USERCOPY checks on sparc.
    
    Based on code from PaX and grsecurity.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index 57aca2792d29..341a5a133f48 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -248,22 +248,28 @@ unsigned long __copy_user(void __user *to, const void __user *from, unsigned lon
 
 static inline unsigned long copy_to_user(void __user *to, const void *from, unsigned long n)
 {
-	if (n && __access_ok((unsigned long) to, n))
+	if (n && __access_ok((unsigned long) to, n)) {
+		if (!__builtin_constant_p(n))
+			check_object_size(from, n, true);
 		return __copy_user(to, (__force void __user *) from, n);
-	else
+	} else
 		return n;
 }
 
 static inline unsigned long __copy_to_user(void __user *to, const void *from, unsigned long n)
 {
+	if (!__builtin_constant_p(n))
+		check_object_size(from, n, true);
 	return __copy_user(to, (__force void __user *) from, n);
 }
 
 static inline unsigned long copy_from_user(void *to, const void __user *from, unsigned long n)
 {
-	if (n && __access_ok((unsigned long) from, n))
+	if (n && __access_ok((unsigned long) from, n)) {
+		if (!__builtin_constant_p(n))
+			check_object_size(to, n, false);
 		return __copy_user((__force void __user *) to, from, n);
-	else
+	} else
 		return n;
 }
 

commit f5e6634ec04b6ed55be4e124277acde240323f2d
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Dec 25 10:04:47 2015 -0500

    put the remnants of ..._user_ret() to rest
    
    they hadn't been used in last 15 years...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index 64ee103dc29d..57aca2792d29 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -205,31 +205,6 @@ int __put_user_bad(void);
 	__gu_ret; \
 })
 
-#define __get_user_check_ret(x, addr, size, type, retval) ({ \
-	register unsigned long __gu_val __asm__ ("l1"); \
-	if (__access_ok(addr, size)) { \
-		switch (size) { \
-		case 1: \
-			__get_user_asm_ret(__gu_val, ub, addr, retval); \
-			break; \
-		case 2: \
-			__get_user_asm_ret(__gu_val, uh, addr, retval); \
-			break; \
-		case 4: \
-			__get_user_asm_ret(__gu_val, , addr, retval); \
-			break; \
-		case 8: \
-			__get_user_asm_ret(__gu_val, d, addr, retval); \
-			break; \
-		default: \
-			if (__get_user_bad()) \
-				return retval; \
-		} \
-		x = (__force type) __gu_val; \
-	} else \
-		return retval; \
-})
-
 #define __get_user_nocheck(x, addr, size, type) ({			\
 	register int __gu_ret;						\
 	register unsigned long __gu_val;				\
@@ -247,20 +222,6 @@ int __put_user_bad(void);
 	__gu_ret;							\
 })
 
-#define __get_user_nocheck_ret(x, addr, size, type, retval) ({		\
-	register unsigned long __gu_val __asm__ ("l1");			\
-	switch (size) {							\
-	case 1: __get_user_asm_ret(__gu_val, ub, addr, retval); break;	\
-	case 2: __get_user_asm_ret(__gu_val, uh, addr, retval); break;	\
-	case 4: __get_user_asm_ret(__gu_val, , addr, retval);  break;	\
-	case 8: __get_user_asm_ret(__gu_val, d, addr, retval); break;	\
-	default:							\
-		if (__get_user_bad())					\
-			return retval;					\
-	}								\
-	x = (__force type) __gu_val;					\
-})
-
 #define __get_user_asm(x, size, addr, ret)				\
 __asm__ __volatile__(							\
 		"/* Get user asm, inline. */\n"				\
@@ -281,32 +242,6 @@ __asm__ __volatile__(							\
 	       : "=&r" (ret), "=&r" (x) : "m" (*__m(addr)),		\
 		 "i" (-EFAULT))
 
-#define __get_user_asm_ret(x, size, addr, retval)			\
-if (__builtin_constant_p(retval) && retval == -EFAULT)			\
-	__asm__ __volatile__(						\
-			"/* Get user asm ret, inline. */\n"		\
-		"1:\t"	"ld"#size " %1, %0\n\n\t"			\
-			".section __ex_table,#alloc\n\t"		\
-			".align	4\n\t"					\
-			".word	1b,__ret_efault\n\n\t"			\
-			".previous\n\t"					\
-		       : "=&r" (x) : "m" (*__m(addr)));			\
-else									\
-	__asm__ __volatile__(						\
-			"/* Get user asm ret, inline. */\n"		\
-		"1:\t"	"ld"#size " %1, %0\n\n\t"			\
-			".section .fixup,#alloc,#execinstr\n\t"		\
-			".align	4\n"					\
-		"3:\n\t"						\
-			"ret\n\t"					\
-			" restore %%g0, %2, %%o0\n\n\t"			\
-			".previous\n\t"					\
-			".section __ex_table,#alloc\n\t"		\
-			".align	4\n\t"					\
-			".word	1b, 3b\n\n\t"				\
-			".previous\n\t"					\
-		       : "=&r" (x) : "m" (*__m(addr)), "i" (retval))
-
 int __get_user_bad(void);
 
 unsigned long __copy_user(void __user *to, const void __user *from, unsigned long size);

commit 0795cb1b46e7938ed679ccd48f933e75272b30e3
Author: Michael S. Tsirkin <mst@redhat.com>
Date:   Tue Jan 6 23:40:11 2015 +0200

    sparc32: nocheck uaccess coding style tweaks
    
    Sam Ravnborg suggested packing single-lines cases in switch statements
    in nocheck uaccess macros makes for easier to read code.
    
    Suggested-by: Sam Ravnborg <sam@ravnborg.org>
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Acked-by: Sam Ravnborg <sam@ravnborg.org>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index f96656209a78..64ee103dc29d 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -142,24 +142,14 @@ struct __large_struct { unsigned long buf[100]; };
 	__pu_ret; \
 })
 
-#define __put_user_nocheck(x, addr, size) ({ \
-	register int __pu_ret; \
-	switch (size) { \
-	case 1: \
-		__put_user_asm(x, b, addr, __pu_ret); \
-		break; \
-	case 2: \
-		__put_user_asm(x, h, addr, __pu_ret); \
-		break; \
-	case 4: \
-		__put_user_asm(x, , addr, __pu_ret); \
-		break; \
-	case 8: \
-		__put_user_asm(x, d, addr, __pu_ret); \
-		break; \
-	default: \
-		__pu_ret = __put_user_bad(); \
-		break; \
+#define __put_user_nocheck(x, addr, size) ({			\
+	register int __pu_ret;					\
+	switch (size) {						\
+	case 1: __put_user_asm(x, b, addr, __pu_ret); break;	\
+	case 2: __put_user_asm(x, h, addr, __pu_ret); break;	\
+	case 4: __put_user_asm(x, , addr, __pu_ret); break;	\
+	case 8: __put_user_asm(x, d, addr, __pu_ret); break;	\
+	default: __pu_ret = __put_user_bad(); break;		\
 	} \
 	__pu_ret; \
 })
@@ -240,51 +230,35 @@ int __put_user_bad(void);
 		return retval; \
 })
 
-#define __get_user_nocheck(x, addr, size, type) ({ \
-	register int __gu_ret; \
-	register unsigned long __gu_val; \
-	switch (size) { \
-	case 1: \
-		__get_user_asm(__gu_val, ub, addr, __gu_ret); \
-		break; \
-	case 2: \
-		__get_user_asm(__gu_val, uh, addr, __gu_ret); \
-		break; \
-	case 4: \
-		__get_user_asm(__gu_val, , addr, __gu_ret); \
-		break; \
-	case 8: \
-		__get_user_asm(__gu_val, d, addr, __gu_ret); \
-		break; \
-	default: \
-		__gu_val = 0; \
-		__gu_ret = __get_user_bad(); \
-		break; \
-	} \
-	x = (__force type) __gu_val; \
-	__gu_ret; \
+#define __get_user_nocheck(x, addr, size, type) ({			\
+	register int __gu_ret;						\
+	register unsigned long __gu_val;				\
+	switch (size) {							\
+	case 1: __get_user_asm(__gu_val, ub, addr, __gu_ret); break;	\
+	case 2: __get_user_asm(__gu_val, uh, addr, __gu_ret); break;	\
+	case 4: __get_user_asm(__gu_val, , addr, __gu_ret); break;	\
+	case 8: __get_user_asm(__gu_val, d, addr, __gu_ret); break;	\
+	default:							\
+		__gu_val = 0;						\
+		__gu_ret = __get_user_bad();				\
+		break;							\
+	}								\
+	x = (__force type) __gu_val;					\
+	__gu_ret;							\
 })
 
-#define __get_user_nocheck_ret(x, addr, size, type, retval) ({ \
-	register unsigned long __gu_val __asm__ ("l1"); \
-	switch (size) { \
-	case 1: \
-		__get_user_asm_ret(__gu_val, ub, addr, retval); \
-		break; \
-	case 2: \
-		__get_user_asm_ret(__gu_val, uh, addr, retval); \
-		break; \
-	case 4: \
-		__get_user_asm_ret(__gu_val, , addr, retval); \
-		break; \
-	case 8: \
-		__get_user_asm_ret(__gu_val, d, addr, retval); \
-		break; \
-	default: \
-		if (__get_user_bad()) \
-			return retval; \
-	} \
-	x = (__force type) __gu_val; \
+#define __get_user_nocheck_ret(x, addr, size, type, retval) ({		\
+	register unsigned long __gu_val __asm__ ("l1");			\
+	switch (size) {							\
+	case 1: __get_user_asm_ret(__gu_val, ub, addr, retval); break;	\
+	case 2: __get_user_asm_ret(__gu_val, uh, addr, retval); break;	\
+	case 4: __get_user_asm_ret(__gu_val, , addr, retval);  break;	\
+	case 8: __get_user_asm_ret(__gu_val, d, addr, retval); break;	\
+	default:							\
+		if (__get_user_bad())					\
+			return retval;					\
+	}								\
+	x = (__force type) __gu_val;					\
 })
 
 #define __get_user_asm(x, size, addr, ret)				\

commit 8ccf7b2599abd08ab3a51d5f2299e301daae0860
Author: Michael S. Tsirkin <mst@redhat.com>
Date:   Tue Jan 6 14:30:51 2015 +0200

    sparc32: uaccess_32 macro whitespace fixes
    
    Macros within arch/sparc/include/asm/uaccess_32.h are made harder to
    read because they violate a bunch of coding style rules.
    
    Fix it up.
    
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Acked-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index 8b571a0db0f6..f96656209a78 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -37,7 +37,7 @@
 #define get_fs()	(current->thread.current_ds)
 #define set_fs(val)	((current->thread.current_ds) = (val))
 
-#define segment_eq(a,b)	((a).seg == (b).seg)
+#define segment_eq(a, b) ((a).seg == (b).seg)
 
 /* We have there a nice not-mapped page at PAGE_OFFSET - PAGE_SIZE, so that this test
  * can be fairly lightweight.
@@ -46,8 +46,8 @@
  */
 #define __user_ok(addr, size) ({ (void)(size); (addr) < STACK_TOP; })
 #define __kernel_ok (segment_eq(get_fs(), KERNEL_DS))
-#define __access_ok(addr,size) (__user_ok((addr) & get_fs().seg,(size)))
-#define access_ok(type, addr, size)					\
+#define __access_ok(addr, size) (__user_ok((addr) & get_fs().seg, (size)))
+#define access_ok(type, addr, size) \
 	({ (void)(type); __access_ok((unsigned long)(addr), size); })
 
 /*
@@ -91,158 +91,247 @@ void __ret_efault(void);
  * of a performance impact. Thus we have a few rather ugly macros here,
  * and hide all the ugliness from the user.
  */
-#define put_user(x,ptr) ({ \
-unsigned long __pu_addr = (unsigned long)(ptr); \
-__chk_user_ptr(ptr); \
-__put_user_check((__typeof__(*(ptr)))(x),__pu_addr,sizeof(*(ptr))); })
-
-#define get_user(x,ptr) ({ \
-unsigned long __gu_addr = (unsigned long)(ptr); \
-__chk_user_ptr(ptr); \
-__get_user_check((x),__gu_addr,sizeof(*(ptr)),__typeof__(*(ptr))); })
+#define put_user(x, ptr) ({ \
+	unsigned long __pu_addr = (unsigned long)(ptr); \
+	__chk_user_ptr(ptr); \
+	__put_user_check((__typeof__(*(ptr)))(x), __pu_addr, sizeof(*(ptr))); \
+})
+
+#define get_user(x, ptr) ({ \
+	unsigned long __gu_addr = (unsigned long)(ptr); \
+	__chk_user_ptr(ptr); \
+	__get_user_check((x), __gu_addr, sizeof(*(ptr)), __typeof__(*(ptr))); \
+})
 
 /*
  * The "__xxx" versions do not do address space checking, useful when
  * doing multiple accesses to the same area (the user has to do the
  * checks by hand with "access_ok()")
  */
-#define __put_user(x,ptr) __put_user_nocheck((__typeof__(*(ptr)))(x),(ptr),sizeof(*(ptr)))
-#define __get_user(x,ptr) __get_user_nocheck((x),(ptr),sizeof(*(ptr)),__typeof__(*(ptr)))
+#define __put_user(x, ptr) \
+	__put_user_nocheck((__typeof__(*(ptr)))(x), (ptr), sizeof(*(ptr)))
+#define __get_user(x, ptr) \
+    __get_user_nocheck((x), (ptr), sizeof(*(ptr)), __typeof__(*(ptr)))
 
 struct __large_struct { unsigned long buf[100]; };
 #define __m(x) ((struct __large_struct __user *)(x))
 
-#define __put_user_check(x,addr,size) ({ \
-register int __pu_ret; \
-if (__access_ok(addr,size)) { \
-switch (size) { \
-case 1: __put_user_asm(x,b,addr,__pu_ret); break; \
-case 2: __put_user_asm(x,h,addr,__pu_ret); break; \
-case 4: __put_user_asm(x,,addr,__pu_ret); break; \
-case 8: __put_user_asm(x,d,addr,__pu_ret); break; \
-default: __pu_ret = __put_user_bad(); break; \
-} } else { __pu_ret = -EFAULT; } __pu_ret; })
-
-#define __put_user_nocheck(x,addr,size) ({ \
-register int __pu_ret; \
-switch (size) { \
-case 1: __put_user_asm(x,b,addr,__pu_ret); break; \
-case 2: __put_user_asm(x,h,addr,__pu_ret); break; \
-case 4: __put_user_asm(x,,addr,__pu_ret); break; \
-case 8: __put_user_asm(x,d,addr,__pu_ret); break; \
-default: __pu_ret = __put_user_bad(); break; \
-} __pu_ret; })
-
-#define __put_user_asm(x,size,addr,ret)					\
+#define __put_user_check(x, addr, size) ({ \
+	register int __pu_ret; \
+	if (__access_ok(addr, size)) { \
+		switch (size) { \
+		case 1: \
+			__put_user_asm(x, b, addr, __pu_ret); \
+			break; \
+		case 2: \
+			__put_user_asm(x, h, addr, __pu_ret); \
+			break; \
+		case 4: \
+			__put_user_asm(x, , addr, __pu_ret); \
+			break; \
+		case 8: \
+			__put_user_asm(x, d, addr, __pu_ret); \
+			break; \
+		default: \
+			__pu_ret = __put_user_bad(); \
+			break; \
+		} \
+	} else { \
+		__pu_ret = -EFAULT; \
+	} \
+	__pu_ret; \
+})
+
+#define __put_user_nocheck(x, addr, size) ({ \
+	register int __pu_ret; \
+	switch (size) { \
+	case 1: \
+		__put_user_asm(x, b, addr, __pu_ret); \
+		break; \
+	case 2: \
+		__put_user_asm(x, h, addr, __pu_ret); \
+		break; \
+	case 4: \
+		__put_user_asm(x, , addr, __pu_ret); \
+		break; \
+	case 8: \
+		__put_user_asm(x, d, addr, __pu_ret); \
+		break; \
+	default: \
+		__pu_ret = __put_user_bad(); \
+		break; \
+	} \
+	__pu_ret; \
+})
+
+#define __put_user_asm(x, size, addr, ret)				\
 __asm__ __volatile__(							\
-	"/* Put user asm, inline. */\n"					\
-"1:\t"	"st"#size " %1, %2\n\t"						\
-	"clr	%0\n"							\
-"2:\n\n\t"								\
-	".section .fixup,#alloc,#execinstr\n\t"				\
-	".align	4\n"							\
-"3:\n\t"								\
-	"b	2b\n\t"							\
-	" mov	%3, %0\n\t"						\
-        ".previous\n\n\t"						\
-	".section __ex_table,#alloc\n\t"				\
-	".align	4\n\t"							\
-	".word	1b, 3b\n\t"						\
-	".previous\n\n\t"						\
-       : "=&r" (ret) : "r" (x), "m" (*__m(addr)),			\
-	 "i" (-EFAULT))
+		"/* Put user asm, inline. */\n"				\
+	"1:\t"	"st"#size " %1, %2\n\t"					\
+		"clr	%0\n"						\
+	"2:\n\n\t"							\
+		".section .fixup,#alloc,#execinstr\n\t"			\
+		".align	4\n"						\
+	"3:\n\t"							\
+		"b	2b\n\t"						\
+		" mov	%3, %0\n\t"					\
+		".previous\n\n\t"					\
+		".section __ex_table,#alloc\n\t"			\
+		".align	4\n\t"						\
+		".word	1b, 3b\n\t"					\
+		".previous\n\n\t"					\
+	       : "=&r" (ret) : "r" (x), "m" (*__m(addr)),		\
+		 "i" (-EFAULT))
 
 int __put_user_bad(void);
 
-#define __get_user_check(x,addr,size,type) ({ \
-register int __gu_ret; \
-register unsigned long __gu_val; \
-if (__access_ok(addr,size)) { \
-switch (size) { \
-case 1: __get_user_asm(__gu_val,ub,addr,__gu_ret); break; \
-case 2: __get_user_asm(__gu_val,uh,addr,__gu_ret); break; \
-case 4: __get_user_asm(__gu_val,,addr,__gu_ret); break; \
-case 8: __get_user_asm(__gu_val,d,addr,__gu_ret); break; \
-default: __gu_val = 0; __gu_ret = __get_user_bad(); break; \
-} } else { __gu_val = 0; __gu_ret = -EFAULT; } x = (__force type) __gu_val; __gu_ret; })
-
-#define __get_user_check_ret(x,addr,size,type,retval) ({ \
-register unsigned long __gu_val __asm__ ("l1"); \
-if (__access_ok(addr,size)) { \
-switch (size) { \
-case 1: __get_user_asm_ret(__gu_val,ub,addr,retval); break; \
-case 2: __get_user_asm_ret(__gu_val,uh,addr,retval); break; \
-case 4: __get_user_asm_ret(__gu_val,,addr,retval); break; \
-case 8: __get_user_asm_ret(__gu_val,d,addr,retval); break; \
-default: if (__get_user_bad()) return retval; \
-} x = (__force type) __gu_val; } else return retval; })
-
-#define __get_user_nocheck(x,addr,size,type) ({ \
-register int __gu_ret; \
-register unsigned long __gu_val; \
-switch (size) { \
-case 1: __get_user_asm(__gu_val,ub,addr,__gu_ret); break; \
-case 2: __get_user_asm(__gu_val,uh,addr,__gu_ret); break; \
-case 4: __get_user_asm(__gu_val,,addr,__gu_ret); break; \
-case 8: __get_user_asm(__gu_val,d,addr,__gu_ret); break; \
-default: __gu_val = 0; __gu_ret = __get_user_bad(); break; \
-} x = (__force type) __gu_val; __gu_ret; })
-
-#define __get_user_nocheck_ret(x,addr,size,type,retval) ({ \
-register unsigned long __gu_val __asm__ ("l1"); \
-switch (size) { \
-case 1: __get_user_asm_ret(__gu_val,ub,addr,retval); break; \
-case 2: __get_user_asm_ret(__gu_val,uh,addr,retval); break; \
-case 4: __get_user_asm_ret(__gu_val,,addr,retval); break; \
-case 8: __get_user_asm_ret(__gu_val,d,addr,retval); break; \
-default: if (__get_user_bad()) return retval; \
-} x = (__force type) __gu_val; })
-
-#define __get_user_asm(x,size,addr,ret)					\
+#define __get_user_check(x, addr, size, type) ({ \
+	register int __gu_ret; \
+	register unsigned long __gu_val; \
+	if (__access_ok(addr, size)) { \
+		switch (size) { \
+		case 1: \
+			 __get_user_asm(__gu_val, ub, addr, __gu_ret); \
+			break; \
+		case 2: \
+			__get_user_asm(__gu_val, uh, addr, __gu_ret); \
+			break; \
+		case 4: \
+			__get_user_asm(__gu_val, , addr, __gu_ret); \
+			break; \
+		case 8: \
+			__get_user_asm(__gu_val, d, addr, __gu_ret); \
+			break; \
+		default: \
+			__gu_val = 0; \
+			__gu_ret = __get_user_bad(); \
+			break; \
+		} \
+	 } else { \
+		 __gu_val = 0; \
+		 __gu_ret = -EFAULT; \
+	} \
+	x = (__force type) __gu_val; \
+	__gu_ret; \
+})
+
+#define __get_user_check_ret(x, addr, size, type, retval) ({ \
+	register unsigned long __gu_val __asm__ ("l1"); \
+	if (__access_ok(addr, size)) { \
+		switch (size) { \
+		case 1: \
+			__get_user_asm_ret(__gu_val, ub, addr, retval); \
+			break; \
+		case 2: \
+			__get_user_asm_ret(__gu_val, uh, addr, retval); \
+			break; \
+		case 4: \
+			__get_user_asm_ret(__gu_val, , addr, retval); \
+			break; \
+		case 8: \
+			__get_user_asm_ret(__gu_val, d, addr, retval); \
+			break; \
+		default: \
+			if (__get_user_bad()) \
+				return retval; \
+		} \
+		x = (__force type) __gu_val; \
+	} else \
+		return retval; \
+})
+
+#define __get_user_nocheck(x, addr, size, type) ({ \
+	register int __gu_ret; \
+	register unsigned long __gu_val; \
+	switch (size) { \
+	case 1: \
+		__get_user_asm(__gu_val, ub, addr, __gu_ret); \
+		break; \
+	case 2: \
+		__get_user_asm(__gu_val, uh, addr, __gu_ret); \
+		break; \
+	case 4: \
+		__get_user_asm(__gu_val, , addr, __gu_ret); \
+		break; \
+	case 8: \
+		__get_user_asm(__gu_val, d, addr, __gu_ret); \
+		break; \
+	default: \
+		__gu_val = 0; \
+		__gu_ret = __get_user_bad(); \
+		break; \
+	} \
+	x = (__force type) __gu_val; \
+	__gu_ret; \
+})
+
+#define __get_user_nocheck_ret(x, addr, size, type, retval) ({ \
+	register unsigned long __gu_val __asm__ ("l1"); \
+	switch (size) { \
+	case 1: \
+		__get_user_asm_ret(__gu_val, ub, addr, retval); \
+		break; \
+	case 2: \
+		__get_user_asm_ret(__gu_val, uh, addr, retval); \
+		break; \
+	case 4: \
+		__get_user_asm_ret(__gu_val, , addr, retval); \
+		break; \
+	case 8: \
+		__get_user_asm_ret(__gu_val, d, addr, retval); \
+		break; \
+	default: \
+		if (__get_user_bad()) \
+			return retval; \
+	} \
+	x = (__force type) __gu_val; \
+})
+
+#define __get_user_asm(x, size, addr, ret)				\
 __asm__ __volatile__(							\
-	"/* Get user asm, inline. */\n"					\
-"1:\t"	"ld"#size " %2, %1\n\t"						\
-	"clr	%0\n"							\
-"2:\n\n\t"								\
-	".section .fixup,#alloc,#execinstr\n\t"				\
-	".align	4\n"							\
-"3:\n\t"								\
-	"clr	%1\n\t"							\
-	"b	2b\n\t"							\
-	" mov	%3, %0\n\n\t"						\
-	".previous\n\t"							\
-	".section __ex_table,#alloc\n\t"				\
-	".align	4\n\t"							\
-	".word	1b, 3b\n\n\t"						\
-	".previous\n\t"							\
-       : "=&r" (ret), "=&r" (x) : "m" (*__m(addr)),			\
-	 "i" (-EFAULT))
-
-#define __get_user_asm_ret(x,size,addr,retval)				\
+		"/* Get user asm, inline. */\n"				\
+	"1:\t"	"ld"#size " %2, %1\n\t"					\
+		"clr	%0\n"						\
+	"2:\n\n\t"							\
+		".section .fixup,#alloc,#execinstr\n\t"			\
+		".align	4\n"						\
+	"3:\n\t"							\
+		"clr	%1\n\t"						\
+		"b	2b\n\t"						\
+		" mov	%3, %0\n\n\t"					\
+		".previous\n\t"						\
+		".section __ex_table,#alloc\n\t"			\
+		".align	4\n\t"						\
+		".word	1b, 3b\n\n\t"					\
+		".previous\n\t"						\
+	       : "=&r" (ret), "=&r" (x) : "m" (*__m(addr)),		\
+		 "i" (-EFAULT))
+
+#define __get_user_asm_ret(x, size, addr, retval)			\
 if (__builtin_constant_p(retval) && retval == -EFAULT)			\
-__asm__ __volatile__(							\
-	"/* Get user asm ret, inline. */\n"				\
-"1:\t"	"ld"#size " %1, %0\n\n\t"					\
-	".section __ex_table,#alloc\n\t"				\
-	".align	4\n\t"							\
-	".word	1b,__ret_efault\n\n\t"					\
-	".previous\n\t"							\
-       : "=&r" (x) : "m" (*__m(addr)));					\
+	__asm__ __volatile__(						\
+			"/* Get user asm ret, inline. */\n"		\
+		"1:\t"	"ld"#size " %1, %0\n\n\t"			\
+			".section __ex_table,#alloc\n\t"		\
+			".align	4\n\t"					\
+			".word	1b,__ret_efault\n\n\t"			\
+			".previous\n\t"					\
+		       : "=&r" (x) : "m" (*__m(addr)));			\
 else									\
-__asm__ __volatile__(							\
-	"/* Get user asm ret, inline. */\n"				\
-"1:\t"	"ld"#size " %1, %0\n\n\t"					\
-	".section .fixup,#alloc,#execinstr\n\t"				\
-	".align	4\n"							\
-"3:\n\t"								\
-	"ret\n\t"							\
-	" restore %%g0, %2, %%o0\n\n\t"					\
-	".previous\n\t"							\
-	".section __ex_table,#alloc\n\t"				\
-	".align	4\n\t"							\
-	".word	1b, 3b\n\n\t"						\
-	".previous\n\t"							\
-       : "=&r" (x) : "m" (*__m(addr)), "i" (retval))
+	__asm__ __volatile__(						\
+			"/* Get user asm ret, inline. */\n"		\
+		"1:\t"	"ld"#size " %1, %0\n\n\t"			\
+			".section .fixup,#alloc,#execinstr\n\t"		\
+			".align	4\n"					\
+		"3:\n\t"						\
+			"ret\n\t"					\
+			" restore %%g0, %2, %%o0\n\n\t"			\
+			".previous\n\t"					\
+			".section __ex_table,#alloc\n\t"		\
+			".align	4\n\t"					\
+			".word	1b, 3b\n\n\t"				\
+			".previous\n\t"					\
+		       : "=&r" (x) : "m" (*__m(addr)), "i" (retval))
 
 int __get_user_bad(void);
 

commit 9b7accb286982e0df140b3accae8216656b3ef37
Author: Michael S. Tsirkin <mst@redhat.com>
Date:   Fri Dec 12 01:56:04 2014 +0200

    sparc32/uaccess: fix sparse errors
    
    virtio wants to read bitwise types from userspace using get_user.  At the
    moment this triggers sparse errors, since the value is passed through an
    integer.
    
    Fix that up using __force.
    
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    
    Acked-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index 9634d086fc56..8b571a0db0f6 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -164,7 +164,7 @@ case 2: __get_user_asm(__gu_val,uh,addr,__gu_ret); break; \
 case 4: __get_user_asm(__gu_val,,addr,__gu_ret); break; \
 case 8: __get_user_asm(__gu_val,d,addr,__gu_ret); break; \
 default: __gu_val = 0; __gu_ret = __get_user_bad(); break; \
-} } else { __gu_val = 0; __gu_ret = -EFAULT; } x = (type) __gu_val; __gu_ret; })
+} } else { __gu_val = 0; __gu_ret = -EFAULT; } x = (__force type) __gu_val; __gu_ret; })
 
 #define __get_user_check_ret(x,addr,size,type,retval) ({ \
 register unsigned long __gu_val __asm__ ("l1"); \
@@ -175,7 +175,7 @@ case 2: __get_user_asm_ret(__gu_val,uh,addr,retval); break; \
 case 4: __get_user_asm_ret(__gu_val,,addr,retval); break; \
 case 8: __get_user_asm_ret(__gu_val,d,addr,retval); break; \
 default: if (__get_user_bad()) return retval; \
-} x = (type) __gu_val; } else return retval; })
+} x = (__force type) __gu_val; } else return retval; })
 
 #define __get_user_nocheck(x,addr,size,type) ({ \
 register int __gu_ret; \
@@ -186,7 +186,7 @@ case 2: __get_user_asm(__gu_val,uh,addr,__gu_ret); break; \
 case 4: __get_user_asm(__gu_val,,addr,__gu_ret); break; \
 case 8: __get_user_asm(__gu_val,d,addr,__gu_ret); break; \
 default: __gu_val = 0; __gu_ret = __get_user_bad(); break; \
-} x = (type) __gu_val; __gu_ret; })
+} x = (__force type) __gu_val; __gu_ret; })
 
 #define __get_user_nocheck_ret(x,addr,size,type,retval) ({ \
 register unsigned long __gu_val __asm__ ("l1"); \
@@ -196,7 +196,7 @@ case 2: __get_user_asm_ret(__gu_val,uh,addr,retval); break; \
 case 4: __get_user_asm_ret(__gu_val,,addr,retval); break; \
 case 8: __get_user_asm_ret(__gu_val,d,addr,retval); break; \
 default: if (__get_user_bad()) return retval; \
-} x = (type) __gu_val; })
+} x = (__force type) __gu_val; })
 
 #define __get_user_asm(x,size,addr,ret)					\
 __asm__ __volatile__(							\

commit f05a68653e56ca2f23bccf7e50be69486886f052
Author: Sam Ravnborg <sam@ravnborg.org>
Date:   Fri May 16 23:25:50 2014 +0200

    sparc: drop use of extern for prototypes in arch/sparc/include/asm
    
    Drop extern for all prototypes and adjust alignment of parameters
    as required after the removal.
    In a few rare cases adjust linelength to conform to maximum 80 chars,
    and likewise in a few rare cases adjust alignment of parameters
    to static functions.
    
    Signed-off-by: Sam Ravnborg <sam@ravnborg.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index 53a28dd59f59..9634d086fc56 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -78,9 +78,9 @@ struct exception_table_entry
 };
 
 /* Returns 0 if exception not found and fixup otherwise.  */
-extern unsigned long search_extables_range(unsigned long addr, unsigned long *g2);
+unsigned long search_extables_range(unsigned long addr, unsigned long *g2);
 
-extern void __ret_efault(void);
+void __ret_efault(void);
 
 /* Uh, these should become the main single-value transfer routines..
  * They automatically use the right size if we just have the right
@@ -152,7 +152,7 @@ __asm__ __volatile__(							\
        : "=&r" (ret) : "r" (x), "m" (*__m(addr)),			\
 	 "i" (-EFAULT))
 
-extern int __put_user_bad(void);
+int __put_user_bad(void);
 
 #define __get_user_check(x,addr,size,type) ({ \
 register int __gu_ret; \
@@ -244,9 +244,9 @@ __asm__ __volatile__(							\
 	".previous\n\t"							\
        : "=&r" (x) : "m" (*__m(addr)), "i" (retval))
 
-extern int __get_user_bad(void);
+int __get_user_bad(void);
 
-extern unsigned long __copy_user(void __user *to, const void __user *from, unsigned long size);
+unsigned long __copy_user(void __user *to, const void __user *from, unsigned long size);
 
 static inline unsigned long copy_to_user(void __user *to, const void *from, unsigned long n)
 {
@@ -306,8 +306,8 @@ static inline unsigned long clear_user(void __user *addr, unsigned long n)
 		return n;
 }
 
-extern __must_check long strlen_user(const char __user *str);
-extern __must_check long strnlen_user(const char __user *str, long n);
+__must_check long strlen_user(const char __user *str);
+__must_check long strnlen_user(const char __user *str, long n);
 
 #endif  /* __ASSEMBLY__ */
 

commit 2c66f623631709aa5f2e4c14c7e089682e7394a3
Author: David Miller <davem@davemloft.net>
Date:   Sat May 26 11:14:27 2012 -0700

    sparc: use the new generic strnlen_user() function
    
    This throws away the sparc-specific functions in favor of the generic
    optimized version.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index 59586b57ef1a..53a28dd59f59 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -16,6 +16,8 @@
 
 #ifndef __ASSEMBLY__
 
+#include <asm/processor.h>
+
 #define ARCH_HAS_SORT_EXTABLE
 #define ARCH_HAS_SEARCH_EXTABLE
 
@@ -304,24 +306,8 @@ static inline unsigned long clear_user(void __user *addr, unsigned long n)
 		return n;
 }
 
-extern long __strlen_user(const char __user *);
-extern long __strnlen_user(const char __user *, long len);
-
-static inline long strlen_user(const char __user *str)
-{
-	if (!access_ok(VERIFY_READ, str, 0))
-		return 0;
-	else
-		return __strlen_user(str);
-}
-
-static inline long strnlen_user(const char __user *str, long len)
-{
-	if (!access_ok(VERIFY_READ, str, 0))
-		return 0;
-	else
-		return __strnlen_user(str, len);
-}
+extern __must_check long strlen_user(const char __user *str);
+extern __must_check long strnlen_user(const char __user *str, long n);
 
 #endif  /* __ASSEMBLY__ */
 

commit ff06dffbc8abfc60d6a0332f058f1d1bb01abb31
Author: David S. Miller <davem@davemloft.net>
Date:   Tue May 22 17:53:19 2012 -0700

    sparc: Add full proper error handling to strncpy_from_user().
    
    Linus removed the end-of-address-space hackery from
    fs/namei.c:do_getname() so we really have to validate these edge
    conditions and cannot cheat any more (as x86 used to as well).
    
    Move to a common C implementation like x86 did.  And if both
    src and dst are sufficiently aligned we'll do word at a time
    copies and checks as well.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index d50c310f5d38..59586b57ef1a 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -304,16 +304,6 @@ static inline unsigned long clear_user(void __user *addr, unsigned long n)
 		return n;
 }
 
-extern long __strncpy_from_user(char *dest, const char __user *src, long count);
-
-static inline long strncpy_from_user(char *dest, const char __user *src, long count)
-{
-	if (__access_ok((unsigned long) src, count))
-		return __strncpy_from_user(dest, src, count);
-	else
-		return -EFAULT;
-}
-
 extern long __strlen_user(const char __user *);
 extern long __strnlen_user(const char __user *, long len);
 

commit 716a5d73a787a3d1f6e2bd8ce34a788bb8bf368f
Author: David S. Miller <davem@davemloft.net>
Date:   Fri May 11 21:07:50 2012 -0700

    sparc32: Kill asm/vac-ops.h
    
    All sun4/sun4c stuff and unused.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index 8303ac481034..d50c310f5d38 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -12,7 +12,6 @@
 #include <linux/sched.h>
 #include <linux/string.h>
 #include <linux/errno.h>
-#include <asm/vac-ops.h>
 #endif
 
 #ifndef __ASSEMBLY__

commit 4cb6066af9ee58ddba58a63cc77b324ac21add75
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Aug 9 00:45:46 2010 -0700

    sparc: Kill user copy check code.
    
    For whatever reason GCC isn't able to figure things out in
    the control flow (in particular when min() and max() expressions
    are involved) on sparc as well as it can on x86.
    
    So lots of useless incorrect user copy warnings get spewed and the
    full-on compile failure mode of the user copy checks were never usable
    on sparc at all.
    
    People can debug these kinds of problems on x86.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index 25f1d10155e8..8303ac481034 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -260,23 +260,8 @@ static inline unsigned long __copy_to_user(void __user *to, const void *from, un
 	return __copy_user(to, (__force void __user *) from, n);
 }
 
-extern void copy_from_user_overflow(void)
-#ifdef CONFIG_DEBUG_STRICT_USER_COPY_CHECKS
-	__compiletime_error("copy_from_user() buffer size is not provably correct")
-#else
-	__compiletime_warning("copy_from_user() buffer size is not provably correct")
-#endif
-;
-
 static inline unsigned long copy_from_user(void *to, const void __user *from, unsigned long n)
 {
-	int sz = __compiletime_object_size(to);
-
-	if (unlikely(sz != -1 && sz < n)) {
-		copy_from_user_overflow();
-		return n;
-	}
-
 	if (n && __access_ok((unsigned long) from, n))
 		return __copy_user((__force void __user *) to, from, n);
 	else

commit 6df1c176994fab993f3112e3e4145a7d2bae64d0
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Tue Jan 5 20:41:48 2010 -0800

    sparc: copy_from_user() should not return -EFAULT
    
    From: Heiko Carstens <heiko.carstens@de.ibm.com>
    
    Callers of copy_from_user() expect it to return the number of bytes
    it could not copy. In no case it is supposed to return -EFAULT.
    
    In case of a detected buffer overflow just return the requested
    length. In addition one could think of a memset that would clear
    the size of the target object.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index 489d2ba92bcb..25f1d10155e8 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -274,7 +274,7 @@ static inline unsigned long copy_from_user(void *to, const void __user *from, un
 
 	if (unlikely(sz != -1 && sz < n)) {
 		copy_from_user_overflow();
-		return -EFAULT;
+		return n;
 	}
 
 	if (n && __access_ok((unsigned long) from, n))

commit fb34035e7b4bb3edc7c2dc0683cfe21f57a9574d
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Dec 10 23:05:23 2009 -0800

    sparc: Use __builtin_object_size() to validate the buffer size for copy_from_user()
    
    This mirrors x86 commit 9f0cf4adb6aa0bfccf675c938124e68f7f06349d
    (x86: Use __builtin_object_size() to validate the buffer size for copy_from_user())
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index 8303ac481034..489d2ba92bcb 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -260,8 +260,23 @@ static inline unsigned long __copy_to_user(void __user *to, const void *from, un
 	return __copy_user(to, (__force void __user *) from, n);
 }
 
+extern void copy_from_user_overflow(void)
+#ifdef CONFIG_DEBUG_STRICT_USER_COPY_CHECKS
+	__compiletime_error("copy_from_user() buffer size is not provably correct")
+#else
+	__compiletime_warning("copy_from_user() buffer size is not provably correct")
+#endif
+;
+
 static inline unsigned long copy_from_user(void *to, const void __user *from, unsigned long n)
 {
+	int sz = __compiletime_object_size(to);
+
+	if (unlikely(sz != -1 && sz < n)) {
+		copy_from_user_overflow();
+		return -EFAULT;
+	}
+
 	if (n && __access_ok((unsigned long) from, n))
 		return __copy_user((__force void __user *) to, from, n);
 	else

commit ad6561dffa17f17bb68d7207d422c26c381c4313
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Fri Jun 12 21:47:03 2009 -0600

    module: trim exception table on init free.
    
    It's theoretically possible that there are exception table entries
    which point into the (freed) init text of modules.  These could cause
    future problems if other modules get loaded into that memory and cause
    an exception as we'd see the wrong fixup.  The only case I know of is
    kvm-intel.ko (when CONFIG_CC_OPTIMIZE_FOR_SIZE=n).
    
    Amerigo fixed this long-standing FIXME in the x86 version, but this
    patch is more general.
    
    This implements trim_init_extable(); most archs are simple since they
    use the standard lib/extable.c sort code.  Alpha and IA64 use relative
    addresses in their fixups, so thier trimming is a slight variation.
    
    Sparc32 is unique; it doesn't seem to define ARCH_HAS_SORT_EXTABLE,
    yet it defines its own sort_extable() which overrides the one in lib.
    It doesn't sort, so we have to mark deleted entries instead of
    actually trimming them.
    
    Inspired-by: Amerigo Wang <amwang@redhat.com>
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Cc: linux-alpha@vger.kernel.org
    Cc: sparclinux@vger.kernel.org
    Cc: linux-ia64@vger.kernel.org

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
index 47d5619d43fa..8303ac481034 100644
--- a/arch/sparc/include/asm/uaccess_32.h
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -17,6 +17,9 @@
 
 #ifndef __ASSEMBLY__
 
+#define ARCH_HAS_SORT_EXTABLE
+#define ARCH_HAS_SEARCH_EXTABLE
+
 /* Sparc is not segmented, however we need to be able to fool access_ok()
  * when doing system calls from kernel mode legitimately.
  *

commit a439fe51a1f8eb087c22dd24d69cebae4a3addac
Author: Sam Ravnborg <sam@ravnborg.org>
Date:   Sun Jul 27 23:00:59 2008 +0200

    sparc, sparc64: use arch/sparc/include
    
    The majority of this patch was created by the following script:
    
    ***
    ASM=arch/sparc/include/asm
    mkdir -p $ASM
    git mv include/asm-sparc64/ftrace.h $ASM
    git rm include/asm-sparc64/*
    git mv include/asm-sparc/* $ASM
    sed -ie 's/asm-sparc64/asm/g' $ASM/*
    sed -ie 's/asm-sparc/asm/g' $ASM/*
    ***
    
    The rest was an update of the top-level Makefile to use sparc
    for header files when sparc64 is being build.
    And a small fixlet to pick up the correct unistd.h from
    sparc64 code.
    
    Signed-off-by: Sam Ravnborg <sam@ravnborg.org>

diff --git a/arch/sparc/include/asm/uaccess_32.h b/arch/sparc/include/asm/uaccess_32.h
new file mode 100644
index 000000000000..47d5619d43fa
--- /dev/null
+++ b/arch/sparc/include/asm/uaccess_32.h
@@ -0,0 +1,336 @@
+/*
+ * uaccess.h: User space memore access functions.
+ *
+ * Copyright (C) 1996 David S. Miller (davem@caip.rutgers.edu)
+ * Copyright (C) 1996,1997 Jakub Jelinek (jj@sunsite.mff.cuni.cz)
+ */
+#ifndef _ASM_UACCESS_H
+#define _ASM_UACCESS_H
+
+#ifdef __KERNEL__
+#include <linux/compiler.h>
+#include <linux/sched.h>
+#include <linux/string.h>
+#include <linux/errno.h>
+#include <asm/vac-ops.h>
+#endif
+
+#ifndef __ASSEMBLY__
+
+/* Sparc is not segmented, however we need to be able to fool access_ok()
+ * when doing system calls from kernel mode legitimately.
+ *
+ * "For historical reasons, these macros are grossly misnamed." -Linus
+ */
+
+#define KERNEL_DS   ((mm_segment_t) { 0 })
+#define USER_DS     ((mm_segment_t) { -1 })
+
+#define VERIFY_READ	0
+#define VERIFY_WRITE	1
+
+#define get_ds()	(KERNEL_DS)
+#define get_fs()	(current->thread.current_ds)
+#define set_fs(val)	((current->thread.current_ds) = (val))
+
+#define segment_eq(a,b)	((a).seg == (b).seg)
+
+/* We have there a nice not-mapped page at PAGE_OFFSET - PAGE_SIZE, so that this test
+ * can be fairly lightweight.
+ * No one can read/write anything from userland in the kernel space by setting
+ * large size and address near to PAGE_OFFSET - a fault will break his intentions.
+ */
+#define __user_ok(addr, size) ({ (void)(size); (addr) < STACK_TOP; })
+#define __kernel_ok (segment_eq(get_fs(), KERNEL_DS))
+#define __access_ok(addr,size) (__user_ok((addr) & get_fs().seg,(size)))
+#define access_ok(type, addr, size)					\
+	({ (void)(type); __access_ok((unsigned long)(addr), size); })
+
+/*
+ * The exception table consists of pairs of addresses: the first is the
+ * address of an instruction that is allowed to fault, and the second is
+ * the address at which the program should continue.  No registers are
+ * modified, so it is entirely up to the continuation code to figure out
+ * what to do.
+ *
+ * All the routines below use bits of fixup code that are out of line
+ * with the main instruction path.  This means when everything is well,
+ * we don't even have to jump over them.  Further, they do not intrude
+ * on our cache or tlb entries.
+ *
+ * There is a special way how to put a range of potentially faulting
+ * insns (like twenty ldd/std's with now intervening other instructions)
+ * You specify address of first in insn and 0 in fixup and in the next
+ * exception_table_entry you specify last potentially faulting insn + 1
+ * and in fixup the routine which should handle the fault.
+ * That fixup code will get
+ * (faulting_insn_address - first_insn_in_the_range_address)/4
+ * in %g2 (ie. index of the faulting instruction in the range).
+ */
+
+struct exception_table_entry
+{
+        unsigned long insn, fixup;
+};
+
+/* Returns 0 if exception not found and fixup otherwise.  */
+extern unsigned long search_extables_range(unsigned long addr, unsigned long *g2);
+
+extern void __ret_efault(void);
+
+/* Uh, these should become the main single-value transfer routines..
+ * They automatically use the right size if we just have the right
+ * pointer type..
+ *
+ * This gets kind of ugly. We want to return _two_ values in "get_user()"
+ * and yet we don't want to do any pointers, because that is too much
+ * of a performance impact. Thus we have a few rather ugly macros here,
+ * and hide all the ugliness from the user.
+ */
+#define put_user(x,ptr) ({ \
+unsigned long __pu_addr = (unsigned long)(ptr); \
+__chk_user_ptr(ptr); \
+__put_user_check((__typeof__(*(ptr)))(x),__pu_addr,sizeof(*(ptr))); })
+
+#define get_user(x,ptr) ({ \
+unsigned long __gu_addr = (unsigned long)(ptr); \
+__chk_user_ptr(ptr); \
+__get_user_check((x),__gu_addr,sizeof(*(ptr)),__typeof__(*(ptr))); })
+
+/*
+ * The "__xxx" versions do not do address space checking, useful when
+ * doing multiple accesses to the same area (the user has to do the
+ * checks by hand with "access_ok()")
+ */
+#define __put_user(x,ptr) __put_user_nocheck((__typeof__(*(ptr)))(x),(ptr),sizeof(*(ptr)))
+#define __get_user(x,ptr) __get_user_nocheck((x),(ptr),sizeof(*(ptr)),__typeof__(*(ptr)))
+
+struct __large_struct { unsigned long buf[100]; };
+#define __m(x) ((struct __large_struct __user *)(x))
+
+#define __put_user_check(x,addr,size) ({ \
+register int __pu_ret; \
+if (__access_ok(addr,size)) { \
+switch (size) { \
+case 1: __put_user_asm(x,b,addr,__pu_ret); break; \
+case 2: __put_user_asm(x,h,addr,__pu_ret); break; \
+case 4: __put_user_asm(x,,addr,__pu_ret); break; \
+case 8: __put_user_asm(x,d,addr,__pu_ret); break; \
+default: __pu_ret = __put_user_bad(); break; \
+} } else { __pu_ret = -EFAULT; } __pu_ret; })
+
+#define __put_user_nocheck(x,addr,size) ({ \
+register int __pu_ret; \
+switch (size) { \
+case 1: __put_user_asm(x,b,addr,__pu_ret); break; \
+case 2: __put_user_asm(x,h,addr,__pu_ret); break; \
+case 4: __put_user_asm(x,,addr,__pu_ret); break; \
+case 8: __put_user_asm(x,d,addr,__pu_ret); break; \
+default: __pu_ret = __put_user_bad(); break; \
+} __pu_ret; })
+
+#define __put_user_asm(x,size,addr,ret)					\
+__asm__ __volatile__(							\
+	"/* Put user asm, inline. */\n"					\
+"1:\t"	"st"#size " %1, %2\n\t"						\
+	"clr	%0\n"							\
+"2:\n\n\t"								\
+	".section .fixup,#alloc,#execinstr\n\t"				\
+	".align	4\n"							\
+"3:\n\t"								\
+	"b	2b\n\t"							\
+	" mov	%3, %0\n\t"						\
+        ".previous\n\n\t"						\
+	".section __ex_table,#alloc\n\t"				\
+	".align	4\n\t"							\
+	".word	1b, 3b\n\t"						\
+	".previous\n\n\t"						\
+       : "=&r" (ret) : "r" (x), "m" (*__m(addr)),			\
+	 "i" (-EFAULT))
+
+extern int __put_user_bad(void);
+
+#define __get_user_check(x,addr,size,type) ({ \
+register int __gu_ret; \
+register unsigned long __gu_val; \
+if (__access_ok(addr,size)) { \
+switch (size) { \
+case 1: __get_user_asm(__gu_val,ub,addr,__gu_ret); break; \
+case 2: __get_user_asm(__gu_val,uh,addr,__gu_ret); break; \
+case 4: __get_user_asm(__gu_val,,addr,__gu_ret); break; \
+case 8: __get_user_asm(__gu_val,d,addr,__gu_ret); break; \
+default: __gu_val = 0; __gu_ret = __get_user_bad(); break; \
+} } else { __gu_val = 0; __gu_ret = -EFAULT; } x = (type) __gu_val; __gu_ret; })
+
+#define __get_user_check_ret(x,addr,size,type,retval) ({ \
+register unsigned long __gu_val __asm__ ("l1"); \
+if (__access_ok(addr,size)) { \
+switch (size) { \
+case 1: __get_user_asm_ret(__gu_val,ub,addr,retval); break; \
+case 2: __get_user_asm_ret(__gu_val,uh,addr,retval); break; \
+case 4: __get_user_asm_ret(__gu_val,,addr,retval); break; \
+case 8: __get_user_asm_ret(__gu_val,d,addr,retval); break; \
+default: if (__get_user_bad()) return retval; \
+} x = (type) __gu_val; } else return retval; })
+
+#define __get_user_nocheck(x,addr,size,type) ({ \
+register int __gu_ret; \
+register unsigned long __gu_val; \
+switch (size) { \
+case 1: __get_user_asm(__gu_val,ub,addr,__gu_ret); break; \
+case 2: __get_user_asm(__gu_val,uh,addr,__gu_ret); break; \
+case 4: __get_user_asm(__gu_val,,addr,__gu_ret); break; \
+case 8: __get_user_asm(__gu_val,d,addr,__gu_ret); break; \
+default: __gu_val = 0; __gu_ret = __get_user_bad(); break; \
+} x = (type) __gu_val; __gu_ret; })
+
+#define __get_user_nocheck_ret(x,addr,size,type,retval) ({ \
+register unsigned long __gu_val __asm__ ("l1"); \
+switch (size) { \
+case 1: __get_user_asm_ret(__gu_val,ub,addr,retval); break; \
+case 2: __get_user_asm_ret(__gu_val,uh,addr,retval); break; \
+case 4: __get_user_asm_ret(__gu_val,,addr,retval); break; \
+case 8: __get_user_asm_ret(__gu_val,d,addr,retval); break; \
+default: if (__get_user_bad()) return retval; \
+} x = (type) __gu_val; })
+
+#define __get_user_asm(x,size,addr,ret)					\
+__asm__ __volatile__(							\
+	"/* Get user asm, inline. */\n"					\
+"1:\t"	"ld"#size " %2, %1\n\t"						\
+	"clr	%0\n"							\
+"2:\n\n\t"								\
+	".section .fixup,#alloc,#execinstr\n\t"				\
+	".align	4\n"							\
+"3:\n\t"								\
+	"clr	%1\n\t"							\
+	"b	2b\n\t"							\
+	" mov	%3, %0\n\n\t"						\
+	".previous\n\t"							\
+	".section __ex_table,#alloc\n\t"				\
+	".align	4\n\t"							\
+	".word	1b, 3b\n\n\t"						\
+	".previous\n\t"							\
+       : "=&r" (ret), "=&r" (x) : "m" (*__m(addr)),			\
+	 "i" (-EFAULT))
+
+#define __get_user_asm_ret(x,size,addr,retval)				\
+if (__builtin_constant_p(retval) && retval == -EFAULT)			\
+__asm__ __volatile__(							\
+	"/* Get user asm ret, inline. */\n"				\
+"1:\t"	"ld"#size " %1, %0\n\n\t"					\
+	".section __ex_table,#alloc\n\t"				\
+	".align	4\n\t"							\
+	".word	1b,__ret_efault\n\n\t"					\
+	".previous\n\t"							\
+       : "=&r" (x) : "m" (*__m(addr)));					\
+else									\
+__asm__ __volatile__(							\
+	"/* Get user asm ret, inline. */\n"				\
+"1:\t"	"ld"#size " %1, %0\n\n\t"					\
+	".section .fixup,#alloc,#execinstr\n\t"				\
+	".align	4\n"							\
+"3:\n\t"								\
+	"ret\n\t"							\
+	" restore %%g0, %2, %%o0\n\n\t"					\
+	".previous\n\t"							\
+	".section __ex_table,#alloc\n\t"				\
+	".align	4\n\t"							\
+	".word	1b, 3b\n\n\t"						\
+	".previous\n\t"							\
+       : "=&r" (x) : "m" (*__m(addr)), "i" (retval))
+
+extern int __get_user_bad(void);
+
+extern unsigned long __copy_user(void __user *to, const void __user *from, unsigned long size);
+
+static inline unsigned long copy_to_user(void __user *to, const void *from, unsigned long n)
+{
+	if (n && __access_ok((unsigned long) to, n))
+		return __copy_user(to, (__force void __user *) from, n);
+	else
+		return n;
+}
+
+static inline unsigned long __copy_to_user(void __user *to, const void *from, unsigned long n)
+{
+	return __copy_user(to, (__force void __user *) from, n);
+}
+
+static inline unsigned long copy_from_user(void *to, const void __user *from, unsigned long n)
+{
+	if (n && __access_ok((unsigned long) from, n))
+		return __copy_user((__force void __user *) to, from, n);
+	else
+		return n;
+}
+
+static inline unsigned long __copy_from_user(void *to, const void __user *from, unsigned long n)
+{
+	return __copy_user((__force void __user *) to, from, n);
+}
+
+#define __copy_to_user_inatomic __copy_to_user
+#define __copy_from_user_inatomic __copy_from_user
+
+static inline unsigned long __clear_user(void __user *addr, unsigned long size)
+{
+	unsigned long ret;
+
+	__asm__ __volatile__ (
+		".section __ex_table,#alloc\n\t"
+		".align 4\n\t"
+		".word 1f,3\n\t"
+		".previous\n\t"
+		"mov %2, %%o1\n"
+		"1:\n\t"
+		"call __bzero\n\t"
+		" mov %1, %%o0\n\t"
+		"mov %%o0, %0\n"
+		: "=r" (ret) : "r" (addr), "r" (size) :
+		"o0", "o1", "o2", "o3", "o4", "o5", "o7",
+		"g1", "g2", "g3", "g4", "g5", "g7", "cc");
+
+	return ret;
+}
+
+static inline unsigned long clear_user(void __user *addr, unsigned long n)
+{
+	if (n && __access_ok((unsigned long) addr, n))
+		return __clear_user(addr, n);
+	else
+		return n;
+}
+
+extern long __strncpy_from_user(char *dest, const char __user *src, long count);
+
+static inline long strncpy_from_user(char *dest, const char __user *src, long count)
+{
+	if (__access_ok((unsigned long) src, count))
+		return __strncpy_from_user(dest, src, count);
+	else
+		return -EFAULT;
+}
+
+extern long __strlen_user(const char __user *);
+extern long __strnlen_user(const char __user *, long len);
+
+static inline long strlen_user(const char __user *str)
+{
+	if (!access_ok(VERIFY_READ, str, 0))
+		return 0;
+	else
+		return __strlen_user(str);
+}
+
+static inline long strnlen_user(const char __user *str, long len)
+{
+	if (!access_ok(VERIFY_READ, str, 0))
+		return 0;
+	else
+		return __strnlen_user(str, len);
+}
+
+#endif  /* __ASSEMBLY__ */
+
+#endif /* _ASM_UACCESS_H */
