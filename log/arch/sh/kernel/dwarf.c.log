commit a67012412e5a820c44239af9712a1a6037b33fd4
Merge: 7e928df80d30 dc56367cb5db
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jan 5 14:08:00 2019 -0800

    Merge tag 'trace-v4.21-1' of git://git.kernel.org/pub/scm/linux/kernel/git/rostedt/linux-trace
    
    Pull ftrace sh build fix from Steven Rostedt:
     "It appears that the zero-day bot did find a bug in my sh build.
    
      And that I didn't have the bad code in my config file when I cross
      compiled it, although there are a few other errors in sh that makes it
      not build for me, I missed that I added one more"
    
    * tag 'trace-v4.21-1' of git://git.kernel.org/pub/scm/linux/kernel/git/rostedt/linux-trace:
      sh: ftrace: Fix missing parenthesis in WARN_ON()

commit dc56367cb5dbf9d593e4b12373489df9a7edb72c
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Thu Jan 3 22:02:39 2019 -0500

    sh: ftrace: Fix missing parenthesis in WARN_ON()
    
    Adding a function inside a WARN_ON() didn't close the WARN_ON parathesis.
    
    Link: http://lkml.kernel.org/r/201901020958.28Mzbs0O%fengguang.wu@intel.com
    Cc: linux-sh@vger.kernel.org
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Rich Felker <dalias@libc.org>
    Reported-by: kbuild test robot <lkp@intel.com>
    Fixes: cec8d0e7f06e ("sh: ftrace: Use ftrace_graph_get_ret_stack() instead of curr_ret_stack")
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index df0fd6efe758..00622598a245 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -619,7 +619,7 @@ struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
 		 * than one patched return address on our stack,
 		 * complain loudly.
 		 */
-		WARN_ON(ftrace_graph_get_ret_stack(current, 1);
+		WARN_ON(ftrace_graph_get_ret_stack(current, 1));
 	}
 #endif
 

commit 495d714ad140e1732e66c45d0409054b24c1a0d6
Merge: f12e840c819b 3d739c1f6156
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Dec 31 11:46:59 2018 -0800

    Merge tag 'trace-v4.21' of git://git.kernel.org/pub/scm/linux/kernel/git/rostedt/linux-trace
    
    Pull tracing updates from Steven Rostedt:
    
     - Rework of the kprobe/uprobe and synthetic events to consolidate all
       the dynamic event code. This will make changes in the future easier.
    
     - Partial rewrite of the function graph tracing infrastructure. This
       will allow for multiple users of hooking onto functions to get the
       callback (return) of the function. This is the ground work for having
       kprobes and function graph tracer using one code base.
    
     - Clean up of the histogram code that will facilitate adding more
       features to the histograms in the future.
    
     - Addition of str_has_prefix() and a few use cases. There currently is
       a similar function strstart() that is used in a few places, but only
       returns a bool and not a length. These instances will be removed in
       the future to use str_has_prefix() instead.
    
     - A few other various clean ups as well.
    
    * tag 'trace-v4.21' of git://git.kernel.org/pub/scm/linux/kernel/git/rostedt/linux-trace: (57 commits)
      tracing: Use the return of str_has_prefix() to remove open coded numbers
      tracing: Have the historgram use the result of str_has_prefix() for len of prefix
      tracing: Use str_has_prefix() instead of using fixed sizes
      tracing: Use str_has_prefix() helper for histogram code
      string.h: Add str_has_prefix() helper function
      tracing: Make function ‘ftrace_exports’ static
      tracing: Simplify printf'ing in seq_print_sym
      tracing: Avoid -Wformat-nonliteral warning
      tracing: Merge seq_print_sym_short() and seq_print_sym_offset()
      tracing: Add hist trigger comments for variable-related fields
      tracing: Remove hist trigger synth_var_refs
      tracing: Use hist trigger's var_ref array to destroy var_refs
      tracing: Remove open-coding of hist trigger var_ref management
      tracing: Use var_refs[] for hist trigger reference checking
      tracing: Change strlen to sizeof for hist trigger static strings
      tracing: Remove unnecessary hist trigger struct field
      tracing: Fix ftrace_graph_get_ret_stack() to use task and not current
      seq_buf: Use size_t for len in seq_buf_puts()
      seq_buf: Make seq_buf_puts() null-terminate the buffer
      arm64: Use ftrace_graph_get_ret_stack() instead of curr_ret_stack
      ...

commit 5933f6d220403b55772d2caf48a9a39d777fd630
Author: Kuninori Morimoto <kuninori.morimoto.gx@renesas.com>
Date:   Fri Dec 28 00:32:24 2018 -0800

    sh: kernel: convert to SPDX identifiers
    
    Update license to use SPDX-License-Identifier instead of verbose license
    text.
    
    Link: http://lkml.kernel.org/r/8736rccswn.wl-kuninori.morimoto.gx@renesas.com
    Signed-off-by: Kuninori Morimoto <kuninori.morimoto.gx@renesas.com>
    Reviewed-by: Simon Horman <horms+renesas@verge.net.au>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index bb511e2d9d68..9e1d26c8a0c4 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -1,10 +1,7 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * Copyright (C) 2009 Matt Fleming <matt@console-pimps.org>
  *
- * This file is subject to the terms and conditions of the GNU General Public
- * License.  See the file "COPYING" in the main directory of this archive
- * for more details.
- *
  * This is an implementation of a DWARF unwinder. Its main purpose is
  * for generating stacktrace information. Based on the DWARF 3
  * specification from http://www.dwarfstd.org.

commit cec8d0e7f06e08b981e9d61bef267c8c36d536f5
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Fri Dec 7 13:06:04 2018 -0500

    sh: ftrace: Use ftrace_graph_get_ret_stack() instead of curr_ret_stack
    
    The structure of the ret_stack array on the task struct is going to
    change, and accessing it directly via the curr_ret_stack index will no
    longer give the ret_stack entry that holds the return address. To access
    that, architectures must now use ftrace_graph_get_ret_stack() to get the
    associated ret_stack that matches the saved return address.
    
    Cc: linux-sh@vger.kernel.org
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Rich Felker <dalias@libc.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index bb511e2d9d68..df0fd6efe758 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -608,17 +608,18 @@ struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
 	 * expected to find the real return address.
 	 */
 	if (pc == (unsigned long)&return_to_handler) {
-		int index = current->curr_ret_stack;
+		struct ftrace_ret_stack *ret_stack;
 
+		ret_stack = ftrace_graph_get_ret_stack(current, 0);
+		if (ret_stack)
+			pc = ret_stack->ret;
 		/*
 		 * We currently have no way of tracking how many
 		 * return_to_handler()'s we've seen. If there is more
 		 * than one patched return address on our stack,
 		 * complain loudly.
 		 */
-		WARN_ON(index > 0);
-
-		pc = current->ret_stack[index].ret;
+		WARN_ON(ftrace_graph_get_ret_stack(current, 1);
 	}
 #endif
 

commit 8d00d0c00c0720c43b0eec0e86a6e916192f35d0
Author: Nick Desaulniers <ndesaulniers@google.com>
Date:   Fri Aug 17 15:44:21 2018 -0700

    sh: prefer _THIS_IP_ to current_text_addr
    
    As part of the effort to reduce the code duplication between _THIS_IP_
    and current_text_addr(), let's consolidate callers of
    current_text_addr() to use _THIS_IP_.
    
    Link: http://lkml.kernel.org/r/20180801185331.39535-1-ndesaulniers@google.com
    Signed-off-by: Nick Desaulniers <ndesaulniers@google.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Rich Felker <dalias@libc.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 1a2526676a87..bb511e2d9d68 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -599,7 +599,7 @@ struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
 	 * time this function makes its first function call.
 	 */
 	if (!pc || !prev)
-		pc = (unsigned long)current_text_addr();
+		pc = _THIS_IP_;
 
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 	/*

commit 75f296d93bcebcfe375884ddac79e30263a31766
Author: Levin, Alexander (Sasha Levin) <alexander.levin@verizon.com>
Date:   Wed Nov 15 17:35:54 2017 -0800

    kmemcheck: stop using GFP_NOTRACK and SLAB_NOTRACK
    
    Convert all allocations that used a NOTRACK flag to stop using it.
    
    Link: http://lkml.kernel.org/r/20171007030159.22241-3-alexander.levin@verizon.com
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Pekka Enberg <penberg@kernel.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Tim Hansen <devtimhansen@gmail.com>
    Cc: Vegard Nossum <vegardno@ifi.uio.no>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index e1d751ae2498..1a2526676a87 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -1172,11 +1172,11 @@ static int __init dwarf_unwinder_init(void)
 
 	dwarf_frame_cachep = kmem_cache_create("dwarf_frames",
 			sizeof(struct dwarf_frame), 0,
-			SLAB_PANIC | SLAB_HWCACHE_ALIGN | SLAB_NOTRACK, NULL);
+			SLAB_PANIC | SLAB_HWCACHE_ALIGN, NULL);
 
 	dwarf_reg_cachep = kmem_cache_create("dwarf_regs",
 			sizeof(struct dwarf_reg), 0,
-			SLAB_PANIC | SLAB_HWCACHE_ALIGN | SLAB_NOTRACK, NULL);
+			SLAB_PANIC | SLAB_HWCACHE_ALIGN, NULL);
 
 	dwarf_frame_pool = mempool_create_slab_pool(DWARF_FRAME_MIN_REQ,
 						    dwarf_frame_cachep);

commit a316399635e334c878a88c90044c1e45f57129a4
Author: Markus Elfring <elfring@users.sourceforge.net>
Date:   Mon Nov 16 08:20:36 2015 +0100

    sh: Delete unnecessary checks before the function call "mempool_destroy"
    
    The mempool_destroy() function tests whether its argument is NULL
    and then returns immediately. Thus the test around the calls is not needed.
    
    This issue was detected by using the Coccinelle software.
    
    Signed-off-by: Markus Elfring <elfring@users.sourceforge.net>
    Signed-off-by: Rich Felker <dalias@libc.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 9d209a07235e..e1d751ae2498 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -1009,10 +1009,8 @@ static void __init dwarf_unwinder_cleanup(void)
 	rbtree_postorder_for_each_entry_safe(cie, next_cie, &cie_root, node)
 		kfree(cie);
 
-	if (dwarf_reg_pool)
-		mempool_destroy(dwarf_reg_pool);
-	if (dwarf_frame_pool)
-		mempool_destroy(dwarf_frame_pool);
+	mempool_destroy(dwarf_reg_pool);
+	mempool_destroy(dwarf_frame_pool);
 	kmem_cache_destroy(dwarf_reg_cachep);
 	kmem_cache_destroy(dwarf_frame_cachep);
 }

commit 1cf370c61179e01313457363b21f0859be0d8cb7
Author: David Rientjes <rientjes@google.com>
Date:   Tue Apr 14 15:42:40 2015 -0700

    arch/sh/kernel/dwarf.c: use mempool_create_slab_pool()
    
    Mempools created for slab caches should use mempool_create_slab_pool().
    
    Signed-off-by: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 60437e9c345e..9d209a07235e 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -1180,17 +1180,13 @@ static int __init dwarf_unwinder_init(void)
 			sizeof(struct dwarf_reg), 0,
 			SLAB_PANIC | SLAB_HWCACHE_ALIGN | SLAB_NOTRACK, NULL);
 
-	dwarf_frame_pool = mempool_create(DWARF_FRAME_MIN_REQ,
-					  mempool_alloc_slab,
-					  mempool_free_slab,
-					  dwarf_frame_cachep);
+	dwarf_frame_pool = mempool_create_slab_pool(DWARF_FRAME_MIN_REQ,
+						    dwarf_frame_cachep);
 	if (!dwarf_frame_pool)
 		goto out;
 
-	dwarf_reg_pool = mempool_create(DWARF_REG_MIN_REQ,
-					 mempool_alloc_slab,
-					 mempool_free_slab,
-					 dwarf_reg_cachep);
+	dwarf_reg_pool = mempool_create_slab_pool(DWARF_REG_MIN_REQ,
+						  dwarf_reg_cachep);
 	if (!dwarf_reg_pool)
 		goto out;
 

commit 7b4b425897cd582897ccc38b637ce7ab5ffc5593
Author: David Rientjes <rientjes@google.com>
Date:   Tue Apr 14 15:42:37 2015 -0700

    arch/sh/kernel/dwarf.c: destroy mempools on cleanup
    
    dwarf_reg_pool and dwarf_frame_pool are not properly destroyed when
    cleaning up the dwarf unwinder.  Destroy them with mempool_destroy().
    
    Also mark dwarf_unwinder_cleanup() as __init.
    
    Signed-off-by: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 67a049e75ec1..60437e9c345e 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -993,7 +993,7 @@ static struct unwinder dwarf_unwinder = {
 	.rating = 150,
 };
 
-static void dwarf_unwinder_cleanup(void)
+static void __init dwarf_unwinder_cleanup(void)
 {
 	struct dwarf_fde *fde, *next_fde;
 	struct dwarf_cie *cie, *next_cie;
@@ -1009,6 +1009,10 @@ static void dwarf_unwinder_cleanup(void)
 	rbtree_postorder_for_each_entry_safe(cie, next_cie, &cie_root, node)
 		kfree(cie);
 
+	if (dwarf_reg_pool)
+		mempool_destroy(dwarf_reg_pool);
+	if (dwarf_frame_pool)
+		mempool_destroy(dwarf_frame_pool);
 	kmem_cache_destroy(dwarf_reg_cachep);
 	kmem_cache_destroy(dwarf_frame_cachep);
 }

commit e376ed7c85fe102ff63db2eb8a0c5595f68151fa
Author: Cody P Schafer <cody@linux.vnet.ibm.com>
Date:   Thu Jan 23 15:56:14 2014 -0800

    arch/sh/kernel/dwarf.c: use rbtree postorder iteration helper instead of solution using repeated rb_erase()
    
    Use rbtree_postorder_for_each_entry_safe() to destroy the rbtree instead
    of using repeated rb_erase() calls
    
    Signed-off-by: Cody P Schafer <cody@linux.vnet.ibm.com>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 49c09c7d5b77..67a049e75ec1 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -995,29 +995,19 @@ static struct unwinder dwarf_unwinder = {
 
 static void dwarf_unwinder_cleanup(void)
 {
-	struct rb_node **fde_rb_node = &fde_root.rb_node;
-	struct rb_node **cie_rb_node = &cie_root.rb_node;
+	struct dwarf_fde *fde, *next_fde;
+	struct dwarf_cie *cie, *next_cie;
 
 	/*
 	 * Deallocate all the memory allocated for the DWARF unwinder.
 	 * Traverse all the FDE/CIE lists and remove and free all the
 	 * memory associated with those data structures.
 	 */
-	while (*fde_rb_node) {
-		struct dwarf_fde *fde;
-
-		fde = rb_entry(*fde_rb_node, struct dwarf_fde, node);
-		rb_erase(*fde_rb_node, &fde_root);
+	rbtree_postorder_for_each_entry_safe(fde, next_fde, &fde_root, node)
 		kfree(fde);
-	}
 
-	while (*cie_rb_node) {
-		struct dwarf_cie *cie;
-
-		cie = rb_entry(*cie_rb_node, struct dwarf_cie, node);
-		rb_erase(*cie_rb_node, &cie_root);
+	rbtree_postorder_for_each_entry_safe(cie, next_cie, &cie_root, node)
 		kfree(cie);
-	}
 
 	kmem_cache_destroy(dwarf_reg_cachep);
 	kmem_cache_destroy(dwarf_frame_cachep);

commit 8a37f520523df971bd3f926d8bd45ead37e857e8
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue May 25 16:16:40 2010 +0900

    sh: handle early calls to return_address() when using dwarf unwinder.
    
    The dwarf unwinder ties in to an early initcall, but it's possible that
    return_address() calls will be made prior to that. This implements some
    additional error handling in to the dwarf unwinder as well as an exit
    path in the return_address() case to bail out if the unwinder hasn't come
    up yet.
    
    This fixes a NULL pointer deref in early boot when mempool_alloc() blows
    up on the not-yet-ready mempool via dwarf_unwind_stack().
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 886d7d83ace3..49c09c7d5b77 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -49,6 +49,8 @@ static DEFINE_SPINLOCK(dwarf_fde_lock);
 
 static struct dwarf_cie *cached_cie;
 
+static unsigned int dwarf_unwinder_ready;
+
 /**
  *	dwarf_frame_alloc_reg - allocate memory for a DWARF register
  *	@frame: the DWARF frame whose list of registers we insert on
@@ -581,6 +583,13 @@ struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
 	struct dwarf_reg *reg;
 	unsigned long addr;
 
+	/*
+	 * If we've been called in to before initialization has
+	 * completed, bail out immediately.
+	 */
+	if (!dwarf_unwinder_ready)
+		return NULL;
+
 	/*
 	 * If we're starting at the top of the stack we need get the
 	 * contents of a physical register to get the CFA in order to
@@ -1167,7 +1176,7 @@ void module_dwarf_cleanup(struct module *mod)
  */
 static int __init dwarf_unwinder_init(void)
 {
-	int err;
+	int err = -ENOMEM;
 
 	dwarf_frame_cachep = kmem_cache_create("dwarf_frames",
 			sizeof(struct dwarf_frame), 0,
@@ -1181,11 +1190,15 @@ static int __init dwarf_unwinder_init(void)
 					  mempool_alloc_slab,
 					  mempool_free_slab,
 					  dwarf_frame_cachep);
+	if (!dwarf_frame_pool)
+		goto out;
 
 	dwarf_reg_pool = mempool_create(DWARF_REG_MIN_REQ,
 					 mempool_alloc_slab,
 					 mempool_free_slab,
 					 dwarf_reg_cachep);
+	if (!dwarf_reg_pool)
+		goto out;
 
 	err = dwarf_parse_section(__start_eh_frame, __stop_eh_frame, NULL);
 	if (err)
@@ -1195,11 +1208,13 @@ static int __init dwarf_unwinder_init(void)
 	if (err)
 		goto out;
 
+	dwarf_unwinder_ready = 1;
+
 	return 0;
 
 out:
 	printk(KERN_ERR "Failed to initialise DWARF unwinder: %d\n", err);
 	dwarf_unwinder_cleanup();
-	return -EINVAL;
+	return err;
 }
 early_initcall(dwarf_unwinder_init);

commit d8252d6272682096835b4e1ef714cb1b593aa7fb
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Thu May 20 20:46:27 2010 +0900

    sh: fix up the dwarf unwinder build for MODULES=n.
    
    Presently the dwarf unwinder build blows up if modules are disabled,
    fix it up.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 5ec1d1818691..886d7d83ace3 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -845,8 +845,10 @@ static int dwarf_parse_cie(void *entry, void *p, unsigned long len,
 	rb_link_node(&cie->node, parent, rb_node);
 	rb_insert_color(&cie->node, &cie_root);
 
+#ifdef CONFIG_MODULES
 	if (mod != NULL)
 		list_add_tail(&cie->link, &mod->arch.cie_list);
+#endif
 
 	spin_unlock_irqrestore(&dwarf_cie_lock, flags);
 
@@ -935,8 +937,10 @@ static int dwarf_parse_fde(void *entry, u32 entry_type,
 	rb_link_node(&fde->node, parent, rb_node);
 	rb_insert_color(&fde->node, &fde_root);
 
+#ifdef CONFIG_MODULES
 	if (mod != NULL)
 		list_add_tail(&fde->link, &mod->arch.fde_list);
+#endif
 
 	spin_unlock_irqrestore(&dwarf_fde_lock, flags);
 

commit e19553427c2e8fdb04fdd98e407164bb59a840ba
Merge: 35f6cd4a0643 83515bc7df81
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Apr 26 16:08:27 2010 +0900

    Merge branch 'sh/stable-updates'
    
    Conflicts:
            arch/sh/kernel/dwarf.c
            drivers/dma/shdma.c
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

commit 1d5cc550ede76825ab401941fb1165f2056e2c46
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Apr 20 14:34:15 2010 +0900

    sh: dwarf unwinder needs linux/module.h.
    
    Previously the struct module definition was pulled in from other headers,
    but we want the reference to be explicit. Fixes up randconfig build
    issues.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 94739ee7aa74..8c09f62cebd1 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -22,6 +22,7 @@
 #include <linux/mm.h>
 #include <linux/elf.h>
 #include <linux/ftrace.h>
+#include <linux/module.h>
 #include <asm/dwarf.h>
 #include <asm/unwinder.h>
 #include <asm/sections.h>

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 94739ee7aa74..a8234b2010d1 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -22,6 +22,7 @@
 #include <linux/mm.h>
 #include <linux/elf.h>
 #include <linux/ftrace.h>
+#include <linux/slab.h>
 #include <asm/dwarf.h>
 #include <asm/unwinder.h>
 #include <asm/sections.h>

commit 4e1a2594094020bdb41c18681c1765671138d06a
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Mar 23 17:07:41 2010 +0900

    sh: Silence unintialized variable warnings in dwarf unwinder.
    
    The parent rb_node needs to be initialized to shut up the compiler, even
    though we're unlikely to ever hit this issue at run time.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index bd1c497280a6..94739ee7aa74 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -727,7 +727,7 @@ static int dwarf_parse_cie(void *entry, void *p, unsigned long len,
 			   unsigned char *end, struct module *mod)
 {
 	struct rb_node **rb_node = &cie_root.rb_node;
-	struct rb_node *parent;
+	struct rb_node *parent = *rb_node;
 	struct dwarf_cie *cie;
 	unsigned long flags;
 	int count;
@@ -856,7 +856,7 @@ static int dwarf_parse_fde(void *entry, u32 entry_type,
 			   unsigned char *end, struct module *mod)
 {
 	struct rb_node **rb_node = &fde_root.rb_node;
-	struct rb_node *parent;
+	struct rb_node *parent = *rb_node;
 	struct dwarf_fde *fde;
 	struct dwarf_cie *cie;
 	unsigned long flags;

commit 858918b77b29d0e9ce7f524d1b57d602d85f5d64
Author: Matt Fleming <matt@console-pimps.org>
Date:   Sun Feb 7 12:40:36 2010 +0000

    sh: Optimise FDE/CIE lookup by using red-black trees
    
    Now that the DWARF unwinder is being used to provide perf callstacks
    unwinding speed is an issue. It is no longer being used in exceptional
    circumstances where we don't care about runtime performance, e.g. when
    panicing, so it makes sense improve performance is possible.
    
    With this patch I saw a 42% improvement in unwind time when calling
    return_address(1). Greater improvements will be seen as the number of
    levels unwound increases as each unwind is now cheaper.
    
    Note that insertion time has doubled but that's just the price we pay
    for keeping the trees balanced. However, this is a one-time cost for
    kernel boot/module load and so the improvements in lookup time dominate
    the extra time we spend keeping the trees balanced.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index e51168064e56..bd1c497280a6 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -39,10 +39,10 @@ static mempool_t *dwarf_frame_pool;
 static struct kmem_cache *dwarf_reg_cachep;
 static mempool_t *dwarf_reg_pool;
 
-static LIST_HEAD(dwarf_cie_list);
+static struct rb_root cie_root;
 static DEFINE_SPINLOCK(dwarf_cie_lock);
 
-static LIST_HEAD(dwarf_fde_list);
+static struct rb_root fde_root;
 static DEFINE_SPINLOCK(dwarf_fde_lock);
 
 static struct dwarf_cie *cached_cie;
@@ -301,7 +301,8 @@ static inline int dwarf_entry_len(char *addr, unsigned long *len)
  */
 static struct dwarf_cie *dwarf_lookup_cie(unsigned long cie_ptr)
 {
-	struct dwarf_cie *cie;
+	struct rb_node **rb_node = &cie_root.rb_node;
+	struct dwarf_cie *cie = NULL;
 	unsigned long flags;
 
 	spin_lock_irqsave(&dwarf_cie_lock, flags);
@@ -315,16 +316,24 @@ static struct dwarf_cie *dwarf_lookup_cie(unsigned long cie_ptr)
 		goto out;
 	}
 
-	list_for_each_entry(cie, &dwarf_cie_list, link) {
-		if (cie->cie_pointer == cie_ptr) {
-			cached_cie = cie;
-			break;
+	while (*rb_node) {
+		struct dwarf_cie *cie_tmp;
+
+		cie_tmp = rb_entry(*rb_node, struct dwarf_cie, node);
+		BUG_ON(!cie_tmp);
+
+		if (cie_ptr == cie_tmp->cie_pointer) {
+			cie = cie_tmp;
+			cached_cie = cie_tmp;
+			goto out;
+		} else {
+			if (cie_ptr < cie_tmp->cie_pointer)
+				rb_node = &(*rb_node)->rb_left;
+			else
+				rb_node = &(*rb_node)->rb_right;
 		}
 	}
 
-	/* Couldn't find the entry in the list. */
-	if (&cie->link == &dwarf_cie_list)
-		cie = NULL;
 out:
 	spin_unlock_irqrestore(&dwarf_cie_lock, flags);
 	return cie;
@@ -336,25 +345,34 @@ static struct dwarf_cie *dwarf_lookup_cie(unsigned long cie_ptr)
  */
 struct dwarf_fde *dwarf_lookup_fde(unsigned long pc)
 {
-	struct dwarf_fde *fde;
+	struct rb_node **rb_node = &fde_root.rb_node;
+	struct dwarf_fde *fde = NULL;
 	unsigned long flags;
 
 	spin_lock_irqsave(&dwarf_fde_lock, flags);
 
-	list_for_each_entry(fde, &dwarf_fde_list, link) {
-		unsigned long start, end;
+	while (*rb_node) {
+		struct dwarf_fde *fde_tmp;
+		unsigned long tmp_start, tmp_end;
 
-		start = fde->initial_location;
-		end = fde->initial_location + fde->address_range;
+		fde_tmp = rb_entry(*rb_node, struct dwarf_fde, node);
+		BUG_ON(!fde_tmp);
 
-		if (pc >= start && pc < end)
-			break;
-	}
+		tmp_start = fde_tmp->initial_location;
+		tmp_end = fde_tmp->initial_location + fde_tmp->address_range;
 
-	/* Couldn't find the entry in the list. */
-	if (&fde->link == &dwarf_fde_list)
-		fde = NULL;
+		if (pc < tmp_start) {
+			rb_node = &(*rb_node)->rb_left;
+		} else {
+			if (pc < tmp_end) {
+				fde = fde_tmp;
+				goto out;
+			} else
+				rb_node = &(*rb_node)->rb_right;
+		}
+	}
 
+out:
 	spin_unlock_irqrestore(&dwarf_fde_lock, flags);
 
 	return fde;
@@ -552,8 +570,8 @@ extern void ret_from_irq(void);
  *	on the callstack. Each of the lower (older) stack frames are
  *	linked via the "prev" member.
  */
-struct dwarf_frame * dwarf_unwind_stack(unsigned long pc,
-					struct dwarf_frame *prev)
+struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
+				       struct dwarf_frame *prev)
 {
 	struct dwarf_frame *frame;
 	struct dwarf_cie *cie;
@@ -708,6 +726,8 @@ struct dwarf_frame * dwarf_unwind_stack(unsigned long pc,
 static int dwarf_parse_cie(void *entry, void *p, unsigned long len,
 			   unsigned char *end, struct module *mod)
 {
+	struct rb_node **rb_node = &cie_root.rb_node;
+	struct rb_node *parent;
 	struct dwarf_cie *cie;
 	unsigned long flags;
 	int count;
@@ -802,11 +822,30 @@ static int dwarf_parse_cie(void *entry, void *p, unsigned long len,
 	cie->initial_instructions = p;
 	cie->instructions_end = end;
 
-	cie->mod = mod;
-
 	/* Add to list */
 	spin_lock_irqsave(&dwarf_cie_lock, flags);
-	list_add_tail(&cie->link, &dwarf_cie_list);
+
+	while (*rb_node) {
+		struct dwarf_cie *cie_tmp;
+
+		cie_tmp = rb_entry(*rb_node, struct dwarf_cie, node);
+
+		parent = *rb_node;
+
+		if (cie->cie_pointer < cie_tmp->cie_pointer)
+			rb_node = &parent->rb_left;
+		else if (cie->cie_pointer >= cie_tmp->cie_pointer)
+			rb_node = &parent->rb_right;
+		else
+			WARN_ON(1);
+	}
+
+	rb_link_node(&cie->node, parent, rb_node);
+	rb_insert_color(&cie->node, &cie_root);
+
+	if (mod != NULL)
+		list_add_tail(&cie->link, &mod->arch.cie_list);
+
 	spin_unlock_irqrestore(&dwarf_cie_lock, flags);
 
 	return 0;
@@ -816,6 +855,8 @@ static int dwarf_parse_fde(void *entry, u32 entry_type,
 			   void *start, unsigned long len,
 			   unsigned char *end, struct module *mod)
 {
+	struct rb_node **rb_node = &fde_root.rb_node;
+	struct rb_node *parent;
 	struct dwarf_fde *fde;
 	struct dwarf_cie *cie;
 	unsigned long flags;
@@ -863,11 +904,38 @@ static int dwarf_parse_fde(void *entry, u32 entry_type,
 	fde->instructions = p;
 	fde->end = end;
 
-	fde->mod = mod;
-
 	/* Add to list. */
 	spin_lock_irqsave(&dwarf_fde_lock, flags);
-	list_add_tail(&fde->link, &dwarf_fde_list);
+
+	while (*rb_node) {
+		struct dwarf_fde *fde_tmp;
+		unsigned long tmp_start, tmp_end;
+		unsigned long start, end;
+
+		fde_tmp = rb_entry(*rb_node, struct dwarf_fde, node);
+
+		start = fde->initial_location;
+		end = fde->initial_location + fde->address_range;
+
+		tmp_start = fde_tmp->initial_location;
+		tmp_end = fde_tmp->initial_location + fde_tmp->address_range;
+
+		parent = *rb_node;
+
+		if (start < tmp_start)
+			rb_node = &parent->rb_left;
+		else if (start >= tmp_end)
+			rb_node = &parent->rb_right;
+		else
+			WARN_ON(1);
+	}
+
+	rb_link_node(&fde->node, parent, rb_node);
+	rb_insert_color(&fde->node, &fde_root);
+
+	if (mod != NULL)
+		list_add_tail(&fde->link, &mod->arch.fde_list);
+
 	spin_unlock_irqrestore(&dwarf_fde_lock, flags);
 
 	return 0;
@@ -912,19 +980,29 @@ static struct unwinder dwarf_unwinder = {
 
 static void dwarf_unwinder_cleanup(void)
 {
-	struct dwarf_cie *cie, *cie_tmp;
-	struct dwarf_fde *fde, *fde_tmp;
+	struct rb_node **fde_rb_node = &fde_root.rb_node;
+	struct rb_node **cie_rb_node = &cie_root.rb_node;
 
 	/*
 	 * Deallocate all the memory allocated for the DWARF unwinder.
 	 * Traverse all the FDE/CIE lists and remove and free all the
 	 * memory associated with those data structures.
 	 */
-	list_for_each_entry_safe(cie, cie_tmp, &dwarf_cie_list, link)
-		kfree(cie);
+	while (*fde_rb_node) {
+		struct dwarf_fde *fde;
 
-	list_for_each_entry_safe(fde, fde_tmp, &dwarf_fde_list, link)
+		fde = rb_entry(*fde_rb_node, struct dwarf_fde, node);
+		rb_erase(*fde_rb_node, &fde_root);
 		kfree(fde);
+	}
+
+	while (*cie_rb_node) {
+		struct dwarf_cie *cie;
+
+		cie = rb_entry(*cie_rb_node, struct dwarf_cie, node);
+		rb_erase(*cie_rb_node, &cie_root);
+		kfree(cie);
+	}
 
 	kmem_cache_destroy(dwarf_reg_cachep);
 	kmem_cache_destroy(dwarf_frame_cachep);
@@ -1024,6 +1102,8 @@ int module_dwarf_finalize(const Elf_Ehdr *hdr, const Elf_Shdr *sechdrs,
 
 	/* Did we find the .eh_frame section? */
 	if (i != hdr->e_shnum) {
+		INIT_LIST_HEAD(&me->arch.cie_list);
+		INIT_LIST_HEAD(&me->arch.fde_list);
 		err = dwarf_parse_section((char *)start, (char *)end, me);
 		if (err) {
 			printk(KERN_WARNING "%s: failed to parse DWARF info\n",
@@ -1044,38 +1124,26 @@ int module_dwarf_finalize(const Elf_Ehdr *hdr, const Elf_Shdr *sechdrs,
  */
 void module_dwarf_cleanup(struct module *mod)
 {
-	struct dwarf_fde *fde;
-	struct dwarf_cie *cie;
+	struct dwarf_fde *fde, *ftmp;
+	struct dwarf_cie *cie, *ctmp;
 	unsigned long flags;
 
 	spin_lock_irqsave(&dwarf_cie_lock, flags);
 
-again_cie:
-	list_for_each_entry(cie, &dwarf_cie_list, link) {
-		if (cie->mod == mod)
-			break;
-	}
-
-	if (&cie->link != &dwarf_cie_list) {
+	list_for_each_entry_safe(cie, ctmp, &mod->arch.cie_list, link) {
 		list_del(&cie->link);
+		rb_erase(&cie->node, &cie_root);
 		kfree(cie);
-		goto again_cie;
 	}
 
 	spin_unlock_irqrestore(&dwarf_cie_lock, flags);
 
 	spin_lock_irqsave(&dwarf_fde_lock, flags);
 
-again_fde:
-	list_for_each_entry(fde, &dwarf_fde_list, link) {
-		if (fde->mod == mod)
-			break;
-	}
-
-	if (&fde->link != &dwarf_fde_list) {
+	list_for_each_entry_safe(fde, ftmp, &mod->arch.fde_list, link) {
 		list_del(&fde->link);
+		rb_erase(&fde->node, &fde_root);
 		kfree(fde);
-		goto again_fde;
 	}
 
 	spin_unlock_irqrestore(&dwarf_fde_lock, flags);
@@ -1094,8 +1162,6 @@ void module_dwarf_cleanup(struct module *mod)
 static int __init dwarf_unwinder_init(void)
 {
 	int err;
-	INIT_LIST_HEAD(&dwarf_cie_list);
-	INIT_LIST_HEAD(&dwarf_fde_list);
 
 	dwarf_frame_cachep = kmem_cache_create("dwarf_frames",
 			sizeof(struct dwarf_frame), 0,

commit 944a3438615da65f11e2559840404a2cac5f65ea
Author: Matt Fleming <matt@console-pimps.org>
Date:   Sat Jan 30 17:36:20 2010 +0000

    sh: Don't continue unwinding across interrupts
    
    Unfortunately, due to poor DWARF info in current toolchains, unwinding
    through interrutps cannot be done reliably. The problem is that the
    DWARF info for function epilogues is wrong.
    
    Take this standard epilogue sequence,
    
    80003cc4:       e3 6f           mov     r14,r15
    80003cc6:       26 4f           lds.l   @r15+,pr
    80003cc8:       f6 6e           mov.l   @r15+,r14
                                                    <---- interrupt here
    80003cca:       f6 6b           mov.l   @r15+,r11
    80003ccc:       f6 6a           mov.l   @r15+,r10
    80003cce:       f6 69           mov.l   @r15+,r9
    80003cd0:       0b 00           rts
    
    If we take an interrupt at the highlighted point, the DWARF info will
    bogusly claim that the return address can be found at some offset from
    the frame pointer, even though the frame pointer was just restored. The
    worst part is if the unwinder finds a text address at the bogus stack
    address - unwinding will continue, for a bit, until it finally comes
    across an unexpected address on the stack and blows up.
    
    The only solution is to stop unwinding once we've calculated the
    function that was executing when the interrupt occurred. This PC can be
    easily calculated from pt_regs->pc.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 88d28ec3780a..e51168064e56 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -540,6 +540,8 @@ void dwarf_free_frame(struct dwarf_frame *frame)
 	mempool_free(frame, dwarf_frame_pool);
 }
 
+extern void ret_from_irq(void);
+
 /**
  *	dwarf_unwind_stack - unwind the stack
  *
@@ -678,6 +680,24 @@ struct dwarf_frame * dwarf_unwind_stack(unsigned long pc,
 	addr = frame->cfa + reg->addr;
 	frame->return_addr = __raw_readl(addr);
 
+	/*
+	 * Ah, the joys of unwinding through interrupts.
+	 *
+	 * Interrupts are tricky - the DWARF info needs to be _really_
+	 * accurate and unfortunately I'm seeing a lot of bogus DWARF
+	 * info. For example, I've seen interrupts occur in epilogues
+	 * just after the frame pointer (r14) had been restored. The
+	 * problem was that the DWARF info claimed that the CFA could be
+	 * reached by using the value of the frame pointer before it was
+	 * restored.
+	 *
+	 * So until the compiler can be trusted to produce reliable
+	 * DWARF info when it really matters, let's stop unwinding once
+	 * we've calculated the function that was interrupted.
+	 */
+	if (prev && prev->pc == (unsigned long)ret_from_irq)
+		frame->return_addr = 0;
+
 	return frame;
 
 bail:

commit 00b3e0a2e059f0601feb537b995b0b4de531b543
Author: Marek Skuczynski <mareksk7@gmail.com>
Date:   Sat Jan 30 22:27:41 2010 +0100

    sh: Fix access to released memory in dwarf_unwinder_cleanup()
    
    Signed-off-by: Marek Skuczynski <mareksk7@gmail.com>
    Acked-by: Matt Fleming <matt@console-pimps.org>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 3576b709f052..88d28ec3780a 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -892,18 +892,18 @@ static struct unwinder dwarf_unwinder = {
 
 static void dwarf_unwinder_cleanup(void)
 {
-	struct dwarf_cie *cie;
-	struct dwarf_fde *fde;
+	struct dwarf_cie *cie, *cie_tmp;
+	struct dwarf_fde *fde, *fde_tmp;
 
 	/*
 	 * Deallocate all the memory allocated for the DWARF unwinder.
 	 * Traverse all the FDE/CIE lists and remove and free all the
 	 * memory associated with those data structures.
 	 */
-	list_for_each_entry(cie, &dwarf_cie_list, link)
+	list_for_each_entry_safe(cie, cie_tmp, &dwarf_cie_list, link)
 		kfree(cie);
 
-	list_for_each_entry(fde, &dwarf_fde_list, link)
+	list_for_each_entry_safe(fde, fde_tmp, &dwarf_fde_list, link)
 		kfree(fde);
 
 	kmem_cache_destroy(dwarf_reg_cachep);

commit 76d2318020bf0c0c497af986a25977196715a1b9
Merge: e9c4148fd4f0 969e46a8533a
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Nov 9 10:55:36 2009 +0900

    Merge branch 'sh/stable-updates'

commit 421b541110b20ccff1a7ff3245439cb24efe9812
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Fri Nov 6 17:23:33 2009 +0900

    sh: unwinder: Fix up invalid PC refetch in dwarf unwinder.
    
    The dwarf unwinder presently attempts to provide a sane PC value if none
    is provided, however the logic is broken and cases where a previous valid
    dwarf frame exists along with a bogus PC value can still proceed. This
    fixes up the test and prevents the unwinder from blowing up.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 2d07084e4882..d76a23170dbb 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -555,7 +555,7 @@ struct dwarf_frame * dwarf_unwind_stack(unsigned long pc,
 	 * NOTE: the return address is guaranteed to be setup by the
 	 * time this function makes its first function call.
 	 */
-	if (!pc && !prev)
+	if (!pc || !prev)
 		pc = (unsigned long)current_text_addr();
 
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER

commit 6253195b671b98a4e5da5d39c2df9f8f257bcea1
Merge: 15893fb56592 60339fad5c68
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Oct 26 10:48:18 2009 +0900

    Merge branch 'sh/stable-updates'
    
    Conflicts:
            arch/sh/kernel/dwarf.c

commit 60339fad5c68c9c533cd14e67194ff8f727c41d9
Author: Matt Fleming <matt@console-pimps.org>
Date:   Sat Oct 24 18:56:57 2009 +0000

    sh: Check for return_to_handler when unwinding the stack
    
    When CONFIG_FUNCTION_GRAPH_TRACER is enabled the function graph tracer
    may patch return addresses on the stack with the address of
    return_to_handler(). This really confuses the DWARF unwinder because it
    will try find the caller of return_to_handler(), not the caller of the
    real return address.
    
    So teach the DWARF unwinder how to find the real return address whenever
    it encounters return_to_handler().
    
    This patch does not cope very well when multiple return addresses on the
    stack have been patched. To make it work properly it would require state
    to track how many return_to_handler()'s have been seen so that we'd know
    where to look in current->curr_ret_stack[]. So for now, instead of
    trying to handle this, just moan if more than one return address on the
    stack has been patched.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 03b3616c80a5..2d07084e4882 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -20,6 +20,7 @@
 #include <linux/list.h>
 #include <linux/mempool.h>
 #include <linux/mm.h>
+#include <linux/ftrace.h>
 #include <asm/dwarf.h>
 #include <asm/unwinder.h>
 #include <asm/sections.h>
@@ -557,6 +558,27 @@ struct dwarf_frame * dwarf_unwind_stack(unsigned long pc,
 	if (!pc && !prev)
 		pc = (unsigned long)current_text_addr();
 
+#ifdef CONFIG_FUNCTION_GRAPH_TRACER
+	/*
+	 * If our stack has been patched by the function graph tracer
+	 * then we might see the address of return_to_handler() where we
+	 * expected to find the real return address.
+	 */
+	if (pc == (unsigned long)&return_to_handler) {
+		int index = current->curr_ret_stack;
+
+		/*
+		 * We currently have no way of tracking how many
+		 * return_to_handler()'s we've seen. If there is more
+		 * than one patched return address on our stack,
+		 * complain loudly.
+		 */
+		WARN_ON(index > 0);
+
+		pc = current->ret_stack[index].ret;
+	}
+#endif
+
 	frame = mempool_alloc(dwarf_frame_pool, GFP_ATOMIC);
 	if (!frame) {
 		printk(KERN_ERR "Unable to allocate a dwarf frame\n");

commit eca28e3764e301fad662743d1e8ba7296cc6a109
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Oct 19 15:51:21 2009 +0900

    sh: Fix up uninitialized variable warning in dwarf unwinder.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 718286be6648..4d8c7bd149df 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -902,7 +902,7 @@ static int dwarf_parse_section(char *eh_frame_start, char *eh_frame_end,
 	u32 entry_type;
 	void *p, *entry;
 	int count, err = 0;
-	unsigned long len;
+	unsigned long len = 0;
 	unsigned int c_entries, f_entries;
 	unsigned char *end;
 

commit 5a3abba77dc0eb0b00332c21899123cdfa3b19e5
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Oct 13 13:32:19 2009 +0900

    sh: Tidy up the dwarf module helpers.
    
    This enables us to build the dwarf unwinder both with modules enabled and
    disabled in addition to reducing code size in the latter case. The
    helpers are also consolidated, and modified to resemble the BUG module
    helpers.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index c274039e9c8d..718286be6648 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -20,6 +20,7 @@
 #include <linux/list.h>
 #include <linux/mempool.h>
 #include <linux/mm.h>
+#include <linux/elf.h>
 #include <asm/dwarf.h>
 #include <asm/unwinder.h>
 #include <asm/sections.h>
@@ -895,8 +896,8 @@ static void dwarf_unwinder_cleanup(void)
  *
  *	Parse the information in a .eh_frame section.
  */
-int dwarf_parse_section(char *eh_frame_start, char *eh_frame_end,
-			struct module *mod)
+static int dwarf_parse_section(char *eh_frame_start, char *eh_frame_end,
+			       struct module *mod)
 {
 	u32 entry_type;
 	void *p, *entry;
@@ -959,14 +960,47 @@ int dwarf_parse_section(char *eh_frame_start, char *eh_frame_end,
 	return err;
 }
 
+#ifdef CONFIG_MODULES
+int module_dwarf_finalize(const Elf_Ehdr *hdr, const Elf_Shdr *sechdrs,
+			  struct module *me)
+{
+	unsigned int i, err;
+	unsigned long start, end;
+	char *secstrings = (void *)hdr + sechdrs[hdr->e_shstrndx].sh_offset;
+
+	start = end = 0;
+
+	for (i = 1; i < hdr->e_shnum; i++) {
+		/* Alloc bit cleared means "ignore it." */
+		if ((sechdrs[i].sh_flags & SHF_ALLOC)
+		    && !strcmp(secstrings+sechdrs[i].sh_name, ".eh_frame")) {
+			start = sechdrs[i].sh_addr;
+			end = start + sechdrs[i].sh_size;
+			break;
+		}
+	}
+
+	/* Did we find the .eh_frame section? */
+	if (i != hdr->e_shnum) {
+		err = dwarf_parse_section((char *)start, (char *)end, me);
+		if (err) {
+			printk(KERN_WARNING "%s: failed to parse DWARF info\n",
+			       me->name);
+			return err;
+		}
+	}
+
+	return 0;
+}
+
 /**
- *	dwarf_module_unload - remove FDE/CIEs associated with @mod
+ *	module_dwarf_cleanup - remove FDE/CIEs associated with @mod
  *	@mod: the module that is being unloaded
  *
  *	Remove any FDEs and CIEs from the global lists that came from
  *	@mod's .eh_frame section because @mod is being unloaded.
  */
-void dwarf_module_unload(struct module *mod)
+void module_dwarf_cleanup(struct module *mod)
 {
 	struct dwarf_fde *fde;
 	struct dwarf_cie *cie;
@@ -1004,6 +1038,7 @@ void dwarf_module_unload(struct module *mod)
 
 	spin_unlock_irqrestore(&dwarf_fde_lock, flags);
 }
+#endif /* CONFIG_MODULES */
 
 /**
  *	dwarf_unwinder_init - initialise the dwarf unwinder

commit 8ec006c58775869175edee3d23f4525b6df2935a
Merge: 3d4e0cfb3372 5ab78ff693d0
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Oct 12 08:50:07 2009 +0900

    Merge branch 'sh/dwarf-unwinder'
    
    Conflicts:
            arch/sh/kernel/dwarf.c

commit c2d474d6f8b48b6698343cfc1a3630c4647aa7b2
Author: Matt Fleming <matt@console-pimps.org>
Date:   Sat Oct 10 16:17:06 2009 +0100

    sh: Remove any reference to recursive functions from comments
    
    Originally, dwarf_unwind_stack() was a recursive function and it seems
    that some of the old comments were never updated.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index ce8bff45d72c..f242cd120cf1 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -540,7 +540,8 @@ void dwarf_free_frame(struct dwarf_frame *frame)
 }
 
 /**
- *	dwarf_unwind_stack - recursively unwind the stack
+ *	dwarf_unwind_stack - unwind the stack
+ *
  *	@pc: address of the function to unwind
  *	@prev: struct dwarf_frame of the previous stackframe on the callstack
  *
@@ -558,9 +559,9 @@ struct dwarf_frame * dwarf_unwind_stack(unsigned long pc,
 	unsigned long addr;
 
 	/*
-	 * If this is the first invocation of this recursive function we
-	 * need get the contents of a physical register to get the CFA
-	 * in order to begin the virtual unwinding of the stack.
+	 * If we're starting at the top of the stack we need get the
+	 * contents of a physical register to get the CFA in order to
+	 * begin the virtual unwinding of the stack.
 	 *
 	 * NOTE: the return address is guaranteed to be setup by the
 	 * time this function makes its first function call.
@@ -582,9 +583,8 @@ struct dwarf_frame * dwarf_unwind_stack(unsigned long pc,
 	fde = dwarf_lookup_fde(pc);
 	if (!fde) {
 		/*
-		 * This is our normal exit path - the one that stops the
-		 * recursion. There's two reasons why we might exit
-		 * here,
+		 * This is our normal exit path. There are two reasons
+		 * why we might exit here,
 		 *
 		 *	a) pc has no asscociated DWARF frame info and so
 		 *	we don't know how to unwind this frame. This is
@@ -626,10 +626,10 @@ struct dwarf_frame * dwarf_unwind_stack(unsigned long pc,
 
 		} else {
 			/*
-			 * Again, this is the first invocation of this
-			 * recurisve function. We need to physically
-			 * read the contents of a register in order to
-			 * get the Canonical Frame Address for this
+			 * Again, we're starting from the top of the
+			 * stack. We need to physically read
+			 * the contents of a register in order to get
+			 * the Canonical Frame Address for this
 			 * function.
 			 */
 			frame->cfa = dwarf_read_arch_reg(frame->cfa_register);

commit ed4fe7f488008f38d5f423f0bcc736b1779d6ddc
Author: Matt Fleming <matt@console-pimps.org>
Date:   Sat Oct 10 16:03:11 2009 +0100

    sh: Fix memory leak in dwarf_unwind_stack()
    
    If we broke out of the while (1) loop because the return address of
    "frame" was zero, then "frame" needs to be free'd before we return.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 981315c6d656..ce8bff45d72c 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -529,6 +529,16 @@ static int dwarf_cfa_execute_insns(unsigned char *insn_start,
 	return 0;
 }
 
+/**
+ *	dwarf_free_frame - free the memory allocated for @frame
+ *	@frame: the frame to free
+ */
+void dwarf_free_frame(struct dwarf_frame *frame)
+{
+	dwarf_frame_free_regs(frame);
+	mempool_free(frame, dwarf_frame_pool);
+}
+
 /**
  *	dwarf_unwind_stack - recursively unwind the stack
  *	@pc: address of the function to unwind
@@ -649,8 +659,7 @@ struct dwarf_frame * dwarf_unwind_stack(unsigned long pc,
 	return frame;
 
 bail:
-	dwarf_frame_free_regs(frame);
-	mempool_free(frame, dwarf_frame_pool);
+	dwarf_free_frame(frame);
 	return NULL;
 }
 
@@ -837,10 +846,8 @@ static void dwarf_unwinder_dump(struct task_struct *task,
 	while (1) {
 		frame = dwarf_unwind_stack(return_addr, _frame);
 
-		if (_frame) {
-			dwarf_frame_free_regs(_frame);
-			mempool_free(_frame, dwarf_frame_pool);
-		}
+		if (_frame)
+			dwarf_free_frame(_frame);
 
 		_frame = frame;
 
@@ -850,6 +857,9 @@ static void dwarf_unwinder_dump(struct task_struct *task,
 		return_addr = frame->return_addr;
 		ops->address(data, return_addr, 1);
 	}
+
+	if (frame)
+		dwarf_free_frame(frame);
 }
 
 static struct unwinder dwarf_unwinder = {

commit a6a2f2ad67506090e332f440457553c0ec011d68
Author: Matt Fleming <matt@console-pimps.org>
Date:   Fri Oct 9 23:20:54 2009 +0100

    sh: Teach the DWARF unwinder about modules
    
    Pass a module's .eh_frame section to the DWARF unwinder at module load
    time so that the section's FDEs and CIEs can be registered with the
    DWARF unwinder. This allows us to unwind the stack through module code
    when generating backtraces.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 577302f31e6a..981315c6d656 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -655,7 +655,7 @@ struct dwarf_frame * dwarf_unwind_stack(unsigned long pc,
 }
 
 static int dwarf_parse_cie(void *entry, void *p, unsigned long len,
-			   unsigned char *end)
+			   unsigned char *end, struct module *mod)
 {
 	struct dwarf_cie *cie;
 	unsigned long flags;
@@ -751,6 +751,8 @@ static int dwarf_parse_cie(void *entry, void *p, unsigned long len,
 	cie->initial_instructions = p;
 	cie->instructions_end = end;
 
+	cie->mod = mod;
+
 	/* Add to list */
 	spin_lock_irqsave(&dwarf_cie_lock, flags);
 	list_add_tail(&cie->link, &dwarf_cie_list);
@@ -761,7 +763,7 @@ static int dwarf_parse_cie(void *entry, void *p, unsigned long len,
 
 static int dwarf_parse_fde(void *entry, u32 entry_type,
 			   void *start, unsigned long len,
-			   unsigned char *end)
+			   unsigned char *end, struct module *mod)
 {
 	struct dwarf_fde *fde;
 	struct dwarf_cie *cie;
@@ -810,6 +812,8 @@ static int dwarf_parse_fde(void *entry, u32 entry_type,
 	fde->instructions = p;
 	fde->end = end;
 
+	fde->mod = mod;
+
 	/* Add to list. */
 	spin_lock_irqsave(&dwarf_fde_lock, flags);
 	list_add_tail(&fde->link, &dwarf_fde_list);
@@ -875,15 +879,15 @@ static void dwarf_unwinder_cleanup(void)
 }
 
 /**
- *	dwarf_unwinder_init - initialise the dwarf unwinder
+ *	dwarf_parse_section - parse DWARF section
+ *	@eh_frame_start: start address of the .eh_frame section
+ *	@eh_frame_end: end address of the .eh_frame section
+ *	@mod: the kernel module containing the .eh_frame section
  *
- *	Build the data structures describing the .dwarf_frame section to
- *	make it easier to lookup CIE and FDE entries. Because the
- *	.eh_frame section is packed as tightly as possible it is not
- *	easy to lookup the FDE for a given PC, so we build a list of FDE
- *	and CIE entries that make it easier.
+ *	Parse the information in a .eh_frame section.
  */
-static int __init dwarf_unwinder_init(void)
+int dwarf_parse_section(char *eh_frame_start, char *eh_frame_end,
+			struct module *mod)
 {
 	u32 entry_type;
 	void *p, *entry;
@@ -891,29 +895,12 @@ static int __init dwarf_unwinder_init(void)
 	unsigned long len;
 	unsigned int c_entries, f_entries;
 	unsigned char *end;
-	INIT_LIST_HEAD(&dwarf_cie_list);
-	INIT_LIST_HEAD(&dwarf_fde_list);
 
 	c_entries = 0;
 	f_entries = 0;
-	entry = &__start_eh_frame;
-
-	dwarf_frame_cachep = kmem_cache_create("dwarf_frames",
-			sizeof(struct dwarf_frame), 0, SLAB_PANIC, NULL);
-	dwarf_reg_cachep = kmem_cache_create("dwarf_regs",
-			sizeof(struct dwarf_reg), 0, SLAB_PANIC, NULL);
-
-	dwarf_frame_pool = mempool_create(DWARF_FRAME_MIN_REQ,
-					  mempool_alloc_slab,
-					  mempool_free_slab,
-					  dwarf_frame_cachep);
+	entry = eh_frame_start;
 
-	dwarf_reg_pool = mempool_create(DWARF_REG_MIN_REQ,
-					 mempool_alloc_slab,
-					 mempool_free_slab,
-					 dwarf_reg_cachep);
-
-	while ((char *)entry < __stop_eh_frame) {
+	while ((char *)entry < eh_frame_end) {
 		p = entry;
 
 		count = dwarf_entry_len(p, &len);
@@ -925,6 +912,7 @@ static int __init dwarf_unwinder_init(void)
 			 * entry and move to the next one because 'len'
 			 * tells us where our next entry is.
 			 */
+			err = -EINVAL;
 			goto out;
 		} else
 			p += count;
@@ -936,13 +924,14 @@ static int __init dwarf_unwinder_init(void)
 		p += 4;
 
 		if (entry_type == DW_EH_FRAME_CIE) {
-			err = dwarf_parse_cie(entry, p, len, end);
+			err = dwarf_parse_cie(entry, p, len, end, mod);
 			if (err < 0)
 				goto out;
 			else
 				c_entries++;
 		} else {
-			err = dwarf_parse_fde(entry, entry_type, p, len, end);
+			err = dwarf_parse_fde(entry, entry_type, p, len,
+					      end, mod);
 			if (err < 0)
 				goto out;
 			else
@@ -955,6 +944,92 @@ static int __init dwarf_unwinder_init(void)
 	printk(KERN_INFO "DWARF unwinder initialised: read %u CIEs, %u FDEs\n",
 	       c_entries, f_entries);
 
+	return 0;
+
+out:
+	return err;
+}
+
+/**
+ *	dwarf_module_unload - remove FDE/CIEs associated with @mod
+ *	@mod: the module that is being unloaded
+ *
+ *	Remove any FDEs and CIEs from the global lists that came from
+ *	@mod's .eh_frame section because @mod is being unloaded.
+ */
+void dwarf_module_unload(struct module *mod)
+{
+	struct dwarf_fde *fde;
+	struct dwarf_cie *cie;
+	unsigned long flags;
+
+	spin_lock_irqsave(&dwarf_cie_lock, flags);
+
+again_cie:
+	list_for_each_entry(cie, &dwarf_cie_list, link) {
+		if (cie->mod == mod)
+			break;
+	}
+
+	if (&cie->link != &dwarf_cie_list) {
+		list_del(&cie->link);
+		kfree(cie);
+		goto again_cie;
+	}
+
+	spin_unlock_irqrestore(&dwarf_cie_lock, flags);
+
+	spin_lock_irqsave(&dwarf_fde_lock, flags);
+
+again_fde:
+	list_for_each_entry(fde, &dwarf_fde_list, link) {
+		if (fde->mod == mod)
+			break;
+	}
+
+	if (&fde->link != &dwarf_fde_list) {
+		list_del(&fde->link);
+		kfree(fde);
+		goto again_fde;
+	}
+
+	spin_unlock_irqrestore(&dwarf_fde_lock, flags);
+}
+
+/**
+ *	dwarf_unwinder_init - initialise the dwarf unwinder
+ *
+ *	Build the data structures describing the .dwarf_frame section to
+ *	make it easier to lookup CIE and FDE entries. Because the
+ *	.eh_frame section is packed as tightly as possible it is not
+ *	easy to lookup the FDE for a given PC, so we build a list of FDE
+ *	and CIE entries that make it easier.
+ */
+static int __init dwarf_unwinder_init(void)
+{
+	int err;
+	INIT_LIST_HEAD(&dwarf_cie_list);
+	INIT_LIST_HEAD(&dwarf_fde_list);
+
+	dwarf_frame_cachep = kmem_cache_create("dwarf_frames",
+			sizeof(struct dwarf_frame), 0, SLAB_PANIC, NULL);
+	dwarf_reg_cachep = kmem_cache_create("dwarf_regs",
+			sizeof(struct dwarf_reg), 0, SLAB_PANIC, NULL);
+
+	dwarf_frame_pool = mempool_create(DWARF_FRAME_MIN_REQ,
+					  mempool_alloc_slab,
+					  mempool_free_slab,
+					  dwarf_frame_cachep);
+
+	dwarf_reg_pool = mempool_create(DWARF_REG_MIN_REQ,
+					 mempool_alloc_slab,
+					 mempool_free_slab,
+					 dwarf_reg_cachep);
+
+	err = dwarf_parse_section(__start_eh_frame, __stop_eh_frame, NULL);
+	if (err)
+		goto out;
+
 	err = unwinder_register(&dwarf_unwinder);
 	if (err)
 		goto out;

commit a6bbce200deefb78c49e159ca718df22f18e5037
Author: Jaswinder Singh Rajput <jaswinder@kernel.org>
Date:   Tue Sep 22 13:50:26 2009 +0000

    sh: includecheck fix: dwarf.c
    
    fix the following 'make includecheck' warning:
    
      arch/sh/kernel/dwarf.c: asm/dwarf.h is included more than once.
    
    Signed-off-by: Jaswinder Singh Rajput <jaswinderrajput@gmail.com>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index bc4d8d75332b..03b3616c80a5 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -24,7 +24,6 @@
 #include <asm/unwinder.h>
 #include <asm/sections.h>
 #include <asm/unaligned.h>
-#include <asm/dwarf.h>
 #include <asm/stacktrace.h>
 
 /* Reserve enough memory for two stack frames */

commit 2f6dafc5fcbf3fddce345c47da1f277a156fe22a
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Aug 31 13:47:06 2009 +0900

    sh: unwinder: Fix up uninitialized variable warnings on sh2a build.
    
    A couple of these popped up on the sh2a build, causing build failures.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 700f7e0fd658..bc4d8d75332b 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -887,7 +887,7 @@ static int __init dwarf_unwinder_init(void)
 {
 	u32 entry_type;
 	void *p, *entry;
-	int count, err;
+	int count, err = 0;
 	unsigned long len;
 	unsigned int c_entries, f_entries;
 	unsigned char *end;

commit 4f896ffca2b72f4b719746e7fbb0b623252e6ac9
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Sat Aug 22 19:03:25 2009 +0900

    sh: unwinder: cacheline align slab cache objects.
    
    The CIE and FDE structs are big enough and accessed regularly enough in
    certain configurations to make cacheline alignment useful.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 577302f31e6a..700f7e0fd658 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -899,9 +899,12 @@ static int __init dwarf_unwinder_init(void)
 	entry = &__start_eh_frame;
 
 	dwarf_frame_cachep = kmem_cache_create("dwarf_frames",
-			sizeof(struct dwarf_frame), 0, SLAB_PANIC, NULL);
+			sizeof(struct dwarf_frame), 0,
+			SLAB_PANIC | SLAB_HWCACHE_ALIGN | SLAB_NOTRACK, NULL);
+
 	dwarf_reg_cachep = kmem_cache_create("dwarf_regs",
-			sizeof(struct dwarf_reg), 0, SLAB_PANIC, NULL);
+			sizeof(struct dwarf_reg), 0,
+			SLAB_PANIC | SLAB_HWCACHE_ALIGN | SLAB_NOTRACK, NULL);
 
 	dwarf_frame_pool = mempool_create(DWARF_FRAME_MIN_REQ,
 					  mempool_alloc_slab,

commit 5580e9044df9c0e87861739d8c527006ead92e52
Author: Matt Fleming <matt@console-pimps.org>
Date:   Thu Aug 20 19:53:49 2009 +0100

    sh: Handle the DWARF op, DW_CFA_undefined
    
    Allow a DWARF register to have an undefined value. When applied to the
    DWARF return address register this lets lets us label a function as
    having no direct caller, e.g. kernel_thread_helper().
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index e6f427cff5ba..577302f31e6a 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -452,6 +452,8 @@ static int dwarf_cfa_execute_insns(unsigned char *insn_start,
 		case DW_CFA_undefined:
 			count = dwarf_read_uleb128(current_insn, &reg);
 			current_insn += count;
+			regp = dwarf_frame_alloc_reg(frame, reg);
+			regp->flags |= DWARF_UNDEFINED;
 			break;
 		case DW_CFA_def_cfa:
 			count = dwarf_read_uleb128(current_insn,
@@ -629,9 +631,16 @@ struct dwarf_frame * dwarf_unwind_stack(unsigned long pc,
 		UNWINDER_BUG();
 	}
 
-	/* If we haven't seen the return address reg, we're screwed. */
 	reg = dwarf_frame_reg(frame, DWARF_ARCH_RA_REG);
-	UNWINDER_BUG_ON(!reg);
+
+	/*
+	 * If we haven't seen the return address register or the return
+	 * address column is undefined then we must assume that this is
+	 * the end of the callstack.
+	 */
+	if (!reg || reg->flags == DWARF_UNDEFINED)
+		goto bail;
+
 	UNWINDER_BUG_ON(reg->flags != DWARF_REG_OFFSET);
 
 	addr = frame->cfa + reg->addr;

commit 5480675dc60c7dda7146e506981b2b40a775cc1e
Author: Matt Fleming <matt@console-pimps.org>
Date:   Thu Aug 20 19:42:34 2009 +0100

    sh: Fix bug calculating the end of the FDE instructions
    
    The 'end' member of struct dwarf_fde denotes one byte past the end of
    the CFA instruction stream for an FDE. The value of 'end' was being
    calcualted incorrectly, it was being set too high. This resulted in
    dwarf_cfa_execute_insns() interpreting data past the end of valid
    instructions, thus causing all sorts of weird crashes.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 606ece37eb42..e6f427cff5ba 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -751,7 +751,8 @@ static int dwarf_parse_cie(void *entry, void *p, unsigned long len,
 }
 
 static int dwarf_parse_fde(void *entry, u32 entry_type,
-			   void *start, unsigned long len)
+			   void *start, unsigned long len,
+			   unsigned char *end)
 {
 	struct dwarf_fde *fde;
 	struct dwarf_cie *cie;
@@ -798,7 +799,7 @@ static int dwarf_parse_fde(void *entry, u32 entry_type,
 
 	/* Call frame instructions. */
 	fde->instructions = p;
-	fde->end = start + len;
+	fde->end = end;
 
 	/* Add to list. */
 	spin_lock_irqsave(&dwarf_fde_lock, flags);
@@ -932,7 +933,7 @@ static int __init dwarf_unwinder_init(void)
 			else
 				c_entries++;
 		} else {
-			err = dwarf_parse_fde(entry, entry_type, p, len);
+			err = dwarf_parse_fde(entry, entry_type, p, len, end);
 			if (err < 0)
 				goto out;
 			else

commit b344e24a8e8ceda83d1285d22e3e5baf4f5e42d3
Author: Matt Fleming <matt@console-pimps.org>
Date:   Sun Aug 16 21:54:48 2009 +0100

    sh: unwinder: Introduce UNWINDER_BUG() and UNWINDER_BUG_ON()
    
    We can't assume that if we execute the unwinder code and the unwinder
    was already running that it has faulted. Clearly two kernel threads can
    invoke the unwinder at the same time and may be running simultaneously.
    
    The previous approach used BUG() and BUG_ON() in the unwinder code to
    detect whether the unwinder was incapable of unwinding the stack, and
    that the next available unwinder should be used instead. A better
    approach is to explicitly invoke a trap handler to switch unwinders when
    the current unwinder cannot continue.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index d271d04adccd..606ece37eb42 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -69,7 +69,7 @@ static struct dwarf_reg *dwarf_frame_alloc_reg(struct dwarf_frame *frame,
 		 * Let's just bomb hard here, we have no way to
 		 * gracefully recover.
 		 */
-		BUG();
+		UNWINDER_BUG();
 	}
 
 	reg->number = reg_num;
@@ -232,7 +232,7 @@ static int dwarf_read_encoded_value(char *addr, unsigned long *val,
 		break;
 	default:
 		pr_debug("encoding=0x%x\n", (encoding & 0x70));
-		BUG();
+		UNWINDER_BUG();
 	}
 
 	if ((encoding & 0x07) == 0x00)
@@ -247,7 +247,7 @@ static int dwarf_read_encoded_value(char *addr, unsigned long *val,
 		break;
 	default:
 		pr_debug("encoding=0x%x\n", encoding);
-		BUG();
+		UNWINDER_BUG();
 	}
 
 	return count;
@@ -519,6 +519,7 @@ static int dwarf_cfa_execute_insns(unsigned char *insn_start,
 			break;
 		default:
 			pr_debug("unhandled DWARF instruction 0x%x\n", insn);
+			UNWINDER_BUG();
 			break;
 		}
 	}
@@ -535,8 +536,8 @@ static int dwarf_cfa_execute_insns(unsigned char *insn_start,
  *	on the callstack. Each of the lower (older) stack frames are
  *	linked via the "prev" member.
  */
-struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
-				       struct dwarf_frame *prev)
+struct dwarf_frame * dwarf_unwind_stack(unsigned long pc,
+					struct dwarf_frame *prev)
 {
 	struct dwarf_frame *frame;
 	struct dwarf_cie *cie;
@@ -558,7 +559,7 @@ struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
 	frame = mempool_alloc(dwarf_frame_pool, GFP_ATOMIC);
 	if (!frame) {
 		printk(KERN_ERR "Unable to allocate a dwarf frame\n");
-		BUG();
+		UNWINDER_BUG();
 	}
 
 	INIT_LIST_HEAD(&frame->reg_list);
@@ -605,7 +606,8 @@ struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
 	case DWARF_FRAME_CFA_REG_OFFSET:
 		if (prev) {
 			reg = dwarf_frame_reg(prev, frame->cfa_register);
-			BUG_ON(!reg);
+			UNWINDER_BUG_ON(!reg);
+			UNWINDER_BUG_ON(reg->flags != DWARF_REG_OFFSET);
 
 			addr = prev->cfa + reg->addr;
 			frame->cfa = __raw_readl(addr);
@@ -624,12 +626,13 @@ struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
 		frame->cfa += frame->cfa_offset;
 		break;
 	default:
-		BUG();
+		UNWINDER_BUG();
 	}
 
 	/* If we haven't seen the return address reg, we're screwed. */
 	reg = dwarf_frame_reg(frame, DWARF_ARCH_RA_REG);
-	BUG_ON(!reg);
+	UNWINDER_BUG_ON(!reg);
+	UNWINDER_BUG_ON(reg->flags != DWARF_REG_OFFSET);
 
 	addr = frame->cfa + reg->addr;
 	frame->return_addr = __raw_readl(addr);
@@ -664,7 +667,7 @@ static int dwarf_parse_cie(void *entry, void *p, unsigned long len,
 	cie->cie_pointer = (unsigned long)entry;
 
 	cie->version = *(char *)p++;
-	BUG_ON(cie->version != 1);
+	UNWINDER_BUG_ON(cie->version != 1);
 
 	cie->augmentation = p;
 	p += strlen(cie->augmentation) + 1;
@@ -694,7 +697,7 @@ static int dwarf_parse_cie(void *entry, void *p, unsigned long len,
 		count = dwarf_read_uleb128(p, &length);
 		p += count;
 
-		BUG_ON((unsigned char *)p > end);
+		UNWINDER_BUG_ON((unsigned char *)p > end);
 
 		cie->initial_instructions = p + length;
 		cie->augmentation++;
@@ -722,16 +725,16 @@ static int dwarf_parse_cie(void *entry, void *p, unsigned long len,
 			 * routine in the CIE
 			 * augmentation.
 			 */
-			BUG();
+			UNWINDER_BUG();
 		} else if (*cie->augmentation == 'S') {
-			BUG();
+			UNWINDER_BUG();
 		} else {
 			/*
 			 * Unknown augmentation. Assume
 			 * 'z' augmentation.
 			 */
 			p = cie->initial_instructions;
-			BUG_ON(!p);
+			UNWINDER_BUG_ON(!p);
 			break;
 		}
 	}
@@ -805,9 +808,11 @@ static int dwarf_parse_fde(void *entry, u32 entry_type,
 	return 0;
 }
 
-static void dwarf_unwinder_dump(struct task_struct *task, struct pt_regs *regs,
+static void dwarf_unwinder_dump(struct task_struct *task,
+				struct pt_regs *regs,
 				unsigned long *sp,
-				const struct stacktrace_ops *ops, void *data)
+				const struct stacktrace_ops *ops,
+				void *data)
 {
 	struct dwarf_frame *frame, *_frame;
 	unsigned long return_addr;
@@ -831,7 +836,6 @@ static void dwarf_unwinder_dump(struct task_struct *task, struct pt_regs *regs,
 		return_addr = frame->return_addr;
 		ops->address(data, return_addr, 1);
 	}
-
 }
 
 static struct unwinder dwarf_unwinder = {

commit 97efbbd5886e27b61c19c77d41f6491f5d96fbd0
Author: Matt Fleming <matt@console-pimps.org>
Date:   Sun Aug 16 15:56:35 2009 +0100

    sh: unwinder: Set the flags for DW_CFA_val_offset ops as DWARF_VAL_OFFSET
    
    The handling of DW_CFA_val_offset ops was incorrectly using the
    DWARF_REG_OFFSET flag but the register's value cannot be calculated
    using the DWARF_REG_OFFSET method. Create a new flag to indicate that a
    different method must be used to calculate the register's value even
    though there is no implementation for DWARF_VAL_OFFSET yet; it's mainly
    just a place holder.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index e4810375207d..d271d04adccd 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -11,6 +11,7 @@
  *
  * TODO:
  *	- DWARF64 doesn't work.
+ *	- Registers with DWARF_VAL_OFFSET rules aren't handled properly.
  */
 
 /* #define DEBUG */
@@ -499,7 +500,7 @@ static int dwarf_cfa_execute_insns(unsigned char *insn_start,
 			count = dwarf_read_leb128(current_insn, &offset);
 			offset *= cie->data_alignment_factor;
 			regp = dwarf_frame_alloc_reg(frame, reg);
-			regp->flags |= DWARF_REG_OFFSET;
+			regp->flags |= DWARF_VAL_OFFSET;
 			regp->addr = offset;
 			break;
 		case DW_CFA_GNU_args_size:

commit fb3f3e7fc6d4afb32f9eba32124beaf40313de3c
Author: Matt Fleming <matt@console-pimps.org>
Date:   Sun Aug 16 15:44:08 2009 +0100

    sh: unwinder: Fix memory leak and create our own kmem cache
    
    Plug a memory leak in dwarf_unwinder_dump() where we didn't free the
    memory that we had previously allocated for the DWARF frames and DWARF
    registers.
    
    Now is also a opportune time to implement our own mempool and kmem
    cache. It's a good idea to have a certain number of frame and register
    objects in reserve at all times, so that we are guaranteed to have our
    allocation satisfied even when memory is scarce. Since we have pools to
    allocate from we can implement the registers for each frame as a linked
    list as opposed to a sparsely populated array. Whilst it's true that the
    lookup time for a linked list is larger than for arrays, there's only
    usually a maximum of 8 registers per frame. So the overhead isn't that
    much of a concern.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index d0652153f576..e4810375207d 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -17,6 +17,7 @@
 #include <linux/kernel.h>
 #include <linux/io.h>
 #include <linux/list.h>
+#include <linux/mempool.h>
 #include <linux/mm.h>
 #include <asm/dwarf.h>
 #include <asm/unwinder.h>
@@ -25,6 +26,17 @@
 #include <asm/dwarf.h>
 #include <asm/stacktrace.h>
 
+/* Reserve enough memory for two stack frames */
+#define DWARF_FRAME_MIN_REQ	2
+/* ... with 4 registers per frame. */
+#define DWARF_REG_MIN_REQ	(DWARF_FRAME_MIN_REQ * 4)
+
+static struct kmem_cache *dwarf_frame_cachep;
+static mempool_t *dwarf_frame_pool;
+
+static struct kmem_cache *dwarf_reg_cachep;
+static mempool_t *dwarf_reg_pool;
+
 static LIST_HEAD(dwarf_cie_list);
 static DEFINE_SPINLOCK(dwarf_cie_lock);
 
@@ -33,33 +45,25 @@ static DEFINE_SPINLOCK(dwarf_fde_lock);
 
 static struct dwarf_cie *cached_cie;
 
-/*
- * Figure out whether we need to allocate some dwarf registers. If dwarf
- * registers have already been allocated then we may need to realloc
- * them. "reg" is a register number that we need to be able to access
- * after this call.
+/**
+ *	dwarf_frame_alloc_reg - allocate memory for a DWARF register
+ *	@frame: the DWARF frame whose list of registers we insert on
+ *	@reg_num: the register number
+ *
+ *	Allocate space for, and initialise, a dwarf reg from
+ *	dwarf_reg_pool and insert it onto the (unsorted) linked-list of
+ *	dwarf registers for @frame.
  *
- * Register numbers start at zero, therefore we need to allocate space
- * for "reg" + 1 registers.
+ *	Return the initialised DWARF reg.
  */
-static void dwarf_frame_alloc_regs(struct dwarf_frame *frame,
-				   unsigned int reg)
+static struct dwarf_reg *dwarf_frame_alloc_reg(struct dwarf_frame *frame,
+					       unsigned int reg_num)
 {
-	struct dwarf_reg *regs;
-	unsigned int num_regs = reg + 1;
-	size_t new_size;
-	size_t old_size;
+	struct dwarf_reg *reg;
 
-	new_size = num_regs * sizeof(*regs);
-	old_size = frame->num_regs * sizeof(*regs);
-
-	/* Fast path: don't allocate any regs if we've already got enough. */
-	if (frame->num_regs >= num_regs)
-		return;
-
-	regs = kzalloc(new_size, GFP_ATOMIC);
-	if (!regs) {
-		printk(KERN_WARNING "Unable to allocate DWARF registers\n");
+	reg = mempool_alloc(dwarf_reg_pool, GFP_ATOMIC);
+	if (!reg) {
+		printk(KERN_WARNING "Unable to allocate a DWARF register\n");
 		/*
 		 * Let's just bomb hard here, we have no way to
 		 * gracefully recover.
@@ -67,13 +71,44 @@ static void dwarf_frame_alloc_regs(struct dwarf_frame *frame,
 		BUG();
 	}
 
-	if (frame->regs) {
-		memcpy(regs, frame->regs, old_size);
-		kfree(frame->regs);
+	reg->number = reg_num;
+	reg->addr = 0;
+	reg->flags = 0;
+
+	list_add(&reg->link, &frame->reg_list);
+
+	return reg;
+}
+
+static void dwarf_frame_free_regs(struct dwarf_frame *frame)
+{
+	struct dwarf_reg *reg, *n;
+
+	list_for_each_entry_safe(reg, n, &frame->reg_list, link) {
+		list_del(&reg->link);
+		mempool_free(reg, dwarf_reg_pool);
+	}
+}
+
+/**
+ *	dwarf_frame_reg - return a DWARF register
+ *	@frame: the DWARF frame to search in for @reg_num
+ *	@reg_num: the register number to search for
+ *
+ *	Lookup and return the dwarf reg @reg_num for this frame. Return
+ *	NULL if @reg_num is an register invalid number.
+ */
+static struct dwarf_reg *dwarf_frame_reg(struct dwarf_frame *frame,
+					 unsigned int reg_num)
+{
+	struct dwarf_reg *reg;
+
+	list_for_each_entry(reg, &frame->reg_list, link) {
+		if (reg->number == reg_num)
+			return reg;
 	}
 
-	frame->regs = regs;
-	frame->num_regs = num_regs;
+	return NULL;
 }
 
 /**
@@ -347,6 +382,7 @@ static int dwarf_cfa_execute_insns(unsigned char *insn_start,
 	unsigned char insn;
 	unsigned char *current_insn;
 	unsigned int count, delta, reg, expr_len, offset;
+	struct dwarf_reg *regp;
 
 	current_insn = insn_start;
 
@@ -369,9 +405,9 @@ static int dwarf_cfa_execute_insns(unsigned char *insn_start,
 			count = dwarf_read_uleb128(current_insn, &offset);
 			current_insn += count;
 			offset *= cie->data_alignment_factor;
-			dwarf_frame_alloc_regs(frame, reg);
-			frame->regs[reg].addr = offset;
-			frame->regs[reg].flags |= DWARF_REG_OFFSET;
+			regp = dwarf_frame_alloc_reg(frame, reg);
+			regp->addr = offset;
+			regp->flags |= DWARF_REG_OFFSET;
 			continue;
 			/* NOTREACHED */
 		case DW_CFA_restore:
@@ -453,17 +489,18 @@ static int dwarf_cfa_execute_insns(unsigned char *insn_start,
 			count = dwarf_read_leb128(current_insn, &offset);
 			current_insn += count;
 			offset *= cie->data_alignment_factor;
-			dwarf_frame_alloc_regs(frame, reg);
-			frame->regs[reg].flags |= DWARF_REG_OFFSET;
-			frame->regs[reg].addr = offset;
+			regp = dwarf_frame_alloc_reg(frame, reg);
+			regp->flags |= DWARF_REG_OFFSET;
+			regp->addr = offset;
 			break;
 		case DW_CFA_val_offset:
 			count = dwarf_read_uleb128(current_insn, &reg);
 			current_insn += count;
 			count = dwarf_read_leb128(current_insn, &offset);
 			offset *= cie->data_alignment_factor;
-			frame->regs[reg].flags |= DWARF_REG_OFFSET;
-			frame->regs[reg].addr = offset;
+			regp = dwarf_frame_alloc_reg(frame, reg);
+			regp->flags |= DWARF_REG_OFFSET;
+			regp->addr = offset;
 			break;
 		case DW_CFA_GNU_args_size:
 			count = dwarf_read_uleb128(current_insn, &offset);
@@ -474,9 +511,10 @@ static int dwarf_cfa_execute_insns(unsigned char *insn_start,
 			current_insn += count;
 			count = dwarf_read_uleb128(current_insn, &offset);
 			offset *= cie->data_alignment_factor;
-			dwarf_frame_alloc_regs(frame, reg);
-			frame->regs[reg].flags |= DWARF_REG_OFFSET;
-			frame->regs[reg].addr = -offset;
+
+			regp = dwarf_frame_alloc_reg(frame, reg);
+			regp->flags |= DWARF_REG_OFFSET;
+			regp->addr = -offset;
 			break;
 		default:
 			pr_debug("unhandled DWARF instruction 0x%x\n", insn);
@@ -502,8 +540,8 @@ struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
 	struct dwarf_frame *frame;
 	struct dwarf_cie *cie;
 	struct dwarf_fde *fde;
+	struct dwarf_reg *reg;
 	unsigned long addr;
-	int i, offset;
 
 	/*
 	 * If this is the first invocation of this recursive function we
@@ -516,11 +554,16 @@ struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
 	if (!pc && !prev)
 		pc = (unsigned long)current_text_addr();
 
-	frame = kzalloc(sizeof(*frame), GFP_ATOMIC);
-	if (!frame)
-		return NULL;
+	frame = mempool_alloc(dwarf_frame_pool, GFP_ATOMIC);
+	if (!frame) {
+		printk(KERN_ERR "Unable to allocate a dwarf frame\n");
+		BUG();
+	}
 
+	INIT_LIST_HEAD(&frame->reg_list);
+	frame->flags = 0;
 	frame->prev = prev;
+	frame->return_addr = 0;
 
 	fde = dwarf_lookup_fde(pc);
 	if (!fde) {
@@ -540,7 +583,7 @@ struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
 		 *	case above, which sucks because we could print a
 		 *	warning here.
 		 */
-		return NULL;
+		goto bail;
 	}
 
 	cie = dwarf_lookup_cie(fde->cie_pointer);
@@ -560,10 +603,10 @@ struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
 	switch (frame->flags) {
 	case DWARF_FRAME_CFA_REG_OFFSET:
 		if (prev) {
-			BUG_ON(!prev->regs[frame->cfa_register].flags);
+			reg = dwarf_frame_reg(prev, frame->cfa_register);
+			BUG_ON(!reg);
 
-			addr = prev->cfa;
-			addr += prev->regs[frame->cfa_register].addr;
+			addr = prev->cfa + reg->addr;
 			frame->cfa = __raw_readl(addr);
 
 		} else {
@@ -584,23 +627,18 @@ struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
 	}
 
 	/* If we haven't seen the return address reg, we're screwed. */
-	BUG_ON(!frame->regs[DWARF_ARCH_RA_REG].flags);
-
-	for (i = 0; i <= frame->num_regs; i++) {
-		struct dwarf_reg *reg = &frame->regs[i];
-
-		if (!reg->flags)
-			continue;
+	reg = dwarf_frame_reg(frame, DWARF_ARCH_RA_REG);
+	BUG_ON(!reg);
 
-		offset = reg->addr;
-		offset += frame->cfa;
-	}
-
-	addr = frame->cfa + frame->regs[DWARF_ARCH_RA_REG].addr;
+	addr = frame->cfa + reg->addr;
 	frame->return_addr = __raw_readl(addr);
 
-	frame->next = dwarf_unwind_stack(frame->return_addr, frame);
 	return frame;
+
+bail:
+	dwarf_frame_free_regs(frame);
+	mempool_free(frame, dwarf_frame_pool);
+	return NULL;
 }
 
 static int dwarf_parse_cie(void *entry, void *p, unsigned long len,
@@ -770,14 +808,29 @@ static void dwarf_unwinder_dump(struct task_struct *task, struct pt_regs *regs,
 				unsigned long *sp,
 				const struct stacktrace_ops *ops, void *data)
 {
-	struct dwarf_frame *frame;
+	struct dwarf_frame *frame, *_frame;
+	unsigned long return_addr;
+
+	_frame = NULL;
+	return_addr = 0;
 
-	frame = dwarf_unwind_stack(0, NULL);
+	while (1) {
+		frame = dwarf_unwind_stack(return_addr, _frame);
+
+		if (_frame) {
+			dwarf_frame_free_regs(_frame);
+			mempool_free(_frame, dwarf_frame_pool);
+		}
+
+		_frame = frame;
+
+		if (!frame || !frame->return_addr)
+			break;
 
-	while (frame && frame->return_addr) {
-		ops->address(data, frame->return_addr, 1);
-		frame = frame->next;
+		return_addr = frame->return_addr;
+		ops->address(data, return_addr, 1);
 	}
+
 }
 
 static struct unwinder dwarf_unwinder = {
@@ -801,6 +854,9 @@ static void dwarf_unwinder_cleanup(void)
 
 	list_for_each_entry(fde, &dwarf_fde_list, link)
 		kfree(fde);
+
+	kmem_cache_destroy(dwarf_reg_cachep);
+	kmem_cache_destroy(dwarf_frame_cachep);
 }
 
 /**
@@ -827,6 +883,21 @@ static int __init dwarf_unwinder_init(void)
 	f_entries = 0;
 	entry = &__start_eh_frame;
 
+	dwarf_frame_cachep = kmem_cache_create("dwarf_frames",
+			sizeof(struct dwarf_frame), 0, SLAB_PANIC, NULL);
+	dwarf_reg_cachep = kmem_cache_create("dwarf_regs",
+			sizeof(struct dwarf_reg), 0, SLAB_PANIC, NULL);
+
+	dwarf_frame_pool = mempool_create(DWARF_FRAME_MIN_REQ,
+					  mempool_alloc_slab,
+					  mempool_free_slab,
+					  dwarf_frame_cachep);
+
+	dwarf_reg_pool = mempool_create(DWARF_REG_MIN_REQ,
+					 mempool_alloc_slab,
+					 mempool_free_slab,
+					 dwarf_reg_cachep);
+
 	while ((char *)entry < __stop_eh_frame) {
 		p = entry;
 

commit 97f361e2498ada54b48a235619eaf5af8e46427e
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Aug 17 05:07:38 2009 +0900

    sh: unwinder: Move initialization to early_initcall() and tidy up locking.
    
    This moves the initialization over to an early_initcall(). This fixes up
    some lockdep interaction issues. At the same time, kill off some
    superfluous locking in the init path.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 5fd6e604816d..d0652153f576 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -26,10 +26,10 @@
 #include <asm/stacktrace.h>
 
 static LIST_HEAD(dwarf_cie_list);
-DEFINE_SPINLOCK(dwarf_cie_lock);
+static DEFINE_SPINLOCK(dwarf_cie_lock);
 
 static LIST_HEAD(dwarf_fde_list);
-DEFINE_SPINLOCK(dwarf_fde_lock);
+static DEFINE_SPINLOCK(dwarf_fde_lock);
 
 static struct dwarf_cie *cached_cie;
 
@@ -264,7 +264,7 @@ static inline int dwarf_entry_len(char *addr, unsigned long *len)
  */
 static struct dwarf_cie *dwarf_lookup_cie(unsigned long cie_ptr)
 {
-	struct dwarf_cie *cie, *n;
+	struct dwarf_cie *cie;
 	unsigned long flags;
 
 	spin_lock_irqsave(&dwarf_cie_lock, flags);
@@ -278,7 +278,7 @@ static struct dwarf_cie *dwarf_lookup_cie(unsigned long cie_ptr)
 		goto out;
 	}
 
-	list_for_each_entry_safe(cie, n, &dwarf_cie_list, link) {
+	list_for_each_entry(cie, &dwarf_cie_list, link) {
 		if (cie->cie_pointer == cie_ptr) {
 			cached_cie = cie;
 			break;
@@ -299,11 +299,12 @@ static struct dwarf_cie *dwarf_lookup_cie(unsigned long cie_ptr)
  */
 struct dwarf_fde *dwarf_lookup_fde(unsigned long pc)
 {
+	struct dwarf_fde *fde;
 	unsigned long flags;
-	struct dwarf_fde *fde, *n;
 
 	spin_lock_irqsave(&dwarf_fde_lock, flags);
-	list_for_each_entry_safe(fde, n, &dwarf_fde_list, link) {
+
+	list_for_each_entry(fde, &dwarf_fde_list, link) {
 		unsigned long start, end;
 
 		start = fde->initial_location;
@@ -787,24 +788,19 @@ static struct unwinder dwarf_unwinder = {
 
 static void dwarf_unwinder_cleanup(void)
 {
-	struct dwarf_cie *cie, *m;
-	struct dwarf_fde *fde, *n;
-	unsigned long flags;
+	struct dwarf_cie *cie;
+	struct dwarf_fde *fde;
 
 	/*
 	 * Deallocate all the memory allocated for the DWARF unwinder.
 	 * Traverse all the FDE/CIE lists and remove and free all the
 	 * memory associated with those data structures.
 	 */
-	spin_lock_irqsave(&dwarf_cie_lock, flags);
-	list_for_each_entry_safe(cie, m, &dwarf_cie_list, link)
+	list_for_each_entry(cie, &dwarf_cie_list, link)
 		kfree(cie);
-	spin_unlock_irqrestore(&dwarf_cie_lock, flags);
 
-	spin_lock_irqsave(&dwarf_fde_lock, flags);
-	list_for_each_entry_safe(fde, n, &dwarf_fde_list, link)
+	list_for_each_entry(fde, &dwarf_fde_list, link)
 		kfree(fde);
-	spin_unlock_irqrestore(&dwarf_fde_lock, flags);
 }
 
 /**
@@ -816,7 +812,7 @@ static void dwarf_unwinder_cleanup(void)
  *	easy to lookup the FDE for a given PC, so we build a list of FDE
  *	and CIE entries that make it easier.
  */
-void dwarf_unwinder_init(void)
+static int __init dwarf_unwinder_init(void)
 {
 	u32 entry_type;
 	void *p, *entry;
@@ -877,9 +873,11 @@ void dwarf_unwinder_init(void)
 	if (err)
 		goto out;
 
-	return;
+	return 0;
 
 out:
 	printk(KERN_ERR "Failed to initialise DWARF unwinder: %d\n", err);
 	dwarf_unwinder_cleanup();
+	return -EINVAL;
 }
+early_initcall(dwarf_unwinder_init);

commit cd7246f0e2747bd2b43d25d0f63f05db182a62c0
Author: Matt Fleming <matt@console-pimps.org>
Date:   Sun Aug 16 01:44:33 2009 +0100

    sh: Add support for DWARF GNU extensions
    
    Also, remove the "fix" to DW_CFA_def_cfa_register where we reset the
    frame's cfa_offset to 0. This action is incorrect when handling
    DW_CFA_def_cfa_register as the DWARF spec specifically states that the
    previous contents of cfa_offset should be used with the new
    register. The reason that I thought cfa_offset should be reset to 0 was
    because it was being assigned a bogus value prior to executing the
    DW_CFA_def_cfa_register op. It turns out that the bogus cfa_offset value
    came from interpreting .cfi_escape pseudo-ops (those used by the GNU
    extensions) as CFA_DW_def_cfa ops.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 44e674ed2871..5fd6e604816d 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -429,7 +429,6 @@ static int dwarf_cfa_execute_insns(unsigned char *insn_start,
 			count = dwarf_read_uleb128(current_insn,
 						   &frame->cfa_register);
 			current_insn += count;
-			frame->cfa_offset = 0;
 			frame->flags |= DWARF_FRAME_CFA_REG_OFFSET;
 			break;
 		case DW_CFA_def_cfa_offset:
@@ -465,6 +464,19 @@ static int dwarf_cfa_execute_insns(unsigned char *insn_start,
 			frame->regs[reg].flags |= DWARF_REG_OFFSET;
 			frame->regs[reg].addr = offset;
 			break;
+		case DW_CFA_GNU_args_size:
+			count = dwarf_read_uleb128(current_insn, &offset);
+			current_insn += count;
+			break;
+		case DW_CFA_GNU_negative_offset_extended:
+			count = dwarf_read_uleb128(current_insn, &reg);
+			current_insn += count;
+			count = dwarf_read_uleb128(current_insn, &offset);
+			offset *= cie->data_alignment_factor;
+			dwarf_frame_alloc_regs(frame, reg);
+			frame->regs[reg].flags |= DWARF_REG_OFFSET;
+			frame->regs[reg].addr = -offset;
+			break;
 		default:
 			pr_debug("unhandled DWARF instruction 0x%x\n", insn);
 			break;

commit b955873bf530ee4b80e6c8b734521ad07cbaed7e
Author: Matt Fleming <matt@console-pimps.org>
Date:   Sat Aug 15 23:10:57 2009 +0100

    sh: Try again at getting the initial return address for an unwind
    
    The previous hack for calculating the return address for the first frame
    we unwind (dwarf_unwinder_dump) didn't always work. The problem was that
    it assumed once it read the rule for calculating the return address,
    there would be no new rules for calculating it. This isn't true because
    the way in which the CFA is calculated can change as you progress
    through a function and the return address is figured out using the
    CFA. Therefore, the way to calculate the return address can change.
    
    So, instead of using some offset from the beginning of
    dwarf_unwind_stack which is just a flakey approach, and instead of
    executing instructions from the FDE until the return address is setup,
    we now figure out the pc in dwarf_unwind_stack() just before we call
    dwarf_cfa_execute_insns().
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index c6c5764a8ab1..44e674ed2871 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -330,7 +330,6 @@ struct dwarf_fde *dwarf_lookup_fde(unsigned long pc)
  *	@fde: the FDE for this function
  *	@frame: the instructions calculate the CFA for this frame
  *	@pc: the program counter of the address we're interested in
- *	@define_ra: keep executing insns until the return addr reg is defined?
  *
  *	Execute the Call Frame instruction sequence starting at
  *	@insn_start and ending at @insn_end. The instructions describe
@@ -342,36 +341,17 @@ static int dwarf_cfa_execute_insns(unsigned char *insn_start,
 				   struct dwarf_cie *cie,
 				   struct dwarf_fde *fde,
 				   struct dwarf_frame *frame,
-				   unsigned long pc,
-				   bool define_ra)
+				   unsigned long pc)
 {
 	unsigned char insn;
 	unsigned char *current_insn;
 	unsigned int count, delta, reg, expr_len, offset;
-	bool seen_ra_reg;
 
 	current_insn = insn_start;
 
-	/*
-	 * If we're executing instructions for the dwarf_unwind_stack()
-	 * FDE we need to keep executing instructions until the value of
-	 * DWARF_ARCH_RA_REG is defined. See the comment in
-	 * dwarf_unwind_stack() for more details.
-	 */
-	if (define_ra)
-		seen_ra_reg = false;
-	else
-		seen_ra_reg = true;
-
-	while (current_insn < insn_end && (frame->pc <= pc || !seen_ra_reg) ) {
+	while (current_insn < insn_end && frame->pc <= pc) {
 		insn = __raw_readb(current_insn++);
 
-		if (!seen_ra_reg) {
-			if (frame->num_regs >= DWARF_ARCH_RA_REG &&
-			    frame->regs[DWARF_ARCH_RA_REG].flags)
-				seen_ra_reg = true;
-		}
-
 		/*
 		 * Firstly, handle the opcodes that embed their operands
 		 * in the instructions.
@@ -511,26 +491,17 @@ struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
 	struct dwarf_fde *fde;
 	unsigned long addr;
 	int i, offset;
-	bool define_ra = false;
 
 	/*
 	 * If this is the first invocation of this recursive function we
 	 * need get the contents of a physical register to get the CFA
 	 * in order to begin the virtual unwinding of the stack.
 	 *
-	 * Setting "define_ra" to true indictates that we want
-	 * dwarf_cfa_execute_insns() to continue executing instructions
-	 * until we know how to calculate the value of DWARF_ARCH_RA_REG
-	 * (which we need in order to kick off the whole unwinding
-	 * process).
-	 *
 	 * NOTE: the return address is guaranteed to be setup by the
 	 * time this function makes its first function call.
 	 */
-	if (!pc && !prev) {
-		pc = (unsigned long)&dwarf_unwind_stack;
-		define_ra = true;
-	}
+	if (!pc && !prev)
+		pc = (unsigned long)current_text_addr();
 
 	frame = kzalloc(sizeof(*frame), GFP_ATOMIC);
 	if (!frame)
@@ -566,11 +537,11 @@ struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
 	/* CIE initial instructions */
 	dwarf_cfa_execute_insns(cie->initial_instructions,
 				cie->instructions_end, cie, fde,
-				frame, pc, false);
+				frame, pc);
 
 	/* FDE instructions */
 	dwarf_cfa_execute_insns(fde->instructions, fde->end, cie,
-				fde, frame, pc, define_ra);
+				fde, frame, pc);
 
 	/* Calculate the CFA */
 	switch (frame->flags) {

commit 180aa6e6aa11922dcd4c13df1967d62bb2ede76c
Author: Matt Fleming <matt@console-pimps.org>
Date:   Sat Aug 15 00:04:00 2009 +0100

    sh: Set the cfa_offset to 0 if we see a DW_CFA_def_cfa_register op
    
    The way that the CFA is calculated can change as we progress through a
    function. If we see a DW_CFA_def_cfa_register op we need to reset the
    frame's cfa_offset value which may have been previously setup.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index db021361b161..c6c5764a8ab1 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -449,6 +449,7 @@ static int dwarf_cfa_execute_insns(unsigned char *insn_start,
 			count = dwarf_read_uleb128(current_insn,
 						   &frame->cfa_register);
 			current_insn += count;
+			frame->cfa_offset = 0;
 			frame->flags |= DWARF_FRAME_CFA_REG_OFFSET;
 			break;
 		case DW_CFA_def_cfa_offset:

commit 0fc11e3618bb1f9e0640127ec84f5d2690fa3894
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Fri Aug 14 23:58:37 2009 +0900

    sh: unwinder: Convert frame allocations to GFP_ATOMIC.
    
    save_stack_trace_tsk() and friends can be called from atomic context (as
    triggered by latencytop), and subsequently hit two problematic allocation
    points that were using GFP_KERNEL (these were dwarf_unwind_stack() and
    dwarf_frame_alloc_regs()). Convert these over to GFP_ATOMIC and get
    latencytop working with the DWARF unwinder.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 83f3cc92549f..db021361b161 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -57,7 +57,7 @@ static void dwarf_frame_alloc_regs(struct dwarf_frame *frame,
 	if (frame->num_regs >= num_regs)
 		return;
 
-	regs = kzalloc(new_size, GFP_KERNEL);
+	regs = kzalloc(new_size, GFP_ATOMIC);
 	if (!regs) {
 		printk(KERN_WARNING "Unable to allocate DWARF registers\n");
 		/*
@@ -531,7 +531,7 @@ struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
 		define_ra = true;
 	}
 
-	frame = kzalloc(sizeof(*frame), GFP_KERNEL);
+	frame = kzalloc(sizeof(*frame), GFP_ATOMIC);
 	if (!frame)
 		return NULL;
 

commit f826466772ae52f26152287fcb2259351de78f0f
Author: Matt Fleming <matt@console-pimps.org>
Date:   Thu Aug 13 20:41:31 2009 +0100

    sh: Delete DWARF_ARCH_UNWIND_OFFSET
    
    Trying to figure out the best value for DWARF_ARCH_UNWIND_OFFSET is
    tricky at best. Various things can change the size (and offset from the
    beginning of the function) of the prologue. Notably, turning on ftrace
    adds calls to mcount at the beginning of functions, thereby pushing the
    prologue further into the function.
    
    So replace DWARF_ARCH_UNWIND_OFFSET with some code that continues to
    execute CFA instructions until the value of return address register is
    defined. This is safe to do because we know that the return address must
    have been pushed onto the frame before our first function call; we just
    can't figure out where at compile-time.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 49d039f19426..83f3cc92549f 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -330,6 +330,7 @@ struct dwarf_fde *dwarf_lookup_fde(unsigned long pc)
  *	@fde: the FDE for this function
  *	@frame: the instructions calculate the CFA for this frame
  *	@pc: the program counter of the address we're interested in
+ *	@define_ra: keep executing insns until the return addr reg is defined?
  *
  *	Execute the Call Frame instruction sequence starting at
  *	@insn_start and ending at @insn_end. The instructions describe
@@ -341,17 +342,36 @@ static int dwarf_cfa_execute_insns(unsigned char *insn_start,
 				   struct dwarf_cie *cie,
 				   struct dwarf_fde *fde,
 				   struct dwarf_frame *frame,
-				   unsigned long pc)
+				   unsigned long pc,
+				   bool define_ra)
 {
 	unsigned char insn;
 	unsigned char *current_insn;
 	unsigned int count, delta, reg, expr_len, offset;
+	bool seen_ra_reg;
 
 	current_insn = insn_start;
 
-	while (current_insn < insn_end && frame->pc <= pc) {
+	/*
+	 * If we're executing instructions for the dwarf_unwind_stack()
+	 * FDE we need to keep executing instructions until the value of
+	 * DWARF_ARCH_RA_REG is defined. See the comment in
+	 * dwarf_unwind_stack() for more details.
+	 */
+	if (define_ra)
+		seen_ra_reg = false;
+	else
+		seen_ra_reg = true;
+
+	while (current_insn < insn_end && (frame->pc <= pc || !seen_ra_reg) ) {
 		insn = __raw_readb(current_insn++);
 
+		if (!seen_ra_reg) {
+			if (frame->num_regs >= DWARF_ARCH_RA_REG &&
+			    frame->regs[DWARF_ARCH_RA_REG].flags)
+				seen_ra_reg = true;
+		}
+
 		/*
 		 * Firstly, handle the opcodes that embed their operands
 		 * in the instructions.
@@ -490,20 +510,25 @@ struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
 	struct dwarf_fde *fde;
 	unsigned long addr;
 	int i, offset;
+	bool define_ra = false;
 
 	/*
 	 * If this is the first invocation of this recursive function we
 	 * need get the contents of a physical register to get the CFA
 	 * in order to begin the virtual unwinding of the stack.
 	 *
-	 * The constant DWARF_ARCH_UNWIND_OFFSET is added to the address of
-	 * this function because the return address register
-	 * (DWARF_ARCH_RA_REG) will probably not be initialised until a
-	 * few instructions into the prologue.
+	 * Setting "define_ra" to true indictates that we want
+	 * dwarf_cfa_execute_insns() to continue executing instructions
+	 * until we know how to calculate the value of DWARF_ARCH_RA_REG
+	 * (which we need in order to kick off the whole unwinding
+	 * process).
+	 *
+	 * NOTE: the return address is guaranteed to be setup by the
+	 * time this function makes its first function call.
 	 */
 	if (!pc && !prev) {
 		pc = (unsigned long)&dwarf_unwind_stack;
-		pc += DWARF_ARCH_UNWIND_OFFSET;
+		define_ra = true;
 	}
 
 	frame = kzalloc(sizeof(*frame), GFP_KERNEL);
@@ -539,11 +564,12 @@ struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
 
 	/* CIE initial instructions */
 	dwarf_cfa_execute_insns(cie->initial_instructions,
-				cie->instructions_end, cie, fde, frame, pc);
+				cie->instructions_end, cie, fde,
+				frame, pc, false);
 
 	/* FDE instructions */
 	dwarf_cfa_execute_insns(fde->instructions, fde->end, cie,
-				fde, frame, pc);
+				fde, frame, pc, define_ra);
 
 	/* Calculate the CFA */
 	switch (frame->flags) {

commit bf43a160ff2d67a21b076286bab6f5e2c993bd0a
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Fri Aug 14 03:06:13 2009 +0900

    sh: unwinder: Restore put_unaligned() for an unaligned destination.
    
    The destination address might be unaligned, so set it with
    put_unaligned() for safety. This restores the previous behaviour, albeit
    through the proper API.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index d1d8536e5ba3..49d039f19426 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -89,7 +89,8 @@ static void dwarf_frame_alloc_regs(struct dwarf_frame *frame,
  */
 static inline int dwarf_read_addr(unsigned long *src, unsigned long *dst)
 {
-	*dst = get_unaligned(src);
+	u32 val = get_unaligned(src);
+	put_unaligned(val, dst);
 	return sizeof(unsigned long *);
 }
 

commit 3497447f15485b479366ec86effaac16fc82411b
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Fri Aug 14 02:10:59 2009 +0900

    sh: unwinder: Fix up usage of unaligned accessors.
    
    This was using internal symbols for unaligned accesses, bypassing the
    exposed interface for variable sized safe accesses. This converts all of
    the __get_unaligned_cpuXX() users over to get_unaligned() directly,
    relying on the cast to select the proper internal routine.
    
    Additionally, the __put_unaligned_cpuXX() case is superfluous given that
    the destination address is aligned in all of the current cases, so just
    drop that outright.
    
    Furthermore, this switches to the asm/unaligned.h header instead of the
    asm-generic version, which was silently bypassing the SH-4A optimized
    unaligned ops.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
index 09c6fd7fd05f..d1d8536e5ba3 100644
--- a/arch/sh/kernel/dwarf.c
+++ b/arch/sh/kernel/dwarf.c
@@ -21,7 +21,7 @@
 #include <asm/dwarf.h>
 #include <asm/unwinder.h>
 #include <asm/sections.h>
-#include <asm-generic/unaligned.h>
+#include <asm/unaligned.h>
 #include <asm/dwarf.h>
 #include <asm/stacktrace.h>
 
@@ -87,11 +87,9 @@ static void dwarf_frame_alloc_regs(struct dwarf_frame *frame,
  *	from @src and writing to @dst, because they can be arbitrarily
  *	aligned. Return 'n' - the number of bytes read.
  */
-static inline int dwarf_read_addr(void *src, void *dst)
+static inline int dwarf_read_addr(unsigned long *src, unsigned long *dst)
 {
-	u32 val = __get_unaligned_cpu32(src);
-	__put_unaligned_cpu32(val, dst);
-
+	*dst = get_unaligned(src);
 	return sizeof(unsigned long *);
 }
 
@@ -207,7 +205,7 @@ static int dwarf_read_encoded_value(char *addr, unsigned long *val,
 	case DW_EH_PE_sdata4:
 	case DW_EH_PE_udata4:
 		count += 4;
-		decoded_addr += __get_unaligned_cpu32(addr);
+		decoded_addr += get_unaligned((u32 *)addr);
 		__raw_writel(decoded_addr, val);
 		break;
 	default:
@@ -232,7 +230,7 @@ static inline int dwarf_entry_len(char *addr, unsigned long *len)
 	u32 initial_len;
 	int count;
 
-	initial_len = __get_unaligned_cpu32(addr);
+	initial_len = get_unaligned((u32 *)addr);
 	count = 4;
 
 	/*
@@ -247,7 +245,7 @@ static inline int dwarf_entry_len(char *addr, unsigned long *len)
 		 * compulsory 32-bit length field.
 		 */
 		if (initial_len == DW_EXT_DWARF64) {
-			*len = __get_unaligned_cpu64(addr + 4);
+			*len = get_unaligned((u64 *)addr + 4);
 			count = 12;
 		} else {
 			printk(KERN_WARNING "Unknown DWARF extension\n");
@@ -392,12 +390,12 @@ static int dwarf_cfa_execute_insns(unsigned char *insn_start,
 			frame->pc += delta * cie->code_alignment_factor;
 			break;
 		case DW_CFA_advance_loc2:
-			delta = __get_unaligned_cpu16(current_insn);
+			delta = get_unaligned((u16 *)current_insn);
 			current_insn += 2;
 			frame->pc += delta * cie->code_alignment_factor;
 			break;
 		case DW_CFA_advance_loc4:
-			delta = __get_unaligned_cpu32(current_insn);
+			delta = get_unaligned((u32 *)current_insn);
 			current_insn += 4;
 			frame->pc += delta * cie->code_alignment_factor;
 			break;
@@ -841,7 +839,7 @@ void dwarf_unwinder_init(void)
 		/* initial length does not include itself */
 		end = p + len;
 
-		entry_type = __get_unaligned_cpu32(p);
+		entry_type = get_unaligned((u32 *)p);
 		p += 4;
 
 		if (entry_type == DW_EH_FRAME_CIE) {

commit bd353861c735b2265c9d8b2559960c693e7c68ab
Author: Matt Fleming <matt@console-pimps.org>
Date:   Fri Aug 14 01:58:43 2009 +0900

    sh: dwarf unwinder support.
    
    This is a first cut at a generic DWARF unwinder for the kernel. It's
    still lacking DWARF64 support and the DWARF expression support hasn't
    been tested very well but it is generating proper stacktraces on SH for
    WARN_ON() and NULL dereferences.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c
new file mode 100644
index 000000000000..09c6fd7fd05f
--- /dev/null
+++ b/arch/sh/kernel/dwarf.c
@@ -0,0 +1,876 @@
+/*
+ * Copyright (C) 2009 Matt Fleming <matt@console-pimps.org>
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * This is an implementation of a DWARF unwinder. Its main purpose is
+ * for generating stacktrace information. Based on the DWARF 3
+ * specification from http://www.dwarfstd.org.
+ *
+ * TODO:
+ *	- DWARF64 doesn't work.
+ */
+
+/* #define DEBUG */
+#include <linux/kernel.h>
+#include <linux/io.h>
+#include <linux/list.h>
+#include <linux/mm.h>
+#include <asm/dwarf.h>
+#include <asm/unwinder.h>
+#include <asm/sections.h>
+#include <asm-generic/unaligned.h>
+#include <asm/dwarf.h>
+#include <asm/stacktrace.h>
+
+static LIST_HEAD(dwarf_cie_list);
+DEFINE_SPINLOCK(dwarf_cie_lock);
+
+static LIST_HEAD(dwarf_fde_list);
+DEFINE_SPINLOCK(dwarf_fde_lock);
+
+static struct dwarf_cie *cached_cie;
+
+/*
+ * Figure out whether we need to allocate some dwarf registers. If dwarf
+ * registers have already been allocated then we may need to realloc
+ * them. "reg" is a register number that we need to be able to access
+ * after this call.
+ *
+ * Register numbers start at zero, therefore we need to allocate space
+ * for "reg" + 1 registers.
+ */
+static void dwarf_frame_alloc_regs(struct dwarf_frame *frame,
+				   unsigned int reg)
+{
+	struct dwarf_reg *regs;
+	unsigned int num_regs = reg + 1;
+	size_t new_size;
+	size_t old_size;
+
+	new_size = num_regs * sizeof(*regs);
+	old_size = frame->num_regs * sizeof(*regs);
+
+	/* Fast path: don't allocate any regs if we've already got enough. */
+	if (frame->num_regs >= num_regs)
+		return;
+
+	regs = kzalloc(new_size, GFP_KERNEL);
+	if (!regs) {
+		printk(KERN_WARNING "Unable to allocate DWARF registers\n");
+		/*
+		 * Let's just bomb hard here, we have no way to
+		 * gracefully recover.
+		 */
+		BUG();
+	}
+
+	if (frame->regs) {
+		memcpy(regs, frame->regs, old_size);
+		kfree(frame->regs);
+	}
+
+	frame->regs = regs;
+	frame->num_regs = num_regs;
+}
+
+/**
+ *	dwarf_read_addr - read dwarf data
+ *	@src: source address of data
+ *	@dst: destination address to store the data to
+ *
+ *	Read 'n' bytes from @src, where 'n' is the size of an address on
+ *	the native machine. We return the number of bytes read, which
+ *	should always be 'n'. We also have to be careful when reading
+ *	from @src and writing to @dst, because they can be arbitrarily
+ *	aligned. Return 'n' - the number of bytes read.
+ */
+static inline int dwarf_read_addr(void *src, void *dst)
+{
+	u32 val = __get_unaligned_cpu32(src);
+	__put_unaligned_cpu32(val, dst);
+
+	return sizeof(unsigned long *);
+}
+
+/**
+ *	dwarf_read_uleb128 - read unsigned LEB128 data
+ *	@addr: the address where the ULEB128 data is stored
+ *	@ret: address to store the result
+ *
+ *	Decode an unsigned LEB128 encoded datum. The algorithm is taken
+ *	from Appendix C of the DWARF 3 spec. For information on the
+ *	encodings refer to section "7.6 - Variable Length Data". Return
+ *	the number of bytes read.
+ */
+static inline unsigned long dwarf_read_uleb128(char *addr, unsigned int *ret)
+{
+	unsigned int result;
+	unsigned char byte;
+	int shift, count;
+
+	result = 0;
+	shift = 0;
+	count = 0;
+
+	while (1) {
+		byte = __raw_readb(addr);
+		addr++;
+		count++;
+
+		result |= (byte & 0x7f) << shift;
+		shift += 7;
+
+		if (!(byte & 0x80))
+			break;
+	}
+
+	*ret = result;
+
+	return count;
+}
+
+/**
+ *	dwarf_read_leb128 - read signed LEB128 data
+ *	@addr: the address of the LEB128 encoded data
+ *	@ret: address to store the result
+ *
+ *	Decode signed LEB128 data. The algorithm is taken from Appendix
+ *	C of the DWARF 3 spec. Return the number of bytes read.
+ */
+static inline unsigned long dwarf_read_leb128(char *addr, int *ret)
+{
+	unsigned char byte;
+	int result, shift;
+	int num_bits;
+	int count;
+
+	result = 0;
+	shift = 0;
+	count = 0;
+
+	while (1) {
+		byte = __raw_readb(addr);
+		addr++;
+		result |= (byte & 0x7f) << shift;
+		shift += 7;
+		count++;
+
+		if (!(byte & 0x80))
+			break;
+	}
+
+	/* The number of bits in a signed integer. */
+	num_bits = 8 * sizeof(result);
+
+	if ((shift < num_bits) && (byte & 0x40))
+		result |= (-1 << shift);
+
+	*ret = result;
+
+	return count;
+}
+
+/**
+ *	dwarf_read_encoded_value - return the decoded value at @addr
+ *	@addr: the address of the encoded value
+ *	@val: where to write the decoded value
+ *	@encoding: the encoding with which we can decode @addr
+ *
+ *	GCC emits encoded address in the .eh_frame FDE entries. Decode
+ *	the value at @addr using @encoding. The decoded value is written
+ *	to @val and the number of bytes read is returned.
+ */
+static int dwarf_read_encoded_value(char *addr, unsigned long *val,
+				    char encoding)
+{
+	unsigned long decoded_addr = 0;
+	int count = 0;
+
+	switch (encoding & 0x70) {
+	case DW_EH_PE_absptr:
+		break;
+	case DW_EH_PE_pcrel:
+		decoded_addr = (unsigned long)addr;
+		break;
+	default:
+		pr_debug("encoding=0x%x\n", (encoding & 0x70));
+		BUG();
+	}
+
+	if ((encoding & 0x07) == 0x00)
+		encoding |= DW_EH_PE_udata4;
+
+	switch (encoding & 0x0f) {
+	case DW_EH_PE_sdata4:
+	case DW_EH_PE_udata4:
+		count += 4;
+		decoded_addr += __get_unaligned_cpu32(addr);
+		__raw_writel(decoded_addr, val);
+		break;
+	default:
+		pr_debug("encoding=0x%x\n", encoding);
+		BUG();
+	}
+
+	return count;
+}
+
+/**
+ *	dwarf_entry_len - return the length of an FDE or CIE
+ *	@addr: the address of the entry
+ *	@len: the length of the entry
+ *
+ *	Read the initial_length field of the entry and store the size of
+ *	the entry in @len. We return the number of bytes read. Return a
+ *	count of 0 on error.
+ */
+static inline int dwarf_entry_len(char *addr, unsigned long *len)
+{
+	u32 initial_len;
+	int count;
+
+	initial_len = __get_unaligned_cpu32(addr);
+	count = 4;
+
+	/*
+	 * An initial length field value in the range DW_LEN_EXT_LO -
+	 * DW_LEN_EXT_HI indicates an extension, and should not be
+	 * interpreted as a length. The only extension that we currently
+	 * understand is the use of DWARF64 addresses.
+	 */
+	if (initial_len >= DW_EXT_LO && initial_len <= DW_EXT_HI) {
+		/*
+		 * The 64-bit length field immediately follows the
+		 * compulsory 32-bit length field.
+		 */
+		if (initial_len == DW_EXT_DWARF64) {
+			*len = __get_unaligned_cpu64(addr + 4);
+			count = 12;
+		} else {
+			printk(KERN_WARNING "Unknown DWARF extension\n");
+			count = 0;
+		}
+	} else
+		*len = initial_len;
+
+	return count;
+}
+
+/**
+ *	dwarf_lookup_cie - locate the cie
+ *	@cie_ptr: pointer to help with lookup
+ */
+static struct dwarf_cie *dwarf_lookup_cie(unsigned long cie_ptr)
+{
+	struct dwarf_cie *cie, *n;
+	unsigned long flags;
+
+	spin_lock_irqsave(&dwarf_cie_lock, flags);
+
+	/*
+	 * We've cached the last CIE we looked up because chances are
+	 * that the FDE wants this CIE.
+	 */
+	if (cached_cie && cached_cie->cie_pointer == cie_ptr) {
+		cie = cached_cie;
+		goto out;
+	}
+
+	list_for_each_entry_safe(cie, n, &dwarf_cie_list, link) {
+		if (cie->cie_pointer == cie_ptr) {
+			cached_cie = cie;
+			break;
+		}
+	}
+
+	/* Couldn't find the entry in the list. */
+	if (&cie->link == &dwarf_cie_list)
+		cie = NULL;
+out:
+	spin_unlock_irqrestore(&dwarf_cie_lock, flags);
+	return cie;
+}
+
+/**
+ *	dwarf_lookup_fde - locate the FDE that covers pc
+ *	@pc: the program counter
+ */
+struct dwarf_fde *dwarf_lookup_fde(unsigned long pc)
+{
+	unsigned long flags;
+	struct dwarf_fde *fde, *n;
+
+	spin_lock_irqsave(&dwarf_fde_lock, flags);
+	list_for_each_entry_safe(fde, n, &dwarf_fde_list, link) {
+		unsigned long start, end;
+
+		start = fde->initial_location;
+		end = fde->initial_location + fde->address_range;
+
+		if (pc >= start && pc < end)
+			break;
+	}
+
+	/* Couldn't find the entry in the list. */
+	if (&fde->link == &dwarf_fde_list)
+		fde = NULL;
+
+	spin_unlock_irqrestore(&dwarf_fde_lock, flags);
+
+	return fde;
+}
+
+/**
+ *	dwarf_cfa_execute_insns - execute instructions to calculate a CFA
+ *	@insn_start: address of the first instruction
+ *	@insn_end: address of the last instruction
+ *	@cie: the CIE for this function
+ *	@fde: the FDE for this function
+ *	@frame: the instructions calculate the CFA for this frame
+ *	@pc: the program counter of the address we're interested in
+ *
+ *	Execute the Call Frame instruction sequence starting at
+ *	@insn_start and ending at @insn_end. The instructions describe
+ *	how to calculate the Canonical Frame Address of a stackframe.
+ *	Store the results in @frame.
+ */
+static int dwarf_cfa_execute_insns(unsigned char *insn_start,
+				   unsigned char *insn_end,
+				   struct dwarf_cie *cie,
+				   struct dwarf_fde *fde,
+				   struct dwarf_frame *frame,
+				   unsigned long pc)
+{
+	unsigned char insn;
+	unsigned char *current_insn;
+	unsigned int count, delta, reg, expr_len, offset;
+
+	current_insn = insn_start;
+
+	while (current_insn < insn_end && frame->pc <= pc) {
+		insn = __raw_readb(current_insn++);
+
+		/*
+		 * Firstly, handle the opcodes that embed their operands
+		 * in the instructions.
+		 */
+		switch (DW_CFA_opcode(insn)) {
+		case DW_CFA_advance_loc:
+			delta = DW_CFA_operand(insn);
+			delta *= cie->code_alignment_factor;
+			frame->pc += delta;
+			continue;
+			/* NOTREACHED */
+		case DW_CFA_offset:
+			reg = DW_CFA_operand(insn);
+			count = dwarf_read_uleb128(current_insn, &offset);
+			current_insn += count;
+			offset *= cie->data_alignment_factor;
+			dwarf_frame_alloc_regs(frame, reg);
+			frame->regs[reg].addr = offset;
+			frame->regs[reg].flags |= DWARF_REG_OFFSET;
+			continue;
+			/* NOTREACHED */
+		case DW_CFA_restore:
+			reg = DW_CFA_operand(insn);
+			continue;
+			/* NOTREACHED */
+		}
+
+		/*
+		 * Secondly, handle the opcodes that don't embed their
+		 * operands in the instruction.
+		 */
+		switch (insn) {
+		case DW_CFA_nop:
+			continue;
+		case DW_CFA_advance_loc1:
+			delta = *current_insn++;
+			frame->pc += delta * cie->code_alignment_factor;
+			break;
+		case DW_CFA_advance_loc2:
+			delta = __get_unaligned_cpu16(current_insn);
+			current_insn += 2;
+			frame->pc += delta * cie->code_alignment_factor;
+			break;
+		case DW_CFA_advance_loc4:
+			delta = __get_unaligned_cpu32(current_insn);
+			current_insn += 4;
+			frame->pc += delta * cie->code_alignment_factor;
+			break;
+		case DW_CFA_offset_extended:
+			count = dwarf_read_uleb128(current_insn, &reg);
+			current_insn += count;
+			count = dwarf_read_uleb128(current_insn, &offset);
+			current_insn += count;
+			offset *= cie->data_alignment_factor;
+			break;
+		case DW_CFA_restore_extended:
+			count = dwarf_read_uleb128(current_insn, &reg);
+			current_insn += count;
+			break;
+		case DW_CFA_undefined:
+			count = dwarf_read_uleb128(current_insn, &reg);
+			current_insn += count;
+			break;
+		case DW_CFA_def_cfa:
+			count = dwarf_read_uleb128(current_insn,
+						   &frame->cfa_register);
+			current_insn += count;
+			count = dwarf_read_uleb128(current_insn,
+						   &frame->cfa_offset);
+			current_insn += count;
+
+			frame->flags |= DWARF_FRAME_CFA_REG_OFFSET;
+			break;
+		case DW_CFA_def_cfa_register:
+			count = dwarf_read_uleb128(current_insn,
+						   &frame->cfa_register);
+			current_insn += count;
+			frame->flags |= DWARF_FRAME_CFA_REG_OFFSET;
+			break;
+		case DW_CFA_def_cfa_offset:
+			count = dwarf_read_uleb128(current_insn, &offset);
+			current_insn += count;
+			frame->cfa_offset = offset;
+			break;
+		case DW_CFA_def_cfa_expression:
+			count = dwarf_read_uleb128(current_insn, &expr_len);
+			current_insn += count;
+
+			frame->cfa_expr = current_insn;
+			frame->cfa_expr_len = expr_len;
+			current_insn += expr_len;
+
+			frame->flags |= DWARF_FRAME_CFA_REG_EXP;
+			break;
+		case DW_CFA_offset_extended_sf:
+			count = dwarf_read_uleb128(current_insn, &reg);
+			current_insn += count;
+			count = dwarf_read_leb128(current_insn, &offset);
+			current_insn += count;
+			offset *= cie->data_alignment_factor;
+			dwarf_frame_alloc_regs(frame, reg);
+			frame->regs[reg].flags |= DWARF_REG_OFFSET;
+			frame->regs[reg].addr = offset;
+			break;
+		case DW_CFA_val_offset:
+			count = dwarf_read_uleb128(current_insn, &reg);
+			current_insn += count;
+			count = dwarf_read_leb128(current_insn, &offset);
+			offset *= cie->data_alignment_factor;
+			frame->regs[reg].flags |= DWARF_REG_OFFSET;
+			frame->regs[reg].addr = offset;
+			break;
+		default:
+			pr_debug("unhandled DWARF instruction 0x%x\n", insn);
+			break;
+		}
+	}
+
+	return 0;
+}
+
+/**
+ *	dwarf_unwind_stack - recursively unwind the stack
+ *	@pc: address of the function to unwind
+ *	@prev: struct dwarf_frame of the previous stackframe on the callstack
+ *
+ *	Return a struct dwarf_frame representing the most recent frame
+ *	on the callstack. Each of the lower (older) stack frames are
+ *	linked via the "prev" member.
+ */
+struct dwarf_frame *dwarf_unwind_stack(unsigned long pc,
+				       struct dwarf_frame *prev)
+{
+	struct dwarf_frame *frame;
+	struct dwarf_cie *cie;
+	struct dwarf_fde *fde;
+	unsigned long addr;
+	int i, offset;
+
+	/*
+	 * If this is the first invocation of this recursive function we
+	 * need get the contents of a physical register to get the CFA
+	 * in order to begin the virtual unwinding of the stack.
+	 *
+	 * The constant DWARF_ARCH_UNWIND_OFFSET is added to the address of
+	 * this function because the return address register
+	 * (DWARF_ARCH_RA_REG) will probably not be initialised until a
+	 * few instructions into the prologue.
+	 */
+	if (!pc && !prev) {
+		pc = (unsigned long)&dwarf_unwind_stack;
+		pc += DWARF_ARCH_UNWIND_OFFSET;
+	}
+
+	frame = kzalloc(sizeof(*frame), GFP_KERNEL);
+	if (!frame)
+		return NULL;
+
+	frame->prev = prev;
+
+	fde = dwarf_lookup_fde(pc);
+	if (!fde) {
+		/*
+		 * This is our normal exit path - the one that stops the
+		 * recursion. There's two reasons why we might exit
+		 * here,
+		 *
+		 *	a) pc has no asscociated DWARF frame info and so
+		 *	we don't know how to unwind this frame. This is
+		 *	usually the case when we're trying to unwind a
+		 *	frame that was called from some assembly code
+		 *	that has no DWARF info, e.g. syscalls.
+		 *
+		 *	b) the DEBUG info for pc is bogus. There's
+		 *	really no way to distinguish this case from the
+		 *	case above, which sucks because we could print a
+		 *	warning here.
+		 */
+		return NULL;
+	}
+
+	cie = dwarf_lookup_cie(fde->cie_pointer);
+
+	frame->pc = fde->initial_location;
+
+	/* CIE initial instructions */
+	dwarf_cfa_execute_insns(cie->initial_instructions,
+				cie->instructions_end, cie, fde, frame, pc);
+
+	/* FDE instructions */
+	dwarf_cfa_execute_insns(fde->instructions, fde->end, cie,
+				fde, frame, pc);
+
+	/* Calculate the CFA */
+	switch (frame->flags) {
+	case DWARF_FRAME_CFA_REG_OFFSET:
+		if (prev) {
+			BUG_ON(!prev->regs[frame->cfa_register].flags);
+
+			addr = prev->cfa;
+			addr += prev->regs[frame->cfa_register].addr;
+			frame->cfa = __raw_readl(addr);
+
+		} else {
+			/*
+			 * Again, this is the first invocation of this
+			 * recurisve function. We need to physically
+			 * read the contents of a register in order to
+			 * get the Canonical Frame Address for this
+			 * function.
+			 */
+			frame->cfa = dwarf_read_arch_reg(frame->cfa_register);
+		}
+
+		frame->cfa += frame->cfa_offset;
+		break;
+	default:
+		BUG();
+	}
+
+	/* If we haven't seen the return address reg, we're screwed. */
+	BUG_ON(!frame->regs[DWARF_ARCH_RA_REG].flags);
+
+	for (i = 0; i <= frame->num_regs; i++) {
+		struct dwarf_reg *reg = &frame->regs[i];
+
+		if (!reg->flags)
+			continue;
+
+		offset = reg->addr;
+		offset += frame->cfa;
+	}
+
+	addr = frame->cfa + frame->regs[DWARF_ARCH_RA_REG].addr;
+	frame->return_addr = __raw_readl(addr);
+
+	frame->next = dwarf_unwind_stack(frame->return_addr, frame);
+	return frame;
+}
+
+static int dwarf_parse_cie(void *entry, void *p, unsigned long len,
+			   unsigned char *end)
+{
+	struct dwarf_cie *cie;
+	unsigned long flags;
+	int count;
+
+	cie = kzalloc(sizeof(*cie), GFP_KERNEL);
+	if (!cie)
+		return -ENOMEM;
+
+	cie->length = len;
+
+	/*
+	 * Record the offset into the .eh_frame section
+	 * for this CIE. It allows this CIE to be
+	 * quickly and easily looked up from the
+	 * corresponding FDE.
+	 */
+	cie->cie_pointer = (unsigned long)entry;
+
+	cie->version = *(char *)p++;
+	BUG_ON(cie->version != 1);
+
+	cie->augmentation = p;
+	p += strlen(cie->augmentation) + 1;
+
+	count = dwarf_read_uleb128(p, &cie->code_alignment_factor);
+	p += count;
+
+	count = dwarf_read_leb128(p, &cie->data_alignment_factor);
+	p += count;
+
+	/*
+	 * Which column in the rule table contains the
+	 * return address?
+	 */
+	if (cie->version == 1) {
+		cie->return_address_reg = __raw_readb(p);
+		p++;
+	} else {
+		count = dwarf_read_uleb128(p, &cie->return_address_reg);
+		p += count;
+	}
+
+	if (cie->augmentation[0] == 'z') {
+		unsigned int length, count;
+		cie->flags |= DWARF_CIE_Z_AUGMENTATION;
+
+		count = dwarf_read_uleb128(p, &length);
+		p += count;
+
+		BUG_ON((unsigned char *)p > end);
+
+		cie->initial_instructions = p + length;
+		cie->augmentation++;
+	}
+
+	while (*cie->augmentation) {
+		/*
+		 * "L" indicates a byte showing how the
+		 * LSDA pointer is encoded. Skip it.
+		 */
+		if (*cie->augmentation == 'L') {
+			p++;
+			cie->augmentation++;
+		} else if (*cie->augmentation == 'R') {
+			/*
+			 * "R" indicates a byte showing
+			 * how FDE addresses are
+			 * encoded.
+			 */
+			cie->encoding = *(char *)p++;
+			cie->augmentation++;
+		} else if (*cie->augmentation == 'P') {
+			/*
+			 * "R" indicates a personality
+			 * routine in the CIE
+			 * augmentation.
+			 */
+			BUG();
+		} else if (*cie->augmentation == 'S') {
+			BUG();
+		} else {
+			/*
+			 * Unknown augmentation. Assume
+			 * 'z' augmentation.
+			 */
+			p = cie->initial_instructions;
+			BUG_ON(!p);
+			break;
+		}
+	}
+
+	cie->initial_instructions = p;
+	cie->instructions_end = end;
+
+	/* Add to list */
+	spin_lock_irqsave(&dwarf_cie_lock, flags);
+	list_add_tail(&cie->link, &dwarf_cie_list);
+	spin_unlock_irqrestore(&dwarf_cie_lock, flags);
+
+	return 0;
+}
+
+static int dwarf_parse_fde(void *entry, u32 entry_type,
+			   void *start, unsigned long len)
+{
+	struct dwarf_fde *fde;
+	struct dwarf_cie *cie;
+	unsigned long flags;
+	int count;
+	void *p = start;
+
+	fde = kzalloc(sizeof(*fde), GFP_KERNEL);
+	if (!fde)
+		return -ENOMEM;
+
+	fde->length = len;
+
+	/*
+	 * In a .eh_frame section the CIE pointer is the
+	 * delta between the address within the FDE
+	 */
+	fde->cie_pointer = (unsigned long)(p - entry_type - 4);
+
+	cie = dwarf_lookup_cie(fde->cie_pointer);
+	fde->cie = cie;
+
+	if (cie->encoding)
+		count = dwarf_read_encoded_value(p, &fde->initial_location,
+						 cie->encoding);
+	else
+		count = dwarf_read_addr(p, &fde->initial_location);
+
+	p += count;
+
+	if (cie->encoding)
+		count = dwarf_read_encoded_value(p, &fde->address_range,
+						 cie->encoding & 0x0f);
+	else
+		count = dwarf_read_addr(p, &fde->address_range);
+
+	p += count;
+
+	if (fde->cie->flags & DWARF_CIE_Z_AUGMENTATION) {
+		unsigned int length;
+		count = dwarf_read_uleb128(p, &length);
+		p += count + length;
+	}
+
+	/* Call frame instructions. */
+	fde->instructions = p;
+	fde->end = start + len;
+
+	/* Add to list. */
+	spin_lock_irqsave(&dwarf_fde_lock, flags);
+	list_add_tail(&fde->link, &dwarf_fde_list);
+	spin_unlock_irqrestore(&dwarf_fde_lock, flags);
+
+	return 0;
+}
+
+static void dwarf_unwinder_dump(struct task_struct *task, struct pt_regs *regs,
+				unsigned long *sp,
+				const struct stacktrace_ops *ops, void *data)
+{
+	struct dwarf_frame *frame;
+
+	frame = dwarf_unwind_stack(0, NULL);
+
+	while (frame && frame->return_addr) {
+		ops->address(data, frame->return_addr, 1);
+		frame = frame->next;
+	}
+}
+
+static struct unwinder dwarf_unwinder = {
+	.name = "dwarf-unwinder",
+	.dump = dwarf_unwinder_dump,
+	.rating = 150,
+};
+
+static void dwarf_unwinder_cleanup(void)
+{
+	struct dwarf_cie *cie, *m;
+	struct dwarf_fde *fde, *n;
+	unsigned long flags;
+
+	/*
+	 * Deallocate all the memory allocated for the DWARF unwinder.
+	 * Traverse all the FDE/CIE lists and remove and free all the
+	 * memory associated with those data structures.
+	 */
+	spin_lock_irqsave(&dwarf_cie_lock, flags);
+	list_for_each_entry_safe(cie, m, &dwarf_cie_list, link)
+		kfree(cie);
+	spin_unlock_irqrestore(&dwarf_cie_lock, flags);
+
+	spin_lock_irqsave(&dwarf_fde_lock, flags);
+	list_for_each_entry_safe(fde, n, &dwarf_fde_list, link)
+		kfree(fde);
+	spin_unlock_irqrestore(&dwarf_fde_lock, flags);
+}
+
+/**
+ *	dwarf_unwinder_init - initialise the dwarf unwinder
+ *
+ *	Build the data structures describing the .dwarf_frame section to
+ *	make it easier to lookup CIE and FDE entries. Because the
+ *	.eh_frame section is packed as tightly as possible it is not
+ *	easy to lookup the FDE for a given PC, so we build a list of FDE
+ *	and CIE entries that make it easier.
+ */
+void dwarf_unwinder_init(void)
+{
+	u32 entry_type;
+	void *p, *entry;
+	int count, err;
+	unsigned long len;
+	unsigned int c_entries, f_entries;
+	unsigned char *end;
+	INIT_LIST_HEAD(&dwarf_cie_list);
+	INIT_LIST_HEAD(&dwarf_fde_list);
+
+	c_entries = 0;
+	f_entries = 0;
+	entry = &__start_eh_frame;
+
+	while ((char *)entry < __stop_eh_frame) {
+		p = entry;
+
+		count = dwarf_entry_len(p, &len);
+		if (count == 0) {
+			/*
+			 * We read a bogus length field value. There is
+			 * nothing we can do here apart from disabling
+			 * the DWARF unwinder. We can't even skip this
+			 * entry and move to the next one because 'len'
+			 * tells us where our next entry is.
+			 */
+			goto out;
+		} else
+			p += count;
+
+		/* initial length does not include itself */
+		end = p + len;
+
+		entry_type = __get_unaligned_cpu32(p);
+		p += 4;
+
+		if (entry_type == DW_EH_FRAME_CIE) {
+			err = dwarf_parse_cie(entry, p, len, end);
+			if (err < 0)
+				goto out;
+			else
+				c_entries++;
+		} else {
+			err = dwarf_parse_fde(entry, entry_type, p, len);
+			if (err < 0)
+				goto out;
+			else
+				f_entries++;
+		}
+
+		entry = (char *)entry + len + 4;
+	}
+
+	printk(KERN_INFO "DWARF unwinder initialised: read %u CIEs, %u FDEs\n",
+	       c_entries, f_entries);
+
+	err = unwinder_register(&dwarf_unwinder);
+	if (err)
+		goto out;
+
+	return;
+
+out:
+	printk(KERN_ERR "Failed to initialise DWARF unwinder: %d\n", err);
+	dwarf_unwinder_cleanup();
+}
