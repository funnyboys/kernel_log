commit 37744feebc086908fd89760650f458ab19071750
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon Apr 20 11:37:12 2020 +0200

    sh: remove sh5 support
    
    sh5 never became a product and has probably never really worked.
    
    Remove it by recursively deleting all associated Kconfig options
    and all corresponding files.
    
    Reviewed-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Rich Felker <dalias@libc.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index ce7291e12a30..1d008745877f 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -103,7 +103,7 @@ void __attribute__ ((weak)) l2_cache_init(void)
 /*
  * Generic first-level cache init
  */
-#if defined(CONFIG_SUPERH32) && !defined(CONFIG_CPU_J2)
+#if !defined(CONFIG_CPU_J2)
 static void cache_init(void)
 {
 	unsigned long ccr, flags;

commit b0a148f80c1526951d6d196ded1d0c93158c2e25
Author: Kuninori Morimoto <kuninori.morimoto.gx@renesas.com>
Date:   Fri Dec 28 00:32:21 2018 -0800

    sh: cpu: convert to SPDX identifiers
    
    Update license to use SPDX-License-Identifier instead of verbose license
    text.
    
    Link: http://lkml.kernel.org/r/874lbscswy.wl-kuninori.morimoto.gx@renesas.com
    Signed-off-by: Kuninori Morimoto <kuninori.morimoto.gx@renesas.com>
    Reviewed-by: Simon Horman <horms+renesas@verge.net.au>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index c4f01c5c8736..ce7291e12a30 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * arch/sh/kernel/cpu/init.c
  *
@@ -5,10 +6,6 @@
  *
  * Copyright (C) 2002 - 2009  Paul Mundt
  * Copyright (C) 2003  Richard Curnow
- *
- * This file is subject to the terms and conditions of the GNU General Public
- * License.  See the file "COPYING" in the main directory of this archive
- * for more details.
  */
 #include <linux/init.h>
 #include <linux/kernel.h>

commit 7c0f6ba682b9c7632072ffbedf8d328c8f3c42ba
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Dec 24 11:46:01 2016 -0800

    Replace <asm/uaccess.h> with <linux/uaccess.h> globally
    
    This was entirely automated, using the script by Al:
    
      PATT='^[[:blank:]]*#[[:blank:]]*include[[:blank:]]*<asm/uaccess.h>'
      sed -i -e "s!$PATT!#include <linux/uaccess.h>!" \
            $(git grep -l "$PATT"|grep -v ^include/linux/uaccess.h)
    
    to do the replacement at the end of the merge window.
    
    Requested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index c8b3be1b54e6..c4f01c5c8736 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -16,7 +16,7 @@
 #include <linux/log2.h>
 #include <asm/mmu_context.h>
 #include <asm/processor.h>
-#include <asm/uaccess.h>
+#include <linux/uaccess.h>
 #include <asm/page.h>
 #include <asm/cacheflush.h>
 #include <asm/cache.h>

commit 5a846abad07f6f30adfa3e46c5c7a47d2e7b1e63
Author: Rich Felker <dalias@libc.org>
Date:   Thu Mar 17 23:09:37 2016 +0000

    sh: add support for J-Core J2 processor
    
    At the CPU/ISA level, the J2 is compatible with SH-2, and thus the
    changes to add J2 support build on existing SH-2 support. However, J2
    does not duplicate the memory-mapped SH-2 features like the cache
    interface. Instead, the cache interfaces is described in the device
    tree, and new code is added to be able to access the flat device tree
    at early boot before it is unflattened.
    
    Support is also added for receiving interrupts on trap numbers in the
    range 16 to 31, since the J-Core aic1 interrupt controller generates
    these traps. This range was unused but nominally for hardware
    exceptions on SH-2, and a few values in this range were used for
    exceptions on SH-2A, but SH-2A has its own version of the relevant
    code.
    
    No individual cpu subtypes are added for J2 since the intent moving
    forward is to represent SoCs with device tree rather than as
    hard-coded subtypes in the kernel. The CPU_SUBTYPE_J2 Kconfig item
    exists only to fit into the existing cpu selection mechanism until it
    is overhauled.
    
    Signed-off-by: Rich Felker <dalias@libc.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index bfd9e2798008..c8b3be1b54e6 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -106,7 +106,7 @@ void __attribute__ ((weak)) l2_cache_init(void)
 /*
  * Generic first-level cache init
  */
-#ifdef CONFIG_SUPERH32
+#if defined(CONFIG_SUPERH32) && !defined(CONFIG_CPU_J2)
 static void cache_init(void)
 {
 	unsigned long ccr, flags;

commit 57155c6523074dd937b8feafcfaa98c82218faa6
Author: Rich Felker <dalias@libc.org>
Date:   Tue Mar 22 22:02:23 2016 +0000

    sh: disable aliased page logic on NOMMU models
    
    SH3/4 (with MMU) have a virtually indexed cache, requiring explicit
    work to avoid consistency problems arising from having the same
    physical address range cached in multiple cache lines. This is
    unneeded for the NOMMU case, and some of the resulting code paths
    (kmap_coherent) don't work. SH2 only avoided this problem by having a
    4-way associative cache with way size equal to the page size (4k),
    yielding no cache index bits outside of the page offset and thus no
    aliases.
    
    Signed-off-by: Rich Felker <dalias@libc.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 0d7360d549c1..bfd9e2798008 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -323,9 +323,13 @@ asmlinkage void cpu_init(void)
 	cache_init();
 
 	if (raw_smp_processor_id() == 0) {
+#ifdef CONFIG_MMU
 		shm_align_mask = max_t(unsigned long,
 				       current_cpu_data.dcache.way_size - 1,
 				       PAGE_SIZE - 1);
+#else
+		shm_align_mask = PAGE_SIZE - 1;
+#endif
 
 		/* Boot CPU sets the cache shape */
 		detect_cache_shape();

commit a5f6ea29f9a918403629f8369ae55fac6b09cb53
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Mon Mar 3 15:38:33 2014 -0800

    sh: prefix sh-specific "CCR" and "CCR2" by "SH_"
    
    Commit bcf24e1daa94 ("mmc: omap_hsmmc: use the generic config for
    omap2plus devices"), enabled the build for other platforms for compile
    testing.
    
    sh-allmodconfig now fails with:
    
        include/linux/omap-dma.h:171:8: error: expected identifier before numeric constant
        make[4]: *** [drivers/mmc/host/omap_hsmmc.o] Error 1
    
    This happens because SuperH #defines "CCR", which is one of the enum
    values in include/linux/omap-dma.h.  There's a similar issue with "CCR2"
    on sh2a.
    
    As "CCR" and "CCR2" are too generic names for global #defines, prefix
    them with "SH_" to fix this.
    
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index ecf83cd158dc..0d7360d549c1 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -112,7 +112,7 @@ static void cache_init(void)
 	unsigned long ccr, flags;
 
 	jump_to_uncached();
-	ccr = __raw_readl(CCR);
+	ccr = __raw_readl(SH_CCR);
 
 	/*
 	 * At this point we don't know whether the cache is enabled or not - a
@@ -189,7 +189,7 @@ static void cache_init(void)
 
 	l2_cache_init();
 
-	__raw_writel(flags, CCR);
+	__raw_writel(flags, SH_CCR);
 	back_to_cached();
 }
 #else

commit 4603f53a1dc3c76dfba841d123db9fa6204934f5
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Tue Jun 18 17:10:12 2013 -0400

    sh: delete __cpuinit usage from all sh files
    
    The __cpuinit type of throwaway sections might have made sense
    some time ago when RAM was more constrained, but now the savings
    do not offset the cost and complications.  For example, the fix in
    commit 5e427ec2d0 ("x86: Fix bit corruption at CPU resume time")
    is a good example of the nasty type of bugs that can be created
    with improper use of the various __init prefixes.
    
    After a discussion on LKML[1] it was decided that cpuinit should go
    the way of devinit and be phased out.  Once all the users are gone,
    we can then finally remove the macros themselves from linux/init.h.
    
    Note that some harmless section mismatch warnings may result, since
    notify_cpu_starting() and cpu_up() are arch independent (kernel/cpu.c)
    are flagged as __cpuinit  -- so if we remove the __cpuinit from
    arch specific callers, we will also get section mismatch warnings.
    As an intermediate step, we intend to turn the linux/init.h cpuinit
    content into no-ops as early as possible, since that will get rid
    of these warnings.  In any case, they are temporary and harmless.
    
    This removes all the arch/sh uses of the __cpuinit macros from
    all C files.  Currently sh does not have any __CPUINIT used in
    assembly files.
    
    [1] https://lkml.org/lkml/2013/5/20/589
    
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: linux-sh@vger.kernel.org
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 61a07dafcd46..ecf83cd158dc 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -43,9 +43,9 @@
  * peripherals (nofpu, nodsp, and so forth).
  */
 #define onchip_setup(x)					\
-static int x##_disabled __cpuinitdata = !cpu_has_##x;	\
+static int x##_disabled = !cpu_has_##x;			\
 							\
-static int __cpuinit x##_setup(char *opts)			\
+static int x##_setup(char *opts)			\
 {							\
 	x##_disabled = 1;				\
 	return 1;					\
@@ -59,7 +59,7 @@ onchip_setup(dsp);
 #define CPUOPM		0xff2f0000
 #define CPUOPM_RABD	(1 << 5)
 
-static void __cpuinit speculative_execution_init(void)
+static void speculative_execution_init(void)
 {
 	/* Clear RABD */
 	__raw_writel(__raw_readl(CPUOPM) & ~CPUOPM_RABD, CPUOPM);
@@ -78,7 +78,7 @@ static void __cpuinit speculative_execution_init(void)
 #define EXPMASK_BRDSSLP		(1 << 1)
 #define EXPMASK_MMCAW		(1 << 4)
 
-static void __cpuinit expmask_init(void)
+static void expmask_init(void)
 {
 	unsigned long expmask = __raw_readl(EXPMASK);
 
@@ -217,7 +217,7 @@ static void detect_cache_shape(void)
 		l2_cache_shape = -1; /* No S-cache */
 }
 
-static void __cpuinit fpu_init(void)
+static void fpu_init(void)
 {
 	/* Disable the FPU */
 	if (fpu_disabled && (current_cpu_data.flags & CPU_HAS_FPU)) {
@@ -230,7 +230,7 @@ static void __cpuinit fpu_init(void)
 }
 
 #ifdef CONFIG_SH_DSP
-static void __cpuinit release_dsp(void)
+static void release_dsp(void)
 {
 	unsigned long sr;
 
@@ -244,7 +244,7 @@ static void __cpuinit release_dsp(void)
 	);
 }
 
-static void __cpuinit dsp_init(void)
+static void dsp_init(void)
 {
 	unsigned long sr;
 
@@ -276,7 +276,7 @@ static void __cpuinit dsp_init(void)
 	release_dsp();
 }
 #else
-static inline void __cpuinit dsp_init(void) { }
+static inline void dsp_init(void) { }
 #endif /* CONFIG_SH_DSP */
 
 /**
@@ -295,7 +295,7 @@ static inline void __cpuinit dsp_init(void) { }
  * Each processor family is still responsible for doing its own probing
  * and cache configuration in cpu_probe().
  */
-asmlinkage void __cpuinit cpu_init(void)
+asmlinkage void cpu_init(void)
 {
 	current_thread_info()->cpu = hard_smp_processor_id();
 

commit e839ca528718e68cad32a307dc9aabf01ef3eb05
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:30:03 2012 +0100

    Disintegrate asm/system.h for SH
    
    Disintegrate asm/system.h for SH.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    cc: linux-sh@vger.kernel.org

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index fac742e514ee..61a07dafcd46 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -18,13 +18,13 @@
 #include <asm/processor.h>
 #include <asm/uaccess.h>
 #include <asm/page.h>
-#include <asm/system.h>
 #include <asm/cacheflush.h>
 #include <asm/cache.h>
 #include <asm/elf.h>
 #include <asm/io.h>
 #include <asm/smp.h>
 #include <asm/sh_bios.h>
+#include <asm/setup.h>
 
 #ifdef CONFIG_SH_FPU
 #define cpu_has_fpu	1

commit 2f98492c5375e906e48c78d88351f45bb11b6a8a
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Oct 26 14:44:58 2010 +0900

    sh: Expose physical addressing mode through cpuinfo.
    
    CPUs can be in either the legacy 29-bit or 32-bit physical addressing
    modes. This follows the x86 approach of tracking the phys bits in cpuinfo
    and exposing it to userspace through procfs.
    
    This change was requested to permit kexec-tools to detect the physical
    addressing mode in order to determine the appropriate address mangling.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 97661061ff20..fac742e514ee 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -340,6 +340,8 @@ asmlinkage void __cpuinit cpu_init(void)
 	 */
 	current_cpu_data.asid_cache = NO_CONTEXT;
 
+	current_cpu_data.phys_bits = __in_29bit_mode() ? 29 : 32;
+
 	speculative_execution_init();
 	expmask_init();
 

commit 4a6feab0ee5240c4bd5378d9f8a46b85718c68a7
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Wed Apr 21 12:20:42 2010 +0900

    sh: __cpuinit annotate the CPU init path.
    
    All of the regular CPU init path needs to be __cpuinit annotated for CPU
    hotplug.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index ffaa00a2216b..97661061ff20 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -43,9 +43,9 @@
  * peripherals (nofpu, nodsp, and so forth).
  */
 #define onchip_setup(x)					\
-static int x##_disabled __initdata = !cpu_has_##x;	\
+static int x##_disabled __cpuinitdata = !cpu_has_##x;	\
 							\
-static int __init x##_setup(char *opts)			\
+static int __cpuinit x##_setup(char *opts)			\
 {							\
 	x##_disabled = 1;				\
 	return 1;					\
@@ -59,7 +59,7 @@ onchip_setup(dsp);
 #define CPUOPM		0xff2f0000
 #define CPUOPM_RABD	(1 << 5)
 
-static void __init speculative_execution_init(void)
+static void __cpuinit speculative_execution_init(void)
 {
 	/* Clear RABD */
 	__raw_writel(__raw_readl(CPUOPM) & ~CPUOPM_RABD, CPUOPM);
@@ -78,7 +78,7 @@ static void __init speculative_execution_init(void)
 #define EXPMASK_BRDSSLP		(1 << 1)
 #define EXPMASK_MMCAW		(1 << 4)
 
-static void __init expmask_init(void)
+static void __cpuinit expmask_init(void)
 {
 	unsigned long expmask = __raw_readl(EXPMASK);
 
@@ -217,7 +217,7 @@ static void detect_cache_shape(void)
 		l2_cache_shape = -1; /* No S-cache */
 }
 
-static void __init fpu_init(void)
+static void __cpuinit fpu_init(void)
 {
 	/* Disable the FPU */
 	if (fpu_disabled && (current_cpu_data.flags & CPU_HAS_FPU)) {
@@ -230,7 +230,7 @@ static void __init fpu_init(void)
 }
 
 #ifdef CONFIG_SH_DSP
-static void __init release_dsp(void)
+static void __cpuinit release_dsp(void)
 {
 	unsigned long sr;
 
@@ -244,7 +244,7 @@ static void __init release_dsp(void)
 	);
 }
 
-static void __init dsp_init(void)
+static void __cpuinit dsp_init(void)
 {
 	unsigned long sr;
 
@@ -276,11 +276,11 @@ static void __init dsp_init(void)
 	release_dsp();
 }
 #else
-static inline void __init dsp_init(void) { }
+static inline void __cpuinit dsp_init(void) { }
 #endif /* CONFIG_SH_DSP */
 
 /**
- * sh_cpu_init
+ * cpu_init
  *
  * This is our initial entry point for each CPU, and is invoked on the
  * boot CPU prior to calling start_kernel(). For SMP, a combination of
@@ -295,7 +295,7 @@ static inline void __init dsp_init(void) { }
  * Each processor family is still responsible for doing its own probing
  * and cache configuration in cpu_probe().
  */
-asmlinkage void __init sh_cpu_init(void)
+asmlinkage void __cpuinit cpu_init(void)
 {
 	current_thread_info()->cpu = hard_smp_processor_id();
 

commit a9079ca0cb15feda15e7a380092e02d5cd834148
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Wed Apr 21 12:01:06 2010 +0900

    sh: Tidy CPU probing and fixup section annotations.
    
    This does a detect_cpu_and_cache_system() -> cpu_probe() rename, tidies
    up the unused return value, and stuffs it under __cpuinit in preparation
    for CPU hotplug.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index c736422344eb..ffaa00a2216b 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -293,14 +293,14 @@ static inline void __init dsp_init(void) { }
  * subtype and initial configuration will all be done.
  *
  * Each processor family is still responsible for doing its own probing
- * and cache configuration in detect_cpu_and_cache_system().
+ * and cache configuration in cpu_probe().
  */
 asmlinkage void __init sh_cpu_init(void)
 {
 	current_thread_info()->cpu = hard_smp_processor_id();
 
 	/* First, probe the CPU */
-	detect_cpu_and_cache_system();
+	cpu_probe();
 
 	if (current_cpu_data.type == CPU_SH_NONE)
 		panic("Unknown CPU");

commit 49f3bfe9334a4cf86079d2ee1d08e674b58862a9
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Wed Feb 17 12:33:22 2010 +0900

    sh: Setup boot CPU VBR early to enable early page faults.
    
    vmemmap and the vmsplit code amongst others need to be able to take page
    faults much earlier than trap_init() time, so move this in to the early
    CPU initialization. VBR setup for secondary CPUs is already handled
    through start_secondary(), so we only need to do this for the boot CPU.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 6311b0b1789d..c736422344eb 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -24,6 +24,7 @@
 #include <asm/elf.h>
 #include <asm/io.h>
 #include <asm/smp.h>
+#include <asm/sh_bios.h>
 
 #ifdef CONFIG_SH_FPU
 #define cpu_has_fpu	1
@@ -342,9 +343,21 @@ asmlinkage void __init sh_cpu_init(void)
 	speculative_execution_init();
 	expmask_init();
 
-	/*
-	 * Boot processor to setup the FP and extended state context info.
-	 */
-	if (raw_smp_processor_id() == 0)
+	/* Do the rest of the boot processor setup */
+	if (raw_smp_processor_id() == 0) {
+		/* Save off the BIOS VBR, if there is one */
+		sh_bios_vbr_init();
+
+		/*
+		 * Setup VBR for boot CPU. Secondary CPUs do this through
+		 * start_secondary().
+		 */
+		per_cpu_trap_init();
+
+		/*
+		 * Boot processor to setup the FP and extended state
+		 * context info.
+		 */
 		init_thread_xstate();
+	}
 }

commit 9d56dd3b083a3bec56e9da35ce07baca81030b03
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Jan 26 12:58:40 2010 +0900

    sh: Mass ctrl_in/outX to __raw_read/writeX conversion.
    
    The old ctrl in/out routines are non-portable and unsuitable for
    cross-platform use. While drivers/sh has already been sanitized, there
    is still quite a lot of code that is not. This converts the arch/sh/ bits
    over, which permits us to flag the routines as deprecated whilst still
    building with -Werror for the architecture code, and to ensure that
    future users are not added.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 05a7d2a373b6..6311b0b1789d 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -61,10 +61,10 @@ onchip_setup(dsp);
 static void __init speculative_execution_init(void)
 {
 	/* Clear RABD */
-	ctrl_outl(ctrl_inl(CPUOPM) & ~CPUOPM_RABD, CPUOPM);
+	__raw_writel(__raw_readl(CPUOPM) & ~CPUOPM_RABD, CPUOPM);
 
 	/* Flush the update */
-	(void)ctrl_inl(CPUOPM);
+	(void)__raw_readl(CPUOPM);
 	ctrl_barrier();
 }
 #else
@@ -111,7 +111,7 @@ static void cache_init(void)
 	unsigned long ccr, flags;
 
 	jump_to_uncached();
-	ccr = ctrl_inl(CCR);
+	ccr = __raw_readl(CCR);
 
 	/*
 	 * At this point we don't know whether the cache is enabled or not - a
@@ -155,7 +155,7 @@ static void cache_init(void)
 			for (addr = addrstart;
 			     addr < addrstart + waysize;
 			     addr += current_cpu_data.dcache.linesz)
-				ctrl_outl(0, addr);
+				__raw_writel(0, addr);
 
 			addrstart += current_cpu_data.dcache.way_incr;
 		} while (--ways);
@@ -188,7 +188,7 @@ static void cache_init(void)
 
 	l2_cache_init();
 
-	ctrl_outl(flags, CCR);
+	__raw_writel(flags, CCR);
 	back_to_cached();
 }
 #else

commit 2dc2f8e0c46864e2a3722c84eaa96513d4cf8b2f
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Thu Jan 21 16:05:25 2010 +0900

    sh: Kill off the special uncached section and fixmap.
    
    Now that cached_to_uncached works as advertized in 32-bit mode and we're
    never going to be able to map < 16MB anyways, there's no need for the
    special uncached section. Kill it off.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index a5bb0550bbf3..05a7d2a373b6 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -98,7 +98,7 @@ static void __init expmask_init(void)
 #endif
 
 /* 2nd-level cache init */
-void __uses_jump_to_uncached __attribute__ ((weak)) l2_cache_init(void)
+void __attribute__ ((weak)) l2_cache_init(void)
 {
 }
 
@@ -106,7 +106,7 @@ void __uses_jump_to_uncached __attribute__ ((weak)) l2_cache_init(void)
  * Generic first-level cache init
  */
 #ifdef CONFIG_SUPERH32
-static void __uses_jump_to_uncached cache_init(void)
+static void cache_init(void)
 {
 	unsigned long ccr, flags;
 

commit 644755e7867710a23e6243dcc69cfc071985f560
Merge: 6430a5987f8b 0ea820cf9bf5 fa94ddea2b29 066000dd8567
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Wed Jan 13 13:02:55 2010 +0900

    Merge branches 'sh/xstate', 'sh/hw-breakpoints' and 'sh/stable-updates'

commit 0ea820cf9bf58f735ed40ec67947159c4f170012
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Wed Jan 13 12:51:40 2010 +0900

    sh: Move over to dynamically allocated FPU context.
    
    This follows the x86 xstate changes and implements a task_xstate slab
    cache that is dynamically sized to match one of hard FP/soft FP/FPU-less.
    
    This also tidies up and consolidates some of the SH-2A/SH-4 FPU
    fragmentation. Now fpu state restorers are commonly defined, with the
    init_fpu()/fpu_init() mess reworked to follow the x86 convention.
    The fpu_init() register initialization has been replaced by xstate setup
    followed by writing out to hardware via the standard restore path.
    
    As init_fpu() now performs a slab allocation a secondary lighterweight
    restorer is also introduced for the context switch.
    
    In the future the DSP state will be rolled in here, too.
    
    More work remains for math emulation and the SH-5 FPU, which presently
    uses its own special (UP-only) interfaces.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 89b4b76c0d76..2e23422280a7 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -28,18 +28,30 @@
 #include <asm/ubc.h>
 #endif
 
+#ifdef CONFIG_SH_FPU
+#define cpu_has_fpu	1
+#else
+#define cpu_has_fpu	0
+#endif
+
+#ifdef CONFIG_SH_DSP
+#define cpu_has_dsp	1
+#else
+#define cpu_has_dsp	0
+#endif
+
 /*
  * Generic wrapper for command line arguments to disable on-chip
  * peripherals (nofpu, nodsp, and so forth).
  */
-#define onchip_setup(x)				\
-static int x##_disabled __initdata = 0;		\
-						\
-static int __init x##_setup(char *opts)		\
-{						\
-	x##_disabled = 1;			\
-	return 1;				\
-}						\
+#define onchip_setup(x)					\
+static int x##_disabled __initdata = !cpu_has_##x;	\
+							\
+static int __init x##_setup(char *opts)			\
+{							\
+	x##_disabled = 1;				\
+	return 1;					\
+}							\
 __setup("no" __stringify(x), x##_setup);
 
 onchip_setup(fpu);
@@ -207,6 +219,18 @@ static void detect_cache_shape(void)
 		l2_cache_shape = -1; /* No S-cache */
 }
 
+static void __init fpu_init(void)
+{
+	/* Disable the FPU */
+	if (fpu_disabled && (current_cpu_data.flags & CPU_HAS_FPU)) {
+		printk("FPU Disabled\n");
+		current_cpu_data.flags &= ~CPU_HAS_FPU;
+	}
+
+	disable_fpu();
+	clear_used_math();
+}
+
 #ifdef CONFIG_SH_DSP
 static void __init release_dsp(void)
 {
@@ -244,9 +268,17 @@ static void __init dsp_init(void)
 	if (sr & SR_DSP)
 		current_cpu_data.flags |= CPU_HAS_DSP;
 
+	/* Disable the DSP */
+	if (dsp_disabled && (current_cpu_data.flags & CPU_HAS_DSP)) {
+		printk("DSP Disabled\n");
+		current_cpu_data.flags &= ~CPU_HAS_DSP;
+	}
+
 	/* Now that we've determined the DSP status, clear the DSP bit. */
 	release_dsp();
 }
+#else
+static inline void __init dsp_init(void) { }
 #endif /* CONFIG_SH_DSP */
 
 /**
@@ -302,18 +334,8 @@ asmlinkage void __init sh_cpu_init(void)
 		detect_cache_shape();
 	}
 
-	/* Disable the FPU */
-	if (fpu_disabled) {
-		printk("FPU Disabled\n");
-		current_cpu_data.flags &= ~CPU_HAS_FPU;
-	}
-
-	/* FPU initialization */
-	disable_fpu();
-	if ((current_cpu_data.flags & CPU_HAS_FPU)) {
-		current_thread_info()->status &= ~TS_USEDFPU;
-		clear_used_math();
-	}
+	fpu_init();
+	dsp_init();
 
 	/*
 	 * Initialize the per-CPU ASID cache very early, since the
@@ -321,18 +343,12 @@ asmlinkage void __init sh_cpu_init(void)
 	 */
 	current_cpu_data.asid_cache = NO_CONTEXT;
 
-#ifdef CONFIG_SH_DSP
-	/* Probe for DSP */
-	dsp_init();
-
-	/* Disable the DSP */
-	if (dsp_disabled) {
-		printk("DSP Disabled\n");
-		current_cpu_data.flags &= ~CPU_HAS_DSP;
-		release_dsp();
-	}
-#endif
-
 	speculative_execution_init();
 	expmask_init();
+
+	/*
+	 * Boot processor to setup the FP and extended state context info.
+	 */
+	if (raw_smp_processor_id() == 0)
+		init_thread_xstate();
 }

commit 7025bec9125b0a02edcaf22c2dce753bf2c95480
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Jan 5 19:16:35 2010 +0900

    sh: Kill off dead UBC headers.
    
    Nothing is using these now, so kill them all off.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 89b4b76c0d76..39b93828c872 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -24,9 +24,6 @@
 #include <asm/elf.h>
 #include <asm/io.h>
 #include <asm/smp.h>
-#ifdef CONFIG_SUPERH32
-#include <asm/ubc.h>
-#endif
 
 /*
  * Generic wrapper for command line arguments to disable on-chip
@@ -252,20 +249,19 @@ static void __init dsp_init(void)
 /**
  * sh_cpu_init
  *
- * This is our initial entry point for each CPU, and is invoked on the boot
- * CPU prior to calling start_kernel(). For SMP, a combination of this and
- * start_secondary() will bring up each processor to a ready state prior
- * to hand forking the idle loop.
+ * This is our initial entry point for each CPU, and is invoked on the
+ * boot CPU prior to calling start_kernel(). For SMP, a combination of
+ * this and start_secondary() will bring up each processor to a ready
+ * state prior to hand forking the idle loop.
  *
- * We do all of the basic processor init here, including setting up the
- * caches, FPU, DSP, kicking the UBC, etc. By the time start_kernel() is
- * hit (and subsequently platform_setup()) things like determining the
- * CPU subtype and initial configuration will all be done.
+ * We do all of the basic processor init here, including setting up
+ * the caches, FPU, DSP, etc. By the time start_kernel() is hit (and
+ * subsequently platform_setup()) things like determining the CPU
+ * subtype and initial configuration will all be done.
  *
  * Each processor family is still responsible for doing its own probing
  * and cache configuration in detect_cpu_and_cache_system().
  */
-
 asmlinkage void __init sh_cpu_init(void)
 {
 	current_thread_info()->cpu = hard_smp_processor_id();

commit 6e8a0d11a088ed51b1b649d3a1127a7bda3700a0
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Fri Dec 4 16:22:11 2009 +0900

    sh: Make associative cache writes fatal on all SH-4A parts.
    
    Now that associative cache writes are no longer needed by the SH-4/SH-4A
    cache flush code, associative write support can be explicitly disabled
    for all SH-4A parts. This makes any associative write throw an exception,
    as this behaviour can not be assumed to exist on future parts.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index ad9dfff9427c..89b4b76c0d76 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -75,16 +75,11 @@ static void __init expmask_init(void)
 	/*
 	 * Future proofing.
 	 *
-	 * Disable support for slottable sleep instruction
-	 * and non-nop instructions in the rte delay slot.
+	 * Disable support for slottable sleep instruction, non-nop
+	 * instructions in the rte delay slot, and associative writes to
+	 * the memory-mapped cache array.
 	 */
-	expmask &= ~(EXPMASK_RTEDS | EXPMASK_BRDSSLP);
-
-	/*
-	 * Enable associative writes to the memory-mapped cache array
-	 * until the cache flush ops have been rewritten.
-	 */
-	expmask |= EXPMASK_MMCAW;
+	expmask &= ~(EXPMASK_RTEDS | EXPMASK_BRDSSLP | EXPMASK_MMCAW);
 
 	__raw_writel(expmask, EXPMASK);
 	ctrl_barrier();

commit d3ea9fa0a563620fe9f416f94bb8927c64390917
Author: Stuart Menefy <stuart.menefy@st.com>
Date:   Fri Sep 25 18:25:10 2009 +0100

    sh: Minor optimisations to FPU handling
    
    A number of small optimisations to FPU handling, in particular:
    
     - move the task USEDFPU flag from the thread_info flags field (which
       is accessed asynchronously to the thread) to a new status field,
       which is only accessed by the thread itself. This allows locking to
       be removed in most cases, or can be reduced to a preempt_lock().
       This mimics the i386 behaviour.
    
     - move the modification of regs->sr and thread_info->status flags out
       of save_fpu() to __unlazy_fpu(). This gives the compiler a better
       chance to optimise things, as well as making save_fpu() symmetrical
       with restore_fpu() and init_fpu().
    
     - implement prepare_to_copy(), so that when creating a thread, we can
       unlazy the FPU prior to copying the thread data structures.
    
    Also make sure that the FPU is disabled while in the kernel, in
    particular while booting, and for newly created kernel threads,
    
    In a very artificial benchmark, the execution time for 2500000
    context switches was reduced from 50 to 45 seconds.
    
    Signed-off-by: Stuart Menefy <stuart.menefy@st.com>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 580d58b94cc5..ad9dfff9427c 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -311,12 +311,12 @@ asmlinkage void __init sh_cpu_init(void)
 	if (fpu_disabled) {
 		printk("FPU Disabled\n");
 		current_cpu_data.flags &= ~CPU_HAS_FPU;
-		disable_fpu();
 	}
 
 	/* FPU initialization */
+	disable_fpu();
 	if ((current_cpu_data.flags & CPU_HAS_FPU)) {
-		clear_thread_flag(TIF_USEDFPU);
+		current_thread_info()->status &= ~TS_USEDFPU;
 		clear_used_math();
 	}
 

commit cae19b5902d52ff059f5df98ea993a00e5686af1
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Fri Oct 16 18:20:42 2009 +0900

    sh: Kill off legacy UBC wakeup cruft.
    
    This code was added for some ancient SH-4 solution engines with peculiar
    boot ROMs that did silly things to the UBC MSTP bits. None of these have
    been in the wild for years, and these days the clock framework wraps up
    the MSTP bits, meaning that the UBC code is one of the few interfaces
    that is stomping MSTP bits underneath the clock framework. At this point
    the risks far outweigh any benefit this code provided, so just kill it
    off.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index e932ebef4738..580d58b94cc5 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -338,17 +338,6 @@ asmlinkage void __init sh_cpu_init(void)
 	}
 #endif
 
-	/*
-	 * Some brain-damaged loaders decided it would be a good idea to put
-	 * the UBC to sleep. This causes some issues when it comes to things
-	 * like PTRACE_SINGLESTEP or doing hardware watchpoints in GDB.  So ..
-	 * we wake it up and hope that all is well.
-	 */
-#ifdef CONFIG_SUPERH32
-	if (raw_smp_processor_id() == 0)
-		ubc_wakeup();
-#endif
-
 	speculative_execution_init();
 	expmask_init();
 }

commit ee8365f23355cdb66e7a6c5c9364e8d3ba4de32f
Merge: 1b3edd9745ef e174d13010a6
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Wed Aug 19 09:12:00 2009 +0900

    Merge branch 'master' into sh/cachetlb
    
    Conflicts:
            arch/sh/kernel/Makefile_64

commit dde5e3ffb770ef2854bbc32c51a365e932919e19
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Sat Aug 15 09:49:32 2009 +0900

    sh: rework nommu for generic cache.c use.
    
    This does a bit of reorganizing for allowing nommu to use the new
    and generic cache.c, no functional changes.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index ad85421099cd..c832fa4cf8ed 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -268,11 +268,9 @@ asmlinkage void __init sh_cpu_init(void)
 	cache_init();
 
 	if (raw_smp_processor_id() == 0) {
-#ifdef CONFIG_MMU
 		shm_align_mask = max_t(unsigned long,
 				       current_cpu_data.dcache.way_size - 1,
 				       PAGE_SIZE - 1);
-#endif
 
 		/* Boot CPU sets the cache shape */
 		detect_cache_shape();

commit 7dd6662a92fe9a15ad565045aa60367995cc533d
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Sat Aug 15 07:43:21 2009 +0900

    sh: delay slot future proofing via EXPMASK on SH-4A parts.
    
    This implements EXPMASK initialization code for SH-4A parts, where it is
    possible to disable compat features that will go away in newer cores.
    Presently this includes disabling support for non-nop instructions in the
    rte delay slot, as well as a sleep instruction being placed in a delay
    slot (neither of which the kernel does any longer). As a result of this,
    any future offenders will have illegal slot exceptions generated for
    them.
    
    Associative writes for the memory-mapped cache array are still left
    enabled, until such a point that special cache operations for SH-4A are
    provided to move off of the current (and rather dated) SH-4 versions.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index ad85421099cd..d40b9db5be03 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -3,7 +3,7 @@
  *
  * CPU init code
  *
- * Copyright (C) 2002 - 2007  Paul Mundt
+ * Copyright (C) 2002 - 2009  Paul Mundt
  * Copyright (C) 2003  Richard Curnow
  *
  * This file is subject to the terms and conditions of the GNU General Public
@@ -62,6 +62,37 @@ static void __init speculative_execution_init(void)
 #define speculative_execution_init()	do { } while (0)
 #endif
 
+#ifdef CONFIG_CPU_SH4A
+#define EXPMASK			0xff2f0004
+#define EXPMASK_RTEDS		(1 << 0)
+#define EXPMASK_BRDSSLP		(1 << 1)
+#define EXPMASK_MMCAW		(1 << 4)
+
+static void __init expmask_init(void)
+{
+	unsigned long expmask = __raw_readl(EXPMASK);
+
+	/*
+	 * Future proofing.
+	 *
+	 * Disable support for slottable sleep instruction
+	 * and non-nop instructions in the rte delay slot.
+	 */
+	expmask &= ~(EXPMASK_RTEDS | EXPMASK_BRDSSLP);
+
+	/*
+	 * Enable associative writes to the memory-mapped cache array
+	 * until the cache flush ops have been rewritten.
+	 */
+	expmask |= EXPMASK_MMCAW;
+
+	__raw_writel(expmask, EXPMASK);
+	ctrl_barrier();
+}
+#else
+#define expmask_init()	do { } while (0)
+#endif
+
 /* 2nd-level cache init */
 void __uses_jump_to_uncached __attribute__ ((weak)) l2_cache_init(void)
 {
@@ -321,4 +352,5 @@ asmlinkage void __init sh_cpu_init(void)
 #endif
 
 	speculative_execution_init();
+	expmask_init();
 }

commit fab88d9fe98e9091aafeb9789fbf2e04fdace8ed
Author: Kuninori Morimoto <morimoto.kuninori@renesas.com>
Date:   Tue Jun 2 02:49:20 2009 +0000

    sh: add weak l2_cache_init function.
    
    Signed-off-by: Kuninori Morimoto <morimoto.kuninori@renesas.com>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index d29e69c156f0..ad85421099cd 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -62,6 +62,11 @@ static void __init speculative_execution_init(void)
 #define speculative_execution_init()	do { } while (0)
 #endif
 
+/* 2nd-level cache init */
+void __uses_jump_to_uncached __attribute__ ((weak)) l2_cache_init(void)
+{
+}
+
 /*
  * Generic first-level cache init
  */
@@ -146,6 +151,8 @@ static void __uses_jump_to_uncached cache_init(void)
 	flags &= ~CCR_CACHE_ENABLE;
 #endif
 
+	l2_cache_init();
+
 	ctrl_outl(flags, CCR);
 	back_to_cached();
 }

commit 4a4a9be3ebdbf17957d29e3521f328a1145f9431
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Wed Nov 12 13:17:38 2008 +0900

    sh: Move arch_get_unmapped_area() in to arch/sh/mm/mmap.c.
    
    Now that arch/sh/mm/mmap.c exists, move arch_get_unmapped_area() there.
    Follows the ARM change.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 75fb03d35670..d29e69c156f0 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -261,9 +261,11 @@ asmlinkage void __init sh_cpu_init(void)
 	cache_init();
 
 	if (raw_smp_processor_id() == 0) {
+#ifdef CONFIG_MMU
 		shm_align_mask = max_t(unsigned long,
 				       current_cpu_data.dcache.way_size - 1,
 				       PAGE_SIZE - 1);
+#endif
 
 		/* Boot CPU sets the cache shape */
 		detect_cache_shape();

commit b2839ed83f54d40870747ac8d655504dff63d1c5
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Thu Mar 6 12:43:38 2008 +0900

    sh: Fix up section mismatches.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 80a31329ead9..75fb03d35670 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -233,7 +233,7 @@ static void __init dsp_init(void)
  * and cache configuration in detect_cpu_and_cache_system().
  */
 
-asmlinkage void __cpuinit sh_cpu_init(void)
+asmlinkage void __init sh_cpu_init(void)
 {
 	current_thread_info()->cpu = hard_smp_processor_id();
 

commit cd01204b82933754a7276838656420477f64d4b8
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Dec 10 15:50:28 2007 +0900

    sh: Encode L1/L2 cache shape in auxvt.
    
    This adds in the L1I/L1D/L2 cache shape support to their respective
    entries in the ELF auxvt, based on the Alpha implementation. We use
    this on the userspace libc side for calculating a tightly packed
    SHMLBA amongst other things.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 0f0c76a842e4..80a31329ead9 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -13,6 +13,7 @@
 #include <linux/init.h>
 #include <linux/kernel.h>
 #include <linux/mm.h>
+#include <linux/log2.h>
 #include <asm/mmu_context.h>
 #include <asm/processor.h>
 #include <asm/uaccess.h>
@@ -20,6 +21,7 @@
 #include <asm/system.h>
 #include <asm/cacheflush.h>
 #include <asm/cache.h>
+#include <asm/elf.h>
 #include <asm/io.h>
 #include <asm/smp.h>
 #ifdef CONFIG_SUPERH32
@@ -151,6 +153,27 @@ static void __uses_jump_to_uncached cache_init(void)
 #define cache_init()	do { } while (0)
 #endif
 
+#define CSHAPE(totalsize, linesize, assoc) \
+	((totalsize & ~0xff) | (linesize << 4) | assoc)
+
+#define CACHE_DESC_SHAPE(desc)	\
+	CSHAPE((desc).way_size * (desc).ways, ilog2((desc).linesz), (desc).ways)
+
+static void detect_cache_shape(void)
+{
+	l1d_cache_shape = CACHE_DESC_SHAPE(current_cpu_data.dcache);
+
+	if (current_cpu_data.dcache.flags & SH_CACHE_COMBINED)
+		l1i_cache_shape = l1d_cache_shape;
+	else
+		l1i_cache_shape = CACHE_DESC_SHAPE(current_cpu_data.icache);
+
+	if (current_cpu_data.flags & CPU_HAS_L2_CACHE)
+		l2_cache_shape = CACHE_DESC_SHAPE(current_cpu_data.scache);
+	else
+		l2_cache_shape = -1; /* No S-cache */
+}
+
 #ifdef CONFIG_SH_DSP
 static void __init release_dsp(void)
 {
@@ -237,11 +260,15 @@ asmlinkage void __cpuinit sh_cpu_init(void)
 	/* Init the cache */
 	cache_init();
 
-	if (raw_smp_processor_id() == 0)
+	if (raw_smp_processor_id() == 0) {
 		shm_align_mask = max_t(unsigned long,
 				       current_cpu_data.dcache.way_size - 1,
 				       PAGE_SIZE - 1);
 
+		/* Boot CPU sets the cache shape */
+		detect_cache_shape();
+	}
+
 	/* Disable the FPU */
 	if (fpu_disabled) {
 		printk("FPU Disabled\n");

commit cbaa118ecfd99fc5ed7adbd9c34a30e1c05e3c93
Author: Stuart Menefy <stuart.menefy@st.com>
Date:   Fri Nov 30 17:06:36 2007 +0900

    sh: Preparation for uncached jumps through PMB.
    
    Presently most of the 29-bit physical parts do P1/P2 segmentation
    with a 1:1 cached/uncached mapping, jumping between the two to
    control the caching behaviour. This provides the basic infrastructure
    to maintain this behaviour on 32-bit physical parts that don't map
    P1/P2 at all, using a shiny new linker section and corresponding
    fixmap entry.
    
    Signed-off-by: Stuart Menefy <stuart.menefy@st.com>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index fd1688e6c61c..0f0c76a842e4 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -64,11 +64,11 @@ static void __init speculative_execution_init(void)
  * Generic first-level cache init
  */
 #ifdef CONFIG_SUPERH32
-static void __init cache_init(void)
+static void __uses_jump_to_uncached cache_init(void)
 {
 	unsigned long ccr, flags;
 
-	jump_to_P2();
+	jump_to_uncached();
 	ccr = ctrl_inl(CCR);
 
 	/*
@@ -145,7 +145,7 @@ static void __init cache_init(void)
 #endif
 
 	ctrl_outl(flags, CCR);
-	back_to_P1();
+	back_to_cached();
 }
 #else
 #define cache_init()	do { } while (0)

commit 27a511c6f37c05c5cf8fae9fe513f60d87af9158
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Sat Nov 10 20:25:28 2007 +0900

    sh: Disable initial cache flush on SH-5.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index f37f1c031631..fd1688e6c61c 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -63,24 +63,11 @@ static void __init speculative_execution_init(void)
 /*
  * Generic first-level cache init
  */
+#ifdef CONFIG_SUPERH32
 static void __init cache_init(void)
 {
 	unsigned long ccr, flags;
 
-	/* First setup the rest of the I-cache info */
-	current_cpu_data.icache.entry_mask = current_cpu_data.icache.way_incr -
-				      current_cpu_data.icache.linesz;
-
-	current_cpu_data.icache.way_size = current_cpu_data.icache.sets *
-				    current_cpu_data.icache.linesz;
-
-	/* And the D-cache too */
-	current_cpu_data.dcache.entry_mask = current_cpu_data.dcache.way_incr -
-				      current_cpu_data.dcache.linesz;
-
-	current_cpu_data.dcache.way_size = current_cpu_data.dcache.sets *
-				    current_cpu_data.dcache.linesz;
-
 	jump_to_P2();
 	ccr = ctrl_inl(CCR);
 
@@ -160,6 +147,9 @@ static void __init cache_init(void)
 	ctrl_outl(flags, CCR);
 	back_to_P1();
 }
+#else
+#define cache_init()	do { } while (0)
+#endif
 
 #ifdef CONFIG_SH_DSP
 static void __init release_dsp(void)
@@ -230,6 +220,20 @@ asmlinkage void __cpuinit sh_cpu_init(void)
 	if (current_cpu_data.type == CPU_SH_NONE)
 		panic("Unknown CPU");
 
+	/* First setup the rest of the I-cache info */
+	current_cpu_data.icache.entry_mask = current_cpu_data.icache.way_incr -
+				      current_cpu_data.icache.linesz;
+
+	current_cpu_data.icache.way_size = current_cpu_data.icache.sets *
+				    current_cpu_data.icache.linesz;
+
+	/* And the D-cache too */
+	current_cpu_data.dcache.entry_mask = current_cpu_data.dcache.way_incr -
+				      current_cpu_data.dcache.linesz;
+
+	current_cpu_data.dcache.way_size = current_cpu_data.dcache.sets *
+				    current_cpu_data.dcache.linesz;
+
 	/* Init the cache */
 	cache_init();
 

commit c881cbc033c80d92d1bb7a0446735561a46e1f9c
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Sat Nov 10 20:18:18 2007 +0900

    sh: Don't reference UBC code in CPU init on sh64.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index c217c4bf0085..f37f1c031631 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -21,8 +21,10 @@
 #include <asm/cacheflush.h>
 #include <asm/cache.h>
 #include <asm/io.h>
-#include <asm/ubc.h>
 #include <asm/smp.h>
+#ifdef CONFIG_SUPERH32
+#include <asm/ubc.h>
+#endif
 
 /*
  * Generic wrapper for command line arguments to disable on-chip
@@ -273,7 +275,10 @@ asmlinkage void __cpuinit sh_cpu_init(void)
 	 * like PTRACE_SINGLESTEP or doing hardware watchpoints in GDB.  So ..
 	 * we wake it up and hope that all is well.
 	 */
+#ifdef CONFIG_SUPERH32
 	if (raw_smp_processor_id() == 0)
 		ubc_wakeup();
+#endif
+
 	speculative_execution_init();
 }

commit aba1030a7e529ec9fe47a8cfc06d12a39180fa71
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Fri Sep 21 18:32:32 2007 +0900

    sh: Bring SMP support back from the dead.
    
    There was a very preliminary bunch of SMP code scattered around for the
    SH7604 microcontrollers from way back when, and it has mostly suffered
    bitrot since then. With the tree already having been slowly getting
    prepped for SMP, this plugs in most of the remaining platform-independent
    bits.
    
    Signed-off-by: Magnus Damm <damm@igel.co.jp>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index fdc245b7b043..c217c4bf0085 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -22,6 +22,7 @@
 #include <asm/cache.h>
 #include <asm/io.h>
 #include <asm/ubc.h>
+#include <asm/smp.h>
 
 /*
  * Generic wrapper for command line arguments to disable on-chip
@@ -216,8 +217,11 @@ static void __init dsp_init(void)
  * Each processor family is still responsible for doing its own probing
  * and cache configuration in detect_cpu_and_cache_system().
  */
-asmlinkage void __init sh_cpu_init(void)
+
+asmlinkage void __cpuinit sh_cpu_init(void)
 {
+	current_thread_info()->cpu = hard_smp_processor_id();
+
 	/* First, probe the CPU */
 	detect_cpu_and_cache_system();
 
@@ -227,9 +231,10 @@ asmlinkage void __init sh_cpu_init(void)
 	/* Init the cache */
 	cache_init();
 
-	shm_align_mask = max_t(unsigned long,
-			       current_cpu_data.dcache.way_size - 1,
-			       PAGE_SIZE - 1);
+	if (raw_smp_processor_id() == 0)
+		shm_align_mask = max_t(unsigned long,
+				       current_cpu_data.dcache.way_size - 1,
+				       PAGE_SIZE - 1);
 
 	/* Disable the FPU */
 	if (fpu_disabled) {
@@ -268,6 +273,7 @@ asmlinkage void __init sh_cpu_init(void)
 	 * like PTRACE_SINGLESTEP or doing hardware watchpoints in GDB.  So ..
 	 * we wake it up and hope that all is well.
 	 */
-	ubc_wakeup();
+	if (raw_smp_processor_id() == 0)
+		ubc_wakeup();
 	speculative_execution_init();
 }

commit e7bd34a15b85655f24d1b45edbe3bdfebf9d027e
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Jul 31 17:07:28 2007 +0900

    sh: Support explicit L1 cache disabling.
    
    This reworks the cache mode configuration in Kconfig, and allows for
    explicit selection of write-back/write-through/off configurations.
    All of the cache flushing routines are optimized away for the off
    case.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 9172e97dc26a..fdc245b7b043 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -143,12 +143,15 @@ static void __init cache_init(void)
 		flags &= ~CCR_CACHE_EMODE;
 #endif
 
-#ifdef CONFIG_SH_WRITETHROUGH
-	/* Turn on Write-through caching */
+#if defined(CONFIG_CACHE_WRITETHROUGH)
+	/* Write-through */
 	flags |= CCR_CACHE_WT;
-#else
-	/* .. or default to Write-back */
+#elif defined(CONFIG_CACHE_WRITEBACK)
+	/* Write-back */
 	flags |= CCR_CACHE_CB;
+#else
+	/* Off */
+	flags &= ~CCR_CACHE_ENABLE;
 #endif
 
 	ctrl_outl(flags, CCR);

commit 357d59469c1179c30b8c425aba302346fac3594e
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Jun 11 15:32:07 2007 +0900

    sh: Tidy up dependencies for SH-2 build.
    
    SH-2 can presently get in to some pretty bogus states, so
    we tidy up the dependencies a bit and get it all building
    again.
    
    This gets us a bit closer to a functional allyesconfig
    and allmodconfig, though there are still a few things to
    fix up.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 6451ad630174..9172e97dc26a 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -21,8 +21,7 @@
 #include <asm/cacheflush.h>
 #include <asm/cache.h>
 #include <asm/io.h>
-
-extern void detect_cpu_and_cache_system(void);
+#include <asm/ubc.h>
 
 /*
  * Generic wrapper for command line arguments to disable on-chip
@@ -152,15 +151,6 @@ static void __init cache_init(void)
 	flags |= CCR_CACHE_CB;
 #endif
 
-#ifdef CONFIG_SH_OCRAM
-	/* Turn on OCRAM -- halve the OC */
-	flags |= CCR_CACHE_ORA;
-	current_cpu_data.dcache.sets >>= 1;
-
-	current_cpu_data.dcache.way_size = current_cpu_data.dcache.sets *
-				    current_cpu_data.dcache.linesz;
-#endif
-
 	ctrl_outl(flags, CCR);
 	back_to_P1();
 }
@@ -269,7 +259,6 @@ asmlinkage void __init sh_cpu_init(void)
 	}
 #endif
 
-#ifdef CONFIG_UBC_WAKEUP
 	/*
 	 * Some brain-damaged loaders decided it would be a good idea to put
 	 * the UBC to sleep. This causes some issues when it comes to things
@@ -277,7 +266,5 @@ asmlinkage void __init sh_cpu_init(void)
 	 * we wake it up and hope that all is well.
 	 */
 	ubc_wakeup();
-#endif
-
 	speculative_execution_init();
 }

commit 45ed285b54930767937deb0eaf718b1d08c3c475
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Thu Mar 8 18:12:17 2007 +0900

    sh: speculative execution support for SH7780.
    
    SH7780 has a speculative execution mode where it can speculatively
    perform an instruction fetch for subroutine returns, this allows it
    to be enabled. There are some various pitfalls associated with this
    mode, so it's left as depending on CONFIG_EXPERIMENTAL and not
    enabled by default.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 726acfcb9b77..6451ad630174 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -41,6 +41,23 @@ __setup("no" __stringify(x), x##_setup);
 onchip_setup(fpu);
 onchip_setup(dsp);
 
+#ifdef CONFIG_SPECULATIVE_EXECUTION
+#define CPUOPM		0xff2f0000
+#define CPUOPM_RABD	(1 << 5)
+
+static void __init speculative_execution_init(void)
+{
+	/* Clear RABD */
+	ctrl_outl(ctrl_inl(CPUOPM) & ~CPUOPM_RABD, CPUOPM);
+
+	/* Flush the update */
+	(void)ctrl_inl(CPUOPM);
+	ctrl_barrier();
+}
+#else
+#define speculative_execution_init()	do { } while (0)
+#endif
+
 /*
  * Generic first-level cache init
  */
@@ -261,4 +278,6 @@ asmlinkage void __init sh_cpu_init(void)
 	 */
 	ubc_wakeup();
 #endif
+
+	speculative_execution_init();
 }

commit ffe1b4e9f436fd7bb784f3bf7ee963c149fbca5f
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Mar 12 16:15:22 2007 +0900

    sh: Fix SH-3 cache entry_mask and way_size calculation.
    
    The code for performing the calculation was only in the SH-4 probe
    path, move it out to the common path so the other parts get this
    right too.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 4b339a640b13..726acfcb9b77 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -3,7 +3,7 @@
  *
  * CPU init code
  *
- * Copyright (C) 2002 - 2006  Paul Mundt
+ * Copyright (C) 2002 - 2007  Paul Mundt
  * Copyright (C) 2003  Richard Curnow
  *
  * This file is subject to the terms and conditions of the GNU General Public
@@ -48,8 +48,19 @@ static void __init cache_init(void)
 {
 	unsigned long ccr, flags;
 
-	if (current_cpu_data.type == CPU_SH_NONE)
-		panic("Unknown CPU");
+	/* First setup the rest of the I-cache info */
+	current_cpu_data.icache.entry_mask = current_cpu_data.icache.way_incr -
+				      current_cpu_data.icache.linesz;
+
+	current_cpu_data.icache.way_size = current_cpu_data.icache.sets *
+				    current_cpu_data.icache.linesz;
+
+	/* And the D-cache too */
+	current_cpu_data.dcache.entry_mask = current_cpu_data.dcache.way_incr -
+				      current_cpu_data.dcache.linesz;
+
+	current_cpu_data.dcache.way_size = current_cpu_data.dcache.sets *
+				    current_cpu_data.dcache.linesz;
 
 	jump_to_P2();
 	ccr = ctrl_inl(CCR);
@@ -200,6 +211,9 @@ asmlinkage void __init sh_cpu_init(void)
 	/* First, probe the CPU */
 	detect_cpu_and_cache_system();
 
+	if (current_cpu_data.type == CPU_SH_NONE)
+		panic("Unknown CPU");
+
 	/* Init the cache */
 	cache_init();
 

commit 11c1965687b0a472add948d4240dfe65a2fcb298
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Dec 25 10:19:56 2006 +0900

    sh: Fixup cpu_data references for the non-boot CPUs.
    
    There are a lot of bogus cpu_data-> references that only end up working
    for the boot CPU, convert these to current_cpu_data to fixup SMP.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 6c3c7687e81f..4b339a640b13 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -48,7 +48,7 @@ static void __init cache_init(void)
 {
 	unsigned long ccr, flags;
 
-	if (cpu_data->type == CPU_SH_NONE)
+	if (current_cpu_data.type == CPU_SH_NONE)
 		panic("Unknown CPU");
 
 	jump_to_P2();
@@ -68,7 +68,7 @@ static void __init cache_init(void)
 	if (ccr & CCR_CACHE_ENABLE) {
 		unsigned long ways, waysize, addrstart;
 
-		waysize = cpu_data->dcache.sets;
+		waysize = current_cpu_data.dcache.sets;
 
 #ifdef CCR_CACHE_ORA
 		/*
@@ -79,7 +79,7 @@ static void __init cache_init(void)
 			waysize >>= 1;
 #endif
 
-		waysize <<= cpu_data->dcache.entry_shift;
+		waysize <<= current_cpu_data.dcache.entry_shift;
 
 #ifdef CCR_CACHE_EMODE
 		/* If EMODE is not set, we only have 1 way to flush. */
@@ -87,7 +87,7 @@ static void __init cache_init(void)
 			ways = 1;
 		else
 #endif
-			ways = cpu_data->dcache.ways;
+			ways = current_cpu_data.dcache.ways;
 
 		addrstart = CACHE_OC_ADDRESS_ARRAY;
 		do {
@@ -95,10 +95,10 @@ static void __init cache_init(void)
 
 			for (addr = addrstart;
 			     addr < addrstart + waysize;
-			     addr += cpu_data->dcache.linesz)
+			     addr += current_cpu_data.dcache.linesz)
 				ctrl_outl(0, addr);
 
-			addrstart += cpu_data->dcache.way_incr;
+			addrstart += current_cpu_data.dcache.way_incr;
 		} while (--ways);
 	}
 
@@ -110,7 +110,7 @@ static void __init cache_init(void)
 
 #ifdef CCR_CACHE_EMODE
 	/* Force EMODE if possible */
-	if (cpu_data->dcache.ways > 1)
+	if (current_cpu_data.dcache.ways > 1)
 		flags |= CCR_CACHE_EMODE;
 	else
 		flags &= ~CCR_CACHE_EMODE;
@@ -127,10 +127,10 @@ static void __init cache_init(void)
 #ifdef CONFIG_SH_OCRAM
 	/* Turn on OCRAM -- halve the OC */
 	flags |= CCR_CACHE_ORA;
-	cpu_data->dcache.sets >>= 1;
+	current_cpu_data.dcache.sets >>= 1;
 
-	cpu_data->dcache.way_size = cpu_data->dcache.sets *
-				    cpu_data->dcache.linesz;
+	current_cpu_data.dcache.way_size = current_cpu_data.dcache.sets *
+				    current_cpu_data.dcache.linesz;
 #endif
 
 	ctrl_outl(flags, CCR);
@@ -172,7 +172,7 @@ static void __init dsp_init(void)
 
 	/* If the DSP bit is still set, this CPU has a DSP */
 	if (sr & SR_DSP)
-		cpu_data->flags |= CPU_HAS_DSP;
+		current_cpu_data.flags |= CPU_HAS_DSP;
 
 	/* Now that we've determined the DSP status, clear the DSP bit. */
 	release_dsp();
@@ -204,18 +204,18 @@ asmlinkage void __init sh_cpu_init(void)
 	cache_init();
 
 	shm_align_mask = max_t(unsigned long,
-			       cpu_data->dcache.way_size - 1,
+			       current_cpu_data.dcache.way_size - 1,
 			       PAGE_SIZE - 1);
 
 	/* Disable the FPU */
 	if (fpu_disabled) {
 		printk("FPU Disabled\n");
-		cpu_data->flags &= ~CPU_HAS_FPU;
+		current_cpu_data.flags &= ~CPU_HAS_FPU;
 		disable_fpu();
 	}
 
 	/* FPU initialization */
-	if ((cpu_data->flags & CPU_HAS_FPU)) {
+	if ((current_cpu_data.flags & CPU_HAS_FPU)) {
 		clear_thread_flag(TIF_USEDFPU);
 		clear_used_math();
 	}
@@ -233,7 +233,7 @@ asmlinkage void __init sh_cpu_init(void)
 	/* Disable the DSP */
 	if (dsp_disabled) {
 		printk("DSP Disabled\n");
-		cpu_data->flags &= ~CPU_HAS_DSP;
+		current_cpu_data.flags &= ~CPU_HAS_DSP;
 		release_dsp();
 	}
 #endif

commit aec5e0e1c179fac4bbca4007a3f0d3107275a73c
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Dec 25 09:51:47 2006 +0900

    sh: Use a per-cpu ASID cache.
    
    Previously this was implemented using a global cache, cache
    this per-CPU instead and bump up the number of context IDs to
    match NR_CPUS.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 48121766e8d2..6c3c7687e81f 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -3,7 +3,7 @@
  *
  * CPU init code
  *
- * Copyright (C) 2002, 2003  Paul Mundt
+ * Copyright (C) 2002 - 2006  Paul Mundt
  * Copyright (C) 2003  Richard Curnow
  *
  * This file is subject to the terms and conditions of the GNU General Public
@@ -12,6 +12,8 @@
  */
 #include <linux/init.h>
 #include <linux/kernel.h>
+#include <linux/mm.h>
+#include <asm/mmu_context.h>
 #include <asm/processor.h>
 #include <asm/uaccess.h>
 #include <asm/page.h>
@@ -218,6 +220,12 @@ asmlinkage void __init sh_cpu_init(void)
 		clear_used_math();
 	}
 
+	/*
+	 * Initialize the per-CPU ASID cache very early, since the
+	 * TLB flushing routines depend on this being setup.
+	 */
+	current_cpu_data.asid_cache = NO_CONTEXT;
+
 #ifdef CONFIG_SH_DSP
 	/* Probe for DSP */
 	dsp_init();
@@ -240,4 +248,3 @@ asmlinkage void __init sh_cpu_init(void)
 	ubc_wakeup();
 #endif
 }
-

commit 9d4436a6fbc8c5eccdfcb8f5884e0a7b4a57f6d2
Author: Yoshinori Sato <ysato@users.sourceforge.jp>
Date:   Sun Nov 5 15:40:13 2006 +0900

    sh: Add support for SH7206 and SH7619 CPU subtypes.
    
    This implements initial support for the SH7206 (SH-2A) and SH7619
    (SH-2) MMU-less CPUs.
    
    Signed-off-by: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index bfb90eb0b7a6..48121766e8d2 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -68,12 +68,14 @@ static void __init cache_init(void)
 
 		waysize = cpu_data->dcache.sets;
 
+#ifdef CCR_CACHE_ORA
 		/*
 		 * If the OC is already in RAM mode, we only have
 		 * half of the entries to flush..
 		 */
 		if (ccr & CCR_CACHE_ORA)
 			waysize >>= 1;
+#endif
 
 		waysize <<= cpu_data->dcache.entry_shift;
 

commit f3c2575818fab45f8609e4aef2e43ab02b3a142e
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Wed Sep 27 18:36:17 2006 +0900

    sh: Calculate shm alignment at runtime.
    
    Set the SHM alignment at runtime, based off of probed cache desc.
    Optimize get_unmapped_area() to only colour align shared mappings.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 731dd61419dd..bfb90eb0b7a6 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -14,6 +14,7 @@
 #include <linux/kernel.h>
 #include <asm/processor.h>
 #include <asm/uaccess.h>
+#include <asm/page.h>
 #include <asm/system.h>
 #include <asm/cacheflush.h>
 #include <asm/cache.h>
@@ -198,6 +199,10 @@ asmlinkage void __init sh_cpu_init(void)
 	/* Init the cache */
 	cache_init();
 
+	shm_align_mask = max_t(unsigned long,
+			       cpu_data->dcache.way_size - 1,
+			       PAGE_SIZE - 1);
+
 	/* Disable the FPU */
 	if (fpu_disabled) {
 		printk("FPU Disabled\n");

commit b638d0b921dc95229af0dfd09cd24850336a2f75
Author: Richard Curnow <richard.curnow@st.com>
Date:   Wed Sep 27 14:09:26 2006 +0900

    sh: Optimized cache handling for SH-4/SH-4A caches.
    
    This reworks some of the SH-4 cache handling code to more easily
    accomodate newer-style caches (particularly for the > direct-mapped
    case), as well as optimizing some of the old code.
    
    Signed-off-by: Richard Curnow <richard.curnow@st.com>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index 868e68b28880..731dd61419dd 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -4,6 +4,7 @@
  * CPU init code
  *
  * Copyright (C) 2002, 2003  Paul Mundt
+ * Copyright (C) 2003  Richard Curnow
  *
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -51,7 +52,15 @@ static void __init cache_init(void)
 	ccr = ctrl_inl(CCR);
 
 	/*
-	 * If the cache is already enabled .. flush it.
+	 * At this point we don't know whether the cache is enabled or not - a
+	 * bootloader may have enabled it.  There are at least 2 things that
+	 * could be dirty in the cache at this point:
+	 * 1. kernel command line set up by boot loader
+	 * 2. spilled registers from the prolog of this function
+	 * => before re-initialising the cache, we must do a purge of the whole
+	 * cache out to memory for safety.  As long as nothing is spilled
+	 * during the loop to lines that have already been done, this is safe.
+	 * - RPC
 	 */
 	if (ccr & CCR_CACHE_ENABLE) {
 		unsigned long ways, waysize, addrstart;
@@ -98,6 +107,8 @@ static void __init cache_init(void)
 	/* Force EMODE if possible */
 	if (cpu_data->dcache.ways > 1)
 		flags |= CCR_CACHE_EMODE;
+	else
+		flags &= ~CCR_CACHE_EMODE;
 #endif
 
 #ifdef CONFIG_SH_WRITETHROUGH
@@ -112,6 +123,9 @@ static void __init cache_init(void)
 	/* Turn on OCRAM -- halve the OC */
 	flags |= CCR_CACHE_ORA;
 	cpu_data->dcache.sets >>= 1;
+
+	cpu_data->dcache.way_size = cpu_data->dcache.sets *
+				    cpu_data->dcache.linesz;
 #endif
 
 	ctrl_outl(flags, CCR);

commit 9b41046cd0ee0a57f849d6e1363f7933e363cca9
Author: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
Date:   Fri Mar 31 02:30:33 2006 -0800

    [PATCH] Don't pass boot parameters to argv_init[]
    
    The boot cmdline is parsed in parse_early_param() and
    parse_args(,unknown_bootoption).
    
    And __setup() is used in obsolete_checksetup().
    
            start_kernel()
                    -> parse_args()
                            -> unknown_bootoption()
                                    -> obsolete_checksetup()
    
    If __setup()'s callback (->setup_func()) returns 1 in
    obsolete_checksetup(), obsolete_checksetup() thinks a parameter was
    handled.
    
    If ->setup_func() returns 0, obsolete_checksetup() tries other
    ->setup_func().  If all ->setup_func() that matched a parameter returns 0,
    a parameter is seted to argv_init[].
    
    Then, when runing /sbin/init or init=app, argv_init[] is passed to the app.
    If the app doesn't ignore those arguments, it will warning and exit.
    
    This patch fixes a wrong usage of it, however fixes obvious one only.
    
    Signed-off-by: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
index cf94e8ef17c5..868e68b28880 100644
--- a/arch/sh/kernel/cpu/init.c
+++ b/arch/sh/kernel/cpu/init.c
@@ -30,7 +30,7 @@ static int x##_disabled __initdata = 0;		\
 static int __init x##_setup(char *opts)		\
 {						\
 	x##_disabled = 1;			\
-	return 0;				\
+	return 1;				\
 }						\
 __setup("no" __stringify(x), x##_setup);
 

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/arch/sh/kernel/cpu/init.c b/arch/sh/kernel/cpu/init.c
new file mode 100644
index 000000000000..cf94e8ef17c5
--- /dev/null
+++ b/arch/sh/kernel/cpu/init.c
@@ -0,0 +1,222 @@
+/*
+ * arch/sh/kernel/cpu/init.c
+ *
+ * CPU init code
+ *
+ * Copyright (C) 2002, 2003  Paul Mundt
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ */
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <asm/processor.h>
+#include <asm/uaccess.h>
+#include <asm/system.h>
+#include <asm/cacheflush.h>
+#include <asm/cache.h>
+#include <asm/io.h>
+
+extern void detect_cpu_and_cache_system(void);
+
+/*
+ * Generic wrapper for command line arguments to disable on-chip
+ * peripherals (nofpu, nodsp, and so forth).
+ */
+#define onchip_setup(x)				\
+static int x##_disabled __initdata = 0;		\
+						\
+static int __init x##_setup(char *opts)		\
+{						\
+	x##_disabled = 1;			\
+	return 0;				\
+}						\
+__setup("no" __stringify(x), x##_setup);
+
+onchip_setup(fpu);
+onchip_setup(dsp);
+
+/*
+ * Generic first-level cache init
+ */
+static void __init cache_init(void)
+{
+	unsigned long ccr, flags;
+
+	if (cpu_data->type == CPU_SH_NONE)
+		panic("Unknown CPU");
+
+	jump_to_P2();
+	ccr = ctrl_inl(CCR);
+
+	/*
+	 * If the cache is already enabled .. flush it.
+	 */
+	if (ccr & CCR_CACHE_ENABLE) {
+		unsigned long ways, waysize, addrstart;
+
+		waysize = cpu_data->dcache.sets;
+
+		/*
+		 * If the OC is already in RAM mode, we only have
+		 * half of the entries to flush..
+		 */
+		if (ccr & CCR_CACHE_ORA)
+			waysize >>= 1;
+
+		waysize <<= cpu_data->dcache.entry_shift;
+
+#ifdef CCR_CACHE_EMODE
+		/* If EMODE is not set, we only have 1 way to flush. */
+		if (!(ccr & CCR_CACHE_EMODE))
+			ways = 1;
+		else
+#endif
+			ways = cpu_data->dcache.ways;
+
+		addrstart = CACHE_OC_ADDRESS_ARRAY;
+		do {
+			unsigned long addr;
+
+			for (addr = addrstart;
+			     addr < addrstart + waysize;
+			     addr += cpu_data->dcache.linesz)
+				ctrl_outl(0, addr);
+
+			addrstart += cpu_data->dcache.way_incr;
+		} while (--ways);
+	}
+
+	/*
+	 * Default CCR values .. enable the caches
+	 * and invalidate them immediately..
+	 */
+	flags = CCR_CACHE_ENABLE | CCR_CACHE_INVALIDATE;
+
+#ifdef CCR_CACHE_EMODE
+	/* Force EMODE if possible */
+	if (cpu_data->dcache.ways > 1)
+		flags |= CCR_CACHE_EMODE;
+#endif
+
+#ifdef CONFIG_SH_WRITETHROUGH
+	/* Turn on Write-through caching */
+	flags |= CCR_CACHE_WT;
+#else
+	/* .. or default to Write-back */
+	flags |= CCR_CACHE_CB;
+#endif
+
+#ifdef CONFIG_SH_OCRAM
+	/* Turn on OCRAM -- halve the OC */
+	flags |= CCR_CACHE_ORA;
+	cpu_data->dcache.sets >>= 1;
+#endif
+
+	ctrl_outl(flags, CCR);
+	back_to_P1();
+}
+
+#ifdef CONFIG_SH_DSP
+static void __init release_dsp(void)
+{
+	unsigned long sr;
+
+	/* Clear SR.DSP bit */
+	__asm__ __volatile__ (
+		"stc\tsr, %0\n\t"
+		"and\t%1, %0\n\t"
+		"ldc\t%0, sr\n\t"
+		: "=&r" (sr)
+		: "r" (~SR_DSP)
+	);
+}
+
+static void __init dsp_init(void)
+{
+	unsigned long sr;
+
+	/*
+	 * Set the SR.DSP bit, wait for one instruction, and then read
+	 * back the SR value.
+	 */
+	__asm__ __volatile__ (
+		"stc\tsr, %0\n\t"
+		"or\t%1, %0\n\t"
+		"ldc\t%0, sr\n\t"
+		"nop\n\t"
+		"stc\tsr, %0\n\t"
+		: "=&r" (sr)
+		: "r" (SR_DSP)
+	);
+
+	/* If the DSP bit is still set, this CPU has a DSP */
+	if (sr & SR_DSP)
+		cpu_data->flags |= CPU_HAS_DSP;
+
+	/* Now that we've determined the DSP status, clear the DSP bit. */
+	release_dsp();
+}
+#endif /* CONFIG_SH_DSP */
+
+/**
+ * sh_cpu_init
+ *
+ * This is our initial entry point for each CPU, and is invoked on the boot
+ * CPU prior to calling start_kernel(). For SMP, a combination of this and
+ * start_secondary() will bring up each processor to a ready state prior
+ * to hand forking the idle loop.
+ *
+ * We do all of the basic processor init here, including setting up the
+ * caches, FPU, DSP, kicking the UBC, etc. By the time start_kernel() is
+ * hit (and subsequently platform_setup()) things like determining the
+ * CPU subtype and initial configuration will all be done.
+ *
+ * Each processor family is still responsible for doing its own probing
+ * and cache configuration in detect_cpu_and_cache_system().
+ */
+asmlinkage void __init sh_cpu_init(void)
+{
+	/* First, probe the CPU */
+	detect_cpu_and_cache_system();
+
+	/* Init the cache */
+	cache_init();
+
+	/* Disable the FPU */
+	if (fpu_disabled) {
+		printk("FPU Disabled\n");
+		cpu_data->flags &= ~CPU_HAS_FPU;
+		disable_fpu();
+	}
+
+	/* FPU initialization */
+	if ((cpu_data->flags & CPU_HAS_FPU)) {
+		clear_thread_flag(TIF_USEDFPU);
+		clear_used_math();
+	}
+
+#ifdef CONFIG_SH_DSP
+	/* Probe for DSP */
+	dsp_init();
+
+	/* Disable the DSP */
+	if (dsp_disabled) {
+		printk("DSP Disabled\n");
+		cpu_data->flags &= ~CPU_HAS_DSP;
+		release_dsp();
+	}
+#endif
+
+#ifdef CONFIG_UBC_WAKEUP
+	/*
+	 * Some brain-damaged loaders decided it would be a good idea to put
+	 * the UBC to sleep. This causes some issues when it comes to things
+	 * like PTRACE_SINGLESTEP or doing hardware watchpoints in GDB.  So ..
+	 * we wake it up and hope that all is well.
+	 */
+	ubc_wakeup();
+#endif
+}
+
