commit 5933f6d220403b55772d2caf48a9a39d777fd630
Author: Kuninori Morimoto <kuninori.morimoto.gx@renesas.com>
Date:   Fri Dec 28 00:32:24 2018 -0800

    sh: kernel: convert to SPDX identifiers
    
    Update license to use SPDX-License-Identifier instead of verbose license
    text.
    
    Link: http://lkml.kernel.org/r/8736rccswn.wl-kuninori.morimoto.gx@renesas.com
    Signed-off-by: Kuninori Morimoto <kuninori.morimoto.gx@renesas.com>
    Reviewed-by: Simon Horman <horms+renesas@verge.net.au>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sh/kernel/unwinder.c b/arch/sh/kernel/unwinder.c
index 521b5432471f..7a54b72dd923 100644
--- a/arch/sh/kernel/unwinder.c
+++ b/arch/sh/kernel/unwinder.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * Copyright (C) 2009  Matt Fleming
  *

commit 60063497a95e716c9a689af3be2687d261f115b4
Author: Arun Sharma <asharma@fb.com>
Date:   Tue Jul 26 16:09:06 2011 -0700

    atomic: use <linux/atomic.h>
    
    This allows us to move duplicated code in <asm/atomic.h>
    (atomic_inc_not_zero() for now) to <linux/atomic.h>
    
    Signed-off-by: Arun Sharma <asharma@fb.com>
    Reviewed-by: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: David Miller <davem@davemloft.net>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Acked-by: Mike Frysinger <vapier@gentoo.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sh/kernel/unwinder.c b/arch/sh/kernel/unwinder.c
index 468889d958f4..521b5432471f 100644
--- a/arch/sh/kernel/unwinder.c
+++ b/arch/sh/kernel/unwinder.c
@@ -13,7 +13,7 @@
 #include <linux/spinlock.h>
 #include <linux/module.h>
 #include <asm/unwinder.h>
-#include <asm/atomic.h>
+#include <linux/atomic.h>
 
 /*
  * This is the most basic stack unwinder an architecture can

commit e115f2c17cbceee93b34d787a7a4a867fc73e7b4
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Sat Aug 22 05:28:25 2009 +0900

    sh: unwinder: Use a special bug flag for unwinder traps.
    
    This simplifies the unwinder trap handling, dropping the use of the
    special trapa vector and simply piggybacking on top of the BUG support. A
    new BUGFLAG_UNWINDER is added for flagging the unwinder fault, before
    continuing on with regular BUG dispatch.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/unwinder.c b/arch/sh/kernel/unwinder.c
index e83861d9739c..468889d958f4 100644
--- a/arch/sh/kernel/unwinder.c
+++ b/arch/sh/kernel/unwinder.c
@@ -161,25 +161,4 @@ void unwind_stack(struct task_struct *task, struct pt_regs *regs,
 
 	curr_unwinder->dump(task, regs, sp, ops, data);
 }
-
-/*
- * Trap handler for UWINDER_BUG() statements. We must switch to the
- * unwinder with the next highest rating.
- */
-BUILD_TRAP_HANDLER(unwinder)
-{
-	insn_size_t insn;
-	TRAP_HANDLER_DECL;
-
-	/* Rewind */
-	regs->pc -= instruction_size(ctrl_inw(regs->pc - 4));
-	insn = *(insn_size_t *)instruction_pointer(regs);
-
-	/* Switch unwinders when unwind_stack() is called */
-	unwinder_faulted = 1;
-
-#ifdef CONFIG_BUG
-	handle_BUG(regs);
-#endif
-}
 EXPORT_SYMBOL_GPL(unwind_stack);

commit c153a58e715e16ffcd6c4b3da7fc6b4a556bf917
Merge: 4ab8f241f6d5 5580e9044df9
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Sat Aug 22 03:49:58 2009 +0900

    Merge branch 'sh/dwarf-unwinder' of git://github.com/mfleming/linux-2.6 into sh/dwarf-unwinder

commit 4ab8f241f6d510470c15b62ac10f6905ff5c97bd
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Sat Aug 22 03:43:15 2009 +0900

    sh: Export unwind_stack() to satisfy modular oprofile.
    
    If the oprofile code is built as a module, unwind_stack() as used by the
    oprofile backtrace code is not available, causing build breakage.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/unwinder.c b/arch/sh/kernel/unwinder.c
index 2b30fa28b440..5f56ff3f55e0 100644
--- a/arch/sh/kernel/unwinder.c
+++ b/arch/sh/kernel/unwinder.c
@@ -11,6 +11,7 @@
 #include <linux/errno.h>
 #include <linux/list.h>
 #include <linux/spinlock.h>
+#include <linux/module.h>
 #include <asm/unwinder.h>
 #include <asm/atomic.h>
 
@@ -160,3 +161,4 @@ void unwind_stack(struct task_struct *task, struct pt_regs *regs,
 
 	atomic_dec(&unwinder_running);
 }
+EXPORT_SYMBOL_GPL(unwind_stack);

commit b344e24a8e8ceda83d1285d22e3e5baf4f5e42d3
Author: Matt Fleming <matt@console-pimps.org>
Date:   Sun Aug 16 21:54:48 2009 +0100

    sh: unwinder: Introduce UNWINDER_BUG() and UNWINDER_BUG_ON()
    
    We can't assume that if we execute the unwinder code and the unwinder
    was already running that it has faulted. Clearly two kernel threads can
    invoke the unwinder at the same time and may be running simultaneously.
    
    The previous approach used BUG() and BUG_ON() in the unwinder code to
    detect whether the unwinder was incapable of unwinding the stack, and
    that the next available unwinder should be used instead. A better
    approach is to explicitly invoke a trap handler to switch unwinders when
    the current unwinder cannot continue.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>

diff --git a/arch/sh/kernel/unwinder.c b/arch/sh/kernel/unwinder.c
index 2b30fa28b440..b9c122abe251 100644
--- a/arch/sh/kernel/unwinder.c
+++ b/arch/sh/kernel/unwinder.c
@@ -53,8 +53,6 @@ static struct list_head unwinder_list = {
 
 static DEFINE_SPINLOCK(unwinder_lock);
 
-static atomic_t unwinder_running = ATOMIC_INIT(0);
-
 /**
  * select_unwinder - Select the best registered stack unwinder.
  *
@@ -122,6 +120,8 @@ int unwinder_register(struct unwinder *u)
 	return ret;
 }
 
+int unwinder_faulted = 0;
+
 /*
  * Unwind the call stack and pass information to the stacktrace_ops
  * functions. Also handle the case where we need to switch to a new
@@ -144,19 +144,40 @@ void unwind_stack(struct task_struct *task, struct pt_regs *regs,
 	 * Hopefully this will give us a semi-reliable stacktrace so we
 	 * can diagnose why curr_unwinder->dump() faulted.
 	 */
-	if (atomic_inc_return(&unwinder_running) != 1) {
+	if (unwinder_faulted) {
 		spin_lock_irqsave(&unwinder_lock, flags);
 
-		if (!list_is_singular(&unwinder_list)) {
+		/* Make sure no one beat us to changing the unwinder */
+		if (unwinder_faulted && !list_is_singular(&unwinder_list)) {
 			list_del(&curr_unwinder->list);
 			curr_unwinder = select_unwinder();
+
+			unwinder_faulted = 0;
 		}
 
 		spin_unlock_irqrestore(&unwinder_lock, flags);
-		atomic_dec(&unwinder_running);
 	}
 
 	curr_unwinder->dump(task, regs, sp, ops, data);
+}
+
+/*
+ * Trap handler for UWINDER_BUG() statements. We must switch to the
+ * unwinder with the next highest rating.
+ */
+BUILD_TRAP_HANDLER(unwinder)
+{
+	insn_size_t insn;
+	TRAP_HANDLER_DECL;
+
+	/* Rewind */
+	regs->pc -= instruction_size(ctrl_inw(regs->pc - 4));
+	insn = *(insn_size_t *)instruction_pointer(regs);
+
+	/* Switch unwinders when unwind_stack() is called */
+	unwinder_faulted = 1;
 
-	atomic_dec(&unwinder_running);
+#ifdef CONFIG_BUG
+	handle_BUG(regs);
+#endif
 }

commit bf61ad1f870be88676a07bfef69acd59ce10172e
Author: Matt Fleming <matt@console-pimps.org>
Date:   Thu Aug 13 19:49:03 2009 +0900

    sh: Allow multiple stack unwinders to be setup
    
    Provide an interface for registering stack unwinders, where each
    unwinder is given a rating that describes its accuracy and
    complexity. The more accurate an unwinder is, the more complex it is.
    
    If a the current stack unwinder faults, then the stack unwinder with the
    next highest accuracy will be used in its place (provided one is
    available). For example, this allows unwinders, such as the DWARF
    unwinder, to liberally sprinkle BUG()s to catch badly formed DWARF debug
    info.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/kernel/unwinder.c b/arch/sh/kernel/unwinder.c
new file mode 100644
index 000000000000..2b30fa28b440
--- /dev/null
+++ b/arch/sh/kernel/unwinder.c
@@ -0,0 +1,162 @@
+/*
+ * Copyright (C) 2009  Matt Fleming
+ *
+ * Based, in part, on kernel/time/clocksource.c.
+ *
+ * This file provides arbitration code for stack unwinders.
+ *
+ * Multiple stack unwinders can be available on a system, usually with
+ * the most accurate unwinder being the currently active one.
+ */
+#include <linux/errno.h>
+#include <linux/list.h>
+#include <linux/spinlock.h>
+#include <asm/unwinder.h>
+#include <asm/atomic.h>
+
+/*
+ * This is the most basic stack unwinder an architecture can
+ * provide. For architectures without reliable frame pointers, e.g.
+ * RISC CPUs, it can be implemented by looking through the stack for
+ * addresses that lie within the kernel text section.
+ *
+ * Other CPUs, e.g. x86, can use their frame pointer register to
+ * construct more accurate stack traces.
+ */
+static struct list_head unwinder_list;
+static struct unwinder stack_reader = {
+	.name = "stack-reader",
+	.dump = stack_reader_dump,
+	.rating = 50,
+	.list = {
+		.next = &unwinder_list,
+		.prev = &unwinder_list,
+	},
+};
+
+/*
+ * "curr_unwinder" points to the stack unwinder currently in use. This
+ * is the unwinder with the highest rating.
+ *
+ * "unwinder_list" is a linked-list of all available unwinders, sorted
+ * by rating.
+ *
+ * All modifications of "curr_unwinder" and "unwinder_list" must be
+ * performed whilst holding "unwinder_lock".
+ */
+static struct unwinder *curr_unwinder = &stack_reader;
+
+static struct list_head unwinder_list = {
+	.next = &stack_reader.list,
+	.prev = &stack_reader.list,
+};
+
+static DEFINE_SPINLOCK(unwinder_lock);
+
+static atomic_t unwinder_running = ATOMIC_INIT(0);
+
+/**
+ * select_unwinder - Select the best registered stack unwinder.
+ *
+ * Private function. Must hold unwinder_lock when called.
+ *
+ * Select the stack unwinder with the best rating. This is useful for
+ * setting up curr_unwinder.
+ */
+static struct unwinder *select_unwinder(void)
+{
+	struct unwinder *best;
+
+	if (list_empty(&unwinder_list))
+		return NULL;
+
+	best = list_entry(unwinder_list.next, struct unwinder, list);
+	if (best == curr_unwinder)
+		return NULL;
+
+	return best;
+}
+
+/*
+ * Enqueue the stack unwinder sorted by rating.
+ */
+static int unwinder_enqueue(struct unwinder *ops)
+{
+	struct list_head *tmp, *entry = &unwinder_list;
+
+	list_for_each(tmp, &unwinder_list) {
+		struct unwinder *o;
+
+		o = list_entry(tmp, struct unwinder, list);
+		if (o == ops)
+			return -EBUSY;
+		/* Keep track of the place, where to insert */
+		if (o->rating >= ops->rating)
+			entry = tmp;
+	}
+	list_add(&ops->list, entry);
+
+	return 0;
+}
+
+/**
+ * unwinder_register - Used to install new stack unwinder
+ * @u: unwinder to be registered
+ *
+ * Install the new stack unwinder on the unwinder list, which is sorted
+ * by rating.
+ *
+ * Returns -EBUSY if registration fails, zero otherwise.
+ */
+int unwinder_register(struct unwinder *u)
+{
+	unsigned long flags;
+	int ret;
+
+	spin_lock_irqsave(&unwinder_lock, flags);
+	ret = unwinder_enqueue(u);
+	if (!ret)
+		curr_unwinder = select_unwinder();
+	spin_unlock_irqrestore(&unwinder_lock, flags);
+
+	return ret;
+}
+
+/*
+ * Unwind the call stack and pass information to the stacktrace_ops
+ * functions. Also handle the case where we need to switch to a new
+ * stack dumper because the current one faulted unexpectedly.
+ */
+void unwind_stack(struct task_struct *task, struct pt_regs *regs,
+		  unsigned long *sp, const struct stacktrace_ops *ops,
+		  void *data)
+{
+	unsigned long flags;
+
+	/*
+	 * The problem with unwinders with high ratings is that they are
+	 * inherently more complicated than the simple ones with lower
+	 * ratings. We are therefore more likely to fault in the
+	 * complicated ones, e.g. hitting BUG()s. If we fault in the
+	 * code for the current stack unwinder we try to downgrade to
+	 * one with a lower rating.
+	 *
+	 * Hopefully this will give us a semi-reliable stacktrace so we
+	 * can diagnose why curr_unwinder->dump() faulted.
+	 */
+	if (atomic_inc_return(&unwinder_running) != 1) {
+		spin_lock_irqsave(&unwinder_lock, flags);
+
+		if (!list_is_singular(&unwinder_list)) {
+			list_del(&curr_unwinder->list);
+			curr_unwinder = select_unwinder();
+		}
+
+		spin_unlock_irqrestore(&unwinder_lock, flags);
+		atomic_dec(&unwinder_running);
+	}
+
+	curr_unwinder->dump(task, regs, sp, ops, data);
+
+	atomic_dec(&unwinder_running);
+}
