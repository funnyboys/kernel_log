commit 59615ecdb516cf218c3699b02d87d9827dc3e0c7
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Fri Jul 2 15:44:09 2010 +0900

    sh: Provide a global TLB flush for U/I-TLB clear.
    
    This provides a sledgehammer approach for clearing the TLBs, only to be
    used in cases where we know we will never want to use the mappings again
    and have no interest in preserving state. This also destroys wired
    entries.
    
    The primary use for this is when we are either entering or exiting the
    kernel completely, in the latter case as a precursor for CPU reset by
    MMU.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/mm/tlbflush_32.c b/arch/sh/mm/tlbflush_32.c
index 3fbe03ce8fe3..a6a20d6de4c0 100644
--- a/arch/sh/mm/tlbflush_32.c
+++ b/arch/sh/mm/tlbflush_32.c
@@ -119,3 +119,19 @@ void local_flush_tlb_mm(struct mm_struct *mm)
 		local_irq_restore(flags);
 	}
 }
+
+void __flush_tlb_global(void)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+
+	/*
+	 * This is the most destructive of the TLB flushing options,
+	 * and will tear down all of the UTLB/ITLB mappings, including
+	 * wired entries.
+	 */
+	__raw_writel(__raw_readl(MMUCR) | MMUCR_TI, MMUCR);
+
+	local_irq_restore(flags);
+}

commit be97d758e5728099e95fe229866d5c6c900d3092
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Fri Apr 2 16:13:27 2010 +0900

    sh: Fix up the SH-3 build for recent TLB changes.
    
    While the MMUCR.URB and ITLB/UTLB differentiation works fine for all SH-4
    and later TLBs, these features are absent on SH-3. This splits out
    local_flush_tlb_all() in to SH-4 and PTEAEX copies while restoring the
    old SH-3 one, subsequently fixing up the build.
    
    This will probably want some further reordering and tidying in the
    future, but that's out of scope at present.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/mm/tlbflush_32.c b/arch/sh/mm/tlbflush_32.c
index 77dc5efa7127..3fbe03ce8fe3 100644
--- a/arch/sh/mm/tlbflush_32.c
+++ b/arch/sh/mm/tlbflush_32.c
@@ -119,31 +119,3 @@ void local_flush_tlb_mm(struct mm_struct *mm)
 		local_irq_restore(flags);
 	}
 }
-
-void local_flush_tlb_all(void)
-{
-	unsigned long flags, status;
-	int i;
-
-	/*
-	 * Flush all the TLB.
-	 */
-	local_irq_save(flags);
-	jump_to_uncached();
-
-	status = __raw_readl(MMUCR);
-	status = ((status & MMUCR_URB) >> MMUCR_URB_SHIFT);
-
-	if (status == 0)
-		status = MMUCR_URB_NENTRIES;
-
-	for (i = 0; i < status; i++)
-		__raw_writel(0x0, MMU_UTLB_ADDRESS_ARRAY | (i << 8));
-
-	for (i = 0; i < 4; i++)
-		__raw_writel(0x0, MMU_ITLB_ADDRESS_ARRAY | (i << 8));
-
-	back_to_cached();
-	ctrl_barrier();
-	local_irq_restore(flags);
-}

commit b5b6c7eea1124de5b110a48ac62650a690ed2419
Author: Matt Fleming <matt@console-pimps.org>
Date:   Sun Mar 21 19:51:52 2010 +0000

    sh: Replace unsafe manipulation of MMUCR
    
    Setting the TI in MMUCR causes all the TLB bits in MMUCR to be
    cleared. Unfortunately, the TLB wired bits are also cleared when setting
    the TI bit, causing any wired TLB entries to become unwired.
    
    Use local_flush_tlb_all() which implements TLB flushing in a safer
    manner by using the memory-mapped TLB registers. As each CPU has its own
    PMB the modifications in pmb_init() only affect the local CPU, so only
    flush the local CPU's TLB.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/mm/tlbflush_32.c b/arch/sh/mm/tlbflush_32.c
index 004bb3f25b5f..77dc5efa7127 100644
--- a/arch/sh/mm/tlbflush_32.c
+++ b/arch/sh/mm/tlbflush_32.c
@@ -123,18 +123,27 @@ void local_flush_tlb_mm(struct mm_struct *mm)
 void local_flush_tlb_all(void)
 {
 	unsigned long flags, status;
+	int i;
 
 	/*
 	 * Flush all the TLB.
-	 *
-	 * Write to the MMU control register's bit:
-	 *	TF-bit for SH-3, TI-bit for SH-4.
-	 *      It's same position, bit #2.
 	 */
 	local_irq_save(flags);
+	jump_to_uncached();
+
 	status = __raw_readl(MMUCR);
-	status |= 0x04;
-	__raw_writel(status, MMUCR);
+	status = ((status & MMUCR_URB) >> MMUCR_URB_SHIFT);
+
+	if (status == 0)
+		status = MMUCR_URB_NENTRIES;
+
+	for (i = 0; i < status; i++)
+		__raw_writel(0x0, MMU_UTLB_ADDRESS_ARRAY | (i << 8));
+
+	for (i = 0; i < 4; i++)
+		__raw_writel(0x0, MMU_ITLB_ADDRESS_ARRAY | (i << 8));
+
+	back_to_cached();
 	ctrl_barrier();
 	local_irq_restore(flags);
 }

commit 9d56dd3b083a3bec56e9da35ce07baca81030b03
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Jan 26 12:58:40 2010 +0900

    sh: Mass ctrl_in/outX to __raw_read/writeX conversion.
    
    The old ctrl in/out routines are non-portable and unsuitable for
    cross-platform use. While drivers/sh has already been sanitized, there
    is still quite a lot of code that is not. This converts the arch/sh/ bits
    over, which permits us to flag the routines as deprecated whilst still
    building with -Werror for the architecture code, and to ensure that
    future users are not added.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/mm/tlbflush_32.c b/arch/sh/mm/tlbflush_32.c
index 6f45c1f8a7fe..004bb3f25b5f 100644
--- a/arch/sh/mm/tlbflush_32.c
+++ b/arch/sh/mm/tlbflush_32.c
@@ -132,9 +132,9 @@ void local_flush_tlb_all(void)
 	 *      It's same position, bit #2.
 	 */
 	local_irq_save(flags);
-	status = ctrl_inl(MMUCR);
+	status = __raw_readl(MMUCR);
 	status |= 0x04;
-	ctrl_outl(status, MMUCR);
+	__raw_writel(status, MMUCR);
 	ctrl_barrier();
 	local_irq_restore(flags);
 }

commit efddb4c882a64b7ca44b2a089d20020b30a2c6dd
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Wed Nov 21 22:30:58 2007 +0900

    sh: Rename the _32 and _64 TLB flush variants.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/mm/tlbflush_32.c b/arch/sh/mm/tlbflush_32.c
new file mode 100644
index 000000000000..6f45c1f8a7fe
--- /dev/null
+++ b/arch/sh/mm/tlbflush_32.c
@@ -0,0 +1,140 @@
+/*
+ * TLB flushing operations for SH with an MMU.
+ *
+ *  Copyright (C) 1999  Niibe Yutaka
+ *  Copyright (C) 2003  Paul Mundt
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ */
+#include <linux/mm.h>
+#include <asm/mmu_context.h>
+#include <asm/tlbflush.h>
+
+void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)
+{
+	unsigned int cpu = smp_processor_id();
+
+	if (vma->vm_mm && cpu_context(cpu, vma->vm_mm) != NO_CONTEXT) {
+		unsigned long flags;
+		unsigned long asid;
+		unsigned long saved_asid = MMU_NO_ASID;
+
+		asid = cpu_asid(cpu, vma->vm_mm);
+		page &= PAGE_MASK;
+
+		local_irq_save(flags);
+		if (vma->vm_mm != current->mm) {
+			saved_asid = get_asid();
+			set_asid(asid);
+		}
+		local_flush_tlb_one(asid, page);
+		if (saved_asid != MMU_NO_ASID)
+			set_asid(saved_asid);
+		local_irq_restore(flags);
+	}
+}
+
+void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
+			   unsigned long end)
+{
+	struct mm_struct *mm = vma->vm_mm;
+	unsigned int cpu = smp_processor_id();
+
+	if (cpu_context(cpu, mm) != NO_CONTEXT) {
+		unsigned long flags;
+		int size;
+
+		local_irq_save(flags);
+		size = (end - start + (PAGE_SIZE - 1)) >> PAGE_SHIFT;
+		if (size > (MMU_NTLB_ENTRIES/4)) { /* Too many TLB to flush */
+			cpu_context(cpu, mm) = NO_CONTEXT;
+			if (mm == current->mm)
+				activate_context(mm, cpu);
+		} else {
+			unsigned long asid;
+			unsigned long saved_asid = MMU_NO_ASID;
+
+			asid = cpu_asid(cpu, mm);
+			start &= PAGE_MASK;
+			end += (PAGE_SIZE - 1);
+			end &= PAGE_MASK;
+			if (mm != current->mm) {
+				saved_asid = get_asid();
+				set_asid(asid);
+			}
+			while (start < end) {
+				local_flush_tlb_one(asid, start);
+				start += PAGE_SIZE;
+			}
+			if (saved_asid != MMU_NO_ASID)
+				set_asid(saved_asid);
+		}
+		local_irq_restore(flags);
+	}
+}
+
+void local_flush_tlb_kernel_range(unsigned long start, unsigned long end)
+{
+	unsigned int cpu = smp_processor_id();
+	unsigned long flags;
+	int size;
+
+	local_irq_save(flags);
+	size = (end - start + (PAGE_SIZE - 1)) >> PAGE_SHIFT;
+	if (size > (MMU_NTLB_ENTRIES/4)) { /* Too many TLB to flush */
+		local_flush_tlb_all();
+	} else {
+		unsigned long asid;
+		unsigned long saved_asid = get_asid();
+
+		asid = cpu_asid(cpu, &init_mm);
+		start &= PAGE_MASK;
+		end += (PAGE_SIZE - 1);
+		end &= PAGE_MASK;
+		set_asid(asid);
+		while (start < end) {
+			local_flush_tlb_one(asid, start);
+			start += PAGE_SIZE;
+		}
+		set_asid(saved_asid);
+	}
+	local_irq_restore(flags);
+}
+
+void local_flush_tlb_mm(struct mm_struct *mm)
+{
+	unsigned int cpu = smp_processor_id();
+
+	/* Invalidate all TLB of this process. */
+	/* Instead of invalidating each TLB, we get new MMU context. */
+	if (cpu_context(cpu, mm) != NO_CONTEXT) {
+		unsigned long flags;
+
+		local_irq_save(flags);
+		cpu_context(cpu, mm) = NO_CONTEXT;
+		if (mm == current->mm)
+			activate_context(mm, cpu);
+		local_irq_restore(flags);
+	}
+}
+
+void local_flush_tlb_all(void)
+{
+	unsigned long flags, status;
+
+	/*
+	 * Flush all the TLB.
+	 *
+	 * Write to the MMU control register's bit:
+	 *	TF-bit for SH-3, TI-bit for SH-4.
+	 *      It's same position, bit #2.
+	 */
+	local_irq_save(flags);
+	status = ctrl_inl(MMUCR);
+	status |= 0x04;
+	ctrl_outl(status, MMUCR);
+	ctrl_barrier();
+	local_irq_restore(flags);
+}
