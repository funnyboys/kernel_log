commit 952ec41c44a4e9802f2c991912c117d2347832af
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun Jun 7 21:42:28 2020 -0700

    sh: implement flush_icache_user_range
    
    The SuperH implementation of flush_icache_range seems to be able to cope
    with user addresses.  Just define flush_icache_user_range to
    flush_icache_range.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Rich Felker <dalias@libc.org>
    Link: http://lkml.kernel.org/r/20200515143646.3857579-22-hch@lst.de
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index b932e42ef028..fe7400079b97 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -46,6 +46,7 @@ extern void flush_cache_range(struct vm_area_struct *vma,
 #define ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE 1
 extern void flush_dcache_page(struct page *page);
 extern void flush_icache_range(unsigned long start, unsigned long end);
+#define flush_icache_user_range flush_icache_range
 extern void flush_icache_page(struct vm_area_struct *vma,
 				 struct page *page);
 extern void flush_cache_sigtramp(unsigned long address);

commit 47fcae0d2a5fc77123fc14b0db9fe0025a1a829a
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Apr 18 08:53:46 2018 +0200

    sh: introduce a sh_cacheop_vaddr helper
    
    And use it in the maple bus code to avoid a dma API dependency.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Yoshinori Sato <ysato@users.sourceforge.jp>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index d103ab5a4e4b..b932e42ef028 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -101,5 +101,12 @@ void kunmap_coherent(void *kvaddr);
 
 void cpu_cache_init(void);
 
+static inline void *sh_cacheop_vaddr(void *vaddr)
+{
+	if (__in_29bit_mode())
+		vaddr = (void *)CAC_ADDR((unsigned long)vaddr);
+	return vaddr;
+}
+
 #endif /* __KERNEL__ */
 #endif /* __ASM_SH_CACHEFLUSH_H */

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index 82e1eabeac98..d103ab5a4e4b 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef __ASM_SH_CACHEFLUSH_H
 #define __ASM_SH_CACHEFLUSH_H
 

commit 55661fc1f105ed75852e937bf8ea408270eb0cca
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Wed Dec 1 15:39:51 2010 +0900

    sh: Assume new page cache pages have dirty dcache lines.
    
    This follows the ARM change c01778001a4f5ad9c62d882776235f3f31922fdd
    ("ARM: 6379/1: Assume new page cache pages have dirty D-cache") for the
    same rationale:
    
        There are places in Linux where writes to newly allocated page
        cache pages happen without a subsequent call to flush_dcache_page()
        (several PIO drivers including USB HCD). This patch changes the
        meaning of PG_arch_1 to be PG_dcache_clean and always flush the
        D-cache for a newly mapped page in update_mmu_cache().
    
    This addresses issues seen with executing binaries from MMC, in
    addition to some of the other HCDs that don't explicitly do cache
    management for their pipe-in buffers.
    
    Requested-by: Yoshihiro Shimoda <yoshihiro.shimoda.uh@renesas.com>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index 1f4e562c5e8c..82e1eabeac98 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -96,7 +96,7 @@ void kmap_coherent_init(void);
 void *kmap_coherent(struct page *page, unsigned long addr);
 void kunmap_coherent(void *kvaddr);
 
-#define PG_dcache_dirty	PG_arch_1
+#define PG_dcache_clean	PG_arch_1
 
 void cpu_cache_init(void);
 

commit b07f6b327e798610bebaa581ffb7a226f3bcb96b
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Thu Mar 4 16:47:30 2010 +0900

    sh: Fix up flush_cache_vmap() on SMP.
    
    flush_cache_all() uses broadcast IPIs, so we can't wrap in to that when
    IRQs are disabled. The local cache flush manages to do what we need here
    anyways, so just switch to that.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index da3ebec921a7..1f4e562c5e8c 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -86,8 +86,8 @@ extern void copy_from_user_page(struct vm_area_struct *vma,
 	struct page *page, unsigned long vaddr, void *dst, const void *src,
 	unsigned long len);
 
-#define flush_cache_vmap(start, end)		flush_cache_all()
-#define flush_cache_vunmap(start, end)		flush_cache_all()
+#define flush_cache_vmap(start, end)		local_flush_cache_all(NULL)
+#define flush_cache_vunmap(start, end)		local_flush_cache_all(NULL)
 
 #define flush_dcache_mmap_lock(mapping)		do { } while (0)
 #define flush_dcache_mmap_unlock(mapping)	do { } while (0)

commit c9334f6067dbe0380141fc75b122e0a533878838
Author: James Bottomley <James.Bottomley@suse.de>
Date:   Mon Jan 25 11:42:23 2010 -0600

    sh: add mm API for DMA to vmalloc/vmap areas
    
    Signed-off-by: James Bottomley <James.Bottomley@suse.de>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index dda96eb3e7c0..da3ebec921a7 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -63,6 +63,14 @@ static inline void flush_anon_page(struct vm_area_struct *vma,
 	if (boot_cpu_data.dcache.n_aliases && PageAnon(page))
 		__flush_anon_page(page, vmaddr);
 }
+static inline void flush_kernel_vmap_range(void *addr, int size)
+{
+	__flush_wback_region(addr, size);
+}
+static inline void invalidate_kernel_vmap_range(void *addr, int size)
+{
+	__flush_invalidate_region(addr, size);
+}
 
 #define ARCH_HAS_FLUSH_KERNEL_DCACHE_PAGE
 static inline void flush_kernel_dcache_page(struct page *page)

commit 2d4dc890b5c8fabd818a8586607e6843c4375e62
Author: Ilya Loginov <isloginov@gmail.com>
Date:   Thu Nov 26 09:16:19 2009 +0100

    block: add helpers to run flush_dcache_page() against a bio and a request's pages
    
    Mtdblock driver doesn't call flush_dcache_page for pages in request.  So,
    this causes problems on architectures where the icache doesn't fill from
    the dcache or with dcache aliases.  The patch fixes this.
    
    The ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE symbol was introduced to avoid
    pointless empty cache-thrashing loops on architectures for which
    flush_dcache_page() is a no-op.  Every architecture was provided with this
    flush pages on architectires where ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE is
    equal 1 or do nothing otherwise.
    
    See "fix mtd_blkdevs problem with caches on some architectures" discussion
    on LKML for more information.
    
    Signed-off-by: Ilya Loginov <isloginov@gmail.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Peter Horton <phorton@bitbox.co.uk>
    Cc: "Ed L. Cashin" <ecashin@coraid.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index c29918f3c819..dda96eb3e7c0 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -42,6 +42,7 @@ extern void flush_cache_page(struct vm_area_struct *vma,
 				unsigned long addr, unsigned long pfn);
 extern void flush_cache_range(struct vm_area_struct *vma,
 				 unsigned long start, unsigned long end);
+#define ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE 1
 extern void flush_dcache_page(struct page *page);
 extern void flush_icache_range(unsigned long start, unsigned long end);
 extern void flush_icache_page(struct vm_area_struct *vma,

commit 0906a3ad33a254094fb74828e3ddb9af8771a6da
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Thu Sep 3 17:21:10 2009 +0900

    sh: Fix up and optimize the kmap_coherent() interface.
    
    This fixes up the kmap_coherent/kunmap_coherent() interface for recent
    changes both in the page fault path and the shared cache flushers, as
    well as adding in some optimizations.
    
    One of the key things to note here is that the TLB flush itself is
    deferred until the unmap, and the call in to update_mmu_cache() itself
    goes away, relying on the regular page fault path to handle the lazy
    dcache writeback if necessary.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index 11e416630585..c29918f3c819 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -85,7 +85,7 @@ extern void copy_from_user_page(struct vm_area_struct *vma,
 
 void kmap_coherent_init(void);
 void *kmap_coherent(struct page *page, unsigned long addr);
-void kunmap_coherent(void);
+void kunmap_coherent(void *kvaddr);
 
 #define PG_dcache_dirty	PG_arch_1
 

commit f26b2a562b46ab186c8383993ab1332673ac4a47
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Fri Aug 21 17:23:14 2009 +0900

    sh: Make cache flushers SMP-aware.
    
    This does a bit of rework for making the cache flushers SMP-aware. The
    function pointer-based flushers are renamed to local variants with the
    exported interface being commonly implemented and wrapping as necessary.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index 32299b7c2b48..11e416630585 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -19,23 +19,40 @@
  *  - flush_icache_page(vma, pg) flushes(invalidates) a page for icache
  *  - flush_cache_sigtramp(vaddr) flushes the signal trampoline
  */
-extern void (*flush_cache_all)(void);
-extern void (*flush_cache_mm)(struct mm_struct *mm);
-extern void (*flush_cache_dup_mm)(struct mm_struct *mm);
-extern void (*flush_cache_page)(struct vm_area_struct *vma,
-				unsigned long addr, unsigned long pfn);
-extern void (*flush_cache_range)(struct vm_area_struct *vma,
-				 unsigned long start, unsigned long end);
-extern void (*flush_dcache_page)(struct page *page);
-extern void (*flush_icache_range)(unsigned long start, unsigned long end);
-extern void (*flush_icache_page)(struct vm_area_struct *vma,
-				 struct page *page);
-extern void (*flush_cache_sigtramp)(unsigned long address);
+extern void (*local_flush_cache_all)(void *args);
+extern void (*local_flush_cache_mm)(void *args);
+extern void (*local_flush_cache_dup_mm)(void *args);
+extern void (*local_flush_cache_page)(void *args);
+extern void (*local_flush_cache_range)(void *args);
+extern void (*local_flush_dcache_page)(void *args);
+extern void (*local_flush_icache_range)(void *args);
+extern void (*local_flush_icache_page)(void *args);
+extern void (*local_flush_cache_sigtramp)(void *args);
+
+static inline void cache_noop(void *args) { }
 
 extern void (*__flush_wback_region)(void *start, int size);
 extern void (*__flush_purge_region)(void *start, int size);
 extern void (*__flush_invalidate_region)(void *start, int size);
 
+extern void flush_cache_all(void);
+extern void flush_cache_mm(struct mm_struct *mm);
+extern void flush_cache_dup_mm(struct mm_struct *mm);
+extern void flush_cache_page(struct vm_area_struct *vma,
+				unsigned long addr, unsigned long pfn);
+extern void flush_cache_range(struct vm_area_struct *vma,
+				 unsigned long start, unsigned long end);
+extern void flush_dcache_page(struct page *page);
+extern void flush_icache_range(unsigned long start, unsigned long end);
+extern void flush_icache_page(struct vm_area_struct *vma,
+				 struct page *page);
+extern void flush_cache_sigtramp(unsigned long address);
+
+struct flusher_data {
+	struct vm_area_struct *vma;
+	unsigned long addr1, addr2;
+};
+
 #define ARCH_HAS_FLUSH_ANON_PAGE
 extern void __flush_anon_page(struct page *page, unsigned long);
 

commit f9bd71f255b4349c4f9f596863161fd5182f67fa
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Fri Aug 21 16:20:57 2009 +0900

    sh: Kill off unused cpu/cacheflush.h.
    
    All CPU-specific overloads are done at runtime now, so this common header
    can go away and simply be folded back in to asm/ version.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index 25b7f46494de..32299b7c2b48 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -4,7 +4,37 @@
 #ifdef __KERNEL__
 
 #include <linux/mm.h>
-#include <cpu/cacheflush.h>
+
+/*
+ * Cache flushing:
+ *
+ *  - flush_cache_all() flushes entire cache
+ *  - flush_cache_mm(mm) flushes the specified mm context's cache lines
+ *  - flush_cache_dup mm(mm) handles cache flushing when forking
+ *  - flush_cache_page(mm, vmaddr, pfn) flushes a single page
+ *  - flush_cache_range(vma, start, end) flushes a range of pages
+ *
+ *  - flush_dcache_page(pg) flushes(wback&invalidates) a page for dcache
+ *  - flush_icache_range(start, end) flushes(invalidates) a range for icache
+ *  - flush_icache_page(vma, pg) flushes(invalidates) a page for icache
+ *  - flush_cache_sigtramp(vaddr) flushes the signal trampoline
+ */
+extern void (*flush_cache_all)(void);
+extern void (*flush_cache_mm)(struct mm_struct *mm);
+extern void (*flush_cache_dup_mm)(struct mm_struct *mm);
+extern void (*flush_cache_page)(struct vm_area_struct *vma,
+				unsigned long addr, unsigned long pfn);
+extern void (*flush_cache_range)(struct vm_area_struct *vma,
+				 unsigned long start, unsigned long end);
+extern void (*flush_dcache_page)(struct page *page);
+extern void (*flush_icache_range)(unsigned long start, unsigned long end);
+extern void (*flush_icache_page)(struct vm_area_struct *vma,
+				 struct page *page);
+extern void (*flush_cache_sigtramp)(unsigned long address);
+
+extern void (*__flush_wback_region)(void *start, int size);
+extern void (*__flush_purge_region)(void *start, int size);
+extern void (*__flush_invalidate_region)(void *start, int size);
 
 #define ARCH_HAS_FLUSH_ANON_PAGE
 extern void __flush_anon_page(struct page *page, unsigned long);

commit 37443ef3f0406e855e169c87ae3f4ffb4b6ff635
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Sat Aug 15 12:29:49 2009 +0900

    sh: Migrate SH-4 cacheflush ops to function pointers.
    
    This paves the way for allowing individual CPUs to overload the
    individual flushing routines that they care about without having to
    depend on weak aliases. SH-4 is converted over initially, as it wires
    up pretty much everything. The majority of the other CPUs will simply use
    the default no-op implementation with their own region flushers wired up.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index b1cf30f423af..25b7f46494de 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -1,46 +1,11 @@
 #ifndef __ASM_SH_CACHEFLUSH_H
 #define __ASM_SH_CACHEFLUSH_H
 
-#include <linux/mm.h>
-
 #ifdef __KERNEL__
 
-#ifdef CONFIG_CACHE_OFF
-/*
- * Nothing to do when the cache is disabled, initial flush and explicit
- * disabling is handled at CPU init time.
- *
- * See arch/sh/kernel/cpu/init.c:cache_init().
- */
-#define flush_cache_all()			do { } while (0)
-#define flush_cache_mm(mm)			do { } while (0)
-#define flush_cache_dup_mm(mm)			do { } while (0)
-#define flush_cache_range(vma, start, end)	do { } while (0)
-#define flush_cache_page(vma, vmaddr, pfn)	do { } while (0)
-#define flush_dcache_page(page)			do { } while (0)
-#define flush_icache_range(start, end)		do { } while (0)
-#define flush_icache_page(vma,pg)		do { } while (0)
-#define flush_cache_sigtramp(vaddr)		do { } while (0)
-#define __flush_wback_region(start, size)	do { (void)(start); } while (0)
-#define __flush_purge_region(start, size)	do { (void)(start); } while (0)
-#define __flush_invalidate_region(start, size)	do { (void)(start); } while (0)
-#else
+#include <linux/mm.h>
 #include <cpu/cacheflush.h>
 
-/*
- * Consistent DMA requires that the __flush_xxx() primitives must be set
- * for any of the enabled non-coherent caches (most of the UP CPUs),
- * regardless of PIPT or VIPT cache configurations.
- */
-
-/* Flush (write-back only) a region (smaller than a page) */
-extern void __flush_wback_region(void *start, int size);
-/* Flush (write-back & invalidate) a region (smaller than a page) */
-extern void __flush_purge_region(void *start, int size);
-/* Flush (invalidate only) a region (smaller than a page) */
-extern void __flush_invalidate_region(void *start, int size);
-#endif
-
 #define ARCH_HAS_FLUSH_ANON_PAGE
 extern void __flush_anon_page(struct page *page, unsigned long);
 

commit 916e97834e023f89b31f796b53cc9c7956e7fe17
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Sat Aug 15 11:38:05 2009 +0900

    sh: Kill off unused flush_icache_user_range().
    
    We use flush_cache_page() outright in copy_to_user_page(), and nothing
    else needs it, so just kill it off. SH-5 still defines its own version,
    but that too will go away in the same fashion once it converts over.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index 52488eb6b739..b1cf30f423af 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -21,7 +21,6 @@
 #define flush_icache_range(start, end)		do { } while (0)
 #define flush_icache_page(vma,pg)		do { } while (0)
 #define flush_cache_sigtramp(vaddr)		do { } while (0)
-#define flush_icache_user_range(vma,pg,adr,len)	do { } while (0)
 #define __flush_wback_region(start, size)	do { (void)(start); } while (0)
 #define __flush_purge_region(start, size)	do { (void)(start); } while (0)
 #define __flush_invalidate_region(start, size)	do { (void)(start); } while (0)

commit 7fbb2d3bdd33e58f54e360df0723d754f0b66153
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Sat Aug 15 11:25:32 2009 +0900

    sh: consolidate flush_dcache_mmap_lock/unlock() definitions.
    
    All of the flush_dcache_mmap_lock()/flush_dcache_mmap_unlock()
    definitions are identical across all CPUs, so just provide them
    generically in asm/cacheflush.h.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index e37654f7f545..52488eb6b739 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -20,8 +20,6 @@
 #define flush_dcache_page(page)			do { } while (0)
 #define flush_icache_range(start, end)		do { } while (0)
 #define flush_icache_page(vma,pg)		do { } while (0)
-#define flush_dcache_mmap_lock(mapping)		do { } while (0)
-#define flush_dcache_mmap_unlock(mapping)	do { } while (0)
 #define flush_cache_sigtramp(vaddr)		do { } while (0)
 #define flush_icache_user_range(vma,pg,adr,len)	do { } while (0)
 #define __flush_wback_region(start, size)	do { (void)(start); } while (0)
@@ -71,6 +69,9 @@ extern void copy_from_user_page(struct vm_area_struct *vma,
 #define flush_cache_vmap(start, end)		flush_cache_all()
 #define flush_cache_vunmap(start, end)		flush_cache_all()
 
+#define flush_dcache_mmap_lock(mapping)		do { } while (0)
+#define flush_dcache_mmap_unlock(mapping)	do { } while (0)
+
 void kmap_coherent_init(void);
 void *kmap_coherent(struct page *page, unsigned long addr);
 void kunmap_coherent(void);

commit ecba1060583635ab55092072441ff903b5e9a659
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Sat Aug 15 11:05:42 2009 +0900

    sh: Centralize the CPU cache initialization routines.
    
    This provides a central point for CPU cache initialization routines.
    This replaces the antiquated p3_cache_init() method, which the vast
    majority of CPUs never cared about.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index 9ec13fb909dd..e37654f7f545 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -12,7 +12,6 @@
  *
  * See arch/sh/kernel/cpu/init.c:cache_init().
  */
-#define p3_cache_init()				do { } while (0)
 #define flush_cache_all()			do { } while (0)
 #define flush_cache_mm(mm)			do { } while (0)
 #define flush_cache_dup_mm(mm)			do { } while (0)
@@ -78,5 +77,7 @@ void kunmap_coherent(void);
 
 #define PG_dcache_dirty	PG_arch_1
 
+void cpu_cache_init(void);
+
 #endif /* __KERNEL__ */
 #endif /* __ASM_SH_CACHEFLUSH_H */

commit dde5e3ffb770ef2854bbc32c51a365e932919e19
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Sat Aug 15 09:49:32 2009 +0900

    sh: rework nommu for generic cache.c use.
    
    This does a bit of reorganizing for allowing nommu to use the new
    and generic cache.c, no functional changes.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index 4bf621e4146d..9ec13fb909dd 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -76,5 +76,7 @@ void kmap_coherent_init(void);
 void *kmap_coherent(struct page *page, unsigned long addr);
 void kunmap_coherent(void);
 
+#define PG_dcache_dirty	PG_arch_1
+
 #endif /* __KERNEL__ */
 #endif /* __ASM_SH_CACHEFLUSH_H */

commit cbbe2f68f678a90bebeb30b8a7fcd8aed0614879
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Sat Aug 15 09:30:39 2009 +0900

    sh: rename pg-mmu.c -> cache.c, enable generically.
    
    This builds in the newly created cache.c (renamed from pg-mmu.c) for both
    MMU and NOMMU configurations. The kmap_coherent() stubs and alias
    information recorded by each CPU family takes care of doing the right
    thing while enabling the code to be commonly shared.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index 0e87e87cc01f..4bf621e4146d 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -45,7 +45,6 @@ extern void __flush_purge_region(void *start, int size);
 extern void __flush_invalidate_region(void *start, int size);
 #endif
 
-#ifdef CONFIG_MMU
 #define ARCH_HAS_FLUSH_ANON_PAGE
 extern void __flush_anon_page(struct page *page, unsigned long);
 
@@ -55,7 +54,6 @@ static inline void flush_anon_page(struct vm_area_struct *vma,
 	if (boot_cpu_data.dcache.n_aliases && PageAnon(page))
 		__flush_anon_page(page, vmaddr);
 }
-#endif
 
 #define ARCH_HAS_FLUSH_KERNEL_DCACHE_PAGE
 static inline void flush_kernel_dcache_page(struct page *page)

commit 2739742c24f1a55365e71f0722bfdce8994e9c4e
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Sat Aug 15 09:19:19 2009 +0900

    sh: Provide the kmap_coherent() interface generically.
    
    This plugs in kmap_coherent() for the non-SH4 cases to permit the
    pg-mmu.c bits to be used generically across all CPUs. SH-5 is still in
    the TODO state, but will move over to fixmap and the generic interface
    gradually.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index 5dffbd126e46..0e87e87cc01f 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -74,5 +74,9 @@ extern void copy_from_user_page(struct vm_area_struct *vma,
 #define flush_cache_vmap(start, end)		flush_cache_all()
 #define flush_cache_vunmap(start, end)		flush_cache_all()
 
+void kmap_coherent_init(void);
+void *kmap_coherent(struct page *page, unsigned long addr);
+void kunmap_coherent(void);
+
 #endif /* __KERNEL__ */
 #endif /* __ASM_SH_CACHEFLUSH_H */

commit c0fe478dbb14fd32e71d1383dbe302b54ce94134
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Aug 4 16:02:43 2009 +0900

    sh: Provide __flush_anon_page().
    
    This provides a __flush_anon_page() that handles both the aliasing and
    non-aliasing cases. This fixes up some crashes with heavy
    get_user_pages() users.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index 4c85d55847cc..5dffbd126e46 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -1,6 +1,8 @@
 #ifndef __ASM_SH_CACHEFLUSH_H
 #define __ASM_SH_CACHEFLUSH_H
 
+#include <linux/mm.h>
+
 #ifdef __KERNEL__
 
 #ifdef CONFIG_CACHE_OFF
@@ -43,6 +45,18 @@ extern void __flush_purge_region(void *start, int size);
 extern void __flush_invalidate_region(void *start, int size);
 #endif
 
+#ifdef CONFIG_MMU
+#define ARCH_HAS_FLUSH_ANON_PAGE
+extern void __flush_anon_page(struct page *page, unsigned long);
+
+static inline void flush_anon_page(struct vm_area_struct *vma,
+				   struct page *page, unsigned long vmaddr)
+{
+	if (boot_cpu_data.dcache.n_aliases && PageAnon(page))
+		__flush_anon_page(page, vmaddr);
+}
+#endif
+
 #define ARCH_HAS_FLUSH_KERNEL_DCACHE_PAGE
 static inline void flush_kernel_dcache_page(struct page *page)
 {

commit 0dfae7d5a21901b28ec0452d71be64adf5ea323e
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Jul 27 21:30:17 2009 +0900

    sh: Use the now generic SH-4 clear/copy page ops for all MMU platforms.
    
    Now that the SH-4 page clear/copy ops are generic, they can be used for
    all platforms with CONFIG_MMU=y. SH-5 remains the odd one out, but it too
    will gradually be converted over to using this interface.
    
    SH-3 platforms which do not contain aliases will see no impact from this
    change, while aliasing SH-3 platforms will get the same interface as
    SH-4.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index 4e360114269d..4c85d55847cc 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -49,7 +49,6 @@ static inline void flush_kernel_dcache_page(struct page *page)
 	flush_dcache_page(page);
 }
 
-#if (defined(CONFIG_CPU_SH4) || defined(CONFIG_SH7705_CACHE_32KB)) && !defined(CONFIG_CACHE_OFF)
 extern void copy_to_user_page(struct vm_area_struct *vma,
 	struct page *page, unsigned long vaddr, void *dst, const void *src,
 	unsigned long len);
@@ -57,20 +56,6 @@ extern void copy_to_user_page(struct vm_area_struct *vma,
 extern void copy_from_user_page(struct vm_area_struct *vma,
 	struct page *page, unsigned long vaddr, void *dst, const void *src,
 	unsigned long len);
-#else
-#define copy_to_user_page(vma, page, vaddr, dst, src, len)	\
-	do {							\
-		flush_cache_page(vma, vaddr, page_to_pfn(page));\
-		memcpy(dst, src, len);				\
-		flush_icache_user_range(vma, page, vaddr, len);	\
-	} while (0)
-
-#define copy_from_user_page(vma, page, vaddr, dst, src, len)	\
-	do {							\
-		flush_cache_page(vma, vaddr, page_to_pfn(page));\
-		memcpy(dst, src, len);				\
-	} while (0)
-#endif
 
 #define flush_cache_vmap(start, end)		flush_cache_all()
 #define flush_cache_vunmap(start, end)		flush_cache_all()

commit dfff0fa65ab15db45acd64b3189787d37ab163cd
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Jul 27 20:53:22 2009 +0900

    sh: wire up clear_user_highpage() for sh4, convert sh7705.
    
    This wires up clear_user_highpage() on SH-4 and subsequently converts the
    SH7705 32kB cache mode over to using it. Now that the SH-4 implementation
    handles all of the dcache purging directly in the aliasing case, there is
    no need to do this in the default clear_page() implementation.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index 4c5462daa74c..4e360114269d 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -49,7 +49,7 @@ static inline void flush_kernel_dcache_page(struct page *page)
 	flush_dcache_page(page);
 }
 
-#if defined(CONFIG_CPU_SH4) && !defined(CONFIG_CACHE_OFF)
+#if (defined(CONFIG_CPU_SH4) || defined(CONFIG_SH7705_CACHE_32KB)) && !defined(CONFIG_CACHE_OFF)
 extern void copy_to_user_page(struct vm_area_struct *vma,
 	struct page *page, unsigned long vaddr, void *dst, const void *src,
 	unsigned long len);

commit ee1acbfabd5270b40ce2cfdc202070b7ca91cdff
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Thu May 7 16:38:16 2009 +0900

    sh: Handle shm_align_mask also for HAVE_ARCH_UNMAPPED_AREA_TOPDOWN.
    
    Presently shm_align_mask is only looked at for the bottom up case, but we
    still want this for proper colouring constraints in the topdown case.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
index 09acbc32d6c7..4c5462daa74c 100644
--- a/arch/sh/include/asm/cacheflush.h
+++ b/arch/sh/include/asm/cacheflush.h
@@ -75,7 +75,5 @@ extern void copy_from_user_page(struct vm_area_struct *vma,
 #define flush_cache_vmap(start, end)		flush_cache_all()
 #define flush_cache_vunmap(start, end)		flush_cache_all()
 
-#define HAVE_ARCH_UNMAPPED_AREA
-
 #endif /* __KERNEL__ */
 #endif /* __ASM_SH_CACHEFLUSH_H */

commit f15cbe6f1a4b4d9df59142fc8e4abb973302cf44
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Jul 29 08:09:44 2008 +0900

    sh: migrate to arch/sh/include/
    
    This follows the sparc changes a439fe51a1f8eb087c22dd24d69cebae4a3addac.
    
    Most of the moving about was done with Sam's directions at:
    
    http://marc.info/?l=linux-sh&m=121724823706062&w=2
    
    with subsequent hacking and fixups entirely my fault.
    
    Signed-off-by: Sam Ravnborg <sam@ravnborg.org>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/cacheflush.h b/arch/sh/include/asm/cacheflush.h
new file mode 100644
index 000000000000..09acbc32d6c7
--- /dev/null
+++ b/arch/sh/include/asm/cacheflush.h
@@ -0,0 +1,81 @@
+#ifndef __ASM_SH_CACHEFLUSH_H
+#define __ASM_SH_CACHEFLUSH_H
+
+#ifdef __KERNEL__
+
+#ifdef CONFIG_CACHE_OFF
+/*
+ * Nothing to do when the cache is disabled, initial flush and explicit
+ * disabling is handled at CPU init time.
+ *
+ * See arch/sh/kernel/cpu/init.c:cache_init().
+ */
+#define p3_cache_init()				do { } while (0)
+#define flush_cache_all()			do { } while (0)
+#define flush_cache_mm(mm)			do { } while (0)
+#define flush_cache_dup_mm(mm)			do { } while (0)
+#define flush_cache_range(vma, start, end)	do { } while (0)
+#define flush_cache_page(vma, vmaddr, pfn)	do { } while (0)
+#define flush_dcache_page(page)			do { } while (0)
+#define flush_icache_range(start, end)		do { } while (0)
+#define flush_icache_page(vma,pg)		do { } while (0)
+#define flush_dcache_mmap_lock(mapping)		do { } while (0)
+#define flush_dcache_mmap_unlock(mapping)	do { } while (0)
+#define flush_cache_sigtramp(vaddr)		do { } while (0)
+#define flush_icache_user_range(vma,pg,adr,len)	do { } while (0)
+#define __flush_wback_region(start, size)	do { (void)(start); } while (0)
+#define __flush_purge_region(start, size)	do { (void)(start); } while (0)
+#define __flush_invalidate_region(start, size)	do { (void)(start); } while (0)
+#else
+#include <cpu/cacheflush.h>
+
+/*
+ * Consistent DMA requires that the __flush_xxx() primitives must be set
+ * for any of the enabled non-coherent caches (most of the UP CPUs),
+ * regardless of PIPT or VIPT cache configurations.
+ */
+
+/* Flush (write-back only) a region (smaller than a page) */
+extern void __flush_wback_region(void *start, int size);
+/* Flush (write-back & invalidate) a region (smaller than a page) */
+extern void __flush_purge_region(void *start, int size);
+/* Flush (invalidate only) a region (smaller than a page) */
+extern void __flush_invalidate_region(void *start, int size);
+#endif
+
+#define ARCH_HAS_FLUSH_KERNEL_DCACHE_PAGE
+static inline void flush_kernel_dcache_page(struct page *page)
+{
+	flush_dcache_page(page);
+}
+
+#if defined(CONFIG_CPU_SH4) && !defined(CONFIG_CACHE_OFF)
+extern void copy_to_user_page(struct vm_area_struct *vma,
+	struct page *page, unsigned long vaddr, void *dst, const void *src,
+	unsigned long len);
+
+extern void copy_from_user_page(struct vm_area_struct *vma,
+	struct page *page, unsigned long vaddr, void *dst, const void *src,
+	unsigned long len);
+#else
+#define copy_to_user_page(vma, page, vaddr, dst, src, len)	\
+	do {							\
+		flush_cache_page(vma, vaddr, page_to_pfn(page));\
+		memcpy(dst, src, len);				\
+		flush_icache_user_range(vma, page, vaddr, len);	\
+	} while (0)
+
+#define copy_from_user_page(vma, page, vaddr, dst, src, len)	\
+	do {							\
+		flush_cache_page(vma, vaddr, page_to_pfn(page));\
+		memcpy(dst, src, len);				\
+	} while (0)
+#endif
+
+#define flush_cache_vmap(start, end)		flush_cache_all()
+#define flush_cache_vunmap(start, end)		flush_cache_all()
+
+#define HAVE_ARCH_UNMAPPED_AREA
+
+#endif /* __KERNEL__ */
+#endif /* __ASM_SH_CACHEFLUSH_H */
