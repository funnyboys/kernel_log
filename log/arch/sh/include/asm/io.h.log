commit ca5999fde0a1761665a38e4c9a72dbcd7d190a81
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Jun 8 21:32:38 2020 -0700

    mm: introduce include/linux/pgtable.h
    
    The include/linux/pgtable.h is going to be the home of generic page table
    manipulation functions.
    
    Start with moving asm-generic/pgtable.h to include/linux/pgtable.h and
    make the latter include asm/pgtable.h.
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200514170327.31389-3-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 3924d91e0fa0..26f0f9b4658b 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -17,7 +17,7 @@
 #include <asm/cache.h>
 #include <asm/addrspace.h>
 #include <asm/machvec.h>
-#include <asm/pgtable.h>
+#include <linux/pgtable.h>
 #include <asm-generic/iomap.h>
 
 #ifdef __KERNEL__

commit 37744feebc086908fd89760650f458ab19071750
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon Apr 20 11:37:12 2020 +0200

    sh: remove sh5 support
    
    sh5 never became a product and has probably never really worked.
    
    Remove it by recursively deleting all associated Kconfig options
    and all corresponding files.
    
    Reviewed-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Rich Felker <dalias@libc.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index b42228906eaf..3924d91e0fa0 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -115,12 +115,8 @@ static inline void pfx##reads##bwlq(volatile void __iomem *mem,		\
 __BUILD_MEMORY_STRING(__raw_, b, u8)
 __BUILD_MEMORY_STRING(__raw_, w, u16)
 
-#ifdef CONFIG_SUPERH32
 void __raw_writesl(void __iomem *addr, const void *data, int longlen);
 void __raw_readsl(const void __iomem *addr, void *data, int longlen);
-#else
-__BUILD_MEMORY_STRING(__raw_, l, u32)
-#endif
 
 __BUILD_MEMORY_STRING(__raw_, q, u64)
 

commit 4580ba4ad2e6b8ddaada3db61d179d4dfac12047
Author: Kuninori Morimoto <kuninori.morimoto.gx@renesas.com>
Date:   Mon Jan 20 10:22:17 2020 +0900

    sh: Convert iounmap() macros to inline functions
    
    Macro iounmap() do nothing, but that results in
    unused variable warnings all over the place.
    This patch convert it to inline to avoid warning
    
    We will get this warning without this patch
    
            ${LINUX}/drivers/thermal/broadcom/ns-thermal.c:78:21: \
              warning: unused variable 'ns_thermal' [-Wunused-variable]
            struct ns_thermal *ns_thermal = platform_get_drvdata(pdev);
            ^~~~~~~~~~
    
    Fixes: 98c90e5ea34e9 ("sh: remove __iounmap")
    Signed-off-by: Kuninori Morimoto <kuninori.morimoto.gx@renesas.com>
    Signed-off-by: Rich Felker <dalias@libc.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 39c9ead489e5..b42228906eaf 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -328,7 +328,7 @@ __ioremap_mode(phys_addr_t offset, unsigned long size, pgprot_t prot)
 #else
 #define __ioremap(offset, size, prot)		((void __iomem *)(offset))
 #define __ioremap_mode(offset, size, prot)	((void __iomem *)(offset))
-#define iounmap(addr)				do { } while (0)
+static inline void iounmap(void __iomem *addr) {}
 #endif /* CONFIG_MMU */
 
 static inline void __iomem *ioremap(phys_addr_t offset, unsigned long size)

commit 4bdc0d676a643140bdf17dbf7eafedee3d496a3c
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon Jan 6 09:43:50 2020 +0100

    remove ioremap_nocache and devm_ioremap_nocache
    
    ioremap has provided non-cached semantics by default since the Linux 2.6
    days, so remove the additional ioremap_nocache interface.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Arnd Bergmann <arnd@arndb.de>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 1495489225ac..39c9ead489e5 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -367,7 +367,6 @@ static inline void ioremap_fixed_init(void) { }
 static inline int iounmap_fixed(void __iomem *addr) { return -EINVAL; }
 #endif
 
-#define ioremap_nocache	ioremap
 #define ioremap_uc	ioremap
 
 /*

commit 98c90e5ea34e98bdd4bcb67c48a0bdfd59bcd6cd
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Aug 13 08:11:46 2019 +0200

    sh: remove __iounmap
    
    No need to indirect iounmap for sh.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index ac0561960c52..1495489225ac 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -267,7 +267,7 @@ unsigned long long poke_real_address_q(unsigned long long addr,
 #ifdef CONFIG_MMU
 void __iomem *__ioremap_caller(phys_addr_t offset, unsigned long size,
 			       pgprot_t prot, void *caller);
-void __iounmap(void __iomem *addr);
+void iounmap(void __iomem *addr);
 
 static inline void __iomem *
 __ioremap(phys_addr_t offset, unsigned long size, pgprot_t prot)
@@ -328,7 +328,7 @@ __ioremap_mode(phys_addr_t offset, unsigned long size, pgprot_t prot)
 #else
 #define __ioremap(offset, size, prot)		((void __iomem *)(offset))
 #define __ioremap_mode(offset, size, prot)	((void __iomem *)(offset))
-#define __iounmap(addr)				do { } while (0)
+#define iounmap(addr)				do { } while (0)
 #endif /* CONFIG_MMU */
 
 static inline void __iomem *ioremap(phys_addr_t offset, unsigned long size)
@@ -370,11 +370,6 @@ static inline int iounmap_fixed(void __iomem *addr) { return -EINVAL; }
 #define ioremap_nocache	ioremap
 #define ioremap_uc	ioremap
 
-static inline void iounmap(void __iomem *addr)
-{
-	__iounmap(addr);
-}
-
 /*
  * Convert a physical pointer to a virtual kernel pointer for /dev/mem
  * access

commit 733f0025f0fb43e382b84db0930ae502099b7e62
Author: Sam Ravnborg <sam@ravnborg.org>
Date:   Thu Jul 11 20:52:52 2019 -0700

    sh: prevent warnings when using iounmap
    
    When building drm/exynos for sh, as part of an allmodconfig build, the
    following warning triggered:
    
      exynos7_drm_decon.c: In function `decon_remove':
      exynos7_drm_decon.c:769:24: warning: unused variable `ctx'
        struct decon_context *ctx = dev_get_drvdata(&pdev->dev);
    
    The ctx variable is only used as argument to iounmap().
    
    In sh - allmodconfig CONFIG_MMU is not defined
    so it ended up in:
    
    \#define __iounmap(addr)        do { } while (0)
    \#define iounmap                __iounmap
    
    Fix the warning by introducing a static inline function for iounmap.
    
    This is similar to several other architectures.
    
    Link: http://lkml.kernel.org/r/20190622114208.24427-1-sam@ravnborg.org
    Signed-off-by: Sam Ravnborg <sam@ravnborg.org>
    Reviewed-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Mark Brown <broonie@kernel.org>
    Cc: Inki Dae <inki.dae@samsung.com>
    Cc: Krzysztof Kozlowski <krzk@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index c28e37a344ad..ac0561960c52 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -369,7 +369,11 @@ static inline int iounmap_fixed(void __iomem *addr) { return -EINVAL; }
 
 #define ioremap_nocache	ioremap
 #define ioremap_uc	ioremap
-#define iounmap		__iounmap
+
+static inline void iounmap(void __iomem *addr)
+{
+	__iounmap(addr);
+}
 
 /*
  * Convert a physical pointer to a virtual kernel pointer for /dev/mem

commit e9e8543fecd2e1ca53616ba82fbd55a25cd2ab8a
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Feb 22 13:37:21 2019 +0000

    sh/mmiowb: Add unconditional mmiowb() to arch_spin_unlock()
    
    The mmiowb() macro is horribly difficult to use and drivers will continue
    to work most of the time if they omit a call when it is required.
    
    Rather than rely on driver authors getting this right, push mmiowb() into
    arch_spin_unlock() for sh. If this is deemed to be a performance issue,
    a subsequent optimisation could make use of ARCH_HAS_MMIOWB to elide
    the barrier in cases where no I/O writes were performed inside the
    critical section.
    
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Rich Felker <dalias@libc.org>
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 4f7f235f15f8..c28e37a344ad 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -229,9 +229,6 @@ __BUILD_IOPORT_STRING(q, u64)
 
 #define IO_SPACE_LIMIT 0xffffffff
 
-/* synco on SH-4A, otherwise a nop */
-#define mmiowb()		wmb()
-
 /* We really want to try and get these to memcpy etc */
 void memcpy_fromio(void *, const volatile void __iomem *, unsigned long);
 void memcpy_toio(volatile void __iomem *, const void *, unsigned long);

commit 915c9e1b6d008fdaebca91b83fa0d2596121d588
Author: Mark Brown <broonie@kernel.org>
Date:   Fri Dec 14 14:17:00 2018 -0800

    arch/sh/include/asm/io.h: provide prototypes for PCI I/O mapping in asm/io.h
    
    Most architectures provide prototypes for the PCI I/O mapping operations
    when asm/io.h is included but SH doesn't currently do that, leading to
    for example warnings in sound/pci/hda/patch_ca0132.c when pci_iomap() is
    used on current -next.  Make SH more consistent with other architectures
    by including asm-generic/pci_iomap.h in asm/io.h.
    
    Link: http://lkml.kernel.org/r/20181106175142.27988-1-broonie@kernel.org
    Signed-off-by: Mark Brown <broonie@kernel.org>
    Reported-by: kbuild test robot <lkp@intel.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 98cb8c802b1a..4f7f235f15f8 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -24,6 +24,7 @@
 #define __IO_PREFIX     generic
 #include <asm/io_generic.h>
 #include <asm/io_trapped.h>
+#include <asm-generic/pci_iomap.h>
 #include <mach/mangle-port.h>
 
 #define __raw_writeb(v,a)	(__chk_io_ptr(a), *(volatile u8  __force *)(a) = (v))

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 3280a6bfa503..98cb8c802b1a 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef __ASM_SH_IO_H
 #define __ASM_SH_IO_H
 

commit 12f03ee606914317e7e6a0815e53a48205c31dae
Merge: d9241b22b58e 004f1afbe199
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Sep 8 14:35:59 2015 -0700

    Merge tag 'libnvdimm-for-4.3' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm
    
    Pull libnvdimm updates from Dan Williams:
     "This update has successfully completed a 0day-kbuild run and has
      appeared in a linux-next release.  The changes outside of the typical
      drivers/nvdimm/ and drivers/acpi/nfit.[ch] paths are related to the
      removal of IORESOURCE_CACHEABLE, the introduction of memremap(), and
      the introduction of ZONE_DEVICE + devm_memremap_pages().
    
      Summary:
    
       - Introduce ZONE_DEVICE and devm_memremap_pages() as a generic
         mechanism for adding device-driver-discovered memory regions to the
         kernel's direct map.
    
         This facility is used by the pmem driver to enable pfn_to_page()
         operations on the page frames returned by DAX ('direct_access' in
         'struct block_device_operations').
    
         For now, the 'memmap' allocation for these "device" pages comes
         from "System RAM".  Support for allocating the memmap from device
         memory will arrive in a later kernel.
    
       - Introduce memremap() to replace usages of ioremap_cache() and
         ioremap_wt().  memremap() drops the __iomem annotation for these
         mappings to memory that do not have i/o side effects.  The
         replacement of ioremap_cache() with memremap() is limited to the
         pmem driver to ease merging the api change in v4.3.
    
         Completion of the conversion is targeted for v4.4.
    
       - Similar to the usage of memcpy_to_pmem() + wmb_pmem() in the pmem
         driver, update the VFS DAX implementation and PMEM api to provide
         persistence guarantees for kernel operations on a DAX mapping.
    
       - Convert the ACPI NFIT 'BLK' driver to map the block apertures as
         cacheable to improve performance.
    
       - Miscellaneous updates and fixes to libnvdimm including support for
         issuing "address range scrub" commands, clarifying the optimal
         'sector size' of pmem devices, a clarification of the usage of the
         ACPI '_STA' (status) property for DIMM devices, and other minor
         fixes"
    
    * tag 'libnvdimm-for-4.3' of git://git.kernel.org/pub/scm/linux/kernel/git/nvdimm/nvdimm: (34 commits)
      libnvdimm, pmem: direct map legacy pmem by default
      libnvdimm, pmem: 'struct page' for pmem
      libnvdimm, pfn: 'struct page' provider infrastructure
      x86, pmem: clarify that ARCH_HAS_PMEM_API implies PMEM mapped WB
      add devm_memremap_pages
      mm: ZONE_DEVICE for "device memory"
      mm: move __phys_to_pfn and __pfn_to_phys to asm/generic/memory_model.h
      dax: drop size parameter to ->direct_access()
      nd_blk: change aperture mapping from WC to WB
      nvdimm: change to use generic kvfree()
      pmem, dax: have direct_access use __pmem annotation
      dax: update I/O path to do proper PMEM flushing
      pmem: add copy_from_iter_pmem() and clear_pmem()
      pmem, x86: clean up conditional pmem includes
      pmem: remove layer when calling arch_has_wmb_pmem()
      pmem, x86: move x86 PMEM API to new pmem.h header
      libnvdimm, e820: make CONFIG_X86_PMEM_LEGACY a tristate option
      pmem: switch to devm_ allocations
      devres: add devm_memremap
      libnvdimm, btt: write and validate parent_uuid
      ...

commit 92281dee825f6d2eb07c441437e4196a44b0861c
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Mon Aug 10 23:07:06 2015 -0400

    arch: introduce memremap()
    
    Existing users of ioremap_cache() are mapping memory that is known in
    advance to not have i/o side effects.  These users are forced to cast
    away the __iomem annotation, or otherwise neglect to fix the sparse
    errors thrown when dereferencing pointers to this memory.  Provide
    memremap() as a non __iomem annotated ioremap_*() in the case when
    ioremap is otherwise a pointer to cacheable memory. Empirically,
    ioremap_<cacheable-type>() call sites are seeking memory-like semantics
    (e.g.  speculative reads, and prefetching permitted).
    
    memremap() is a break from the ioremap implementation pattern of adding
    a new memremap_<type>() for each mapping type and having silent
    compatibility fall backs.  Instead, the implementation defines flags
    that are passed to the central memremap() and if a mapping type is not
    supported by an arch memremap returns NULL.
    
    We introduce a memremap prototype as a trivial wrapper of
    ioremap_cache() and ioremap_wt().  Later, once all ioremap_cache() and
    ioremap_wt() usage has been removed from drivers we teach archs to
    implement arch_memremap() with the ability to strictly enforce the
    mapping type.
    
    Cc: Arnd Bergmann <arnd@arndb.de>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 728c4c571f40..6194e20fccca 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -342,6 +342,7 @@ ioremap_cache(phys_addr_t offset, unsigned long size)
 {
 	return __ioremap_mode(offset, size, PAGE_KERNEL);
 }
+#define ioremap_cache ioremap_cache
 
 #ifdef CONFIG_HAVE_IOREMAP_PROT
 static inline void __iomem *

commit 4c73e8926623ca0f64c2c6111289ab8096fa647a
Author: Luis R. Rodriguez <mcgrof@suse.com>
Date:   Tue Jul 28 20:17:13 2015 +0200

    arch/*/io.h: Add ioremap_uc() to all architectures
    
    This adds ioremap_uc() only for architectures that do not
    include asm-generic.h/io.h as that already provides a default
    definition for them for both cases where you have CONFIG_MMU
    and you do not, and because of this, the number of architectures
    this patch address is less than the architectures that the
    ioremap_wt() patch addressed, "arch/*/io.h: Add ioremap_wt() to
    all architectures").
    
    In order to reduce the number of architectures we have to
    modify by adding new architecture IO APIs we'll have to review
    the architectures in this patch, see why they can't add
    asm-generic.h/io.h or issues that would be created by doing
    so and then spread a consistent inclusion of this header
    towards the end of their own header. For instance arch/metag
    includes the asm-generic/io.h *before* the ioremap*()
    definitions, this should be the other way around but only
    once we have guard wrappers for the non-MMU case also for
    asm-generic/io.h.
    
    Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Luis R. Rodriguez <mcgrof@suse.com>
    Cc: Abhilash Kesavan <a.kesavan@samsung.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Chris Metcalf <cmetcalf@ezchip.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Fengguang Wu <fengguang.wu@intel.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Greg Ungerer <gerg@uclinux.org>
    Cc: Guenter Roeck <linux@roeck-us.net>
    Cc: Haavard Skinnemoen <hskinnemoen@gmail.com>
    Cc: Hans-Christian Egtvedt <egtvedt@samfundet.no>
    Cc: Koichi Yasutake <yasutake.koichi@jp.panasonic.com>
    Cc: Kyle McMartin <kyle@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Hurley <peter@hurleysoftware.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rob Herring <robh@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Toshi Kani <toshi.kani@hp.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linux-am33-list@redhat.com
    Cc: linux-arch@vger.kernel.org
    Cc: linux-m68k@lists.linux-m68k.org
    Cc: linux-sh@vger.kernel.org
    Cc: linuxppc-dev@lists.ozlabs.org
    Link: http://lkml.kernel.org/r/20150728181713.GB30479@wotan.suse.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 728c4c571f40..93ec9066dbef 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -368,6 +368,7 @@ static inline int iounmap_fixed(void __iomem *addr) { return -EINVAL; }
 #endif
 
 #define ioremap_nocache	ioremap
+#define ioremap_uc	ioremap
 #define iounmap		__iounmap
 
 /*

commit ce816fa88cca083c47ab9000b2138a83043a78be
Author: Uwe Kleine-König <u.kleine-koenig@pengutronix.de>
Date:   Mon Apr 7 15:39:19 2014 -0700

    Kconfig: rename HAS_IOPORT to HAS_IOPORT_MAP
    
    If the renamed symbol is defined lib/iomap.c implements ioport_map and
    ioport_unmap and currently (nearly) all platforms define the port
    accessor functions outb/inb and friend unconditionally.  So
    HAS_IOPORT_MAP is the better name for this.
    
    Consequently NO_IOPORT is renamed to NO_IOPORT_MAP.
    
    The motivation for this change is to reintroduce a symbol HAS_IOPORT
    that signals if outb/int et al are available.  I will address that at
    least one merge window later though to keep surprises to a minimum and
    catch new introductions of (HAS|NO)_IOPORT.
    
    The changes in this commit were done using:
    
            $ git grep -l -E '(NO|HAS)_IOPORT' | xargs perl -p -i -e 's/\b((?:CONFIG_)?(?:NO|HAS)_IOPORT)\b/$1_MAP/'
    
    Signed-off-by: Uwe Kleine-König <u.kleine-koenig@pengutronix.de>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 629db2ad7916..728c4c571f40 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -122,7 +122,7 @@ __BUILD_MEMORY_STRING(__raw_, l, u32)
 
 __BUILD_MEMORY_STRING(__raw_, q, u64)
 
-#ifdef CONFIG_HAS_IOPORT
+#ifdef CONFIG_HAS_IOPORT_MAP
 
 /*
  * Slowdown I/O port space accesses for antique hardware.
@@ -218,7 +218,7 @@ __BUILD_IOPORT_STRING(w, u16)
 __BUILD_IOPORT_STRING(l, u32)
 __BUILD_IOPORT_STRING(q, u64)
 
-#else /* !CONFIG_HAS_IOPORT */
+#else /* !CONFIG_HAS_IOPORT_MAP */
 
 #include <asm/io_noioport.h>
 

commit 7e6735c3578e76c270a2797225a4214176ba13ef
Author: Cyril Chemparathy <cyril@ti.com>
Date:   Wed Sep 12 14:05:58 2012 -0400

    /dev/mem: use phys_addr_t for physical addresses
    
    This patch fixes the /dev/mem driver to use phys_addr_t for physical
    addresses.  This is required on PAE systems, especially those that run
    entirely out of >4G physical memory space.
    
    Signed-off-by: Cyril Chemparathy <cyril@ti.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 73a23f4617a3..629db2ad7916 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -382,7 +382,7 @@ static inline int iounmap_fixed(void __iomem *addr) { return -EINVAL; }
 #define xlate_dev_kmem_ptr(p)	p
 
 #define ARCH_HAS_VALID_PHYS_ADDR_RANGE
-int valid_phys_addr_range(unsigned long addr, size_t size);
+int valid_phys_addr_range(phys_addr_t addr, size_t size);
 int valid_mmap_phys_addr_range(unsigned long pfn, size_t size);
 
 #endif /* __KERNEL__ */

commit 666e81fdca5486cad644ee3fb64bb7d83e2f3723
Author: Andi Kleen <ak@linux.intel.com>
Date:   Thu Oct 4 17:11:41 2012 -0700

    sections: fix section conflicts in arch/sh
    
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 0cf60a628814..73a23f4617a3 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -134,7 +134,7 @@ __BUILD_MEMORY_STRING(__raw_, q, u64)
  * load/store instructions. sh_io_port_base is the virtual address to
  * which all ports are being mapped.
  */
-extern const unsigned long sh_io_port_base;
+extern unsigned long sh_io_port_base;
 
 static inline void __set_io_port_base(unsigned long pbase)
 {

commit c5e50fa90ce42b1689692f587d4881308881b73d
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Thu May 10 13:07:55 2012 +0900

    sh: Provide stubbed I/O routines for NO_IOPORT case.
    
    Too many drivers fail at IOPORT vs IOMEM checking before blindly calling
    in to the API, so we may as well just provide basic stubs to get more
    build coverage. Other platforms already do this, too (tile, parisc, etc.)
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index ec464a6b95fe..0cf60a628814 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -218,8 +218,13 @@ __BUILD_IOPORT_STRING(w, u16)
 __BUILD_IOPORT_STRING(l, u32)
 __BUILD_IOPORT_STRING(q, u64)
 
+#else /* !CONFIG_HAS_IOPORT */
+
+#include <asm/io_noioport.h>
+
 #endif
 
+
 #define IO_SPACE_LIMIT 0xffffffff
 
 /* synco on SH-4A, otherwise a nop */

commit f52b69f86e27903d6896ed5fa7cd280fec8de532
Merge: 2f7fa1be66dc b7e68d6876df
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Mar 30 00:09:17 2012 -0700

    Merge tag 'sh-for-linus' of git://github.com/pmundt/linux-sh
    
    Pull SuperH updates from Paul Mundt.
    
    * tag 'sh-for-linus' of git://github.com/pmundt/linux-sh: (25 commits)
      sh: Support I/O space swapping where needed.
      sh: use set_current_blocked() and block_sigmask()
      sh: no need to reset handler if SA_ONESHOT
      sh: intc: Fix up section mismatch for intc_ack_data
      sh: select ARCH_DISCARD_MEMBLOCK.
      sh: Consolidate duplicate _32/_64 unistd definitions.
      sh: ecovec: switch SDHI controllers to card polling
      sh: Avoid exporting unimplemented syscalls.
      sh: add platform_device for RSPI in setup-sh7757
      SH: pci-sh7780: enable big-endian operation.
      serial: sh-sci: fix a race of DMA submit_tx on transfer
      sh: dma: Collect up CHCR of SH7763, SH7764, SH7780 and SH7785
      sh: dma: Collect up CHCR of SH7723 and SH7730
      sh/next: Fix build fail by asm/system.h in asm/bitops.h
      arch/sh/drivers/dma/{dma-g2,dmabrg}.c: ensure arguments to request_irq and free_irq are compatible
      sh: cpufreq: Wire up scaling_available_freqs support.
      sh: cpufreq: notify about rate rounding fallback.
      sh: cpufreq: Support CPU clock frequency table.
      sh: cpufreq: struct device lookup from CPU topology.
      sh: cpufreq: percpu struct clk accounting.
      ...

commit b7e68d6876dfbab087bc3859211a9efc74cbe30c
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Thu Mar 29 16:05:10 2012 +0900

    sh: Support I/O space swapping where needed.
    
    This adopts a trimmed down version of the MIPS port mangling interface
    limited to the I/O swabbing for platforms that can't use little endian
    accessors. For platforms with mixed I/O spaces involving PCI it will
    still be necessary to enable byte swapping at the host controller level.
    Attention needs to be paid to all of host controller endianness, CPU
    endianness, and whether I/O accesses are explicitly swapped or not via
    SWAP_IO_SPACE. Fortunately the platforms that need this are in the
    minority.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 28c5aa58bb45..eb76cb32f49f 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -24,6 +24,7 @@
 #define __IO_PREFIX     generic
 #include <asm/io_generic.h>
 #include <asm/io_trapped.h>
+#include <mach/mangle-port.h>
 
 #define __raw_writeb(v,a)	(__chk_io_ptr(a), *(volatile u8  __force *)(a) = (v))
 #define __raw_writew(v,a)	(__chk_io_ptr(a), *(volatile u16 __force *)(a) = (v))
@@ -35,21 +36,15 @@
 #define __raw_readl(a)		(__chk_io_ptr(a), *(volatile u32 __force *)(a))
 #define __raw_readq(a)		(__chk_io_ptr(a), *(volatile u64 __force *)(a))
 
-#define readb_relaxed(c)	({ u8  __v = __raw_readb(c); __v; })
-#define readw_relaxed(c)	({ u16 __v = le16_to_cpu((__force __le16) \
-					__raw_readw(c)); __v; })
-#define readl_relaxed(c)	({ u32 __v = le32_to_cpu((__force __le32) \
-					__raw_readl(c)); __v; })
-#define readq_relaxed(c)	({ u64 __v = le64_to_cpu((__force __le64) \
-					__raw_readq(c)); __v; })
-
-#define writeb_relaxed(v,c)	((void)__raw_writeb(v,c))
-#define writew_relaxed(v,c)	((void)__raw_writew((__force u16) \
-					cpu_to_le16(v),c))
-#define writel_relaxed(v,c)	((void)__raw_writel((__force u32) \
-					cpu_to_le32(v),c))
-#define writeq_relaxed(v,c)	((void)__raw_writeq((__force u64) \
-					cpu_to_le64(v),c))
+#define readb_relaxed(c)	({ u8  __v = ioswabb(__raw_readb(c)); __v; })
+#define readw_relaxed(c)	({ u16 __v = ioswabw(__raw_readw(c)); __v; })
+#define readl_relaxed(c)	({ u32 __v = ioswabl(__raw_readl(c)); __v; })
+#define readq_relaxed(c)	({ u64 __v = ioswabq(__raw_readq(c)); __v; })
+
+#define writeb_relaxed(v,c)	((void)__raw_writeb((__force  u8)ioswabb(v),c))
+#define writew_relaxed(v,c)	((void)__raw_writew((__force u16)ioswabw(v),c))
+#define writel_relaxed(v,c)	((void)__raw_writel((__force u32)ioswabl(v),c))
+#define writeq_relaxed(v,c)	((void)__raw_writeq((__force u64)ioswabq(v),c))
 
 #define readb(a)		({ u8  r_ = readb_relaxed(a); rmb(); r_; })
 #define readw(a)		({ u16 r_ = readw_relaxed(a); rmb(); r_; })

commit e839ca528718e68cad32a307dc9aabf01ef3eb05
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:30:03 2012 +0100

    Disintegrate asm/system.h for SH
    
    Disintegrate asm/system.h for SH.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    cc: linux-sh@vger.kernel.org

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 28c5aa58bb45..35fc8b077cb1 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -14,7 +14,6 @@
  */
 #include <linux/errno.h>
 #include <asm/cache.h>
-#include <asm/system.h>
 #include <asm/addrspace.h>
 #include <asm/machvec.h>
 #include <asm/pgtable.h>

commit efb3e34b6176d30c4fe8635fa8e1beb6280cc2cd
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Jan 11 15:02:59 2011 +0900

    sh: Fix up legacy PTEA space attribute mapping.
    
    When p3_ioremap() was converted to ioremap_prot() there was some breakage
    introduced where the 29-bit segmentation logic would trap the area range
    and return an identity mapping without having allowed the area
    specification to force mapping through page tables. This wires up a PCC
    mask for pgprot verification to work out whether to short-circuit the
    identity mapping on legacy parts, restoring the previous behaviour.
    
    Reported-by: Nobuhiro Iwamatsu <iwamatsu@nigauri.org>
    Cc: stable@kernel.org
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 70c1186b5088..28c5aa58bb45 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -290,7 +290,15 @@ __ioremap_29bit(phys_addr_t offset, unsigned long size, pgprot_t prot)
 	 * mapping must be done by the PMB or by using page tables.
 	 */
 	if (likely(PXSEG(offset) < P3SEG && PXSEG(last_addr) < P3SEG)) {
-		if (unlikely(pgprot_val(prot) & _PAGE_CACHABLE))
+		u64 flags = pgprot_val(prot);
+
+		/*
+		 * Anything using the legacy PTEA space attributes needs
+		 * to be kicked down to page table mappings.
+		 */
+		if (unlikely(flags & _PAGE_PCC_MASK))
+			return NULL;
+		if (unlikely(flags & _PAGE_CACHABLE))
 			return (void __iomem *)P1SEGADDR(offset);
 
 		return (void __iomem *)P2SEGADDR(offset);

commit 0d6ae8fa945aba732edadce1ead9929520d61b99
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Jan 11 12:36:37 2011 +0900

    sh: Kill off deprecated ctrl_in/out I/O routines.
    
    Now that all of the in-tree drivers have been converted to portable I/O
    accessors, we can kill off the legacy ones with extreme prejudice.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 89ab2c57a4c2..70c1186b5088 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -11,11 +11,6 @@
  *
  * While read{b,w,l,q} and write{b,w,l,q} contain memory barriers
  * automatically, there are also __raw versions, which do not.
- *
- * Historically, we have also had ctrl_in{b,w,l,q}/ctrl_out{b,w,l,q} for
- * SuperH specific I/O (raw I/O to on-chip CPU peripherals). In practice
- * these have the same semantics as the __raw variants, and as such, all
- * new code should be using the __raw versions.
  */
 #include <linux/errno.h>
 #include <asm/cache.h>
@@ -231,52 +226,6 @@ __BUILD_IOPORT_STRING(q, u64)
 
 #endif
 
-/*
- * Legacy SuperH on-chip I/O functions
- *
- * These are all deprecated, all new (and especially cross-platform) code
- * should be using the __raw_xxx() routines directly.
- */
-static inline u8 __deprecated ctrl_inb(unsigned long addr)
-{
-	return __raw_readb(addr);
-}
-
-static inline u16 __deprecated ctrl_inw(unsigned long addr)
-{
-	return __raw_readw(addr);
-}
-
-static inline u32 __deprecated ctrl_inl(unsigned long addr)
-{
-	return __raw_readl(addr);
-}
-
-static inline u64 __deprecated ctrl_inq(unsigned long addr)
-{
-	return __raw_readq(addr);
-}
-
-static inline void __deprecated ctrl_outb(u8 v, unsigned long addr)
-{
-	__raw_writeb(v, addr);
-}
-
-static inline void __deprecated ctrl_outw(u16 v, unsigned long addr)
-{
-	__raw_writew(v, addr);
-}
-
-static inline void __deprecated ctrl_outl(u32 v, unsigned long addr)
-{
-	__raw_writel(v, addr);
-}
-
-static inline void __deprecated ctrl_outq(u64 v, unsigned long addr)
-{
-	__raw_writeq(v, addr);
-}
-
 #define IO_SPACE_LIMIT 0xffffffff
 
 /* synco on SH-4A, otherwise a nop */

commit 37b7a97884ba64bf7d403351ac2a9476ab4f1bba
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Nov 1 09:49:04 2010 -0400

    sh: machvec IO death.
    
    This takes a bit of a sledgehammer to the machvec I/O routines. The
    iomem case requires no special casing and so can just be dropped
    outright. This only leaves the ioport casing for PCI and SuperIO
    mangling. With the SuperIO case going through the standard ioport
    mapping, it's possible to replace everything with generic routines.
    
    With this done the standard I/O routines are tidied up and NO_IOPORT
    now gets default-enabled for the vast majority of boards.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index b237d525d592..89ab2c57a4c2 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -1,5 +1,6 @@
 #ifndef __ASM_SH_IO_H
 #define __ASM_SH_IO_H
+
 /*
  * Convention:
  *    read{b,w,l,q}/write{b,w,l,q} are for PCI,
@@ -15,12 +16,6 @@
  * SuperH specific I/O (raw I/O to on-chip CPU peripherals). In practice
  * these have the same semantics as the __raw variants, and as such, all
  * new code should be using the __raw versions.
- *
- * All ISA I/O routines are wrapped through the machine vector. If a
- * board does not provide overrides, a generic set that are copied in
- * from the default machine vector are used instead. These are largely
- * for old compat code for I/O offseting to SuperIOs, all of which are
- * better handled through the machvec ioport mapping routines these days.
  */
 #include <linux/errno.h>
 #include <asm/cache.h>
@@ -31,39 +26,10 @@
 #include <asm-generic/iomap.h>
 
 #ifdef __KERNEL__
-/*
- * Depending on which platform we are running on, we need different
- * I/O functions.
- */
-#define __IO_PREFIX	generic
+#define __IO_PREFIX     generic
 #include <asm/io_generic.h>
 #include <asm/io_trapped.h>
 
-#ifdef CONFIG_HAS_IOPORT
-
-#define inb(p)			sh_mv.mv_inb((p))
-#define inw(p)			sh_mv.mv_inw((p))
-#define inl(p)			sh_mv.mv_inl((p))
-#define outb(x,p)		sh_mv.mv_outb((x),(p))
-#define outw(x,p)		sh_mv.mv_outw((x),(p))
-#define outl(x,p)		sh_mv.mv_outl((x),(p))
-
-#define inb_p(p)		sh_mv.mv_inb_p((p))
-#define inw_p(p)		sh_mv.mv_inw_p((p))
-#define inl_p(p)		sh_mv.mv_inl_p((p))
-#define outb_p(x,p)		sh_mv.mv_outb_p((x),(p))
-#define outw_p(x,p)		sh_mv.mv_outw_p((x),(p))
-#define outl_p(x,p)		sh_mv.mv_outl_p((x),(p))
-
-#define insb(p,b,c)		sh_mv.mv_insb((p), (b), (c))
-#define insw(p,b,c)		sh_mv.mv_insw((p), (b), (c))
-#define insl(p,b,c)		sh_mv.mv_insl((p), (b), (c))
-#define outsb(p,b,c)		sh_mv.mv_outsb((p), (b), (c))
-#define outsw(p,b,c)		sh_mv.mv_outsw((p), (b), (c))
-#define outsl(p,b,c)		sh_mv.mv_outsl((p), (b), (c))
-
-#endif
-
 #define __raw_writeb(v,a)	(__chk_io_ptr(a), *(volatile u8  __force *)(a) = (v))
 #define __raw_writew(v,a)	(__chk_io_ptr(a), *(volatile u16 __force *)(a) = (v))
 #define __raw_writel(v,a)	(__chk_io_ptr(a), *(volatile u32 __force *)(a) = (v))
@@ -74,68 +40,39 @@
 #define __raw_readl(a)		(__chk_io_ptr(a), *(volatile u32 __force *)(a))
 #define __raw_readq(a)		(__chk_io_ptr(a), *(volatile u64 __force *)(a))
 
-#define readb(a)		({ u8  r_ = __raw_readb(a); mb(); r_; })
-#define readw(a)		({ u16 r_ = __raw_readw(a); mb(); r_; })
-#define readl(a)		({ u32 r_ = __raw_readl(a); mb(); r_; })
-#define readq(a)		({ u64 r_ = __raw_readq(a); mb(); r_; })
-
-#define writeb(v,a)		({ __raw_writeb((v),(a)); mb(); })
-#define writew(v,a)		({ __raw_writew((v),(a)); mb(); })
-#define writel(v,a)		({ __raw_writel((v),(a)); mb(); })
-#define writeq(v,a)		({ __raw_writeq((v),(a)); mb(); })
-
-/*
- * Legacy SuperH on-chip I/O functions
- *
- * These are all deprecated, all new (and especially cross-platform) code
- * should be using the __raw_xxx() routines directly.
- */
-static inline u8 __deprecated ctrl_inb(unsigned long addr)
-{
-	return __raw_readb(addr);
-}
-
-static inline u16 __deprecated ctrl_inw(unsigned long addr)
-{
-	return __raw_readw(addr);
-}
-
-static inline u32 __deprecated ctrl_inl(unsigned long addr)
-{
-	return __raw_readl(addr);
-}
-
-static inline u64 __deprecated ctrl_inq(unsigned long addr)
-{
-	return __raw_readq(addr);
-}
-
-static inline void __deprecated ctrl_outb(u8 v, unsigned long addr)
-{
-	__raw_writeb(v, addr);
-}
-
-static inline void __deprecated ctrl_outw(u16 v, unsigned long addr)
-{
-	__raw_writew(v, addr);
-}
-
-static inline void __deprecated ctrl_outl(u32 v, unsigned long addr)
-{
-	__raw_writel(v, addr);
-}
-
-static inline void __deprecated ctrl_outq(u64 v, unsigned long addr)
-{
-	__raw_writeq(v, addr);
-}
-
-extern unsigned long generic_io_base;
-
-static inline void ctrl_delay(void)
-{
-	__raw_readw(generic_io_base);
-}
+#define readb_relaxed(c)	({ u8  __v = __raw_readb(c); __v; })
+#define readw_relaxed(c)	({ u16 __v = le16_to_cpu((__force __le16) \
+					__raw_readw(c)); __v; })
+#define readl_relaxed(c)	({ u32 __v = le32_to_cpu((__force __le32) \
+					__raw_readl(c)); __v; })
+#define readq_relaxed(c)	({ u64 __v = le64_to_cpu((__force __le64) \
+					__raw_readq(c)); __v; })
+
+#define writeb_relaxed(v,c)	((void)__raw_writeb(v,c))
+#define writew_relaxed(v,c)	((void)__raw_writew((__force u16) \
+					cpu_to_le16(v),c))
+#define writel_relaxed(v,c)	((void)__raw_writel((__force u32) \
+					cpu_to_le32(v),c))
+#define writeq_relaxed(v,c)	((void)__raw_writeq((__force u64) \
+					cpu_to_le64(v),c))
+
+#define readb(a)		({ u8  r_ = readb_relaxed(a); rmb(); r_; })
+#define readw(a)		({ u16 r_ = readw_relaxed(a); rmb(); r_; })
+#define readl(a)		({ u32 r_ = readl_relaxed(a); rmb(); r_; })
+#define readq(a)		({ u64 r_ = readq_relaxed(a); rmb(); r_; })
+
+#define writeb(v,a)		({ wmb(); writeb_relaxed((v),(a)); })
+#define writew(v,a)		({ wmb(); writew_relaxed((v),(a)); })
+#define writel(v,a)		({ wmb(); writel_relaxed((v),(a)); })
+#define writeq(v,a)		({ wmb(); writeq_relaxed((v),(a)); })
+
+#define readsb(p,d,l)		__raw_readsb(p,d,l)
+#define readsw(p,d,l)		__raw_readsw(p,d,l)
+#define readsl(p,d,l)		__raw_readsl(p,d,l)
+
+#define writesb(p,d,l)		__raw_writesb(p,d,l)
+#define writesw(p,d,l)		__raw_writesw(p,d,l)
+#define writesl(p,d,l)		__raw_writesl(p,d,l)
 
 #define __BUILD_UNCACHED_IO(bwlq, type)					\
 static inline type read##bwlq##_uncached(unsigned long addr)		\
@@ -159,10 +96,11 @@ __BUILD_UNCACHED_IO(w, u16)
 __BUILD_UNCACHED_IO(l, u32)
 __BUILD_UNCACHED_IO(q, u64)
 
-#define __BUILD_MEMORY_STRING(bwlq, type)				\
+#define __BUILD_MEMORY_STRING(pfx, bwlq, type)				\
 									\
-static inline void __raw_writes##bwlq(volatile void __iomem *mem,	\
-				const void *addr, unsigned int count)	\
+static inline void							\
+pfx##writes##bwlq(volatile void __iomem *mem, const void *addr,		\
+		  unsigned int count)					\
 {									\
 	const volatile type *__addr = addr;				\
 									\
@@ -172,8 +110,8 @@ static inline void __raw_writes##bwlq(volatile void __iomem *mem,	\
 	}								\
 }									\
 									\
-static inline void __raw_reads##bwlq(volatile void __iomem *mem,	\
-			       void *addr, unsigned int count)		\
+static inline void pfx##reads##bwlq(volatile void __iomem *mem,		\
+				    void *addr, unsigned int count)	\
 {									\
 	volatile type *__addr = addr;					\
 									\
@@ -183,85 +121,166 @@ static inline void __raw_reads##bwlq(volatile void __iomem *mem,	\
 	}								\
 }
 
-__BUILD_MEMORY_STRING(b, u8)
-__BUILD_MEMORY_STRING(w, u16)
+__BUILD_MEMORY_STRING(__raw_, b, u8)
+__BUILD_MEMORY_STRING(__raw_, w, u16)
 
 #ifdef CONFIG_SUPERH32
 void __raw_writesl(void __iomem *addr, const void *data, int longlen);
 void __raw_readsl(const void __iomem *addr, void *data, int longlen);
 #else
-__BUILD_MEMORY_STRING(l, u32)
+__BUILD_MEMORY_STRING(__raw_, l, u32)
 #endif
 
-__BUILD_MEMORY_STRING(q, u64)
-
-#define writesb			__raw_writesb
-#define writesw			__raw_writesw
-#define writesl			__raw_writesl
-
-#define readsb			__raw_readsb
-#define readsw			__raw_readsw
-#define readsl			__raw_readsl
-
-#define readb_relaxed(a)	readb(a)
-#define readw_relaxed(a)	readw(a)
-#define readl_relaxed(a)	readl(a)
-#define readq_relaxed(a)	readq(a)
-
-#ifndef CONFIG_GENERIC_IOMAP
-/* Simple MMIO */
-#define ioread8(a)		__raw_readb(a)
-#define ioread16(a)		__raw_readw(a)
-#define ioread16be(a)		be16_to_cpu(__raw_readw((a)))
-#define ioread32(a)		__raw_readl(a)
-#define ioread32be(a)		be32_to_cpu(__raw_readl((a)))
-
-#define iowrite8(v,a)		__raw_writeb((v),(a))
-#define iowrite16(v,a)		__raw_writew((v),(a))
-#define iowrite16be(v,a)	__raw_writew(cpu_to_be16((v)),(a))
-#define iowrite32(v,a)		__raw_writel((v),(a))
-#define iowrite32be(v,a)	__raw_writel(cpu_to_be32((v)),(a))
-
-#define ioread8_rep(a, d, c)	__raw_readsb((a), (d), (c))
-#define ioread16_rep(a, d, c)	__raw_readsw((a), (d), (c))
-#define ioread32_rep(a, d, c)	__raw_readsl((a), (d), (c))
-
-#define iowrite8_rep(a, s, c)	__raw_writesb((a), (s), (c))
-#define iowrite16_rep(a, s, c)	__raw_writesw((a), (s), (c))
-#define iowrite32_rep(a, s, c)	__raw_writesl((a), (s), (c))
+__BUILD_MEMORY_STRING(__raw_, q, u64)
+
+#ifdef CONFIG_HAS_IOPORT
+
+/*
+ * Slowdown I/O port space accesses for antique hardware.
+ */
+#undef CONF_SLOWDOWN_IO
+
+/*
+ * On SuperH I/O ports are memory mapped, so we access them using normal
+ * load/store instructions. sh_io_port_base is the virtual address to
+ * which all ports are being mapped.
+ */
+extern const unsigned long sh_io_port_base;
+
+static inline void __set_io_port_base(unsigned long pbase)
+{
+	*(unsigned long *)&sh_io_port_base = pbase;
+	barrier();
+}
+
+#ifdef CONFIG_GENERIC_IOMAP
+#define __ioport_map ioport_map
+#else
+extern void __iomem *__ioport_map(unsigned long addr, unsigned int size);
 #endif
 
-#define mmio_insb(p,d,c)	__raw_readsb(p,d,c)
-#define mmio_insw(p,d,c)	__raw_readsw(p,d,c)
-#define mmio_insl(p,d,c)	__raw_readsl(p,d,c)
+#ifdef CONF_SLOWDOWN_IO
+#define SLOW_DOWN_IO __raw_readw(sh_io_port_base)
+#else
+#define SLOW_DOWN_IO
+#endif
 
-#define mmio_outsb(p,s,c)	__raw_writesb(p,s,c)
-#define mmio_outsw(p,s,c)	__raw_writesw(p,s,c)
-#define mmio_outsl(p,s,c)	__raw_writesl(p,s,c)
+#define __BUILD_IOPORT_SINGLE(pfx, bwlq, type, p, slow)			\
+									\
+static inline void pfx##out##bwlq##p(type val, unsigned long port)	\
+{									\
+	volatile type *__addr;						\
+									\
+	__addr = __ioport_map(port, sizeof(type));			\
+	*__addr = val;							\
+	slow;								\
+}									\
+									\
+static inline type pfx##in##bwlq##p(unsigned long port)			\
+{									\
+	volatile type *__addr;						\
+	type __val;							\
+									\
+	__addr = __ioport_map(port, sizeof(type));			\
+	__val = *__addr;						\
+	slow;								\
+									\
+	return __val;							\
+}
 
-/* synco on SH-4A, otherwise a nop */
-#define mmiowb()		wmb()
+#define __BUILD_IOPORT_PFX(bus, bwlq, type)				\
+	__BUILD_IOPORT_SINGLE(bus, bwlq, type, ,)			\
+	__BUILD_IOPORT_SINGLE(bus, bwlq, type, _p, SLOW_DOWN_IO)
 
-#define IO_SPACE_LIMIT 0xffffffff
+#define BUILDIO_IOPORT(bwlq, type)					\
+	__BUILD_IOPORT_PFX(, bwlq, type)
 
-#ifdef CONFIG_HAS_IOPORT
+BUILDIO_IOPORT(b, u8)
+BUILDIO_IOPORT(w, u16)
+BUILDIO_IOPORT(l, u32)
+BUILDIO_IOPORT(q, u64)
+
+#define __BUILD_IOPORT_STRING(bwlq, type)				\
+									\
+static inline void outs##bwlq(unsigned long port, const void *addr,	\
+			      unsigned int count)			\
+{									\
+	const volatile type *__addr = addr;				\
+									\
+	while (count--) {						\
+		out##bwlq(*__addr, port);				\
+		__addr++;						\
+	}								\
+}									\
+									\
+static inline void ins##bwlq(unsigned long port, void *addr,		\
+			     unsigned int count)			\
+{									\
+	volatile type *__addr = addr;					\
+									\
+	while (count--) {						\
+		*__addr = in##bwlq(port);				\
+		__addr++;						\
+	}								\
+}
+
+__BUILD_IOPORT_STRING(b, u8)
+__BUILD_IOPORT_STRING(w, u16)
+__BUILD_IOPORT_STRING(l, u32)
+__BUILD_IOPORT_STRING(q, u64)
+
+#endif
 
 /*
- * This function provides a method for the generic case where a
- * board-specific ioport_map simply needs to return the port + some
- * arbitrary port base.
+ * Legacy SuperH on-chip I/O functions
  *
- * We use this at board setup time to implicitly set the port base, and
- * as a result, we can use the generic ioport_map.
+ * These are all deprecated, all new (and especially cross-platform) code
+ * should be using the __raw_xxx() routines directly.
  */
-static inline void __set_io_port_base(unsigned long pbase)
+static inline u8 __deprecated ctrl_inb(unsigned long addr)
 {
-	generic_io_base = pbase;
+	return __raw_readb(addr);
 }
 
-#define __ioport_map(p, n) sh_mv.mv_ioport_map((p), (n))
+static inline u16 __deprecated ctrl_inw(unsigned long addr)
+{
+	return __raw_readw(addr);
+}
 
-#endif
+static inline u32 __deprecated ctrl_inl(unsigned long addr)
+{
+	return __raw_readl(addr);
+}
+
+static inline u64 __deprecated ctrl_inq(unsigned long addr)
+{
+	return __raw_readq(addr);
+}
+
+static inline void __deprecated ctrl_outb(u8 v, unsigned long addr)
+{
+	__raw_writeb(v, addr);
+}
+
+static inline void __deprecated ctrl_outw(u16 v, unsigned long addr)
+{
+	__raw_writew(v, addr);
+}
+
+static inline void __deprecated ctrl_outl(u32 v, unsigned long addr)
+{
+	__raw_writel(v, addr);
+}
+
+static inline void __deprecated ctrl_outq(u64 v, unsigned long addr)
+{
+	__raw_writeq(v, addr);
+}
+
+#define IO_SPACE_LIMIT 0xffffffff
+
+/* synco on SH-4A, otherwise a nop */
+#define mmiowb()		wmb()
 
 /* We really want to try and get these to memcpy etc */
 void memcpy_fromio(void *, const volatile void __iomem *, unsigned long);
@@ -395,10 +414,6 @@ static inline int iounmap_fixed(void __iomem *addr) { return -EINVAL; }
 #define ioremap_nocache	ioremap
 #define iounmap		__iounmap
 
-#define maybebadio(port) \
-	printk(KERN_ERR "bad PC-like io %s:%u for port 0x%lx at 0x%08x\n", \
-	       __func__, __LINE__, (port), (u32)__builtin_return_address(0))
-
 /*
  * Convert a physical pointer to a virtual kernel pointer for /dev/mem
  * access

commit 86e4dd5add77ab809f5427391dfabb8f78cbcb58
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue May 25 20:06:13 2010 +0900

    sh: support for platforms without PIO.
    
    This extends some of the existing special casing for HAS_IOPORT
    platforms and gets it to the point where platforms can begin to
    conditionally select it.
    
    The major changes here are that the PIO routines themselves go away
    completely, including all of the machvec port mapping wrappers. With this
    in place it's possible for any non-machvec abusing platform to disable
    PIO completely. At present this is left as an opt-in until the abusers
    are the odd ones out instead of the majority.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index f689554e17c1..b237d525d592 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -39,6 +39,8 @@
 #include <asm/io_generic.h>
 #include <asm/io_trapped.h>
 
+#ifdef CONFIG_HAS_IOPORT
+
 #define inb(p)			sh_mv.mv_inb((p))
 #define inw(p)			sh_mv.mv_inw((p))
 #define inl(p)			sh_mv.mv_inl((p))
@@ -60,6 +62,8 @@
 #define outsw(p,b,c)		sh_mv.mv_outsw((p), (b), (c))
 #define outsl(p,b,c)		sh_mv.mv_outsl((p), (b), (c))
 
+#endif
+
 #define __raw_writeb(v,a)	(__chk_io_ptr(a), *(volatile u8  __force *)(a) = (v))
 #define __raw_writew(v,a)	(__chk_io_ptr(a), *(volatile u16 __force *)(a) = (v))
 #define __raw_writel(v,a)	(__chk_io_ptr(a), *(volatile u32 __force *)(a) = (v))
@@ -240,6 +244,8 @@ __BUILD_MEMORY_STRING(q, u64)
 
 #define IO_SPACE_LIMIT 0xffffffff
 
+#ifdef CONFIG_HAS_IOPORT
+
 /*
  * This function provides a method for the generic case where a
  * board-specific ioport_map simply needs to return the port + some
@@ -255,6 +261,8 @@ static inline void __set_io_port_base(unsigned long pbase)
 
 #define __ioport_map(p, n) sh_mv.mv_ioport_map((p), (n))
 
+#endif
+
 /* We really want to try and get these to memcpy etc */
 void memcpy_fromio(void *, const volatile void __iomem *, unsigned long);
 void memcpy_toio(volatile void __iomem *, const void *, unsigned long);

commit 90e7d649d86f21d478dc134f74c88e19dd472393
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Feb 23 16:20:53 2010 +0900

    sh: reworked dynamic PMB mapping.
    
    This implements a fairly significant overhaul of the dynamic PMB mapping
    code. The primary change here is that the PMB gets its own VMA that
    follows the uncached mapping and we attempt to be a bit more intelligent
    with dynamic sizing, multi-entry mapping, and so forth.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 7dab7b23a5ec..f689554e17c1 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -291,21 +291,21 @@ unsigned long long poke_real_address_q(unsigned long long addr,
  * doesn't exist, so everything must go through page tables.
  */
 #ifdef CONFIG_MMU
-void __iomem *__ioremap_caller(unsigned long offset, unsigned long size,
+void __iomem *__ioremap_caller(phys_addr_t offset, unsigned long size,
 			       pgprot_t prot, void *caller);
 void __iounmap(void __iomem *addr);
 
 static inline void __iomem *
-__ioremap(unsigned long offset, unsigned long size, pgprot_t prot)
+__ioremap(phys_addr_t offset, unsigned long size, pgprot_t prot)
 {
 	return __ioremap_caller(offset, size, prot, __builtin_return_address(0));
 }
 
 static inline void __iomem *
-__ioremap_29bit(unsigned long offset, unsigned long size, pgprot_t prot)
+__ioremap_29bit(phys_addr_t offset, unsigned long size, pgprot_t prot)
 {
 #ifdef CONFIG_29BIT
-	unsigned long last_addr = offset + size - 1;
+	phys_addr_t last_addr = offset + size - 1;
 
 	/*
 	 * For P1 and P2 space this is trivial, as everything is already
@@ -329,7 +329,7 @@ __ioremap_29bit(unsigned long offset, unsigned long size, pgprot_t prot)
 }
 
 static inline void __iomem *
-__ioremap_mode(unsigned long offset, unsigned long size, pgprot_t prot)
+__ioremap_mode(phys_addr_t offset, unsigned long size, pgprot_t prot)
 {
 	void __iomem *ret;
 
@@ -349,35 +349,32 @@ __ioremap_mode(unsigned long offset, unsigned long size, pgprot_t prot)
 #define __iounmap(addr)				do { } while (0)
 #endif /* CONFIG_MMU */
 
-static inline void __iomem *
-ioremap(unsigned long offset, unsigned long size)
+static inline void __iomem *ioremap(phys_addr_t offset, unsigned long size)
 {
 	return __ioremap_mode(offset, size, PAGE_KERNEL_NOCACHE);
 }
 
 static inline void __iomem *
-ioremap_cache(unsigned long offset, unsigned long size)
+ioremap_cache(phys_addr_t offset, unsigned long size)
 {
 	return __ioremap_mode(offset, size, PAGE_KERNEL);
 }
 
 #ifdef CONFIG_HAVE_IOREMAP_PROT
 static inline void __iomem *
-ioremap_prot(resource_size_t offset, unsigned long size, unsigned long flags)
+ioremap_prot(phys_addr_t offset, unsigned long size, unsigned long flags)
 {
 	return __ioremap_mode(offset, size, __pgprot(flags));
 }
 #endif
 
 #ifdef CONFIG_IOREMAP_FIXED
-extern void __iomem *ioremap_fixed(resource_size_t, unsigned long,
-				   unsigned long, pgprot_t);
+extern void __iomem *ioremap_fixed(phys_addr_t, unsigned long, pgprot_t);
 extern int iounmap_fixed(void __iomem *);
 extern void ioremap_fixed_init(void);
 #else
 static inline void __iomem *
-ioremap_fixed(resource_size_t phys_addr, unsigned long offset,
-	      unsigned long size, pgprot_t prot)
+ioremap_fixed(phys_addr_t phys_addr, unsigned long size, pgprot_t prot)
 {
 	BUG();
 	return NULL;

commit b8f7918f332873a79e4c820e90e7a245ce4d3042
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Thu Feb 18 13:23:30 2010 +0900

    sh: Provide uncached I/O helpers.
    
    There are lots of registers that can only be updated from the uncached
    mapping, so we add some helpers for those cases in order to make it
    easier to ensure that we only make the jump when it's absolutely
    necessary.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index bd5fafa23eb4..7dab7b23a5ec 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -133,6 +133,28 @@ static inline void ctrl_delay(void)
 	__raw_readw(generic_io_base);
 }
 
+#define __BUILD_UNCACHED_IO(bwlq, type)					\
+static inline type read##bwlq##_uncached(unsigned long addr)		\
+{									\
+	type ret;							\
+	jump_to_uncached();						\
+	ret = __raw_read##bwlq(addr);					\
+	back_to_cached();						\
+	return ret;							\
+}									\
+									\
+static inline void write##bwlq##_uncached(type v, unsigned long addr)	\
+{									\
+	jump_to_uncached();						\
+	__raw_write##bwlq(v, addr);					\
+	back_to_cached();						\
+}
+
+__BUILD_UNCACHED_IO(b, u8)
+__BUILD_UNCACHED_IO(w, u16)
+__BUILD_UNCACHED_IO(l, u32)
+__BUILD_UNCACHED_IO(q, u64)
+
 #define __BUILD_MEMORY_STRING(bwlq, type)				\
 									\
 static inline void __raw_writes##bwlq(volatile void __iomem *mem,	\

commit d627a2ebd1a303aa4ac1962c553d1e8738735d01
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Thu Jan 28 18:17:29 2010 +0900

    sh: Fix up the ioremap_fixed() build for nommu.
    
    arch/sh/kernel/setup.c:455: error: implicit declaration of function 'ioremap_fixed_init'
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 98c62fa168c2..bd5fafa23eb4 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -273,24 +273,6 @@ void __iomem *__ioremap_caller(unsigned long offset, unsigned long size,
 			       pgprot_t prot, void *caller);
 void __iounmap(void __iomem *addr);
 
-#ifdef CONFIG_IOREMAP_FIXED
-extern void __iomem *ioremap_fixed(resource_size_t, unsigned long,
-				   unsigned long, pgprot_t);
-extern int iounmap_fixed(void __iomem *);
-extern void ioremap_fixed_init(void);
-#else
-static inline void __iomem *
-ioremap_fixed(resource_size_t phys_addr, unsigned long offset,
-	      unsigned long size, pgprot_t prot)
-{
-	BUG();
-	return NULL;
-}
-
-static inline void ioremap_fixed_init(void) { }
-static inline int iounmap_fixed(void __iomem *addr) { return -EINVAL; }
-#endif
-
 static inline void __iomem *
 __ioremap(unsigned long offset, unsigned long size, pgprot_t prot)
 {
@@ -365,6 +347,24 @@ ioremap_prot(resource_size_t offset, unsigned long size, unsigned long flags)
 }
 #endif
 
+#ifdef CONFIG_IOREMAP_FIXED
+extern void __iomem *ioremap_fixed(resource_size_t, unsigned long,
+				   unsigned long, pgprot_t);
+extern int iounmap_fixed(void __iomem *);
+extern void ioremap_fixed_init(void);
+#else
+static inline void __iomem *
+ioremap_fixed(resource_size_t phys_addr, unsigned long offset,
+	      unsigned long size, pgprot_t prot)
+{
+	BUG();
+	return NULL;
+}
+
+static inline void ioremap_fixed_init(void) { }
+static inline int iounmap_fixed(void __iomem *addr) { return -EINVAL; }
+#endif
+
 #define ioremap_nocache	ioremap
 #define iounmap		__iounmap
 

commit 485773f3e401fca31c112c1ff24797e42ff87afd
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Jan 26 13:02:10 2010 +0900

    sh: flag ctrl_in/outX as __deprecated.
    
    These routines are unsuitable for cross-platform use and no new code
    should be using them, flag them as deprecated in order to give drivers
    sufficient time to migrate over.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index e4f563f472eb..98c62fa168c2 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -80,16 +80,51 @@
 #define writel(v,a)		({ __raw_writel((v),(a)); mb(); })
 #define writeq(v,a)		({ __raw_writeq((v),(a)); mb(); })
 
-/* SuperH on-chip I/O functions */
-#define ctrl_inb		__raw_readb
-#define ctrl_inw		__raw_readw
-#define ctrl_inl		__raw_readl
-#define ctrl_inq		__raw_readq
-
-#define ctrl_outb		__raw_writeb
-#define ctrl_outw		__raw_writew
-#define ctrl_outl		__raw_writel
-#define ctrl_outq		__raw_writeq
+/*
+ * Legacy SuperH on-chip I/O functions
+ *
+ * These are all deprecated, all new (and especially cross-platform) code
+ * should be using the __raw_xxx() routines directly.
+ */
+static inline u8 __deprecated ctrl_inb(unsigned long addr)
+{
+	return __raw_readb(addr);
+}
+
+static inline u16 __deprecated ctrl_inw(unsigned long addr)
+{
+	return __raw_readw(addr);
+}
+
+static inline u32 __deprecated ctrl_inl(unsigned long addr)
+{
+	return __raw_readl(addr);
+}
+
+static inline u64 __deprecated ctrl_inq(unsigned long addr)
+{
+	return __raw_readq(addr);
+}
+
+static inline void __deprecated ctrl_outb(u8 v, unsigned long addr)
+{
+	__raw_writeb(v, addr);
+}
+
+static inline void __deprecated ctrl_outw(u16 v, unsigned long addr)
+{
+	__raw_writew(v, addr);
+}
+
+static inline void __deprecated ctrl_outl(u32 v, unsigned long addr)
+{
+	__raw_writel(v, addr);
+}
+
+static inline void __deprecated ctrl_outq(u64 v, unsigned long addr)
+{
+	__raw_writeq(v, addr);
+}
 
 extern unsigned long generic_io_base;
 

commit 70911b861bfbba1851cbb3497635030f34703c7a
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Wed Jan 20 02:45:05 2010 +0900

    sh: Shut up noisy IOREMAP_FIXED=n build.
    
    The ioremap_fixed() stub neglected to provide a return value, resulting
    in a fairly noisy build.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 4bad72a1b39e..e4f563f472eb 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -245,10 +245,11 @@ extern int iounmap_fixed(void __iomem *);
 extern void ioremap_fixed_init(void);
 #else
 static inline void __iomem *
-ioremap_fixed(resource_size t phys_addr, unsigned long offset,
+ioremap_fixed(resource_size_t phys_addr, unsigned long offset,
 	      unsigned long size, pgprot_t prot)
 {
 	BUG();
+	return NULL;
 }
 
 static inline void ioremap_fixed_init(void) { }

commit 6d63e73d520b690e4378cef3003eb5f01f7d128c
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Jan 19 14:00:14 2010 +0900

    sh: Limit ioremap_prot() to 32bit pgprot parts.
    
    Presently ioremap_prot() uses an unsigned long to pass the pgprot value
    around. This results in the upper half of the pgprot being chomped when
    using 64-bit pgprots on a 32-bit ABI (X2TLB and SH-5).
    
    As the only users of ioremap_prot() are presently legacy parts, this
    doesn't cause too much of an issue. In the future when the interface is
    converted to use pgprot_t directly this can be re-enabled for the other
    parts, too.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index c32a55601d01..4bad72a1b39e 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -321,11 +321,13 @@ ioremap_cache(unsigned long offset, unsigned long size)
 	return __ioremap_mode(offset, size, PAGE_KERNEL);
 }
 
+#ifdef CONFIG_HAVE_IOREMAP_PROT
 static inline void __iomem *
 ioremap_prot(resource_size_t offset, unsigned long size, unsigned long flags)
 {
 	return __ioremap_mode(offset, size, __pgprot(flags));
 }
+#endif
 
 #define ioremap_nocache	ioremap
 #define iounmap		__iounmap

commit f33609344acfdde1c1acedf6de3efe6b80af93a6
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Jan 19 13:55:41 2010 +0900

    sh: Convert p3_ioremap() users to ioremap_prot().
    
    This kills off the ancient p3_ioremap(), converting over to the more
    generic ioremap_prot() instead.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 70269813cef1..c32a55601d01 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -328,7 +328,6 @@ ioremap_prot(resource_size_t offset, unsigned long size, unsigned long flags)
 }
 
 #define ioremap_nocache	ioremap
-#define p3_ioremap	__ioremap
 #define iounmap		__iounmap
 
 #define maybebadio(port) \

commit acf2c9685fb8295cb62a623d7358a1cfde8b07ea
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Jan 19 13:49:19 2010 +0900

    sh: Kill off duplicate address alignment in ioremap_fixed().
    
    This is already taken care of in the top-level ioremap, and now that
    no one should be calling ioremap_fixed() directly we can simply throw the
    mapping displacement in as an additional argument.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 13696dfccc16..70269813cef1 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -239,12 +239,14 @@ void __iomem *__ioremap_caller(unsigned long offset, unsigned long size,
 void __iounmap(void __iomem *addr);
 
 #ifdef CONFIG_IOREMAP_FIXED
-extern void __iomem *ioremap_fixed(resource_size_t, unsigned long, pgprot_t);
+extern void __iomem *ioremap_fixed(resource_size_t, unsigned long,
+				   unsigned long, pgprot_t);
 extern int iounmap_fixed(void __iomem *);
 extern void ioremap_fixed_init(void);
 #else
 static inline void __iomem *
-ioremap_fixed(resource_size t phys_addr, unsigned long size, pgprot_t prot)
+ioremap_fixed(resource_size t phys_addr, unsigned long offset,
+	      unsigned long size, pgprot_t prot)
 {
 	BUG();
 }

commit d57d64080ddc0ff13fcffc898b6251074a482ba1
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Jan 19 13:34:38 2010 +0900

    sh: Prevent 64-bit pgprot clobbering across ioremap implementations.
    
    Presently 'flags' gets passed around a lot between the various ioremap
    helpers and implementations, which is only 32-bits. In the X2TLB case
    we use 64-bit pgprots which presently results in the upper 32bits being
    chopped off (which handily include our read/write/exec permissions).
    
    As such, we convert everything internally to using pgprot_t directly and
    simply convert over with pgprot_val() where needed. With this in place,
    transparent fixmap utilization for early ioremap works as expected.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 6a0dd8c1e0a9..13696dfccc16 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -235,7 +235,7 @@ unsigned long long poke_real_address_q(unsigned long long addr,
  */
 #ifdef CONFIG_MMU
 void __iomem *__ioremap_caller(unsigned long offset, unsigned long size,
-			       unsigned long flags, void *caller);
+			       pgprot_t prot, void *caller);
 void __iounmap(void __iomem *addr);
 
 #ifdef CONFIG_IOREMAP_FIXED
@@ -254,13 +254,13 @@ static inline int iounmap_fixed(void __iomem *addr) { return -EINVAL; }
 #endif
 
 static inline void __iomem *
-__ioremap(unsigned long offset, unsigned long size, unsigned long flags)
+__ioremap(unsigned long offset, unsigned long size, pgprot_t prot)
 {
-	return __ioremap_caller(offset, size, flags, __builtin_return_address(0));
+	return __ioremap_caller(offset, size, prot, __builtin_return_address(0));
 }
 
 static inline void __iomem *
-__ioremap_29bit(unsigned long offset, unsigned long size, unsigned long flags)
+__ioremap_29bit(unsigned long offset, unsigned long size, pgprot_t prot)
 {
 #ifdef CONFIG_29BIT
 	unsigned long last_addr = offset + size - 1;
@@ -272,7 +272,7 @@ __ioremap_29bit(unsigned long offset, unsigned long size, unsigned long flags)
 	 * mapping must be done by the PMB or by using page tables.
 	 */
 	if (likely(PXSEG(offset) < P3SEG && PXSEG(last_addr) < P3SEG)) {
-		if (unlikely(flags & _PAGE_CACHABLE))
+		if (unlikely(pgprot_val(prot) & _PAGE_CACHABLE))
 			return (void __iomem *)P1SEGADDR(offset);
 
 		return (void __iomem *)P2SEGADDR(offset);
@@ -287,7 +287,7 @@ __ioremap_29bit(unsigned long offset, unsigned long size, unsigned long flags)
 }
 
 static inline void __iomem *
-__ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
+__ioremap_mode(unsigned long offset, unsigned long size, pgprot_t prot)
 {
 	void __iomem *ret;
 
@@ -295,30 +295,39 @@ __ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
 	if (ret)
 		return ret;
 
-	ret = __ioremap_29bit(offset, size, flags);
+	ret = __ioremap_29bit(offset, size, prot);
 	if (ret)
 		return ret;
 
-	return __ioremap(offset, size, flags);
+	return __ioremap(offset, size, prot);
 }
 #else
-#define __ioremap(offset, size, flags)		((void __iomem *)(offset))
-#define __ioremap_mode(offset, size, flags)	((void __iomem *)(offset))
+#define __ioremap(offset, size, prot)		((void __iomem *)(offset))
+#define __ioremap_mode(offset, size, prot)	((void __iomem *)(offset))
 #define __iounmap(addr)				do { } while (0)
 #endif /* CONFIG_MMU */
 
-#define ioremap(offset, size)				\
-	__ioremap_mode((offset), (size), 0)
-#define ioremap_nocache(offset, size)			\
-	__ioremap_mode((offset), (size), 0)
-#define ioremap_cache(offset, size)			\
-	__ioremap_mode((offset), (size), _PAGE_CACHABLE)
-#define p3_ioremap(offset, size, flags)			\
-	__ioremap((offset), (size), (flags))
-#define ioremap_prot(offset, size, flags)		\
-	__ioremap_mode((offset), (size), (flags))
-#define iounmap(addr)					\
-	__iounmap((addr))
+static inline void __iomem *
+ioremap(unsigned long offset, unsigned long size)
+{
+	return __ioremap_mode(offset, size, PAGE_KERNEL_NOCACHE);
+}
+
+static inline void __iomem *
+ioremap_cache(unsigned long offset, unsigned long size)
+{
+	return __ioremap_mode(offset, size, PAGE_KERNEL);
+}
+
+static inline void __iomem *
+ioremap_prot(resource_size_t offset, unsigned long size, unsigned long flags)
+{
+	return __ioremap_mode(offset, size, __pgprot(flags));
+}
+
+#define ioremap_nocache	ioremap
+#define p3_ioremap	__ioremap
+#define iounmap		__iounmap
 
 #define maybebadio(port) \
 	printk(KERN_ERR "bad PC-like io %s:%u for port 0x%lx at 0x%08x\n", \

commit 4f744affc345f8b158615e0cdd01d1f4985837c3
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Jan 18 21:30:29 2010 +0900

    sh: Make iounmap_fixed() return success/failure for iounmap() path.
    
    This converts iounmap_fixed() to return success/error if it handled the
    unmap request or not. At the same time, drop the __init label, as this
    can be called in to later.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 9aa9438c66c3..6a0dd8c1e0a9 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -22,6 +22,7 @@
  * for old compat code for I/O offseting to SuperIOs, all of which are
  * better handled through the machvec ioport mapping routines these days.
  */
+#include <linux/errno.h>
 #include <asm/cache.h>
 #include <asm/system.h>
 #include <asm/addrspace.h>
@@ -239,7 +240,7 @@ void __iounmap(void __iomem *addr);
 
 #ifdef CONFIG_IOREMAP_FIXED
 extern void __iomem *ioremap_fixed(resource_size_t, unsigned long, pgprot_t);
-extern void iounmap_fixed(void __iomem *);
+extern int iounmap_fixed(void __iomem *);
 extern void ioremap_fixed_init(void);
 #else
 static inline void __iomem *
@@ -249,7 +250,7 @@ ioremap_fixed(resource_size t phys_addr, unsigned long size, pgprot_t prot)
 }
 
 static inline void ioremap_fixed_init(void) { }
-static inline void iounmap_fixed(void __iomem *addr) { }
+static inline int iounmap_fixed(void __iomem *addr) { return -EINVAL; }
 #endif
 
 static inline void __iomem *

commit edf711b66f2a8a9629aa253ad8b3a5a03b5d7af5
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Jan 18 21:20:13 2010 +0900

    sh: Fixup the IOREMAP_FIXED=n build.
    
    Presently the fixed ioremap API is only defined when CONFIG_IOREMAP_FIXED
    is set. As we want to call in to it unconditionally, provide a stubbed
    out interface.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index bee5965e0a82..9aa9438c66c3 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -241,6 +241,15 @@ void __iounmap(void __iomem *addr);
 extern void __iomem *ioremap_fixed(resource_size_t, unsigned long, pgprot_t);
 extern void iounmap_fixed(void __iomem *);
 extern void ioremap_fixed_init(void);
+#else
+static inline void __iomem *
+ioremap_fixed(resource_size t phys_addr, unsigned long size, pgprot_t prot)
+{
+	BUG();
+}
+
+static inline void ioremap_fixed_init(void) { }
+static inline void iounmap_fixed(void __iomem *addr) { }
 #endif
 
 static inline void __iomem *

commit 4d35b93a66e9b87df20784fcf130d2e8760be53f
Author: Matt Fleming <matt@console-pimps.org>
Date:   Thu Nov 5 07:54:17 2009 +0000

    sh: Add fixed ioremap support
    
    Some devices need to be ioremap'd and accessed very early in the boot
    process. It is not possible to use the standard ioremap() function in
    this case because that requires kmalloc()'ing some virtual address space
    and kmalloc() may not be available so early in boot.
    
    This patch provides fixmap mappings that allow physical address ranges
    to be remapped into the kernel address space during the early boot
    stages.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index f4314d8b05b8..bee5965e0a82 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -237,6 +237,12 @@ void __iomem *__ioremap_caller(unsigned long offset, unsigned long size,
 			       unsigned long flags, void *caller);
 void __iounmap(void __iomem *addr);
 
+#ifdef CONFIG_IOREMAP_FIXED
+extern void __iomem *ioremap_fixed(resource_size_t, unsigned long, pgprot_t);
+extern void iounmap_fixed(void __iomem *);
+extern void ioremap_fixed_init(void);
+#endif
+
 static inline void __iomem *
 __ioremap(unsigned long offset, unsigned long size, unsigned long flags)
 {

commit a0ab36689a36e583b6e736f1c99ac8c9aebdad59
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Wed Jan 13 18:31:48 2010 +0900

    sh: fixed PMB mode refactoring.
    
    This introduces some much overdue chainsawing of the fixed PMB support.
    fixed PMB was introduced initially to work around the fact that dynamic
    PMB mode was relatively broken, though they were never intended to
    converge. The main areas where there are differences are whether the
    system is booted in 29-bit mode or 32-bit mode, and whether legacy
    mappings are to be preserved. Any system booting in true 32-bit mode will
    not care about legacy mappings, so these are roughly decoupled.
    
    Regardless of the entry point, PMB and 32BIT are directly related as far
    as the kernel is concerned, so we also switch back to having one select
    the other.
    
    With legacy mappings iterated through and applied in the initialization
    path it's now possible to finally merge the two implementations and
    permit dynamic remapping overtop of remaining entries regardless of
    whether boot mappings are crafted by hand or inherited from the boot
    loader.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 026dd659a640..f4314d8b05b8 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -244,18 +244,11 @@ __ioremap(unsigned long offset, unsigned long size, unsigned long flags)
 }
 
 static inline void __iomem *
-__ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
+__ioremap_29bit(unsigned long offset, unsigned long size, unsigned long flags)
 {
-#if defined(CONFIG_SUPERH32) && !defined(CONFIG_PMB_FIXED) && !defined(CONFIG_PMB)
+#ifdef CONFIG_29BIT
 	unsigned long last_addr = offset + size - 1;
-#endif
-	void __iomem *ret;
 
-	ret = __ioremap_trapped(offset, size);
-	if (ret)
-		return ret;
-
-#if defined(CONFIG_SUPERH32) && !defined(CONFIG_PMB_FIXED) && !defined(CONFIG_PMB)
 	/*
 	 * For P1 and P2 space this is trivial, as everything is already
 	 * mapped. Uncached access for P1 addresses are done through P2.
@@ -274,6 +267,22 @@ __ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
 		return (void __iomem *)P4SEGADDR(offset);
 #endif
 
+	return NULL;
+}
+
+static inline void __iomem *
+__ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
+{
+	void __iomem *ret;
+
+	ret = __ioremap_trapped(offset, size);
+	if (ret)
+		return ret;
+
+	ret = __ioremap_29bit(offset, size, flags);
+	if (ret)
+		return ret;
+
 	return __ioremap(offset, size, flags);
 }
 #else

commit 0eb37e26ed332b2a96630cf7f7ebe9fddb41cc3c
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Dec 14 14:55:45 2009 +0900

    sh: Stub in P3 ioremap support for nommu parts.
    
    p3_ioremap() references __ioremap() which is presently undefined on
    nommu. This provides a trivial stub to fix the build up.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 988c1be58e51..026dd659a640 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -277,6 +277,7 @@ __ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
 	return __ioremap(offset, size, flags);
 }
 #else
+#define __ioremap(offset, size, flags)		((void __iomem *)(offset))
 #define __ioremap_mode(offset, size, flags)	((void __iomem *)(offset))
 #define __iounmap(addr)				do { } while (0)
 #endif /* CONFIG_MMU */

commit bf3cdeda901c7f42de3cddc8c5aa19f6b8d8f9df
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Mon Dec 14 14:23:41 2009 +0900

    sh: wire up vmallocinfo support in ioremap() implementations.
    
    This wires up the caller information for the ioremap VMA, which allows
    for more helpful caller tracking via /proc/vmallocinfo. Follows the x86
    and powerpc changes of the same nature.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 512cd3e9d0ca..988c1be58e51 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -233,10 +233,16 @@ unsigned long long poke_real_address_q(unsigned long long addr,
  * doesn't exist, so everything must go through page tables.
  */
 #ifdef CONFIG_MMU
-void __iomem *__ioremap(unsigned long offset, unsigned long size,
-			unsigned long flags);
+void __iomem *__ioremap_caller(unsigned long offset, unsigned long size,
+			       unsigned long flags, void *caller);
 void __iounmap(void __iomem *addr);
 
+static inline void __iomem *
+__ioremap(unsigned long offset, unsigned long size, unsigned long flags)
+{
+	return __ioremap_caller(offset, size, flags, __builtin_return_address(0));
+}
+
 static inline void __iomem *
 __ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
 {

commit e9c58fc57b17bfa75c256fb4f45ce22de6626858
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Thu Nov 12 16:36:26 2009 +0900

    sh: Use the generic I/O port base for slowdown.
    
    This fixes up the build and behaviour for various configurations. Namely
    the CONFIG_32BIT cases where legacy mappings do not exist, as well as the
    sh64 build.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 0cf2a5708e26..512cd3e9d0ca 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -90,15 +90,11 @@
 #define ctrl_outl		__raw_writel
 #define ctrl_outq		__raw_writeq
 
+extern unsigned long generic_io_base;
+
 static inline void ctrl_delay(void)
 {
-#ifdef CONFIG_CPU_SH4
-	__raw_readw(CCN_PVR);
-#elif defined(P2SEG)
-	__raw_readw(P2SEG);
-#else
-#error "Need a dummy address for delay"
-#endif
+	__raw_readw(generic_io_base);
 }
 
 #define __BUILD_MEMORY_STRING(bwlq, type)				\
@@ -186,8 +182,6 @@ __BUILD_MEMORY_STRING(q, u64)
 
 #define IO_SPACE_LIMIT 0xffffffff
 
-extern unsigned long generic_io_base;
-
 /*
  * This function provides a method for the generic case where a
  * board-specific ioport_map simply needs to return the port + some

commit 3105121949b609964f370d42d1b90fe7fc01d6b1
Author: Matt Fleming <matt@console-pimps.org>
Date:   Tue Oct 6 21:22:30 2009 +0000

    sh: Remap physical memory into P1 and P2 in pmb_init()
    
    Eventually we'll have complete control over what physical memory gets
    mapped where and we can probably do other interesting things. For now
    though, when the MMU is in 32-bit mode, we map physical memory into the
    P1 and P2 virtual address ranges with the same semantics as they have in
    29-bit mode.
    
    Signed-off-by: Matt Fleming <matt@console-pimps.org>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 5be45ea4dfec..0cf2a5708e26 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -246,7 +246,7 @@ void __iounmap(void __iomem *addr);
 static inline void __iomem *
 __ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
 {
-#if defined(CONFIG_SUPERH32) && !defined(CONFIG_PMB_FIXED)
+#if defined(CONFIG_SUPERH32) && !defined(CONFIG_PMB_FIXED) && !defined(CONFIG_PMB)
 	unsigned long last_addr = offset + size - 1;
 #endif
 	void __iomem *ret;
@@ -255,7 +255,7 @@ __ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
 	if (ret)
 		return ret;
 
-#if defined(CONFIG_SUPERH32) && !defined(CONFIG_PMB_FIXED)
+#if defined(CONFIG_SUPERH32) && !defined(CONFIG_PMB_FIXED) && !defined(CONFIG_PMB)
 	/*
 	 * For P1 and P2 space this is trivial, as everything is already
 	 * mapped. Uncached access for P1 addresses are done through P2.

commit 7d9c035150897c2bebedae280505513dbdef2abc
Author: Stuart Menefy <stuart.menefy@st.com>
Date:   Mon Aug 24 17:13:52 2009 +0900

    sh: Read from CCN_PVR instead of ROM for delay.
    
    Reading from the ROM is not a good idea as it could disturb some
    flash operation that it is in progress.
    
    Signed-off-by: Stuart Menefy <stuart.menefy@st.com>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index aeecf432d48c..5be45ea4dfec 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -92,8 +92,12 @@
 
 static inline void ctrl_delay(void)
 {
-#ifdef P2SEG
+#ifdef CONFIG_CPU_SH4
+	__raw_readw(CCN_PVR);
+#elif defined(P2SEG)
 	__raw_readw(P2SEG);
+#else
+#error "Need a dummy address for delay"
 #endif
 }
 

commit 15444a8973dcfbd286b3e638cbadac2446a9271a
Author: David McKay <david.mckay@st.com>
Date:   Mon Aug 24 16:10:40 2009 +0900

    sh: Allow use of GENERIC_IOMAP
    
    The synopsys PCI cell used in the later STMicro chips requires code to
    be run in order to do IO cycles, rather than just memory mapping the IO
    space. Rather than extending the existing SH infrastructure to allow
    this, use the GENERIC_IOMAP implmentation to save re-inventing the
    wheel.
    
    This set of changes allows the SH to be built with GENERIC_IOMAP
    enabled, it just ifdef's out the functions provided by the GENERIC_IOMAP
    implementation, and provides a few required missing functions.
    
    Signed-off-by: David McKay <david.mckay@st.com>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 25348141674b..aeecf432d48c 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -146,6 +146,7 @@ __BUILD_MEMORY_STRING(q, u64)
 #define readl_relaxed(a)	readl(a)
 #define readq_relaxed(a)	readq(a)
 
+#ifndef CONFIG_GENERIC_IOMAP
 /* Simple MMIO */
 #define ioread8(a)		__raw_readb(a)
 #define ioread16(a)		__raw_readw(a)
@@ -166,6 +167,15 @@ __BUILD_MEMORY_STRING(q, u64)
 #define iowrite8_rep(a, s, c)	__raw_writesb((a), (s), (c))
 #define iowrite16_rep(a, s, c)	__raw_writesw((a), (s), (c))
 #define iowrite32_rep(a, s, c)	__raw_writesl((a), (s), (c))
+#endif
+
+#define mmio_insb(p,d,c)	__raw_readsb(p,d,c)
+#define mmio_insw(p,d,c)	__raw_readsw(p,d,c)
+#define mmio_insl(p,d,c)	__raw_readsl(p,d,c)
+
+#define mmio_outsb(p,s,c)	__raw_writesb(p,s,c)
+#define mmio_outsw(p,s,c)	__raw_writesw(p,s,c)
+#define mmio_outsl(p,s,c)	__raw_writesl(p,s,c)
 
 /* synco on SH-4A, otherwise a nop */
 #define mmiowb()		wmb()

commit 6dbe47a170f80159f23c856ad4e02f2685c6f6cb
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Sat May 9 14:44:30 2009 +0900

    sh: Provide __read_{read,write}sl() definitions for sh64.
    
    These are presently only defined for sh32, use the plain unoptimized
    versions for sh64. Fixes up smsc911x build.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index c7c360b58667..25348141674b 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -123,10 +123,15 @@ static inline void __raw_reads##bwlq(volatile void __iomem *mem,	\
 
 __BUILD_MEMORY_STRING(b, u8)
 __BUILD_MEMORY_STRING(w, u16)
-__BUILD_MEMORY_STRING(q, u64)
 
+#ifdef CONFIG_SUPERH32
 void __raw_writesl(void __iomem *addr, const void *data, int longlen);
 void __raw_readsl(const void __iomem *addr, void *data, int longlen);
+#else
+__BUILD_MEMORY_STRING(l, u32)
+#endif
+
+__BUILD_MEMORY_STRING(q, u64)
 
 #define writesb			__raw_writesb
 #define writesw			__raw_writesw

commit 0fb849b9d743a20056f2418cd955e5c650658663
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Thu May 7 18:10:27 2009 +0900

    sh: Integrate the SH-5 onchip_remap() more coherently.
    
    Presently this is special-cased for early initialization. While there are
    situations where these static early initializations are still necessary,
    with minor changes it is possible to use this for the regular ioremap
    implementation as well. This allows us to kill off the special-casing for
    the remap completely and to start tidying up all of the SH-5
    special-casing in drivers.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index ef217344afcb..c7c360b58667 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -224,11 +224,6 @@ void __iomem *__ioremap(unsigned long offset, unsigned long size,
 			unsigned long flags);
 void __iounmap(void __iomem *addr);
 
-/* arch/sh/mm/ioremap_64.c */
-unsigned long onchip_remap(unsigned long addr, unsigned long size,
-			   const char *name);
-extern void onchip_unmap(unsigned long vaddr);
-
 static inline void __iomem *
 __ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
 {
@@ -263,8 +258,6 @@ __ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
 	return __ioremap(offset, size, flags);
 }
 #else
-#define onchip_remap(addr, size, name)		(addr)
-#define onchip_unmap(addr)			do { } while (0)
 #define __ioremap_mode(offset, size, flags)	((void __iomem *)(offset))
 #define __iounmap(addr)				do { } while (0)
 #endif /* CONFIG_MMU */

commit e6be3a25861429166f945499c7ee616875bc3db9
Author: Magnus Damm <damm@igel.co.jp>
Date:   Thu Apr 30 12:56:37 2009 +0900

    sh: pass through ioremap() for non-mmu processors.
    
    All 32-bit SuperH processors currently go through __ioremap_mode()
    and check for IO_TRAPPED and directly mapped segments. With this
    patch we simplify the MMU less case with a pass through version of
     __ioremap_mode() which just returns the physical address.
    
    The effects of this is change are:
     - fix non-MMU ioremap() of high address hardware blocks (sh7203 CMT)
     - make sure IO_TRAPPED is not selected
    
    Signed-off-by: Magnus Damm <damm@igel.co.jp>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 0454f8d68059..ef217344afcb 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -228,12 +228,6 @@ void __iounmap(void __iomem *addr);
 unsigned long onchip_remap(unsigned long addr, unsigned long size,
 			   const char *name);
 extern void onchip_unmap(unsigned long vaddr);
-#else
-#define __ioremap(offset, size, flags)	((void __iomem *)(offset))
-#define __iounmap(addr)			do { } while (0)
-#define onchip_remap(addr, size, name)	(addr)
-#define onchip_unmap(addr)		do { } while (0)
-#endif /* CONFIG_MMU */
 
 static inline void __iomem *
 __ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
@@ -268,6 +262,12 @@ __ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
 
 	return __ioremap(offset, size, flags);
 }
+#else
+#define onchip_remap(addr, size, name)		(addr)
+#define onchip_unmap(addr)			do { } while (0)
+#define __ioremap_mode(offset, size, flags)	((void __iomem *)(offset))
+#define __iounmap(addr)				do { } while (0)
+#endif /* CONFIG_MMU */
 
 #define ioremap(offset, size)				\
 	__ioremap_mode((offset), (size), 0)

commit 2f47f44790a9c8fc43e515df3c6be19a35ee5de5
Author: Yoshihiro Shimoda <shimoda.yoshihiro@renesas.com>
Date:   Tue Mar 10 15:49:54 2009 +0900

    sh: Support fixed 32-bit PMB mappings from bootloader.
    
    This provides a method for supporting fixed PMB mappings inherited from
    the bootloader, as an alternative to the dynamic PMB mapping currently
    used by the kernel. In the future these methods will be combined.
    
    P1/P2 area is handled like a regular 29-bit physical address, and local
    bus device are assigned P3 area addresses.
    
    Signed-off-by: Yoshihiro Shimoda <shimoda.yoshihiro@renesas.com>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 61f6dae40534..0454f8d68059 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -238,7 +238,7 @@ extern void onchip_unmap(unsigned long vaddr);
 static inline void __iomem *
 __ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
 {
-#ifdef CONFIG_SUPERH32
+#if defined(CONFIG_SUPERH32) && !defined(CONFIG_PMB_FIXED)
 	unsigned long last_addr = offset + size - 1;
 #endif
 	void __iomem *ret;
@@ -247,7 +247,7 @@ __ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
 	if (ret)
 		return ret;
 
-#ifdef CONFIG_SUPERH32
+#if defined(CONFIG_SUPERH32) && !defined(CONFIG_PMB_FIXED)
 	/*
 	 * For P1 and P2 space this is trivial, as everything is already
 	 * mapped. Uncached access for P1 addresses are done through P2.

commit 716777db7270255f1f7210fd87a7188b08c9a267
Author: Magnus Damm <damm@igel.co.jp>
Date:   Tue Nov 25 21:57:29 2008 +0900

    sh: P4 ioremap pass-through
    
    This patch adds a pass-through case when ioremapping P4 addresses.
    
    Addresses passed to ioremap() should be physical addresses, so the
    best option is usually to convert the virtual address to a physical
    address before calling ioremap. This will give you a virtual address
    in P2 which matches the physical address and this works well for
    most internal hardware blocks on the SuperH architecture.
    
    However, some hardware blocks must be accessed through P4. Converting
    the P4 address to a physical and then back to a P2 does not work. One
    example of this is the sh7722 TMU block, it must be accessed through P4.
    
    Without this patch P4 addresses will be mapped using PTEs which
    requires the page allocator to be up and running.
    
    Signed-off-by: Magnus Damm <damm@igel.co.jp>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 65eaae34e753..61f6dae40534 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -260,6 +260,10 @@ __ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
 
 		return (void __iomem *)P2SEGADDR(offset);
 	}
+
+	/* P4 above the store queues are always mapped. */
+	if (unlikely(offset >= P3_ADDR_MAX))
+		return (void __iomem *)P4SEGADDR(offset);
 #endif
 
 	return __ioremap(offset, size, flags);

commit 185aed75570fb4f78ef283dfa26cd9da5fa06a91
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Wed Nov 12 12:53:48 2008 +0900

    sh: Provide a sane valid_phys_addr_range() to prevent TLB reset with PMB.
    
    With the PMB enabled, only P1SEG and up are covered by the PMB mappings,
    meaning that situations where out-of-bounds physical addresses are read
    from will lead to TLB reset after the PMB miss, allowing for use cases
    like dd if=/dev/mem to reset the TLB.
    
    Fix this up to make sure the reference is between __MEMORY_START (phys)
    and __pa(high_memory). This is coherent across all variants of sh/sh64
    with and without MMU, though the PMB bug itself is only applicable to
    SH-4A parts.
    
    Reported-by: Hideo Saito <saito@densan.co.jp>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 436c28539577..65eaae34e753 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -293,6 +293,10 @@ __ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
  */
 #define xlate_dev_kmem_ptr(p)	p
 
+#define ARCH_HAS_VALID_PHYS_ADDR_RANGE
+int valid_phys_addr_range(unsigned long addr, size_t size);
+int valid_mmap_phys_addr_range(unsigned long pfn, size_t size);
+
 #endif /* __KERNEL__ */
 
 #endif /* __ASM_SH_IO_H */

commit 14866543ad22014a0b12e10657a917eb6b487248
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Sat Oct 4 05:25:52 2008 +0900

    sh: More I/O routine overhauling.
    
    This tidies up a lot of the PIO/MMIO split. No in-tree platforms were
    making use of the MMIO overloading through the machvec (nor have any of
    them been in some time), so we just kill all of that off. The ISA I/O
    routine wrapping remains unaffected, which remains the only special
    casing outside of the iomap API that boards need to think about.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index d9e794eff830..436c28539577 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -1,27 +1,26 @@
 #ifndef __ASM_SH_IO_H
 #define __ASM_SH_IO_H
-
 /*
  * Convention:
- *    read{b,w,l}/write{b,w,l} are for PCI,
+ *    read{b,w,l,q}/write{b,w,l,q} are for PCI,
  *    while in{b,w,l}/out{b,w,l} are for ISA
- * These may (will) be platform specific function.
+ *
  * In addition we have 'pausing' versions: in{b,w,l}_p/out{b,w,l}_p
  * and 'string' versions: ins{b,w,l}/outs{b,w,l}
- * For read{b,w,l} and write{b,w,l} there are also __raw versions, which
- * do not have a memory barrier after them.
  *
- * In addition, we have
- *   ctrl_in{b,w,l}/ctrl_out{b,w,l} for SuperH specific I/O.
- *   which are processor specific.
- */
-
-/*
- * We follow the Alpha convention here:
- *  __inb expands to an inline function call (which calls via the mv)
- *  _inb  is a real function call (note ___raw fns are _ version of __raw)
- *  inb   by default expands to _inb, but the machine specific code may
- *        define it to __inb if it chooses.
+ * While read{b,w,l,q} and write{b,w,l,q} contain memory barriers
+ * automatically, there are also __raw versions, which do not.
+ *
+ * Historically, we have also had ctrl_in{b,w,l,q}/ctrl_out{b,w,l,q} for
+ * SuperH specific I/O (raw I/O to on-chip CPU peripherals). In practice
+ * these have the same semantics as the __raw variants, and as such, all
+ * new code should be using the __raw versions.
+ *
+ * All ISA I/O routines are wrapped through the machine vector. If a
+ * board does not provide overrides, a generic set that are copied in
+ * from the default machine vector are used instead. These are largely
+ * for old compat code for I/O offseting to SuperIOs, all of which are
+ * better handled through the machvec ioport mapping routines these days.
  */
 #include <asm/cache.h>
 #include <asm/system.h>
@@ -31,7 +30,6 @@
 #include <asm-generic/iomap.h>
 
 #ifdef __KERNEL__
-
 /*
  * Depending on which platform we are running on, we need different
  * I/O functions.
@@ -40,90 +38,64 @@
 #include <asm/io_generic.h>
 #include <asm/io_trapped.h>
 
-#define maybebadio(port) \
-  printk(KERN_ERR "bad PC-like io %s:%u for port 0x%lx at 0x%08x\n", \
-	 __FUNCTION__, __LINE__, (port), (u32)__builtin_return_address(0))
+#define inb(p)			sh_mv.mv_inb((p))
+#define inw(p)			sh_mv.mv_inw((p))
+#define inl(p)			sh_mv.mv_inl((p))
+#define outb(x,p)		sh_mv.mv_outb((x),(p))
+#define outw(x,p)		sh_mv.mv_outw((x),(p))
+#define outl(x,p)		sh_mv.mv_outl((x),(p))
+
+#define inb_p(p)		sh_mv.mv_inb_p((p))
+#define inw_p(p)		sh_mv.mv_inw_p((p))
+#define inl_p(p)		sh_mv.mv_inl_p((p))
+#define outb_p(x,p)		sh_mv.mv_outb_p((x),(p))
+#define outw_p(x,p)		sh_mv.mv_outw_p((x),(p))
+#define outl_p(x,p)		sh_mv.mv_outl_p((x),(p))
+
+#define insb(p,b,c)		sh_mv.mv_insb((p), (b), (c))
+#define insw(p,b,c)		sh_mv.mv_insw((p), (b), (c))
+#define insl(p,b,c)		sh_mv.mv_insl((p), (b), (c))
+#define outsb(p,b,c)		sh_mv.mv_outsb((p), (b), (c))
+#define outsw(p,b,c)		sh_mv.mv_outsw((p), (b), (c))
+#define outsl(p,b,c)		sh_mv.mv_outsl((p), (b), (c))
+
+#define __raw_writeb(v,a)	(__chk_io_ptr(a), *(volatile u8  __force *)(a) = (v))
+#define __raw_writew(v,a)	(__chk_io_ptr(a), *(volatile u16 __force *)(a) = (v))
+#define __raw_writel(v,a)	(__chk_io_ptr(a), *(volatile u32 __force *)(a) = (v))
+#define __raw_writeq(v,a)	(__chk_io_ptr(a), *(volatile u64 __force *)(a) = (v))
+
+#define __raw_readb(a)		(__chk_io_ptr(a), *(volatile u8  __force *)(a))
+#define __raw_readw(a)		(__chk_io_ptr(a), *(volatile u16 __force *)(a))
+#define __raw_readl(a)		(__chk_io_ptr(a), *(volatile u32 __force *)(a))
+#define __raw_readq(a)		(__chk_io_ptr(a), *(volatile u64 __force *)(a))
+
+#define readb(a)		({ u8  r_ = __raw_readb(a); mb(); r_; })
+#define readw(a)		({ u16 r_ = __raw_readw(a); mb(); r_; })
+#define readl(a)		({ u32 r_ = __raw_readl(a); mb(); r_; })
+#define readq(a)		({ u64 r_ = __raw_readq(a); mb(); r_; })
+
+#define writeb(v,a)		({ __raw_writeb((v),(a)); mb(); })
+#define writew(v,a)		({ __raw_writew((v),(a)); mb(); })
+#define writel(v,a)		({ __raw_writel((v),(a)); mb(); })
+#define writeq(v,a)		({ __raw_writeq((v),(a)); mb(); })
 
-/*
- * Since boards are able to define their own set of I/O routines through
- * their respective machine vector, we always wrap through the mv.
- *
- * Also, in the event that a board hasn't provided its own definition for
- * a given routine, it will be wrapped to generic code at run-time.
- */
-
-#define __inb(p)	sh_mv.mv_inb((p))
-#define __inw(p)	sh_mv.mv_inw((p))
-#define __inl(p)	sh_mv.mv_inl((p))
-#define __outb(x,p)	sh_mv.mv_outb((x),(p))
-#define __outw(x,p)	sh_mv.mv_outw((x),(p))
-#define __outl(x,p)	sh_mv.mv_outl((x),(p))
-
-#define __inb_p(p)	sh_mv.mv_inb_p((p))
-#define __inw_p(p)	sh_mv.mv_inw_p((p))
-#define __inl_p(p)	sh_mv.mv_inl_p((p))
-#define __outb_p(x,p)	sh_mv.mv_outb_p((x),(p))
-#define __outw_p(x,p)	sh_mv.mv_outw_p((x),(p))
-#define __outl_p(x,p)	sh_mv.mv_outl_p((x),(p))
-
-#define __insb(p,b,c)	sh_mv.mv_insb((p), (b), (c))
-#define __insw(p,b,c)	sh_mv.mv_insw((p), (b), (c))
-#define __insl(p,b,c)	sh_mv.mv_insl((p), (b), (c))
-#define __outsb(p,b,c)	sh_mv.mv_outsb((p), (b), (c))
-#define __outsw(p,b,c)	sh_mv.mv_outsw((p), (b), (c))
-#define __outsl(p,b,c)	sh_mv.mv_outsl((p), (b), (c))
-
-#define __readb(a)	sh_mv.mv_readb((a))
-#define __readw(a)	sh_mv.mv_readw((a))
-#define __readl(a)	sh_mv.mv_readl((a))
-#define __writeb(v,a)	sh_mv.mv_writeb((v),(a))
-#define __writew(v,a)	sh_mv.mv_writew((v),(a))
-#define __writel(v,a)	sh_mv.mv_writel((v),(a))
-
-#define inb		__inb
-#define inw		__inw
-#define inl		__inl
-#define outb		__outb
-#define outw		__outw
-#define outl		__outl
-
-#define inb_p		__inb_p
-#define inw_p		__inw_p
-#define inl_p		__inl_p
-#define outb_p		__outb_p
-#define outw_p		__outw_p
-#define outl_p		__outl_p
-
-#define insb		__insb
-#define insw		__insw
-#define insl		__insl
-#define outsb		__outsb
-#define outsw		__outsw
-#define outsl		__outsl
-
-#define __raw_writeb(v,a)	(__chk_io_ptr(a), *(volatile unsigned char __force  *)(a) = (v))
-#define __raw_writew(v,a)	(__chk_io_ptr(a), *(volatile unsigned short __force *)(a) = (v))
-#define __raw_writel(v,a)	(__chk_io_ptr(a), *(volatile unsigned int __force   *)(a) = (v))
-
-#define __raw_readb(a)		(__chk_io_ptr(a), *(volatile unsigned char __force  *)(a))
-#define __raw_readw(a)		(__chk_io_ptr(a), *(volatile unsigned short __force *)(a))
-#define __raw_readl(a)		(__chk_io_ptr(a), *(volatile unsigned int __force   *)(a))
-
-void __raw_writesl(void __iomem *addr, const void *data, int longlen);
-void __raw_readsl(const void __iomem *addr, void *data, int longlen);
+/* SuperH on-chip I/O functions */
+#define ctrl_inb		__raw_readb
+#define ctrl_inw		__raw_readw
+#define ctrl_inl		__raw_readl
+#define ctrl_inq		__raw_readq
 
-/*
- * The platform header files may define some of these macros to use
- * the inlined versions where appropriate.  These macros may also be
- * redefined by userlevel programs.
- */
-#define readb(a)	({ unsigned int r_ = __readb(a); mb(); r_; })
-#define readw(a)	({ unsigned int r_ = __readw(a); mb(); r_; })
-#define readl(a)	({ unsigned int r_ = __readl(a); mb(); r_; })
+#define ctrl_outb		__raw_writeb
+#define ctrl_outw		__raw_writew
+#define ctrl_outl		__raw_writel
+#define ctrl_outq		__raw_writeq
 
-#define writeb(v,a)	({ __writeb((v),(a)); mb(); })
-#define writew(v,a)	({ __writew((v),(a)); mb(); })
-#define writel(v,a)	({ __writel((v),(a)); mb(); })
+static inline void ctrl_delay(void)
+{
+#ifdef P2SEG
+	__raw_readw(P2SEG);
+#endif
+}
 
 #define __BUILD_MEMORY_STRING(bwlq, type)				\
 									\
@@ -151,18 +123,23 @@ static inline void __raw_reads##bwlq(volatile void __iomem *mem,	\
 
 __BUILD_MEMORY_STRING(b, u8)
 __BUILD_MEMORY_STRING(w, u16)
+__BUILD_MEMORY_STRING(q, u64)
+
+void __raw_writesl(void __iomem *addr, const void *data, int longlen);
+void __raw_readsl(const void __iomem *addr, void *data, int longlen);
 
-#define writesb	__raw_writesb
-#define writesw	__raw_writesw
-#define writesl __raw_writesl
+#define writesb			__raw_writesb
+#define writesw			__raw_writesw
+#define writesl			__raw_writesl
 
-#define readsb	__raw_readsb
-#define readsw	__raw_readsw
-#define readsl  __raw_readsl
+#define readsb			__raw_readsb
+#define readsw			__raw_readsw
+#define readsl			__raw_readsl
 
-#define readb_relaxed(a) readb(a)
-#define readw_relaxed(a) readw(a)
-#define readl_relaxed(a) readl(a)
+#define readb_relaxed(a)	readb(a)
+#define readw_relaxed(a)	readw(a)
+#define readl_relaxed(a)	readl(a)
+#define readq_relaxed(a)	readq(a)
 
 /* Simple MMIO */
 #define ioread8(a)		__raw_readb(a)
@@ -185,15 +162,17 @@ __BUILD_MEMORY_STRING(w, u16)
 #define iowrite16_rep(a, s, c)	__raw_writesw((a), (s), (c))
 #define iowrite32_rep(a, s, c)	__raw_writesl((a), (s), (c))
 
-#define mmiowb()	wmb()	/* synco on SH-4A, otherwise a nop */
+/* synco on SH-4A, otherwise a nop */
+#define mmiowb()		wmb()
 
 #define IO_SPACE_LIMIT 0xffffffff
 
 extern unsigned long generic_io_base;
 
 /*
- * This function provides a method for the generic case where a board-specific
- * ioport_map simply needs to return the port + some arbitrary port base.
+ * This function provides a method for the generic case where a
+ * board-specific ioport_map simply needs to return the port + some
+ * arbitrary port base.
  *
  * We use this at board setup time to implicitly set the port base, and
  * as a result, we can use the generic ioport_map.
@@ -206,57 +185,9 @@ static inline void __set_io_port_base(unsigned long pbase)
 #define __ioport_map(p, n) sh_mv.mv_ioport_map((p), (n))
 
 /* We really want to try and get these to memcpy etc */
-extern void memcpy_fromio(void *, volatile void __iomem *, unsigned long);
-extern void memcpy_toio(volatile void __iomem *, const void *, unsigned long);
-extern void memset_io(volatile void __iomem *, int, unsigned long);
-
-/* SuperH on-chip I/O functions */
-static inline unsigned char ctrl_inb(unsigned long addr)
-{
-	return *(volatile unsigned char*)addr;
-}
-
-static inline unsigned short ctrl_inw(unsigned long addr)
-{
-	return *(volatile unsigned short*)addr;
-}
-
-static inline unsigned int ctrl_inl(unsigned long addr)
-{
-	return *(volatile unsigned long*)addr;
-}
-
-static inline unsigned long long ctrl_inq(unsigned long addr)
-{
-	return *(volatile unsigned long long*)addr;
-}
-
-static inline void ctrl_outb(unsigned char b, unsigned long addr)
-{
-	*(volatile unsigned char*)addr = b;
-}
-
-static inline void ctrl_outw(unsigned short b, unsigned long addr)
-{
-	*(volatile unsigned short*)addr = b;
-}
-
-static inline void ctrl_outl(unsigned int b, unsigned long addr)
-{
-        *(volatile unsigned long*)addr = b;
-}
-
-static inline void ctrl_outq(unsigned long long b, unsigned long addr)
-{
-	*(volatile unsigned long long*)addr = b;
-}
-
-static inline void ctrl_delay(void)
-{
-#ifdef P2SEG
-	ctrl_inw(P2SEG);
-#endif
-}
+void memcpy_fromio(void *, const volatile void __iomem *, unsigned long);
+void memcpy_toio(volatile void __iomem *, const void *, unsigned long);
+void memset_io(volatile void __iomem *, int, unsigned long);
 
 /* Quad-word real-mode I/O, don't ask.. */
 unsigned long long peek_real_address_q(unsigned long long addr);
@@ -347,6 +278,10 @@ __ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
 #define iounmap(addr)					\
 	__iounmap((addr))
 
+#define maybebadio(port) \
+	printk(KERN_ERR "bad PC-like io %s:%u for port 0x%lx at 0x%08x\n", \
+	       __func__, __LINE__, (port), (u32)__builtin_return_address(0))
+
 /*
  * Convert a physical pointer to a virtual kernel pointer for /dev/mem
  * access

commit 64c9627c2628bc3bd3291710b8ee6f8335883f8b
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Wed Oct 1 15:12:27 2008 +0900

    sh: Fix up the __raw_read/writeX() definitions.
    
    These were doing largely bogus things and using the wrong typing for
    the address. Bring these in line with the ARM definitions.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index 1857666136f2..d9e794eff830 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -101,44 +101,33 @@
 #define outsw		__outsw
 #define outsl		__outsl
 
-#define __raw_readb(a)		__readb((void __iomem *)(a))
-#define __raw_readw(a)		__readw((void __iomem *)(a))
-#define __raw_readl(a)		__readl((void __iomem *)(a))
-#define __raw_writeb(v, a)	__writeb(v, (void __iomem *)(a))
-#define __raw_writew(v, a)	__writew(v, (void __iomem *)(a))
-#define __raw_writel(v, a)	__writel(v, (void __iomem *)(a))
+#define __raw_writeb(v,a)	(__chk_io_ptr(a), *(volatile unsigned char __force  *)(a) = (v))
+#define __raw_writew(v,a)	(__chk_io_ptr(a), *(volatile unsigned short __force *)(a) = (v))
+#define __raw_writel(v,a)	(__chk_io_ptr(a), *(volatile unsigned int __force   *)(a) = (v))
 
-void __raw_writesl(unsigned long addr, const void *data, int longlen);
-void __raw_readsl(unsigned long addr, void *data, int longlen);
+#define __raw_readb(a)		(__chk_io_ptr(a), *(volatile unsigned char __force  *)(a))
+#define __raw_readw(a)		(__chk_io_ptr(a), *(volatile unsigned short __force *)(a))
+#define __raw_readl(a)		(__chk_io_ptr(a), *(volatile unsigned int __force   *)(a))
+
+void __raw_writesl(void __iomem *addr, const void *data, int longlen);
+void __raw_readsl(const void __iomem *addr, void *data, int longlen);
 
 /*
  * The platform header files may define some of these macros to use
  * the inlined versions where appropriate.  These macros may also be
  * redefined by userlevel programs.
  */
-#ifdef __readb
-# define readb(a)	({ unsigned int r_ = __raw_readb(a); mb(); r_; })
-#endif
-#ifdef __raw_readw
-# define readw(a)	({ unsigned int r_ = __raw_readw(a); mb(); r_; })
-#endif
-#ifdef __raw_readl
-# define readl(a)	({ unsigned int r_ = __raw_readl(a); mb(); r_; })
-#endif
+#define readb(a)	({ unsigned int r_ = __readb(a); mb(); r_; })
+#define readw(a)	({ unsigned int r_ = __readw(a); mb(); r_; })
+#define readl(a)	({ unsigned int r_ = __readl(a); mb(); r_; })
 
-#ifdef __raw_writeb
-# define writeb(v,a)	({ __raw_writeb((v),(a)); mb(); })
-#endif
-#ifdef __raw_writew
-# define writew(v,a)	({ __raw_writew((v),(a)); mb(); })
-#endif
-#ifdef __raw_writel
-# define writel(v,a)	({ __raw_writel((v),(a)); mb(); })
-#endif
+#define writeb(v,a)	({ __writeb((v),(a)); mb(); })
+#define writew(v,a)	({ __writew((v),(a)); mb(); })
+#define writel(v,a)	({ __writel((v),(a)); mb(); })
 
 #define __BUILD_MEMORY_STRING(bwlq, type)				\
 									\
-static inline void writes##bwlq(volatile void __iomem *mem,		\
+static inline void __raw_writes##bwlq(volatile void __iomem *mem,	\
 				const void *addr, unsigned int count)	\
 {									\
 	const volatile type *__addr = addr;				\
@@ -149,8 +138,8 @@ static inline void writes##bwlq(volatile void __iomem *mem,		\
 	}								\
 }									\
 									\
-static inline void reads##bwlq(volatile void __iomem *mem, void *addr,	\
-			       unsigned int count)			\
+static inline void __raw_reads##bwlq(volatile void __iomem *mem,	\
+			       void *addr, unsigned int count)		\
 {									\
 	volatile type *__addr = addr;					\
 									\
@@ -162,7 +151,13 @@ static inline void reads##bwlq(volatile void __iomem *mem, void *addr,	\
 
 __BUILD_MEMORY_STRING(b, u8)
 __BUILD_MEMORY_STRING(w, u16)
+
+#define writesb	__raw_writesb
+#define writesw	__raw_writesw
 #define writesl __raw_writesl
+
+#define readsb	__raw_readsb
+#define readsw	__raw_readsw
 #define readsl  __raw_readsl
 
 #define readb_relaxed(a) readb(a)
@@ -170,25 +165,25 @@ __BUILD_MEMORY_STRING(w, u16)
 #define readl_relaxed(a) readl(a)
 
 /* Simple MMIO */
-#define ioread8(a)		readb(a)
-#define ioread16(a)		readw(a)
+#define ioread8(a)		__raw_readb(a)
+#define ioread16(a)		__raw_readw(a)
 #define ioread16be(a)		be16_to_cpu(__raw_readw((a)))
-#define ioread32(a)		readl(a)
+#define ioread32(a)		__raw_readl(a)
 #define ioread32be(a)		be32_to_cpu(__raw_readl((a)))
 
-#define iowrite8(v,a)		writeb((v),(a))
-#define iowrite16(v,a)		writew((v),(a))
+#define iowrite8(v,a)		__raw_writeb((v),(a))
+#define iowrite16(v,a)		__raw_writew((v),(a))
 #define iowrite16be(v,a)	__raw_writew(cpu_to_be16((v)),(a))
-#define iowrite32(v,a)		writel((v),(a))
+#define iowrite32(v,a)		__raw_writel((v),(a))
 #define iowrite32be(v,a)	__raw_writel(cpu_to_be32((v)),(a))
 
-#define ioread8_rep(a, d, c)	readsb((a), (d), (c))
-#define ioread16_rep(a, d, c)	readsw((a), (d), (c))
-#define ioread32_rep(a, d, c)	readsl((a), (d), (c))
+#define ioread8_rep(a, d, c)	__raw_readsb((a), (d), (c))
+#define ioread16_rep(a, d, c)	__raw_readsw((a), (d), (c))
+#define ioread32_rep(a, d, c)	__raw_readsl((a), (d), (c))
 
-#define iowrite8_rep(a, s, c)	writesb((a), (s), (c))
-#define iowrite16_rep(a, s, c)	writesw((a), (s), (c))
-#define iowrite32_rep(a, s, c)	writesl((a), (s), (c))
+#define iowrite8_rep(a, s, c)	__raw_writesb((a), (s), (c))
+#define iowrite16_rep(a, s, c)	__raw_writesw((a), (s), (c))
+#define iowrite32_rep(a, s, c)	__raw_writesl((a), (s), (c))
 
 #define mmiowb()	wmb()	/* synco on SH-4A, otherwise a nop */
 

commit cb700aa4f13d38726defab3060d3ebeaf67dc189
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Fri Sep 12 20:41:05 2008 +0900

    sh: ioremap_prot support.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index e49cfee95fb2..1857666136f2 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -347,6 +347,8 @@ __ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
 	__ioremap_mode((offset), (size), _PAGE_CACHABLE)
 #define p3_ioremap(offset, size, flags)			\
 	__ioremap((offset), (size), (flags))
+#define ioremap_prot(offset, size, flags)		\
+	__ioremap_mode((offset), (size), (flags))
 #define iounmap(addr)					\
 	__iounmap((addr))
 

commit fa43972fab24a3c050e880a7831f9378c6cebc0b
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Thu Sep 4 18:53:58 2008 +0900

    sh: fixup many sparse errors.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
index a4fbf0c84fb1..e49cfee95fb2 100644
--- a/arch/sh/include/asm/io.h
+++ b/arch/sh/include/asm/io.h
@@ -194,6 +194,8 @@ __BUILD_MEMORY_STRING(w, u16)
 
 #define IO_SPACE_LIMIT 0xffffffff
 
+extern unsigned long generic_io_base;
+
 /*
  * This function provides a method for the generic case where a board-specific
  * ioport_map simply needs to return the port + some arbitrary port base.
@@ -203,8 +205,6 @@ __BUILD_MEMORY_STRING(w, u16)
  */
 static inline void __set_io_port_base(unsigned long pbase)
 {
-	extern unsigned long generic_io_base;
-
 	generic_io_base = pbase;
 }
 

commit f15cbe6f1a4b4d9df59142fc8e4abb973302cf44
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Jul 29 08:09:44 2008 +0900

    sh: migrate to arch/sh/include/
    
    This follows the sparc changes a439fe51a1f8eb087c22dd24d69cebae4a3addac.
    
    Most of the moving about was done with Sam's directions at:
    
    http://marc.info/?l=linux-sh&m=121724823706062&w=2
    
    with subsequent hacking and fixups entirely my fault.
    
    Signed-off-by: Sam Ravnborg <sam@ravnborg.org>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/asm/io.h b/arch/sh/include/asm/io.h
new file mode 100644
index 000000000000..a4fbf0c84fb1
--- /dev/null
+++ b/arch/sh/include/asm/io.h
@@ -0,0 +1,366 @@
+#ifndef __ASM_SH_IO_H
+#define __ASM_SH_IO_H
+
+/*
+ * Convention:
+ *    read{b,w,l}/write{b,w,l} are for PCI,
+ *    while in{b,w,l}/out{b,w,l} are for ISA
+ * These may (will) be platform specific function.
+ * In addition we have 'pausing' versions: in{b,w,l}_p/out{b,w,l}_p
+ * and 'string' versions: ins{b,w,l}/outs{b,w,l}
+ * For read{b,w,l} and write{b,w,l} there are also __raw versions, which
+ * do not have a memory barrier after them.
+ *
+ * In addition, we have
+ *   ctrl_in{b,w,l}/ctrl_out{b,w,l} for SuperH specific I/O.
+ *   which are processor specific.
+ */
+
+/*
+ * We follow the Alpha convention here:
+ *  __inb expands to an inline function call (which calls via the mv)
+ *  _inb  is a real function call (note ___raw fns are _ version of __raw)
+ *  inb   by default expands to _inb, but the machine specific code may
+ *        define it to __inb if it chooses.
+ */
+#include <asm/cache.h>
+#include <asm/system.h>
+#include <asm/addrspace.h>
+#include <asm/machvec.h>
+#include <asm/pgtable.h>
+#include <asm-generic/iomap.h>
+
+#ifdef __KERNEL__
+
+/*
+ * Depending on which platform we are running on, we need different
+ * I/O functions.
+ */
+#define __IO_PREFIX	generic
+#include <asm/io_generic.h>
+#include <asm/io_trapped.h>
+
+#define maybebadio(port) \
+  printk(KERN_ERR "bad PC-like io %s:%u for port 0x%lx at 0x%08x\n", \
+	 __FUNCTION__, __LINE__, (port), (u32)__builtin_return_address(0))
+
+/*
+ * Since boards are able to define their own set of I/O routines through
+ * their respective machine vector, we always wrap through the mv.
+ *
+ * Also, in the event that a board hasn't provided its own definition for
+ * a given routine, it will be wrapped to generic code at run-time.
+ */
+
+#define __inb(p)	sh_mv.mv_inb((p))
+#define __inw(p)	sh_mv.mv_inw((p))
+#define __inl(p)	sh_mv.mv_inl((p))
+#define __outb(x,p)	sh_mv.mv_outb((x),(p))
+#define __outw(x,p)	sh_mv.mv_outw((x),(p))
+#define __outl(x,p)	sh_mv.mv_outl((x),(p))
+
+#define __inb_p(p)	sh_mv.mv_inb_p((p))
+#define __inw_p(p)	sh_mv.mv_inw_p((p))
+#define __inl_p(p)	sh_mv.mv_inl_p((p))
+#define __outb_p(x,p)	sh_mv.mv_outb_p((x),(p))
+#define __outw_p(x,p)	sh_mv.mv_outw_p((x),(p))
+#define __outl_p(x,p)	sh_mv.mv_outl_p((x),(p))
+
+#define __insb(p,b,c)	sh_mv.mv_insb((p), (b), (c))
+#define __insw(p,b,c)	sh_mv.mv_insw((p), (b), (c))
+#define __insl(p,b,c)	sh_mv.mv_insl((p), (b), (c))
+#define __outsb(p,b,c)	sh_mv.mv_outsb((p), (b), (c))
+#define __outsw(p,b,c)	sh_mv.mv_outsw((p), (b), (c))
+#define __outsl(p,b,c)	sh_mv.mv_outsl((p), (b), (c))
+
+#define __readb(a)	sh_mv.mv_readb((a))
+#define __readw(a)	sh_mv.mv_readw((a))
+#define __readl(a)	sh_mv.mv_readl((a))
+#define __writeb(v,a)	sh_mv.mv_writeb((v),(a))
+#define __writew(v,a)	sh_mv.mv_writew((v),(a))
+#define __writel(v,a)	sh_mv.mv_writel((v),(a))
+
+#define inb		__inb
+#define inw		__inw
+#define inl		__inl
+#define outb		__outb
+#define outw		__outw
+#define outl		__outl
+
+#define inb_p		__inb_p
+#define inw_p		__inw_p
+#define inl_p		__inl_p
+#define outb_p		__outb_p
+#define outw_p		__outw_p
+#define outl_p		__outl_p
+
+#define insb		__insb
+#define insw		__insw
+#define insl		__insl
+#define outsb		__outsb
+#define outsw		__outsw
+#define outsl		__outsl
+
+#define __raw_readb(a)		__readb((void __iomem *)(a))
+#define __raw_readw(a)		__readw((void __iomem *)(a))
+#define __raw_readl(a)		__readl((void __iomem *)(a))
+#define __raw_writeb(v, a)	__writeb(v, (void __iomem *)(a))
+#define __raw_writew(v, a)	__writew(v, (void __iomem *)(a))
+#define __raw_writel(v, a)	__writel(v, (void __iomem *)(a))
+
+void __raw_writesl(unsigned long addr, const void *data, int longlen);
+void __raw_readsl(unsigned long addr, void *data, int longlen);
+
+/*
+ * The platform header files may define some of these macros to use
+ * the inlined versions where appropriate.  These macros may also be
+ * redefined by userlevel programs.
+ */
+#ifdef __readb
+# define readb(a)	({ unsigned int r_ = __raw_readb(a); mb(); r_; })
+#endif
+#ifdef __raw_readw
+# define readw(a)	({ unsigned int r_ = __raw_readw(a); mb(); r_; })
+#endif
+#ifdef __raw_readl
+# define readl(a)	({ unsigned int r_ = __raw_readl(a); mb(); r_; })
+#endif
+
+#ifdef __raw_writeb
+# define writeb(v,a)	({ __raw_writeb((v),(a)); mb(); })
+#endif
+#ifdef __raw_writew
+# define writew(v,a)	({ __raw_writew((v),(a)); mb(); })
+#endif
+#ifdef __raw_writel
+# define writel(v,a)	({ __raw_writel((v),(a)); mb(); })
+#endif
+
+#define __BUILD_MEMORY_STRING(bwlq, type)				\
+									\
+static inline void writes##bwlq(volatile void __iomem *mem,		\
+				const void *addr, unsigned int count)	\
+{									\
+	const volatile type *__addr = addr;				\
+									\
+	while (count--) {						\
+		__raw_write##bwlq(*__addr, mem);			\
+		__addr++;						\
+	}								\
+}									\
+									\
+static inline void reads##bwlq(volatile void __iomem *mem, void *addr,	\
+			       unsigned int count)			\
+{									\
+	volatile type *__addr = addr;					\
+									\
+	while (count--) {						\
+		*__addr = __raw_read##bwlq(mem);			\
+		__addr++;						\
+	}								\
+}
+
+__BUILD_MEMORY_STRING(b, u8)
+__BUILD_MEMORY_STRING(w, u16)
+#define writesl __raw_writesl
+#define readsl  __raw_readsl
+
+#define readb_relaxed(a) readb(a)
+#define readw_relaxed(a) readw(a)
+#define readl_relaxed(a) readl(a)
+
+/* Simple MMIO */
+#define ioread8(a)		readb(a)
+#define ioread16(a)		readw(a)
+#define ioread16be(a)		be16_to_cpu(__raw_readw((a)))
+#define ioread32(a)		readl(a)
+#define ioread32be(a)		be32_to_cpu(__raw_readl((a)))
+
+#define iowrite8(v,a)		writeb((v),(a))
+#define iowrite16(v,a)		writew((v),(a))
+#define iowrite16be(v,a)	__raw_writew(cpu_to_be16((v)),(a))
+#define iowrite32(v,a)		writel((v),(a))
+#define iowrite32be(v,a)	__raw_writel(cpu_to_be32((v)),(a))
+
+#define ioread8_rep(a, d, c)	readsb((a), (d), (c))
+#define ioread16_rep(a, d, c)	readsw((a), (d), (c))
+#define ioread32_rep(a, d, c)	readsl((a), (d), (c))
+
+#define iowrite8_rep(a, s, c)	writesb((a), (s), (c))
+#define iowrite16_rep(a, s, c)	writesw((a), (s), (c))
+#define iowrite32_rep(a, s, c)	writesl((a), (s), (c))
+
+#define mmiowb()	wmb()	/* synco on SH-4A, otherwise a nop */
+
+#define IO_SPACE_LIMIT 0xffffffff
+
+/*
+ * This function provides a method for the generic case where a board-specific
+ * ioport_map simply needs to return the port + some arbitrary port base.
+ *
+ * We use this at board setup time to implicitly set the port base, and
+ * as a result, we can use the generic ioport_map.
+ */
+static inline void __set_io_port_base(unsigned long pbase)
+{
+	extern unsigned long generic_io_base;
+
+	generic_io_base = pbase;
+}
+
+#define __ioport_map(p, n) sh_mv.mv_ioport_map((p), (n))
+
+/* We really want to try and get these to memcpy etc */
+extern void memcpy_fromio(void *, volatile void __iomem *, unsigned long);
+extern void memcpy_toio(volatile void __iomem *, const void *, unsigned long);
+extern void memset_io(volatile void __iomem *, int, unsigned long);
+
+/* SuperH on-chip I/O functions */
+static inline unsigned char ctrl_inb(unsigned long addr)
+{
+	return *(volatile unsigned char*)addr;
+}
+
+static inline unsigned short ctrl_inw(unsigned long addr)
+{
+	return *(volatile unsigned short*)addr;
+}
+
+static inline unsigned int ctrl_inl(unsigned long addr)
+{
+	return *(volatile unsigned long*)addr;
+}
+
+static inline unsigned long long ctrl_inq(unsigned long addr)
+{
+	return *(volatile unsigned long long*)addr;
+}
+
+static inline void ctrl_outb(unsigned char b, unsigned long addr)
+{
+	*(volatile unsigned char*)addr = b;
+}
+
+static inline void ctrl_outw(unsigned short b, unsigned long addr)
+{
+	*(volatile unsigned short*)addr = b;
+}
+
+static inline void ctrl_outl(unsigned int b, unsigned long addr)
+{
+        *(volatile unsigned long*)addr = b;
+}
+
+static inline void ctrl_outq(unsigned long long b, unsigned long addr)
+{
+	*(volatile unsigned long long*)addr = b;
+}
+
+static inline void ctrl_delay(void)
+{
+#ifdef P2SEG
+	ctrl_inw(P2SEG);
+#endif
+}
+
+/* Quad-word real-mode I/O, don't ask.. */
+unsigned long long peek_real_address_q(unsigned long long addr);
+unsigned long long poke_real_address_q(unsigned long long addr,
+				       unsigned long long val);
+
+#if !defined(CONFIG_MMU)
+#define virt_to_phys(address)	((unsigned long)(address))
+#define phys_to_virt(address)	((void *)(address))
+#else
+#define virt_to_phys(address)	(__pa(address))
+#define phys_to_virt(address)	(__va(address))
+#endif
+
+/*
+ * On 32-bit SH, we traditionally have the whole physical address space
+ * mapped at all times (as MIPS does), so "ioremap()" and "iounmap()" do
+ * not need to do anything but place the address in the proper segment.
+ * This is true for P1 and P2 addresses, as well as some P3 ones.
+ * However, most of the P3 addresses and newer cores using extended
+ * addressing need to map through page tables, so the ioremap()
+ * implementation becomes a bit more complicated.
+ *
+ * See arch/sh/mm/ioremap.c for additional notes on this.
+ *
+ * We cheat a bit and always return uncachable areas until we've fixed
+ * the drivers to handle caching properly.
+ *
+ * On the SH-5 the concept of segmentation in the 1:1 PXSEG sense simply
+ * doesn't exist, so everything must go through page tables.
+ */
+#ifdef CONFIG_MMU
+void __iomem *__ioremap(unsigned long offset, unsigned long size,
+			unsigned long flags);
+void __iounmap(void __iomem *addr);
+
+/* arch/sh/mm/ioremap_64.c */
+unsigned long onchip_remap(unsigned long addr, unsigned long size,
+			   const char *name);
+extern void onchip_unmap(unsigned long vaddr);
+#else
+#define __ioremap(offset, size, flags)	((void __iomem *)(offset))
+#define __iounmap(addr)			do { } while (0)
+#define onchip_remap(addr, size, name)	(addr)
+#define onchip_unmap(addr)		do { } while (0)
+#endif /* CONFIG_MMU */
+
+static inline void __iomem *
+__ioremap_mode(unsigned long offset, unsigned long size, unsigned long flags)
+{
+#ifdef CONFIG_SUPERH32
+	unsigned long last_addr = offset + size - 1;
+#endif
+	void __iomem *ret;
+
+	ret = __ioremap_trapped(offset, size);
+	if (ret)
+		return ret;
+
+#ifdef CONFIG_SUPERH32
+	/*
+	 * For P1 and P2 space this is trivial, as everything is already
+	 * mapped. Uncached access for P1 addresses are done through P2.
+	 * In the P3 case or for addresses outside of the 29-bit space,
+	 * mapping must be done by the PMB or by using page tables.
+	 */
+	if (likely(PXSEG(offset) < P3SEG && PXSEG(last_addr) < P3SEG)) {
+		if (unlikely(flags & _PAGE_CACHABLE))
+			return (void __iomem *)P1SEGADDR(offset);
+
+		return (void __iomem *)P2SEGADDR(offset);
+	}
+#endif
+
+	return __ioremap(offset, size, flags);
+}
+
+#define ioremap(offset, size)				\
+	__ioremap_mode((offset), (size), 0)
+#define ioremap_nocache(offset, size)			\
+	__ioremap_mode((offset), (size), 0)
+#define ioremap_cache(offset, size)			\
+	__ioremap_mode((offset), (size), _PAGE_CACHABLE)
+#define p3_ioremap(offset, size, flags)			\
+	__ioremap((offset), (size), (flags))
+#define iounmap(addr)					\
+	__iounmap((addr))
+
+/*
+ * Convert a physical pointer to a virtual kernel pointer for /dev/mem
+ * access
+ */
+#define xlate_dev_mem_ptr(p)	__va(p)
+
+/*
+ * Convert a virtual cached pointer to an uncached pointer
+ */
+#define xlate_dev_kmem_ptr(p)	p
+
+#endif /* __KERNEL__ */
+
+#endif /* __ASM_SH_IO_H */
