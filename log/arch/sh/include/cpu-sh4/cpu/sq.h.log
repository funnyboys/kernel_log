commit 6a0abce4c4cce0890e2c930b960b9a05c8c6e5da
Author: Kuninori Morimoto <kuninori.morimoto.gx@renesas.com>
Date:   Fri Dec 28 00:31:53 2018 -0800

    sh: include: convert to SPDX identifiers
    
    Update license to use SPDX-License-Identifier instead of verbose license
    text.
    
    Link: http://lkml.kernel.org/r/87ftvccszx.wl-kuninori.morimoto.gx@renesas.com
    Signed-off-by: Kuninori Morimoto <kuninori.morimoto.gx@renesas.com>
    Reviewed-by: Simon Horman <horms+renesas@verge.net.au>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/sh/include/cpu-sh4/cpu/sq.h b/arch/sh/include/cpu-sh4/cpu/sq.h
index 74716ba2dc3c..81966e41fc21 100644
--- a/arch/sh/include/cpu-sh4/cpu/sq.h
+++ b/arch/sh/include/cpu-sh4/cpu/sq.h
@@ -1,12 +1,9 @@
-/*
+/* SPDX-License-Identifier: GPL-2.0
+ *
  * include/asm-sh/cpu-sh4/sq.h
  *
  * Copyright (C) 2001, 2002, 2003  Paul Mundt
  * Copyright (C) 2001, 2002  M. R. Brown
- *
- * This file is subject to the terms and conditions of the GNU General Public
- * License.  See the file "COPYING" in the main directory of this archive
- * for more details.
  */
 #ifndef __ASM_CPU_SH4_SQ_H
 #define __ASM_CPU_SH4_SQ_H

commit 7bdda6209f224aa784a036df54b22cb338d2e859
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Wed Feb 17 13:23:00 2010 +0900

    sh: Fix up more 64-bit pgprot truncation on SH-X2 TLB.
    
    Both the store queue API and the PMB remapping take unsigned long for
    their pgprot flags, which cuts off the extended protection bits. In the
    case of the PMB this isn't really a problem since the cache attribute
    bits that we care about are all in the lower 32-bits, but we do it just
    to be safe. The store queue remapping on the other hand depends on the
    extended prot bits for enabling userspace access to the mappings.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/cpu-sh4/cpu/sq.h b/arch/sh/include/cpu-sh4/cpu/sq.h
index 586d6491816a..74716ba2dc3c 100644
--- a/arch/sh/include/cpu-sh4/cpu/sq.h
+++ b/arch/sh/include/cpu-sh4/cpu/sq.h
@@ -12,6 +12,7 @@
 #define __ASM_CPU_SH4_SQ_H
 
 #include <asm/addrspace.h>
+#include <asm/page.h>
 
 /*
  * Store queues range from e0000000-e3fffffc, allowing approx. 64MB to be
@@ -28,7 +29,7 @@
 
 /* arch/sh/kernel/cpu/sh4/sq.c */
 unsigned long sq_remap(unsigned long phys, unsigned int size,
-		       const char *name, unsigned long flags);
+		       const char *name, pgprot_t prot);
 void sq_unmap(unsigned long vaddr);
 void sq_flush_range(unsigned long start, unsigned int len);
 

commit f15cbe6f1a4b4d9df59142fc8e4abb973302cf44
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Jul 29 08:09:44 2008 +0900

    sh: migrate to arch/sh/include/
    
    This follows the sparc changes a439fe51a1f8eb087c22dd24d69cebae4a3addac.
    
    Most of the moving about was done with Sam's directions at:
    
    http://marc.info/?l=linux-sh&m=121724823706062&w=2
    
    with subsequent hacking and fixups entirely my fault.
    
    Signed-off-by: Sam Ravnborg <sam@ravnborg.org>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

diff --git a/arch/sh/include/cpu-sh4/cpu/sq.h b/arch/sh/include/cpu-sh4/cpu/sq.h
new file mode 100644
index 000000000000..586d6491816a
--- /dev/null
+++ b/arch/sh/include/cpu-sh4/cpu/sq.h
@@ -0,0 +1,35 @@
+/*
+ * include/asm-sh/cpu-sh4/sq.h
+ *
+ * Copyright (C) 2001, 2002, 2003  Paul Mundt
+ * Copyright (C) 2001, 2002  M. R. Brown
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ */
+#ifndef __ASM_CPU_SH4_SQ_H
+#define __ASM_CPU_SH4_SQ_H
+
+#include <asm/addrspace.h>
+
+/*
+ * Store queues range from e0000000-e3fffffc, allowing approx. 64MB to be
+ * mapped to any physical address space. Since data is written (and aligned)
+ * to 32-byte boundaries, we need to be sure that all allocations are aligned.
+ */
+#define SQ_SIZE                 32
+#define SQ_ALIGN_MASK           (~(SQ_SIZE - 1))
+#define SQ_ALIGN(addr)          (((addr)+SQ_SIZE-1) & SQ_ALIGN_MASK)
+
+#define SQ_QACR0		(P4SEG_REG_BASE  + 0x38)
+#define SQ_QACR1		(P4SEG_REG_BASE  + 0x3c)
+#define SQ_ADDRMAX              (P4SEG_STORE_QUE + 0x04000000)
+
+/* arch/sh/kernel/cpu/sh4/sq.c */
+unsigned long sq_remap(unsigned long phys, unsigned int size,
+		       const char *name, unsigned long flags);
+void sq_unmap(unsigned long vaddr);
+void sq_flush_range(unsigned long start, unsigned int len);
+
+#endif /* __ASM_CPU_SH4_SQ_H */
