commit e05c7b1f2bc4b7b28199b9a7572f73436d97317e
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Jun 8 21:33:05 2020 -0700

    mm: pgtable: add shortcuts for accessing kernel PMD and PTE
    
    The powerpc 32-bit implementation of pgtable has nice shortcuts for
    accessing kernel PMD and PTE for a given virtual address.  Make these
    helpers available for all architectures.
    
    [rppt@linux.ibm.com: microblaze: fix page table traversal in setup_rt_frame()]
      Link: http://lkml.kernel.org/r/20200518191511.GD1118872@kernel.org
    [akpm@linux-foundation.org: s/pmd_ptr_k/pmd_off_k/ in various powerpc places]
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200514170327.31389-9-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index d943f69784b1..521b59ba716c 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -50,15 +50,6 @@ unsigned long lowmem_size;
 pte_t *kmap_pte;
 EXPORT_SYMBOL(kmap_pte);
 
-static inline pte_t *virt_to_kpte(unsigned long vaddr)
-{
-	pgd_t *pgd = pgd_offset_k(vaddr);
-	p4d_t *p4d = p4d_offset(pgd, vaddr);
-	pud_t *pud = pud_offset(p4d, vaddr);
-
-	return pte_offset_kernel(pmd_offset(pud, vaddr), vaddr);
-}
-
 static void __init highmem_init(void)
 {
 	pr_debug("%x\n", (u32)PKMAP_BASE);

commit db458d73fa35e256bba90b59a6776810800c8bb6
Author: Ira Weiny <ira.weiny@intel.com>
Date:   Thu Jun 4 16:47:50 2020 -0700

    arch/kmap: ensure kmap_prot visibility
    
    We want to support kmap_atomic_prot() on all architectures and it makes
    sense to define kmap_atomic() to use the default kmap_prot.
    
    So we ensure all arch's have a globally available kmap_prot either as a
    define or exported symbol.
    
    Signed-off-by: Ira Weiny <ira.weiny@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Christian KÃ¶nig <christian.koenig@amd.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Helge Deller <deller@gmx.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <James.Bottomley@HansenPartnership.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20200507150004.1423069-9-ira.weiny@intel.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index dcaa53d11339..d943f69784b1 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -49,8 +49,6 @@ unsigned long lowmem_size;
 #ifdef CONFIG_HIGHMEM
 pte_t *kmap_pte;
 EXPORT_SYMBOL(kmap_pte);
-pgprot_t kmap_prot;
-EXPORT_SYMBOL(kmap_prot);
 
 static inline pte_t *virt_to_kpte(unsigned long vaddr)
 {
@@ -68,7 +66,6 @@ static void __init highmem_init(void)
 	pkmap_page_table = virt_to_kpte(PKMAP_BASE);
 
 	kmap_pte = virt_to_kpte(__fix_to_virt(FIX_KMAP_BEGIN));
-	kmap_prot = PAGE_KERNEL;
 }
 
 static void highmem_setup(void)

commit 9691a071aa26a21fc8dac804a2b98d3c24f76f9a
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Wed Jun 3 15:57:10 2020 -0700

    mm: use free_area_init() instead of free_area_init_nodes()
    
    free_area_init() has effectively became a wrapper for
    free_area_init_nodes() and there is no point of keeping it.  Still
    free_area_init() name is shorter and more general as it does not imply
    necessity to initialize multiple nodes.
    
    Rename free_area_init_nodes() to free_area_init(), update the callers and
    drop old version of free_area_init().
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Tested-by: Hoan Tran <hoan@os.amperecomputing.com>      [arm64]
    Reviewed-by: Baoquan He <bhe@redhat.com>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: "James E.J. Bottomley" <James.Bottomley@HansenPartnership.com>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200412194859.12663-6-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 1ffbfa96b9b8..dcaa53d11339 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -112,7 +112,7 @@ static void __init paging_init(void)
 #endif
 
 	/* We don't have holes in memory map */
-	free_area_init_nodes(zones_size);
+	free_area_init(zones_size);
 }
 
 void __init setup_memory(void)

commit 1babf557bf6e6ab92d5ebea642b9f636c77a4912
Author: Arvind Sankar <nivedita@alum.mit.edu>
Date:   Thu Mar 5 10:05:03 2020 -0500

    microblaze: Stop printing the virtual memory layout
    
    For security, don't display the kernel's virtual memory layout.
    
    Kees Cook points out:
    "These have been entirely removed on other architectures, so let's
    just do the same for ia32 and remove it unconditionally."
    
    071929dbdd86 ("arm64: Stop printing the virtual memory layout")
    1c31d4e96b8c ("ARM: 8820/1: mm: Stop printing the virtual memory layout")
    31833332f798 ("m68k/mm: Stop printing the virtual memory layout")
    fd8d0ca25631 ("parisc: Hide virtual kernel memory layout")
    adb1fe9ae2ee ("mm/page_alloc: Remove kernel address exposure in free_reserved_area()")
    
    Signed-off-by: Arvind Sankar <nivedita@alum.mit.edu>
    Acked-by: Tycho Andersen <tycho@tycho.ws>
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 9899ff2ef9b6..1ffbfa96b9b8 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -201,18 +201,6 @@ void __init mem_init(void)
 #endif
 
 	mem_init_print_info(NULL);
-#ifdef CONFIG_MMU
-	pr_info("Kernel virtual memory layout:\n");
-	pr_info("  * 0x%08lx..0x%08lx  : fixmap\n", FIXADDR_START, FIXADDR_TOP);
-#ifdef CONFIG_HIGHMEM
-	pr_info("  * 0x%08lx..0x%08lx  : highmem PTEs\n",
-		PKMAP_BASE, PKMAP_ADDR(LAST_PKMAP));
-#endif /* CONFIG_HIGHMEM */
-	pr_info("  * 0x%08lx..0x%08lx  : early ioremap\n",
-		ioremap_bot, ioremap_base);
-	pr_info("  * 0x%08lx..0x%08lx  : vmalloc & ioremap\n",
-		(unsigned long)VMALLOC_START, VMALLOC_END);
-#endif
 	mem_init_done = 1;
 }
 

commit dcf639fe6f801f6418357ec20376b2218f666f44
Author: Michal Simek <michal.simek@xilinx.com>
Date:   Tue Jan 14 11:00:41 2020 +0100

    microblaze: Kernel parameters should be parsed earlier
    
    Kernel command line should be parsed before cma initialization to be able
    to get cma sizes from command line. That's why call parse_early_param()
    before dma_continugous_reserve().
    
    Unfortunately it can't be called earlier in machine_early_init() because
    if earlycon is passed in the command line the parse_early_param() attempts
    an ioremap which fails as the memory params are not set yet.
    
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>
    Signed-off-by: Shubhrajyoti Datta <shubhrajyoti.datta@xilinx.com>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 1056f1674065..9899ff2ef9b6 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -347,6 +347,8 @@ asmlinkage void __init mmu_init(void)
 	 * inside 768MB limit */
 	memblock_set_current_limit(memory_start + lowmem_size - 1);
 
+	parse_early_param();
+
 	/* CMA initialization */
 	dma_contiguous_reserve(memory_start + lowmem_size - 1);
 }

commit 2602276d3d3811b1a48c48113042cd75fcbfc27d
Author: Michal Simek <michal.simek@xilinx.com>
Date:   Tue Jan 14 10:05:24 2020 +0100

    microblaze: Wire CMA allocator
    
    Based on commit 04e3543e228f ("microblaze: use the generic dma coherent
    remap allocator")
    CMA can be easily enabled by calling dma_contiguous_reserve() at the end of
    mmu_init(). High limit is end of lowmem space which is completely unused at
    this point of time.
    
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 050fc621c920..1056f1674065 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -7,6 +7,7 @@
  * for more details.
  */
 
+#include <linux/dma-contiguous.h>
 #include <linux/memblock.h>
 #include <linux/init.h>
 #include <linux/kernel.h>
@@ -345,6 +346,9 @@ asmlinkage void __init mmu_init(void)
 	/* This will also cause that unflatten device tree will be allocated
 	 * inside 768MB limit */
 	memblock_set_current_limit(memory_start + lowmem_size - 1);
+
+	/* CMA initialization */
+	dma_contiguous_reserve(memory_start + lowmem_size - 1);
 }
 
 /* This is only called until mem_init is done. */

commit ed48e1f812b585e2af5dee6e08712c64d75978e2
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Wed Dec 4 16:54:03 2019 -0800

    microblaze: use pgtable-nopmd instead of 4level-fixup
    
    microblaze has only two-level page tables and can use pgtable-nopmd and
    folding of the upper layers.
    
    Replace usage of include/asm-generic/4level-fixup.h and explicit
    definition of __PAGETABLE_PMD_FOLDED in microblaze with
    include/asm-generic/pgtable-nopmd.h and adjust page table manipulation
    macros and functions accordingly.
    
    Link: http://lkml.kernel.org/r/1572938135-31886-7-git-send-email-rppt@kernel.org
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Cc: Anatoly Pugachev <matorola@gmail.com>
    Cc: Anton Ivanov <anton.ivanov@cambridgegreys.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: Helge Deller <deller@gmx.de>
    Cc: "James E.J. Bottomley" <James.Bottomley@HansenPartnership.com>
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: "Kirill A. Shutemov" <kirill@shutemov.name>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Peter Rosin <peda@axentia.se>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rolf Eike Beer <eike-kernel@sf-tec.de>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Russell King <rmk+kernel@armlinux.org.uk>
    Cc: Sam Creasey <sammy@sammy.net>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Vineet Gupta <Vineet.Gupta1@synopsys.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index a015a951c8b7..050fc621c920 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -53,8 +53,11 @@ EXPORT_SYMBOL(kmap_prot);
 
 static inline pte_t *virt_to_kpte(unsigned long vaddr)
 {
-	return pte_offset_kernel(pmd_offset(pgd_offset_k(vaddr),
-			vaddr), vaddr);
+	pgd_t *pgd = pgd_offset_k(vaddr);
+	p4d_t *p4d = p4d_offset(pgd, vaddr);
+	pud_t *pud = pud_offset(p4d, vaddr);
+
+	return pte_offset_kernel(pmd_offset(pud, vaddr), vaddr);
 }
 
 static void __init highmem_init(void)

commit 997aef68af3ef1f2cb97da1c0b41a5afa87f63e2
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon May 13 17:18:40 2019 -0700

    init: provide a generic free_initmem implementation
    
    Patch series "provide a generic free_initmem implementation", v2.
    
    Many architectures implement free_initmem() in exactly the same or very
    similar way: they wrap the call to free_initmem_default() with sometimes
    different 'poison' parameter.
    
    These patches switch those architectures to use a generic implementation
    that does free_initmem_default(POISON_FREE_INITMEM).
    
    This was inspired by Christoph's patches for free_initrd_mem [1] and I
    shamelessly copied changelog entries from his patches :)
    
    [1] https://lore.kernel.org/lkml/20190213174621.29297-1-hch@lst.de/
    
    This patch (of 2):
    
    For most architectures free_initmem just a wrapper for the same
    free_initmem_default(-1) call.  Provide that as a generic implementation
    marked __weak.
    
    Link: http://lkml.kernel.org/r/1550515285-17446-2-git-send-email-rppt@linux.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Palmer Dabbelt <palmer@sifive.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index b675bc666e68..a015a951c8b7 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -186,11 +186,6 @@ void __init setup_memory(void)
 	paging_init();
 }
 
-void free_initmem(void)
-{
-	free_initmem_default(-1);
-}
-
 void __init mem_init(void)
 {
 	high_memory = (void *)__va(memory_start + lowmem_size - 1);

commit 4afd58e14dd415e456fd236755373f52e6055ec7
Author: Christoph Hellwig <hch@lst.de>
Date:   Mon May 13 17:18:34 2019 -0700

    initramfs: provide a generic free_initrd_mem implementation
    
    For most architectures free_initrd_mem just expands to the same
    free_reserved_area call.  Provide that as a generic implementation marked
    __weak.
    
    Link: http://lkml.kernel.org/r/20190213174621.29297-8-hch@lst.de
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org>     [m68k]
    Acked-by: Mike Rapoport <rppt@linux.ibm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>   [arm64]
    Cc: Steven Price <steven.price@arm.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 7e97d44f6538..b675bc666e68 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -186,13 +186,6 @@ void __init setup_memory(void)
 	paging_init();
 }
 
-#ifdef CONFIG_BLK_DEV_INITRD
-void free_initrd_mem(unsigned long start, unsigned long end)
-{
-	free_reserved_area((void *)start, (void *)end, -1, "initrd");
-}
-#endif
-
 void free_initmem(void)
 {
 	free_initmem_default(-1);

commit 8a7f97b902f4fb0d94b355b6b3f1fbd7154cafb9
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Mar 11 23:30:31 2019 -0700

    treewide: add checks for the return value of memblock_alloc*()
    
    Add check for the return value of memblock_alloc*() functions and call
    panic() in case of error.  The panic message repeats the one used by
    panicing memblock allocators with adjustment of parameters to include
    only relevant ones.
    
    The replacement was mostly automated with semantic patches like the one
    below with manual massaging of format strings.
    
      @@
      expression ptr, size, align;
      @@
      ptr = memblock_alloc(size, align);
      + if (!ptr)
      +     panic("%s: Failed to allocate %lu bytes align=0x%lx\n", __func__, size, align);
    
    [anders.roxell@linaro.org: use '%pa' with 'phys_addr_t' type]
      Link: http://lkml.kernel.org/r/20190131161046.21886-1-anders.roxell@linaro.org
    [rppt@linux.ibm.com: fix format strings for panics after memblock_alloc]
      Link: http://lkml.kernel.org/r/1548950940-15145-1-git-send-email-rppt@linux.ibm.com
    [rppt@linux.ibm.com: don't panic if the allocation in sparse_buffer_init fails]
      Link: http://lkml.kernel.org/r/20190131074018.GD28876@rapoport-lnx
    [akpm@linux-foundation.org: fix xtensa printk warning]
    Link: http://lkml.kernel.org/r/1548057848-15136-20-git-send-email-rppt@linux.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Anders Roxell <anders.roxell@linaro.org>
    Reviewed-by: Guo Ren <ren_guo@c-sky.com>                [c-sky]
    Acked-by: Paul Burton <paul.burton@mips.com>            [MIPS]
    Acked-by: Heiko Carstens <heiko.carstens@de.ibm.com>    [s390]
    Reviewed-by: Juergen Gross <jgross@suse.com>            [Xen]
    Reviewed-by: Geert Uytterhoeven <geert@linux-m68k.org>  [m68k]
    Acked-by: Max Filippov <jcmvbkbc@gmail.com>             [xtensa]
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Christophe Leroy <christophe.leroy@c-s.fr>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Dennis Zhou <dennis@kernel.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Petr Mladek <pmladek@suse.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Rob Herring <robh+dt@kernel.org>
    Cc: Rob Herring <robh@kernel.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index bd1cd4bff449..7e97d44f6538 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -374,10 +374,14 @@ void * __ref zalloc_maybe_bootmem(size_t size, gfp_t mask)
 {
 	void *p;
 
-	if (mem_init_done)
+	if (mem_init_done) {
 		p = kzalloc(size, mask);
-	else
+	} else {
 		p = memblock_alloc(size, SMP_CACHE_BYTES);
+		if (!p)
+			panic("%s: Failed to allocate %zu bytes\n",
+			      __func__, size);
+	}
 
 	return p;
 }

commit 0240dfd5b4de79980a484cef8ddf0d52d52bce40
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Mar 11 23:29:56 2019 -0700

    arch: don't memset(0) memory returned by memblock_alloc()
    
    memblock_alloc() already clears the allocated memory, no point in doing
    it twice.
    
    Link: http://lkml.kernel.org/r/1548057848-15136-14-git-send-email-rppt@linux.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org>     [m68k]
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Christophe Leroy <christophe.leroy@c-s.fr>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Dennis Zhou <dennis@kernel.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Guo Ren <ren_guo@c-sky.com>                         [c-sky]
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Juergen Gross <jgross@suse.com>                     [Xen]
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Petr Mladek <pmladek@suse.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Rob Herring <robh+dt@kernel.org>
    Cc: Rob Herring <robh@kernel.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 44f4b8910c21..bd1cd4bff449 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -376,10 +376,8 @@ void * __ref zalloc_maybe_bootmem(size_t size, gfp_t mask)
 
 	if (mem_init_done)
 		p = kzalloc(size, mask);
-	else {
+	else
 		p = memblock_alloc(size, SMP_CACHE_BYTES);
-		if (p)
-			memset(p, 0, size);
-	}
+
 	return p;
 }

commit 3e5e79f240425d93b6c21409c82cbc3d5c2cb71b
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Thu Mar 7 16:30:53 2019 -0800

    microblaze: prefer memblock API returning virtual address
    
    Rather than use the memblock_alloc_base that returns a physical address
    and then convert this address to the virtual one, use appropriate
    memblock function that returns a virtual address.
    
    Link: http://lkml.kernel.org/r/1546248566-14910-3-git-send-email-rppt@linux.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Tested-by: Michal Simek <michal.simek@xilinx.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Stefan Kristiansson <stefan.kristiansson@saunalahti.fi>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index b17fd8aafd64..44f4b8910c21 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -363,8 +363,9 @@ void __init *early_get_page(void)
 	 * Mem start + kernel_tlb -> here is limit
 	 * because of mem mapping from head.S
 	 */
-	return __va(memblock_alloc_base(PAGE_SIZE, PAGE_SIZE,
-				memory_start + kernel_tlb));
+	return memblock_alloc_try_nid_raw(PAGE_SIZE, PAGE_SIZE,
+				MEMBLOCK_LOW_LIMIT, memory_start + kernel_tlb,
+				NUMA_NO_NODE);
 }
 
 #endif /* CONFIG_MMU */

commit 7e1c4e27928e5f87b9b1eaf06dc31773b2f1e7f1
Author: Mike Rapoport <rppt@linux.vnet.ibm.com>
Date:   Tue Oct 30 15:09:57 2018 -0700

    memblock: stop using implicit alignment to SMP_CACHE_BYTES
    
    When a memblock allocation APIs are called with align = 0, the alignment
    is implicitly set to SMP_CACHE_BYTES.
    
    Implicit alignment is done deep in the memblock allocator and it can
    come as a surprise.  Not that such an alignment would be wrong even
    when used incorrectly but it is better to be explicit for the sake of
    clarity and the prinicple of the least surprise.
    
    Replace all such uses of memblock APIs with the 'align' parameter
    explicitly set to SMP_CACHE_BYTES and stop implicit alignment assignment
    in the memblock internal allocation functions.
    
    For the case when memblock APIs are used via helper functions, e.g.  like
    iommu_arena_new_node() in Alpha, the helper functions were detected with
    Coccinelle's help and then manually examined and updated where
    appropriate.
    
    The direct memblock APIs users were updated using the semantic patch below:
    
    @@
    expression size, min_addr, max_addr, nid;
    @@
    (
    |
    - memblock_alloc_try_nid_raw(size, 0, min_addr, max_addr, nid)
    + memblock_alloc_try_nid_raw(size, SMP_CACHE_BYTES, min_addr, max_addr,
    nid)
    |
    - memblock_alloc_try_nid_nopanic(size, 0, min_addr, max_addr, nid)
    + memblock_alloc_try_nid_nopanic(size, SMP_CACHE_BYTES, min_addr, max_addr,
    nid)
    |
    - memblock_alloc_try_nid(size, 0, min_addr, max_addr, nid)
    + memblock_alloc_try_nid(size, SMP_CACHE_BYTES, min_addr, max_addr, nid)
    |
    - memblock_alloc(size, 0)
    + memblock_alloc(size, SMP_CACHE_BYTES)
    |
    - memblock_alloc_raw(size, 0)
    + memblock_alloc_raw(size, SMP_CACHE_BYTES)
    |
    - memblock_alloc_from(size, 0, min_addr)
    + memblock_alloc_from(size, SMP_CACHE_BYTES, min_addr)
    |
    - memblock_alloc_nopanic(size, 0)
    + memblock_alloc_nopanic(size, SMP_CACHE_BYTES)
    |
    - memblock_alloc_low(size, 0)
    + memblock_alloc_low(size, SMP_CACHE_BYTES)
    |
    - memblock_alloc_low_nopanic(size, 0)
    + memblock_alloc_low_nopanic(size, SMP_CACHE_BYTES)
    |
    - memblock_alloc_from_nopanic(size, 0, min_addr)
    + memblock_alloc_from_nopanic(size, SMP_CACHE_BYTES, min_addr)
    |
    - memblock_alloc_node(size, 0, nid)
    + memblock_alloc_node(size, SMP_CACHE_BYTES, nid)
    )
    
    [mhocko@suse.com: changelog update]
    [akpm@linux-foundation.org: coding-style fixes]
    [rppt@linux.ibm.com: fix missed uses of implicit alignment]
      Link: http://lkml.kernel.org/r/20181016133656.GA10925@rapoport-lnx
    Link: http://lkml.kernel.org/r/1538687224-17535-1-git-send-email-rppt@linux.vnet.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Suggested-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Paul Burton <paul.burton@mips.com>    [MIPS]
    Acked-by: Michael Ellerman <mpe@ellerman.id.au> [powerpc]
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 8c14988f52f2..b17fd8aafd64 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -376,7 +376,7 @@ void * __ref zalloc_maybe_bootmem(size_t size, gfp_t mask)
 	if (mem_init_done)
 		p = kzalloc(size, mask);
 	else {
-		p = memblock_alloc(size, 0);
+		p = memblock_alloc(size, SMP_CACHE_BYTES);
 		if (p)
 			memset(p, 0, size);
 	}

commit 57c8a661d95dff48dd9c2f2496139082bbaf241a
Author: Mike Rapoport <rppt@linux.vnet.ibm.com>
Date:   Tue Oct 30 15:09:49 2018 -0700

    mm: remove include/linux/bootmem.h
    
    Move remaining definitions and declarations from include/linux/bootmem.h
    into include/linux/memblock.h and remove the redundant header.
    
    The includes were replaced with the semantic patch below and then
    semi-automated removal of duplicated '#include <linux/memblock.h>
    
    @@
    @@
    - #include <linux/bootmem.h>
    + #include <linux/memblock.h>
    
    [sfr@canb.auug.org.au: dma-direct: fix up for the removal of linux/bootmem.h]
      Link: http://lkml.kernel.org/r/20181002185342.133d1680@canb.auug.org.au
    [sfr@canb.auug.org.au: powerpc: fix up for removal of linux/bootmem.h]
      Link: http://lkml.kernel.org/r/20181005161406.73ef8727@canb.auug.org.au
    [sfr@canb.auug.org.au: x86/kaslr, ACPI/NUMA: fix for linux/bootmem.h removal]
      Link: http://lkml.kernel.org/r/20181008190341.5e396491@canb.auug.org.au
    Link: http://lkml.kernel.org/r/1536927045-23536-30-git-send-email-rppt@linux.vnet.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Ley Foon Tan <lftan@altera.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Palmer Dabbelt <palmer@sifive.com>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Serge Semin <fancer.lancer@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 9989740d397a..8c14988f52f2 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -7,10 +7,9 @@
  * for more details.
  */
 
-#include <linux/bootmem.h>
+#include <linux/memblock.h>
 #include <linux/init.h>
 #include <linux/kernel.h>
-#include <linux/memblock.h>
 #include <linux/mm.h> /* mem_init */
 #include <linux/initrd.h>
 #include <linux/pagemap.h>

commit c6ffc5ca8fb311a89cb6de5c31b6511308ddac8d
Author: Mike Rapoport <rppt@linux.vnet.ibm.com>
Date:   Tue Oct 30 15:09:30 2018 -0700

    memblock: rename free_all_bootmem to memblock_free_all
    
    The conversion is done using
    
    sed -i 's@free_all_bootmem@memblock_free_all@' \
        $(git grep -l free_all_bootmem)
    
    Link: http://lkml.kernel.org/r/1536927045-23536-26-git-send-email-rppt@linux.vnet.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Ley Foon Tan <lftan@altera.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Palmer Dabbelt <palmer@sifive.com>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Serge Semin <fancer.lancer@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 8c7f074ec20f..9989740d397a 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -204,7 +204,7 @@ void __init mem_init(void)
 	high_memory = (void *)__va(memory_start + lowmem_size - 1);
 
 	/* this will put all memory onto the freelists */
-	free_all_bootmem();
+	memblock_free_all();
 #ifdef CONFIG_HIGHMEM
 	highmem_setup();
 #endif

commit 2a5bda5a624d6471d25e953b9adba5182ab1b51f
Author: Mike Rapoport <rppt@linux.vnet.ibm.com>
Date:   Tue Oct 30 15:09:09 2018 -0700

    memblock: replace alloc_bootmem with memblock_alloc
    
    The alloc_bootmem(size) is a shortcut for allocation of SMP_CACHE_BYTES
    aligned memory. When the align parameter of memblock_alloc() is 0, the
    alignment is implicitly set to SMP_CACHE_BYTES and thus alloc_bootmem(size)
    and memblock_alloc(size, 0) are equivalent.
    
    The conversion is done using the following semantic patch:
    
    @@
    expression size;
    @@
    - alloc_bootmem(size)
    + memblock_alloc(size, 0)
    
    Link: http://lkml.kernel.org/r/1536927045-23536-22-git-send-email-rppt@linux.vnet.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Ley Foon Tan <lftan@altera.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Palmer Dabbelt <palmer@sifive.com>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Serge Semin <fancer.lancer@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index df6de7ccdc2e..8c7f074ec20f 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -377,7 +377,7 @@ void * __ref zalloc_maybe_bootmem(size_t size, gfp_t mask)
 	if (mem_init_done)
 		p = kzalloc(size, mask);
 	else {
-		p = alloc_bootmem(size);
+		p = memblock_alloc(size, 0);
 		if (p)
 			memset(p, 0, size);
 	}

commit 101646a24a2f9cdb61d7732459fbf068a7bbb542
Author: Rob Herring <robh@kernel.org>
Date:   Fri Mar 9 09:54:07 2018 -0600

    microblaze: switch to NO_BOOTMEM
    
    Microblaze doesn't set CONFIG_NO_BOOTMEM and so memblock_virt_alloc()
    doesn't work for CONFIG_HAVE_MEMBLOCK && !CONFIG_NO_BOOTMEM.
    
    Similar change was already done by others architectures
    "ARM: mm: Remove bootmem code and switch to NO_BOOTMEM"
    (sha1: 84f452b1e8fc73ac0e31254c66e3e2260ce5263d)
    or
    "openrisc: Consolidate setup to use memblock instead of bootmem"
    (sha1: 266c7fad157265bb54d17db1c9545f2aaa488643)
    or
    "parisc: Drop bootmem and switch to memblock"
    (sha1: 4fe9e1d957e45ad8eba9885ee860a0e93d13a7c7)
    or
    "powerpc: Remove bootmem allocator"
    (sha1: 10239733ee8617bac3f1c1769af43a88ed979324)
    or
    "s390/mm: Convert bootmem to memblock"
    (sha1: 50be634507284eea38df78154d22615d21200b42)
    or
    "sparc64: Convert over to NO_BOOTMEM."
    (sha1: 625d693e9784f988371e69c2b41a2172c0be6c11)
    or
    "xtensa: drop sysmem and switch to memblock"
    (sha1: 0e46c1115f5816949220d62dd3ff04aa68e7ac6b)
    
    Issue was introduced by:
    "of/fdt: use memblock_virt_alloc for early alloc"
    (sha1: 0fa1c579349fdd90173381712ad78aa99c09d38b)
    
    Signed-off-by: Rob Herring <robh@kernel.org>
    Tested-by: Alvaro Gamez Machado <alvaro.gamez@hazent.com>
    Tested-by: Michal Simek <michal.simek@xilinx.com>
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 5bc9c7fbb541..df6de7ccdc2e 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -32,9 +32,6 @@ int mem_init_done;
 #ifndef CONFIG_MMU
 unsigned int __page_offset;
 EXPORT_SYMBOL(__page_offset);
-
-#else
-static int init_bootmem_done;
 #endif /* CONFIG_MMU */
 
 char *klimit = _end;
@@ -117,7 +114,6 @@ static void __init paging_init(void)
 
 void __init setup_memory(void)
 {
-	unsigned long map_size;
 	struct memblock_region *reg;
 
 #ifndef CONFIG_MMU
@@ -174,17 +170,6 @@ void __init setup_memory(void)
 	pr_info("%s: max_low_pfn: %#lx\n", __func__, max_low_pfn);
 	pr_info("%s: max_pfn: %#lx\n", __func__, max_pfn);
 
-	/*
-	 * Find an area to use for the bootmem bitmap.
-	 * We look for the first area which is at least
-	 * 128kB in length (128kB is enough for a bitmap
-	 * for 4GB of memory, using 4kB pages), plus 1 page
-	 * (in case the address isn't page-aligned).
-	 */
-	map_size = init_bootmem_node(NODE_DATA(0),
-		PFN_UP(TOPHYS((u32)klimit)), min_low_pfn, max_low_pfn);
-	memblock_reserve(PFN_UP(TOPHYS((u32)klimit)) << PAGE_SHIFT, map_size);
-
 	/* Add active regions with valid PFNs */
 	for_each_memblock(memory, reg) {
 		unsigned long start_pfn, end_pfn;
@@ -196,32 +181,9 @@ void __init setup_memory(void)
 				  &memblock.memory, 0);
 	}
 
-	/* free bootmem is whole main memory */
-	free_bootmem_with_active_regions(0, max_low_pfn);
-
-	/* reserve allocate blocks */
-	for_each_memblock(reserved, reg) {
-		unsigned long top = reg->base + reg->size - 1;
-
-		pr_debug("reserved - 0x%08x-0x%08x, %lx, %lx\n",
-			 (u32) reg->base, (u32) reg->size, top,
-						memory_start + lowmem_size - 1);
-
-		if (top <= (memory_start + lowmem_size - 1)) {
-			reserve_bootmem(reg->base, reg->size, BOOTMEM_DEFAULT);
-		} else if (reg->base < (memory_start + lowmem_size - 1)) {
-			unsigned long trunc_size = memory_start + lowmem_size -
-								reg->base;
-			reserve_bootmem(reg->base, trunc_size, BOOTMEM_DEFAULT);
-		}
-	}
-
 	/* XXX need to clip this if using highmem? */
 	sparse_memory_present_with_active_regions(0);
 
-#ifdef CONFIG_MMU
-	init_bootmem_done = 1;
-#endif
 	paging_init();
 }
 
@@ -398,18 +360,12 @@ asmlinkage void __init mmu_init(void)
 /* This is only called until mem_init is done. */
 void __init *early_get_page(void)
 {
-	void *p;
-	if (init_bootmem_done) {
-		p = alloc_bootmem_pages(PAGE_SIZE);
-	} else {
-		/*
-		 * Mem start + kernel_tlb -> here is limit
-		 * because of mem mapping from head.S
-		 */
-		p = __va(memblock_alloc_base(PAGE_SIZE, PAGE_SIZE,
-					memory_start + kernel_tlb));
-	}
-	return p;
+	/*
+	 * Mem start + kernel_tlb -> here is limit
+	 * because of mem mapping from head.S
+	 */
+	return __va(memblock_alloc_base(PAGE_SIZE, PAGE_SIZE,
+				memory_start + kernel_tlb));
 }
 
 #endif /* CONFIG_MMU */

commit cd4dfee6a8bfbbe404e9905aff85e267ec99f5fa
Author: Rob Herring <robh@kernel.org>
Date:   Fri Mar 9 09:52:55 2018 -0600

    microblaze: remove unused alloc_maybe_bootmem
    
    alloc_maybe_bootmem is unused, so remove it.
    
    Signed-off-by: Rob Herring <robh@kernel.org>
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 434639f9a3a6..5bc9c7fbb541 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -414,14 +414,6 @@ void __init *early_get_page(void)
 
 #endif /* CONFIG_MMU */
 
-void * __ref alloc_maybe_bootmem(size_t size, gfp_t mask)
-{
-	if (mem_init_done)
-		return kmalloc(size, mask);
-	else
-		return alloc_bootmem(size);
-}
-
 void * __ref zalloc_maybe_bootmem(size_t size, gfp_t mask)
 {
 	void *p;

commit bd721ea73e1f965569b40620538c942001f76294
Author: Fabian Frederick <fabf@skynet.be>
Date:   Tue Aug 2 14:03:33 2016 -0700

    treewide: replace obsolete _refok by __ref
    
    There was only one use of __initdata_refok and __exit_refok
    
    __init_refok was used 46 times against 82 for __ref.
    
    Those definitions are obsolete since commit 312b1485fb50 ("Introduce new
    section reference annotations tags: __ref, __refdata, __refconst")
    
    This patch removes the following compatibility definitions and replaces
    them treewide.
    
    /* compatibility defines */
    #define __init_refok     __ref
    #define __initdata_refok __refdata
    #define __exit_refok     __ref
    
    I can also provide separate patches if necessary.
    (One patch per tree and check in 1 month or 2 to remove old definitions)
    
    [akpm@linux-foundation.org: coding-style fixes]
    Link: http://lkml.kernel.org/r/1466796271-3043-1-git-send-email-fabf@skynet.be
    Signed-off-by: Fabian Frederick <fabf@skynet.be>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Sam Ravnborg <sam@ravnborg.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 77bc7c7e6522..434639f9a3a6 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -414,7 +414,7 @@ void __init *early_get_page(void)
 
 #endif /* CONFIG_MMU */
 
-void * __init_refok alloc_maybe_bootmem(size_t size, gfp_t mask)
+void * __ref alloc_maybe_bootmem(size_t size, gfp_t mask)
 {
 	if (mem_init_done)
 		return kmalloc(size, mask);
@@ -422,7 +422,7 @@ void * __init_refok alloc_maybe_bootmem(size_t size, gfp_t mask)
 		return alloc_bootmem(size);
 }
 
-void * __init_refok zalloc_maybe_bootmem(size_t size, gfp_t mask)
+void * __ref zalloc_maybe_bootmem(size_t size, gfp_t mask)
 {
 	void *p;
 

commit a66a626538af65cbfc611e2b2fce500ed3f24518
Author: Michal Simek <michal.simek@xilinx.com>
Date:   Thu Feb 7 15:12:24 2013 +0100

    microblaze: Use asm-generic/io.h
    
    Using generic io.h will narrow down code duplication
    in architecture io.h.
    
    - define PCI_IOBASE
    - remove non existing pci_io_base extern
    
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 89077d346714..77bc7c7e6522 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -369,7 +369,7 @@ asmlinkage void __init mmu_init(void)
 	if (initrd_start) {
 		unsigned long size;
 		size = initrd_end - initrd_start;
-		memblock_reserve(virt_to_phys(initrd_start), size);
+		memblock_reserve(__virt_to_phys(initrd_start), size);
 	}
 #endif /* CONFIG_BLK_DEV_INITRD */
 

commit e7e8de5918dd6a07cbddae559600d7765ad6a56e
Author: Tang Chen <tangchen@cn.fujitsu.com>
Date:   Tue Jan 21 15:49:26 2014 -0800

    memblock: make memblock_set_node() support different memblock_type
    
    [sfr@canb.auug.org.au: fix powerpc build]
    Signed-off-by: Tang Chen <tangchen@cn.fujitsu.com>
    Reviewed-by: Zhang Yanfei <zhangyanfei@cn.fujitsu.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: "Rafael J . Wysocki" <rjw@sisk.pl>
    Cc: Chen Tang <imtangchen@gmail.com>
    Cc: Gong Chen <gong.chen@linux.intel.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Jiang Liu <jiang.liu@huawei.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Lai Jiangshan <laijs@cn.fujitsu.com>
    Cc: Larry Woodman <lwoodman@redhat.com>
    Cc: Len Brown <lenb@kernel.org>
    Cc: Liu Jiang <jiang.liu@huawei.com>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Michal Nazarewicz <mina86@mina86.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Taku Izumi <izumi.taku@jp.fujitsu.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Thomas Renninger <trenn@suse.de>
    Cc: Toshi Kani <toshi.kani@hp.com>
    Cc: Vasilis Liaskovitis <vasilis.liaskovitis@profitbricks.com>
    Cc: Wanpeng Li <liwanp@linux.vnet.ibm.com>
    Cc: Wen Congyang <wency@cn.fujitsu.com>
    Cc: Yasuaki Ishimatsu <isimatu.yasuaki@jp.fujitsu.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 74c7bcc1e82d..89077d346714 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -192,7 +192,8 @@ void __init setup_memory(void)
 		start_pfn = memblock_region_memory_base_pfn(reg);
 		end_pfn = memblock_region_memory_end_pfn(reg);
 		memblock_set_node(start_pfn << PAGE_SHIFT,
-					(end_pfn - start_pfn) << PAGE_SHIFT, 0);
+				  (end_pfn - start_pfn) << PAGE_SHIFT,
+				  &memblock.memory, 0);
 	}
 
 	/* free bootmem is whole main memory */

commit 6879ea83c6d14e4f21bf48b5780ed549197c668b
Author: Jiang Liu <liuj97@gmail.com>
Date:   Wed Jul 3 15:04:02 2013 -0700

    mm/microblaze: prepare for removing num_physpages and simplify mem_init()
    
    Prepare for removing num_physpages and simplify mem_init().
    
    Signed-off-by: Jiang Liu <jiang.liu@huawei.com>
    Cc: Michal Simek <monstr@monstr.eu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index b384cbc2c8f2..74c7bcc1e82d 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -71,24 +71,17 @@ static void __init highmem_init(void)
 	kmap_prot = PAGE_KERNEL;
 }
 
-static unsigned long highmem_setup(void)
+static void highmem_setup(void)
 {
 	unsigned long pfn;
-	unsigned long reservedpages = 0;
 
 	for (pfn = max_low_pfn; pfn < max_pfn; ++pfn) {
 		struct page *page = pfn_to_page(pfn);
 
 		/* FIXME not sure about */
-		if (memblock_is_reserved(pfn << PAGE_SHIFT))
-			continue;
-		free_highmem_page(page);
-		reservedpages++;
+		if (!memblock_is_reserved(pfn << PAGE_SHIFT))
+			free_highmem_page(page);
 	}
-	pr_info("High memory: %luk\n",
-					totalhigh_pages << (PAGE_SHIFT-10));
-
-	return reservedpages;
 }
 #endif /* CONFIG_HIGHMEM */
 
@@ -167,13 +160,12 @@ void __init setup_memory(void)
 	 * min_low_pfn - the first page (mm/bootmem.c - node_boot_start)
 	 * max_low_pfn
 	 * max_mapnr - the first unused page (mm/bootmem.c - node_low_pfn)
-	 * num_physpages - number of all pages
 	 */
 
 	/* memory start is from the kernel end (aligned) to higher addr */
 	min_low_pfn = memory_start >> PAGE_SHIFT; /* minimum for allocation */
 	/* RAM is assumed contiguous */
-	num_physpages = max_mapnr = memory_size >> PAGE_SHIFT;
+	max_mapnr = memory_size >> PAGE_SHIFT;
 	max_low_pfn = ((u64)memory_start + (u64)lowmem_size) >> PAGE_SHIFT;
 	max_pfn = ((u64)memory_start + (u64)memory_size) >> PAGE_SHIFT;
 
@@ -246,46 +238,15 @@ void free_initmem(void)
 
 void __init mem_init(void)
 {
-	pg_data_t *pgdat;
-	unsigned long reservedpages = 0, codesize, initsize, datasize, bsssize;
-
 	high_memory = (void *)__va(memory_start + lowmem_size - 1);
 
 	/* this will put all memory onto the freelists */
 	free_all_bootmem();
-
-	for_each_online_pgdat(pgdat) {
-		unsigned long i;
-		struct page *page;
-
-		for (i = 0; i < pgdat->node_spanned_pages; i++) {
-			if (!pfn_valid(pgdat->node_start_pfn + i))
-				continue;
-			page = pgdat_page_nr(pgdat, i);
-			if (PageReserved(page))
-				reservedpages++;
-		}
-	}
-
 #ifdef CONFIG_HIGHMEM
-	reservedpages -= highmem_setup();
+	highmem_setup();
 #endif
 
-	codesize = (unsigned long)&_sdata - (unsigned long)&_stext;
-	datasize = (unsigned long)&_edata - (unsigned long)&_sdata;
-	initsize = (unsigned long)&__init_end - (unsigned long)&__init_begin;
-	bsssize = (unsigned long)&__bss_stop - (unsigned long)&__bss_start;
-
-	pr_info("Memory: %luk/%luk available (%luk kernel code, ",
-		nr_free_pages() << (PAGE_SHIFT-10),
-		num_physpages << (PAGE_SHIFT-10),
-		codesize >> 10);
-	pr_cont("%luk reserved, %luk data, %luk bss, %luk init)\n",
-		reservedpages << (PAGE_SHIFT-10),
-		datasize >> 10,
-		bsssize >> 10,
-		initsize >> 10);
-
+	mem_init_print_info(NULL);
 #ifdef CONFIG_MMU
 	pr_info("Kernel virtual memory layout:\n");
 	pr_info("  * 0x%08lx..0x%08lx  : fixmap\n", FIXADDR_START, FIXADDR_TOP);

commit 0c988534737a358fdff42fcce78f0ff1a12dbfc5
Author: Jiang Liu <liuj97@gmail.com>
Date:   Wed Jul 3 15:03:24 2013 -0700

    mm: concentrate modification of totalram_pages into the mm core
    
    Concentrate code to modify totalram_pages into the mm core, so the arch
    memory initialized code doesn't need to take care of it.  With these
    changes applied, only following functions from mm core modify global
    variable totalram_pages: free_bootmem_late(), free_all_bootmem(),
    free_all_bootmem_node(), adjust_managed_page_count().
    
    With this patch applied, it will be much more easier for us to keep
    totalram_pages and zone->managed_pages in consistence.
    
    Signed-off-by: Jiang Liu <jiang.liu@huawei.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: "Michael S. Tsirkin" <mst@redhat.com>
    Cc: <sworddragon2@aol.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Jianguo Wu <wujianguo@huawei.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Kamezawa Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Tang Chen <tangchen@cn.fujitsu.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wen Congyang <wency@cn.fujitsu.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Yasuaki Ishimatsu <isimatu.yasuaki@jp.fujitsu.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index d149e0ebb767..b384cbc2c8f2 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -252,7 +252,7 @@ void __init mem_init(void)
 	high_memory = (void *)__va(memory_start + lowmem_size - 1);
 
 	/* this will put all memory onto the freelists */
-	totalram_pages += free_all_bootmem();
+	free_all_bootmem();
 
 	for_each_online_pgdat(pgdat) {
 		unsigned long i;

commit dbe67df4ba78c79db547c7864e1120981c144c97
Author: Jiang Liu <liuj97@gmail.com>
Date:   Wed Jul 3 15:02:51 2013 -0700

    mm: enhance free_reserved_area() to support poisoning memory with zero
    
    Address more review comments from last round of code review.
    1) Enhance free_reserved_area() to support poisoning freed memory with
       pattern '0'. This could be used to get rid of poison_init_mem()
       on ARM64.
    2) A previous patch has disabled memory poison for initmem on s390
       by mistake, so restore to the original behavior.
    3) Remove redundant PAGE_ALIGN() when calling free_reserved_area().
    
    Signed-off-by: Jiang Liu <jiang.liu@huawei.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: "Michael S. Tsirkin" <mst@redhat.com>
    Cc: <sworddragon2@aol.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Jianguo Wu <wujianguo@huawei.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Kamezawa Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Tang Chen <tangchen@cn.fujitsu.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wen Congyang <wency@cn.fujitsu.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Yasuaki Ishimatsu <isimatu.yasuaki@jp.fujitsu.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index d7b8ada9345f..d149e0ebb767 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -235,13 +235,13 @@ void __init setup_memory(void)
 #ifdef CONFIG_BLK_DEV_INITRD
 void free_initrd_mem(unsigned long start, unsigned long end)
 {
-	free_reserved_area((void *)start, (void *)end, 0, "initrd");
+	free_reserved_area((void *)start, (void *)end, -1, "initrd");
 }
 #endif
 
 void free_initmem(void)
 {
-	free_initmem_default(0);
+	free_initmem_default(-1);
 }
 
 void __init mem_init(void)

commit 11199692d83dd3fe1511203024fb9853d176ec4c
Author: Jiang Liu <liuj97@gmail.com>
Date:   Wed Jul 3 15:02:48 2013 -0700

    mm: change signature of free_reserved_area() to fix building warnings
    
    Change signature of free_reserved_area() according to Russell King's
    suggestion to fix following build warnings:
    
      arch/arm/mm/init.c: In function 'mem_init':
      arch/arm/mm/init.c:603:2: warning: passing argument 1 of 'free_reserved_area' makes integer from pointer without a cast [enabled by default]
        free_reserved_area(__va(PHYS_PFN_OFFSET), swapper_pg_dir, 0, NULL);
        ^
      In file included from include/linux/mman.h:4:0,
                       from arch/arm/mm/init.c:15:
      include/linux/mm.h:1301:22: note: expected 'long unsigned int' but argument is of type 'void *'
       extern unsigned long free_reserved_area(unsigned long start, unsigned long end,
    
       mm/page_alloc.c: In function 'free_reserved_area':
    >> mm/page_alloc.c:5134:3: warning: passing argument 1 of 'virt_to_phys' makes pointer from integer without a cast [enabled by default]
       In file included from arch/mips/include/asm/page.h:49:0,
                        from include/linux/mmzone.h:20,
                        from include/linux/gfp.h:4,
                        from include/linux/mm.h:8,
                        from mm/page_alloc.c:18:
       arch/mips/include/asm/io.h:119:29: note: expected 'const volatile void *' but argument is of type 'long unsigned int'
       mm/page_alloc.c: In function 'free_area_init_nodes':
       mm/page_alloc.c:5030:34: warning: array subscript is below array bounds [-Warray-bounds]
    
    Also address some minor code review comments.
    
    Signed-off-by: Jiang Liu <jiang.liu@huawei.com>
    Reported-by: Arnd Bergmann <arnd@arndb.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: "Michael S. Tsirkin" <mst@redhat.com>
    Cc: <sworddragon2@aol.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Jianguo Wu <wujianguo@huawei.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Kamezawa Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Tang Chen <tangchen@cn.fujitsu.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wen Congyang <wency@cn.fujitsu.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Yasuaki Ishimatsu <isimatu.yasuaki@jp.fujitsu.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index b38ae3acfeb4..d7b8ada9345f 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -235,7 +235,7 @@ void __init setup_memory(void)
 #ifdef CONFIG_BLK_DEV_INITRD
 void free_initrd_mem(unsigned long start, unsigned long end)
 {
-	free_reserved_area(start, end, 0, "initrd");
+	free_reserved_area((void *)start, (void *)end, 0, "initrd");
 }
 #endif
 

commit 5eec2f0228e40318e452d83a5e91052986437d3b
Author: Michal Simek <michal.simek@xilinx.com>
Date:   Thu May 2 15:53:51 2013 +0200

    microblaze: Fix initrd support
    
    Initrd/ramdisk support has been never validated.
    
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 4ec137d13ad7..b38ae3acfeb4 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -404,10 +404,11 @@ asmlinkage void __init mmu_init(void)
 
 #if defined(CONFIG_BLK_DEV_INITRD)
 	/* Remove the init RAM disk from the available memory. */
-/*	if (initrd_start) {
-		mem_pieces_remove(&phys_avail, __pa(initrd_start),
-				  initrd_end - initrd_start, 1);
-	}*/
+	if (initrd_start) {
+		unsigned long size;
+		size = initrd_end - initrd_start;
+		memblock_reserve(virt_to_phys(initrd_start), size);
+	}
 #endif /* CONFIG_BLK_DEV_INITRD */
 
 	/* Initialize the MMU hardware */

commit ec601a34f5bbe9d155181410d854e3875df57c8b
Author: Jiang Liu <liuj97@gmail.com>
Date:   Mon Apr 29 15:07:06 2013 -0700

    mm/microblaze: use free_highmem_page() to free highmem pages into buddy system
    
    Use helper function free_highmem_page() to free highmem pages into
    the buddy system.
    
    Signed-off-by: Jiang Liu <jiang.liu@huawei.com>
    Cc: Michal Simek <monstr@monstr.eu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 9be53024a832..4ec137d13ad7 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -82,13 +82,9 @@ static unsigned long highmem_setup(void)
 		/* FIXME not sure about */
 		if (memblock_is_reserved(pfn << PAGE_SHIFT))
 			continue;
-		ClearPageReserved(page);
-		init_page_count(page);
-		__free_page(page);
-		totalhigh_pages++;
+		free_highmem_page(page);
 		reservedpages++;
 	}
-	totalram_pages += totalhigh_pages;
 	pr_info("High memory: %luk\n",
 					totalhigh_pages << (PAGE_SHIFT-10));
 

commit 7beb5987875bd633c0e10162fbdd4e35d266a9e1
Author: Jiang Liu <liuj97@gmail.com>
Date:   Mon Apr 29 15:06:42 2013 -0700

    mm/microblaze: use common help functions to free reserved pages
    
    Use common help functions to free reserved pages.
    
    Signed-off-by: Jiang Liu <jiang.liu@huawei.com>
    Cc: Michal Simek <monstr@monstr.eu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 8f8b367c079e..9be53024a832 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -236,40 +236,16 @@ void __init setup_memory(void)
 	paging_init();
 }
 
-void free_init_pages(char *what, unsigned long begin, unsigned long end)
-{
-	unsigned long addr;
-
-	for (addr = begin; addr < end; addr += PAGE_SIZE) {
-		ClearPageReserved(virt_to_page(addr));
-		init_page_count(virt_to_page(addr));
-		free_page(addr);
-		totalram_pages++;
-	}
-	pr_info("Freeing %s: %ldk freed\n", what, (end - begin) >> 10);
-}
-
 #ifdef CONFIG_BLK_DEV_INITRD
 void free_initrd_mem(unsigned long start, unsigned long end)
 {
-	int pages = 0;
-	for (; start < end; start += PAGE_SIZE) {
-		ClearPageReserved(virt_to_page(start));
-		init_page_count(virt_to_page(start));
-		free_page(start);
-		totalram_pages++;
-		pages++;
-	}
-	pr_notice("Freeing initrd memory: %dk freed\n",
-					(int)(pages * (PAGE_SIZE / 1024)));
+	free_reserved_area(start, end, 0, "initrd");
 }
 #endif
 
 void free_initmem(void)
 {
-	free_init_pages("unused kernel memory",
-			(unsigned long)(&__init_begin),
-			(unsigned long)(&__init_end));
+	free_initmem_default(0);
 }
 
 void __init mem_init(void)

commit 6bd55f0bbaebb79b39e147aa864401fd0c94db82
Author: Michal Simek <monstr@monstr.eu>
Date:   Thu Dec 27 10:40:38 2012 +0100

    microblaze: Fix coding style issues
    
    Fix coding style issues reported by checkpatch.pl.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index ce80823051ba..8f8b367c079e 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -89,7 +89,7 @@ static unsigned long highmem_setup(void)
 		reservedpages++;
 	}
 	totalram_pages += totalhigh_pages;
-	printk(KERN_INFO "High memory: %luk\n",
+	pr_info("High memory: %luk\n",
 					totalhigh_pages << (PAGE_SHIFT-10));
 
 	return reservedpages;
@@ -142,8 +142,8 @@ void __init setup_memory(void)
 			((u32)_text <= (memory_start + lowmem_size - 1))) {
 			memory_size = lowmem_size;
 			PAGE_OFFSET = memory_start;
-			printk(KERN_INFO "%s: Main mem: 0x%x, "
-				"size 0x%08x\n", __func__, (u32) memory_start,
+			pr_info("%s: Main mem: 0x%x, size 0x%08x\n",
+				__func__, (u32) memory_start,
 					(u32) memory_size);
 			break;
 		}
@@ -158,7 +158,7 @@ void __init setup_memory(void)
 	kernel_align_start = PAGE_DOWN((u32)_text);
 	/* ALIGN can be remove because _end in vmlinux.lds.S is align */
 	kernel_align_size = PAGE_UP((u32)klimit) - kernel_align_start;
-	printk(KERN_INFO "%s: kernel addr:0x%08x-0x%08x size=0x%08x\n",
+	pr_info("%s: kernel addr:0x%08x-0x%08x size=0x%08x\n",
 		__func__, kernel_align_start, kernel_align_start
 			+ kernel_align_size, kernel_align_size);
 	memblock_reserve(kernel_align_start, kernel_align_size);
@@ -181,10 +181,10 @@ void __init setup_memory(void)
 	max_low_pfn = ((u64)memory_start + (u64)lowmem_size) >> PAGE_SHIFT;
 	max_pfn = ((u64)memory_start + (u64)memory_size) >> PAGE_SHIFT;
 
-	printk(KERN_INFO "%s: max_mapnr: %#lx\n", __func__, max_mapnr);
-	printk(KERN_INFO "%s: min_low_pfn: %#lx\n", __func__, min_low_pfn);
-	printk(KERN_INFO "%s: max_low_pfn: %#lx\n", __func__, max_low_pfn);
-	printk(KERN_INFO "%s: max_pfn: %#lx\n", __func__, max_pfn);
+	pr_info("%s: max_mapnr: %#lx\n", __func__, max_mapnr);
+	pr_info("%s: min_low_pfn: %#lx\n", __func__, min_low_pfn);
+	pr_info("%s: max_low_pfn: %#lx\n", __func__, max_low_pfn);
+	pr_info("%s: max_pfn: %#lx\n", __func__, max_pfn);
 
 	/*
 	 * Find an area to use for the bootmem bitmap.
@@ -246,7 +246,7 @@ void free_init_pages(char *what, unsigned long begin, unsigned long end)
 		free_page(addr);
 		totalram_pages++;
 	}
-	printk(KERN_INFO "Freeing %s: %ldk freed\n", what, (end - begin) >> 10);
+	pr_info("Freeing %s: %ldk freed\n", what, (end - begin) >> 10);
 }
 
 #ifdef CONFIG_BLK_DEV_INITRD
@@ -260,7 +260,7 @@ void free_initrd_mem(unsigned long start, unsigned long end)
 		totalram_pages++;
 		pages++;
 	}
-	printk(KERN_NOTICE "Freeing initrd memory: %dk freed\n",
+	pr_notice("Freeing initrd memory: %dk freed\n",
 					(int)(pages * (PAGE_SIZE / 1024)));
 }
 #endif
@@ -304,11 +304,11 @@ void __init mem_init(void)
 	initsize = (unsigned long)&__init_end - (unsigned long)&__init_begin;
 	bsssize = (unsigned long)&__bss_stop - (unsigned long)&__bss_start;
 
-	pr_info("Memory: %luk/%luk available (%luk kernel code, "
-		"%luk reserved, %luk data, %luk bss, %luk init)\n",
+	pr_info("Memory: %luk/%luk available (%luk kernel code, ",
 		nr_free_pages() << (PAGE_SHIFT-10),
 		num_physpages << (PAGE_SHIFT-10),
-		codesize >> 10,
+		codesize >> 10);
+	pr_cont("%luk reserved, %luk data, %luk bss, %luk init)\n",
 		reservedpages << (PAGE_SHIFT-10),
 		datasize >> 10,
 		bsssize >> 10,
@@ -394,17 +394,17 @@ asmlinkage void __init mmu_init(void)
 	unsigned int kstart, ksize;
 
 	if (!memblock.reserved.cnt) {
-		printk(KERN_EMERG "Error memory count\n");
+		pr_emerg("Error memory count\n");
 		machine_restart(NULL);
 	}
 
 	if ((u32) memblock.memory.regions[0].size < 0x400000) {
-		printk(KERN_EMERG "Memory must be greater than 4MB\n");
+		pr_emerg("Memory must be greater than 4MB\n");
 		machine_restart(NULL);
 	}
 
 	if ((u32) memblock.memory.regions[0].size < kernel_tlb) {
-		printk(KERN_EMERG "Kernel size is greater than memory node\n");
+		pr_emerg("Kernel size is greater than memory node\n");
 		machine_restart(NULL);
 	}
 

commit 95b0f9ea66661681f6ae081ea28416744d622c07
Author: Michal Simek <monstr@monstr.eu>
Date:   Mon Feb 8 16:41:38 2010 +0100

    microblaze: Improve TLB calculation for small systems
    
    Systems with small amount of memory need to be handled
    differently. Linux can't allocate the whole 32MB with two TLBs
    because then there is no MMU protection.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 95297b13dd9e..ce80823051ba 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -398,10 +398,16 @@ asmlinkage void __init mmu_init(void)
 		machine_restart(NULL);
 	}
 
-	if ((u32) memblock.memory.regions[0].size < 0x1000000) {
-		printk(KERN_EMERG "Memory must be greater than 16MB\n");
+	if ((u32) memblock.memory.regions[0].size < 0x400000) {
+		printk(KERN_EMERG "Memory must be greater than 4MB\n");
 		machine_restart(NULL);
 	}
+
+	if ((u32) memblock.memory.regions[0].size < kernel_tlb) {
+		printk(KERN_EMERG "Kernel size is greater than memory node\n");
+		machine_restart(NULL);
+	}
+
 	/* Find main memory where the kernel is */
 	memory_start = (u32) memblock.memory.regions[0].base;
 	lowmem_size = memory_size = (u32) memblock.memory.regions[0].size;
@@ -462,11 +468,11 @@ void __init *early_get_page(void)
 		p = alloc_bootmem_pages(PAGE_SIZE);
 	} else {
 		/*
-		 * Mem start + 32MB -> here is limit
+		 * Mem start + kernel_tlb -> here is limit
 		 * because of mem mapping from head.S
 		 */
 		p = __va(memblock_alloc_base(PAGE_SIZE, PAGE_SIZE,
-					memory_start + 0x2000000));
+					memory_start + kernel_tlb));
 	}
 	return p;
 }

commit 2f2f371f8907d169650f594850ca6096e2f73b77
Author: Michal Simek <monstr@monstr.eu>
Date:   Thu Dec 15 15:02:37 2011 +0100

    microblaze: Highmem support
    
    The first highmem implementation.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 43b3f604bafe..95297b13dd9e 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -49,6 +49,53 @@ unsigned long memory_size;
 EXPORT_SYMBOL(memory_size);
 unsigned long lowmem_size;
 
+#ifdef CONFIG_HIGHMEM
+pte_t *kmap_pte;
+EXPORT_SYMBOL(kmap_pte);
+pgprot_t kmap_prot;
+EXPORT_SYMBOL(kmap_prot);
+
+static inline pte_t *virt_to_kpte(unsigned long vaddr)
+{
+	return pte_offset_kernel(pmd_offset(pgd_offset_k(vaddr),
+			vaddr), vaddr);
+}
+
+static void __init highmem_init(void)
+{
+	pr_debug("%x\n", (u32)PKMAP_BASE);
+	map_page(PKMAP_BASE, 0, 0);	/* XXX gross */
+	pkmap_page_table = virt_to_kpte(PKMAP_BASE);
+
+	kmap_pte = virt_to_kpte(__fix_to_virt(FIX_KMAP_BEGIN));
+	kmap_prot = PAGE_KERNEL;
+}
+
+static unsigned long highmem_setup(void)
+{
+	unsigned long pfn;
+	unsigned long reservedpages = 0;
+
+	for (pfn = max_low_pfn; pfn < max_pfn; ++pfn) {
+		struct page *page = pfn_to_page(pfn);
+
+		/* FIXME not sure about */
+		if (memblock_is_reserved(pfn << PAGE_SHIFT))
+			continue;
+		ClearPageReserved(page);
+		init_page_count(page);
+		__free_page(page);
+		totalhigh_pages++;
+		reservedpages++;
+	}
+	totalram_pages += totalhigh_pages;
+	printk(KERN_INFO "High memory: %luk\n",
+					totalhigh_pages << (PAGE_SHIFT-10));
+
+	return reservedpages;
+}
+#endif /* CONFIG_HIGHMEM */
+
 /*
  * paging_init() sets up the page tables - in fact we've already done this.
  */
@@ -66,7 +113,14 @@ static void __init paging_init(void)
 	/* Clean every zones */
 	memset(zones_size, 0, sizeof(zones_size));
 
+#ifdef CONFIG_HIGHMEM
+	highmem_init();
+
+	zones_size[ZONE_DMA] = max_low_pfn;
+	zones_size[ZONE_HIGHMEM] = max_pfn;
+#else
 	zones_size[ZONE_DMA] = max_pfn;
+#endif
 
 	/* We don't have holes in memory map */
 	free_area_init_nodes(zones_size);
@@ -241,6 +295,10 @@ void __init mem_init(void)
 		}
 	}
 
+#ifdef CONFIG_HIGHMEM
+	reservedpages -= highmem_setup();
+#endif
+
 	codesize = (unsigned long)&_sdata - (unsigned long)&_stext;
 	datasize = (unsigned long)&_edata - (unsigned long)&_sdata;
 	initsize = (unsigned long)&__init_end - (unsigned long)&__init_begin;
@@ -259,6 +317,10 @@ void __init mem_init(void)
 #ifdef CONFIG_MMU
 	pr_info("Kernel virtual memory layout:\n");
 	pr_info("  * 0x%08lx..0x%08lx  : fixmap\n", FIXADDR_START, FIXADDR_TOP);
+#ifdef CONFIG_HIGHMEM
+	pr_info("  * 0x%08lx..0x%08lx  : highmem PTEs\n",
+		PKMAP_BASE, PKMAP_ADDR(LAST_PKMAP));
+#endif /* CONFIG_HIGHMEM */
 	pr_info("  * 0x%08lx..0x%08lx  : early ioremap\n",
 		ioremap_bot, ioremap_base);
 	pr_info("  * 0x%08lx..0x%08lx  : vmalloc & ioremap\n",
@@ -346,7 +408,9 @@ asmlinkage void __init mmu_init(void)
 
 	if (lowmem_size > CONFIG_LOWMEM_SIZE) {
 		lowmem_size = CONFIG_LOWMEM_SIZE;
+#ifndef CONFIG_HIGHMEM
 		memory_size = lowmem_size;
+#endif
 	}
 
 	mm_cmdline_setup(); /* FIXME parse args from command line - not used */
@@ -375,7 +439,11 @@ asmlinkage void __init mmu_init(void)
 	mapin_ram();
 
 	/* Extend vmalloc and ioremap area as big as possible */
+#ifdef CONFIG_HIGHMEM
+	ioremap_base = ioremap_bot = PKMAP_BASE;
+#else
 	ioremap_base = ioremap_bot = FIXADDR_START;
+#endif
 
 	/* Initialize the context management stuff */
 	mmu_context_init();

commit baab8a828d2d6b5b073c192ebe777514bbf3c831
Author: Michal Simek <monstr@monstr.eu>
Date:   Thu Dec 15 15:47:16 2011 +0100

    microblaze: Use active regions
    
    Register lowmem active regions.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index cbcdf24b1c89..43b3f604bafe 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -68,7 +68,8 @@ static void __init paging_init(void)
 
 	zones_size[ZONE_DMA] = max_pfn;
 
-	free_area_init(zones_size);
+	/* We don't have holes in memory map */
+	free_area_init_nodes(zones_size);
 }
 
 void __init setup_memory(void)
@@ -142,8 +143,18 @@ void __init setup_memory(void)
 		PFN_UP(TOPHYS((u32)klimit)), min_low_pfn, max_low_pfn);
 	memblock_reserve(PFN_UP(TOPHYS((u32)klimit)) << PAGE_SHIFT, map_size);
 
+	/* Add active regions with valid PFNs */
+	for_each_memblock(memory, reg) {
+		unsigned long start_pfn, end_pfn;
+
+		start_pfn = memblock_region_memory_base_pfn(reg);
+		end_pfn = memblock_region_memory_end_pfn(reg);
+		memblock_set_node(start_pfn << PAGE_SHIFT,
+					(end_pfn - start_pfn) << PAGE_SHIFT, 0);
+	}
+
 	/* free bootmem is whole main memory */
-	free_bootmem(memory_start, lowmem_size);
+	free_bootmem_with_active_regions(0, max_low_pfn);
 
 	/* reserve allocate blocks */
 	for_each_memblock(reserved, reg) {
@@ -162,6 +173,9 @@ void __init setup_memory(void)
 		}
 	}
 
+	/* XXX need to clip this if using highmem? */
+	sparse_memory_present_with_active_regions(0);
+
 #ifdef CONFIG_MMU
 	init_bootmem_done = 1;
 #endif

commit 832997990ab912ab8ed4ade08cb6ac5f471efa1e
Author: Michal Simek <monstr@monstr.eu>
Date:   Mon Dec 19 13:47:03 2011 +0100

    microblaze: Show more detailed information about memory
    
    Microblaze MMU is similar to ppc that's why ppc layout
    was reused.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index af87fd71a83e..cbcdf24b1c89 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -206,14 +206,50 @@ void free_initmem(void)
 
 void __init mem_init(void)
 {
+	pg_data_t *pgdat;
+	unsigned long reservedpages = 0, codesize, initsize, datasize, bsssize;
+
 	high_memory = (void *)__va(memory_start + lowmem_size - 1);
 
 	/* this will put all memory onto the freelists */
 	totalram_pages += free_all_bootmem();
 
-	printk(KERN_INFO "Memory: %luk/%luk available\n",
-	       nr_free_pages() << (PAGE_SHIFT-10),
-	       num_physpages << (PAGE_SHIFT-10));
+	for_each_online_pgdat(pgdat) {
+		unsigned long i;
+		struct page *page;
+
+		for (i = 0; i < pgdat->node_spanned_pages; i++) {
+			if (!pfn_valid(pgdat->node_start_pfn + i))
+				continue;
+			page = pgdat_page_nr(pgdat, i);
+			if (PageReserved(page))
+				reservedpages++;
+		}
+	}
+
+	codesize = (unsigned long)&_sdata - (unsigned long)&_stext;
+	datasize = (unsigned long)&_edata - (unsigned long)&_sdata;
+	initsize = (unsigned long)&__init_end - (unsigned long)&__init_begin;
+	bsssize = (unsigned long)&__bss_stop - (unsigned long)&__bss_start;
+
+	pr_info("Memory: %luk/%luk available (%luk kernel code, "
+		"%luk reserved, %luk data, %luk bss, %luk init)\n",
+		nr_free_pages() << (PAGE_SHIFT-10),
+		num_physpages << (PAGE_SHIFT-10),
+		codesize >> 10,
+		reservedpages << (PAGE_SHIFT-10),
+		datasize >> 10,
+		bsssize >> 10,
+		initsize >> 10);
+
+#ifdef CONFIG_MMU
+	pr_info("Kernel virtual memory layout:\n");
+	pr_info("  * 0x%08lx..0x%08lx  : fixmap\n", FIXADDR_START, FIXADDR_TOP);
+	pr_info("  * 0x%08lx..0x%08lx  : early ioremap\n",
+		ioremap_bot, ioremap_base);
+	pr_info("  * 0x%08lx..0x%08lx  : vmalloc & ioremap\n",
+		(unsigned long)VMALLOC_START, VMALLOC_END);
+#endif
 	mem_init_done = 1;
 }
 

commit 419387612c03fce2ca6d5a3d6aac3dae42069264
Author: Michal Simek <monstr@monstr.eu>
Date:   Thu Dec 15 14:33:32 2011 +0100

    microblaze: Introduce fixmap
    
    Fixmap will be used for highmem support.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 2253e122aa85..af87fd71a83e 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -24,6 +24,7 @@
 #include <asm/pgalloc.h>
 #include <asm/sections.h>
 #include <asm/tlb.h>
+#include <asm/fixmap.h>
 
 /* Use for MMU and noMMU because of PCI generic code */
 int mem_init_done;
@@ -54,6 +55,13 @@ unsigned long lowmem_size;
 static void __init paging_init(void)
 {
 	unsigned long zones_size[MAX_NR_ZONES];
+#ifdef CONFIG_MMU
+	int idx;
+
+	/* Setup fixmaps */
+	for (idx = 0; idx < __end_of_fixed_addresses; idx++)
+		clear_fixmap(idx);
+#endif
 
 	/* Clean every zones */
 	memset(zones_size, 0, sizeof(zones_size));
@@ -316,12 +324,9 @@ asmlinkage void __init mmu_init(void)
 	/* Map in all of RAM starting at CONFIG_KERNEL_START */
 	mapin_ram();
 
-#ifdef CONFIG_HIGHMEM_START_BOOL
-	ioremap_base = CONFIG_HIGHMEM_START;
-#else
-	ioremap_base = 0xfe000000UL;	/* for now, could be 0xfffff000 */
-#endif /* CONFIG_HIGHMEM_START_BOOL */
-	ioremap_bot = ioremap_base;
+	/* Extend vmalloc and ioremap area as big as possible */
+	ioremap_base = ioremap_bot = FIXADDR_START;
+
 	/* Initialize the context management stuff */
 	mmu_context_init();
 

commit 83a92529c1789f86481190743a6bb09f31ec39a8
Author: Michal Simek <monstr@monstr.eu>
Date:   Mon Dec 19 13:46:35 2011 +0100

    microblaze: mm: Fix lowmem max memory size limits
    
    Use CONFIG_LOWMEM_SIZE if system has larger ram size.
    For system with larger ram size, enable HIGMEM support.
    
    Also setup limitation for memblock and use memblock
    allocation in lowmem region.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index a72f42498c25..2253e122aa85 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -44,9 +44,9 @@ char *klimit = _end;
  */
 unsigned long memory_start;
 EXPORT_SYMBOL(memory_start);
-unsigned long memory_end; /* due to mm/nommu.c */
 unsigned long memory_size;
 EXPORT_SYMBOL(memory_size);
+unsigned long lowmem_size;
 
 /*
  * paging_init() sets up the page tables - in fact we've already done this.
@@ -58,7 +58,7 @@ static void __init paging_init(void)
 	/* Clean every zones */
 	memset(zones_size, 0, sizeof(zones_size));
 
-	zones_size[ZONE_DMA] = max_mapnr;
+	zones_size[ZONE_DMA] = max_pfn;
 
 	free_area_init(zones_size);
 }
@@ -74,32 +74,31 @@ void __init setup_memory(void)
 	/* Find main memory where is the kernel */
 	for_each_memblock(memory, reg) {
 		memory_start = (u32)reg->base;
-		memory_end = (u32) reg->base + reg->size;
+		lowmem_size = reg->size;
 		if ((memory_start <= (u32)_text) &&
-					((u32)_text <= memory_end)) {
-			memory_size = memory_end - memory_start;
+			((u32)_text <= (memory_start + lowmem_size - 1))) {
+			memory_size = lowmem_size;
 			PAGE_OFFSET = memory_start;
-			printk(KERN_INFO "%s: Main mem: 0x%x-0x%x, "
+			printk(KERN_INFO "%s: Main mem: 0x%x, "
 				"size 0x%08x\n", __func__, (u32) memory_start,
-					(u32) memory_end, (u32) memory_size);
+					(u32) memory_size);
 			break;
 		}
 	}
 
-	if (!memory_start || !memory_end) {
-		panic("%s: Missing memory setting 0x%08x-0x%08x\n",
-			__func__, (u32) memory_start, (u32) memory_end);
+	if (!memory_start || !memory_size) {
+		panic("%s: Missing memory setting 0x%08x, size=0x%08x\n",
+			__func__, (u32) memory_start, (u32) memory_size);
 	}
 
 	/* reservation of region where is the kernel */
 	kernel_align_start = PAGE_DOWN((u32)_text);
 	/* ALIGN can be remove because _end in vmlinux.lds.S is align */
 	kernel_align_size = PAGE_UP((u32)klimit) - kernel_align_start;
-	memblock_reserve(kernel_align_start, kernel_align_size);
-	printk(KERN_INFO "%s: kernel addr=0x%08x-0x%08x size=0x%08x\n",
+	printk(KERN_INFO "%s: kernel addr:0x%08x-0x%08x size=0x%08x\n",
 		__func__, kernel_align_start, kernel_align_start
 			+ kernel_align_size, kernel_align_size);
-
+	memblock_reserve(kernel_align_start, kernel_align_size);
 #endif
 	/*
 	 * Kernel:
@@ -116,11 +115,13 @@ void __init setup_memory(void)
 	min_low_pfn = memory_start >> PAGE_SHIFT; /* minimum for allocation */
 	/* RAM is assumed contiguous */
 	num_physpages = max_mapnr = memory_size >> PAGE_SHIFT;
-	max_pfn = max_low_pfn = memory_end >> PAGE_SHIFT;
+	max_low_pfn = ((u64)memory_start + (u64)lowmem_size) >> PAGE_SHIFT;
+	max_pfn = ((u64)memory_start + (u64)memory_size) >> PAGE_SHIFT;
 
 	printk(KERN_INFO "%s: max_mapnr: %#lx\n", __func__, max_mapnr);
 	printk(KERN_INFO "%s: min_low_pfn: %#lx\n", __func__, min_low_pfn);
 	printk(KERN_INFO "%s: max_low_pfn: %#lx\n", __func__, max_low_pfn);
+	printk(KERN_INFO "%s: max_pfn: %#lx\n", __func__, max_pfn);
 
 	/*
 	 * Find an area to use for the bootmem bitmap.
@@ -134,14 +135,25 @@ void __init setup_memory(void)
 	memblock_reserve(PFN_UP(TOPHYS((u32)klimit)) << PAGE_SHIFT, map_size);
 
 	/* free bootmem is whole main memory */
-	free_bootmem(memory_start, memory_size);
+	free_bootmem(memory_start, lowmem_size);
 
 	/* reserve allocate blocks */
 	for_each_memblock(reserved, reg) {
-		pr_debug("reserved - 0x%08x-0x%08x\n",
-			 (u32) reg->base, (u32) reg->size);
-		reserve_bootmem(reg->base, reg->size, BOOTMEM_DEFAULT);
+		unsigned long top = reg->base + reg->size - 1;
+
+		pr_debug("reserved - 0x%08x-0x%08x, %lx, %lx\n",
+			 (u32) reg->base, (u32) reg->size, top,
+						memory_start + lowmem_size - 1);
+
+		if (top <= (memory_start + lowmem_size - 1)) {
+			reserve_bootmem(reg->base, reg->size, BOOTMEM_DEFAULT);
+		} else if (reg->base < (memory_start + lowmem_size - 1)) {
+			unsigned long trunc_size = memory_start + lowmem_size -
+								reg->base;
+			reserve_bootmem(reg->base, trunc_size, BOOTMEM_DEFAULT);
+		}
 	}
+
 #ifdef CONFIG_MMU
 	init_bootmem_done = 1;
 #endif
@@ -186,7 +198,8 @@ void free_initmem(void)
 
 void __init mem_init(void)
 {
-	high_memory = (void *)__va(memory_end);
+	high_memory = (void *)__va(memory_start + lowmem_size - 1);
+
 	/* this will put all memory onto the freelists */
 	totalram_pages += free_all_bootmem();
 
@@ -222,7 +235,6 @@ static void mm_cmdline_setup(void)
 		maxmem = memparse(p, &p);
 		if (maxmem && memory_size > maxmem) {
 			memory_size = maxmem;
-			memory_end = memory_start + memory_size;
 			memblock.memory.regions[0].size = memory_size;
 		}
 	}
@@ -272,9 +284,12 @@ asmlinkage void __init mmu_init(void)
 	}
 	/* Find main memory where the kernel is */
 	memory_start = (u32) memblock.memory.regions[0].base;
-	memory_end = (u32) memblock.memory.regions[0].base +
-				(u32) memblock.memory.regions[0].size;
-	memory_size = memory_end - memory_start;
+	lowmem_size = memory_size = (u32) memblock.memory.regions[0].size;
+
+	if (lowmem_size > CONFIG_LOWMEM_SIZE) {
+		lowmem_size = CONFIG_LOWMEM_SIZE;
+		memory_size = lowmem_size;
+	}
 
 	mm_cmdline_setup(); /* FIXME parse args from command line - not used */
 
@@ -307,9 +322,13 @@ asmlinkage void __init mmu_init(void)
 	ioremap_base = 0xfe000000UL;	/* for now, could be 0xfffff000 */
 #endif /* CONFIG_HIGHMEM_START_BOOL */
 	ioremap_bot = ioremap_base;
-
 	/* Initialize the context management stuff */
 	mmu_context_init();
+
+	/* Shortly after that, the entire linear mapping will be available */
+	/* This will also cause that unflatten device tree will be allocated
+	 * inside 768MB limit */
+	memblock_set_current_limit(memory_start + lowmem_size - 1);
 }
 
 /* This is only called until mem_init is done. */

commit 4e2e4124b7fe68b28e9f759b7ecc0ec16307fce6
Author: Michal Simek <monstr@monstr.eu>
Date:   Thu Dec 15 09:24:06 2011 +0100

    microblaze: mm: Use ZONE_DMA instead of ZONE_NORMAL
    
    We should use ZONE_DMA because all address space is dma-able.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 565d193c7ebf..a72f42498c25 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -58,11 +58,7 @@ static void __init paging_init(void)
 	/* Clean every zones */
 	memset(zones_size, 0, sizeof(zones_size));
 
-	/*
-	 * old: we can DMA to/from any address.put all page into ZONE_DMA
-	 * We use only ZONE_NORMAL
-	 */
-	zones_size[ZONE_NORMAL] = max_mapnr;
+	zones_size[ZONE_DMA] = max_mapnr;
 
 	free_area_init(zones_size);
 }

commit 66421a648d11c60e75d1ec4876f0748341598f5d
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Thu Sep 22 11:22:55 2011 -0400

    microblaze: Add export.h to arch/microblaze files as required
    
    For access to the EXPORT_SYMBOL variants and THIS_MODULE macros.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 36a133e5ee35..565d193c7ebf 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -17,6 +17,7 @@
 #include <linux/pfn.h>
 #include <linux/slab.h>
 #include <linux/swap.h>
+#include <linux/export.h>
 
 #include <asm/page.h>
 #include <asm/mmu_context.h>

commit 6be9dd121ddeca9dcfb35aee96273c92bbd28014
Author: Paul Bolle <pebolle@tiscali.nl>
Date:   Wed Oct 12 21:28:36 2011 +0200

    microblaze: add missing CONFIG_ prefixes
    
    Signed-off-by: Paul Bolle <pebolle@tiscali.nl>
    Acked-by: Michal Simek <monstr@monstr.eu>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 213f2d671669..36a133e5ee35 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -304,11 +304,11 @@ asmlinkage void __init mmu_init(void)
 	/* Map in all of RAM starting at CONFIG_KERNEL_START */
 	mapin_ram();
 
-#ifdef HIGHMEM_START_BOOL
-	ioremap_base = HIGHMEM_START;
+#ifdef CONFIG_HIGHMEM_START_BOOL
+	ioremap_base = CONFIG_HIGHMEM_START;
 #else
 	ioremap_base = 0xfe000000UL;	/* for now, could be 0xfffff000 */
-#endif /* CONFIG_HIGHMEM */
+#endif /* CONFIG_HIGHMEM_START_BOOL */
 	ioremap_bot = ioremap_base;
 
 	/* Initialize the context management stuff */

commit 1c395176962176660bb108f90e97e1686cfe0d85
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Tue May 24 17:11:58 2011 -0700

    mm: now that all old mmu_gather code is gone, remove the storage
    
    Fold all the mmu_gather rework patches into one for submission
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Reported-by: Hugh Dickins <hughd@google.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: David Miller <davem@davemloft.net>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Nick Piggin <npiggin@kernel.dk>
    Cc: Namhyung Kim <namhyung@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index c8437866d3b7..213f2d671669 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -32,8 +32,6 @@ unsigned int __page_offset;
 EXPORT_SYMBOL(__page_offset);
 
 #else
-DEFINE_PER_CPU(struct mmu_gather, mmu_gathers);
-
 static int init_bootmem_done;
 #endif /* CONFIG_MMU */
 

commit da5ab11cdfdf496448e0e9cdbbc2dfe207a96c94
Author: Michal Simek <monstr@monstr.eu>
Date:   Sat Sep 11 00:07:06 2010 -0700

    memblock, microblaze: Fix memblock API change fallout
    
    Adopt Microblaze to the memblock API changes, to fix this
    build failure:
    
      CC      arch/microblaze/mm/init.o
     arch/microblaze/mm/init.c: In function 'mm_cmdline_setup':
     arch/microblaze/mm/init.c:236: error: 'struct memblock_type' has no member named 'region'
     ...
    
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Cc: linux-mm@kvack.org
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    LKML-Reference: <4C8B2A9A.1040303@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 840026c5bc56..c8437866d3b7 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -228,7 +228,7 @@ static void mm_cmdline_setup(void)
 		if (maxmem && memory_size > maxmem) {
 			memory_size = maxmem;
 			memory_end = memory_start + memory_size;
-			memblock.memory.region[0].size = memory_size;
+			memblock.memory.regions[0].size = memory_size;
 		}
 	}
 }
@@ -271,14 +271,14 @@ asmlinkage void __init mmu_init(void)
 		machine_restart(NULL);
 	}
 
-	if ((u32) memblock.memory.region[0].size < 0x1000000) {
+	if ((u32) memblock.memory.regions[0].size < 0x1000000) {
 		printk(KERN_EMERG "Memory must be greater than 16MB\n");
 		machine_restart(NULL);
 	}
 	/* Find main memory where the kernel is */
-	memory_start = (u32) memblock.memory.region[0].base;
-	memory_end = (u32) memblock.memory.region[0].base +
-				(u32) memblock.memory.region[0].size;
+	memory_start = (u32) memblock.memory.regions[0].base;
+	memory_end = (u32) memblock.memory.regions[0].base +
+				(u32) memblock.memory.regions[0].size;
 	memory_size = memory_end - memory_start;
 
 	mm_cmdline_setup(); /* FIXME parse args from command line - not used */

commit daab7fc734a53fdeaf844b7c03053118ad1769da
Merge: 774ea0bcb27f 2bfc96a127bc
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Aug 31 09:45:21 2010 +0200

    Merge commit 'v2.6.36-rc3' into x86/memblock
    
    Conflicts:
            arch/x86/kernel/trampoline.c
            mm/memblock.c
    
    Merge reason: Resolve the conflicts, update to latest upstream.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit e05816679b61e47e90d7455a8f6dc6126dc479e3
Author: Michal Simek <monstr@monstr.eu>
Date:   Thu May 27 11:17:35 2010 +0200

    microblaze: Sync noMMU and MMU setup_memory
    
    Both versions can use the same node to register NODE_DATA(0)
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index db5934989926..65eb00419d19 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -134,13 +134,8 @@ void __init setup_memory(void)
 	 * for 4GB of memory, using 4kB pages), plus 1 page
 	 * (in case the address isn't page-aligned).
 	 */
-#ifndef CONFIG_MMU
-	map_size = init_bootmem_node(NODE_DATA(0), PFN_UP(TOPHYS((u32)klimit)),
-					min_low_pfn, max_low_pfn);
-#else
-	map_size = init_bootmem_node(&contig_page_data,
+	map_size = init_bootmem_node(NODE_DATA(0),
 		PFN_UP(TOPHYS((u32)klimit)), min_low_pfn, max_low_pfn);
-#endif
 	memblock_reserve(PFN_UP(TOPHYS((u32)klimit)) << PAGE_SHIFT, map_size);
 
 	/* free bootmem is whole main memory */

commit 76bfcc818f87d884e427908f5010128dae32d11a
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Aug 4 14:13:06 2010 +1000

    memblock/microblaze: Use new accessors
    
    CC: Michal Simek <monstr@monstr.eu>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index afd6494fbbc6..32a702b621c8 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -70,16 +70,16 @@ static void __init paging_init(void)
 
 void __init setup_memory(void)
 {
-	int i;
 	unsigned long map_size;
+	struct memblock_region *reg;
+
 #ifndef CONFIG_MMU
 	u32 kernel_align_start, kernel_align_size;
 
 	/* Find main memory where is the kernel */
-	for (i = 0; i < memblock.memory.cnt; i++) {
-		memory_start = (u32) memblock.memory.regions[i].base;
-		memory_end = (u32) memblock.memory.regions[i].base
-				+ (u32) memblock.memory.region[i].size;
+	for_each_memblock(memory, reg) {
+		memory_start = (u32)reg->base;
+		memory_end = (u32) reg->base + reg->size;
 		if ((memory_start <= (u32)_text) &&
 					((u32)_text <= memory_end)) {
 			memory_size = memory_end - memory_start;
@@ -147,12 +147,10 @@ void __init setup_memory(void)
 	free_bootmem(memory_start, memory_size);
 
 	/* reserve allocate blocks */
-	for (i = 0; i < memblock.reserved.cnt; i++) {
-		pr_debug("reserved %d - 0x%08x-0x%08x\n", i,
-			(u32) memblock.reserved.region[i].base,
-			(u32) memblock_size_bytes(&memblock.reserved, i));
-		reserve_bootmem(memblock.reserved.region[i].base,
-			memblock_size_bytes(&memblock.reserved, i) - 1, BOOTMEM_DEFAULT);
+	for_each_memblock(reserved, reg) {
+		pr_debug("reserved - 0x%08x-0x%08x\n",
+			 (u32) reg->base, (u32) reg->size);
+		reserve_bootmem(reg->base, reg->size, BOOTMEM_DEFAULT);
 	}
 #ifdef CONFIG_MMU
 	init_bootmem_done = 1;

commit e3239ff92a17976ac5d26fa0fe40ef3a9daf2523
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Aug 4 14:06:41 2010 +1000

    memblock: Rename memblock_region to memblock_type and memblock_property to memblock_region
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index db5934989926..afd6494fbbc6 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -77,8 +77,8 @@ void __init setup_memory(void)
 
 	/* Find main memory where is the kernel */
 	for (i = 0; i < memblock.memory.cnt; i++) {
-		memory_start = (u32) memblock.memory.region[i].base;
-		memory_end = (u32) memblock.memory.region[i].base
+		memory_start = (u32) memblock.memory.regions[i].base;
+		memory_end = (u32) memblock.memory.regions[i].base
 				+ (u32) memblock.memory.region[i].size;
 		if ((memory_start <= (u32)_text) &&
 					((u32)_text <= memory_end)) {

commit 95f72d1ed41a66f1c1c29c24d479de81a0bea36f
Author: Yinghai Lu <yinghai@kernel.org>
Date:   Mon Jul 12 14:36:09 2010 +1000

    lmb: rename to memblock
    
    via following scripts
    
          FILES=$(find * -type f | grep -vE 'oprofile|[^K]config')
    
          sed -i \
            -e 's/lmb/memblock/g' \
            -e 's/LMB/MEMBLOCK/g' \
            $FILES
    
          for N in $(find . -name lmb.[ch]); do
            M=$(echo $N | sed 's/lmb/memblock/g')
            mv $N $M
          done
    
    and remove some wrong change like lmbench and dlmb etc.
    
    also move memblock.c from lib/ to mm/
    
    Suggested-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: "H. Peter Anvin" <hpa@zytor.com>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Yinghai Lu <yinghai@kernel.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index cca3579d4268..db5934989926 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -10,7 +10,7 @@
 #include <linux/bootmem.h>
 #include <linux/init.h>
 #include <linux/kernel.h>
-#include <linux/lmb.h>
+#include <linux/memblock.h>
 #include <linux/mm.h> /* mem_init */
 #include <linux/initrd.h>
 #include <linux/pagemap.h>
@@ -76,10 +76,10 @@ void __init setup_memory(void)
 	u32 kernel_align_start, kernel_align_size;
 
 	/* Find main memory where is the kernel */
-	for (i = 0; i < lmb.memory.cnt; i++) {
-		memory_start = (u32) lmb.memory.region[i].base;
-		memory_end = (u32) lmb.memory.region[i].base
-				+ (u32) lmb.memory.region[i].size;
+	for (i = 0; i < memblock.memory.cnt; i++) {
+		memory_start = (u32) memblock.memory.region[i].base;
+		memory_end = (u32) memblock.memory.region[i].base
+				+ (u32) memblock.memory.region[i].size;
 		if ((memory_start <= (u32)_text) &&
 					((u32)_text <= memory_end)) {
 			memory_size = memory_end - memory_start;
@@ -100,7 +100,7 @@ void __init setup_memory(void)
 	kernel_align_start = PAGE_DOWN((u32)_text);
 	/* ALIGN can be remove because _end in vmlinux.lds.S is align */
 	kernel_align_size = PAGE_UP((u32)klimit) - kernel_align_start;
-	lmb_reserve(kernel_align_start, kernel_align_size);
+	memblock_reserve(kernel_align_start, kernel_align_size);
 	printk(KERN_INFO "%s: kernel addr=0x%08x-0x%08x size=0x%08x\n",
 		__func__, kernel_align_start, kernel_align_start
 			+ kernel_align_size, kernel_align_size);
@@ -141,18 +141,18 @@ void __init setup_memory(void)
 	map_size = init_bootmem_node(&contig_page_data,
 		PFN_UP(TOPHYS((u32)klimit)), min_low_pfn, max_low_pfn);
 #endif
-	lmb_reserve(PFN_UP(TOPHYS((u32)klimit)) << PAGE_SHIFT, map_size);
+	memblock_reserve(PFN_UP(TOPHYS((u32)klimit)) << PAGE_SHIFT, map_size);
 
 	/* free bootmem is whole main memory */
 	free_bootmem(memory_start, memory_size);
 
 	/* reserve allocate blocks */
-	for (i = 0; i < lmb.reserved.cnt; i++) {
+	for (i = 0; i < memblock.reserved.cnt; i++) {
 		pr_debug("reserved %d - 0x%08x-0x%08x\n", i,
-			(u32) lmb.reserved.region[i].base,
-			(u32) lmb_size_bytes(&lmb.reserved, i));
-		reserve_bootmem(lmb.reserved.region[i].base,
-			lmb_size_bytes(&lmb.reserved, i) - 1, BOOTMEM_DEFAULT);
+			(u32) memblock.reserved.region[i].base,
+			(u32) memblock_size_bytes(&memblock.reserved, i));
+		reserve_bootmem(memblock.reserved.region[i].base,
+			memblock_size_bytes(&memblock.reserved, i) - 1, BOOTMEM_DEFAULT);
 	}
 #ifdef CONFIG_MMU
 	init_bootmem_done = 1;
@@ -235,7 +235,7 @@ static void mm_cmdline_setup(void)
 		if (maxmem && memory_size > maxmem) {
 			memory_size = maxmem;
 			memory_end = memory_start + memory_size;
-			lmb.memory.region[0].size = memory_size;
+			memblock.memory.region[0].size = memory_size;
 		}
 	}
 }
@@ -273,19 +273,19 @@ asmlinkage void __init mmu_init(void)
 {
 	unsigned int kstart, ksize;
 
-	if (!lmb.reserved.cnt) {
+	if (!memblock.reserved.cnt) {
 		printk(KERN_EMERG "Error memory count\n");
 		machine_restart(NULL);
 	}
 
-	if ((u32) lmb.memory.region[0].size < 0x1000000) {
+	if ((u32) memblock.memory.region[0].size < 0x1000000) {
 		printk(KERN_EMERG "Memory must be greater than 16MB\n");
 		machine_restart(NULL);
 	}
 	/* Find main memory where the kernel is */
-	memory_start = (u32) lmb.memory.region[0].base;
-	memory_end = (u32) lmb.memory.region[0].base +
-				(u32) lmb.memory.region[0].size;
+	memory_start = (u32) memblock.memory.region[0].base;
+	memory_end = (u32) memblock.memory.region[0].base +
+				(u32) memblock.memory.region[0].size;
 	memory_size = memory_end - memory_start;
 
 	mm_cmdline_setup(); /* FIXME parse args from command line - not used */
@@ -297,7 +297,7 @@ asmlinkage void __init mmu_init(void)
 	kstart = __pa(CONFIG_KERNEL_START); /* kernel start */
 	/* kernel size */
 	ksize = PAGE_ALIGN(((u32)_end - (u32)CONFIG_KERNEL_START));
-	lmb_reserve(kstart, ksize);
+	memblock_reserve(kstart, ksize);
 
 #if defined(CONFIG_BLK_DEV_INITRD)
 	/* Remove the init RAM disk from the available memory. */
@@ -335,7 +335,7 @@ void __init *early_get_page(void)
 		 * Mem start + 32MB -> here is limit
 		 * because of mem mapping from head.S
 		 */
-		p = __va(lmb_alloc_base(PAGE_SIZE, PAGE_SIZE,
+		p = __va(memblock_alloc_base(PAGE_SIZE, PAGE_SIZE,
 					memory_start + 0x2000000));
 	}
 	return p;

commit ee4bcdf1d248c4ebe5f73e11631c3bd3f76d777b
Author: Michal Simek <monstr@monstr.eu>
Date:   Thu May 13 12:11:42 2010 +0200

    microblaze: export assembly functions used by modules
    
    Export __strncpy_user, memory_size, ioremap_bot for modules.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index f42c2dde8b1c..cca3579d4268 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -47,6 +47,7 @@ unsigned long memory_start;
 EXPORT_SYMBOL(memory_start);
 unsigned long memory_end; /* due to mm/nommu.c */
 unsigned long memory_size;
+EXPORT_SYMBOL(memory_size);
 
 /*
  * paging_init() sets up the page tables - in fact we've already done this.

commit 336f5899d287f06d8329e208fc14ce50f7ec9698
Merge: a4ab2773205e db217dece300
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Apr 5 11:37:28 2010 +0900

    Merge branch 'master' into export-slabh

commit 60a729f7bb936a9ab82b430de70a1952f560adf3
Author: Michal Simek <monstr@monstr.eu>
Date:   Fri Mar 5 15:49:53 2010 +0100

    microblaze: move noMMU __range_ok function to uaccess.h
    
    The same noMMU and MMU functions should be placed in
    one file.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 45b4bce606bb..40bc10ede097 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -207,14 +207,6 @@ void __init mem_init(void)
 }
 
 #ifndef CONFIG_MMU
-/* Check against bounds of physical memory */
-int ___range_ok(unsigned long addr, unsigned long size)
-{
-	return ((addr < memory_start) ||
-		((addr + size) > memory_end));
-}
-EXPORT_SYMBOL(___range_ok);
-
 int page_is_ram(unsigned long pfn)
 {
 	return __range_ok(pfn, 0);

commit 4009819cf90c26e3ec7b0ed949d5ff37c568e197
Author: Michal Simek <monstr@monstr.eu>
Date:   Wed Mar 3 17:03:21 2010 +0100

    microblaze: Remove memset in free_init_pages
    
    We don't need to do it.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 1608e2e1a44a..45b4bce606bb 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -165,7 +165,6 @@ void free_init_pages(char *what, unsigned long begin, unsigned long end)
 	for (addr = begin; addr < end; addr += PAGE_SIZE) {
 		ClearPageReserved(virt_to_page(addr));
 		init_page_count(virt_to_page(addr));
-		memset((void *)addr, 0xcc, PAGE_SIZE);
 		free_page(addr);
 		totalram_pages++;
 	}

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 1608e2e1a44a..77c9e3033e71 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -15,6 +15,7 @@
 #include <linux/initrd.h>
 #include <linux/pagemap.h>
 #include <linux/pfn.h>
+#include <linux/slab.h>
 #include <linux/swap.h>
 
 #include <asm/page.h>

commit 79bf3a137617e6deeac411c39f1660b7e91d6348
Author: Michal Simek <monstr@monstr.eu>
Date:   Wed Jan 20 15:17:08 2010 +0100

    microblaze: PCI early support for noMMU system
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index aa6e163411b5..1608e2e1a44a 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -23,6 +23,9 @@
 #include <asm/sections.h>
 #include <asm/tlb.h>
 
+/* Use for MMU and noMMU because of PCI generic code */
+int mem_init_done;
+
 #ifndef CONFIG_MMU
 unsigned int __page_offset;
 EXPORT_SYMBOL(__page_offset);
@@ -30,7 +33,6 @@ EXPORT_SYMBOL(__page_offset);
 #else
 DEFINE_PER_CPU(struct mmu_gather, mmu_gathers);
 
-int mem_init_done;
 static int init_bootmem_done;
 #endif /* CONFIG_MMU */
 
@@ -202,9 +204,7 @@ void __init mem_init(void)
 	printk(KERN_INFO "Memory: %luk/%luk available\n",
 	       nr_free_pages() << (PAGE_SHIFT-10),
 	       num_physpages << (PAGE_SHIFT-10));
-#ifdef CONFIG_MMU
 	mem_init_done = 1;
-#endif
 }
 
 #ifndef CONFIG_MMU
@@ -216,6 +216,10 @@ int ___range_ok(unsigned long addr, unsigned long size)
 }
 EXPORT_SYMBOL(___range_ok);
 
+int page_is_ram(unsigned long pfn)
+{
+	return __range_ok(pfn, 0);
+}
 #else
 int page_is_ram(unsigned long pfn)
 {
@@ -344,6 +348,8 @@ void __init *early_get_page(void)
 	return p;
 }
 
+#endif /* CONFIG_MMU */
+
 void * __init_refok alloc_maybe_bootmem(size_t size, gfp_t mask)
 {
 	if (mem_init_done)
@@ -365,5 +371,3 @@ void * __init_refok zalloc_maybe_bootmem(size_t size, gfp_t mask)
 	}
 	return p;
 }
-
-#endif /* CONFIG_MMU */

commit e786c6ad2ba7f1f9b9cc9d75d5e7ba7d9cdc550a
Author: Michal Simek <monstr@monstr.eu>
Date:   Mon Feb 8 14:48:16 2010 +0100

    microblaze: Use generic show_mem()
    
    Remove arch-specific show_mem() in favor of the generic version.
    It is based on powerpc patch.
    bda2fa535564ace56a395d5b65c6dc81305401fa
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 6eea5544ad8b..aa6e163411b5 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -193,12 +193,6 @@ void free_initmem(void)
 			(unsigned long)(&__init_end));
 }
 
-/* FIXME from arch/powerpc/mm/mem.c*/
-void show_mem(void)
-{
-	printk(KERN_NOTICE "%s\n", __func__);
-}
-
 void __init mem_init(void)
 {
 	high_memory = (void *)__va(memory_end);

commit a84642a339235020e6dccc022de27055f1fa9340
Author: Michal Simek <monstr@monstr.eu>
Date:   Thu Jan 14 17:03:49 2010 +0100

    microblaze: Add {z,}alloc_maybe_bootmem functions
    
    I will need {z,}alloc_maybe_bootmem functions for pci patches
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index a57cedf36715..6eea5544ad8b 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -349,4 +349,27 @@ void __init *early_get_page(void)
 	}
 	return p;
 }
+
+void * __init_refok alloc_maybe_bootmem(size_t size, gfp_t mask)
+{
+	if (mem_init_done)
+		return kmalloc(size, mask);
+	else
+		return alloc_bootmem(size);
+}
+
+void * __init_refok zalloc_maybe_bootmem(size_t size, gfp_t mask)
+{
+	void *p;
+
+	if (mem_init_done)
+		p = kzalloc(size, mask);
+	else {
+		p = alloc_bootmem(size);
+		if (p)
+			memset(p, 0, size);
+	}
+	return p;
+}
+
 #endif /* CONFIG_MMU */

commit fd6ed51f4f9c01b5cea4a8be50bf49b0ae2fbd51
Author: Michal Simek <monstr@monstr.eu>
Date:   Thu Jul 23 08:23:53 2009 +0200

    microblaze: Export memory_start for modules
    
    memory_start symbol is needed by kernel modules.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index a44892e7cd5b..a57cedf36715 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -41,6 +41,7 @@ char *klimit = _end;
  * have available.
  */
 unsigned long memory_start;
+EXPORT_SYMBOL(memory_start);
 unsigned long memory_end; /* due to mm/nommu.c */
 unsigned long memory_size;
 

commit a6b49cb210f878709bdc0bddc16a853f18790d02
Merge: 2c9871de0ae8 bfc8125858d7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 24 09:01:44 2009 -0700

    Merge branch 'for-linus' of git://git.monstr.eu/linux-2.6-microblaze
    
    * 'for-linus' of git://git.monstr.eu/linux-2.6-microblaze: (24 commits)
      microblaze: Disable heartbeat/enable emaclite in defconfigs
      microblaze: Support simpleImage.dts make target
      microblaze: Fix _start symbol to physical address
      microblaze: Use LOAD_OFFSET macro to get correct LMA for all sections
      microblaze: Create the LOAD_OFFSET macro used to compute VMA vs LMA offsets
      microblaze: Copy ppc asm-compat.h for clean handling of constants in asm and C
      microblaze: Actually show KiB rather than pages in "Freeing initrd memory:"
      microblaze: Support ptrace syscall tracing.
      microblaze: Updated CPU version and FPGA family codes in PVR
      microblaze: Generate correct signal and siginfo for integer div-by-zero
      microblaze: Don't be noisy when userspace causes hardware exceptions
      microblaze: Remove ipc.h file which points to non-existing asm-generic file
      microblaze: Clear sticky FSR register after generating exception signals
      microblaze: Ensure CPU usermode is set on new userspace processes
      microblaze: Use correct kbuild variable KBUILD_CFLAGS
      microblaze: Save and restore msr in hw exception
      microblaze: Add architectural support for USB EHCI host controllers
      microblaze: Implement include/asm/syscall.h.
      microblaze: Improve checking mechanism for MSR instruction
      microblaze: Add checking mechanism for MSR instruction
      ...

commit cc013a88906bad9d2832d6316de1c7dbc1c2a794
Author: Geert Uytterhoeven <Geert.Uytterhoeven@sonycom.com>
Date:   Mon Sep 21 17:02:36 2009 -0700

    arches: drop superfluous casts in nr_free_pages() callers
    
    Commit 96177299416dbccb73b54e6b344260154a445375 ("Drop free_pages()")
    modified nr_free_pages() to return 'unsigned long' instead of 'unsigned
    int'.  This made the casts to 'unsigned long' in most callers superfluous,
    so remove them.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Geert Uytterhoeven <Geert.Uytterhoeven@sonycom.com>
    Reviewed-by: Christoph Lameter <cl@linux-foundation.org>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Acked-by: David S. Miller <davem@davemloft.net>
    Acked-by: Kyle McMartin <kyle@mcmartin.ca>
    Acked-by: WANG Cong <xiyou.wangcong@gmail.com>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Haavard Skinnemoen <hskinnemoen@atmel.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Hirokazu Takata <takata@linux-m32r.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: David Howells <dhowells@redhat.com>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Chris Zankel <zankel@tensilica.com>
    Cc: Michal Simek <monstr@monstr.eu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index f207f1a94dbc..1110784eb3f7 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -204,7 +204,7 @@ void __init mem_init(void)
 	totalram_pages += free_all_bootmem();
 
 	printk(KERN_INFO "Memory: %luk/%luk available\n",
-	       (unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
+	       nr_free_pages() << (PAGE_SHIFT-10),
 	       num_physpages << (PAGE_SHIFT-10));
 #ifdef CONFIG_MMU
 	mem_init_done = 1;

commit d6f61770f910a976050458807ff8891e78303297
Author: Lennart Sorensen <lsorense@csclub.uwaterloo.ca>
Date:   Thu Sep 17 11:47:06 2009 -0400

    microblaze: Actually show KiB rather than pages in "Freeing initrd memory:"
    
    Fix "Freeing initrd memory:" message on microblaze to show kilobytes as
    claimed rather than number of pages.
    
    Signed-off-by: Lennart Sorensen <lsorense@csclub.uwaterloo.ca>
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index f207f1a94dbc..42cbc15e015a 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -180,7 +180,8 @@ void free_initrd_mem(unsigned long start, unsigned long end)
 		totalram_pages++;
 		pages++;
 	}
-	printk(KERN_NOTICE "Freeing initrd memory: %dk freed\n", pages);
+	printk(KERN_NOTICE "Freeing initrd memory: %dk freed\n",
+					(int)(pages * (PAGE_SIZE / 1024)));
 }
 #endif
 

commit 8f37b6c9852ff79cc8472c44ea6f6485dfd58bd2
Author: Michal Simek <monstr@monstr.eu>
Date:   Tue Aug 11 12:36:12 2009 +0200

    microblaze: Use klimit instead of _end for memory init
    
    For noMMU system when you use larger rootfs image
    there is problem with using _end label because
    we increase klimit but in memory initialization
    we use still _end which is wrong. Larger mtd rootfs
    was rewritten by init_bootmem_node.
    
    MMU kernel use static initialization where klimit
    is setup to _end. There is no any other hanling
    with klimit.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 8d92c4efe9a4..f207f1a94dbc 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -130,13 +130,13 @@ void __init setup_memory(void)
 	 * (in case the address isn't page-aligned).
 	 */
 #ifndef CONFIG_MMU
-	map_size = init_bootmem_node(NODE_DATA(0), PFN_UP(TOPHYS((u32)_end)),
+	map_size = init_bootmem_node(NODE_DATA(0), PFN_UP(TOPHYS((u32)klimit)),
 					min_low_pfn, max_low_pfn);
 #else
 	map_size = init_bootmem_node(&contig_page_data,
-		PFN_UP(TOPHYS((u32)_end)), min_low_pfn, max_low_pfn);
+		PFN_UP(TOPHYS((u32)klimit)), min_low_pfn, max_low_pfn);
 #endif
-	lmb_reserve(PFN_UP(TOPHYS((u32)_end)) << PAGE_SHIFT, map_size);
+	lmb_reserve(PFN_UP(TOPHYS((u32)klimit)) << PAGE_SHIFT, map_size);
 
 	/* free bootmem is whole main memory */
 	free_bootmem(memory_start, memory_size);

commit db6e3f91efd2cf61b9965f722902199cf54adc4f
Author: Michal Simek <monstr@monstr.eu>
Date:   Mon Jul 6 08:21:09 2009 +0200

    microblaze: Fix cast warning for init.c
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index b5a701cd71e0..8d92c4efe9a4 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -80,15 +80,15 @@ void __init setup_memory(void)
 			memory_size = memory_end - memory_start;
 			PAGE_OFFSET = memory_start;
 			printk(KERN_INFO "%s: Main mem: 0x%x-0x%x, "
-				"size 0x%08x\n", __func__, memory_start,
-						memory_end, memory_size);
+				"size 0x%08x\n", __func__, (u32) memory_start,
+					(u32) memory_end, (u32) memory_size);
 			break;
 		}
 	}
 
 	if (!memory_start || !memory_end) {
 		panic("%s: Missing memory setting 0x%08x-0x%08x\n",
-			__func__, memory_start, memory_end);
+			__func__, (u32) memory_start, (u32) memory_end);
 	}
 
 	/* reservation of region where is the kernel */

commit 4dc60832f516c4ccfd1e6aa07d92cc0f6d21bacb
Author: Michal Simek <monstr@monstr.eu>
Date:   Tue May 26 16:30:12 2009 +0200

    microblaze_mmu_v2: MMU initialization
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index af789e26a7ce..b5a701cd71e0 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -23,18 +23,26 @@
 #include <asm/sections.h>
 #include <asm/tlb.h>
 
+#ifndef CONFIG_MMU
 unsigned int __page_offset;
 EXPORT_SYMBOL(__page_offset);
 
+#else
+DEFINE_PER_CPU(struct mmu_gather, mmu_gathers);
+
+int mem_init_done;
+static int init_bootmem_done;
+#endif /* CONFIG_MMU */
+
 char *klimit = _end;
 
 /*
  * Initialize the bootmem system and give it all the memory we
  * have available.
  */
-unsigned int memory_start;
-unsigned int memory_end; /* due to mm/nommu.c */
-unsigned int memory_size;
+unsigned long memory_start;
+unsigned long memory_end; /* due to mm/nommu.c */
+unsigned long memory_size;
 
 /*
  * paging_init() sets up the page tables - in fact we've already done this.
@@ -59,6 +67,7 @@ void __init setup_memory(void)
 {
 	int i;
 	unsigned long map_size;
+#ifndef CONFIG_MMU
 	u32 kernel_align_start, kernel_align_size;
 
 	/* Find main memory where is the kernel */
@@ -91,6 +100,7 @@ void __init setup_memory(void)
 		__func__, kernel_align_start, kernel_align_start
 			+ kernel_align_size, kernel_align_size);
 
+#endif
 	/*
 	 * Kernel:
 	 * start: base phys address of kernel - page align
@@ -119,9 +129,13 @@ void __init setup_memory(void)
 	 * for 4GB of memory, using 4kB pages), plus 1 page
 	 * (in case the address isn't page-aligned).
 	 */
+#ifndef CONFIG_MMU
 	map_size = init_bootmem_node(NODE_DATA(0), PFN_UP(TOPHYS((u32)_end)),
 					min_low_pfn, max_low_pfn);
-
+#else
+	map_size = init_bootmem_node(&contig_page_data,
+		PFN_UP(TOPHYS((u32)_end)), min_low_pfn, max_low_pfn);
+#endif
 	lmb_reserve(PFN_UP(TOPHYS((u32)_end)) << PAGE_SHIFT, map_size);
 
 	/* free bootmem is whole main memory */
@@ -135,6 +149,9 @@ void __init setup_memory(void)
 		reserve_bootmem(lmb.reserved.region[i].base,
 			lmb_size_bytes(&lmb.reserved, i) - 1, BOOTMEM_DEFAULT);
 	}
+#ifdef CONFIG_MMU
+	init_bootmem_done = 1;
+#endif
 	paging_init();
 }
 
@@ -189,8 +206,12 @@ void __init mem_init(void)
 	printk(KERN_INFO "Memory: %luk/%luk available\n",
 	       (unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
 	       num_physpages << (PAGE_SHIFT-10));
+#ifdef CONFIG_MMU
+	mem_init_done = 1;
+#endif
 }
 
+#ifndef CONFIG_MMU
 /* Check against bounds of physical memory */
 int ___range_ok(unsigned long addr, unsigned long size)
 {
@@ -198,3 +219,132 @@ int ___range_ok(unsigned long addr, unsigned long size)
 		((addr + size) > memory_end));
 }
 EXPORT_SYMBOL(___range_ok);
+
+#else
+int page_is_ram(unsigned long pfn)
+{
+	return pfn < max_low_pfn;
+}
+
+/*
+ * Check for command-line options that affect what MMU_init will do.
+ */
+static void mm_cmdline_setup(void)
+{
+	unsigned long maxmem = 0;
+	char *p = cmd_line;
+
+	/* Look for mem= option on command line */
+	p = strstr(cmd_line, "mem=");
+	if (p) {
+		p += 4;
+		maxmem = memparse(p, &p);
+		if (maxmem && memory_size > maxmem) {
+			memory_size = maxmem;
+			memory_end = memory_start + memory_size;
+			lmb.memory.region[0].size = memory_size;
+		}
+	}
+}
+
+/*
+ * MMU_init_hw does the chip-specific initialization of the MMU hardware.
+ */
+static void __init mmu_init_hw(void)
+{
+	/*
+	 * The Zone Protection Register (ZPR) defines how protection will
+	 * be applied to every page which is a member of a given zone. At
+	 * present, we utilize only two of the zones.
+	 * The zone index bits (of ZSEL) in the PTE are used for software
+	 * indicators, except the LSB.  For user access, zone 1 is used,
+	 * for kernel access, zone 0 is used.  We set all but zone 1
+	 * to zero, allowing only kernel access as indicated in the PTE.
+	 * For zone 1, we set a 01 binary (a value of 10 will not work)
+	 * to allow user access as indicated in the PTE.  This also allows
+	 * kernel access as indicated in the PTE.
+	 */
+	__asm__ __volatile__ ("ori r11, r0, 0x10000000;" \
+			"mts rzpr, r11;"
+			: : : "r11");
+}
+
+/*
+ * MMU_init sets up the basic memory mappings for the kernel,
+ * including both RAM and possibly some I/O regions,
+ * and sets up the page tables and the MMU hardware ready to go.
+ */
+
+/* called from head.S */
+asmlinkage void __init mmu_init(void)
+{
+	unsigned int kstart, ksize;
+
+	if (!lmb.reserved.cnt) {
+		printk(KERN_EMERG "Error memory count\n");
+		machine_restart(NULL);
+	}
+
+	if ((u32) lmb.memory.region[0].size < 0x1000000) {
+		printk(KERN_EMERG "Memory must be greater than 16MB\n");
+		machine_restart(NULL);
+	}
+	/* Find main memory where the kernel is */
+	memory_start = (u32) lmb.memory.region[0].base;
+	memory_end = (u32) lmb.memory.region[0].base +
+				(u32) lmb.memory.region[0].size;
+	memory_size = memory_end - memory_start;
+
+	mm_cmdline_setup(); /* FIXME parse args from command line - not used */
+
+	/*
+	 * Map out the kernel text/data/bss from the available physical
+	 * memory.
+	 */
+	kstart = __pa(CONFIG_KERNEL_START); /* kernel start */
+	/* kernel size */
+	ksize = PAGE_ALIGN(((u32)_end - (u32)CONFIG_KERNEL_START));
+	lmb_reserve(kstart, ksize);
+
+#if defined(CONFIG_BLK_DEV_INITRD)
+	/* Remove the init RAM disk from the available memory. */
+/*	if (initrd_start) {
+		mem_pieces_remove(&phys_avail, __pa(initrd_start),
+				  initrd_end - initrd_start, 1);
+	}*/
+#endif /* CONFIG_BLK_DEV_INITRD */
+
+	/* Initialize the MMU hardware */
+	mmu_init_hw();
+
+	/* Map in all of RAM starting at CONFIG_KERNEL_START */
+	mapin_ram();
+
+#ifdef HIGHMEM_START_BOOL
+	ioremap_base = HIGHMEM_START;
+#else
+	ioremap_base = 0xfe000000UL;	/* for now, could be 0xfffff000 */
+#endif /* CONFIG_HIGHMEM */
+	ioremap_bot = ioremap_base;
+
+	/* Initialize the context management stuff */
+	mmu_context_init();
+}
+
+/* This is only called until mem_init is done. */
+void __init *early_get_page(void)
+{
+	void *p;
+	if (init_bootmem_done) {
+		p = alloc_bootmem_pages(PAGE_SIZE);
+	} else {
+		/*
+		 * Mem start + 32MB -> here is limit
+		 * because of mem mapping from head.S
+		 */
+		p = __va(lmb_alloc_base(PAGE_SIZE, PAGE_SIZE,
+					memory_start + 0x2000000));
+	}
+	return p;
+}
+#endif /* CONFIG_MMU */

commit e93b55bfb3ead1cb4d9df7a5e0686318cfa8690c
Author: Michal Simek <monstr@monstr.eu>
Date:   Thu May 21 13:53:56 2009 +0200

    Microblaze: Remove unused variable from paging init
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 6ef5088a8d2a..af789e26a7ce 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -41,7 +41,6 @@ unsigned int memory_size;
  */
 static void __init paging_init(void)
 {
-	int i;
 	unsigned long zones_size[MAX_NR_ZONES];
 
 	/* Clean every zones */

commit 5af90438023786e27178cc542f9a775594f8a126
Author: Steve Magnani <steve@digidescorp.com>
Date:   Mon May 18 03:22:40 2009 +0200

    microblaze: Fix paging init-zone initialization
    
    This patch fix problem with bad zone initialization.
    This bug wasn't perform because Microblaze doesn't
    define CONFIG_ZONE_DMA and ZONE_NORMAL was 0 for this case
    that's why free_area_init works with correct values.
    
    Original message:
    I believe that the switch from ZONE_DMA (== 0) to ZONE_NORMAL
    broke the free area initialization.
    
    Signed-off-by: Steven J. Magnani <steve@digidescorp.com>
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 31ec053c1dd6..6ef5088a8d2a 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -44,16 +44,15 @@ static void __init paging_init(void)
 	int i;
 	unsigned long zones_size[MAX_NR_ZONES];
 
+	/* Clean every zones */
+	memset(zones_size, 0, sizeof(zones_size));
+
 	/*
 	 * old: we can DMA to/from any address.put all page into ZONE_DMA
 	 * We use only ZONE_NORMAL
 	 */
 	zones_size[ZONE_NORMAL] = max_mapnr;
 
-	/* every other zones are empty */
-	for (i = 1; i < MAX_NR_ZONES; i++)
-		zones_size[i] = 0;
-
 	free_area_init(zones_size);
 }
 

commit 5af7fa68103e7b2efb0fd9d901b1c25bad96fd21
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Fri May 1 21:48:15 2009 +0000

    microblaze: export some symbols
    
    Some device drivers require the symbols _ebss, kernel_thread,
    __page_offset or ___range_ok, so export them.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index b0c8213cd6cf..31ec053c1dd6 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -24,7 +24,7 @@
 #include <asm/tlb.h>
 
 unsigned int __page_offset;
-/* EXPORT_SYMBOL(__page_offset); */
+EXPORT_SYMBOL(__page_offset);
 
 char *klimit = _end;
 
@@ -199,3 +199,4 @@ int ___range_ok(unsigned long addr, unsigned long size)
 	return ((addr < memory_start) ||
 		((addr + size) > memory_end));
 }
+EXPORT_SYMBOL(___range_ok);

commit a95d0e1602f9f3ab54c7dbc9727bf22095705d1e
Author: Michal Simek <monstr@monstr.eu>
Date:   Fri Mar 27 14:25:29 2009 +0100

    microblaze_v8: memory inicialization, MMU, TLB
    
    Reviewed-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: John Linn <john.linn@xilinx.com>
    Acked-by: Stephen Neuendorffer <stephen.neuendorffer@xilinx.com>
    Acked-by: John Williams <john.williams@petalogix.com>
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
new file mode 100644
index 000000000000..b0c8213cd6cf
--- /dev/null
+++ b/arch/microblaze/mm/init.c
@@ -0,0 +1,201 @@
+/*
+ * Copyright (C) 2007-2008 Michal Simek <monstr@monstr.eu>
+ * Copyright (C) 2006 Atmark Techno, Inc.
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License. See the file "COPYING" in the main directory of this archive
+ * for more details.
+ */
+
+#include <linux/bootmem.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/lmb.h>
+#include <linux/mm.h> /* mem_init */
+#include <linux/initrd.h>
+#include <linux/pagemap.h>
+#include <linux/pfn.h>
+#include <linux/swap.h>
+
+#include <asm/page.h>
+#include <asm/mmu_context.h>
+#include <asm/pgalloc.h>
+#include <asm/sections.h>
+#include <asm/tlb.h>
+
+unsigned int __page_offset;
+/* EXPORT_SYMBOL(__page_offset); */
+
+char *klimit = _end;
+
+/*
+ * Initialize the bootmem system and give it all the memory we
+ * have available.
+ */
+unsigned int memory_start;
+unsigned int memory_end; /* due to mm/nommu.c */
+unsigned int memory_size;
+
+/*
+ * paging_init() sets up the page tables - in fact we've already done this.
+ */
+static void __init paging_init(void)
+{
+	int i;
+	unsigned long zones_size[MAX_NR_ZONES];
+
+	/*
+	 * old: we can DMA to/from any address.put all page into ZONE_DMA
+	 * We use only ZONE_NORMAL
+	 */
+	zones_size[ZONE_NORMAL] = max_mapnr;
+
+	/* every other zones are empty */
+	for (i = 1; i < MAX_NR_ZONES; i++)
+		zones_size[i] = 0;
+
+	free_area_init(zones_size);
+}
+
+void __init setup_memory(void)
+{
+	int i;
+	unsigned long map_size;
+	u32 kernel_align_start, kernel_align_size;
+
+	/* Find main memory where is the kernel */
+	for (i = 0; i < lmb.memory.cnt; i++) {
+		memory_start = (u32) lmb.memory.region[i].base;
+		memory_end = (u32) lmb.memory.region[i].base
+				+ (u32) lmb.memory.region[i].size;
+		if ((memory_start <= (u32)_text) &&
+					((u32)_text <= memory_end)) {
+			memory_size = memory_end - memory_start;
+			PAGE_OFFSET = memory_start;
+			printk(KERN_INFO "%s: Main mem: 0x%x-0x%x, "
+				"size 0x%08x\n", __func__, memory_start,
+						memory_end, memory_size);
+			break;
+		}
+	}
+
+	if (!memory_start || !memory_end) {
+		panic("%s: Missing memory setting 0x%08x-0x%08x\n",
+			__func__, memory_start, memory_end);
+	}
+
+	/* reservation of region where is the kernel */
+	kernel_align_start = PAGE_DOWN((u32)_text);
+	/* ALIGN can be remove because _end in vmlinux.lds.S is align */
+	kernel_align_size = PAGE_UP((u32)klimit) - kernel_align_start;
+	lmb_reserve(kernel_align_start, kernel_align_size);
+	printk(KERN_INFO "%s: kernel addr=0x%08x-0x%08x size=0x%08x\n",
+		__func__, kernel_align_start, kernel_align_start
+			+ kernel_align_size, kernel_align_size);
+
+	/*
+	 * Kernel:
+	 * start: base phys address of kernel - page align
+	 * end: base phys address of kernel - page align
+	 *
+	 * min_low_pfn - the first page (mm/bootmem.c - node_boot_start)
+	 * max_low_pfn
+	 * max_mapnr - the first unused page (mm/bootmem.c - node_low_pfn)
+	 * num_physpages - number of all pages
+	 */
+
+	/* memory start is from the kernel end (aligned) to higher addr */
+	min_low_pfn = memory_start >> PAGE_SHIFT; /* minimum for allocation */
+	/* RAM is assumed contiguous */
+	num_physpages = max_mapnr = memory_size >> PAGE_SHIFT;
+	max_pfn = max_low_pfn = memory_end >> PAGE_SHIFT;
+
+	printk(KERN_INFO "%s: max_mapnr: %#lx\n", __func__, max_mapnr);
+	printk(KERN_INFO "%s: min_low_pfn: %#lx\n", __func__, min_low_pfn);
+	printk(KERN_INFO "%s: max_low_pfn: %#lx\n", __func__, max_low_pfn);
+
+	/*
+	 * Find an area to use for the bootmem bitmap.
+	 * We look for the first area which is at least
+	 * 128kB in length (128kB is enough for a bitmap
+	 * for 4GB of memory, using 4kB pages), plus 1 page
+	 * (in case the address isn't page-aligned).
+	 */
+	map_size = init_bootmem_node(NODE_DATA(0), PFN_UP(TOPHYS((u32)_end)),
+					min_low_pfn, max_low_pfn);
+
+	lmb_reserve(PFN_UP(TOPHYS((u32)_end)) << PAGE_SHIFT, map_size);
+
+	/* free bootmem is whole main memory */
+	free_bootmem(memory_start, memory_size);
+
+	/* reserve allocate blocks */
+	for (i = 0; i < lmb.reserved.cnt; i++) {
+		pr_debug("reserved %d - 0x%08x-0x%08x\n", i,
+			(u32) lmb.reserved.region[i].base,
+			(u32) lmb_size_bytes(&lmb.reserved, i));
+		reserve_bootmem(lmb.reserved.region[i].base,
+			lmb_size_bytes(&lmb.reserved, i) - 1, BOOTMEM_DEFAULT);
+	}
+	paging_init();
+}
+
+void free_init_pages(char *what, unsigned long begin, unsigned long end)
+{
+	unsigned long addr;
+
+	for (addr = begin; addr < end; addr += PAGE_SIZE) {
+		ClearPageReserved(virt_to_page(addr));
+		init_page_count(virt_to_page(addr));
+		memset((void *)addr, 0xcc, PAGE_SIZE);
+		free_page(addr);
+		totalram_pages++;
+	}
+	printk(KERN_INFO "Freeing %s: %ldk freed\n", what, (end - begin) >> 10);
+}
+
+#ifdef CONFIG_BLK_DEV_INITRD
+void free_initrd_mem(unsigned long start, unsigned long end)
+{
+	int pages = 0;
+	for (; start < end; start += PAGE_SIZE) {
+		ClearPageReserved(virt_to_page(start));
+		init_page_count(virt_to_page(start));
+		free_page(start);
+		totalram_pages++;
+		pages++;
+	}
+	printk(KERN_NOTICE "Freeing initrd memory: %dk freed\n", pages);
+}
+#endif
+
+void free_initmem(void)
+{
+	free_init_pages("unused kernel memory",
+			(unsigned long)(&__init_begin),
+			(unsigned long)(&__init_end));
+}
+
+/* FIXME from arch/powerpc/mm/mem.c*/
+void show_mem(void)
+{
+	printk(KERN_NOTICE "%s\n", __func__);
+}
+
+void __init mem_init(void)
+{
+	high_memory = (void *)__va(memory_end);
+	/* this will put all memory onto the freelists */
+	totalram_pages += free_all_bootmem();
+
+	printk(KERN_INFO "Memory: %luk/%luk available\n",
+	       (unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
+	       num_physpages << (PAGE_SHIFT-10));
+}
+
+/* Check against bounds of physical memory */
+int ___range_ok(unsigned long addr, unsigned long size)
+{
+	return ((addr < memory_start) ||
+		((addr + size) > memory_end));
+}
