commit 061d2c1d593076424c910cb1b64ecdb5c9a6923f
Author: Shubhrajyoti Datta <shubhrajyoti.datta@xilinx.com>
Date:   Sat Jan 11 18:44:34 2020 +0530

    microblaze: Prevent the overflow of the start
    
    In case the start + cache size is more than the max int the
    start overflows.
    Prevent the same.
    
    Signed-off-by: Shubhrajyoti Datta <shubhrajyoti.datta@xilinx.com>
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/microblaze/kernel/cpu/cache.c b/arch/microblaze/kernel/cpu/cache.c
index 0bde47e4fa69..dcba53803fa5 100644
--- a/arch/microblaze/kernel/cpu/cache.c
+++ b/arch/microblaze/kernel/cpu/cache.c
@@ -92,7 +92,8 @@ static inline void __disable_dcache_nomsr(void)
 #define CACHE_LOOP_LIMITS(start, end, cache_line_length, cache_size)	\
 do {									\
 	int align = ~(cache_line_length - 1);				\
-	end = min(start + cache_size, end);				\
+	if (start <  UINT_MAX - cache_size)				\
+		end = min(start + cache_size, end);			\
 	start &= align;							\
 } while (0)
 

commit 2558cd8cab793e9c8c3b17bdf06552bfb98d49e5
Author: Michal Simek <michal.simek@xilinx.com>
Date:   Thu Dec 18 15:38:00 2014 +0100

    microblaze: Use unsigned type for limit comparison in cache.c
    
    The patch removes warnings:
    arch/microblaze/kernel/cpu/cache.c:146:14: warning: comparison of
    unsigned expression < 0 is always false [-Wtype-limits]
    
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/microblaze/kernel/cpu/cache.c b/arch/microblaze/kernel/cpu/cache.c
index a6e44410672d..0bde47e4fa69 100644
--- a/arch/microblaze/kernel/cpu/cache.c
+++ b/arch/microblaze/kernel/cpu/cache.c
@@ -140,10 +140,10 @@ do {									\
 /* It is used only first parameter for OP - for wic, wdc */
 #define CACHE_RANGE_LOOP_1(start, end, line_length, op)			\
 do {									\
-	int volatile temp = 0;						\
-	int align = ~(line_length - 1);					\
+	unsigned int volatile temp = 0;						\
+	unsigned int align = ~(line_length - 1);					\
 	end = ((end & align) == end) ? end - line_length : end & align;	\
-	WARN_ON(end - start < 0);					\
+	WARN_ON(end < start);					\
 									\
 	__asm__ __volatile__ (" 1:	" #op "	%1, r0;"		\
 					"cmpu	%0, %1, %2;"		\

commit 972be324fe0adaa67717407510aa067a4ae53d2d
Author: Michal Simek <michal.simek@xilinx.com>
Date:   Tue May 14 09:06:17 2013 +0200

    microblaze: Initialize temp variable to remove compilation warning
    
    Compilation warning:
    arch/microblaze/kernel/cpu/cache.c:148:2: warning:
     'temp' is used uninitialized in this function [-Wuninitialized]
    
    Signed-off-by: Michal Simek <michal.simek@xilinx.com>

diff --git a/arch/microblaze/kernel/cpu/cache.c b/arch/microblaze/kernel/cpu/cache.c
index 4254514b4c8c..a6e44410672d 100644
--- a/arch/microblaze/kernel/cpu/cache.c
+++ b/arch/microblaze/kernel/cpu/cache.c
@@ -140,7 +140,7 @@ do {									\
 /* It is used only first parameter for OP - for wic, wdc */
 #define CACHE_RANGE_LOOP_1(start, end, line_length, op)			\
 do {									\
-	int volatile temp;						\
+	int volatile temp = 0;						\
 	int align = ~(line_length - 1);					\
 	end = ((end & align) == end) ? end - line_length : end & align;	\
 	WARN_ON(end - start < 0);					\

commit 6bd55f0bbaebb79b39e147aa864401fd0c94db82
Author: Michal Simek <monstr@monstr.eu>
Date:   Thu Dec 27 10:40:38 2012 +0100

    microblaze: Fix coding style issues
    
    Fix coding style issues reported by checkpatch.pl.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/kernel/cpu/cache.c b/arch/microblaze/kernel/cpu/cache.c
index 4b7d8a3f4aef..4254514b4c8c 100644
--- a/arch/microblaze/kernel/cpu/cache.c
+++ b/arch/microblaze/kernel/cpu/cache.c
@@ -17,82 +17,70 @@
 
 static inline void __enable_icache_msr(void)
 {
-	__asm__ __volatile__ ("	msrset	r0, %0;		\
-				nop; "			\
+	__asm__ __volatile__ ("	 msrset	r0, %0;"	\
+				"nop;"			\
 			: : "i" (MSR_ICE) : "memory");
 }
 
 static inline void __disable_icache_msr(void)
 {
-	__asm__ __volatile__ ("	msrclr	r0, %0;		\
-				nop; "			\
+	__asm__ __volatile__ ("	 msrclr	r0, %0;"	\
+				"nop;"			\
 			: : "i" (MSR_ICE) : "memory");
 }
 
 static inline void __enable_dcache_msr(void)
 {
-	__asm__ __volatile__ ("	msrset	r0, %0;		\
-				nop; "			\
-				:			\
-				: "i" (MSR_DCE)		\
-				: "memory");
+	__asm__ __volatile__ ("	 msrset	r0, %0;"	\
+				"nop;"			\
+			: : "i" (MSR_DCE) : "memory");
 }
 
 static inline void __disable_dcache_msr(void)
 {
-	__asm__ __volatile__ ("	msrclr	r0, %0;		\
-				nop; "			\
-				:			\
-				: "i" (MSR_DCE)		\
-				: "memory");
+	__asm__ __volatile__ ("	 msrclr	r0, %0;"	\
+				"nop; "			\
+			: : "i" (MSR_DCE) : "memory");
 }
 
 static inline void __enable_icache_nomsr(void)
 {
-	__asm__ __volatile__ ("	mfs	r12, rmsr;	\
-				nop;			\
-				ori	r12, r12, %0;	\
-				mts	rmsr, r12;	\
-				nop; "			\
-				:			\
-				: "i" (MSR_ICE)		\
-				: "memory", "r12");
+	__asm__ __volatile__ ("	 mfs	r12, rmsr;"	\
+				"nop;"			\
+				"ori	r12, r12, %0;"	\
+				"mts	rmsr, r12;"	\
+				"nop;"			\
+			: : "i" (MSR_ICE) : "memory", "r12");
 }
 
 static inline void __disable_icache_nomsr(void)
 {
-	__asm__ __volatile__ ("	mfs	r12, rmsr;	\
-				nop;			\
-				andi	r12, r12, ~%0;	\
-				mts	rmsr, r12;	\
-				nop; "			\
-				:			\
-				: "i" (MSR_ICE)		\
-				: "memory", "r12");
+	__asm__ __volatile__ ("	 mfs	r12, rmsr;"	\
+				"nop;"			\
+				"andi	r12, r12, ~%0;"	\
+				"mts	rmsr, r12;"	\
+				"nop;"			\
+			: : "i" (MSR_ICE) : "memory", "r12");
 }
 
 static inline void __enable_dcache_nomsr(void)
 {
-	__asm__ __volatile__ ("	mfs	r12, rmsr;	\
-				nop;			\
-				ori	r12, r12, %0;	\
-				mts	rmsr, r12;	\
-				nop; "			\
-				:			\
-				: "i" (MSR_DCE)		\
-				: "memory", "r12");
+	__asm__ __volatile__ ("	 mfs	r12, rmsr;"	\
+				"nop;"			\
+				"ori	r12, r12, %0;"	\
+				"mts	rmsr, r12;"	\
+				"nop;"			\
+			: : "i" (MSR_DCE) : "memory", "r12");
 }
 
 static inline void __disable_dcache_nomsr(void)
 {
-	__asm__ __volatile__ ("	mfs	r12, rmsr;	\
-				nop;			\
-				andi	r12, r12, ~%0;	\
-				mts	rmsr, r12;	\
-				nop; "			\
-				:			\
-				: "i" (MSR_DCE)		\
-				: "memory", "r12");
+	__asm__ __volatile__ ("	 mfs	r12, rmsr;"	\
+				"nop;"			\
+				"andi	r12, r12, ~%0;"	\
+				"mts	rmsr, r12;"	\
+				"nop;"			\
+			: : "i" (MSR_DCE) : "memory", "r12");
 }
 
 
@@ -106,7 +94,7 @@ do {									\
 	int align = ~(cache_line_length - 1);				\
 	end = min(start + cache_size, end);				\
 	start &= align;							\
-} while (0);
+} while (0)
 
 /*
  * Helper macro to loop over the specified cache_size/line_length and
@@ -118,12 +106,12 @@ do {									\
 	int step = -line_length;					\
 	WARN_ON(step >= 0);						\
 									\
-	__asm__ __volatile__ (" 1:      " #op " %0, r0;			\
-					bgtid   %0, 1b;			\
-					addk    %0, %0, %1;		\
-					" : : "r" (len), "r" (step)	\
+	__asm__ __volatile__ (" 1:      " #op " %0, r0;"		\
+					"bgtid   %0, 1b;"		\
+					"addk    %0, %0, %1;"		\
+					: : "r" (len), "r" (step)	\
 					: "memory");			\
-} while (0);
+} while (0)
 
 /* Used for wdc.flush/clear which can use rB for offset which is not possible
  * to use for simple wdc or wic.
@@ -142,12 +130,12 @@ do {									\
 	count = end - start;						\
 	WARN_ON(count < 0);						\
 									\
-	__asm__ __volatile__ (" 1:	" #op "	%0, %1;			\
-					bgtid	%1, 1b;			\
-					addk	%1, %1, %2;		\
-					" : : "r" (start), "r" (count),	\
+	__asm__ __volatile__ (" 1:	" #op "	%0, %1;"		\
+					"bgtid	%1, 1b;"		\
+					"addk	%1, %1, %2;"		\
+					: : "r" (start), "r" (count),	\
 					"r" (step) : "memory");		\
-} while (0);
+} while (0)
 
 /* It is used only first parameter for OP - for wic, wdc */
 #define CACHE_RANGE_LOOP_1(start, end, line_length, op)			\
@@ -157,13 +145,13 @@ do {									\
 	end = ((end & align) == end) ? end - line_length : end & align;	\
 	WARN_ON(end - start < 0);					\
 									\
-	__asm__ __volatile__ (" 1:	" #op "	%1, r0;			\
-					cmpu	%0, %1, %2;		\
-					bgtid	%0, 1b;			\
-					addk	%1, %1, %3;		\
-				" : : "r" (temp), "r" (start), "r" (end),\
+	__asm__ __volatile__ (" 1:	" #op "	%1, r0;"		\
+					"cmpu	%0, %1, %2;"		\
+					"bgtid	%0, 1b;"		\
+					"addk	%1, %1, %3;"		\
+				: : "r" (temp), "r" (start), "r" (end),	\
 					"r" (line_length) : "memory");	\
-} while (0);
+} while (0)
 
 #define ASM_LOOP
 
@@ -352,7 +340,7 @@ static void __invalidate_dcache_all_noirq_wt(void)
 #endif
 	pr_debug("%s\n", __func__);
 #ifdef ASM_LOOP
-	CACHE_ALL_LOOP(cpuinfo.dcache_size, cpuinfo.dcache_line_length, wdc)
+	CACHE_ALL_LOOP(cpuinfo.dcache_size, cpuinfo.dcache_line_length, wdc);
 #else
 	for (i = 0; i < cpuinfo.dcache_size;
 		 i += cpuinfo.dcache_line_length)
@@ -361,7 +349,8 @@ static void __invalidate_dcache_all_noirq_wt(void)
 #endif
 }
 
-/* FIXME It is blindly invalidation as is expected
+/*
+ * FIXME It is blindly invalidation as is expected
  * but can't be called on noMMU in microblaze_cache_init below
  *
  * MS: noMMU kernel won't boot if simple wdc is used
@@ -375,7 +364,7 @@ static void __invalidate_dcache_all_wb(void)
 	pr_debug("%s\n", __func__);
 #ifdef ASM_LOOP
 	CACHE_ALL_LOOP(cpuinfo.dcache_size, cpuinfo.dcache_line_length,
-					wdc)
+					wdc);
 #else
 	for (i = 0; i < cpuinfo.dcache_size;
 		 i += cpuinfo.dcache_line_length)
@@ -616,49 +605,48 @@ static const struct scache wt_nomsr_noirq = {
 #define CPUVER_7_20_A	0x0c
 #define CPUVER_7_20_D	0x0f
 
-#define INFO(s)	printk(KERN_INFO "cache: " s "\n");
-
 void microblaze_cache_init(void)
 {
 	if (cpuinfo.use_instr & PVR2_USE_MSR_INSTR) {
 		if (cpuinfo.dcache_wb) {
-			INFO("wb_msr");
+			pr_info("wb_msr\n");
 			mbc = (struct scache *)&wb_msr;
 			if (cpuinfo.ver_code <= CPUVER_7_20_D) {
 				/* MS: problem with signal handling - hw bug */
-				INFO("WB won't work properly");
+				pr_info("WB won't work properly\n");
 			}
 		} else {
 			if (cpuinfo.ver_code >= CPUVER_7_20_A) {
-				INFO("wt_msr_noirq");
+				pr_info("wt_msr_noirq\n");
 				mbc = (struct scache *)&wt_msr_noirq;
 			} else {
-				INFO("wt_msr");
+				pr_info("wt_msr\n");
 				mbc = (struct scache *)&wt_msr;
 			}
 		}
 	} else {
 		if (cpuinfo.dcache_wb) {
-			INFO("wb_nomsr");
+			pr_info("wb_nomsr\n");
 			mbc = (struct scache *)&wb_nomsr;
 			if (cpuinfo.ver_code <= CPUVER_7_20_D) {
 				/* MS: problem with signal handling - hw bug */
-				INFO("WB won't work properly");
+				pr_info("WB won't work properly\n");
 			}
 		} else {
 			if (cpuinfo.ver_code >= CPUVER_7_20_A) {
-				INFO("wt_nomsr_noirq");
+				pr_info("wt_nomsr_noirq\n");
 				mbc = (struct scache *)&wt_nomsr_noirq;
 			} else {
-				INFO("wt_nomsr");
+				pr_info("wt_nomsr\n");
 				mbc = (struct scache *)&wt_nomsr;
 			}
 		}
 	}
-/* FIXME Invalidation is done in U-BOOT
- * WT cache: Data is already written to main memory
- * WB cache: Discard data on noMMU which caused that kernel doesn't boot
- */
+	/*
+	 * FIXME Invalidation is done in U-BOOT
+	 * WT cache: Data is already written to main memory
+	 * WB cache: Discard data on noMMU which caused that kernel doesn't boot
+	 */
 	/* invalidate_dcache(); */
 	enable_dcache();
 

commit 25985edcedea6396277003854657b5f3cb31a628
Author: Lucas De Marchi <lucas.demarchi@profusion.mobi>
Date:   Wed Mar 30 22:57:33 2011 -0300

    Fix common misspellings
    
    Fixes generated by 'codespell' and manually reviewed.
    
    Signed-off-by: Lucas De Marchi <lucas.demarchi@profusion.mobi>

diff --git a/arch/microblaze/kernel/cpu/cache.c b/arch/microblaze/kernel/cpu/cache.c
index cf0afd90a2c0..4b7d8a3f4aef 100644
--- a/arch/microblaze/kernel/cpu/cache.c
+++ b/arch/microblaze/kernel/cpu/cache.c
@@ -129,7 +129,7 @@ do {									\
  * to use for simple wdc or wic.
  *
  * start address is cache aligned
- * end address is not aligned, if end is aligned then I have to substract
+ * end address is not aligned, if end is aligned then I have to subtract
  * cacheline length because I can't flush/invalidate the next cacheline.
  * If is not, I align it because I will flush/invalidate whole line.
  */

commit 954e8b9599d64a959fe81cfaa8b0e0ee6387271c
Author: Michal Simek <monstr@monstr.eu>
Date:   Mon Feb 7 12:21:42 2011 +0100

    microblaze: Fix sparse warnings - cache.c
    
    Warning log:
    CHECK   arch/microblaze/kernel/cpu/cache.c
    arch/microblaze/kernel/cpu/cache.c:522:21: warning: symbol 'wb_msr' was not declared. Should it be static?
    arch/microblaze/kernel/cpu/cache.c:538:21: warning: symbol 'wb_nomsr' was not declared. Should it be static?
    arch/microblaze/kernel/cpu/cache.c:554:21: warning: symbol 'wt_msr' was not declared. Should it be static?
    arch/microblaze/kernel/cpu/cache.c:569:21: warning: symbol 'wt_nomsr' was not declared. Should it be static?
    arch/microblaze/kernel/cpu/cache.c:585:21: warning: symbol 'wt_msr_noirq' was not declared. Should it be static?
    arch/microblaze/kernel/cpu/cache.c:600:21: warning: symbol 'wt_nomsr_noirq' was not declared. Should it be static?
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/kernel/cpu/cache.c b/arch/microblaze/kernel/cpu/cache.c
index 8cf0828a83ad..cf0afd90a2c0 100644
--- a/arch/microblaze/kernel/cpu/cache.c
+++ b/arch/microblaze/kernel/cpu/cache.c
@@ -519,7 +519,7 @@ static void __flush_dcache_range_wb(unsigned long start, unsigned long end)
 struct scache *mbc;
 
 /* new wb cache model */
-const struct scache wb_msr = {
+static const struct scache wb_msr = {
 	.ie = __enable_icache_msr,
 	.id = __disable_icache_msr,
 	.ifl = __flush_icache_all_noirq,
@@ -535,7 +535,7 @@ const struct scache wb_msr = {
 };
 
 /* There is only difference in ie, id, de, dd functions */
-const struct scache wb_nomsr = {
+static const struct scache wb_nomsr = {
 	.ie = __enable_icache_nomsr,
 	.id = __disable_icache_nomsr,
 	.ifl = __flush_icache_all_noirq,
@@ -551,7 +551,7 @@ const struct scache wb_nomsr = {
 };
 
 /* Old wt cache model with disabling irq and turn off cache */
-const struct scache wt_msr = {
+static const struct scache wt_msr = {
 	.ie = __enable_icache_msr,
 	.id = __disable_icache_msr,
 	.ifl = __flush_icache_all_msr_irq,
@@ -566,7 +566,7 @@ const struct scache wt_msr = {
 	.dinr = __invalidate_dcache_range_msr_irq_wt,
 };
 
-const struct scache wt_nomsr = {
+static const struct scache wt_nomsr = {
 	.ie = __enable_icache_nomsr,
 	.id = __disable_icache_nomsr,
 	.ifl = __flush_icache_all_nomsr_irq,
@@ -582,7 +582,7 @@ const struct scache wt_nomsr = {
 };
 
 /* New wt cache model for newer Microblaze versions */
-const struct scache wt_msr_noirq = {
+static const struct scache wt_msr_noirq = {
 	.ie = __enable_icache_msr,
 	.id = __disable_icache_msr,
 	.ifl = __flush_icache_all_noirq,
@@ -597,7 +597,7 @@ const struct scache wt_msr_noirq = {
 	.dinr = __invalidate_dcache_range_nomsr_wt,
 };
 
-const struct scache wt_nomsr_noirq = {
+static const struct scache wt_nomsr_noirq = {
 	.ie = __enable_icache_nomsr,
 	.id = __disable_icache_nomsr,
 	.ifl = __flush_icache_all_noirq,

commit b9dc9e7781f1c3e85e0d1b8044021fa8974422b1
Author: Michal Simek <monstr@monstr.eu>
Date:   Mon May 31 21:16:30 2010 +0200

    microblaze: Label MB 7.20.d as broken with WB cache
    
    MB version 7.20.d contains fault which is related with WB that's why
    error message will be shown.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/kernel/cpu/cache.c b/arch/microblaze/kernel/cpu/cache.c
index 109876e8d643..8cf0828a83ad 100644
--- a/arch/microblaze/kernel/cpu/cache.c
+++ b/arch/microblaze/kernel/cpu/cache.c
@@ -624,7 +624,7 @@ void microblaze_cache_init(void)
 		if (cpuinfo.dcache_wb) {
 			INFO("wb_msr");
 			mbc = (struct scache *)&wb_msr;
-			if (cpuinfo.ver_code < CPUVER_7_20_D) {
+			if (cpuinfo.ver_code <= CPUVER_7_20_D) {
 				/* MS: problem with signal handling - hw bug */
 				INFO("WB won't work properly");
 			}
@@ -641,7 +641,7 @@ void microblaze_cache_init(void)
 		if (cpuinfo.dcache_wb) {
 			INFO("wb_nomsr");
 			mbc = (struct scache *)&wb_nomsr;
-			if (cpuinfo.ver_code < CPUVER_7_20_D) {
+			if (cpuinfo.ver_code <= CPUVER_7_20_D) {
 				/* MS: problem with signal handling - hw bug */
 				INFO("WB won't work properly");
 			}

commit ddfbc935eae68294834dc29998f93147a5422a0d
Author: Michal Simek <monstr@monstr.eu>
Date:   Thu May 13 10:55:47 2010 +0200

    microblaze: Remove compilation warnings in cache macro
    
    CC      arch/microblaze/kernel/cpu/cache.o
    arch/microblaze/kernel/cpu/cache.c: In function '__invalidate_dcache_range_wb':
    arch/microblaze/kernel/cpu/cache.c:398: warning: ISO C90 forbids mixed declarations and code
    arch/microblaze/kernel/cpu/cache.c: In function '__flush_dcache_range_wb':
    arch/microblaze/kernel/cpu/cache.c:509: warning: ISO C90 forbids mixed declara
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/kernel/cpu/cache.c b/arch/microblaze/kernel/cpu/cache.c
index 21c3a92394de..109876e8d643 100644
--- a/arch/microblaze/kernel/cpu/cache.c
+++ b/arch/microblaze/kernel/cpu/cache.c
@@ -137,8 +137,9 @@ do {									\
 do {									\
 	int step = -line_length;					\
 	int align = ~(line_length - 1);					\
+	int count;							\
 	end = ((end & align) == end) ? end - line_length : end & align;	\
-	int count = end - start;					\
+	count = end - start;						\
 	WARN_ON(count < 0);						\
 									\
 	__asm__ __volatile__ (" 1:	" #op "	%0, %1;			\

commit 3274c5707c22221574b396d140d0db3480a2027a
Author: Michal Simek <monstr@monstr.eu>
Date:   Mon Apr 26 08:54:13 2010 +0200

    microblaze: Optimize CACHE_LOOP_LIMITS and CACHE_RANGE_LOOP macros
    
    1. Remove CACHE_ALL_LOOP2 macro because it is identical to CACHE_ALL_LOOP
    2. Change BUG_ON to WARN_ON
    3. Remove end aligned from CACHE_LOOP_LIMITS.
    C implementation do not need aligned end address and ASM code do aligned
    in their macros
    4. ASM optimized  CACHE_RANGE_LOOP_1/2 macros needs to get aligned end address.
    Because end address is compound from start + size, end address is the first address
    which is exclude.
    
    Here is the corresponding code which describe it.
    +       int align = ~(line_length - 1);
    +       end = ((end & align) == end) ? end - line_length : end & align;
    
    a) end is aligned:
    it is necessary to subtruct line length because we don't want to work with
    next cacheline
    b) end address is not aligned:
    Just align it to be ready for ASM code.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/kernel/cpu/cache.c b/arch/microblaze/kernel/cpu/cache.c
index 19dae71dbaaf..21c3a92394de 100644
--- a/arch/microblaze/kernel/cpu/cache.c
+++ b/arch/microblaze/kernel/cpu/cache.c
@@ -96,13 +96,16 @@ static inline void __disable_dcache_nomsr(void)
 }
 
 
-/* Helper macro for computing the limits of cache range loops */
+/* Helper macro for computing the limits of cache range loops
+ *
+ * End address can be unaligned which is OK for C implementation.
+ * ASM implementation align it in ASM macros
+ */
 #define CACHE_LOOP_LIMITS(start, end, cache_line_length, cache_size)	\
 do {									\
 	int align = ~(cache_line_length - 1);				\
 	end = min(start + cache_size, end);				\
 	start &= align;							\
-	end = ((end & align) + cache_line_length);			\
 } while (0);
 
 /*
@@ -111,9 +114,9 @@ do {									\
  */
 #define CACHE_ALL_LOOP(cache_size, line_length, op)			\
 do {									\
-	unsigned int len = cache_size;					\
+	unsigned int len = cache_size - line_length;			\
 	int step = -line_length;					\
-	BUG_ON(step >= 0);						\
+	WARN_ON(step >= 0);						\
 									\
 	__asm__ __volatile__ (" 1:      " #op " %0, r0;			\
 					bgtid   %0, 1b;			\
@@ -122,26 +125,21 @@ do {									\
 					: "memory");			\
 } while (0);
 
-
-#define CACHE_ALL_LOOP2(cache_size, line_length, op)			\
-do {									\
-	unsigned int len = cache_size;					\
-	int step = -line_length;					\
-	BUG_ON(step >= 0);						\
-									\
-	__asm__ __volatile__ (" 1:	" #op "	r0, %0;			\
-					bgtid	%0, 1b;			\
-					addk	%0, %0, %1;		\
-					" : : "r" (len), "r" (step)	\
-					: "memory");			\
-} while (0);
-
-/* for wdc.flush/clear */
+/* Used for wdc.flush/clear which can use rB for offset which is not possible
+ * to use for simple wdc or wic.
+ *
+ * start address is cache aligned
+ * end address is not aligned, if end is aligned then I have to substract
+ * cacheline length because I can't flush/invalidate the next cacheline.
+ * If is not, I align it because I will flush/invalidate whole line.
+ */
 #define CACHE_RANGE_LOOP_2(start, end, line_length, op)			\
 do {									\
 	int step = -line_length;					\
+	int align = ~(line_length - 1);					\
+	end = ((end & align) == end) ? end - line_length : end & align;	\
 	int count = end - start;					\
-	BUG_ON(count <= 0);						\
+	WARN_ON(count < 0);						\
 									\
 	__asm__ __volatile__ (" 1:	" #op "	%0, %1;			\
 					bgtid	%1, 1b;			\
@@ -154,7 +152,9 @@ do {									\
 #define CACHE_RANGE_LOOP_1(start, end, line_length, op)			\
 do {									\
 	int volatile temp;						\
-	BUG_ON(end - start <= 0);					\
+	int align = ~(line_length - 1);					\
+	end = ((end & align) == end) ? end - line_length : end & align;	\
+	WARN_ON(end - start < 0);					\
 									\
 	__asm__ __volatile__ (" 1:	" #op "	%1, r0;			\
 					cmpu	%0, %1, %2;		\
@@ -360,8 +360,12 @@ static void __invalidate_dcache_all_noirq_wt(void)
 #endif
 }
 
-/* FIXME this is weird - should be only wdc but not work
- * MS: I am getting bus errors and other weird things */
+/* FIXME It is blindly invalidation as is expected
+ * but can't be called on noMMU in microblaze_cache_init below
+ *
+ * MS: noMMU kernel won't boot if simple wdc is used
+ * The reason should be that there are discared data which kernel needs
+ */
 static void __invalidate_dcache_all_wb(void)
 {
 #ifndef ASM_LOOP
@@ -369,12 +373,12 @@ static void __invalidate_dcache_all_wb(void)
 #endif
 	pr_debug("%s\n", __func__);
 #ifdef ASM_LOOP
-	CACHE_ALL_LOOP2(cpuinfo.dcache_size, cpuinfo.dcache_line_length,
-					wdc.clear)
+	CACHE_ALL_LOOP(cpuinfo.dcache_size, cpuinfo.dcache_line_length,
+					wdc)
 #else
 	for (i = 0; i < cpuinfo.dcache_size;
 		 i += cpuinfo.dcache_line_length)
-			__asm__ __volatile__ ("wdc.clear	%0, r0;" \
+			__asm__ __volatile__ ("wdc	%0, r0;" \
 					: : "r" (i));
 #endif
 }
@@ -650,7 +654,11 @@ void microblaze_cache_init(void)
 			}
 		}
 	}
-	invalidate_dcache();
+/* FIXME Invalidation is done in U-BOOT
+ * WT cache: Data is already written to main memory
+ * WB cache: Discard data on noMMU which caused that kernel doesn't boot
+ */
+	/* invalidate_dcache(); */
 	enable_dcache();
 
 	invalidate_icache();

commit c17e1a1cedb723d48d4822cae1af1c010b608b5c
Author: Michal Simek <monstr@monstr.eu>
Date:   Fri Apr 23 11:38:43 2010 +0200

    microblaze: Fix typo fault in cache code
    
    Copy & paste error.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/kernel/cpu/cache.c b/arch/microblaze/kernel/cpu/cache.c
index f04d8a86dead..19dae71dbaaf 100644
--- a/arch/microblaze/kernel/cpu/cache.c
+++ b/arch/microblaze/kernel/cpu/cache.c
@@ -393,7 +393,7 @@ static void __invalidate_dcache_range_wb(unsigned long start,
 #ifdef ASM_LOOP
 	CACHE_RANGE_LOOP_2(start, end, cpuinfo.dcache_line_length, wdc.clear);
 #else
-	for (i = start; i < end; i += cpuinfo.icache_line_length)
+	for (i = start; i < end; i += cpuinfo.dcache_line_length)
 		__asm__ __volatile__ ("wdc.clear	%0, r0;"	\
 				: : "r" (i));
 #endif
@@ -413,7 +413,7 @@ static void __invalidate_dcache_range_nomsr_wt(unsigned long start,
 #ifdef ASM_LOOP
 	CACHE_RANGE_LOOP_1(start, end, cpuinfo.dcache_line_length, wdc);
 #else
-	for (i = start; i < end; i += cpuinfo.icache_line_length)
+	for (i = start; i < end; i += cpuinfo.dcache_line_length)
 		__asm__ __volatile__ ("wdc	%0, r0;"	\
 				: : "r" (i));
 #endif
@@ -437,7 +437,7 @@ static void __invalidate_dcache_range_msr_irq_wt(unsigned long start,
 #ifdef ASM_LOOP
 	CACHE_RANGE_LOOP_1(start, end, cpuinfo.dcache_line_length, wdc);
 #else
-	for (i = start; i < end; i += cpuinfo.icache_line_length)
+	for (i = start; i < end; i += cpuinfo.dcache_line_length)
 		__asm__ __volatile__ ("wdc	%0, r0;"	\
 				: : "r" (i));
 #endif
@@ -465,7 +465,7 @@ static void __invalidate_dcache_range_nomsr_irq(unsigned long start,
 #ifdef ASM_LOOP
 	CACHE_RANGE_LOOP_1(start, end, cpuinfo.dcache_line_length, wdc);
 #else
-	for (i = start; i < end; i += cpuinfo.icache_line_length)
+	for (i = start; i < end; i += cpuinfo.dcache_line_length)
 		__asm__ __volatile__ ("wdc	%0, r0;"	\
 				: : "r" (i));
 #endif
@@ -504,7 +504,7 @@ static void __flush_dcache_range_wb(unsigned long start, unsigned long end)
 #ifdef ASM_LOOP
 	CACHE_RANGE_LOOP_2(start, end, cpuinfo.dcache_line_length, wdc.flush);
 #else
-	for (i = start; i < end; i += cpuinfo.icache_line_length)
+	for (i = start; i < end; i += cpuinfo.dcache_line_length)
 		__asm__ __volatile__ ("wdc.flush	%0, r0;"	\
 				: : "r" (i));
 #endif

commit 22607a28213068af113b46862eafa785f00a482e
Author: Michal Simek <monstr@monstr.eu>
Date:   Mon Feb 15 16:41:40 2010 +0100

    microblaze: Add define for ASM_LOOP
    
    It is default option but both options must be measured.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/kernel/cpu/cache.c b/arch/microblaze/kernel/cpu/cache.c
index 13f0c1de3234..f04d8a86dead 100644
--- a/arch/microblaze/kernel/cpu/cache.c
+++ b/arch/microblaze/kernel/cpu/cache.c
@@ -15,25 +15,6 @@
 #include <asm/cpuinfo.h>
 #include <asm/pvr.h>
 
-static inline void __invalidate_flush_icache(unsigned int addr)
-{
-	__asm__ __volatile__ ("wic	%0, r0;"	\
-					: : "r" (addr));
-}
-
-static inline void __flush_dcache(unsigned int addr)
-{
-	__asm__ __volatile__ ("wdc.flush	%0, r0;"	\
-					: : "r" (addr));
-}
-
-static inline void __invalidate_dcache(unsigned int baseaddr,
-						unsigned int offset)
-{
-	__asm__ __volatile__ ("wdc.clear	%0, %1;"	\
-					: : "r" (baseaddr), "r" (offset));
-}
-
 static inline void __enable_icache_msr(void)
 {
 	__asm__ __volatile__ ("	msrset	r0, %0;		\
@@ -148,9 +129,9 @@ do {									\
 	int step = -line_length;					\
 	BUG_ON(step >= 0);						\
 									\
-	__asm__ __volatile__ (" 1:      " #op " r0, %0;			\
-					bgtid   %0, 1b;			\
-					addk    %0, %0, %1;		\
+	__asm__ __volatile__ (" 1:	" #op "	r0, %0;			\
+					bgtid	%0, 1b;			\
+					addk	%0, %0, %1;		\
 					" : : "r" (len), "r" (step)	\
 					: "memory");			\
 } while (0);
@@ -162,9 +143,9 @@ do {									\
 	int count = end - start;					\
 	BUG_ON(count <= 0);						\
 									\
-	__asm__ __volatile__ (" 1:	" #op " %0, %1;			\
-					bgtid   %1, 1b;			\
-					addk    %1, %1, %2;		\
+	__asm__ __volatile__ (" 1:	" #op "	%0, %1;			\
+					bgtid	%1, 1b;			\
+					addk	%1, %1, %2;		\
 					" : : "r" (start), "r" (count),	\
 					"r" (step) : "memory");		\
 } while (0);
@@ -175,7 +156,7 @@ do {									\
 	int volatile temp;						\
 	BUG_ON(end - start <= 0);					\
 									\
-	__asm__ __volatile__ (" 1:	" #op " %1, r0;			\
+	__asm__ __volatile__ (" 1:	" #op "	%1, r0;			\
 					cmpu	%0, %1, %2;		\
 					bgtid	%0, 1b;			\
 					addk	%1, %1, %3;		\
@@ -183,10 +164,14 @@ do {									\
 					"r" (line_length) : "memory");	\
 } while (0);
 
+#define ASM_LOOP
+
 static void __flush_icache_range_msr_irq(unsigned long start, unsigned long end)
 {
 	unsigned long flags;
-
+#ifndef ASM_LOOP
+	int i;
+#endif
 	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
 				(unsigned int)start, (unsigned int) end);
 
@@ -196,8 +181,13 @@ static void __flush_icache_range_msr_irq(unsigned long start, unsigned long end)
 	local_irq_save(flags);
 	__disable_icache_msr();
 
+#ifdef ASM_LOOP
 	CACHE_RANGE_LOOP_1(start, end, cpuinfo.icache_line_length, wic);
-
+#else
+	for (i = start; i < end; i += cpuinfo.icache_line_length)
+		__asm__ __volatile__ ("wic	%0, r0;"	\
+				: : "r" (i));
+#endif
 	__enable_icache_msr();
 	local_irq_restore(flags);
 }
@@ -206,7 +196,9 @@ static void __flush_icache_range_nomsr_irq(unsigned long start,
 				unsigned long end)
 {
 	unsigned long flags;
-
+#ifndef ASM_LOOP
+	int i;
+#endif
 	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
 				(unsigned int)start, (unsigned int) end);
 
@@ -216,7 +208,13 @@ static void __flush_icache_range_nomsr_irq(unsigned long start,
 	local_irq_save(flags);
 	__disable_icache_nomsr();
 
+#ifdef ASM_LOOP
 	CACHE_RANGE_LOOP_1(start, end, cpuinfo.icache_line_length, wic);
+#else
+	for (i = start; i < end; i += cpuinfo.icache_line_length)
+		__asm__ __volatile__ ("wic	%0, r0;"	\
+				: : "r" (i));
+#endif
 
 	__enable_icache_nomsr();
 	local_irq_restore(flags);
@@ -225,25 +223,41 @@ static void __flush_icache_range_nomsr_irq(unsigned long start,
 static void __flush_icache_range_noirq(unsigned long start,
 				unsigned long end)
 {
+#ifndef ASM_LOOP
+	int i;
+#endif
 	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
 				(unsigned int)start, (unsigned int) end);
 
 	CACHE_LOOP_LIMITS(start, end,
 			cpuinfo.icache_line_length, cpuinfo.icache_size);
+#ifdef ASM_LOOP
 	CACHE_RANGE_LOOP_1(start, end, cpuinfo.icache_line_length, wic);
+#else
+	for (i = start; i < end; i += cpuinfo.icache_line_length)
+		__asm__ __volatile__ ("wic	%0, r0;"	\
+				: : "r" (i));
+#endif
 }
 
 static void __flush_icache_all_msr_irq(void)
 {
 	unsigned long flags;
-
+#ifndef ASM_LOOP
+	int i;
+#endif
 	pr_debug("%s\n", __func__);
 
 	local_irq_save(flags);
 	__disable_icache_msr();
-
+#ifdef ASM_LOOP
 	CACHE_ALL_LOOP(cpuinfo.icache_size, cpuinfo.icache_line_length, wic);
-
+#else
+	for (i = 0; i < cpuinfo.icache_size;
+		 i += cpuinfo.icache_line_length)
+			__asm__ __volatile__ ("wic	%0, r0;" \
+					: : "r" (i));
+#endif
 	__enable_icache_msr();
 	local_irq_restore(flags);
 }
@@ -251,35 +265,59 @@ static void __flush_icache_all_msr_irq(void)
 static void __flush_icache_all_nomsr_irq(void)
 {
 	unsigned long flags;
-
+#ifndef ASM_LOOP
+	int i;
+#endif
 	pr_debug("%s\n", __func__);
 
 	local_irq_save(flags);
 	__disable_icache_nomsr();
-
+#ifdef ASM_LOOP
 	CACHE_ALL_LOOP(cpuinfo.icache_size, cpuinfo.icache_line_length, wic);
-
+#else
+	for (i = 0; i < cpuinfo.icache_size;
+		 i += cpuinfo.icache_line_length)
+			__asm__ __volatile__ ("wic	%0, r0;" \
+					: : "r" (i));
+#endif
 	__enable_icache_nomsr();
 	local_irq_restore(flags);
 }
 
 static void __flush_icache_all_noirq(void)
 {
+#ifndef ASM_LOOP
+	int i;
+#endif
 	pr_debug("%s\n", __func__);
+#ifdef ASM_LOOP
 	CACHE_ALL_LOOP(cpuinfo.icache_size, cpuinfo.icache_line_length, wic);
+#else
+	for (i = 0; i < cpuinfo.icache_size;
+		 i += cpuinfo.icache_line_length)
+			__asm__ __volatile__ ("wic	%0, r0;" \
+					: : "r" (i));
+#endif
 }
 
 static void __invalidate_dcache_all_msr_irq(void)
 {
 	unsigned long flags;
-
+#ifndef ASM_LOOP
+	int i;
+#endif
 	pr_debug("%s\n", __func__);
 
 	local_irq_save(flags);
 	__disable_dcache_msr();
-
+#ifdef ASM_LOOP
 	CACHE_ALL_LOOP(cpuinfo.dcache_size, cpuinfo.dcache_line_length, wdc);
-
+#else
+	for (i = 0; i < cpuinfo.dcache_size;
+		 i += cpuinfo.dcache_line_length)
+			__asm__ __volatile__ ("wdc	%0, r0;" \
+					: : "r" (i));
+#endif
 	__enable_dcache_msr();
 	local_irq_restore(flags);
 }
@@ -287,60 +325,107 @@ static void __invalidate_dcache_all_msr_irq(void)
 static void __invalidate_dcache_all_nomsr_irq(void)
 {
 	unsigned long flags;
-
+#ifndef ASM_LOOP
+	int i;
+#endif
 	pr_debug("%s\n", __func__);
 
 	local_irq_save(flags);
 	__disable_dcache_nomsr();
-
+#ifdef ASM_LOOP
 	CACHE_ALL_LOOP(cpuinfo.dcache_size, cpuinfo.dcache_line_length, wdc);
-
+#else
+	for (i = 0; i < cpuinfo.dcache_size;
+		 i += cpuinfo.dcache_line_length)
+			__asm__ __volatile__ ("wdc	%0, r0;" \
+					: : "r" (i));
+#endif
 	__enable_dcache_nomsr();
 	local_irq_restore(flags);
 }
 
 static void __invalidate_dcache_all_noirq_wt(void)
 {
+#ifndef ASM_LOOP
+	int i;
+#endif
 	pr_debug("%s\n", __func__);
+#ifdef ASM_LOOP
 	CACHE_ALL_LOOP(cpuinfo.dcache_size, cpuinfo.dcache_line_length, wdc)
+#else
+	for (i = 0; i < cpuinfo.dcache_size;
+		 i += cpuinfo.dcache_line_length)
+			__asm__ __volatile__ ("wdc	%0, r0;" \
+					: : "r" (i));
+#endif
 }
 
 /* FIXME this is weird - should be only wdc but not work
  * MS: I am getting bus errors and other weird things */
 static void __invalidate_dcache_all_wb(void)
 {
+#ifndef ASM_LOOP
+	int i;
+#endif
 	pr_debug("%s\n", __func__);
+#ifdef ASM_LOOP
 	CACHE_ALL_LOOP2(cpuinfo.dcache_size, cpuinfo.dcache_line_length,
 					wdc.clear)
+#else
+	for (i = 0; i < cpuinfo.dcache_size;
+		 i += cpuinfo.dcache_line_length)
+			__asm__ __volatile__ ("wdc.clear	%0, r0;" \
+					: : "r" (i));
+#endif
 }
 
 static void __invalidate_dcache_range_wb(unsigned long start,
 						unsigned long end)
 {
+#ifndef ASM_LOOP
+	int i;
+#endif
 	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
 				(unsigned int)start, (unsigned int) end);
 
 	CACHE_LOOP_LIMITS(start, end,
 			cpuinfo.dcache_line_length, cpuinfo.dcache_size);
+#ifdef ASM_LOOP
 	CACHE_RANGE_LOOP_2(start, end, cpuinfo.dcache_line_length, wdc.clear);
+#else
+	for (i = start; i < end; i += cpuinfo.icache_line_length)
+		__asm__ __volatile__ ("wdc.clear	%0, r0;"	\
+				: : "r" (i));
+#endif
 }
 
 static void __invalidate_dcache_range_nomsr_wt(unsigned long start,
 							unsigned long end)
 {
+#ifndef ASM_LOOP
+	int i;
+#endif
 	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
 				(unsigned int)start, (unsigned int) end);
 	CACHE_LOOP_LIMITS(start, end,
 			cpuinfo.dcache_line_length, cpuinfo.dcache_size);
 
+#ifdef ASM_LOOP
 	CACHE_RANGE_LOOP_1(start, end, cpuinfo.dcache_line_length, wdc);
+#else
+	for (i = start; i < end; i += cpuinfo.icache_line_length)
+		__asm__ __volatile__ ("wdc	%0, r0;"	\
+				: : "r" (i));
+#endif
 }
 
 static void __invalidate_dcache_range_msr_irq_wt(unsigned long start,
 							unsigned long end)
 {
 	unsigned long flags;
-
+#ifndef ASM_LOOP
+	int i;
+#endif
 	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
 				(unsigned int)start, (unsigned int) end);
 	CACHE_LOOP_LIMITS(start, end,
@@ -349,7 +434,13 @@ static void __invalidate_dcache_range_msr_irq_wt(unsigned long start,
 	local_irq_save(flags);
 	__disable_dcache_msr();
 
+#ifdef ASM_LOOP
 	CACHE_RANGE_LOOP_1(start, end, cpuinfo.dcache_line_length, wdc);
+#else
+	for (i = start; i < end; i += cpuinfo.icache_line_length)
+		__asm__ __volatile__ ("wdc	%0, r0;"	\
+				: : "r" (i));
+#endif
 
 	__enable_dcache_msr();
 	local_irq_restore(flags);
@@ -359,7 +450,9 @@ static void __invalidate_dcache_range_nomsr_irq(unsigned long start,
 							unsigned long end)
 {
 	unsigned long flags;
-
+#ifndef ASM_LOOP
+	int i;
+#endif
 	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
 				(unsigned int)start, (unsigned int) end);
 
@@ -369,7 +462,13 @@ static void __invalidate_dcache_range_nomsr_irq(unsigned long start,
 	local_irq_save(flags);
 	__disable_dcache_nomsr();
 
+#ifdef ASM_LOOP
 	CACHE_RANGE_LOOP_1(start, end, cpuinfo.dcache_line_length, wdc);
+#else
+	for (i = start; i < end; i += cpuinfo.icache_line_length)
+		__asm__ __volatile__ ("wdc	%0, r0;"	\
+				: : "r" (i));
+#endif
 
 	__enable_dcache_nomsr();
 	local_irq_restore(flags);
@@ -377,19 +476,38 @@ static void __invalidate_dcache_range_nomsr_irq(unsigned long start,
 
 static void __flush_dcache_all_wb(void)
 {
+#ifndef ASM_LOOP
+	int i;
+#endif
 	pr_debug("%s\n", __func__);
+#ifdef ASM_LOOP
 	CACHE_ALL_LOOP(cpuinfo.dcache_size, cpuinfo.dcache_line_length,
 				wdc.flush);
+#else
+	for (i = 0; i < cpuinfo.dcache_size;
+		 i += cpuinfo.dcache_line_length)
+			__asm__ __volatile__ ("wdc.flush	%0, r0;" \
+					: : "r" (i));
+#endif
 }
 
 static void __flush_dcache_range_wb(unsigned long start, unsigned long end)
 {
+#ifndef ASM_LOOP
+	int i;
+#endif
 	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
 				(unsigned int)start, (unsigned int) end);
 
 	CACHE_LOOP_LIMITS(start, end,
 			cpuinfo.dcache_line_length, cpuinfo.dcache_size);
+#ifdef ASM_LOOP
 	CACHE_RANGE_LOOP_2(start, end, cpuinfo.dcache_line_length, wdc.flush);
+#else
+	for (i = start; i < end; i += cpuinfo.icache_line_length)
+		__asm__ __volatile__ ("wdc.flush	%0, r0;"	\
+				: : "r" (i));
+#endif
 }
 
 /* struct for wb caches and for wt caches */

commit 4c912c1a33abb67aefecb5ed8bd73d91887c4977
Author: Frans Pop <elendil@planet.nl>
Date:   Sat Feb 6 18:47:12 2010 +0100

    microblaze: remove trailing space in messages
    
    Signed-off-by: Frans Pop <elendil@planet.nl>
    Cc: microblaze-uclinux@itee.uq.edu.au
    Cc: Michal Simek <monstr@monstr.eu>
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/kernel/cpu/cache.c b/arch/microblaze/kernel/cpu/cache.c
index 5425f89335ed..13f0c1de3234 100644
--- a/arch/microblaze/kernel/cpu/cache.c
+++ b/arch/microblaze/kernel/cpu/cache.c
@@ -493,7 +493,7 @@ const struct scache wt_nomsr_noirq = {
 #define CPUVER_7_20_A	0x0c
 #define CPUVER_7_20_D	0x0f
 
-#define INFO(s)	printk(KERN_INFO "cache: " s " \n");
+#define INFO(s)	printk(KERN_INFO "cache: " s "\n");
 
 void microblaze_cache_init(void)
 {

commit 407c1da07d5afa001ed0fdb8f379c00bbd09990a
Author: Michal Simek <monstr@monstr.eu>
Date:   Tue Jan 12 14:51:04 2010 +0100

    microblaze: Move cache function to cache.c
    
    It is better to have init cache handling on one place.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/kernel/cpu/cache.c b/arch/microblaze/kernel/cpu/cache.c
index 2a56bccce4e0..5425f89335ed 100644
--- a/arch/microblaze/kernel/cpu/cache.c
+++ b/arch/microblaze/kernel/cpu/cache.c
@@ -532,4 +532,9 @@ void microblaze_cache_init(void)
 			}
 		}
 	}
+	invalidate_dcache();
+	enable_dcache();
+
+	invalidate_icache();
+	enable_icache();
 }

commit 0d670b24729be268eba98b3920b8571f60798d8d
Author: Michal Simek <monstr@monstr.eu>
Date:   Mon Feb 15 10:50:42 2010 +0100

    microblaze: Fix cache loop function for cache range
    
    I create wrong asm code but none test shows that this part of code is wrong.
    I am not convinces that were good idea to create asm optimized macros
    for caches. The reason is that there is not optimization with previous code
    that's why make sense to add old code and do some benchmarking which
    functions are faster.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/kernel/cpu/cache.c b/arch/microblaze/kernel/cpu/cache.c
index d9d63831cc2f..2a56bccce4e0 100644
--- a/arch/microblaze/kernel/cpu/cache.c
+++ b/arch/microblaze/kernel/cpu/cache.c
@@ -172,16 +172,15 @@ do {									\
 /* It is used only first parameter for OP - for wic, wdc */
 #define CACHE_RANGE_LOOP_1(start, end, line_length, op)			\
 do {									\
-	int step = -line_length;					\
-	int count = end - start;					\
-	BUG_ON(count <= 0);						\
+	int volatile temp;						\
+	BUG_ON(end - start <= 0);					\
 									\
-	__asm__ __volatile__ (" 1:	addk	%0, %0, %1;		\
-					" #op " %0, r0;			\
-					bgtid   %1, 1b;			\
-					addk    %1, %1, %2;		\
-					" : : "r" (start), "r" (count),	\
-					"r" (step) : "memory");		\
+	__asm__ __volatile__ (" 1:	" #op " %1, r0;			\
+					cmpu	%0, %1, %2;		\
+					bgtid	%0, 1b;			\
+					addk	%1, %1, %3;		\
+				" : : "r" (temp), "r" (start), "r" (end),\
+					"r" (line_length) : "memory");	\
 } while (0);
 
 static void __flush_icache_range_msr_irq(unsigned long start, unsigned long end)
@@ -313,16 +312,6 @@ static void __invalidate_dcache_all_wb(void)
 	pr_debug("%s\n", __func__);
 	CACHE_ALL_LOOP2(cpuinfo.dcache_size, cpuinfo.dcache_line_length,
 					wdc.clear)
-
-#if 0
-	unsigned int i;
-
-	pr_debug("%s\n", __func__);
-
-	/* Just loop through cache size and invalidate it */
-	for (i = 0; i < cpuinfo.dcache_size; i += cpuinfo.dcache_line_length)
-			__invalidate_dcache(0, i);
-#endif
 }
 
 static void __invalidate_dcache_range_wb(unsigned long start,

commit 2ee2ff875a4d3bdb941e2bb1173cd927c09d5a67
Author: Michal Simek <monstr@monstr.eu>
Date:   Thu Dec 10 11:43:57 2009 +0100

    microblaze: Support for WB cache
    
    Microblaze version 7.20.d is the first MB version which can be run
    on MMU linux. Please do not used previous version because they contain
    HW bug.
    Based on WB support was necessary to redesign whole cache design.
    Microblaze versions from 7.20.a don't need to disable IRQ and cache
    before working with them that's why there are special structures for it.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/kernel/cpu/cache.c b/arch/microblaze/kernel/cpu/cache.c
index 538f1df6761d..d9d63831cc2f 100644
--- a/arch/microblaze/kernel/cpu/cache.c
+++ b/arch/microblaze/kernel/cpu/cache.c
@@ -3,7 +3,7 @@
  *
  * Copyright (C) 2007-2009 Michal Simek <monstr@monstr.eu>
  * Copyright (C) 2007-2009 PetaLogix
- * Copyright (C) 2007 John Williams <john.williams@petalogix.com>
+ * Copyright (C) 2007-2009 John Williams <john.williams@petalogix.com>
  *
  * This file is subject to the terms and conditions of the GNU General
  * Public License. See the file COPYING in the main directory of this
@@ -13,243 +13,534 @@
 #include <asm/cacheflush.h>
 #include <linux/cache.h>
 #include <asm/cpuinfo.h>
+#include <asm/pvr.h>
 
-/* Exported functions */
+static inline void __invalidate_flush_icache(unsigned int addr)
+{
+	__asm__ __volatile__ ("wic	%0, r0;"	\
+					: : "r" (addr));
+}
+
+static inline void __flush_dcache(unsigned int addr)
+{
+	__asm__ __volatile__ ("wdc.flush	%0, r0;"	\
+					: : "r" (addr));
+}
+
+static inline void __invalidate_dcache(unsigned int baseaddr,
+						unsigned int offset)
+{
+	__asm__ __volatile__ ("wdc.clear	%0, %1;"	\
+					: : "r" (baseaddr), "r" (offset));
+}
 
-void _enable_icache(void)
+static inline void __enable_icache_msr(void)
 {
-	if (cpuinfo.use_icache) {
-#if CONFIG_XILINX_MICROBLAZE0_USE_MSR_INSTR
-		__asm__ __volatile__ ("					\
-				msrset	r0, %0;				\
-				nop; "					\
-				:					\
-				: "i" (MSR_ICE)				\
+	__asm__ __volatile__ ("	msrset	r0, %0;		\
+				nop; "			\
+			: : "i" (MSR_ICE) : "memory");
+}
+
+static inline void __disable_icache_msr(void)
+{
+	__asm__ __volatile__ ("	msrclr	r0, %0;		\
+				nop; "			\
+			: : "i" (MSR_ICE) : "memory");
+}
+
+static inline void __enable_dcache_msr(void)
+{
+	__asm__ __volatile__ ("	msrset	r0, %0;		\
+				nop; "			\
+				:			\
+				: "i" (MSR_DCE)		\
 				: "memory");
-#else
-		__asm__ __volatile__ ("					\
-				mfs	r12, rmsr;			\
-				nop;					\
-				ori	r12, r12, %0;			\
-				mts	rmsr, r12;			\
-				nop; "					\
-				:					\
-				: "i" (MSR_ICE)				\
-				: "memory", "r12");
-#endif
-	}
 }
 
-void _disable_icache(void)
+static inline void __disable_dcache_msr(void)
 {
-	if (cpuinfo.use_icache) {
-#if CONFIG_XILINX_MICROBLAZE0_USE_MSR_INSTR
-		__asm__ __volatile__ ("					\
-				msrclr r0, %0;				\
-				nop; "					\
-				:					\
-				: "i" (MSR_ICE)				\
+	__asm__ __volatile__ ("	msrclr	r0, %0;		\
+				nop; "			\
+				:			\
+				: "i" (MSR_DCE)		\
 				: "memory");
-#else
-		__asm__ __volatile__ ("					\
-				mfs	r12, rmsr;			\
-				nop;					\
-				andi	r12, r12, ~%0;			\
-				mts	rmsr, r12;			\
-				nop; "					\
-				:					\
-				: "i" (MSR_ICE)				\
+}
+
+static inline void __enable_icache_nomsr(void)
+{
+	__asm__ __volatile__ ("	mfs	r12, rmsr;	\
+				nop;			\
+				ori	r12, r12, %0;	\
+				mts	rmsr, r12;	\
+				nop; "			\
+				:			\
+				: "i" (MSR_ICE)		\
 				: "memory", "r12");
-#endif
-	}
 }
 
-void _invalidate_icache(unsigned int addr)
+static inline void __disable_icache_nomsr(void)
 {
-	if (cpuinfo.use_icache) {
-		__asm__ __volatile__ ("					\
-				wic	%0, r0"				\
-				:					\
-				: "r" (addr));
-	}
+	__asm__ __volatile__ ("	mfs	r12, rmsr;	\
+				nop;			\
+				andi	r12, r12, ~%0;	\
+				mts	rmsr, r12;	\
+				nop; "			\
+				:			\
+				: "i" (MSR_ICE)		\
+				: "memory", "r12");
 }
 
-void _enable_dcache(void)
+static inline void __enable_dcache_nomsr(void)
 {
-	if (cpuinfo.use_dcache) {
-#if CONFIG_XILINX_MICROBLAZE0_USE_MSR_INSTR
-		__asm__ __volatile__ ("					\
-				msrset	r0, %0;				\
-				nop; "					\
-				:					\
-				: "i" (MSR_DCE)				\
-				: "memory");
-#else
-		__asm__ __volatile__ ("					\
-				mfs	r12, rmsr;			\
-				nop;					\
-				ori	r12, r12, %0;			\
-				mts	rmsr, r12;			\
-				nop; "					\
-				:					\
-				: "i" (MSR_DCE)			\
+	__asm__ __volatile__ ("	mfs	r12, rmsr;	\
+				nop;			\
+				ori	r12, r12, %0;	\
+				mts	rmsr, r12;	\
+				nop; "			\
+				:			\
+				: "i" (MSR_DCE)		\
 				: "memory", "r12");
-#endif
-	}
 }
 
-void _disable_dcache(void)
+static inline void __disable_dcache_nomsr(void)
 {
-#if CONFIG_XILINX_MICROBLAZE0_USE_MSR_INSTR
-		__asm__ __volatile__ ("					\
-				msrclr	r0, %0;				\
-				nop; "					\
-				:					\
-				: "i" (MSR_DCE)			\
-				: "memory");
-#else
-		__asm__ __volatile__ ("					\
-				mfs	r12, rmsr;			\
-				nop;					\
-				andi	r12, r12, ~%0;			\
-				mts	rmsr, r12;			\
-				nop; "					\
-				:					\
-				: "i" (MSR_DCE)			\
+	__asm__ __volatile__ ("	mfs	r12, rmsr;	\
+				nop;			\
+				andi	r12, r12, ~%0;	\
+				mts	rmsr, r12;	\
+				nop; "			\
+				:			\
+				: "i" (MSR_DCE)		\
 				: "memory", "r12");
-#endif
 }
 
-void _invalidate_dcache(unsigned int addr)
+
+/* Helper macro for computing the limits of cache range loops */
+#define CACHE_LOOP_LIMITS(start, end, cache_line_length, cache_size)	\
+do {									\
+	int align = ~(cache_line_length - 1);				\
+	end = min(start + cache_size, end);				\
+	start &= align;							\
+	end = ((end & align) + cache_line_length);			\
+} while (0);
+
+/*
+ * Helper macro to loop over the specified cache_size/line_length and
+ * execute 'op' on that cacheline
+ */
+#define CACHE_ALL_LOOP(cache_size, line_length, op)			\
+do {									\
+	unsigned int len = cache_size;					\
+	int step = -line_length;					\
+	BUG_ON(step >= 0);						\
+									\
+	__asm__ __volatile__ (" 1:      " #op " %0, r0;			\
+					bgtid   %0, 1b;			\
+					addk    %0, %0, %1;		\
+					" : : "r" (len), "r" (step)	\
+					: "memory");			\
+} while (0);
+
+
+#define CACHE_ALL_LOOP2(cache_size, line_length, op)			\
+do {									\
+	unsigned int len = cache_size;					\
+	int step = -line_length;					\
+	BUG_ON(step >= 0);						\
+									\
+	__asm__ __volatile__ (" 1:      " #op " r0, %0;			\
+					bgtid   %0, 1b;			\
+					addk    %0, %0, %1;		\
+					" : : "r" (len), "r" (step)	\
+					: "memory");			\
+} while (0);
+
+/* for wdc.flush/clear */
+#define CACHE_RANGE_LOOP_2(start, end, line_length, op)			\
+do {									\
+	int step = -line_length;					\
+	int count = end - start;					\
+	BUG_ON(count <= 0);						\
+									\
+	__asm__ __volatile__ (" 1:	" #op " %0, %1;			\
+					bgtid   %1, 1b;			\
+					addk    %1, %1, %2;		\
+					" : : "r" (start), "r" (count),	\
+					"r" (step) : "memory");		\
+} while (0);
+
+/* It is used only first parameter for OP - for wic, wdc */
+#define CACHE_RANGE_LOOP_1(start, end, line_length, op)			\
+do {									\
+	int step = -line_length;					\
+	int count = end - start;					\
+	BUG_ON(count <= 0);						\
+									\
+	__asm__ __volatile__ (" 1:	addk	%0, %0, %1;		\
+					" #op " %0, r0;			\
+					bgtid   %1, 1b;			\
+					addk    %1, %1, %2;		\
+					" : : "r" (start), "r" (count),	\
+					"r" (step) : "memory");		\
+} while (0);
+
+static void __flush_icache_range_msr_irq(unsigned long start, unsigned long end)
 {
-		__asm__ __volatile__ ("					\
-				wdc	%0, r0"				\
-				:					\
-				: "r" (addr));
+	unsigned long flags;
+
+	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
+				(unsigned int)start, (unsigned int) end);
+
+	CACHE_LOOP_LIMITS(start, end,
+			cpuinfo.icache_line_length, cpuinfo.icache_size);
+
+	local_irq_save(flags);
+	__disable_icache_msr();
+
+	CACHE_RANGE_LOOP_1(start, end, cpuinfo.icache_line_length, wic);
+
+	__enable_icache_msr();
+	local_irq_restore(flags);
 }
 
-void __invalidate_icache_all(void)
+static void __flush_icache_range_nomsr_irq(unsigned long start,
+				unsigned long end)
 {
-	unsigned int i;
-	unsigned flags;
+	unsigned long flags;
 
-	if (cpuinfo.use_icache) {
-		local_irq_save(flags);
-		__disable_icache();
+	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
+				(unsigned int)start, (unsigned int) end);
 
-		/* Just loop through cache size and invalidate, no need to add
-			CACHE_BASE address */
-		for (i = 0; i < cpuinfo.icache_size;
-			i += cpuinfo.icache_line_length)
-				__invalidate_icache(i);
+	CACHE_LOOP_LIMITS(start, end,
+			cpuinfo.icache_line_length, cpuinfo.icache_size);
 
-		__enable_icache();
-		local_irq_restore(flags);
-	}
+	local_irq_save(flags);
+	__disable_icache_nomsr();
+
+	CACHE_RANGE_LOOP_1(start, end, cpuinfo.icache_line_length, wic);
+
+	__enable_icache_nomsr();
+	local_irq_restore(flags);
 }
 
-void __invalidate_icache_range(unsigned long start, unsigned long end)
+static void __flush_icache_range_noirq(unsigned long start,
+				unsigned long end)
 {
-	unsigned int i;
-	unsigned flags;
-	unsigned int align;
-
-	if (cpuinfo.use_icache) {
-		/*
-		 * No need to cover entire cache range,
-		 * just cover cache footprint
-		 */
-		end = min(start + cpuinfo.icache_size, end);
-		align = ~(cpuinfo.icache_line_length - 1);
-		start &= align; /* Make sure we are aligned */
-		/* Push end up to the next cache line */
-		end = ((end & align) + cpuinfo.icache_line_length);
-
-		local_irq_save(flags);
-		__disable_icache();
-
-		for (i = start; i < end; i += cpuinfo.icache_line_length)
-			__invalidate_icache(i);
-
-		__enable_icache();
-		local_irq_restore(flags);
-	}
+	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
+				(unsigned int)start, (unsigned int) end);
+
+	CACHE_LOOP_LIMITS(start, end,
+			cpuinfo.icache_line_length, cpuinfo.icache_size);
+	CACHE_RANGE_LOOP_1(start, end, cpuinfo.icache_line_length, wic);
+}
+
+static void __flush_icache_all_msr_irq(void)
+{
+	unsigned long flags;
+
+	pr_debug("%s\n", __func__);
+
+	local_irq_save(flags);
+	__disable_icache_msr();
+
+	CACHE_ALL_LOOP(cpuinfo.icache_size, cpuinfo.icache_line_length, wic);
+
+	__enable_icache_msr();
+	local_irq_restore(flags);
+}
+
+static void __flush_icache_all_nomsr_irq(void)
+{
+	unsigned long flags;
+
+	pr_debug("%s\n", __func__);
+
+	local_irq_save(flags);
+	__disable_icache_nomsr();
+
+	CACHE_ALL_LOOP(cpuinfo.icache_size, cpuinfo.icache_line_length, wic);
+
+	__enable_icache_nomsr();
+	local_irq_restore(flags);
 }
 
-void __invalidate_icache_page(struct vm_area_struct *vma, struct page *page)
+static void __flush_icache_all_noirq(void)
 {
-	__invalidate_icache_all();
+	pr_debug("%s\n", __func__);
+	CACHE_ALL_LOOP(cpuinfo.icache_size, cpuinfo.icache_line_length, wic);
 }
 
-void __invalidate_icache_user_range(struct vm_area_struct *vma,
-				struct page *page, unsigned long adr,
-				int len)
+static void __invalidate_dcache_all_msr_irq(void)
 {
-	__invalidate_icache_all();
+	unsigned long flags;
+
+	pr_debug("%s\n", __func__);
+
+	local_irq_save(flags);
+	__disable_dcache_msr();
+
+	CACHE_ALL_LOOP(cpuinfo.dcache_size, cpuinfo.dcache_line_length, wdc);
+
+	__enable_dcache_msr();
+	local_irq_restore(flags);
 }
 
-void __invalidate_cache_sigtramp(unsigned long addr)
+static void __invalidate_dcache_all_nomsr_irq(void)
 {
-	__invalidate_icache_range(addr, addr + 8);
+	unsigned long flags;
+
+	pr_debug("%s\n", __func__);
+
+	local_irq_save(flags);
+	__disable_dcache_nomsr();
+
+	CACHE_ALL_LOOP(cpuinfo.dcache_size, cpuinfo.dcache_line_length, wdc);
+
+	__enable_dcache_nomsr();
+	local_irq_restore(flags);
 }
 
-void __invalidate_dcache_all(void)
+static void __invalidate_dcache_all_noirq_wt(void)
 {
-	unsigned int i;
-	unsigned flags;
-
-	if (cpuinfo.use_dcache) {
-		local_irq_save(flags);
-		__disable_dcache();
-
-		/*
-		 * Just loop through cache size and invalidate,
-		 * no need to add CACHE_BASE address
-		 */
-		for (i = 0; i < cpuinfo.dcache_size;
-			i += cpuinfo.dcache_line_length)
-				__invalidate_dcache(i);
-
-		__enable_dcache();
-		local_irq_restore(flags);
-	}
+	pr_debug("%s\n", __func__);
+	CACHE_ALL_LOOP(cpuinfo.dcache_size, cpuinfo.dcache_line_length, wdc)
 }
 
-void __invalidate_dcache_range(unsigned long start, unsigned long end)
+/* FIXME this is weird - should be only wdc but not work
+ * MS: I am getting bus errors and other weird things */
+static void __invalidate_dcache_all_wb(void)
 {
+	pr_debug("%s\n", __func__);
+	CACHE_ALL_LOOP2(cpuinfo.dcache_size, cpuinfo.dcache_line_length,
+					wdc.clear)
+
+#if 0
 	unsigned int i;
-	unsigned flags;
-	unsigned int align;
-
-	if (cpuinfo.use_dcache) {
-		/*
-		 * No need to cover entire cache range,
-		 * just cover cache footprint
-		 */
-		end = min(start + cpuinfo.dcache_size, end);
-		align = ~(cpuinfo.dcache_line_length - 1);
-		start &= align; /* Make sure we are aligned */
-		/* Push end up to the next cache line */
-		end = ((end & align) + cpuinfo.dcache_line_length);
-		local_irq_save(flags);
-		__disable_dcache();
-
-		for (i = start; i < end; i += cpuinfo.dcache_line_length)
-			__invalidate_dcache(i);
-
-		__enable_dcache();
-		local_irq_restore(flags);
-	}
+
+	pr_debug("%s\n", __func__);
+
+	/* Just loop through cache size and invalidate it */
+	for (i = 0; i < cpuinfo.dcache_size; i += cpuinfo.dcache_line_length)
+			__invalidate_dcache(0, i);
+#endif
+}
+
+static void __invalidate_dcache_range_wb(unsigned long start,
+						unsigned long end)
+{
+	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
+				(unsigned int)start, (unsigned int) end);
+
+	CACHE_LOOP_LIMITS(start, end,
+			cpuinfo.dcache_line_length, cpuinfo.dcache_size);
+	CACHE_RANGE_LOOP_2(start, end, cpuinfo.dcache_line_length, wdc.clear);
+}
+
+static void __invalidate_dcache_range_nomsr_wt(unsigned long start,
+							unsigned long end)
+{
+	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
+				(unsigned int)start, (unsigned int) end);
+	CACHE_LOOP_LIMITS(start, end,
+			cpuinfo.dcache_line_length, cpuinfo.dcache_size);
+
+	CACHE_RANGE_LOOP_1(start, end, cpuinfo.dcache_line_length, wdc);
 }
 
-void __invalidate_dcache_page(struct vm_area_struct *vma, struct page *page)
+static void __invalidate_dcache_range_msr_irq_wt(unsigned long start,
+							unsigned long end)
 {
-	__invalidate_dcache_all();
+	unsigned long flags;
+
+	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
+				(unsigned int)start, (unsigned int) end);
+	CACHE_LOOP_LIMITS(start, end,
+			cpuinfo.dcache_line_length, cpuinfo.dcache_size);
+
+	local_irq_save(flags);
+	__disable_dcache_msr();
+
+	CACHE_RANGE_LOOP_1(start, end, cpuinfo.dcache_line_length, wdc);
+
+	__enable_dcache_msr();
+	local_irq_restore(flags);
+}
+
+static void __invalidate_dcache_range_nomsr_irq(unsigned long start,
+							unsigned long end)
+{
+	unsigned long flags;
+
+	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
+				(unsigned int)start, (unsigned int) end);
+
+	CACHE_LOOP_LIMITS(start, end,
+			cpuinfo.dcache_line_length, cpuinfo.dcache_size);
+
+	local_irq_save(flags);
+	__disable_dcache_nomsr();
+
+	CACHE_RANGE_LOOP_1(start, end, cpuinfo.dcache_line_length, wdc);
+
+	__enable_dcache_nomsr();
+	local_irq_restore(flags);
+}
+
+static void __flush_dcache_all_wb(void)
+{
+	pr_debug("%s\n", __func__);
+	CACHE_ALL_LOOP(cpuinfo.dcache_size, cpuinfo.dcache_line_length,
+				wdc.flush);
 }
 
-void __invalidate_dcache_user_range(struct vm_area_struct *vma,
-				struct page *page, unsigned long adr,
-				int len)
+static void __flush_dcache_range_wb(unsigned long start, unsigned long end)
 {
-	__invalidate_dcache_all();
+	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
+				(unsigned int)start, (unsigned int) end);
+
+	CACHE_LOOP_LIMITS(start, end,
+			cpuinfo.dcache_line_length, cpuinfo.dcache_size);
+	CACHE_RANGE_LOOP_2(start, end, cpuinfo.dcache_line_length, wdc.flush);
+}
+
+/* struct for wb caches and for wt caches */
+struct scache *mbc;
+
+/* new wb cache model */
+const struct scache wb_msr = {
+	.ie = __enable_icache_msr,
+	.id = __disable_icache_msr,
+	.ifl = __flush_icache_all_noirq,
+	.iflr = __flush_icache_range_noirq,
+	.iin = __flush_icache_all_noirq,
+	.iinr = __flush_icache_range_noirq,
+	.de = __enable_dcache_msr,
+	.dd = __disable_dcache_msr,
+	.dfl = __flush_dcache_all_wb,
+	.dflr = __flush_dcache_range_wb,
+	.din = __invalidate_dcache_all_wb,
+	.dinr = __invalidate_dcache_range_wb,
+};
+
+/* There is only difference in ie, id, de, dd functions */
+const struct scache wb_nomsr = {
+	.ie = __enable_icache_nomsr,
+	.id = __disable_icache_nomsr,
+	.ifl = __flush_icache_all_noirq,
+	.iflr = __flush_icache_range_noirq,
+	.iin = __flush_icache_all_noirq,
+	.iinr = __flush_icache_range_noirq,
+	.de = __enable_dcache_nomsr,
+	.dd = __disable_dcache_nomsr,
+	.dfl = __flush_dcache_all_wb,
+	.dflr = __flush_dcache_range_wb,
+	.din = __invalidate_dcache_all_wb,
+	.dinr = __invalidate_dcache_range_wb,
+};
+
+/* Old wt cache model with disabling irq and turn off cache */
+const struct scache wt_msr = {
+	.ie = __enable_icache_msr,
+	.id = __disable_icache_msr,
+	.ifl = __flush_icache_all_msr_irq,
+	.iflr = __flush_icache_range_msr_irq,
+	.iin = __flush_icache_all_msr_irq,
+	.iinr = __flush_icache_range_msr_irq,
+	.de = __enable_dcache_msr,
+	.dd = __disable_dcache_msr,
+	.dfl = __invalidate_dcache_all_msr_irq,
+	.dflr = __invalidate_dcache_range_msr_irq_wt,
+	.din = __invalidate_dcache_all_msr_irq,
+	.dinr = __invalidate_dcache_range_msr_irq_wt,
+};
+
+const struct scache wt_nomsr = {
+	.ie = __enable_icache_nomsr,
+	.id = __disable_icache_nomsr,
+	.ifl = __flush_icache_all_nomsr_irq,
+	.iflr = __flush_icache_range_nomsr_irq,
+	.iin = __flush_icache_all_nomsr_irq,
+	.iinr = __flush_icache_range_nomsr_irq,
+	.de = __enable_dcache_nomsr,
+	.dd = __disable_dcache_nomsr,
+	.dfl = __invalidate_dcache_all_nomsr_irq,
+	.dflr = __invalidate_dcache_range_nomsr_irq,
+	.din = __invalidate_dcache_all_nomsr_irq,
+	.dinr = __invalidate_dcache_range_nomsr_irq,
+};
+
+/* New wt cache model for newer Microblaze versions */
+const struct scache wt_msr_noirq = {
+	.ie = __enable_icache_msr,
+	.id = __disable_icache_msr,
+	.ifl = __flush_icache_all_noirq,
+	.iflr = __flush_icache_range_noirq,
+	.iin = __flush_icache_all_noirq,
+	.iinr = __flush_icache_range_noirq,
+	.de = __enable_dcache_msr,
+	.dd = __disable_dcache_msr,
+	.dfl = __invalidate_dcache_all_noirq_wt,
+	.dflr = __invalidate_dcache_range_nomsr_wt,
+	.din = __invalidate_dcache_all_noirq_wt,
+	.dinr = __invalidate_dcache_range_nomsr_wt,
+};
+
+const struct scache wt_nomsr_noirq = {
+	.ie = __enable_icache_nomsr,
+	.id = __disable_icache_nomsr,
+	.ifl = __flush_icache_all_noirq,
+	.iflr = __flush_icache_range_noirq,
+	.iin = __flush_icache_all_noirq,
+	.iinr = __flush_icache_range_noirq,
+	.de = __enable_dcache_nomsr,
+	.dd = __disable_dcache_nomsr,
+	.dfl = __invalidate_dcache_all_noirq_wt,
+	.dflr = __invalidate_dcache_range_nomsr_wt,
+	.din = __invalidate_dcache_all_noirq_wt,
+	.dinr = __invalidate_dcache_range_nomsr_wt,
+};
+
+/* CPU version code for 7.20.c - see arch/microblaze/kernel/cpu/cpuinfo.c */
+#define CPUVER_7_20_A	0x0c
+#define CPUVER_7_20_D	0x0f
+
+#define INFO(s)	printk(KERN_INFO "cache: " s " \n");
+
+void microblaze_cache_init(void)
+{
+	if (cpuinfo.use_instr & PVR2_USE_MSR_INSTR) {
+		if (cpuinfo.dcache_wb) {
+			INFO("wb_msr");
+			mbc = (struct scache *)&wb_msr;
+			if (cpuinfo.ver_code < CPUVER_7_20_D) {
+				/* MS: problem with signal handling - hw bug */
+				INFO("WB won't work properly");
+			}
+		} else {
+			if (cpuinfo.ver_code >= CPUVER_7_20_A) {
+				INFO("wt_msr_noirq");
+				mbc = (struct scache *)&wt_msr_noirq;
+			} else {
+				INFO("wt_msr");
+				mbc = (struct scache *)&wt_msr;
+			}
+		}
+	} else {
+		if (cpuinfo.dcache_wb) {
+			INFO("wb_nomsr");
+			mbc = (struct scache *)&wb_nomsr;
+			if (cpuinfo.ver_code < CPUVER_7_20_D) {
+				/* MS: problem with signal handling - hw bug */
+				INFO("WB won't work properly");
+			}
+		} else {
+			if (cpuinfo.ver_code >= CPUVER_7_20_A) {
+				INFO("wt_nomsr_noirq");
+				mbc = (struct scache *)&wt_nomsr_noirq;
+			} else {
+				INFO("wt_nomsr");
+				mbc = (struct scache *)&wt_nomsr;
+			}
+		}
+	}
 }

commit 44e4e196a9b3a703ebe273ffe3fb6cda326fe5d3
Author: Michal Simek <monstr@monstr.eu>
Date:   Thu Oct 8 13:06:42 2009 +0200

    microblaze: Fix cache_line_lenght
    
    We used cache_line as cache_line_lenght. For this reason
    we did cache flushing 4 times longer than was necessary.
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/kernel/cpu/cache.c b/arch/microblaze/kernel/cpu/cache.c
index af866a450125..538f1df6761d 100644
--- a/arch/microblaze/kernel/cpu/cache.c
+++ b/arch/microblaze/kernel/cpu/cache.c
@@ -140,7 +140,7 @@ void __invalidate_icache_all(void)
 		/* Just loop through cache size and invalidate, no need to add
 			CACHE_BASE address */
 		for (i = 0; i < cpuinfo.icache_size;
-			i += cpuinfo.icache_line)
+			i += cpuinfo.icache_line_length)
 				__invalidate_icache(i);
 
 		__enable_icache();
@@ -160,15 +160,15 @@ void __invalidate_icache_range(unsigned long start, unsigned long end)
 		 * just cover cache footprint
 		 */
 		end = min(start + cpuinfo.icache_size, end);
-		align = ~(cpuinfo.icache_line - 1);
+		align = ~(cpuinfo.icache_line_length - 1);
 		start &= align; /* Make sure we are aligned */
 		/* Push end up to the next cache line */
-		end = ((end & align) + cpuinfo.icache_line);
+		end = ((end & align) + cpuinfo.icache_line_length);
 
 		local_irq_save(flags);
 		__disable_icache();
 
-		for (i = start; i < end; i += cpuinfo.icache_line)
+		for (i = start; i < end; i += cpuinfo.icache_line_length)
 			__invalidate_icache(i);
 
 		__enable_icache();
@@ -207,7 +207,7 @@ void __invalidate_dcache_all(void)
 		 * no need to add CACHE_BASE address
 		 */
 		for (i = 0; i < cpuinfo.dcache_size;
-			i += cpuinfo.dcache_line)
+			i += cpuinfo.dcache_line_length)
 				__invalidate_dcache(i);
 
 		__enable_dcache();
@@ -227,14 +227,14 @@ void __invalidate_dcache_range(unsigned long start, unsigned long end)
 		 * just cover cache footprint
 		 */
 		end = min(start + cpuinfo.dcache_size, end);
-		align = ~(cpuinfo.dcache_line - 1);
+		align = ~(cpuinfo.dcache_line_length - 1);
 		start &= align; /* Make sure we are aligned */
 		/* Push end up to the next cache line */
-		end = ((end & align) + cpuinfo.dcache_line);
+		end = ((end & align) + cpuinfo.dcache_line_length);
 		local_irq_save(flags);
 		__disable_dcache();
 
-		for (i = start; i < end; i += cpuinfo.dcache_line)
+		for (i = start; i < end; i += cpuinfo.dcache_line_length)
 			__invalidate_dcache(i);
 
 		__enable_dcache();

commit 6dfb79aa114ac69032f3931235ffc90799e9630b
Author: Michal Simek <monstr@monstr.eu>
Date:   Tue Apr 21 14:07:00 2009 +0200

    microblaze: Do not check use_dcache
    
    It is not necessary to check cpuinfo.use_dcache because
    this checking is done in function which call that functions
    
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/kernel/cpu/cache.c b/arch/microblaze/kernel/cpu/cache.c
index be9fecca4f91..af866a450125 100644
--- a/arch/microblaze/kernel/cpu/cache.c
+++ b/arch/microblaze/kernel/cpu/cache.c
@@ -100,7 +100,6 @@ void _enable_dcache(void)
 
 void _disable_dcache(void)
 {
-	if (cpuinfo.use_dcache) {
 #if CONFIG_XILINX_MICROBLAZE0_USE_MSR_INSTR
 		__asm__ __volatile__ ("					\
 				msrclr	r0, %0;				\
@@ -119,12 +118,10 @@ void _disable_dcache(void)
 				: "i" (MSR_DCE)			\
 				: "memory", "r12");
 #endif
-	}
 }
 
 void _invalidate_dcache(unsigned int addr)
 {
-	if (cpuinfo.use_dcache)
 		__asm__ __volatile__ ("					\
 				wdc	%0, r0"				\
 				:					\

commit 8beb8503bfa305cd7d9efa590517a9c01e2f97b4
Author: Michal Simek <monstr@monstr.eu>
Date:   Fri Mar 27 14:25:16 2009 +0100

    microblaze_v8: cache support
    
    Reviewed-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: Stephen Neuendorffer <stephen.neuendorffer@xilinx.com>
    Acked-by: John Linn <john.linn@xilinx.com>
    Acked-by: John Williams <john.williams@petalogix.com>
    Signed-off-by: Michal Simek <monstr@monstr.eu>

diff --git a/arch/microblaze/kernel/cpu/cache.c b/arch/microblaze/kernel/cpu/cache.c
new file mode 100644
index 000000000000..be9fecca4f91
--- /dev/null
+++ b/arch/microblaze/kernel/cpu/cache.c
@@ -0,0 +1,258 @@
+/*
+ * Cache control for MicroBlaze cache memories
+ *
+ * Copyright (C) 2007-2009 Michal Simek <monstr@monstr.eu>
+ * Copyright (C) 2007-2009 PetaLogix
+ * Copyright (C) 2007 John Williams <john.williams@petalogix.com>
+ *
+ * This file is subject to the terms and conditions of the GNU General
+ * Public License. See the file COPYING in the main directory of this
+ * archive for more details.
+ */
+
+#include <asm/cacheflush.h>
+#include <linux/cache.h>
+#include <asm/cpuinfo.h>
+
+/* Exported functions */
+
+void _enable_icache(void)
+{
+	if (cpuinfo.use_icache) {
+#if CONFIG_XILINX_MICROBLAZE0_USE_MSR_INSTR
+		__asm__ __volatile__ ("					\
+				msrset	r0, %0;				\
+				nop; "					\
+				:					\
+				: "i" (MSR_ICE)				\
+				: "memory");
+#else
+		__asm__ __volatile__ ("					\
+				mfs	r12, rmsr;			\
+				nop;					\
+				ori	r12, r12, %0;			\
+				mts	rmsr, r12;			\
+				nop; "					\
+				:					\
+				: "i" (MSR_ICE)				\
+				: "memory", "r12");
+#endif
+	}
+}
+
+void _disable_icache(void)
+{
+	if (cpuinfo.use_icache) {
+#if CONFIG_XILINX_MICROBLAZE0_USE_MSR_INSTR
+		__asm__ __volatile__ ("					\
+				msrclr r0, %0;				\
+				nop; "					\
+				:					\
+				: "i" (MSR_ICE)				\
+				: "memory");
+#else
+		__asm__ __volatile__ ("					\
+				mfs	r12, rmsr;			\
+				nop;					\
+				andi	r12, r12, ~%0;			\
+				mts	rmsr, r12;			\
+				nop; "					\
+				:					\
+				: "i" (MSR_ICE)				\
+				: "memory", "r12");
+#endif
+	}
+}
+
+void _invalidate_icache(unsigned int addr)
+{
+	if (cpuinfo.use_icache) {
+		__asm__ __volatile__ ("					\
+				wic	%0, r0"				\
+				:					\
+				: "r" (addr));
+	}
+}
+
+void _enable_dcache(void)
+{
+	if (cpuinfo.use_dcache) {
+#if CONFIG_XILINX_MICROBLAZE0_USE_MSR_INSTR
+		__asm__ __volatile__ ("					\
+				msrset	r0, %0;				\
+				nop; "					\
+				:					\
+				: "i" (MSR_DCE)				\
+				: "memory");
+#else
+		__asm__ __volatile__ ("					\
+				mfs	r12, rmsr;			\
+				nop;					\
+				ori	r12, r12, %0;			\
+				mts	rmsr, r12;			\
+				nop; "					\
+				:					\
+				: "i" (MSR_DCE)			\
+				: "memory", "r12");
+#endif
+	}
+}
+
+void _disable_dcache(void)
+{
+	if (cpuinfo.use_dcache) {
+#if CONFIG_XILINX_MICROBLAZE0_USE_MSR_INSTR
+		__asm__ __volatile__ ("					\
+				msrclr	r0, %0;				\
+				nop; "					\
+				:					\
+				: "i" (MSR_DCE)			\
+				: "memory");
+#else
+		__asm__ __volatile__ ("					\
+				mfs	r12, rmsr;			\
+				nop;					\
+				andi	r12, r12, ~%0;			\
+				mts	rmsr, r12;			\
+				nop; "					\
+				:					\
+				: "i" (MSR_DCE)			\
+				: "memory", "r12");
+#endif
+	}
+}
+
+void _invalidate_dcache(unsigned int addr)
+{
+	if (cpuinfo.use_dcache)
+		__asm__ __volatile__ ("					\
+				wdc	%0, r0"				\
+				:					\
+				: "r" (addr));
+}
+
+void __invalidate_icache_all(void)
+{
+	unsigned int i;
+	unsigned flags;
+
+	if (cpuinfo.use_icache) {
+		local_irq_save(flags);
+		__disable_icache();
+
+		/* Just loop through cache size and invalidate, no need to add
+			CACHE_BASE address */
+		for (i = 0; i < cpuinfo.icache_size;
+			i += cpuinfo.icache_line)
+				__invalidate_icache(i);
+
+		__enable_icache();
+		local_irq_restore(flags);
+	}
+}
+
+void __invalidate_icache_range(unsigned long start, unsigned long end)
+{
+	unsigned int i;
+	unsigned flags;
+	unsigned int align;
+
+	if (cpuinfo.use_icache) {
+		/*
+		 * No need to cover entire cache range,
+		 * just cover cache footprint
+		 */
+		end = min(start + cpuinfo.icache_size, end);
+		align = ~(cpuinfo.icache_line - 1);
+		start &= align; /* Make sure we are aligned */
+		/* Push end up to the next cache line */
+		end = ((end & align) + cpuinfo.icache_line);
+
+		local_irq_save(flags);
+		__disable_icache();
+
+		for (i = start; i < end; i += cpuinfo.icache_line)
+			__invalidate_icache(i);
+
+		__enable_icache();
+		local_irq_restore(flags);
+	}
+}
+
+void __invalidate_icache_page(struct vm_area_struct *vma, struct page *page)
+{
+	__invalidate_icache_all();
+}
+
+void __invalidate_icache_user_range(struct vm_area_struct *vma,
+				struct page *page, unsigned long adr,
+				int len)
+{
+	__invalidate_icache_all();
+}
+
+void __invalidate_cache_sigtramp(unsigned long addr)
+{
+	__invalidate_icache_range(addr, addr + 8);
+}
+
+void __invalidate_dcache_all(void)
+{
+	unsigned int i;
+	unsigned flags;
+
+	if (cpuinfo.use_dcache) {
+		local_irq_save(flags);
+		__disable_dcache();
+
+		/*
+		 * Just loop through cache size and invalidate,
+		 * no need to add CACHE_BASE address
+		 */
+		for (i = 0; i < cpuinfo.dcache_size;
+			i += cpuinfo.dcache_line)
+				__invalidate_dcache(i);
+
+		__enable_dcache();
+		local_irq_restore(flags);
+	}
+}
+
+void __invalidate_dcache_range(unsigned long start, unsigned long end)
+{
+	unsigned int i;
+	unsigned flags;
+	unsigned int align;
+
+	if (cpuinfo.use_dcache) {
+		/*
+		 * No need to cover entire cache range,
+		 * just cover cache footprint
+		 */
+		end = min(start + cpuinfo.dcache_size, end);
+		align = ~(cpuinfo.dcache_line - 1);
+		start &= align; /* Make sure we are aligned */
+		/* Push end up to the next cache line */
+		end = ((end & align) + cpuinfo.dcache_line);
+		local_irq_save(flags);
+		__disable_dcache();
+
+		for (i = start; i < end; i += cpuinfo.dcache_line)
+			__invalidate_dcache(i);
+
+		__enable_dcache();
+		local_irq_restore(flags);
+	}
+}
+
+void __invalidate_dcache_page(struct vm_area_struct *vma, struct page *page)
+{
+	__invalidate_dcache_all();
+}
+
+void __invalidate_dcache_user_range(struct vm_area_struct *vma,
+				struct page *page, unsigned long adr,
+				int len)
+{
+	__invalidate_dcache_all();
+}
