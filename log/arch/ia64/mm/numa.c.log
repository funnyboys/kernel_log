commit 9a626c4a6326da4433a0d4d4a8a7d1571caf1ed3
Author: Randy Dunlap <rdunlap@infradead.org>
Date:   Tue May 28 09:14:30 2019 -0700

    ia64: fix build errors by exporting paddr_to_nid()
    
    Fix build errors on ia64 when DISCONTIGMEM=y and NUMA=y by
    exporting paddr_to_nid().
    
    Fixes these build errors:
    
    ERROR: "paddr_to_nid" [sound/core/snd-pcm.ko] undefined!
    ERROR: "paddr_to_nid" [net/sunrpc/sunrpc.ko] undefined!
    ERROR: "paddr_to_nid" [fs/cifs/cifs.ko] undefined!
    ERROR: "paddr_to_nid" [drivers/video/fbdev/core/fb.ko] undefined!
    ERROR: "paddr_to_nid" [drivers/usb/mon/usbmon.ko] undefined!
    ERROR: "paddr_to_nid" [drivers/usb/core/usbcore.ko] undefined!
    ERROR: "paddr_to_nid" [drivers/md/raid1.ko] undefined!
    ERROR: "paddr_to_nid" [drivers/md/dm-mod.ko] undefined!
    ERROR: "paddr_to_nid" [drivers/md/dm-crypt.ko] undefined!
    ERROR: "paddr_to_nid" [drivers/md/dm-bufio.ko] undefined!
    ERROR: "paddr_to_nid" [drivers/ide/ide-core.ko] undefined!
    ERROR: "paddr_to_nid" [drivers/ide/ide-cd_mod.ko] undefined!
    ERROR: "paddr_to_nid" [drivers/gpu/drm/drm.ko] undefined!
    ERROR: "paddr_to_nid" [drivers/char/agp/agpgart.ko] undefined!
    ERROR: "paddr_to_nid" [drivers/block/nbd.ko] undefined!
    ERROR: "paddr_to_nid" [drivers/block/loop.ko] undefined!
    ERROR: "paddr_to_nid" [drivers/block/brd.ko] undefined!
    ERROR: "paddr_to_nid" [crypto/ccm.ko] undefined!
    
    Reported-by: kbuild test robot <lkp@intel.com>
    Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: linux-ia64@vger.kernel.org
    Signed-off-by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/mm/numa.c b/arch/ia64/mm/numa.c
index a03803506b0c..5e1015eb6d0d 100644
--- a/arch/ia64/mm/numa.c
+++ b/arch/ia64/mm/numa.c
@@ -55,6 +55,7 @@ paddr_to_nid(unsigned long paddr)
 
 	return (i < num_node_memblks) ? node_memblk[i].nid : (num_node_memblks ? -1 : 0);
 }
+EXPORT_SYMBOL(paddr_to_nid);
 
 #if defined(CONFIG_SPARSEMEM) && defined(CONFIG_NUMA)
 /*

commit ef78e5ec9214376c5cb989f5da70b02d0c117b66
Author: Matias Bjørling <mb@lightnvm.io>
Date:   Mon Nov 26 11:27:03 2018 -0800

    ia64: export node_distance function
    
    The numa_slit variable used by node_distance is available to a
    module as long as it is linked at compile-time. However, it is
    not available to loadable modules. Leading to errors such as:
    
      ERROR: "numa_slit" [drivers/nvme/host/nvme-core.ko] undefined!
    
    The error above is caused by the nvme multipath code that makes
    use of node_distance for its path calculation. When the patch was
    added, the lightnvm subsystem would select nvme and always compile
    it in, leading to the node_distance call to always succeed.
    However, when this requirement was removed, nvme could be compiled
    in as a module, which exposed this bug.
    
    This patch extracts node_distance to a function and exports it.
    Since ACPI is depending on node_distance being a simple lookup to
    numa_slit, the previous behavior is exposed as slit_distance and its
    users updated.
    
    Fixes: f333444708f82 "nvme: take node locality into account when selecting a path"
    Fixes: 73569e11032f "lightnvm: remove dependencies on BLK_DEV_NVME and PCI"
    Signed-off-by: Matias Bjøring <mb@lightnvm.io>
    Signed-off-by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/mm/numa.c b/arch/ia64/mm/numa.c
index 3861d6e32d5f..a03803506b0c 100644
--- a/arch/ia64/mm/numa.c
+++ b/arch/ia64/mm/numa.c
@@ -36,6 +36,12 @@ struct node_cpuid_s node_cpuid[NR_CPUS] =
  */
 u8 numa_slit[MAX_NUMNODES * MAX_NUMNODES];
 
+int __node_distance(int from, int to)
+{
+	return slit_distance(from, to);
+}
+EXPORT_SYMBOL(__node_distance);
+
 /* Identify which cnode a physical address resides on */
 int
 paddr_to_nid(unsigned long paddr)

commit 57c8a661d95dff48dd9c2f2496139082bbaf241a
Author: Mike Rapoport <rppt@linux.vnet.ibm.com>
Date:   Tue Oct 30 15:09:49 2018 -0700

    mm: remove include/linux/bootmem.h
    
    Move remaining definitions and declarations from include/linux/bootmem.h
    into include/linux/memblock.h and remove the redundant header.
    
    The includes were replaced with the semantic patch below and then
    semi-automated removal of duplicated '#include <linux/memblock.h>
    
    @@
    @@
    - #include <linux/bootmem.h>
    + #include <linux/memblock.h>
    
    [sfr@canb.auug.org.au: dma-direct: fix up for the removal of linux/bootmem.h]
      Link: http://lkml.kernel.org/r/20181002185342.133d1680@canb.auug.org.au
    [sfr@canb.auug.org.au: powerpc: fix up for removal of linux/bootmem.h]
      Link: http://lkml.kernel.org/r/20181005161406.73ef8727@canb.auug.org.au
    [sfr@canb.auug.org.au: x86/kaslr, ACPI/NUMA: fix for linux/bootmem.h removal]
      Link: http://lkml.kernel.org/r/20181008190341.5e396491@canb.auug.org.au
    Link: http://lkml.kernel.org/r/1536927045-23536-30-git-send-email-rppt@linux.vnet.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Ley Foon Tan <lftan@altera.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Palmer Dabbelt <palmer@sifive.com>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Serge Semin <fancer.lancer@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/mm/numa.c b/arch/ia64/mm/numa.c
index aa19b7ac8222..3861d6e32d5f 100644
--- a/arch/ia64/mm/numa.c
+++ b/arch/ia64/mm/numa.c
@@ -15,7 +15,7 @@
 #include <linux/mm.h>
 #include <linux/node.h>
 #include <linux/init.h>
-#include <linux/bootmem.h>
+#include <linux/memblock.h>
 #include <linux/module.h>
 #include <asm/mmzone.h>
 #include <asm/numa.h>

commit 8a942fdea560d4ac0e9d9fabcd5201ad20e0c382
Author: Mel Gorman <mgorman@suse.de>
Date:   Tue Jun 30 14:56:55 2015 -0700

    mm: meminit: make __early_pfn_to_nid SMP-safe and introduce meminit_pfn_in_nid
    
    __early_pfn_to_nid() use static variables to cache recent lookups as
    memblock lookups are very expensive but it assumes that memory
    initialisation is single-threaded.  Parallel initialisation of struct
    pages will break that assumption so this patch makes __early_pfn_to_nid()
    SMP-safe by requiring the caller to cache recent search information.
    early_pfn_to_nid() keeps the same interface but is only safe to use early
    in boot due to the use of a global static variable.  meminit_pfn_in_nid()
    is an SMP-safe version that callers must maintain their own state for.
    
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Tested-by: Nate Zimmer <nzimmer@sgi.com>
    Tested-by: Waiman Long <waiman.long@hp.com>
    Tested-by: Daniel J Blueman <daniel@numascale.com>
    Acked-by: Pekka Enberg <penberg@kernel.org>
    Cc: Robin Holt <robinmholt@gmail.com>
    Cc: Nate Zimmer <nzimmer@sgi.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Waiman Long <waiman.long@hp.com>
    Cc: Scott Norton <scott.norton@hp.com>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/mm/numa.c b/arch/ia64/mm/numa.c
index ea21d4cad540..aa19b7ac8222 100644
--- a/arch/ia64/mm/numa.c
+++ b/arch/ia64/mm/numa.c
@@ -58,27 +58,22 @@ paddr_to_nid(unsigned long paddr)
  * SPARSEMEM to allocate the SPARSEMEM sectionmap on the NUMA node where
  * the section resides.
  */
-int __meminit __early_pfn_to_nid(unsigned long pfn)
+int __meminit __early_pfn_to_nid(unsigned long pfn,
+					struct mminit_pfnnid_cache *state)
 {
 	int i, section = pfn >> PFN_SECTION_SHIFT, ssec, esec;
-	/*
-	 * NOTE: The following SMP-unsafe globals are only used early in boot
-	 * when the kernel is running single-threaded.
-	 */
-	static int __meminitdata last_ssec, last_esec;
-	static int __meminitdata last_nid;
 
-	if (section >= last_ssec && section < last_esec)
-		return last_nid;
+	if (section >= state->last_start && section < state->last_end)
+		return state->last_nid;
 
 	for (i = 0; i < num_node_memblks; i++) {
 		ssec = node_memblk[i].start_paddr >> PA_SECTION_SHIFT;
 		esec = (node_memblk[i].start_paddr + node_memblk[i].size +
 			((1L << PA_SECTION_SHIFT) - 1)) >> PA_SECTION_SHIFT;
 		if (section >= ssec && section < esec) {
-			last_ssec = ssec;
-			last_esec = esec;
-			last_nid = node_memblk[i].nid;
+			state->last_start = ssec;
+			state->last_end = esec;
+			state->last_nid = node_memblk[i].nid;
 			return node_memblk[i].nid;
 		}
 	}

commit ccce9bb83ed20bca52f82ff9d7cf889d23a2ec01
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Mon Jun 17 15:51:20 2013 -0400

    [IA64] Delete __cpuinit usage from all ia64 users
    
    The __cpuinit type of throwaway sections might have made sense
    some time ago when RAM was more constrained, but now the savings
    do not offset the cost and complications.  For example, the fix in
    commit 5e427ec2d0 ("x86: Fix bit corruption at CPU resume time")
    is a good example of the nasty type of bugs that can be created
    with improper use of the various __init prefixes.
    
    After a discussion on LKML[1] it was decided that cpuinit should go
    the way of devinit and be phased out.  Once all the users are gone,
    we can then finally remove the macros themselves from linux/init.h.
    
    This removes all the ia64 uses of the __cpuinit macros.
    
    [1] https://lkml.org/lkml/2013/5/20/589
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/mm/numa.c b/arch/ia64/mm/numa.c
index 4248492b9321..ea21d4cad540 100644
--- a/arch/ia64/mm/numa.c
+++ b/arch/ia64/mm/numa.c
@@ -86,7 +86,7 @@ int __meminit __early_pfn_to_nid(unsigned long pfn)
 	return -1;
 }
 
-void __cpuinit numa_clear_node(int cpu)
+void numa_clear_node(int cpu)
 {
 	unmap_cpu_from_node(cpu, NUMA_NO_NODE);
 }

commit 7c243c7168dcc1bc2081fc0494923cd7cc808fb6
Author: Russ Anderson <rja@sgi.com>
Date:   Mon Apr 29 15:07:59 2013 -0700

    mm: speedup in __early_pfn_to_nid
    
    When booting on a large memory system, the kernel spends considerable
    time in memmap_init_zone() setting up memory zones.  Analysis shows
    significant time spent in __early_pfn_to_nid().
    
    The routine memmap_init_zone() checks each PFN to verify the nid is
    valid.  __early_pfn_to_nid() sequentially scans the list of pfn ranges
    to find the right range and returns the nid.  This does not scale well.
    On a 4 TB (single rack) system there are 308 memory ranges to scan.  The
    higher the PFN the more time spent sequentially spinning through memory
    ranges.
    
    Since memmap_init_zone() increments pfn, it will almost always be
    looking for the same range as the previous pfn, so check that range
    first.  If it is in the same range, return that nid.  If not, scan the
    list as before.
    
    A 4 TB (single rack) UV1 system takes 512 seconds to get through the
    zone code.  This performance optimization reduces the time by 189
    seconds, a 36% improvement.
    
    A 2 TB (single rack) UV2 system goes from 212.7 seconds to 99.8 seconds,
    a 112.9 second (53%) reduction.
    
    [akpm@linux-foundation.org: make the statics __meminitdata]
    [akpm@linux-foundation.org: fix comment formatting]
    [akpm@linux-foundation.org: fix ia64, per yinghai]
    [akpm@linux-foundation.org: add missing semicolon, per Tony]
    Signed-off-by: Russ Anderson <rja@sgi.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Tested-by: "Luck, Tony" <tony.luck@intel.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Lin Feng <linfeng@cn.fujitsu.com>
    Cc: KOSAKI Motohiro <kosaki.motohiro@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/mm/numa.c b/arch/ia64/mm/numa.c
index def782e31aac..4248492b9321 100644
--- a/arch/ia64/mm/numa.c
+++ b/arch/ia64/mm/numa.c
@@ -61,13 +61,26 @@ paddr_to_nid(unsigned long paddr)
 int __meminit __early_pfn_to_nid(unsigned long pfn)
 {
 	int i, section = pfn >> PFN_SECTION_SHIFT, ssec, esec;
+	/*
+	 * NOTE: The following SMP-unsafe globals are only used early in boot
+	 * when the kernel is running single-threaded.
+	 */
+	static int __meminitdata last_ssec, last_esec;
+	static int __meminitdata last_nid;
+
+	if (section >= last_ssec && section < last_esec)
+		return last_nid;
 
 	for (i = 0; i < num_node_memblks; i++) {
 		ssec = node_memblk[i].start_paddr >> PA_SECTION_SHIFT;
 		esec = (node_memblk[i].start_paddr + node_memblk[i].size +
 			((1L << PA_SECTION_SHIFT) - 1)) >> PA_SECTION_SHIFT;
-		if (section >= ssec && section < esec)
+		if (section >= ssec && section < esec) {
+			last_ssec = ssec;
+			last_esec = esec;
+			last_nid = node_memblk[i].nid;
 			return node_memblk[i].nid;
+		}
 	}
 
 	return -1;

commit eee46b3de715c9a2a25ebf3c135b88a1d73d92c2
Author: Yijing Wang <wangyijing@huawei.com>
Date:   Thu Mar 21 11:50:30 2013 +0800

    Fix build error for numa_clear_node() under IA64
    
    numa_clear_node() function is not implemented under IA64,
    it will be called in unmap_cpu_on_node() in mm/memory_hotplug.c.
    This cause build error under IA64, this patch adds numa_clear_node()
    in IA64 to fix this problem.
    
    [Added __cpuinit notation to numa_clear_node() to keep linker happy -Tony]
    
    Signed-off-by: Yijing Wang <wangyijing@huawei.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/mm/numa.c b/arch/ia64/mm/numa.c
index 3efea7d0a351..def782e31aac 100644
--- a/arch/ia64/mm/numa.c
+++ b/arch/ia64/mm/numa.c
@@ -73,6 +73,11 @@ int __meminit __early_pfn_to_nid(unsigned long pfn)
 	return -1;
 }
 
+void __cpuinit numa_clear_node(int cpu)
+{
+	unmap_cpu_from_node(cpu, NUMA_NO_NODE);
+}
+
 #ifdef CONFIG_MEMORY_HOTPLUG
 /*
  *  SRAT information is stored in node_memblk[], then we can use SRAT

commit b3f2f6cd1ff935ecac9a5346904b899d7af689fe
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun May 30 10:08:03 2010 -0700

    ia64: revert __node_random addition
    
    This partially reverts commit 4ec37de89d8c758ee8115e0e64b3f994910789ee
    ("[IA64] Fix build breakage"), since the commit that made it necessary
    got reverted earlier (see commit 35926ff5fba8, 'Revert "cpusets:
    randomize node rotor used in cpuset_mem_spread_node()"')
    
    Even if we ever re-introduce this, there is no reason to make
    __node_random be some architecture-specific function.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/mm/numa.c b/arch/ia64/mm/numa.c
index 2437718bd6b1..3efea7d0a351 100644
--- a/arch/ia64/mm/numa.c
+++ b/arch/ia64/mm/numa.c
@@ -17,7 +17,6 @@
 #include <linux/init.h>
 #include <linux/bootmem.h>
 #include <linux/module.h>
-#include <linux/random.h>
 #include <asm/mmzone.h>
 #include <asm/numa.h>
 
@@ -51,22 +50,6 @@ paddr_to_nid(unsigned long paddr)
 	return (i < num_node_memblks) ? node_memblk[i].nid : (num_node_memblks ? -1 : 0);
 }
 
-/*
- * Return the bit number of a random bit set in the nodemask.
- *   (returns -1 if nodemask is empty)
- */
-int __node_random(const nodemask_t *maskp)
-{
-	int w, bit = -1;
-
-	w = nodes_weight(*maskp);
-	if (w)
-		bit = bitmap_ord_to_pos(maskp->bits,
-			get_random_int() % w, MAX_NUMNODES);
-	return bit;
-}
-EXPORT_SYMBOL(__node_random);
-
 #if defined(CONFIG_SPARSEMEM) && defined(CONFIG_NUMA)
 /*
  * Because of holes evaluate on section limits.

commit 4ec37de89d8c758ee8115e0e64b3f994910789ee
Author: Tony Luck <tony.luck@intel.com>
Date:   Thu May 27 15:35:13 2010 -0700

    [IA64] Fix build breakage
    
    In commit 0ac0c0d0f837c499afd02a802f9cf52d3027fa3b
    cpusets: randomize node rotor used in cpuset_mem_spread_node()
    
    Jack Steiner fixed a problem with too many small tasks being
    assigned to node 0. Copy his code to ia64 to avoid build error.
    
        arch/ia64/kernel/smpboot.c:641: error: ‘cpu_to_node_map’ undeclared (first use in this function)
    
    In commit 3bccd996276b108c138e8176793a26ecef54d573
    numa: ia64: use generic percpu var numa_node_id() implementation
    
    Lee Schermerhorn added some set_numa_node() calls - but these
    only work on CONFIG_NUMA=y configurations. Surround the calls
    with #ifdef CONFIG_NUMA
    
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/mm/numa.c b/arch/ia64/mm/numa.c
index 3efea7d0a351..2437718bd6b1 100644
--- a/arch/ia64/mm/numa.c
+++ b/arch/ia64/mm/numa.c
@@ -17,6 +17,7 @@
 #include <linux/init.h>
 #include <linux/bootmem.h>
 #include <linux/module.h>
+#include <linux/random.h>
 #include <asm/mmzone.h>
 #include <asm/numa.h>
 
@@ -50,6 +51,22 @@ paddr_to_nid(unsigned long paddr)
 	return (i < num_node_memblks) ? node_memblk[i].nid : (num_node_memblks ? -1 : 0);
 }
 
+/*
+ * Return the bit number of a random bit set in the nodemask.
+ *   (returns -1 if nodemask is empty)
+ */
+int __node_random(const nodemask_t *maskp)
+{
+	int w, bit = -1;
+
+	w = nodes_weight(*maskp);
+	if (w)
+		bit = bitmap_ord_to_pos(maskp->bits,
+			get_random_int() % w, MAX_NUMNODES);
+	return bit;
+}
+EXPORT_SYMBOL(__node_random);
+
 #if defined(CONFIG_SPARSEMEM) && defined(CONFIG_NUMA)
 /*
  * Because of holes evaluate on section limits.

commit cc2559bccc72767cb446f79b071d96c30c26439b
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Wed Feb 18 14:48:33 2009 -0800

    mm: fix memmap init for handling memory hole
    
    Now, early_pfn_in_nid(PFN, NID) may returns false if PFN is a hole.
    and memmap initialization was not done. This was a trouble for
    sparc boot.
    
    To fix this, the PFN should be initialized and marked as PG_reserved.
    This patch changes early_pfn_in_nid() return true if PFN is a hole.
    
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Reported-by: David Miller <davem@davemlloft.net>
    Tested-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: <stable@kernel.org>         [2.6.25.x, 2.6.26.x, 2.6.27.x, 2.6.28.x]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/mm/numa.c b/arch/ia64/mm/numa.c
index 5061c3fb6796..3efea7d0a351 100644
--- a/arch/ia64/mm/numa.c
+++ b/arch/ia64/mm/numa.c
@@ -70,7 +70,7 @@ int __meminit __early_pfn_to_nid(unsigned long pfn)
 			return node_memblk[i].nid;
 	}
 
-	return 0;
+	return -1;
 }
 
 #ifdef CONFIG_MEMORY_HOTPLUG

commit f2dbcfa738368c8a40d4a5f0b65dc9879577cb21
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Wed Feb 18 14:48:32 2009 -0800

    mm: clean up for early_pfn_to_nid()
    
    What's happening is that the assertion in mm/page_alloc.c:move_freepages()
    is triggering:
    
            BUG_ON(page_zone(start_page) != page_zone(end_page));
    
    Once I knew this is what was happening, I added some annotations:
    
            if (unlikely(page_zone(start_page) != page_zone(end_page))) {
                    printk(KERN_ERR "move_freepages: Bogus zones: "
                           "start_page[%p] end_page[%p] zone[%p]\n",
                           start_page, end_page, zone);
                    printk(KERN_ERR "move_freepages: "
                           "start_zone[%p] end_zone[%p]\n",
                           page_zone(start_page), page_zone(end_page));
                    printk(KERN_ERR "move_freepages: "
                           "start_pfn[0x%lx] end_pfn[0x%lx]\n",
                           page_to_pfn(start_page), page_to_pfn(end_page));
                    printk(KERN_ERR "move_freepages: "
                           "start_nid[%d] end_nid[%d]\n",
                           page_to_nid(start_page), page_to_nid(end_page));
     ...
    
    And here's what I got:
    
            move_freepages: Bogus zones: start_page[2207d0000] end_page[2207dffc0] zone[fffff8103effcb00]
            move_freepages: start_zone[fffff8103effcb00] end_zone[fffff8003fffeb00]
            move_freepages: start_pfn[0x81f600] end_pfn[0x81f7ff]
            move_freepages: start_nid[1] end_nid[0]
    
    My memory layout on this box is:
    
    [    0.000000] Zone PFN ranges:
    [    0.000000]   Normal   0x00000000 -> 0x0081ff5d
    [    0.000000] Movable zone start PFN for each node
    [    0.000000] early_node_map[8] active PFN ranges
    [    0.000000]     0: 0x00000000 -> 0x00020000
    [    0.000000]     1: 0x00800000 -> 0x0081f7ff
    [    0.000000]     1: 0x0081f800 -> 0x0081fe50
    [    0.000000]     1: 0x0081fed1 -> 0x0081fed8
    [    0.000000]     1: 0x0081feda -> 0x0081fedb
    [    0.000000]     1: 0x0081fedd -> 0x0081fee5
    [    0.000000]     1: 0x0081fee7 -> 0x0081ff51
    [    0.000000]     1: 0x0081ff59 -> 0x0081ff5d
    
    So it's a block move in that 0x81f600-->0x81f7ff region which triggers
    the problem.
    
    This patch:
    
    Declaration of early_pfn_to_nid() is scattered over per-arch include
    files, and it seems it's complicated to know when the declaration is used.
     I think it makes fix-for-memmap-init not easy.
    
    This patch moves all declaration to include/linux/mm.h
    
    After this,
      if !CONFIG_NODES_POPULATES_NODE_MAP && !CONFIG_HAVE_ARCH_EARLY_PFN_TO_NID
         -> Use static definition in include/linux/mm.h
      else if !CONFIG_HAVE_ARCH_EARLY_PFN_TO_NID
         -> Use generic definition in mm/page_alloc.c
      else
         -> per-arch back end function will be called.
    
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Tested-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Reported-by: David Miller <davem@davemlloft.net>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: <stable@kernel.org>         [2.6.25.x, 2.6.26.x, 2.6.27.x, 2.6.28.x]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/mm/numa.c b/arch/ia64/mm/numa.c
index b73bf1838e57..5061c3fb6796 100644
--- a/arch/ia64/mm/numa.c
+++ b/arch/ia64/mm/numa.c
@@ -58,7 +58,7 @@ paddr_to_nid(unsigned long paddr)
  * SPARSEMEM to allocate the SPARSEMEM sectionmap on the NUMA node where
  * the section resides.
  */
-int early_pfn_to_nid(unsigned long pfn)
+int __meminit __early_pfn_to_nid(unsigned long pfn)
 {
 	int i, section = pfn >> PFN_SECTION_SHIFT, ssec, esec;
 

commit 2c6e6db41f01b6b4eb98809350827c9678996698
Author: holt@sgi.com <holt@sgi.com>
Date:   Thu Apr 3 15:17:13 2008 -0500

    [IA64] Minimize per_cpu reservations.
    
    This attached patch significantly shrinks boot memory allocation on ia64.
    It does this by not allocating per_cpu areas for cpus that can never
    exist.
    
    In the case where acpi does not have any numa node description of the
    cpus, I defaulted to assigning the first 32 round-robin on the known
    nodes..  For the !CONFIG_ACPI  I used for_each_possible_cpu().
    
    Signed-off-by: Robin Holt <holt@sgi.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/mm/numa.c b/arch/ia64/mm/numa.c
index 7807fc5c0422..b73bf1838e57 100644
--- a/arch/ia64/mm/numa.c
+++ b/arch/ia64/mm/numa.c
@@ -27,7 +27,9 @@
  */
 int num_node_memblks;
 struct node_memblk_s node_memblk[NR_NODE_MEMBLKS];
-struct node_cpuid_s node_cpuid[NR_CPUS];
+struct node_cpuid_s node_cpuid[NR_CPUS] =
+	{ [0 ... NR_CPUS-1] = { .phys_id = 0, .nid = NUMA_NO_NODE } };
+
 /*
  * This is a matrix with "distances" between nodes, they should be
  * proportional to the memory access latency ratios.

commit 8c2676a5870ab15cbeea9f826266bc946fe3cc26
Author: Keith Mannthey <kmannth@us.ibm.com>
Date:   Sat Sep 30 23:27:07 2006 -0700

    [PATCH] hot-add-mem x86_64: memory_add_physaddr_to_nid node fixup
    
    In cases where the acpi memory-add event does not containe the pxm (node)
    infomation allow the driver to look up node info based on the address.  The
    acpi_get_node call returns -1 if it can't decode the pxm info, this causes
    add_memory to panic.  acpi_get_node would have to decode the resource from the
    handle (a lenghty proposition).  This seems to be the cleanist point to
    interject the hook.
    
    [kamezawa.hiroyu@jp.fujitsu.com: build fixes]
    [y-goto@jp.fujitsu.com: build fixes]
    Signed-off-by: Keith Mannthey <kmannth@us.ibm.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Andi Kleen <ak@muc.de>
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Yasunori Goto <y-goto@jp.fujitsu.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/ia64/mm/numa.c b/arch/ia64/mm/numa.c
index 64e4c21f311c..7807fc5c0422 100644
--- a/arch/ia64/mm/numa.c
+++ b/arch/ia64/mm/numa.c
@@ -16,6 +16,7 @@
 #include <linux/node.h>
 #include <linux/init.h>
 #include <linux/bootmem.h>
+#include <linux/module.h>
 #include <asm/mmzone.h>
 #include <asm/numa.h>
 
@@ -69,4 +70,21 @@ int early_pfn_to_nid(unsigned long pfn)
 
 	return 0;
 }
+
+#ifdef CONFIG_MEMORY_HOTPLUG
+/*
+ *  SRAT information is stored in node_memblk[], then we can use SRAT
+ *  information at memory-hot-add if necessary.
+ */
+
+int memory_add_physaddr_to_nid(u64 addr)
+{
+	int nid = paddr_to_nid(addr);
+	if (nid < 0)
+		return 0;
+	return nid;
+}
+
+EXPORT_SYMBOL_GPL(memory_add_physaddr_to_nid);
+#endif
 #endif

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: Jörn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: Jörn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/arch/ia64/mm/numa.c b/arch/ia64/mm/numa.c
index 4e5c8b36ad93..64e4c21f311c 100644
--- a/arch/ia64/mm/numa.c
+++ b/arch/ia64/mm/numa.c
@@ -10,7 +10,6 @@
  *                         2002/08/07 Erich Focht <efocht@ess.nec.de>
  */
 
-#include <linux/config.h>
 #include <linux/cpu.h>
 #include <linux/kernel.h>
 #include <linux/mm.h>

commit 2d4b1fa234417b902c9d3034442387c1805bfa7b
Author: Bob Picco <bob.picco@hp.com>
Date:   Tue Oct 4 15:13:57 2005 -0400

    [PATCH] V5 ia64 SPARSEMEM - SPARSEMEM code changes
    
    This patch is the minimal set of changes required by ia64 to use SPARSEMEM.
    
    Signed-off-by: Bob Picco <bob.picco@hp.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/mm/numa.c b/arch/ia64/mm/numa.c
index 77118bbf3d8b..4e5c8b36ad93 100644
--- a/arch/ia64/mm/numa.c
+++ b/arch/ia64/mm/numa.c
@@ -47,3 +47,27 @@ paddr_to_nid(unsigned long paddr)
 
 	return (i < num_node_memblks) ? node_memblk[i].nid : (num_node_memblks ? -1 : 0);
 }
+
+#if defined(CONFIG_SPARSEMEM) && defined(CONFIG_NUMA)
+/*
+ * Because of holes evaluate on section limits.
+ * If the section of memory exists, then return the node where the section
+ * resides.  Otherwise return node 0 as the default.  This is used by
+ * SPARSEMEM to allocate the SPARSEMEM sectionmap on the NUMA node where
+ * the section resides.
+ */
+int early_pfn_to_nid(unsigned long pfn)
+{
+	int i, section = pfn >> PFN_SECTION_SHIFT, ssec, esec;
+
+	for (i = 0; i < num_node_memblks; i++) {
+		ssec = node_memblk[i].start_paddr >> PA_SECTION_SHIFT;
+		esec = (node_memblk[i].start_paddr + node_memblk[i].size +
+			((1L << PA_SECTION_SHIFT) - 1)) >> PA_SECTION_SHIFT;
+		if (section >= ssec && section < esec)
+			return node_memblk[i].nid;
+	}
+
+	return 0;
+}
+#endif

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/arch/ia64/mm/numa.c b/arch/ia64/mm/numa.c
new file mode 100644
index 000000000000..77118bbf3d8b
--- /dev/null
+++ b/arch/ia64/mm/numa.c
@@ -0,0 +1,49 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * This file contains NUMA specific variables and functions which can
+ * be split away from DISCONTIGMEM and are used on NUMA machines with
+ * contiguous memory.
+ * 
+ *                         2002/08/07 Erich Focht <efocht@ess.nec.de>
+ */
+
+#include <linux/config.h>
+#include <linux/cpu.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/node.h>
+#include <linux/init.h>
+#include <linux/bootmem.h>
+#include <asm/mmzone.h>
+#include <asm/numa.h>
+
+
+/*
+ * The following structures are usually initialized by ACPI or
+ * similar mechanisms and describe the NUMA characteristics of the machine.
+ */
+int num_node_memblks;
+struct node_memblk_s node_memblk[NR_NODE_MEMBLKS];
+struct node_cpuid_s node_cpuid[NR_CPUS];
+/*
+ * This is a matrix with "distances" between nodes, they should be
+ * proportional to the memory access latency ratios.
+ */
+u8 numa_slit[MAX_NUMNODES * MAX_NUMNODES];
+
+/* Identify which cnode a physical address resides on */
+int
+paddr_to_nid(unsigned long paddr)
+{
+	int	i;
+
+	for (i = 0; i < num_node_memblks; i++)
+		if (paddr >= node_memblk[i].start_paddr &&
+		    paddr < node_memblk[i].start_paddr + node_memblk[i].size)
+			break;
+
+	return (i < num_node_memblks) ? node_memblk[i].nid : (num_node_memblks ? -1 : 0);
+}
