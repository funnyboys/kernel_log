commit 90341cd8e0a9c2ec190a0cb2d9c3bc89a25eef6d
Author: afzal mohammed <afzal.mohd.ma@gmail.com>
Date:   Sun Mar 8 17:33:49 2020 +0530

    ia64: replace setup_irq() by request_irq()
    
    request_irq() is preferred over setup_irq(). Invocations of setup_irq()
    occur after memory allocators are ready.
    
    Per tglx[1], setup_irq() existed in olden days when allocators were not
    ready by the time early interrupts were initialized.
    
    Hence replace setup_irq() by request_irq().
    
    Changing 'ia64_native_register_percpu_irq' decleration to include
    'irq_handler_t' as an argument type in arch/ia64/include/asm/hw_irq.h
    was causing build error - 'unknown type name 'irq_handler_t''
    
    This was due to below header file sequence,
    + include/interrupt.h
     + include/hardirq.h
      + asm/hardirq.h
       + include/irq.h
        + asm/hw_irq.h
           [ 'ia64_native_register_percpu_irq' declared w/ 'irq_handler_t']
     [ 'irq_handler_t' typedef'ed here in 'include/interrupt.h']
    
    'register_percpu_irq' defined to 'ia64_native_register_percpu_irq' is
    the one invoked by the caller, not the latter directly. This was done
    to support paravirtualization which was removed around 4 years back.
    And 'register_percpu_irq' is invoked only inside 'arch/ia64/kernel'.
    
    So 'register_percpu_irq' define to 'ia64_native_register_percpu_irq' is
    removed, instead 'ia64_native_register_percpu_irq' is renamed to
    'register_precpu_irq()' & it is directly invoked. Also,
    'register_precpu_irq()' is declared in a new header file 'irq.h' inside
    'arch/ia64/kernel/', this header file is included by C files invoking
    'register_percpu_irq()'.
    
    [1] https://lkml.kernel.org/r/alpine.DEB.2.20.1710191609480.1971@nanos
    
    Signed-off-by: afzal mohammed <afzal.mohd.ma@gmail.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 91b4024c9351..7abc5f37bfaf 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -32,6 +32,7 @@
 #include <asm/sections.h>
 
 #include "fsyscall_gtod_data.h"
+#include "irq.h"
 
 static u64 itc_get_cycles(struct clocksource *cs);
 
@@ -380,13 +381,6 @@ static u64 itc_get_cycles(struct clocksource *cs)
 	return now;
 }
 
-
-static struct irqaction timer_irqaction = {
-	.handler =	timer_interrupt,
-	.flags =	IRQF_IRQPOLL,
-	.name =		"timer"
-};
-
 void read_persistent_clock64(struct timespec64 *ts)
 {
 	efi_gettimeofday(ts);
@@ -395,7 +389,8 @@ void read_persistent_clock64(struct timespec64 *ts)
 void __init
 time_init (void)
 {
-	register_percpu_irq(IA64_TIMER_VECTOR, &timer_irqaction);
+	register_percpu_irq(IA64_TIMER_VECTOR, timer_interrupt, IRQF_IRQPOLL,
+			    "timer");
 	ia64_init_itm();
 }
 

commit f83eeb1a01689b2691f6f56629ac9f66de8d41c2
Author: Frederic Weisbecker <frederic@kernel.org>
Date:   Thu Oct 3 18:17:44 2019 +0200

    sched/cputime: Rename vtime_account_system() to vtime_account_kernel()
    
    vtime_account_system() decides if we need to account the time to the
    system (__vtime_account_system()) or to the guest (vtime_account_guest()).
    
    So this function is a misnomer as we are on a higher level than
    "system". All we know when we call that function is that we are
    accounting kernel cputime. Whether it belongs to guest or system time
    is a lower level detail.
    
    Rename this function to vtime_account_kernel(). This will clarify things
    and avoid too many underscored vtime_account_system() versions.
    
    Signed-off-by: Frederic Weisbecker <frederic@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wanpeng Li <wanpengli@tencent.com>
    Cc: Yauheni Kaliuta <yauheni.kaliuta@redhat.com>
    Link: https://lkml.kernel.org/r/20191003161745.28464-2-frederic@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 1e95d32c8877..91b4024c9351 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -132,7 +132,7 @@ static __u64 vtime_delta(struct task_struct *tsk)
 	return delta_stime;
 }
 
-void vtime_account_system(struct task_struct *tsk)
+void vtime_account_kernel(struct task_struct *tsk)
 {
 	struct thread_info *ti = task_thread_info(tsk);
 	__u64 stime = vtime_delta(tsk);
@@ -146,7 +146,7 @@ void vtime_account_system(struct task_struct *tsk)
 	else
 		ti->stime += stime;
 }
-EXPORT_SYMBOL_GPL(vtime_account_system);
+EXPORT_SYMBOL_GPL(vtime_account_kernel);
 
 void vtime_account_idle(struct task_struct *tsk)
 {

commit df41017eafd267c08acbfff99d34e4f96bbfbc92
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Aug 13 09:25:12 2019 +0200

    ia64: remove support for machvecs
    
    The only thing remaining of the machvecs is a few checks if we are
    running on an SGI UV system.  Replace those with the existing
    is_uv_system() check that has been rewritten to simply check the
    OEM ID directly.
    
    That leaves us with a generic kernel that is as fast as the previous
    DIG/ZX1/UV kernels, but can support all hardware.  Support for UV
    and the HP SBA IOMMU is now optional based on new config options.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Link: https://lkml.kernel.org/r/20190813072514.23299-27-hch@lst.de
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index d9ad93a6d825..1e95d32c8877 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -25,7 +25,6 @@
 #include <linux/platform_device.h>
 #include <linux/sched/cputime.h>
 
-#include <asm/machvec.h>
 #include <asm/delay.h>
 #include <asm/hw_irq.h>
 #include <asm/ptrace.h>

commit 05933aac7b11911955de307a329dc2a7a14b7bd0
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Aug 13 09:25:02 2019 +0200

    ia64: remove now unused machvec indirections
    
    With the SGI SN2 machvec removal most of the indirections are unused
    now, so remove them.  This includes the entire removal of the mmio
    read*/write* macros as the generic ones are identical to the
    asm-generic/io.h version.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Link: https://lkml.kernel.org/r/20190813072514.23299-17-hch@lst.de
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 4ecd81b0e8ec..d9ad93a6d825 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -167,8 +167,6 @@ timer_interrupt (int irq, void *dev_id)
 		return IRQ_HANDLED;
 	}
 
-	platform_timer_interrupt(irq, dev_id);
-
 	new_itm = local_cpu_data->itm_next;
 
 	if (!time_after(ia64_get_itc(), new_itm))

commit 457c89965399115e5cd8bf38f9c597293405703d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun May 19 13:08:55 2019 +0100

    treewide: Add SPDX license identifier for missed files
    
    Add SPDX license identifiers to all files which:
    
     - Have no license information of any form
    
     - Have EXPORT_.*_SYMBOL_GPL inside which was used in the
       initial scan/conversion to ignore the file
    
    These files fall under the project license, GPL v2 only. The resulting SPDX
    license identifier is:
    
      GPL-2.0-only
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 9025699049ca..4ecd81b0e8ec 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0-only
 /*
  * linux/arch/ia64/kernel/time.c
  *

commit 7729bebc619307a0233c86f8585a4bf3eadc7ce4
Author: Valentin Ilie <valentin.ilie@gmail.com>
Date:   Fri Jan 5 23:12:59 2018 +0000

    ia64, sched/cputime: Fix build error if CONFIG_VIRT_CPU_ACCOUNTING_NATIVE=y
    
    Remove the extra parenthesis.
    
    This bug was introduced by:
    
      e2339a4caa5e: ("ia64: Convert vtime to use nsec units directly")
    
    Signed-off-by: Valentin Ilie <valentin.ilie@gmail.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: fenghua.yu@intel.com
    Cc: linux-ia64@vger.kernel.org
    Cc: tony.luck@intel.com
    Link: http://lkml.kernel.org/r/1515193979-24873-1-git-send-email-valentin.ilie@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index c6ecb97151a2..9025699049ca 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -88,7 +88,7 @@ void vtime_flush(struct task_struct *tsk)
 	}
 
 	if (ti->softirq_time) {
-		delta = cycle_to_nsec(ti->softirq_time));
+		delta = cycle_to_nsec(ti->softirq_time);
 		account_system_index_time(tsk, delta, CPUTIME_SOFTIRQ);
 	}
 

commit d4d1fc61eb38ff8e5af657e2d2f2290859a277f2
Author: Tony Luck <tony.luck@intel.com>
Date:   Tue Oct 31 10:43:39 2017 -0700

    ia64: Update fsyscall gettime to use modern vsyscall_update
    
    John Stultz provided the outline for this patch back in May 2014 here:
    
            http://patches.linaro.org/patch/30501/
    
    but I let this sit on the shelf for too long and in the intervening
    years almost every field in "struct timekeeper" was changed. So this
    is almost completely different from his original. Though the key change
    in arch/ia64/kernel/fsys.S remains the same.
    
    The core logic change with the updated vsyscall method is that we
    preserve the base nanosecond value in shifted nanoseconds, which
    allows us to avoid truncating and rounding up to the next nanosecond
    every tick to avoid inconsistencies.
    
    Thus the logic moved from
    nsec = ((cycle_delta * mult)>>shift) + base_nsec;
    to
    nsec = ((cycle_delta * mult) + base_snsec) >> shift;
    
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: linux-ia64@vger.kernel.org
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index aa7be020a904..c6ecb97151a2 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -430,30 +430,32 @@ void update_vsyscall_tz(void)
 {
 }
 
-void update_vsyscall_old(struct timespec *wall, struct timespec *wtm,
-			 struct clocksource *c, u32 mult, u64 cycle_last)
+void update_vsyscall(struct timekeeper *tk)
 {
 	write_seqcount_begin(&fsyscall_gtod_data.seq);
 
-        /* copy fsyscall clock data */
-        fsyscall_gtod_data.clk_mask = c->mask;
-        fsyscall_gtod_data.clk_mult = mult;
-        fsyscall_gtod_data.clk_shift = c->shift;
-        fsyscall_gtod_data.clk_fsys_mmio = c->archdata.fsys_mmio;
-        fsyscall_gtod_data.clk_cycle_last = cycle_last;
-
-	/* copy kernel time structures */
-        fsyscall_gtod_data.wall_time.tv_sec = wall->tv_sec;
-        fsyscall_gtod_data.wall_time.tv_nsec = wall->tv_nsec;
-	fsyscall_gtod_data.monotonic_time.tv_sec = wtm->tv_sec
-							+ wall->tv_sec;
-	fsyscall_gtod_data.monotonic_time.tv_nsec = wtm->tv_nsec
-							+ wall->tv_nsec;
+	/* copy vsyscall data */
+	fsyscall_gtod_data.clk_mask = tk->tkr_mono.mask;
+	fsyscall_gtod_data.clk_mult = tk->tkr_mono.mult;
+	fsyscall_gtod_data.clk_shift = tk->tkr_mono.shift;
+	fsyscall_gtod_data.clk_fsys_mmio = tk->tkr_mono.clock->archdata.fsys_mmio;
+	fsyscall_gtod_data.clk_cycle_last = tk->tkr_mono.cycle_last;
+
+	fsyscall_gtod_data.wall_time.sec = tk->xtime_sec;
+	fsyscall_gtod_data.wall_time.snsec = tk->tkr_mono.xtime_nsec;
+
+	fsyscall_gtod_data.monotonic_time.sec = tk->xtime_sec
+					      + tk->wall_to_monotonic.tv_sec;
+	fsyscall_gtod_data.monotonic_time.snsec = tk->tkr_mono.xtime_nsec
+						+ ((u64)tk->wall_to_monotonic.tv_nsec
+							<< tk->tkr_mono.shift);
 
 	/* normalize */
-	while (fsyscall_gtod_data.monotonic_time.tv_nsec >= NSEC_PER_SEC) {
-		fsyscall_gtod_data.monotonic_time.tv_nsec -= NSEC_PER_SEC;
-		fsyscall_gtod_data.monotonic_time.tv_sec++;
+	while (fsyscall_gtod_data.monotonic_time.snsec >=
+					(((u64)NSEC_PER_SEC) << tk->tkr_mono.shift)) {
+		fsyscall_gtod_data.monotonic_time.snsec -=
+					((u64)NSEC_PER_SEC) << tk->tkr_mono.shift;
+		fsyscall_gtod_data.monotonic_time.sec++;
 	}
 
 	write_seqcount_end(&fsyscall_gtod_data.seq);

commit 32ef5517c298042ed58408545f475df43afe1f24
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sun Feb 5 11:48:36 2017 +0100

    sched/headers: Prepare to move cputime functionality from <linux/sched.h> into <linux/sched/cputime.h>
    
    Introduce a trivial, mostly empty <linux/sched/cputime.h> header
    to prepare for the moving of cputime functionality out of sched.h.
    
    Update all code that relies on these facilities.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 144f9db7a876..aa7be020a904 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -22,7 +22,7 @@
 #include <linux/timex.h>
 #include <linux/timekeeper_internal.h>
 #include <linux/platform_device.h>
-#include <linux/cputime.h>
+#include <linux/sched/cputime.h>
 
 #include <asm/machvec.h>
 #include <asm/delay.h>

commit 38b8d208a4544c9a26b10baec89b8a21042e5305
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:31 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/nmi.h>
    
    We are going to move softlockup APIs out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    <linux/nmi.h> already includes <linux/sched.h>.
    
    Include the <linux/nmi.h> header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index faa116822c4c..144f9db7a876 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -16,6 +16,7 @@
 #include <linux/profile.h>
 #include <linux/sched.h>
 #include <linux/time.h>
+#include <linux/nmi.h>
 #include <linux/interrupt.h>
 #include <linux/efi.h>
 #include <linux/timex.h>

commit e2339a4caa5e83a3da5e76880d81e8a23e97aa16
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Jan 31 04:09:45 2017 +0100

    ia64: Convert vtime to use nsec units directly
    
    There is no need anymore for this cputime_t midlayer. Let's use nsec
    units directly.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1485832191-26889-30-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index f15bca4776a7..faa116822c4c 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -60,7 +60,7 @@ static struct clocksource *itc_clocksource;
 
 #include <linux/kernel_stat.h>
 
-extern cputime_t cycle_to_cputime(u64 cyc);
+extern u64 cycle_to_nsec(u64 cyc);
 
 void vtime_flush(struct task_struct *tsk)
 {
@@ -68,26 +68,26 @@ void vtime_flush(struct task_struct *tsk)
 	u64 delta;
 
 	if (ti->utime)
-		account_user_time(tsk, cputime_to_nsecs(cycle_to_cputime(ti->utime)));
+		account_user_time(tsk, cycle_to_nsec(ti->utime));
 
 	if (ti->gtime)
-		account_guest_time(tsk, cputime_to_nsecs(cycle_to_cputime(ti->gtime)));
+		account_guest_time(tsk, cycle_to_nsec(ti->gtime));
 
 	if (ti->idle_time)
-		account_idle_time(cputime_to_nsecs(cycle_to_cputime(ti->idle_time)));
+		account_idle_time(cycle_to_nsec(ti->idle_time));
 
 	if (ti->stime) {
-		delta = cputime_to_nsecs(cycle_to_cputime(ti->stime));
+		delta = cycle_to_nsec(ti->stime);
 		account_system_index_time(tsk, delta, CPUTIME_SYSTEM);
 	}
 
 	if (ti->hardirq_time) {
-		delta = cputime_to_nsecs(cycle_to_cputime(ti->hardirq_time));
+		delta = cycle_to_nsec(ti->hardirq_time);
 		account_system_index_time(tsk, delta, CPUTIME_IRQ);
 	}
 
 	if (ti->softirq_time) {
-		delta = cputime_to_nsecs(cycle_to_cputime(ti->softirq_time));
+		delta = cycle_to_nsec(ti->softirq_time));
 		account_system_index_time(tsk, delta, CPUTIME_SOFTIRQ);
 	}
 

commit fb8b049c988f1ff460b063b8a41ea9a3c79921c2
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Jan 31 04:09:40 2017 +0100

    sched/cputime: Push time to account_system_time() in nsecs
    
    This is one more step toward converting cputime accounting to pure nsecs.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1485832191-26889-25-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 5dc801d97790..f15bca4776a7 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -21,6 +21,7 @@
 #include <linux/timex.h>
 #include <linux/timekeeper_internal.h>
 #include <linux/platform_device.h>
+#include <linux/cputime.h>
 
 #include <asm/machvec.h>
 #include <asm/delay.h>
@@ -64,29 +65,29 @@ extern cputime_t cycle_to_cputime(u64 cyc);
 void vtime_flush(struct task_struct *tsk)
 {
 	struct thread_info *ti = task_thread_info(tsk);
-	cputime_t delta;
+	u64 delta;
 
 	if (ti->utime)
 		account_user_time(tsk, cputime_to_nsecs(cycle_to_cputime(ti->utime)));
 
 	if (ti->gtime)
-		account_guest_time(tsk, cycle_to_cputime(ti->gtime));
+		account_guest_time(tsk, cputime_to_nsecs(cycle_to_cputime(ti->gtime)));
 
 	if (ti->idle_time)
 		account_idle_time(cputime_to_nsecs(cycle_to_cputime(ti->idle_time)));
 
 	if (ti->stime) {
-		delta = cycle_to_cputime(ti->stime);
+		delta = cputime_to_nsecs(cycle_to_cputime(ti->stime));
 		account_system_index_time(tsk, delta, CPUTIME_SYSTEM);
 	}
 
 	if (ti->hardirq_time) {
-		delta = cycle_to_cputime(ti->hardirq_time);
+		delta = cputime_to_nsecs(cycle_to_cputime(ti->hardirq_time));
 		account_system_index_time(tsk, delta, CPUTIME_IRQ);
 	}
 
 	if (ti->softirq_time) {
-		delta = cycle_to_cputime(ti->softirq_time);
+		delta = cputime_to_nsecs(cycle_to_cputime(ti->softirq_time));
 		account_system_index_time(tsk, delta, CPUTIME_SOFTIRQ);
 	}
 

commit 18b43a9bd7ae91185e398dd983fb4fffb9e81b3a
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Jan 31 04:09:39 2017 +0100

    sched/cputime: Push time to account_idle_time() in nsecs
    
    This is one more step toward converting cputime accounting to pure nsecs.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1485832191-26889-24-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index ed98b26047c2..5dc801d97790 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -73,7 +73,7 @@ void vtime_flush(struct task_struct *tsk)
 		account_guest_time(tsk, cycle_to_cputime(ti->gtime));
 
 	if (ti->idle_time)
-		account_idle_time(cycle_to_cputime(ti->idle_time));
+		account_idle_time(cputime_to_nsecs(cycle_to_cputime(ti->idle_time)));
 
 	if (ti->stime) {
 		delta = cycle_to_cputime(ti->stime);

commit 23244a5c8003d4154161a8289a7d3783b0237c08
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Jan 31 04:09:37 2017 +0100

    sched/cputime: Push time to account_user_time() in nsecs
    
    This is one more step toward converting cputime accounting to pure nsecs.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1485832191-26889-22-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index d040f12ea9f9..ed98b26047c2 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -67,7 +67,7 @@ void vtime_flush(struct task_struct *tsk)
 	cputime_t delta;
 
 	if (ti->utime)
-		account_user_time(tsk, cycle_to_cputime(ti->utime));
+		account_user_time(tsk, cputime_to_nsecs(cycle_to_cputime(ti->utime)));
 
 	if (ti->gtime)
 		account_guest_time(tsk, cycle_to_cputime(ti->gtime));

commit c8d7dabf8f91fadd265e6eb87afb201d14ea299b
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Jan 5 18:11:50 2017 +0100

    sched/cputime: Rename vtime_account_user() to vtime_flush()
    
    CONFIG_VIRT_CPU_ACCOUNTING_NATIVE=y used to accumulate user time and
    account it on ticks and context switches only through the
    vtime_account_user() function.
    
    Now this model has been generalized on the 3 archs for all kind of
    cputime (system, irq, ...) and all the cputime flushing happens under
    vtime_account_user().
    
    So let's rename this function to better reflect its new role.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1483636310-6557-11-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 37f1b315d9b6..d040f12ea9f9 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -61,7 +61,7 @@ static struct clocksource *itc_clocksource;
 
 extern cputime_t cycle_to_cputime(u64 cyc);
 
-void vtime_account_user(struct task_struct *tsk)
+void vtime_flush(struct task_struct *tsk)
 {
 	struct thread_info *ti = task_thread_info(tsk);
 	cputime_t delta;

commit 7dd582305d19fd178bb42ecd1666285ecfb1657a
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Jan 5 18:11:48 2017 +0100

    sched/cputime, ia64: Accumulate cputime and account only on tick/task switch
    
    Currently CONFIG_VIRT_CPU_ACCOUNTING_NATIVE=y accounts the cputime on
    any context boundary: irq entry/exit, guest entry/exit, context switch,
    etc...
    
    Calling functions such as account_system_time(), account_user_time()
    and such can be costly, especially if they are called on many fastpath
    such as twice per IRQ. Those functions do more than just accounting to
    kcpustat and task cputime. Depending on the config, some subsystems can
    perform unpleasant multiplications and divisions, among other things.
    
    So lets accumulate the cputime instead and delay the accounting on ticks
    and context switches only.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1483636310-6557-9-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 637e7413632c..37f1b315d9b6 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -63,14 +63,39 @@ extern cputime_t cycle_to_cputime(u64 cyc);
 
 void vtime_account_user(struct task_struct *tsk)
 {
-	cputime_t delta_utime;
 	struct thread_info *ti = task_thread_info(tsk);
+	cputime_t delta;
 
-	if (ti->ac_utime) {
-		delta_utime = cycle_to_cputime(ti->ac_utime);
-		account_user_time(tsk, delta_utime);
-		ti->ac_utime = 0;
+	if (ti->utime)
+		account_user_time(tsk, cycle_to_cputime(ti->utime));
+
+	if (ti->gtime)
+		account_guest_time(tsk, cycle_to_cputime(ti->gtime));
+
+	if (ti->idle_time)
+		account_idle_time(cycle_to_cputime(ti->idle_time));
+
+	if (ti->stime) {
+		delta = cycle_to_cputime(ti->stime);
+		account_system_index_time(tsk, delta, CPUTIME_SYSTEM);
+	}
+
+	if (ti->hardirq_time) {
+		delta = cycle_to_cputime(ti->hardirq_time);
+		account_system_index_time(tsk, delta, CPUTIME_IRQ);
+	}
+
+	if (ti->softirq_time) {
+		delta = cycle_to_cputime(ti->softirq_time);
+		account_system_index_time(tsk, delta, CPUTIME_SOFTIRQ);
 	}
+
+	ti->utime = 0;
+	ti->gtime = 0;
+	ti->idle_time = 0;
+	ti->stime = 0;
+	ti->hardirq_time = 0;
+	ti->softirq_time = 0;
 }
 
 /*
@@ -91,18 +116,15 @@ void arch_vtime_task_switch(struct task_struct *prev)
  * Account time for a transition between system, hard irq or soft irq state.
  * Note that this function is called with interrupts enabled.
  */
-static cputime_t vtime_delta(struct task_struct *tsk)
+static __u64 vtime_delta(struct task_struct *tsk)
 {
 	struct thread_info *ti = task_thread_info(tsk);
-	cputime_t delta_stime;
-	__u64 now;
+	__u64 now, delta_stime;
 
 	WARN_ON_ONCE(!irqs_disabled());
 
 	now = ia64_get_itc();
-
-	delta_stime = cycle_to_cputime(ti->ac_stime + (now - ti->ac_stamp));
-	ti->ac_stime = 0;
+	delta_stime = now - ti->ac_stamp;
 	ti->ac_stamp = now;
 
 	return delta_stime;
@@ -110,15 +132,25 @@ static cputime_t vtime_delta(struct task_struct *tsk)
 
 void vtime_account_system(struct task_struct *tsk)
 {
-	cputime_t delta = vtime_delta(tsk);
-
-	account_system_time(tsk, 0, delta);
+	struct thread_info *ti = task_thread_info(tsk);
+	__u64 stime = vtime_delta(tsk);
+
+	if ((tsk->flags & PF_VCPU) && !irq_count())
+		ti->gtime += stime;
+	else if (hardirq_count())
+		ti->hardirq_time += stime;
+	else if (in_serving_softirq())
+		ti->softirq_time += stime;
+	else
+		ti->stime += stime;
 }
 EXPORT_SYMBOL_GPL(vtime_account_system);
 
 void vtime_account_idle(struct task_struct *tsk)
 {
-	account_idle_time(vtime_delta(tsk));
+	struct thread_info *ti = task_thread_info(tsk);
+
+	ti->idle_time += vtime_delta(tsk);
 }
 
 #endif /* CONFIG_VIRT_CPU_ACCOUNTING_NATIVE */

commit 8388d21468e7e7656867b67ab2ec98a78c9ad799
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Jan 5 18:11:42 2017 +0100

    sched/cputime, ia64: Fix incorrect start cputime assignment on task switch
    
    On task switch we must initialize the current cputime of the next task
    using the value of the previous task which got freshly updated.
    
    But we are confusing that with doing the opposite, which should result
    in incorrect cputime accounting.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1483636310-6557-3-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 71775b95d6cc..637e7413632c 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -83,7 +83,7 @@ void arch_vtime_task_switch(struct task_struct *prev)
 	struct thread_info *pi = task_thread_info(prev);
 	struct thread_info *ni = task_thread_info(current);
 
-	pi->ac_stamp = ni->ac_stamp;
+	ni->ac_stamp = pi->ac_stamp;
 	ni->ac_stime = ni->ac_utime = 0;
 }
 

commit a5a1d1c2914b5316924c7893eb683a5420ebd3be
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Dec 21 20:32:01 2016 +0100

    clocksource: Use a plain u64 instead of cycle_t
    
    There is no point in having an extra type for extra confusion. u64 is
    unambiguous.
    
    Conversion was done with the following coccinelle script:
    
    @rem@
    @@
    -typedef u64 cycle_t;
    
    @fix@
    typedef cycle_t;
    @@
    -cycle_t
    +u64
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: John Stultz <john.stultz@linaro.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 021f44ab4bfb..71775b95d6cc 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -31,7 +31,7 @@
 
 #include "fsyscall_gtod_data.h"
 
-static cycle_t itc_get_cycles(struct clocksource *cs);
+static u64 itc_get_cycles(struct clocksource *cs);
 
 struct fsyscall_gtod_data_t fsyscall_gtod_data;
 
@@ -323,7 +323,7 @@ void ia64_init_itm(void)
 	}
 }
 
-static cycle_t itc_get_cycles(struct clocksource *cs)
+static u64 itc_get_cycles(struct clocksource *cs)
 {
 	unsigned long lcycle, now, ret;
 
@@ -397,7 +397,7 @@ void update_vsyscall_tz(void)
 }
 
 void update_vsyscall_old(struct timespec *wall, struct timespec *wtm,
-			 struct clocksource *c, u32 mult, cycle_t cycle_last)
+			 struct clocksource *c, u32 mult, u64 cycle_last)
 {
 	write_seqcount_begin(&fsyscall_gtod_data.seq);
 

commit 40565b5aedd6d0ca88b7dfd3859d709d2f6f8cf9
Author: Stanislaw Gruszka <sgruszka@redhat.com>
Date:   Tue Nov 15 03:06:51 2016 +0100

    sched/cputime, powerpc, s390: Make scaled cputime arch specific
    
    Only s390 and powerpc have hardware facilities allowing to measure
    cputimes scaled by frequency. On all other architectures
    utimescaled/stimescaled are equal to utime/stime (however they are
    accounted separately).
    
    Remove {u,s}timescaled accounting on all architectures except
    powerpc and s390, where those values are explicitly accounted
    in the proper places.
    
    Signed-off-by: Stanislaw Gruszka <sgruszka@redhat.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Neuling <mikey@neuling.org>
    Cc: Paul Mackerras <paulus@ozlabs.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20161031162143.GB12646@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 6f892b94e906..021f44ab4bfb 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -68,7 +68,7 @@ void vtime_account_user(struct task_struct *tsk)
 
 	if (ti->ac_utime) {
 		delta_utime = cycle_to_cputime(ti->ac_utime);
-		account_user_time(tsk, delta_utime, delta_utime);
+		account_user_time(tsk, delta_utime);
 		ti->ac_utime = 0;
 	}
 }
@@ -112,7 +112,7 @@ void vtime_account_system(struct task_struct *tsk)
 {
 	cputime_t delta = vtime_delta(tsk);
 
-	account_system_time(tsk, 0, delta, delta);
+	account_system_time(tsk, 0, delta);
 }
 EXPORT_SYMBOL_GPL(vtime_account_system);
 

commit 70f4f9352317ed8bc70cd7fe2bf34a3f9f7f21e3
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Fri Jun 17 16:48:17 2016 +0200

    ia64: efi: use timespec64 for persistent clock
    
    We have a generic read_persistent_clock64 interface now, and can
    change the ia64 implementation to provide that instead of
    read_persistent_clock.
    
    The main point of this is to avoid the use of struct timespec
    in the global efi.h, which would cause build errors as soon
    as we want to build a kernel without 'struct timespec' defined
    on 32-bit architectures.
    
    Aside from this, we get a little closer to removing the
    __weak read_persistent_clock() definition, which relies on
    converting all architectures to provide read_persistent_clock64
    instead.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index c8dbe2acd735..6f892b94e906 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -355,7 +355,7 @@ static struct irqaction timer_irqaction = {
 	.name =		"timer"
 };
 
-void read_persistent_clock(struct timespec *ts)
+void read_persistent_clock64(struct timespec64 *ts)
 {
 	efi_gettimeofday(ts);
 }

commit e55645ec5725a33eac9d6133f3bce381af1e993d
Author: Luis R. Rodriguez <mcgrof@suse.com>
Date:   Tue Jun 2 11:42:02 2015 -0700

    ia64: remove paravirt code
    
    All the ia64 pvops code is now dead code since both
    xen and kvm support have been ripped out [0] [1]. Just
    that no one had troubled to rip this stuff out. The only
    useful remaining pieces were the old pvops docs but that
    was recently also generalized and moved out from ia64 [2].
    
    This has been run time tested on an ia64 Madison system.
    
    [0] 003f7de625890 "KVM: ia64: remove" since v3.19-rc1
    [1] d52eefb47d4eb "ia64/xen: Remove Xen support for ia64" since v3.14-rc1
    [2] "virtual: Documentation: simplify and generalize paravirt_ops.txt"
    
    Signed-off-by: Luis R. Rodriguez <mcgrof@suse.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 9a0104a38cd3..c8dbe2acd735 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -25,7 +25,6 @@
 #include <asm/machvec.h>
 #include <asm/delay.h>
 #include <asm/hw_irq.h>
-#include <asm/paravirt.h>
 #include <asm/ptrace.h>
 #include <asm/sal.h>
 #include <asm/sections.h>
@@ -47,33 +46,12 @@ EXPORT_SYMBOL(last_cli_ip);
 
 #endif
 
-#ifdef CONFIG_PARAVIRT
-/* We need to define a real function for sched_clock, to override the
-   weak default version */
-unsigned long long sched_clock(void)
-{
-        return paravirt_sched_clock();
-}
-#endif
-
-#ifdef CONFIG_PARAVIRT
-static void
-paravirt_clocksource_resume(struct clocksource *cs)
-{
-	if (pv_time_ops.clocksource_resume)
-		pv_time_ops.clocksource_resume();
-}
-#endif
-
 static struct clocksource clocksource_itc = {
 	.name           = "itc",
 	.rating         = 350,
 	.read           = itc_get_cycles,
 	.mask           = CLOCKSOURCE_MASK(64),
 	.flags          = CLOCK_SOURCE_IS_CONTINUOUS,
-#ifdef CONFIG_PARAVIRT
-	.resume		= paravirt_clocksource_resume,
-#endif
 };
 static struct clocksource *itc_clocksource;
 
@@ -164,9 +142,6 @@ timer_interrupt (int irq, void *dev_id)
 
 	profile_tick(CPU_PROFILING);
 
-	if (paravirt_do_steal_accounting(&new_itm))
-		goto skip_process_time_accounting;
-
 	while (1) {
 		update_process_times(user_mode(get_irq_regs()));
 
@@ -187,8 +162,6 @@ timer_interrupt (int irq, void *dev_id)
 		local_irq_disable();
 	}
 
-skip_process_time_accounting:
-
 	do {
 		/*
 		 * If we're too close to the next clock tick for
@@ -337,8 +310,6 @@ void ia64_init_itm(void)
 		 */
 		clocksource_itc.rating = 50;
 
-	paravirt_init_missing_ticks_accounting(smp_processor_id());
-
 	/* avoid softlock up message when cpu is unplug and plugged again. */
 	touch_softlockup_watchdog();
 

commit da167ad7638759adb811afa3c80ff4cb67608242
Author: Mark Salter <msalter@redhat.com>
Date:   Fri Aug 8 14:20:14 2014 -0700

    rtc: ia64: allow other architectures to use EFI RTC
    
    Currently, the rtc-efi driver is restricted to ia64 only.  Newer
    architectures with EFI support may want to also use that driver.  This
    patch moves the platform device setup from ia64 into drivers/rtc and
    allow any architecture with CONFIG_EFI=y to use the rtc-efi driver.
    
    Signed-off-by: Mark Salter <msalter@redhat.com>
    Cc: Alessandro Zummo <a.zummo@towertech.it>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 3e71ef85e439..9a0104a38cd3 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -384,21 +384,6 @@ static struct irqaction timer_irqaction = {
 	.name =		"timer"
 };
 
-static struct platform_device rtc_efi_dev = {
-	.name = "rtc-efi",
-	.id = -1,
-};
-
-static int __init rtc_init(void)
-{
-	if (platform_device_register(&rtc_efi_dev) < 0)
-		printk(KERN_ERR "unable to register rtc device...\n");
-
-	/* not necessarily an error */
-	return 0;
-}
-module_init(rtc_init);
-
 void read_persistent_clock(struct timespec *ts)
 {
 	efi_gettimeofday(ts);

commit 953dec21aed4038464fec02f96a2f1b8701a5bce
Author: John Stultz <john.stultz@linaro.org>
Date:   Fri Jul 25 21:37:19 2014 -0700

    timekeeping: Fixup typo in update_vsyscall_old definition
    
    In commit 4a0e637738f0 ("clocksource: Get rid of cycle_last"),
    currently in the -tip tree, there was a small typo where cycles_t
    was used intstead of cycle_t. This broke ppc64 builds.
    
    Fix this by using the proper cycle_t type for this usage, in
    both the definition and the ia64 implementation.
    
    Now, having both cycle_t and cycles_t types seems like a very
    bad idea just asking for these sorts of issues. But that
    will be a cleanup for another day.
    
    Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1406349439-11785-1-git-send-email-john.stultz@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 11dc42da7daf..3e71ef85e439 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -441,7 +441,7 @@ void update_vsyscall_tz(void)
 }
 
 void update_vsyscall_old(struct timespec *wall, struct timespec *wtm,
-			 struct clocksource *c, u32 mult, cycles_t cycle_last)
+			 struct clocksource *c, u32 mult, cycle_t cycle_last)
 {
 	write_seqcount_begin(&fsyscall_gtod_data.seq);
 

commit 4a0e637738f06673725792d74eed67f8779b62c7
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Jul 16 21:05:13 2014 +0000

    clocksource: Get rid of cycle_last
    
    cycle_last was added to the clocksource to support the TSC
    validation. We moved that to the core code, so we can get rid of the
    extra copy.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 71c52bc7c28d..11dc42da7daf 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -441,7 +441,7 @@ void update_vsyscall_tz(void)
 }
 
 void update_vsyscall_old(struct timespec *wall, struct timespec *wtm,
-			struct clocksource *c, u32 mult)
+			 struct clocksource *c, u32 mult, cycles_t cycle_last)
 {
 	write_seqcount_begin(&fsyscall_gtod_data.seq);
 
@@ -450,7 +450,7 @@ void update_vsyscall_old(struct timespec *wall, struct timespec *wtm,
         fsyscall_gtod_data.clk_mult = mult;
         fsyscall_gtod_data.clk_shift = c->shift;
         fsyscall_gtod_data.clk_fsys_mmio = c->archdata.fsys_mmio;
-        fsyscall_gtod_data.clk_cycle_last = c->cycle_last;
+        fsyscall_gtod_data.clk_cycle_last = cycle_last;
 
 	/* copy kernel time structures */
         fsyscall_gtod_data.wall_time.tv_sec = wall->tv_sec;

commit 2958a489d7d31552fd1a0a8f54a5005c278d4606
Author: Michael Opdenacker <michael.opdenacker@free-electrons.com>
Date:   Tue Mar 4 21:29:13 2014 +0100

    ia64: Remove deprecated IRQF_DISABLED
    
    This patch removes the IRQF_DISABLED flag from ia64 architecture
    code. It's a NOOP since 2.6.35 and it will be removed one day.
    
    Signed-off-by: Michael Opdenacker <michael.opdenacker@free-electrons.com>
    Cc: paul.gortmaker@windriver.com
    Cc: viro@zeniv.linux.org.uk
    Cc: srivatsa.bhat@linux.vnet.ibm.com
    Cc: andriy.shevchenko@linux.intel.com
    Cc: fenghua.yu@intel.com
    Cc: tony.luck@intel.com
    Link: http://lkml.kernel.org/r/1393964953-17002-1-git-send-email-michael.opdenacker@free-electrons.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index fbaac1afb844..71c52bc7c28d 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -380,7 +380,7 @@ static cycle_t itc_get_cycles(struct clocksource *cs)
 
 static struct irqaction timer_irqaction = {
 	.handler =	timer_interrupt,
-	.flags =	IRQF_DISABLED | IRQF_IRQPOLL,
+	.flags =	IRQF_IRQPOLL,
 	.name =		"timer"
 };
 

commit c11f11fcbdb5be790c565aed46411486a7586afc
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Mon Jan 21 00:50:22 2013 +0100

    kvm: Prepare to add generic guest entry/exit callbacks
    
    Do some ground preparatory work before adding guest_enter()
    and guest_exit() context tracking callbacks. Those will
    be later used to read the guest cputime safely when we
    run in full dynticks mode.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Gleb Natapov <gleb@redhat.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Li Zhong <zhong@linux.vnet.ibm.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index a3a3f5a1cb3a..fbaac1afb844 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -136,6 +136,7 @@ void vtime_account_system(struct task_struct *tsk)
 
 	account_system_time(tsk, 0, delta, delta);
 }
+EXPORT_SYMBOL_GPL(vtime_account_system);
 
 void vtime_account_idle(struct task_struct *tsk)
 {

commit abf917cd91cbb73952758f9741e2fa65002a48ee
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Wed Jul 25 07:56:04 2012 +0200

    cputime: Generic on-demand virtual cputime accounting
    
    If we want to stop the tick further idle, we need to be
    able to account the cputime without using the tick.
    
    Virtual based cputime accounting solves that problem by
    hooking into kernel/user boundaries.
    
    However implementing CONFIG_VIRT_CPU_ACCOUNTING require
    low level hooks and involves more overhead. But we already
    have a generic context tracking subsystem that is required
    for RCU needs by archs which plan to shut down the tick
    outside idle.
    
    This patch implements a generic virtual based cputime
    accounting that relies on these generic kernel/user hooks.
    
    There are some upsides of doing this:
    
    - This requires no arch code to implement CONFIG_VIRT_CPU_ACCOUNTING
    if context tracking is already built (already necessary for RCU in full
    tickless mode).
    
    - We can rely on the generic context tracking subsystem to dynamically
    (de)activate the hooks, so that we can switch anytime between virtual
    and tick based accounting. This way we don't have the overhead
    of the virtual accounting when the tick is running periodically.
    
    And one downside:
    
    - There is probably more overhead than a native virtual based cputime
    accounting. But this relies on hooks that are already set anyway.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Li Zhong <zhong@linux.vnet.ibm.com>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 88a794536bc0..a3a3f5a1cb3a 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -77,7 +77,7 @@ static struct clocksource clocksource_itc = {
 };
 static struct clocksource *itc_clocksource;
 
-#ifdef CONFIG_VIRT_CPU_ACCOUNTING
+#ifdef CONFIG_VIRT_CPU_ACCOUNTING_NATIVE
 
 #include <linux/kernel_stat.h>
 
@@ -142,7 +142,7 @@ void vtime_account_idle(struct task_struct *tsk)
 	account_idle_time(vtime_delta(tsk));
 }
 
-#endif /* CONFIG_VIRT_CPU_ACCOUNTING */
+#endif /* CONFIG_VIRT_CPU_ACCOUNTING_NATIVE */
 
 static irqreturn_t
 timer_interrupt (int irq, void *dev_id)

commit 5b5e76e9cb294fc01cc81d21cd7b5feead067a40
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Fri Dec 21 14:05:13 2012 -0800

    IA64: drivers: remove __dev* attributes.
    
    CONFIG_HOTPLUG is going away as an option.  As a result, the __dev*
    markings need to be removed.
    
    This change removes the use of __devinit, __devexit_p, __devinitdata,
    and __devexit from these drivers.
    
    Based on patches originally written by Bill Pemberton, but redone by me
    in order to handle some of the coding style issues better, by hand.
    
    Cc: Bill Pemberton <wfp5p@virginia.edu>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index b1995efbfd21..88a794536bc0 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -243,8 +243,7 @@ static int __init nojitter_setup(char *str)
 __setup("nojitter", nojitter_setup);
 
 
-void __devinit
-ia64_init_itm (void)
+void ia64_init_itm(void)
 {
 	unsigned long platform_base_freq, itc_freq;
 	struct pal_freq_ratio itc_ratio, proc_ratio;

commit 1b2852b152be5150fbef7b585388ec43cf6f4415
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Mon Nov 19 17:00:24 2012 +0100

    vtime: Warn if irqs aren't disabled on system time accounting APIs
    
    System time accounting APIs such as vtime_account_system() and
    vtime_account_idle() need to be irqsafe. Current callers include
    irq entry, exit and kvm, all of which have been checked against that
    requirement. Now it's better to grow that with an automatic check
    in case we have further callers or we missed something.
    
    Suggested-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index c9a7d2ebe089..b1995efbfd21 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -119,6 +119,8 @@ static cputime_t vtime_delta(struct task_struct *tsk)
 	cputime_t delta_stime;
 	__u64 now;
 
+	WARN_ON_ONCE(!irqs_disabled());
+
 	now = ia64_get_itc();
 
 	delta_stime = cycle_to_cputime(ti->ac_stime + (now - ti->ac_stamp));

commit e3942ba04052364d3c6454103362cafd87456010
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Wed Nov 14 00:24:25 2012 +0100

    vtime: Consolidate a bit the ctx switch code
    
    On ia64 and powerpc, vtime context switch only consists
    in flushing system and user pending time, plus a few
    arch housekeeping.
    
    Consolidate that into a generic implementation. s390 is
    a special case because pending user and system time accounting
    there is hard to dissociate. So it's keeping its own implementation.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Reviewed-by: Steven Rostedt <rostedt@goodmis.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 834c78bd3b5f..c9a7d2ebe089 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -100,18 +100,11 @@ void vtime_account_user(struct task_struct *tsk)
  * accumulated times to the current process, and to prepare accounting on
  * the next process.
  */
-void vtime_task_switch(struct task_struct *prev)
+void arch_vtime_task_switch(struct task_struct *prev)
 {
 	struct thread_info *pi = task_thread_info(prev);
 	struct thread_info *ni = task_thread_info(current);
 
-	if (idle_task(smp_processor_id()) != prev)
-		vtime_account_system(prev);
-	else
-		vtime_account_idle(prev);
-
-	vtime_account_user(prev);
-
 	pi->ac_stamp = ni->ac_stamp;
 	ni->ac_stime = ni->ac_utime = 0;
 }

commit bcebdf846522056a84ba0b0cba5f5413868c9394
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Nov 13 23:51:06 2012 +0100

    vtime: Explicitly account pending user time on process tick
    
    All vtime implementations just flush the user time on process
    tick. Consolidate that in generic code by calling a user time
    accounting helper. This avoids an indirect call in ia64 and
    prepare to also consolidate vtime context switch code.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Reviewed-by: Steven Rostedt <rostedt@goodmis.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index f6388216080d..834c78bd3b5f 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -83,7 +83,7 @@ static struct clocksource *itc_clocksource;
 
 extern cputime_t cycle_to_cputime(u64 cyc);
 
-static void vtime_account_user(struct task_struct *tsk)
+void vtime_account_user(struct task_struct *tsk)
 {
 	cputime_t delta_utime;
 	struct thread_info *ti = task_thread_info(tsk);
@@ -147,15 +147,6 @@ void vtime_account_idle(struct task_struct *tsk)
 	account_idle_time(vtime_delta(tsk));
 }
 
-/*
- * Called from the timer interrupt handler to charge accumulated user time
- * to the current process.  Must be called with interrupts disabled.
- */
-void account_process_tick(struct task_struct *p, int user_tick)
-{
-	vtime_account_user(p);
-}
-
 #endif /* CONFIG_VIRT_CPU_ACCOUNTING */
 
 static irqreturn_t

commit fd25b4c2f226de818e1d2b71e3e681d28bcaf5ba
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Nov 13 18:21:22 2012 +0100

    vtime: Remove the underscore prefix invasion
    
    Prepending irq-unsafe vtime APIs with underscores was actually
    a bad idea as the result is a big mess in the API namespace that
    is even waiting to be further extended. Also these helpers
    are always called from irq safe callers except kvm. Just
    provide a vtime_account_system_irqsafe() for this specific
    case so that we can remove the underscore prefix on other
    vtime functions.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Reviewed-by: Steven Rostedt <rostedt@goodmis.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 5e4850305d3f..f6388216080d 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -106,9 +106,9 @@ void vtime_task_switch(struct task_struct *prev)
 	struct thread_info *ni = task_thread_info(current);
 
 	if (idle_task(smp_processor_id()) != prev)
-		__vtime_account_system(prev);
+		vtime_account_system(prev);
 	else
-		__vtime_account_idle(prev);
+		vtime_account_idle(prev);
 
 	vtime_account_user(prev);
 
@@ -135,14 +135,14 @@ static cputime_t vtime_delta(struct task_struct *tsk)
 	return delta_stime;
 }
 
-void __vtime_account_system(struct task_struct *tsk)
+void vtime_account_system(struct task_struct *tsk)
 {
 	cputime_t delta = vtime_delta(tsk);
 
 	account_system_time(tsk, 0, delta, delta);
 }
 
-void __vtime_account_idle(struct task_struct *tsk)
+void vtime_account_idle(struct task_struct *tsk)
 {
 	account_idle_time(vtime_delta(tsk));
 }

commit 11113334d1c5dd5355c86e531c29f1202a855c86
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Wed Oct 24 18:05:51 2012 +0200

    vtime: Make vtime_account_system() irqsafe
    
    vtime_account_system() currently has only one caller with
    vtime_account() which is irq safe.
    
    Now we are going to call it from other places like kvm where
    irqs are not always disabled by the time we account the cputime.
    
    So let's make it irqsafe. The arch implementation part is now
    prefixed with "__".
    
    vtime_account_idle() arch implementation is prefixed accordingly
    to stay consistent.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index f6388216080d..5e4850305d3f 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -106,9 +106,9 @@ void vtime_task_switch(struct task_struct *prev)
 	struct thread_info *ni = task_thread_info(current);
 
 	if (idle_task(smp_processor_id()) != prev)
-		vtime_account_system(prev);
+		__vtime_account_system(prev);
 	else
-		vtime_account_idle(prev);
+		__vtime_account_idle(prev);
 
 	vtime_account_user(prev);
 
@@ -135,14 +135,14 @@ static cputime_t vtime_delta(struct task_struct *tsk)
 	return delta_stime;
 }
 
-void vtime_account_system(struct task_struct *tsk)
+void __vtime_account_system(struct task_struct *tsk)
 {
 	cputime_t delta = vtime_delta(tsk);
 
 	account_system_time(tsk, 0, delta, delta);
 }
 
-void vtime_account_idle(struct task_struct *tsk)
+void __vtime_account_idle(struct task_struct *tsk)
 {
 	account_idle_time(vtime_delta(tsk));
 }

commit 03d3602a833715f83ea53b9feb078b9c4c5f6c1a
Merge: 0588f1f93479 5b3900cd4094
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 12 22:17:48 2012 +0900

    Merge branch 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull timer core update from Thomas Gleixner:
     - Bug fixes (one for a longstanding dead loop issue)
     - Rework of time related vsyscalls
     - Alarm timer updates
     - Jiffies updates to remove compile time dependencies
    
    * 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      timekeeping: Cast raw_interval to u64 to avoid shift overflow
      timers: Fix endless looping between cascade() and internal_add_timer()
      time/jiffies: bring back unconditional LATCH definition
      time: Convert x86_64 to using new update_vsyscall
      time: Only do nanosecond rounding on GENERIC_TIME_VSYSCALL_OLD systems
      time: Introduce new GENERIC_TIME_VSYSCALL
      time: Convert CONFIG_GENERIC_TIME_VSYSCALL to CONFIG_GENERIC_TIME_VSYSCALL_OLD
      time: Move update_vsyscall definitions to timekeeper_internal.h
      time: Move timekeeper structure to timekeeper_internal.h for vsyscall changes
      jiffies: Remove compile time assumptions about CLOCK_TICK_RATE
      jiffies: Kill unused TICK_USEC_TO_NSEC
      alarmtimer: Rename alarmtimer_remove to alarmtimer_dequeue
      alarmtimer: Remove unused helpers & defines
      alarmtimer: Use hrtimer per-alarm instead of per-base
      alarmtimer: Implement minimum alarm interval for allowing suspend

commit 9dc16f64e84fea59d6af6bb5da59603b369ff05c
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Sat Sep 8 18:07:29 2012 +0200

    ia64: Reuse system and user vtime accounting functions on task switch
    
    To avoid code duplication.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 351df5850309..80ff9acc5edf 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -104,20 +104,15 @@ void vtime_task_switch(struct task_struct *prev)
 {
 	struct thread_info *pi = task_thread_info(prev);
 	struct thread_info *ni = task_thread_info(current);
-	cputime_t delta_stime;
-	__u64 now;
-
-	now = ia64_get_itc();
 
-	delta_stime = cycle_to_cputime(pi->ac_stime + (now - pi->ac_stamp));
 	if (idle_task(smp_processor_id()) != prev)
-		account_system_time(prev, 0, delta_stime, delta_stime);
+		vtime_account_system(prev);
 	else
-		account_idle_time(delta_stime);
+		vtime_account_idle(prev);
 
 	vtime_account_user(prev);
 
-	pi->ac_stamp = ni->ac_stamp = now;
+	pi->ac_stamp = ni->ac_stamp;
 	ni->ac_stime = ni->ac_utime = 0;
 }
 

commit 5bf412cd769eb5830fb3716d4b2b222b6a5515ff
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Sat Sep 8 18:00:02 2012 +0200

    ia64: Consolidate user vtime accounting
    
    Factorize the code that accounts user time into a
    single function to avoid code duplication.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 01cd43e491cd..351df5850309 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -83,6 +83,18 @@ static struct clocksource *itc_clocksource;
 
 extern cputime_t cycle_to_cputime(u64 cyc);
 
+static void vtime_account_user(struct task_struct *tsk)
+{
+	cputime_t delta_utime;
+	struct thread_info *ti = task_thread_info(tsk);
+
+	if (ti->ac_utime) {
+		delta_utime = cycle_to_cputime(ti->ac_utime);
+		account_user_time(tsk, delta_utime, delta_utime);
+		ti->ac_utime = 0;
+	}
+}
+
 /*
  * Called from the context switch with interrupts disabled, to charge all
  * accumulated times to the current process, and to prepare accounting on
@@ -92,7 +104,7 @@ void vtime_task_switch(struct task_struct *prev)
 {
 	struct thread_info *pi = task_thread_info(prev);
 	struct thread_info *ni = task_thread_info(current);
-	cputime_t delta_stime, delta_utime;
+	cputime_t delta_stime;
 	__u64 now;
 
 	now = ia64_get_itc();
@@ -103,10 +115,7 @@ void vtime_task_switch(struct task_struct *prev)
 	else
 		account_idle_time(delta_stime);
 
-	if (pi->ac_utime) {
-		delta_utime = cycle_to_cputime(pi->ac_utime);
-		account_user_time(prev, delta_utime, delta_utime);
-	}
+	vtime_account_user(prev);
 
 	pi->ac_stamp = ni->ac_stamp = now;
 	ni->ac_stime = ni->ac_utime = 0;
@@ -149,14 +158,7 @@ void vtime_account_idle(struct task_struct *tsk)
  */
 void account_process_tick(struct task_struct *p, int user_tick)
 {
-	struct thread_info *ti = task_thread_info(p);
-	cputime_t delta_utime;
-
-	if (ti->ac_utime) {
-		delta_utime = cycle_to_cputime(ti->ac_utime);
-		account_user_time(p, delta_utime, delta_utime);
-		ti->ac_utime = 0;
-	}
+	vtime_account_user(p);
 }
 
 #endif /* CONFIG_VIRT_CPU_ACCOUNTING */

commit a7e1a9e3af71b45ecae2dae35851f238117b317d
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Sat Sep 8 16:14:02 2012 +0200

    vtime: Consolidate system/idle context detection
    
    Move the code that finds out to which context we account the
    cputime into generic layer.
    
    Archs that consider the whole time spent in the idle task as idle
    time (ia64, powerpc) can rely on the generic vtime_account()
    and implement vtime_account_system() and vtime_account_idle(),
    letting the generic code to decide when to call which API.
    
    Archs that have their own meaning of idle time, such as s390
    that only considers the time spent in CPU low power mode as idle
    time, can just override vtime_account().
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 16bb6eda879d..01cd43e491cd 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -116,29 +116,32 @@ void vtime_task_switch(struct task_struct *prev)
  * Account time for a transition between system, hard irq or soft irq state.
  * Note that this function is called with interrupts enabled.
  */
-void vtime_account(struct task_struct *tsk)
+static cputime_t vtime_delta(struct task_struct *tsk)
 {
 	struct thread_info *ti = task_thread_info(tsk);
-	unsigned long flags;
 	cputime_t delta_stime;
 	__u64 now;
 
-	local_irq_save(flags);
-
 	now = ia64_get_itc();
 
 	delta_stime = cycle_to_cputime(ti->ac_stime + (now - ti->ac_stamp));
-	if (irq_count() || idle_task(smp_processor_id()) != tsk)
-		account_system_time(tsk, 0, delta_stime, delta_stime);
-	else
-		account_idle_time(delta_stime);
 	ti->ac_stime = 0;
-
 	ti->ac_stamp = now;
 
-	local_irq_restore(flags);
+	return delta_stime;
+}
+
+void vtime_account_system(struct task_struct *tsk)
+{
+	cputime_t delta = vtime_delta(tsk);
+
+	account_system_time(tsk, 0, delta, delta);
+}
+
+void vtime_account_idle(struct task_struct *tsk)
+{
+	account_idle_time(vtime_delta(tsk));
 }
-EXPORT_SYMBOL_GPL(vtime_account);
 
 /*
  * Called from the timer interrupt handler to charge accumulated user time

commit bf9fae9f5e4ca8dce4708812f9ad6281e61df109
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Sat Sep 8 15:23:11 2012 +0200

    cputime: Use a proper subsystem naming for vtime related APIs
    
    Use a naming based on vtime as a prefix for virtual based
    cputime accounting APIs:
    
    - account_system_vtime() -> vtime_account()
    - account_switch_vtime() -> vtime_task_switch()
    
    It makes it easier to allow for further declension such
    as vtime_account_system(), vtime_account_idle(), ... if we
    want to find out the context we account to from generic code.
    
    This also make it better to know on which subsystem these APIs
    refer to.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 6247197b9877..16bb6eda879d 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -88,7 +88,7 @@ extern cputime_t cycle_to_cputime(u64 cyc);
  * accumulated times to the current process, and to prepare accounting on
  * the next process.
  */
-void account_switch_vtime(struct task_struct *prev)
+void vtime_task_switch(struct task_struct *prev)
 {
 	struct thread_info *pi = task_thread_info(prev);
 	struct thread_info *ni = task_thread_info(current);
@@ -116,7 +116,7 @@ void account_switch_vtime(struct task_struct *prev)
  * Account time for a transition between system, hard irq or soft irq state.
  * Note that this function is called with interrupts enabled.
  */
-void account_system_vtime(struct task_struct *tsk)
+void vtime_account(struct task_struct *tsk)
 {
 	struct thread_info *ti = task_thread_info(tsk);
 	unsigned long flags;
@@ -138,7 +138,7 @@ void account_system_vtime(struct task_struct *tsk)
 
 	local_irq_restore(flags);
 }
-EXPORT_SYMBOL_GPL(account_system_vtime);
+EXPORT_SYMBOL_GPL(vtime_account);
 
 /*
  * Called from the timer interrupt handler to charge accumulated user time

commit 706394211648117762edfaeffd6fc04bf3b1a75d
Author: John Stultz <john.stultz@linaro.org>
Date:   Tue Sep 4 15:34:21 2012 -0400

    time: Convert CONFIG_GENERIC_TIME_VSYSCALL to CONFIG_GENERIC_TIME_VSYSCALL_OLD
    
    To help migrate archtectures over to the new update_vsyscall method,
    redfine CONFIG_GENERIC_TIME_VSYSCALL as CONFIG_GENERIC_TIME_VSYSCALL_OLD
    
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Turner <pjt@google.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index acb688fe2354..d2f4e260db40 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -454,7 +454,7 @@ void update_vsyscall_tz(void)
 {
 }
 
-void update_vsyscall(struct timespec *wall, struct timespec *wtm,
+void update_vsyscall_old(struct timespec *wall, struct timespec *wtm,
 			struct clocksource *c, u32 mult)
 {
 	write_seqcount_begin(&fsyscall_gtod_data.seq);

commit 189374aed657e2228ad6b39ece438c9cdafc8dae
Author: John Stultz <john.stultz@linaro.org>
Date:   Tue Sep 4 15:27:48 2012 -0400

    time: Move update_vsyscall definitions to timekeeper_internal.h
    
    Since users will need to include timekeeper_internal.h, move
    update_vsyscall definitions to timekeeper_internal.h.
    
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Turner <pjt@google.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index ecc904b33c5f..acb688fe2354 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -19,7 +19,7 @@
 #include <linux/interrupt.h>
 #include <linux/efi.h>
 #include <linux/timex.h>
-#include <linux/clocksource.h>
+#include <linux/timekeeper_internal.h>
 #include <linux/platform_device.h>
 
 #include <asm/machvec.h>

commit baa36046d09ea6dbc122c795566992318663d9eb
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Mon Jun 18 17:54:14 2012 +0200

    cputime: Consolidate vtime handling on context switch
    
    The archs that implement virtual cputime accounting all
    flush the cputime of a task when it gets descheduled
    and sometimes set up some ground initialization for the
    next task to account its cputime.
    
    These archs all put their own hooks in their context
    switch callbacks and handle the off-case themselves.
    
    Consolidate this by creating a new account_switch_vtime()
    callback called in generic code right after a context switch
    and that these archs must implement to flush the prev task
    cputime and initialize the next task cputime related state.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Acked-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index ecc904b33c5f..6247197b9877 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -88,10 +88,10 @@ extern cputime_t cycle_to_cputime(u64 cyc);
  * accumulated times to the current process, and to prepare accounting on
  * the next process.
  */
-void ia64_account_on_switch(struct task_struct *prev, struct task_struct *next)
+void account_switch_vtime(struct task_struct *prev)
 {
 	struct thread_info *pi = task_thread_info(prev);
-	struct thread_info *ni = task_thread_info(next);
+	struct thread_info *ni = task_thread_info(current);
 	cputime_t delta_stime, delta_utime;
 	__u64 now;
 

commit bcd550745fc54f789c14e7526e0633222c505faa
Merge: 93f378883cec 646783a38982
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 29 14:16:48 2012 -0700

    Merge branch 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull timer core updates from Thomas Gleixner.
    
    * 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      ia64: vsyscall: Add missing paranthesis
      alarmtimer: Don't call rtc_timer_init() when CONFIG_RTC_CLASS=n
      x86: vdso: Put declaration before code
      x86-64: Inline vdso clock_gettime helpers
      x86-64: Simplify and optimize vdso clock_gettime monotonic variants
      kernel-time: fix s/then/than/ spelling errors
      time: remove no_sync_cmos_clock
      time: Avoid scary backtraces when warning of > 11% adj
      alarmtimer: Make sure we initialize the rtctimer
      ntp: Fix leap-second hrtimer livelock
      x86, tsc: Skip refined tsc calibration on systems with reliable TSC
      rtc: Provide flag for rtc devices that don't support UIE
      ia64: vsyscall: Use seqcount instead of seqlock
      x86: vdso: Use seqcount instead of seqlock
      x86: vdso: Remove bogus locking in update_vsyscall_tz()
      time: Remove bogus comments
      time: Fix change_clocksource locking
      time: x86: Fix race switching from vsyscall to non-vsyscall clock

commit c140d87995b68b428f70635c2e4071e4e8b3256e
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:30:02 2012 +0100

    Disintegrate asm/system.h for IA64
    
    Disintegrate asm/system.h for IA64.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Tony Luck <tony.luck@intel.com>
    cc: linux-ia64@vger.kernel.org

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 43920de425f1..aa94bdda9de8 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -29,7 +29,6 @@
 #include <asm/ptrace.h>
 #include <asm/sal.h>
 #include <asm/sections.h>
-#include <asm/system.h>
 
 #include "fsyscall_gtod_data.h"
 

commit 74a622be3db2898251cb524d1edbeaea589f2723
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Feb 28 19:46:05 2012 +0000

    ia64: vsyscall: Use seqcount instead of seqlock
    
    The update of the vdso data happens under xtime_lock, so adding a
    nested lock is pointless. Just use a seqcount to sync the readers.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 43920de425f1..8e991a0b5e35 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -35,9 +35,7 @@
 
 static cycle_t itc_get_cycles(struct clocksource *cs);
 
-struct fsyscall_gtod_data_t fsyscall_gtod_data = {
-	.lock = __SEQLOCK_UNLOCKED(fsyscall_gtod_data.lock),
-};
+struct fsyscall_gtod_data_t fsyscall_gtod_data;
 
 struct itc_jitter_data_t itc_jitter_data;
 
@@ -460,9 +458,7 @@ void update_vsyscall_tz(void)
 void update_vsyscall(struct timespec *wall, struct timespec *wtm,
 			struct clocksource *c, u32 mult)
 {
-        unsigned long flags;
-
-        write_seqlock_irqsave(&fsyscall_gtod_data.lock, flags);
+	write_seqcount_begin(&fsyscall_gtod_data.seq);
 
         /* copy fsyscall clock data */
         fsyscall_gtod_data.clk_mask = c->mask;
@@ -485,6 +481,6 @@ void update_vsyscall(struct timespec *wall, struct timespec *wtm,
 		fsyscall_gtod_data.monotonic_time.tv_sec++;
 	}
 
-        write_sequnlock_irqrestore(&fsyscall_gtod_data.lock, flags);
+	write_seqcount_end(&fsyscall_gtod_data.seq);
 }
 

commit 574c44fa8fa6262ffd5939789ef51a6e98ed62d7
Author: Andy Lutomirski <luto@mit.edu>
Date:   Wed Jul 13 09:24:15 2011 -0400

    ia64: Replace clocksource.fsys_mmio with generic arch data
    
    Now that clocksource.archdata is available, use it for ia64-specific
    code.
    
    Cc: Clemens Ladisch <clemens@ladisch.de>
    Cc: linux-ia64@vger.kernel.org
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: John Stultz <johnstul@us.ibm.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andy Lutomirski <luto@mit.edu>
    Link: http://lkml.kernel.org/r/d31de0ee0842a0e322fb6441571c2b0adb323fa2.1310563276.git.luto@mit.edu
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 85118dfe9bb5..43920de425f1 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -468,7 +468,7 @@ void update_vsyscall(struct timespec *wall, struct timespec *wtm,
         fsyscall_gtod_data.clk_mask = c->mask;
         fsyscall_gtod_data.clk_mult = mult;
         fsyscall_gtod_data.clk_shift = c->shift;
-        fsyscall_gtod_data.clk_fsys_mmio = c->fsys_mmio;
+        fsyscall_gtod_data.clk_fsys_mmio = c->archdata.fsys_mmio;
         fsyscall_gtod_data.clk_cycle_last = c->cycle_last;
 
 	/* copy kernel time structures */

commit c4dbe54ed7296ac3249c415d512dd6d649f66f4b
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Tue May 24 14:08:08 2011 +0200

    seqlock: Get rid of SEQLOCK_UNLOCKED
    
    All static seqlock should be initialized with the lockdep friendly
    __SEQLOCK_UNLOCKED() macro.
    
    Remove legacy SEQLOCK_UNLOCKED() macro.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: David Miller <davem@davemloft.net>
    Link: http://lkml.kernel.org/r/%3C1306238888.3026.31.camel%40edumazet-laptop%3E
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 04440cc09b40..85118dfe9bb5 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -36,7 +36,7 @@
 static cycle_t itc_get_cycles(struct clocksource *cs);
 
 struct fsyscall_gtod_data_t fsyscall_gtod_data = {
-	.lock = SEQLOCK_UNLOCKED,
+	.lock = __SEQLOCK_UNLOCKED(fsyscall_gtod_data.lock),
 };
 
 struct itc_jitter_data_t itc_jitter_data;

commit a18f22a968de17b29f2310cdb7ba69163e65ec15
Merge: a1c57e0fec53 798778b8653f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat May 14 12:06:36 2011 +0200

    Merge branch 'consolidate-clksrc-i8253' of master.kernel.org:~rmk/linux-2.6-arm into timers/clocksource
    
    Conflicts:
            arch/ia64/kernel/cyclone.c
            arch/mips/kernel/i8253.c
            arch/x86/kernel/i8253.c
    
    Reason: Resolve conflicts so further cleanups do not conflict further
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit d60c3041778c11f564969fb62b337df68232ee80
Author: John Stultz <johnstul@us.ibm.com>
Date:   Mon Apr 26 20:20:47 2010 -0700

    ia64: convert to clocksource_register_hz/khz
    
    This converts the ia64 clocksources to use clocksource_register_hz/khz
    
    CC: Tony Luck <tony.luck@intel.com>
    CC: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Tony Luck <tony.luck@intel.com> [clocksource_itc path]
    Signed-off-by: John Stultz <johnstul@us.ibm.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 9702fa92489e..41c40f0e4796 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -73,8 +73,6 @@ static struct clocksource clocksource_itc = {
 	.rating         = 350,
 	.read           = itc_get_cycles,
 	.mask           = CLOCKSOURCE_MASK(64),
-	.mult           = 0, /*to be calculated*/
-	.shift          = 16,
 	.flags          = CLOCK_SOURCE_IS_CONTINUOUS,
 #ifdef CONFIG_PARAVIRT
 	.resume		= paravirt_clocksource_resume,
@@ -374,11 +372,8 @@ ia64_init_itm (void)
 	ia64_cpu_local_tick();
 
 	if (!itc_clocksource) {
-		/* Sort out mult/shift values: */
-		clocksource_itc.mult =
-			clocksource_hz2mult(local_cpu_data->itc_freq,
-						clocksource_itc.shift);
-		clocksource_register(&clocksource_itc);
+		clocksource_register_hz(&clocksource_itc,
+						local_cpu_data->itc_freq);
 		itc_clocksource = &clocksource_itc;
 	}
 }

commit 1aabd67d2e97e6affdf5a7c65f442ac91ace3f85
Author: Torben Hohn <torbenh@gmx.de>
Date:   Thu Jan 27 15:59:56 2011 +0100

    ia64: Switch do_timer() to xtime_update()
    
    local_cpu_data->itm_next = new_itm; does not need to be protected by
    xtime_lock. xtime_update() takes the lock itself.
    
    Signed-off-by: Torben Hohn <torbenh@gmx.de>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: johnstul@us.ibm.com
    Cc: hch@infradead.org
    Cc: yong.zhang0@gmail.com
    LKML-Reference: <20110127145956.23248.49107.stgit@localhost>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 9702fa92489e..156ad803d5b7 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -190,19 +190,10 @@ timer_interrupt (int irq, void *dev_id)
 
 		new_itm += local_cpu_data->itm_delta;
 
-		if (smp_processor_id() == time_keeper_id) {
-			/*
-			 * Here we are in the timer irq handler. We have irqs locally
-			 * disabled, but we don't know if the timer_bh is running on
-			 * another CPU. We need to avoid to SMP race by acquiring the
-			 * xtime_lock.
-			 */
-			write_seqlock(&xtime_lock);
-			do_timer(1);
-			local_cpu_data->itm_next = new_itm;
-			write_sequnlock(&xtime_lock);
-		} else
-			local_cpu_data->itm_next = new_itm;
+		if (smp_processor_id() == time_keeper_id)
+			xtime_update(1);
+
+		local_cpu_data->itm_next = new_itm;
 
 		if (time_after(new_itm, ia64_get_itc()))
 			break;
@@ -222,7 +213,7 @@ timer_interrupt (int irq, void *dev_id)
 		 * comfort, we increase the safety margin by
 		 * intentionally dropping the next tick(s).  We do NOT
 		 * update itm.next because that would force us to call
-		 * do_timer() which in turn would let our clock run
+		 * xtime_update() which in turn would let our clock run
 		 * too fast (with the potentially devastating effect
 		 * of losing monotony of time).
 		 */

commit e7d282535c94cddc208c03b7cd0815f70d676a0e
Author: Joe Perches <joe@perches.com>
Date:   Thu Dec 9 23:16:55 2010 -0800

    [IA64] Remove unlikely from cpu_is_offline
    
    cpu_is_offline already uses unlikely internally.
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index ed6f22eb5b12..9702fa92489e 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -168,7 +168,7 @@ timer_interrupt (int irq, void *dev_id)
 {
 	unsigned long new_itm;
 
-	if (unlikely(cpu_is_offline(smp_processor_id()))) {
+	if (cpu_is_offline(smp_processor_id())) {
 		return IRQ_HANDLED;
 	}
 

commit 7615856ebfee52b080c22d263ca4debbd0df0ac1
Author: John Stultz <johnstul@us.ibm.com>
Date:   Tue Jul 13 17:56:23 2010 -0700

    timkeeping: Fix update_vsyscall to provide wall_to_monotonic offset
    
    update_vsyscall() did not provide the wall_to_monotoinc offset,
    so arch specific implementations tend to reference wall_to_monotonic
    directly. This limits future cleanups in the timekeeping core, so
    this patch fixes the update_vsyscall interface to provide
    wall_to_monotonic, allowing wall_to_monotonic to be made static
    as planned in Documentation/feature-removal-schedule.txt
    
    Signed-off-by: John Stultz <johnstul@us.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Anton Blanchard <anton@samba.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Tony Luck <tony.luck@intel.com>
    LKML-Reference: <1279068988-21864-7-git-send-email-johnstul@us.ibm.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 653b3c46ea82..ed6f22eb5b12 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -471,7 +471,8 @@ void update_vsyscall_tz(void)
 {
 }
 
-void update_vsyscall(struct timespec *wall, struct clocksource *c, u32 mult)
+void update_vsyscall(struct timespec *wall, struct timespec *wtm,
+			struct clocksource *c, u32 mult)
 {
         unsigned long flags;
 
@@ -487,9 +488,9 @@ void update_vsyscall(struct timespec *wall, struct clocksource *c, u32 mult)
 	/* copy kernel time structures */
         fsyscall_gtod_data.wall_time.tv_sec = wall->tv_sec;
         fsyscall_gtod_data.wall_time.tv_nsec = wall->tv_nsec;
-        fsyscall_gtod_data.monotonic_time.tv_sec = wall_to_monotonic.tv_sec
+	fsyscall_gtod_data.monotonic_time.tv_sec = wtm->tv_sec
 							+ wall->tv_sec;
-        fsyscall_gtod_data.monotonic_time.tv_nsec = wall_to_monotonic.tv_nsec
+	fsyscall_gtod_data.monotonic_time.tv_nsec = wtm->tv_nsec
 							+ wall->tv_nsec;
 
 	/* normalize */

commit 6ffdc5774a9ef80e58db398a8307d5b2db2644ce
Author: John Stultz <johnstul@us.ibm.com>
Date:   Wed Mar 3 19:57:22 2010 -0800

    ia64: Convert ia64 to use read/update_persistent_clock
    
    This patch converts the ia64 architecture to use the generic
    read_persistent_clock and update_persistent_clock interfaces, reducing
    the amount of arch specific code we have to maintain, and allowing for
    further cleanups in the future.
    
    I have not built or tested this patch, so help from arch maintainers
    would be appreciated.
    
    Signed-off-by: John Stultz <johnstul@us.ibm.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    LKML-Reference: <1267675049-12337-8-git-send-email-johnstul@us.ibm.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 47a192781b0a..653b3c46ea82 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -430,18 +430,16 @@ static int __init rtc_init(void)
 }
 module_init(rtc_init);
 
+void read_persistent_clock(struct timespec *ts)
+{
+	efi_gettimeofday(ts);
+}
+
 void __init
 time_init (void)
 {
 	register_percpu_irq(IA64_TIMER_VECTOR, &timer_irqaction);
-	efi_gettimeofday(&xtime);
 	ia64_init_itm();
-
-	/*
-	 * Initialize wall_to_monotonic such that adding it to xtime will yield zero, the
-	 * tv_nsec field must be normalized (i.e., 0 <= nsec < NSEC_PER_SEC).
-	 */
-	set_normalized_timespec(&wall_to_monotonic, -xtime.tv_sec, -xtime.tv_nsec);
 }
 
 /*

commit 17622339af2536b32cf29699ddd4ba0fe79a61d5
Author: Magnus Damm <damm@opensource.se>
Date:   Tue Feb 2 14:41:39 2010 -0800

    clocksource: add argument to resume callback
    
    Pass the clocksource as an argument to the clocksource resume callback.
    Needed so we can point out which CMT channel the sh_cmt.c driver shall
    resume.
    
    Signed-off-by: Magnus Damm <damm@opensource.se>
    Cc: john stultz <johnstul@us.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index a35c661e5e89..47a192781b0a 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -61,7 +61,7 @@ unsigned long long sched_clock(void)
 
 #ifdef CONFIG_PARAVIRT
 static void
-paravirt_clocksource_resume(void)
+paravirt_clocksource_resume(struct clocksource *cs)
 {
 	if (pv_time_ops.clocksource_resume)
 		pv_time_ops.clocksource_resume();

commit 0696b711e4be45fa104c12329f617beb29c03f78
Author: Lin Ming <ming.m.lin@intel.com>
Date:   Tue Nov 17 13:49:50 2009 +0800

    timekeeping: Fix clock_gettime vsyscall time warp
    
    Since commit 0a544198 "timekeeping: Move NTP adjusted clock multiplier
    to struct timekeeper" the clock multiplier of vsyscall is updated with
    the unmodified clock multiplier of the clock source and not with the
    NTP adjusted multiplier of the timekeeper.
    
    This causes user space observerable time warps:
    new CLOCK-warp maximum: 120 nsecs,  00000025c337c537 -> 00000025c337c4bf
    
    Add a new argument "mult" to update_vsyscall() and hand in the
    timekeeping internal NTP adjusted multiplier.
    
    Signed-off-by: Lin Ming <ming.m.lin@intel.com>
    Cc: "Zhang Yanmin" <yanmin_zhang@linux.intel.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Tony Luck <tony.luck@intel.com>
    LKML-Reference: <1258436990.17765.83.camel@minggr.sh.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 4990495d7531..a35c661e5e89 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -473,7 +473,7 @@ void update_vsyscall_tz(void)
 {
 }
 
-void update_vsyscall(struct timespec *wall, struct clocksource *c)
+void update_vsyscall(struct timespec *wall, struct clocksource *c, u32 mult)
 {
         unsigned long flags;
 
@@ -481,7 +481,7 @@ void update_vsyscall(struct timespec *wall, struct clocksource *c)
 
         /* copy fsyscall clock data */
         fsyscall_gtod_data.clk_mask = c->mask;
-        fsyscall_gtod_data.clk_mult = c->mult;
+        fsyscall_gtod_data.clk_mult = mult;
         fsyscall_gtod_data.clk_shift = c->shift;
         fsyscall_gtod_data.clk_fsys_mmio = c->fsys_mmio;
         fsyscall_gtod_data.clk_cycle_last = c->cycle_last;

commit e088a4ad7fa53c3dc3c29f930025f41ccf01953e
Author: Matthew Wilcox <matthew@wil.cx>
Date:   Fri May 22 13:49:49 2009 -0700

    [IA64] Convert ia64 to use int-ll64.h
    
    It is generally agreed that it would be beneficial for u64 to be an
    unsigned long long on all architectures.  ia64 (in common with several
    other 64-bit architectures) currently uses unsigned long.  Migrating
    piecemeal is too painful; this giant patch fixes all compilation warnings
    and errors that come as a result of switching to use int-ll64.h.
    
    Note that userspace will still see __u64 defined as unsigned long.  This
    is important as it affects C++ name mangling.
    
    [Updated by Tony Luck to change efi.h:efi_freemem_callback_t to use
     u64 for start/end rather than unsigned long]
    
    Signed-off-by: Matthew Wilcox <willy@linux.intel.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 604c1a35db33..4990495d7531 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -385,7 +385,7 @@ ia64_init_itm (void)
 
 static cycle_t itc_get_cycles(struct clocksource *cs)
 {
-	u64 lcycle, now, ret;
+	unsigned long lcycle, now, ret;
 
 	if (!itc_jitter_data.itc_jitter)
 		return get_cycles();

commit 8e19608e8b5c001e4a66ce482edc474f05fb7355
Author: Magnus Damm <damm@igel.co.jp>
Date:   Tue Apr 21 12:24:00 2009 -0700

    clocksource: pass clocksource to read() callback
    
    Pass clocksource pointer to the read() callback for clocksources.  This
    allows us to share the callback between multiple instances.
    
    [hugh@veritas.com: fix powerpc build of clocksource pass clocksource mods]
    [akpm@linux-foundation.org: cleanup]
    Signed-off-by: Magnus Damm <damm@igel.co.jp>
    Acked-by: John Stultz <johnstul@us.ibm.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 641c8b61c4f1..604c1a35db33 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -33,7 +33,7 @@
 
 #include "fsyscall_gtod_data.h"
 
-static cycle_t itc_get_cycles(void);
+static cycle_t itc_get_cycles(struct clocksource *cs);
 
 struct fsyscall_gtod_data_t fsyscall_gtod_data = {
 	.lock = SEQLOCK_UNLOCKED,
@@ -383,7 +383,7 @@ ia64_init_itm (void)
 	}
 }
 
-static cycle_t itc_get_cycles(void)
+static cycle_t itc_get_cycles(struct clocksource *cs)
 {
 	u64 lcycle, now, ret;
 

commit 8b53ef33d9d8fa5f771ae11cc6a6e7bc0182beec
Merge: ef5ddd3d5913 80a03e29164c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Apr 1 13:33:41 2009 -0700

    Merge branch 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/aegl/linux-2.6
    
    * 'release' of git://git.kernel.org/pub/scm/linux/kernel/git/aegl/linux-2.6: (29 commits)
      [IA64] BUG to BUG_ON changes
      [IA64] Fix typo/thinko in arch/ia64/sn/kernel/sn2/sn2_smp.c
      ia64: remove some warnings.
      ia64/xen: fix the link error.
      ia64/pv_ops/bp/xen: implemented binary patchable pv_cpu_ops.
      ia64/pv_ops/binary patch: define paravirt_dv_serialize_data() and suppress false positive warning.
      ia64/pv_ops/bp/module: support binary patching for kernel module.
      ia64/pv_ops: implement binary patching optimization for native.
      ia64/pv_op/binarypatch: add helper functions to support binary patching for paravirt_ops.
      ia64/pv_ops/xen/gate.S: xen gate page paravirtualization
      ia64/pv_ops: paravirtualize gate.S.
      ia64/pv_ops: move down __kernel_syscall_via_epc.
      ia64/pv_ops/xen: define xen specific gate page.
      ia64/pv_ops: gate page paravirtualization.
      ia64/pv_ops/xen/pv_time_ops: implement sched_clock.
      ia64/pv_ops/pv_time_ops: add sched_clock hook.
      ia64/pv_ops/xen: paravirtualize read/write ar.itc and ar.itm
      ia64/pv_ops: paravirtualize mov = ar.itc.
      ia64/pv_ops/pvchecker: support mov = ar.itc paravirtualization
      ia64/pv_ops: paravirtualize fsys.S.
      ...

commit 5e3fd9e5810f141c9c70c36992d4ed72b3aa1fed
Author: dann frazier <dannf@dannf.org>
Date:   Tue Mar 31 15:24:48 2009 -0700

    rtc: add platform driver for EFI
    
    Munge Stephane Eranian's efirtc.c code into an rtc platform driver
    
    [akpm@linux-foundation.org: use is_leap_year()]
    Signed-off-by: dann frazier <dannf@hp.com>
    Cc: Alessandro Zummo <alessandro.zummo@towertech.it>
    Cc: stephane eranian <eranian@googlemail.com>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: David Brownell <david-b@pacbell.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index f0ebb342409d..d6747bae52d8 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -20,6 +20,7 @@
 #include <linux/efi.h>
 #include <linux/timex.h>
 #include <linux/clocksource.h>
+#include <linux/platform_device.h>
 
 #include <asm/machvec.h>
 #include <asm/delay.h>
@@ -405,6 +406,21 @@ static struct irqaction timer_irqaction = {
 	.name =		"timer"
 };
 
+static struct platform_device rtc_efi_dev = {
+	.name = "rtc-efi",
+	.id = -1,
+};
+
+static int __init rtc_init(void)
+{
+	if (platform_device_register(&rtc_efi_dev) < 0)
+		printk(KERN_ERR "unable to register rtc device...\n");
+
+	/* not necessarily an error */
+	return 0;
+}
+module_init(rtc_init);
+
 void __init
 time_init (void)
 {

commit f927da178671a824cf6c530f0623544206387e57
Author: Isaku Yamahata <yamahata@valinux.co.jp>
Date:   Wed Mar 4 21:05:40 2009 +0900

    ia64/pv_ops/pv_time_ops: add sched_clock hook.
    
    add sched_clock() hook to paravirtualize sched_clock().
    ia64 sched_clock() is based on ar.itc which isn't stable
    on virtualized environment because vcpu may move around on
    pcpus. So it needs paravirtualization.
    
    Signed-off-by: Isaku Yamahata <yamahata@valinux.co.jp>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index f0ebb342409d..c323c7b9c775 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -49,6 +49,15 @@ EXPORT_SYMBOL(last_cli_ip);
 
 #endif
 
+#ifdef CONFIG_PARAVIRT
+/* We need to define a real function for sched_clock, to override the
+   weak default version */
+unsigned long long sched_clock(void)
+{
+        return paravirt_sched_clock();
+}
+#endif
+
 #ifdef CONFIG_PARAVIRT
 static void
 paravirt_clocksource_resume(void)

commit 79741dd35713ff4f6fd0eafd59fa94e8a4ba922d
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Wed Dec 31 15:11:38 2008 +0100

    [PATCH] idle cputime accounting
    
    The cpu time spent by the idle process actually doing something is
    currently accounted as idle time. This is plain wrong, the architectures
    that support VIRT_CPU_ACCOUNTING=y can do better: distinguish between the
    time spent doing nothing and the time spent by idle doing work. The first
    is accounted with account_idle_time and the second with account_system_time.
    The architectures that use the account_xxx_time interface directly and not
    the account_xxx_ticks interface now need to do the check for the idle
    process in their arch code. In particular to improve the system vs true
    idle time accounting the arch code needs to measure the true idle time
    instead of just testing for the idle process.
    To improve the tick based accounting as well we would need an architecture
    primitive that can tell us if the pt_regs of the interrupted context
    points to the magic instruction that halts the cpu.
    
    In addition idle time is no more added to the stime of the idle process.
    This field now contains the system time of the idle process as it should
    be. On systems without VIRT_CPU_ACCOUNTING this will always be zero as
    every tick that occurs while idle is running will be accounted as idle
    time.
    
    This patch contains the necessary common code changes to be able to
    distinguish idle system time and true idle time. The architectures with
    support for VIRT_CPU_ACCOUNTING need some changes to exploit this.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 4ee367817049..f0ebb342409d 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -93,7 +93,10 @@ void ia64_account_on_switch(struct task_struct *prev, struct task_struct *next)
 	now = ia64_get_itc();
 
 	delta_stime = cycle_to_cputime(pi->ac_stime + (now - pi->ac_stamp));
-	account_system_time(prev, 0, delta_stime, delta_stime);
+	if (idle_task(smp_processor_id()) != prev)
+		account_system_time(prev, 0, delta_stime, delta_stime);
+	else
+		account_idle_time(delta_stime);
 
 	if (pi->ac_utime) {
 		delta_utime = cycle_to_cputime(pi->ac_utime);
@@ -120,7 +123,10 @@ void account_system_vtime(struct task_struct *tsk)
 	now = ia64_get_itc();
 
 	delta_stime = cycle_to_cputime(ti->ac_stime + (now - ti->ac_stamp));
-	account_system_time(tsk, 0, delta_stime, delta_stime);
+	if (irq_count() || idle_task(smp_processor_id()) != tsk)
+		account_system_time(tsk, 0, delta_stime, delta_stime);
+	else
+		account_idle_time(delta_stime);
 	ti->ac_stime = 0;
 
 	ti->ac_stamp = now;

commit 457533a7d3402d1d91fbc125c8bd1bd16dcd3cd4
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Wed Dec 31 15:11:37 2008 +0100

    [PATCH] fix scaled & unscaled cputime accounting
    
    The utimescaled / stimescaled fields in the task structure and the
    global cpustat should be set on all architectures. On s390 the calls
    to account_user_time_scaled and account_system_time_scaled never have
    been added. In addition system time that is accounted as guest time
    to the user time of a process is accounted to the scaled system time
    instead of the scaled user time.
    To fix the bugs and to prevent future forgetfulness this patch merges
    account_system_time_scaled into account_system_time and
    account_user_time_scaled into account_user_time.
    
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Jeremy Fitzhardinge <jeremy@xensource.com>
    Cc: Chris Wright <chrisw@sous-sol.org>
    Cc: Michael Neuling <mikey@neuling.org>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 65c10a42c88f..4ee367817049 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -93,13 +93,11 @@ void ia64_account_on_switch(struct task_struct *prev, struct task_struct *next)
 	now = ia64_get_itc();
 
 	delta_stime = cycle_to_cputime(pi->ac_stime + (now - pi->ac_stamp));
-	account_system_time(prev, 0, delta_stime);
-	account_system_time_scaled(prev, delta_stime);
+	account_system_time(prev, 0, delta_stime, delta_stime);
 
 	if (pi->ac_utime) {
 		delta_utime = cycle_to_cputime(pi->ac_utime);
-		account_user_time(prev, delta_utime);
-		account_user_time_scaled(prev, delta_utime);
+		account_user_time(prev, delta_utime, delta_utime);
 	}
 
 	pi->ac_stamp = ni->ac_stamp = now;
@@ -122,8 +120,7 @@ void account_system_vtime(struct task_struct *tsk)
 	now = ia64_get_itc();
 
 	delta_stime = cycle_to_cputime(ti->ac_stime + (now - ti->ac_stamp));
-	account_system_time(tsk, 0, delta_stime);
-	account_system_time_scaled(tsk, delta_stime);
+	account_system_time(tsk, 0, delta_stime, delta_stime);
 	ti->ac_stime = 0;
 
 	ti->ac_stamp = now;
@@ -143,8 +140,7 @@ void account_process_tick(struct task_struct *p, int user_tick)
 
 	if (ti->ac_utime) {
 		delta_utime = cycle_to_cputime(ti->ac_utime);
-		account_user_time(p, delta_utime);
-		account_user_time_scaled(p, delta_utime);
+		account_user_time(p, delta_utime, delta_utime);
 		ti->ac_utime = 0;
 	}
 }

commit fca515fbfa5ecd9f7b54db311317e2c877d7831a
Merge: 2b04be7e8ab5 4d58bbcc89e2
Author: Tony Luck <tony.luck@intel.com>
Date:   Thu Jul 17 10:53:37 2008 -0700

    Pull pvops into release branch

commit 3a677d216445dba3332a000063405de3fc135859
Author: Doug Chapman <doug.chapman@hp.com>
Date:   Mon Jun 30 15:06:48 2008 -0700

    [IA64] export account_system_vtime
    
    The symbol account_system_vtime is used by the kvm module but
    not exported.  This breaks building with CONFIG_VIRT_CPU_ACCOUNTING
    and CONFIG_KVM=m.
    
    Signed-off-by: Doug Chapman <doug.chapman@hp.com>
    Acked-by: Hidetosho Seto <seto.hidetoshi@jp.fujitsu.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 8c73643f2d66..aad1b7b1fff9 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -117,6 +117,7 @@ void account_system_vtime(struct task_struct *tsk)
 
 	local_irq_restore(flags);
 }
+EXPORT_SYMBOL_GPL(account_system_vtime);
 
 /*
  * Called from the timer interrupt handler to charge accumulated user time

commit 00d21d82b8a9e290286e09d8eedc20bfc33b0eee
Author: Isaku Yamahata <yamahata@valinux.co.jp>
Date:   Mon May 19 22:13:44 2008 +0900

    [IA64] pvops: add to hooks, pv_time_ops, for steal time accounting.
    
    Introduce pv_time_ops which adds hook to steal time accounting.
    On virtualized environment, cpus are shared by many guests and
    steal time is the time which is used for other guests.
    On virtualized environtment, streal time should be accounted.
    
    Signed-off-by: Isaku Yamahata <yamahata@valinux.co.jp>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 8c73643f2d66..046ca89efc05 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -24,6 +24,7 @@
 #include <asm/machvec.h>
 #include <asm/delay.h>
 #include <asm/hw_irq.h>
+#include <asm/paravirt.h>
 #include <asm/ptrace.h>
 #include <asm/sal.h>
 #include <asm/sections.h>
@@ -48,6 +49,15 @@ EXPORT_SYMBOL(last_cli_ip);
 
 #endif
 
+#ifdef CONFIG_PARAVIRT
+static void
+paravirt_clocksource_resume(void)
+{
+	if (pv_time_ops.clocksource_resume)
+		pv_time_ops.clocksource_resume();
+}
+#endif
+
 static struct clocksource clocksource_itc = {
 	.name           = "itc",
 	.rating         = 350,
@@ -56,6 +66,9 @@ static struct clocksource clocksource_itc = {
 	.mult           = 0, /*to be calculated*/
 	.shift          = 16,
 	.flags          = CLOCK_SOURCE_IS_CONTINUOUS,
+#ifdef CONFIG_PARAVIRT
+	.resume		= paravirt_clocksource_resume,
+#endif
 };
 static struct clocksource *itc_clocksource;
 
@@ -156,6 +169,9 @@ timer_interrupt (int irq, void *dev_id)
 
 	profile_tick(CPU_PROFILING);
 
+	if (paravirt_do_steal_accounting(&new_itm))
+		goto skip_process_time_accounting;
+
 	while (1) {
 		update_process_times(user_mode(get_irq_regs()));
 
@@ -185,6 +201,8 @@ timer_interrupt (int irq, void *dev_id)
 		local_irq_disable();
 	}
 
+skip_process_time_accounting:
+
 	do {
 		/*
 		 * If we're too close to the next clock tick for
@@ -334,6 +352,11 @@ ia64_init_itm (void)
 		 */
 		clocksource_itc.rating = 50;
 
+	paravirt_init_missing_ticks_accounting(smp_processor_id());
+
+	/* avoid softlock up message when cpu is unplug and plugged again. */
+	touch_softlockup_watchdog();
+
 	/* Setup the CPU local timer tick */
 	ia64_cpu_local_tick();
 

commit 751fc7849d623bcd5e77fd494b01662599a8dccf
Author: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
Date:   Wed Apr 30 16:50:43 2008 +0900

    [IA64] fix section mismatch in arch/ia64/kernel/irq.c
    
    This patch shuts up the following:
    
            WARNING: vmlinux.o(.text+0x7102): Section mismatch in
            reference from the function fixup_irqs() to the function
            .devinit.text:ia64_disable_timer()
    
    Removing ia64_disable_timer() is safe because there are no functions
    calling it other than the fixup_irqs(),
    
    Signed-off-by: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 48e15a51782f..8c73643f2d66 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -379,11 +379,6 @@ static struct irqaction timer_irqaction = {
 	.name =		"timer"
 };
 
-void __devinit ia64_disable_timer(void)
-{
-	ia64_set_itv(1 << 16);
-}
-
 void __init
 time_init (void)
 {

commit b64f34cdfe5bef9dfed1304c513220b0f2862eca
Author: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
Date:   Tue Jan 29 14:27:30 2008 +0900

    [IA64] VIRT_CPU_ACCOUNTING (accurate cpu time accounting)
    
    This patch implements VIRT_CPU_ACCOUNTING for ia64,
    which enable us to use more accurate cpu time accounting.
    
    The VIRT_CPU_ACCOUNTING is an item of kernel config, which s390
    and powerpc arch have.  By turning this config on, these archs
    change the mechanism of cpu time accounting from tick-sampling
    based one to state-transition based one.
    
    The state-transition based accounting is done by checking time
    (cycle counter in processor) at every state-transition point,
    such as entrance/exit of kernel, interrupt, softirq etc.
    The difference between point to point is the actual time consumed
    during in the state. There is no doubt about that this value is
    more accurate than that of tick-sampling based accounting.
    
    Signed-off-by: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 17fda5293c67..48e15a51782f 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -59,6 +59,84 @@ static struct clocksource clocksource_itc = {
 };
 static struct clocksource *itc_clocksource;
 
+#ifdef CONFIG_VIRT_CPU_ACCOUNTING
+
+#include <linux/kernel_stat.h>
+
+extern cputime_t cycle_to_cputime(u64 cyc);
+
+/*
+ * Called from the context switch with interrupts disabled, to charge all
+ * accumulated times to the current process, and to prepare accounting on
+ * the next process.
+ */
+void ia64_account_on_switch(struct task_struct *prev, struct task_struct *next)
+{
+	struct thread_info *pi = task_thread_info(prev);
+	struct thread_info *ni = task_thread_info(next);
+	cputime_t delta_stime, delta_utime;
+	__u64 now;
+
+	now = ia64_get_itc();
+
+	delta_stime = cycle_to_cputime(pi->ac_stime + (now - pi->ac_stamp));
+	account_system_time(prev, 0, delta_stime);
+	account_system_time_scaled(prev, delta_stime);
+
+	if (pi->ac_utime) {
+		delta_utime = cycle_to_cputime(pi->ac_utime);
+		account_user_time(prev, delta_utime);
+		account_user_time_scaled(prev, delta_utime);
+	}
+
+	pi->ac_stamp = ni->ac_stamp = now;
+	ni->ac_stime = ni->ac_utime = 0;
+}
+
+/*
+ * Account time for a transition between system, hard irq or soft irq state.
+ * Note that this function is called with interrupts enabled.
+ */
+void account_system_vtime(struct task_struct *tsk)
+{
+	struct thread_info *ti = task_thread_info(tsk);
+	unsigned long flags;
+	cputime_t delta_stime;
+	__u64 now;
+
+	local_irq_save(flags);
+
+	now = ia64_get_itc();
+
+	delta_stime = cycle_to_cputime(ti->ac_stime + (now - ti->ac_stamp));
+	account_system_time(tsk, 0, delta_stime);
+	account_system_time_scaled(tsk, delta_stime);
+	ti->ac_stime = 0;
+
+	ti->ac_stamp = now;
+
+	local_irq_restore(flags);
+}
+
+/*
+ * Called from the timer interrupt handler to charge accumulated user time
+ * to the current process.  Must be called with interrupts disabled.
+ */
+void account_process_tick(struct task_struct *p, int user_tick)
+{
+	struct thread_info *ti = task_thread_info(p);
+	cputime_t delta_utime;
+
+	if (ti->ac_utime) {
+		delta_utime = cycle_to_cputime(ti->ac_utime);
+		account_user_time(p, delta_utime);
+		account_user_time_scaled(p, delta_utime);
+		ti->ac_utime = 0;
+	}
+}
+
+#endif /* CONFIG_VIRT_CPU_ACCOUNTING */
+
 static irqreturn_t
 timer_interrupt (int irq, void *dev_id)
 {

commit 3eb056764dd806bbe84eb604e45e7470feeaafd8
Author: Li Zefan <lizf@cn.fujitsu.com>
Date:   Fri Feb 8 04:19:25 2008 -0800

    time: fix typo in comments
    
    Fix typo in comments.
    
    BTW: I have to fix coding style in arch/ia64/kernel/time.c also, otherwise
    checkpatch.pl will be complaining.
    
    Signed-off-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: john stultz <johnstul@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 3ab042720970..17fda5293c67 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -49,13 +49,13 @@ EXPORT_SYMBOL(last_cli_ip);
 #endif
 
 static struct clocksource clocksource_itc = {
-        .name           = "itc",
-        .rating         = 350,
-        .read           = itc_get_cycles,
-        .mask           = CLOCKSOURCE_MASK(64),
-        .mult           = 0, /*to be caluclated*/
-        .shift          = 16,
-        .flags          = CLOCK_SOURCE_IS_CONTINUOUS,
+	.name           = "itc",
+	.rating         = 350,
+	.read           = itc_get_cycles,
+	.mask           = CLOCKSOURCE_MASK(64),
+	.mult           = 0, /*to be calculated*/
+	.shift          = 16,
+	.flags          = CLOCK_SOURCE_IS_CONTINUOUS,
 };
 static struct clocksource *itc_clocksource;
 

commit b842271fbb9c8b5fd0e1c3e1895a3b67ba5bcc54
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Jan 25 21:07:59 2008 +0100

    sched: remove printk_clock()
    
    printk_clock() is obsolete - it has been replaced with cpu_clock().
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 2bb84214e5f1..3ab042720970 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -344,33 +344,6 @@ udelay (unsigned long usecs)
 }
 EXPORT_SYMBOL(udelay);
 
-static unsigned long long ia64_itc_printk_clock(void)
-{
-	if (ia64_get_kr(IA64_KR_PER_CPU_DATA))
-		return sched_clock();
-	return 0;
-}
-
-static unsigned long long ia64_default_printk_clock(void)
-{
-	return (unsigned long long)(jiffies_64 - INITIAL_JIFFIES) *
-		(1000000000/HZ);
-}
-
-unsigned long long (*ia64_printk_clock)(void) = &ia64_default_printk_clock;
-
-unsigned long long printk_clock(void)
-{
-	return ia64_printk_clock();
-}
-
-void __init
-ia64_setup_printk_clock(void)
-{
-	if (!(sal_platform_features & IA64_SAL_PLATFORM_FEATURE_ITC_DRIFT))
-		ia64_printk_clock = ia64_itc_printk_clock;
-}
-
 /* IA64 doesn't cache the timezone */
 void update_vsyscall_tz(void)
 {

commit 2c6221483169ddd4c04797cd7296ed4fe52fcdd7
Author: Tony Breeds <tony@bakeyournoodle.com>
Date:   Thu Oct 18 03:04:57 2007 -0700

    Fix discrepancy between VDSO based gettimeofday() and sys_gettimeofday().
    
    On platforms that copy sys_tz into the vdso (currently only x86_64, soon to
    include powerpc), it is possible for the vdso to get out of sync if a user
    calls (admittedly unusual) settimeofday(NULL, ptr).
    
    This patch adds a hook for architectures that set
    CONFIG_GENERIC_TIME_VSYSCALL to ensure when sys_tz is updated they can also
    updatee their copy in the vdso.
    
    Signed-off-by: Tony Breeds <tony@bakeyournoodle.com>
    Cc: Andi Kleen <ak@suse.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Acked-by: John Stultz <johnstul@us.ibm.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 98cfc90cab1d..2bb84214e5f1 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -371,6 +371,11 @@ ia64_setup_printk_clock(void)
 		ia64_printk_clock = ia64_itc_printk_clock;
 }
 
+/* IA64 doesn't cache the timezone */
+void update_vsyscall_tz(void)
+{
+}
+
 void update_vsyscall(struct timespec *wall, struct clocksource *c)
 {
         unsigned long flags;

commit b718f91c14604e4ab5cdfe8d3baff8111425ea7d
Author: Christoph Lameter <clameter@sgi.com>
Date:   Wed Aug 1 13:49:45 2007 -0700

    [IA64] ITC: Reduce rating for ITC clock if ITCs are drifty
    
    Make sure to reduce the rating of the ITC clock if ITCs are drifty. If they
    are drifting then we have not synchronized the ITC values, nor are we doing
    the jitter compensation (useless since drift may increase the differentials
    arbitrarily).
    
    Without this patch it is possible that the ITC clock becomes selected as
    the system clock on systems with drifty ITCs which will result in
    nanosleep hanging.
    
    One can still select the itc clock manually on such systems via
    
    clocksource=itc
    
    (Produces nice hangs on SGI Altix.)
    
    Signed-off-by: Christoph Lameter <clameter@sgi.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 6c0e9e2e1b82..98cfc90cab1d 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -240,7 +240,21 @@ ia64_init_itm (void)
 		if (!nojitter)
 			itc_jitter_data.itc_jitter = 1;
 #endif
-	}
+	} else
+		/*
+		 * ITC is drifty and we have not synchronized the ITCs in smpboot.c.
+		 * ITC values may fluctuate significantly between processors.
+		 * Clock should not be used for hrtimers. Mark itc as only
+		 * useful for boot and testing.
+		 *
+		 * Note that jitter compensation is off! There is no point of
+		 * synchronizing ITCs since they may be large differentials
+		 * that change over time.
+		 *
+		 * The only way to fix this would be to repeatedly sync the
+		 * ITCs. Until that time we have to avoid ITC.
+		 */
+		clocksource_itc.rating = 50;
 
 	/* Setup the CPU local timer tick */
 	ia64_cpu_local_tick();

commit 712aaa1cb1c0a83e5ffb5376e1d7ee3dd539f4e4
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Thu Jul 26 17:34:49 2007 +0100

    use CLOCKSOURCE_MASK() instead of too large constant
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 1169d46126ac..6c0e9e2e1b82 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -52,7 +52,7 @@ static struct clocksource clocksource_itc = {
         .name           = "itc",
         .rating         = 350,
         .read           = itc_get_cycles,
-        .mask           = 0xffffffffffffffff,
+        .mask           = CLOCKSOURCE_MASK(64),
         .mult           = 0, /*to be caluclated*/
         .shift          = 16,
         .flags          = CLOCK_SOURCE_IS_CONTINUOUS,

commit 8dc946307c45ab9a6f56c56371e1ccfb7155015e
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Thu Jul 26 17:34:29 2007 +0100

    ia64 time.c: ANSIfy
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 627785c48ea9..1169d46126ac 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -255,7 +255,7 @@ ia64_init_itm (void)
 	}
 }
 
-static cycle_t itc_get_cycles()
+static cycle_t itc_get_cycles(void)
 {
 	u64 lcycle, now, ret;
 

commit 0aa366f351d044703e25c8425e508170e80d83b1
Author: Tony Luck <tony.luck@intel.com>
Date:   Fri Jul 20 11:22:30 2007 -0700

    [IA64] Convert to generic timekeeping/clocksource
    
    This is a merge of Peter Keilty's initial patch (which was
    revived by Bob Picco) for this with Hidetoshi Seto's fixes
    and scaling improvements.
    
    Acked-by: Bob Picco <bob.picco@hp.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 3486fe7d6e65..627785c48ea9 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -19,6 +19,7 @@
 #include <linux/interrupt.h>
 #include <linux/efi.h>
 #include <linux/timex.h>
+#include <linux/clocksource.h>
 
 #include <asm/machvec.h>
 #include <asm/delay.h>
@@ -28,6 +29,16 @@
 #include <asm/sections.h>
 #include <asm/system.h>
 
+#include "fsyscall_gtod_data.h"
+
+static cycle_t itc_get_cycles(void);
+
+struct fsyscall_gtod_data_t fsyscall_gtod_data = {
+	.lock = SEQLOCK_UNLOCKED,
+};
+
+struct itc_jitter_data_t itc_jitter_data;
+
 volatile int time_keeper_id = 0; /* smp_processor_id() of time-keeper */
 
 #ifdef CONFIG_IA64_DEBUG_IRQ
@@ -37,11 +48,16 @@ EXPORT_SYMBOL(last_cli_ip);
 
 #endif
 
-static struct time_interpolator itc_interpolator = {
-	.shift = 16,
-	.mask = 0xffffffffffffffffLL,
-	.source = TIME_SOURCE_CPU
+static struct clocksource clocksource_itc = {
+        .name           = "itc",
+        .rating         = 350,
+        .read           = itc_get_cycles,
+        .mask           = 0xffffffffffffffff,
+        .mult           = 0, /*to be caluclated*/
+        .shift          = 16,
+        .flags          = CLOCK_SOURCE_IS_CONTINUOUS,
 };
+static struct clocksource *itc_clocksource;
 
 static irqreturn_t
 timer_interrupt (int irq, void *dev_id)
@@ -210,8 +226,6 @@ ia64_init_itm (void)
 					+ itc_freq/2)/itc_freq;
 
 	if (!(sal_platform_features & IA64_SAL_PLATFORM_FEATURE_ITC_DRIFT)) {
-		itc_interpolator.frequency = local_cpu_data->itc_freq;
-		itc_interpolator.drift = itc_drift;
 #ifdef CONFIG_SMP
 		/* On IA64 in an SMP configuration ITCs are never accurately synchronized.
 		 * Jitter compensation requires a cmpxchg which may limit
@@ -223,15 +237,50 @@ ia64_init_itm (void)
 		 * even going backward) if the ITC offsets between the individual CPUs
 		 * are too large.
 		 */
-		if (!nojitter) itc_interpolator.jitter = 1;
+		if (!nojitter)
+			itc_jitter_data.itc_jitter = 1;
 #endif
-		register_time_interpolator(&itc_interpolator);
 	}
 
 	/* Setup the CPU local timer tick */
 	ia64_cpu_local_tick();
+
+	if (!itc_clocksource) {
+		/* Sort out mult/shift values: */
+		clocksource_itc.mult =
+			clocksource_hz2mult(local_cpu_data->itc_freq,
+						clocksource_itc.shift);
+		clocksource_register(&clocksource_itc);
+		itc_clocksource = &clocksource_itc;
+	}
 }
 
+static cycle_t itc_get_cycles()
+{
+	u64 lcycle, now, ret;
+
+	if (!itc_jitter_data.itc_jitter)
+		return get_cycles();
+
+	lcycle = itc_jitter_data.itc_lastcycle;
+	now = get_cycles();
+	if (lcycle && time_after(lcycle, now))
+		return lcycle;
+
+	/*
+	 * Keep track of the last timer value returned.
+	 * In an SMP environment, you could lose out in contention of
+	 * cmpxchg. If so, your cmpxchg returns new value which the
+	 * winner of contention updated to. Use the new value instead.
+	 */
+	ret = cmpxchg(&itc_jitter_data.itc_lastcycle, lcycle, now);
+	if (unlikely(ret != lcycle))
+		return ret;
+
+	return now;
+}
+
+
 static struct irqaction timer_irqaction = {
 	.handler =	timer_interrupt,
 	.flags =	IRQF_DISABLED | IRQF_IRQPOLL,
@@ -307,3 +356,34 @@ ia64_setup_printk_clock(void)
 	if (!(sal_platform_features & IA64_SAL_PLATFORM_FEATURE_ITC_DRIFT))
 		ia64_printk_clock = ia64_itc_printk_clock;
 }
+
+void update_vsyscall(struct timespec *wall, struct clocksource *c)
+{
+        unsigned long flags;
+
+        write_seqlock_irqsave(&fsyscall_gtod_data.lock, flags);
+
+        /* copy fsyscall clock data */
+        fsyscall_gtod_data.clk_mask = c->mask;
+        fsyscall_gtod_data.clk_mult = c->mult;
+        fsyscall_gtod_data.clk_shift = c->shift;
+        fsyscall_gtod_data.clk_fsys_mmio = c->fsys_mmio;
+        fsyscall_gtod_data.clk_cycle_last = c->cycle_last;
+
+	/* copy kernel time structures */
+        fsyscall_gtod_data.wall_time.tv_sec = wall->tv_sec;
+        fsyscall_gtod_data.wall_time.tv_nsec = wall->tv_nsec;
+        fsyscall_gtod_data.monotonic_time.tv_sec = wall_to_monotonic.tv_sec
+							+ wall->tv_sec;
+        fsyscall_gtod_data.monotonic_time.tv_nsec = wall_to_monotonic.tv_nsec
+							+ wall->tv_nsec;
+
+	/* normalize */
+	while (fsyscall_gtod_data.monotonic_time.tv_nsec >= NSEC_PER_SEC) {
+		fsyscall_gtod_data.monotonic_time.tv_nsec -= NSEC_PER_SEC;
+		fsyscall_gtod_data.monotonic_time.tv_sec++;
+	}
+
+        write_sequnlock_irqrestore(&fsyscall_gtod_data.lock, flags);
+}
+

commit 2e77ff21d225f7676517ac895df2be8ada573f4f
Author: MUNEDA Takahiro <muneda.takahiro@jp.fujitsu.com>
Date:   Wed Jun 20 13:00:00 2007 +0900

    [IA64] remove duplicate header include line
    
    Remove duplicate header include line from arch/ia64/kernel/time.c.
    
    Signed-off-by: MUNEDA Takahiro <muneda.takahiro@jp.fujitsu.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index a06667c7acc0..3486fe7d6e65 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -18,7 +18,6 @@
 #include <linux/time.h>
 #include <linux/interrupt.h>
 #include <linux/efi.h>
-#include <linux/profile.h>
 #include <linux/timex.h>
 
 #include <asm/machvec.h>

commit d217c265dc60ebfaa05ca003e9873476382de225
Author: Bernhard Walle <bwalle@suse.de>
Date:   Tue May 8 00:35:31 2007 -0700

    Add IRQF_IRQPOLL flag on IA64
    
    Add IRQF_IRQPOLL for the timer interrupt on IA64.
    
    Signed-off-by: Bernhard Walle <bwalle@suse.de>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 39e0cd3a0884..a06667c7acc0 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -235,7 +235,7 @@ ia64_init_itm (void)
 
 static struct irqaction timer_irqaction = {
 	.handler =	timer_interrupt,
-	.flags =	IRQF_DISABLED,
+	.flags =	IRQF_DISABLED | IRQF_IRQPOLL,
 	.name =		"timer"
 };
 

commit accaddb27a2d544e38e10ff2a2782b33bbbad913
Author: Jack Steiner <steiner@sgi.com>
Date:   Mon Oct 16 12:56:54 2006 -0500

    [IA64] - Allow IPIs in timer loop
    
    Allow pending IPIs to interrupt a timer interrupt that is looping
    in the do_timer() "while" loop in timer_interrupt(). (Interrupts are
    allowed at only 1 spot in the code).
    
    Signed-off-by: Jack Steiner <steiner@sgi.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 41169a9bc301..39e0cd3a0884 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -84,6 +84,12 @@ timer_interrupt (int irq, void *dev_id)
 
 		if (time_after(new_itm, ia64_get_itc()))
 			break;
+
+		/*
+		 * Allow IPIs to interrupt the timer loop.
+		 */
+		local_irq_enable();
+		local_irq_disable();
 	}
 
 	do {

commit 7d12e780e003f93433d49ce78cfedf4b4c52adc5
Author: David Howells <dhowells@redhat.com>
Date:   Thu Oct 5 14:55:46 2006 +0100

    IRQ: Maintain regs pointer globally rather than passing to IRQ handlers
    
    Maintain a per-CPU global "struct pt_regs *" variable which can be used instead
    of passing regs around manually through all ~1800 interrupt handlers in the
    Linux kernel.
    
    The regs pointer is used in few places, but it potentially costs both stack
    space and code to pass it around.  On the FRV arch, removing the regs parameter
    from all the genirq function results in a 20% speed up of the IRQ exit path
    (ie: from leaving timer_interrupt() to leaving do_IRQ()).
    
    Where appropriate, an arch may override the generic storage facility and do
    something different with the variable.  On FRV, for instance, the address is
    maintained in GR28 at all times inside the kernel as part of general exception
    handling.
    
    Having looked over the code, it appears that the parameter may be handed down
    through up to twenty or so layers of functions.  Consider a USB character
    device attached to a USB hub, attached to a USB controller that posts its
    interrupts through a cascaded auxiliary interrupt controller.  A character
    device driver may want to pass regs to the sysrq handler through the input
    layer which adds another few layers of parameter passing.
    
    I've build this code with allyesconfig for x86_64 and i386.  I've runtested the
    main part of the code on FRV and i386, though I can't test most of the drivers.
    I've also done partial conversion for powerpc and MIPS - these at least compile
    with minimal configurations.
    
    This will affect all archs.  Mostly the changes should be relatively easy.
    Take do_IRQ(), store the regs pointer at the beginning, saving the old one:
    
            struct pt_regs *old_regs = set_irq_regs(regs);
    
    And put the old one back at the end:
    
            set_irq_regs(old_regs);
    
    Don't pass regs through to generic_handle_irq() or __do_IRQ().
    
    In timer_interrupt(), this sort of change will be necessary:
    
            -       update_process_times(user_mode(regs));
            -       profile_tick(CPU_PROFILING, regs);
            +       update_process_times(user_mode(get_irq_regs()));
            +       profile_tick(CPU_PROFILING);
    
    I'd like to move update_process_times()'s use of get_irq_regs() into itself,
    except that i386, alone of the archs, uses something other than user_mode().
    
    Some notes on the interrupt handling in the drivers:
    
     (*) input_dev() is now gone entirely.  The regs pointer is no longer stored in
         the input_dev struct.
    
     (*) finish_unlinks() in drivers/usb/host/ohci-q.c needs checking.  It does
         something different depending on whether it's been supplied with a regs
         pointer or not.
    
     (*) Various IRQ handler function pointers have been moved to type
         irq_handler_t.
    
    Signed-Off-By: David Howells <dhowells@redhat.com>
    (cherry picked from 1b16e7ac850969f38b375e511e3fa2f474a33867 commit)

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 62e07f906e05..41169a9bc301 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -45,7 +45,7 @@ static struct time_interpolator itc_interpolator = {
 };
 
 static irqreturn_t
-timer_interrupt (int irq, void *dev_id, struct pt_regs *regs)
+timer_interrupt (int irq, void *dev_id)
 {
 	unsigned long new_itm;
 
@@ -53,7 +53,7 @@ timer_interrupt (int irq, void *dev_id, struct pt_regs *regs)
 		return IRQ_HANDLED;
 	}
 
-	platform_timer_interrupt(irq, dev_id, regs);
+	platform_timer_interrupt(irq, dev_id);
 
 	new_itm = local_cpu_data->itm_next;
 
@@ -61,10 +61,10 @@ timer_interrupt (int irq, void *dev_id, struct pt_regs *regs)
 		printk(KERN_ERR "Oops: timer tick before it's due (itc=%lx,itm=%lx)\n",
 		       ia64_get_itc(), new_itm);
 
-	profile_tick(CPU_PROFILING, regs);
+	profile_tick(CPU_PROFILING);
 
 	while (1) {
-		update_process_times(user_mode(regs));
+		update_process_times(user_mode(get_irq_regs()));
 
 		new_itm += local_cpu_data->itm_delta;
 

commit 8ef386092d7c2891bd7acefb2a87f878f7e9a0d6
Author: Atsushi Nemoto <anemo@mba.ocn.ne.jp>
Date:   Sat Sep 30 23:28:31 2006 -0700

    [PATCH] kill wall_jiffies
    
    With 2.6.18-rc4-mm2, now wall_jiffies will always be the same as jiffies.
    So we can kill wall_jiffies completely.
    
    This is just a cleanup and logically should not change any real behavior
    except for one thing: RTC updating code in (old) ppc and xtensa use a
    condition "jiffies - wall_jiffies == 1".  This condition is never met so I
    suppose it is just a bug.  I just remove that condition only instead of
    kill the whole "if" block.
    
    [heiko.carstens@de.ibm.com: s390 build fix and cleanup]
    Signed-off-by: Atsushi Nemoto <anemo@mba.ocn.ne.jp>
    Cc: Andi Kleen <ak@muc.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Ian Molton <spyro@f2s.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Hirokazu Takata <takata.hirokazu@renesas.com>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Kazumoto Kojima <kkojima@rr.iij4u.or.jp>
    Cc: Richard Curnow <rc@rc0.org.uk>
    Cc: William Lee Irwin III <wli@holomorphy.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Paolo 'Blaisorblade' Giarrusso <blaisorblade@yahoo.it>
    Cc: Miles Bader <uclinux-v850@lsi.nec.co.jp>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 16262687a103..62e07f906e05 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -29,8 +29,6 @@
 #include <asm/sections.h>
 #include <asm/system.h>
 
-extern unsigned long wall_jiffies;
-
 volatile int time_keeper_id = 0; /* smp_processor_id() of time-keeper */
 
 #ifdef CONFIG_IA64_DEBUG_IRQ

commit 3171a0305d62e6627a24bff35af4f997e4988a80
Author: Atsushi Nemoto <anemo@mba.ocn.ne.jp>
Date:   Fri Sep 29 02:00:32 2006 -0700

    [PATCH] simplify update_times (avoid jiffies/jiffies_64 aliasing problem)
    
    Pass ticks to do_timer() and update_times(), and adjust x86_64 and s390
    timer interrupt handler with this change.
    
    Currently update_times() calculates ticks by "jiffies - wall_jiffies", but
    callers of do_timer() should know how many ticks to update.  Passing ticks
    get rid of this redundant calculation.  Also there are another redundancy
    pointed out by Martin Schwidefsky.
    
    This cleanup make a barrier added by
    5aee405c662ca644980c184774277fc6d0769a84 needless.  So this patch removes
    it.
    
    As a bonus, this cleanup make wall_jiffies can be removed easily, since now
    wall_jiffies is always synced with jiffies.  (This patch does not really
    remove wall_jiffies.  It would be another cleanup patch)
    
    Signed-off-by: Atsushi Nemoto <anemo@mba.ocn.ne.jp>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: john stultz <johnstul@us.ibm.com>
    Cc: Andi Kleen <ak@muc.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Acked-by: Russell King <rmk@arm.linux.org.uk>
    Cc: Ian Molton <spyro@f2s.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Hirokazu Takata <takata.hirokazu@renesas.com>
    Acked-by: Ralf Baechle <ralf@linux-mips.org>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Kazumoto Kojima <kkojima@rr.iij4u.or.jp>
    Cc: Richard Curnow <rc@rc0.org.uk>
    Cc: William Lee Irwin III <wli@holomorphy.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Paolo 'Blaisorblade' Giarrusso <blaisorblade@yahoo.it>
    Cc: Miles Bader <uclinux-v850@lsi.nec.co.jp>
    Cc: Chris Zankel <chris@zankel.net>
    Acked-by: "Luck, Tony" <tony.luck@intel.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 6928ef0d64d8..16262687a103 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -78,7 +78,7 @@ timer_interrupt (int irq, void *dev_id, struct pt_regs *regs)
 			 * xtime_lock.
 			 */
 			write_seqlock(&xtime_lock);
-			do_timer(regs);
+			do_timer(1);
 			local_cpu_data->itm_next = new_itm;
 			write_sequnlock(&xtime_lock);
 		} else

commit 121a4226e89aae6654d667d58ab72df740b97b92
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 1 19:29:17 2006 -0700

    [PATCH] irq-flags: IA64: Use the new IRQF_ constants
    
    Use the new IRQF_ constants and remove the SA_INTERRUPT define
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 71ccddabc715..6928ef0d64d8 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -231,7 +231,7 @@ ia64_init_itm (void)
 
 static struct irqaction timer_irqaction = {
 	.handler =	timer_interrupt,
-	.flags =	SA_INTERRUPT,
+	.flags =	IRQF_DISABLED,
 	.name =		"timer"
 };
 

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: Jrn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: Jrn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 49958904045b..71ccddabc715 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -8,7 +8,6 @@
  * Copyright (C) 1999-2000 VA Linux Systems
  * Copyright (C) 1999-2000 Walt Drummond <drummond@valinux.com>
  */
-#include <linux/config.h>
 
 #include <linux/cpu.h>
 #include <linux/init.h>

commit 2ab9391dea6e36fed13443c29bf97d3be05f5289
Author: Tony Luck <tony.luck@intel.com>
Date:   Fri Mar 31 10:28:29 2006 -0800

    [IA64] Avoid "u64 foo : 32;" for gcc3 vs. gcc4 compatibility
    
    gcc3 thinks that a 32-bit field of a u64 type is itself a u64, so
    should be printed with "%ld".  gcc4 thinks it needs just "%d".
    Make both versions happy by avoiding this construct.
    
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index ac167436e936..49958904045b 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -188,7 +188,7 @@ ia64_init_itm (void)
 	itc_freq = (platform_base_freq*itc_ratio.num)/itc_ratio.den;
 
 	local_cpu_data->itm_delta = (itc_freq + HZ/2) / HZ;
-	printk(KERN_DEBUG "CPU %d: base freq=%lu.%03luMHz, ITC ratio=%lu/%lu, "
+	printk(KERN_DEBUG "CPU %d: base freq=%lu.%03luMHz, ITC ratio=%u/%u, "
 	       "ITC freq=%lu.%03luMHz", smp_processor_id(),
 	       platform_base_freq / 1000000, (platform_base_freq / 1000) % 1000,
 	       itc_ratio.num, itc_ratio.den, itc_freq / 1000000, (itc_freq / 1000) % 1000);

commit 536ea4e4198eeaa5a73fb734ea675e621609bb7e
Merge: 7705a8792b0f b88e926584bf
Author: Tony Luck <tony.luck@intel.com>
Date:   Tue Mar 21 08:16:21 2006 -0800

    Pull bsp-removal into release branch

commit defbb2c929cbe89dc92239b303cd33d3c85e9a83
Author: hawkes@sgi.com <hawkes@sgi.com>
Date:   Tue Feb 14 10:40:17 2006 -0800

    [IA64] ia64: simplify and fix udelay()
    
    The original ia64 udelay() was simple, but flawed for platforms without
    synchronized ITCs:  a preemption and migration to another CPU during the
    while-loop likely resulted in too-early termination or very, very
    lengthy looping.
    
    The first fix (now in 2.6.15) broke the delay loop into smaller,
    non-preemptible chunks, reenabling preemption between the chunks.  This
    fix is flawed in that the total udelay is computed to be the sum of just
    the non-premptible while-loop pieces, i.e., not counting the time spent
    in the interim preemptible periods.  If an interrupt or a migration
    occurs during one of these interim periods, then that time is invisible
    and only serves to lengthen the effective udelay().
    
    This new fix backs out the current flawed fix and returns to a simple
    udelay(), fully preemptible and interruptible.  It implements two simple
    alternative udelay() routines:  one a default generic version that uses
    ia64_get_itc(), and the other an sn-specific version that uses that
    platform's RTC.
    
    Signed-off-by: John Hawkes <hawkes@sgi.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index a094ec49ccfa..307d01e15b2e 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -250,32 +250,27 @@ time_init (void)
 	set_normalized_timespec(&wall_to_monotonic, -xtime.tv_sec, -xtime.tv_nsec);
 }
 
-#define SMALLUSECS 100
-
-void
-udelay (unsigned long usecs)
+/*
+ * Generic udelay assumes that if preemption is allowed and the thread
+ * migrates to another CPU, that the ITC values are synchronized across
+ * all CPUs.
+ */
+static void
+ia64_itc_udelay (unsigned long usecs)
 {
-	unsigned long start;
-	unsigned long cycles;
-	unsigned long smallusecs;
+	unsigned long start = ia64_get_itc();
+	unsigned long end = start + usecs*local_cpu_data->cyc_per_usec;
 
-	/*
-	 * Execute the non-preemptible delay loop (because the ITC might
-	 * not be synchronized between CPUS) in relatively short time
-	 * chunks, allowing preemption between the chunks.
-	 */
-	while (usecs > 0) {
-		smallusecs = (usecs > SMALLUSECS) ? SMALLUSECS : usecs;
-		preempt_disable();
-		cycles = smallusecs*local_cpu_data->cyc_per_usec;
-		start = ia64_get_itc();
+	while (time_before(ia64_get_itc(), end))
+		cpu_relax();
+}
 
-		while (ia64_get_itc() - start < cycles)
-			cpu_relax();
+void (*ia64_udelay)(unsigned long usecs) = &ia64_itc_udelay;
 
-		preempt_enable();
-		usecs -= smallusecs;
-	}
+void
+udelay (unsigned long usecs)
+{
+	(*ia64_udelay)(usecs);
 }
 EXPORT_SYMBOL(udelay);
 

commit d6e56a2a088935f3c1feee5ff5a06c67f2ec6002
Author: Tony Luck <tony.luck@intel.com>
Date:   Tue Feb 7 15:25:57 2006 -0800

    [IA64] Fix CONFIG_PRINTK_TIME
    
    There were two problems with enabling the PRINTK_TIME config
    option:
    1) The first calls to printk() occur before per-cpu data virtual
    address is pinned into the TLB, so sched_clock() can fault.
    2) sched_clock() is based on ar.itc, which may not be synchronized
    across cpus.
    
    Ken Chen started this patch, Tony Luck tinkered with it, and Jes
    Sorensen perfected it.
    
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 028a2b95936c..a094ec49ccfa 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -278,3 +278,30 @@ udelay (unsigned long usecs)
 	}
 }
 EXPORT_SYMBOL(udelay);
+
+static unsigned long long ia64_itc_printk_clock(void)
+{
+	if (ia64_get_kr(IA64_KR_PER_CPU_DATA))
+		return sched_clock();
+	return 0;
+}
+
+static unsigned long long ia64_default_printk_clock(void)
+{
+	return (unsigned long long)(jiffies_64 - INITIAL_JIFFIES) *
+		(1000000000/HZ);
+}
+
+unsigned long long (*ia64_printk_clock)(void) = &ia64_default_printk_clock;
+
+unsigned long long printk_clock(void)
+{
+	return ia64_printk_clock();
+}
+
+void __init
+ia64_setup_printk_clock(void)
+{
+	if (!(sal_platform_features & IA64_SAL_PLATFORM_FEATURE_ITC_DRIFT))
+		ia64_printk_clock = ia64_itc_printk_clock;
+}

commit ff741906ad3cf4b8ca1a958acb013a97a6381ca2
Author: Ashok Raj <ashok.raj@intel.com>
Date:   Fri Nov 11 14:32:40 2005 -0800

    [IA64] support for cpu0 removal
    
    here is the BSP removal support for IA64. Its pretty much the same thing that
    was released a while back, but has your feedback incorporated.
    
    - Removed CONFIG_BSP_REMOVE_WORKAROUND and associated cmdline param
    - Fixed compile issue with sn2/zx1 due to a undefined fix_b0_for_bsp
    - some formatting nits (whitespace etc)
    
    This has been tested on tiger and long back by alex on hp systems as well.
    
    Signed-off-by: Ashok Raj <ashok.raj@intel.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 028a2b95936c..1ca130a83856 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -32,7 +32,7 @@
 
 extern unsigned long wall_jiffies;
 
-#define TIME_KEEPER_ID	0	/* smp_processor_id() of time-keeper */
+volatile int time_keeper_id = 0; /* smp_processor_id() of time-keeper */
 
 #ifdef CONFIG_IA64_DEBUG_IRQ
 
@@ -71,7 +71,7 @@ timer_interrupt (int irq, void *dev_id, struct pt_regs *regs)
 
 		new_itm += local_cpu_data->itm_delta;
 
-		if (smp_processor_id() == TIME_KEEPER_ID) {
+		if (smp_processor_id() == time_keeper_id) {
 			/*
 			 * Here we are in the timer irq handler. We have irqs locally
 			 * disabled, but we don't know if the timer_bh is running on
@@ -236,6 +236,11 @@ static struct irqaction timer_irqaction = {
 	.name =		"timer"
 };
 
+void __devinit ia64_disable_timer(void)
+{
+	ia64_set_itv(1 << 16);
+}
+
 void __init
 time_init (void)
 {

commit f5899b5d4fa806403f547dc41312d017d94ec273
Author: John Hawkes <hawkes@sgi.com>
Date:   Fri Dec 16 10:00:24 2005 -0800

    [IA64] disable preemption in udelay()
    
    The udelay() inline for ia64 uses the ITC.  If CONFIG_PREEMPT is enabled
    and the platform has unsynchronized ITCs and the calling task migrates
    to another CPU while doing the udelay loop, then the effective delay may
    be too short or very, very long.
    
    This patch disables preemption around 100 usec chunks of the overall
    desired udelay time.  This minimizes preemption-holdoffs.
    
    udelay() is now too big to be inline, move it out of line and export it.
    
    Signed-off-by: John Hawkes <hawkes@sgi.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 5b7e736f3b49..028a2b95936c 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -249,3 +249,32 @@ time_init (void)
 	 */
 	set_normalized_timespec(&wall_to_monotonic, -xtime.tv_sec, -xtime.tv_nsec);
 }
+
+#define SMALLUSECS 100
+
+void
+udelay (unsigned long usecs)
+{
+	unsigned long start;
+	unsigned long cycles;
+	unsigned long smallusecs;
+
+	/*
+	 * Execute the non-preemptible delay loop (because the ITC might
+	 * not be synchronized between CPUS) in relatively short time
+	 * chunks, allowing preemption between the chunks.
+	 */
+	while (usecs > 0) {
+		smallusecs = (usecs > SMALLUSECS) ? SMALLUSECS : usecs;
+		preempt_disable();
+		cycles = smallusecs*local_cpu_data->cyc_per_usec;
+		start = ia64_get_itc();
+
+		while (ia64_get_itc() - start < cycles)
+			cpu_relax();
+
+		preempt_enable();
+		usecs -= smallusecs;
+	}
+}
+EXPORT_SYMBOL(udelay);

commit ecea8d19c9f0ebd62ddaa07fc919ff4e4b820d99
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Oct 30 15:03:00 2005 -0800

    [PATCH] jiffies_64 cleanup
    
    Define jiffies_64 in kernel/timer.c rather than having 24 duplicated
    defines in each architecture.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
index 8b8a5a45b621..5b7e736f3b49 100644
--- a/arch/ia64/kernel/time.c
+++ b/arch/ia64/kernel/time.c
@@ -32,10 +32,6 @@
 
 extern unsigned long wall_jiffies;
 
-u64 jiffies_64 __cacheline_aligned_in_smp = INITIAL_JIFFIES;
-
-EXPORT_SYMBOL(jiffies_64);
-
 #define TIME_KEEPER_ID	0	/* smp_processor_id() of time-keeper */
 
 #ifdef CONFIG_IA64_DEBUG_IRQ

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/arch/ia64/kernel/time.c b/arch/ia64/kernel/time.c
new file mode 100644
index 000000000000..8b8a5a45b621
--- /dev/null
+++ b/arch/ia64/kernel/time.c
@@ -0,0 +1,255 @@
+/*
+ * linux/arch/ia64/kernel/time.c
+ *
+ * Copyright (C) 1998-2003 Hewlett-Packard Co
+ *	Stephane Eranian <eranian@hpl.hp.com>
+ *	David Mosberger <davidm@hpl.hp.com>
+ * Copyright (C) 1999 Don Dugger <don.dugger@intel.com>
+ * Copyright (C) 1999-2000 VA Linux Systems
+ * Copyright (C) 1999-2000 Walt Drummond <drummond@valinux.com>
+ */
+#include <linux/config.h>
+
+#include <linux/cpu.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/profile.h>
+#include <linux/sched.h>
+#include <linux/time.h>
+#include <linux/interrupt.h>
+#include <linux/efi.h>
+#include <linux/profile.h>
+#include <linux/timex.h>
+
+#include <asm/machvec.h>
+#include <asm/delay.h>
+#include <asm/hw_irq.h>
+#include <asm/ptrace.h>
+#include <asm/sal.h>
+#include <asm/sections.h>
+#include <asm/system.h>
+
+extern unsigned long wall_jiffies;
+
+u64 jiffies_64 __cacheline_aligned_in_smp = INITIAL_JIFFIES;
+
+EXPORT_SYMBOL(jiffies_64);
+
+#define TIME_KEEPER_ID	0	/* smp_processor_id() of time-keeper */
+
+#ifdef CONFIG_IA64_DEBUG_IRQ
+
+unsigned long last_cli_ip;
+EXPORT_SYMBOL(last_cli_ip);
+
+#endif
+
+static struct time_interpolator itc_interpolator = {
+	.shift = 16,
+	.mask = 0xffffffffffffffffLL,
+	.source = TIME_SOURCE_CPU
+};
+
+static irqreturn_t
+timer_interrupt (int irq, void *dev_id, struct pt_regs *regs)
+{
+	unsigned long new_itm;
+
+	if (unlikely(cpu_is_offline(smp_processor_id()))) {
+		return IRQ_HANDLED;
+	}
+
+	platform_timer_interrupt(irq, dev_id, regs);
+
+	new_itm = local_cpu_data->itm_next;
+
+	if (!time_after(ia64_get_itc(), new_itm))
+		printk(KERN_ERR "Oops: timer tick before it's due (itc=%lx,itm=%lx)\n",
+		       ia64_get_itc(), new_itm);
+
+	profile_tick(CPU_PROFILING, regs);
+
+	while (1) {
+		update_process_times(user_mode(regs));
+
+		new_itm += local_cpu_data->itm_delta;
+
+		if (smp_processor_id() == TIME_KEEPER_ID) {
+			/*
+			 * Here we are in the timer irq handler. We have irqs locally
+			 * disabled, but we don't know if the timer_bh is running on
+			 * another CPU. We need to avoid to SMP race by acquiring the
+			 * xtime_lock.
+			 */
+			write_seqlock(&xtime_lock);
+			do_timer(regs);
+			local_cpu_data->itm_next = new_itm;
+			write_sequnlock(&xtime_lock);
+		} else
+			local_cpu_data->itm_next = new_itm;
+
+		if (time_after(new_itm, ia64_get_itc()))
+			break;
+	}
+
+	do {
+		/*
+		 * If we're too close to the next clock tick for
+		 * comfort, we increase the safety margin by
+		 * intentionally dropping the next tick(s).  We do NOT
+		 * update itm.next because that would force us to call
+		 * do_timer() which in turn would let our clock run
+		 * too fast (with the potentially devastating effect
+		 * of losing monotony of time).
+		 */
+		while (!time_after(new_itm, ia64_get_itc() + local_cpu_data->itm_delta/2))
+			new_itm += local_cpu_data->itm_delta;
+		ia64_set_itm(new_itm);
+		/* double check, in case we got hit by a (slow) PMI: */
+	} while (time_after_eq(ia64_get_itc(), new_itm));
+	return IRQ_HANDLED;
+}
+
+/*
+ * Encapsulate access to the itm structure for SMP.
+ */
+void
+ia64_cpu_local_tick (void)
+{
+	int cpu = smp_processor_id();
+	unsigned long shift = 0, delta;
+
+	/* arrange for the cycle counter to generate a timer interrupt: */
+	ia64_set_itv(IA64_TIMER_VECTOR);
+
+	delta = local_cpu_data->itm_delta;
+	/*
+	 * Stagger the timer tick for each CPU so they don't occur all at (almost) the
+	 * same time:
+	 */
+	if (cpu) {
+		unsigned long hi = 1UL << ia64_fls(cpu);
+		shift = (2*(cpu - hi) + 1) * delta/hi/2;
+	}
+	local_cpu_data->itm_next = ia64_get_itc() + delta + shift;
+	ia64_set_itm(local_cpu_data->itm_next);
+}
+
+static int nojitter;
+
+static int __init nojitter_setup(char *str)
+{
+	nojitter = 1;
+	printk("Jitter checking for ITC timers disabled\n");
+	return 1;
+}
+
+__setup("nojitter", nojitter_setup);
+
+
+void __devinit
+ia64_init_itm (void)
+{
+	unsigned long platform_base_freq, itc_freq;
+	struct pal_freq_ratio itc_ratio, proc_ratio;
+	long status, platform_base_drift, itc_drift;
+
+	/*
+	 * According to SAL v2.6, we need to use a SAL call to determine the platform base
+	 * frequency and then a PAL call to determine the frequency ratio between the ITC
+	 * and the base frequency.
+	 */
+	status = ia64_sal_freq_base(SAL_FREQ_BASE_PLATFORM,
+				    &platform_base_freq, &platform_base_drift);
+	if (status != 0) {
+		printk(KERN_ERR "SAL_FREQ_BASE_PLATFORM failed: %s\n", ia64_sal_strerror(status));
+	} else {
+		status = ia64_pal_freq_ratios(&proc_ratio, NULL, &itc_ratio);
+		if (status != 0)
+			printk(KERN_ERR "PAL_FREQ_RATIOS failed with status=%ld\n", status);
+	}
+	if (status != 0) {
+		/* invent "random" values */
+		printk(KERN_ERR
+		       "SAL/PAL failed to obtain frequency info---inventing reasonable values\n");
+		platform_base_freq = 100000000;
+		platform_base_drift = -1;	/* no drift info */
+		itc_ratio.num = 3;
+		itc_ratio.den = 1;
+	}
+	if (platform_base_freq < 40000000) {
+		printk(KERN_ERR "Platform base frequency %lu bogus---resetting to 75MHz!\n",
+		       platform_base_freq);
+		platform_base_freq = 75000000;
+		platform_base_drift = -1;
+	}
+	if (!proc_ratio.den)
+		proc_ratio.den = 1;	/* avoid division by zero */
+	if (!itc_ratio.den)
+		itc_ratio.den = 1;	/* avoid division by zero */
+
+	itc_freq = (platform_base_freq*itc_ratio.num)/itc_ratio.den;
+
+	local_cpu_data->itm_delta = (itc_freq + HZ/2) / HZ;
+	printk(KERN_DEBUG "CPU %d: base freq=%lu.%03luMHz, ITC ratio=%lu/%lu, "
+	       "ITC freq=%lu.%03luMHz", smp_processor_id(),
+	       platform_base_freq / 1000000, (platform_base_freq / 1000) % 1000,
+	       itc_ratio.num, itc_ratio.den, itc_freq / 1000000, (itc_freq / 1000) % 1000);
+
+	if (platform_base_drift != -1) {
+		itc_drift = platform_base_drift*itc_ratio.num/itc_ratio.den;
+		printk("+/-%ldppm\n", itc_drift);
+	} else {
+		itc_drift = -1;
+		printk("\n");
+	}
+
+	local_cpu_data->proc_freq = (platform_base_freq*proc_ratio.num)/proc_ratio.den;
+	local_cpu_data->itc_freq = itc_freq;
+	local_cpu_data->cyc_per_usec = (itc_freq + USEC_PER_SEC/2) / USEC_PER_SEC;
+	local_cpu_data->nsec_per_cyc = ((NSEC_PER_SEC<<IA64_NSEC_PER_CYC_SHIFT)
+					+ itc_freq/2)/itc_freq;
+
+	if (!(sal_platform_features & IA64_SAL_PLATFORM_FEATURE_ITC_DRIFT)) {
+		itc_interpolator.frequency = local_cpu_data->itc_freq;
+		itc_interpolator.drift = itc_drift;
+#ifdef CONFIG_SMP
+		/* On IA64 in an SMP configuration ITCs are never accurately synchronized.
+		 * Jitter compensation requires a cmpxchg which may limit
+		 * the scalability of the syscalls for retrieving time.
+		 * The ITC synchronization is usually successful to within a few
+		 * ITC ticks but this is not a sure thing. If you need to improve
+		 * timer performance in SMP situations then boot the kernel with the
+		 * "nojitter" option. However, doing so may result in time fluctuating (maybe
+		 * even going backward) if the ITC offsets between the individual CPUs
+		 * are too large.
+		 */
+		if (!nojitter) itc_interpolator.jitter = 1;
+#endif
+		register_time_interpolator(&itc_interpolator);
+	}
+
+	/* Setup the CPU local timer tick */
+	ia64_cpu_local_tick();
+}
+
+static struct irqaction timer_irqaction = {
+	.handler =	timer_interrupt,
+	.flags =	SA_INTERRUPT,
+	.name =		"timer"
+};
+
+void __init
+time_init (void)
+{
+	register_percpu_irq(IA64_TIMER_VECTOR, &timer_irqaction);
+	efi_gettimeofday(&xtime);
+	ia64_init_itm();
+
+	/*
+	 * Initialize wall_to_monotonic such that adding it to xtime will yield zero, the
+	 * tv_nsec field must be normalized (i.e., 0 <= nsec < NSEC_PER_SEC).
+	 */
+	set_normalized_timespec(&wall_to_monotonic, -xtime.tv_sec, -xtime.tv_nsec);
+}
