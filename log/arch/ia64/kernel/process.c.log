commit 9cb8f069deeed708bf19486d5893e297dc467ae0
Author: Dmitry Safonov <dima@arista.com>
Date:   Mon Jun 8 21:32:29 2020 -0700

    kernel: rename show_stack_loglvl() => show_stack()
    
    Now the last users of show_stack() got converted to use an explicit log
    level, show_stack_loglvl() can drop it's redundant suffix and become once
    again well known show_stack().
    
    Signed-off-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Link: http://lkml.kernel.org/r/20200418201944.482088-51-dima@arista.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 913d9a01cbf9..96dfb9e4b16f 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -85,8 +85,7 @@ ia64_do_show_stack (struct unw_frame_info *info, void *arg)
 }
 
 void
-show_stack_loglvl (struct task_struct *task, unsigned long *sp,
-		   const char *loglvl)
+show_stack (struct task_struct *task, unsigned long *sp, const char *loglvl)
 {
 	if (!task)
 		unw_init_running(ia64_do_show_stack, (void *)loglvl);
@@ -98,12 +97,6 @@ show_stack_loglvl (struct task_struct *task, unsigned long *sp,
 	}
 }
 
-void
-show_stack (struct task_struct *task, unsigned long *sp)
-{
-	show_stack_loglvl(task, sp, KERN_DEFAULT);
-}
-
 void
 show_regs (struct pt_regs *regs)
 {
@@ -158,7 +151,7 @@ show_regs (struct pt_regs *regs)
 			       ((i == sof - 1) || (i % 3) == 2) ? "\n" : " ");
 		}
 	} else
-		show_stack(NULL, NULL);
+		show_stack(NULL, NULL, KERN_DEFAULT);
 }
 
 /* local support for deprecated console_print */

commit ffdac29e40545cfb21d347c67daeb72541792ec8
Author: Dmitry Safonov <dima@arista.com>
Date:   Mon Jun 8 21:30:44 2020 -0700

    ia64: add show_stack_loglvl()
    
    Currently, the log-level of show_stack() depends on a platform
    realization.  It creates situations where the headers are printed with
    lower log level or higher than the stacktrace (depending on a platform or
    user).
    
    Furthermore, it forces the logic decision from user to an architecture
    side.  In result, some users as sysrq/kdb/etc are doing tricks with
    temporary rising console_loglevel while printing their messages.  And in
    result it not only may print unwanted messages from other CPUs, but also
    omit printing at all in the unlucky case where the printk() was deferred.
    
    Introducing log-level parameter and KERN_UNSUPPRESSED [1] seems an easier
    approach than introducing more printk buffers.  Also, it will consolidate
    printings with headers.
    
    Introduce show_stack_loglvl(), that eventually will substitute
    show_stack().
    
    [1]: https://lore.kernel.org/lkml/20190528002412.1625-1-dima@arista.com/T/#u
    
    Signed-off-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Link: http://lkml.kernel.org/r/20200418201944.482088-17-dima@arista.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 332c6dfe7333..913d9a01cbf9 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -85,18 +85,25 @@ ia64_do_show_stack (struct unw_frame_info *info, void *arg)
 }
 
 void
-show_stack (struct task_struct *task, unsigned long *sp)
+show_stack_loglvl (struct task_struct *task, unsigned long *sp,
+		   const char *loglvl)
 {
 	if (!task)
-		unw_init_running(ia64_do_show_stack, (void *)KERN_DEFAULT);
+		unw_init_running(ia64_do_show_stack, (void *)loglvl);
 	else {
 		struct unw_frame_info info;
 
 		unw_init_from_blocked_task(&info, task);
-		ia64_do_show_stack(&info, (void *)KERN_DEFAULT);
+		ia64_do_show_stack(&info, (void *)loglvl);
 	}
 }
 
+void
+show_stack (struct task_struct *task, unsigned long *sp)
+{
+	show_stack_loglvl(task, sp, KERN_DEFAULT);
+}
+
 void
 show_regs (struct pt_regs *regs)
 {

commit c261ad6ee80e337fb01a9cee91241f195c80f3d1
Author: Dmitry Safonov <dima@arista.com>
Date:   Mon Jun 8 21:30:41 2020 -0700

    ia64: pass log level as arg into ia64_do_show_stack()
    
    Currently, the log-level of show_stack() depends on a platform
    realization.  It creates situations where the headers are printed with
    lower log level or higher than the stacktrace (depending on a platform or
    user).
    
    Furthermore, it forces the logic decision from user to an architecture
    side.  In result, some users as sysrq/kdb/etc are doing tricks with
    temporary rising console_loglevel while printing their messages.  And in
    result it not only may print unwanted messages from other CPUs, but also
    omit printing at all in the unlucky case where the printk() was deferred.
    
    Introducing log-level parameter and KERN_UNSUPPRESSED [1] seems an easier
    approach than introducing more printk buffers.  Also, it will consolidate
    printings with headers.
    
    Add log level argument to ia64_do_show_stack() as a preparation to
    introduce show_stack_loglvl().  Also, make ia64_do_show_stack() static as
    it's not used outside.
    
    [1]: https://lore.kernel.org/lkml/20190528002412.1625-1-dima@arista.com/T/#u
    
    Signed-off-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Link: http://lkml.kernel.org/r/20200418201944.482088-16-dima@arista.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 10cb9382ab76..332c6dfe7333 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -64,12 +64,13 @@ EXPORT_SYMBOL(boot_option_idle_override);
 void (*pm_power_off) (void);
 EXPORT_SYMBOL(pm_power_off);
 
-void
+static void
 ia64_do_show_stack (struct unw_frame_info *info, void *arg)
 {
 	unsigned long ip, sp, bsp;
+	const char *loglvl = arg;
 
-	printk("\nCall Trace:\n");
+	printk("%s\nCall Trace:\n", loglvl);
 	do {
 		unw_get_ip(info, &ip);
 		if (ip == 0)
@@ -77,9 +78,9 @@ ia64_do_show_stack (struct unw_frame_info *info, void *arg)
 
 		unw_get_sp(info, &sp);
 		unw_get_bsp(info, &bsp);
-		printk(" [<%016lx>] %pS\n"
+		printk("%s [<%016lx>] %pS\n"
 			 "                                sp=%016lx bsp=%016lx\n",
-			 ip, (void *)ip, sp, bsp);
+			 loglvl, ip, (void *)ip, sp, bsp);
 	} while (unw_unwind(info) >= 0);
 }
 
@@ -87,12 +88,12 @@ void
 show_stack (struct task_struct *task, unsigned long *sp)
 {
 	if (!task)
-		unw_init_running(ia64_do_show_stack, NULL);
+		unw_init_running(ia64_do_show_stack, (void *)KERN_DEFAULT);
 	else {
 		struct unw_frame_info info;
 
 		unw_init_from_blocked_task(&info, task);
-		ia64_do_show_stack(&info, NULL);
+		ia64_do_show_stack(&info, (void *)KERN_DEFAULT);
 	}
 }
 

commit 992a1a3b45b5c0b6e69ecc2a3f32b0d02da28d58
Merge: 2d385336afcc e98eac6ff1b4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Mar 30 18:06:39 2020 -0700

    Merge tag 'smp-core-2020-03-30' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull core SMP updates from Thomas Gleixner:
     "CPU (hotplug) updates:
    
       - Support for locked CSD objects in smp_call_function_single_async()
         which allows to simplify callsites in the scheduler core and MIPS
    
       - Treewide consolidation of CPU hotplug functions which ensures the
         consistency between the sysfs interface and kernel state. The low
         level functions cpu_up/down() are now confined to the core code and
         not longer accessible from random code"
    
    * tag 'smp-core-2020-03-30' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (22 commits)
      cpu/hotplug: Ignore pm_wakeup_pending() for disable_nonboot_cpus()
      cpu/hotplug: Hide cpu_up/down()
      cpu/hotplug: Move bringup of secondary CPUs out of smp_init()
      torture: Replace cpu_up/down() with add/remove_cpu()
      firmware: psci: Replace cpu_up/down() with add/remove_cpu()
      xen/cpuhotplug: Replace cpu_up/down() with device_online/offline()
      parisc: Replace cpu_up/down() with add/remove_cpu()
      sparc: Replace cpu_up/down() with add/remove_cpu()
      powerpc: Replace cpu_up/down() with add/remove_cpu()
      x86/smp: Replace cpu_up/down() with add/remove_cpu()
      arm64: hibernate: Use bringup_hibernate_cpu()
      cpu/hotplug: Provide bringup_hibernate_cpu()
      arm64: Use reboot_cpu instead of hardconding it to 0
      arm64: Don't use disable_nonboot_cpus()
      ARM: Use reboot_cpu instead of hardcoding it to 0
      ARM: Don't use disable_nonboot_cpus()
      ia64: Replace cpu_down() with smp_shutdown_nonboot_cpus()
      cpu/hotplug: Create a new function to shutdown nonboot cpus
      cpu/hotplug: Add new {add,remove}_cpu() functions
      sched/core: Remove rq.hrtick_csd_pending
      ...

commit 1e42176b4dac328b0be7075c2cebdf2006d31eb3
Author: Qais Yousef <qais.yousef@arm.com>
Date:   Mon Mar 23 13:50:56 2020 +0000

    ia64: Replace cpu_down() with smp_shutdown_nonboot_cpus()
    
    Use the new smp_shutdown_nonboot_cpus() instead of using cpu_down()
    directly.
    
    Use reboot_cpu instead of hardcoding the boot CPU to 0.
    
    This also prepares to make cpu_up/down() a private interface of the CPU
    subsystem.
    
    Signed-off-by: Qais Yousef <qais.yousef@arm.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Link: https://lkml.kernel.org/r/20200323135110.30522-4-qais.yousef@arm.com

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 968b5f33e725..bf4c0cdb7a25 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -646,14 +646,8 @@ cpu_halt (void)
 
 void machine_shutdown(void)
 {
-#ifdef CONFIG_HOTPLUG_CPU
-	int cpu;
+	smp_shutdown_nonboot_cpus(reboot_cpu);
 
-	for_each_online_cpu(cpu) {
-		if (cpu != smp_processor_id())
-			cpu_down(cpu);
-	}
-#endif
 #ifdef CONFIG_KEXEC
 	kexec_disable_iosapic();
 #endif

commit 6f28b46c4f93b4b4632e8f598c4f796244851a58
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Sat Mar 21 12:25:53 2020 +0100

    ia64: Remove mm.h from asm/uaccess.h
    
    The defconfig compiles without linux/mm.h. With mm.h included the
    include chain leands to:
    |   CC      kernel/locking/percpu-rwsem.o
    | In file included from include/linux/huge_mm.h:8,
    |                  from include/linux/mm.h:567,
    |                  from arch/ia64/include/asm/uaccess.h:,
    |                  from include/linux/uaccess.h:11,
    |                  from include/linux/sched/task.h:11,
    |                  from include/linux/sched/signal.h:9,
    |                  from include/linux/rcuwait.h:6,
    |                  from include/linux/percpu-rwsem.h:8,
    |                  from kernel/locking/percpu-rwsem.c:6:
    | include/linux/fs.h:1422:29: error: array type has incomplete element type 'struct percpu_rw_semaphore'
    |  1422 |  struct percpu_rw_semaphore rw_sem[SB_FREEZE_LEVELS];
    
    once rcuwait.h includes linux/sched/signal.h.
    
    Remove the linux/mm.h include.
    
    Reported-by: kbuild test robot <lkp@intel.com>
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20200321113241.624070289@linutronix.de

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 968b5f33e725..743aaf528327 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -681,3 +681,4 @@ machine_power_off (void)
 	machine_halt();
 }
 
+EXPORT_SYMBOL(ia64_delay_loop);

commit 253c962020636252bdc4b9b682035ffe4a7eaa2e
Author: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
Date:   Mon Dec 11 21:50:16 2017 +0900

    ia64: do not use print_symbol()
    
    print_symbol() is a very old API that has been obsoleted by %pS format
    specifier in a normal printk() call.
    
    Replace print_symbol() with a direct printk("%pS") call and avoid
    using continuous lines.
    
    Link: http://lkml.kernel.org/r/20171211125025.2270-5-sergey.senozhatsky@gmail.com
    To: Andrew Morton <akpm@linux-foundation.org>
    To: Russell King <linux@armlinux.org.uk>
    To: Catalin Marinas <catalin.marinas@arm.com>
    To: Mark Salter <msalter@redhat.com>
    To: Tony Luck <tony.luck@intel.com>
    To: David Howells <dhowells@redhat.com>
    To: Yoshinori Sato <ysato@users.sourceforge.jp>
    To: Guan Xuetao <gxt@mprc.pku.edu.cn>
    To: Borislav Petkov <bp@alien8.de>
    To: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    To: Thomas Gleixner <tglx@linutronix.de>
    To: Peter Zijlstra <peterz@infradead.org>
    To: Vineet Gupta <vgupta@synopsys.com>
    To: Fengguang Wu <fengguang.wu@intel.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Petr Mladek <pmladek@suse.com>
    Cc: LKML <linux-kernel@vger.kernel.org>
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-c6x-dev@linux-c6x.org
    Cc: linux-ia64@vger.kernel.org
    Cc: linux-am33-list@redhat.com
    Cc: linux-sh@vger.kernel.org
    Cc: linux-edac@vger.kernel.org
    Cc: x86@kernel.org
    Cc: linux-snps-arc@lists.infradead.org
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    [pmladek@suse.com: updated commit message]
    Signed-off-by: Petr Mladek <pmladek@suse.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index dda0082056b3..968b5f33e725 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -13,7 +13,6 @@
 #include <linux/pm.h>
 #include <linux/elf.h>
 #include <linux/errno.h>
-#include <linux/kallsyms.h>
 #include <linux/kernel.h>
 #include <linux/mm.h>
 #include <linux/slab.h>
@@ -69,7 +68,6 @@ void
 ia64_do_show_stack (struct unw_frame_info *info, void *arg)
 {
 	unsigned long ip, sp, bsp;
-	char buf[128];			/* don't make it so big that it overflows the stack! */
 
 	printk("\nCall Trace:\n");
 	do {
@@ -79,11 +77,9 @@ ia64_do_show_stack (struct unw_frame_info *info, void *arg)
 
 		unw_get_sp(info, &sp);
 		unw_get_bsp(info, &bsp);
-		snprintf(buf, sizeof(buf),
-			 " [<%016lx>] %%s\n"
+		printk(" [<%016lx>] %pS\n"
 			 "                                sp=%016lx bsp=%016lx\n",
-			 ip, sp, bsp);
-		print_symbol(buf, ip);
+			 ip, (void *)ip, sp, bsp);
 	} while (unw_unwind(info) >= 0);
 }
 
@@ -111,7 +107,7 @@ show_regs (struct pt_regs *regs)
 	printk("psr : %016lx ifs : %016lx ip  : [<%016lx>]    %s (%s)\n",
 	       regs->cr_ipsr, regs->cr_ifs, ip, print_tainted(),
 	       init_utsname()->release);
-	print_symbol("ip is at %s\n", ip);
+	printk("ip is at %pS\n", (void *)ip);
 	printk("unat: %016lx pfs : %016lx rsc : %016lx\n",
 	       regs->ar_unat, regs->ar_pfs, regs->ar_rsc);
 	printk("rnat: %016lx bsps: %016lx pr  : %016lx\n",

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index d344d0d691aa..dda0082056b3 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * Architecture-specific setup.
  *

commit 68db0cf10678630d286f4bbbbdfa102951a35faa
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:37 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/task_stack.h>
    
    We are going to split <linux/sched/task_stack.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/task_stack.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 054facf22156..d344d0d691aa 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -23,6 +23,7 @@
 #include <linux/sched/debug.h>
 #include <linux/sched/hotplug.h>
 #include <linux/sched/task.h>
+#include <linux/sched/task_stack.h>
 #include <linux/stddef.h>
 #include <linux/thread_info.h>
 #include <linux/unistd.h>

commit 299300258d1bc4e997b7db340a2e06636757fe2e
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:36 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/task.h>
    
    We are going to split <linux/sched/task.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/task.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 2204ae450d65..054facf22156 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -22,6 +22,7 @@
 #include <linux/sched.h>
 #include <linux/sched/debug.h>
 #include <linux/sched/hotplug.h>
+#include <linux/sched/task.h>
 #include <linux/stddef.h>
 #include <linux/thread_info.h>
 #include <linux/unistd.h>

commit ef8bd77f332bb0a4e467d7171bbfc6c57aa08a88
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:36 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/hotplug.h>
    
    We are going to split <linux/sched/hotplug.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/hotplug.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 804b251ee5d1..2204ae450d65 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -21,6 +21,7 @@
 #include <linux/personality.h>
 #include <linux/sched.h>
 #include <linux/sched/debug.h>
+#include <linux/sched/hotplug.h>
 #include <linux/stddef.h>
 #include <linux/thread_info.h>
 #include <linux/unistd.h>

commit b17b01533b719e9949e437abf66436a875739b40
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:35 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/debug.h>
    
    We are going to split <linux/sched/debug.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/debug.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 52deab683ba1..804b251ee5d1 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -20,6 +20,7 @@
 #include <linux/notifier.h>
 #include <linux/personality.h>
 #include <linux/sched.h>
+#include <linux/sched/debug.h>
 #include <linux/stddef.h>
 #include <linux/thread_info.h>
 #include <linux/unistd.h>

commit 7c0f6ba682b9c7632072ffbedf8d328c8f3c42ba
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Dec 24 11:46:01 2016 -0800

    Replace <asm/uaccess.h> with <linux/uaccess.h> globally
    
    This was entirely automated, using the script by Al:
    
      PATT='^[[:blank:]]*#[[:blank:]]*include[[:blank:]]*<asm/uaccess.h>'
      sed -i -e "s!$PATT!#include <linux/uaccess.h>!" \
            $(git grep -l "$PATT"|grep -v ^include/linux/uaccess.h)
    
    to do the replacement at the end of the merge window.
    
    Requested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index aae6c4dc7ae7..52deab683ba1 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -41,7 +41,7 @@
 #include <asm/sal.h>
 #include <asm/switch_to.h>
 #include <asm/tlbflush.h>
-#include <asm/uaccess.h>
+#include <linux/uaccess.h>
 #include <asm/unwind.h>
 #include <asm/user.h>
 

commit e64646946ed32902fd597fa6e514b1da84642de3
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Fri May 20 17:00:20 2016 -0700

    exit_thread: accept a task parameter to be exited
    
    We need to call exit_thread from copy_process in a fail path.  So make it
    accept task_struct as a parameter.
    
    [v2]
    * s390: exit_thread_runtime_instr doesn't make sense to be called for
      non-current tasks.
    * arm: fix the comment in vfp_thread_copy
    * change 'me' to 'tsk' for task_struct
    * now we can change only archs that actually have exit_thread
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
    Cc: Aurelien Jacquiot <a-jacquiot@ti.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chen Liqin <liqin.linux@gmail.com>
    Cc: Chris Metcalf <cmetcalf@mellanox.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
    Cc: Haavard Skinnemoen <hskinnemoen@gmail.com>
    Cc: Hans-Christian Egtvedt <egtvedt@samfundet.no>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: James Hogan <james.hogan@imgtec.com>
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Jesper Nilsson <jesper.nilsson@axis.com>
    Cc: Jiri Slaby <jslaby@suse.cz>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Koichi Yasutake <yasutake.koichi@jp.panasonic.com>
    Cc: Lennox Wu <lennox.wu@gmail.com>
    Cc: Ley Foon Tan <lftan@altera.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Steven Miao <realmz6@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index b51514957620..aae6c4dc7ae7 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -570,22 +570,22 @@ flush_thread (void)
 }
 
 /*
- * Clean up state associated with current thread.  This is called when
+ * Clean up state associated with a thread.  This is called when
  * the thread calls exit().
  */
 void
-exit_thread (void)
+exit_thread (struct task_struct *tsk)
 {
 
-	ia64_drop_fpu(current);
+	ia64_drop_fpu(tsk);
 #ifdef CONFIG_PERFMON
        /* if needed, stop monitoring and flush state to perfmon context */
-	if (current->thread.pfm_context)
-		pfm_exit_thread(current);
+	if (tsk->thread.pfm_context)
+		pfm_exit_thread(tsk);
 
 	/* free debug register resources */
-	if (current->thread.flags & IA64_THREAD_DBG_VALID)
-		pfm_release_debug_registers(current);
+	if (tsk->thread.flags & IA64_THREAD_DBG_VALID)
+		pfm_release_debug_registers(tsk);
 #endif
 }
 

commit 6065a244a039a23d933e4b803a4e052da2849208
Author: Christoph Lameter <cl@linux.com>
Date:   Sun Aug 17 12:30:47 2014 -0500

    ia64: Replace __get_cpu_var uses
    
    __get_cpu_var() is used for multiple purposes in the kernel source. One of
    them is address calculation via the form &__get_cpu_var(x).  This calculates
    the address for the instance of the percpu variable of the current processor
    based on an offset.
    
    Other use cases are for storing and retrieving data from the current
    processors percpu area.  __get_cpu_var() can be used as an lvalue when
    writing data or on the right side of an assignment.
    
    __get_cpu_var() is defined as :
    
    #define __get_cpu_var(var) (*this_cpu_ptr(&(var)))
    
    __get_cpu_var() always only does an address determination. However, store
    and retrieve operations could use a segment prefix (or global register on
    other platforms) to avoid the address calculation.
    
    this_cpu_write() and this_cpu_read() can directly take an offset into a
    percpu area and use optimized assembly code to read and write per cpu
    variables.
    
    This patch converts __get_cpu_var into either an explicit address
    calculation using this_cpu_ptr() or into a use of this_cpu operations that
    use the offset.  Thereby address calculations are avoided and less registers
    are used when code is generated.
    
    At the end of the patch set all uses of __get_cpu_var have been removed so
    the macro is removed too.
    
    The patch set includes passes over all arches as well. Once these operations
    are used throughout then specialized macros can be defined in non -x86
    arches as well in order to optimize per cpu access by f.e.  using a global
    register that may be set to the per cpu base.
    
    Transformations done to __get_cpu_var()
    
    1. Determine the address of the percpu instance of the current processor.
    
            DEFINE_PER_CPU(int, y);
            int *x = &__get_cpu_var(y);
    
        Converts to
    
            int *x = this_cpu_ptr(&y);
    
    2. Same as #1 but this time an array structure is involved.
    
            DEFINE_PER_CPU(int, y[20]);
            int *x = __get_cpu_var(y);
    
        Converts to
    
            int *x = this_cpu_ptr(y);
    
    3. Retrieve the content of the current processors instance of a per cpu
    variable.
    
            DEFINE_PER_CPU(int, y);
            int x = __get_cpu_var(y)
    
       Converts to
    
            int x = __this_cpu_read(y);
    
    4. Retrieve the content of a percpu struct
    
            DEFINE_PER_CPU(struct mystruct, y);
            struct mystruct x = __get_cpu_var(y);
    
       Converts to
    
            memcpy(&x, this_cpu_ptr(&y), sizeof(x));
    
    5. Assignment to a per cpu variable
    
            DEFINE_PER_CPU(int, y)
            __get_cpu_var(y) = x;
    
       Converts to
    
            __this_cpu_write(y, x);
    
    6. Increment/Decrement etc of a per cpu variable
    
            DEFINE_PER_CPU(int, y);
            __get_cpu_var(y)++
    
       Converts to
    
            __this_cpu_inc(y)
    
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: linux-ia64@vger.kernel.org
    Signed-off-by: Christoph Lameter <cl@linux.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index deed6fa96bb0..b51514957620 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -215,7 +215,7 @@ static inline void play_dead(void)
 	unsigned int this_cpu = smp_processor_id();
 
 	/* Ack it */
-	__get_cpu_var(cpu_state) = CPU_DEAD;
+	__this_cpu_write(cpu_state, CPU_DEAD);
 
 	max_xtp();
 	local_irq_disable();
@@ -273,7 +273,7 @@ ia64_save_extra (struct task_struct *task)
 	if ((task->thread.flags & IA64_THREAD_PM_VALID) != 0)
 		pfm_save_regs(task);
 
-	info = __get_cpu_var(pfm_syst_info);
+	info = __this_cpu_read(pfm_syst_info);
 	if (info & PFM_CPUINFO_SYST_WIDE)
 		pfm_syst_wide_update_task(task, info, 0);
 #endif
@@ -293,7 +293,7 @@ ia64_load_extra (struct task_struct *task)
 	if ((task->thread.flags & IA64_THREAD_PM_VALID) != 0)
 		pfm_load_regs(task);
 
-	info = __get_cpu_var(pfm_syst_info);
+	info = __this_cpu_read(pfm_syst_info);
 	if (info & PFM_CPUINFO_SYST_WIDE) 
 		pfm_syst_wide_update_task(task, info, 1);
 #endif

commit 8562c99cdd30217dea3609e268572f8764f401a5
Author: Matt Fleming <matt.fleming@intel.com>
Date:   Fri Jun 13 12:22:22 2014 +0100

    efi/reboot: Add generic wrapper around EfiResetSystem()
    
    Implement efi_reboot(), which is really just a wrapper around the
    EfiResetSystem() EFI runtime service, but it does at least allow us to
    funnel all callers through a single location.
    
    It also simplifies the callsites since users no longer need to check to
    see whether EFI_RUNTIME_SERVICES are enabled.
    
    Cc: Tony Luck <tony.luck@intel.com>
    Tested-by: Mark Salter <msalter@redhat.com>
    Signed-off-by: Matt Fleming <matt.fleming@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 55d4ba47a907..deed6fa96bb0 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -662,7 +662,7 @@ void
 machine_restart (char *restart_cmd)
 {
 	(void) notify_die(DIE_MACHINE_RESTART, restart_cmd, NULL, 0, 0, 0);
-	(*efi.reset_system)(EFI_RESET_WARM, 0, 0, NULL);
+	efi_reboot(REBOOT_WARM, NULL);
 }
 
 void

commit a43cb95d547a061ed5bf1acb28e0f5fd575e26c1
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Apr 30 15:27:17 2013 -0700

    dump_stack: unify debug information printed by show_regs()
    
    show_regs() is inherently arch-dependent but it does make sense to print
    generic debug information and some archs already do albeit in slightly
    different forms.  This patch introduces a generic function to print debug
    information from show_regs() so that different archs print out the same
    information and it's much easier to modify what's printed.
    
    show_regs_print_info() prints out the same debug info as dump_stack()
    does plus task and thread_info pointers.
    
    * Archs which didn't print debug info now do.
    
      alpha, arc, blackfin, c6x, cris, frv, h8300, hexagon, ia64, m32r,
      metag, microblaze, mn10300, openrisc, parisc, score, sh64, sparc,
      um, xtensa
    
    * Already prints debug info.  Replaced with show_regs_print_info().
      The printed information is superset of what used to be there.
    
      arm, arm64, avr32, mips, powerpc, sh32, tile, unicore32, x86
    
    * s390 is special in that it used to print arch-specific information
      along with generic debug info.  Heiko and Martin think that the
      arch-specific extra isn't worth keeping s390 specfic implementation.
      Converted to use the generic version.
    
    Note that now all archs print the debug info before actual register
    dumps.
    
    An example BUG() dump follows.
    
     kernel BUG at /work/os/work/kernel/workqueue.c:4841!
     invalid opcode: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC
     Modules linked in:
     CPU: 0 PID: 1 Comm: swapper/0 Not tainted 3.9.0-rc1-work+ #7
     Hardware name: empty empty/S3992, BIOS 080011  10/26/2007
     task: ffff88007c85e040 ti: ffff88007c860000 task.ti: ffff88007c860000
     RIP: 0010:[<ffffffff8234a07e>]  [<ffffffff8234a07e>] init_workqueues+0x4/0x6
     RSP: 0000:ffff88007c861ec8  EFLAGS: 00010246
     RAX: ffff88007c861fd8 RBX: ffffffff824466a8 RCX: 0000000000000001
     RDX: 0000000000000046 RSI: 0000000000000001 RDI: ffffffff8234a07a
     RBP: ffff88007c861ec8 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000001 R11: 0000000000000000 R12: ffffffff8234a07a
     R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
     FS:  0000000000000000(0000) GS:ffff88007dc00000(0000) knlGS:0000000000000000
     CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
     CR2: ffff88015f7ff000 CR3: 00000000021f1000 CR4: 00000000000007f0
     DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
     DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
     Stack:
      ffff88007c861ef8 ffffffff81000312 ffffffff824466a8 ffff88007c85e650
      0000000000000003 0000000000000000 ffff88007c861f38 ffffffff82335e5d
      ffff88007c862080 ffffffff8223d8c0 ffff88007c862080 ffffffff81c47760
     Call Trace:
      [<ffffffff81000312>] do_one_initcall+0x122/0x170
      [<ffffffff82335e5d>] kernel_init_freeable+0x9b/0x1c8
      [<ffffffff81c47760>] ? rest_init+0x140/0x140
      [<ffffffff81c4776e>] kernel_init+0xe/0xf0
      [<ffffffff81c6be9c>] ret_from_fork+0x7c/0xb0
      [<ffffffff81c47760>] ? rest_init+0x140/0x140
      ...
    
    v2: Typo fix in x86-32.
    
    v3: CPU number dropped from show_regs_print_info() as
        dump_stack_print_info() has been updated to print it.  s390
        specific implementation dropped as requested by s390 maintainers.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: David S. Miller <davem@davemloft.net>
    Acked-by: Jesper Nilsson <jesper.nilsson@axis.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: Fengguang Wu <fengguang.wu@intel.com>
    Cc: Mike Frysinger <vapier@gentoo.org>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Sam Ravnborg <sam@ravnborg.org>
    Acked-by: Chris Metcalf <cmetcalf@tilera.com>           [tile bits]
    Acked-by: Richard Kuo <rkuo@codeaurora.org>             [hexagon bits]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 182bd64cc726..55d4ba47a907 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -101,8 +101,8 @@ show_regs (struct pt_regs *regs)
 	unsigned long ip = regs->cr_iip + ia64_psr(regs)->ri;
 
 	print_modules();
-	printk("\nPid: %d, CPU %d, comm: %20s\n", task_pid_nr(current),
-			smp_processor_id(), current->comm);
+	printk("\n");
+	show_regs_print_info(KERN_DEFAULT);
 	printk("psr : %016lx ifs : %016lx ip  : [<%016lx>]    %s (%s)\n",
 	       regs->cr_ipsr, regs->cr_ifs, ip, print_tainted(),
 	       init_utsname()->release);

commit 196779b9b4ce1922afabdc20d0270720603bd46c
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Apr 30 15:27:12 2013 -0700

    dump_stack: consolidate dump_stack() implementations and unify their behaviors
    
    Both dump_stack() and show_stack() are currently implemented by each
    architecture.  show_stack(NULL, NULL) dumps the backtrace for the
    current task as does dump_stack().  On some archs, dump_stack() prints
    extra information - pid, utsname and so on - in addition to the
    backtrace while the two are identical on other archs.
    
    The usages in arch-independent code of the two functions indicate
    show_stack(NULL, NULL) should print out bare backtrace while
    dump_stack() is used for debugging purposes when something went wrong,
    so it does make sense to print additional information on the task which
    triggered dump_stack().
    
    There's no reason to require archs to implement two separate but mostly
    identical functions.  It leads to unnecessary subtle information.
    
    This patch expands the dummy fallback dump_stack() implementation in
    lib/dump_stack.c such that it prints out debug information (taken from
    x86) and invokes show_stack(NULL, NULL) and drops arch-specific
    dump_stack() implementations in all archs except blackfin.  Blackfin's
    dump_stack() does something wonky that I don't understand.
    
    Debug information can be printed separately by calling
    dump_stack_print_info() so that arch-specific dump_stack()
    implementation can still emit the same debug information.  This is used
    in blackfin.
    
    This patch brings the following behavior changes.
    
    * On some archs, an extra level in backtrace for show_stack() could be
      printed.  This is because the top frame was determined in
      dump_stack() on those archs while generic dump_stack() can't do that
      reliably.  It can be compensated by inlining dump_stack() but not
      sure whether that'd be necessary.
    
    * Most archs didn't use to print debug info on dump_stack().  They do
      now.
    
    An example WARN dump follows.
    
     WARNING: at kernel/workqueue.c:4841 init_workqueues+0x35/0x505()
     Hardware name: empty
     Modules linked in:
     CPU: 0 PID: 1 Comm: swapper/0 Not tainted 3.9.0-rc1-work+ #9
      0000000000000009 ffff88007c861e08 ffffffff81c614dc ffff88007c861e48
      ffffffff8108f50f ffffffff82228240 0000000000000040 ffffffff8234a03c
      0000000000000000 0000000000000000 0000000000000000 ffff88007c861e58
     Call Trace:
      [<ffffffff81c614dc>] dump_stack+0x19/0x1b
      [<ffffffff8108f50f>] warn_slowpath_common+0x7f/0xc0
      [<ffffffff8108f56a>] warn_slowpath_null+0x1a/0x20
      [<ffffffff8234a071>] init_workqueues+0x35/0x505
      ...
    
    v2: CPU number added to the generic debug info as requested by s390
        folks and dropped the s390 specific dump_stack().  This loses %ksp
        from the debug message which the maintainers think isn't important
        enough to keep the s390-specific dump_stack() implementation.
    
        dump_stack_print_info() is moved to kernel/printk.c from
        lib/dump_stack.c.  Because linkage is per objecct file,
        dump_stack_print_info() living in the same lib file as generic
        dump_stack() means that archs which implement custom dump_stack()
        - at this point, only blackfin - can't use dump_stack_print_info()
        as that will bring in the generic version of dump_stack() too.  v1
        The v1 patch broke build on blackfin due to this issue.  The build
        breakage was reported by Fengguang Wu.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: David S. Miller <davem@davemloft.net>
    Acked-by: Vineet Gupta <vgupta@synopsys.com>
    Acked-by: Jesper Nilsson <jesper.nilsson@axis.com>
    Acked-by: Vineet Gupta <vgupta@synopsys.com>
    Acked-by: Martin Schwidefsky <schwidefsky@de.ibm.com>   [s390 bits]
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Mike Frysinger <vapier@gentoo.org>
    Cc: Fengguang Wu <fengguang.wu@intel.com>
    Cc: Bjorn Helgaas <bhelgaas@google.com>
    Cc: Sam Ravnborg <sam@ravnborg.org>
    Acked-by: Richard Kuo <rkuo@codeaurora.org>             [hexagon bits]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index a26fc640e4ce..182bd64cc726 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -95,14 +95,6 @@ show_stack (struct task_struct *task, unsigned long *sp)
 	}
 }
 
-void
-dump_stack (void)
-{
-	show_stack(NULL, NULL);
-}
-
-EXPORT_SYMBOL(dump_stack);
-
 void
 show_regs (struct pt_regs *regs)
 {

commit 91d591c387af34db00c39da2d1d25e69a91cf591
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Mar 21 22:49:47 2013 +0100

    ia64: Use generic idle loop
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Paul McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Reviewed-by: Cc: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Cc: Magnus Damm <magnus.damm@gmail.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Link: http://lkml.kernel.org/r/20130321215234.406851909@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 6f7dc8b7b35c..a26fc640e4ce 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -209,41 +209,13 @@ do_notify_resume_user(sigset_t *unused, struct sigscratch *scr, long in_syscall)
 	local_irq_disable();	/* force interrupt disable */
 }
 
-static int pal_halt        = 1;
-static int can_do_pal_halt = 1;
-
 static int __init nohalt_setup(char * str)
 {
-	pal_halt = can_do_pal_halt = 0;
+	cpu_idle_poll_ctrl(true);
 	return 1;
 }
 __setup("nohalt", nohalt_setup);
 
-void
-update_pal_halt_status(int status)
-{
-	can_do_pal_halt = pal_halt && status;
-}
-
-/*
- * We use this if we don't have any better idle routine..
- */
-void
-default_idle (void)
-{
-	local_irq_enable();
-	while (!need_resched()) {
-		if (can_do_pal_halt) {
-			local_irq_disable();
-			if (!need_resched()) {
-				safe_halt();
-			}
-			local_irq_enable();
-		} else
-			cpu_relax();
-	}
-}
-
 #ifdef CONFIG_HOTPLUG_CPU
 /* We don't actually take CPU down, just spin without interrupts. */
 static inline void play_dead(void)
@@ -270,47 +242,29 @@ static inline void play_dead(void)
 }
 #endif /* CONFIG_HOTPLUG_CPU */
 
-void __attribute__((noreturn))
-cpu_idle (void)
+void arch_cpu_idle_dead(void)
+{
+	play_dead();
+}
+
+void arch_cpu_idle(void)
 {
 	void (*mark_idle)(int) = ia64_mark_idle;
-  	int cpu = smp_processor_id();
-
-	/* endless idle loop with no priority at all */
-	while (1) {
-		rcu_idle_enter();
-		if (can_do_pal_halt) {
-			current_thread_info()->status &= ~TS_POLLING;
-			/*
-			 * TS_POLLING-cleared state must be visible before we
-			 * test NEED_RESCHED:
-			 */
-			smp_mb();
-		} else {
-			current_thread_info()->status |= TS_POLLING;
-		}
 
-		if (!need_resched()) {
 #ifdef CONFIG_SMP
-			min_xtp();
+	min_xtp();
 #endif
-			rmb();
-			if (mark_idle)
-				(*mark_idle)(1);
+	rmb();
+	if (mark_idle)
+		(*mark_idle)(1);
+
+	safe_halt();
 
-			default_idle();
-			if (mark_idle)
-				(*mark_idle)(0);
+	if (mark_idle)
+		(*mark_idle)(0);
 #ifdef CONFIG_SMP
-			normal_xtp();
+	normal_xtp();
 #endif
-		}
-		rcu_idle_exit();
-		schedule_preempt_disabled();
-		check_pgt_cache();
-		if (cpu_is_offline(cpu))
-			play_dead();
-	}
 }
 
 void

commit ed176886b68fbc450ddbe808684a142fcad72b56
Author: Len Brown <len.brown@intel.com>
Date:   Fri Mar 29 11:02:30 2013 -0700

    ia64 idle: delete stale (*idle)() function pointer
    
    Commit 3e7fc708eb41 ("ia64 idle: delete pm_idle") in 3.9-rc1 didn't
    finish the job, leaving an un-initialized reference to (*idle)().
    
    [ Haven't seen a crash from this - but seems like we are just being
      lucky that "idle" is zero so it does get initialized before we jump to
      randomland  - Len ]
    
    Reported-by: Lars-Peter Clausen <lars@metafoo.de>
    Signed-off-by: Len Brown <len.brown@intel.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index e34f565f595a..6f7dc8b7b35c 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -291,7 +291,6 @@ cpu_idle (void)
 		}
 
 		if (!need_resched()) {
-			void (*idle)(void);
 #ifdef CONFIG_SMP
 			min_xtp();
 #endif
@@ -299,9 +298,7 @@ cpu_idle (void)
 			if (mark_idle)
 				(*mark_idle)(1);
 
-			if (!idle)
-				idle = default_idle;
-			(*idle)();
+			default_idle();
 			if (mark_idle)
 				(*mark_idle)(0);
 #ifdef CONFIG_SMP

commit 3e7fc708eb41f6385cf5cf64a68417a4be822be8
Author: Len Brown <len.brown@intel.com>
Date:   Sat Feb 9 22:28:34 2013 -0500

    ia64 idle: delete pm_idle
    
    pm_idle() on ia64 was a synonym for default_idle().
    So simply invoke default_idle() directly.
    
    Signed-off-by: Len Brown <len.brown@intel.com>
    Cc: linux-ia64@vger.kernel.org

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 31360cbbd5f8..e34f565f595a 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -57,8 +57,6 @@ void (*ia64_mark_idle)(int);
 
 unsigned long boot_option_idle_override = IDLE_NO_OVERRIDE;
 EXPORT_SYMBOL(boot_option_idle_override);
-void (*pm_idle) (void);
-EXPORT_SYMBOL(pm_idle);
 void (*pm_power_off) (void);
 EXPORT_SYMBOL(pm_power_off);
 
@@ -301,7 +299,6 @@ cpu_idle (void)
 			if (mark_idle)
 				(*mark_idle)(1);
 
-			idle = pm_idle;
 			if (!idle)
 				idle = default_idle;
 			(*idle)();

commit afa86fc426ff7e7f5477f15da9c405d08d5cf790
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Oct 22 22:51:14 2012 -0400

    flagday: don't pass regs to copy_thread()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 25543a295ad9..31360cbbd5f8 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -393,12 +393,13 @@ ia64_load_extra (struct task_struct *task)
 int
 copy_thread(unsigned long clone_flags,
 	     unsigned long user_stack_base, unsigned long user_stack_size,
-	     struct task_struct *p, struct pt_regs *regs)
+	     struct task_struct *p)
 {
 	extern char ia64_ret_from_clone;
 	struct switch_stack *child_stack, *stack;
 	unsigned long rbs, child_rbs, rbs_size;
 	struct pt_regs *child_ptregs;
+	struct pt_regs *regs = current_pt_regs();
 	int retval = 0;
 
 	child_ptregs = (struct pt_regs *) ((unsigned long) p + IA64_STK_OFFSET) - 1;

commit 71b4ecc3d8056b2ed5cbc0d77af13fed38bcac49
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Oct 14 15:53:04 2012 -0400

    ia64: switch to generic sys_execve()
    
    Acked-by: Tony Luck <tony.luck@intel.com>
    Tested-by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 37686dbfd264..25543a295ad9 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -617,25 +617,6 @@ dump_fpu (struct pt_regs *pt, elf_fpregset_t dst)
 	return 1;	/* f0-f31 are always valid so we always return 1 */
 }
 
-long
-sys_execve (const char __user *filename,
-	    const char __user *const __user *argv,
-	    const char __user *const __user *envp,
-	    struct pt_regs *regs)
-{
-	struct filename *fname;
-	int error;
-
-	fname = getname(filename);
-	error = PTR_ERR(fname);
-	if (IS_ERR(fname))
-		goto out;
-	error = do_execve(fname->name, argv, envp, regs);
-	putname(fname);
-out:
-	return error;
-}
-
 /*
  * Flush thread state.  This is called when a thread does an execve().
  */

commit 54d496c3915a10b5e46c5dd9de1a6d301ceb32bd
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Oct 14 15:43:06 2012 -0400

    ia64: switch to generic kernel_thread()/kernel_execve()
    
    Acked-by: Tony Luck <tony.luck@intel.com>
    Tested-by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 6a48775d9363..37686dbfd264 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -401,55 +401,15 @@ copy_thread(unsigned long clone_flags,
 	struct pt_regs *child_ptregs;
 	int retval = 0;
 
-	stack = ((struct switch_stack *) regs) - 1;
-
 	child_ptregs = (struct pt_regs *) ((unsigned long) p + IA64_STK_OFFSET) - 1;
 	child_stack = (struct switch_stack *) child_ptregs - 1;
 
-	/* copy parent's switch_stack & pt_regs to child: */
-	memcpy(child_stack, stack, sizeof(*child_ptregs) + sizeof(*child_stack));
-
 	rbs = (unsigned long) current + IA64_RBS_OFFSET;
 	child_rbs = (unsigned long) p + IA64_RBS_OFFSET;
 
-	if (likely(user_mode(child_ptregs))) {
-		/* copy the parent's register backing store to the child: */
-		rbs_size = stack->ar_bspstore - rbs;
-		memcpy((void *) child_rbs, (void *) rbs, rbs_size);
-		if (clone_flags & CLONE_SETTLS)
-			child_ptregs->r13 = regs->r16;	/* see sys_clone2() in entry.S */
-		if (user_stack_base) {
-			child_ptregs->r12 = user_stack_base + user_stack_size - 16;
-			child_ptregs->ar_bspstore = user_stack_base;
-			child_ptregs->ar_rnat = 0;
-			child_ptregs->loadrs = 0;
-		}
-	} else {
-		/*
-		 * Note: we simply preserve the relative position of
-		 * the stack pointer here.  There is no need to
-		 * allocate a scratch area here, since that will have
-		 * been taken care of by the caller of sys_clone()
-		 * already.
-		 */
-		rbs_size = 0;
-		child_ptregs->r12 = (unsigned long) child_ptregs - 16; /* kernel sp */
-		child_ptregs->r13 = (unsigned long) p;		/* set `current' pointer */
-	}
-	child_stack->ar_bspstore = child_rbs + rbs_size;
-	child_stack->b0 = (unsigned long) &ia64_ret_from_clone;
-
 	/* copy parts of thread_struct: */
 	p->thread.ksp = (unsigned long) child_stack - 16;
 
-	/* stop some PSR bits from being inherited.
-	 * the psr.up/psr.pp bits must be cleared on fork but inherited on execve()
-	 * therefore we must specify them explicitly here and not include them in
-	 * IA64_PSR_BITS_TO_CLEAR.
-	 */
-	child_ptregs->cr_ipsr = ((child_ptregs->cr_ipsr | IA64_PSR_BITS_TO_SET)
-				 & ~(IA64_PSR_BITS_TO_CLEAR | IA64_PSR_PP | IA64_PSR_UP));
-
 	/*
 	 * NOTE: The calling convention considers all floating point
 	 * registers in the high partition (fph) to be scratch.  Since
@@ -471,8 +431,66 @@ copy_thread(unsigned long clone_flags,
 #	define THREAD_FLAGS_TO_SET	0
 	p->thread.flags = ((current->thread.flags & ~THREAD_FLAGS_TO_CLEAR)
 			   | THREAD_FLAGS_TO_SET);
+
 	ia64_drop_fpu(p);	/* don't pick up stale state from a CPU's fph */
 
+	if (unlikely(p->flags & PF_KTHREAD)) {
+		if (unlikely(!user_stack_base)) {
+			/* fork_idle() called us */
+			return 0;
+		}
+		memset(child_stack, 0, sizeof(*child_ptregs) + sizeof(*child_stack));
+		child_stack->r4 = user_stack_base;	/* payload */
+		child_stack->r5 = user_stack_size;	/* argument */
+		/*
+		 * Preserve PSR bits, except for bits 32-34 and 37-45,
+		 * which we can't read.
+		 */
+		child_ptregs->cr_ipsr = ia64_getreg(_IA64_REG_PSR) | IA64_PSR_BN;
+		/* mark as valid, empty frame */
+		child_ptregs->cr_ifs = 1UL << 63;
+		child_stack->ar_fpsr = child_ptregs->ar_fpsr
+			= ia64_getreg(_IA64_REG_AR_FPSR);
+		child_stack->pr = (1 << PRED_KERNEL_STACK);
+		child_stack->ar_bspstore = child_rbs;
+		child_stack->b0 = (unsigned long) &ia64_ret_from_clone;
+
+		/* stop some PSR bits from being inherited.
+		 * the psr.up/psr.pp bits must be cleared on fork but inherited on execve()
+		 * therefore we must specify them explicitly here and not include them in
+		 * IA64_PSR_BITS_TO_CLEAR.
+		 */
+		child_ptregs->cr_ipsr = ((child_ptregs->cr_ipsr | IA64_PSR_BITS_TO_SET)
+				 & ~(IA64_PSR_BITS_TO_CLEAR | IA64_PSR_PP | IA64_PSR_UP));
+
+		return 0;
+	}
+	stack = ((struct switch_stack *) regs) - 1;
+	/* copy parent's switch_stack & pt_regs to child: */
+	memcpy(child_stack, stack, sizeof(*child_ptregs) + sizeof(*child_stack));
+
+	/* copy the parent's register backing store to the child: */
+	rbs_size = stack->ar_bspstore - rbs;
+	memcpy((void *) child_rbs, (void *) rbs, rbs_size);
+	if (clone_flags & CLONE_SETTLS)
+		child_ptregs->r13 = regs->r16;	/* see sys_clone2() in entry.S */
+	if (user_stack_base) {
+		child_ptregs->r12 = user_stack_base + user_stack_size - 16;
+		child_ptregs->ar_bspstore = user_stack_base;
+		child_ptregs->ar_rnat = 0;
+		child_ptregs->loadrs = 0;
+	}
+	child_stack->ar_bspstore = child_rbs + rbs_size;
+	child_stack->b0 = (unsigned long) &ia64_ret_from_clone;
+
+	/* stop some PSR bits from being inherited.
+	 * the psr.up/psr.pp bits must be cleared on fork but inherited on execve()
+	 * therefore we must specify them explicitly here and not include them in
+	 * IA64_PSR_BITS_TO_CLEAR.
+	 */
+	child_ptregs->cr_ipsr = ((child_ptregs->cr_ipsr | IA64_PSR_BITS_TO_SET)
+				 & ~(IA64_PSR_BITS_TO_CLEAR | IA64_PSR_PP | IA64_PSR_UP));
+
 #ifdef CONFIG_PERFMON
 	if (current->thread.pfm_context)
 		pfm_inherit(p, child_ptregs);
@@ -618,37 +636,6 @@ sys_execve (const char __user *filename,
 	return error;
 }
 
-pid_t
-kernel_thread (int (*fn)(void *), void *arg, unsigned long flags)
-{
-	extern void start_kernel_thread (void);
-	unsigned long *helper_fptr = (unsigned long *) &start_kernel_thread;
-	struct {
-		struct switch_stack sw;
-		struct pt_regs pt;
-	} regs;
-
-	memset(&regs, 0, sizeof(regs));
-	regs.pt.cr_iip = helper_fptr[0];	/* set entry point (IP) */
-	regs.pt.r1 = helper_fptr[1];		/* set GP */
-	regs.pt.r9 = (unsigned long) fn;	/* 1st argument */
-	regs.pt.r11 = (unsigned long) arg;	/* 2nd argument */
-	/* Preserve PSR bits, except for bits 32-34 and 37-45, which we can't read.  */
-	regs.pt.cr_ipsr = ia64_getreg(_IA64_REG_PSR) | IA64_PSR_BN;
-	regs.pt.cr_ifs = 1UL << 63;		/* mark as valid, empty frame */
-	regs.sw.ar_fpsr = regs.pt.ar_fpsr = ia64_getreg(_IA64_REG_AR_FPSR);
-	regs.sw.pr = (1 << PRED_KERNEL_STACK);
-	return do_fork(flags | CLONE_VM | CLONE_UNTRACED, 0, &regs.pt, 0, NULL, NULL);
-}
-EXPORT_SYMBOL(kernel_thread);
-
-/* This gets called from kernel_thread() via ia64_invoke_thread_helper().  */
-int
-kernel_thread_helper (int (*fn)(void *), void *arg)
-{
-	return (*fn)(arg);
-}
-
 /*
  * Flush thread state.  This is called when a thread does an execve().
  */

commit c19e6d67e4be16e20ff90f0baa98b16d926d23a5
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Sep 30 00:27:40 2012 -0400

    ia64: don't mess with ar_bspstore in kernel_thread()
    
    the only thing we use that for is in copy_thread(), where the way
    we set it will result in rbs_size being 0.  Just move that calculating
    rbs_size and copying rbs to non-kernel-thread side of
    if (user_mode(regs)) in copy_thread() and set rbs_size to 0 on
    kernel thread side.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 63a77b8b5cfa..6a48775d9363 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -411,12 +411,11 @@ copy_thread(unsigned long clone_flags,
 
 	rbs = (unsigned long) current + IA64_RBS_OFFSET;
 	child_rbs = (unsigned long) p + IA64_RBS_OFFSET;
-	rbs_size = stack->ar_bspstore - rbs;
-
-	/* copy the parent's register backing store to the child: */
-	memcpy((void *) child_rbs, (void *) rbs, rbs_size);
 
 	if (likely(user_mode(child_ptregs))) {
+		/* copy the parent's register backing store to the child: */
+		rbs_size = stack->ar_bspstore - rbs;
+		memcpy((void *) child_rbs, (void *) rbs, rbs_size);
 		if (clone_flags & CLONE_SETTLS)
 			child_ptregs->r13 = regs->r16;	/* see sys_clone2() in entry.S */
 		if (user_stack_base) {
@@ -433,6 +432,7 @@ copy_thread(unsigned long clone_flags,
 		 * been taken care of by the caller of sys_clone()
 		 * already.
 		 */
+		rbs_size = 0;
 		child_ptregs->r12 = (unsigned long) child_ptregs - 16; /* kernel sp */
 		child_ptregs->r13 = (unsigned long) p;		/* set `current' pointer */
 	}
@@ -637,7 +637,6 @@ kernel_thread (int (*fn)(void *), void *arg, unsigned long flags)
 	regs.pt.cr_ipsr = ia64_getreg(_IA64_REG_PSR) | IA64_PSR_BN;
 	regs.pt.cr_ifs = 1UL << 63;		/* mark as valid, empty frame */
 	regs.sw.ar_fpsr = regs.pt.ar_fpsr = ia64_getreg(_IA64_REG_AR_FPSR);
-	regs.sw.ar_bspstore = (unsigned long) current + IA64_RBS_OFFSET;
 	regs.sw.pr = (1 << PRED_KERNEL_STACK);
 	return do_fork(flags | CLONE_VM | CLONE_UNTRACED, 0, &regs.pt, 0, NULL, NULL);
 }

commit c4aee363af2a81f9726c5fa13e136ebaf02852bd
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sun Sep 30 00:23:05 2012 -0400

    ia64: dead code in copy_thread() since 2004
    
    It used to be called with NULL regs when creating idle threads on
    secondaries.  Not used that way since wli had buried that kludge...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 35e106f2ed13..63a77b8b5cfa 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -401,15 +401,6 @@ copy_thread(unsigned long clone_flags,
 	struct pt_regs *child_ptregs;
 	int retval = 0;
 
-#ifdef CONFIG_SMP
-	/*
-	 * For SMP idle threads, fork_by_hand() calls do_fork with
-	 * NULL regs.
-	 */
-	if (!regs)
-		return 0;
-#endif
-
 	stack = ((struct switch_stack *) regs) - 1;
 
 	child_ptregs = (struct pt_regs *) ((unsigned long) p + IA64_STK_OFFSET) - 1;

commit 91a27b2a756784714e924e5e854b919273082d26
Author: Jeff Layton <jlayton@redhat.com>
Date:   Wed Oct 10 15:25:28 2012 -0400

    vfs: define struct filename and have getname() return it
    
    getname() is intended to copy pathname strings from userspace into a
    kernel buffer. The result is just a string in kernel space. It would
    however be quite helpful to be able to attach some ancillary info to
    the string.
    
    For instance, we could attach some audit-related info to reduce the
    amount of audit-related processing needed. When auditing is enabled,
    we could also call getname() on the string more than once and not
    need to recopy it from userspace.
    
    This patchset converts the getname()/putname() interfaces to return
    a struct instead of a string. For now, the struct just tracks the
    string in kernel space and the original userland pointer for it.
    
    Later, we'll add other information to the struct as it becomes
    convenient.
    
    Signed-off-by: Jeff Layton <jlayton@redhat.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index ee31fe9b310e..35e106f2ed13 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -614,14 +614,14 @@ sys_execve (const char __user *filename,
 	    const char __user *const __user *envp,
 	    struct pt_regs *regs)
 {
-	char *fname;
+	struct filename *fname;
 	int error;
 
 	fname = getname(filename);
 	error = PTR_ERR(fname);
 	if (IS_ERR(fname))
 		goto out;
-	error = do_execve(fname, argv, envp, regs);
+	error = do_execve(fname->name, argv, envp, regs);
 	putname(fname);
 out:
 	return error;

commit a57d985e378ca69f430b85852e4187db3698a89e
Merge: cdeb9b014331 39c9a4ab2b91
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Oct 1 13:56:35 2012 -0700

    Merge tag 'please-pull-ia64-for-3.7' of git://git.kernel.org/pub/scm/linux/kernel/git/aegl/linux
    
    Pull ia64 update from Tony Luck:
     "Usual mish-mash of ia64 fixes for next merge window"
    
    * tag 'please-pull-ia64-for-3.7' of git://git.kernel.org/pub/scm/linux/kernel/git/aegl/linux:
      [IA64] xen: Fix return value check in xencomm_vtop()
      [IA64] Must enable interrupts in do_notify_resume_user before calling tracehook_notify_resume()
      [IA64] kexec: Move the dereference below the NULL test
      [IA64] Fix a node distance bug

commit 93482f4ef1093f5961a63359a34612183d6beea0
Author: Paul E. McKenney <paul.mckenney@linaro.org>
Date:   Fri Aug 24 13:22:13 2012 -0700

    ia64: Add missing RCU idle APIs on idle loop
    
    Traditionally, the entire idle task served as an RCU quiescent state.
    But when RCU read side critical sections started appearing within the
    idle loop, this traditional strategy became untenable.  The fix was to
    create new RCU APIs named rcu_idle_enter() and rcu_idle_exit(), which
    must be called by each architecture's idle loop so that RCU can tell
    when it is safe to ignore a given idle CPU.
    
    Unfortunately, this fix was never applied to ia64, a shortcoming remedied
    by this commit.
    
    Reported by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Paul E. McKenney <paul.mckenney@linaro.org>
    Cc: <stable@vger.kernel.org> # 3.3+
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Tested by: Tony Luck <tony.luck@intel.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index dd6fc1449741..3e316ec0b835 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -29,6 +29,7 @@
 #include <linux/kdebug.h>
 #include <linux/utsname.h>
 #include <linux/tracehook.h>
+#include <linux/rcupdate.h>
 
 #include <asm/cpu.h>
 #include <asm/delay.h>
@@ -279,6 +280,7 @@ cpu_idle (void)
 
 	/* endless idle loop with no priority at all */
 	while (1) {
+		rcu_idle_enter();
 		if (can_do_pal_halt) {
 			current_thread_info()->status &= ~TS_POLLING;
 			/*
@@ -309,6 +311,7 @@ cpu_idle (void)
 			normal_xtp();
 #endif
 		}
+		rcu_idle_exit();
 		schedule_preempt_disabled();
 		check_pgt_cache();
 		if (cpu_is_offline(cpu))

commit 0967237ca6521c63822340138e4d62ecf8a3d173
Author: Tony Luck <tony.luck@intel.com>
Date:   Thu Sep 20 11:47:13 2012 -0700

    [IA64] Must enable interrupts in do_notify_resume_user before calling tracehook_notify_resume()
    
    If we call with interrupts disabled, we'll be hit with:
    
    WARNING: at kernel/softirq.c:160 local_bh_enable_ip+0x150/0x180() and a stack
    trace like this:
    
    Call Trace:
     [<a000000100015480>] show_stack+0x80/0xa0
     [<a000000100d9a520>] dump_stack+0x30/0x50
     [<a000000100072fc0>] warn_slowpath_common+0xc0/0x100
     [<a000000100073040>] warn_slowpath_null+0x40/0x60
     [<a0000001000884d0>] local_bh_enable_ip+0x150/0x180
     [<a000000100da2960>] _raw_write_unlock_bh+0x40/0x60
     [<a000000100cf03c0>] unix_release_sock+0x120/0x5a0
     [<a000000100cf0880>] unix_release+0x40/0x60
     [<a000000100b84400>] sock_release+0x60/0x1a0
     [<a000000100b84b70>] sock_close+0x30/0xa0
     [<a0000001001d10f0>] __fput+0x190/0x500
     [<a0000001001d1580>] ____fput+0x20/0x40
     [<a0000001000b6570>] task_work_run+0x1b0/0x260
     [<a000000100015190>] do_notify_resume_user+0x110/0x2a0
     [<a00000010000c5a0>] notify_resume_user+0x40/0x60
     [<a00000010000c4d0>] skip_rbs_switch+0xe0/0xf0
     [<a000000000040720>] ia64_ivt+0xffffffff00040720/0x400
    
    Fix-suggested-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index dd6fc1449741..cf84a2f37c13 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -196,8 +196,8 @@ do_notify_resume_user(sigset_t *unused, struct sigscratch *scr, long in_syscall)
 		ia64_do_signal(scr, in_syscall);
 	}
 
-	if (test_thread_flag(TIF_NOTIFY_RESUME)) {
-		clear_thread_flag(TIF_NOTIFY_RESUME);
+	if (test_and_clear_thread_flag(TIF_NOTIFY_RESUME)) {
+		local_irq_enable();	/* force interrupt enable */
 		tracehook_notify_resume(&scr->pt);
 	}
 

commit a42c6ded827dbd396d2efde7530620be029a72d1
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed May 23 14:44:37 2012 -0400

    move key_repace_session_keyring() into tracehook_notify_resume()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 5e0e86ddb12f..dd6fc1449741 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -199,8 +199,6 @@ do_notify_resume_user(sigset_t *unused, struct sigscratch *scr, long in_syscall)
 	if (test_thread_flag(TIF_NOTIFY_RESUME)) {
 		clear_thread_flag(TIF_NOTIFY_RESUME);
 		tracehook_notify_resume(&scr->pt);
-		if (current->replacement_session_keyring)
-			key_replace_session_keyring();
 	}
 
 	/* copy user rbs to kernel rbs */

commit bbe78cbd729f85c4da6e04f45c8b2de43c3573f1
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 7 17:59:50 2012 +0000

    ia64: Remove unused cpu_idle_wait()
    
    IA64 does not set CONFIG_ARCH_HAVE_IDLE_WAIT and cpuidle uses a
    generic function now. Remove the unused code.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Tony Luck <tony.luck@intel.com>
    Link: http://lkml.kernel.org/r/20120507175652.392394511@linutronix.de

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index ce74e143aea3..5e0e86ddb12f 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -273,26 +273,6 @@ static inline void play_dead(void)
 }
 #endif /* CONFIG_HOTPLUG_CPU */
 
-static void do_nothing(void *unused)
-{
-}
-
-/*
- * cpu_idle_wait - Used to ensure that all the CPUs discard old value of
- * pm_idle and update to new pm_idle value. Required while changing pm_idle
- * handler on SMP systems.
- *
- * Caller must have changed pm_idle to the new value before the call. Old
- * pm_idle value will not be used by any CPU after the return of this function.
- */
-void cpu_idle_wait(void)
-{
-	smp_mb();
-	/* kick all the CPUs so that they exit out of pm_idle */
-	smp_call_function(do_nothing, NULL, 1);
-}
-EXPORT_SYMBOL_GPL(cpu_idle_wait);
-
 void __attribute__((noreturn))
 cpu_idle (void)
 {

commit 93f378883cecb9dcb2cf5b51d9d24175906659da
Author: Luck, Tony <tony.luck@intel.com>
Date:   Thu Mar 29 13:35:22 2012 -0700

    Fix ia64 build errors (fallout from system.h disintegration)
    
    Fix this build error on ia64:
    
      In file included from include/linux/sched.h:92,
                      from arch/ia64/kernel/asm-offsets.c:9:
      include/linux/llist.h:59:25: error: asm/cmpxchg.h: No such file or directory
      make[1]: *** [arch/ia64/kernel/asm-offsets.s] Error 1
    
    Right now we don't seem to need any actual contents for the
    asm/cmpxchg.h to make the build work ...  so leave the migration of
    xchg() and cmpxchg() to this new header file for a future patch.
    
    Also process.c needs <asm/switch_to.h> (for definition of pfm_syst_info).
    
    Signed-off-by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 9dc52b63fc87..ce74e143aea3 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -38,6 +38,7 @@
 #include <asm/pgalloc.h>
 #include <asm/processor.h>
 #include <asm/sal.h>
+#include <asm/switch_to.h>
 #include <asm/tlbflush.h>
 #include <asm/uaccess.h>
 #include <asm/unwind.h>

commit bd2f55361f18347e890d52ff9cfd8895455ec11b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Mar 21 12:33:18 2011 +0100

    sched/rt: Use schedule_preempt_disabled()
    
    Coccinelle based conversion.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/n/tip-24swm5zut3h9c4a6s46x8rws@git.kernel.org
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 6d33c5cc94f0..9dc52b63fc87 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -330,9 +330,7 @@ cpu_idle (void)
 			normal_xtp();
 #endif
 		}
-		preempt_enable_no_resched();
-		schedule();
-		preempt_disable();
+		schedule_preempt_disabled();
 		check_pgt_cache();
 		if (cpu_is_offline(cpu))
 			play_dead();

commit d18960494f65ca4fa0d67c865aaca99452070d15
Author: Thomas Renninger <trenn@suse.de>
Date:   Wed Nov 3 17:06:14 2010 +0100

    ACPI, intel_idle: Cleanup idle= internal variables
    
    Having four variables for the same thing:
      idle_halt, idle_nomwait, force_mwait and boot_option_idle_overrides
    is rather confusing and unnecessary complex.
    
    if idle= boot param is passed, only set up one variable:
    boot_option_idle_overrides
    
    Introduces following functional changes/fixes:
      - intel_idle driver does not register if any idle=xy
        boot param is passed.
      - processor_idle.c will also not register a cpuidle driver
        and get active if idle=halt is passed.
        Before a cpuidle driver with one (C1, halt) state got registered
        Now the default_idle function will be used which finally uses
        the same idle call to enter sleep state (safe_halt()), but
        without registering a whole cpuidle driver.
    
    That means idle= param will always avoid cpuidle drivers to register
    with one exception (same behavior as before):
    idle=nomwait
    may still register acpi_idle cpuidle driver, but C1 will not use
    mwait, but hlt. This can be a workaround for IO based deeper sleep
    states where C1 mwait causes problems.
    
    Signed-off-by: Thomas Renninger <trenn@suse.de>
    cc: x86@kernel.org
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 16f1c7b04c69..6d33c5cc94f0 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -53,12 +53,8 @@
 
 void (*ia64_mark_idle)(int);
 
-unsigned long boot_option_idle_override = 0;
+unsigned long boot_option_idle_override = IDLE_NO_OVERRIDE;
 EXPORT_SYMBOL(boot_option_idle_override);
-unsigned long idle_halt;
-EXPORT_SYMBOL(idle_halt);
-unsigned long idle_nomwait;
-EXPORT_SYMBOL(idle_nomwait);
 void (*pm_idle) (void);
 EXPORT_SYMBOL(pm_idle);
 void (*pm_power_off) (void);

commit d7627467b7a8dd6944885290a03a07ceb28c10eb
Author: David Howells <dhowells@redhat.com>
Date:   Tue Aug 17 23:52:56 2010 +0100

    Make do_execve() take a const filename pointer
    
    Make do_execve() take a const filename pointer so that kernel_execve() compiles
    correctly on ARM:
    
    arch/arm/kernel/sys_arm.c:88: warning: passing argument 1 of 'do_execve' discards qualifiers from pointer target type
    
    This also requires the argv and envp arguments to be consted twice, once for
    the pointer array and once for the strings the array points to.  This is
    because do_execve() passes a pointer to the filename (now const) to
    copy_strings_kernel().  A simpler alternative would be to cast the filename
    pointer in do_execve() when it's passed to copy_strings_kernel().
    
    do_execve() may not change any of the strings it is passed as part of the argv
    or envp lists as they are some of them in .rodata, so marking these strings as
    const should be fine.
    
    Further kernel_execve() and sys_execve() need to be changed to match.
    
    This has been test built on x86_64, frv, arm and mips.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Tested-by: Ralf Baechle <ralf@linux-mips.org>
    Acked-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index a879c03b7f1c..16f1c7b04c69 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -633,7 +633,9 @@ dump_fpu (struct pt_regs *pt, elf_fpregset_t dst)
 }
 
 long
-sys_execve (const char __user *filename, char __user * __user *argv, char __user * __user *envp,
+sys_execve (const char __user *filename,
+	    const char __user *const __user *argv,
+	    const char __user *const __user *envp,
 	    struct pt_regs *regs)
 {
 	char *fname;

commit c7887325230aec47d47a32562a6e26014a0fafca
Author: David Howells <dhowells@redhat.com>
Date:   Wed Aug 11 11:26:22 2010 +0100

    Mark arguments to certain syscalls as being const
    
    Mark arguments to certain system calls as being const where they should be but
    aren't.  The list includes:
    
     (*) The filename arguments of various stat syscalls, execve(), various utimes
         syscalls and some mount syscalls.
    
     (*) The filename arguments of some syscall helpers relating to the above.
    
     (*) The buffer argument of various write syscalls.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 53f1648c8b81..a879c03b7f1c 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -633,7 +633,7 @@ dump_fpu (struct pt_regs *pt, elf_fpregset_t dst)
 }
 
 long
-sys_execve (char __user *filename, char __user * __user *argv, char __user * __user *envp,
+sys_execve (const char __user *filename, char __user * __user *argv, char __user * __user *envp,
 	    struct pt_regs *regs)
 {
 	char *fname;

commit 5a0e3ad6af8660be21ca98a971cd00f331318c05
Author: Tejun Heo <tj@kernel.org>
Date:   Wed Mar 24 17:04:11 2010 +0900

    include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h
    
    percpu.h is included by sched.h and module.h and thus ends up being
    included when building most .c files.  percpu.h includes slab.h which
    in turn includes gfp.h making everything defined by the two files
    universally available and complicating inclusion dependencies.
    
    percpu.h -> slab.h dependency is about to be removed.  Prepare for
    this change by updating users of gfp and slab facilities include those
    headers directly instead of assuming availability.  As this conversion
    needs to touch large number of source files, the following script is
    used as the basis of conversion.
    
      http://userweb.kernel.org/~tj/misc/slabh-sweep.py
    
    The script does the followings.
    
    * Scan files for gfp and slab usages and update includes such that
      only the necessary includes are there.  ie. if only gfp is used,
      gfp.h, if slab is used, slab.h.
    
    * When the script inserts a new include, it looks at the include
      blocks and try to put the new include such that its order conforms
      to its surrounding.  It's put in the include block which contains
      core kernel includes, in the same order that the rest are ordered -
      alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
      doesn't seem to be any matching order.
    
    * If the script can't find a place to put a new include (mostly
      because the file doesn't have fitting include block), it prints out
      an error message indicating which .h file needs to be added to the
      file.
    
    The conversion was done in the following steps.
    
    1. The initial automatic conversion of all .c files updated slightly
       over 4000 files, deleting around 700 includes and adding ~480 gfp.h
       and ~3000 slab.h inclusions.  The script emitted errors for ~400
       files.
    
    2. Each error was manually checked.  Some didn't need the inclusion,
       some needed manual addition while adding it to implementation .h or
       embedding .c file was more appropriate for others.  This step added
       inclusions to around 150 files.
    
    3. The script was run again and the output was compared to the edits
       from #2 to make sure no file was left behind.
    
    4. Several build tests were done and a couple of problems were fixed.
       e.g. lib/decompress_*.c used malloc/free() wrappers around slab
       APIs requiring slab.h to be added manually.
    
    5. The script was run on all .h files but without automatically
       editing them as sprinkling gfp.h and slab.h inclusions around .h
       files could easily lead to inclusion dependency hell.  Most gfp.h
       inclusion directives were ignored as stuff from gfp.h was usually
       wildly available and often used in preprocessor macros.  Each
       slab.h inclusion directive was examined and added manually as
       necessary.
    
    6. percpu.h was updated not to include slab.h.
    
    7. Build test were done on the following configurations and failures
       were fixed.  CONFIG_GCOV_KERNEL was turned off for all tests (as my
       distributed build env didn't work with gcov compiles) and a few
       more options had to be turned off depending on archs to make things
       build (like ipr on powerpc/64 which failed due to missing writeq).
    
       * x86 and x86_64 UP and SMP allmodconfig and a custom test config.
       * powerpc and powerpc64 SMP allmodconfig
       * sparc and sparc64 SMP allmodconfig
       * ia64 SMP allmodconfig
       * s390 SMP allmodconfig
       * alpha SMP allmodconfig
       * um on x86_64 SMP allmodconfig
    
    8. percpu.h modifications were reverted so that it could be applied as
       a separate patch and serve as bisection point.
    
    Given the fact that I had only a couple of failures from tests on step
    6, I'm fairly confident about the coverage of this conversion patch.
    If there is a breakage, it's likely to be something in one of the arch
    headers which should be easily discoverable easily on most builds of
    the specific arch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Guess-its-ok-by: Christoph Lameter <cl@linux-foundation.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Lee Schermerhorn <Lee.Schermerhorn@hp.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index d92765cae10a..53f1648c8b81 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -15,11 +15,11 @@
 #include <linux/kallsyms.h>
 #include <linux/kernel.h>
 #include <linux/mm.h>
+#include <linux/slab.h>
 #include <linux/module.h>
 #include <linux/notifier.h>
 #include <linux/personality.h>
 #include <linux/sched.h>
-#include <linux/slab.h>
 #include <linux/stddef.h>
 #include <linux/thread_info.h>
 #include <linux/unistd.h>

commit 65c9bb6cca78a3677c66c6b279d5d77aa863bb32
Merge: 8d6339b8a532 e72aca30837d
Author: Tony Luck <tony.luck@intel.com>
Date:   Fri Feb 26 12:04:22 2010 -0800

    Pull alex into release branch

commit d868080d2a1c95526cb01e3d0c14096721cbb87a
Author: Alex Chiang <achiang@hp.com>
Date:   Thu Feb 25 14:09:52 2010 -0700

    [IA64] Only build arch/ia64/kernel/acpi.o when CONFIG_ACPI
    
    The following commit broke the ia64 sim_defconfig build:
            3b2b84c0b81108a9a869a88bf2beeb5a95d81dd1
            ACPI: processor: driver doesn't need to evaluate _PDC
    
    This is because it added:
            +#include <acpi/processor.h>
    
    To arch/ia64/kernel/acpi.c. Unfortunately, the ia64_simdefconfig does
    not turn on CONFIG_ACPI, and we get build errors.
    
    The fix described in $subject seems to be the most sensible way to
    untangle the mess.
    
    The other issue is that acpi_get_sysname() is required for all configs,
    most of which define CONFIG_ACPI, but are not CONFIG_IA64_GENERIC. Turn
    it into an inline to cover the "non generic" ia64 configs; to prevent
    a duplicate definition build error, we need to wrap the definition in
    acpi.o inside an #ifdef.
    
    Finally, move the pm_idle and pm_power_off exports into process.c (which
    is always built), similar to other architectures, and allow the sim
    defconfig to link.
    
    Signed-off-by: Alex Chiang <achiang@hp.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 9bcec9945c12..454a6a448f5a 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -60,6 +60,10 @@ unsigned long idle_halt;
 EXPORT_SYMBOL(idle_halt);
 unsigned long idle_nomwait;
 EXPORT_SYMBOL(idle_nomwait);
+void (*pm_idle) (void);
+EXPORT_SYMBOL(pm_idle);
+void (*pm_power_off) (void);
+EXPORT_SYMBOL(pm_power_off);
 
 void
 ia64_do_show_stack (struct unw_frame_info *info, void *arg)

commit 32974ad4907cdde6c9de612cd1b2ee0568fb9409
Author: Tony Luck <tony.luck@intel.com>
Date:   Mon Feb 8 10:42:17 2010 -0800

    [IA64] Remove COMPAT_IA32 support
    
    This has been broken since May 2008 when Al Viro killed altroot support.
    Since nobody has complained, it would appear that there are no users of
    this code (A plausible theory since the main OSVs that support ia64 prefer
    to use the IA32-EL software emulation).
    
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 9bcec9945c12..883ecc9cfef5 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -33,7 +33,6 @@
 #include <asm/cpu.h>
 #include <asm/delay.h>
 #include <asm/elf.h>
-#include <asm/ia32.h>
 #include <asm/irq.h>
 #include <asm/kexec.h>
 #include <asm/pgalloc.h>
@@ -358,11 +357,6 @@ ia64_save_extra (struct task_struct *task)
 	if (info & PFM_CPUINFO_SYST_WIDE)
 		pfm_syst_wide_update_task(task, info, 0);
 #endif
-
-#ifdef CONFIG_IA32_SUPPORT
-	if (IS_IA32_PROCESS(task_pt_regs(task)))
-		ia32_save_state(task);
-#endif
 }
 
 void
@@ -383,11 +377,6 @@ ia64_load_extra (struct task_struct *task)
 	if (info & PFM_CPUINFO_SYST_WIDE) 
 		pfm_syst_wide_update_task(task, info, 1);
 #endif
-
-#ifdef CONFIG_IA32_SUPPORT
-	if (IS_IA32_PROCESS(task_pt_regs(task)))
-		ia32_load_state(task);
-#endif
 }
 
 /*
@@ -426,7 +415,7 @@ copy_thread(unsigned long clone_flags,
 	     unsigned long user_stack_base, unsigned long user_stack_size,
 	     struct task_struct *p, struct pt_regs *regs)
 {
-	extern char ia64_ret_from_clone, ia32_ret_from_clone;
+	extern char ia64_ret_from_clone;
 	struct switch_stack *child_stack, *stack;
 	unsigned long rbs, child_rbs, rbs_size;
 	struct pt_regs *child_ptregs;
@@ -457,7 +446,7 @@ copy_thread(unsigned long clone_flags,
 	memcpy((void *) child_rbs, (void *) rbs, rbs_size);
 
 	if (likely(user_mode(child_ptregs))) {
-		if ((clone_flags & CLONE_SETTLS) && !IS_IA32_PROCESS(regs))
+		if (clone_flags & CLONE_SETTLS)
 			child_ptregs->r13 = regs->r16;	/* see sys_clone2() in entry.S */
 		if (user_stack_base) {
 			child_ptregs->r12 = user_stack_base + user_stack_size - 16;
@@ -477,10 +466,7 @@ copy_thread(unsigned long clone_flags,
 		child_ptregs->r13 = (unsigned long) p;		/* set `current' pointer */
 	}
 	child_stack->ar_bspstore = child_rbs + rbs_size;
-	if (IS_IA32_PROCESS(regs))
-		child_stack->b0 = (unsigned long) &ia32_ret_from_clone;
-	else
-		child_stack->b0 = (unsigned long) &ia64_ret_from_clone;
+	child_stack->b0 = (unsigned long) &ia64_ret_from_clone;
 
 	/* copy parts of thread_struct: */
 	p->thread.ksp = (unsigned long) child_stack - 16;
@@ -515,22 +501,6 @@ copy_thread(unsigned long clone_flags,
 	p->thread.flags = ((current->thread.flags & ~THREAD_FLAGS_TO_CLEAR)
 			   | THREAD_FLAGS_TO_SET);
 	ia64_drop_fpu(p);	/* don't pick up stale state from a CPU's fph */
-#ifdef CONFIG_IA32_SUPPORT
-	/*
-	 * If we're cloning an IA32 task then save the IA32 extra
-	 * state from the current task to the new task
-	 */
-	if (IS_IA32_PROCESS(task_pt_regs(current))) {
-		ia32_save_state(p);
-		if (clone_flags & CLONE_SETTLS)
-			retval = ia32_clone_tls(p, child_ptregs);
-
-		/* Copy partially mapped page list */
-		if (!retval)
-			retval = ia32_copy_ia64_partial_page_list(p,
-								clone_flags);
-	}
-#endif
 
 #ifdef CONFIG_PERFMON
 	if (current->thread.pfm_context)
@@ -704,15 +674,6 @@ EXPORT_SYMBOL(kernel_thread);
 int
 kernel_thread_helper (int (*fn)(void *), void *arg)
 {
-#ifdef CONFIG_IA32_SUPPORT
-	if (IS_IA32_PROCESS(task_pt_regs(current))) {
-		/* A kernel thread is always a 64-bit process. */
-		current->thread.map_base  = DEFAULT_MAP_BASE;
-		current->thread.task_size = DEFAULT_TASK_SIZE;
-		ia64_set_kr(IA64_KR_IO_BASE, current->thread.old_iob);
-		ia64_set_kr(IA64_KR_TSSD, current->thread.old_k1);
-	}
-#endif
 	return (*fn)(arg);
 }
 
@@ -725,14 +686,6 @@ flush_thread (void)
 	/* drop floating-point and debug-register state if it exists: */
 	current->thread.flags &= ~(IA64_THREAD_FPH_VALID | IA64_THREAD_DBG_VALID);
 	ia64_drop_fpu(current);
-#ifdef CONFIG_IA32_SUPPORT
-	if (IS_IA32_PROCESS(task_pt_regs(current))) {
-		ia32_drop_ia64_partial_page_list(current);
-		current->thread.task_size = IA32_PAGE_OFFSET;
-		set_fs(USER_DS);
-		memset(current->thread.tls_array, 0, sizeof(current->thread.tls_array));
-	}
-#endif
 }
 
 /*
@@ -753,8 +706,6 @@ exit_thread (void)
 	if (current->thread.flags & IA64_THREAD_DBG_VALID)
 		pfm_release_debug_registers(current);
 #endif
-	if (IS_IA32_PROCESS(task_pt_regs(current)))
-		ia32_drop_ia64_partial_page_list(current);
 }
 
 unsigned long

commit 353f6dd2dec992ddd34620a94b051b0f76227379
Author: Anirban Sinha <asinha@zeugmasystems.com>
Date:   Mon Sep 14 11:13:37 2009 -0700

    cleanup console_print()
    
    console_print() is an old legacy interface mostly unused in the entire
    kernel tree. It's best to clean up its existing use and let developers
    use their own implementation of it as they feel fit.
    
    Signed-off-by: Anirban Sinha <asinha@zeugmasystems.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 89969e950045..9bcec9945c12 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -161,6 +161,13 @@ show_regs (struct pt_regs *regs)
 		show_stack(NULL, NULL);
 }
 
+/* local support for deprecated console_print */
+void
+console_print(const char *s)
+{
+	printk(KERN_EMERG "%s", s);
+}
+
 void
 do_notify_resume_user(sigset_t *unused, struct sigscratch *scr, long in_syscall)
 {

commit ee18d64c1f632043a02e6f5ba5e045bb26a5465f
Author: David Howells <dhowells@redhat.com>
Date:   Wed Sep 2 09:14:21 2009 +0100

    KEYS: Add a keyctl to install a process's session keyring on its parent [try #6]
    
    Add a keyctl to install a process's session keyring onto its parent.  This
    replaces the parent's session keyring.  Because the COW credential code does
    not permit one process to change another process's credentials directly, the
    change is deferred until userspace next starts executing again.  Normally this
    will be after a wait*() syscall.
    
    To support this, three new security hooks have been provided:
    cred_alloc_blank() to allocate unset security creds, cred_transfer() to fill in
    the blank security creds and key_session_to_parent() - which asks the LSM if
    the process may replace its parent's session keyring.
    
    The replacement may only happen if the process has the same ownership details
    as its parent, and the process has LINK permission on the session keyring, and
    the session keyring is owned by the process, and the LSM permits it.
    
    Note that this requires alteration to each architecture's notify_resume path.
    This has been done for all arches barring blackfin, m68k* and xtensa, all of
    which need assembly alteration to support TIF_NOTIFY_RESUME.  This allows the
    replacement to be performed at the point the parent process resumes userspace
    execution.
    
    This allows the userspace AFS pioctl emulation to fully emulate newpag() and
    the VIOCSETTOK and VIOCSETTOK2 pioctls, all of which require the ability to
    alter the parent process's PAG membership.  However, since kAFS doesn't use
    PAGs per se, but rather dumps the keys into the session keyring, the session
    keyring of the parent must be replaced if, for example, VIOCSETTOK is passed
    the newpag flag.
    
    This can be tested with the following program:
    
            #include <stdio.h>
            #include <stdlib.h>
            #include <keyutils.h>
    
            #define KEYCTL_SESSION_TO_PARENT        18
    
            #define OSERROR(X, S) do { if ((long)(X) == -1) { perror(S); exit(1); } } while(0)
    
            int main(int argc, char **argv)
            {
                    key_serial_t keyring, key;
                    long ret;
    
                    keyring = keyctl_join_session_keyring(argv[1]);
                    OSERROR(keyring, "keyctl_join_session_keyring");
    
                    key = add_key("user", "a", "b", 1, keyring);
                    OSERROR(key, "add_key");
    
                    ret = keyctl(KEYCTL_SESSION_TO_PARENT);
                    OSERROR(ret, "KEYCTL_SESSION_TO_PARENT");
    
                    return 0;
            }
    
    Compiled and linked with -lkeyutils, you should see something like:
    
            [dhowells@andromeda ~]$ keyctl show
            Session Keyring
                   -3 --alswrv   4043  4043  keyring: _ses
            355907932 --alswrv   4043    -1   \_ keyring: _uid.4043
            [dhowells@andromeda ~]$ /tmp/newpag
            [dhowells@andromeda ~]$ keyctl show
            Session Keyring
                   -3 --alswrv   4043  4043  keyring: _ses
            1055658746 --alswrv   4043  4043   \_ user: a
            [dhowells@andromeda ~]$ /tmp/newpag hello
            [dhowells@andromeda ~]$ keyctl show
            Session Keyring
                   -3 --alswrv   4043  4043  keyring: hello
            340417692 --alswrv   4043  4043   \_ user: a
    
    Where the test program creates a new session keyring, sticks a user key named
    'a' into it and then installs it on its parent.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: James Morris <jmorris@namei.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 5d7c0e5b9e76..89969e950045 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -192,6 +192,8 @@ do_notify_resume_user(sigset_t *unused, struct sigscratch *scr, long in_syscall)
 	if (test_thread_flag(TIF_NOTIFY_RESUME)) {
 		clear_thread_flag(TIF_NOTIFY_RESUME);
 		tracehook_notify_resume(&scr->pt);
+		if (current->replacement_session_keyring)
+			key_replace_session_keyring();
 	}
 
 	/* copy user rbs to kernel rbs */

commit 6f2c55b843836d26528c56a0968689accaedbc67
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Thu Apr 2 16:56:59 2009 -0700

    Simplify copy_thread()
    
    First argument unused since 2.3.11.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Cc: <linux-arch@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index c57162705147..5d7c0e5b9e76 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -413,7 +413,7 @@ ia64_load_extra (struct task_struct *task)
  * so there is nothing to worry about.
  */
 int
-copy_thread (int nr, unsigned long clone_flags,
+copy_thread(unsigned long clone_flags,
 	     unsigned long user_stack_base, unsigned long user_stack_size,
 	     struct task_struct *p, struct pt_regs *regs)
 {

commit 22ca532a4d137545244fdff0b687325fd4e13eae
Merge: 9224652cc764 f8d1f99f3958
Author: Tony Luck <tony.luck@intel.com>
Date:   Fri Oct 17 13:51:28 2008 -0700

    Pull pv_ops-xen into release branch

commit 1b4a18fcfadcc51987682fc266bb88ed59d12935
Author: Isaku Yamahata <yamahata@valinux.co.jp>
Date:   Fri Oct 17 11:17:44 2008 +0900

    ia64: move function declaration, ia64_cpu_local_tick() from .c to .h
    
    eliminate the function declaration ia64_cpu_local_tick() in
    process.c by defining in arch/ia64/include/asm/timex.h
    The same function will be used in a different .c file later.
    
    Signed-off-by: Isaku Yamahata <yamahata@valinux.co.jp>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 3ab8373103ec..8de0f460c88d 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -251,7 +251,6 @@ default_idle (void)
 /* We don't actually take CPU down, just spin without interrupts. */
 static inline void play_dead(void)
 {
-	extern void ia64_cpu_local_tick (void);
 	unsigned int this_cpu = smp_processor_id();
 
 	/* Ack it */

commit f14488ccfe0f41207e40520fab60dce356ed9e57
Author: Shaohua Li <shaohua.li@intel.com>
Date:   Mon Oct 6 10:43:06 2008 -0700

    [IA64] utrace use generic trace hook
    
    Make IA64 use generic trace hook in some paths.
    
    Signed-off-by: Shaohua Li <shaohua.li@intel.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 3ab8373103ec..341a0319a5ba 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -28,6 +28,7 @@
 #include <linux/delay.h>
 #include <linux/kdebug.h>
 #include <linux/utsname.h>
+#include <linux/tracehook.h>
 
 #include <asm/cpu.h>
 #include <asm/delay.h>
@@ -160,21 +161,6 @@ show_regs (struct pt_regs *regs)
 		show_stack(NULL, NULL);
 }
 
-void tsk_clear_notify_resume(struct task_struct *tsk)
-{
-#ifdef CONFIG_PERFMON
-	if (tsk->thread.pfm_needs_checking)
-		return;
-#endif
-	if (test_ti_thread_flag(task_thread_info(tsk), TIF_RESTORE_RSE))
-		return;
-	clear_ti_thread_flag(task_thread_info(tsk), TIF_NOTIFY_RESUME);
-}
-
-/*
- * do_notify_resume_user():
- *	Called from notify_resume_user at entry.S, with interrupts disabled.
- */
 void
 do_notify_resume_user(sigset_t *unused, struct sigscratch *scr, long in_syscall)
 {
@@ -203,6 +189,11 @@ do_notify_resume_user(sigset_t *unused, struct sigscratch *scr, long in_syscall)
 		ia64_do_signal(scr, in_syscall);
 	}
 
+	if (test_thread_flag(TIF_NOTIFY_RESUME)) {
+		clear_thread_flag(TIF_NOTIFY_RESUME);
+		tracehook_notify_resume(&scr->pt);
+	}
+
 	/* copy user rbs to kernel rbs */
 	if (unlikely(test_thread_flag(TIF_RESTORE_RSE))) {
 		local_irq_enable();	/* force interrupt enable */

commit da5e09a1b3e5a9fc0b15a3feb64e921ccc55ba74
Author: Zhao Yakui <yakui.zhao@intel.com>
Date:   Tue Jun 24 18:01:09 2008 +0800

    ACPI : Create "idle=nomwait" bootparam
    
    "idle=nomwait" disables the use of the MWAIT
    instruction from both C1 (C1_FFH) and deeper (C2C3_FFH)
    C-states.
    
    When MWAIT is unavailable, the BIOS and OS generally
    negotiate to use the HALT instruction for C1,
    and use IO accesses for deeper C-states.
    
    This option is useful for power and performance
    comparisons, and also to work around BIOS bugs
    where broken MWAIT support is advertised.
    
    http://bugzilla.kernel.org/show_bug.cgi?id=10807
    http://bugzilla.kernel.org/show_bug.cgi?id=10914
    
    Signed-off-by: Zhao Yakui <yakui.zhao@intel.com>
    Signed-off-by: Li Shaohua <shaohua.li@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>
    Signed-off-by: Andi Kleen <ak@linux.intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 612b3c4a0603..3ab8373103ec 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -57,6 +57,8 @@ unsigned long boot_option_idle_override = 0;
 EXPORT_SYMBOL(boot_option_idle_override);
 unsigned long idle_halt;
 EXPORT_SYMBOL(idle_halt);
+unsigned long idle_nomwait;
+EXPORT_SYMBOL(idle_nomwait);
 
 void
 ia64_do_show_stack (struct unw_frame_info *info, void *arg)

commit c1e3b377ad48febba6f91b8ae42c44ee4d4ab45e
Author: Zhao Yakui <yakui.zhao@intel.com>
Date:   Tue Jun 24 17:58:53 2008 +0800

    ACPI: Create "idle=halt" bootparam
    
    "idle=halt" limits the idle loop to using
    the halt instruction.  No MWAIT, no IO accesses,
    no C-states deeper than C1.
    
    If something is broken in the idle code,
    "idle=halt" is a less severe workaround
    than "idle=poll" which disables all power savings.
    
    Signed-off-by: Zhao Yakui <yakui.zhao@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>
    Signed-off-by: Andi Kleen <ak@linux.intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index fabaf08d9a69..612b3c4a0603 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -55,6 +55,8 @@ void (*ia64_mark_idle)(int);
 
 unsigned long boot_option_idle_override = 0;
 EXPORT_SYMBOL(boot_option_idle_override);
+unsigned long idle_halt;
+EXPORT_SYMBOL(idle_halt);
 
 void
 ia64_do_show_stack (struct unw_frame_info *info, void *arg)

commit 8691e5a8f691cc2a4fda0651e8d307aaba0e7d68
Author: Jens Axboe <jens.axboe@oracle.com>
Date:   Fri Jun 6 11:18:06 2008 +0200

    smp_call_function: get rid of the unused nonatomic/retry argument
    
    It's never used and the comments refer to nonatomic and retry
    interchangably. So get rid of it.
    
    Acked-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Signed-off-by: Jens Axboe <jens.axboe@oracle.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index a3a34b4eb038..fabaf08d9a69 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -286,7 +286,7 @@ void cpu_idle_wait(void)
 {
 	smp_mb();
 	/* kick all the CPUs so that they exit out of pm_idle */
-	smp_call_function(do_nothing, NULL, 0, 1);
+	smp_call_function(do_nothing, NULL, 1);
 }
 EXPORT_SYMBOL_GPL(cpu_idle_wait);
 

commit 3633c7308005e8c1dab594f69ef904424f8b639a
Author: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
Date:   Fri May 9 15:26:35 2008 +0900

    [IA64] fix interrupt masking for pending works on kernel leave
    
    [Bug-fix for "[BUG?][2.6.25-mm1] sleeping during IRQ disabled"]
    
    This patch does:
     - enable interrupts before calling schedule() as same as others, ex. x86
     - enable interrupts during ia64_do_signal() and ia64_sync_krbs()
     - do_notify_resume_user() is still called with interrupts disabled, since
       we can take short path of fsys_mode if-statement quickly.
     - pfm_handle_work() is also called with interrupts disabled, since
       it can deal interrupt mask within itself.
     - fix/add some comments/notes
    
    Reported-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Signed-off-by: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 58dcfac5ea88..a3a34b4eb038 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -167,11 +167,18 @@ void tsk_clear_notify_resume(struct task_struct *tsk)
 	clear_ti_thread_flag(task_thread_info(tsk), TIF_NOTIFY_RESUME);
 }
 
+/*
+ * do_notify_resume_user():
+ *	Called from notify_resume_user at entry.S, with interrupts disabled.
+ */
 void
-do_notify_resume_user (sigset_t *unused, struct sigscratch *scr, long in_syscall)
+do_notify_resume_user(sigset_t *unused, struct sigscratch *scr, long in_syscall)
 {
 	if (fsys_mode(current, &scr->pt)) {
-		/* defer signal-handling etc. until we return to privilege-level 0.  */
+		/*
+		 * defer signal-handling etc. until we return to
+		 * privilege-level 0.
+		 */
 		if (!ia64_psr(&scr->pt)->lp)
 			ia64_psr(&scr->pt)->lp = 1;
 		return;
@@ -179,16 +186,26 @@ do_notify_resume_user (sigset_t *unused, struct sigscratch *scr, long in_syscall
 
 #ifdef CONFIG_PERFMON
 	if (current->thread.pfm_needs_checking)
+		/*
+		 * Note: pfm_handle_work() allow us to call it with interrupts
+		 * disabled, and may enable interrupts within the function.
+		 */
 		pfm_handle_work();
 #endif
 
 	/* deal with pending signal delivery */
-	if (test_thread_flag(TIF_SIGPENDING))
+	if (test_thread_flag(TIF_SIGPENDING)) {
+		local_irq_enable();	/* force interrupt enable */
 		ia64_do_signal(scr, in_syscall);
+	}
 
 	/* copy user rbs to kernel rbs */
-	if (unlikely(test_thread_flag(TIF_RESTORE_RSE)))
+	if (unlikely(test_thread_flag(TIF_RESTORE_RSE))) {
+		local_irq_enable();	/* force interrupt enable */
 		ia64_sync_krbs();
+	}
+
+	local_irq_disable();	/* force interrupt disable */
 }
 
 static int pal_halt        = 1;

commit 49eaeb4bc4c901c327ee259c7768be20fd020a30
Author: akpm@linux-foundation.org <akpm@linux-foundation.org>
Date:   Wed Apr 30 00:53:09 2008 -0700

    signals: ia64 renumber TIF_RESTORE_SIGMASK
    
    TIF_RESTORE_SIGMASK no longer needs to be in the _TIF_WORK_* masks.
    Those low bits are scarce.  Renumber TIF_RESTORE_SIGMASK to free one up.
    
    Signed-off-by: Roland McGrath <roland@redhat.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index a5ea817cbcbf..58dcfac5ea88 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -183,7 +183,7 @@ do_notify_resume_user (sigset_t *unused, struct sigscratch *scr, long in_syscall
 #endif
 
 	/* deal with pending signal delivery */
-	if (test_thread_flag(TIF_SIGPENDING)||test_thread_flag(TIF_RESTORE_SIGMASK))
+	if (test_thread_flag(TIF_SIGPENDING))
 		ia64_do_signal(scr, in_syscall);
 
 	/* copy user rbs to kernel rbs */

commit 6cb53d7a6f40858181facde0f52587731d2e621f
Author: Shaohua Li <shaohua.li@intel.com>
Date:   Thu Feb 28 16:09:38 2008 +0800

    [IA64] use CORE_DUMP_USE_REGSET
    
    After we have regset support, we can use CORE_DUMP_USE_REGSET.
    
    Signed-off-by: Shaohua Li <shaohua.li@intel.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 49937a383b23..a5ea817cbcbf 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -625,42 +625,12 @@ do_dump_fpu (struct unw_frame_info *info, void *arg)
 	do_dump_task_fpu(current, info, arg);
 }
 
-int
-dump_task_regs(struct task_struct *task, elf_gregset_t *regs)
-{
-	struct unw_frame_info tcore_info;
-
-	if (current == task) {
-		unw_init_running(do_copy_regs, regs);
-	} else {
-		memset(&tcore_info, 0, sizeof(tcore_info));
-		unw_init_from_blocked_task(&tcore_info, task);
-		do_copy_task_regs(task, &tcore_info, regs);
-	}
-	return 1;
-}
-
 void
 ia64_elf_core_copy_regs (struct pt_regs *pt, elf_gregset_t dst)
 {
 	unw_init_running(do_copy_regs, dst);
 }
 
-int
-dump_task_fpu (struct task_struct *task, elf_fpregset_t *dst)
-{
-	struct unw_frame_info tcore_info;
-
-	if (current == task) {
-		unw_init_running(do_dump_fpu, dst);
-	} else {
-		memset(&tcore_info, 0, sizeof(tcore_info));
-		unw_init_from_blocked_task(&tcore_info, task);
-		do_dump_task_fpu(task, &tcore_info, dst);
-	}
-	return 1;
-}
-
 int
 dump_fpu (struct pt_regs *pt, elf_fpregset_t dst)
 {

commit 427639354ff346710012b53e1ceed5e3f3200e0c
Author: Tony Luck <tony.luck@intel.com>
Date:   Fri Feb 8 11:53:09 2008 -0800

    [IA64] Simplify cpu_idle_wait
    
    This is just Venki's patch[*] for x86 ported to ia64.
    
    * http://marc.info/?l=linux-kernel&m=120249201318159&w=2
    
    Acked-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index be6c6f7be027..49937a383b23 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -52,7 +52,6 @@
 #include "sigframe.h"
 
 void (*ia64_mark_idle)(int);
-static DEFINE_PER_CPU(unsigned int, cpu_idle_state);
 
 unsigned long boot_option_idle_override = 0;
 EXPORT_SYMBOL(boot_option_idle_override);
@@ -254,33 +253,23 @@ static inline void play_dead(void)
 }
 #endif /* CONFIG_HOTPLUG_CPU */
 
-void cpu_idle_wait(void)
+static void do_nothing(void *unused)
 {
-	unsigned int cpu, this_cpu = get_cpu();
-	cpumask_t map;
-	cpumask_t tmp = current->cpus_allowed;
-
-	set_cpus_allowed(current, cpumask_of_cpu(this_cpu));
-	put_cpu();
-
-	cpus_clear(map);
-	for_each_online_cpu(cpu) {
-		per_cpu(cpu_idle_state, cpu) = 1;
-		cpu_set(cpu, map);
-	}
-
-	__get_cpu_var(cpu_idle_state) = 0;
+}
 
-	wmb();
-	do {
-		ssleep(1);
-		for_each_online_cpu(cpu) {
-			if (cpu_isset(cpu, map) && !per_cpu(cpu_idle_state, cpu))
-				cpu_clear(cpu, map);
-		}
-		cpus_and(map, map, cpu_online_map);
-	} while (!cpus_empty(map));
-	set_cpus_allowed(current, tmp);
+/*
+ * cpu_idle_wait - Used to ensure that all the CPUs discard old value of
+ * pm_idle and update to new pm_idle value. Required while changing pm_idle
+ * handler on SMP systems.
+ *
+ * Caller must have changed pm_idle to the new value before the call. Old
+ * pm_idle value will not be used by any CPU after the return of this function.
+ */
+void cpu_idle_wait(void)
+{
+	smp_mb();
+	/* kick all the CPUs so that they exit out of pm_idle */
+	smp_call_function(do_nothing, NULL, 0, 1);
 }
 EXPORT_SYMBOL_GPL(cpu_idle_wait);
 
@@ -308,9 +297,6 @@ cpu_idle (void)
 #ifdef CONFIG_SMP
 			min_xtp();
 #endif
-			if (__get_cpu_var(cpu_idle_state))
-				__get_cpu_var(cpu_idle_state) = 0;
-
 			rmb();
 			if (mark_idle)
 				(*mark_idle)(1);

commit 3b2ce0b17824c42bc2e46f7dd903b4acf5e9fff9
Author: Petr Tesarik <ptesarik@suse.cz>
Date:   Wed Dec 12 15:23:34 2007 +0100

    [IA64] Synchronize kernel RSE to user-space and back
    
    This is base kernel patch for ptrace RSE bug. It's basically a backport
    from the utrace RSE patch I sent out several weeks ago. please review.
    
    when a thread is stopped (ptraced), debugger might change thread's user
    stack (change memory directly), and we must avoid the RSE stored in
    kernel to override user stack (user space's RSE is newer than kernel's
    in the case). To workaround the issue, we copy kernel RSE to user RSE
    before the task is stopped, so user RSE has updated data.  we then copy
    user RSE to kernel after the task is resummed from traced stop and
    kernel will use the newer RSE to return to user.
    
    Signed-off-by: Shaohua Li <shaohua.li@intel.com>
    Signed-off-by: Petr Tesarik <ptesarik@suse.cz>
    CC: Roland McGrath <roland@redhat.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 5c9efe626563..be6c6f7be027 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -163,6 +163,8 @@ void tsk_clear_notify_resume(struct task_struct *tsk)
 	if (tsk->thread.pfm_needs_checking)
 		return;
 #endif
+	if (test_ti_thread_flag(task_thread_info(tsk), TIF_RESTORE_RSE))
+		return;
 	clear_ti_thread_flag(task_thread_info(tsk), TIF_NOTIFY_RESUME);
 }
 
@@ -184,6 +186,10 @@ do_notify_resume_user (sigset_t *unused, struct sigscratch *scr, long in_syscall
 	/* deal with pending signal delivery */
 	if (test_thread_flag(TIF_SIGPENDING)||test_thread_flag(TIF_RESTORE_SIGMASK))
 		ia64_do_signal(scr, in_syscall);
+
+	/* copy user rbs to kernel rbs */
+	if (unlikely(test_thread_flag(TIF_RESTORE_RSE)))
+		ia64_sync_krbs();
 }
 
 static int pal_halt        = 1;

commit 5aa92ffda1b6244b4a248df0b95c07d183ab96d2
Author: Petr Tesarik <ptesarik@suse.cz>
Date:   Wed Dec 12 15:21:16 2007 +0100

    [IA64] Rename TIF_PERFMON_WORK back to TIF_NOTIFY_RESUME
    
    Since the RSE synchronization will need a TIF_ flag, but all
    
    work-to-be-done bits are already used, so we have to multiplex
    TIF_NOTIFY_RESUME again.
    
    Signed-off-by: Shaohua Li <shaohua.li@intel.com>
    Signed-off-by: Petr Tesarik <ptesarik@suse.cz>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 7377d323131d..5c9efe626563 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -157,6 +157,15 @@ show_regs (struct pt_regs *regs)
 		show_stack(NULL, NULL);
 }
 
+void tsk_clear_notify_resume(struct task_struct *tsk)
+{
+#ifdef CONFIG_PERFMON
+	if (tsk->thread.pfm_needs_checking)
+		return;
+#endif
+	clear_ti_thread_flag(task_thread_info(tsk), TIF_NOTIFY_RESUME);
+}
+
 void
 do_notify_resume_user (sigset_t *unused, struct sigscratch *scr, long in_syscall)
 {

commit e384f41409cb9e543fbc84b375e2ba46cbcbec6a
Author: Ian Wienand <ianw@gelato.unsw.edu.au>
Date:   Tue Nov 20 14:12:46 2007 +1100

    [IA64] set_thread_area fails in IA32 chroot
    
    I tried to upgrade an IA32 chroot on my IA64 to a new glibc with TLS.
    It kept dying because set_thread_area was returning -ESRCH
    (bugs.debian.org/451939).
    
    I instrumented arch/ia64/ia32/sys_ia32.c:get_free_idx() and ended up
    seeing output like
    
    [pid] idx   desc->a  desc->b
    -----------------------------
    [2710] 0 -> c6b0ffff 40dff31b
    [2710] 1 -> 0 0
    [2710] 2 -> 0 0
    
    [2710] 0 -> c6b0ffff 40dff31b
    [2710] 1 -> c6b0ffff 40dff31b
    [2710] 2 -> 0 0
    
    [2711] 0 -> c6b0ffff 40dff31b
    [2711] 1 -> c6b0ffff 40dff31b
    [2711] 2 -> 48c0ffff 40dff317
    
    which suggested to me that TLS pointers were surviving exec() calls,
    leading to GDT pointers filling up and the eventual failure of
    get_free_idx().
    
    I think the solution is flushing the tls array on exec.
    
    Signed-Off-By: Ian Wienand <ianw@gelato.unsw.edu.au>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index a70ad185725c..7377d323131d 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -739,6 +739,7 @@ flush_thread (void)
 		ia32_drop_ia64_partial_page_list(current);
 		current->thread.task_size = IA32_PAGE_OFFSET;
 		set_fs(USER_DS);
+		memset(current->thread.tls_array, 0, sizeof(current->thread.tls_array));
 	}
 #endif
 }

commit ee211b37aa98123b1d9b19d228011e632a4bbe75
Author: Luck, Tony <tony.luck@intel.com>
Date:   Tue Dec 18 11:46:38 2007 -0800

    [IA64] print kernel release in OOPS to make kerneloops.org happy
    
    The ia64 oops message doesn't include the kernel version, which
    makes it hard to automatically categorize oops messages scraped
    from mailing lists and bug databases.
    
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 2418289ee5ca..a70ad185725c 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -27,6 +27,7 @@
 #include <linux/interrupt.h>
 #include <linux/delay.h>
 #include <linux/kdebug.h>
+#include <linux/utsname.h>
 
 #include <asm/cpu.h>
 #include <asm/delay.h>
@@ -107,8 +108,9 @@ show_regs (struct pt_regs *regs)
 	print_modules();
 	printk("\nPid: %d, CPU %d, comm: %20s\n", task_pid_nr(current),
 			smp_processor_id(), current->comm);
-	printk("psr : %016lx ifs : %016lx ip  : [<%016lx>]    %s\n",
-	       regs->cr_ipsr, regs->cr_ifs, ip, print_tainted());
+	printk("psr : %016lx ifs : %016lx ip  : [<%016lx>]    %s (%s)\n",
+	       regs->cr_ipsr, regs->cr_ifs, ip, print_tainted(),
+	       init_utsname()->release);
 	print_symbol("ip is at %s\n", ip);
 	printk("unat: %016lx pfs : %016lx rsc : %016lx\n",
 	       regs->ar_unat, regs->ar_pfs, regs->ar_rsc);

commit 19c5870c0eefd27c6d09d867465e0571262e05d0
Author: Alexey Dobriyan <adobriyan@openvz.org>
Date:   Thu Oct 18 23:40:41 2007 -0700

    Use helpers to obtain task pid in printks (arch code)
    
    One of the easiest things to isolate is the pid printed in kernel log.
    There was a patch, that made this for arch-independent code, this one makes
    so for arch/xxx files.
    
    It took some time to cross-compile it, but hopefully these are all the
    printks in arch code.
    
    Signed-off-by: Alexey Dobriyan <adobriyan@openvz.org>
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Cc: <linux-arch@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index c613fc0e91cc..2418289ee5ca 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -105,7 +105,8 @@ show_regs (struct pt_regs *regs)
 	unsigned long ip = regs->cr_iip + ia64_psr(regs)->ri;
 
 	print_modules();
-	printk("\nPid: %d, CPU %d, comm: %20s\n", current->pid, smp_processor_id(), current->comm);
+	printk("\nPid: %d, CPU %d, comm: %20s\n", task_pid_nr(current),
+			smp_processor_id(), current->comm);
 	printk("psr : %016lx ifs : %016lx ip  : [<%016lx>]    %s\n",
 	       regs->cr_ipsr, regs->cr_ifs, ip, print_tainted());
 	print_symbol("ip is at %s\n", ip);

commit 71416bea5afa9e5a6c76c1509ab69c46c857a2bb
Author: Dimitri Sivanich <sivanich@sgi.com>
Date:   Tue Aug 7 08:49:32 2007 -0500

    [IA64] disable irq's and check need_resched before safe_halt
    
    While sending interrupts to a cpu to repeatedly wake a thread, on occasion
    that thread will take a full timer tick cycle (4002 usec in my case)
    to wakeup.
    
    The problem concerns a race condition in the code around the safe_halt()
    call in the default_idle() routine.  Setting 'nohalt' on the kernel
    command line causes the long wakeups to disappear.
    
    void
    default_idle (void)
    {
            local_irq_enable();
            while (!need_resched()) {
    -->             if (can_do_pal_halt)
    -->                     safe_halt();
                    else
    
    A timer tick could arrive between the check for !need_resched and the
    actual call to safe_halt() (which does a pal call to PAL_HALT_LIGHT).
    By the time the timer tick completes, a thread that might now need to run
    could get held up for as long as a timer tick waiting for the halted cpu.
    
    I'm proposing that we disable irq's and check need_resched again before
    calling safe_halt().  Does anyone see any problem with this approach?
    
    Signed-off-by: Dimitri Sivanich <sivanich@sgi.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 4158906c45aa..c613fc0e91cc 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -198,9 +198,13 @@ default_idle (void)
 {
 	local_irq_enable();
 	while (!need_resched()) {
-		if (can_do_pal_halt)
-			safe_halt();
-		else
+		if (can_do_pal_halt) {
+			local_irq_disable();
+			if (!need_resched()) {
+				safe_halt();
+			}
+			local_irq_enable();
+		} else
 			cpu_relax();
 	}
 }

commit 3b74d18e54e20fc1d398eb391bea5b9aed22aca5
Author: akpm@linux-foundation.org <akpm@linux-foundation.org>
Date:   Tue Jul 24 19:44:55 2007 -0700

    [IA64] rename partial_page
    
    Jens has added a partial_page thing in splice whcih conflicts with the ia64
    one.  Rename ia64 out of the way.  (ia64 chose poorly).
    
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index fa40cba43350..4158906c45aa 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -499,7 +499,8 @@ copy_thread (int nr, unsigned long clone_flags,
 
 		/* Copy partially mapped page list */
 		if (!retval)
-			retval = ia32_copy_partial_page_list(p, clone_flags);
+			retval = ia32_copy_ia64_partial_page_list(p,
+								clone_flags);
 	}
 #endif
 
@@ -728,7 +729,7 @@ flush_thread (void)
 	ia64_drop_fpu(current);
 #ifdef CONFIG_IA32_SUPPORT
 	if (IS_IA32_PROCESS(task_pt_regs(current))) {
-		ia32_drop_partial_page_list(current);
+		ia32_drop_ia64_partial_page_list(current);
 		current->thread.task_size = IA32_PAGE_OFFSET;
 		set_fs(USER_DS);
 	}
@@ -754,7 +755,7 @@ exit_thread (void)
 		pfm_release_debug_registers(current);
 #endif
 	if (IS_IA32_PROCESS(task_pt_regs(current)))
-		ia32_drop_partial_page_list(current);
+		ia32_drop_ia64_partial_page_list(current);
 }
 
 unsigned long

commit 256a7e097ba3d1179867b4c9aba1b75fb32d44f2
Author: Jes Sorensen <jes@sgi.com>
Date:   Wed Jul 11 17:26:30 2007 +0200

    [IA64] silence GCC ia64 unused variable warnings
    
    Tell GCC to stop spewing out unnecessary warnings for unused variables
    passed to functions as pointers for ia64 files.
    
    Signed-off-by: Jes Sorensen <jes@sgi.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index af73b8dfde28..fa40cba43350 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -513,7 +513,8 @@ copy_thread (int nr, unsigned long clone_flags,
 static void
 do_copy_task_regs (struct task_struct *task, struct unw_frame_info *info, void *arg)
 {
-	unsigned long mask, sp, nat_bits = 0, ip, ar_rnat, urbs_end, cfm;
+	unsigned long mask, sp, nat_bits = 0, ar_rnat, urbs_end, cfm;
+	unsigned long uninitialized_var(ip);	/* GCC be quiet */
 	elf_greg_t *dst = arg;
 	struct pt_regs *pt;
 	char nat;

commit 6ae384884d936cb39ab20238af34689933e44525
Author: Robin Holt <holt@sgi.com>
Date:   Fri May 18 13:46:52 2007 -0500

    [IA64] Only unwind non-running tasks.
    
    Unwinding a running task has proven problematic.
    
    In one instance, the running task was attempting to unwind itself and
    received an interrupt between when get_wchan allocated local variables on
    the stack and when unw_init_from_blocked_task was called which resulted
    in unw_init_frame_info to place this tasks task_struct pointer over the
    switch stack's ar_bspstore entry.
    
    Signed-off-by: Robin Holt <holt@sgi.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index d1c3ed9943e5..af73b8dfde28 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -763,6 +763,9 @@ get_wchan (struct task_struct *p)
 	unsigned long ip;
 	int count = 0;
 
+	if (!p || p == current || p->state == TASK_RUNNING)
+		return 0;
+
 	/*
 	 * Note: p may not be a blocked task (it could be current or
 	 * another process running on some other CPU.  Rather than
@@ -773,6 +776,8 @@ get_wchan (struct task_struct *p)
 	 */
 	unw_init_from_blocked_task(&info, p);
 	do {
+		if (p->state == TASK_RUNNING)
+			return 0;
 		if (unw_unwind(&info) < 0)
 			return 0;
 		unw_get_ip(&info, &ip);

commit 38cb162b7585d837083b8365da1eb32687c5164c
Merge: ba7cc09c9c9e e180583b85f4
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Wed May 9 13:38:45 2007 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/aegl/linux-2.6
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/aegl/linux-2.6:
      [IA64] wire up pselect, ppoll
      [IA64] Add TIF_RESTORE_SIGMASK
      [IA64] unwind did not work for processes born with CLONE_STOPPED
      [IA64] Optional method to purge the TLB on SN systems
      [IA64] SPIN_LOCK_UNLOCKED macro cleanup in arch/ia64
      [IA64-SN2][KJ] mmtimer.c-kzalloc
      [IA64] fix stack alignment for ia32 signal handlers
      [IA64] - Altix: hotplug after intr redirect can crash system
      [IA64] save and restore cpus_allowed in cpu_idle_wait
      [IA64] Removal of percpu TR cleanup in kexec code
      [IA64] Fix some section mismatch errors

commit 4a177cbf84f827cf9f1d6cfa5264fafd3cc33ce0
Author: Alexey Dobriyan <adobriyan@openvz.org>
Date:   Tue Jan 23 19:03:17 2007 +0300

    [IA64] Add TIF_RESTORE_SIGMASK
    
    Preparation for pselect and ppoll.
    ia32 compat code not tested. :-(
    
    Signed-off-by: Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>
    Signed-off-by: Alexey Dobriyan <adobriyan@openvz.org>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index cba6ac398736..d7b7d3da1ebb 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -156,7 +156,7 @@ show_regs (struct pt_regs *regs)
 }
 
 void
-do_notify_resume_user (sigset_t *oldset, struct sigscratch *scr, long in_syscall)
+do_notify_resume_user (sigset_t *unused, struct sigscratch *scr, long in_syscall)
 {
 	if (fsys_mode(current, &scr->pt)) {
 		/* defer signal-handling etc. until we return to privilege-level 0.  */
@@ -171,8 +171,8 @@ do_notify_resume_user (sigset_t *oldset, struct sigscratch *scr, long in_syscall
 #endif
 
 	/* deal with pending signal delivery */
-	if (test_thread_flag(TIF_SIGPENDING))
-		ia64_do_signal(oldset, scr, in_syscall);
+	if (test_thread_flag(TIF_SIGPENDING)||test_thread_flag(TIF_RESTORE_SIGMASK))
+		ia64_do_signal(scr, in_syscall);
 }
 
 static int pal_halt        = 1;

commit e63340ae6b6205fef26b40a75673d1c9c0c8bb90
Author: Randy Dunlap <randy.dunlap@oracle.com>
Date:   Tue May 8 00:28:08 2007 -0700

    header cleaning: don't include smp_lock.h when not used
    
    Remove includes of <linux/smp_lock.h> where it is not used/needed.
    Suggested by Al Viro.
    
    Builds cleanly on x86_64, i386, alpha, ia64, powerpc, sparc,
    sparc64, and arm (all 59 defconfigs).
    
    Signed-off-by: Randy Dunlap <randy.dunlap@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 7ab36c772e21..8bb571a8a738 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -20,7 +20,6 @@
 #include <linux/personality.h>
 #include <linux/sched.h>
 #include <linux/slab.h>
-#include <linux/smp_lock.h>
 #include <linux/stddef.h>
 #include <linux/thread_info.h>
 #include <linux/unistd.h>

commit 1eeb66a1bb973534dc3d064920a5ca683823372e
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue May 8 00:27:03 2007 -0700

    move die notifier handling to common code
    
    This patch moves the die notifier handling to common code.  Previous
    various architectures had exactly the same code for it.  Note that the new
    code is compiled unconditionally, this should be understood as an appel to
    the other architecture maintainer to implement support for it aswell (aka
    sprinkling a notify_die or two in the proper place)
    
    arm had a notifiy_die that did something totally different, I renamed it to
    arm_notify_die as part of the patch and made it static to the file it's
    declared and used at.  avr32 used to pass slightly less information through
    this interface and I brought it into line with the other architectures.
    
    [akpm@linux-foundation.org: build fix]
    [akpm@linux-foundation.org: fix vmalloc_sync_all bustage]
    [bryan.wu@analog.com: fix vmalloc_sync_all in nommu]
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Cc: <linux-arch@vger.kernel.org>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Bryan Wu <bryan.wu@analog.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index ae96d4176995..7ab36c772e21 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -27,13 +27,13 @@
 #include <linux/efi.h>
 #include <linux/interrupt.h>
 #include <linux/delay.h>
+#include <linux/kdebug.h>
 
 #include <asm/cpu.h>
 #include <asm/delay.h>
 #include <asm/elf.h>
 #include <asm/ia32.h>
 #include <asm/irq.h>
-#include <asm/kdebug.h>
 #include <asm/kexec.h>
 #include <asm/pgalloc.h>
 #include <asm/processor.h>

commit bb8416bf8b93d88e23cbbfde962ef85acda5bd5f
Author: Siddha, Suresh B <suresh.b.siddha@intel.com>
Date:   Tue May 8 09:22:47 2007 -0700

    [IA64] save and restore cpus_allowed in cpu_idle_wait
    
    Save and Restore the task's cpus_allowed mask, across the set_cpus_allowed()
    in cpu_idle_wait(). Without this, we will endup corrupting task's cpu affinity.
    
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index ae96d4176995..cba6ac398736 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -237,6 +237,7 @@ void cpu_idle_wait(void)
 {
 	unsigned int cpu, this_cpu = get_cpu();
 	cpumask_t map;
+	cpumask_t tmp = current->cpus_allowed;
 
 	set_cpus_allowed(current, cpumask_of_cpu(this_cpu));
 	put_cpu();
@@ -258,6 +259,7 @@ void cpu_idle_wait(void)
 		}
 		cpus_and(map, map, cpu_online_map);
 	} while (!cpus_empty(map));
+	set_cpus_allowed(current, tmp);
 }
 EXPORT_SYMBOL_GPL(cpu_idle_wait);
 

commit c237508afa5d47282d3047784864013eebdc68ab
Author: Horms <horms@verge.net.au>
Date:   Mon Feb 5 13:49:10 2007 -0800

    [IA64] kexec: Move machine_shutdown from machine_kexec.c to process.c
    
    This moves the ia64 implementation of machine_shutdown() from
    machine_kexec.c to process.c, which is in keeping with the implelmentation
    on other architectures, and seems like a much more appropriate home for it.
    
    Signed-off-by: Simon Horman <horms@verge.net.au>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 17685abaf496..ae96d4176995 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -34,6 +34,7 @@
 #include <asm/ia32.h>
 #include <asm/irq.h>
 #include <asm/kdebug.h>
+#include <asm/kexec.h>
 #include <asm/pgalloc.h>
 #include <asm/processor.h>
 #include <asm/sal.h>
@@ -803,6 +804,21 @@ cpu_halt (void)
 		ia64_pal_halt(min_power_state);
 }
 
+void machine_shutdown(void)
+{
+#ifdef CONFIG_HOTPLUG_CPU
+	int cpu;
+
+	for_each_online_cpu(cpu) {
+		if (cpu != smp_processor_id())
+			cpu_down(cpu);
+	}
+#endif
+#ifdef CONFIG_KEXEC
+	kexec_disable_iosapic();
+#endif
+}
+
 void
 machine_restart (char *restart_cmd)
 {

commit 0888f06ac99f993df2bb4c479f5b9306dafe154f
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Dec 22 01:11:56 2006 -0800

    [PATCH] sched: fix bad missed wakeups in the i386, x86_64, ia64, ACPI and APM idle code
    
    Fernando Lopez-Lezcano reported frequent scheduling latencies and audio
    xruns starting at the 2.6.18-rt kernel, and those problems persisted all
    until current -rt kernels. The latencies were serious and unjustified by
    system load, often in the milliseconds range.
    
    After a patient and heroic multi-month effort of Fernando, where he
    tested dozens of kernels, tried various configs, boot options,
    test-patches of mine and provided latency traces of those incidents, the
    following 'smoking gun' trace was captured by him:
    
                     _------=> CPU#
                    / _-----=> irqs-off
                   | / _----=> need-resched
                   || / _---=> hardirq/softirq
                   ||| / _--=> preempt-depth
                   |||| /
                   |||||     delay
       cmd     pid ||||| time  |   caller
          \   /    |||||   \   |   /
      IRQ_19-1479  1D..1    0us : __trace_start_sched_wakeup (try_to_wake_up)
      IRQ_19-1479  1D..1    0us : __trace_start_sched_wakeup <<...>-5856> (37 0)
      IRQ_19-1479  1D..1    0us : __trace_start_sched_wakeup (c01262ba 0 0)
      IRQ_19-1479  1D..1    0us : resched_task (try_to_wake_up)
      IRQ_19-1479  1D..1    0us : __spin_unlock_irqrestore (try_to_wake_up)
      ...
      <idle>-0     1...1   11us!: default_idle (cpu_idle)
      ...
      <idle>-0     0Dn.1  602us : smp_apic_timer_interrupt (c0103baf 1 0)
      ...
       <...>-5856  0D..2  618us : __switch_to (__schedule)
       <...>-5856  0D..2  618us : __schedule <<idle>-0> (20 162)
       <...>-5856  0D..2  619us : __spin_unlock_irq (__schedule)
       <...>-5856  0...1  619us : trace_stop_sched_switched (__schedule)
       <...>-5856  0D..1  619us : trace_stop_sched_switched <<...>-5856> (37 0)
    
    what is visible in this trace is that CPU#1 ran try_to_wake_up() for
    PID:5856, it placed PID:5856 on CPU#0's runqueue and ran resched_task()
    for CPU#0. But it decided to not send an IPI that no CPU - due to
    TS_POLLING. But CPU#0 never woke up after its NEED_RESCHED bit was set,
    and only rescheduled to PID:5856 upon the next lapic timer IRQ. The
    result was a 600+ usecs latency and a missed wakeup!
    
    the bug turned out to be an idle-wakeup bug introduced into the mainline
    kernel this summer via an optimization in the x86_64 tree:
    
        commit 495ab9c045e1b0e5c82951b762257fe1c9d81564
        Author: Andi Kleen <ak@suse.de>
        Date:   Mon Jun 26 13:59:11 2006 +0200
    
        [PATCH] i386/x86-64/ia64: Move polling flag into thread_info_status
    
        During some profiling I noticed that default_idle causes a lot of
        memory traffic. I think that is caused by the atomic operations
        to clear/set the polling flag in thread_info. There is actually
        no reason to make this atomic - only the idle thread does it
        to itself, other CPUs only read it. So I moved it into ti->status.
    
    the problem is this type of change:
    
            if (!hlt_counter && boot_cpu_data.hlt_works_ok) {
    -               clear_thread_flag(TIF_POLLING_NRFLAG);
    +               current_thread_info()->status &= ~TS_POLLING;
                    smp_mb__after_clear_bit();
                    while (!need_resched()) {
                            local_irq_disable();
    
    this changes clear_thread_flag() to an explicit clearing of TS_POLLING.
    clear_thread_flag() is defined as:
    
            clear_bit(flag, &ti->flags);
    
    and clear_bit() is a LOCK-ed atomic instruction on all x86 platforms:
    
      static inline void clear_bit(int nr, volatile unsigned long * addr)
      {
              __asm__ __volatile__( LOCK_PREFIX
                      "btrl %1,%0"
    
    hence smp_mb__after_clear_bit() is defined as a simple compile barrier:
    
      #define smp_mb__after_clear_bit()       barrier()
    
    but the explicit TS_POLLING clearing introduced by the patch:
    
    +               current_thread_info()->status &= ~TS_POLLING;
    
    is not an atomic op! So the clearing of the TS_POLLING bit is freely
    reorderable with the reading of the NEED_RESCHED bit - and both now
    reside in different memory addresses.
    
    CPU idle wakeup very much depends on ordered memory ops, the clearing of
    the TS_POLLING flag must always be done before we test need_resched()
    and hit the idle instruction(s). [Symmetrically, the wakeup code needs
    to set NEED_RESCHED before it tests the TS_POLLING flag, so memory
    ordering is paramount.]
    
    Fernando's dual-core Athlon64 system has a sufficiently advanced memory
    ordering model so that it triggered this scenario very often.
    
    ( And it also turned out that the reason why these latencies never
      triggered on my testsystems is that i routinely use idle=poll, which
      was the only idle variant not affected by this bug. )
    
    The fix is to change the smp_mb__after_clear_bit() to an smp_mb(), to
    act as an absolute barrier between the TS_POLLING write and the
    NEED_RESCHED read. This affects almost all idling methods (default,
    ACPI, APM), on all 3 x86 architectures: i386, x86_64, ia64.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Tested-by: Fernando Lopez-Lezcano <nando@ccrma.Stanford.EDU>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 51922b98086a..17685abaf496 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -268,10 +268,16 @@ cpu_idle (void)
 
 	/* endless idle loop with no priority at all */
 	while (1) {
-		if (can_do_pal_halt)
+		if (can_do_pal_halt) {
 			current_thread_info()->status &= ~TS_POLLING;
-		else
+			/*
+			 * TS_POLLING-cleared state must be visible before we
+			 * test NEED_RESCHED:
+			 */
+			smp_mb();
+		} else {
 			current_thread_info()->status |= TS_POLLING;
+		}
 
 		if (!need_resched()) {
 			void (*idle)(void);

commit 135ab6ec8fdad6f61aabe53f456821baf4a4aa0e
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon Oct 2 02:18:44 2006 -0700

    [PATCH] remove remaining errno and __KERNEL_SYSCALLS__ references
    
    The last in-kernel user of errno is gone, so we should remove the definition
    and everything referring to it.  This also removes the now-unused lib/execve.c
    file that was introduced earlier.
    
    Also remove every trace of __KERNEL_SYSCALLS__ that still remained in the
    kernel.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Cc: Andi Kleen <ak@muc.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Ian Molton <spyro@f2s.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Hirokazu Takata <takata.hirokazu@renesas.com>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Kyle McMartin <kyle@mcmartin.ca>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Kazumoto Kojima <kkojima@rr.iij4u.or.jp>
    Cc: Richard Curnow <rc@rc0.org.uk>
    Cc: William Lee Irwin III <wli@holomorphy.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Paolo 'Blaisorblade' Giarrusso <blaisorblade@yahoo.it>
    Cc: Miles Bader <uclinux-v850@lsi.nec.co.jp>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "Luck, Tony" <tony.luck@intel.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index ea914cc6812a..51922b98086a 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -8,8 +8,6 @@
  * 2005-10-07 Keith Owens <kaos@sgi.com>
  *	      Add notify_die() hooks.
  */
-#define __KERNEL_SYSCALLS__	/* see <asm/unistd.h> */
-
 #include <linux/cpu.h>
 #include <linux/pm.h>
 #include <linux/elf.h>

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: Jörn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: Jörn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index b045c279136c..ea914cc6812a 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -9,7 +9,6 @@
  *	      Add notify_die() hooks.
  */
 #define __KERNEL_SYSCALLS__	/* see <asm/unistd.h> */
-#include <linux/config.h>
 
 #include <linux/cpu.h>
 #include <linux/pm.h>

commit 495ab9c045e1b0e5c82951b762257fe1c9d81564
Author: Andi Kleen <ak@suse.de>
Date:   Mon Jun 26 13:59:11 2006 +0200

    [PATCH] i386/x86-64/ia64: Move polling flag into thread_info_status
    
    During some profiling I noticed that default_idle causes a lot of
    memory traffic. I think that is caused by the atomic operations
    to clear/set the polling flag in thread_info. There is actually
    no reason to make this atomic - only the idle thread does it
    to itself, other CPUs only read it. So I moved it into ti->status.
    
    Converted i386/x86-64/ia64 for now because that was the easiest
    way to fix ACPI which also manipulates these flags in its idle
    function.
    
    Cc: Nick Piggin <npiggin@novell.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Len Brown <len.brown@intel.com>
    Signed-off-by: Andi Kleen <ak@suse.de>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 355d57970ba3..b045c279136c 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -272,9 +272,9 @@ cpu_idle (void)
 	/* endless idle loop with no priority at all */
 	while (1) {
 		if (can_do_pal_halt)
-			clear_thread_flag(TIF_POLLING_NRFLAG);
+			current_thread_info()->status &= ~TS_POLLING;
 		else
-			set_thread_flag(TIF_POLLING_NRFLAG);
+			current_thread_info()->status |= TS_POLLING;
 
 		if (!need_resched()) {
 			void (*idle)(void);

commit c6fd91f0bdcd294a0ae0ba2b2a7f7456ef4b7144
Author: bibo mao <bibo_mao@linux.intel.com>
Date:   Sun Mar 26 01:38:20 2006 -0800

    [PATCH] kretprobe instance recycled by parent process
    
    When kretprobe probes the schedule() function, if the probed process exits
    then schedule() will never return, so some kretprobe instances will never
    be recycled.
    
    In this patch the parent process will recycle retprobe instances of the
    probed function and there will be no memory leak of kretprobe instances.
    
    Signed-off-by: bibo mao <bibo.mao@intel.com>
    Cc: Masami Hiramatsu <hiramatu@sdl.hitachi.co.jp>
    Cc: Prasanna S Panchamukhi <prasanna@in.ibm.com>
    Cc: Ananth N Mavinakayanahalli <ananth@in.ibm.com>
    Cc: Anil S Keshavamurthy <anil.s.keshavamurthy@intel.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 309d59658e5f..355d57970ba3 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -30,7 +30,6 @@
 #include <linux/efi.h>
 #include <linux/interrupt.h>
 #include <linux/delay.h>
-#include <linux/kprobes.h>
 
 #include <asm/cpu.h>
 #include <asm/delay.h>
@@ -738,13 +737,6 @@ void
 exit_thread (void)
 {
 
-	/*
-	 * Remove function-return probe instances associated with this task
-	 * and put them back on the free list. Do not insert an exit probe for
-	 * this function, it will be disabled by kprobe_flush_task if you do.
-	 */
-	kprobe_flush_task(current);
-
 	ia64_drop_fpu(current);
 #ifdef CONFIG_PERFMON
        /* if needed, stop monitoring and flush state to perfmon context */

commit 6450578f32cdca587ae5f148e2118b2fcc36bb11
Author: Al Viro <viro@ftp.linux.org.uk>
Date:   Thu Jan 12 01:06:06 2006 -0800

    [PATCH] ia64: task_pt_regs()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index e9904c74d2ba..309d59658e5f 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -328,7 +328,7 @@ ia64_save_extra (struct task_struct *task)
 #endif
 
 #ifdef CONFIG_IA32_SUPPORT
-	if (IS_IA32_PROCESS(ia64_task_regs(task)))
+	if (IS_IA32_PROCESS(task_pt_regs(task)))
 		ia32_save_state(task);
 #endif
 }
@@ -353,7 +353,7 @@ ia64_load_extra (struct task_struct *task)
 #endif
 
 #ifdef CONFIG_IA32_SUPPORT
-	if (IS_IA32_PROCESS(ia64_task_regs(task)))
+	if (IS_IA32_PROCESS(task_pt_regs(task)))
 		ia32_load_state(task);
 #endif
 }
@@ -488,7 +488,7 @@ copy_thread (int nr, unsigned long clone_flags,
 	 * If we're cloning an IA32 task then save the IA32 extra
 	 * state from the current task to the new task
 	 */
-	if (IS_IA32_PROCESS(ia64_task_regs(current))) {
+	if (IS_IA32_PROCESS(task_pt_regs(current))) {
 		ia32_save_state(p);
 		if (clone_flags & CLONE_SETTLS)
 			retval = ia32_clone_tls(p, child_ptregs);
@@ -701,7 +701,7 @@ int
 kernel_thread_helper (int (*fn)(void *), void *arg)
 {
 #ifdef CONFIG_IA32_SUPPORT
-	if (IS_IA32_PROCESS(ia64_task_regs(current))) {
+	if (IS_IA32_PROCESS(task_pt_regs(current))) {
 		/* A kernel thread is always a 64-bit process. */
 		current->thread.map_base  = DEFAULT_MAP_BASE;
 		current->thread.task_size = DEFAULT_TASK_SIZE;
@@ -722,7 +722,7 @@ flush_thread (void)
 	current->thread.flags &= ~(IA64_THREAD_FPH_VALID | IA64_THREAD_DBG_VALID);
 	ia64_drop_fpu(current);
 #ifdef CONFIG_IA32_SUPPORT
-	if (IS_IA32_PROCESS(ia64_task_regs(current))) {
+	if (IS_IA32_PROCESS(task_pt_regs(current))) {
 		ia32_drop_partial_page_list(current);
 		current->thread.task_size = IA32_PAGE_OFFSET;
 		set_fs(USER_DS);
@@ -755,7 +755,7 @@ exit_thread (void)
 	if (current->thread.flags & IA64_THREAD_DBG_VALID)
 		pfm_release_debug_registers(current);
 #endif
-	if (IS_IA32_PROCESS(ia64_task_regs(current)))
+	if (IS_IA32_PROCESS(task_pt_regs(current)))
 		ia32_drop_partial_page_list(current);
 }
 

commit 27af4cfd11883073359bd5acab1962b0fa96a3bf
Author: Robin Holt <holt@sgi.com>
Date:   Wed Dec 14 06:58:05 2005 -0600

    [IA64] fix for SET_PERSONALITY when CONFIG_IA32_SUPPORT is not set.
    
    Missed this when fixing the SET_PERSONALITY change.
    
    Signed-off-by: Robin Holt <holt@sgi.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index a4da715a360c..e9904c74d2ba 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -721,11 +721,13 @@ flush_thread (void)
 	/* drop floating-point and debug-register state if it exists: */
 	current->thread.flags &= ~(IA64_THREAD_FPH_VALID | IA64_THREAD_DBG_VALID);
 	ia64_drop_fpu(current);
+#ifdef CONFIG_IA32_SUPPORT
 	if (IS_IA32_PROCESS(ia64_task_regs(current))) {
 		ia32_drop_partial_page_list(current);
 		current->thread.task_size = IA32_PAGE_OFFSET;
 		set_fs(USER_DS);
 	}
+#endif
 }
 
 /*

commit bd1d6e2451f2bb0132416fda4d129c4f57a827bc
Author: Robin Holt <holt@sgi.com>
Date:   Mon Dec 5 20:02:31 2005 -0600

    [IA64] Change SET_PERSONALITY to comply with comment in binfmt_elf.c.
    
    We have a customer application which trips a bug.  The problem arises
    when a driver attempts to call do_munmap on an area which is mapped, but
    because current->thread.task_size has been set to 0xC0000000, the call
    to do_munmap fails thinking it is an unmap beyond the user's address
    space.
    
    The comment in fs/binfmt_elf.c in load_elf_library() before the call
    to SET_PERSONALITY() indicates that task_size must not be changed for
    the running application until flush_thread, but is for ia64 executing
    ia32 binaries.
    
    This patch moves the setting of task_size from SET_PERSONALITY() to
    flush_thread() as indicated.  The customer application no longer is able
    to trip the bug.
    
    Signed-off-by: Robin Holt <holt@sgi.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 2e33665d9c18..a4da715a360c 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -721,8 +721,11 @@ flush_thread (void)
 	/* drop floating-point and debug-register state if it exists: */
 	current->thread.flags &= ~(IA64_THREAD_FPH_VALID | IA64_THREAD_DBG_VALID);
 	ia64_drop_fpu(current);
-	if (IS_IA32_PROCESS(ia64_task_regs(current)))
+	if (IS_IA32_PROCESS(ia64_task_regs(current))) {
 		ia32_drop_partial_page_list(current);
+		current->thread.task_size = IA32_PAGE_OFFSET;
+		set_fs(USER_DS);
+	}
 }
 
 /*

commit 8bf1101bd52573e0573e374d56d2feecdbb5e444
Author: Jim Keniston <jkenisto@us.ibm.com>
Date:   Wed Nov 23 13:37:42 2005 -0800

    [PATCH] kprobes: Fix return probes on sys_execve
    
    Fix a bug in kprobes that can cause an Oops or even a crash when a return
    probe is installed on one of the following functions: sys_execve,
    do_execve, load_*_binary, flush_old_exec, or flush_thread.  The fix is to
    remove the call to kprobe_flush_task() in flush_thread().  This fix has
    been tested on all architectures for which the return-probes feature has
    been implemented (i386, x86_64, ppc64, ia64).  Please apply.
    
    BACKGROUND
    
    Up to now, we have called kprobe_flush_task() under two situations: when a
    task exits, and when it execs.  Flushing kretprobe_instances on exit is
    correct because (a) do_exit() doesn't return, and (b) one or more
    return-probed functions may be active when a task calls do_exit().  Neither
    is the case for sys_execve() and its callees.
    
    Initially, the mistaken call to kprobe_flush_task() on exec was harmless
    because we put the "real" return address of each active probed function
    back in the stack, just to be safe, when we recycled its
    kretprobe_instance.  When support for ppc64 and ia64 was added, this safety
    measure couldn't be employed, and was eventually dropped even for i386 and
    x86_64.  sys_execve() and its callees were informally blacklisted for
    return probes until this fix was developed.
    
    Acked-by: Prasanna S Panchamukhi <prasanna@in.ibm.com>
    Signed-off-by: Jim Keniston <jkenisto@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 4305d2ba76f6..2e33665d9c18 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -718,13 +718,6 @@ kernel_thread_helper (int (*fn)(void *), void *arg)
 void
 flush_thread (void)
 {
-	/*
-	 * Remove function-return probe instances associated with this task
-	 * and put them back on the free list. Do not insert an exit probe for
-	 * this function, it will be disabled by kprobe_flush_task if you do.
-	 */
-	kprobe_flush_task(current);
-
 	/* drop floating-point and debug-register state if it exists: */
 	current->thread.flags &= ~(IA64_THREAD_FPH_VALID | IA64_THREAD_DBG_VALID);
 	ia64_drop_fpu(current);

commit 1e185b97b4364063f1135604b87f8d8469944233
Author: Chen, Kenneth W <kenneth.w.chen@intel.com>
Date:   Tue Nov 15 14:37:05 2005 -0800

    [PATCH] ia64: cpu_idle performance bug fix
    
    Our performance validation on 2.6.15-rc1 caught a disastrous performance
    regression on ia64 with netperf (-98%) and volanomark (-58%) compares to
    previous kernel version 2.6.14-git7.  See the following chart (result
    group 1 & 2).
    
      http://kernel-perf.sourceforge.net/results.machine_id=26.html
    
    We have root caused it to commit 64c7c8f88559624abdbe12b5da6502e8879f8d28
    
    This changeset broke the ia64 task resched notification.  In
    sched.c:resched_task(), a reschedule IPI is conditioned upon
    TIF_POLLING_NRFLAG.  However, the above changeset unconditionally set
    the polling thread flag for idle tasks regardless whether pal_halt_light
    is in use or not.  As a result, resched IPI is not sent from
    resched_task().  And since the default behavior on ia64 is to use
    pal_halt_light, we end up delaying the rescheduling task until next
    timer tick, and thus cause the performance regression.
    
    This fixes the performance bug.  I'm glad our performance suite is
    turning up bad performance bug like this in time.
    
    Signed-off-by: Ken Chen <kenneth.w.chen@intel.com>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index e92ea64d8040..4305d2ba76f6 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -202,12 +202,9 @@ default_idle (void)
 {
 	local_irq_enable();
 	while (!need_resched()) {
-		if (can_do_pal_halt) {
-			local_irq_disable();
-			if (!need_resched())
-				safe_halt();
-			local_irq_enable();
-		} else
+		if (can_do_pal_halt)
+			safe_halt();
+		else
 			cpu_relax();
 	}
 }
@@ -272,10 +269,14 @@ cpu_idle (void)
 {
 	void (*mark_idle)(int) = ia64_mark_idle;
   	int cpu = smp_processor_id();
-	set_thread_flag(TIF_POLLING_NRFLAG);
 
 	/* endless idle loop with no priority at all */
 	while (1) {
+		if (can_do_pal_halt)
+			clear_thread_flag(TIF_POLLING_NRFLAG);
+		else
+			set_thread_flag(TIF_POLLING_NRFLAG);
+
 		if (!need_resched()) {
 			void (*idle)(void);
 #ifdef CONFIG_SMP

commit cb8a55e4cda017ed37a3ee051365f33a86956312
Merge: 4ddccb8eb9d1 9138d581b0ef
Author: Tony Luck <tony.luck@intel.com>
Date:   Thu Nov 10 10:39:09 2005 -0800

    Pull extend-notify-die into release branch

commit 64c7c8f88559624abdbe12b5da6502e8879f8d28
Author: Nick Piggin <nickpiggin@yahoo.com.au>
Date:   Tue Nov 8 21:39:04 2005 -0800

    [PATCH] sched: resched and cpu_idle rework
    
    Make some changes to the NEED_RESCHED and POLLING_NRFLAG to reduce
    confusion, and make their semantics rigid.  Improves efficiency of
    resched_task and some cpu_idle routines.
    
    * In resched_task:
    - TIF_NEED_RESCHED is only cleared with the task's runqueue lock held,
      and as we hold it during resched_task, then there is no need for an
      atomic test and set there. The only other time this should be set is
      when the task's quantum expires, in the timer interrupt - this is
      protected against because the rq lock is irq-safe.
    
    - If TIF_NEED_RESCHED is set, then we don't need to do anything. It
      won't get unset until the task get's schedule()d off.
    
    - If we are running on the same CPU as the task we resched, then set
      TIF_NEED_RESCHED and no further action is required.
    
    - If we are running on another CPU, and TIF_POLLING_NRFLAG is *not* set
      after TIF_NEED_RESCHED has been set, then we need to send an IPI.
    
    Using these rules, we are able to remove the test and set operation in
    resched_task, and make clear the previously vague semantics of
    POLLING_NRFLAG.
    
    * In idle routines:
    - Enter cpu_idle with preempt disabled. When the need_resched() condition
      becomes true, explicitly call schedule(). This makes things a bit clearer
      (IMO), but haven't updated all architectures yet.
    
    - Many do a test and clear of TIF_NEED_RESCHED for some reason. According
      to the resched_task rules, this isn't needed (and actually breaks the
      assumption that TIF_NEED_RESCHED is only cleared with the runqueue lock
      held). So remove that. Generally one less locked memory op when switching
      to the idle thread.
    
    - Many idle routines clear TIF_POLLING_NRFLAG, and only set it in the inner
      most polling idle loops. The above resched_task semantics allow it to be
      set until before the last time need_resched() is checked before going into
      a halt requiring interrupt wakeup.
    
      Many idle routines simply never enter such a halt, and so POLLING_NRFLAG
      can be always left set, completely eliminating resched IPIs when rescheduling
      the idle task.
    
      POLLING_NRFLAG width can be increased, to reduce the chance of resched IPIs.
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Con Kolivas <kernel@kolivas.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 4c621fc3c3b9..640d6908f8ec 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -197,11 +197,15 @@ void
 default_idle (void)
 {
 	local_irq_enable();
-	while (!need_resched())
-		if (can_do_pal_halt)
-			safe_halt();
-		else
+	while (!need_resched()) {
+		if (can_do_pal_halt) {
+			local_irq_disable();
+			if (!need_resched())
+				safe_halt();
+			local_irq_enable();
+		} else
 			cpu_relax();
+	}
 }
 
 #ifdef CONFIG_HOTPLUG_CPU
@@ -263,16 +267,16 @@ void __attribute__((noreturn))
 cpu_idle (void)
 {
 	void (*mark_idle)(int) = ia64_mark_idle;
+  	int cpu = smp_processor_id();
+	set_thread_flag(TIF_POLLING_NRFLAG);
 
 	/* endless idle loop with no priority at all */
 	while (1) {
+		if (!need_resched()) {
+			void (*idle)(void);
 #ifdef CONFIG_SMP
-		if (!need_resched())
 			min_xtp();
 #endif
-		while (!need_resched()) {
-			void (*idle)(void);
-
 			if (__get_cpu_var(cpu_idle_state))
 				__get_cpu_var(cpu_idle_state) = 0;
 
@@ -284,19 +288,17 @@ cpu_idle (void)
 			if (!idle)
 				idle = default_idle;
 			(*idle)();
-		}
-
-		if (mark_idle)
-			(*mark_idle)(0);
-
+			if (mark_idle)
+				(*mark_idle)(0);
 #ifdef CONFIG_SMP
-		normal_xtp();
+			normal_xtp();
 #endif
+		}
 		preempt_enable_no_resched();
 		schedule();
 		preempt_disable();
 		check_pgt_cache();
-		if (cpu_is_offline(smp_processor_id()))
+		if (cpu_is_offline(cpu))
 			play_dead();
 	}
 }

commit 5bfb5d690f36d316a5f3b4f7775fda996faa6b12
Author: Nick Piggin <nickpiggin@yahoo.com.au>
Date:   Tue Nov 8 21:39:01 2005 -0800

    [PATCH] sched: disable preempt in idle tasks
    
    Run idle threads with preempt disabled.
    
    Also corrected a bugs in arm26's cpu_idle (make it actually call schedule()).
    How did it ever work before?
    
    Might fix the CPU hotplugging hang which Nigel Cunningham noted.
    
    We think the bug hits if the idle thread is preempted after checking
    need_resched() and before going to sleep, then the CPU offlined.
    
    After calling stop_machine_run, the CPU eventually returns from preemption and
    into the idle thread and goes to sleep.  The CPU will continue executing
    previous idle and have no chance to call play_dead.
    
    By disabling preemption until we are ready to explicitly schedule, this bug is
    fixed and the idle threads generally become more robust.
    
    From: alexs <ashepard@u.washington.edu>
    
      PPC build fix
    
    From: Yoichi Yuasa <yuasa@hh.iij4u.or.jp>
    
      MIPS build fix
    
    Signed-off-by: Nick Piggin <npiggin@suse.de>
    Signed-off-by: Yoichi Yuasa <yuasa@hh.iij4u.or.jp>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 051e050359e4..4c621fc3c3b9 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -292,7 +292,9 @@ cpu_idle (void)
 #ifdef CONFIG_SMP
 		normal_xtp();
 #endif
+		preempt_enable_no_resched();
 		schedule();
+		preempt_disable();
 		check_pgt_cache();
 		if (cpu_is_offline(smp_processor_id()))
 			play_dead();

commit 9138d581b0ef855c0314c41c14852a7231b9941c
Author: Keith Owens <kaos@sgi.com>
Date:   Mon Nov 7 11:27:13 2005 -0800

    [IA64] Extend notify_die() hooks for IA64
    
    notify_die() added for MCA_{MONARCH,SLAVE,RENDEZVOUS}_{ENTER,PROCESS,LEAVE} and
    INIT_{MONARCH,SLAVE}_{ENTER,PROCESS,LEAVE}.  We need multiple
    notification points for these events because they can take many seconds
    to run which has nasty effects on the behaviour of the rest of the
    system.
    
    DIE_SS replaced by a generic DIE_FAULT which checks the vector number,
    to allow interception of faults other than SS.
    
    DIE_MACHINE_{HALT,RESTART} added to allow last minute close down
    processing, especially when the halt/restart routines are called from
    error handlers.
    
    DIE_OOPS added.
    
    The check for kprobe's break numbers has been moved from traps.c to
    kprobes.c, allowing DIE_BREAK to be used for any additional break
    numbers, i.e. it is no longer kprobes specific.
    
    Hooks for kernel debuggers and kernel dumpers added, ENTER and LEAVE.
    Both of these disable the system for long periods which impact on
    watchdogs and heartbeat systems in general.  More patches to come that
    use these events to reset watchdogs and heartbeats.
    
    unregister_die_notifier() added and both routines exported.  Requested
    by Dean Nelson.
    
    Lock removed from {un,}register_die_notifier.  notifier_chain_register()
    already takes a lock.  Also the generic notifier chain locking is being
    reworked to distinguish between callbacks that can block and those that
    cannot, the lock in {un,}register_die_notifier would interfere with
    that change.  http://marc.theaimsgroup.com/?l=linux-kernel&m=113018709002036&w=2
    
    Leading white space removed from arch/ia64/kernel/kprobes.c.
    
    Typo in mca.c in original version of this patch found & fixed by Dean
    Nelson.
    
    Signed-off-by: Keith Owens <kaos@sgi.com>
    Acked-by: Dean Nelson <dcn@sgi.com>
    Acked-by: Anil Keshavamurthy <anil.s.keshavamurthy@intel.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 051e050359e4..c78355cb8902 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -4,6 +4,9 @@
  * Copyright (C) 1998-2003 Hewlett-Packard Co
  *	David Mosberger-Tang <davidm@hpl.hp.com>
  * 04/11/17 Ashok Raj	<ashok.raj@intel.com> Added CPU Hotplug Support
+ *
+ * 2005-10-07 Keith Owens <kaos@sgi.com>
+ *	      Add notify_die() hooks.
  */
 #define __KERNEL_SYSCALLS__	/* see <asm/unistd.h> */
 #include <linux/config.h>
@@ -34,6 +37,7 @@
 #include <asm/elf.h>
 #include <asm/ia32.h>
 #include <asm/irq.h>
+#include <asm/kdebug.h>
 #include <asm/pgalloc.h>
 #include <asm/processor.h>
 #include <asm/sal.h>
@@ -804,12 +808,14 @@ cpu_halt (void)
 void
 machine_restart (char *restart_cmd)
 {
+	(void) notify_die(DIE_MACHINE_RESTART, restart_cmd, NULL, 0, 0, 0);
 	(*efi.reset_system)(EFI_RESET_WARM, 0, 0, NULL);
 }
 
 void
 machine_halt (void)
 {
+	(void) notify_die(DIE_MACHINE_HALT, "", NULL, 0, 0, 0);
 	cpu_halt();
 }
 

commit fb573856b2d82926b36ed059899d883474a3b9eb
Author: Ken Chen <kenneth.w.chen@intel.com>
Date:   Mon Aug 8 15:25:00 2005 -0700

    [IA64] fix nohalt boot option
    
    this changeset broke the "nohalt" kernel boot option.
      8df5a500a3e97f7811cdce0f553ca1917ccd4220
    
    default_idle() is looking at new variable can_do_pal_halt.  However,
    that variable did not get cleared upon "nohalt" boot option.  Result
    is that "nohalt" option is ignored until perfmon is exercised.
    
    Signed-off-by: Ken Chen <kenneth.w.chen@intel.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 66e840609808..051e050359e4 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -179,7 +179,7 @@ static int can_do_pal_halt = 1;
 
 static int __init nohalt_setup(char * str)
 {
-	pal_halt = 0;
+	pal_halt = can_do_pal_halt = 0;
 	return 1;
 }
 __setup("nohalt", nohalt_setup);

commit 59586e5a262a29361c45c929ea3253d4aec830b0
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Tue Jul 26 11:36:01 2005 -0600

    [PATCH] Don't export machine_restart, machine_halt, or machine_power_off.
    
    machine_restart, machine_halt and machine_power_off are machine
    specific hooks deep into the reboot logic, that modules
    have no business messing with.  Usually code should be calling
    kernel_restart, kernel_halt, kernel_power_off, or
    emergency_restart. So don't export machine_restart,
    machine_halt, and machine_power_off so we can catch buggy users.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index e484910246ad..66e840609808 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -807,16 +807,12 @@ machine_restart (char *restart_cmd)
 	(*efi.reset_system)(EFI_RESET_WARM, 0, 0, NULL);
 }
 
-EXPORT_SYMBOL(machine_restart);
-
 void
 machine_halt (void)
 {
 	cpu_halt();
 }
 
-EXPORT_SYMBOL(machine_halt);
-
 void
 machine_power_off (void)
 {
@@ -825,4 +821,3 @@ machine_power_off (void)
 	machine_halt();
 }
 
-EXPORT_SYMBOL(machine_power_off);

commit 5028770a42e7bc4d15791a44c28f0ad539323807
Merge: 9f02d6b7b43d d8683a0cb5d0
Author: Len Brown <len.brown@intel.com>
Date:   Tue Jul 12 17:21:56 2005 -0400

    [ACPI] merge acpi-2.6.12 branch into latest Linux 2.6.13-rc...
    
    Signed-off-by: Len Brown <len.brown@intel.com>

commit 6c4fa56033c11ad5c5929bf3edd1505d3d8a8c0b
Author: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
Date:   Mon Apr 18 23:06:47 2005 -0400

    [ACPI] fix C1 patch for IA64
    http://bugzilla.kernel.org/show_bug.cgi?id=4233
    
    Signed-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>
    Signed-off-by: Len Brown <len.brown@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index ebb71f3d6d19..a9bfba46733d 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -195,6 +195,7 @@ update_pal_halt_status(int status)
 void
 default_idle (void)
 {
+	local_irq_enable();
 	while (!need_resched())
 		if (can_do_pal_halt)
 			safe_halt();

commit 9508dbfe39112813612085c00d55bacd398eddc6
Author: Rusty Lynch <rusty.lynch@intel.com>
Date:   Mon Jun 27 15:17:12 2005 -0700

    [PATCH] Return probe redesign: ia64 specific implementation
    
    The following patch implements function return probes for ia64 using
    the revised design.  With this new design we no longer need to do some
    of the odd hacks previous required on the last ia64 return probe port
    that I sent out for comments.
    
    Note that this new implementation still does not resolve the problem noted
    by Keith Owens where backtrace data is lost after a return probe is hit.
    
    Changes include:
     * Addition of kretprobe_trampoline to act as a dummy function for instrumented
       functions to return to, and for the return probe infrastructure to place
       a kprobe on on, gaining control so that the return probe handler
       can be called, and so that the instruction pointer can be moved back
       to the original return address.
     * Addition of arch_init(), allowing a kprobe to be registered on
       kretprobe_trampoline
     * Addition of trampoline_probe_handler() which is used as the pre_handler
       for the kprobe inserted on kretprobe_implementation.  This is the function
       that handles the details for calling the return probe handler function
       and returning control back at the original return address
     * Addition of arch_prepare_kretprobe() which is setup as the pre_handler
       for a kprobe registered at the beginning of the target function by
       kernel/kprobes.c so that a return probe instance can be setup when
       a caller enters the target function.  (A return probe instance contains
       all the needed information for trampoline_probe_handler to do it's job.)
     * Hooks added to the exit path of a task so that we can cleanup any left-over
       return probe instances (i.e. if a task dies while inside a targeted function
       then the return probe instance was reserved at the beginning of the function
       but the function never returns so we need to mark the instance as unused.)
    
    Signed-off-by: Rusty Lynch <rusty.lynch@intel.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index ebb71f3d6d19..6e35bff05d59 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -27,6 +27,7 @@
 #include <linux/efi.h>
 #include <linux/interrupt.h>
 #include <linux/delay.h>
+#include <linux/kprobes.h>
 
 #include <asm/cpu.h>
 #include <asm/delay.h>
@@ -707,6 +708,13 @@ kernel_thread_helper (int (*fn)(void *), void *arg)
 void
 flush_thread (void)
 {
+	/*
+	 * Remove function-return probe instances associated with this task
+	 * and put them back on the free list. Do not insert an exit probe for
+	 * this function, it will be disabled by kprobe_flush_task if you do.
+	 */
+	kprobe_flush_task(current);
+
 	/* drop floating-point and debug-register state if it exists: */
 	current->thread.flags &= ~(IA64_THREAD_FPH_VALID | IA64_THREAD_DBG_VALID);
 	ia64_drop_fpu(current);
@@ -721,6 +729,14 @@ flush_thread (void)
 void
 exit_thread (void)
 {
+
+	/*
+	 * Remove function-return probe instances associated with this task
+	 * and put them back on the free list. Do not insert an exit probe for
+	 * this function, it will be disabled by kprobe_flush_task if you do.
+	 */
+	kprobe_flush_task(current);
+
 	ia64_drop_fpu(current);
 #ifdef CONFIG_PERFMON
        /* if needed, stop monitoring and flush state to perfmon context */

commit a71f62edc935fbdc346c5b16bea19f1480d29635
Author: Tony Luck <tony.luck@intel.com>
Date:   Tue May 3 16:21:45 2005 -0700

    [IA64] Fix two warnings introduced by perfmon patches.
    
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 474d75f9de8a..ebb71f3d6d19 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -183,7 +183,7 @@ static int __init nohalt_setup(char * str)
 }
 __setup("nohalt", nohalt_setup);
 
-int
+void
 update_pal_halt_status(int status)
 {
 	can_do_pal_halt = pal_halt && status;
@@ -195,8 +195,6 @@ update_pal_halt_status(int status)
 void
 default_idle (void)
 {
-	int can_do_pal;
-
 	while (!need_resched())
 		if (can_do_pal_halt)
 			safe_halt();

commit 8df5a500a3e97f7811cdce0f553ca1917ccd4220
Author: Stephane Eranian <eranian@hpl.hp.com>
Date:   Mon Apr 11 13:45:00 2005 -0700

    [IA64] perfmon & PAL_HALT again
    
    The pmu_active test is based on the values of PSR.up. THIS IS THE PROBLEM as
    it does not take into account the lazy restore logic which is as follow (simplified):
    
    context switch out:
            save PMDs
            clear psr.up
            release ownership
    
    context switch in:
            if (ctx->last_cpu == smp_processor_id() && ctx->cpu_activation == cpu_activation) {
                    set psr.up
                    return
            }
            restore PMD
            restore PMC
            ctx->last_cpu   = smp_processor_id();
            ctx->activation = ++cpu_activation;
            set psr.up
    
    The key here is that on context switch out, we clear psr.up and on context switch in
    we check if nobody else used the PMU on that processor since last time we came. In
    that case, we assume the PMD/PMC are ours and we simply reactivate.
    
    The Caliper problem is that between the moment we context switch out and the moment we
    come back, nobody effectively used the PMU BUT the processor went idle. Normally this
    would have no incidence but PAL_HALT does alter the PMU registers.  In default_idle(),
    the test on psr.up is not strong enough to cover this case and we go into PAL which
    trashed the PMU resgisters. When we come back we falsely assume that this is our state
    yet it is corrupted. Very nasty indeed.
    
    To avoid the problem it is necessary to forbid going to PAL_HALT as soon as perfmon
    installs some valid state in the PMU registers. This happens with an application
    attaches a context to a thread or CPU. It is not enough to check the psr/dcr bits.
    Hence I propose the attached patch. It adds a callback in process.c to modify the
    condition to enter PAL on idle. Basically, now it is conditional to pal_halt=1 AND
    perfmon saying it is okay.
    
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index c0140f4235e4..474d75f9de8a 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -173,7 +173,9 @@ do_notify_resume_user (sigset_t *oldset, struct sigscratch *scr, long in_syscall
 		ia64_do_signal(oldset, scr, in_syscall);
 }
 
-static int pal_halt = 1;
+static int pal_halt        = 1;
+static int can_do_pal_halt = 1;
+
 static int __init nohalt_setup(char * str)
 {
 	pal_halt = 0;
@@ -181,16 +183,22 @@ static int __init nohalt_setup(char * str)
 }
 __setup("nohalt", nohalt_setup);
 
+int
+update_pal_halt_status(int status)
+{
+	can_do_pal_halt = pal_halt && status;
+}
+
 /*
  * We use this if we don't have any better idle routine..
  */
 void
 default_idle (void)
 {
-	unsigned long pmu_active = ia64_getreg(_IA64_REG_PSR) & (IA64_PSR_PP | IA64_PSR_UP);
+	int can_do_pal;
 
 	while (!need_resched())
-		if (pal_halt && !pmu_active)
+		if (can_do_pal_halt)
 			safe_halt();
 		else
 			cpu_relax();

commit 7d5f9c0f10255000ca007fb03773c6b825c2b9ce
Author: Zwane Mwaikambo <zwane@arm.linux.org.uk>
Date:   Wed Mar 30 21:40:00 2005 -0700

    [IA64] reduce cacheline bouncing in cpu_idle_wait
    
    Andi noted that during normal runtime cpu_idle_map is bounced around a lot,
    and occassionally at a higher frequency than the timer interrupt wakeup
    which we normally exit pm_idle from.  So switch to a percpu variable.
    
    I didn't move things to the slow path because it would involve adding
    scheduler code to wakeup the idle thread on the cpus we're waiting for.
    
    Signed-off-by: Zwane Mwaikambo <zwane@arm.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 7c43aea5f7f7..c0140f4235e4 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -50,7 +50,7 @@
 #include "sigframe.h"
 
 void (*ia64_mark_idle)(int);
-static cpumask_t cpu_idle_map;
+static DEFINE_PER_CPU(unsigned int, cpu_idle_state);
 
 unsigned long boot_option_idle_override = 0;
 EXPORT_SYMBOL(boot_option_idle_override);
@@ -223,20 +223,31 @@ static inline void play_dead(void)
 }
 #endif /* CONFIG_HOTPLUG_CPU */
 
-
 void cpu_idle_wait(void)
 {
-        int cpu;
-        cpumask_t map;
+	unsigned int cpu, this_cpu = get_cpu();
+	cpumask_t map;
+
+	set_cpus_allowed(current, cpumask_of_cpu(this_cpu));
+	put_cpu();
 
-        for_each_online_cpu(cpu)
-                cpu_set(cpu, cpu_idle_map);
+	cpus_clear(map);
+	for_each_online_cpu(cpu) {
+		per_cpu(cpu_idle_state, cpu) = 1;
+		cpu_set(cpu, map);
+	}
 
-        wmb();
-        do {
-                ssleep(1);
-                cpus_and(map, cpu_idle_map, cpu_online_map);
-        } while (!cpus_empty(map));
+	__get_cpu_var(cpu_idle_state) = 0;
+
+	wmb();
+	do {
+		ssleep(1);
+		for_each_online_cpu(cpu) {
+			if (cpu_isset(cpu, map) && !per_cpu(cpu_idle_state, cpu))
+				cpu_clear(cpu, map);
+		}
+		cpus_and(map, map, cpu_online_map);
+	} while (!cpus_empty(map));
 }
 EXPORT_SYMBOL_GPL(cpu_idle_wait);
 
@@ -244,7 +255,6 @@ void __attribute__((noreturn))
 cpu_idle (void)
 {
 	void (*mark_idle)(int) = ia64_mark_idle;
-	int cpu = smp_processor_id();
 
 	/* endless idle loop with no priority at all */
 	while (1) {
@@ -255,12 +265,13 @@ cpu_idle (void)
 		while (!need_resched()) {
 			void (*idle)(void);
 
+			if (__get_cpu_var(cpu_idle_state))
+				__get_cpu_var(cpu_idle_state) = 0;
+
+			rmb();
 			if (mark_idle)
 				(*mark_idle)(1);
 
-			if (cpu_isset(cpu, cpu_idle_map))
-				cpu_clear(cpu, cpu_idle_map);
-			rmb();
 			idle = pm_idle;
 			if (!idle)
 				idle = default_idle;

commit b8d8b883e6f029e99c35c88f853501740e322131
Author: Ashok Raj <ashok.raj@intel.com>
Date:   Fri Apr 22 14:44:40 2005 -0700

    [IA64] cpu hotplug: return offlined cpus to SAL
    
    This patch is required to support cpu removal for IPF systems. Existing code
    just fakes the real offline by keeping it run the idle thread, and polling
    for the bit to re-appear in the cpu_state to get out of the idle loop.
    
    For the cpu-offline to work correctly, we need to pass control of this CPU
    back to SAL so it can continue in the boot-rendez mode. This gives the
    SAL control to not pick this cpu as the monarch processor for global MCA
    events, and addition does not wait for this cpu to checkin with SAL
    for global MCA events as well. The handoff is implemented as documented in
    SAL specification section 3.2.5.1 "OS_BOOT_RENDEZ to SAL return State"
    
    Signed-off-by: Ashok Raj <ashok.raj@intel.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
index 91293388dd29..7c43aea5f7f7 100644
--- a/arch/ia64/kernel/process.c
+++ b/arch/ia64/kernel/process.c
@@ -3,6 +3,7 @@
  *
  * Copyright (C) 1998-2003 Hewlett-Packard Co
  *	David Mosberger-Tang <davidm@hpl.hp.com>
+ * 04/11/17 Ashok Raj	<ashok.raj@intel.com> Added CPU Hotplug Support
  */
 #define __KERNEL_SYSCALLS__	/* see <asm/unistd.h> */
 #include <linux/config.h>
@@ -200,27 +201,20 @@ default_idle (void)
 static inline void play_dead(void)
 {
 	extern void ia64_cpu_local_tick (void);
+	unsigned int this_cpu = smp_processor_id();
+
 	/* Ack it */
 	__get_cpu_var(cpu_state) = CPU_DEAD;
 
-	/* We shouldn't have to disable interrupts while dead, but
-	 * some interrupts just don't seem to go away, and this makes
-	 * it "work" for testing purposes. */
 	max_xtp();
 	local_irq_disable();
-	/* Death loop */
-	while (__get_cpu_var(cpu_state) != CPU_UP_PREPARE)
-		cpu_relax();
-
+	idle_task_exit();
+	ia64_jump_to_sal(&sal_boot_rendez_state[this_cpu]);
 	/*
-	 * Enable timer interrupts from now on
-	 * Not required if we put processor in SAL_BOOT_RENDEZ mode.
+	 * The above is a point of no-return, the processor is
+	 * expected to be in SAL loop now.
 	 */
-	local_flush_tlb_all();
-	cpu_set(smp_processor_id(), cpu_online_map);
-	wmb();
-	ia64_cpu_local_tick ();
-	local_irq_enable();
+	BUG();
 }
 #else
 static inline void play_dead(void)

commit 1da177e4c3f41524e886b7f1b8a0c1fc7321cac2
Author: Linus Torvalds <torvalds@ppc970.osdl.org>
Date:   Sat Apr 16 15:20:36 2005 -0700

    Linux-2.6.12-rc2
    
    Initial git repository build. I'm not bothering with the full history,
    even though we have it. We can create a separate "historical" git
    archive of that later if we want to, and in the meantime it's about
    3.2GB when imported into git - space that would just make the early
    git days unnecessarily complicated, when we don't have a lot of good
    infrastructure for it.
    
    Let it rip!

diff --git a/arch/ia64/kernel/process.c b/arch/ia64/kernel/process.c
new file mode 100644
index 000000000000..91293388dd29
--- /dev/null
+++ b/arch/ia64/kernel/process.c
@@ -0,0 +1,800 @@
+/*
+ * Architecture-specific setup.
+ *
+ * Copyright (C) 1998-2003 Hewlett-Packard Co
+ *	David Mosberger-Tang <davidm@hpl.hp.com>
+ */
+#define __KERNEL_SYSCALLS__	/* see <asm/unistd.h> */
+#include <linux/config.h>
+
+#include <linux/cpu.h>
+#include <linux/pm.h>
+#include <linux/elf.h>
+#include <linux/errno.h>
+#include <linux/kallsyms.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/module.h>
+#include <linux/notifier.h>
+#include <linux/personality.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/smp_lock.h>
+#include <linux/stddef.h>
+#include <linux/thread_info.h>
+#include <linux/unistd.h>
+#include <linux/efi.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+
+#include <asm/cpu.h>
+#include <asm/delay.h>
+#include <asm/elf.h>
+#include <asm/ia32.h>
+#include <asm/irq.h>
+#include <asm/pgalloc.h>
+#include <asm/processor.h>
+#include <asm/sal.h>
+#include <asm/tlbflush.h>
+#include <asm/uaccess.h>
+#include <asm/unwind.h>
+#include <asm/user.h>
+
+#include "entry.h"
+
+#ifdef CONFIG_PERFMON
+# include <asm/perfmon.h>
+#endif
+
+#include "sigframe.h"
+
+void (*ia64_mark_idle)(int);
+static cpumask_t cpu_idle_map;
+
+unsigned long boot_option_idle_override = 0;
+EXPORT_SYMBOL(boot_option_idle_override);
+
+void
+ia64_do_show_stack (struct unw_frame_info *info, void *arg)
+{
+	unsigned long ip, sp, bsp;
+	char buf[128];			/* don't make it so big that it overflows the stack! */
+
+	printk("\nCall Trace:\n");
+	do {
+		unw_get_ip(info, &ip);
+		if (ip == 0)
+			break;
+
+		unw_get_sp(info, &sp);
+		unw_get_bsp(info, &bsp);
+		snprintf(buf, sizeof(buf),
+			 " [<%016lx>] %%s\n"
+			 "                                sp=%016lx bsp=%016lx\n",
+			 ip, sp, bsp);
+		print_symbol(buf, ip);
+	} while (unw_unwind(info) >= 0);
+}
+
+void
+show_stack (struct task_struct *task, unsigned long *sp)
+{
+	if (!task)
+		unw_init_running(ia64_do_show_stack, NULL);
+	else {
+		struct unw_frame_info info;
+
+		unw_init_from_blocked_task(&info, task);
+		ia64_do_show_stack(&info, NULL);
+	}
+}
+
+void
+dump_stack (void)
+{
+	show_stack(NULL, NULL);
+}
+
+EXPORT_SYMBOL(dump_stack);
+
+void
+show_regs (struct pt_regs *regs)
+{
+	unsigned long ip = regs->cr_iip + ia64_psr(regs)->ri;
+
+	print_modules();
+	printk("\nPid: %d, CPU %d, comm: %20s\n", current->pid, smp_processor_id(), current->comm);
+	printk("psr : %016lx ifs : %016lx ip  : [<%016lx>]    %s\n",
+	       regs->cr_ipsr, regs->cr_ifs, ip, print_tainted());
+	print_symbol("ip is at %s\n", ip);
+	printk("unat: %016lx pfs : %016lx rsc : %016lx\n",
+	       regs->ar_unat, regs->ar_pfs, regs->ar_rsc);
+	printk("rnat: %016lx bsps: %016lx pr  : %016lx\n",
+	       regs->ar_rnat, regs->ar_bspstore, regs->pr);
+	printk("ldrs: %016lx ccv : %016lx fpsr: %016lx\n",
+	       regs->loadrs, regs->ar_ccv, regs->ar_fpsr);
+	printk("csd : %016lx ssd : %016lx\n", regs->ar_csd, regs->ar_ssd);
+	printk("b0  : %016lx b6  : %016lx b7  : %016lx\n", regs->b0, regs->b6, regs->b7);
+	printk("f6  : %05lx%016lx f7  : %05lx%016lx\n",
+	       regs->f6.u.bits[1], regs->f6.u.bits[0],
+	       regs->f7.u.bits[1], regs->f7.u.bits[0]);
+	printk("f8  : %05lx%016lx f9  : %05lx%016lx\n",
+	       regs->f8.u.bits[1], regs->f8.u.bits[0],
+	       regs->f9.u.bits[1], regs->f9.u.bits[0]);
+	printk("f10 : %05lx%016lx f11 : %05lx%016lx\n",
+	       regs->f10.u.bits[1], regs->f10.u.bits[0],
+	       regs->f11.u.bits[1], regs->f11.u.bits[0]);
+
+	printk("r1  : %016lx r2  : %016lx r3  : %016lx\n", regs->r1, regs->r2, regs->r3);
+	printk("r8  : %016lx r9  : %016lx r10 : %016lx\n", regs->r8, regs->r9, regs->r10);
+	printk("r11 : %016lx r12 : %016lx r13 : %016lx\n", regs->r11, regs->r12, regs->r13);
+	printk("r14 : %016lx r15 : %016lx r16 : %016lx\n", regs->r14, regs->r15, regs->r16);
+	printk("r17 : %016lx r18 : %016lx r19 : %016lx\n", regs->r17, regs->r18, regs->r19);
+	printk("r20 : %016lx r21 : %016lx r22 : %016lx\n", regs->r20, regs->r21, regs->r22);
+	printk("r23 : %016lx r24 : %016lx r25 : %016lx\n", regs->r23, regs->r24, regs->r25);
+	printk("r26 : %016lx r27 : %016lx r28 : %016lx\n", regs->r26, regs->r27, regs->r28);
+	printk("r29 : %016lx r30 : %016lx r31 : %016lx\n", regs->r29, regs->r30, regs->r31);
+
+	if (user_mode(regs)) {
+		/* print the stacked registers */
+		unsigned long val, *bsp, ndirty;
+		int i, sof, is_nat = 0;
+
+		sof = regs->cr_ifs & 0x7f;	/* size of frame */
+		ndirty = (regs->loadrs >> 19);
+		bsp = ia64_rse_skip_regs((unsigned long *) regs->ar_bspstore, ndirty);
+		for (i = 0; i < sof; ++i) {
+			get_user(val, (unsigned long __user *) ia64_rse_skip_regs(bsp, i));
+			printk("r%-3u:%c%016lx%s", 32 + i, is_nat ? '*' : ' ', val,
+			       ((i == sof - 1) || (i % 3) == 2) ? "\n" : " ");
+		}
+	} else
+		show_stack(NULL, NULL);
+}
+
+void
+do_notify_resume_user (sigset_t *oldset, struct sigscratch *scr, long in_syscall)
+{
+	if (fsys_mode(current, &scr->pt)) {
+		/* defer signal-handling etc. until we return to privilege-level 0.  */
+		if (!ia64_psr(&scr->pt)->lp)
+			ia64_psr(&scr->pt)->lp = 1;
+		return;
+	}
+
+#ifdef CONFIG_PERFMON
+	if (current->thread.pfm_needs_checking)
+		pfm_handle_work();
+#endif
+
+	/* deal with pending signal delivery */
+	if (test_thread_flag(TIF_SIGPENDING))
+		ia64_do_signal(oldset, scr, in_syscall);
+}
+
+static int pal_halt = 1;
+static int __init nohalt_setup(char * str)
+{
+	pal_halt = 0;
+	return 1;
+}
+__setup("nohalt", nohalt_setup);
+
+/*
+ * We use this if we don't have any better idle routine..
+ */
+void
+default_idle (void)
+{
+	unsigned long pmu_active = ia64_getreg(_IA64_REG_PSR) & (IA64_PSR_PP | IA64_PSR_UP);
+
+	while (!need_resched())
+		if (pal_halt && !pmu_active)
+			safe_halt();
+		else
+			cpu_relax();
+}
+
+#ifdef CONFIG_HOTPLUG_CPU
+/* We don't actually take CPU down, just spin without interrupts. */
+static inline void play_dead(void)
+{
+	extern void ia64_cpu_local_tick (void);
+	/* Ack it */
+	__get_cpu_var(cpu_state) = CPU_DEAD;
+
+	/* We shouldn't have to disable interrupts while dead, but
+	 * some interrupts just don't seem to go away, and this makes
+	 * it "work" for testing purposes. */
+	max_xtp();
+	local_irq_disable();
+	/* Death loop */
+	while (__get_cpu_var(cpu_state) != CPU_UP_PREPARE)
+		cpu_relax();
+
+	/*
+	 * Enable timer interrupts from now on
+	 * Not required if we put processor in SAL_BOOT_RENDEZ mode.
+	 */
+	local_flush_tlb_all();
+	cpu_set(smp_processor_id(), cpu_online_map);
+	wmb();
+	ia64_cpu_local_tick ();
+	local_irq_enable();
+}
+#else
+static inline void play_dead(void)
+{
+	BUG();
+}
+#endif /* CONFIG_HOTPLUG_CPU */
+
+
+void cpu_idle_wait(void)
+{
+        int cpu;
+        cpumask_t map;
+
+        for_each_online_cpu(cpu)
+                cpu_set(cpu, cpu_idle_map);
+
+        wmb();
+        do {
+                ssleep(1);
+                cpus_and(map, cpu_idle_map, cpu_online_map);
+        } while (!cpus_empty(map));
+}
+EXPORT_SYMBOL_GPL(cpu_idle_wait);
+
+void __attribute__((noreturn))
+cpu_idle (void)
+{
+	void (*mark_idle)(int) = ia64_mark_idle;
+	int cpu = smp_processor_id();
+
+	/* endless idle loop with no priority at all */
+	while (1) {
+#ifdef CONFIG_SMP
+		if (!need_resched())
+			min_xtp();
+#endif
+		while (!need_resched()) {
+			void (*idle)(void);
+
+			if (mark_idle)
+				(*mark_idle)(1);
+
+			if (cpu_isset(cpu, cpu_idle_map))
+				cpu_clear(cpu, cpu_idle_map);
+			rmb();
+			idle = pm_idle;
+			if (!idle)
+				idle = default_idle;
+			(*idle)();
+		}
+
+		if (mark_idle)
+			(*mark_idle)(0);
+
+#ifdef CONFIG_SMP
+		normal_xtp();
+#endif
+		schedule();
+		check_pgt_cache();
+		if (cpu_is_offline(smp_processor_id()))
+			play_dead();
+	}
+}
+
+void
+ia64_save_extra (struct task_struct *task)
+{
+#ifdef CONFIG_PERFMON
+	unsigned long info;
+#endif
+
+	if ((task->thread.flags & IA64_THREAD_DBG_VALID) != 0)
+		ia64_save_debug_regs(&task->thread.dbr[0]);
+
+#ifdef CONFIG_PERFMON
+	if ((task->thread.flags & IA64_THREAD_PM_VALID) != 0)
+		pfm_save_regs(task);
+
+	info = __get_cpu_var(pfm_syst_info);
+	if (info & PFM_CPUINFO_SYST_WIDE)
+		pfm_syst_wide_update_task(task, info, 0);
+#endif
+
+#ifdef CONFIG_IA32_SUPPORT
+	if (IS_IA32_PROCESS(ia64_task_regs(task)))
+		ia32_save_state(task);
+#endif
+}
+
+void
+ia64_load_extra (struct task_struct *task)
+{
+#ifdef CONFIG_PERFMON
+	unsigned long info;
+#endif
+
+	if ((task->thread.flags & IA64_THREAD_DBG_VALID) != 0)
+		ia64_load_debug_regs(&task->thread.dbr[0]);
+
+#ifdef CONFIG_PERFMON
+	if ((task->thread.flags & IA64_THREAD_PM_VALID) != 0)
+		pfm_load_regs(task);
+
+	info = __get_cpu_var(pfm_syst_info);
+	if (info & PFM_CPUINFO_SYST_WIDE) 
+		pfm_syst_wide_update_task(task, info, 1);
+#endif
+
+#ifdef CONFIG_IA32_SUPPORT
+	if (IS_IA32_PROCESS(ia64_task_regs(task)))
+		ia32_load_state(task);
+#endif
+}
+
+/*
+ * Copy the state of an ia-64 thread.
+ *
+ * We get here through the following  call chain:
+ *
+ *	from user-level:	from kernel:
+ *
+ *	<clone syscall>	        <some kernel call frames>
+ *	sys_clone		   :
+ *	do_fork			do_fork
+ *	copy_thread		copy_thread
+ *
+ * This means that the stack layout is as follows:
+ *
+ *	+---------------------+ (highest addr)
+ *	|   struct pt_regs    |
+ *	+---------------------+
+ *	| struct switch_stack |
+ *	+---------------------+
+ *	|                     |
+ *	|    memory stack     |
+ *	|                     | <-- sp (lowest addr)
+ *	+---------------------+
+ *
+ * Observe that we copy the unat values that are in pt_regs and switch_stack.  Spilling an
+ * integer to address X causes bit N in ar.unat to be set to the NaT bit of the register,
+ * with N=(X & 0x1ff)/8.  Thus, copying the unat value preserves the NaT bits ONLY if the
+ * pt_regs structure in the parent is congruent to that of the child, modulo 512.  Since
+ * the stack is page aligned and the page size is at least 4KB, this is always the case,
+ * so there is nothing to worry about.
+ */
+int
+copy_thread (int nr, unsigned long clone_flags,
+	     unsigned long user_stack_base, unsigned long user_stack_size,
+	     struct task_struct *p, struct pt_regs *regs)
+{
+	extern char ia64_ret_from_clone, ia32_ret_from_clone;
+	struct switch_stack *child_stack, *stack;
+	unsigned long rbs, child_rbs, rbs_size;
+	struct pt_regs *child_ptregs;
+	int retval = 0;
+
+#ifdef CONFIG_SMP
+	/*
+	 * For SMP idle threads, fork_by_hand() calls do_fork with
+	 * NULL regs.
+	 */
+	if (!regs)
+		return 0;
+#endif
+
+	stack = ((struct switch_stack *) regs) - 1;
+
+	child_ptregs = (struct pt_regs *) ((unsigned long) p + IA64_STK_OFFSET) - 1;
+	child_stack = (struct switch_stack *) child_ptregs - 1;
+
+	/* copy parent's switch_stack & pt_regs to child: */
+	memcpy(child_stack, stack, sizeof(*child_ptregs) + sizeof(*child_stack));
+
+	rbs = (unsigned long) current + IA64_RBS_OFFSET;
+	child_rbs = (unsigned long) p + IA64_RBS_OFFSET;
+	rbs_size = stack->ar_bspstore - rbs;
+
+	/* copy the parent's register backing store to the child: */
+	memcpy((void *) child_rbs, (void *) rbs, rbs_size);
+
+	if (likely(user_mode(child_ptregs))) {
+		if ((clone_flags & CLONE_SETTLS) && !IS_IA32_PROCESS(regs))
+			child_ptregs->r13 = regs->r16;	/* see sys_clone2() in entry.S */
+		if (user_stack_base) {
+			child_ptregs->r12 = user_stack_base + user_stack_size - 16;
+			child_ptregs->ar_bspstore = user_stack_base;
+			child_ptregs->ar_rnat = 0;
+			child_ptregs->loadrs = 0;
+		}
+	} else {
+		/*
+		 * Note: we simply preserve the relative position of
+		 * the stack pointer here.  There is no need to
+		 * allocate a scratch area here, since that will have
+		 * been taken care of by the caller of sys_clone()
+		 * already.
+		 */
+		child_ptregs->r12 = (unsigned long) child_ptregs - 16; /* kernel sp */
+		child_ptregs->r13 = (unsigned long) p;		/* set `current' pointer */
+	}
+	child_stack->ar_bspstore = child_rbs + rbs_size;
+	if (IS_IA32_PROCESS(regs))
+		child_stack->b0 = (unsigned long) &ia32_ret_from_clone;
+	else
+		child_stack->b0 = (unsigned long) &ia64_ret_from_clone;
+
+	/* copy parts of thread_struct: */
+	p->thread.ksp = (unsigned long) child_stack - 16;
+
+	/* stop some PSR bits from being inherited.
+	 * the psr.up/psr.pp bits must be cleared on fork but inherited on execve()
+	 * therefore we must specify them explicitly here and not include them in
+	 * IA64_PSR_BITS_TO_CLEAR.
+	 */
+	child_ptregs->cr_ipsr = ((child_ptregs->cr_ipsr | IA64_PSR_BITS_TO_SET)
+				 & ~(IA64_PSR_BITS_TO_CLEAR | IA64_PSR_PP | IA64_PSR_UP));
+
+	/*
+	 * NOTE: The calling convention considers all floating point
+	 * registers in the high partition (fph) to be scratch.  Since
+	 * the only way to get to this point is through a system call,
+	 * we know that the values in fph are all dead.  Hence, there
+	 * is no need to inherit the fph state from the parent to the
+	 * child and all we have to do is to make sure that
+	 * IA64_THREAD_FPH_VALID is cleared in the child.
+	 *
+	 * XXX We could push this optimization a bit further by
+	 * clearing IA64_THREAD_FPH_VALID on ANY system call.
+	 * However, it's not clear this is worth doing.  Also, it
+	 * would be a slight deviation from the normal Linux system
+	 * call behavior where scratch registers are preserved across
+	 * system calls (unless used by the system call itself).
+	 */
+#	define THREAD_FLAGS_TO_CLEAR	(IA64_THREAD_FPH_VALID | IA64_THREAD_DBG_VALID \
+					 | IA64_THREAD_PM_VALID)
+#	define THREAD_FLAGS_TO_SET	0
+	p->thread.flags = ((current->thread.flags & ~THREAD_FLAGS_TO_CLEAR)
+			   | THREAD_FLAGS_TO_SET);
+	ia64_drop_fpu(p);	/* don't pick up stale state from a CPU's fph */
+#ifdef CONFIG_IA32_SUPPORT
+	/*
+	 * If we're cloning an IA32 task then save the IA32 extra
+	 * state from the current task to the new task
+	 */
+	if (IS_IA32_PROCESS(ia64_task_regs(current))) {
+		ia32_save_state(p);
+		if (clone_flags & CLONE_SETTLS)
+			retval = ia32_clone_tls(p, child_ptregs);
+
+		/* Copy partially mapped page list */
+		if (!retval)
+			retval = ia32_copy_partial_page_list(p, clone_flags);
+	}
+#endif
+
+#ifdef CONFIG_PERFMON
+	if (current->thread.pfm_context)
+		pfm_inherit(p, child_ptregs);
+#endif
+	return retval;
+}
+
+static void
+do_copy_task_regs (struct task_struct *task, struct unw_frame_info *info, void *arg)
+{
+	unsigned long mask, sp, nat_bits = 0, ip, ar_rnat, urbs_end, cfm;
+	elf_greg_t *dst = arg;
+	struct pt_regs *pt;
+	char nat;
+	int i;
+
+	memset(dst, 0, sizeof(elf_gregset_t));	/* don't leak any kernel bits to user-level */
+
+	if (unw_unwind_to_user(info) < 0)
+		return;
+
+	unw_get_sp(info, &sp);
+	pt = (struct pt_regs *) (sp + 16);
+
+	urbs_end = ia64_get_user_rbs_end(task, pt, &cfm);
+
+	if (ia64_sync_user_rbs(task, info->sw, pt->ar_bspstore, urbs_end) < 0)
+		return;
+
+	ia64_peek(task, info->sw, urbs_end, (long) ia64_rse_rnat_addr((long *) urbs_end),
+		  &ar_rnat);
+
+	/*
+	 * coredump format:
+	 *	r0-r31
+	 *	NaT bits (for r0-r31; bit N == 1 iff rN is a NaT)
+	 *	predicate registers (p0-p63)
+	 *	b0-b7
+	 *	ip cfm user-mask
+	 *	ar.rsc ar.bsp ar.bspstore ar.rnat
+	 *	ar.ccv ar.unat ar.fpsr ar.pfs ar.lc ar.ec
+	 */
+
+	/* r0 is zero */
+	for (i = 1, mask = (1UL << i); i < 32; ++i) {
+		unw_get_gr(info, i, &dst[i], &nat);
+		if (nat)
+			nat_bits |= mask;
+		mask <<= 1;
+	}
+	dst[32] = nat_bits;
+	unw_get_pr(info, &dst[33]);
+
+	for (i = 0; i < 8; ++i)
+		unw_get_br(info, i, &dst[34 + i]);
+
+	unw_get_rp(info, &ip);
+	dst[42] = ip + ia64_psr(pt)->ri;
+	dst[43] = cfm;
+	dst[44] = pt->cr_ipsr & IA64_PSR_UM;
+
+	unw_get_ar(info, UNW_AR_RSC, &dst[45]);
+	/*
+	 * For bsp and bspstore, unw_get_ar() would return the kernel
+	 * addresses, but we need the user-level addresses instead:
+	 */
+	dst[46] = urbs_end;	/* note: by convention PT_AR_BSP points to the end of the urbs! */
+	dst[47] = pt->ar_bspstore;
+	dst[48] = ar_rnat;
+	unw_get_ar(info, UNW_AR_CCV, &dst[49]);
+	unw_get_ar(info, UNW_AR_UNAT, &dst[50]);
+	unw_get_ar(info, UNW_AR_FPSR, &dst[51]);
+	dst[52] = pt->ar_pfs;	/* UNW_AR_PFS is == to pt->cr_ifs for interrupt frames */
+	unw_get_ar(info, UNW_AR_LC, &dst[53]);
+	unw_get_ar(info, UNW_AR_EC, &dst[54]);
+	unw_get_ar(info, UNW_AR_CSD, &dst[55]);
+	unw_get_ar(info, UNW_AR_SSD, &dst[56]);
+}
+
+void
+do_dump_task_fpu (struct task_struct *task, struct unw_frame_info *info, void *arg)
+{
+	elf_fpreg_t *dst = arg;
+	int i;
+
+	memset(dst, 0, sizeof(elf_fpregset_t));	/* don't leak any "random" bits */
+
+	if (unw_unwind_to_user(info) < 0)
+		return;
+
+	/* f0 is 0.0, f1 is 1.0 */
+
+	for (i = 2; i < 32; ++i)
+		unw_get_fr(info, i, dst + i);
+
+	ia64_flush_fph(task);
+	if ((task->thread.flags & IA64_THREAD_FPH_VALID) != 0)
+		memcpy(dst + 32, task->thread.fph, 96*16);
+}
+
+void
+do_copy_regs (struct unw_frame_info *info, void *arg)
+{
+	do_copy_task_regs(current, info, arg);
+}
+
+void
+do_dump_fpu (struct unw_frame_info *info, void *arg)
+{
+	do_dump_task_fpu(current, info, arg);
+}
+
+int
+dump_task_regs(struct task_struct *task, elf_gregset_t *regs)
+{
+	struct unw_frame_info tcore_info;
+
+	if (current == task) {
+		unw_init_running(do_copy_regs, regs);
+	} else {
+		memset(&tcore_info, 0, sizeof(tcore_info));
+		unw_init_from_blocked_task(&tcore_info, task);
+		do_copy_task_regs(task, &tcore_info, regs);
+	}
+	return 1;
+}
+
+void
+ia64_elf_core_copy_regs (struct pt_regs *pt, elf_gregset_t dst)
+{
+	unw_init_running(do_copy_regs, dst);
+}
+
+int
+dump_task_fpu (struct task_struct *task, elf_fpregset_t *dst)
+{
+	struct unw_frame_info tcore_info;
+
+	if (current == task) {
+		unw_init_running(do_dump_fpu, dst);
+	} else {
+		memset(&tcore_info, 0, sizeof(tcore_info));
+		unw_init_from_blocked_task(&tcore_info, task);
+		do_dump_task_fpu(task, &tcore_info, dst);
+	}
+	return 1;
+}
+
+int
+dump_fpu (struct pt_regs *pt, elf_fpregset_t dst)
+{
+	unw_init_running(do_dump_fpu, dst);
+	return 1;	/* f0-f31 are always valid so we always return 1 */
+}
+
+long
+sys_execve (char __user *filename, char __user * __user *argv, char __user * __user *envp,
+	    struct pt_regs *regs)
+{
+	char *fname;
+	int error;
+
+	fname = getname(filename);
+	error = PTR_ERR(fname);
+	if (IS_ERR(fname))
+		goto out;
+	error = do_execve(fname, argv, envp, regs);
+	putname(fname);
+out:
+	return error;
+}
+
+pid_t
+kernel_thread (int (*fn)(void *), void *arg, unsigned long flags)
+{
+	extern void start_kernel_thread (void);
+	unsigned long *helper_fptr = (unsigned long *) &start_kernel_thread;
+	struct {
+		struct switch_stack sw;
+		struct pt_regs pt;
+	} regs;
+
+	memset(&regs, 0, sizeof(regs));
+	regs.pt.cr_iip = helper_fptr[0];	/* set entry point (IP) */
+	regs.pt.r1 = helper_fptr[1];		/* set GP */
+	regs.pt.r9 = (unsigned long) fn;	/* 1st argument */
+	regs.pt.r11 = (unsigned long) arg;	/* 2nd argument */
+	/* Preserve PSR bits, except for bits 32-34 and 37-45, which we can't read.  */
+	regs.pt.cr_ipsr = ia64_getreg(_IA64_REG_PSR) | IA64_PSR_BN;
+	regs.pt.cr_ifs = 1UL << 63;		/* mark as valid, empty frame */
+	regs.sw.ar_fpsr = regs.pt.ar_fpsr = ia64_getreg(_IA64_REG_AR_FPSR);
+	regs.sw.ar_bspstore = (unsigned long) current + IA64_RBS_OFFSET;
+	regs.sw.pr = (1 << PRED_KERNEL_STACK);
+	return do_fork(flags | CLONE_VM | CLONE_UNTRACED, 0, &regs.pt, 0, NULL, NULL);
+}
+EXPORT_SYMBOL(kernel_thread);
+
+/* This gets called from kernel_thread() via ia64_invoke_thread_helper().  */
+int
+kernel_thread_helper (int (*fn)(void *), void *arg)
+{
+#ifdef CONFIG_IA32_SUPPORT
+	if (IS_IA32_PROCESS(ia64_task_regs(current))) {
+		/* A kernel thread is always a 64-bit process. */
+		current->thread.map_base  = DEFAULT_MAP_BASE;
+		current->thread.task_size = DEFAULT_TASK_SIZE;
+		ia64_set_kr(IA64_KR_IO_BASE, current->thread.old_iob);
+		ia64_set_kr(IA64_KR_TSSD, current->thread.old_k1);
+	}
+#endif
+	return (*fn)(arg);
+}
+
+/*
+ * Flush thread state.  This is called when a thread does an execve().
+ */
+void
+flush_thread (void)
+{
+	/* drop floating-point and debug-register state if it exists: */
+	current->thread.flags &= ~(IA64_THREAD_FPH_VALID | IA64_THREAD_DBG_VALID);
+	ia64_drop_fpu(current);
+	if (IS_IA32_PROCESS(ia64_task_regs(current)))
+		ia32_drop_partial_page_list(current);
+}
+
+/*
+ * Clean up state associated with current thread.  This is called when
+ * the thread calls exit().
+ */
+void
+exit_thread (void)
+{
+	ia64_drop_fpu(current);
+#ifdef CONFIG_PERFMON
+       /* if needed, stop monitoring and flush state to perfmon context */
+	if (current->thread.pfm_context)
+		pfm_exit_thread(current);
+
+	/* free debug register resources */
+	if (current->thread.flags & IA64_THREAD_DBG_VALID)
+		pfm_release_debug_registers(current);
+#endif
+	if (IS_IA32_PROCESS(ia64_task_regs(current)))
+		ia32_drop_partial_page_list(current);
+}
+
+unsigned long
+get_wchan (struct task_struct *p)
+{
+	struct unw_frame_info info;
+	unsigned long ip;
+	int count = 0;
+
+	/*
+	 * Note: p may not be a blocked task (it could be current or
+	 * another process running on some other CPU.  Rather than
+	 * trying to determine if p is really blocked, we just assume
+	 * it's blocked and rely on the unwind routines to fail
+	 * gracefully if the process wasn't really blocked after all.
+	 * --davidm 99/12/15
+	 */
+	unw_init_from_blocked_task(&info, p);
+	do {
+		if (unw_unwind(&info) < 0)
+			return 0;
+		unw_get_ip(&info, &ip);
+		if (!in_sched_functions(ip))
+			return ip;
+	} while (count++ < 16);
+	return 0;
+}
+
+void
+cpu_halt (void)
+{
+	pal_power_mgmt_info_u_t power_info[8];
+	unsigned long min_power;
+	int i, min_power_state;
+
+	if (ia64_pal_halt_info(power_info) != 0)
+		return;
+
+	min_power_state = 0;
+	min_power = power_info[0].pal_power_mgmt_info_s.power_consumption;
+	for (i = 1; i < 8; ++i)
+		if (power_info[i].pal_power_mgmt_info_s.im
+		    && power_info[i].pal_power_mgmt_info_s.power_consumption < min_power) {
+			min_power = power_info[i].pal_power_mgmt_info_s.power_consumption;
+			min_power_state = i;
+		}
+
+	while (1)
+		ia64_pal_halt(min_power_state);
+}
+
+void
+machine_restart (char *restart_cmd)
+{
+	(*efi.reset_system)(EFI_RESET_WARM, 0, 0, NULL);
+}
+
+EXPORT_SYMBOL(machine_restart);
+
+void
+machine_halt (void)
+{
+	cpu_halt();
+}
+
+EXPORT_SYMBOL(machine_halt);
+
+void
+machine_power_off (void)
+{
+	if (pm_power_off)
+		pm_power_off();
+	machine_halt();
+}
+
+EXPORT_SYMBOL(machine_power_off);
