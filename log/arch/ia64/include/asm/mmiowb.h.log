commit 05933aac7b11911955de307a329dc2a7a14b7bd0
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Aug 13 09:25:02 2019 +0200

    ia64: remove now unused machvec indirections
    
    With the SGI SN2 machvec removal most of the indirections are unused
    now, so remove them.  This includes the entire removal of the mmio
    read*/write* macros as the generic ones are identical to the
    asm-generic/io.h version.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Link: https://lkml.kernel.org/r/20190813072514.23299-17-hch@lst.de
    Signed-off-by: Tony Luck <tony.luck@intel.com>

diff --git a/arch/ia64/include/asm/mmiowb.h b/arch/ia64/include/asm/mmiowb.h
index 297b85ac84a0..d67aab4ea3b4 100644
--- a/arch/ia64/include/asm/mmiowb.h
+++ b/arch/ia64/include/asm/mmiowb.h
@@ -3,22 +3,14 @@
 #ifndef _ASM_IA64_MMIOWB_H
 #define _ASM_IA64_MMIOWB_H
 
-#include <asm/machvec.h>
-
 /**
- * ___ia64_mmiowb - I/O write barrier
+ * mmiowb - I/O write barrier
  *
  * Ensure ordering of I/O space writes.  This will make sure that writes
  * following the barrier will arrive after all previous writes.  For most
  * ia64 platforms, this is a simple 'mf.a' instruction.
  */
-static inline void ___ia64_mmiowb(void)
-{
-	ia64_mfa();
-}
-
-#define __ia64_mmiowb	___ia64_mmiowb
-#define mmiowb()	platform_mmiowb()
+#define mmiowb()	ia64_mfa()
 
 #include <asm-generic/mmiowb.h>
 

commit 49ca6462fc9e0f5a67cd96eeddd844efc3fb33b9
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Feb 22 13:37:21 2019 +0000

    ia64/mmiowb: Add unconditional mmiowb() to arch_spin_unlock()
    
    The mmiowb() macro is horribly difficult to use and drivers will continue
    to work most of the time if they omit a call when it is required.
    
    Rather than rely on driver authors getting this right, push mmiowb() into
    arch_spin_unlock() for ia64. If this is deemed to be a performance issue,
    a subsequent optimisation could make use of ARCH_HAS_MMIOWB to elide
    the barrier in cases where no I/O writes were performed inside the
    critical section.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/ia64/include/asm/mmiowb.h b/arch/ia64/include/asm/mmiowb.h
new file mode 100644
index 000000000000..297b85ac84a0
--- /dev/null
+++ b/arch/ia64/include/asm/mmiowb.h
@@ -0,0 +1,25 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+
+#ifndef _ASM_IA64_MMIOWB_H
+#define _ASM_IA64_MMIOWB_H
+
+#include <asm/machvec.h>
+
+/**
+ * ___ia64_mmiowb - I/O write barrier
+ *
+ * Ensure ordering of I/O space writes.  This will make sure that writes
+ * following the barrier will arrive after all previous writes.  For most
+ * ia64 platforms, this is a simple 'mf.a' instruction.
+ */
+static inline void ___ia64_mmiowb(void)
+{
+	ia64_mfa();
+}
+
+#define __ia64_mmiowb	___ia64_mmiowb
+#define mmiowb()	platform_mmiowb()
+
+#include <asm-generic/mmiowb.h>
+
+#endif	/* _ASM_IA64_MMIOWB_H */
