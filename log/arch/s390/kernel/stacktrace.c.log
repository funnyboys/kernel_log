commit aa137a6d302b5989ed205b7dfb7fe40a8851babc
Author: Miroslav Benes <mbenes@suse.cz>
Date:   Wed Nov 6 10:56:01 2019 +0100

    s390/livepatch: Implement reliable stack tracing for the consistency model
    
    The livepatch consistency model requires reliable stack tracing
    architecture support in order to work properly. In order to achieve
    this, two main issues have to be solved. First, reliable and consistent
    call chain backtracing has to be ensured. Second, the unwinder needs to
    be able to detect stack corruptions and return errors.
    
    The "zSeries ELF Application Binary Interface Supplement" says:
    
      "The stack pointer points to the first word of the lowest allocated
      stack frame. If the "back chain" is implemented this word will point to
      the previously allocated stack frame (towards higher addresses), except
      for the first stack frame, which shall have a back chain of zero (NULL).
      The stack shall grow downwards, in other words towards lower addresses."
    
    "back chain" is optional. GCC option -mbackchain enables it. Quoting
    Martin Schwidefsky [1]:
    
      "The compiler is called with the -mbackchain option, all normal C
      function will store the backchain in the function prologue. All
      functions written in assembler code should do the same, if you find one
      that does not we should fix that. The end result is that a task that
      *voluntarily* called schedule() should have a proper backchain at all
      times.
    
      Dependent on the use case this may or may not be enough. Asynchronous
      interrupts may stop the CPU at the beginning of a function, if kernel
      preemption is enabled we can end up with a broken backchain.  The
      production kernels for IBM Z are all compiled *without* kernel
      preemption. So yes, we might get away without the objtool support.
    
      On a side-note, we do have a line item to implement the ORC unwinder for
      the kernel, that includes the objtool support. Once we have that we can
      drop the -mbackchain option for the kernel build. That gives us a nice
      little performance benefit. I hope that the change from backchain to the
      ORC unwinder will not be too hard to implement in the livepatch tools."
    
    Since -mbackchain is enabled by default when the kernel is compiled, the
    call chain backtracing should be currently ensured and objtool should
    not be necessary for livepatch purposes.
    
    Regarding the second issue, stack corruptions and non-reliable states
    have to be recognized by the unwinder. Mainly it means to detect
    preemption or page faults, the end of the task stack must be reached,
    return addresses must be valid text addresses and hacks like function
    graph tracing and kretprobes must be properly detected.
    
    Unwinding a running task's stack is not a problem, because there is a
    livepatch requirement that every checked task is blocked, except for the
    current task. Due to that, the implementation can be much simpler
    compared to the existing non-reliable infrastructure. We can consider a
    task's kernel/thread stack only and skip the other stacks.
    
    [1] 20180912121106.31ffa97c@mschwideX1 [not archived on lore.kernel.org]
    
    Link: https://lkml.kernel.org/r/20191106095601.29986-5-mbenes@suse.cz
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Tested-by: Miroslav Benes <mbenes@suse.cz>
    Signed-off-by: Miroslav Benes <mbenes@suse.cz>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index f8fc4f8aef9b..fc5419ac64c8 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -9,6 +9,7 @@
 #include <linux/stacktrace.h>
 #include <asm/stacktrace.h>
 #include <asm/unwind.h>
+#include <asm/kprobes.h>
 
 void arch_stack_walk(stack_trace_consume_fn consume_entry, void *cookie,
 		     struct task_struct *task, struct pt_regs *regs)
@@ -22,3 +23,45 @@ void arch_stack_walk(stack_trace_consume_fn consume_entry, void *cookie,
 			break;
 	}
 }
+
+/*
+ * This function returns an error if it detects any unreliable features of the
+ * stack.  Otherwise it guarantees that the stack trace is reliable.
+ *
+ * If the task is not 'current', the caller *must* ensure the task is inactive.
+ */
+int arch_stack_walk_reliable(stack_trace_consume_fn consume_entry,
+			     void *cookie, struct task_struct *task)
+{
+	struct unwind_state state;
+	unsigned long addr;
+
+	unwind_for_each_frame(&state, task, NULL, 0) {
+		if (state.stack_info.type != STACK_TYPE_TASK)
+			return -EINVAL;
+
+		if (state.regs)
+			return -EINVAL;
+
+		addr = unwind_get_return_address(&state);
+		if (!addr)
+			return -EINVAL;
+
+#ifdef CONFIG_KPROBES
+		/*
+		 * Mark stacktraces with kretprobed functions on them
+		 * as unreliable.
+		 */
+		if (state.ip == (unsigned long)kretprobe_trampoline)
+			return -EINVAL;
+#endif
+
+		if (!consume_entry(cookie, addr, false))
+			return -EINVAL;
+	}
+
+	/* Check for stack corruption */
+	if (unwind_error(&state))
+		return -EINVAL;
+	return 0;
+}

commit e991e5bb11d6eacf8a49867ff9d4ec6e1cde3718
Author: Vasily Gorbik <gor@linux.ibm.com>
Date:   Wed Aug 14 14:27:44 2019 +0200

    s390/stacktrace: use common arch_stack_walk infrastructure
    
    Use common arch_stack_walk infrastructure to avoid duplicated code and
    avoid taking care of the stack storage and filtering.
    
    Common code also uses try_get_task_stack/put_task_stack when needed which
    have been missing in our code, which also solves potential problem for us.
    
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index f6a620f854e1..f8fc4f8aef9b 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -6,57 +6,19 @@
  *  Author(s): Heiko Carstens <heiko.carstens@de.ibm.com>
  */
 
-#include <linux/sched.h>
-#include <linux/sched/debug.h>
 #include <linux/stacktrace.h>
-#include <linux/kallsyms.h>
-#include <linux/export.h>
 #include <asm/stacktrace.h>
 #include <asm/unwind.h>
 
-void save_stack_trace(struct stack_trace *trace)
+void arch_stack_walk(stack_trace_consume_fn consume_entry, void *cookie,
+		     struct task_struct *task, struct pt_regs *regs)
 {
 	struct unwind_state state;
+	unsigned long addr;
 
-	unwind_for_each_frame(&state, current, NULL, 0) {
-		if (trace->nr_entries >= trace->max_entries)
+	unwind_for_each_frame(&state, task, regs, 0) {
+		addr = unwind_get_return_address(&state);
+		if (!addr || !consume_entry(cookie, addr, false))
 			break;
-		if (trace->skip > 0)
-			trace->skip--;
-		else
-			trace->entries[trace->nr_entries++] = state.ip;
 	}
 }
-EXPORT_SYMBOL_GPL(save_stack_trace);
-
-void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
-{
-	struct unwind_state state;
-
-	unwind_for_each_frame(&state, tsk, NULL, 0) {
-		if (trace->nr_entries >= trace->max_entries)
-			break;
-		if (in_sched_functions(state.ip))
-			continue;
-		if (trace->skip > 0)
-			trace->skip--;
-		else
-			trace->entries[trace->nr_entries++] = state.ip;
-	}
-}
-EXPORT_SYMBOL_GPL(save_stack_trace_tsk);
-
-void save_stack_trace_regs(struct pt_regs *regs, struct stack_trace *trace)
-{
-	struct unwind_state state;
-
-	unwind_for_each_frame(&state, current, regs, 0) {
-		if (trace->nr_entries >= trace->max_entries)
-			break;
-		if (trace->skip > 0)
-			trace->skip--;
-		else
-			trace->entries[trace->nr_entries++] = state.ip;
-	}
-}
-EXPORT_SYMBOL_GPL(save_stack_trace_regs);

commit 14be4c61c205dcb0a72251c1e2790814181bd9ba
Merge: ccbc2e5ed192 ce968f6012f6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 6 16:42:54 2019 -0700

    Merge tag 's390-5.2-1' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux
    
    Pull s390 updates from Martin Schwidefsky:
    
     - Support for kernel address space layout randomization
    
     - Add support for kernel image signature verification
    
     - Convert s390 to the generic get_user_pages_fast code
    
     - Convert s390 to the stack unwind API analog to x86
    
     - Add support for CPU directed interrupts for PCI devices
    
     - Provide support for MIO instructions to the PCI base layer, this will
       allow the use of direct PCI mappings in user space code
    
     - Add the basic KVM guest ultravisor interface for protected VMs
    
     - Add AT_HWCAP bits for several new hardware capabilities
    
     - Update the CPU measurement facility counter definitions to SVN 6
    
     - Arnds cleanup patches for his quest to get LLVM compiles working
    
     - A vfio-ccw update with bug fixes and support for halt and clear
    
     - Improvements for the hardware TRNG code
    
     - Another round of cleanup for the QDIO layer
    
     - Numerous cleanups and bug fixes
    
    * tag 's390-5.2-1' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux: (98 commits)
      s390/vdso: drop unnecessary cc-ldoption
      s390: fix clang -Wpointer-sign warnigns in boot code
      s390: drop CONFIG_VIRT_TO_BUS
      s390: boot, purgatory: pass $(CLANG_FLAGS) where needed
      s390: only build for new CPUs with clang
      s390: simplify disabled_wait
      s390/ftrace: use HAVE_FUNCTION_GRAPH_RET_ADDR_PTR
      s390/unwind: introduce stack unwind API
      s390/opcodes: add missing instructions to the disassembler
      s390/bug: add entry size to the __bug_table section
      s390: use proper expoline sections for .dma code
      s390/nospec: rename assembler generated expoline thunks
      s390: add missing ENDPROC statements to assembler functions
      locking/lockdep: check for freed initmem in static_obj()
      s390/kernel: add support for kernel address space layout randomization (KASLR)
      s390/kernel: introduce .dma sections
      s390/sclp: do not use static sccbs
      s390/kprobes: use static buffer for insn_page
      s390/kernel: convert SYSCALL and PGM_CHECK handlers to .quad
      s390/kernel: build a relocatable kernel
      ...

commit 78c98f9074135d3dab4e39544e0a537f92388fce
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Mon Jan 28 08:33:08 2019 +0100

    s390/unwind: introduce stack unwind API
    
    Rework the dump_trace() stack unwinder interface to support different
    unwinding algorithms. The new interface looks like this:
    
            struct unwind_state state;
            unwind_for_each_frame(&state, task, regs, start_stack)
                    do_something(state.sp, state.ip, state.reliable);
    
    The unwind_bc.c file contains the implementation for the classic
    back-chain unwinder.
    
    One positive side effect of the new code is it now handles ftraced
    functions gracefully. It prints the real name of the return function
    instead of 'return_to_handler'.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index 460dcfba7d4e..89f9f63dca18 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -11,40 +11,21 @@
 #include <linux/stacktrace.h>
 #include <linux/kallsyms.h>
 #include <linux/export.h>
-
-static int __save_address(void *data, unsigned long address, int nosched)
-{
-	struct stack_trace *trace = data;
-
-	if (nosched && in_sched_functions(address))
-		return 0;
-	if (trace->skip > 0) {
-		trace->skip--;
-		return 0;
-	}
-	if (trace->nr_entries < trace->max_entries) {
-		trace->entries[trace->nr_entries++] = address;
-		return 0;
-	}
-	return 1;
-}
-
-static int save_address(void *data, unsigned long address, int reliable)
-{
-	return __save_address(data, address, 0);
-}
-
-static int save_address_nosched(void *data, unsigned long address, int reliable)
-{
-	return __save_address(data, address, 1);
-}
+#include <asm/stacktrace.h>
+#include <asm/unwind.h>
 
 void save_stack_trace(struct stack_trace *trace)
 {
-	unsigned long sp;
+	struct unwind_state state;
 
-	sp = current_stack_pointer();
-	dump_trace(save_address, trace, NULL, sp);
+	unwind_for_each_frame(&state, current, NULL, 0) {
+		if (trace->nr_entries >= trace->max_entries)
+			break;
+		if (trace->skip > 0)
+			trace->skip--;
+		else
+			trace->entries[trace->nr_entries++] = state.ip;
+	}
 	if (trace->nr_entries < trace->max_entries)
 		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }
@@ -52,12 +33,18 @@ EXPORT_SYMBOL_GPL(save_stack_trace);
 
 void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 {
-	unsigned long sp;
+	struct unwind_state state;
 
-	sp = tsk->thread.ksp;
-	if (tsk == current)
-		sp = current_stack_pointer();
-	dump_trace(save_address_nosched, trace, tsk, sp);
+	unwind_for_each_frame(&state, tsk, NULL, 0) {
+		if (trace->nr_entries >= trace->max_entries)
+			break;
+		if (in_sched_functions(state.ip))
+			continue;
+		if (trace->skip > 0)
+			trace->skip--;
+		else
+			trace->entries[trace->nr_entries++] = state.ip;
+	}
 	if (trace->nr_entries < trace->max_entries)
 		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }
@@ -65,10 +52,16 @@ EXPORT_SYMBOL_GPL(save_stack_trace_tsk);
 
 void save_stack_trace_regs(struct pt_regs *regs, struct stack_trace *trace)
 {
-	unsigned long sp;
+	struct unwind_state state;
 
-	sp = kernel_stack_pointer(regs);
-	dump_trace(save_address, trace, NULL, sp);
+	unwind_for_each_frame(&state, current, regs, 0) {
+		if (trace->nr_entries >= trace->max_entries)
+			break;
+		if (trace->skip > 0)
+			trace->skip--;
+		else
+			trace->entries[trace->nr_entries++] = state.ip;
+	}
 	if (trace->nr_entries < trace->max_entries)
 		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }

commit 6a28b4c2d93b812512d8d2e5179e61a14f578560
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Apr 10 12:28:03 2019 +0200

    s390/stacktrace: Remove the pointless ULONG_MAX marker
    
    Terminating the last trace entry with ULONG_MAX is a completely pointless
    exercise and none of the consumers can rely on it because it's
    inconsistently implemented across architectures. In fact quite some of the
    callers remove the entry and adjust stack_trace.nr_entries afterwards.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: linux-s390@vger.kernel.org
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Link: https://lkml.kernel.org/r/20190410103644.396788431@linutronix.de

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index 460dcfba7d4e..cc9ed9787068 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -45,8 +45,6 @@ void save_stack_trace(struct stack_trace *trace)
 
 	sp = current_stack_pointer();
 	dump_trace(save_address, trace, NULL, sp);
-	if (trace->nr_entries < trace->max_entries)
-		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }
 EXPORT_SYMBOL_GPL(save_stack_trace);
 
@@ -58,8 +56,6 @@ void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 	if (tsk == current)
 		sp = current_stack_pointer();
 	dump_trace(save_address_nosched, trace, tsk, sp);
-	if (trace->nr_entries < trace->max_entries)
-		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }
 EXPORT_SYMBOL_GPL(save_stack_trace_tsk);
 
@@ -69,7 +65,5 @@ void save_stack_trace_regs(struct pt_regs *regs, struct stack_trace *trace)
 
 	sp = kernel_stack_pointer(regs);
 	dump_trace(save_address, trace, NULL, sp);
-	if (trace->nr_entries < trace->max_entries)
-		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }
 EXPORT_SYMBOL_GPL(save_stack_trace_regs);

commit a17ae4c3a6add7579e9962df5dd12cb1f3bed431
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Fri Nov 24 15:00:32 2017 +0100

    s390: kernel: add SPDX identifiers to the remaining files
    
    It's good to have SPDX identifiers in all files to make it easier to
    audit the kernel tree for correct licenses.
    
    Update the arch/s390/kernel/ files with the correct SPDX license
    identifier based on the license text in the file itself.  The SPDX
    identifier is a legally binding shorthand, which can be used instead of
    the full boiler plate text.
    
    This work is based on a script and data from Thomas Gleixner, Philippe
    Ombredanne, and Kate Stewart.
    
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Kate Stewart <kstewart@linuxfoundation.org>
    Cc: Philippe Ombredanne <pombredanne@nexb.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index e66687dc6144..460dcfba7d4e 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -1,3 +1,4 @@
+// SPDX-License-Identifier: GPL-2.0
 /*
  * Stack trace management functions
  *

commit b17b01533b719e9949e437abf66436a875739b40
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:35 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/debug.h>
    
    We are going to split <linux/sched/debug.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/debug.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index 0085b2d8ed7d..e66687dc6144 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -6,6 +6,7 @@
  */
 
 #include <linux/sched.h>
+#include <linux/sched/debug.h>
 #include <linux/stacktrace.h>
 #include <linux/kallsyms.h>
 #include <linux/export.h>

commit 3994a52b54569c4d71d43e3e00464eb9127f86a5
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Thu Feb 9 15:20:23 2017 -0500

    s390: kernel: Audit and remove any unnecessary uses of module.h
    
    Historically a lot of these existed because we did not have
    a distinction between what was modular code and what was providing
    support to modules via EXPORT_SYMBOL and friends.  That changed
    when we forked out support for the latter into the export.h file.
    
    This means we should be able to reduce the usage of module.h
    in code that is obj-y Makefile or bool Kconfig.  The advantage
    in doing so is that module.h itself sources about 15 other headers;
    adding significantly to what we feed cpp, and it can obscure what
    headers we are effectively using.
    
    Since module.h was the source for init.h (for __init) and for
    export.h (for EXPORT_SYMBOL) we consider each change instance
    for the presence of either and replace as needed.  Build testing
    revealed some implicit header usage that was fixed up accordingly.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index 355db9db8210..0085b2d8ed7d 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -8,7 +8,7 @@
 #include <linux/sched.h>
 #include <linux/stacktrace.h>
 #include <linux/kallsyms.h>
-#include <linux/module.h>
+#include <linux/export.h>
 
 static int __save_address(void *data, unsigned long address, int nosched)
 {

commit d0208639dbc6fe97a25054df44faa2d19aca9380
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon Oct 17 11:08:31 2016 +0200

    s390/dumpstack: restore reliable indicator for call traces
    
    Before merging all different stack tracers the call traces printed had
    an indicator if an entry can be considered reliable or not.
    Unreliable entries were put in braces, reliable not. Currently all
    lines contain these extra braces.
    
    This patch restores the old behaviour by adding an extra "reliable"
    parameter to the callback functions. Only show_trace makes currently
    use of it.
    
    Before:
    [    0.804751] Call Trace:
    [    0.804753] ([<000000000017d0e0>] try_to_wake_up+0x318/0x5e0)
    [    0.804756] ([<0000000000161d64>] create_worker+0x174/0x1c0)
    
    After:
    [    0.804751] Call Trace:
    [    0.804753] ([<000000000017d0e0>] try_to_wake_up+0x318/0x5e0)
    [    0.804756]  [<0000000000161d64>] create_worker+0x174/0x1c0
    
    Fixes: 758d39ebd3d5 ("s390/dumpstack: merge all four stack tracers")
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index 44f84b23d4e5..355db9db8210 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -27,12 +27,12 @@ static int __save_address(void *data, unsigned long address, int nosched)
 	return 1;
 }
 
-static int save_address(void *data, unsigned long address)
+static int save_address(void *data, unsigned long address, int reliable)
 {
 	return __save_address(data, address, 0);
 }
 
-static int save_address_nosched(void *data, unsigned long address)
+static int save_address_nosched(void *data, unsigned long address, int reliable)
 {
 	return __save_address(data, address, 1);
 }

commit 758d39ebd3d5666edb3b1c339f7f138c349ff8bf
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Tue Feb 9 12:58:54 2016 +0100

    s390/dumpstack: merge all four stack tracers
    
    We have four different stack tracers of which three had bugs. So it's
    time to merge them to a single stack tracer which allows to specify a
    call back function which will be called for each step.
    
    This patch changes behavior a bit:
    
    - the "nosched" and "in_sched_functions" check within
      save_stack_trace_tsk did work only for the last stack frame within a
      context. Now it considers the check for each stack frame like it
      should.
    
    - both the oprofile variant and the perf_events variant did save a
      return address twice if a zero back chain was detected, which
      indicates an interrupt frame. The new dump_trace function will call
      the oprofile and perf_events backends with the psw address that is
      contained within the corresponding pt_regs structure instead.
    
    - the original show_trace and save_context_stack functions did already
      use the psw address of the pt_regs structure if a zero back chain
      was detected. However now we ignore the psw address if it is a user
      space address. After all we trace the kernel stack and not the user
      space stack. This way we also get rid of the garbage user space
      address in case of warnings and / or panic call traces.
    
    So this should make life easier since now there is only one stack
    tracer left which we can break.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index 7dd8360b1c39..44f84b23d4e5 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -10,69 +10,31 @@
 #include <linux/kallsyms.h>
 #include <linux/module.h>
 
-static unsigned long save_context_stack(struct stack_trace *trace,
-					unsigned long sp,
-					unsigned long low,
-					unsigned long high,
-					int nosched)
+static int __save_address(void *data, unsigned long address, int nosched)
 {
-	struct stack_frame *sf;
-	struct pt_regs *regs;
-	unsigned long addr;
+	struct stack_trace *trace = data;
 
-	while(1) {
-		if (sp < low || sp > high)
-			return sp;
-		sf = (struct stack_frame *)sp;
-		while(1) {
-			addr = sf->gprs[8];
-			if (!trace->skip)
-				trace->entries[trace->nr_entries++] = addr;
-			else
-				trace->skip--;
-			if (trace->nr_entries >= trace->max_entries)
-				return sp;
-			low = sp;
-			sp = sf->back_chain;
-			if (!sp)
-				break;
-			if (sp <= low || sp > high - sizeof(*sf))
-				return sp;
-			sf = (struct stack_frame *)sp;
-		}
-		/* Zero backchain detected, check for interrupt frame. */
-		sp = (unsigned long)(sf + 1);
-		if (sp <= low || sp > high - sizeof(*regs))
-			return sp;
-		regs = (struct pt_regs *)sp;
-		addr = regs->psw.addr;
-		if (!nosched || !in_sched_functions(addr)) {
-			if (!trace->skip)
-				trace->entries[trace->nr_entries++] = addr;
-			else
-				trace->skip--;
-		}
-		if (trace->nr_entries >= trace->max_entries)
-			return sp;
-		low = sp;
-		sp = regs->gprs[15];
+	if (nosched && in_sched_functions(address))
+		return 0;
+	if (trace->skip > 0) {
+		trace->skip--;
+		return 0;
 	}
+	if (trace->nr_entries < trace->max_entries) {
+		trace->entries[trace->nr_entries++] = address;
+		return 0;
+	}
+	return 1;
 }
 
-static void __save_stack_trace(struct stack_trace *trace, unsigned long sp)
+static int save_address(void *data, unsigned long address)
 {
-	unsigned long new_sp, frame_size;
+	return __save_address(data, address, 0);
+}
 
-	frame_size = STACK_FRAME_OVERHEAD + sizeof(struct pt_regs);
-	new_sp = save_context_stack(trace, sp,
-			S390_lowcore.panic_stack + frame_size - PAGE_SIZE,
-			S390_lowcore.panic_stack + frame_size, 0);
-	new_sp = save_context_stack(trace, new_sp,
-			S390_lowcore.async_stack + frame_size - ASYNC_SIZE,
-			S390_lowcore.async_stack + frame_size, 0);
-	save_context_stack(trace, new_sp,
-			   S390_lowcore.thread_info,
-			   S390_lowcore.thread_info + THREAD_SIZE, 0);
+static int save_address_nosched(void *data, unsigned long address)
+{
+	return __save_address(data, address, 1);
 }
 
 void save_stack_trace(struct stack_trace *trace)
@@ -80,7 +42,7 @@ void save_stack_trace(struct stack_trace *trace)
 	unsigned long sp;
 
 	sp = current_stack_pointer();
-	__save_stack_trace(trace, sp);
+	dump_trace(save_address, trace, NULL, sp);
 	if (trace->nr_entries < trace->max_entries)
 		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }
@@ -88,14 +50,12 @@ EXPORT_SYMBOL_GPL(save_stack_trace);
 
 void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 {
-	unsigned long sp, low, high;
+	unsigned long sp;
 
 	sp = tsk->thread.ksp;
 	if (tsk == current)
 		sp = current_stack_pointer();
-	low = (unsigned long) task_stack_page(tsk);
-	high = (unsigned long) task_pt_regs(tsk);
-	save_context_stack(trace, sp, low, high, 1);
+	dump_trace(save_address_nosched, trace, tsk, sp);
 	if (trace->nr_entries < trace->max_entries)
 		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }
@@ -106,7 +66,7 @@ void save_stack_trace_regs(struct pt_regs *regs, struct stack_trace *trace)
 	unsigned long sp;
 
 	sp = kernel_stack_pointer(regs);
-	__save_stack_trace(trace, sp);
+	dump_trace(save_address, trace, NULL, sp);
 	if (trace->nr_entries < trace->max_entries)
 		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }

commit 76737ce17ab4c88f14e4452076610474108246d7
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Sun Jan 31 17:06:16 2016 +0100

    s390: add current_stack_pointer() helper function
    
    Implement current_stack_pointer() helper function and use it
    everywhere, instead of having several different inline assembly
    variants.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Tested-by: Peter Oberparleiter <oberpar@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index 3872d14fe1a1..7dd8360b1c39 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -77,10 +77,9 @@ static void __save_stack_trace(struct stack_trace *trace, unsigned long sp)
 
 void save_stack_trace(struct stack_trace *trace)
 {
-	register unsigned long r15 asm ("15");
 	unsigned long sp;
 
-	sp = r15;
+	sp = current_stack_pointer();
 	__save_stack_trace(trace, sp);
 	if (trace->nr_entries < trace->max_entries)
 		trace->entries[trace->nr_entries++] = ULONG_MAX;
@@ -92,10 +91,8 @@ void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 	unsigned long sp, low, high;
 
 	sp = tsk->thread.ksp;
-	if (tsk == current) {
-		/* Get current stack pointer. */
-		asm volatile("la %0,0(15)" : "=a" (sp));
-	}
+	if (tsk == current)
+		sp = current_stack_pointer();
 	low = (unsigned long) task_stack_page(tsk);
 	high = (unsigned long) task_pt_regs(tsk);
 	save_context_stack(trace, sp, low, high, 1);

commit 77ec8a545136272ca3056ca3759836df0cfee5e5
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon Feb 1 14:12:08 2016 +0100

    s390/stacktrace: use nosched instead of savesched parameter
    
    Use the inversed "nosched" logic like all other architectures.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Tested-by: Peter Oberparleiter <oberpar@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index 8f64ebd63767..3872d14fe1a1 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -14,7 +14,7 @@ static unsigned long save_context_stack(struct stack_trace *trace,
 					unsigned long sp,
 					unsigned long low,
 					unsigned long high,
-					int savesched)
+					int nosched)
 {
 	struct stack_frame *sf;
 	struct pt_regs *regs;
@@ -46,7 +46,7 @@ static unsigned long save_context_stack(struct stack_trace *trace,
 			return sp;
 		regs = (struct pt_regs *)sp;
 		addr = regs->psw.addr;
-		if (savesched || !in_sched_functions(addr)) {
+		if (!nosched || !in_sched_functions(addr)) {
 			if (!trace->skip)
 				trace->entries[trace->nr_entries++] = addr;
 			else
@@ -66,13 +66,13 @@ static void __save_stack_trace(struct stack_trace *trace, unsigned long sp)
 	frame_size = STACK_FRAME_OVERHEAD + sizeof(struct pt_regs);
 	new_sp = save_context_stack(trace, sp,
 			S390_lowcore.panic_stack + frame_size - PAGE_SIZE,
-			S390_lowcore.panic_stack + frame_size, 1);
+			S390_lowcore.panic_stack + frame_size, 0);
 	new_sp = save_context_stack(trace, new_sp,
 			S390_lowcore.async_stack + frame_size - ASYNC_SIZE,
-			S390_lowcore.async_stack + frame_size, 1);
+			S390_lowcore.async_stack + frame_size, 0);
 	save_context_stack(trace, new_sp,
 			   S390_lowcore.thread_info,
-			   S390_lowcore.thread_info + THREAD_SIZE, 1);
+			   S390_lowcore.thread_info + THREAD_SIZE, 0);
 }
 
 void save_stack_trace(struct stack_trace *trace)
@@ -98,7 +98,7 @@ void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 	}
 	low = (unsigned long) task_stack_page(tsk);
 	high = (unsigned long) task_pt_regs(tsk);
-	save_context_stack(trace, sp, low, high, 0);
+	save_context_stack(trace, sp, low, high, 1);
 	if (trace->nr_entries < trace->max_entries)
 		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }

commit e0115875c04548255212ebd7dbd90bdbe1257f48
Author: Pratyush Anand <panand@redhat.com>
Date:   Fri Jan 29 10:50:28 2016 +0530

    s390/stacktrace: add save_stack_trace_regs()
    
    Implement save_stack_trace_regs, so that a stack trace of a kprobe
    event can be obtained.
    
    Without this we see following warning:
    "save_stack_trace_regs() not implemented yet."
    when we execute:
    echo stacktrace > /sys/kernel/debug/tracing/trace_options
    echo "p kfree" >> /sys/kernel/debug/tracing/kprobe_events
    echo 1 > /sys/kernel/debug/tracing/events/kprobes/enable
    
    Reported-by: Chunyu Hu <chuhu@redhat.com>
    Signed-off-by: Pratyush Anand <panand@redhat.com>
    [heiko.carstens@de.ibm.com]: changed patch to use __save_stack_trace()
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Tested-by: Peter Oberparleiter <oberpar@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index e0fec2d8ac40..8f64ebd63767 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -103,3 +103,14 @@ void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }
 EXPORT_SYMBOL_GPL(save_stack_trace_tsk);
+
+void save_stack_trace_regs(struct pt_regs *regs, struct stack_trace *trace)
+{
+	unsigned long sp;
+
+	sp = kernel_stack_pointer(regs);
+	__save_stack_trace(trace, sp);
+	if (trace->nr_entries < trace->max_entries)
+		trace->entries[trace->nr_entries++] = ULONG_MAX;
+}
+EXPORT_SYMBOL_GPL(save_stack_trace_regs);

commit 66adce8f1f9f3bcd743a0e72c10aa850df8c5fa7
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon Feb 1 14:14:04 2016 +0100

    s390/stacktrace: save full stack traces
    
    save_stack_trace() only saves the stack trace of the current context
    (interrupt or process context). This is different to what other
    architectures like x86 do, which save the full stack trace across
    different contexts.
    
    Also extract a __save_stack_trace() helper function which will be used
    by a follow on patch.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Tested-by: Peter Oberparleiter <oberpar@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index 75e6ea930692..e0fec2d8ac40 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -59,26 +59,29 @@ static unsigned long save_context_stack(struct stack_trace *trace,
 	}
 }
 
-void save_stack_trace(struct stack_trace *trace)
+static void __save_stack_trace(struct stack_trace *trace, unsigned long sp)
 {
-	register unsigned long sp asm ("15");
-	unsigned long orig_sp, new_sp, frame_size;
+	unsigned long new_sp, frame_size;
 
 	frame_size = STACK_FRAME_OVERHEAD + sizeof(struct pt_regs);
-	orig_sp = sp;
-	new_sp = save_context_stack(trace, orig_sp,
+	new_sp = save_context_stack(trace, sp,
 			S390_lowcore.panic_stack + frame_size - PAGE_SIZE,
 			S390_lowcore.panic_stack + frame_size, 1);
-	if (new_sp != orig_sp)
-		return;
 	new_sp = save_context_stack(trace, new_sp,
 			S390_lowcore.async_stack + frame_size - ASYNC_SIZE,
 			S390_lowcore.async_stack + frame_size, 1);
-	if (new_sp != orig_sp)
-		return;
 	save_context_stack(trace, new_sp,
 			   S390_lowcore.thread_info,
 			   S390_lowcore.thread_info + THREAD_SIZE, 1);
+}
+
+void save_stack_trace(struct stack_trace *trace)
+{
+	register unsigned long r15 asm ("15");
+	unsigned long sp;
+
+	sp = r15;
+	__save_stack_trace(trace, sp);
 	if (trace->nr_entries < trace->max_entries)
 		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }

commit f6331aaccbd980a49bff1559d66abcbd46af5b0a
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon Feb 1 14:06:57 2016 +0100

    s390/stacktrace: add missing end marker
    
    save_stack_trace() did not write the ULONG_MAX end marker if there is
    enough space left. So simply follow x86 and arm64.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Tested-by: Peter Oberparleiter <oberpar@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index 225bed00aa92..75e6ea930692 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -79,6 +79,8 @@ void save_stack_trace(struct stack_trace *trace)
 	save_context_stack(trace, new_sp,
 			   S390_lowcore.thread_info,
 			   S390_lowcore.thread_info + THREAD_SIZE, 1);
+	if (trace->nr_entries < trace->max_entries)
+		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }
 EXPORT_SYMBOL_GPL(save_stack_trace);
 

commit 9900c48c46d8bcf497972024c5fe366e6d9771f3
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon Feb 1 10:13:05 2016 +0100

    s390/stacktrace: fix address ranges for asynchronous and panic stack
    
    git commit dc7ee00d4771 ("s390: lowcore stack pointer offsets")
    introduced a regression in regard to save_stack_trace(). The stack
    pointer for the asynchronous and the panic stack in the lowcore now
    have an additional offset applied to them. This offset needs to be
    taken into account in the calculation for the low and high address for
    the stacks.
    
    This bug was already partially fixed with 9cc5c206d9b4
    ("s390/dumpstack: fix address ranges for asynchronous and panic
    stack"). This patch fixes it also for the stacktrace code.
    
    Fixes: dc7ee00d4771 ("s390: lowcore stack pointer offsets")
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Tested-by: Peter Oberparleiter <oberpar@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index dd484c75be56..225bed00aa92 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -62,17 +62,18 @@ static unsigned long save_context_stack(struct stack_trace *trace,
 void save_stack_trace(struct stack_trace *trace)
 {
 	register unsigned long sp asm ("15");
-	unsigned long orig_sp, new_sp;
+	unsigned long orig_sp, new_sp, frame_size;
 
+	frame_size = STACK_FRAME_OVERHEAD + sizeof(struct pt_regs);
 	orig_sp = sp;
 	new_sp = save_context_stack(trace, orig_sp,
-				    S390_lowcore.panic_stack - PAGE_SIZE,
-				    S390_lowcore.panic_stack, 1);
+			S390_lowcore.panic_stack + frame_size - PAGE_SIZE,
+			S390_lowcore.panic_stack + frame_size, 1);
 	if (new_sp != orig_sp)
 		return;
 	new_sp = save_context_stack(trace, new_sp,
-				    S390_lowcore.async_stack - ASYNC_SIZE,
-				    S390_lowcore.async_stack, 1);
+			S390_lowcore.async_stack + frame_size - ASYNC_SIZE,
+			S390_lowcore.async_stack + frame_size, 1);
 	if (new_sp != orig_sp)
 		return;
 	save_context_stack(trace, new_sp,

commit 665ca9187c4087736fa57b0e00bcf33ea601fb6f
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Sun Jan 31 14:23:30 2016 +0100

    s390/stacktrace: fix save_stack_trace_tsk() for current task
    
    The function save_stack_trace_tsk() did not consider that it can be
    used for tsk == current, for which the current stack pointer obviously
    cannot be found in the thread structure.
    
    Fix this and get the stack pointer with an inline assembly.
    
    This fixes e.g. the output of "cat /proc/self/stack".
    
    Before:
    [<0000000000000000>]           (null)
    [<ffffffffffffffff>] 0xffffffffffffffff
    
    After:
    [<000000000011b3ee>] save_stack_trace_tsk+0x56/0x98
    [<0000000000366cde>] proc_pid_stack+0xae/0x108
    [<00000000003636f0>] proc_single_show+0x70/0xc0
    [<0000000000311fbc>] seq_read+0xcc/0x448
    [<00000000002e7716>] __vfs_read+0x36/0x100
    [<00000000002e872e>] vfs_read+0x76/0x130
    [<00000000002e975e>] SyS_read+0x66/0xd8
    [<000000000089490e>] system_call+0xd6/0x264
    [<ffffffffffffffff>] 0xffffffffffffffff
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Tested-by: Peter Oberparleiter <oberpar@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index 5acba3cb7220..dd484c75be56 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -86,6 +86,10 @@ void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 	unsigned long sp, low, high;
 
 	sp = tsk->thread.ksp;
+	if (tsk == current) {
+		/* Get current stack pointer. */
+		asm volatile("la %0,0(15)" : "=a" (sp));
+	}
 	low = (unsigned long) task_stack_page(tsk);
 	high = (unsigned long) task_pt_regs(tsk);
 	save_context_stack(trace, sp, low, high, 0);

commit 9cb1ccecb69d133e014b7be4de2609f689398c07
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon Jan 18 13:12:19 2016 +0100

    s390: remove all usages of PSW_ADDR_INSN
    
    Yet another leftover from the 31 bit era. The usual operation
    "y = x & PSW_ADDR_INSN" with the PSW_ADDR_INSN mask is a nop for
    CONFIG_64BIT.
    
    Therefore remove all usages and hope the code is a bit less confusing.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Reviewed-by: David Hildenbrand <dahi@linux.vnet.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index 1785cd82253c..5acba3cb7220 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -21,12 +21,11 @@ static unsigned long save_context_stack(struct stack_trace *trace,
 	unsigned long addr;
 
 	while(1) {
-		sp &= PSW_ADDR_INSN;
 		if (sp < low || sp > high)
 			return sp;
 		sf = (struct stack_frame *)sp;
 		while(1) {
-			addr = sf->gprs[8] & PSW_ADDR_INSN;
+			addr = sf->gprs[8];
 			if (!trace->skip)
 				trace->entries[trace->nr_entries++] = addr;
 			else
@@ -34,7 +33,7 @@ static unsigned long save_context_stack(struct stack_trace *trace,
 			if (trace->nr_entries >= trace->max_entries)
 				return sp;
 			low = sp;
-			sp = sf->back_chain & PSW_ADDR_INSN;
+			sp = sf->back_chain;
 			if (!sp)
 				break;
 			if (sp <= low || sp > high - sizeof(*sf))
@@ -46,7 +45,7 @@ static unsigned long save_context_stack(struct stack_trace *trace,
 		if (sp <= low || sp > high - sizeof(*regs))
 			return sp;
 		regs = (struct pt_regs *)sp;
-		addr = regs->psw.addr & PSW_ADDR_INSN;
+		addr = regs->psw.addr;
 		if (savesched || !in_sched_functions(addr)) {
 			if (!trace->skip)
 				trace->entries[trace->nr_entries++] = addr;
@@ -65,7 +64,7 @@ void save_stack_trace(struct stack_trace *trace)
 	register unsigned long sp asm ("15");
 	unsigned long orig_sp, new_sp;
 
-	orig_sp = sp & PSW_ADDR_INSN;
+	orig_sp = sp;
 	new_sp = save_context_stack(trace, orig_sp,
 				    S390_lowcore.panic_stack - PAGE_SIZE,
 				    S390_lowcore.panic_stack, 1);
@@ -86,7 +85,7 @@ void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 {
 	unsigned long sp, low, high;
 
-	sp = tsk->thread.ksp & PSW_ADDR_INSN;
+	sp = tsk->thread.ksp;
 	low = (unsigned long) task_stack_page(tsk);
 	high = (unsigned long) task_pt_regs(tsk);
 	save_context_stack(trace, sp, low, high, 0);

commit a53c8fab3f87c995c30ac226a03af95361243144
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Fri Jul 20 11:15:04 2012 +0200

    s390/comments: unify copyright messages and remove file names
    
    Remove the file name from the comment at top of many files. In most
    cases the file name was wrong anyway, so it's rather pointless.
    
    Also unify the IBM copyright statement. We did have a lot of sightly
    different statements and wanted to change them one after another
    whenever a file gets touched. However that never happened. Instead
    people start to take the old/"wrong" statements to use as a template
    for new files.
    So unify all of them in one go.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index 8841919ef7e6..1785cd82253c 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -1,9 +1,7 @@
 /*
- * arch/s390/kernel/stacktrace.c
- *
  * Stack trace management functions
  *
- *  Copyright (C) IBM Corp. 2006
+ *  Copyright IBM Corp. 2006
  *  Author(s): Heiko Carstens <heiko.carstens@de.ibm.com>
  */
 

commit 8de2ce86cdde64d00fc4a4034008b35d8fc0dc83
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Thu Jul 17 17:16:45 2008 +0200

    [S390] Fix stacktrace compile bug.
    
    Add missing module.h include to fix this:
    
      CC      arch/s390/kernel/stacktrace.o
    arch/s390/kernel/stacktrace.c:84: warning: data definition has no type or storage class
    arch/s390/kernel/stacktrace.c:84: warning: type defaults to 'int' in declaration of 'EXPORT_SYMBOL_GPL'
    arch/s390/kernel/stacktrace.c:84: warning: parameter names (without types) in function declaration
    arch/s390/kernel/stacktrace.c:97: warning: data definition has no type or storage class
    arch/s390/kernel/stacktrace.c:97: warning: type defaults to 'int' in declaration of 'EXPORT_SYMBOL_GPL'
    arch/s390/kernel/stacktrace.c:97: warning: parameter names (without types) in function declaration
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index 57571f10270c..8841919ef7e6 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -10,6 +10,7 @@
 #include <linux/sched.h>
 #include <linux/stacktrace.h>
 #include <linux/kallsyms.h>
+#include <linux/module.h>
 
 static unsigned long save_context_stack(struct stack_trace *trace,
 					unsigned long sp,

commit 7b4c9505f2fd82b117dd015b561f723b9a5dab79
Author: Ingo Molnar <mingo@elte.hu>
Date:   Thu Jul 3 09:17:55 2008 +0200

    stacktrace: export save_stack_trace[_tsk]
    
    Andrew Morton reported this against linux-next:
    
    ERROR: ".save_stack_trace" [tests/backtracetest.ko] undefined!
    
    Reported-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index 85e46a5d0e08..57571f10270c 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -81,6 +81,7 @@ void save_stack_trace(struct stack_trace *trace)
 			   S390_lowcore.thread_info,
 			   S390_lowcore.thread_info + THREAD_SIZE, 1);
 }
+EXPORT_SYMBOL_GPL(save_stack_trace);
 
 void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 {
@@ -93,3 +94,4 @@ void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
 	if (trace->nr_entries < trace->max_entries)
 		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }
+EXPORT_SYMBOL_GPL(save_stack_trace_tsk);

commit a3afe70b83fdbbd4d757d2911900d168bc798a31
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Tue Feb 5 16:50:45 2008 +0100

    [S390] latencytop s390 support.
    
    Cc: Holger Wolf <wolf@linux.vnet.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index da6924729964..85e46a5d0e08 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -14,7 +14,8 @@
 static unsigned long save_context_stack(struct stack_trace *trace,
 					unsigned long sp,
 					unsigned long low,
-					unsigned long high)
+					unsigned long high,
+					int savesched)
 {
 	struct stack_frame *sf;
 	struct pt_regs *regs;
@@ -47,10 +48,12 @@ static unsigned long save_context_stack(struct stack_trace *trace,
 			return sp;
 		regs = (struct pt_regs *)sp;
 		addr = regs->psw.addr & PSW_ADDR_INSN;
-		if (!trace->skip)
-			trace->entries[trace->nr_entries++] = addr;
-		else
-			trace->skip--;
+		if (savesched || !in_sched_functions(addr)) {
+			if (!trace->skip)
+				trace->entries[trace->nr_entries++] = addr;
+			else
+				trace->skip--;
+		}
 		if (trace->nr_entries >= trace->max_entries)
 			return sp;
 		low = sp;
@@ -66,15 +69,27 @@ void save_stack_trace(struct stack_trace *trace)
 	orig_sp = sp & PSW_ADDR_INSN;
 	new_sp = save_context_stack(trace, orig_sp,
 				    S390_lowcore.panic_stack - PAGE_SIZE,
-				    S390_lowcore.panic_stack);
+				    S390_lowcore.panic_stack, 1);
 	if (new_sp != orig_sp)
 		return;
 	new_sp = save_context_stack(trace, new_sp,
 				    S390_lowcore.async_stack - ASYNC_SIZE,
-				    S390_lowcore.async_stack);
+				    S390_lowcore.async_stack, 1);
 	if (new_sp != orig_sp)
 		return;
 	save_context_stack(trace, new_sp,
 			   S390_lowcore.thread_info,
-			   S390_lowcore.thread_info + THREAD_SIZE);
+			   S390_lowcore.thread_info + THREAD_SIZE, 1);
+}
+
+void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
+{
+	unsigned long sp, low, high;
+
+	sp = tsk->thread.ksp & PSW_ADDR_INSN;
+	low = (unsigned long) task_stack_page(tsk);
+	high = (unsigned long) task_pt_regs(tsk);
+	save_context_stack(trace, sp, low, high, 0);
+	if (trace->nr_entries < trace->max_entries)
+		trace->entries[trace->nr_entries++] = ULONG_MAX;
 }

commit e90a2857c666913258528ce96decc43c749bbf95
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Tue Jul 17 13:36:07 2007 +0200

    [S390] Simplify stack trace.
    
    sparse gives us a few of these:
    stacktrace.c:69:38: warning: incorrect type in argument 2
                        (different signedness)
    stacktrace.c:69:38:    expected unsigned int *skip
    
    Just get rid of the 'skip' argument since it is contained in the
    struct stack_trace that gets passed anyway.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index 515ff9011dd7..da6924729964 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -12,7 +12,6 @@
 #include <linux/kallsyms.h>
 
 static unsigned long save_context_stack(struct stack_trace *trace,
-					unsigned int *skip,
 					unsigned long sp,
 					unsigned long low,
 					unsigned long high)
@@ -28,10 +27,10 @@ static unsigned long save_context_stack(struct stack_trace *trace,
 		sf = (struct stack_frame *)sp;
 		while(1) {
 			addr = sf->gprs[8] & PSW_ADDR_INSN;
-			if (!(*skip))
+			if (!trace->skip)
 				trace->entries[trace->nr_entries++] = addr;
 			else
-				(*skip)--;
+				trace->skip--;
 			if (trace->nr_entries >= trace->max_entries)
 				return sp;
 			low = sp;
@@ -48,10 +47,10 @@ static unsigned long save_context_stack(struct stack_trace *trace,
 			return sp;
 		regs = (struct pt_regs *)sp;
 		addr = regs->psw.addr & PSW_ADDR_INSN;
-		if (!(*skip))
+		if (!trace->skip)
 			trace->entries[trace->nr_entries++] = addr;
 		else
-			(*skip)--;
+			trace->skip--;
 		if (trace->nr_entries >= trace->max_entries)
 			return sp;
 		low = sp;
@@ -65,20 +64,17 @@ void save_stack_trace(struct stack_trace *trace)
 	unsigned long orig_sp, new_sp;
 
 	orig_sp = sp & PSW_ADDR_INSN;
-
-	new_sp = save_context_stack(trace, &trace->skip, orig_sp,
-				S390_lowcore.panic_stack - PAGE_SIZE,
-				S390_lowcore.panic_stack);
+	new_sp = save_context_stack(trace, orig_sp,
+				    S390_lowcore.panic_stack - PAGE_SIZE,
+				    S390_lowcore.panic_stack);
 	if (new_sp != orig_sp)
 		return;
-	new_sp = save_context_stack(trace, &trace->skip, new_sp,
-				S390_lowcore.async_stack - ASYNC_SIZE,
-				S390_lowcore.async_stack);
+	new_sp = save_context_stack(trace, new_sp,
+				    S390_lowcore.async_stack - ASYNC_SIZE,
+				    S390_lowcore.async_stack);
 	if (new_sp != orig_sp)
 		return;
-
-	save_context_stack(trace, &trace->skip, new_sp,
+	save_context_stack(trace, new_sp,
 			   S390_lowcore.thread_info,
 			   S390_lowcore.thread_info + THREAD_SIZE);
-	return;
 }

commit ab1b6f03a10ba1f5638188ab06bf46e33ac3a160
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue May 8 00:23:29 2007 -0700

    simplify the stacktrace code
    
    Simplify the stacktrace code:
    
     - remove the unused task argument to save_stack_trace, it's always
       current
     - remove the all_contexts flag, it's alwasy 0
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Andi Kleen <ak@suse.de>
    Cc: Akinobu Mita <akinobu.mita@gmail.com>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index 2e5c65a1863e..515ff9011dd7 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -59,7 +59,7 @@ static unsigned long save_context_stack(struct stack_trace *trace,
 	}
 }
 
-void save_stack_trace(struct stack_trace *trace, struct task_struct *task)
+void save_stack_trace(struct stack_trace *trace)
 {
 	register unsigned long sp asm ("15");
 	unsigned long orig_sp, new_sp;
@@ -69,20 +69,16 @@ void save_stack_trace(struct stack_trace *trace, struct task_struct *task)
 	new_sp = save_context_stack(trace, &trace->skip, orig_sp,
 				S390_lowcore.panic_stack - PAGE_SIZE,
 				S390_lowcore.panic_stack);
-	if ((new_sp != orig_sp) && !trace->all_contexts)
+	if (new_sp != orig_sp)
 		return;
 	new_sp = save_context_stack(trace, &trace->skip, new_sp,
 				S390_lowcore.async_stack - ASYNC_SIZE,
 				S390_lowcore.async_stack);
-	if ((new_sp != orig_sp) && !trace->all_contexts)
+	if (new_sp != orig_sp)
 		return;
-	if (task)
-		save_context_stack(trace, &trace->skip, new_sp,
-				   (unsigned long) task_stack_page(task),
-				   (unsigned long) task_stack_page(task) + THREAD_SIZE);
-	else
-		save_context_stack(trace, &trace->skip, new_sp,
-				   S390_lowcore.thread_info,
-				   S390_lowcore.thread_info + THREAD_SIZE);
+
+	save_context_stack(trace, &trace->skip, new_sp,
+			   S390_lowcore.thread_info,
+			   S390_lowcore.thread_info + THREAD_SIZE);
 	return;
 }

commit 4d284cac76d0bfebc42d76b428c4e44d921200a9
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon Feb 5 21:18:53 2007 +0100

    [S390] Avoid excessive inlining.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index 0d14a4789bf2..2e5c65a1863e 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -11,11 +11,11 @@
 #include <linux/stacktrace.h>
 #include <linux/kallsyms.h>
 
-static inline unsigned long save_context_stack(struct stack_trace *trace,
-					       unsigned int *skip,
-					       unsigned long sp,
-					       unsigned long low,
-					       unsigned long high)
+static unsigned long save_context_stack(struct stack_trace *trace,
+					unsigned int *skip,
+					unsigned long sp,
+					unsigned long low,
+					unsigned long high)
 {
 	struct stack_frame *sf;
 	struct pt_regs *regs;

commit 75e9de18f079a51fa987ef0703112d5bc125fdb7
Author: Christian Borntraeger <cborntra@de.ibm.com>
Date:   Wed Oct 11 15:31:52 2006 +0200

    [S390] stacktrace bug.
    
    The latest kernel 2.6.19-rc1 triggers a bug in the s390 specific stack
    trace code when compiled with gcc 3.4.
    This patch fixes the latest lock dependency validator code (2.6.19-rc1)
    on s390 gcc 3.4. The variable sp was fixed to r15 (which is the stack
    pointer in the s390 abi) and assigned new values to r15. Therefore,
    gcc 3.4 assigns a new value to r15 and does not restore it on exit (r15
    is supposed to be call save) - the kernel stack is broken. Avoid trouble
    by not assigning any new value to sp (r15).
    
    Signed-off-by: Christian Borntraeger <cborntra@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index d9428a0fc8fb..0d14a4789bf2 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -62,27 +62,26 @@ static inline unsigned long save_context_stack(struct stack_trace *trace,
 void save_stack_trace(struct stack_trace *trace, struct task_struct *task)
 {
 	register unsigned long sp asm ("15");
-	unsigned long orig_sp;
+	unsigned long orig_sp, new_sp;
 
-	sp &= PSW_ADDR_INSN;
-	orig_sp = sp;
+	orig_sp = sp & PSW_ADDR_INSN;
 
-	sp = save_context_stack(trace, &trace->skip, sp,
+	new_sp = save_context_stack(trace, &trace->skip, orig_sp,
 				S390_lowcore.panic_stack - PAGE_SIZE,
 				S390_lowcore.panic_stack);
-	if ((sp != orig_sp) && !trace->all_contexts)
+	if ((new_sp != orig_sp) && !trace->all_contexts)
 		return;
-	sp = save_context_stack(trace, &trace->skip, sp,
+	new_sp = save_context_stack(trace, &trace->skip, new_sp,
 				S390_lowcore.async_stack - ASYNC_SIZE,
 				S390_lowcore.async_stack);
-	if ((sp != orig_sp) && !trace->all_contexts)
+	if ((new_sp != orig_sp) && !trace->all_contexts)
 		return;
 	if (task)
-		save_context_stack(trace, &trace->skip, sp,
+		save_context_stack(trace, &trace->skip, new_sp,
 				   (unsigned long) task_stack_page(task),
 				   (unsigned long) task_stack_page(task) + THREAD_SIZE);
 	else
-		save_context_stack(trace, &trace->skip, sp,
+		save_context_stack(trace, &trace->skip, new_sp,
 				   S390_lowcore.thread_info,
 				   S390_lowcore.thread_info + THREAD_SIZE);
 	return;

commit 5a1b3999d6cb7ab87f1f3b1700bc91839fd6fa29
Author: Andi Kleen <ak@suse.de>
Date:   Tue Sep 26 10:52:34 2006 +0200

    [PATCH] x86: Some preparationary cleanup for stack trace
    
    - Remove unused all_contexts parameter
    No caller used it
    - Move skip argument into the structure (needed for
    followon patches)
    
    Cc: mingo@elte.hu
    
    Signed-off-by: Andi Kleen <ak@suse.de>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
index de83f38288d0..d9428a0fc8fb 100644
--- a/arch/s390/kernel/stacktrace.c
+++ b/arch/s390/kernel/stacktrace.c
@@ -59,9 +59,7 @@ static inline unsigned long save_context_stack(struct stack_trace *trace,
 	}
 }
 
-void save_stack_trace(struct stack_trace *trace,
-		      struct task_struct *task, int all_contexts,
-		      unsigned int skip)
+void save_stack_trace(struct stack_trace *trace, struct task_struct *task)
 {
 	register unsigned long sp asm ("15");
 	unsigned long orig_sp;
@@ -69,22 +67,23 @@ void save_stack_trace(struct stack_trace *trace,
 	sp &= PSW_ADDR_INSN;
 	orig_sp = sp;
 
-	sp = save_context_stack(trace, &skip, sp,
+	sp = save_context_stack(trace, &trace->skip, sp,
 				S390_lowcore.panic_stack - PAGE_SIZE,
 				S390_lowcore.panic_stack);
-	if ((sp != orig_sp) && !all_contexts)
+	if ((sp != orig_sp) && !trace->all_contexts)
 		return;
-	sp = save_context_stack(trace, &skip, sp,
+	sp = save_context_stack(trace, &trace->skip, sp,
 				S390_lowcore.async_stack - ASYNC_SIZE,
 				S390_lowcore.async_stack);
-	if ((sp != orig_sp) && !all_contexts)
+	if ((sp != orig_sp) && !trace->all_contexts)
 		return;
 	if (task)
-		save_context_stack(trace, &skip, sp,
+		save_context_stack(trace, &trace->skip, sp,
 				   (unsigned long) task_stack_page(task),
 				   (unsigned long) task_stack_page(task) + THREAD_SIZE);
 	else
-		save_context_stack(trace, &skip, sp, S390_lowcore.thread_info,
+		save_context_stack(trace, &trace->skip, sp,
+				   S390_lowcore.thread_info,
 				   S390_lowcore.thread_info + THREAD_SIZE);
 	return;
 }

commit 5bdc9b447c0076f494a56fdcd93ee8c5e78a2afd
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon Jul 3 00:24:41 2006 -0700

    [PATCH] lockdep: stacktrace subsystem, s390 support
    
    stacktrace interface for s390 as needed by lock validator.
    
    [clg@fr.ibm.com: build fix]
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Arjan van de Ven <arjan@infradead.org>
    Signed-off-by: Cedric Le Goater <clg@fr.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/s390/kernel/stacktrace.c b/arch/s390/kernel/stacktrace.c
new file mode 100644
index 000000000000..de83f38288d0
--- /dev/null
+++ b/arch/s390/kernel/stacktrace.c
@@ -0,0 +1,90 @@
+/*
+ * arch/s390/kernel/stacktrace.c
+ *
+ * Stack trace management functions
+ *
+ *  Copyright (C) IBM Corp. 2006
+ *  Author(s): Heiko Carstens <heiko.carstens@de.ibm.com>
+ */
+
+#include <linux/sched.h>
+#include <linux/stacktrace.h>
+#include <linux/kallsyms.h>
+
+static inline unsigned long save_context_stack(struct stack_trace *trace,
+					       unsigned int *skip,
+					       unsigned long sp,
+					       unsigned long low,
+					       unsigned long high)
+{
+	struct stack_frame *sf;
+	struct pt_regs *regs;
+	unsigned long addr;
+
+	while(1) {
+		sp &= PSW_ADDR_INSN;
+		if (sp < low || sp > high)
+			return sp;
+		sf = (struct stack_frame *)sp;
+		while(1) {
+			addr = sf->gprs[8] & PSW_ADDR_INSN;
+			if (!(*skip))
+				trace->entries[trace->nr_entries++] = addr;
+			else
+				(*skip)--;
+			if (trace->nr_entries >= trace->max_entries)
+				return sp;
+			low = sp;
+			sp = sf->back_chain & PSW_ADDR_INSN;
+			if (!sp)
+				break;
+			if (sp <= low || sp > high - sizeof(*sf))
+				return sp;
+			sf = (struct stack_frame *)sp;
+		}
+		/* Zero backchain detected, check for interrupt frame. */
+		sp = (unsigned long)(sf + 1);
+		if (sp <= low || sp > high - sizeof(*regs))
+			return sp;
+		regs = (struct pt_regs *)sp;
+		addr = regs->psw.addr & PSW_ADDR_INSN;
+		if (!(*skip))
+			trace->entries[trace->nr_entries++] = addr;
+		else
+			(*skip)--;
+		if (trace->nr_entries >= trace->max_entries)
+			return sp;
+		low = sp;
+		sp = regs->gprs[15];
+	}
+}
+
+void save_stack_trace(struct stack_trace *trace,
+		      struct task_struct *task, int all_contexts,
+		      unsigned int skip)
+{
+	register unsigned long sp asm ("15");
+	unsigned long orig_sp;
+
+	sp &= PSW_ADDR_INSN;
+	orig_sp = sp;
+
+	sp = save_context_stack(trace, &skip, sp,
+				S390_lowcore.panic_stack - PAGE_SIZE,
+				S390_lowcore.panic_stack);
+	if ((sp != orig_sp) && !all_contexts)
+		return;
+	sp = save_context_stack(trace, &skip, sp,
+				S390_lowcore.async_stack - ASYNC_SIZE,
+				S390_lowcore.async_stack);
+	if ((sp != orig_sp) && !all_contexts)
+		return;
+	if (task)
+		save_context_stack(trace, &skip, sp,
+				   (unsigned long) task_stack_page(task),
+				   (unsigned long) task_stack_page(task) + THREAD_SIZE);
+	else
+		save_context_stack(trace, &skip, sp, S390_lowcore.thread_info,
+				   S390_lowcore.thread_info + THREAD_SIZE);
+	return;
+}
