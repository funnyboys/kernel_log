commit 4ac24c092b4eef69b2436ee4d478500dc886e8b5
Author: Vasily Gorbik <gor@linux.ibm.com>
Date:   Mon Nov 25 13:34:59 2019 +0100

    s390: fix register clobbering in CALL_ON_STACK
    
    CALL_ON_STACK defines and initializes register variables. Inline
    assembly which follows might trigger compiler to generate memory access
    for "stack" argument (e.g. in case of S390_lowcore.nodat_stack). This
    memory access produces a function call under kasan with outline
    instrumentation which clobbers registers.
    
    Switch "stack" argument in CALL_ON_STACK helper to use memory reference
    constraint and perform load instead.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/arch/s390/include/asm/stacktrace.h b/arch/s390/include/asm/stacktrace.h
index 4725315a9cb1..ee056f4a4fa3 100644
--- a/arch/s390/include/asm/stacktrace.h
+++ b/arch/s390/include/asm/stacktrace.h
@@ -112,12 +112,12 @@ struct stack_frame {
 									\
 	asm volatile(							\
 		"	la	%[_prev],0(15)\n"			\
-		"	la	15,0(%[_stack])\n"			\
+		"	lg	15,%[_stack]\n"				\
 		"	stg	%[_frame],%[_bc](15)\n"			\
 		"	brasl	14,%[_fn]\n"				\
 		"	la	15,0(%[_prev])\n"			\
 		: [_prev] "=&a" (prev), CALL_FMT_##nr			\
-		  [_stack] "a" (stack),					\
+		  [_stack] "R" (stack),					\
 		  [_bc] "i" (offsetof(struct stack_frame, back_chain)),	\
 		  [_frame] "d" (frame),					\
 		  [_fn] "X" (fn) : CALL_CLOBBER_##nr);			\

commit adcfb8cdc910bdd0b5d52d2ba88103af93dc43d3
Author: Vasily Gorbik <gor@linux.ibm.com>
Date:   Tue Nov 26 17:40:04 2019 +0100

    s390/unwind: always inline get_stack_pointer
    
    Always inline get_stack_pointer() to avoid potential problems
    due to compiler inlining decisions, i.e. getting stack pointer of
    get_stack_pointer() itself which is later reused.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/arch/s390/include/asm/stacktrace.h b/arch/s390/include/asm/stacktrace.h
index 4f3dd1c86c0d..4725315a9cb1 100644
--- a/arch/s390/include/asm/stacktrace.h
+++ b/arch/s390/include/asm/stacktrace.h
@@ -33,8 +33,8 @@ static inline bool on_stack(struct stack_info *info,
 	return addr >= info->begin && addr + len <= info->end;
 }
 
-static inline unsigned long get_stack_pointer(struct task_struct *task,
-					      struct pt_regs *regs)
+static __always_inline unsigned long get_stack_pointer(struct task_struct *task,
+						       struct pt_regs *regs)
 {
 	if (regs)
 		return (unsigned long) kernel_stack_pointer(regs);

commit 7bcaad1f9fac889f5fcd1a383acf7e00d006da41
Author: Vasily Gorbik <gor@linux.ibm.com>
Date:   Fri Nov 22 13:12:57 2019 +0100

    s390: avoid misusing CALL_ON_STACK for task stack setup
    
    CALL_ON_STACK is intended to be used for temporary stack switching with
    potential return to the caller.
    
    When CALL_ON_STACK is misused to switch from nodat stack to task stack
    back_chain information would later lead stack unwinder from task stack into
    (per cpu) nodat stack which is reused for other purposes. This would
    yield confusing unwinding result or errors.
    
    To avoid that introduce CALL_ON_STACK_NORETURN to be used instead. It
    makes sure that back_chain is zeroed and unwinder finishes gracefully
    ending up at task pt_regs.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/arch/s390/include/asm/stacktrace.h b/arch/s390/include/asm/stacktrace.h
index bb854e33e460..4f3dd1c86c0d 100644
--- a/arch/s390/include/asm/stacktrace.h
+++ b/arch/s390/include/asm/stacktrace.h
@@ -124,4 +124,15 @@ struct stack_frame {
 	r2;								\
 })
 
+#define CALL_ON_STACK_NORETURN(fn, stack)				\
+({									\
+	asm volatile(							\
+		"	la	15,0(%[_stack])\n"			\
+		"	xc	%[_bc](8,15),%[_bc](15)\n"		\
+		"	brasl	14,%[_fn]\n"				\
+		::[_bc] "i" (offsetof(struct stack_frame, back_chain)),	\
+		  [_stack] "a" (stack), [_fn] "X" (fn));		\
+	BUG();								\
+})
+
 #endif /* _ASM_S390_STACKTRACE_H */

commit 7579425777c0d802237e0d59ae395e8cf60723e1
Author: Vasily Gorbik <gor@linux.ibm.com>
Date:   Fri Nov 22 12:47:52 2019 +0100

    s390: correct CALL_ON_STACK back_chain saving
    
    Currently CALL_ON_STACK saves r15 as back_chain in the first stack frame of
    the stack we about to switch to. But if a function which uses CALL_ON_STACK
    calls other function it allocates a stack frame for a callee. In this
    case r15 is pointing to a callee stack frame and not a stack frame of
    function itself. This results in dummy unwinding entry with random
    sp and ip values.
    
    Introduce and utilize current_frame_address macro to get an address of
    actual function stack frame.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/arch/s390/include/asm/stacktrace.h b/arch/s390/include/asm/stacktrace.h
index 0ae4bbf7779c..bb854e33e460 100644
--- a/arch/s390/include/asm/stacktrace.h
+++ b/arch/s390/include/asm/stacktrace.h
@@ -62,6 +62,17 @@ struct stack_frame {
 };
 #endif
 
+/*
+ * Unlike current_stack_pointer() which simply returns current value of %r15
+ * current_frame_address() returns function stack frame address, which matches
+ * %r15 upon function invocation. It may differ from %r15 later if function
+ * allocates stack for local variables or new stack frame to call other
+ * functions.
+ */
+#define current_frame_address()						\
+	((unsigned long)__builtin_frame_address(0) -			\
+	 offsetof(struct stack_frame, back_chain))
+
 #define CALL_ARGS_0()							\
 	register unsigned long r2 asm("2")
 #define CALL_ARGS_1(arg1)						\
@@ -95,18 +106,20 @@ struct stack_frame {
 
 #define CALL_ON_STACK(fn, stack, nr, args...)				\
 ({									\
+	unsigned long frame = current_frame_address();			\
 	CALL_ARGS_##nr(args);						\
 	unsigned long prev;						\
 									\
 	asm volatile(							\
 		"	la	%[_prev],0(15)\n"			\
 		"	la	15,0(%[_stack])\n"			\
-		"	stg	%[_prev],%[_bc](15)\n"			\
+		"	stg	%[_frame],%[_bc](15)\n"			\
 		"	brasl	14,%[_fn]\n"				\
 		"	la	15,0(%[_prev])\n"			\
 		: [_prev] "=&a" (prev), CALL_FMT_##nr			\
 		  [_stack] "a" (stack),					\
 		  [_bc] "i" (offsetof(struct stack_frame, back_chain)),	\
+		  [_frame] "d" (frame),					\
 		  [_fn] "X" (fn) : CALL_CLOBBER_##nr);			\
 	r2;								\
 })

commit 103b4cca60d2c8c51f1290cc984b7046ccb8b46d
Author: Vasily Gorbik <gor@linux.ibm.com>
Date:   Fri Nov 22 12:35:34 2019 +0100

    s390/unwind: unify task is current checks
    
    Avoid mixture of task == NULL and task == current meaning the same
    thing and simply always initialize task with current in unwind_start.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/arch/s390/include/asm/stacktrace.h b/arch/s390/include/asm/stacktrace.h
index fee40212af11..0ae4bbf7779c 100644
--- a/arch/s390/include/asm/stacktrace.h
+++ b/arch/s390/include/asm/stacktrace.h
@@ -38,7 +38,7 @@ static inline unsigned long get_stack_pointer(struct task_struct *task,
 {
 	if (regs)
 		return (unsigned long) kernel_stack_pointer(regs);
-	if (!task || task == current)
+	if (task == current)
 		return current_stack_pointer();
 	return (unsigned long) task->thread.ksp;
 }

commit ea3f6dcfa71afb51753ad3729c29570f90d6abbc
Author: Ilya Leoshkevich <iii@linux.ibm.com>
Date:   Wed Oct 2 12:56:27 2019 +0200

    s390/unwind: fix get_stack_pointer(NULL, NULL)
    
    unwind_for_each_frame(NULL, NULL, 0) does not return any valid frames.
    
    The reason is that get_stack_pointer, unlike get_stack_info and
    show_stack, does not handle NULL argument.
    
    Fix by making get_stack_pointer treat NULL as current, like
    get_stack_info and show_stack do.
    
    Reviewed-by: Vasily Gorbik <gor@linux.ibm.com>
    Tested-by: Vasily Gorbik <gor@linux.ibm.com>
    Signed-off-by: Ilya Leoshkevich <iii@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/arch/s390/include/asm/stacktrace.h b/arch/s390/include/asm/stacktrace.h
index 0ae4bbf7779c..fee40212af11 100644
--- a/arch/s390/include/asm/stacktrace.h
+++ b/arch/s390/include/asm/stacktrace.h
@@ -38,7 +38,7 @@ static inline unsigned long get_stack_pointer(struct task_struct *task,
 {
 	if (regs)
 		return (unsigned long) kernel_stack_pointer(regs);
-	if (task == current)
+	if (!task || task == current)
 		return current_stack_pointer();
 	return (unsigned long) task->thread.ksp;
 }

commit 0ab0d7ac2090eae30f1c0b01ae981bb7a368f598
Author: Vasily Gorbik <gor@linux.ibm.com>
Date:   Thu Jun 6 16:58:45 2019 +0200

    s390/unwind: correct stack switching during unwind
    
    Adjust conditions in on_stack function. That fixes backchain unwinder
    which was unable to read pt_regs at the very bottom of the stack and
    hence couldn't follow stacks (e.g. from async stack to a task stack).
    
    Fixes: 78c98f907413 ("s390/unwind: introduce stack unwind API")
    Reported-by: Julian Wiedmann <jwi@linux.ibm.com>
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/arch/s390/include/asm/stacktrace.h b/arch/s390/include/asm/stacktrace.h
index 49634bfbecdd..0ae4bbf7779c 100644
--- a/arch/s390/include/asm/stacktrace.h
+++ b/arch/s390/include/asm/stacktrace.h
@@ -30,7 +30,7 @@ static inline bool on_stack(struct stack_info *info,
 		return false;
 	if (addr + len < addr)
 		return false;
-	return addr >= info->begin && addr + len < info->end;
+	return addr >= info->begin && addr + len <= info->end;
 }
 
 static inline unsigned long get_stack_pointer(struct task_struct *task,

commit 78c98f9074135d3dab4e39544e0a537f92388fce
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Mon Jan 28 08:33:08 2019 +0100

    s390/unwind: introduce stack unwind API
    
    Rework the dump_trace() stack unwinder interface to support different
    unwinding algorithms. The new interface looks like this:
    
            struct unwind_state state;
            unwind_for_each_frame(&state, task, regs, start_stack)
                    do_something(state.sp, state.ip, state.reliable);
    
    The unwind_bc.c file contains the implementation for the classic
    back-chain unwinder.
    
    One positive side effect of the new code is it now handles ftraced
    functions gracefully. It prints the real name of the return function
    instead of 'return_to_handler'.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/stacktrace.h b/arch/s390/include/asm/stacktrace.h
new file mode 100644
index 000000000000..49634bfbecdd
--- /dev/null
+++ b/arch/s390/include/asm/stacktrace.h
@@ -0,0 +1,114 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+#ifndef _ASM_S390_STACKTRACE_H
+#define _ASM_S390_STACKTRACE_H
+
+#include <linux/uaccess.h>
+#include <linux/ptrace.h>
+#include <asm/switch_to.h>
+
+enum stack_type {
+	STACK_TYPE_UNKNOWN,
+	STACK_TYPE_TASK,
+	STACK_TYPE_IRQ,
+	STACK_TYPE_NODAT,
+	STACK_TYPE_RESTART,
+};
+
+struct stack_info {
+	enum stack_type type;
+	unsigned long begin, end;
+};
+
+const char *stack_type_name(enum stack_type type);
+int get_stack_info(unsigned long sp, struct task_struct *task,
+		   struct stack_info *info, unsigned long *visit_mask);
+
+static inline bool on_stack(struct stack_info *info,
+			    unsigned long addr, size_t len)
+{
+	if (info->type == STACK_TYPE_UNKNOWN)
+		return false;
+	if (addr + len < addr)
+		return false;
+	return addr >= info->begin && addr + len < info->end;
+}
+
+static inline unsigned long get_stack_pointer(struct task_struct *task,
+					      struct pt_regs *regs)
+{
+	if (regs)
+		return (unsigned long) kernel_stack_pointer(regs);
+	if (task == current)
+		return current_stack_pointer();
+	return (unsigned long) task->thread.ksp;
+}
+
+/*
+ * Stack layout of a C stack frame.
+ */
+#ifndef __PACK_STACK
+struct stack_frame {
+	unsigned long back_chain;
+	unsigned long empty1[5];
+	unsigned long gprs[10];
+	unsigned int  empty2[8];
+};
+#else
+struct stack_frame {
+	unsigned long empty1[5];
+	unsigned int  empty2[8];
+	unsigned long gprs[10];
+	unsigned long back_chain;
+};
+#endif
+
+#define CALL_ARGS_0()							\
+	register unsigned long r2 asm("2")
+#define CALL_ARGS_1(arg1)						\
+	register unsigned long r2 asm("2") = (unsigned long)(arg1)
+#define CALL_ARGS_2(arg1, arg2)						\
+	CALL_ARGS_1(arg1);						\
+	register unsigned long r3 asm("3") = (unsigned long)(arg2)
+#define CALL_ARGS_3(arg1, arg2, arg3)					\
+	CALL_ARGS_2(arg1, arg2);					\
+	register unsigned long r4 asm("4") = (unsigned long)(arg3)
+#define CALL_ARGS_4(arg1, arg2, arg3, arg4)				\
+	CALL_ARGS_3(arg1, arg2, arg3);					\
+	register unsigned long r4 asm("5") = (unsigned long)(arg4)
+#define CALL_ARGS_5(arg1, arg2, arg3, arg4, arg5)			\
+	CALL_ARGS_4(arg1, arg2, arg3, arg4);				\
+	register unsigned long r4 asm("6") = (unsigned long)(arg5)
+
+#define CALL_FMT_0 "=&d" (r2) :
+#define CALL_FMT_1 "+&d" (r2) :
+#define CALL_FMT_2 CALL_FMT_1 "d" (r3),
+#define CALL_FMT_3 CALL_FMT_2 "d" (r4),
+#define CALL_FMT_4 CALL_FMT_3 "d" (r5),
+#define CALL_FMT_5 CALL_FMT_4 "d" (r6),
+
+#define CALL_CLOBBER_5 "0", "1", "14", "cc", "memory"
+#define CALL_CLOBBER_4 CALL_CLOBBER_5
+#define CALL_CLOBBER_3 CALL_CLOBBER_4, "5"
+#define CALL_CLOBBER_2 CALL_CLOBBER_3, "4"
+#define CALL_CLOBBER_1 CALL_CLOBBER_2, "3"
+#define CALL_CLOBBER_0 CALL_CLOBBER_1
+
+#define CALL_ON_STACK(fn, stack, nr, args...)				\
+({									\
+	CALL_ARGS_##nr(args);						\
+	unsigned long prev;						\
+									\
+	asm volatile(							\
+		"	la	%[_prev],0(15)\n"			\
+		"	la	15,0(%[_stack])\n"			\
+		"	stg	%[_prev],%[_bc](15)\n"			\
+		"	brasl	14,%[_fn]\n"				\
+		"	la	15,0(%[_prev])\n"			\
+		: [_prev] "=&a" (prev), CALL_FMT_##nr			\
+		  [_stack] "a" (stack),					\
+		  [_bc] "i" (offsetof(struct stack_frame, back_chain)),	\
+		  [_fn] "X" (fn) : CALL_CLOBBER_##nr);			\
+	r2;								\
+})
+
+#endif /* _ASM_S390_STACKTRACE_H */
