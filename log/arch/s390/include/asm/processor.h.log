commit 0b0ed657fe003fdf4df3766b898e8869950aa1ce
Author: Sven Schnelle <svens@linux.ibm.com>
Date:   Thu Feb 20 12:09:36 2020 +0100

    s390: remove critical section cleanup from entry.S
    
    The current code is rather complex and caused a lot of subtle
    and hard to debug bugs in the past. Simplify the code by calling
    the system_call handler with interrupts disabled, save
    machine state, and re-enable them later.
    
    This requires significant changes to the machine check handling code
    as well. When the machine check interrupt arrived while being in kernel
    mode the new code will signal pending machine checks with a SIGP external
    call. When userspace was interrupted, the handler will switch to the
    kernel stack and directly execute s390_handle_mcck().
    
    Signed-off-by: Sven Schnelle <svens@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 555d148ccf32..962da04234af 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -14,17 +14,15 @@
 
 #include <linux/bits.h>
 
-#define CIF_MCCK_PENDING	0	/* machine check handling is pending */
-#define CIF_ASCE_PRIMARY	1	/* primary asce needs fixup / uaccess */
-#define CIF_ASCE_SECONDARY	2	/* secondary asce needs fixup / uaccess */
-#define CIF_NOHZ_DELAY		3	/* delay HZ disable for a tick */
-#define CIF_FPU			4	/* restore FPU registers */
-#define CIF_IGNORE_IRQ		5	/* ignore interrupt (for udelay) */
-#define CIF_ENABLED_WAIT	6	/* in enabled wait state */
-#define CIF_MCCK_GUEST		7	/* machine check happening in guest */
-#define CIF_DEDICATED_CPU	8	/* this CPU is dedicated */
-
-#define _CIF_MCCK_PENDING	BIT(CIF_MCCK_PENDING)
+#define CIF_ASCE_PRIMARY	0	/* primary asce needs fixup / uaccess */
+#define CIF_ASCE_SECONDARY	1	/* secondary asce needs fixup / uaccess */
+#define CIF_NOHZ_DELAY		2	/* delay HZ disable for a tick */
+#define CIF_FPU			3	/* restore FPU registers */
+#define CIF_IGNORE_IRQ		4	/* ignore interrupt (for udelay) */
+#define CIF_ENABLED_WAIT	5	/* in enabled wait state */
+#define CIF_MCCK_GUEST		6	/* machine check happening in guest */
+#define CIF_DEDICATED_CPU	7	/* this CPU is dedicated */
+
 #define _CIF_ASCE_PRIMARY	BIT(CIF_ASCE_PRIMARY)
 #define _CIF_ASCE_SECONDARY	BIT(CIF_ASCE_SECONDARY)
 #define _CIF_NOHZ_DELAY		BIT(CIF_NOHZ_DELAY)

commit ad0bf4eb91c2f9b93479b679e5472094ddb76da8
Merge: 5364abc57993 1058c163dc31
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Apr 4 09:45:50 2020 -0700

    Merge tag 's390-5.7-1' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux
    
    Pull s390 updates from Vasily Gorbik:
    
     - Update maintainers. Niklas Schnelle takes over zpci and Vineeth
       Vijayan common io code.
    
     - Extend cpuinfo to include topology information.
    
     - Add new extended counters for IBM z15 and sampling buffer allocation
       rework in perf code.
    
     - Add control over zeroing out memory during system restart.
    
     - CCA protected key block version 2 support and other
       fixes/improvements in crypto code.
    
     - Convert to new fallthrough; annotations.
    
     - Replace zero-length arrays with flexible-arrays.
    
     - QDIO debugfs and other small improvements.
    
     - Drop 2-level paging support optimization for compat tasks. Varios mm
       cleanups.
    
     - Remove broken and unused hibernate / power management support.
    
     - Remove fake numa support which does not bring any benefits.
    
     - Exclude offline CPUs from CPU topology masks to be more consistent
       with other architectures.
    
     - Prevent last branching instruction address leaking to userspace.
    
     - Other small various fixes and improvements all over the code.
    
    * tag 's390-5.7-1' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux: (57 commits)
      s390/mm: cleanup init_new_context() callback
      s390/mm: cleanup virtual memory constants usage
      s390/mm: remove page table downgrade support
      s390/qdio: set qdio_irq->cdev at allocation time
      s390/qdio: remove unused function declarations
      s390/ccwgroup: remove pm support
      s390/ap: remove power management code from ap bus and drivers
      s390/zcrypt: use kvmalloc instead of kmalloc for 256k alloc
      s390/mm: cleanup arch_get_unmapped_area() and friends
      s390/ism: remove pm support
      s390/cio: use fallthrough;
      s390/vfio: use fallthrough;
      s390/zcrypt: use fallthrough;
      s390: use fallthrough;
      s390/cpum_sf: Fix wrong page count in error message
      s390/diag: fix display of diagnose call statistics
      s390/ap: Remove ap device suspend and resume callbacks
      s390/pci: Improve handling of unset UID
      s390/pci: Fix zpci_alloc_domain() over allocation
      s390/qdio: pass ISC as parameter to chsc_sadc()
      ...

commit f75556081afe5a565c2ce200837406303a59ae2b
Author: Alexander Gordeev <agordeev@linux.ibm.com>
Date:   Thu Mar 19 13:44:49 2020 +0100

    s390/mm: cleanup virtual memory constants usage
    
    Remove duplicate definitions and consolidate usage
    of virutal and address translation constants.
    
    Signed-off-by: Alexander Gordeev <agordeev@linux.ibm.com>
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index dee5e57da518..d052adfd53f3 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -93,15 +93,15 @@ extern void __bpon(void);
  */
 
 #define TASK_SIZE_OF(tsk)	(test_tsk_thread_flag(tsk, TIF_31BIT) ? \
-					(1UL << 31) : -PAGE_SIZE)
+					_REGION3_SIZE : TASK_SIZE_MAX)
 #define TASK_UNMAPPED_BASE	(test_thread_flag(TIF_31BIT) ? \
-					(1UL << 30) : (1UL << 41))
+					(_REGION3_SIZE >> 1) : (_REGION2_SIZE >> 1))
 #define TASK_SIZE		TASK_SIZE_OF(current)
 #define TASK_SIZE_MAX		(-PAGE_SIZE)
 
 #define STACK_TOP		(test_thread_flag(TIF_31BIT) ? \
-					(1UL << 31) : (1UL << 42))
-#define STACK_TOP_MAX		(1UL << 42)
+					_REGION3_SIZE : _REGION2_SIZE)
+#define STACK_TOP_MAX		_REGION2_SIZE
 
 #define HAVE_ARCH_PICK_MMAP_LAYOUT
 

commit 6a3eb35e56b3308966945b76ec1dfbc18537feef
Author: Alexander Gordeev <agordeev@linux.ibm.com>
Date:   Fri Feb 28 11:32:01 2020 +0100

    s390/mm: remove page table downgrade support
    
    This update consolidates page table handling code. Because
    there are hardly any 31-bit binaries left we do not need to
    optimize for that.
    
    No extra efforts are needed to ensure that a compat task does
    not map anything above 2GB. The TASK_SIZE limit for 31-bit
    tasks is 2GB already and the generic code does check that a
    resulting map address would not surpass that limit.
    
    Signed-off-by: Alexander Gordeev <agordeev@linux.ibm.com>
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index c9522346799f..dee5e57da518 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -179,7 +179,6 @@ typedef struct thread_struct thread_struct;
 	regs->psw.mask	= PSW_USER_BITS | PSW_MASK_BA;			\
 	regs->psw.addr	= new_psw;					\
 	regs->gprs[15]	= new_stackp;					\
-	crst_table_downgrade(current->mm);				\
 	execve_tail();							\
 } while (0)
 

commit 0b38b5e1d0e2f361e418e05c179db05bb688bbd6
Author: Sven Schnelle <svens@linux.ibm.com>
Date:   Wed Jan 22 13:38:22 2020 +0100

    s390: prevent leaking kernel address in BEAR
    
    When userspace executes a syscall or gets interrupted,
    BEAR contains a kernel address when returning to userspace.
    This make it pretty easy to figure out where the kernel is
    mapped even with KASLR enabled. To fix this, add lpswe to
    lowcore and always execute it there, so userspace sees only
    the lowcore address of lpswe. For this we have to extend
    both critical_cleanup and the SWITCH_ASYNC macro to also check
    for lpswe addresses in lowcore.
    
    Fixes: b2d24b97b2a9 ("s390/kernel: add support for kernel address space layout randomization (KASLR)")
    Cc: <stable@vger.kernel.org> # v5.2+
    Reviewed-by: Gerald Schaefer <gerald.schaefer@de.ibm.com>
    Signed-off-by: Sven Schnelle <svens@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 361ef5eda468..c9522346799f 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -162,6 +162,7 @@ typedef struct thread_struct thread_struct;
 #define INIT_THREAD {							\
 	.ksp = sizeof(init_stack) + (unsigned long) &init_stack,	\
 	.fpu.regs = (void *) init_task.thread.fpu.fprs,			\
+	.last_break = 1,						\
 }
 
 /*

commit 140588bfed2727e9a4814211617a79401d74922f
Author: Stephen Kitt <steve@sk2.org>
Date:   Fri Feb 14 18:26:28 2020 +0100

    s390: remove obsolete ieee_emulation_warnings
    
    s390 math emulation was removed with commit 5a79859ae0f3 ("s390:
    remove 31 bit support"), rendering ieee_emulation_warnings useless.
    The code still built because it was protected by CONFIG_MATHEMU, which
    was no longer selectable.
    
    This patch removes the sysctl_ieee_emulation_warnings declaration and
    the sysctl entry declaration.
    
    Link: https://lkml.kernel.org/r/20200214172628.3598516-1-steve@sk2.org
    Reviewed-by: Vasily Gorbik <gor@linux.ibm.com>
    Signed-off-by: Stephen Kitt <steve@sk2.org>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 361ef5eda468..aadb3d0e2adc 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -84,7 +84,6 @@ void s390_update_cpu_mhz(void);
 void cpu_detect_mhz_feature(void);
 
 extern const struct seq_operations cpuinfo_op;
-extern int sysctl_ieee_emulation_warnings;
 extern void execve_tail(void);
 extern void __bpon(void);
 

commit c2e06e15ad92bad94b54df257c683f7e715238a1
Author: Vasily Gorbik <gor@linux.ibm.com>
Date:   Fri Nov 22 12:08:44 2019 +0100

    s390: always inline disabled_wait
    
    disabled_wait uses _THIS_IP_ and assumes that compiler would inline it.
    Make sure this assumption is always correct by utilizing __always_inline.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 881fc37c11c6..361ef5eda468 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -310,7 +310,7 @@ void enabled_wait(void);
 /*
  * Function to drop a processor into disabled wait state
  */
-static inline void __noreturn disabled_wait(void)
+static __always_inline void __noreturn disabled_wait(void)
 {
 	psw_t psw;
 

commit 265f79dcb5702aeffcd9453c8cbb5fb707652323
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed Oct 30 16:55:56 2019 +0100

    s390: always inline current_stack_pointer()
    
    This function must be inlined since any caller expects the current
    stack pointer; which wouldn't be true if the function isn't inlined.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 51a0e4a2dc96..881fc37c11c6 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -206,7 +206,7 @@ unsigned long get_wchan(struct task_struct *p);
 /* Has task runtime instrumentation enabled ? */
 #define is_ri_task(tsk) (!!(tsk)->thread.ri_cb)
 
-static inline unsigned long current_stack_pointer(void)
+static __always_inline unsigned long current_stack_pointer(void)
 {
 	unsigned long sp;
 

commit 512222789ce8aba54295854c4641aa6f680c1897
Author: Vasily Gorbik <gor@linux.ibm.com>
Date:   Mon Sep 2 16:59:32 2019 +0200

    s390/base: remove unused s390_base_mcck_handler
    
    s390_base_mcck_handler was used during system reset if diag308 set was
    not available. But after commit d485235b0054 ("s390: assume diag308 set
    always works") is a dead code and could be removed.
    
    Acked-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index d56c519bc696..51a0e4a2dc96 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -324,11 +324,9 @@ static inline void __noreturn disabled_wait(void)
  * Basic Machine Check/Program Check Handler.
  */
 
-extern void s390_base_mcck_handler(void);
 extern void s390_base_pgm_handler(void);
 extern void s390_base_ext_handler(void);
 
-extern void (*s390_base_mcck_handler_fn)(void);
 extern void (*s390_base_pgm_handler_fn)(void);
 extern void (*s390_base_ext_handler_fn)(void);
 

commit fe6ba88b251aa76a94be2cb441d2e6b7c623b989
Author: Masahiro Yamada <yamada.masahiro@socionext.com>
Date:   Tue Jul 16 16:27:01 2019 -0700

    arch: replace _BITUL() in kernel-space headers with BIT()
    
    Now that BIT() can be used from assembly code, we can safely replace
    _BITUL() with equivalent BIT().
    
    UAPI headers are still required to use _BITUL(), but there is no more
    reason to use it in kernel headers.  BIT() is shorter.
    
    Link: http://lkml.kernel.org/r/20190609153941.17249-2-yamada.masahiro@socionext.com
    Signed-off-by: Masahiro Yamada <yamada.masahiro@socionext.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Vasily Gorbik <gor@linux.ibm.com>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 14883b1562e0..d56c519bc696 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -12,7 +12,7 @@
 #ifndef __ASM_S390_PROCESSOR_H
 #define __ASM_S390_PROCESSOR_H
 
-#include <linux/const.h>
+#include <linux/bits.h>
 
 #define CIF_MCCK_PENDING	0	/* machine check handling is pending */
 #define CIF_ASCE_PRIMARY	1	/* primary asce needs fixup / uaccess */
@@ -24,15 +24,15 @@
 #define CIF_MCCK_GUEST		7	/* machine check happening in guest */
 #define CIF_DEDICATED_CPU	8	/* this CPU is dedicated */
 
-#define _CIF_MCCK_PENDING	_BITUL(CIF_MCCK_PENDING)
-#define _CIF_ASCE_PRIMARY	_BITUL(CIF_ASCE_PRIMARY)
-#define _CIF_ASCE_SECONDARY	_BITUL(CIF_ASCE_SECONDARY)
-#define _CIF_NOHZ_DELAY		_BITUL(CIF_NOHZ_DELAY)
-#define _CIF_FPU		_BITUL(CIF_FPU)
-#define _CIF_IGNORE_IRQ		_BITUL(CIF_IGNORE_IRQ)
-#define _CIF_ENABLED_WAIT	_BITUL(CIF_ENABLED_WAIT)
-#define _CIF_MCCK_GUEST		_BITUL(CIF_MCCK_GUEST)
-#define _CIF_DEDICATED_CPU	_BITUL(CIF_DEDICATED_CPU)
+#define _CIF_MCCK_PENDING	BIT(CIF_MCCK_PENDING)
+#define _CIF_ASCE_PRIMARY	BIT(CIF_ASCE_PRIMARY)
+#define _CIF_ASCE_SECONDARY	BIT(CIF_ASCE_SECONDARY)
+#define _CIF_NOHZ_DELAY		BIT(CIF_NOHZ_DELAY)
+#define _CIF_FPU		BIT(CIF_FPU)
+#define _CIF_IGNORE_IRQ		BIT(CIF_IGNORE_IRQ)
+#define _CIF_ENABLED_WAIT	BIT(CIF_ENABLED_WAIT)
+#define _CIF_MCCK_GUEST		BIT(CIF_MCCK_GUEST)
+#define _CIF_DEDICATED_CPU	BIT(CIF_DEDICATED_CPU)
 
 #ifndef __ASSEMBLY__
 

commit 4ecf0a43e729a7e641d800c294faabe87378fc05
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Sat Jun 8 12:13:57 2019 +0200

    processor: get rid of cpu_relax_yield
    
    stop_machine is the only user left of cpu_relax_yield. Given that it
    now has special semantics which are tied to stop_machine introduce a
    weak stop_machine_yield function which architectures can override, and
    get rid of the generic cpu_relax_yield implementation.
    
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 445ce9ee4404..14883b1562e0 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -222,12 +222,6 @@ static __no_kasan_or_inline unsigned short stap(void)
 	return cpu_address;
 }
 
-/*
- * Give up the time slice of the virtual PU.
- */
-#define cpu_relax_yield cpu_relax_yield
-void cpu_relax_yield(const struct cpumask *cpumask);
-
 #define cpu_relax() barrier()
 
 #define ECAG_CACHE_ATTRIBUTE	0

commit 38f2c691a4b3e89d476f8e8350d1ca299974b89d
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Fri May 17 12:50:42 2019 +0200

    s390: improve wait logic of stop_machine
    
    The stop_machine loop to advance the state machine and to wait for all
    affected CPUs to check-in calls cpu_relax_yield in a tight loop until
    the last missing CPUs acknowledged the state transition.
    
    On a virtual system where not all logical CPUs are backed by real CPUs
    all the time it can take a while for all CPUs to check-in. With the
    current definition of cpu_relax_yield a diagnose 0x44 is done which
    tells the hypervisor to schedule *some* other CPU. That can be any
    CPU and not necessarily one of the CPUs that need to run in order to
    advance the state machine. This can lead to a pretty bad diagnose 0x44
    storm until the last missing CPU finally checked-in.
    
    Replace the undirected cpu_relax_yield based on diagnose 0x44 with a
    directed yield. Each CPU in the wait loop will pick up the next CPU
    in the cpumask of stop_machine. The diagnose 0x9c is used to tell the
    hypervisor to run this next CPU instead of the current one. If there
    is only a limited number of real CPUs backing the virtual CPUs we
    end up with the real CPUs passed around in a round-robin fashion.
    
    [heiko.carstens@de.ibm.com]:
        Use cpumask_next_wrap as suggested by Peter Zijlstra.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index b0fcbc37b637..445ce9ee4404 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -36,6 +36,7 @@
 
 #ifndef __ASSEMBLY__
 
+#include <linux/cpumask.h>
 #include <linux/linkage.h>
 #include <linux/irqflags.h>
 #include <asm/cpu.h>
@@ -225,7 +226,7 @@ static __no_kasan_or_inline unsigned short stap(void)
  * Give up the time slice of the virtual PU.
  */
 #define cpu_relax_yield cpu_relax_yield
-void cpu_relax_yield(void);
+void cpu_relax_yield(const struct cpumask *cpumask);
 
 #define cpu_relax() barrier()
 

commit 98587c2d894c34c9af5cd84ca169e1cd493aa692
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Apr 30 12:33:45 2019 +0200

    s390: simplify disabled_wait
    
    The disabled_wait() function uses its argument as the PSW address when
    it stops the CPU with a wait PSW that is disabled for interrupts.
    The different callers sometimes use a specific number like 0xdeadbeef
    to indicate a specific failure, the early boot code uses 0 and some
    other calls sites use __builtin_return_address(0).
    
    At the time a dump is created the current PSW and the registers of a
    CPU are written to lowcore to make them avaiable to the dump analysis
    tool. For a CPU stopped with disabled_wait the PSW and the registers
    do not really make sense together, the PSW address does not point to
    the function the registers belong to.
    
    Simplify disabled_wait() by using _THIS_IP_ for the PSW address and
    drop the argument to the function.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 9f2ff4a54aff..b0fcbc37b637 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -315,12 +315,12 @@ void enabled_wait(void);
 /*
  * Function to drop a processor into disabled wait state
  */
-static inline void __noreturn disabled_wait(unsigned long code)
+static inline void __noreturn disabled_wait(void)
 {
 	psw_t psw;
 
 	psw.mask = PSW_MASK_BASE | PSW_MASK_WAIT | PSW_MASK_BA | PSW_MASK_EA;
-	psw.addr = code;
+	psw.addr = _THIS_IP_;
 	__load_psw(psw);
 	while (1);
 }

commit 78c98f9074135d3dab4e39544e0a537f92388fce
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Mon Jan 28 08:33:08 2019 +0100

    s390/unwind: introduce stack unwind API
    
    Rework the dump_trace() stack unwinder interface to support different
    unwinding algorithms. The new interface looks like this:
    
            struct unwind_state state;
            unwind_for_each_frame(&state, task, regs, start_stack)
                    do_something(state.sp, state.ip, state.reliable);
    
    The unwind_bc.c file contains the implementation for the classic
    back-chain unwinder.
    
    One positive side effect of the new code is it now handles ftraced
    functions gracefully. It prints the real name of the return function
    instead of 'return_to_handler'.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 8aa85e39f50b..9f2ff4a54aff 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -156,25 +156,6 @@ struct thread_struct {
 
 typedef struct thread_struct thread_struct;
 
-/*
- * Stack layout of a C stack frame.
- */
-#ifndef __PACK_STACK
-struct stack_frame {
-	unsigned long back_chain;
-	unsigned long empty1[5];
-	unsigned long gprs[10];
-	unsigned int  empty2[8];
-};
-#else
-struct stack_frame {
-	unsigned long empty1[5];
-	unsigned int  empty2[8];
-	unsigned long gprs[10];
-	unsigned long back_chain;
-};
-#endif
-
 #define ARCH_MIN_TASKALIGN	8
 
 #define INIT_THREAD {							\
@@ -206,11 +187,7 @@ struct mm_struct;
 struct seq_file;
 struct pt_regs;
 
-typedef int (*dump_trace_func_t)(void *data, unsigned long address, int reliable);
-void dump_trace(dump_trace_func_t func, void *data,
-		struct task_struct *task, unsigned long sp);
 void show_registers(struct pt_regs *regs);
-
 void show_cacheinfo(struct seq_file *m);
 
 /* Free all resources held by a thread. */
@@ -244,55 +221,6 @@ static __no_kasan_or_inline unsigned short stap(void)
 	return cpu_address;
 }
 
-#define CALL_ARGS_0()							\
-	register unsigned long r2 asm("2")
-#define CALL_ARGS_1(arg1)						\
-	register unsigned long r2 asm("2") = (unsigned long)(arg1)
-#define CALL_ARGS_2(arg1, arg2)						\
-	CALL_ARGS_1(arg1);						\
-	register unsigned long r3 asm("3") = (unsigned long)(arg2)
-#define CALL_ARGS_3(arg1, arg2, arg3)					\
-	CALL_ARGS_2(arg1, arg2);					\
-	register unsigned long r4 asm("4") = (unsigned long)(arg3)
-#define CALL_ARGS_4(arg1, arg2, arg3, arg4)				\
-	CALL_ARGS_3(arg1, arg2, arg3);					\
-	register unsigned long r4 asm("5") = (unsigned long)(arg4)
-#define CALL_ARGS_5(arg1, arg2, arg3, arg4, arg5)			\
-	CALL_ARGS_4(arg1, arg2, arg3, arg4);				\
-	register unsigned long r4 asm("6") = (unsigned long)(arg5)
-
-#define CALL_FMT_0 "=&d" (r2) :
-#define CALL_FMT_1 "+&d" (r2) :
-#define CALL_FMT_2 CALL_FMT_1 "d" (r3),
-#define CALL_FMT_3 CALL_FMT_2 "d" (r4),
-#define CALL_FMT_4 CALL_FMT_3 "d" (r5),
-#define CALL_FMT_5 CALL_FMT_4 "d" (r6),
-
-#define CALL_CLOBBER_5 "0", "1", "14", "cc", "memory"
-#define CALL_CLOBBER_4 CALL_CLOBBER_5
-#define CALL_CLOBBER_3 CALL_CLOBBER_4, "5"
-#define CALL_CLOBBER_2 CALL_CLOBBER_3, "4"
-#define CALL_CLOBBER_1 CALL_CLOBBER_2, "3"
-#define CALL_CLOBBER_0 CALL_CLOBBER_1
-
-#define CALL_ON_STACK(fn, stack, nr, args...)				\
-({									\
-	CALL_ARGS_##nr(args);						\
-	unsigned long prev;						\
-									\
-	asm volatile(							\
-		"	la	%[_prev],0(15)\n"			\
-		"	la	15,0(%[_stack])\n"			\
-		"	stg	%[_prev],%[_bc](15)\n"			\
-		"	brasl	14,%[_fn]\n"				\
-		"	la	15,0(%[_prev])\n"			\
-		: [_prev] "=&a" (prev), CALL_FMT_##nr			\
-		  [_stack] "a" (stack),					\
-		  [_bc] "i" (offsetof(struct stack_frame, back_chain)),	\
-		  [_fn] "X" (fn) : CALL_CLOBBER_##nr);			\
-	r2;								\
-})
-
 /*
  * Give up the time slice of the virtual PU.
  */

commit 0a113efc3b48e9a8952e3c6e19dfdcc48b62226f
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon Apr 8 23:26:22 2019 +0200

    s390: make __load_psw_mask work with clang
    
    clang fails to use the %O and %R inline assembly modifiers
    the same way as gcc, leading to build failures with every use
    of __load_psw_mask():
    
    /tmp/nmi-4a9f80.s: Assembler messages:
    /tmp/nmi-4a9f80.s:571: Error: junk at end of line: `+8(160(%r11))'
    /tmp/nmi-4a9f80.s:626: Error: junk at end of line: `+8(160(%r11))'
    
    Replace these with a more conventional way of passing the addresses
    that should work with both clang and gcc.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 0ee022247580..8aa85e39f50b 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -339,10 +339,10 @@ static __no_kasan_or_inline void __load_psw_mask(unsigned long mask)
 
 	asm volatile(
 		"	larl	%0,1f\n"
-		"	stg	%0,%O1+8(%R1)\n"
-		"	lpswe	%1\n"
+		"	stg	%0,%1\n"
+		"	lpswe	%2\n"
 		"1:"
-		: "=&d" (addr), "=Q" (psw) : "Q" (psw) : "memory", "cc");
+		: "=&d" (addr), "=Q" (psw.addr) : "Q" (psw) : "memory", "cc");
 }
 
 /*

commit 7aa0055e06475f7b486c0673bc59c6478bc055fa
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Wed Apr 10 15:48:43 2019 +0200

    s390: fine-tune stack switch helper
    
    The CALL_ON_STACK helper currently does not work with clang and for
    calls without arguments. It does not initialize r2 although the constraint
    is "+&d". Rework the CALL_FMT_x and the CALL_ON_STACK macros to work
    with clang and produce optimal code in all cases.
    
    Reported-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 81038ab357ce..0ee022247580 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -261,12 +261,12 @@ static __no_kasan_or_inline unsigned short stap(void)
 	CALL_ARGS_4(arg1, arg2, arg3, arg4);				\
 	register unsigned long r4 asm("6") = (unsigned long)(arg5)
 
-#define CALL_FMT_0
-#define CALL_FMT_1 CALL_FMT_0, "0" (r2)
-#define CALL_FMT_2 CALL_FMT_1, "d" (r3)
-#define CALL_FMT_3 CALL_FMT_2, "d" (r4)
-#define CALL_FMT_4 CALL_FMT_3, "d" (r5)
-#define CALL_FMT_5 CALL_FMT_4, "d" (r6)
+#define CALL_FMT_0 "=&d" (r2) :
+#define CALL_FMT_1 "+&d" (r2) :
+#define CALL_FMT_2 CALL_FMT_1 "d" (r3),
+#define CALL_FMT_3 CALL_FMT_2 "d" (r4),
+#define CALL_FMT_4 CALL_FMT_3 "d" (r5),
+#define CALL_FMT_5 CALL_FMT_4 "d" (r6),
 
 #define CALL_CLOBBER_5 "0", "1", "14", "cc", "memory"
 #define CALL_CLOBBER_4 CALL_CLOBBER_5
@@ -286,10 +286,10 @@ static __no_kasan_or_inline unsigned short stap(void)
 		"	stg	%[_prev],%[_bc](15)\n"			\
 		"	brasl	14,%[_fn]\n"				\
 		"	la	15,0(%[_prev])\n"			\
-		: "+&d" (r2), [_prev] "=&a" (prev)			\
-		: [_stack] "a" (stack),					\
+		: [_prev] "=&a" (prev), CALL_FMT_##nr			\
+		  [_stack] "a" (stack),					\
 		  [_bc] "i" (offsetof(struct stack_frame, back_chain)),	\
-		  [_fn] "X" (fn) CALL_FMT_##nr : CALL_CLOBBER_##nr);	\
+		  [_fn] "X" (fn) : CALL_CLOBBER_##nr);			\
 	r2;								\
 })
 

commit 163c8d54a997153ee1a1e07fcac087492ad85b37
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Mon Nov 5 07:36:28 2018 +0100

    compiler: remove __no_sanitize_address_or_inline again
    
    The __no_sanitize_address_or_inline and __no_kasan_or_inline defines
    are almost identical. The only difference is that __no_kasan_or_inline
    does not have the 'notrace' attribute.
    
    To be able to replace __no_sanitize_address_or_inline with the older
    definition, add 'notrace' to __no_kasan_or_inline and change to two
    users of __no_sanitize_address_or_inline in the s390 code.
    
    The 'notrace' option is necessary for e.g. the __load_psw_mask function
    in arch/s390/include/asm/processor.h. Without the option it is possible
    to trace __load_psw_mask which leads to kernel stack overflow.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Pointed-out-by: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Acked-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 302795c47c06..81038ab357ce 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -236,7 +236,7 @@ static inline unsigned long current_stack_pointer(void)
 	return sp;
 }
 
-static __no_sanitize_address_or_inline unsigned short stap(void)
+static __no_kasan_or_inline unsigned short stap(void)
 {
 	unsigned short cpu_address;
 
@@ -330,7 +330,7 @@ static inline void __load_psw(psw_t psw)
  * Set PSW mask to specified value, while leaving the
  * PSW addr pointing to the next instruction.
  */
-static __no_sanitize_address_or_inline void __load_psw_mask(unsigned long mask)
+static __no_kasan_or_inline void __load_psw_mask(unsigned long mask)
 {
 	unsigned long addr;
 	psw_t psw;

commit de0d22e50cd3d57277f073ccf65d57aa519d6888
Author: Nick Desaulniers <ndesaulniers@google.com>
Date:   Tue Oct 30 15:04:47 2018 -0700

    treewide: remove current_text_addr
    
    Prefer _THIS_IP_ defined in linux/kernel.h.
    
    Most definitions of current_text_addr were the same as _THIS_IP_, but
    a few archs had inline assembly instead.
    
    This patch removes the final call site of current_text_addr, making all
    of the definitions dead code.
    
    [akpm@linux-foundation.org: fix arch/csky/include/asm/processor.h]
    Link: http://lkml.kernel.org/r/20180911182413.180715-1-ndesaulniers@google.com
    Signed-off-by: Nick Desaulniers <ndesaulniers@google.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 34768e6ef4fb..302795c47c06 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -73,12 +73,6 @@ static inline int test_cpu_flag_of(int flag, int cpu)
 
 #define arch_needs_cpu() test_cpu_flag(CIF_NOHZ_DELAY)
 
-/*
- * Default implementation of macro that returns current
- * instruction pointer ("program counter").
- */
-#define current_text_addr() ({ void *pc; asm("basr %0,0" : "=a" (pc)); pc; })
-
 static inline void get_cpu_id(struct cpuid *ptr)
 {
 	asm volatile("stidp %0" : "=Q" (*ptr));

commit ac1256f82619724357242eb514f162c40d5b64d8
Author: Vasily Gorbik <gor@linux.ibm.com>
Date:   Mon Nov 20 12:15:10 2017 +0100

    s390/kasan: reipl and kexec support
    
    Some functions from both arch/s390/kernel/ipl.c and
    arch/s390/kernel/machine_kexec.c are called without DAT enabled
    (or with and without DAT enabled code paths). There is no easy way
    to partially disable kasan for those files without a substantial
    rework. Disable kasan for both files for now.
    
    To avoid disabling kasan for arch/s390/kernel/diag.c DAT flag is
    enabled in diag308 call. pcpu_delegate which disables DAT is marked
    with __no_sanitize_address to disable instrumentation for that one
    function.
    
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 55956c96558c..34768e6ef4fb 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -242,7 +242,7 @@ static inline unsigned long current_stack_pointer(void)
 	return sp;
 }
 
-static inline unsigned short stap(void)
+static __no_sanitize_address_or_inline unsigned short stap(void)
 {
 	unsigned short cpu_address;
 

commit 9e8df6daed9e59153624e52aa4832ddaf39f1ae8
Author: Vasily Gorbik <gor@linux.ibm.com>
Date:   Mon Nov 20 12:13:52 2017 +0100

    s390/smp: kasan stack instrumentation support
    
    smp_start_secondary function is called without DAT enabled. To avoid
    disabling kasan instrumentation for entire arch/s390/kernel/smp.c
    smp_start_secondary has been split in 2 parts. smp_start_secondary has
    instrumentation disabled, it does minimal setup and enables DAT. Then
    instrumentated __smp_start_secondary is called to do the rest.
    
    __load_psw_mask function instrumentation has been disabled as well
    to be able to call it from smp_start_secondary.
    
    Reviewed-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 43494a014d5b..55956c96558c 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -336,7 +336,7 @@ static inline void __load_psw(psw_t psw)
  * Set PSW mask to specified value, while leaving the
  * PSW addr pointing to the next instruction.
  */
-static inline void __load_psw_mask(unsigned long mask)
+static __no_sanitize_address_or_inline void __load_psw_mask(unsigned long mask)
 {
 	unsigned long addr;
 	psw_t psw;

commit 32ce55a6592fc3e117e70953001a9ea1931f7941
Author: Vasily Gorbik <gor@linux.ibm.com>
Date:   Tue Sep 18 18:23:40 2018 +0200

    s390: unify stack size definitions
    
    Remove STACK_ORDER and STACK_SIZE in favour of identical THREAD_SIZE_ORDER
    and THREAD_SIZE definitions. THREAD_SIZE and THREAD_SIZE_ORDER naming is
    misleading since it is used as general kernel stack size information. But
    both those definitions are used in the common code and throughout
    architectures specific code, so changing the naming is problematic.
    
    Reviewed-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 3c1e723a143a..43494a014d5b 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -162,14 +162,6 @@ struct thread_struct {
 
 typedef struct thread_struct thread_struct;
 
-/*
- * General size of a stack
- */
-#define STACK_ORDER 2
-#define STACK_SIZE (PAGE_SIZE << STACK_ORDER)
-#define STACK_INIT_OFFSET \
-	(STACK_SIZE - STACK_FRAME_OVERHEAD - sizeof(struct pt_regs))
-
 /*
  * Stack layout of a C stack frame.
  */

commit ce3dc447493ff4186b192b38d723ab5e8c1eb52f
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Sep 12 16:37:33 2017 +0200

    s390: add support for virtually mapped kernel stacks
    
    With virtually mapped kernel stacks the kernel stack overflow detection
    is now fault based, every stack has a guard page in the vmalloc space.
    The panic_stack is renamed to nodat_stack and is used for all function
    that need to run without DAT, e.g. memcpy_real or do_start_kdump.
    
    The main effect is a reduction in the kernel image size as with vmap
    stacks the old style overflow checking that adds two instructions per
    function is not needed anymore. Result from bloat-o-meter:
    
    add/remove: 20/1 grow/shrink: 13/26854 up/down: 2198/-216240 (-214042)
    
    In regard to performance the micro-benchmark for fork has a hit of a
    few microseconds, allocating 4 pages in vmalloc space is more expensive
    compare to an order-2 page allocation. But with real workload I could
    not find a noticeable difference.
    
    Acked-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 43494a014d5b..3c1e723a143a 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -162,6 +162,14 @@ struct thread_struct {
 
 typedef struct thread_struct thread_struct;
 
+/*
+ * General size of a stack
+ */
+#define STACK_ORDER 2
+#define STACK_SIZE (PAGE_SIZE << STACK_ORDER)
+#define STACK_INIT_OFFSET \
+	(STACK_SIZE - STACK_FRAME_OVERHEAD - sizeof(struct pt_regs))
+
 /*
  * Stack layout of a C stack frame.
  */

commit ff340d2472ec7618443913928af9fb85a7009270
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Thu Sep 7 17:03:19 2017 +0200

    s390: add stack switch helper
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 7f2953c15c37..43494a014d5b 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -250,6 +250,55 @@ static inline unsigned short stap(void)
 	return cpu_address;
 }
 
+#define CALL_ARGS_0()							\
+	register unsigned long r2 asm("2")
+#define CALL_ARGS_1(arg1)						\
+	register unsigned long r2 asm("2") = (unsigned long)(arg1)
+#define CALL_ARGS_2(arg1, arg2)						\
+	CALL_ARGS_1(arg1);						\
+	register unsigned long r3 asm("3") = (unsigned long)(arg2)
+#define CALL_ARGS_3(arg1, arg2, arg3)					\
+	CALL_ARGS_2(arg1, arg2);					\
+	register unsigned long r4 asm("4") = (unsigned long)(arg3)
+#define CALL_ARGS_4(arg1, arg2, arg3, arg4)				\
+	CALL_ARGS_3(arg1, arg2, arg3);					\
+	register unsigned long r4 asm("5") = (unsigned long)(arg4)
+#define CALL_ARGS_5(arg1, arg2, arg3, arg4, arg5)			\
+	CALL_ARGS_4(arg1, arg2, arg3, arg4);				\
+	register unsigned long r4 asm("6") = (unsigned long)(arg5)
+
+#define CALL_FMT_0
+#define CALL_FMT_1 CALL_FMT_0, "0" (r2)
+#define CALL_FMT_2 CALL_FMT_1, "d" (r3)
+#define CALL_FMT_3 CALL_FMT_2, "d" (r4)
+#define CALL_FMT_4 CALL_FMT_3, "d" (r5)
+#define CALL_FMT_5 CALL_FMT_4, "d" (r6)
+
+#define CALL_CLOBBER_5 "0", "1", "14", "cc", "memory"
+#define CALL_CLOBBER_4 CALL_CLOBBER_5
+#define CALL_CLOBBER_3 CALL_CLOBBER_4, "5"
+#define CALL_CLOBBER_2 CALL_CLOBBER_3, "4"
+#define CALL_CLOBBER_1 CALL_CLOBBER_2, "3"
+#define CALL_CLOBBER_0 CALL_CLOBBER_1
+
+#define CALL_ON_STACK(fn, stack, nr, args...)				\
+({									\
+	CALL_ARGS_##nr(args);						\
+	unsigned long prev;						\
+									\
+	asm volatile(							\
+		"	la	%[_prev],0(15)\n"			\
+		"	la	15,0(%[_stack])\n"			\
+		"	stg	%[_prev],%[_bc](15)\n"			\
+		"	brasl	14,%[_fn]\n"				\
+		"	la	15,0(%[_prev])\n"			\
+		: "+&d" (r2), [_prev] "=&a" (prev)			\
+		: [_stack] "a" (stack),					\
+		  [_bc] "i" (offsetof(struct stack_frame, back_chain)),	\
+		  [_fn] "X" (fn) CALL_FMT_##nr : CALL_CLOBBER_##nr);	\
+	r2;								\
+})
+
 /*
  * Give up the time slice of the virtual PU.
  */

commit 6b73044b2b0081ee3dd1cd6eaab7dee552601efb
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Jan 16 07:36:46 2018 +0100

    s390: run user space and KVM guests with modified branch prediction
    
    Define TIF_ISOLATE_BP and TIF_ISOLATE_BP_GUEST and add the necessary
    plumbing in entry.S to be able to run user space and KVM guests with
    limited branch prediction.
    
    To switch a user space process to limited branch prediction the
    s390_isolate_bp() function has to be call, and to run a vCPU of a KVM
    guest associated with the current task with limited branch prediction
    call s390_isolate_bp_guest().
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 5f37f9ceef5e..7f2953c15c37 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -378,6 +378,9 @@ extern void memcpy_absolute(void *, void *, size_t);
 	memcpy_absolute(&(dest), &__tmp, sizeof(__tmp));	\
 } while (0)
 
+extern int s390_isolate_bp(void);
+extern int s390_isolate_bp_guest(void);
+
 #endif /* __ASSEMBLY__ */
 
 #endif /* __ASM_S390_PROCESSOR_H */

commit d768bd892fc8f066cd3aa000eb1867bcf32db0ee
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Jan 16 07:11:45 2018 +0100

    s390: add options to change branch prediction behaviour for the kernel
    
    Add the PPA instruction to the system entry and exit path to switch
    the kernel to a different branch prediction behaviour. The instructions
    are added via CPU alternatives and can be disabled with the "nospec"
    or the "nobp=0" kernel parameter. If the default behaviour selected
    with CONFIG_KERNEL_NOBP is set to "n" then the "nobp=1" parameter can be
    used to enable the changed kernel branch prediction.
    
    Acked-by: Cornelia Huck <cohuck@redhat.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index bfbfad482289..5f37f9ceef5e 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -91,6 +91,7 @@ void cpu_detect_mhz_feature(void);
 extern const struct seq_operations cpuinfo_op;
 extern int sysctl_ieee_emulation_warnings;
 extern void execve_tail(void);
+extern void __bpon(void);
 
 /*
  * User space process size: 2GB for 31 bit, 4TB or 8PT for 64 bit.

commit 11776eaa6568f5357542bf41b0c7bb90854137cc
Author: Vasily Gorbik <gor@linux.vnet.ibm.com>
Date:   Mon Nov 13 16:37:33 2017 +0100

    s390: correct some inline assembly constraints
    
    Inline assembly code changed in this patch should really use "Q"
    constraint "Memory reference without index register and with short
    displacement". The kernel does not compile with kasan support enabled
    otherwise (due to stack instrumentation).
    
    Signed-off-by: Vasily Gorbik <gor@linux.vnet.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 709351bce80e..bfbfad482289 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -245,7 +245,7 @@ static inline unsigned short stap(void)
 {
 	unsigned short cpu_address;
 
-	asm volatile("stap %0" : "=m" (cpu_address));
+	asm volatile("stap %0" : "=Q" (cpu_address));
 	return cpu_address;
 }
 

commit 0aaba41b58bc5f3074c0c0a6136b9500b5e29e19
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Aug 22 12:08:22 2017 +0200

    s390: remove all code using the access register mode
    
    The vdso code for the getcpu() and the clock_gettime() call use the access
    register mode to access the per-CPU vdso data page with the current code.
    
    An alternative to the complicated AR mode is to use the secondary space
    mode. This makes the vdso faster and quite a bit simpler. The downside is
    that the uaccess code has to be changed quite a bit.
    
    Which instructions are used depends on the machine and what kind of uaccess
    operation is requested. The instruction dictates which ASCE value needs
    to be loaded into %cr1 and %cr7.
    
    The different cases:
    
    * User copy with MVCOS for z10 and newer machines
      The MVCOS instruction can copy between the primary space (aka user) and
      the home space (aka kernel) directly. For set_fs(KERNEL_DS) the kernel
      ASCE is loaded into %cr1. For set_fs(USER_DS) the user space is already
      loaded in %cr1.
    
    * User copy with MVCP/MVCS for older machines
      To be able to execute the MVCP/MVCS instructions the kernel needs to
      switch to primary mode. The control register %cr1 has to be set to the
      kernel ASCE and %cr7 to either the kernel ASCE or the user ASCE dependent
      on set_fs(KERNEL_DS) vs set_fs(USER_DS).
    
    * Data access in the user address space for strnlen / futex
      To use "normal" instruction with data from the user address space the
      secondary space mode is used. The kernel needs to switch to primary mode,
      %cr1 has to contain the kernel ASCE and %cr7 either the user ASCE or the
      kernel ASCE, dependent on set_fs.
    
    To load a new value into %cr1 or %cr7 is an expensive operation, the kernel
    tries to be lazy about it. E.g. for multiple user copies in a row with
    MVCP/MVCS the replacement of the vdso ASCE in %cr7 with the user ASCE is
    done only once. On return to user space a CPU bit is checked that loads the
    vdso ASCE again.
    
    To enable and disable the data access via the secondary space two new
    functions are added, enable_sacf_uaccess and disable_sacf_uaccess. The fact
    that a context is in secondary space uaccess mode is stored in the
    mm_segment_t value for the task. The code of an interrupt may use set_fs
    as long as it returns to the previous state it got with get_fs with another
    call to set_fs. The code in finish_arch_post_lock_switch simply has to do a
    set_fs with the current mm_segment_t value for the task.
    
    For CPUs with MVCOS:
    
    CPU running in                        | %cr1 ASCE | %cr7 ASCE |
    --------------------------------------|-----------|-----------|
    user space                            |  user     |  vdso     |
    kernel, USER_DS, normal-mode          |  user     |  vdso     |
    kernel, USER_DS, normal-mode, lazy    |  user     |  user     |
    kernel, USER_DS, sacf-mode            |  kernel   |  user     |
    kernel, KERNEL_DS, normal-mode        |  kernel   |  vdso     |
    kernel, KERNEL_DS, normal-mode, lazy  |  kernel   |  kernel   |
    kernel, KERNEL_DS, sacf-mode          |  kernel   |  kernel   |
    
    For CPUs without MVCOS:
    
    CPU running in                        | %cr1 ASCE | %cr7 ASCE |
    --------------------------------------|-----------|-----------|
    user space                            |  user     |  vdso     |
    kernel, USER_DS, normal-mode          |  user     |  vdso     |
    kernel, USER_DS, normal-mode lazy     |  kernel   |  user     |
    kernel, USER_DS, sacf-mode            |  kernel   |  user     |
    kernel, KERNEL_DS, normal-mode        |  kernel   |  vdso     |
    kernel, KERNEL_DS, normal-mode, lazy  |  kernel   |  kernel   |
    kernel, KERNEL_DS, sacf-mode          |  kernel   |  kernel   |
    
    The lines with "lazy" refer to the state after a copy via the secondary
    space with a delayed reload of %cr1 and %cr7.
    
    There are three hardware address spaces that can cause a DAT exception,
    primary, secondary and home space. The exception can be related to
    four different fault types: user space fault, vdso fault, kernel fault,
    and the gmap faults.
    
    Dependent on the set_fs state and normal vs. sacf mode there are a number
    of fault combinations:
    
    1) user address space fault via the primary ASCE
    2) gmap address space fault via the primary ASCE
    3) kernel address space fault via the primary ASCE for machines with
       MVCOS and set_fs(KERNEL_DS)
    4) vdso address space faults via the secondary ASCE with an invalid
       address while running in secondary space in problem state
    5) user address space fault via the secondary ASCE for user-copy
       based on the secondary space mode, e.g. futex_ops or strnlen_user
    6) kernel address space fault via the secondary ASCE for user-copy
       with secondary space mode with set_fs(KERNEL_DS)
    7) kernel address space fault via the primary ASCE for user-copy
       with secondary space mode with set_fs(USER_DS) on machines without
       MVCOS.
    8) kernel address space fault via the home space ASCE
    
    Replace user_space_fault() with a new function get_fault_type() that
    can distinguish all four different fault types.
    
    With these changes the futex atomic ops from the kernel and the
    strnlen_user will get a little bit slower, as well as the old style
    uaccess with MVCP/MVCS. All user accesses based on MVCOS will be as
    fast as before. On the positive side, the user space vdso code is a
    lot faster and Linux ceases to use the complicated AR mode.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index f25bfe888933..709351bce80e 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -109,9 +109,7 @@ extern void execve_tail(void);
 
 #define HAVE_ARCH_PICK_MMAP_LAYOUT
 
-typedef struct {
-        __u32 ar4;
-} mm_segment_t;
+typedef unsigned int mm_segment_t;
 
 /*
  * Thread structure

commit d60a540ac5f2fbab3e6fe592717b445bd7343a91
Merge: 2101dd64b304 364a5607d698
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 13 11:47:01 2017 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux
    
    Pull s390 updates from Heiko Carstens:
     "Since Martin is on vacation you get the s390 pull request for the
      v4.15 merge window this time from me.
    
      Besides a lot of cleanups and bug fixes these are the most important
      changes:
    
       - a new regset for runtime instrumentation registers
    
       - hardware accelerated AES-GCM support for the aes_s390 module
    
       - support for the new CEX6S crypto cards
    
       - support for FORTIFY_SOURCE
    
       - addition of missing z13 and new z14 instructions to the in-kernel
         disassembler
    
       - generate opcode tables for the in-kernel disassembler out of a
         simple text file instead of having to manually maintain those
         tables
    
       - fast memset16, memset32 and memset64 implementations
    
       - removal of named saved segment support
    
       - hardware counter support for z14
    
       - queued spinlocks and queued rwlocks implementations for s390
    
       - use the stack_depth tracking feature for s390 BPF JIT
    
       - a new s390_sthyi system call which emulates the sthyi (store
         hypervisor information) instruction
    
       - removal of the old KVM virtio transport
    
       - an s390 specific CPU alternatives implementation which is used in
         the new spinlock code"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux: (88 commits)
      MAINTAINERS: add virtio-ccw.h to virtio/s390 section
      s390/noexec: execute kexec datamover without DAT
      s390: fix transactional execution control register handling
      s390/bpf: take advantage of stack_depth tracking
      s390: simplify transactional execution elf hwcap handling
      s390/zcrypt: Rework struct ap_qact_ap_info.
      s390/virtio: remove unused header file kvm_virtio.h
      s390: avoid undefined behaviour
      s390/disassembler: generate opcode tables from text file
      s390/disassembler: remove insn_to_mnemonic()
      s390/dasd: avoid calling do_gettimeofday()
      s390: vfio-ccw: Do not attempt to free no-op, test and tic cda.
      s390: remove named saved segment support
      s390/archrandom: Reconsider s390 arch random implementation
      s390/pci: do not require AIS facility
      s390/qdio: sanitize put_indicator
      s390/qdio: use atomic_cmpxchg
      s390/nmi: avoid using long-displacement facility
      s390: pass endianness info to sparse
      s390/decompressor: remove informational messages
      ...

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index c25d57e0aad3..9cf92abe23c3 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  *  S390 version
  *    Copyright IBM Corp. 1999

commit 1887aa07b6765d345dd79f26017aa2d15d49d7af
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Fri Sep 22 14:17:41 2017 +0200

    s390/topology: add detection of dedicated vs shared CPUs
    
    The topology information returned by STSI 15.x.x contains a flag
    if the CPUs of a topology-list are dedicated or shared. Make this
    information available if the machine provides topology information.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 58eaaccd3cf0..4c5fde30d741 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -21,6 +21,7 @@
 #define CIF_IGNORE_IRQ		5	/* ignore interrupt (for udelay) */
 #define CIF_ENABLED_WAIT	6	/* in enabled wait state */
 #define CIF_MCCK_GUEST		7	/* machine check happening in guest */
+#define CIF_DEDICATED_CPU	8	/* this CPU is dedicated */
 
 #define _CIF_MCCK_PENDING	_BITUL(CIF_MCCK_PENDING)
 #define _CIF_ASCE_PRIMARY	_BITUL(CIF_ASCE_PRIMARY)
@@ -30,6 +31,7 @@
 #define _CIF_IGNORE_IRQ		_BITUL(CIF_IGNORE_IRQ)
 #define _CIF_ENABLED_WAIT	_BITUL(CIF_ENABLED_WAIT)
 #define _CIF_MCCK_GUEST		_BITUL(CIF_MCCK_GUEST)
+#define _CIF_DEDICATED_CPU	_BITUL(CIF_DEDICATED_CPU)
 
 #ifndef __ASSEMBLY__
 

commit 7b83c6297d2fc7350997e86188df84c27fd59530
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon Sep 11 11:24:23 2017 +0200

    s390/guarded storage: simplify task exit handling
    
    Free data structures required for guarded storage from
    arch_release_task_struct(). This allows to simplify the code a bit,
    and also makes the semantics a bit easier: arch_release_task_struct()
    is never called from the task that is being removed.
    
    In addition this allows to get rid of exit_thread() in a later patch.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 4cc9bf53074b..58eaaccd3cf0 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -220,8 +220,8 @@ void show_cacheinfo(struct seq_file *m);
 /* Free all resources held by a thread. */
 static inline void release_thread(struct task_struct *tsk) { }
 
-/* Free guarded storage control block for current */
-void exit_thread_gs(void);
+/* Free guarded storage control block */
+void guarded_storage_release(struct task_struct *tsk);
 
 unsigned long get_wchan(struct task_struct *p);
 #define task_pt_regs(tsk) ((struct pt_regs *) \

commit 8076428f0c9f24d90270204fd39ccb11b83db71d
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon Sep 11 11:24:22 2017 +0200

    s390: convert release_thread() into a static inline function
    
    release_thread() is an empty function that gets called on every task
    exit. Move the function to a header file and force inlining of it, so
    that the compiler can optimize it away instead of generating a
    pointless function call.
    
    Acked-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index c25d57e0aad3..4cc9bf53074b 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -218,7 +218,7 @@ void show_registers(struct pt_regs *regs);
 void show_cacheinfo(struct seq_file *m);
 
 /* Free all resources held by a thread. */
-extern void release_thread(struct task_struct *);
+static inline void release_thread(struct task_struct *tsk) { }
 
 /* Free guarded storage control block for current */
 void exit_thread_gs(void);

commit e0f3e8f14da868047c524a0cf11e08b95fd1b008
Merge: e5859eb84576 9e293b5a7062
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 3 15:39:36 2017 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux
    
    Pull s390 updates from Martin Schwidefsky:
     "The bulk of the s390 patches for 4.13. Some new things but mostly bug
      fixes and cleanups. Noteworthy changes:
    
       - The SCM block driver is converted to blk-mq
    
       - Switch s390 to 5 level page tables. The virtual address space for a
         user space process can now have up to 16EB-4KB.
    
       - Introduce a ELF phdr flag for qemu to avoid the global
         vm.alloc_pgste which forces all processes to large page tables
    
       - A couple of PCI improvements to improve error recovery
    
       - Included is the merge of the base support for proper machine checks
         for KVM"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux: (52 commits)
      s390/dasd: Fix faulty ENODEV for RO sysfs attribute
      s390/pci: recognize name clashes with uids
      s390/pci: provide more debug information
      s390/pci: fix handling of PEC 306
      s390/pci: improve pci hotplug
      s390/pci: introduce clp_get_state
      s390/pci: improve error handling during fmb (de)registration
      s390/pci: improve unreg_ioat error handling
      s390/pci: improve error handling during interrupt deregistration
      s390/pci: don't cleanup in arch_setup_msi_irqs
      KVM: s390: Backup the guest's machine check info
      s390/nmi: s390: New low level handling for machine check happening in guest
      s390/fpu: export save_fpu_regs for all configs
      s390/kvm: avoid global config of vm.alloc_pgste=1
      s390: rename struct psw_bits members
      s390: rename psw_bits enums
      s390/mm: use correct address space when enabling DAT
      s390/cio: introduce io_subchannel_type
      s390/ipl: revert Load Normal semantics for LPAR CCW-type re-IPL
      s390/dumpstack: remove raw stack dump
      ...

commit 6474924e2b5ddb0030c355558966adcbe3b49022
Author: Tobias Klauser <tklauser@distanz.ch>
Date:   Wed Jun 28 15:30:02 2017 +0200

    arch: remove unused macro/function thread_saved_pc()
    
    The only user of thread_saved_pc() in non-arch-specific code was removed
    in commit 8243d5597793 ("sched/core: Remove pointless printout in
    sched_show_task()").  Remove the implementations as well.
    
    Some architectures use thread_saved_pc() in their arch-specific code.
    Leave their thread_saved_pc() intact.
    
    Signed-off-by: Tobias Klauser <tklauser@distanz.ch>
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 60d395fdc864..aeac013968f2 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -221,11 +221,6 @@ extern void release_thread(struct task_struct *);
 /* Free guarded storage control block for current */
 void exit_thread_gs(void);
 
-/*
- * Return saved PC of a blocked thread.
- */
-extern unsigned long thread_saved_pc(struct task_struct *t);
-
 unsigned long get_wchan(struct task_struct *p);
 #define task_pt_regs(tsk) ((struct pt_regs *) \
         (task_stack_page(tsk) + THREAD_SIZE) - 1)

commit 9e293b5a7062981016ace93160c56a980fcb73b8
Merge: 795c9a510611 da72ca4d4090
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Wed Jun 28 12:57:47 2017 +0200

    Merge tag 'nmiforkvm' of git://git.kernel.org/pub/scm/linux/kernel/git/kvms390/linux into features
    
    Pull kvm patches from Christian Borntraeger:
    "s390,kvm: provide plumbing for machines checks when running guests"
    
    This provides the basic plumbing for handling machine checks when
    running guests

commit c929500d7a5aaea4f2eeba10816bc5341c66ae57
Author: QingFeng Hao <haoqf@linux.vnet.ibm.com>
Date:   Wed Jun 7 11:30:42 2017 +0200

    s390/nmi: s390: New low level handling for machine check happening in guest
    
    Add the logic to check if the machine check happens when the guest is
    running. If yes, set the exit reason -EINTR in the machine check's
    interrupt handler. Refactor s390_do_machine_check to avoid panicing
    the host for some kinds of machine checks which happen
    when guest is running.
    Reinject the instruction processing damage's machine checks including
    Delayed Access Exception instead of damaging the host if it happens
    in the guest because it could be caused by improper update on TLB entry
    or other software case and impacts the guest only.
    
    Signed-off-by: QingFeng Hao <haoqf@linux.vnet.ibm.com>
    Acked-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Acked-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Acked-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 60d395fdc864..5b1b247dfbca 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -20,6 +20,7 @@
 #define CIF_FPU			4	/* restore FPU registers */
 #define CIF_IGNORE_IRQ		5	/* ignore interrupt (for udelay) */
 #define CIF_ENABLED_WAIT	6	/* in enabled wait state */
+#define CIF_MCCK_GUEST		7	/* machine check happening in guest */
 
 #define _CIF_MCCK_PENDING	_BITUL(CIF_MCCK_PENDING)
 #define _CIF_ASCE_PRIMARY	_BITUL(CIF_ASCE_PRIMARY)
@@ -28,6 +29,7 @@
 #define _CIF_FPU		_BITUL(CIF_FPU)
 #define _CIF_IGNORE_IRQ		_BITUL(CIF_IGNORE_IRQ)
 #define _CIF_ENABLED_WAIT	_BITUL(CIF_ENABLED_WAIT)
+#define _CIF_MCCK_GUEST		_BITUL(CIF_MCCK_GUEST)
 
 #ifndef __ASSEMBLY__
 

commit 1aea9b3f921003f0880f0676ae85d87c9f1cb4a2
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Mon Apr 24 18:19:10 2017 +0200

    s390/mm: implement 5 level pages tables
    
    Add the logic to upgrade the page table for a 64-bit process to
    five levels. This increases the TASK_SIZE from 8PB to 16EB-4K.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 60d395fdc864..f57c017a5c03 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -92,11 +92,11 @@ extern void execve_tail(void);
  */
 
 #define TASK_SIZE_OF(tsk)	(test_tsk_thread_flag(tsk, TIF_31BIT) ? \
-					(1UL << 31) : (1UL << 53))
+					(1UL << 31) : -PAGE_SIZE)
 #define TASK_UNMAPPED_BASE	(test_thread_flag(TIF_31BIT) ? \
 					(1UL << 30) : (1UL << 41))
 #define TASK_SIZE		TASK_SIZE_OF(current)
-#define TASK_SIZE_MAX		(1UL << 53)
+#define TASK_SIZE_MAX		(-PAGE_SIZE)
 
 #define STACK_TOP		(test_thread_flag(TIF_31BIT) ? \
 					(1UL << 31) : (1UL << 42))

commit ee71d16d22bb268c1f6a64ef6d3654ace5f1e8c7
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Thu Apr 20 14:43:51 2017 +0200

    s390/mm: make TASK_SIZE independent from the number of page table levels
    
    The TASK_SIZE for a process should be maximum possible size of the address
    space, 2GB for a 31-bit process and 8PB for a 64-bit process. The number
    of page table levels required for a given memory layout is a consequence
    of the mapped memory areas and their location.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index cc101f9371cb..60d395fdc864 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -91,14 +91,15 @@ extern void execve_tail(void);
  * User space process size: 2GB for 31 bit, 4TB or 8PT for 64 bit.
  */
 
-#define TASK_SIZE_OF(tsk)	((tsk)->mm ? \
-				 (tsk)->mm->context.asce_limit : TASK_MAX_SIZE)
+#define TASK_SIZE_OF(tsk)	(test_tsk_thread_flag(tsk, TIF_31BIT) ? \
+					(1UL << 31) : (1UL << 53))
 #define TASK_UNMAPPED_BASE	(test_thread_flag(TIF_31BIT) ? \
 					(1UL << 30) : (1UL << 41))
 #define TASK_SIZE		TASK_SIZE_OF(current)
-#define TASK_MAX_SIZE		(1UL << 53)
+#define TASK_SIZE_MAX		(1UL << 53)
 
-#define STACK_TOP		(1UL << (test_thread_flag(TIF_31BIT) ? 31:42))
+#define STACK_TOP		(test_thread_flag(TIF_31BIT) ? \
+					(1UL << 31) : (1UL << 42))
 #define STACK_TOP_MAX		(1UL << 42)
 
 #define HAVE_ARCH_PICK_MMAP_LAYOUT

commit 916cda1aa1b412d7cf2991c3af7479544942d121
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Jan 26 14:10:34 2016 +0100

    s390: add a system call for guarded storage
    
    This adds a new system call to enable the use of guarded storage for
    user space processes. The system call takes two arguments, a command
    and pointer to a guarded storage control block:
    
        s390_guarded_storage(int command, struct gs_cb *gs_cb);
    
    The second argument is relevant only for the GS_SET_BC_CB command.
    
    The commands in detail:
    
    0 - GS_ENABLE
        Enable the guarded storage facility for the current task. The
        initial content of the guarded storage control block will be
        all zeros. After the enablement the user space code can use
        load-guarded-storage-controls instruction (LGSC) to load an
        arbitrary control block. While a task is enabled the kernel
        will save and restore the current content of the guarded
        storage registers on context switch.
    1 - GS_DISABLE
        Disables the use of the guarded storage facility for the current
        task. The kernel will cease to save and restore the content of
        the guarded storage registers, the task specific content of
        these registers is lost.
    2 - GS_SET_BC_CB
        Set a broadcast guarded storage control block. This is called
        per thread and stores a specific guarded storage control block
        in the task struct of the current task. This control block will
        be used for the broadcast event GS_BROADCAST.
    3 - GS_CLEAR_BC_CB
        Clears the broadcast guarded storage control block. The guarded-
        storage control block is removed from the task struct that was
        established by GS_SET_BC_CB.
    4 - GS_BROADCAST
        Sends a broadcast to all thread siblings of the current task.
        Every sibling that has established a broadcast guarded storage
        control block will load this control block and will be enabled
        for guarded storage. The broadcast guarded storage control block
        is used up, a second broadcast without a refresh of the stored
        control block with GS_SET_BC_CB will not have any effect.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index e4988710aa86..cc101f9371cb 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -135,6 +135,8 @@ struct thread_struct {
 	struct list_head list;
 	/* cpu runtime instrumentation */
 	struct runtime_instr_cb *ri_cb;
+	struct gs_cb *gs_cb;		/* Current guarded storage cb */
+	struct gs_cb *gs_bc_cb;		/* Broadcast guarded storage cb */
 	unsigned char trap_tdb[256];	/* Transaction abort diagnose block */
 	/*
 	 * Warning: 'fpu' is dynamically-sized. It *MUST* be at
@@ -215,6 +217,9 @@ void show_cacheinfo(struct seq_file *m);
 /* Free all resources held by a thread. */
 extern void release_thread(struct task_struct *);
 
+/* Free guarded storage control block for current */
+void exit_thread_gs(void);
+
 /*
  * Return saved PC of a blocked thread.
  */

commit fb94a687d96c570d46332a4a890f1dcb7310e643
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Fri Feb 24 07:43:51 2017 +0100

    s390: TASK_SIZE for kernel threads
    
    Return a sensible value if TASK_SIZE if called from a kernel thread.
    
    This gets us around an issue with copy_mount_options that does a magic
    size calculation "TASK_SIZE - (unsigned long)data" while in a kernel
    thread and data pointing to kernel space.
    
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index c57c5c2f2484..e4988710aa86 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -91,7 +91,8 @@ extern void execve_tail(void);
  * User space process size: 2GB for 31 bit, 4TB or 8PT for 64 bit.
  */
 
-#define TASK_SIZE_OF(tsk)	((tsk)->mm->context.asce_limit)
+#define TASK_SIZE_OF(tsk)	((tsk)->mm ? \
+				 (tsk)->mm->context.asce_limit : TASK_MAX_SIZE)
 #define TASK_UNMAPPED_BASE	(test_thread_flag(TIF_31BIT) ? \
 					(1UL << 30) : (1UL << 41))
 #define TASK_SIZE		TASK_SIZE_OF(current)

commit b5a882fcf146c87cb6b67c6df353e1c042b8773d
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Fri Feb 17 08:13:28 2017 +0100

    s390: restore address space when returning to user space
    
    Unbalanced set_fs usages (e.g. early exit from a function and a
    forgotten set_fs(USER_DS) call) may lead to a situation where the
    secondary asce is the kernel space asce when returning to user
    space. This would allow user space to modify kernel space at will.
    
    This would only be possible with the above mentioned kernel bug,
    however we can detect this and fix the secondary asce before returning
    to user space.
    
    Therefore a new TIF_ASCE_SECONDARY which is used within set_fs. When
    returning to user space check if TIF_ASCE_SECONDARY is set, which
    would indicate a bug. If it is set print a message to the console,
    fixup the secondary asce, and then return to user space.
    
    This is similar to what is being discussed for x86 and arm:
    "[RFC] syscalls: Restore address limit after a syscall".
    
    Reviewed-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 3c8fae02ac2d..c57c5c2f2484 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -15,13 +15,15 @@
 
 #define CIF_MCCK_PENDING	0	/* machine check handling is pending */
 #define CIF_ASCE_PRIMARY	1	/* primary asce needs fixup / uaccess */
-#define CIF_NOHZ_DELAY		2	/* delay HZ disable for a tick */
-#define CIF_FPU			3	/* restore FPU registers */
-#define CIF_IGNORE_IRQ		4	/* ignore interrupt (for udelay) */
-#define CIF_ENABLED_WAIT	5	/* in enabled wait state */
+#define CIF_ASCE_SECONDARY	2	/* secondary asce needs fixup / uaccess */
+#define CIF_NOHZ_DELAY		3	/* delay HZ disable for a tick */
+#define CIF_FPU			4	/* restore FPU registers */
+#define CIF_IGNORE_IRQ		5	/* ignore interrupt (for udelay) */
+#define CIF_ENABLED_WAIT	6	/* in enabled wait state */
 
 #define _CIF_MCCK_PENDING	_BITUL(CIF_MCCK_PENDING)
 #define _CIF_ASCE_PRIMARY	_BITUL(CIF_ASCE_PRIMARY)
+#define _CIF_ASCE_SECONDARY	_BITUL(CIF_ASCE_SECONDARY)
 #define _CIF_NOHZ_DELAY		_BITUL(CIF_NOHZ_DELAY)
 #define _CIF_FPU		_BITUL(CIF_FPU)
 #define _CIF_IGNORE_IRQ		_BITUL(CIF_IGNORE_IRQ)
@@ -200,10 +202,12 @@ struct stack_frame {
 struct task_struct;
 struct mm_struct;
 struct seq_file;
+struct pt_regs;
 
 typedef int (*dump_trace_func_t)(void *data, unsigned long address, int reliable);
 void dump_trace(dump_trace_func_t func, void *data,
 		struct task_struct *task, unsigned long sp);
+void show_registers(struct pt_regs *regs);
 
 void show_cacheinfo(struct seq_file *m);
 

commit 606aa4aa0b2c6d7c4f5d2e459922675ea1d7e459
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Fri Feb 17 08:12:30 2017 +0100

    s390: rename CIF_ASCE to CIF_ASCE_PRIMARY
    
    This is just a preparation patch in order to keep the "restore address
    space after syscall" patch small.
    Rename CIF_ASCE to CIF_ASCE_PRIMARY to be unique and specific when
    introducing a second CIF_ASCE_SECONDARY CIF flag.
    
    Suggested-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index dacba341e475..3c8fae02ac2d 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -14,14 +14,14 @@
 #include <linux/const.h>
 
 #define CIF_MCCK_PENDING	0	/* machine check handling is pending */
-#define CIF_ASCE		1	/* user asce needs fixup / uaccess */
+#define CIF_ASCE_PRIMARY	1	/* primary asce needs fixup / uaccess */
 #define CIF_NOHZ_DELAY		2	/* delay HZ disable for a tick */
 #define CIF_FPU			3	/* restore FPU registers */
 #define CIF_IGNORE_IRQ		4	/* ignore interrupt (for udelay) */
 #define CIF_ENABLED_WAIT	5	/* in enabled wait state */
 
 #define _CIF_MCCK_PENDING	_BITUL(CIF_MCCK_PENDING)
-#define _CIF_ASCE		_BITUL(CIF_ASCE)
+#define _CIF_ASCE_PRIMARY	_BITUL(CIF_ASCE_PRIMARY)
 #define _CIF_NOHZ_DELAY		_BITUL(CIF_NOHZ_DELAY)
 #define _CIF_FPU		_BITUL(CIF_FPU)
 #define _CIF_IGNORE_IRQ		_BITUL(CIF_IGNORE_IRQ)

commit ff47d8c05019d6e7753cef270d6399cb5a33be57
Merge: 3051bf36c25d d24b98e3a9c6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Feb 22 10:20:04 2017 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux
    
    Pull s390 updates from Martin Schwidefsky:
    
     - New entropy generation for the pseudo random number generator.
    
     - Early boot printk output via sclp to help debug crashes on boot. This
       needs to be enabled with a kernel parameter.
    
     - Add proper no-execute support with a bit in the page table entry.
    
     - Bug fixes and cleanups.
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux: (65 commits)
      s390/syscall: fix single stepped system calls
      s390/zcrypt: make ap_bus explicitly non-modular
      s390/zcrypt: Removed unneeded debug feature directory creation.
      s390: add missing "do {} while (0)" loop constructs to multiline macros
      s390/mm: add cond_resched call to kernel page table dumper
      s390: get rid of MACHINE_HAS_PFMF and MACHINE_HAS_HPAGE
      s390/mm: make memory_block_size_bytes available for !MEMORY_HOTPLUG
      s390: replace ACCESS_ONCE with READ_ONCE
      s390: Audit and remove any remaining unnecessary uses of module.h
      s390: mm: Audit and remove any unnecessary uses of module.h
      s390: kernel: Audit and remove any unnecessary uses of module.h
      s390/kdump: Use "LINUX" ELF note name instead of "CORE"
      s390: add no-execute support
      s390: report new vector facilities
      s390: use correct input data address for setup_randomness
      s390/sclp: get rid of common response code handling
      s390/sclp: don't add new lines to each printed string
      s390/sclp: make early sclp code readable
      s390/sclp: disable early sclp code as soon as the base sclp driver is active
      s390/sclp: move early printk code to drivers
      ...

commit 1228f7befbf3280906e75f532a1700c7d3138117
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Thu Feb 16 10:41:52 2017 +0100

    s390: add missing "do {} while (0)" loop constructs to multiline macros
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 6bca916a5ba0..2e21c645343c 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -358,12 +358,12 @@ extern void (*s390_base_ext_handler_fn)(void);
 extern int memcpy_real(void *, void *, size_t);
 extern void memcpy_absolute(void *, void *, size_t);
 
-#define mem_assign_absolute(dest, val) {			\
+#define mem_assign_absolute(dest, val) do {			\
 	__typeof__(dest) __tmp = (val);				\
 								\
 	BUILD_BUG_ON(sizeof(__tmp) != sizeof(val));		\
 	memcpy_absolute(&(dest), &__tmp, sizeof(__tmp));	\
-}
+} while (0)
 
 #endif /* __ASSEMBLY__ */
 

commit b7394a5f4ce9542666cc68422c3594ea854adc2c
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Thu Jan 5 18:11:49 2017 +0100

    sched/cputime, s390: Implement delayed accounting of system time
    
    The account_system_time() function is called with a cputime that
    occurred while running in the kernel. The function detects which
    context the CPU is currently running in and accounts the time to
    the correct bucket. This forces the arch code to account the
    cputime for hardirq and softirq immediately.
    
    Such accounting function can be costly and perform unwelcome divisions
    and multiplications, among others.
    
    The arch code can delay the accounting for system time. For s390
    the accounting is done once per timer tick and for each task switch.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    [ Rebase against latest linus tree and move account_system_index_scaled(). ]
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1483636310-6557-10-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 6bca916a5ba0..977a5b6501b8 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -111,7 +111,10 @@ struct thread_struct {
 	unsigned int  acrs[NUM_ACRS];
         unsigned long ksp;              /* kernel stack pointer             */
 	unsigned long user_timer;	/* task cputime in user space */
+	unsigned long guest_timer;	/* task cputime in kvm guest */
 	unsigned long system_timer;	/* task cputime in kernel space */
+	unsigned long hardirq_timer;	/* task cputime in hardirq context */
+	unsigned long softirq_timer;	/* task cputime in softirq context */
 	unsigned long sys_call_table;	/* system call table address */
 	mm_segment_t mm_segment;
 	unsigned long gmap_addr;	/* address of last gmap fault. */

commit 2ec4584eb89b8933d1ee307f2fc9c42e745847d7
Merge: aa3ecf388adc c19805f870c1
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 13 16:33:33 2016 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux
    
    Pull s390 updates from Martin Schwidefsky:
     "The main bulk of the s390 patches for the 4.10 merge window:
    
       - Add support for the contiguous memory allocator.
    
       - The recovery for I/O errors in the dasd device driver is improved,
         the driver will now remove channel paths that are not working
         properly.
    
       - Additional fields are added to /proc/sysinfo, the extended
         partition name and the partition UUID.
    
       - New naming for PCI devices with system defined UIDs.
    
       - The last few remaining alloc_bootmem calls are converted to
         memblock.
    
       - The thread_info structure is stripped down and moved to the
         task_struct. The only field left in thread_info is the flags field.
    
       - Rework of the arch topology code to fix a fake numa issue.
    
       - Refactoring of the atomic primitives and add a new preempt_count
         implementation.
    
       - Clocksource steering for the STP sync check offsets.
    
       - The s390 specific headers are changed to make them usable with
         CLANG.
    
       - Bug fixes and cleanup"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux: (70 commits)
      s390/cpumf: Use configuration level indication for sampling data
      s390: provide memmove implementation
      s390: cleanup arch/s390/kernel Makefile
      s390: fix initrd corruptions with gcov/kcov instrumented kernels
      s390: exclude early C code from gcov profiling
      s390/dasd: channel path aware error recovery
      s390/dasd: extend dasd path handling
      s390: remove unused labels from entry.S
      s390/vmlogrdr: fix IUCV buffer allocation
      s390/crypto: unlock on error in prng_tdes_read()
      s390/sysinfo: show partition extended name and UUID if available
      s390/numa: pin all possible cpus to nodes early
      s390/numa: establish cpu to node mapping early
      s390/topology: use cpu_topology array instead of per cpu variable
      s390/smp: initialize cpu_present_mask in setup_arch
      s390/topology: always use s390 specific sched_domain_topology_level
      s390/smp: use smp_get_base_cpu() helper function
      s390/numa: always use logical cpu and core ids
      s390: Remove VLAIS in ptff() and clear_table()
      s390: fix machine check panic stack switch
      ...

commit 6d0d287891a022ebba572327cbd70b5de69a63a2
Author: Christian Borntraeger <borntraeger@de.ibm.com>
Date:   Wed Nov 16 13:23:05 2016 +0100

    locking/core: Provide common cpu_relax_yield() definition
    
    No need to duplicate the same define everywhere. Since
    the only user is stop-machine and the only provider is
    s390, we can use a default implementation of cpu_relax_yield()
    in sched.h.
    
    Suggested-by: Russell King <rmk+kernel@armlinux.org.uk>
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Reviewed-by: David Hildenbrand <david@redhat.com>
    Acked-by: Russell King <rmk+kernel@armlinux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Nicholas Piggin <npiggin@gmail.com>
    Cc: Noam Camus <noamc@ezchip.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: kvm@vger.kernel.org
    Cc: linux-arch@vger.kernel.org
    Cc: linux-s390 <linux-s390@vger.kernel.org>
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: sparclinux@vger.kernel.org
    Cc: virtualization@lists.linux-foundation.org
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/1479298985-191589-1-git-send-email-borntraeger@de.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 9e32f25bdea3..9d3a21aedc97 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -234,6 +234,7 @@ static inline unsigned short stap(void)
 /*
  * Give up the time slice of the virtual PU.
  */
+#define cpu_relax_yield cpu_relax_yield
 void cpu_relax_yield(void);
 
 #define cpu_relax() barrier()

commit 5bd0b85ba8bb9de6f61f33f3752fc85f4c87fc22
Author: Christian Borntraeger <borntraeger@de.ibm.com>
Date:   Tue Oct 25 11:03:15 2016 +0200

    locking/core, arch: Remove cpu_relax_lowlatency()
    
    As there are no users left, we can remove cpu_relax_lowlatency()
    implementations from every architecture.
    
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Nicholas Piggin <npiggin@gmail.com>
    Cc: Noam Camus <noamc@ezchip.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: virtualization@lists.linux-foundation.org
    Cc: xen-devel@lists.xenproject.org
    Cc: <linux-arch@vger.kernel.org>
    Link: http://lkml.kernel.org/r/1477386195-32736-6-git-send-email-borntraeger@de.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 79343e37b455..9e32f25bdea3 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -237,7 +237,6 @@ static inline unsigned short stap(void)
 void cpu_relax_yield(void);
 
 #define cpu_relax() barrier()
-#define cpu_relax_lowlatency()  barrier()
 
 #define ECAG_CACHE_ATTRIBUTE	0
 #define ECAG_CPU_ATTRIBUTE	1

commit 22b6430d36659b37ed139b7fd87fcc7237fb0cfd
Author: Christian Borntraeger <borntraeger@de.ibm.com>
Date:   Tue Oct 25 11:03:13 2016 +0200

    locking/core, s390: Make cpu_relax() a barrier again
    
    stop_machine() seemed to be the only important place for yielding during
    cpu_relax(). This was fixed by using cpu_relax_yield().
    
    Therefore, we can now redefine cpu_relax() to be a barrier instead on s390,
    making s390 identical to all other architectures.
    
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Nicholas Piggin <npiggin@gmail.com>
    Cc: Noam Camus <noamc@ezchip.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: virtualization@lists.linux-foundation.org
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/1477386195-32736-4-git-send-email-borntraeger@de.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 5bb44333d320..79343e37b455 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -236,7 +236,7 @@ static inline unsigned short stap(void)
  */
 void cpu_relax_yield(void);
 
-#define cpu_relax() cpu_relax_yield()
+#define cpu_relax() barrier()
 #define cpu_relax_lowlatency()  barrier()
 
 #define ECAG_CACHE_ATTRIBUTE	0

commit 79ab11cdb90d8536817ab7357ecb6b1ff76be26c
Author: Christian Borntraeger <borntraeger@de.ibm.com>
Date:   Tue Oct 25 11:03:11 2016 +0200

    locking/core: Introduce cpu_relax_yield()
    
    For spinning loops people do often use barrier() or cpu_relax().
    For most architectures cpu_relax and barrier are the same, but on
    some architectures cpu_relax can add some latency.
    For example on power,sparc64 and arc, cpu_relax can shift the CPU
    towards other hardware threads in an SMT environment.
    On s390 cpu_relax does even more, it uses an hypercall to the
    hypervisor to give up the timeslice.
    In contrast to the SMT yielding this can result in larger latencies.
    In some places this latency is unwanted, so another variant
    "cpu_relax_lowlatency" was introduced. Before this is used in more
    and more places, lets revert the logic and provide a cpu_relax_yield
    that can be called in places where yielding is more important than
    latency. By default this is the same as cpu_relax on all architectures.
    
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Nicholas Piggin <npiggin@gmail.com>
    Cc: Noam Camus <noamc@ezchip.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: virtualization@lists.linux-foundation.org
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/1477386195-32736-2-git-send-email-borntraeger@de.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 602af692efdc..5bb44333d320 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -234,8 +234,9 @@ static inline unsigned short stap(void)
 /*
  * Give up the time slice of the virtual PU.
  */
-void cpu_relax(void);
+void cpu_relax_yield(void);
 
+#define cpu_relax() cpu_relax_yield()
 #define cpu_relax_lowlatency()  barrier()
 
 #define ECAG_CACHE_ATTRIBUTE	0

commit ef280c859f4c1592696b91d602dc19add1021697
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Nov 8 12:33:38 2016 +0100

    s390: move sys_call_table and last_break from thread_info to thread_struct
    
    Move the last two architecture specific fields from the thread_info
    structure to the thread_struct. All that is left in thread_info is
    the flags field.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index ecfa40874f79..9c00351f1545 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -112,6 +112,7 @@ struct thread_struct {
         unsigned long ksp;              /* kernel stack pointer             */
 	unsigned long user_timer;	/* task cputime in user space */
 	unsigned long system_timer;	/* task cputime in kernel space */
+	unsigned long sys_call_table;	/* system call table address */
 	mm_segment_t mm_segment;
 	unsigned long gmap_addr;	/* address of last gmap fault. */
 	unsigned int gmap_write_flag;	/* gmap fault write indication */
@@ -122,6 +123,7 @@ struct thread_struct {
 	struct per_event per_event;	/* Cause of the last PER trap */
 	unsigned long per_flags;	/* Flags to control debug behavior */
 	unsigned int system_call;	/* system call number in signal */
+	unsigned long last_break;	/* last breaking-event-address. */
         /* pfault_wait is used to block the process on a pfault event */
 	unsigned long pfault_wait;
 	struct list_head list;

commit 90c53e65806323382e8bff212cc993700a4a62d9
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Nov 8 12:15:59 2016 +0100

    s390: move cputime accounting fields from thread_info to thread_struct
    
    The user_timer and system_timer fields are used for the per-thread
    cputime accounting code. The access to these values is simpler if
    they are moved to the thread_struct as the task_thread_info(tsk)
    indirection is not needed anymore.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index f96a3711b475..ecfa40874f79 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -110,6 +110,8 @@ typedef struct {
 struct thread_struct {
 	unsigned int  acrs[NUM_ACRS];
         unsigned long ksp;              /* kernel stack pointer             */
+	unsigned long user_timer;	/* task cputime in user space */
+	unsigned long system_timer;	/* task cputime in kernel space */
 	mm_segment_t mm_segment;
 	unsigned long gmap_addr;	/* address of last gmap fault. */
 	unsigned int gmap_write_flag;	/* gmap fault write indication */

commit f8fc82b47149e3449d23e94d6ecf30af2ffcebff
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Nov 8 11:11:02 2016 +0100

    s390: move system_call field from thread_info to thread_struct
    
    The system_call field in thread_info structure is used by the signal
    code to store the number of the current system call while the debugger
    interacts with its inferior. A better location for the system_call
    field is with the other debugger related information in the
    thread_struct.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 602af692efdc..f96a3711b475 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -115,9 +115,11 @@ struct thread_struct {
 	unsigned int gmap_write_flag;	/* gmap fault write indication */
 	unsigned int gmap_int_code;	/* int code of last gmap fault */
 	unsigned int gmap_pfault;	/* signal of a pending guest pfault */
+	/* Per-thread information related to debugging */
 	struct per_regs per_user;	/* User specified PER registers */
 	struct per_event per_event;	/* Cause of the last PER trap */
 	unsigned long per_flags;	/* Flags to control debug behavior */
+	unsigned int system_call;	/* system call number in signal */
         /* pfault_wait is used to block the process on a pfault event */
 	unsigned long pfault_wait;
 	struct list_head list;

commit d0208639dbc6fe97a25054df44faa2d19aca9380
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon Oct 17 11:08:31 2016 +0200

    s390/dumpstack: restore reliable indicator for call traces
    
    Before merging all different stack tracers the call traces printed had
    an indicator if an entry can be considered reliable or not.
    Unreliable entries were put in braces, reliable not. Currently all
    lines contain these extra braces.
    
    This patch restores the old behaviour by adding an extra "reliable"
    parameter to the callback functions. Only show_trace makes currently
    use of it.
    
    Before:
    [    0.804751] Call Trace:
    [    0.804753] ([<000000000017d0e0>] try_to_wake_up+0x318/0x5e0)
    [    0.804756] ([<0000000000161d64>] create_worker+0x174/0x1c0)
    
    After:
    [    0.804751] Call Trace:
    [    0.804753] ([<000000000017d0e0>] try_to_wake_up+0x318/0x5e0)
    [    0.804756]  [<0000000000161d64>] create_worker+0x174/0x1c0
    
    Fixes: 758d39ebd3d5 ("s390/dumpstack: merge all four stack tracers")
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 03323175de30..602af692efdc 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -192,7 +192,7 @@ struct task_struct;
 struct mm_struct;
 struct seq_file;
 
-typedef int (*dump_trace_func_t)(void *data, unsigned long address);
+typedef int (*dump_trace_func_t)(void *data, unsigned long address, int reliable);
 void dump_trace(dump_trace_func_t func, void *data,
 		struct task_struct *task, unsigned long sp);
 

commit 221bb8a46e230b9824204ae86537183d9991ff2a
Merge: f7b32e4c021f 23528bb21ee2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Aug 2 16:11:27 2016 -0400

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull KVM updates from Paolo Bonzini:
    
     - ARM: GICv3 ITS emulation and various fixes.  Removal of the
       old VGIC implementation.
    
     - s390: support for trapping software breakpoints, nested
       virtualization (vSIE), the STHYI opcode, initial extensions
       for CPU model support.
    
     - MIPS: support for MIPS64 hosts (32-bit guests only) and lots
       of cleanups, preliminary to this and the upcoming support for
       hardware virtualization extensions.
    
     - x86: support for execute-only mappings in nested EPT; reduced
       vmexit latency for TSC deadline timer (by about 30%) on Intel
       hosts; support for more than 255 vCPUs.
    
     - PPC: bugfixes.
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (302 commits)
      KVM: PPC: Introduce KVM_CAP_PPC_HTM
      MIPS: Select HAVE_KVM for MIPS64_R{2,6}
      MIPS: KVM: Reset CP0_PageMask during host TLB flush
      MIPS: KVM: Fix ptr->int cast via KVM_GUEST_KSEGX()
      MIPS: KVM: Sign extend MFC0/RDHWR results
      MIPS: KVM: Fix 64-bit big endian dynamic translation
      MIPS: KVM: Fail if ebase doesn't fit in CP0_EBase
      MIPS: KVM: Use 64-bit CP0_EBase when appropriate
      MIPS: KVM: Set CP0_Status.KX on MIPS64
      MIPS: KVM: Make entry code MIPS64 friendly
      MIPS: KVM: Use kmap instead of CKSEG0ADDR()
      MIPS: KVM: Use virt_to_phys() to get commpage PFN
      MIPS: Fix definition of KSEGX() for 64-bit
      KVM: VMX: Add VMCS to CPU's loaded VMCSs before VMPTRLD
      kvm: x86: nVMX: maintain internal copy of current VMCS
      KVM: PPC: Book3S HV: Save/restore TM state in H_CEDE
      KVM: PPC: Book3S HV: Pull out TM state save/restore into separate procedures
      KVM: arm64: vgic-its: Simplify MAPI error handling
      KVM: arm64: vgic-its: Make vgic_its_cmd_handle_mapi similar to other handlers
      KVM: arm64: vgic-its: Turn device_id validation into generic ID validation
      ...

commit 4a49443924731823da2e9b3ae9311b74a34e7ed8
Author: David Hildenbrand <dahi@linux.vnet.ibm.com>
Date:   Tue Mar 8 12:31:52 2016 +0100

    s390/mm: remember the int code for the last gmap fault
    
    For nested virtualization, we want to know if we are handling a protection
    exception, because these can directly be forwarded to the guest without
    additional checks.
    
    Acked-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: David Hildenbrand <dahi@linux.vnet.ibm.com>
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 94c80b6d031d..8c2922f540f9 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -110,6 +110,7 @@ struct thread_struct {
 	mm_segment_t mm_segment;
 	unsigned long gmap_addr;	/* address of last gmap fault. */
 	unsigned int gmap_write_flag;	/* gmap fault write indication */
+	unsigned int gmap_int_code;	/* int code of last gmap fault */
 	unsigned int gmap_pfault;	/* signal of a pending guest pfault */
 	struct per_regs per_user;	/* User specified PER registers */
 	struct per_event per_event;	/* Cause of the last PER trap */

commit 4be130a08420d6918d80c1067f8078f425eb98df
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Mar 8 12:12:18 2016 +0100

    s390/mm: add shadow gmap support
    
    For a nested KVM guest the outer KVM host needs to create shadow
    page tables for the nested guest. This patch adds the basic support
    to the guest address space (gmap) code.
    
    For each guest address space the inner KVM host creates, the first
    outer KVM host needs to create shadow page tables. The address space
    is identified by the ASCE loaded into the control register 1 at the
    time the inner SIE instruction for the second nested KVM guest is
    executed. The outer KVM host creates the shadow tables starting with
    the table identified by the ASCE on a on-demand basis. The outer KVM
    host will get repeated faults for all the shadow tables needed to
    run the second KVM guest.
    
    While a shadow page table for the second KVM guest is active the access
    to the origin region, segment and page tables needs to be restricted
    for the first KVM guest. For region and segment and page tables the first
    KVM guest may read the memory, but write attempt has to lead to an
    unshadow.  This is done using the page invalid and read-only bits in the
    page table of the first KVM guest. If the first guest re-accesses one of
    the origin pages of a shadow, it gets a fault and the affected parts of
    the shadow page table hierarchy needs to be removed again.
    
    PGSTE tables don't have to be shadowed, as all interpretation assist can't
    deal with the invalid bits in the shadow pte being set differently than
    the original ones provided by the first KVM guest.
    
    Many bug fixes and improvements by David Hildenbrand.
    
    Reviewed-by: David Hildenbrand <dahi@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 9d4d311d7e52..94c80b6d031d 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -109,6 +109,7 @@ struct thread_struct {
         unsigned long ksp;              /* kernel stack pointer             */
 	mm_segment_t mm_segment;
 	unsigned long gmap_addr;	/* address of last gmap fault. */
+	unsigned int gmap_write_flag;	/* gmap fault write indication */
 	unsigned int gmap_pfault;	/* signal of a pending guest pfault */
 	struct per_regs per_user;	/* User specified PER registers */
 	struct per_event per_event;	/* Cause of the last PER trap */

commit 097a116c7e9023267b61fb96b37fdcb2864a1ae3
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Thu Apr 14 12:35:22 2016 +0200

    s390/cpuinfo: show dynamic and static cpu mhz
    
    Show the dynamic and static cpu mhz of each cpu. Since these values
    are per cpu this requires a fundamental extension of the format of
    /proc/cpuinfo.
    
    Historically we had only a single line per cpu and a summary at the
    top of the file. This format is hardly extendible if we want to add
    more per cpu information.
    
    Therefore this patch adds per cpu blocks at the end of /proc/cpuinfo:
    
    cpu             : 0
    cpu Mhz dynamic : 5504
    cpu Mhz static  : 5504
    
    cpu             : 1
    cpu Mhz dynamic : 5504
    cpu Mhz static  : 5504
    
    cpu             : 2
    cpu Mhz dynamic : 5504
    cpu Mhz static  : 5504
    
    cpu             : 3
    cpu Mhz dynamic : 5504
    cpu Mhz static  : 5504
    
    Right now each block contains only the dynamic and static cpu mhz,
    but it can be easily extended like on every other architecture.
    
    This extension is supposed to be compatible with the old format.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Acked-by: Sascha Silbe <silbe@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 9d4d311d7e52..09529202ea77 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -77,7 +77,10 @@ static inline void get_cpu_id(struct cpuid *ptr)
 	asm volatile("stidp %0" : "=Q" (*ptr));
 }
 
-extern void s390_adjust_jiffies(void);
+void s390_adjust_jiffies(void);
+void s390_update_cpu_mhz(void);
+void cpu_detect_mhz_feature(void);
+
 extern const struct seq_operations cpuinfo_op;
 extern int sysctl_ieee_emulation_warnings;
 extern void execve_tail(void);
@@ -233,6 +236,18 @@ void cpu_relax(void);
 
 #define cpu_relax_lowlatency()  barrier()
 
+#define ECAG_CACHE_ATTRIBUTE	0
+#define ECAG_CPU_ATTRIBUTE	1
+
+static inline unsigned long __ecag(unsigned int asi, unsigned char parm)
+{
+	unsigned long val;
+
+	asm volatile(".insn	rsy,0xeb000000004c,%0,0,0(%1)" /* ecag */
+		     : "=d" (val) : "a" (asi << 8 | parm));
+	return val;
+}
+
 static inline void psw_set_key(unsigned int key)
 {
 	asm volatile("spka 0(%0)" : : "d" (key));

commit f61a657fdf221403d99e6f0d4c6d24762920d4a9
Merge: 0e034f5c4bc4 c53db5222b92
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed May 18 12:17:16 2016 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux
    
    Pull s390 updates from Martin Schwidefsky:
     "The s390 patches for the 4.7 merge window have the usual bug fixes and
      cleanups, and the following new features:
    
       - An interface for dasd driver to query if a volume is online to
         another operating system
    
       - A new ioctl for the dasd driver to verify the format for a range of
         tracks
    
       - Following the example of x86 the struct fpu is now allocated with
         the task_struct
    
       - The 'report_error' interface for the PCI bus to send an
         adapter-error notification from user space to the service element
         of the machine"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux: (29 commits)
      s390/vmem: remove unused function parameter
      s390/vmem: fix identity mapping
      s390: add missing include statements
      s390: add missing declarations
      s390: make couple of variables and functions static
      s390/cache: remove superfluous locking
      s390/cpuinfo: simplify locking and skip offline cpus early
      s390/3270: hangup the 3270 tty after a disconnect
      s390/3270: handle reconnect of a tty with a different size
      s390/3270: avoid endless I/O loop with disconnected 3270 terminals
      s390/3270: fix garbled output on 3270 tty view
      s390/3270: fix view reference counting
      s390/3270: add missing tty_kref_put
      s390/dumpstack: implement and use return_address()
      s390/cpum_sf: Remove superfluous SMP function call
      s390/cpum_cf: Remove superfluous SMP function call
      s390/Kconfig: make z196 the default processor type
      s390/sclp: avoid compile warning in sclp_pci_report
      s390/fpu: allocate 'struct fpu' with the task_struct
      s390/crypto: cleanup and move the header with the cpacf definitions
      ...

commit 3f6813b9a5e0aaec162a10037c203771a1b2c110
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Fri Apr 1 15:42:15 2016 +0200

    s390/fpu: allocate 'struct fpu' with the task_struct
    
    Analog to git commit 0c8c0f03e3a292e031596484275c14cf39c0ab7a
    "x86/fpu, sched: Dynamically allocate 'struct fpu'"
    move the struct fpu to the end of the struct thread_struct,
    set CONFIG_ARCH_WANTS_DYNAMIC_TASK_STRUCT and add the
    setup_task_size() function to calculate the correct size
    fo the task struct.
    
    For the performance_defconfig this increases the size of
    struct task_struct from 7424 bytes to 7936 bytes (MACHINE_HAS_VX==1)
    or 7552 bytes (MACHINE_HAS_VX==0). The dynamic allocation of the
    struct fpu is removed. The slab cache uses an 8KB block for the
    task struct in all cases, there is enough room for the struct fpu.
    For MACHINE_HAS_VX==1 each task now needs 512 bytes less memory.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index d6fd22ea270d..332f4f7dc8d3 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -105,7 +105,6 @@ typedef struct {
  * Thread structure
  */
 struct thread_struct {
-	struct fpu fpu;			/* FP and VX register save area */
 	unsigned int  acrs[NUM_ACRS];
         unsigned long ksp;              /* kernel stack pointer             */
 	mm_segment_t mm_segment;
@@ -120,6 +119,11 @@ struct thread_struct {
 	/* cpu runtime instrumentation */
 	struct runtime_instr_cb *ri_cb;
 	unsigned char trap_tdb[256];	/* Transaction abort diagnose block */
+	/*
+	 * Warning: 'fpu' is dynamically-sized. It *MUST* be at
+	 * the end.
+	 */
+	struct fpu fpu;			/* FP and VX register save area */
 };
 
 /* Flag to disable transactions. */
@@ -155,10 +159,9 @@ struct stack_frame {
 
 #define ARCH_MIN_TASKALIGN	8
 
-extern __vector128 init_task_fpu_regs[__NUM_VXRS];
 #define INIT_THREAD {							\
 	.ksp = sizeof(init_stack) + (unsigned long) &init_stack,	\
-	.fpu.regs = (void *)&init_task_fpu_regs,			\
+	.fpu.regs = (void *) init_task.thread.fpu.fprs,			\
 }
 
 /*

commit 723cacbd9dc79582e562c123a0bacf8bfc69e72a
Author: Gerald Schaefer <gerald.schaefer@de.ibm.com>
Date:   Fri Apr 15 16:38:40 2016 +0200

    s390/mm: fix asce_bits handling with dynamic pagetable levels
    
    There is a race with multi-threaded applications between context switch and
    pagetable upgrade. In switch_mm() a new user_asce is built from mm->pgd and
    mm->context.asce_bits, w/o holding any locks. A concurrent mmap with a
    pagetable upgrade on another thread in crst_table_upgrade() could already
    have set new asce_bits, but not yet the new mm->pgd. This would result in a
    corrupt user_asce in switch_mm(), and eventually in a kernel panic from a
    translation exception.
    
    Fix this by storing the complete asce instead of just the asce_bits, which
    can then be read atomically from switch_mm(), so that it either sees the
    old value or the new value, but no mixture. Both cases are OK. Having the
    old value would result in a page fault on access to the higher level memory,
    but the fault handler would see the new mm->pgd, if it was a valid access
    after the mmap on the other thread has completed. So as worst-case scenario
    we would have a page fault loop for the racing thread until the next time
    slice.
    
    Also remove dead code and simplify the upgrade/downgrade path, there are no
    upgrades from 2 levels, and only downgrades from 3 levels for compat tasks.
    There are also no concurrent upgrades, because the mmap_sem is held with
    down_write() in do_mmap, so the flush and table checks during upgrade can
    be removed.
    
    Reported-by: Michael Munday <munday@ca.ibm.com>
    Reviewed-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Gerald Schaefer <gerald.schaefer@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index d6fd22ea270d..18cdede1aeda 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -175,7 +175,7 @@ extern __vector128 init_task_fpu_regs[__NUM_VXRS];
 	regs->psw.mask	= PSW_USER_BITS | PSW_MASK_BA;			\
 	regs->psw.addr	= new_psw;					\
 	regs->gprs[15]	= new_stackp;					\
-	crst_table_downgrade(current->mm, 1UL << 31);			\
+	crst_table_downgrade(current->mm);				\
 	execve_tail();							\
 } while (0)
 

commit 758d39ebd3d5666edb3b1c339f7f138c349ff8bf
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Tue Feb 9 12:58:54 2016 +0100

    s390/dumpstack: merge all four stack tracers
    
    We have four different stack tracers of which three had bugs. So it's
    time to merge them to a single stack tracer which allows to specify a
    call back function which will be called for each step.
    
    This patch changes behavior a bit:
    
    - the "nosched" and "in_sched_functions" check within
      save_stack_trace_tsk did work only for the last stack frame within a
      context. Now it considers the check for each stack frame like it
      should.
    
    - both the oprofile variant and the perf_events variant did save a
      return address twice if a zero back chain was detected, which
      indicates an interrupt frame. The new dump_trace function will call
      the oprofile and perf_events backends with the psw address that is
      contained within the corresponding pt_regs structure instead.
    
    - the original show_trace and save_context_stack functions did already
      use the psw address of the pt_regs structure if a zero back chain
      was detected. However now we ignore the psw address if it is a user
      space address. After all we trace the kernel stack and not the user
      space stack. This way we also get rid of the garbage user space
      address in case of warnings and / or panic call traces.
    
    So this should make life easier since now there is only one stack
    tracer left which we can break.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 073e18bc1676..d6fd22ea270d 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -184,6 +184,10 @@ struct task_struct;
 struct mm_struct;
 struct seq_file;
 
+typedef int (*dump_trace_func_t)(void *data, unsigned long address);
+void dump_trace(dump_trace_func_t func, void *data,
+		struct task_struct *task, unsigned long sp);
+
 void show_cacheinfo(struct seq_file *m);
 
 /* Free all resources held by a thread. */

commit 76737ce17ab4c88f14e4452076610474108246d7
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Sun Jan 31 17:06:16 2016 +0100

    s390: add current_stack_pointer() helper function
    
    Implement current_stack_pointer() helper function and use it
    everywhere, instead of having several different inline assembly
    variants.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Tested-by: Peter Oberparleiter <oberpar@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 1c4fe129486d..073e18bc1676 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -203,6 +203,14 @@ unsigned long get_wchan(struct task_struct *p);
 /* Has task runtime instrumentation enabled ? */
 #define is_ri_task(tsk) (!!(tsk)->thread.ri_cb)
 
+static inline unsigned long current_stack_pointer(void)
+{
+	unsigned long sp;
+
+	asm volatile("la %0,0(15)" : "=a" (sp));
+	return sp;
+}
+
 static inline unsigned short stap(void)
 {
 	unsigned short cpu_address;

commit fecc868a668774b0fc666728c3f5d9f6fceefe64
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon Jan 18 12:49:44 2016 +0100

    s390: remove all usages of PSW_ADDR_AMODE
    
    This is a leftover from the 31 bit area. For CONFIG_64BIT the usual
    operation "y = x | PSW_ADDR_AMODE" is a nop. Therefore remove all
    usages of PSW_ADDR_AMODE and make the code a bit less confusing.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Reviewed-by: David Hildenbrand <dahi@linux.vnet.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index f16debf6a612..1c4fe129486d 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -166,14 +166,14 @@ extern __vector128 init_task_fpu_regs[__NUM_VXRS];
  */
 #define start_thread(regs, new_psw, new_stackp) do {			\
 	regs->psw.mask	= PSW_USER_BITS | PSW_MASK_EA | PSW_MASK_BA;	\
-	regs->psw.addr	= new_psw | PSW_ADDR_AMODE;			\
+	regs->psw.addr	= new_psw;					\
 	regs->gprs[15]	= new_stackp;					\
 	execve_tail();							\
 } while (0)
 
 #define start_thread31(regs, new_psw, new_stackp) do {			\
 	regs->psw.mask	= PSW_USER_BITS | PSW_MASK_BA;			\
-	regs->psw.addr	= new_psw | PSW_ADDR_AMODE;			\
+	regs->psw.addr	= new_psw;					\
 	regs->gprs[15]	= new_stackp;					\
 	crst_table_downgrade(current->mm, 1UL << 31);			\
 	execve_tail();							\

commit c667aeacc16e0de9e205faa93f57121d6f691973
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Thu Dec 31 10:29:00 2015 +0100

    s390: rename struct _lowcore to struct lowcore
    
    Finally get rid of the leading underscore. I tried this already two or
    three years ago, however Michael Holzheu objected since this would
    break the crash utility (again).
    
    However Michael integrated support for the new name into the crash
    utility back then, so it doesn't break if the name will be changed
    now.  So finally get rid of the ever confusing leading underscore.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 5592c94ebe31..f16debf6a612 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -60,7 +60,7 @@ static inline int test_cpu_flag(int flag)
  */
 static inline int test_cpu_flag_of(int flag, int cpu)
 {
-	struct _lowcore *lc = lowcore_ptr[cpu];
+	struct lowcore *lc = lowcore_ptr[cpu];
 	return !!(lc->cpu_flags & (1UL << flag));
 }
 

commit 419123f900dac58fb27ce5285b21074f5300095a
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Thu Nov 19 11:09:45 2015 +0100

    s390/spinlock: do not yield to a CPU in udelay/mdelay
    
    It does not make sense to try to relinquish the time slice with diag 0x9c
    to a CPU in a state that does not allow to schedule the CPU. The scenario
    where this can happen is a CPU waiting in udelay/mdelay while holding a
    spin-lock.
    
    Add a CIF bit to tag a CPU in enabled wait and use it to detect that the
    yield of a CPU will not be successful and skip the diagnose call.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index b16c3d0a1b9f..5592c94ebe31 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -18,12 +18,14 @@
 #define CIF_NOHZ_DELAY		2	/* delay HZ disable for a tick */
 #define CIF_FPU			3	/* restore FPU registers */
 #define CIF_IGNORE_IRQ		4	/* ignore interrupt (for udelay) */
+#define CIF_ENABLED_WAIT	5	/* in enabled wait state */
 
 #define _CIF_MCCK_PENDING	_BITUL(CIF_MCCK_PENDING)
 #define _CIF_ASCE		_BITUL(CIF_ASCE)
 #define _CIF_NOHZ_DELAY		_BITUL(CIF_NOHZ_DELAY)
 #define _CIF_FPU		_BITUL(CIF_FPU)
 #define _CIF_IGNORE_IRQ		_BITUL(CIF_IGNORE_IRQ)
+#define _CIF_ENABLED_WAIT	_BITUL(CIF_ENABLED_WAIT)
 
 #ifndef __ASSEMBLY__
 
@@ -52,6 +54,16 @@ static inline int test_cpu_flag(int flag)
 	return !!(S390_lowcore.cpu_flags & (1UL << flag));
 }
 
+/*
+ * Test CIF flag of another CPU. The caller needs to ensure that
+ * CPU hotplug can not happen, e.g. by disabling preemption.
+ */
+static inline int test_cpu_flag_of(int flag, int cpu)
+{
+	struct _lowcore *lc = lowcore_ptr[cpu];
+	return !!(lc->cpu_flags & (1UL << flag));
+}
+
 #define arch_needs_cpu() test_cpu_flag(CIF_NOHZ_DELAY)
 
 /*

commit b38feccd663b55ab07116208b68e1ffc7c3c7e78
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Mon Nov 2 14:03:46 2015 +0100

    s390: remove runtime instrumentation interrupts
    
    The external interrupts for runtime instrumentation buffer-full
    and runtime instrumentation halted are unused and have no current
    user. Remove the support and ignore the second parameter of the
    s390_runtime_instr system call from now on.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index d39cca3a3153..b16c3d0a1b9f 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -107,7 +107,6 @@ struct thread_struct {
 	struct list_head list;
 	/* cpu runtime instrumentation */
 	struct runtime_instr_cb *ri_cb;
-	int ri_signum;
 	unsigned char trap_tdb[256];	/* Transaction abort diagnose block */
 };
 

commit f9e6edfb9cf780edfe0a649a85ed00032e787f69
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon Oct 12 12:28:28 2015 +0200

    s390: don't store registers on disabled wait anymore
    
    The current disabled wait code stores register contents into their
    save areas, however it is (at least) missing the new vector registers.
    
    Given the fact that the whole exercise seems to be rather pointless
    simply don't save any registers anymore.
    
    In a "live" system it is always possible to inspect register contents,
    and in case of a dump the register contents will be stored by the
    dump mechanism.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 07e6b0389502..d39cca3a3153 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -283,47 +283,11 @@ void enabled_wait(void);
  */
 static inline void __noreturn disabled_wait(unsigned long code)
 {
-        unsigned long ctl_buf;
-        psw_t dw_psw;
-
-	dw_psw.mask = PSW_MASK_BASE | PSW_MASK_WAIT | PSW_MASK_BA | PSW_MASK_EA;
-        dw_psw.addr = code;
-        /* 
-         * Store status and then load disabled wait psw,
-         * the processor is dead afterwards
-         */
-	asm volatile(
-		"	stctg	0,0,0(%2)\n"
-		"	ni	4(%2),0xef\n"	/* switch off protection */
-		"	lctlg	0,0,0(%2)\n"
-		"	lghi	1,0x1000\n"
-		"	stpt	0x328(1)\n"	/* store timer */
-		"	stckc	0x330(1)\n"	/* store clock comparator */
-		"	stpx	0x318(1)\n"	/* store prefix register */
-		"	stam	0,15,0x340(1)\n"/* store access registers */
-		"	stfpc	0x31c(1)\n"	/* store fpu control */
-		"	std	0,0x200(1)\n"	/* store f0 */
-		"	std	1,0x208(1)\n"	/* store f1 */
-		"	std	2,0x210(1)\n"	/* store f2 */
-		"	std	3,0x218(1)\n"	/* store f3 */
-		"	std	4,0x220(1)\n"	/* store f4 */
-		"	std	5,0x228(1)\n"	/* store f5 */
-		"	std	6,0x230(1)\n"	/* store f6 */
-		"	std	7,0x238(1)\n"	/* store f7 */
-		"	std	8,0x240(1)\n"	/* store f8 */
-		"	std	9,0x248(1)\n"	/* store f9 */
-		"	std	10,0x250(1)\n"	/* store f10 */
-		"	std	11,0x258(1)\n"	/* store f11 */
-		"	std	12,0x260(1)\n"	/* store f12 */
-		"	std	13,0x268(1)\n"	/* store f13 */
-		"	std	14,0x270(1)\n"	/* store f14 */
-		"	std	15,0x278(1)\n"	/* store f15 */
-		"	stmg	0,15,0x280(1)\n"/* store general registers */
-		"	stctg	0,15,0x380(1)\n"/* store control registers */
-		"	oi	0x384(1),0x10\n"/* fake protection bit */
-		"	lpswe	0(%1)"
-		: "=m" (ctl_buf)
-		: "a" (&dw_psw), "a" (&ctl_buf), "m" (dw_psw) : "cc", "0", "1");
+	psw_t psw;
+
+	psw.mask = PSW_MASK_BASE | PSW_MASK_WAIT | PSW_MASK_BA | PSW_MASK_EA;
+	psw.addr = code;
+	__load_psw(psw);
 	while (1);
 }
 

commit ecbafda85371a3d85814aab8ff080a19e4d98b36
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon Oct 12 11:54:03 2015 +0200

    s390: get rid of __set_psw_mask()
    
    With the removal of 31 bit code we can always assume that the epsw
    instruction is available. Therefore use the __extract_psw() function
    to disable and enable machine checks.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index a83015e17f39..07e6b0389502 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -224,7 +224,7 @@ static inline void __load_psw(psw_t psw)
  * Set PSW mask to specified value, while leaving the
  * PSW addr pointing to the next instruction.
  */
-static inline void __load_psw_mask (unsigned long mask)
+static inline void __load_psw_mask(unsigned long mask)
 {
 	unsigned long addr;
 	psw_t psw;
@@ -250,6 +250,16 @@ static inline unsigned long __extract_psw(void)
 	return (((unsigned long) reg1) << 32) | ((unsigned long) reg2);
 }
 
+static inline void local_mcck_enable(void)
+{
+	__load_psw_mask(__extract_psw() | PSW_MASK_MCHECK);
+}
+
+static inline void local_mcck_disable(void)
+{
+	__load_psw_mask(__extract_psw() & ~PSW_MASK_MCHECK);
+}
+
 /*
  * Rewind PSW instruction address by specified number of bytes.
  */
@@ -317,21 +327,6 @@ static inline void __noreturn disabled_wait(unsigned long code)
 	while (1);
 }
 
-/*
- * Use to set psw mask except for the first byte which
- * won't be changed by this function.
- */
-static inline void
-__set_psw_mask(unsigned long mask)
-{
-	__load_psw_mask(mask | (arch_local_save_flags() & ~(-1UL >> 8)));
-}
-
-#define local_mcck_enable() \
-	__set_psw_mask(PSW_KERNEL_BITS | PSW_MASK_DAT | PSW_MASK_MCHECK)
-#define local_mcck_disable() \
-	__set_psw_mask(PSW_KERNEL_BITS | PSW_MASK_DAT)
-
 /*
  * Basic Machine Check/Program Check Handler.
  */

commit b0753902d42f5cb01c33f0dec47ba2aa7ecfbb3f
Author: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
Date:   Tue Oct 6 12:25:59 2015 +0200

    s390/fpu: split fpu-internal.h into fpu internals, api, and type headers
    
    Split the API and FPU type definitions into separate header files
    similar to "x86/fpu: Rename fpu-internal.h to fpu/internal.h" (78f7f1e54b).
    
    The new header files and their meaning are:
    
    asm/fpu/types.h:
            FPU related data types, needed for 'struct thread_struct' and
            'struct task_struct'.
    
    asm/fpu/api.h:
            FPU related 'public' functions for other subsystems and device
            drivers.
    
    asm/fpu/internal.h:
            FPU internal functions mainly used to convert
            FPU register contents in signal handling.
    
    Signed-off-by: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 43ff624f7510..a83015e17f39 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -16,7 +16,7 @@
 #define CIF_MCCK_PENDING	0	/* machine check handling is pending */
 #define CIF_ASCE		1	/* user asce needs fixup / uaccess */
 #define CIF_NOHZ_DELAY		2	/* delay HZ disable for a tick */
-#define CIF_FPU			3	/* restore vector registers */
+#define CIF_FPU			3	/* restore FPU registers */
 #define CIF_IGNORE_IRQ		4	/* ignore interrupt (for udelay) */
 
 #define _CIF_MCCK_PENDING	_BITUL(CIF_MCCK_PENDING)
@@ -34,7 +34,8 @@
 #include <asm/ptrace.h>
 #include <asm/setup.h>
 #include <asm/runtime_instr.h>
-#include <asm/fpu-internal.h>
+#include <asm/fpu/types.h>
+#include <asm/fpu/internal.h>
 
 static inline void set_cpu_flag(int flag)
 {

commit 92778b9920abddacf31876b3f15d8ea07edeca8d
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Tue Oct 6 16:23:39 2015 +0200

    s390/flags: use _BITUL macro
    
    The defines that are used in entry.S have been partially converted to
    use the _BITUL macro (setup.h). This patch converts the rest.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Reviewed-by: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index eefe543f84c9..43ff624f7510 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -11,17 +11,19 @@
 #ifndef __ASM_S390_PROCESSOR_H
 #define __ASM_S390_PROCESSOR_H
 
+#include <linux/const.h>
+
 #define CIF_MCCK_PENDING	0	/* machine check handling is pending */
 #define CIF_ASCE		1	/* user asce needs fixup / uaccess */
 #define CIF_NOHZ_DELAY		2	/* delay HZ disable for a tick */
 #define CIF_FPU			3	/* restore vector registers */
 #define CIF_IGNORE_IRQ		4	/* ignore interrupt (for udelay) */
 
-#define _CIF_MCCK_PENDING	(1<<CIF_MCCK_PENDING)
-#define _CIF_ASCE		(1<<CIF_ASCE)
-#define _CIF_NOHZ_DELAY		(1<<CIF_NOHZ_DELAY)
-#define _CIF_FPU		(1<<CIF_FPU)
-#define _CIF_IGNORE_IRQ		(1<<CIF_IGNORE_IRQ)
+#define _CIF_MCCK_PENDING	_BITUL(CIF_MCCK_PENDING)
+#define _CIF_ASCE		_BITUL(CIF_ASCE)
+#define _CIF_NOHZ_DELAY		_BITUL(CIF_NOHZ_DELAY)
+#define _CIF_FPU		_BITUL(CIF_FPU)
+#define _CIF_IGNORE_IRQ		_BITUL(CIF_IGNORE_IRQ)
 
 #ifndef __ASSEMBLY__
 

commit ac25e790d9c3c9b5d34609b7dc1d60c09494c668
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Tue Oct 6 16:23:29 2015 +0200

    s390/flags: fix flag handling
    
    The cpu flags and pt_regs flags fields are each 64 bits in size. A flag can
    be set with helper functions like set_cpu_flags().
    
    These functions create a mask using "1U << flag". This doesn't work if flag
    is larger than 31, since 1U << 32 == 0.
    
    So fix this in case we ever will have such flag numbers.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Reviewed-by: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 9e1cdcf8d124..eefe543f84c9 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -36,17 +36,17 @@
 
 static inline void set_cpu_flag(int flag)
 {
-	S390_lowcore.cpu_flags |= (1U << flag);
+	S390_lowcore.cpu_flags |= (1UL << flag);
 }
 
 static inline void clear_cpu_flag(int flag)
 {
-	S390_lowcore.cpu_flags &= ~(1U << flag);
+	S390_lowcore.cpu_flags &= ~(1UL << flag);
 }
 
 static inline int test_cpu_flag(int flag)
 {
-	return !!(S390_lowcore.cpu_flags & (1U << flag));
+	return !!(S390_lowcore.cpu_flags & (1UL << flag));
 }
 
 #define arch_needs_cpu() test_cpu_flag(CIF_NOHZ_DELAY)

commit db7e007fd61ca07e5f3b04cf2168531b074d318d
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Sat Aug 15 11:42:21 2015 +0200

    s390/udelay: make udelay have busy loop semantics
    
    When using systemtap it was observed that our udelay implementation is
    rather suboptimal if being called from a kprobe handler installed by
    systemtap.
    
    The problem observed when a kprobe was installed on lock_acquired().
    When the probe was hit the kprobe handler did call udelay, which set
    up an (internal) timer and reenabled interrupts (only the clock comparator
    interrupt) and waited for the interrupt.
    This is an optimization to avoid that the cpu is busy looping while waiting
    that enough time passes. The problem is that the interrupt handler still
    does call irq_enter()/irq_exit() which then again can lead to a deadlock,
    since some accounting functions may take locks as well.
    
    If one of these locks is the same, which caused lock_acquired() to be
    called, we have a nice deadlock.
    
    This patch reworks the udelay code for the interrupts disabled case to
    immediately leave the low level interrupt handler when the clock
    comparator interrupt happens. That way no C code is being called and the
    deadlock cannot happen anymore.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Reviewed-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 5900877bb19c..9e1cdcf8d124 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -15,11 +15,13 @@
 #define CIF_ASCE		1	/* user asce needs fixup / uaccess */
 #define CIF_NOHZ_DELAY		2	/* delay HZ disable for a tick */
 #define CIF_FPU			3	/* restore vector registers */
+#define CIF_IGNORE_IRQ		4	/* ignore interrupt (for udelay) */
 
 #define _CIF_MCCK_PENDING	(1<<CIF_MCCK_PENDING)
 #define _CIF_ASCE		(1<<CIF_ASCE)
 #define _CIF_NOHZ_DELAY		(1<<CIF_NOHZ_DELAY)
 #define _CIF_FPU		(1<<CIF_FPU)
+#define _CIF_IGNORE_IRQ		(1<<CIF_IGNORE_IRQ)
 
 #ifndef __ASSEMBLY__
 

commit 0ac277790ec938087c9047bc7b1b4f30a65406cd
Author: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
Date:   Tue Sep 29 17:53:22 2015 +0200

    s390/fpu: add static FPU save area for init_task
    
    Previously, the init task did not have an allocated FPU save area and
    saving an FPU state was not possible.  Now if the vector extension is
    always enabled, provide a static FPU save area to save FPU states of
    vector instructions that can be executed quite early.
    
    Signed-off-by: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 085fb0d3c54e..5900877bb19c 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -139,8 +139,10 @@ struct stack_frame {
 
 #define ARCH_MIN_TASKALIGN	8
 
+extern __vector128 init_task_fpu_regs[__NUM_VXRS];
 #define INIT_THREAD {							\
 	.ksp = sizeof(init_stack) + (unsigned long) &init_stack,	\
+	.fpu.regs = (void *)&init_task_fpu_regs,			\
 }
 
 /*

commit 22362a0e23182d230527a5add690b4027860d7d3
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Wed Jul 8 10:20:04 2015 +0200

    s390/sclp: convert early sclp console code to C
    
    The 31-bit assembler code for the early sclp console is error
    prone as git commit fde24b54d976cc123506695c17db01438a11b673
    "s390/sclp: clear upper register halves in _sclp_print_early"
    has shown.
    
    Convert the assembler code to C.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index c417015c5304..085fb0d3c54e 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -232,6 +232,17 @@ static inline void __load_psw_mask (unsigned long mask)
 		: "=&d" (addr), "=Q" (psw) : "Q" (psw) : "memory", "cc");
 }
 
+/*
+ * Extract current PSW mask
+ */
+static inline unsigned long __extract_psw(void)
+{
+	unsigned int reg1, reg2;
+
+	asm volatile("epsw %0,%1" : "=d" (reg1), "=a" (reg2));
+	return (((unsigned long) reg1) << 32) | ((unsigned long) reg2);
+}
+
 /*
  * Rewind PSW instruction address by specified number of bytes.
  */

commit 9977e886cbbc758b4b601a160b5825ba573b5ca8
Author: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
Date:   Wed Jun 10 12:53:42 2015 +0200

    s390/kernel: lazy restore fpu registers
    
    Improve the save and restore behavior of FPU register contents to use the
    vector extension within the kernel.
    
    The kernel does not use floating-point or vector registers and, therefore,
    saving and restoring the FPU register contents are performed for handling
    signals or switching processes only.  To prepare for using vector
    instructions and vector registers within the kernel, enhance the save
    behavior and implement a lazy restore at return to user space from a
    system call or interrupt.
    
    To implement the lazy restore, the save_fpu_regs() sets a CPU information
    flag, CIF_FPU, to indicate that the FPU registers must be restored.
    Saving and setting CIF_FPU is performed in an atomic fashion to be
    interrupt-safe.  When the kernel wants to use the vector extension or
    wants to change the FPU register state for a task during signal handling,
    the save_fpu_regs() must be called first.  The CIF_FPU flag is also set at
    process switch.  At return to user space, the FPU state is restored.  In
    particular, the FPU state includes the floating-point or vector register
    contents, as well as, vector-enablement and floating-point control.  The
    FPU state restore and clearing CIF_FPU is also performed in an atomic
    fashion.
    
    For KVM, the restore of the FPU register state is performed when restoring
    the general-purpose guest registers before the SIE instructions is started.
    Because the path towards the SIE instruction is interruptible, the CIF_FPU
    flag must be checked again right before going into SIE.  If set, the guest
    registers must be reloaded again by re-entering the outer SIE loop.  This
    is the same behavior as if the SIE critical section is interrupted.
    
    Signed-off-by: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 19f51db7c5e6..c417015c5304 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -14,10 +14,12 @@
 #define CIF_MCCK_PENDING	0	/* machine check handling is pending */
 #define CIF_ASCE		1	/* user asce needs fixup / uaccess */
 #define CIF_NOHZ_DELAY		2	/* delay HZ disable for a tick */
+#define CIF_FPU			3	/* restore vector registers */
 
 #define _CIF_MCCK_PENDING	(1<<CIF_MCCK_PENDING)
 #define _CIF_ASCE		(1<<CIF_ASCE)
 #define _CIF_NOHZ_DELAY		(1<<CIF_NOHZ_DELAY)
+#define _CIF_FPU		(1<<CIF_FPU)
 
 #ifndef __ASSEMBLY__
 

commit 904818e2f229f3d94ec95f6932a6358c81e73d78
Author: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
Date:   Thu Jun 11 15:33:54 2015 +0200

    s390/kernel: introduce fpu-internal.h with fpu helper functions
    
    Introduce a new structure to manage FP and VX registers. Refactor the
    save and restore of floating point and vector registers with a set
    of helper functions in fpu-internal.h.
    
    Signed-off-by: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index f4d9f741421d..19f51db7c5e6 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -28,6 +28,7 @@
 #include <asm/ptrace.h>
 #include <asm/setup.h>
 #include <asm/runtime_instr.h>
+#include <asm/fpu-internal.h>
 
 static inline void set_cpu_flag(int flag)
 {
@@ -85,7 +86,7 @@ typedef struct {
  * Thread structure
  */
 struct thread_struct {
-	s390_fp_regs fp_regs;
+	struct fpu fpu;			/* FP and VX register save area */
 	unsigned int  acrs[NUM_ACRS];
         unsigned long ksp;              /* kernel stack pointer             */
 	mm_segment_t mm_segment;
@@ -101,7 +102,6 @@ struct thread_struct {
 	struct runtime_instr_cb *ri_cb;
 	int ri_signum;
 	unsigned char trap_tdb[256];	/* Transaction abort diagnose block */
-	__vector128 *vxrs;		/* Vector register save area */
 };
 
 /* Flag to disable transactions. */

commit 2e54dc3c7dadd4d012f132b1a2b3ab89d9a48cc2
Author: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
Date:   Fri Jun 12 10:57:40 2015 +0200

    s390/kernel: move EX_TABLE macros to linkage.h header file
    
    Move the EX_TABLE macro definitions from the processor.h to the linkage.h
    header file.  It helps to reduce circular header file dependencies.
    
    Signed-off-by: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index dedb6218544b..f4d9f741421d 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -336,25 +336,6 @@ extern void memcpy_absolute(void *, void *, size_t);
 	memcpy_absolute(&(dest), &__tmp, sizeof(__tmp));	\
 }
 
-/*
- * Helper macro for exception table entries
- */
-#define EX_TABLE(_fault, _target)	\
-	".section __ex_table,\"a\"\n"	\
-	".align	4\n"			\
-	".long	(" #_fault ") - .\n"	\
-	".long	(" #_target ") - .\n"	\
-	".previous\n"
-
-#else /* __ASSEMBLY__ */
-
-#define EX_TABLE(_fault, _target)	\
-	.section __ex_table,"a"	;	\
-	.align	4 ;			\
-	.long	(_fault) - . ;		\
-	.long	(_target) - . ;		\
-	.previous
-
 #endif /* __ASSEMBLY__ */
 
 #endif /* __ASM_S390_PROCESSOR_H */

commit 5a79859ae0f35d25c67a03e82bf0c80592f16a39
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Thu Feb 12 13:08:27 2015 +0100

    s390: remove 31 bit support
    
    Remove the 31 bit support in order to reduce maintenance cost and
    effectively remove dead code. Since a couple of years there is no
    distribution left that comes with a 31 bit kernel.
    
    The 31 bit kernel also has been broken since more than a year before
    anybody noticed. In addition I added a removal warning to the kernel
    shown at ipl for 5 minutes: a960062e5826 ("s390: add 31 bit warning
    message") which let everybody know about the plan to remove 31 bit
    code. We didn't get any response.
    
    Given that the last 31 bit only machine was introduced in 1999 let's
    remove the code.
    Anybody with 31 bit user space code can still use the compat mode.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index e7cbbdcdee13..dedb6218544b 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -19,7 +19,6 @@
 #define _CIF_ASCE		(1<<CIF_ASCE)
 #define _CIF_NOHZ_DELAY		(1<<CIF_NOHZ_DELAY)
 
-
 #ifndef __ASSEMBLY__
 
 #include <linux/linkage.h>
@@ -66,13 +65,6 @@ extern void execve_tail(void);
 /*
  * User space process size: 2GB for 31 bit, 4TB or 8PT for 64 bit.
  */
-#ifndef CONFIG_64BIT
-
-#define TASK_SIZE		(1UL << 31)
-#define TASK_MAX_SIZE		(1UL << 31)
-#define TASK_UNMAPPED_BASE	(1UL << 30)
-
-#else /* CONFIG_64BIT */
 
 #define TASK_SIZE_OF(tsk)	((tsk)->mm->context.asce_limit)
 #define TASK_UNMAPPED_BASE	(test_thread_flag(TIF_31BIT) ? \
@@ -80,15 +72,8 @@ extern void execve_tail(void);
 #define TASK_SIZE		TASK_SIZE_OF(current)
 #define TASK_MAX_SIZE		(1UL << 53)
 
-#endif /* CONFIG_64BIT */
-
-#ifndef CONFIG_64BIT
-#define STACK_TOP		(1UL << 31)
-#define STACK_TOP_MAX		(1UL << 31)
-#else /* CONFIG_64BIT */
 #define STACK_TOP		(1UL << (test_thread_flag(TIF_31BIT) ? 31:42))
 #define STACK_TOP_MAX		(1UL << 42)
-#endif /* CONFIG_64BIT */
 
 #define HAVE_ARCH_PICK_MMAP_LAYOUT
 
@@ -115,10 +100,8 @@ struct thread_struct {
 	/* cpu runtime instrumentation */
 	struct runtime_instr_cb *ri_cb;
 	int ri_signum;
-#ifdef CONFIG_64BIT
 	unsigned char trap_tdb[256];	/* Transaction abort diagnose block */
 	__vector128 *vxrs;		/* Vector register save area */
-#endif
 };
 
 /* Flag to disable transactions. */
@@ -181,11 +164,7 @@ struct task_struct;
 struct mm_struct;
 struct seq_file;
 
-#ifdef CONFIG_64BIT
-extern void show_cacheinfo(struct seq_file *m);
-#else
-static inline void show_cacheinfo(struct seq_file *m) { }
-#endif
+void show_cacheinfo(struct seq_file *m);
 
 /* Free all resources held by a thread. */
 extern void release_thread(struct task_struct *);
@@ -229,11 +208,7 @@ static inline void psw_set_key(unsigned int key)
  */
 static inline void __load_psw(psw_t psw)
 {
-#ifndef CONFIG_64BIT
-	asm volatile("lpsw  %0" : : "Q" (psw) : "cc");
-#else
 	asm volatile("lpswe %0" : : "Q" (psw) : "cc");
-#endif
 }
 
 /*
@@ -247,22 +222,12 @@ static inline void __load_psw_mask (unsigned long mask)
 
 	psw.mask = mask;
 
-#ifndef CONFIG_64BIT
-	asm volatile(
-		"	basr	%0,0\n"
-		"0:	ahi	%0,1f-0b\n"
-		"	st	%0,%O1+4(%R1)\n"
-		"	lpsw	%1\n"
-		"1:"
-		: "=&d" (addr), "=Q" (psw) : "Q" (psw) : "memory", "cc");
-#else /* CONFIG_64BIT */
 	asm volatile(
 		"	larl	%0,1f\n"
 		"	stg	%0,%O1+8(%R1)\n"
 		"	lpswe	%1\n"
 		"1:"
 		: "=&d" (addr), "=Q" (psw) : "Q" (psw) : "memory", "cc");
-#endif /* CONFIG_64BIT */
 }
 
 /*
@@ -270,20 +235,12 @@ static inline void __load_psw_mask (unsigned long mask)
  */
 static inline unsigned long __rewind_psw(psw_t psw, unsigned long ilc)
 {
-#ifndef CONFIG_64BIT
-	if (psw.addr & PSW_ADDR_AMODE)
-		/* 31 bit mode */
-		return (psw.addr - ilc) | PSW_ADDR_AMODE;
-	/* 24 bit mode */
-	return (psw.addr - ilc) & ((1UL << 24) - 1);
-#else
 	unsigned long mask;
 
 	mask = (psw.mask & PSW_MASK_EA) ? -1UL :
 	       (psw.mask & PSW_MASK_BA) ? (1UL << 31) - 1 :
 					  (1UL << 24) - 1;
 	return (psw.addr - ilc) & mask;
-#endif
 }
 
 /*
@@ -305,26 +262,6 @@ static inline void __noreturn disabled_wait(unsigned long code)
          * Store status and then load disabled wait psw,
          * the processor is dead afterwards
          */
-#ifndef CONFIG_64BIT
-	asm volatile(
-		"	stctl	0,0,0(%2)\n"
-		"	ni	0(%2),0xef\n"	/* switch off protection */
-		"	lctl	0,0,0(%2)\n"
-		"	stpt	0xd8\n"		/* store timer */
-		"	stckc	0xe0\n"		/* store clock comparator */
-		"	stpx	0x108\n"	/* store prefix register */
-		"	stam	0,15,0x120\n"	/* store access registers */
-		"	std	0,0x160\n"	/* store f0 */
-		"	std	2,0x168\n"	/* store f2 */
-		"	std	4,0x170\n"	/* store f4 */
-		"	std	6,0x178\n"	/* store f6 */
-		"	stm	0,15,0x180\n"	/* store general registers */
-		"	stctl	0,15,0x1c0\n"	/* store control registers */
-		"	oi	0x1c0,0x10\n"	/* fake protection bit */
-		"	lpsw	0(%1)"
-		: "=m" (ctl_buf)
-		: "a" (&dw_psw), "a" (&ctl_buf), "m" (dw_psw) : "cc");
-#else /* CONFIG_64BIT */
 	asm volatile(
 		"	stctg	0,0,0(%2)\n"
 		"	ni	4(%2),0xef\n"	/* switch off protection */
@@ -357,7 +294,6 @@ static inline void __noreturn disabled_wait(unsigned long code)
 		"	lpswe	0(%1)"
 		: "=m" (ctl_buf)
 		: "a" (&dw_psw), "a" (&ctl_buf), "m" (dw_psw) : "cc", "0", "1");
-#endif /* CONFIG_64BIT */
 	while (1);
 }
 

commit 4d92f50249eb3ed1c066276e214e8cc7be81e96d
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed Jan 28 07:43:56 2015 +0100

    s390: reintroduce diag 44 calls for cpu_relax()
    
    Christian Borntraeger reported that the now missing diag 44 calls (voluntary
    time slice end) does cause a performance regression for stop_machine() calls
    if a machine has more virtual cpus than the host has physical cpus.
    
    This patch mainly reverts 57f2ffe14fd125c2 ("s390: remove diag 44 calls from
    cpu_relax()") with the exception that we still do not issue diag 44 calls if
    running with smt enabled. Due to group scheduling algorithms when running in
    LPAR this would lead to significant latencies.
    However, when running in LPAR we do not have more virtual than physical cpus.
    
    Reported-and-tested-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index bed05ea7ec27..e7cbbdcdee13 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -215,10 +215,7 @@ static inline unsigned short stap(void)
 /*
  * Give up the time slice of the virtual PU.
  */
-static inline void cpu_relax(void)
-{
-	barrier();
-}
+void cpu_relax(void);
 
 #define cpu_relax_lowlatency()  barrier()
 

commit 57f2ffe14fd125c240babd88b99d8a57d3ed060e
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon Sep 15 10:50:47 2014 +0200

    s390: remove diag 44 calls from cpu_relax()
    
    Simplify cpu_relax() to a simple barrier(). Performance wise this doesn't
    seem to make any big difference anymore, since nearly all lock variants
    have directed yield semantics in the meantime.
    Also this makes s390 behave like all other architectures.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index d559bdb03d18..bed05ea7ec27 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -217,8 +217,6 @@ static inline unsigned short stap(void)
  */
 static inline void cpu_relax(void)
 {
-	if (MACHINE_HAS_DIAG44)
-		asm volatile("diag 0,0,68");
 	barrier();
 }
 

commit 8070361799ae1e3f4ef347bd10f0a508ac10acfb
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Mon Oct 6 17:53:53 2014 +0200

    s390: add support for vector extension
    
    The vector extension introduces 32 128-bit vector registers and a set of
    instruction to operate on the vector registers.
    
    The kernel can control the use of vector registers for the problem state
    program with a bit in control register 0. Once enabled for a process the
    kernel needs to retain the content of the vector registers on context
    switch. The signal frame is extended to include the vector registers.
    Two new register sets NT_S390_VXRS_LOW and NT_S390_VXRS_HIGH are added
    to the regset interface for the debugger and core dumps.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 3d0871058306..d559bdb03d18 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -117,6 +117,7 @@ struct thread_struct {
 	int ri_signum;
 #ifdef CONFIG_64BIT
 	unsigned char trap_tdb[256];	/* Transaction abort diagnose block */
+	__vector128 *vxrs;		/* Vector register save area */
 #endif
 };
 

commit b5f87f15e20092c060f465b283b07a76af7f2e5f
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Wed Oct 1 10:57:57 2014 +0200

    s390/idle: consolidate idle functions and definitions
    
    Move the C functions and definitions related to the idle state handling
    to arch/s390/include/asm/idle.h and arch/s390/kernel/idle.c. The function
    s390_get_idle_time is renamed to arch_cpu_idle_time and vtime_stop_cpu to
    enabled_wait.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index bc796d73129b..3d0871058306 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -289,7 +289,12 @@ static inline unsigned long __rewind_psw(psw_t psw, unsigned long ilc)
 	return (psw.addr - ilc) & mask;
 #endif
 }
- 
+
+/*
+ * Function to stop a processor until the next interrupt occurs
+ */
+void enabled_wait(void);
+
 /*
  * Function to drop a processor into disabled wait state
  */

commit fe0f49768d807a8fe6336b097feb8c4441951710
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Sep 30 17:37:52 2014 +0200

    s390/nohz: use a per-cpu flag for arch_needs_cpu
    
    Move the nohz_delay bit from the s390_idle data structure to the
    per-cpu flags. Clear the nohz delay flag in __cpu_disable and
    remove the cpu hotplug notifier that used to do this.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index e568fc8a7250..bc796d73129b 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -13,9 +13,11 @@
 
 #define CIF_MCCK_PENDING	0	/* machine check handling is pending */
 #define CIF_ASCE		1	/* user asce needs fixup / uaccess */
+#define CIF_NOHZ_DELAY		2	/* delay HZ disable for a tick */
 
 #define _CIF_MCCK_PENDING	(1<<CIF_MCCK_PENDING)
 #define _CIF_ASCE		(1<<CIF_ASCE)
+#define _CIF_NOHZ_DELAY		(1<<CIF_NOHZ_DELAY)
 
 
 #ifndef __ASSEMBLY__
@@ -43,6 +45,8 @@ static inline int test_cpu_flag(int flag)
 	return !!(S390_lowcore.cpu_flags & (1U << flag));
 }
 
+#define arch_needs_cpu() test_cpu_flag(CIF_NOHZ_DELAY)
+
 /*
  * Default implementation of macro that returns current
  * instruction pointer ("program counter").

commit 3a6bfbc91df04b081a44d419e0260bad54abddf7
Author: Davidlohr Bueso <davidlohr@hp.com>
Date:   Sun Jun 29 15:09:33 2014 -0700

    arch, locking: Ciao arch_mutex_cpu_relax()
    
    The arch_mutex_cpu_relax() function, introduced by 34b133f, is
    hacky and ugly. It was added a few years ago to address the fact
    that common cpu_relax() calls include yielding on s390, and thus
    impact the optimistic spinning functionality of mutexes. Nowadays
    we use this function well beyond mutexes: rwsem, qrwlock, mcs and
    lockref. Since the macro that defines the call is in the mutex header,
    any users must include mutex.h and the naming is misleading as well.
    
    This patch (i) renames the call to cpu_relax_lowlatency  ("relax, but
    only if you can do it with very low latency") and (ii) defines it in
    each arch's asm/processor.h local header, just like for regular cpu_relax
    functions. On all archs, except s390, cpu_relax_lowlatency is simply cpu_relax,
    and thus we can take it out of mutex.h. While this can seem redundant,
    I believe it is a good choice as it allows us to move out arch specific
    logic from generic locking primitives and enables future(?) archs to
    transparently define it, similarly to System Z.
    
    Signed-off-by: Davidlohr Bueso <davidlohr@hp.com>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Anton Blanchard <anton@samba.org>
    Cc: Aurelien Jacquiot <a-jacquiot@ti.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Bharat Bhushan <r65777@freescale.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chen Liqin <liqin.linux@gmail.com>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: David Howells <dhowells@redhat.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
    Cc: Dominik Dingel <dingel@linux.vnet.ibm.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
    Cc: Haavard Skinnemoen <hskinnemoen@gmail.com>
    Cc: Hans-Christian Egtvedt <egtvedt@samfundet.no>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Hirokazu Takata <takata@linux-m32r.org>
    Cc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>
    Cc: James E.J. Bottomley <jejb@parisc-linux.org>
    Cc: James Hogan <james.hogan@imgtec.com>
    Cc: Jason Wang <jasowang@redhat.com>
    Cc: Jesper Nilsson <jesper.nilsson@axis.com>
    Cc: Joe Perches <joe@perches.com>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Joseph Myers <joseph@codesourcery.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Koichi Yasutake <yasutake.koichi@jp.panasonic.com>
    Cc: Lennox Wu <lennox.wu@gmail.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Neuling <mikey@neuling.org>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: Nicolas Pitre <nico@linaro.org>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Paul Burton <paul.burton@imgtec.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Qais Yousef <qais.yousef@imgtec.com>
    Cc: Qiaowei Ren <qiaowei.ren@intel.com>
    Cc: Rafael Wysocki <rafael.j.wysocki@intel.com>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Steven Miao <realmz6@gmail.com>
    Cc: Steven Rostedt <srostedt@redhat.com>
    Cc: Stratos Karafotis <stratosk@semaphore.gr>
    Cc: Tim Chen <tim.c.chen@linux.intel.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vasily Kulikov <segoon@openwall.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Vineet Gupta <Vineet.Gupta1@synopsys.com>
    Cc: Waiman Long <Waiman.Long@hp.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Wolfram Sang <wsa@the-dreams.de>
    Cc: adi-buildroot-devel@lists.sourceforge.net
    Cc: linux390@de.ibm.com
    Cc: linux-alpha@vger.kernel.org
    Cc: linux-am33-list@redhat.com
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-c6x-dev@linux-c6x.org
    Cc: linux-cris-kernel@axis.com
    Cc: linux-hexagon@vger.kernel.org
    Cc: linux-ia64@vger.kernel.org
    Cc: linux@lists.openrisc.net
    Cc: linux-m32r-ja@ml.linux-m32r.org
    Cc: linux-m32r@ml.linux-m32r.org
    Cc: linux-m68k@lists.linux-m68k.org
    Cc: linux-metag@vger.kernel.org
    Cc: linux-mips@linux-mips.org
    Cc: linux-parisc@vger.kernel.org
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: linux-s390@vger.kernel.org
    Cc: linux-sh@vger.kernel.org
    Cc: linux-xtensa@linux-xtensa.org
    Cc: sparclinux@vger.kernel.org
    Link: http://lkml.kernel.org/r/1404079773.2619.4.camel@buesod1.americas.hpqcorp.net
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 6f02d452bbee..e568fc8a7250 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -217,7 +217,7 @@ static inline void cpu_relax(void)
 	barrier();
 }
 
-#define arch_mutex_cpu_relax()  barrier()
+#define cpu_relax_lowlatency()  barrier()
 
 static inline void psw_set_key(unsigned int key)
 {

commit d3a73acbc26a4a81a01a35fd162973e53d0386f5
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Apr 15 12:55:07 2014 +0200

    s390: split TIF bits into CIF, PIF and TIF bits
    
    The oi and ni instructions used in entry[64].S to set and clear bits
    in the thread-flags are not guaranteed to be atomic in regard to other
    CPUs. Split the TIF bits into CPU, pt_regs and thread-info specific
    bits. Updates on the TIF bits are done with atomic instructions,
    updates on CPU and pt_regs bits are done with non-atomic instructions.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index dc5fc4f90e52..6f02d452bbee 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -11,6 +11,13 @@
 #ifndef __ASM_S390_PROCESSOR_H
 #define __ASM_S390_PROCESSOR_H
 
+#define CIF_MCCK_PENDING	0	/* machine check handling is pending */
+#define CIF_ASCE		1	/* user asce needs fixup / uaccess */
+
+#define _CIF_MCCK_PENDING	(1<<CIF_MCCK_PENDING)
+#define _CIF_ASCE		(1<<CIF_ASCE)
+
+
 #ifndef __ASSEMBLY__
 
 #include <linux/linkage.h>
@@ -21,6 +28,21 @@
 #include <asm/setup.h>
 #include <asm/runtime_instr.h>
 
+static inline void set_cpu_flag(int flag)
+{
+	S390_lowcore.cpu_flags |= (1U << flag);
+}
+
+static inline void clear_cpu_flag(int flag)
+{
+	S390_lowcore.cpu_flags &= ~(1U << flag);
+}
+
+static inline int test_cpu_flag(int flag)
+{
+	return !!(S390_lowcore.cpu_flags & (1U << flag));
+}
+
 /*
  * Default implementation of macro that returns current
  * instruction pointer ("program counter").

commit 24eb3a824c4f3ccfaa2305dc1d9d9e2a708828c5
Author: Dominik Dingel <dingel@linux.vnet.ibm.com>
Date:   Mon Jun 17 16:25:18 2013 +0200

    KVM: s390: Add FAULT_FLAG_RETRY_NOWAIT for guest fault
    
    In the case of a fault, we will retry to exit sie64 but with gmap fault
    indication for this thread set. This makes it possible to handle async
    page faults.
    
    Based on a patch from Martin Schwidefsky.
    
    Signed-off-by: Dominik Dingel <dingel@linux.vnet.ibm.com>
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 0a876bc543d3..dc5fc4f90e52 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -79,6 +79,7 @@ struct thread_struct {
         unsigned long ksp;              /* kernel stack pointer             */
 	mm_segment_t mm_segment;
 	unsigned long gmap_addr;	/* address of last gmap fault. */
+	unsigned int gmap_pfault;	/* signal of a pending guest pfault */
 	struct per_regs per_user;	/* User specified PER registers */
 	struct per_event per_event;	/* Cause of the last PER trap */
 	unsigned long per_flags;	/* Flags to control debug behavior */

commit 106078641f32a6a10d9759f809f809725695cb09
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Mon Oct 28 14:48:30 2013 +0100

    s390/mm,tlb: correct tlb flush on page table upgrade
    
    The IDTE instruction used to flush TLB entries for a specific address
    space uses the address-space-control element (ASCE) to identify
    affected TLB entries. The upgrade of a page table adds a new top
    level page table which changes the ASCE. The TLB entries associated
    with the old ASCE need to be flushed and the ASCE for the address space
    needs to be replaced synchronously on all CPUs which currently use it.
    The concept of a lazy ASCE update with an exception handler is broken.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index a56e63483e0f..0a876bc543d3 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -144,9 +144,7 @@ struct stack_frame {
 	regs->psw.mask	= PSW_USER_BITS | PSW_MASK_BA;			\
 	regs->psw.addr	= new_psw | PSW_ADDR_AMODE;			\
 	regs->gprs[15]	= new_stackp;					\
-	__tlb_flush_mm(current->mm);					\
 	crst_table_downgrade(current->mm, 1UL << 31);			\
-	update_mm(current->mm, current);				\
 	execve_tail();							\
 } while (0)
 

commit 5ebf250dabbae83ad875f0dda5a108503cf78f3b
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed Oct 16 09:58:01 2013 +0200

    s390: fix handling of runtime instrumentation psw bit
    
    Fix the following bugs:
    - When returning from a signal the signal handler copies the saved psw mask
      from user space and uses parts of it. Especially it restores the RI bit
      unconditionally. If however the machine doesn't support RI, or RI is
      disabled for the task, the last lpswe instruction which returns to user
      space will generate a specification exception.
      To fix this check if the RI bit is allowed to be set and kill the task
      if not.
    - In the compat mode signal handler code the RI bit of the psw mask gets
      propagated to the mask of the return psw: if user space enables RI in the
      signal handler, RI will also be enabled after the signal handler is
      finished.
      This is a different behaviour than with 64 bit tasks. So change this to
      match the 64 bit semantics, which restores the original RI bit value.
    - Fix similar oddities within the ptrace code as well.
    
    Reviewed-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 3caaf6548ef5..a56e63483e0f 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -175,6 +175,9 @@ unsigned long get_wchan(struct task_struct *p);
 #define KSTK_EIP(tsk)	(task_pt_regs(tsk)->psw.addr)
 #define KSTK_ESP(tsk)	(task_pt_regs(tsk)->gprs[15])
 
+/* Has task runtime instrumentation enabled ? */
+#define is_ri_task(tsk) (!!(tsk)->thread.ri_cb)
+
 static inline unsigned short stap(void)
 {
 	unsigned short cpu_address;

commit e258d719ff28ecc7a048eb8f78380e68c4b3a3f0
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Sep 24 09:14:56 2013 +0200

    s390/uaccess: always run the kernel in home space
    
    Simplify the uaccess code by removing the user_mode=home option.
    The kernel will now always run in the home space mode.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 50256f05fbcf..3caaf6548ef5 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -134,14 +134,14 @@ struct stack_frame {
  * Do necessary setup to start up a new thread.
  */
 #define start_thread(regs, new_psw, new_stackp) do {			\
-	regs->psw.mask	= psw_user_bits | PSW_MASK_EA | PSW_MASK_BA;	\
+	regs->psw.mask	= PSW_USER_BITS | PSW_MASK_EA | PSW_MASK_BA;	\
 	regs->psw.addr	= new_psw | PSW_ADDR_AMODE;			\
 	regs->gprs[15]	= new_stackp;					\
 	execve_tail();							\
 } while (0)
 
 #define start_thread31(regs, new_psw, new_stackp) do {			\
-	regs->psw.mask	= psw_user_bits | PSW_MASK_BA;			\
+	regs->psw.mask	= PSW_USER_BITS | PSW_MASK_BA;			\
 	regs->psw.addr	= new_psw | PSW_ADDR_AMODE;			\
 	regs->gprs[15]	= new_stackp;					\
 	__tlb_flush_mm(current->mm);					\
@@ -343,9 +343,9 @@ __set_psw_mask(unsigned long mask)
 }
 
 #define local_mcck_enable() \
-	__set_psw_mask(psw_kernel_bits | PSW_MASK_DAT | PSW_MASK_MCHECK)
+	__set_psw_mask(PSW_KERNEL_BITS | PSW_MASK_DAT | PSW_MASK_MCHECK)
 #define local_mcck_disable() \
-	__set_psw_mask(psw_kernel_bits | PSW_MASK_DAT)
+	__set_psw_mask(PSW_KERNEL_BITS | PSW_MASK_DAT)
 
 /*
  * Basic Machine Check/Program Check Handler.

commit 0f20822a69148f53bbafbe6ee3d43e8eff0bad27
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Fri Sep 13 13:36:25 2013 +0200

    s390/dis: move disassembler function prototypes to proper header file
    
    Now that the in-kernel disassembler has an own header file move the
    disassembler related function prototypes to that header file.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index ca7821f07260..50256f05fbcf 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -169,11 +169,6 @@ extern void release_thread(struct task_struct *);
  */
 extern unsigned long thread_saved_pc(struct task_struct *t);
 
-extern void show_code(struct pt_regs *regs);
-extern void print_fn_code(unsigned char *code, unsigned long len);
-extern int insn_to_mnemonic(unsigned char *instruction, char *buf,
-			    unsigned int len);
-
 unsigned long get_wchan(struct task_struct *p);
 #define task_pt_regs(tsk) ((struct pt_regs *) \
         (task_stack_page(tsk) + THREAD_SIZE) - 1)

commit 083986e8248d978b6c961d3da6beb0c921c68220
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Sat Sep 28 11:23:59 2013 +0200

    mutex: replace CONFIG_HAVE_ARCH_MUTEX_CPU_RELAX with simple ifdef
    
    Linus suggested to replace
    
     #ifndef CONFIG_HAVE_ARCH_MUTEX_CPU_RELAX
     #define arch_mutex_cpu_relax() cpu_relax()
     #endif
    
    with just a simple
    
      #ifndef arch_mutex_cpu_relax
      # define arch_mutex_cpu_relax() cpu_relax()
      #endif
    
    to get rid of CONFIG_HAVE_CPU_RELAX_SIMPLE. So architectures can
    simply define arch_mutex_cpu_relax if they want an architecture
    specific function instead of having to add a select statement in
    their Kconfig in addition.
    
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 0eb37505cab1..ca7821f07260 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -198,6 +198,8 @@ static inline void cpu_relax(void)
 	barrier();
 }
 
+#define arch_mutex_cpu_relax()  barrier()
+
 static inline void psw_set_key(unsigned int key)
 {
 	asm volatile("spka 0(%0)" : : "d" (key));

commit ae7a835cc546fc67df90edaaa0c48ae2b22a29fe
Merge: cf39c8e5352b 6b9e4fa07443
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Sep 4 18:15:06 2013 -0700

    Merge branch 'next' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull KVM updates from Gleb Natapov:
     "The highlights of the release are nested EPT and pv-ticketlocks
      support (hypervisor part, guest part, which is most of the code, goes
      through tip tree).  Apart of that there are many fixes for all arches"
    
    Fix up semantic conflicts as discussed in the pull request thread..
    
    * 'next' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (88 commits)
      ARM: KVM: Add newlines to panic strings
      ARM: KVM: Work around older compiler bug
      ARM: KVM: Simplify tracepoint text
      ARM: KVM: Fix kvm_set_pte assignment
      ARM: KVM: vgic: Bump VGIC_NR_IRQS to 256
      ARM: KVM: Bugfix: vgic_bytemap_get_reg per cpu regs
      ARM: KVM: vgic: fix GICD_ICFGRn access
      ARM: KVM: vgic: simplify vgic_get_target_reg
      KVM: MMU: remove unused parameter
      KVM: PPC: Book3S PR: Rework kvmppc_mmu_book3s_64_xlate()
      KVM: PPC: Book3S PR: Make instruction fetch fallback work for system calls
      KVM: PPC: Book3S PR: Don't corrupt guest state when kernel uses VMX
      KVM: x86: update masterclock when kvmclock_offset is calculated (v2)
      KVM: PPC: Book3S: Fix compile error in XICS emulation
      KVM: PPC: Book3S PR: return appropriate error when allocation fails
      arch: powerpc: kvm: add signed type cast for comparation
      KVM: x86: add comments where MMIO does not return to the emulator
      KVM: vmx: count exits to userspace during invalid guest emulation
      KVM: rename __kvm_io_bus_sort_cmp to kvm_io_bus_cmp
      kvm: optimize away THP checks in kvm_is_mmio_pfn()
      ...

commit ee6ee55bb505c5bd8e64bc652281a93fb99c07b3
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Fri Jul 26 15:04:03 2013 +0200

    KVM: s390: fix task size check
    
    The gmap_map_segment function uses PGDIR_SIZE in the check for the
    maximum address in the tasks address space. This incorrectly limits
    the amount of memory usable for a kvm guest to 4TB. The correct limit
    is (1UL << 53). As the TASK_SIZE has different values (4TB vs 8PB)
    dependent on the existance of the fourth page table level, create
    a new define 'TASK_MAX_SIZE' for (1UL << 53).
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 6b499870662f..83c85c217f5c 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -43,6 +43,7 @@ extern void execve_tail(void);
 #ifndef CONFIG_64BIT
 
 #define TASK_SIZE		(1UL << 31)
+#define TASK_MAX_SIZE		(1UL << 31)
 #define TASK_UNMAPPED_BASE	(1UL << 30)
 
 #else /* CONFIG_64BIT */
@@ -51,6 +52,7 @@ extern void execve_tail(void);
 #define TASK_UNMAPPED_BASE	(test_thread_flag(TIF_31BIT) ? \
 					(1UL << 30) : (1UL << 41))
 #define TASK_SIZE		TASK_SIZE_OF(current)
+#define TASK_MAX_SIZE		(1UL << 53)
 
 #endif /* CONFIG_64BIT */
 

commit 64597f9dae1850e0360ae2e9b5485d4b5d1fdf4c
Author: Michael Mueller <mimu@linux.vnet.ibm.com>
Date:   Tue Jul 2 22:58:26 2013 +0200

    s390/ptrace: PTRACE_TE_ABORT_RAND
    
    The patch implements a s390 specific ptrace request
    PTRACE_TE_ABORT_RAND to modify the randomness of spontaneous
    aborts of memory transactions of the transaction execution
    facility. The data argument of the ptrace request is used to
    specify the levels of randomness, 0 for normal operation, 1 to
    abort every transaction at a random instruction, and 2 to abort
    a random transaction at a random instruction. The default is 0
    for normal operation.
    
    Acked-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Michael Mueller <mimu@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 6b499870662f..b0e6435b2f02 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -91,7 +91,15 @@ struct thread_struct {
 #endif
 };
 
-#define PER_FLAG_NO_TE		1UL	/* Flag to disable transactions. */
+/* Flag to disable transactions. */
+#define PER_FLAG_NO_TE			1UL
+/* Flag to enable random transaction aborts. */
+#define PER_FLAG_TE_ABORT_RAND		2UL
+/* Flag to specify random transaction abort mode:
+ * - abort each transaction at a random instruction before TEND if set.
+ * - abort random transactions at a random instruction if cleared.
+ */
+#define PER_FLAG_TE_ABORT_RAND_TEND	4UL
 
 typedef struct thread_struct thread_struct;
 

commit 0bcc94baca601c266ded6347c614b180316a383c
Author: Stefan Raspl <raspl@linux.vnet.ibm.com>
Date:   Tue Mar 5 10:39:55 2013 +0100

    s390/dis: use explicit buf len
    
    Pass buffer length in extra parameter.
    
    Signed-off-by: Stefan Raspl <raspl@linux.vnet.ibm.com>
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 94e749c90230..6b499870662f 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -161,7 +161,8 @@ extern unsigned long thread_saved_pc(struct task_struct *t);
 
 extern void show_code(struct pt_regs *regs);
 extern void print_fn_code(unsigned char *code, unsigned long len);
-extern int insn_to_mnemonic(unsigned char *instruction, char buf[8]);
+extern int insn_to_mnemonic(unsigned char *instruction, char *buf,
+			    unsigned int len);
 
 unsigned long get_wchan(struct task_struct *p);
 #define task_pt_regs(tsk) ((struct pt_regs *) \

commit 42859eea96ba6beabfb0369a1eeffa3c7d2bd9cb
Merge: f59b51fe3d30 f322220d6159
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Oct 10 12:02:25 2012 +0900

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal
    
    Pull generic execve() changes from Al Viro:
     "This introduces the generic kernel_thread() and kernel_execve()
      functions, and switches x86, arm, alpha, um and s390 over to them."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/signal: (26 commits)
      s390: convert to generic kernel_execve()
      s390: switch to generic kernel_thread()
      s390: fold kernel_thread_helper() into ret_from_fork()
      s390: fold execve_tail() into start_thread(), convert to generic sys_execve()
      um: switch to generic kernel_thread()
      x86, um/x86: switch to generic sys_execve and kernel_execve
      x86: split ret_from_fork
      alpha: introduce ret_from_kernel_execve(), switch to generic kernel_execve()
      alpha: switch to generic kernel_thread()
      alpha: switch to generic sys_execve()
      arm: get rid of execve wrapper, switch to generic execve() implementation
      arm: optimized current_pt_regs()
      arm: introduce ret_from_kernel_execve(), switch to generic kernel_execve()
      arm: split ret_from_fork, simplify kernel_thread() [based on patch by rmk]
      generic sys_execve()
      generic kernel_execve()
      new helper: current_pt_regs()
      preparation for generic kernel_thread()
      um: kill thread->forking
      um: let signal_delivered() do SIGTRAP on singlestepping into handler
      ...

commit ecefbd94b834fa32559d854646d777c56749ef1c
Merge: ce57e981f2b9 3d11df7abbff
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Oct 4 09:30:33 2012 -0700

    Merge tag 'kvm-3.7-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull KVM updates from Avi Kivity:
     "Highlights of the changes for this release include support for vfio
      level triggered interrupts, improved big real mode support on older
      Intels, a streamlines guest page table walker, guest APIC speedups,
      PIO optimizations, better overcommit handling, and read-only memory."
    
    * tag 'kvm-3.7-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (138 commits)
      KVM: s390: Fix vcpu_load handling in interrupt code
      KVM: x86: Fix guest debug across vcpu INIT reset
      KVM: Add resampling irqfds for level triggered interrupts
      KVM: optimize apic interrupt delivery
      KVM: MMU: Eliminate pointless temporary 'ac'
      KVM: MMU: Avoid access/dirty update loop if all is well
      KVM: MMU: Eliminate eperm temporary
      KVM: MMU: Optimize is_last_gpte()
      KVM: MMU: Simplify walk_addr_generic() loop
      KVM: MMU: Optimize pte permission checks
      KVM: MMU: Update accessed and dirty bits after guest pagetable walk
      KVM: MMU: Move gpte_access() out of paging_tmpl.h
      KVM: MMU: Optimize gpte_access() slightly
      KVM: MMU: Push clean gpte write protection out of gpte_access()
      KVM: clarify kvmclock documentation
      KVM: make processes waiting on vcpu mutex killable
      KVM: SVM: Make use of asm.h
      KVM: VMX: Make use of asm.h
      KVM: VMX: Make lto-friendly
      KVM: x86: lapic: Clean up find_highest_vector() and count_vectors()
      ...
    
    Conflicts:
            arch/s390/include/asm/processor.h
            arch/x86/kvm/i8259.c

commit f9a7e025dfc28783fd2b05812e663251acf4bf21
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Sep 21 20:48:32 2012 -0400

    s390: switch to generic kernel_thread()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 0bc77619c3a3..da6f5baeee5c 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -135,7 +135,6 @@ struct seq_file;
 
 /* Free all resources held by a thread. */
 extern void release_thread(struct task_struct *);
-extern int kernel_thread(int (*fn)(void *), void * arg, unsigned long flags);
 
 /*
  * Return saved PC of a blocked thread.

commit 65f22a906e154e8086ed561904d09c3586de85f4
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu Sep 6 15:48:11 2012 -0400

    s390: fold execve_tail() into start_thread(), convert to generic sys_execve()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 11e4e3236937..0bc77619c3a3 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -32,6 +32,7 @@ static inline void get_cpu_id(struct cpuid *ptr)
 extern void s390_adjust_jiffies(void);
 extern const struct seq_operations cpuinfo_op;
 extern int sysctl_ieee_emulation_warnings;
+extern void execve_tail(void);
 
 /*
  * User space process size: 2GB for 31 bit, 4TB or 8PT for 64 bit.
@@ -114,6 +115,7 @@ struct stack_frame {
 	regs->psw.mask	= psw_user_bits | PSW_MASK_EA | PSW_MASK_BA;	\
 	regs->psw.addr	= new_psw | PSW_ADDR_AMODE;			\
 	regs->gprs[15]	= new_stackp;					\
+	execve_tail();							\
 } while (0)
 
 #define start_thread31(regs, new_psw, new_stackp) do {			\
@@ -123,6 +125,7 @@ struct stack_frame {
 	__tlb_flush_mm(current->mm);					\
 	crst_table_downgrade(current->mm, 1UL << 31);			\
 	update_mm(current->mm, current);				\
+	execve_tail();							\
 } while (0)
 
 /* Forward declaration, a strange C thing */

commit eb608fb366de123a97227437e5306f731f4a63c5
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed Sep 5 13:26:11 2012 +0200

    s390/exceptions: switch to relative exception table entries
    
    This is the s390 port of 70627654 "x86, extable: Switch to relative
    exception table entries".
    Reduces the size of our exception tables by 50% on 64 bit builds.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 7e81ff17a89b..f3e0aabfc6bc 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -11,6 +11,8 @@
 #ifndef __ASM_S390_PROCESSOR_H
 #define __ASM_S390_PROCESSOR_H
 
+#ifndef __ASSEMBLY__
+
 #include <linux/linkage.h>
 #include <linux/irqflags.h>
 #include <asm/cpu.h>
@@ -348,23 +350,6 @@ extern void (*s390_base_ext_handler_fn)(void);
 
 #define ARCH_LOW_ADDRESS_LIMIT	0x7fffffffUL
 
-/*
- * Helper macro for exception table entries
- */
-#ifndef CONFIG_64BIT
-#define EX_TABLE(_fault,_target)			\
-	".section __ex_table,\"a\"\n"			\
-	"	.align 4\n"				\
-	"	.long  " #_fault "," #_target "\n"	\
-	".previous\n"
-#else
-#define EX_TABLE(_fault,_target)			\
-	".section __ex_table,\"a\"\n"			\
-	"	.align 8\n"				\
-	"	.quad  " #_fault "," #_target "\n"	\
-	".previous\n"
-#endif
-
 extern int memcpy_real(void *, void *, size_t);
 extern void memcpy_absolute(void *, void *, size_t);
 
@@ -375,4 +360,25 @@ extern void memcpy_absolute(void *, void *, size_t);
 	memcpy_absolute(&(dest), &__tmp, sizeof(__tmp));	\
 }
 
-#endif                                 /* __ASM_S390_PROCESSOR_H           */
+/*
+ * Helper macro for exception table entries
+ */
+#define EX_TABLE(_fault, _target)	\
+	".section __ex_table,\"a\"\n"	\
+	".align	4\n"			\
+	".long	(" #_fault ") - .\n"	\
+	".long	(" #_target ") - .\n"	\
+	".previous\n"
+
+#else /* __ASSEMBLY__ */
+
+#define EX_TABLE(_fault, _target)	\
+	.section __ex_table,"a"	;	\
+	.align	4 ;			\
+	.long	(_fault) - . ;		\
+	.long	(_target) - . ;		\
+	.previous
+
+#endif /* __ASSEMBLY__ */
+
+#endif /* __ASM_S390_PROCESSOR_H */

commit 6668022c7bde3fdc96d3d257294a7216c7a46829
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed Aug 29 14:12:20 2012 +0200

    s390/cache: add cpu cache information to /proc/cpuinfo
    
    Add a line for each cpu cache to /proc/cpuinfo.
    Since we only have information of private cpu caches in sysfs we
    add a line for each cpu cache in /proc/cpuinfo which will also
    contain information about shared caches.
    
    For a z196 machine /proc/cpuinfo now looks like:
    
    vendor_id       : IBM/S390
    bogomips per cpu: 14367.00
    features        : esan3 zarch stfle msa ldisp eimm dfp etf3eh highgprs
    cache0          : level=1 type=Data scope=Private size=64K line_size=256 associativity=4
    cache1          : level=1 type=Instruction scope=Private size=128K line_size=256 associativity=8
    cache2          : level=2 type=Unified scope=Private size=1536K line_size=256 associativity=12
    cache3          : level=3 type=Unified scope=Shared size=24576K line_size=256 associativity=12
    cache4          : level=4 type=Unified scope=Shared size=196608K line_size=256 associativity=24
    processor 0: version = FF,  identification = 000123,  machine = 2817
    processor 1: version = FF,  identification = 100123,  machine = 2817
    processor 2: version = FF,  identification = 200123,  machine = 2817
    processor 3: version = FF,  identification = 200123,  machine = 2817
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 46fe1fbf91c5..7e81ff17a89b 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -140,6 +140,12 @@ struct task_struct;
 struct mm_struct;
 struct seq_file;
 
+#ifdef CONFIG_64BIT
+extern void show_cacheinfo(struct seq_file *m);
+#else
+static inline void show_cacheinfo(struct seq_file *m) { }
+#endif
+
 /* Free all resources held by a thread. */
 extern void release_thread(struct task_struct *);
 extern int kernel_thread(int (*fn)(void *), void * arg, unsigned long flags);

commit d35339a42dd1f53b0bb86cf75418a9b7cf5f0f30
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Jul 31 11:03:04 2012 +0200

    s390: add support for transactional memory
    
    Allow user-space processes to use transactional execution (TX).
    If the TX facility is available user space programs can use
    transactions for fine-grained serialization based on the data
    objects that are referenced during a transaction. This is
    useful for lockless data structures and speculative compiler
    optimizations.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 0fff583d2c7c..46fe1fbf91c5 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -76,14 +76,20 @@ struct thread_struct {
 	unsigned long gmap_addr;	/* address of last gmap fault. */
 	struct per_regs per_user;	/* User specified PER registers */
 	struct per_event per_event;	/* Cause of the last PER trap */
+	unsigned long per_flags;	/* Flags to control debug behavior */
         /* pfault_wait is used to block the process on a pfault event */
 	unsigned long pfault_wait;
 	struct list_head list;
 	/* cpu runtime instrumentation */
 	struct runtime_instr_cb *ri_cb;
 	int ri_signum;
+#ifdef CONFIG_64BIT
+	unsigned char trap_tdb[256];	/* Transaction abort diagnose block */
+#endif
 };
 
+#define PER_FLAG_NO_TE		1UL	/* Flag to disable transactions. */
+
 typedef struct thread_struct thread_struct;
 
 /*

commit e4b8b3f33fcaa0ed6e6b5482a606091d8cd20beb
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Tue Jul 31 10:52:05 2012 +0200

    s390: add support for runtime instrumentation
    
    Allow user-space threads to use runtime instrumentation (RI). To enable RI
    for a thread there is a new s390 specific system call, sys_s390_runtime_instr,
    that takes as parameter a realtime signal number. If the RI facility is
    available the system call sets up a control block for the calling thread with
    the appropriate permissions for the thread to modify the control block.
    
    The user-space thread can then use the store and modify RI instructions to
    alter the control block and start/stop the instrumentation via RION/RIOFF.
    
    If the user specified program buffer runs full RI triggers an external
    interrupt. The external interrupt is translated to a real-time signal that
    is delivered to the thread that enabled RI on that CPU. The number of
    the real-time signal is the number specified in the RI system call. So,
    user-space can select any available real-time signal number in case the
    application itself uses real-time signals for other purposes.
    
    The kernel saves the RI control blocks on task switch only if the running
    thread was enabled for RI. Therefore, the performance impact on task switch
    should be negligible if RI is not used.
    
    RI is only enabled for user-space mode and is disabled for the supervisor
    state.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index d4477ba99a16..0fff583d2c7c 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -17,6 +17,7 @@
 #include <asm/page.h>
 #include <asm/ptrace.h>
 #include <asm/setup.h>
+#include <asm/runtime_instr.h>
 
 /*
  * Default implementation of macro that returns current
@@ -78,6 +79,9 @@ struct thread_struct {
         /* pfault_wait is used to block the process on a pfault event */
 	unsigned long pfault_wait;
 	struct list_head list;
+	/* cpu runtime instrumentation */
+	struct runtime_instr_cb *ri_cb;
+	int ri_signum;
 };
 
 typedef struct thread_struct thread_struct;

commit c10302efe569bfd646b4c22df29577a4595b4580
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Jul 31 16:23:59 2012 +0200

    s390/bpf,jit: BPF Just In Time compiler for s390
    
    The s390 implementation of the JIT compiler for packet filter speedup.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 11e4e3236937..d4477ba99a16 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -140,6 +140,7 @@ extern int kernel_thread(int (*fn)(void *), void * arg, unsigned long flags);
 extern unsigned long thread_saved_pc(struct task_struct *t);
 
 extern void show_code(struct pt_regs *regs);
+extern void print_fn_code(unsigned char *code, unsigned long len);
 
 unsigned long get_wchan(struct task_struct *p);
 #define task_pt_regs(tsk) ((struct pt_regs *) \

commit fe56097b23b1303b894eefd91582e4a64247d03f
Merge: e115676e042f e7882d6c4087
Author: Avi Kivity <avi@redhat.com>
Date:   Sun Aug 5 13:25:10 2012 +0300

    Merge remote-tracking branch 'upstream' into next
    
     - bring back critical fixes (esp. aa67f6096c19bc)
     - provide an updated base for development
    
    * upstream: (4334 commits)
      missed mnt_drop_write() in do_dentry_open()
      UBIFS: nuke pdflush from comments
      gfs2: nuke pdflush from comments
      drbd: nuke pdflush from comments
      nilfs2: nuke write_super from comments
      hfs: nuke write_super from comments
      vfs: nuke pdflush from comments
      jbd/jbd2: nuke write_super from comments
      btrfs: nuke pdflush from comments
      btrfs: nuke write_super from comments
      ext4: nuke pdflush from comments
      ext4: nuke write_super from comments
      ext3: nuke write_super from comments
      Documentation: fix the VM knobs descritpion WRT pdflush
      Documentation: get rid of write_super
      vfs: kill write_super and sync_supers
      ACPI processor: Fix tick_broadcast_mask online/offline regression
      ACPI: Only count valid srat memory structures
      ACPI: Untangle a return statement for better readability
      Linux 3.6-rc1
      ...
    
    Signed-off-by: Avi Kivity <avi@redhat.com>

commit 0f6f281b731d20bfe75c13f85d33f3f05b440222
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Thu Jul 26 08:53:06 2012 +0200

    s390/mm: downgrade page table after fork of a 31 bit process
    
    The downgrade of the 4 level page table created by init_new_context is
    currently done only in start_thread31. If a 31 bit process forks the
    new mm uses a 4 level page table, including the task size of 2<<42
    that goes along with it. This is incorrect as now a 31 bit process
    can map memory beyond 2GB. Define arch_dup_mmap to do the downgrade
    after fork.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index c40fa91e38a8..11e4e3236937 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -120,7 +120,9 @@ struct stack_frame {
 	regs->psw.mask	= psw_user_bits | PSW_MASK_BA;			\
 	regs->psw.addr	= new_psw | PSW_ADDR_AMODE;			\
 	regs->gprs[15]	= new_stackp;					\
+	__tlb_flush_mm(current->mm);					\
 	crst_table_downgrade(current->mm, 1UL << 31);			\
+	update_mm(current->mm, current);				\
 } while (0)
 
 /* Forward declaration, a strange C thing */

commit 9b7fb990e080f3a7c5dff9a829d11247e629b98f
Author: Cornelia Huck <cornelia.huck@de.ibm.com>
Date:   Mon Jul 23 17:20:28 2012 +0200

    s390/dis: Instruction decoding interface
    
    Provide a new function, insn_to_mnemonic, by which e.g. kvm can obtain
    a human-readable decoding of an instruction's opcode.
    
    Reviewed-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Cornelia Huck <cornelia.huck@de.ibm.com>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index c40fa91e38a8..31feac630544 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -138,6 +138,7 @@ extern int kernel_thread(int (*fn)(void *), void * arg, unsigned long flags);
 extern unsigned long thread_saved_pc(struct task_struct *t);
 
 extern void show_code(struct pt_regs *regs);
+extern int insn_to_mnemonic(unsigned char *instruction, char buf[8]);
 
 unsigned long get_wchan(struct task_struct *p);
 #define task_pt_regs(tsk) ((struct pt_regs *) \

commit a53c8fab3f87c995c30ac226a03af95361243144
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Fri Jul 20 11:15:04 2012 +0200

    s390/comments: unify copyright messages and remove file names
    
    Remove the file name from the comment at top of many files. In most
    cases the file name was wrong anyway, so it's rather pointless.
    
    Also unify the IBM copyright statement. We did have a lot of sightly
    different statements and wanted to change them one after another
    whenever a file gets touched. However that never happened. Instead
    people start to take the old/"wrong" statements to use as a template
    for new files.
    So unify all of them in one go.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index f1700c5c8884..c40fa91e38a8 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -1,8 +1,6 @@
 /*
- *  include/asm-s390/processor.h
- *
  *  S390 version
- *    Copyright (C) 1999 IBM Deutschland Entwicklung GmbH, IBM Corporation
+ *    Copyright IBM Corp. 1999
  *    Author(s): Hartmut Penner (hp@de.ibm.com),
  *               Martin Schwidefsky (schwidefsky@de.ibm.com)
  *

commit fbe765680d1fe9d08187ea4dad5041a7955a2c3a
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Tue Jun 5 09:59:52 2012 +0200

    s390/smp: make absolute lowcore / cpu restart parameter accesses more robust
    
    Setting the cpu restart parameters is done in three different fashions:
    - directly setting the four parameters individually
    - copying the four parameters with memcpy (using 4 * sizeof(long))
    - copying the four parameters using a private structure
    
    In addition code in entry*.S relies on a certain order of the restart
    members of struct _lowcore.
    
    Make all of this more robust to future changes by adding a
    mem_absolute_assign(dest, val) define, which assigns val to dest
    using absolute addressing mode. Also the load multiple instructions
    in entry*.S have been split into separate load instruction so the
    order of the struct _lowcore members doesn't matter anymore.
    
    In addition move the prototypes of memcpy_real/absolute from uaccess.h
    to processor.h. These memcpy* variants are not related to uaccess at all.
    string.h doesn't seem to match as well, so lets use processor.h.
    
    Also replace the eight byte array in struct _lowcore which represents a
    misaliged u64 with a u64. The compiler will always create code that
    handles the misaligned u64 correctly.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 20d0585cf905..f1700c5c8884 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -348,4 +348,14 @@ extern void (*s390_base_ext_handler_fn)(void);
 	".previous\n"
 #endif
 
+extern int memcpy_real(void *, void *, size_t);
+extern void memcpy_absolute(void *, void *, size_t);
+
+#define mem_assign_absolute(dest, val) {			\
+	__typeof__(dest) __tmp = (val);				\
+								\
+	BUILD_BUG_ON(sizeof(__tmp) != sizeof(val));		\
+	memcpy_absolute(&(dest), &__tmp, sizeof(__tmp));	\
+}
+
 #endif                                 /* __ASM_S390_PROCESSOR_H           */

commit 8ee78c6fb982b3a7343faf561e7937d4cfa955ff
Merge: aac422afeffa 491af9903b85
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu May 31 10:51:10 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux
    
    Pull s390 patches from Heiko Carstens:
     "A couple of s390 patches for the 3.5 merge window.  Just a collection
      of bug fixes and cleanups."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux:
      s390/uaccess: fix access_ok compile warnings
      s390/cmpxchg: select HAVE_CMPXCHG_LOCAL option
      s390/cmpxchg: fix sign extension bugs
      s390/cmpxchg: fix 1 and 2 byte memory accesses
      s390/cmpxchg: fix compile warnings specific to s390
      s390/cmpxchg: add missing memory barrier to cmpxchg64
      s390/cpu: remove cpu "capabilities" sysfs attribute
      s390/kernel: Fix smp_call_ipl_cpu() for offline CPUs
      s390/kernel: Introduce memcpy_absolute() function
      s390/headers: replace __s390x__ with CONFIG_64BIT where possible
      s390/headers: remove #ifdef __KERNEL__ from not exported headers
      s390/irq: split irq stats for cpu-measurement alert facilities
      s390/kexec: Move early_pgm_check_handler() to text section
      s390/kdump: Use real mode for PSW restart and kexec
      s390/kdump: Account /sys/kernel/kexec_crash_size changes in OS info
      s390/kernel: Remove OS info init function call and diag 308 for kdump

commit b9e3f776c811cc0647c7360844714b6a9b5fd0ef
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Fri May 25 09:39:29 2012 +0200

    s390/cpu: remove cpu "capabilities" sysfs attribute
    
    It has been a big mistage to add the capabilities attribute to the
    cpus in sysfs:
    First the attribute only contains the cpu capability of primary cpus,
    which however is not necessarily (or better: unlikely) the type of
    cpu the kernel runs on, which is typically an IFL.
    In addition all information that is necessary is available in
    /proc/sysinfo already. So this attribute partially duplicated
    informations.
    So programs should look into the sysinfo file to retrieve all
    informations they are interested in.
    
    Since with this kernel release also the powersavings cpu attributes
    are removed this seems to be a good opportunity to remove another
    broken interface.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 62e0d9f9a29a..a6951a7e9aea 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -32,7 +32,6 @@ static inline void get_cpu_id(struct cpuid *ptr)
 }
 
 extern void s390_adjust_jiffies(void);
-extern int get_cpu_capability(unsigned int *);
 extern const struct seq_operations cpuinfo_op;
 extern int sysctl_ieee_emulation_warnings;
 

commit f4815ac6c935b8e441fe12504d62e0e8ff7f7ce5
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed May 23 16:24:51 2012 +0200

    s390/headers: replace __s390x__ with CONFIG_64BIT where possible
    
    Replace __s390x__ with CONFIG_64BIT in all places that are not exported
    to userspace or guarded with #ifdef __KERNEL__.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 0aa04f9bc624..62e0d9f9a29a 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -39,27 +39,27 @@ extern int sysctl_ieee_emulation_warnings;
 /*
  * User space process size: 2GB for 31 bit, 4TB or 8PT for 64 bit.
  */
-#ifndef __s390x__
+#ifndef CONFIG_64BIT
 
 #define TASK_SIZE		(1UL << 31)
 #define TASK_UNMAPPED_BASE	(1UL << 30)
 
-#else /* __s390x__ */
+#else /* CONFIG_64BIT */
 
 #define TASK_SIZE_OF(tsk)	((tsk)->mm->context.asce_limit)
 #define TASK_UNMAPPED_BASE	(test_thread_flag(TIF_31BIT) ? \
 					(1UL << 30) : (1UL << 41))
 #define TASK_SIZE		TASK_SIZE_OF(current)
 
-#endif /* __s390x__ */
+#endif /* CONFIG_64BIT */
 
-#ifndef __s390x__
+#ifndef CONFIG_64BIT
 #define STACK_TOP		(1UL << 31)
 #define STACK_TOP_MAX		(1UL << 31)
-#else /* __s390x__ */
+#else /* CONFIG_64BIT */
 #define STACK_TOP		(1UL << (test_thread_flag(TIF_31BIT) ? 31:42))
 #define STACK_TOP_MAX		(1UL << 42)
-#endif /* __s390x__ */
+#endif /* CONFIG_64BIT */
 
 #define HAVE_ARCH_PICK_MMAP_LAYOUT
 
@@ -179,7 +179,7 @@ static inline void psw_set_key(unsigned int key)
  */
 static inline void __load_psw(psw_t psw)
 {
-#ifndef __s390x__
+#ifndef CONFIG_64BIT
 	asm volatile("lpsw  %0" : : "Q" (psw) : "cc");
 #else
 	asm volatile("lpswe %0" : : "Q" (psw) : "cc");
@@ -197,7 +197,7 @@ static inline void __load_psw_mask (unsigned long mask)
 
 	psw.mask = mask;
 
-#ifndef __s390x__
+#ifndef CONFIG_64BIT
 	asm volatile(
 		"	basr	%0,0\n"
 		"0:	ahi	%0,1f-0b\n"
@@ -205,14 +205,14 @@ static inline void __load_psw_mask (unsigned long mask)
 		"	lpsw	%1\n"
 		"1:"
 		: "=&d" (addr), "=Q" (psw) : "Q" (psw) : "memory", "cc");
-#else /* __s390x__ */
+#else /* CONFIG_64BIT */
 	asm volatile(
 		"	larl	%0,1f\n"
 		"	stg	%0,%O1+8(%R1)\n"
 		"	lpswe	%1\n"
 		"1:"
 		: "=&d" (addr), "=Q" (psw) : "Q" (psw) : "memory", "cc");
-#endif /* __s390x__ */
+#endif /* CONFIG_64BIT */
 }
 
 /*
@@ -220,7 +220,7 @@ static inline void __load_psw_mask (unsigned long mask)
  */
 static inline unsigned long __rewind_psw(psw_t psw, unsigned long ilc)
 {
-#ifndef __s390x__
+#ifndef CONFIG_64BIT
 	if (psw.addr & PSW_ADDR_AMODE)
 		/* 31 bit mode */
 		return (psw.addr - ilc) | PSW_ADDR_AMODE;
@@ -250,7 +250,7 @@ static inline void __noreturn disabled_wait(unsigned long code)
          * Store status and then load disabled wait psw,
          * the processor is dead afterwards
          */
-#ifndef __s390x__
+#ifndef CONFIG_64BIT
 	asm volatile(
 		"	stctl	0,0,0(%2)\n"
 		"	ni	0(%2),0xef\n"	/* switch off protection */
@@ -269,7 +269,7 @@ static inline void __noreturn disabled_wait(unsigned long code)
 		"	lpsw	0(%1)"
 		: "=m" (ctl_buf)
 		: "a" (&dw_psw), "a" (&ctl_buf), "m" (dw_psw) : "cc");
-#else /* __s390x__ */
+#else /* CONFIG_64BIT */
 	asm volatile(
 		"	stctg	0,0,0(%2)\n"
 		"	ni	4(%2),0xef\n"	/* switch off protection */
@@ -302,7 +302,7 @@ static inline void __noreturn disabled_wait(unsigned long code)
 		"	lpswe	0(%1)"
 		: "=m" (ctl_buf)
 		: "a" (&dw_psw), "a" (&ctl_buf), "m" (dw_psw) : "cc", "0", "1");
-#endif /* __s390x__ */
+#endif /* CONFIG_64BIT */
 	while (1);
 }
 
@@ -338,7 +338,7 @@ extern void (*s390_base_ext_handler_fn)(void);
 /*
  * Helper macro for exception table entries
  */
-#ifndef __s390x__
+#ifndef CONFIG_64BIT
 #define EX_TABLE(_fault,_target)			\
 	".section __ex_table,\"a\"\n"			\
 	"	.align 4\n"				\

commit da477737c5ec99d37cb78dab909aa0402a0ebf18
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed May 23 13:55:45 2012 +0200

    s390/headers: remove #ifdef __KERNEL__ from not exported headers
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index d499b30ea487..0aa04f9bc624 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -20,7 +20,6 @@
 #include <asm/ptrace.h>
 #include <asm/setup.h>
 
-#ifdef __KERNEL__
 /*
  * Default implementation of macro that returns current
  * instruction pointer ("program counter").
@@ -54,8 +53,6 @@ extern int sysctl_ieee_emulation_warnings;
 
 #endif /* __s390x__ */
 
-#ifdef __KERNEL__
-
 #ifndef __s390x__
 #define STACK_TOP		(1UL << 31)
 #define STACK_TOP_MAX		(1UL << 31)
@@ -64,9 +61,6 @@ extern int sysctl_ieee_emulation_warnings;
 #define STACK_TOP_MAX		(1UL << 42)
 #endif /* __s390x__ */
 
-
-#endif
-
 #define HAVE_ARCH_PICK_MMAP_LAYOUT
 
 typedef struct {
@@ -341,8 +335,6 @@ extern void (*s390_base_ext_handler_fn)(void);
 
 #define ARCH_LOW_ADDRESS_LIMIT	0x7fffffffUL
 
-#endif
-
 /*
  * Helper macro for exception table entries
  */

commit 55ccf3fe3f9a3441731aa79cf42a628fc4ecace9
Author: Suresh Siddha <suresh.b.siddha@intel.com>
Date:   Wed May 16 15:03:51 2012 -0700

    fork: move the real prepare_to_copy() users to arch_dup_task_struct()
    
    Historical prepare_to_copy() is mostly a no-op, duplicated for majority of
    the architectures and the rest following the x86 model of flushing the extended
    register state like fpu there.
    
    Remove it and use the arch_dup_task_struct() instead.
    
    Suggested-by: Oleg Nesterov <oleg@redhat.com>
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Link: http://lkml.kernel.org/r/1336692811-30576-1-git-send-email-suresh.b.siddha@intel.com
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Koichi Yasutake <yasutake.koichi@jp.panasonic.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: Richard Henderson <rth@twiddle.net>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Haavard Skinnemoen <hskinnemoen@gmail.com>
    Cc: Mike Frysinger <vapier@gentoo.org>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Aurelien Jacquiot <a-jacquiot@ti.com>
    Cc: Mikael Starvik <starvik@axis.com>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: James E.J. Bottomley <jejb@parisc-linux.org>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Chen Liqin <liqin.chen@sunplusct.com>
    Cc: Lennox Wu <lennox.wu@gmail.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: Jeff Dike <jdike@addtoit.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index d499b30ea487..6cbf31311673 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -141,9 +141,6 @@ struct seq_file;
 extern void release_thread(struct task_struct *);
 extern int kernel_thread(int (*fn)(void *), void * arg, unsigned long flags);
 
-/* Prepare to copy thread state - unlazy all lazy status */
-#define prepare_to_copy(tsk)	do { } while (0)
-
 /*
  * Return saved PC of a blocked thread.
  */

commit a0616cdebcfd575dcd4c46102d1b52fbb827fc29
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:30:02 2012 +0100

    Disintegrate asm/system.h for S390
    
    Disintegrate asm/system.h for S390.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    cc: linux-s390@vger.kernel.org

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index d25843a6a915..d499b30ea487 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -14,6 +14,7 @@
 #define __ASM_S390_PROCESSOR_H
 
 #include <linux/linkage.h>
+#include <linux/irqflags.h>
 #include <asm/cpu.h>
 #include <asm/page.h>
 #include <asm/ptrace.h>
@@ -156,6 +157,14 @@ unsigned long get_wchan(struct task_struct *p);
 #define KSTK_EIP(tsk)	(task_pt_regs(tsk)->psw.addr)
 #define KSTK_ESP(tsk)	(task_pt_regs(tsk)->gprs[15])
 
+static inline unsigned short stap(void)
+{
+	unsigned short cpu_address;
+
+	asm volatile("stap %0" : "=m" (cpu_address));
+	return cpu_address;
+}
+
 /*
  * Give up the time slice of the virtual PU.
  */
@@ -303,6 +312,21 @@ static inline void __noreturn disabled_wait(unsigned long code)
 	while (1);
 }
 
+/*
+ * Use to set psw mask except for the first byte which
+ * won't be changed by this function.
+ */
+static inline void
+__set_psw_mask(unsigned long mask)
+{
+	__load_psw_mask(mask | (arch_local_save_flags() & ~(-1UL >> 8)));
+}
+
+#define local_mcck_enable() \
+	__set_psw_mask(psw_kernel_bits | PSW_MASK_DAT | PSW_MASK_MCHECK)
+#define local_mcck_disable() \
+	__set_psw_mask(psw_kernel_bits | PSW_MASK_DAT)
+
 /*
  * Basic Machine Check/Program Check Handler.
  */

commit ff2d8b19a3a62559afba1c53360c8577a7697714
Author: Joe Perches <joe@perches.com>
Date:   Thu Jan 12 17:17:21 2012 -0800

    treewide: convert uses of ATTRIB_NORETURN to __noreturn
    
    Use the more commonly used __noreturn instead of ATTRIB_NORETURN.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Joe Perches <joe@perches.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Haavard Skinnemoen <hskinnemoen@gmail.com>
    Cc: Hans-Christian Egtvedt <egtvedt@samfundet.no>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Acked-by: Ralf Baechle <ralf@linux-mips.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 27272f6a14c2..d25843a6a915 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -236,7 +236,7 @@ static inline unsigned long __rewind_psw(psw_t psw, unsigned long ilc)
 /*
  * Function to drop a processor into disabled wait state
  */
-static inline void ATTRIB_NORET disabled_wait(unsigned long code)
+static inline void __noreturn disabled_wait(unsigned long code)
 {
         unsigned long ctl_buf;
         psw_t dw_psw;

commit aa33c8cbbae2eb98489a3a363099b362146a8f4c
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Dec 27 11:27:18 2011 +0100

    [S390] cleanup trap handling
    
    Move the program interruption code and the translation exception identifier
    to the pt_regs structure as 'int_code' and 'int_parm_long' and make the
    first level interrupt handler in entry[64].S store the two values. That
    makes it possible to drop 'prot_addr' and 'trap_no' from the thread_struct
    and to reduce the number of arguments to a lot of functions. Finally
    un-inline do_trap. Overall this saves 5812 bytes in the .text section of
    the 64 bit kernel.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 5f33d37d032c..27272f6a14c2 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -80,8 +80,6 @@ struct thread_struct {
 	unsigned int  acrs[NUM_ACRS];
         unsigned long ksp;              /* kernel stack pointer             */
 	mm_segment_t mm_segment;
-        unsigned long prot_addr;        /* address of protection-excep.     */
-        unsigned int trap_no;
 	unsigned long gmap_addr;	/* address of last gmap fault. */
 	struct per_regs per_user;	/* User specified PER registers */
 	struct per_event per_event;	/* Cause of the last PER trap */

commit 638ad34a8811119b32247b7722288ef8b90907d1
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Sun Oct 30 15:17:13 2011 +0100

    [S390] sparse: fix sparse warnings about missing prototypes
    
    Add prototypes and includes for functions used in different modules.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 20ffb12d4ae9..5f33d37d032c 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -33,6 +33,8 @@ static inline void get_cpu_id(struct cpuid *ptr)
 
 extern void s390_adjust_jiffies(void);
 extern int get_cpu_capability(unsigned int *);
+extern const struct seq_operations cpuinfo_op;
+extern int sysctl_ieee_emulation_warnings;
 
 /*
  * User space process size: 2GB for 31 bit, 4TB or 8PT for 64 bit.

commit b50511e41aa51a89b4176784a670582424bc7db6
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Sun Oct 30 15:16:50 2011 +0100

    [S390] cleanup psw related bits and pieces
    
    Split out addressing mode bits from PSW_BASE_BITS, rename PSW_BASE_BITS
    to PSW_MASK_BASE, get rid of psw_user32_bits, remove unused function
    enabled_wait(), introduce PSW_MASK_USER, and drop PSW_MASK_MERGE macros.
    Change psw_kernel_bits / psw_user_bits to contain only the bits that
    are always set in the respective mode.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 306c93c1b184..20ffb12d4ae9 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -118,17 +118,17 @@ struct stack_frame {
 /*
  * Do necessary setup to start up a new thread.
  */
-#define start_thread(regs, new_psw, new_stackp) do {		\
-	regs->psw.mask	= psw_user_bits;			\
-	regs->psw.addr	= new_psw | PSW_ADDR_AMODE;		\
-	regs->gprs[15]	= new_stackp;				\
+#define start_thread(regs, new_psw, new_stackp) do {			\
+	regs->psw.mask	= psw_user_bits | PSW_MASK_EA | PSW_MASK_BA;	\
+	regs->psw.addr	= new_psw | PSW_ADDR_AMODE;			\
+	regs->gprs[15]	= new_stackp;					\
 } while (0)
 
-#define start_thread31(regs, new_psw, new_stackp) do {		\
-	regs->psw.mask	= psw_user32_bits;			\
-	regs->psw.addr	= new_psw | PSW_ADDR_AMODE;		\
-	regs->gprs[15]	= new_stackp;				\
-	crst_table_downgrade(current->mm, 1UL << 31);		\
+#define start_thread31(regs, new_psw, new_stackp) do {			\
+	regs->psw.mask	= psw_user_bits | PSW_MASK_BA;			\
+	regs->psw.addr	= new_psw | PSW_ADDR_AMODE;			\
+	regs->gprs[15]	= new_stackp;					\
+	crst_table_downgrade(current->mm, 1UL << 31);			\
 } while (0)
 
 /* Forward declaration, a strange C thing */
@@ -233,25 +233,15 @@ static inline unsigned long __rewind_psw(psw_t psw, unsigned long ilc)
 #endif
 }
  
-/*
- * Function to stop a processor until an interruption occurred
- */
-static inline void enabled_wait(void)
-{
-	__load_psw_mask(PSW_BASE_BITS | PSW_MASK_IO | PSW_MASK_EXT |
-			PSW_MASK_MCHECK | PSW_MASK_WAIT | PSW_DEFAULT_KEY);
-}
-
 /*
  * Function to drop a processor into disabled wait state
  */
-
 static inline void ATTRIB_NORET disabled_wait(unsigned long code)
 {
         unsigned long ctl_buf;
         psw_t dw_psw;
 
-        dw_psw.mask = PSW_BASE_BITS | PSW_MASK_WAIT;
+	dw_psw.mask = PSW_MASK_BASE | PSW_MASK_WAIT | PSW_MASK_BA | PSW_MASK_EA;
         dw_psw.addr = code;
         /* 
          * Store status and then load disabled wait psw,

commit ccf45cafb0805978e6f13a672caca0e536e87cad
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Sun Oct 30 15:16:48 2011 +0100

    [S390] addressing mode limits and psw address wrapping
    
    An instruction with an address right below the adress limit for the
    current addressing mode will wrap. The instruction restart logic in
    the protection fault handler and the signal code need to follow the
    wrapping rules to find the correct instruction address.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index a4b6229e5d4b..306c93c1b184 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -187,7 +187,6 @@ static inline void __load_psw(psw_t psw)
  * Set PSW mask to specified value, while leaving the
  * PSW addr pointing to the next instruction.
  */
-
 static inline void __load_psw_mask (unsigned long mask)
 {
 	unsigned long addr;
@@ -212,6 +211,27 @@ static inline void __load_psw_mask (unsigned long mask)
 		: "=&d" (addr), "=Q" (psw) : "Q" (psw) : "memory", "cc");
 #endif /* __s390x__ */
 }
+
+/*
+ * Rewind PSW instruction address by specified number of bytes.
+ */
+static inline unsigned long __rewind_psw(psw_t psw, unsigned long ilc)
+{
+#ifndef __s390x__
+	if (psw.addr & PSW_ADDR_AMODE)
+		/* 31 bit mode */
+		return (psw.addr - ilc) | PSW_ADDR_AMODE;
+	/* 24 bit mode */
+	return (psw.addr - ilc) & ((1UL << 24) - 1);
+#else
+	unsigned long mask;
+
+	mask = (psw.mask & PSW_MASK_EA) ? -1UL :
+	       (psw.mask & PSW_MASK_BA) ? (1UL << 31) - 1 :
+					  (1UL << 24) - 1;
+	return (psw.addr - ilc) & mask;
+#endif
+}
  
 /*
  * Function to stop a processor until an interruption occurred

commit ada5ed5484f492e4eb13d788c6c077cf243f53e6
Author: Mathias Krause <minipli@googlemail.com>
Date:   Wed Aug 3 16:44:28 2011 +0200

    [S390] exec: remove redundant set_fs(USER_DS)
    
    The address limit is already set in flush_old_exec() so those calls to
    set_fs(USER_DS) are redundant.
    
    Signed-off-by: Mathias Krause <minipli@googlemail.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 55dfcc8bdc0d..a4b6229e5d4b 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -119,14 +119,12 @@ struct stack_frame {
  * Do necessary setup to start up a new thread.
  */
 #define start_thread(regs, new_psw, new_stackp) do {		\
-	set_fs(USER_DS);					\
 	regs->psw.mask	= psw_user_bits;			\
 	regs->psw.addr	= new_psw | PSW_ADDR_AMODE;		\
 	regs->gprs[15]	= new_stackp;				\
 } while (0)
 
 #define start_thread31(regs, new_psw, new_stackp) do {		\
-	set_fs(USER_DS);					\
 	regs->psw.mask	= psw_user32_bits;			\
 	regs->psw.addr	= new_psw | PSW_ADDR_AMODE;		\
 	regs->gprs[15]	= new_stackp;				\

commit e5992f2e6c3829cd43dbc4438ee13dcd6506f7f3
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Sun Jul 24 10:48:20 2011 +0200

    [S390] kvm guest address space mapping
    
    Add code that allows KVM to control the virtual memory layout that
    is seen by a guest. The guest address space uses a second page table
    that shares the last level pte-tables with the process page table.
    If a page is unmapped from the process page table it is automatically
    unmapped from the guest page table as well.
    
    The guest address space mapping starts out empty, KVM can map any
    individual 1MB segments from the process virtual memory to any 1MB
    aligned location in the guest virtual memory. If a target segment in
    the process virtual memory does not exist or is unmapped while a
    guest mapping exists the desired target address is stored as an
    invalid segment table entry in the guest page table.
    The population of the guest page table is fault driven.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 1300c3025334..55dfcc8bdc0d 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -80,6 +80,7 @@ struct thread_struct {
 	mm_segment_t mm_segment;
         unsigned long prot_addr;        /* address of protection-excep.     */
         unsigned int trap_no;
+	unsigned long gmap_addr;	/* address of last gmap fault. */
 	struct per_regs per_user;	/* User specified PER registers */
 	struct per_event per_event;	/* Cause of the last PER trap */
         /* pfault_wait is used to block the process on a pfault event */

commit f2db2e6cb3f5f766cbb3788af44705685ff2445a
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon May 23 10:24:34 2011 +0200

    [S390] pfault: cpu hotplug vs missing completion interrupts
    
    On cpu hot remove a PFAULT CANCEL command is sent to the hypervisor
    which in turn will cancel all outstanding pfault requests that have
    been issued on that cpu (the same happens with a SIGP cpu reset).
    
    The result is that we end up with uninterruptible processes where
    the interrupt that would wake up these processes never arrives.
    
    In order to solve this all processes which wait for a pfault
    completion interrupt get woken up after a cpu hot remove. The worst
    case that could happen is that they fault again and in turn need to
    wait again.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 2c79b6416271..1300c3025334 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -84,6 +84,7 @@ struct thread_struct {
 	struct per_event per_event;	/* Cause of the last PER trap */
         /* pfault_wait is used to block the process on a pfault event */
 	unsigned long pfault_wait;
+	struct list_head list;
 };
 
 typedef struct thread_struct thread_struct;

commit 261cd298a8c363d7985e3482946edb4bfedacf98
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Feb 15 09:43:32 2011 +0100

    s390: remove task_show_regs
    
    task_show_regs used to be a debugging aid in the early bringup days
    of Linux on s390. /proc/<pid>/status is a world readable file, it
    is not a good idea to show the registers of a process. The only
    correct fix is to remove task_show_regs.
    
    Reported-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index bf3de04170a7..2c79b6416271 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -148,11 +148,6 @@ extern int kernel_thread(int (*fn)(void *), void * arg, unsigned long flags);
  */
 extern unsigned long thread_saved_pc(struct task_struct *t);
 
-/*
- * Print register of task into buffer. Used in fs/proc/array.c.
- */
-extern void task_show_regs(struct seq_file *m, struct task_struct *task);
-
 extern void show_code(struct pt_regs *regs);
 
 unsigned long get_wchan(struct task_struct *p);

commit 974de4d7e70a6d759457722a6f322cc86b480eea
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Wed Jan 5 12:48:16 2011 +0100

    [S390] smp: remove cpu hotplug messages
    
    Get rid of messages that indicate if a cpu went online or offline.
    There is nothing special about this anymore and these messages might
    flood the kernel log buffer which makes debugging harder since more
    important messages might be overwritten.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 1988807d415e..bf3de04170a7 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -32,7 +32,6 @@ static inline void get_cpu_id(struct cpuid *ptr)
 }
 
 extern void s390_adjust_jiffies(void);
-extern void print_cpu_info(void);
 extern int get_cpu_capability(unsigned int *);
 
 /*

commit 5e9a26928f550157563cfc06ce12c4ae121a02ec
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Wed Jan 5 12:48:10 2011 +0100

    [S390] ptrace cleanup
    
    Overhaul program event recording and the code dealing with the ptrace
    user space interface.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 8d6f87169577..1988807d415e 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -81,7 +81,8 @@ struct thread_struct {
 	mm_segment_t mm_segment;
         unsigned long prot_addr;        /* address of protection-excep.     */
         unsigned int trap_no;
-        per_struct per_info;
+	struct per_regs per_user;	/* User specified PER registers */
+	struct per_event per_event;	/* Cause of the last PER trap */
         /* pfault_wait is used to block the process on a pfault event */
 	unsigned long pfault_wait;
 };

commit ba6cadfebc18f786ef4e60e9ff03f9656ce3d584
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Mon Oct 25 16:10:41 2010 +0200

    [S390] remove ieee_instruction_pointer from thread_struct
    
    The ieee_instruction_pointer can not be read from user space anymore
    since git commit 613e1def6b52c399a8b72a5e11bc2e57d2546fb8, the ptrace
    interface always returns zero. Remove it from the thread_struct. It
    is still present in the user_regs_struct for compatability reasons.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 73e259834e10..8d6f87169577 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -82,8 +82,6 @@ struct thread_struct {
         unsigned long prot_addr;        /* address of protection-excep.     */
         unsigned int trap_no;
         per_struct per_info;
-	/* Used to give failing instruction back to user for ieee exceptions */
-	unsigned long ieee_instruction_pointer; 
         /* pfault_wait is used to block the process on a pfault event */
 	unsigned long pfault_wait;
 };

commit 987bcdacb18a3adc2a48d85c9b005069c2f4dd7b
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Fri Feb 26 22:37:31 2010 +0100

    [S390] use inline assembly contraints available with gcc 3.3.3
    
    Drop support to compile the kernel with gcc versions older than 3.3.3.
    This allows us to use the "Q" inline assembly contraint on some more
    inline assemblies without duplicating a lot of complex code (e.g. __xchg
    and __cmpxchg). The distinction for older gcc versions can be removed
    which saves a few lines and simplifies the code.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index b42715458312..73e259834e10 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -28,7 +28,7 @@
 
 static inline void get_cpu_id(struct cpuid *ptr)
 {
-	asm volatile("stidp 0(%1)" : "=m" (*ptr) : "a" (ptr));
+	asm volatile("stidp %0" : "=Q" (*ptr));
 }
 
 extern void s390_adjust_jiffies(void);
@@ -184,9 +184,9 @@ static inline void psw_set_key(unsigned int key)
 static inline void __load_psw(psw_t psw)
 {
 #ifndef __s390x__
-	asm volatile("lpsw  0(%0)" : : "a" (&psw), "m" (psw) : "cc");
+	asm volatile("lpsw  %0" : : "Q" (psw) : "cc");
 #else
-	asm volatile("lpswe 0(%0)" : : "a" (&psw), "m" (psw) : "cc");
+	asm volatile("lpswe %0" : : "Q" (psw) : "cc");
 #endif
 }
 
@@ -206,17 +206,17 @@ static inline void __load_psw_mask (unsigned long mask)
 	asm volatile(
 		"	basr	%0,0\n"
 		"0:	ahi	%0,1f-0b\n"
-		"	st	%0,4(%1)\n"
-		"	lpsw	0(%1)\n"
+		"	st	%0,%O1+4(%R1)\n"
+		"	lpsw	%1\n"
 		"1:"
-		: "=&d" (addr) : "a" (&psw), "m" (psw) : "memory", "cc");
+		: "=&d" (addr), "=Q" (psw) : "Q" (psw) : "memory", "cc");
 #else /* __s390x__ */
 	asm volatile(
 		"	larl	%0,1f\n"
-		"	stg	%0,8(%1)\n"
-		"	lpswe	0(%1)\n"
+		"	stg	%0,%O1+8(%R1)\n"
+		"	lpswe	%1\n"
 		"1:"
-		: "=&d" (addr) : "a" (&psw), "m" (psw) : "memory", "cc");
+		: "=&d" (addr), "=Q" (psw) : "Q" (psw) : "memory", "cc");
 #endif /* __s390x__ */
 }
  

commit bdd42b28cde0453fb8c3d9b4e4868ca2d8124806
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Tue Sep 22 22:58:47 2009 +0200

    [S390] fix disabled_wait inline assembly clobber list
    
    The disabled_wait inline assmembly also clobbers register r1, but it
    is missing in the clobber list.
    Fixes recursive Oops on panic.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index cf8eed3fa779..b42715458312 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -295,7 +295,7 @@ static inline void ATTRIB_NORET disabled_wait(unsigned long code)
 		"	oi	0x384(1),0x10\n"/* fake protection bit */
 		"	lpswe	0(%1)"
 		: "=m" (ctl_buf)
-		: "a" (&dw_psw), "a" (&ctl_buf), "m" (dw_psw) : "cc", "0");
+		: "a" (&dw_psw), "a" (&ctl_buf), "m" (dw_psw) : "cc", "0", "1");
 #endif /* __s390x__ */
 	while (1);
 }

commit e86a6ed63f46fe8fb555fda531084bca3ef62fd7
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Fri Sep 11 10:29:04 2009 +0200

    [S390] Get rid of cpuid.h header file.
    
    Merge cpuid.h header file into cpu.h.
    While at it convert from typedef to struct declaration and also
    convert cio code to use proper lowcore structure instead of casts.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index c139fa7b8e89..cf8eed3fa779 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -14,7 +14,7 @@
 #define __ASM_S390_PROCESSOR_H
 
 #include <linux/linkage.h>
-#include <asm/cpuid.h>
+#include <asm/cpu.h>
 #include <asm/page.h>
 #include <asm/ptrace.h>
 #include <asm/setup.h>
@@ -26,7 +26,7 @@
  */
 #define current_text_addr() ({ void *pc; asm("basr %0,0" : "=a" (pc)); pc; })
 
-static inline void get_cpu_id(cpuid_t *ptr)
+static inline void get_cpu_id(struct cpuid *ptr)
 {
 	asm volatile("stidp 0(%1)" : "=m" (*ptr) : "a" (ptr));
 }

commit 25097bf153391f7be4c591d47061b3dc4990dac2
Author: Christian Ehrhardt <ehrhardt@linux.vnet.ibm.com>
Date:   Tue Apr 14 15:36:16 2009 +0200

    [S390] s390: move machine flags to lowcore
    
    Currently the storage of the machine flags is a globally exported unsigned
    long long variable. By moving the storage location into the lowcore struct we
    allow assembler code to check machine_flags directly even without needing a
    register. Addtionally the lowcore and therefore the machine flags too will be
    in cache most of the time.
    
    Signed-off-by: Christian Ehrhardt <ehrhardt@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 61862b3ac794..c139fa7b8e89 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -14,7 +14,10 @@
 #define __ASM_S390_PROCESSOR_H
 
 #include <linux/linkage.h>
+#include <asm/cpuid.h>
+#include <asm/page.h>
 #include <asm/ptrace.h>
+#include <asm/setup.h>
 
 #ifdef __KERNEL__
 /*
@@ -23,20 +26,6 @@
  */
 #define current_text_addr() ({ void *pc; asm("basr %0,0" : "=a" (pc)); pc; })
 
-/*
- *  CPU type and hardware bug flags. Kept separately for each CPU.
- *  Members of this structure are referenced in head.S, so think twice
- *  before touching them. [mj]
- */
-
-typedef struct
-{
-        unsigned int version :  8;
-        unsigned int ident   : 24;
-        unsigned int machine : 16;
-        unsigned int unused  : 16;
-} __attribute__ ((packed)) cpuid_t;
-
 static inline void get_cpu_id(cpuid_t *ptr)
 {
 	asm volatile("stidp 0(%1)" : "=m" (*ptr) : "a" (ptr));

commit 7b4684880dfc6c45bc56039ca5eada771d7643ab
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Thu Mar 26 15:24:42 2009 +0100

    [S390] eliminate cpuinfo_S390 structure
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index db4523fe38ac..61862b3ac794 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -42,22 +42,8 @@ static inline void get_cpu_id(cpuid_t *ptr)
 	asm volatile("stidp 0(%1)" : "=m" (*ptr) : "a" (ptr));
 }
 
-struct cpuinfo_S390
-{
-        cpuid_t  cpu_id;
-        __u16    cpu_addr;
-        __u16    cpu_nr;
-        unsigned long loops_per_jiffy;
-        unsigned long *pgd_quick;
-#ifdef __s390x__
-        unsigned long *pmd_quick;
-#endif /* __s390x__ */
-        unsigned long *pte_quick;
-        unsigned long pgtable_cache_sz;
-};
-
 extern void s390_adjust_jiffies(void);
-extern void print_cpu_info(struct cpuinfo_S390 *);
+extern void print_cpu_info(void);
 extern int get_cpu_capability(unsigned int *);
 
 /*

commit f481bfafd36e621d6cbc62d4b25f74811410aef7
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Wed Mar 18 13:27:36 2009 +0100

    [S390] make page table walking more robust
    
    Make page table walking on s390 more robust. The current code requires
    that the pgd/pud/pmd/pte loop is only done for address ranges that are
    below the end address of the last vma of the address space. But this
    is not always true, e.g. the generic page table walker does not guarantee
    this. Change TASK_SIZE/TASK_SIZE_OF to reflect the current size of the
    address space. This makes the generic page table walker happy but it
    breaks the upgrade of a 3 level page table to a 4 level page table.
    To make the upgrade work again another fix is required.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 066b99502e09..db4523fe38ac 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -61,7 +61,7 @@ extern void print_cpu_info(struct cpuinfo_S390 *);
 extern int get_cpu_capability(unsigned int *);
 
 /*
- * User space process size: 2GB for 31 bit, 4TB for 64 bit.
+ * User space process size: 2GB for 31 bit, 4TB or 8PT for 64 bit.
  */
 #ifndef __s390x__
 
@@ -70,8 +70,7 @@ extern int get_cpu_capability(unsigned int *);
 
 #else /* __s390x__ */
 
-#define TASK_SIZE_OF(tsk)	(test_tsk_thread_flag(tsk,TIF_31BIT) ? \
-					(1UL << 31) : (1UL << 53))
+#define TASK_SIZE_OF(tsk)	((tsk)->mm->context.asce_limit)
 #define TASK_UNMAPPED_BASE	(test_thread_flag(TIF_31BIT) ? \
 					(1UL << 30) : (1UL << 41))
 #define TASK_SIZE		TASK_SIZE_OF(current)

commit edd5378740fe7717b1377ee04e593cfad8d29650
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Thu Dec 25 13:39:16 2008 +0100

    [S390] mark disabled_wait as noreturn function
    
    disabled_wait() won't return, so add an __attribute__((noreturn)).
    This will remove a false positive finding which our internal code
    checker reports.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
index 4af80af2a88f..066b99502e09 100644
--- a/arch/s390/include/asm/processor.h
+++ b/arch/s390/include/asm/processor.h
@@ -13,6 +13,7 @@
 #ifndef __ASM_S390_PROCESSOR_H
 #define __ASM_S390_PROCESSOR_H
 
+#include <linux/linkage.h>
 #include <asm/ptrace.h>
 
 #ifdef __KERNEL__
@@ -258,7 +259,7 @@ static inline void enabled_wait(void)
  * Function to drop a processor into disabled wait state
  */
 
-static inline void disabled_wait(unsigned long code)
+static inline void ATTRIB_NORET disabled_wait(unsigned long code)
 {
         unsigned long ctl_buf;
         psw_t dw_psw;
@@ -322,6 +323,7 @@ static inline void disabled_wait(unsigned long code)
 		: "=m" (ctl_buf)
 		: "a" (&dw_psw), "a" (&ctl_buf), "m" (dw_psw) : "cc", "0");
 #endif /* __s390x__ */
+	while (1);
 }
 
 /*

commit c6557e7f2b6ae76a44653d38f835174074c42e05
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Fri Aug 1 20:42:05 2008 +0200

    [S390] move include/asm-s390 to arch/s390/include/asm
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/processor.h b/arch/s390/include/asm/processor.h
new file mode 100644
index 000000000000..4af80af2a88f
--- /dev/null
+++ b/arch/s390/include/asm/processor.h
@@ -0,0 +1,360 @@
+/*
+ *  include/asm-s390/processor.h
+ *
+ *  S390 version
+ *    Copyright (C) 1999 IBM Deutschland Entwicklung GmbH, IBM Corporation
+ *    Author(s): Hartmut Penner (hp@de.ibm.com),
+ *               Martin Schwidefsky (schwidefsky@de.ibm.com)
+ *
+ *  Derived from "include/asm-i386/processor.h"
+ *    Copyright (C) 1994, Linus Torvalds
+ */
+
+#ifndef __ASM_S390_PROCESSOR_H
+#define __ASM_S390_PROCESSOR_H
+
+#include <asm/ptrace.h>
+
+#ifdef __KERNEL__
+/*
+ * Default implementation of macro that returns current
+ * instruction pointer ("program counter").
+ */
+#define current_text_addr() ({ void *pc; asm("basr %0,0" : "=a" (pc)); pc; })
+
+/*
+ *  CPU type and hardware bug flags. Kept separately for each CPU.
+ *  Members of this structure are referenced in head.S, so think twice
+ *  before touching them. [mj]
+ */
+
+typedef struct
+{
+        unsigned int version :  8;
+        unsigned int ident   : 24;
+        unsigned int machine : 16;
+        unsigned int unused  : 16;
+} __attribute__ ((packed)) cpuid_t;
+
+static inline void get_cpu_id(cpuid_t *ptr)
+{
+	asm volatile("stidp 0(%1)" : "=m" (*ptr) : "a" (ptr));
+}
+
+struct cpuinfo_S390
+{
+        cpuid_t  cpu_id;
+        __u16    cpu_addr;
+        __u16    cpu_nr;
+        unsigned long loops_per_jiffy;
+        unsigned long *pgd_quick;
+#ifdef __s390x__
+        unsigned long *pmd_quick;
+#endif /* __s390x__ */
+        unsigned long *pte_quick;
+        unsigned long pgtable_cache_sz;
+};
+
+extern void s390_adjust_jiffies(void);
+extern void print_cpu_info(struct cpuinfo_S390 *);
+extern int get_cpu_capability(unsigned int *);
+
+/*
+ * User space process size: 2GB for 31 bit, 4TB for 64 bit.
+ */
+#ifndef __s390x__
+
+#define TASK_SIZE		(1UL << 31)
+#define TASK_UNMAPPED_BASE	(1UL << 30)
+
+#else /* __s390x__ */
+
+#define TASK_SIZE_OF(tsk)	(test_tsk_thread_flag(tsk,TIF_31BIT) ? \
+					(1UL << 31) : (1UL << 53))
+#define TASK_UNMAPPED_BASE	(test_thread_flag(TIF_31BIT) ? \
+					(1UL << 30) : (1UL << 41))
+#define TASK_SIZE		TASK_SIZE_OF(current)
+
+#endif /* __s390x__ */
+
+#ifdef __KERNEL__
+
+#ifndef __s390x__
+#define STACK_TOP		(1UL << 31)
+#define STACK_TOP_MAX		(1UL << 31)
+#else /* __s390x__ */
+#define STACK_TOP		(1UL << (test_thread_flag(TIF_31BIT) ? 31:42))
+#define STACK_TOP_MAX		(1UL << 42)
+#endif /* __s390x__ */
+
+
+#endif
+
+#define HAVE_ARCH_PICK_MMAP_LAYOUT
+
+typedef struct {
+        __u32 ar4;
+} mm_segment_t;
+
+/*
+ * Thread structure
+ */
+struct thread_struct {
+	s390_fp_regs fp_regs;
+	unsigned int  acrs[NUM_ACRS];
+        unsigned long ksp;              /* kernel stack pointer             */
+	mm_segment_t mm_segment;
+        unsigned long prot_addr;        /* address of protection-excep.     */
+        unsigned int trap_no;
+        per_struct per_info;
+	/* Used to give failing instruction back to user for ieee exceptions */
+	unsigned long ieee_instruction_pointer; 
+        /* pfault_wait is used to block the process on a pfault event */
+	unsigned long pfault_wait;
+};
+
+typedef struct thread_struct thread_struct;
+
+/*
+ * Stack layout of a C stack frame.
+ */
+#ifndef __PACK_STACK
+struct stack_frame {
+	unsigned long back_chain;
+	unsigned long empty1[5];
+	unsigned long gprs[10];
+	unsigned int  empty2[8];
+};
+#else
+struct stack_frame {
+	unsigned long empty1[5];
+	unsigned int  empty2[8];
+	unsigned long gprs[10];
+	unsigned long back_chain;
+};
+#endif
+
+#define ARCH_MIN_TASKALIGN	8
+
+#define INIT_THREAD {							\
+	.ksp = sizeof(init_stack) + (unsigned long) &init_stack,	\
+}
+
+/*
+ * Do necessary setup to start up a new thread.
+ */
+#define start_thread(regs, new_psw, new_stackp) do {		\
+	set_fs(USER_DS);					\
+	regs->psw.mask	= psw_user_bits;			\
+	regs->psw.addr	= new_psw | PSW_ADDR_AMODE;		\
+	regs->gprs[15]	= new_stackp;				\
+} while (0)
+
+#define start_thread31(regs, new_psw, new_stackp) do {		\
+	set_fs(USER_DS);					\
+	regs->psw.mask	= psw_user32_bits;			\
+	regs->psw.addr	= new_psw | PSW_ADDR_AMODE;		\
+	regs->gprs[15]	= new_stackp;				\
+	crst_table_downgrade(current->mm, 1UL << 31);		\
+} while (0)
+
+/* Forward declaration, a strange C thing */
+struct task_struct;
+struct mm_struct;
+struct seq_file;
+
+/* Free all resources held by a thread. */
+extern void release_thread(struct task_struct *);
+extern int kernel_thread(int (*fn)(void *), void * arg, unsigned long flags);
+
+/* Prepare to copy thread state - unlazy all lazy status */
+#define prepare_to_copy(tsk)	do { } while (0)
+
+/*
+ * Return saved PC of a blocked thread.
+ */
+extern unsigned long thread_saved_pc(struct task_struct *t);
+
+/*
+ * Print register of task into buffer. Used in fs/proc/array.c.
+ */
+extern void task_show_regs(struct seq_file *m, struct task_struct *task);
+
+extern void show_code(struct pt_regs *regs);
+
+unsigned long get_wchan(struct task_struct *p);
+#define task_pt_regs(tsk) ((struct pt_regs *) \
+        (task_stack_page(tsk) + THREAD_SIZE) - 1)
+#define KSTK_EIP(tsk)	(task_pt_regs(tsk)->psw.addr)
+#define KSTK_ESP(tsk)	(task_pt_regs(tsk)->gprs[15])
+
+/*
+ * Give up the time slice of the virtual PU.
+ */
+static inline void cpu_relax(void)
+{
+	if (MACHINE_HAS_DIAG44)
+		asm volatile("diag 0,0,68");
+	barrier();
+}
+
+static inline void psw_set_key(unsigned int key)
+{
+	asm volatile("spka 0(%0)" : : "d" (key));
+}
+
+/*
+ * Set PSW to specified value.
+ */
+static inline void __load_psw(psw_t psw)
+{
+#ifndef __s390x__
+	asm volatile("lpsw  0(%0)" : : "a" (&psw), "m" (psw) : "cc");
+#else
+	asm volatile("lpswe 0(%0)" : : "a" (&psw), "m" (psw) : "cc");
+#endif
+}
+
+/*
+ * Set PSW mask to specified value, while leaving the
+ * PSW addr pointing to the next instruction.
+ */
+
+static inline void __load_psw_mask (unsigned long mask)
+{
+	unsigned long addr;
+	psw_t psw;
+
+	psw.mask = mask;
+
+#ifndef __s390x__
+	asm volatile(
+		"	basr	%0,0\n"
+		"0:	ahi	%0,1f-0b\n"
+		"	st	%0,4(%1)\n"
+		"	lpsw	0(%1)\n"
+		"1:"
+		: "=&d" (addr) : "a" (&psw), "m" (psw) : "memory", "cc");
+#else /* __s390x__ */
+	asm volatile(
+		"	larl	%0,1f\n"
+		"	stg	%0,8(%1)\n"
+		"	lpswe	0(%1)\n"
+		"1:"
+		: "=&d" (addr) : "a" (&psw), "m" (psw) : "memory", "cc");
+#endif /* __s390x__ */
+}
+ 
+/*
+ * Function to stop a processor until an interruption occurred
+ */
+static inline void enabled_wait(void)
+{
+	__load_psw_mask(PSW_BASE_BITS | PSW_MASK_IO | PSW_MASK_EXT |
+			PSW_MASK_MCHECK | PSW_MASK_WAIT | PSW_DEFAULT_KEY);
+}
+
+/*
+ * Function to drop a processor into disabled wait state
+ */
+
+static inline void disabled_wait(unsigned long code)
+{
+        unsigned long ctl_buf;
+        psw_t dw_psw;
+
+        dw_psw.mask = PSW_BASE_BITS | PSW_MASK_WAIT;
+        dw_psw.addr = code;
+        /* 
+         * Store status and then load disabled wait psw,
+         * the processor is dead afterwards
+         */
+#ifndef __s390x__
+	asm volatile(
+		"	stctl	0,0,0(%2)\n"
+		"	ni	0(%2),0xef\n"	/* switch off protection */
+		"	lctl	0,0,0(%2)\n"
+		"	stpt	0xd8\n"		/* store timer */
+		"	stckc	0xe0\n"		/* store clock comparator */
+		"	stpx	0x108\n"	/* store prefix register */
+		"	stam	0,15,0x120\n"	/* store access registers */
+		"	std	0,0x160\n"	/* store f0 */
+		"	std	2,0x168\n"	/* store f2 */
+		"	std	4,0x170\n"	/* store f4 */
+		"	std	6,0x178\n"	/* store f6 */
+		"	stm	0,15,0x180\n"	/* store general registers */
+		"	stctl	0,15,0x1c0\n"	/* store control registers */
+		"	oi	0x1c0,0x10\n"	/* fake protection bit */
+		"	lpsw	0(%1)"
+		: "=m" (ctl_buf)
+		: "a" (&dw_psw), "a" (&ctl_buf), "m" (dw_psw) : "cc");
+#else /* __s390x__ */
+	asm volatile(
+		"	stctg	0,0,0(%2)\n"
+		"	ni	4(%2),0xef\n"	/* switch off protection */
+		"	lctlg	0,0,0(%2)\n"
+		"	lghi	1,0x1000\n"
+		"	stpt	0x328(1)\n"	/* store timer */
+		"	stckc	0x330(1)\n"	/* store clock comparator */
+		"	stpx	0x318(1)\n"	/* store prefix register */
+		"	stam	0,15,0x340(1)\n"/* store access registers */
+		"	stfpc	0x31c(1)\n"	/* store fpu control */
+		"	std	0,0x200(1)\n"	/* store f0 */
+		"	std	1,0x208(1)\n"	/* store f1 */
+		"	std	2,0x210(1)\n"	/* store f2 */
+		"	std	3,0x218(1)\n"	/* store f3 */
+		"	std	4,0x220(1)\n"	/* store f4 */
+		"	std	5,0x228(1)\n"	/* store f5 */
+		"	std	6,0x230(1)\n"	/* store f6 */
+		"	std	7,0x238(1)\n"	/* store f7 */
+		"	std	8,0x240(1)\n"	/* store f8 */
+		"	std	9,0x248(1)\n"	/* store f9 */
+		"	std	10,0x250(1)\n"	/* store f10 */
+		"	std	11,0x258(1)\n"	/* store f11 */
+		"	std	12,0x260(1)\n"	/* store f12 */
+		"	std	13,0x268(1)\n"	/* store f13 */
+		"	std	14,0x270(1)\n"	/* store f14 */
+		"	std	15,0x278(1)\n"	/* store f15 */
+		"	stmg	0,15,0x280(1)\n"/* store general registers */
+		"	stctg	0,15,0x380(1)\n"/* store control registers */
+		"	oi	0x384(1),0x10\n"/* fake protection bit */
+		"	lpswe	0(%1)"
+		: "=m" (ctl_buf)
+		: "a" (&dw_psw), "a" (&ctl_buf), "m" (dw_psw) : "cc", "0");
+#endif /* __s390x__ */
+}
+
+/*
+ * Basic Machine Check/Program Check Handler.
+ */
+
+extern void s390_base_mcck_handler(void);
+extern void s390_base_pgm_handler(void);
+extern void s390_base_ext_handler(void);
+
+extern void (*s390_base_mcck_handler_fn)(void);
+extern void (*s390_base_pgm_handler_fn)(void);
+extern void (*s390_base_ext_handler_fn)(void);
+
+#define ARCH_LOW_ADDRESS_LIMIT	0x7fffffffUL
+
+#endif
+
+/*
+ * Helper macro for exception table entries
+ */
+#ifndef __s390x__
+#define EX_TABLE(_fault,_target)			\
+	".section __ex_table,\"a\"\n"			\
+	"	.align 4\n"				\
+	"	.long  " #_fault "," #_target "\n"	\
+	".previous\n"
+#else
+#define EX_TABLE(_fault,_target)			\
+	".section __ex_table,\"a\"\n"			\
+	"	.align 8\n"				\
+	"	.quad  " #_fault "," #_target "\n"	\
+	".previous\n"
+#endif
+
+#endif                                 /* __ASM_S390_PROCESSOR_H           */
