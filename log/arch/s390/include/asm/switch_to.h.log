commit fbbd7f1a51965b50dd12924841da0d478f3da71b
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Mon Nov 20 12:38:44 2017 +0100

    s390: always save and restore all registers on context switch
    
    The switch_to() macro has an optimization to avoid saving and
    restoring register contents that aren't needed for kernel threads.
    
    There is however the possibility that a kernel thread execve's a user
    space program. In such a case the execve'd process can partially see
    the contents of the previous process, which shouldn't be allowed.
    
    To avoid this, simply always save and restore register contents on
    context switch.
    
    Cc: <stable@vger.kernel.org> # v2.6.37+
    Fixes: fdb6d070effba ("switch_to: dont restore/save access & fpu regs for kernel threads")
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index ec7b476c1ac5..c61b2cc1a8a8 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -30,21 +30,20 @@ static inline void restore_access_regs(unsigned int *acrs)
 	asm volatile("lam 0,15,%0" : : "Q" (*(acrstype *)acrs));
 }
 
-#define switch_to(prev,next,last) do {					\
-	if (prev->mm) {							\
-		save_fpu_regs();					\
-		save_access_regs(&prev->thread.acrs[0]);		\
-		save_ri_cb(prev->thread.ri_cb);				\
-		save_gs_cb(prev->thread.gs_cb);				\
-	}								\
+#define switch_to(prev, next, last) do {				\
+	/* save_fpu_regs() sets the CIF_FPU flag, which enforces	\
+	 * a restore of the floating point / vector registers as	\
+	 * soon as the next task returns to user space			\
+	 */								\
+	save_fpu_regs();						\
+	save_access_regs(&prev->thread.acrs[0]);			\
+	save_ri_cb(prev->thread.ri_cb);					\
+	save_gs_cb(prev->thread.gs_cb);					\
 	update_cr_regs(next);						\
-	if (next->mm) {							\
-		set_cpu_flag(CIF_FPU);					\
-		restore_access_regs(&next->thread.acrs[0]);		\
-		restore_ri_cb(next->thread.ri_cb, prev->thread.ri_cb);	\
-		restore_gs_cb(next->thread.gs_cb);			\
-	}								\
-	prev = __switch_to(prev,next);					\
+	restore_access_regs(&next->thread.acrs[0]);			\
+	restore_ri_cb(next->thread.ri_cb, prev->thread.ri_cb);		\
+	restore_gs_cb(next->thread.gs_cb);				\
+	prev = __switch_to(prev, next);					\
 } while (0)
 
 #endif /* __ASM_SWITCH_TO_H */

commit d60a540ac5f2fbab3e6fe592717b445bd7343a91
Merge: 2101dd64b304 364a5607d698
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 13 11:47:01 2017 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux
    
    Pull s390 updates from Heiko Carstens:
     "Since Martin is on vacation you get the s390 pull request for the
      v4.15 merge window this time from me.
    
      Besides a lot of cleanups and bug fixes these are the most important
      changes:
    
       - a new regset for runtime instrumentation registers
    
       - hardware accelerated AES-GCM support for the aes_s390 module
    
       - support for the new CEX6S crypto cards
    
       - support for FORTIFY_SOURCE
    
       - addition of missing z13 and new z14 instructions to the in-kernel
         disassembler
    
       - generate opcode tables for the in-kernel disassembler out of a
         simple text file instead of having to manually maintain those
         tables
    
       - fast memset16, memset32 and memset64 implementations
    
       - removal of named saved segment support
    
       - hardware counter support for z14
    
       - queued spinlocks and queued rwlocks implementations for s390
    
       - use the stack_depth tracking feature for s390 BPF JIT
    
       - a new s390_sthyi system call which emulates the sthyi (store
         hypervisor information) instruction
    
       - removal of the old KVM virtio transport
    
       - an s390 specific CPU alternatives implementation which is used in
         the new spinlock code"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux: (88 commits)
      MAINTAINERS: add virtio-ccw.h to virtio/s390 section
      s390/noexec: execute kexec datamover without DAT
      s390: fix transactional execution control register handling
      s390/bpf: take advantage of stack_depth tracking
      s390: simplify transactional execution elf hwcap handling
      s390/zcrypt: Rework struct ap_qact_ap_info.
      s390/virtio: remove unused header file kvm_virtio.h
      s390: avoid undefined behaviour
      s390/disassembler: generate opcode tables from text file
      s390/disassembler: remove insn_to_mnemonic()
      s390/dasd: avoid calling do_gettimeofday()
      s390: vfio-ccw: Do not attempt to free no-op, test and tic cda.
      s390: remove named saved segment support
      s390/archrandom: Reconsider s390 arch random implementation
      s390/pci: do not require AIS facility
      s390/qdio: sanitize put_indicator
      s390/qdio: use atomic_cmpxchg
      s390/nmi: avoid using long-displacement facility
      s390: pass endianness info to sparse
      s390/decompressor: remove informational messages
      ...

commit a1c5befc1c24eb9c1ee83f711e0f21ee79cbb556
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Thu Nov 9 12:29:34 2017 +0100

    s390: fix transactional execution control register handling
    
    Dan Horák reported the following crash related to transactional execution:
    
    User process fault: interruption code 0013 ilc:3 in libpthread-2.26.so[3ff93c00000+1b000]
    CPU: 2 PID: 1 Comm: /init Not tainted 4.13.4-300.fc27.s390x #1
    Hardware name: IBM 2827 H43 400 (z/VM 6.4.0)
    task: 00000000fafc8000 task.stack: 00000000fafc4000
    User PSW : 0705200180000000 000003ff93c14e70
               R:0 T:1 IO:1 EX:1 Key:0 M:1 W:0 P:1 AS:0 CC:2 PM:0 RI:0 EA:3
    User GPRS: 0000000000000077 000003ff00000000 000003ff93144d48 000003ff93144d5e
               0000000000000000 0000000000000002 0000000000000000 000003ff00000000
               0000000000000000 0000000000000418 0000000000000000 000003ffcc9fe770
               000003ff93d28f50 000003ff9310acf0 000003ff92b0319a 000003ffcc9fe6d0
    User Code: 000003ff93c14e62: 60e0b030            std     %f14,48(%r11)
               000003ff93c14e66: 60f0b038            std     %f15,56(%r11)
              #000003ff93c14e6a: e5600000ff0e        tbegin  0,65294
              >000003ff93c14e70: a7740006            brc     7,3ff93c14e7c
               000003ff93c14e74: a7080000            lhi     %r0,0
               000003ff93c14e78: a7f40023            brc     15,3ff93c14ebe
               000003ff93c14e7c: b2220000            ipm     %r0
               000003ff93c14e80: 8800001c            srl     %r0,28
    
    There are several bugs with control register handling with respect to
    transactional execution:
    
    - on task switch update_per_regs() is only called if the next task has
      an mm (is not a kernel thread). This however is incorrect. This
      breaks e.g. for user mode helper handling, where the kernel creates
      a kernel thread and then execve's a user space program. Control
      register contents related to transactional execution won't be
      updated on execve. If the previous task ran with transactional
      execution disabled then the new task will also run with
      transactional execution disabled, which is incorrect. Therefore call
      update_per_regs() unconditionally within switch_to().
    
    - on startup the transactional execution facility is not enabled for
      the idle thread. This is not really a bug, but an inconsistency to
      other facilities. Therefore enable the facility if it is available.
    
    - on fork the new thread's per_flags field is not cleared. This means
      that a child process inherits the PER_FLAG_NO_TE flag. This flag can
      be set with a ptrace request to disable transactional execution for
      the current process. It should not be inherited by new child
      processes in order to be consistent with the handling of all other
      PER related debugging options. Therefore clear the per_flags field in
      copy_thread_tls().
    
    Reported-and-tested-by: Dan Horák <dan@danny.cz>
    Fixes: d35339a42dd1 ("s390: add support for transactional memory")
    Cc: <stable@vger.kernel.org> # v3.7+
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Reviewed-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Reviewed-by: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index f6c2b5814ab0..8e6b07609ff4 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -36,8 +36,8 @@ static inline void restore_access_regs(unsigned int *acrs)
 		save_ri_cb(prev->thread.ri_cb);				\
 		save_gs_cb(prev->thread.gs_cb);				\
 	}								\
+	update_cr_regs(next);						\
 	if (next->mm) {							\
-		update_cr_regs(next);					\
 		set_cpu_flag(CIF_FPU);					\
 		restore_access_regs(&next->thread.acrs[0]);		\
 		restore_ri_cb(next->thread.ri_cb, prev->thread.ri_cb);	\

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index f6c2b5814ab0..c21fe1d57c00 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  * Copyright IBM Corp. 1999, 2009
  *

commit 916cda1aa1b412d7cf2991c3af7479544942d121
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Jan 26 14:10:34 2016 +0100

    s390: add a system call for guarded storage
    
    This adds a new system call to enable the use of guarded storage for
    user space processes. The system call takes two arguments, a command
    and pointer to a guarded storage control block:
    
        s390_guarded_storage(int command, struct gs_cb *gs_cb);
    
    The second argument is relevant only for the GS_SET_BC_CB command.
    
    The commands in detail:
    
    0 - GS_ENABLE
        Enable the guarded storage facility for the current task. The
        initial content of the guarded storage control block will be
        all zeros. After the enablement the user space code can use
        load-guarded-storage-controls instruction (LGSC) to load an
        arbitrary control block. While a task is enabled the kernel
        will save and restore the current content of the guarded
        storage registers on context switch.
    1 - GS_DISABLE
        Disables the use of the guarded storage facility for the current
        task. The kernel will cease to save and restore the content of
        the guarded storage registers, the task specific content of
        these registers is lost.
    2 - GS_SET_BC_CB
        Set a broadcast guarded storage control block. This is called
        per thread and stores a specific guarded storage control block
        in the task struct of the current task. This control block will
        be used for the broadcast event GS_BROADCAST.
    3 - GS_CLEAR_BC_CB
        Clears the broadcast guarded storage control block. The guarded-
        storage control block is removed from the task struct that was
        established by GS_SET_BC_CB.
    4 - GS_BROADCAST
        Sends a broadcast to all thread siblings of the current task.
        Every sibling that has established a broadcast guarded storage
        control block will load this control block and will be enabled
        for guarded storage. The broadcast guarded storage control block
        is used up, a second broadcast without a refresh of the stored
        control block with GS_SET_BC_CB will not have any effect.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index 12d45f0cfdd9..f6c2b5814ab0 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -10,6 +10,7 @@
 #include <linux/thread_info.h>
 #include <asm/fpu/api.h>
 #include <asm/ptrace.h>
+#include <asm/guarded_storage.h>
 
 extern struct task_struct *__switch_to(void *, void *);
 extern void update_cr_regs(struct task_struct *task);
@@ -33,12 +34,14 @@ static inline void restore_access_regs(unsigned int *acrs)
 		save_fpu_regs();					\
 		save_access_regs(&prev->thread.acrs[0]);		\
 		save_ri_cb(prev->thread.ri_cb);				\
+		save_gs_cb(prev->thread.gs_cb);				\
 	}								\
 	if (next->mm) {							\
 		update_cr_regs(next);					\
 		set_cpu_flag(CIF_FPU);					\
 		restore_access_regs(&next->thread.acrs[0]);		\
 		restore_ri_cb(next->thread.ri_cb, prev->thread.ri_cb);	\
+		restore_gs_cb(next->thread.gs_cb);			\
 	}								\
 	prev = __switch_to(prev,next);					\
 } while (0)

commit b0753902d42f5cb01c33f0dec47ba2aa7ecfbb3f
Author: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
Date:   Tue Oct 6 12:25:59 2015 +0200

    s390/fpu: split fpu-internal.h into fpu internals, api, and type headers
    
    Split the API and FPU type definitions into separate header files
    similar to "x86/fpu: Rename fpu-internal.h to fpu/internal.h" (78f7f1e54b).
    
    The new header files and their meaning are:
    
    asm/fpu/types.h:
            FPU related data types, needed for 'struct thread_struct' and
            'struct task_struct'.
    
    asm/fpu/api.h:
            FPU related 'public' functions for other subsystems and device
            drivers.
    
    asm/fpu/internal.h:
            FPU internal functions mainly used to convert
            FPU register contents in signal handling.
    
    Signed-off-by: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index dcadfde32265..12d45f0cfdd9 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -8,7 +8,7 @@
 #define __ASM_SWITCH_TO_H
 
 #include <linux/thread_info.h>
-#include <asm/fpu-internal.h>
+#include <asm/fpu/api.h>
 #include <asm/ptrace.h>
 
 extern struct task_struct *__switch_to(void *, void *);

commit d0164ee20d98847d3c777a0ae90e678e7ac1e416
Author: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
Date:   Mon Jun 29 16:43:06 2015 +0200

    s390/kernel: remove save_fpu_regs() parameter and use __LC_CURRENT instead
    
    All calls to save_fpu_regs() specify the fpu structure of the current task
    pointer as parameter.  The task pointer of the current task can also be
    retrieved from the CPU lowcore directly.  Remove the parameter definition,
    load the __LC_CURRENT task pointer from the CPU lowcore, and rebase the FPU
    structure onto the task structure.  Apply the same approach for the
    load_fpu_regs() function.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index 0a4a3150b7d7..dcadfde32265 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -30,7 +30,7 @@ static inline void restore_access_regs(unsigned int *acrs)
 
 #define switch_to(prev,next,last) do {					\
 	if (prev->mm) {							\
-		save_fpu_regs(&prev->thread.fpu);			\
+		save_fpu_regs();					\
 		save_access_regs(&prev->thread.acrs[0]);		\
 		save_ri_cb(prev->thread.ri_cb);				\
 	}								\

commit 9977e886cbbc758b4b601a160b5825ba573b5ca8
Author: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
Date:   Wed Jun 10 12:53:42 2015 +0200

    s390/kernel: lazy restore fpu registers
    
    Improve the save and restore behavior of FPU register contents to use the
    vector extension within the kernel.
    
    The kernel does not use floating-point or vector registers and, therefore,
    saving and restoring the FPU register contents are performed for handling
    signals or switching processes only.  To prepare for using vector
    instructions and vector registers within the kernel, enhance the save
    behavior and implement a lazy restore at return to user space from a
    system call or interrupt.
    
    To implement the lazy restore, the save_fpu_regs() sets a CPU information
    flag, CIF_FPU, to indicate that the FPU registers must be restored.
    Saving and setting CIF_FPU is performed in an atomic fashion to be
    interrupt-safe.  When the kernel wants to use the vector extension or
    wants to change the FPU register state for a task during signal handling,
    the save_fpu_regs() must be called first.  The CIF_FPU flag is also set at
    process switch.  At return to user space, the FPU state is restored.  In
    particular, the FPU state includes the floating-point or vector register
    contents, as well as, vector-enablement and floating-point control.  The
    FPU state restore and clearing CIF_FPU is also performed in an atomic
    fashion.
    
    For KVM, the restore of the FPU register state is performed when restoring
    the general-purpose guest registers before the SIE instructions is started.
    Because the path towards the SIE instruction is interruptible, the CIF_FPU
    flag must be checked again right before going into SIE.  If set, the guest
    registers must be reloaded again by re-entering the outer SIE loop.  This
    is the same behavior as if the SIE critical section is interrupted.
    
    Signed-off-by: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index caf4f23462b0..0a4a3150b7d7 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -36,7 +36,7 @@ static inline void restore_access_regs(unsigned int *acrs)
 	}								\
 	if (next->mm) {							\
 		update_cr_regs(next);					\
-		restore_fpu_regs(&next->thread.fpu);			\
+		set_cpu_flag(CIF_FPU);					\
 		restore_access_regs(&next->thread.acrs[0]);		\
 		restore_ri_cb(next->thread.ri_cb, prev->thread.ri_cb);	\
 	}								\

commit 904818e2f229f3d94ec95f6932a6358c81e73d78
Author: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
Date:   Thu Jun 11 15:33:54 2015 +0200

    s390/kernel: introduce fpu-internal.h with fpu helper functions
    
    Introduce a new structure to manage FP and VX registers. Refactor the
    save and restore of floating point and vector registers with a set
    of helper functions in fpu-internal.h.
    
    Signed-off-by: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index b304031d9d11..caf4f23462b0 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -8,138 +8,12 @@
 #define __ASM_SWITCH_TO_H
 
 #include <linux/thread_info.h>
+#include <asm/fpu-internal.h>
 #include <asm/ptrace.h>
 
 extern struct task_struct *__switch_to(void *, void *);
 extern void update_cr_regs(struct task_struct *task);
 
-static inline int test_fp_ctl(u32 fpc)
-{
-	u32 orig_fpc;
-	int rc;
-
-	asm volatile(
-		"	efpc    %1\n"
-		"	sfpc	%2\n"
-		"0:	sfpc	%1\n"
-		"	la	%0,0\n"
-		"1:\n"
-		EX_TABLE(0b,1b)
-		: "=d" (rc), "=d" (orig_fpc)
-		: "d" (fpc), "0" (-EINVAL));
-	return rc;
-}
-
-static inline void save_fp_ctl(u32 *fpc)
-{
-	asm volatile(
-		"       stfpc   %0\n"
-		: "+Q" (*fpc));
-}
-
-static inline int restore_fp_ctl(u32 *fpc)
-{
-	int rc;
-
-	asm volatile(
-		"	lfpc    %1\n"
-		"0:	la	%0,0\n"
-		"1:\n"
-		: "=d" (rc) : "Q" (*fpc), "0" (-EINVAL));
-	return rc;
-}
-
-static inline void save_fp_regs(freg_t *fprs)
-{
-	asm volatile("std 0,%0" : "=Q" (fprs[0]));
-	asm volatile("std 2,%0" : "=Q" (fprs[2]));
-	asm volatile("std 4,%0" : "=Q" (fprs[4]));
-	asm volatile("std 6,%0" : "=Q" (fprs[6]));
-	asm volatile("std 1,%0" : "=Q" (fprs[1]));
-	asm volatile("std 3,%0" : "=Q" (fprs[3]));
-	asm volatile("std 5,%0" : "=Q" (fprs[5]));
-	asm volatile("std 7,%0" : "=Q" (fprs[7]));
-	asm volatile("std 8,%0" : "=Q" (fprs[8]));
-	asm volatile("std 9,%0" : "=Q" (fprs[9]));
-	asm volatile("std 10,%0" : "=Q" (fprs[10]));
-	asm volatile("std 11,%0" : "=Q" (fprs[11]));
-	asm volatile("std 12,%0" : "=Q" (fprs[12]));
-	asm volatile("std 13,%0" : "=Q" (fprs[13]));
-	asm volatile("std 14,%0" : "=Q" (fprs[14]));
-	asm volatile("std 15,%0" : "=Q" (fprs[15]));
-}
-
-static inline void restore_fp_regs(freg_t *fprs)
-{
-	asm volatile("ld 0,%0" : : "Q" (fprs[0]));
-	asm volatile("ld 2,%0" : : "Q" (fprs[2]));
-	asm volatile("ld 4,%0" : : "Q" (fprs[4]));
-	asm volatile("ld 6,%0" : : "Q" (fprs[6]));
-	asm volatile("ld 1,%0" : : "Q" (fprs[1]));
-	asm volatile("ld 3,%0" : : "Q" (fprs[3]));
-	asm volatile("ld 5,%0" : : "Q" (fprs[5]));
-	asm volatile("ld 7,%0" : : "Q" (fprs[7]));
-	asm volatile("ld 8,%0" : : "Q" (fprs[8]));
-	asm volatile("ld 9,%0" : : "Q" (fprs[9]));
-	asm volatile("ld 10,%0" : : "Q" (fprs[10]));
-	asm volatile("ld 11,%0" : : "Q" (fprs[11]));
-	asm volatile("ld 12,%0" : : "Q" (fprs[12]));
-	asm volatile("ld 13,%0" : : "Q" (fprs[13]));
-	asm volatile("ld 14,%0" : : "Q" (fprs[14]));
-	asm volatile("ld 15,%0" : : "Q" (fprs[15]));
-}
-
-static inline void save_vx_regs(__vector128 *vxrs)
-{
-	typedef struct { __vector128 _[__NUM_VXRS]; } addrtype;
-
-	asm volatile(
-		"	la	1,%0\n"
-		"	.word	0xe70f,0x1000,0x003e\n"	/* vstm 0,15,0(1) */
-		"	.word	0xe70f,0x1100,0x0c3e\n"	/* vstm 16,31,256(1) */
-		: "=Q" (*(addrtype *) vxrs) : : "1");
-}
-
-static inline void save_vx_regs_safe(__vector128 *vxrs)
-{
-	unsigned long cr0, flags;
-
-	flags = arch_local_irq_save();
-	__ctl_store(cr0, 0, 0);
-	__ctl_set_bit(0, 17);
-	__ctl_set_bit(0, 18);
-	save_vx_regs(vxrs);
-	__ctl_load(cr0, 0, 0);
-	arch_local_irq_restore(flags);
-}
-
-static inline void restore_vx_regs(__vector128 *vxrs)
-{
-	typedef struct { __vector128 _[__NUM_VXRS]; } addrtype;
-
-	asm volatile(
-		"	la	1,%0\n"
-		"	.word	0xe70f,0x1000,0x0036\n"	/* vlm 0,15,0(1) */
-		"	.word	0xe70f,0x1100,0x0c36\n"	/* vlm 16,31,256(1) */
-		: : "Q" (*(addrtype *) vxrs) : "1");
-}
-
-static inline void save_fp_vx_regs(struct task_struct *task)
-{
-	if (task->thread.vxrs)
-		save_vx_regs(task->thread.vxrs);
-	else
-		save_fp_regs(task->thread.fp_regs.fprs);
-}
-
-static inline void restore_fp_vx_regs(struct task_struct *task)
-{
-	if (task->thread.vxrs)
-		restore_vx_regs(task->thread.vxrs);
-	else
-		restore_fp_regs(task->thread.fp_regs.fprs);
-}
-
 static inline void save_access_regs(unsigned int *acrs)
 {
 	typedef struct { int _[NUM_ACRS]; } acrstype;
@@ -156,15 +30,13 @@ static inline void restore_access_regs(unsigned int *acrs)
 
 #define switch_to(prev,next,last) do {					\
 	if (prev->mm) {							\
-		save_fp_ctl(&prev->thread.fp_regs.fpc);			\
-		save_fp_vx_regs(prev);					\
+		save_fpu_regs(&prev->thread.fpu);			\
 		save_access_regs(&prev->thread.acrs[0]);		\
 		save_ri_cb(prev->thread.ri_cb);				\
 	}								\
 	if (next->mm) {							\
 		update_cr_regs(next);					\
-		restore_fp_ctl(&next->thread.fp_regs.fpc);		\
-		restore_fp_vx_regs(next);				\
+		restore_fpu_regs(&next->thread.fpu);			\
 		restore_access_regs(&next->thread.acrs[0]);		\
 		restore_ri_cb(next->thread.ri_cb, prev->thread.ri_cb);	\
 	}								\

commit 4084eb7767418861a81d9e24d222f2536537f58e
Author: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
Date:   Tue Apr 28 11:30:40 2015 +0200

    s390/kernel: use test_fp_ctl() to verify the floating-point control word
    
    Use the test_fp_ctl() to test the floating-point control word
    for validity and use restore_fp_ctl() to set it in load_sigregs.
    
    Signed-off-by: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index d62e7a69605f..b304031d9d11 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -45,7 +45,6 @@ static inline int restore_fp_ctl(u32 *fpc)
 		"	lfpc    %1\n"
 		"0:	la	%0,0\n"
 		"1:\n"
-		EX_TABLE(0b,1b)
 		: "=d" (rc) : "Q" (*fpc), "0" (-EINVAL));
 	return rc;
 }

commit 5a79859ae0f35d25c67a03e82bf0c80592f16a39
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Thu Feb 12 13:08:27 2015 +0100

    s390: remove 31 bit support
    
    Remove the 31 bit support in order to reduce maintenance cost and
    effectively remove dead code. Since a couple of years there is no
    distribution left that comes with a 31 bit kernel.
    
    The 31 bit kernel also has been broken since more than a year before
    anybody noticed. In addition I added a removal warning to the kernel
    shown at ipl for 5 minutes: a960062e5826 ("s390: add 31 bit warning
    message") which let everybody know about the plan to remove 31 bit
    code. We didn't get any response.
    
    Given that the last 31 bit only machine was introduced in 1999 let's
    remove the code.
    Anybody with 31 bit user space code can still use the compat mode.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index 2542a7e4c8b4..d62e7a69605f 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -18,9 +18,6 @@ static inline int test_fp_ctl(u32 fpc)
 	u32 orig_fpc;
 	int rc;
 
-	if (!MACHINE_HAS_IEEE)
-		return 0;
-
 	asm volatile(
 		"	efpc    %1\n"
 		"	sfpc	%2\n"
@@ -35,9 +32,6 @@ static inline int test_fp_ctl(u32 fpc)
 
 static inline void save_fp_ctl(u32 *fpc)
 {
-	if (!MACHINE_HAS_IEEE)
-		return;
-
 	asm volatile(
 		"       stfpc   %0\n"
 		: "+Q" (*fpc));
@@ -47,9 +41,6 @@ static inline int restore_fp_ctl(u32 *fpc)
 {
 	int rc;
 
-	if (!MACHINE_HAS_IEEE)
-		return 0;
-
 	asm volatile(
 		"	lfpc    %1\n"
 		"0:	la	%0,0\n"
@@ -65,8 +56,6 @@ static inline void save_fp_regs(freg_t *fprs)
 	asm volatile("std 2,%0" : "=Q" (fprs[2]));
 	asm volatile("std 4,%0" : "=Q" (fprs[4]));
 	asm volatile("std 6,%0" : "=Q" (fprs[6]));
-	if (!MACHINE_HAS_IEEE)
-		return;
 	asm volatile("std 1,%0" : "=Q" (fprs[1]));
 	asm volatile("std 3,%0" : "=Q" (fprs[3]));
 	asm volatile("std 5,%0" : "=Q" (fprs[5]));
@@ -87,8 +76,6 @@ static inline void restore_fp_regs(freg_t *fprs)
 	asm volatile("ld 2,%0" : : "Q" (fprs[2]));
 	asm volatile("ld 4,%0" : : "Q" (fprs[4]));
 	asm volatile("ld 6,%0" : : "Q" (fprs[6]));
-	if (!MACHINE_HAS_IEEE)
-		return;
 	asm volatile("ld 1,%0" : : "Q" (fprs[1]));
 	asm volatile("ld 3,%0" : : "Q" (fprs[3]));
 	asm volatile("ld 5,%0" : : "Q" (fprs[5]));
@@ -140,22 +127,18 @@ static inline void restore_vx_regs(__vector128 *vxrs)
 
 static inline void save_fp_vx_regs(struct task_struct *task)
 {
-#ifdef CONFIG_64BIT
 	if (task->thread.vxrs)
 		save_vx_regs(task->thread.vxrs);
 	else
-#endif
-	save_fp_regs(task->thread.fp_regs.fprs);
+		save_fp_regs(task->thread.fp_regs.fprs);
 }
 
 static inline void restore_fp_vx_regs(struct task_struct *task)
 {
-#ifdef CONFIG_64BIT
 	if (task->thread.vxrs)
 		restore_vx_regs(task->thread.vxrs);
 	else
-#endif
-	restore_fp_regs(task->thread.fp_regs.fprs);
+		restore_fp_regs(task->thread.fp_regs.fprs);
 }
 
 static inline void save_access_regs(unsigned int *acrs)

commit a62bc0739253939d6fce40d51d92412252a9bb55
Author: Michael Holzheu <holzheu@linux.vnet.ibm.com>
Date:   Mon Oct 6 17:57:43 2014 +0200

    s390/kdump: add support for vector extension
    
    With this patch for kdump the s390 vector registers are stored into the
    prepared save areas in the old kernel and into the REGSET_VX_LOW and
    REGSET_VX_HIGH ELF notes for /proc/vmcore in the new kernel.
    
    The NT_S390_VXRS_LOW note contains the lower halves of the first 16 vector
    registers 0-15. The higher halves are stored in the floating point register
    ELF note.  The NT_S390_VXRS_HIGH contains the full vector registers 16-31.
    
    The kernel provides a save area for storing vector register in case of
    machine checks. A pointer to this save are is stored in the CPU lowcore
    at offset 0x11b0. This save area is also used to save the registers for
    kdump. In case of a dumped crashed kdump those areas are used to extract
    the registers of the production system.
    
    The vector registers for remote CPUs are stored using the "store additional
    status at address" SIGP. For the dump CPU the vector registers are stored
    with the VSTM instruction.
    
    With this patch also zfcpdump stores the vector registers.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Michael Holzheu <holzheu@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index 0e0109578021..2542a7e4c8b4 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -114,6 +114,19 @@ static inline void save_vx_regs(__vector128 *vxrs)
 		: "=Q" (*(addrtype *) vxrs) : : "1");
 }
 
+static inline void save_vx_regs_safe(__vector128 *vxrs)
+{
+	unsigned long cr0, flags;
+
+	flags = arch_local_irq_save();
+	__ctl_store(cr0, 0, 0);
+	__ctl_set_bit(0, 17);
+	__ctl_set_bit(0, 18);
+	save_vx_regs(vxrs);
+	__ctl_load(cr0, 0, 0);
+	arch_local_irq_restore(flags);
+}
+
 static inline void restore_vx_regs(__vector128 *vxrs)
 {
 	typedef struct { __vector128 _[__NUM_VXRS]; } addrtype;

commit 8070361799ae1e3f4ef347bd10f0a508ac10acfb
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Mon Oct 6 17:53:53 2014 +0200

    s390: add support for vector extension
    
    The vector extension introduces 32 128-bit vector registers and a set of
    instruction to operate on the vector registers.
    
    The kernel can control the use of vector registers for the problem state
    program with a bit in control register 0. Once enabled for a process the
    kernel needs to retain the content of the vector registers on context
    switch. The signal frame is extended to include the vector registers.
    Two new register sets NT_S390_VXRS_LOW and NT_S390_VXRS_HIGH are added
    to the regset interface for the debugger and core dumps.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index 18ea9e3f8142..0e0109578021 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -103,6 +103,48 @@ static inline void restore_fp_regs(freg_t *fprs)
 	asm volatile("ld 15,%0" : : "Q" (fprs[15]));
 }
 
+static inline void save_vx_regs(__vector128 *vxrs)
+{
+	typedef struct { __vector128 _[__NUM_VXRS]; } addrtype;
+
+	asm volatile(
+		"	la	1,%0\n"
+		"	.word	0xe70f,0x1000,0x003e\n"	/* vstm 0,15,0(1) */
+		"	.word	0xe70f,0x1100,0x0c3e\n"	/* vstm 16,31,256(1) */
+		: "=Q" (*(addrtype *) vxrs) : : "1");
+}
+
+static inline void restore_vx_regs(__vector128 *vxrs)
+{
+	typedef struct { __vector128 _[__NUM_VXRS]; } addrtype;
+
+	asm volatile(
+		"	la	1,%0\n"
+		"	.word	0xe70f,0x1000,0x0036\n"	/* vlm 0,15,0(1) */
+		"	.word	0xe70f,0x1100,0x0c36\n"	/* vlm 16,31,256(1) */
+		: : "Q" (*(addrtype *) vxrs) : "1");
+}
+
+static inline void save_fp_vx_regs(struct task_struct *task)
+{
+#ifdef CONFIG_64BIT
+	if (task->thread.vxrs)
+		save_vx_regs(task->thread.vxrs);
+	else
+#endif
+	save_fp_regs(task->thread.fp_regs.fprs);
+}
+
+static inline void restore_fp_vx_regs(struct task_struct *task)
+{
+#ifdef CONFIG_64BIT
+	if (task->thread.vxrs)
+		restore_vx_regs(task->thread.vxrs);
+	else
+#endif
+	restore_fp_regs(task->thread.fp_regs.fprs);
+}
+
 static inline void save_access_regs(unsigned int *acrs)
 {
 	typedef struct { int _[NUM_ACRS]; } acrstype;
@@ -120,16 +162,16 @@ static inline void restore_access_regs(unsigned int *acrs)
 #define switch_to(prev,next,last) do {					\
 	if (prev->mm) {							\
 		save_fp_ctl(&prev->thread.fp_regs.fpc);			\
-		save_fp_regs(prev->thread.fp_regs.fprs);		\
+		save_fp_vx_regs(prev);					\
 		save_access_regs(&prev->thread.acrs[0]);		\
 		save_ri_cb(prev->thread.ri_cb);				\
 	}								\
 	if (next->mm) {							\
+		update_cr_regs(next);					\
 		restore_fp_ctl(&next->thread.fp_regs.fpc);		\
-		restore_fp_regs(next->thread.fp_regs.fprs);		\
+		restore_fp_vx_regs(next);				\
 		restore_access_regs(&next->thread.acrs[0]);		\
 		restore_ri_cb(next->thread.ri_cb, prev->thread.ri_cb);	\
-		update_cr_regs(next);					\
 	}								\
 	prev = __switch_to(prev,next);					\
 } while (0)

commit 9f86745722d95bc7f855069bd82285bd10dc97ff
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Jul 15 10:41:37 2014 +0200

    s390: fix restore of invalid floating-point-control
    
    The fixup of the inline assembly to restore the floating-point-control
    register needs to check for instruction address *after* the lfcp
    instruction as the specification and data exceptions are suppresssing.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index df38c70cd59e..18ea9e3f8142 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -51,8 +51,8 @@ static inline int restore_fp_ctl(u32 *fpc)
 		return 0;
 
 	asm volatile(
-		"0:	lfpc    %1\n"
-		"	la	%0,0\n"
+		"	lfpc    %1\n"
+		"0:	la	%0,0\n"
 		"1:\n"
 		EX_TABLE(0b,1b)
 		: "=d" (rc) : "Q" (*fpc), "0" (-EINVAL));

commit f8b13505607823bb9a212eb9410669ecf2bc2615
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Mon Jun 2 14:53:57 2014 +0200

    s390/uaccess: always load the kernel ASCE after task switch
    
    This patch fixes a problem introduced with git commit beef560b4cdfafb2
    "s390/uaccess: simplify control register updates".
    
    The switch_mm function is not called if the next process is a kernel
    thread without an attached mm or is a nop if the mm does not change.
    But CR1 still needs to be loaded with the kernel ASCE in case the
    code returns to a uaccess function that uses the secondary space mode.
    
    In addition move the set_fs call from finish_arch_switch to
    finish_arch_post_lock_switch and then remove finish_arch_switch.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index 29c81f82705e..df38c70cd59e 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -134,8 +134,4 @@ static inline void restore_access_regs(unsigned int *acrs)
 	prev = __switch_to(prev,next);					\
 } while (0)
 
-#define finish_arch_switch(prev) do {					     \
-	set_fs(current->thread.mm_segment);				     \
-} while (0)
-
 #endif /* __ASM_SWITCH_TO_H */

commit beef560b4cdfafb2211a856e1d722540f5151933
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Mon Apr 14 15:11:26 2014 +0200

    s390/uaccess: simplify control register updates
    
    Always switch to the kernel ASCE in switch_mm. Load the secondary
    space ASCE in finish_arch_post_lock_switch after checking that
    any pending page table operations have completed. The primary
    ASCE is loaded in entry[64].S. With this the update_primary_asce
    call can be removed from the switch_to macro and from the start
    of switch_mm function. Remove the load_primary argument from
    update_user_asce/clear_user_asce, rename update_user_asce to
    set_user_asce and rename update_primary_asce to load_kernel_asce.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index e759181357fc..29c81f82705e 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -132,7 +132,6 @@ static inline void restore_access_regs(unsigned int *acrs)
 		update_cr_regs(next);					\
 	}								\
 	prev = __switch_to(prev,next);					\
-	update_primary_asce(current);					\
 } while (0)
 
 #define finish_arch_switch(prev) do {					     \

commit 457f2180951cdcbfb4657ddcc83b486e93497f56
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Fri Mar 21 10:42:25 2014 +0100

    s390/uaccess: rework uaccess code - fix locking issues
    
    The current uaccess code uses a page table walk in some circumstances,
    e.g. in case of the in atomic futex operations or if running on old
    hardware which doesn't support the mvcos instruction.
    
    However it turned out that the page table walk code does not correctly
    lock page tables when accessing page table entries.
    In other words: a different cpu may invalidate a page table entry while
    the current cpu inspects the pte. This may lead to random data corruption.
    
    Adding correct locking however isn't trivial for all uaccess operations.
    Especially copy_in_user() is problematic since that requires to hold at
    least two locks, but must be protected against ABBA deadlock when a
    different cpu also performs a copy_in_user() operation.
    
    So the solution is a different approach where we change address spaces:
    
    User space runs in primary address mode, or access register mode within
    vdso code, like it currently already does.
    
    The kernel usually also runs in home space mode, however when accessing
    user space the kernel switches to primary or secondary address mode if
    the mvcos instruction is not available or if a compare-and-swap (futex)
    instruction on a user space address is performed.
    KVM however is special, since that requires the kernel to run in home
    address space while implicitly accessing user space with the sie
    instruction.
    
    So we end up with:
    
    User space:
    - runs in primary or access register mode
    - cr1 contains the user asce
    - cr7 contains the user asce
    - cr13 contains the kernel asce
    
    Kernel space:
    - runs in home space mode
    - cr1 contains the user or kernel asce
      -> the kernel asce is loaded when a uaccess requires primary or
         secondary address mode
    - cr7 contains the user or kernel asce, (changed with set_fs())
    - cr13 contains the kernel asce
    
    In case of uaccess the kernel changes to:
    - primary space mode in case of a uaccess (copy_to_user) and uses
      e.g. the mvcp instruction to access user space. However the kernel
      will stay in home space mode if the mvcos instruction is available
    - secondary space mode in case of futex atomic operations, so that the
      instructions come from primary address space and data from secondary
      space
    
    In case of kvm the kernel runs in home space mode, but cr1 gets switched
    to contain the gmap asce before the sie instruction gets executed. When
    the sie instruction is finished cr1 will be switched back to contain the
    user asce.
    
    A context switch between two processes will always load the kernel asce
    for the next process in cr1. So the first exit to user space is a bit
    more expensive (one extra load control register instruction) than before,
    however keeps the code rather simple.
    
    In sum this means there is no need to perform any error prone page table
    walks anymore when accessing user space.
    
    The patch seems to be rather large, however it mainly removes the
    the page table walk code and restores the previously deleted "standard"
    uaccess code, with a couple of changes.
    
    The uaccess without mvcos mode can be enforced with the "uaccess_primary"
    kernel parameter.
    
    Reported-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index 29c81f82705e..e759181357fc 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -132,6 +132,7 @@ static inline void restore_access_regs(unsigned int *acrs)
 		update_cr_regs(next);					\
 	}								\
 	prev = __switch_to(prev,next);					\
+	update_primary_asce(current);					\
 } while (0)
 
 #define finish_arch_switch(prev) do {					     \

commit 4725c86055f5bbdcdfe47199c0715881893a2c79
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Oct 15 16:08:34 2013 +0200

    s390: fix save and restore of the floating-point-control register
    
    The FPC_VALID_MASK has been used to check the validity of the value
    to be loaded into the floating-point-control register. With the
    introduction of the floating-point extension facility and the
    decimal-floating-point additional bits have been defined which need
    to be checked in a non straight forward way. So far these bits have
    been ignored which can cause an incorrect results for decimal-
    floating-point operations, e.g. an incorrect rounding mode to be
    set after signal return.
    
    The static check with the FPC_VALID_MASK is replaced with a trial
    load of the floating-point-control value, see test_fp_ctl.
    
    In addition an information leak with the padding word between the
    floating-point-control word and the floating-point registers in
    the s390_fp_regs is fixed.
    
    Reported-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index 6dbd559763c9..29c81f82705e 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -13,58 +13,94 @@
 extern struct task_struct *__switch_to(void *, void *);
 extern void update_cr_regs(struct task_struct *task);
 
-static inline void save_fp_regs(s390_fp_regs *fpregs)
+static inline int test_fp_ctl(u32 fpc)
 {
+	u32 orig_fpc;
+	int rc;
+
+	if (!MACHINE_HAS_IEEE)
+		return 0;
+
 	asm volatile(
-		"	std	0,%O0+8(%R0)\n"
-		"	std	2,%O0+24(%R0)\n"
-		"	std	4,%O0+40(%R0)\n"
-		"	std	6,%O0+56(%R0)"
-		: "=Q" (*fpregs) : "Q" (*fpregs));
+		"	efpc    %1\n"
+		"	sfpc	%2\n"
+		"0:	sfpc	%1\n"
+		"	la	%0,0\n"
+		"1:\n"
+		EX_TABLE(0b,1b)
+		: "=d" (rc), "=d" (orig_fpc)
+		: "d" (fpc), "0" (-EINVAL));
+	return rc;
+}
+
+static inline void save_fp_ctl(u32 *fpc)
+{
 	if (!MACHINE_HAS_IEEE)
 		return;
+
 	asm volatile(
-		"	stfpc	%0\n"
-		"	std	1,%O0+16(%R0)\n"
-		"	std	3,%O0+32(%R0)\n"
-		"	std	5,%O0+48(%R0)\n"
-		"	std	7,%O0+64(%R0)\n"
-		"	std	8,%O0+72(%R0)\n"
-		"	std	9,%O0+80(%R0)\n"
-		"	std	10,%O0+88(%R0)\n"
-		"	std	11,%O0+96(%R0)\n"
-		"	std	12,%O0+104(%R0)\n"
-		"	std	13,%O0+112(%R0)\n"
-		"	std	14,%O0+120(%R0)\n"
-		"	std	15,%O0+128(%R0)\n"
-		: "=Q" (*fpregs) : "Q" (*fpregs));
+		"       stfpc   %0\n"
+		: "+Q" (*fpc));
 }
 
-static inline void restore_fp_regs(s390_fp_regs *fpregs)
+static inline int restore_fp_ctl(u32 *fpc)
 {
+	int rc;
+
+	if (!MACHINE_HAS_IEEE)
+		return 0;
+
 	asm volatile(
-		"	ld	0,%O0+8(%R0)\n"
-		"	ld	2,%O0+24(%R0)\n"
-		"	ld	4,%O0+40(%R0)\n"
-		"	ld	6,%O0+56(%R0)"
-		: : "Q" (*fpregs));
+		"0:	lfpc    %1\n"
+		"	la	%0,0\n"
+		"1:\n"
+		EX_TABLE(0b,1b)
+		: "=d" (rc) : "Q" (*fpc), "0" (-EINVAL));
+	return rc;
+}
+
+static inline void save_fp_regs(freg_t *fprs)
+{
+	asm volatile("std 0,%0" : "=Q" (fprs[0]));
+	asm volatile("std 2,%0" : "=Q" (fprs[2]));
+	asm volatile("std 4,%0" : "=Q" (fprs[4]));
+	asm volatile("std 6,%0" : "=Q" (fprs[6]));
 	if (!MACHINE_HAS_IEEE)
 		return;
-	asm volatile(
-		"	lfpc	%0\n"
-		"	ld	1,%O0+16(%R0)\n"
-		"	ld	3,%O0+32(%R0)\n"
-		"	ld	5,%O0+48(%R0)\n"
-		"	ld	7,%O0+64(%R0)\n"
-		"	ld	8,%O0+72(%R0)\n"
-		"	ld	9,%O0+80(%R0)\n"
-		"	ld	10,%O0+88(%R0)\n"
-		"	ld	11,%O0+96(%R0)\n"
-		"	ld	12,%O0+104(%R0)\n"
-		"	ld	13,%O0+112(%R0)\n"
-		"	ld	14,%O0+120(%R0)\n"
-		"	ld	15,%O0+128(%R0)\n"
-		: : "Q" (*fpregs));
+	asm volatile("std 1,%0" : "=Q" (fprs[1]));
+	asm volatile("std 3,%0" : "=Q" (fprs[3]));
+	asm volatile("std 5,%0" : "=Q" (fprs[5]));
+	asm volatile("std 7,%0" : "=Q" (fprs[7]));
+	asm volatile("std 8,%0" : "=Q" (fprs[8]));
+	asm volatile("std 9,%0" : "=Q" (fprs[9]));
+	asm volatile("std 10,%0" : "=Q" (fprs[10]));
+	asm volatile("std 11,%0" : "=Q" (fprs[11]));
+	asm volatile("std 12,%0" : "=Q" (fprs[12]));
+	asm volatile("std 13,%0" : "=Q" (fprs[13]));
+	asm volatile("std 14,%0" : "=Q" (fprs[14]));
+	asm volatile("std 15,%0" : "=Q" (fprs[15]));
+}
+
+static inline void restore_fp_regs(freg_t *fprs)
+{
+	asm volatile("ld 0,%0" : : "Q" (fprs[0]));
+	asm volatile("ld 2,%0" : : "Q" (fprs[2]));
+	asm volatile("ld 4,%0" : : "Q" (fprs[4]));
+	asm volatile("ld 6,%0" : : "Q" (fprs[6]));
+	if (!MACHINE_HAS_IEEE)
+		return;
+	asm volatile("ld 1,%0" : : "Q" (fprs[1]));
+	asm volatile("ld 3,%0" : : "Q" (fprs[3]));
+	asm volatile("ld 5,%0" : : "Q" (fprs[5]));
+	asm volatile("ld 7,%0" : : "Q" (fprs[7]));
+	asm volatile("ld 8,%0" : : "Q" (fprs[8]));
+	asm volatile("ld 9,%0" : : "Q" (fprs[9]));
+	asm volatile("ld 10,%0" : : "Q" (fprs[10]));
+	asm volatile("ld 11,%0" : : "Q" (fprs[11]));
+	asm volatile("ld 12,%0" : : "Q" (fprs[12]));
+	asm volatile("ld 13,%0" : : "Q" (fprs[13]));
+	asm volatile("ld 14,%0" : : "Q" (fprs[14]));
+	asm volatile("ld 15,%0" : : "Q" (fprs[15]));
 }
 
 static inline void save_access_regs(unsigned int *acrs)
@@ -83,12 +119,14 @@ static inline void restore_access_regs(unsigned int *acrs)
 
 #define switch_to(prev,next,last) do {					\
 	if (prev->mm) {							\
-		save_fp_regs(&prev->thread.fp_regs);			\
+		save_fp_ctl(&prev->thread.fp_regs.fpc);			\
+		save_fp_regs(prev->thread.fp_regs.fprs);		\
 		save_access_regs(&prev->thread.acrs[0]);		\
 		save_ri_cb(prev->thread.ri_cb);				\
 	}								\
 	if (next->mm) {							\
-		restore_fp_regs(&next->thread.fp_regs);			\
+		restore_fp_ctl(&next->thread.fp_regs.fpc);		\
+		restore_fp_regs(next->thread.fp_regs.fprs);		\
 		restore_access_regs(&next->thread.acrs[0]);		\
 		restore_ri_cb(next->thread.ri_cb, prev->thread.ri_cb);	\
 		update_cr_regs(next);					\

commit bee5c2863ef807fa50bbdf8b2bae887c54a97083
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Tue Aug 20 10:24:12 2013 +0200

    s390/switch_to: fix save_access_regs() / restore_access_regs()
    
    Fix broken contraints for both save_access_regs() and restore_access_regs().
    The constraints are incorrect since they tell the compiler that the inline
    assemblies only access the first element of an array of 16 elements.
    Therefore the compiler could generate incorrect code.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index 80b6f11263c4..6dbd559763c9 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -8,6 +8,7 @@
 #define __ASM_SWITCH_TO_H
 
 #include <linux/thread_info.h>
+#include <asm/ptrace.h>
 
 extern struct task_struct *__switch_to(void *, void *);
 extern void update_cr_regs(struct task_struct *task);
@@ -68,12 +69,16 @@ static inline void restore_fp_regs(s390_fp_regs *fpregs)
 
 static inline void save_access_regs(unsigned int *acrs)
 {
-	asm volatile("stam 0,15,%0" : "=Q" (*acrs));
+	typedef struct { int _[NUM_ACRS]; } acrstype;
+
+	asm volatile("stam 0,15,%0" : "=Q" (*(acrstype *)acrs));
 }
 
 static inline void restore_access_regs(unsigned int *acrs)
 {
-	asm volatile("lam 0,15,%0" : : "Q" (*acrs));
+	typedef struct { int _[NUM_ACRS]; } acrstype;
+
+	asm volatile("lam 0,15,%0" : : "Q" (*(acrstype *)acrs));
 }
 
 #define switch_to(prev,next,last) do {					\

commit 64597f9dae1850e0360ae2e9b5485d4b5d1fdf4c
Author: Michael Mueller <mimu@linux.vnet.ibm.com>
Date:   Tue Jul 2 22:58:26 2013 +0200

    s390/ptrace: PTRACE_TE_ABORT_RAND
    
    The patch implements a s390 specific ptrace request
    PTRACE_TE_ABORT_RAND to modify the randomness of spontaneous
    aborts of memory transactions of the transaction execution
    facility. The data argument of the ptrace request is used to
    specify the levels of randomness, 0 for normal operation, 1 to
    abort every transaction at a random instruction, and 2 to abort
    a random transaction at a random instruction. The default is 0
    for normal operation.
    
    Acked-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Michael Mueller <mimu@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index f3a9e0f92704..80b6f11263c4 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -10,7 +10,7 @@
 #include <linux/thread_info.h>
 
 extern struct task_struct *__switch_to(void *, void *);
-extern void update_per_regs(struct task_struct *task);
+extern void update_cr_regs(struct task_struct *task);
 
 static inline void save_fp_regs(s390_fp_regs *fpregs)
 {
@@ -86,7 +86,7 @@ static inline void restore_access_regs(unsigned int *acrs)
 		restore_fp_regs(&next->thread.fp_regs);			\
 		restore_access_regs(&next->thread.acrs[0]);		\
 		restore_ri_cb(next->thread.ri_cb, prev->thread.ri_cb);	\
-		update_per_regs(next);					\
+		update_cr_regs(next);					\
 	}								\
 	prev = __switch_to(prev,next);					\
 } while (0)

commit 6c09931b3f987898f5c581d267ef269f5e2e9575
Merge: b3eda8d05c1a c397031f58f9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Oct 1 11:49:56 2012 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux
    
    Pull s390 updates from Martin Schwidefsky:
     "The main new feature is machine support for System zEC12 including
      transactional memory, runtime instrumentation, support for scm block
      devices via eadm subchannels, and support for CEX4 crypto cards.
    
      In addition there are some nice improvements: bpf jit compiler, arch
      backend for cmpxchg_double, relative exception table entries, dasd
      partition detection independent from the dasd driver ioctls, and cpu
      cache information in /proc/cpuinfo and /sys/device/cpu.
    
      And last but not least a series of cleanup patches from Heiko."
    
    Fix up trivial add-add conflict in arch/s390/Kconfig due to commit
    b952741c8079 ("cputime: Generalize CONFIG_VIRT_CPU_ACCOUNTING")
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux: (76 commits)
      s390: update defconfig
      s390/jump label,nss: let shared kernel support depend on !JUMP_LABEL
      s390/disassembler: fix decoding of risblg instruction
      s390/bpf,jit: add support for BPF_S_ANC_ALU_XOR_X instruction
      s390/traps: move call to print_modules() out of show_regs()
      s390/mm: mark free_initrd_mem() as __init
      s390/dasd: check count address during online setting
      drivers/s390/char/monreader.c: fix error return code
      s390/cmpxchg,percpu: implement cmpxchg_double()
      s390/percpu: implement this_cpu_add_return()
      s390/percpu: implement this_cpu_xchg()
      s390/kexec: remove CONFIG_KEXEC
      s390/irq: use designated initializers for irq class array
      s390: add uninitialized_var() to suppress false positive compiler warnings
      s390/crashdump: move fill_cpu_elf_notes() prototype to header file
      s390/process: add missing header include
      s390/ptrace: add missing ifdef
      s390/ipl,decrompressor: disable branch profiling
      s390/perf_events: compile only for CONFIG_64BIT
      s390/tape: remove even more tape block leftovers
      ...

commit e4b8b3f33fcaa0ed6e6b5482a606091d8cd20beb
Author: Jan Glauber <jang@linux.vnet.ibm.com>
Date:   Tue Jul 31 10:52:05 2012 +0200

    s390: add support for runtime instrumentation
    
    Allow user-space threads to use runtime instrumentation (RI). To enable RI
    for a thread there is a new s390 specific system call, sys_s390_runtime_instr,
    that takes as parameter a realtime signal number. If the RI facility is
    available the system call sets up a control block for the calling thread with
    the appropriate permissions for the thread to modify the control block.
    
    The user-space thread can then use the store and modify RI instructions to
    alter the control block and start/stop the instrumentation via RION/RIOFF.
    
    If the user specified program buffer runs full RI triggers an external
    interrupt. The external interrupt is translated to a real-time signal that
    is delivered to the thread that enabled RI on that CPU. The number of
    the real-time signal is the number specified in the RI system call. So,
    user-space can select any available real-time signal number in case the
    application itself uses real-time signals for other purposes.
    
    The kernel saves the RI control blocks on task switch only if the running
    thread was enabled for RI. Therefore, the performance impact on task switch
    should be negligible if RI is not used.
    
    RI is only enabled for user-space mode and is disabled for the supervisor
    state.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Jan Glauber <jang@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index f223068b7822..dc4967b0e056 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -80,10 +80,12 @@ static inline void restore_access_regs(unsigned int *acrs)
 	if (prev->mm) {							\
 		save_fp_regs(&prev->thread.fp_regs);			\
 		save_access_regs(&prev->thread.acrs[0]);		\
+		save_ri_cb(prev->thread.ri_cb);				\
 	}								\
 	if (next->mm) {							\
 		restore_fp_regs(&next->thread.fp_regs);			\
 		restore_access_regs(&next->thread.acrs[0]);		\
+		restore_ri_cb(next->thread.ri_cb, prev->thread.ri_cb);	\
 		update_per_regs(next);					\
 	}								\
 	prev = __switch_to(prev,next);					\

commit b9bb50db9126c4ccad78af2dfb77277ca17c9b64
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Mon Jun 18 17:55:38 2012 +0200

    s390: Remove leftover account_tick_vtime() header
    
    The function doesn't seem to exist anymore.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Acked-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index e7f9b3d04fa1..314cc9426fc4 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -89,8 +89,6 @@ static inline void restore_access_regs(unsigned int *acrs)
 	prev = __switch_to(prev,next);					\
 } while (0)
 
-extern void account_tick_vtime(struct task_struct *);
-
 #define finish_arch_switch(prev) do {					     \
 	set_fs(current->thread.mm_segment);				     \
 } while (0)

commit baa36046d09ea6dbc122c795566992318663d9eb
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Mon Jun 18 17:54:14 2012 +0200

    cputime: Consolidate vtime handling on context switch
    
    The archs that implement virtual cputime accounting all
    flush the cputime of a task when it gets descheduled
    and sometimes set up some ground initialization for the
    next task to account its cputime.
    
    These archs all put their own hooks in their context
    switch callbacks and handle the off-case themselves.
    
    Consolidate this by creating a new account_switch_vtime()
    callback called in generic code right after a context switch
    and that these archs must implement to flush the prev task
    cputime and initialize the next task cputime related state.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Acked-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
index f223068b7822..e7f9b3d04fa1 100644
--- a/arch/s390/include/asm/switch_to.h
+++ b/arch/s390/include/asm/switch_to.h
@@ -89,12 +89,10 @@ static inline void restore_access_regs(unsigned int *acrs)
 	prev = __switch_to(prev,next);					\
 } while (0)
 
-extern void account_vtime(struct task_struct *, struct task_struct *);
 extern void account_tick_vtime(struct task_struct *);
 
 #define finish_arch_switch(prev) do {					     \
 	set_fs(current->thread.mm_segment);				     \
-	account_vtime(prev, current);					     \
 } while (0)
 
 #endif /* __ASM_SWITCH_TO_H */

commit a0616cdebcfd575dcd4c46102d1b52fbb827fc29
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:30:02 2012 +0100

    Disintegrate asm/system.h for S390
    
    Disintegrate asm/system.h for S390.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    cc: linux-s390@vger.kernel.org

diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h
new file mode 100644
index 000000000000..f223068b7822
--- /dev/null
+++ b/arch/s390/include/asm/switch_to.h
@@ -0,0 +1,100 @@
+/*
+ * Copyright IBM Corp. 1999, 2009
+ *
+ * Author(s): Martin Schwidefsky <schwidefsky@de.ibm.com>
+ */
+
+#ifndef __ASM_SWITCH_TO_H
+#define __ASM_SWITCH_TO_H
+
+#include <linux/thread_info.h>
+
+extern struct task_struct *__switch_to(void *, void *);
+extern void update_per_regs(struct task_struct *task);
+
+static inline void save_fp_regs(s390_fp_regs *fpregs)
+{
+	asm volatile(
+		"	std	0,%O0+8(%R0)\n"
+		"	std	2,%O0+24(%R0)\n"
+		"	std	4,%O0+40(%R0)\n"
+		"	std	6,%O0+56(%R0)"
+		: "=Q" (*fpregs) : "Q" (*fpregs));
+	if (!MACHINE_HAS_IEEE)
+		return;
+	asm volatile(
+		"	stfpc	%0\n"
+		"	std	1,%O0+16(%R0)\n"
+		"	std	3,%O0+32(%R0)\n"
+		"	std	5,%O0+48(%R0)\n"
+		"	std	7,%O0+64(%R0)\n"
+		"	std	8,%O0+72(%R0)\n"
+		"	std	9,%O0+80(%R0)\n"
+		"	std	10,%O0+88(%R0)\n"
+		"	std	11,%O0+96(%R0)\n"
+		"	std	12,%O0+104(%R0)\n"
+		"	std	13,%O0+112(%R0)\n"
+		"	std	14,%O0+120(%R0)\n"
+		"	std	15,%O0+128(%R0)\n"
+		: "=Q" (*fpregs) : "Q" (*fpregs));
+}
+
+static inline void restore_fp_regs(s390_fp_regs *fpregs)
+{
+	asm volatile(
+		"	ld	0,%O0+8(%R0)\n"
+		"	ld	2,%O0+24(%R0)\n"
+		"	ld	4,%O0+40(%R0)\n"
+		"	ld	6,%O0+56(%R0)"
+		: : "Q" (*fpregs));
+	if (!MACHINE_HAS_IEEE)
+		return;
+	asm volatile(
+		"	lfpc	%0\n"
+		"	ld	1,%O0+16(%R0)\n"
+		"	ld	3,%O0+32(%R0)\n"
+		"	ld	5,%O0+48(%R0)\n"
+		"	ld	7,%O0+64(%R0)\n"
+		"	ld	8,%O0+72(%R0)\n"
+		"	ld	9,%O0+80(%R0)\n"
+		"	ld	10,%O0+88(%R0)\n"
+		"	ld	11,%O0+96(%R0)\n"
+		"	ld	12,%O0+104(%R0)\n"
+		"	ld	13,%O0+112(%R0)\n"
+		"	ld	14,%O0+120(%R0)\n"
+		"	ld	15,%O0+128(%R0)\n"
+		: : "Q" (*fpregs));
+}
+
+static inline void save_access_regs(unsigned int *acrs)
+{
+	asm volatile("stam 0,15,%0" : "=Q" (*acrs));
+}
+
+static inline void restore_access_regs(unsigned int *acrs)
+{
+	asm volatile("lam 0,15,%0" : : "Q" (*acrs));
+}
+
+#define switch_to(prev,next,last) do {					\
+	if (prev->mm) {							\
+		save_fp_regs(&prev->thread.fp_regs);			\
+		save_access_regs(&prev->thread.acrs[0]);		\
+	}								\
+	if (next->mm) {							\
+		restore_fp_regs(&next->thread.fp_regs);			\
+		restore_access_regs(&next->thread.acrs[0]);		\
+		update_per_regs(next);					\
+	}								\
+	prev = __switch_to(prev,next);					\
+} while (0)
+
+extern void account_vtime(struct task_struct *, struct task_struct *);
+extern void account_tick_vtime(struct task_struct *);
+
+#define finish_arch_switch(prev) do {					     \
+	set_fs(current->thread.mm_segment);				     \
+	account_vtime(prev, current);					     \
+} while (0)
+
+#endif /* __ASM_SWITCH_TO_H */
