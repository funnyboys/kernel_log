commit 3a83f677a6eeff65751b29e3648d7c69c3be83f3
Author: Michael Roth <mdroth@linux.vnet.ibm.com>
Date:   Wed Sep 11 17:31:55 2019 -0500

    KVM: PPC: Book3S HV: use smp_mb() when setting/clearing host_ipi flag
    
    On a 2-socket Power9 system with 32 cores/128 threads (SMT4) and 1TB
    of memory running the following guest configs:
    
      guest A:
        - 224GB of memory
        - 56 VCPUs (sockets=1,cores=28,threads=2), where:
          VCPUs 0-1 are pinned to CPUs 0-3,
          VCPUs 2-3 are pinned to CPUs 4-7,
          ...
          VCPUs 54-55 are pinned to CPUs 108-111
    
      guest B:
        - 4GB of memory
        - 4 VCPUs (sockets=1,cores=4,threads=1)
    
    with the following workloads (with KSM and THP enabled in all):
    
      guest A:
        stress --cpu 40 --io 20 --vm 20 --vm-bytes 512M
    
      guest B:
        stress --cpu 4 --io 4 --vm 4 --vm-bytes 512M
    
      host:
        stress --cpu 4 --io 4 --vm 2 --vm-bytes 256M
    
    the below soft-lockup traces were observed after an hour or so and
    persisted until the host was reset (this was found to be reliably
    reproducible for this configuration, for kernels 4.15, 4.18, 5.0,
    and 5.3-rc5):
    
      [ 1253.183290] rcu: INFO: rcu_sched self-detected stall on CPU
      [ 1253.183319] rcu:     124-....: (5250 ticks this GP) idle=10a/1/0x4000000000000002 softirq=5408/5408 fqs=1941
      [ 1256.287426] watchdog: BUG: soft lockup - CPU#105 stuck for 23s! [CPU 52/KVM:19709]
      [ 1264.075773] watchdog: BUG: soft lockup - CPU#24 stuck for 23s! [worker:19913]
      [ 1264.079769] watchdog: BUG: soft lockup - CPU#31 stuck for 23s! [worker:20331]
      [ 1264.095770] watchdog: BUG: soft lockup - CPU#45 stuck for 23s! [worker:20338]
      [ 1264.131773] watchdog: BUG: soft lockup - CPU#64 stuck for 23s! [avocado:19525]
      [ 1280.408480] watchdog: BUG: soft lockup - CPU#124 stuck for 22s! [ksmd:791]
      [ 1316.198012] rcu: INFO: rcu_sched self-detected stall on CPU
      [ 1316.198032] rcu:     124-....: (21003 ticks this GP) idle=10a/1/0x4000000000000002 softirq=5408/5408 fqs=8243
      [ 1340.411024] watchdog: BUG: soft lockup - CPU#124 stuck for 22s! [ksmd:791]
      [ 1379.212609] rcu: INFO: rcu_sched self-detected stall on CPU
      [ 1379.212629] rcu:     124-....: (36756 ticks this GP) idle=10a/1/0x4000000000000002 softirq=5408/5408 fqs=14714
      [ 1404.413615] watchdog: BUG: soft lockup - CPU#124 stuck for 22s! [ksmd:791]
      [ 1442.227095] rcu: INFO: rcu_sched self-detected stall on CPU
      [ 1442.227115] rcu:     124-....: (52509 ticks this GP) idle=10a/1/0x4000000000000002 softirq=5408/5408 fqs=21403
      [ 1455.111787] INFO: task worker:19907 blocked for more than 120 seconds.
      [ 1455.111822]       Tainted: G             L    5.3.0-rc5-mdr-vanilla+ #1
      [ 1455.111833] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
      [ 1455.111884] INFO: task worker:19908 blocked for more than 120 seconds.
      [ 1455.111905]       Tainted: G             L    5.3.0-rc5-mdr-vanilla+ #1
      [ 1455.111925] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
      [ 1455.111966] INFO: task worker:20328 blocked for more than 120 seconds.
      [ 1455.111986]       Tainted: G             L    5.3.0-rc5-mdr-vanilla+ #1
      [ 1455.111998] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
      [ 1455.112048] INFO: task worker:20330 blocked for more than 120 seconds.
      [ 1455.112068]       Tainted: G             L    5.3.0-rc5-mdr-vanilla+ #1
      [ 1455.112097] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
      [ 1455.112138] INFO: task worker:20332 blocked for more than 120 seconds.
      [ 1455.112159]       Tainted: G             L    5.3.0-rc5-mdr-vanilla+ #1
      [ 1455.112179] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
      [ 1455.112210] INFO: task worker:20333 blocked for more than 120 seconds.
      [ 1455.112231]       Tainted: G             L    5.3.0-rc5-mdr-vanilla+ #1
      [ 1455.112242] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
      [ 1455.112282] INFO: task worker:20335 blocked for more than 120 seconds.
      [ 1455.112303]       Tainted: G             L    5.3.0-rc5-mdr-vanilla+ #1
      [ 1455.112332] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
      [ 1455.112372] INFO: task worker:20336 blocked for more than 120 seconds.
      [ 1455.112392]       Tainted: G             L    5.3.0-rc5-mdr-vanilla+ #1
    
    CPUs 45, 24, and 124 are stuck on spin locks, likely held by
    CPUs 105 and 31.
    
    CPUs 105 and 31 are stuck in smp_call_function_many(), waiting on
    target CPU 42. For instance:
    
      # CPU 105 registers (via xmon)
      R00 = c00000000020b20c   R16 = 00007d1bcd800000
      R01 = c00000363eaa7970   R17 = 0000000000000001
      R02 = c0000000019b3a00   R18 = 000000000000006b
      R03 = 000000000000002a   R19 = 00007d537d7aecf0
      R04 = 000000000000002a   R20 = 60000000000000e0
      R05 = 000000000000002a   R21 = 0801000000000080
      R06 = c0002073fb0caa08   R22 = 0000000000000d60
      R07 = c0000000019ddd78   R23 = 0000000000000001
      R08 = 000000000000002a   R24 = c00000000147a700
      R09 = 0000000000000001   R25 = c0002073fb0ca908
      R10 = c000008ffeb4e660   R26 = 0000000000000000
      R11 = c0002073fb0ca900   R27 = c0000000019e2464
      R12 = c000000000050790   R28 = c0000000000812b0
      R13 = c000207fff623e00   R29 = c0002073fb0ca808
      R14 = 00007d1bbee00000   R30 = c0002073fb0ca800
      R15 = 00007d1bcd600000   R31 = 0000000000000800
      pc  = c00000000020b260 smp_call_function_many+0x3d0/0x460
      cfar= c00000000020b270 smp_call_function_many+0x3e0/0x460
      lr  = c00000000020b20c smp_call_function_many+0x37c/0x460
      msr = 900000010288b033   cr  = 44024824
      ctr = c000000000050790   xer = 0000000000000000   trap =  100
    
    CPU 42 is running normally, doing VCPU work:
    
      # CPU 42 stack trace (via xmon)
      [link register   ] c00800001be17188 kvmppc_book3s_radix_page_fault+0x90/0x2b0 [kvm_hv]
      [c000008ed3343820] c000008ed3343850 (unreliable)
      [c000008ed33438d0] c00800001be11b6c kvmppc_book3s_hv_page_fault+0x264/0xe30 [kvm_hv]
      [c000008ed33439d0] c00800001be0d7b4 kvmppc_vcpu_run_hv+0x8dc/0xb50 [kvm_hv]
      [c000008ed3343ae0] c00800001c10891c kvmppc_vcpu_run+0x34/0x48 [kvm]
      [c000008ed3343b00] c00800001c10475c kvm_arch_vcpu_ioctl_run+0x244/0x420 [kvm]
      [c000008ed3343b90] c00800001c0f5a78 kvm_vcpu_ioctl+0x470/0x7c8 [kvm]
      [c000008ed3343d00] c000000000475450 do_vfs_ioctl+0xe0/0xc70
      [c000008ed3343db0] c0000000004760e4 ksys_ioctl+0x104/0x120
      [c000008ed3343e00] c000000000476128 sys_ioctl+0x28/0x80
      [c000008ed3343e20] c00000000000b388 system_call+0x5c/0x70
      --- Exception: c00 (System Call) at 00007d545cfd7694
      SP (7d53ff7edf50) is in userspace
    
    It was subsequently found that ipi_message[PPC_MSG_CALL_FUNCTION]
    was set for CPU 42 by at least 1 of the CPUs waiting in
    smp_call_function_many(), but somehow the corresponding
    call_single_queue entries were never processed by CPU 42, causing the
    callers to spin in csd_lock_wait() indefinitely.
    
    Nick Piggin suggested something similar to the following sequence as
    a possible explanation (interleaving of CALL_FUNCTION/RESCHEDULE
    IPI messages seems to be most common, but any mix of CALL_FUNCTION and
    !CALL_FUNCTION messages could trigger it):
    
        CPU
          X: smp_muxed_ipi_set_message():
          X:   smp_mb()
          X:   message[RESCHEDULE] = 1
          X: doorbell_global_ipi(42):
          X:   kvmppc_set_host_ipi(42, 1)
          X:   ppc_msgsnd_sync()/smp_mb()
          X:   ppc_msgsnd() -> 42
         42: doorbell_exception(): // from CPU X
         42:   ppc_msgsync()
        105: smp_muxed_ipi_set_message():
        105:   smb_mb()
             // STORE DEFERRED DUE TO RE-ORDERING
      --105:   message[CALL_FUNCTION] = 1
      | 105: doorbell_global_ipi(42):
      | 105:   kvmppc_set_host_ipi(42, 1)
      |  42:   kvmppc_set_host_ipi(42, 0)
      |  42: smp_ipi_demux_relaxed()
      |  42: // returns to executing guest
      |      // RE-ORDERED STORE COMPLETES
      ->105:   message[CALL_FUNCTION] = 1
        105:   ppc_msgsnd_sync()/smp_mb()
        105:   ppc_msgsnd() -> 42
         42: local_paca->kvm_hstate.host_ipi == 0 // IPI ignored
        105: // hangs waiting on 42 to process messages/call_single_queue
    
    This can be prevented with an smp_mb() at the beginning of
    kvmppc_set_host_ipi(), such that stores to message[<type>] (or other
    state indicated by the host_ipi flag) are ordered vs. the store to
    to host_ipi.
    
    However, doing so might still allow for the following scenario (not
    yet observed):
    
        CPU
          X: smp_muxed_ipi_set_message():
          X:   smp_mb()
          X:   message[RESCHEDULE] = 1
          X: doorbell_global_ipi(42):
          X:   kvmppc_set_host_ipi(42, 1)
          X:   ppc_msgsnd_sync()/smp_mb()
          X:   ppc_msgsnd() -> 42
         42: doorbell_exception(): // from CPU X
         42:   ppc_msgsync()
             // STORE DEFERRED DUE TO RE-ORDERING
      -- 42:   kvmppc_set_host_ipi(42, 0)
      |  42: smp_ipi_demux_relaxed()
      | 105: smp_muxed_ipi_set_message():
      | 105:   smb_mb()
      | 105:   message[CALL_FUNCTION] = 1
      | 105: doorbell_global_ipi(42):
      | 105:   kvmppc_set_host_ipi(42, 1)
      |      // RE-ORDERED STORE COMPLETES
      -> 42:   kvmppc_set_host_ipi(42, 0)
         42: // returns to executing guest
        105:   ppc_msgsnd_sync()/smp_mb()
        105:   ppc_msgsnd() -> 42
         42: local_paca->kvm_hstate.host_ipi == 0 // IPI ignored
        105: // hangs waiting on 42 to process messages/call_single_queue
    
    Fixing this scenario would require an smp_mb() *after* clearing
    host_ipi flag in kvmppc_set_host_ipi() to order the store vs.
    subsequent processing of IPI messages.
    
    To handle both cases, this patch splits kvmppc_set_host_ipi() into
    separate set/clear functions, where we execute smp_mb() prior to
    setting host_ipi flag, and after clearing host_ipi flag. These
    functions pair with each other to synchronize the sender and receiver
    sides.
    
    With that change in place the above workload ran for 20 hours without
    triggering any lock-ups.
    
    Fixes: 755563bc79c7 ("powerpc/powernv: Fixes for hypervisor doorbell handling") # v4.0
    Signed-off-by: Michael Roth <mdroth@linux.vnet.ibm.com>
    Acked-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190911223155.16045-1-mdroth@linux.vnet.ibm.com

diff --git a/arch/powerpc/sysdev/xics/icp-opal.c b/arch/powerpc/sysdev/xics/icp-opal.c
index 8bb8dd7dd6ad..68fd2540b093 100644
--- a/arch/powerpc/sysdev/xics/icp-opal.c
+++ b/arch/powerpc/sysdev/xics/icp-opal.c
@@ -126,7 +126,7 @@ static void icp_opal_cause_ipi(int cpu)
 {
 	int hw_cpu = get_hard_smp_processor_id(cpu);
 
-	kvmppc_set_host_ipi(cpu, 1);
+	kvmppc_set_host_ipi(cpu);
 	opal_int_set_mfrr(hw_cpu, IPI_PRIORITY);
 }
 
@@ -134,7 +134,7 @@ static irqreturn_t icp_opal_ipi_action(int irq, void *dev_id)
 {
 	int cpu = smp_processor_id();
 
-	kvmppc_set_host_ipi(cpu, 0);
+	kvmppc_clear_host_ipi(cpu);
 	opal_int_set_mfrr(get_hard_smp_processor_id(cpu), 0xff);
 
 	return smp_ipi_demux();
@@ -157,7 +157,7 @@ void icp_opal_flush_interrupt(void)
 		if (vec == XICS_IPI) {
 			/* Clear pending IPI */
 			int cpu = smp_processor_id();
-			kvmppc_set_host_ipi(cpu, 0);
+			kvmppc_clear_host_ipi(cpu);
 			opal_int_set_mfrr(get_hard_smp_processor_id(cpu), 0xff);
 		} else {
 			pr_err("XICS: hw interrupt 0x%x to offline cpu, "

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/sysdev/xics/icp-opal.c b/arch/powerpc/sysdev/xics/icp-opal.c
index c71d2ea42627..8bb8dd7dd6ad 100644
--- a/arch/powerpc/sysdev/xics/icp-opal.c
+++ b/arch/powerpc/sysdev/xics/icp-opal.c
@@ -1,10 +1,6 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  * Copyright 2016 IBM Corporation.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version
- * 2 of the License, or (at your option) any later version.
  */
 #include <linux/types.h>
 #include <linux/kernel.h>

commit b866cc2199d6a6cdcefe4acfe4cfca3ac3c6d38e
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Thu Apr 13 20:16:21 2017 +1000

    powerpc: Change the doorbell IPI calling convention
    
    Change the doorbell callers to know about their msgsnd addressing,
    rather than have them set a per-cpu target data tag at boot that gets
    sent to the cause_ipi functions. The data is only used for doorbell IPI
    functions, no other IPI types, so it makes sense to keep that detail
    local to doorbell.
    
    Have the platform code understand doorbell IPIs, rather than the
    interrupt controller code understand them. Platform code can look at
    capabilities it has available and decide which to use.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/sysdev/xics/icp-opal.c b/arch/powerpc/sysdev/xics/icp-opal.c
index b53f80f0b4d8..c71d2ea42627 100644
--- a/arch/powerpc/sysdev/xics/icp-opal.c
+++ b/arch/powerpc/sysdev/xics/icp-opal.c
@@ -126,7 +126,7 @@ static void icp_opal_eoi(struct irq_data *d)
 
 #ifdef CONFIG_SMP
 
-static void icp_opal_cause_ipi(int cpu, unsigned long data)
+static void icp_opal_cause_ipi(int cpu)
 {
 	int hw_cpu = get_hard_smp_processor_id(cpu);
 

commit a69e2fb70350a66f91175cd2625f1e8215c5b6e9
Author: Balbir Singh <bsingharora@gmail.com>
Date:   Fri Mar 3 11:58:44 2017 +1100

    powerpc/xics: Work around limitations of OPAL XICS priority handling
    
    The CPPR (Current Processor Priority Register) of a XICS interrupt
    presentation controller contains a value N, such that only interrupts
    with a priority "more favoured" than N will be received by the CPU,
    where "more favoured" means "less than". So if the CPPR has the value 5
    then only interrupts with a priority of 0-4 inclusive will be received.
    
    In theory the CPPR can support a value of 0 to 255 inclusive.
    In practice Linux only uses values of 0, 4, 5 and 0xff. Setting the CPPR
    to 0 rejects all interrupts, setting it to 0xff allows all interrupts.
    The values 4 and 5 are used to differentiate IPIs from external
    interrupts. Setting the CPPR to 5 allows IPIs to be received but not
    external interrupts.
    
    The CPPR emulation in the OPAL XICS implementation only directly
    supports priorities 0 and 0xff. All other priorities are considered
    equivalent, and mapped to a single priority value internally. This means
    when using icp-opal we can not allow IPIs but not externals.
    
    This breaks Linux's use of priority values when a CPU is hot unplugged.
    After migrating IRQs away from the CPU that is being offlined, we set
    the priority to 5, meaning we still want the offline CPU to receive
    IPIs. But the effect of the OPAL XICS emulation's use of a single
    priority value is that all interrupts are rejected by the CPU. With the
    CPU offline, and not receiving IPIs, we may not be able to wake it up to
    bring it back online.
    
    The first part of the fix is in icp_opal_set_cpu_priority(). CPPR values
    of 0 to 4 inclusive will correctly cause all interrupts to be rejected,
    so we pass those CPPR values through to OPAL. However if we are called
    with a CPPR of 5 or greater, the caller is expecting to be able to allow
    IPIs but not external interrupts. We know this doesn't work, so instead
    of rejecting all interrupts we choose the opposite which is to allow all
    interrupts. This is still not correct behaviour, but we know for the
    only existing caller (xics_migrate_irqs_away()), that it is the better
    option.
    
    The other part of the fix is in xics_migrate_irqs_away(). Instead of
    setting priority (CPPR) to 0, and then back to 5 before migrating IRQs,
    we migrate the IRQs before setting the priority back to 5. This should
    have no effect on an ICP backend with a working set_priority(), and on
    icp-opal it means we will keep all interrupts blocked until after we've
    finished doing the IRQ migration. Additionally we wait for 5ms after
    doing the migration to make sure there are no IRQs in flight.
    
    Fixes: d74361881f0d ("powerpc/xics: Add ICP OPAL backend")
    Cc: stable@vger.kernel.org # v4.8+
    Suggested-by: Michael Ellerman <mpe@ellerman.id.au>
    Reported-by: Vaidyanathan Srinivasan <svaidy@linux.vnet.ibm.com>
    Tested-by: Vaidyanathan Srinivasan <svaidy@linux.vnet.ibm.com>
    Signed-off-by: Balbir Singh <bsingharora@gmail.com>
    [mpe: Rewrote comments and change log, change delay to 5ms]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/sysdev/xics/icp-opal.c b/arch/powerpc/sysdev/xics/icp-opal.c
index f9670eabfcfa..b53f80f0b4d8 100644
--- a/arch/powerpc/sysdev/xics/icp-opal.c
+++ b/arch/powerpc/sysdev/xics/icp-opal.c
@@ -91,6 +91,16 @@ static unsigned int icp_opal_get_irq(void)
 
 static void icp_opal_set_cpu_priority(unsigned char cppr)
 {
+	/*
+	 * Here be dragons. The caller has asked to allow only IPI's and not
+	 * external interrupts. But OPAL XIVE doesn't support that. So instead
+	 * of allowing no interrupts allow all. That's still not right, but
+	 * currently the only caller who does this is xics_migrate_irqs_away()
+	 * and it works in that case.
+	 */
+	if (cppr >= DEFAULT_PRIORITY)
+		cppr = LOWEST_PRIORITY;
+
 	xics_set_base_cppr(cppr);
 	opal_int_set_cppr(cppr);
 	iosync();

commit f83e6862047e1e371bdc5d512dd6cabe8a3965b8
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Feb 7 11:35:36 2017 +1100

    powerpc/powernv: Properly set "host-ipi" on IPIs
    
    Otherwise KVM will fail to pass them through to the host
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/sysdev/xics/icp-opal.c b/arch/powerpc/sysdev/xics/icp-opal.c
index c96c0cb95d87..f9670eabfcfa 100644
--- a/arch/powerpc/sysdev/xics/icp-opal.c
+++ b/arch/powerpc/sysdev/xics/icp-opal.c
@@ -120,14 +120,16 @@ static void icp_opal_cause_ipi(int cpu, unsigned long data)
 {
 	int hw_cpu = get_hard_smp_processor_id(cpu);
 
+	kvmppc_set_host_ipi(cpu, 1);
 	opal_int_set_mfrr(hw_cpu, IPI_PRIORITY);
 }
 
 static irqreturn_t icp_opal_ipi_action(int irq, void *dev_id)
 {
-	int hw_cpu = hard_smp_processor_id();
+	int cpu = smp_processor_id();
 
-	opal_int_set_mfrr(hw_cpu, 0xff);
+	kvmppc_set_host_ipi(cpu, 0);
+	opal_int_set_mfrr(get_hard_smp_processor_id(cpu), 0xff);
 
 	return smp_ipi_demux();
 }

commit 9b256714979fad61ae11d90b53cf67dd5e6484eb
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Feb 7 11:35:31 2017 +1100

    powerpc/powernv: Fix CPU hotplug to handle waking on HVI
    
    The IPIs come in as HVI not EE, so we need to test the appropriate
    SRR1 bits. The encoding is such that it won't have false positives
    on P7 and P8 so we can just test it like that. We also need to handle
    the icp-opal variant of the flush.
    
    Fixes: d74361881f0d ("powerpc/xics: Add ICP OPAL backend")
    Cc: stable@vger.kernel.org # v4.8+
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/sysdev/xics/icp-opal.c b/arch/powerpc/sysdev/xics/icp-opal.c
index 60c57657c772..c96c0cb95d87 100644
--- a/arch/powerpc/sysdev/xics/icp-opal.c
+++ b/arch/powerpc/sysdev/xics/icp-opal.c
@@ -132,6 +132,35 @@ static irqreturn_t icp_opal_ipi_action(int irq, void *dev_id)
 	return smp_ipi_demux();
 }
 
+/*
+ * Called when an interrupt is received on an off-line CPU to
+ * clear the interrupt, so that the CPU can go back to nap mode.
+ */
+void icp_opal_flush_interrupt(void)
+{
+	unsigned int xirr;
+	unsigned int vec;
+
+	do {
+		xirr = icp_opal_get_xirr();
+		vec = xirr & 0x00ffffff;
+		if (vec == XICS_IRQ_SPURIOUS)
+			break;
+		if (vec == XICS_IPI) {
+			/* Clear pending IPI */
+			int cpu = smp_processor_id();
+			kvmppc_set_host_ipi(cpu, 0);
+			opal_int_set_mfrr(get_hard_smp_processor_id(cpu), 0xff);
+		} else {
+			pr_err("XICS: hw interrupt 0x%x to offline cpu, "
+			       "disabling\n", vec);
+			xics_mask_unknown_vec(vec);
+		}
+
+		/* EOI the interrupt */
+	} while (opal_int_eoi(xirr) > 0);
+}
+
 #endif /* CONFIG_SMP */
 
 static const struct icp_ops icp_opal_ops = {

commit 9728a7c8ab2f7a1c8d5c95278d2e4f4ac1285385
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon Jan 16 11:58:53 2017 -0600

    powerpc/icp-opal: Fix missing KVM case and harden replay
    
    The icp-opal call is missing the code from icp-native to recover
    interrupts snatched by KVM. Without that, when running KVM, we can
    get into a situation where an interrupt is lost and the CPU stuck
    with an elevated CPPR.
    
    Also harden replay by always checking the return from opal_int_eoi().
    
    Fixes: d74361881f0d ("powerpc/xics: Add ICP OPAL backend")
    Cc: stable@vger.kernel.org # v4.8+
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/sysdev/xics/icp-opal.c b/arch/powerpc/sysdev/xics/icp-opal.c
index d38e86fd5720..60c57657c772 100644
--- a/arch/powerpc/sysdev/xics/icp-opal.c
+++ b/arch/powerpc/sysdev/xics/icp-opal.c
@@ -20,6 +20,7 @@
 #include <asm/xics.h>
 #include <asm/io.h>
 #include <asm/opal.h>
+#include <asm/kvm_ppc.h>
 
 static void icp_opal_teardown_cpu(void)
 {
@@ -39,7 +40,26 @@ static void icp_opal_flush_ipi(void)
 	 * Should we be flagging idle loop instead?
 	 * Or creating some task to be scheduled?
 	 */
-	opal_int_eoi((0x00 << 24) | XICS_IPI);
+	if (opal_int_eoi((0x00 << 24) | XICS_IPI) > 0)
+		force_external_irq_replay();
+}
+
+static unsigned int icp_opal_get_xirr(void)
+{
+	unsigned int kvm_xirr;
+	__be32 hw_xirr;
+	int64_t rc;
+
+	/* Handle an interrupt latched by KVM first */
+	kvm_xirr = kvmppc_get_xics_latch();
+	if (kvm_xirr)
+		return kvm_xirr;
+
+	/* Then ask OPAL */
+	rc = opal_int_get_xirr(&hw_xirr, false);
+	if (rc < 0)
+		return 0;
+	return be32_to_cpu(hw_xirr);
 }
 
 static unsigned int icp_opal_get_irq(void)
@@ -47,12 +67,8 @@ static unsigned int icp_opal_get_irq(void)
 	unsigned int xirr;
 	unsigned int vec;
 	unsigned int irq;
-	int64_t rc;
 
-	rc = opal_int_get_xirr(&xirr, false);
-	if (rc < 0)
-		return 0;
-	xirr = be32_to_cpu(xirr);
+	xirr = icp_opal_get_xirr();
 	vec = xirr & 0x00ffffff;
 	if (vec == XICS_IRQ_SPURIOUS)
 		return 0;
@@ -67,7 +83,8 @@ static unsigned int icp_opal_get_irq(void)
 	xics_mask_unknown_vec(vec);
 
 	/* We might learn about it later, so EOI it */
-	opal_int_eoi(xirr);
+	if (opal_int_eoi(xirr) > 0)
+		force_external_irq_replay();
 
 	return 0;
 }

commit 07021b43597f506cc525d139ed1a94e79cf184f2
Merge: d1f5323370fc b7b7013cac55
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 7 20:19:31 2016 -0700

    Merge tag 'powerpc-4.9-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Highlights:
       - Major rework of Book3S 64-bit exception vectors (Nicholas Piggin)
       - Use gas sections for arranging exception vectors et. al.
       - Large set of TM cleanups and selftests (Cyril Bur)
       - Enable transactional memory (TM) lazily for userspace (Cyril Bur)
       - Support for XZ compression in the zImage wrapper (Oliver
         O'Halloran)
       - Add support for bpf constant blinding (Naveen N. Rao)
       - Beginnings of upstream support for PA Semi Nemo motherboards
         (Darren Stevens)
    
      Fixes:
       - Ensure .mem(init|exit).text are within _stext/_etext (Michael
         Ellerman)
       - xmon: Don't use ld on 32-bit (Michael Ellerman)
       - vdso64: Use double word compare on pointers (Anton Blanchard)
       - powerpc/nvram: Fix an incorrect partition merge (Pan Xinhui)
       - powerpc: Fix usage of _PAGE_RO in hugepage (Christophe Leroy)
       - powerpc/mm: Update FORCE_MAX_ZONEORDER range to allow hugetlb w/4K
         (Aneesh Kumar K.V)
       - Fix memory leak in queue_hotplug_event() error path (Andrew
         Donnellan)
       - Replay hypervisor maintenance interrupt first (Nicholas Piggin)
    
      Various performance optimisations (Anton Blanchard):
       - Align hot loops of memset() and backwards_memcpy()
       - During context switch, check before setting mm_cpumask
       - Remove static branch prediction in atomic{, 64}_add_unless
       - Only disable HAVE_EFFICIENT_UNALIGNED_ACCESS on POWER7 little
         endian
       - Set default CPU type to POWER8 for little endian builds
    
      Cleanups & features:
       - Sparse fixes/cleanups (Daniel Axtens)
       - Preserve CFAR value on SLB miss caused by access to bogus address
         (Paul Mackerras)
       - Radix MMU fixups for POWER9 (Aneesh Kumar K.V)
       - Support for setting used_(vsr|vr|spe) in sigreturn path (for CRIU)
         (Simon Guo)
       - Optimise syscall entry for virtual, relocatable case (Nicholas
         Piggin)
       - Optimise MSR handling in exception handling (Nicholas Piggin)
       - Support for kexec with Radix MMU (Benjamin Herrenschmidt)
       - powernv EEH fixes (Russell Currey)
       - Suprise PCI hotplug support for powernv (Gavin Shan)
       - Endian/sparse fixes for powernv PCI (Gavin Shan)
       - Defconfig updates (Anton Blanchard)
       - KVM: PPC: Book3S HV: Migrate pinned pages out of CMA (Balbir Singh)
       - cxl: Flush PSL cache before resetting the adapter (Frederic Barrat)
       - cxl: replace loop with for_each_child_of_node(), remove unneeded
         of_node_put() (Andrew Donnellan)
       - Fix HV facility unavailable to use correct handler (Nicholas
         Piggin)
       - Remove unnecessary syscall trampoline (Nicholas Piggin)
       - fadump: Fix build break when CONFIG_PROC_VMCORE=n (Michael
         Ellerman)
       - Quieten EEH message when no adapters are found (Anton Blanchard)
       - powernv: Add PHB register dump debugfs handle (Russell Currey)
       - Use kprobe blacklist for exception handlers & asm functions
         (Nicholas Piggin)
       - Document the syscall ABI (Nicholas Piggin)
       - MAINTAINERS: Update cxl maintainers (Michael Neuling)
       - powerpc: Remove all usages of NO_IRQ (Michael Ellerman)
    
      Minor cleanups:
       - Andrew Donnellan, Christophe Leroy, Colin Ian King, Cyril Bur,
         Frederic Barrat, Pan Xinhui, PrasannaKumar Muralidharan, Rui Teng,
         Simon Guo"
    
    * tag 'powerpc-4.9-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (156 commits)
      powerpc/bpf: Add support for bpf constant blinding
      powerpc/bpf: Implement support for tail calls
      powerpc/bpf: Introduce accessors for using the tmp local stack space
      powerpc/fadump: Fix build break when CONFIG_PROC_VMCORE=n
      powerpc: tm: Enable transactional memory (TM) lazily for userspace
      powerpc/tm: Add TM Unavailable Exception
      powerpc: Remove do_load_up_transact_{fpu,altivec}
      powerpc: tm: Rename transct_(*) to ck(\1)_state
      powerpc: tm: Always use fp_state and vr_state to store live registers
      selftests/powerpc: Add checks for transactional VSXs in signal contexts
      selftests/powerpc: Add checks for transactional VMXs in signal contexts
      selftests/powerpc: Add checks for transactional FPUs in signal contexts
      selftests/powerpc: Add checks for transactional GPRs in signal contexts
      selftests/powerpc: Check that signals always get delivered
      selftests/powerpc: Add TM tcheck helpers in C
      selftests/powerpc: Allow tests to extend their kill timeout
      selftests/powerpc: Introduce GPR asm helper header file
      selftests/powerpc: Move VMX stack frame macros to header file
      selftests/powerpc: Rework FPU stack placement macros and move to header file
      selftests/powerpc: Check for VSX preservation across userspace preemption
      ...

commit ef24ba7091517d2bbf9ba2cb4256c0dccd51d248
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Sep 6 21:53:24 2016 +1000

    powerpc: Remove all usages of NO_IRQ
    
    NO_IRQ has been == 0 on powerpc for just over ten years (since commit
    0ebfff1491ef ("[POWERPC] Add new interrupt mapping core and change
    platforms to use it")). It's also 0 on most other arches.
    
    Although it's fairly harmless, every now and then it causes confusion
    when a driver is built on powerpc and another arch which doesn't define
    NO_IRQ. There's at least 6 definitions of NO_IRQ in drivers/, at least
    some of which are to work around that problem.
    
    So we'd like to remove it. This is fairly trivial in the arch code, we
    just convert:
    
        if (irq == NO_IRQ)  to      if (!irq)
        if (irq != NO_IRQ)  to      if (irq)
        irq = NO_IRQ;       to      irq = 0;
        return NO_IRQ;      to      return 0;
    
    And a few other odd cases as well.
    
    At least for now we keep the #define NO_IRQ, because there is driver
    code that uses NO_IRQ and the fixes to remove those will go via other
    trees.
    
    Note we also change some occurrences in PPC sound drivers, drivers/ps3,
    and drivers/macintosh.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/sysdev/xics/icp-opal.c b/arch/powerpc/sysdev/xics/icp-opal.c
index 57d72f10a97f..7357cfddb040 100644
--- a/arch/powerpc/sysdev/xics/icp-opal.c
+++ b/arch/powerpc/sysdev/xics/icp-opal.c
@@ -51,14 +51,14 @@ static unsigned int icp_opal_get_irq(void)
 
 	rc = opal_int_get_xirr(&xirr, false);
 	if (rc < 0)
-		return NO_IRQ;
+		return 0;
 	xirr = be32_to_cpu(xirr);
 	vec = xirr & 0x00ffffff;
 	if (vec == XICS_IRQ_SPURIOUS)
-		return NO_IRQ;
+		return 0;
 
 	irq = irq_find_mapping(xics_host, vec);
-	if (likely(irq != NO_IRQ)) {
+	if (likely(irq)) {
 		xics_push_cppr(vec);
 		return irq;
 	}
@@ -69,7 +69,7 @@ static unsigned int icp_opal_get_irq(void)
 	/* We might learn about it later, so EOI it */
 	opal_int_eoi(xirr);
 
-	return NO_IRQ;
+	return 0;
 }
 
 static void icp_opal_set_cpu_priority(unsigned char cppr)

commit f8e33475b0da98c4bffc91017a3fbbfb443a7bdb
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Sep 6 13:43:45 2016 +1000

    powerpc/xics/opal: Fix processor numbers in OPAL ICP
    
    When using the OPAL ICP backend we incorrectly pass Linux CPU numbers
    rather than HW CPU numbers to OPAL.
    
    Fixes: d74361881f0d ("powerpc/xics: Add ICP OPAL backend")
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/sysdev/xics/icp-opal.c b/arch/powerpc/sysdev/xics/icp-opal.c
index 57d72f10a97f..9114243fa1b5 100644
--- a/arch/powerpc/sysdev/xics/icp-opal.c
+++ b/arch/powerpc/sysdev/xics/icp-opal.c
@@ -23,10 +23,10 @@
 
 static void icp_opal_teardown_cpu(void)
 {
-	int cpu = smp_processor_id();
+	int hw_cpu = hard_smp_processor_id();
 
 	/* Clear any pending IPI */
-	opal_int_set_mfrr(cpu, 0xff);
+	opal_int_set_mfrr(hw_cpu, 0xff);
 }
 
 static void icp_opal_flush_ipi(void)
@@ -101,14 +101,16 @@ static void icp_opal_eoi(struct irq_data *d)
 
 static void icp_opal_cause_ipi(int cpu, unsigned long data)
 {
-	opal_int_set_mfrr(cpu, IPI_PRIORITY);
+	int hw_cpu = get_hard_smp_processor_id(cpu);
+
+	opal_int_set_mfrr(hw_cpu, IPI_PRIORITY);
 }
 
 static irqreturn_t icp_opal_ipi_action(int irq, void *dev_id)
 {
-	int cpu = smp_processor_id();
+	int hw_cpu = hard_smp_processor_id();
 
-	opal_int_set_mfrr(cpu, 0xff);
+	opal_int_set_mfrr(hw_cpu, 0xff);
 
 	return smp_ipi_demux();
 }

commit d74361881f0dfe5f9dcac37d1b753a15a2345d8c
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Jul 8 16:37:08 2016 +1000

    powerpc/xics: Add ICP OPAL backend
    
    This adds a new XICS backend that uses OPAL calls, which can be
    used when we don't have native support for the platform interrupt
    controller.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/sysdev/xics/icp-opal.c b/arch/powerpc/sysdev/xics/icp-opal.c
new file mode 100644
index 000000000000..57d72f10a97f
--- /dev/null
+++ b/arch/powerpc/sysdev/xics/icp-opal.c
@@ -0,0 +1,144 @@
+/*
+ * Copyright 2016 IBM Corporation.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/irq.h>
+#include <linux/smp.h>
+#include <linux/interrupt.h>
+#include <linux/cpu.h>
+#include <linux/of.h>
+
+#include <asm/smp.h>
+#include <asm/irq.h>
+#include <asm/errno.h>
+#include <asm/xics.h>
+#include <asm/io.h>
+#include <asm/opal.h>
+
+static void icp_opal_teardown_cpu(void)
+{
+	int cpu = smp_processor_id();
+
+	/* Clear any pending IPI */
+	opal_int_set_mfrr(cpu, 0xff);
+}
+
+static void icp_opal_flush_ipi(void)
+{
+	/*
+	 * We take the ipi irq but and never return so we need to EOI the IPI,
+	 * but want to leave our priority 0.
+	 *
+	 * Should we check all the other interrupts too?
+	 * Should we be flagging idle loop instead?
+	 * Or creating some task to be scheduled?
+	 */
+	opal_int_eoi((0x00 << 24) | XICS_IPI);
+}
+
+static unsigned int icp_opal_get_irq(void)
+{
+	unsigned int xirr;
+	unsigned int vec;
+	unsigned int irq;
+	int64_t rc;
+
+	rc = opal_int_get_xirr(&xirr, false);
+	if (rc < 0)
+		return NO_IRQ;
+	xirr = be32_to_cpu(xirr);
+	vec = xirr & 0x00ffffff;
+	if (vec == XICS_IRQ_SPURIOUS)
+		return NO_IRQ;
+
+	irq = irq_find_mapping(xics_host, vec);
+	if (likely(irq != NO_IRQ)) {
+		xics_push_cppr(vec);
+		return irq;
+	}
+
+	/* We don't have a linux mapping, so have rtas mask it. */
+	xics_mask_unknown_vec(vec);
+
+	/* We might learn about it later, so EOI it */
+	opal_int_eoi(xirr);
+
+	return NO_IRQ;
+}
+
+static void icp_opal_set_cpu_priority(unsigned char cppr)
+{
+	xics_set_base_cppr(cppr);
+	opal_int_set_cppr(cppr);
+	iosync();
+}
+
+static void icp_opal_eoi(struct irq_data *d)
+{
+	unsigned int hw_irq = (unsigned int)irqd_to_hwirq(d);
+	int64_t rc;
+
+	iosync();
+	rc = opal_int_eoi((xics_pop_cppr() << 24) | hw_irq);
+
+	/*
+	 * EOI tells us whether there are more interrupts to fetch.
+	 *
+	 * Some HW implementations might not be able to send us another
+	 * external interrupt in that case, so we force a replay.
+	 */
+	if (rc > 0)
+		force_external_irq_replay();
+}
+
+#ifdef CONFIG_SMP
+
+static void icp_opal_cause_ipi(int cpu, unsigned long data)
+{
+	opal_int_set_mfrr(cpu, IPI_PRIORITY);
+}
+
+static irqreturn_t icp_opal_ipi_action(int irq, void *dev_id)
+{
+	int cpu = smp_processor_id();
+
+	opal_int_set_mfrr(cpu, 0xff);
+
+	return smp_ipi_demux();
+}
+
+#endif /* CONFIG_SMP */
+
+static const struct icp_ops icp_opal_ops = {
+	.get_irq	= icp_opal_get_irq,
+	.eoi		= icp_opal_eoi,
+	.set_priority	= icp_opal_set_cpu_priority,
+	.teardown_cpu	= icp_opal_teardown_cpu,
+	.flush_ipi	= icp_opal_flush_ipi,
+#ifdef CONFIG_SMP
+	.ipi_action	= icp_opal_ipi_action,
+	.cause_ipi	= icp_opal_cause_ipi,
+#endif
+};
+
+int icp_opal_init(void)
+{
+	struct device_node *np;
+
+	np = of_find_compatible_node(NULL, NULL, "ibm,opal-intc");
+	if (!np)
+		return -ENODEV;
+
+	icp_ops = &icp_opal_ops;
+
+	printk("XICS: Using OPAL ICP fallbacks\n");
+
+	return 0;
+}
+
