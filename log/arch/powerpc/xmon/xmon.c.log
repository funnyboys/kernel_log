commit e31cf2f4ca422ac9b14ecc4a1295b8977a20f812
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Jun 8 21:32:33 2020 -0700

    mm: don't include asm/pgtable.h if linux/mm.h is already included
    
    Patch series "mm: consolidate definitions of page table accessors", v2.
    
    The low level page table accessors (pXY_index(), pXY_offset()) are
    duplicated across all architectures and sometimes more than once.  For
    instance, we have 31 definition of pgd_offset() for 25 supported
    architectures.
    
    Most of these definitions are actually identical and typically it boils
    down to, e.g.
    
    static inline unsigned long pmd_index(unsigned long address)
    {
            return (address >> PMD_SHIFT) & (PTRS_PER_PMD - 1);
    }
    
    static inline pmd_t *pmd_offset(pud_t *pud, unsigned long address)
    {
            return (pmd_t *)pud_page_vaddr(*pud) + pmd_index(address);
    }
    
    These definitions can be shared among 90% of the arches provided
    XYZ_SHIFT, PTRS_PER_XYZ and xyz_page_vaddr() are defined.
    
    For architectures that really need a custom version there is always
    possibility to override the generic version with the usual ifdefs magic.
    
    These patches introduce include/linux/pgtable.h that replaces
    include/asm-generic/pgtable.h and add the definitions of the page table
    accessors to the new header.
    
    This patch (of 12):
    
    The linux/mm.h header includes <asm/pgtable.h> to allow inlining of the
    functions involving page table manipulations, e.g.  pte_alloc() and
    pmd_alloc().  So, there is no point to explicitly include <asm/pgtable.h>
    in the files that include <linux/mm.h>.
    
    The include statements in such cases are remove with a simple loop:
    
            for f in $(git grep -l "include <linux/mm.h>") ; do
                    sed -i -e '/include <asm\/pgtable.h>/ d' $f
            done
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Mike Rapoport <rppt@kernel.org>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200514170327.31389-1-rppt@kernel.org
    Link: http://lkml.kernel.org/r/20200514170327.31389-2-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index bfd152933376..7efe4bc3ccf6 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -35,7 +35,6 @@
 #include <asm/machdep.h>
 #include <asm/xmon.h>
 #include <asm/processor.h>
-#include <asm/pgtable.h>
 #include <asm/mmu.h>
 #include <asm/mmu_context.h>
 #include <asm/plpar_wrappers.h>

commit 081096d98bb23946f16215357b141c5616b234bf
Merge: e611c0fe318c a1b44ea340b2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Jun 7 09:52:36 2020 -0700

    Merge tag 'tty-5.8-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/tty
    
    Pull tty/serial driver updates from Greg KH:
     "Here is the tty and serial driver updates for 5.8-rc1
    
      Nothing huge at all, just a lot of little serial driver fixes, updates
      for new devices and features, and other small things. Full details are
      in the shortlog.
    
      All of these have been in linux-next with no issues for a while"
    
    * tag 'tty-5.8-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/tty: (67 commits)
      tty: serial: qcom_geni_serial: Add 51.2MHz frequency support
      tty: serial: imx: clear Ageing Timer Interrupt in handler
      serial: 8250_fintek: Add F81966 Support
      sc16is7xx: Add flag to activate IrDA mode
      dt-bindings: sc16is7xx: Add flag to activate IrDA mode
      serial: 8250: Support rs485 bus termination GPIO
      serial: 8520_port: Fix function param documentation
      dt-bindings: serial: Add binding for rs485 bus termination GPIO
      vt: keyboard: avoid signed integer overflow in k_ascii
      serial: 8250: Enable 16550A variants by default on non-x86
      tty: hvc_console, fix crashes on parallel open/close
      serial: imx: Initialize lock for non-registered console
      sc16is7xx: Read the LSR register for basic device presence check
      sc16is7xx: Allow sharing the IRQ line
      sc16is7xx: Use threaded IRQ
      sc16is7xx: Always use falling edge IRQ
      tty: n_gsm: Fix bogus i++ in gsm_data_kick
      tty: n_gsm: Remove unnecessary test in gsm_print_packet()
      serial: stm32: add no_console_suspend support
      tty: serial: fsl_lpuart: Use __maybe_unused instead of #if CONFIG_PM_SLEEP
      ...

commit 7ae77150d94d3b535c7b85e6b3647113095e79bf
Merge: 084623e468d5 1395375c5927
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jun 5 12:39:30 2020 -0700

    Merge tag 'powerpc-5.8-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
    
     - Support for userspace to send requests directly to the on-chip GZIP
       accelerator on Power9.
    
     - Rework of our lockless page table walking (__find_linux_pte()) to
       make it safe against parallel page table manipulations without
       relying on an IPI for serialisation.
    
     - A series of fixes & enhancements to make our machine check handling
       more robust.
    
     - Lots of plumbing to add support for "prefixed" (64-bit) instructions
       on Power10.
    
     - Support for using huge pages for the linear mapping on 8xx (32-bit).
    
     - Remove obsolete Xilinx PPC405/PPC440 support, and an associated sound
       driver.
    
     - Removal of some obsolete 40x platforms and associated cruft.
    
     - Initial support for booting on Power10.
    
     - Lots of other small features, cleanups & fixes.
    
    Thanks to: Alexey Kardashevskiy, Alistair Popple, Andrew Donnellan,
    Andrey Abramov, Aneesh Kumar K.V, Balamuruhan S, Bharata B Rao, Bulent
    Abali, CÃ©dric Le Goater, Chen Zhou, Christian Zigotzky, Christophe
    JAILLET, Christophe Leroy, Dmitry Torokhov, Emmanuel Nicolet, Erhard F.,
    Gautham R. Shenoy, Geoff Levand, George Spelvin, Greg Kurz, Gustavo A.
    R. Silva, Gustavo Walbon, Haren Myneni, Hari Bathini, Joel Stanley,
    Jordan Niethe, Kajol Jain, Kees Cook, Leonardo Bras, Madhavan
    Srinivasan., Mahesh Salgaonkar, Markus Elfring, Michael Neuling, Michal
    Simek, Nathan Chancellor, Nathan Lynch, Naveen N. Rao, Nicholas Piggin,
    Oliver O'Halloran, Paul Mackerras, Pingfan Liu, Qian Cai, Ram Pai,
    Raphael Moreira Zinsly, Ravi Bangoria, Sam Bobroff, Sandipan Das, Segher
    Boessenkool, Stephen Rothwell, Sukadev Bhattiprolu, Tyrel Datwyler,
    Wolfram Sang, Xiongfeng Wang.
    
    * tag 'powerpc-5.8-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (299 commits)
      powerpc/pseries: Make vio and ibmebus initcalls pseries specific
      cxl: Remove dead Kconfig options
      powerpc: Add POWER10 architected mode
      powerpc/dt_cpu_ftrs: Add MMA feature
      powerpc/dt_cpu_ftrs: Enable Prefixed Instructions
      powerpc/dt_cpu_ftrs: Advertise support for ISA v3.1 if selected
      powerpc: Add support for ISA v3.1
      powerpc: Add new HWCAP bits
      powerpc/64s: Don't set FSCR bits in INIT_THREAD
      powerpc/64s: Save FSCR to init_task.thread.fscr after feature init
      powerpc/64s: Don't let DT CPU features set FSCR_DSCR
      powerpc/64s: Don't init FSCR_DSCR in __init_FSCR()
      powerpc/32s: Fix another build failure with CONFIG_PPC_KUAP_DEBUG
      powerpc/module_64: Use special stub for _mcount() with -mprofile-kernel
      powerpc/module_64: Simplify check for -mprofile-kernel ftrace relocations
      powerpc/module_64: Consolidate ftrace code
      powerpc/32: Disable KASAN with pages bigger than 16k
      powerpc/uaccess: Don't set KUEP by default on book3s/32
      powerpc/uaccess: Don't set KUAP by default on book3s/32
      powerpc/8xx: Reduce time spent in allow_user_access() and friends
      ...

commit 2fb4706057bcf8261b3b0521ec7a62b54b82ce48
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Thu Jun 4 16:46:44 2020 -0700

    powerpc: add support for folded p4d page tables
    
    Implement primitives necessary for the 4th level folding, add walks of p4d
    level where appropriate and replace 5level-fixup.h with pgtable-nop4d.h.
    
    [rppt@linux.ibm.com: powerpc/xmon: drop unused pgdir varialble in show_pte() function]
      Link: http://lkml.kernel.org/r/20200519181454.GI1059226@linux.ibm.com
    [rppt@linux.ibm.com; build fix]
      Link: http://lkml.kernel.org/r/20200423141845.GI13521@linux.ibm.com
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Tested-by: Christophe Leroy <christophe.leroy@c-s.fr> # 8xx and 83xx
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Geert Uytterhoeven <geert+renesas@glider.be>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: James Morse <james.morse@arm.com>
    Cc: Jonas Bonn <jonas@southpole.se>
    Cc: Julien Thierry <julien.thierry.kdev@gmail.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Marc Zyngier <maz@kernel.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Stefan Kristiansson <stefan.kristiansson@saunalahti.fi>
    Cc: Suzuki K Poulose <suzuki.poulose@arm.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200414153455.21744-9-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 7af840c0fc93..89415b84c597 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -3135,7 +3135,8 @@ static void show_pte(unsigned long addr)
 	unsigned long tskv = 0;
 	struct task_struct *tsk = NULL;
 	struct mm_struct *mm;
-	pgd_t *pgdp, *pgdir;
+	pgd_t *pgdp;
+	p4d_t *p4dp;
 	pud_t *pudp;
 	pmd_t *pmdp;
 	pte_t *ptep;
@@ -3159,28 +3160,26 @@ static void show_pte(unsigned long addr)
 	catch_memory_errors = 1;
 	sync();
 
-	if (mm == &init_mm) {
+	if (mm == &init_mm)
 		pgdp = pgd_offset_k(addr);
-		pgdir = pgd_offset_k(0);
-	} else {
+	else
 		pgdp = pgd_offset(mm, addr);
-		pgdir = pgd_offset(mm, 0);
-	}
 
-	if (pgd_none(*pgdp)) {
-		printf("no linux page table for address\n");
+	p4dp = p4d_offset(pgdp, addr);
+
+	if (p4d_none(*p4dp)) {
+		printf("No valid P4D\n");
 		return;
 	}
 
-	printf("pgd  @ 0x%px\n", pgdir);
-
-	if (pgd_is_leaf(*pgdp)) {
-		format_pte(pgdp, pgd_val(*pgdp));
+	if (p4d_is_leaf(*p4dp)) {
+		format_pte(p4dp, p4d_val(*p4dp));
 		return;
 	}
-	printf("pgdp @ 0x%px = 0x%016lx\n", pgdp, pgd_val(*pgdp));
 
-	pudp = pud_offset(pgdp, addr);
+	printf("p4dp @ 0x%px = 0x%016lx\n", p4dp, p4d_val(*p4dp));
+
+	pudp = pud_offset(p4dp, addr);
 
 	if (pud_none(*pudp)) {
 		printf("No valid PUD\n");

commit 0e7e92efe11bc5993def689e10f7bcb36f127651
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed May 20 21:17:40 2020 +1000

    powerpc/xmon: Show task->thread.regs in process display
    
    Show the address of the tasks regs in the process listing in xmon. The
    regs should always be on the stack page that we also print the address
    of, but it's still helpful not to have to find them by hand.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200520111740.953679-1-mpe@ellerman.id.au

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 16ee6639a60c..b34d7034526e 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -3185,8 +3185,8 @@ static void show_task(struct task_struct *tsk)
 		(tsk->exit_state & EXIT_DEAD) ? 'E' :
 		(tsk->state & TASK_INTERRUPTIBLE) ? 'S' : '?';
 
-	printf("%px %016lx %6d %6d %c %2d %s\n", tsk,
-		tsk->thread.ksp,
+	printf("%16px %16lx %16px %6d %6d %c %2d %s\n", tsk,
+		tsk->thread.ksp, tsk->thread.regs,
 		tsk->pid, rcu_dereference(tsk->parent)->pid,
 		state, task_cpu(tsk),
 		tsk->comm);
@@ -3309,7 +3309,7 @@ static void show_tasks(void)
 	unsigned long tskv;
 	struct task_struct *tsk = NULL;
 
-	printf("     task_struct     ->thread.ksp    PID   PPID S  P CMD\n");
+	printf("     task_struct     ->thread.ksp    ->thread.regs    PID   PPID S  P CMD\n");
 
 	if (scanhex(&tskv))
 		tsk = (struct task_struct *)tskv;

commit c5ff46d69c410f7fac173e4fde3eea484b4b4eda
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Fri May 22 23:33:18 2020 +1000

    powerpc: Add ppc_inst_next()
    
    In a few places we want to calculate the address of the next
    instruction. Previously that was simple, we just added 4 bytes, or if
    using a u32 * we incremented that pointer by 1.
    
    But prefixed instructions make it more complicated, we need to advance
    by either 4 or 8 bytes depending on the actual instruction. We also
    can't do pointer arithmetic using struct ppc_inst, because it is
    always 8 bytes in size on 64-bit, even though we might only need to
    advance by 4 bytes.
    
    So add a ppc_inst_next() helper which calculates the location of the
    next instruction, if the given instruction was located at the given
    address. Note the instruction doesn't need to actually be at the
    address in memory.
    
    Although it would seem natural for the value to be passed by value,
    that makes it too easy to write a loop that will read off the end of a
    page, eg:
    
            for (; src < end; src = ppc_inst_next(src, *src),
                              dest = ppc_inst_next(dest, *dest))
    
    As noticed by Christophe and Jordan, if end is the exact end of a
    page, and the next page is not mapped, this will fault, because *dest
    will read 8 bytes, 4 bytes into the next page.
    
    So value is passed by reference, so the helper can be careful to use
    ppc_inst_read() on it.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Jordan Niethe <jniethe5@gmail.com>
    Link: https://lore.kernel.org/r/20200522133318.1681406-1-mpe@ellerman.id.au

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index de585204d1d2..16ee6639a60c 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -939,7 +939,7 @@ static void insert_bpts(void)
 		}
 
 		patch_instruction(bp->instr, instr);
-		patch_instruction((void *)bp->instr + ppc_inst_len(instr),
+		patch_instruction(ppc_inst_next(bp->instr, &instr),
 				  ppc_inst(bpinstr));
 		if (bp->enabled & BP_CIABR)
 			continue;

commit 30df74d67d48949da87e3a5b57c381763e8fd526
Author: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
Date:   Thu May 14 16:47:41 2020 +0530

    powerpc/watchpoint/xmon: Support 2nd DAWR
    
    Add support for 2nd DAWR in xmon. With this, we can have two
    simultaneous breakpoints from xmon.
    
    Signed-off-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Michael Neuling <mikey@neuling.org>
    Link: https://lore.kernel.org/r/20200514111741.97993-17-ravi.bangoria@linux.ibm.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 094bf4715f2c..de585204d1d2 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -112,7 +112,7 @@ struct bpt {
 #define BP_DABR		4
 
 static struct bpt bpts[NBPTS];
-static struct bpt dabr;
+static struct bpt dabr[HBP_NUM_MAX];
 static struct bpt *iabr;
 static unsigned bpinstr = 0x7fe00008;	/* trap */
 
@@ -784,10 +784,17 @@ static int xmon_sstep(struct pt_regs *regs)
 
 static int xmon_break_match(struct pt_regs *regs)
 {
+	int i;
+
 	if ((regs->msr & (MSR_IR|MSR_PR|MSR_64BIT)) != (MSR_IR|MSR_64BIT))
 		return 0;
-	if (dabr.enabled == 0)
-		return 0;
+	for (i = 0; i < nr_wp_slots(); i++) {
+		if (dabr[i].enabled)
+			goto found;
+	}
+	return 0;
+
+found:
 	xmon_core(regs, 0);
 	return 1;
 }
@@ -948,13 +955,16 @@ static void insert_bpts(void)
 
 static void insert_cpu_bpts(void)
 {
+	int i;
 	struct arch_hw_breakpoint brk;
 
-	if (dabr.enabled) {
-		brk.address = dabr.address;
-		brk.type = (dabr.enabled & HW_BRK_TYPE_DABR) | HW_BRK_TYPE_PRIV_ALL;
-		brk.len = DABR_MAX_LEN;
-		__set_breakpoint(0, &brk);
+	for (i = 0; i < nr_wp_slots(); i++) {
+		if (dabr[i].enabled) {
+			brk.address = dabr[i].address;
+			brk.type = (dabr[i].enabled & HW_BRK_TYPE_DABR) | HW_BRK_TYPE_PRIV_ALL;
+			brk.len = 8;
+			__set_breakpoint(i, &brk);
+		}
 	}
 
 	if (iabr)
@@ -1366,6 +1376,35 @@ static long check_bp_loc(unsigned long addr)
 	return 1;
 }
 
+static int find_free_data_bpt(void)
+{
+	int i;
+
+	for (i = 0; i < nr_wp_slots(); i++) {
+		if (!dabr[i].enabled)
+			return i;
+	}
+	printf("Couldn't find free breakpoint register\n");
+	return -1;
+}
+
+static void print_data_bpts(void)
+{
+	int i;
+
+	for (i = 0; i < nr_wp_slots(); i++) {
+		if (!dabr[i].enabled)
+			continue;
+
+		printf("   data   "REG"  [", dabr[i].address);
+		if (dabr[i].enabled & 1)
+			printf("r");
+		if (dabr[i].enabled & 2)
+			printf("w");
+		printf("]\n");
+	}
+}
+
 static char *breakpoint_help_string =
     "Breakpoint command usage:\n"
     "b                show breakpoints\n"
@@ -1399,10 +1438,9 @@ bpt_cmds(void)
 			printf("Hardware data breakpoint not supported on this cpu\n");
 			break;
 		}
-		if (dabr.enabled) {
-			printf("Couldn't find free breakpoint register\n");
+		i = find_free_data_bpt();
+		if (i < 0)
 			break;
-		}
 		mode = 7;
 		cmd = inchar();
 		if (cmd == 'r')
@@ -1411,15 +1449,15 @@ bpt_cmds(void)
 			mode = 6;
 		else
 			termch = cmd;
-		dabr.address = 0;
-		dabr.enabled = 0;
-		if (scanhex(&dabr.address)) {
-			if (!is_kernel_addr(dabr.address)) {
+		dabr[i].address = 0;
+		dabr[i].enabled = 0;
+		if (scanhex(&dabr[i].address)) {
+			if (!is_kernel_addr(dabr[i].address)) {
 				printf(badaddr);
 				break;
 			}
-			dabr.address &= ~HW_BRK_TYPE_DABR;
-			dabr.enabled = mode | BP_DABR;
+			dabr[i].address &= ~HW_BRK_TYPE_DABR;
+			dabr[i].enabled = mode | BP_DABR;
 		}
 
 		force_enable_xmon();
@@ -1458,7 +1496,9 @@ bpt_cmds(void)
 			for (i = 0; i < NBPTS; ++i)
 				bpts[i].enabled = 0;
 			iabr = NULL;
-			dabr.enabled = 0;
+			for (i = 0; i < nr_wp_slots(); i++)
+				dabr[i].enabled = 0;
+
 			printf("All breakpoints cleared\n");
 			break;
 		}
@@ -1492,14 +1532,7 @@ bpt_cmds(void)
 		if (xmon_is_ro || !scanhex(&a)) {
 			/* print all breakpoints */
 			printf("   type            address\n");
-			if (dabr.enabled) {
-				printf("   data   "REG"  [", dabr.address);
-				if (dabr.enabled & 1)
-					printf("r");
-				if (dabr.enabled & 2)
-					printf("w");
-				printf("]\n");
-			}
+			print_data_bpts();
 			for (bp = bpts; bp < &bpts[NBPTS]; ++bp) {
 				if (!bp->enabled)
 					continue;
@@ -1959,8 +1992,13 @@ static void dump_207_sprs(void)
 
 	printf("hfscr  = %.16lx  dhdes = %.16lx rpr    = %.16lx\n",
 		mfspr(SPRN_HFSCR), mfspr(SPRN_DHDES), mfspr(SPRN_RPR));
-	printf("dawr   = %.16lx  dawrx = %.16lx ciabr  = %.16lx\n",
-		mfspr(SPRN_DAWR0), mfspr(SPRN_DAWRX0), mfspr(SPRN_CIABR));
+	printf("dawr0  = %.16lx dawrx0 = %.16lx\n",
+	       mfspr(SPRN_DAWR0), mfspr(SPRN_DAWRX0));
+	if (nr_wp_slots() > 1) {
+		printf("dawr1  = %.16lx dawrx1 = %.16lx\n",
+		       mfspr(SPRN_DAWR1), mfspr(SPRN_DAWRX1));
+	}
+	printf("ciabr  = %.16lx\n", mfspr(SPRN_CIABR));
 #endif
 }
 
@@ -3909,10 +3947,9 @@ static void clear_all_bpt(void)
 		bpts[i].enabled = 0;
 
 	/* Clear any data or iabr breakpoints */
-	if (iabr || dabr.enabled) {
-		iabr = NULL;
-		dabr.enabled = 0;
-	}
+	iabr = NULL;
+	for (i = 0; i < nr_wp_slots(); i++)
+		dabr[i].enabled = 0;
 }
 
 #ifdef CONFIG_DEBUG_FS

commit 514db915e7b33e7eaf8e40192b93380f79b319b5
Author: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
Date:   Thu May 14 16:47:40 2020 +0530

    powerpc/watchpoint/xmon: Don't allow breakpoint overwriting
    
    Xmon allows overwriting breakpoints because it's supported by only
    one DAWR. But with multiple DAWRs, overwriting becomes ambiguous
    or unnecessary complicated. So let's not allow it.
    
    Signed-off-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Michael Neuling <mikey@neuling.org>
    Link: https://lore.kernel.org/r/20200514111741.97993-16-ravi.bangoria@linux.ibm.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 30b3e3d99c0d..094bf4715f2c 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1399,6 +1399,10 @@ bpt_cmds(void)
 			printf("Hardware data breakpoint not supported on this cpu\n");
 			break;
 		}
+		if (dabr.enabled) {
+			printf("Couldn't find free breakpoint register\n");
+			break;
+		}
 		mode = 7;
 		cmd = inchar();
 		if (cmd == 'r')

commit 4a8a9379f2af4c9928529b3959bc2d8f7023c6bc
Author: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
Date:   Thu May 14 16:47:31 2020 +0530

    powerpc/watchpoint: Provide DAWR number to __set_breakpoint
    
    Introduce new parameter 'nr' to __set_breakpoint() which indicates
    which DAWR should be programed. Also convert current_brk variable
    to an array.
    
    Signed-off-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Michael Neuling <mikey@neuling.org>
    Link: https://lore.kernel.org/r/20200514111741.97993-7-ravi.bangoria@linux.ibm.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index effb10c2e32f..30b3e3d99c0d 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -954,7 +954,7 @@ static void insert_cpu_bpts(void)
 		brk.address = dabr.address;
 		brk.type = (dabr.enabled & HW_BRK_TYPE_DABR) | HW_BRK_TYPE_PRIV_ALL;
 		brk.len = DABR_MAX_LEN;
-		__set_breakpoint(&brk);
+		__set_breakpoint(0, &brk);
 	}
 
 	if (iabr)

commit 09f82b063aa9c248a3ef919aeec361054e7b044a
Author: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
Date:   Thu May 14 16:47:26 2020 +0530

    powerpc/watchpoint: Rename current DAWR macros
    
    Power10 is introducing second DAWR. Use real register names from ISA
    for current macros:
      s/SPRN_DAWR/SPRN_DAWR0/
      s/SPRN_DAWRX/SPRN_DAWRX0/
    
    Signed-off-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Michael Neuling <mikey@neuling.org>
    Link: https://lore.kernel.org/r/20200514111741.97993-2-ravi.bangoria@linux.ibm.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index d1a79f9e0566..effb10c2e32f 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1956,7 +1956,7 @@ static void dump_207_sprs(void)
 	printf("hfscr  = %.16lx  dhdes = %.16lx rpr    = %.16lx\n",
 		mfspr(SPRN_HFSCR), mfspr(SPRN_DHDES), mfspr(SPRN_RPR));
 	printf("dawr   = %.16lx  dawrx = %.16lx ciabr  = %.16lx\n",
-		mfspr(SPRN_DAWR), mfspr(SPRN_DAWRX), mfspr(SPRN_CIABR));
+		mfspr(SPRN_DAWR0), mfspr(SPRN_DAWRX0), mfspr(SPRN_CIABR));
 #endif
 }
 

commit c9c831aebd8663d0129bbcee4d76be889f0627fe
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:46 2020 +1000

    powerpc/xmon: Don't allow breakpoints on suffixes
    
    Do not allow placing xmon breakpoints on the suffix of a prefix
    instruction.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    [mpe: Don't split printf strings across lines]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-27-jniethe5@gmail.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index ac8ccf333d51..d1a79f9e0566 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -889,8 +889,8 @@ static struct bpt *new_breakpoint(unsigned long a)
 static void insert_bpts(void)
 {
 	int i;
-	struct ppc_inst instr;
-	struct bpt *bp;
+	struct ppc_inst instr, instr2;
+	struct bpt *bp, *bp2;
 
 	bp = bpts;
 	for (i = 0; i < NBPTS; ++i, ++bp) {
@@ -908,6 +908,29 @@ static void insert_bpts(void)
 			bp->enabled = 0;
 			continue;
 		}
+		/*
+		 * Check the address is not a suffix by looking for a prefix in
+		 * front of it.
+		 */
+		if (mread_instr(bp->address - 4, &instr2) == 8) {
+			printf("Breakpoint at %lx is on the second word of a prefixed instruction, disabling it\n",
+			       bp->address);
+			bp->enabled = 0;
+			continue;
+		}
+		/*
+		 * We might still be a suffix - if the prefix has already been
+		 * replaced by a breakpoint we won't catch it with the above
+		 * test.
+		 */
+		bp2 = at_breakpoint(bp->address - 4);
+		if (bp2 && ppc_inst_prefixed(ppc_inst_read(bp2->instr))) {
+			printf("Breakpoint at %lx is on the second word of a prefixed instruction, disabling it\n",
+			       bp->address);
+			bp->enabled = 0;
+			continue;
+		}
+
 		patch_instruction(bp->instr, instr);
 		patch_instruction((void *)bp->instr + ppc_inst_len(instr),
 				  ppc_inst(bpinstr));

commit 650b55b707fdfa764e9f2b81314d3eb4216fb962
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Fri May 15 12:12:55 2020 +1000

    powerpc: Add prefixed instructions to instruction data type
    
    For powerpc64, redefine the ppc_inst type so both word and prefixed
    instructions can be represented. On powerpc32 the type will remain the
    same. Update places which had assumed instructions to be 4 bytes long.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Reviewed-by: Alistair Popple <alistair@popple.id.au>
    [mpe: Rework the get_user_inst() macros to be parameterised, and don't
          assign to the dest if an error occurred. Use CONFIG_PPC64 not
          __powerpc64__ in a few places. Address other comments from
          Christophe. Fix some sparse complaints.]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-24-jniethe5@gmail.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 00b24f357c2b..ac8ccf333d51 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -758,8 +758,8 @@ static int xmon_bpt(struct pt_regs *regs)
 
 	/* Are we at the trap at bp->instr[1] for some bp? */
 	bp = in_breakpoint_table(regs->nip, &offset);
-	if (bp != NULL && offset == 4) {
-		regs->nip = bp->address + 4;
+	if (bp != NULL && (offset == 4 || offset == 8)) {
+		regs->nip = bp->address + offset;
 		atomic_dec(&bp->ref_count);
 		return 1;
 	}

commit 7fccfcfba04f9cb46438f368755d368f6c57f3a0
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:39 2020 +1000

    powerpc/xmon: Move insertion of breakpoint for xol'ing
    
    When a new breakpoint is created, the second instruction of that
    breakpoint is patched with a trap instruction. This assumes the length
    of the instruction is always the same. In preparation for prefixed
    instructions, remove this assumption. Insert the trap instruction at the
    same time the first instruction is inserted.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Alistair Popple <alistair@popple.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-20-jniethe5@gmail.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index d8b29f6925be..00b24f357c2b 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -878,7 +878,6 @@ static struct bpt *new_breakpoint(unsigned long a)
 		if (!bp->enabled && atomic_read(&bp->ref_count) == 0) {
 			bp->address = a;
 			bp->instr = (void *)(bpt_table + ((bp - bpts) * BPT_WORDS));
-			patch_instruction(bp->instr + 1, ppc_inst(bpinstr));
 			return bp;
 		}
 	}
@@ -910,6 +909,8 @@ static void insert_bpts(void)
 			continue;
 		}
 		patch_instruction(bp->instr, instr);
+		patch_instruction((void *)bp->instr + ppc_inst_len(instr),
+				  ppc_inst(bpinstr));
 		if (bp->enabled & BP_CIABR)
 			continue;
 		if (patch_instruction((struct ppc_inst *)bp->address,

commit 6c7a4f0a9f66fc7fdc6e208559e5d562f53e0991
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:38 2020 +1000

    powerpc/xmon: Use a function for reading instructions
    
    Currently in xmon, mread() is used for reading instructions. In
    preparation for prefixed instructions, create and use a new function,
    mread_instr(), especially for reading instructions.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Alistair Popple <alistair@popple.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-19-jniethe5@gmail.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index a4f8f570dbbe..d8b29f6925be 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -122,6 +122,7 @@ static unsigned bpinstr = 0x7fe00008;	/* trap */
 static int cmds(struct pt_regs *);
 static int mread(unsigned long, void *, int);
 static int mwrite(unsigned long, void *, int);
+static int mread_instr(unsigned long, struct ppc_inst *);
 static int handle_fault(struct pt_regs *);
 static void byterev(unsigned char *, int);
 static void memex(void);
@@ -896,7 +897,7 @@ static void insert_bpts(void)
 	for (i = 0; i < NBPTS; ++i, ++bp) {
 		if ((bp->enabled & (BP_TRAP|BP_CIABR)) == 0)
 			continue;
-		if (mread(bp->address, &instr, 4) != 4) {
+		if (!mread_instr(bp->address, &instr)) {
 			printf("Couldn't read instruction at %lx, "
 			       "disabling breakpoint there\n", bp->address);
 			bp->enabled = 0;
@@ -946,7 +947,7 @@ static void remove_bpts(void)
 	for (i = 0; i < NBPTS; ++i, ++bp) {
 		if ((bp->enabled & (BP_TRAP|BP_CIABR)) != BP_TRAP)
 			continue;
-		if (mread(bp->address, &instr, 4) == 4
+		if (mread_instr(bp->address, &instr)
 		    && ppc_inst_equal(instr, ppc_inst(bpinstr))
 		    && patch_instruction(
 			(struct ppc_inst *)bp->address, ppc_inst_read(bp->instr)) != 0)
@@ -1162,7 +1163,7 @@ static int do_step(struct pt_regs *regs)
 	force_enable_xmon();
 	/* check we are in 64-bit kernel mode, translation enabled */
 	if ((regs->msr & (MSR_64BIT|MSR_PR|MSR_IR)) == (MSR_64BIT|MSR_IR)) {
-		if (mread(regs->nip, &instr, 4) == 4) {
+		if (mread_instr(regs->nip, &instr)) {
 			stepped = emulate_step(regs, instr);
 			if (stepped < 0) {
 				printf("Couldn't single-step %s instruction\n",
@@ -1329,7 +1330,7 @@ static long check_bp_loc(unsigned long addr)
 		printf("Breakpoints may only be placed at kernel addresses\n");
 		return 0;
 	}
-	if (!mread(addr, &instr, sizeof(instr))) {
+	if (!mread_instr(addr, &instr)) {
 		printf("Can't read instruction at address %lx\n", addr);
 		return 0;
 	}
@@ -2122,6 +2123,25 @@ mwrite(unsigned long adrs, void *buf, int size)
 	return n;
 }
 
+static int
+mread_instr(unsigned long adrs, struct ppc_inst *instr)
+{
+	volatile int n;
+
+	n = 0;
+	if (setjmp(bus_error_jmp) == 0) {
+		catch_memory_errors = 1;
+		sync();
+		*instr = ppc_inst_read((struct ppc_inst *)adrs);
+		sync();
+		/* wait a little while to see if we get a machine check */
+		__delay(200);
+		n = ppc_inst_len(*instr);
+	}
+	catch_memory_errors = 0;
+	return n;
+}
+
 static int fault_type;
 static int fault_except;
 static char *fault_chars[] = { "--", "**", "##" };

commit f8faaffaa7d99028e457ef2d1dcb43a98f736938
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:32 2020 +1000

    powerpc: Use a function for reading instructions
    
    Prefixed instructions will mean there are instructions of different
    length. As a result dereferencing a pointer to an instruction will not
    necessarily give the desired result. Introduce a function for reading
    instructions from memory into the instruction data type.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Alistair Popple <alistair@popple.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-13-jniethe5@gmail.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 2e3b15813cf1..a4f8f570dbbe 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -702,13 +702,13 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 	if ((regs->msr & (MSR_IR|MSR_PR|MSR_64BIT)) == (MSR_IR|MSR_64BIT)) {
 		bp = at_breakpoint(regs->nip);
 		if (bp != NULL) {
-			int stepped = emulate_step(regs, bp->instr[0]);
+			int stepped = emulate_step(regs, ppc_inst_read(bp->instr));
 			if (stepped == 0) {
 				regs->nip = (unsigned long) &bp->instr[0];
 				atomic_inc(&bp->ref_count);
 			} else if (stepped < 0) {
 				printf("Couldn't single-step %s instruction\n",
-				    (IS_RFID(bp->instr[0])? "rfid": "mtmsrd"));
+				    IS_RFID(ppc_inst_read(bp->instr))? "rfid": "mtmsrd");
 			}
 		}
 	}
@@ -949,7 +949,7 @@ static void remove_bpts(void)
 		if (mread(bp->address, &instr, 4) == 4
 		    && ppc_inst_equal(instr, ppc_inst(bpinstr))
 		    && patch_instruction(
-			(struct ppc_inst *)bp->address, bp->instr[0]) != 0)
+			(struct ppc_inst *)bp->address, ppc_inst_read(bp->instr)) != 0)
 			printf("Couldn't remove breakpoint at %lx\n",
 			       bp->address);
 	}

commit 94afd069d937d84fb4f696eb9a78db4084e43d21
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:31 2020 +1000

    powerpc: Use a datatype for instructions
    
    Currently unsigned ints are used to represent instructions on powerpc.
    This has worked well as instructions have always been 4 byte words.
    
    However, ISA v3.1 introduces some changes to instructions that mean
    this scheme will no longer work as well. This change is Prefixed
    Instructions. A prefixed instruction is made up of a word prefix
    followed by a word suffix to make an 8 byte double word instruction.
    No matter the endianness of the system the prefix always comes first.
    Prefixed instructions are only planned for powerpc64.
    
    Introduce a ppc_inst type to represent both prefixed and word
    instructions on powerpc64 while keeping it possible to exclusively
    have word instructions on powerpc32.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    [mpe: Fix compile error in emulate_spe()]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-12-jniethe5@gmail.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 4cf998518047..2e3b15813cf1 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -100,7 +100,7 @@ static long *xmon_fault_jmp[NR_CPUS];
 /* Breakpoint stuff */
 struct bpt {
 	unsigned long	address;
-	unsigned int	*instr;
+	struct ppc_inst	*instr;
 	atomic_t	ref_count;
 	int		enabled;
 	unsigned long	pad;
@@ -876,8 +876,8 @@ static struct bpt *new_breakpoint(unsigned long a)
 	for (bp = bpts; bp < &bpts[NBPTS]; ++bp) {
 		if (!bp->enabled && atomic_read(&bp->ref_count) == 0) {
 			bp->address = a;
-			bp->instr = bpt_table + ((bp - bpts) * BPT_WORDS);
-			patch_instruction(bp->instr + 1, bpinstr);
+			bp->instr = (void *)(bpt_table + ((bp - bpts) * BPT_WORDS));
+			patch_instruction(bp->instr + 1, ppc_inst(bpinstr));
 			return bp;
 		}
 	}
@@ -889,7 +889,7 @@ static struct bpt *new_breakpoint(unsigned long a)
 static void insert_bpts(void)
 {
 	int i;
-	unsigned int instr;
+	struct ppc_inst instr;
 	struct bpt *bp;
 
 	bp = bpts;
@@ -911,8 +911,8 @@ static void insert_bpts(void)
 		patch_instruction(bp->instr, instr);
 		if (bp->enabled & BP_CIABR)
 			continue;
-		if (patch_instruction((unsigned int *)bp->address,
-							bpinstr) != 0) {
+		if (patch_instruction((struct ppc_inst *)bp->address,
+				      ppc_inst(bpinstr)) != 0) {
 			printf("Couldn't write instruction at %lx, "
 			       "disabling breakpoint there\n", bp->address);
 			bp->enabled &= ~BP_TRAP;
@@ -940,7 +940,7 @@ static void remove_bpts(void)
 {
 	int i;
 	struct bpt *bp;
-	unsigned instr;
+	struct ppc_inst instr;
 
 	bp = bpts;
 	for (i = 0; i < NBPTS; ++i, ++bp) {
@@ -949,7 +949,7 @@ static void remove_bpts(void)
 		if (mread(bp->address, &instr, 4) == 4
 		    && ppc_inst_equal(instr, ppc_inst(bpinstr))
 		    && patch_instruction(
-			(unsigned int *)bp->address, bp->instr[0]) != 0)
+			(struct ppc_inst *)bp->address, bp->instr[0]) != 0)
 			printf("Couldn't remove breakpoint at %lx\n",
 			       bp->address);
 	}
@@ -1156,7 +1156,7 @@ static int do_step(struct pt_regs *regs)
  */
 static int do_step(struct pt_regs *regs)
 {
-	unsigned int instr;
+	struct ppc_inst instr;
 	int stepped;
 
 	force_enable_xmon();
@@ -1322,7 +1322,7 @@ csum(void)
  */
 static long check_bp_loc(unsigned long addr)
 {
-	unsigned int instr;
+	struct ppc_inst instr;
 
 	addr &= ~3;
 	if (!is_kernel_addr(addr)) {
@@ -2848,7 +2848,7 @@ generic_inst_dump(unsigned long adr, long count, int praddr,
 {
 	int nr, dotted;
 	unsigned long first_adr;
-	unsigned int inst, last_inst = ppc_inst(0);
+	struct ppc_inst inst, last_inst = ppc_inst(0);
 	unsigned char val[4];
 
 	dotted = 0;

commit 217862d9b98bf08958d57fd7b31b9de0f1a9477d
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:30 2020 +1000

    powerpc: Introduce functions for instruction equality
    
    In preparation for an instruction data type that can not be directly
    used with the '==' operator use functions for checking equality.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Balamuruhan S <bala24@linux.ibm.com>
    Link: https://lore.kernel.org/r/20200506034050.24806-11-jniethe5@gmail.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index c5e4218716e4..4cf998518047 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -947,7 +947,7 @@ static void remove_bpts(void)
 		if ((bp->enabled & (BP_TRAP|BP_CIABR)) != BP_TRAP)
 			continue;
 		if (mread(bp->address, &instr, 4) == 4
-		    && instr == ppc_inst(bpinstr)
+		    && ppc_inst_equal(instr, ppc_inst(bpinstr))
 		    && patch_instruction(
 			(unsigned int *)bp->address, bp->instr[0]) != 0)
 			printf("Couldn't remove breakpoint at %lx\n",
@@ -2862,7 +2862,7 @@ generic_inst_dump(unsigned long adr, long count, int praddr,
 			break;
 		}
 		inst = ppc_inst(GETWORD(val));
-		if (adr > first_adr && inst == last_inst) {
+		if (adr > first_adr && ppc_inst_equal(inst, last_inst)) {
 			if (!dotted) {
 				printf(" ...\n");
 				dotted = 1;

commit 777e26f0edf8dab58b8dd474d35d83bde0ac6d76
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:27 2020 +1000

    powerpc: Use an accessor for instructions
    
    In preparation for introducing a more complicated instruction type to
    accommodate prefixed instructions use an accessor for getting an
    instruction as a u32.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-8-jniethe5@gmail.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index a56dcb004396..c5e4218716e4 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2872,9 +2872,9 @@ generic_inst_dump(unsigned long adr, long count, int praddr,
 		dotted = 0;
 		last_inst = inst;
 		if (praddr)
-			printf(REG"  %.8x", adr, inst);
+			printf(REG"  %.8x", adr, ppc_inst_val(inst));
 		printf("\t");
-		dump_func(inst, adr);
+		dump_func(ppc_inst_val(inst), adr);
 		printf("\n");
 	}
 	return adr - first_adr;

commit 753462512868674a788ecc77bb96752efb818785
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:26 2020 +1000

    powerpc: Use a macro for creating instructions from u32s
    
    In preparation for instructions having a more complex data type start
    using a macro, ppc_inst(), for making an instruction out of a u32.  A
    macro is used so that instructions can be used as initializer elements.
    Currently this does nothing, but it will allow for creating a data type
    that can represent prefixed instructions.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    [mpe: Change include guard to _ASM_POWERPC_INST_H]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Alistair Popple <alistair@popple.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-7-jniethe5@gmail.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 0fa3aaeee105..a56dcb004396 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -54,6 +54,7 @@
 #include <asm/firmware.h>
 #include <asm/code-patching.h>
 #include <asm/sections.h>
+#include <asm/inst.h>
 
 #ifdef CONFIG_PPC64
 #include <asm/hvcall.h>
@@ -946,7 +947,7 @@ static void remove_bpts(void)
 		if ((bp->enabled & (BP_TRAP|BP_CIABR)) != BP_TRAP)
 			continue;
 		if (mread(bp->address, &instr, 4) == 4
-		    && instr == bpinstr
+		    && instr == ppc_inst(bpinstr)
 		    && patch_instruction(
 			(unsigned int *)bp->address, bp->instr[0]) != 0)
 			printf("Couldn't remove breakpoint at %lx\n",
@@ -2847,7 +2848,7 @@ generic_inst_dump(unsigned long adr, long count, int praddr,
 {
 	int nr, dotted;
 	unsigned long first_adr;
-	unsigned int inst, last_inst = 0;
+	unsigned int inst, last_inst = ppc_inst(0);
 	unsigned char val[4];
 
 	dotted = 0;
@@ -2860,7 +2861,7 @@ generic_inst_dump(unsigned long adr, long count, int praddr,
 			}
 			break;
 		}
-		inst = GETWORD(val);
+		inst = ppc_inst(GETWORD(val));
 		if (adr > first_adr && inst == last_inst) {
 			if (!dotted) {
 				printf(" ...\n");

commit 5a7fdcab54ef17c395fc47e73c828a1432e51683
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:24 2020 +1000

    powerpc/xmon: Use bitwise calculations in_breakpoint_table()
    
    A modulo operation is used for calculating the current offset from a
    breakpoint within the breakpoint table. As instruction lengths are
    always a power of 2, this can be replaced with a bitwise 'and'. The
    current check for word alignment can be replaced with checking that the
    lower 2 bits are not set.
    
    Suggested-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Alistair Popple <alistair@popple.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-5-jniethe5@gmail.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 948d025f2939..0fa3aaeee105 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -857,8 +857,8 @@ static struct bpt *in_breakpoint_table(unsigned long nip, unsigned long *offp)
 	off = nip - (unsigned long)bpt_table;
 	if (off >= sizeof(bpt_table))
 		return NULL;
-	*offp = off % BPT_SIZE;
-	if (*offp != 0 && *offp != 4)
+	*offp = off & (BPT_SIZE - 1);
+	if (off & 3)
 		return NULL;
 	return bpts + (off / BPT_SIZE);
 }

commit 4eff2b4f32a309e2171bfe53db3e93b5614f77cb
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:23 2020 +1000

    powerpc/xmon: Move breakpoints to text section
    
    The instructions for xmon's breakpoint are stored bpt_table[] which is in
    the data section. This is problematic as the data section may be marked
    as no execute. Move bpt_table[] to the text section.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-4-jniethe5@gmail.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index afb28ad660a7..948d025f2939 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -62,6 +62,7 @@
 
 #include "nonstdio.h"
 #include "dis-asm.h"
+#include "xmon_bpts.h"
 
 #ifdef CONFIG_SMP
 static cpumask_t cpus_in_xmon = CPU_MASK_NONE;
@@ -109,7 +110,6 @@ struct bpt {
 #define BP_TRAP		2
 #define BP_DABR		4
 
-#define NBPTS	256
 static struct bpt bpts[NBPTS];
 static struct bpt dabr;
 static struct bpt *iabr;
@@ -117,10 +117,6 @@ static unsigned bpinstr = 0x7fe00008;	/* trap */
 
 #define BP_NUM(bp)	((bp) - bpts + 1)
 
-#define BPT_SIZE       (sizeof(unsigned int) * 2)
-#define BPT_WORDS      (BPT_SIZE / sizeof(unsigned int))
-static unsigned int bpt_table[NBPTS * BPT_WORDS];
-
 /* Prototypes */
 static int cmds(struct pt_regs *);
 static int mread(unsigned long, void *, int);

commit 51c9ba11f17f25ace1ea6bbfd4586c59105432de
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:22 2020 +1000

    powerpc/xmon: Move breakpoint instructions to own array
    
    To execute an instruction out of line after a breakpoint, the NIP is set
    to the address of struct bpt::instr. Here a copy of the instruction that
    was replaced with a breakpoint is kept, along with a trap so normal flow
    can be resumed after XOLing. The struct bpt's are located within the
    data section. This is problematic as the data section may be marked as
    no execute.
    
    Instead of each struct bpt holding the instructions to be XOL'd, make a
    new array, bpt_table[], with enough space to hold instructions for the
    number of supported breakpoints. A later patch will move this to the
    text section.
    Make struct bpt::instr a pointer to the instructions in bpt_table[]
    associated with that breakpoint. This association is a simple mapping:
    bpts[n] -> bpt_table[n * words per breakpoint]. Currently we only need
    the copied instruction followed by a trap, so 2 words per breakpoint.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Alistair Popple <alistair@popple.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-3-jniethe5@gmail.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index f65cb5bafc0f..afb28ad660a7 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -98,7 +98,7 @@ static long *xmon_fault_jmp[NR_CPUS];
 /* Breakpoint stuff */
 struct bpt {
 	unsigned long	address;
-	unsigned int	instr[2];
+	unsigned int	*instr;
 	atomic_t	ref_count;
 	int		enabled;
 	unsigned long	pad;
@@ -117,6 +117,10 @@ static unsigned bpinstr = 0x7fe00008;	/* trap */
 
 #define BP_NUM(bp)	((bp) - bpts + 1)
 
+#define BPT_SIZE       (sizeof(unsigned int) * 2)
+#define BPT_WORDS      (BPT_SIZE / sizeof(unsigned int))
+static unsigned int bpt_table[NBPTS * BPT_WORDS];
+
 /* Prototypes */
 static int cmds(struct pt_regs *);
 static int mread(unsigned long, void *, int);
@@ -854,15 +858,13 @@ static struct bpt *in_breakpoint_table(unsigned long nip, unsigned long *offp)
 {
 	unsigned long off;
 
-	off = nip - (unsigned long) bpts;
-	if (off >= sizeof(bpts))
+	off = nip - (unsigned long)bpt_table;
+	if (off >= sizeof(bpt_table))
 		return NULL;
-	off %= sizeof(struct bpt);
-	if (off != offsetof(struct bpt, instr[0])
-	    && off != offsetof(struct bpt, instr[1]))
+	*offp = off % BPT_SIZE;
+	if (*offp != 0 && *offp != 4)
 		return NULL;
-	*offp = off - offsetof(struct bpt, instr[0]);
-	return (struct bpt *) (nip - off);
+	return bpts + (off / BPT_SIZE);
 }
 
 static struct bpt *new_breakpoint(unsigned long a)
@@ -877,7 +879,8 @@ static struct bpt *new_breakpoint(unsigned long a)
 	for (bp = bpts; bp < &bpts[NBPTS]; ++bp) {
 		if (!bp->enabled && atomic_read(&bp->ref_count) == 0) {
 			bp->address = a;
-			patch_instruction(&bp->instr[1], bpinstr);
+			bp->instr = bpt_table + ((bp - bpts) * BPT_WORDS);
+			patch_instruction(bp->instr + 1, bpinstr);
 			return bp;
 		}
 	}

commit 802268fd82676ffce432776f60b93a0b15e58e0c
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:21 2020 +1000

    powerpc/xmon: Remove store_inst() for patch_instruction()
    
    For modifying instructions in xmon, patch_instruction() can serve the
    same role that store_inst() is performing with the advantage of not
    being specific to xmon. In some places patch_instruction() is already
    being using followed by store_inst(). In these cases just remove the
    store_inst(). Otherwise replace store_inst() with patch_instruction().
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    Link: https://lore.kernel.org/r/20200506034050.24806-2-jniethe5@gmail.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index a7430632bab4..f65cb5bafc0f 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -326,11 +326,6 @@ static inline void sync(void)
 	asm volatile("sync; isync");
 }
 
-static inline void store_inst(void *p)
-{
-	asm volatile ("dcbst 0,%0; sync; icbi 0,%0; isync" : : "r" (p));
-}
-
 static inline void cflush(void *p)
 {
 	asm volatile ("dcbf 0,%0; icbi 0,%0" : : "r" (p));
@@ -882,8 +877,7 @@ static struct bpt *new_breakpoint(unsigned long a)
 	for (bp = bpts; bp < &bpts[NBPTS]; ++bp) {
 		if (!bp->enabled && atomic_read(&bp->ref_count) == 0) {
 			bp->address = a;
-			bp->instr[1] = bpinstr;
-			store_inst(&bp->instr[1]);
+			patch_instruction(&bp->instr[1], bpinstr);
 			return bp;
 		}
 	}
@@ -895,25 +889,26 @@ static struct bpt *new_breakpoint(unsigned long a)
 static void insert_bpts(void)
 {
 	int i;
+	unsigned int instr;
 	struct bpt *bp;
 
 	bp = bpts;
 	for (i = 0; i < NBPTS; ++i, ++bp) {
 		if ((bp->enabled & (BP_TRAP|BP_CIABR)) == 0)
 			continue;
-		if (mread(bp->address, &bp->instr[0], 4) != 4) {
+		if (mread(bp->address, &instr, 4) != 4) {
 			printf("Couldn't read instruction at %lx, "
 			       "disabling breakpoint there\n", bp->address);
 			bp->enabled = 0;
 			continue;
 		}
-		if (IS_MTMSRD(bp->instr[0]) || IS_RFID(bp->instr[0])) {
+		if (IS_MTMSRD(instr) || IS_RFID(instr)) {
 			printf("Breakpoint at %lx is on an mtmsrd or rfid "
 			       "instruction, disabling it\n", bp->address);
 			bp->enabled = 0;
 			continue;
 		}
-		store_inst(&bp->instr[0]);
+		patch_instruction(bp->instr, instr);
 		if (bp->enabled & BP_CIABR)
 			continue;
 		if (patch_instruction((unsigned int *)bp->address,
@@ -923,7 +918,6 @@ static void insert_bpts(void)
 			bp->enabled &= ~BP_TRAP;
 			continue;
 		}
-		store_inst((void *)bp->address);
 	}
 }
 
@@ -958,8 +952,6 @@ static void remove_bpts(void)
 			(unsigned int *)bp->address, bp->instr[0]) != 0)
 			printf("Couldn't remove breakpoint at %lx\n",
 			       bp->address);
-		else
-			store_inst((void *)bp->address);
 	}
 }
 

commit fff134c2e8dd948de595ab21575fd66d5ddabb3d
Author: Emil Velikov <emil.l.velikov@gmail.com>
Date:   Wed May 13 22:43:46 2020 +0100

    powerpc/xmon: constify sysrq_key_op
    
    With earlier commits, the API no longer discards the const-ness of the
    sysrq_key_op. As such we can add the notation.
    
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Jiri Slaby <jslaby@suse.com>
    Cc: linux-kernel@vger.kernel.org
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: linuxppc-dev@lists.ozlabs.org
    Acked-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Emil Velikov <emil.l.velikov@gmail.com>
    Link: https://lore.kernel.org/r/20200513214351.2138580-6-emil.l.velikov@gmail.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 7af840c0fc93..0d8ca5c9f131 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -3842,7 +3842,7 @@ static void sysrq_handle_xmon(int key)
 		xmon_init(0);
 }
 
-static struct sysrq_key_op sysrq_xmon_op = {
+static const struct sysrq_key_op sysrq_xmon_op = {
 	.handler =	sysrq_handle_xmon,
 	.help_msg =	"xmon(x)",
 	.action_msg =	"Entering xmon",

commit 912237ea166428edcbf3c137adf12cb987c477f2
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Thu May 7 22:13:31 2020 +1000

    powerpc: trap_is_syscall() helper to hide syscall trap number
    
    A new system call interrupt will be added with a new trap number.
    Hide the explicit 0xc00 test behind an accessor to reduce churn
    in callers.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Make it a static inline]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200507121332.2233629-3-mpe@ellerman.id.au

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 92761e47fb5c..a7430632bab4 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1776,7 +1776,7 @@ static void prregs(struct pt_regs *fp)
 #endif
 	printf("pc  = ");
 	xmon_print_symbol(fp->nip, " ", "\n");
-	if (TRAP(fp) != 0xc00 && cpu_has_feature(CPU_FTR_CFAR)) {
+	if (!trap_is_syscall(fp) && cpu_has_feature(CPU_FTR_CFAR)) {
 		printf("cfar= ");
 		xmon_print_symbol(fp->orig_gpr3, " ", "\n");
 	}

commit db30144b5c9cfb09c6b8b2fa7a9c351c94aa3433
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Thu May 7 22:13:30 2020 +1000

    powerpc: Use set_trap() and avoid open-coding trap masking
    
    The pt_regs.trap field keeps 4 low bits for some metadata about the
    trap or how it was handled, which is masked off in order to test the
    architectural trap number.
    
    Add a set_trap() accessor to set this, equivalent to TRAP() for
    returning it. This is actually not quite the equivalent of TRAP()
    because it always clears the low bits, which may be harmless if
    it can only be updated via ptrace syscall, but it seems dangerous.
    
    In fact settting TRAP from ptrace doesn't seem like a great idea
    so maybe it's better deleted.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Make it a static inline rather than a shouty macro]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200507121332.2233629-2-mpe@ellerman.id.au

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 7af840c0fc93..92761e47fb5c 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1178,7 +1178,7 @@ static int do_step(struct pt_regs *regs)
 				return 0;
 			}
 			if (stepped > 0) {
-				regs->trap = 0xd00 | (regs->trap & 1);
+				set_trap(regs, 0xd00);
 				printf("stepped to ");
 				xmon_print_symbol(regs->nip, " ", "\n");
 				ppc_inst_dump(regs->nip, 1, 0);

commit 8ec26c25c33d21468a8b39722337463550b15e5b
Author: Douglas Miller <dougmill@linux.vnet.ibm.com>
Date:   Mon Feb 27 08:28:14 2017 -0600

    powerpc/xmon: Add ASCII dump to d1,d2,d4,d8 commands.
    
    The reason debuggers add an ASCII dump to other types of memory dumps
    is to give the user visual reference points in the case that ASCII
    strings are adjacent to other structures or element.  For example,
    when examining the task_struct structure one can look for the comm[]
    string and use it to locate other important elements.
    
    ASCII strings do not have endianess, they exist in memory in the same
    order regardless of CPU endianess. ASCII strings are, by definition,
    human readable and so should be presented in a human readable format.
    
    For these reasons, the supplemental ASCII dump does not re-order
    the strings from memory to match the endianess of the corresponding
    16, 32, or 64 bit words. That would make the ASCII dump much less
    useful.
    
    Signed-off-by: Douglas Miller <dougmill@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/1488205694-13337-1-git-send-email-dougmill@linux.vnet.ibm.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index ea303b7e4e29..7af840c0fc93 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2713,7 +2713,12 @@ static void dump_by_size(unsigned long addr, long count, int size)
 
 			printf("%0*llx", size * 2, val);
 		}
-		printf("\n");
+		printf("  |");
+		for (j = 0; j < 16; ++j) {
+			val = temp[j];
+			putchar(' ' <= val && val <= '~' ? val : '.');
+		}
+		printf("|\n");
 	}
 }
 

commit d64c7dbb4d98306b794401ca924ad053f84b59f8
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Feb 19 22:00:07 2020 +1100

    powerpc/xmon: Lower limits on nidump and ndump
    
    In xmon we have two variables that are used by the dump commands.
    There's ndump which is the number of bytes to dump using 'd', and
    nidump which is the number of instructions to dump using 'di'.
    
    ndump starts as 64 and nidump starts as 16, but both can be set by the
    user.
    
    It's fairly common to be pasting addresses into xmon when trying to
    debug something, and if you inadvertently double paste an address like
    so:
    
      0:mon> di c000000002101f6c c000000002101f6c
    
    The second value is interpreted as the number of instructions to dump.
    
    Luckily it doesn't dump 13 quintrillion instructions, the value is
    limited to MAX_DUMP (128K). But as each instruction is dumped on a
    single line, that's still a lot of output. If you're on a slow console
    that can take multiple minutes to print. If you were "just popping in
    and out of xmon quickly before the RCU/hardlockup detector fires" you
    are now having a bad day.
    
    Things are not as bad with 'd' because we print 16 bytes per line, so
    it's fewer lines. But it's still quite a lot.
    
    So shrink the maximum for 'd' to 64K (one page), which is 4096 lines.
    For 'di' add a new limit which is the above / 4 - because instructions
    are 4 bytes, meaning again we can dump one page.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200219110007.31195-1-mpe@ellerman.id.au

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 0ec9640335bb..ea303b7e4e29 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -81,8 +81,9 @@ static bool xmon_is_ro = IS_ENABLED(CONFIG_XMON_DEFAULT_RO_MODE);
 
 static unsigned long adrs;
 static int size = 1;
-#define MAX_DUMP (128 * 1024)
+#define MAX_DUMP (64 * 1024)
 static unsigned long ndump = 64;
+#define MAX_IDUMP (MAX_DUMP >> 2)
 static unsigned long nidump = 16;
 static unsigned long ncsum = 4096;
 static int termch;
@@ -2756,8 +2757,8 @@ dump(void)
 		scanhex(&nidump);
 		if (nidump == 0)
 			nidump = 16;
-		else if (nidump > MAX_DUMP)
-			nidump = MAX_DUMP;
+		else if (nidump > MAX_IDUMP)
+			nidump = MAX_IDUMP;
 		adrs += ppc_inst_dump(adrs, nidump, 1);
 		last_cmd = "di\n";
 	} else if (c == 'l') {

commit 066bc3576e653b615ee3f5230a89d69c8ebeeb71
Author: Oliver O'Halloran <oohall@gmail.com>
Date:   Mon Feb 17 15:13:43 2020 +1100

    powerpc/xmon: Fix whitespace handling in getstring()
    
    The ls (lookup symbol) and zr (reboot) commands use xmon's getstring()
    helper to read a string argument from the xmon prompt. This function
    skips over leading whitespace, but doesn't check if the first
    "non-whitespace" character is a newline which causes some odd
    behaviour (<enter> indicates a the enter key was pressed):
    
      0:mon> ls printk<enter>
      printk: c0000000001680c4
    
      0:mon> ls<enter>
      printk<enter>
      Symbol '
      printk' not found.
      0:mon>
    
    With commit 2d9b332d99b ("powerpc/xmon: Allow passing an argument to
    ppc_md.restart()") we have a similar problem with the zr command.
    Previously zr took no arguments so "zr<enter> would trigger a reboot.
    With that patch applied a second newline needs to be sent in order for
    the reboot to occur. Fix this by checking if the leading whitespace
    ended on a newline:
    
      0:mon> ls<enter>
      Symbol '' not found.
    
    Fixes: 2d9b332d99b2 ("powerpc/xmon: Allow passing an argument to ppc_md.restart()")
    Reported-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Oliver O'Halloran <oohall@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200217041343.2454-1-oohall@gmail.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index e8c84d265602..0ec9640335bb 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -3435,6 +3435,11 @@ getstring(char *s, int size)
 	int c;
 
 	c = skipbl();
+	if (c == '\n') {
+		*s = 0;
+		return;
+	}
+
 	do {
 		if( size > 1 ){
 			*s++ = c;

commit 2d9b332d99b24f27f77e9ba38ce3c8beb11a81c0
Author: Oliver O'Halloran <oohall@gmail.com>
Date:   Fri Nov 1 19:55:21 2019 +1100

    powerpc/xmon: Allow passing an argument to ppc_md.restart()
    
    On PowerNV a few different kinds of reboot are supported. We'd like to be
    able to exercise these from xmon so allow 'zr' to take an argument, and
    pass that to the ppc_md.restart() function.
    
    Signed-off-by: Oliver O'Halloran <oohall@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20191101085522.3055-1-oohall@gmail.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 03d23075ac43..e8c84d265602 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1192,16 +1192,19 @@ static int do_step(struct pt_regs *regs)
 
 static void bootcmds(void)
 {
+	char tmp[64];
 	int cmd;
 
 	cmd = inchar();
-	if (cmd == 'r')
-		ppc_md.restart(NULL);
-	else if (cmd == 'h')
+	if (cmd == 'r') {
+		getstring(tmp, 64);
+		ppc_md.restart(tmp);
+	} else if (cmd == 'h') {
 		ppc_md.halt();
-	else if (cmd == 'p')
+	} else if (cmd == 'p') {
 		if (pm_power_off)
 			pm_power_off();
+	}
 }
 
 static int cpu_cmd(void)

commit c2a20711fc181e7f22ee5c16c28cb9578af84729
Author: Sukadev Bhattiprolu <sukadev@linux.ibm.com>
Date:   Mon Jan 6 13:50:02 2020 -0600

    powerpc/xmon: don't access ASDR in VMs
    
    ASDR is HV-privileged and must only be accessed in HV-mode.
    Fixes a Program Check (0x700) when xmon in a VM dumps SPRs.
    
    Fixes: d1e1b351f50f ("powerpc/xmon: Add ISA v3.0 SPRs to SPR dump")
    Cc: stable@vger.kernel.org # v4.14+
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.ibm.com>
    Reviewed-by: Andrew Donnellan <ajd@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200107021633.GB29843@us.ibm.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index a7056049709e..03d23075ac43 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1949,15 +1949,14 @@ static void dump_300_sprs(void)
 
 	printf("pidr   = %.16lx  tidr  = %.16lx\n",
 		mfspr(SPRN_PID), mfspr(SPRN_TIDR));
-	printf("asdr   = %.16lx  psscr = %.16lx\n",
-		mfspr(SPRN_ASDR), hv ? mfspr(SPRN_PSSCR)
-					: mfspr(SPRN_PSSCR_PR));
+	printf("psscr  = %.16lx\n",
+		hv ? mfspr(SPRN_PSSCR) : mfspr(SPRN_PSSCR_PR));
 
 	if (!hv)
 		return;
 
-	printf("ptcr   = %.16lx\n",
-		mfspr(SPRN_PTCR));
+	printf("ptcr   = %.16lx  asdr  = %.16lx\n",
+		mfspr(SPRN_PTCR), mfspr(SPRN_ASDR));
 #endif
 }
 

commit b811be615cb78c90fca42bbd5b958427d03ba7e0
Author: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
Date:   Thu Oct 17 15:01:58 2019 +0530

    powerpc/watchpoint: Introduce macros for watchpoint length
    
    We are hadrcoding length everywhere in the watchpoint code. Introduce
    macros for the length and use them.
    
    Signed-off-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20191017093204.7511-2-ravi.bangoria@linux.ibm.com

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 0a438b51dbb5..a7056049709e 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -933,7 +933,7 @@ static void insert_cpu_bpts(void)
 	if (dabr.enabled) {
 		brk.address = dabr.address;
 		brk.type = (dabr.enabled & HW_BRK_TYPE_DABR) | HW_BRK_TYPE_PRIV_ALL;
-		brk.len = 8;
+		brk.len = DABR_MAX_LEN;
 		__set_breakpoint(&brk);
 	}
 

commit 69393cb03ccdf29f3b452d3482ef918469d1c098
Author: Christopher M. Riedl <cmr@informatik.wtf>
Date:   Sat Sep 7 01:11:24 2019 -0500

    powerpc/xmon: Restrict when kernel is locked down
    
    Xmon should be either fully or partially disabled depending on the
    kernel lockdown state.
    
    Put xmon into read-only mode for lockdown=integrity and prevent user
    entry into xmon when lockdown=confidentiality. Xmon checks the lockdown
    state on every attempted entry:
    
     (1) during early xmon'ing
    
     (2) when triggered via sysrq
    
     (3) when toggled via debugfs
    
     (4) when triggered via a previously enabled breakpoint
    
    The following lockdown state transitions are handled:
    
     (1) lockdown=none -> lockdown=integrity
         set xmon read-only mode
    
     (2) lockdown=none -> lockdown=confidentiality
         clear all breakpoints, set xmon read-only mode,
         prevent user re-entry into xmon
    
     (3) lockdown=integrity -> lockdown=confidentiality
         clear all breakpoints, set xmon read-only mode,
         prevent user re-entry into xmon
    
    Suggested-by: Andrew Donnellan <ajd@linux.ibm.com>
    Signed-off-by: Christopher M. Riedl <cmr@informatik.wtf>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190907061124.1947-3-cmr@informatik.wtf

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 0a0d84261678..0a438b51dbb5 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -25,6 +25,7 @@
 #include <linux/nmi.h>
 #include <linux/ctype.h>
 #include <linux/highmem.h>
+#include <linux/security.h>
 
 #include <asm/debugfs.h>
 #include <asm/ptrace.h>
@@ -187,6 +188,8 @@ static void dump_tlb_44x(void);
 static void dump_tlb_book3e(void);
 #endif
 
+static void clear_all_bpt(void);
+
 #ifdef CONFIG_PPC64
 #define REG		"%.16lx"
 #else
@@ -283,10 +286,38 @@ Commands:\n\
 "  U	show uptime information\n"
 "  ?	help\n"
 "  # n	limit output to n lines per page (for dp, dpa, dl)\n"
-"  zr	reboot\n\
-  zh	halt\n"
+"  zr	reboot\n"
+"  zh	halt\n"
 ;
 
+#ifdef CONFIG_SECURITY
+static bool xmon_is_locked_down(void)
+{
+	static bool lockdown;
+
+	if (!lockdown) {
+		lockdown = !!security_locked_down(LOCKDOWN_XMON_RW);
+		if (lockdown) {
+			printf("xmon: Disabled due to kernel lockdown\n");
+			xmon_is_ro = true;
+		}
+	}
+
+	if (!xmon_is_ro) {
+		xmon_is_ro = !!security_locked_down(LOCKDOWN_XMON_WR);
+		if (xmon_is_ro)
+			printf("xmon: Read-only due to kernel lockdown\n");
+	}
+
+	return lockdown;
+}
+#else /* CONFIG_SECURITY */
+static inline bool xmon_is_locked_down(void)
+{
+	return false;
+}
+#endif
+
 static struct pt_regs *xmon_regs;
 
 static inline void sync(void)
@@ -438,7 +469,10 @@ static bool wait_for_other_cpus(int ncpus)
 
 	return false;
 }
-#endif /* CONFIG_SMP */
+#else /* CONFIG_SMP */
+static inline void get_output_lock(void) {}
+static inline void release_output_lock(void) {}
+#endif
 
 static inline int unrecoverable_excp(struct pt_regs *regs)
 {
@@ -455,6 +489,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 	int cmd = 0;
 	struct bpt *bp;
 	long recurse_jmp[JMP_BUF_LEN];
+	bool locked_down;
 	unsigned long offset;
 	unsigned long flags;
 #ifdef CONFIG_SMP
@@ -465,6 +500,8 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 	local_irq_save(flags);
 	hard_irq_disable();
 
+	locked_down = xmon_is_locked_down();
+
 	if (!fromipi) {
 		tracing_enabled = tracing_is_on();
 		tracing_off();
@@ -518,7 +555,8 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 
 	if (!fromipi) {
 		get_output_lock();
-		excprint(regs);
+		if (!locked_down)
+			excprint(regs);
 		if (bp) {
 			printf("cpu 0x%x stopped at breakpoint 0x%tx (",
 			       cpu, BP_NUM(bp));
@@ -570,10 +608,14 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 		}
 		remove_bpts();
 		disable_surveillance();
-		/* for breakpoint or single step, print the current instr. */
-		if (bp || TRAP(regs) == 0xd00)
-			ppc_inst_dump(regs->nip, 1, 0);
-		printf("enter ? for help\n");
+
+		if (!locked_down) {
+			/* for breakpoint or single step, print curr insn */
+			if (bp || TRAP(regs) == 0xd00)
+				ppc_inst_dump(regs->nip, 1, 0);
+			printf("enter ? for help\n");
+		}
+
 		mb();
 		xmon_gate = 1;
 		barrier();
@@ -597,8 +639,9 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 			spin_cpu_relax();
 			touch_nmi_watchdog();
 		} else {
-			cmd = cmds(regs);
-			if (cmd != 0) {
+			if (!locked_down)
+				cmd = cmds(regs);
+			if (locked_down || cmd != 0) {
 				/* exiting xmon */
 				insert_bpts();
 				xmon_gate = 0;
@@ -635,13 +678,16 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 			       "can't continue\n");
 		remove_bpts();
 		disable_surveillance();
-		/* for breakpoint or single step, print the current instr. */
-		if (bp || TRAP(regs) == 0xd00)
-			ppc_inst_dump(regs->nip, 1, 0);
-		printf("enter ? for help\n");
+		if (!locked_down) {
+			/* for breakpoint or single step, print current insn */
+			if (bp || TRAP(regs) == 0xd00)
+				ppc_inst_dump(regs->nip, 1, 0);
+			printf("enter ? for help\n");
+		}
 	}
 
-	cmd = cmds(regs);
+	if (!locked_down)
+		cmd = cmds(regs);
 
 	insert_bpts();
 	in_xmon = 0;
@@ -670,7 +716,10 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 		}
 	}
 #endif
-	insert_cpu_bpts();
+	if (locked_down)
+		clear_all_bpt();
+	else
+		insert_cpu_bpts();
 
 	touch_nmi_watchdog();
 	local_irq_restore(flags);
@@ -3768,6 +3817,11 @@ static void xmon_init(int enable)
 #ifdef CONFIG_MAGIC_SYSRQ
 static void sysrq_handle_xmon(int key)
 {
+	if (xmon_is_locked_down()) {
+		clear_all_bpt();
+		xmon_init(0);
+		return;
+	}
 	/* ensure xmon is enabled */
 	xmon_init(1);
 	debugger(get_irq_regs());
@@ -3789,7 +3843,6 @@ static int __init setup_xmon_sysrq(void)
 device_initcall(setup_xmon_sysrq);
 #endif /* CONFIG_MAGIC_SYSRQ */
 
-#ifdef CONFIG_DEBUG_FS
 static void clear_all_bpt(void)
 {
 	int i;
@@ -3807,18 +3860,22 @@ static void clear_all_bpt(void)
 		iabr = NULL;
 		dabr.enabled = 0;
 	}
-
-	printf("xmon: All breakpoints cleared\n");
 }
 
+#ifdef CONFIG_DEBUG_FS
 static int xmon_dbgfs_set(void *data, u64 val)
 {
 	xmon_on = !!val;
 	xmon_init(xmon_on);
 
 	/* make sure all breakpoints removed when disabling */
-	if (!xmon_on)
+	if (!xmon_on) {
 		clear_all_bpt();
+		get_output_lock();
+		printf("xmon: All breakpoints cleared\n");
+		release_output_lock();
+	}
+
 	return 0;
 }
 
@@ -3844,7 +3901,11 @@ static int xmon_early __initdata;
 
 static int __init early_parse_xmon(char *p)
 {
-	if (!p || strncmp(p, "early", 5) == 0) {
+	if (xmon_is_locked_down()) {
+		xmon_init(0);
+		xmon_early = 0;
+		xmon_on = 0;
+	} else if (!p || strncmp(p, "early", 5) == 0) {
 		/* just "xmon" is equivalent to "xmon=early" */
 		xmon_init(1);
 		xmon_early = 1;

commit 96664dee5cf1815777286227b09884b4f019727f
Author: Christopher M. Riedl <cmr@informatik.wtf>
Date:   Sat Sep 7 01:11:23 2019 -0500

    powerpc/xmon: Allow listing and clearing breakpoints in read-only mode
    
    Read-only mode should not prevent listing and clearing any active
    breakpoints.
    
    Tested-by: Daniel Axtens <dja@axtens.net>
    Reviewed-by: Daniel Axtens <dja@axtens.net>
    Signed-off-by: Christopher M. Riedl <cmr@informatik.wtf>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190907061124.1947-2-cmr@informatik.wtf

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index d83364ebc5c5..0a0d84261678 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1047,10 +1047,6 @@ cmds(struct pt_regs *excp)
 			set_lpp_cmd();
 			break;
 		case 'b':
-			if (xmon_is_ro) {
-				printf(xmon_ro_msg);
-				break;
-			}
 			bpt_cmds();
 			break;
 		case 'C':
@@ -1319,11 +1315,16 @@ bpt_cmds(void)
 	struct bpt *bp;
 
 	cmd = inchar();
+
 	switch (cmd) {
 #ifndef CONFIG_PPC_8xx
 	static const char badaddr[] = "Only kernel addresses are permitted for breakpoints\n";
 	int mode;
 	case 'd':	/* bd - hardware data breakpoint */
+		if (xmon_is_ro) {
+			printf(xmon_ro_msg);
+			break;
+		}
 		if (!ppc_breakpoint_available()) {
 			printf("Hardware data breakpoint not supported on this cpu\n");
 			break;
@@ -1351,6 +1352,10 @@ bpt_cmds(void)
 		break;
 
 	case 'i':	/* bi - hardware instr breakpoint */
+		if (xmon_is_ro) {
+			printf(xmon_ro_msg);
+			break;
+		}
 		if (!cpu_has_feature(CPU_FTR_ARCH_207S)) {
 			printf("Hardware instruction breakpoint "
 			       "not supported on this cpu\n");
@@ -1409,7 +1414,8 @@ bpt_cmds(void)
 			break;
 		}
 		termch = cmd;
-		if (!scanhex(&a)) {
+
+		if (xmon_is_ro || !scanhex(&a)) {
 			/* print all breakpoints */
 			printf("   type            address\n");
 			if (dabr.enabled) {

commit 5896163f7f91c0560cc41908c808661eee4c4121
Author: CÃ©dric Le Goater <clg@kaod.org>
Date:   Tue Sep 10 10:18:49 2019 +0200

    powerpc/xmon: Improve output of XIVE interrupts
    
    When looping on the list of interrupts, add the current value of the
    PQ bits with a load on the ESB page. This has the side effect of
    faulting the ESB page of all interrupts.
    
    Signed-off-by: CÃ©dric Le Goater <clg@kaod.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190910081850.26038-2-clg@kaod.org

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index dc9832e06256..d83364ebc5c5 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2572,16 +2572,9 @@ static void dump_all_xives(void)
 		dump_one_xive(cpu);
 }
 
-static void dump_one_xive_irq(u32 num)
+static void dump_one_xive_irq(u32 num, struct irq_data *d)
 {
-	int rc;
-	u32 target;
-	u8 prio;
-	u32 lirq;
-
-	rc = xmon_xive_get_irq_config(num, &target, &prio, &lirq);
-	xmon_printf("IRQ 0x%08x : target=0x%x prio=%d lirq=0x%x (rc=%d)\n",
-		    num, target, prio, lirq, rc);
+	xmon_xive_get_irq_config(num, d);
 }
 
 static void dump_all_xive_irq(void)
@@ -2599,7 +2592,7 @@ static void dump_all_xive_irq(void)
 		hwirq = (unsigned int)irqd_to_hwirq(d);
 		/* IPIs are special (HW number 0) */
 		if (hwirq)
-			dump_one_xive_irq(hwirq);
+			dump_one_xive_irq(hwirq, d);
 	}
 }
 
@@ -2619,7 +2612,7 @@ static void dump_xives(void)
 		return;
 	} else if (c == 'i') {
 		if (scanhex(&num))
-			dump_one_xive_irq(num);
+			dump_one_xive_irq(num, NULL);
 		else
 			dump_all_xive_irq();
 		return;

commit 39f14e79b15a40709ef177bc4c07f193b6d3bce3
Author: CÃ©dric Le Goater <clg@kaod.org>
Date:   Wed Aug 14 17:47:54 2019 +0200

    powerpc/xmon: Add a dump of all XIVE interrupts
    
    Modify the xmon 'dxi' command to query all interrupts if no IRQ number
    is specified.
    
    Signed-off-by: CÃ©dric Le Goater <clg@kaod.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190814154754.23682-4-clg@kaod.org

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 4ea53e05053f..dc9832e06256 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2584,6 +2584,25 @@ static void dump_one_xive_irq(u32 num)
 		    num, target, prio, lirq, rc);
 }
 
+static void dump_all_xive_irq(void)
+{
+	unsigned int i;
+	struct irq_desc *desc;
+
+	for_each_irq_desc(i, desc) {
+		struct irq_data *d = irq_desc_get_irq_data(desc);
+		unsigned int hwirq;
+
+		if (!d)
+			continue;
+
+		hwirq = (unsigned int)irqd_to_hwirq(d);
+		/* IPIs are special (HW number 0) */
+		if (hwirq)
+			dump_one_xive_irq(hwirq);
+	}
+}
+
 static void dump_xives(void)
 {
 	unsigned long num;
@@ -2601,6 +2620,8 @@ static void dump_xives(void)
 	} else if (c == 'i') {
 		if (scanhex(&num))
 			dump_one_xive_irq(num);
+		else
+			dump_all_xive_irq();
 		return;
 	}
 

commit b4868ff55d082bc66b0c287a41e4888f6d3e5f87
Author: CÃ©dric Le Goater <clg@kaod.org>
Date:   Wed Aug 14 17:47:53 2019 +0200

    powerpc/xive: Fix dump of XIVE interrupt under pseries
    
    The xmon 'dxi' command calls OPAL to query the XIVE configuration of a
    interrupt. This can only be done on baremetal (PowerNV) and it will
    crash a pseries machine.
    
    Introduce a new XIVE get_irq_config() operation which implements a
    different query depending on the platform, PowerNV or pseries, and
    modify xmon to use a top level wrapper.
    
    Signed-off-by: CÃ©dric Le Goater <clg@kaod.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190814154754.23682-3-clg@kaod.org

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 25d4adccf750..4ea53e05053f 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2574,14 +2574,14 @@ static void dump_all_xives(void)
 
 static void dump_one_xive_irq(u32 num)
 {
-	s64 rc;
-	__be64 vp;
+	int rc;
+	u32 target;
 	u8 prio;
-	__be32 lirq;
+	u32 lirq;
 
-	rc = opal_xive_get_irq_config(num, &vp, &prio, &lirq);
-	xmon_printf("IRQ 0x%x config: vp=0x%llx prio=%d lirq=0x%x (rc=%lld)\n",
-		    num, be64_to_cpu(vp), prio, be32_to_cpu(lirq), rc);
+	rc = xmon_xive_get_irq_config(num, &target, &prio, &lirq);
+	xmon_printf("IRQ 0x%08x : target=0x%x prio=%d lirq=0x%x (rc=%d)\n",
+		    num, target, prio, lirq, rc);
 }
 
 static void dump_xives(void)

commit c3e0dbd7f780a58c4695f1cd8fc8afde80376737
Author: CÃ©dric Le Goater <clg@kaod.org>
Date:   Wed Aug 14 17:47:52 2019 +0200

    powerpc/xmon: Check for HV mode when dumping XIVE info from OPAL
    
    Currently, the xmon 'dx' command calls OPAL to dump the XIVE state in
    the OPAL logs and also outputs some of the fields of the internal XIVE
    structures in Linux. The OPAL calls can only be done on baremetal
    (PowerNV) and they crash a pseries machine. Fix by checking the
    hypervisor feature of the CPU.
    
    Signed-off-by: CÃ©dric Le Goater <clg@kaod.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190814154754.23682-2-clg@kaod.org

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 14e56c25879f..25d4adccf750 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2534,13 +2534,16 @@ static void dump_pacas(void)
 static void dump_one_xive(int cpu)
 {
 	unsigned int hwid = get_hard_smp_processor_id(cpu);
-
-	opal_xive_dump(XIVE_DUMP_TM_HYP, hwid);
-	opal_xive_dump(XIVE_DUMP_TM_POOL, hwid);
-	opal_xive_dump(XIVE_DUMP_TM_OS, hwid);
-	opal_xive_dump(XIVE_DUMP_TM_USER, hwid);
-	opal_xive_dump(XIVE_DUMP_VP, hwid);
-	opal_xive_dump(XIVE_DUMP_EMU_STATE, hwid);
+	bool hv = cpu_has_feature(CPU_FTR_HVMODE);
+
+	if (hv) {
+		opal_xive_dump(XIVE_DUMP_TM_HYP, hwid);
+		opal_xive_dump(XIVE_DUMP_TM_POOL, hwid);
+		opal_xive_dump(XIVE_DUMP_TM_OS, hwid);
+		opal_xive_dump(XIVE_DUMP_TM_USER, hwid);
+		opal_xive_dump(XIVE_DUMP_VP, hwid);
+		opal_xive_dump(XIVE_DUMP_EMU_STATE, hwid);
+	}
 
 	if (setjmp(bus_error_jmp) != 0) {
 		catch_memory_errors = 0;

commit 192f0f8e9db7efe4ac98d47f5fa4334e43c1204d
Merge: ec9249752465 f5a9e488d623
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jul 13 16:08:36 2019 -0700

    Merge tag 'powerpc-5.3-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Notable changes:
    
       - Removal of the NPU DMA code, used by the out-of-tree Nvidia driver,
         as well as some other functions only used by drivers that haven't
         (yet?) made it upstream.
    
       - A fix for a bug in our handling of hardware watchpoints (eg. perf
         record -e mem: ...) which could lead to register corruption and
         kernel crashes.
    
       - Enable HAVE_ARCH_HUGE_VMAP, which allows us to use large pages for
         vmalloc when using the Radix MMU.
    
       - A large but incremental rewrite of our exception handling code to
         use gas macros rather than multiple levels of nested CPP macros.
    
      And the usual small fixes, cleanups and improvements.
    
      Thanks to: Alastair D'Silva, Alexey Kardashevskiy, Andreas Schwab,
      Aneesh Kumar K.V, Anju T Sudhakar, Anton Blanchard, Arnd Bergmann,
      Athira Rajeev, CÃ©dric Le Goater, Christian Lamparter, Christophe
      Leroy, Christophe Lombard, Christoph Hellwig, Daniel Axtens, Denis
      Efremov, Enrico Weigelt, Frederic Barrat, Gautham R. Shenoy, Geert
      Uytterhoeven, Geliang Tang, Gen Zhang, Greg Kroah-Hartman, Greg Kurz,
      Gustavo Romero, Krzysztof Kozlowski, Madhavan Srinivasan, Masahiro
      Yamada, Mathieu Malaterre, Michael Neuling, Nathan Lynch, Naveen N.
      Rao, Nicholas Piggin, Nishad Kamdar, Oliver O'Halloran, Qian Cai, Ravi
      Bangoria, Sachin Sant, Sam Bobroff, Satheesh Rajendran, Segher
      Boessenkool, Shaokun Zhang, Shawn Anastasio, Stewart Smith, Suraj
      Jitindar Singh, Thiago Jung Bauermann, YueHaibing"
    
    * tag 'powerpc-5.3-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (163 commits)
      powerpc/powernv/idle: Fix restore of SPRN_LDBAR for POWER9 stop state.
      powerpc/eeh: Handle hugepages in ioremap space
      ocxl: Update for AFU descriptor template version 1.1
      powerpc/boot: pass CONFIG options in a simpler and more robust way
      powerpc/boot: add {get, put}_unaligned_be32 to xz_config.h
      powerpc/irq: Don't WARN continuously in arch_local_irq_restore()
      powerpc/module64: Use symbolic instructions names.
      powerpc/module32: Use symbolic instructions names.
      powerpc: Move PPC_HA() PPC_HI() and PPC_LO() to ppc-opcode.h
      powerpc/module64: Fix comment in R_PPC64_ENTRY handling
      powerpc/boot: Add lzo support for uImage
      powerpc/boot: Add lzma support for uImage
      powerpc/boot: don't force gzipped uImage
      powerpc/8xx: Add microcode patch to move SMC parameter RAM.
      powerpc/8xx: Use IO accessors in microcode programming.
      powerpc/8xx: replace #ifdefs by IS_ENABLED() in microcode.c
      powerpc/8xx: refactor programming of microcode CPM params.
      powerpc/8xx: refactor printing of microcode patch name.
      powerpc/8xx: Refactor microcode write
      powerpc/8xx: refactor writing of CPM microcode arrays
      ...

commit d6eacedd1f0ebf00bdf1c77715d194f7c1036fd4
Author: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
Date:   Tue May 14 11:33:00 2019 +0530

    powerpc/book3s: Use config independent helpers for page table walk
    
    Even when we have HugeTLB and THP disabled, kernel linear map can still be
    mapped with hugepages. This is only an issue with radix translation because hash
    MMU doesn't map kernel linear range in linux page table and other kernel
    map areas are not mapped using hugepage.
    
    Add config independent helpers and put WARN_ON() when we don't expect things
    to be mapped via hugepages.
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index f879e9fe9733..2ec20a5bb556 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -3098,7 +3098,7 @@ static void show_pte(unsigned long addr)
 
 	printf("pgd  @ 0x%px\n", pgdir);
 
-	if (pgd_huge(*pgdp)) {
+	if (pgd_is_leaf(*pgdp)) {
 		format_pte(pgdp, pgd_val(*pgdp));
 		return;
 	}
@@ -3111,7 +3111,7 @@ static void show_pte(unsigned long addr)
 		return;
 	}
 
-	if (pud_huge(*pudp)) {
+	if (pud_is_leaf(*pudp)) {
 		format_pte(pudp, pud_val(*pudp));
 		return;
 	}
@@ -3125,7 +3125,7 @@ static void show_pte(unsigned long addr)
 		return;
 	}
 
-	if (pmd_huge(*pmdp)) {
+	if (pmd_is_leaf(*pmdp)) {
 		format_pte(pmdp, pmd_val(*pmdp));
 		return;
 	}

commit 0a882e28468f48ab3d9a36dde0a5723ea29ed1ed
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Fri Jun 28 16:33:18 2019 +1000

    powerpc/64s/exception: remove bad stack branch
    
    The bad stack test in interrupt handlers has a few problems. For
    performance it is taken in the common case, which is a fetch bubble
    and a waste of i-cache.
    
    For code development and maintainence, it requires yet another stack
    frame setup routine, and that constrains all exception handlers to
    follow the same register save pattern which inhibits future
    optimisation.
    
    Remove the test/branch and replace it with a trap. Teach the program
    check handler to use the emergency stack for this case.
    
    This does not result in quite so nice a message, however the SRR0 and
    SRR1 of the crashed interrupt can be seen in r11 and r12, as is the
    original r1 (adjusted by INT_FRAME_SIZE). These are the most important
    parts to debugging the issue.
    
    The original r9-12 and cr0 is lost, which is the main downside.
    
      kernel BUG at linux/arch/powerpc/kernel/exceptions-64s.S:847!
      Oops: Exception in kernel mode, sig: 5 [#1]
      BE SMP NR_CPUS=2048 NUMA PowerNV
      Modules linked in:
      CPU: 0 PID: 1 Comm: swapper/0 Not tainted
      NIP:  c000000000009108 LR: c000000000cadbcc CTR: c0000000000090f0
      REGS: c0000000fffcbd70 TRAP: 0700   Not tainted
      MSR:  9000000000021032 <SF,HV,ME,IR,DR,RI>  CR: 28222448  XER: 20040000
      CFAR: c000000000009100 IRQMASK: 0
      GPR00: 000000000000003d fffffffffffffd00 c0000000018cfb00 c0000000f02b3166
      GPR04: fffffffffffffffd 0000000000000007 fffffffffffffffb 0000000000000030
      GPR08: 0000000000000037 0000000028222448 0000000000000000 c000000000ca8de0
      GPR12: 9000000002009032 c000000001ae0000 c000000000010a00 0000000000000000
      GPR16: 0000000000000000 0000000000000000 0000000000000000 0000000000000000
      GPR20: c0000000f00322c0 c000000000f85200 0000000000000004 ffffffffffffffff
      GPR24: fffffffffffffffe 0000000000000000 0000000000000000 000000000000000a
      GPR28: 0000000000000000 0000000000000000 c0000000f02b391c c0000000f02b3167
      NIP [c000000000009108] decrementer_common+0x18/0x160
      LR [c000000000cadbcc] .vsnprintf+0x3ec/0x4f0
      Call Trace:
      Instruction dump:
      996d098a 994d098b 38610070 480246ed 48005518 60000000 38200000 718a4000
      7c2a0b78 3821fd00 41c20008 e82d0970 <0981fd00> f92101a0 f9610170 f9810178
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index f1c4e1601b9d..f879e9fe9733 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2454,7 +2454,9 @@ static void dump_one_paca(int cpu)
 	DUMP(p, canary, "%#-*lx");
 #endif
 	DUMP(p, saved_r1, "%#-*llx");
+#ifdef CONFIG_PPC_BOOK3E
 	DUMP(p, trap_save, "%#-*x");
+#endif
 	DUMP(p, irq_soft_mask, "%#-*x");
 	DUMP(p, irq_happened, "%#-*x");
 #ifdef CONFIG_MMIOWB

commit aaf06665f7ea3ee9f9754e16c1a507a89f1de5b1
Author: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
Date:   Thu Jun 27 15:29:40 2019 +0530

    powerpc/xmon: Fix disabling tracing while in xmon
    
    Commit ed49f7fd6438d ("powerpc/xmon: Disable tracing when entering
    xmon") added code to disable recording trace entries while in xmon. The
    commit introduced a variable 'tracing_enabled' to record if tracing was
    enabled on xmon entry, and used this to conditionally enable tracing
    during exit from xmon.
    
    However, we are not checking the value of 'fromipi' variable in
    xmon_core() when setting 'tracing_enabled'. Due to this, when secondary
    cpus enter xmon, they will see tracing as being disabled already and
    tracing won't be re-enabled on exit. Fix the same.
    
    Fixes: ed49f7fd6438d ("powerpc/xmon: Disable tracing when entering xmon")
    Signed-off-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 1b0149b2bb6c..f1c4e1601b9d 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -469,8 +469,10 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 	local_irq_save(flags);
 	hard_irq_disable();
 
-	tracing_enabled = tracing_is_on();
-	tracing_off();
+	if (!fromipi) {
+		tracing_enabled = tracing_is_on();
+		tracing_off();
+	}
 
 	bp = in_breakpoint_table(regs->nip, &offset);
 	if (bp != NULL) {

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 1b0149b2bb6c..d0620d762a5a 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1,14 +1,10 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
 /*
  * Routines providing a simple monitor for use on the PowerMac.
  *
  * Copyright (C) 1996-2005 Paul Mackerras.
  * Copyright (C) 2001 PPC64 Team, IBM Corp
  * Copyrignt (C) 2006 Michael Ellerman, IBM Corp
- *
- *      This program is free software; you can redistribute it and/or
- *      modify it under the terms of the GNU General Public License
- *      as published by the Free Software Foundation; either version
- *      2 of the License, or (at your option) any later version.
  */
 
 #include <linux/kernel.h>

commit b970afcfcabd63cd3832e95db096439c177c3592
Merge: 8ea5b2abd07e 8150a153c013
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 10 05:29:27 2019 -0700

    Merge tag 'powerpc-5.2-1' of ssh://gitolite.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Slightly delayed due to the issue with printk() calling
      probe_kernel_read() interacting with our new user access prevention
      stuff, but all fixed now.
    
      The only out-of-area changes are the addition of a cpuhp_state, small
      additions to Documentation and MAINTAINERS updates.
    
      Highlights:
    
       - Support for Kernel Userspace Access/Execution Prevention (like
         SMAP/SMEP/PAN/PXN) on some 64-bit and 32-bit CPUs. This prevents
         the kernel from accidentally accessing userspace outside
         copy_to/from_user(), or ever executing userspace.
    
       - KASAN support on 32-bit.
    
       - Rework of where we map the kernel, vmalloc, etc. on 64-bit hash to
         use the same address ranges we use with the Radix MMU.
    
       - A rewrite into C of large parts of our idle handling code for
         64-bit Book3S (ie. power8 & power9).
    
       - A fast path entry for syscalls on 32-bit CPUs, for a 12-17% speedup
         in the null_syscall benchmark.
    
       - On 64-bit bare metal we have support for recovering from errors
         with the time base (our clocksource), however if that fails
         currently we hang in __delay() and never crash. We now have support
         for detecting that case and short circuiting __delay() so we at
         least panic() and reboot.
    
       - Add support for optionally enabling the DAWR on Power9, which had
         to be disabled by default due to a hardware erratum. This has the
         effect of enabling hardware breakpoints for GDB, the downside is a
         badly behaved program could crash the machine by pointing the DAWR
         at cache inhibited memory. This is opt-in obviously.
    
       - xmon, our crash handler, gets support for a read only mode where
         operations that could change memory or otherwise disturb the system
         are disabled.
    
      Plus many clean-ups, reworks and minor fixes etc.
    
      Thanks to: Christophe Leroy, Akshay Adiga, Alastair D'Silva, Alexey
      Kardashevskiy, Andrew Donnellan, Aneesh Kumar K.V, Anju T Sudhakar,
      Anton Blanchard, Ben Hutchings, Bo YU, Breno Leitao, CÃ©dric Le Goater,
      Christopher M. Riedl, Christoph Hellwig, Colin Ian King, David Gibson,
      Ganesh Goudar, Gautham R. Shenoy, George Spelvin, Greg Kroah-Hartman,
      Greg Kurz, Horia GeantÄ, Jagadeesh Pagadala, Joel Stanley, Joe
      Perches, Julia Lawall, Laurentiu Tudor, Laurent Vivier, Lukas Bulwahn,
      Madhavan Srinivasan, Mahesh Salgaonkar, Mathieu Malaterre, Michael
      Neuling, Mukesh Ojha, Nathan Fontenot, Nathan Lynch, Nicholas Piggin,
      Nick Desaulniers, Oliver O'Halloran, Peng Hao, Qian Cai, Ravi
      Bangoria, Rick Lindsley, Russell Currey, Sachin Sant, Stewart Smith,
      Sukadev Bhattiprolu, Thomas Huth, Tobin C. Harding, Tyrel Datwyler,
      Valentin Schneider, Wei Yongjun, Wen Yang, YueHaibing"
    
    * tag 'powerpc-5.2-1' of ssh://gitolite.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (205 commits)
      powerpc/64s: Use early_mmu_has_feature() in set_kuap()
      powerpc/book3s/64: check for NULL pointer in pgd_alloc()
      powerpc/mm: Fix hugetlb page initialization
      ocxl: Fix return value check in afu_ioctl()
      powerpc/mm: fix section mismatch for setup_kup()
      powerpc/mm: fix redundant inclusion of pgtable-frag.o in Makefile
      powerpc/mm: Fix makefile for KASAN
      powerpc/kasan: add missing/lost Makefile
      selftests/powerpc: Add a signal fuzzer selftest
      powerpc/booke64: set RI in default MSR
      ocxl: Provide global MMIO accessors for external drivers
      ocxl: move event_fd handling to frontend
      ocxl: afu_irq only deals with IRQ IDs, not offsets
      ocxl: Allow external drivers to use OpenCAPI contexts
      ocxl: Create a clear delineation between ocxl backend & frontend
      ocxl: Don't pass pci_dev around
      ocxl: Split pci.c
      ocxl: Remove some unused exported symbols
      ocxl: Remove superfluous 'extern' from headers
      ocxl: read_pasid never returns an error, so make it void
      ...

commit 0acb5f64560a052fd66ab37b212a72964847160f
Author: Christopher M. Riedl <cmr@informatik.wtf>
Date:   Mon Apr 15 22:26:38 2019 -0500

    powerpc/xmon: add read-only mode
    
    Operations which write to memory and special purpose registers should be
    restricted on systems with integrity guarantees (such as Secure Boot)
    and, optionally, to avoid self-destructive behaviors.
    
    Add a config option, XMON_DEFAULT_RO_MODE, to set default xmon behavior.
    The kernel cmdline options xmon=ro and xmon=rw override this default.
    
    The following xmon operations are affected:
    memops:
            disable memmove
            disable memset
            disable memzcan
    memex:
            no-op'd mwrite
    super_regs:
            no-op'd write_spr
    bpt_cmds:
            disable
    proc_call:
            disable
    
    Signed-off-by: Christopher M. Riedl <cmr@informatik.wtf>
    Reviewed-by: Oliver O'Halloran <oohall@gmail.com>
    Reviewed-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index e583ed3f6b93..3e7be19aa208 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -80,6 +80,7 @@ static int set_indicator_token = RTAS_UNKNOWN_SERVICE;
 #endif
 static unsigned long in_xmon __read_mostly = 0;
 static int xmon_on = IS_ENABLED(CONFIG_XMON_DEFAULT);
+static bool xmon_is_ro = IS_ENABLED(CONFIG_XMON_DEFAULT_RO_MODE);
 
 static unsigned long adrs;
 static int size = 1;
@@ -202,6 +203,8 @@ static void dump_tlb_book3e(void);
 #define GETWORD(v)	(((v)[0] << 24) + ((v)[1] << 16) + ((v)[2] << 8) + (v)[3])
 #endif
 
+static const char *xmon_ro_msg = "Operation disabled: xmon in read-only mode\n";
+
 static char *help_string = "\
 Commands:\n\
   b	show breakpoints\n\
@@ -989,6 +992,10 @@ cmds(struct pt_regs *excp)
 				memlocate();
 				break;
 			case 'z':
+				if (xmon_is_ro) {
+					printf(xmon_ro_msg);
+					break;
+				}
 				memzcan();
 				break;
 			case 'i':
@@ -1042,6 +1049,10 @@ cmds(struct pt_regs *excp)
 			set_lpp_cmd();
 			break;
 		case 'b':
+			if (xmon_is_ro) {
+				printf(xmon_ro_msg);
+				break;
+			}
 			bpt_cmds();
 			break;
 		case 'C':
@@ -1055,6 +1066,10 @@ cmds(struct pt_regs *excp)
 			bootcmds();
 			break;
 		case 'p':
+			if (xmon_is_ro) {
+				printf(xmon_ro_msg);
+				break;
+			}
 			proccall();
 			break;
 		case 'P':
@@ -1777,6 +1792,11 @@ read_spr(int n, unsigned long *vp)
 static void
 write_spr(int n, unsigned long val)
 {
+	if (xmon_is_ro) {
+		printf(xmon_ro_msg);
+		return;
+	}
+
 	if (setjmp(bus_error_jmp) == 0) {
 		catch_spr_faults = 1;
 		sync();
@@ -2016,6 +2036,12 @@ mwrite(unsigned long adrs, void *buf, int size)
 	char *p, *q;
 
 	n = 0;
+
+	if (xmon_is_ro) {
+		printf(xmon_ro_msg);
+		return n;
+	}
+
 	if (setjmp(bus_error_jmp) == 0) {
 		catch_memory_errors = 1;
 		sync();
@@ -2880,9 +2906,17 @@ memops(int cmd)
 	scanhex((void *)&mcount);
 	switch( cmd ){
 	case 'm':
+		if (xmon_is_ro) {
+			printf(xmon_ro_msg);
+			break;
+		}
 		memmove((void *)mdest, (void *)msrc, mcount);
 		break;
 	case 's':
+		if (xmon_is_ro) {
+			printf(xmon_ro_msg);
+			break;
+		}
 		memset((void *)mdest, mval, mcount);
 		break;
 	case 'd':
@@ -3792,6 +3826,14 @@ static int __init early_parse_xmon(char *p)
 	} else if (strncmp(p, "on", 2) == 0) {
 		xmon_init(1);
 		xmon_on = 1;
+	} else if (strncmp(p, "rw", 2) == 0) {
+		xmon_init(1);
+		xmon_on = 1;
+		xmon_is_ro = false;
+	} else if (strncmp(p, "ro", 2) == 0) {
+		xmon_init(1);
+		xmon_on = 1;
+		xmon_is_ro = true;
 	} else if (strncmp(p, "off", 3) == 0)
 		xmon_on = 0;
 	else

commit 10d91611f426d4bafd2a83d966c36da811b2f7ad
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Sat Apr 13 00:30:52 2019 +1000

    powerpc/64s: Reimplement book3s idle code in C
    
    Reimplement Book3S idle code in C, moving POWER7/8/9 implementation
    speific HV idle code to the powernv platform code.
    
    Book3S assembly stubs are kept in common code and used only to save
    the stack frame and non-volatile GPRs before executing architected
    idle instructions, and restoring the stack and reloading GPRs then
    returning to C after waking from idle.
    
    The complex logic dealing with threads and subcores, locking, SPRs,
    HMIs, timebase resync, etc., is all done in C which makes it more
    maintainable.
    
    This is not a strict translation to C code, there are some
    significant differences:
    
    - Idle wakeup no longer uses the ->cpu_restore call to reinit SPRs,
      but saves and restores them itself.
    
    - The optimisation where EC=ESL=0 idle modes did not have to save GPRs
      or change MSR is restored, because it's now simple to do. ESL=1
      sleeps that do not lose GPRs can use this optimization too.
    
    - KVM secondary entry and cede is now more of a call/return style
      rather than branchy. nap_state_lost is not required because KVM
      always returns via NVGPR restoring path.
    
    - KVM secondary wakeup from offline sequence is moved entirely into
      the offline wakeup, which avoids a hwsync in the normal idle wakeup
      path.
    
    Performance measured with context switch ping-pong on different
    threads or cores, is possibly improved a small amount, 1-3% depending
    on stop state and core vs thread test for shallow states. Deep states
    it's in the noise compared with other latencies.
    
    KVM improvements:
    
    - Idle sleepers now always return to caller rather than branch out
      to KVM first.
    
    - This allows optimisations like very fast return to caller when no
      state has been lost.
    
    - KVM no longer requires nap_state_lost because it controls NVGPR
      save/restore itself on the way in and out.
    
    - The heavy idle wakeup KVM request check can be moved out of the
      normal host idle code and into the not-performance-critical offline
      code.
    
    - KVM nap code now returns from where it is called, which makes the
      flow a bit easier to follow.
    
    Reviewed-by: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Squash the KVM changes in]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index a0f44f992360..e583ed3f6b93 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2431,7 +2431,6 @@ static void dump_one_paca(int cpu)
 	DUMP(p, irq_happened, "%#-*x");
 	DUMP(p, io_sync, "%#-*x");
 	DUMP(p, irq_work_pending, "%#-*x");
-	DUMP(p, nap_state_lost, "%#-*x");
 	DUMP(p, sprg_vdso, "%#-*llx");
 
 #ifdef CONFIG_PPC_TRANSACTIONAL_MEM
@@ -2439,19 +2438,16 @@ static void dump_one_paca(int cpu)
 #endif
 
 #ifdef CONFIG_PPC_POWERNV
-	DUMP(p, core_idle_state_ptr, "%-*px");
-	DUMP(p, thread_idle_state, "%#-*x");
-	DUMP(p, thread_mask, "%#-*x");
-	DUMP(p, subcore_sibling_mask, "%#-*x");
-	DUMP(p, requested_psscr, "%#-*llx");
-	DUMP(p, stop_sprs.pid, "%#-*llx");
-	DUMP(p, stop_sprs.ldbar, "%#-*llx");
-	DUMP(p, stop_sprs.fscr, "%#-*llx");
-	DUMP(p, stop_sprs.hfscr, "%#-*llx");
-	DUMP(p, stop_sprs.mmcr1, "%#-*llx");
-	DUMP(p, stop_sprs.mmcr2, "%#-*llx");
-	DUMP(p, stop_sprs.mmcra, "%#-*llx");
-	DUMP(p, dont_stop.counter, "%#-*x");
+	DUMP(p, idle_state, "%#-*lx");
+	if (!early_cpu_has_feature(CPU_FTR_ARCH_300)) {
+		DUMP(p, thread_idle_state, "%#-*x");
+		DUMP(p, subcore_sibling_mask, "%#-*x");
+	} else {
+#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE
+		DUMP(p, requested_psscr, "%#-*llx");
+		DUMP(p, dont_stop.counter, "%#-*x");
+#endif
+	}
 #endif
 
 	DUMP(p, accounting.utime, "%#-*lx");

commit 420af1554790a95e6813f56f63b6d2361614082b
Author: Will Deacon <will.deacon@arm.com>
Date:   Fri Feb 22 14:45:42 2019 +0000

    powerpc/mmiowb: Hook up mmwiob() implementation to asm-generic code
    
    In a bid to kill off explicit mmiowb() usage in driver code, hook up
    the asm-generic mmiowb() tracking code but provide a definition of
    arch_mmiowb_state() so that the tracking data can remain in the paca
    as it does at present
    
    This replaces the existing (flawed) implementation.
    
    Acked-by: Michael Ellerman <mpe@ellerman.id.au>
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index a0f44f992360..13c6a47e6150 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2429,7 +2429,10 @@ static void dump_one_paca(int cpu)
 	DUMP(p, trap_save, "%#-*x");
 	DUMP(p, irq_soft_mask, "%#-*x");
 	DUMP(p, irq_happened, "%#-*x");
-	DUMP(p, io_sync, "%#-*x");
+#ifdef CONFIG_MMIOWB
+	DUMP(p, mmiowb_state.nesting_count, "%#-*x");
+	DUMP(p, mmiowb_state.mmiowb_pending, "%#-*x");
+#endif
 	DUMP(p, irq_work_pending, "%#-*x");
 	DUMP(p, nap_state_lost, "%#-*x");
 	DUMP(p, sprg_vdso, "%#-*llx");

commit 054860897cd35a4e9cec953ae955b429e31e74f7
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Jan 31 10:08:50 2019 +0000

    powerpc: Only use task_struct 'cpu' field on SMP
    
    When moving to CONFIG_THREAD_INFO_IN_TASK, the thread_info 'cpu' field
    gets moved into task_struct and only defined when CONFIG_SMP is set.
    
    This patch ensures that TI_CPU is only used when CONFIG_SMP is set and
    that task_struct 'cpu' field is not used directly out of SMP code.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 757b8499aba2..a0f44f992360 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2997,7 +2997,7 @@ static void show_task(struct task_struct *tsk)
 	printf("%px %016lx %6d %6d %c %2d %s\n", tsk,
 		tsk->thread.ksp,
 		tsk->pid, rcu_dereference(tsk->parent)->pid,
-		state, task_thread_info(tsk)->cpu,
+		state, task_cpu(tsk),
 		tsk->comm);
 }
 

commit 32c8c4c621897199e690760c2d57054f8b84b6e6
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Fri Nov 16 17:31:08 2018 +0000

    powerpc/xmon: fix dump_segments()
    
    mfsrin() takes segment num from bits 31-28 (IBM bits 0-3).
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    [mpe: Clarify bit numbering]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 372f4d80bcd6..757b8499aba2 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -3504,7 +3504,7 @@ void dump_segments(void)
 
 	printf("sr0-15 =");
 	for (i = 0; i < 16; ++i)
-		printf(" %x", mfsrin(i));
+		printf(" %x", mfsrin(i << 28));
 	printf("\n");
 }
 #endif

commit 8ad940217cce2b6ccc8d8cc7156e9aea34ae5573
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Thu Nov 29 09:28:30 2018 +1100

    powerpc: annotate implicit fall throughs
    
    There is a plan to build the kernel with -Wimplicit-fallthrough and these
    places in the code produced warnings, but because we build arch/powerpc
    with -Werror, they became errors.  Fix them up.
    
    This patch produces no change in behaviour, but should be reviewed in
    case these are actually bugs not intentional fallthoughs.
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 1f943e884e85..372f4d80bcd6 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -4043,6 +4043,7 @@ static int do_spu_cmd(void)
 		subcmd = inchar();
 		if (isxdigit(subcmd) || subcmd == '\n')
 			termch = subcmd;
+		/* fall through */
 	case 'f':
 		scanhex(&num);
 		if (num >= XMON_NUM_SPUS || !spu_info[num].spu) {

commit 8d4a862276a9c30a269d368d324fb56529e6d5fd
Author: Breno Leitao <leitao@debian.org>
Date:   Thu Nov 8 15:12:42 2018 -0200

    powerpc/xmon: Fix invocation inside lock region
    
    Currently xmon needs to get devtree_lock (through rtas_token()) during its
    invocation (at crash time). If there is a crash while devtree_lock is being
    held, then xmon tries to get the lock but spins forever and never get into
    the interactive debugger, as in the following case:
    
            int *ptr = NULL;
            raw_spin_lock_irqsave(&devtree_lock, flags);
            *ptr = 0xdeadbeef;
    
    This patch avoids calling rtas_token(), thus trying to get the same lock,
    at crash time. This new mechanism proposes getting the token at
    initialization time (xmon_init()) and just consuming it at crash time.
    
    This would allow xmon to be possible invoked independent of devtree_lock
    being held or not.
    
    Signed-off-by: Breno Leitao <leitao@debian.org>
    Reviewed-by: Thiago Jung Bauermann <bauerman@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 1e718431ac1c..1f943e884e85 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -75,6 +75,9 @@ static int xmon_gate;
 #define xmon_owner 0
 #endif /* CONFIG_SMP */
 
+#ifdef CONFIG_PPC_PSERIES
+static int set_indicator_token = RTAS_UNKNOWN_SERVICE;
+#endif
 static unsigned long in_xmon __read_mostly = 0;
 static int xmon_on = IS_ENABLED(CONFIG_XMON_DEFAULT);
 
@@ -358,7 +361,6 @@ static inline void disable_surveillance(void)
 #ifdef CONFIG_PPC_PSERIES
 	/* Since this can't be a module, args should end up below 4GB. */
 	static struct rtas_args args;
-	int token;
 
 	/*
 	 * At this point we have got all the cpus we can into
@@ -367,11 +369,11 @@ static inline void disable_surveillance(void)
 	 * If we did try to take rtas.lock there would be a
 	 * real possibility of deadlock.
 	 */
-	token = rtas_token("set-indicator");
-	if (token == RTAS_UNKNOWN_SERVICE)
+	if (set_indicator_token == RTAS_UNKNOWN_SERVICE)
 		return;
 
-	rtas_call_unlocked(&args, token, 3, 1, NULL, SURVEILLANCE_TOKEN, 0, 0);
+	rtas_call_unlocked(&args, set_indicator_token, 3, 1, NULL,
+			   SURVEILLANCE_TOKEN, 0, 0);
 
 #endif /* CONFIG_PPC_PSERIES */
 }
@@ -3688,6 +3690,14 @@ static void xmon_init(int enable)
 		__debugger_iabr_match = xmon_iabr_match;
 		__debugger_break_match = xmon_break_match;
 		__debugger_fault_handler = xmon_fault_handler;
+
+#ifdef CONFIG_PPC_PSERIES
+		/*
+		 * Get the token here to avoid trying to get a lock
+		 * during the crash, causing a deadlock.
+		 */
+		set_indicator_token = rtas_token("set-indicator");
+#endif
 	} else {
 		__debugger = NULL;
 		__debugger_ipi = NULL;

commit 5b3e84fc10ddb77193d6ac1d2be991d47264c716
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Sat Nov 17 10:25:04 2018 +0000

    powerpc: change CONFIG_PPC_STD_MMU to CONFIG_PPC_BOOK3S
    
    Today we have:
    
    config PPC_BOOK3S
            def_bool y
            depends on PPC_BOOK3S_32 || PPC_BOOK3S_64
    
    config PPC_STD_MMU
            def_bool y
            depends on PPC_BOOK3S
    
    PPC_STD_MMU is therefore redundant with PPC_BOOK3S. Lets remove it.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 23845c94d90c..1e718431ac1c 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1058,7 +1058,7 @@ cmds(struct pt_regs *excp)
 		case 'P':
 			show_tasks();
 			break;
-#ifdef CONFIG_PPC_STD_MMU
+#ifdef CONFIG_PPC_BOOK3S
 		case 'u':
 			dump_segments();
 			break;

commit 68289ae935da5a8488c0268111631f644d27b683
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Sat Nov 17 10:25:02 2018 +0000

    powerpc: change CONFIG_PPC_STD_MMU_32 to CONFIG_PPC_BOOK3S_32
    
    Today we have:
    
    config PPC_BOOK3S_32
            bool "512x/52xx/6xx/7xx/74xx/82xx/83xx/86xx"
            [depends on PPC32 within a choice]
    
    config PPC_BOOK3S
            def_bool y
            depends on PPC_BOOK3S_32 || PPC_BOOK3S_64
    
    config PPC_STD_MMU
            def_bool y
            depends on PPC_BOOK3S
    
    config PPC_STD_MMU_32
            def_bool y
            depends on PPC_STD_MMU && PPC32
    
    PPC_STD_MMU_32 is therefore redundant with PPC_BOOK3S_32.
    
    In order to make the code clearer, lets use preferably PPC_BOOK3S_32.
    This will allow to remove CONFIG_PPC_STD_MMU_32 in a later patch.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index fee96bbabf42..23845c94d90c 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -273,7 +273,7 @@ Commands:\n\
   X	exit monitor and don't recover\n"
 #if defined(CONFIG_PPC64) && !defined(CONFIG_PPC_BOOK3E)
 "  u	dump segment table or SLB\n"
-#elif defined(CONFIG_PPC_STD_MMU_32)
+#elif defined(CONFIG_PPC_BOOK3S_32)
 "  u	dump segment registers\n"
 #elif defined(CONFIG_44x) || defined(CONFIG_PPC_BOOK3E)
 "  u	dump TLB\n"
@@ -3495,7 +3495,7 @@ void dump_segments(void)
 }
 #endif
 
-#ifdef CONFIG_PPC_STD_MMU_32
+#ifdef CONFIG_PPC_BOOK3S_32
 void dump_segments(void)
 {
 	int i;

commit e3a8379948623e5f03789bbd24055170b6216abd
Author: Breno Leitao <leitao@debian.org>
Date:   Mon Oct 22 11:54:16 2018 -0300

    powerpc/xmon: Define static functions
    
    Currently sparse is complaining about three issues on the xmon code. Two
    storage classes issues and a dereferencing a 'noderef'  pointer. These are
    the warnings:
    
            arch/powerpc/xmon/xmon.c:2783:1: warning: symbol 'dump_log_buf' was not declared. Should it be static?
            arch/powerpc/xmon/xmon.c:2989:6: warning: symbol 'format_pte' was not declared. Should it be static?
            arch/powerpc/xmon/xmon.c:2983:30: warning: dereference of noderef expression
    
    This patch fixes all of them, turning both functions static and
    dereferencing a pointer calling rcu_dereference() instead of a
    straightforward dereference.
    
    Signed-off-by: Breno Leitao <leitao@debian.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 36b8dc47a3c3..fee96bbabf42 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2793,7 +2793,7 @@ print_address(unsigned long addr)
 	xmon_print_symbol(addr, "\t# ", "");
 }
 
-void
+static void
 dump_log_buf(void)
 {
 	struct kmsg_dumper dumper = { .active = 1 };
@@ -2994,13 +2994,13 @@ static void show_task(struct task_struct *tsk)
 
 	printf("%px %016lx %6d %6d %c %2d %s\n", tsk,
 		tsk->thread.ksp,
-		tsk->pid, tsk->parent->pid,
+		tsk->pid, rcu_dereference(tsk->parent)->pid,
 		state, task_thread_info(tsk)->cpu,
 		tsk->comm);
 }
 
 #ifdef CONFIG_PPC_BOOK3S_64
-void format_pte(void *ptep, unsigned long pte)
+static void format_pte(void *ptep, unsigned long pte)
 {
 	pte_t entry = __pte(pte);
 

commit abcff86df2d2ec0a0ca9470fa5d2a184af18928a
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Aug 2 07:53:59 2018 +0000

    powerpc/time: Only set CONFIG_ARCH_HAS_SCALED_CPUTIME on PPC64
    
    scaled cputime is only meaningfull when the processor has
    SPURR and/or PURR, which means only on PPC64.
    
    Removing it on PPC32 significantly reduces the size of
    vtime_account_system() and vtime_account_idle() on an 8xx:
    
    Before:
    00000000 l     F .text  000000a8 vtime_delta
    00000280 g     F .text  0000010c vtime_account_system
    0000038c g     F .text  00000048 vtime_account_idle
    
    After:
    (vtime_delta gets inlined inside the two functions)
    000001d8 g     F .text  000000a0 vtime_account_system
    00000278 g     F .text  00000038 vtime_account_idle
    
    In terms of performance, we also get approximatly 7% improvement on
    task switch. The following small benchmark app is run with perf stat:
    
    void *thread(void *arg)
    {
            int i;
    
            for (i = 0; i < atoi((char*)arg); i++)
                    pthread_yield();
    }
    
    int main(int argc, char **argv)
    {
            pthread_t th1, th2;
    
            pthread_create(&th1, NULL, thread, argv[1]);
            pthread_create(&th2, NULL, thread, argv[1]);
            pthread_join(th1, NULL);
            pthread_join(th2, NULL);
    
            return 0;
    }
    
    Before the patch:
    
     Performance counter stats for 'chrt -f 98 ./sched 100000' (50 runs):
    
           8228.476465      task-clock (msec)         #    0.954 CPUs utilized            ( +-  0.23% )
                200004      context-switches          #    0.024 M/sec                    ( +-  0.00% )
    
    After the patch:
    
     Performance counter stats for 'chrt -f 98 ./sched 100000' (50 runs):
    
           7649.070444      task-clock (msec)         #    0.955 CPUs utilized            ( +-  0.27% )
                200004      context-switches          #    0.026 M/sec                    ( +-  0.00% )
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 58e67b67a97c..36b8dc47a3c3 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2454,11 +2454,15 @@ static void dump_one_paca(int cpu)
 
 	DUMP(p, accounting.utime, "%#-*lx");
 	DUMP(p, accounting.stime, "%#-*lx");
+#ifdef CONFIG_ARCH_HAS_SCALED_CPUTIME
 	DUMP(p, accounting.utime_scaled, "%#-*lx");
+#endif
 	DUMP(p, accounting.starttime, "%#-*lx");
 	DUMP(p, accounting.starttime_user, "%#-*lx");
+#ifdef CONFIG_ARCH_HAS_SCALED_CPUTIME
 	DUMP(p, accounting.startspurr, "%#-*lx");
 	DUMP(p, accounting.utime_sspurr, "%#-*lx");
+#endif
 	DUMP(p, accounting.steal_time, "%#-*lx");
 #undef DUMP
 

commit 126b11b294d15a90e38eb2dcded2433619b2c794
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Sat Sep 15 01:30:53 2018 +1000

    powerpc/64s/hash: Add SLB allocation status bitmaps
    
    Add 32-entry bitmaps to track the allocation status of the first 32
    SLB entries, and whether they are user or kernel entries. These are
    used to allocate free SLB entries first, before resorting to the round
    robin allocator.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 8345defa0e43..58e67b67a97c 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2394,7 +2394,9 @@ static void dump_one_paca(int cpu)
 			}
 		}
 		DUMP(p, vmalloc_sllp, "%#-*x");
-		DUMP(p, stab_rr, "%#-*llx");
+		DUMP(p, stab_rr, "%#-*x");
+		DUMP(p, slb_used_bitmap, "%#-*x");
+		DUMP(p, slb_kern_bitmap, "%#-*x");
 
 		if (!early_cpu_has_feature(CPU_FTR_ARCH_300)) {
 			DUMP(p, slb_cache_ptr, "%#-*x");

commit 26973fa5ac0e3b88d0d476caccfc10839b26098b
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Tue Oct 9 13:51:56 2018 +0000

    powerpc/mm: use pte helpers in generic code
    
    Get rid of platform specific _PAGE_XXXX in powerpc common code and
    use helpers instead.
    
    mm/dump_linuxpagetables.c will be handled separately
    
    Reviewed-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index d139741f26fe..8345defa0e43 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2996,15 +2996,17 @@ static void show_task(struct task_struct *tsk)
 #ifdef CONFIG_PPC_BOOK3S_64
 void format_pte(void *ptep, unsigned long pte)
 {
+	pte_t entry = __pte(pte);
+
 	printf("ptep @ 0x%016lx = 0x%016lx\n", (unsigned long)ptep, pte);
 	printf("Maps physical address = 0x%016lx\n", pte & PTE_RPN_MASK);
 
 	printf("Flags = %s%s%s%s%s\n",
-	       (pte & _PAGE_ACCESSED) ? "Accessed " : "",
-	       (pte & _PAGE_DIRTY)    ? "Dirty " : "",
-	       (pte & _PAGE_READ)     ? "Read " : "",
-	       (pte & _PAGE_WRITE)    ? "Write " : "",
-	       (pte & _PAGE_EXEC)     ? "Exec " : "");
+	       pte_young(entry) ? "Accessed " : "",
+	       pte_dirty(entry) ? "Dirty " : "",
+	       pte_read(entry)  ? "Read " : "",
+	       pte_write(entry) ? "Write " : "",
+	       pte_exec(entry)  ? "Exec " : "");
 }
 
 static void show_pte(unsigned long addr)

commit 50530f5eac0c023cfc313d7ed342d4f1731becdb
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Fri Oct 12 13:58:52 2018 +1100

    powerpc/xmon: Show the stack protector canary in xmon
    
    This is helpful for debugging stack protector crashes.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index c70d17c9a6ba..d139741f26fe 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2418,6 +2418,9 @@ static void dump_one_paca(int cpu)
 	DUMP(p, __current, "%-*px");
 	DUMP(p, kstack, "%#-*llx");
 	printf(" %-*s = 0x%016llx\n", 25, "kstack_base", p->kstack & ~(THREAD_SIZE - 1));
+#ifdef CONFIG_STACKPROTECTOR
+	DUMP(p, canary, "%#-*lx");
+#endif
 	DUMP(p, saved_r1, "%#-*llx");
 	DUMP(p, trap_save, "%#-*x");
 	DUMP(p, irq_soft_mask, "%#-*x");

commit 54be0b9c7c9888ebe63b89a31a17ee3df6a68d61
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Oct 2 23:56:39 2018 +1000

    Revert "convert SLB miss handlers to C" and subsequent commits
    
    This reverts commits:
      5e46e29e6a97 ("powerpc/64s/hash: convert SLB miss handlers to C")
      8fed04d0f6ae ("powerpc/64s/hash: remove user SLB data from the paca")
      655deecf67b2 ("powerpc/64s/hash: SLB allocation status bitmaps")
      2e1626744e8d ("powerpc/64s/hash: provide arch_setup_exec hooks for hash slice setup")
      89ca4e126a3f ("powerpc/64s/hash: Add a SLB preload cache")
    
    This series had a few bugs, and the fixes are not all trivial. So
    revert most of it for now.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 694c1d92e796..c70d17c9a6ba 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2394,9 +2394,7 @@ static void dump_one_paca(int cpu)
 			}
 		}
 		DUMP(p, vmalloc_sllp, "%#-*x");
-		DUMP(p, stab_rr, "%#-*x");
-		DUMP(p, slb_used_bitmap, "%#-*x");
-		DUMP(p, slb_kern_bitmap, "%#-*x");
+		DUMP(p, stab_rr, "%#-*llx");
 
 		if (!early_cpu_has_feature(CPU_FTR_ARCH_300)) {
 			DUMP(p, slb_cache_ptr, "%#-*x");

commit e83cbf7fb7d17618a5d8a415d5c7bb760812a5cb
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Sat Sep 15 01:30:54 2018 +1000

    powerpc/64s: xmon do not dump hash fields when using radix mode
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index ad6a549a3080..694c1d92e796 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2378,30 +2378,32 @@ static void dump_one_paca(int cpu)
 	DUMP(p, cpu_start, "%#-*x");
 	DUMP(p, kexec_state, "%#-*x");
 #ifdef CONFIG_PPC_BOOK3S_64
-	for (i = 0; i < SLB_NUM_BOLTED; i++) {
-		u64 esid, vsid;
+	if (!early_radix_enabled()) {
+		for (i = 0; i < SLB_NUM_BOLTED; i++) {
+			u64 esid, vsid;
 
-		if (!p->slb_shadow_ptr)
-			continue;
+			if (!p->slb_shadow_ptr)
+				continue;
 
-		esid = be64_to_cpu(p->slb_shadow_ptr->save_area[i].esid);
-		vsid = be64_to_cpu(p->slb_shadow_ptr->save_area[i].vsid);
+			esid = be64_to_cpu(p->slb_shadow_ptr->save_area[i].esid);
+			vsid = be64_to_cpu(p->slb_shadow_ptr->save_area[i].vsid);
 
-		if (esid || vsid) {
-			printf(" %-*s[%d] = 0x%016llx 0x%016llx\n",
-			       22, "slb_shadow", i, esid, vsid);
+			if (esid || vsid) {
+				printf(" %-*s[%d] = 0x%016llx 0x%016llx\n",
+				       22, "slb_shadow", i, esid, vsid);
+			}
 		}
-	}
-	DUMP(p, vmalloc_sllp, "%#-*x");
-	DUMP(p, stab_rr, "%#-*x");
-	DUMP(p, slb_used_bitmap, "%#-*x");
-	DUMP(p, slb_kern_bitmap, "%#-*x");
+		DUMP(p, vmalloc_sllp, "%#-*x");
+		DUMP(p, stab_rr, "%#-*x");
+		DUMP(p, slb_used_bitmap, "%#-*x");
+		DUMP(p, slb_kern_bitmap, "%#-*x");
 
-	if (!early_cpu_has_feature(CPU_FTR_ARCH_300)) {
-		DUMP(p, slb_cache_ptr, "%#-*x");
-		for (i = 0; i < SLB_CACHE_ENTRIES; i++)
-			printf(" %-*s[%d] = 0x%016x\n",
-			       22, "slb_cache", i, p->slb_cache[i]);
+		if (!early_cpu_has_feature(CPU_FTR_ARCH_300)) {
+			DUMP(p, slb_cache_ptr, "%#-*x");
+			for (i = 0; i < SLB_CACHE_ENTRIES; i++)
+				printf(" %-*s[%d] = 0x%016x\n",
+				       22, "slb_cache", i, p->slb_cache[i]);
+		}
 	}
 
 	DUMP(p, rfi_flush_fallback_area, "%-*px");

commit 655deecf67b240bf7bb4e73df4e1235900c26a01
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Sat Sep 15 01:30:53 2018 +1000

    powerpc/64s/hash: SLB allocation status bitmaps
    
    Add 32-entry bitmaps to track the allocation status of the first 32
    SLB entries, and whether they are user or kernel entries. These are
    used to allocate free SLB entries first, before resorting to the round
    robin allocator.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index cd43c168dc1b..ad6a549a3080 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2393,6 +2393,9 @@ static void dump_one_paca(int cpu)
 		}
 	}
 	DUMP(p, vmalloc_sllp, "%#-*x");
+	DUMP(p, stab_rr, "%#-*x");
+	DUMP(p, slb_used_bitmap, "%#-*x");
+	DUMP(p, slb_kern_bitmap, "%#-*x");
 
 	if (!early_cpu_has_feature(CPU_FTR_ARCH_300)) {
 		DUMP(p, slb_cache_ptr, "%#-*x");
@@ -2415,7 +2418,6 @@ static void dump_one_paca(int cpu)
 	DUMP(p, __current, "%-*px");
 	DUMP(p, kstack, "%#-*llx");
 	printf(" %-*s = 0x%016llx\n", 25, "kstack_base", p->kstack & ~(THREAD_SIZE - 1));
-	DUMP(p, stab_rr, "%#-*llx");
 	DUMP(p, saved_r1, "%#-*llx");
 	DUMP(p, trap_save, "%#-*x");
 	DUMP(p, irq_soft_mask, "%#-*x");

commit 82d8f4c22f3514eface7e082750bc917193d91f9
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Sat Sep 15 01:30:50 2018 +1000

    powerpc/64s/hash: Use POWER9 SLBIA IH=3 variant in switch_slb
    
    POWER9 introduces SLBIA IH=3, which invalidates all SLB entries and
    associated lookaside information that have a class value of 1, which
    Linux assigns to user addresses. This matches what switch_slb wants,
    and allows a simple fast implementation that avoids the slb_cache
    complexity.
    
    As a side-effect, the POWER5 < DD2.1 SLB invalidation workaround is
    also avoided on POWER9.
    
    Process context switching rate is improved about 2.2% for a small
    process that hits the slb cache which is the best case for the current
    code.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 4264aedc7775..cd43c168dc1b 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2393,10 +2393,13 @@ static void dump_one_paca(int cpu)
 		}
 	}
 	DUMP(p, vmalloc_sllp, "%#-*x");
-	DUMP(p, slb_cache_ptr, "%#-*x");
-	for (i = 0; i < SLB_CACHE_ENTRIES; i++)
-		printf(" %-*s[%d] = 0x%016x\n",
-		       22, "slb_cache", i, p->slb_cache[i]);
+
+	if (!early_cpu_has_feature(CPU_FTR_ARCH_300)) {
+		DUMP(p, slb_cache_ptr, "%#-*x");
+		for (i = 0; i < SLB_CACHE_ENTRIES; i++)
+			printf(" %-*s[%d] = 0x%016x\n",
+			       22, "slb_cache", i, p->slb_cache[i]);
+	}
 
 	DUMP(p, rfi_flush_fallback_area, "%-*px");
 #endif

commit b3124ec2f9970c7374d34b00843d9791fca66afc
Merge: f7a6947cd49b cca19f0b684f
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Mon Aug 13 15:59:06 2018 +1000

    Merge branch 'fixes' into next
    
    Merge our fixes branch from the 4.18 cycle to resolve some minor
    conflicts.

commit 302c7b0c4ff5aed585419603f835dee30207e5d5
Author: Boqun Feng <boqun.feng@gmail.com>
Date:   Tue Nov 22 17:20:09 2016 +0800

    powerpc/xmon: Add address lookup for percpu symbols
    
    Currently, in xmon, there is no obvious way to get an address for a
    percpu symbol for a particular cpu. Having such an ability would be
    good for debugging the system when percpu variables got involved.
    
    Therefore, this patch introduces a new xmon command "lp" to lookup the
    address for percpu symbols. Usage of "lp" is similar to "ls", except
    that we could add a cpu number to choose the variable of which cpu we
    want to lookup. If no cpu number is given, lookup for current cpu.
    
    Signed-off-by: Boqun Feng <boqun.feng@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index b7dd683b0470..7c4aa5b00302 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -56,6 +56,7 @@
 #include <asm/opal.h>
 #include <asm/firmware.h>
 #include <asm/code-patching.h>
+#include <asm/sections.h>
 
 #ifdef CONFIG_PPC64
 #include <asm/hvcall.h>
@@ -244,6 +245,7 @@ Commands:\n\
   f	flush cache\n\
   la	lookup symbol+offset of specified address\n\
   ls	lookup address of specified symbol\n\
+  lp s [#]	lookup address of percpu symbol s for current cpu, or cpu #\n\
   m	examine/change memory\n\
   mm	move a block of memory\n\
   ms	set a block of memory\n\
@@ -3352,7 +3354,8 @@ static void
 symbol_lookup(void)
 {
 	int type = inchar();
-	unsigned long addr;
+	unsigned long addr, cpu;
+	void __percpu *ptr = NULL;
 	static char tmp[64];
 
 	switch (type) {
@@ -3373,6 +3376,34 @@ symbol_lookup(void)
 				printf("Symbol '%s' not found.\n", tmp);
 			sync();
 		}
+		catch_memory_errors = 0;
+		termch = 0;
+		break;
+	case 'p':
+		getstring(tmp, 64);
+		if (setjmp(bus_error_jmp) == 0) {
+			catch_memory_errors = 1;
+			sync();
+			ptr = (void __percpu *)kallsyms_lookup_name(tmp);
+			sync();
+		}
+
+		if (ptr &&
+		    ptr >= (void __percpu *)__per_cpu_start &&
+		    ptr < (void __percpu *)__per_cpu_end)
+		{
+			if (scanhex(&cpu) && cpu < num_possible_cpus()) {
+				addr = (unsigned long)per_cpu_ptr(ptr, cpu);
+			} else {
+				cpu = raw_smp_processor_id();
+				addr = (unsigned long)this_cpu_ptr(ptr);
+			}
+
+			printf("%s for cpu 0x%lx: %lx\n", tmp, cpu, addr);
+		} else {
+			printf("Percpu symbol '%s' not found.\n", tmp);
+		}
+
 		catch_memory_errors = 0;
 		termch = 0;
 		break;

commit ce57c6610cc2d7cde61fc005a2d2090bce46fc73
Merge: 9c3250a12790 a68bd1267b72
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Jul 19 14:37:57 2018 +1000

    Merge branch 'topic/ppc-kvm' into next
    
    Merge in some commits we're sharing with the KVM tree.
    
    I manually propagated the change from commit d3d4ffaae439
    ("powerpc/powernv/ioda2: Reduce upper limit for DMA window size") into
    pci-ioda-tce.c.
    
    Conflicts:
            arch/powerpc/include/asm/cputable.h
            arch/powerpc/platforms/powernv/pci-ioda.c
            arch/powerpc/platforms/powernv/pci.h

commit 941d810725ad48cc21948f4cff8cf70fa2a67cf9
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Mon Jul 16 23:52:14 2018 +1000

    powerpc/xmon: Fix disassembly since printf changes
    
    The recent change to add printf annotations to xmon inadvertently made
    the disassembly output ugly, eg:
    
      c00000002001e058  7ee00026      mfcr    r23
      c00000002001e05c  fffffffffae101a0      std     r23,416(r1)
      c00000002001e060  fffffffff8230000      std     r1,0(r3)
    
    The problem being that negative 32-bit values are being displayed in
    full 64-bits.
    
    The printf conversion was actually correct, we are passing unsigned
    long so it should use "lx". But powerpc instructions are only 4 bytes
    and the code only reads 4 bytes, so inst should really just be
    unsigned int, and that also fixes the printing to look the way we
    want:
    
      c00000002001e058  7ee00026      mfcr    r23
      c00000002001e05c  fae101a0      std     r23,416(r1)
      c00000002001e060  f8230000      std     r1,0(r3)
    
    Fixes: e70d8f55268b ("powerpc/xmon: Add __printf annotation to xmon_printf()")
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 47166ad2a669..196978733e64 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2734,7 +2734,7 @@ generic_inst_dump(unsigned long adr, long count, int praddr,
 {
 	int nr, dotted;
 	unsigned long first_adr;
-	unsigned long inst, last_inst = 0;
+	unsigned int inst, last_inst = 0;
 	unsigned char val[4];
 
 	dotted = 0;
@@ -2758,7 +2758,7 @@ generic_inst_dump(unsigned long adr, long count, int praddr,
 		dotted = 0;
 		last_inst = inst;
 		if (praddr)
-			printf(REG"  %.8lx", adr, inst);
+			printf(REG"  %.8x", adr, inst);
 		printf("\t");
 		dump_func(inst, adr);
 		printf("\n");

commit 2bf1071a8d50928a4ae366bb3108833166c2b70c
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Thu Jul 5 18:47:00 2018 +1000

    powerpc/64s: Remove POWER9 DD1 support
    
    POWER9 DD1 was never a product. It is no longer supported by upstream
    firmware, and it is not effectively supported in Linux due to lack of
    testing.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Reviewed-by: Michael Ellerman <mpe@ellerman.id.au>
    [mpe: Remove arch_make_huge_pte() entirely]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 47166ad2a669..21119cfe8474 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2429,7 +2429,6 @@ static void dump_one_paca(int cpu)
 	DUMP(p, thread_idle_state, "%#-*x");
 	DUMP(p, thread_mask, "%#-*x");
 	DUMP(p, subcore_sibling_mask, "%#-*x");
-	DUMP(p, thread_sibling_pacas, "%-*px");
 	DUMP(p, requested_psscr, "%#-*llx");
 	DUMP(p, stop_sprs.pid, "%#-*llx");
 	DUMP(p, stop_sprs.ldbar, "%#-*llx");

commit f6bd74fa084eb9ad573ffbb236a095454163f66d
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon Jun 18 11:56:24 2018 +0200

    powerpc: xmon: use ktime_get_coarse_boottime64
    
    get_monotonic_boottime() is deprecated, and may not be safe to call in
    every context, as it has to read a hardware clocksource.
    
    This changes xmon to print the time using ktime_get_coarse_boottime64()
    instead, which avoids the old timespec type and the HW access.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Balbir Singh <bsingharora@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 47166ad2a669..45e3d0ec1246 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -918,13 +918,13 @@ static void remove_cpu_bpts(void)
 static void
 show_uptime(void)
 {
-	struct timespec uptime;
+	struct timespec64 uptime;
 
 	if (setjmp(bus_error_jmp) == 0) {
 		catch_memory_errors = 1;
 		sync();
 
-		get_monotonic_boottime(&uptime);
+		ktime_get_coarse_boottime_ts64(&uptime);
 		printf("Uptime: %lu.%.2lu seconds\n", (unsigned long)uptime.tv_sec,
 			((unsigned long)uptime.tv_nsec / (NSEC_PER_SEC/100)));
 

commit 7b08729cb272b4cd5c657cd5ac0dddae15a593ff
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed May 2 23:07:26 2018 +1000

    powerpc/64: Save stack pointer when we hard disable interrupts
    
    A CPU that gets stuck with interrupts hard disable can be difficult to
    debug, as on some platforms we have no way to interrupt the CPU to
    find out what it's doing.
    
    A stop-gap is to have the CPU save it's stack pointer (r1) in its paca
    when it hard disables interrupts. That way if we can't interrupt it,
    we can at least trace the stack based on where it last disabled
    interrupts.
    
    In some cases that will be total junk, but the stack trace code should
    handle that. In the simple case of a CPU that disable interrupts and
    then gets stuck in a loop, the stack trace should be informative.
    
    We could clear the saved stack pointer when we enable interrupts, but
    that loses information which could be useful if we have nothing else
    to go on.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 0561c14b276b..47166ad2a669 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1172,6 +1172,10 @@ static int cpu_cmd(void)
 	/* try to switch to cpu specified */
 	if (!cpumask_test_cpu(cpu, &cpus_in_xmon)) {
 		printf("cpu 0x%lx isn't in xmon\n", cpu);
+#ifdef CONFIG_PPC64
+		printf("backtrace of paca[0x%lx].saved_r1 (possibly stale):\n", cpu);
+		xmon_show_stack(paca_ptrs[cpu]->saved_r1, 0, 0);
+#endif
 		return 0;
 	}
 	xmon_taken = 0;

commit 3130a7bb6eb595f2d963976a4d3e57db77bcf06f
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Thu May 10 11:04:24 2018 +1000

    powerpc/64: change softe to irqmask in show_regs and xmon
    
    When the soft enabled flag was changed to a soft disable mask, xmon
    and register dump code was not updated to reflect that, which is
    confusing ('SOFTE: 1' previously meant interrupts were soft enabled,
    currently it means the opposite, the general interrupt type has been
    disabled).
    
    Fix this by using the name irqmask, and printing it in hex.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Acked-by: Balbir Singh <bsingharora@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index d94a41254b11..0561c14b276b 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1637,7 +1637,7 @@ static void excprint(struct pt_regs *fp)
 
 	printf("  current = 0x%px\n", current);
 #ifdef CONFIG_PPC64
-	printf("  paca    = 0x%px\t softe: %d\t irq_happened: 0x%02x\n",
+	printf("  paca    = 0x%px\t irqmask: 0x%02x\t irq_happened: 0x%02x\n",
 	       local_paca, local_paca->irq_soft_mask, local_paca->irq_happened);
 #endif
 	if (current) {

commit 0abbf2bfdc9dec32e9832aa8d4522a57d698e753
Author: Yisheng Xie <xieyisheng1@huawei.com>
Date:   Thu May 31 19:11:25 2018 +0800

    powerpc/xmon: use match_string() helper
    
    match_string() returns the index of an array for a matching string,
    which can be used instead of open coded variant.
    
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: linuxppc-dev@lists.ozlabs.org
    Signed-off-by: Yisheng Xie <xieyisheng1@huawei.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index c2e9270728c7..d94a41254b11 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -3173,7 +3173,7 @@ skipbl(void)
 }
 
 #define N_PTREGS	44
-static char *regnames[N_PTREGS] = {
+static const char *regnames[N_PTREGS] = {
 	"r0", "r1", "r2", "r3", "r4", "r5", "r6", "r7",
 	"r8", "r9", "r10", "r11", "r12", "r13", "r14", "r15",
 	"r16", "r17", "r18", "r19", "r20", "r21", "r22", "r23",
@@ -3208,18 +3208,17 @@ scanhex(unsigned long *vp)
 			regname[i] = c;
 		}
 		regname[i] = 0;
-		for (i = 0; i < N_PTREGS; ++i) {
-			if (strcmp(regnames[i], regname) == 0) {
-				if (xmon_regs == NULL) {
-					printf("regs not available\n");
-					return 0;
-				}
-				*vp = ((unsigned long *)xmon_regs)[i];
-				return 1;
-			}
+		i = match_string(regnames, N_PTREGS, regname);
+		if (i < 0) {
+			printf("invalid register name '%%%s'\n", regname);
+			return 0;
 		}
-		printf("invalid register name '%%%s'\n", regname);
-		return 0;
+		if (xmon_regs == NULL) {
+			printf("regs not available\n");
+			return 0;
+		}
+		*vp = ((unsigned long *)xmon_regs)[i];
+		return 1;
 	}
 
 	/* skip leading "0x" if any */

commit 2e0986d761324376021c880ddbf00c6d04ef1841
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Mon May 21 19:47:20 2018 +1000

    powerpc/xmon: Update paca fields dumped in xmon
    
    The set of paca fields we dump in xmon has gotten somewhat out of
    date. Update to add some recently added fields.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 56c83eab3d27..c2e9270728c7 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2425,6 +2425,16 @@ static void dump_one_paca(int cpu)
 	DUMP(p, thread_idle_state, "%#-*x");
 	DUMP(p, thread_mask, "%#-*x");
 	DUMP(p, subcore_sibling_mask, "%#-*x");
+	DUMP(p, thread_sibling_pacas, "%-*px");
+	DUMP(p, requested_psscr, "%#-*llx");
+	DUMP(p, stop_sprs.pid, "%#-*llx");
+	DUMP(p, stop_sprs.ldbar, "%#-*llx");
+	DUMP(p, stop_sprs.fscr, "%#-*llx");
+	DUMP(p, stop_sprs.hfscr, "%#-*llx");
+	DUMP(p, stop_sprs.mmcr1, "%#-*llx");
+	DUMP(p, stop_sprs.mmcr2, "%#-*llx");
+	DUMP(p, stop_sprs.mmcra, "%#-*llx");
+	DUMP(p, dont_stop.counter, "%#-*x");
 #endif
 
 	DUMP(p, accounting.utime, "%#-*lx");

commit 9ce53e27265e7bab728774fac785f66db97e206e
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Mon May 21 21:28:34 2018 +1000

    powerpc/xmon: Realign paca dump fields
    
    We've added some fields with longer names since we originally wrote
    this, so the fields are no longer lined up. Adjust the widths to make
    it all look nice again, eg:
    
      0:mon> dp
      paca for cpu 0x0 @ c000000001fa0000:
       possible                  = yes
       ...
       slb_shadow            [0] = 0xc000000008000000 0x400ea1b217000500
       slb_shadow            [1] = 0xd000000008000001 0x400d43642f000510
       ...
       rfi_flush_fallback_area   = c0000000fff80000   (0xcc8)
       ...
       accounting.starttime_user = 0x51582f07         (0xae8)
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 152eb185bfcf..56c83eab3d27 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2346,12 +2346,12 @@ static void dump_one_paca(int cpu)
 
 	printf("paca for cpu 0x%x @ %px:\n", cpu, p);
 
-	printf(" %-*s = %s\n", 20, "possible", cpu_possible(cpu) ? "yes" : "no");
-	printf(" %-*s = %s\n", 20, "present", cpu_present(cpu) ? "yes" : "no");
-	printf(" %-*s = %s\n", 20, "online", cpu_online(cpu) ? "yes" : "no");
+	printf(" %-*s = %s\n", 25, "possible", cpu_possible(cpu) ? "yes" : "no");
+	printf(" %-*s = %s\n", 25, "present", cpu_present(cpu) ? "yes" : "no");
+	printf(" %-*s = %s\n", 25, "online", cpu_online(cpu) ? "yes" : "no");
 
 #define DUMP(paca, name, format)				\
-	printf(" %-*s = "format"\t(0x%lx)\n", 20, #name, 18, paca->name, \
+	printf(" %-*s = "format"\t(0x%lx)\n", 25, #name, 18, paca->name, \
 		offsetof(struct paca_struct, name));
 
 	DUMP(p, lock_token, "%#-*x");
@@ -2382,14 +2382,15 @@ static void dump_one_paca(int cpu)
 		vsid = be64_to_cpu(p->slb_shadow_ptr->save_area[i].vsid);
 
 		if (esid || vsid) {
-			printf(" slb_shadow[%d]:       = 0x%016llx 0x%016llx\n",
-				i, esid, vsid);
+			printf(" %-*s[%d] = 0x%016llx 0x%016llx\n",
+			       22, "slb_shadow", i, esid, vsid);
 		}
 	}
 	DUMP(p, vmalloc_sllp, "%#-*x");
 	DUMP(p, slb_cache_ptr, "%#-*x");
 	for (i = 0; i < SLB_CACHE_ENTRIES; i++)
-		printf(" slb_cache[%d]:        = 0x%016x\n", i, p->slb_cache[i]);
+		printf(" %-*s[%d] = 0x%016x\n",
+		       22, "slb_cache", i, p->slb_cache[i]);
 
 	DUMP(p, rfi_flush_fallback_area, "%-*px");
 #endif
@@ -2404,7 +2405,7 @@ static void dump_one_paca(int cpu)
 #endif
 	DUMP(p, __current, "%-*px");
 	DUMP(p, kstack, "%#-*llx");
-	printf(" kstack_base          = 0x%016llx\n", p->kstack & ~(THREAD_SIZE - 1));
+	printf(" %-*s = 0x%016llx\n", 25, "kstack_base", p->kstack & ~(THREAD_SIZE - 1));
 	DUMP(p, stab_rr, "%#-*llx");
 	DUMP(p, saved_r1, "%#-*llx");
 	DUMP(p, trap_save, "%#-*x");

commit e70d8f55268ba95f00c61857df2bab638365f10f
Author: Mathieu Malaterre <malat@debian.org>
Date:   Sun Mar 25 11:06:47 2018 +0200

    powerpc/xmon: Add __printf annotation to xmon_printf()
    
    This allows the compiler to verify the format strings vs the types of
    the arguments.
    
    Update the other prototype declarations in asm/xmon.h.
    
    Silence warnings (triggered at W=1) by adding relevant __printf
    attribute. Move #define at bottom of the file to prevent conflict with
    gcc attribute.
    
    Solves the original warning:
    
      arch/powerpc/xmon/nonstdio.c:178:2: error: function might be
      possible candidate for âgnu_printfâ format attribute
    
    In turn this uncovered many formatting errors in xmon.c, all fixed in
    this patch.
    
    Signed-off-by: Mathieu Malaterre <malat@debian.org>
    [mpe: Always use px not p, fixup the 44x specific code, tweak change log]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index a3d597c8cfa2..152eb185bfcf 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -515,7 +515,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 		get_output_lock();
 		excprint(regs);
 		if (bp) {
-			printf("cpu 0x%x stopped at breakpoint 0x%lx (",
+			printf("cpu 0x%x stopped at breakpoint 0x%tx (",
 			       cpu, BP_NUM(bp));
 			xmon_print_symbol(regs->nip, " ", ")\n");
 		}
@@ -622,7 +622,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 		excprint(regs);
 		bp = at_breakpoint(regs->nip);
 		if (bp) {
-			printf("Stopped at breakpoint %lx (", BP_NUM(bp));
+			printf("Stopped at breakpoint %tx (", BP_NUM(bp));
 			xmon_print_symbol(regs->nip, " ", ")\n");
 		}
 		if (unrecoverable_excp(regs))
@@ -1171,7 +1171,7 @@ static int cpu_cmd(void)
 	}
 	/* try to switch to cpu specified */
 	if (!cpumask_test_cpu(cpu, &cpus_in_xmon)) {
-		printf("cpu 0x%x isn't in xmon\n", cpu);
+		printf("cpu 0x%lx isn't in xmon\n", cpu);
 		return 0;
 	}
 	xmon_taken = 0;
@@ -1185,7 +1185,7 @@ static int cpu_cmd(void)
 			/* take control back */
 			mb();
 			xmon_owner = smp_processor_id();
-			printf("cpu 0x%x didn't take control\n", cpu);
+			printf("cpu 0x%lx didn't take control\n", cpu);
 			return 0;
 		}
 		barrier();
@@ -1375,7 +1375,7 @@ bpt_cmds(void)
 			}
 		}
 
-		printf("Cleared breakpoint %lx (", BP_NUM(bp));
+		printf("Cleared breakpoint %tx (", BP_NUM(bp));
 		xmon_print_symbol(bp->address, " ", ")\n");
 		bp->enabled = 0;
 		break;
@@ -1402,7 +1402,7 @@ bpt_cmds(void)
 			for (bp = bpts; bp < &bpts[NBPTS]; ++bp) {
 				if (!bp->enabled)
 					continue;
-				printf("%2x %s   ", BP_NUM(bp),
+				printf("%tx %s   ", BP_NUM(bp),
 				    (bp->enabled & BP_CIABR) ? "inst": "trap");
 				xmon_print_symbol(bp->address, "  ", "\n");
 			}
@@ -1619,11 +1619,11 @@ static void excprint(struct pt_regs *fp)
 #endif /* CONFIG_SMP */
 
 	trap = TRAP(fp);
-	printf("Vector: %lx %s at [%lx]\n", fp->trap, getvecname(trap), fp);
+	printf("Vector: %lx %s at [%px]\n", fp->trap, getvecname(trap), fp);
 	printf("    pc: ");
 	xmon_print_symbol(fp->nip, ": ", "\n");
 
-	printf("    lr: ", fp->link);
+	printf("    lr: ");
 	xmon_print_symbol(fp->link, ": ", "\n");
 
 	printf("    sp: %lx\n", fp->gpr[1]);
@@ -1635,13 +1635,13 @@ static void excprint(struct pt_regs *fp)
 			printf(" dsisr: %lx\n", fp->dsisr);
 	}
 
-	printf("  current = 0x%lx\n", current);
+	printf("  current = 0x%px\n", current);
 #ifdef CONFIG_PPC64
-	printf("  paca    = 0x%lx\t softe: %d\t irq_happened: 0x%02x\n",
+	printf("  paca    = 0x%px\t softe: %d\t irq_happened: 0x%02x\n",
 	       local_paca, local_paca->irq_soft_mask, local_paca->irq_happened);
 #endif
 	if (current) {
-		printf("    pid   = %ld, comm = %s\n",
+		printf("    pid   = %d, comm = %s\n",
 		       current->pid, current->comm);
 	}
 
@@ -1677,16 +1677,16 @@ static void prregs(struct pt_regs *fp)
 #ifdef CONFIG_PPC64
 	if (FULL_REGS(fp)) {
 		for (n = 0; n < 16; ++n)
-			printf("R%.2ld = "REG"   R%.2ld = "REG"\n",
+			printf("R%.2d = "REG"   R%.2d = "REG"\n",
 			       n, fp->gpr[n], n+16, fp->gpr[n+16]);
 	} else {
 		for (n = 0; n < 7; ++n)
-			printf("R%.2ld = "REG"   R%.2ld = "REG"\n",
+			printf("R%.2d = "REG"   R%.2d = "REG"\n",
 			       n, fp->gpr[n], n+7, fp->gpr[n+7]);
 	}
 #else
 	for (n = 0; n < 32; ++n) {
-		printf("R%.2d = %.8x%s", n, fp->gpr[n],
+		printf("R%.2d = %.8lx%s", n, fp->gpr[n],
 		       (n & 3) == 3? "\n": "   ");
 		if (n == 12 && !FULL_REGS(fp)) {
 			printf("\n");
@@ -1790,9 +1790,9 @@ static void dump_206_sprs(void)
 
 	/* Actually some of these pre-date 2.06, but whatevs */
 
-	printf("srr0   = %.16lx  srr1  = %.16lx dsisr  = %.8x\n",
+	printf("srr0   = %.16lx  srr1  = %.16lx dsisr  = %.8lx\n",
 		mfspr(SPRN_SRR0), mfspr(SPRN_SRR1), mfspr(SPRN_DSISR));
-	printf("dscr   = %.16lx  ppr   = %.16lx pir    = %.8x\n",
+	printf("dscr   = %.16lx  ppr   = %.16lx pir    = %.8lx\n",
 		mfspr(SPRN_DSCR), mfspr(SPRN_PPR), mfspr(SPRN_PIR));
 	printf("amr    = %.16lx  uamor = %.16lx\n",
 		mfspr(SPRN_AMR), mfspr(SPRN_UAMOR));
@@ -1800,11 +1800,11 @@ static void dump_206_sprs(void)
 	if (!(mfmsr() & MSR_HV))
 		return;
 
-	printf("sdr1   = %.16lx  hdar  = %.16lx hdsisr = %.8x\n",
+	printf("sdr1   = %.16lx  hdar  = %.16lx hdsisr = %.8lx\n",
 		mfspr(SPRN_SDR1), mfspr(SPRN_HDAR), mfspr(SPRN_HDSISR));
 	printf("hsrr0  = %.16lx hsrr1  = %.16lx hdec   = %.16lx\n",
 		mfspr(SPRN_HSRR0), mfspr(SPRN_HSRR1), mfspr(SPRN_HDEC));
-	printf("lpcr   = %.16lx  pcr   = %.16lx lpidr  = %.8x\n",
+	printf("lpcr   = %.16lx  pcr   = %.16lx lpidr  = %.8lx\n",
 		mfspr(SPRN_LPCR), mfspr(SPRN_PCR), mfspr(SPRN_LPID));
 	printf("hsprg0 = %.16lx hsprg1 = %.16lx amor   = %.16lx\n",
 		mfspr(SPRN_HSPRG0), mfspr(SPRN_HSPRG1), mfspr(SPRN_AMOR));
@@ -1821,10 +1821,10 @@ static void dump_207_sprs(void)
 	if (!cpu_has_feature(CPU_FTR_ARCH_207S))
 		return;
 
-	printf("dpdes  = %.16lx  tir   = %.16lx cir    = %.8x\n",
+	printf("dpdes  = %.16lx  tir   = %.16lx cir    = %.8lx\n",
 		mfspr(SPRN_DPDES), mfspr(SPRN_TIR), mfspr(SPRN_CIR));
 
-	printf("fscr   = %.16lx  tar   = %.16lx pspb   = %.8x\n",
+	printf("fscr   = %.16lx  tar   = %.16lx pspb   = %.8lx\n",
 		mfspr(SPRN_FSCR), mfspr(SPRN_TAR), mfspr(SPRN_PSPB));
 
 	msr = mfmsr();
@@ -1837,12 +1837,12 @@ static void dump_207_sprs(void)
 
 	printf("mmcr0  = %.16lx  mmcr1 = %.16lx mmcr2  = %.16lx\n",
 		mfspr(SPRN_MMCR0), mfspr(SPRN_MMCR1), mfspr(SPRN_MMCR2));
-	printf("pmc1   = %.8x pmc2 = %.8x  pmc3 = %.8x  pmc4   = %.8x\n",
+	printf("pmc1   = %.8lx pmc2 = %.8lx  pmc3 = %.8lx  pmc4   = %.8lx\n",
 		mfspr(SPRN_PMC1), mfspr(SPRN_PMC2),
 		mfspr(SPRN_PMC3), mfspr(SPRN_PMC4));
-	printf("mmcra  = %.16lx   siar = %.16lx pmc5   = %.8x\n",
+	printf("mmcra  = %.16lx   siar = %.16lx pmc5   = %.8lx\n",
 		mfspr(SPRN_MMCRA), mfspr(SPRN_SIAR), mfspr(SPRN_PMC5));
-	printf("sdar   = %.16lx   sier = %.16lx pmc6   = %.8x\n",
+	printf("sdar   = %.16lx   sier = %.16lx pmc6   = %.8lx\n",
 		mfspr(SPRN_SDAR), mfspr(SPRN_SIER), mfspr(SPRN_PMC6));
 	printf("ebbhr  = %.16lx  ebbrr = %.16lx bescr  = %.16lx\n",
 		mfspr(SPRN_EBBHR), mfspr(SPRN_EBBRR), mfspr(SPRN_BESCR));
@@ -2356,9 +2356,9 @@ static void dump_one_paca(int cpu)
 
 	DUMP(p, lock_token, "%#-*x");
 	DUMP(p, paca_index, "%#-*x");
-	DUMP(p, kernel_toc, "%#-*lx");
-	DUMP(p, kernelbase, "%#-*lx");
-	DUMP(p, kernel_msr, "%#-*lx");
+	DUMP(p, kernel_toc, "%#-*llx");
+	DUMP(p, kernelbase, "%#-*llx");
+	DUMP(p, kernel_msr, "%#-*llx");
 	DUMP(p, emergency_sp, "%-*px");
 #ifdef CONFIG_PPC_BOOK3S_64
 	DUMP(p, nmi_emergency_sp, "%-*px");
@@ -2367,7 +2367,7 @@ static void dump_one_paca(int cpu)
 	DUMP(p, in_mce, "%#-*x");
 	DUMP(p, hmi_event_available, "%#-*x");
 #endif
-	DUMP(p, data_offset, "%#-*lx");
+	DUMP(p, data_offset, "%#-*llx");
 	DUMP(p, hw_cpu_id, "%#-*x");
 	DUMP(p, cpu_start, "%#-*x");
 	DUMP(p, kexec_state, "%#-*x");
@@ -2382,14 +2382,14 @@ static void dump_one_paca(int cpu)
 		vsid = be64_to_cpu(p->slb_shadow_ptr->save_area[i].vsid);
 
 		if (esid || vsid) {
-			printf(" slb_shadow[%d]:       = 0x%016lx 0x%016lx\n",
+			printf(" slb_shadow[%d]:       = 0x%016llx 0x%016llx\n",
 				i, esid, vsid);
 		}
 	}
 	DUMP(p, vmalloc_sllp, "%#-*x");
 	DUMP(p, slb_cache_ptr, "%#-*x");
 	for (i = 0; i < SLB_CACHE_ENTRIES; i++)
-		printf(" slb_cache[%d]:        = 0x%016lx\n", i, p->slb_cache[i]);
+		printf(" slb_cache[%d]:        = 0x%016x\n", i, p->slb_cache[i]);
 
 	DUMP(p, rfi_flush_fallback_area, "%-*px");
 #endif
@@ -2403,10 +2403,10 @@ static void dump_one_paca(int cpu)
 	DUMP(p, dbg_kstack, "%-*px");
 #endif
 	DUMP(p, __current, "%-*px");
-	DUMP(p, kstack, "%#-*lx");
-	printf(" kstack_base          = 0x%016lx\n", p->kstack & ~(THREAD_SIZE - 1));
-	DUMP(p, stab_rr, "%#-*lx");
-	DUMP(p, saved_r1, "%#-*lx");
+	DUMP(p, kstack, "%#-*llx");
+	printf(" kstack_base          = 0x%016llx\n", p->kstack & ~(THREAD_SIZE - 1));
+	DUMP(p, stab_rr, "%#-*llx");
+	DUMP(p, saved_r1, "%#-*llx");
 	DUMP(p, trap_save, "%#-*x");
 	DUMP(p, irq_soft_mask, "%#-*x");
 	DUMP(p, irq_happened, "%#-*x");
@@ -2426,14 +2426,14 @@ static void dump_one_paca(int cpu)
 	DUMP(p, subcore_sibling_mask, "%#-*x");
 #endif
 
-	DUMP(p, accounting.utime, "%#-*llx");
-	DUMP(p, accounting.stime, "%#-*llx");
-	DUMP(p, accounting.utime_scaled, "%#-*llx");
-	DUMP(p, accounting.starttime, "%#-*llx");
-	DUMP(p, accounting.starttime_user, "%#-*llx");
-	DUMP(p, accounting.startspurr, "%#-*llx");
-	DUMP(p, accounting.utime_sspurr, "%#-*llx");
-	DUMP(p, accounting.steal_time, "%#-*llx");
+	DUMP(p, accounting.utime, "%#-*lx");
+	DUMP(p, accounting.stime, "%#-*lx");
+	DUMP(p, accounting.utime_scaled, "%#-*lx");
+	DUMP(p, accounting.starttime, "%#-*lx");
+	DUMP(p, accounting.starttime_user, "%#-*lx");
+	DUMP(p, accounting.startspurr, "%#-*lx");
+	DUMP(p, accounting.utime_sspurr, "%#-*lx");
+	DUMP(p, accounting.steal_time, "%#-*lx");
 #undef DUMP
 
 	catch_memory_errors = 0;
@@ -2579,7 +2579,7 @@ static void dump_by_size(unsigned long addr, long count, int size)
 			default: val = 0;
 			}
 
-			printf("%0*lx", size * 2, val);
+			printf("%0*llx", size * 2, val);
 		}
 		printf("\n");
 	}
@@ -2743,7 +2743,7 @@ generic_inst_dump(unsigned long adr, long count, int praddr,
 		dotted = 0;
 		last_inst = inst;
 		if (praddr)
-			printf(REG"  %.8x", adr, inst);
+			printf(REG"  %.8lx", adr, inst);
 		printf("\t");
 		dump_func(inst, adr);
 		printf("\n");
@@ -2875,7 +2875,7 @@ memdiffs(unsigned char *p1, unsigned char *p2, unsigned nb, unsigned maxpr)
 	for( n = nb; n > 0; --n )
 		if( *p1++ != *p2++ )
 			if( ++prt <= maxpr )
-				printf("%.16x %.2x # %.16x %.2x\n", p1 - 1,
+				printf("%px %.2x # %px %.2x\n", p1 - 1,
 					p1[-1], p2 - 1, p2[-1]);
 	if( prt > maxpr )
 		printf("Total of %d differences\n", prt);
@@ -2935,13 +2935,13 @@ memzcan(void)
 		if (ok && !ook) {
 			printf("%.8x .. ", a);
 		} else if (!ok && ook)
-			printf("%.8x\n", a - mskip);
+			printf("%.8lx\n", a - mskip);
 		ook = ok;
 		if (a + mskip < a)
 			break;
 	}
 	if (ook)
-		printf("%.8x\n", a - mskip);
+		printf("%.8lx\n", a - mskip);
 }
 
 static void show_task(struct task_struct *tsk)
@@ -3025,13 +3025,13 @@ static void show_pte(unsigned long addr)
 		return;
 	}
 
-	printf("pgd  @ 0x%016lx\n", pgdir);
+	printf("pgd  @ 0x%px\n", pgdir);
 
 	if (pgd_huge(*pgdp)) {
 		format_pte(pgdp, pgd_val(*pgdp));
 		return;
 	}
-	printf("pgdp @ 0x%016lx = 0x%016lx\n", pgdp, pgd_val(*pgdp));
+	printf("pgdp @ 0x%px = 0x%016lx\n", pgdp, pgd_val(*pgdp));
 
 	pudp = pud_offset(pgdp, addr);
 
@@ -3045,7 +3045,7 @@ static void show_pte(unsigned long addr)
 		return;
 	}
 
-	printf("pudp @ 0x%016lx = 0x%016lx\n", pudp, pud_val(*pudp));
+	printf("pudp @ 0x%px = 0x%016lx\n", pudp, pud_val(*pudp));
 
 	pmdp = pmd_offset(pudp, addr);
 
@@ -3058,7 +3058,7 @@ static void show_pte(unsigned long addr)
 		format_pte(pmdp, pmd_val(*pmdp));
 		return;
 	}
-	printf("pmdp @ 0x%016lx = 0x%016lx\n", pmdp, pmd_val(*pmdp));
+	printf("pmdp @ 0x%px = 0x%016lx\n", pmdp, pmd_val(*pmdp));
 
 	ptep = pte_offset_map(pmdp, addr);
 	if (pte_none(*ptep)) {
@@ -3457,9 +3457,9 @@ static void dump_tlb_44x(void)
 		asm volatile("tlbre  %0,%1,0" : "=r" (w0) : "r" (i));
 		asm volatile("tlbre  %0,%1,1" : "=r" (w1) : "r" (i));
 		asm volatile("tlbre  %0,%1,2" : "=r" (w2) : "r" (i));
-		printf("[%02x] %08x %08x %08x ", i, w0, w1, w2);
+		printf("[%02x] %08lx %08lx %08lx ", i, w0, w1, w2);
 		if (w0 & PPC44x_TLB_VALID) {
-			printf("V %08x -> %01x%08x %c%c%c%c%c",
+			printf("V %08lx -> %01lx%08lx %c%c%c%c%c",
 			       w0 & PPC44x_TLB_EPN_MASK,
 			       w1 & PPC44x_TLB_ERPN_MASK,
 			       w1 & PPC44x_TLB_RPN_MASK,
@@ -3883,19 +3883,19 @@ static void dump_spu_fields(struct spu *spu)
 	DUMP_FIELD(spu, "0x%lx", ls_size);
 	DUMP_FIELD(spu, "0x%x", node);
 	DUMP_FIELD(spu, "0x%lx", flags);
-	DUMP_FIELD(spu, "%d", class_0_pending);
-	DUMP_FIELD(spu, "0x%lx", class_0_dar);
-	DUMP_FIELD(spu, "0x%lx", class_1_dar);
-	DUMP_FIELD(spu, "0x%lx", class_1_dsisr);
-	DUMP_FIELD(spu, "0x%lx", irqs[0]);
-	DUMP_FIELD(spu, "0x%lx", irqs[1]);
-	DUMP_FIELD(spu, "0x%lx", irqs[2]);
+	DUMP_FIELD(spu, "%llu", class_0_pending);
+	DUMP_FIELD(spu, "0x%llx", class_0_dar);
+	DUMP_FIELD(spu, "0x%llx", class_1_dar);
+	DUMP_FIELD(spu, "0x%llx", class_1_dsisr);
+	DUMP_FIELD(spu, "0x%x", irqs[0]);
+	DUMP_FIELD(spu, "0x%x", irqs[1]);
+	DUMP_FIELD(spu, "0x%x", irqs[2]);
 	DUMP_FIELD(spu, "0x%x", slb_replace);
 	DUMP_FIELD(spu, "%d", pid);
 	DUMP_FIELD(spu, "0x%p", mm);
 	DUMP_FIELD(spu, "0x%p", ctx);
 	DUMP_FIELD(spu, "0x%p", rq);
-	DUMP_FIELD(spu, "0x%p", timestamp);
+	DUMP_FIELD(spu, "0x%llx", timestamp);
 	DUMP_FIELD(spu, "0x%lx", problem_phys);
 	DUMP_FIELD(spu, "0x%p", problem);
 	DUMP_VALUE("0x%x", problem->spu_runcntl_RW,
@@ -3926,7 +3926,7 @@ static void dump_spu_ls(unsigned long num, int subcmd)
 		__delay(200);
 	} else {
 		catch_memory_errors = 0;
-		printf("*** Error: accessing spu info for spu %d\n", num);
+		printf("*** Error: accessing spu info for spu %ld\n", num);
 		return;
 	}
 	catch_memory_errors = 0;

commit 6671683db8540e5766f44a1089549c168730ae41
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Mon May 21 21:06:19 2018 +1000

    powerpc/xmon: Specify the full format in DUMP() macro
    
    In dump_one_paca() the DUMP macro unconditionally prepends '#' to the
    printf format specifier. In most cases we're using either 'x' or 'lx'
    etc. and that is OK. But for 'p' and other formats using '#' is
    actually undefined, and once we enable printf() checking for
    xmon_printf() we will get warnings from the compiler.
    
    So just have each usage specify the full format, that way we can omit
    '#' when it's inappropriate.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Mathieu Malaterre <malat@debian.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 252df9741d20..a3d597c8cfa2 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2350,27 +2350,27 @@ static void dump_one_paca(int cpu)
 	printf(" %-*s = %s\n", 20, "present", cpu_present(cpu) ? "yes" : "no");
 	printf(" %-*s = %s\n", 20, "online", cpu_online(cpu) ? "yes" : "no");
 
-#define DUMP(paca, name, format) \
-	printf(" %-*s = %#-*"format"\t(0x%lx)\n", 20, #name, 18, paca->name, \
+#define DUMP(paca, name, format)				\
+	printf(" %-*s = "format"\t(0x%lx)\n", 20, #name, 18, paca->name, \
 		offsetof(struct paca_struct, name));
 
-	DUMP(p, lock_token, "x");
-	DUMP(p, paca_index, "x");
-	DUMP(p, kernel_toc, "lx");
-	DUMP(p, kernelbase, "lx");
-	DUMP(p, kernel_msr, "lx");
-	DUMP(p, emergency_sp, "px");
+	DUMP(p, lock_token, "%#-*x");
+	DUMP(p, paca_index, "%#-*x");
+	DUMP(p, kernel_toc, "%#-*lx");
+	DUMP(p, kernelbase, "%#-*lx");
+	DUMP(p, kernel_msr, "%#-*lx");
+	DUMP(p, emergency_sp, "%-*px");
 #ifdef CONFIG_PPC_BOOK3S_64
-	DUMP(p, nmi_emergency_sp, "px");
-	DUMP(p, mc_emergency_sp, "px");
-	DUMP(p, in_nmi, "x");
-	DUMP(p, in_mce, "x");
-	DUMP(p, hmi_event_available, "x");
+	DUMP(p, nmi_emergency_sp, "%-*px");
+	DUMP(p, mc_emergency_sp, "%-*px");
+	DUMP(p, in_nmi, "%#-*x");
+	DUMP(p, in_mce, "%#-*x");
+	DUMP(p, hmi_event_available, "%#-*x");
 #endif
-	DUMP(p, data_offset, "lx");
-	DUMP(p, hw_cpu_id, "x");
-	DUMP(p, cpu_start, "x");
-	DUMP(p, kexec_state, "x");
+	DUMP(p, data_offset, "%#-*lx");
+	DUMP(p, hw_cpu_id, "%#-*x");
+	DUMP(p, cpu_start, "%#-*x");
+	DUMP(p, kexec_state, "%#-*x");
 #ifdef CONFIG_PPC_BOOK3S_64
 	for (i = 0; i < SLB_NUM_BOLTED; i++) {
 		u64 esid, vsid;
@@ -2386,54 +2386,54 @@ static void dump_one_paca(int cpu)
 				i, esid, vsid);
 		}
 	}
-	DUMP(p, vmalloc_sllp, "x");
-	DUMP(p, slb_cache_ptr, "x");
+	DUMP(p, vmalloc_sllp, "%#-*x");
+	DUMP(p, slb_cache_ptr, "%#-*x");
 	for (i = 0; i < SLB_CACHE_ENTRIES; i++)
 		printf(" slb_cache[%d]:        = 0x%016lx\n", i, p->slb_cache[i]);
 
-	DUMP(p, rfi_flush_fallback_area, "px");
+	DUMP(p, rfi_flush_fallback_area, "%-*px");
 #endif
-	DUMP(p, dscr_default, "llx");
+	DUMP(p, dscr_default, "%#-*llx");
 #ifdef CONFIG_PPC_BOOK3E
-	DUMP(p, pgd, "px");
-	DUMP(p, kernel_pgd, "px");
-	DUMP(p, tcd_ptr, "px");
-	DUMP(p, mc_kstack, "px");
-	DUMP(p, crit_kstack, "px");
-	DUMP(p, dbg_kstack, "px");
+	DUMP(p, pgd, "%-*px");
+	DUMP(p, kernel_pgd, "%-*px");
+	DUMP(p, tcd_ptr, "%-*px");
+	DUMP(p, mc_kstack, "%-*px");
+	DUMP(p, crit_kstack, "%-*px");
+	DUMP(p, dbg_kstack, "%-*px");
 #endif
-	DUMP(p, __current, "px");
-	DUMP(p, kstack, "lx");
+	DUMP(p, __current, "%-*px");
+	DUMP(p, kstack, "%#-*lx");
 	printf(" kstack_base          = 0x%016lx\n", p->kstack & ~(THREAD_SIZE - 1));
-	DUMP(p, stab_rr, "lx");
-	DUMP(p, saved_r1, "lx");
-	DUMP(p, trap_save, "x");
-	DUMP(p, irq_soft_mask, "x");
-	DUMP(p, irq_happened, "x");
-	DUMP(p, io_sync, "x");
-	DUMP(p, irq_work_pending, "x");
-	DUMP(p, nap_state_lost, "x");
-	DUMP(p, sprg_vdso, "llx");
+	DUMP(p, stab_rr, "%#-*lx");
+	DUMP(p, saved_r1, "%#-*lx");
+	DUMP(p, trap_save, "%#-*x");
+	DUMP(p, irq_soft_mask, "%#-*x");
+	DUMP(p, irq_happened, "%#-*x");
+	DUMP(p, io_sync, "%#-*x");
+	DUMP(p, irq_work_pending, "%#-*x");
+	DUMP(p, nap_state_lost, "%#-*x");
+	DUMP(p, sprg_vdso, "%#-*llx");
 
 #ifdef CONFIG_PPC_TRANSACTIONAL_MEM
-	DUMP(p, tm_scratch, "llx");
+	DUMP(p, tm_scratch, "%#-*llx");
 #endif
 
 #ifdef CONFIG_PPC_POWERNV
-	DUMP(p, core_idle_state_ptr, "px");
-	DUMP(p, thread_idle_state, "x");
-	DUMP(p, thread_mask, "x");
-	DUMP(p, subcore_sibling_mask, "x");
+	DUMP(p, core_idle_state_ptr, "%-*px");
+	DUMP(p, thread_idle_state, "%#-*x");
+	DUMP(p, thread_mask, "%#-*x");
+	DUMP(p, subcore_sibling_mask, "%#-*x");
 #endif
 
-	DUMP(p, accounting.utime, "llx");
-	DUMP(p, accounting.stime, "llx");
-	DUMP(p, accounting.utime_scaled, "llx");
-	DUMP(p, accounting.starttime, "llx");
-	DUMP(p, accounting.starttime_user, "llx");
-	DUMP(p, accounting.startspurr, "llx");
-	DUMP(p, accounting.utime_sspurr, "llx");
-	DUMP(p, accounting.steal_time, "llx");
+	DUMP(p, accounting.utime, "%#-*llx");
+	DUMP(p, accounting.stime, "%#-*llx");
+	DUMP(p, accounting.utime_scaled, "%#-*llx");
+	DUMP(p, accounting.starttime, "%#-*llx");
+	DUMP(p, accounting.starttime_user, "%#-*llx");
+	DUMP(p, accounting.startspurr, "%#-*llx");
+	DUMP(p, accounting.utime_sspurr, "%#-*llx");
+	DUMP(p, accounting.steal_time, "%#-*llx");
 #undef DUMP
 
 	catch_memory_errors = 0;

commit 7daf59300999693b85233762b847f1b2313cccbd
Author: Michal Suchanek <msuchanek@suse.de>
Date:   Wed May 23 20:00:54 2018 +0200

    powerpc/xmon: Also setup debugger hooks when single-stepping
    
    When single-stepping kernel code from xmon without a debug hook
    enabled the kernel crashes. This can happen when kernel starts with
    xmon on crash disabled but xmon is entered using sysrq.
    
    Call force_enable_xmon when single-stepping in xmon to install the
    xmon debug hooks.
    
    Fixes: e1368d0c9edb ("powerpc/xmon: Setup debugger hooks when first break-point is set")
    Signed-off-by: Michal Suchanek <msuchanek@suse.de>
    Reviewed-by: Vaibhav Jain <vaibhav@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index a0842f1ff72c..252df9741d20 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -778,6 +778,16 @@ static int xmon_fault_handler(struct pt_regs *regs)
 	return 0;
 }
 
+/* Force enable xmon if not already enabled */
+static inline void force_enable_xmon(void)
+{
+	/* Enable xmon hooks if needed */
+	if (!xmon_on) {
+		printf("xmon: Enabling debugger hooks\n");
+		xmon_on = 1;
+	}
+}
+
 static struct bpt *at_breakpoint(unsigned long pc)
 {
 	int i;
@@ -1094,6 +1104,7 @@ static int do_step(struct pt_regs *regs)
 	unsigned int instr;
 	int stepped;
 
+	force_enable_xmon();
 	/* check we are in 64-bit kernel mode, translation enabled */
 	if ((regs->msr & (MSR_64BIT|MSR_PR|MSR_IR)) == (MSR_64BIT|MSR_IR)) {
 		if (mread(regs->nip, &instr, 4) == 4) {
@@ -1268,16 +1279,6 @@ static long check_bp_loc(unsigned long addr)
 	return 1;
 }
 
-/* Force enable xmon if not already enabled */
-static inline void force_enable_xmon(void)
-{
-	/* Enable xmon hooks if needed */
-	if (!xmon_on) {
-		printf("xmon: Enabling debugger hooks\n");
-		xmon_on = 1;
-	}
-}
-
 static char *breakpoint_help_string =
     "Breakpoint command usage:\n"
     "b                show breakpoints\n"

commit f437c51748fa1dd423a878c870ad203843a51c8d
Merge: 872a100a49c3 29ab6c4708a5
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Sat Mar 31 00:11:24 2018 +1100

    Merge branch 'topic/paca' into next
    
    Bring in yet another series that touches KVM code, and might need to
    be merged into the kvm-ppc branch to resolve conflicts.
    
    This required some changes in pnv_power9_force_smt4_catch/release()
    due to the paca array becomming an array of pointers.

commit d2e60075a3d4422dc54b919f3b125d8066b839d4
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Wed Feb 14 01:08:12 2018 +1000

    powerpc/64: Use array of paca pointers and allocate pacas individually
    
    Change the paca array into an array of pointers to pacas. Allocate
    pacas individually.
    
    This allows flexibility in where the PACAs are allocated. Future work
    will allocate them node-local. Platforms that don't have address limits
    on PACAs would be able to defer PACA allocations until later in boot
    rather than allocate all possible ones up-front then freeing unused.
    
    This is slightly more overhead (one additional indirection) for cross
    CPU paca references, but those aren't too common.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 82e1a3ee6e0f..b6574b6f7d4a 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2327,7 +2327,7 @@ static void dump_one_paca(int cpu)
 	catch_memory_errors = 1;
 	sync();
 
-	p = &paca[cpu];
+	p = paca_ptrs[cpu];
 
 	printf("paca for cpu 0x%x @ %px:\n", cpu, p);
 

commit c0b346729b5dd3c7d0232f043f5b15947ffc7978
Merge: 34a286a4ac57 9654153158d3
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Mar 27 23:55:49 2018 +1100

    Merge branch 'topic/ppc-kvm' into next
    
    Merge the DAWR series, which touches arch code and KVM code and may need
    to be merged into the kvm-ppc tree.

commit 9bc2bd5d9d8d3eddf410075e2eea70bb493dfa26
Author: Michael Neuling <mikey@neuling.org>
Date:   Tue Mar 27 15:37:19 2018 +1100

    powerpc: Update xmon to use ppc_breakpoint_available()
    
    The 'bd' command will now print an error and not set the breakpoint on
    P9.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    [mpe: Unsplit quoted string]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 82e1a3ee6e0f..b481f9f48489 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1297,6 +1297,10 @@ bpt_cmds(void)
 	static const char badaddr[] = "Only kernel addresses are permitted for breakpoints\n";
 	int mode;
 	case 'd':	/* bd - hardware data breakpoint */
+		if (!ppc_breakpoint_available()) {
+			printf("Hardware data breakpoint not supported on this cpu\n");
+			break;
+		}
 		mode = 7;
 		cmd = inchar();
 		if (cmd == 'r')

commit ab83dc794c9d8870e4844cca9a2945b782b8ee7e
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Mar 8 13:54:42 2018 +1100

    powerpc/xmon: Move empty plpar_set_ciabr() into plpar_wrappers.h
    
    Now that plpar_wrappers.h has an #ifdef PSERIES we can move the empty
    version of plpar_set_ciabr() which xmon wants into there.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 2bf6e2af28c2..a06cf6e38978 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -41,6 +41,7 @@
 #include <asm/pgtable.h>
 #include <asm/mmu.h>
 #include <asm/mmu_context.h>
+#include <asm/plpar_wrappers.h>
 #include <asm/cputable.h>
 #include <asm/rtas.h>
 #include <asm/sstep.h>
@@ -61,12 +62,6 @@
 #include <asm/paca.h>
 #endif
 
-#if defined(CONFIG_PPC_SPLPAR)
-#include <asm/plpar_wrappers.h>
-#else
-static inline long plpar_set_ciabr(unsigned long ciabr) {return 0; };
-#endif
-
 #include "nonstdio.h"
 #include "dis-asm.h"
 

commit 7c09c1869c9ceb8b356e23161d2ceb0ed0849ac5
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Mar 8 13:54:41 2018 +1100

    powerpc: Rename plapr routines to plpar
    
    Back in 2013 we added some hypercall wrappers which misspelled
    "plpar" (P-series Logical PARtition) as "plapr".
    
    Visually they're hard to distinguish and it almost doesn't matter, but
    it is confusing when grepping to miss some calls because of the typo.
    
    They've also started spreading, so before they take over let's fix
    them all to be "plpar".
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 3ddf9dd9a55f..2bf6e2af28c2 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -64,7 +64,7 @@
 #if defined(CONFIG_PPC_SPLPAR)
 #include <asm/plpar_wrappers.h>
 #else
-static inline long plapr_set_ciabr(unsigned long ciabr) {return 0; };
+static inline long plpar_set_ciabr(unsigned long ciabr) {return 0; };
 #endif
 
 #include "nonstdio.h"
@@ -328,7 +328,7 @@ static void write_ciabr(unsigned long ciabr)
 		mtspr(SPRN_CIABR, ciabr);
 		return;
 	}
-	plapr_set_ciabr(ciabr);
+	plpar_set_ciabr(ciabr);
 }
 
 /**

commit 1ff3b404019adf9d605224e1dce0677a0375d274
Author: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
Date:   Sun Mar 4 23:01:32 2018 +0530

    powerpc/xmon: Clear all breakpoints when xmon is disabled via debugfs
    
    Presently when xmon is disabled by debugfs any existing
    instruction/data-access breakpoints set are not disabled. This may
    lead to kernel oops when those breakpoints are hit as the necessary
    debugger hooks aren't installed.
    
    Hence this patch introduces a new function named clear_all_bpt() which
    is called when xmon is disabled via debugfs. The function will
    unpatch/clear all the trap and ciabr/dab based breakpoints.
    
    Signed-off-by: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
    Reviewed-by: Balbir Singh <bsingharora@gmail.com>
    [mpe: Fix build break when CONFIG_DEBUG_FS=n]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index ee4b6071007d..3ddf9dd9a55f 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -3664,11 +3664,35 @@ device_initcall(setup_xmon_sysrq);
 #endif /* CONFIG_MAGIC_SYSRQ */
 
 #ifdef CONFIG_DEBUG_FS
+static void clear_all_bpt(void)
+{
+	int i;
+
+	/* clear/unpatch all breakpoints */
+	remove_bpts();
+	remove_cpu_bpts();
+
+	/* Disable all breakpoints */
+	for (i = 0; i < NBPTS; ++i)
+		bpts[i].enabled = 0;
+
+	/* Clear any data or iabr breakpoints */
+	if (iabr || dabr.enabled) {
+		iabr = NULL;
+		dabr.enabled = 0;
+	}
+
+	printf("xmon: All breakpoints cleared\n");
+}
+
 static int xmon_dbgfs_set(void *data, u64 val)
 {
 	xmon_on = !!val;
 	xmon_init(xmon_on);
 
+	/* make sure all breakpoints removed when disabling */
+	if (!xmon_on)
+		clear_all_bpt();
 	return 0;
 }
 

commit e1368d0c9edbc366e45216e7295fd61ae55c2b12
Author: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
Date:   Sun Mar 4 23:00:25 2018 +0530

    powerpc/xmon: Setup debugger hooks when first break-point is set
    
    Presently sysrq key for xmon('x') is registered during kernel init
    irrespective of the value of kernel param 'xmon'. Thus xmon is enabled
    even if 'xmon=off' is passed on the kernel command line. However this
    doesn't enable the kernel debugger hooks needed for instruction or
    data breakpoints. Thus when a break-point is hit with xmon=off a
    kernel oops of the form below is reported:
    
      Oops: Exception in kernel mode, sig: 5 [#1]
      < snip >
      Trace/breakpoint trap
    
    To fix this the patch checks and enables debugger hooks when an
    instruction or data break-point is set via xmon console.
    
    Signed-off-by: Vaibhav Jain <vaibhav@linux.vnet.ibm.com>
    Reviewed-by: Balbir Singh <bsingharora@gmail.com>
    [mpe: Just printf directly, no need for static const char[]]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 82e1a3ee6e0f..ee4b6071007d 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1273,6 +1273,16 @@ static long check_bp_loc(unsigned long addr)
 	return 1;
 }
 
+/* Force enable xmon if not already enabled */
+static inline void force_enable_xmon(void)
+{
+	/* Enable xmon hooks if needed */
+	if (!xmon_on) {
+		printf("xmon: Enabling debugger hooks\n");
+		xmon_on = 1;
+	}
+}
+
 static char *breakpoint_help_string =
     "Breakpoint command usage:\n"
     "b                show breakpoints\n"
@@ -1315,6 +1325,8 @@ bpt_cmds(void)
 			dabr.address &= ~HW_BRK_TYPE_DABR;
 			dabr.enabled = mode | BP_DABR;
 		}
+
+		force_enable_xmon();
 		break;
 
 	case 'i':	/* bi - hardware instr breakpoint */
@@ -1335,6 +1347,7 @@ bpt_cmds(void)
 		if (bp != NULL) {
 			bp->enabled |= BP_CIABR;
 			iabr = bp;
+			force_enable_xmon();
 		}
 		break;
 #endif
@@ -1399,8 +1412,10 @@ bpt_cmds(void)
 		if (!check_bp_loc(a))
 			break;
 		bp = new_breakpoint(a);
-		if (bp != NULL)
+		if (bp != NULL) {
 			bp->enabled |= BP_TRAP;
+			force_enable_xmon();
+		}
 		break;
 	}
 }

commit bdcb1aefc5b3f7d0f1dc8b02673602bca2ff7a4b
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Wed Jan 17 23:58:18 2018 +1000

    powerpc/64s: Improve RFI L1-D cache flush fallback
    
    The fallback RFI flush is used when firmware does not provide a way
    to flush the cache. It's a "displacement flush" that evicts useful
    data by displacing it with an uninteresting buffer.
    
    The flush has to take care to work with implementation specific cache
    replacment policies, so the recipe has been in flux. The initial
    slow but conservative approach is to touch all lines of a congruence
    class, with dependencies between each load. It has since been
    determined that a linear pattern of loads without dependencies is
    sufficient, and is significantly faster.
    
    Measuring the speed of a null syscall with RFI fallback flush enabled
    gives the relative improvement:
    
    P8 - 1.83x
    P9 - 1.75x
    
    The flush also becomes simpler and more adaptable to different cache
    geometries.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 01d9a2dcff20..82e1a3ee6e0f 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2377,8 +2377,6 @@ static void dump_one_paca(int cpu)
 		printf(" slb_cache[%d]:        = 0x%016lx\n", i, p->slb_cache[i]);
 
 	DUMP(p, rfi_flush_fallback_area, "px");
-	DUMP(p, l1d_flush_congruence, "llx");
-	DUMP(p, l1d_flush_sets, "llx");
 #endif
 	DUMP(p, dscr_default, "llx");
 #ifdef CONFIG_PPC_BOOK3E

commit ebf0b6a8b1e445d2be66087732aafcda12ab9f59
Merge: 5400fc229e60 1b689a95ce74
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Sun Jan 21 23:21:14 2018 +1100

    Merge branch 'fixes' into next
    
    Merge our fixes branch from the 4.15 cycle.
    
    Unusually the fixes branch saw some significant features merged,
    notably the RFI flush patches, so we want the code in next to be
    tested against that, to avoid any surprises when the two are merged.
    
    There's also some other work on the panic handling that was reverted
    in fixes and we now want to do properly in next, which would conflict.
    
    And we also fix a few other minor merge conflicts.

commit 4e26bc4a4ed683c42ba45f09050575a671c6f1f4
Author: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
Date:   Wed Dec 20 09:25:50 2017 +0530

    powerpc/64: Rename soft_enabled to irq_soft_mask
    
    Rename the paca->soft_enabled to paca->irq_soft_mask as it is no
    longer used as a flag for interrupt state, but a mask.
    
    Signed-off-by: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 1b2d8cb49abb..2695f8dd2359 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1623,7 +1623,7 @@ static void excprint(struct pt_regs *fp)
 	printf("  current = 0x%lx\n", current);
 #ifdef CONFIG_PPC64
 	printf("  paca    = 0x%lx\t softe: %d\t irq_happened: 0x%02x\n",
-	       local_paca, local_paca->soft_enabled, local_paca->irq_happened);
+	       local_paca, local_paca->irq_soft_mask, local_paca->irq_happened);
 #endif
 	if (current) {
 		printf("    pid   = %ld, comm = %s\n",
@@ -2391,7 +2391,7 @@ static void dump_one_paca(int cpu)
 	DUMP(p, stab_rr, "lx");
 	DUMP(p, saved_r1, "lx");
 	DUMP(p, trap_save, "x");
-	DUMP(p, soft_enabled, "x");
+	DUMP(p, irq_soft_mask, "x");
 	DUMP(p, irq_happened, "x");
 	DUMP(p, io_sync, "x");
 	DUMP(p, irq_work_pending, "x");

commit 2248fade965a5f1ba2a8e6e63f84df696b2d2780
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Jan 11 01:17:24 2018 +1100

    powerpc/xmon: Don't print hashed pointers in paca dump
    
    Remember when the biggest problem we had to worry about was hashed
    pointers, those were the days.
    
    These were missed in my earlier patch because they don't match "%p",
    but the macro is hiding a "%p", so these all end up being hashed,
    which is not what we want in xmon. Convert them to "%px".
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index b3bb5beec54a..0ddc7ac6c5f1 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2344,10 +2344,10 @@ static void dump_one_paca(int cpu)
 	DUMP(p, kernel_toc, "lx");
 	DUMP(p, kernelbase, "lx");
 	DUMP(p, kernel_msr, "lx");
-	DUMP(p, emergency_sp, "p");
+	DUMP(p, emergency_sp, "px");
 #ifdef CONFIG_PPC_BOOK3S_64
-	DUMP(p, nmi_emergency_sp, "p");
-	DUMP(p, mc_emergency_sp, "p");
+	DUMP(p, nmi_emergency_sp, "px");
+	DUMP(p, mc_emergency_sp, "px");
 	DUMP(p, in_nmi, "x");
 	DUMP(p, in_mce, "x");
 	DUMP(p, hmi_event_available, "x");
@@ -2382,14 +2382,14 @@ static void dump_one_paca(int cpu)
 #endif
 	DUMP(p, dscr_default, "llx");
 #ifdef CONFIG_PPC_BOOK3E
-	DUMP(p, pgd, "p");
-	DUMP(p, kernel_pgd, "p");
-	DUMP(p, tcd_ptr, "p");
-	DUMP(p, mc_kstack, "p");
-	DUMP(p, crit_kstack, "p");
-	DUMP(p, dbg_kstack, "p");
+	DUMP(p, pgd, "px");
+	DUMP(p, kernel_pgd, "px");
+	DUMP(p, tcd_ptr, "px");
+	DUMP(p, mc_kstack, "px");
+	DUMP(p, crit_kstack, "px");
+	DUMP(p, dbg_kstack, "px");
 #endif
-	DUMP(p, __current, "p");
+	DUMP(p, __current, "px");
 	DUMP(p, kstack, "lx");
 	printf(" kstack_base          = 0x%016lx\n", p->kstack & ~(THREAD_SIZE - 1));
 	DUMP(p, stab_rr, "lx");
@@ -2407,7 +2407,7 @@ static void dump_one_paca(int cpu)
 #endif
 
 #ifdef CONFIG_PPC_POWERNV
-	DUMP(p, core_idle_state_ptr, "p");
+	DUMP(p, core_idle_state_ptr, "px");
 	DUMP(p, thread_idle_state, "x");
 	DUMP(p, thread_mask, "x");
 	DUMP(p, subcore_sibling_mask, "x");

commit 274920a3ecd5f43af0cc380bc0a9ee73a52b9f8a
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Jan 10 23:49:12 2018 +1100

    powerpc/xmon: Add RFI flush related fields to paca dump
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index cab24f549e7c..b3bb5beec54a 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2375,6 +2375,10 @@ static void dump_one_paca(int cpu)
 	DUMP(p, slb_cache_ptr, "x");
 	for (i = 0; i < SLB_CACHE_ENTRIES; i++)
 		printf(" slb_cache[%d]:        = 0x%016lx\n", i, p->slb_cache[i]);
+
+	DUMP(p, rfi_flush_fallback_area, "px");
+	DUMP(p, l1d_flush_congruence, "llx");
+	DUMP(p, l1d_flush_sets, "llx");
 #endif
 	DUMP(p, dscr_default, "llx");
 #ifdef CONFIG_PPC_BOOK3E

commit d8104182087319fd753d6d8e0afcd95d84c2aa2f
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Dec 6 23:23:28 2017 +1100

    powerpc/xmon: Don't print hashed pointers in xmon
    
    Since commit ad67b74d2469 ("printk: hash addresses printed with %p")
    pointers printed with %p are hashed, ie. you don't see the actual
    pointer value but rather a cryptographic hash of its value.
    
    In xmon we want to see the actual pointer values, because xmon is a
    debugger, so replace %p with %px which prints the actual pointer
    value.
    
    We justify doing this in xmon because 1) xmon is a kernel crash
    debugger, it's only accessible via the console 2) xmon doesn't print
    to dmesg, so the pointers it prints are not able to be leaked that
    way.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 1b2d8cb49abb..cab24f549e7c 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1590,7 +1590,7 @@ static void print_bug_trap(struct pt_regs *regs)
 	printf("kernel BUG at %s:%u!\n",
 	       bug->file, bug->line);
 #else
-	printf("kernel BUG at %p!\n", (void *)bug->bug_addr);
+	printf("kernel BUG at %px!\n", (void *)bug->bug_addr);
 #endif
 #endif /* CONFIG_BUG */
 }
@@ -2329,7 +2329,7 @@ static void dump_one_paca(int cpu)
 
 	p = &paca[cpu];
 
-	printf("paca for cpu 0x%x @ %p:\n", cpu, p);
+	printf("paca for cpu 0x%x @ %px:\n", cpu, p);
 
 	printf(" %-*s = %s\n", 20, "possible", cpu_possible(cpu) ? "yes" : "no");
 	printf(" %-*s = %s\n", 20, "present", cpu_present(cpu) ? "yes" : "no");
@@ -2945,7 +2945,7 @@ static void show_task(struct task_struct *tsk)
 		(tsk->exit_state & EXIT_DEAD) ? 'E' :
 		(tsk->state & TASK_INTERRUPTIBLE) ? 'S' : '?';
 
-	printf("%p %016lx %6d %6d %c %2d %s\n", tsk,
+	printf("%px %016lx %6d %6d %c %2d %s\n", tsk,
 		tsk->thread.ksp,
 		tsk->pid, tsk->parent->pid,
 		state, task_thread_info(tsk)->cpu,
@@ -2988,7 +2988,7 @@ static void show_pte(unsigned long addr)
 
 	if (setjmp(bus_error_jmp) != 0) {
 		catch_memory_errors = 0;
-		printf("*** Error dumping pte for task %p\n", tsk);
+		printf("*** Error dumping pte for task %px\n", tsk);
 		return;
 	}
 
@@ -3074,7 +3074,7 @@ static void show_tasks(void)
 
 	if (setjmp(bus_error_jmp) != 0) {
 		catch_memory_errors = 0;
-		printf("*** Error dumping task %p\n", tsk);
+		printf("*** Error dumping task %px\n", tsk);
 		return;
 	}
 

commit 80eff6c484799722736471d15ff9cc86b64cae7a
Author: Balbir Singh <bsingharora@gmail.com>
Date:   Mon Oct 30 22:01:12 2017 +1100

    powerpc/xmon: Support dumping software pagetables
    
    It would be nice to be able to dump page tables in a particular
    context.
    
    eg: dumping vmalloc space:
    
      0:mon> dv 0xd00037fffff00000
      pgd  @ 0xc0000000017c0000
      pgdp @ 0xc0000000017c00d8 = 0x00000000f10b1000
      pudp @ 0xc0000000f10b13f8 = 0x00000000f10d0000
      pmdp @ 0xc0000000f10d1ff8 = 0x00000000f1102000
      ptep @ 0xc0000000f1102780 = 0xc0000000f1ba018e
      Maps physical address = 0x00000000f1ba0000
      Flags = Accessed Dirty Read Write
    
    This patch does not replicate the complex code of dump_pagetable and
    has no support for bolted linear mapping, thats why I've it's called
    dump virtual page table support. The format of the PTE can be expanded
    even further to add more useful information about the flags in the PTE
    if required.
    
    Signed-off-by: Balbir Singh <bsingharora@gmail.com>
    [mpe: Bike shed the output format, show the pgdir, fix build failures]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 6b1236b85622..1b2d8cb49abb 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -28,6 +28,7 @@
 #include <linux/bug.h>
 #include <linux/nmi.h>
 #include <linux/ctype.h>
+#include <linux/highmem.h>
 
 #include <asm/debugfs.h>
 #include <asm/ptrace.h>
@@ -127,6 +128,7 @@ static void byterev(unsigned char *, int);
 static void memex(void);
 static int bsesc(void);
 static void dump(void);
+static void show_pte(unsigned long);
 static void prdump(unsigned long, long);
 static int ppc_inst_dump(unsigned long, long, int);
 static void dump_log_buf(void);
@@ -234,6 +236,7 @@ Commands:\n\
 #endif
   "\
   dr	dump stream of raw bytes\n\
+  dv	dump virtual address translation \n\
   dt	dump the tracing buffers (uses printk)\n\
   dtc	dump the tracing buffers for current CPU (uses printk)\n\
 "
@@ -2613,6 +2616,9 @@ dump(void)
 		dump_log_buf();
 	} else if (c == 'o') {
 		dump_opal_msglog();
+	} else if (c == 'v') {
+		/* dump virtual to physical translation */
+		show_pte(adrs);
 	} else if (c == 'r') {
 		scanhex(&ndump);
 		if (ndump == 0)
@@ -2946,6 +2952,116 @@ static void show_task(struct task_struct *tsk)
 		tsk->comm);
 }
 
+#ifdef CONFIG_PPC_BOOK3S_64
+void format_pte(void *ptep, unsigned long pte)
+{
+	printf("ptep @ 0x%016lx = 0x%016lx\n", (unsigned long)ptep, pte);
+	printf("Maps physical address = 0x%016lx\n", pte & PTE_RPN_MASK);
+
+	printf("Flags = %s%s%s%s%s\n",
+	       (pte & _PAGE_ACCESSED) ? "Accessed " : "",
+	       (pte & _PAGE_DIRTY)    ? "Dirty " : "",
+	       (pte & _PAGE_READ)     ? "Read " : "",
+	       (pte & _PAGE_WRITE)    ? "Write " : "",
+	       (pte & _PAGE_EXEC)     ? "Exec " : "");
+}
+
+static void show_pte(unsigned long addr)
+{
+	unsigned long tskv = 0;
+	struct task_struct *tsk = NULL;
+	struct mm_struct *mm;
+	pgd_t *pgdp, *pgdir;
+	pud_t *pudp;
+	pmd_t *pmdp;
+	pte_t *ptep;
+
+	if (!scanhex(&tskv))
+		mm = &init_mm;
+	else
+		tsk = (struct task_struct *)tskv;
+
+	if (tsk == NULL)
+		mm = &init_mm;
+	else
+		mm = tsk->active_mm;
+
+	if (setjmp(bus_error_jmp) != 0) {
+		catch_memory_errors = 0;
+		printf("*** Error dumping pte for task %p\n", tsk);
+		return;
+	}
+
+	catch_memory_errors = 1;
+	sync();
+
+	if (mm == &init_mm) {
+		pgdp = pgd_offset_k(addr);
+		pgdir = pgd_offset_k(0);
+	} else {
+		pgdp = pgd_offset(mm, addr);
+		pgdir = pgd_offset(mm, 0);
+	}
+
+	if (pgd_none(*pgdp)) {
+		printf("no linux page table for address\n");
+		return;
+	}
+
+	printf("pgd  @ 0x%016lx\n", pgdir);
+
+	if (pgd_huge(*pgdp)) {
+		format_pte(pgdp, pgd_val(*pgdp));
+		return;
+	}
+	printf("pgdp @ 0x%016lx = 0x%016lx\n", pgdp, pgd_val(*pgdp));
+
+	pudp = pud_offset(pgdp, addr);
+
+	if (pud_none(*pudp)) {
+		printf("No valid PUD\n");
+		return;
+	}
+
+	if (pud_huge(*pudp)) {
+		format_pte(pudp, pud_val(*pudp));
+		return;
+	}
+
+	printf("pudp @ 0x%016lx = 0x%016lx\n", pudp, pud_val(*pudp));
+
+	pmdp = pmd_offset(pudp, addr);
+
+	if (pmd_none(*pmdp)) {
+		printf("No valid PMD\n");
+		return;
+	}
+
+	if (pmd_huge(*pmdp)) {
+		format_pte(pmdp, pmd_val(*pmdp));
+		return;
+	}
+	printf("pmdp @ 0x%016lx = 0x%016lx\n", pmdp, pmd_val(*pmdp));
+
+	ptep = pte_offset_map(pmdp, addr);
+	if (pte_none(*ptep)) {
+		printf("no valid PTE\n");
+		return;
+	}
+
+	format_pte(ptep, pte_val(*ptep));
+
+	sync();
+	__delay(200);
+	catch_memory_errors = 0;
+}
+#else
+static void show_pte(unsigned long addr)
+{
+	printf("show_pte not yet implemented\n");
+}
+#endif /* CONFIG_PPC_BOOK3S_64 */
+
 static void show_tasks(void)
 {
 	unsigned long tskv;

commit 4e003747043d57aa75c9762fa148ef38afe68dd8
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Oct 19 15:08:43 2017 +1100

    powerpc/64s: Replace CONFIG_PPC_STD_MMU_64 with CONFIG_PPC_BOOK3S_64
    
    CONFIG_PPC_STD_MMU_64 indicates support for the "standard" powerpc MMU
    on 64-bit CPUs. The "standard" MMU refers to the hash page table MMU
    found in "server" processors, from IBM mainly.
    
    Currently CONFIG_PPC_STD_MMU_64 is == CONFIG_PPC_BOOK3S_64. While it's
    annoying to have two symbols that always have the same value, it's not
    quite annoying enough to bother removing one.
    
    However with the arrival of Power9, we now have the situation where
    CONFIG_PPC_STD_MMU_64 is enabled, but the kernel is running using the
    Radix MMU - *not* the "standard" MMU. So it is now actively confusing
    to use it, because it implies that code is disabled or inactive when
    the Radix MMU is in use, however that is not necessarily true.
    
    So s/CONFIG_PPC_STD_MMU_64/CONFIG_PPC_BOOK3S_64/, and do some minor
    formatting updates of some of the affected lines.
    
    This will be a pain for backports, but c'est la vie.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 83e7faf5b3d3..6b1236b85622 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2312,7 +2312,7 @@ static void dump_tracing(void)
 static void dump_one_paca(int cpu)
 {
 	struct paca_struct *p;
-#ifdef CONFIG_PPC_STD_MMU_64
+#ifdef CONFIG_PPC_BOOK3S_64
 	int i = 0;
 #endif
 
@@ -2353,7 +2353,7 @@ static void dump_one_paca(int cpu)
 	DUMP(p, hw_cpu_id, "x");
 	DUMP(p, cpu_start, "x");
 	DUMP(p, kexec_state, "x");
-#ifdef CONFIG_PPC_STD_MMU_64
+#ifdef CONFIG_PPC_BOOK3S_64
 	for (i = 0; i < SLB_NUM_BOLTED; i++) {
 		u64 esid, vsid;
 
@@ -3263,7 +3263,7 @@ static void xmon_print_symbol(unsigned long address, const char *mid,
 	printf("%s", after);
 }
 
-#ifdef CONFIG_PPC_STD_MMU_64
+#ifdef CONFIG_PPC_BOOK3S_64
 void dump_segments(void)
 {
 	int i;

commit 90d6473747b289739b435d5fa6ae8e38ae2921d1
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Mon Oct 9 21:59:32 2017 +1100

    powerpc/xmon: Add kstack base to paca dump
    
    When dumping the paca in xmon we currently show kstack. Although it's
    not hard it's a bit fiddly to work out what the bounds of the kernel
    stack should be based on the kstack value.
    
    To make life easier and "kstack_base" which is the base (lowest
    address) of the kernel stack, eg:
    
     kstack               = 0xc0000000f1a7be30      (0x258)
     kstack_base          = 0xc0000000f1a78000
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 2e2320edb96b..83e7faf5b3d3 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2384,6 +2384,7 @@ static void dump_one_paca(int cpu)
 #endif
 	DUMP(p, __current, "p");
 	DUMP(p, kstack, "lx");
+	printf(" kstack_base          = 0x%016lx\n", p->kstack & ~(THREAD_SIZE - 1));
 	DUMP(p, stab_rr, "lx");
 	DUMP(p, saved_r1, "lx");
 	DUMP(p, trap_save, "x");

commit 402e172a2ce76210f2fe921cf419d12103851344
Author: Breno Leitao <leitao@debian.org>
Date:   Tue Oct 17 16:20:18 2017 -0200

    powerpc/xmon: Check before calling xive functions
    
    Currently xmon could call XIVE functions from OPAL even if the XIVE is
    disabled or does not exist in the system, as in POWER8 machines. This
    causes the following exception:
    
     1:mon> dx
     cpu 0x1: Vector: 700 (Program Check) at [c000000423c93450]
         pc: c00000000009cfa4: opal_xive_dump+0x50/0x68
         lr: c0000000000997b8: opal_return+0x0/0x50
    
    This patch simply checks if XIVE is enabled before calling XIVE
    functions.
    
    Fixes: 243e25112d06 ("powerpc/xive: Native exploitation of the XIVE interrupt controller")
    Suggested-by: Guilherme G. Piccoli <gpiccoli@linux.vnet.ibm.com>
    Signed-off-by: Breno Leitao <leitao@debian.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 4679aeb84767..2e2320edb96b 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2508,6 +2508,11 @@ static void dump_xives(void)
 	unsigned long num;
 	int c;
 
+	if (!xive_enabled()) {
+		printf("Xive disabled on this system\n");
+		return;
+	}
+
 	c = inchar();
 	if (c == 'a') {
 		dump_all_xives();

commit 59d3391e8cf274097c42369866070c565891bae5
Author: Guilherme G. Piccoli <gpiccoli@linux.vnet.ibm.com>
Date:   Mon Sep 18 11:16:58 2017 -0300

    powerpc/xmon: Add option to show uptime information
    
    It might be useful to quickly get the uptime of a running system on
    xmon, without needing to grab data from memory and doing math on
    struct addresses.
    
    For example, it'd be useful to check for how long after a crash a
    system is on xmon shell or if some test was started after the first
    test crashed (and this 2nd test crashed too into xmon).
    
    This small patch adds the 'U' command, to accomplish this.
    
    Suggested-by: Murilo Fossa Vicentini <muvic@linux.vnet.ibm.com>
    Signed-off-by: Guilherme G. Piccoli <gpiccoli@linux.vnet.ibm.com>
    [mpe: Display units (seconds), add sync()/__delay() sequence]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index d9a12102b111..4679aeb84767 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -278,6 +278,7 @@ Commands:\n\
 #elif defined(CONFIG_44x) || defined(CONFIG_PPC_BOOK3E)
 "  u	dump TLB\n"
 #endif
+"  U	show uptime information\n"
 "  ?	help\n"
 "  # n	limit output to n lines per page (for dp, dpa, dl)\n"
 "  zr	reboot\n\
@@ -905,6 +906,26 @@ static void remove_cpu_bpts(void)
 	write_ciabr(0);
 }
 
+/* Based on uptime_proc_show(). */
+static void
+show_uptime(void)
+{
+	struct timespec uptime;
+
+	if (setjmp(bus_error_jmp) == 0) {
+		catch_memory_errors = 1;
+		sync();
+
+		get_monotonic_boottime(&uptime);
+		printf("Uptime: %lu.%.2lu seconds\n", (unsigned long)uptime.tv_sec,
+			((unsigned long)uptime.tv_nsec / (NSEC_PER_SEC/100)));
+
+		sync();
+		__delay(200);						\
+	}
+	catch_memory_errors = 0;
+}
+
 static void set_lpp_cmd(void)
 {
 	unsigned long lpp;
@@ -1040,6 +1061,9 @@ cmds(struct pt_regs *excp)
 			dump_tlb_book3e();
 			break;
 #endif
+		case 'U':
+			show_uptime();
+			break;
 		default:
 			printf("Unrecognized command: ");
 			do {

commit 064996d62a33ffe10264b5af5dca92d54f60f806
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Fri Sep 29 13:29:40 2017 +1000

    powerpc/xmon: Avoid tripping SMP hardlockup watchdog
    
    The SMP hardlockup watchdog cross-checks other CPUs for lockups, which
    causes xmon headaches because it's assuming interrupts hard disabled
    means no watchdog troubles. Try to improve that by calling
    touch_nmi_watchdog() in obvious places where secondaries are spinning.
    
    Also annotate these spin loops with spin_begin/end calls.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 33351c6704b1..d9a12102b111 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -530,14 +530,19 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 
  waiting:
 	secondary = 1;
+	spin_begin();
 	while (secondary && !xmon_gate) {
 		if (in_xmon == 0) {
-			if (fromipi)
+			if (fromipi) {
+				spin_end();
 				goto leave;
+			}
 			secondary = test_and_set_bit(0, &in_xmon);
 		}
-		barrier();
+		spin_cpu_relax();
+		touch_nmi_watchdog();
 	}
+	spin_end();
 
 	if (!secondary && !xmon_gate) {
 		/* we are the first cpu to come in */
@@ -568,21 +573,25 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 		mb();
 		xmon_gate = 1;
 		barrier();
+		touch_nmi_watchdog();
 	}
 
  cmdloop:
 	while (in_xmon) {
 		if (secondary) {
+			spin_begin();
 			if (cpu == xmon_owner) {
 				if (!test_and_set_bit(0, &xmon_taken)) {
 					secondary = 0;
+					spin_end();
 					continue;
 				}
 				/* missed it */
 				while (cpu == xmon_owner)
-					barrier();
+					spin_cpu_relax();
 			}
-			barrier();
+			spin_cpu_relax();
+			touch_nmi_watchdog();
 		} else {
 			cmd = cmds(regs);
 			if (cmd != 0) {

commit d1e1b351f50f9e5941f436f6c63949731979e00c
Author: Balbir Singh <bsingharora@gmail.com>
Date:   Wed Aug 30 21:45:09 2017 +1000

    powerpc/xmon: Add ISA v3.0 SPRs to SPR dump
    
    Add support for printing the PIDR/TIDR for ISA 300 and PSSCR and PTCR
    in ISA 3.0 hypervisor mode.
    
    SPRN_PSSCR_PR is the privileged mode access and is used when we are
    not in hypervisor mode.
    
    Signed-off-by: Balbir Singh <bsingharora@gmail.com>
    [mpe: Split out of larger patch]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 9d2c5e0ef305..33351c6704b1 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1807,6 +1807,28 @@ static void dump_207_sprs(void)
 #endif
 }
 
+static void dump_300_sprs(void)
+{
+#ifdef CONFIG_PPC64
+	bool hv = mfmsr() & MSR_HV;
+
+	if (!cpu_has_feature(CPU_FTR_ARCH_300))
+		return;
+
+	printf("pidr   = %.16lx  tidr  = %.16lx\n",
+		mfspr(SPRN_PID), mfspr(SPRN_TIDR));
+	printf("asdr   = %.16lx  psscr = %.16lx\n",
+		mfspr(SPRN_ASDR), hv ? mfspr(SPRN_PSSCR)
+					: mfspr(SPRN_PSSCR_PR));
+
+	if (!hv)
+		return;
+
+	printf("ptcr   = %.16lx\n",
+		mfspr(SPRN_PTCR));
+#endif
+}
+
 static void dump_one_spr(int spr, bool show_unimplemented)
 {
 	unsigned long val;
@@ -1860,6 +1882,7 @@ static void super_regs(void)
 
 		dump_206_sprs();
 		dump_207_sprs();
+		dump_300_sprs();
 
 		return;
 	}

commit 64d66aa051544c31048ca58ab0ff81f294d37e9d
Author: Balbir Singh <bsingharora@gmail.com>
Date:   Wed Aug 30 21:43:34 2017 +1000

    powerpc/xmon: Add AMR, UAMOR, AMOR, IAMR to SPR dump
    
    This patch adds support to xmon for dumping the AMR, UAMOR, AMOR and
    IAMR SPRs based on their supported ISA revisions.
    
    Signed-off-by: Balbir Singh <bsingharora@gmail.com>
    [mpe: Split out of larger patch]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 1b26d5394f19..9d2c5e0ef305 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1743,18 +1743,20 @@ static void dump_206_sprs(void)
 		mfspr(SPRN_SRR0), mfspr(SPRN_SRR1), mfspr(SPRN_DSISR));
 	printf("dscr   = %.16lx  ppr   = %.16lx pir    = %.8x\n",
 		mfspr(SPRN_DSCR), mfspr(SPRN_PPR), mfspr(SPRN_PIR));
+	printf("amr    = %.16lx  uamor = %.16lx\n",
+		mfspr(SPRN_AMR), mfspr(SPRN_UAMOR));
 
 	if (!(mfmsr() & MSR_HV))
 		return;
 
 	printf("sdr1   = %.16lx  hdar  = %.16lx hdsisr = %.8x\n",
 		mfspr(SPRN_SDR1), mfspr(SPRN_HDAR), mfspr(SPRN_HDSISR));
-	printf("hsrr0  = %.16lx hsrr1  = %.16lx hdec = %.16lx\n",
+	printf("hsrr0  = %.16lx hsrr1  = %.16lx hdec   = %.16lx\n",
 		mfspr(SPRN_HSRR0), mfspr(SPRN_HSRR1), mfspr(SPRN_HDEC));
-	printf("lpcr   = %.16lx  pcr   = %.16lx lpidr = %.8x\n",
+	printf("lpcr   = %.16lx  pcr   = %.16lx lpidr  = %.8x\n",
 		mfspr(SPRN_LPCR), mfspr(SPRN_PCR), mfspr(SPRN_LPID));
-	printf("hsprg0 = %.16lx hsprg1 = %.16lx\n",
-		mfspr(SPRN_HSPRG0), mfspr(SPRN_HSPRG1));
+	printf("hsprg0 = %.16lx hsprg1 = %.16lx amor   = %.16lx\n",
+		mfspr(SPRN_HSPRG0), mfspr(SPRN_HSPRG1), mfspr(SPRN_AMOR));
 	printf("dabr   = %.16lx dabrx  = %.16lx\n",
 		mfspr(SPRN_DABR), mfspr(SPRN_DABRX));
 #endif
@@ -1793,6 +1795,7 @@ static void dump_207_sprs(void)
 		mfspr(SPRN_SDAR), mfspr(SPRN_SIER), mfspr(SPRN_PMC6));
 	printf("ebbhr  = %.16lx  ebbrr = %.16lx bescr  = %.16lx\n",
 		mfspr(SPRN_EBBHR), mfspr(SPRN_EBBRR), mfspr(SPRN_BESCR));
+	printf("iamr   = %.16lx\n", mfspr(SPRN_IAMR));
 
 	if (!(msr & MSR_HV))
 		return;

commit cf9159c36cca6b3d82a6eb620055b321af3c5b9b
Author: Balbir Singh <bsingharora@gmail.com>
Date:   Wed Aug 30 10:27:44 2017 +1000

    powerpc/xmon: Dump all 64 bits of HDEC
    
    ISA 3.0 defines hypervisor decrementer to be 64 bits in length.
    This patch extends the print format for to be 64 bits.
    
    Signed-off-by: Balbir Singh <bsingharora@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 9e68f1dca568..1b26d5394f19 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1749,7 +1749,7 @@ static void dump_206_sprs(void)
 
 	printf("sdr1   = %.16lx  hdar  = %.16lx hdsisr = %.8x\n",
 		mfspr(SPRN_SDR1), mfspr(SPRN_HDAR), mfspr(SPRN_HDSISR));
-	printf("hsrr0  = %.16lx hsrr1  = %.16lx hdec = %.8x\n",
+	printf("hsrr0  = %.16lx hsrr1  = %.16lx hdec = %.16lx\n",
 		mfspr(SPRN_HSRR0), mfspr(SPRN_HSRR1), mfspr(SPRN_HDEC));
 	printf("lpcr   = %.16lx  pcr   = %.16lx lpidr = %.8x\n",
 		mfspr(SPRN_LPCR), mfspr(SPRN_PCR), mfspr(SPRN_LPID));

commit c47a94031e81bd497704a535d60d0262a3155dbf
Author: Balbir Singh <bsingharora@gmail.com>
Date:   Tue Aug 29 17:22:36 2017 +1000

    powerpc/xmon: Fix display of SPRs
    
    Convert 0.16x to 0.16lx. Otherwise we lose the top 8 nibbles and
    effectively print only the last 32 bits.
    
    Fixes: 1846193b178d ("powerpc/xmon: Dump ISA 2.06 SPRs")
    Signed-off-by: Balbir Singh <bsingharora@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index d038e7db44c4..9e68f1dca568 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1739,23 +1739,23 @@ static void dump_206_sprs(void)
 
 	/* Actually some of these pre-date 2.06, but whatevs */
 
-	printf("srr0   = %.16x  srr1  = %.16x dsisr  = %.8x\n",
+	printf("srr0   = %.16lx  srr1  = %.16lx dsisr  = %.8x\n",
 		mfspr(SPRN_SRR0), mfspr(SPRN_SRR1), mfspr(SPRN_DSISR));
-	printf("dscr   = %.16x  ppr   = %.16x pir    = %.8x\n",
+	printf("dscr   = %.16lx  ppr   = %.16lx pir    = %.8x\n",
 		mfspr(SPRN_DSCR), mfspr(SPRN_PPR), mfspr(SPRN_PIR));
 
 	if (!(mfmsr() & MSR_HV))
 		return;
 
-	printf("sdr1   = %.16x  hdar  = %.16x hdsisr = %.8x\n",
+	printf("sdr1   = %.16lx  hdar  = %.16lx hdsisr = %.8x\n",
 		mfspr(SPRN_SDR1), mfspr(SPRN_HDAR), mfspr(SPRN_HDSISR));
-	printf("hsrr0  = %.16x hsrr1  = %.16x hdec = %.8x\n",
+	printf("hsrr0  = %.16lx hsrr1  = %.16lx hdec = %.8x\n",
 		mfspr(SPRN_HSRR0), mfspr(SPRN_HSRR1), mfspr(SPRN_HDEC));
-	printf("lpcr   = %.16x  pcr   = %.16x lpidr = %.8x\n",
+	printf("lpcr   = %.16lx  pcr   = %.16lx lpidr = %.8x\n",
 		mfspr(SPRN_LPCR), mfspr(SPRN_PCR), mfspr(SPRN_LPID));
-	printf("hsprg0 = %.16x hsprg1 = %.16x\n",
+	printf("hsprg0 = %.16lx hsprg1 = %.16lx\n",
 		mfspr(SPRN_HSPRG0), mfspr(SPRN_HSPRG1));
-	printf("dabr   = %.16x dabrx  = %.16x\n",
+	printf("dabr   = %.16lx dabrx  = %.16lx\n",
 		mfspr(SPRN_DABR), mfspr(SPRN_DABRX));
 #endif
 }
@@ -1768,38 +1768,38 @@ static void dump_207_sprs(void)
 	if (!cpu_has_feature(CPU_FTR_ARCH_207S))
 		return;
 
-	printf("dpdes  = %.16x  tir   = %.16x cir    = %.8x\n",
+	printf("dpdes  = %.16lx  tir   = %.16lx cir    = %.8x\n",
 		mfspr(SPRN_DPDES), mfspr(SPRN_TIR), mfspr(SPRN_CIR));
 
-	printf("fscr   = %.16x  tar   = %.16x pspb   = %.8x\n",
+	printf("fscr   = %.16lx  tar   = %.16lx pspb   = %.8x\n",
 		mfspr(SPRN_FSCR), mfspr(SPRN_TAR), mfspr(SPRN_PSPB));
 
 	msr = mfmsr();
 	if (msr & MSR_TM) {
 		/* Only if TM has been enabled in the kernel */
-		printf("tfhar  = %.16x  tfiar = %.16x texasr = %.16x\n",
+		printf("tfhar  = %.16lx  tfiar = %.16lx texasr = %.16lx\n",
 			mfspr(SPRN_TFHAR), mfspr(SPRN_TFIAR),
 			mfspr(SPRN_TEXASR));
 	}
 
-	printf("mmcr0  = %.16x  mmcr1 = %.16x mmcr2  = %.16x\n",
+	printf("mmcr0  = %.16lx  mmcr1 = %.16lx mmcr2  = %.16lx\n",
 		mfspr(SPRN_MMCR0), mfspr(SPRN_MMCR1), mfspr(SPRN_MMCR2));
 	printf("pmc1   = %.8x pmc2 = %.8x  pmc3 = %.8x  pmc4   = %.8x\n",
 		mfspr(SPRN_PMC1), mfspr(SPRN_PMC2),
 		mfspr(SPRN_PMC3), mfspr(SPRN_PMC4));
-	printf("mmcra  = %.16x   siar = %.16x pmc5   = %.8x\n",
+	printf("mmcra  = %.16lx   siar = %.16lx pmc5   = %.8x\n",
 		mfspr(SPRN_MMCRA), mfspr(SPRN_SIAR), mfspr(SPRN_PMC5));
-	printf("sdar   = %.16x   sier = %.16x pmc6   = %.8x\n",
+	printf("sdar   = %.16lx   sier = %.16lx pmc6   = %.8x\n",
 		mfspr(SPRN_SDAR), mfspr(SPRN_SIER), mfspr(SPRN_PMC6));
-	printf("ebbhr  = %.16x  ebbrr = %.16x bescr  = %.16x\n",
+	printf("ebbhr  = %.16lx  ebbrr = %.16lx bescr  = %.16lx\n",
 		mfspr(SPRN_EBBHR), mfspr(SPRN_EBBRR), mfspr(SPRN_BESCR));
 
 	if (!(msr & MSR_HV))
 		return;
 
-	printf("hfscr  = %.16x  dhdes = %.16x rpr    = %.16x\n",
+	printf("hfscr  = %.16lx  dhdes = %.16lx rpr    = %.16lx\n",
 		mfspr(SPRN_HFSCR), mfspr(SPRN_DHDES), mfspr(SPRN_RPR));
-	printf("dawr   = %.16x  dawrx = %.16x ciabr  = %.16x\n",
+	printf("dawr   = %.16lx  dawrx = %.16lx ciabr  = %.16lx\n",
 		mfspr(SPRN_DAWR), mfspr(SPRN_DAWRX), mfspr(SPRN_CIABR));
 #endif
 }

commit ed49f7fd6438dcc8c93fa7d1d7d815e47c7115dd
Author: Breno Leitao <leitao@debian.org>
Date:   Wed Aug 2 17:14:06 2017 -0300

    powerpc/xmon: Disable tracing when entering xmon
    
    If tracing is enabled and you get into xmon, the tracing buffer
    continues to be updated, causing possible loss of data and unnecessary
    tracing information coming from xmon functions.
    
    This patch simple disables tracing when entering xmon, and re-enables it
    if the kernel is resumed (with 'x').
    
    Signed-off-by: Breno Leitao <leitao@debian.org>
    Acked-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index e0522f60f0ee..d038e7db44c4 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -89,6 +89,7 @@ static unsigned long nidump = 16;
 static unsigned long ncsum = 4096;
 static int termch;
 static char tmpstr[128];
+static int tracing_enabled;
 
 static long bus_error_jmp[JMP_BUF_LEN];
 static int catch_memory_errors;
@@ -462,6 +463,9 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 	local_irq_save(flags);
 	hard_irq_disable();
 
+	tracing_enabled = tracing_is_on();
+	tracing_off();
+
 	bp = in_breakpoint_table(regs->nip, &offset);
 	if (bp != NULL) {
 		regs->nip = bp->address + offset;
@@ -982,6 +986,8 @@ cmds(struct pt_regs *excp)
 			break;
 		case 'x':
 		case 'X':
+			if (tracing_enabled)
+				tracing_on();
 			return cmd;
 		case EOF:
 			printf(" <no input ...>\n");
@@ -2241,8 +2247,6 @@ static void dump_tracing(void)
 		ftrace_dump(DUMP_ORIG);
 	else
 		ftrace_dump(DUMP_ALL);
-
-	tracing_on();
 }
 
 #ifdef CONFIG_PPC64

commit 4125d012ff9dafe6624197d8dbd237d0916b3c35
Author: Breno Leitao <leitao@debian.org>
Date:   Wed Aug 2 17:14:05 2017 -0300

    powerpc/xmon: Dump ftrace buffers for the current CPU only
    
    Current xmon 'dt' command dumps the tracing buffer for all the CPUs,
    which makes it very hard to read due to the fact that most of
    powerpc machines currently have many CPUs. Other than that, the CPU
    lines are interleaved in the ftrace log.
    
    This new option just dumps the ftrace buffer for the current CPU.
    
    Signed-off-by: Breno Leitao <leitao@debian.org>
    Acked-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 08e367e3e8c3..e0522f60f0ee 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -234,6 +234,7 @@ Commands:\n\
   "\
   dr	dump stream of raw bytes\n\
   dt	dump the tracing buffers (uses printk)\n\
+  dtc	dump the tracing buffers for current CPU (uses printk)\n\
 "
 #ifdef CONFIG_PPC_POWERNV
 "  dx#   dump xive on CPU #\n\
@@ -2231,6 +2232,19 @@ static void xmon_rawdump (unsigned long adrs, long ndump)
 	printf("\n");
 }
 
+static void dump_tracing(void)
+{
+	int c;
+
+	c = inchar();
+	if (c == 'c')
+		ftrace_dump(DUMP_ORIG);
+	else
+		ftrace_dump(DUMP_ALL);
+
+	tracing_on();
+}
+
 #ifdef CONFIG_PPC64
 static void dump_one_paca(int cpu)
 {
@@ -2507,6 +2521,11 @@ dump(void)
 	}
 #endif
 
+	if (c == 't') {
+		dump_tracing();
+		return;
+	}
+
 	if (c == '\n')
 		termch = c;
 
@@ -2525,9 +2544,6 @@ dump(void)
 		dump_log_buf();
 	} else if (c == 'o') {
 		dump_opal_msglog();
-	} else if (c == 't') {
-		ftrace_dump(DUMP_ALL);
-		tracing_on();
 	} else if (c == 'r') {
 		scanhex(&ndump);
 		if (ndump == 0)

commit efe4fbb1ac3a6489c1dc7d31b51ecb7425807b1b
Author: Balbir Singh <bsingharora@gmail.com>
Date:   Tue Jun 27 17:48:58 2017 +1000

    powerpc/xmon: Add patch_instruction() support for xmon
    
    Move from mwrite() to patch_instruction() for xmon for
    breakpoint addition and removal.
    
    Signed-off-by: Balbir Singh <bsingharora@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index a728e1919613..08e367e3e8c3 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -53,6 +53,7 @@
 #include <asm/xive.h>
 #include <asm/opal.h>
 #include <asm/firmware.h>
+#include <asm/code-patching.h>
 
 #ifdef CONFIG_PPC64
 #include <asm/hvcall.h>
@@ -837,7 +838,8 @@ static void insert_bpts(void)
 		store_inst(&bp->instr[0]);
 		if (bp->enabled & BP_CIABR)
 			continue;
-		if (mwrite(bp->address, &bpinstr, 4) != 4) {
+		if (patch_instruction((unsigned int *)bp->address,
+							bpinstr) != 0) {
 			printf("Couldn't write instruction at %lx, "
 			       "disabling breakpoint there\n", bp->address);
 			bp->enabled &= ~BP_TRAP;
@@ -874,7 +876,8 @@ static void remove_bpts(void)
 			continue;
 		if (mread(bp->address, &instr, 4) == 4
 		    && instr == bpinstr
-		    && mwrite(bp->address, &bp->instr, 4) != 4)
+		    && patch_instruction(
+			(unsigned int *)bp->address, bp->instr[0]) != 0)
 			printf("Couldn't remove breakpoint at %lx\n",
 			       bp->address);
 		else

commit 09b6c1129f899c72d70b8bea36020644aa3b5a28
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Fri May 12 10:47:07 2017 +1000

    powerpc/xmon: Fix compile error with PPC_8xx=y
    
    Rearrange the code so that mode and badaddr are only defined when
    they're used.
    
    Also unsplit the string for easier grepping, and switch from CONFIG_8xx
    which is deprecated to CONFIG_PPC_8xx.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index f11f65634aab..a728e1919613 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1242,14 +1242,14 @@ bpt_cmds(void)
 {
 	int cmd;
 	unsigned long a;
-	int mode, i;
+	int i;
 	struct bpt *bp;
-	const char badaddr[] = "Only kernel addresses are permitted "
-		"for breakpoints\n";
 
 	cmd = inchar();
 	switch (cmd) {
-#ifndef CONFIG_8xx
+#ifndef CONFIG_PPC_8xx
+	static const char badaddr[] = "Only kernel addresses are permitted for breakpoints\n";
+	int mode;
 	case 'd':	/* bd - hardware data breakpoint */
 		mode = 7;
 		cmd = inchar();

commit 8915bcd68b2547c819b8a2a33c098121af9accb2
Author: Michael Neuling <mikey@neuling.org>
Date:   Thu Mar 16 14:04:40 2017 +1100

    powerpc/xmon: Teach xmon oops about radix vectors
    
    Currently if we take an oops caused by an 0x380 or 0x480 exception, we get a
    print which assumes SLB problems. With radix, these vectors have different
    meanings.
    
    This patch updates the oops message to reflect these different meanings.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index da5619847517..f11f65634aab 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1369,9 +1369,19 @@ const char *getvecname(unsigned long vec)
 	case 0x100:	ret = "(System Reset)"; break;
 	case 0x200:	ret = "(Machine Check)"; break;
 	case 0x300:	ret = "(Data Access)"; break;
-	case 0x380:	ret = "(Data SLB Access)"; break;
+	case 0x380:
+		if (radix_enabled())
+			ret = "(Data Access Out of Range)";
+		else
+			ret = "(Data SLB Access)";
+		break;
 	case 0x400:	ret = "(Instruction Access)"; break;
-	case 0x480:	ret = "(Instruction SLB Access)"; break;
+	case 0x480:
+		if (radix_enabled())
+			ret = "(Instruction Access Out of Range)";
+		else
+			ret = "(Instruction SLB Access)";
+		break;
 	case 0x500:	ret = "(Hardware Interrupt)"; break;
 	case 0x600:	ret = "(Alignment)"; break;
 	case 0x700:	ret = "(Program Check)"; break;

commit 1cd6ed7c2e35a716dcf1347c33f58a7ce7d1414f
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Dec 20 04:30:11 2016 +1000

    powerpc/xmon: Wait for secondaries before IPI'ing on system reset
    
    An externally triggered system reset (e.g., via QEMU nmi command, or pseries
    reset button) can cause system reset interrupts on all CPUs. In case this causes
    xmon to be entered, it is undesirable for the primary (first) CPU into xmon to
    trigger an NMI IPI to others, because this may cause a nested system reset
    interrupt.
    
    So spin for a time waiting for secondaries to join xmon before performing the
    NMI IPI, similarly to what the crash dump code does.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Only do it when we come in from system reset, not via sysrq etc.]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 682506821bba..da5619847517 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -418,7 +418,22 @@ int cpus_are_in_xmon(void)
 {
 	return !cpumask_empty(&cpus_in_xmon);
 }
-#endif
+
+static bool wait_for_other_cpus(int ncpus)
+{
+	unsigned long timeout;
+
+	/* We wait for 2s, which is a metric "little while" */
+	for (timeout = 20000; timeout != 0; --timeout) {
+		if (cpumask_weight(&cpus_in_xmon) >= ncpus)
+			return true;
+		udelay(100);
+		barrier();
+	}
+
+	return false;
+}
+#endif /* CONFIG_SMP */
 
 static inline int unrecoverable_excp(struct pt_regs *regs)
 {
@@ -440,7 +455,6 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 #ifdef CONFIG_SMP
 	int cpu;
 	int secondary;
-	unsigned long timeout;
 #endif
 
 	local_irq_save(flags);
@@ -527,13 +541,17 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 		xmon_owner = cpu;
 		mb();
 		if (ncpus > 1) {
-			smp_send_debugger_break();
-			/* wait for other cpus to come in */
-			for (timeout = 100000000; timeout != 0; --timeout) {
-				if (cpumask_weight(&cpus_in_xmon) >= ncpus)
-					break;
-				barrier();
-			}
+			/*
+			 * A system reset (trap == 0x100) can be triggered on
+			 * all CPUs, so when we come in via 0x100 try waiting
+			 * for the other CPUs to come in before we send the
+			 * debugger break (IPI). This is similar to
+			 * crash_kexec_secondary().
+			 */
+			if (TRAP(regs) != 0x100 || !wait_for_other_cpus(ncpus))
+				smp_send_debugger_break();
+
+			wait_for_other_cpus(ncpus);
 		}
 		remove_bpts();
 		disable_surveillance();

commit b1ee8a3de5790777f325416ad97340428d8ae25f
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Dec 20 04:30:06 2016 +1000

    powerpc/64s: Dedicated system reset interrupt stack
    
    The system reset interrupt is used for crash/debug situations, so it is
    desirable to have as little impact on the normal state of the system as
    possible.
    
    Currently it uses the current kernel stack to process the exception.
    This stores into the stack which may be involved with the crash. The
    stack pointer may be corrupted, or it may have overflowed.
    
    Avoid or minimise these problems by creating a dedicated NMI stack for
    the system reset interrupt to use.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 99348a2961b8..682506821bba 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2235,6 +2235,7 @@ static void dump_one_paca(int cpu)
 	DUMP(p, kernel_msr, "lx");
 	DUMP(p, emergency_sp, "p");
 #ifdef CONFIG_PPC_BOOK3S_64
+	DUMP(p, nmi_emergency_sp, "p");
 	DUMP(p, mc_emergency_sp, "p");
 	DUMP(p, in_nmi, "x");
 	DUMP(p, in_mce, "x");

commit c4f3b52ce7b16824befb16ab3d045c891b08b7db
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Dec 20 04:30:05 2016 +1000

    powerpc/64s: Disallow system reset vs system reset reentrancy
    
    In preparation for using a dedicated stack for system reset interrupts,
    prevent a nested system reset from recovering, in order to simplify
    code that is called in crash/debug path. This allows a system reset
    interrupt to just use the base stack pointer.
    
    Keep an in_nmi nesting counter similarly to the in_mce counter. Consider
    the interrrupt non-recoverable if it is taken inside another system
    reset.
    
    Interrupt nesting could be allowed similarly to MCE, but system reset
    is a special case that's not for normal operation, so simplicity wins
    until there is requirement for nested system reset interrupts.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 2b21e90fff8d..99348a2961b8 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2236,6 +2236,7 @@ static void dump_one_paca(int cpu)
 	DUMP(p, emergency_sp, "p");
 #ifdef CONFIG_PPC_BOOK3S_64
 	DUMP(p, mc_emergency_sp, "p");
+	DUMP(p, in_nmi, "x");
 	DUMP(p, in_mce, "x");
 	DUMP(p, hmi_event_available, "x");
 #endif

commit 856736466806ceb72c7402eb0f06bea8f5b83c5a
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Mon Apr 24 10:35:14 2017 +1000

    powerpc/xmon: Deindent the SLB dumping logic
    
    Currently the code that dumps SLB entries uses a double-nested if. This
    means the actual dumping logic is a bit squashed. Deindent it by using
    continue.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Rashmica Gupta <rashmica.g@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index f77a104abf9f..2b21e90fff8d 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -3157,23 +3157,28 @@ void dump_segments(void)
 	for (i = 0; i < mmu_slb_size; i++) {
 		asm volatile("slbmfee  %0,%1" : "=r" (esid) : "r" (i));
 		asm volatile("slbmfev  %0,%1" : "=r" (vsid) : "r" (i));
-		if (esid || vsid) {
-			printf("%02d %016lx %016lx", i, esid, vsid);
-			if (esid & SLB_ESID_V) {
-				llp = vsid & SLB_VSID_LLP;
-				if (vsid & SLB_VSID_B_1T) {
-					printf("  1T  ESID=%9lx  VSID=%13lx LLP:%3lx \n",
-						GET_ESID_1T(esid),
-						(vsid & ~SLB_VSID_B) >> SLB_VSID_SHIFT_1T,
-						llp);
-				} else {
-					printf(" 256M ESID=%9lx  VSID=%13lx LLP:%3lx \n",
-						GET_ESID(esid),
-						(vsid & ~SLB_VSID_B) >> SLB_VSID_SHIFT,
-						llp);
-				}
-			} else
-				printf("\n");
+
+		if (!esid && !vsid)
+			continue;
+
+		printf("%02d %016lx %016lx", i, esid, vsid);
+
+		if (!(esid & SLB_ESID_V)) {
+			printf("\n");
+			continue;
+		}
+
+		llp = vsid & SLB_VSID_LLP;
+		if (vsid & SLB_VSID_B_1T) {
+			printf("  1T  ESID=%9lx  VSID=%13lx LLP:%3lx \n",
+				GET_ESID_1T(esid),
+				(vsid & ~SLB_VSID_B) >> SLB_VSID_SHIFT_1T,
+				llp);
+		} else {
+			printf(" 256M ESID=%9lx  VSID=%13lx LLP:%3lx \n",
+				GET_ESID(esid),
+				(vsid & ~SLB_VSID_B) >> SLB_VSID_SHIFT,
+				llp);
 		}
 	}
 }

commit 3c19d5ada1bec8b97119215298df7669d3ffb3db
Merge: 17ed4c8f81da 08a1e650cc63
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Apr 12 22:25:02 2017 +1000

    Merge branch 'topic/xive' (early part) into next
    
    This merges the arch part of the XIVE support, leaving the final commit
    with the KVM specific pieces dangling on the branch for Paul to merge
    via the kvm-ppc tree.

commit 7644d5819cf8956d799a0a0e5dc75f5a29889bd5
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Fri Feb 10 12:04:56 2017 +1100

    powerpc: Create asm/debugfs.h and move powerpc_debugfs_root there
    
    powerpc_debugfs_root is the dentry representing the root of the
    "powerpc" directory tree in debugfs.
    
    Currently it sits in asm/debug.h, a long with some other things that
    have "debug" in the name, but are otherwise unrelated.
    
    Pull it out into a separate header, which also includes linux/debugfs.h,
    and convert all the users to include debugfs.h instead of debug.h.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 0fab9d7349eb..fddc857af772 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -29,10 +29,7 @@
 #include <linux/nmi.h>
 #include <linux/ctype.h>
 
-#ifdef CONFIG_DEBUG_FS
-#include <linux/debugfs.h>
-#endif
-
+#include <asm/debugfs.h>
 #include <asm/ptrace.h>
 #include <asm/string.h>
 #include <asm/prom.h>

commit 243e25112d06b348f087a6f7aba4bbc288285bdd
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Apr 5 17:54:50 2017 +1000

    powerpc/xive: Native exploitation of the XIVE interrupt controller
    
    The XIVE interrupt controller is the new interrupt controller
    found in POWER9. It supports advanced virtualization capabilities
    among other things.
    
    Currently we use a set of firmware calls that simulate the old
    "XICS" interrupt controller but this is fairly inefficient.
    
    This adds the framework for using XIVE along with a native
    backend which OPAL for configuration. Later, a backend allowing
    the use in a KVM or PowerVM guest will also be provided.
    
    This disables some fast path for interrupts in KVM when XIVE is
    enabled as these rely on the firmware emulation code which is no
    longer available when the XIVE is used natively by Linux.
    
    A latter patch will make KVM also directly exploit the XIVE, thus
    recovering the lost performance (and more).
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    [mpe: Fixup pr_xxx("XIVE:"...), don't split pr_xxx() strings,
     tweak Kconfig so XIVE_NATIVE selects XIVE and depends on POWERNV,
     fix build errors when SMP=n, fold in fixes from Ben:
       Don't call cpu_online() on an invalid CPU number
       Fix irq target selection returning out of bounds cpu#
       Extra sanity checks on cpu numbers
     ]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 16321ad9e70c..67435b9bf98d 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -30,6 +30,7 @@
 #include <linux/ctype.h>
 
 #include <asm/ptrace.h>
+#include <asm/smp.h>
 #include <asm/string.h>
 #include <asm/prom.h>
 #include <asm/machdep.h>
@@ -48,7 +49,7 @@
 #include <asm/reg.h>
 #include <asm/debug.h>
 #include <asm/hw_breakpoint.h>
-
+#include <asm/xive.h>
 #include <asm/opal.h>
 #include <asm/firmware.h>
 
@@ -232,7 +233,13 @@ Commands:\n\
   "\
   dr	dump stream of raw bytes\n\
   dt	dump the tracing buffers (uses printk)\n\
-  e	print exception information\n\
+"
+#ifdef CONFIG_PPC_POWERNV
+"  dx#   dump xive on CPU #\n\
+  dxi#  dump xive irq state #\n\
+  dxa   dump xive on all CPUs\n"
+#endif
+"  e	print exception information\n\
   f	flush cache\n\
   la	lookup symbol+offset of specified address\n\
   ls	lookup address of specified symbol\n\
@@ -2338,6 +2345,81 @@ static void dump_pacas(void)
 }
 #endif
 
+#ifdef CONFIG_PPC_POWERNV
+static void dump_one_xive(int cpu)
+{
+	unsigned int hwid = get_hard_smp_processor_id(cpu);
+
+	opal_xive_dump(XIVE_DUMP_TM_HYP, hwid);
+	opal_xive_dump(XIVE_DUMP_TM_POOL, hwid);
+	opal_xive_dump(XIVE_DUMP_TM_OS, hwid);
+	opal_xive_dump(XIVE_DUMP_TM_USER, hwid);
+	opal_xive_dump(XIVE_DUMP_VP, hwid);
+	opal_xive_dump(XIVE_DUMP_EMU_STATE, hwid);
+
+	if (setjmp(bus_error_jmp) != 0) {
+		catch_memory_errors = 0;
+		printf("*** Error dumping xive on cpu %d\n", cpu);
+		return;
+	}
+
+	catch_memory_errors = 1;
+	sync();
+	xmon_xive_do_dump(cpu);
+	sync();
+	__delay(200);
+	catch_memory_errors = 0;
+}
+
+static void dump_all_xives(void)
+{
+	int cpu;
+
+	if (num_possible_cpus() == 0) {
+		printf("No possible cpus, use 'dx #' to dump individual cpus\n");
+		return;
+	}
+
+	for_each_possible_cpu(cpu)
+		dump_one_xive(cpu);
+}
+
+static void dump_one_xive_irq(u32 num)
+{
+	s64 rc;
+	__be64 vp;
+	u8 prio;
+	__be32 lirq;
+
+	rc = opal_xive_get_irq_config(num, &vp, &prio, &lirq);
+	xmon_printf("IRQ 0x%x config: vp=0x%llx prio=%d lirq=0x%x (rc=%lld)\n",
+		    num, be64_to_cpu(vp), prio, be32_to_cpu(lirq), rc);
+}
+
+static void dump_xives(void)
+{
+	unsigned long num;
+	int c;
+
+	c = inchar();
+	if (c == 'a') {
+		dump_all_xives();
+		return;
+	} else if (c == 'i') {
+		if (scanhex(&num))
+			dump_one_xive_irq(num);
+		return;
+	}
+
+	termch = c;	/* Put c back, it wasn't 'a' */
+
+	if (scanhex(&num))
+		dump_one_xive(num);
+	else
+		dump_one_xive(xmon_owner);
+}
+#endif /* CONFIG_PPC_POWERNV */
+
 static void dump_by_size(unsigned long addr, long count, int size)
 {
 	unsigned char temp[16];
@@ -2386,6 +2468,14 @@ dump(void)
 		return;
 	}
 #endif
+#ifdef CONFIG_PPC_POWERNV
+	if (c == 'x') {
+		xmon_start_pagination();
+		dump_xives();
+		xmon_end_pagination();
+		return;
+	}
+#endif
 
 	if (c == '\n')
 		termch = c;

commit de78ae6c9ef55d9ded036c8e29d9364e1ce5f6b7
Author: Guilherme G. Piccoli <gpiccoli@linux.vnet.ibm.com>
Date:   Wed Mar 22 16:27:51 2017 -0300

    powerpc/xmon: add debugfs entry for xmon
    
    Currently the xmon debugger is set only via kernel boot command-line.
    It's disabled by default, and can be enabled with "xmon=on" on the
    command-line. Also, xmon may be accessed via sysrq mechanism.
    But we cannot enable/disable xmon in runtime, it needs kernel reload.
    
    This patch introduces a debugfs entry for xmon, allowing user to query
    its current state and change it if desired. Basically, the "xmon" file
    to read from/write to is under the debugfs mount point, on powerpc
    directory. It's a simple attribute, value 0 meaning xmon is disabled
    and value 1 the opposite. Writing these states to the file will take
    immediate effect in the debugger.
    
    Signed-off-by: Guilherme G. Piccoli <gpiccoli@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 25a32815f310..0fab9d7349eb 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -29,6 +29,10 @@
 #include <linux/nmi.h>
 #include <linux/ctype.h>
 
+#ifdef CONFIG_DEBUG_FS
+#include <linux/debugfs.h>
+#endif
+
 #include <asm/ptrace.h>
 #include <asm/string.h>
 #include <asm/prom.h>
@@ -3316,6 +3320,33 @@ static int __init setup_xmon_sysrq(void)
 device_initcall(setup_xmon_sysrq);
 #endif /* CONFIG_MAGIC_SYSRQ */
 
+#ifdef CONFIG_DEBUG_FS
+static int xmon_dbgfs_set(void *data, u64 val)
+{
+	xmon_on = !!val;
+	xmon_init(xmon_on);
+
+	return 0;
+}
+
+static int xmon_dbgfs_get(void *data, u64 *val)
+{
+	*val = xmon_on;
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(xmon_dbgfs_ops, xmon_dbgfs_get,
+			xmon_dbgfs_set, "%llu\n");
+
+static int __init setup_xmon_dbgfs(void)
+{
+	debugfs_create_file("xmon", 0600, powerpc_debugfs_root, NULL,
+				&xmon_dbgfs_ops);
+	return 0;
+}
+device_initcall(setup_xmon_dbgfs);
+#endif /* CONFIG_DEBUG_FS */
+
 static int xmon_early __initdata;
 
 static int __init early_parse_xmon(char *p)

commit b561783c7bfd4bcb18ad30e1410ee19500c36a7c
Author: Guilherme G. Piccoli <gpiccoli@linux.vnet.ibm.com>
Date:   Wed Mar 22 16:27:50 2017 -0300

    powerpc/xmon: drop the nobt option from xmon plus minor fixes
    
    The xmon parameter nobt was added long time ago, by commit 26c8af5f01df
    ("[POWERPC] print backtrace when entering xmon"). The problem that time
    was that during a crash in a machine with USB keyboard, xmon wouldn't
    respond to commands from the keyboard, so printing the backtrace wouldn't
    be possible.
    
    Idea then was to show automatically the backtrace on xmon crash for the
    first time it's invoked (if it recovers, next time xmon won't show
    backtrace automatically). The nobt parameter was added _only_ to prevent
    this automatic trace show. Seems long time ago USB keyboards didn't work
    that well!
    
    We don't need this parameter anymore, the feature of auto showing the
    backtrace is interesting (imagine a case of auto-reboot script),
    so this patch extends the functionality, by always showing the backtrace
    automatically when xmon is invoked; it removes the nobt parameter too.
    
    Also, this patch fixes __initdata placement on xmon_early and replaces
    __initcall() with modern device_initcall() on sysrq handler.
    
    Signed-off-by: Guilherme G. Piccoli <gpiccoli@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index a89db1b3f66d..25a32815f310 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -185,8 +185,6 @@ static void dump_tlb_44x(void);
 static void dump_tlb_book3e(void);
 #endif
 
-static int xmon_no_auto_backtrace;
-
 #ifdef CONFIG_PPC64
 #define REG		"%.16lx"
 #else
@@ -885,10 +883,7 @@ cmds(struct pt_regs *excp)
 	last_cmd = NULL;
 	xmon_regs = excp;
 
-	if (!xmon_no_auto_backtrace) {
-		xmon_no_auto_backtrace = 1;
-		xmon_show_stack(excp->gpr[1], excp->link, excp->nip);
-	}
+	xmon_show_stack(excp->gpr[1], excp->link, excp->nip);
 
 	for(;;) {
 #ifdef CONFIG_SMP
@@ -3318,10 +3313,10 @@ static int __init setup_xmon_sysrq(void)
 	register_sysrq_key('x', &sysrq_xmon_op);
 	return 0;
 }
-__initcall(setup_xmon_sysrq);
+device_initcall(setup_xmon_sysrq);
 #endif /* CONFIG_MAGIC_SYSRQ */
 
-static int __initdata xmon_early;
+static int xmon_early __initdata;
 
 static int __init early_parse_xmon(char *p)
 {
@@ -3335,8 +3330,6 @@ static int __init early_parse_xmon(char *p)
 		xmon_on = 1;
 	} else if (strncmp(p, "off", 3) == 0)
 		xmon_on = 0;
-	else if (strncmp(p, "nobt", 4) == 0)
-		xmon_no_auto_backtrace = 1;
 	else
 		return 1;
 

commit 3b5bf42b81d56085fd58692b5117f69aa77fdff7
Author: Pan Xinhui <xinhui.pan@linux.vnet.ibm.com>
Date:   Wed Mar 22 16:27:49 2017 -0300

    powerpc/xmon: Fix an unexpected xmon on/off state change
    
    Once xmon is triggered by sysrq-x, it is enabled always afterwards even
    if it is disabled during boot. This will cause a system reset interrupt
    fail to dump. So keep xmon in its original state after exit.
    
    We have several ways to set xmon on or off.
    1) by a build config CONFIG_XMON_DEFAULT.
    2) by a boot cmdline with xmon or xmon=early or xmon=on to enable xmon
    and xmon=off to disable xmon. This value will override that in step 1.
    3) by a debugfs interface, as proposed in this patchset.
    And this value can override those in step 1 and 2.
    
    Signed-off-by: Pan Xinhui <xinhui.pan@linux.vnet.ibm.com>
    Signed-off-by: Guilherme G. Piccoli <gpiccoli@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 16321ad9e70c..a89db1b3f66d 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -76,6 +76,7 @@ static int xmon_gate;
 #endif /* CONFIG_SMP */
 
 static unsigned long in_xmon __read_mostly = 0;
+static int xmon_on = IS_ENABLED(CONFIG_XMON_DEFAULT);
 
 static unsigned long adrs;
 static int size = 1;
@@ -3302,6 +3303,8 @@ static void sysrq_handle_xmon(int key)
 	/* ensure xmon is enabled */
 	xmon_init(1);
 	debugger(get_irq_regs());
+	if (!xmon_on)
+		xmon_init(0);
 }
 
 static struct sysrq_key_op sysrq_xmon_op = {
@@ -3318,7 +3321,7 @@ static int __init setup_xmon_sysrq(void)
 __initcall(setup_xmon_sysrq);
 #endif /* CONFIG_MAGIC_SYSRQ */
 
-static int __initdata xmon_early, xmon_off;
+static int __initdata xmon_early;
 
 static int __init early_parse_xmon(char *p)
 {
@@ -3326,10 +3329,12 @@ static int __init early_parse_xmon(char *p)
 		/* just "xmon" is equivalent to "xmon=early" */
 		xmon_init(1);
 		xmon_early = 1;
-	} else if (strncmp(p, "on", 2) == 0)
+		xmon_on = 1;
+	} else if (strncmp(p, "on", 2) == 0) {
 		xmon_init(1);
-	else if (strncmp(p, "off", 3) == 0)
-		xmon_off = 1;
+		xmon_on = 1;
+	} else if (strncmp(p, "off", 3) == 0)
+		xmon_on = 0;
 	else if (strncmp(p, "nobt", 4) == 0)
 		xmon_no_auto_backtrace = 1;
 	else
@@ -3341,10 +3346,8 @@ early_param("xmon", early_parse_xmon);
 
 void __init xmon_setup(void)
 {
-#ifdef CONFIG_XMON_DEFAULT
-	if (!xmon_off)
+	if (xmon_on)
 		xmon_init(1);
-#endif
 	if (xmon_early)
 		debugger(NULL);
 }

commit 3f07c0144132e4f59d88055ac8ff3e691a5fa2b8
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 8 18:51:30 2017 +0100

    sched/headers: Prepare for new header dependencies before moving code to <linux/sched/signal.h>
    
    We are going to split <linux/sched/signal.h> out of <linux/sched.h>, which
    will have to be picked up from other headers and a couple of .c files.
    
    Create a trivial placeholder <linux/sched/signal.h> file that just
    maps to <linux/sched.h> to make this patch obviously correct and
    bisectable.
    
    Include the new header in the files that are going to need it.
    
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 26fa03fc9f3c..16321ad9e70c 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -13,7 +13,7 @@
 
 #include <linux/kernel.h>
 #include <linux/errno.h>
-#include <linux/sched.h>
+#include <linux/sched/signal.h>
 #include <linux/smp.h>
 #include <linux/mm.h>
 #include <linux/reboot.h>

commit b286cedd473006b33d5ae076afac509e6b2c3bf4
Merge: 522214d9be9c 9f3768e02335
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 1 10:10:16 2017 -0800

    Merge tag 'powerpc-4.11-2' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull more powerpc updates from Michael Ellerman:
     "Highlights include:
    
       - an update of the disassembly code used by xmon to the latest
         versions in binutils. We've received permission from all the
         authors of the relevant binutils changes to relicense their changes
         to the relevant files from GPLv3 to GPLv2, for inclusion in Linux.
         Thanks to Peter Bergner for doing the leg work to get permission
         from everyone.
    
       - addition of the "architected" Power9 CPU table entry, allowing us
         to boot in Power9 architected mode under a hypervisor.
    
       - updates to the Power9 PMU code.
    
       - implementation of clear_bit_unlock_is_negative_byte() to optimise
         unlock_page().
    
       - Freescale updates from Scott: "Highlights include 8xx breakpoints
         and perf, t1042rdb display support, and board updates."
    
      Thanks to:
        Al Viro, Andrew Donnellan, Aneesh Kumar K.V, Balbir Singh, Douglas
        Miller, FrÃ©dÃ©ric Weisbecker, Gavin Shan, Madhavan Srinivasan,
        Michael Roth, Nathan Fontenot, Naveen N. Rao, Nicholas Piggin, Peter
        Bergner, Paul E. McKenney, Rashmica Gupta, Russell Currey, Sahil
        Mehta, Stewart Smith"
    
    * tag 'powerpc-4.11-2' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (48 commits)
      powerpc: Remove leftover cputime_to_nsecs call causing build error
      powerpc/mm/hash: Always clear UPRT and Host Radix bits when setting up CPU
      powerpc/optprobes: Fix TOC handling in optprobes trampoline
      powerpc/pseries: Advertise Hot Plug Event support to firmware
      cxl: fix nested locking hang during EEH hotplug
      powerpc/xmon: Dump memory in CPU endian format
      powerpc/pseries: Revert 'Auto-online hotplugged memory'
      powerpc/powernv: Make PCI non-optional
      powerpc/64: Implement clear_bit_unlock_is_negative_byte()
      powerpc/powernv: Remove unused variable in pnv_pci_sriov_disable()
      powerpc/kernel: Remove error message in pcibios_setup_phb_resources()
      powerpc/mm: Fix typo in set_pte_at()
      pci/hotplug/pnv-php: Disable MSI and PCI device properly
      pci/hotplug/pnv-php: Disable surprise hotplug capability on conflicts
      pci/hotplug/pnv-php: Remove WARN_ON() in pnv_php_put_slot()
      powerpc: Add POWER9 architected mode to cputable
      powerpc/perf: use is_kernel_addr macro in perf_get_misc_flags()
      powerpc/perf: Avoid FAB_*_MATCH checks for power9
      powerpc/perf: Add restrictions to PMC5 in power9 DD1
      powerpc/perf: Use Instruction Counter value
      ...

commit 9af744d743170b5f5ef70031dea8d772d166ab28
Author: Michal Hocko <mhocko@suse.com>
Date:   Wed Feb 22 15:46:16 2017 -0800

    lib/show_mem.c: teach show_mem to work with the given nodemask
    
    show_mem() allows to filter out node specific data which is irrelevant
    to the allocation request via SHOW_MEM_FILTER_NODES.  The filtering is
    done in skip_free_areas_node which skips all nodes which are not in the
    mems_allowed of the current process.  This works most of the time as
    expected because the nodemask shouldn't be outside of the allocating
    task but there are some exceptions.  E.g.  memory hotplug might want to
    request allocations from outside of the allowed nodes (see
    new_node_page).
    
    Get rid of this hardcoded behavior and push the allocation mask down the
    show_mem path and use it instead of cpuset_current_mems_allowed.  NULL
    nodemask is interpreted as cpuset_current_mems_allowed.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Link: http://lkml.kernel.org/r/20170117091543.25850-5-mhocko@kernel.org
    Signed-off-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Mel Gorman <mgorman@suse.de>
    Cc: Hillf Danton <hillf.zj@alibaba-inc.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 1be0499f5397..5720236d0266 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -916,7 +916,7 @@ cmds(struct pt_regs *excp)
 				memzcan();
 				break;
 			case 'i':
-				show_mem(0);
+				show_mem(0, NULL);
 				break;
 			default:
 				termch = cmd;

commit 38705613b74ab090eee55c327cd0cb77fb10eb26
Merge: ff47d8c05019 438e69b52be7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Feb 22 10:30:38 2017 -0800

    Merge tag 'powerpc-4.11-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Highlights include:
    
       - Support for direct mapped LPC on POWER9, giving Linux direct access
         to devices that may be on there such as a UART.
    
       - Memory hotplug support for the Power9 Radix MMU.
    
       - Add new AUX vectors describing the processor's cache geometry, to
         be used by glibc.
    
       - The ability for a guest to ask the hypervisor to resize the guest's
         hash table, and in addition support for doing so automatically when
         memory is hotplugged into/out-of the guest. This allows the hash
         table to be sized based on the current memory usage of the guest,
         rather than the maximum possible memory usage.
    
       - Implementation of optprobes (kprobe optimisation) for powerpc.
    
      In addition there's the topic branch shared with the KVM tree, which
      includes support for guests to use the Radix MMU on Power9.
    
      Thanks to:
        Alistair Popple, Andrew Donnellan, Aneesh Kumar K.V, Anju T, Anton
        Blanchard, Benjamin Herrenschmidt, Chris Packham, Daniel Axtens,
        Daniel Borkmann, David Gibson, Finn Thain, Gautham R. Shenoy, Gavin
        Shan, Greg Kurz, Joel Stanley, John Allen, Madhavan Srinivasan,
        Mahesh Salgaonkar, Markus Elfring, Michael Neuling, Nathan Fontenot,
        Naveen N. Rao, Nicholas Piggin, Paul Mackerras, Ravi Bangoria, Reza
        Arbab, Shailendra Singh, Vaibhav Jain, Wei Yongjun"
    
    * tag 'powerpc-4.11-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (129 commits)
      powerpc/mm/radix: Skip ptesync in pte update helpers
      powerpc/mm/radix: Use ptep_get_and_clear_full when clearing pte for full mm
      powerpc/mm/radix: Update pte update sequence for pte clear case
      powerpc/mm: Update PROTFAULT handling in the page fault path
      powerpc/xmon: Fix data-breakpoint
      powerpc/mm: Fix build break with BOOK3S_64=n and MEMORY_HOTPLUG=y
      powerpc/mm: Fix build break when CMA=n && SPAPR_TCE_IOMMU=y
      powerpc/mm: Fix build break with RADIX=y & HUGETLBFS=n
      powerpc/pseries: Fix typo in parameter description
      powerpc/kprobes: Remove kprobe_exceptions_notify()
      kprobes: Introduce weak variant of kprobe_exceptions_notify()
      powerpc/ftrace: Fix confusing help text for DISABLE_MPROFILE_KERNEL
      powerpc/powernv: Fix opal_exit tracepoint opcode
      powerpc: Add a prototype for mcount() so it can be versioned
      powerpc: Drop GPL from of_node_to_nid() export to match other arches
      powerpc/kprobes: Optimize kprobe in kretprobe_trampoline()
      powerpc/kprobes: Implement Optprobes
      powerpc/kprobes: Fixes for kprobe_lookup_name() on BE
      powerpc: Add helper to check if offset is within relative branch range
      powerpc/bpf: Introduce __PPC_SH64()
      ...

commit 5e48dc0aa4d9daf93e9bff2a274473623a134ec8
Author: Douglas Miller <dougmill@linux.vnet.ibm.com>
Date:   Tue Feb 7 07:40:44 2017 -0600

    powerpc/xmon: Dump memory in CPU endian format
    
    Extend the dump command to allow display of 2, 4, and 8 byte words in
    CPU endian format. Also adds dump command for "1 byte values" for the
    sake of symmetry. New commands are:
    
      d1    dump 1 byte values
      d2    dump 2 byte values
      d4    dump 4 byte values
      d8    dump 8 byte values
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Douglas Miller <dougmill@linux.vnet.ibm.com>
    Acked-by: Balbir Singh <bsingharora@gmail.com>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index a44b049b9cf6..57503cdbd76f 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -212,6 +212,10 @@ Commands:\n\
   "\
   C	checksum\n\
   d	dump bytes\n\
+  d1	dump 1 byte values\n\
+  d2	dump 2 byte values\n\
+  d4	dump 4 byte values\n\
+  d8	dump 8 byte values\n\
   di	dump instructions\n\
   df	dump float values\n\
   dd	dump double values\n\
@@ -2334,9 +2338,42 @@ static void dump_pacas(void)
 }
 #endif
 
+static void dump_by_size(unsigned long addr, long count, int size)
+{
+	unsigned char temp[16];
+	int i, j;
+	u64 val;
+
+	count = ALIGN(count, 16);
+
+	for (i = 0; i < count; i += 16, addr += 16) {
+		printf(REG, addr);
+
+		if (mread(addr, temp, 16) != 16) {
+			printf("\nFaulted reading %d bytes from 0x"REG"\n", 16, addr);
+			return;
+		}
+
+		for (j = 0; j < 16; j += size) {
+			putchar(' ');
+			switch (size) {
+			case 1: val = temp[j]; break;
+			case 2: val = *(u16 *)&temp[j]; break;
+			case 4: val = *(u32 *)&temp[j]; break;
+			case 8: val = *(u64 *)&temp[j]; break;
+			default: val = 0;
+			}
+
+			printf("%0*lx", size * 2, val);
+		}
+		printf("\n");
+	}
+}
+
 static void
 dump(void)
 {
+	static char last[] = { "d?\n" };
 	int c;
 
 	c = inchar();
@@ -2350,8 +2387,9 @@ dump(void)
 	}
 #endif
 
-	if ((isxdigit(c) && c != 'f' && c != 'd') || c == '\n')
+	if (c == '\n')
 		termch = c;
+
 	scanhex((void *)&adrs);
 	if (termch != '\n')
 		termch = 0;
@@ -2383,9 +2421,23 @@ dump(void)
 			ndump = 64;
 		else if (ndump > MAX_DUMP)
 			ndump = MAX_DUMP;
-		prdump(adrs, ndump);
+
+		switch (c) {
+		case '8':
+		case '4':
+		case '2':
+		case '1':
+			ndump = ALIGN(ndump, 16);
+			dump_by_size(adrs, ndump, c - '0');
+			last[1] = c;
+			last_cmd = last;
+			break;
+		default:
+			prdump(adrs, ndump);
+			last_cmd = "d\n";
+		}
+
 		adrs += ndump;
-		last_cmd = "d\n";
 	}
 }
 

commit e71ff89c712cb387914abff373ac830d6298b012
Author: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
Date:   Thu Jan 5 16:38:15 2017 +0530

    powerpc/xmon: Cleanup to use is_kernel_addr macro
    
    Signed-off-by: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 9c0e17cf6886..a44b049b9cf6 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1403,7 +1403,7 @@ static void xmon_show_stack(unsigned long sp, unsigned long lr,
 	struct pt_regs regs;
 
 	while (max_to_print--) {
-		if (sp < PAGE_OFFSET) {
+		if (!is_kernel_addr(sp)) {
 			if (sp != 0)
 				printf("SP (%lx) is in userspace\n", sp);
 			break;
@@ -1431,12 +1431,12 @@ static void xmon_show_stack(unsigned long sp, unsigned long lr,
 				mread(newsp + LRSAVE_OFFSET, &nextip,
 				      sizeof(unsigned long));
 			if (lr == ip) {
-				if (lr < PAGE_OFFSET
+				if (!is_kernel_addr(lr)
 				    || (fnstart <= lr && lr < fnend))
 					printip = 0;
 			} else if (lr == nextip) {
 				printip = 0;
-			} else if (lr >= PAGE_OFFSET
+			} else if (is_kernel_addr(lr)
 				   && !(fnstart <= lr && lr < fnend)) {
 				printf("[link register   ] ");
 				xmon_print_symbol(lr, " ", "\n");
@@ -1496,7 +1496,7 @@ static void print_bug_trap(struct pt_regs *regs)
 	if (regs->msr & MSR_PR)
 		return;		/* not in kernel */
 	addr = regs->nip;	/* address of trap instruction */
-	if (addr < PAGE_OFFSET)
+	if (!is_kernel_addr(addr))
 		return;
 	bug = find_bug(regs->nip);
 	if (bug == NULL)

commit f828c3d0aebab130a19d36336b50afa3414fa0bc
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Jan 5 18:11:46 2017 +0100

    sched/cputime, powerpc: Migrate stolen_time field to the accounting structure
    
    That in order to gather all cputime accumulation to the same place.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1483636310-6557-7-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 9f3b170d9e0b..3f864c36d847 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2294,7 +2294,7 @@ static void dump_one_paca(int cpu)
 	DUMP(p, accounting.starttime_user, "llx");
 	DUMP(p, accounting.startspurr, "llx");
 	DUMP(p, accounting.utime_sspurr, "llx");
-	DUMP(p, stolen_time, "llx");
+	DUMP(p, accounting.steal_time, "llx");
 #undef DUMP
 
 	catch_memory_errors = 0;

commit 8c8b73c4811f2b5e458a7418dca07d2ef85c7db1
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Jan 5 18:11:45 2017 +0100

    sched/cputime, powerpc: Prepare accounting structure for cputime flush on tick
    
    In order to prepare for CONFIG_VIRT_CPU_ACCOUNTING_NATIVE=y to delay
    cputime accounting to the tick, provide finegrained accumulators to
    powerpc in order to store the cputime until flushing.
    
    While at it, normalize the name of several fields according to common
    cputime naming.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Christian Borntraeger <borntraeger@de.ibm.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/1483636310-6557-6-git-send-email-fweisbec@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 9c0e17cf6886..9f3b170d9e0b 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2287,9 +2287,9 @@ static void dump_one_paca(int cpu)
 	DUMP(p, subcore_sibling_mask, "x");
 #endif
 
-	DUMP(p, accounting.user_time, "llx");
-	DUMP(p, accounting.system_time, "llx");
-	DUMP(p, accounting.user_time_scaled, "llx");
+	DUMP(p, accounting.utime, "llx");
+	DUMP(p, accounting.stime, "llx");
+	DUMP(p, accounting.utime_scaled, "llx");
 	DUMP(p, accounting.starttime, "llx");
 	DUMP(p, accounting.starttime_user, "llx");
 	DUMP(p, accounting.startspurr, "llx");

commit 56144ec7c93f6f18aa878560074633ac3ad16896
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Fri Nov 6 13:21:17 2015 +1100

    powerpc/xmon: Add 'dt' command to dump trace buffers
    
    There is a nice interface for asking ftrace to dump all its tracing
    buffers. The only down side for use in xmon is that it uses printk.
    Depending on circumstances printk may not work when in xmon, but it also
    may, so add a 'dt' command which dumps the ftrace buffers, and add a
    note to the help to mentiont that it uses printk.
    
    Calling this routine also disables tracing, which is problematic if you
    return from xmon and expect the system to keep operating normally. So
    after we do the dump turn tracing back on.
    
    Both functions already have nop versions defined for when ftrace is not
    enabled, so we don't need any extra #ifdefs.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 760545519a0b..9c0e17cf6886 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -10,6 +10,8 @@
  *      as published by the Free Software Foundation; either version
  *      2 of the License, or (at your option) any later version.
  */
+
+#include <linux/kernel.h>
 #include <linux/errno.h>
 #include <linux/sched.h>
 #include <linux/smp.h>
@@ -225,6 +227,7 @@ Commands:\n\
 #endif
   "\
   dr	dump stream of raw bytes\n\
+  dt	dump the tracing buffers (uses printk)\n\
   e	print exception information\n\
   f	flush cache\n\
   la	lookup symbol+offset of specified address\n\
@@ -2364,6 +2367,9 @@ dump(void)
 		dump_log_buf();
 	} else if (c == 'o') {
 		dump_opal_msglog();
+	} else if (c == 't') {
+		ftrace_dump(DUMP_ALL);
+		tracing_on();
 	} else if (c == 'r') {
 		scanhex(&ndump);
 		if (ndump == 0)

commit 719dbb2df78fc9a40e28392b07cd715bfc5a665c
Merge: fbef66f0adcd 9f595fd8b548
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Sat Jul 30 13:43:19 2016 +1000

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/scottwood/linux into next
    
    Freescale updates from Scott:
    
    "Highlights include more 8xx optimizations, device tree updates,
    and MVME7100 support."

commit e0ddf7a24558b356d5cf5ecc12cb4e305c800953
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Jul 7 22:54:30 2016 +1000

    powerpc/xmon: Dump ISA 2.07 SPRs
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 8d95793365d8..255523360405 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1711,6 +1711,49 @@ static void dump_206_sprs(void)
 #endif
 }
 
+static void dump_207_sprs(void)
+{
+#ifdef CONFIG_PPC64
+	unsigned long msr;
+
+	if (!cpu_has_feature(CPU_FTR_ARCH_207S))
+		return;
+
+	printf("dpdes  = %.16x  tir   = %.16x cir    = %.8x\n",
+		mfspr(SPRN_DPDES), mfspr(SPRN_TIR), mfspr(SPRN_CIR));
+
+	printf("fscr   = %.16x  tar   = %.16x pspb   = %.8x\n",
+		mfspr(SPRN_FSCR), mfspr(SPRN_TAR), mfspr(SPRN_PSPB));
+
+	msr = mfmsr();
+	if (msr & MSR_TM) {
+		/* Only if TM has been enabled in the kernel */
+		printf("tfhar  = %.16x  tfiar = %.16x texasr = %.16x\n",
+			mfspr(SPRN_TFHAR), mfspr(SPRN_TFIAR),
+			mfspr(SPRN_TEXASR));
+	}
+
+	printf("mmcr0  = %.16x  mmcr1 = %.16x mmcr2  = %.16x\n",
+		mfspr(SPRN_MMCR0), mfspr(SPRN_MMCR1), mfspr(SPRN_MMCR2));
+	printf("pmc1   = %.8x pmc2 = %.8x  pmc3 = %.8x  pmc4   = %.8x\n",
+		mfspr(SPRN_PMC1), mfspr(SPRN_PMC2),
+		mfspr(SPRN_PMC3), mfspr(SPRN_PMC4));
+	printf("mmcra  = %.16x   siar = %.16x pmc5   = %.8x\n",
+		mfspr(SPRN_MMCRA), mfspr(SPRN_SIAR), mfspr(SPRN_PMC5));
+	printf("sdar   = %.16x   sier = %.16x pmc6   = %.8x\n",
+		mfspr(SPRN_SDAR), mfspr(SPRN_SIER), mfspr(SPRN_PMC6));
+	printf("ebbhr  = %.16x  ebbrr = %.16x bescr  = %.16x\n",
+		mfspr(SPRN_EBBHR), mfspr(SPRN_EBBRR), mfspr(SPRN_BESCR));
+
+	if (!(msr & MSR_HV))
+		return;
+
+	printf("hfscr  = %.16x  dhdes = %.16x rpr    = %.16x\n",
+		mfspr(SPRN_HFSCR), mfspr(SPRN_DHDES), mfspr(SPRN_RPR));
+	printf("dawr   = %.16x  dawrx = %.16x ciabr  = %.16x\n",
+		mfspr(SPRN_DAWR), mfspr(SPRN_DAWRX), mfspr(SPRN_CIABR));
+#endif
+}
 
 static void dump_one_spr(int spr, bool show_unimplemented)
 {
@@ -1764,6 +1807,7 @@ static void super_regs(void)
 		printf("toc    = "REG"  dar   = "REG"\n", toc, mfspr(SPRN_DAR));
 
 		dump_206_sprs();
+		dump_207_sprs();
 
 		return;
 	}

commit 1846193b178dcc58435fdc57352db7b74826ef37
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Jul 7 22:54:29 2016 +1000

    powerpc/xmon: Dump ISA 2.06 SPRs
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 4300ad63ad8e..8d95793365d8 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1682,6 +1682,35 @@ write_spr(int n, unsigned long val)
 	catch_spr_faults = 0;
 }
 
+static void dump_206_sprs(void)
+{
+#ifdef CONFIG_PPC64
+	if (!cpu_has_feature(CPU_FTR_ARCH_206))
+		return;
+
+	/* Actually some of these pre-date 2.06, but whatevs */
+
+	printf("srr0   = %.16x  srr1  = %.16x dsisr  = %.8x\n",
+		mfspr(SPRN_SRR0), mfspr(SPRN_SRR1), mfspr(SPRN_DSISR));
+	printf("dscr   = %.16x  ppr   = %.16x pir    = %.8x\n",
+		mfspr(SPRN_DSCR), mfspr(SPRN_PPR), mfspr(SPRN_PIR));
+
+	if (!(mfmsr() & MSR_HV))
+		return;
+
+	printf("sdr1   = %.16x  hdar  = %.16x hdsisr = %.8x\n",
+		mfspr(SPRN_SDR1), mfspr(SPRN_HDAR), mfspr(SPRN_HDSISR));
+	printf("hsrr0  = %.16x hsrr1  = %.16x hdec = %.8x\n",
+		mfspr(SPRN_HSRR0), mfspr(SPRN_HSRR1), mfspr(SPRN_HDEC));
+	printf("lpcr   = %.16x  pcr   = %.16x lpidr = %.8x\n",
+		mfspr(SPRN_LPCR), mfspr(SPRN_PCR), mfspr(SPRN_LPID));
+	printf("hsprg0 = %.16x hsprg1 = %.16x\n",
+		mfspr(SPRN_HSPRG0), mfspr(SPRN_HSPRG1));
+	printf("dabr   = %.16x dabrx  = %.16x\n",
+		mfspr(SPRN_DABR), mfspr(SPRN_DABRX));
+#endif
+}
+
 
 static void dump_one_spr(int spr, bool show_unimplemented)
 {
@@ -1734,6 +1763,8 @@ static void super_regs(void)
 		printf("sp     = "REG"  sprg3 = "REG"\n", sp, mfspr(SPRN_SPRG3));
 		printf("toc    = "REG"  dar   = "REG"\n", toc, mfspr(SPRN_DAR));
 
+		dump_206_sprs();
+
 		return;
 	}
 	case 'w': {

commit 56346ad88d65fd60dde7b0535ff08daac45b560b
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Jul 7 22:54:28 2016 +1000

    powerpc/xmon: Adjust spacing of existing SPRs to make room for more
    
    Purely to make it pleasing to the eye.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 369501283994..4300ad63ad8e 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1725,14 +1725,15 @@ static void super_regs(void)
 		asm("mr %0,1" : "=r" (sp) :);
 		asm("mr %0,2" : "=r" (toc) :);
 
-		printf("msr  = "REG"  sprg0= "REG"\n",
+		printf("msr    = "REG"  sprg0 = "REG"\n",
 		       mfmsr(), mfspr(SPRN_SPRG0));
-		printf("pvr  = "REG"  sprg1= "REG"\n",
+		printf("pvr    = "REG"  sprg1 = "REG"\n",
 		       mfspr(SPRN_PVR), mfspr(SPRN_SPRG1));
-		printf("dec  = "REG"  sprg2= "REG"\n",
+		printf("dec    = "REG"  sprg2 = "REG"\n",
 		       mfspr(SPRN_DEC), mfspr(SPRN_SPRG2));
-		printf("sp   = "REG"  sprg3= "REG"\n", sp, mfspr(SPRN_SPRG3));
-		printf("toc  = "REG"  dar  = "REG"\n", toc, mfspr(SPRN_DAR));
+		printf("sp     = "REG"  sprg3 = "REG"\n", sp, mfspr(SPRN_SPRG3));
+		printf("toc    = "REG"  dar   = "REG"\n", toc, mfspr(SPRN_DAR));
+
 		return;
 	}
 	case 'w': {

commit 13629dad1e30e310bb21baa102d1c0dcc17b47ae
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Jul 7 22:54:27 2016 +1000

    powerpc/xmon: Move static regno into its only user
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index f351ba6a58ab..369501283994 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1682,7 +1682,6 @@ write_spr(int n, unsigned long val)
 	catch_spr_faults = 0;
 }
 
-static unsigned long regno;
 
 static void dump_one_spr(int spr, bool show_unimplemented)
 {
@@ -1714,6 +1713,7 @@ static void dump_one_spr(int spr, bool show_unimplemented)
 
 static void super_regs(void)
 {
+	static unsigned long regno;
 	int cmd;
 	int spr;
 

commit 5b71eff78267a1e0d2f178a8b5397f4b23dfdf97
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Jul 7 22:54:26 2016 +1000

    powerpc/xmon: Remove unused externs
    
    None of these are used, or have been since we merged ppc & ppc64.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index c5e155108be5..f351ba6a58ab 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -184,9 +184,6 @@ static void dump_tlb_book3e(void);
 
 static int xmon_no_auto_backtrace;
 
-extern void xmon_enter(void);
-extern void xmon_leave(void);
-
 #ifdef CONFIG_PPC64
 #define REG		"%.16lx"
 #else
@@ -1686,8 +1683,6 @@ write_spr(int n, unsigned long val)
 }
 
 static unsigned long regno;
-extern char exc_prolog;
-extern char dec_exc;
 
 static void dump_one_spr(int spr, bool show_unimplemented)
 {

commit c223c90386bc2306510e0ceacd768a0123ff2a2f
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Tue May 17 08:33:46 2016 +0200

    powerpc32: provide VIRT_CPU_ACCOUNTING
    
    This patch provides VIRT_CPU_ACCOUTING to PPC32 architecture.
    PPC32 doesn't have the PACA structure, so we use the task_info
    structure to store the accounting data.
    
    In order to reuse on PPC32 the PPC64 functions, all u64 data has
    been replaced by 'unsigned long' so that it is u32 on PPC32 and
    u64 on PPC64
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Scott Wood <oss@buserror.net>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index c5e155108be5..4f7c29d87ec3 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2213,13 +2213,13 @@ static void dump_one_paca(int cpu)
 	DUMP(p, subcore_sibling_mask, "x");
 #endif
 
-	DUMP(p, user_time, "llx");
-	DUMP(p, system_time, "llx");
-	DUMP(p, user_time_scaled, "llx");
-	DUMP(p, starttime, "llx");
-	DUMP(p, starttime_user, "llx");
-	DUMP(p, startspurr, "llx");
-	DUMP(p, utime_sspurr, "llx");
+	DUMP(p, accounting.user_time, "llx");
+	DUMP(p, accounting.system_time, "llx");
+	DUMP(p, accounting.user_time_scaled, "llx");
+	DUMP(p, accounting.starttime, "llx");
+	DUMP(p, accounting.starttime_user, "llx");
+	DUMP(p, accounting.startspurr, "llx");
+	DUMP(p, accounting.utime_sspurr, "llx");
 	DUMP(p, stolen_time, "llx");
 #undef DUMP
 

commit 31cdd0c39c7544ced79da53aa0b7e989f3a39582
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Wed Apr 13 21:31:24 2016 +1000

    powerpc/xmon: Fix SPR read/write commands and add command to dump SPRs
    
    xmon has commands for reading and writing SPRs, but they don't work
    currently for several reasons. They attempt to synthesize a small
    function containing an mfspr or mtspr instruction and call it. However,
    the instructions are on the stack, which is usually not executable.
    Also, for 64-bit we set up a procedure descriptor, which is fine for the
    big-endian ABIv1, but not correct for ABIv2. Finally, the code uses the
    infrastructure for catching memory errors, but that only catches data
    storage interrupts and machine check interrupts, but a failed
    mfspr/mtspr can generate a program interrupt or a hypervisor emulation
    assist interrupt, or be a no-op.
    
    Instead of trying to synthesize a function on the fly, this adds two new
    functions, xmon_mfspr() and xmon_mtspr(), which take an SPR number as an
    argument and read or write the SPR. Because there is no Power ISA
    instruction which takes an SPR number in a register, we have to generate
    one of each possible mfspr and mtspr instruction, for all 1024 possible
    SPRs. Thus we get just over 8k bytes of code for each of xmon_mfspr()
    and xmon_mtspr(). However, this 16kB of code pales in comparison to the
    > 130kB of PPC opcode tables used by the xmon disassembler.
    
    To catch interrupts caused by the mfspr/mtspr instructions, we add a new
    'catch_spr_faults' flag. If an interrupt occurs while it is set, we come
    back into xmon() via program_check_interrupt(), _exception() and die(),
    see that catch_spr_faults is set and do a longjmp to bus_error_jmp, back
    into read_spr() or write_spr().
    
    This adds a couple of other nice features: first, a "Sa" command that
    attempts to read and print out the value of all 1024 SPRs. If any mfspr
    instruction acts as a no-op, then the SPR is not implemented and not
    printed.
    
    Secondly, the Sr and Sw commands detect when an SPR is not
    implemented (i.e. mfspr is a no-op) and print a message to that effect
    rather than printing a bogus value.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 308283b7b60c..c5e155108be5 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -86,6 +86,7 @@ static char tmpstr[128];
 
 static long bus_error_jmp[JMP_BUF_LEN];
 static int catch_memory_errors;
+static int catch_spr_faults;
 static long *xmon_fault_jmp[NR_CPUS];
 
 /* Breakpoint stuff */
@@ -147,7 +148,7 @@ void getstring(char *, int);
 static void flush_input(void);
 static int inchar(void);
 static void take_input(char *);
-static unsigned long read_spr(int);
+static int  read_spr(int, unsigned long *);
 static void write_spr(int, unsigned long);
 static void super_regs(void);
 static void remove_bpts(void);
@@ -250,6 +251,9 @@ Commands:\n\
   sdi #	disassemble spu local store for spu # (in hex)\n"
 #endif
 "  S	print special registers\n\
+  Sa    print all SPRs\n\
+  Sr #	read SPR #\n\
+  Sw #v write v to SPR #\n\
   t	print backtrace\n\
   x	exit monitor and recover\n\
   X	exit monitor and don't recover\n"
@@ -442,6 +446,12 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 #ifdef CONFIG_SMP
 	cpu = smp_processor_id();
 	if (cpumask_test_cpu(cpu, &cpus_in_xmon)) {
+		/*
+		 * We catch SPR read/write faults here because the 0x700, 0xf60
+		 * etc. handlers don't call debugger_fault_handler().
+		 */
+		if (catch_spr_faults)
+			longjmp(bus_error_jmp, 1);
 		get_output_lock();
 		excprint(regs);
 		printf("cpu 0x%x: Exception %lx %s in xmon, "
@@ -1635,89 +1645,87 @@ static void cacheflush(void)
 	catch_memory_errors = 0;
 }
 
-static unsigned long
-read_spr(int n)
+extern unsigned long xmon_mfspr(int spr, unsigned long default_value);
+extern void xmon_mtspr(int spr, unsigned long value);
+
+static int
+read_spr(int n, unsigned long *vp)
 {
-	unsigned int instrs[2];
-	unsigned long (*code)(void);
 	unsigned long ret = -1UL;
-#ifdef CONFIG_PPC64
-	unsigned long opd[3];
-
-	opd[0] = (unsigned long)instrs;
-	opd[1] = 0;
-	opd[2] = 0;
-	code = (unsigned long (*)(void)) opd;
-#else
-	code = (unsigned long (*)(void)) instrs;
-#endif
-
-	/* mfspr r3,n; blr */
-	instrs[0] = 0x7c6002a6 + ((n & 0x1F) << 16) + ((n & 0x3e0) << 6);
-	instrs[1] = 0x4e800020;
-	store_inst(instrs);
-	store_inst(instrs+1);
+	int ok = 0;
 
 	if (setjmp(bus_error_jmp) == 0) {
-		catch_memory_errors = 1;
+		catch_spr_faults = 1;
 		sync();
 
-		ret = code();
+		ret = xmon_mfspr(n, *vp);
 
 		sync();
-		/* wait a little while to see if we get a machine check */
-		__delay(200);
-		n = size;
+		*vp = ret;
+		ok = 1;
 	}
+	catch_spr_faults = 0;
 
-	return ret;
+	return ok;
 }
 
 static void
 write_spr(int n, unsigned long val)
 {
-	unsigned int instrs[2];
-	unsigned long (*code)(unsigned long);
-#ifdef CONFIG_PPC64
-	unsigned long opd[3];
-
-	opd[0] = (unsigned long)instrs;
-	opd[1] = 0;
-	opd[2] = 0;
-	code = (unsigned long (*)(unsigned long)) opd;
-#else
-	code = (unsigned long (*)(unsigned long)) instrs;
-#endif
-
-	instrs[0] = 0x7c6003a6 + ((n & 0x1F) << 16) + ((n & 0x3e0) << 6);
-	instrs[1] = 0x4e800020;
-	store_inst(instrs);
-	store_inst(instrs+1);
-
 	if (setjmp(bus_error_jmp) == 0) {
-		catch_memory_errors = 1;
+		catch_spr_faults = 1;
 		sync();
 
-		code(val);
+		xmon_mtspr(n, val);
 
 		sync();
-		/* wait a little while to see if we get a machine check */
-		__delay(200);
-		n = size;
+	} else {
+		printf("SPR 0x%03x (%4d) Faulted during write\n", n, n);
 	}
+	catch_spr_faults = 0;
 }
 
 static unsigned long regno;
 extern char exc_prolog;
 extern char dec_exc;
 
+static void dump_one_spr(int spr, bool show_unimplemented)
+{
+	unsigned long val;
+
+	val = 0xdeadbeef;
+	if (!read_spr(spr, &val)) {
+		printf("SPR 0x%03x (%4d) Faulted during read\n", spr, spr);
+		return;
+	}
+
+	if (val == 0xdeadbeef) {
+		/* Looks like read was a nop, confirm */
+		val = 0x0badcafe;
+		if (!read_spr(spr, &val)) {
+			printf("SPR 0x%03x (%4d) Faulted during read\n", spr, spr);
+			return;
+		}
+
+		if (val == 0x0badcafe) {
+			if (show_unimplemented)
+				printf("SPR 0x%03x (%4d) Unimplemented\n", spr, spr);
+			return;
+		}
+	}
+
+	printf("SPR 0x%03x (%4d) = 0x%lx\n", spr, spr, val);
+}
+
 static void super_regs(void)
 {
 	int cmd;
-	unsigned long val;
+	int spr;
 
 	cmd = skipbl();
-	if (cmd == '\n') {
+
+	switch (cmd) {
+	case '\n': {
 		unsigned long sp, toc;
 		asm("mr %0,1" : "=r" (sp) :);
 		asm("mr %0,2" : "=r" (toc) :);
@@ -1730,21 +1738,29 @@ static void super_regs(void)
 		       mfspr(SPRN_DEC), mfspr(SPRN_SPRG2));
 		printf("sp   = "REG"  sprg3= "REG"\n", sp, mfspr(SPRN_SPRG3));
 		printf("toc  = "REG"  dar  = "REG"\n", toc, mfspr(SPRN_DAR));
-
 		return;
 	}
-
-	scanhex(&regno);
-	switch (cmd) {
-	case 'w':
-		val = read_spr(regno);
+	case 'w': {
+		unsigned long val;
+		scanhex(&regno);
+		val = 0;
+		read_spr(regno, &val);
 		scanhex(&val);
 		write_spr(regno, val);
-		/* fall through */
+		dump_one_spr(regno, true);
+		break;
+	}
 	case 'r':
-		printf("spr %lx = %lx\n", regno, read_spr(regno));
+		scanhex(&regno);
+		dump_one_spr(regno, true);
+		break;
+	case 'a':
+		/* dump ALL SPRs */
+		for (spr = 1; spr < 1024; ++spr)
+			dump_one_spr(spr, false);
 		break;
 	}
+
 	scannl();
 }
 

commit caca285e5ab4a7a19fede51688106ceed6fc45dd
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Fri Apr 29 23:26:07 2016 +1000

    powerpc/mm/radix: Use STD_MMU_64 to properly isolate hash related code
    
    We also use MMU_FTR_RADIX to branch out from code path specific to
    hash.
    
    No functionality change.
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 942796fa4767..308283b7b60c 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2913,7 +2913,7 @@ static void xmon_print_symbol(unsigned long address, const char *mid,
 	printf("%s", after);
 }
 
-#ifdef CONFIG_PPC_BOOK3S_64
+#ifdef CONFIG_PPC_STD_MMU_64
 void dump_segments(void)
 {
 	int i;

commit 6dfb54049f9a99b24fe5d5cd2d3af19eadc8f31f
Author: Douglas Miller <dougmill@linux.vnet.ibm.com>
Date:   Mon Nov 23 09:01:15 2015 -0600

    powerpc/xmon: Add xmon command to dump process/task similar to ps(1)
    
    Add 'P' command with optional task_struct address to dump all/one task's
    information: task pointer, kernel stack pointer, PID, PPID, state
    (interpreted), CPU where (last) running, and command.
    
    Signed-off-by: Douglas Miller <dougmill@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 47e195d66a9a..942796fa4767 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -163,6 +163,7 @@ static int  cpu_cmd(void);
 static void csum(void);
 static void bootcmds(void);
 static void proccall(void);
+static void show_tasks(void);
 void dump_segments(void);
 static void symbol_lookup(void);
 static void xmon_show_stack(unsigned long sp, unsigned long lr,
@@ -238,6 +239,7 @@ Commands:\n\
   mz	zero a block of memory\n\
   mi	show information about memory allocation\n\
   p 	call a procedure\n\
+  P 	list processes/tasks\n\
   r	print registers\n\
   s	single step\n"
 #ifdef CONFIG_SPU_BASE
@@ -967,6 +969,9 @@ cmds(struct pt_regs *excp)
 		case 'p':
 			proccall();
 			break;
+		case 'P':
+			show_tasks();
+			break;
 #ifdef CONFIG_PPC_STD_MMU
 		case 'u':
 			dump_segments();
@@ -2566,6 +2571,61 @@ memzcan(void)
 		printf("%.8x\n", a - mskip);
 }
 
+static void show_task(struct task_struct *tsk)
+{
+	char state;
+
+	/*
+	 * Cloned from kdb_task_state_char(), which is not entirely
+	 * appropriate for calling from xmon. This could be moved
+	 * to a common, generic, routine used by both.
+	 */
+	state = (tsk->state == 0) ? 'R' :
+		(tsk->state < 0) ? 'U' :
+		(tsk->state & TASK_UNINTERRUPTIBLE) ? 'D' :
+		(tsk->state & TASK_STOPPED) ? 'T' :
+		(tsk->state & TASK_TRACED) ? 'C' :
+		(tsk->exit_state & EXIT_ZOMBIE) ? 'Z' :
+		(tsk->exit_state & EXIT_DEAD) ? 'E' :
+		(tsk->state & TASK_INTERRUPTIBLE) ? 'S' : '?';
+
+	printf("%p %016lx %6d %6d %c %2d %s\n", tsk,
+		tsk->thread.ksp,
+		tsk->pid, tsk->parent->pid,
+		state, task_thread_info(tsk)->cpu,
+		tsk->comm);
+}
+
+static void show_tasks(void)
+{
+	unsigned long tskv;
+	struct task_struct *tsk = NULL;
+
+	printf("     task_struct     ->thread.ksp    PID   PPID S  P CMD\n");
+
+	if (scanhex(&tskv))
+		tsk = (struct task_struct *)tskv;
+
+	if (setjmp(bus_error_jmp) != 0) {
+		catch_memory_errors = 0;
+		printf("*** Error dumping task %p\n", tsk);
+		return;
+	}
+
+	catch_memory_errors = 1;
+	sync();
+
+	if (tsk)
+		show_task(tsk);
+	else
+		for_each_process(tsk)
+			show_task(tsk);
+
+	sync();
+	__delay(200);
+	catch_memory_errors = 0;
+}
+
 static void proccall(void)
 {
 	unsigned long args[8];

commit fde93a0f774f510bfaabccd5ba00f97972be1e12
Author: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
Date:   Tue Feb 9 18:17:49 2016 +1100

    powerpc/xmon: add command to dump OPAL msglog
    
    Add the 'do' command to dump the OPAL msglog in xmon.
    
    Signed-off-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    [mpe: Reduce the amount of ifdefery required]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index d5c8a156f63c..47e195d66a9a 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -47,6 +47,9 @@
 #include <asm/debug.h>
 #include <asm/hw_breakpoint.h>
 
+#include <asm/opal.h>
+#include <asm/firmware.h>
+
 #ifdef CONFIG_PPC64
 #include <asm/hvcall.h>
 #include <asm/paca.h>
@@ -119,6 +122,16 @@ static void dump(void);
 static void prdump(unsigned long, long);
 static int ppc_inst_dump(unsigned long, long, int);
 static void dump_log_buf(void);
+
+#ifdef CONFIG_PPC_POWERNV
+static void dump_opal_msglog(void);
+#else
+static inline void dump_opal_msglog(void)
+{
+	printf("Machine is not running OPAL firmware.\n");
+}
+#endif
+
 static void backtrace(struct pt_regs *);
 static void excprint(struct pt_regs *);
 static void prregs(struct pt_regs *);
@@ -202,6 +215,10 @@ Commands:\n\
   df	dump float values\n\
   dd	dump double values\n\
   dl    dump the kernel log buffer\n"
+#ifdef CONFIG_PPC_POWERNV
+  "\
+  do    dump the OPAL message log\n"
+#endif
 #ifdef CONFIG_PPC64
   "\
   dp[#]	dump paca for current cpu, or cpu #\n\
@@ -2253,6 +2270,8 @@ dump(void)
 		last_cmd = "di\n";
 	} else if (c == 'l') {
 		dump_log_buf();
+	} else if (c == 'o') {
+		dump_opal_msglog();
 	} else if (c == 'r') {
 		scanhex(&ndump);
 		if (ndump == 0)
@@ -2395,6 +2414,45 @@ dump_log_buf(void)
 	catch_memory_errors = 0;
 }
 
+#ifdef CONFIG_PPC_POWERNV
+static void dump_opal_msglog(void)
+{
+	unsigned char buf[128];
+	ssize_t res;
+	loff_t pos = 0;
+
+	if (!firmware_has_feature(FW_FEATURE_OPAL)) {
+		printf("Machine is not running OPAL firmware.\n");
+		return;
+	}
+
+	if (setjmp(bus_error_jmp) != 0) {
+		printf("Error dumping OPAL msglog!\n");
+		return;
+	}
+
+	catch_memory_errors = 1;
+	sync();
+
+	xmon_start_pagination();
+	while ((res = opal_msglog_copy(buf, pos, sizeof(buf) - 1))) {
+		if (res < 0) {
+			printf("Error dumping OPAL msglog! Error: %zd\n", res);
+			break;
+		}
+		buf[res] = '\0';
+		printf("%s", buf);
+		pos += res;
+	}
+	xmon_end_pagination();
+
+	sync();
+	/* wait a little while to see if we get a machine check */
+	__delay(200);
+	catch_memory_errors = 0;
+}
+#endif
+
 /*
  * Memory operations - move, set, print differences
  */

commit 2e34057929cad8a90b775581216886d22b642e0a
Author: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
Date:   Wed Jan 27 11:29:44 2016 +1100

    powerpc/xmon: fix typo in usage message
    
    Signed-off-by: Andrew Donnellan <andrew.donnellan@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 07a8508cb7fa..d5c8a156f63c 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -233,7 +233,7 @@ Commands:\n\
 "  S	print special registers\n\
   t	print backtrace\n\
   x	exit monitor and recover\n\
-  X	exit monitor and dont recover\n"
+  X	exit monitor and don't recover\n"
 #if defined(CONFIG_PPC64) && !defined(CONFIG_PPC_BOOK3E)
 "  u	dump segment table or SLB\n"
 #elif defined(CONFIG_PPC_STD_MMU_32)

commit 08eb105a7c18c917f2ed7afc5a151f0514f26460
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Nov 24 22:26:09 2015 +1100

    powerpc/xmon: Use rtas_call_unlocked() in xmon
    
    Avoid open coding the logic by using rtas_call_unlocked().
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index e8c7a937955e..07a8508cb7fa 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -320,6 +320,7 @@ static inline void disable_surveillance(void)
 #ifdef CONFIG_PPC_PSERIES
 	/* Since this can't be a module, args should end up below 4GB. */
 	static struct rtas_args args;
+	int token;
 
 	/*
 	 * At this point we have got all the cpus we can into
@@ -328,17 +329,12 @@ static inline void disable_surveillance(void)
 	 * If we did try to take rtas.lock there would be a
 	 * real possibility of deadlock.
 	 */
-	args.token = rtas_token("set-indicator");
-	if (args.token == RTAS_UNKNOWN_SERVICE)
+	token = rtas_token("set-indicator");
+	if (token == RTAS_UNKNOWN_SERVICE)
 		return;
-	args.token = cpu_to_be32(args.token);
-	args.nargs = cpu_to_be32(3);
-	args.nret = cpu_to_be32(1);
-	args.rets = &args.args[3];
-	args.args[0] = cpu_to_be32(SURVEILLANCE_TOKEN);
-	args.args[1] = 0;
-	args.args[2] = 0;
-	enter_rtas(__pa(&args));
+
+	rtas_call_unlocked(&args, token, 3, 1, NULL, SURVEILLANCE_TOKEN, 0, 0);
+
 #endif /* CONFIG_PPC_PSERIES */
 }
 

commit eb925d64604991095b6e9476d7c437a994f3369c
Author: Rashmica Gupta <rashmicy@gmail.com>
Date:   Wed Nov 25 13:46:25 2015 +1100

    powerpc/xmon: Append linux_banner to exception information in xmon.
    
    Currently if you are in xmon without an oops etc. to view the kernel
    version you have to type "d $linux_banner" - not necessarily obvious. As
    this is useful information, append to the output of "e" command.
    
    Example output:
      $mon> e
      cpu 0x1: Vector: 0  at [c0000000f879ba80]
          pc: c000000000081718: sysrq_handle_xmon+0x68/0x80
          lr: c000000000081718: sysrq_handle_xmon+0x68/0x80
          sp: c0000000f879bbe0
         msr: 8000000000009033
        current = 0xc0000000f604d5c0
        paca    = 0xc00000000fdc0480         softe: 0        irq_happened: 0x01
          pid   = 2467, comm = bash
      Linux version 4.4.0-rc2-00008-gc51af91c3ab3-dirty (rashmica@circle) (gcc
      version 5.1.1 20150629 (GCC) ) #45 SMP Wed Nov 25 10:25:12 AEDT 2015
    
    Signed-off-by: Rashmica Gupta <rashmicy@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 786bf01691c9..e8c7a937955e 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1522,6 +1522,8 @@ static void excprint(struct pt_regs *fp)
 
 	if (trap == 0x700)
 		print_bug_trap(fp);
+
+	printf(linux_banner);
 }
 
 static void prregs(struct pt_regs *fp)

commit ad987fc8eae7b5f4085c5ad2610b9af12018c38a
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Oct 14 16:58:36 2015 +1100

    powerpc/xmon: Add some more elements to the existing PACA dump list
    
    This patch adds a set of new elements to the existing PACA dump list
    inside an xmon session which can be listed below improving the overall
    xmon debug support.
    
    With this patch, a typical xmon PACA dump looks something like this.
    
    paca for cpu 0x0 @ c00000000fdc0000:
     possible             = yes
     present              = yes
     online               = yes
     lock_token           = 0x8000                  (0xa)
     paca_index           = 0x0                     (0x8)
     kernel_toc           = 0xc000000001393200      (0x10)
     kernelbase           = 0xc000000000000000      (0x18)
     kernel_msr           = 0xb000000000001033      (0x20)
     emergency_sp         = 0xc00000003fff0000      (0x28)
     mc_emergency_sp      = 0xc00000003ffec000      (0x2e0)
     in_mce               = 0x0                     (0x2e8)
     hmi_event_available  = 0x0                     (0x2ea)
     data_offset          = 0x1fe7b0000             (0x30)
     hw_cpu_id            = 0x0                     (0x38)
     cpu_start            = 0x1                     (0x3a)
     kexec_state          = 0x0                     (0x3b)
     slb_shadow[0]:       = 0xc000000008000000 0x40016e7779000510
     slb_shadow[1]:       = 0xd000000008000001 0x400142add1000510
     vmalloc_sllp         = 0x510                   (0x1b8)
     slb_cache_ptr        = 0x4                     (0x1ba)
     slb_cache[0]:        = 0x000000000003f000
     slb_cache[1]:        = 0x0000000000000001
     slb_cache[2]:        = 0x0000000000000003
     slb_cache[3]:        = 0x0000000000001000
     slb_cache[4]:        = 0x0000000000001000
     slb_cache[5]:        = 0x0000000000000000
     slb_cache[6]:        = 0x0000000000000000
     slb_cache[7]:        = 0x0000000000000000
     dscr_default         = 0x0                     (0x58)
     __current            = 0xc000000001331e80      (0x290)
     kstack               = 0xc000000001393e30      (0x298)
     stab_rr              = 0x11                    (0x2a0)
     saved_r1             = 0xc0000001fffef5e0      (0x2a8)
     trap_save            = 0x0                     (0x2b8)
     soft_enabled         = 0x0                     (0x2ba)
     irq_happened         = 0x1                     (0x2bb)
     io_sync              = 0x0                     (0x2bc)
     irq_work_pending     = 0x0                     (0x2bd)
     nap_state_lost       = 0x0                     (0x2be)
     sprg_vdso            = 0x0                     (0x2c0)
     tm_scratch           = 0x8000000100009033      (0x2c8)
     core_idle_state_ptr  = (null)                  (0x2d0)
     thread_idle_state    = 0x0                     (0x2d8)
     thread_mask          = 0x0                     (0x2d9)
     subcore_sibling_mask = 0x0                     (0x2da)
     user_time            = 0x0                     (0x2f0)
     system_time          = 0x0                     (0x2f8)
     user_time_scaled     = 0x0                     (0x300)
     starttime            = 0x3f462418b5cf4         (0x308)
     starttime_user       = 0x3f4622a57092a         (0x310)
     startspurr           = 0xd62a5718              (0x318)
     utime_sspurr         = 0x0                     (0x320)
     stolen_time          = 0x0                     (0x328)
    
    Signed-off-by: Anshuman Khandual <khandual@linux.vnet.ibm.com>
    [mpe: Endian swap slb_shadow before display, minor formatting]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index bf8f49a8b3a7..786bf01691c9 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2086,6 +2086,9 @@ static void xmon_rawdump (unsigned long adrs, long ndump)
 static void dump_one_paca(int cpu)
 {
 	struct paca_struct *p;
+#ifdef CONFIG_PPC_STD_MMU_64
+	int i = 0;
+#endif
 
 	if (setjmp(bus_error_jmp) != 0) {
 		printf("*** Error dumping paca for cpu 0x%x!\n", cpu);
@@ -2099,12 +2102,12 @@ static void dump_one_paca(int cpu)
 
 	printf("paca for cpu 0x%x @ %p:\n", cpu, p);
 
-	printf(" %-*s = %s\n", 16, "possible", cpu_possible(cpu) ? "yes" : "no");
-	printf(" %-*s = %s\n", 16, "present", cpu_present(cpu) ? "yes" : "no");
-	printf(" %-*s = %s\n", 16, "online", cpu_online(cpu) ? "yes" : "no");
+	printf(" %-*s = %s\n", 20, "possible", cpu_possible(cpu) ? "yes" : "no");
+	printf(" %-*s = %s\n", 20, "present", cpu_present(cpu) ? "yes" : "no");
+	printf(" %-*s = %s\n", 20, "online", cpu_online(cpu) ? "yes" : "no");
 
 #define DUMP(paca, name, format) \
-	printf(" %-*s = %#-*"format"\t(0x%lx)\n", 16, #name, 18, paca->name, \
+	printf(" %-*s = %#-*"format"\t(0x%lx)\n", 20, #name, 18, paca->name, \
 		offsetof(struct paca_struct, name));
 
 	DUMP(p, lock_token, "x");
@@ -2116,11 +2119,41 @@ static void dump_one_paca(int cpu)
 #ifdef CONFIG_PPC_BOOK3S_64
 	DUMP(p, mc_emergency_sp, "p");
 	DUMP(p, in_mce, "x");
+	DUMP(p, hmi_event_available, "x");
 #endif
 	DUMP(p, data_offset, "lx");
 	DUMP(p, hw_cpu_id, "x");
 	DUMP(p, cpu_start, "x");
 	DUMP(p, kexec_state, "x");
+#ifdef CONFIG_PPC_STD_MMU_64
+	for (i = 0; i < SLB_NUM_BOLTED; i++) {
+		u64 esid, vsid;
+
+		if (!p->slb_shadow_ptr)
+			continue;
+
+		esid = be64_to_cpu(p->slb_shadow_ptr->save_area[i].esid);
+		vsid = be64_to_cpu(p->slb_shadow_ptr->save_area[i].vsid);
+
+		if (esid || vsid) {
+			printf(" slb_shadow[%d]:       = 0x%016lx 0x%016lx\n",
+				i, esid, vsid);
+		}
+	}
+	DUMP(p, vmalloc_sllp, "x");
+	DUMP(p, slb_cache_ptr, "x");
+	for (i = 0; i < SLB_CACHE_ENTRIES; i++)
+		printf(" slb_cache[%d]:        = 0x%016lx\n", i, p->slb_cache[i]);
+#endif
+	DUMP(p, dscr_default, "llx");
+#ifdef CONFIG_PPC_BOOK3E
+	DUMP(p, pgd, "p");
+	DUMP(p, kernel_pgd, "p");
+	DUMP(p, tcd_ptr, "p");
+	DUMP(p, mc_kstack, "p");
+	DUMP(p, crit_kstack, "p");
+	DUMP(p, dbg_kstack, "p");
+#endif
 	DUMP(p, __current, "p");
 	DUMP(p, kstack, "lx");
 	DUMP(p, stab_rr, "lx");
@@ -2131,7 +2164,27 @@ static void dump_one_paca(int cpu)
 	DUMP(p, io_sync, "x");
 	DUMP(p, irq_work_pending, "x");
 	DUMP(p, nap_state_lost, "x");
+	DUMP(p, sprg_vdso, "llx");
+
+#ifdef CONFIG_PPC_TRANSACTIONAL_MEM
+	DUMP(p, tm_scratch, "llx");
+#endif
+
+#ifdef CONFIG_PPC_POWERNV
+	DUMP(p, core_idle_state_ptr, "p");
+	DUMP(p, thread_idle_state, "x");
+	DUMP(p, thread_mask, "x");
+	DUMP(p, subcore_sibling_mask, "x");
+#endif
 
+	DUMP(p, user_time, "llx");
+	DUMP(p, system_time, "llx");
+	DUMP(p, user_time_scaled, "llx");
+	DUMP(p, starttime, "llx");
+	DUMP(p, starttime_user, "llx");
+	DUMP(p, startspurr, "llx");
+	DUMP(p, utime_sspurr, "llx");
+	DUMP(p, stolen_time, "llx");
 #undef DUMP
 
 	catch_memory_errors = 0;

commit 0c23a88ccc32db31c31677d70e37b49ef3ae9ed9
Author: Sam bobroff <sam.bobroff@au1.ibm.com>
Date:   Thu Oct 8 11:50:24 2015 +1100

    powerpc/xmon: Paginate kernel log buffer display
    
    The kernel log buffer is often much longer than the size of a terminal
    so paginate it's output.
    
    Signed-off-by: Sam Bobroff <sam.bobroff@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index f829baf45fd7..bf8f49a8b3a7 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -242,9 +242,7 @@ Commands:\n\
 "  u	dump TLB\n"
 #endif
 "  ?	help\n"
-#ifdef CONFIG_PPC64
-"  # n	limit output to n lines per page (dump paca only)\n"
-#endif
+"  # n	limit output to n lines per page (for dp, dpa, dl)\n"
 "  zr	reboot\n\
   zh	halt\n"
 ;
@@ -2333,10 +2331,12 @@ dump_log_buf(void)
 	sync();
 
 	kmsg_dump_rewind_nolock(&dumper);
+	xmon_start_pagination();
 	while (kmsg_dump_get_line_nolock(&dumper, false, buf, sizeof(buf), &len)) {
 		buf[len] = '\0';
 		printf("%s", buf);
 	}
+	xmon_end_pagination();
 
 	sync();
 	/* wait a little while to see if we get a machine check */

commit 958b7c80507a6eb847777b0d6d99d2cad08c529c
Author: Sam bobroff <sam.bobroff@au1.ibm.com>
Date:   Thu Oct 8 11:50:23 2015 +1100

    powerpc/xmon: Paged output for paca display
    
    The paca display is already more than 24 lines, which can be problematic
    if you have an old school 80x24 terminal, or more likely you are on a
    virtual terminal which does not scroll for whatever reason.
    
    This patch adds a new command "#", which takes a single (hex) numeric
    argument: lines per page. It will cause the output of "dp" and "dpa"
    to be broken into pages, if necessary.
    
    Sample output:
    
    0:mon> # 10
    0:mon> dp1
    paca for cpu 0x1 @ c00000000fdc0480:
     possible         = yes
     present          = yes
     online           = yes
     lock_token       = 0x8000              (0x8)
     paca_index       = 0x1                 (0xa)
     kernel_toc       = 0xc000000000eb2400  (0x10)
     kernelbase       = 0xc000000000000000  (0x18)
     kernel_msr       = 0xb000000000001032  (0x20)
     emergency_sp     = 0xc00000003ffe8000  (0x28)
     mc_emergency_sp  = 0xc00000003ffe4000  (0x2e0)
     in_mce           = 0x0                 (0x2e8)
     data_offset      = 0x7f170000          (0x30)
     hw_cpu_id        = 0x8                 (0x38)
     cpu_start        = 0x1                 (0x3a)
     kexec_state      = 0x0                 (0x3b)
    [Hit a key (a:all, q:truncate, any:next page)]
    0:mon>
     __current        = 0xc00000007e696620  (0x290)
     kstack           = 0xc00000007e6ebe30  (0x298)
     stab_rr          = 0xb                 (0x2a0)
     saved_r1         = 0xc00000007ef37860  (0x2a8)
     trap_save        = 0x0                 (0x2b8)
     soft_enabled     = 0x0                 (0x2ba)
     irq_happened     = 0x1                 (0x2bb)
     io_sync          = 0x0                 (0x2bc)
     irq_work_pending = 0x0                 (0x2bd)
     nap_state_lost   = 0x0                 (0x2be)
    0:mon>
    
    Signed-off-by: Sam Bobroff <sam.bobroff@au1.ibm.com>
    [mpe: Use bool, make some variables static]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 6ef1231c6e9c..f829baf45fd7 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -242,6 +242,9 @@ Commands:\n\
 "  u	dump TLB\n"
 #endif
 "  ?	help\n"
+#ifdef CONFIG_PPC64
+"  # n	limit output to n lines per page (dump paca only)\n"
+#endif
 "  zr	reboot\n\
   zh	halt\n"
 ;
@@ -833,6 +836,16 @@ static void remove_cpu_bpts(void)
 	write_ciabr(0);
 }
 
+static void set_lpp_cmd(void)
+{
+	unsigned long lpp;
+
+	if (!scanhex(&lpp)) {
+		printf("Invalid number.\n");
+		lpp = 0;
+	}
+	xmon_set_pagination_lpp(lpp);
+}
 /* Command interpreting routine */
 static char *last_cmd;
 
@@ -924,6 +937,9 @@ cmds(struct pt_regs *excp)
 		case '?':
 			xmon_puts(help_string);
 			break;
+		case '#':
+			set_lpp_cmd();
+			break;
 		case 'b':
 			bpt_cmds();
 			break;
@@ -2166,7 +2182,9 @@ dump(void)
 
 #ifdef CONFIG_PPC64
 	if (c == 'p') {
+		xmon_start_pagination();
 		dump_pacas();
+		xmon_end_pagination();
 		return;
 	}
 #endif

commit 8218a3031c204b20582ba689aaf3bb6d318779d3
Author: Anshuman Khandual <khandual@linux.vnet.ibm.com>
Date:   Wed Jul 29 12:40:04 2015 +0530

    powerpc/xmon: Drop the valid variable completely in dump_segments()
    
    The value of 'valid' is always zero when 'esid' is zero, and if 'esid'
    is non-zero then the value of 'valid' is irrelevant because we are using
    logical or in the if expression.
    
    In fact 'valid' can be dropped completely from dump_segments() by
    simply doing the check with SLB_ESID_V directly in the if.
    
    Signed-off-by: Anshuman Khandual <khandual@linux.vnet.ibm.com>
    [mpe: Rewrite change log]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 7a39f6cb8a3d..6ef1231c6e9c 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2730,7 +2730,7 @@ static void xmon_print_symbol(unsigned long address, const char *mid,
 void dump_segments(void)
 {
 	int i;
-	unsigned long esid,vsid,valid;
+	unsigned long esid,vsid;
 	unsigned long llp;
 
 	printf("SLB contents of cpu 0x%x\n", smp_processor_id());
@@ -2738,10 +2738,9 @@ void dump_segments(void)
 	for (i = 0; i < mmu_slb_size; i++) {
 		asm volatile("slbmfee  %0,%1" : "=r" (esid) : "r" (i));
 		asm volatile("slbmfev  %0,%1" : "=r" (vsid) : "r" (i));
-		valid = (esid & SLB_ESID_V);
-		if (valid | esid | vsid) {
+		if (esid || vsid) {
 			printf("%02d %016lx %016lx", i, esid, vsid);
-			if (valid) {
+			if (esid & SLB_ESID_V) {
 				llp = vsid & SLB_VSID_LLP;
 				if (vsid & SLB_VSID_B_1T) {
 					printf("  1T  ESID=%9lx  VSID=%13lx LLP:%3lx \n",

commit a825ac078b50266fb09168547752dd73c2fd4b4a
Author: Joe Perches <joe@perches.com>
Date:   Mon Jun 29 14:30:39 2015 -0700

    powerpc: Remove redundant breaks
    
    break; break; isn't useful.
    
    Remove one.
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index e599259d84fc..7a39f6cb8a3d 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1987,7 +1987,6 @@ memex(void)
 			case '^':
 				adrs -= size;
 				break;
-				break;
 			case '/':
 				if (nslash > 0)
 					adrs -= 1 << nslash;

commit d3f180ea1a44aecba1b0dab2a253428e77f906bf
Merge: 6b00f7efb530 a6130ed253a9
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Feb 11 18:15:38 2015 -0800

    Merge tag 'powerpc-3.20-1' of git://git.kernel.org/pub/scm/linux/kernel/git/mpe/linux
    
    Pull powerpc updates from Michael Ellerman:
    
     - Update of all defconfigs
    
     - Addition of a bunch of config options to modernise our defconfigs
    
     - Some PS3 updates from Geoff
    
     - Optimised memcmp for 64 bit from Anton
    
     - Fix for kprobes that allows 'perf probe' to work from Naveen
    
     - Several cxl updates from Ian & Ryan
    
     - Expanded support for the '24x7' PMU from Cody & Sukadev
    
     - Freescale updates from Scott:
        "Highlights include 8xx optimizations, some more work on datapath
         device tree content, e300 machine check support, t1040 corenet
         error reporting, and various cleanups and fixes"
    
    * tag 'powerpc-3.20-1' of git://git.kernel.org/pub/scm/linux/kernel/git/mpe/linux: (102 commits)
      cxl: Add missing return statement after handling AFU errror
      cxl: Fail AFU initialisation if an invalid configuration record is found
      cxl: Export optional AFU configuration record in sysfs
      powerpc/mm: Warn on flushing tlb page in kernel context
      powerpc/powernv: Add OPAL soft-poweroff routine
      powerpc/perf/hv-24x7: Document sysfs event description entries
      powerpc/perf/hv-gpci: add the remaining gpci requests
      powerpc/perf/{hv-gpci, hv-common}: generate requests with counters annotated
      powerpc/perf/hv-24x7: parse catalog and populate sysfs with events
      perf: define EVENT_DEFINE_RANGE_FORMAT_LITE helper
      perf: add PMU_EVENT_ATTR_STRING() helper
      perf: provide sysfs_show for struct perf_pmu_events_attr
      powerpc/kernel: Avoid initializing device-tree pointer twice
      powerpc: Remove old compile time disabled syscall tracing code
      powerpc/kernel: Make syscall_exit a local label
      cxl: Fix device_node reference counting
      powerpc/mm: bail out early when flushing TLB page
      powerpc: defconfigs: add MTD_SPI_NOR (new dependency for M25P80)
      perf/powerpc: reset event hw state when adding it to the PMU
      powerpc/qe: Use strlcpy()
      ...

commit e6eb2eba494d6f99e69ca3c3748cd37a2544ab38
Author: Laurent Dufour <ldufour@linux.vnet.ibm.com>
Date:   Thu Jan 15 18:23:47 2015 +0100

    powerpc/xmon: Fix another endiannes issue in RTAS call from xmon
    
    The commit 3b8a3c010969 ("powerpc/pseries: Fix endiannes issue in RTAS
    call from xmon") was fixing an endianness issue in the call made from
    xmon to RTAS.
    
    However, as Michael Ellerman noticed, this fix was not complete, the
    token value was not byte swapped. This lead to call an unexpected and
    most of the time unexisting RTAS function, which is silently ignored by
    RTAS.
    
    This fix addresses this hole.
    
    Reported-by: Michael Ellerman <mpe@ellerman.id.au>
    Cc: stable@vger.kernel.org
    Signed-off-by: Laurent Dufour <ldufour@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 5b150f0c5df9..13c6e200b24e 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -337,6 +337,7 @@ static inline void disable_surveillance(void)
 	args.token = rtas_token("set-indicator");
 	if (args.token == RTAS_UNKNOWN_SERVICE)
 		return;
+	args.token = cpu_to_be32(args.token);
 	args.nargs = cpu_to_be32(3);
 	args.nret = cpu_to_be32(1);
 	args.rets = &args.args[3];

commit 05b981f493e07856371ecd4a9294f187f5b50cf6
Author: Vincent Bernat <vincent@bernat.im>
Date:   Tue Jul 15 13:43:47 2014 +0200

    powerpc/xmon: use isspace/isxdigit/isalnum from linux/ctype.h
    
    isxdigit() macro definition is the same.
    
    isalnum() from linux/ctype.h will accept additional latin non-ASCII
    characters. This is harmless since this macro is used in scanhex() which
    parses user input.
    
    isspace() from linux/ctype.h will accept vertical tab and form feed but
    not NULL. The use of this macro is modified to accept NULL as
    well. Additional characters are harmless since this macro is also only
    used in scanhex().
    
    Signed-off-by: Vincent Bernat <vincent@bernat.im>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 5b150f0c5df9..e66ace703a69 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -25,6 +25,7 @@
 #include <linux/irq.h>
 #include <linux/bug.h>
 #include <linux/nmi.h>
+#include <linux/ctype.h>
 
 #include <asm/ptrace.h>
 #include <asm/string.h>
@@ -183,14 +184,6 @@ extern void xmon_leave(void);
 #define GETWORD(v)	(((v)[0] << 24) + ((v)[1] << 16) + ((v)[2] << 8) + (v)[3])
 #endif
 
-#define isxdigit(c)	(('0' <= (c) && (c) <= '9') \
-			 || ('a' <= (c) && (c) <= 'f') \
-			 || ('A' <= (c) && (c) <= 'F'))
-#define isalnum(c)	(('0' <= (c) && (c) <= '9') \
-			 || ('a' <= (c) && (c) <= 'z') \
-			 || ('A' <= (c) && (c) <= 'Z'))
-#define isspace(c)	(c == ' ' || c == '\t' || c == 10 || c == 13 || c == 0)
-
 static char *help_string = "\
 Commands:\n\
   b	show breakpoints\n\
@@ -2164,9 +2157,6 @@ static void dump_pacas(void)
 }
 #endif
 
-#define isxdigit(c)	(('0' <= (c) && (c) <= '9') \
-			 || ('a' <= (c) && (c) <= 'f') \
-			 || ('A' <= (c) && (c) <= 'F'))
 static void
 dump(void)
 {
@@ -2569,7 +2559,7 @@ scanhex(unsigned long *vp)
 		int i;
 		for (i=0; i<63; i++) {
 			c = inchar();
-			if (isspace(c)) {
+			if (isspace(c) || c == '\0') {
 				termch = c;
 				break;
 			}

commit 140cd7fb04a4a2bc09a30980bc8104cc89e09330
Merge: 27afc5dbda52 56548fc0e86c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Dec 11 17:48:14 2014 -0800

    Merge tag 'powerpc-3.19-1' of git://git.kernel.org/pub/scm/linux/kernel/git/mpe/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Some nice cleanups like removing bootmem, and removal of
      __get_cpu_var().
    
      There is one patch to mm/gup.c.  This is the generic GUP
      implementation, but is only used by us and arm(64).  We have an ack
      from Steve Capper, and although we didn't get an ack from Andrew he
      told us to take the patch through the powerpc tree.
    
      There's one cxl patch.  This is in drivers/misc, but Greg said he was
      happy for us to manage fixes for it.
    
      There is an infrastructure patch to support an IPMI driver for OPAL.
    
      There is also an RTC driver for OPAL.  We weren't able to get any
      response from the RTC maintainer, Alessandro Zummo, so in the end we
      just merged the driver.
    
      The usual batch of Freescale updates from Scott"
    
    * tag 'powerpc-3.19-1' of git://git.kernel.org/pub/scm/linux/kernel/git/mpe/linux: (101 commits)
      powerpc/powernv: Return to cpu offline loop when finished in KVM guest
      powerpc/book3s: Fix partial invalidation of TLBs in MCE code.
      powerpc/mm: don't do tlbie for updatepp request with NO HPTE fault
      powerpc/xmon: Cleanup the breakpoint flags
      powerpc/xmon: Enable HW instruction breakpoint on POWER8
      powerpc/mm/thp: Use tlbiel if possible
      powerpc/mm/thp: Remove code duplication
      powerpc/mm/hugetlb: Sanity check gigantic hugepage count
      powerpc/oprofile: Disable pagefaults during user stack read
      powerpc/mm: Check for matching hpte without taking hpte lock
      powerpc: Drop useless warning in eeh_init()
      powerpc/powernv: Cleanup unused MCE definitions/declarations.
      powerpc/eeh: Dump PHB diag-data early
      powerpc/eeh: Recover EEH error on ownership change for BCM5719
      powerpc/eeh: Set EEH_PE_RESET on PE reset
      powerpc/eeh: Refactor eeh_reset_pe()
      powerpc: Remove more traces of bootmem
      powerpc/pseries: Initialise nvram_pstore_info's buf_lock
      cxl: Name interrupts in /proc/interrupt
      cxl: Return error to PSL if IRQ demultiplexing fails & print clearer warning
      ...

commit abb90ee7bca5af977b90a0c6be44f631fdacc932
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Mon Dec 1 16:54:13 2014 +1100

    powerpc/xmon: Cleanup the breakpoint flags
    
    Drop BP_IABR_TE, which though used, does not do anything useful. Rename
    BP_IABR to BP_CIABR. Renumber the flags.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 820dc135f040..dfe337238699 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -94,10 +94,9 @@ struct bpt {
 };
 
 /* Bits in bpt.enabled */
-#define BP_IABR_TE	1		/* IABR translation enabled */
-#define BP_IABR		2
-#define BP_TRAP		8
-#define BP_DABR		0x10
+#define BP_CIABR	1
+#define BP_TRAP		2
+#define BP_DABR		4
 
 #define NBPTS	256
 static struct bpt bpts[NBPTS];
@@ -772,7 +771,7 @@ static void insert_bpts(void)
 
 	bp = bpts;
 	for (i = 0; i < NBPTS; ++i, ++bp) {
-		if ((bp->enabled & (BP_TRAP|BP_IABR)) == 0)
+		if ((bp->enabled & (BP_TRAP|BP_CIABR)) == 0)
 			continue;
 		if (mread(bp->address, &bp->instr[0], 4) != 4) {
 			printf("Couldn't read instruction at %lx, "
@@ -787,7 +786,7 @@ static void insert_bpts(void)
 			continue;
 		}
 		store_inst(&bp->instr[0]);
-		if (bp->enabled & BP_IABR)
+		if (bp->enabled & BP_CIABR)
 			continue;
 		if (mwrite(bp->address, &bpinstr, 4) != 4) {
 			printf("Couldn't write instruction at %lx, "
@@ -822,7 +821,7 @@ static void remove_bpts(void)
 
 	bp = bpts;
 	for (i = 0; i < NBPTS; ++i, ++bp) {
-		if ((bp->enabled & (BP_TRAP|BP_IABR)) != BP_TRAP)
+		if ((bp->enabled & (BP_TRAP|BP_CIABR)) != BP_TRAP)
 			continue;
 		if (mread(bp->address, &instr, 4) == 4
 		    && instr == bpinstr
@@ -1217,7 +1216,7 @@ bpt_cmds(void)
 			break;
 		}
 		if (iabr) {
-			iabr->enabled &= ~(BP_IABR | BP_IABR_TE);
+			iabr->enabled &= ~BP_CIABR;
 			iabr = NULL;
 		}
 		if (!scanhex(&a))
@@ -1226,7 +1225,7 @@ bpt_cmds(void)
 			break;
 		bp = new_breakpoint(a);
 		if (bp != NULL) {
-			bp->enabled |= BP_IABR | BP_IABR_TE;
+			bp->enabled |= BP_CIABR;
 			iabr = bp;
 		}
 		break;
@@ -1283,7 +1282,7 @@ bpt_cmds(void)
 				if (!bp->enabled)
 					continue;
 				printf("%2x %s   ", BP_NUM(bp),
-				    (bp->enabled & BP_IABR)? "inst": "trap");
+				    (bp->enabled & BP_CIABR) ? "inst": "trap");
 				xmon_print_symbol(bp->address, "  ", "\n");
 			}
 			break;

commit 1ad7d70562eeb14df8b6d3e1a0a56f1bdfb990f7
Author: Anshuman Khandual <khandual@linux.vnet.ibm.com>
Date:   Fri Nov 28 10:06:42 2014 +0530

    powerpc/xmon: Enable HW instruction breakpoint on POWER8
    
    This patch enables support for hardware instruction breakpoint in xmon
    on POWER8 platform with the help of a new register called the CIABR
    (Completed Instruction Address Breakpoint Register). With this patch, a
    single hardware instruction breakpoint can be added and cleared during
    any active xmon debug session. The hardware based instruction breakpoint
    mechanism works correctly with the existing TRAP based instruction
    breakpoint available on xmon.
    
    There are no powerpc CPU with CPU_FTR_IABR feature any more. This patch
    has re-purposed all the existing IABR related code to work with CIABR
    register based HW instruction breakpoint.
    
    This has one odd feature, which is that when we hit a breakpoint xmon
    doesn't tell us we have hit the breakpoint. This is because xmon is
    expecting bp->address == regs->nip. Because CIABR fires on completition
    regs->nip points to the instruction after the breakpoint. We could fix
    that, but it would then confuse other parts of the xmon code which think
    we need to emulate the instruction. [mpe]
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Anshuman Khandual <khandual@linux.vnet.ibm.com>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index ef18021d52e1..820dc135f040 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -51,6 +51,12 @@
 #include <asm/paca.h>
 #endif
 
+#if defined(CONFIG_PPC_SPLPAR)
+#include <asm/plpar_wrappers.h>
+#else
+static inline long plapr_set_ciabr(unsigned long ciabr) {return 0; };
+#endif
+
 #include "nonstdio.h"
 #include "dis-asm.h"
 
@@ -270,6 +276,45 @@ static inline void cinval(void *p)
 	asm volatile ("dcbi 0,%0; icbi 0,%0" : : "r" (p));
 }
 
+/**
+ * write_ciabr() - write the CIABR SPR
+ * @ciabr:	The value to write.
+ *
+ * This function writes a value to the CIARB register either directly
+ * through mtspr instruction if the kernel is in HV privilege mode or
+ * call a hypervisor function to achieve the same in case the kernel
+ * is in supervisor privilege mode.
+ */
+static void write_ciabr(unsigned long ciabr)
+{
+	if (!cpu_has_feature(CPU_FTR_ARCH_207S))
+		return;
+
+	if (cpu_has_feature(CPU_FTR_HVMODE)) {
+		mtspr(SPRN_CIABR, ciabr);
+		return;
+	}
+	plapr_set_ciabr(ciabr);
+}
+
+/**
+ * set_ciabr() - set the CIABR
+ * @addr:	The value to set.
+ *
+ * This function sets the correct privilege value into the the HW
+ * breakpoint address before writing it up in the CIABR register.
+ */
+static void set_ciabr(unsigned long addr)
+{
+	addr &= ~CIABR_PRIV;
+
+	if (cpu_has_feature(CPU_FTR_HVMODE))
+		addr |= CIABR_PRIV_HYPER;
+	else
+		addr |= CIABR_PRIV_SUPER;
+	write_ciabr(addr);
+}
+
 /*
  * Disable surveillance (the service processor watchdog function)
  * while we are in xmon.
@@ -764,9 +809,9 @@ static void insert_cpu_bpts(void)
 		brk.len = 8;
 		__set_breakpoint(&brk);
 	}
-	if (iabr && cpu_has_feature(CPU_FTR_IABR))
-		mtspr(SPRN_IABR, iabr->address
-			 | (iabr->enabled & (BP_IABR|BP_IABR_TE)));
+
+	if (iabr)
+		set_ciabr(iabr->address);
 }
 
 static void remove_bpts(void)
@@ -792,8 +837,7 @@ static void remove_bpts(void)
 static void remove_cpu_bpts(void)
 {
 	hw_breakpoint_disable();
-	if (cpu_has_feature(CPU_FTR_IABR))
-		mtspr(SPRN_IABR, 0);
+	write_ciabr(0);
 }
 
 /* Command interpreting routine */
@@ -1128,7 +1172,7 @@ static char *breakpoint_help_string =
     "b <addr> [cnt]   set breakpoint at given instr addr\n"
     "bc               clear all breakpoints\n"
     "bc <n/addr>      clear breakpoint number n or at addr\n"
-    "bi <addr> [cnt]  set hardware instr breakpoint (POWER3/RS64 only)\n"
+    "bi <addr> [cnt]  set hardware instr breakpoint (POWER8 only)\n"
     "bd <addr> [cnt]  set hardware data breakpoint\n"
     "";
 
@@ -1167,7 +1211,7 @@ bpt_cmds(void)
 		break;
 
 	case 'i':	/* bi - hardware instr breakpoint */
-		if (!cpu_has_feature(CPU_FTR_IABR)) {
+		if (!cpu_has_feature(CPU_FTR_ARCH_207S)) {
 			printf("Hardware instruction breakpoint "
 			       "not supported on this cpu\n");
 			break;

commit 3b8a3c01096925a824ed3272601082289d9c23a5
Author: Laurent Dufour <ldufour@linux.vnet.ibm.com>
Date:   Mon Nov 24 15:07:53 2014 +0100

    powerpc/pseries: Fix endiannes issue in RTAS call from xmon
    
    On pseries system (LPAR) xmon failed to enter when running in LE mode,
    system is hunging. Inititating xmon will lead to such an output on the
    console:
    
    SysRq : Entering xmon
    cpu 0x15: Vector: 0  at [c0000003f39ffb10]
        pc: c00000000007ed7c: sysrq_handle_xmon+0x5c/0x70
        lr: c00000000007ed7c: sysrq_handle_xmon+0x5c/0x70
        sp: c0000003f39ffc70
       msr: 8000000000009033
      current = 0xc0000003fafa7180
      paca    = 0xc000000007d75e80   softe: 0        irq_happened: 0x01
        pid   = 14617, comm = bash
    Bad kernel stack pointer fafb4b0 at eca7cc4
    cpu 0x15: Vector: 300 (Data Access) at [c000000007f07d40]
        pc: 000000000eca7cc4
        lr: 000000000eca7c44
        sp: fafb4b0
       msr: 8000000000001000
       dar: 10000000
     dsisr: 42000000
      current = 0xc0000003fafa7180
      paca    = 0xc000000007d75e80   softe: 0        irq_happened: 0x01
        pid   = 14617, comm = bash
    cpu 0x15: Exception 300 (Data Access) in xmon, returning to main loop
    xmon: WARNING: bad recursive fault on cpu 0x15
    
    The root cause is that xmon is calling RTAS to turn off the surveillance
    when entering xmon, and RTAS is requiring big endian parameters.
    
    This patch is byte swapping the RTAS arguments when running in LE mode.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Laurent Dufour <ldufour@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index b988b5addf86..c8efbb37d6e0 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -293,10 +293,10 @@ static inline void disable_surveillance(void)
 	args.token = rtas_token("set-indicator");
 	if (args.token == RTAS_UNKNOWN_SERVICE)
 		return;
-	args.nargs = 3;
-	args.nret = 1;
+	args.nargs = cpu_to_be32(3);
+	args.nret = cpu_to_be32(1);
 	args.rets = &args.args[3];
-	args.args[0] = SURVEILLANCE_TOKEN;
+	args.args[0] = cpu_to_be32(SURVEILLANCE_TOKEN);
 	args.args[1] = 0;
 	args.args[2] = 0;
 	enter_rtas(__pa(&args));

commit d8ee6f34fdd28ade6b7b3a9be175bc5c0c3cfb38
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Nov 12 16:54:54 2014 +1100

    powerpc/xmon: Fix build when 4xx=y and 44x=n
    
    dump_tlb_44x() is only defined when 44x=y, but the ifdef in xmon.c
    checks for 4xx, leading to a build failure:
    
      arch/powerpc/xmon/xmon.c:912:4: error: implicit declaration of function 'dump_tlb_44x'
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 506d25681fe3..ef18021d52e1 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -907,7 +907,7 @@ cmds(struct pt_regs *excp)
 		case 'u':
 			dump_segments();
 			break;
-#elif defined(CONFIG_4xx)
+#elif defined(CONFIG_44x)
 		case 'u':
 			dump_tlb_44x();
 			break;

commit 9178ba294b6839eeff1a91bed95515d783f3ee6c
Author: Alexander Graf <agraf@suse.de>
Date:   Mon Oct 13 16:01:09 2014 +0200

    powerpc: Convert power off logic to pm_power_off
    
    The generic Linux framework to power off the machine is a function pointer
    called pm_power_off. The trick about this pointer is that device drivers can
    potentially implement it rather than board files.
    
    Today on powerpc we set pm_power_off to invoke our generic full machine power
    off logic which then calls ppc_md.power_off to invoke machine specific power
    off.
    
    However, when we want to add a power off GPIO via the "gpio-poweroff" driver,
    this card house falls apart. That driver only registers itself if pm_power_off
    is NULL to ensure it doesn't override board specific logic. However, since we
    always set pm_power_off to the generic power off logic (which will just not
    power off the machine if no ppc_md.power_off call is implemented), we can't
    implement power off via the generic GPIO power off driver.
    
    To fix this up, let's get rid of the ppc_md.power_off logic and just always use
    pm_power_off as was intended. Then individual drivers such as the GPIO power off
    driver can implement power off logic via that function pointer.
    
    With this patch set applied and a few patches on top of QEMU that implement a
    power off GPIO on the virt e500 machine, I can successfully turn off my virtual
    machine after halt.
    
    Signed-off-by: Alexander Graf <agraf@suse.de>
    [mpe: Squash into one patch and update changelog based on cover letter]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index b988b5addf86..506d25681fe3 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -981,7 +981,8 @@ static void bootcmds(void)
 	else if (cmd == 'h')
 		ppc_md.halt();
 	else if (cmd == 'p')
-		ppc_md.power_off();
+		if (pm_power_off)
+			pm_power_off();
 }
 
 static int cpu_cmd(void)

commit a71d64b4dc4067808549935583d984c7fc9ea647
Author: Anton Blanchard <anton@samba.org>
Date:   Tue Aug 5 14:55:00 2014 +1000

    powerpc: Hard disable interrupts in xmon
    
    xmon only soft disables interrupts. This seems like a bad idea - we
    certainly don't want decrementer and PMU exceptions going off when
    we are debugging something inside xmon.
    
    This issue was uncovered when the hard lockup detector went off
    inside xmon. To ensure we wont get a spurious hard lockup warning,
    I also call touch_nmi_watchdog() when exiting xmon.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 8d198b5e9e0a..b988b5addf86 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -24,6 +24,7 @@
 #include <linux/interrupt.h>
 #include <linux/irq.h>
 #include <linux/bug.h>
+#include <linux/nmi.h>
 
 #include <asm/ptrace.h>
 #include <asm/string.h>
@@ -374,6 +375,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 #endif
 
 	local_irq_save(flags);
+	hard_irq_disable();
 
 	bp = in_breakpoint_table(regs->nip, &offset);
 	if (bp != NULL) {
@@ -558,6 +560,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 #endif
 	insert_cpu_bpts();
 
+	touch_nmi_watchdog();
 	local_irq_restore(flags);
 
 	return cmd != 'X' && cmd != EOF;

commit 13b3d13b813ab834fac67dc05f8b86dbcc29c134
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Jul 10 12:29:20 2014 +1000

    powerpc: Remove MMU_FTR_SLB
    
    We now only support cpus that use an SLB, so we don't need an MMU
    feature to indicate that.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index dc8cf285c3ff..8d198b5e9e0a 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2690,7 +2690,7 @@ static void xmon_print_symbol(unsigned long address, const char *mid,
 }
 
 #ifdef CONFIG_PPC_BOOK3S_64
-static void dump_slb(void)
+void dump_segments(void)
 {
 	int i;
 	unsigned long esid,vsid,valid;
@@ -2722,12 +2722,6 @@ static void dump_slb(void)
 		}
 	}
 }
-
-void dump_segments(void)
-{
-	if (mmu_has_feature(MMU_FTR_SLB))
-		dump_slb();
-}
 #endif
 
 #ifdef CONFIG_PPC_STD_MMU_32

commit 376af5947c0e441ccbf98f0212d4ffbf171528f6
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Jul 10 12:29:19 2014 +1000

    powerpc: Remove STAB code
    
    Old cpus didn't have a Segment Lookaside Buffer (SLB), instead they had
    a Segment Table (STAB). Now that we've dropped support for those cpus,
    we can remove the STAB support entirely.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index d199bfa2f1fa..dc8cf285c3ff 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2058,10 +2058,6 @@ static void dump_one_paca(int cpu)
 	DUMP(p, kernel_toc, "lx");
 	DUMP(p, kernelbase, "lx");
 	DUMP(p, kernel_msr, "lx");
-#ifdef CONFIG_PPC_STD_MMU_64
-	DUMP(p, stab_real, "lx");
-	DUMP(p, stab_addr, "lx");
-#endif
 	DUMP(p, emergency_sp, "p");
 #ifdef CONFIG_PPC_BOOK3S_64
 	DUMP(p, mc_emergency_sp, "p");
@@ -2727,32 +2723,10 @@ static void dump_slb(void)
 	}
 }
 
-static void dump_stab(void)
-{
-	int i;
-	unsigned long *tmp = (unsigned long *)local_paca->stab_addr;
-
-	printf("Segment table contents of cpu 0x%x\n", smp_processor_id());
-
-	for (i = 0; i < PAGE_SIZE/16; i++) {
-		unsigned long a, b;
-
-		a = *tmp++;
-		b = *tmp++;
-
-		if (a || b) {
-			printf("%03d %016lx ", i, a);
-			printf("%016lx\n", b);
-		}
-	}
-}
-
 void dump_segments(void)
 {
 	if (mmu_has_feature(MMU_FTR_SLB))
 		dump_slb();
-	else
-		dump_stab();
 }
 #endif
 

commit 736256e4f1bc50bb8198c9b61dffd5fd0de17477
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Mon May 26 21:02:14 2014 +1000

    powerpc/xmon: Fix up xmon format strings
    
    There are a couple of places where xmon is using %x to print values that
    are unsigned long.
    
    I found this out the hard way recently:
    
     0:mon> p c000000000d0e7c8 c00000033dc90000 00000000a0000089 c000000000000000
     return value is 0x96300500
    
    Which is calling find_linux_pte_or_hugepte(), the result should be a
    kernel pointer. After decoding the page tables by hand I discovered the
    correct value was c000000396300500.
    
    So fix up that case and a few others.
    
    We also use a mix of 0x%x, %x and %u to print cpu numbers. So
    standardise on 0x%x.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index d3759b7a5535..d199bfa2f1fa 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -419,7 +419,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 		get_output_lock();
 		excprint(regs);
 		if (bp) {
-			printf("cpu 0x%x stopped at breakpoint 0x%x (",
+			printf("cpu 0x%x stopped at breakpoint 0x%lx (",
 			       cpu, BP_NUM(bp));
 			xmon_print_symbol(regs->nip, " ", ")\n");
 		}
@@ -513,7 +513,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 		excprint(regs);
 		bp = at_breakpoint(regs->nip);
 		if (bp) {
-			printf("Stopped at breakpoint %x (", BP_NUM(bp));
+			printf("Stopped at breakpoint %lx (", BP_NUM(bp));
 			xmon_print_symbol(regs->nip, " ", ")\n");
 		}
 		if (unrecoverable_excp(regs))
@@ -997,14 +997,14 @@ static int cpu_cmd(void)
 					last_cpu = cpu;
 				} else {
 					if (last_cpu != first_cpu)
-						printf("-%lx", last_cpu);
+						printf("-0x%lx", last_cpu);
 					last_cpu = first_cpu = cpu;
-					printf(" %lx", cpu);
+					printf(" 0x%lx", cpu);
 				}
 			}
 		}
 		if (last_cpu != first_cpu)
-			printf("-%lx", last_cpu);
+			printf("-0x%lx", last_cpu);
 		printf("\n");
 		return 0;
 	}
@@ -1024,7 +1024,7 @@ static int cpu_cmd(void)
 			/* take control back */
 			mb();
 			xmon_owner = smp_processor_id();
-			printf("cpu %u didn't take control\n", cpu);
+			printf("cpu 0x%x didn't take control\n", cpu);
 			return 0;
 		}
 		barrier();
@@ -1086,7 +1086,7 @@ csum(void)
 	fcs = 0xffff;
 	for (i = 0; i < ncsum; ++i) {
 		if (mread(adrs+i, &v, 1) == 0) {
-			printf("csum stopped at %x\n", adrs+i);
+			printf("csum stopped at "REG"\n", adrs+i);
 			break;
 		}
 		fcs = FCS(fcs, v);
@@ -1202,12 +1202,12 @@ bpt_cmds(void)
 			/* assume a breakpoint address */
 			bp = at_breakpoint(a);
 			if (bp == NULL) {
-				printf("No breakpoint at %x\n", a);
+				printf("No breakpoint at %lx\n", a);
 				break;
 			}
 		}
 
-		printf("Cleared breakpoint %x (", BP_NUM(bp));
+		printf("Cleared breakpoint %lx (", BP_NUM(bp));
 		xmon_print_symbol(bp->address, " ", ")\n");
 		bp->enabled = 0;
 		break;
@@ -1746,7 +1746,7 @@ mwrite(unsigned long adrs, void *buf, int size)
 		__delay(200);
 		n = size;
 	} else {
-		printf("*** Error writing address %x\n", adrs + n);
+		printf("*** Error writing address "REG"\n", adrs + n);
 	}
 	catch_memory_errors = 0;
 	return n;
@@ -2435,7 +2435,7 @@ static void proccall(void)
 		ret = func(args[0], args[1], args[2], args[3],
 			   args[4], args[5], args[6], args[7]);
 		sync();
-		printf("return value is %x\n", ret);
+		printf("return value is 0x%lx\n", ret);
 	} else {
 		printf("*** %x exception occurred\n", fault_except);
 	}
@@ -2700,7 +2700,7 @@ static void dump_slb(void)
 	unsigned long esid,vsid,valid;
 	unsigned long llp;
 
-	printf("SLB contents of cpu %x\n", smp_processor_id());
+	printf("SLB contents of cpu 0x%x\n", smp_processor_id());
 
 	for (i = 0; i < mmu_slb_size; i++) {
 		asm volatile("slbmfee  %0,%1" : "=r" (esid) : "r" (i));
@@ -2732,7 +2732,7 @@ static void dump_stab(void)
 	int i;
 	unsigned long *tmp = (unsigned long *)local_paca->stab_addr;
 
-	printf("Segment table contents of cpu %x\n", smp_processor_id());
+	printf("Segment table contents of cpu 0x%x\n", smp_processor_id());
 
 	for (i = 0; i < PAGE_SIZE/16; i++) {
 		unsigned long a, b;

commit 21f585073d6347651f2262da187606fa1c4ee16d
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Tue Apr 29 15:25:17 2014 -0400

    powerpc: Fix smp_processor_id() in preemptible splat in set_breakpoint
    
    Currently, on 8641D, which doesn't set CONFIG_HAVE_HW_BREAKPOINT
    we get the following splat:
    
    BUG: using smp_processor_id() in preemptible [00000000] code: login/1382
    caller is set_breakpoint+0x1c/0xa0
    CPU: 0 PID: 1382 Comm: login Not tainted 3.15.0-rc3-00041-g2aafe1a4d451 #1
    Call Trace:
    [decd5d80] [c0008dc4] show_stack+0x50/0x158 (unreliable)
    [decd5dc0] [c03c6fa0] dump_stack+0x7c/0xdc
    [decd5de0] [c01f8818] check_preemption_disabled+0xf4/0x104
    [decd5e00] [c00086b8] set_breakpoint+0x1c/0xa0
    [decd5e10] [c00d4530] flush_old_exec+0x2bc/0x588
    [decd5e40] [c011c468] load_elf_binary+0x2ac/0x1164
    [decd5ec0] [c00d35f8] search_binary_handler+0xc4/0x1f8
    [decd5ef0] [c00d4ee8] do_execve+0x3d8/0x4b8
    [decd5f40] [c001185c] ret_from_syscall+0x0/0x38
     --- Exception: c01 at 0xfeee554
        LR = 0xfeee7d4
    
    The call path in this case is:
    
            flush_thread
               --> set_debug_reg_defaults
                 --> set_breakpoint
                   --> __get_cpu_var
    
    Since preemption is enabled in the cleanup of flush thread, and
    there is no need to disable it, introduce the distinction between
    set_breakpoint and __set_breakpoint, leaving only the flush_thread
    instance as the current user of set_breakpoint.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 08504e75b2c7..d3759b7a5535 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -759,7 +759,7 @@ static void insert_cpu_bpts(void)
 		brk.address = dabr.address;
 		brk.type = (dabr.enabled & HW_BRK_TYPE_DABR) | HW_BRK_TYPE_PRIV_ALL;
 		brk.len = 8;
-		set_breakpoint(&brk);
+		__set_breakpoint(&brk);
 	}
 	if (iabr && cpu_has_feature(CPU_FTR_IABR))
 		mtspr(SPRN_IABR, iabr->address

commit 72eceef67abbe596a4e93ee79e08d9e6c35430ae
Author: Philippe Bergheaud <felix@linux.vnet.ibm.com>
Date:   Mon Dec 2 10:10:12 2013 +0100

    powerpc: Fix xmon disassembler for little-endian
    
    This patch fixes the disassembler of the powerpc kernel debugger xmon,
    for little-endian.
    
    Signed-off-by: Philippe Bergheaud <felix@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index b07909850f77..08504e75b2c7 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -171,7 +171,11 @@ extern void xmon_leave(void);
 #define REG		"%.8lx"
 #endif
 
+#ifdef __LITTLE_ENDIAN__
+#define GETWORD(v)	(((v)[3] << 24) + ((v)[2] << 16) + ((v)[1] << 8) + (v)[0])
+#else
 #define GETWORD(v)	(((v)[0] << 24) + ((v)[1] << 16) + ((v)[2] << 8) + (v)[3])
+#endif
 
 #define isxdigit(c)	(('0' <= (c) && (c) <= '9') \
 			 || ('a' <= (c) && (c) <= 'f') \

commit d2b496e5e1fa7a6796534e435440eb9d3ed184dd
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Mon Dec 23 23:46:06 2013 +1100

    powerpc/xmon: Don't signal we've entered until we're finished printing
    
    Currently we set our cpu's bit in cpus_in_xmon, and then we take the
    output lock and print the exception information.
    
    This can race with the master cpu entering the command loop and printing
    the backtrace. The result is that the backtrace gets garbled with
    another cpu's exception print out.
    
    Fix it by delaying the set of cpus_in_xmon until we are finished
    printing.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index d712b23974ec..b07909850f77 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -404,7 +404,6 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 	}
 
 	xmon_fault_jmp[cpu] = recurse_jmp;
-	cpumask_set_cpu(cpu, &cpus_in_xmon);
 
 	bp = NULL;
 	if ((regs->msr & (MSR_IR|MSR_PR|MSR_64BIT)) == (MSR_IR|MSR_64BIT))
@@ -426,6 +425,8 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 		release_output_lock();
 	}
 
+	cpumask_set_cpu(cpu, &cpus_in_xmon);
+
  waiting:
 	secondary = 1;
 	while (secondary && !xmon_gate) {

commit 1507589787529b0d8e2a9e66e0c6f113ecab5181
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Mon Dec 23 23:46:05 2013 +1100

    powerpc/xmon: Fix timeout loop in get_output_lock()
    
    As far as I can tell, our 70s era timeout loop in get_output_lock() is
    generating no code.
    
    This leads to the hostile takeover happening more or less simultaneously
    on all cpus. The result is "interesting", some example output that is
    more readable than most:
    
        cpu 0x1: Vector: 100 (Scypsut e0mx bR:e setV)e catto xc0p:u[ c 00
        c0:0  000t0o0V0erc0td:o5 rfc28050000]0c00 0 0  0 6t(pSrycsV1ppuot
        uxe 1m 2 0Rx21e3:0s0ce000c00000t00)00 60602oV2SerucSayt0y 0p 1sxs
    
    Fix it by using udelay() in the timeout loop. The wait time and check
    frequency are arbitrary, but seem to work OK. We already rely on
    udelay() working so this is not a new dependency.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 598cdc7c7adc..d712b23974ec 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -315,10 +315,17 @@ static void get_output_lock(void)
 		if (last_speaker == 0)
 			return;
 
-		timeout = 10000000;
+		/*
+		 * Wait a full second for the lock, we might be on a slow
+		 * console, but check every 100us.
+		 */
+		timeout = 10000;
 		while (xmon_speaker == last_speaker) {
-			if (--timeout > 0)
+			if (--timeout > 0) {
+				udelay(100);
 				continue;
+			}
+
 			/* hostile takeover */
 			prev = cmpxchg(&xmon_speaker, last_speaker, me);
 			if (prev == last_speaker)

commit 730efb6193f8568354fd80849612291afa9fa81e
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Mon Dec 23 23:46:04 2013 +1100

    powerpc/xmon: Don't loop forever in get_output_lock()
    
    If we enter with xmon_speaker != 0 we skip the first cmpxchg(), we also
    skip the while loop because xmon_speaker != last_speaker (0) - meaning we
    skip the second cmpxchg() also.
    
    Following that code path the compiler sees no memory barriers and so is
    within its rights to never reload xmon_speaker. The end result is we loop
    forever.
    
    This manifests as all cpus being in xmon ('c' command), but they refuse
    to take control when you switch to them ('c x' for cpu # x).
    
    I have seen this deadlock in practice and also checked the generated code to
    confirm this is what's happening.
    
    The simplest fix is just to always try the cmpxchg().
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index a90731b3d44a..598cdc7c7adc 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -309,12 +309,12 @@ static void get_output_lock(void)
 
 	if (xmon_speaker == me)
 		return;
+
 	for (;;) {
-		if (xmon_speaker == 0) {
-			last_speaker = cmpxchg(&xmon_speaker, 0, me);
-			if (last_speaker == 0)
-				return;
-		}
+		last_speaker = cmpxchg(&xmon_speaker, 0, me);
+		if (last_speaker == 0)
+			return;
+
 		timeout = 10000000;
 		while (xmon_speaker == last_speaker) {
 			if (--timeout > 0)

commit 729b0f715371ce1e7636b4958fc45d6882442456
Author: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
Date:   Wed Oct 30 20:04:00 2013 +0530

    powerpc/book3s: Introduce exclusive emergency stack for machine check exception.
    
    This patch introduces exclusive emergency stack for machine check exception.
    We use emergency stack to handle machine check exception so that we can save
    MCE information (srr1, srr0, dar and dsisr) before turning on ME bit and be
    ready for re-entrancy. This helps us to prevent clobbering of MCE information
    in case of nested machine checks.
    
    The reason for using emergency stack over normal kernel stack is that the
    machine check might occur in the middle of setting up a stack frame which may
    result into improper use of kernel stack.
    
    Signed-off-by: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index af9d3469fb99..a90731b3d44a 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2051,6 +2051,10 @@ static void dump_one_paca(int cpu)
 	DUMP(p, stab_addr, "lx");
 #endif
 	DUMP(p, emergency_sp, "p");
+#ifdef CONFIG_PPC_BOOK3S_64
+	DUMP(p, mc_emergency_sp, "p");
+	DUMP(p, in_mce, "x");
+#endif
 	DUMP(p, data_offset, "lx");
 	DUMP(p, hw_cpu_id, "x");
 	DUMP(p, cpu_start, "x");

commit fd3bb91287b600d8b389c159e8dd96391410087b
Author: Paul Mackerras <paulus@samba.org>
Date:   Tue Sep 3 20:16:23 2013 +1000

    powerpc/xmon: Fix printing of set of CPUs in xmon
    
    Commit 24ec2125f3 ("powerpc/xmon: Use cpumask iterator to avoid warning")
    replaced a loop from 0 to NR_CPUS-1 with a for_each_possible_cpu() loop,
    which means that if the last possible cpu is in xmon, we print the
    wrong value for the end of the range.  For example, if 4 cpus are
    possible, NR_CPUS is 128, and all cpus are in xmon, we print "0-7f"
    rather than "0-3".  The code also assumes that the set of possible
    cpus is contiguous, which may not necessarily be true.
    
    This fixes the code to check explicitly for contiguity, and to print
    the ending value correctly.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 9f3655be695d..af9d3469fb99 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -972,27 +972,27 @@ static void bootcmds(void)
 static int cpu_cmd(void)
 {
 #ifdef CONFIG_SMP
-	unsigned long cpu;
+	unsigned long cpu, first_cpu, last_cpu;
 	int timeout;
-	int count;
 
 	if (!scanhex(&cpu)) {
 		/* print cpus waiting or in xmon */
 		printf("cpus stopped:");
-		count = 0;
+		last_cpu = first_cpu = NR_CPUS;
 		for_each_possible_cpu(cpu) {
 			if (cpumask_test_cpu(cpu, &cpus_in_xmon)) {
-				if (count == 0)
-					printf(" %x", cpu);
-				++count;
-			} else {
-				if (count > 1)
-					printf("-%x", cpu - 1);
-				count = 0;
+				if (cpu == last_cpu + 1) {
+					last_cpu = cpu;
+				} else {
+					if (last_cpu != first_cpu)
+						printf("-%lx", last_cpu);
+					last_cpu = first_cpu = cpu;
+					printf(" %lx", cpu);
+				}
 			}
 		}
-		if (count > 1)
-			printf("-%x", NR_CPUS - 1);
+		if (last_cpu != first_cpu)
+			printf("-%lx", last_cpu);
 		printf("\n");
 		return 0;
 	}

commit 660e034ce167b0954b83fd024c8be02c2911dbc9
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Aug 15 15:22:16 2013 +1000

    powerpc: Add more trap names to xmon
    
    We haven't updated these for a while it seems, it's nice to have in the
    oops output.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 96bf5bd30fbc..9f3655be695d 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1256,11 +1256,18 @@ const char *getvecname(unsigned long vec)
 	case 0x700:	ret = "(Program Check)"; break;
 	case 0x800:	ret = "(FPU Unavailable)"; break;
 	case 0x900:	ret = "(Decrementer)"; break;
+	case 0x980:	ret = "(Hypervisor Decrementer)"; break;
+	case 0xa00:	ret = "(Doorbell)"; break;
 	case 0xc00:	ret = "(System Call)"; break;
 	case 0xd00:	ret = "(Single Step)"; break;
+	case 0xe40:	ret = "(Emulation Assist)"; break;
+	case 0xe60:	ret = "(HMI)"; break;
+	case 0xe80:	ret = "(Hypervisor Doorbell)"; break;
 	case 0xf00:	ret = "(Performance Monitor)"; break;
 	case 0xf20:	ret = "(Altivec Unavailable)"; break;
 	case 0x1300:	ret = "(Instruction Breakpoint)"; break;
+	case 0x1500:	ret = "(Denormalisation)"; break;
+	case 0x1700:	ret = "(Altivec Assist)"; break;
 	default: ret = "";
 	}
 	return ret;

commit 5a148af66932c31814e263366094b5812210b501
Merge: 99c6bcf46d22 54d5999d98f2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu May 2 10:16:16 2013 -0700

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc
    
    Pull powerpc update from Benjamin Herrenschmidt:
     "The main highlights this time around are:
    
       - A pile of addition POWER8 bits and nits, such as updated
         performance counter support (Michael Ellerman), new branch history
         buffer support (Anshuman Khandual), base support for the new PCI
         host bridge when not using the hypervisor (Gavin Shan) and other
         random related bits and fixes from various contributors.
    
       - Some rework of our page table format by Aneesh Kumar which fixes a
         thing or two and paves the way for THP support.  THP itself will
         not make it this time around however.
    
       - More Freescale updates, including Altivec support on the new e6500
         cores, new PCI controller support, and a pile of new boards support
         and updates.
    
       - The usual batch of trivial cleanups & fixes"
    
    * 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc: (156 commits)
      powerpc: Fix build error for book3e
      powerpc: Context switch the new EBB SPRs
      powerpc: Turn on the EBB H/FSCR bits
      powerpc: Replace CPU_FTR_BCTAR with CPU_FTR_ARCH_207S
      powerpc: Setup BHRB instructions facility in HFSCR for POWER8
      powerpc: Fix interrupt range check on debug exception
      powerpc: Update tlbie/tlbiel as per ISA doc
      powerpc: Print page size info during boot
      powerpc: print both base and actual page size on hash failure
      powerpc: Fix hpte_decode to use the correct decoding for page sizes
      powerpc: Decode the pte-lp-encoding bits correctly.
      powerpc: Use encode avpn where we need only avpn values
      powerpc: Reduce PTE table memory wastage
      powerpc: Move the pte free routines from common header
      powerpc: Reduce the PTE_INDEX_SIZE
      powerpc: Switch 16GB and 16MB explicit hugepages to a different page table format
      powerpc: New hugepage directory format
      powerpc: Don't truncate pgd_index wrongly
      powerpc: Don't hard code the size of pte page
      powerpc: Save DAR and DSISR in pt_regs on MCE
      ...

commit 90a102e59ab9c94071fe1993134daff462d17a3f
Author: zhangwei(Jovi) <jovi.zhangwei@huawei.com>
Date:   Tue Apr 30 15:28:54 2013 -0700

    powerpc/xmon/sysrq: fix inconstistent help message of sysrq key
    
    Currently help message of /proc/sysrq-trigger highlight its
    upper-case characters, like below:
    
          SysRq : HELP : loglevel(0-9) reBoot Crash terminate-all-tasks(E)
          memory-full-oom-kill(F) kill-all-tasks(I) ...
    
    this would confuse user trigger sysrq by upper-case character, which is
    inconsistent with the real lower-case character registed key.
    
    This inconsistent help message will also lead more confused when
    26 upper-case letters put into use in future.
    
    This patch fix powerpc xmon sysrq key: "xmon(x)"
    
    Signed-off-by: zhangwei(Jovi) <jovi.zhangwei@huawei.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 13f85defabed..3e34cd224b7c 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2947,7 +2947,7 @@ static void sysrq_handle_xmon(int key)
 
 static struct sysrq_key_op sysrq_xmon_op = {
 	.handler =	sysrq_handle_xmon,
-	.help_msg =	"Xmon",
+	.help_msg =	"xmon(x)",
 	.action_msg =	"Entering xmon",
 };
 

commit ce54152f429ed5e6ad83e5e9f61825b5a795dd1e
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Sun Apr 28 09:37:26 2013 +0000

    powerpc: Save DAR and DSISR in pt_regs on MCE
    
    We were not saving DAR and DSISR on MCE. Save then and also print the values
    along with exception details in xmon.
    
    Acked-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 13f85defabed..51e237c4648f 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1430,7 +1430,7 @@ static void excprint(struct pt_regs *fp)
 	printf("    sp: %lx\n", fp->gpr[1]);
 	printf("   msr: %lx\n", fp->msr);
 
-	if (trap == 0x300 || trap == 0x380 || trap == 0x600) {
+	if (trap == 0x300 || trap == 0x380 || trap == 0x600 || trap == 0x200) {
 		printf("   dar: %lx\n", fp->dar);
 		if (trap != 0x380)
 			printf(" dsisr: %lx\n", fp->dsisr);

commit b9818c3312da66f4b83a4a2e8650628be1237cb5
Author: Michael Neuling <mikey@neuling.org>
Date:   Thu Jan 10 14:25:34 2013 +0000

    powerpc: Rename set_break to avoid naming conflict
    
    With allmodconfig we are getting:
      drivers/tty/synclink_gt.c:160:12: error: conflicting types for 'set_break'
      arch/powerpc/include/asm/debug.h:49:5: note: previous declaration of 'set_break' was here
    
      drivers/tty/synclinkmp.c:526:12: error: conflicting types for 'set_break'
      arch/powerpc/include/asm/debug.h:49:5: note: previous declaration of 'set_break' was here
    
    This renames set_break to set_breakpoint to avoid this naming conflict
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Reported-by: Fengguang Wu <fengguang.wu@intel.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 529c1ed7f59f..13f85defabed 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -747,7 +747,7 @@ static void insert_cpu_bpts(void)
 		brk.address = dabr.address;
 		brk.type = (dabr.enabled & HW_BRK_TYPE_DABR) | HW_BRK_TYPE_PRIV_ALL;
 		brk.len = 8;
-		set_break(&brk);
+		set_breakpoint(&brk);
 	}
 	if (iabr && cpu_has_feature(CPU_FTR_IABR))
 		mtspr(SPRN_IABR, iabr->address

commit 9422de3e953d0e60eb95f5430a9dd803eec1c6d7
Author: Michael Neuling <mikey@neuling.org>
Date:   Thu Dec 20 14:06:44 2012 +0000

    powerpc: Hardware breakpoints rewrite to handle non DABR breakpoint registers
    
    This is a rewrite so that we don't assume we are using the DABR throughout the
    code.  We now use the arch_hw_breakpoint to store the breakpoint in a generic
    manner in the thread_struct, rather than storing the raw DABR value.
    
    The ptrace GET/SET_DEBUGREG interface currently passes the raw DABR in from
    userspace.  We keep this functionality, so that future changes (like the POWER8
    DAWR), will still fake the DABR to userspace.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 1f8d2f10a432..529c1ed7f59f 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -43,6 +43,7 @@
 #include <asm/setjmp.h>
 #include <asm/reg.h>
 #include <asm/debug.h>
+#include <asm/hw_breakpoint.h>
 
 #ifdef CONFIG_PPC64
 #include <asm/hvcall.h>
@@ -607,7 +608,7 @@ static int xmon_sstep(struct pt_regs *regs)
 	return 1;
 }
 
-static int xmon_dabr_match(struct pt_regs *regs)
+static int xmon_break_match(struct pt_regs *regs)
 {
 	if ((regs->msr & (MSR_IR|MSR_PR|MSR_64BIT)) != (MSR_IR|MSR_64BIT))
 		return 0;
@@ -740,8 +741,14 @@ static void insert_bpts(void)
 
 static void insert_cpu_bpts(void)
 {
-	if (dabr.enabled)
-		set_dabr(dabr.address | (dabr.enabled & 7), DABRX_ALL);
+	struct arch_hw_breakpoint brk;
+
+	if (dabr.enabled) {
+		brk.address = dabr.address;
+		brk.type = (dabr.enabled & HW_BRK_TYPE_DABR) | HW_BRK_TYPE_PRIV_ALL;
+		brk.len = 8;
+		set_break(&brk);
+	}
 	if (iabr && cpu_has_feature(CPU_FTR_IABR))
 		mtspr(SPRN_IABR, iabr->address
 			 | (iabr->enabled & (BP_IABR|BP_IABR_TE)));
@@ -769,7 +776,7 @@ static void remove_bpts(void)
 
 static void remove_cpu_bpts(void)
 {
-	set_dabr(0, 0);
+	hw_breakpoint_disable();
 	if (cpu_has_feature(CPU_FTR_IABR))
 		mtspr(SPRN_IABR, 0);
 }
@@ -1138,7 +1145,7 @@ bpt_cmds(void)
 				printf(badaddr);
 				break;
 			}
-			dabr.address &= ~7;
+			dabr.address &= ~HW_BRK_TYPE_DABR;
 			dabr.enabled = mode | BP_DABR;
 		}
 		break;
@@ -2917,7 +2924,7 @@ static void xmon_init(int enable)
 		__debugger_bpt = xmon_bpt;
 		__debugger_sstep = xmon_sstep;
 		__debugger_iabr_match = xmon_iabr_match;
-		__debugger_dabr_match = xmon_dabr_match;
+		__debugger_break_match = xmon_break_match;
 		__debugger_fault_handler = xmon_fault_handler;
 	} else {
 		__debugger = NULL;
@@ -2925,7 +2932,7 @@ static void xmon_init(int enable)
 		__debugger_bpt = NULL;
 		__debugger_sstep = NULL;
 		__debugger_iabr_match = NULL;
-		__debugger_dabr_match = NULL;
+		__debugger_break_match = NULL;
 		__debugger_fault_handler = NULL;
 	}
 }

commit 0104cd6839bd575f0aa1af4125eb865dc0391aae
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Oct 9 04:20:36 2012 +0000

    powerpc/xmon: Fiddle xmon_depth_to_print logic in xmon_show_stack()
    
    Currently xmon_depth_to_print is static and global, but it's only
    ever used in xmon_show_stack().
    
    At least with a modern compiler it's inlined, so there's no point
    in it being static, we could #define it but it's only used in one
    place.
    
    By reworking the logic we can drop count and just decrement the
    max value as a loop counter. Also switch to a while loop so we
    actually print no more than 64 frames as you'd expect based on the
    variable name.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index d940234b09ec..1f8d2f10a432 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1281,21 +1281,19 @@ static void get_function_bounds(unsigned long pc, unsigned long *startp,
 	catch_memory_errors = 0;
 }
 
-static int xmon_depth_to_print = 64;
-
 #define LRSAVE_OFFSET		(STACK_FRAME_LR_SAVE * sizeof(unsigned long))
 #define MARKER_OFFSET		(STACK_FRAME_MARKER * sizeof(unsigned long))
 
 static void xmon_show_stack(unsigned long sp, unsigned long lr,
 			    unsigned long pc)
 {
+	int max_to_print = 64;
 	unsigned long ip;
 	unsigned long newsp;
 	unsigned long marker;
-	int count = 0;
 	struct pt_regs regs;
 
-	do {
+	while (max_to_print--) {
 		if (sp < PAGE_OFFSET) {
 			if (sp != 0)
 				printf("SP (%lx) is in userspace\n", sp);
@@ -1366,7 +1364,7 @@ static void xmon_show_stack(unsigned long sp, unsigned long lr,
 			break;
 
 		sp = newsp;
-	} while (count++ < xmon_depth_to_print);
+	}
 }
 
 static void backtrace(struct pt_regs *excp)

commit c4de38093ed9fe94fa35c3adb14afc40bf05e1da
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Oct 9 04:20:35 2012 +0000

    powerpc/xmon: Use STACK_FRAME_OVERHEAD in xmon_show_stack()
    
    We use STACK_FRAME_OVERHEAD in the exception vectors to establish
    the exception frame, so it should be good enough to use here.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index abf6be446356..d940234b09ec 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1286,12 +1286,6 @@ static int xmon_depth_to_print = 64;
 #define LRSAVE_OFFSET		(STACK_FRAME_LR_SAVE * sizeof(unsigned long))
 #define MARKER_OFFSET		(STACK_FRAME_MARKER * sizeof(unsigned long))
 
-#ifdef __powerpc64__
-#define REGS_OFFSET		0x70
-#else
-#define REGS_OFFSET		16
-#endif
-
 static void xmon_show_stack(unsigned long sp, unsigned long lr,
 			    unsigned long pc)
 {
@@ -1355,10 +1349,10 @@ static void xmon_show_stack(unsigned long sp, unsigned long lr,
 		   an exception frame. */
 		if (mread(sp + MARKER_OFFSET, &marker, sizeof(unsigned long))
 		    && marker == STACK_FRAME_REGS_MARKER) {
-			if (mread(sp + REGS_OFFSET, &regs, sizeof(regs))
+			if (mread(sp + STACK_FRAME_OVERHEAD, &regs, sizeof(regs))
 			    != sizeof(regs)) {
 				printf("Couldn't read registers at %lx\n",
-				       sp + REGS_OFFSET);
+				       sp + STACK_FRAME_OVERHEAD);
 				break;
 			}
 			printf("--- Exception: %lx %s at ", regs.trap,

commit c5c5714d5093e677ec962921210eae14156f7179
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Oct 9 04:20:34 2012 +0000

    powerpc/xmon: Remove unused #defines
    
    Neither REGS_PER_LINE or LAST_VOLATILE are used, nor have they ever
    been as far back as I can see.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index cc96a7129756..abf6be446356 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -166,12 +166,8 @@ extern void xmon_leave(void);
 
 #ifdef CONFIG_PPC64
 #define REG		"%.16lx"
-#define REGS_PER_LINE	4
-#define LAST_VOLATILE	13
 #else
 #define REG		"%.8lx"
-#define REGS_PER_LINE	8
-#define LAST_VOLATILE	12
 #endif
 
 #define GETWORD(v)	(((v)[0] << 24) + ((v)[1] << 16) + ((v)[2] << 8) + (v)[3])

commit b3dc19cddce37a1aaebc911c8db94e5209a9764d
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Oct 9 04:20:33 2012 +0000

    powerpc/xmon: Remove renaming #defines of scanhex() and skipbl()
    
    We have two #defines that rename scanhex() and skipbl() to
    xmon_scanhex() and xmon_skipbl() - but no one ever uses those
    names.
    
    So the only effect is to rename the actual symbols in the generated
    code, and AFACIS there is no reason to do that, so drop them.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 67d36ab445eb..cc96a7129756 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -52,9 +52,6 @@
 #include "nonstdio.h"
 #include "dis-asm.h"
 
-#define scanhex	xmon_scanhex
-#define skipbl	xmon_skipbl
-
 #ifdef CONFIG_SMP
 static cpumask_t cpus_in_xmon = CPU_MASK_NONE;
 static unsigned long xmon_taken = 1;

commit 08702c73a6182d0f6a429271383a553abc92c0b8
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Oct 9 04:20:30 2012 +0000

    powerpc/xmon: Remove empty xmon_map_scc()
    
    This has been empty since 2005, commit 51d3082 "Unify udbg (#2)".
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 3a56a639a92e..67d36ab445eb 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2943,7 +2943,6 @@ static void xmon_init(int enable)
 		__debugger_dabr_match = NULL;
 		__debugger_fault_handler = NULL;
 	}
-	xmon_map_scc();
 }
 
 #ifdef CONFIG_MAGIC_SYSRQ

commit ddadb6b8e88979a00ac44fba9c92896eec113bd1
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Sep 13 23:01:31 2012 +0000

    powerpc: Add an xmon command to dump one or all pacas
    
    This was originally motivated by a desire to see the mapping between
    logical and hardware cpu numbers.
    
    But it seemed that it made more sense to just add a command to dump
    (most of) the paca.
    
    With no arguments "dp" will dump the paca for the current cpu.
    
    It also takes an argument, eg. "dp 3" which is the logical cpu number
    in hex. This form does not check if the cpu is possible, but displays
    the paca regardless, as well as the cpu's state in the possible, present
    and online masks.
    
    Thirdly, "dpa" will display the paca for all possible cpus. If there are
    no possible cpus, like early in boot, it will tell you that.
    
    Sample output, number in brackets is the offset into the struct:
    
    2:mon> dp 3
    paca for cpu 0x3 @ c00000000ff20a80:
     possible         = yes
     present          = yes
     online           = yes
     lock_token       = 0x8000              (0x8)
     paca_index       = 0x3                 (0xa)
     kernel_toc       = 0xc00000000144f990  (0x10)
     kernelbase       = 0xc000000000000000  (0x18)
     kernel_msr       = 0xb000000000001032  (0x20)
     stab_real        = 0x0                 (0x28)
     stab_addr        = 0x0                 (0x30)
     emergency_sp     = 0xc00000003ffe4000  (0x38)
     data_offset      = 0xa40000            (0x40)
     hw_cpu_id        = 0x9                 (0x50)
     cpu_start        = 0x1                 (0x52)
     kexec_state      = 0x0                 (0x53)
     __current        = 0xc00000007e568680  (0x218)
     kstack           = 0xc00000007e5a3e30  (0x220)
     stab_rr          = 0x1a                (0x228)
     saved_r1         = 0xc00000007e7cb450  (0x230)
     trap_save        = 0x0                 (0x240)
     soft_enabled     = 0x0                 (0x242)
     irq_happened     = 0x0                 (0x243)
     io_sync          = 0x0                 (0x244)
     irq_work_pending = 0x0                 (0x245)
     nap_state_lost   = 0x0                 (0x246)
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 987f441525cb..3a56a639a92e 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -60,6 +60,8 @@ static cpumask_t cpus_in_xmon = CPU_MASK_NONE;
 static unsigned long xmon_taken = 1;
 static int xmon_owner;
 static int xmon_gate;
+#else
+#define xmon_owner 0
 #endif /* CONFIG_SMP */
 
 static unsigned long in_xmon __read_mostly = 0;
@@ -202,7 +204,13 @@ Commands:\n\
   di	dump instructions\n\
   df	dump float values\n\
   dd	dump double values\n\
-  dl    dump the kernel log buffer\n\
+  dl    dump the kernel log buffer\n"
+#ifdef CONFIG_PPC64
+  "\
+  dp[#]	dump paca for current cpu, or cpu #\n\
+  dpa	dump paca for all possible cpus\n"
+#endif
+  "\
   dr	dump stream of raw bytes\n\
   e	print exception information\n\
   f	flush cache\n\
@@ -2009,6 +2017,95 @@ static void xmon_rawdump (unsigned long adrs, long ndump)
 	printf("\n");
 }
 
+#ifdef CONFIG_PPC64
+static void dump_one_paca(int cpu)
+{
+	struct paca_struct *p;
+
+	if (setjmp(bus_error_jmp) != 0) {
+		printf("*** Error dumping paca for cpu 0x%x!\n", cpu);
+		return;
+	}
+
+	catch_memory_errors = 1;
+	sync();
+
+	p = &paca[cpu];
+
+	printf("paca for cpu 0x%x @ %p:\n", cpu, p);
+
+	printf(" %-*s = %s\n", 16, "possible", cpu_possible(cpu) ? "yes" : "no");
+	printf(" %-*s = %s\n", 16, "present", cpu_present(cpu) ? "yes" : "no");
+	printf(" %-*s = %s\n", 16, "online", cpu_online(cpu) ? "yes" : "no");
+
+#define DUMP(paca, name, format) \
+	printf(" %-*s = %#-*"format"\t(0x%lx)\n", 16, #name, 18, paca->name, \
+		offsetof(struct paca_struct, name));
+
+	DUMP(p, lock_token, "x");
+	DUMP(p, paca_index, "x");
+	DUMP(p, kernel_toc, "lx");
+	DUMP(p, kernelbase, "lx");
+	DUMP(p, kernel_msr, "lx");
+#ifdef CONFIG_PPC_STD_MMU_64
+	DUMP(p, stab_real, "lx");
+	DUMP(p, stab_addr, "lx");
+#endif
+	DUMP(p, emergency_sp, "p");
+	DUMP(p, data_offset, "lx");
+	DUMP(p, hw_cpu_id, "x");
+	DUMP(p, cpu_start, "x");
+	DUMP(p, kexec_state, "x");
+	DUMP(p, __current, "p");
+	DUMP(p, kstack, "lx");
+	DUMP(p, stab_rr, "lx");
+	DUMP(p, saved_r1, "lx");
+	DUMP(p, trap_save, "x");
+	DUMP(p, soft_enabled, "x");
+	DUMP(p, irq_happened, "x");
+	DUMP(p, io_sync, "x");
+	DUMP(p, irq_work_pending, "x");
+	DUMP(p, nap_state_lost, "x");
+
+#undef DUMP
+
+	catch_memory_errors = 0;
+	sync();
+}
+
+static void dump_all_pacas(void)
+{
+	int cpu;
+
+	if (num_possible_cpus() == 0) {
+		printf("No possible cpus, use 'dp #' to dump individual cpus\n");
+		return;
+	}
+
+	for_each_possible_cpu(cpu)
+		dump_one_paca(cpu);
+}
+
+static void dump_pacas(void)
+{
+	unsigned long num;
+	int c;
+
+	c = inchar();
+	if (c == 'a') {
+		dump_all_pacas();
+		return;
+	}
+
+	termch = c;	/* Put c back, it wasn't 'a' */
+
+	if (scanhex(&num))
+		dump_one_paca(num);
+	else
+		dump_one_paca(xmon_owner);
+}
+#endif
+
 #define isxdigit(c)	(('0' <= (c) && (c) <= '9') \
 			 || ('a' <= (c) && (c) <= 'f') \
 			 || ('A' <= (c) && (c) <= 'F'))
@@ -2018,6 +2115,14 @@ dump(void)
 	int c;
 
 	c = inchar();
+
+#ifdef CONFIG_PPC64
+	if (c == 'p') {
+		dump_pacas();
+		return;
+	}
+#endif
+
 	if ((isxdigit(c) && c != 'f' && c != 'd') || c == '\n')
 		termch = c;
 	scanhex((void *)&adrs);

commit 4474ef055c5d8cb8eaf002d69e49af71e3aa3a88
Author: Michael Neuling <mikey@neuling.org>
Date:   Thu Sep 6 21:24:56 2012 +0000

    powerpc: Rework set_dabr so it can take a DABRX value as well
    
    Rework set_dabr to take a DABRX value as well.
    
    Both the pseries and PS3 hypervisors do some checks on the DABRX
    values that are passed in the hcall.  This patch stops bogus values
    from being passed to hypervisor.  Also, in the case where we are
    clearing the breakpoint, where DABR and DABRX are zero, we modify the
    DABRX value to make it valid so that the hcall won't fail.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 9b49c65ee7a4..987f441525cb 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -740,7 +740,7 @@ static void insert_bpts(void)
 static void insert_cpu_bpts(void)
 {
 	if (dabr.enabled)
-		set_dabr(dabr.address | (dabr.enabled & 7));
+		set_dabr(dabr.address | (dabr.enabled & 7), DABRX_ALL);
 	if (iabr && cpu_has_feature(CPU_FTR_IABR))
 		mtspr(SPRN_IABR, iabr->address
 			 | (iabr->enabled & (BP_IABR|BP_IABR_TE)));
@@ -768,7 +768,7 @@ static void remove_bpts(void)
 
 static void remove_cpu_bpts(void)
 {
-	set_dabr(0);
+	set_dabr(0, 0);
 	if (cpu_has_feature(CPU_FTR_IABR))
 		mtspr(SPRN_IABR, 0);
 }

commit e3bc8049e524f13e09a58f5bad70b6738494277a
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Aug 23 22:09:13 2012 +0000

    powerpc: Fixup whitespace in xmon
    
    There are a few whitespace goolies in xmon.c, some of them appear to
    be my fault. Fix them all in one go.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 013f28668781..9b49c65ee7a4 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -895,13 +895,13 @@ cmds(struct pt_regs *excp)
 #endif
 		default:
 			printf("Unrecognized command: ");
-		        do {
+			do {
 				if (' ' < cmd && cmd <= '~')
 					putchar(cmd);
 				else
 					printf("\\x%x", cmd);
 				cmd = inchar();
-		        } while (cmd != '\n'); 
+			} while (cmd != '\n');
 			printf(" (type ? for help)\n");
 			break;
 		}
@@ -1098,7 +1098,7 @@ static long check_bp_loc(unsigned long addr)
 	return 1;
 }
 
-static char *breakpoint_help_string = 
+static char *breakpoint_help_string =
     "Breakpoint command usage:\n"
     "b                show breakpoints\n"
     "b <addr> [cnt]   set breakpoint at given instr addr\n"
@@ -1194,7 +1194,7 @@ bpt_cmds(void)
 
 	default:
 		termch = cmd;
-	        cmd = skipbl();
+		cmd = skipbl();
 		if (cmd == '?') {
 			printf(breakpoint_help_string);
 			break;
@@ -1360,7 +1360,7 @@ static void xmon_show_stack(unsigned long sp, unsigned long lr,
 				       sp + REGS_OFFSET);
 				break;
 			}
-                        printf("--- Exception: %lx %s at ", regs.trap,
+			printf("--- Exception: %lx %s at ", regs.trap,
 			       getvecname(TRAP(&regs)));
 			pc = regs.nip;
 			lr = regs.link;
@@ -1624,14 +1624,14 @@ static void super_regs(void)
 
 	cmd = skipbl();
 	if (cmd == '\n') {
-	        unsigned long sp, toc;
+		unsigned long sp, toc;
 		asm("mr %0,1" : "=r" (sp) :);
 		asm("mr %0,2" : "=r" (toc) :);
 
 		printf("msr  = "REG"  sprg0= "REG"\n",
 		       mfmsr(), mfspr(SPRN_SPRG0));
 		printf("pvr  = "REG"  sprg1= "REG"\n",
-		       mfspr(SPRN_PVR), mfspr(SPRN_SPRG1)); 
+		       mfspr(SPRN_PVR), mfspr(SPRN_SPRG1));
 		printf("dec  = "REG"  sprg2= "REG"\n",
 		       mfspr(SPRN_DEC), mfspr(SPRN_SPRG2));
 		printf("sp   = "REG"  sprg3= "REG"\n", sp, mfspr(SPRN_SPRG3));
@@ -1784,7 +1784,7 @@ byterev(unsigned char *val, int size)
 static int brev;
 static int mnoread;
 
-static char *memex_help_string = 
+static char *memex_help_string =
     "Memory examine command usage:\n"
     "m [addr] [flags] examine/change memory\n"
     "  addr is optional.  will start where left off.\n"
@@ -1799,7 +1799,7 @@ static char *memex_help_string =
     "NOTE: flags are saved as defaults\n"
     "";
 
-static char *memex_subcmd_help_string = 
+static char *memex_subcmd_help_string =
     "Memory examine subcommands:\n"
     "  hexval   write this val to current location\n"
     "  'string' write chars from string to this location\n"
@@ -2065,7 +2065,7 @@ prdump(unsigned long adrs, long ndump)
 		nr = mread(adrs, temp, r);
 		adrs += nr;
 		for (m = 0; m < r; ++m) {
-		        if ((m & (sizeof(long) - 1)) == 0 && m > 0)
+			if ((m & (sizeof(long) - 1)) == 0 && m > 0)
 				putchar(' ');
 			if (m < nr)
 				printf("%.2x", temp[m]);
@@ -2073,7 +2073,7 @@ prdump(unsigned long adrs, long ndump)
 				printf("%s", fault_chars[fault_type]);
 		}
 		for (; m < 16; ++m) {
-		        if ((m & (sizeof(long) - 1)) == 0)
+			if ((m & (sizeof(long) - 1)) == 0)
 				putchar(' ');
 			printf("  ");
 		}
@@ -2153,13 +2153,13 @@ dump_log_buf(void)
 	unsigned char buf[128];
 	size_t len;
 
-        if (setjmp(bus_error_jmp) != 0) {
+	if (setjmp(bus_error_jmp) != 0) {
 		printf("Error dumping printk buffer!\n");
-                return;
-        }
+		return;
+	}
 
-        catch_memory_errors = 1;
-        sync();
+	catch_memory_errors = 1;
+	sync();
 
 	kmsg_dump_rewind_nolock(&dumper);
 	while (kmsg_dump_get_line_nolock(&dumper, false, buf, sizeof(buf), &len)) {
@@ -2167,10 +2167,10 @@ dump_log_buf(void)
 		printf("%s", buf);
 	}
 
-        sync();
-        /* wait a little while to see if we get a machine check */
-        __delay(200);
-        catch_memory_errors = 0;
+	sync();
+	/* wait a little while to see if we get a machine check */
+	__delay(200);
+	catch_memory_errors = 0;
 }
 
 /*

commit ca5dd3954a62dc14c2afff1c34b3b5d8dc74f777
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Aug 23 22:09:12 2012 +0000

    powerpc: Fix xmon dl command for new printk implementation
    
    Since the printk internals were reworked the xmon 'dl' command which
    dumps the content of __log_buf has stopped working.
    
    It is now a structured buffer, so just dumping it doesn't really work.
    
    Use the helpers added for kgdb to print out the content.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index eab3492a45c5..013f28668781 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -17,6 +17,7 @@
 #include <linux/reboot.h>
 #include <linux/delay.h>
 #include <linux/kallsyms.h>
+#include <linux/kmsg_dump.h>
 #include <linux/cpumask.h>
 #include <linux/export.h>
 #include <linux/sysrq.h>
@@ -2148,40 +2149,23 @@ print_address(unsigned long addr)
 void
 dump_log_buf(void)
 {
-        const unsigned long size = 128;
-        unsigned long end, addr;
-        unsigned char buf[size + 1];
-
-        addr = 0;
-        buf[size] = '\0';
+	struct kmsg_dumper dumper = { .active = 1 };
+	unsigned char buf[128];
+	size_t len;
 
         if (setjmp(bus_error_jmp) != 0) {
-                printf("Unable to lookup symbol __log_buf!\n");
+		printf("Error dumping printk buffer!\n");
                 return;
         }
 
         catch_memory_errors = 1;
         sync();
-        addr = kallsyms_lookup_name("__log_buf");
-
-        if (! addr)
-                printf("Symbol __log_buf not found!\n");
-        else {
-                end = addr + (1 << CONFIG_LOG_BUF_SHIFT);
-                while (addr < end) {
-                        if (! mread(addr, buf, size)) {
-                                printf("Can't read memory at address 0x%lx\n", addr);
-                                break;
-                        }
-
-                        printf("%s", buf);
 
-                        if (strlen(buf) < size)
-                                break;
-
-                        addr += size;
-                }
-        }
+	kmsg_dump_rewind_nolock(&dumper);
+	while (kmsg_dump_get_line_nolock(&dumper, false, buf, sizeof(buf), &len)) {
+		buf[len] = '\0';
+		printf("%s", buf);
+	}
 
         sync();
         /* wait a little while to see if we get a machine check */

commit bc1d7702910c7c7e88eb60b58429dbfe293683ce
Author: Anton Blanchard <anton@samba.org>
Date:   Thu Jun 28 19:28:57 2012 +0000

    powerpc/xmon: Use cpumask iterator to avoid warning
    
    We have a bug report where the kernel hits a warning in the cpumask
    code:
    
    WARNING: at include/linux/cpumask.h:107
    
    Which is:
            WARN_ON_ONCE(cpu >= nr_cpumask_bits);
    
    The backtrace is:
            cpu_cmd
            cmds
            xmon_core
            xmon
            die
    
    xmon is iterating through 0 to NR_CPUS. I'm not sure why we are still
    open coding this but iterating above nr_cpu_ids is definitely a bug.
    
    This patch iterates through all possible cpus, in case we issue a
    system reset and CPUs in an offline state call in.
    
    Perhaps the old code was trying to handle CPUs that were in the
    partition but were never started (eg kexec into a kernel with an
    nr_cpus= boot option). They are going to die way before we get into
    xmon since we haven't set any kernel state up for them.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    CC: <stable@kernel.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 0f3ab06d2222..eab3492a45c5 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -971,7 +971,7 @@ static int cpu_cmd(void)
 		/* print cpus waiting or in xmon */
 		printf("cpus stopped:");
 		count = 0;
-		for (cpu = 0; cpu < NR_CPUS; ++cpu) {
+		for_each_possible_cpu(cpu) {
 			if (cpumask_test_cpu(cpu, &cpus_in_xmon)) {
 				if (count == 0)
 					printf(" %x", cpu);

commit ae3a197e3d0bfe3f4bf1693723e82dc018c096f3
Author: David Howells <dhowells@redhat.com>
Date:   Wed Mar 28 18:30:02 2012 +0100

    Disintegrate asm/system.h for PowerPC
    
    Disintegrate asm/system.h for PowerPC.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    cc: linuxppc-dev@lists.ozlabs.org

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 68a9cbbab450..0f3ab06d2222 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -41,6 +41,7 @@
 #include <asm/spu_priv1.h>
 #include <asm/setjmp.h>
 #include <asm/reg.h>
+#include <asm/debug.h>
 
 #ifdef CONFIG_PPC64
 #include <asm/hvcall.h>

commit f5339277eb8d3aed37f12a27988366f68ab68930
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Thu Mar 15 18:18:00 2012 +0000

    powerpc: Remove FW_FEATURE ISERIES from arch code
    
    This is no longer selectable, so just remove all the dependent code.
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 974a47b3c9b8..68a9cbbab450 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -39,7 +39,6 @@
 #include <asm/irq_regs.h>
 #include <asm/spu.h>
 #include <asm/spu_priv1.h>
-#include <asm/firmware.h>
 #include <asm/setjmp.h>
 #include <asm/reg.h>
 
@@ -1635,25 +1634,6 @@ static void super_regs(void)
 		       mfspr(SPRN_DEC), mfspr(SPRN_SPRG2));
 		printf("sp   = "REG"  sprg3= "REG"\n", sp, mfspr(SPRN_SPRG3));
 		printf("toc  = "REG"  dar  = "REG"\n", toc, mfspr(SPRN_DAR));
-#ifdef CONFIG_PPC_ISERIES
-		if (firmware_has_feature(FW_FEATURE_ISERIES)) {
-			struct paca_struct *ptrPaca;
-			struct lppaca *ptrLpPaca;
-
-			/* Dump out relevant Paca data areas. */
-			printf("Paca: \n");
-			ptrPaca = local_paca;
-
-			printf("  Local Processor Control Area (LpPaca): \n");
-			ptrLpPaca = ptrPaca->lppaca_ptr;
-			printf("    Saved Srr0=%.16lx  Saved Srr1=%.16lx \n",
-			       ptrLpPaca->saved_srr0, ptrLpPaca->saved_srr1);
-			printf("    Saved Gpr3=%.16lx  Saved Gpr4=%.16lx \n",
-			       ptrLpPaca->saved_gpr3, ptrLpPaca->saved_gpr4);
-			printf("    Saved Gpr5=%.16lx \n",
-				ptrLpPaca->gpr5_dword.saved_gpr5);
-		}
-#endif
 
 		return;
 	}
@@ -2856,10 +2836,6 @@ static void dump_tlb_book3e(void)
 
 static void xmon_init(int enable)
 {
-#ifdef CONFIG_PPC_ISERIES
-	if (firmware_has_feature(FW_FEATURE_ISERIES))
-		return;
-#endif
 	if (enable) {
 		__debugger = xmon;
 		__debugger_ipi = xmon_ipi;
@@ -2896,10 +2872,6 @@ static struct sysrq_key_op sysrq_xmon_op = {
 
 static int __init setup_xmon_sysrq(void)
 {
-#ifdef CONFIG_PPC_ISERIES
-	if (firmware_has_feature(FW_FEATURE_ISERIES))
-		return 0;
-#endif
 	register_sysrq_key('x', &sysrq_xmon_op);
 	return 0;
 }

commit 7230c5644188cd9e3fb380cc97dde00c464a3ba7
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Mar 6 18:27:59 2012 +1100

    powerpc: Rework lazy-interrupt handling
    
    The current implementation of lazy interrupts handling has some
    issues that this tries to address.
    
    We don't do the various workarounds we need to do when re-enabling
    interrupts in some cases such as when returning from an interrupt
    and thus we may still lose or get delayed decrementer or doorbell
    interrupts.
    
    The current scheme also makes it much harder to handle the external
    "edge" interrupts provided by some BookE processors when using the
    EPR facility (External Proxy) and the Freescale Hypervisor.
    
    Additionally, we tend to keep interrupts hard disabled in a number
    of cases, such as decrementer interrupts, external interrupts, or
    when a masked decrementer interrupt is pending. This is sub-optimal.
    
    This is an attempt at fixing it all in one go by reworking the way
    we do the lazy interrupt disabling from the ground up.
    
    The base idea is to replace the "hard_enabled" field with a
    "irq_happened" field in which we store a bit mask of what interrupt
    occurred while soft-disabled.
    
    When re-enabling, either via arch_local_irq_restore() or when returning
    from an interrupt, we can now decide what to do by testing bits in that
    field.
    
    We then implement replaying of the missed interrupts either by
    re-using the existing exception frame (in exception exit case) or via
    the creation of a new one from an assembly trampoline (in the
    arch_local_irq_enable case).
    
    This removes the need to play with the decrementer to try to create
    fake interrupts, among others.
    
    In addition, this adds a few refinements:
    
     - We no longer  hard disable decrementer interrupts that occur
    while soft-disabled. We now simply bump the decrementer back to max
    (on BookS) or leave it stopped (on BookE) and continue with hard interrupts
    enabled, which means that we'll potentially get better sample quality from
    performance monitor interrupts.
    
     - Timer, decrementer and doorbell interrupts now hard-enable
    shortly after removing the source of the interrupt, which means
    they no longer run entirely hard disabled. Again, this will improve
    perf sample quality.
    
     - On Book3E 64-bit, we now make the performance monitor interrupt
    act as an NMI like Book3S (the necessary C code for that to work
    appear to already be present in the FSL perf code, notably calling
    nmi_enter instead of irq_enter). (This also fixes a bug where BookE
    perfmon interrupts could clobber r14 ... oops)
    
     - We could make "masked" decrementer interrupts act as NMIs when doing
    timer-based perf sampling to improve the sample quality.
    
    Signed-off-by-yet: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    ---
    
    v2:
    
    - Add hard-enable to decrementer, timer and doorbells
    - Fix CR clobber in masked irq handling on BookE
    - Make embedded perf interrupt act as an NMI
    - Add a PACA_HAPPENED_EE_EDGE for use by FSL if they want
      to retrigger an interrupt without preventing hard-enable
    
    v3:
    
     - Fix or vs. ori bug on Book3E
     - Fix enabling of interrupts for some exceptions on Book3E
    
    v4:
    
     - Fix resend of doorbells on return from interrupt on Book3E
    
    v5:
    
     - Rebased on top of my latest series, which involves some significant
    rework of some aspects of the patch.
    
    v6:
     - 32-bit compile fix
     - more compile fixes with various .config combos
     - factor out the asm code to soft-disable interrupts
     - remove the C wrapper around preempt_schedule_irq
    
    v7:
     - Fix a bug with hard irq state tracking on native power7

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 63846ebd3276..974a47b3c9b8 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1437,8 +1437,8 @@ static void excprint(struct pt_regs *fp)
 
 	printf("  current = 0x%lx\n", current);
 #ifdef CONFIG_PPC64
-	printf("  paca    = 0x%lx\t softe: %d\t harde: %d\n",
-	       local_paca, local_paca->soft_enabled, local_paca->hard_enabled);
+	printf("  paca    = 0x%lx\t softe: %d\t irq_happened: 0x%02x\n",
+	       local_paca, local_paca->soft_enabled, local_paca->irq_happened);
 #endif
 	if (current) {
 		printf("    pid   = %ld, comm = %s\n",

commit 7ac21cd465391802d931bd5e692302639383b8f5
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Mar 2 10:10:09 2012 +1100

    powerpc/xmon: Add display of soft & hard irq states
    
    Also use local_paca instead of get_paca() to avoid getting into
    the smp_processor_id() debugging code from the debugger
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index cb95eea74d3d..63846ebd3276 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1437,7 +1437,8 @@ static void excprint(struct pt_regs *fp)
 
 	printf("  current = 0x%lx\n", current);
 #ifdef CONFIG_PPC64
-	printf("  paca    = 0x%lx\n", get_paca());
+	printf("  paca    = 0x%lx\t softe: %d\t harde: %d\n",
+	       local_paca, local_paca->soft_enabled, local_paca->hard_enabled);
 #endif
 	if (current) {
 		printf("    pid   = %ld, comm = %s\n",
@@ -1641,7 +1642,7 @@ static void super_regs(void)
 
 			/* Dump out relevant Paca data areas. */
 			printf("Paca: \n");
-			ptrPaca = get_paca();
+			ptrPaca = local_paca;
 
 			printf("  Local Processor Control Area (LpPaca): \n");
 			ptrLpPaca = ptrPaca->lppaca_ptr;
@@ -2644,7 +2645,7 @@ static void dump_slb(void)
 static void dump_stab(void)
 {
 	int i;
-	unsigned long *tmp = (unsigned long *)get_paca()->stab_addr;
+	unsigned long *tmp = (unsigned long *)local_paca->stab_addr;
 
 	printf("Segment table contents of cpu %x\n", smp_processor_id());
 

commit 08f6d6abc3eadb88f020075910e6f3a849e56690
Author: Jimi Xenidis <jimix@pobox.com>
Date:   Thu Sep 29 12:05:28 2011 +0000

    powerpc/xmon: Fix #if typo for systems without MSR[RI]
    
    Sorry, there was a typo in the #if
    
    signed-off-by: Jimi Xenidis <jimix@pobox.com>
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 95cf53b71499..cb95eea74d3d 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -338,7 +338,7 @@ int cpus_are_in_xmon(void)
 
 static inline int unrecoverable_excp(struct pt_regs *regs)
 {
-#if defined(CONFIG_4xx) || defined(CONFIG_BOOK3E)
+#if defined(CONFIG_4xx) || defined(CONFIG_PPC_BOOK3E)
 	/* We have no MSR_RI bit on 4xx or Book3e, so we simply return false */
 	return 0;
 #else

commit 79873e8df64cc124cdcad56d1d8330b3f45690bc
Author: Jimi Xenidis <jimix@pobox.com>
Date:   Thu Sep 29 11:25:10 2011 +0000

    powerpc/xmon: Fix the 'u' command description
    
    The 'u' command will print the TLB on book3e parts and the SLB on
    Book3s parts, but the help system doesn't say that correctly.
    
    Signed-off-by: Jimi Xenidis <jimix@pobox.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 03a217ae3be0..95cf53b71499 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -228,13 +228,11 @@ Commands:\n\
   t	print backtrace\n\
   x	exit monitor and recover\n\
   X	exit monitor and dont recover\n"
-#ifdef CONFIG_PPC64
+#if defined(CONFIG_PPC64) && !defined(CONFIG_PPC_BOOK3E)
 "  u	dump segment table or SLB\n"
-#endif
-#ifdef CONFIG_PPC_STD_MMU_32
+#elif defined(CONFIG_PPC_STD_MMU_32)
 "  u	dump segment registers\n"
-#endif
-#ifdef CONFIG_44x
+#elif defined(CONFIG_44x) || defined(CONFIG_PPC_BOOK3E)
 "  u	dump TLB\n"
 #endif
 "  ?	help\n"
@@ -885,13 +883,11 @@ cmds(struct pt_regs *excp)
 		case 'u':
 			dump_segments();
 			break;
-#endif
-#ifdef CONFIG_4xx
+#elif defined(CONFIG_4xx)
 		case 'u':
 			dump_tlb_44x();
 			break;
-#endif
-#ifdef CONFIG_PPC_BOOK3E
+#elif defined(CONFIG_PPC_BOOK3E)
 		case 'u':
 			dump_tlb_book3e();
 			break;

commit 32aaeffbd4a7457bf2f7448b33b5946ff2a960eb
Merge: 208bca086040 67b84999b1a8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Nov 6 19:44:47 2011 -0800

    Merge branch 'modsplit-Oct31_2011' of git://git.kernel.org/pub/scm/linux/kernel/git/paulg/linux
    
    * 'modsplit-Oct31_2011' of git://git.kernel.org/pub/scm/linux/kernel/git/paulg/linux: (230 commits)
      Revert "tracing: Include module.h in define_trace.h"
      irq: don't put module.h into irq.h for tracking irqgen modules.
      bluetooth: macroize two small inlines to avoid module.h
      ip_vs.h: fix implicit use of module_get/module_put from module.h
      nf_conntrack.h: fix up fallout from implicit moduleparam.h presence
      include: replace linux/module.h with "struct module" wherever possible
      include: convert various register fcns to macros to avoid include chaining
      crypto.h: remove unused crypto_tfm_alg_modname() inline
      uwb.h: fix implicit use of asm/page.h for PAGE_SIZE
      pm_runtime.h: explicitly requires notifier.h
      linux/dmaengine.h: fix implicit use of bitmap.h and asm/page.h
      miscdevice.h: fix up implicit use of lists and types
      stop_machine.h: fix implicit use of smp.h for smp_processor_id
      of: fix implicit use of errno.h in include/linux/of.h
      of_platform.h: delete needless include <linux/module.h>
      acpi: remove module.h include from platform/aclinux.h
      miscdevice.h: delete unnecessary inclusion of module.h
      device_cgroup.h: delete needless include <linux/module.h>
      net: sch_generic remove redundant use of <linux/module.h>
      net: inet_timewait_sock doesnt need <linux/module.h>
      ...
    
    Fix up trivial conflicts (other header files, and  removal of the ab3550 mfd driver) in
     - drivers/media/dvb/frontends/dibx000_common.c
     - drivers/media/video/{mt9m111.c,ov6650.c}
     - drivers/mfd/ab3550-core.c
     - include/linux/dmaengine.h

commit 4b16f8e2d6d64249f0ed3ca7fe2a319d0dde2719
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Fri Jul 22 18:24:23 2011 -0400

    powerpc: various straight conversions from module.h --> export.h
    
    All these files were including module.h just for the basic
    EXPORT_SYMBOL infrastructure.  We can shift them off to the
    export.h header which is a way smaller footprint and thus
    realize some compile time gains.
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 42541bbcc7fa..0f5643fb9747 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -18,7 +18,7 @@
 #include <linux/delay.h>
 #include <linux/kallsyms.h>
 #include <linux/cpumask.h>
-#include <linux/module.h>
+#include <linux/export.h>
 #include <linux/sysrq.h>
 #include <linux/interrupt.h>
 #include <linux/irq.h>

commit 66857b3a9e88ac6f6e279eaa06b84367e662c0dd
Author: Jimi Xenidis <jimix@pobox.com>
Date:   Fri Sep 23 05:40:46 2011 +0000

    powerpc: Fix xmon for systems without MSR[RI]
    
    Based on patch by David Gibson <dwg@au1.ibm.com>
    
    xmon has a longstanding bug on systems which are SMP-capable but lack
    the MSR[RI] bit.  In these cases, xmon invoked by IPI on secondary
    CPUs will not properly keep quiet, but will print stuff, thereby
    garbling the primary xmon's output.  This patch fixes it, by ignoring
    the RI bit if the processor does not support it.
    
    There's already a version of this for 4xx upstream, which we'll need
    to extend to other RI-lacking CPUs at some point.  For now this adds
    Book3e processors to the mix.
    
    Signed-off-by: Jimi Xenidis <jimix@pobox.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 42541bbcc7fa..13f82f847669 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -340,8 +340,8 @@ int cpus_are_in_xmon(void)
 
 static inline int unrecoverable_excp(struct pt_regs *regs)
 {
-#ifdef CONFIG_4xx
-	/* We have no MSR_RI bit on 4xx, so we simply return false */
+#if defined(CONFIG_4xx) || defined(CONFIG_BOOK3E)
+	/* We have no MSR_RI bit on 4xx or Book3e, so we simply return false */
 	return 0;
 #else
 	return ((regs->msr & MSR_RI) == 0);

commit e04763713286b1e00e1c2a33fe2741caf9470f2b
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 10 19:29:06 2011 +0000

    powerpc: Remove call sites of MSG_ALL_BUT_SELF
    
    The only user of MSG_ALL_BUT_SELF in the whole kernel tree is powerpc,
    and it only uses it to start the debugger. Both debuggers always call
    smp_send_debugger_break with MSG_ALL_BUT_SELF, and only mpic can do
    anything more optimal than a loop over all online cpus, but all message
    passing implementations have to code for this special delivery target.
    
    Convert smp_send_debugger_break to take void and loop calling the smp_ops
    message_pass function for each of the other cpus in the online cpumask.
    
    Use raw_smp_processor_id() because we are either entering the debugger
    or trying to start kdump and the additional warning it not useful were
    it to trigger.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 91309c5c00d7..42541bbcc7fa 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -437,7 +437,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 		xmon_owner = cpu;
 		mb();
 		if (ncpus > 1) {
-			smp_send_debugger_break(MSG_ALL_BUT_SELF);
+			smp_send_debugger_break();
 			/* wait for other cpus to come in */
 			for (timeout = 100000000; timeout != 0; --timeout) {
 				if (cpumask_weight(&cpus_in_xmon) >= ncpus)

commit 104699c0ab473535793b5fea156adaf309afd29b
Author: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Date:   Thu Apr 28 05:07:23 2011 +0000

    powerpc: Convert old cpumask API into new one
    
    Adapt new API.
    
    Almost change is trivial. Most important change is the below line
    because we plan to change task->cpus_allowed implementation.
    
    -       ctx->cpus_allowed = current->cpus_allowed;
    
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 909804aaeebb..91309c5c00d7 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -334,7 +334,7 @@ static void release_output_lock(void)
 
 int cpus_are_in_xmon(void)
 {
-	return !cpus_empty(cpus_in_xmon);
+	return !cpumask_empty(&cpus_in_xmon);
 }
 #endif
 
@@ -373,7 +373,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 
 #ifdef CONFIG_SMP
 	cpu = smp_processor_id();
-	if (cpu_isset(cpu, cpus_in_xmon)) {
+	if (cpumask_test_cpu(cpu, &cpus_in_xmon)) {
 		get_output_lock();
 		excprint(regs);
 		printf("cpu 0x%x: Exception %lx %s in xmon, "
@@ -396,7 +396,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 	}
 
 	xmon_fault_jmp[cpu] = recurse_jmp;
-	cpu_set(cpu, cpus_in_xmon);
+	cpumask_set_cpu(cpu, &cpus_in_xmon);
 
 	bp = NULL;
 	if ((regs->msr & (MSR_IR|MSR_PR|MSR_64BIT)) == (MSR_IR|MSR_64BIT))
@@ -440,7 +440,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 			smp_send_debugger_break(MSG_ALL_BUT_SELF);
 			/* wait for other cpus to come in */
 			for (timeout = 100000000; timeout != 0; --timeout) {
-				if (cpus_weight(cpus_in_xmon) >= ncpus)
+				if (cpumask_weight(&cpus_in_xmon) >= ncpus)
 					break;
 				barrier();
 			}
@@ -484,7 +484,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 		}
 	}
  leave:
-	cpu_clear(cpu, cpus_in_xmon);
+	cpumask_clear_cpu(cpu, &cpus_in_xmon);
 	xmon_fault_jmp[cpu] = NULL;
 #else
 	/* UP is simple... */
@@ -630,7 +630,7 @@ static int xmon_iabr_match(struct pt_regs *regs)
 static int xmon_ipi(struct pt_regs *regs)
 {
 #ifdef CONFIG_SMP
-	if (in_xmon && !cpu_isset(smp_processor_id(), cpus_in_xmon))
+	if (in_xmon && !cpumask_test_cpu(smp_processor_id(), &cpus_in_xmon))
 		xmon_core(regs, 1);
 #endif
 	return 0;
@@ -976,7 +976,7 @@ static int cpu_cmd(void)
 		printf("cpus stopped:");
 		count = 0;
 		for (cpu = 0; cpu < NR_CPUS; ++cpu) {
-			if (cpu_isset(cpu, cpus_in_xmon)) {
+			if (cpumask_test_cpu(cpu, &cpus_in_xmon)) {
 				if (count == 0)
 					printf(" %x", cpu);
 				++count;
@@ -992,7 +992,7 @@ static int cpu_cmd(void)
 		return 0;
 	}
 	/* try to switch to cpu specified */
-	if (!cpu_isset(cpu, cpus_in_xmon)) {
+	if (!cpumask_test_cpu(cpu, &cpus_in_xmon)) {
 		printf("cpu 0x%x isn't in xmon\n", cpu);
 		return 0;
 	}

commit 48404f2e95ef0ffd8134d89c8abcd1a15e15f1b0
Author: Paul Mackerras <paulus@samba.org>
Date:   Sun May 1 19:48:20 2011 +0000

    powerpc: Save Come-From Address Register (CFAR) in exception frame
    
    Recent 64-bit server processors (POWER6 and POWER7) have a "Come-From
    Address Register" (CFAR), that records the address of the most recent
    branch or rfid (return from interrupt) instruction for debugging purposes.
    
    This saves the value of the CFAR in the exception entry code and stores
    it in the exception frame.  We also make xmon print the CFAR value in
    its register dump code.
    
    Rather than extend the pt_regs struct at this time, we steal the orig_gpr3
    field, which is only used for system calls, and use it for the CFAR value
    for all exceptions/interrupts other than system calls.  This means we
    don't save the CFAR on system calls, which is not a great problem since
    system calls tend not to happen unexpectedly, and also avoids adding the
    overhead of reading the CFAR to the system call entry path.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 60593ad861e8..909804aaeebb 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1497,6 +1497,10 @@ static void prregs(struct pt_regs *fp)
 #endif
 	printf("pc  = ");
 	xmon_print_symbol(fp->nip, " ", "\n");
+	if (TRAP(fp) != 0xc00 && cpu_has_feature(CPU_FTR_CFAR)) {
+		printf("cfar= ");
+		xmon_print_symbol(fp->orig_gpr3, " ", "\n");
+	}
 	printf("lr  = ");
 	xmon_print_symbol(fp->link, " ", "\n");
 	printf("msr = "REG"   cr  = %.8lx\n", fp->msr, fp->ccr);

commit 44ae3ab3358e962039c36ad4ae461ae9fb29596c
Author: Matt Evans <matt@ozlabs.org>
Date:   Wed Apr 6 19:48:50 2011 +0000

    powerpc: Free up some CPU feature bits by moving out MMU-related features
    
    Some of the 64bit PPC CPU features are MMU-related, so this patch moves
    them to MMU_FTR_ bits.  All cpu_has_feature()-style tests are moved to
    mmu_has_feature(), and seven feature bits are freed as a result.
    
    Signed-off-by: Matt Evans <matt@ozlabs.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index ef9756ee284e..60593ad861e8 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2663,7 +2663,7 @@ static void dump_stab(void)
 
 void dump_segments(void)
 {
-	if (cpu_has_feature(CPU_FTR_SLB))
+	if (mmu_has_feature(MMU_FTR_SLB))
 		dump_slb();
 	else
 		dump_stab();

commit 9f0b079320ad1cc71ad7ea4e0ed0b64cd72bbd6d
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Apr 7 21:56:03 2011 +0000

    powerpc: Use MSR_64BIT in places
    
    Use the new MSR_64BIT in a few places. Some of these are already ifdef'ed
    for BOOKE vs BOOKS, but it's still clearer, MSR_SF does not immediately
    parse as "MSR bit for 64bit".
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 33794c1d92c3..ef9756ee284e 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -399,7 +399,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 	cpu_set(cpu, cpus_in_xmon);
 
 	bp = NULL;
-	if ((regs->msr & (MSR_IR|MSR_PR|MSR_SF)) == (MSR_IR|MSR_SF))
+	if ((regs->msr & (MSR_IR|MSR_PR|MSR_64BIT)) == (MSR_IR|MSR_64BIT))
 		bp = at_breakpoint(regs->nip);
 	if (bp || unrecoverable_excp(regs))
 		fromipi = 0;
@@ -529,7 +529,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 		}
 	}
 #else
-	if ((regs->msr & (MSR_IR|MSR_PR|MSR_SF)) == (MSR_IR|MSR_SF)) {
+	if ((regs->msr & (MSR_IR|MSR_PR|MSR_64BIT)) == (MSR_IR|MSR_64BIT)) {
 		bp = at_breakpoint(regs->nip);
 		if (bp != NULL) {
 			int stepped = emulate_step(regs, bp->instr[0]);
@@ -578,7 +578,7 @@ static int xmon_bpt(struct pt_regs *regs)
 	struct bpt *bp;
 	unsigned long offset;
 
-	if ((regs->msr & (MSR_IR|MSR_PR|MSR_SF)) != (MSR_IR|MSR_SF))
+	if ((regs->msr & (MSR_IR|MSR_PR|MSR_64BIT)) != (MSR_IR|MSR_64BIT))
 		return 0;
 
 	/* Are we at the trap at bp->instr[1] for some bp? */
@@ -609,7 +609,7 @@ static int xmon_sstep(struct pt_regs *regs)
 
 static int xmon_dabr_match(struct pt_regs *regs)
 {
-	if ((regs->msr & (MSR_IR|MSR_PR|MSR_SF)) != (MSR_IR|MSR_SF))
+	if ((regs->msr & (MSR_IR|MSR_PR|MSR_64BIT)) != (MSR_IR|MSR_64BIT))
 		return 0;
 	if (dabr.enabled == 0)
 		return 0;
@@ -619,7 +619,7 @@ static int xmon_dabr_match(struct pt_regs *regs)
 
 static int xmon_iabr_match(struct pt_regs *regs)
 {
-	if ((regs->msr & (MSR_IR|MSR_PR|MSR_SF)) != (MSR_IR|MSR_SF))
+	if ((regs->msr & (MSR_IR|MSR_PR|MSR_64BIT)) != (MSR_IR|MSR_64BIT))
 		return 0;
 	if (iabr == NULL)
 		return 0;
@@ -644,7 +644,7 @@ static int xmon_fault_handler(struct pt_regs *regs)
 	if (in_xmon && catch_memory_errors)
 		handle_fault(regs);	/* doesn't return */
 
-	if ((regs->msr & (MSR_IR|MSR_PR|MSR_SF)) == (MSR_IR|MSR_SF)) {
+	if ((regs->msr & (MSR_IR|MSR_PR|MSR_64BIT)) == (MSR_IR|MSR_64BIT)) {
 		bp = in_breakpoint_table(regs->nip, &offset);
 		if (bp != NULL) {
 			regs->nip = bp->address + offset;
@@ -929,7 +929,7 @@ static int do_step(struct pt_regs *regs)
 	int stepped;
 
 	/* check we are in 64-bit kernel mode, translation enabled */
-	if ((regs->msr & (MSR_SF|MSR_PR|MSR_IR)) == (MSR_SF|MSR_IR)) {
+	if ((regs->msr & (MSR_64BIT|MSR_PR|MSR_IR)) == (MSR_64BIT|MSR_IR)) {
 		if (mread(regs->nip, &instr, 4) == 4) {
 			stepped = emulate_step(regs, instr);
 			if (stepped < 0) {

commit b2b755b5f10eb32fbdc73a9907c07006b17f714b
Author: David Rientjes <rientjes@google.com>
Date:   Thu Mar 24 15:18:15 2011 -0700

    lib, arch: add filter argument to show_mem and fix private implementations
    
    Commit ddd588b5dd55 ("oom: suppress nodes that are not allowed from
    meminfo on oom kill") moved lib/show_mem.o out of lib/lib.a, which
    resulted in build warnings on all architectures that implement their own
    versions of show_mem():
    
            lib/lib.a(show_mem.o): In function `show_mem':
            show_mem.c:(.text+0x1f4): multiple definition of `show_mem'
            arch/sparc/mm/built-in.o:(.text+0xd70): first defined here
    
    The fix is to remove __show_mem() and add its argument to show_mem() in
    all implementations to prevent this breakage.
    
    Architectures that implement their own show_mem() actually don't do
    anything with the argument yet, but they could be made to filter nodes
    that aren't allowed in the current context in the future just like the
    generic implementation.
    
    Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Reported-by: James Bottomley <James.Bottomley@hansenpartnership.com>
    Suggested-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: David Rientjes <rientjes@google.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index d17d04cfb2cd..33794c1d92c3 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -821,7 +821,7 @@ cmds(struct pt_regs *excp)
 				memzcan();
 				break;
 			case 'i':
-				show_mem();
+				show_mem(0);
 				break;
 			default:
 				termch = cmd;

commit 1495cc9df4e81f5a8fa9b0b8f1034b14d24b7d8c
Author: Dmitry Torokhov <dmitry.torokhov@gmail.com>
Date:   Tue Aug 17 21:15:46 2010 -0700

    Input: sysrq - drop tty argument from sysrq ops handlers
    
    Noone is using tty argument so let's get rid of it.
    
    Acked-by: Alan Cox <alan@lxorguk.ukuu.org.uk>
    Acked-by: Jason Wessel <jason.wessel@windriver.com>
    Acked-by: Greg Kroah-Hartman <gregkh@suse.de>
    Signed-off-by: Dmitry Torokhov <dtor@mail.ru>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 0554445200bf..d17d04cfb2cd 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2880,15 +2880,14 @@ static void xmon_init(int enable)
 }
 
 #ifdef CONFIG_MAGIC_SYSRQ
-static void sysrq_handle_xmon(int key, struct tty_struct *tty) 
+static void sysrq_handle_xmon(int key)
 {
 	/* ensure xmon is enabled */
 	xmon_init(1);
 	debugger(get_irq_regs());
 }
 
-static struct sysrq_key_op sysrq_xmon_op = 
-{
+static struct sysrq_key_op sysrq_xmon_op = {
 	.handler =	sysrq_handle_xmon,
 	.help_msg =	"Xmon",
 	.action_msg =	"Entering xmon",

commit 03247157f73912c98baa918cf46b98ee5483d7f8
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Jul 9 15:34:50 2010 +1000

    powerpc/book3e: Add TLB dump in xmon for Book3E
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 8bad7d5f32af..0554445200bf 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -155,6 +155,9 @@ static int do_spu_cmd(void);
 #ifdef CONFIG_44x
 static void dump_tlb_44x(void);
 #endif
+#ifdef CONFIG_PPC_BOOK3E
+static void dump_tlb_book3e(void);
+#endif
 
 static int xmon_no_auto_backtrace;
 
@@ -887,6 +890,11 @@ cmds(struct pt_regs *excp)
 		case 'u':
 			dump_tlb_44x();
 			break;
+#endif
+#ifdef CONFIG_PPC_BOOK3E
+		case 'u':
+			dump_tlb_book3e();
+			break;
 #endif
 		default:
 			printf("Unrecognized command: ");
@@ -2701,6 +2709,150 @@ static void dump_tlb_44x(void)
 }
 #endif /* CONFIG_44x */
 
+#ifdef CONFIG_PPC_BOOK3E
+static void dump_tlb_book3e(void)
+{
+	u32 mmucfg, pidmask, lpidmask;
+	u64 ramask;
+	int i, tlb, ntlbs, pidsz, lpidsz, rasz, lrat = 0;
+	int mmu_version;
+	static const char *pgsz_names[] = {
+		"  1K",
+		"  2K",
+		"  4K",
+		"  8K",
+		" 16K",
+		" 32K",
+		" 64K",
+		"128K",
+		"256K",
+		"512K",
+		"  1M",
+		"  2M",
+		"  4M",
+		"  8M",
+		" 16M",
+		" 32M",
+		" 64M",
+		"128M",
+		"256M",
+		"512M",
+		"  1G",
+		"  2G",
+		"  4G",
+		"  8G",
+		" 16G",
+		" 32G",
+		" 64G",
+		"128G",
+		"256G",
+		"512G",
+		"  1T",
+		"  2T",
+	};
+
+	/* Gather some infos about the MMU */
+	mmucfg = mfspr(SPRN_MMUCFG);
+	mmu_version = (mmucfg & 3) + 1;
+	ntlbs = ((mmucfg >> 2) & 3) + 1;
+	pidsz = ((mmucfg >> 6) & 0x1f) + 1;
+	lpidsz = (mmucfg >> 24) & 0xf;
+	rasz = (mmucfg >> 16) & 0x7f;
+	if ((mmu_version > 1) && (mmucfg & 0x10000))
+		lrat = 1;
+	printf("Book3E MMU MAV=%d.0,%d TLBs,%d-bit PID,%d-bit LPID,%d-bit RA\n",
+	       mmu_version, ntlbs, pidsz, lpidsz, rasz);
+	pidmask = (1ul << pidsz) - 1;
+	lpidmask = (1ul << lpidsz) - 1;
+	ramask = (1ull << rasz) - 1;
+
+	for (tlb = 0; tlb < ntlbs; tlb++) {
+		u32 tlbcfg;
+		int nent, assoc, new_cc = 1;
+		printf("TLB %d:\n------\n", tlb);
+		switch(tlb) {
+		case 0:
+			tlbcfg = mfspr(SPRN_TLB0CFG);
+			break;
+		case 1:
+			tlbcfg = mfspr(SPRN_TLB1CFG);
+			break;
+		case 2:
+			tlbcfg = mfspr(SPRN_TLB2CFG);
+			break;
+		case 3:
+			tlbcfg = mfspr(SPRN_TLB3CFG);
+			break;
+		default:
+			printf("Unsupported TLB number !\n");
+			continue;
+		}
+		nent = tlbcfg & 0xfff;
+		assoc = (tlbcfg >> 24) & 0xff;
+		for (i = 0; i < nent; i++) {
+			u32 mas0 = MAS0_TLBSEL(tlb);
+			u32 mas1 = MAS1_TSIZE(BOOK3E_PAGESZ_4K);
+			u64 mas2 = 0;
+			u64 mas7_mas3;
+			int esel = i, cc = i;
+
+			if (assoc != 0) {
+				cc = i / assoc;
+				esel = i % assoc;
+				mas2 = cc * 0x1000;
+			}
+
+			mas0 |= MAS0_ESEL(esel);
+			mtspr(SPRN_MAS0, mas0);
+			mtspr(SPRN_MAS1, mas1);
+			mtspr(SPRN_MAS2, mas2);
+			asm volatile("tlbre  0,0,0" : : : "memory");
+			mas1 = mfspr(SPRN_MAS1);
+			mas2 = mfspr(SPRN_MAS2);
+			mas7_mas3 = mfspr(SPRN_MAS7_MAS3);
+			if (assoc && (i % assoc) == 0)
+				new_cc = 1;
+			if (!(mas1 & MAS1_VALID))
+				continue;
+			if (assoc == 0)
+				printf("%04x- ", i);
+			else if (new_cc)
+				printf("%04x-%c", cc, 'A' + esel);
+			else
+				printf("    |%c", 'A' + esel);
+			new_cc = 0;
+			printf(" %016llx %04x %s %c%c AS%c",
+			       mas2 & ~0x3ffull,
+			       (mas1 >> 16) & 0x3fff,
+			       pgsz_names[(mas1 >> 7) & 0x1f],
+			       mas1 & MAS1_IND ? 'I' : ' ',
+			       mas1 & MAS1_IPROT ? 'P' : ' ',
+			       mas1 & MAS1_TS ? '1' : '0');
+			printf(" %c%c%c%c%c%c%c",
+			       mas2 & MAS2_X0 ? 'a' : ' ',
+			       mas2 & MAS2_X1 ? 'v' : ' ',
+			       mas2 & MAS2_W  ? 'w' : ' ',
+			       mas2 & MAS2_I  ? 'i' : ' ',
+			       mas2 & MAS2_M  ? 'm' : ' ',
+			       mas2 & MAS2_G  ? 'g' : ' ',
+			       mas2 & MAS2_E  ? 'e' : ' ');
+			printf(" %016llx", mas7_mas3 & ramask & ~0x7ffull);
+			if (mas1 & MAS1_IND)
+				printf(" %s\n",
+				       pgsz_names[(mas7_mas3 >> 1) & 0x1f]);
+			else
+				printf(" U%c%c%c S%c%c%c\n",
+				       mas7_mas3 & MAS3_UX ? 'x' : ' ',
+				       mas7_mas3 & MAS3_UW ? 'w' : ' ',
+				       mas7_mas3 & MAS3_UR ? 'r' : ' ',
+				       mas7_mas3 & MAS3_SX ? 'x' : ' ',
+				       mas7_mas3 & MAS3_SW ? 'w' : ' ',
+				       mas7_mas3 & MAS3_SR ? 'r' : ' ');
+		}
+	}
+}
+#endif /* CONFIG_PPC_BOOK3E */
+
 static void xmon_init(int enable)
 {
 #ifdef CONFIG_PPC_ISERIES

commit 5be3492f972b73051ead7ecbac6fb9efd1e8e0ec
Author: Anton Blanchard <anton@samba.org>
Date:   Tue Jan 12 00:50:14 2010 +0000

    powerpc: Mark some variables in the page fault path __read_mostly
    
    Using perf to trace L1 dcache misses and dumping data addresses I found a few
    variables taking a lot of misses. Since they are almost never written, they
    should go into the __read_mostly section.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 4e6152c13764..8bad7d5f32af 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -61,7 +61,7 @@ static int xmon_owner;
 static int xmon_gate;
 #endif /* CONFIG_SMP */
 
-static unsigned long in_xmon = 0;
+static unsigned long in_xmon __read_mostly = 0;
 
 static unsigned long adrs;
 static int size = 1;

commit 69ddb57cbea0b3dd851ea5f1edd1e609ad4da04e
Author: Gautham R Shenoy <ego@in.ibm.com>
Date:   Thu Oct 29 19:22:48 2009 +0000

    powerpc/pseries: Add extended_cede_processor() helper function.
    
    This patch provides an extended_cede_processor() helper function
    which takes the cede latency hint as an argument. This hint is to be passed
    on to the hypervisor to cede to the corresponding state on platforms
    which support it.
    
    Signed-off-by: Gautham R Shenoy <ego@in.ibm.com>
    Signed-off-by: Arun R Bharadwaj <arun@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index bdbe96c8a7e4..4e6152c13764 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1641,7 +1641,8 @@ static void super_regs(void)
 			       ptrLpPaca->saved_srr0, ptrLpPaca->saved_srr1);
 			printf("    Saved Gpr3=%.16lx  Saved Gpr4=%.16lx \n",
 			       ptrLpPaca->saved_gpr3, ptrLpPaca->saved_gpr4);
-			printf("    Saved Gpr5=%.16lx \n", ptrLpPaca->saved_gpr5);
+			printf("    Saved Gpr5=%.16lx \n",
+				ptrLpPaca->gpr5_dword.saved_gpr5);
 		}
 #endif
 

commit cdd3904dcc56d9d24ef86be897e421d3cc364226
Author: Josh Boyer <jwboyer@linux.vnet.ibm.com>
Date:   Mon Oct 5 04:46:05 2009 +0000

    powerpc/booke: Fix xmon single step on PowerPC Book-E
    
    Prior to the arch/ppc -> arch/powerpc transition, xmon had support for single
    stepping on 4xx boards.  The functionality was lost when arch/ppc was removed.
    This patch restores single step support for 44x boards, and Book-E in general.
    
    Signed-off-by: Josh Boyer <jwboyer@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index c6f0a71b405e..bdbe96c8a7e4 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -517,6 +517,15 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 	in_xmon = 0;
 #endif
 
+#ifdef CONFIG_BOOKE
+	if (regs->msr & MSR_DE) {
+		bp = at_breakpoint(regs->nip);
+		if (bp != NULL) {
+			regs->nip = (unsigned long) &bp->instr[0];
+			atomic_inc(&bp->ref_count);
+		}
+	}
+#else
 	if ((regs->msr & (MSR_IR|MSR_PR|MSR_SF)) == (MSR_IR|MSR_SF)) {
 		bp = at_breakpoint(regs->nip);
 		if (bp != NULL) {
@@ -530,7 +539,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 			}
 		}
 	}
-
+#endif
 	insert_cpu_bpts();
 
 	local_irq_restore(flags);
@@ -894,6 +903,14 @@ cmds(struct pt_regs *excp)
 	}
 }
 
+#ifdef CONFIG_BOOKE
+static int do_step(struct pt_regs *regs)
+{
+	regs->msr |= MSR_DE;
+	mtspr(SPRN_DBCR0, mfspr(SPRN_DBCR0) | DBCR0_IC | DBCR0_IDM);
+	return 1;
+}
+#else
 /*
  * Step a single instruction.
  * Some instructions we emulate, others we execute with MSR_SE set.
@@ -924,6 +941,7 @@ static int do_step(struct pt_regs *regs)
 	regs->msr |= MSR_SE;
 	return 1;
 }
+#endif
 
 static void bootcmds(void)
 {

commit daf8f40391b2a1978ea2071c20959d91fade6b1a
Author: Josh Boyer <jwboyer@linux.vnet.ibm.com>
Date:   Wed Sep 23 03:51:04 2009 +0000

    powerpc/4xx: Fix erroneous xmon warning on PowerPC 4xx
    
    The xmon code relies on MSR_RI being non-zero to indicate that an exception
    is recoverable.  If it is not, it prints a warning message.  However, the
    PowerPC 4xx cores do not have an MSR_RI bit and this warning is produced for
    every xmon event.
    
    This introduces an unrecoverable_excp function to determine if an exception
    is recoverable or not.  This gets rid of the erroneous warnings on 4xx.
    
    Signed-off-by: Josh Boyer <jwboyer@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 0e09a45ac79a..c6f0a71b405e 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -335,6 +335,16 @@ int cpus_are_in_xmon(void)
 }
 #endif
 
+static inline int unrecoverable_excp(struct pt_regs *regs)
+{
+#ifdef CONFIG_4xx
+	/* We have no MSR_RI bit on 4xx, so we simply return false */
+	return 0;
+#else
+	return ((regs->msr & MSR_RI) == 0);
+#endif
+}
+
 static int xmon_core(struct pt_regs *regs, int fromipi)
 {
 	int cmd = 0;
@@ -388,7 +398,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 	bp = NULL;
 	if ((regs->msr & (MSR_IR|MSR_PR|MSR_SF)) == (MSR_IR|MSR_SF))
 		bp = at_breakpoint(regs->nip);
-	if (bp || (regs->msr & MSR_RI) == 0)
+	if (bp || unrecoverable_excp(regs))
 		fromipi = 0;
 
 	if (!fromipi) {
@@ -399,7 +409,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 			       cpu, BP_NUM(bp));
 			xmon_print_symbol(regs->nip, " ", ")\n");
 		}
-		if ((regs->msr & MSR_RI) == 0)
+		if (unrecoverable_excp(regs))
 			printf("WARNING: exception is not recoverable, "
 			       "can't continue\n");
 		release_output_lock();
@@ -490,7 +500,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 			printf("Stopped at breakpoint %x (", BP_NUM(bp));
 			xmon_print_symbol(regs->nip, " ", ")\n");
 		}
-		if ((regs->msr & MSR_RI) == 0)
+		if (unrecoverable_excp(regs))
 			printf("WARNING: exception is not recoverable, "
 			       "can't continue\n");
 		remove_bpts();

commit 2d27cfd3286966c04d4192a9db5a6c7ea60eebf1
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Jul 23 23:15:59 2009 +0000

    powerpc: Remaining 64-bit Book3E support
    
    This contains all the bits that didn't fit in previous patches :-) This
    includes the actual exception handlers assembly, the changes to the
    kernel entry, other misc bits and wiring it all up in Kconfig.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index e1f33a81e5e1..0e09a45ac79a 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2570,7 +2570,7 @@ static void xmon_print_symbol(unsigned long address, const char *mid,
 	printf("%s", after);
 }
 
-#ifdef CONFIG_PPC64
+#ifdef CONFIG_PPC_BOOK3S_64
 static void dump_slb(void)
 {
 	int i;

commit 6d1386d517e2b9b0de994cc47b1e490db7972a2a
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Tue Jun 2 18:15:33 2009 +0000

    powerpc/xmon: Remove unused variable in xmon.c
    
    Gets rid of this warning:
    
    arch/powerpc/xmon/xmon.c: In function 'dump_log_buf':
    arch/powerpc/xmon/xmon.c:2133: warning: unused variable 'i'
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 08121d3e47ba..e1f33a81e5e1 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2130,7 +2130,7 @@ void
 dump_log_buf(void)
 {
         const unsigned long size = 128;
-        unsigned long i, end, addr;
+        unsigned long end, addr;
         unsigned char buf[size + 1];
 
         addr = 0;

commit f312deb4cd0c88196edf6dab192b7d42514398d6
Author: Vinay Sridhar <vinay@linux.vnet.ibm.com>
Date:   Thu May 14 23:13:07 2009 +0000

    powerpc/xmon: Add dl command to dump contents of __log_buf
    
    Hello All,
    
    Quite a while back Michael Ellerman had posted a patch to add support to xmon to print the contents of the console log pointed to by __log_buf.
    Here's the link to that patch - http://ozlabs.org/pipermail/linuxppc64-dev/2005-March/003657.html
    I've ported the patch in the above link to 2.6.30-rc5 and have tested it.
    
    Thanks & regards,
    Vinay
    
    Signed-off-by: Michael Ellerman <michael at ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 8dfad7d9a004..08121d3e47ba 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -110,6 +110,7 @@ static int bsesc(void);
 static void dump(void);
 static void prdump(unsigned long, long);
 static int ppc_inst_dump(unsigned long, long, int);
+static void dump_log_buf(void);
 static void backtrace(struct pt_regs *);
 static void excprint(struct pt_regs *);
 static void prregs(struct pt_regs *);
@@ -197,6 +198,7 @@ Commands:\n\
   di	dump instructions\n\
   df	dump float values\n\
   dd	dump double values\n\
+  dl    dump the kernel log buffer\n\
   dr	dump stream of raw bytes\n\
   e	print exception information\n\
   f	flush cache\n\
@@ -2009,6 +2011,8 @@ dump(void)
 			nidump = MAX_DUMP;
 		adrs += ppc_inst_dump(adrs, nidump, 1);
 		last_cmd = "di\n";
+	} else if (c == 'l') {
+		dump_log_buf();
 	} else if (c == 'r') {
 		scanhex(&ndump);
 		if (ndump == 0)
@@ -2122,6 +2126,49 @@ print_address(unsigned long addr)
 	xmon_print_symbol(addr, "\t# ", "");
 }
 
+void
+dump_log_buf(void)
+{
+        const unsigned long size = 128;
+        unsigned long i, end, addr;
+        unsigned char buf[size + 1];
+
+        addr = 0;
+        buf[size] = '\0';
+
+        if (setjmp(bus_error_jmp) != 0) {
+                printf("Unable to lookup symbol __log_buf!\n");
+                return;
+        }
+
+        catch_memory_errors = 1;
+        sync();
+        addr = kallsyms_lookup_name("__log_buf");
+
+        if (! addr)
+                printf("Symbol __log_buf not found!\n");
+        else {
+                end = addr + (1 << CONFIG_LOG_BUF_SHIFT);
+                while (addr < end) {
+                        if (! mread(addr, buf, size)) {
+                                printf("Can't read memory at address 0x%lx\n", addr);
+                                break;
+                        }
+
+                        printf("%s", buf);
+
+                        if (strlen(buf) < size)
+                                break;
+
+                        addr += size;
+                }
+        }
+
+        sync();
+        /* wait a little while to see if we get a machine check */
+        __delay(200);
+        catch_memory_errors = 0;
+}
 
 /*
  * Memory operations - move, set, print differences

commit 322b439455ea62e6480e300c77b258e872896381
Author: Anton Vorontsov <avorontsov@ru.mvista.com>
Date:   Wed Dec 17 10:08:55 2008 +0000

    powerpc: Prepare xmon_save_regs for use with kdump
    
    Today the arch/powerpc/xmon/setjmp.S file contains only the
    xmon_save_regs function.  We want to use it for kdump purposes, so
    let's move the file into arch/powerpc/kernel/ and give the function a
    more generic name (ppc_save_regs).
    
    Signed-off-by: Anton Vorontsov <avorontsov@ru.mvista.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 076368c8b8a9..8dfad7d9a004 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -41,6 +41,7 @@
 #include <asm/spu_priv1.h>
 #include <asm/firmware.h>
 #include <asm/setjmp.h>
+#include <asm/reg.h>
 
 #ifdef CONFIG_PPC64
 #include <asm/hvcall.h>
@@ -159,8 +160,6 @@ static int xmon_no_auto_backtrace;
 extern void xmon_enter(void);
 extern void xmon_leave(void);
 
-extern void xmon_save_regs(struct pt_regs *);
-
 #ifdef CONFIG_PPC64
 #define REG		"%.16lx"
 #define REGS_PER_LINE	4
@@ -532,7 +531,7 @@ int xmon(struct pt_regs *excp)
 	struct pt_regs regs;
 
 	if (excp == NULL) {
-		xmon_save_regs(&regs);
+		ppc_save_regs(&regs);
 		excp = &regs;
 	}
 

commit ebdba9af940d63e469dc8e46b4aa1fc474e8ee2d
Author: Paul Mackerras <paulus@samba.org>
Date:   Fri Oct 31 21:34:09 2008 +1100

    powerpc: Fix compile errors with CONFIG_BUG=n
    
    This makes sure we don't try to call find_bug or is_warning_bug when
    CONFIG_BUG=n and CONFIG_XMON=y.  Otherwise we get these errors:
    
    arch/powerpc/xmon/xmon.c: In function âprint_bug_trapâ:
    arch/powerpc/xmon/xmon.c:1364: error: implicit declaration of function âfind_bugâ
    arch/powerpc/xmon/xmon.c:1364: warning: assignment makes pointer from integer without a cast
    arch/powerpc/xmon/xmon.c:1367: error: implicit declaration of function âis_warning_bugâ
    arch/powerpc/xmon/xmon.c:1374: error: dereferencing pointer to incomplete type
    make[2]: *** [arch/powerpc/xmon/xmon.o] Error 1
    make[1]: *** [arch/powerpc/xmon] Error 2
    make: *** [sub-make] Error 2
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 34c3d0688fe0..076368c8b8a9 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1353,6 +1353,7 @@ static void backtrace(struct pt_regs *excp)
 
 static void print_bug_trap(struct pt_regs *regs)
 {
+#ifdef CONFIG_BUG
 	const struct bug_entry *bug;
 	unsigned long addr;
 
@@ -1373,6 +1374,7 @@ static void print_bug_trap(struct pt_regs *regs)
 #else
 	printf("kernel BUG at %p!\n", (void *)bug->bug_addr);
 #endif
+#endif /* CONFIG_BUG */
 }
 
 static void excprint(struct pt_regs *fp)

commit e9a4b6a3f6592862a67837e80aad3f50468857a6
Merge: 441dbb500b43 1702b52092e9
Author: Paul Mackerras <paulus@samba.org>
Date:   Mon Jun 30 10:16:50 2008 +1000

    Merge branch 'linux-2.6'

commit 1f64643aa5f5a17f1723f7ea0f17b7a3a8f632b3
Author: Luke Browning <lukebrowning@us.ibm.com>
Date:   Thu Jun 5 17:30:25 2008 +0800

    powerpc/spufs: remove class_0_dsisr from spu exception handling
    
    According to the CBEA, the SPU dsisr is not updated for class 0
    exceptions.
    
    spu_stopped() is testing the dsisr that was passed to it from the class
    0 exception handler, so we return a false positive here.
    
    This patch cleans up the interrupt handler and erroneous tests in
    spu_stopped. It also removes the fields from the csa since it is not
    needed to process class 0 events.
    
    Signed-off-by: Luke Browning <lukebrowning@us.ibm.com>
    Signed-off-by: Jeremy Kerr <jk@ozlabs.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 1702de9395ee..bfcf70ee8959 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2844,7 +2844,6 @@ static void dump_spu_fields(struct spu *spu)
 	DUMP_FIELD(spu, "0x%lx", flags);
 	DUMP_FIELD(spu, "%d", class_0_pending);
 	DUMP_FIELD(spu, "0x%lx", class_0_dar);
-	DUMP_FIELD(spu, "0x%lx", class_0_dsisr);
 	DUMP_FIELD(spu, "0x%lx", class_1_dar);
 	DUMP_FIELD(spu, "0x%lx", class_1_dsisr);
 	DUMP_FIELD(spu, "0x%lx", irqs[0]);

commit 1c8950ff87de950a3b6ccfb26650fc0a56278836
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu May 8 14:27:17 2008 +1000

    [POWERPC] Make cpus_in_xmon static and remove extern mess from hvc_console.c
    
    This is a little messier than I'd like because xmon.h only exists
    on powerpc and we can't have a static inline and an extern declaration
    visible at the same time.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 95f24c9822b1..6726da07c065 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -54,7 +54,7 @@
 #define skipbl	xmon_skipbl
 
 #ifdef CONFIG_SMP
-cpumask_t cpus_in_xmon = CPU_MASK_NONE;
+static cpumask_t cpus_in_xmon = CPU_MASK_NONE;
 static unsigned long xmon_taken = 1;
 static int xmon_owner;
 static int xmon_gate;
@@ -327,6 +327,11 @@ static void release_output_lock(void)
 {
 	xmon_speaker = 0;
 }
+
+int cpus_are_in_xmon(void)
+{
+	return !cpus_empty(cpus_in_xmon);
+}
 #endif
 
 static int xmon_core(struct pt_regs *regs, int fromipi)

commit 9f1067c2d98ac1c43f0c82892f5647774a6ac759
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu May 8 14:27:16 2008 +1000

    [POWERPC] Fix sparse warnings in xmon.c
    
    warning: Using plain integer as NULL pointer
    warning: Using plain integer as NULL pointer
    warning: symbol 'excprint' was not declared. Should it be static?
    warning: symbol 'prregs' was not declared. Should it be static?
    warning: symbol 'cacheflush' was not declared. Should it be static?
    warning: symbol 'read_spr' was not declared. Should it be static?
    warning: symbol 'write_spr' was not declared. Should it be static?
    warning: symbol 'super_regs' was not declared. Should it be static?
    warning: symbol 'mread' was not declared. Should it be static?
    warning: symbol 'mwrite' was not declared. Should it be static?
    warning: symbol 'byterev' was not declared. Should it be static?
    warning: symbol 'memex' was not declared. Should it be static?
    warning: symbol 'bsesc' was not declared. Should it be static?
    warning: symbol 'dump' was not declared. Should it be static?
    warning: symbol 'prdump' was not declared. Should it be static?
    warning: symbol 'generic_inst_dump' was not declared. Should it be static?
    warning: symbol 'ppc_inst_dump' was not declared. Should it be static?
    warning: symbol 'memops' was not declared. Should it be static?
    warning: symbol 'memdiffs' was not declared. Should it be static?
    warning: symbol 'memlocate' was not declared. Should it be static?
    warning: symbol 'memzcan' was not declared. Should it be static?
    warning: symbol 'proccall' was not declared. Should it be static?
    warning: symbol 'scannl' was not declared. Should it be static?
    warning: symbol 'hexdigit' was not declared. Should it be static?
    warning: symbol 'flush_input' was not declared. Should it be static?
    warning: symbol 'inchar' was not declared. Should it be static?
    warning: symbol 'take_input' was not declared. Should it be static?
    warning: symbol 'xmon_init' was not declared. Should it be static?
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 1702de9395ee..95f24c9822b1 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -154,7 +154,7 @@ static int do_spu_cmd(void);
 static void dump_tlb_44x(void);
 #endif
 
-int xmon_no_auto_backtrace;
+static int xmon_no_auto_backtrace;
 
 extern void xmon_enter(void);
 extern void xmon_leave(void);
@@ -593,7 +593,7 @@ static int xmon_iabr_match(struct pt_regs *regs)
 {
 	if ((regs->msr & (MSR_IR|MSR_PR|MSR_SF)) != (MSR_IR|MSR_SF))
 		return 0;
-	if (iabr == 0)
+	if (iabr == NULL)
 		return 0;
 	xmon_core(regs, 0);
 	return 1;
@@ -1142,7 +1142,7 @@ bpt_cmds(void)
 		} else {
 			/* assume a breakpoint address */
 			bp = at_breakpoint(a);
-			if (bp == 0) {
+			if (bp == NULL) {
 				printf("No breakpoint at %x\n", a);
 				break;
 			}
@@ -1370,7 +1370,7 @@ static void print_bug_trap(struct pt_regs *regs)
 #endif
 }
 
-void excprint(struct pt_regs *fp)
+static void excprint(struct pt_regs *fp)
 {
 	unsigned long trap;
 
@@ -1408,7 +1408,7 @@ void excprint(struct pt_regs *fp)
 		print_bug_trap(fp);
 }
 
-void prregs(struct pt_regs *fp)
+static void prregs(struct pt_regs *fp)
 {
 	int n, trap;
 	unsigned long base;
@@ -1463,7 +1463,7 @@ void prregs(struct pt_regs *fp)
 		printf("dar = "REG"   dsisr = %.8lx\n", fp->dar, fp->dsisr);
 }
 
-void cacheflush(void)
+static void cacheflush(void)
 {
 	int cmd;
 	unsigned long nflush;
@@ -1495,7 +1495,7 @@ void cacheflush(void)
 	catch_memory_errors = 0;
 }
 
-unsigned long
+static unsigned long
 read_spr(int n)
 {
 	unsigned int instrs[2];
@@ -1533,7 +1533,7 @@ read_spr(int n)
 	return ret;
 }
 
-void
+static void
 write_spr(int n, unsigned long val)
 {
 	unsigned int instrs[2];
@@ -1571,7 +1571,7 @@ static unsigned long regno;
 extern char exc_prolog;
 extern char dec_exc;
 
-void super_regs(void)
+static void super_regs(void)
 {
 	int cmd;
 	unsigned long val;
@@ -1629,7 +1629,7 @@ void super_regs(void)
 /*
  * Stuff for reading and writing memory safely
  */
-int
+static int
 mread(unsigned long adrs, void *buf, int size)
 {
 	volatile int n;
@@ -1666,7 +1666,7 @@ mread(unsigned long adrs, void *buf, int size)
 	return n;
 }
 
-int
+static int
 mwrite(unsigned long adrs, void *buf, int size)
 {
 	volatile int n;
@@ -1731,7 +1731,7 @@ static int handle_fault(struct pt_regs *regs)
 
 #define SWAP(a, b, t)	((t) = (a), (a) = (b), (b) = (t))
 
-void
+static void
 byterev(unsigned char *val, int size)
 {
 	int t;
@@ -1793,7 +1793,7 @@ static char *memex_subcmd_help_string =
     "  x        exit this mode\n"
     "";
 
-void
+static void
 memex(void)
 {
 	int cmd, inc, i, nslash;
@@ -1944,7 +1944,7 @@ memex(void)
 	}
 }
 
-int
+static int
 bsesc(void)
 {
 	int c;
@@ -1984,7 +1984,7 @@ static void xmon_rawdump (unsigned long adrs, long ndump)
 #define isxdigit(c)	(('0' <= (c) && (c) <= '9') \
 			 || ('a' <= (c) && (c) <= 'f') \
 			 || ('A' <= (c) && (c) <= 'F'))
-void
+static void
 dump(void)
 {
 	int c;
@@ -2022,7 +2022,7 @@ dump(void)
 	}
 }
 
-void
+static void
 prdump(unsigned long adrs, long ndump)
 {
 	long n, m, c, r, nr;
@@ -2066,7 +2066,7 @@ prdump(unsigned long adrs, long ndump)
 
 typedef int (*instruction_dump_func)(unsigned long inst, unsigned long addr);
 
-int
+static int
 generic_inst_dump(unsigned long adr, long count, int praddr,
 			instruction_dump_func dump_func)
 {
@@ -2104,7 +2104,7 @@ generic_inst_dump(unsigned long adr, long count, int praddr,
 	return adr - first_adr;
 }
 
-int
+static int
 ppc_inst_dump(unsigned long adr, long count, int praddr)
 {
 	return generic_inst_dump(adr, count, praddr, print_insn_powerpc);
@@ -2126,7 +2126,7 @@ static unsigned long mval;		/* byte value to set memory to */
 static unsigned long mcount;		/* # bytes to affect */
 static unsigned long mdiffs;		/* max # differences to print */
 
-void
+static void
 memops(int cmd)
 {
 	scanhex((void *)&mdest);
@@ -2152,7 +2152,7 @@ memops(int cmd)
 	}
 }
 
-void
+static void
 memdiffs(unsigned char *p1, unsigned char *p2, unsigned nb, unsigned maxpr)
 {
 	unsigned n, prt;
@@ -2170,7 +2170,7 @@ memdiffs(unsigned char *p1, unsigned char *p2, unsigned nb, unsigned maxpr)
 static unsigned mend;
 static unsigned mask;
 
-void
+static void
 memlocate(void)
 {
 	unsigned a, n;
@@ -2203,7 +2203,7 @@ memlocate(void)
 static unsigned long mskip = 0x1000;
 static unsigned long mlim = 0xffffffff;
 
-void
+static void
 memzcan(void)
 {
 	unsigned char v;
@@ -2230,7 +2230,7 @@ memzcan(void)
 		printf("%.8x\n", a - mskip);
 }
 
-void proccall(void)
+static void proccall(void)
 {
 	unsigned long args[8];
 	unsigned long ret;
@@ -2388,7 +2388,7 @@ scanhex(unsigned long *vp)
 	return 1;
 }
 
-void
+static void
 scannl(void)
 {
 	int c;
@@ -2399,7 +2399,7 @@ scannl(void)
 		c = inchar();
 }
 
-int hexdigit(int c)
+static int hexdigit(int c)
 {
 	if( '0' <= c && c <= '9' )
 		return c - '0';
@@ -2430,13 +2430,13 @@ getstring(char *s, int size)
 static char line[256];
 static char *lineptr;
 
-void
+static void
 flush_input(void)
 {
 	lineptr = NULL;
 }
 
-int
+static int
 inchar(void)
 {
 	if (lineptr == NULL || *lineptr == 0) {
@@ -2449,7 +2449,7 @@ inchar(void)
 	return *lineptr++;
 }
 
-void
+static void
 take_input(char *str)
 {
 	lineptr = str;
@@ -2618,7 +2618,8 @@ static void dump_tlb_44x(void)
 	}
 }
 #endif /* CONFIG_44x */
-void xmon_init(int enable)
+
+static void xmon_init(int enable)
 {
 #ifdef CONFIG_PPC_ISERIES
 	if (firmware_has_feature(FW_FEATURE_ISERIES))

commit f3d69e0507f84903059d456c5d19f10b2df3ac69
Author: Luke Browning <lukebr@linux.vnet.ibm.com>
Date:   Sun Apr 27 18:41:55 2008 +0000

    [POWERPC] spufs: fix concurrent delivery of class 0 & 1 exceptions
    
    SPU class 0 & 1 exceptions may occur in parallel, so we may end up
    overwriting csa.dsisr.
    
    This change adds dedicated fields for each class to the spu and the spu
    context so that fault data is not overwritten.
    
    Signed-off-by: Luke Browning <lukebr@linux.vnet.ibm.com>
    Signed-off-by: Jeremy Kerr <jk@ozlabs.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 52c74780f403..1702de9395ee 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2842,9 +2842,11 @@ static void dump_spu_fields(struct spu *spu)
 	DUMP_FIELD(spu, "0x%lx", ls_size);
 	DUMP_FIELD(spu, "0x%x", node);
 	DUMP_FIELD(spu, "0x%lx", flags);
-	DUMP_FIELD(spu, "0x%lx", dar);
-	DUMP_FIELD(spu, "0x%lx", dsisr);
 	DUMP_FIELD(spu, "%d", class_0_pending);
+	DUMP_FIELD(spu, "0x%lx", class_0_dar);
+	DUMP_FIELD(spu, "0x%lx", class_0_dsisr);
+	DUMP_FIELD(spu, "0x%lx", class_1_dar);
+	DUMP_FIELD(spu, "0x%lx", class_1_dsisr);
 	DUMP_FIELD(spu, "0x%lx", irqs[0]);
 	DUMP_FIELD(spu, "0x%lx", irqs[1]);
 	DUMP_FIELD(spu, "0x%lx", irqs[2]);

commit ec2b36b9f23cfbbe94d89724b796b44fd57d5221
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Apr 17 14:34:59 2008 +1000

    [POWERPC] Move stackframe definitions to common header
    
    This moves various definitions used all over the place to parse stack
    frames to ptrace.h so only one definition is needed.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 00fd7647f807..52c74780f403 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1243,15 +1243,12 @@ static void get_function_bounds(unsigned long pc, unsigned long *startp,
 
 static int xmon_depth_to_print = 64;
 
-#ifdef CONFIG_PPC64
-#define LRSAVE_OFFSET		0x10
-#define REG_FRAME_MARKER	0x7265677368657265ul	/* "regshere" */
-#define MARKER_OFFSET		0x60
+#define LRSAVE_OFFSET		(STACK_FRAME_LR_SAVE * sizeof(unsigned long))
+#define MARKER_OFFSET		(STACK_FRAME_MARKER * sizeof(unsigned long))
+
+#ifdef __powerpc64__
 #define REGS_OFFSET		0x70
 #else
-#define LRSAVE_OFFSET		4
-#define REG_FRAME_MARKER	0x72656773
-#define MARKER_OFFSET		8
 #define REGS_OFFSET		16
 #endif
 
@@ -1317,7 +1314,7 @@ static void xmon_show_stack(unsigned long sp, unsigned long lr,
 		/* Look for "regshere" marker to see if this is
 		   an exception frame. */
 		if (mread(sp + MARKER_OFFSET, &marker, sizeof(unsigned long))
-		    && marker == REG_FRAME_MARKER) {
+		    && marker == STACK_FRAME_REGS_MARKER) {
 			if (mread(sp + REGS_OFFSET, &regs, sizeof(regs))
 			    != sizeof(regs)) {
 				printf("Couldn't read registers at %lx\n",

commit 30ff2e87ed55e83b4eb436f5f14a7e49ff81ad99
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Thu Apr 10 16:43:47 2008 +1000

    [POWERPC] iSeries: Make iseries_reg_save private to iSeries
    
    Now that we have the alpaca, the reg_save_ptr is no longer needed in the
    paca.  Eradicate all global uses of it and make it static in the iSeries
    lpardata.c
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index a34172ddc468..00fd7647f807 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -45,7 +45,6 @@
 #ifdef CONFIG_PPC64
 #include <asm/hvcall.h>
 #include <asm/paca.h>
-#include <asm/iseries/it_lp_reg_save.h>
 #endif
 
 #include "nonstdio.h"
@@ -1598,7 +1597,6 @@ void super_regs(void)
 		if (firmware_has_feature(FW_FEATURE_ISERIES)) {
 			struct paca_struct *ptrPaca;
 			struct lppaca *ptrLpPaca;
-			struct ItLpRegSave *ptrLpRegSave;
 
 			/* Dump out relevant Paca data areas. */
 			printf("Paca: \n");
@@ -1611,15 +1609,6 @@ void super_regs(void)
 			printf("    Saved Gpr3=%.16lx  Saved Gpr4=%.16lx \n",
 			       ptrLpPaca->saved_gpr3, ptrLpPaca->saved_gpr4);
 			printf("    Saved Gpr5=%.16lx \n", ptrLpPaca->saved_gpr5);
-
-			printf("  Local Processor Register Save Area (LpRegSave): \n");
-			ptrLpRegSave = ptrPaca->reg_save_ptr;
-			printf("    Saved Sprg0=%.16lx  Saved Sprg1=%.16lx \n",
-			       ptrLpRegSave->xSPRG0, ptrLpRegSave->xSPRG0);
-			printf("    Saved Sprg2=%.16lx  Saved Sprg3=%.16lx \n",
-			       ptrLpRegSave->xSPRG2, ptrLpRegSave->xSPRG3);
-			printf("    Saved Msr  =%.16lx  Saved Nia  =%.16lx \n",
-			       ptrLpRegSave->xMSR, ptrLpRegSave->xNIA);
 		}
 #endif
 

commit c3b75bd7bbf4a0438dc140033b80657995fd30ed
Author: Michael Neuling <mikey@neuling.org>
Date:   Fri Jan 18 15:50:30 2008 +1100

    [POWERPC] Make setjmp/longjmp code usable outside of xmon
    
    This makes the setjmp/longjmp code used by xmon, generically available
    to other code.  It also removes the requirement for debugger hooks to
    be only called on 0x300 (data storage) exception.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 865e36751f21..a34172ddc468 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -40,6 +40,7 @@
 #include <asm/spu.h>
 #include <asm/spu_priv1.h>
 #include <asm/firmware.h>
+#include <asm/setjmp.h>
 
 #ifdef CONFIG_PPC64
 #include <asm/hvcall.h>
@@ -71,12 +72,9 @@ static unsigned long ncsum = 4096;
 static int termch;
 static char tmpstr[128];
 
-#define JMP_BUF_LEN	23
 static long bus_error_jmp[JMP_BUF_LEN];
 static int catch_memory_errors;
 static long *xmon_fault_jmp[NR_CPUS];
-#define setjmp xmon_setjmp
-#define longjmp xmon_longjmp
 
 /* Breakpoint stuff */
 struct bpt {
@@ -162,8 +160,6 @@ int xmon_no_auto_backtrace;
 extern void xmon_enter(void);
 extern void xmon_leave(void);
 
-extern long setjmp(long *);
-extern void longjmp(long *, long);
 extern void xmon_save_regs(struct pt_regs *);
 
 #ifdef CONFIG_PPC64

commit b3b9595f50f73f0d53ebd71c463c5f09a6e64a21
Author: will schmidt <will_schmidt@vnet.ibm.com>
Date:   Fri Dec 7 08:22:23 2007 +1100

    [POWERPC] Update xmon slb code
    
    This adds a bit more detail to the xmon SLB output.  When the valid
    bit is set, this displays the ESID and VSID values, as well as
    decoding the segment size -- 1T or 256M -- and displaying the LLP
    bits.  This supresses the output for any slb entries that contain only
    zeros.
    
    sample output from power6 (1T segment support):
    00 c000000008000000 40004f7ca3000500  1T  ESID=   c00000  VSID=       4f7ca3 LLP:100
    01 d000000008000000 4000eb71b0000400  1T  ESID=   d00000  VSID=       eb71b0 LLP:  0
    08 0000000018000000 0000c8499f8ccc80 256M ESID=        1  VSID=    c8499f8cc LLP:  0
    09 00000000f8000000 0000d2c1a8e46c80 256M ESID=        f  VSID=    d2c1a8e46 LLP:  0
    10 0000000048000000 0000ca87eab1dc80 256M ESID=        4  VSID=    ca87eab1d LLP:  0
    43 cf00000008000000 400011b260000500  1T  ESID=   cf0000  VSID=       11b260 LLP:100
    
    sample output from power5 (notice the non-valid but non-zero entries)
    10 0000000008000000 00004fd0e077ac80 256M ESID=        0  VSID=    4fd0e077a LLP:  0
    11 00000000f8000000 00005b085830fc80 256M ESID=        f  VSID=    5b085830f LLP:  0
    12 0000000048000000 000052ce99fe6c80 256M ESID=        4  VSID=    52ce99fe6 LLP:  0
    13 0000000018000000 000050904ed95c80 256M ESID=        1  VSID=    50904ed95 LLP:  0
    14 cf00000008000000 0000d59aca40f500 256M ESID=cf0000000  VSID=    d59aca40f LLP:100
    15 c000000078000000 000045cb97751500 256M ESID=c00000007  VSID=    45cb97751 LLP:100
    
    Tested on power5 and power6.
    
    Signed-Off-By: Will Schmidt <will_schmidt@vnet.ibm.com>
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index c60d123e9f1f..865e36751f21 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2539,16 +2539,33 @@ static void xmon_print_symbol(unsigned long address, const char *mid,
 static void dump_slb(void)
 {
 	int i;
-	unsigned long tmp;
+	unsigned long esid,vsid,valid;
+	unsigned long llp;
 
 	printf("SLB contents of cpu %x\n", smp_processor_id());
 
 	for (i = 0; i < mmu_slb_size; i++) {
-		asm volatile("slbmfee  %0,%1" : "=r" (tmp) : "r" (i));
-		printf("%02d %016lx ", i, tmp);
-
-		asm volatile("slbmfev  %0,%1" : "=r" (tmp) : "r" (i));
-		printf("%016lx\n", tmp);
+		asm volatile("slbmfee  %0,%1" : "=r" (esid) : "r" (i));
+		asm volatile("slbmfev  %0,%1" : "=r" (vsid) : "r" (i));
+		valid = (esid & SLB_ESID_V);
+		if (valid | esid | vsid) {
+			printf("%02d %016lx %016lx", i, esid, vsid);
+			if (valid) {
+				llp = vsid & SLB_VSID_LLP;
+				if (vsid & SLB_VSID_B_1T) {
+					printf("  1T  ESID=%9lx  VSID=%13lx LLP:%3lx \n",
+						GET_ESID_1T(esid),
+						(vsid & ~SLB_VSID_B) >> SLB_VSID_SHIFT_1T,
+						llp);
+				} else {
+					printf(" 256M ESID=%9lx  VSID=%13lx LLP:%3lx \n",
+						GET_ESID(esid),
+						(vsid & ~SLB_VSID_B) >> SLB_VSID_SHIFT,
+						llp);
+				}
+			} else
+				printf("\n");
+		}
 	}
 }
 

commit 584f8b71a2e8abdaeb4b6f4fddaf542b61392453
Author: Michael Neuling <mikey@neuling.org>
Date:   Thu Dec 6 17:24:48 2007 +1100

    [POWERPC] Use SLB size from the device tree
    
    Currently we hardwire the number of SLBs to 64, but PAPR says we
    should use the ibm,slb-size property to obtain the number of SLB
    entries.  This uses this property instead of assuming 64.  If no
    property is found, we assume 64 entries as before.
    
    This soft patches the SLB handler, so it shouldn't change performance
    at all.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 381d467cf55b..c60d123e9f1f 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2543,7 +2543,7 @@ static void dump_slb(void)
 
 	printf("SLB contents of cpu %x\n", smp_processor_id());
 
-	for (i = 0; i < SLB_NUM_ENTRIES; i++) {
+	for (i = 0; i < mmu_slb_size; i++) {
 		asm volatile("slbmfee  %0,%1" : "=r" (tmp) : "r" (i));
 		printf("%02d %016lx ", i, tmp);
 

commit 5a8a1a28bb35a62561367c0a1144dbc5dcb95230
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Nov 16 18:23:33 2007 +1100

    [POWERPC] Add xmon function to dump 44x TLB
    
    This adds a function to xmon to dump the content of the 44x processor
    TLB with a little bit of decoding (but not much).
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 121b04d165d1..381d467cf55b 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -153,6 +153,10 @@ static const char *getvecname(unsigned long vec);
 
 static int do_spu_cmd(void);
 
+#ifdef CONFIG_44x
+static void dump_tlb_44x(void);
+#endif
+
 int xmon_no_auto_backtrace;
 
 extern void xmon_enter(void);
@@ -231,6 +235,9 @@ Commands:\n\
 #ifdef CONFIG_PPC_STD_MMU_32
 "  u	dump segment registers\n"
 #endif
+#ifdef CONFIG_44x
+"  u	dump TLB\n"
+#endif
 "  ?	help\n"
 "  zr	reboot\n\
   zh	halt\n"
@@ -855,6 +862,11 @@ cmds(struct pt_regs *excp)
 		case 'u':
 			dump_segments();
 			break;
+#endif
+#ifdef CONFIG_4xx
+		case 'u':
+			dump_tlb_44x();
+			break;
 #endif
 		default:
 			printf("Unrecognized command: ");
@@ -2581,6 +2593,32 @@ void dump_segments(void)
 }
 #endif
 
+#ifdef CONFIG_44x
+static void dump_tlb_44x(void)
+{
+	int i;
+
+	for (i = 0; i < PPC44x_TLB_SIZE; i++) {
+		unsigned long w0,w1,w2;
+		asm volatile("tlbre  %0,%1,0" : "=r" (w0) : "r" (i));
+		asm volatile("tlbre  %0,%1,1" : "=r" (w1) : "r" (i));
+		asm volatile("tlbre  %0,%1,2" : "=r" (w2) : "r" (i));
+		printf("[%02x] %08x %08x %08x ", i, w0, w1, w2);
+		if (w0 & PPC44x_TLB_VALID) {
+			printf("V %08x -> %01x%08x %c%c%c%c%c",
+			       w0 & PPC44x_TLB_EPN_MASK,
+			       w1 & PPC44x_TLB_ERPN_MASK,
+			       w1 & PPC44x_TLB_RPN_MASK,
+			       (w2 & PPC44x_TLB_W) ? 'W' : 'w',
+			       (w2 & PPC44x_TLB_I) ? 'I' : 'i',
+			       (w2 & PPC44x_TLB_M) ? 'M' : 'm',
+			       (w2 & PPC44x_TLB_G) ? 'G' : 'g',
+			       (w2 & PPC44x_TLB_E) ? 'E' : 'e');
+		}
+		printf("\n");
+	}
+}
+#endif /* CONFIG_44x */
 void xmon_init(int enable)
 {
 #ifdef CONFIG_PPC_ISERIES

commit 4d404edce30f911004850d472e05a31efd751662
Author: Ishizaki Kou <kou.ishizaki@toshiba.co.jp>
Date:   Wed Jul 18 19:26:40 2007 +1000

    [POWERPC] fix showing xmon help
    
    In some configuration, xmon help string is larger than xmon_printf
    buffer.  We need not to use printf.  This patch adds xmon_puts and
    change to use it to show help string.
    
    Signed-off-by: Kou Ishizaki <kou.ishizaki@toshiba.co.jp>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 669e6566ad70..121b04d165d1 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -833,7 +833,7 @@ cmds(struct pt_regs *excp)
 			mdelay(2000);
 			return cmd;
 		case '?':
-			printf(help_string);
+			xmon_puts(help_string);
 			break;
 		case 'b':
 			bpt_cmds();

commit f5e6a280d153bff3b0cd15651d29d409f8dea698
Author: Olaf Hering <olaf@aepfle.de>
Date:   Sun Jun 24 16:57:08 2007 +1000

    [POWERPC] Make two xmon variables static
    
    xmon_early and xmon_off are only used in this file.
    
    Signed-off-by: Olaf Hering <olaf@aepfle.de>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 28fdf4f50c27..669e6566ad70 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2634,7 +2634,7 @@ static int __init setup_xmon_sysrq(void)
 __initcall(setup_xmon_sysrq);
 #endif /* CONFIG_MAGIC_SYSRQ */
 
-int __initdata xmon_early, xmon_off;
+static int __initdata xmon_early, xmon_off;
 
 static int __init early_parse_xmon(char *p)
 {

commit ffb45122766db220d0bf3d01848d575fbbcb6430
Author: Alexey Dobriyan <adobriyan@sw.ru>
Date:   Tue May 8 00:28:41 2007 -0700

    Simplify kallsyms_lookup()
    
    Several kallsyms_lookup() pass dummy arguments but only need, say, module's
    name.  Make kallsyms_lookup() accept NULLs where possible.
    
    Also, makes picture clearer about what interfaces are needed for all symbol
    resolving business.
    
    Signed-off-by: Alexey Dobriyan <adobriyan@sw.ru>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Acked-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index b481db1dacb4..28fdf4f50c27 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1217,7 +1217,6 @@ static void get_function_bounds(unsigned long pc, unsigned long *startp,
 {
 	unsigned long size, offset;
 	const char *name;
-	char *modname;
 
 	*startp = *endp = 0;
 	if (pc == 0)
@@ -1225,7 +1224,7 @@ static void get_function_bounds(unsigned long pc, unsigned long *startp,
 	if (setjmp(bus_error_jmp) == 0) {
 		catch_memory_errors = 1;
 		sync();
-		name = kallsyms_lookup(pc, &size, &offset, &modname, tmpstr);
+		name = kallsyms_lookup(pc, &size, &offset, NULL, tmpstr);
 		if (name != NULL) {
 			*startp = pc - offset;
 			*endp = pc - offset + size;

commit f13659e0b3907548402ce1f47bf866544b804260
Author: Anton Blanchard <anton@samba.org>
Date:   Wed Mar 21 01:48:34 2007 +1100

    [POWERPC] Fix WARN_ON when entering xmon
    
    Whenever we enter xmon we get a WARN_ON out of the rtas code since it
    thinks interrupts are still on:
    
    Unable to handle kernel paging request for data at address 0x00000000
    Faulting instruction address: 0xd000000000080008
    cpu 0x3: Vector: 300 (Data Access) at [c0000000075dba00]
        pc: d000000000080008: .doit+0x8/0x40 [oopser]
        lr: c000000000077704: .sys_init_module+0x1664/0x1824
        sp: c0000000075dbc80
       msr: 9000000000009032
       dar: 0
     dsisr: 42000000
      current = 0xc000000003fa64b0
      paca    = 0xc000000000694280
        pid   = 2260, comm = insmod
    
    ------------[ cut here ]------------
    Badness at arch/powerpc/kernel/entry_64.S:651
    Call Trace:
    [C0000000075DAE70] [C00000000000EB64] .show_stack+0x68/0x1b0 (unreliable)
    [C0000000075DAF10] [C000000000216254] .report_bug+0x94/0xe8
    [C0000000075DAFA0] [C00000000047B140] __kprobes_text_start+0x178/0x584
    [C0000000075DB040] [C0000000000044F4] program_check_common+0xf4/0x100
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index f12687d0354d..b481db1dacb4 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -330,18 +330,17 @@ static void release_output_lock(void)
 static int xmon_core(struct pt_regs *regs, int fromipi)
 {
 	int cmd = 0;
-	unsigned long msr;
 	struct bpt *bp;
 	long recurse_jmp[JMP_BUF_LEN];
 	unsigned long offset;
+	unsigned long flags;
 #ifdef CONFIG_SMP
 	int cpu;
 	int secondary;
 	unsigned long timeout;
 #endif
 
-	msr = mfmsr();
-	mtmsr(msr & ~MSR_EE);	/* disable interrupts */
+	local_irq_save(flags);
 
 	bp = in_breakpoint_table(regs->nip, &offset);
 	if (bp != NULL) {
@@ -516,7 +515,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 
 	insert_cpu_bpts();
 
-	mtmsr(msr);		/* restore interrupt enable */
+	local_irq_restore(flags);
 
 	return cmd != 'X' && cmd != EOF;
 }

commit 0a7c7efccc08f00ae6fc8e1f2de0ee61f07357fd
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Sun Mar 4 17:05:34 2007 +1100

    [POWERPC] Allow xmon to build without CONFIG_DEBUG_BUGVERBOSE
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index bf299b66f3fc..f12687d0354d 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1360,8 +1360,12 @@ static void print_bug_trap(struct pt_regs *regs)
 	if (is_warning_bug(bug))
 		return;
 
+#ifdef CONFIG_DEBUG_BUGVERBOSE
 	printf("kernel BUG at %s:%u!\n",
 	       bug->file, bug->line);
+#else
+	printf("kernel BUG at %p!\n", (void *)bug->bug_addr);
+#endif
 }
 
 void excprint(struct pt_regs *fp)

commit c99176a230097b076c2f98e4bf963399fe114ffd
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Mon Feb 26 18:14:06 2007 +0900

    [POWERPC] Add missing newline in xmon help output
    
    My patch to add spu disassembly (af89fb8041562508895c8f3ba04790d7c2f4338c)
    removed a newline from the xmon help that it shouldn't have, put it back.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 0183e5fbaf46..bf299b66f3fc 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -218,7 +218,7 @@ Commands:\n\
 "  ss	stop execution on all spus\n\
   sr	restore execution on stopped spus\n\
   sf  #	dump spu fields for spu # (in hex)\n\
-  sd  #	dump spu local store for spu # (in hex)\
+  sd  #	dump spu local store for spu # (in hex)\n\
   sdi #	disassemble spu local store for spu # (in hex)\n"
 #endif
 "  S	print special registers\n\

commit 8389998ae9ea2888c86c446f7911ddced50052a1
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Feb 13 21:54:22 2007 +0100

    [POWERPC] spufs: move prio to spu_context
    
    It doesn't make any sense to have a priority field in the physical spu
    structure.  Move it into the spu context instead.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 77540a2f7704..0183e5fbaf46 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2811,7 +2811,6 @@ static void dump_spu_fields(struct spu *spu)
 	DUMP_FIELD(spu, "0x%lx", irqs[2]);
 	DUMP_FIELD(spu, "0x%x", slb_replace);
 	DUMP_FIELD(spu, "%d", pid);
-	DUMP_FIELD(spu, "%d", prio);
 	DUMP_FIELD(spu, "0x%p", mm);
 	DUMP_FIELD(spu, "0x%p", ctx);
 	DUMP_FIELD(spu, "0x%p", rq);

commit 73c9ceab40b1269d6195e556773167c078ac8311
Author: Jeremy Fitzhardinge <jeremy@goop.org>
Date:   Fri Dec 8 03:30:41 2006 -0800

    [POWERPC] Generic BUG for powerpc
    
    This makes powerpc use the generic BUG machinery.  The biggest reports the
    function name, since it is redundant with kallsyms, and not needed in general.
    
    There is an overall reduction of code, since module_32/64 duplicated several
    functions.
    
    Unfortunately there's no way to tell gcc that BUG won't return, so the BUG
    macro includes a goto loop.  This will generate a real jmp instruction, which
    is never used.
    
    [akpm@osdl.org: build fix]
    [paulus@samba.org: remove infinite loop in BUG_ON]
    Signed-off-by: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Andi Kleen <ak@muc.de>
    Cc: Hugh Dickens <hugh@veritas.com>
    Cc: Michael Ellerman <michael@ellerman.id.au>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index a34ed49e0356..77540a2f7704 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -22,6 +22,7 @@
 #include <linux/sysrq.h>
 #include <linux/interrupt.h>
 #include <linux/irq.h>
+#include <linux/bug.h>
 
 #include <asm/ptrace.h>
 #include <asm/string.h>
@@ -35,7 +36,6 @@
 #include <asm/cputable.h>
 #include <asm/rtas.h>
 #include <asm/sstep.h>
-#include <asm/bug.h>
 #include <asm/irq_regs.h>
 #include <asm/spu.h>
 #include <asm/spu_priv1.h>
@@ -1346,7 +1346,7 @@ static void backtrace(struct pt_regs *excp)
 
 static void print_bug_trap(struct pt_regs *regs)
 {
-	struct bug_entry *bug;
+	const struct bug_entry *bug;
 	unsigned long addr;
 
 	if (regs->msr & MSR_PR)
@@ -1357,11 +1357,11 @@ static void print_bug_trap(struct pt_regs *regs)
 	bug = find_bug(regs->nip);
 	if (bug == NULL)
 		return;
-	if (bug->line & BUG_WARNING_TRAP)
+	if (is_warning_bug(bug))
 		return;
 
-	printf("kernel BUG in %s at %s:%d!\n",
-	       bug->function, bug->file, (unsigned int)bug->line);
+	printf("kernel BUG at %s:%u!\n",
+	       bug->file, bug->line);
 }
 
 void excprint(struct pt_regs *fp)

commit bbb681779012fae778c0a53081bbb19cf43bca4e
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Thu Nov 30 11:44:09 2006 +1100

    [POWERPC] Allow xmon to build on legacy iSeries
    
    xmon still does not run on iSeries, but this allows us to build a combined
    kernel that includes it.
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index dc8a3760a98c..a34ed49e0356 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -44,6 +44,7 @@
 #ifdef CONFIG_PPC64
 #include <asm/hvcall.h>
 #include <asm/paca.h>
+#include <asm/iseries/it_lp_reg_save.h>
 #endif
 
 #include "nonstdio.h"
@@ -2580,6 +2581,10 @@ void dump_segments(void)
 
 void xmon_init(int enable)
 {
+#ifdef CONFIG_PPC_ISERIES
+	if (firmware_has_feature(FW_FEATURE_ISERIES))
+		return;
+#endif
 	if (enable) {
 		__debugger = xmon;
 		__debugger_ipi = xmon_ipi;
@@ -2617,6 +2622,10 @@ static struct sysrq_key_op sysrq_xmon_op =
 
 static int __init setup_xmon_sysrq(void)
 {
+#ifdef CONFIG_PPC_ISERIES
+	if (firmware_has_feature(FW_FEATURE_ISERIES))
+		return 0;
+#endif
 	register_sysrq_key('x', &sysrq_xmon_op);
 	return 0;
 }

commit e055595d3e5f5233374211bc6893e5d16976df99
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon Nov 27 19:18:55 2006 +0100

    [POWERPC] cell: fix building without spufs
    
    It may be desireable to build a kernel for cell without
    spufs, e.g. as the initial kboot kernel. This requires
    that the SPU specific parts of the core dump and the xmon
    code depend on CONFIG_SPU_BASE instead of CONFIG_PPC_CELL.
    
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 1cf90c8ac34a..dc8a3760a98c 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -213,7 +213,7 @@ Commands:\n\
   p 	call a procedure\n\
   r	print registers\n\
   s	single step\n"
-#ifdef CONFIG_PPC_CELL
+#ifdef CONFIG_SPU_BASE
 "  ss	stop execution on all spus\n\
   sr	restore execution on stopped spus\n\
   sf  #	dump spu fields for spu # (in hex)\n\
@@ -2654,7 +2654,7 @@ void __init xmon_setup(void)
 		debugger(NULL);
 }
 
-#ifdef CONFIG_PPC_CELL
+#ifdef CONFIG_SPU_BASE
 
 struct spu_info {
 	struct spu *spu;
@@ -2907,7 +2907,7 @@ static int do_spu_cmd(void)
 
 	return 0;
 }
-#else /* ! CONFIG_PPC_CELL */
+#else /* ! CONFIG_SPU_BASE */
 static int do_spu_cmd(void)
 {
 	return -1;

commit a985239bdf017e00e985c3a31149d6ae128fdc5f
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Nov 23 00:46:50 2006 +0100

    [POWERPC] cell: spu management xmon routines
    
    This fixes the xmon support for the cell spu to be compatable with the split
    spu platform code.
    
    Signed-off-by: Geoff Levand <geoffrey.levand@am.sony.com>
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index c999638cc2de..1cf90c8ac34a 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2789,8 +2789,6 @@ static void dump_spu_fields(struct spu *spu)
 
 	DUMP_FIELD(spu, "0x%x", number);
 	DUMP_FIELD(spu, "%s", name);
-	DUMP_FIELD(spu, "%s", devnode->full_name);
-	DUMP_FIELD(spu, "0x%x", nid);
 	DUMP_FIELD(spu, "0x%lx", local_store_phys);
 	DUMP_FIELD(spu, "0x%p", local_store);
 	DUMP_FIELD(spu, "0x%lx", ls_size);
@@ -2817,14 +2815,8 @@ static void dump_spu_fields(struct spu *spu)
 			in_be32(&spu->problem->spu_status_R));
 	DUMP_VALUE("0x%x", problem->spu_npc_RW,
 			in_be32(&spu->problem->spu_npc_RW));
-	DUMP_FIELD(spu, "0x%p", priv1);
-
-	if (spu->priv1) {
-		DUMP_VALUE("0x%lx", priv1->mfc_sr1_RW,
-				in_be64(&spu->priv1->mfc_sr1_RW));
-	}
-
 	DUMP_FIELD(spu, "0x%p", priv2);
+	DUMP_FIELD(spu, "0x%p", pdata);
 }
 
 int

commit e0426047cb684842700f0098f74842a38260dbae
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Nov 23 00:46:45 2006 +0100

    [POWERPC] Make xmon disassembly optional
    
    While adding spu disassembly support it struck me that we're actually
    carrying quite a lot of code around, just to do disassembly in the case
    of a crash.
    
    While on large systems it's not an issue, on smaller ones it might be
    nice to have xmon - but without the weight of the disassembly support.
    For a Cell build this saves ~230KB (!), and for pSeries ~195KB.
    
    We still support the 'di' and 'sdi' commands, however they just dump
    the instruction in hex.
    
    Move the definitions into a header to clean xmon.c just a tiny bit.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 7a0eec23cb9c..c999638cc2de 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -47,6 +47,7 @@
 #endif
 
 #include "nonstdio.h"
+#include "dis-asm.h"
 
 #define scanhex	xmon_scanhex
 #define skipbl	xmon_skipbl
@@ -110,7 +111,6 @@ static int bsesc(void);
 static void dump(void);
 static void prdump(unsigned long, long);
 static int ppc_inst_dump(unsigned long, long, int);
-void print_address(unsigned long);
 static void backtrace(struct pt_regs *);
 static void excprint(struct pt_regs *);
 static void prregs(struct pt_regs *);
@@ -154,9 +154,6 @@ static int do_spu_cmd(void);
 
 int xmon_no_auto_backtrace;
 
-extern int print_insn_powerpc(unsigned long insn, unsigned long memaddr);
-extern int print_insn_spu(unsigned long insn, unsigned long memaddr);
-
 extern void xmon_enter(void);
 extern void xmon_leave(void);
 

commit af89fb8041562508895c8f3ba04790d7c2f4338c
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Nov 23 00:46:44 2006 +0100

    [POWERPC] Add spu disassembly to xmon
    
    This patch adds a "sdi" command to xmon, to disassemble the contents
    of an spu's local store.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index a39b17638b7b..7a0eec23cb9c 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -155,6 +155,7 @@ static int do_spu_cmd(void);
 int xmon_no_auto_backtrace;
 
 extern int print_insn_powerpc(unsigned long insn, unsigned long memaddr);
+extern int print_insn_spu(unsigned long insn, unsigned long memaddr);
 
 extern void xmon_enter(void);
 extern void xmon_leave(void);
@@ -219,7 +220,8 @@ Commands:\n\
 "  ss	stop execution on all spus\n\
   sr	restore execution on stopped spus\n\
   sf  #	dump spu fields for spu # (in hex)\n\
-  sd  #	dump spu local store for spu # (in hex)\n"
+  sd  #	dump spu local store for spu # (in hex)\
+  sdi #	disassemble spu local store for spu # (in hex)\n"
 #endif
 "  S	print special registers\n\
   t	print backtrace\n\
@@ -2828,7 +2830,13 @@ static void dump_spu_fields(struct spu *spu)
 	DUMP_FIELD(spu, "0x%p", priv2);
 }
 
-static void dump_spu_ls(unsigned long num)
+int
+spu_inst_dump(unsigned long adr, long count, int praddr)
+{
+	return generic_inst_dump(adr, count, praddr, print_insn_spu);
+}
+
+static void dump_spu_ls(unsigned long num, int subcmd)
 {
 	unsigned long offset, addr, ls_addr;
 
@@ -2855,9 +2863,17 @@ static void dump_spu_ls(unsigned long num)
 		return;
 	}
 
-	prdump(addr, 64);
-	addr += 64;
-	last_cmd = "sd\n";
+	switch (subcmd) {
+	case 'i':
+		addr += spu_inst_dump(addr, 16, 1);
+		last_cmd = "sdi\n";
+		break;
+	default:
+		prdump(addr, 64);
+		addr += 64;
+		last_cmd = "sd\n";
+		break;
+	}
 
 	spu_info[num].dump_addr = addr;
 }
@@ -2865,7 +2881,7 @@ static void dump_spu_ls(unsigned long num)
 static int do_spu_cmd(void)
 {
 	static unsigned long num = 0;
-	int cmd;
+	int cmd, subcmd = 0;
 
 	cmd = inchar();
 	switch (cmd) {
@@ -2875,8 +2891,11 @@ static int do_spu_cmd(void)
 	case 'r':
 		restart_spus();
 		break;
-	case 'f':
 	case 'd':
+		subcmd = inchar();
+		if (isxdigit(subcmd) || subcmd == '\n')
+			termch = subcmd;
+	case 'f':
 		scanhex(&num);
 		if (num >= XMON_NUM_SPUS || !spu_info[num].spu) {
 			printf("*** Error: invalid spu number\n");
@@ -2888,7 +2907,7 @@ static int do_spu_cmd(void)
 			dump_spu_fields(spu_info[num].spu);
 			break;
 		default:
-			dump_spu_ls(num);
+			dump_spu_ls(num, subcmd);
 			break;
 		}
 

commit 4c4c8723684b1b2cd0dfdf5e0685f35642bde253
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Nov 23 00:46:42 2006 +0100

    [POWERPC] Prepare for spu disassembly in xmon
    
    In order to do disassembly of spu binaries in xmon, we need to abstract
    the disassembly function from ppc_inst_dump.
    
    We do this by making the actual disassembly function a function pointer
    that we pass to ppc_inst_dump(). To save updating all the callers, we
    turn ppc_inst_dump() into generic_inst_dump() and make ppc_inst_dump()
    a wrapper which always uses print_insn_powerpc().
    
    Currently we pass the dialect into print_insn_powerpc(), but we always
    pass 0 - so just make it a local.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index be2c12d68785..a39b17638b7b 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -154,7 +154,7 @@ static int do_spu_cmd(void);
 
 int xmon_no_auto_backtrace;
 
-extern int print_insn_powerpc(unsigned long, unsigned long, int);
+extern int print_insn_powerpc(unsigned long insn, unsigned long memaddr);
 
 extern void xmon_enter(void);
 extern void xmon_leave(void);
@@ -2068,8 +2068,11 @@ prdump(unsigned long adrs, long ndump)
 	}
 }
 
+typedef int (*instruction_dump_func)(unsigned long inst, unsigned long addr);
+
 int
-ppc_inst_dump(unsigned long adr, long count, int praddr)
+generic_inst_dump(unsigned long adr, long count, int praddr,
+			instruction_dump_func dump_func)
 {
 	int nr, dotted;
 	unsigned long first_adr;
@@ -2099,12 +2102,18 @@ ppc_inst_dump(unsigned long adr, long count, int praddr)
 		if (praddr)
 			printf(REG"  %.8x", adr, inst);
 		printf("\t");
-		print_insn_powerpc(inst, adr, 0);	/* always returns 4 */
+		dump_func(inst, adr);
 		printf("\n");
 	}
 	return adr - first_adr;
 }
 
+int
+ppc_inst_dump(unsigned long adr, long count, int praddr)
+{
+	return generic_inst_dump(adr, count, praddr, print_insn_powerpc);
+}
+
 void
 print_address(unsigned long addr)
 {

commit 24a24c85d3c35790a355138d7cd34c074cb1b3ac
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Nov 23 00:46:41 2006 +0100

    [POWERPC] Add a sd command (spu dump) to xmon to dump spu local store
    
    Add a command to xmon to dump the memory of a spu's local store.
    This mimics the 'd' command which dumps regular memory, but does
    a little hand holding by taking the user supplied address and
    finding that offset in the local store for the specified spu.
    
    This makes it easy for example to look at what was executing on a spu:
    
    1:mon> ss
    ...
    Stopped spu 04 (was running)
    ...
    1:mon> sf 4
    Dumping spu fields at address c0000000019e0a00:
    ...
      problem->spu_npc_RW     = 0x228
    ...
    1:mon> sd 4 0x228
    d000080080318228 01a00c021cffc408 4020007f217ff488  |........@ ..!...|
    
    Aha, 01a00c02, which is of course rdch $2,$ch24 !
    
    --
    
    Updated to only do the setjmp goo around the spu access, and not
    around prdump because it does its own (via mread).
    
    Also the num variable is now common between sf and sd, so you don't
    have to keep typing the spu number in if you're repeating commands
    on the same spu.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index ac17abbe3ef0..be2c12d68785 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -218,7 +218,8 @@ Commands:\n\
 #ifdef CONFIG_PPC_CELL
 "  ss	stop execution on all spus\n\
   sr	restore execution on stopped spus\n\
-  sf #	dump spu fields for spu # (in hex)\n"
+  sf  #	dump spu fields for spu # (in hex)\n\
+  sd  #	dump spu local store for spu # (in hex)\n"
 #endif
 "  S	print special registers\n\
   t	print backtrace\n\
@@ -2651,6 +2652,7 @@ struct spu_info {
 	struct spu *spu;
 	u64 saved_mfc_sr1_RW;
 	u32 saved_spu_runcntl_RW;
+	unsigned long dump_addr;
 	u8 stopped_ok;
 };
 
@@ -2670,6 +2672,8 @@ void xmon_register_spus(struct list_head *list)
 
 		spu_info[spu->number].spu = spu;
 		spu_info[spu->number].stopped_ok = 0;
+		spu_info[spu->number].dump_addr = (unsigned long)
+				spu_info[spu->number].spu->local_store;
 	}
 }
 
@@ -2815,9 +2819,43 @@ static void dump_spu_fields(struct spu *spu)
 	DUMP_FIELD(spu, "0x%p", priv2);
 }
 
+static void dump_spu_ls(unsigned long num)
+{
+	unsigned long offset, addr, ls_addr;
+
+	if (setjmp(bus_error_jmp) == 0) {
+		catch_memory_errors = 1;
+		sync();
+		ls_addr = (unsigned long)spu_info[num].spu->local_store;
+		sync();
+		__delay(200);
+	} else {
+		catch_memory_errors = 0;
+		printf("*** Error: accessing spu info for spu %d\n", num);
+		return;
+	}
+	catch_memory_errors = 0;
+
+	if (scanhex(&offset))
+		addr = ls_addr + offset;
+	else
+		addr = spu_info[num].dump_addr;
+
+	if (addr >= ls_addr + LS_SIZE) {
+		printf("*** Error: address outside of local store\n");
+		return;
+	}
+
+	prdump(addr, 64);
+	addr += 64;
+	last_cmd = "sd\n";
+
+	spu_info[num].dump_addr = addr;
+}
+
 static int do_spu_cmd(void)
 {
-	unsigned long num = 0;
+	static unsigned long num = 0;
 	int cmd;
 
 	cmd = inchar();
@@ -2829,10 +2867,22 @@ static int do_spu_cmd(void)
 		restart_spus();
 		break;
 	case 'f':
-		if (scanhex(&num) && num < XMON_NUM_SPUS && spu_info[num].spu)
-			dump_spu_fields(spu_info[num].spu);
-		else
+	case 'd':
+		scanhex(&num);
+		if (num >= XMON_NUM_SPUS || !spu_info[num].spu) {
 			printf("*** Error: invalid spu number\n");
+			return 0;
+		}
+
+		switch (cmd) {
+		case 'f':
+			dump_spu_fields(spu_info[num].spu);
+			break;
+		default:
+			dump_spu_ls(num);
+			break;
+		}
+
 		break;
 	default:
 		return -1;

commit 2a14442bfebfea23d004fa4dfd067a94f5720ed7
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Nov 23 00:46:40 2006 +0100

    [POWERPC] Show state of spus as theyre stopped in Cell xmon helper
    
    After stopping spus in xmon I often find myself trawling through the
    field dumps to find out which spus were running. The spu stopping
    code actually knows what's running, so let's print it out to save
    the user some futzing.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 6b9d720f7ff8..ac17abbe3ef0 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2702,7 +2702,10 @@ static void stop_spus(void)
 			__delay(200);
 
 			spu_info[i].stopped_ok = 1;
-			printf("Stopped spu %.2d\n", i);
+
+			printf("Stopped spu %.2d (was %s)\n", i,
+					spu_info[i].saved_spu_runcntl_RW ?
+					"running" : "stopped");
 		} else {
 			catch_memory_errors = 0;
 			printf("*** Error stopping spu %.2d\n", i);

commit 437a0706837d09d8ab071c6790da07d9d6bb3d22
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Nov 23 00:46:39 2006 +0100

    [POWERPC] Fix sparse warning in xmon Cell code
    
    My patch to add spu helpers to xmon (a898497088f46252e6750405504064e2dce53117)
    introduced a few sparse warnings, because I was dereferencing an __iomem
    pointer.
    
    I think the best way to handle it is to actually use the appropriate in_beXX
    functions. Need to rejigger the DUMP macro a little to accomodate that.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index d66c3a170327..6b9d720f7ff8 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2748,13 +2748,13 @@ static void restart_spus(void)
 }
 
 #define DUMP_WIDTH	23
-#define DUMP_FIELD(obj, format, field)					\
+#define DUMP_VALUE(format, field, value)				\
 do {									\
 	if (setjmp(bus_error_jmp) == 0) {				\
 		catch_memory_errors = 1;				\
 		sync();							\
 		printf("  %-*s = "format"\n", DUMP_WIDTH,		\
-				#field, obj->field);			\
+				#field, value);				\
 		sync();							\
 		__delay(200);						\
 	} else {							\
@@ -2765,6 +2765,9 @@ do {									\
 	catch_memory_errors = 0;					\
 } while (0)
 
+#define DUMP_FIELD(obj, format, field)	\
+	DUMP_VALUE(format, field, obj->field)
+
 static void dump_spu_fields(struct spu *spu)
 {
 	printf("Dumping spu fields at address %p:\n", spu);
@@ -2793,13 +2796,18 @@ static void dump_spu_fields(struct spu *spu)
 	DUMP_FIELD(spu, "0x%p", timestamp);
 	DUMP_FIELD(spu, "0x%lx", problem_phys);
 	DUMP_FIELD(spu, "0x%p", problem);
-	DUMP_FIELD(spu, "0x%x", problem->spu_runcntl_RW);
-	DUMP_FIELD(spu, "0x%x", problem->spu_status_R);
-	DUMP_FIELD(spu, "0x%x", problem->spu_npc_RW);
+	DUMP_VALUE("0x%x", problem->spu_runcntl_RW,
+			in_be32(&spu->problem->spu_runcntl_RW));
+	DUMP_VALUE("0x%x", problem->spu_status_R,
+			in_be32(&spu->problem->spu_status_R));
+	DUMP_VALUE("0x%x", problem->spu_npc_RW,
+			in_be32(&spu->problem->spu_npc_RW));
 	DUMP_FIELD(spu, "0x%p", priv1);
 
-	if (spu->priv1)
-		DUMP_FIELD(spu, "0x%lx", priv1->mfc_sr1_RW);
+	if (spu->priv1) {
+		DUMP_VALUE("0x%lx", priv1->mfc_sr1_RW,
+				in_be64(&spu->priv1->mfc_sr1_RW));
+	}
 
 	DUMP_FIELD(spu, "0x%p", priv2);
 }

commit 1d13581d00a041797c2c14adaccd306c91f87d46
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Mon Nov 13 14:50:28 2006 +1100

    [POWERPC] iSeries: fix xmon.c for combined build
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 0689c0845777..d66c3a170327 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -39,6 +39,7 @@
 #include <asm/irq_regs.h>
 #include <asm/spu.h>
 #include <asm/spu_priv1.h>
+#include <asm/firmware.h>
 
 #ifdef CONFIG_PPC64
 #include <asm/hvcall.h>
@@ -1567,11 +1568,6 @@ void super_regs(void)
 {
 	int cmd;
 	unsigned long val;
-#ifdef CONFIG_PPC_ISERIES
-	struct paca_struct *ptrPaca = NULL;
-	struct lppaca *ptrLpPaca = NULL;
-	struct ItLpRegSave *ptrLpRegSave = NULL;
-#endif
 
 	cmd = skipbl();
 	if (cmd == '\n') {
@@ -1588,26 +1584,32 @@ void super_regs(void)
 		printf("sp   = "REG"  sprg3= "REG"\n", sp, mfspr(SPRN_SPRG3));
 		printf("toc  = "REG"  dar  = "REG"\n", toc, mfspr(SPRN_DAR));
 #ifdef CONFIG_PPC_ISERIES
-		// Dump out relevant Paca data areas.
-		printf("Paca: \n");
-		ptrPaca = get_paca();
-    
-		printf("  Local Processor Control Area (LpPaca): \n");
-		ptrLpPaca = ptrPaca->lppaca_ptr;
-		printf("    Saved Srr0=%.16lx  Saved Srr1=%.16lx \n",
-		       ptrLpPaca->saved_srr0, ptrLpPaca->saved_srr1);
-		printf("    Saved Gpr3=%.16lx  Saved Gpr4=%.16lx \n",
-		       ptrLpPaca->saved_gpr3, ptrLpPaca->saved_gpr4);
-		printf("    Saved Gpr5=%.16lx \n", ptrLpPaca->saved_gpr5);
-    
-		printf("  Local Processor Register Save Area (LpRegSave): \n");
-		ptrLpRegSave = ptrPaca->reg_save_ptr;
-		printf("    Saved Sprg0=%.16lx  Saved Sprg1=%.16lx \n",
-		       ptrLpRegSave->xSPRG0, ptrLpRegSave->xSPRG0);
-		printf("    Saved Sprg2=%.16lx  Saved Sprg3=%.16lx \n",
-		       ptrLpRegSave->xSPRG2, ptrLpRegSave->xSPRG3);
-		printf("    Saved Msr  =%.16lx  Saved Nia  =%.16lx \n",
-		       ptrLpRegSave->xMSR, ptrLpRegSave->xNIA);
+		if (firmware_has_feature(FW_FEATURE_ISERIES)) {
+			struct paca_struct *ptrPaca;
+			struct lppaca *ptrLpPaca;
+			struct ItLpRegSave *ptrLpRegSave;
+
+			/* Dump out relevant Paca data areas. */
+			printf("Paca: \n");
+			ptrPaca = get_paca();
+
+			printf("  Local Processor Control Area (LpPaca): \n");
+			ptrLpPaca = ptrPaca->lppaca_ptr;
+			printf("    Saved Srr0=%.16lx  Saved Srr1=%.16lx \n",
+			       ptrLpPaca->saved_srr0, ptrLpPaca->saved_srr1);
+			printf("    Saved Gpr3=%.16lx  Saved Gpr4=%.16lx \n",
+			       ptrLpPaca->saved_gpr3, ptrLpPaca->saved_gpr4);
+			printf("    Saved Gpr5=%.16lx \n", ptrLpPaca->saved_gpr5);
+
+			printf("  Local Processor Register Save Area (LpRegSave): \n");
+			ptrLpRegSave = ptrPaca->reg_save_ptr;
+			printf("    Saved Sprg0=%.16lx  Saved Sprg1=%.16lx \n",
+			       ptrLpRegSave->xSPRG0, ptrLpRegSave->xSPRG0);
+			printf("    Saved Sprg2=%.16lx  Saved Sprg3=%.16lx \n",
+			       ptrLpRegSave->xSPRG2, ptrLpRegSave->xSPRG3);
+			printf("    Saved Msr  =%.16lx  Saved Nia  =%.16lx \n",
+			       ptrLpRegSave->xMSR, ptrLpRegSave->xNIA);
+		}
 #endif
 
 		return;

commit a898497088f46252e6750405504064e2dce53117
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Oct 24 18:31:28 2006 +0200

    [POWERPC] add support for dumping spu info from xmon
    
    This patch adds a command to xmon for dumping information about
    spu structs. The command is 'sf' for "spu fields" perhaps, and
    takes the spu number as an argument. This is the same value as the
    spu->number field, or the "phys-id" value of a context when it is
    bound to a physical spu.
    
    We try to catch memory errors as we dump each field, hopefully this
    will make the command reasonably robust, but YMMV. If people see a
    need we can easily add more fields to the dump in future.
    
    Output looks something like this:
    
    0:mon> sf 0
    Dumping spu fields at address c00000001ffd9e80:
      number                  = 0x0
      name                    = spe
      devnode->full_name      = /cpus/PowerPC,BE@0/spes/spe@0
      nid                     = 0x0
      local_store_phys        = 0x20000000000
      local_store             = 0xd0000800801e0000
      ls_size                 = 0x0
      isrc                    = 0x4
      node                    = 0x0
      flags                   = 0x0
      dar                     = 0x0
      dsisr                   = 0x0
      class_0_pending         = 0
      irqs[0]                 = 0x16
      irqs[1]                 = 0x17
      irqs[2]                 = 0x24
      slb_replace             = 0x0
      pid                     = 0
      prio                    = 0
      mm                      = 0x0000000000000000
      ctx                     = 0x0000000000000000
      rq                      = 0x0000000000000000
      timestamp               = 0x0000000000000000
      problem_phys            = 0x20000040000
      problem                 = 0xd000080080220000
      problem->spu_runcntl_RW = 0x0
      problem->spu_status_R   = 0x0
      problem->spu_npc_RW     = 0x0
      priv1                   = 0xd000080080240000
      priv1->mfc_sr1_RW       = 0x33
      priv2                   = 0xd000080080250000
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 6a2ed8b319f0..0689c0845777 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -216,7 +216,8 @@ Commands:\n\
   s	single step\n"
 #ifdef CONFIG_PPC_CELL
 "  ss	stop execution on all spus\n\
-  sr	restore execution on stopped spus\n"
+  sr	restore execution on stopped spus\n\
+  sf #	dump spu fields for spu # (in hex)\n"
 #endif
 "  S	print special registers\n\
   t	print backtrace\n\
@@ -2744,8 +2745,66 @@ static void restart_spus(void)
 	}
 }
 
+#define DUMP_WIDTH	23
+#define DUMP_FIELD(obj, format, field)					\
+do {									\
+	if (setjmp(bus_error_jmp) == 0) {				\
+		catch_memory_errors = 1;				\
+		sync();							\
+		printf("  %-*s = "format"\n", DUMP_WIDTH,		\
+				#field, obj->field);			\
+		sync();							\
+		__delay(200);						\
+	} else {							\
+		catch_memory_errors = 0;				\
+		printf("  %-*s = *** Error reading field.\n",		\
+					DUMP_WIDTH, #field);		\
+	}								\
+	catch_memory_errors = 0;					\
+} while (0)
+
+static void dump_spu_fields(struct spu *spu)
+{
+	printf("Dumping spu fields at address %p:\n", spu);
+
+	DUMP_FIELD(spu, "0x%x", number);
+	DUMP_FIELD(spu, "%s", name);
+	DUMP_FIELD(spu, "%s", devnode->full_name);
+	DUMP_FIELD(spu, "0x%x", nid);
+	DUMP_FIELD(spu, "0x%lx", local_store_phys);
+	DUMP_FIELD(spu, "0x%p", local_store);
+	DUMP_FIELD(spu, "0x%lx", ls_size);
+	DUMP_FIELD(spu, "0x%x", node);
+	DUMP_FIELD(spu, "0x%lx", flags);
+	DUMP_FIELD(spu, "0x%lx", dar);
+	DUMP_FIELD(spu, "0x%lx", dsisr);
+	DUMP_FIELD(spu, "%d", class_0_pending);
+	DUMP_FIELD(spu, "0x%lx", irqs[0]);
+	DUMP_FIELD(spu, "0x%lx", irqs[1]);
+	DUMP_FIELD(spu, "0x%lx", irqs[2]);
+	DUMP_FIELD(spu, "0x%x", slb_replace);
+	DUMP_FIELD(spu, "%d", pid);
+	DUMP_FIELD(spu, "%d", prio);
+	DUMP_FIELD(spu, "0x%p", mm);
+	DUMP_FIELD(spu, "0x%p", ctx);
+	DUMP_FIELD(spu, "0x%p", rq);
+	DUMP_FIELD(spu, "0x%p", timestamp);
+	DUMP_FIELD(spu, "0x%lx", problem_phys);
+	DUMP_FIELD(spu, "0x%p", problem);
+	DUMP_FIELD(spu, "0x%x", problem->spu_runcntl_RW);
+	DUMP_FIELD(spu, "0x%x", problem->spu_status_R);
+	DUMP_FIELD(spu, "0x%x", problem->spu_npc_RW);
+	DUMP_FIELD(spu, "0x%p", priv1);
+
+	if (spu->priv1)
+		DUMP_FIELD(spu, "0x%lx", priv1->mfc_sr1_RW);
+
+	DUMP_FIELD(spu, "0x%p", priv2);
+}
+
 static int do_spu_cmd(void)
 {
+	unsigned long num = 0;
 	int cmd;
 
 	cmd = inchar();
@@ -2756,6 +2815,12 @@ static int do_spu_cmd(void)
 	case 'r':
 		restart_spus();
 		break;
+	case 'f':
+		if (scanhex(&num) && num < XMON_NUM_SPUS && spu_info[num].spu)
+			dump_spu_fields(spu_info[num].spu);
+		else
+			printf("*** Error: invalid spu number\n");
+		break;
 	default:
 		return -1;
 	}

commit ff8a8f25976aa58bbae7883405b00dcbaf4cc823
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Oct 24 18:31:27 2006 +0200

    [POWERPC] add support for stopping spus from xmon
    
    This patch adds support for stopping, and restarting, spus
    from xmon. We use the spu master runcntl bit to stop execution,
    this is apparently the "right" way to control spu execution and
    spufs will be changed in the future to use this bit.
    
    Testing has shown that to restart execution we have to turn the
    master runcntl bit on and also rewrite the spu runcntl bit, even
    if it is already set to 1 (running).
    
    Stopping spus is triggered by the xmon command 'ss' - "spus stop"
    perhaps. Restarting them is triggered via 'sr'. Restart doesn't
    start execution on spus unless they were running prior to being
    stopped by xmon.
    
    Walking the spu->full_list in xmon after a panic, would mean
    corruption of any spu struct would make all the others
    inaccessible. To avoid this, and also to make the next patch
    easier, we cache pointers to all spus during boot.
    
    We attempt to catch and recover from errors while stopping and
    restarting the spus, but as with most xmon functionality there are
    no guarantees that performing these operations won't crash xmon
    itself.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Arnd Bergmann <arnd.bergmann@de.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index f56ffef4defa..6a2ed8b319f0 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -37,6 +37,8 @@
 #include <asm/sstep.h>
 #include <asm/bug.h>
 #include <asm/irq_regs.h>
+#include <asm/spu.h>
+#include <asm/spu_priv1.h>
 
 #ifdef CONFIG_PPC64
 #include <asm/hvcall.h>
@@ -147,6 +149,8 @@ static void xmon_print_symbol(unsigned long address, const char *mid,
 			      const char *after);
 static const char *getvecname(unsigned long vec);
 
+static int do_spu_cmd(void);
+
 int xmon_no_auto_backtrace;
 
 extern int print_insn_powerpc(unsigned long, unsigned long, int);
@@ -209,8 +213,12 @@ Commands:\n\
   mi	show information about memory allocation\n\
   p 	call a procedure\n\
   r	print registers\n\
-  s	single step\n\
-  S	print special registers\n\
+  s	single step\n"
+#ifdef CONFIG_PPC_CELL
+"  ss	stop execution on all spus\n\
+  sr	restore execution on stopped spus\n"
+#endif
+"  S	print special registers\n\
   t	print backtrace\n\
   x	exit monitor and recover\n\
   X	exit monitor and dont recover\n"
@@ -518,6 +526,7 @@ int xmon(struct pt_regs *excp)
 		xmon_save_regs(&regs);
 		excp = &regs;
 	}
+
 	return xmon_core(excp, 0);
 }
 EXPORT_SYMBOL(xmon);
@@ -809,6 +818,8 @@ cmds(struct pt_regs *excp)
 			cacheflush();
 			break;
 		case 's':
+			if (do_spu_cmd() == 0)
+				break;
 			if (do_step(excp))
 				return cmd;
 			break;
@@ -2630,3 +2641,130 @@ void __init xmon_setup(void)
 	if (xmon_early)
 		debugger(NULL);
 }
+
+#ifdef CONFIG_PPC_CELL
+
+struct spu_info {
+	struct spu *spu;
+	u64 saved_mfc_sr1_RW;
+	u32 saved_spu_runcntl_RW;
+	u8 stopped_ok;
+};
+
+#define XMON_NUM_SPUS	16	/* Enough for current hardware */
+
+static struct spu_info spu_info[XMON_NUM_SPUS];
+
+void xmon_register_spus(struct list_head *list)
+{
+	struct spu *spu;
+
+	list_for_each_entry(spu, list, full_list) {
+		if (spu->number >= XMON_NUM_SPUS) {
+			WARN_ON(1);
+			continue;
+		}
+
+		spu_info[spu->number].spu = spu;
+		spu_info[spu->number].stopped_ok = 0;
+	}
+}
+
+static void stop_spus(void)
+{
+	struct spu *spu;
+	int i;
+	u64 tmp;
+
+	for (i = 0; i < XMON_NUM_SPUS; i++) {
+		if (!spu_info[i].spu)
+			continue;
+
+		if (setjmp(bus_error_jmp) == 0) {
+			catch_memory_errors = 1;
+			sync();
+
+			spu = spu_info[i].spu;
+
+			spu_info[i].saved_spu_runcntl_RW =
+				in_be32(&spu->problem->spu_runcntl_RW);
+
+			tmp = spu_mfc_sr1_get(spu);
+			spu_info[i].saved_mfc_sr1_RW = tmp;
+
+			tmp &= ~MFC_STATE1_MASTER_RUN_CONTROL_MASK;
+			spu_mfc_sr1_set(spu, tmp);
+
+			sync();
+			__delay(200);
+
+			spu_info[i].stopped_ok = 1;
+			printf("Stopped spu %.2d\n", i);
+		} else {
+			catch_memory_errors = 0;
+			printf("*** Error stopping spu %.2d\n", i);
+		}
+		catch_memory_errors = 0;
+	}
+}
+
+static void restart_spus(void)
+{
+	struct spu *spu;
+	int i;
+
+	for (i = 0; i < XMON_NUM_SPUS; i++) {
+		if (!spu_info[i].spu)
+			continue;
+
+		if (!spu_info[i].stopped_ok) {
+			printf("*** Error, spu %d was not successfully stopped"
+					", not restarting\n", i);
+			continue;
+		}
+
+		if (setjmp(bus_error_jmp) == 0) {
+			catch_memory_errors = 1;
+			sync();
+
+			spu = spu_info[i].spu;
+			spu_mfc_sr1_set(spu, spu_info[i].saved_mfc_sr1_RW);
+			out_be32(&spu->problem->spu_runcntl_RW,
+					spu_info[i].saved_spu_runcntl_RW);
+
+			sync();
+			__delay(200);
+
+			printf("Restarted spu %.2d\n", i);
+		} else {
+			catch_memory_errors = 0;
+			printf("*** Error restarting spu %.2d\n", i);
+		}
+		catch_memory_errors = 0;
+	}
+}
+
+static int do_spu_cmd(void)
+{
+	int cmd;
+
+	cmd = inchar();
+	switch (cmd) {
+	case 's':
+		stop_spus();
+		break;
+	case 'r':
+		restart_spus();
+		break;
+	default:
+		return -1;
+	}
+
+	return 0;
+}
+#else /* ! CONFIG_PPC_CELL */
+static int do_spu_cmd(void)
+{
+	return -1;
+}
+#endif

commit f583ffce1aac783fd16d5d75cd69ac5ebb8f4933
Author: Paul Mackerras <paulus@samba.org>
Date:   Tue Oct 10 11:47:07 2006 +1000

    [POWERPC] Fix xmon IRQ handler for pt_regs removal
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 5a854f36383c..f56ffef4defa 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -36,6 +36,7 @@
 #include <asm/rtas.h>
 #include <asm/sstep.h>
 #include <asm/bug.h>
+#include <asm/irq_regs.h>
 
 #ifdef CONFIG_PPC64
 #include <asm/hvcall.h>
@@ -521,13 +522,12 @@ int xmon(struct pt_regs *excp)
 }
 EXPORT_SYMBOL(xmon);
 
-irqreturn_t
-xmon_irq(int irq, void *d, struct pt_regs *regs)
+irqreturn_t xmon_irq(int irq, void *d)
 {
 	unsigned long flags;
 	local_irq_save(flags);
 	printf("Keyboard interrupt\n");
-	xmon(regs);
+	xmon(get_irq_regs());
 	local_irq_restore(flags);
 	return IRQ_HANDLED;
 }

commit 7d12e780e003f93433d49ce78cfedf4b4c52adc5
Author: David Howells <dhowells@redhat.com>
Date:   Thu Oct 5 14:55:46 2006 +0100

    IRQ: Maintain regs pointer globally rather than passing to IRQ handlers
    
    Maintain a per-CPU global "struct pt_regs *" variable which can be used instead
    of passing regs around manually through all ~1800 interrupt handlers in the
    Linux kernel.
    
    The regs pointer is used in few places, but it potentially costs both stack
    space and code to pass it around.  On the FRV arch, removing the regs parameter
    from all the genirq function results in a 20% speed up of the IRQ exit path
    (ie: from leaving timer_interrupt() to leaving do_IRQ()).
    
    Where appropriate, an arch may override the generic storage facility and do
    something different with the variable.  On FRV, for instance, the address is
    maintained in GR28 at all times inside the kernel as part of general exception
    handling.
    
    Having looked over the code, it appears that the parameter may be handed down
    through up to twenty or so layers of functions.  Consider a USB character
    device attached to a USB hub, attached to a USB controller that posts its
    interrupts through a cascaded auxiliary interrupt controller.  A character
    device driver may want to pass regs to the sysrq handler through the input
    layer which adds another few layers of parameter passing.
    
    I've build this code with allyesconfig for x86_64 and i386.  I've runtested the
    main part of the code on FRV and i386, though I can't test most of the drivers.
    I've also done partial conversion for powerpc and MIPS - these at least compile
    with minimal configurations.
    
    This will affect all archs.  Mostly the changes should be relatively easy.
    Take do_IRQ(), store the regs pointer at the beginning, saving the old one:
    
            struct pt_regs *old_regs = set_irq_regs(regs);
    
    And put the old one back at the end:
    
            set_irq_regs(old_regs);
    
    Don't pass regs through to generic_handle_irq() or __do_IRQ().
    
    In timer_interrupt(), this sort of change will be necessary:
    
            -       update_process_times(user_mode(regs));
            -       profile_tick(CPU_PROFILING, regs);
            +       update_process_times(user_mode(get_irq_regs()));
            +       profile_tick(CPU_PROFILING);
    
    I'd like to move update_process_times()'s use of get_irq_regs() into itself,
    except that i386, alone of the archs, uses something other than user_mode().
    
    Some notes on the interrupt handling in the drivers:
    
     (*) input_dev() is now gone entirely.  The regs pointer is no longer stored in
         the input_dev struct.
    
     (*) finish_unlinks() in drivers/usb/host/ohci-q.c needs checking.  It does
         something different depending on whether it's been supplied with a regs
         pointer or not.
    
     (*) Various IRQ handler function pointers have been moved to type
         irq_handler_t.
    
    Signed-Off-By: David Howells <dhowells@redhat.com>
    (cherry picked from 1b16e7ac850969f38b375e511e3fa2f474a33867 commit)

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 708236f34746..5a854f36383c 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -21,6 +21,7 @@
 #include <linux/module.h>
 #include <linux/sysrq.h>
 #include <linux/interrupt.h>
+#include <linux/irq.h>
 
 #include <asm/ptrace.h>
 #include <asm/string.h>
@@ -2577,12 +2578,11 @@ void xmon_init(int enable)
 }
 
 #ifdef CONFIG_MAGIC_SYSRQ
-static void sysrq_handle_xmon(int key, struct pt_regs *pt_regs,
-			      struct tty_struct *tty) 
+static void sysrq_handle_xmon(int key, struct tty_struct *tty) 
 {
 	/* ensure xmon is enabled */
 	xmon_init(1);
-	debugger(pt_regs);
+	debugger(get_irq_regs());
 }
 
 static struct sysrq_key_op sysrq_xmon_op = 

commit 0a730ae59960165ae50de3284fb50316d1755d98
Author: Paul Mackerras <paulus@samba.org>
Date:   Tue Oct 3 21:32:49 2006 +1000

    [POWERPC] Don't try to just continue if xmon has no input device
    
    Currently, if xmon has no input device (as is generally the case on
    G5 powermacs), and we drop into xmon as a result of a fatal exception,
    it will return 1, which die() interprets as "continue without causing
    an oops".  This fixes it by making xmon() return 0 in the case where
    it has no input device.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index b54ff980ecd4..708236f34746 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -505,7 +505,7 @@ static int xmon_core(struct pt_regs *regs, int fromipi)
 
 	mtmsr(msr);		/* restore interrupt enable */
 
-	return cmd != 'X';
+	return cmd != 'X' && cmd != EOF;
 }
 
 int xmon(struct pt_regs *excp)

commit 476792839467c08ddeedd8b44a7423d415b68259
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Oct 3 14:12:08 2006 +1000

    [POWERPC] Fix xmon=off and cleanup xmon initialisation
    
    My patch to make the early xmon logic work with earlier early param
    parsing (480f6f35a149802a94ad5c1a2673ed6ec8d2c158) breaks xmon=off.
    
    No one does this obviously as xmon rocks, but it should really work
    as documented.
    
    While fixing that it struck me that we could move the xmon param
    handling into xmon.c, and also consolidate the
    xmon_init()/do_early_xmon logic into xmon_setup(). This means
    xmon=early drops into xmon a little earlier on 32-bit, but it
    seems to work just fine.
    
    Tested on PSERIES and CLASSIC32.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 8adad1444a51..b54ff980ecd4 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -2,6 +2,8 @@
  * Routines providing a simple monitor for use on the PowerMac.
  *
  * Copyright (C) 1996-2005 Paul Mackerras.
+ * Copyright (C) 2001 PPC64 Team, IBM Corp
+ * Copyrignt (C) 2006 Michael Ellerman, IBM Corp
  *
  *      This program is free software; you can redistribute it and/or
  *      modify it under the terms of the GNU General Public License
@@ -2597,3 +2599,34 @@ static int __init setup_xmon_sysrq(void)
 }
 __initcall(setup_xmon_sysrq);
 #endif /* CONFIG_MAGIC_SYSRQ */
+
+int __initdata xmon_early, xmon_off;
+
+static int __init early_parse_xmon(char *p)
+{
+	if (!p || strncmp(p, "early", 5) == 0) {
+		/* just "xmon" is equivalent to "xmon=early" */
+		xmon_init(1);
+		xmon_early = 1;
+	} else if (strncmp(p, "on", 2) == 0)
+		xmon_init(1);
+	else if (strncmp(p, "off", 3) == 0)
+		xmon_off = 1;
+	else if (strncmp(p, "nobt", 4) == 0)
+		xmon_no_auto_backtrace = 1;
+	else
+		return 1;
+
+	return 0;
+}
+early_param("xmon", early_parse_xmon);
+
+void __init xmon_setup(void)
+{
+#ifdef CONFIG_XMON_DEFAULT
+	if (!xmon_off)
+		xmon_init(1);
+#endif
+	if (xmon_early)
+		debugger(NULL);
+}

commit 26c8af5f01dfb91f709cc2ba07fb650949aae13e
Author: Olaf Hering <olaf@aepfle.de>
Date:   Fri Sep 8 16:29:21 2006 +0200

    [POWERPC] print backtrace when entering xmon
    
    xmon does not print a backtrace per default. This is bad on systems with
    USB keyboard, the most needed info about the crash is lost.
    print a backtrace during the very first xmon entry.
    
    Booting with xmon=nobt disables the autobacktrace functionality.
    
    Signed-off-by: Olaf Hering <olaf@aepfle.de>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 179b10ced8c7..8adad1444a51 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -137,10 +137,14 @@ static void bootcmds(void);
 static void proccall(void);
 void dump_segments(void);
 static void symbol_lookup(void);
+static void xmon_show_stack(unsigned long sp, unsigned long lr,
+			    unsigned long pc);
 static void xmon_print_symbol(unsigned long address, const char *mid,
 			      const char *after);
 static const char *getvecname(unsigned long vec);
 
+int xmon_no_auto_backtrace;
+
 extern int print_insn_powerpc(unsigned long, unsigned long, int);
 
 extern void xmon_enter(void);
@@ -736,6 +740,12 @@ cmds(struct pt_regs *excp)
 
 	last_cmd = NULL;
 	xmon_regs = excp;
+
+	if (!xmon_no_auto_backtrace) {
+		xmon_no_auto_backtrace = 1;
+		xmon_show_stack(excp->gpr[1], excp->link, excp->nip);
+	}
+
 	for(;;) {
 #ifdef CONFIG_SMP
 		printf("%x:", smp_processor_id());

commit 6ab3d5624e172c553004ecc862bfeac16d9d68b7
Author: JÃ¶rn Engel <joern@wohnheim.fh-wedel.de>
Date:   Fri Jun 30 19:25:36 2006 +0200

    Remove obsolete #include <linux/config.h>
    
    Signed-off-by: JÃ¶rn Engel <joern@wohnheim.fh-wedel.de>
    Signed-off-by: Adrian Bunk <bunk@stusta.de>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 0741df8c41b7..179b10ced8c7 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -8,7 +8,6 @@
  *      as published by the Free Software Foundation; either version
  *      2 of the License, or (at your option) any later version.
  */
-#include <linux/config.h>
 #include <linux/errno.h>
 #include <linux/sched.h>
 #include <linux/smp.h>

commit 5474c120aafe78ca54bf272f7a01107c42da2b21
Author: Michael Hanselmann <linux-kernel@hansmi.ch>
Date:   Sun Jun 25 05:47:08 2006 -0700

    [PATCH] Rewritten backlight infrastructure for portable Apple computers
    
    This patch contains a total rewrite of the backlight infrastructure for
    portable Apple computers.  Backward compatibility is retained.  A sysfs
    interface allows userland to control the brightness with more steps than
    before.  Userland is allowed to upload a brightness curve for different
    monitors, similar to Mac OS X.
    
    [akpm@osdl.org: add needed exports]
    Signed-off-by: Michael Hanselmann <linux-kernel@hansmi.ch>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Richard Purdie <rpurdie@rpsys.net>
    Cc: "Antonino A. Daplas" <adaplas@pol.net>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 4735b41c113c..0741df8c41b7 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -26,9 +26,6 @@
 #include <asm/prom.h>
 #include <asm/machdep.h>
 #include <asm/xmon.h>
-#ifdef CONFIG_PMAC_BACKLIGHT
-#include <asm/backlight.h>
-#endif
 #include <asm/processor.h>
 #include <asm/pgtable.h>
 #include <asm/mmu.h>

commit 7e5b59384eebe35bff8429243f089931ce1cdf38
Author: Olaf Hering <olh@suse.de>
Date:   Wed Mar 8 20:40:28 2006 +0100

    [PATCH] powerpc: add a raw dump command to xmon
    
    Dump a stream of rawbytes with a new 'dr' command.
    Produces less output and it is simpler to feed the output to scripts.
    Also, dr has no dumpsize limits.
    
    Signed-off-by: Olaf Hering <olh@suse.de>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 7d02fa2a8990..4735b41c113c 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -191,6 +191,7 @@ Commands:\n\
   di	dump instructions\n\
   df	dump float values\n\
   dd	dump double values\n\
+  dr	dump stream of raw bytes\n\
   e	print exception information\n\
   f	flush cache\n\
   la	lookup symbol+offset of specified address\n\
@@ -1938,6 +1939,28 @@ bsesc(void)
 	return c;
 }
 
+static void xmon_rawdump (unsigned long adrs, long ndump)
+{
+	long n, m, r, nr;
+	unsigned char temp[16];
+
+	for (n = ndump; n > 0;) {
+		r = n < 16? n: 16;
+		nr = mread(adrs, temp, r);
+		adrs += nr;
+		for (m = 0; m < r; ++m) {
+			if (m < nr)
+				printf("%.2x", temp[m]);
+			else
+				printf("%s", fault_chars[fault_type]);
+		}
+		n -= r;
+		if (nr < r)
+			break;
+	}
+	printf("\n");
+}
+
 #define isxdigit(c)	(('0' <= (c) && (c) <= '9') \
 			 || ('a' <= (c) && (c) <= 'f') \
 			 || ('A' <= (c) && (c) <= 'F'))
@@ -1960,6 +1983,13 @@ dump(void)
 			nidump = MAX_DUMP;
 		adrs += ppc_inst_dump(adrs, nidump, 1);
 		last_cmd = "di\n";
+	} else if (c == 'r') {
+		scanhex(&ndump);
+		if (ndump == 0)
+			ndump = 64;
+		xmon_rawdump(adrs, ndump);
+		adrs += ndump;
+		last_cmd = "dr\n";
 	} else {
 		scanhex(&ndump);
 		if (ndump == 0)

commit b0da985644faa45def84ce5d8e18af6f1680f490
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed Jan 11 00:00:05 2006 +0000

    [PATCH] powerpc: xmon namespace cleanups
    
    These symbols are only used in the file that they are defined in,
    so they should not be in the global namespace.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 22612ed5379c..7d02fa2a8990 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -311,7 +311,7 @@ static void release_output_lock(void)
 }
 #endif
 
-int xmon_core(struct pt_regs *regs, int fromipi)
+static int xmon_core(struct pt_regs *regs, int fromipi)
 {
 	int cmd = 0;
 	unsigned long msr;
@@ -528,7 +528,7 @@ xmon_irq(int irq, void *d, struct pt_regs *regs)
 	return IRQ_HANDLED;
 }
 
-int xmon_bpt(struct pt_regs *regs)
+static int xmon_bpt(struct pt_regs *regs)
 {
 	struct bpt *bp;
 	unsigned long offset;
@@ -554,7 +554,7 @@ int xmon_bpt(struct pt_regs *regs)
 	return 1;
 }
 
-int xmon_sstep(struct pt_regs *regs)
+static int xmon_sstep(struct pt_regs *regs)
 {
 	if (user_mode(regs))
 		return 0;
@@ -562,7 +562,7 @@ int xmon_sstep(struct pt_regs *regs)
 	return 1;
 }
 
-int xmon_dabr_match(struct pt_regs *regs)
+static int xmon_dabr_match(struct pt_regs *regs)
 {
 	if ((regs->msr & (MSR_IR|MSR_PR|MSR_SF)) != (MSR_IR|MSR_SF))
 		return 0;
@@ -572,7 +572,7 @@ int xmon_dabr_match(struct pt_regs *regs)
 	return 1;
 }
 
-int xmon_iabr_match(struct pt_regs *regs)
+static int xmon_iabr_match(struct pt_regs *regs)
 {
 	if ((regs->msr & (MSR_IR|MSR_PR|MSR_SF)) != (MSR_IR|MSR_SF))
 		return 0;
@@ -582,7 +582,7 @@ int xmon_iabr_match(struct pt_regs *regs)
 	return 1;
 }
 
-int xmon_ipi(struct pt_regs *regs)
+static int xmon_ipi(struct pt_regs *regs)
 {
 #ifdef CONFIG_SMP
 	if (in_xmon && !cpu_isset(smp_processor_id(), cpus_in_xmon))
@@ -591,7 +591,7 @@ int xmon_ipi(struct pt_regs *regs)
 	return 0;
 }
 
-int xmon_fault_handler(struct pt_regs *regs)
+static int xmon_fault_handler(struct pt_regs *regs)
 {
 	struct bpt *bp;
 	unsigned long offset;

commit 51fae6de24da57bc6cdaa1b253595c3513ecbf2d
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Sun Dec 4 18:39:15 2005 +1100

    [PATCH] powerpc: Add a is_kernel_addr() macro
    
    There's a bunch of code that compares an address with KERNELBASE to see if
    it's a "kernel address", ie. >= KERNELBASE. The proper test is actually to
    compare with PAGE_OFFSET, since we're going to change KERNELBASE soon.
    
    So replace all of them with an is_kernel_addr() macro that does that.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 465b75c5647e..22612ed5379c 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1013,7 +1013,7 @@ static long check_bp_loc(unsigned long addr)
 	unsigned int instr;
 
 	addr &= ~3;
-	if (addr < KERNELBASE) {
+	if (!is_kernel_addr(addr)) {
 		printf("Breakpoints may only be placed at kernel addresses\n");
 		return 0;
 	}
@@ -1064,7 +1064,7 @@ bpt_cmds(void)
 		dabr.address = 0;
 		dabr.enabled = 0;
 		if (scanhex(&dabr.address)) {
-			if (dabr.address < KERNELBASE) {
+			if (!is_kernel_addr(dabr.address)) {
 				printf(badaddr);
 				break;
 			}

commit bb6b9b28d6847bc71f910e2e82c9040ff4b97ec0
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Nov 30 16:54:12 2005 +1100

    [PATCH] powerpc: udbg updates
    
    The udbg low level io layer has an issue with udbg_getc() returning a
    char (unsigned on ppc) instead of an int, thus the -1 if you had no
    available input device could end up turned into 0xff, filling your
    display with bogus characters. This fixes it, along with adding a little
    blob to xmon to do a delay before exiting when getting an EOF and fixing
    the detection of ADB keyboards in udbg_adb.c
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index c45a6ad5f3b7..465b75c5647e 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -450,7 +450,6 @@ int xmon_core(struct pt_regs *regs, int fromipi)
  leave:
 	cpu_clear(cpu, cpus_in_xmon);
 	xmon_fault_jmp[cpu] = NULL;
-
 #else
 	/* UP is simple... */
 	if (in_xmon) {
@@ -805,7 +804,10 @@ cmds(struct pt_regs *excp)
 			break;
 		case 'x':
 		case 'X':
+			return cmd;
 		case EOF:
+			printf(" <no input ...>\n");
+			mdelay(2000);
 			return cmd;
 		case '?':
 			printf(help_string);

commit 4694ca02d19f42f5fd0b62cc2d0c7d3e5a0eef47
Author: Andrew Morton <akpm@osdl.org>
Date:   Sun Nov 13 16:06:50 2005 -0800

    [PATCH] powerpc-xmon-build-fix
    
    arch/powerpc/xmon/xmon.c:525: error: syntax error before "xmon_irq"
    arch/powerpc/xmon/xmon.c:526: warning: return type defaults to `int'
    arch/powerpc/xmon/xmon.c: In function `xmon_irq':
    arch/powerpc/xmon/xmon.c:532: error: `IRQ_HANDLED' undeclared (first use in this function)
    arch/powerpc/xmon/xmon.c:532: error: (Each undeclared identifier is reported only once
    arch/powerpc/xmon/xmon.c:532: error: for each function it appears in.)
    
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index ef4356b29a97..c45a6ad5f3b7 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -19,6 +19,7 @@
 #include <linux/cpumask.h>
 #include <linux/module.h>
 #include <linux/sysrq.h>
+#include <linux/interrupt.h>
 
 #include <asm/ptrace.h>
 #include <asm/string.h>

commit 548ccebc2a79c780724529948c79de0613f96776
Author: Paul Mackerras <paulus@samba.org>
Date:   Fri Nov 11 22:36:34 2005 +1100

    powerpc: Fix reading and writing SPRs from xmon on 32-bit
    
    When we created the instructions to read/write SPRs in xmon, we were
    setting up a ppc64-style procedure descriptor and calling that, which
    doesn't work in 32-bit.  For 32-bit a function pointer just points
    to the instructions of the function.  This fixes it to do the right
    thing for both 32-bit and 64-bit.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index cfcb2a56d662..ef4356b29a97 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1467,17 +1467,23 @@ read_spr(int n)
 {
 	unsigned int instrs[2];
 	unsigned long (*code)(void);
-	unsigned long opd[3];
 	unsigned long ret = -1UL;
+#ifdef CONFIG_PPC64
+	unsigned long opd[3];
 
-	instrs[0] = 0x7c6002a6 + ((n & 0x1F) << 16) + ((n & 0x3e0) << 6);
-	instrs[1] = 0x4e800020;
 	opd[0] = (unsigned long)instrs;
 	opd[1] = 0;
 	opd[2] = 0;
+	code = (unsigned long (*)(void)) opd;
+#else
+	code = (unsigned long (*)(void)) instrs;
+#endif
+
+	/* mfspr r3,n; blr */
+	instrs[0] = 0x7c6002a6 + ((n & 0x1F) << 16) + ((n & 0x3e0) << 6);
+	instrs[1] = 0x4e800020;
 	store_inst(instrs);
 	store_inst(instrs+1);
-	code = (unsigned long (*)(void)) opd;
 
 	if (setjmp(bus_error_jmp) == 0) {
 		catch_memory_errors = 1;
@@ -1499,16 +1505,21 @@ write_spr(int n, unsigned long val)
 {
 	unsigned int instrs[2];
 	unsigned long (*code)(unsigned long);
+#ifdef CONFIG_PPC64
 	unsigned long opd[3];
 
-	instrs[0] = 0x7c6003a6 + ((n & 0x1F) << 16) + ((n & 0x3e0) << 6);
-	instrs[1] = 0x4e800020;
 	opd[0] = (unsigned long)instrs;
 	opd[1] = 0;
 	opd[2] = 0;
+	code = (unsigned long (*)(unsigned long)) opd;
+#else
+	code = (unsigned long (*)(unsigned long)) instrs;
+#endif
+
+	instrs[0] = 0x7c6003a6 + ((n & 0x1F) << 16) + ((n & 0x3e0) << 6);
+	instrs[1] = 0x4e800020;
 	store_inst(instrs);
 	store_inst(instrs+1);
-	code = (unsigned long (*)(unsigned long)) opd;
 
 	if (setjmp(bus_error_jmp) == 0) {
 		catch_memory_errors = 1;

commit e1449ed956ae29129bde3e5137dde1d579d585ff
Author: Paul Mackerras <paulus@samba.org>
Date:   Thu Nov 10 14:30:20 2005 +1100

    powerpc: 32-bit fixes for xmon
    
    This makes the memory examine/change command print the address as
    8 digits instead of 16, and makes the memory dump command print
    4 4-byte values per line instead of 2 8-byte values.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index b43a57425ea9..cfcb2a56d662 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1792,7 +1792,7 @@ memex(void)
 	for(;;){
 		if (!mnoread)
 			n = mread(adrs, val, size);
-		printf("%.16x%c", adrs, brev? 'r': ' ');
+		printf(REG"%c", adrs, brev? 'r': ' ');
 		if (!mnoread) {
 			if (brev)
 				byterev(val, size);
@@ -1971,17 +1971,18 @@ prdump(unsigned long adrs, long ndump)
 		nr = mread(adrs, temp, r);
 		adrs += nr;
 		for (m = 0; m < r; ++m) {
-		        if ((m & 7) == 0 && m > 0)
-			    putchar(' ');
+		        if ((m & (sizeof(long) - 1)) == 0 && m > 0)
+				putchar(' ');
 			if (m < nr)
 				printf("%.2x", temp[m]);
 			else
 				printf("%s", fault_chars[fault_type]);
 		}
-		if (m <= 8)
-			printf(" ");
-		for (; m < 16; ++m)
+		for (; m < 16; ++m) {
+		        if ((m & (sizeof(long) - 1)) == 0)
+				putchar(' ');
 			printf("  ");
+		}
 		printf("  |");
 		for (m = 0; m < r; ++m) {
 			if (m < nr) {

commit fca5dcd4835ed09bb1a48a355344aff7a25c76e0
Author: Paul Mackerras <paulus@samba.org>
Date:   Tue Nov 8 22:55:08 2005 +1100

    powerpc: Simplify and clean up the xmon terminal I/O
    
    This factors out the common bits of arch/powerpc/xmon/start_*.c into
    a new nonstdio.c, and removes some stuff that was supposed to make
    xmon's I/O routines somewhat stdio-like but was never used.
    
    It also makes the parsing of the xmon= command line option common,
    so that ppc32 can now use xmon={off,on,early} also.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index 1124f1146202..b43a57425ea9 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -1,7 +1,7 @@
 /*
  * Routines providing a simple monitor for use on the PowerMac.
  *
- * Copyright (C) 1996 Paul Mackerras.
+ * Copyright (C) 1996-2005 Paul Mackerras.
  *
  *      This program is free software; you can redistribute it and/or
  *      modify it under the terms of the GNU General Public License
@@ -18,6 +18,7 @@
 #include <linux/kallsyms.h>
 #include <linux/cpumask.h>
 #include <linux/module.h>
+#include <linux/sysrq.h>
 
 #include <asm/ptrace.h>
 #include <asm/string.h>
@@ -144,15 +145,10 @@ static void xmon_print_symbol(unsigned long address, const char *mid,
 static const char *getvecname(unsigned long vec);
 
 extern int print_insn_powerpc(unsigned long, unsigned long, int);
-extern void printf(const char *fmt, ...);
-extern void xmon_vfprintf(void *f, const char *fmt, va_list ap);
-extern int xmon_putc(int c, void *f);
-extern int putchar(int ch);
 
 extern void xmon_enter(void);
 extern void xmon_leave(void);
 
-extern int xmon_read_poll(void);
 extern long setjmp(long *);
 extern void longjmp(long *, long);
 extern void xmon_save_regs(struct pt_regs *);
@@ -748,7 +744,6 @@ cmds(struct pt_regs *excp)
 		printf("%x:", smp_processor_id());
 #endif /* CONFIG_SMP */
 		printf("mon> ");
-		fflush(stdout);
 		flush_input();
 		termch = 0;
 		cmd = skipbl();
@@ -2151,7 +2146,6 @@ memzcan(void)
 		ok = mread(a, &v, 1);
 		if (ok && !ook) {
 			printf("%.8x .. ", a);
-			fflush(stdout);
 		} else if (!ok && ook)
 			printf("%.8x\n", a - mskip);
 		ook = ok;
@@ -2372,7 +2366,7 @@ int
 inchar(void)
 {
 	if (lineptr == NULL || *lineptr == 0) {
-		if (fgets(line, sizeof(line), stdin) == NULL) {
+		if (xmon_gets(line, sizeof(line)) == NULL) {
 			lineptr = NULL;
 			return EOF;
 		}
@@ -2526,4 +2520,29 @@ void xmon_init(int enable)
 		__debugger_dabr_match = NULL;
 		__debugger_fault_handler = NULL;
 	}
+	xmon_map_scc();
 }
+
+#ifdef CONFIG_MAGIC_SYSRQ
+static void sysrq_handle_xmon(int key, struct pt_regs *pt_regs,
+			      struct tty_struct *tty) 
+{
+	/* ensure xmon is enabled */
+	xmon_init(1);
+	debugger(pt_regs);
+}
+
+static struct sysrq_key_op sysrq_xmon_op = 
+{
+	.handler =	sysrq_handle_xmon,
+	.help_msg =	"Xmon",
+	.action_msg =	"Entering xmon",
+};
+
+static int __init setup_xmon_sysrq(void)
+{
+	register_sysrq_key('x', &sysrq_xmon_op);
+	return 0;
+}
+__initcall(setup_xmon_sysrq);
+#endif /* CONFIG_MAGIC_SYSRQ */

commit eb66ce6333742e32825f0294310ff53e284fa828
Author: Paul Mackerras <paulus@samba.org>
Date:   Sat Oct 29 22:11:06 2005 +1000

    powerpc: Remove T command from xmon help text since it no longer exists
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
index d0623e0fd8ee..1124f1146202 100644
--- a/arch/powerpc/xmon/xmon.c
+++ b/arch/powerpc/xmon/xmon.c
@@ -210,7 +210,6 @@ Commands:\n\
   s	single step\n\
   S	print special registers\n\
   t	print backtrace\n\
-  T	Enable/Disable PPCDBG flags\n\
   x	exit monitor and recover\n\
   X	exit monitor and dont recover\n"
 #ifdef CONFIG_PPC64

commit f78541dcec327b0c46b150ee7d727f3db80275c4
Author: Paul Mackerras <paulus@samba.org>
Date:   Fri Oct 28 22:53:37 2005 +1000

    powerpc: Merge xmon
    
    The merged version follows the ppc64 version pretty closely mostly,
    and in fact ARCH=ppc64 now uses the arch/powerpc/xmon version.
    The main difference for ppc64 is that the 'p' command to call
    show_state (which was always pretty dodgy) has been replaced by
    the ppc32 'p' command, which calls a given procedure (so in fact
    the old 'p' command behaviour can be achieved with 'p $show_state').
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/xmon/xmon.c b/arch/powerpc/xmon/xmon.c
new file mode 100644
index 000000000000..d0623e0fd8ee
--- /dev/null
+++ b/arch/powerpc/xmon/xmon.c
@@ -0,0 +1,2530 @@
+/*
+ * Routines providing a simple monitor for use on the PowerMac.
+ *
+ * Copyright (C) 1996 Paul Mackerras.
+ *
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+#include <linux/config.h>
+#include <linux/errno.h>
+#include <linux/sched.h>
+#include <linux/smp.h>
+#include <linux/mm.h>
+#include <linux/reboot.h>
+#include <linux/delay.h>
+#include <linux/kallsyms.h>
+#include <linux/cpumask.h>
+#include <linux/module.h>
+
+#include <asm/ptrace.h>
+#include <asm/string.h>
+#include <asm/prom.h>
+#include <asm/machdep.h>
+#include <asm/xmon.h>
+#ifdef CONFIG_PMAC_BACKLIGHT
+#include <asm/backlight.h>
+#endif
+#include <asm/processor.h>
+#include <asm/pgtable.h>
+#include <asm/mmu.h>
+#include <asm/mmu_context.h>
+#include <asm/cputable.h>
+#include <asm/rtas.h>
+#include <asm/sstep.h>
+#include <asm/bug.h>
+
+#ifdef CONFIG_PPC64
+#include <asm/hvcall.h>
+#include <asm/paca.h>
+#endif
+
+#include "nonstdio.h"
+
+#define scanhex	xmon_scanhex
+#define skipbl	xmon_skipbl
+
+#ifdef CONFIG_SMP
+cpumask_t cpus_in_xmon = CPU_MASK_NONE;
+static unsigned long xmon_taken = 1;
+static int xmon_owner;
+static int xmon_gate;
+#endif /* CONFIG_SMP */
+
+static unsigned long in_xmon = 0;
+
+static unsigned long adrs;
+static int size = 1;
+#define MAX_DUMP (128 * 1024)
+static unsigned long ndump = 64;
+static unsigned long nidump = 16;
+static unsigned long ncsum = 4096;
+static int termch;
+static char tmpstr[128];
+
+#define JMP_BUF_LEN	23
+static long bus_error_jmp[JMP_BUF_LEN];
+static int catch_memory_errors;
+static long *xmon_fault_jmp[NR_CPUS];
+#define setjmp xmon_setjmp
+#define longjmp xmon_longjmp
+
+/* Breakpoint stuff */
+struct bpt {
+	unsigned long	address;
+	unsigned int	instr[2];
+	atomic_t	ref_count;
+	int		enabled;
+	unsigned long	pad;
+};
+
+/* Bits in bpt.enabled */
+#define BP_IABR_TE	1		/* IABR translation enabled */
+#define BP_IABR		2
+#define BP_TRAP		8
+#define BP_DABR		0x10
+
+#define NBPTS	256
+static struct bpt bpts[NBPTS];
+static struct bpt dabr;
+static struct bpt *iabr;
+static unsigned bpinstr = 0x7fe00008;	/* trap */
+
+#define BP_NUM(bp)	((bp) - bpts + 1)
+
+/* Prototypes */
+static int cmds(struct pt_regs *);
+static int mread(unsigned long, void *, int);
+static int mwrite(unsigned long, void *, int);
+static int handle_fault(struct pt_regs *);
+static void byterev(unsigned char *, int);
+static void memex(void);
+static int bsesc(void);
+static void dump(void);
+static void prdump(unsigned long, long);
+static int ppc_inst_dump(unsigned long, long, int);
+void print_address(unsigned long);
+static void backtrace(struct pt_regs *);
+static void excprint(struct pt_regs *);
+static void prregs(struct pt_regs *);
+static void memops(int);
+static void memlocate(void);
+static void memzcan(void);
+static void memdiffs(unsigned char *, unsigned char *, unsigned, unsigned);
+int skipbl(void);
+int scanhex(unsigned long *valp);
+static void scannl(void);
+static int hexdigit(int);
+void getstring(char *, int);
+static void flush_input(void);
+static int inchar(void);
+static void take_input(char *);
+static unsigned long read_spr(int);
+static void write_spr(int, unsigned long);
+static void super_regs(void);
+static void remove_bpts(void);
+static void insert_bpts(void);
+static void remove_cpu_bpts(void);
+static void insert_cpu_bpts(void);
+static struct bpt *at_breakpoint(unsigned long pc);
+static struct bpt *in_breakpoint_table(unsigned long pc, unsigned long *offp);
+static int  do_step(struct pt_regs *);
+static void bpt_cmds(void);
+static void cacheflush(void);
+static int  cpu_cmd(void);
+static void csum(void);
+static void bootcmds(void);
+static void proccall(void);
+void dump_segments(void);
+static void symbol_lookup(void);
+static void xmon_print_symbol(unsigned long address, const char *mid,
+			      const char *after);
+static const char *getvecname(unsigned long vec);
+
+extern int print_insn_powerpc(unsigned long, unsigned long, int);
+extern void printf(const char *fmt, ...);
+extern void xmon_vfprintf(void *f, const char *fmt, va_list ap);
+extern int xmon_putc(int c, void *f);
+extern int putchar(int ch);
+
+extern void xmon_enter(void);
+extern void xmon_leave(void);
+
+extern int xmon_read_poll(void);
+extern long setjmp(long *);
+extern void longjmp(long *, long);
+extern void xmon_save_regs(struct pt_regs *);
+
+#ifdef CONFIG_PPC64
+#define REG		"%.16lx"
+#define REGS_PER_LINE	4
+#define LAST_VOLATILE	13
+#else
+#define REG		"%.8lx"
+#define REGS_PER_LINE	8
+#define LAST_VOLATILE	12
+#endif
+
+#define GETWORD(v)	(((v)[0] << 24) + ((v)[1] << 16) + ((v)[2] << 8) + (v)[3])
+
+#define isxdigit(c)	(('0' <= (c) && (c) <= '9') \
+			 || ('a' <= (c) && (c) <= 'f') \
+			 || ('A' <= (c) && (c) <= 'F'))
+#define isalnum(c)	(('0' <= (c) && (c) <= '9') \
+			 || ('a' <= (c) && (c) <= 'z') \
+			 || ('A' <= (c) && (c) <= 'Z'))
+#define isspace(c)	(c == ' ' || c == '\t' || c == 10 || c == 13 || c == 0)
+
+static char *help_string = "\
+Commands:\n\
+  b	show breakpoints\n\
+  bd	set data breakpoint\n\
+  bi	set instruction breakpoint\n\
+  bc	clear breakpoint\n"
+#ifdef CONFIG_SMP
+  "\
+  c	print cpus stopped in xmon\n\
+  c#	try to switch to cpu number h (in hex)\n"
+#endif
+  "\
+  C	checksum\n\
+  d	dump bytes\n\
+  di	dump instructions\n\
+  df	dump float values\n\
+  dd	dump double values\n\
+  e	print exception information\n\
+  f	flush cache\n\
+  la	lookup symbol+offset of specified address\n\
+  ls	lookup address of specified symbol\n\
+  m	examine/change memory\n\
+  mm	move a block of memory\n\
+  ms	set a block of memory\n\
+  md	compare two blocks of memory\n\
+  ml	locate a block of memory\n\
+  mz	zero a block of memory\n\
+  mi	show information about memory allocation\n\
+  p 	call a procedure\n\
+  r	print registers\n\
+  s	single step\n\
+  S	print special registers\n\
+  t	print backtrace\n\
+  T	Enable/Disable PPCDBG flags\n\
+  x	exit monitor and recover\n\
+  X	exit monitor and dont recover\n"
+#ifdef CONFIG_PPC64
+"  u	dump segment table or SLB\n"
+#endif
+#ifdef CONFIG_PPC_STD_MMU_32
+"  u	dump segment registers\n"
+#endif
+"  ?	help\n"
+"  zr	reboot\n\
+  zh	halt\n"
+;
+
+static struct pt_regs *xmon_regs;
+
+static inline void sync(void)
+{
+	asm volatile("sync; isync");
+}
+
+static inline void store_inst(void *p)
+{
+	asm volatile ("dcbst 0,%0; sync; icbi 0,%0; isync" : : "r" (p));
+}
+
+static inline void cflush(void *p)
+{
+	asm volatile ("dcbf 0,%0; icbi 0,%0" : : "r" (p));
+}
+
+static inline void cinval(void *p)
+{
+	asm volatile ("dcbi 0,%0; icbi 0,%0" : : "r" (p));
+}
+
+/*
+ * Disable surveillance (the service processor watchdog function)
+ * while we are in xmon.
+ * XXX we should re-enable it when we leave. :)
+ */
+#define SURVEILLANCE_TOKEN	9000
+
+static inline void disable_surveillance(void)
+{
+#ifdef CONFIG_PPC_PSERIES
+	/* Since this can't be a module, args should end up below 4GB. */
+	static struct rtas_args args;
+
+	/*
+	 * At this point we have got all the cpus we can into
+	 * xmon, so there is hopefully no other cpu calling RTAS
+	 * at the moment, even though we don't take rtas.lock.
+	 * If we did try to take rtas.lock there would be a
+	 * real possibility of deadlock.
+	 */
+	args.token = rtas_token("set-indicator");
+	if (args.token == RTAS_UNKNOWN_SERVICE)
+		return;
+	args.nargs = 3;
+	args.nret = 1;
+	args.rets = &args.args[3];
+	args.args[0] = SURVEILLANCE_TOKEN;
+	args.args[1] = 0;
+	args.args[2] = 0;
+	enter_rtas(__pa(&args));
+#endif /* CONFIG_PPC_PSERIES */
+}
+
+#ifdef CONFIG_SMP
+static int xmon_speaker;
+
+static void get_output_lock(void)
+{
+	int me = smp_processor_id() + 0x100;
+	int last_speaker = 0, prev;
+	long timeout;
+
+	if (xmon_speaker == me)
+		return;
+	for (;;) {
+		if (xmon_speaker == 0) {
+			last_speaker = cmpxchg(&xmon_speaker, 0, me);
+			if (last_speaker == 0)
+				return;
+		}
+		timeout = 10000000;
+		while (xmon_speaker == last_speaker) {
+			if (--timeout > 0)
+				continue;
+			/* hostile takeover */
+			prev = cmpxchg(&xmon_speaker, last_speaker, me);
+			if (prev == last_speaker)
+				return;
+			break;
+		}
+	}
+}
+
+static void release_output_lock(void)
+{
+	xmon_speaker = 0;
+}
+#endif
+
+int xmon_core(struct pt_regs *regs, int fromipi)
+{
+	int cmd = 0;
+	unsigned long msr;
+	struct bpt *bp;
+	long recurse_jmp[JMP_BUF_LEN];
+	unsigned long offset;
+#ifdef CONFIG_SMP
+	int cpu;
+	int secondary;
+	unsigned long timeout;
+#endif
+
+	msr = mfmsr();
+	mtmsr(msr & ~MSR_EE);	/* disable interrupts */
+
+	bp = in_breakpoint_table(regs->nip, &offset);
+	if (bp != NULL) {
+		regs->nip = bp->address + offset;
+		atomic_dec(&bp->ref_count);
+	}
+
+	remove_cpu_bpts();
+
+#ifdef CONFIG_SMP
+	cpu = smp_processor_id();
+	if (cpu_isset(cpu, cpus_in_xmon)) {
+		get_output_lock();
+		excprint(regs);
+		printf("cpu 0x%x: Exception %lx %s in xmon, "
+		       "returning to main loop\n",
+		       cpu, regs->trap, getvecname(TRAP(regs)));
+		release_output_lock();
+		longjmp(xmon_fault_jmp[cpu], 1);
+	}
+
+	if (setjmp(recurse_jmp) != 0) {
+		if (!in_xmon || !xmon_gate) {
+			get_output_lock();
+			printf("xmon: WARNING: bad recursive fault "
+			       "on cpu 0x%x\n", cpu);
+			release_output_lock();
+			goto waiting;
+		}
+		secondary = !(xmon_taken && cpu == xmon_owner);
+		goto cmdloop;
+	}
+
+	xmon_fault_jmp[cpu] = recurse_jmp;
+	cpu_set(cpu, cpus_in_xmon);
+
+	bp = NULL;
+	if ((regs->msr & (MSR_IR|MSR_PR|MSR_SF)) == (MSR_IR|MSR_SF))
+		bp = at_breakpoint(regs->nip);
+	if (bp || (regs->msr & MSR_RI) == 0)
+		fromipi = 0;
+
+	if (!fromipi) {
+		get_output_lock();
+		excprint(regs);
+		if (bp) {
+			printf("cpu 0x%x stopped at breakpoint 0x%x (",
+			       cpu, BP_NUM(bp));
+			xmon_print_symbol(regs->nip, " ", ")\n");
+		}
+		if ((regs->msr & MSR_RI) == 0)
+			printf("WARNING: exception is not recoverable, "
+			       "can't continue\n");
+		release_output_lock();
+	}
+
+ waiting:
+	secondary = 1;
+	while (secondary && !xmon_gate) {
+		if (in_xmon == 0) {
+			if (fromipi)
+				goto leave;
+			secondary = test_and_set_bit(0, &in_xmon);
+		}
+		barrier();
+	}
+
+	if (!secondary && !xmon_gate) {
+		/* we are the first cpu to come in */
+		/* interrupt other cpu(s) */
+		int ncpus = num_online_cpus();
+
+		xmon_owner = cpu;
+		mb();
+		if (ncpus > 1) {
+			smp_send_debugger_break(MSG_ALL_BUT_SELF);
+			/* wait for other cpus to come in */
+			for (timeout = 100000000; timeout != 0; --timeout) {
+				if (cpus_weight(cpus_in_xmon) >= ncpus)
+					break;
+				barrier();
+			}
+		}
+		remove_bpts();
+		disable_surveillance();
+		/* for breakpoint or single step, print the current instr. */
+		if (bp || TRAP(regs) == 0xd00)
+			ppc_inst_dump(regs->nip, 1, 0);
+		printf("enter ? for help\n");
+		mb();
+		xmon_gate = 1;
+		barrier();
+	}
+
+ cmdloop:
+	while (in_xmon) {
+		if (secondary) {
+			if (cpu == xmon_owner) {
+				if (!test_and_set_bit(0, &xmon_taken)) {
+					secondary = 0;
+					continue;
+				}
+				/* missed it */
+				while (cpu == xmon_owner)
+					barrier();
+			}
+			barrier();
+		} else {
+			cmd = cmds(regs);
+			if (cmd != 0) {
+				/* exiting xmon */
+				insert_bpts();
+				xmon_gate = 0;
+				wmb();
+				in_xmon = 0;
+				break;
+			}
+			/* have switched to some other cpu */
+			secondary = 1;
+		}
+	}
+ leave:
+	cpu_clear(cpu, cpus_in_xmon);
+	xmon_fault_jmp[cpu] = NULL;
+
+#else
+	/* UP is simple... */
+	if (in_xmon) {
+		printf("Exception %lx %s in xmon, returning to main loop\n",
+		       regs->trap, getvecname(TRAP(regs)));
+		longjmp(xmon_fault_jmp[0], 1);
+	}
+	if (setjmp(recurse_jmp) == 0) {
+		xmon_fault_jmp[0] = recurse_jmp;
+		in_xmon = 1;
+
+		excprint(regs);
+		bp = at_breakpoint(regs->nip);
+		if (bp) {
+			printf("Stopped at breakpoint %x (", BP_NUM(bp));
+			xmon_print_symbol(regs->nip, " ", ")\n");
+		}
+		if ((regs->msr & MSR_RI) == 0)
+			printf("WARNING: exception is not recoverable, "
+			       "can't continue\n");
+		remove_bpts();
+		disable_surveillance();
+		/* for breakpoint or single step, print the current instr. */
+		if (bp || TRAP(regs) == 0xd00)
+			ppc_inst_dump(regs->nip, 1, 0);
+		printf("enter ? for help\n");
+	}
+
+	cmd = cmds(regs);
+
+	insert_bpts();
+	in_xmon = 0;
+#endif
+
+	if ((regs->msr & (MSR_IR|MSR_PR|MSR_SF)) == (MSR_IR|MSR_SF)) {
+		bp = at_breakpoint(regs->nip);
+		if (bp != NULL) {
+			int stepped = emulate_step(regs, bp->instr[0]);
+			if (stepped == 0) {
+				regs->nip = (unsigned long) &bp->instr[0];
+				atomic_inc(&bp->ref_count);
+			} else if (stepped < 0) {
+				printf("Couldn't single-step %s instruction\n",
+				    (IS_RFID(bp->instr[0])? "rfid": "mtmsrd"));
+			}
+		}
+	}
+
+	insert_cpu_bpts();
+
+	mtmsr(msr);		/* restore interrupt enable */
+
+	return cmd != 'X';
+}
+
+int xmon(struct pt_regs *excp)
+{
+	struct pt_regs regs;
+
+	if (excp == NULL) {
+		xmon_save_regs(&regs);
+		excp = &regs;
+	}
+	return xmon_core(excp, 0);
+}
+EXPORT_SYMBOL(xmon);
+
+irqreturn_t
+xmon_irq(int irq, void *d, struct pt_regs *regs)
+{
+	unsigned long flags;
+	local_irq_save(flags);
+	printf("Keyboard interrupt\n");
+	xmon(regs);
+	local_irq_restore(flags);
+	return IRQ_HANDLED;
+}
+
+int xmon_bpt(struct pt_regs *regs)
+{
+	struct bpt *bp;
+	unsigned long offset;
+
+	if ((regs->msr & (MSR_IR|MSR_PR|MSR_SF)) != (MSR_IR|MSR_SF))
+		return 0;
+
+	/* Are we at the trap at bp->instr[1] for some bp? */
+	bp = in_breakpoint_table(regs->nip, &offset);
+	if (bp != NULL && offset == 4) {
+		regs->nip = bp->address + 4;
+		atomic_dec(&bp->ref_count);
+		return 1;
+	}
+
+	/* Are we at a breakpoint? */
+	bp = at_breakpoint(regs->nip);
+	if (!bp)
+		return 0;
+
+	xmon_core(regs, 0);
+
+	return 1;
+}
+
+int xmon_sstep(struct pt_regs *regs)
+{
+	if (user_mode(regs))
+		return 0;
+	xmon_core(regs, 0);
+	return 1;
+}
+
+int xmon_dabr_match(struct pt_regs *regs)
+{
+	if ((regs->msr & (MSR_IR|MSR_PR|MSR_SF)) != (MSR_IR|MSR_SF))
+		return 0;
+	if (dabr.enabled == 0)
+		return 0;
+	xmon_core(regs, 0);
+	return 1;
+}
+
+int xmon_iabr_match(struct pt_regs *regs)
+{
+	if ((regs->msr & (MSR_IR|MSR_PR|MSR_SF)) != (MSR_IR|MSR_SF))
+		return 0;
+	if (iabr == 0)
+		return 0;
+	xmon_core(regs, 0);
+	return 1;
+}
+
+int xmon_ipi(struct pt_regs *regs)
+{
+#ifdef CONFIG_SMP
+	if (in_xmon && !cpu_isset(smp_processor_id(), cpus_in_xmon))
+		xmon_core(regs, 1);
+#endif
+	return 0;
+}
+
+int xmon_fault_handler(struct pt_regs *regs)
+{
+	struct bpt *bp;
+	unsigned long offset;
+
+	if (in_xmon && catch_memory_errors)
+		handle_fault(regs);	/* doesn't return */
+
+	if ((regs->msr & (MSR_IR|MSR_PR|MSR_SF)) == (MSR_IR|MSR_SF)) {
+		bp = in_breakpoint_table(regs->nip, &offset);
+		if (bp != NULL) {
+			regs->nip = bp->address + offset;
+			atomic_dec(&bp->ref_count);
+		}
+	}
+
+	return 0;
+}
+
+static struct bpt *at_breakpoint(unsigned long pc)
+{
+	int i;
+	struct bpt *bp;
+
+	bp = bpts;
+	for (i = 0; i < NBPTS; ++i, ++bp)
+		if (bp->enabled && pc == bp->address)
+			return bp;
+	return NULL;
+}
+
+static struct bpt *in_breakpoint_table(unsigned long nip, unsigned long *offp)
+{
+	unsigned long off;
+
+	off = nip - (unsigned long) bpts;
+	if (off >= sizeof(bpts))
+		return NULL;
+	off %= sizeof(struct bpt);
+	if (off != offsetof(struct bpt, instr[0])
+	    && off != offsetof(struct bpt, instr[1]))
+		return NULL;
+	*offp = off - offsetof(struct bpt, instr[0]);
+	return (struct bpt *) (nip - off);
+}
+
+static struct bpt *new_breakpoint(unsigned long a)
+{
+	struct bpt *bp;
+
+	a &= ~3UL;
+	bp = at_breakpoint(a);
+	if (bp)
+		return bp;
+
+	for (bp = bpts; bp < &bpts[NBPTS]; ++bp) {
+		if (!bp->enabled && atomic_read(&bp->ref_count) == 0) {
+			bp->address = a;
+			bp->instr[1] = bpinstr;
+			store_inst(&bp->instr[1]);
+			return bp;
+		}
+	}
+
+	printf("Sorry, no free breakpoints.  Please clear one first.\n");
+	return NULL;
+}
+
+static void insert_bpts(void)
+{
+	int i;
+	struct bpt *bp;
+
+	bp = bpts;
+	for (i = 0; i < NBPTS; ++i, ++bp) {
+		if ((bp->enabled & (BP_TRAP|BP_IABR)) == 0)
+			continue;
+		if (mread(bp->address, &bp->instr[0], 4) != 4) {
+			printf("Couldn't read instruction at %lx, "
+			       "disabling breakpoint there\n", bp->address);
+			bp->enabled = 0;
+			continue;
+		}
+		if (IS_MTMSRD(bp->instr[0]) || IS_RFID(bp->instr[0])) {
+			printf("Breakpoint at %lx is on an mtmsrd or rfid "
+			       "instruction, disabling it\n", bp->address);
+			bp->enabled = 0;
+			continue;
+		}
+		store_inst(&bp->instr[0]);
+		if (bp->enabled & BP_IABR)
+			continue;
+		if (mwrite(bp->address, &bpinstr, 4) != 4) {
+			printf("Couldn't write instruction at %lx, "
+			       "disabling breakpoint there\n", bp->address);
+			bp->enabled &= ~BP_TRAP;
+			continue;
+		}
+		store_inst((void *)bp->address);
+	}
+}
+
+static void insert_cpu_bpts(void)
+{
+	if (dabr.enabled)
+		set_dabr(dabr.address | (dabr.enabled & 7));
+	if (iabr && cpu_has_feature(CPU_FTR_IABR))
+		mtspr(SPRN_IABR, iabr->address
+			 | (iabr->enabled & (BP_IABR|BP_IABR_TE)));
+}
+
+static void remove_bpts(void)
+{
+	int i;
+	struct bpt *bp;
+	unsigned instr;
+
+	bp = bpts;
+	for (i = 0; i < NBPTS; ++i, ++bp) {
+		if ((bp->enabled & (BP_TRAP|BP_IABR)) != BP_TRAP)
+			continue;
+		if (mread(bp->address, &instr, 4) == 4
+		    && instr == bpinstr
+		    && mwrite(bp->address, &bp->instr, 4) != 4)
+			printf("Couldn't remove breakpoint at %lx\n",
+			       bp->address);
+		else
+			store_inst((void *)bp->address);
+	}
+}
+
+static void remove_cpu_bpts(void)
+{
+	set_dabr(0);
+	if (cpu_has_feature(CPU_FTR_IABR))
+		mtspr(SPRN_IABR, 0);
+}
+
+/* Command interpreting routine */
+static char *last_cmd;
+
+static int
+cmds(struct pt_regs *excp)
+{
+	int cmd = 0;
+
+	last_cmd = NULL;
+	xmon_regs = excp;
+	for(;;) {
+#ifdef CONFIG_SMP
+		printf("%x:", smp_processor_id());
+#endif /* CONFIG_SMP */
+		printf("mon> ");
+		fflush(stdout);
+		flush_input();
+		termch = 0;
+		cmd = skipbl();
+		if( cmd == '\n' ) {
+			if (last_cmd == NULL)
+				continue;
+			take_input(last_cmd);
+			last_cmd = NULL;
+			cmd = inchar();
+		}
+		switch (cmd) {
+		case 'm':
+			cmd = inchar();
+			switch (cmd) {
+			case 'm':
+			case 's':
+			case 'd':
+				memops(cmd);
+				break;
+			case 'l':
+				memlocate();
+				break;
+			case 'z':
+				memzcan();
+				break;
+			case 'i':
+				show_mem();
+				break;
+			default:
+				termch = cmd;
+				memex();
+			}
+			break;
+		case 'd':
+			dump();
+			break;
+		case 'l':
+			symbol_lookup();
+			break;
+		case 'r':
+			prregs(excp);	/* print regs */
+			break;
+		case 'e':
+			excprint(excp);
+			break;
+		case 'S':
+			super_regs();
+			break;
+		case 't':
+			backtrace(excp);
+			break;
+		case 'f':
+			cacheflush();
+			break;
+		case 's':
+			if (do_step(excp))
+				return cmd;
+			break;
+		case 'x':
+		case 'X':
+		case EOF:
+			return cmd;
+		case '?':
+			printf(help_string);
+			break;
+		case 'b':
+			bpt_cmds();
+			break;
+		case 'C':
+			csum();
+			break;
+		case 'c':
+			if (cpu_cmd())
+				return 0;
+			break;
+		case 'z':
+			bootcmds();
+			break;
+		case 'p':
+			proccall();
+			break;
+#ifdef CONFIG_PPC_STD_MMU
+		case 'u':
+			dump_segments();
+			break;
+#endif
+		default:
+			printf("Unrecognized command: ");
+		        do {
+				if (' ' < cmd && cmd <= '~')
+					putchar(cmd);
+				else
+					printf("\\x%x", cmd);
+				cmd = inchar();
+		        } while (cmd != '\n'); 
+			printf(" (type ? for help)\n");
+			break;
+		}
+	}
+}
+
+/*
+ * Step a single instruction.
+ * Some instructions we emulate, others we execute with MSR_SE set.
+ */
+static int do_step(struct pt_regs *regs)
+{
+	unsigned int instr;
+	int stepped;
+
+	/* check we are in 64-bit kernel mode, translation enabled */
+	if ((regs->msr & (MSR_SF|MSR_PR|MSR_IR)) == (MSR_SF|MSR_IR)) {
+		if (mread(regs->nip, &instr, 4) == 4) {
+			stepped = emulate_step(regs, instr);
+			if (stepped < 0) {
+				printf("Couldn't single-step %s instruction\n",
+				       (IS_RFID(instr)? "rfid": "mtmsrd"));
+				return 0;
+			}
+			if (stepped > 0) {
+				regs->trap = 0xd00 | (regs->trap & 1);
+				printf("stepped to ");
+				xmon_print_symbol(regs->nip, " ", "\n");
+				ppc_inst_dump(regs->nip, 1, 0);
+				return 0;
+			}
+		}
+	}
+	regs->msr |= MSR_SE;
+	return 1;
+}
+
+static void bootcmds(void)
+{
+	int cmd;
+
+	cmd = inchar();
+	if (cmd == 'r')
+		ppc_md.restart(NULL);
+	else if (cmd == 'h')
+		ppc_md.halt();
+	else if (cmd == 'p')
+		ppc_md.power_off();
+}
+
+static int cpu_cmd(void)
+{
+#ifdef CONFIG_SMP
+	unsigned long cpu;
+	int timeout;
+	int count;
+
+	if (!scanhex(&cpu)) {
+		/* print cpus waiting or in xmon */
+		printf("cpus stopped:");
+		count = 0;
+		for (cpu = 0; cpu < NR_CPUS; ++cpu) {
+			if (cpu_isset(cpu, cpus_in_xmon)) {
+				if (count == 0)
+					printf(" %x", cpu);
+				++count;
+			} else {
+				if (count > 1)
+					printf("-%x", cpu - 1);
+				count = 0;
+			}
+		}
+		if (count > 1)
+			printf("-%x", NR_CPUS - 1);
+		printf("\n");
+		return 0;
+	}
+	/* try to switch to cpu specified */
+	if (!cpu_isset(cpu, cpus_in_xmon)) {
+		printf("cpu 0x%x isn't in xmon\n", cpu);
+		return 0;
+	}
+	xmon_taken = 0;
+	mb();
+	xmon_owner = cpu;
+	timeout = 10000000;
+	while (!xmon_taken) {
+		if (--timeout == 0) {
+			if (test_and_set_bit(0, &xmon_taken))
+				break;
+			/* take control back */
+			mb();
+			xmon_owner = smp_processor_id();
+			printf("cpu %u didn't take control\n", cpu);
+			return 0;
+		}
+		barrier();
+	}
+	return 1;
+#else
+	return 0;
+#endif /* CONFIG_SMP */
+}
+
+static unsigned short fcstab[256] = {
+	0x0000, 0x1189, 0x2312, 0x329b, 0x4624, 0x57ad, 0x6536, 0x74bf,
+	0x8c48, 0x9dc1, 0xaf5a, 0xbed3, 0xca6c, 0xdbe5, 0xe97e, 0xf8f7,
+	0x1081, 0x0108, 0x3393, 0x221a, 0x56a5, 0x472c, 0x75b7, 0x643e,
+	0x9cc9, 0x8d40, 0xbfdb, 0xae52, 0xdaed, 0xcb64, 0xf9ff, 0xe876,
+	0x2102, 0x308b, 0x0210, 0x1399, 0x6726, 0x76af, 0x4434, 0x55bd,
+	0xad4a, 0xbcc3, 0x8e58, 0x9fd1, 0xeb6e, 0xfae7, 0xc87c, 0xd9f5,
+	0x3183, 0x200a, 0x1291, 0x0318, 0x77a7, 0x662e, 0x54b5, 0x453c,
+	0xbdcb, 0xac42, 0x9ed9, 0x8f50, 0xfbef, 0xea66, 0xd8fd, 0xc974,
+	0x4204, 0x538d, 0x6116, 0x709f, 0x0420, 0x15a9, 0x2732, 0x36bb,
+	0xce4c, 0xdfc5, 0xed5e, 0xfcd7, 0x8868, 0x99e1, 0xab7a, 0xbaf3,
+	0x5285, 0x430c, 0x7197, 0x601e, 0x14a1, 0x0528, 0x37b3, 0x263a,
+	0xdecd, 0xcf44, 0xfddf, 0xec56, 0x98e9, 0x8960, 0xbbfb, 0xaa72,
+	0x6306, 0x728f, 0x4014, 0x519d, 0x2522, 0x34ab, 0x0630, 0x17b9,
+	0xef4e, 0xfec7, 0xcc5c, 0xddd5, 0xa96a, 0xb8e3, 0x8a78, 0x9bf1,
+	0x7387, 0x620e, 0x5095, 0x411c, 0x35a3, 0x242a, 0x16b1, 0x0738,
+	0xffcf, 0xee46, 0xdcdd, 0xcd54, 0xb9eb, 0xa862, 0x9af9, 0x8b70,
+	0x8408, 0x9581, 0xa71a, 0xb693, 0xc22c, 0xd3a5, 0xe13e, 0xf0b7,
+	0x0840, 0x19c9, 0x2b52, 0x3adb, 0x4e64, 0x5fed, 0x6d76, 0x7cff,
+	0x9489, 0x8500, 0xb79b, 0xa612, 0xd2ad, 0xc324, 0xf1bf, 0xe036,
+	0x18c1, 0x0948, 0x3bd3, 0x2a5a, 0x5ee5, 0x4f6c, 0x7df7, 0x6c7e,
+	0xa50a, 0xb483, 0x8618, 0x9791, 0xe32e, 0xf2a7, 0xc03c, 0xd1b5,
+	0x2942, 0x38cb, 0x0a50, 0x1bd9, 0x6f66, 0x7eef, 0x4c74, 0x5dfd,
+	0xb58b, 0xa402, 0x9699, 0x8710, 0xf3af, 0xe226, 0xd0bd, 0xc134,
+	0x39c3, 0x284a, 0x1ad1, 0x0b58, 0x7fe7, 0x6e6e, 0x5cf5, 0x4d7c,
+	0xc60c, 0xd785, 0xe51e, 0xf497, 0x8028, 0x91a1, 0xa33a, 0xb2b3,
+	0x4a44, 0x5bcd, 0x6956, 0x78df, 0x0c60, 0x1de9, 0x2f72, 0x3efb,
+	0xd68d, 0xc704, 0xf59f, 0xe416, 0x90a9, 0x8120, 0xb3bb, 0xa232,
+	0x5ac5, 0x4b4c, 0x79d7, 0x685e, 0x1ce1, 0x0d68, 0x3ff3, 0x2e7a,
+	0xe70e, 0xf687, 0xc41c, 0xd595, 0xa12a, 0xb0a3, 0x8238, 0x93b1,
+	0x6b46, 0x7acf, 0x4854, 0x59dd, 0x2d62, 0x3ceb, 0x0e70, 0x1ff9,
+	0xf78f, 0xe606, 0xd49d, 0xc514, 0xb1ab, 0xa022, 0x92b9, 0x8330,
+	0x7bc7, 0x6a4e, 0x58d5, 0x495c, 0x3de3, 0x2c6a, 0x1ef1, 0x0f78
+};
+
+#define FCS(fcs, c)	(((fcs) >> 8) ^ fcstab[((fcs) ^ (c)) & 0xff])
+
+static void
+csum(void)
+{
+	unsigned int i;
+	unsigned short fcs;
+	unsigned char v;
+
+	if (!scanhex(&adrs))
+		return;
+	if (!scanhex(&ncsum))
+		return;
+	fcs = 0xffff;
+	for (i = 0; i < ncsum; ++i) {
+		if (mread(adrs+i, &v, 1) == 0) {
+			printf("csum stopped at %x\n", adrs+i);
+			break;
+		}
+		fcs = FCS(fcs, v);
+	}
+	printf("%x\n", fcs);
+}
+
+/*
+ * Check if this is a suitable place to put a breakpoint.
+ */
+static long check_bp_loc(unsigned long addr)
+{
+	unsigned int instr;
+
+	addr &= ~3;
+	if (addr < KERNELBASE) {
+		printf("Breakpoints may only be placed at kernel addresses\n");
+		return 0;
+	}
+	if (!mread(addr, &instr, sizeof(instr))) {
+		printf("Can't read instruction at address %lx\n", addr);
+		return 0;
+	}
+	if (IS_MTMSRD(instr) || IS_RFID(instr)) {
+		printf("Breakpoints may not be placed on mtmsrd or rfid "
+		       "instructions\n");
+		return 0;
+	}
+	return 1;
+}
+
+static char *breakpoint_help_string = 
+    "Breakpoint command usage:\n"
+    "b                show breakpoints\n"
+    "b <addr> [cnt]   set breakpoint at given instr addr\n"
+    "bc               clear all breakpoints\n"
+    "bc <n/addr>      clear breakpoint number n or at addr\n"
+    "bi <addr> [cnt]  set hardware instr breakpoint (POWER3/RS64 only)\n"
+    "bd <addr> [cnt]  set hardware data breakpoint\n"
+    "";
+
+static void
+bpt_cmds(void)
+{
+	int cmd;
+	unsigned long a;
+	int mode, i;
+	struct bpt *bp;
+	const char badaddr[] = "Only kernel addresses are permitted "
+		"for breakpoints\n";
+
+	cmd = inchar();
+	switch (cmd) {
+#ifndef CONFIG_8xx
+	case 'd':	/* bd - hardware data breakpoint */
+		mode = 7;
+		cmd = inchar();
+		if (cmd == 'r')
+			mode = 5;
+		else if (cmd == 'w')
+			mode = 6;
+		else
+			termch = cmd;
+		dabr.address = 0;
+		dabr.enabled = 0;
+		if (scanhex(&dabr.address)) {
+			if (dabr.address < KERNELBASE) {
+				printf(badaddr);
+				break;
+			}
+			dabr.address &= ~7;
+			dabr.enabled = mode | BP_DABR;
+		}
+		break;
+
+	case 'i':	/* bi - hardware instr breakpoint */
+		if (!cpu_has_feature(CPU_FTR_IABR)) {
+			printf("Hardware instruction breakpoint "
+			       "not supported on this cpu\n");
+			break;
+		}
+		if (iabr) {
+			iabr->enabled &= ~(BP_IABR | BP_IABR_TE);
+			iabr = NULL;
+		}
+		if (!scanhex(&a))
+			break;
+		if (!check_bp_loc(a))
+			break;
+		bp = new_breakpoint(a);
+		if (bp != NULL) {
+			bp->enabled |= BP_IABR | BP_IABR_TE;
+			iabr = bp;
+		}
+		break;
+#endif
+
+	case 'c':
+		if (!scanhex(&a)) {
+			/* clear all breakpoints */
+			for (i = 0; i < NBPTS; ++i)
+				bpts[i].enabled = 0;
+			iabr = NULL;
+			dabr.enabled = 0;
+			printf("All breakpoints cleared\n");
+			break;
+		}
+
+		if (a <= NBPTS && a >= 1) {
+			/* assume a breakpoint number */
+			bp = &bpts[a-1];	/* bp nums are 1 based */
+		} else {
+			/* assume a breakpoint address */
+			bp = at_breakpoint(a);
+			if (bp == 0) {
+				printf("No breakpoint at %x\n", a);
+				break;
+			}
+		}
+
+		printf("Cleared breakpoint %x (", BP_NUM(bp));
+		xmon_print_symbol(bp->address, " ", ")\n");
+		bp->enabled = 0;
+		break;
+
+	default:
+		termch = cmd;
+	        cmd = skipbl();
+		if (cmd == '?') {
+			printf(breakpoint_help_string);
+			break;
+		}
+		termch = cmd;
+		if (!scanhex(&a)) {
+			/* print all breakpoints */
+			printf("   type            address\n");
+			if (dabr.enabled) {
+				printf("   data   "REG"  [", dabr.address);
+				if (dabr.enabled & 1)
+					printf("r");
+				if (dabr.enabled & 2)
+					printf("w");
+				printf("]\n");
+			}
+			for (bp = bpts; bp < &bpts[NBPTS]; ++bp) {
+				if (!bp->enabled)
+					continue;
+				printf("%2x %s   ", BP_NUM(bp),
+				    (bp->enabled & BP_IABR)? "inst": "trap");
+				xmon_print_symbol(bp->address, "  ", "\n");
+			}
+			break;
+		}
+
+		if (!check_bp_loc(a))
+			break;
+		bp = new_breakpoint(a);
+		if (bp != NULL)
+			bp->enabled |= BP_TRAP;
+		break;
+	}
+}
+
+/* Very cheap human name for vector lookup. */
+static
+const char *getvecname(unsigned long vec)
+{
+	char *ret;
+
+	switch (vec) {
+	case 0x100:	ret = "(System Reset)"; break;
+	case 0x200:	ret = "(Machine Check)"; break;
+	case 0x300:	ret = "(Data Access)"; break;
+	case 0x380:	ret = "(Data SLB Access)"; break;
+	case 0x400:	ret = "(Instruction Access)"; break;
+	case 0x480:	ret = "(Instruction SLB Access)"; break;
+	case 0x500:	ret = "(Hardware Interrupt)"; break;
+	case 0x600:	ret = "(Alignment)"; break;
+	case 0x700:	ret = "(Program Check)"; break;
+	case 0x800:	ret = "(FPU Unavailable)"; break;
+	case 0x900:	ret = "(Decrementer)"; break;
+	case 0xc00:	ret = "(System Call)"; break;
+	case 0xd00:	ret = "(Single Step)"; break;
+	case 0xf00:	ret = "(Performance Monitor)"; break;
+	case 0xf20:	ret = "(Altivec Unavailable)"; break;
+	case 0x1300:	ret = "(Instruction Breakpoint)"; break;
+	default: ret = "";
+	}
+	return ret;
+}
+
+static void get_function_bounds(unsigned long pc, unsigned long *startp,
+				unsigned long *endp)
+{
+	unsigned long size, offset;
+	const char *name;
+	char *modname;
+
+	*startp = *endp = 0;
+	if (pc == 0)
+		return;
+	if (setjmp(bus_error_jmp) == 0) {
+		catch_memory_errors = 1;
+		sync();
+		name = kallsyms_lookup(pc, &size, &offset, &modname, tmpstr);
+		if (name != NULL) {
+			*startp = pc - offset;
+			*endp = pc - offset + size;
+		}
+		sync();
+	}
+	catch_memory_errors = 0;
+}
+
+static int xmon_depth_to_print = 64;
+
+#ifdef CONFIG_PPC64
+#define LRSAVE_OFFSET		0x10
+#define REG_FRAME_MARKER	0x7265677368657265ul	/* "regshere" */
+#define MARKER_OFFSET		0x60
+#define REGS_OFFSET		0x70
+#else
+#define LRSAVE_OFFSET		4
+#define REG_FRAME_MARKER	0x72656773
+#define MARKER_OFFSET		8
+#define REGS_OFFSET		16
+#endif
+
+static void xmon_show_stack(unsigned long sp, unsigned long lr,
+			    unsigned long pc)
+{
+	unsigned long ip;
+	unsigned long newsp;
+	unsigned long marker;
+	int count = 0;
+	struct pt_regs regs;
+
+	do {
+		if (sp < PAGE_OFFSET) {
+			if (sp != 0)
+				printf("SP (%lx) is in userspace\n", sp);
+			break;
+		}
+
+		if (!mread(sp + LRSAVE_OFFSET, &ip, sizeof(unsigned long))
+		    || !mread(sp, &newsp, sizeof(unsigned long))) {
+			printf("Couldn't read stack frame at %lx\n", sp);
+			break;
+		}
+
+		/*
+		 * For the first stack frame, try to work out if
+		 * LR and/or the saved LR value in the bottommost
+		 * stack frame are valid.
+		 */
+		if ((pc | lr) != 0) {
+			unsigned long fnstart, fnend;
+			unsigned long nextip;
+			int printip = 1;
+
+			get_function_bounds(pc, &fnstart, &fnend);
+			nextip = 0;
+			if (newsp > sp)
+				mread(newsp + LRSAVE_OFFSET, &nextip,
+				      sizeof(unsigned long));
+			if (lr == ip) {
+				if (lr < PAGE_OFFSET
+				    || (fnstart <= lr && lr < fnend))
+					printip = 0;
+			} else if (lr == nextip) {
+				printip = 0;
+			} else if (lr >= PAGE_OFFSET
+				   && !(fnstart <= lr && lr < fnend)) {
+				printf("[link register   ] ");
+				xmon_print_symbol(lr, " ", "\n");
+			}
+			if (printip) {
+				printf("["REG"] ", sp);
+				xmon_print_symbol(ip, " ", " (unreliable)\n");
+			}
+			pc = lr = 0;
+
+		} else {
+			printf("["REG"] ", sp);
+			xmon_print_symbol(ip, " ", "\n");
+		}
+
+		/* Look for "regshere" marker to see if this is
+		   an exception frame. */
+		if (mread(sp + MARKER_OFFSET, &marker, sizeof(unsigned long))
+		    && marker == REG_FRAME_MARKER) {
+			if (mread(sp + REGS_OFFSET, &regs, sizeof(regs))
+			    != sizeof(regs)) {
+				printf("Couldn't read registers at %lx\n",
+				       sp + REGS_OFFSET);
+				break;
+			}
+                        printf("--- Exception: %lx %s at ", regs.trap,
+			       getvecname(TRAP(&regs)));
+			pc = regs.nip;
+			lr = regs.link;
+			xmon_print_symbol(pc, " ", "\n");
+		}
+
+		if (newsp == 0)
+			break;
+
+		sp = newsp;
+	} while (count++ < xmon_depth_to_print);
+}
+
+static void backtrace(struct pt_regs *excp)
+{
+	unsigned long sp;
+
+	if (scanhex(&sp))
+		xmon_show_stack(sp, 0, 0);
+	else
+		xmon_show_stack(excp->gpr[1], excp->link, excp->nip);
+	scannl();
+}
+
+static void print_bug_trap(struct pt_regs *regs)
+{
+	struct bug_entry *bug;
+	unsigned long addr;
+
+	if (regs->msr & MSR_PR)
+		return;		/* not in kernel */
+	addr = regs->nip;	/* address of trap instruction */
+	if (addr < PAGE_OFFSET)
+		return;
+	bug = find_bug(regs->nip);
+	if (bug == NULL)
+		return;
+	if (bug->line & BUG_WARNING_TRAP)
+		return;
+
+	printf("kernel BUG in %s at %s:%d!\n",
+	       bug->function, bug->file, (unsigned int)bug->line);
+}
+
+void excprint(struct pt_regs *fp)
+{
+	unsigned long trap;
+
+#ifdef CONFIG_SMP
+	printf("cpu 0x%x: ", smp_processor_id());
+#endif /* CONFIG_SMP */
+
+	trap = TRAP(fp);
+	printf("Vector: %lx %s at [%lx]\n", fp->trap, getvecname(trap), fp);
+	printf("    pc: ");
+	xmon_print_symbol(fp->nip, ": ", "\n");
+
+	printf("    lr: ", fp->link);
+	xmon_print_symbol(fp->link, ": ", "\n");
+
+	printf("    sp: %lx\n", fp->gpr[1]);
+	printf("   msr: %lx\n", fp->msr);
+
+	if (trap == 0x300 || trap == 0x380 || trap == 0x600) {
+		printf("   dar: %lx\n", fp->dar);
+		if (trap != 0x380)
+			printf(" dsisr: %lx\n", fp->dsisr);
+	}
+
+	printf("  current = 0x%lx\n", current);
+#ifdef CONFIG_PPC64
+	printf("  paca    = 0x%lx\n", get_paca());
+#endif
+	if (current) {
+		printf("    pid   = %ld, comm = %s\n",
+		       current->pid, current->comm);
+	}
+
+	if (trap == 0x700)
+		print_bug_trap(fp);
+}
+
+void prregs(struct pt_regs *fp)
+{
+	int n, trap;
+	unsigned long base;
+	struct pt_regs regs;
+
+	if (scanhex(&base)) {
+		if (setjmp(bus_error_jmp) == 0) {
+			catch_memory_errors = 1;
+			sync();
+			regs = *(struct pt_regs *)base;
+			sync();
+			__delay(200);
+		} else {
+			catch_memory_errors = 0;
+			printf("*** Error reading registers from "REG"\n",
+			       base);
+			return;
+		}
+		catch_memory_errors = 0;
+		fp = &regs;
+	}
+
+#ifdef CONFIG_PPC64
+	if (FULL_REGS(fp)) {
+		for (n = 0; n < 16; ++n)
+			printf("R%.2ld = "REG"   R%.2ld = "REG"\n",
+			       n, fp->gpr[n], n+16, fp->gpr[n+16]);
+	} else {
+		for (n = 0; n < 7; ++n)
+			printf("R%.2ld = "REG"   R%.2ld = "REG"\n",
+			       n, fp->gpr[n], n+7, fp->gpr[n+7]);
+	}
+#else
+	for (n = 0; n < 32; ++n) {
+		printf("R%.2d = %.8x%s", n, fp->gpr[n],
+		       (n & 3) == 3? "\n": "   ");
+		if (n == 12 && !FULL_REGS(fp)) {
+			printf("\n");
+			break;
+		}
+	}
+#endif
+	printf("pc  = ");
+	xmon_print_symbol(fp->nip, " ", "\n");
+	printf("lr  = ");
+	xmon_print_symbol(fp->link, " ", "\n");
+	printf("msr = "REG"   cr  = %.8lx\n", fp->msr, fp->ccr);
+	printf("ctr = "REG"   xer = "REG"   trap = %4lx\n",
+	       fp->ctr, fp->xer, fp->trap);
+	trap = TRAP(fp);
+	if (trap == 0x300 || trap == 0x380 || trap == 0x600)
+		printf("dar = "REG"   dsisr = %.8lx\n", fp->dar, fp->dsisr);
+}
+
+void cacheflush(void)
+{
+	int cmd;
+	unsigned long nflush;
+
+	cmd = inchar();
+	if (cmd != 'i')
+		termch = cmd;
+	scanhex((void *)&adrs);
+	if (termch != '\n')
+		termch = 0;
+	nflush = 1;
+	scanhex(&nflush);
+	nflush = (nflush + L1_CACHE_BYTES - 1) / L1_CACHE_BYTES;
+	if (setjmp(bus_error_jmp) == 0) {
+		catch_memory_errors = 1;
+		sync();
+
+		if (cmd != 'i') {
+			for (; nflush > 0; --nflush, adrs += L1_CACHE_BYTES)
+				cflush((void *) adrs);
+		} else {
+			for (; nflush > 0; --nflush, adrs += L1_CACHE_BYTES)
+				cinval((void *) adrs);
+		}
+		sync();
+		/* wait a little while to see if we get a machine check */
+		__delay(200);
+	}
+	catch_memory_errors = 0;
+}
+
+unsigned long
+read_spr(int n)
+{
+	unsigned int instrs[2];
+	unsigned long (*code)(void);
+	unsigned long opd[3];
+	unsigned long ret = -1UL;
+
+	instrs[0] = 0x7c6002a6 + ((n & 0x1F) << 16) + ((n & 0x3e0) << 6);
+	instrs[1] = 0x4e800020;
+	opd[0] = (unsigned long)instrs;
+	opd[1] = 0;
+	opd[2] = 0;
+	store_inst(instrs);
+	store_inst(instrs+1);
+	code = (unsigned long (*)(void)) opd;
+
+	if (setjmp(bus_error_jmp) == 0) {
+		catch_memory_errors = 1;
+		sync();
+
+		ret = code();
+
+		sync();
+		/* wait a little while to see if we get a machine check */
+		__delay(200);
+		n = size;
+	}
+
+	return ret;
+}
+
+void
+write_spr(int n, unsigned long val)
+{
+	unsigned int instrs[2];
+	unsigned long (*code)(unsigned long);
+	unsigned long opd[3];
+
+	instrs[0] = 0x7c6003a6 + ((n & 0x1F) << 16) + ((n & 0x3e0) << 6);
+	instrs[1] = 0x4e800020;
+	opd[0] = (unsigned long)instrs;
+	opd[1] = 0;
+	opd[2] = 0;
+	store_inst(instrs);
+	store_inst(instrs+1);
+	code = (unsigned long (*)(unsigned long)) opd;
+
+	if (setjmp(bus_error_jmp) == 0) {
+		catch_memory_errors = 1;
+		sync();
+
+		code(val);
+
+		sync();
+		/* wait a little while to see if we get a machine check */
+		__delay(200);
+		n = size;
+	}
+}
+
+static unsigned long regno;
+extern char exc_prolog;
+extern char dec_exc;
+
+void super_regs(void)
+{
+	int cmd;
+	unsigned long val;
+#ifdef CONFIG_PPC_ISERIES
+	struct paca_struct *ptrPaca = NULL;
+	struct lppaca *ptrLpPaca = NULL;
+	struct ItLpRegSave *ptrLpRegSave = NULL;
+#endif
+
+	cmd = skipbl();
+	if (cmd == '\n') {
+	        unsigned long sp, toc;
+		asm("mr %0,1" : "=r" (sp) :);
+		asm("mr %0,2" : "=r" (toc) :);
+
+		printf("msr  = "REG"  sprg0= "REG"\n",
+		       mfmsr(), mfspr(SPRN_SPRG0));
+		printf("pvr  = "REG"  sprg1= "REG"\n",
+		       mfspr(SPRN_PVR), mfspr(SPRN_SPRG1)); 
+		printf("dec  = "REG"  sprg2= "REG"\n",
+		       mfspr(SPRN_DEC), mfspr(SPRN_SPRG2));
+		printf("sp   = "REG"  sprg3= "REG"\n", sp, mfspr(SPRN_SPRG3));
+		printf("toc  = "REG"  dar  = "REG"\n", toc, mfspr(SPRN_DAR));
+#ifdef CONFIG_PPC_ISERIES
+		// Dump out relevant Paca data areas.
+		printf("Paca: \n");
+		ptrPaca = get_paca();
+    
+		printf("  Local Processor Control Area (LpPaca): \n");
+		ptrLpPaca = ptrPaca->lppaca_ptr;
+		printf("    Saved Srr0=%.16lx  Saved Srr1=%.16lx \n",
+		       ptrLpPaca->saved_srr0, ptrLpPaca->saved_srr1);
+		printf("    Saved Gpr3=%.16lx  Saved Gpr4=%.16lx \n",
+		       ptrLpPaca->saved_gpr3, ptrLpPaca->saved_gpr4);
+		printf("    Saved Gpr5=%.16lx \n", ptrLpPaca->saved_gpr5);
+    
+		printf("  Local Processor Register Save Area (LpRegSave): \n");
+		ptrLpRegSave = ptrPaca->reg_save_ptr;
+		printf("    Saved Sprg0=%.16lx  Saved Sprg1=%.16lx \n",
+		       ptrLpRegSave->xSPRG0, ptrLpRegSave->xSPRG0);
+		printf("    Saved Sprg2=%.16lx  Saved Sprg3=%.16lx \n",
+		       ptrLpRegSave->xSPRG2, ptrLpRegSave->xSPRG3);
+		printf("    Saved Msr  =%.16lx  Saved Nia  =%.16lx \n",
+		       ptrLpRegSave->xMSR, ptrLpRegSave->xNIA);
+#endif
+
+		return;
+	}
+
+	scanhex(&regno);
+	switch (cmd) {
+	case 'w':
+		val = read_spr(regno);
+		scanhex(&val);
+		write_spr(regno, val);
+		/* fall through */
+	case 'r':
+		printf("spr %lx = %lx\n", regno, read_spr(regno));
+		break;
+	}
+	scannl();
+}
+
+/*
+ * Stuff for reading and writing memory safely
+ */
+int
+mread(unsigned long adrs, void *buf, int size)
+{
+	volatile int n;
+	char *p, *q;
+
+	n = 0;
+	if (setjmp(bus_error_jmp) == 0) {
+		catch_memory_errors = 1;
+		sync();
+		p = (char *)adrs;
+		q = (char *)buf;
+		switch (size) {
+		case 2:
+			*(u16 *)q = *(u16 *)p;
+			break;
+		case 4:
+			*(u32 *)q = *(u32 *)p;
+			break;
+		case 8:
+			*(u64 *)q = *(u64 *)p;
+			break;
+		default:
+			for( ; n < size; ++n) {
+				*q++ = *p++;
+				sync();
+			}
+		}
+		sync();
+		/* wait a little while to see if we get a machine check */
+		__delay(200);
+		n = size;
+	}
+	catch_memory_errors = 0;
+	return n;
+}
+
+int
+mwrite(unsigned long adrs, void *buf, int size)
+{
+	volatile int n;
+	char *p, *q;
+
+	n = 0;
+	if (setjmp(bus_error_jmp) == 0) {
+		catch_memory_errors = 1;
+		sync();
+		p = (char *) adrs;
+		q = (char *) buf;
+		switch (size) {
+		case 2:
+			*(u16 *)p = *(u16 *)q;
+			break;
+		case 4:
+			*(u32 *)p = *(u32 *)q;
+			break;
+		case 8:
+			*(u64 *)p = *(u64 *)q;
+			break;
+		default:
+			for ( ; n < size; ++n) {
+				*p++ = *q++;
+				sync();
+			}
+		}
+		sync();
+		/* wait a little while to see if we get a machine check */
+		__delay(200);
+		n = size;
+	} else {
+		printf("*** Error writing address %x\n", adrs + n);
+	}
+	catch_memory_errors = 0;
+	return n;
+}
+
+static int fault_type;
+static int fault_except;
+static char *fault_chars[] = { "--", "**", "##" };
+
+static int handle_fault(struct pt_regs *regs)
+{
+	fault_except = TRAP(regs);
+	switch (TRAP(regs)) {
+	case 0x200:
+		fault_type = 0;
+		break;
+	case 0x300:
+	case 0x380:
+		fault_type = 1;
+		break;
+	default:
+		fault_type = 2;
+	}
+
+	longjmp(bus_error_jmp, 1);
+
+	return 0;
+}
+
+#define SWAP(a, b, t)	((t) = (a), (a) = (b), (b) = (t))
+
+void
+byterev(unsigned char *val, int size)
+{
+	int t;
+	
+	switch (size) {
+	case 2:
+		SWAP(val[0], val[1], t);
+		break;
+	case 4:
+		SWAP(val[0], val[3], t);
+		SWAP(val[1], val[2], t);
+		break;
+	case 8: /* is there really any use for this? */
+		SWAP(val[0], val[7], t);
+		SWAP(val[1], val[6], t);
+		SWAP(val[2], val[5], t);
+		SWAP(val[3], val[4], t);
+		break;
+	}
+}
+
+static int brev;
+static int mnoread;
+
+static char *memex_help_string = 
+    "Memory examine command usage:\n"
+    "m [addr] [flags] examine/change memory\n"
+    "  addr is optional.  will start where left off.\n"
+    "  flags may include chars from this set:\n"
+    "    b   modify by bytes (default)\n"
+    "    w   modify by words (2 byte)\n"
+    "    l   modify by longs (4 byte)\n"
+    "    d   modify by doubleword (8 byte)\n"
+    "    r   toggle reverse byte order mode\n"
+    "    n   do not read memory (for i/o spaces)\n"
+    "    .   ok to read (default)\n"
+    "NOTE: flags are saved as defaults\n"
+    "";
+
+static char *memex_subcmd_help_string = 
+    "Memory examine subcommands:\n"
+    "  hexval   write this val to current location\n"
+    "  'string' write chars from string to this location\n"
+    "  '        increment address\n"
+    "  ^        decrement address\n"
+    "  /        increment addr by 0x10.  //=0x100, ///=0x1000, etc\n"
+    "  \\        decrement addr by 0x10.  \\\\=0x100, \\\\\\=0x1000, etc\n"
+    "  `        clear no-read flag\n"
+    "  ;        stay at this addr\n"
+    "  v        change to byte mode\n"
+    "  w        change to word (2 byte) mode\n"
+    "  l        change to long (4 byte) mode\n"
+    "  u        change to doubleword (8 byte) mode\n"
+    "  m addr   change current addr\n"
+    "  n        toggle no-read flag\n"
+    "  r        toggle byte reverse flag\n"
+    "  < count  back up count bytes\n"
+    "  > count  skip forward count bytes\n"
+    "  x        exit this mode\n"
+    "";
+
+void
+memex(void)
+{
+	int cmd, inc, i, nslash;
+	unsigned long n;
+	unsigned char val[16];
+
+	scanhex((void *)&adrs);
+	cmd = skipbl();
+	if (cmd == '?') {
+		printf(memex_help_string);
+		return;
+	} else {
+		termch = cmd;
+	}
+	last_cmd = "m\n";
+	while ((cmd = skipbl()) != '\n') {
+		switch( cmd ){
+		case 'b':	size = 1;	break;
+		case 'w':	size = 2;	break;
+		case 'l':	size = 4;	break;
+		case 'd':	size = 8;	break;
+		case 'r': 	brev = !brev;	break;
+		case 'n':	mnoread = 1;	break;
+		case '.':	mnoread = 0;	break;
+		}
+	}
+	if( size <= 0 )
+		size = 1;
+	else if( size > 8 )
+		size = 8;
+	for(;;){
+		if (!mnoread)
+			n = mread(adrs, val, size);
+		printf("%.16x%c", adrs, brev? 'r': ' ');
+		if (!mnoread) {
+			if (brev)
+				byterev(val, size);
+			putchar(' ');
+			for (i = 0; i < n; ++i)
+				printf("%.2x", val[i]);
+			for (; i < size; ++i)
+				printf("%s", fault_chars[fault_type]);
+		}
+		putchar(' ');
+		inc = size;
+		nslash = 0;
+		for(;;){
+			if( scanhex(&n) ){
+				for (i = 0; i < size; ++i)
+					val[i] = n >> (i * 8);
+				if (!brev)
+					byterev(val, size);
+				mwrite(adrs, val, size);
+				inc = size;
+			}
+			cmd = skipbl();
+			if (cmd == '\n')
+				break;
+			inc = 0;
+			switch (cmd) {
+			case '\'':
+				for(;;){
+					n = inchar();
+					if( n == '\\' )
+						n = bsesc();
+					else if( n == '\'' )
+						break;
+					for (i = 0; i < size; ++i)
+						val[i] = n >> (i * 8);
+					if (!brev)
+						byterev(val, size);
+					mwrite(adrs, val, size);
+					adrs += size;
+				}
+				adrs -= size;
+				inc = size;
+				break;
+			case ',':
+				adrs += size;
+				break;
+			case '.':
+				mnoread = 0;
+				break;
+			case ';':
+				break;
+			case 'x':
+			case EOF:
+				scannl();
+				return;
+			case 'b':
+			case 'v':
+				size = 1;
+				break;
+			case 'w':
+				size = 2;
+				break;
+			case 'l':
+				size = 4;
+				break;
+			case 'u':
+				size = 8;
+				break;
+			case '^':
+				adrs -= size;
+				break;
+				break;
+			case '/':
+				if (nslash > 0)
+					adrs -= 1 << nslash;
+				else
+					nslash = 0;
+				nslash += 4;
+				adrs += 1 << nslash;
+				break;
+			case '\\':
+				if (nslash < 0)
+					adrs += 1 << -nslash;
+				else
+					nslash = 0;
+				nslash -= 4;
+				adrs -= 1 << -nslash;
+				break;
+			case 'm':
+				scanhex((void *)&adrs);
+				break;
+			case 'n':
+				mnoread = 1;
+				break;
+			case 'r':
+				brev = !brev;
+				break;
+			case '<':
+				n = size;
+				scanhex(&n);
+				adrs -= n;
+				break;
+			case '>':
+				n = size;
+				scanhex(&n);
+				adrs += n;
+				break;
+			case '?':
+				printf(memex_subcmd_help_string);
+				break;
+			}
+		}
+		adrs += inc;
+	}
+}
+
+int
+bsesc(void)
+{
+	int c;
+
+	c = inchar();
+	switch( c ){
+	case 'n':	c = '\n';	break;
+	case 'r':	c = '\r';	break;
+	case 'b':	c = '\b';	break;
+	case 't':	c = '\t';	break;
+	}
+	return c;
+}
+
+#define isxdigit(c)	(('0' <= (c) && (c) <= '9') \
+			 || ('a' <= (c) && (c) <= 'f') \
+			 || ('A' <= (c) && (c) <= 'F'))
+void
+dump(void)
+{
+	int c;
+
+	c = inchar();
+	if ((isxdigit(c) && c != 'f' && c != 'd') || c == '\n')
+		termch = c;
+	scanhex((void *)&adrs);
+	if (termch != '\n')
+		termch = 0;
+	if (c == 'i') {
+		scanhex(&nidump);
+		if (nidump == 0)
+			nidump = 16;
+		else if (nidump > MAX_DUMP)
+			nidump = MAX_DUMP;
+		adrs += ppc_inst_dump(adrs, nidump, 1);
+		last_cmd = "di\n";
+	} else {
+		scanhex(&ndump);
+		if (ndump == 0)
+			ndump = 64;
+		else if (ndump > MAX_DUMP)
+			ndump = MAX_DUMP;
+		prdump(adrs, ndump);
+		adrs += ndump;
+		last_cmd = "d\n";
+	}
+}
+
+void
+prdump(unsigned long adrs, long ndump)
+{
+	long n, m, c, r, nr;
+	unsigned char temp[16];
+
+	for (n = ndump; n > 0;) {
+		printf(REG, adrs);
+		putchar(' ');
+		r = n < 16? n: 16;
+		nr = mread(adrs, temp, r);
+		adrs += nr;
+		for (m = 0; m < r; ++m) {
+		        if ((m & 7) == 0 && m > 0)
+			    putchar(' ');
+			if (m < nr)
+				printf("%.2x", temp[m]);
+			else
+				printf("%s", fault_chars[fault_type]);
+		}
+		if (m <= 8)
+			printf(" ");
+		for (; m < 16; ++m)
+			printf("  ");
+		printf("  |");
+		for (m = 0; m < r; ++m) {
+			if (m < nr) {
+				c = temp[m];
+				putchar(' ' <= c && c <= '~'? c: '.');
+			} else
+				putchar(' ');
+		}
+		n -= r;
+		for (; m < 16; ++m)
+			putchar(' ');
+		printf("|\n");
+		if (nr < r)
+			break;
+	}
+}
+
+int
+ppc_inst_dump(unsigned long adr, long count, int praddr)
+{
+	int nr, dotted;
+	unsigned long first_adr;
+	unsigned long inst, last_inst = 0;
+	unsigned char val[4];
+
+	dotted = 0;
+	for (first_adr = adr; count > 0; --count, adr += 4) {
+		nr = mread(adr, val, 4);
+		if (nr == 0) {
+			if (praddr) {
+				const char *x = fault_chars[fault_type];
+				printf(REG"  %s%s%s%s\n", adr, x, x, x, x);
+			}
+			break;
+		}
+		inst = GETWORD(val);
+		if (adr > first_adr && inst == last_inst) {
+			if (!dotted) {
+				printf(" ...\n");
+				dotted = 1;
+			}
+			continue;
+		}
+		dotted = 0;
+		last_inst = inst;
+		if (praddr)
+			printf(REG"  %.8x", adr, inst);
+		printf("\t");
+		print_insn_powerpc(inst, adr, 0);	/* always returns 4 */
+		printf("\n");
+	}
+	return adr - first_adr;
+}
+
+void
+print_address(unsigned long addr)
+{
+	xmon_print_symbol(addr, "\t# ", "");
+}
+
+
+/*
+ * Memory operations - move, set, print differences
+ */
+static unsigned long mdest;		/* destination address */
+static unsigned long msrc;		/* source address */
+static unsigned long mval;		/* byte value to set memory to */
+static unsigned long mcount;		/* # bytes to affect */
+static unsigned long mdiffs;		/* max # differences to print */
+
+void
+memops(int cmd)
+{
+	scanhex((void *)&mdest);
+	if( termch != '\n' )
+		termch = 0;
+	scanhex((void *)(cmd == 's'? &mval: &msrc));
+	if( termch != '\n' )
+		termch = 0;
+	scanhex((void *)&mcount);
+	switch( cmd ){
+	case 'm':
+		memmove((void *)mdest, (void *)msrc, mcount);
+		break;
+	case 's':
+		memset((void *)mdest, mval, mcount);
+		break;
+	case 'd':
+		if( termch != '\n' )
+			termch = 0;
+		scanhex((void *)&mdiffs);
+		memdiffs((unsigned char *)mdest, (unsigned char *)msrc, mcount, mdiffs);
+		break;
+	}
+}
+
+void
+memdiffs(unsigned char *p1, unsigned char *p2, unsigned nb, unsigned maxpr)
+{
+	unsigned n, prt;
+
+	prt = 0;
+	for( n = nb; n > 0; --n )
+		if( *p1++ != *p2++ )
+			if( ++prt <= maxpr )
+				printf("%.16x %.2x # %.16x %.2x\n", p1 - 1,
+					p1[-1], p2 - 1, p2[-1]);
+	if( prt > maxpr )
+		printf("Total of %d differences\n", prt);
+}
+
+static unsigned mend;
+static unsigned mask;
+
+void
+memlocate(void)
+{
+	unsigned a, n;
+	unsigned char val[4];
+
+	last_cmd = "ml";
+	scanhex((void *)&mdest);
+	if (termch != '\n') {
+		termch = 0;
+		scanhex((void *)&mend);
+		if (termch != '\n') {
+			termch = 0;
+			scanhex((void *)&mval);
+			mask = ~0;
+			if (termch != '\n') termch = 0;
+			scanhex((void *)&mask);
+		}
+	}
+	n = 0;
+	for (a = mdest; a < mend; a += 4) {
+		if (mread(a, val, 4) == 4
+			&& ((GETWORD(val) ^ mval) & mask) == 0) {
+			printf("%.16x:  %.16x\n", a, GETWORD(val));
+			if (++n >= 10)
+				break;
+		}
+	}
+}
+
+static unsigned long mskip = 0x1000;
+static unsigned long mlim = 0xffffffff;
+
+void
+memzcan(void)
+{
+	unsigned char v;
+	unsigned a;
+	int ok, ook;
+
+	scanhex(&mdest);
+	if (termch != '\n') termch = 0;
+	scanhex(&mskip);
+	if (termch != '\n') termch = 0;
+	scanhex(&mlim);
+	ook = 0;
+	for (a = mdest; a < mlim; a += mskip) {
+		ok = mread(a, &v, 1);
+		if (ok && !ook) {
+			printf("%.8x .. ", a);
+			fflush(stdout);
+		} else if (!ok && ook)
+			printf("%.8x\n", a - mskip);
+		ook = ok;
+		if (a + mskip < a)
+			break;
+	}
+	if (ook)
+		printf("%.8x\n", a - mskip);
+}
+
+void proccall(void)
+{
+	unsigned long args[8];
+	unsigned long ret;
+	int i;
+	typedef unsigned long (*callfunc_t)(unsigned long, unsigned long,
+			unsigned long, unsigned long, unsigned long,
+			unsigned long, unsigned long, unsigned long);
+	callfunc_t func;
+
+	if (!scanhex(&adrs))
+		return;
+	if (termch != '\n')
+		termch = 0;
+	for (i = 0; i < 8; ++i)
+		args[i] = 0;
+	for (i = 0; i < 8; ++i) {
+		if (!scanhex(&args[i]) || termch == '\n')
+			break;
+		termch = 0;
+	}
+	func = (callfunc_t) adrs;
+	ret = 0;
+	if (setjmp(bus_error_jmp) == 0) {
+		catch_memory_errors = 1;
+		sync();
+		ret = func(args[0], args[1], args[2], args[3],
+			   args[4], args[5], args[6], args[7]);
+		sync();
+		printf("return value is %x\n", ret);
+	} else {
+		printf("*** %x exception occurred\n", fault_except);
+	}
+	catch_memory_errors = 0;
+}
+
+/* Input scanning routines */
+int
+skipbl(void)
+{
+	int c;
+
+	if( termch != 0 ){
+		c = termch;
+		termch = 0;
+	} else
+		c = inchar();
+	while( c == ' ' || c == '\t' )
+		c = inchar();
+	return c;
+}
+
+#define N_PTREGS	44
+static char *regnames[N_PTREGS] = {
+	"r0", "r1", "r2", "r3", "r4", "r5", "r6", "r7",
+	"r8", "r9", "r10", "r11", "r12", "r13", "r14", "r15",
+	"r16", "r17", "r18", "r19", "r20", "r21", "r22", "r23",
+	"r24", "r25", "r26", "r27", "r28", "r29", "r30", "r31",
+	"pc", "msr", "or3", "ctr", "lr", "xer", "ccr",
+#ifdef CONFIG_PPC64
+	"softe",
+#else
+	"mq",
+#endif
+	"trap", "dar", "dsisr", "res"
+};
+
+int
+scanhex(unsigned long *vp)
+{
+	int c, d;
+	unsigned long v;
+
+	c = skipbl();
+	if (c == '%') {
+		/* parse register name */
+		char regname[8];
+		int i;
+
+		for (i = 0; i < sizeof(regname) - 1; ++i) {
+			c = inchar();
+			if (!isalnum(c)) {
+				termch = c;
+				break;
+			}
+			regname[i] = c;
+		}
+		regname[i] = 0;
+		for (i = 0; i < N_PTREGS; ++i) {
+			if (strcmp(regnames[i], regname) == 0) {
+				if (xmon_regs == NULL) {
+					printf("regs not available\n");
+					return 0;
+				}
+				*vp = ((unsigned long *)xmon_regs)[i];
+				return 1;
+			}
+		}
+		printf("invalid register name '%%%s'\n", regname);
+		return 0;
+	}
+
+	/* skip leading "0x" if any */
+
+	if (c == '0') {
+		c = inchar();
+		if (c == 'x') {
+			c = inchar();
+		} else {
+			d = hexdigit(c);
+			if (d == EOF) {
+				termch = c;
+				*vp = 0;
+				return 1;
+			}
+		}
+	} else if (c == '$') {
+		int i;
+		for (i=0; i<63; i++) {
+			c = inchar();
+			if (isspace(c)) {
+				termch = c;
+				break;
+			}
+			tmpstr[i] = c;
+		}
+		tmpstr[i++] = 0;
+		*vp = 0;
+		if (setjmp(bus_error_jmp) == 0) {
+			catch_memory_errors = 1;
+			sync();
+			*vp = kallsyms_lookup_name(tmpstr);
+			sync();
+		}
+		catch_memory_errors = 0;
+		if (!(*vp)) {
+			printf("unknown symbol '%s'\n", tmpstr);
+			return 0;
+		}
+		return 1;
+	}
+
+	d = hexdigit(c);
+	if (d == EOF) {
+		termch = c;
+		return 0;
+	}
+	v = 0;
+	do {
+		v = (v << 4) + d;
+		c = inchar();
+		d = hexdigit(c);
+	} while (d != EOF);
+	termch = c;
+	*vp = v;
+	return 1;
+}
+
+void
+scannl(void)
+{
+	int c;
+
+	c = termch;
+	termch = 0;
+	while( c != '\n' )
+		c = inchar();
+}
+
+int hexdigit(int c)
+{
+	if( '0' <= c && c <= '9' )
+		return c - '0';
+	if( 'A' <= c && c <= 'F' )
+		return c - ('A' - 10);
+	if( 'a' <= c && c <= 'f' )
+		return c - ('a' - 10);
+	return EOF;
+}
+
+void
+getstring(char *s, int size)
+{
+	int c;
+
+	c = skipbl();
+	do {
+		if( size > 1 ){
+			*s++ = c;
+			--size;
+		}
+		c = inchar();
+	} while( c != ' ' && c != '\t' && c != '\n' );
+	termch = c;
+	*s = 0;
+}
+
+static char line[256];
+static char *lineptr;
+
+void
+flush_input(void)
+{
+	lineptr = NULL;
+}
+
+int
+inchar(void)
+{
+	if (lineptr == NULL || *lineptr == 0) {
+		if (fgets(line, sizeof(line), stdin) == NULL) {
+			lineptr = NULL;
+			return EOF;
+		}
+		lineptr = line;
+	}
+	return *lineptr++;
+}
+
+void
+take_input(char *str)
+{
+	lineptr = str;
+}
+
+
+static void
+symbol_lookup(void)
+{
+	int type = inchar();
+	unsigned long addr;
+	static char tmp[64];
+
+	switch (type) {
+	case 'a':
+		if (scanhex(&addr))
+			xmon_print_symbol(addr, ": ", "\n");
+		termch = 0;
+		break;
+	case 's':
+		getstring(tmp, 64);
+		if (setjmp(bus_error_jmp) == 0) {
+			catch_memory_errors = 1;
+			sync();
+			addr = kallsyms_lookup_name(tmp);
+			if (addr)
+				printf("%s: %lx\n", tmp, addr);
+			else
+				printf("Symbol '%s' not found.\n", tmp);
+			sync();
+		}
+		catch_memory_errors = 0;
+		termch = 0;
+		break;
+	}
+}
+
+
+/* Print an address in numeric and symbolic form (if possible) */
+static void xmon_print_symbol(unsigned long address, const char *mid,
+			      const char *after)
+{
+	char *modname;
+	const char *name = NULL;
+	unsigned long offset, size;
+
+	printf(REG, address);
+	if (setjmp(bus_error_jmp) == 0) {
+		catch_memory_errors = 1;
+		sync();
+		name = kallsyms_lookup(address, &size, &offset, &modname,
+				       tmpstr);
+		sync();
+		/* wait a little while to see if we get a machine check */
+		__delay(200);
+	}
+
+	catch_memory_errors = 0;
+
+	if (name) {
+		printf("%s%s+%#lx/%#lx", mid, name, offset, size);
+		if (modname)
+			printf(" [%s]", modname);
+	}
+	printf("%s", after);
+}
+
+#ifdef CONFIG_PPC64
+static void dump_slb(void)
+{
+	int i;
+	unsigned long tmp;
+
+	printf("SLB contents of cpu %x\n", smp_processor_id());
+
+	for (i = 0; i < SLB_NUM_ENTRIES; i++) {
+		asm volatile("slbmfee  %0,%1" : "=r" (tmp) : "r" (i));
+		printf("%02d %016lx ", i, tmp);
+
+		asm volatile("slbmfev  %0,%1" : "=r" (tmp) : "r" (i));
+		printf("%016lx\n", tmp);
+	}
+}
+
+static void dump_stab(void)
+{
+	int i;
+	unsigned long *tmp = (unsigned long *)get_paca()->stab_addr;
+
+	printf("Segment table contents of cpu %x\n", smp_processor_id());
+
+	for (i = 0; i < PAGE_SIZE/16; i++) {
+		unsigned long a, b;
+
+		a = *tmp++;
+		b = *tmp++;
+
+		if (a || b) {
+			printf("%03d %016lx ", i, a);
+			printf("%016lx\n", b);
+		}
+	}
+}
+
+void dump_segments(void)
+{
+	if (cpu_has_feature(CPU_FTR_SLB))
+		dump_slb();
+	else
+		dump_stab();
+}
+#endif
+
+#ifdef CONFIG_PPC_STD_MMU_32
+void dump_segments(void)
+{
+	int i;
+
+	printf("sr0-15 =");
+	for (i = 0; i < 16; ++i)
+		printf(" %x", mfsrin(i));
+	printf("\n");
+}
+#endif
+
+void xmon_init(int enable)
+{
+	if (enable) {
+		__debugger = xmon;
+		__debugger_ipi = xmon_ipi;
+		__debugger_bpt = xmon_bpt;
+		__debugger_sstep = xmon_sstep;
+		__debugger_iabr_match = xmon_iabr_match;
+		__debugger_dabr_match = xmon_dabr_match;
+		__debugger_fault_handler = xmon_fault_handler;
+	} else {
+		__debugger = NULL;
+		__debugger_ipi = NULL;
+		__debugger_bpt = NULL;
+		__debugger_sstep = NULL;
+		__debugger_iabr_match = NULL;
+		__debugger_dabr_match = NULL;
+		__debugger_fault_handler = NULL;
+	}
+}
