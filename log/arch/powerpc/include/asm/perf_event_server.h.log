commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index e60aeb46d6a0..3e9703f44c7c 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -1,12 +1,8 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
 /*
  * Performance event support - PowerPC classic/server specific definitions.
  *
  * Copyright 2008-2009 Paul Mackerras, IBM Corporation.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version
- * 2 of the License, or (at your option) any later version.
  */
 
 #include <linux/types.h>

commit 59029136d75022cb8b7c7bebd1738ae70232416e
Author: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
Date:   Sun Jun 10 19:57:01 2018 +0530

    powerpc/perf: Add constraints for power9 l2/l3 bus events
    
    In previous generation processors, both bus events and direct
    events of performance monitoring unit can be individually
    programmabled and monitored in PMCs.
    
    But in Power9, L2/L3 bus events are always available as a
    "bank" of 4 events. To obtain the counts for any of the
    l2/l3 bus events in a given bank, the user will have to
    program PMC4 with corresponding l2/l3 bus event for that
    bank.
    
    Patch enforce two contraints incase of L2/L3 bus events.
    
    1)Any L2/L3 event when programmed is also expected to program corresponding
    PMC4 event from that group.
    2)PMC4 event should always been programmed first due to group constraint
    logic limitation
    
    For ex. consider these L3 bus events
    
    PM_L3_PF_ON_CHIP_MEM (0x460A0),
    PM_L3_PF_MISS_L3 (0x160A0),
    PM_L3_CO_MEM (0x260A0),
    PM_L3_PF_ON_CHIP_CACHE (0x360A0),
    
    1) This is an INVALID group for L3 Bus event monitoring,
    since it is missing PMC4 event.
            perf stat -e "{r160A0,r260A0,r360A0}" < >
    
    And this is a VALID group for L3 Bus events:
            perf stat -e "{r460A0,r160A0,r260A0,r360A0}" < >
    
    2) This is an INVALID group for L3 Bus event monitoring,
    since it is missing PMC4 event.
            perf stat -e "{r260A0,r360A0}" < >
    
    And this is a VALID group for L3 Bus events:
            perf stat -e "{r460A0,r260A0,r360A0}" < >
    
    3) This is an INVALID group for L3 Bus event monitoring,
    since it is missing PMC4 event.
            perf stat -e "{r360A0}" < >
    
    And this is a VALID group for L3 Bus events:
            perf stat -e "{r460A0,r360A0}" < >
    
    Patch here implements group constraint logic suggested by Michael Ellerman.
    
    Signed-off-by: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index 67a8a9585d50..e60aeb46d6a0 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -41,6 +41,8 @@ struct power_pmu {
 	void		(*get_mem_data_src)(union perf_mem_data_src *dsrc,
 				u32 flags, struct pt_regs *regs);
 	void		(*get_mem_weight)(u64 *weight);
+	unsigned long	group_constraint_mask;
+	unsigned long	group_constraint_val;
 	u64             (*bhrb_filter_map)(u64 branch_sample_type);
 	void            (*config_bhrb)(u64 pmu_bhrb_filter);
 	void		(*disable_pmc)(unsigned int pmc, unsigned long mmcr[]);

commit b58064da046243f0c988afd939997e9317dc6d48
Author: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
Date:   Sun Mar 4 17:26:26 2018 +0530

    powerpc/perf: Infrastructure to support addition of blacklisted events
    
    Introduce code to support addition of blacklisted events for a
    processor version. Blacklisted events are events that are known to not
    count correctly on that CPU revision, and so should be prevented from
    being counted so as to avoid user confusion.
    
    A 'pointer' and 'int' variable to hold the number of events are added
    to 'struct power_pmu', along with a generic function to loop through
    the list to validate the given event. Generic function
    'is_event_blacklisted' is called in power_pmu_event_init() to detect
    and reject early.
    
    Signed-off-by: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index 723bf48e7494..67a8a9585d50 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -53,6 +53,8 @@ struct power_pmu {
 			       [PERF_COUNT_HW_CACHE_OP_MAX]
 			       [PERF_COUNT_HW_CACHE_RESULT_MAX];
 
+	int		n_blacklist_ev;
+	int 		*blacklist_ev;
 	/* BHRB entries in the PMU */
 	int		bhrb_nr;
 };

commit 170a315f41c647ce826e389c64047ee1f4cd2dde
Author: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
Date:   Tue Apr 11 07:21:07 2017 +0530

    powerpc/perf: Support to export MMCRA[TEC*] field to userspace
    
    Threshold feature when used with MMCRA [Threshold Event Counter Event],
    MMCRA[Threshold Start event] and MMCRA[Threshold End event] will update
    MMCRA[Threashold Event Counter Exponent] and MMCRA[Threshold Event
    Counter Multiplier] with the corresponding threshold event count values.
    Patch to export MMCRA[TECX/TECM] to userspace in 'weight' field of
    struct perf_sample_data.
    
    Signed-off-by: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index 446cdcd9b7f5..723bf48e7494 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -40,6 +40,7 @@ struct power_pmu {
 				u64 alt[]);
 	void		(*get_mem_data_src)(union perf_mem_data_src *dsrc,
 				u32 flags, struct pt_regs *regs);
+	void		(*get_mem_weight)(u64 *weight);
 	u64             (*bhrb_filter_map)(u64 branch_sample_type);
 	void            (*config_bhrb)(u64 pmu_bhrb_filter);
 	void		(*disable_pmc)(unsigned int pmc, unsigned long mmcr[]);

commit 79e96f8f930d425ab48c511f8a6db16ca7fc68b1
Author: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
Date:   Tue Apr 11 07:21:06 2017 +0530

    powerpc/perf: Export memory hierarchy info to user space
    
    The LDST field and DATA_SRC in SIER identifies the memory hierarchy level
    (eg: L1, L2 etc), from which a data-cache miss for a marked instruction
    was satisfied. Use the 'perf_mem_data_src' object to export this
    hierarchy level to user space.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Signed-off-by: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index ae0a23091a9b..446cdcd9b7f5 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -38,6 +38,8 @@ struct power_pmu {
 				unsigned long *valp);
 	int		(*get_alternatives)(u64 event_id, unsigned int flags,
 				u64 alt[]);
+	void		(*get_mem_data_src)(union perf_mem_data_src *dsrc,
+				u32 flags, struct pt_regs *regs);
 	u64             (*bhrb_filter_map)(u64 branch_sample_type);
 	void            (*config_bhrb)(u64 pmu_bhrb_filter);
 	void		(*disable_pmc)(unsigned int pmc, unsigned long mmcr[]);

commit 27593d72c4ad451ed13af35354b941bcd0abcec6
Author: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
Date:   Wed Jan 18 09:12:56 2017 +0530

    powerpc/perf: Use MSR to report privilege level on P9 DD1
    
    SIER and SIAR are not updated correctly for some samples, so force the
    use of MSR and regs->nip instead for misc_flag updates. This is done by
    adding a new ppmu flag and updating the use_siar logic in
    perf_read_regs() to use it, and dropping the PPMU_HAS_SIER flag.
    
    Signed-off-by: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
    [mpe: Rename flag to PPMU_NO_SIAR, and also drop PPMU_HAS_SIER]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index e157489ee7a1..ae0a23091a9b 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -65,6 +65,7 @@ struct power_pmu {
 #define PPMU_HAS_SSLOT		0x00000020 /* Has sampled slot in MMCRA */
 #define PPMU_HAS_SIER		0x00000040 /* Has SIER */
 #define PPMU_ARCH_207S		0x00000080 /* PMC is architecture v2.07S */
+#define PPMU_NO_SIAR		0x00000100 /* Do not use SIAR */
 
 /*
  * Values for flags to get_alternatives()

commit e0728b50d480da6be228dd160a43b37e4c0b1636
Author: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
Date:   Mon Jan 11 14:55:26 2016 -0800

    powerpc/perf: Export Power8 generic and cache events to sysfs
    
    Power8 supports a large number of events in each susbystem so when a
    user runs:
    
            perf stat -e branch-instructions sleep 1
            perf stat -e L1-dcache-loads sleep 1
    
    it is not clear as to which PMU events were monitored.
    
    Export the generic hardware and cache perf events for Power8 to sysfs,
    so users can precisely determine the PMU event monitored by the generic
    event.
    
    Eg:
            cat /sys/bus/event_source/devices/cpu/events/branch-instructions
            event=0x10068
    
            $ cat /sys/bus/event_source/devices/cpu/events/L1-dcache-loads
            event=0x100ee
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index 069108717163..e157489ee7a1 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -136,6 +136,11 @@ extern ssize_t power_events_sysfs_show(struct device *dev,
  * event 'cpu-cycles' can have two entries in sysfs: 'cpu-cycles' and
  * 'PM_CYC' where the latter is the name by which the event is known in
  * POWER CPU specification.
+ *
+ * Similarly, some hardware and cache events use the same event code. Eg.
+ * on POWER8, both "cache-references" and "L1-dcache-loads" events refer
+ * to the same event, PM_LD_REF_L1.  The suffix, allows us to have two
+ * sysfs objects for the same event and thus two entries/aliases in sysfs.
  */
 #define	EVENT_VAR(_id, _suffix)		event_attr_##_id##_suffix
 #define	EVENT_PTR(_id, _suffix)		&EVENT_VAR(_id, _suffix).attr.attr
@@ -147,5 +152,8 @@ extern ssize_t power_events_sysfs_show(struct device *dev,
 #define	GENERIC_EVENT_ATTR(_name, _id)	EVENT_ATTR(_name, _id, _g)
 #define	GENERIC_EVENT_PTR(_id)		EVENT_PTR(_id, _g)
 
+#define	CACHE_EVENT_ATTR(_name, _id)	EVENT_ATTR(_name, _id, _c)
+#define	CACHE_EVENT_PTR(_id)		EVENT_PTR(_id, _c)
+
 #define	POWER_EVENT_ATTR(_name, _id)	EVENT_ATTR(_name, _id, _p)
 #define	POWER_EVENT_PTR(_id)		EVENT_PTR(_id, _p)

commit d4969e2459c6e852a6862256cf8e869aaa3e8adf
Author: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
Date:   Mon Jan 11 14:55:25 2016 -0800

    powerpc/perf: Remove PME_ prefix for power7 events
    
    We used the PME_ prefix earlier to avoid some macro/variable name
    collisions.  We have since changed the way we define/use the event
    macros so we no longer need the prefix.
    
    By dropping the prefix, we keep the the event macros consistent with
    their official names.
    
    Reported-by: Michael Ellerman <ellerman@au1.ibm.com>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index 814622146d5a..069108717163 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -141,7 +141,7 @@ extern ssize_t power_events_sysfs_show(struct device *dev,
 #define	EVENT_PTR(_id, _suffix)		&EVENT_VAR(_id, _suffix).attr.attr
 
 #define	EVENT_ATTR(_name, _id, _suffix)					\
-	PMU_EVENT_ATTR(_name, EVENT_VAR(_id, _suffix), PME_##_id,	\
+	PMU_EVENT_ATTR(_name, EVENT_VAR(_id, _suffix), _id,		\
 			power_events_sysfs_show)
 
 #define	GENERIC_EVENT_ATTR(_name, _id)	EVENT_ATTR(_name, _id, _g)

commit 8abd818fc76705065f3699a753ad2df594dafe86
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Jul 23 21:12:37 2014 +1000

    powerpc/perf: Pass the struct perf_events down to compute_mmcr()
    
    To support per-event exclude settings on Power8 we need access to the
    struct perf_events in compute_mmcr().
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index b3e936027b26..814622146d5a 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -19,6 +19,8 @@
 #define MAX_EVENT_ALTERNATIVES	8
 #define MAX_LIMITED_HWCOUNTERS	2
 
+struct perf_event;
+
 /*
  * This struct provides the constants and functions needed to
  * describe the PMU on a particular POWER-family CPU.
@@ -30,7 +32,8 @@ struct power_pmu {
 	unsigned long	add_fields;
 	unsigned long	test_adder;
 	int		(*compute_mmcr)(u64 events[], int n_ev,
-				unsigned int hwc[], unsigned long mmcr[]);
+				unsigned int hwc[], unsigned long mmcr[],
+				struct perf_event *pevents[]);
 	int		(*get_constraint)(u64 event_id, unsigned long *mskp,
 				unsigned long *valp);
 	int		(*get_alternatives)(u64 event_id, unsigned int flags,

commit 4d9690dd56b0d18f2af8a9d4a279cb205aae3345
Author: Joel Stanley <joel@jms.id.au>
Date:   Tue Jul 8 16:08:21 2014 +0930

    powerpc/perf: Add PPMU_ARCH_207S define
    
    Instead of separate bits for every POWER8 PMU feature, have a single one
    for v2.07 of the architecture.
    
    This saves us adding a MMCR2 define for a future patch.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Joel Stanley <joel@jms.id.au>
    Acked-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index 9ed737146dbb..b3e936027b26 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -61,8 +61,7 @@ struct power_pmu {
 #define PPMU_SIAR_VALID		0x00000010 /* Processor has SIAR Valid bit */
 #define PPMU_HAS_SSLOT		0x00000020 /* Has sampled slot in MMCRA */
 #define PPMU_HAS_SIER		0x00000040 /* Has SIER */
-#define PPMU_BHRB		0x00000080 /* has BHRB feature enabled */
-#define PPMU_EBB		0x00000100 /* supports event based branch */
+#define PPMU_ARCH_207S		0x00000080 /* PMC is architecture v2.07S */
 
 /*
  * Values for flags to get_alternatives()

commit 5f6d0380c64051400961accf99ec41e70ec6d8ca
Author: Anshuman Khandual <khandual@linux.vnet.ibm.com>
Date:   Fri Mar 14 16:00:27 2014 +1100

    powerpc/perf: Define perf_event_print_debug() to print PMU register values
    
    Currently the sysrq ShowRegs command does not print any PMU registers as
    we have an empty definition for perf_event_print_debug(). This patch
    defines perf_event_print_debug() to print various PMU registers.
    
    Example output:
    
    CPU: 0 PMU registers, ppmu = POWER7 n_counters = 6
    PMC1:  00000000 PMC2: 00000000 PMC3: 00000000 PMC4: 00000000
    PMC5:  00000000 PMC6: 00000000 PMC7: deadbeef PMC8: deadbeef
    MMCR0: 0000000080000000 MMCR1: 0000000000000000 MMCRA: 0f00000001000000
    SIAR:  0000000000000000 SDAR:  0000000000000000 SIER:  0000000000000000
    
    Signed-off-by: Anshuman Khandual <khandual@linux.vnet.ibm.com>
    [mpe: Fix 32 bit build and rework formatting for compactness]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index 3fd2f1b6f906..9ed737146dbb 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -14,6 +14,7 @@
 #include <linux/device.h>
 #include <uapi/asm/perf_event.h>
 
+/* Update perf_event_print_debug() if this changes */
 #define MAX_HWEVENTS		8
 #define MAX_EVENT_ALTERNATIVES	8
 #define MAX_LIMITED_HWCOUNTERS	2

commit c9572f010d369d9905309f63e31180f291b66a8a
Merge: 58cea307432e d4e4ab86bcba
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Aug 15 10:00:09 2013 +0200

    Merge tag 'v3.11-rc5' into perf/core
    
    Merge Linux 3.11-rc5, to sync up with the latest upstream fixes since -rc1.
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 8d7c55d01e4648605fd0dacc82d8d3989ead4db7
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Jul 23 18:07:45 2013 +1000

    powerpc/perf: Export PERF_EVENT_CONFIG_EBB_SHIFT to userspace
    
    We use bit 63 of the event code for userspace to request that the event
    be counted using EBB (Event Based Branches). Export this value, making
    it part of the API - though only on processors that support EBB.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index 2dd7bfc459be..8b2492644754 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -12,6 +12,7 @@
 #include <linux/types.h>
 #include <asm/hw_irq.h>
 #include <linux/device.h>
+#include <uapi/asm/perf_event.h>
 
 #define MAX_HWEVENTS		8
 #define MAX_EVENT_ALTERNATIVES	8
@@ -69,11 +70,6 @@ struct power_pmu {
 #define PPMU_LIMITED_PMC_REQD	2	/* have to put this on a limited PMC */
 #define PPMU_ONLY_COUNT_RUN	4	/* only counting in run state */
 
-/*
- * We use the event config bit 63 as a flag to request EBB.
- */
-#define EVENT_CONFIG_EBB_SHIFT	63
-
 extern int register_power_pmu(struct power_pmu *);
 
 struct pt_regs;

commit 5a9821321e0a61674fd5c4b5a9e95007d0e7e052
Merge: e43fff2b98b4 2a08c3ec4f7d
Author: Ingo Molnar <mingo@kernel.org>
Date:   Fri Jul 19 09:35:30 2013 +0200

    Merge tag 'perf-core-for-mingo' of git://git.kernel.org/pub/scm/linux/kernel/git/acme/linux into perf/core
    
    Pull perf/core improvements and fixes from Arnaldo Carvalho de Melo:
    
     * Add missing 'finished_round' event forwarding in 'perf inject', from Adrian Hunter.
    
     * Assorted tidy ups, from Adrian Hunter.
    
     * Fall back to sysfs event names when parsing fails, from Andi Kleen.
    
     * List pmu events in perf list, from Andi Kleen.
    
     * Cleanup some memory allocation/freeing uses, from David Ahern.
    
     * Add option to collapse undesired parts of call graph, from Greg Price.
    
     * Prep work for multi perf data file storage, from Jiri Olsa.
    
     * Add support for more than two files comparision in 'perf diff', from Jiri Olsa
    
     * A few more 'perf test' improvements, from Jiri Olsa
    
     * libtraceevent cleanups, from Namhyung Kim.
    
     * Remove odd build stall in 'perf sched' by moving a large struct initialization
       from a local variable to a global one, from Namhyung Kim.
    
     * Add support for callchains in the gtk UI, from Namhyung Kim.
    
     * Do not apply symfs for an absolute vmlinux path, fix from Namhyung Kim.
    
     * Use default include path notation for libtraceevent, from Robert Richter.
    
     * Fix 'make tools/perf', from Robert Richter.
    
     * Make Power7 events available, from Runzhen Wang.
    
     * Add --objdump option to 'perf top', from Sukadev Bhattiprolu.
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit cfe0d8ba14a1d98245b371e486c68f37eba1ca52
Author: Runzhen Wang <runzhen@linux.vnet.ibm.com>
Date:   Fri Jun 28 16:14:57 2013 +0800

    perf tools: Make Power7 events available for perf
    
    Power7 supports over 530 different perf events but only a small subset
    of these can be specified by name, for the remaining events, we must
    specify them by their raw code:
    
            perf stat -e r2003c <application>
    
    This patch makes all the POWER7 events available in sysfs.  So we can
    instead specify these as:
    
            perf stat -e 'cpu/PM_CMPLU_STALL_DFU/' <application>
    
    where PM_CMPLU_STALL_DFU is the r2003c in previous example.
    
    Before this patch is applied, the size of power7-pmu.o is:
    
    $ size arch/powerpc/perf/power7-pmu.o
       text    data     bss     dec     hex filename
       3073    2720       0    5793    16a1 arch/powerpc/perf/power7-pmu.o
    
    and after the patch is applied, it is:
    
    $ size arch/powerpc/perf/power7-pmu.o
       text    data     bss     dec     hex filename
      15950   31112       0   47062    b7d6 arch/powerpc/perf/power7-pmu.o
    
    For the run time overhead, I use two scripts, one is "event_name.sh",
    which contains 50 event names, it looks like:
    
     # ./perf record  -e 'cpu/PM_CMPLU_STALL_DFU/' -e .....  /bin/sleep 1
    
    the other one is named "event_code.sh" which use corresponding  events
    raw
    code instead of events names, it looks like:
    
     # ./perf record -e r2003c -e ......  /bin/sleep 1
    
    below is the result.
    
    Using events name:
    
    [root@localhost perf]# time ./event_name.sh
    [ perf record: Woken up 1 times to write data ]
    [ perf record: Captured and wrote 0.002 MB perf.data (~102 samples) ]
    
    real    0m1.192s
    user    0m0.028s
    sys     0m0.106s
    
    Using events raw code:
    
    [root@localhost perf]# time ./event_code.sh
    [ perf record: Woken up 1 times to write data ]
    [ perf record: Captured and wrote 0.003 MB perf.data (~112 samples) ]
    
    real    0m1.198s
    user    0m0.028s
    sys     0m0.105s
    
    Signed-off-by: Runzhen Wang <runzhen@linux.vnet.ibm.com>
    Acked-by: Michael Ellerman <michael@ellerman.id.au>
    Cc: icycoder@gmail.com
    Cc: linuxppc-dev@lists.ozlabs.org
    Cc: Michael Ellerman <michael@ellerman.id.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Runzhen Wang <runzhew@clemson.edu>
    Cc: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Cc: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Link: http://lkml.kernel.org/r/1372407297-6996-3-git-send-email-runzhen@linux.vnet.ibm.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index f265049dd7d6..d9270d8eb087 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -136,11 +136,11 @@ extern ssize_t power_events_sysfs_show(struct device *dev,
 #define	EVENT_PTR(_id, _suffix)		&EVENT_VAR(_id, _suffix).attr.attr
 
 #define	EVENT_ATTR(_name, _id, _suffix)					\
-	PMU_EVENT_ATTR(_name, EVENT_VAR(_id, _suffix), PME_PM_##_id,	\
+	PMU_EVENT_ATTR(_name, EVENT_VAR(_id, _suffix), PME_##_id,	\
 			power_events_sysfs_show)
 
 #define	GENERIC_EVENT_ATTR(_name, _id)	EVENT_ATTR(_name, _id, _g)
 #define	GENERIC_EVENT_PTR(_id)		EVENT_PTR(_id, _g)
 
-#define	POWER_EVENT_ATTR(_name, _id)	EVENT_ATTR(PM_##_name, _id, _p)
+#define	POWER_EVENT_ATTR(_name, _id)	EVENT_ATTR(_name, _id, _p)
 #define	POWER_EVENT_PTR(_id)		EVENT_PTR(_id, _p)

commit 330a1eb7775ba876dbd46b9885556e57f705e3d4
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Fri Jun 28 18:15:16 2013 +1000

    powerpc/perf: Core EBB support for 64-bit book3s
    
    Add support for EBB (Event Based Branches) on 64-bit book3s. See the
    included documentation for more details.
    
    EBBs are a feature which allows the hardware to branch directly to a
    specified user space address when a PMU event overflows. This can be
    used by programs for self-monitoring with no kernel involvement in the
    inner loop.
    
    Most of the logic is in the generic book3s code, primarily to avoid a
    proliferation of PMU callbacks.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index f265049dd7d6..2dd7bfc459be 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -60,6 +60,7 @@ struct power_pmu {
 #define PPMU_HAS_SSLOT		0x00000020 /* Has sampled slot in MMCRA */
 #define PPMU_HAS_SIER		0x00000040 /* Has SIER */
 #define PPMU_BHRB		0x00000080 /* has BHRB feature enabled */
+#define PPMU_EBB		0x00000100 /* supports event based branch */
 
 /*
  * Values for flags to get_alternatives()
@@ -68,6 +69,11 @@ struct power_pmu {
 #define PPMU_LIMITED_PMC_REQD	2	/* have to put this on a limited PMC */
 #define PPMU_ONLY_COUNT_RUN	4	/* only counting in run state */
 
+/*
+ * We use the event config bit 63 as a flag to request EBB.
+ */
+#define EVENT_CONFIG_EBB_SHIFT	63
+
 extern int register_power_pmu(struct power_pmu *);
 
 struct pt_regs;

commit 3925f46bb5902ba9f227591584e27acb6a32c9b0
Author: Anshuman Khandual <khandual@linux.vnet.ibm.com>
Date:   Mon Apr 22 19:42:44 2013 +0000

    powerpc/perf: Enable branch stack sampling framework
    
    Provides basic enablement for perf branch stack sampling framework on
    POWER8 processor based platforms. Adds new BHRB related elements into
    cpu_hw_event structure to represent current BHRB config, BHRB filter
    configuration, manage context and to hold output BHRB buffer during
    PMU interrupt before passing to the user space. This also enables
    processing of BHRB data and converts them into generic perf branch
    stack data format.
    
    Signed-off-by: Anshuman Khandual <khandual@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index 3f0c15c6f068..f265049dd7d6 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -73,6 +73,7 @@ extern int register_power_pmu(struct power_pmu *);
 struct pt_regs;
 extern unsigned long perf_misc_flags(struct pt_regs *regs);
 extern unsigned long perf_instruction_pointer(struct pt_regs *regs);
+extern unsigned long int read_bhrb(int n);
 
 /*
  * Only override the default definitions in include/linux/perf_event.h

commit 5afc9b52a797790bd02680207d183ba218e73d20
Author: Anshuman Khandual <khandual@linux.vnet.ibm.com>
Date:   Mon Apr 22 19:42:42 2013 +0000

    powerpc/perf: Add new BHRB related generic functions, data and flags
    
    This patch adds couple of generic functions to power_pmu structure
    which would configure the BHRB and it's filters. It also adds
    representation of the number of BHRB entries present on the PMU.
    A new PMU flag PPMU_BHRB would indicate presence of BHRB feature.
    
    Signed-off-by: Anshuman Khandual <khandual@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index 57b42da03b62..3f0c15c6f068 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -33,6 +33,8 @@ struct power_pmu {
 				unsigned long *valp);
 	int		(*get_alternatives)(u64 event_id, unsigned int flags,
 				u64 alt[]);
+	u64             (*bhrb_filter_map)(u64 branch_sample_type);
+	void            (*config_bhrb)(u64 pmu_bhrb_filter);
 	void		(*disable_pmc)(unsigned int pmc, unsigned long mmcr[]);
 	int		(*limited_pmc_event)(u64 event_id);
 	u32		flags;
@@ -42,6 +44,9 @@ struct power_pmu {
 	int		(*cache_events)[PERF_COUNT_HW_CACHE_MAX]
 			       [PERF_COUNT_HW_CACHE_OP_MAX]
 			       [PERF_COUNT_HW_CACHE_RESULT_MAX];
+
+	/* BHRB entries in the PMU */
+	int		bhrb_nr;
 };
 
 /*
@@ -54,6 +59,7 @@ struct power_pmu {
 #define PPMU_SIAR_VALID		0x00000010 /* Processor has SIAR Valid bit */
 #define PPMU_HAS_SSLOT		0x00000020 /* Has sampled slot in MMCRA */
 #define PPMU_HAS_SIER		0x00000040 /* Has SIER */
+#define PPMU_BHRB		0x00000080 /* has BHRB feature enabled */
 
 /*
  * Values for flags to get_alternatives()

commit 8f61aa325fab3a40b7c847bd35601ad99d7959c9
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Apr 25 19:28:27 2013 +0000

    powerpc/perf: Add support for SIER
    
    On power8 we have a new SIER (Sampled Instruction Event Register), which
    captures information about instructions when we have random sampling
    enabled.
    
    Add support for loading the SIER into pt_regs, overloading regs->dar.
    Also set the new NO_SIPR flag in regs->result if we don't have SIPR.
    
    Update regs_sihv/sipr() to look for SIPR/SIHV in SIER.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index 7074aeccb9f9..57b42da03b62 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -53,6 +53,7 @@ struct power_pmu {
 #define PPMU_NO_CONT_SAMPLING	0x00000008 /* no continuous sampling */
 #define PPMU_SIAR_VALID		0x00000010 /* Processor has SIAR Valid bit */
 #define PPMU_HAS_SSLOT		0x00000020 /* Has sampled slot in MMCRA */
+#define PPMU_HAS_SIER		0x00000040 /* Has SIER */
 
 /*
  * Values for flags to get_alternatives()

commit 7a7868326d77416018e8f3b4c4697a3c57444549
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Apr 25 19:28:23 2013 +0000

    powerpc/perf: Add an explict flag indicating presence of SLOT field
    
    In perf_ip_adjust() we potentially use the MMCRA[SLOT] field to adjust
    the reported IP of a sampled instruction.
    
    Currently the logic is written so that if the backend does NOT have
    the PPMU_ALT_SIPR flag set then we assume MMCRA[SLOT] exists.
    
    However on power8 we do not want to set ALT_SIPR (it's in a third
    location), and we also do not have MMCRA[SLOT].
    
    So add a new flag which only indicates whether MMCRA[SLOT] exists.
    
    Naively we'd set it on everything except power6/7, because they set
    ALT_SIPR, and we've reversed the polarity of the flag. But it's more
    complicated than that.
    
    mpc7450 is 32-bit, and uses its own version of perf_ip_adjust()
    which doesn't use MMCRA[SLOT], so it doesn't need the new flag set and
    the behaviour is unchanged.
    
    PPC970 (and I assume power4) don't have MMCRA[SLOT], so shouldn't have
    the new flag set. This is a behaviour change on those cpus, though we
    were probably getting lucky and the bits in question were 0.
    
    power5 and power5+ set the new flag, behaviour unchanged.
    
    power6 & power7 do not set the new flag, behaviour unchanged.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index d0aec72722e9..7074aeccb9f9 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -52,6 +52,7 @@ struct power_pmu {
 #define PPMU_NO_SIPR		0x00000004 /* no SIPR/HV in MMCRA at all */
 #define PPMU_NO_CONT_SAMPLING	0x00000008 /* no continuous sampling */
 #define PPMU_SIAR_VALID		0x00000010 /* Processor has SIAR Valid bit */
+#define PPMU_HAS_SSLOT		0x00000020 /* Has sampled slot in MMCRA */
 
 /*
  * Values for flags to get_alternatives()

commit 9d3cae26acb471d5954cfdc25d1438b32060babe
Merge: df24eef3e794 8520e443aa56
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Feb 23 17:09:55 2013 -0800

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc
    
    Pull powerpc updates from Benjamin Herrenschmidt:
     "So from the depth of frozen Minnesota, here's the powerpc pull request
      for 3.9.  It has a few interesting highlights, in addition to the
      usual bunch of bug fixes, minor updates, embedded device tree updates
      and new boards:
    
       - Hand tuned asm implementation of SHA1 (by Paulus & Michael
         Ellerman)
    
       - Support for Doorbell interrupts on Power8 (kind of fast
         thread-thread IPIs) by Ian Munsie
    
       - Long overdue cleanup of the way we handle relocation of our open
         firmware trampoline (prom_init.c) on 64-bit by Anton Blanchard
    
       - Support for saving/restoring & context switching the PPR (Processor
         Priority Register) on server processors that support it.  This
         allows the kernel to preserve thread priorities established by
         userspace.  By Haren Myneni.
    
       - DAWR (new watchpoint facility) support on Power8 by Michael Neuling
    
       - Ability to change the DSCR (Data Stream Control Register) which
         controls cache prefetching on a running process via ptrace by
         Alexey Kardashevskiy
    
       - Support for context switching the TAR register on Power8 (new
         branch target register meant to be used by some new specific
         userspace perf event interrupt facility which is yet to be enabled)
         by Ian Munsie.
    
       - Improve preservation of the CFAR register (which captures the
         origin of a branch) on various exception conditions by Paulus.
    
       - Move the Bestcomm DMA driver from arch powerpc to drivers/dma where
         it belongs by Philippe De Muyter
    
       - Support for Transactional Memory on Power8 by Michael Neuling
         (based on original work by Matt Evans).  For those curious about
         the feature, the patch contains a pretty good description."
    
    (See commit db8ff907027b: "powerpc: Documentation for transactional
    memory on powerpc" for the mentioned description added to the file
    Documentation/powerpc/transactional_memory.txt)
    
    * 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc: (140 commits)
      powerpc/kexec: Disable hard IRQ before kexec
      powerpc/85xx: l2sram - Add compatible string for BSC9131 platform
      powerpc/85xx: bsc9131 - Correct typo in SDHC device node
      powerpc/e500/qemu-e500: enable coreint
      powerpc/mpic: allow coreint to be determined by MPIC version
      powerpc/fsl_pci: Store the pci ctlr device ptr in the pci ctlr struct
      powerpc/85xx: Board support for ppa8548
      powerpc/fsl: remove extraneous DIU platform functions
      arch/powerpc/platforms/85xx/p1022_ds.c: adjust duplicate test
      powerpc: Documentation for transactional memory on powerpc
      powerpc: Add transactional memory to pseries and ppc64 defconfigs
      powerpc: Add config option for transactional memory
      powerpc: Add transactional memory to POWER8 cpu features
      powerpc: Add new transactional memory state to the signal context
      powerpc: Hook in new transactional memory code
      powerpc: Routines for FP/VSX/VMX unavailable during a transaction
      powerpc: Add transactional memory unavaliable execption handler
      powerpc: Add reclaim and recheckpoint functions for context switching transactional memory processes
      powerpc: Add FP/VSX and VMX register load functions for transactional memory
      powerpc: Add helper functions for transactional memory context switching
      ...

commit f2b4367a69c60c644a1df36f63a65e0e677d3b0f
Author: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
Date:   Tue Feb 5 15:04:49 2013 -0800

    perf/powerpc: Fix build error
    
    Fix compile errors like those below:
    
      CC      arch/powerpc/perf/power7-pmu.o
       /home/git/linux/arch/powerpc/perf/power7-pmu.c:397:2: error: initialization from incompatible pointer type [-Werror]
    
    Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Acked-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>
    Cc: linuxppc-dev@ozlabs.org
    Link: http://lkml.kernel.org/r/20130205231938.GA24125@us.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index b29fcc651601..136bba62efa4 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -124,7 +124,7 @@ extern ssize_t power_events_sysfs_show(struct device *dev,
  * POWER CPU specification.
  */
 #define	EVENT_VAR(_id, _suffix)		event_attr_##_id##_suffix
-#define	EVENT_PTR(_id, _suffix)		&EVENT_VAR(_id, _suffix)
+#define	EVENT_PTR(_id, _suffix)		&EVENT_VAR(_id, _suffix).attr.attr
 
 #define	EVENT_ATTR(_name, _id, _suffix)					\
 	PMU_EVENT_ATTR(_name, EVENT_VAR(_id, _suffix), PME_PM_##_id,	\

commit 886c3b2d677fe248cce8101fa66a1b3e05c3ba16
Author: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
Date:   Tue Jan 22 22:25:29 2013 -0800

    perf/POWER7: Make some POWER7 events available in sysfs
    
    Make some POWER7-specific perf events available in sysfs.
    
            $ /bin/ls -1 /sys/bus/event_source/devices/cpu/events/
            branch-instructions
            branch-misses
            cache-misses
            cache-references
            cpu-cycles
            instructions
            PM_BRU_FIN
            PM_BRU_MPRED
            PM_CMPLU_STALL
            PM_CYC
            PM_GCT_NOSLOT_CYC
            PM_INST_CMPL
            PM_LD_MISS_L1
            PM_LD_REF_L1
            stalled-cycles-backend
            stalled-cycles-frontend
    
    where the 'PM_*' events are POWER specific and the others are the
    generic events.
    
    This will enable users to specify these events with their symbolic
    names rather than with their raw code.
    
            perf stat -e 'cpu/PM_CYC' ...
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Anton Blanchard <anton@au1.ibm.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Robert Richter <robert.richter@amd.com>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: linuxppc-dev@ozlabs.org
    Link: http://lkml.kernel.org/r/20130123062528.GE13720@us.ibm.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index b9b6c557bd0c..b29fcc651601 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -132,3 +132,6 @@ extern ssize_t power_events_sysfs_show(struct device *dev,
 
 #define	GENERIC_EVENT_ATTR(_name, _id)	EVENT_ATTR(_name, _id, _g)
 #define	GENERIC_EVENT_PTR(_id)		EVENT_PTR(_id, _g)
+
+#define	POWER_EVENT_ATTR(_name, _id)	EVENT_ATTR(PM_##_name, _id, _p)
+#define	POWER_EVENT_PTR(_id)		EVENT_PTR(_id, _p)

commit 1c53a270724df91276d28d66f8e5a302fc6a5d74
Author: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
Date:   Tue Jan 22 22:24:54 2013 -0800

    perf/POWER7: Make generic event translations available in sysfs
    
    Make the generic perf events in POWER7 available via sysfs.
    
            $ ls /sys/bus/event_source/devices/cpu/events
            branch-instructions
            branch-misses
            cache-misses
            cache-references
            cpu-cycles
            instructions
            stalled-cycles-backend
            stalled-cycles-frontend
    
            $ cat /sys/bus/event_source/devices/cpu/events/cache-misses
            event=0x400f0
    
    This patch is based on commits that implement this functionality on x86.
    Eg:
            commit a47473939db20e3961b200eb00acf5fcf084d755
            Author: Jiri Olsa <jolsa@redhat.com>
            Date:   Wed Oct 10 14:53:11 2012 +0200
    
                perf/x86: Make hardware event translations available in sysfs
    
    Changelog:[v2]
            [Jiri Osla] Drop EVENT_ID() macro since it is only used once.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Anton Blanchard <anton@au1.ibm.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Robert Richter <robert.richter@amd.com>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: linuxppc-dev@ozlabs.org
    Link: http://lkml.kernel.org/r/20130123062454.GD13720@us.ibm.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index 9710be3a2d17..b9b6c557bd0c 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -11,6 +11,7 @@
 
 #include <linux/types.h>
 #include <asm/hw_irq.h>
+#include <linux/device.h>
 
 #define MAX_HWEVENTS		8
 #define MAX_EVENT_ALTERNATIVES	8
@@ -35,6 +36,7 @@ struct power_pmu {
 	void		(*disable_pmc)(unsigned int pmc, unsigned long mmcr[]);
 	int		(*limited_pmc_event)(u64 event_id);
 	u32		flags;
+	const struct attribute_group	**attr_groups;
 	int		n_generic;
 	int		*generic_events;
 	int		(*cache_events)[PERF_COUNT_HW_CACHE_MAX]
@@ -109,3 +111,24 @@ extern unsigned long perf_instruction_pointer(struct pt_regs *regs);
  * If an event_id is not subject to the constraint expressed by a particular
  * field, then it will have 0 in both the mask and value for that field.
  */
+
+extern ssize_t power_events_sysfs_show(struct device *dev,
+				struct device_attribute *attr, char *page);
+
+/*
+ * EVENT_VAR() is same as PMU_EVENT_VAR with a suffix.
+ *
+ * Having a suffix allows us to have aliases in sysfs - eg: the generic
+ * event 'cpu-cycles' can have two entries in sysfs: 'cpu-cycles' and
+ * 'PM_CYC' where the latter is the name by which the event is known in
+ * POWER CPU specification.
+ */
+#define	EVENT_VAR(_id, _suffix)		event_attr_##_id##_suffix
+#define	EVENT_PTR(_id, _suffix)		&EVENT_VAR(_id, _suffix)
+
+#define	EVENT_ATTR(_name, _id, _suffix)					\
+	PMU_EVENT_ATTR(_name, EVENT_VAR(_id, _suffix), PME_PM_##_id,	\
+			power_events_sysfs_show)
+
+#define	GENERIC_EVENT_ATTR(_name, _id)	EVENT_ATTR(_name, _id, _g)
+#define	GENERIC_EVENT_PTR(_id)		EVENT_PTR(_id, _g)

commit 6f79cb8134c5cd9f3346087906829013dce8d460
Author: Anshuman Khandual <khandual@linux.vnet.ibm.com>
Date:   Mon Nov 19 01:11:46 2012 +0000

    powerpc/perf: Change PMU flag representation from decimal to hex
    
    Change the representation of the PMU flags from decimal to hex since they
    are bitfields which are easier to read in hex.
    
    Signed-off-by: Anshuman Khandual <khandual@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index 9710be3a2d17..d3e97487c72c 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -45,11 +45,11 @@ struct power_pmu {
 /*
  * Values for power_pmu.flags
  */
-#define PPMU_LIMITED_PMC5_6	1	/* PMC5/6 have limited function */
-#define PPMU_ALT_SIPR		2	/* uses alternate posn for SIPR/HV */
-#define PPMU_NO_SIPR		4	/* no SIPR/HV in MMCRA at all */
-#define PPMU_NO_CONT_SAMPLING	8	/* no continuous sampling */
-#define PPMU_SIAR_VALID		16	/* Processor has SIAR Valid bit */
+#define PPMU_LIMITED_PMC5_6	0x00000001 /* PMC5/6 have limited function */
+#define PPMU_ALT_SIPR		0x00000002 /* uses alternate posn for SIPR/HV */
+#define PPMU_NO_SIPR		0x00000004 /* no SIPR/HV in MMCRA at all */
+#define PPMU_NO_CONT_SAMPLING	0x00000008 /* no continuous sampling */
+#define PPMU_SIAR_VALID		0x00000010 /* Processor has SIAR Valid bit */
 
 /*
  * Values for flags to get_alternatives()

commit e6878835ac4794f25385522d29c634b7bbb7cca9
Author: sukadev@linux.vnet.ibm.com <sukadev@linux.vnet.ibm.com>
Date:   Tue Sep 18 20:56:11 2012 +0000

    powerpc/perf: Sample only if SIAR-Valid bit is set in P7+
    
    powerpc/perf: Sample only if SIAR-Valid bit is set in P7+
    
    On POWER7+ two new bits (mmcra[35] and mmcra[36]) indicate whether the
    contents of SIAR and SDAR are valid.
    
    For marked instructions on P7+, we must save the contents of SIAR and
    SDAR registers only if these new bits are set.
    
    This code/check for the SIAR-Valid bit is specific to P7+, so rather than
    waste a CPU-feature bit use the PVR flag.
    
    Note that Carl Love proposed a similar change for oprofile:
    
            https://lkml.org/lkml/2012/6/22/309
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index 078019b5b353..9710be3a2d17 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -49,6 +49,7 @@ struct power_pmu {
 #define PPMU_ALT_SIPR		2	/* uses alternate posn for SIPR/HV */
 #define PPMU_NO_SIPR		4	/* no SIPR/HV in MMCRA at all */
 #define PPMU_NO_CONT_SAMPLING	8	/* no continuous sampling */
+#define PPMU_SIAR_VALID		16	/* Processor has SIAR Valid bit */
 
 /*
  * Values for flags to get_alternatives()

commit 1ce447b90f3e71c81ae59e0062bc305ef267668b
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon Mar 26 20:47:34 2012 +0000

    powerpc/perf: Fix instruction address sampling on 970 and Power4
    
    970 and Power4 don't support "continuous sampling" which means that
    when we aren't in marked instruction sampling mode (marked events),
    SIAR isn't updated with the last instruction sampled before the
    perf interrupt. On those processors, we must thus use the exception
    SRR0 value as the sampled instruction pointer.
    
    Those processors also don't support the SIPR and SIHV bits in MMCRA
    which means we need some kind of heuristic to decide if SIAR values
    represent kernel or user addresses.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index 1a8093fa8f71..078019b5b353 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -47,6 +47,8 @@ struct power_pmu {
  */
 #define PPMU_LIMITED_PMC5_6	1	/* PMC5/6 have limited function */
 #define PPMU_ALT_SIPR		2	/* uses alternate posn for SIPR/HV */
+#define PPMU_NO_SIPR		4	/* no SIPR/HV in MMCRA at all */
+#define PPMU_NO_CONT_SAMPLING	8	/* no continuous sampling */
 
 /*
  * Values for flags to get_alternatives()

commit 35edc2a5095efb189e60dc32bbb9d2663aec6d24
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Sun Nov 20 20:36:02 2011 +0100

    perf, arch: Rework perf_event_index()
    
    Put the logic to compute the event index into a per pmu method. This
    is required because the x86 rules are weird and wonderful and don't
    match the capabilities of the current scheme.
    
    AFAIK only powerpc actually has a usable userspace read of the PMCs
    but I'm not at all sure anybody actually used that.
    
    ARM is restored to the default since it currently does not support
    userspace access at all. And all software events are provided with a
    method that reports their index as 0 (disabled).
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Michael Cree <mcree@orcon.net.nz>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Deng-Cheng Zhu <dengcheng.zhu@gmail.com>
    Cc: Anton Blanchard <anton@samba.org>
    Cc: Eric B Munson <emunson@mgebm.net>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Richard Kuo <rkuo@codeaurora.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Arun Sharma <asharma@fb.com>
    Link: http://lkml.kernel.org/n/tip-dfydxodki16lylkt3gl2j7cw@git.kernel.org
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
index 8f1df1208d23..1a8093fa8f71 100644
--- a/arch/powerpc/include/asm/perf_event_server.h
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -61,8 +61,6 @@ struct pt_regs;
 extern unsigned long perf_misc_flags(struct pt_regs *regs);
 extern unsigned long perf_instruction_pointer(struct pt_regs *regs);
 
-#define PERF_EVENT_INDEX_OFFSET	1
-
 /*
  * Only override the default definitions in include/linux/perf_event.h
  * if we have hardware PMU support.

commit a11106544f33c104706ae42d27219a409b67478e
Author: Scott Wood <scottwood@freescale.com>
Date:   Thu Feb 25 18:09:45 2010 -0600

    powerpc/perf: e500 support
    
    This implements perf_event support for the Freescale embedded performance
    monitor, based on the existing perf_event.c that supports server/classic
    chips.
    
    Some limitations:
    - Performance monitor interrupts are regular EE interrupts, and thus you
      can't profile places with interrupts disabled.  We may want to implement
      soft IRQ-disabling, with perfmon interrupts exempted and treated as NMIs.
    - When trying to schedule multiple event groups at once, and using
      restricted events, situations could arise where scheduling fails even
      though it would be possible.  Consider three groups, each with two events.
      One group has restricted events, the others don't.  The two non-restricted
      groups are scheduled, then one is removed, which happens to occupy the two
      counters that can't do restricted events.  The remaining non-restricted
      group will not be moved to the non-restricted-capable counters to make
      room if the restricted group tries to be scheduled.
    
    Signed-off-by: Scott Wood <scottwood@freescale.com>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/perf_event_server.h b/arch/powerpc/include/asm/perf_event_server.h
new file mode 100644
index 000000000000..8f1df1208d23
--- /dev/null
+++ b/arch/powerpc/include/asm/perf_event_server.h
@@ -0,0 +1,110 @@
+/*
+ * Performance event support - PowerPC classic/server specific definitions.
+ *
+ * Copyright 2008-2009 Paul Mackerras, IBM Corporation.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+#include <linux/types.h>
+#include <asm/hw_irq.h>
+
+#define MAX_HWEVENTS		8
+#define MAX_EVENT_ALTERNATIVES	8
+#define MAX_LIMITED_HWCOUNTERS	2
+
+/*
+ * This struct provides the constants and functions needed to
+ * describe the PMU on a particular POWER-family CPU.
+ */
+struct power_pmu {
+	const char	*name;
+	int		n_counter;
+	int		max_alternatives;
+	unsigned long	add_fields;
+	unsigned long	test_adder;
+	int		(*compute_mmcr)(u64 events[], int n_ev,
+				unsigned int hwc[], unsigned long mmcr[]);
+	int		(*get_constraint)(u64 event_id, unsigned long *mskp,
+				unsigned long *valp);
+	int		(*get_alternatives)(u64 event_id, unsigned int flags,
+				u64 alt[]);
+	void		(*disable_pmc)(unsigned int pmc, unsigned long mmcr[]);
+	int		(*limited_pmc_event)(u64 event_id);
+	u32		flags;
+	int		n_generic;
+	int		*generic_events;
+	int		(*cache_events)[PERF_COUNT_HW_CACHE_MAX]
+			       [PERF_COUNT_HW_CACHE_OP_MAX]
+			       [PERF_COUNT_HW_CACHE_RESULT_MAX];
+};
+
+/*
+ * Values for power_pmu.flags
+ */
+#define PPMU_LIMITED_PMC5_6	1	/* PMC5/6 have limited function */
+#define PPMU_ALT_SIPR		2	/* uses alternate posn for SIPR/HV */
+
+/*
+ * Values for flags to get_alternatives()
+ */
+#define PPMU_LIMITED_PMC_OK	1	/* can put this on a limited PMC */
+#define PPMU_LIMITED_PMC_REQD	2	/* have to put this on a limited PMC */
+#define PPMU_ONLY_COUNT_RUN	4	/* only counting in run state */
+
+extern int register_power_pmu(struct power_pmu *);
+
+struct pt_regs;
+extern unsigned long perf_misc_flags(struct pt_regs *regs);
+extern unsigned long perf_instruction_pointer(struct pt_regs *regs);
+
+#define PERF_EVENT_INDEX_OFFSET	1
+
+/*
+ * Only override the default definitions in include/linux/perf_event.h
+ * if we have hardware PMU support.
+ */
+#ifdef CONFIG_PPC_PERF_CTRS
+#define perf_misc_flags(regs)	perf_misc_flags(regs)
+#endif
+
+/*
+ * The power_pmu.get_constraint function returns a 32/64-bit value and
+ * a 32/64-bit mask that express the constraints between this event_id and
+ * other events.
+ *
+ * The value and mask are divided up into (non-overlapping) bitfields
+ * of three different types:
+ *
+ * Select field: this expresses the constraint that some set of bits
+ * in MMCR* needs to be set to a specific value for this event_id.  For a
+ * select field, the mask contains 1s in every bit of the field, and
+ * the value contains a unique value for each possible setting of the
+ * MMCR* bits.  The constraint checking code will ensure that two events
+ * that set the same field in their masks have the same value in their
+ * value dwords.
+ *
+ * Add field: this expresses the constraint that there can be at most
+ * N events in a particular class.  A field of k bits can be used for
+ * N <= 2^(k-1) - 1.  The mask has the most significant bit of the field
+ * set (and the other bits 0), and the value has only the least significant
+ * bit of the field set.  In addition, the 'add_fields' and 'test_adder'
+ * in the struct power_pmu for this processor come into play.  The
+ * add_fields value contains 1 in the LSB of the field, and the
+ * test_adder contains 2^(k-1) - 1 - N in the field.
+ *
+ * NAND field: this expresses the constraint that you may not have events
+ * in all of a set of classes.  (For example, on PPC970, you can't select
+ * events from the FPU, ISU and IDU simultaneously, although any two are
+ * possible.)  For N classes, the field is N+1 bits wide, and each class
+ * is assigned one bit from the least-significant N bits.  The mask has
+ * only the most-significant bit set, and the value has only the bit
+ * for the event_id's class set.  The test_adder has the least significant
+ * bit set in the field.
+ *
+ * If an event_id is not subject to the constraint expressed by a particular
+ * field, then it will have 0 in both the mask and value for that field.
+ */
