commit b711531641038f3ff3723914f3d5ba79848d347e
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Mon Apr 20 18:36:36 2020 +0000

    powerpc: Replace _ALIGN_UP() by ALIGN()
    
    _ALIGN_UP() is specific to powerpc
    ALIGN() is generic and does the same
    
    Replace _ALIGN_UP() by ALIGN()
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Joel Stanley <joel@jms.id.au>
    Link: https://lore.kernel.org/r/8a6d7e45f7904c73a0af539642d3962e2a3c7268.1587407777.git.christophe.leroy@c-s.fr

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 350101e11ddb..5032f1593299 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -22,11 +22,11 @@
 #define IOMMU_PAGE_SHIFT_4K      12
 #define IOMMU_PAGE_SIZE_4K       (ASM_CONST(1) << IOMMU_PAGE_SHIFT_4K)
 #define IOMMU_PAGE_MASK_4K       (~((1 << IOMMU_PAGE_SHIFT_4K) - 1))
-#define IOMMU_PAGE_ALIGN_4K(addr) _ALIGN_UP(addr, IOMMU_PAGE_SIZE_4K)
+#define IOMMU_PAGE_ALIGN_4K(addr) ALIGN(addr, IOMMU_PAGE_SIZE_4K)
 
 #define IOMMU_PAGE_SIZE(tblptr) (ASM_CONST(1) << (tblptr)->it_page_shift)
 #define IOMMU_PAGE_MASK(tblptr) (~((1 << (tblptr)->it_page_shift) - 1))
-#define IOMMU_PAGE_ALIGN(addr, tblptr) _ALIGN_UP(addr, IOMMU_PAGE_SIZE(tblptr))
+#define IOMMU_PAGE_ALIGN(addr, tblptr) ALIGN(addr, IOMMU_PAGE_SIZE(tblptr))
 
 /* Boot time flags */
 extern int iommu_is_off;

commit 9044adca782c065de182d28876808446b3a8ccde
Merge: 07aa1e786d4f 68e0aa8ec5ce
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Fri Aug 30 09:52:57 2019 +1000

    Merge branch 'topic/ppc-kvm' into next
    
    Merge our ppc-kvm topic branch to bring in the Ultravisor support
    patches.

commit a102f139aac54689eeb05883952742ae780159f3
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Thu Aug 29 18:52:52 2019 +1000

    powerpc/powernv/ioda: Remove obsolete iommu_table_ops::exchange callbacks
    
    As now we have xchg_no_kill/tce_kill, these are not used anymore so
    remove them.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190829085252.72370-6-aik@ozlabs.ru

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index babddede9245..9ed0206cd98c 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -48,16 +48,6 @@ struct iommu_table_ops {
 	 * returns old TCE and DMA direction mask.
 	 * @tce is a physical address.
 	 */
-	int (*exchange)(struct iommu_table *tbl,
-			long index,
-			unsigned long *hpa,
-			enum dma_data_direction *direction);
-	/* Real mode */
-	int (*exchange_rm)(struct iommu_table *tbl,
-			long index,
-			unsigned long *hpa,
-			enum dma_data_direction *direction);
-
 	int (*xchg_no_kill)(struct iommu_table *tbl,
 			long index,
 			unsigned long *hpa,

commit 35872480da47ec714fd9c4f2f3d2d83daf304851
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Thu Aug 29 18:52:48 2019 +1000

    powerpc/powernv/ioda: Split out TCE invalidation from TCE updates
    
    At the moment updates in a TCE table are made by iommu_table_ops::exchange
    which update one TCE and invalidates an entry in the PHB/NPU TCE cache
    via set of registers called "TCE Kill" (hence the naming).
    Writing a TCE is a simple xchg() but invalidating the TCE cache is
    a relatively expensive OPAL call. Mapping a 100GB guest with PCI+NPU
    passed through devices takes about 20s.
    
    Thankfully we can do better. Since such big mappings happen at the boot
    time and when memory is plugged/onlined (i.e. not often), these requests
    come in 512 pages so we call call OPAL 512 times less which brings 20s
    from the above to less than 10s. Also, since TCE caches can be flushed
    entirely, calling OPAL for 512 TCEs helps skiboot [1] to decide whether
    to flush the entire cache or not.
    
    This implements 2 new iommu_table_ops callbacks:
    - xchg_no_kill() to update a single TCE with no TCE invalidation;
    - tce_kill() to invalidate multiple TCEs.
    This uses the same xchg_no_kill() callback for IODA1/2.
    
    This implements 2 new wrappers on top of the new callbacks similar to
    the existing iommu_tce_xchg().
    
    This does not use the new callbacks yet, the next patches will;
    so this should not cause any behavioral change.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190829085252.72370-2-aik@ozlabs.ru

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 18d342b815e4..babddede9245 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -58,6 +58,17 @@ struct iommu_table_ops {
 			unsigned long *hpa,
 			enum dma_data_direction *direction);
 
+	int (*xchg_no_kill)(struct iommu_table *tbl,
+			long index,
+			unsigned long *hpa,
+			enum dma_data_direction *direction,
+			bool realmode);
+
+	void (*tce_kill)(struct iommu_table *tbl,
+			unsigned long index,
+			unsigned long pages,
+			bool realmode);
+
 	__be64 *(*useraddrptr)(struct iommu_table *tbl, long index, bool alloc);
 #endif
 	void (*clear)(struct iommu_table *tbl,
@@ -206,6 +217,12 @@ extern void iommu_del_device(struct device *dev);
 extern long iommu_tce_xchg(struct mm_struct *mm, struct iommu_table *tbl,
 		unsigned long entry, unsigned long *hpa,
 		enum dma_data_direction *direction);
+extern long iommu_tce_xchg_no_kill(struct mm_struct *mm,
+		struct iommu_table *tbl,
+		unsigned long entry, unsigned long *hpa,
+		enum dma_data_direction *direction);
+extern void iommu_tce_kill(struct iommu_table *tbl,
+		unsigned long entry, unsigned long pages);
 #else
 static inline void iommu_register_group(struct iommu_table_group *table_group,
 					int pci_domain_number,

commit 201ed7f327a17577debec52c33786d4b3259d0dc
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Thu Jul 18 15:11:39 2019 +1000

    powerpc/powernv/ioda2: Create bigger default window with 64k IOMMU pages
    
    At the moment we create a small window only for 32bit devices, the window
    maps 0..2GB of the PCI space only. For other devices we either use
    a sketchy bypass or hardware bypass but the former can only work if
    the amount of RAM is no bigger than the device's DMA mask and the latter
    requires devices to support at least 59bit DMA.
    
    This extends the default DMA window to the maximum size possible to allow
    a wider DMA mask than just 32bit. The default window size is now limited
    by the the iommu_table::it_map allocation bitmap which is a contiguous
    array, 1 bit per an IOMMU page.
    
    This increases the default IOMMU page size from hard coded 4K to
    the system page size to allow wider DMA masks.
    
    This increases the level number to not exceed the max order allocation
    limit per TCE level. By the same time, this keeps minimal levels number
    as 2 in order to save memory.
    
    As the extended window now overlaps the 32bit MMIO region, this adds
    an area reservation to iommu_init_table().
    
    After this change the default window size is 0x80000000000==1<<43 so
    devices limited to DMA mask smaller than the amount of system RAM can
    still use more than just 2GB of memory for DMA.
    
    This is an optimization and not a bug fix for DMA API usage.
    
    With the on-demand allocation of indirect TCE table levels enabled and
    2 levels, the first TCE level size is just
    1<<ceil((log2(0x7ffffffffff+1)-16)/2)=16384 TCEs or 2 system pages.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190718051139.74787-5-aik@ozlabs.ru

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 18d342b815e4..d7bf1f104c15 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -111,6 +111,8 @@ struct iommu_table {
 	struct iommu_table_ops *it_ops;
 	struct kref    it_kref;
 	int it_nid;
+	unsigned long it_reserved_start; /* Start of not-DMA-able (MMIO) area */
+	unsigned long it_reserved_end;
 };
 
 #define IOMMU_TABLE_USERSPACE_ENTRY_RO(tbl, entry) \
@@ -149,8 +151,9 @@ extern int iommu_tce_table_put(struct iommu_table *tbl);
 /* Initializes an iommu_table based in values set in the passed-in
  * structure
  */
-extern struct iommu_table *iommu_init_table(struct iommu_table * tbl,
-					    int nid);
+extern struct iommu_table *iommu_init_table(struct iommu_table *tbl,
+		int nid, unsigned long res_start, unsigned long res_end);
+
 #define IOMMU_TABLE_GROUP_MAX_TABLES	2
 
 struct iommu_table_group;

commit 192f0f8e9db7efe4ac98d47f5fa4334e43c1204d
Merge: ec9249752465 f5a9e488d623
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jul 13 16:08:36 2019 -0700

    Merge tag 'powerpc-5.3-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Notable changes:
    
       - Removal of the NPU DMA code, used by the out-of-tree Nvidia driver,
         as well as some other functions only used by drivers that haven't
         (yet?) made it upstream.
    
       - A fix for a bug in our handling of hardware watchpoints (eg. perf
         record -e mem: ...) which could lead to register corruption and
         kernel crashes.
    
       - Enable HAVE_ARCH_HUGE_VMAP, which allows us to use large pages for
         vmalloc when using the Radix MMU.
    
       - A large but incremental rewrite of our exception handling code to
         use gas macros rather than multiple levels of nested CPP macros.
    
      And the usual small fixes, cleanups and improvements.
    
      Thanks to: Alastair D'Silva, Alexey Kardashevskiy, Andreas Schwab,
      Aneesh Kumar K.V, Anju T Sudhakar, Anton Blanchard, Arnd Bergmann,
      Athira Rajeev, Cédric Le Goater, Christian Lamparter, Christophe
      Leroy, Christophe Lombard, Christoph Hellwig, Daniel Axtens, Denis
      Efremov, Enrico Weigelt, Frederic Barrat, Gautham R. Shenoy, Geert
      Uytterhoeven, Geliang Tang, Gen Zhang, Greg Kroah-Hartman, Greg Kurz,
      Gustavo Romero, Krzysztof Kozlowski, Madhavan Srinivasan, Masahiro
      Yamada, Mathieu Malaterre, Michael Neuling, Nathan Lynch, Naveen N.
      Rao, Nicholas Piggin, Nishad Kamdar, Oliver O'Halloran, Qian Cai, Ravi
      Bangoria, Sachin Sant, Sam Bobroff, Satheesh Rajendran, Segher
      Boessenkool, Shaokun Zhang, Shawn Anastasio, Stewart Smith, Suraj
      Jitindar Singh, Thiago Jung Bauermann, YueHaibing"
    
    * tag 'powerpc-5.3-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (163 commits)
      powerpc/powernv/idle: Fix restore of SPRN_LDBAR for POWER9 stop state.
      powerpc/eeh: Handle hugepages in ioremap space
      ocxl: Update for AFU descriptor template version 1.1
      powerpc/boot: pass CONFIG options in a simpler and more robust way
      powerpc/boot: add {get, put}_unaligned_be32 to xz_config.h
      powerpc/irq: Don't WARN continuously in arch_local_irq_restore()
      powerpc/module64: Use symbolic instructions names.
      powerpc/module32: Use symbolic instructions names.
      powerpc: Move PPC_HA() PPC_HI() and PPC_LO() to ppc-opcode.h
      powerpc/module64: Fix comment in R_PPC64_ENTRY handling
      powerpc/boot: Add lzo support for uImage
      powerpc/boot: Add lzma support for uImage
      powerpc/boot: don't force gzipped uImage
      powerpc/8xx: Add microcode patch to move SMC parameter RAM.
      powerpc/8xx: Use IO accessors in microcode programming.
      powerpc/8xx: replace #ifdefs by IS_ENABLED() in microcode.c
      powerpc/8xx: refactor programming of microcode CPM params.
      powerpc/8xx: refactor printing of microcode patch name.
      powerpc/8xx: Refactor microcode write
      powerpc/8xx: refactor writing of CPM microcode arrays
      ...

commit 24911acd64cee411c9e626d3d0ca0733805b009b
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jun 29 10:03:59 2019 +0200

    powerpc: remove device_to_mask()
    
    Use the dma_get_mask() helper from dma-mapping.h instead, as they are
    functionally identical.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 0ac52392ed99..f98f2864b66a 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -327,13 +327,5 @@ extern bool iommu_fixed_is_weak;
 
 extern const struct dma_map_ops dma_iommu_ops;
 
-static inline unsigned long device_to_mask(struct device *dev)
-{
-	if (dev->dma_mask && *dev->dma_mask)
-		return *dev->dma_mask;
-	/* Assume devices without mask can take 32 bit addresses */
-	return 0xfffffffful;
-}
-
 #endif /* __KERNEL__ */
 #endif /* _ASM_IOMMU_H */

commit 1a59d1b8e05ea6ab45f7e18897de1ef0e6bc3da6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:05 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 156
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version this program is distributed in the
      hope that it will be useful but without any warranty without even
      the implied warranty of merchantability or fitness for a particular
      purpose see the gnu general public license for more details you
      should have received a copy of the gnu general public license along
      with this program if not write to the free software foundation inc
      59 temple place suite 330 boston ma 02111 1307 usa
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 1334 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Richard Fontana <rfontana@redhat.com>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070033.113240726@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 0ac52392ed99..2c1845e5e851 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -1,21 +1,8 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
 /*
  * Copyright (C) 2001 Mike Corrigan & Dave Engebretsen, IBM Corporation
  * Rewrite, cleanup:
  * Copyright (C) 2004 Olof Johansson <olof@lixom.net>, IBM Corporation
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
 
 #ifndef _ASM_IOMMU_H

commit 4a605e2d1a69f5aea06da10d81e22802a90812a3
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Feb 13 08:01:33 2019 +0100

    powerpc/dma: trim the fat from <asm/dma-mapping.h>
    
    There is no need to provide anything but get_arch_dma_ops to
    <linux/dma-mapping.h>.  More the remaining declarations to <asm/iommu.h>
    and drop all the includes.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Tested-by: Christian Zigotzky <chzigotzky@xenosoft.de>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 6f00a892ebdf..0ac52392ed99 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -325,5 +325,15 @@ extern bool iommu_fixed_is_weak;
 #define iommu_fixed_is_weak false
 #endif
 
+extern const struct dma_map_ops dma_iommu_ops;
+
+static inline unsigned long device_to_mask(struct device *dev)
+{
+	if (dev->dma_mask && *dev->dma_mask)
+		return *dev->dma_mask;
+	/* Assume devices without mask can take 32 bit addresses */
+	return 0xfffffffful;
+}
+
 #endif /* __KERNEL__ */
 #endif /* _ASM_IOMMU_H */

commit ba767b5283c06e1a2fcdd1835c33e42b8fccd09c
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Feb 13 08:01:09 2019 +0100

    powerpc/cell: use the generic iommu bypass code
    
    This gets rid of a lot of clumsy code and finally allows us to mark
    dma_iommu_ops const.
    
    Includes fixes from Michael Ellerman.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index bd069a6542ab..6f00a892ebdf 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -319,5 +319,11 @@ extern void iommu_release_ownership(struct iommu_table *tbl);
 extern enum dma_data_direction iommu_tce_direction(unsigned long tce);
 extern unsigned long iommu_direction_to_tce_perm(enum dma_data_direction dir);
 
+#ifdef CONFIG_PPC_CELL_NATIVE
+extern bool iommu_fixed_is_weak;
+#else
+#define iommu_fixed_is_weak false
+#endif
+
 #endif /* __KERNEL__ */
 #endif /* _ASM_IOMMU_H */

commit a20f507f577b04f286c88a4885ac528e69f6f308
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Feb 13 08:01:04 2019 +0100

    powerpc/dma: untangle vio_dma_mapping_ops from dma_iommu_ops
    
    vio_dma_mapping_ops currently does a lot of indirect calls through
    dma_iommu_ops, which not only make the code harder to follow but are
    also expensive in the post-spectre world.  Unwind the indirect calls
    by calling the ppc_iommu_* or iommu_* APIs directly applicable, or
    just use the dma_iommu_* methods directly where we can.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 17524d222a7b..bd069a6542ab 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -237,6 +237,7 @@ static inline void iommu_del_device(struct device *dev)
 }
 #endif /* !CONFIG_IOMMU_API */
 
+u64 dma_iommu_get_required_mask(struct device *dev);
 #else
 
 static inline void *get_iommu_table_base(struct device *dev)

commit af7ddd8a627c62a835524b3f5b471edbbbcce025
Merge: fe2b0cdabcd9 8b1cce9f5832
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Dec 28 14:12:21 2018 -0800

    Merge tag 'dma-mapping-4.21' of git://git.infradead.org/users/hch/dma-mapping
    
    Pull DMA mapping updates from Christoph Hellwig:
     "A huge update this time, but a lot of that is just consolidating or
      removing code:
    
       - provide a common DMA_MAPPING_ERROR definition and avoid indirect
         calls for dma_map_* error checking
    
       - use direct calls for the DMA direct mapping case, avoiding huge
         retpoline overhead for high performance workloads
    
       - merge the swiotlb dma_map_ops into dma-direct
    
       - provide a generic remapping DMA consistent allocator for
         architectures that have devices that perform DMA that is not cache
         coherent. Based on the existing arm64 implementation and also used
         for csky now.
    
       - improve the dma-debug infrastructure, including dynamic allocation
         of entries (Robin Murphy)
    
       - default to providing chaining scatterlist everywhere, with opt-outs
         for the few architectures (alpha, parisc, most arm32 variants) that
         can't cope with it
    
       - misc sparc32 dma-related cleanups
    
       - remove the dma_mark_clean arch hook used by swiotlb on ia64 and
         replace it with the generic noncoherent infrastructure
    
       - fix the return type of dma_set_max_seg_size (Niklas Söderlund)
    
       - move the dummy dma ops for not DMA capable devices from arm64 to
         common code (Robin Murphy)
    
       - ensure dma_alloc_coherent returns zeroed memory to avoid kernel
         data leaks through userspace. We already did this for most common
         architectures, but this ensures we do it everywhere.
         dma_zalloc_coherent has been deprecated and can hopefully be
         removed after -rc1 with a coccinelle script"
    
    * tag 'dma-mapping-4.21' of git://git.infradead.org/users/hch/dma-mapping: (73 commits)
      dma-mapping: fix inverted logic in dma_supported
      dma-mapping: deprecate dma_zalloc_coherent
      dma-mapping: zero memory returned from dma_alloc_*
      sparc/iommu: fix ->map_sg return value
      sparc/io-unit: fix ->map_sg return value
      arm64: default to the direct mapping in get_arch_dma_ops
      PCI: Remove unused attr variable in pci_dma_configure
      ia64: only select ARCH_HAS_DMA_COHERENT_TO_PFN if swiotlb is enabled
      dma-mapping: bypass indirect calls for dma-direct
      vmd: use the proper dma_* APIs instead of direct methods calls
      dma-direct: merge swiotlb_dma_ops into the dma_direct code
      dma-direct: use dma_direct_map_page to implement dma_direct_map_sg
      dma-direct: improve addressability error reporting
      swiotlb: remove dma_mark_clean
      swiotlb: remove SWIOTLB_MAP_ERROR
      ACPI / scan: Refactor _CCA enforcement
      dma-mapping: factor out dummy DMA ops
      dma-mapping: always build the direct mapping code
      dma-mapping: move dma_cache_sync out of line
      dma-mapping: move various slow path functions out of line
      ...

commit c4e9d3c1e65aac3f65995e9cb1cede7330c594dc
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Wed Dec 19 19:52:21 2018 +1100

    powerpc/powernv/pseries: Rework device adding to IOMMU groups
    
    The powernv platform registers IOMMU groups and adds devices to them
    from the pci_controller_ops::setup_bridge() hook except one case when
    virtual functions (SRIOV VFs) are added from a bus notifier.
    
    The pseries platform registers IOMMU groups from
    the pci_controller_ops::dma_bus_setup() hook and adds devices from
    the pci_controller_ops::dma_dev_setup() hook. The very same bus notifier
    used for powernv does not add devices for pseries though as
    __of_scan_bus() adds devices first, then it does the bus/dev DMA setup.
    
    Both platforms use iommu_add_device() which takes a device and expects
    it to have a valid IOMMU table struct with an iommu_table_group pointer
    which in turn points the iommu_group struct (which represents
    an IOMMU group). Although the helper seems easy to use, it relies on
    some pre-existing device configuration and associated data structures
    which it does not really need.
    
    This simplifies iommu_add_device() to take the table_group pointer
    directly. Pseries already has a table_group pointer handy and the bus
    notified is not used anyway. For powernv, this copies the existing bus
    notifier, makes it work for powernv only which means an easy way of
    getting to the table_group pointer. This was tested on VFs but should
    also support physical PCI hotplug.
    
    Since iommu_add_device() receives the table_group pointer directly,
    pseries does not do TCE cache invalidation (the hypervisor does) nor
    allow multiple groups per a VFIO container (in other words sharing
    an IOMMU table between partitionable endpoints), this removes
    iommu_table_group_link from pseries.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index a8aeac0db01c..e847ff69cb2b 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -215,9 +215,9 @@ struct iommu_table_group {
 
 extern void iommu_register_group(struct iommu_table_group *table_group,
 				 int pci_domain_number, unsigned long pe_num);
-extern int iommu_add_device(struct device *dev);
+extern int iommu_add_device(struct iommu_table_group *table_group,
+		struct device *dev);
 extern void iommu_del_device(struct device *dev);
-extern int __init tce_iommu_bus_notifier_init(void);
 extern long iommu_tce_xchg(struct mm_struct *mm, struct iommu_table *tbl,
 		unsigned long entry, unsigned long *hpa,
 		enum dma_data_direction *direction);
@@ -228,7 +228,8 @@ static inline void iommu_register_group(struct iommu_table_group *table_group,
 {
 }
 
-static inline int iommu_add_device(struct device *dev)
+static inline int iommu_add_device(struct iommu_table_group *table_group,
+		struct device *dev)
 {
 	return 0;
 }
@@ -236,11 +237,6 @@ static inline int iommu_add_device(struct device *dev)
 static inline void iommu_del_device(struct device *dev)
 {
 }
-
-static inline int __init tce_iommu_bus_notifier_init(void)
-{
-        return 0;
-}
 #endif /* !CONFIG_IOMMU_API */
 
 int dma_iommu_mapping_error(struct device *dev, dma_addr_t dma_addr);

commit c10c21efa4bccab486c2e6a047c13dfa6cf7426c
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Wed Dec 19 19:52:15 2018 +1100

    powerpc/vfio/iommu/kvm: Do not pin device memory
    
    This new memory does not have page structs as it is not plugged to
    the host so gup() will fail anyway.
    
    This adds 2 helpers:
    - mm_iommu_newdev() to preregister the "memory device" memory so
    the rest of API can still be used;
    - mm_iommu_is_devmem() to know if the physical address is one of thise
    new regions which we must avoid unpinning of.
    
    This adds @mm to tce_page_is_contained() and iommu_tce_xchg() to test
    if the memory is device memory to avoid pfn_to_page().
    
    This adds a check for device memory in mm_iommu_ua_mark_dirty_rm() which
    does delayed pages dirtying.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Reviewed-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 35db0cbc9222..a8aeac0db01c 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -218,8 +218,9 @@ extern void iommu_register_group(struct iommu_table_group *table_group,
 extern int iommu_add_device(struct device *dev);
 extern void iommu_del_device(struct device *dev);
 extern int __init tce_iommu_bus_notifier_init(void);
-extern long iommu_tce_xchg(struct iommu_table *tbl, unsigned long entry,
-		unsigned long *hpa, enum dma_data_direction *direction);
+extern long iommu_tce_xchg(struct mm_struct *mm, struct iommu_table *tbl,
+		unsigned long entry, unsigned long *hpa,
+		enum dma_data_direction *direction);
 #else
 static inline void iommu_register_group(struct iommu_table_group *table_group,
 					int pci_domain_number,

commit d11e3d3d03360cd49497c837490576f793baf746
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed Nov 21 18:56:25 2018 +0100

    powerpc/iommu: remove the mapping_error dma_map_ops method
    
    The powerpc iommu code already returns (~(dma_addr_t)0x0) on mapping
    failures, so we can switch over to returning DMA_MAPPING_ERROR and let
    the core dma-mapping code handle the rest.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 35db0cbc9222..55312990d1d2 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -143,8 +143,6 @@ struct scatterlist;
 
 #ifdef CONFIG_PPC64
 
-#define IOMMU_MAPPING_ERROR		(~(dma_addr_t)0x0)
-
 static inline void set_iommu_table_base(struct device *dev,
 					struct iommu_table *base)
 {
@@ -242,8 +240,6 @@ static inline int __init tce_iommu_bus_notifier_init(void)
 }
 #endif /* !CONFIG_IOMMU_API */
 
-int dma_iommu_mapping_error(struct device *dev, dma_addr_t dma_addr);
-
 #else
 
 static inline void *get_iommu_table_base(struct device *dev)

commit 6e301a8e56e429d6b01d83d427a9e54fdbb0fa60
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Mon Oct 15 21:08:41 2018 +1100

    KVM: PPC: Optimize clearing TCEs for sparse tables
    
    The powernv platform maintains 2 TCE tables for VFIO - a hardware TCE
    table and a table with userspace addresses. These tables are radix trees,
    we allocate indirect levels when they are written to. Since
    the memory allocation is problematic in real mode, we have 2 accessors
    to the entries:
    - for virtual mode: it allocates the memory and it is always expected
    to return non-NULL;
    - fr real mode: it does not allocate and can return NULL.
    
    Also, DMA windows can span to up to 55 bits of the address space and since
    we never have this much RAM, such windows are sparse. However currently
    the SPAPR TCE IOMMU driver walks through all TCEs to unpin DMA memory.
    
    Since we maintain a userspace addresses table for VFIO which is a mirror
    of the hardware table, we can use it to know which parts of the DMA
    window have not been mapped and skip these so does this patch.
    
    The bare metal systems do not have this problem as they use a bypass mode
    of a PHB which maps RAM directly.
    
    This helps a lot with sparse DMA windows, reducing the shutdown time from
    about 3 minutes per 1 billion TCEs to a few seconds for 32GB sparse guest.
    Just skipping the last level seems to be good enough.
    
    As non-allocating accessor is used now in virtual mode as well, rename it
    from IOMMU_TABLE_USERSPACE_ENTRY_RM (real mode) to _RO (read only).
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 3d4b88cb8599..35db0cbc9222 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -126,7 +126,7 @@ struct iommu_table {
 	int it_nid;
 };
 
-#define IOMMU_TABLE_USERSPACE_ENTRY_RM(tbl, entry) \
+#define IOMMU_TABLE_USERSPACE_ENTRY_RO(tbl, entry) \
 		((tbl)->it_ops->useraddrptr((tbl), (entry), false))
 #define IOMMU_TABLE_USERSPACE_ENTRY(tbl, entry) \
 		((tbl)->it_ops->useraddrptr((tbl), (entry), true))

commit 425333bf3a7743715c17e503049d0837d6c4a603
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Mon Sep 10 18:29:07 2018 +1000

    KVM: PPC: Avoid marking DMA-mapped pages dirty in real mode
    
    At the moment the real mode handler of H_PUT_TCE calls iommu_tce_xchg_rm()
    which in turn reads the old TCE and if it was a valid entry, marks
    the physical page dirty if it was mapped for writing. Since it is in
    real mode, realmode_pfn_to_page() is used instead of pfn_to_page()
    to get the page struct. However SetPageDirty() itself reads the compound
    page head and returns a virtual address for the head page struct and
    setting dirty bit for that kills the system.
    
    This adds additional dirty bit tracking into the MM/IOMMU API for use
    in the real mode. Note that this does not change how VFIO and
    KVM (in virtual mode) set this bit. The KVM (real mode) changes include:
    - use the lowest bit of the cached host phys address to carry
    the dirty bit;
    - mark pages dirty when they are unpinned which happens when
    the preregistered memory is released which always happens in virtual
    mode;
    - add mm_iommu_ua_mark_dirty_rm() helper to set delayed dirty bit;
    - change iommu_tce_xchg_rm() to take the kvm struct for the mm to use
    in the new mm_iommu_ua_mark_dirty_rm() helper;
    - move iommu_tce_xchg_rm() to book3s_64_vio_hv.c (which is the only
    caller anyway) to reduce the real mode KVM and IOMMU knowledge
    across different subsystems.
    
    This removes realmode_pfn_to_page() as it is not used anymore.
    
    While we at it, remove some EXPORT_SYMBOL_GPL() as that code is for
    the real mode only and modules cannot call it anyway.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index ab3a4fba38e3..3d4b88cb8599 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -220,8 +220,6 @@ extern void iommu_del_device(struct device *dev);
 extern int __init tce_iommu_bus_notifier_init(void);
 extern long iommu_tce_xchg(struct iommu_table *tbl, unsigned long entry,
 		unsigned long *hpa, enum dma_data_direction *direction);
-extern long iommu_tce_xchg_rm(struct iommu_table *tbl, unsigned long entry,
-		unsigned long *hpa, enum dma_data_direction *direction);
 #else
 static inline void iommu_register_group(struct iommu_table_group *table_group,
 					int pci_domain_number,

commit ec0c464cdbf38bf6ddabec8bfa595bd421cab203
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Jul 5 16:24:57 2018 +0000

    powerpc: move ASM_CONST and stringify_in_c() into asm-const.h
    
    This patch moves ASM_CONST() and stringify_in_c() into
    dedicated asm-const.h, then cleans all related inclusions.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    [mpe: asm-compat.h should include asm-const.h]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index daa3ee5d7ad2..ab3a4fba38e3 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -30,6 +30,7 @@
 #include <asm/machdep.h>
 #include <asm/types.h>
 #include <asm/pci-bridge.h>
+#include <asm/asm-const.h>
 
 #define IOMMU_PAGE_SHIFT_4K      12
 #define IOMMU_PAGE_SIZE_4K       (ASM_CONST(1) << IOMMU_PAGE_SHIFT_4K)

commit a68bd1267b7286b1687905651b404e765046de25
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Wed Jul 4 16:13:49 2018 +1000

    powerpc/powernv/ioda: Allocate indirect TCE levels on demand
    
    At the moment we allocate the entire TCE table, twice (hardware part and
    userspace translation cache). This normally works as we normally have
    contigous memory and the guest will map entire RAM for 64bit DMA.
    
    However if we have sparse RAM (one example is a memory device), then
    we will allocate TCEs which will never be used as the guest only maps
    actual memory for DMA. If it is a single level TCE table, there is nothing
    we can really do but if it a multilevel table, we can skip allocating
    TCEs we know we won't need.
    
    This adds ability to allocate only first level, saving memory.
    
    This changes iommu_table::free() to avoid allocating of an extra level;
    iommu_table::set() will do this when needed.
    
    This adds @alloc parameter to iommu_table::exchange() to tell the callback
    if it can allocate an extra level; the flag is set to "false" for
    the realmode KVM handlers of H_PUT_TCE hcalls and the callback returns
    H_TOO_HARD.
    
    This still requires the entire table to be counted in mm::locked_vm.
    
    To be conservative, this only does on-demand allocation when
    the usespace cache table is requested which is the case of VFIO.
    
    The example math for a system replicating a powernv setup with NVLink2
    in a guest:
    16GB RAM mapped at 0x0
    128GB GPU RAM window (16GB of actual RAM) mapped at 0x244000000000
    
    the table to cover that all with 64K pages takes:
    (((0x244000000000 + 0x2000000000) >> 16)*8)>>20 = 4556MB
    
    If we allocate only necessary TCE levels, we will only need:
    (((0x400000000 + 0x400000000) >> 16)*8)>>20 = 4MB (plus some for indirect
    levels).
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 4bdcf22509e6..daa3ee5d7ad2 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -70,7 +70,7 @@ struct iommu_table_ops {
 			unsigned long *hpa,
 			enum dma_data_direction *direction);
 
-	__be64 *(*useraddrptr)(struct iommu_table *tbl, long index);
+	__be64 *(*useraddrptr)(struct iommu_table *tbl, long index, bool alloc);
 #endif
 	void (*clear)(struct iommu_table *tbl,
 			long index, long npages);
@@ -122,10 +122,13 @@ struct iommu_table {
 	__be64 *it_userspace; /* userspace view of the table */
 	struct iommu_table_ops *it_ops;
 	struct kref    it_kref;
+	int it_nid;
 };
 
+#define IOMMU_TABLE_USERSPACE_ENTRY_RM(tbl, entry) \
+		((tbl)->it_ops->useraddrptr((tbl), (entry), false))
 #define IOMMU_TABLE_USERSPACE_ENTRY(tbl, entry) \
-		((tbl)->it_ops->useraddrptr((tbl), (entry)))
+		((tbl)->it_ops->useraddrptr((tbl), (entry), true))
 
 /* Pure 2^n version of get_order */
 static inline __attribute_const__

commit 090bad39b237aad92d8e01baa033699cf0c81cbe
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Wed Jul 4 16:13:47 2018 +1000

    powerpc/powernv: Add indirect levels to it_userspace
    
    We want to support sparse memory and therefore huge chunks of DMA windows
    do not need to be mapped. If a DMA window big enough to require 2 or more
    indirect levels, and a DMA window is used to map all RAM (which is
    a default case for 64bit window), we can actually save some memory by
    not allocation TCE for regions which we are not going to map anyway.
    
    The hardware tables alreary support indirect levels but we also keep
    host-physical-to-userspace translation array which is allocated by
    vmalloc() and is a flat array which might use quite some memory.
    
    This converts it_userspace from vmalloc'ed array to a multi level table.
    
    As the format becomes platform dependend, this replaces the direct access
    to it_usespace with a iommu_table_ops::useraddrptr hook which returns
    a pointer to the userspace copy of a TCE; future extension will return
    NULL if the level was not allocated.
    
    This should not change non-KVM handling of TCE tables and it_userspace
    will not be allocated for non-KVM tables.
    
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 803ac70ecedf..4bdcf22509e6 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -69,6 +69,8 @@ struct iommu_table_ops {
 			long index,
 			unsigned long *hpa,
 			enum dma_data_direction *direction);
+
+	__be64 *(*useraddrptr)(struct iommu_table *tbl, long index);
 #endif
 	void (*clear)(struct iommu_table *tbl,
 			long index, long npages);
@@ -123,9 +125,7 @@ struct iommu_table {
 };
 
 #define IOMMU_TABLE_USERSPACE_ENTRY(tbl, entry) \
-		((tbl)->it_userspace ? \
-			&((tbl)->it_userspace[(entry) - (tbl)->it_offset]) : \
-			NULL)
+		((tbl)->it_ops->useraddrptr((tbl), (entry)))
 
 /* Pure 2^n version of get_order */
 static inline __attribute_const__

commit 00a5c58d9499bd0c290b57205f43a70f2e69d3f6
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Wed Jul 4 16:13:46 2018 +1000

    KVM: PPC: Make iommu_table::it_userspace big endian
    
    We are going to reuse multilevel TCE code for the userspace copy of
    the TCE table and since it is big endian, let's make the copy big endian
    too.
    
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Acked-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 20febe0b7f32..803ac70ecedf 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -117,7 +117,7 @@ struct iommu_table {
 	unsigned long *it_map;       /* A simple allocation bitmap for now */
 	unsigned long  it_page_shift;/* table iommu page size */
 	struct list_head it_group_list;/* List of iommu_table_group_link */
-	unsigned long *it_userspace; /* userspace view of the table */
+	__be64 *it_userspace; /* userspace view of the table */
 	struct iommu_table_ops *it_ops;
 	struct kref    it_kref;
 };

commit 6009faa43f804c99b3d8fff94fa1e0692be70358
Author: Christoph Hellwig <hch@lst.de>
Date:   Sun May 21 14:17:10 2017 +0200

    powerpc: implement ->mapping_error
    
    DMA_ERROR_CODE is going to go away, so don't rely on it.  Instead
    define a ->mapping_error method for all IOMMU based dma operation
    instances.  The direct ops don't ever return an error and don't
    need a ->mapping_error method.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Acked-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 8a8ce220d7d0..20febe0b7f32 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -139,6 +139,8 @@ struct scatterlist;
 
 #ifdef CONFIG_PPC64
 
+#define IOMMU_MAPPING_ERROR		(~(dma_addr_t)0x0)
+
 static inline void set_iommu_table_base(struct device *dev,
 					struct iommu_table *base)
 {
@@ -238,6 +240,8 @@ static inline int __init tce_iommu_bus_notifier_init(void)
 }
 #endif /* !CONFIG_IOMMU_API */
 
+int dma_iommu_mapping_error(struct device *dev, dma_addr_t dma_addr);
+
 #else
 
 static inline void *get_iommu_table_base(struct device *dev)

commit b1af23d836f811137d504d14d4cbdd01929dec34
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Wed Mar 22 15:21:55 2017 +1100

    KVM: PPC: iommu: Unify TCE checking
    
    This reworks helpers for checking TCE update parameters in way they
    can be used in KVM.
    
    This should cause no behavioral change.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Acked-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index d96142572e6d..8a8ce220d7d0 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -296,11 +296,21 @@ static inline void iommu_restore(void)
 #endif
 
 /* The API to support IOMMU operations for VFIO */
-extern int iommu_tce_clear_param_check(struct iommu_table *tbl,
-		unsigned long ioba, unsigned long tce_value,
-		unsigned long npages);
-extern int iommu_tce_put_param_check(struct iommu_table *tbl,
-		unsigned long ioba, unsigned long tce);
+extern int iommu_tce_check_ioba(unsigned long page_shift,
+		unsigned long offset, unsigned long size,
+		unsigned long ioba, unsigned long npages);
+extern int iommu_tce_check_gpa(unsigned long page_shift,
+		unsigned long gpa);
+
+#define iommu_tce_clear_param_check(tbl, ioba, tce_value, npages) \
+		(iommu_tce_check_ioba((tbl)->it_page_shift,       \
+				(tbl)->it_offset, (tbl)->it_size, \
+				(ioba), (npages)) || (tce_value))
+#define iommu_tce_put_param_check(tbl, ioba, gpa)                 \
+		(iommu_tce_check_ioba((tbl)->it_page_shift,       \
+				(tbl)->it_offset, (tbl)->it_size, \
+				(ioba), 1) ||                     \
+		iommu_tce_check_gpa((tbl)->it_page_shift, (gpa)))
 
 extern void iommu_flush_tce(struct iommu_table *tbl);
 extern int iommu_take_ownership(struct iommu_table *tbl);

commit e5afdf9dd515a9446c009f44f99f9bc2f91b89a7
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Wed Mar 22 15:21:50 2017 +1100

    powerpc/vfio_spapr_tce: Add reference counting to iommu_table
    
    So far iommu_table obejcts were only used in virtual mode and had
    a single owner. We are going to change this by implementing in-kernel
    acceleration of DMA mapping requests. The proposed acceleration
    will handle requests in real mode and KVM will keep references to tables.
    
    This adds a kref to iommu_table and defines new helpers to update it.
    This replaces iommu_free_table() with iommu_tce_table_put() and makes
    iommu_free_table() static. iommu_tce_table_get() is not used in this patch
    but it will be in the following patch.
    
    Since this touches prototypes, this also removes @node_name parameter as
    it has never been really useful on powernv and carrying it for
    the pseries platform code to iommu_free_table() seems to be quite
    useless as well.
    
    This should cause no behavioral change.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 4554699aec02..d96142572e6d 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -119,6 +119,7 @@ struct iommu_table {
 	struct list_head it_group_list;/* List of iommu_table_group_link */
 	unsigned long *it_userspace; /* userspace view of the table */
 	struct iommu_table_ops *it_ops;
+	struct kref    it_kref;
 };
 
 #define IOMMU_TABLE_USERSPACE_ENTRY(tbl, entry) \
@@ -151,8 +152,8 @@ static inline void *get_iommu_table_base(struct device *dev)
 
 extern int dma_iommu_dma_supported(struct device *dev, u64 mask);
 
-/* Frees table for an individual device node */
-extern void iommu_free_table(struct iommu_table *tbl, const char *node_name);
+extern struct iommu_table *iommu_tce_table_get(struct iommu_table *tbl);
+extern int iommu_tce_table_put(struct iommu_table *tbl);
 
 /* Initializes an iommu_table based in values set in the passed-in
  * structure

commit a540aa56ba3d29084f28710c8b93cc9c3c422943
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Wed Mar 22 15:21:48 2017 +1100

    powerpc/powernv/iommu: Add real mode version of iommu_table_ops::exchange()
    
    In real mode, TCE tables are invalidated using special
    cache-inhibited store instructions which are not available in
    virtual mode
    
    This defines and implements exchange_rm() callback. This does not
    define set_rm/clear_rm/flush_rm callbacks as there is no user for those -
    exchange/exchange_rm are only to be used by KVM for VFIO.
    
    The exchange_rm callback is defined for IODA1/IODA2 powernv platforms.
    
    This replaces list_for_each_entry_rcu with its lockless version as
    from now on pnv_pci_ioda2_tce_invalidate() can be called in
    the real mode too.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 2c1d50792944..4554699aec02 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -64,6 +64,11 @@ struct iommu_table_ops {
 			long index,
 			unsigned long *hpa,
 			enum dma_data_direction *direction);
+	/* Real mode */
+	int (*exchange_rm)(struct iommu_table *tbl,
+			long index,
+			unsigned long *hpa,
+			enum dma_data_direction *direction);
 #endif
 	void (*clear)(struct iommu_table *tbl,
 			long index, long npages);
@@ -208,6 +213,8 @@ extern void iommu_del_device(struct device *dev);
 extern int __init tce_iommu_bus_notifier_init(void);
 extern long iommu_tce_xchg(struct iommu_table *tbl, unsigned long entry,
 		unsigned long *hpa, enum dma_data_direction *direction);
+extern long iommu_tce_xchg_rm(struct iommu_table *tbl, unsigned long entry,
+		unsigned long *hpa, enum dma_data_direction *direction);
 #else
 static inline void iommu_register_group(struct iommu_table_group *table_group,
 					int pci_domain_number,

commit 00085f1efa387a8ce100e3734920f7639c80caa3
Author: Krzysztof Kozlowski <k.kozlowski@samsung.com>
Date:   Wed Aug 3 13:46:00 2016 -0700

    dma-mapping: use unsigned long for dma_attrs
    
    The dma-mapping core and the implementations do not change the DMA
    attributes passed by pointer.  Thus the pointer can point to const data.
    However the attributes do not have to be a bitfield.  Instead unsigned
    long will do fine:
    
    1. This is just simpler.  Both in terms of reading the code and setting
       attributes.  Instead of initializing local attributes on the stack
       and passing pointer to it to dma_set_attr(), just set the bits.
    
    2. It brings safeness and checking for const correctness because the
       attributes are passed by value.
    
    Semantic patches for this change (at least most of them):
    
        virtual patch
        virtual context
    
        @r@
        identifier f, attrs;
    
        @@
        f(...,
        - struct dma_attrs *attrs
        + unsigned long attrs
        , ...)
        {
        ...
        }
    
        @@
        identifier r.f;
        @@
        f(...,
        - NULL
        + 0
         )
    
    and
    
        // Options: --all-includes
        virtual patch
        virtual context
    
        @r@
        identifier f, attrs;
        type t;
    
        @@
        t f(..., struct dma_attrs *attrs);
    
        @@
        identifier r.f;
        @@
        f(...,
        - NULL
        + 0
         )
    
    Link: http://lkml.kernel.org/r/1468399300-5399-2-git-send-email-k.kozlowski@samsung.com
    Signed-off-by: Krzysztof Kozlowski <k.kozlowski@samsung.com>
    Acked-by: Vineet Gupta <vgupta@synopsys.com>
    Acked-by: Robin Murphy <robin.murphy@arm.com>
    Acked-by: Hans-Christian Noren Egtvedt <egtvedt@samfundet.no>
    Acked-by: Mark Salter <msalter@redhat.com> [c6x]
    Acked-by: Jesper Nilsson <jesper.nilsson@axis.com> [cris]
    Acked-by: Daniel Vetter <daniel.vetter@ffwll.ch> [drm]
    Reviewed-by: Bart Van Assche <bart.vanassche@sandisk.com>
    Acked-by: Joerg Roedel <jroedel@suse.de> [iommu]
    Acked-by: Fabien Dessenne <fabien.dessenne@st.com> [bdisp]
    Reviewed-by: Marek Szyprowski <m.szyprowski@samsung.com> [vb2-core]
    Acked-by: David Vrabel <david.vrabel@citrix.com> [xen]
    Acked-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com> [xen swiotlb]
    Acked-by: Joerg Roedel <jroedel@suse.de> [iommu]
    Acked-by: Richard Kuo <rkuo@codeaurora.org> [hexagon]
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org> [m68k]
    Acked-by: Gerald Schaefer <gerald.schaefer@de.ibm.com> [s390]
    Acked-by: Bjorn Andersson <bjorn.andersson@linaro.org>
    Acked-by: Hans-Christian Noren Egtvedt <egtvedt@samfundet.no> [avr32]
    Acked-by: Vineet Gupta <vgupta@synopsys.com> [arc]
    Acked-by: Robin Murphy <robin.murphy@arm.com> [arm64 and dma-iommu]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index f49a72a9062d..2c1d50792944 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -53,7 +53,7 @@ struct iommu_table_ops {
 			long index, long npages,
 			unsigned long uaddr,
 			enum dma_data_direction direction,
-			struct dma_attrs *attrs);
+			unsigned long attrs);
 #ifdef CONFIG_IOMMU_API
 	/*
 	 * Exchanges existing TCE with new TCE plus direction bits;
@@ -248,12 +248,12 @@ extern int ppc_iommu_map_sg(struct device *dev, struct iommu_table *tbl,
 			    struct scatterlist *sglist, int nelems,
 			    unsigned long mask,
 			    enum dma_data_direction direction,
-			    struct dma_attrs *attrs);
+			    unsigned long attrs);
 extern void ppc_iommu_unmap_sg(struct iommu_table *tbl,
 			       struct scatterlist *sglist,
 			       int nelems,
 			       enum dma_data_direction direction,
-			       struct dma_attrs *attrs);
+			       unsigned long attrs);
 
 extern void *iommu_alloc_coherent(struct device *dev, struct iommu_table *tbl,
 				  size_t size, dma_addr_t *dma_handle,
@@ -264,10 +264,10 @@ extern dma_addr_t iommu_map_page(struct device *dev, struct iommu_table *tbl,
 				 struct page *page, unsigned long offset,
 				 size_t size, unsigned long mask,
 				 enum dma_data_direction direction,
-				 struct dma_attrs *attrs);
+				 unsigned long attrs);
 extern void iommu_unmap_page(struct iommu_table *tbl, dma_addr_t dma_handle,
 			     size_t size, enum dma_data_direction direction,
-			     struct dma_attrs *attrs);
+			     unsigned long attrs);
 
 extern void iommu_init_early_pSeries(void);
 extern void iommu_init_early_dart(struct pci_controller_ops *controller_ops);

commit c40785ad305b32e9b0b5fbc888f1f5d57f29bf44
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Jul 5 15:03:47 2016 +1000

    powerpc/dart: Use a cachable DART
    
    Instead of punching a hole in the linear mapping, just use normal
    cachable memory, and apply the flush sequence documented in the
    CPC625 (aka U3) user manual.
    
    This allows us to remove quite a bit of code related to the early
    allocation of the DART and the hole in the linear mapping. We can
    also get rid of the copy of the DART for suspend/resume as the
    original memory can just be saved/restored now, as long as we
    properly sync the caches.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    [mpe: Integrate dart_init() fix to return ENODEV when DART disabled]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 7b87bab09564..f49a72a9062d 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -273,7 +273,6 @@ extern void iommu_init_early_pSeries(void);
 extern void iommu_init_early_dart(struct pci_controller_ops *controller_ops);
 extern void iommu_init_early_pasemi(void);
 
-extern void alloc_dart_table(void);
 #if defined(CONFIG_PPC64) && defined(CONFIG_PM)
 static inline void iommu_save(void)
 {

commit 2db4928bb559f8b43ca75879548111dc13a7de31
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Jun 24 15:25:22 2015 +1000

    powerpc/iommu: Remove dma_data union
    
    To support "hybrid" DMA ops in a subsequent patch, we will need both
    a direct DMA offset and an iommu pointer. Those are currently exclusive
    (a union), so change them to be separate fields.
    
    While there, also type iommu_table_base properly and make exist only
    on CONFIG_PPC64 since it's not referenced on 32-bit at all.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index ca18cff90900..7b87bab09564 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -2,17 +2,17 @@
  * Copyright (C) 2001 Mike Corrigan & Dave Engebretsen, IBM Corporation
  * Rewrite, cleanup:
  * Copyright (C) 2004 Olof Johansson <olof@lixom.net>, IBM Corporation
- * 
+ *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
- * 
+ *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
- * 
+ *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
@@ -131,16 +131,21 @@ int get_iommu_order(unsigned long size, struct iommu_table *tbl)
 
 struct scatterlist;
 
-static inline void set_iommu_table_base(struct device *dev, void *base)
+#ifdef CONFIG_PPC64
+
+static inline void set_iommu_table_base(struct device *dev,
+					struct iommu_table *base)
 {
-	dev->archdata.dma_data.iommu_table_base = base;
+	dev->archdata.iommu_table_base = base;
 }
 
 static inline void *get_iommu_table_base(struct device *dev)
 {
-	return dev->archdata.dma_data.iommu_table_base;
+	return dev->archdata.iommu_table_base;
 }
 
+extern int dma_iommu_dma_supported(struct device *dev, u64 mask);
+
 /* Frees table for an individual device node */
 extern void iommu_free_table(struct iommu_table *tbl, const char *node_name);
 
@@ -225,6 +230,20 @@ static inline int __init tce_iommu_bus_notifier_init(void)
 }
 #endif /* !CONFIG_IOMMU_API */
 
+#else
+
+static inline void *get_iommu_table_base(struct device *dev)
+{
+	return NULL;
+}
+
+static inline int dma_iommu_dma_supported(struct device *dev, u64 mask)
+{
+	return 0;
+}
+
+#endif /* CONFIG_PPC64 */
+
 extern int ppc_iommu_map_sg(struct device *dev, struct iommu_table *tbl,
 			    struct scatterlist *sglist, int nelems,
 			    unsigned long mask,

commit e633bc86a922468a82300eef5b9802e17be5e23d
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Fri Jun 5 16:35:26 2015 +1000

    vfio: powerpc/spapr: Support Dynamic DMA windows
    
    This adds create/remove window ioctls to create and remove DMA windows.
    sPAPR defines a Dynamic DMA windows capability which allows
    para-virtualized guests to create additional DMA windows on a PCI bus.
    The existing linux kernels use this new window to map the entire guest
    memory and switch to the direct DMA operations saving time on map/unmap
    requests which would normally happen in a big amounts.
    
    This adds 2 ioctl handlers - VFIO_IOMMU_SPAPR_TCE_CREATE and
    VFIO_IOMMU_SPAPR_TCE_REMOVE - to create and remove windows.
    Up to 2 windows are supported now by the hardware and by this driver.
    
    This changes VFIO_IOMMU_SPAPR_TCE_GET_INFO handler to return additional
    information such as a number of supported windows and maximum number
    levels of TCE tables.
    
    DDW is added as a capability, not as a SPAPR TCE IOMMU v2 unique feature
    as we still want to support v2 on platforms which cannot do DDW for
    the sake of TCE acceleration in KVM (coming soon).
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    [aw: for the vfio related changes]
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index f9957eb4c659..ca18cff90900 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -149,7 +149,7 @@ extern void iommu_free_table(struct iommu_table *tbl, const char *node_name);
  */
 extern struct iommu_table *iommu_init_table(struct iommu_table * tbl,
 					    int nid);
-#define IOMMU_TABLE_GROUP_MAX_TABLES	1
+#define IOMMU_TABLE_GROUP_MAX_TABLES	2
 
 struct iommu_table_group;
 

commit 2157e7b82f3b81f57bd80cd67cef09ef26e5f74c
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Fri Jun 5 16:35:25 2015 +1000

    vfio: powerpc/spapr: Register memory and define IOMMU v2
    
    The existing implementation accounts the whole DMA window in
    the locked_vm counter. This is going to be worse with multiple
    containers and huge DMA windows. Also, real-time accounting would requite
    additional tracking of accounted pages due to the page size difference -
    IOMMU uses 4K pages and system uses 4K or 64K pages.
    
    Another issue is that actual pages pinning/unpinning happens on every
    DMA map/unmap request. This does not affect the performance much now as
    we spend way too much time now on switching context between
    guest/userspace/host but this will start to matter when we add in-kernel
    DMA map/unmap acceleration.
    
    This introduces a new IOMMU type for SPAPR - VFIO_SPAPR_TCE_v2_IOMMU.
    New IOMMU deprecates VFIO_IOMMU_ENABLE/VFIO_IOMMU_DISABLE and introduces
    2 new ioctls to register/unregister DMA memory -
    VFIO_IOMMU_SPAPR_REGISTER_MEMORY and VFIO_IOMMU_SPAPR_UNREGISTER_MEMORY -
    which receive user space address and size of a memory region which
    needs to be pinned/unpinned and counted in locked_vm.
    New IOMMU splits physical pages pinning and TCE table update
    into 2 different operations. It requires:
    1) guest pages to be registered first
    2) consequent map/unmap requests to work only with pre-registered memory.
    For the default single window case this means that the entire guest
    (instead of 2GB) needs to be pinned before using VFIO.
    When a huge DMA window is added, no additional pinning will be
    required, otherwise it would be guest RAM + 2GB.
    
    The new memory registration ioctls are not supported by
    VFIO_SPAPR_TCE_IOMMU. Dynamic DMA window and in-kernel acceleration
    will require memory to be preregistered in order to work.
    
    The accounting is done per the user process.
    
    This advertises v2 SPAPR TCE IOMMU and restricts what the userspace
    can do with v1 or v2 IOMMUs.
    
    In order to support memory pre-registration, we need a way to track
    the use of every registered memory region and only allow unregistration
    if a region is not in use anymore. So we need a way to tell from what
    region the just cleared TCE was from.
    
    This adds a userspace view of the TCE table into iommu_table struct.
    It contains userspace address, one per TCE entry. The table is only
    allocated when the ownership over an IOMMU group is taken which means
    it is only used from outside of the powernv code (such as VFIO).
    
    As v2 IOMMU supports IODA2 and pre-IODA2 IOMMUs (which do not support
    DDW API), this creates a default DMA window for IODA2 for consistency.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    [aw: for the vfio related changes]
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 9d3749287689..f9957eb4c659 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -112,9 +112,15 @@ struct iommu_table {
 	unsigned long *it_map;       /* A simple allocation bitmap for now */
 	unsigned long  it_page_shift;/* table iommu page size */
 	struct list_head it_group_list;/* List of iommu_table_group_link */
+	unsigned long *it_userspace; /* userspace view of the table */
 	struct iommu_table_ops *it_ops;
 };
 
+#define IOMMU_TABLE_USERSPACE_ENTRY(tbl, entry) \
+		((tbl)->it_userspace ? \
+			&((tbl)->it_userspace[(entry) - (tbl)->it_offset]) : \
+			NULL)
+
 /* Pure 2^n version of get_order */
 static inline __attribute_const__
 int get_iommu_order(unsigned long size, struct iommu_table *tbl)

commit 0054719386d96984153ad31d714a8be4ec7eba80
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Fri Jun 5 16:35:22 2015 +1000

    powerpc/iommu/ioda2: Add get_table_size() to calculate the size of future table
    
    This adds a way for the IOMMU user to know how much a new table will
    use so it can be accounted in the locked_vm limit before allocation
    happens.
    
    This stores the allocated table size in pnv_pci_ioda2_get_table_size()
    so the locked_vm counter can be updated correctly when a table is
    being disposed.
    
    This defines an iommu_table_group_ops callback to let VFIO know
    how much memory will be locked if a table is created.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index e5541759a37d..9d3749287689 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -99,6 +99,7 @@ struct iommu_table {
 	unsigned long  it_size;      /* Size of iommu table in entries */
 	unsigned long  it_indirect_levels;
 	unsigned long  it_level_size;
+	unsigned long  it_allocated_size;
 	unsigned long  it_offset;    /* Offset into global table */
 	unsigned long  it_base;      /* mapped address of tce table */
 	unsigned long  it_index;     /* which iommu table this is */
@@ -147,6 +148,10 @@ extern struct iommu_table *iommu_init_table(struct iommu_table * tbl,
 struct iommu_table_group;
 
 struct iommu_table_group_ops {
+	unsigned long (*get_table_size)(
+			__u32 page_shift,
+			__u64 window_size,
+			__u32 levels);
 	long (*create_table)(struct iommu_table_group *table_group,
 			int num,
 			__u32 page_shift,

commit 4793d65d1ac056d92b594d05c6aab3c040d913dd
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Fri Jun 5 16:35:20 2015 +1000

    vfio: powerpc/spapr: powerpc/powernv/ioda: Define and implement DMA windows API
    
    This extends iommu_table_group_ops by a set of callbacks to support
    dynamic DMA windows management.
    
    create_table() creates a TCE table with specific parameters.
    it receives iommu_table_group to know nodeid in order to allocate
    TCE table memory closer to the PHB. The exact format of allocated
    multi-level table might be also specific to the PHB model (not
    the case now though).
    This callback calculated the DMA window offset on a PCI bus from @num
    and stores it in a just created table.
    
    set_window() sets the window at specified TVT index + @num on PHB.
    
    unset_window() unsets the window from specified TVT.
    
    This adds a free() callback to iommu_table_ops to free the memory
    (potentially a tree of tables) allocated for the TCE table.
    
    create_table() and free() are supposed to be called once per
    VFIO container and set_window()/unset_window() are supposed to be
    called for every group in a container.
    
    This adds IOMMU capabilities to iommu_table_group such as default
    32bit window parameters and others. This makes use of new values in
    vfio_iommu_spapr_tce. IODA1/P5IOC2 do not support DDW so they do not
    advertise pagemasks to the userspace.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 706cfc0b1190..e5541759a37d 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -70,6 +70,7 @@ struct iommu_table_ops {
 	/* get() returns a physical address */
 	unsigned long (*get)(struct iommu_table *tbl, long index);
 	void (*flush)(struct iommu_table *tbl);
+	void (*free)(struct iommu_table *tbl);
 };
 
 /* These are used by VIO */
@@ -146,6 +147,17 @@ extern struct iommu_table *iommu_init_table(struct iommu_table * tbl,
 struct iommu_table_group;
 
 struct iommu_table_group_ops {
+	long (*create_table)(struct iommu_table_group *table_group,
+			int num,
+			__u32 page_shift,
+			__u64 window_size,
+			__u32 levels,
+			struct iommu_table **ptbl);
+	long (*set_window)(struct iommu_table_group *table_group,
+			int num,
+			struct iommu_table *tblnew);
+	long (*unset_window)(struct iommu_table_group *table_group,
+			int num);
 	/* Switch ownership from platform code to external user (e.g. VFIO) */
 	void (*take_ownership)(struct iommu_table_group *table_group);
 	/* Switch ownership from external user (e.g. VFIO) back to core */
@@ -159,6 +171,13 @@ struct iommu_table_group_link {
 };
 
 struct iommu_table_group {
+	/* IOMMU properties */
+	__u32 tce32_start;
+	__u32 tce32_size;
+	__u64 pgsizes; /* Bitmap of supported page sizes */
+	__u32 max_dynamic_windows_supported;
+	__u32 max_levels;
+
 	struct iommu_group *group;
 	struct iommu_table *tables[IOMMU_TABLE_GROUP_MAX_TABLES];
 	struct iommu_table_group_ops *ops;

commit bbb845c4bac88d8feffa8945dd28b50849984e30
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Fri Jun 5 16:35:19 2015 +1000

    powerpc/powernv: Implement multilevel TCE tables
    
    TCE tables might get too big in case of 4K IOMMU pages and DDW enabled
    on huge guests (hundreds of GB of RAM) so the kernel might be unable to
    allocate contiguous chunk of physical memory to store the TCE table.
    
    To address this, POWER8 CPU (actually, IODA2) supports multi-level
    TCE tables, up to 5 levels which splits the table into a tree of
    smaller subtables.
    
    This adds multi-level TCE tables support to
    pnv_pci_ioda2_table_alloc_pages() and pnv_pci_ioda2_table_free_pages()
    helpers.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 4636734604d7..706cfc0b1190 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -96,6 +96,8 @@ struct iommu_pool {
 struct iommu_table {
 	unsigned long  it_busno;     /* Bus number this table belongs to */
 	unsigned long  it_size;      /* Size of iommu table in entries */
+	unsigned long  it_indirect_levels;
+	unsigned long  it_level_size;
 	unsigned long  it_offset;    /* Offset into global table */
 	unsigned long  it_base;      /* mapped address of tce table */
 	unsigned long  it_index;     /* which iommu table this is */

commit 05c6cfb9dce0d13d37e9d007ee6a4af36f1c0a58
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Fri Jun 5 16:35:15 2015 +1000

    powerpc/iommu/powernv: Release replaced TCE
    
    At the moment writing new TCE value to the IOMMU table fails with EBUSY
    if there is a valid entry already. However PAPR specification allows
    the guest to write new TCE value without clearing it first.
    
    Another problem this patch is addressing is the use of pool locks for
    external IOMMU users such as VFIO. The pool locks are to protect
    DMA page allocator rather than entries and since the host kernel does
    not control what pages are in use, there is no point in pool locks and
    exchange()+put_page(oldtce) is sufficient to avoid possible races.
    
    This adds an exchange() callback to iommu_table_ops which does the same
    thing as set() plus it returns replaced TCE and DMA direction so
    the caller can release the pages afterwards. The exchange() receives
    a physical address unlike set() which receives linear mapping address;
    and returns a physical address as the clear() does.
    
    This implements exchange() for P5IOC2/IODA/IODA2. This adds a requirement
    for a platform to have exchange() implemented in order to support VFIO.
    
    This replaces iommu_tce_build() and iommu_clear_tce() with
    a single iommu_tce_xchg().
    
    This makes sure that TCE permission bits are not set in TCE passed to
    IOMMU API as those are to be calculated by platform code from
    DMA direction.
    
    This moves SetPageDirty() to the IOMMU code to make it work for both
    VFIO ioctl interface in in-kernel TCE acceleration (when it becomes
    available later).
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    [aw: for the vfio related changes]
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 489133cf7c5e..4636734604d7 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -45,13 +45,29 @@ extern int iommu_is_off;
 extern int iommu_force_on;
 
 struct iommu_table_ops {
+	/*
+	 * When called with direction==DMA_NONE, it is equal to clear().
+	 * uaddr is a linear map address.
+	 */
 	int (*set)(struct iommu_table *tbl,
 			long index, long npages,
 			unsigned long uaddr,
 			enum dma_data_direction direction,
 			struct dma_attrs *attrs);
+#ifdef CONFIG_IOMMU_API
+	/*
+	 * Exchanges existing TCE with new TCE plus direction bits;
+	 * returns old TCE and DMA direction mask.
+	 * @tce is a physical address.
+	 */
+	int (*exchange)(struct iommu_table *tbl,
+			long index,
+			unsigned long *hpa,
+			enum dma_data_direction *direction);
+#endif
 	void (*clear)(struct iommu_table *tbl,
 			long index, long npages);
+	/* get() returns a physical address */
 	unsigned long (*get)(struct iommu_table *tbl, long index);
 	void (*flush)(struct iommu_table *tbl);
 };
@@ -153,6 +169,8 @@ extern void iommu_register_group(struct iommu_table_group *table_group,
 extern int iommu_add_device(struct device *dev);
 extern void iommu_del_device(struct device *dev);
 extern int __init tce_iommu_bus_notifier_init(void);
+extern long iommu_tce_xchg(struct iommu_table *tbl, unsigned long entry,
+		unsigned long *hpa, enum dma_data_direction *direction);
 #else
 static inline void iommu_register_group(struct iommu_table_group *table_group,
 					int pci_domain_number,
@@ -225,10 +243,6 @@ extern int iommu_tce_clear_param_check(struct iommu_table *tbl,
 		unsigned long npages);
 extern int iommu_tce_put_param_check(struct iommu_table *tbl,
 		unsigned long ioba, unsigned long tce);
-extern int iommu_tce_build(struct iommu_table *tbl, unsigned long entry,
-		unsigned long hwaddr, enum dma_data_direction direction);
-extern unsigned long iommu_clear_tce(struct iommu_table *tbl,
-		unsigned long entry);
 
 extern void iommu_flush_tce(struct iommu_table *tbl);
 extern int iommu_take_ownership(struct iommu_table *tbl);

commit f87a88642e660edd8912ad39fe77848c6f9927a2
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Fri Jun 5 16:35:10 2015 +1000

    vfio: powerpc/spapr/iommu/powernv/ioda2: Rework IOMMU ownership control
    
    This adds tce_iommu_take_ownership() and tce_iommu_release_ownership
    which call in a loop iommu_take_ownership()/iommu_release_ownership()
    for every table on the group. As there is just one now, no change in
    behaviour is expected.
    
    At the moment the iommu_table struct has a set_bypass() which enables/
    disables DMA bypass on IODA2 PHB. This is exposed to POWERPC IOMMU code
    which calls this callback when external IOMMU users such as VFIO are
    about to get over a PHB.
    
    The set_bypass() callback is not really an iommu_table function but
    IOMMU/PE function. This introduces a iommu_table_group_ops struct and
    adds take_ownership()/release_ownership() callbacks to it which are
    called when an external user takes/releases control over the IOMMU.
    
    This replaces set_bypass() with ownership callbacks as it is not
    necessarily just bypass enabling, it can be something else/more
    so let's give it more generic name.
    
    The callbacks is implemented for IODA2 only. Other platforms (P5IOC2,
    IODA1) will use the old iommu_take_ownership/iommu_release_ownership API.
    The following patches will replace iommu_take_ownership/
    iommu_release_ownership calls in IODA2 with full IOMMU table release/
    create.
    
    As we here and touching bypass control, this removes
    pnv_pci_ioda2_setup_bypass_pe() as it does not do much
    more compared to pnv_pci_ioda2_set_bypass. This moves tce_bypass_base
    initialization to pnv_pci_ioda2_setup_dma_pe.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    [aw: for the vfio related changes]
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Reviewed-by: Gavin Shan <gwshan@linux.vnet.ibm.com>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 44a20ccf06b4..489133cf7c5e 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -93,7 +93,6 @@ struct iommu_table {
 	unsigned long  it_page_shift;/* table iommu page size */
 	struct list_head it_group_list;/* List of iommu_table_group_link */
 	struct iommu_table_ops *it_ops;
-	void (*set_bypass)(struct iommu_table *tbl, bool enable);
 };
 
 /* Pure 2^n version of get_order */
@@ -126,6 +125,15 @@ extern struct iommu_table *iommu_init_table(struct iommu_table * tbl,
 					    int nid);
 #define IOMMU_TABLE_GROUP_MAX_TABLES	1
 
+struct iommu_table_group;
+
+struct iommu_table_group_ops {
+	/* Switch ownership from platform code to external user (e.g. VFIO) */
+	void (*take_ownership)(struct iommu_table_group *table_group);
+	/* Switch ownership from external user (e.g. VFIO) back to core */
+	void (*release_ownership)(struct iommu_table_group *table_group);
+};
+
 struct iommu_table_group_link {
 	struct list_head next;
 	struct rcu_head rcu;
@@ -135,6 +143,7 @@ struct iommu_table_group_link {
 struct iommu_table_group {
 	struct iommu_group *group;
 	struct iommu_table *tables[IOMMU_TABLE_GROUP_MAX_TABLES];
+	struct iommu_table_group_ops *ops;
 };
 
 #ifdef CONFIG_IOMMU_API

commit 0eaf4defc7c44ed5dd33a03cab12a5f88c9b4b86
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Fri Jun 5 16:35:09 2015 +1000

    powerpc/spapr: vfio: Switch from iommu_table to new iommu_table_group
    
    So far one TCE table could only be used by one IOMMU group. However
    IODA2 hardware allows programming the same TCE table address to
    multiple PE allowing sharing tables.
    
    This replaces a single pointer to a group in a iommu_table struct
    with a linked list of groups which provides the way of invalidating
    TCE cache for every PE when an actual TCE table is updated. This adds
    pnv_pci_link_table_and_group() and pnv_pci_unlink_table_and_group()
    helpers to manage the list. However without VFIO, it is still going
    to be a single IOMMU group per iommu_table.
    
    This changes iommu_add_device() to add a device to a first group
    from the group list of a table as it is only called from the platform
    init code or PCI bus notifier and at these moments there is only
    one group per table.
    
    This does not change TCE invalidation code to loop through all
    attached groups in order to simplify this patch and because
    it is not really needed in most cases. IODA2 is fixed in a later
    patch.
    
    This should cause no behavioural change.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    [aw: for the vfio related changes]
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Reviewed-by: Gavin Shan <gwshan@linux.vnet.ibm.com>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 5a7267f47bdb..44a20ccf06b4 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -91,7 +91,7 @@ struct iommu_table {
 	struct iommu_pool pools[IOMMU_NR_POOLS];
 	unsigned long *it_map;       /* A simple allocation bitmap for now */
 	unsigned long  it_page_shift;/* table iommu page size */
-	struct iommu_table_group *it_table_group;
+	struct list_head it_group_list;/* List of iommu_table_group_link */
 	struct iommu_table_ops *it_ops;
 	void (*set_bypass)(struct iommu_table *tbl, bool enable);
 };
@@ -126,6 +126,12 @@ extern struct iommu_table *iommu_init_table(struct iommu_table * tbl,
 					    int nid);
 #define IOMMU_TABLE_GROUP_MAX_TABLES	1
 
+struct iommu_table_group_link {
+	struct list_head next;
+	struct rcu_head rcu;
+	struct iommu_table_group *table_group;
+};
+
 struct iommu_table_group {
 	struct iommu_group *group;
 	struct iommu_table *tables[IOMMU_TABLE_GROUP_MAX_TABLES];

commit b348aa65297659c310943221ac1d3f4b4491ea44
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Fri Jun 5 16:35:08 2015 +1000

    powerpc/spapr: vfio: Replace iommu_table with iommu_table_group
    
    Modern IBM POWERPC systems support multiple (currently two) TCE tables
    per IOMMU group (a.k.a. PE). This adds a iommu_table_group container
    for TCE tables. Right now just one table is supported.
    
    This defines iommu_table_group struct which stores pointers to
    iommu_group and iommu_table(s). This replaces iommu_table with
    iommu_table_group where iommu_table was used to identify a group:
    - iommu_register_group();
    - iommudata of generic iommu_group;
    
    This removes @data from iommu_table as it_table_group provides
    same access to pnv_ioda_pe.
    
    For IODA, instead of embedding iommu_table, the new iommu_table_group
    keeps pointers to those. The iommu_table structs are allocated
    dynamically.
    
    For P5IOC2, both iommu_table_group and iommu_table are embedded into
    PE struct. As there is no EEH and SRIOV support for P5IOC2,
    iommu_free_table() should not be called on iommu_table struct pointers
    so we can keep it embedded in pnv_phb::p5ioc2.
    
    For pSeries, this replaces multiple calls of kzalloc_node() with a new
    iommu_pseries_alloc_group() helper and stores the table group struct
    pointer into the pci_dn struct. For release, a iommu_table_free_group()
    helper is added.
    
    This moves iommu_table struct allocation from SR-IOV code to
    the generic DMA initialization code in pnv_pci_ioda_setup_dma_pe and
    pnv_pci_ioda2_setup_dma_pe as this is where DMA is actually initialized.
    This change is here because those lines had to be changed anyway.
    
    This should cause no behavioural change.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    [aw: for the vfio related changes]
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Reviewed-by: Gavin Shan <gwshan@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index e2a45c37dba8..5a7267f47bdb 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -91,14 +91,9 @@ struct iommu_table {
 	struct iommu_pool pools[IOMMU_NR_POOLS];
 	unsigned long *it_map;       /* A simple allocation bitmap for now */
 	unsigned long  it_page_shift;/* table iommu page size */
-#ifdef CONFIG_IOMMU_API
-	struct iommu_group *it_group;
-#endif
+	struct iommu_table_group *it_table_group;
 	struct iommu_table_ops *it_ops;
 	void (*set_bypass)(struct iommu_table *tbl, bool enable);
-#ifdef CONFIG_PPC_POWERNV
-	void           *data;
-#endif
 };
 
 /* Pure 2^n version of get_order */
@@ -129,14 +124,22 @@ extern void iommu_free_table(struct iommu_table *tbl, const char *node_name);
  */
 extern struct iommu_table *iommu_init_table(struct iommu_table * tbl,
 					    int nid);
+#define IOMMU_TABLE_GROUP_MAX_TABLES	1
+
+struct iommu_table_group {
+	struct iommu_group *group;
+	struct iommu_table *tables[IOMMU_TABLE_GROUP_MAX_TABLES];
+};
+
 #ifdef CONFIG_IOMMU_API
-extern void iommu_register_group(struct iommu_table *tbl,
+
+extern void iommu_register_group(struct iommu_table_group *table_group,
 				 int pci_domain_number, unsigned long pe_num);
 extern int iommu_add_device(struct device *dev);
 extern void iommu_del_device(struct device *dev);
 extern int __init tce_iommu_bus_notifier_init(void);
 #else
-static inline void iommu_register_group(struct iommu_table *tbl,
+static inline void iommu_register_group(struct iommu_table_group *table_group,
 					int pci_domain_number,
 					unsigned long pe_num)
 {

commit da004c3600f52e4f05017f60970e5010978006bc
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Fri Jun 5 16:35:06 2015 +1000

    powerpc/iommu: Move tce_xxx callbacks from ppc_md to iommu_table
    
    This adds a iommu_table_ops struct and puts pointer to it into
    the iommu_table struct. This moves tce_build/tce_free/tce_get/tce_flush
    callbacks from ppc_md to the new struct where they really belong to.
    
    This adds the requirement for @it_ops to be initialized before calling
    iommu_init_table() to make sure that we do not leave any IOMMU table
    with iommu_table_ops uninitialized. This is not a parameter of
    iommu_init_table() though as there will be cases when iommu_init_table()
    will not be called on TCE tables, for example - VFIO.
    
    This does s/tce_build/set/, s/tce_free/clear/ and removes "tce_"
    redundant prefixes.
    
    This removes tce_xxx_rm handlers from ppc_md but does not add
    them to iommu_table_ops as this will be done later if we decide to
    support TCE hypercalls in real mode. This removes _vm callbacks as
    only virtual mode is supported by now so this also removes @rm parameter.
    
    For pSeries, this always uses tce_buildmulti_pSeriesLP/
    tce_buildmulti_pSeriesLP. This changes multi callback to fall back to
    tce_build_pSeriesLP/tce_free_pSeriesLP if FW_FEATURE_MULTITCE is not
    present. The reason for this is we still have to support "multitce=off"
    boot parameter in disable_multitce() and we do not want to walk through
    all IOMMU tables in the system and replace "multi" callbacks with single
    ones.
    
    For powernv, this defines _ops per PHB type which are P5IOC2/IODA1/IODA2.
    This makes the callbacks for them public. Later patches will extend
    callbacks for IODA1/2.
    
    No change in behaviour is expected.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Reviewed-by: Gavin Shan <gwshan@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index d91bd69d3196..e2a45c37dba8 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -44,6 +44,22 @@
 extern int iommu_is_off;
 extern int iommu_force_on;
 
+struct iommu_table_ops {
+	int (*set)(struct iommu_table *tbl,
+			long index, long npages,
+			unsigned long uaddr,
+			enum dma_data_direction direction,
+			struct dma_attrs *attrs);
+	void (*clear)(struct iommu_table *tbl,
+			long index, long npages);
+	unsigned long (*get)(struct iommu_table *tbl, long index);
+	void (*flush)(struct iommu_table *tbl);
+};
+
+/* These are used by VIO */
+extern struct iommu_table_ops iommu_table_lpar_multi_ops;
+extern struct iommu_table_ops iommu_table_pseries_ops;
+
 /*
  * IOMAP_MAX_ORDER defines the largest contiguous block
  * of dma space we can get.  IOMAP_MAX_ORDER = 13
@@ -78,6 +94,7 @@ struct iommu_table {
 #ifdef CONFIG_IOMMU_API
 	struct iommu_group *it_group;
 #endif
+	struct iommu_table_ops *it_ops;
 	void (*set_bypass)(struct iommu_table *tbl, bool enable);
 #ifdef CONFIG_PPC_POWERNV
 	void           *data;

commit 10b35b2b7485c342334a48cf199063eed8b8748e
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Fri Jun 5 16:35:05 2015 +1000

    powerpc/powernv: Do not set "read" flag if direction==DMA_NONE
    
    Normally a bitmap from the iommu_table is used to track what TCE entry
    is in use. Since we are going to use iommu_table without its locks and
    do xchg() instead, it becomes essential not to put bits which are not
    implied in the direction flag as the old TCE value (more precisely -
    the permission bits) will be used to decide whether to put the page or not.
    
    This adds iommu_direction_to_tce_perm() (its counterpart is there already)
    and uses it for powernv's pnv_tce_build().
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Reviewed-by: Gavin Shan <gwshan@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index e94a5e3c5a2f..d91bd69d3196 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -200,6 +200,7 @@ extern int iommu_take_ownership(struct iommu_table *tbl);
 extern void iommu_release_ownership(struct iommu_table *tbl);
 
 extern enum dma_data_direction iommu_tce_direction(unsigned long tce);
+extern unsigned long iommu_direction_to_tce_perm(enum dma_data_direction dir);
 
 #endif /* __KERNEL__ */
 #endif /* _ASM_IOMMU_H */

commit 9b14a1ff8657d3ee844f8987482bc367a716848c
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Fri Jun 5 16:34:58 2015 +1000

    vfio: powerpc/spapr: Move page pinning from arch code to VFIO IOMMU driver
    
    This moves page pinning (get_user_pages_fast()/put_page()) code out of
    the platform IOMMU code and puts it to VFIO IOMMU driver where it belongs
    to as the platform code does not deal with page pinning.
    
    This makes iommu_take_ownership()/iommu_release_ownership() deal with
    the IOMMU table bitmap only.
    
    This removes page unpinning from iommu_take_ownership() as the actual
    TCE table might contain garbage and doing put_page() on it is undefined
    behaviour.
    
    Besides the last part, the rest of the patch is mechanical.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    [aw: for the vfio related changes]
    Acked-by: Alex Williamson <alex.williamson@redhat.com>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Reviewed-by: Gavin Shan <gwshan@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 8353c865db6f..e94a5e3c5a2f 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -194,10 +194,6 @@ extern int iommu_tce_build(struct iommu_table *tbl, unsigned long entry,
 		unsigned long hwaddr, enum dma_data_direction direction);
 extern unsigned long iommu_clear_tce(struct iommu_table *tbl,
 		unsigned long entry);
-extern int iommu_clear_tces_and_put_pages(struct iommu_table *tbl,
-		unsigned long entry, unsigned long pages);
-extern int iommu_put_tce_user_mode(struct iommu_table *tbl,
-		unsigned long entry, unsigned long tce);
 
 extern void iommu_flush_tce(struct iommu_table *tbl);
 extern int iommu_take_ownership(struct iommu_table *tbl);

commit 4617082ec049d92a797e8be0b4ba2ba6b59d90d1
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Fri Jun 5 16:34:54 2015 +1000

    powerpc/iommu/powernv: Get rid of set_iommu_table_base_and_group
    
    The set_iommu_table_base_and_group() name suggests that the function
    sets table base and add a device to an IOMMU group.
    
    The actual purpose for table base setting is to put some reference
    into a device so later iommu_add_device() can get the IOMMU group
    reference and the device to the group.
    
    At the moment a group cannot be explicitly passed to iommu_add_device()
    as we want it to work from the bus notifier, we can fix it later and
    remove confusing calls of set_iommu_table_base().
    
    This replaces set_iommu_table_base_and_group() with a couple of
    set_iommu_table_base() + iommu_add_device() which makes reading the code
    easier.
    
    This adds few comments why set_iommu_table_base() and iommu_add_device()
    are called where they are called.
    
    For IODA1/2, this essentially removes iommu_add_device() call from
    the pnv_pci_ioda_dma_dev_setup() as it will always fail at this particular
    place:
    - for physical PE, the device is already attached by iommu_add_device()
    in pnv_pci_ioda_setup_dma_pe();
    - for virtual PE, the sysfs entries are not ready to create all symlinks
    so actual adding is happening in tce_iommu_bus_notifier.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Reviewed-by: Gavin Shan <gwshan@linux.vnet.ibm.com>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 1e27d6338565..8353c865db6f 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -140,13 +140,6 @@ static inline int __init tce_iommu_bus_notifier_init(void)
 }
 #endif /* !CONFIG_IOMMU_API */
 
-static inline void set_iommu_table_base_and_group(struct device *dev,
-						  void *base)
-{
-	set_iommu_table_base(dev, base);
-	iommu_add_device(dev);
-}
-
 extern int ppc_iommu_map_sg(struct device *dev, struct iommu_table *tbl,
 			    struct scatterlist *sglist, int nelems,
 			    unsigned long mask,

commit ad30cb9946515f72af5c3e89ad9de18870c1a1e7
Merge: b0a478ede669 d4ed11aa4881
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Apr 14 09:29:23 2015 +1000

    Merge branch 'next-sriov' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc into next
    
    Merge Richard's work to support SR-IOV on PowerNV. All generic PCI
    patches acked by Bjorn.
    
    Some minor conflicts with Daniel's pci_controller_ops work.
    
    Conflicts:
            arch/powerpc/include/asm/machdep.h
            arch/powerpc/platforms/powernv/pci-ioda.c

commit 798248a3c083a4cf0ead44a85e66c6a18647abea
Author: Daniel Axtens <dja@axtens.net>
Date:   Tue Mar 31 16:00:48 2015 +1100

    powerpc: dart_iommu: optionally populate controller_ops on init
    
    If a pci_controller_ops struct is provided to iommu_init_early_dart,
    populate that with the DMA setup ops, rather than ppc_md. If NULL is
    provided, populate ppc_md as before.
    
    This also patches the call sites for Maple and Power Mac to pass
    NULL, so existing behaviour is preserved.
    
    The benefit of making this optional is that it means we don't have
    to change dart, Maple and Power Mac over to the controller_ops
    system in one fell swoop.
    
    Signed-off-by: Daniel Axtens <dja@axtens.net>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index f1ea5972f6ec..0be7d9e13189 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -29,6 +29,7 @@
 #include <linux/bitops.h>
 #include <asm/machdep.h>
 #include <asm/types.h>
+#include <asm/pci-bridge.h>
 
 #define IOMMU_PAGE_SHIFT_4K      12
 #define IOMMU_PAGE_SIZE_4K       (ASM_CONST(1) << IOMMU_PAGE_SHIFT_4K)
@@ -169,7 +170,7 @@ extern void iommu_unmap_page(struct iommu_table *tbl, dma_addr_t dma_handle,
 			     struct dma_attrs *attrs);
 
 extern void iommu_init_early_pSeries(void);
-extern void iommu_init_early_dart(void);
+extern void iommu_init_early_dart(struct pci_controller_ops *controller_ops);
 extern void iommu_init_early_pasemi(void);
 
 extern void alloc_dart_table(void);

commit 9e8d4a19ab66ec9e132d405357b9108a4f26efd3
Author: Wei Yang <weiyang@linux.vnet.ibm.com>
Date:   Wed Mar 25 16:23:54 2015 +0800

    powerpc/powernv: Allocate struct pnv_ioda_pe iommu_table dynamically
    
    Previously the iommu_table had the same lifetime as a struct pnv_ioda_pe
    and was embedded in it. The pnv_ioda_pe was assigned to a PE on the bootup
    stage. Since PEs are based on the hardware layout which is static in the
    system, they will never get released. This means the iommu_table in the
    pnv_ioda_pe will never get released either.
    
    This no longer works for VF PE. VF PEs are created and released dynamically
    when VFs are created and released. So we need to assign pnv_ioda_pe to VF
    PEs respectively when VFs are enabled and clean up those resources for VF
    PE when VFs are disabled. And iommu_table is one of the resources we need
    to handle dynamically.
    
    Current iommu_table is a static field in pnv_ioda_pe, which will face a
    problem when freeing it. During the disabling of a VF,
    pnv_pci_ioda2_release_dma_pe will call iommu_free_table to release the
    iommu_table for this PE. A static iommu_table will fail in
    iommu_free_table.
    
    According to these requirement, this patch allocates iommu_table
    dynamically.
    
    Signed-off-by: Wei Yang <weiyang@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index f1ea5972f6ec..e2abbe8a1f4d 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -78,6 +78,9 @@ struct iommu_table {
 	struct iommu_group *it_group;
 #endif
 	void (*set_bypass)(struct iommu_table *tbl, bool enable);
+#ifdef CONFIG_PPC_POWERNV
+	void           *data;
+#endif
 };
 
 /* Pure 2^n version of get_order */

commit 4ad04e5987115ece5fa8a0cf1dc72fcd4707e33e
Author: Nishanth Aravamudan <nacc@linux.vnet.ibm.com>
Date:   Sat Feb 21 11:00:50 2015 -0800

    powerpc/iommu: Remove IOMMU device references via bus notifier
    
    After d905c5df9aef ("PPC: POWERNV: move iommu_add_device earlier"), the
    refcnt on the kobject backing the IOMMU group for a PCI device is
    elevated by each call to pci_dma_dev_setup_pSeriesLP() (via
    set_iommu_table_base_and_group). When we go to dlpar a multi-function
    PCI device out:
    
            iommu_reconfig_notifier ->
                    iommu_free_table ->
                            iommu_group_put
                            BUG_ON(tbl->it_group)
    
    We trip this BUG_ON, because there are still references on the table, so
    it is not freed. Fix this by moving the powernv bus notifier to common
    code and calling it for both powernv and pseries.
    
    Fixes: d905c5df9aef ("PPC: POWERNV: move iommu_add_device earlier")
    Signed-off-by: Nishanth Aravamudan <nacc@linux.vnet.ibm.com>
    Tested-by: Nishanth Aravamudan <nacc@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 9cfa3706a1b8..f1ea5972f6ec 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -113,6 +113,7 @@ extern void iommu_register_group(struct iommu_table *tbl,
 				 int pci_domain_number, unsigned long pe_num);
 extern int iommu_add_device(struct device *dev);
 extern void iommu_del_device(struct device *dev);
+extern int __init tce_iommu_bus_notifier_init(void);
 #else
 static inline void iommu_register_group(struct iommu_table *tbl,
 					int pci_domain_number,
@@ -128,6 +129,11 @@ static inline int iommu_add_device(struct device *dev)
 static inline void iommu_del_device(struct device *dev)
 {
 }
+
+static inline int __init tce_iommu_bus_notifier_init(void)
+{
+        return 0;
+}
 #endif /* !CONFIG_IOMMU_API */
 
 static inline void set_iommu_table_base_and_group(struct device *dev,

commit 0690cbd2e55a72a8eae557c389d1a136ed9fa142
Author: Joerg Roedel <jroedel@suse.de>
Date:   Wed Nov 5 15:28:30 2014 +0100

    powerpc/iommu: Rename iommu_[un]map_sg functions
    
    The IOMMU-API gained support for a new iommu_map_sg
    function. This causes compile failures on powerpc because
    the function name is already globally used there.
    This patch renames adds a ppc_ prefix to these functions to
    solve the compile problem.
    
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 42632c7a2a4e..9cfa3706a1b8 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -137,13 +137,16 @@ static inline void set_iommu_table_base_and_group(struct device *dev,
 	iommu_add_device(dev);
 }
 
-extern int iommu_map_sg(struct device *dev, struct iommu_table *tbl,
-			struct scatterlist *sglist, int nelems,
-			unsigned long mask, enum dma_data_direction direction,
-			struct dma_attrs *attrs);
-extern void iommu_unmap_sg(struct iommu_table *tbl, struct scatterlist *sglist,
-			   int nelems, enum dma_data_direction direction,
-			   struct dma_attrs *attrs);
+extern int ppc_iommu_map_sg(struct device *dev, struct iommu_table *tbl,
+			    struct scatterlist *sglist, int nelems,
+			    unsigned long mask,
+			    enum dma_data_direction direction,
+			    struct dma_attrs *attrs);
+extern void ppc_iommu_unmap_sg(struct iommu_table *tbl,
+			       struct scatterlist *sglist,
+			       int nelems,
+			       enum dma_data_direction direction,
+			       struct dma_attrs *attrs);
 
 extern void *iommu_alloc_coherent(struct device *dev, struct iommu_table *tbl,
 				  size_t size, dma_addr_t *dma_handle,

commit cd15b048445d0a54f7147c35a86c5a16ef231554
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Feb 11 11:32:38 2014 +1100

    powerpc/powernv: Add iommu DMA bypass support for IODA2
    
    This patch adds the support for to create a direct iommu "bypass"
    window on IODA2 bridges (such as Power8) allowing to bypass iommu
    page translation completely for 64-bit DMA capable devices, thus
    significantly improving DMA performances.
    
    Additionally, this adds a hook to the struct iommu_table so that
    the IOMMU API / VFIO can disable the bypass when external ownership
    is requested, since in that case, the device will be used by an
    environment such as userspace or a KVM guest which must not be
    allowed to bypass translations.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index f7a8036579b5..42632c7a2a4e 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -77,6 +77,7 @@ struct iommu_table {
 #ifdef CONFIG_IOMMU_API
 	struct iommu_group *it_group;
 #endif
+	void (*set_bypass)(struct iommu_table *tbl, bool enable);
 };
 
 /* Pure 2^n version of get_order */

commit d084775738b746648d4102337163a04534a02982
Author: Alistair Popple <alistair@popple.id.au>
Date:   Mon Dec 9 18:17:03 2013 +1100

    powerpc/iommu: Update the generic code to use dynamic iommu page sizes
    
    This patch updates the generic iommu backend code to use the
    it_page_shift field to determine the iommu page size instead of
    using hardcoded values.
    
    Signed-off-by: Alistair Popple <alistair@popple.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 7c928342f3f5..f7a8036579b5 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -35,17 +35,14 @@
 #define IOMMU_PAGE_MASK_4K       (~((1 << IOMMU_PAGE_SHIFT_4K) - 1))
 #define IOMMU_PAGE_ALIGN_4K(addr) _ALIGN_UP(addr, IOMMU_PAGE_SIZE_4K)
 
+#define IOMMU_PAGE_SIZE(tblptr) (ASM_CONST(1) << (tblptr)->it_page_shift)
+#define IOMMU_PAGE_MASK(tblptr) (~((1 << (tblptr)->it_page_shift) - 1))
+#define IOMMU_PAGE_ALIGN(addr, tblptr) _ALIGN_UP(addr, IOMMU_PAGE_SIZE(tblptr))
+
 /* Boot time flags */
 extern int iommu_is_off;
 extern int iommu_force_on;
 
-/* Pure 2^n version of get_order */
-static __inline__ __attribute_const__ int get_iommu_order(unsigned long size)
-{
-	return __ilog2((size - 1) >> IOMMU_PAGE_SHIFT_4K) + 1;
-}
-
-
 /*
  * IOMAP_MAX_ORDER defines the largest contiguous block
  * of dma space we can get.  IOMAP_MAX_ORDER = 13
@@ -82,6 +79,14 @@ struct iommu_table {
 #endif
 };
 
+/* Pure 2^n version of get_order */
+static inline __attribute_const__
+int get_iommu_order(unsigned long size, struct iommu_table *tbl)
+{
+	return __ilog2((size - 1) >> tbl->it_page_shift) + 1;
+}
+
+
 struct scatterlist;
 
 static inline void set_iommu_table_base(struct device *dev, void *base)

commit 3a553170d35d69bea3877bffa508489dfa6f133d
Author: Alistair Popple <alistair@popple.id.au>
Date:   Mon Dec 9 18:17:02 2013 +1100

    powerpc/iommu: Add it_page_shift field to determine iommu page size
    
    This patch adds a it_page_shift field to struct iommu_table and
    initiliases it to 4K for all platforms.
    
    Signed-off-by: Alistair Popple <alistair@popple.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 0869c7e74421..7c928342f3f5 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -76,6 +76,7 @@ struct iommu_table {
 	struct iommu_pool large_pool;
 	struct iommu_pool pools[IOMMU_NR_POOLS];
 	unsigned long *it_map;       /* A simple allocation bitmap for now */
+	unsigned long  it_page_shift;/* table iommu page size */
 #ifdef CONFIG_IOMMU_API
 	struct iommu_group *it_group;
 #endif

commit e589a4404fa06730355de204d3d136ed9bbc7dea
Author: Alistair Popple <alistair@popple.id.au>
Date:   Mon Dec 9 18:17:01 2013 +1100

    powerpc/iommu: Update constant names to reflect their hardcoded page size
    
    The powerpc iommu uses a hardcoded page size of 4K. This patch changes
    the name of the IOMMU_PAGE_* macros to reflect the hardcoded values. A
    future patch will use the existing names to support dynamic page
    sizes.
    
    Signed-off-by: Alistair Popple <alistair@popple.id.au>
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 774fa2776907..0869c7e74421 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -30,10 +30,10 @@
 #include <asm/machdep.h>
 #include <asm/types.h>
 
-#define IOMMU_PAGE_SHIFT      12
-#define IOMMU_PAGE_SIZE       (ASM_CONST(1) << IOMMU_PAGE_SHIFT)
-#define IOMMU_PAGE_MASK       (~((1 << IOMMU_PAGE_SHIFT) - 1))
-#define IOMMU_PAGE_ALIGN(addr) _ALIGN_UP(addr, IOMMU_PAGE_SIZE)
+#define IOMMU_PAGE_SHIFT_4K      12
+#define IOMMU_PAGE_SIZE_4K       (ASM_CONST(1) << IOMMU_PAGE_SHIFT_4K)
+#define IOMMU_PAGE_MASK_4K       (~((1 << IOMMU_PAGE_SHIFT_4K) - 1))
+#define IOMMU_PAGE_ALIGN_4K(addr) _ALIGN_UP(addr, IOMMU_PAGE_SIZE_4K)
 
 /* Boot time flags */
 extern int iommu_is_off;
@@ -42,7 +42,7 @@ extern int iommu_force_on;
 /* Pure 2^n version of get_order */
 static __inline__ __attribute_const__ int get_iommu_order(unsigned long size)
 {
-	return __ilog2((size - 1) >> IOMMU_PAGE_SHIFT) + 1;
+	return __ilog2((size - 1) >> IOMMU_PAGE_SHIFT_4K) + 1;
 }
 
 

commit d905c5df9aef38d63df268f6f5e7b13894f626d3
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Thu Nov 21 17:43:14 2013 +1100

    PPC: POWERNV: move iommu_add_device earlier
    
    The current implementation of IOMMU on sPAPR does not use iommu_ops
    and therefore does not call IOMMU API's bus_set_iommu() which
    1) sets iommu_ops for a bus
    2) registers a bus notifier
    Instead, PCI devices are added to IOMMU groups from
    subsys_initcall_sync(tce_iommu_init) which does basically the same
    thing without using iommu_ops callbacks.
    
    However Freescale PAMU driver (https://lkml.org/lkml/2013/7/1/158)
    implements iommu_ops and when tce_iommu_init is called, every PCI device
    is already added to some group so there is a conflict.
    
    This patch does 2 things:
    1. removes the loop in which PCI devices were added to groups and
    adds explicit iommu_add_device() calls to add devices as soon as they get
    the iommu_table pointer assigned to them.
    2. moves a bus notifier to powernv code in order to avoid conflict with
    the notifier from Freescale driver.
    
    iommu_add_device() and iommu_del_device() are public now.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index c34656a8925e..774fa2776907 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -101,8 +101,34 @@ extern void iommu_free_table(struct iommu_table *tbl, const char *node_name);
  */
 extern struct iommu_table *iommu_init_table(struct iommu_table * tbl,
 					    int nid);
+#ifdef CONFIG_IOMMU_API
 extern void iommu_register_group(struct iommu_table *tbl,
 				 int pci_domain_number, unsigned long pe_num);
+extern int iommu_add_device(struct device *dev);
+extern void iommu_del_device(struct device *dev);
+#else
+static inline void iommu_register_group(struct iommu_table *tbl,
+					int pci_domain_number,
+					unsigned long pe_num)
+{
+}
+
+static inline int iommu_add_device(struct device *dev)
+{
+	return 0;
+}
+
+static inline void iommu_del_device(struct device *dev)
+{
+}
+#endif /* !CONFIG_IOMMU_API */
+
+static inline void set_iommu_table_base_and_group(struct device *dev,
+						  void *base)
+{
+	set_iommu_table_base(dev, base);
+	iommu_add_device(dev);
+}
 
 extern int iommu_map_sg(struct device *dev, struct iommu_table *tbl,
 			struct scatterlist *sglist, int nelems,

commit 5524f3fc069b6435f9ff0db573e3a8b5082ef528
Author: Bjorn Helgaas <bhelgaas@google.com>
Date:   Tue Jun 11 13:57:05 2013 -0600

    powerpc/iommu: Remove unused pci_iommu_init() and pci_direct_iommu_init()
    
    pci_iommu_init() and pci_direct_iommu_init() are not referenced anywhere,
    so remove them.
    
    Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 98d14229f893..c34656a8925e 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -130,13 +130,6 @@ extern void iommu_init_early_pSeries(void);
 extern void iommu_init_early_dart(void);
 extern void iommu_init_early_pasemi(void);
 
-#ifdef CONFIG_PCI
-extern void pci_iommu_init(void);
-extern void pci_direct_iommu_init(void);
-#else
-static inline void pci_iommu_init(void) { }
-#endif
-
 extern void alloc_dart_table(void);
 #if defined(CONFIG_PPC64) && defined(CONFIG_PM)
 static inline void iommu_save(void)

commit 4e13c1ac6baa1d6c2b650d66ca89e1e12727ec19
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Tue May 21 13:33:09 2013 +1000

    powerpc/vfio: Enable on PowerNV platform
    
    This initializes IOMMU groups based on the IOMMU configuration
    discovered during the PCI scan on POWERNV (POWER non virtualized)
    platform.  The IOMMU groups are to be used later by the VFIO driver,
    which is used for PCI pass through.
    
    It also implements an API for mapping/unmapping pages for
    guest PCI drivers and providing DMA window properties.
    This API is going to be used later by QEMU-VFIO to handle
    h_put_tce hypercalls from the KVM guest.
    
    The iommu_put_tce_user_mode() does only a single page mapping
    as an API for adding many mappings at once is going to be
    added later.
    
    Although this driver has been tested only on the POWERNV
    platform, it should work on any platform which supports
    TCE tables.  As h_put_tce hypercall is received by the host
    kernel and processed by the QEMU (what involves calling
    the host kernel again), performance is not the best -
    circa 220MB/s on 10Gb ethernet network.
    
    To enable VFIO on POWER, enable SPAPR_TCE_IOMMU config
    option and configure VFIO as required.
    
    Cc: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index cbfe678e3dbe..98d14229f893 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -76,6 +76,9 @@ struct iommu_table {
 	struct iommu_pool large_pool;
 	struct iommu_pool pools[IOMMU_NR_POOLS];
 	unsigned long *it_map;       /* A simple allocation bitmap for now */
+#ifdef CONFIG_IOMMU_API
+	struct iommu_group *it_group;
+#endif
 };
 
 struct scatterlist;
@@ -98,6 +101,8 @@ extern void iommu_free_table(struct iommu_table *tbl, const char *node_name);
  */
 extern struct iommu_table *iommu_init_table(struct iommu_table * tbl,
 					    int nid);
+extern void iommu_register_group(struct iommu_table *tbl,
+				 int pci_domain_number, unsigned long pe_num);
 
 extern int iommu_map_sg(struct device *dev, struct iommu_table *tbl,
 			struct scatterlist *sglist, int nelems,
@@ -147,5 +152,26 @@ static inline void iommu_restore(void)
 }
 #endif
 
+/* The API to support IOMMU operations for VFIO */
+extern int iommu_tce_clear_param_check(struct iommu_table *tbl,
+		unsigned long ioba, unsigned long tce_value,
+		unsigned long npages);
+extern int iommu_tce_put_param_check(struct iommu_table *tbl,
+		unsigned long ioba, unsigned long tce);
+extern int iommu_tce_build(struct iommu_table *tbl, unsigned long entry,
+		unsigned long hwaddr, enum dma_data_direction direction);
+extern unsigned long iommu_clear_tce(struct iommu_table *tbl,
+		unsigned long entry);
+extern int iommu_clear_tces_and_put_pages(struct iommu_table *tbl,
+		unsigned long entry, unsigned long pages);
+extern int iommu_put_tce_user_mode(struct iommu_table *tbl,
+		unsigned long entry, unsigned long tce);
+
+extern void iommu_flush_tce(struct iommu_table *tbl);
+extern int iommu_take_ownership(struct iommu_table *tbl);
+extern void iommu_release_ownership(struct iommu_table *tbl);
+
+extern enum dma_data_direction iommu_tce_direction(unsigned long tce);
+
 #endif /* __KERNEL__ */
 #endif /* _ASM_IOMMU_H */

commit b4c3a8729ae57b4f84d661e16a192f828eca1d03
Author: Anton Blanchard <anton@samba.org>
Date:   Thu Jun 7 18:14:48 2012 +0000

    powerpc/iommu: Implement IOMMU pools to improve multiqueue adapter performance
    
    At the moment all queues in a multiqueue adapter will serialise
    against the IOMMU table lock. This is proving to be a big issue,
    especially with 10Gbit ethernet.
    
    This patch creates 4 pools and tries to spread the load across
    them. If the table is under 1GB in size we revert back to the
    original behaviour of 1 pool and 1 largealloc pool.
    
    We create a hash to map CPUs to pools. Since we prefer interrupts to
    be affinitised to primary CPUs, without some form of hashing we are
    very likely to end up using the same pool. As an example, POWER7
    has 4 way SMT and with 4 pools all primary threads will map to the
    same pool.
    
    The largealloc pool is reduced from 1/2 to 1/4 of the space to
    partially offset the overhead of breaking the table up into pools.
    
    Some performance numbers were obtained with a Chelsio T3 adapter on
    two POWER7 boxes, running a 100 session TCP round robin test.
    
    Performance improved 69% with this patch applied.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 957a83f43646..cbfe678e3dbe 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -53,6 +53,16 @@ static __inline__ __attribute_const__ int get_iommu_order(unsigned long size)
  */
 #define IOMAP_MAX_ORDER		13
 
+#define IOMMU_POOL_HASHBITS	2
+#define IOMMU_NR_POOLS		(1 << IOMMU_POOL_HASHBITS)
+
+struct iommu_pool {
+	unsigned long start;
+	unsigned long end;
+	unsigned long hint;
+	spinlock_t lock;
+} ____cacheline_aligned_in_smp;
+
 struct iommu_table {
 	unsigned long  it_busno;     /* Bus number this table belongs to */
 	unsigned long  it_size;      /* Size of iommu table in entries */
@@ -61,10 +71,10 @@ struct iommu_table {
 	unsigned long  it_index;     /* which iommu table this is */
 	unsigned long  it_type;      /* type: PCI or Virtual Bus */
 	unsigned long  it_blocksize; /* Entries in each block (cacheline) */
-	unsigned long  it_hint;      /* Hint for next alloc */
-	unsigned long  it_largehint; /* Hint for large allocs */
-	unsigned long  it_halfpoint; /* Breaking point for small/large allocs */
-	spinlock_t     it_lock;      /* Protects it_map */
+	unsigned long  poolsize;
+	unsigned long  nr_pools;
+	struct iommu_pool large_pool;
+	struct iommu_pool pools[IOMMU_NR_POOLS];
 	unsigned long *it_map;       /* A simple allocation bitmap for now */
 };
 

commit 1d9a47315042606b4217691bcea36cfa6ccbde66
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Wed Mar 21 18:23:27 2012 +0000

    powerpc: Random little legacy iSeries removal tidy ups
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index edfc9803ec91..957a83f43646 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -112,7 +112,6 @@ extern void iommu_unmap_page(struct iommu_table *tbl, dma_addr_t dma_handle,
 			     struct dma_attrs *attrs);
 
 extern void iommu_init_early_pSeries(void);
-extern void iommu_init_early_iSeries(void);
 extern void iommu_init_early_dart(void);
 extern void iommu_init_early_pasemi(void);
 

commit 738ef42e32fe95553a424c04016b936c9f6c9afb
Author: Becky Bruce <beckyb@kernel.crashing.org>
Date:   Mon Sep 21 08:26:35 2009 +0000

    powerpc: Change archdata dma_data to a union
    
    Sometimes this is used to hold a simple offset, and sometimes
    it is used to hold a pointer.  This patch changes it to a union containing
    void * and dma_addr_t.  get/set accessors are also provided, because it was
    getting a bit ugly to get to the actual data.
    
    Signed-off-by: Becky Bruce <beckyb@kernel.crashing.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 7464c0daddd1..edfc9803ec91 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -70,6 +70,16 @@ struct iommu_table {
 
 struct scatterlist;
 
+static inline void set_iommu_table_base(struct device *dev, void *base)
+{
+	dev->archdata.dma_data.iommu_table_base = base;
+}
+
+static inline void *get_iommu_table_base(struct device *dev)
+{
+	return dev->archdata.dma_data.iommu_table_base;
+}
+
 /* Frees table for an individual device node */
 extern void iommu_free_table(struct iommu_table *tbl, const char *node_name);
 

commit 9413c8836a16e9d034928a7f9d3ad81bebd71ce9
Author: Geert Uytterhoeven <Geert.Uytterhoeven@sonycom.com>
Date:   Wed Jul 29 02:06:42 2009 +0000

    powerpc/cell: Move CBE_IOPTE_* to <asm/cell-regs.h>
    
    As <asm/iommu.h> doesn't contain any other hardware specific definitions
    but only interfaces.
    
    Reported-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Geert Uytterhoeven <Geert.Uytterhoeven@sonycom.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 7ead7c16fb7c..7464c0daddd1 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -35,16 +35,6 @@
 #define IOMMU_PAGE_MASK       (~((1 << IOMMU_PAGE_SHIFT) - 1))
 #define IOMMU_PAGE_ALIGN(addr) _ALIGN_UP(addr, IOMMU_PAGE_SIZE)
 
-/* Cell page table entries */
-#define CBE_IOPTE_PP_W		0x8000000000000000ul /* protection: write */
-#define CBE_IOPTE_PP_R		0x4000000000000000ul /* protection: read */
-#define CBE_IOPTE_M		0x2000000000000000ul /* coherency required */
-#define CBE_IOPTE_SO_R		0x1000000000000000ul /* ordering: writes */
-#define CBE_IOPTE_SO_RW		0x1800000000000000ul /* ordering: r & w */
-#define CBE_IOPTE_RPN_Mask	0x07fffffffffff000ul /* RPN */
-#define CBE_IOPTE_H		0x0000000000000800ul /* cache hint */
-#define CBE_IOPTE_IOID_Mask	0x00000000000007fful /* ioid */
-
 /* Boot time flags */
 extern int iommu_is_off;
 extern int iommu_force_on;

commit 5c6fc8db768fb9990ee67ab052896fd46fbe2651
Author: Geert Uytterhoeven <Geert.Uytterhoeven@sonycom.com>
Date:   Wed Jun 10 04:38:45 2009 +0000

    powerpc/cell: Extract duplicated IOPTE_* to <asm/iommu.h>
    
    Both arch/powerpc/platforms/cell/iommu.c and arch/powerpc/platforms/ps3/mm.c
    contain the same Cell IOMMU page table entry definitions. Extract them and move
    them to <asm/iommu.h>, while adding a CBE_ prefix.
    This also allows them to be used by drivers.
    
    Signed-off-by: Geert Uytterhoeven <Geert.Uytterhoeven@sonycom.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 7464c0daddd1..7ead7c16fb7c 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -35,6 +35,16 @@
 #define IOMMU_PAGE_MASK       (~((1 << IOMMU_PAGE_SHIFT) - 1))
 #define IOMMU_PAGE_ALIGN(addr) _ALIGN_UP(addr, IOMMU_PAGE_SIZE)
 
+/* Cell page table entries */
+#define CBE_IOPTE_PP_W		0x8000000000000000ul /* protection: write */
+#define CBE_IOPTE_PP_R		0x4000000000000000ul /* protection: read */
+#define CBE_IOPTE_M		0x2000000000000000ul /* coherency required */
+#define CBE_IOPTE_SO_R		0x1000000000000000ul /* ordering: writes */
+#define CBE_IOPTE_SO_RW		0x1800000000000000ul /* ordering: r & w */
+#define CBE_IOPTE_RPN_Mask	0x07fffffffffff000ul /* RPN */
+#define CBE_IOPTE_H		0x0000000000000800ul /* cache hint */
+#define CBE_IOPTE_IOID_Mask	0x00000000000007fful /* ioid */
+
 /* Boot time flags */
 extern int iommu_is_off;
 extern int iommu_force_on;

commit f9226d572d2f8b5f564596db8c6a13e458c46191
Author: Mark Nelson <markn@au1.ibm.com>
Date:   Mon Oct 27 20:38:08 2008 +0000

    powerpc: Update remaining dma_mapping_ops to use map/unmap_page
    
    After the merge of the 32 and 64bit DMA code, dma_direct_ops lost
    their map/unmap_single() functions but gained map/unmap_page().  This
    caused a problem for Cell because Cell's dma_iommu_fixed_ops called
    the dma_direct_ops if the fixed linear mapping was to be used or the
    iommu ops if the dynamic window was to be used.  So in order to fix
    this problem we need to update the 64bit DMA code to use
    map/unmap_page.
    
    First, we update the generic IOMMU code so that iommu_map_single()
    becomes iommu_map_page() and iommu_unmap_single() becomes
    iommu_unmap_page().  Then we propagate these changes up through all
    the callers of these two functions and in the process update all the
    dma_mapping_ops so that they have map/unmap_page rahter than
    map/unmap_single.  We can do this because on 64bit there is no HIGHMEM
    memory so map/unmap_page ends up performing exactly the same function
    as map/unmap_single, just taking different arguments.
    
    This has no affect on drivers because the dma_map_single_attrs() just
    ends up calling the map_page() function of the appropriate
    dma_mapping_ops and similarly the dma_unmap_single_attrs() calls
    unmap_page().
    
    This fixes an oops on Cell blades, which oops on boot without this
    because they call dma_direct_ops.map_single, which is NULL.
    
    Signed-off-by: Mark Nelson <markn@au1.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
index 51ecfef8d843..7464c0daddd1 100644
--- a/arch/powerpc/include/asm/iommu.h
+++ b/arch/powerpc/include/asm/iommu.h
@@ -92,13 +92,14 @@ extern void *iommu_alloc_coherent(struct device *dev, struct iommu_table *tbl,
 				  unsigned long mask, gfp_t flag, int node);
 extern void iommu_free_coherent(struct iommu_table *tbl, size_t size,
 				void *vaddr, dma_addr_t dma_handle);
-extern dma_addr_t iommu_map_single(struct device *dev, struct iommu_table *tbl,
-				   void *vaddr, size_t size, unsigned long mask,
-				   enum dma_data_direction direction,
-				   struct dma_attrs *attrs);
-extern void iommu_unmap_single(struct iommu_table *tbl, dma_addr_t dma_handle,
-			       size_t size, enum dma_data_direction direction,
-			       struct dma_attrs *attrs);
+extern dma_addr_t iommu_map_page(struct device *dev, struct iommu_table *tbl,
+				 struct page *page, unsigned long offset,
+				 size_t size, unsigned long mask,
+				 enum dma_data_direction direction,
+				 struct dma_attrs *attrs);
+extern void iommu_unmap_page(struct iommu_table *tbl, dma_addr_t dma_handle,
+			     size_t size, enum dma_data_direction direction,
+			     struct dma_attrs *attrs);
 
 extern void iommu_init_early_pSeries(void);
 extern void iommu_init_early_iSeries(void);

commit b8b572e1015f81b4e748417be2629dfe51ab99f9
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Fri Aug 1 15:20:30 2008 +1000

    powerpc: Move include files to arch/powerpc/include/asm
    
    from include/asm-powerpc.  This is the result of a
    
    mkdir arch/powerpc/include/asm
    git mv include/asm-powerpc/* arch/powerpc/include/asm
    
    Followed by a few documentation/comment fixups and a couple of places
    where <asm-powepc/...> was being used explicitly.  Of the latter only
    one was outside the arch code and it is a driver only built for powerpc.
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/include/asm/iommu.h b/arch/powerpc/include/asm/iommu.h
new file mode 100644
index 000000000000..51ecfef8d843
--- /dev/null
+++ b/arch/powerpc/include/asm/iommu.h
@@ -0,0 +1,131 @@
+/*
+ * Copyright (C) 2001 Mike Corrigan & Dave Engebretsen, IBM Corporation
+ * Rewrite, cleanup:
+ * Copyright (C) 2004 Olof Johansson <olof@lixom.net>, IBM Corporation
+ * 
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ * 
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ * 
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
+ */
+
+#ifndef _ASM_IOMMU_H
+#define _ASM_IOMMU_H
+#ifdef __KERNEL__
+
+#include <linux/compiler.h>
+#include <linux/spinlock.h>
+#include <linux/device.h>
+#include <linux/dma-mapping.h>
+#include <linux/bitops.h>
+#include <asm/machdep.h>
+#include <asm/types.h>
+
+#define IOMMU_PAGE_SHIFT      12
+#define IOMMU_PAGE_SIZE       (ASM_CONST(1) << IOMMU_PAGE_SHIFT)
+#define IOMMU_PAGE_MASK       (~((1 << IOMMU_PAGE_SHIFT) - 1))
+#define IOMMU_PAGE_ALIGN(addr) _ALIGN_UP(addr, IOMMU_PAGE_SIZE)
+
+/* Boot time flags */
+extern int iommu_is_off;
+extern int iommu_force_on;
+
+/* Pure 2^n version of get_order */
+static __inline__ __attribute_const__ int get_iommu_order(unsigned long size)
+{
+	return __ilog2((size - 1) >> IOMMU_PAGE_SHIFT) + 1;
+}
+
+
+/*
+ * IOMAP_MAX_ORDER defines the largest contiguous block
+ * of dma space we can get.  IOMAP_MAX_ORDER = 13
+ * allows up to 2**12 pages (4096 * 4096) = 16 MB
+ */
+#define IOMAP_MAX_ORDER		13
+
+struct iommu_table {
+	unsigned long  it_busno;     /* Bus number this table belongs to */
+	unsigned long  it_size;      /* Size of iommu table in entries */
+	unsigned long  it_offset;    /* Offset into global table */
+	unsigned long  it_base;      /* mapped address of tce table */
+	unsigned long  it_index;     /* which iommu table this is */
+	unsigned long  it_type;      /* type: PCI or Virtual Bus */
+	unsigned long  it_blocksize; /* Entries in each block (cacheline) */
+	unsigned long  it_hint;      /* Hint for next alloc */
+	unsigned long  it_largehint; /* Hint for large allocs */
+	unsigned long  it_halfpoint; /* Breaking point for small/large allocs */
+	spinlock_t     it_lock;      /* Protects it_map */
+	unsigned long *it_map;       /* A simple allocation bitmap for now */
+};
+
+struct scatterlist;
+
+/* Frees table for an individual device node */
+extern void iommu_free_table(struct iommu_table *tbl, const char *node_name);
+
+/* Initializes an iommu_table based in values set in the passed-in
+ * structure
+ */
+extern struct iommu_table *iommu_init_table(struct iommu_table * tbl,
+					    int nid);
+
+extern int iommu_map_sg(struct device *dev, struct iommu_table *tbl,
+			struct scatterlist *sglist, int nelems,
+			unsigned long mask, enum dma_data_direction direction,
+			struct dma_attrs *attrs);
+extern void iommu_unmap_sg(struct iommu_table *tbl, struct scatterlist *sglist,
+			   int nelems, enum dma_data_direction direction,
+			   struct dma_attrs *attrs);
+
+extern void *iommu_alloc_coherent(struct device *dev, struct iommu_table *tbl,
+				  size_t size, dma_addr_t *dma_handle,
+				  unsigned long mask, gfp_t flag, int node);
+extern void iommu_free_coherent(struct iommu_table *tbl, size_t size,
+				void *vaddr, dma_addr_t dma_handle);
+extern dma_addr_t iommu_map_single(struct device *dev, struct iommu_table *tbl,
+				   void *vaddr, size_t size, unsigned long mask,
+				   enum dma_data_direction direction,
+				   struct dma_attrs *attrs);
+extern void iommu_unmap_single(struct iommu_table *tbl, dma_addr_t dma_handle,
+			       size_t size, enum dma_data_direction direction,
+			       struct dma_attrs *attrs);
+
+extern void iommu_init_early_pSeries(void);
+extern void iommu_init_early_iSeries(void);
+extern void iommu_init_early_dart(void);
+extern void iommu_init_early_pasemi(void);
+
+#ifdef CONFIG_PCI
+extern void pci_iommu_init(void);
+extern void pci_direct_iommu_init(void);
+#else
+static inline void pci_iommu_init(void) { }
+#endif
+
+extern void alloc_dart_table(void);
+#if defined(CONFIG_PPC64) && defined(CONFIG_PM)
+static inline void iommu_save(void)
+{
+	if (ppc_md.iommu_save)
+		ppc_md.iommu_save();
+}
+
+static inline void iommu_restore(void)
+{
+	if (ppc_md.iommu_restore)
+		ppc_md.iommu_restore();
+}
+#endif
+
+#endif /* __KERNEL__ */
+#endif /* _ASM_IOMMU_H */
