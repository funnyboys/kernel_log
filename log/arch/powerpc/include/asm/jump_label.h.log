commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/include/asm/jump_label.h b/arch/powerpc/include/asm/jump_label.h
index a3b2cf940b4e..09297ec9fa52 100644
--- a/arch/powerpc/include/asm/jump_label.h
+++ b/arch/powerpc/include/asm/jump_label.h
@@ -1,13 +1,9 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
 #ifndef _ASM_POWERPC_JUMP_LABEL_H
 #define _ASM_POWERPC_JUMP_LABEL_H
 
 /*
  * Copyright 2010 Michael Ellerman, IBM Corp.
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version
- * 2 of the License, or (at your option) any later version.
  */
 
 #ifndef __ASSEMBLY__

commit ec0c464cdbf38bf6ddabec8bfa595bd421cab203
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Jul 5 16:24:57 2018 +0000

    powerpc: move ASM_CONST and stringify_in_c() into asm-const.h
    
    This patch moves ASM_CONST() and stringify_in_c() into
    dedicated asm-const.h, then cleans all related inclusions.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    [mpe: asm-compat.h should include asm-const.h]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/jump_label.h b/arch/powerpc/include/asm/jump_label.h
index 9a287e0ac8b1..a3b2cf940b4e 100644
--- a/arch/powerpc/include/asm/jump_label.h
+++ b/arch/powerpc/include/asm/jump_label.h
@@ -14,7 +14,7 @@
 #include <linux/types.h>
 
 #include <asm/feature-fixups.h>
-#include <asm/asm-compat.h>
+#include <asm/asm-const.h>
 
 #define JUMP_ENTRY_TYPE		stringify_in_c(FTR_ENTRY_LONG)
 #define JUMP_LABEL_NOP_SIZE	4

commit 2cfd716d2777489db54a237f466a1c42700879c6
Merge: 755b20f49220 eea8148c69f3
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Aug 5 09:00:54 2016 -0400

    Merge tag 'powerpc-4.8-2' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull more powerpc updates from Michael Ellerman:
     "These were delayed for various reasons, so I let them sit in next a
      bit longer, rather than including them in my first pull request.
    
      Fixes:
       - Fix early access to cpu_spec relocation from Benjamin Herrenschmidt
       - Fix incorrect event codes in power9-event-list from Madhavan Srinivasan
       - Move register_process_table() out of ppc_md from Michael Ellerman
    
      Use jump_label use for [cpu|mmu]_has_feature():
       - Add mmu_early_init_devtree() from Michael Ellerman
       - Move disable_radix handling into mmu_early_init_devtree() from Michael Ellerman
       - Do hash device tree scanning earlier from Michael Ellerman
       - Do radix device tree scanning earlier from Michael Ellerman
       - Do feature patching before MMU init from Michael Ellerman
       - Check features don't change after patching from Michael Ellerman
       - Make MMU_FTR_RADIX a MMU family feature from Aneesh Kumar K.V
       - Convert mmu_has_feature() to returning bool from Michael Ellerman
       - Convert cpu_has_feature() to returning bool from Michael Ellerman
       - Define radix_enabled() in one place & use static inline from Michael Ellerman
       - Add early_[cpu|mmu]_has_feature() from Michael Ellerman
       - Convert early cpu/mmu feature check to use the new helpers from Aneesh Kumar K.V
       - jump_label: Make it possible for arches to invoke jump_label_init() earlier from Kevin Hao
       - Call jump_label_init() in apply_feature_fixups() from Aneesh Kumar K.V
       - Remove mfvtb() from Kevin Hao
       - Move cpu_has_feature() to a separate file from Kevin Hao
       - Add kconfig option to use jump labels for cpu/mmu_has_feature() from Michael Ellerman
       - Add option to use jump label for cpu_has_feature() from Kevin Hao
       - Add option to use jump label for mmu_has_feature() from Kevin Hao
       - Catch usage of cpu/mmu_has_feature() before jump label init from Aneesh Kumar K.V
       - Annotate jump label assembly from Michael Ellerman
    
      TLB flush enhancements from Aneesh Kumar K.V:
       - radix: Implement tlb mmu gather flush efficiently
       - Add helper for finding SLBE LLP encoding
       - Use hugetlb flush functions
       - Drop multiple definition of mm_is_core_local
       - radix: Add tlb flush of THP ptes
       - radix: Rename function and drop unused arg
       - radix/hugetlb: Add helper for finding page size
       - hugetlb: Add flush_hugetlb_tlb_range
       - remove flush_tlb_page_nohash
    
      Add new ptrace regsets from Anshuman Khandual and Simon Guo:
       - elf: Add powerpc specific core note sections
       - Add the function flush_tmregs_to_thread
       - Enable in transaction NT_PRFPREG ptrace requests
       - Enable in transaction NT_PPC_VMX ptrace requests
       - Enable in transaction NT_PPC_VSX ptrace requests
       - Adapt gpr32_get, gpr32_set functions for transaction
       - Enable support for NT_PPC_CGPR
       - Enable support for NT_PPC_CFPR
       - Enable support for NT_PPC_CVMX
       - Enable support for NT_PPC_CVSX
       - Enable support for TM SPR state
       - Enable NT_PPC_TM_CTAR, NT_PPC_TM_CPPR, NT_PPC_TM_CDSCR
       - Enable support for NT_PPPC_TAR, NT_PPC_PPR, NT_PPC_DSCR
       - Enable support for EBB registers
       - Enable support for Performance Monitor registers"
    
    * tag 'powerpc-4.8-2' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (48 commits)
      powerpc/mm: Move register_process_table() out of ppc_md
      powerpc/perf: Fix incorrect event codes in power9-event-list
      powerpc/32: Fix early access to cpu_spec relocation
      powerpc/ptrace: Enable support for Performance Monitor registers
      powerpc/ptrace: Enable support for EBB registers
      powerpc/ptrace: Enable support for NT_PPPC_TAR, NT_PPC_PPR, NT_PPC_DSCR
      powerpc/ptrace: Enable NT_PPC_TM_CTAR, NT_PPC_TM_CPPR, NT_PPC_TM_CDSCR
      powerpc/ptrace: Enable support for TM SPR state
      powerpc/ptrace: Enable support for NT_PPC_CVSX
      powerpc/ptrace: Enable support for NT_PPC_CVMX
      powerpc/ptrace: Enable support for NT_PPC_CFPR
      powerpc/ptrace: Enable support for NT_PPC_CGPR
      powerpc/ptrace: Adapt gpr32_get, gpr32_set functions for transaction
      powerpc/ptrace: Enable in transaction NT_PPC_VSX ptrace requests
      powerpc/ptrace: Enable in transaction NT_PPC_VMX ptrace requests
      powerpc/ptrace: Enable in transaction NT_PRFPREG ptrace requests
      powerpc/process: Add the function flush_tmregs_to_thread
      elf: Add powerpc specific core note sections
      powerpc/mm: remove flush_tlb_page_nohash
      powerpc/mm/hugetlb: Add flush_hugetlb_tlb_range
      ...

commit 5411fd7fdc8713fe17236b7a8f88b74bd8ce9f51
Author: Jason Baron <jbaron@akamai.com>
Date:   Wed Aug 3 13:46:24 2016 -0700

    powerpc: add explicit #include <asm/asm-compat.h> for jump label
    
    The stringify_in_c() macro may not be included. Make the dependency
    explicit.
    
    Link: http://lkml.kernel.org/r/564720c5328edd53c9d56db325be7215440eec3e.1467837322.git.jbaron@akamai.com
    Signed-off-by: Jason Baron <jbaron@akamai.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Joe Perches <joe@perches.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Chris Metcalf <cmetcalf@mellanox.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Joe Perches <joe@perches.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/include/asm/jump_label.h b/arch/powerpc/include/asm/jump_label.h
index 47e155f15433..9af103a23975 100644
--- a/arch/powerpc/include/asm/jump_label.h
+++ b/arch/powerpc/include/asm/jump_label.h
@@ -14,6 +14,7 @@
 #include <linux/types.h>
 
 #include <asm/feature-fixups.h>
+#include <asm/asm-compat.h>
 
 #define JUMP_ENTRY_TYPE		stringify_in_c(FTR_ENTRY_LONG)
 #define JUMP_LABEL_NOP_SIZE	4

commit e2985fd9b8de51a24fa290e06c9376a03f9a8924
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Jul 27 15:35:55 2016 +1000

    powerpc/jump_label: Annotate jump label assembly
    
    Add a comment to the generated assembler for jump labels. This makes it
    easier to identify them in asm listings (generated with $ make foo.s).
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/jump_label.h b/arch/powerpc/include/asm/jump_label.h
index 47e155f15433..9878cac7b47c 100644
--- a/arch/powerpc/include/asm/jump_label.h
+++ b/arch/powerpc/include/asm/jump_label.h
@@ -21,7 +21,7 @@
 static __always_inline bool arch_static_branch(struct static_key *key, bool branch)
 {
 	asm_volatile_goto("1:\n\t"
-		 "nop\n\t"
+		 "nop # arch_static_branch\n\t"
 		 ".pushsection __jump_table,  \"aw\"\n\t"
 		 JUMP_ENTRY_TYPE "1b, %l[l_yes], %c0\n\t"
 		 ".popsection \n\t"
@@ -35,7 +35,7 @@ static __always_inline bool arch_static_branch(struct static_key *key, bool bran
 static __always_inline bool arch_static_branch_jump(struct static_key *key, bool branch)
 {
 	asm_volatile_goto("1:\n\t"
-		 "b %l[l_yes]\n\t"
+		 "b %l[l_yes] # arch_static_branch_jump\n\t"
 		 ".pushsection __jump_table,  \"aw\"\n\t"
 		 JUMP_ENTRY_TYPE "1b, %l[l_yes], %c0\n\t"
 		 ".popsection \n\t"

commit 11276d5306b8e5b438a36bbff855fe792d7eaa61
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Jul 24 15:09:55 2015 +0200

    locking/static_keys: Add a new static_key interface
    
    There are various problems and short-comings with the current
    static_key interface:
    
     - static_key_{true,false}() read like a branch depending on the key
       value, instead of the actual likely/unlikely branch depending on
       init value.
    
     - static_key_{true,false}() are, as stated above, tied to the
       static_key init values STATIC_KEY_INIT_{TRUE,FALSE}.
    
     - we're limited to the 2 (out of 4) possible options that compile to
       a default NOP because that's what our arch_static_branch() assembly
       emits.
    
    So provide a new static_key interface:
    
      DEFINE_STATIC_KEY_TRUE(name);
      DEFINE_STATIC_KEY_FALSE(name);
    
    Which define a key of different types with an initial true/false
    value.
    
    Then allow:
    
       static_branch_likely()
       static_branch_unlikely()
    
    to take a key of either type and emit the right instruction for the
    case.
    
    This means adding a second arch_static_branch_jump() assembly helper
    which emits a JMP per default.
    
    In order to determine the right instruction for the right state,
    encode the branch type in the LSB of jump_entry::key.
    
    This is the final step in removing the naming confusion that has led to
    a stream of avoidable bugs such as:
    
      a833581e372a ("x86, perf: Fix static_key bug in load_mm_cr4()")
    
    ... but it also allows new static key combinations that will give us
    performance enhancements in the subsequent patches.
    
    Tested-by: Rabin Vincent <rabin@rab.in> # arm
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Michael Ellerman <mpe@ellerman.id.au> # ppc
    Acked-by: Heiko Carstens <heiko.carstens@de.ibm.com> # s390
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/powerpc/include/asm/jump_label.h b/arch/powerpc/include/asm/jump_label.h
index efbf9a322a23..47e155f15433 100644
--- a/arch/powerpc/include/asm/jump_label.h
+++ b/arch/powerpc/include/asm/jump_label.h
@@ -18,14 +18,29 @@
 #define JUMP_ENTRY_TYPE		stringify_in_c(FTR_ENTRY_LONG)
 #define JUMP_LABEL_NOP_SIZE	4
 
-static __always_inline bool arch_static_branch(struct static_key *key)
+static __always_inline bool arch_static_branch(struct static_key *key, bool branch)
 {
 	asm_volatile_goto("1:\n\t"
 		 "nop\n\t"
 		 ".pushsection __jump_table,  \"aw\"\n\t"
 		 JUMP_ENTRY_TYPE "1b, %l[l_yes], %c0\n\t"
 		 ".popsection \n\t"
-		 : :  "i" (key) : : l_yes);
+		 : :  "i" (&((char *)key)[branch]) : : l_yes);
+
+	return false;
+l_yes:
+	return true;
+}
+
+static __always_inline bool arch_static_branch_jump(struct static_key *key, bool branch)
+{
+	asm_volatile_goto("1:\n\t"
+		 "b %l[l_yes]\n\t"
+		 ".pushsection __jump_table,  \"aw\"\n\t"
+		 JUMP_ENTRY_TYPE "1b, %l[l_yes], %c0\n\t"
+		 ".popsection \n\t"
+		 : :  "i" (&((char *)key)[branch]) : : l_yes);
+
 	return false;
 l_yes:
 	return true;

commit cc1adb5f32557f10f48e8febbef7278a2db9d593
Author: Anton Blanchard <anton@samba.org>
Date:   Thu Jul 3 15:52:03 2014 +1000

    powerpc/pseries: Use jump labels for hcall tracepoints
    
    hcall tracepoints add quite a few instructions to our hcall path:
    
    plpar_hcall:
            mr      r2,r2
            mfcr    r0
            stw     r0,8(r1)
            b       164             <---- start
            ld      r12,0(r2)
            std     r12,32(r1)
            cmpdi   r12,0
            beq     164             <---- end
    ...
    
    We have an unconditional branch that gets noped out during boot and
    a load/compare/branch. We also store the tracepoint value to the
    stack for the hcall_exit path to use.
    
    By using jump labels we can simplify this to just a single nop that
    gets replaced with a branch when the tracepoint is enabled:
    
    plpar_hcall:
            mr      r2,r2
            mfcr    r0
            stw     r0,8(r1)
            nop                     <----
    ...
    
    If jump labels are not enabled, we fall back to the old method.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/jump_label.h b/arch/powerpc/include/asm/jump_label.h
index f016bb699b5f..efbf9a322a23 100644
--- a/arch/powerpc/include/asm/jump_label.h
+++ b/arch/powerpc/include/asm/jump_label.h
@@ -10,6 +10,7 @@
  * 2 of the License, or (at your option) any later version.
  */
 
+#ifndef __ASSEMBLY__
 #include <linux/types.h>
 
 #include <asm/feature-fixups.h>
@@ -42,4 +43,12 @@ struct jump_entry {
 	jump_label_t key;
 };
 
+#else
+#define ARCH_STATIC_BRANCH(LABEL, KEY)		\
+1098:	nop;					\
+	.pushsection __jump_table, "aw";	\
+	FTR_ENTRY_LONG 1098b, LABEL, KEY;	\
+	.popsection
+#endif
+
 #endif /* _ASM_POWERPC_JUMP_LABEL_H */

commit 3f0116c3238a96bc18ad4b4acefe4e7be32fa861
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Oct 10 10:16:30 2013 +0200

    compiler/gcc4: Add quirk for 'asm goto' miscompilation bug
    
    Fengguang Wu, Oleg Nesterov and Peter Zijlstra tracked down
    a kernel crash to a GCC bug: GCC miscompiles certain 'asm goto'
    constructs, as outlined here:
    
      http://gcc.gnu.org/bugzilla/show_bug.cgi?id=58670
    
    Implement a workaround suggested by Jakub Jelinek.
    
    Reported-and-tested-by: Fengguang Wu <fengguang.wu@intel.com>
    Reported-by: Oleg Nesterov <oleg@redhat.com>
    Reported-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Suggested-by: Jakub Jelinek <jakub@redhat.com>
    Reviewed-by: Richard Henderson <rth@twiddle.net>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: <stable@kernel.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

diff --git a/arch/powerpc/include/asm/jump_label.h b/arch/powerpc/include/asm/jump_label.h
index ae098c438f00..f016bb699b5f 100644
--- a/arch/powerpc/include/asm/jump_label.h
+++ b/arch/powerpc/include/asm/jump_label.h
@@ -19,7 +19,7 @@
 
 static __always_inline bool arch_static_branch(struct static_key *key)
 {
-	asm goto("1:\n\t"
+	asm_volatile_goto("1:\n\t"
 		 "nop\n\t"
 		 ".pushsection __jump_table,  \"aw\"\n\t"
 		 JUMP_ENTRY_TYPE "1b, %l[l_yes], %c0\n\t"

commit c5905afb0ee6550b42c49213da1c22d67316c194
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Feb 24 08:31:31 2012 +0100

    static keys: Introduce 'struct static_key', static_key_true()/false() and static_key_slow_[inc|dec]()
    
    So here's a boot tested patch on top of Jason's series that does
    all the cleanups I talked about and turns jump labels into a
    more intuitive to use facility. It should also address the
    various misconceptions and confusions that surround jump labels.
    
    Typical usage scenarios:
    
            #include <linux/static_key.h>
    
            struct static_key key = STATIC_KEY_INIT_TRUE;
    
            if (static_key_false(&key))
                    do unlikely code
            else
                    do likely code
    
    Or:
    
            if (static_key_true(&key))
                    do likely code
            else
                    do unlikely code
    
    The static key is modified via:
    
            static_key_slow_inc(&key);
            ...
            static_key_slow_dec(&key);
    
    The 'slow' prefix makes it abundantly clear that this is an
    expensive operation.
    
    I've updated all in-kernel code to use this everywhere. Note
    that I (intentionally) have not pushed through the rename
    blindly through to the lowest levels: the actual jump-label
    patching arch facility should be named like that, so we want to
    decouple jump labels from the static-key facility a bit.
    
    On non-jump-label enabled architectures static keys default to
    likely()/unlikely() branches.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Acked-by: Jason Baron <jbaron@redhat.com>
    Acked-by: Steven Rostedt <rostedt@goodmis.org>
    Cc: a.p.zijlstra@chello.nl
    Cc: mathieu.desnoyers@efficios.com
    Cc: davem@davemloft.net
    Cc: ddaney.cavm@gmail.com
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Link: http://lkml.kernel.org/r/20120222085809.GA26397@elte.hu
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/powerpc/include/asm/jump_label.h b/arch/powerpc/include/asm/jump_label.h
index 938986e412f1..ae098c438f00 100644
--- a/arch/powerpc/include/asm/jump_label.h
+++ b/arch/powerpc/include/asm/jump_label.h
@@ -17,7 +17,7 @@
 #define JUMP_ENTRY_TYPE		stringify_in_c(FTR_ENTRY_LONG)
 #define JUMP_LABEL_NOP_SIZE	4
 
-static __always_inline bool arch_static_branch(struct jump_label_key *key)
+static __always_inline bool arch_static_branch(struct static_key *key)
 {
 	asm goto("1:\n\t"
 		 "nop\n\t"

commit c113a3aee2b68e311f2bc55f70fe56b64c3a476b
Author: Anton Blanchard <anton@samba.org>
Date:   Tue Jul 26 14:35:46 2011 +0000

    powerpc: Jump label misalignment causes oops at boot
    
    I hit an oops at boot on the first instruction of timer_cpu_notify:
    
    NIP [c000000000722f88] .timer_cpu_notify+0x0/0x388
    
    The code should look like:
    
    c000000000722f78:       eb e9 00 30     ld      r31,48(r9)
    c000000000722f7c:       2f bf 00 00     cmpdi   cr7,r31,0
    c000000000722f80:       40 9e ff 44     bne+    cr7,c000000000722ec4
    c000000000722f84:       4b ff ff 74     b       c000000000722ef8
    
    c000000000722f88 <.timer_cpu_notify>:
    c000000000722f88:       7c 08 02 a6     mflr    r0
    c000000000722f8c:       2f a4 00 07     cmpdi   cr7,r4,7
    c000000000722f90:       fb c1 ff f0     std     r30,-16(r1)
    c000000000722f94:       fb 61 ff d8     std     r27,-40(r1)
    
    But the oops output shows:
    
    eb61ffd8 eb81ffe0 eba1ffe8 ebc1fff0 7c0803a6 ebe1fff8 4e800020
    00000000 ebe90030 c0000000 00ad0a28 00000000 2fa40007 fbc1fff0 fb61ffd8
    
    So we scribbled over our instructions with c000000000ad0a28, which
    is an address inside the jump_table ELF section.
    
    It turns out the jump_table section is only aligned to 8 bytes but
    we are aligning our entries within the section to 16 bytes. This
    means our entries are offset from the table:
    
    c000000000acd4a8 <__start___jump_table>:
            ...
    c000000000ad0a10:       c0 00 00 00     lfs     f0,0(0)
    c000000000ad0a14:       00 70 cd 5c     .long 0x70cd5c
    c000000000ad0a18:       c0 00 00 00     lfs     f0,0(0)
    c000000000ad0a1c:       00 70 cd 90     .long 0x70cd90
    c000000000ad0a20:       c0 00 00 00     lfs     f0,0(0)
    c000000000ad0a24:       00 ac a4 20     .long 0xaca420
    
    And the jump table sort code gets very confused and writes into the
    wrong spot. Remove the alignment, and also remove the padding since
    we it saves some space and we shouldn't need it.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/jump_label.h b/arch/powerpc/include/asm/jump_label.h
index 1f780b95c0f0..938986e412f1 100644
--- a/arch/powerpc/include/asm/jump_label.h
+++ b/arch/powerpc/include/asm/jump_label.h
@@ -22,7 +22,6 @@ static __always_inline bool arch_static_branch(struct jump_label_key *key)
 	asm goto("1:\n\t"
 		 "nop\n\t"
 		 ".pushsection __jump_table,  \"aw\"\n\t"
-		 ".align 4\n\t"
 		 JUMP_ENTRY_TYPE "1b, %l[l_yes], %c0\n\t"
 		 ".popsection \n\t"
 		 : :  "i" (key) : : l_yes);
@@ -41,7 +40,6 @@ struct jump_entry {
 	jump_label_t code;
 	jump_label_t target;
 	jump_label_t key;
-	jump_label_t pad;
 };
 
 #endif /* _ASM_POWERPC_JUMP_LABEL_H */

commit ac5f89c7d87f6f2fb7073723fc943488d9c3479d
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Wed Jun 29 19:16:59 2011 +0000

    powerpc: Add jump label support
    
    This patch adds support for the new "jump label" feature.
    
    Unlike x86 and sparc we just merrily patch the code with no locks etc,
    as far as I know this is safe, but I'm not really sure what the x86/sparc
    code is protecting against so maybe it's not.
    
    I also don't see any reason for us to implement the poke_early() routine,
    even though sparc does.
    
    [BenH: Updated the patch to upstream generic changes]
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/jump_label.h b/arch/powerpc/include/asm/jump_label.h
new file mode 100644
index 000000000000..1f780b95c0f0
--- /dev/null
+++ b/arch/powerpc/include/asm/jump_label.h
@@ -0,0 +1,47 @@
+#ifndef _ASM_POWERPC_JUMP_LABEL_H
+#define _ASM_POWERPC_JUMP_LABEL_H
+
+/*
+ * Copyright 2010 Michael Ellerman, IBM Corp.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+#include <linux/types.h>
+
+#include <asm/feature-fixups.h>
+
+#define JUMP_ENTRY_TYPE		stringify_in_c(FTR_ENTRY_LONG)
+#define JUMP_LABEL_NOP_SIZE	4
+
+static __always_inline bool arch_static_branch(struct jump_label_key *key)
+{
+	asm goto("1:\n\t"
+		 "nop\n\t"
+		 ".pushsection __jump_table,  \"aw\"\n\t"
+		 ".align 4\n\t"
+		 JUMP_ENTRY_TYPE "1b, %l[l_yes], %c0\n\t"
+		 ".popsection \n\t"
+		 : :  "i" (key) : : l_yes);
+	return false;
+l_yes:
+	return true;
+}
+
+#ifdef CONFIG_PPC64
+typedef u64 jump_label_t;
+#else
+typedef u32 jump_label_t;
+#endif
+
+struct jump_entry {
+	jump_label_t code;
+	jump_label_t target;
+	jump_label_t key;
+	jump_label_t pad;
+};
+
+#endif /* _ASM_POWERPC_JUMP_LABEL_H */
