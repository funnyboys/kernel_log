commit 74c6881019b7d56c327fffc268d97adb5eb1b4f9
Author: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
Date:   Thu May 14 16:47:38 2020 +0530

    powerpc/watchpoint: Prepare handler to handle more than one watchpoint
    
    Currently we assume that we have only one watchpoint supported by hw.
    Get rid of that assumption and use dynamic loop instead. This should
    make supporting more watchpoints very easy.
    
    With more than one watchpoint, exception handler needs to know which
    DAWR caused the exception, and hw currently does not provide it. So
    we need sw logic for the same. To figure out which DAWR caused the
    exception, check all different combinations of user specified range,
    DAWR address range, actual access range and DAWRX constrains. For ex,
    if user specified range and actual access range overlaps but DAWRX is
    configured for readonly watchpoint and the instruction is store, this
    DAWR must not have caused exception.
    
    Signed-off-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Reviewed-by: Michael Neuling <mikey@neuling.org>
    [mpe: Unsplit multi-line printk() strings, fix some sparse warnings]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200514111741.97993-14-ravi.bangoria@linux.ibm.com

diff --git a/arch/powerpc/include/asm/sstep.h b/arch/powerpc/include/asm/sstep.h
index 9b200a5f8794..3b01c69a44aa 100644
--- a/arch/powerpc/include/asm/sstep.h
+++ b/arch/powerpc/include/asm/sstep.h
@@ -49,6 +49,8 @@ enum instruction_type {
 
 #define INSTR_TYPE_MASK	0x1f
 
+#define OP_IS_LOAD(type)	((LOAD <= (type) && (type) <= LOAD_VSX) || (type) == LARX)
+#define OP_IS_STORE(type)	((STORE <= (type) && (type) <= STORE_VSX) || (type) == STCX)
 #define OP_IS_LOAD_STORE(type)	(LOAD <= (type) && (type) <= STCX)
 
 /* Compute flags, ORed in with type */

commit 50b80a12e4ccff46d53b93754d817acd98bc9ae0
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:49 2020 +1000

    powerpc sstep: Add support for prefixed load/stores
    
    This adds emulation support for the following prefixed integer
    load/stores:
      * Prefixed Load Byte and Zero (plbz)
      * Prefixed Load Halfword and Zero (plhz)
      * Prefixed Load Halfword Algebraic (plha)
      * Prefixed Load Word and Zero (plwz)
      * Prefixed Load Word Algebraic (plwa)
      * Prefixed Load Doubleword (pld)
      * Prefixed Store Byte (pstb)
      * Prefixed Store Halfword (psth)
      * Prefixed Store Word (pstw)
      * Prefixed Store Doubleword (pstd)
      * Prefixed Load Quadword (plq)
      * Prefixed Store Quadword (pstq)
    
    the follow prefixed floating-point load/stores:
      * Prefixed Load Floating-Point Single (plfs)
      * Prefixed Load Floating-Point Double (plfd)
      * Prefixed Store Floating-Point Single (pstfs)
      * Prefixed Store Floating-Point Double (pstfd)
    
    and for the following prefixed VSX load/stores:
      * Prefixed Load VSX Scalar Doubleword (plxsd)
      * Prefixed Load VSX Scalar Single-Precision (plxssp)
      * Prefixed Load VSX Vector [0|1]  (plxv, plxv0, plxv1)
      * Prefixed Store VSX Scalar Doubleword (pstxsd)
      * Prefixed Store VSX Scalar Single-Precision (pstxssp)
      * Prefixed Store VSX Vector [0|1] (pstxv, pstxv0, pstxv1)
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Reviewed-by: Balamuruhan S <bala24@linux.ibm.com>
    [mpe: Use CONFIG_PPC64 not __powerpc64__, use get_op()]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-30-jniethe5@gmail.com

diff --git a/arch/powerpc/include/asm/sstep.h b/arch/powerpc/include/asm/sstep.h
index c3ce903ac488..9b200a5f8794 100644
--- a/arch/powerpc/include/asm/sstep.h
+++ b/arch/powerpc/include/asm/sstep.h
@@ -90,11 +90,15 @@ enum instruction_type {
 #define VSX_LDLEFT	4	/* load VSX register from left */
 #define VSX_CHECK_VEC	8	/* check MSR_VEC not MSR_VSX for reg >= 32 */
 
+/* Prefixed flag, ORed in with type */
+#define PREFIXED       0x800
+
 /* Size field in type word */
 #define SIZE(n)		((n) << 12)
 #define GETSIZE(w)	((w) >> 12)
 
 #define GETTYPE(t)	((t) & INSTR_TYPE_MASK)
+#define GETLENGTH(t)   (((t) & PREFIXED) ? 8 : 4)
 
 #define MKOP(t, f, s)	((t) | (f) | SIZE(s))
 

commit 94afd069d937d84fb4f696eb9a78db4084e43d21
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:31 2020 +1000

    powerpc: Use a datatype for instructions
    
    Currently unsigned ints are used to represent instructions on powerpc.
    This has worked well as instructions have always been 4 byte words.
    
    However, ISA v3.1 introduces some changes to instructions that mean
    this scheme will no longer work as well. This change is Prefixed
    Instructions. A prefixed instruction is made up of a word prefix
    followed by a word suffix to make an 8 byte double word instruction.
    No matter the endianness of the system the prefix always comes first.
    Prefixed instructions are only planned for powerpc64.
    
    Introduce a ppc_inst type to represent both prefixed and word
    instructions on powerpc64 while keeping it possible to exclusively
    have word instructions on powerpc32.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    [mpe: Fix compile error in emulate_spe()]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-12-jniethe5@gmail.com

diff --git a/arch/powerpc/include/asm/sstep.h b/arch/powerpc/include/asm/sstep.h
index 26d729562fe2..c3ce903ac488 100644
--- a/arch/powerpc/include/asm/sstep.h
+++ b/arch/powerpc/include/asm/sstep.h
@@ -2,6 +2,7 @@
 /*
  * Copyright (C) 2004 Paul Mackerras <paulus@au.ibm.com>, IBM
  */
+#include <asm/inst.h>
 
 struct pt_regs;
 
@@ -132,7 +133,7 @@ union vsx_reg {
  * otherwise.
  */
 extern int analyse_instr(struct instruction_op *op, const struct pt_regs *regs,
-			 unsigned int instr);
+			 struct ppc_inst instr);
 
 /*
  * Emulate an instruction that can be executed just by updating
@@ -149,7 +150,7 @@ void emulate_update_regs(struct pt_regs *reg, struct instruction_op *op);
  * 0 if it could not be emulated, or -1 for an instruction that
  * should not be emulated (rfid, mtmsrd clearing MSR_RI, etc.).
  */
-extern int emulate_step(struct pt_regs *regs, unsigned int instr);
+extern int emulate_step(struct pt_regs *regs, struct ppc_inst instr);
 
 /*
  * Emulate a load or store instruction by reading/writing the

commit 777e26f0edf8dab58b8dd474d35d83bde0ac6d76
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:27 2020 +1000

    powerpc: Use an accessor for instructions
    
    In preparation for introducing a more complicated instruction type to
    accommodate prefixed instructions use an accessor for getting an
    instruction as a u32.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-8-jniethe5@gmail.com

diff --git a/arch/powerpc/include/asm/sstep.h b/arch/powerpc/include/asm/sstep.h
index 769f055509c9..26d729562fe2 100644
--- a/arch/powerpc/include/asm/sstep.h
+++ b/arch/powerpc/include/asm/sstep.h
@@ -15,9 +15,9 @@ struct pt_regs;
  * Note that IS_MTMSRD returns true for both an mtmsr (32-bit)
  * and an mtmsrd (64-bit).
  */
-#define IS_MTMSRD(instr)	(((instr) & 0xfc0007be) == 0x7c000124)
-#define IS_RFID(instr)		(((instr) & 0xfc0007fe) == 0x4c000024)
-#define IS_RFI(instr)		(((instr) & 0xfc0007fe) == 0x4c000064)
+#define IS_MTMSRD(instr)	((ppc_inst_val(instr) & 0xfc0007be) == 0x7c000124)
+#define IS_RFID(instr)		((ppc_inst_val(instr) & 0xfc0007fe) == 0x4c000024)
+#define IS_RFI(instr)		((ppc_inst_val(instr) & 0xfc0007fe) == 0x4c000064)
 
 enum instruction_type {
 	COMPUTE,		/* arith/logical/CR op, etc. */

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/include/asm/sstep.h b/arch/powerpc/include/asm/sstep.h
index 4547891a684b..769f055509c9 100644
--- a/arch/powerpc/include/asm/sstep.h
+++ b/arch/powerpc/include/asm/sstep.h
@@ -1,10 +1,6 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
 /*
  * Copyright (C) 2004 Paul Mackerras <paulus@au.ibm.com>, IBM
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version
- * 2 of the License, or (at your option) any later version.
  */
 
 struct pt_regs;

commit e6684d07e4308430b9b6497265781a6fb9fd87a0
Author: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
Date:   Mon May 21 09:51:06 2018 +0530

    powerpc/sstep: Introduce GETTYPE macro
    
    Replace 'op->type & INSTR_TYPE_MASK' expression with GETTYPE(op->type)
    macro.
    
    Signed-off-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/sstep.h b/arch/powerpc/include/asm/sstep.h
index ab9d849644d0..4547891a684b 100644
--- a/arch/powerpc/include/asm/sstep.h
+++ b/arch/powerpc/include/asm/sstep.h
@@ -97,6 +97,8 @@ enum instruction_type {
 #define SIZE(n)		((n) << 12)
 #define GETSIZE(w)	((w) >> 12)
 
+#define GETTYPE(t)	((t) & INSTR_TYPE_MASK)
+
 #define MKOP(t, f, s)	((t) | (f) | SIZE(s))
 
 struct instruction_op {

commit d2b65ac6526a82965212b632d42687251e122a36
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Wed Aug 30 16:34:09 2017 +1000

    powerpc: Emulate load/store floating point as integer word instructions
    
    This adds emulation for the lfiwax, lfiwzx and stfiwx instructions.
    This necessitated adding a new flag to indicate whether a floating
    point or an integer conversion was needed for LOAD_FP and STORE_FP,
    so this moves the size field in op->type up 4 bits.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/sstep.h b/arch/powerpc/include/asm/sstep.h
index 309d1c5de143..ab9d849644d0 100644
--- a/arch/powerpc/include/asm/sstep.h
+++ b/arch/powerpc/include/asm/sstep.h
@@ -68,6 +68,7 @@ enum instruction_type {
 #define SIGNEXT		0x20
 #define UPDATE		0x40	/* matches bit in opcode 31 instructions */
 #define BYTEREV		0x80
+#define FPCONV		0x100
 
 /* Barrier type field, ORed in with type */
 #define BARRIER_MASK	0xe0
@@ -93,8 +94,8 @@ enum instruction_type {
 #define VSX_CHECK_VEC	8	/* check MSR_VEC not MSR_VSX for reg >= 32 */
 
 /* Size field in type word */
-#define SIZE(n)		((n) << 8)
-#define GETSIZE(w)	((w) >> 8)
+#define SIZE(n)		((n) << 12)
+#define GETSIZE(w)	((w) >> 12)
 
 #define MKOP(t, f, s)	((t) | (f) | SIZE(s))
 

commit a53d5182e24c22986ad0e99e52f8fe343ee7d7ac
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Wed Aug 30 14:12:39 2017 +1000

    powerpc: Separate out load/store emulation into its own function
    
    This moves the parts of emulate_step() that deal with emulating
    load and store instructions into a new function called
    emulate_loadstore().  This is to make it possible to reuse this
    code in the alignment handler.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/sstep.h b/arch/powerpc/include/asm/sstep.h
index 958c2c55bcfe..309d1c5de143 100644
--- a/arch/powerpc/include/asm/sstep.h
+++ b/arch/powerpc/include/asm/sstep.h
@@ -152,6 +152,15 @@ void emulate_update_regs(struct pt_regs *reg, struct instruction_op *op);
  */
 extern int emulate_step(struct pt_regs *regs, unsigned int instr);
 
+/*
+ * Emulate a load or store instruction by reading/writing the
+ * memory of the current process.  FP/VMX/VSX registers are assumed
+ * to hold live values if the appropriate enable bit in regs->msr is
+ * set; otherwise this will use the saved values in the thread struct
+ * for user-mode accesses.
+ */
+extern int emulate_loadstore(struct pt_regs *regs, struct instruction_op *op);
+
 extern void emulate_vsx_load(struct instruction_op *op, union vsx_reg *reg,
 			     const void *mem, bool cross_endian);
 extern void emulate_vsx_store(struct instruction_op *op,

commit d955189ae42796621fb439e5e778ccaeebc2a1e7
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Wed Aug 30 14:12:38 2017 +1000

    powerpc: Handle opposite-endian processes in emulation code
    
    This adds code to the load and store emulation code to byte-swap
    the data appropriately when the process being emulated is set to
    the opposite endianness to that of the kernel.
    
    This also enables the emulation for the multiple-register loads
    and stores (lmw, stmw, lswi, stswi, lswx, stswx) to work for
    little-endian.  In little-endian mode, the partial word at the
    end of a transfer for lsw*/stsw* (when the byte count is not a
    multiple of 4) is loaded/stored at the least-significant end of
    the register.  Additionally, this fixes a bug in the previous
    code in that it could call read_mem/write_mem with a byte count
    that was not 1, 2, 4 or 8.
    
    Note that this only works correctly on processors with "true"
    little-endian mode, such as IBM POWER processors from POWER6 on, not
    the so-called "PowerPC" little-endian mode that uses address swizzling
    as implemented on the old 32-bit 603, 604, 740/750, 74xx CPUs.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/sstep.h b/arch/powerpc/include/asm/sstep.h
index 793639a5aa5e..958c2c55bcfe 100644
--- a/arch/powerpc/include/asm/sstep.h
+++ b/arch/powerpc/include/asm/sstep.h
@@ -153,7 +153,8 @@ void emulate_update_regs(struct pt_regs *reg, struct instruction_op *op);
 extern int emulate_step(struct pt_regs *regs, unsigned int instr);
 
 extern void emulate_vsx_load(struct instruction_op *op, union vsx_reg *reg,
-			     const void *mem);
-extern void emulate_vsx_store(struct instruction_op *op, const union vsx_reg *reg,
-			      void *mem);
+			     const void *mem, bool cross_endian);
+extern void emulate_vsx_store(struct instruction_op *op,
+			      const union vsx_reg *reg, void *mem,
+			      bool cross_endian);
 extern int emulate_dcbz(unsigned long ea, struct pt_regs *regs);

commit b2543f7b20bb2a551ed340447d7303f0ce4644f1
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Wed Aug 30 14:12:36 2017 +1000

    powerpc: Emulate the dcbz instruction
    
    This adds code to analyse_instr() and emulate_step() to understand the
    dcbz (data cache block zero) instruction.  The emulate_dcbz() function
    is made public so it can be used by the alignment handler in future.
    (The apparently unnecessary cropping of the address to 32 bits is
    there because it will be needed in that situation.)
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/sstep.h b/arch/powerpc/include/asm/sstep.h
index 474a99255689..793639a5aa5e 100644
--- a/arch/powerpc/include/asm/sstep.h
+++ b/arch/powerpc/include/asm/sstep.h
@@ -84,6 +84,7 @@ enum instruction_type {
 #define DCBTST		0x200
 #define DCBT		0x300
 #define ICBI		0x400
+#define DCBZ		0x500
 
 /* VSX flags values */
 #define VSX_FPCONV	1	/* do floating point SP/DP conversion */
@@ -155,3 +156,4 @@ extern void emulate_vsx_load(struct instruction_op *op, union vsx_reg *reg,
 			     const void *mem);
 extern void emulate_vsx_store(struct instruction_op *op, const union vsx_reg *reg,
 			      void *mem);
+extern int emulate_dcbz(unsigned long ea, struct pt_regs *regs);

commit c22435a5f3d8f85ea162ae523a6ba60a58521ba5
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Wed Aug 30 14:12:33 2017 +1000

    powerpc: Emulate FP/vector/VSX loads/stores correctly when regs not live
    
    At present, the analyse_instr/emulate_step code checks for the
    relevant MSR_FP/VEC/VSX bit being set when a FP/VMX/VSX load
    or store is decoded, but doesn't recheck the bit before reading or
    writing the relevant FP/VMX/VSX register in emulate_step().
    
    Since we don't have preemption disabled, it is possible that we get
    preempted between checking the MSR bit and doing the register access.
    If that happened, then the registers would have been saved to the
    thread_struct for the current process.  Accesses to the CPU registers
    would then potentially read stale values, or write values that would
    never be seen by the user process.
    
    Another way that the registers can become non-live is if a page
    fault occurs when accessing user memory, and the page fault code
    calls a copy routine that wants to use the VMX or VSX registers.
    
    To fix this, the code for all the FP/VMX/VSX loads gets restructured
    so that it forms an image in a local variable of the desired register
    contents, then disables preemption, checks the MSR bit and either
    sets the CPU register or writes the value to the thread struct.
    Similarly, the code for stores checks the MSR bit, copies either the
    CPU register or the thread struct to a local variable, then reenables
    preemption and then copies the register image to memory.
    
    If the instruction being emulated is in the kernel, then we must not
    use the register values in the thread_struct.  In this case, if the
    relevant MSR enable bit is not set, then emulate_step refuses to
    emulate the instruction.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/sstep.h b/arch/powerpc/include/asm/sstep.h
index 4fcc2c9a6ed5..474a99255689 100644
--- a/arch/powerpc/include/asm/sstep.h
+++ b/arch/powerpc/include/asm/sstep.h
@@ -119,6 +119,7 @@ union vsx_reg {
 	unsigned long d[2];
 	float	fp[4];
 	double	dp[2];
+	__vector128 v;
 };
 
 /*

commit d120cdbce68c3739f94f733bec376460fb9cbc14
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Wed Aug 30 14:12:28 2017 +1000

    powerpc/64: Fix update forms of loads and stores to write 64-bit EA
    
    When a 64-bit processor is executing in 32-bit mode, the update forms
    of load and store instructions are required by the architecture to
    write the full 64-bit effective address into the RA register, though
    only the bottom 32 bits are used to address memory.  Currently,
    the instruction emulation code writes the truncated address to the
    RA register.  This fixes it by keeping the full 64-bit EA in the
    instruction_op structure, truncating the address in emulate_step()
    where it is used to address memory, rather than in the address
    computations in analyse_instr().
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/sstep.h b/arch/powerpc/include/asm/sstep.h
index 980197024c0b..4fcc2c9a6ed5 100644
--- a/arch/powerpc/include/asm/sstep.h
+++ b/arch/powerpc/include/asm/sstep.h
@@ -25,7 +25,7 @@ struct pt_regs;
 
 enum instruction_type {
 	COMPUTE,		/* arith/logical/CR op, etc. */
-	LOAD,
+	LOAD,			/* load and store types need to be contiguous */
 	LOAD_MULTI,
 	LOAD_FP,
 	LOAD_VMX,
@@ -52,6 +52,8 @@ enum instruction_type {
 
 #define INSTR_TYPE_MASK	0x1f
 
+#define OP_IS_LOAD_STORE(type)	(LOAD <= (type) && (type) <= STCX)
+
 /* Compute flags, ORed in with type */
 #define SETREG		0x20
 #define SETCC		0x40

commit 350779a29f11f80ac66a8b38a7718ad30f003f18
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Wed Aug 30 14:12:27 2017 +1000

    powerpc: Handle most loads and stores in instruction emulation code
    
    This extends the instruction emulation infrastructure in sstep.c to
    handle all the load and store instructions defined in the Power ISA
    v3.0, except for the atomic memory operations, ldmx (which was never
    implemented), lfdp/stfdp, and the vector element load/stores.
    
    The instructions added are:
    
    Integer loads and stores: lbarx, lharx, lqarx, stbcx., sthcx., stqcx.,
    lq, stq.
    
    VSX loads and stores: lxsiwzx, lxsiwax, stxsiwx, lxvx, lxvl, lxvll,
    lxvdsx, lxvwsx, stxvx, stxvl, stxvll, lxsspx, lxsdx, stxsspx, stxsdx,
    lxvw4x, lxsibzx, lxvh8x, lxsihzx, lxvb16x, stxvw4x, stxsibx, stxvh8x,
    stxsihx, stxvb16x, lxsd, lxssp, lxv, stxsd, stxssp, stxv.
    
    These instructions are handled both in the analyse_instr phase and in
    the emulate_step phase.
    
    The code for lxvd2ux and stxvd2ux has been taken out, as those
    instructions were never implemented in any processor and have been
    taken out of the architecture, and their opcodes have been reused for
    other instructions in POWER9 (lxvb16x and stxvb16x).
    
    The emulation for the VSX loads and stores uses helper functions
    which don't access registers or memory directly, which can hopefully
    be reused by KVM later.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/sstep.h b/arch/powerpc/include/asm/sstep.h
index 442e6363eb5a..980197024c0b 100644
--- a/arch/powerpc/include/asm/sstep.h
+++ b/arch/powerpc/include/asm/sstep.h
@@ -83,6 +83,12 @@ enum instruction_type {
 #define DCBT		0x300
 #define ICBI		0x400
 
+/* VSX flags values */
+#define VSX_FPCONV	1	/* do floating point SP/DP conversion */
+#define VSX_SPLAT	2	/* store loaded value into all elements */
+#define VSX_LDLEFT	4	/* load VSX register from left */
+#define VSX_CHECK_VEC	8	/* check MSR_VEC not MSR_VSX for reg >= 32 */
+
 /* Size field in type word */
 #define SIZE(n)		((n) << 8)
 #define GETSIZE(w)	((w) >> 8)
@@ -100,6 +106,17 @@ struct instruction_op {
 	int spr;
 	u32 ccval;
 	u32 xerval;
+	u8 element_size;	/* for VSX/VMX loads/stores */
+	u8 vsx_flags;
+};
+
+union vsx_reg {
+	u8	b[16];
+	u16	h[8];
+	u32	w[4];
+	unsigned long d[2];
+	float	fp[4];
+	double	dp[2];
 };
 
 /*
@@ -131,3 +148,7 @@ void emulate_update_regs(struct pt_regs *reg, struct instruction_op *op);
  */
 extern int emulate_step(struct pt_regs *regs, unsigned int instr);
 
+extern void emulate_vsx_load(struct instruction_op *op, union vsx_reg *reg,
+			     const void *mem);
+extern void emulate_vsx_store(struct instruction_op *op, const union vsx_reg *reg,
+			      void *mem);

commit 3cdfcbfd32b9d1c0d4a6fa80ee9c390927aab948
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Wed Aug 30 14:12:25 2017 +1000

    powerpc: Change analyse_instr so it doesn't modify *regs
    
    The analyse_instr function currently doesn't just work out what an
    instruction does, it also executes those instructions whose effect
    is only to update CPU registers that are stored in struct pt_regs.
    This is undesirable because optprobes uses analyse_instr to work out
    if an instruction could be successfully emulated in future.
    
    This changes analyse_instr so it doesn't modify *regs; instead it
    stores information in the instruction_op structure to indicate what
    registers (GPRs, CR, XER, LR) would be set and what value they would
    be set to.  A companion function called emulate_update_regs() can
    then use that information to update a pt_regs struct appropriately.
    
    As a minor cleanup, this replaces inline asm using the cntlzw and
    cntlzd instructions with calls to __builtin_clz() and __builtin_clzl().
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/sstep.h b/arch/powerpc/include/asm/sstep.h
index d3a42cc45a82..442e6363eb5a 100644
--- a/arch/powerpc/include/asm/sstep.h
+++ b/arch/powerpc/include/asm/sstep.h
@@ -23,9 +23,6 @@ struct pt_regs;
 #define IS_RFID(instr)		(((instr) & 0xfc0007fe) == 0x4c000024)
 #define IS_RFI(instr)		(((instr) & 0xfc0007fe) == 0x4c000064)
 
-/* Emulate instructions that cause a transfer of control. */
-extern int emulate_step(struct pt_regs *regs, unsigned int instr);
-
 enum instruction_type {
 	COMPUTE,		/* arith/logical/CR op, etc. */
 	LOAD,
@@ -55,11 +52,29 @@ enum instruction_type {
 
 #define INSTR_TYPE_MASK	0x1f
 
+/* Compute flags, ORed in with type */
+#define SETREG		0x20
+#define SETCC		0x40
+#define SETXER		0x80
+
+/* Branch flags, ORed in with type */
+#define SETLK		0x20
+#define BRTAKEN		0x40
+#define DECCTR		0x80
+
 /* Load/store flags, ORed in with type */
 #define SIGNEXT		0x20
 #define UPDATE		0x40	/* matches bit in opcode 31 instructions */
 #define BYTEREV		0x80
 
+/* Barrier type field, ORed in with type */
+#define BARRIER_MASK	0xe0
+#define BARRIER_SYNC	0x00
+#define BARRIER_ISYNC	0x20
+#define BARRIER_EIEIO	0x40
+#define BARRIER_LWSYNC	0x60
+#define BARRIER_PTESYNC	0x80
+
 /* Cacheop values, ORed in with type */
 #define CACHEOP_MASK	0x700
 #define DCBST		0
@@ -83,7 +98,36 @@ struct instruction_op {
 	int update_reg;
 	/* For MFSPR */
 	int spr;
+	u32 ccval;
+	u32 xerval;
 };
 
-extern int analyse_instr(struct instruction_op *op, struct pt_regs *regs,
+/*
+ * Decode an instruction, and return information about it in *op
+ * without changing *regs.
+ *
+ * Return value is 1 if the instruction can be emulated just by
+ * updating *regs with the information in *op, -1 if we need the
+ * GPRs but *regs doesn't contain the full register set, or 0
+ * otherwise.
+ */
+extern int analyse_instr(struct instruction_op *op, const struct pt_regs *regs,
 			 unsigned int instr);
+
+/*
+ * Emulate an instruction that can be executed just by updating
+ * fields in *regs.
+ */
+void emulate_update_regs(struct pt_regs *reg, struct instruction_op *op);
+
+/*
+ * Emulate instructions that cause a transfer of control,
+ * arithmetic/logical instructions, loads and stores,
+ * cache operations and barriers.
+ *
+ * Returns 1 if the instruction was emulated successfully,
+ * 0 if it could not be emulated, or -1 for an instruction that
+ * should not be emulated (rfid, mtmsrd clearing MSR_RI, etc.).
+ */
+extern int emulate_step(struct pt_regs *regs, unsigned int instr);
+

commit cf87c3f6b64791ce5d4c7e591c915065d31a162d
Author: Paul Mackerras <paulus@samba.org>
Date:   Tue Sep 2 14:35:08 2014 +1000

    powerpc: Emulate icbi, mcrf and conditional-trap instructions
    
    This extends the instruction emulation done by analyse_instr() and
    emulate_step() to handle a few more instructions that are found in
    the kernel.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/sstep.h b/arch/powerpc/include/asm/sstep.h
index 1a693b13ddc5..d3a42cc45a82 100644
--- a/arch/powerpc/include/asm/sstep.h
+++ b/arch/powerpc/include/asm/sstep.h
@@ -66,6 +66,7 @@ enum instruction_type {
 #define DCBF		0x100
 #define DCBTST		0x200
 #define DCBT		0x300
+#define ICBI		0x400
 
 /* Size field in type word */
 #define SIZE(n)		((n) << 8)

commit be96f63375a14ee8e690856ac77e579c75bd0bae
Author: Paul Mackerras <paulus@samba.org>
Date:   Tue Sep 2 14:35:07 2014 +1000

    powerpc: Split out instruction analysis part of emulate_step()
    
    This splits out the instruction analysis part of emulate_step() into
    a separate analyse_instr() function, which decodes the instruction,
    but doesn't execute any load or store instructions.  It does execute
    integer instructions and branches which can be executed purely by
    updating register values in the pt_regs struct.  For other instructions,
    it returns the instruction type and other details in a new
    instruction_op struct.  emulate_step() then uses that information
    to execute loads, stores, cache operations, mfmsr, mtmsr[d], and
    (on 64-bit) sc instructions.
    
    The reason for doing this is so that the KVM code can use it instead
    of having its own separate instruction emulation code.  Possibly the
    alignment interrupt handler could also use this.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/sstep.h b/arch/powerpc/include/asm/sstep.h
index f593b0f9b627..1a693b13ddc5 100644
--- a/arch/powerpc/include/asm/sstep.h
+++ b/arch/powerpc/include/asm/sstep.h
@@ -25,3 +25,64 @@ struct pt_regs;
 
 /* Emulate instructions that cause a transfer of control. */
 extern int emulate_step(struct pt_regs *regs, unsigned int instr);
+
+enum instruction_type {
+	COMPUTE,		/* arith/logical/CR op, etc. */
+	LOAD,
+	LOAD_MULTI,
+	LOAD_FP,
+	LOAD_VMX,
+	LOAD_VSX,
+	STORE,
+	STORE_MULTI,
+	STORE_FP,
+	STORE_VMX,
+	STORE_VSX,
+	LARX,
+	STCX,
+	BRANCH,
+	MFSPR,
+	MTSPR,
+	CACHEOP,
+	BARRIER,
+	SYSCALL,
+	MFMSR,
+	MTMSR,
+	RFI,
+	INTERRUPT,
+	UNKNOWN
+};
+
+#define INSTR_TYPE_MASK	0x1f
+
+/* Load/store flags, ORed in with type */
+#define SIGNEXT		0x20
+#define UPDATE		0x40	/* matches bit in opcode 31 instructions */
+#define BYTEREV		0x80
+
+/* Cacheop values, ORed in with type */
+#define CACHEOP_MASK	0x700
+#define DCBST		0
+#define DCBF		0x100
+#define DCBTST		0x200
+#define DCBT		0x300
+
+/* Size field in type word */
+#define SIZE(n)		((n) << 8)
+#define GETSIZE(w)	((w) >> 8)
+
+#define MKOP(t, f, s)	((t) | (f) | SIZE(s))
+
+struct instruction_op {
+	int type;
+	int reg;
+	unsigned long val;
+	/* For LOAD/STORE/LARX/STCX */
+	unsigned long ea;
+	int update_reg;
+	/* For MFSPR */
+	int spr;
+};
+
+extern int analyse_instr(struct instruction_op *op, struct pt_regs *regs,
+			 unsigned int instr);

commit b8b572e1015f81b4e748417be2629dfe51ab99f9
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Fri Aug 1 15:20:30 2008 +1000

    powerpc: Move include files to arch/powerpc/include/asm
    
    from include/asm-powerpc.  This is the result of a
    
    mkdir arch/powerpc/include/asm
    git mv include/asm-powerpc/* arch/powerpc/include/asm
    
    Followed by a few documentation/comment fixups and a couple of places
    where <asm-powepc/...> was being used explicitly.  Of the latter only
    one was outside the arch code and it is a driver only built for powerpc.
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/include/asm/sstep.h b/arch/powerpc/include/asm/sstep.h
new file mode 100644
index 000000000000..f593b0f9b627
--- /dev/null
+++ b/arch/powerpc/include/asm/sstep.h
@@ -0,0 +1,27 @@
+/*
+ * Copyright (C) 2004 Paul Mackerras <paulus@au.ibm.com>, IBM
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+struct pt_regs;
+
+/*
+ * We don't allow single-stepping an mtmsrd that would clear
+ * MSR_RI, since that would make the exception unrecoverable.
+ * Since we need to single-step to proceed from a breakpoint,
+ * we don't allow putting a breakpoint on an mtmsrd instruction.
+ * Similarly we don't allow breakpoints on rfid instructions.
+ * These macros tell us if an instruction is a mtmsrd or rfid.
+ * Note that IS_MTMSRD returns true for both an mtmsr (32-bit)
+ * and an mtmsrd (64-bit).
+ */
+#define IS_MTMSRD(instr)	(((instr) & 0xfc0007be) == 0x7c000124)
+#define IS_RFID(instr)		(((instr) & 0xfc0007fe) == 0x4c000024)
+#define IS_RFI(instr)		(((instr) & 0xfc0007fe) == 0x4c000064)
+
+/* Emulate instructions that cause a transfer of control. */
+extern int emulate_step(struct pt_regs *regs, unsigned int instr);
