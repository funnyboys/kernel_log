commit 7900757ce1b4affda1591aa3fd073e27d202f406
Author: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
Date:   Tue May 5 12:47:11 2020 +0530

    powerpc/hash64: Restrict page table lookup using init_mm with __flush_hash_table_range
    
    This is only used with init_mm currently. Walking init_mm is much simpler
    because we don't need to handle concurrent page table like other mm_context
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200505071729.54912-5-aneesh.kumar@linux.ibm.com

diff --git a/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h b/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
index 64d02a704bcb..3b95769739c7 100644
--- a/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
+++ b/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
@@ -113,8 +113,7 @@ static inline void hash__flush_tlb_kernel_range(unsigned long start,
 struct mmu_gather;
 extern void hash__tlb_flush(struct mmu_gather *tlb);
 /* Private function for use by PCI IO mapping code */
-extern void __flush_hash_table_range(struct mm_struct *mm, unsigned long start,
-				     unsigned long end);
+extern void __flush_hash_table_range(unsigned long start, unsigned long end);
 extern void flush_tlb_pmd_range(struct mm_struct *mm, pmd_t *pmd,
 				unsigned long addr);
 #endif /*  _ASM_POWERPC_BOOK3S_64_TLBFLUSH_HASH_H */

commit d4748276ae14ce951a3254852dddc3675797c277
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Sun Dec 24 01:15:50 2017 +1000

    powerpc/64s: Improve local TLB flush for boot and MCE on POWER9
    
    There are several cases outside the normal address space management
    where a CPU's entire local TLB is to be flushed:
    
      1. Booting the kernel, in case something has left stale entries in
         the TLB (e.g., kexec).
    
      2. Machine check, to clean corrupted TLB entries.
    
    One other place where the TLB is flushed, is waking from deep idle
    states. The flush is a side-effect of calling ->cpu_restore with the
    intention of re-setting various SPRs. The flush itself is unnecessary
    because in the first case, the TLB should not acquire new corrupted
    TLB entries as part of sleep/wake (though they may be lost).
    
    This type of TLB flush is coded inflexibly, several times for each CPU
    type, and they have a number of problems with ISA v3.0B:
    
    - The current radix mode of the MMU is not taken into account, it is
      always done as a hash flushn For IS=2 (LPID-matching flush from host)
      and IS=3 with HV=0 (guest kernel flush), tlbie(l) is undefined if
      the R field does not match the current radix mode.
    
    - ISA v3.0B hash must flush the partition and process table caches as
      well.
    
    - ISA v3.0B radix must flush partition and process scoped translations,
      partition and process table caches, and also the page walk cache.
    
    So consolidate the flushing code and implement it in C and inline asm
    under the mm/ directory with the rest of the flush code. Add ISA v3.0B
    cases for radix and hash, and use the radix flush in radix environment.
    
    Provide a way for IS=2 (LPID flush) to specify the radix mode of the
    partition. Have KVM pass in the radix mode of the guest.
    
    Take out the flushes from early cputable/dt_cpu_ftrs detection hooks,
    and move it later in the boot process after, the MMU registers are set
    up and before relocation is first turned on.
    
    The TLB flush is no longer called when restoring from deep idle states.
    This was not be done as a separate step because booting secondaries
    uses the same cpu_restore as idle restore, which needs the TLB flush.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h b/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
index 849ecaae9e79..64d02a704bcb 100644
--- a/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
+++ b/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
@@ -51,6 +51,7 @@ static inline void arch_leave_lazy_mmu_mode(void)
 
 #define arch_flush_lazy_mmu_mode()      do {} while (0)
 
+extern void hash__tlbiel_all(unsigned int action);
 
 extern void flush_hash_page(unsigned long vpn, real_pte_t pte, int psize,
 			    int ssize, unsigned long flags);

commit 5b0e2cb020085efe202123162502e0b551e49a0e
Merge: 758f875848d7 3ffa9d9e2a7c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Nov 16 12:47:46 2017 -0800

    Merge tag 'powerpc-4.15-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "A bit of a small release, I suspect in part due to me travelling for
      KS. But my backlog of patches to review is smaller than usual, so I
      think in part folks just didn't send as much this cycle.
    
      Non-highlights:
    
       - Five fixes for the >128T address space handling, both to fix bugs
         in our implementation and to bring the semantics exactly into line
         with x86.
    
      Highlights:
    
       - Support for a new OPAL call on bare metal machines which gives us a
         true NMI (ie. is not masked by MSR[EE]=0) for debugging etc.
    
       - Support for Power9 DD2 in the CXL driver.
    
       - Improvements to machine check handling so that uncorrectable errors
         can be reported into the generic memory_failure() machinery.
    
       - Some fixes and improvements for VPHN, which is used under PowerVM
         to notify the Linux partition of topology changes.
    
       - Plumbing to enable TM (transactional memory) without suspend on
         some Power9 processors (PPC_FEATURE2_HTM_NO_SUSPEND).
    
       - Support for emulating vector loads form cache-inhibited memory, on
         some Power9 revisions.
    
       - Disable the fast-endian switch "syscall" by default (behind a
         CONFIG), we believe it has never had any users.
    
       - A major rework of the API drivers use when initiating and waiting
         for long running operations performed by OPAL firmware, and changes
         to the powernv_flash driver to use the new API.
    
       - Several fixes for the handling of FP/VMX/VSX while processes are
         using transactional memory.
    
       - Optimisations of TLB range flushes when using the radix MMU on
         Power9.
    
       - Improvements to the VAS facility used to access coprocessors on
         Power9, and related improvements to the way the NX crypto driver
         handles requests.
    
       - Implementation of PMEM_API and UACCESS_FLUSHCACHE for 64-bit.
    
      Thanks to: Alexey Kardashevskiy, Alistair Popple, Allen Pais, Andrew
      Donnellan, Aneesh Kumar K.V, Arnd Bergmann, Balbir Singh, Benjamin
      Herrenschmidt, Breno Leitao, Christophe Leroy, Christophe Lombard,
      Cyril Bur, Frederic Barrat, Gautham R. Shenoy, Geert Uytterhoeven,
      Guilherme G. Piccoli, Gustavo Romero, Haren Myneni, Joel Stanley,
      Kamalesh Babulal, Kautuk Consul, Markus Elfring, Masami Hiramatsu,
      Michael Bringmann, Michael Neuling, Michal Suchanek, Naveen N. Rao,
      Nicholas Piggin, Oliver O'Halloran, Paul Mackerras, Pedro Miraglia
      Franco de Carvalho, Philippe Bergheaud, Sandipan Das, Seth Forshee,
      Shriya, Stephen Rothwell, Stewart Smith, Sukadev Bhattiprolu, Tyrel
      Datwyler, Vaibhav Jain, Vaidyanathan Srinivasan, and William A.
      Kennington III"
    
    * tag 'powerpc-4.15-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (151 commits)
      powerpc/64s: Fix Power9 DD2.0 workarounds by adding DD2.1 feature
      powerpc/64s: Fix masking of SRR1 bits on instruction fault
      powerpc/64s: mm_context.addr_limit is only used on hash
      powerpc/64s/radix: Fix 128TB-512TB virtual address boundary case allocation
      powerpc/64s/hash: Allow MAP_FIXED allocations to cross 128TB boundary
      powerpc/64s/hash: Fix fork() with 512TB process address space
      powerpc/64s/hash: Fix 128TB-512TB virtual address boundary case allocation
      powerpc/64s/hash: Fix 512T hint detection to use >= 128T
      powerpc: Fix DABR match on hash based systems
      powerpc/signal: Properly handle return value from uprobe_deny_signal()
      powerpc/fadump: use kstrtoint to handle sysfs store
      powerpc/lib: Implement UACCESS_FLUSHCACHE API
      powerpc/lib: Implement PMEM API
      powerpc/powernv/npu: Don't explicitly flush nmmu tlb
      powerpc/powernv/npu: Use flush_all_mm() instead of flush_tlb_mm()
      powerpc/powernv/idle: Round up latency and residency values
      powerpc/kprobes: refactor kprobe_lookup_name for safer string operations
      powerpc/kprobes: Blacklist emulate_update_regs() from kprobes
      powerpc/kprobes: Do not disable interrupts for optprobes and kprobes_on_ftrace
      powerpc/kprobes: Disable preemption before invoking probe handler for optprobes
      ...

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h b/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
index 2f6373144e2c..42178897a050 100644
--- a/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
+++ b/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef _ASM_POWERPC_BOOK3S_64_TLBFLUSH_HASH_H
 #define _ASM_POWERPC_BOOK3S_64_TLBFLUSH_HASH_H
 

commit 6110236b9bbd177debc045c5fc29224444686ece
Author: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
Date:   Sun Sep 3 20:15:12 2017 +0200

    powerpc/mm: Export flush_all_mm()
    
    With the optimizations introduced by commit a46cc7a90fd8
    ("powerpc/mm/radix: Improve TLB/PWC flushes"), flush_tlb_mm() no
    longer flushes the page walk cache (PWC) with radix. This patch
    introduces flush_all_mm(), which flushes everything, TLB and PWC, for
    a given mm.
    
    Signed-off-by: Frederic Barrat <fbarrat@linux.vnet.ibm.com>
    Reviewed-By: Alistair Popple <alistair@popple.id.au>
    [mpe: Add a WARN_ON_ONCE() in the empty hash routines]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h b/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
index 2f6373144e2c..99c99bb04353 100644
--- a/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
+++ b/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
@@ -65,6 +65,28 @@ static inline void hash__flush_tlb_mm(struct mm_struct *mm)
 {
 }
 
+static inline void hash__local_flush_all_mm(struct mm_struct *mm)
+{
+	/*
+	 * There's no Page Walk Cache for hash, so what is needed is
+	 * the same as flush_tlb_mm(), which doesn't really make sense
+	 * with hash. So the only thing we could do is flush the
+	 * entire LPID! Punt for now, as it's not being used.
+	 */
+	WARN_ON_ONCE(1);
+}
+
+static inline void hash__flush_all_mm(struct mm_struct *mm)
+{
+	/*
+	 * There's no Page Walk Cache for hash, so what is needed is
+	 * the same as flush_tlb_mm(), which doesn't really make sense
+	 * with hash. So the only thing we could do is flush the
+	 * entire LPID! Punt for now, as it's not being used.
+	 */
+	WARN_ON_ONCE(1);
+}
+
 static inline void hash__local_flush_tlb_page(struct vm_area_struct *vma,
 					  unsigned long vmaddr)
 {

commit 703b41ad1a8759949adc1b641a82c2b227d18223
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Wed Jul 13 15:06:44 2016 +0530

    powerpc/mm: remove flush_tlb_page_nohash
    
    This should be same as flush_tlb_page except for hash32. For hash32
    I guess the existing code is wrong, because we don't seem to be
    flushing tlb for Hash != 0 case at all. Fix this by switching to
    calling flush_tlb_page() which does the right thing by flushing
    tlb for both hash and nohash case with hash32
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h b/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
index f12ddf5e8de5..2f6373144e2c 100644
--- a/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
+++ b/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
@@ -75,11 +75,6 @@ static inline void hash__flush_tlb_page(struct vm_area_struct *vma,
 {
 }
 
-static inline void hash__flush_tlb_page_nohash(struct vm_area_struct *vma,
-					   unsigned long vmaddr)
-{
-}
-
 static inline void hash__flush_tlb_range(struct vm_area_struct *vma,
 				     unsigned long start, unsigned long end)
 {

commit 1a472c9dba6b9646fd36717968f6a531b4441c7d
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Fri Apr 29 23:26:05 2016 +1000

    powerpc/mm/radix: Add tlbflush routines
    
    Core kernel doesn't track the page size of the VA range that we are
    invalidating. Hence we end up flushing TLB for the entire mm here. Later
    patches will improve this.
    
    We also don't flush page walk cache separetly instead use RIC=2 when
    flushing TLB, because we do a MMU gather flush after freeing page table.
    
    MMU_NO_CONTEXT is updated for hash.
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h b/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
index cc092ea0387c..f12ddf5e8de5 100644
--- a/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
+++ b/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
@@ -1,8 +1,6 @@
 #ifndef _ASM_POWERPC_BOOK3S_64_TLBFLUSH_HASH_H
 #define _ASM_POWERPC_BOOK3S_64_TLBFLUSH_HASH_H
 
-#define MMU_NO_CONTEXT		0
-
 /*
  * TLB flushing for 64-bit hash-MMU CPUs
  */
@@ -29,14 +27,21 @@ extern void __flush_tlb_pending(struct ppc64_tlb_batch *batch);
 
 static inline void arch_enter_lazy_mmu_mode(void)
 {
-	struct ppc64_tlb_batch *batch = this_cpu_ptr(&ppc64_tlb_batch);
+	struct ppc64_tlb_batch *batch;
 
+	if (radix_enabled())
+		return;
+	batch = this_cpu_ptr(&ppc64_tlb_batch);
 	batch->active = 1;
 }
 
 static inline void arch_leave_lazy_mmu_mode(void)
 {
-	struct ppc64_tlb_batch *batch = this_cpu_ptr(&ppc64_tlb_batch);
+	struct ppc64_tlb_batch *batch;
+
+	if (radix_enabled())
+		return;
+	batch = this_cpu_ptr(&ppc64_tlb_batch);
 
 	if (batch->index)
 		__flush_tlb_pending(batch);

commit 676012a66f651a98808459bc8ab75661828ed96f
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Fri Apr 29 23:26:04 2016 +1000

    powerpc/mm: Hash abstraction for tlbflush routines
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h b/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
index 1b753f96b374..cc092ea0387c 100644
--- a/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
+++ b/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
@@ -52,40 +52,42 @@ extern void flush_hash_range(unsigned long number, int local);
 extern void flush_hash_hugepage(unsigned long vsid, unsigned long addr,
 				pmd_t *pmdp, unsigned int psize, int ssize,
 				unsigned long flags);
-
-static inline void local_flush_tlb_mm(struct mm_struct *mm)
+static inline void hash__local_flush_tlb_mm(struct mm_struct *mm)
 {
 }
 
-static inline void flush_tlb_mm(struct mm_struct *mm)
+static inline void hash__flush_tlb_mm(struct mm_struct *mm)
 {
 }
 
-static inline void local_flush_tlb_page(struct vm_area_struct *vma,
-					unsigned long vmaddr)
+static inline void hash__local_flush_tlb_page(struct vm_area_struct *vma,
+					  unsigned long vmaddr)
 {
 }
 
-static inline void flush_tlb_page(struct vm_area_struct *vma,
-				  unsigned long vmaddr)
+static inline void hash__flush_tlb_page(struct vm_area_struct *vma,
+				    unsigned long vmaddr)
 {
 }
 
-static inline void flush_tlb_page_nohash(struct vm_area_struct *vma,
-					 unsigned long vmaddr)
+static inline void hash__flush_tlb_page_nohash(struct vm_area_struct *vma,
+					   unsigned long vmaddr)
 {
 }
 
-static inline void flush_tlb_range(struct vm_area_struct *vma,
-				   unsigned long start, unsigned long end)
+static inline void hash__flush_tlb_range(struct vm_area_struct *vma,
+				     unsigned long start, unsigned long end)
 {
 }
 
-static inline void flush_tlb_kernel_range(unsigned long start,
-					  unsigned long end)
+static inline void hash__flush_tlb_kernel_range(unsigned long start,
+					    unsigned long end)
 {
 }
 
+
+struct mmu_gather;
+extern void hash__tlb_flush(struct mmu_gather *tlb);
 /* Private function for use by PCI IO mapping code */
 extern void __flush_hash_table_range(struct mm_struct *mm, unsigned long start,
 				     unsigned long end);

commit ee3b93ebfbed6279f7a329001433c75c50ddfcc9
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Tue Mar 1 12:59:21 2016 +0530

    powerpc/mm: Move hash64 tlbflush code into a new header
    
    No code changes.
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h b/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
new file mode 100644
index 000000000000..1b753f96b374
--- /dev/null
+++ b/arch/powerpc/include/asm/book3s/64/tlbflush-hash.h
@@ -0,0 +1,94 @@
+#ifndef _ASM_POWERPC_BOOK3S_64_TLBFLUSH_HASH_H
+#define _ASM_POWERPC_BOOK3S_64_TLBFLUSH_HASH_H
+
+#define MMU_NO_CONTEXT		0
+
+/*
+ * TLB flushing for 64-bit hash-MMU CPUs
+ */
+
+#include <linux/percpu.h>
+#include <asm/page.h>
+
+#define PPC64_TLB_BATCH_NR 192
+
+struct ppc64_tlb_batch {
+	int			active;
+	unsigned long		index;
+	struct mm_struct	*mm;
+	real_pte_t		pte[PPC64_TLB_BATCH_NR];
+	unsigned long		vpn[PPC64_TLB_BATCH_NR];
+	unsigned int		psize;
+	int			ssize;
+};
+DECLARE_PER_CPU(struct ppc64_tlb_batch, ppc64_tlb_batch);
+
+extern void __flush_tlb_pending(struct ppc64_tlb_batch *batch);
+
+#define __HAVE_ARCH_ENTER_LAZY_MMU_MODE
+
+static inline void arch_enter_lazy_mmu_mode(void)
+{
+	struct ppc64_tlb_batch *batch = this_cpu_ptr(&ppc64_tlb_batch);
+
+	batch->active = 1;
+}
+
+static inline void arch_leave_lazy_mmu_mode(void)
+{
+	struct ppc64_tlb_batch *batch = this_cpu_ptr(&ppc64_tlb_batch);
+
+	if (batch->index)
+		__flush_tlb_pending(batch);
+	batch->active = 0;
+}
+
+#define arch_flush_lazy_mmu_mode()      do {} while (0)
+
+
+extern void flush_hash_page(unsigned long vpn, real_pte_t pte, int psize,
+			    int ssize, unsigned long flags);
+extern void flush_hash_range(unsigned long number, int local);
+extern void flush_hash_hugepage(unsigned long vsid, unsigned long addr,
+				pmd_t *pmdp, unsigned int psize, int ssize,
+				unsigned long flags);
+
+static inline void local_flush_tlb_mm(struct mm_struct *mm)
+{
+}
+
+static inline void flush_tlb_mm(struct mm_struct *mm)
+{
+}
+
+static inline void local_flush_tlb_page(struct vm_area_struct *vma,
+					unsigned long vmaddr)
+{
+}
+
+static inline void flush_tlb_page(struct vm_area_struct *vma,
+				  unsigned long vmaddr)
+{
+}
+
+static inline void flush_tlb_page_nohash(struct vm_area_struct *vma,
+					 unsigned long vmaddr)
+{
+}
+
+static inline void flush_tlb_range(struct vm_area_struct *vma,
+				   unsigned long start, unsigned long end)
+{
+}
+
+static inline void flush_tlb_kernel_range(unsigned long start,
+					  unsigned long end)
+{
+}
+
+/* Private function for use by PCI IO mapping code */
+extern void __flush_hash_table_range(struct mm_struct *mm, unsigned long start,
+				     unsigned long end);
+extern void flush_tlb_pmd_range(struct mm_struct *mm, pmd_t *pmd,
+				unsigned long addr);
+#endif /*  _ASM_POWERPC_BOOK3S_64_TLBFLUSH_HASH_H */
