commit 87939d50e5888bd78478d9aa9455f56b919df658
Author: Alistair Popple <alistair@popple.id.au>
Date:   Thu May 21 11:43:40 2020 +1000

    powerpc/dt_cpu_ftrs: Add MMA feature
    
    Matrix multiple assist (MMA) is a new feature added to ISAv3.1 and
    POWER10. Support on powernv can be selected via a firmware CPU device
    tree feature which enables it via a PCR bit.
    
    Signed-off-by: Alistair Popple <alistair@popple.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200521014341.29095-7-alistair@popple.id.au

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index dd20af367b57..88e6c78100d9 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -481,7 +481,8 @@
 #define   PCR_VEC_DIS	(__MASK(63-0))	/* Vec. disable (bit NA since POWER8) */
 #define   PCR_VSX_DIS	(__MASK(63-1))	/* VSX disable (bit NA since POWER8) */
 #define   PCR_TM_DIS	(__MASK(63-2))	/* Trans. memory disable (POWER8) */
-#define   PCR_HIGH_BITS	(PCR_VEC_DIS | PCR_VSX_DIS | PCR_TM_DIS)
+#define   PCR_MMA_DIS	(__MASK(63-3)) /* Matrix-Multiply Accelerator */
+#define   PCR_HIGH_BITS	(PCR_MMA_DIS | PCR_VEC_DIS | PCR_VSX_DIS | PCR_TM_DIS)
 /*
  * These bits are used in the function kvmppc_set_arch_compat() to specify and
  * determine both the compatibility level which we want to emulate and the

commit 3fd5836ee801ab9ac5b314c26550e209bafa5eaa
Author: Alistair Popple <alistair@popple.id.au>
Date:   Thu May 21 11:43:36 2020 +1000

    powerpc: Add support for ISA v3.1
    
    Newer ISA versions are enabled by clearing all bits in the PCR
    associated with previous versions of the ISA. Enable ISA v3.1 support
    by updating the PCR mask to include ISA v3.0. This ensures all PCR
    bits corresponding to earlier architecture versions get cleared
    thereby enabling ISA v3.1 if supported by the hardware.
    
    Signed-off-by: Alistair Popple <alistair@popple.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200521014341.29095-3-alistair@popple.id.au

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 054f8a71d686..dd20af367b57 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -487,10 +487,11 @@
  * determine both the compatibility level which we want to emulate and the
  * compatibility level which the host is capable of emulating.
  */
+#define   PCR_ARCH_300	0x10		/* Architecture 3.00 */
 #define   PCR_ARCH_207	0x8		/* Architecture 2.07 */
 #define   PCR_ARCH_206	0x4		/* Architecture 2.06 */
 #define   PCR_ARCH_205	0x2		/* Architecture 2.05 */
-#define   PCR_LOW_BITS	(PCR_ARCH_207 | PCR_ARCH_206 | PCR_ARCH_205)
+#define   PCR_LOW_BITS	(PCR_ARCH_207 | PCR_ARCH_206 | PCR_ARCH_205 | PCR_ARCH_300)
 #define   PCR_MASK	~(PCR_HIGH_BITS | PCR_LOW_BITS)	/* PCR Reserved Bits */
 #define	SPRN_HEIR	0x153	/* Hypervisor Emulated Instruction Register */
 #define SPRN_TLBINDEXR	0x154	/* P7 TLB control register */

commit 4a4ec2289a5d748cb64ff67ca8d74535a76a8436
Author: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
Date:   Thu May 14 16:47:27 2020 +0530

    powerpc/watchpoint: Add SPRN macros for second DAWR
    
    Power10 is introducing second DAWR. Add SPRN_ macros for the same.
    
    Signed-off-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Michael Neuling <mikey@neuling.org>
    Link: https://lore.kernel.org/r/20200514111741.97993-3-ravi.bangoria@linux.ibm.com

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 60a21b6b2057..054f8a71d686 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -284,6 +284,7 @@
 #define   CTRL_TE	0x00c00000	/* thread enable */
 #define   CTRL_RUNLATCH	0x1
 #define SPRN_DAWR0	0xB4
+#define SPRN_DAWR1	0xB5
 #define SPRN_RPR	0xBA	/* Relative Priority Register */
 #define SPRN_CIABR	0xBB
 #define   CIABR_PRIV		0x3
@@ -291,6 +292,7 @@
 #define   CIABR_PRIV_SUPER	2
 #define   CIABR_PRIV_HYPER	3
 #define SPRN_DAWRX0	0xBC
+#define SPRN_DAWRX1	0xBD
 #define   DAWRX_USER	__MASK(0)
 #define   DAWRX_KERNEL	__MASK(1)
 #define   DAWRX_HYP	__MASK(2)

commit 09f82b063aa9c248a3ef919aeec361054e7b044a
Author: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
Date:   Thu May 14 16:47:26 2020 +0530

    powerpc/watchpoint: Rename current DAWR macros
    
    Power10 is introducing second DAWR. Use real register names from ISA
    for current macros:
      s/SPRN_DAWR/SPRN_DAWR0/
      s/SPRN_DAWRX/SPRN_DAWRX0/
    
    Signed-off-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Michael Neuling <mikey@neuling.org>
    Link: https://lore.kernel.org/r/20200514111741.97993-2-ravi.bangoria@linux.ibm.com

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index f95eb8f97756..60a21b6b2057 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -283,14 +283,14 @@
 #define   CTRL_CT1	0x40000000	/* thread 1 */
 #define   CTRL_TE	0x00c00000	/* thread enable */
 #define   CTRL_RUNLATCH	0x1
-#define SPRN_DAWR	0xB4
+#define SPRN_DAWR0	0xB4
 #define SPRN_RPR	0xBA	/* Relative Priority Register */
 #define SPRN_CIABR	0xBB
 #define   CIABR_PRIV		0x3
 #define   CIABR_PRIV_USER	1
 #define   CIABR_PRIV_SUPER	2
 #define   CIABR_PRIV_HYPER	3
-#define SPRN_DAWRX	0xBC
+#define SPRN_DAWRX0	0xBC
 #define   DAWRX_USER	__MASK(0)
 #define   DAWRX_KERNEL	__MASK(1)
 #define   DAWRX_HYP	__MASK(2)

commit b691505ef9232a6e82f1c160911afcb4cb20487b
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Wed May 6 13:40:42 2020 +1000

    powerpc: Define new SRR1 bits for a ISA v3.1
    
    Add the BOUNDARY SRR1 bit definition for when the cause of an
    alignment exception is a prefixed instruction that crosses a 64-byte
    boundary. Add the PREFIXED SRR1 bit definition for exceptions caused
    by prefixed instructions.
    
    Bit 35 of SRR1 is called SRR1_ISI_N_OR_G. This name comes from it
    being used to indicate that an ISI was due to the access being no-exec
    or guarded. ISA v3.1 adds another purpose. It is also set if there is
    an access in a cache-inhibited location for prefixed instruction.
    Rename from SRR1_ISI_N_OR_G to SRR1_ISI_N_G_OR_CIP.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Alistair Popple <alistair@popple.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-23-jniethe5@gmail.com

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 773f76402392..f95eb8f97756 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -762,7 +762,7 @@
 #endif
 
 #define   SRR1_ISI_NOPT		0x40000000 /* ISI: Not found in hash */
-#define   SRR1_ISI_N_OR_G	0x10000000 /* ISI: Access is no-exec or G */
+#define   SRR1_ISI_N_G_OR_CIP	0x10000000 /* ISI: Access is no-exec or G or CI for a prefixed instruction */
 #define   SRR1_ISI_PROT		0x08000000 /* ISI: Other protection fault */
 #define   SRR1_WAKEMASK		0x00380000 /* reason for wakeup */
 #define   SRR1_WAKEMASK_P8	0x003c0000 /* reason for wakeup on POWER8 and 9 */
@@ -789,6 +789,8 @@
 #define   SRR1_PROGADDR		0x00010000 /* SRR0 contains subsequent addr */
 
 #define   SRR1_MCE_MCP		0x00080000 /* Machine check signal caused interrupt */
+#define   SRR1_BOUNDARY		0x10000000 /* Prefixed instruction crosses 64-byte boundary */
+#define   SRR1_PREFIXED		0x20000000 /* Exception caused by prefixed instruction */
 
 #define SPRN_HSRR0	0x13A	/* Save/Restore Register 0 */
 #define SPRN_HSRR1	0x13B	/* Save/Restore Register 1 */

commit 2aa6195e43b3740258ead93aee42ac719dd4c4b0
Author: Alistair Popple <alistair@popple.id.au>
Date:   Wed May 6 13:40:41 2020 +1000

    powerpc: Enable Prefixed Instructions
    
    Prefix instructions have their own FSCR bit which needs to enabled via
    a CPU feature. The kernel will save the FSCR for problem state but it
    needs to be enabled initially.
    
    If prefixed instructions are made unavailable by the [H]FSCR, attempting
    to use them will cause a facility unavailable exception. Add "PREFIX" to
    the facility_strings[].
    
    Currently there are no prefixed instructions that are actually emulated
    by emulate_instruction() within facility_unavailable_exception().
    However, when caused by a prefixed instructions the SRR1 PREFIXED bit is
    set. Prepare for dealing with emulated prefixed instructions by checking
    for this bit.
    
    Signed-off-by: Alistair Popple <alistair@popple.id.au>
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    Link: https://lore.kernel.org/r/20200506034050.24806-22-jniethe5@gmail.com

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index da5cab038e25..773f76402392 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -397,6 +397,7 @@
 #define SPRN_RWMR	0x375	/* Region-Weighting Mode Register */
 
 /* HFSCR and FSCR bit numbers are the same */
+#define FSCR_PREFIX_LG	13	/* Enable Prefix Instructions */
 #define FSCR_SCV_LG	12	/* Enable System Call Vectored */
 #define FSCR_MSGP_LG	10	/* Enable MSGP */
 #define FSCR_TAR_LG	8	/* Enable Target Address Register */
@@ -408,11 +409,13 @@
 #define FSCR_VECVSX_LG	1	/* Enable VMX/VSX  */
 #define FSCR_FP_LG	0	/* Enable Floating Point */
 #define SPRN_FSCR	0x099	/* Facility Status & Control Register */
+#define   FSCR_PREFIX	__MASK(FSCR_PREFIX_LG)
 #define   FSCR_SCV	__MASK(FSCR_SCV_LG)
 #define   FSCR_TAR	__MASK(FSCR_TAR_LG)
 #define   FSCR_EBB	__MASK(FSCR_EBB_LG)
 #define   FSCR_DSCR	__MASK(FSCR_DSCR_LG)
 #define SPRN_HFSCR	0xbe	/* HV=1 Facility Status & Control Register */
+#define   HFSCR_PREFIX	__MASK(FSCR_PREFIX_LG)
 #define   HFSCR_MSGP	__MASK(FSCR_MSGP_LG)
 #define   HFSCR_TAR	__MASK(FSCR_TAR_LG)
 #define   HFSCR_EBB	__MASK(FSCR_EBB_LG)

commit 0e63f0151719ee4cb90d85e60c98045099c995e2
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Feb 20 22:51:38 2020 +1100

    powerpc: Add current_stack_pointer as a register global
    
    current_stack_frame() doesn't return the stack pointer, but the
    caller's stack frame. See commit bfe9a2cfe91a ("powerpc: Reimplement
    __get_SP() as a function not a define") and commit
    acf620ecf56c ("powerpc: Rename __get_SP() to current_stack_pointer()")
    for details.
    
    In some cases this is overkill or incorrect, as it doesn't return the
    current value of r1.
    
    So add a current_stack_pointer register global to get the value of r1
    directly.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    [mpe: Split out of other patch, tweak change log]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200220115141.2707-2-mpe@ellerman.id.au

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 1b1ffdba6097..da5cab038e25 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1450,6 +1450,8 @@ static inline void mtsrin(u32 val, u32 idx)
 
 extern unsigned long current_stack_frame(void);
 
+register unsigned long current_stack_pointer asm("r1");
+
 extern unsigned long scom970_read(unsigned int address);
 extern void scom970_write(unsigned int address, unsigned long value);
 

commit 3d13e839e801e081bdece0127c2affa33d0f77cf
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Feb 20 22:51:37 2020 +1100

    powerpc: Rename current_stack_pointer() to current_stack_frame()
    
    current_stack_pointer(), which was called __get_SP(), used to just
    return the value in r1.
    
    But that caused problems in some cases, so it was turned into a
    function in commit bfe9a2cfe91a ("powerpc: Reimplement __get_SP() as a
    function not a define").
    
    Because it's a function in a separate compilation unit to all its
    callers, it has the effect of causing a stack frame to be created, and
    then returns the address of that frame. This is good in some cases
    like those described in the above commit, but in other cases it's
    overkill, we just need to know what stack page we're on.
    
    On some other arches current_stack_pointer is just a register global
    giving the stack pointer, and we'd like to do that too. So rename our
    current_stack_pointer() to current_stack_frame() to make that
    possible.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Link: https://lore.kernel.org/r/20200220115141.2707-1-mpe@ellerman.id.au

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 1aa46dff0957..1b1ffdba6097 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1448,7 +1448,7 @@ static inline void mtsrin(u32 val, u32 idx)
 
 #define proc_trap()	asm volatile("trap")
 
-extern unsigned long current_stack_pointer(void);
+extern unsigned long current_stack_frame(void);
 
 extern unsigned long scom970_read(unsigned int address);
 extern void scom970_write(unsigned int address, unsigned long value);

commit 7794b1d4185e2587af46435e3e2f6696dae314c7
Merge: 9dd0013824fc 2807273f5e88
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Nov 30 14:35:43 2019 -0800

    Merge tag 'powerpc-5.5-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Highlights:
    
       - Infrastructure for secure boot on some bare metal Power9 machines.
         The firmware support is still in development, so the code here
         won't actually activate secure boot on any existing systems.
    
       - A change to xmon (our crash handler / pseudo-debugger) to restrict
         it to read-only mode when the kernel is lockdown'ed, otherwise it's
         trivial to drop into xmon and modify kernel data, such as the
         lockdown state.
    
       - Support for KASLR on 32-bit BookE machines (Freescale / NXP).
    
       - Fixes for our flush_icache_range() and __kernel_sync_dicache()
         (VDSO) to work with memory ranges >4GB.
    
       - Some reworks of the pseries CMM (Cooperative Memory Management)
         driver to make it behave more like other balloon drivers and enable
         some cleanups of generic mm code.
    
       - A series of fixes to our hardware breakpoint support to properly
         handle unaligned watchpoint addresses.
    
      Plus a bunch of other smaller improvements, fixes and cleanups.
    
      Thanks to: Alastair D'Silva, Andrew Donnellan, Aneesh Kumar K.V,
      Anthony Steinhauser, Cédric Le Goater, Chris Packham, Chris Smart,
      Christophe Leroy, Christopher M. Riedl, Christoph Hellwig, Claudio
      Carvalho, Daniel Axtens, David Hildenbrand, Deb McLemore, Diana
      Craciun, Eric Richter, Geert Uytterhoeven, Greg Kroah-Hartman, Greg
      Kurz, Gustavo L. F. Walbon, Hari Bathini, Harish, Jason Yan, Krzysztof
      Kozlowski, Leonardo Bras, Mathieu Malaterre, Mauro S. M. Rodrigues,
      Michal Suchanek, Mimi Zohar, Nathan Chancellor, Nathan Lynch, Nayna
      Jain, Nick Desaulniers, Oliver O'Halloran, Qian Cai, Rasmus Villemoes,
      Ravi Bangoria, Sam Bobroff, Santosh Sivaraj, Scott Wood, Thomas Huth,
      Tyrel Datwyler, Vaibhav Jain, Valentin Longchamp, YueHaibing"
    
    * tag 'powerpc-5.5-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (144 commits)
      powerpc/fixmap: fix crash with HIGHMEM
      x86/efi: remove unused variables
      powerpc: Define arch_is_kernel_initmem_freed() for lockdep
      powerpc/prom_init: Use -ffreestanding to avoid a reference to bcmp
      powerpc: Avoid clang warnings around setjmp and longjmp
      powerpc: Don't add -mabi= flags when building with Clang
      powerpc: Fix Kconfig indentation
      powerpc/fixmap: don't clear fixmap area in paging_init()
      selftests/powerpc: spectre_v2 test must be built 64-bit
      powerpc/powernv: Disable native PCIe port management
      powerpc/kexec: Move kexec files into a dedicated subdir.
      powerpc/32: Split kexec low level code out of misc_32.S
      powerpc/sysdev: drop simple gpio
      powerpc/83xx: map IMMR with a BAT.
      powerpc/32s: automatically allocate BAT in setbat()
      powerpc/ioremap: warn on early use of ioremap()
      powerpc: Add support for GENERIC_EARLY_IOREMAP
      powerpc/fixmap: Use __fix_to_virt() instead of fix_to_virt()
      powerpc/8xx: use the fixmapped IMMR in cpm_reset()
      powerpc/8xx: add __init to cpm1 init functions
      ...

commit b020aa9d1e875c1c91b1390acdf42320e7060d84
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Aug 29 08:45:13 2019 +0000

    powerpc: cleanup hw_irq.h
    
    SET_MSR_EE() is just use in this file and doesn't provide
    any added value compared to mtmsr(). Drop it.
    
    Add a wrtee() inline function to use wrtee/wrteei insn.
    
    Replace #ifdefs by IS_ENABLED()
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/a28a20514d5f6df9629c1a117b667e48c4272736.1567068137.git.christophe.leroy@c-s.fr

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index b7faf6c781a7..0b7900f194c8 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1368,6 +1368,14 @@ static inline void mtmsr_isync(unsigned long val)
 #define wrtspr(rn)	asm volatile("mtspr " __stringify(rn) ",0" : \
 				     : : "memory")
 
+static inline void wrtee(unsigned long val)
+{
+	if (__builtin_constant_p(val))
+		asm volatile("wrteei %0" : : "i" ((val & MSR_EE) ? 1 : 0) : "memory");
+	else
+		asm volatile("wrtee %0" : : "r" (val) : "memory");
+}
+
 extern unsigned long msr_check_and_set(unsigned long bits);
 extern bool strict_msr_control;
 extern void __msr_check_and_clear(unsigned long bits);

commit 44448640dd0df98891c5ea4695d89a4972cb4c1f
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Aug 29 08:45:12 2019 +0000

    powerpc: permanently include 8xx registers in reg.h
    
    Most 8xx registers have specific names, so just include
    reg_8xx.h all the time in reg.h in order to have them defined
    even when CONFIG_PPC_8xx is not selected. This will avoid
    the need for #ifdefs in C code.
    
    Guard SPRN_ICTRL in an #ifdef CONFIG_PPC_8xx as this register
    has same name but different meaning and different spr number as
    another register in the mpc7450.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/dd82934ad91aab607d0eb7e626c14e6ac0d654eb.1567068137.git.christophe.leroy@c-s.fr

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index f3f368819f9c..b7faf6c781a7 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -25,9 +25,7 @@
 #include <asm/reg_fsl_emb.h>
 #endif
 
-#ifdef CONFIG_PPC_8xx
 #include <asm/reg_8xx.h>
-#endif /* CONFIG_PPC_8xx */
 
 #define MSR_SF_LG	63              /* Enable 64 bit mode */
 #define MSR_ISF_LG	61              /* Interrupt 64b mode valid on 630 */

commit b06174345f6e70200916136695514e0b6b95ac17
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Wed Aug 28 13:42:01 2019 +0000

    powerpc/reg: use ASM_FTR_IFSET() instead of opencoding fixup.
    
    mftb() includes a feature fixup for CELL ppc.
    
    Use ASM_FTR_IFSET() macro instead of opencoding the setup
    of the fixup sections.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/ac19713826fa55e9e7bfe3100c5a7b1712ab9526.1566999711.git.christophe.leroy@c-s.fr

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index b3cbb1136bce..f3f368819f9c 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1384,19 +1384,9 @@ static inline void msr_check_and_clear(unsigned long bits)
 #define mftb()		({unsigned long rval;				\
 			asm volatile(					\
 				"90:	mfspr %0, %2;\n"		\
-				"97:	cmpwi %0,0;\n"			\
-				"	beq- 90b;\n"			\
-				"99:\n"					\
-				".section __ftr_fixup,\"a\"\n"		\
-				".align 3\n"				\
-				"98:\n"					\
-				"	.8byte %1\n"			\
-				"	.8byte %1\n"			\
-				"	.8byte 97b-98b\n"		\
-				"	.8byte 99b-98b\n"		\
-				"	.8byte 0\n"			\
-				"	.8byte 0\n"			\
-				".previous"				\
+				ASM_FTR_IFSET(				\
+					"97:	cmpwi %0,0;\n"		\
+					"	beq- 90b;\n", "", %1)	\
 			: "=r" (rval) \
 			: "i" (CPU_FTR_CELL_TB_BUG), "i" (SPRN_TBRL) : "cr0"); \
 			rval;})

commit 9ee6471eb9d43114ba4f0de3e0f483bf6fb2a906
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Wed Oct 2 16:00:21 2019 +1000

    KVM: PPC: Book3S: Define and use SRR1_MSR_BITS
    
    Acked-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index b3cbb1136bce..75c7e95a321b 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -748,6 +748,18 @@
 #define SPRN_USPRG7	0x107	/* SPRG7 userspace read */
 #define SPRN_SRR0	0x01A	/* Save/Restore Register 0 */
 #define SPRN_SRR1	0x01B	/* Save/Restore Register 1 */
+
+#ifdef CONFIG_PPC_BOOK3S
+/*
+ * Bits loaded from MSR upon interrupt.
+ * PPC (64-bit) bits 33-36,42-47 are interrupt dependent, the others are
+ * loaded from MSR. The exception is that SRESET and MCE do not always load
+ * bit 62 (RI) from MSR. Don't use PPC_BITMASK for this because 32-bit uses
+ * it.
+ */
+#define   SRR1_MSR_BITS		(~0x783f0000UL)
+#endif
+
 #define   SRR1_ISI_NOPT		0x40000000 /* ISI: Not found in hash */
 #define   SRR1_ISI_N_OR_G	0x10000000 /* ISI: Access is no-exec or G */
 #define   SRR1_ISI_PROT		0x08000000 /* ISI: Other protection fault */

commit 13c7bb3c57dcfe779ea5b4b083f6c47753cc5327
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Tue Sep 17 10:46:05 2019 +1000

    powerpc/64s: Set reserved PCR bits
    
    Currently the reserved bits of the Processor Compatibility
    Register (PCR) are cleared as per the Programming Note in Section
    1.3.3 of version 3.0B of the Power ISA. This causes all new
    architecture features to be made available when running on newer
    processors with new architecture features added to the PCR as bits
    must be set to disable a given feature.
    
    For example to disable new features added as part of Version 2.07 of
    the ISA the corresponding bit in the PCR needs to be set.
    
    As new processor features generally require explicit kernel support
    they should be disabled until such support is implemented. Therefore
    kernels should set all unknown/reserved bits in the PCR such that any
    new architecture features which the kernel does not currently know
    about get disabled.
    
    An update is planned to the ISA to clarify that the PCR is an
    exception to the Programming Note on reserved bits in Section 1.3.3.
    
    Signed-off-by: Alistair Popple <alistair@popple.id.au>
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Tested-by: Joel Stanley <joel@jms.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190917004605.22471-2-alistair@popple.id.au

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 931939af95d1..b3cbb1136bce 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -478,6 +478,7 @@
 #define   PCR_VEC_DIS	(__MASK(63-0))	/* Vec. disable (bit NA since POWER8) */
 #define   PCR_VSX_DIS	(__MASK(63-1))	/* VSX disable (bit NA since POWER8) */
 #define   PCR_TM_DIS	(__MASK(63-2))	/* Trans. memory disable (POWER8) */
+#define   PCR_HIGH_BITS	(PCR_VEC_DIS | PCR_VSX_DIS | PCR_TM_DIS)
 /*
  * These bits are used in the function kvmppc_set_arch_compat() to specify and
  * determine both the compatibility level which we want to emulate and the
@@ -486,6 +487,8 @@
 #define   PCR_ARCH_207	0x8		/* Architecture 2.07 */
 #define   PCR_ARCH_206	0x4		/* Architecture 2.06 */
 #define   PCR_ARCH_205	0x2		/* Architecture 2.05 */
+#define   PCR_LOW_BITS	(PCR_ARCH_207 | PCR_ARCH_206 | PCR_ARCH_205)
+#define   PCR_MASK	~(PCR_HIGH_BITS | PCR_LOW_BITS)	/* PCR Reserved Bits */
 #define	SPRN_HEIR	0x153	/* Hypervisor Emulated Instruction Register */
 #define SPRN_TLBINDEXR	0x154	/* P7 TLB control register */
 #define SPRN_TLBVPNR	0x155	/* P7 TLB control register */

commit c6fadabb2868f817299ddb338ac15885e25d12d2
Author: Alistair Popple <alistair@popple.id.au>
Date:   Tue Sep 17 10:46:04 2019 +1000

    powerpc: Fix definition of PCR bits to work with old binutils
    
    Commit 388cc6e133132 ("KVM: PPC: Book3S HV: Support POWER6
    compatibility mode on POWER7") introduced new macros defining the PCR
    bits. When used from assembly files these definitions lead to build
    errors using older versions of binutils that don't support the 'ul'
    suffix. This fixes the build errors by updating the definitions to use
    the __MASK() macro which selects the appropriate suffix.
    
    Signed-off-by: Alistair Popple <alistair@popple.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190917004605.22471-1-alistair@popple.id.au

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index ec3714cf0989..931939af95d1 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -475,9 +475,9 @@
 #define   HMER_DEBUG_TRIG	(1ul << (63 - 17)) /* Debug trigger */
 #define	SPRN_HMEER	0x151	/* Hyp maintenance exception enable reg */
 #define SPRN_PCR	0x152	/* Processor compatibility register */
-#define   PCR_VEC_DIS	(1ul << (63-0))	/* Vec. disable (bit NA since POWER8) */
-#define   PCR_VSX_DIS	(1ul << (63-1))	/* VSX disable (bit NA since POWER8) */
-#define   PCR_TM_DIS	(1ul << (63-2))	/* Trans. memory disable (POWER8) */
+#define   PCR_VEC_DIS	(__MASK(63-0))	/* Vec. disable (bit NA since POWER8) */
+#define   PCR_VSX_DIS	(__MASK(63-1))	/* VSX disable (bit NA since POWER8) */
+#define   PCR_TM_DIS	(__MASK(63-2))	/* Trans. memory disable (POWER8) */
 /*
  * These bits are used in the function kvmppc_set_arch_compat() to specify and
  * determine both the compatibility level which we want to emulate and the

commit 7f70c3815a352f76d69fc5642ae9685033a428c0
Author: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
Date:   Mon Aug 19 23:13:16 2019 -0300

    powerpc: Introduce the MSR_S bit
    
    Protected Execution Facility (PEF) is an architectural change for
    POWER 9 that enables Secure Virtual Machines (SVMs). When enabled,
    PEF adds a new higher privileged mode, called Ultravisor mode, to
    POWER architecture.
    
    The hardware changes include the following:
    
      * There is a new bit in the MSR that determines whether the current
        process is running in secure mode, MSR(S) bit 41. MSR(S)=1, process
        is in secure mode, MSR(s)=0 process is in normal mode.
    
      * The MSR(S) bit can only be set by the Ultravisor.
    
      * HRFID cannot be used to set the MSR(S) bit. If the hypervisor needs
        to return to a SVM it must use an ultracall. It can determine if
        the VM it is returning to is secure.
    
      * The privilege of a process is now determined by three MSR bits,
        MSR(S, HV, PR). In each of the tables below the modes are listed
        from least privilege to highest privilege. The higher privilege
        modes can access all the resources of the lower privilege modes.
    
        **Secure Mode MSR Settings**
    
           +---+---+---+---------------+
           | S | HV| PR|Privilege      |
           +===+===+===+===============+
           | 1 | 0 | 1 | Problem       |
           +---+---+---+---------------+
           | 1 | 0 | 0 | Privileged(OS)|
           +---+---+---+---------------+
           | 1 | 1 | 0 | Ultravisor    |
           +---+---+---+---------------+
           | 1 | 1 | 1 | Reserved      |
           +---+---+---+---------------+
    
        **Normal Mode MSR Settings**
    
           +---+---+---+---------------+
           | S | HV| PR|Privilege      |
           +===+===+===+===============+
           | 0 | 0 | 1 | Problem       |
           +---+---+---+---------------+
           | 0 | 0 | 0 | Privileged(OS)|
           +---+---+---+---------------+
           | 0 | 1 | 0 | Hypervisor    |
           +---+---+---+---------------+
           | 0 | 1 | 1 | Problem (HV)  |
           +---+---+---+---------------+
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Signed-off-by: Ram Pai <linuxram@us.ibm.com>
    [ cclaudio: Update the commit message ]
    Signed-off-by: Claudio Carvalho <cclaudio@linux.ibm.com>
    Signed-off-by: Thiago Jung Bauermann <bauerman@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190820021326.6884-7-bauerman@linux.ibm.com

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 10caa145f98b..ec3714cf0989 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -38,6 +38,7 @@
 #define MSR_TM_LG	32		/* Trans Mem Available */
 #define MSR_VEC_LG	25	        /* Enable AltiVec */
 #define MSR_VSX_LG	23		/* Enable VSX */
+#define MSR_S_LG	22		/* Secure state */
 #define MSR_POW_LG	18		/* Enable Power Management */
 #define MSR_WE_LG	18		/* Wait State Enable */
 #define MSR_TGPR_LG	17		/* TLB Update registers in use */
@@ -71,11 +72,13 @@
 #define MSR_SF		__MASK(MSR_SF_LG)	/* Enable 64 bit mode */
 #define MSR_ISF		__MASK(MSR_ISF_LG)	/* Interrupt 64b mode valid on 630 */
 #define MSR_HV 		__MASK(MSR_HV_LG)	/* Hypervisor state */
+#define MSR_S		__MASK(MSR_S_LG)	/* Secure state */
 #else
 /* so tests for these bits fail on 32-bit */
 #define MSR_SF		0
 #define MSR_ISF		0
 #define MSR_HV		0
+#define MSR_S		0
 #endif
 
 /*

commit 10d91611f426d4bafd2a83d966c36da811b2f7ad
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Sat Apr 13 00:30:52 2019 +1000

    powerpc/64s: Reimplement book3s idle code in C
    
    Reimplement Book3S idle code in C, moving POWER7/8/9 implementation
    speific HV idle code to the powernv platform code.
    
    Book3S assembly stubs are kept in common code and used only to save
    the stack frame and non-volatile GPRs before executing architected
    idle instructions, and restoring the stack and reloading GPRs then
    returning to C after waking from idle.
    
    The complex logic dealing with threads and subcores, locking, SPRs,
    HMIs, timebase resync, etc., is all done in C which makes it more
    maintainable.
    
    This is not a strict translation to C code, there are some
    significant differences:
    
    - Idle wakeup no longer uses the ->cpu_restore call to reinit SPRs,
      but saves and restores them itself.
    
    - The optimisation where EC=ESL=0 idle modes did not have to save GPRs
      or change MSR is restored, because it's now simple to do. ESL=1
      sleeps that do not lose GPRs can use this optimization too.
    
    - KVM secondary entry and cede is now more of a call/return style
      rather than branchy. nap_state_lost is not required because KVM
      always returns via NVGPR restoring path.
    
    - KVM secondary wakeup from offline sequence is moved entirely into
      the offline wakeup, which avoids a hwsync in the normal idle wakeup
      path.
    
    Performance measured with context switch ping-pong on different
    threads or cores, is possibly improved a small amount, 1-3% depending
    on stop state and core vs thread test for shallow states. Deep states
    it's in the noise compared with other latencies.
    
    KVM improvements:
    
    - Idle sleepers now always return to caller rather than branch out
      to KVM first.
    
    - This allows optimisations like very fast return to caller when no
      state has been lost.
    
    - KVM no longer requires nap_state_lost because it controls NVGPR
      save/restore itself on the way in and out.
    
    - The heavy idle wakeup KVM request check can be moved out of the
      normal host idle code and into the not-performance-critical offline
      code.
    
    - KVM nap code now returns from where it is called, which makes the
      flow a bit easier to follow.
    
    Reviewed-by: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Squash the KVM changes in]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c5b2aff0ce8e..10caa145f98b 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -168,6 +168,7 @@
 #define PSSCR_ESL		0x00200000 /* Enable State Loss */
 #define PSSCR_SD		0x00400000 /* Status Disable */
 #define PSSCR_PLS	0xf000000000000000 /* Power-saving Level Status */
+#define PSSCR_PLS_SHIFT	60
 #define PSSCR_GUEST_VIS	0xf0000000000003ffUL /* Guest-visible PSSCR fields */
 #define PSSCR_FAKE_SUSPEND	0x00000400 /* Fake-suspend bit (P9 DD2.2) */
 #define PSSCR_FAKE_SUSPEND_LG	10	   /* Fake-suspend bit position */
@@ -758,10 +759,9 @@
 #define	  SRR1_WAKERESET	0x00100000 /* System reset */
 #define   SRR1_WAKEHDBELL	0x000c0000 /* Hypervisor doorbell on P8 */
 #define	  SRR1_WAKESTATE	0x00030000 /* Powersave exit mask [46:47] */
-#define	  SRR1_WS_DEEPEST	0x00030000 /* Some resources not maintained,
-					  * may not be recoverable */
-#define	  SRR1_WS_DEEPER	0x00020000 /* Some resources not maintained */
-#define	  SRR1_WS_DEEP		0x00010000 /* All resources maintained */
+#define	  SRR1_WS_HVLOSS	0x00030000 /* HV resources not maintained */
+#define	  SRR1_WS_GPRLOSS	0x00020000 /* GPRs not maintained */
+#define	  SRR1_WS_NOLOSS	0x00010000 /* All resources maintained */
 #define   SRR1_PROGTM		0x00200000 /* TM Bad Thing */
 #define   SRR1_PROGFPE		0x00100000 /* Floating Point Enabled */
 #define   SRR1_PROGILL		0x00080000 /* Illegal instruction */

commit 4e67bfd7aa21b4b737a43df627956dba9c742983
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Jan 17 23:25:53 2019 +1100

    powerpc: Update comments in preparation for THREAD_INFO_IN_TASK
    
    Update a few comments that talk about current_thread_info() in
    preparation for THREAD_INFO_IN_TASK.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Split out of larger patch]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c25880e6a16a..c5b2aff0ce8e 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1062,7 +1062,7 @@
  *	- SPRG9 debug exception scratch
  *
  * All 32-bit:
- *	- SPRG3 current thread_info pointer
+ *	- SPRG3 current thread_struct physical addr pointer
  *        (virtual on BookE, physical on others)
  *
  * 32-bit classic:

commit 02d5d13b4544dff5fc0c0aa0179085ed52b72ecd
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Feb 21 19:08:44 2019 +0000

    powerpc/32: add helper to write into segment registers
    
    This patch add an helper which wraps 'mtsrin' instruction
    to write into segment registers.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 1f79e1d8fb0b..c25880e6a16a 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1425,6 +1425,11 @@ static inline void msr_check_and_clear(unsigned long bits)
 #define mfsrin(v)	({unsigned int rval; \
 			asm volatile("mfsrin %0,%1" : "=r" (rval) : "r" (v)); \
 					rval;})
+
+static inline void mtsrin(u32 val, u32 idx)
+{
+	asm volatile("mtsrin %0, %1" : : "r" (val), "r" (idx));
+}
 #endif
 
 #define proc_trap()	asm volatile("trap")

commit 93c4a162b014d238a287f8264adb25c009c79e61
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Feb 21 10:37:55 2019 +0000

    powerpc/6xx: Store PGDIR physical address in a SPRG
    
    Use SPRN_SPRG2 to store the current thread PGDIR and
    avoid reading thread_struct.pgdir at every TLB miss.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 371ef6e8248e..1f79e1d8fb0b 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1167,6 +1167,7 @@
 #ifdef CONFIG_PPC_BOOK3S_32
 #define SPRN_SPRG_SCRATCH0	SPRN_SPRG0
 #define SPRN_SPRG_SCRATCH1	SPRN_SPRG1
+#define SPRN_SPRG_PGDIR		SPRN_SPRG2
 #define SPRN_SPRG_603_LRU	SPRN_SPRG4
 #endif
 

commit 0df977eafc792a5365a7f81d8d5920132e03afad
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Feb 21 10:37:54 2019 +0000

    powerpc/6xx: Don't use SPRN_SPRG2 for storing stack pointer while in RTAS
    
    When calling RTAS, the stack pointer is stored in SPRN_SPRG2
    in order to be able to restore it in case of machine check in RTAS.
    
    As machine check is not a perfomance critical path, this patch
    frees SPRN_SPRG2 by using a field in thread struct instead.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 1c98ef1f2d5b..371ef6e8248e 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1167,7 +1167,6 @@
 #ifdef CONFIG_PPC_BOOK3S_32
 #define SPRN_SPRG_SCRATCH0	SPRN_SPRG0
 #define SPRN_SPRG_SCRATCH1	SPRN_SPRG1
-#define SPRN_SPRG_RTAS		SPRN_SPRG2
 #define SPRN_SPRG_603_LRU	SPRN_SPRG4
 #endif
 

commit 0deae39cec6dab3a66794f3e9e83ca4dc30080f1
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Mon Dec 10 11:41:29 2018 +0000

    powerpc/83xx: handle machine check caused by watchdog timer
    
    When the watchdog timer is set in interrupt mode, it causes a
    machine check when it times out. The purpose of this mode is to
    ease debugging, not to crash the kernel and reboot the machine.
    
    This patch implements a special handling for that, in order to not
    crash the kernel if the watchdog times out while in interrupt or
    within the idle task.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    [scottwood: added missing #include]
    Signed-off-by: Scott Wood <oss@buserror.net>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 0d2139a0d5b9..1c98ef1f2d5b 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -769,6 +769,8 @@
 #define   SRR1_PROGTRAP		0x00020000 /* Trap */
 #define   SRR1_PROGADDR		0x00010000 /* SRR0 contains subsequent addr */
 
+#define   SRR1_MCE_MCP		0x00080000 /* Machine check signal caused interrupt */
+
 #define SPRN_HSRR0	0x13A	/* Save/Restore Register 0 */
 #define SPRN_HSRR1	0x13B	/* Save/Restore Register 1 */
 #define   HSRR1_DENORM		0x00100000 /* Denorm exception */

commit d7cceda96badc1bd444cff27ab9c375a1277c1e3
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Sat Nov 17 10:24:56 2018 +0000

    powerpc: change CONFIG_6xx to CONFIG_PPC_BOOK3S_32
    
    Today we have:
    
    config PPC_BOOK3S_32
            bool "512x/52xx/6xx/7xx/74xx/82xx/83xx/86xx"
            [depends on PPC32 within a choice]
    
    config PPC_BOOK3S
            def_bool y
            depends on PPC_BOOK3S_32 || PPC_BOOK3S_64
    
    config 6xx
            def_bool y
            depends on PPC32 && PPC_BOOK3S
    
    6xx is therefore redundant with PPC_BOOK3S_32.
    
    In order to make the code clearer, lets use preferably PPC_BOOK3S_32.
    This will allow to remove CONFIG_6xx in a later patch.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index de52c3166ba4..0d2139a0d5b9 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -582,7 +582,7 @@
 #define HID0_POWER9_RADIX	__MASK(63 - 8)
 
 #define SPRN_HID1	0x3F1		/* Hardware Implementation Register 1 */
-#ifdef CONFIG_6xx
+#ifdef CONFIG_PPC_BOOK3S_32
 #define HID1_EMCP	(1<<31)		/* 7450 Machine Check Pin Enable */
 #define HID1_DFS	(1<<22)		/* 7447A Dynamic Frequency Scaling */
 #define HID1_PC0	(1<<16)		/* 7450 PLL_CFG[0] */

commit 685f7e4f161425b137056abe35ba8ef7b669d83d
Merge: c7a2c49ea6c9 58cfbac25b1f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 26 14:36:21 2018 -0700

    Merge tag 'powerpc-4.20-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Notable changes:
    
       - A large series to rewrite our SLB miss handling, replacing a lot of
         fairly complicated asm with much fewer lines of C.
    
       - Following on from that, we now maintain a cache of SLB entries for
         each process and preload them on context switch. Leading to a 27%
         speedup for our context switch benchmark on Power9.
    
       - Improvements to our handling of SLB multi-hit errors. We now print
         more debug information when they occur, and try to continue running
         by flushing the SLB and reloading, rather than treating them as
         fatal.
    
       - Enable THP migration on 64-bit Book3S machines (eg. Power7/8/9).
    
       - Add support for physical memory up to 2PB in the linear mapping on
         64-bit Book3S. We only support up to 512TB as regular system
         memory, otherwise the percpu allocator runs out of vmalloc space.
    
       - Add stack protector support for 32 and 64-bit, with a per-task
         canary.
    
       - Add support for PTRACE_SYSEMU and PTRACE_SYSEMU_SINGLESTEP.
    
       - Support recognising "big cores" on Power9, where two SMT4 cores are
         presented to us as a single SMT8 core.
    
       - A large series to cleanup some of our ioremap handling and PTE
         flags.
    
       - Add a driver for the PAPR SCM (storage class memory) interface,
         allowing guests to operate on SCM devices (acked by Dan).
    
       - Changes to our ftrace code to handle very large kernels, where we
         need to use a trampoline to get to ftrace_caller().
    
      And many other smaller enhancements and cleanups.
    
      Thanks to: Alan Modra, Alistair Popple, Aneesh Kumar K.V, Anton
      Blanchard, Aravinda Prasad, Bartlomiej Zolnierkiewicz, Benjamin
      Herrenschmidt, Breno Leitao, Cédric Le Goater, Christophe Leroy,
      Christophe Lombard, Dan Carpenter, Daniel Axtens, Finn Thain, Gautham
      R. Shenoy, Gustavo Romero, Haren Myneni, Hari Bathini, Jia Hongtao,
      Joel Stanley, John Allen, Laurent Dufour, Madhavan Srinivasan, Mahesh
      Salgaonkar, Mark Hairgrove, Masahiro Yamada, Michael Bringmann,
      Michael Neuling, Michal Suchanek, Murilo Opsfelder Araujo, Nathan
      Fontenot, Naveen N. Rao, Nicholas Piggin, Nick Desaulniers, Oliver
      O'Halloran, Paul Mackerras, Petr Vorel, Rashmica Gupta, Reza Arbab,
      Rob Herring, Sam Bobroff, Samuel Mendoza-Jonas, Scott Wood, Stan
      Johnson, Stephen Rothwell, Stewart Smith, Suraj Jitindar Singh, Tyrel
      Datwyler, Vaibhav Jain, Vasant Hegde, YueHaibing, zhong jiang"
    
    * tag 'powerpc-4.20-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (221 commits)
      Revert "selftests/powerpc: Fix out-of-tree build errors"
      powerpc/msi: Fix compile error on mpc83xx
      powerpc: Fix stack protector crashes on CPU hotplug
      powerpc/traps: restore recoverability of machine_check interrupts
      powerpc/64/module: REL32 relocation range check
      powerpc/64s/radix: Fix radix__flush_tlb_collapsed_pmd double flushing pmd
      selftests/powerpc: Add a test of wild bctr
      powerpc/mm: Fix page table dump to work on Radix
      powerpc/mm/radix: Display if mappings are exec or not
      powerpc/mm/radix: Simplify split mapping logic
      powerpc/mm/radix: Remove the retry in the split mapping logic
      powerpc/mm/radix: Fix small page at boundary when splitting
      powerpc/mm/radix: Fix overuse of small pages in splitting logic
      powerpc/mm/radix: Fix off-by-one in split mapping logic
      powerpc/ftrace: Handle large kernel configs
      powerpc/mm: Fix WARN_ON with THP NUMA migration
      selftests/powerpc: Fix out-of-tree build errors
      powerpc/time: no steal_time when CONFIG_PPC_SPLPAR is not selected
      powerpc/time: Only set CONFIG_ARCH_HAS_SCALED_CPUTIME on PPC64
      powerpc/time: isolate scaled cputime accounting in dedicated functions.
      ...

commit 73937deb4b2d7f08ac48e9125de889c757a7a9b3
Author: Suraj Jitindar Singh <sjitindarsingh@gmail.com>
Date:   Mon Oct 8 16:31:14 2018 +1100

    KVM: PPC: Book3S HV: Sanitise hv_regs on nested guest entry
    
    restore_hv_regs() is used to copy the hv_regs L1 wants to set to run the
    nested (L2) guest into the vcpu structure. We need to sanitise these
    values to ensure we don't let the L1 guest hypervisor do things we don't
    want it to.
    
    We don't let data address watchpoints or completed instruction address
    breakpoints be set to match in hypervisor state.
    
    We also don't let L1 enable features in the hypervisor facility status
    and control register (HFSCR) for L2 which we have disabled for L1. That
    is L2 will get the subset of features which the L0 hypervisor has
    enabled for L1 and the features L1 wants to enable for L2. This could
    mean we give L1 a hypervisor facility unavailable interrupt for a
    facility it thinks it has enabled, however it shouldn't have enabled a
    facility it itself doesn't have for the L2 guest.
    
    We sanitise the registers when copying in the L2 hv_regs. We don't need
    to sanitise when copying back the L1 hv_regs since these shouldn't be
    able to contain invalid values as they're just what was copied out.
    
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Suraj Jitindar Singh <sjitindarsingh@gmail.com>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 6fda746ba328..c90698972f42 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -415,6 +415,7 @@
 #define   HFSCR_DSCR	__MASK(FSCR_DSCR_LG)
 #define   HFSCR_VECVSX	__MASK(FSCR_VECVSX_LG)
 #define   HFSCR_FP	__MASK(FSCR_FP_LG)
+#define   HFSCR_INTR_CAUSE (ASM_CONST(0xFF) << 56)	/* interrupt cause */
 #define SPRN_TAR	0x32f	/* Target Address Register */
 #define SPRN_LPCR	0x13E	/* LPAR Control Register */
 #define   LPCR_VPM0		ASM_CONST(0x8000000000000000)

commit 32eb150aee8dce5076638ebafe53732276c9f28e
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Mon Oct 8 16:30:56 2018 +1100

    KVM: PPC: Book3S HV: Handle hypervisor instruction faults better
    
    Currently the code for handling hypervisor instruction page faults
    passes 0 for the flags indicating the type of fault, which is OK in
    the usual case that the page is not mapped in the partition-scoped
    page tables.  However, there are other causes for hypervisor
    instruction page faults, such as not being to update a reference
    (R) or change (C) bit.  The cause is indicated in bits in HSRR1,
    including a bit which indicates that the fault is due to not being
    able to write to a page (for example to update an R or C bit).
    Not handling these other kinds of faults correctly can lead to a
    loop of continual faults without forward progress in the guest.
    
    In order to handle these faults better, this patch constructs a
    "DSISR-like" value from the bits which DSISR and SRR1 (for a HISI)
    have in common, and passes it to kvmppc_book3s_hv_page_fault() so
    that it knows what caused the fault.
    
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index e5b314ed054e..6fda746ba328 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -766,6 +766,7 @@
 #define SPRN_HSRR0	0x13A	/* Save/Restore Register 0 */
 #define SPRN_HSRR1	0x13B	/* Save/Restore Register 1 */
 #define   HSRR1_DENORM		0x00100000 /* Denorm exception */
+#define   HSRR1_HISI_WRITE	0x00010000 /* HISI bcs couldn't update mem */
 
 #define SPRN_TBCTL	0x35f	/* PA6T Timebase control register */
 #define   TBCTL_FREEZE		0x0000000000000000ull /* Freeze all tbs */

commit 5c784c8414fba11b62e12439f11e109fb5751f38
Author: Breno Leitao <leitao@debian.org>
Date:   Thu Aug 16 14:21:07 2018 -0300

    powerpc/tm: Remove msr_tm_active()
    
    Currently msr_tm_active() is a wrapper around MSR_TM_ACTIVE() if
    CONFIG_PPC_TRANSACTIONAL_MEM is set, or it is just a function that
    returns false if CONFIG_PPC_TRANSACTIONAL_MEM is not set.
    
    This function is not necessary, since MSR_TM_ACTIVE() just do the same and
    could be used, removing the dualism and simplifying the code.
    
    This patchset remove every instance of msr_tm_active() and replaced it
    by MSR_TM_ACTIVE().
    
    Signed-off-by: Breno Leitao <leitao@debian.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index e5b314ed054e..640a4d818772 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -118,11 +118,16 @@
 #define MSR_TS_S	__MASK(MSR_TS_S_LG)	/*  Transaction Suspended */
 #define MSR_TS_T	__MASK(MSR_TS_T_LG)	/*  Transaction Transactional */
 #define MSR_TS_MASK	(MSR_TS_T | MSR_TS_S)   /* Transaction State bits */
-#define MSR_TM_ACTIVE(x) (((x) & MSR_TS_MASK) != 0) /* Transaction active? */
 #define MSR_TM_RESV(x) (((x) & MSR_TS_MASK) == MSR_TS_MASK) /* Reserved */
 #define MSR_TM_TRANSACTIONAL(x)	(((x) & MSR_TS_MASK) == MSR_TS_T)
 #define MSR_TM_SUSPENDED(x)	(((x) & MSR_TS_MASK) == MSR_TS_S)
 
+#ifdef CONFIG_PPC_TRANSACTIONAL_MEM
+#define MSR_TM_ACTIVE(x) (((x) & MSR_TS_MASK) != 0) /* Transaction active? */
+#else
+#define MSR_TM_ACTIVE(x) 0
+#endif
+
 #if defined(CONFIG_PPC_BOOK3S_64)
 #define MSR_64BIT	MSR_SF
 

commit e61cf2e3a5b452cfefcb145021f5a8ea88735cc1
Merge: 1009aa1205c2 28a1f3ac1d0c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Aug 19 10:38:36 2018 -0700

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull first set of KVM updates from Paolo Bonzini:
     "PPC:
       - minor code cleanups
    
      x86:
       - PCID emulation and CR3 caching for shadow page tables
       - nested VMX live migration
       - nested VMCS shadowing
       - optimized IPI hypercall
       - some optimizations
    
      ARM will come next week"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (85 commits)
      kvm: x86: Set highest physical address bits in non-present/reserved SPTEs
      KVM/x86: Use CC_SET()/CC_OUT in arch/x86/kvm/vmx.c
      KVM: X86: Implement PV IPIs in linux guest
      KVM: X86: Add kvm hypervisor init time platform setup callback
      KVM: X86: Implement "send IPI" hypercall
      KVM/x86: Move X86_CR4_OSXSAVE check into kvm_valid_sregs()
      KVM: x86: Skip pae_root shadow allocation if tdp enabled
      KVM/MMU: Combine flushing remote tlb in mmu_set_spte()
      KVM: vmx: skip VMWRITE of HOST_{FS,GS}_BASE when possible
      KVM: vmx: skip VMWRITE of HOST_{FS,GS}_SEL when possible
      KVM: vmx: always initialize HOST_{FS,GS}_BASE to zero during setup
      KVM: vmx: move struct host_state usage to struct loaded_vmcs
      KVM: vmx: compute need to reload FS/GS/LDT on demand
      KVM: nVMX: remove a misleading comment regarding vmcs02 fields
      KVM: vmx: rename __vmx_load_host_state() and vmx_save_host_state()
      KVM: vmx: add dedicated utility to access guest's kernel_gs_base
      KVM: vmx: track host_state.loaded using a loaded_vmcs pointer
      KVM: vmx: refactor segmentation code in vmx_save_host_state()
      kvm: nVMX: Fix fault priority for VMX operations
      kvm: nVMX: Fix fault vector for VMX operation at CPL > 0
      ...

commit 2c86cd188f8a5631f3d75a1dea14d22df85189b4
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Jul 5 16:25:01 2018 +0000

    powerpc: clean inclusions of asm/feature-fixups.h
    
    files not using feature fixup don't need asm/feature-fixups.h
    files using feature fixup need asm/feature-fixups.h
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index d4a8dc71a057..486b7c83b8c5 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -14,6 +14,7 @@
 #include <linux/stringify.h>
 #include <asm/cputable.h>
 #include <asm/asm-const.h>
+#include <asm/feature-fixups.h>
 
 /* Pickup Book E specific registers. */
 #if defined(CONFIG_BOOKE) || defined(CONFIG_40x)

commit ec0c464cdbf38bf6ddabec8bfa595bd421cab203
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Jul 5 16:24:57 2018 +0000

    powerpc: move ASM_CONST and stringify_in_c() into asm-const.h
    
    This patch moves ASM_CONST() and stringify_in_c() into
    dedicated asm-const.h, then cleans all related inclusions.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    [mpe: asm-compat.h should include asm-const.h]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 562568414cf4..d4a8dc71a057 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -13,6 +13,7 @@
 
 #include <linux/stringify.h>
 #include <asm/cputable.h>
+#include <asm/asm-const.h>
 
 /* Pickup Book E specific registers. */
 #if defined(CONFIG_BOOKE) || defined(CONFIG_40x)

commit 0abb75b7a16d21e2fb0d98634df44c37c184f186
Author: Nicholas Mc Guire <hofrat@osadl.org>
Date:   Sat Jul 7 11:07:25 2018 +0200

    KVM: PPC: Book3S HV: Fix constant size warning
    
    The constants are 64bit but not explicitly declared UL resulting
    in sparse warnings. Fix this by declaring the constants UL.
    
    Signed-off-by: Nicholas Mc Guire <hofrat@osadl.org>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 562568414cf4..858aa7984ab0 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -161,7 +161,7 @@
 #define PSSCR_ESL		0x00200000 /* Enable State Loss */
 #define PSSCR_SD		0x00400000 /* Status Disable */
 #define PSSCR_PLS	0xf000000000000000 /* Power-saving Level Status */
-#define PSSCR_GUEST_VIS	0xf0000000000003ff /* Guest-visible PSSCR fields */
+#define PSSCR_GUEST_VIS	0xf0000000000003ffUL /* Guest-visible PSSCR fields */
 #define PSSCR_FAKE_SUSPEND	0x00000400 /* Fake-suspend bit (P9 DD2.2) */
 #define PSSCR_FAKE_SUSPEND_LG	10	   /* Fake-suspend bit position */
 

commit 43b812d9ab21bb212542ae2cfcdf1be877f279ca
Merge: 7b0e827c6970 eacbb218fbba
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Thu May 31 09:27:10 2018 +1000

    Merge remote-tracking branch 'remotes/powerpc/topic/ppc-kvm' into kvm-ppc-next
    
    This merges in the ppc-kvm topic branch of the powerpc repository
    to get some changes on which future patches will depend, in particular
    some new exports and TEXASR bit definitions.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

commit ab3759b5734544dd1430527c3d89730990cfa4bb
Author: Simon Guo <wei.guo.simon@gmail.com>
Date:   Wed May 23 15:01:45 2018 +0800

    powerpc/reg: Add TEXASR related macros
    
    This patches add some macros for CR0/TEXASR bits so that PR KVM TM
    logic (tbegin./treclaim./tabort.) can make use of them later.
    
    Signed-off-by: Simon Guo <wei.guo.simon@gmail.com>
    Reviewed-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index cb0f272ce123..75c5b2cd9d66 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -146,6 +146,12 @@
 #define MSR_64BIT	0
 #endif
 
+/* Condition Register related */
+#define CR0_SHIFT	28
+#define CR0_MASK	0xF
+#define CR0_TBEGIN_FAILURE	(0x2 << 28) /* 0b0010 */
+
+
 /* Power Management - Processor Stop Status and Control Register Fields */
 #define PSSCR_RL_MASK		0x0000000F /* Requested Level */
 #define PSSCR_MTL_MASK		0x000000F0 /* Maximum Transition Level */
@@ -239,13 +245,27 @@
 #define SPRN_TFIAR	0x81	/* Transaction Failure Inst Addr   */
 #define SPRN_TEXASR	0x82	/* Transaction EXception & Summary */
 #define SPRN_TEXASRU	0x83	/* ''	   ''	   ''	 Upper 32  */
-#define   TEXASR_ABORT	__MASK(63-31) /* terminated by tabort or treclaim */
-#define   TEXASR_SUSP	__MASK(63-32) /* tx failed in suspended state */
-#define   TEXASR_HV	__MASK(63-34) /* MSR[HV] when failure occurred */
-#define   TEXASR_PR	__MASK(63-35) /* MSR[PR] when failure occurred */
-#define   TEXASR_FS	__MASK(63-36) /* TEXASR Failure Summary */
-#define   TEXASR_EXACT	__MASK(63-37) /* TFIAR value is exact */
+
+#define TEXASR_FC_LG	(63 - 7)	/* Failure Code */
+#define TEXASR_AB_LG	(63 - 31)	/* Abort */
+#define TEXASR_SU_LG	(63 - 32)	/* Suspend */
+#define TEXASR_HV_LG	(63 - 34)	/* Hypervisor state*/
+#define TEXASR_PR_LG	(63 - 35)	/* Privilege level */
+#define TEXASR_FS_LG	(63 - 36)	/* failure summary */
+#define TEXASR_EX_LG	(63 - 37)	/* TFIAR exact bit */
+#define TEXASR_ROT_LG	(63 - 38)	/* ROT bit */
+
+#define   TEXASR_ABORT	__MASK(TEXASR_AB_LG) /* terminated by tabort or treclaim */
+#define   TEXASR_SUSP	__MASK(TEXASR_SU_LG) /* tx failed in suspended state */
+#define   TEXASR_HV	__MASK(TEXASR_HV_LG) /* MSR[HV] when failure occurred */
+#define   TEXASR_PR	__MASK(TEXASR_PR_LG) /* MSR[PR] when failure occurred */
+#define   TEXASR_FS	__MASK(TEXASR_FS_LG) /* TEXASR Failure Summary */
+#define   TEXASR_EXACT	__MASK(TEXASR_EX_LG) /* TFIAR value is exact */
+#define   TEXASR_ROT	__MASK(TEXASR_ROT_LG)
+#define   TEXASR_FC	(ASM_CONST(0xFF) << TEXASR_FC_LG)
+
 #define SPRN_TFHAR	0x80	/* Transaction Failure Handler Addr */
+
 #define SPRN_TIDR	144	/* Thread ID register */
 #define SPRN_CTRLF	0x088
 #define SPRN_CTRLT	0x098

commit 7aa15842c15f8a32000372ad2b3195029fde6fd4
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Fri Apr 20 19:53:22 2018 +1000

    KVM: PPC: Book3S HV: Set RWMR on POWER8 so PURR/SPURR count correctly
    
    Although Linux doesn't use PURR and SPURR ((Scaled) Processor
    Utilization of Resources Register), other OSes depend on them.
    On POWER8 they count at a rate depending on whether the VCPU is
    idle or running, the activity of the VCPU, and the value in the
    RWMR (Region-Weighting Mode Register).  Hardware expects the
    hypervisor to update the RWMR when a core is dispatched to reflect
    the number of online VCPUs in the vcore.
    
    This adds code to maintain a count in the vcore struct indicating
    how many VCPUs are online.  In kvmppc_run_core we use that count
    to set the RWMR register on POWER8.  If the core is split because
    of a static or dynamic micro-threading mode, we use the value for
    8 threads.  The RWMR value is not relevant when the host is
    executing because Linux does not use the PURR or SPURR register,
    so we don't bother saving and restoring the host value.
    
    For the sake of old userspace which does not set the KVM_REG_PPC_ONLINE
    register, we set online to 1 if it was 0 at the time of a KVM_RUN
    ioctl.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index cb0f272ce123..44b2be4a65d1 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -365,6 +365,7 @@
 #define SPRN_PSSCR	0x357	/* Processor Stop Status and Control Register (ISA 3.0) */
 #define SPRN_PSSCR_PR	0x337	/* PSSCR ISA 3.0, privileged mode access */
 #define SPRN_PMCR	0x374	/* Power Management Control Register */
+#define SPRN_RWMR	0x375	/* Region-Weighting Mode Register */
 
 /* HFSCR and FSCR bit numbers are the same */
 #define FSCR_SCV_LG	12	/* Enable System Call Vectored */

commit 4bb3c7a0208fc13ca70598efd109901a7cd45ae7
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Wed Mar 21 21:32:01 2018 +1100

    KVM: PPC: Book3S HV: Work around transactional memory bugs in POWER9
    
    POWER9 has hardware bugs relating to transactional memory and thread
    reconfiguration (changes to hardware SMT mode).  Specifically, the core
    does not have enough storage to store a complete checkpoint of all the
    architected state for all four threads.  The DD2.2 version of POWER9
    includes hardware modifications designed to allow hypervisor software
    to implement workarounds for these problems.  This patch implements
    those workarounds in KVM code so that KVM guests see a full, working
    transactional memory implementation.
    
    The problems center around the use of TM suspended state, where the
    CPU has a checkpointed state but execution is not transactional.  The
    workaround is to implement a "fake suspend" state, which looks to the
    guest like suspended state but the CPU does not store a checkpoint.
    In this state, any instruction that would cause a transition to
    transactional state (rfid, rfebb, mtmsrd, tresume) or would use the
    checkpointed state (treclaim) causes a "soft patch" interrupt (vector
    0x1500) to the hypervisor so that it can be emulated.  The trechkpt
    instruction also causes a soft patch interrupt.
    
    On POWER9 DD2.2, we avoid returning to the guest in any state which
    would require a checkpoint to be present.  The trechkpt in the guest
    entry path which would normally create that checkpoint is replaced by
    either a transition to fake suspend state, if the guest is in suspend
    state, or a rollback to the pre-transactional state if the guest is in
    transactional state.  Fake suspend state is indicated by a flag in the
    PACA plus a new bit in the PSSCR.  The new PSSCR bit is write-only and
    reads back as 0.
    
    On exit from the guest, if the guest is in fake suspend state, we still
    do the treclaim instruction as we would in real suspend state, in order
    to get into non-transactional state, but we do not save the resulting
    register state since there was no checkpoint.
    
    Emulation of the instructions that cause a softpatch interrupt is
    handled in two paths.  If the guest is in real suspend mode, we call
    kvmhv_p9_tm_emulation_early() to handle the cases where the guest is
    transitioning to transactional state.  This is called before we do the
    treclaim in the guest exit path; because we haven't done treclaim, we
    can get back to the guest with the transaction still active.  If the
    instruction is a case that kvmhv_p9_tm_emulation_early() doesn't
    handle, or if the guest is in fake suspend state, then we proceed to
    do the complete guest exit path and subsequently call
    kvmhv_p9_tm_emulation() in host context with the MMU on.  This handles
    all the cases including the cases that generate program interrupts
    (illegal instruction or TM Bad Thing) and facility unavailable
    interrupts.
    
    The emulation is reasonably straightforward and is mostly concerned
    with checking for exception conditions and updating the state of
    registers such as MSR and CR0.  The treclaim emulation takes care to
    ensure that the TEXASR register gets updated as if it were the guest
    treclaim instruction that had done failure recording, not the treclaim
    done in hypervisor state in the guest exit path.
    
    With this, the KVM_CAP_PPC_HTM capability returns true (1) even if
    transactional memory is not available to host userspace.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index e6c7eadf6bce..cb0f272ce123 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -156,6 +156,8 @@
 #define PSSCR_SD		0x00400000 /* Status Disable */
 #define PSSCR_PLS	0xf000000000000000 /* Power-saving Level Status */
 #define PSSCR_GUEST_VIS	0xf0000000000003ff /* Guest-visible PSSCR fields */
+#define PSSCR_FAKE_SUSPEND	0x00000400 /* Fake-suspend bit (P9 DD2.2) */
+#define PSSCR_FAKE_SUSPEND_LG	10	   /* Fake-suspend bit position */
 
 /* Floating Point Status and Control Register (FPSCR) Fields */
 #define FPSCR_FX	0x80000000	/* FPU exception summary */
@@ -237,7 +239,12 @@
 #define SPRN_TFIAR	0x81	/* Transaction Failure Inst Addr   */
 #define SPRN_TEXASR	0x82	/* Transaction EXception & Summary */
 #define SPRN_TEXASRU	0x83	/* ''	   ''	   ''	 Upper 32  */
+#define   TEXASR_ABORT	__MASK(63-31) /* terminated by tabort or treclaim */
+#define   TEXASR_SUSP	__MASK(63-32) /* tx failed in suspended state */
+#define   TEXASR_HV	__MASK(63-34) /* MSR[HV] when failure occurred */
+#define   TEXASR_PR	__MASK(63-35) /* MSR[PR] when failure occurred */
 #define   TEXASR_FS	__MASK(63-36) /* TEXASR Failure Summary */
+#define   TEXASR_EXACT	__MASK(63-37) /* TFIAR value is exact */
 #define SPRN_TFHAR	0x80	/* Transaction Failure Handler Addr */
 #define SPRN_TIDR	144	/* Thread ID register */
 #define SPRN_CTRLF	0x088

commit 5400fc229e6078a6964b15fb98e9a994df3d642a
Merge: 02ef6dd8109b 76b03dc07eeb
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Sun Jan 21 22:43:43 2018 +1100

    Merge branch 'topic/ppc-kvm' into next
    
    Merge the topic branch we share with kvm-ppc, this brings in two xive
    commits, one from Paul to rework HMI handling, and a minor cleanup to
    drop an unused flag.

commit e6c2a4797e101a25eced94aa9e1fc42c30247aec
Author: Ram Pai <linuxram@us.ibm.com>
Date:   Thu Jan 18 17:50:40 2018 -0800

    powerpc: Handle exceptions caused by pkey violation
    
    Handle Data and  Instruction exceptions caused by memory
    protection-key.
    
    The CPU will detect the key fault if the HPTE is already
    programmed with the key.
    
    However if the HPTE is not  hashed, a key fault will not
    be detected by the hardware. The software will detect
    pkey violation in such a case.
    
    Signed-off-by: Ram Pai <linuxram@us.ibm.com>
    Signed-off-by: Thiago Jung Bauermann <bauerman@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index b779f3ccd412..ffc9990e8040 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -312,7 +312,6 @@
 				 DSISR_BAD_EXT_CTRL)
 #define	  DSISR_BAD_FAULT_64S	(DSISR_BAD_FAULT_32S	| \
 				 DSISR_ATTR_CONFLICT	| \
-				 DSISR_KEYFAULT		| \
 				 DSISR_UNSUPP_MMU	| \
 				 DSISR_PRTABLE_FAULT	| \
 				 DSISR_ICSWX_NO_CT	| \

commit d075745d893c78730e4a3b7a60fca23c2f764081
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Wed Jan 17 20:51:13 2018 +1100

    KVM: PPC: Book3S HV: Improve handling of debug-trigger HMIs on POWER9
    
    Hypervisor maintenance interrupts (HMIs) are generated by various
    causes, signalled by bits in the hypervisor maintenance exception
    register (HMER).  In most cases calling OPAL to handle the interrupt
    is the correct thing to do, but the "debug trigger" HMIs signalled by
    PPC bit 17 (bit 46) of HMER are used to invoke software workarounds
    for hardware bugs, and OPAL does not have any code to handle this
    cause.  The debug trigger HMI is used in POWER9 DD2.0 and DD2.1 chips
    to work around a hardware bug in executing vector load instructions to
    cache inhibited memory.  In POWER9 DD2.2 chips, it is generated when
    conditions are detected relating to threads being in TM (transactional
    memory) suspended mode when the core SMT configuration needs to be
    reconfigured.
    
    The kernel currently has code to detect the vector CI load condition,
    but only when the HMI occurs in the host, not when it occurs in a
    guest.  If a HMI occurs in the guest, it is always passed to OPAL, and
    then we always re-sync the timebase, because the HMI cause might have
    been a timebase error, for which OPAL would re-sync the timebase, thus
    removing the timebase offset which KVM applied for the guest.  Since
    we don't know what OPAL did, we don't know whether to subtract the
    timebase offset from the timebase, so instead we re-sync the timebase.
    
    This adds code to determine explicitly what the cause of a debug
    trigger HMI will be.  This is based on a new device-tree property
    under the CPU nodes called ibm,hmi-special-triggers, if it is
    present, or otherwise based on the PVR (processor version register).
    The handling of debug trigger HMIs is pulled out into a separate
    function which can be called from the KVM guest exit code.  If this
    function handles and clears the HMI, and no other HMI causes remain,
    then we skip calling OPAL and we proceed to subtract the guest
    timebase offset from the timebase.
    
    The overall handling for HMIs that occur in the host (i.e. not in a
    KVM guest) is largely unchanged, except that we now don't set the flag
    for the vector CI load workaround on DD2.2 processors.
    
    This also removes a BUG_ON in the KVM code.  BUG_ON is generally not
    useful in KVM guest entry/exit code since it is difficult to handle
    the resulting trap gracefully.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index b779f3ccd412..14e41b843952 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -432,8 +432,9 @@
 #define SPRN_LPID	0x13F	/* Logical Partition Identifier */
 #endif
 #define   LPID_RSVD	0x3ff		/* Reserved LPID for partn switching */
-#define	SPRN_HMER	0x150	/* Hardware m? error recovery */
-#define	SPRN_HMEER	0x151	/* Hardware m? enable error recovery */
+#define	SPRN_HMER	0x150	/* Hypervisor maintenance exception reg */
+#define   HMER_DEBUG_TRIG	(1ul << (63 - 17)) /* Debug trigger */
+#define	SPRN_HMEER	0x151	/* Hyp maintenance exception enable reg */
 #define SPRN_PCR	0x152	/* Processor compatibility register */
 #define   PCR_VEC_DIS	(1ul << (63-0))	/* Vec. disable (bit NA since POWER8) */
 #define   PCR_VSX_DIS	(1ul << (63-1))	/* VSX disable (bit NA since POWER8) */

commit b24413180f5600bcb3bb70fbed5cf186b60864bd
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 1 15:07:57 2017 +0100

    License cleanup: add SPDX GPL-2.0 license identifier to files with no license
    
    Many source files in the tree are missing licensing information, which
    makes it harder for compliance tools to determine the correct license.
    
    By default all files without license information are under the default
    license of the kernel, which is GPL version 2.
    
    Update the files which contain no license information with the 'GPL-2.0'
    SPDX license identifier.  The SPDX identifier is a legally binding
    shorthand, which can be used instead of the full boiler plate text.
    
    This patch is based on work done by Thomas Gleixner and Kate Stewart and
    Philippe Ombredanne.
    
    How this work was done:
    
    Patches were generated and checked against linux-4.14-rc6 for a subset of
    the use cases:
     - file had no licensing information it it.
     - file was a */uapi/* one with no licensing information in it,
     - file was a */uapi/* one with existing licensing information,
    
    Further patches will be generated in subsequent months to fix up cases
    where non-standard license headers were used, and references to license
    had to be inferred by heuristics based on keywords.
    
    The analysis to determine which SPDX License Identifier to be applied to
    a file was done in a spreadsheet of side by side results from of the
    output of two independent scanners (ScanCode & Windriver) producing SPDX
    tag:value files created by Philippe Ombredanne.  Philippe prepared the
    base worksheet, and did an initial spot review of a few 1000 files.
    
    The 4.13 kernel was the starting point of the analysis with 60,537 files
    assessed.  Kate Stewart did a file by file comparison of the scanner
    results in the spreadsheet to determine which SPDX license identifier(s)
    to be applied to the file. She confirmed any determination that was not
    immediately clear with lawyers working with the Linux Foundation.
    
    Criteria used to select files for SPDX license identifier tagging was:
     - Files considered eligible had to be source code files.
     - Make and config files were included as candidates if they contained >5
       lines of source
     - File already had some variant of a license header in it (even if <5
       lines).
    
    All documentation files were explicitly excluded.
    
    The following heuristics were used to determine which SPDX license
    identifiers to apply.
    
     - when both scanners couldn't find any license traces, file was
       considered to have no license information in it, and the top level
       COPYING file license applied.
    
       For non */uapi/* files that summary was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0                                              11139
    
       and resulted in the first patch in this series.
    
       If that file was a */uapi/* path one, it was "GPL-2.0 WITH
       Linux-syscall-note" otherwise it was "GPL-2.0".  Results of that was:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|-------
       GPL-2.0 WITH Linux-syscall-note                        930
    
       and resulted in the second patch in this series.
    
     - if a file had some form of licensing information in it, and was one
       of the */uapi/* ones, it was denoted with the Linux-syscall-note if
       any GPL family license was found in the file or had no licensing in
       it (per prior point).  Results summary:
    
       SPDX license identifier                            # files
       ---------------------------------------------------|------
       GPL-2.0 WITH Linux-syscall-note                       270
       GPL-2.0+ WITH Linux-syscall-note                      169
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-2-Clause)    21
       ((GPL-2.0 WITH Linux-syscall-note) OR BSD-3-Clause)    17
       LGPL-2.1+ WITH Linux-syscall-note                      15
       GPL-1.0+ WITH Linux-syscall-note                       14
       ((GPL-2.0+ WITH Linux-syscall-note) OR BSD-3-Clause)    5
       LGPL-2.0+ WITH Linux-syscall-note                       4
       LGPL-2.1 WITH Linux-syscall-note                        3
       ((GPL-2.0 WITH Linux-syscall-note) OR MIT)              3
       ((GPL-2.0 WITH Linux-syscall-note) AND MIT)             1
    
       and that resulted in the third patch in this series.
    
     - when the two scanners agreed on the detected license(s), that became
       the concluded license(s).
    
     - when there was disagreement between the two scanners (one detected a
       license but the other didn't, or they both detected different
       licenses) a manual inspection of the file occurred.
    
     - In most cases a manual inspection of the information in the file
       resulted in a clear resolution of the license that should apply (and
       which scanner probably needed to revisit its heuristics).
    
     - When it was not immediately clear, the license identifier was
       confirmed with lawyers working with the Linux Foundation.
    
     - If there was any question as to the appropriate license identifier,
       the file was flagged for further research and to be revisited later
       in time.
    
    In total, over 70 hours of logged manual review was done on the
    spreadsheet to determine the SPDX license identifiers to apply to the
    source files by Kate, Philippe, Thomas and, in some cases, confirmation
    by lawyers working with the Linux Foundation.
    
    Kate also obtained a third independent scan of the 4.13 code base from
    FOSSology, and compared selected files where the other two scanners
    disagreed against that SPDX file, to see if there was new insights.  The
    Windriver scanner is based on an older version of FOSSology in part, so
    they are related.
    
    Thomas did random spot checks in about 500 files from the spreadsheets
    for the uapi headers and agreed with SPDX license identifier in the
    files he inspected. For the non-uapi files Thomas did random spot checks
    in about 15000 files.
    
    In initial set of patches against 4.14-rc6, 3 files were found to have
    copy/paste license identifier errors, and have been fixed to reflect the
    correct identifier.
    
    Additionally Philippe spent 10 hours this week doing a detailed manual
    inspection and review of the 12,461 patched files from the initial patch
    version early this week with:
     - a full scancode scan run, collecting the matched texts, detected
       license ids and scores
     - reviewing anything where there was a license detected (about 500+
       files) to ensure that the applied SPDX license was correct
     - reviewing anything where there was no detection but the patch license
       was not GPL-2.0 WITH Linux-syscall-note to ensure that the applied
       SPDX license was correct
    
    This produced a worksheet with 20 files needing minor correction.  This
    worksheet was then exported into 3 different .csv files for the
    different types of files to be modified.
    
    These .csv files were then reviewed by Greg.  Thomas wrote a script to
    parse the csv files and add the proper SPDX tag to the file, in the
    format that the file expected.  This script was further refined by Greg
    based on the output to detect more types of files automatically and to
    distinguish between header and source .c files (which need different
    comment types.)  Finally Greg ran the script using the .csv files to
    generate the patches.
    
    Reviewed-by: Kate Stewart <kstewart@linuxfoundation.org>
    Reviewed-by: Philippe Ombredanne <pombredanne@nexb.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index f92eaf7a4c0d..b779f3ccd412 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0 */
 /*
  * Contains the definition of registers common to all PowerPC variants.
  * If a register definition has been changed in a different PowerPC

commit eb039161da2ff388cc30d076badd8e06fb015f33
Author: Tobin C. Harding <me@tobin.cc>
Date:   Thu Mar 9 16:42:12 2017 +1100

    powerpc/asm: Convert .llong directives to .8byte
    
    .llong is an undocumented PPC specific directive. The generic
    equivalent is .quad, but even better (because it's self describing) is
    .8byte.
    
    Convert all .llong directives to .8byte.
    
    Signed-off-by: Tobin C. Harding <me@tobin.cc>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 2c4366ada976..f92eaf7a4c0d 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1344,12 +1344,12 @@ static inline void msr_check_and_clear(unsigned long bits)
 				".section __ftr_fixup,\"a\"\n"		\
 				".align 3\n"				\
 				"98:\n"					\
-				"	.llong %1\n"			\
-				"	.llong %1\n"			\
-				"	.llong 97b-98b\n"		\
-				"	.llong 99b-98b\n"		\
-				"	.llong 0\n"			\
-				"	.llong 0\n"			\
+				"	.8byte %1\n"			\
+				"	.8byte %1\n"			\
+				"	.8byte 97b-98b\n"		\
+				"	.8byte 99b-98b\n"		\
+				"	.8byte 0\n"			\
+				"	.8byte 0\n"			\
 				".previous"				\
 			: "=r" (rval) \
 			: "i" (CPU_FTR_CELL_TB_BUG), "i" (SPRN_TBRL) : "cr0"); \

commit d1e1b351f50f9e5941f436f6c63949731979e00c
Author: Balbir Singh <bsingharora@gmail.com>
Date:   Wed Aug 30 21:45:09 2017 +1000

    powerpc/xmon: Add ISA v3.0 SPRs to SPR dump
    
    Add support for printing the PIDR/TIDR for ISA 300 and PSSCR and PTCR
    in ISA 3.0 hypervisor mode.
    
    SPRN_PSSCR_PR is the privileged mode access and is used when we are
    not in hypervisor mode.
    
    Signed-off-by: Balbir Singh <bsingharora@gmail.com>
    [mpe: Split out of larger patch]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c36823d64ec9..2c4366ada976 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -356,6 +356,7 @@
 #define SPRN_PMSR	0x355   /* Power Management Status Reg */
 #define SPRN_PMMAR	0x356	/* Power Management Memory Activity Register */
 #define SPRN_PSSCR	0x357	/* Processor Stop Status and Control Register (ISA 3.0) */
+#define SPRN_PSSCR_PR	0x337	/* PSSCR ISA 3.0, privileged mode access */
 #define SPRN_PMCR	0x374	/* Power Management Control Register */
 
 /* HFSCR and FSCR bit numbers are the same */

commit 3ee87674e0212a152419a479dfb1eed501bab386
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Tue Aug 8 13:58:58 2017 +0200

    powerpc/8xx: Use symbolic PVR value
    
    For the 8xx, PVR values defined in arch/powerpc/include/asm/reg.h
    are nowhere used.
    
    Remove all defines and add PVR_8xx
    
    Use it in arch/powerpc/kernel/cputable.c
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 70722e5b93e7..c36823d64ec9 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1247,10 +1247,8 @@
  * differentiated by the version number in the Communication Processor
  * Module (CPM).
  */
-#define PVR_821		0x00500000
-#define PVR_823		PVR_821
-#define PVR_850		PVR_821
-#define PVR_860		PVR_821
+#define PVR_8xx		0x00500000
+
 #define PVR_8240	0x00810100
 #define PVR_8245	0x80811014
 #define PVR_8260	PVR_8240

commit 968159c0031ac1e07ab4426397e786c9c483f068
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Tue Aug 8 13:58:54 2017 +0200

    powerpc/8xx: Getting rid of remaining use of CONFIG_8xx
    
    Two config options exist to define powerpc MPC8xx:
    * CONFIG_PPC_8xx
    * CONFIG_8xx
    
    arch/powerpc/platforms/Kconfig.cputype has contained the following
    comment about CONFIG_8xx item for some years:
    "# this is temp to handle compat with arch=ppc"
    
    arch/powerpc is now the only place with remaining use of
    CONFIG_8xx: get rid of them.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c0600e9e0ff5..70722e5b93e7 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -22,9 +22,9 @@
 #include <asm/reg_fsl_emb.h>
 #endif
 
-#ifdef CONFIG_8xx
+#ifdef CONFIG_PPC_8xx
 #include <asm/reg_8xx.h>
-#endif /* CONFIG_8xx */
+#endif /* CONFIG_PPC_8xx */
 
 #define MSR_SF_LG	63              /* Enable 64 bit mode */
 #define MSR_ISF_LG	61              /* Interrupt 64b mode valid on 630 */
@@ -135,7 +135,7 @@
 #define MSR_KERNEL	(MSR_ | MSR_64BIT)
 #define MSR_USER32	(MSR_ | MSR_PR | MSR_EE)
 #define MSR_USER64	(MSR_USER32 | MSR_64BIT)
-#elif defined(CONFIG_PPC_BOOK3S_32) || defined(CONFIG_8xx)
+#elif defined(CONFIG_PPC_BOOK3S_32) || defined(CONFIG_PPC_8xx)
 /* Default MSR for kernel mode. */
 #define MSR_KERNEL	(MSR_ME|MSR_RI|MSR_IR|MSR_DR)
 #define MSR_USER	(MSR_KERNEL|MSR_PR|MSR_EE)
@@ -1164,7 +1164,7 @@
 #endif
 #endif
 
-#ifdef CONFIG_8xx
+#ifdef CONFIG_PPC_8xx
 #define SPRN_SPRG_SCRATCH0	SPRN_SPRG0
 #define SPRN_SPRG_SCRATCH1	SPRN_SPRG1
 #define SPRN_SPRG_SCRATCH2	SPRN_SPRG2
@@ -1363,7 +1363,7 @@ static inline void msr_check_and_clear(unsigned long bits)
 
 #else /* __powerpc64__ */
 
-#if defined(CONFIG_8xx)
+#if defined(CONFIG_PPC_8xx)
 #define mftbl()		({unsigned long rval;	\
 			asm volatile("mftbl %0" : "=r" (rval)); rval;})
 #define mftbu()		({unsigned long rval;	\

commit d30a5a5262ca64d58aa07fb2ecd7f992df83b4bc
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Aug 8 16:39:25 2017 +1000

    powerpc/traps: Use SRR1 defines for program check reasons
    
    Currently we open code the reason codes for program checks. Instead use
    the existing SRR1 defines.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 73be2f71dbbb..c0600e9e0ff5 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -724,6 +724,7 @@
 					  * may not be recoverable */
 #define	  SRR1_WS_DEEPER	0x00020000 /* Some resources not maintained */
 #define	  SRR1_WS_DEEP		0x00010000 /* All resources maintained */
+#define   SRR1_PROGTM		0x00200000 /* TM Bad Thing */
 #define   SRR1_PROGFPE		0x00100000 /* Floating Point Enabled */
 #define   SRR1_PROGILL		0x00080000 /* Illegal instruction */
 #define   SRR1_PROGPRIV		0x00040000 /* Privileged instruction */

commit 870cfe77a91e91cac5937784d73b9d27b6a12296
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Jul 19 14:49:26 2017 +1000

    powerpc/mm: Update definitions of DSISR bits
    
    This updates the definitions for the various DSISR bits to
    match both some historical stuff and to match new bits on
    POWER9.
    
    In addition, we define some masks corresponding to the "bad"
    faults on Book3S, and some masks corresponding to the bits
    that match between DSISR and SRR1 for a DSI and an ISI.
    
    This comes with a small code update to change the definition
    of DSISR_PGDIRFAULT which becomes DSISR_PRTABLE_FAULT to
    match architecture 3.0B
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index a3b6575c7842..73be2f71dbbb 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -272,16 +272,65 @@
 #define SPRN_DAR	0x013	/* Data Address Register */
 #define SPRN_DBCR	0x136	/* e300 Data Breakpoint Control Reg */
 #define SPRN_DSISR	0x012	/* Data Storage Interrupt Status Register */
-#define   DSISR_NOHPTE		0x40000000	/* no translation found */
-#define   DSISR_PROTFAULT	0x08000000	/* protection fault */
-#define   DSISR_BADACCESS	0x04000000	/* bad access to CI or G */
-#define   DSISR_ISSTORE		0x02000000	/* access was a store */
-#define   DSISR_DABRMATCH	0x00400000	/* hit data breakpoint */
-#define   DSISR_NOSEGMENT	0x00200000	/* SLB miss */
-#define   DSISR_KEYFAULT	0x00200000	/* Key fault */
-#define   DSISR_UNSUPP_MMU	0x00080000	/* Unsupported MMU config */
-#define   DSISR_SET_RC		0x00040000	/* Failed setting of R/C bits */
-#define   DSISR_PGDIRFAULT      0x00020000      /* Fault on page directory */
+#define   DSISR_BAD_DIRECT_ST	0x80000000 /* Obsolete: Direct store error */
+#define   DSISR_NOHPTE		0x40000000 /* no translation found */
+#define   DSISR_ATTR_CONFLICT	0x20000000 /* P9: Process vs. Partition attr */
+#define   DSISR_NOEXEC_OR_G	0x10000000 /* Alias of SRR1 bit, see below */
+#define   DSISR_PROTFAULT	0x08000000 /* protection fault */
+#define   DSISR_BADACCESS	0x04000000 /* bad access to CI or G */
+#define   DSISR_ISSTORE		0x02000000 /* access was a store */
+#define   DSISR_DABRMATCH	0x00400000 /* hit data breakpoint */
+#define   DSISR_NOSEGMENT	0x00200000 /* STAB miss (unsupported) */
+#define   DSISR_KEYFAULT	0x00200000 /* Storage Key fault */
+#define   DSISR_BAD_EXT_CTRL	0x00100000 /* Obsolete: External ctrl error */
+#define   DSISR_UNSUPP_MMU	0x00080000 /* P9: Unsupported MMU config */
+#define   DSISR_SET_RC		0x00040000 /* P9: Failed setting of R/C bits */
+#define   DSISR_PRTABLE_FAULT   0x00020000 /* P9: Fault on process table */
+#define   DSISR_ICSWX_NO_CT     0x00004000 /* P7: icswx unavailable cp type */
+#define   DSISR_BAD_COPYPASTE   0x00000008 /* P9: Copy/Paste on wrong memtype */
+#define   DSISR_BAD_AMO		0x00000004 /* P9: Incorrect AMO opcode */
+#define   DSISR_BAD_CI_LDST	0x00000002 /* P8: Bad HV CI load/store */
+
+/*
+ * DSISR_NOEXEC_OR_G doesn't actually exist. This bit is always
+ * 0 on DSIs. However, on ISIs, the corresponding bit in SRR1
+ * indicates an attempt at executing from a no-execute PTE
+ * or segment or from a guarded page.
+ *
+ * We add a definition here for completeness as we alias
+ * DSISR and SRR1 in do_page_fault.
+ */
+
+/*
+ * DSISR bits that are treated as a fault. Any bit set
+ * here will skip hash_page, and cause do_page_fault to
+ * trigger a SIGBUS or SIGSEGV:
+ */
+#define   DSISR_BAD_FAULT_32S	(DSISR_BAD_DIRECT_ST	| \
+				 DSISR_BADACCESS	| \
+				 DSISR_BAD_EXT_CTRL)
+#define	  DSISR_BAD_FAULT_64S	(DSISR_BAD_FAULT_32S	| \
+				 DSISR_ATTR_CONFLICT	| \
+				 DSISR_KEYFAULT		| \
+				 DSISR_UNSUPP_MMU	| \
+				 DSISR_PRTABLE_FAULT	| \
+				 DSISR_ICSWX_NO_CT	| \
+				 DSISR_BAD_COPYPASTE	| \
+				 DSISR_BAD_AMO		| \
+				 DSISR_BAD_CI_LDST)
+/*
+ * These bits are equivalent in SRR1 and DSISR for 0x400
+ * instruction access interrupts on Book3S
+ */
+#define   DSISR_SRR1_MATCH_32S	(DSISR_NOHPTE		| \
+				 DSISR_NOEXEC_OR_G	| \
+				 DSISR_PROTFAULT)
+#define   DSISR_SRR1_MATCH_64S	(DSISR_SRR1_MATCH_32S	| \
+				 DSISR_KEYFAULT		| \
+				 DSISR_UNSUPP_MMU	| \
+				 DSISR_SET_RC		| \
+				 DSISR_PRTABLE_FAULT)
+
 #define SPRN_TBRL	0x10C	/* Time Base Read Lower Register (user, R/O) */
 #define SPRN_TBRU	0x10D	/* Time Base Read Upper Register (user, R/O) */
 #define SPRN_CIR	0x11B	/* Chip Information Register (hyper, R/0) */

commit 2400fd822f467cb4c886c879d8ad99feac9cf319
Author: Oliver O'Halloran <oohall@gmail.com>
Date:   Thu Jul 6 18:46:43 2017 +1000

    powerpc/asm: Mark cr0 as clobbered in mftb()
    
    The workaround for the CELL timebase bug does not correctly mark cr0 as
    being clobbered. This means GCC doesn't know that the asm block changes cr0 and
    might leave the result of an unrelated comparison in cr0 across the block, which
    we then trash, leading to basically random behaviour.
    
    Fixes: 859deea949c3 ("[POWERPC] Cell timebase bug workaround")
    Cc: stable@vger.kernel.org # v2.6.19+
    Signed-off-by: Oliver O'Halloran <oohall@gmail.com>
    [mpe: Tweak change log and flag for stable]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 7e50e47375d6..a3b6575c7842 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1303,7 +1303,7 @@ static inline void msr_check_and_clear(unsigned long bits)
 				"	.llong 0\n"			\
 				".previous"				\
 			: "=r" (rval) \
-			: "i" (CPU_FTR_CELL_TB_BUG), "i" (SPRN_TBRL)); \
+			: "i" (CPU_FTR_CELL_TB_BUG), "i" (SPRN_TBRL) : "cr0"); \
 			rval;})
 #else
 #define mftb()		({unsigned long rval;	\

commit 5a61ef74f269f2573f48fa53607a8911216c3326
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue May 9 13:16:52 2017 +1000

    powerpc/64s: Support new device tree binding for discovering CPU features
    
    The ibm,powerpc-cpu-features device tree binding describes CPU features with
    ASCII names and extensible compatibility, privilege, and enablement metadata
    that allows improved flexibility and compatibility with new hardware.
    
    The interface is described in detail in ibm,powerpc-cpu-features.txt in this
    patch.
    
    Currently this code is not enabled by default, and there are no released
    firmwares that provide the binding.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index d4f653c9259a..7e50e47375d6 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1229,6 +1229,7 @@
 #define PVR_POWER8E	0x004B
 #define PVR_POWER8NVL	0x004C
 #define PVR_POWER8	0x004D
+#define PVR_POWER9	0x004E
 #define PVR_BE		0x0070
 #define PVR_PA6T	0x0090
 

commit 1945bc4549e5cb1f9aa873ec29191aa54dc851d2
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Wed Apr 19 23:05:47 2017 +1000

    powerpc/64s: Fix POWER9 machine check handler from stop state
    
    The ISA specifies power save wakeup due to a machine check exception can
    cause a machine check interrupt (rather than the usual system reset
    interrupt).
    
    The machine check handler copes with this by doing low level machine
    check recovery without restoring full state from idle, then queues up a
    machine check event for logging, then directly executes the same idle
    instruction it woke from. This minimises the work done before recovery
    is performed.
    
    The problem is that it requires machine specific instructions and
    knowledge of the book3s idle code. Currently it only has code to handle
    POWER8 idle, so POWER9 crashes when trying to execute the P8 idle
    instructions which don't exist in ISAv3.0B.
    
    cpu 0x0: Vector: e40 (Emulation Assist) at [c0000000008f3810]
        pc: c000000000008380: machine_check_handle_early+0x130/0x2f0
        lr: c00000000053a098: stop_loop+0x68/0xd0
        sp: c0000000008f3a90
       msr: 9000000000081001
      current = 0xc0000000008a1080
      paca    = 0xc00000000ffd0000   softe: 0        irq_happened: 0x01
        pid   = 0, comm = swapper/0
    
    Instead of going to sleep after recovery, do the usual idle wakeup and
    state restoration by calling into the normal idle wakeup path. This
    reuses the normal idle wakeup paths.
    
    Reviewed-by: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
    Reviewed-by: Mahesh J Salgaonkar <mahesh@linux.vnet.ibm.com>
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 4b594ed6180a..d4f653c9259a 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -659,6 +659,7 @@
 #define   SRR1_ISI_PROT		0x08000000 /* ISI: Other protection fault */
 #define   SRR1_WAKEMASK		0x00380000 /* reason for wakeup */
 #define   SRR1_WAKEMASK_P8	0x003c0000 /* reason for wakeup on POWER8 and 9 */
+#define   SRR1_WAKEMCE_RESVD	0x003c0000 /* Unused/reserved value used by MCE wakeup to indicate cause to idle wakeup handler */
 #define   SRR1_WAKESYSERR	0x00300000 /* System error */
 #define   SRR1_WAKEEE		0x00200000 /* External interrupt */
 #define   SRR1_WAKEHVI		0x00240000 /* Hypervisor Virtualization Interrupt (P9) */

commit 9b7ff0c6586bc0541ebcd1ff6773b11a49f1a058
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Fri Apr 7 11:27:44 2017 +1000

    powerpc/64s: Add SCV FSCR bit for ISA v3.0
    
    Add the bit definition and use it in facility_unavailable_exception() so we can
    intelligently report the cause if we take a fault for SCV. This doesn't actually
    enable SCV.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Drop whitespace changes to the existing entries, flush out change log]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index d0b332b8afad..4b594ed6180a 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -310,6 +310,7 @@
 #define SPRN_PMCR	0x374	/* Power Management Control Register */
 
 /* HFSCR and FSCR bit numbers are the same */
+#define FSCR_SCV_LG	12	/* Enable System Call Vectored */
 #define FSCR_MSGP_LG	10	/* Enable MSGP */
 #define FSCR_TAR_LG	8	/* Enable Target Address Register */
 #define FSCR_EBB_LG	7	/* Enable Event Based Branching */
@@ -320,6 +321,7 @@
 #define FSCR_VECVSX_LG	1	/* Enable VMX/VSX  */
 #define FSCR_FP_LG	0	/* Enable Floating Point */
 #define SPRN_FSCR	0x099	/* Facility Status & Control Register */
+#define   FSCR_SCV	__MASK(FSCR_SCV_LG)
 #define   FSCR_TAR	__MASK(FSCR_TAR_LG)
 #define   FSCR_EBB	__MASK(FSCR_EBB_LG)
 #define   FSCR_DSCR	__MASK(FSCR_DSCR_LG)

commit 08a1e650cc631ccc8cfe670beb38b2f9c58402cd
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Apr 5 17:54:55 2017 +1000

    powerpc: Fixup LPCR:PECE and HEIC setting on POWER9
    
    We need to set LPES in order for normal external interrupts (0x500)
    to be directed to the guest while running in guest state.
    
    We also need HEIC set to prevent them to be sent to the host while
    in host state.
    
    With XIVE the host never gets one of these and wouldn't know how to
    handle it. All host external interrupts come in via the new
    hypervisor virtualization interrupts vector.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index fc879fd6bdae..d0b332b8afad 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -365,6 +365,7 @@
 #define   LPCR_MER_SH		11
 #define	  LPCR_GTSE		ASM_CONST(0x0000000000000400)  	/* Guest Translation Shootdown Enable */
 #define   LPCR_TC		ASM_CONST(0x0000000000000200)	/* Translation control */
+#define   LPCR_HEIC		ASM_CONST(0x0000000000000010)   /* Hypervisor External Interrupt Control */
 #define   LPCR_LPES		0x0000000c
 #define   LPCR_LPES0		ASM_CONST(0x0000000000000008)      /* LPAR Env selector 0 */
 #define   LPCR_LPES1		ASM_CONST(0x0000000000000004)      /* LPAR Env selector 1 */

commit b286cedd473006b33d5ae076afac509e6b2c3bf4
Merge: 522214d9be9c 9f3768e02335
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 1 10:10:16 2017 -0800

    Merge tag 'powerpc-4.11-2' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull more powerpc updates from Michael Ellerman:
     "Highlights include:
    
       - an update of the disassembly code used by xmon to the latest
         versions in binutils. We've received permission from all the
         authors of the relevant binutils changes to relicense their changes
         to the relevant files from GPLv3 to GPLv2, for inclusion in Linux.
         Thanks to Peter Bergner for doing the leg work to get permission
         from everyone.
    
       - addition of the "architected" Power9 CPU table entry, allowing us
         to boot in Power9 architected mode under a hypervisor.
    
       - updates to the Power9 PMU code.
    
       - implementation of clear_bit_unlock_is_negative_byte() to optimise
         unlock_page().
    
       - Freescale updates from Scott: "Highlights include 8xx breakpoints
         and perf, t1042rdb display support, and board updates."
    
      Thanks to:
        Al Viro, Andrew Donnellan, Aneesh Kumar K.V, Balbir Singh, Douglas
        Miller, Frédéric Weisbecker, Gavin Shan, Madhavan Srinivasan,
        Michael Roth, Nathan Fontenot, Naveen N. Rao, Nicholas Piggin, Peter
        Bergner, Paul E. McKenney, Rashmica Gupta, Russell Currey, Sahil
        Mehta, Stewart Smith"
    
    * tag 'powerpc-4.11-2' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (48 commits)
      powerpc: Remove leftover cputime_to_nsecs call causing build error
      powerpc/mm/hash: Always clear UPRT and Host Radix bits when setting up CPU
      powerpc/optprobes: Fix TOC handling in optprobes trampoline
      powerpc/pseries: Advertise Hot Plug Event support to firmware
      cxl: fix nested locking hang during EEH hotplug
      powerpc/xmon: Dump memory in CPU endian format
      powerpc/pseries: Revert 'Auto-online hotplugged memory'
      powerpc/powernv: Make PCI non-optional
      powerpc/64: Implement clear_bit_unlock_is_negative_byte()
      powerpc/powernv: Remove unused variable in pnv_pci_sriov_disable()
      powerpc/kernel: Remove error message in pcibios_setup_phb_resources()
      powerpc/mm: Fix typo in set_pte_at()
      pci/hotplug/pnv-php: Disable MSI and PCI device properly
      pci/hotplug/pnv-php: Disable surprise hotplug capability on conflicts
      pci/hotplug/pnv-php: Remove WARN_ON() in pnv_php_put_slot()
      powerpc: Add POWER9 architected mode to cputable
      powerpc/perf: use is_kernel_addr macro in perf_get_misc_flags()
      powerpc/perf: Avoid FAB_*_MATCH checks for power9
      powerpc/perf: Add restrictions to PMC5 in power9 DD1
      powerpc/perf: Use Instruction Counter value
      ...

commit 38705613b74ab090eee55c327cd0cb77fb10eb26
Merge: ff47d8c05019 438e69b52be7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Feb 22 10:30:38 2017 -0800

    Merge tag 'powerpc-4.11-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Highlights include:
    
       - Support for direct mapped LPC on POWER9, giving Linux direct access
         to devices that may be on there such as a UART.
    
       - Memory hotplug support for the Power9 Radix MMU.
    
       - Add new AUX vectors describing the processor's cache geometry, to
         be used by glibc.
    
       - The ability for a guest to ask the hypervisor to resize the guest's
         hash table, and in addition support for doing so automatically when
         memory is hotplugged into/out-of the guest. This allows the hash
         table to be sized based on the current memory usage of the guest,
         rather than the maximum possible memory usage.
    
       - Implementation of optprobes (kprobe optimisation) for powerpc.
    
      In addition there's the topic branch shared with the KVM tree, which
      includes support for guests to use the Radix MMU on Power9.
    
      Thanks to:
        Alistair Popple, Andrew Donnellan, Aneesh Kumar K.V, Anju T, Anton
        Blanchard, Benjamin Herrenschmidt, Chris Packham, Daniel Axtens,
        Daniel Borkmann, David Gibson, Finn Thain, Gautham R. Shenoy, Gavin
        Shan, Greg Kurz, Joel Stanley, John Allen, Madhavan Srinivasan,
        Mahesh Salgaonkar, Markus Elfring, Michael Neuling, Nathan Fontenot,
        Naveen N. Rao, Nicholas Piggin, Paul Mackerras, Ravi Bangoria, Reza
        Arbab, Shailendra Singh, Vaibhav Jain, Wei Yongjun"
    
    * tag 'powerpc-4.11-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (129 commits)
      powerpc/mm/radix: Skip ptesync in pte update helpers
      powerpc/mm/radix: Use ptep_get_and_clear_full when clearing pte for full mm
      powerpc/mm/radix: Update pte update sequence for pte clear case
      powerpc/mm: Update PROTFAULT handling in the page fault path
      powerpc/xmon: Fix data-breakpoint
      powerpc/mm: Fix build break with BOOK3S_64=n and MEMORY_HOTPLUG=y
      powerpc/mm: Fix build break when CMA=n && SPAPR_TCE_IOMMU=y
      powerpc/mm: Fix build break with RADIX=y & HUGETLBFS=n
      powerpc/pseries: Fix typo in parameter description
      powerpc/kprobes: Remove kprobe_exceptions_notify()
      kprobes: Introduce weak variant of kprobe_exceptions_notify()
      powerpc/ftrace: Fix confusing help text for DISABLE_MPROFILE_KERNEL
      powerpc/powernv: Fix opal_exit tracepoint opcode
      powerpc: Add a prototype for mcount() so it can be versioned
      powerpc: Drop GPL from of_node_to_nid() export to match other arches
      powerpc/kprobes: Optimize kprobe in kretprobe_trampoline()
      powerpc/kprobes: Implement Optprobes
      powerpc/kprobes: Fixes for kprobe_lookup_name() on BE
      powerpc: Add helper to check if offset is within relative branch range
      powerpc/bpf: Introduce __PPC_SH64()
      ...

commit 6c8f9ad566ddc63da5da84c3c9e6c1bb0434c64f
Merge: d11914b21c4c 75b824727680
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Sat Feb 18 21:37:14 2017 +1100

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/scottwood/linux into next
    
    Freescale updates from Scott:
    
    "Highlights include 8xx breakpoints and perf, t1042rdb display support,
    and board updates."

commit da0e7e6276968fcc61ac7484d0026cd5fdd94dc3
Merge: a05ef161cdd2 ab9bad0ead9a
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Feb 14 17:18:29 2017 +1100

    Merge branch 'topic/ppc-kvm' into next
    
    Merge the topic branch we're sharing with the kvm-ppc tree.

commit 9b256714979fad61ae11d90b53cf67dd5e6484eb
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Feb 7 11:35:31 2017 +1100

    powerpc/powernv: Fix CPU hotplug to handle waking on HVI
    
    The IPIs come in as HVI not EE, so we need to test the appropriate
    SRR1 bits. The encoding is such that it won't have false positives
    on P7 and P8 so we can just test it like that. We also need to handle
    the icp-opal variant of the flush.
    
    Fixes: d74361881f0d ("powerpc/xics: Add ICP OPAL backend")
    Cc: stable@vger.kernel.org # v4.8+
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 0d4531aa2052..dff79798903d 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -649,9 +649,10 @@
 #define   SRR1_ISI_N_OR_G	0x10000000 /* ISI: Access is no-exec or G */
 #define   SRR1_ISI_PROT		0x08000000 /* ISI: Other protection fault */
 #define   SRR1_WAKEMASK		0x00380000 /* reason for wakeup */
-#define   SRR1_WAKEMASK_P8	0x003c0000 /* reason for wakeup on POWER8 */
+#define   SRR1_WAKEMASK_P8	0x003c0000 /* reason for wakeup on POWER8 and 9 */
 #define   SRR1_WAKESYSERR	0x00300000 /* System error */
 #define   SRR1_WAKEEE		0x00200000 /* External interrupt */
+#define   SRR1_WAKEHVI		0x00240000 /* Hypervisor Virtualization Interrupt (P9) */
 #define   SRR1_WAKEMT		0x00280000 /* mtctrl */
 #define	  SRR1_WAKEHMI		0x00280000 /* Hypervisor maintenance */
 #define   SRR1_WAKEDEC		0x00180000 /* Decrementer interrupt */

commit dbcbfee0c81c7938e40d7d6bc659a5191f490b50
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Mon Jan 30 21:21:37 2017 +1100

    powerpc/64: More definitions for POWER9
    
    This adds definitions for bits in the DSISR register which are used
    by POWER9 for various translation-related exception conditions, and
    for some more bits in the partition table entry that will be needed
    by KVM.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 0d4531aa2052..aa44a83ad3ec 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -274,10 +274,14 @@
 #define SPRN_DSISR	0x012	/* Data Storage Interrupt Status Register */
 #define   DSISR_NOHPTE		0x40000000	/* no translation found */
 #define   DSISR_PROTFAULT	0x08000000	/* protection fault */
+#define   DSISR_BADACCESS	0x04000000	/* bad access to CI or G */
 #define   DSISR_ISSTORE		0x02000000	/* access was a store */
 #define   DSISR_DABRMATCH	0x00400000	/* hit data breakpoint */
 #define   DSISR_NOSEGMENT	0x00200000	/* SLB miss */
 #define   DSISR_KEYFAULT	0x00200000	/* Key fault */
+#define   DSISR_UNSUPP_MMU	0x00080000	/* Unsupported MMU config */
+#define   DSISR_SET_RC		0x00040000	/* Failed setting of R/C bits */
+#define   DSISR_PGDIRFAULT      0x00020000      /* Fault on page directory */
 #define SPRN_TBRL	0x10C	/* Time Base Read Lower Register (user, R/O) */
 #define SPRN_TBRU	0x10D	/* Time Base Read Upper Register (user, R/O) */
 #define SPRN_CIR	0x11B	/* Chip Information Register (hyper, R/0) */

commit 75b824727680a9d12c34d78096a5ac642e53f5d0
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Dec 15 13:42:18 2016 +0100

    powerpc/8xx: Perf events on PPC 8xx
    
    This patch has been reworked since RFC version. In the RFC, this patch
    was preceded by a patch clearing MSR RI for all PPC32 at all time at
    exception prologs. Now MSR RI clearing is done only when this 8xx perf
    events functionality is compiled in, it is therefore limited to 8xx
    and merged inside this patch.
    Other main changes have been to take into account detailed review from
    Peter Zijlstra. The instructions counter has been reworked to behave
    as a free running counter like the three other counters.
    
    The 8xx has no PMU, however some events can be emulated by other means.
    
    This patch implements the following events (as reported by 'perf list'):
      cpu-cycles OR cycles                          [Hardware event]
      instructions                                  [Hardware event]
      dTLB-load-misses                              [Hardware cache event]
      iTLB-load-misses                              [Hardware cache event]
    
    'cycles' event is implemented using the timebase clock. Timebase clock
    corresponds to CPU clock divided by 16, so number of cycles is
    approximatly 16 times the number of TB ticks
    
    On the 8xx, TLB misses are handled by software. It is therefore
    easy to count all TLB misses each time the TLB miss exception is
    called.
    
    'instructions' is calculated by using instruction watchpoint counter.
    This patch sets counter A to count instructions at address greater
    than 0, hence we count all instructions executed while MSR RI bit is
    set. The counter is set to the maximum which is 0xffff. Every 65535
    instructions, debug instruction breakpoint exception fires. The
    exception handler increments a counter in memory which then
    represent the upper part of the instruction counter. We therefore
    end up with a 48 bits counter. In order to avoid unnecessary overhead
    while no perf event is active, this counter is started when the first
    event referring to this counter is added, and the counter is stopped
    when the last event referring to it is deleted. In order to properly
    support breakpoint exceptions, MSR RI bit has to be unset in exception
    epilogs in order to avoid breakpoint exceptions during critical
    sections during changes to SRR0 and SRR1 would be problematic.
    
    All counters are handled as free running counters.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Scott Wood <oss@buserror.net>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 0d4531aa2052..9098b35b46a8 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -548,7 +548,9 @@
 #define SPRN_IBAT7U	0x236		/* Instruction BAT 7 Upper Register */
 #define SPRN_ICMP	0x3D5		/* Instruction TLB Compare Register */
 #define SPRN_ICTC	0x3FB	/* Instruction Cache Throttling Control Reg */
+#ifndef SPRN_ICTRL
 #define SPRN_ICTRL	0x3F3	/* 1011 7450 icache and interrupt ctrl */
+#endif
 #define ICTRL_EICE	0x08000000	/* enable icache parity errs */
 #define ICTRL_EDC	0x04000000	/* enable dcache parity errs */
 #define ICTRL_EICP	0x00000100	/* enable icache par. check */

commit 4ab2537c4204b976e4ca350bbdc193b4649cad28
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Thu Dec 8 09:12:13 2016 +0530

    powerpc/mm: Fixup wrong LPCR_VRMASD value
    
    In commit a4b349540a26af ("powerpc/mm: Cleanup LPCR defines") we updated
    LPCR_VRMASD wrongly as below.
    
    -#define   LPCR_VRMASD  (0x1ful << (63-16))
    +#define   LPCR_VRMASD_SH       47
    +#define   LPCR_VRMASD          (ASM_CONST(1) << LPCR_VRMASD_SH)
    
    We initialize the VRMA bits in LPCR to 0x00 in kvm. Hence using a
    different mask value as above while updating lpcr should not have any
    impact.
    
    This patch updates it to the correct value.
    
    Fixes: a4b349540a26 ("powerpc/mm: Cleanup LPCR defines")
    Reported-by: Ram Pai <linuxram@us.ibm.com>
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Jia He <hejianet@gmail.com>
    Acked-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 0d4531aa2052..818c4e878e60 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -338,7 +338,7 @@
 #define   LPCR_DPFD_SH		52
 #define   LPCR_DPFD		(ASM_CONST(7) << LPCR_DPFD_SH)
 #define   LPCR_VRMASD_SH	47
-#define   LPCR_VRMASD		(ASM_CONST(1) << LPCR_VRMASD_SH)
+#define   LPCR_VRMASD		(ASM_CONST(0x1f) << LPCR_VRMASD_SH)
 #define   LPCR_VRMA_L		ASM_CONST(0x0008000000000000)
 #define   LPCR_VRMA_LP0		ASM_CONST(0x0001000000000000)
 #define   LPCR_VRMA_LP1		ASM_CONST(0x0000800000000000)

commit ddbefe7e77603cc9645a571a8bf680e193caac97
Merge: 3382a6220ff3 02ed21aeda0e
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Nov 24 22:14:52 2016 +1100

    Merge branch 'topic/ppc-kvm' into next
    
    Merge the topic branch we're sharing with the kvm-ppc tree.

commit 02ed21aeda0e02d84af493f92b1b6b6b13ddd6e8
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed Nov 23 10:44:09 2016 +1100

    powerpc/powernv: Define and set POWER9 HFSCR doorbell bit
    
    Define and set the POWER9 HFSCR doorbell bit so that guests can use
    msgsndp.
    
    ISA 3.0 calls this MSGP, so name it accordingly in the code.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c94df450bdd6..04aa1ee8cdb6 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -309,6 +309,7 @@
 
 /* HFSCR and FSCR bit numbers are the same */
 #define FSCR_LM_LG	11	/* Enable Load Monitor Registers */
+#define FSCR_MSGP_LG	10	/* Enable MSGP */
 #define FSCR_TAR_LG	8	/* Enable Target Address Register */
 #define FSCR_EBB_LG	7	/* Enable Event Based Branching */
 #define FSCR_TM_LG	5	/* Enable Transactional Memory */
@@ -324,6 +325,7 @@
 #define   FSCR_DSCR	__MASK(FSCR_DSCR_LG)
 #define SPRN_HFSCR	0xbe	/* HV=1 Facility Status & Control Register */
 #define   HFSCR_LM	__MASK(FSCR_LM_LG)
+#define   HFSCR_MSGP	__MASK(FSCR_MSGP_LG)
 #define   HFSCR_TAR	__MASK(FSCR_TAR_LG)
 #define   HFSCR_EBB	__MASK(FSCR_EBB_LG)
 #define   HFSCR_TM	__MASK(FSCR_TM_LG)

commit 1f0f2e72270c089c291aac794800cc326c4c05dd
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Nov 22 14:50:39 2016 +1100

    powerpc/reg: Add definition for LPCR_PECE_HVEE
    
    ISA 3.0 defines a new PECE (Power-saving mode Exit Cause Enable) field
    in the LPCR (Logical Partitioning Control Register), called
    LPCR_PECE_HVEE (Hypervisor Virtualization Exit Enable).
    
    KVM code will need to know about this bit, so add a definition for it.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 30d9adbc32ba..c94df450bdd6 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -359,6 +359,7 @@
 #define     LPCR_PECE0		ASM_CONST(0x0000000000004000)	/* ext. exceptions can cause exit */
 #define     LPCR_PECE1		ASM_CONST(0x0000000000002000)	/* decrementer can cause exit */
 #define     LPCR_PECE2		ASM_CONST(0x0000000000001000)	/* machine check etc can cause exit */
+#define     LPCR_PECE_HVEE	ASM_CONST(0x0000400000000000)	/* P9 Wakeup on HV interrupts */
 #define   LPCR_MER		ASM_CONST(0x0000000000000800)	/* Mediated External Exception */
 #define   LPCR_MER_SH		11
 #define	  LPCR_GTSE		ASM_CONST(0x0000000000000400)  	/* Guest Translation Shootdown Enable */

commit 9dd17e8517f5ccd594a01374b0b41ec1a1c266af
Author: Suraj Jitindar Singh <sjitindarsingh@gmail.com>
Date:   Mon Nov 21 16:02:35 2016 +1100

    powerpc/64: Define new ISA v3.00 logical PVR value and PCR register value
    
    ISA 3.00 adds the logical PVR value 0x0f000005, so add a definition for
    this.
    
    Define PCR_ARCH_207 to reflect ISA 2.07 compatibility mode in the processor
    compatibility register (PCR).
    
    [paulus@ozlabs.org - moved dummy PCR_ARCH_300 value into next patch]
    
    Signed-off-by: Suraj Jitindar Singh <sjitindarsingh@gmail.com>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index df81411a85ea..30d9adbc32ba 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -382,6 +382,12 @@
 #define   PCR_VEC_DIS	(1ul << (63-0))	/* Vec. disable (bit NA since POWER8) */
 #define   PCR_VSX_DIS	(1ul << (63-1))	/* VSX disable (bit NA since POWER8) */
 #define   PCR_TM_DIS	(1ul << (63-2))	/* Trans. memory disable (POWER8) */
+/*
+ * These bits are used in the function kvmppc_set_arch_compat() to specify and
+ * determine both the compatibility level which we want to emulate and the
+ * compatibility level which the host is capable of emulating.
+ */
+#define   PCR_ARCH_207	0x8		/* Architecture 2.07 */
 #define   PCR_ARCH_206	0x4		/* Architecture 2.06 */
 #define   PCR_ARCH_205	0x2		/* Architecture 2.05 */
 #define	SPRN_HEIR	0x153	/* Hypervisor Emulated Instruction Register */
@@ -1223,6 +1229,7 @@
 #define PVR_ARCH_206	0x0f000003
 #define PVR_ARCH_206p	0x0f100003
 #define PVR_ARCH_207	0x0f000004
+#define PVR_ARCH_300	0x0f000005
 
 /* Macros for setting and retrieving special purpose registers */
 #ifndef __ASSEMBLY__

commit 7fd317f8c330a8d3ed6468d5670e5c09c25846e2
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Mon Nov 21 16:00:23 2016 +1100

    powerpc/64: Add some more SPRs and SPR bits for POWER9
    
    These definitions will be needed by KVM.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 9cd4e8cbc78c..df81411a85ea 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -153,6 +153,8 @@
 #define PSSCR_EC		0x00100000 /* Exit Criterion */
 #define PSSCR_ESL		0x00200000 /* Enable State Loss */
 #define PSSCR_SD		0x00400000 /* Status Disable */
+#define PSSCR_PLS	0xf000000000000000 /* Power-saving Level Status */
+#define PSSCR_GUEST_VIS	0xf0000000000003ff /* Guest-visible PSSCR fields */
 
 /* Floating Point Status and Control Register (FPSCR) Fields */
 #define FPSCR_FX	0x80000000	/* FPU exception summary */
@@ -236,6 +238,7 @@
 #define SPRN_TEXASRU	0x83	/* ''	   ''	   ''	 Upper 32  */
 #define   TEXASR_FS	__MASK(63-36) /* TEXASR Failure Summary */
 #define SPRN_TFHAR	0x80	/* Transaction Failure Handler Addr */
+#define SPRN_TIDR	144	/* Thread ID register */
 #define SPRN_CTRLF	0x088
 #define SPRN_CTRLT	0x098
 #define   CTRL_CT	0xc0000000	/* current thread */
@@ -294,6 +297,7 @@
 #define SPRN_HSRR1	0x13B	/* Hypervisor Save/Restore 1 */
 #define SPRN_LMRR	0x32D	/* Load Monitor Region Register */
 #define SPRN_LMSER	0x32E	/* Load Monitor Section Enable Register */
+#define SPRN_ASDR	0x330	/* Access segment descriptor register */
 #define SPRN_IC		0x350	/* Virtual Instruction Count */
 #define SPRN_VTB	0x351	/* Virtual Time Base */
 #define SPRN_LDBAR	0x352	/* LD Base Address Register */
@@ -357,6 +361,7 @@
 #define     LPCR_PECE2		ASM_CONST(0x0000000000001000)	/* machine check etc can cause exit */
 #define   LPCR_MER		ASM_CONST(0x0000000000000800)	/* Mediated External Exception */
 #define   LPCR_MER_SH		11
+#define	  LPCR_GTSE		ASM_CONST(0x0000000000000400)  	/* Guest Translation Shootdown Enable */
 #define   LPCR_TC		ASM_CONST(0x0000000000000200)	/* Translation control */
 #define   LPCR_LPES		0x0000000c
 #define   LPCR_LPES0		ASM_CONST(0x0000000000000008)      /* LPAR Env selector 0 */

commit 29a969b764817c1dce819c2bc8c00a147529a5ef
Author: Michael Neuling <mikey@neuling.org>
Date:   Mon Oct 31 13:19:39 2016 +1100

    powerpc: Revert Load Monitor Register Support
    
    Load monitored is no longer supported on POWER9 so let's remove the
    code.
    
    This reverts commit bd3ea317fddf ("powerpc: Load Monitor Register
    Support").
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 9cd4e8cbc78c..c491cfebfc05 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -292,8 +292,6 @@
 #define SPRN_HRMOR	0x139	/* Real mode offset register */
 #define SPRN_HSRR0	0x13A	/* Hypervisor Save/Restore 0 */
 #define SPRN_HSRR1	0x13B	/* Hypervisor Save/Restore 1 */
-#define SPRN_LMRR	0x32D	/* Load Monitor Region Register */
-#define SPRN_LMSER	0x32E	/* Load Monitor Section Enable Register */
 #define SPRN_IC		0x350	/* Virtual Instruction Count */
 #define SPRN_VTB	0x351	/* Virtual Time Base */
 #define SPRN_LDBAR	0x352	/* LD Base Address Register */
@@ -304,7 +302,6 @@
 #define SPRN_PMCR	0x374	/* Power Management Control Register */
 
 /* HFSCR and FSCR bit numbers are the same */
-#define FSCR_LM_LG	11	/* Enable Load Monitor Registers */
 #define FSCR_TAR_LG	8	/* Enable Target Address Register */
 #define FSCR_EBB_LG	7	/* Enable Event Based Branching */
 #define FSCR_TM_LG	5	/* Enable Transactional Memory */
@@ -314,12 +311,10 @@
 #define FSCR_VECVSX_LG	1	/* Enable VMX/VSX  */
 #define FSCR_FP_LG	0	/* Enable Floating Point */
 #define SPRN_FSCR	0x099	/* Facility Status & Control Register */
-#define   FSCR_LM	__MASK(FSCR_LM_LG)
 #define   FSCR_TAR	__MASK(FSCR_TAR_LG)
 #define   FSCR_EBB	__MASK(FSCR_EBB_LG)
 #define   FSCR_DSCR	__MASK(FSCR_DSCR_LG)
 #define SPRN_HFSCR	0xbe	/* HV=1 Facility Status & Control Register */
-#define   HFSCR_LM	__MASK(FSCR_LM_LG)
 #define   HFSCR_TAR	__MASK(FSCR_TAR_LG)
 #define   HFSCR_EBB	__MASK(FSCR_EBB_LG)
 #define   HFSCR_TM	__MASK(FSCR_TM_LG)

commit d8bfb96a2e3c42f91a9944a19638c043cb86dd8f
Merge: 11ed3e0ef354 08bf75ba852e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 14 11:07:42 2016 -0700

    Merge tag 'powerpc-4.9-2' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull more powerpc updates from Michael Ellerman:
     "Some more powerpc updates for 4.9:
    
      Freescale updates from Scott Wood:
       - qbman support (a prerequisite for datapath drivers such as ethernet)
       - a PCI DMA fix+improvement
       - reset handler changes
       - more 8xx optimizations
       - some cleanups and fixes.'
    
      Fixes:
       - selftests/powerpc: Add missing binaries to .gitignores (Michael Ellerman)
       - selftests/powerpc: Fix build break caused by EXPORT_SYMBOL changes (Michael Ellerman)
       - powerpc/pseries: Fix stack corruption in htpe code (Laurent Dufour)
       - powerpc/64s: Fix power4_fixup_nap placement (Nicholas Piggin)
       - powerpc/64: Fix incorrect return value from __copy_tofrom_user (Paul Mackerras)
       - powerpc/mm/hash64: Fix might_have_hea() check (Michael Ellerman)
    
      Other:
       - MAINTAINERS: Remove myself from PA Semi entries (Olof Johansson)
       - MAINTAINERS: Drop separate pseries entry (Michael Ellerman)
       - MAINTAINERS: Update powerpc website & add selftests (Michael Ellerman):
    
    * tag 'powerpc-4.9-2' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (35 commits)
      powerpc/mm/hash64: Fix might_have_hea() check
      powerpc/64: Fix incorrect return value from __copy_tofrom_user
      powerpc/64s: Fix power4_fixup_nap placement
      powerpc/pseries: Fix stack corruption in htpe code
      selftests/powerpc: Fix build break caused by EXPORT_SYMBOL changes
      MAINTAINERS: Update powerpc website & add selftests
      MAINTAINERS: Drop separate pseries entry
      MAINTAINERS: Remove myself from PA Semi entries
      selftests/powerpc: Add missing binaries to .gitignores
      arch/powerpc: Add CONFIG_FSL_DPAA to corenetXX_smp_defconfig
      soc/qman: Add self-test for QMan driver
      soc/bman: Add self-test for BMan driver
      soc/fsl: Introduce DPAA 1.x QMan device driver
      soc/fsl: Introduce DPAA 1.x BMan device driver
      powerpc/8xx: make user addr DTLB miss the short path
      powerpc/8xx: Move additional DTLBMiss handlers out of exception area
      powerpc/8xx: use r3 to scratch CR in ITLBmiss
      soc/fsl/qe: fix gpio save_regs functions
      powerpc/8xx: add dedicated machine check handler
      powerpc/8xx: add system_reset_exception
      ...

commit 065397a969a0f80624598c5030c2551abbd986fd
Merge: 8321564a11bb e0b80f00bb96
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Oct 11 20:07:56 2016 +1100

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/scottwood/linux into next
    
    Freescale updates from Scott:
    
    "Highlights include qbman support (a prerequisite for datapath drivers
    such as ethernet), a PCI DMA fix+improvement, reset handler changes, more
    8xx optimizations, and some cleanups and fixes."

commit 07021b43597f506cc525d139ed1a94e79cf184f2
Merge: d1f5323370fc b7b7013cac55
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 7 20:19:31 2016 -0700

    Merge tag 'powerpc-4.9-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Highlights:
       - Major rework of Book3S 64-bit exception vectors (Nicholas Piggin)
       - Use gas sections for arranging exception vectors et. al.
       - Large set of TM cleanups and selftests (Cyril Bur)
       - Enable transactional memory (TM) lazily for userspace (Cyril Bur)
       - Support for XZ compression in the zImage wrapper (Oliver
         O'Halloran)
       - Add support for bpf constant blinding (Naveen N. Rao)
       - Beginnings of upstream support for PA Semi Nemo motherboards
         (Darren Stevens)
    
      Fixes:
       - Ensure .mem(init|exit).text are within _stext/_etext (Michael
         Ellerman)
       - xmon: Don't use ld on 32-bit (Michael Ellerman)
       - vdso64: Use double word compare on pointers (Anton Blanchard)
       - powerpc/nvram: Fix an incorrect partition merge (Pan Xinhui)
       - powerpc: Fix usage of _PAGE_RO in hugepage (Christophe Leroy)
       - powerpc/mm: Update FORCE_MAX_ZONEORDER range to allow hugetlb w/4K
         (Aneesh Kumar K.V)
       - Fix memory leak in queue_hotplug_event() error path (Andrew
         Donnellan)
       - Replay hypervisor maintenance interrupt first (Nicholas Piggin)
    
      Various performance optimisations (Anton Blanchard):
       - Align hot loops of memset() and backwards_memcpy()
       - During context switch, check before setting mm_cpumask
       - Remove static branch prediction in atomic{, 64}_add_unless
       - Only disable HAVE_EFFICIENT_UNALIGNED_ACCESS on POWER7 little
         endian
       - Set default CPU type to POWER8 for little endian builds
    
      Cleanups & features:
       - Sparse fixes/cleanups (Daniel Axtens)
       - Preserve CFAR value on SLB miss caused by access to bogus address
         (Paul Mackerras)
       - Radix MMU fixups for POWER9 (Aneesh Kumar K.V)
       - Support for setting used_(vsr|vr|spe) in sigreturn path (for CRIU)
         (Simon Guo)
       - Optimise syscall entry for virtual, relocatable case (Nicholas
         Piggin)
       - Optimise MSR handling in exception handling (Nicholas Piggin)
       - Support for kexec with Radix MMU (Benjamin Herrenschmidt)
       - powernv EEH fixes (Russell Currey)
       - Suprise PCI hotplug support for powernv (Gavin Shan)
       - Endian/sparse fixes for powernv PCI (Gavin Shan)
       - Defconfig updates (Anton Blanchard)
       - KVM: PPC: Book3S HV: Migrate pinned pages out of CMA (Balbir Singh)
       - cxl: Flush PSL cache before resetting the adapter (Frederic Barrat)
       - cxl: replace loop with for_each_child_of_node(), remove unneeded
         of_node_put() (Andrew Donnellan)
       - Fix HV facility unavailable to use correct handler (Nicholas
         Piggin)
       - Remove unnecessary syscall trampoline (Nicholas Piggin)
       - fadump: Fix build break when CONFIG_PROC_VMCORE=n (Michael
         Ellerman)
       - Quieten EEH message when no adapters are found (Anton Blanchard)
       - powernv: Add PHB register dump debugfs handle (Russell Currey)
       - Use kprobe blacklist for exception handlers & asm functions
         (Nicholas Piggin)
       - Document the syscall ABI (Nicholas Piggin)
       - MAINTAINERS: Update cxl maintainers (Michael Neuling)
       - powerpc: Remove all usages of NO_IRQ (Michael Ellerman)
    
      Minor cleanups:
       - Andrew Donnellan, Christophe Leroy, Colin Ian King, Cyril Bur,
         Frederic Barrat, Pan Xinhui, PrasannaKumar Muralidharan, Rui Teng,
         Simon Guo"
    
    * tag 'powerpc-4.9-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (156 commits)
      powerpc/bpf: Add support for bpf constant blinding
      powerpc/bpf: Implement support for tail calls
      powerpc/bpf: Introduce accessors for using the tmp local stack space
      powerpc/fadump: Fix build break when CONFIG_PROC_VMCORE=n
      powerpc: tm: Enable transactional memory (TM) lazily for userspace
      powerpc/tm: Add TM Unavailable Exception
      powerpc: Remove do_load_up_transact_{fpu,altivec}
      powerpc: tm: Rename transct_(*) to ck(\1)_state
      powerpc: tm: Always use fp_state and vr_state to store live registers
      selftests/powerpc: Add checks for transactional VSXs in signal contexts
      selftests/powerpc: Add checks for transactional VMXs in signal contexts
      selftests/powerpc: Add checks for transactional FPUs in signal contexts
      selftests/powerpc: Add checks for transactional GPRs in signal contexts
      selftests/powerpc: Check that signals always get delivered
      selftests/powerpc: Add TM tcheck helpers in C
      selftests/powerpc: Allow tests to extend their kill timeout
      selftests/powerpc: Introduce GPR asm helper header file
      selftests/powerpc: Move VMX stack frame macros to header file
      selftests/powerpc: Rework FPU stack placement macros and move to header file
      selftests/powerpc: Check for VSX preservation across userspace preemption
      ...

commit 3cee070a13b141b8eb5727c3bfa9920092f87264
Author: Cyril Bur <cyrilbur@gmail.com>
Date:   Fri Sep 23 16:18:10 2016 +1000

    powerpc: Return the new MSR from msr_check_and_set()
    
    msr_check_and_set() always performs a mfmsr() to determine if it needs
    to perform an mtmsr(), as mfmsr() can be a costly operation
    msr_check_and_set() could return the MSR now on the CPU to avoid
    callers of msr_check_and_set having to make their own mfmsr() call.
    
    Signed-off-by: Cyril Bur <cyrilbur@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 9dddabc2fced..a8f63bcb71af 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1250,7 +1250,7 @@ static inline void mtmsr_isync(unsigned long val)
 				     : "memory")
 #endif
 
-extern void msr_check_and_set(unsigned long bits);
+extern unsigned long msr_check_and_set(unsigned long bits);
 extern bool strict_msr_control;
 extern void __msr_check_and_clear(unsigned long bits);
 static inline void msr_check_and_clear(unsigned long bits)

commit fa73c3b25bd8d0d393dc6109a1dba3c2aef0451e
Author: Thomas Huth <thuth@redhat.com>
Date:   Wed Sep 21 15:06:45 2016 +0200

    KVM: PPC: Book3s PR: Allow access to unprivileged MMCR2 register
    
    The MMCR2 register is available twice, one time with number 785
    (privileged access), and one time with number 769 (unprivileged,
    but it can be disabled completely). In former times, the Linux
    kernel was using the unprivileged register 769 only, but since
    commit 8dd75ccb571f3c92c ("powerpc: Use privileged SPR number
    for MMCR2"), it uses the privileged register 785 instead.
    The KVM-PR code then of course also switched to use the SPR 785,
    but this is causing older guest kernels to crash, since these
    kernels still access 769 instead. So to support older kernels
    with KVM-PR again, we have to support register 769 in KVM-PR, too.
    
    Fixes: 8dd75ccb571f3c92c48014b3dabd3d51a115ab41
    Cc: stable@vger.kernel.org # v3.10+
    Signed-off-by: Thomas Huth <thuth@redhat.com>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index f69f40f1519a..978dada662ae 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -737,6 +737,7 @@
 #define   MMCR0_FCHV	0x00000001UL /* freeze conditions in hypervisor mode */
 #define SPRN_MMCR1	798
 #define SPRN_MMCR2	785
+#define SPRN_UMMCR2	769
 #define SPRN_MMCRA	0x312
 #define   MMCRA_SDSYNC	0x80000000UL /* SDAR synced with SIAR */
 #define   MMCRA_SDAR_DCACHE_MISS 0x40000000UL

commit 834e5a692120cc25c3935e8652a1989c2bc1c9e9
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Tue Aug 23 15:58:56 2016 +0200

    powerpc/8xx: use SPRN_EIE and SPRN_EID to enable/disable interrupts
    
    The 8xx has two special registers called EID (External Interrupt
    Disable) and EIE (External Interrupt Enable) for clearing/setting
    EE in MSR. It avoids the three instructions set mfmsr/ori/mtmsr or
    mfmsr/rlwinm/mtmsr and it avoids using a general register.
    
    We just have to write something in the special register to change MSR EE
    bit. So we write r0 into the register, regardless of r0 value.
    
    Writing to one of those two special registers also set the MSR RI bit,
    but this bit is only unset during beginning of exception prolog and end
    of exception epilog. When executing C-functions MSR RI is always set.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Scott Wood <oss@buserror.net>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 9dddabc2fced..b320c8fb0450 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1249,6 +1249,8 @@ static inline void mtmsr_isync(unsigned long val)
 				     : "r" ((unsigned long)(v)) \
 				     : "memory")
 #endif
+#define wrtspr(rn)	asm volatile("mtspr " __stringify(rn) ",0" : \
+				     : : "memory")
 
 extern void msr_check_and_set(unsigned long bits);
 extern bool strict_msr_control;

commit ad410674f5606a53ea2f2d45a78448a95e271fa0
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Wed Aug 24 15:03:39 2016 +0530

    powerpc/mm: Update the HID bit when switching from radix to hash
    
    Power9 DD1 requires to update the hid0 register when switching from
    hash to radix.
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Acked-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index f69f40f1519a..9dddabc2fced 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -475,6 +475,9 @@
 #define HID0_POWER8_1TO4LPAR	__MASK(51)
 #define HID0_POWER8_DYNLPARDIS	__MASK(48)
 
+/* POWER9 HID0 bits */
+#define HID0_POWER9_RADIX	__MASK(63 - 8)
+
 #define SPRN_HID1	0x3F1		/* Hardware Implementation Register 1 */
 #ifdef CONFIG_6xx
 #define HID1_EMCP	(1<<31)		/* 7450 Machine Check Pin Enable */

commit 905259e33d0ca0ee8e0d55783c3eef3402df81b7
Author: Kevin Hao <haokexin@gmail.com>
Date:   Sat Jul 23 14:42:39 2016 +0530

    powerpc: Remove mfvtb()
    
    This function is only used by get_vtb(). They are almost the same except
    the reading from the real register. Move the mfspr() to get_vtb() and
    kill the function mfvtb(). With this, we can eliminate the use of
    cpu_has_feature() in very core header file like reg.h. This is a
    preparation for the use of jump label for cpu_has_feature().
    
    Signed-off-by: Kevin Hao <haokexin@gmail.com>
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 40f3615bf940..f69f40f1519a 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1256,15 +1256,6 @@ static inline void msr_check_and_clear(unsigned long bits)
 		__msr_check_and_clear(bits);
 }
 
-static inline unsigned long mfvtb (void)
-{
-#ifdef CONFIG_PPC_BOOK3S_64
-	if (cpu_has_feature(CPU_FTR_ARCH_207S))
-		return mfspr(SPRN_VTB);
-#endif
-	return 0;
-}
-
 #ifdef __powerpc64__
 #if defined(CONFIG_PPC_CELL) || defined(CONFIG_PPC_FSL_BOOK3E)
 #define mftb()		({unsigned long rval;				\

commit 719dbb2df78fc9a40e28392b07cd715bfc5a665c
Merge: fbef66f0adcd 9f595fd8b548
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Sat Jul 30 13:43:19 2016 +1000

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/scottwood/linux into next
    
    Freescale updates from Scott:
    
    "Highlights include more 8xx optimizations, device tree updates,
    and MVME7100 support."

commit a4b349540a26af9a544e2e858223140fb9ddc35c
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Fri Jul 15 21:04:26 2016 +1000

    powerpc/mm: Cleanup LPCR defines
    
    This makes it easy to verify we are not overloading the bits.
    No functionality change by this patch.
    
    mpe: Cleanup more. Completely fixup whitespace, convert all UL values to
    ASM_CONST(), and replace all occurrences of 63-x with the actual shift.
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 295a19aec9b9..d7e9ab5e4709 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -330,43 +330,43 @@
 #define   HFSCR_FP	__MASK(FSCR_FP_LG)
 #define SPRN_TAR	0x32f	/* Target Address Register */
 #define SPRN_LPCR	0x13E	/* LPAR Control Register */
-#define   LPCR_VPM0	(1ul << (63-0))
-#define   LPCR_VPM1	(1ul << (63-1))
-#define   LPCR_ISL	(1ul << (63-2))
-#define   LPCR_VC_SH	(63-2)
-#define   LPCR_DPFD_SH	(63-11)
-#define   LPCR_DPFD	(7ul << LPCR_DPFD_SH)
-#define   LPCR_VRMASD	(0x1ful << (63-16))
-#define   LPCR_VRMA_L	(1ul << (63-12))
-#define   LPCR_VRMA_LP0	(1ul << (63-15))
-#define   LPCR_VRMA_LP1	(1ul << (63-16))
-#define   LPCR_VRMASD_SH (63-16)
-#define   LPCR_RMLS    0x1C000000      /* impl dependent rmo limit sel */
-#define	  LPCR_RMLS_SH	(63-37)
-#define   LPCR_ILE     0x02000000      /* !HV irqs set MSR:LE */
-#define   LPCR_AIL	0x01800000	/* Alternate interrupt location */
-#define   LPCR_AIL_0	0x00000000	/* MMU off exception offset 0x0 */
-#define   LPCR_AIL_3	0x01800000	/* MMU on exception offset 0xc00...4xxx */
-#define   LPCR_ONL	0x00040000	/* online - PURR/SPURR count */
-#define   LPCR_LD	0x00020000	/* large decremeter */
-#define   LPCR_PECE	0x0001f000	/* powersave exit cause enable */
-#define     LPCR_PECEDP	0x00010000	/* directed priv dbells cause exit */
-#define     LPCR_PECEDH	0x00008000	/* directed hyp dbells cause exit */
-#define     LPCR_PECE0	0x00004000	/* ext. exceptions can cause exit */
-#define     LPCR_PECE1	0x00002000	/* decrementer can cause exit */
-#define     LPCR_PECE2	0x00001000	/* machine check etc can cause exit */
-#define   LPCR_MER	0x00000800	/* Mediated External Exception */
-#define   LPCR_MER_SH	11
-#define   LPCR_TC      0x00000200	/* Translation control */
-#define   LPCR_LPES    0x0000000c
-#define   LPCR_LPES0   0x00000008      /* LPAR Env selector 0 */
-#define   LPCR_LPES1   0x00000004      /* LPAR Env selector 1 */
-#define   LPCR_LPES_SH	2
-#define   LPCR_RMI     0x00000002      /* real mode is cache inhibit */
-#define   LPCR_HVICE   0x00000002      /* P9: HV interrupt enable */
-#define   LPCR_HDICE   0x00000001      /* Hyp Decr enable (HV,PR,EE) */
-#define   LPCR_UPRT    0x00400000      /* Use Process Table (ISA 3) */
-#define   LPCR_HR      0x00100000
+#define   LPCR_VPM0		ASM_CONST(0x8000000000000000)
+#define   LPCR_VPM1		ASM_CONST(0x4000000000000000)
+#define   LPCR_ISL		ASM_CONST(0x2000000000000000)
+#define   LPCR_VC_SH		61
+#define   LPCR_DPFD_SH		52
+#define   LPCR_DPFD		(ASM_CONST(7) << LPCR_DPFD_SH)
+#define   LPCR_VRMASD_SH	47
+#define   LPCR_VRMASD		(ASM_CONST(1) << LPCR_VRMASD_SH)
+#define   LPCR_VRMA_L		ASM_CONST(0x0008000000000000)
+#define   LPCR_VRMA_LP0		ASM_CONST(0x0001000000000000)
+#define   LPCR_VRMA_LP1		ASM_CONST(0x0000800000000000)
+#define   LPCR_RMLS		0x1C000000	/* Implementation dependent RMO limit sel */
+#define   LPCR_RMLS_SH		26
+#define   LPCR_ILE		ASM_CONST(0x0000000002000000)   /* !HV irqs set MSR:LE */
+#define   LPCR_AIL		ASM_CONST(0x0000000001800000)	/* Alternate interrupt location */
+#define   LPCR_AIL_0		ASM_CONST(0x0000000000000000)	/* MMU off exception offset 0x0 */
+#define   LPCR_AIL_3		ASM_CONST(0x0000000001800000)   /* MMU on exception offset 0xc00...4xxx */
+#define   LPCR_ONL		ASM_CONST(0x0000000000040000)	/* online - PURR/SPURR count */
+#define   LPCR_LD		ASM_CONST(0x0000000000020000)	/* large decremeter */
+#define   LPCR_PECE		ASM_CONST(0x000000000001f000)	/* powersave exit cause enable */
+#define     LPCR_PECEDP	ASM_CONST(0x0000000000010000)	/* directed priv dbells cause exit */
+#define     LPCR_PECEDH	ASM_CONST(0x0000000000008000)	/* directed hyp dbells cause exit */
+#define     LPCR_PECE0		ASM_CONST(0x0000000000004000)	/* ext. exceptions can cause exit */
+#define     LPCR_PECE1		ASM_CONST(0x0000000000002000)	/* decrementer can cause exit */
+#define     LPCR_PECE2		ASM_CONST(0x0000000000001000)	/* machine check etc can cause exit */
+#define   LPCR_MER		ASM_CONST(0x0000000000000800)	/* Mediated External Exception */
+#define   LPCR_MER_SH		11
+#define   LPCR_TC		ASM_CONST(0x0000000000000200)	/* Translation control */
+#define   LPCR_LPES		0x0000000c
+#define   LPCR_LPES0		ASM_CONST(0x0000000000000008)      /* LPAR Env selector 0 */
+#define   LPCR_LPES1		ASM_CONST(0x0000000000000004)      /* LPAR Env selector 1 */
+#define   LPCR_LPES_SH		2
+#define   LPCR_RMI		ASM_CONST(0x0000000000000002)      /* real mode is cache inhibit */
+#define   LPCR_HVICE		ASM_CONST(0x0000000000000002)      /* P9: HV interrupt enable */
+#define   LPCR_HDICE		ASM_CONST(0x0000000000000001)      /* Hyp Decr enable (HV,PR,EE) */
+#define   LPCR_UPRT		ASM_CONST(0x0000000000400000)      /* Use Process Table (ISA 3) */
+#define   LPCR_HR		ASM_CONST(0x0000000000100000)
 #ifndef SPRN_LPID
 #define SPRN_LPID	0x13F	/* Logical Partition Identifier */
 #endif

commit bf16cdf48a5369ba29614a0ade4ae5daf7a9e47c
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Wed Jul 13 15:05:21 2016 +0530

    powerpc/mm/radix: Update LPCR HR bit as per ISA
    
    PowerISA 3.0 requires the MMU mode (radix vs. hash) of the hypervisor
    to be mirrored in the LPCR register, in addition to the partition table.
    This is done to avoid fetching from the table when deciding, among other
    things, how to perform transitions to HV mode on some interrupts.
    So let's set it up appropriately
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Acked-by: Balbir Singh <bsingharora@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 6de6abe7deef..295a19aec9b9 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -366,6 +366,7 @@
 #define   LPCR_HVICE   0x00000002      /* P9: HV interrupt enable */
 #define   LPCR_HDICE   0x00000001      /* Hyp Decr enable (HV,PR,EE) */
 #define   LPCR_UPRT    0x00400000      /* Use Process Table (ISA 3) */
+#define   LPCR_HR      0x00100000
 #ifndef SPRN_LPID
 #define SPRN_LPID	0x13F	/* Logical Partition Identifier */
 #endif

commit 9baaef0a22c82a6c5d85b7535240e778c06e5b20
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Jul 8 16:37:06 2016 +1000

    powerpc/irq: Add support for HV virtualization interrupts
    
    This will be delivering external interrupts from the XIVE to the
    Hypervisor. We treat it as a normal external interrupt for the
    lazy irq disable code (so it will be replayed as a 0x500) and
    route it to do_IRQ.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c0263a2d1008..6de6abe7deef 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -363,6 +363,7 @@
 #define   LPCR_LPES1   0x00000004      /* LPAR Env selector 1 */
 #define   LPCR_LPES_SH	2
 #define   LPCR_RMI     0x00000002      /* real mode is cache inhibit */
+#define   LPCR_HVICE   0x00000002      /* P9: HV interrupt enable */
 #define   LPCR_HDICE   0x00000001      /* Hyp Decr enable (HV,PR,EE) */
 #define   LPCR_UPRT    0x00400000      /* Use Process Table (ISA 3) */
 #ifndef SPRN_LPID

commit bcef83a00dc44ee25ff4d6e078cf6432ddf74dec
Author: Shreyas B. Prabhu <shreyas@linux.vnet.ibm.com>
Date:   Fri Jul 8 11:50:49 2016 +0530

    powerpc/powernv: Add platform support for stop instruction
    
    POWER ISA v3 defines a new idle processor core mechanism. In summary,
     a) new instruction named stop is added. This instruction replaces
            instructions like nap, sleep, rvwinkle.
     b) new per thread SPR named Processor Stop Status and Control Register
            (PSSCR) is added which controls the behavior of stop instruction.
    
    PSSCR layout:
    ----------------------------------------------------------
    | PLS | /// | SD | ESL | EC | PSLL | /// | TR | MTL | RL |
    ----------------------------------------------------------
    0      4     41   42    43   44     48    54   56    60
    
    PSSCR key fields:
            Bits 0:3  - Power-Saving Level Status. This field indicates the lowest
            power-saving state the thread entered since stop instruction was last
            executed.
    
            Bit 42 - Enable State Loss
            0 - No state is lost irrespective of other fields
            1 - Allows state loss
    
            Bits 44:47 - Power-Saving Level Limit
            This limits the power-saving level that can be entered into.
    
            Bits 60:63 - Requested Level
            Used to specify which power-saving level must be entered on executing
            stop instruction
    
    This patch adds support for stop instruction and PSSCR handling.
    
    Reviewed-by: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
    Signed-off-by: Shreyas B. Prabhu <shreyas@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index ac4be83f8fdc..c0263a2d1008 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -145,6 +145,15 @@
 #define MSR_64BIT	0
 #endif
 
+/* Power Management - Processor Stop Status and Control Register Fields */
+#define PSSCR_RL_MASK		0x0000000F /* Requested Level */
+#define PSSCR_MTL_MASK		0x000000F0 /* Maximum Transition Level */
+#define PSSCR_TR_MASK		0x00000300 /* Transition State */
+#define PSSCR_PSLL_MASK		0x000F0000 /* Power-Saving Level Limit */
+#define PSSCR_EC		0x00100000 /* Exit Criterion */
+#define PSSCR_ESL		0x00200000 /* Enable State Loss */
+#define PSSCR_SD		0x00400000 /* Status Disable */
+
 /* Floating Point Status and Control Register (FPSCR) Fields */
 #define FPSCR_FX	0x80000000	/* FPU exception summary */
 #define FPSCR_FEX	0x40000000	/* FPU enabled exception summary */
@@ -291,6 +300,7 @@
 #define SPRN_PMICR	0x354   /* Power Management Idle Control Reg */
 #define SPRN_PMSR	0x355   /* Power Management Status Reg */
 #define SPRN_PMMAR	0x356	/* Power Management Memory Activity Register */
+#define SPRN_PSSCR	0x357	/* Processor Stop Status and Control Register (ISA 3.0) */
 #define SPRN_PMCR	0x374	/* Power Management Control Register */
 
 /* HFSCR and FSCR bit numbers are the same */

commit e0ddf7a24558b356d5cf5ecc12cb4e305c800953
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Jul 7 22:54:30 2016 +1000

    powerpc/xmon: Dump ISA 2.07 SPRs
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 320136f5fe28..ac4be83f8fdc 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -268,6 +268,7 @@
 #define   DSISR_KEYFAULT	0x00200000	/* Key fault */
 #define SPRN_TBRL	0x10C	/* Time Base Read Lower Register (user, R/O) */
 #define SPRN_TBRU	0x10D	/* Time Base Read Upper Register (user, R/O) */
+#define SPRN_CIR	0x11B	/* Chip Information Register (hyper, R/0) */
 #define SPRN_TBWL	0x11C	/* Time Base Lower Register (super, R/W) */
 #define SPRN_TBWU	0x11D	/* Time Base Upper Register (super, R/W) */
 #define SPRN_TBU40	0x11E	/* Timebase upper 40 bits (hyper, R/W) */

commit c223c90386bc2306510e0ceacd768a0123ff2a2f
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Tue May 17 08:33:46 2016 +0200

    powerpc32: provide VIRT_CPU_ACCOUNTING
    
    This patch provides VIRT_CPU_ACCOUTING to PPC32 architecture.
    PPC32 doesn't have the PACA structure, so we use the task_info
    structure to store the accounting data.
    
    In order to reuse on PPC32 the PPC64 functions, all u64 data has
    been replaced by 'unsigned long' so that it is u32 on PPC32 and
    u64 on PPC64
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Scott Wood <oss@buserror.net>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 320136f5fe28..d383f13b9fac 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1294,6 +1294,7 @@ static inline unsigned long mfvtb (void)
 			asm volatile("mfspr %0, %1" : "=r" (rval) : \
 				"i" (SPRN_TBRU)); rval;})
 #endif
+#define mftb()		mftbl()
 #endif /* !__powerpc64__ */
 
 #define mttbl(v)	asm volatile("mttbl %0":: "r"(v))

commit 799010244685334b34e674d354a1a71a3a6b6148
Author: Oliver O'Halloran <oohall@gmail.com>
Date:   Fri Jul 1 16:20:39 2016 +1000

    powerpc/timer: Large Decrementer support
    
    Power ISAv3 adds a large decrementer (LD) mode which increases the size
    of the decrementer register. The size of the enlarged decrementer
    register is between 32 and 64 bits with the exact size being dependent
    on the implementation. When in LD mode, reads are sign extended to 64
    bits and a decrementer exception is raised when the high bit is set (i.e
    the value goes below zero). Writes however are truncated to the physical
    register width so some care needs to be taken to ensure that the high
    bit is not set when reloading the decrementer. This patch adds support
    for using the LD inside the host kernel on processors that support it.
    
    When LD mode is supported firmware will supply the ibm,dec-bits property
    for CPU nodes to allow the kernel to determine the maximum decrementer
    value. Enabling LD mode is a hypervisor privileged operation so the kernel
    can only enable it manually when running in hypervisor mode. Guests that
    support LD mode can request it using the "ibm,client-architecture-support"
    firmware call (not implemented in this patch) or some other platform
    specific method. If this property is not supplied then the traditional
    decrementer width of 32 bit is assumed and LD mode will not be enabled.
    
    This patch was based on initial work by Jack Miller.
    
    Signed-off-by: Oliver O'Halloran <oohall@gmail.com>
    Signed-off-by: Balbir Singh <bsingharora@gmail.com>
    Acked-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index ce44fe27f48f..320136f5fe28 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -337,6 +337,7 @@
 #define   LPCR_AIL_0	0x00000000	/* MMU off exception offset 0x0 */
 #define   LPCR_AIL_3	0x01800000	/* MMU on exception offset 0xc00...4xxx */
 #define   LPCR_ONL	0x00040000	/* online - PURR/SPURR count */
+#define   LPCR_LD	0x00020000	/* large decremeter */
 #define   LPCR_PECE	0x0001f000	/* powersave exit cause enable */
 #define     LPCR_PECEDP	0x00010000	/* directed priv dbells cause exit */
 #define     LPCR_PECEDH	0x00008000	/* directed hyp dbells cause exit */

commit bd3ea317fddfd0f2044f94bed294b90c4bc8e69e
Author: Jack Miller <jack@codezen.org>
Date:   Thu Jun 9 12:31:09 2016 +1000

    powerpc: Load Monitor Register Support
    
    This enables new registers, LMRR and LMSER, that can trigger an EBB in
    userspace code when a monitored load (via the new ldmx instruction)
    loads memory from a monitored space. This facility is controlled by a
    new FSCR bit, LM.
    
    This patch disables the FSCR LM control bit on task init and enables
    that bit when a load monitor facility unavailable exception is taken
    for using it. On context switch, this bit is then used to determine
    whether the two relevant registers are saved and restored. This is
    done lazily for performance reasons.
    
    Signed-off-by: Jack Miller <jack@codezen.org>
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index a0948f40bc7b..ce44fe27f48f 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -282,6 +282,8 @@
 #define SPRN_HRMOR	0x139	/* Real mode offset register */
 #define SPRN_HSRR0	0x13A	/* Hypervisor Save/Restore 0 */
 #define SPRN_HSRR1	0x13B	/* Hypervisor Save/Restore 1 */
+#define SPRN_LMRR	0x32D	/* Load Monitor Region Register */
+#define SPRN_LMSER	0x32E	/* Load Monitor Section Enable Register */
 #define SPRN_IC		0x350	/* Virtual Instruction Count */
 #define SPRN_VTB	0x351	/* Virtual Time Base */
 #define SPRN_LDBAR	0x352	/* LD Base Address Register */
@@ -291,6 +293,7 @@
 #define SPRN_PMCR	0x374	/* Power Management Control Register */
 
 /* HFSCR and FSCR bit numbers are the same */
+#define FSCR_LM_LG	11	/* Enable Load Monitor Registers */
 #define FSCR_TAR_LG	8	/* Enable Target Address Register */
 #define FSCR_EBB_LG	7	/* Enable Event Based Branching */
 #define FSCR_TM_LG	5	/* Enable Transactional Memory */
@@ -300,10 +303,12 @@
 #define FSCR_VECVSX_LG	1	/* Enable VMX/VSX  */
 #define FSCR_FP_LG	0	/* Enable Floating Point */
 #define SPRN_FSCR	0x099	/* Facility Status & Control Register */
+#define   FSCR_LM	__MASK(FSCR_LM_LG)
 #define   FSCR_TAR	__MASK(FSCR_TAR_LG)
 #define   FSCR_EBB	__MASK(FSCR_EBB_LG)
 #define   FSCR_DSCR	__MASK(FSCR_DSCR_LG)
 #define SPRN_HFSCR	0xbe	/* HV=1 Facility Status & Control Register */
+#define   HFSCR_LM	__MASK(FSCR_LM_LG)
 #define   HFSCR_TAR	__MASK(FSCR_TAR_LG)
 #define   HFSCR_EBB	__MASK(FSCR_EBB_LG)
 #define   HFSCR_TM	__MASK(FSCR_TM_LG)

commit 8dd75ccb571f3c92c48014b3dabd3d51a115ab41
Author: Thomas Huth <thuth@redhat.com>
Date:   Thu May 12 13:29:11 2016 +0200

    powerpc: Use privileged SPR number for MMCR2
    
    We are already using the privileged versions of MMCR0, MMCR1
    and MMCRA in the kernel, so for MMCR2, we should better use
    the privileged versions, too, to be consistent.
    
    Fixes: 240686c13687 ("powerpc: Initialise PMU related regs on Power8")
    Cc: stable@vger.kernel.org # v3.10+
    Suggested-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Thomas Huth <thuth@redhat.com>
    Acked-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c58a3e76caf1..a0948f40bc7b 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -717,7 +717,7 @@
 #define   MMCR0_FCWAIT	0x00000002UL /* freeze counter in WAIT state */
 #define   MMCR0_FCHV	0x00000001UL /* freeze conditions in hypervisor mode */
 #define SPRN_MMCR1	798
-#define SPRN_MMCR2	769
+#define SPRN_MMCR2	785
 #define SPRN_MMCRA	0x312
 #define   MMCRA_SDSYNC	0x80000000UL /* SDAR synced with SIAR */
 #define   MMCRA_SDAR_DCACHE_MISS 0x40000000UL

commit d23fac2b27d94aeb7b65536a50d32bfdc21fe01e
Author: Thomas Huth <thuth@redhat.com>
Date:   Thu May 12 13:26:44 2016 +0200

    powerpc: Fix definition of SIAR and SDAR registers
    
    The SIAR and SDAR registers are available twice, one time as SPRs
    780 / 781 (unprivileged, but read-only), and one time as the SPRs
    796 / 797 (privileged, but read and write). The Linux kernel code
    currently uses the unprivileged  SPRs - while this is OK for reading,
    writing to that register of course does not work.
    Since the KVM code tries to write to this register, too (see the mtspr
    in book3s_hv_rmhandlers.S), the contents of this register sometimes get
    lost for the guests, e.g. during migration of a VM.
    To fix this issue, simply switch to the privileged SPR numbers instead.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Thomas Huth <thuth@redhat.com>
    Acked-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c1e82e968506..c58a3e76caf1 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -754,13 +754,13 @@
 #define SPRN_PMC6	792
 #define SPRN_PMC7	793
 #define SPRN_PMC8	794
-#define SPRN_SIAR	780
-#define SPRN_SDAR	781
 #define SPRN_SIER	784
 #define   SIER_SIPR		0x2000000	/* Sampled MSR_PR */
 #define   SIER_SIHV		0x1000000	/* Sampled MSR_HV */
 #define   SIER_SIAR_VALID	0x0400000	/* SIAR contents valid */
 #define   SIER_SDAR_VALID	0x0200000	/* SDAR contents valid */
+#define SPRN_SIAR	796
+#define SPRN_SDAR	797
 #define SPRN_TACR	888
 #define SPRN_TCSCR	889
 #define SPRN_CSIGR	890

commit 2bfd65e45e877fb5704730244da67c748d28a1b8
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Fri Apr 29 23:25:58 2016 +1000

    powerpc/mm/radix: Add radix callbacks for early init routines
    
    This adds routines for early setup for radix. We use device tree
    property "ibm,processor-radix-AP-encodings" to find supported page
    sizes. If we don't find the above we consider 64K and 4K as supported
    page sizes.
    
    We do map vmemap using 2M page size if we can. The linear mapping is
    done such that we use required page size for that range. For example
    memory of 3.5G is mapped such that we use 1G mapping till 3G range and
    use 2M mapping for the rest.
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 47082bcbf1e5..c1e82e968506 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -347,6 +347,7 @@
 #define   LPCR_LPES_SH	2
 #define   LPCR_RMI     0x00000002      /* real mode is cache inhibit */
 #define   LPCR_HDICE   0x00000001      /* Hyp Decr enable (HV,PR,EE) */
+#define   LPCR_UPRT    0x00400000      /* Use Process Table (ISA 3) */
 #ifndef SPRN_LPID
 #define SPRN_LPID	0x13F	/* Logical Partition Identifier */
 #endif

commit e99833448c5fa198a120db6d7087dd17149dc273
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Fri Apr 29 23:25:42 2016 +1000

    powerpc/mm/radix: Add partition table format & callback
    
    Add structs and #defines related to the radix MMU partition table
    format. We also add a ppc_md callback for updating a partition table
    entry.
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index cf09c6eb5ee7..47082bcbf1e5 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -587,6 +587,7 @@
 #define SPRN_PIR	0x3FF	/* Processor Identification Register */
 #endif
 #define SPRN_TIR	0x1BE	/* Thread Identification Register */
+#define SPRN_PTCR	0x1D0	/* Partition table control Register */
 #define SPRN_PSPB	0x09F	/* Problem State Priority Boost reg */
 #define SPRN_PTEHI	0x3D5	/* 981 7450 PTE HI word (S/W TLB load) */
 #define SPRN_PTELO	0x3D6	/* 982 7450 PTE LO word (S/W TLB load) */

commit 86c9ffcc1ed17497a5df473232a7e654fa8cfa1f
Author: Philippe Bergheaud <felix@linux.vnet.ibm.com>
Date:   Thu Mar 31 11:19:27 2016 +0200

    powerpc: Define PVR value for POWER8NVL processor
    
    Signed-off-by: Philippe Bergheaud <felix@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index f5f4c66bbbc9..cf09c6eb5ee7 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1182,6 +1182,7 @@
 #define PVR_970GX	0x0045
 #define PVR_POWER7p	0x004A
 #define PVR_POWER8E	0x004B
+#define PVR_POWER8NVL	0x004C
 #define PVR_POWER8	0x004D
 #define PVR_BE		0x0070
 #define PVR_PA6T	0x0090

commit 1458dd951f7cc0127508f928497c9ab06b5e557d
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Tue Feb 9 17:08:14 2016 +0100

    powerpc/8xx: Handle CPU6 ERRATA directly in mtspr() macro
    
    MPC8xx has an ERRATA on the use of mtspr() for some registers
    This patch includes the ERRATA handling directly into mtspr() macro
    so that mtspr() users don't need to bother about that errata
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Scott Wood <oss@buserror.net>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 52ed654d01ba..f5f4c66bbbc9 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1219,9 +1219,11 @@ static inline void mtmsr_isync(unsigned long val)
 #define mfspr(rn)	({unsigned long rval; \
 			asm volatile("mfspr %0," __stringify(rn) \
 				: "=r" (rval)); rval;})
+#ifndef mtspr
 #define mtspr(rn, v)	asm volatile("mtspr " __stringify(rn) ",%0" : \
 				     : "r" ((unsigned long)(v)) \
 				     : "memory")
+#endif
 
 extern void msr_check_and_set(unsigned long bits);
 extern bool strict_msr_control;

commit de2a20aa7237b45d3c14a2505804a8daa95a8f53
Author: Cyril Bur <cyrilbur@gmail.com>
Date:   Mon Feb 29 17:53:48 2016 +1100

    powerpc: Prepare for splitting giveup_{fpu, altivec, vsx} in two
    
    This prepares for the decoupling of saving {fpu,altivec,vsx} registers and
    marking {fpu,altivec,vsx} as being unused by a thread.
    
    Currently giveup_{fpu,altivec,vsx}() does both however optimisations to
    task switching can be made if these two operations are decoupled.
    save_all() will permit the saving of registers to thread structs and leave
    threads MSR with bits enabled.
    
    This patch introduces no functional change.
    
    Signed-off-by: Cyril Bur <cyrilbur@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 11a81bd5dabd..52ed654d01ba 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -75,6 +75,14 @@
 #define MSR_HV		0
 #endif
 
+/*
+ * To be used in shared book E/book S, this avoids needing to worry about
+ * book S/book E in shared code
+ */
+#ifndef MSR_SPE
+#define MSR_SPE 	0
+#endif
+
 #define MSR_VEC		__MASK(MSR_VEC_LG)	/* Enable AltiVec */
 #define MSR_VSX		__MASK(MSR_VSX_LG)	/* Enable VSX */
 #define MSR_POW		__MASK(MSR_POW_LG)	/* Enable Power Management */

commit 446957ba5127141ee007fc61509e24a9e60853d9
Author: Adam Buchbinder <adam.buchbinder@gmail.com>
Date:   Wed Feb 24 10:51:11 2016 -0800

    powerpc: Fix misspellings in comments.
    
    Signed-off-by: Adam Buchbinder <adam.buchbinder@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c4cb2ffc624e..11a81bd5dabd 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -376,7 +376,7 @@
 #define SPRN_TSCR	0x399	/* Thread Switch Control Register */
 
 #define SPRN_DEC	0x016		/* Decrement Register */
-#define SPRN_DER	0x095		/* Debug Enable Regsiter */
+#define SPRN_DER	0x095		/* Debug Enable Register */
 #define DER_RSTE	0x40000000	/* Reset Interrupt */
 #define DER_CHSTPE	0x20000000	/* Check Stop */
 #define DER_MCIE	0x10000000	/* Machine Check Interrupt */
@@ -401,7 +401,7 @@
 #define SPRN_DPDES	0x0B0		/* Directed Priv. Doorbell Exc. State */
 #define SPRN_EAR	0x11A		/* External Address Register */
 #define SPRN_HASH1	0x3D2		/* Primary Hash Address Register */
-#define SPRN_HASH2	0x3D3		/* Secondary Hash Address Resgister */
+#define SPRN_HASH2	0x3D3		/* Secondary Hash Address Register */
 #define SPRN_HID0	0x3F0		/* Hardware Implementation Register 0 */
 #define HID0_HDICE_SH	(63 - 23)	/* 970 HDEC interrupt enable */
 #define HID0_EMCP	(1<<31)		/* Enable Machine Check pin */
@@ -514,7 +514,7 @@
 #define ICTRL_EICP	0x00000100	/* enable icache par. check */
 #define SPRN_IMISS	0x3D4		/* Instruction TLB Miss Register */
 #define SPRN_IMMR	0x27E		/* Internal Memory Map Register */
-#define SPRN_L2CR	0x3F9		/* Level 2 Cache Control Regsiter */
+#define SPRN_L2CR	0x3F9		/* Level 2 Cache Control Register */
 #define SPRN_L2CR2	0x3f8
 #define L2CR_L2E		0x80000000	/* L2 enable */
 #define L2CR_L2PE		0x40000000	/* L2 parity enable */
@@ -549,7 +549,7 @@
 #define L2CR_L2DO_745x		0x00010000	/* L2 data only (745x) */
 #define L2CR_L2REP_745x		0x00001000	/* L2 repl. algorithm (745x) */
 #define L2CR_L2HWF_745x		0x00000800	/* L2 hardware flush (745x) */
-#define SPRN_L3CR		0x3FA	/* Level 3 Cache Control Regsiter */
+#define SPRN_L3CR		0x3FA	/* Level 3 Cache Control Register */
 #define L3CR_L3E		0x80000000	/* L3 enable */
 #define L3CR_L3PE		0x40000000	/* L3 data parity enable */
 #define L3CR_L3APE		0x20000000	/* L3 addr parity enable */

commit 1901d8bb45c3b82335c48e6232871f72ad10ed95
Merge: 801c0b2c4db3 7f821fc9c77a
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Mon Dec 14 20:40:32 2015 +1100

    Merge tag 'powerpc-4.4-3' into next
    
    Merge the two TM fixes we merged in 4.4. We are about to merge selftests
    for these, and without the fixes the selftests will oops.
    
    powerpc fixes for 4.4 #2
    
     - tm: Block signal return from setting invalid MSR state from Michael Neuling
     - tm: Check for already reclaimed tasks from Michael Neuling

commit 3eb5d5888dc68c9b187998ca4249b8b9fa481eeb
Author: Anton Blanchard <anton@samba.org>
Date:   Thu Oct 29 11:44:06 2015 +1100

    powerpc: Add ppc_strict_facility_enable boot option
    
    Add a boot option that strictly manages the MSR unavailable bits.
    This catches kernel uses of FP/Altivec/SPE that would otherwise
    corrupt user state.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 987dac090244..eb2986e60c50 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1214,6 +1214,15 @@ static inline void mtmsr_isync(unsigned long val)
 				     : "r" ((unsigned long)(v)) \
 				     : "memory")
 
+extern void msr_check_and_set(unsigned long bits);
+extern bool strict_msr_control;
+extern void __msr_check_and_clear(unsigned long bits);
+static inline void msr_check_and_clear(unsigned long bits)
+{
+	if (strict_msr_control)
+		__msr_check_and_clear(bits);
+}
+
 static inline unsigned long mfvtb (void)
 {
 #ifdef CONFIG_PPC_BOOK3S_64

commit 611b0e5c19963374175b39f42117b03ee7573228
Author: Anton Blanchard <anton@samba.org>
Date:   Thu Oct 29 11:43:59 2015 +1100

    powerpc: Create mtmsrd_isync()
    
    mtmsrd_isync() will do an mtmsrd followed by an isync on older
    processors. On newer processors we avoid the isync via a feature fixup.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index a908ada8e0a5..987dac090244 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1193,12 +1193,20 @@
 #define __mtmsrd(v, l)	asm volatile("mtmsrd %0," __stringify(l) \
 				     : : "r" (v) : "memory")
 #define mtmsr(v)	__mtmsrd((v), 0)
+#define __MTMSR		"mtmsrd"
 #else
 #define mtmsr(v)	asm volatile("mtmsr %0" : \
 				     : "r" ((unsigned long)(v)) \
 				     : "memory")
+#define __MTMSR		"mtmsr"
 #endif
 
+static inline void mtmsr_isync(unsigned long val)
+{
+	asm volatile(__MTMSR " %0; " ASM_FTR_IFCLR("isync", "nop", %1) : :
+			"r" (val), "i" (CPU_FTR_ARCH_206) : "memory");
+}
+
 #define mfspr(rn)	({unsigned long rval; \
 			asm volatile("mfspr %0," __stringify(rn) \
 				: "=r" (rval)); rval;})

commit d2b9d2a5ad5ef04ff978c9923d19730cb05efd55
Author: Michael Neuling <mikey@neuling.org>
Date:   Thu Nov 19 15:44:44 2015 +1100

    powerpc/tm: Block signal return setting invalid MSR state
    
    Currently we allow both the MSR T and S bits to be set by userspace on
    a signal return.  Unfortunately this is a reserved configuration and
    will cause a TM Bad Thing exception if attempted (via rfid).
    
    This patch checks for this case in both the 32 and 64 bit signals
    code.  If both T and S are set, we mark the context as invalid.
    
    Found using a syscall fuzzer.
    
    Fixes: 2b0a576d15e0 ("powerpc: Add new transactional memory state to the signal context")
    Cc: stable@vger.kernel.org # v3.9+
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index a908ada8e0a5..2220f7a60def 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -108,6 +108,7 @@
 #define MSR_TS_T	__MASK(MSR_TS_T_LG)	/*  Transaction Transactional */
 #define MSR_TS_MASK	(MSR_TS_T | MSR_TS_S)   /* Transaction State bits */
 #define MSR_TM_ACTIVE(x) (((x) & MSR_TS_MASK) != 0) /* Transaction active? */
+#define MSR_TM_RESV(x) (((x) & MSR_TS_MASK) == MSR_TS_MASK) /* Reserved */
 #define MSR_TM_TRANSACTIONAL(x)	(((x) & MSR_TS_MASK) == MSR_TS_T)
 #define MSR_TM_SUSPENDED(x)	(((x) & MSR_TS_MASK) == MSR_TS_S)
 

commit 23316316c1af0677a041c81f3ad6efb9dc470b33
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Oct 21 16:03:14 2015 +1100

    powerpc: Revert "Use the POWER8 Micro Partition Prefetch Engine in KVM HV on POWER8"
    
    This reverts commit 9678cdaae939 ("Use the POWER8 Micro Partition
    Prefetch Engine in KVM HV on POWER8") because the original commit had
    multiple, partly self-cancelling bugs, that could cause occasional
    memory corruption.
    
    In fact the logmpp instruction was incorrectly using register r0 as the
    source of the buffer address and operation code, and depending on what
    was in r0, it would either do nothing or corrupt the 64k page pointed to
    by r0.
    
    The logmpp instruction encoding and the operation code definitions could
    be corrected, but then there is the problem that there is no clearly
    defined way to know when the hardware has finished writing to the
    buffer.
    
    The original commit attempted to work around this by aborting the
    write-out before starting the prefetch, but this is ineffective in the
    case where the virtual core is now executing on a different physical
    core from the one where the write-out was initiated.
    
    These problems plus advice from the hardware designers not to use the
    function (since the measured performance improvement from using the
    feature was actually mostly negative), mean that reverting the code is
    the best option.
    
    Fixes: 9678cdaae939 ("Use the POWER8 Micro Partition Prefetch Engine in KVM HV on POWER8")
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index aa1cc5f015ee..a908ada8e0a5 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -226,7 +226,6 @@
 #define   CTRL_TE	0x00c00000	/* thread enable */
 #define   CTRL_RUNLATCH	0x1
 #define SPRN_DAWR	0xB4
-#define SPRN_MPPR	0xB8	/* Micro Partition Prefetch Register */
 #define SPRN_RPR	0xBA	/* Relative Priority Register */
 #define SPRN_CIABR	0xBB
 #define   CIABR_PRIV		0x3

commit e63dbd16ab7be41f5b66a70f1082242d76dd21d7
Author: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
Date:   Wed Aug 5 12:38:31 2015 +0530

    powerpc: Add an inline function to update POWER8 HID0
    
    Section 3.7 of Version 1.2 of the Power8 Processor User's Manual
    prescribes that updates to HID0 be preceded by a SYNC instruction and
    followed by an ISYNC instruction (Page 91).
    
    Create an inline function name update_power8_hid0() which follows this
    recipe and invoke it from the static split core path.
    
    Signed-off-by: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
    Reviewed-by: Sam Bobroff <sam.bobroff@au1.ibm.com>
    Tested-by: Sam Bobroff <sam.bobroff@au1.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index bb2758819bc9..aa1cc5f015ee 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1280,6 +1280,15 @@ struct pt_regs;
 
 extern void ppc_save_regs(struct pt_regs *regs);
 
+static inline void update_power8_hid0(unsigned long hid0)
+{
+	/*
+	 *  The HID0 update on Power8 should at the very least be
+	 *  preceded by a a SYNC instruction followed by an ISYNC
+	 *  instruction
+	 */
+	asm volatile("sync; mtspr %0,%1; isync":: "i"(SPRN_HID0), "r"(hid0));
+}
 #endif /* __ASSEMBLY__ */
 #endif /* __KERNEL__ */
 #endif /* _ASM_POWERPC_REG_H */

commit 1c53973172f84fafa8ad94f17ac427fdd4f260a2
Author: Anton Blanchard <anton@samba.org>
Date:   Tue Jul 7 13:56:59 2015 +1000

    powerpc: Remove mtmsrd(), use existing mtmsr()
    
    mtmsr() does the right thing on 32bit and 64bit, so use it everywhere.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index af56b5c6c81a..bb2758819bc9 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1193,8 +1193,7 @@
 #ifdef CONFIG_PPC_BOOK3S_64
 #define __mtmsrd(v, l)	asm volatile("mtmsrd %0," __stringify(l) \
 				     : : "r" (v) : "memory")
-#define mtmsrd(v)	__mtmsrd((v), 0)
-#define mtmsr(v)	mtmsrd(v)
+#define mtmsr(v)	__mtmsrd((v), 0)
 #else
 #define mtmsr(v)	asm volatile("mtmsr %0" : \
 				     : "r" ((unsigned long)(v)) \

commit 755563bc79c764c90b9f44db5e4fe6c556d3440c
Author: Paul Mackerras <paulus@samba.org>
Date:   Thu Mar 19 19:29:01 2015 +1100

    powerpc/powernv: Fixes for hypervisor doorbell handling
    
    Since we can now use hypervisor doorbells for host IPIs, this makes
    sure we clear the host IPI flag when taking a doorbell interrupt, and
    clears any pending doorbell IPI in pnv_smp_cpu_kill_self() (as we
    already do for IPIs sent via the XICS interrupt controller).  Otherwise
    if there did happen to be a leftover pending doorbell interrupt for
    an offline CPU thread for any reason, it would prevent that thread from
    going into a power-saving mode; it would instead keep waking up because
    of the interrupt.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 1c874fb533bb..af56b5c6c81a 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -608,13 +608,16 @@
 #define   SRR1_ISI_N_OR_G	0x10000000 /* ISI: Access is no-exec or G */
 #define   SRR1_ISI_PROT		0x08000000 /* ISI: Other protection fault */
 #define   SRR1_WAKEMASK		0x00380000 /* reason for wakeup */
+#define   SRR1_WAKEMASK_P8	0x003c0000 /* reason for wakeup on POWER8 */
 #define   SRR1_WAKESYSERR	0x00300000 /* System error */
 #define   SRR1_WAKEEE		0x00200000 /* External interrupt */
 #define   SRR1_WAKEMT		0x00280000 /* mtctrl */
 #define	  SRR1_WAKEHMI		0x00280000 /* Hypervisor maintenance */
 #define   SRR1_WAKEDEC		0x00180000 /* Decrementer interrupt */
+#define   SRR1_WAKEDBELL	0x00140000 /* Privileged doorbell on P8 */
 #define   SRR1_WAKETHERM	0x00100000 /* Thermal management interrupt */
 #define	  SRR1_WAKERESET	0x00100000 /* System reset */
+#define   SRR1_WAKEHDBELL	0x000c0000 /* Hypervisor doorbell on P8 */
 #define	  SRR1_WAKESTATE	0x00030000 /* Powersave exit mask [46:47] */
 #define	  SRR1_WS_DEEPEST	0x00030000 /* Some resources not maintained,
 					  * may not be recoverable */

commit 77b54e9f213f76a23736940cf94bcd765fc00f40
Author: Shreyas B. Prabhu <shreyas@linux.vnet.ibm.com>
Date:   Wed Dec 10 00:26:53 2014 +0530

    powernv/powerpc: Add winkle support for offline cpus
    
    Winkle is a deep idle state supported in power8 chips. A core enters
    winkle when all the threads of the core enter winkle. In this state
    power supply to the entire chiplet i.e core, private L2 and private L3
    is turned off. As a result it gives higher powersavings compared to
    sleep.
    
    But entering winkle results in a total hypervisor state loss. Hence the
    hypervisor context has to be preserved before entering winkle and
    restored upon wake up.
    
    Power-on Reset Engine (PORE) is a dedicated engine which is responsible
    for powering on the chiplet during wake up. It can be programmed to
    restore the register contests of a few specific registers. This patch
    uses PORE to restore register state wherever possible and uses stack to
    save and restore rest of the necessary registers.
    
    With hypervisor state restore things fall under three categories-
    per-core state, per-subcore state and per-thread state. To manage this,
    extend the infrastructure introduced for sleep. Mainly we add a paca
    variable subcore_sibling_mask. Using this and the core_idle_state we can
    distingush first thread in core and subcore.
    
    Signed-off-by: Shreyas B. Prabhu <shreyas@linux.vnet.ibm.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: linuxppc-dev@lists.ozlabs.org
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index a68ee15964b3..1c874fb533bb 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -373,6 +373,7 @@
 #define SPRN_DBAT7L	0x23F	/* Data BAT 7 Lower Register */
 #define SPRN_DBAT7U	0x23E	/* Data BAT 7 Upper Register */
 #define SPRN_PPR	0x380	/* SMT Thread status Register */
+#define SPRN_TSCR	0x399	/* Thread Switch Control Register */
 
 #define SPRN_DEC	0x016		/* Decrement Register */
 #define SPRN_DER	0x095		/* Debug Enable Regsiter */
@@ -730,6 +731,7 @@
 #define SPRN_BESCR	806	/* Branch event status and control register */
 #define   BESCR_GE	0x8000000000000000ULL /* Global Enable */
 #define SPRN_WORT	895	/* Workload optimization register - thread */
+#define SPRN_WORC	863	/* Workload optimization register - core */
 
 #define SPRN_PMC1	787
 #define SPRN_PMC2	788

commit 8117ac6a6c2fa0f847ff6a21a1f32c8d2c8501d0
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Dec 10 00:26:50 2014 +0530

    powerpc/powernv: Switch off MMU before entering nap/sleep/rvwinkle mode
    
    Currently, when going idle, we set the flag indicating that we are in
    nap mode (paca->kvm_hstate.hwthread_state) and then execute the nap
    (or sleep or rvwinkle) instruction, all with the MMU on.  This is bad
    for two reasons: (a) the architecture specifies that those instructions
    must be executed with the MMU off, and in fact with only the SF, HV, ME
    and possibly RI bits set, and (b) this introduces a race, because as
    soon as we set the flag, another thread can switch the MMU to a guest
    context.  If the race is lost, this thread will typically start looping
    on relocation-on ISIs at 0xc...4400.
    
    This fixes it by setting the MSR as required by the architecture before
    setting the flag or executing the nap/sleep/rvwinkle instruction.
    
    Cc: stable@vger.kernel.org
    [ shreyas@linux.vnet.ibm.com: Edited to handle LE ]
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Shreyas B. Prabhu <shreyas@linux.vnet.ibm.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: linuxppc-dev@lists.ozlabs.org
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c998279bd85b..a68ee15964b3 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -118,8 +118,10 @@
 #define __MSR		(MSR_ME | MSR_RI | MSR_IR | MSR_DR | MSR_ISF |MSR_HV)
 #ifdef __BIG_ENDIAN__
 #define MSR_		__MSR
+#define MSR_IDLE	(MSR_ME | MSR_SF | MSR_HV)
 #else
 #define MSR_		(__MSR | MSR_LE)
+#define MSR_IDLE	(MSR_ME | MSR_SF | MSR_HV | MSR_LE)
 #endif
 #define MSR_KERNEL	(MSR_ | MSR_64BIT)
 #define MSR_USER32	(MSR_ | MSR_PR | MSR_EE)

commit acf620ecf56cfc4edaffaf158250e128539cdd26
Author: Anton Blanchard <anton@samba.org>
Date:   Mon Oct 13 19:41:39 2014 +1100

    powerpc: Rename __get_SP() to current_stack_pointer()
    
    Michael points out that __get_SP() is a pretty horrible
    function name. Let's give it a better name.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index e539d7e71451..c998279bd85b 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1265,7 +1265,7 @@ static inline unsigned long mfvtb (void)
 
 #define proc_trap()	asm volatile("trap")
 
-extern unsigned long __get_SP(void);
+extern unsigned long current_stack_pointer(void);
 
 extern unsigned long scom970_read(unsigned int address);
 extern void scom970_write(unsigned int address, unsigned long value);

commit bfe9a2cfe91a1c920f152ce5fd0a9ad74b3daf12
Author: Anton Blanchard <anton@samba.org>
Date:   Mon Oct 13 19:41:38 2014 +1100

    powerpc: Reimplement __get_SP() as a function not a define
    
    Li Zhong points out an issue with our current __get_SP()
    implementation. If ftrace function tracing is enabled (ie -pg
    profiling using _mcount) we spill a stack frame on 64bit all the
    time.
    
    If a function calls __get_SP() and later calls a function that is
    tail call optimised, we will pop the stack frame and the value
    returned by __get_SP() is no longer valid. An example from Li can
    be found in save_stack_trace -> save_context_stack:
    
    c0000000000432c0 <.save_stack_trace>:
    c0000000000432c0:       mflr    r0
    c0000000000432c4:       std     r0,16(r1)
    c0000000000432c8:       stdu    r1,-128(r1) <-- stack frame for _mcount
    c0000000000432cc:       std     r3,112(r1)
    c0000000000432d0:       bl      <._mcount>
    c0000000000432d4:       nop
    
    c0000000000432d8:       mr      r4,r1 <-- __get_SP()
    
    c0000000000432dc:       ld      r5,632(r13)
    c0000000000432e0:       ld      r3,112(r1)
    c0000000000432e4:       li      r6,1
    
    c0000000000432e8:       addi    r1,r1,128 <-- pop stack frame
    
    c0000000000432ec:       ld      r0,16(r1)
    c0000000000432f0:       mtlr    r0
    c0000000000432f4:       b       <.save_context_stack> <-- tail call optimized
    
    save_context_stack ends up with a stack pointer below the current
    one, and it is likely to be scribbled over.
    
    Fix this by making __get_SP() a function which returns the
    callers stack frame. Also replace inline assembly which grabs
    the stack pointer in save_stack_trace and show_stack with
    __get_SP().
    
    This also fixes an issue with perf_arch_fetch_caller_regs().
    It currently unwinds the stack once, which will skip a
    valid stack frame on a leaf function. With the __get_SP() fixes
    in this patch, we never need to unwind the stack frame to get
    to the first interesting frame.
    
    We have to export __get_SP() because perf_arch_fetch_caller_regs()
    (which is used in modules) calls it from a header file.
    
    Reported-by: Li Zhong <zhong@linux.vnet.ibm.com>
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index fe3f9488f321..e539d7e71451 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1265,8 +1265,7 @@ static inline unsigned long mfvtb (void)
 
 #define proc_trap()	asm volatile("trap")
 
-#define __get_SP()	({unsigned long sp; \
-			asm volatile("mr %0,1": "=r" (sp)); sp;})
+extern unsigned long __get_SP(void);
 
 extern unsigned long scom970_read(unsigned int address);
 extern void scom970_write(unsigned int address, unsigned long value);

commit 75d43b2d0a323ba894d85060888f039e41b441ca
Merge: d0b7abb2c7c0 cb0446c1b625
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Sat Oct 4 08:59:06 2014 +1000

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/scottwood/linux.git
    
    Freescale updates from Scott (27 commits):
    
      "Highlights include DMA32 zone support (SATA, USB, etc now works on 64-bit
       FSL kernels), MSI changes, 8xx optimizations and cleanup, t104x board
       support, and PrPMC PCI enumeration."

commit ae466bde19752f8638fd458225fb65ded5db5e16
Author: LEROY Christophe <christophe.leroy@c-s.fr>
Date:   Fri Aug 29 11:14:37 2014 +0200

    powerpc/8xx: Declare SPRG2 as a SCRATCH register
    
    Since commit 469d62be9263b92f2c3329540cbb1c076111f4f3, SPRG2 is used as a
    scratch register just like SPRG0 and SPRG1. So Declare it as such and fix
    the comment which is not valid anymore since that commit.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Scott Wood <scottwood@freescale.com>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index bffd89d27301..1ff8ba94b9f4 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -950,7 +950,7 @@
  * 32-bit 8xx:
  *	- SPRG0 scratch for exception vectors
  *	- SPRG1 scratch for exception vectors
- *	- SPRG2 apparently unused but initialized
+ *	- SPRG2 scratch for exception vectors
  *
  */
 #ifdef CONFIG_PPC64
@@ -1060,6 +1060,7 @@
 #ifdef CONFIG_8xx
 #define SPRN_SPRG_SCRATCH0	SPRN_SPRG0
 #define SPRN_SPRG_SCRATCH1	SPRN_SPRG1
+#define SPRN_SPRG_SCRATCH2	SPRN_SPRG2
 #endif
 
 

commit 56758e3c3ca7e3d8960e0e8f881e80adf119f4fe
Author: Nishanth Aravamudan <nacc@linux.vnet.ibm.com>
Date:   Mon Aug 11 16:43:18 2014 -0700

    powerpc: remove duplicate definition of TEXASR_FS
    
    It appears that commits 7f06f21d40a6 ("powerpc/tm: Add checking to
    treclaim/trechkpt") and e4e38121507a ("KVM: PPC: Book3S HV: Add
    transactional memory support") both added definitions of TEXASR_FS.
    Remove one of them. At the same time, fix the alignment of the remaining
    definition (should be tab-separated like the rest of the #defines).
    
    Signed-off-by: Nishanth Aravamudan <nacc@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 1c987bf794ef..0c0505956a29 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -213,9 +213,8 @@
 #define SPRN_ACOP	0x1F	/* Available Coprocessor Register */
 #define SPRN_TFIAR	0x81	/* Transaction Failure Inst Addr   */
 #define SPRN_TEXASR	0x82	/* Transaction EXception & Summary */
-#define   TEXASR_FS	__MASK(63-36)	/* Transaction Failure Summary */
 #define SPRN_TEXASRU	0x83	/* ''	   ''	   ''	 Upper 32  */
-#define   TEXASR_FS     __MASK(63-36) /* TEXASR Failure Summary */
+#define   TEXASR_FS	__MASK(63-36) /* TEXASR Failure Summary */
 #define SPRN_TFHAR	0x80	/* Transaction Failure Handler Addr */
 #define SPRN_CTRLF	0x088
 #define SPRN_CTRLT	0x098

commit 66bb0aa077978dbb76e6283531eb3cc7a878de38
Merge: e306e3be1cbe c77dcacb3975
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Aug 7 11:35:30 2014 -0700

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull second round of KVM changes from Paolo Bonzini:
     "Here are the PPC and ARM changes for KVM, which I separated because
      they had small conflicts (respectively within KVM documentation, and
      with 3.16-rc changes).  Since they were all within the subsystem, I
      took care of them.
    
      Stephen Rothwell reported some snags in PPC builds, but they are all
      fixed now; the latest linux-next report was clean.
    
      New features for ARM include:
       - KVM VGIC v2 emulation on GICv3 hardware
       - Big-Endian support for arm/arm64 (guest and host)
       - Debug Architecture support for arm64 (arm32 is on Christoffer's todo list)
    
      And for PPC:
       - Book3S: Good number of LE host fixes, enable HV on LE
       - Book3S HV: Add in-guest debug support
    
      This release drops support for KVM on the PPC440.  As a result, the
      PPC merge removes more lines than it adds.  :)
    
      I also included an x86 change, since Davidlohr tied it to an
      independent bug report and the reporter quickly provided a Tested-by;
      there was no reason to wait for -rc2"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (122 commits)
      KVM: Move more code under CONFIG_HAVE_KVM_IRQFD
      KVM: nVMX: fix "acknowledge interrupt on exit" when APICv is in use
      KVM: nVMX: Fix nested vmexit ack intr before load vmcs01
      KVM: PPC: Enable IRQFD support for the XICS interrupt controller
      KVM: Give IRQFD its own separate enabling Kconfig option
      KVM: Move irq notifier implementation into eventfd.c
      KVM: Move all accesses to kvm::irq_routing into irqchip.c
      KVM: irqchip: Provide and use accessors for irq routing table
      KVM: Don't keep reference to irq routing table in irqfd struct
      KVM: PPC: drop duplicate tracepoint
      arm64: KVM: fix 64bit CP15 VM access for 32bit guests
      KVM: arm64: GICv3: mandate page-aligned GICV region
      arm64: KVM: GICv3: move system register access to msr_s/mrs_s
      KVM: PPC: PR: Handle FSCR feature deselects
      KVM: PPC: HV: Remove generic instruction emulation
      KVM: PPC: BOOKEHV: rename e500hv_spr to bookehv_spr
      KVM: PPC: Remove DCR handling
      KVM: PPC: Expose helper functions for data/inst faults
      KVM: PPC: Separate loadstore emulation from priv emulation
      KVM: PPC: Handle magic page in kvmppc_ld/st
      ...

commit 9678cdaae93932473f696fdea5debf3eee1e1260
Author: Stewart Smith <stewart@linux.vnet.ibm.com>
Date:   Fri Jul 18 14:18:43 2014 +1000

    Use the POWER8 Micro Partition Prefetch Engine in KVM HV on POWER8
    
    The POWER8 processor has a Micro Partition Prefetch Engine, which is
    a fancy way of saying "has way to store and load contents of L2 or
    L2+MRU way of L3 cache". We initiate the storing of the log (list of
    addresses) using the logmpp instruction and start restore by writing
    to a SPR.
    
    The logmpp instruction takes parameters in a single 64bit register:
    - starting address of the table to store log of L2/L2+L3 cache contents
      - 32kb for L2
      - 128kb for L2+L3
      - Aligned relative to maximum size of the table (32kb or 128kb)
    - Log control (no-op, L2 only, L2 and L3, abort logout)
    
    We should abort any ongoing logging before initiating one.
    
    To initiate restore, we write to the MPPR SPR. The format of what to write
    to the SPR is similar to the logmpp instruction parameter:
    - starting address of the table to read from (same alignment requirements)
    - table size (no data, until end of table)
    - prefetch rate (from fastest possible to slower. about every 8, 16, 24 or
      32 cycles)
    
    The idea behind loading and storing the contents of L2/L3 cache is to
    reduce memory latency in a system that is frequently swapping vcores on
    a physical CPU.
    
    The best case scenario for doing this is when some vcores are doing very
    cache heavy workloads. The worst case is when they have about 0 cache hits,
    so we just generate needless memory operations.
    
    This implementation just does L2 store/load. In my benchmarks this proves
    to be useful.
    
    Benchmark 1:
     - 16 core POWER8
     - 3x Ubuntu 14.04LTS guests (LE) with 8 VCPUs each
     - No split core/SMT
     - two guests running sysbench memory test.
       sysbench --test=memory --num-threads=8 run
     - one guest running apache bench (of default HTML page)
       ab -n 490000 -c 400 http://localhost/
    
    This benchmark aims to measure performance of real world application (apache)
    where other guests are cache hot with their own workloads. The sysbench memory
    benchmark does pointer sized writes to a (small) memory buffer in a loop.
    
    In this benchmark with this patch I can see an improvement both in requests
    per second (~5%) and in mean and median response times (again, about 5%).
    The spread of minimum and maximum response times were largely unchanged.
    
    benchmark 2:
     - Same VM config as benchmark 1
     - all three guests running sysbench memory benchmark
    
    This benchmark aims to see if there is a positive or negative affect to this
    cache heavy benchmark. Although due to the nature of the benchmark (stores) we
    may not see a difference in performance, but rather hopefully an improvement
    in consistency of performance (when vcore switched in, don't have to wait
    many times for cachelines to be pulled in)
    
    The results of this benchmark are improvements in consistency of performance
    rather than performance itself. With this patch, the few outliers in duration
    go away and we get more consistent performance in each guest.
    
    benchmark 3:
     - same 3 guests and CPU configuration as benchmark 1 and 2.
     - two idle guests
     - 1 guest running STREAM benchmark
    
    This scenario also saw performance improvement with this patch. On Copy and
    Scale workloads from STREAM, I got 5-6% improvement with this patch. For
    Add and triad, it was around 10% (or more).
    
    benchmark 4:
     - same 3 guests as previous benchmarks
     - two guests running sysbench --memory, distinctly different cache heavy
       workload
     - one guest running STREAM benchmark.
    
    Similar improvements to benchmark 3.
    
    benchmark 5:
     - 1 guest, 8 VCPUs, Ubuntu 14.04
     - Host configured with split core (SMT8, subcores-per-core=4)
     - STREAM benchmark
    
    In this benchmark, we see a 10-20% performance improvement across the board
    of STREAM benchmark results with this patch.
    
    Based on preliminary investigation and microbenchmarks
    by Prerna Saxena <prerna@linux.vnet.ibm.com>
    
    Signed-off-by: Stewart Smith <stewart@linux.vnet.ibm.com>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 0ef17ade7730..c547b26371b8 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -225,6 +225,7 @@
 #define   CTRL_TE	0x00c00000	/* thread enable */
 #define   CTRL_RUNLATCH	0x1
 #define SPRN_DAWR	0xB4
+#define SPRN_MPPR	0xB8	/* Micro Partition Prefetch Register */
 #define SPRN_RPR	0xBA	/* Relative Priority Register */
 #define SPRN_CIABR	0xBB
 #define   CIABR_PRIV		0x3

commit 8c95ead6039d46d2d5c375d3cadac8708121fbe4
Author: Bharat Bhushan <Bharat.Bhushan@freescale.com>
Date:   Fri Jul 25 11:32:43 2014 +0530

    KVM: PPC: Remove comment saying SPRG1 is used for vcpu pointer
    
    Scott Wood pointed out that We are no longer using SPRG1 for vcpu pointer,
    but using SPRN_SPRG_THREAD <=> SPRG3 (thread->vcpu). So this comment
    is not valid now.
    
    Note: SPRN_SPRG3R is not supported (do not see any need as of now),
    and if we want to support this in future then we have to shift to using
    SPRG1 for VCPU pointer.
    
    Signed-off-by: Bharat Bhushan <Bharat.Bhushan@freescale.com>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c8f33816a381..0ef17ade7730 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -944,9 +944,6 @@
  *      readable variant for reads, which can avoid a fault
  *      with KVM type virtualization.
  *
- *      (*) Under KVM, the host SPRG1 is used to point to
- *      the current VCPU data structure
- *
  * 32-bit 8xx:
  *	- SPRG0 scratch for exception vectors
  *	- SPRG1 scratch for exception vectors

commit 8f42ab2749d00ea15157ab896cfbed73a247b3e1
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Thu Jun 5 17:38:02 2014 +0530

    KVM: PPC: BOOK3S: PR: Emulate virtual timebase register
    
    virtual time base register is a per VM, per cpu register that needs
    to be saved and restored on vm exit and entry. Writing to VTB is not
    allowed in the privileged mode.
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    [agraf: fix compile error]
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index bffd89d27301..c8f33816a381 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1203,6 +1203,15 @@
 				     : "r" ((unsigned long)(v)) \
 				     : "memory")
 
+static inline unsigned long mfvtb (void)
+{
+#ifdef CONFIG_PPC_BOOK3S_64
+	if (cpu_has_feature(CPU_FTR_ARCH_207S))
+		return mfspr(SPRN_VTB);
+#endif
+	return 0;
+}
+
 #ifdef __powerpc64__
 #if defined(CONFIG_PPC_CELL) || defined(CONFIG_PPC_FSL_BOOK3E)
 #define mftb()		({unsigned long rval;				\

commit 376af5947c0e441ccbf98f0212d4ffbf171528f6
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Jul 10 12:29:19 2014 +1000

    powerpc: Remove STAB code
    
    Old cpus didn't have a Segment Lookaside Buffer (SLB), instead they had
    a Segment Table (STAB). Now that we've dropped support for those cpus,
    we can remove the STAB support entirely.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index bffd89d27301..f7b97b895708 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -254,7 +254,7 @@
 #define   DSISR_PROTFAULT	0x08000000	/* protection fault */
 #define   DSISR_ISSTORE		0x02000000	/* access was a store */
 #define   DSISR_DABRMATCH	0x00400000	/* hit data breakpoint */
-#define   DSISR_NOSEGMENT	0x00200000	/* STAB/SLB miss */
+#define   DSISR_NOSEGMENT	0x00200000	/* SLB miss */
 #define   DSISR_KEYFAULT	0x00200000	/* Key fault */
 #define SPRN_TBRL	0x10C	/* Time Base Read Lower Register (user, R/O) */
 #define SPRN_TBRU	0x10D	/* Time Base Read Upper Register (user, R/O) */

commit c5aec4c76af1a2d89ee2f2d4d5463b2ad2d85de5
Merge: 2937f5efa575 0c0a3e5a100b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jun 10 18:54:22 2014 -0700

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc
    
    Pull powerpc updates from Ben Herrenschmidt:
     "Here is the bulk of the powerpc changes for this merge window.  It got
      a bit delayed in part because I wasn't paying attention, and in part
      because I discovered I had a core PCI change without a PCI maintainer
      ack in it.  Bjorn eventually agreed it was ok to merge it though we'll
      probably improve it later and I didn't want to rebase to add his ack.
    
      There is going to be a bit more next week, essentially fixes that I
      still want to sort through and test.
    
      The biggest item this time is the support to build the ppc64 LE kernel
      with our new v2 ABI.  We previously supported v2 userspace but the
      kernel itself was a tougher nut to crack.  This is now sorted mostly
      thanks to Anton and Rusty.
    
      We also have a fairly big series from Cedric that add support for
      64-bit LE zImage boot wrapper.  This was made harder by the fact that
      traditionally our zImage wrapper was always 32-bit, but our new LE
      toolchains don't really support 32-bit anymore (it's somewhat there
      but not really "supported") so we didn't want to rely on it.  This
      meant more churn that just endian fixes.
    
      This brings some more LE bits as well, such as the ability to run in
      LE mode without a hypervisor (ie. under OPAL firmware) by doing the
      right OPAL call to reinitialize the CPU to take HV interrupts in the
      right mode and the usual pile of endian fixes.
    
      There's another series from Gavin adding EEH improvements (one day we
      *will* have a release with less than 20 EEH patches, I promise!).
    
      Another highlight is the support for the "Split core" functionality on
      P8 by Michael.  This allows a P8 core to be split into "sub cores" of
      4 threads which allows the subcores to run different guests under KVM
      (the HW still doesn't support a partition per thread).
    
      And then the usual misc bits and fixes ..."
    
    [ Further delayed by gmail deciding that BenH is a dirty spammer.
      Google knows.  ]
    
    * 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc: (155 commits)
      powerpc/powernv: Add missing include to LPC code
      selftests/powerpc: Test the THP bug we fixed in the previous commit
      powerpc/mm: Check paca psize is up to date for huge mappings
      powerpc/powernv: Pass buffer size to OPAL validate flash call
      powerpc/pseries: hcall functions are exported to modules, need _GLOBAL_TOC()
      powerpc: Exported functions __clear_user and copy_page use r2 so need _GLOBAL_TOC()
      powerpc/powernv: Set memory_block_size_bytes to 256MB
      powerpc: Allow ppc_md platform hook to override memory_block_size_bytes
      powerpc/powernv: Fix endian issues in memory error handling code
      powerpc/eeh: Skip eeh sysfs when eeh is disabled
      powerpc: 64bit sendfile is capped at 2GB
      powerpc/powernv: Provide debugfs access to the LPC bus via OPAL
      powerpc/serial: Use saner flags when creating legacy ports
      powerpc: Add cpu family documentation
      powerpc/xmon: Fix up xmon format strings
      powerpc/powernv: Add calls to support little endian host
      powerpc: Document sysfs DSCR interface
      powerpc: Fix regression of per-CPU DSCR setting
      powerpc: Split __SYSFS_SPRSETUP macro
      arch: powerpc/fadump: Cleaning up inconsistent NULL checks
      ...

commit 9bc01a9bc77edac2ea6db62c5111a7f4335d4021
Author: Paul Mackerras <paulus@samba.org>
Date:   Mon May 26 19:48:40 2014 +1000

    KVM: PPC: Book3S HV: Work around POWER8 performance monitor bugs
    
    This adds workarounds for two hardware bugs in the POWER8 performance
    monitor unit (PMU), both related to interrupt generation.  The effect
    of these bugs is that PMU interrupts can get lost, leading to tools
    such as perf reporting fewer counts and samples than they should.
    
    The first bug relates to the PMAO (perf. mon. alert occurred) bit in
    MMCR0; setting it should cause an interrupt, but doesn't.  The other
    bug relates to the PMAE (perf. mon. alert enable) bit in MMCR0.
    Setting PMAE when a counter is negative and counter negative
    conditions are enabled to cause alerts should cause an alert, but
    doesn't.
    
    The workaround for the first bug is to create conditions where a
    counter will overflow, whenever we are about to restore a MMCR0
    value that has PMAO set (and PMAO_SYNC clear).  The workaround for
    the second bug is to freeze all counters using MMCR2 before reading
    MMCR0.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index e5d2e0bc7e03..4852bcf270f3 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -670,18 +670,20 @@
 #define   MMCR0_PROBLEM_DISABLE MMCR0_FCP
 #define   MMCR0_FCM1	0x10000000UL /* freeze counters while MSR mark = 1 */
 #define   MMCR0_FCM0	0x08000000UL /* freeze counters while MSR mark = 0 */
-#define   MMCR0_PMXE	0x04000000UL /* performance monitor exception enable */
-#define   MMCR0_FCECE	0x02000000UL /* freeze ctrs on enabled cond or event */
+#define   MMCR0_PMXE	ASM_CONST(0x04000000) /* perf mon exception enable */
+#define   MMCR0_FCECE	ASM_CONST(0x02000000) /* freeze ctrs on enabled cond or event */
 #define   MMCR0_TBEE	0x00400000UL /* time base exception enable */
 #define   MMCR0_BHRBA	0x00200000UL /* BHRB Access allowed in userspace */
 #define   MMCR0_EBE	0x00100000UL /* Event based branch enable */
 #define   MMCR0_PMCC	0x000c0000UL /* PMC control */
 #define   MMCR0_PMCC_U6	0x00080000UL /* PMC1-6 are R/W by user (PR) */
 #define   MMCR0_PMC1CE	0x00008000UL /* PMC1 count enable*/
-#define   MMCR0_PMCjCE	0x00004000UL /* PMCj count enable*/
+#define   MMCR0_PMCjCE	ASM_CONST(0x00004000) /* PMCj count enable*/
 #define   MMCR0_TRIGGER	0x00002000UL /* TRIGGER enable */
-#define   MMCR0_PMAO_SYNC 0x00000800UL /* PMU interrupt is synchronous */
-#define   MMCR0_PMAO	0x00000080UL /* performance monitor alert has occurred, set to 0 after handling exception */
+#define   MMCR0_PMAO_SYNC ASM_CONST(0x00000800) /* PMU intr is synchronous */
+#define   MMCR0_C56RUN	ASM_CONST(0x00000100) /* PMC5/6 count when RUN=0 */
+/* performance monitor alert has occurred, set to 0 after handling exception */
+#define   MMCR0_PMAO	ASM_CONST(0x00000080)
 #define   MMCR0_SHRFC	0x00000040UL /* SHRre freeze conditions between threads */
 #define   MMCR0_FC56	0x00000010UL /* freeze counters 5 and 6 */
 #define   MMCR0_FCTI	0x00000008UL /* freeze counters in tags inactive mode */

commit e2186023f2d81ee7bb42d2a7dec3d889df7cdace
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Fri May 23 18:15:30 2014 +1000

    powerpc/powernv: Add support for POWER8 split core on powernv
    
    Upcoming POWER8 chips support a concept called split core. This is where the
    core can be split into subcores that although not full cores, are able to
    appear as full cores to a guest.
    
    The splitting & unsplitting procedure is mildly complicated, and explained at
    length in the comments within the patch.
    
    One notable detail is that when splitting or unsplitting we need to pull
    offline cpus out of their offline state to do work as part of the procedure.
    
    The interface for changing the split mode is via a sysfs file, eg:
    
     $ echo 2 > /sys/devices/system/cpu/subcores_per_core
    
    Currently supported values are '1', '2' and '4'. And indicate respectively that
    the core should be unsplit, split in half, and split in quarters. These modes
    correspond to threads_per_subcore of 8, 4 and 2.
    
    We do not allow changing the split mode while KVM VMs are active. This is to
    prevent the value changing while userspace is configuring the VM, and also to
    prevent the mode being changed in such a way that existing guests are unable to
    be run.
    
    CPU hotplug fixes by Srivatsa.  max_cpus fixes by Mahesh.  cpuset fixes by
    benh.  Fix for irq race by paulus.  The rest by mikey and mpe.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Signed-off-by: Mahesh Salgaonkar <mahesh@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 29de0152878f..2cd799b382ec 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -225,6 +225,7 @@
 #define   CTRL_TE	0x00c00000	/* thread enable */
 #define   CTRL_RUNLATCH	0x1
 #define SPRN_DAWR	0xB4
+#define SPRN_RPR	0xBA	/* Relative Priority Register */
 #define SPRN_CIABR	0xBB
 #define   CIABR_PRIV		0x3
 #define   CIABR_PRIV_USER	1
@@ -273,8 +274,10 @@
 #define SPRN_HSRR1	0x13B	/* Hypervisor Save/Restore 1 */
 #define SPRN_IC		0x350	/* Virtual Instruction Count */
 #define SPRN_VTB	0x351	/* Virtual Time Base */
+#define SPRN_LDBAR	0x352	/* LD Base Address Register */
 #define SPRN_PMICR	0x354   /* Power Management Idle Control Reg */
 #define SPRN_PMSR	0x355   /* Power Management Status Reg */
+#define SPRN_PMMAR	0x356	/* Power Management Memory Activity Register */
 #define SPRN_PMCR	0x374	/* Power Management Control Register */
 
 /* HFSCR and FSCR bit numbers are the same */
@@ -434,6 +437,12 @@
 #define HID0_BTCD	(1<<1)		/* Branch target cache disable */
 #define HID0_NOPDST	(1<<1)		/* No-op dst, dstt, etc. instr. */
 #define HID0_NOPTI	(1<<0)		/* No-op dcbt and dcbst instr. */
+/* POWER8 HID0 bits */
+#define HID0_POWER8_4LPARMODE	__MASK(61)
+#define HID0_POWER8_2LPARMODE	__MASK(57)
+#define HID0_POWER8_1TO2LPAR	__MASK(52)
+#define HID0_POWER8_1TO4LPAR	__MASK(51)
+#define HID0_POWER8_DYNLPARDIS	__MASK(48)
 
 #define SPRN_HID1	0x3F1		/* Hardware Implementation Register 1 */
 #ifdef CONFIG_6xx

commit 7f06f21d40a638e1ca759ceda0f21cd81082607e
Author: Michael Neuling <mikey@neuling.org>
Date:   Fri Mar 28 16:40:34 2014 +1100

    powerpc/tm: Add checking to treclaim/trechkpt
    
    If we do a treclaim and we are not in TM suspend mode, it results in a TM bad
    thing (ie. a 0x700 program check).  Similarly if we do a trechkpt and we have
    an active transaction or TEXASR Failure Summary (FS) is not set, we also take a
    TM bad thing.
    
    This should never happen, but if it does (ie. a kernel bug), the cause is
    almost impossible to debug as the GPR state is mostly userspace and hence we
    don't get a call chain.
    
    This adds some checks in these cases case a BUG_ON() (in asm) in case we ever
    hit these cases.  It moves the register saving around to preserve r1 till later
    also.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index e5d2e0bc7e03..29de0152878f 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -215,6 +215,7 @@
 #define SPRN_TEXASR	0x82	/* Transaction EXception & Summary */
 #define   TEXASR_FS	__MASK(63-36)	/* Transaction Failure Summary */
 #define SPRN_TEXASRU	0x83	/* ''	   ''	   ''	 Upper 32  */
+#define   TEXASR_FS     __MASK(63-36) /* TEXASR Failure Summary */
 #define SPRN_TFHAR	0x80	/* Transaction Failure Handler Addr */
 #define SPRN_CTRLF	0x088
 #define SPRN_CTRLT	0x098

commit fe10739284bae68b57d3dbcad81f34772cfd2716
Merge: 8c73c4d8319f f334a1e8434c
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Tue Apr 8 13:28:02 2014 +0200

    Merge branch 'pm-cpufreq'
    
    * pm-cpufreq:
      cpufreq: ppc: Remove duplicate inclusion of fsl_soc.h
      cpufreq: create another field .flags in cpufreq_frequency_table
      cpufreq: use kzalloc() to allocate memory for cpufreq_frequency_table
      cpufreq: don't print value of .driver_data from core
      cpufreq: ia64: don't set .driver_data to index
      cpufreq: powernv: Select CPUFreq related Kconfig options for powernv
      cpufreq: powernv: Use cpufreq_frequency_table.driver_data to store pstate ids
      cpufreq: powernv: cpufreq driver for powernv platform
      cpufreq: at32ap: don't declare local variable as static
      cpufreq: loongson2_cpufreq: don't declare local variable as static
      cpufreq: unicore32: fix typo issue for 'clk'
      cpufreq: exynos: Disable on multiplatform build

commit b3d627a5f2bf1a9a486f65af6f7c2ce0e09b3d12
Author: Vaidyanathan Srinivasan <svaidy@linux.vnet.ibm.com>
Date:   Tue Apr 1 12:43:26 2014 +0530

    cpufreq: powernv: cpufreq driver for powernv platform
    
    Backend driver to dynamically set voltage and frequency on
    IBM POWER non-virtualized platforms.  Power management SPRs
    are used to set the required PState.
    
    This driver works in conjunction with cpufreq governors
    like 'ondemand' to provide a demand based frequency and
    voltage setting on IBM POWER non-virtualized platforms.
    
    PState table is obtained from OPAL v3 firmware through device
    tree.
    
    powernv_cpufreq back-end driver would parse the relevant device-tree
    nodes and initialise the cpufreq subsystem on powernv platform.
    
    The code was originally written by svaidy@linux.vnet.ibm.com. Over
    time it was modified to accomodate bug-fixes as well as updates to the
    the cpu-freq core. Relevant portions of the change logs corresponding
    to those modifications are noted below:
    
     * The policy->cpus needs to be populated in a hotplug-invariant
       manner instead of using cpu_sibling_mask() which varies with
       cpu-hotplug. This is because the cpufreq core code copies this
       content into policy->related_cpus mask which should not vary on
       cpu-hotplug. [Authored by srivatsa.bhat@linux.vnet.ibm.com]
    
     * Create a helper routine that can return the cpu-frequency for the
       corresponding pstate_id. Also, cache the values of the pstate_max,
       pstate_min and pstate_nominal and nr_pstates in a static structure
       so that they can be reused in the future to perform any
       validations. [Authored by ego@linux.vnet.ibm.com]
    
     * Create a driver attribute named cpuinfo_nominal_freq which creates
       a sysfs read-only file named cpuinfo_nominal_freq. Export the
       frequency corresponding to the nominal_pstate through this
       interface.
    
         Nominal frequency is the highest non-turbo frequency for the
       platform.  This is generally used for setting governor policies
       from user space for optimal energy efficiency. [Authored by
       ego@linux.vnet.ibm.com]
    
     * Implement a powernv_cpufreq_get(unsigned int cpu) method which will
       return the current operating frequency. Export this via the sysfs
       interface cpuinfo_cur_freq by setting powernv_cpufreq_driver.get to
       powernv_cpufreq_get(). [Authored by ego@linux.vnet.ibm.com]
    
    [Change log updated by ego@linux.vnet.ibm.com]
    
    Reviewed-by: Preeti U Murthy <preeti@linux.vnet.ibm.com>
    Signed-off-by: Vaidyanathan Srinivasan <svaidy@linux.vnet.ibm.com>
    Signed-off-by: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 1a36b8ede417..2189f8f2ca88 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -271,6 +271,10 @@
 #define SPRN_HSRR1	0x13B	/* Hypervisor Save/Restore 1 */
 #define SPRN_IC		0x350	/* Virtual Instruction Count */
 #define SPRN_VTB	0x351	/* Virtual Time Base */
+#define SPRN_PMICR	0x354   /* Power Management Idle Control Reg */
+#define SPRN_PMSR	0x355   /* Power Management Status Reg */
+#define SPRN_PMCR	0x374	/* Power Management Control Register */
+
 /* HFSCR and FSCR bit numbers are the same */
 #define FSCR_TAR_LG	8	/* Enable Target Address Register */
 #define FSCR_EBB_LG	7	/* Enable Event Based Branching */

commit 7cbb39d4d4d530dff12f2ff06ed6c85c504ba91a
Merge: 64056a94256e 7227fc066660
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Apr 2 14:50:10 2014 -0700

    Merge tag 'kvm-3.15-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull kvm updates from Paolo Bonzini:
     "PPC and ARM do not have much going on this time.  Most of the cool
      stuff, instead, is in s390 and (after a few releases) x86.
    
      ARM has some caching fixes and PPC has transactional memory support in
      guests.  MIPS has some fixes, with more probably coming in 3.16 as
      QEMU will soon get support for MIPS KVM.
    
      For x86 there are optimizations for debug registers, which trigger on
      some Windows games, and other important fixes for Windows guests.  We
      now expose to the guest Broadwell instruction set extensions and also
      Intel MPX.  There's also a fix/workaround for OS X guests, nested
      virtualization features (preemption timer), and a couple kvmclock
      refinements.
    
      For s390, the main news is asynchronous page faults, together with
      improvements to IRQs (floating irqs and adapter irqs) that speed up
      virtio devices"
    
    * tag 'kvm-3.15-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (96 commits)
      KVM: PPC: Book3S HV: Save/restore host PMU registers that are new in POWER8
      KVM: PPC: Book3S HV: Fix decrementer timeouts with non-zero TB offset
      KVM: PPC: Book3S HV: Don't use kvm_memslots() in real mode
      KVM: PPC: Book3S HV: Return ENODEV error rather than EIO
      KVM: PPC: Book3S: Trim top 4 bits of physical address in RTAS code
      KVM: PPC: Book3S HV: Add get/set_one_reg for new TM state
      KVM: PPC: Book3S HV: Add transactional memory support
      KVM: Specify byte order for KVM_EXIT_MMIO
      KVM: vmx: fix MPX detection
      KVM: PPC: Book3S HV: Fix KVM hang with CONFIG_KVM_XICS=n
      KVM: PPC: Book3S: Introduce hypervisor call H_GET_TCE
      KVM: PPC: Book3S HV: Fix incorrect userspace exit on ioeventfd write
      KVM: s390: clear local interrupts at cpu initial reset
      KVM: s390: Fix possible memory leak in SIGP functions
      KVM: s390: fix calculation of idle_mask array size
      KVM: s390: randomize sca address
      KVM: ioapic: reinject pending interrupts on KVM_SET_IRQCHIP
      KVM: Bump KVM_MAX_IRQ_ROUTES for s390
      KVM: s390: irq routing for adapter interrupts.
      KVM: s390: adapter interrupt sources
      ...

commit 7227fc0666606b0df2c0d2966a7f4859b01bdf74
Merge: 6acdb1603a7d 72cde5a88d37
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Sat Mar 29 15:44:05 2014 +0100

    Merge branch 'kvm-ppchv-next' of git://git.kernel.org/pub/scm/linux/kernel/git/paulus/powerpc into kvm-next

commit e4e38121507a27d2ccc4b28d9e7fc4818a12c44c
Author: Michael Neuling <mikey@neuling.org>
Date:   Tue Mar 25 10:47:02 2014 +1100

    KVM: PPC: Book3S HV: Add transactional memory support
    
    This adds saving of the transactional memory (TM) checkpointed state
    on guest entry and exit.  We only do this if we see that the guest has
    an active transaction.
    
    It also adds emulation of the TM state changes when delivering IRQs
    into the guest.  According to the architecture, if we are
    transactional when an IRQ occurs, the TM state is changed to
    suspended, otherwise it's left unchanged.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Acked-by: Scott Wood <scottwood@freescale.com>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 6ba8d4af3999..af21e876837e 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -213,6 +213,7 @@
 #define SPRN_ACOP	0x1F	/* Available Coprocessor Register */
 #define SPRN_TFIAR	0x81	/* Transaction Failure Inst Addr   */
 #define SPRN_TEXASR	0x82	/* Transaction EXception & Summary */
+#define   TEXASR_FS	__MASK(63-36)	/* Transaction Failure Summary */
 #define SPRN_TEXASRU	0x83	/* ''	   ''	   ''	 Upper 32  */
 #define SPRN_TFHAR	0x80	/* Transaction Failure Handler Addr */
 #define SPRN_CTRLF	0x088

commit cd427485357c0c4b99f69719251baacf25946e11
Merge: d410ae212648 48b16180d0d9
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon Mar 24 10:26:10 2014 +1100

    Merge remote-tracking branch 'scott/next' into next
    
    Freescale updates from Scott. Mostly support for critical
    and machine check exceptions on 64-bit BookE, some new
    PCI suspend/resume work and misc bits.

commit 76cb8a783a4b7403a6731ffdeec0831cd4b19936
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Fri Mar 14 16:00:34 2014 +1100

    powerpc/perf: Enable BHRB access for EBB events
    
    The previous commit added constraint and register handling to allow
    processes using EBB (Event Based Branches) to request access to the BHRB
    (Branch History Rolling Buffer).
    
    With that in place we can allow processes using EBB to access the BHRB.
    This is achieved by setting BHRBA in MMCR0 when we enable EBB access. We
    must also clear BHRBA when we are disabling.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 30034720589a..980e8db2f261 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -664,6 +664,7 @@
 #define   MMCR0_PMXE	0x04000000UL /* performance monitor exception enable */
 #define   MMCR0_FCECE	0x02000000UL /* freeze ctrs on enabled cond or event */
 #define   MMCR0_TBEE	0x00400000UL /* time base exception enable */
+#define   MMCR0_BHRBA	0x00200000UL /* BHRB Access allowed in userspace */
 #define   MMCR0_EBE	0x00100000UL /* Event based branch enable */
 #define   MMCR0_PMCC	0x000c0000UL /* PMC control */
 #define   MMCR0_PMCC_U6	0x00080000UL /* PMC1-6 are R/W by user (PR) */

commit c2e37a2626a7471875f3a6452b99dfd3809972b9
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Fri Mar 14 16:00:29 2014 +1100

    powerpc/perf: Add lost exception workaround
    
    Some power8 revisions have a hardware bug where we can lose a PMU
    exception, this commit adds a workaround to detect the bad condition and
    rectify the situation.
    
    See the comment in the commit for a full description.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 90c06ec6eff5..30034720589a 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -670,6 +670,7 @@
 #define   MMCR0_PMC1CE	0x00008000UL /* PMC1 count enable*/
 #define   MMCR0_PMCjCE	0x00004000UL /* PMCj count enable*/
 #define   MMCR0_TRIGGER	0x00002000UL /* TRIGGER enable */
+#define   MMCR0_PMAO_SYNC 0x00000800UL /* PMU interrupt is synchronous */
 #define   MMCR0_PMAO	0x00000080UL /* performance monitor alert has occurred, set to 0 after handling exception */
 #define   MMCR0_SHRFC	0x00000040UL /* SHRre freeze conditions between threads */
 #define   MMCR0_FC56	0x00000010UL /* freeze counters 5 and 6 */
@@ -703,6 +704,7 @@
 #define SPRN_EBBHR	804	/* Event based branch handler register */
 #define SPRN_EBBRR	805	/* Event based branch return register */
 #define SPRN_BESCR	806	/* Branch event status and control register */
+#define   BESCR_GE	0x8000000000000000ULL /* Global Enable */
 #define SPRN_WORT	895	/* Workload optimization register - thread */
 
 #define SPRN_PMC1	787

commit 9d378dfac885f72b8b369d08fc61bef36e2f2dd1
Author: Scott Wood <scottwood@freescale.com>
Date:   Mon Mar 10 17:29:38 2014 -0500

    powerpc/booke64: Use SPRG7 for VDSO
    
    Previously SPRG3 was marked for use by both VDSO and critical
    interrupts (though critical interrupts were not fully implemented).
    
    In commit 8b64a9dfb091f1eca8b7e58da82f1e7d1d5fe0ad ("powerpc/booke64:
    Use SPRG0/3 scratch for bolted TLB miss & crit int"), Mihai Caraman
    made an attempt to resolve this conflict by restoring the VDSO value
    early in the critical interrupt, but this has some issues:
    
     - It's incompatible with EXCEPTION_COMMON which restores r13 from the
       by-then-overwritten scratch (this cost me some debugging time).
     - It forces critical exceptions to be a special case handled
       differently from even machine check and debug level exceptions.
     - It didn't occur to me that it was possible to make this work at all
       (by doing a final "ld r13, PACA_EXCRIT+EX_R13(r13)") until after
       I made (most of) this patch. :-)
    
    It might be worth investigating using a load rather than SPRG on return
    from all exceptions (except TLB misses where the scratch never leaves
    the SPRG) -- it could save a few cycles.  Until then, let's stick with
    SPRG for all exceptions.
    
    Since we cannot use SPRG4-7 for scratch without corrupting the state of
    a KVM guest, move VDSO to SPRG7 on book3e.  Since neither SPRG4-7 nor
    critical interrupts exist on book3s, SPRG3 is still used for VDSO
    there.
    
    Signed-off-by: Scott Wood <scottwood@freescale.com>
    Cc: Mihai Caraman <mihai.caraman@freescale.com>
    Cc: Anton Blanchard <anton@samba.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: kvm-ppc@vger.kernel.org

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index bf0fb4db0855..f7251c2dc049 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -577,9 +577,13 @@
 #define SPRN_SPRG3	0x113	/* Special Purpose Register General 3 */
 #define SPRN_USPRG3	0x103	/* SPRG3 userspace read */
 #define SPRN_SPRG4	0x114	/* Special Purpose Register General 4 */
+#define SPRN_USPRG4	0x104	/* SPRG4 userspace read */
 #define SPRN_SPRG5	0x115	/* Special Purpose Register General 5 */
+#define SPRN_USPRG5	0x105	/* SPRG5 userspace read */
 #define SPRN_SPRG6	0x116	/* Special Purpose Register General 6 */
+#define SPRN_USPRG6	0x106	/* SPRG6 userspace read */
 #define SPRN_SPRG7	0x117	/* Special Purpose Register General 7 */
+#define SPRN_USPRG7	0x107	/* SPRG7 userspace read */
 #define SPRN_SRR0	0x01A	/* Save/Restore Register 0 */
 #define SPRN_SRR1	0x01B	/* Save/Restore Register 1 */
 #define   SRR1_ISI_NOPT		0x40000000 /* ISI: Not found in hash */
@@ -879,11 +883,10 @@
  * 64-bit embedded
  *	- SPRG0 generic exception scratch
  *	- SPRG2 TLB exception stack
- *	- SPRG3 critical exception scratch and
- *        CPU and NUMA node for VDSO getcpu (user visible)
+ *	- SPRG3 critical exception scratch (user visible, sorry!)
  *	- SPRG4 unused (user visible)
  *	- SPRG6 TLB miss scratch (user visible, sorry !)
- *	- SPRG7 critical exception scratch
+ *	- SPRG7 CPU and NUMA node for VDSO getcpu (user visible)
  *	- SPRG8 machine check exception scratch
  *	- SPRG9 debug exception scratch
  *
@@ -940,6 +943,8 @@
 #define SPRN_SPRG_SCRATCH0	SPRN_SPRG2
 #define SPRN_SPRG_HPACA		SPRN_HSPRG0
 #define SPRN_SPRG_HSCRATCH0	SPRN_HSPRG1
+#define SPRN_SPRG_VDSO_READ	SPRN_USPRG3
+#define SPRN_SPRG_VDSO_WRITE	SPRN_SPRG3
 
 #define GET_PACA(rX)					\
 	BEGIN_FTR_SECTION_NESTED(66);			\
@@ -983,6 +988,8 @@
 #define SPRN_SPRG_TLB_SCRATCH	SPRN_SPRG6
 #define SPRN_SPRG_GEN_SCRATCH	SPRN_SPRG0
 #define SPRN_SPRG_GDBELL_SCRATCH SPRN_SPRG_GEN_SCRATCH
+#define SPRN_SPRG_VDSO_READ	SPRN_USPRG7
+#define SPRN_SPRG_VDSO_WRITE	SPRN_SPRG7
 
 #define SET_PACA(rX)	mtspr	SPRN_SPRG_PACA,rX
 #define GET_PACA(rX)	mfspr	rX,SPRN_SPRG_PACA

commit b0b7dcbdf327bc57018d498e07331b2c96916dc7
Author: Wang Dongsheng <dongsheng.wang@freescale.com>
Date:   Fri Mar 7 12:57:57 2014 +0800

    powerpc/fsl: add PVR definition for E500MC and E5500
    
    Signed-off-by: Wang Dongsheng <dongsheng.wang@freescale.com>
    Signed-off-by: Scott Wood <scottwood@freescale.com>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 90c06ec6eff5..bf0fb4db0855 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1102,6 +1102,8 @@
 #define PVR_8560	0x80200000
 #define PVR_VER_E500V1	0x8020
 #define PVR_VER_E500V2	0x8021
+#define PVR_VER_E500MC	0x8023
+#define PVR_VER_E5500	0x8024
 #define PVR_VER_E6500	0x8040
 
 /*

commit e2a0f813e0d53014b78aae76f0359c8a41f05eeb
Merge: e30b82bbe098 b73117c49364
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jan 31 08:37:32 2014 -0800

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull more KVM updates from Paolo Bonzini:
     "Second batch of KVM updates.  Some minor x86 fixes, two s390 guest
      features that need some handling in the host, and all the PPC changes.
    
      The PPC changes include support for little-endian guests and
      enablement for new POWER8 features"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (45 commits)
      x86, kvm: correctly access the KVM_CPUID_FEATURES leaf at 0x40000101
      x86, kvm: cache the base of the KVM cpuid leaves
      kvm: x86: move KVM_CAP_HYPERV_TIME outside #ifdef
      KVM: PPC: Book3S PR: Cope with doorbell interrupts
      KVM: PPC: Book3S HV: Add software abort codes for transactional memory
      KVM: PPC: Book3S HV: Add new state for transactional memory
      powerpc/Kconfig: Make TM select VSX and VMX
      KVM: PPC: Book3S HV: Basic little-endian guest support
      KVM: PPC: Book3S HV: Add support for DABRX register on POWER7
      KVM: PPC: Book3S HV: Prepare for host using hypervisor doorbells
      KVM: PPC: Book3S HV: Handle new LPCR bits on POWER8
      KVM: PPC: Book3S HV: Handle guest using doorbells for IPIs
      KVM: PPC: Book3S HV: Consolidate code that checks reason for wake from nap
      KVM: PPC: Book3S HV: Implement architecture compatibility modes for POWER8
      KVM: PPC: Book3S HV: Add handler for HV facility unavailable
      KVM: PPC: Book3S HV: Flush the correct number of TLB sets on POWER8
      KVM: PPC: Book3S HV: Context-switch new POWER8 SPRs
      KVM: PPC: Book3S HV: Align physical and virtual CPU thread numbers
      KVM: PPC: Book3S HV: Don't set DABR on POWER8
      kvm/ppc: IRQ disabling cleanup
      ...

commit b73117c49364551ff789db7c424a115ac5b77850
Merge: 77f01bdfa5e5 4068890931f6
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Wed Jan 29 18:29:01 2014 +0100

    Merge branch 'kvm-ppc-next' of git://github.com/agraf/linux-2.6 into kvm-queue
    
    Conflicts:
            arch/powerpc/kvm/book3s_hv_rmhandlers.S
            arch/powerpc/kvm/booke.c

commit 8563bf52d509213e746295341ab52896b562ca5e
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Jan 8 21:25:29 2014 +1100

    KVM: PPC: Book3S HV: Add support for DABRX register on POWER7
    
    The DABRX (DABR extension) register on POWER7 processors provides finer
    control over which accesses cause a data breakpoint interrupt.  It
    contains 3 bits which indicate whether to enable accesses in user,
    kernel and hypervisor modes respectively to cause data breakpoint
    interrupts, plus one bit that enables both real mode and virtual mode
    accesses to cause interrupts.  Currently, KVM sets DABRX to allow
    both kernel and user accesses to cause interrupts while in the guest.
    
    This adds support for the guest to specify other values for DABRX.
    PAPR defines a H_SET_XDABR hcall to allow the guest to set both DABR
    and DABRX with one call.  This adds a real-mode implementation of
    H_SET_XDABR, which shares most of its code with the existing H_SET_DABR
    implementation.  To support this, we add a per-vcpu field to store the
    DABRX value plus code to get and set it via the ONE_REG interface.
    
    For Linux guests to use this new hcall, userspace needs to add
    "hcall-xdabr" to the set of strings in the /chosen/hypertas-functions
    property in the device tree.  If userspace does this and then migrates
    the guest to a host where the kernel doesn't include this patch, then
    userspace will need to implement H_SET_XDABR by writing the specified
    DABR value to the DABR using the ONE_REG interface.  In that case, the
    old kernel will set DABRX to DABRX_USER | DABRX_KERNEL.  That should
    still work correctly, at least for Linux guests, since Linux guests
    cope with getting data breakpoint interrupts in modes that weren't
    requested by just ignoring the interrupt, and Linux guests never set
    DABRX_BTI.
    
    The other thing this does is to make H_SET_DABR and H_SET_XDABR work
    on POWER8, which has the DAWR and DAWRX instead of DABR/X.  Guests that
    know about POWER8 should use H_SET_MODE rather than H_SET_[X]DABR, but
    guests running in POWER7 compatibility mode will still use H_SET_[X]DABR.
    For them, this adds the logic to convert DABR/X values into DAWR/X values
    on POWER8.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 05ecb072540c..adf644a80a3e 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -229,16 +229,20 @@
 #define   CIABR_PRIV_SUPER	2
 #define   CIABR_PRIV_HYPER	3
 #define SPRN_DAWRX	0xBC
-#define   DAWRX_USER	(1UL << 0)
-#define   DAWRX_KERNEL	(1UL << 1)
-#define   DAWRX_HYP	(1UL << 2)
+#define   DAWRX_USER	__MASK(0)
+#define   DAWRX_KERNEL	__MASK(1)
+#define   DAWRX_HYP	__MASK(2)
+#define   DAWRX_WTI	__MASK(3)
+#define   DAWRX_WT	__MASK(4)
+#define   DAWRX_DR	__MASK(5)
+#define   DAWRX_DW	__MASK(6)
 #define SPRN_DABR	0x3F5	/* Data Address Breakpoint Register */
 #define SPRN_DABR2	0x13D	/* e300 */
 #define SPRN_DABRX	0x3F7	/* Data Address Breakpoint Register Extension */
-#define   DABRX_USER	(1UL << 0)
-#define   DABRX_KERNEL	(1UL << 1)
-#define   DABRX_HYP	(1UL << 2)
-#define   DABRX_BTI	(1UL << 3)
+#define   DABRX_USER	__MASK(0)
+#define   DABRX_KERNEL	__MASK(1)
+#define   DABRX_HYP	__MASK(2)
+#define   DABRX_BTI	__MASK(3)
 #define   DABRX_ALL     (DABRX_BTI | DABRX_HYP | DABRX_KERNEL | DABRX_USER)
 #define SPRN_DAR	0x013	/* Data Address Register */
 #define SPRN_DBCR	0x136	/* e300 Data Breakpoint Control Reg */

commit e0622bd9f2fccc8a801fa7aaf4fa6d7c728c3a78
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Jan 8 21:25:27 2014 +1100

    KVM: PPC: Book3S HV: Handle new LPCR bits on POWER8
    
    POWER8 has a bit in the LPCR to enable or disable the PURR and SPURR
    registers to count when in the guest.  Set this bit.
    
    POWER8 has a field in the LPCR called AIL (Alternate Interrupt Location)
    which is used to enable relocation-on interrupts.  Allow userspace to
    set this field.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 1248b40107ea..05ecb072540c 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -305,8 +305,10 @@
 #define   LPCR_RMLS    0x1C000000      /* impl dependent rmo limit sel */
 #define	  LPCR_RMLS_SH	(63-37)
 #define   LPCR_ILE     0x02000000      /* !HV irqs set MSR:LE */
+#define   LPCR_AIL	0x01800000	/* Alternate interrupt location */
 #define   LPCR_AIL_0	0x00000000	/* MMU off exception offset 0x0 */
 #define   LPCR_AIL_3	0x01800000	/* MMU on exception offset 0xc00...4xxx */
+#define   LPCR_ONL	0x00040000	/* online - PURR/SPURR count */
 #define   LPCR_PECE	0x0001f000	/* powersave exit cause enable */
 #define     LPCR_PECEDP	0x00010000	/* directed priv dbells cause exit */
 #define     LPCR_PECEDH	0x00008000	/* directed hyp dbells cause exit */

commit aa31e843225769735b79795c955426c9479046a5
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Jan 8 21:25:26 2014 +1100

    KVM: PPC: Book3S HV: Handle guest using doorbells for IPIs
    
    * SRR1 wake reason field for system reset interrupt on wakeup from nap
      is now a 4-bit field on P8, compared to 3 bits on P7.
    
    * Set PECEDP in LPCR when napping because of H_CEDE so guest doorbells
      will wake us up.
    
    * Waking up from nap because of a guest doorbell interrupt is not a
      reason to exit the guest.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 5a9983147683..1248b40107ea 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -307,7 +307,9 @@
 #define   LPCR_ILE     0x02000000      /* !HV irqs set MSR:LE */
 #define   LPCR_AIL_0	0x00000000	/* MMU off exception offset 0x0 */
 #define   LPCR_AIL_3	0x01800000	/* MMU on exception offset 0xc00...4xxx */
-#define   LPCR_PECE	0x00007000	/* powersave exit cause enable */
+#define   LPCR_PECE	0x0001f000	/* powersave exit cause enable */
+#define     LPCR_PECEDP	0x00010000	/* directed priv dbells cause exit */
+#define     LPCR_PECEDH	0x00008000	/* directed hyp dbells cause exit */
 #define     LPCR_PECE0	0x00004000	/* ext. exceptions can cause exit */
 #define     LPCR_PECE1	0x00002000	/* decrementer can cause exit */
 #define     LPCR_PECE2	0x00001000	/* machine check etc can cause exit */

commit 5557ae0ec77c2b4b5bbce2883c0603054ab66e68
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Jan 8 21:25:24 2014 +1100

    KVM: PPC: Book3S HV: Implement architecture compatibility modes for POWER8
    
    This allows us to select architecture 2.05 (POWER6) or 2.06 (POWER7)
    compatibility modes on a POWER8 processor.  (Note that transactional
    memory is disabled for usermode if either or both of the PCR_TM_DIS
    and PCR_ARCH_206 bits are set.)
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 2f41e6475648..5a9983147683 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -329,6 +329,8 @@
 #define SPRN_PCR	0x152	/* Processor compatibility register */
 #define   PCR_VEC_DIS	(1ul << (63-0))	/* Vec. disable (bit NA since POWER8) */
 #define   PCR_VSX_DIS	(1ul << (63-1))	/* VSX disable (bit NA since POWER8) */
+#define   PCR_TM_DIS	(1ul << (63-2))	/* Trans. memory disable (POWER8) */
+#define   PCR_ARCH_206	0x4		/* Architecture 2.06 */
 #define   PCR_ARCH_205	0x2		/* Architecture 2.05 */
 #define	SPRN_HEIR	0x153	/* Hypervisor Emulated Instruction Register */
 #define SPRN_TLBINDEXR	0x154	/* P7 TLB control register */

commit b005255e12a311d2c87ea70a7c7b192b2187c22c
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed Jan 8 21:25:21 2014 +1100

    KVM: PPC: Book3S HV: Context-switch new POWER8 SPRs
    
    This adds fields to the struct kvm_vcpu_arch to store the new
    guest-accessible SPRs on POWER8, adds code to the get/set_one_reg
    functions to allow userspace to access this state, and adds code to
    the guest entry and exit to context-switch these SPRs between host
    and guest.
    
    Note that DPDES (Directed Privileged Doorbell Exception State) is
    shared between threads on a core; hence we store it in struct
    kvmppc_vcore and have the master thread save and restore it.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 5c45787d551e..2f41e6475648 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -223,6 +223,11 @@
 #define   CTRL_TE	0x00c00000	/* thread enable */
 #define   CTRL_RUNLATCH	0x1
 #define SPRN_DAWR	0xB4
+#define SPRN_CIABR	0xBB
+#define   CIABR_PRIV		0x3
+#define   CIABR_PRIV_USER	1
+#define   CIABR_PRIV_SUPER	2
+#define   CIABR_PRIV_HYPER	3
 #define SPRN_DAWRX	0xBC
 #define   DAWRX_USER	(1UL << 0)
 #define   DAWRX_KERNEL	(1UL << 1)
@@ -260,6 +265,8 @@
 #define SPRN_HRMOR	0x139	/* Real mode offset register */
 #define SPRN_HSRR0	0x13A	/* Hypervisor Save/Restore 0 */
 #define SPRN_HSRR1	0x13B	/* Hypervisor Save/Restore 1 */
+#define SPRN_IC		0x350	/* Virtual Instruction Count */
+#define SPRN_VTB	0x351	/* Virtual Time Base */
 /* HFSCR and FSCR bit numbers are the same */
 #define FSCR_TAR_LG	8	/* Enable Target Address Register */
 #define FSCR_EBB_LG	7	/* Enable Event Based Branching */
@@ -368,6 +375,8 @@
 #define DER_EBRKE	0x00000002	/* External Breakpoint Interrupt */
 #define DER_DPIE	0x00000001	/* Dev. Port Nonmaskable Request */
 #define SPRN_DMISS	0x3D0		/* Data TLB Miss Register */
+#define SPRN_DHDES	0x0B1		/* Directed Hyp. Doorbell Exc. State */
+#define SPRN_DPDES	0x0B0		/* Directed Priv. Doorbell Exc. State */
 #define SPRN_EAR	0x11A		/* External Address Register */
 #define SPRN_HASH1	0x3D2		/* Primary Hash Address Register */
 #define SPRN_HASH2	0x3D3		/* Secondary Hash Address Resgister */
@@ -427,6 +436,7 @@
 #define SPRN_IABR	0x3F2	/* Instruction Address Breakpoint Register */
 #define SPRN_IABR2	0x3FA		/* 83xx */
 #define SPRN_IBCR	0x135		/* 83xx Insn Breakpoint Control Reg */
+#define SPRN_IAMR	0x03D		/* Instr. Authority Mask Reg */
 #define SPRN_HID4	0x3F4		/* 970 HID4 */
 #define  HID4_LPES0	 (1ul << (63-0)) /* LPAR env. sel. bit 0 */
 #define	 HID4_RMLS2_SH	 (63 - 2)	/* Real mode limit bottom 2 bits */
@@ -541,6 +551,7 @@
 #define SPRN_PIR	0x3FF	/* Processor Identification Register */
 #endif
 #define SPRN_TIR	0x1BE	/* Thread Identification Register */
+#define SPRN_PSPB	0x09F	/* Problem State Priority Boost reg */
 #define SPRN_PTEHI	0x3D5	/* 981 7450 PTE HI word (S/W TLB load) */
 #define SPRN_PTELO	0x3D6	/* 982 7450 PTE LO word (S/W TLB load) */
 #define SPRN_PURR	0x135	/* Processor Utilization of Resources Reg */
@@ -682,6 +693,7 @@
 #define SPRN_EBBHR	804	/* Event based branch handler register */
 #define SPRN_EBBRR	805	/* Event based branch return register */
 #define SPRN_BESCR	806	/* Branch event status and control register */
+#define SPRN_WORT	895	/* Workload optimization register - thread */
 
 #define SPRN_PMC1	787
 #define SPRN_PMC2	788
@@ -698,6 +710,11 @@
 #define   SIER_SIHV		0x1000000	/* Sampled MSR_HV */
 #define   SIER_SIAR_VALID	0x0400000	/* SIAR contents valid */
 #define   SIER_SDAR_VALID	0x0200000	/* SDAR contents valid */
+#define SPRN_TACR	888
+#define SPRN_TCSCR	889
+#define SPRN_CSIGR	890
+#define SPRN_SPMC1	892
+#define SPRN_SPMC2	893
 
 /* When EBB is enabled, some of MMCR0/MMCR2/SIER are user accessible */
 #define MMCR0_USER_MASK	(MMCR0_FC | MMCR0_PMXE | MMCR0_PMAO)

commit 71a6fa17e1526d3f26f4711cc55d339f96c49a95
Author: Wang Dongsheng <dongsheng.wang@freescale.com>
Date:   Tue Dec 17 16:16:59 2013 +0800

    powerpc/fsl: add E6500 PVR and SPRN_PWRMGTCR0 define
    
    E6500 PVR and SPRN_PWRMGTCR0 will be used in subsequent pw20/altivec
    idle patches.
    
    Signed-off-by: Wang Dongsheng <dongsheng.wang@freescale.com>
    Signed-off-by: Scott Wood <scottwood@freescale.com>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index fa8388ed94c5..62b114e079cf 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1075,6 +1075,8 @@
 #define PVR_8560	0x80200000
 #define PVR_VER_E500V1	0x8020
 #define PVR_VER_E500V2	0x8021
+#define PVR_VER_E6500	0x8040
+
 /*
  * For the 8xx processors, all of them report the same PVR family for
  * the PowerPC core. The various versions of these processors must be

commit ae2163be10ac6090e7aeed72591e2d7fabb1cdda
Author: LEROY Christophe <christophe.leroy@c-s.fr>
Date:   Fri Nov 22 17:57:31 2013 +0100

    powerpc/8xx: mfspr SPRN_TBRx in lieu of mftb/mftbu is not supported
    
    Commit beb2dc0a7a84be003ce54e98b95d65cc66e6e536 breaks the MPC8xx which
    seems to not support using mfspr SPRN_TBRx instead of mftb/mftbu
    despite what is written in the reference manual.
    
    This patch reverts to the use of mftb/mftbu when CONFIG_8xx is
    selected.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Scott Wood <scottwood@freescale.com>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 5c45787d551e..fa8388ed94c5 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1174,12 +1174,19 @@
 
 #else /* __powerpc64__ */
 
+#if defined(CONFIG_8xx)
+#define mftbl()		({unsigned long rval;	\
+			asm volatile("mftbl %0" : "=r" (rval)); rval;})
+#define mftbu()		({unsigned long rval;	\
+			asm volatile("mftbu %0" : "=r" (rval)); rval;})
+#else
 #define mftbl()		({unsigned long rval;	\
 			asm volatile("mfspr %0, %1" : "=r" (rval) : \
 				"i" (SPRN_TBRL)); rval;})
 #define mftbu()		({unsigned long rval;	\
 			asm volatile("mfspr %0, %1" : "=r" (rval) : \
 				"i" (SPRN_TBRU)); rval;})
+#endif
 #endif /* !__powerpc64__ */
 
 #define mttbl(v)	asm volatile("mttbl %0":: "r"(v))

commit f080480488028bcc25357f85e8ae54ccc3bb7173
Merge: eda670c626a4 e504c9098ed6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 15 13:51:36 2013 +0900

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull KVM changes from Paolo Bonzini:
     "Here are the 3.13 KVM changes.  There was a lot of work on the PPC
      side: the HV and emulation flavors can now coexist in a single kernel
      is probably the most interesting change from a user point of view.
    
      On the x86 side there are nested virtualization improvements and a few
      bugfixes.
    
      ARM got transparent huge page support, improved overcommit, and
      support for big endian guests.
    
      Finally, there is a new interface to connect KVM with VFIO.  This
      helps with devices that use NoSnoop PCI transactions, letting the
      driver in the guest execute WBINVD instructions.  This includes some
      nVidia cards on Windows, that fail to start without these patches and
      the corresponding userspace changes"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (146 commits)
      kvm, vmx: Fix lazy FPU on nested guest
      arm/arm64: KVM: PSCI: propagate caller endianness to the incoming vcpu
      arm/arm64: KVM: MMIO support for BE guest
      kvm, cpuid: Fix sparse warning
      kvm: Delete prototype for non-existent function kvm_check_iopl
      kvm: Delete prototype for non-existent function complete_pio
      hung_task: add method to reset detector
      pvclock: detect watchdog reset at pvclock read
      kvm: optimize out smp_mb after srcu_read_unlock
      srcu: API for barrier after srcu read unlock
      KVM: remove vm mmap method
      KVM: IOMMU: hva align mapping page size
      KVM: x86: trace cpuid emulation when called from emulator
      KVM: emulator: cleanup decode_register_operand() a bit
      KVM: emulator: check rex prefix inside decode_register()
      KVM: x86: fix emulation of "movzbl %bpl, %eax"
      kvm_host: typo fix
      KVM: x86: emulate SAHF instruction
      MAINTAINERS: add tree for kvm.git
      Documentation/kvm: add a 00-INDEX file
      ...

commit 388cc6e133132e6c9b64e7d5361114a3a7d57663
Author: Paul Mackerras <paulus@samba.org>
Date:   Sat Sep 21 14:35:02 2013 +1000

    KVM: PPC: Book3S HV: Support POWER6 compatibility mode on POWER7
    
    This enables us to use the Processor Compatibility Register (PCR) on
    POWER7 to put the processor into architecture 2.05 compatibility mode
    when running a guest.  In this mode the new instructions and registers
    that were introduced on POWER7 are disabled in user mode.  This
    includes all the VSX facilities plus several other instructions such
    as ldbrx, stdbrx, popcntw, popcntd, etc.
    
    To select this mode, we have a new register accessible through the
    set/get_one_reg interface, called KVM_REG_PPC_ARCH_COMPAT.  Setting
    this to zero gives the full set of capabilities of the processor.
    Setting it to one of the "logical" PVR values defined in PAPR puts
    the vcpu into the compatibility mode for the corresponding
    architecture level.  The supported values are:
    
    0x0f000002      Architecture 2.05 (POWER6)
    0x0f000003      Architecture 2.06 (POWER7)
    0x0f100003      Architecture 2.06+ (POWER7+)
    
    Since the PCR is per-core, the architecture compatibility level and
    the corresponding PCR value are stored in the struct kvmppc_vcore, and
    are therefore shared between all vcpus in a virtual core.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    [agraf: squash in fix to add missing break statements and documentation]
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 4bec4df3fb98..e294673e9d4b 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -314,6 +314,10 @@
 #define   LPID_RSVD	0x3ff		/* Reserved LPID for partn switching */
 #define	SPRN_HMER	0x150	/* Hardware m? error recovery */
 #define	SPRN_HMEER	0x151	/* Hardware m? enable error recovery */
+#define SPRN_PCR	0x152	/* Processor compatibility register */
+#define   PCR_VEC_DIS	(1ul << (63-0))	/* Vec. disable (bit NA since POWER8) */
+#define   PCR_VSX_DIS	(1ul << (63-1))	/* VSX disable (bit NA since POWER8) */
+#define   PCR_ARCH_205	0x2		/* Architecture 2.05 */
 #define	SPRN_HEIR	0x153	/* Hypervisor Emulated Instruction Register */
 #define SPRN_TLBINDEXR	0x154	/* P7 TLB control register */
 #define SPRN_TLBVPNR	0x155	/* P7 TLB control register */
@@ -1106,6 +1110,13 @@
 #define PVR_BE		0x0070
 #define PVR_PA6T	0x0090
 
+/* "Logical" PVR values defined in PAPR, representing architecture levels */
+#define PVR_ARCH_204	0x0f000001
+#define PVR_ARCH_205	0x0f000002
+#define PVR_ARCH_206	0x0f000003
+#define PVR_ARCH_206p	0x0f100003
+#define PVR_ARCH_207	0x0f000004
+
 /* Macros for setting and retrieving special purpose registers */
 #ifndef __ASSEMBLY__
 #define mfmsr()		({unsigned long rval; \

commit a0144e2a6b0b4a137a32f0102354782547bf0935
Author: Paul Mackerras <paulus@samba.org>
Date:   Fri Sep 20 14:52:38 2013 +1000

    KVM: PPC: Book3S HV: Store LPCR value for each virtual core
    
    This adds the ability to have a separate LPCR (Logical Partitioning
    Control Register) value relating to a guest for each virtual core,
    rather than only having a single value for the whole VM.  This
    corresponds to what real POWER hardware does, where there is a LPCR
    per CPU thread but most of the fields are required to have the same
    value on all active threads in a core.
    
    The per-virtual-core LPCR can be read and written using the
    GET/SET_ONE_REG interface.  Userspace can can only modify the
    following fields of the LPCR value:
    
    DPFD    Default prefetch depth
    ILE     Interrupt little-endian
    TC      Translation control (secondary HPT hash group search disable)
    
    We still maintain a per-VM default LPCR value in kvm->arch.lpcr, which
    contains bits relating to memory management, i.e. the Virtualized
    Partition Memory (VPM) bits and the bits relating to guest real mode.
    When this default value is updated, the update needs to be propagated
    to the per-vcore values, so we add a kvmppc_update_lpcr() helper to do
    that.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    [agraf: fix whitespace]
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index fd4db15e6f2a..4bec4df3fb98 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -284,6 +284,7 @@
 #define   LPCR_ISL	(1ul << (63-2))
 #define   LPCR_VC_SH	(63-2)
 #define   LPCR_DPFD_SH	(63-11)
+#define   LPCR_DPFD	(7ul << LPCR_DPFD_SH)
 #define   LPCR_VRMASD	(0x1ful << (63-16))
 #define   LPCR_VRMA_L	(1ul << (63-12))
 #define   LPCR_VRMA_LP0	(1ul << (63-15))
@@ -300,6 +301,7 @@
 #define     LPCR_PECE2	0x00001000	/* machine check etc can cause exit */
 #define   LPCR_MER	0x00000800	/* Mediated External Exception */
 #define   LPCR_MER_SH	11
+#define   LPCR_TC      0x00000200	/* Translation control */
 #define   LPCR_LPES    0x0000000c
 #define   LPCR_LPES0   0x00000008      /* LPAR Env selector 0 */
 #define   LPCR_LPES1   0x00000004      /* LPAR Env selector 1 */
@@ -421,6 +423,7 @@
 #define	 HID4_RMLS2_SH	 (63 - 2)	/* Real mode limit bottom 2 bits */
 #define	 HID4_LPID5_SH	 (63 - 6)	/* partition ID bottom 4 bits */
 #define	 HID4_RMOR_SH	 (63 - 22)	/* real mode offset (16 bits) */
+#define  HID4_RMOR	 (0xFFFFul << HID4_RMOR_SH)
 #define  HID4_LPES1	 (1 << (63-57))	/* LPAR env. sel. bit 1 */
 #define  HID4_RMLS0_SH	 (63 - 58)	/* Real mode limit top bit */
 #define	 HID4_LPID1_SH	 0		/* partition ID top 2 bits */

commit 93b0f4dc29c5f077a1c97bd1d484147230c3779a
Author: Paul Mackerras <paulus@samba.org>
Date:   Fri Sep 6 13:17:46 2013 +1000

    KVM: PPC: Book3S HV: Implement timebase offset for guests
    
    This allows guests to have a different timebase origin from the host.
    This is needed for migration, where a guest can migrate from one host
    to another and the two hosts might have a different timebase origin.
    However, the timebase seen by the guest must not go backwards, and
    should go forwards only by a small amount corresponding to the time
    taken for the migration.
    
    Therefore this provides a new per-vcpu value accessed via the one_reg
    interface using the new KVM_REG_PPC_TB_OFFSET identifier.  This value
    defaults to 0 and is not modified by KVM.  On entering the guest, this
    value is added onto the timebase, and on exiting the guest, it is
    subtracted from the timebase.
    
    This is only supported for recent POWER hardware which has the TBU40
    (timebase upper 40 bits) register.  Writing to the TBU40 register only
    alters the upper 40 bits of the timebase, leaving the lower 24 bits
    unchanged.  This provides a way to modify the timebase for guest
    migration without disturbing the synchronization of the timebase
    registers across CPU cores.  The kernel rounds up the value given
    to a multiple of 2^24.
    
    Timebase values stored in KVM structures (struct kvm_vcpu, struct
    kvmppc_vcore, etc.) are stored as host timebase values.  The timebase
    values in the dispatch trace log need to be guest timebase values,
    however, since that is read directly by the guest.  This moves the
    setting of vcpu->arch.dec_expires on guest exit to a point after we
    have restored the host timebase so that vcpu->arch.dec_expires is a
    host timebase value.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 10d1ef016bf1..fd4db15e6f2a 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -243,6 +243,7 @@
 #define SPRN_TBRU	0x10D	/* Time Base Read Upper Register (user, R/O) */
 #define SPRN_TBWL	0x11C	/* Time Base Lower Register (super, R/W) */
 #define SPRN_TBWU	0x11D	/* Time Base Upper Register (super, R/W) */
+#define SPRN_TBU40	0x11E	/* Timebase upper 40 bits (hyper, R/W) */
 #define SPRN_SPURR	0x134	/* Scaled PURR */
 #define SPRN_HSPRG0	0x130	/* Hypervisor Scratch 0 */
 #define SPRN_HSPRG1	0x131	/* Hypervisor Scratch 1 */

commit ef1967ff875d58c290108f9c6872a53a79855c4b
Author: Anton Blanchard <anton@samba.org>
Date:   Mon Sep 23 12:04:42 2013 +1000

    powerpc: Set MSR_LE bit on little endian builds
    
    We need to set MSR_LE in kernel and userspace for little endian builds
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 10d1ef016bf1..126f6e98f84d 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -115,7 +115,12 @@
 #define MSR_64BIT	MSR_SF
 
 /* Server variant */
-#define MSR_		(MSR_ME | MSR_RI | MSR_IR | MSR_DR | MSR_ISF |MSR_HV)
+#define __MSR		(MSR_ME | MSR_RI | MSR_IR | MSR_DR | MSR_ISF |MSR_HV)
+#ifdef __BIG_ENDIAN__
+#define MSR_		__MSR
+#else
+#define MSR_		(__MSR | MSR_LE)
+#endif
 #define MSR_KERNEL	(MSR_ | MSR_64BIT)
 #define MSR_USER32	(MSR_ | MSR_PR | MSR_EE)
 #define MSR_USER64	(MSR_USER32 | MSR_64BIT)

commit 9f24b0c9ef9b6b1292579c9e2cd7ff07ddc372b7
Author: Paul Mackerras <paulus@samba.org>
Date:   Thu Sep 5 16:01:16 2013 +1000

    powerpc: Correct FSCR bit definitions
    
    Commit 74e400cee6 ("powerpc: Rework setting up H/FSCR bit definitions")
    ended up with incorrect bit numbers for FSCR_PM_LG and FSCR_BHRB_LG.
    This fixes them.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Acked-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index dc10bf549635..10d1ef016bf1 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -258,8 +258,8 @@
 #define FSCR_TAR_LG	8	/* Enable Target Address Register */
 #define FSCR_EBB_LG	7	/* Enable Event Based Branching */
 #define FSCR_TM_LG	5	/* Enable Transactional Memory */
-#define FSCR_PM_LG	4	/* Enable prob/priv access to PMU SPRs */
-#define FSCR_BHRB_LG	3	/* Enable Branch History Rolling Buffer*/
+#define FSCR_BHRB_LG	4	/* Enable Branch History Rolling Buffer*/
+#define FSCR_PM_LG	3	/* Enable prob/priv access to PMU SPRs */
 #define FSCR_DSCR_LG	2	/* Enable Data Stream Control Register */
 #define FSCR_VECVSX_LG	1	/* Enable VMX/VSX  */
 #define FSCR_FP_LG	0	/* Enable Floating Point */

commit 3f1f4311881b330a7b5429dd101e676df191b159
Merge: 5935ff4343a6 28e61cc466d8
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Aug 27 15:03:30 2013 +1000

    Merge branch 'merge' into next
    
    Merge stuff that already went into Linus via "merge" which
    are pre-reqs for subsequent patches

commit beb2dc0a7a84be003ce54e98b95d65cc66e6e536
Author: Scott Wood <scottwood@freescale.com>
Date:   Tue Aug 20 19:33:12 2013 -0500

    powerpc: Convert some mftb/mftbu into mfspr
    
    Some CPUs (such as e500v1/v2) don't implement mftb and will take a
    trap.  mfspr should work on everything that has a timebase, and is the
    preferred instruction according to ISA v2.06.
    
    Currently we get away with mftb on 85xx because the assembler converts
    it to mfspr due to -Wa,-me500.  However, that flag has other effects
    that are undesireable for certain targets (e.g.  lwsync is converted to
    sync), and is hostile to multiplatform kernels.  Thus we would like to
    stop setting it for all e500-family builds.
    
    mftb/mftbu instances which are in 85xx code or common code are
    converted.  Instances which will never run on 85xx are left alone.
    
    Signed-off-by: Scott Wood <scottwood@freescale.com>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 55b03079d197..64264bf601f5 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1120,7 +1120,7 @@
 #if defined(CONFIG_PPC_CELL) || defined(CONFIG_PPC_FSL_BOOK3E)
 #define mftb()		({unsigned long rval;				\
 			asm volatile(					\
-				"90:	mftb %0;\n"			\
+				"90:	mfspr %0, %2;\n"		\
 				"97:	cmpwi %0,0;\n"			\
 				"	beq- 90b;\n"			\
 				"99:\n"					\
@@ -1134,18 +1134,23 @@
 				"	.llong 0\n"			\
 				"	.llong 0\n"			\
 				".previous"				\
-			: "=r" (rval) : "i" (CPU_FTR_CELL_TB_BUG)); rval;})
+			: "=r" (rval) \
+			: "i" (CPU_FTR_CELL_TB_BUG), "i" (SPRN_TBRL)); \
+			rval;})
 #else
 #define mftb()		({unsigned long rval;	\
-			asm volatile("mftb %0" : "=r" (rval)); rval;})
+			asm volatile("mfspr %0, %1" : \
+				     "=r" (rval) : "i" (SPRN_TBRL)); rval;})
 #endif /* !CONFIG_PPC_CELL */
 
 #else /* __powerpc64__ */
 
 #define mftbl()		({unsigned long rval;	\
-			asm volatile("mftbl %0" : "=r" (rval)); rval;})
+			asm volatile("mfspr %0, %1" : "=r" (rval) : \
+				"i" (SPRN_TBRL)); rval;})
 #define mftbu()		({unsigned long rval;	\
-			asm volatile("mftbu %0" : "=r" (rval)); rval;})
+			asm volatile("mfspr %0, %1" : "=r" (rval) : \
+				"i" (SPRN_TBRU)); rval;})
 #endif /* !__powerpc64__ */
 
 #define mttbl(v)	asm volatile("mttbl %0":: "r"(v))

commit d52459ca3047435aa5d7957e50857fc7ba193411
Author: Scott Wood <scottwood@freescale.com>
Date:   Tue Jul 23 20:21:11 2013 -0500

    powerpc/fsl-booke: Work around erratum A-006958
    
    Erratum A-006598 says that 64-bit mftb is not atomic -- it's subject
    to a similar race condition as doing mftbu/mftbl on 32-bit.  The lower
    half of timebase is updated before the upper half; thus, we can share
    the workaround for a similar bug on Cell.  This workaround involves
    looping if the lower half of timebase is zero, thus avoiding the need
    for a scratch register (other than CR0).  This workaround must be
    avoided when the timebase is frozen, such as during the timebase sync
    code.
    
    This deals with kernel and vdso accesses, but other userspace accesses
    will of course need to be fixed elsewhere.
    
    Signed-off-by: Scott Wood <scottwood@freescale.com>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index a312e0c8cef4..55b03079d197 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1117,7 +1117,7 @@
 				     : "memory")
 
 #ifdef __powerpc64__
-#ifdef CONFIG_PPC_CELL
+#if defined(CONFIG_PPC_CELL) || defined(CONFIG_PPC_FSL_BOOK3E)
 #define mftb()		({unsigned long rval;				\
 			asm volatile(					\
 				"90:	mftb %0;\n"			\

commit 594bd38303b489156c005177ccb4af52f942e2f5
Author: Anton Blanchard <anton@samba.org>
Date:   Wed Aug 7 02:01:20 2013 +1000

    powerpc: Wrap MSR macros with parentheses
    
    Not having parentheses around a macro is asking for trouble.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index a6840e4e24f7..a312e0c8cef4 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -115,10 +115,10 @@
 #define MSR_64BIT	MSR_SF
 
 /* Server variant */
-#define MSR_		MSR_ME | MSR_RI | MSR_IR | MSR_DR | MSR_ISF |MSR_HV
-#define MSR_KERNEL	MSR_ | MSR_64BIT
-#define MSR_USER32	MSR_ | MSR_PR | MSR_EE
-#define MSR_USER64	MSR_USER32 | MSR_64BIT
+#define MSR_		(MSR_ME | MSR_RI | MSR_IR | MSR_DR | MSR_ISF |MSR_HV)
+#define MSR_KERNEL	(MSR_ | MSR_64BIT)
+#define MSR_USER32	(MSR_ | MSR_PR | MSR_EE)
+#define MSR_USER64	(MSR_USER32 | MSR_64BIT)
 #elif defined(CONFIG_PPC_BOOK3S_32) || defined(CONFIG_8xx)
 /* Default MSR for kernel mode. */
 #define MSR_KERNEL	(MSR_ME|MSR_RI|MSR_IR|MSR_DR)

commit 74e400cee6c0266ba2d940ed78d981f1e24a8167
Author: Michael Neuling <mikey@neuling.org>
Date:   Fri Aug 9 17:29:28 2013 +1000

    powerpc: Rework setting up H/FSCR bit definitions
    
    This reworks the Facility Status and Control Regsiter (FSCR) config bit
    definitions so that we can access the bit numbers.  This is needed for a
    subsequent patch to fix the userspace DSCR handling.
    
    HFSCR and FSCR bit definitions are the same, so reuse them.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Cc: <stable@vger.kernel.org> [v3.10]
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index a6840e4e24f7..99222e27f173 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -254,19 +254,28 @@
 #define SPRN_HRMOR	0x139	/* Real mode offset register */
 #define SPRN_HSRR0	0x13A	/* Hypervisor Save/Restore 0 */
 #define SPRN_HSRR1	0x13B	/* Hypervisor Save/Restore 1 */
+/* HFSCR and FSCR bit numbers are the same */
+#define FSCR_TAR_LG	8	/* Enable Target Address Register */
+#define FSCR_EBB_LG	7	/* Enable Event Based Branching */
+#define FSCR_TM_LG	5	/* Enable Transactional Memory */
+#define FSCR_PM_LG	4	/* Enable prob/priv access to PMU SPRs */
+#define FSCR_BHRB_LG	3	/* Enable Branch History Rolling Buffer*/
+#define FSCR_DSCR_LG	2	/* Enable Data Stream Control Register */
+#define FSCR_VECVSX_LG	1	/* Enable VMX/VSX  */
+#define FSCR_FP_LG	0	/* Enable Floating Point */
 #define SPRN_FSCR	0x099	/* Facility Status & Control Register */
-#define   FSCR_TAR	(1 << (63-55)) /* Enable Target Address Register */
-#define   FSCR_EBB	(1 << (63-56)) /* Enable Event Based Branching */
-#define   FSCR_DSCR	(1 << (63-61)) /* Enable Data Stream Control Register */
+#define   FSCR_TAR	__MASK(FSCR_TAR_LG)
+#define   FSCR_EBB	__MASK(FSCR_EBB_LG)
+#define   FSCR_DSCR	__MASK(FSCR_DSCR_LG)
 #define SPRN_HFSCR	0xbe	/* HV=1 Facility Status & Control Register */
-#define   HFSCR_TAR	(1 << (63-55)) /* Enable Target Address Register */
-#define   HFSCR_EBB	(1 << (63-56)) /* Enable Event Based Branching */
-#define   HFSCR_TM	(1 << (63-58)) /* Enable Transactional Memory */
-#define   HFSCR_PM	(1 << (63-60)) /* Enable prob/priv access to PMU SPRs */
-#define   HFSCR_BHRB	(1 << (63-59)) /* Enable Branch History Rolling Buffer*/
-#define   HFSCR_DSCR	(1 << (63-61)) /* Enable Data Stream Control Register */
-#define   HFSCR_VECVSX	(1 << (63-62)) /* Enable VMX/VSX  */
-#define   HFSCR_FP	(1 << (63-63)) /* Enable Floating Point */
+#define   HFSCR_TAR	__MASK(FSCR_TAR_LG)
+#define   HFSCR_EBB	__MASK(FSCR_EBB_LG)
+#define   HFSCR_TM	__MASK(FSCR_TM_LG)
+#define   HFSCR_PM	__MASK(FSCR_PM_LG)
+#define   HFSCR_BHRB	__MASK(FSCR_BHRB_LG)
+#define   HFSCR_DSCR	__MASK(FSCR_DSCR_LG)
+#define   HFSCR_VECVSX	__MASK(FSCR_VECVSX_LG)
+#define   HFSCR_FP	__MASK(FSCR_FP_LG)
 #define SPRN_TAR	0x32f	/* Target Address Register */
 #define SPRN_LPCR	0x13E	/* LPAR Control Register */
 #define   LPCR_VPM0	(1ul << (63-0))

commit 33959f88fce9b8d3346d8000b3425814cbc6d6c0
Author: Michael Neuling <mikey@neuling.org>
Date:   Thu Jul 18 11:31:51 2013 +1000

    powerpc: Add second POWER8 PVR entry
    
    POWER8 comes with two different PVRs.  This patch enables the additional
    PVR in the cputable.
    
    The existing entry (PVR=0x4b) is renamed to POWER8E and the new entry
    (PVR=0x4d) is given POWER8.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 5d7d9c2a5473..a6840e4e24f7 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1088,7 +1088,8 @@
 #define PVR_970MP	0x0044
 #define PVR_970GX	0x0045
 #define PVR_POWER7p	0x004A
-#define PVR_POWER8	0x004B
+#define PVR_POWER8E	0x004B
+#define PVR_POWER8	0x004D
 #define PVR_BE		0x0070
 #define PVR_PA6T	0x0090
 

commit 330a1eb7775ba876dbd46b9885556e57f705e3d4
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Fri Jun 28 18:15:16 2013 +1000

    powerpc/perf: Core EBB support for 64-bit book3s
    
    Add support for EBB (Event Based Branches) on 64-bit book3s. See the
    included documentation for more details.
    
    EBBs are a feature which allows the hardware to branch directly to a
    specified user space address when a PMU event overflows. This can be
    used by programs for self-monitoring with no kernel involvement in the
    inner loop.
    
    Most of the logic is in the generic book3s code, primarily to avoid a
    proliferation of PMU callbacks.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 362142b69d5b..5d7d9c2a5473 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -621,6 +621,9 @@
 #define   MMCR0_PMXE	0x04000000UL /* performance monitor exception enable */
 #define   MMCR0_FCECE	0x02000000UL /* freeze ctrs on enabled cond or event */
 #define   MMCR0_TBEE	0x00400000UL /* time base exception enable */
+#define   MMCR0_EBE	0x00100000UL /* Event based branch enable */
+#define   MMCR0_PMCC	0x000c0000UL /* PMC control */
+#define   MMCR0_PMCC_U6	0x00080000UL /* PMC1-6 are R/W by user (PR) */
 #define   MMCR0_PMC1CE	0x00008000UL /* PMC1 count enable*/
 #define   MMCR0_PMCjCE	0x00004000UL /* PMCj count enable*/
 #define   MMCR0_TRIGGER	0x00002000UL /* TRIGGER enable */
@@ -674,6 +677,11 @@
 #define   SIER_SIAR_VALID	0x0400000	/* SIAR contents valid */
 #define   SIER_SDAR_VALID	0x0200000	/* SDAR contents valid */
 
+/* When EBB is enabled, some of MMCR0/MMCR2/SIER are user accessible */
+#define MMCR0_USER_MASK	(MMCR0_FC | MMCR0_PMXE | MMCR0_PMAO)
+#define MMCR2_USER_MASK	0x4020100804020000UL /* (FC1P|FC2P|FC3P|FC4P|FC5P|FC6P) */
+#define SIER_USER_MASK	0x7fffffUL
+
 #define SPRN_PA6T_MMCR0 795
 #define   PA6T_MMCR0_EN0	0x0000000000000001UL
 #define   PA6T_MMCR0_EN1	0x0000000000000002UL

commit 7a7a41f9d5b28ac3a916b057a7d3cd3f435ee9a6
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Fri Jun 28 18:15:12 2013 +1000

    powerpc/perf: Freeze PMC5/6 if we're not using them
    
    On Power8 we can freeze PMC5 and 6 if we're not using them. Normally they
    run all the time.
    
    As noticed by Anshuman, we should unfreeze them when we disable the PMU
    as there are legacy tools which expect them to run all the time.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    CC: <stable@vger.kernel.org> [v3.10]
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 4a9e408644fe..362142b69d5b 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -626,6 +626,7 @@
 #define   MMCR0_TRIGGER	0x00002000UL /* TRIGGER enable */
 #define   MMCR0_PMAO	0x00000080UL /* performance monitor alert has occurred, set to 0 after handling exception */
 #define   MMCR0_SHRFC	0x00000040UL /* SHRre freeze conditions between threads */
+#define   MMCR0_FC56	0x00000010UL /* freeze counters 5 and 6 */
 #define   MMCR0_FCTI	0x00000008UL /* freeze counters in tags inactive mode */
 #define   MMCR0_FCTA	0x00000004UL /* freeze counters in tags active mode */
 #define   MMCR0_FCWAIT	0x00000002UL /* freeze counter in WAIT state */

commit b75c100ef24894bd2c8b52e123bcc5f191c5d9fd
Author: Michael Neuling <mikey@neuling.org>
Date:   Sun May 26 18:30:56 2013 +0000

    powerpc/tm: Move TM abort cause codes to uapi
    
    These cause codes are usable by userspace, so let's export to uapi.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Cc: <stable@vger.kernel.org> # v3.9
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index d0528e0d6db8..4a9e408644fe 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -111,20 +111,6 @@
 #define MSR_TM_TRANSACTIONAL(x)	(((x) & MSR_TS_MASK) == MSR_TS_T)
 #define MSR_TM_SUSPENDED(x)	(((x) & MSR_TS_MASK) == MSR_TS_S)
 
-/* Reason codes describing kernel causes for transaction aborts.  By
-   convention, bit0 is copied to TEXASR[56] (IBM bit 7) which is set if
-   the failure is persistent.  PAPR saves 0xff-0xe0 for the hypervisor.
-*/
-#define TM_CAUSE_PERSISTENT	0x01
-#define TM_CAUSE_RESCHED	0xde
-#define TM_CAUSE_TLBI		0xdc
-#define TM_CAUSE_FAC_UNAV	0xda
-#define TM_CAUSE_SYSCALL	0xd8  /* future use */
-#define TM_CAUSE_MISC		0xd6  /* future use */
-#define TM_CAUSE_SIGNAL		0xd4
-#define TM_CAUSE_ALIGNMENT	0xd2
-#define TM_CAUSE_EMULATE	0xd0
-
 #if defined(CONFIG_PPC_BOOK3S_64)
 #define MSR_64BIT	MSR_SF
 

commit 6ce6c629fd8254b3177650de99699682ff7f6707
Author: Michael Neuling <mikey@neuling.org>
Date:   Sun May 26 18:09:39 2013 +0000

    powerpc/tm: Abort on emulation and alignment faults
    
    If we are emulating an instruction inside an active user transaction that
    touches memory, the kernel can't emulate it as it operates in transactional
    suspend context.  We need to abort these transactions and send them back to
    userspace for the hardware to rollback.
    
    We can service these if the user transaction is in suspend mode, since the
    kernel will operate in the same suspend context.
    
    This adds a check to all alignment faults and to specific instruction
    emulations (only string instructions for now).  If the user process is in an
    active (non-suspended) transaction, we abort the transaction go back to
    userspace allowing the HW to roll back the transaction and tell the user of the
    failure.  This also adds new tm abort cause codes to report the reason of the
    persistent error to the user.
    
    Crappy test case here http://neuling.org/devel/junkcode/aligntm.c
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Cc: <stable@vger.kernel.org> # v3.9
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 8f6a94b2dc99..d0528e0d6db8 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -122,6 +122,8 @@
 #define TM_CAUSE_SYSCALL	0xd8  /* future use */
 #define TM_CAUSE_MISC		0xd6  /* future use */
 #define TM_CAUSE_SIGNAL		0xd4
+#define TM_CAUSE_ALIGNMENT	0xd2
+#define TM_CAUSE_EMULATE	0xd0
 
 #if defined(CONFIG_PPC_BOOK3S_64)
 #define MSR_64BIT	MSR_SF

commit 35f7097fcedec63fcba1852dbee96f74a2d90878
Author: Michael Neuling <mikey@neuling.org>
Date:   Sun May 26 18:09:37 2013 +0000

    powerpc/tm: Make room for hypervisor in abort cause codes
    
    PAPR carves out 0xff-0xe0 for hypervisor use of transactional memory software
    abort cause codes.  Unfortunately we don't respect this currently.
    
    Below fixes this to move our cause codes to below this region.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Cc: <stable@vger.kernel.org> # 3.9 only
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index a6136515c7f2..8f6a94b2dc99 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -113,14 +113,15 @@
 
 /* Reason codes describing kernel causes for transaction aborts.  By
    convention, bit0 is copied to TEXASR[56] (IBM bit 7) which is set if
-   the failure is persistent.
+   the failure is persistent.  PAPR saves 0xff-0xe0 for the hypervisor.
 */
-#define TM_CAUSE_RESCHED	0xfe
-#define TM_CAUSE_TLBI		0xfc
-#define TM_CAUSE_FAC_UNAV	0xfa
-#define TM_CAUSE_SYSCALL	0xf9 /* Persistent */
-#define TM_CAUSE_MISC		0xf6
-#define TM_CAUSE_SIGNAL		0xf4
+#define TM_CAUSE_PERSISTENT	0x01
+#define TM_CAUSE_RESCHED	0xde
+#define TM_CAUSE_TLBI		0xdc
+#define TM_CAUSE_FAC_UNAV	0xda
+#define TM_CAUSE_SYSCALL	0xd8  /* future use */
+#define TM_CAUSE_MISC		0xd6  /* future use */
+#define TM_CAUSE_SIGNAL		0xd4
 
 #if defined(CONFIG_PPC_BOOK3S_64)
 #define MSR_64BIT	MSR_SF

commit 01227a889ed56ae53aeebb9f93be9d54dd8b2de8
Merge: 9e6879460c8e db6ae6158186
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun May 5 14:47:31 2013 -0700

    Merge tag 'kvm-3.10-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull kvm updates from Gleb Natapov:
     "Highlights of the updates are:
    
      general:
       - new emulated device API
       - legacy device assignment is now optional
       - irqfd interface is more generic and can be shared between arches
    
      x86:
       - VMCS shadow support and other nested VMX improvements
       - APIC virtualization and Posted Interrupt hardware support
       - Optimize mmio spte zapping
    
      ppc:
        - BookE: in-kernel MPIC emulation with irqfd support
        - Book3S: in-kernel XICS emulation (incomplete)
        - Book3S: HV: migration fixes
        - BookE: more debug support preparation
        - BookE: e6500 support
    
      ARM:
       - reworking of Hyp idmaps
    
      s390:
       - ioeventfd for virtio-ccw
    
      And many other bug fixes, cleanups and improvements"
    
    * tag 'kvm-3.10-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (204 commits)
      kvm: Add compat_ioctl for device control API
      KVM: x86: Account for failing enable_irq_window for NMI window request
      KVM: PPC: Book3S: Add API for in-kernel XICS emulation
      kvm/ppc/mpic: fix missing unlock in set_base_addr()
      kvm/ppc: Hold srcu lock when calling kvm_io_bus_read/write
      kvm/ppc/mpic: remove users
      kvm/ppc/mpic: fix mmio region lists when multiple guests used
      kvm/ppc/mpic: remove default routes from documentation
      kvm: KVM_CAP_IOMMU only available with device assignment
      ARM: KVM: iterate over all CPUs for CPU compatibility check
      KVM: ARM: Fix spelling in error message
      ARM: KVM: define KVM_ARM_MAX_VCPUS unconditionally
      KVM: ARM: Fix API documentation for ONE_REG encoding
      ARM: KVM: promote vfp_host pointer to generic host cpu context
      ARM: KVM: add architecture specific hook for capabilities
      ARM: KVM: perform HYP initilization for hotplugged CPUs
      ARM: KVM: switch to a dual-step HYP init code
      ARM: KVM: rework HYP page table freeing
      ARM: KVM: enforce maximum size for identity mapped code
      ARM: KVM: move to a KVM provided HYP idmap
      ...

commit 9353374b8e1585d5fa47a1e5c1d3e9155dd0eb7c
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Tue Apr 30 20:17:04 2013 +0000

    powerpc: Context switch the new EBB SPRs
    
    This context switches the new Event Based Branching (EBB) SPRs.  The three new
    SPRs are:
      - Event Based Branch Handler Register (EBBHR)
      - Event Based Branch Return Register (EBBRR)
      - Branch Event Status and Control Register (BESCR)
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Matt Evans <matt@ozlabs.org>
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 93be5fb20394..3d17427e4fd7 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -663,6 +663,9 @@
 #define SPRN_MMCRH	316	/* Hypervisor monitor mode control register */
 #define SPRN_MMCRS	894	/* Supervisor monitor mode control register */
 #define SPRN_MMCRC	851	/* Core monitor mode control register */
+#define SPRN_EBBHR	804	/* Event based branch handler register */
+#define SPRN_EBBRR	805	/* Event based branch return register */
+#define SPRN_BESCR	806	/* Branch event status and control register */
 
 #define SPRN_PMC1	787
 #define SPRN_PMC2	788

commit 1ddf499e1a49e67c02b89e6565d091a0bda29a91
Author: Michael Neuling <mikey@neuling.org>
Date:   Tue Apr 30 20:17:03 2013 +0000

    powerpc: Turn on the EBB H/FSCR bits
    
    This turns Event Based Branching (EBB) on in the Hypervisor Facility Status and
    Control Register (HFSCR) and Facility Status and Control Register (FSCR).
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 178a85844462..93be5fb20394 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -267,9 +267,11 @@
 #define SPRN_HSRR1	0x13B	/* Hypervisor Save/Restore 1 */
 #define SPRN_FSCR	0x099	/* Facility Status & Control Register */
 #define   FSCR_TAR	(1 << (63-55)) /* Enable Target Address Register */
+#define   FSCR_EBB	(1 << (63-56)) /* Enable Event Based Branching */
 #define   FSCR_DSCR	(1 << (63-61)) /* Enable Data Stream Control Register */
 #define SPRN_HFSCR	0xbe	/* HV=1 Facility Status & Control Register */
 #define   HFSCR_TAR	(1 << (63-55)) /* Enable Target Address Register */
+#define   HFSCR_EBB	(1 << (63-56)) /* Enable Event Based Branching */
 #define   HFSCR_TM	(1 << (63-58)) /* Enable Transactional Memory */
 #define   HFSCR_PM	(1 << (63-60)) /* Enable prob/priv access to PMU SPRs */
 #define   HFSCR_BHRB	(1 << (63-59)) /* Enable Branch History Rolling Buffer*/

commit 53b56ca0195b8a2a098a358088ecfefafb030b40
Author: Anshuman Khandual <khandual@linux.vnet.ibm.com>
Date:   Thu Apr 25 20:54:55 2013 +0000

    powerpc: Setup BHRB instructions facility in HFSCR for POWER8
    
    Make BHRB instructions available in problem and privileged states.
    
    Signed-off-by: Anshuman Khandual <khandual@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 5c6fbe2c5ce6..178a85844462 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -272,6 +272,7 @@
 #define   HFSCR_TAR	(1 << (63-55)) /* Enable Target Address Register */
 #define   HFSCR_TM	(1 << (63-58)) /* Enable Transactional Memory */
 #define   HFSCR_PM	(1 << (63-60)) /* Enable prob/priv access to PMU SPRs */
+#define   HFSCR_BHRB	(1 << (63-59)) /* Enable Branch History Rolling Buffer*/
 #define   HFSCR_DSCR	(1 << (63-61)) /* Enable Data Stream Control Register */
 #define   HFSCR_VECVSX	(1 << (63-62)) /* Enable VMX/VSX  */
 #define   HFSCR_FP	(1 << (63-63)) /* Enable Floating Point */

commit 4619ac88b72c43c622ef1eae3069de0e6f2cba9d
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Apr 17 20:31:41 2013 +0000

    KVM: PPC: Book3S HV: Improve real-mode handling of external interrupts
    
    This streamlines our handling of external interrupts that come in
    while we're in the guest.  First, when waking up a hardware thread
    that was napping, we split off the "napping due to H_CEDE" case
    earlier, and use the code that handles an external interrupt (0x500)
    in the guest to handle that too.  Secondly, the code that handles
    those external interrupts now checks if any other thread is exiting
    to the host before bouncing an external interrupt to the guest, and
    also checks that there is actually an external interrupt pending for
    the guest before setting the LPCR MER bit (mediated external request).
    
    This also makes sure that we clear the "ceded" flag when we handle a
    wakeup from cede in real mode, and fixes a potential infinite loop
    in kvmppc_run_vcpu() which can occur if we ever end up with the ceded
    flag set but MSR[EE] off.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c9c67fc888c9..799322433620 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -290,6 +290,7 @@
 #define     LPCR_PECE1	0x00002000	/* decrementer can cause exit */
 #define     LPCR_PECE2	0x00001000	/* machine check etc can cause exit */
 #define   LPCR_MER	0x00000800	/* Mediated External Exception */
+#define   LPCR_MER_SH	11
 #define   LPCR_LPES    0x0000000c
 #define   LPCR_LPES0   0x00000008      /* LPAR Env selector 0 */
 #define   LPCR_LPES1   0x00000004      /* LPAR Env selector 1 */

commit 8f61aa325fab3a40b7c847bd35601ad99d7959c9
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Apr 25 19:28:27 2013 +0000

    powerpc/perf: Add support for SIER
    
    On power8 we have a new SIER (Sampled Instruction Event Register), which
    captures information about instructions when we have random sampling
    enabled.
    
    Add support for loading the SIER into pt_regs, overloading regs->dar.
    Also set the new NO_SIPR flag in regs->result if we don't have SIPR.
    
    Update regs_sihv/sipr() to look for SIPR/SIHV in SIER.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 5735ebbd5888..5c6fbe2c5ce6 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -671,6 +671,11 @@
 #define SPRN_PMC8	794
 #define SPRN_SIAR	780
 #define SPRN_SDAR	781
+#define SPRN_SIER	784
+#define   SIER_SIPR		0x2000000	/* Sampled MSR_PR */
+#define   SIER_SIHV		0x1000000	/* Sampled MSR_HV */
+#define   SIER_SIAR_VALID	0x0400000	/* SIAR contents valid */
+#define   SIER_SDAR_VALID	0x0200000	/* SDAR contents valid */
 
 #define SPRN_PA6T_MMCR0 795
 #define   PA6T_MMCR0_EN0	0x0000000000000001UL

commit 240686c1368775b5dc80aae863301189b25f9bfa
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Apr 25 19:28:22 2013 +0000

    powerpc: Initialise PMU related regs on Power8
    
    For both HV and guest kernels, intialise PMU regs to something sane.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 4ae2d446dedb..5735ebbd5888 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -271,6 +271,7 @@
 #define SPRN_HFSCR	0xbe	/* HV=1 Facility Status & Control Register */
 #define   HFSCR_TAR	(1 << (63-55)) /* Enable Target Address Register */
 #define   HFSCR_TM	(1 << (63-58)) /* Enable Transactional Memory */
+#define   HFSCR_PM	(1 << (63-60)) /* Enable prob/priv access to PMU SPRs */
 #define   HFSCR_DSCR	(1 << (63-61)) /* Enable Data Stream Control Register */
 #define   HFSCR_VECVSX	(1 << (63-62)) /* Enable VMX/VSX  */
 #define   HFSCR_FP	(1 << (63-63)) /* Enable Floating Point */
@@ -637,6 +638,7 @@
 #define   MMCR0_FCWAIT	0x00000002UL /* freeze counter in WAIT state */
 #define   MMCR0_FCHV	0x00000001UL /* freeze conditions in hypervisor mode */
 #define SPRN_MMCR1	798
+#define SPRN_MMCR2	769
 #define SPRN_MMCRA	0x312
 #define   MMCRA_SDSYNC	0x80000000UL /* SDAR synced with SIAR */
 #define   MMCRA_SDAR_DCACHE_MISS 0x40000000UL
@@ -655,6 +657,10 @@
 #define   POWER7P_MMCRA_SIAR_VALID 0x10000000	/* P7+ SIAR contents valid */
 #define   POWER7P_MMCRA_SDAR_VALID 0x08000000	/* P7+ SDAR contents valid */
 
+#define SPRN_MMCRH	316	/* Hypervisor monitor mode control register */
+#define SPRN_MMCRS	894	/* Supervisor monitor mode control register */
+#define SPRN_MMCRC	851	/* Core monitor mode control register */
+
 #define SPRN_PMC1	787
 #define SPRN_PMC2	788
 #define SPRN_PMC3	789

commit 04b418c97f4e6cabe186484e9d9cd2f42e67d912
Author: Michael Neuling <mikey@neuling.org>
Date:   Tue Mar 5 17:35:23 2013 +0000

    powerpc: Add HFSCR SPR definitions
    
    Add SPR number and bit definitions for the HFSCR (Hypervisor Facility Status
    and Control Register).
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c9c67fc888c9..4ae2d446dedb 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -268,6 +268,12 @@
 #define SPRN_FSCR	0x099	/* Facility Status & Control Register */
 #define   FSCR_TAR	(1 << (63-55)) /* Enable Target Address Register */
 #define   FSCR_DSCR	(1 << (63-61)) /* Enable Data Stream Control Register */
+#define SPRN_HFSCR	0xbe	/* HV=1 Facility Status & Control Register */
+#define   HFSCR_TAR	(1 << (63-55)) /* Enable Target Address Register */
+#define   HFSCR_TM	(1 << (63-58)) /* Enable Transactional Memory */
+#define   HFSCR_DSCR	(1 << (63-61)) /* Enable Data Stream Control Register */
+#define   HFSCR_VECVSX	(1 << (63-62)) /* Enable VMX/VSX  */
+#define   HFSCR_FP	(1 << (63-63)) /* Enable Floating Point */
 #define SPRN_TAR	0x32f	/* Target Address Register */
 #define SPRN_LPCR	0x13E	/* LPAR Control Register */
 #define   LPCR_VPM0	(1ul << (63-0))

commit fa759e9b0984748cf626aac59bca60bdab42c644
Author: Michael Neuling <mikey@neuling.org>
Date:   Mon Mar 4 19:45:51 2013 +0000

    powerpc: Add DSCR FSCR register bit definition
    
    This sets the DSCR (Data Stream Control Register) in the FSCR (Facility Status
    & Control Register).
    
    Also harmonise TAR (Target Address Register) FSCR bit definition too.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index e66586122030..c9c67fc888c9 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -266,7 +266,8 @@
 #define SPRN_HSRR0	0x13A	/* Hypervisor Save/Restore 0 */
 #define SPRN_HSRR1	0x13B	/* Hypervisor Save/Restore 1 */
 #define SPRN_FSCR	0x099	/* Facility Status & Control Register */
-#define FSCR_TAR	(1<<8)	/* Enable Target Adress Register */
+#define   FSCR_TAR	(1 << (63-55)) /* Enable Target Address Register */
+#define   FSCR_DSCR	(1 << (63-61)) /* Enable Data Stream Control Register */
 #define SPRN_TAR	0x32f	/* Target Address Register */
 #define SPRN_LPCR	0x13E	/* LPAR Control Register */
 #define   LPCR_VPM0	(1ul << (63-0))

commit 89f883372fa60f604d136924baf3e89ff1870e9e
Merge: 9e2d59ad580d 6b73a96065e8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Feb 24 13:07:18 2013 -0800

    Merge tag 'kvm-3.9-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull KVM updates from Marcelo Tosatti:
     "KVM updates for the 3.9 merge window, including x86 real mode
      emulation fixes, stronger memory slot interface restrictions, mmu_lock
      spinlock hold time reduction, improved handling of large page faults
      on shadow, initial APICv HW acceleration support, s390 channel IO
      based virtio, amongst others"
    
    * tag 'kvm-3.9-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (143 commits)
      Revert "KVM: MMU: lazily drop large spte"
      x86: pvclock kvm: align allocation size to page size
      KVM: nVMX: Remove redundant get_vmcs12 from nested_vmx_exit_handled_msr
      x86 emulator: fix parity calculation for AAD instruction
      KVM: PPC: BookE: Handle alignment interrupts
      booke: Added DBCR4 SPR number
      KVM: PPC: booke: Allow multiple exception types
      KVM: PPC: booke: use vcpu reference from thread_struct
      KVM: Remove user_alloc from struct kvm_memory_slot
      KVM: VMX: disable apicv by default
      KVM: s390: Fix handling of iscs.
      KVM: MMU: cleanup __direct_map
      KVM: MMU: remove pt_access in mmu_set_spte
      KVM: MMU: cleanup mapping-level
      KVM: MMU: lazily drop large spte
      KVM: VMX: cleanup vmx_set_cr0().
      KVM: VMX: add missing exit names to VMX_EXIT_REASONS array
      KVM: VMX: disable SMEP feature when guest is in non-paging mode
      KVM: Remove duplicate text in api.txt
      Revert "KVM: MMU: split kvm_mmu_free_page"
      ...

commit 2b0a576d15e0e14751f00f9c87e46bad27f217e7
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed Feb 13 16:21:41 2013 +0000

    powerpc: Add new transactional memory state to the signal context
    
    This adds the new transactional memory archtected state to the signal context
    in both 32 and 64 bit.
    
    Signed-off-by: Matt Evans <matt@ozlabs.org>
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index eee2a60994bf..7035e608f3fa 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -120,6 +120,7 @@
 #define TM_CAUSE_FAC_UNAV	0xfa
 #define TM_CAUSE_SYSCALL	0xf9 /* Persistent */
 #define TM_CAUSE_MISC		0xf6
+#define TM_CAUSE_SIGNAL		0xf4
 
 #if defined(CONFIG_PPC_BOOK3S_64)
 #define MSR_64BIT	MSR_SF

commit 98ae22e15b430bfed5def01ac1a88ec9396284c8
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed Feb 13 16:21:35 2013 +0000

    powerpc: Add helper functions for transactional memory context switching
    
    Here we add the helper functions to be used when context switching.  These
    allow us to fully reclaim and recheckpoint a transaction.
    
    We introduce a new paca field called tm_scratch to help us store away register
    values when doing the low level tm reclaim register save.
    
    Signed-off-by: Matt Evans <matt@ozlabs.org>
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 7844c285f6e1..eee2a60994bf 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -797,7 +797,7 @@
  *        HV mode in which case it is HSPRG0
  *
  * 64-bit server:
- *	- SPRG0 unused (reserved for HV on Power4)
+ *	- SPRG0 scratch for TM recheckpoint/reclaim (reserved for HV on Power4)
  *	- SPRG2 scratch for exception vectors
  *	- SPRG3 CPU and NUMA node for VDSO getcpu (user visible)
  *      - HSPRG0 stores PACA in HV mode

commit 97a0aac9b844a8bcfebb6805322998f8ca4db9dc
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed Feb 13 16:21:33 2013 +0000

    powerpc: Register defines for various transactional memory registers
    
    Defines for MSR bits and transactional memory related SPRs TFIAR, TEXASR and
    TEXASRU.
    
    Signed-off-by: Matt Evans <matt@ozlabs.org>
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index e09ac51961d7..7844c285f6e1 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -29,6 +29,10 @@
 #define MSR_SF_LG	63              /* Enable 64 bit mode */
 #define MSR_ISF_LG	61              /* Interrupt 64b mode valid on 630 */
 #define MSR_HV_LG 	60              /* Hypervisor state */
+#define MSR_TS_T_LG	34		/* Trans Mem state: Transactional */
+#define MSR_TS_S_LG	33		/* Trans Mem state: Suspended */
+#define MSR_TS_LG	33		/* Trans Mem state (2 bits) */
+#define MSR_TM_LG	32		/* Trans Mem Available */
 #define MSR_VEC_LG	25	        /* Enable AltiVec */
 #define MSR_VSX_LG	23		/* Enable VSX */
 #define MSR_POW_LG	18		/* Enable Power Management */
@@ -98,6 +102,25 @@
 #define MSR_RI		__MASK(MSR_RI_LG)	/* Recoverable Exception */
 #define MSR_LE		__MASK(MSR_LE_LG)	/* Little Endian */
 
+#define MSR_TM		__MASK(MSR_TM_LG)	/* Transactional Mem Available */
+#define MSR_TS_N	0			/*  Non-transactional */
+#define MSR_TS_S	__MASK(MSR_TS_S_LG)	/*  Transaction Suspended */
+#define MSR_TS_T	__MASK(MSR_TS_T_LG)	/*  Transaction Transactional */
+#define MSR_TS_MASK	(MSR_TS_T | MSR_TS_S)   /* Transaction State bits */
+#define MSR_TM_ACTIVE(x) (((x) & MSR_TS_MASK) != 0) /* Transaction active? */
+#define MSR_TM_TRANSACTIONAL(x)	(((x) & MSR_TS_MASK) == MSR_TS_T)
+#define MSR_TM_SUSPENDED(x)	(((x) & MSR_TS_MASK) == MSR_TS_S)
+
+/* Reason codes describing kernel causes for transaction aborts.  By
+   convention, bit0 is copied to TEXASR[56] (IBM bit 7) which is set if
+   the failure is persistent.
+*/
+#define TM_CAUSE_RESCHED	0xfe
+#define TM_CAUSE_TLBI		0xfc
+#define TM_CAUSE_FAC_UNAV	0xfa
+#define TM_CAUSE_SYSCALL	0xf9 /* Persistent */
+#define TM_CAUSE_MISC		0xf6
+
 #if defined(CONFIG_PPC_BOOK3S_64)
 #define MSR_64BIT	MSR_SF
 
@@ -193,6 +216,10 @@
 #define SPRN_UAMOR	0x9d	/* User Authority Mask Override Register */
 #define SPRN_AMOR	0x15d	/* Authority Mask Override Register */
 #define SPRN_ACOP	0x1F	/* Available Coprocessor Register */
+#define SPRN_TFIAR	0x81	/* Transaction Failure Inst Addr   */
+#define SPRN_TEXASR	0x82	/* Transaction EXception & Summary */
+#define SPRN_TEXASRU	0x83	/* ''	   ''	   ''	 Upper 32  */
+#define SPRN_TFHAR	0x80	/* Transaction Failure Handler Addr */
 #define SPRN_CTRLF	0x088
 #define SPRN_CTRLT	0x098
 #define   CTRL_CT	0xc0000000	/* current thread */

commit ffe129ecd79779221fdb03305049ec8b5a8beb0f
Author: Bharat Bhushan <Bharat.Bhushan@freescale.com>
Date:   Tue Jan 15 22:20:42 2013 +0000

    KVM: PPC: booke: use vcpu reference from thread_struct
    
    Like other places, use thread_struct to get vcpu reference.
    
    Signed-off-by: Bharat Bhushan <bharat.bhushan@freescale.com>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 97d37278ea2d..11ae3d8ba3a2 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -919,8 +919,6 @@
 #define SPRN_SPRG_RSCRATCH_DBG	SPRN_SPRG9
 #define SPRN_SPRG_WSCRATCH_DBG	SPRN_SPRG9
 #endif
-#define SPRN_SPRG_RVCPU		SPRN_SPRG1
-#define SPRN_SPRG_WVCPU		SPRN_SPRG1
 #endif
 
 #ifdef CONFIG_8xx

commit 2468dcf641e4f3e1b0153e3e11ca20740b2f4ce8
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Thu Feb 7 15:46:58 2013 +0000

    powerpc: Add support for context switching the TAR register
    
    This patch adds support for enabling and context switching the Target
    Address Register in Power8. The TAR is a new special purpose register
    that can be used for computed branches with the bctar[l] (branch
    conditional to TAR) instruction in the same manner as the count and link
    registers.
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Signed-off-by: Matt Evans <matt@ozlabs.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 1f59fbb7b054..e09ac51961d7 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -237,6 +237,9 @@
 #define SPRN_HRMOR	0x139	/* Real mode offset register */
 #define SPRN_HSRR0	0x13A	/* Hypervisor Save/Restore 0 */
 #define SPRN_HSRR1	0x13B	/* Hypervisor Save/Restore 1 */
+#define SPRN_FSCR	0x099	/* Facility Status & Control Register */
+#define FSCR_TAR	(1<<8)	/* Enable Target Adress Register */
+#define SPRN_TAR	0x32f	/* Target Address Register */
 #define SPRN_LPCR	0x13E	/* LPAR Control Register */
 #define   LPCR_VPM0	(1ul << (63-0))
 #define   LPCR_VPM1	(1ul << (63-1))

commit 9422de3e953d0e60eb95f5430a9dd803eec1c6d7
Author: Michael Neuling <mikey@neuling.org>
Date:   Thu Dec 20 14:06:44 2012 +0000

    powerpc: Hardware breakpoints rewrite to handle non DABR breakpoint registers
    
    This is a rewrite so that we don't assume we are using the DABR throughout the
    code.  We now use the arch_hw_breakpoint to store the breakpoint in a generic
    manner in the thread_struct, rather than storing the raw DABR value.
    
    The ptrace GET/SET_DEBUGREG interface currently passes the raw DABR in from
    userspace.  We keep this functionality, so that future changes (like the POWER8
    DAWR), will still fake the DABR to userspace.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index d111beb1acdb..1f59fbb7b054 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -206,9 +206,6 @@
 #define   DAWRX_KERNEL	(1UL << 1)
 #define   DAWRX_HYP	(1UL << 2)
 #define SPRN_DABR	0x3F5	/* Data Address Breakpoint Register */
-#define   DABR_TRANSLATION	(1UL << 2)
-#define   DABR_DATA_WRITE	(1UL << 1)
-#define   DABR_DATA_READ	(1UL << 0)
 #define SPRN_DABR2	0x13D	/* e300 */
 #define SPRN_DABRX	0x3F7	/* Data Address Breakpoint Register Extension */
 #define   DABRX_USER	(1UL << 0)

commit a8190a59e7440a7e3f7c0889d72a13e157988b3c
Author: Michael Neuling <mikey@neuling.org>
Date:   Thu Dec 20 14:06:43 2012 +0000

    powerpc: Add DAWR/X SPR number definitions
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 1bdba54839b4..d111beb1acdb 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -200,6 +200,11 @@
 #define   CTRL_CT1	0x40000000	/* thread 1 */
 #define   CTRL_TE	0x00c00000	/* thread enable */
 #define   CTRL_RUNLATCH	0x1
+#define SPRN_DAWR	0xB4
+#define SPRN_DAWRX	0xBC
+#define   DAWRX_USER	(1UL << 0)
+#define   DAWRX_KERNEL	(1UL << 1)
+#define   DAWRX_HYP	(1UL << 2)
 #define SPRN_DABR	0x3F5	/* Data Address Breakpoint Register */
 #define   DABR_TRANSLATION	(1UL << 2)
 #define   DABR_DATA_WRITE	(1UL << 1)

commit 13e7a8e846c2ea38a552b986ea49332f965bbb7a
Author: Haren Myneni <haren@linux.vnet.ibm.com>
Date:   Thu Dec 6 21:50:32 2012 +0000

    powerpc: Macros for saving/restore PPR
    
    [PATCH 5/6] powerpc: Macros for saving/restore PPR
    
    Several macros are defined for saving and restore user defined PPR value.
    
    Signed-off-by: Haren Myneni <haren@us.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index af88486b0c23..1bdba54839b4 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -289,6 +289,7 @@
 #define SPRN_DBAT6U	0x23C	/* Data BAT 6 Upper Register */
 #define SPRN_DBAT7L	0x23F	/* Data BAT 7 Lower Register */
 #define SPRN_DBAT7U	0x23E	/* Data BAT 7 Upper Register */
+#define SPRN_PPR	0x380	/* SMT Thread status Register */
 
 #define SPRN_DEC	0x016		/* Decrement Register */
 #define SPRN_DER	0x095		/* Debug Enable Regsiter */

commit 42d02b81f265b77be39262666c888d50cb488fc5
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Wed Nov 14 18:49:44 2012 +0000

    powerpc: Define differences between doorbells on book3e and book3s
    
    There are a few key differences between doorbells on server compared
    with embedded that we care about on Linux, namely:
    
    - We have a new msgsndp instruction for directed privileged doorbells.
      msgsnd is used for directed hypervisor doorbells.
    - The tag we use in the instruction is the Thread Identification
      Register of the recipient thread (since server doorbells can only
      occur between threads within a single core), and is only 7 bits wide.
    - A new message type is introduced for server doorbells (none of the
      existing book3e message types are currently supported on book3s).
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Tested-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 3d5c9dc8917a..af88486b0c23 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -483,6 +483,7 @@
 #ifndef SPRN_PIR
 #define SPRN_PIR	0x3FF	/* Processor Identification Register */
 #endif
+#define SPRN_TIR	0x1BE	/* Thread Identification Register */
 #define SPRN_PTEHI	0x3D5	/* 981 7450 PTE HI word (S/W TLB load) */
 #define SPRN_PTELO	0x3D6	/* 982 7450 PTE LO word (S/W TLB load) */
 #define SPRN_PURR	0x135	/* Processor Utilization of Resources Reg */

commit 16e024f30ce96ef5fa651e2914e19d175a924cab
Merge: c36e0501ee91 376bddd34433
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 18 09:58:09 2012 -0800

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc
    
    Pull powerpc update from Benjamin Herrenschmidt:
     "The main highlight is probably some base POWER8 support.  There's more
      to come such as transactional memory support but that will wait for
      the next one.
    
      Overall it's pretty quiet, or rather I've been pretty poor at picking
      things up from patchwork and reviewing them this time around and Kumar
      no better on the FSL side it seems..."
    
    * 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc: (73 commits)
      powerpc+of: Rename and fix OF reconfig notifier error inject module
      powerpc: mpc5200: Add a3m071 board support
      powerpc/512x: don't compile any platform DIU code if the DIU is not enabled
      powerpc/mpc52xx: use module_platform_driver macro
      powerpc+of: Export of_reconfig_notifier_[register,unregister]
      powerpc/dma/raidengine: add raidengine device
      powerpc/iommu/fsl: Add PAMU bypass enable register to ccsr_guts struct
      powerpc/mpc85xx: Change spin table to cached memory
      powerpc/fsl-pci: Add PCI controller ATMU PM support
      powerpc/86xx: fsl_pcibios_fixup_bus requires CONFIG_PCI
      drivers/virt: the Freescale hypervisor driver doesn't need to check MSR[GS]
      powerpc/85xx: p1022ds: Use NULL instead of 0 for pointers
      powerpc: Disable relocation on exceptions when kexecing
      powerpc: Enable relocation on during exceptions at boot
      powerpc: Move get_longbusy_msecs into hvcall.h and remove duplicate function
      powerpc: Add wrappers to enable/disable relocation on exceptions
      powerpc: Add set_mode hcall
      powerpc: Setup relocation on exceptions for bare metal systems
      powerpc: Move initial mfspr LPCR out of __init_LPCR
      powerpc: Add relocation on exception vector handlers
      ...

commit 28c483b62fcd2589dadfc1250970f85aa0ab3df6
Author: Paul Mackerras <paulus@samba.org>
Date:   Sun Nov 4 18:16:46 2012 +0000

    KVM: PPC: Book3S PR: Fix VSX handling
    
    This fixes various issues in how we were handling the VSX registers
    that exist on POWER7 machines.  First, we were running off the end
    of the current->thread.fpr[] array.  Ultimately this was because the
    vcpu->arch.vsr[] array is sized to be able to store both the FP
    registers and the extra VSX registers (i.e. 64 entries), but PR KVM
    only uses it for the extra VSX registers (i.e. 32 entries).
    
    Secondly, calling load_up_vsx() from C code is a really bad idea,
    because it jumps to fast_exception_return at the end, rather than
    returning with a blr instruction.  This was causing it to jump off
    to a random location with random register contents, since it was using
    the largely uninitialized stack frame created by kvmppc_load_up_vsx.
    
    In fact, it isn't necessary to call either __giveup_vsx or load_up_vsx,
    since giveup_fpu and load_up_fpu handle the extra VSX registers as well
    as the standard FP registers on machines with VSX.  Also, since VSX
    instructions can access the VMX registers and the FP registers as well
    as the extra VSX registers, we have to load up the FP and VMX registers
    before we can turn on the MSR_VSX bit for the guest.  Conversely, if
    we save away any of the VSX or FP registers, we have to turn off MSR_VSX
    for the guest.
    
    To handle all this, it is more convenient for a single call to
    kvmppc_giveup_ext() to handle all the state saving that needs to be done,
    so we make it take a set of MSR bits rather than just one, and the switch
    statement becomes a series of if statements.  Similarly kvmppc_handle_ext
    needs to be able to load up more than one set of registers.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index d24c14163966..97d37278ea2d 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -518,6 +518,7 @@
 #define	  SRR1_WS_DEEPER	0x00020000 /* Some resources not maintained */
 #define	  SRR1_WS_DEEP		0x00010000 /* All resources maintained */
 #define   SRR1_PROGFPE		0x00100000 /* Floating Point Enabled */
+#define   SRR1_PROGILL		0x00080000 /* Illegal instruction */
 #define   SRR1_PROGPRIV		0x00040000 /* Privileged instruction */
 #define   SRR1_PROGTRAP		0x00020000 /* Trap */
 #define   SRR1_PROGADDR		0x00010000 /* SRR0 contains subsequent addr */

commit b0302722eec7c086a31de6e3d9789304ef21df7b
Author: Michael Neuling <mikey@neuling.org>
Date:   Fri Nov 2 16:41:58 2012 +1100

    powerpc: Setup relocation on exceptions for bare metal systems
    
    This turns on MMU on execptions via AIL field in the LPCR.
    
    Signed-off-by: Matt Evans <matt@ozlabs.org>
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 7b44a6e3e0f0..1b853f744f8b 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -249,6 +249,8 @@
 #define   LPCR_RMLS    0x1C000000      /* impl dependent rmo limit sel */
 #define	  LPCR_RMLS_SH	(63-37)
 #define   LPCR_ILE     0x02000000      /* !HV irqs set MSR:LE */
+#define   LPCR_AIL_0	0x00000000	/* MMU off exception offset 0x0 */
+#define   LPCR_AIL_3	0x01800000	/* MMU on exception offset 0xc00...4xxx */
 #define   LPCR_PECE	0x00007000	/* powersave exit cause enable */
 #define     LPCR_PECE0	0x00004000	/* ext. exceptions can cause exit */
 #define     LPCR_PECE1	0x00002000	/* decrementer can cause exit */

commit 71e184972456a8095657e80fd1470a3857b441a0
Author: Michael Neuling <mikey@neuling.org>
Date:   Tue Oct 30 19:34:15 2012 +0000

    powerpc: POWER8 cputable entry
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index d24c14163966..7b44a6e3e0f0 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1029,6 +1029,7 @@
 #define PVR_970MP	0x0044
 #define PVR_970GX	0x0045
 #define PVR_POWER7p	0x004A
+#define PVR_POWER8	0x004B
 #define PVR_BE		0x0070
 #define PVR_PA6T	0x0090
 

commit e6878835ac4794f25385522d29c634b7bbb7cca9
Author: sukadev@linux.vnet.ibm.com <sukadev@linux.vnet.ibm.com>
Date:   Tue Sep 18 20:56:11 2012 +0000

    powerpc/perf: Sample only if SIAR-Valid bit is set in P7+
    
    powerpc/perf: Sample only if SIAR-Valid bit is set in P7+
    
    On POWER7+ two new bits (mmcra[35] and mmcra[36]) indicate whether the
    contents of SIAR and SDAR are valid.
    
    For marked instructions on P7+, we must save the contents of SIAR and
    SDAR registers only if these new bits are set.
    
    This code/check for the SIAR-Valid bit is specific to P7+, so rather than
    waste a CPU-feature bit use the PVR flag.
    
    Note that Carl Love proposed a similar change for oprofile:
    
            https://lkml.org/lkml/2012/6/22/309
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index a1096fb62816..d24c14163966 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -606,6 +606,10 @@
 #define   POWER6_MMCRA_SIPR   0x0000020000000000ULL
 #define   POWER6_MMCRA_THRM	0x00000020UL
 #define   POWER6_MMCRA_OTHER	0x0000000EUL
+
+#define   POWER7P_MMCRA_SIAR_VALID 0x10000000	/* P7+ SIAR contents valid */
+#define   POWER7P_MMCRA_SDAR_VALID 0x08000000	/* P7+ SDAR contents valid */
+
 #define SPRN_PMC1	787
 #define SPRN_PMC2	788
 #define SPRN_PMC3	789

commit b92a66a65cb4480774066d9a3080c77eb34b7232
Author: Michael Neuling <mikey@neuling.org>
Date:   Mon Sep 10 00:35:26 2012 +0000

    powerpc: Add denormalisation exception handling for POWER6/7
    
    On POWER6 and POWER7 if the input operand to an instruction is a
    denormalised single precision binary floating point value we can take
    a denormalisation exception where it's expected that the hypervisor
    (HV=1) will fix up the inputs before the instruction is run.
    
    This adds code to handle this denormalisation exception for POWER6 and
    POWER7.
    
    It also add a CONFIG_PPC_DENORMALISATION option and sets it in
    pseries/ppc64_defconfig.
    
    This is useful on bare metal systems only.  Based on patch from Milton
    Miller.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 121a90bbf778..a1096fb62816 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -524,6 +524,7 @@
 
 #define SPRN_HSRR0	0x13A	/* Save/Restore Register 0 */
 #define SPRN_HSRR1	0x13B	/* Save/Restore Register 1 */
+#define   HSRR1_DENORM		0x00100000 /* Denorm exception */
 
 #define SPRN_TBCTL	0x35f	/* PA6T Timebase control register */
 #define   TBCTL_FREEZE		0x0000000000000000ull /* Freeze all tbs */

commit 4474ef055c5d8cb8eaf002d69e49af71e3aa3a88
Author: Michael Neuling <mikey@neuling.org>
Date:   Thu Sep 6 21:24:56 2012 +0000

    powerpc: Rework set_dabr so it can take a DABRX value as well
    
    Rework set_dabr to take a DABRX value as well.
    
    Both the pseries and PS3 hypervisors do some checks on the DABRX
    values that are passed in the hcall.  This patch stops bogus values
    from being passed to hypervisor.  Also, in the case where we are
    clearing the breakpoint, where DABR and DABRX are zero, we modify the
    DABRX value to make it valid so that the hcall won't fail.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index ad400a535d23..121a90bbf778 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -208,6 +208,9 @@
 #define SPRN_DABRX	0x3F7	/* Data Address Breakpoint Register Extension */
 #define   DABRX_USER	(1UL << 0)
 #define   DABRX_KERNEL	(1UL << 1)
+#define   DABRX_HYP	(1UL << 2)
+#define   DABRX_BTI	(1UL << 3)
+#define   DABRX_ALL     (DABRX_BTI | DABRX_HYP | DABRX_KERNEL | DABRX_USER)
 #define SPRN_DAR	0x013	/* Data Address Register */
 #define SPRN_DBCR	0x136	/* e300 Data Breakpoint Control Reg */
 #define SPRN_DSISR	0x012	/* Data Storage Interrupt Status Register */

commit 22d8ce887991f8f70a68fb68972f187ec79d44b7
Author: sukadev@linux.vnet.ibm.com <sukadev@linux.vnet.ibm.com>
Date:   Mon Jul 16 11:22:02 2012 +0000

    powerpc: Define Power7+ PV constant PV_POWER7p
    
    This definition will be used by subsequent perf and oprofile patches
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index a391244c18e1..ad400a535d23 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1020,6 +1020,7 @@
 #define PVR_630p	0x0041
 #define PVR_970MP	0x0044
 #define PVR_970GX	0x0045
+#define PVR_POWER7p	0x004A
 #define PVR_BE		0x0070
 #define PVR_PA6T	0x0090
 

commit 8b64a9dfb091f1eca8b7e58da82f1e7d1d5fe0ad
Author: Mihai Caraman <mihai.caraman@freescale.com>
Date:   Mon Aug 6 03:27:07 2012 +0000

    powerpc/booke64: Use SPRG0/3 scratch for bolted TLB miss & crit int
    
    Embedded.Hypervisor category defines GSPRG0..3 physical registers for guests.
    Avoid SPRG4-7 usage as scratch in host exception handlers, otherwise guest
    SPRG4-7 registers will be clobbered.
    For bolted TLB miss exception handlers, which is the version currently
    supported by KVM, use SPRN_SPRG_GEN_SCRATCH aka SPRG0 instead of
    SPRN_SPRG_TLB_SCRATCH aka SPRG6. Keep using TLB PACA slots to fit in one
    64-byte cache line.
    For critical exception handlers use SPRG3 instead of SPRG7. Provide a routine
    to store and restore user-visible SPRGs. This will be subsequently used
    to restore VDSO information in SPRG3. Add EX_R13 to paca slots to free up
    SPRG3 and change the critical exception epilog to use it.
    
    Signed-off-by: Mihai Caraman <mihai.caraman@freescale.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c195bf0e6241..a391244c18e1 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -761,7 +761,8 @@
  * 64-bit embedded
  *	- SPRG0 generic exception scratch
  *	- SPRG2 TLB exception stack
- *	- SPRG3 CPU and NUMA node for VDSO getcpu (user visible)
+ *	- SPRG3 critical exception scratch and
+ *        CPU and NUMA node for VDSO getcpu (user visible)
  *	- SPRG4 unused (user visible)
  *	- SPRG6 TLB miss scratch (user visible, sorry !)
  *	- SPRG7 critical exception scratch
@@ -858,7 +859,7 @@
 
 #ifdef CONFIG_PPC_BOOK3E_64
 #define SPRN_SPRG_MC_SCRATCH	SPRN_SPRG8
-#define SPRN_SPRG_CRIT_SCRATCH	SPRN_SPRG7
+#define SPRN_SPRG_CRIT_SCRATCH	SPRN_SPRG3
 #define SPRN_SPRG_DBG_SCRATCH	SPRN_SPRG9
 #define SPRN_SPRG_TLB_EXFRAME	SPRN_SPRG2
 #define SPRN_SPRG_TLB_SCRATCH	SPRN_SPRG6

commit 5473eb1c07009956be5f4df65d51f8e24d8eb1de
Author: Mihai Caraman <mihai.caraman@freescale.com>
Date:   Mon Aug 6 03:27:04 2012 +0000

    powerpc/booke64: Use GSRR registers in Guest Doorbell interrupts
    
    Guest Doorbell interrupts use guest save and restore registers. Add a new
    Guest Doorbell exception type to accommodate GSRR0/1 SPRs usage in exception
    prolog and fix the exception handler.
    
    Signed-off-by: Mihai Caraman <mihai.caraman@freescale.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 43bb15fc899b..c195bf0e6241 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -863,6 +863,7 @@
 #define SPRN_SPRG_TLB_EXFRAME	SPRN_SPRG2
 #define SPRN_SPRG_TLB_SCRATCH	SPRN_SPRG6
 #define SPRN_SPRG_GEN_SCRATCH	SPRN_SPRG0
+#define SPRN_SPRG_GDBELL_SCRATCH SPRN_SPRG_GEN_SCRATCH
 
 #define SET_PACA(rX)	mtspr	SPRN_SPRG_PACA,rX
 #define GET_PACA(rX)	mfspr	rX,SPRN_SPRG_PACA

commit d3dbeef657fdc9e870e0b01f811bbb906af052f8
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Sun Aug 19 21:44:01 2012 +0000

    powerpc: Rename 64-bit PVR constants to PVR_foo
    
    We have an old FIXME in reg.h which points out that we should standardise
    on PVR_foo for our PVR #defines. Currently we use PVR_ on 32-bit and PV_
    on 64-bit.
    
    So do that rename and remove the FIXME.
    
    Seeing as we're touching all but one usage of __is_processor(), rename it
    to something less ugly and more indicative of what it does, which is
    simply to check the PVR version.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 638608677e2a..43bb15fc899b 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -937,7 +937,7 @@
 #define PVR_VER(pvr)	(((pvr) >>  16) & 0xFFFF)	/* Version field */
 #define PVR_REV(pvr)	(((pvr) >>   0) & 0xFFFF)	/* Revison field */
 
-#define __is_processor(pv)	(PVR_VER(mfspr(SPRN_PVR)) == (pv))
+#define pvr_version_is(pvr)	(PVR_VER(mfspr(SPRN_PVR)) == (pvr))
 
 /*
  * IBM has further subdivided the standard PowerPC 16-bit version and
@@ -1002,25 +1002,24 @@
 #define PVR_476_ISS	0x00052000
 
 /* 64-bit processors */
-/* XXX the prefix should be PVR_, we'll do a global sweep to fix it one day */
-#define PV_NORTHSTAR	0x0033
-#define PV_PULSAR	0x0034
-#define PV_POWER4	0x0035
-#define PV_ICESTAR	0x0036
-#define PV_SSTAR	0x0037
-#define PV_POWER4p	0x0038
-#define PV_970		0x0039
-#define PV_POWER5	0x003A
-#define PV_POWER5p	0x003B
-#define PV_970FX	0x003C
-#define PV_POWER6	0x003E
-#define PV_POWER7	0x003F
-#define PV_630		0x0040
-#define PV_630p	0x0041
-#define PV_970MP	0x0044
-#define PV_970GX	0x0045
-#define PV_BE		0x0070
-#define PV_PA6T		0x0090
+#define PVR_NORTHSTAR	0x0033
+#define PVR_PULSAR	0x0034
+#define PVR_POWER4	0x0035
+#define PVR_ICESTAR	0x0036
+#define PVR_SSTAR	0x0037
+#define PVR_POWER4p	0x0038
+#define PVR_970		0x0039
+#define PVR_POWER5	0x003A
+#define PVR_POWER5p	0x003B
+#define PVR_970FX	0x003C
+#define PVR_POWER6	0x003E
+#define PVR_POWER7	0x003F
+#define PVR_630		0x0040
+#define PVR_630p	0x0041
+#define PVR_970MP	0x0044
+#define PVR_970GX	0x0045
+#define PVR_BE		0x0070
+#define PVR_PA6T	0x0090
 
 /* Macros for setting and retrieving special purpose registers */
 #ifndef __ASSEMBLY__

commit b416c9a10baae6a177b4f9ee858b8d309542fbef
Author: Tiejun Chen <tiejun.chen@windriver.com>
Date:   Wed Jul 11 14:22:46 2012 +1000

    powerpc: Add "memory" attribute for mfmsr()
    
    Add "memory" attribute in inline assembly language as a compiler
    barrier to make sure 4.6.x GCC don't reorder mfmsr().
    
    Signed-off-by: Tiejun Chen <tiejun.chen@windriver.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    CC: stable@vger.kernel.org

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 2baeb7c8764f..638608677e2a 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1025,7 +1025,8 @@
 /* Macros for setting and retrieving special purpose registers */
 #ifndef __ASSEMBLY__
 #define mfmsr()		({unsigned long rval; \
-			asm volatile("mfmsr %0" : "=r" (rval)); rval;})
+			asm volatile("mfmsr %0" : "=r" (rval) : \
+						: "memory"); rval;})
 #ifdef CONFIG_PPC_BOOK3S_64
 #define __mtmsrd(v, l)	asm volatile("mtmsrd %0," __stringify(l) \
 				     : : "r" (v) : "memory")

commit 18ad51dd342a7eb09dbcd059d0b451b616d4dafc
Author: Anton Blanchard <anton@samba.org>
Date:   Wed Jul 4 20:37:11 2012 +0000

    powerpc: Add VDSO version of getcpu
    
    We have a request for a fast method of getting CPU and NUMA node IDs
    from userspace. This patch implements a getcpu VDSO function,
    similar to x86.
    
    Ben suggested we use SPRG3 which is userspace readable. SPRG3 can be
    modified by a KVM guest, so we save the SPRG3 value in the paca and
    restore it when transitioning from the guest to the host.
    
    I have a glibc patch that implements sched_getcpu on top of this.
    Testing on a POWER7:
    
    baseline: 538 cycles
    vdso:      30 cycles
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index f0cb7f461b9d..2baeb7c8764f 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -491,6 +491,7 @@
 #define SPRN_SPRG1	0x111	/* Special Purpose Register General 1 */
 #define SPRN_SPRG2	0x112	/* Special Purpose Register General 2 */
 #define SPRN_SPRG3	0x113	/* Special Purpose Register General 3 */
+#define SPRN_USPRG3	0x103	/* SPRG3 userspace read */
 #define SPRN_SPRG4	0x114	/* Special Purpose Register General 4 */
 #define SPRN_SPRG5	0x115	/* Special Purpose Register General 5 */
 #define SPRN_SPRG6	0x116	/* Special Purpose Register General 6 */
@@ -753,14 +754,14 @@
  * 64-bit server:
  *	- SPRG0 unused (reserved for HV on Power4)
  *	- SPRG2 scratch for exception vectors
- *	- SPRG3 unused (user visible)
+ *	- SPRG3 CPU and NUMA node for VDSO getcpu (user visible)
  *      - HSPRG0 stores PACA in HV mode
  *      - HSPRG1 scratch for "HV" exceptions
  *
  * 64-bit embedded
  *	- SPRG0 generic exception scratch
  *	- SPRG2 TLB exception stack
- *	- SPRG3 unused (user visible)
+ *	- SPRG3 CPU and NUMA node for VDSO getcpu (user visible)
  *	- SPRG4 unused (user visible)
  *	- SPRG6 TLB miss scratch (user visible, sorry !)
  *	- SPRG7 critical exception scratch

commit d30f6e480055e5be12e7a03fd11ea912a451daa5
Author: Scott Wood <scottwood@freescale.com>
Date:   Tue Dec 20 15:34:43 2011 +0000

    KVM: PPC: booke: category E.HV (GS-mode) support
    
    Chips such as e500mc that implement category E.HV in Power ISA 2.06
    provide hardware virtualization features, including a new MSR mode for
    guest state.  The guest OS can perform many operations without trapping
    into the hypervisor, including transitions to and from guest userspace.
    
    Since we can use SRR1[GS] to reliably tell whether an exception came from
    guest state, instead of messing around with IVPR, we use DO_KVM similarly
    to book3s.
    
    Current issues include:
     - Machine checks from guest state are not routed to the host handler.
     - The guest can cause a host oops by executing an emulated instruction
       in a page that lacks read permission.  Existing e500/4xx support has
       the same problem.
    
    Includes work by Ashish Kalra <Ashish.Kalra@freescale.com>,
    Varun Sethi <Varun.Sethi@freescale.com>, and
    Liu Yu <yu.liu@freescale.com>.
    
    Signed-off-by: Scott Wood <scottwood@freescale.com>
    [agraf: remove pt_regs usage]
    Signed-off-by: Alexander Graf <agraf@suse.de>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 9d7f0fb69028..f0cb7f461b9d 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -257,7 +257,9 @@
 #define   LPCR_LPES_SH	2
 #define   LPCR_RMI     0x00000002      /* real mode is cache inhibit */
 #define   LPCR_HDICE   0x00000001      /* Hyp Decr enable (HV,PR,EE) */
+#ifndef SPRN_LPID
 #define SPRN_LPID	0x13F	/* Logical Partition Identifier */
+#endif
 #define   LPID_RSVD	0x3ff		/* Reserved LPID for partn switching */
 #define	SPRN_HMER	0x150	/* Hardware m? error recovery */
 #define	SPRN_HMEER	0x151	/* Hardware m? enable error recovery */

commit 2e7580b0e75d771d93e24e681031a165b1d31071
Merge: d25413efa953 cf9eeac46350
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 28 14:35:31 2012 -0700

    Merge branch 'kvm-updates/3.4' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull kvm updates from Avi Kivity:
     "Changes include timekeeping improvements, support for assigning host
      PCI devices that share interrupt lines, s390 user-controlled guests, a
      large ppc update, and random fixes."
    
    This is with the sign-off's fixed, hopefully next merge window we won't
    have rebased commits.
    
    * 'kvm-updates/3.4' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (130 commits)
      KVM: Convert intx_mask_lock to spin lock
      KVM: x86: fix kvm_write_tsc() TSC matching thinko
      x86: kvmclock: abstract save/restore sched_clock_state
      KVM: nVMX: Fix erroneous exception bitmap check
      KVM: Ignore the writes to MSR_K7_HWCR(3)
      KVM: MMU: make use of ->root_level in reset_rsvds_bits_mask
      KVM: PMU: add proper support for fixed counter 2
      KVM: PMU: Fix raw event check
      KVM: PMU: warn when pin control is set in eventsel msr
      KVM: VMX: Fix delayed load of shared MSRs
      KVM: use correct tlbs dirty type in cmpxchg
      KVM: Allow host IRQ sharing for assigned PCI 2.3 devices
      KVM: Ensure all vcpus are consistent with in-kernel irqchip settings
      KVM: x86 emulator: Allow PM/VM86 switch during task switch
      KVM: SVM: Fix CPL updates
      KVM: x86 emulator: VM86 segments must have DPL 3
      KVM: x86 emulator: Fix task switch privilege checks
      arch/powerpc/kvm/book3s_hv.c: included linux/sched.h twice
      KVM: x86 emulator: correctly mask pmc index bits in RDPMC instruction emulation
      KVM: mmu_notifier: Flush TLBs before releasing mmu_lock
      ...

commit fe1952fc0afb9a2e4c79f103c08aef5d13db1873
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Mar 1 12:45:27 2012 +1100

    powerpc: Rework runlatch code
    
    This moves the inlines into system.h and changes the runlatch
    code to use the thread local flags (non-atomic) rather than
    the TIF flags (atomic) to keep track of the latch state.
    
    The code to turn it back on in an asynchronous interrupt is
    now simplified and partially inlined.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 7fdc2c0b7fa0..b1a215eabef6 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1079,30 +1079,12 @@
 
 #define proc_trap()	asm volatile("trap")
 
-#ifdef CONFIG_PPC64
-
-extern void ppc64_runlatch_on(void);
-extern void __ppc64_runlatch_off(void);
-
-#define ppc64_runlatch_off()					\
-	do {							\
-		if (cpu_has_feature(CPU_FTR_CTRL) &&		\
-		    test_thread_flag(TIF_RUNLATCH))		\
-			__ppc64_runlatch_off();			\
-	} while (0)
+#define __get_SP()	({unsigned long sp; \
+			asm volatile("mr %0,1": "=r" (sp)); sp;})
 
 extern unsigned long scom970_read(unsigned int address);
 extern void scom970_write(unsigned int address, unsigned long value);
 
-#else
-#define ppc64_runlatch_on()
-#define ppc64_runlatch_off()
-
-#endif /* CONFIG_PPC64 */
-
-#define __get_SP()	({unsigned long sp; \
-			asm volatile("mr %0,1": "=r" (sp)); sp;})
-
 struct pt_regs;
 
 extern void ppc_save_regs(struct pt_regs *regs);

commit 342d3db763f2621ed4546ebf8f6c61cb29d7fbdb
Author: Paul Mackerras <paulus@samba.org>
Date:   Mon Dec 12 12:38:05 2011 +0000

    KVM: PPC: Implement MMU notifiers for Book3S HV guests
    
    This adds the infrastructure to enable us to page out pages underneath
    a Book3S HV guest, on processors that support virtualized partition
    memory, that is, POWER7.  Instead of pinning all the guest's pages,
    we now look in the host userspace Linux page tables to find the
    mapping for a given guest page.  Then, if the userspace Linux PTE
    gets invalidated, kvm_unmap_hva() gets called for that address, and
    we replace all the guest HPTEs that refer to that page with absent
    HPTEs, i.e. ones with the valid bit clear and the HPTE_V_ABSENT bit
    set, which will cause an HDSI when the guest tries to access them.
    Finally, the page fault handler is extended to reinstantiate the
    guest HPTE when the guest tries to access a page which has been paged
    out.
    
    Since we can't intercept the guest DSI and ISI interrupts on PPC970,
    we still have to pin all the guest pages on PPC970.  We have a new flag,
    kvm->arch.using_mmu_notifiers, that indicates whether we can page
    guest pages out.  If it is not set, the MMU notifier callbacks do
    nothing and everything operates as before.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 16efb3151c20..35c9309bf038 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -495,6 +495,9 @@
 #define SPRN_SPRG7	0x117	/* Special Purpose Register General 7 */
 #define SPRN_SRR0	0x01A	/* Save/Restore Register 0 */
 #define SPRN_SRR1	0x01B	/* Save/Restore Register 1 */
+#define   SRR1_ISI_NOPT		0x40000000 /* ISI: Not found in hash */
+#define   SRR1_ISI_N_OR_G	0x10000000 /* ISI: Access is no-exec or G */
+#define   SRR1_ISI_PROT		0x08000000 /* ISI: Other protection fault */
 #define   SRR1_WAKEMASK		0x00380000 /* reason for wakeup */
 #define   SRR1_WAKESYSERR	0x00300000 /* System error */
 #define   SRR1_WAKEEE		0x00200000 /* External interrupt */

commit 697d3899dcb4bcd918d060a92db57b794e56b077
Author: Paul Mackerras <paulus@samba.org>
Date:   Mon Dec 12 12:36:37 2011 +0000

    KVM: PPC: Implement MMIO emulation support for Book3S HV guests
    
    This provides the low-level support for MMIO emulation in Book3S HV
    guests.  When the guest tries to map a page which is not covered by
    any memslot, that page is taken to be an MMIO emulation page.  Instead
    of inserting a valid HPTE, we insert an HPTE that has the valid bit
    clear but another hypervisor software-use bit set, which we call
    HPTE_V_ABSENT, to indicate that this is an absent page.  An
    absent page is treated much like a valid page as far as guest hcalls
    (H_ENTER, H_REMOVE, H_READ etc.) are concerned, except of course that
    an absent HPTE doesn't need to be invalidated with tlbie since it
    was never valid as far as the hardware is concerned.
    
    When the guest accesses a page for which there is an absent HPTE, it
    will take a hypervisor data storage interrupt (HDSI) since we now set
    the VPM1 bit in the LPCR.  Our HDSI handler for HPTE-not-present faults
    looks up the hash table and if it finds an absent HPTE mapping the
    requested virtual address, will switch to kernel mode and handle the
    fault in kvmppc_book3s_hv_page_fault(), which at present just calls
    kvmppc_hv_emulate_mmio() to set up the MMIO emulation.
    
    This is based on an earlier patch by Benjamin Herrenschmidt, but since
    heavily reworked.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 64447f6c049a..16efb3151c20 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -216,6 +216,7 @@
 #define   DSISR_ISSTORE		0x02000000	/* access was a store */
 #define   DSISR_DABRMATCH	0x00400000	/* hit data breakpoint */
 #define   DSISR_NOSEGMENT	0x00200000	/* STAB/SLB miss */
+#define   DSISR_KEYFAULT	0x00200000	/* Key fault */
 #define SPRN_TBRL	0x10C	/* Time Base Read Lower Register (user, R/O) */
 #define SPRN_TBRU	0x10D	/* Time Base Read Upper Register (user, R/O) */
 #define SPRN_TBWL	0x11C	/* Time Base Lower Register (super, R/W) */

commit da9d1d7f2875cc8c1ffbce8f3501d0b33f4e7a4d
Author: Paul Mackerras <paulus@samba.org>
Date:   Mon Dec 12 12:31:41 2011 +0000

    KVM: PPC: Allow use of small pages to back Book3S HV guests
    
    This relaxes the requirement that the guest memory be provided as
    16MB huge pages, allowing it to be provided as normal memory, i.e.
    in pages of PAGE_SIZE bytes (4k or 64k).  To allow this, we index
    the kvm->arch.slot_phys[] arrays with a small page index, even if
    huge pages are being used, and use the low-order 5 bits of each
    entry to store the order of the enclosing page with respect to
    normal pages, i.e. log_2(enclosing_page_size / PAGE_SIZE).
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 7fdc2c0b7fa0..64447f6c049a 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -237,6 +237,7 @@
 #define   LPCR_ISL	(1ul << (63-2))
 #define   LPCR_VC_SH	(63-2)
 #define   LPCR_DPFD_SH	(63-11)
+#define   LPCR_VRMASD	(0x1ful << (63-16))
 #define   LPCR_VRMA_L	(1ul << (63-12))
 #define   LPCR_VRMA_LP0	(1ul << (63-15))
 #define   LPCR_VRMA_LP1	(1ul << (63-16))

commit df777bd39a266637d1765d48043493489418e75b
Author: Tony Breeds <tony@bakeyournoodle.com>
Date:   Wed Nov 30 21:39:23 2011 +0000

    powerpc/476fpe: Add 476fpe SoC code
    
    Based on original work by David 'Shaggy' Kleikamp.
    
    Signed-off-by: Tony Breeds <tony@bakeyournoodle.com>
    Signed-off-by: Josh Boyer <jwboyer@gmail.com>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 559da199edb5..7fdc2c0b7fa0 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -951,6 +951,7 @@
 #define PVR_403GCX	0x00201400
 #define PVR_405GP	0x40110000
 #define PVR_476		0x11a52000
+#define PVR_476FPE	0x7ff50000
 #define PVR_STB03XXX	0x40310000
 #define PVR_NP405H	0x41410000
 #define PVR_NP405L	0x41610000

commit 501d238633a3f9869f4e777b3b281ca7660b7156
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Wed Jul 27 07:27:21 2011 +0000

    ppc: Remove duplicate definition of PV_POWER7
    
    One definition of PV_POWER7 seems enough to me.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 9561e6016ec6..559da199edb5 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1003,7 +1003,6 @@
 #define PV_970		0x0039
 #define PV_POWER5	0x003A
 #define PV_POWER5p	0x003B
-#define PV_POWER7	0x003F
 #define PV_970FX	0x003C
 #define PV_POWER6	0x003E
 #define PV_POWER7	0x003F

commit 326ed6a9bcf8d451a6d714d10c8b0f40941a3ed3
Author: Scott Wood <scottwood@freescale.com>
Date:   Mon Jul 25 11:02:11 2011 +0000

    powerpc: mtspr/mtmsr should take an unsigned long
    
    Add a cast in case the caller passes in a different type, as it would
    if mtspr/mtmsr were functions.
    
    Previously, if a 64-bit type was passed in on 32-bit, GCC would bind the
    constraint to a pair of registers, and would substitute the first register
    in the pair in the asm code.  This corresponds to the upper half of the
    64-bit register, which is generally not the desired behavior.
    
    Signed-off-by: Scott Wood <scottwood@freescale.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index e8aaf6fce38b..9561e6016ec6 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -1024,13 +1024,16 @@
 #define mtmsrd(v)	__mtmsrd((v), 0)
 #define mtmsr(v)	mtmsrd(v)
 #else
-#define mtmsr(v)	asm volatile("mtmsr %0" : : "r" (v) : "memory")
+#define mtmsr(v)	asm volatile("mtmsr %0" : \
+				     : "r" ((unsigned long)(v)) \
+				     : "memory")
 #endif
 
 #define mfspr(rn)	({unsigned long rval; \
 			asm volatile("mfspr %0," __stringify(rn) \
 				: "=r" (rval)); rval;})
-#define mtspr(rn, v)	asm volatile("mtspr " __stringify(rn) ",%0" : : "r" (v)\
+#define mtspr(rn, v)	asm volatile("mtspr " __stringify(rn) ",%0" : \
+				     : "r" ((unsigned long)(v)) \
 				     : "memory")
 
 #ifdef __powerpc64__

commit 184475029a724b6b900d88fc3a5f462a6107d5af
Merge: 3b76eefe0f97 f1f4ee01c0d3
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 25 22:59:39 2011 -0700

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc
    
    * 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc: (99 commits)
      drivers/virt: add missing linux/interrupt.h to fsl_hypervisor.c
      powerpc/85xx: fix mpic configuration in CAMP mode
      powerpc: Copy back TIF flags on return from softirq stack
      powerpc/64: Make server perfmon only built on ppc64 server devices
      powerpc/pseries: Fix hvc_vio.c build due to recent changes
      powerpc: Exporting boot_cpuid_phys
      powerpc: Add CFAR to oops output
      hvc_console: Add kdb support
      powerpc/pseries: Fix hvterm_raw_get_chars to accept < 16 chars, fixing xmon
      powerpc/irq: Quieten irq mapping printks
      powerpc: Enable lockup and hung task detectors in pseries and ppc64 defeconfigs
      powerpc: Add mpt2sas driver to pseries and ppc64 defconfig
      powerpc: Disable IRQs off tracer in ppc64 defconfig
      powerpc: Sync pseries and ppc64 defconfigs
      powerpc/pseries/hvconsole: Fix dropped console output
      hvc_console: Improve tty/console put_chars handling
      powerpc/kdump: Fix timeout in crash_kexec_wait_realmode
      powerpc/mm: Fix output of total_ram.
      powerpc/cpufreq: Add cpufreq driver for Momentum Maple boards
      powerpc: Correct annotations of pmu registration functions
      ...
    
    Fix up trivial Kconfig/Makefile conflicts in arch/powerpc, drivers, and
    drivers/cpufreq

commit 969391c58a4efb8411d6881179945f425ad9cbb5
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Jun 29 00:26:11 2011 +0000

    powerpc, KVM: Split HVMODE_206 cpu feature bit into separate HV and architecture bits
    
    This replaces the single CPU_FTR_HVMODE_206 bit with two bits, one to
    indicate that we have a usable hypervisor mode, and another to indicate
    that the processor conforms to PowerISA version 2.06.  We also add
    another bit to indicate that the processor conforms to ISA version 2.01
    and set that for PPC970 and derivatives.
    
    Some PPC970 chips (specifically those in Apple machines) have a
    hypervisor mode in that MSR[HV] is always 1, but the hypervisor mode
    is not useful in the sense that there is no way to run any code in
    supervisor mode (HV=0 PR=0).  On these processors, the LPES0 and LPES1
    bits in HID4 are always 0, and we use that as a way of detecting that
    hypervisor mode is not useful.
    
    Where we have a feature section in assembly code around code that
    only applies on POWER7 in hypervisor mode, we use a construct like
    
    END_FTR_SECTION_IFSET(CPU_FTR_HVMODE | CPU_FTR_ARCH_206)
    
    The definition of END_FTR_SECTION_IFSET is such that the code will
    be enabled (not overwritten with nops) only if all bits in the
    provided mask are set.
    
    Note that the CPU feature check in __tlbie() only needs to check the
    ARCH_206 bit, not the HVMODE bit, because __tlbie() can only get called
    if we are running bare-metal, i.e. in hypervisor mode.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 20a053c14270..ddbe57ae8584 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -307,6 +307,7 @@
 #define SPRN_HASH1	0x3D2		/* Primary Hash Address Register */
 #define SPRN_HASH2	0x3D3		/* Secondary Hash Address Resgister */
 #define SPRN_HID0	0x3F0		/* Hardware Implementation Register 0 */
+#define HID0_HDICE_SH	(63 - 23)	/* 970 HDEC interrupt enable */
 #define HID0_EMCP	(1<<31)		/* Enable Machine Check pin */
 #define HID0_EBA	(1<<29)		/* Enable Bus Address Parity */
 #define HID0_EBD	(1<<28)		/* Enable Bus Data Parity */
@@ -362,6 +363,13 @@
 #define SPRN_IABR2	0x3FA		/* 83xx */
 #define SPRN_IBCR	0x135		/* 83xx Insn Breakpoint Control Reg */
 #define SPRN_HID4	0x3F4		/* 970 HID4 */
+#define  HID4_LPES0	 (1ul << (63-0)) /* LPAR env. sel. bit 0 */
+#define	 HID4_RMLS2_SH	 (63 - 2)	/* Real mode limit bottom 2 bits */
+#define	 HID4_LPID5_SH	 (63 - 6)	/* partition ID bottom 4 bits */
+#define	 HID4_RMOR_SH	 (63 - 22)	/* real mode offset (16 bits) */
+#define  HID4_LPES1	 (1 << (63-57))	/* LPAR env. sel. bit 1 */
+#define  HID4_RMLS0_SH	 (63 - 58)	/* Real mode limit top bit */
+#define	 HID4_LPID1_SH	 0		/* partition ID top 2 bits */
 #define SPRN_HID4_GEKKO	0x3F3		/* Gekko HID4 */
 #define SPRN_HID5	0x3F6		/* 970 HID5 */
 #define SPRN_HID6	0x3F9	/* BE HID 6 */
@@ -811,28 +819,28 @@
 	mfspr	rX,SPRN_SPRG_PACA;			\
 	FTR_SECTION_ELSE_NESTED(66);			\
 	mfspr	rX,SPRN_SPRG_HPACA;			\
-	ALT_FTR_SECTION_END_NESTED_IFCLR(CPU_FTR_HVMODE_206, 66)
+	ALT_FTR_SECTION_END_NESTED_IFCLR(CPU_FTR_HVMODE, 66)
 
 #define SET_PACA(rX)					\
 	BEGIN_FTR_SECTION_NESTED(66);			\
 	mtspr	SPRN_SPRG_PACA,rX;			\
 	FTR_SECTION_ELSE_NESTED(66);			\
 	mtspr	SPRN_SPRG_HPACA,rX;			\
-	ALT_FTR_SECTION_END_NESTED_IFCLR(CPU_FTR_HVMODE_206, 66)
+	ALT_FTR_SECTION_END_NESTED_IFCLR(CPU_FTR_HVMODE, 66)
 
 #define GET_SCRATCH0(rX)				\
 	BEGIN_FTR_SECTION_NESTED(66);			\
 	mfspr	rX,SPRN_SPRG_SCRATCH0;			\
 	FTR_SECTION_ELSE_NESTED(66);			\
 	mfspr	rX,SPRN_SPRG_HSCRATCH0;			\
-	ALT_FTR_SECTION_END_NESTED_IFCLR(CPU_FTR_HVMODE_206, 66)
+	ALT_FTR_SECTION_END_NESTED_IFCLR(CPU_FTR_HVMODE, 66)
 
 #define SET_SCRATCH0(rX)				\
 	BEGIN_FTR_SECTION_NESTED(66);			\
 	mtspr	SPRN_SPRG_SCRATCH0,rX;			\
 	FTR_SECTION_ELSE_NESTED(66);			\
 	mtspr	SPRN_SPRG_HSCRATCH0,rX;			\
-	ALT_FTR_SECTION_END_NESTED_IFCLR(CPU_FTR_HVMODE_206, 66)
+	ALT_FTR_SECTION_END_NESTED_IFCLR(CPU_FTR_HVMODE, 66)
 
 #else /* CONFIG_PPC_BOOK3S_64 */
 #define GET_SCRATCH0(rX)	mfspr	rX,SPRN_SPRG_SCRATCH0

commit aa04b4cc5be64b4fb9ef4e0fdf2418e2f4737fb2
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Jun 29 00:25:44 2011 +0000

    KVM: PPC: Allocate RMAs (Real Mode Areas) at boot for use by guests
    
    This adds infrastructure which will be needed to allow book3s_hv KVM to
    run on older POWER processors, including PPC970, which don't support
    the Virtual Real Mode Area (VRMA) facility, but only the Real Mode
    Offset (RMO) facility.  These processors require a physically
    contiguous, aligned area of memory for each guest.  When the guest does
    an access in real mode (MMU off), the address is compared against a
    limit value, and if it is lower, the address is ORed with an offset
    value (from the Real Mode Offset Register (RMOR)) and the result becomes
    the real address for the access.  The size of the RMA has to be one of
    a set of supported values, which usually includes 64MB, 128MB, 256MB
    and some larger powers of 2.
    
    Since we are unlikely to be able to allocate 64MB or more of physically
    contiguous memory after the kernel has been running for a while, we
    allocate a pool of RMAs at boot time using the bootmem allocator.  The
    size and number of the RMAs can be set using the kvm_rma_size=xx and
    kvm_rma_count=xx kernel command line options.
    
    KVM exports a new capability, KVM_CAP_PPC_RMA, to signal the availability
    of the pool of preallocated RMAs.  The capability value is 1 if the
    processor can use an RMA but doesn't require one (because it supports
    the VRMA facility), or 2 if the processor requires an RMA for each guest.
    
    This adds a new ioctl, KVM_ALLOCATE_RMA, which allocates an RMA from the
    pool and returns a file descriptor which can be used to map the RMA.  It
    also returns the size of the RMA in the argument structure.
    
    Having an RMA means we will get multiple KMV_SET_USER_MEMORY_REGION
    ioctl calls from userspace.  To cope with this, we now preallocate the
    kvm->arch.ram_pginfo array when the VM is created with a size sufficient
    for up to 64GB of guest memory.  Subsequently we will get rid of this
    array and use memory associated with each memslot instead.
    
    This moves most of the code that translates the user addresses into
    host pfns (page frame numbers) out of kvmppc_prepare_vrma up one level
    to kvmppc_core_prepare_memory_region.  Also, instead of having to look
    up the VMA for each page in order to check the page size, we now check
    that the pages we get are compound pages of 16MB.  However, if we are
    adding memory that is mapped to an RMA, we don't bother with calling
    get_user_pages_fast and instead just offset from the base pfn for the
    RMA.
    
    Typically the RMA gets added after vcpus are created, which makes it
    inconvenient to have the LPCR (logical partition control register) value
    in the vcpu->arch struct, since the LPCR controls whether the processor
    uses RMA or VRMA for the guest.  This moves the LPCR value into the
    kvm->arch struct and arranges for the MER (mediated external request)
    bit, which is the only bit that varies between vcpus, to be set in
    assembly code when going into the guest if there is a pending external
    interrupt request.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 36a611b398c5..20a053c14270 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -242,6 +242,7 @@
 #define   LPCR_VRMA_LP1	(1ul << (63-16))
 #define   LPCR_VRMASD_SH (63-16)
 #define   LPCR_RMLS    0x1C000000      /* impl dependent rmo limit sel */
+#define	  LPCR_RMLS_SH	(63-37)
 #define   LPCR_ILE     0x02000000      /* !HV irqs set MSR:LE */
 #define   LPCR_PECE	0x00007000	/* powersave exit cause enable */
 #define     LPCR_PECE0	0x00004000	/* ext. exceptions can cause exit */

commit de56a948b9182fbcf92cb8212f114de096c2d574
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Jun 29 00:21:34 2011 +0000

    KVM: PPC: Add support for Book3S processors in hypervisor mode
    
    This adds support for KVM running on 64-bit Book 3S processors,
    specifically POWER7, in hypervisor mode.  Using hypervisor mode means
    that the guest can use the processor's supervisor mode.  That means
    that the guest can execute privileged instructions and access privileged
    registers itself without trapping to the host.  This gives excellent
    performance, but does mean that KVM cannot emulate a processor
    architecture other than the one that the hardware implements.
    
    This code assumes that the guest is running paravirtualized using the
    PAPR (Power Architecture Platform Requirements) interface, which is the
    interface that IBM's PowerVM hypervisor uses.  That means that existing
    Linux distributions that run on IBM pSeries machines will also run
    under KVM without modification.  In order to communicate the PAPR
    hypercalls to qemu, this adds a new KVM_EXIT_PAPR_HCALL exit code
    to include/linux/kvm.h.
    
    Currently the choice between book3s_hv support and book3s_pr support
    (i.e. the existing code, which runs the guest in user mode) has to be
    made at kernel configuration time, so a given kernel binary can only
    do one or the other.
    
    This new book3s_hv code doesn't support MMIO emulation at present.
    Since we are running paravirtualized guests, this isn't a serious
    restriction.
    
    With the guest running in supervisor mode, most exceptions go straight
    to the guest.  We will never get data or instruction storage or segment
    interrupts, alignment interrupts, decrementer interrupts, program
    interrupts, single-step interrupts, etc., coming to the hypervisor from
    the guest.  Therefore this introduces a new KVMTEST_NONHV macro for the
    exception entry path so that we don't have to do the KVM test on entry
    to those exception handlers.
    
    We do however get hypervisor decrementer, hypervisor data storage,
    hypervisor instruction storage, and hypervisor emulation assist
    interrupts, so we have to handle those.
    
    In hypervisor mode, real-mode accesses can access all of RAM, not just
    a limited amount.  Therefore we put all the guest state in the vcpu.arch
    and use the shadow_vcpu in the PACA only for temporary scratch space.
    We allocate the vcpu with kzalloc rather than vzalloc, and we don't use
    anything in the kvmppc_vcpu_book3s struct, so we don't allocate it.
    We don't have a shared page with the guest, but we still need a
    kvm_vcpu_arch_shared struct to store the values of various registers,
    so we include one in the vcpu_arch struct.
    
    The POWER7 processor has a restriction that all threads in a core have
    to be in the same partition.  MMU-on kernel code counts as a partition
    (partition 0), so we have to do a partition switch on every entry to and
    exit from the guest.  At present we require the host and guest to run
    in single-thread mode because of this hardware restriction.
    
    This code allocates a hashed page table for the guest and initializes
    it with HPTEs for the guest's Virtual Real Memory Area (VRMA).  We
    require that the guest memory is allocated using 16MB huge pages, in
    order to simplify the low-level memory management.  This also means that
    we can get away without tracking paging activity in the host for now,
    since huge pages can't be paged or swapped.
    
    This also adds a few new exports needed by the book3s_hv code.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index d879a6b91635..36a611b398c5 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -189,6 +189,9 @@
 #define SPRN_CTR	0x009	/* Count Register */
 #define SPRN_DSCR	0x11
 #define SPRN_CFAR	0x1c	/* Come From Address Register */
+#define SPRN_AMR	0x1d	/* Authority Mask Register */
+#define SPRN_UAMOR	0x9d	/* User Authority Mask Override Register */
+#define SPRN_AMOR	0x15d	/* Authority Mask Override Register */
 #define SPRN_ACOP	0x1F	/* Available Coprocessor Register */
 #define SPRN_CTRLF	0x088
 #define SPRN_CTRLT	0x098
@@ -252,6 +255,7 @@
 #define   LPCR_RMI     0x00000002      /* real mode is cache inhibit */
 #define   LPCR_HDICE   0x00000001      /* Hyp Decr enable (HV,PR,EE) */
 #define SPRN_LPID	0x13F	/* Logical Partition Identifier */
+#define   LPID_RSVD	0x3ff		/* Reserved LPID for partn switching */
 #define	SPRN_HMER	0x150	/* Hardware m? error recovery */
 #define	SPRN_HMEER	0x151	/* Hardware m? enable error recovery */
 #define	SPRN_HEIR	0x153	/* Hypervisor Emulated Instruction Register */

commit 923c53caea446d246949c94703be83e68f251af7
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Jun 29 00:20:24 2011 +0000

    powerpc: Set up LPCR for running guest partitions
    
    In hypervisor mode, the LPCR controls several aspects of guest
    partitions, including virtual partition memory mode, and also controls
    whether the hypervisor decrementer interrupts are enabled.  This sets
    up LPCR at boot time so that guest partitions will use a virtual real
    memory area (VRMA) composed of 16MB large pages, and hypervisor
    decrementer interrupts are disabled.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c5cae0dd176c..d879a6b91635 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -232,10 +232,12 @@
 #define   LPCR_VPM0	(1ul << (63-0))
 #define   LPCR_VPM1	(1ul << (63-1))
 #define   LPCR_ISL	(1ul << (63-2))
+#define   LPCR_VC_SH	(63-2)
 #define   LPCR_DPFD_SH	(63-11)
 #define   LPCR_VRMA_L	(1ul << (63-12))
 #define   LPCR_VRMA_LP0	(1ul << (63-15))
 #define   LPCR_VRMA_LP1	(1ul << (63-16))
+#define   LPCR_VRMASD_SH (63-16)
 #define   LPCR_RMLS    0x1C000000      /* impl dependent rmo limit sel */
 #define   LPCR_ILE     0x02000000      /* !HV irqs set MSR:LE */
 #define   LPCR_PECE	0x00007000	/* powersave exit cause enable */
@@ -243,8 +245,10 @@
 #define     LPCR_PECE1	0x00002000	/* decrementer can cause exit */
 #define     LPCR_PECE2	0x00001000	/* machine check etc can cause exit */
 #define   LPCR_MER	0x00000800	/* Mediated External Exception */
+#define   LPCR_LPES    0x0000000c
 #define   LPCR_LPES0   0x00000008      /* LPAR Env selector 0 */
 #define   LPCR_LPES1   0x00000004      /* LPAR Env selector 1 */
+#define   LPCR_LPES_SH	2
 #define   LPCR_RMI     0x00000002      /* real mode is cache inhibit */
 #define   LPCR_HDICE   0x00000001      /* Hyp Decr enable (HV,PR,EE) */
 #define SPRN_LPID	0x13F	/* Logical Partition Identifier */

commit 1325a684b553d4b5c41ae0482f8991b43f945746
Author: Ashish Kalra <Ashish.Kalra@freescale.com>
Date:   Fri Apr 22 16:48:27 2011 -0500

    powerpc/85xx: Save scratch registers to thread info instead of using SPRGs.
    
    We expect this is actually faster, and we end up needing more space than we
    can get from the SPRGs in some instances.  This is also useful when running
    as a guest OS - SPRGs4-7 do not have guest versions.
    
    8 slots are allocated in thread_info for this even though we only actually
    use 4 of them - this allows space for future code to have more scratch
    space (and we know we'll need it for things like hugetlb).
    
    Signed-off-by: Ashish Kalra <Ashish.Kalra@freescale.com>
    Signed-off-by: Becky Bruce <beckyb@kernel.crashing.org>
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c5cae0dd176c..213d1d712499 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -872,8 +872,8 @@
 #define SPRN_SPRG_WSCRATCH2	SPRN_SPRG4W
 #define SPRN_SPRG_RSCRATCH3	SPRN_SPRG5R
 #define SPRN_SPRG_WSCRATCH3	SPRN_SPRG5W
-#define SPRN_SPRG_RSCRATCH_MC	SPRN_SPRG6R
-#define SPRN_SPRG_WSCRATCH_MC	SPRN_SPRG6W
+#define SPRN_SPRG_RSCRATCH_MC	SPRN_SPRG1
+#define SPRN_SPRG_WSCRATCH_MC	SPRN_SPRG1
 #define SPRN_SPRG_RSCRATCH4	SPRN_SPRG7R
 #define SPRN_SPRG_WSCRATCH4	SPRN_SPRG7W
 #ifdef CONFIG_E200

commit 593adf317cf165f7c66facf2285db9d4befbd1c0
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed May 11 00:39:50 2011 +0000

    powerpc/kvm: Fix the build for 32-bit Book 3S (classic) processors
    
    Commits a5d4f3ad3a ("powerpc: Base support for exceptions using
    HSRR0/1") and 673b189a2e ("powerpc: Always use SPRN_SPRG_HSCRATCH0
    when running in HV mode") cause compile and link errors for 32-bit
    classic Book 3S processors when KVM is enabled.  This fixes these
    errors.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index fdec59333053..c5cae0dd176c 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -824,6 +824,11 @@
 	FTR_SECTION_ELSE_NESTED(66);			\
 	mtspr	SPRN_SPRG_HSCRATCH0,rX;			\
 	ALT_FTR_SECTION_END_NESTED_IFCLR(CPU_FTR_HVMODE_206, 66)
+
+#else /* CONFIG_PPC_BOOK3S_64 */
+#define GET_SCRATCH0(rX)	mfspr	rX,SPRN_SPRG_SCRATCH0
+#define SET_SCRATCH0(rX)	mtspr	SPRN_SPRG_SCRATCH0,rX
+
 #endif
 
 #ifdef CONFIG_PPC_BOOK3E_64

commit 48404f2e95ef0ffd8134d89c8abcd1a15e15f1b0
Author: Paul Mackerras <paulus@samba.org>
Date:   Sun May 1 19:48:20 2011 +0000

    powerpc: Save Come-From Address Register (CFAR) in exception frame
    
    Recent 64-bit server processors (POWER6 and POWER7) have a "Come-From
    Address Register" (CFAR), that records the address of the most recent
    branch or rfid (return from interrupt) instruction for debugging purposes.
    
    This saves the value of the CFAR in the exception entry code and stores
    it in the exception frame.  We also make xmon print the CFAR value in
    its register dump code.
    
    Rather than extend the pt_regs struct at this time, we steal the orig_gpr3
    field, which is only used for system calls, and use it for the CFAR value
    for all exceptions/interrupts other than system calls.  This means we
    don't save the CFAR on system calls, which is not a great problem since
    system calls tend not to happen unexpectedly, and also avoids adding the
    overhead of reading the CFAR to the system call entry path.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 632e78e14441..fdec59333053 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -188,6 +188,7 @@
 
 #define SPRN_CTR	0x009	/* Count Register */
 #define SPRN_DSCR	0x11
+#define SPRN_CFAR	0x1c	/* Come From Address Register */
 #define SPRN_ACOP	0x1F	/* Available Coprocessor Register */
 #define SPRN_CTRLF	0x088
 #define SPRN_CTRLT	0x098

commit 851d2e2fe8dbcbe3afcad6fc4569c881d8ad4ce9
Author: Tseng-Hui (Frank) Lin <thlin@linux.vnet.ibm.com>
Date:   Mon May 2 20:43:04 2011 +0000

    powerpc: Add Initiate Coprocessor Store Word (icswx) support
    
    Icswx is a PowerPC instruction to send data to a co-processor. On Book-S
    processors the LPAR_ID and process ID (PID) of the owning process are
    registered in the window context of the co-processor at initialization
    time. When the icswx instruction is executed the L2 generates a cop-reg
    transaction on PowerBus. The transaction has no address and the
    processor does not perform an MMU access to authenticate the transaction.
    The co-processor compares the LPAR_ID and the PID included in the
    transaction and the LPAR_ID and PID held in the window context to
    determine if the process is authorized to generate the transaction.
    
    The OS needs to assign a 16-bit PID for the process. This cop-PID needs
    to be updated during context switch. The cop-PID needs to be destroyed
    when the context is destroyed.
    
    Signed-off-by: Sonny Rao <sonnyrao@linux.vnet.ibm.com>
    Signed-off-by: Tseng-Hui (Frank) Lin <thlin@linux.vnet.ibm.com>
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 1f9ac12742e6..632e78e14441 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -188,6 +188,7 @@
 
 #define SPRN_CTR	0x009	/* Count Register */
 #define SPRN_DSCR	0x11
+#define SPRN_ACOP	0x1F	/* Available Coprocessor Register */
 #define SPRN_CTRLF	0x088
 #define SPRN_CTRLT	0x098
 #define   CTRL_CT	0xc0000000	/* current thread */

commit 9d4a2925c290a053bb279e75e7a649069fdcaf6b
Author: Michael Ellerman <michael@ellerman.id.au>
Date:   Thu Apr 7 21:56:02 2011 +0000

    powerpc: Add MSR_64BIT
    
    The MSR bit which indicates 64-bit-ness is different between server and
    booke, so add a #define which gives you the right mask regardless.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 76d7d5fea5be..1f9ac12742e6 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -99,17 +99,23 @@
 #define MSR_LE		__MASK(MSR_LE_LG)	/* Little Endian */
 
 #if defined(CONFIG_PPC_BOOK3S_64)
+#define MSR_64BIT	MSR_SF
+
 /* Server variant */
 #define MSR_		MSR_ME | MSR_RI | MSR_IR | MSR_DR | MSR_ISF |MSR_HV
-#define MSR_KERNEL      MSR_ | MSR_SF
+#define MSR_KERNEL	MSR_ | MSR_64BIT
 #define MSR_USER32	MSR_ | MSR_PR | MSR_EE
-#define MSR_USER64	MSR_USER32 | MSR_SF
+#define MSR_USER64	MSR_USER32 | MSR_64BIT
 #elif defined(CONFIG_PPC_BOOK3S_32) || defined(CONFIG_8xx)
 /* Default MSR for kernel mode. */
 #define MSR_KERNEL	(MSR_ME|MSR_RI|MSR_IR|MSR_DR)
 #define MSR_USER	(MSR_KERNEL|MSR_PR|MSR_EE)
 #endif
 
+#ifndef MSR_64BIT
+#define MSR_64BIT	0
+#endif
+
 /* Floating Point Status and Control Register (FPSCR) Fields */
 #define FPSCR_FX	0x80000000	/* FPU exception summary */
 #define FPSCR_FEX	0x40000000	/* FPU enabled exception summary */

commit 673b189a2e3353061fa8c49515d1014dab6ad9b9
Author: Paul Mackerras <paulus@samba.org>
Date:   Tue Apr 5 13:59:58 2011 +1000

    powerpc: Always use SPRN_SPRG_HSCRATCH0 when running in HV mode
    
    This uses feature sections to arrange that we always use HSPRG1
    as the scratch register in the interrupt entry code rather than
    SPRG2 when we're running in hypervisor mode on POWER7.  This will
    ensure that we don't trash the guest's SPRG2 when we are running
    KVM guests.  To simplify the code, we define GET_SCRATCH0() and
    SET_SCRATCH0() macros like the GET_PACA/SET_PACA macros.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 13429a0eba09..76d7d5fea5be 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -802,6 +802,20 @@
 	FTR_SECTION_ELSE_NESTED(66);			\
 	mtspr	SPRN_SPRG_HPACA,rX;			\
 	ALT_FTR_SECTION_END_NESTED_IFCLR(CPU_FTR_HVMODE_206, 66)
+
+#define GET_SCRATCH0(rX)				\
+	BEGIN_FTR_SECTION_NESTED(66);			\
+	mfspr	rX,SPRN_SPRG_SCRATCH0;			\
+	FTR_SECTION_ELSE_NESTED(66);			\
+	mfspr	rX,SPRN_SPRG_HSCRATCH0;			\
+	ALT_FTR_SECTION_END_NESTED_IFCLR(CPU_FTR_HVMODE_206, 66)
+
+#define SET_SCRATCH0(rX)				\
+	BEGIN_FTR_SECTION_NESTED(66);			\
+	mtspr	SPRN_SPRG_SCRATCH0,rX;			\
+	FTR_SECTION_ELSE_NESTED(66);			\
+	mtspr	SPRN_SPRG_HSCRATCH0,rX;			\
+	ALT_FTR_SECTION_END_NESTED_IFCLR(CPU_FTR_HVMODE_206, 66)
 #endif
 
 #ifdef CONFIG_PPC_BOOK3E_64

commit 2dd60d79e0202628a47af9812a84d502cc63628c
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Jan 20 17:50:21 2011 +1100

    powerpc: In HV mode, use HSPRG0 for PACA
    
    When running in Hypervisor mode (arch 2.06 or later), we store the PACA
    in HSPRG0 instead of SPRG1. The architecture specifies that SPRGs may be
    lost during a "nap" power management operation (though they aren't
    currently on POWER7) and this enables use of SPRG1 by KVM guests.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 6eb1d77edb4b..13429a0eba09 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -715,12 +715,15 @@
  * SPRG usage:
  *
  * All 64-bit:
- *	- SPRG1 stores PACA pointer
+ *	- SPRG1 stores PACA pointer except 64-bit server in
+ *        HV mode in which case it is HSPRG0
  *
  * 64-bit server:
  *	- SPRG0 unused (reserved for HV on Power4)
  *	- SPRG2 scratch for exception vectors
  *	- SPRG3 unused (user visible)
+ *      - HSPRG0 stores PACA in HV mode
+ *      - HSPRG1 scratch for "HV" exceptions
  *
  * 64-bit embedded
  *	- SPRG0 generic exception scratch
@@ -783,6 +786,22 @@
 
 #ifdef CONFIG_PPC_BOOK3S_64
 #define SPRN_SPRG_SCRATCH0	SPRN_SPRG2
+#define SPRN_SPRG_HPACA		SPRN_HSPRG0
+#define SPRN_SPRG_HSCRATCH0	SPRN_HSPRG1
+
+#define GET_PACA(rX)					\
+	BEGIN_FTR_SECTION_NESTED(66);			\
+	mfspr	rX,SPRN_SPRG_PACA;			\
+	FTR_SECTION_ELSE_NESTED(66);			\
+	mfspr	rX,SPRN_SPRG_HPACA;			\
+	ALT_FTR_SECTION_END_NESTED_IFCLR(CPU_FTR_HVMODE_206, 66)
+
+#define SET_PACA(rX)					\
+	BEGIN_FTR_SECTION_NESTED(66);			\
+	mtspr	SPRN_SPRG_PACA,rX;			\
+	FTR_SECTION_ELSE_NESTED(66);			\
+	mtspr	SPRN_SPRG_HPACA,rX;			\
+	ALT_FTR_SECTION_END_NESTED_IFCLR(CPU_FTR_HVMODE_206, 66)
 #endif
 
 #ifdef CONFIG_PPC_BOOK3E_64
@@ -792,6 +811,10 @@
 #define SPRN_SPRG_TLB_EXFRAME	SPRN_SPRG2
 #define SPRN_SPRG_TLB_SCRATCH	SPRN_SPRG6
 #define SPRN_SPRG_GEN_SCRATCH	SPRN_SPRG0
+
+#define SET_PACA(rX)	mtspr	SPRN_SPRG_PACA,rX
+#define GET_PACA(rX)	mfspr	rX,SPRN_SPRG_PACA
+
 #endif
 
 #ifdef CONFIG_PPC_BOOK3S_32
@@ -842,6 +865,8 @@
 #define SPRN_SPRG_SCRATCH1	SPRN_SPRG1
 #endif
 
+
+
 /*
  * An mtfsf instruction with the L bit set. On CPUs that support this a
  * full 64bits of FPSCR is restored and on other CPUs the L bit is ignored.

commit 50fb8ebe7c4ad60d147700d253f78bd1e615a526
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Jan 12 17:41:28 2011 +1100

    powerpc: Add more Power7 specific definitions
    
    This adds more SPR definitions used on newer processors when running
    in hypervisor mode. Along with some other P7 specific bits and pieces
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 7e4abebe76c0..6eb1d77edb4b 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -210,8 +210,43 @@
 #define SPRN_TBWL	0x11C	/* Time Base Lower Register (super, R/W) */
 #define SPRN_TBWU	0x11D	/* Time Base Upper Register (super, R/W) */
 #define SPRN_SPURR	0x134	/* Scaled PURR */
+#define SPRN_HSPRG0	0x130	/* Hypervisor Scratch 0 */
+#define SPRN_HSPRG1	0x131	/* Hypervisor Scratch 1 */
+#define SPRN_HDSISR     0x132
+#define SPRN_HDAR       0x133
+#define SPRN_HDEC	0x136	/* Hypervisor Decrementer */
 #define SPRN_HIOR	0x137	/* 970 Hypervisor interrupt offset */
+#define SPRN_RMOR	0x138	/* Real mode offset register */
+#define SPRN_HRMOR	0x139	/* Real mode offset register */
+#define SPRN_HSRR0	0x13A	/* Hypervisor Save/Restore 0 */
+#define SPRN_HSRR1	0x13B	/* Hypervisor Save/Restore 1 */
 #define SPRN_LPCR	0x13E	/* LPAR Control Register */
+#define   LPCR_VPM0	(1ul << (63-0))
+#define   LPCR_VPM1	(1ul << (63-1))
+#define   LPCR_ISL	(1ul << (63-2))
+#define   LPCR_DPFD_SH	(63-11)
+#define   LPCR_VRMA_L	(1ul << (63-12))
+#define   LPCR_VRMA_LP0	(1ul << (63-15))
+#define   LPCR_VRMA_LP1	(1ul << (63-16))
+#define   LPCR_RMLS    0x1C000000      /* impl dependent rmo limit sel */
+#define   LPCR_ILE     0x02000000      /* !HV irqs set MSR:LE */
+#define   LPCR_PECE	0x00007000	/* powersave exit cause enable */
+#define     LPCR_PECE0	0x00004000	/* ext. exceptions can cause exit */
+#define     LPCR_PECE1	0x00002000	/* decrementer can cause exit */
+#define     LPCR_PECE2	0x00001000	/* machine check etc can cause exit */
+#define   LPCR_MER	0x00000800	/* Mediated External Exception */
+#define   LPCR_LPES0   0x00000008      /* LPAR Env selector 0 */
+#define   LPCR_LPES1   0x00000004      /* LPAR Env selector 1 */
+#define   LPCR_RMI     0x00000002      /* real mode is cache inhibit */
+#define   LPCR_HDICE   0x00000001      /* Hyp Decr enable (HV,PR,EE) */
+#define SPRN_LPID	0x13F	/* Logical Partition Identifier */
+#define	SPRN_HMER	0x150	/* Hardware m? error recovery */
+#define	SPRN_HMEER	0x151	/* Hardware m? enable error recovery */
+#define	SPRN_HEIR	0x153	/* Hypervisor Emulated Instruction Register */
+#define SPRN_TLBINDEXR	0x154	/* P7 TLB control register */
+#define SPRN_TLBVPNR	0x155	/* P7 TLB control register */
+#define SPRN_TLBRPNR	0x156	/* P7 TLB control register */
+#define SPRN_TLBLPIDR	0x157	/* P7 TLB control register */
 #define SPRN_DBAT0L	0x219	/* Data BAT 0 Lower Register */
 #define SPRN_DBAT0U	0x218	/* Data BAT 0 Upper Register */
 #define SPRN_DBAT1L	0x21B	/* Data BAT 1 Lower Register */
@@ -434,16 +469,23 @@
 #define SPRN_SRR0	0x01A	/* Save/Restore Register 0 */
 #define SPRN_SRR1	0x01B	/* Save/Restore Register 1 */
 #define   SRR1_WAKEMASK		0x00380000 /* reason for wakeup */
-#define   SRR1_WAKERESET	0x00380000 /* System reset */
 #define   SRR1_WAKESYSERR	0x00300000 /* System error */
 #define   SRR1_WAKEEE		0x00200000 /* External interrupt */
 #define   SRR1_WAKEMT		0x00280000 /* mtctrl */
+#define	  SRR1_WAKEHMI		0x00280000 /* Hypervisor maintenance */
 #define   SRR1_WAKEDEC		0x00180000 /* Decrementer interrupt */
 #define   SRR1_WAKETHERM	0x00100000 /* Thermal management interrupt */
+#define	  SRR1_WAKERESET	0x00100000 /* System reset */
+#define	  SRR1_WAKESTATE	0x00030000 /* Powersave exit mask [46:47] */
+#define	  SRR1_WS_DEEPEST	0x00030000 /* Some resources not maintained,
+					  * may not be recoverable */
+#define	  SRR1_WS_DEEPER	0x00020000 /* Some resources not maintained */
+#define	  SRR1_WS_DEEP		0x00010000 /* All resources maintained */
 #define   SRR1_PROGFPE		0x00100000 /* Floating Point Enabled */
 #define   SRR1_PROGPRIV		0x00040000 /* Privileged instruction */
 #define   SRR1_PROGTRAP		0x00020000 /* Trap */
 #define   SRR1_PROGADDR		0x00010000 /* SRR0 contains subsequent addr */
+
 #define SPRN_HSRR0	0x13A	/* Save/Restore Register 0 */
 #define SPRN_HSRR1	0x13B	/* Save/Restore Register 1 */
 
@@ -894,6 +936,8 @@
 #define PV_POWER5p	0x003B
 #define PV_POWER7	0x003F
 #define PV_970FX	0x003C
+#define PV_POWER6	0x003E
+#define PV_POWER7	0x003F
 #define PV_630		0x0040
 #define PV_630p	0x0041
 #define PV_970MP	0x0044

commit 619297855aa16646246ea4b1f6e05f1b2455c808
Merge: e16b396ce314 1ef1d1c23539
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Mar 18 10:38:34 2011 -0700

    Merge branch 'perf-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'perf-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (30 commits)
      trace, filters: Initialize the match variable in process_ops() properly
      trace, documentation: Fix branch profiling location in debugfs
      oprofile, s390: Cleanups
      oprofile, s390: Remove hwsampler_files.c and merge it into init.c
      perf: Fix tear-down of inherited group events
      perf: Reorder & optimize perf_event_context to remove alignment padding on 64 bit builds
      perf: Handle stopped state with tracepoints
      perf: Fix the software events state check
      perf, powerpc: Handle events that raise an exception without overflowing
      perf, x86: Use INTEL_*_CONSTRAINT() for all PEBS event constraints
      perf, x86: Clean up SandyBridge PEBS events
      perf lock: Fix sorting by wait_min
      perf tools: Version incorrect with some versions of grep
      perf evlist: New command to list the names of events present in a perf.data file
      perf script: Add support for H/W and S/W events
      perf script: Add support for dumping symbols
      perf script: Support custom field selection for output
      perf script: Move printing of 'common' data from print_event and rename
      perf tracing: Remove print_graph_cpu and print_graph_proc from trace-event-parse
      perf script: Change process_event prototype
      ...

commit 0837e3242c73566fc1c0196b4ec61779c25ffc93
Author: Anton Blanchard <anton@samba.org>
Date:   Wed Mar 9 14:38:42 2011 +1100

    perf, powerpc: Handle events that raise an exception without overflowing
    
    Events on POWER7 can roll back if a speculative event doesn't
    eventually complete. Unfortunately in some rare cases they will
    raise a performance monitor exception. We need to catch this to
    ensure we reset the PMC. In all cases the PMC will be 256 or less
    cycles from overflow.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: <stable@kernel.org> # as far back as it applies cleanly
    LKML-Reference: <20110309143842.6c22845e@kryten>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 125fc1ad665d..7626fa78e1f8 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -880,6 +880,7 @@
 #define PV_970		0x0039
 #define PV_POWER5	0x003A
 #define PV_POWER5p	0x003B
+#define PV_POWER7	0x003F
 #define PV_970FX	0x003C
 #define PV_630		0x0040
 #define PV_630p	0x0041

commit ac6f120369ffe66058518fabf90cdd53b2503a82
Author: Liu Yu <yu.liu@freescale.com>
Date:   Tue Jan 25 14:02:13 2011 +0800

    powerpc/85xx: Workaroudn e500 CPU erratum A005
    
    This erratum can occur if a single-precision floating-point,
    double-precision floating-point or vector floating-point instruction on a
    mispredicted branch path signals one of the floating-point data interrupts
    which are enabled by the SPEFSCR (FINVE, FDBZE, FUNFE or FOVFE bits).  This
    interrupt must be recorded in a one-cycle window when the misprediction is
    resolved.  If this extremely rare event should occur, the result could be:
    
    The SPE Data Exception from the mispredicted path may be reported
    erroneously if a single-precision floating-point, double-precision
    floating-point or vector floating-point instruction is the second
    instruction on the correct branch path.
    
    According to errata description, some efp instructions which are not
    supposed to trigger SPE exceptions can trigger the exceptions in this case.
    However, as we haven't emulated these instructions here, a signal will
    send to userspace, and userspace application would exit.
    
    This patch re-issue the efp instruction that we haven't emulated,
    so that hardware can properly execute it again if this case happen.
    
    Signed-off-by: Liu Yu <yu.liu@freescale.com>
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index bd0d36e1c945..1bc6a12f3725 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -862,6 +862,8 @@
 #define PVR_7450	0x80000000
 #define PVR_8540	0x80200000
 #define PVR_8560	0x80200000
+#define PVR_VER_E500V1	0x8020
+#define PVR_VER_E500V2	0x8021
 /*
  * For the 8xx processors, all of them report the same PVR family for
  * the PowerPC core. The various versions of these processors must be

commit 6edc642ebee87dfceb97050d51c5ab1fe539a597
Author: Tseng-Hui (Frank) Lin <thlin@linux.vnet.ibm.com>
Date:   Wed Mar 2 07:20:50 2011 +0000

    powerpc: Cleanup definition of the PID register
    
    Move SPRN_PID declearations in various locations into one place.
    
    Signed-off-by: Tseng-Hui (Frank) Lin <thlin@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 125fc1ad665d..bd0d36e1c945 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -170,6 +170,16 @@
 #define SPEFSCR_FRMC 	0x00000003	/* Embedded FP rounding mode control */
 
 /* Special Purpose Registers (SPRNs)*/
+
+#ifdef CONFIG_40x
+#define SPRN_PID	0x3B1	/* Process ID */
+#else
+#define SPRN_PID	0x030	/* Process ID */
+#ifdef CONFIG_BOOKE
+#define SPRN_PID0	SPRN_PID/* Process ID Register 0 */
+#endif
+#endif
+
 #define SPRN_CTR	0x009	/* Count Register */
 #define SPRN_DSCR	0x11
 #define SPRN_CTRLF	0x088

commit 86985db66ea2fda174615be05112a7d1b13645c4
Author: Li Yang <leoli@freescale.com>
Date:   Wed Nov 3 17:35:31 2010 +0800

    powerpc/85xx: add e500 HID1 bit definition
    
    Also make 74xx HID1 definition conditional.
    
    Signed-off-by: Li Yang <leoli@freescale.com>
    Signed-off-by: Shaohui Xie <b21989@freescale.com>
    Cc: Roy Zang <tie-fei.zang@freescale.com>
    Cc: Alexandre Bounine <alexandre.bounine@idt.com>
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index ff0005eec7dd..125fc1ad665d 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -283,6 +283,7 @@
 #define HID0_NOPTI	(1<<0)		/* No-op dcbt and dcbst instr. */
 
 #define SPRN_HID1	0x3F1		/* Hardware Implementation Register 1 */
+#ifdef CONFIG_6xx
 #define HID1_EMCP	(1<<31)		/* 7450 Machine Check Pin Enable */
 #define HID1_DFS	(1<<22)		/* 7447A Dynamic Frequency Scaling */
 #define HID1_PC0	(1<<16)		/* 7450 PLL_CFG[0] */
@@ -292,6 +293,7 @@
 #define HID1_SYNCBE	(1<<11)		/* 7450 ABE for sync, eieio */
 #define HID1_ABE	(1<<10)		/* 7450 Address Broadcast Enable */
 #define HID1_PS		(1<<16)		/* 750FX PLL selection */
+#endif
 #define SPRN_HID2	0x3F8		/* Hardware Implementation Register 2 */
 #define SPRN_HID2_GEKKO	0x398		/* Gekko HID2 Register */
 #define SPRN_IABR	0x3F2	/* Instruction Address Breakpoint Register */

commit 4138d65333fa8961714441ed40229ea8cbeaf7e5
Author: Anton Blanchard <anton@samba.org>
Date:   Fri Aug 6 03:28:19 2010 +0000

    powerpc: Inline ppc64_runlatch_off
    
    I'm sick of seeing ppc64_runlatch_off in our profiles, so inline it
    into the callers. To avoid a mess of circular includes I didn't add
    it as an inline function.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Acked-by: Olof Johansson <olof@lixom.net>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index d8be016d2ede..ff0005eec7dd 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -951,7 +951,14 @@
 #ifdef CONFIG_PPC64
 
 extern void ppc64_runlatch_on(void);
-extern void ppc64_runlatch_off(void);
+extern void __ppc64_runlatch_off(void);
+
+#define ppc64_runlatch_off()					\
+	do {							\
+		if (cpu_has_feature(CPU_FTR_CTRL) &&		\
+		    test_thread_flag(TIF_RUNLATCH))		\
+			__ppc64_runlatch_off();			\
+	} while (0)
 
 extern unsigned long scom970_read(unsigned int address);
 extern void scom970_write(unsigned int address, unsigned long value);

commit 0866eb99cc4d5951cb0ed6ddfa92d5a3d55216ae
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Jul 9 15:21:41 2010 +1000

    powerpc/book3e: mtmsr should not be mtmsrd on book3e 64-bit
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index d62fdf4e504b..d8be016d2ede 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -890,7 +890,7 @@
 #ifndef __ASSEMBLY__
 #define mfmsr()		({unsigned long rval; \
 			asm volatile("mfmsr %0" : "=r" (rval)); rval;})
-#ifdef CONFIG_PPC64
+#ifdef CONFIG_PPC_BOOK3S_64
 #define __mtmsrd(v, l)	asm volatile("mtmsrd %0," __stringify(l) \
 				     : : "r" (v) : "memory")
 #define mtmsrd(v)	__mtmsrd((v), 0)

commit 98edb6ca4174f17a64890a02f44c211c8b44fb3c
Merge: a8251096b427 8fbf065d6256
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 21 17:16:21 2010 -0700

    Merge branch 'kvm-updates/2.6.35' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    * 'kvm-updates/2.6.35' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (269 commits)
      KVM: x86: Add missing locking to arch specific vcpu ioctls
      KVM: PPC: Add missing vcpu_load()/vcpu_put() in vcpu ioctls
      KVM: MMU: Segregate shadow pages with different cr0.wp
      KVM: x86: Check LMA bit before set_efer
      KVM: Don't allow lmsw to clear cr0.pe
      KVM: Add cpuid.txt file
      KVM: x86: Tell the guest we'll warn it about tsc stability
      x86, paravirt: don't compute pvclock adjustments if we trust the tsc
      x86: KVM guest: Try using new kvm clock msrs
      KVM: x86: export paravirtual cpuid flags in KVM_GET_SUPPORTED_CPUID
      KVM: x86: add new KVMCLOCK cpuid feature
      KVM: x86: change msr numbers for kvmclock
      x86, paravirt: Add a global synchronization point for pvclock
      x86, paravirt: Enable pvclock flags in vcpu_time_info structure
      KVM: x86: Inject #GP with the right rip on efer writes
      KVM: SVM: Don't allow nested guest to VMMCALL into host
      KVM: x86: Fix exception reinjection forced to true
      KVM: Fix wallclock version writing race
      KVM: MMU: Don't read pdptrs with mmu spinlock held in mmu_alloc_roots
      KVM: VMX: enable VMXON check with SMX enabled (Intel TXT)
      ...

commit b4e8c8dd8456c1d3685fb5b715c9795d250f500e
Author: Torez Smith <lnxtorez@linux.vnet.ibm.com>
Date:   Fri Mar 5 10:45:54 2010 +0000

    powerpc/4xx: Simple platform for the ISS 4xx simulator
    
    This is a trivial 4xx plaform that uses the new simple bsp from
    Josh and is handy to use in simulators such as ISS or even Mambo
    who don't properly implement most of the actual devices in the
    SoC but really only the core.
    
    Signed-off-by: Torez Smith  <lnxtorez@linux.vnet.ibm.com>
    Signed-off-by: Dave Kleikamp <shaggy@linux.vnet.ibm.com>
    Signed-off-by: Josh Boyer <jwboyer@linux.vnet.ibm.com>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index b2d1ac635f22..b68f025924a8 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -854,6 +854,9 @@
 #define PVR_8245	0x80811014
 #define PVR_8260	PVR_8240
 
+/* 476 Simulator seems to currently have the PVR of the 602... */
+#define PVR_476_ISS	0x00052000
+
 /* 64-bit processors */
 /* XXX the prefix should be PVR_, we'll do a global sweep to fix it one day */
 #define PV_NORTHSTAR	0x0033

commit e7f75ad01d590243904c2d95ab47e6b2e9ef6dad
Author: Dave Kleikamp <shaggy@linux.vnet.ibm.com>
Date:   Fri Mar 5 10:43:12 2010 +0000

    powerpc/47x: Base ppc476 support
    
    This patch adds the base support for the 476 processor.  The code was
    primarily written by Ben Herrenschmidt and Torez Smith, but I've been
    maintaining it for a while.
    
    The goal is to have a single binary that will run on 44x and 47x, but
    we still have some details to work out.  The biggest is that the L1 cache
    line size differs on the two platforms, but it's currently a compile-time
    option.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Torez Smith  <lnxtorez@linux.vnet.ibm.com>
    Signed-off-by: Dave Kleikamp <shaggy@linux.vnet.ibm.com>
    Signed-off-by: Josh Boyer <jwboyer@linux.vnet.ibm.com>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 5572e86223f4..b2d1ac635f22 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -817,6 +817,7 @@
 #define PVR_403GC	0x00200200
 #define PVR_403GCX	0x00201400
 #define PVR_405GP	0x40110000
+#define PVR_476		0x11a52000
 #define PVR_STB03XXX	0x40310000
 #define PVR_NP405H	0x41410000
 #define PVR_NP405L	0x41610000

commit d6d549b20776c937cb4717b24ef05baec4768f99
Author: Alexander Graf <agraf@suse.de>
Date:   Fri Feb 19 11:00:33 2010 +0100

    KVM: PPC: Add Gekko SPRs
    
    The Gekko has some SPR values that differ from other PPC core values and
    also some additional ones.
    
    Let's add support for them in our mfspr/mtspr emulator.
    
    Signed-off-by: Alexander Graf <agraf@suse.de>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 5572e86223f4..8a69a39a10b1 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -293,10 +293,12 @@
 #define HID1_ABE	(1<<10)		/* 7450 Address Broadcast Enable */
 #define HID1_PS		(1<<16)		/* 750FX PLL selection */
 #define SPRN_HID2	0x3F8		/* Hardware Implementation Register 2 */
+#define SPRN_HID2_GEKKO	0x398		/* Gekko HID2 Register */
 #define SPRN_IABR	0x3F2	/* Instruction Address Breakpoint Register */
 #define SPRN_IABR2	0x3FA		/* 83xx */
 #define SPRN_IBCR	0x135		/* 83xx Insn Breakpoint Control Reg */
 #define SPRN_HID4	0x3F4		/* 970 HID4 */
+#define SPRN_HID4_GEKKO	0x3F3		/* Gekko HID4 */
 #define SPRN_HID5	0x3F6		/* 970 HID5 */
 #define SPRN_HID6	0x3F9	/* BE HID 6 */
 #define   HID6_LB	(0x0F<<12) /* Concurrent Large Page Modes */
@@ -465,6 +467,14 @@
 #define SPRN_VRSAVE	0x100	/* Vector Register Save Register */
 #define SPRN_XER	0x001	/* Fixed Point Exception Register */
 
+#define SPRN_MMCR0_GEKKO 0x3B8 /* Gekko Monitor Mode Control Register 0 */
+#define SPRN_MMCR1_GEKKO 0x3BC /* Gekko Monitor Mode Control Register 1 */
+#define SPRN_PMC1_GEKKO  0x3B9 /* Gekko Performance Monitor Control 1 */
+#define SPRN_PMC2_GEKKO  0x3BA /* Gekko Performance Monitor Control 2 */
+#define SPRN_PMC3_GEKKO  0x3BD /* Gekko Performance Monitor Control 3 */
+#define SPRN_PMC4_GEKKO  0x3BE /* Gekko Performance Monitor Control 4 */
+#define SPRN_WPAR_GEKKO  0x399 /* Gekko Write Pipe Address Register */
+
 #define SPRN_SCOMC	0x114	/* SCOM Access Control */
 #define SPRN_SCOMD	0x115	/* SCOM Access DATA */
 

commit 25a8a02d26a71c28e26417a3520c653c2d40af6b
Author: Alexander Graf <agraf@suse.de>
Date:   Fri Jan 8 02:58:07 2010 +0100

    KVM: PPC: Emulate trap SRR1 flags properly
    
    Book3S needs some flags in SRR1 to get to know details about an interrupt.
    
    One such example is the trap instruction. It tells the guest kernel that
    a program interrupt is due to a trap using a bit in SRR1.
    
    This patch implements above behavior, making WARN_ON behave like WARN_ON.
    
    Signed-off-by: Alexander Graf <agraf@suse.de>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index bc8dd53f718a..5572e86223f4 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -426,6 +426,10 @@
 #define   SRR1_WAKEMT		0x00280000 /* mtctrl */
 #define   SRR1_WAKEDEC		0x00180000 /* Decrementer interrupt */
 #define   SRR1_WAKETHERM	0x00100000 /* Thermal management interrupt */
+#define   SRR1_PROGFPE		0x00100000 /* Floating Point Enabled */
+#define   SRR1_PROGPRIV		0x00040000 /* Privileged instruction */
+#define   SRR1_PROGTRAP		0x00020000 /* Trap */
+#define   SRR1_PROGADDR		0x00010000 /* SRR0 contains subsequent addr */
 #define SPRN_HSRR0	0x13A	/* Save/Restore Register 0 */
 #define SPRN_HSRR1	0x13B	/* Save/Restore Register 1 */
 

commit 81cd5ae303e88a1e9d3a3e0f1fe8abd100edde16
Author: Anton Blanchard <anton@samba.org>
Date:   Tue Oct 27 18:31:29 2009 +0000

    powerpc: perf_event: Enable SDAR in continous sample mode
    
    In continuous sampling mode we want the SDAR to update.  While we can
    select between dcache misses and ERAT (L1-TLB) misses, a decent default
    is to enable both.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 6315edc205d8..bc8dd53f718a 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -489,6 +489,8 @@
 #define SPRN_MMCR1	798
 #define SPRN_MMCRA	0x312
 #define   MMCRA_SDSYNC	0x80000000UL /* SDAR synced with SIAR */
+#define   MMCRA_SDAR_DCACHE_MISS 0x40000000UL
+#define   MMCRA_SDAR_ERAT_MISS   0x20000000UL
 #define   MMCRA_SIHV	0x10000000UL /* state of MSR HV when SIAR set */
 #define   MMCRA_SIPR	0x08000000UL /* state of MSR PR when SIAR set */
 #define   MMCRA_SLOT	0x07000000UL /* SLOT bits (37-39) */

commit 13363ab9b9d040ebeace3a1a3a5ddcb13bf0d644
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Jul 23 23:15:39 2009 +0000

    powerpc: Add definitions used by exception handling on 64-bit Book3E
    
    This adds various definitions and macros used by the exception and TLB
    miss handling on 64-bit BookE
    
    It also adds the definitions of the SPRGs used for various exception types
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c8715331e1b0..6315edc205d8 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -652,6 +652,16 @@
  *	- SPRG2 scratch for exception vectors
  *	- SPRG3 unused (user visible)
  *
+ * 64-bit embedded
+ *	- SPRG0 generic exception scratch
+ *	- SPRG2 TLB exception stack
+ *	- SPRG3 unused (user visible)
+ *	- SPRG4 unused (user visible)
+ *	- SPRG6 TLB miss scratch (user visible, sorry !)
+ *	- SPRG7 critical exception scratch
+ *	- SPRG8 machine check exception scratch
+ *	- SPRG9 debug exception scratch
+ *
  * All 32-bit:
  *	- SPRG3 current thread_info pointer
  *        (virtual on BookE, physical on others)
@@ -705,6 +715,15 @@
 #define SPRN_SPRG_SCRATCH0	SPRN_SPRG2
 #endif
 
+#ifdef CONFIG_PPC_BOOK3E_64
+#define SPRN_SPRG_MC_SCRATCH	SPRN_SPRG8
+#define SPRN_SPRG_CRIT_SCRATCH	SPRN_SPRG7
+#define SPRN_SPRG_DBG_SCRATCH	SPRN_SPRG9
+#define SPRN_SPRG_TLB_EXFRAME	SPRN_SPRG2
+#define SPRN_SPRG_TLB_SCRATCH	SPRN_SPRG6
+#define SPRN_SPRG_GEN_SCRATCH	SPRN_SPRG0
+#endif
+
 #ifdef CONFIG_PPC_BOOK3S_32
 #define SPRN_SPRG_SCRATCH0	SPRN_SPRG0
 #define SPRN_SPRG_SCRATCH1	SPRN_SPRG1

commit 0257c99cdfaca53a881339e1cbca638c61569b05
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Jul 23 23:15:34 2009 +0000

    powerpc: Add SPR definitions for new 64-bit BookE
    
    This adds various SPRs defined on 64-bit BookE, along with changes
    to the definition of the base MSR values to add the values needed
    for 64-bit Book3E.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 2cedbb427618..c8715331e1b0 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -98,19 +98,15 @@
 #define MSR_RI		__MASK(MSR_RI_LG)	/* Recoverable Exception */
 #define MSR_LE		__MASK(MSR_LE_LG)	/* Little Endian */
 
-#ifdef CONFIG_PPC64
+#if defined(CONFIG_PPC_BOOK3S_64)
+/* Server variant */
 #define MSR_		MSR_ME | MSR_RI | MSR_IR | MSR_DR | MSR_ISF |MSR_HV
 #define MSR_KERNEL      MSR_ | MSR_SF
-
 #define MSR_USER32	MSR_ | MSR_PR | MSR_EE
 #define MSR_USER64	MSR_USER32 | MSR_SF
-
-#else /* 32-bit */
+#elif defined(CONFIG_PPC_BOOK3S_32) || defined(CONFIG_8xx)
 /* Default MSR for kernel mode. */
-#ifndef MSR_KERNEL	/* reg_booke.h also defines this */
 #define MSR_KERNEL	(MSR_ME|MSR_RI|MSR_IR|MSR_DR)
-#endif
-
 #define MSR_USER	(MSR_KERNEL|MSR_PR|MSR_EE)
 #endif
 

commit 063517bea114d4cb57bf582353d0a99b82775a63
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Jul 14 20:52:56 2009 +0000

    powerpc: Change PACA from SPRG3 to SPRG1
    
    This change the SPRG used to store the PACA on ppc64 from
    SPRG3 to SPRG1. SPRG3 is user readable on most processors
    and we want to use it for other things. We change the scratch
    SPRG used by exception vectors from SRPG1 to SPRG2.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index d17af2b3d4ce..2cedbb427618 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -649,12 +649,12 @@
  * SPRG usage:
  *
  * All 64-bit:
- *	- SPRG3 stores PACA pointer
+ *	- SPRG1 stores PACA pointer
  *
  * 64-bit server:
  *	- SPRG0 unused (reserved for HV on Power4)
- *	- SPRG1 scratch for exception vectors
- *	- SPRG2 unused
+ *	- SPRG2 scratch for exception vectors
+ *	- SPRG3 unused (user visible)
  *
  * All 32-bit:
  *	- SPRG3 current thread_info pointer
@@ -700,13 +700,13 @@
  *
  */
 #ifdef CONFIG_PPC64
-#define SPRN_SPRG_PACA 		SPRN_SPRG3
+#define SPRN_SPRG_PACA 		SPRN_SPRG1
 #else
 #define SPRN_SPRG_THREAD 	SPRN_SPRG3
 #endif
 
 #ifdef CONFIG_PPC_BOOK3S_64
-#define SPRN_SPRG_SCRATCH0	SPRN_SPRG1
+#define SPRN_SPRG_SCRATCH0	SPRN_SPRG2
 #endif
 
 #ifdef CONFIG_PPC_BOOK3S_32

commit c5a8c0c99f67ae8a784faafbaaea1529825796e2
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Jul 16 19:36:57 2009 +0000

    powerpc: Remove use of a second scratch SPRG in STAB code
    
    The STAB code used on Power3 and RS/64 uses a second scratch SPRG to
    save a GPR in order to decide whether to go to do_stab_bolted_* or
    to handle a normal data access exception.
    
    This prevents our scheme of freeing SPRG3 which is user visible for
    user uses since we cannot use SPRG0 which, on RS/64, seems to be
    read-only for supervisor mode (like POWER4).
    
    This reworks the STAB exception entry to use the PACA as temporary
    storage instead.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index a8179cc99ac4..d17af2b3d4ce 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -654,7 +654,7 @@
  * 64-bit server:
  *	- SPRG0 unused (reserved for HV on Power4)
  *	- SPRG1 scratch for exception vectors
- *	- SPRG2 scratch for exception vectors
+ *	- SPRG2 unused
  *
  * All 32-bit:
  *	- SPRG3 current thread_info pointer
@@ -707,7 +707,6 @@
 
 #ifdef CONFIG_PPC_BOOK3S_64
 #define SPRN_SPRG_SCRATCH0	SPRN_SPRG1
-#define SPRN_SPRG_SCRATCH1	SPRN_SPRG2
 #endif
 
 #ifdef CONFIG_PPC_BOOK3S_32

commit ee43eb788b3a06425fffb912677e2e1c8b00dd3b
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Jul 14 20:52:54 2009 +0000

    powerpc: Use names rather than numbers for SPRGs (v2)
    
    The kernel uses SPRG registers for various purposes, typically in
    low level assembly code as scratch registers or to hold per-cpu
    global infos such as the PACA or the current thread_info pointer.
    
    We want to be able to easily shuffle the usage of those registers
    as some implementations have specific constraints realted to some
    of them, for example, some have userspace readable aliases, etc..
    and the current choice isn't always the best.
    
    This patch should not change any code generation, and replaces the
    usage of SPRN_SPRGn everywhere in the kernel with a named replacement
    and adds documentation next to the definition of the names as to
    what those are used for on each processor family.
    
    The only parts that still use the original numbers are bits of KVM
    or suspend/resume code that just blindly needs to save/restore all
    the SPRGs.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index 1170267736d3..a8179cc99ac4 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -645,6 +645,119 @@
 #define MMCR0_PMC2_LOADMISSTIME	0x5
 #endif
 
+/*
+ * SPRG usage:
+ *
+ * All 64-bit:
+ *	- SPRG3 stores PACA pointer
+ *
+ * 64-bit server:
+ *	- SPRG0 unused (reserved for HV on Power4)
+ *	- SPRG1 scratch for exception vectors
+ *	- SPRG2 scratch for exception vectors
+ *
+ * All 32-bit:
+ *	- SPRG3 current thread_info pointer
+ *        (virtual on BookE, physical on others)
+ *
+ * 32-bit classic:
+ *	- SPRG0 scratch for exception vectors
+ *	- SPRG1 scratch for exception vectors
+ *	- SPRG2 indicator that we are in RTAS
+ *	- SPRG4 (603 only) pseudo TLB LRU data
+ *
+ * 32-bit 40x:
+ *	- SPRG0 scratch for exception vectors
+ *	- SPRG1 scratch for exception vectors
+ *	- SPRG2 scratch for exception vectors
+ *	- SPRG4 scratch for exception vectors (not 403)
+ *	- SPRG5 scratch for exception vectors (not 403)
+ *	- SPRG6 scratch for exception vectors (not 403)
+ *	- SPRG7 scratch for exception vectors (not 403)
+ *
+ * 32-bit 440 and FSL BookE:
+ *	- SPRG0 scratch for exception vectors
+ *	- SPRG1 scratch for exception vectors (*)
+ *	- SPRG2 scratch for crit interrupts handler
+ *	- SPRG4 scratch for exception vectors
+ *	- SPRG5 scratch for exception vectors
+ *	- SPRG6 scratch for machine check handler
+ *	- SPRG7 scratch for exception vectors
+ *	- SPRG9 scratch for debug vectors (e500 only)
+ *
+ *      Additionally, BookE separates "read" and "write"
+ *      of those registers. That allows to use the userspace
+ *      readable variant for reads, which can avoid a fault
+ *      with KVM type virtualization.
+ *
+ *      (*) Under KVM, the host SPRG1 is used to point to
+ *      the current VCPU data structure
+ *
+ * 32-bit 8xx:
+ *	- SPRG0 scratch for exception vectors
+ *	- SPRG1 scratch for exception vectors
+ *	- SPRG2 apparently unused but initialized
+ *
+ */
+#ifdef CONFIG_PPC64
+#define SPRN_SPRG_PACA 		SPRN_SPRG3
+#else
+#define SPRN_SPRG_THREAD 	SPRN_SPRG3
+#endif
+
+#ifdef CONFIG_PPC_BOOK3S_64
+#define SPRN_SPRG_SCRATCH0	SPRN_SPRG1
+#define SPRN_SPRG_SCRATCH1	SPRN_SPRG2
+#endif
+
+#ifdef CONFIG_PPC_BOOK3S_32
+#define SPRN_SPRG_SCRATCH0	SPRN_SPRG0
+#define SPRN_SPRG_SCRATCH1	SPRN_SPRG1
+#define SPRN_SPRG_RTAS		SPRN_SPRG2
+#define SPRN_SPRG_603_LRU	SPRN_SPRG4
+#endif
+
+#ifdef CONFIG_40x
+#define SPRN_SPRG_SCRATCH0	SPRN_SPRG0
+#define SPRN_SPRG_SCRATCH1	SPRN_SPRG1
+#define SPRN_SPRG_SCRATCH2	SPRN_SPRG2
+#define SPRN_SPRG_SCRATCH3	SPRN_SPRG4
+#define SPRN_SPRG_SCRATCH4	SPRN_SPRG5
+#define SPRN_SPRG_SCRATCH5	SPRN_SPRG6
+#define SPRN_SPRG_SCRATCH6	SPRN_SPRG7
+#endif
+
+#ifdef CONFIG_BOOKE
+#define SPRN_SPRG_RSCRATCH0	SPRN_SPRG0
+#define SPRN_SPRG_WSCRATCH0	SPRN_SPRG0
+#define SPRN_SPRG_RSCRATCH1	SPRN_SPRG1
+#define SPRN_SPRG_WSCRATCH1	SPRN_SPRG1
+#define SPRN_SPRG_RSCRATCH_CRIT	SPRN_SPRG2
+#define SPRN_SPRG_WSCRATCH_CRIT	SPRN_SPRG2
+#define SPRN_SPRG_RSCRATCH2	SPRN_SPRG4R
+#define SPRN_SPRG_WSCRATCH2	SPRN_SPRG4W
+#define SPRN_SPRG_RSCRATCH3	SPRN_SPRG5R
+#define SPRN_SPRG_WSCRATCH3	SPRN_SPRG5W
+#define SPRN_SPRG_RSCRATCH_MC	SPRN_SPRG6R
+#define SPRN_SPRG_WSCRATCH_MC	SPRN_SPRG6W
+#define SPRN_SPRG_RSCRATCH4	SPRN_SPRG7R
+#define SPRN_SPRG_WSCRATCH4	SPRN_SPRG7W
+#ifdef CONFIG_E200
+#define SPRN_SPRG_RSCRATCH_DBG	SPRN_SPRG6R
+#define SPRN_SPRG_WSCRATCH_DBG	SPRN_SPRG6W
+#else
+#define SPRN_SPRG_RSCRATCH_DBG	SPRN_SPRG9
+#define SPRN_SPRG_WSCRATCH_DBG	SPRN_SPRG9
+#endif
+#define SPRN_SPRG_RVCPU		SPRN_SPRG1
+#define SPRN_SPRG_WVCPU		SPRN_SPRG1
+#endif
+
+#ifdef CONFIG_8xx
+#define SPRN_SPRG_SCRATCH0	SPRN_SPRG0
+#define SPRN_SPRG_SCRATCH1	SPRN_SPRG1
+#endif
+
 /*
  * An mtfsf instruction with the L bit set. On CPUs that support this a
  * full 64bits of FPSCR is restored and on other CPUs the L bit is ignored.

commit 2fae0a524b193e200b71778407ad29b22417056a
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Sun Jun 14 16:16:10 2009 +0000

    powerpc: Add memory clobber to mtspr()
    
    Without this clobber, mtspr can be re-ordered by gcc vs. surrounding
    memory accesses. While this might be ok for some cases, it's not in
    others and I'm not confident that all callers get it right (In fact
    I'm sure some of them don't).
    
    So for now, let's make mtspr() itself contain a memory clobber until
    we can audit and fix everything, at which point we can remove it
    if we think it's worth doing so.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index a3c28e46947c..1170267736d3 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -755,7 +755,8 @@
 #define mfspr(rn)	({unsigned long rval; \
 			asm volatile("mfspr %0," __stringify(rn) \
 				: "=r" (rval)); rval;})
-#define mtspr(rn, v)	asm volatile("mtspr " __stringify(rn) ",%0" : : "r" (v))
+#define mtspr(rn, v)	asm volatile("mtspr " __stringify(rn) ",%0" : : "r" (v)\
+				     : "memory")
 
 #ifdef __powerpc64__
 #ifdef CONFIG_PPC_CELL

commit 4c75f84f2c781beb230031234ed961d28771a764
Author: Paul Mackerras <paulus@samba.org>
Date:   Fri Jun 12 02:00:50 2009 +0000

    powerpc: Add compiler memory barrier to mtmsr macro
    
    On 32-bit non-Book E, local_irq_restore() turns into just mtmsr(),
    which doesn't currently have a compiler memory barrier.  This means
    that accesses to memory inside a local_irq_save/restore section,
    or a spin_lock_irqsave/spin_unlock_irqrestore section on UP, can
    be reordered by the compiler to occur outside that section.
    
    To fix this, this adds a compiler memory barrier to mtmsr for both
    32-bit and 64-bit.  Having a compiler memory barrier in mtmsr makes
    sense because it will almost always be changing something about the
    context in which memory accesses are done, so in general we don't want
    memory accesses getting moved from one side of an mtmsr to the other.
    
    With the barrier in mtmsr(), some of the explicit barriers in
    hw_irq.h are now redundant, so this removes them.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index fb359b0a6937..a3c28e46947c 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -745,11 +745,11 @@
 			asm volatile("mfmsr %0" : "=r" (rval)); rval;})
 #ifdef CONFIG_PPC64
 #define __mtmsrd(v, l)	asm volatile("mtmsrd %0," __stringify(l) \
-				     : : "r" (v))
+				     : : "r" (v) : "memory")
 #define mtmsrd(v)	__mtmsrd((v), 0)
 #define mtmsr(v)	mtmsrd(v)
 #else
-#define mtmsr(v)	asm volatile("mtmsr %0" : : "r" (v))
+#define mtmsr(v)	asm volatile("mtmsr %0" : : "r" (v) : "memory")
 #endif
 
 #define mfspr(rn)	({unsigned long rval; \

commit 0bbd0d4be8d5d3676c126e06e3c75c16def00441
Author: Paul Mackerras <paulus@samba.org>
Date:   Thu May 14 13:31:48 2009 +1000

    perf_counter: powerpc: supply more precise information on counter overflow events
    
    This uses values from the MMCRA, SIAR and SDAR registers on
    powerpc to supply more precise information for overflow events,
    including a data address when PERF_RECORD_ADDR is specified.
    
    Since POWER6 uses different bit positions in MMCRA from earlier
    processors, this converts the struct power_pmu limited_pmc5_6
    field, which only had 0/1 values, into a flags field and
    defines bit values for its previous use (PPMU_LIMITED_PMC5_6)
    and a new flag (PPMU_ALT_SIPR) to indicate that the processor
    uses the POWER6 bit positions rather than the earlier
    positions.  It also adds definitions in reg.h for the new and
    old positions of the bit that indicates that the SIAR and SDAR
    values come from the same instruction.
    
    For the data address, the SDAR value is supplied if we are not
    doing instruction sampling.  In that case there is no guarantee
    that the address given in the PERF_RECORD_ADDR subrecord will
    correspond to the instruction whose address is given in the
    PERF_RECORD_IP subrecord.
    
    If instruction sampling is enabled (e.g. because this counter
    is counting a marked instruction event), then we only supply
    the SDAR value for the PERF_RECORD_ADDR subrecord if it
    corresponds to the instruction whose address is in the
    PERF_RECORD_IP subrecord.  Otherwise we supply 0.
    
    [ Impact: support more PMU hardware features on PowerPC ]
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    LKML-Reference: <18955.37028.48861.555309@drongo.ozlabs.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index e8018d540e87..fb359b0a6937 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -492,11 +492,13 @@
 #define   MMCR0_FCHV	0x00000001UL /* freeze conditions in hypervisor mode */
 #define SPRN_MMCR1	798
 #define SPRN_MMCRA	0x312
+#define   MMCRA_SDSYNC	0x80000000UL /* SDAR synced with SIAR */
 #define   MMCRA_SIHV	0x10000000UL /* state of MSR HV when SIAR set */
 #define   MMCRA_SIPR	0x08000000UL /* state of MSR PR when SIAR set */
 #define   MMCRA_SLOT	0x07000000UL /* SLOT bits (37-39) */
 #define   MMCRA_SLOT_SHIFT	24
 #define   MMCRA_SAMPLE_ENABLE 0x00000001UL /* enable sampling */
+#define   POWER6_MMCRA_SDSYNC 0x0000080000000000ULL	/* SDAR/SIAR synced */
 #define   POWER6_MMCRA_SIHV   0x0000040000000000ULL
 #define   POWER6_MMCRA_SIPR   0x0000020000000000ULL
 #define   POWER6_MMCRA_THRM	0x00000020UL

commit 39fd09320b2d952c360b430c70846f8fa0244a51
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Wed Apr 1 16:25:33 2009 -0500

    powerpc: Move SPEFSCR defines to common header
    
    SPEFSCR is a user space register and doesn't conflict with anything.
    Moving the defines of the various bit fields makes some emulation
    code have fewer ifdefs
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c9ff1ec97479..e8018d540e87 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -143,6 +143,36 @@
 #define FPSCR_NI	0x00000004	/* FPU non IEEE-Mode */
 #define FPSCR_RN	0x00000003	/* FPU rounding control */
 
+/* Bit definitions for SPEFSCR. */
+#define SPEFSCR_SOVH	0x80000000	/* Summary integer overflow high */
+#define SPEFSCR_OVH	0x40000000	/* Integer overflow high */
+#define SPEFSCR_FGH	0x20000000	/* Embedded FP guard bit high */
+#define SPEFSCR_FXH	0x10000000	/* Embedded FP sticky bit high */
+#define SPEFSCR_FINVH	0x08000000	/* Embedded FP invalid operation high */
+#define SPEFSCR_FDBZH	0x04000000	/* Embedded FP div by zero high */
+#define SPEFSCR_FUNFH	0x02000000	/* Embedded FP underflow high */
+#define SPEFSCR_FOVFH	0x01000000	/* Embedded FP overflow high */
+#define SPEFSCR_FINXS	0x00200000	/* Embedded FP inexact sticky */
+#define SPEFSCR_FINVS	0x00100000	/* Embedded FP invalid op. sticky */
+#define SPEFSCR_FDBZS	0x00080000	/* Embedded FP div by zero sticky */
+#define SPEFSCR_FUNFS	0x00040000	/* Embedded FP underflow sticky */
+#define SPEFSCR_FOVFS	0x00020000	/* Embedded FP overflow sticky */
+#define SPEFSCR_MODE	0x00010000	/* Embedded FP mode */
+#define SPEFSCR_SOV	0x00008000	/* Integer summary overflow */
+#define SPEFSCR_OV	0x00004000	/* Integer overflow */
+#define SPEFSCR_FG	0x00002000	/* Embedded FP guard bit */
+#define SPEFSCR_FX	0x00001000	/* Embedded FP sticky bit */
+#define SPEFSCR_FINV	0x00000800	/* Embedded FP invalid operation */
+#define SPEFSCR_FDBZ	0x00000400	/* Embedded FP div by zero */
+#define SPEFSCR_FUNF	0x00000200	/* Embedded FP underflow */
+#define SPEFSCR_FOVF	0x00000100	/* Embedded FP overflow */
+#define SPEFSCR_FINXE	0x00000040	/* Embedded FP inexact enable */
+#define SPEFSCR_FINVE	0x00000020	/* Embedded FP invalid op. enable */
+#define SPEFSCR_FDBZE	0x00000010	/* Embedded FP div by zero enable */
+#define SPEFSCR_FUNFE	0x00000008	/* Embedded FP underflow enable */
+#define SPEFSCR_FOVFE	0x00000004	/* Embedded FP overflow enable */
+#define SPEFSCR_FRMC 	0x00000003	/* Embedded FP rounding mode control */
+
 /* Special Purpose Registers (SPRNs)*/
 #define SPRN_CTR	0x009	/* Count Register */
 #define SPRN_DSCR	0x11

commit c9c38320e80aea06f1b5541a20be8bda508691e3
Author: Geoff Levand <geoffrey.levand@am.sony.com>
Date:   Tue Mar 3 08:33:05 2009 +0000

    powerpc: Add missing DABR flags
    
    The powerpc 64 bit architecture defines three flags for the
    DABR (Data Address Breakpoint Register).  Add definitions
    for the currently missing DABR_DATA_WRITE and DABR_DATA_READ
    flags to the powerpc reg.h file.
    
    Signed-off-by: Geoff Levand <geoffrey.levand@am.sony.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index f484a343efba..c9ff1ec97479 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -155,6 +155,8 @@
 #define   CTRL_RUNLATCH	0x1
 #define SPRN_DABR	0x3F5	/* Data Address Breakpoint Register */
 #define   DABR_TRANSLATION	(1UL << 2)
+#define   DABR_DATA_WRITE	(1UL << 1)
+#define   DABR_DATA_READ	(1UL << 0)
 #define SPRN_DABR2	0x13D	/* e300 */
 #define SPRN_DABRX	0x3F7	/* Data Address Breakpoint Register Extension */
 #define   DABRX_USER	(1UL << 0)

commit 322b439455ea62e6480e300c77b258e872896381
Author: Anton Vorontsov <avorontsov@ru.mvista.com>
Date:   Wed Dec 17 10:08:55 2008 +0000

    powerpc: Prepare xmon_save_regs for use with kdump
    
    Today the arch/powerpc/xmon/setjmp.S file contains only the
    xmon_save_regs function.  We want to use it for kdump purposes, so
    let's move the file into arch/powerpc/kernel/ and give the function a
    more generic name (ppc_save_regs).
    
    Signed-off-by: Anton Vorontsov <avorontsov@ru.mvista.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
index c6d1ab650778..f484a343efba 100644
--- a/arch/powerpc/include/asm/reg.h
+++ b/arch/powerpc/include/asm/reg.h
@@ -783,6 +783,10 @@ extern void scom970_write(unsigned int address, unsigned long value);
 #define __get_SP()	({unsigned long sp; \
 			asm volatile("mr %0,1": "=r" (sp)); sp;})
 
+struct pt_regs;
+
+extern void ppc_save_regs(struct pt_regs *regs);
+
 #endif /* __ASSEMBLY__ */
 #endif /* __KERNEL__ */
 #endif /* _ASM_POWERPC_REG_H */

commit b8b572e1015f81b4e748417be2629dfe51ab99f9
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Fri Aug 1 15:20:30 2008 +1000

    powerpc: Move include files to arch/powerpc/include/asm
    
    from include/asm-powerpc.  This is the result of a
    
    mkdir arch/powerpc/include/asm
    git mv include/asm-powerpc/* arch/powerpc/include/asm
    
    Followed by a few documentation/comment fixups and a couple of places
    where <asm-powepc/...> was being used explicitly.  Of the latter only
    one was outside the arch code and it is a driver only built for powerpc.
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
new file mode 100644
index 000000000000..c6d1ab650778
--- /dev/null
+++ b/arch/powerpc/include/asm/reg.h
@@ -0,0 +1,788 @@
+/*
+ * Contains the definition of registers common to all PowerPC variants.
+ * If a register definition has been changed in a different PowerPC
+ * variant, we will case it in #ifndef XXX ... #endif, and have the
+ * number used in the Programming Environments Manual For 32-Bit
+ * Implementations of the PowerPC Architecture (a.k.a. Green Book) here.
+ */
+
+#ifndef _ASM_POWERPC_REG_H
+#define _ASM_POWERPC_REG_H
+#ifdef __KERNEL__
+
+#include <linux/stringify.h>
+#include <asm/cputable.h>
+
+/* Pickup Book E specific registers. */
+#if defined(CONFIG_BOOKE) || defined(CONFIG_40x)
+#include <asm/reg_booke.h>
+#endif /* CONFIG_BOOKE || CONFIG_40x */
+
+#ifdef CONFIG_FSL_EMB_PERFMON
+#include <asm/reg_fsl_emb.h>
+#endif
+
+#ifdef CONFIG_8xx
+#include <asm/reg_8xx.h>
+#endif /* CONFIG_8xx */
+
+#define MSR_SF_LG	63              /* Enable 64 bit mode */
+#define MSR_ISF_LG	61              /* Interrupt 64b mode valid on 630 */
+#define MSR_HV_LG 	60              /* Hypervisor state */
+#define MSR_VEC_LG	25	        /* Enable AltiVec */
+#define MSR_VSX_LG	23		/* Enable VSX */
+#define MSR_POW_LG	18		/* Enable Power Management */
+#define MSR_WE_LG	18		/* Wait State Enable */
+#define MSR_TGPR_LG	17		/* TLB Update registers in use */
+#define MSR_CE_LG	17		/* Critical Interrupt Enable */
+#define MSR_ILE_LG	16		/* Interrupt Little Endian */
+#define MSR_EE_LG	15		/* External Interrupt Enable */
+#define MSR_PR_LG	14		/* Problem State / Privilege Level */
+#define MSR_FP_LG	13		/* Floating Point enable */
+#define MSR_ME_LG	12		/* Machine Check Enable */
+#define MSR_FE0_LG	11		/* Floating Exception mode 0 */
+#define MSR_SE_LG	10		/* Single Step */
+#define MSR_BE_LG	9		/* Branch Trace */
+#define MSR_DE_LG	9 		/* Debug Exception Enable */
+#define MSR_FE1_LG	8		/* Floating Exception mode 1 */
+#define MSR_IP_LG	6		/* Exception prefix 0x000/0xFFF */
+#define MSR_IR_LG	5 		/* Instruction Relocate */
+#define MSR_DR_LG	4 		/* Data Relocate */
+#define MSR_PE_LG	3		/* Protection Enable */
+#define MSR_PX_LG	2		/* Protection Exclusive Mode */
+#define MSR_PMM_LG	2		/* Performance monitor */
+#define MSR_RI_LG	1		/* Recoverable Exception */
+#define MSR_LE_LG	0 		/* Little Endian */
+
+#ifdef __ASSEMBLY__
+#define __MASK(X)	(1<<(X))
+#else
+#define __MASK(X)	(1UL<<(X))
+#endif
+
+#ifdef CONFIG_PPC64
+#define MSR_SF		__MASK(MSR_SF_LG)	/* Enable 64 bit mode */
+#define MSR_ISF		__MASK(MSR_ISF_LG)	/* Interrupt 64b mode valid on 630 */
+#define MSR_HV 		__MASK(MSR_HV_LG)	/* Hypervisor state */
+#else
+/* so tests for these bits fail on 32-bit */
+#define MSR_SF		0
+#define MSR_ISF		0
+#define MSR_HV		0
+#endif
+
+#define MSR_VEC		__MASK(MSR_VEC_LG)	/* Enable AltiVec */
+#define MSR_VSX		__MASK(MSR_VSX_LG)	/* Enable VSX */
+#define MSR_POW		__MASK(MSR_POW_LG)	/* Enable Power Management */
+#define MSR_WE		__MASK(MSR_WE_LG)	/* Wait State Enable */
+#define MSR_TGPR	__MASK(MSR_TGPR_LG)	/* TLB Update registers in use */
+#define MSR_CE		__MASK(MSR_CE_LG)	/* Critical Interrupt Enable */
+#define MSR_ILE		__MASK(MSR_ILE_LG)	/* Interrupt Little Endian */
+#define MSR_EE		__MASK(MSR_EE_LG)	/* External Interrupt Enable */
+#define MSR_PR		__MASK(MSR_PR_LG)	/* Problem State / Privilege Level */
+#define MSR_FP		__MASK(MSR_FP_LG)	/* Floating Point enable */
+#define MSR_ME		__MASK(MSR_ME_LG)	/* Machine Check Enable */
+#define MSR_FE0		__MASK(MSR_FE0_LG)	/* Floating Exception mode 0 */
+#define MSR_SE		__MASK(MSR_SE_LG)	/* Single Step */
+#define MSR_BE		__MASK(MSR_BE_LG)	/* Branch Trace */
+#define MSR_DE		__MASK(MSR_DE_LG)	/* Debug Exception Enable */
+#define MSR_FE1		__MASK(MSR_FE1_LG)	/* Floating Exception mode 1 */
+#define MSR_IP		__MASK(MSR_IP_LG)	/* Exception prefix 0x000/0xFFF */
+#define MSR_IR		__MASK(MSR_IR_LG)	/* Instruction Relocate */
+#define MSR_DR		__MASK(MSR_DR_LG)	/* Data Relocate */
+#define MSR_PE		__MASK(MSR_PE_LG)	/* Protection Enable */
+#define MSR_PX		__MASK(MSR_PX_LG)	/* Protection Exclusive Mode */
+#ifndef MSR_PMM
+#define MSR_PMM		__MASK(MSR_PMM_LG)	/* Performance monitor */
+#endif
+#define MSR_RI		__MASK(MSR_RI_LG)	/* Recoverable Exception */
+#define MSR_LE		__MASK(MSR_LE_LG)	/* Little Endian */
+
+#ifdef CONFIG_PPC64
+#define MSR_		MSR_ME | MSR_RI | MSR_IR | MSR_DR | MSR_ISF |MSR_HV
+#define MSR_KERNEL      MSR_ | MSR_SF
+
+#define MSR_USER32	MSR_ | MSR_PR | MSR_EE
+#define MSR_USER64	MSR_USER32 | MSR_SF
+
+#else /* 32-bit */
+/* Default MSR for kernel mode. */
+#ifndef MSR_KERNEL	/* reg_booke.h also defines this */
+#define MSR_KERNEL	(MSR_ME|MSR_RI|MSR_IR|MSR_DR)
+#endif
+
+#define MSR_USER	(MSR_KERNEL|MSR_PR|MSR_EE)
+#endif
+
+/* Floating Point Status and Control Register (FPSCR) Fields */
+#define FPSCR_FX	0x80000000	/* FPU exception summary */
+#define FPSCR_FEX	0x40000000	/* FPU enabled exception summary */
+#define FPSCR_VX	0x20000000	/* Invalid operation summary */
+#define FPSCR_OX	0x10000000	/* Overflow exception summary */
+#define FPSCR_UX	0x08000000	/* Underflow exception summary */
+#define FPSCR_ZX	0x04000000	/* Zero-divide exception summary */
+#define FPSCR_XX	0x02000000	/* Inexact exception summary */
+#define FPSCR_VXSNAN	0x01000000	/* Invalid op for SNaN */
+#define FPSCR_VXISI	0x00800000	/* Invalid op for Inv - Inv */
+#define FPSCR_VXIDI	0x00400000	/* Invalid op for Inv / Inv */
+#define FPSCR_VXZDZ	0x00200000	/* Invalid op for Zero / Zero */
+#define FPSCR_VXIMZ	0x00100000	/* Invalid op for Inv * Zero */
+#define FPSCR_VXVC	0x00080000	/* Invalid op for Compare */
+#define FPSCR_FR	0x00040000	/* Fraction rounded */
+#define FPSCR_FI	0x00020000	/* Fraction inexact */
+#define FPSCR_FPRF	0x0001f000	/* FPU Result Flags */
+#define FPSCR_FPCC	0x0000f000	/* FPU Condition Codes */
+#define FPSCR_VXSOFT	0x00000400	/* Invalid op for software request */
+#define FPSCR_VXSQRT	0x00000200	/* Invalid op for square root */
+#define FPSCR_VXCVI	0x00000100	/* Invalid op for integer convert */
+#define FPSCR_VE	0x00000080	/* Invalid op exception enable */
+#define FPSCR_OE	0x00000040	/* IEEE overflow exception enable */
+#define FPSCR_UE	0x00000020	/* IEEE underflow exception enable */
+#define FPSCR_ZE	0x00000010	/* IEEE zero divide exception enable */
+#define FPSCR_XE	0x00000008	/* FP inexact exception enable */
+#define FPSCR_NI	0x00000004	/* FPU non IEEE-Mode */
+#define FPSCR_RN	0x00000003	/* FPU rounding control */
+
+/* Special Purpose Registers (SPRNs)*/
+#define SPRN_CTR	0x009	/* Count Register */
+#define SPRN_DSCR	0x11
+#define SPRN_CTRLF	0x088
+#define SPRN_CTRLT	0x098
+#define   CTRL_CT	0xc0000000	/* current thread */
+#define   CTRL_CT0	0x80000000	/* thread 0 */
+#define   CTRL_CT1	0x40000000	/* thread 1 */
+#define   CTRL_TE	0x00c00000	/* thread enable */
+#define   CTRL_RUNLATCH	0x1
+#define SPRN_DABR	0x3F5	/* Data Address Breakpoint Register */
+#define   DABR_TRANSLATION	(1UL << 2)
+#define SPRN_DABR2	0x13D	/* e300 */
+#define SPRN_DABRX	0x3F7	/* Data Address Breakpoint Register Extension */
+#define   DABRX_USER	(1UL << 0)
+#define   DABRX_KERNEL	(1UL << 1)
+#define SPRN_DAR	0x013	/* Data Address Register */
+#define SPRN_DBCR	0x136	/* e300 Data Breakpoint Control Reg */
+#define SPRN_DSISR	0x012	/* Data Storage Interrupt Status Register */
+#define   DSISR_NOHPTE		0x40000000	/* no translation found */
+#define   DSISR_PROTFAULT	0x08000000	/* protection fault */
+#define   DSISR_ISSTORE		0x02000000	/* access was a store */
+#define   DSISR_DABRMATCH	0x00400000	/* hit data breakpoint */
+#define   DSISR_NOSEGMENT	0x00200000	/* STAB/SLB miss */
+#define SPRN_TBRL	0x10C	/* Time Base Read Lower Register (user, R/O) */
+#define SPRN_TBRU	0x10D	/* Time Base Read Upper Register (user, R/O) */
+#define SPRN_TBWL	0x11C	/* Time Base Lower Register (super, R/W) */
+#define SPRN_TBWU	0x11D	/* Time Base Upper Register (super, R/W) */
+#define SPRN_SPURR	0x134	/* Scaled PURR */
+#define SPRN_HIOR	0x137	/* 970 Hypervisor interrupt offset */
+#define SPRN_LPCR	0x13E	/* LPAR Control Register */
+#define SPRN_DBAT0L	0x219	/* Data BAT 0 Lower Register */
+#define SPRN_DBAT0U	0x218	/* Data BAT 0 Upper Register */
+#define SPRN_DBAT1L	0x21B	/* Data BAT 1 Lower Register */
+#define SPRN_DBAT1U	0x21A	/* Data BAT 1 Upper Register */
+#define SPRN_DBAT2L	0x21D	/* Data BAT 2 Lower Register */
+#define SPRN_DBAT2U	0x21C	/* Data BAT 2 Upper Register */
+#define SPRN_DBAT3L	0x21F	/* Data BAT 3 Lower Register */
+#define SPRN_DBAT3U	0x21E	/* Data BAT 3 Upper Register */
+#define SPRN_DBAT4L	0x239	/* Data BAT 4 Lower Register */
+#define SPRN_DBAT4U	0x238	/* Data BAT 4 Upper Register */
+#define SPRN_DBAT5L	0x23B	/* Data BAT 5 Lower Register */
+#define SPRN_DBAT5U	0x23A	/* Data BAT 5 Upper Register */
+#define SPRN_DBAT6L	0x23D	/* Data BAT 6 Lower Register */
+#define SPRN_DBAT6U	0x23C	/* Data BAT 6 Upper Register */
+#define SPRN_DBAT7L	0x23F	/* Data BAT 7 Lower Register */
+#define SPRN_DBAT7U	0x23E	/* Data BAT 7 Upper Register */
+
+#define SPRN_DEC	0x016		/* Decrement Register */
+#define SPRN_DER	0x095		/* Debug Enable Regsiter */
+#define DER_RSTE	0x40000000	/* Reset Interrupt */
+#define DER_CHSTPE	0x20000000	/* Check Stop */
+#define DER_MCIE	0x10000000	/* Machine Check Interrupt */
+#define DER_EXTIE	0x02000000	/* External Interrupt */
+#define DER_ALIE	0x01000000	/* Alignment Interrupt */
+#define DER_PRIE	0x00800000	/* Program Interrupt */
+#define DER_FPUVIE	0x00400000	/* FP Unavailable Interrupt */
+#define DER_DECIE	0x00200000	/* Decrementer Interrupt */
+#define DER_SYSIE	0x00040000	/* System Call Interrupt */
+#define DER_TRE		0x00020000	/* Trace Interrupt */
+#define DER_SEIE	0x00004000	/* FP SW Emulation Interrupt */
+#define DER_ITLBMSE	0x00002000	/* Imp. Spec. Instruction TLB Miss */
+#define DER_ITLBERE	0x00001000	/* Imp. Spec. Instruction TLB Error */
+#define DER_DTLBMSE	0x00000800	/* Imp. Spec. Data TLB Miss */
+#define DER_DTLBERE	0x00000400	/* Imp. Spec. Data TLB Error */
+#define DER_LBRKE	0x00000008	/* Load/Store Breakpoint Interrupt */
+#define DER_IBRKE	0x00000004	/* Instruction Breakpoint Interrupt */
+#define DER_EBRKE	0x00000002	/* External Breakpoint Interrupt */
+#define DER_DPIE	0x00000001	/* Dev. Port Nonmaskable Request */
+#define SPRN_DMISS	0x3D0		/* Data TLB Miss Register */
+#define SPRN_EAR	0x11A		/* External Address Register */
+#define SPRN_HASH1	0x3D2		/* Primary Hash Address Register */
+#define SPRN_HASH2	0x3D3		/* Secondary Hash Address Resgister */
+#define SPRN_HID0	0x3F0		/* Hardware Implementation Register 0 */
+#define HID0_EMCP	(1<<31)		/* Enable Machine Check pin */
+#define HID0_EBA	(1<<29)		/* Enable Bus Address Parity */
+#define HID0_EBD	(1<<28)		/* Enable Bus Data Parity */
+#define HID0_SBCLK	(1<<27)
+#define HID0_EICE	(1<<26)
+#define HID0_TBEN	(1<<26)		/* Timebase enable - 745x */
+#define HID0_ECLK	(1<<25)
+#define HID0_PAR	(1<<24)
+#define HID0_STEN	(1<<24)		/* Software table search enable - 745x */
+#define HID0_HIGH_BAT	(1<<23)		/* Enable high BATs - 7455 */
+#define HID0_DOZE	(1<<23)
+#define HID0_NAP	(1<<22)
+#define HID0_SLEEP	(1<<21)
+#define HID0_DPM	(1<<20)
+#define HID0_BHTCLR	(1<<18)		/* Clear branch history table - 7450 */
+#define HID0_XAEN	(1<<17)		/* Extended addressing enable - 7450 */
+#define HID0_NHR	(1<<16)		/* Not hard reset (software bit-7450)*/
+#define HID0_ICE	(1<<15)		/* Instruction Cache Enable */
+#define HID0_DCE	(1<<14)		/* Data Cache Enable */
+#define HID0_ILOCK	(1<<13)		/* Instruction Cache Lock */
+#define HID0_DLOCK	(1<<12)		/* Data Cache Lock */
+#define HID0_ICFI	(1<<11)		/* Instr. Cache Flash Invalidate */
+#define HID0_DCI	(1<<10)		/* Data Cache Invalidate */
+#define HID0_SPD	(1<<9)		/* Speculative disable */
+#define HID0_DAPUEN	(1<<8)		/* Debug APU enable */
+#define HID0_SGE	(1<<7)		/* Store Gathering Enable */
+#define HID0_SIED	(1<<7)		/* Serial Instr. Execution [Disable] */
+#define HID0_DCFA	(1<<6)		/* Data Cache Flush Assist */
+#define HID0_LRSTK	(1<<4)		/* Link register stack - 745x */
+#define HID0_BTIC	(1<<5)		/* Branch Target Instr Cache Enable */
+#define HID0_ABE	(1<<3)		/* Address Broadcast Enable */
+#define HID0_FOLD	(1<<3)		/* Branch Folding enable - 745x */
+#define HID0_BHTE	(1<<2)		/* Branch History Table Enable */
+#define HID0_BTCD	(1<<1)		/* Branch target cache disable */
+#define HID0_NOPDST	(1<<1)		/* No-op dst, dstt, etc. instr. */
+#define HID0_NOPTI	(1<<0)		/* No-op dcbt and dcbst instr. */
+
+#define SPRN_HID1	0x3F1		/* Hardware Implementation Register 1 */
+#define HID1_EMCP	(1<<31)		/* 7450 Machine Check Pin Enable */
+#define HID1_DFS	(1<<22)		/* 7447A Dynamic Frequency Scaling */
+#define HID1_PC0	(1<<16)		/* 7450 PLL_CFG[0] */
+#define HID1_PC1	(1<<15)		/* 7450 PLL_CFG[1] */
+#define HID1_PC2	(1<<14)		/* 7450 PLL_CFG[2] */
+#define HID1_PC3	(1<<13)		/* 7450 PLL_CFG[3] */
+#define HID1_SYNCBE	(1<<11)		/* 7450 ABE for sync, eieio */
+#define HID1_ABE	(1<<10)		/* 7450 Address Broadcast Enable */
+#define HID1_PS		(1<<16)		/* 750FX PLL selection */
+#define SPRN_HID2	0x3F8		/* Hardware Implementation Register 2 */
+#define SPRN_IABR	0x3F2	/* Instruction Address Breakpoint Register */
+#define SPRN_IABR2	0x3FA		/* 83xx */
+#define SPRN_IBCR	0x135		/* 83xx Insn Breakpoint Control Reg */
+#define SPRN_HID4	0x3F4		/* 970 HID4 */
+#define SPRN_HID5	0x3F6		/* 970 HID5 */
+#define SPRN_HID6	0x3F9	/* BE HID 6 */
+#define   HID6_LB	(0x0F<<12) /* Concurrent Large Page Modes */
+#define   HID6_DLP	(1<<20)	/* Disable all large page modes (4K only) */
+#define SPRN_TSC_CELL	0x399	/* Thread switch control on Cell */
+#define   TSC_CELL_DEC_ENABLE_0	0x400000 /* Decrementer Interrupt */
+#define   TSC_CELL_DEC_ENABLE_1	0x200000 /* Decrementer Interrupt */
+#define   TSC_CELL_EE_ENABLE	0x100000 /* External Interrupt */
+#define   TSC_CELL_EE_BOOST	0x080000 /* External Interrupt Boost */
+#define SPRN_TSC 	0x3FD	/* Thread switch control on others */
+#define SPRN_TST 	0x3FC	/* Thread switch timeout on others */
+#if !defined(SPRN_IAC1) && !defined(SPRN_IAC2)
+#define SPRN_IAC1	0x3F4		/* Instruction Address Compare 1 */
+#define SPRN_IAC2	0x3F5		/* Instruction Address Compare 2 */
+#endif
+#define SPRN_IBAT0L	0x211		/* Instruction BAT 0 Lower Register */
+#define SPRN_IBAT0U	0x210		/* Instruction BAT 0 Upper Register */
+#define SPRN_IBAT1L	0x213		/* Instruction BAT 1 Lower Register */
+#define SPRN_IBAT1U	0x212		/* Instruction BAT 1 Upper Register */
+#define SPRN_IBAT2L	0x215		/* Instruction BAT 2 Lower Register */
+#define SPRN_IBAT2U	0x214		/* Instruction BAT 2 Upper Register */
+#define SPRN_IBAT3L	0x217		/* Instruction BAT 3 Lower Register */
+#define SPRN_IBAT3U	0x216		/* Instruction BAT 3 Upper Register */
+#define SPRN_IBAT4L	0x231		/* Instruction BAT 4 Lower Register */
+#define SPRN_IBAT4U	0x230		/* Instruction BAT 4 Upper Register */
+#define SPRN_IBAT5L	0x233		/* Instruction BAT 5 Lower Register */
+#define SPRN_IBAT5U	0x232		/* Instruction BAT 5 Upper Register */
+#define SPRN_IBAT6L	0x235		/* Instruction BAT 6 Lower Register */
+#define SPRN_IBAT6U	0x234		/* Instruction BAT 6 Upper Register */
+#define SPRN_IBAT7L	0x237		/* Instruction BAT 7 Lower Register */
+#define SPRN_IBAT7U	0x236		/* Instruction BAT 7 Upper Register */
+#define SPRN_ICMP	0x3D5		/* Instruction TLB Compare Register */
+#define SPRN_ICTC	0x3FB	/* Instruction Cache Throttling Control Reg */
+#define SPRN_ICTRL	0x3F3	/* 1011 7450 icache and interrupt ctrl */
+#define ICTRL_EICE	0x08000000	/* enable icache parity errs */
+#define ICTRL_EDC	0x04000000	/* enable dcache parity errs */
+#define ICTRL_EICP	0x00000100	/* enable icache par. check */
+#define SPRN_IMISS	0x3D4		/* Instruction TLB Miss Register */
+#define SPRN_IMMR	0x27E		/* Internal Memory Map Register */
+#define SPRN_L2CR	0x3F9		/* Level 2 Cache Control Regsiter */
+#define SPRN_L2CR2	0x3f8
+#define L2CR_L2E		0x80000000	/* L2 enable */
+#define L2CR_L2PE		0x40000000	/* L2 parity enable */
+#define L2CR_L2SIZ_MASK		0x30000000	/* L2 size mask */
+#define L2CR_L2SIZ_256KB	0x10000000	/* L2 size 256KB */
+#define L2CR_L2SIZ_512KB	0x20000000	/* L2 size 512KB */
+#define L2CR_L2SIZ_1MB		0x30000000	/* L2 size 1MB */
+#define L2CR_L2CLK_MASK		0x0e000000	/* L2 clock mask */
+#define L2CR_L2CLK_DISABLED	0x00000000	/* L2 clock disabled */
+#define L2CR_L2CLK_DIV1		0x02000000	/* L2 clock / 1 */
+#define L2CR_L2CLK_DIV1_5	0x04000000	/* L2 clock / 1.5 */
+#define L2CR_L2CLK_DIV2		0x08000000	/* L2 clock / 2 */
+#define L2CR_L2CLK_DIV2_5	0x0a000000	/* L2 clock / 2.5 */
+#define L2CR_L2CLK_DIV3		0x0c000000	/* L2 clock / 3 */
+#define L2CR_L2RAM_MASK		0x01800000	/* L2 RAM type mask */
+#define L2CR_L2RAM_FLOW		0x00000000	/* L2 RAM flow through */
+#define L2CR_L2RAM_PIPE		0x01000000	/* L2 RAM pipelined */
+#define L2CR_L2RAM_PIPE_LW	0x01800000	/* L2 RAM pipelined latewr */
+#define L2CR_L2DO		0x00400000	/* L2 data only */
+#define L2CR_L2I		0x00200000	/* L2 global invalidate */
+#define L2CR_L2CTL		0x00100000	/* L2 RAM control */
+#define L2CR_L2WT		0x00080000	/* L2 write-through */
+#define L2CR_L2TS		0x00040000	/* L2 test support */
+#define L2CR_L2OH_MASK		0x00030000	/* L2 output hold mask */
+#define L2CR_L2OH_0_5		0x00000000	/* L2 output hold 0.5 ns */
+#define L2CR_L2OH_1_0		0x00010000	/* L2 output hold 1.0 ns */
+#define L2CR_L2SL		0x00008000	/* L2 DLL slow */
+#define L2CR_L2DF		0x00004000	/* L2 differential clock */
+#define L2CR_L2BYP		0x00002000	/* L2 DLL bypass */
+#define L2CR_L2IP		0x00000001	/* L2 GI in progress */
+#define L2CR_L2IO_745x		0x00100000	/* L2 instr. only (745x) */
+#define L2CR_L2DO_745x		0x00010000	/* L2 data only (745x) */
+#define L2CR_L2REP_745x		0x00001000	/* L2 repl. algorithm (745x) */
+#define L2CR_L2HWF_745x		0x00000800	/* L2 hardware flush (745x) */
+#define SPRN_L3CR		0x3FA	/* Level 3 Cache Control Regsiter */
+#define L3CR_L3E		0x80000000	/* L3 enable */
+#define L3CR_L3PE		0x40000000	/* L3 data parity enable */
+#define L3CR_L3APE		0x20000000	/* L3 addr parity enable */
+#define L3CR_L3SIZ		0x10000000	/* L3 size */
+#define L3CR_L3CLKEN		0x08000000	/* L3 clock enable */
+#define L3CR_L3RES		0x04000000	/* L3 special reserved bit */
+#define L3CR_L3CLKDIV		0x03800000	/* L3 clock divisor */
+#define L3CR_L3IO		0x00400000	/* L3 instruction only */
+#define L3CR_L3SPO		0x00040000	/* L3 sample point override */
+#define L3CR_L3CKSP		0x00030000	/* L3 clock sample point */
+#define L3CR_L3PSP		0x0000e000	/* L3 P-clock sample point */
+#define L3CR_L3REP		0x00001000	/* L3 replacement algorithm */
+#define L3CR_L3HWF		0x00000800	/* L3 hardware flush */
+#define L3CR_L3I		0x00000400	/* L3 global invalidate */
+#define L3CR_L3RT		0x00000300	/* L3 SRAM type */
+#define L3CR_L3NIRCA		0x00000080	/* L3 non-integer ratio clock adj. */
+#define L3CR_L3DO		0x00000040	/* L3 data only mode */
+#define L3CR_PMEN		0x00000004	/* L3 private memory enable */
+#define L3CR_PMSIZ		0x00000001	/* L3 private memory size */
+
+#define SPRN_MSSCR0	0x3f6	/* Memory Subsystem Control Register 0 */
+#define SPRN_MSSSR0	0x3f7	/* Memory Subsystem Status Register 1 */
+#define SPRN_LDSTCR	0x3f8	/* Load/Store control register */
+#define SPRN_LDSTDB	0x3f4	/* */
+#define SPRN_LR		0x008	/* Link Register */
+#ifndef SPRN_PIR
+#define SPRN_PIR	0x3FF	/* Processor Identification Register */
+#endif
+#define SPRN_PTEHI	0x3D5	/* 981 7450 PTE HI word (S/W TLB load) */
+#define SPRN_PTELO	0x3D6	/* 982 7450 PTE LO word (S/W TLB load) */
+#define SPRN_PURR	0x135	/* Processor Utilization of Resources Reg */
+#define SPRN_PVR	0x11F	/* Processor Version Register */
+#define SPRN_RPA	0x3D6	/* Required Physical Address Register */
+#define SPRN_SDA	0x3BF	/* Sampled Data Address Register */
+#define SPRN_SDR1	0x019	/* MMU Hash Base Register */
+#define SPRN_ASR	0x118   /* Address Space Register */
+#define SPRN_SIA	0x3BB	/* Sampled Instruction Address Register */
+#define SPRN_SPRG0	0x110	/* Special Purpose Register General 0 */
+#define SPRN_SPRG1	0x111	/* Special Purpose Register General 1 */
+#define SPRN_SPRG2	0x112	/* Special Purpose Register General 2 */
+#define SPRN_SPRG3	0x113	/* Special Purpose Register General 3 */
+#define SPRN_SPRG4	0x114	/* Special Purpose Register General 4 */
+#define SPRN_SPRG5	0x115	/* Special Purpose Register General 5 */
+#define SPRN_SPRG6	0x116	/* Special Purpose Register General 6 */
+#define SPRN_SPRG7	0x117	/* Special Purpose Register General 7 */
+#define SPRN_SRR0	0x01A	/* Save/Restore Register 0 */
+#define SPRN_SRR1	0x01B	/* Save/Restore Register 1 */
+#define   SRR1_WAKEMASK		0x00380000 /* reason for wakeup */
+#define   SRR1_WAKERESET	0x00380000 /* System reset */
+#define   SRR1_WAKESYSERR	0x00300000 /* System error */
+#define   SRR1_WAKEEE		0x00200000 /* External interrupt */
+#define   SRR1_WAKEMT		0x00280000 /* mtctrl */
+#define   SRR1_WAKEDEC		0x00180000 /* Decrementer interrupt */
+#define   SRR1_WAKETHERM	0x00100000 /* Thermal management interrupt */
+#define SPRN_HSRR0	0x13A	/* Save/Restore Register 0 */
+#define SPRN_HSRR1	0x13B	/* Save/Restore Register 1 */
+
+#define SPRN_TBCTL	0x35f	/* PA6T Timebase control register */
+#define   TBCTL_FREEZE		0x0000000000000000ull /* Freeze all tbs */
+#define   TBCTL_RESTART		0x0000000100000000ull /* Restart all tbs */
+#define   TBCTL_UPDATE_UPPER	0x0000000200000000ull /* Set upper 32 bits */
+#define   TBCTL_UPDATE_LOWER	0x0000000300000000ull /* Set lower 32 bits */
+
+#ifndef SPRN_SVR
+#define SPRN_SVR	0x11E	/* System Version Register */
+#endif
+#define SPRN_THRM1	0x3FC		/* Thermal Management Register 1 */
+/* these bits were defined in inverted endian sense originally, ugh, confusing */
+#define THRM1_TIN	(1 << 31)
+#define THRM1_TIV	(1 << 30)
+#define THRM1_THRES(x)	((x&0x7f)<<23)
+#define THRM3_SITV(x)	((x&0x3fff)<<1)
+#define THRM1_TID	(1<<2)
+#define THRM1_TIE	(1<<1)
+#define THRM1_V		(1<<0)
+#define SPRN_THRM2	0x3FD		/* Thermal Management Register 2 */
+#define SPRN_THRM3	0x3FE		/* Thermal Management Register 3 */
+#define THRM3_E		(1<<0)
+#define SPRN_TLBMISS	0x3D4		/* 980 7450 TLB Miss Register */
+#define SPRN_UMMCR0	0x3A8	/* User Monitor Mode Control Register 0 */
+#define SPRN_UMMCR1	0x3AC	/* User Monitor Mode Control Register 0 */
+#define SPRN_UPMC1	0x3A9	/* User Performance Counter Register 1 */
+#define SPRN_UPMC2	0x3AA	/* User Performance Counter Register 2 */
+#define SPRN_UPMC3	0x3AD	/* User Performance Counter Register 3 */
+#define SPRN_UPMC4	0x3AE	/* User Performance Counter Register 4 */
+#define SPRN_USIA	0x3AB	/* User Sampled Instruction Address Register */
+#define SPRN_VRSAVE	0x100	/* Vector Register Save Register */
+#define SPRN_XER	0x001	/* Fixed Point Exception Register */
+
+#define SPRN_SCOMC	0x114	/* SCOM Access Control */
+#define SPRN_SCOMD	0x115	/* SCOM Access DATA */
+
+/* Performance monitor SPRs */
+#ifdef CONFIG_PPC64
+#define SPRN_MMCR0	795
+#define   MMCR0_FC	0x80000000UL /* freeze counters */
+#define   MMCR0_FCS	0x40000000UL /* freeze in supervisor state */
+#define   MMCR0_KERNEL_DISABLE MMCR0_FCS
+#define   MMCR0_FCP	0x20000000UL /* freeze in problem state */
+#define   MMCR0_PROBLEM_DISABLE MMCR0_FCP
+#define   MMCR0_FCM1	0x10000000UL /* freeze counters while MSR mark = 1 */
+#define   MMCR0_FCM0	0x08000000UL /* freeze counters while MSR mark = 0 */
+#define   MMCR0_PMXE	0x04000000UL /* performance monitor exception enable */
+#define   MMCR0_FCECE	0x02000000UL /* freeze ctrs on enabled cond or event */
+#define   MMCR0_TBEE	0x00400000UL /* time base exception enable */
+#define   MMCR0_PMC1CE	0x00008000UL /* PMC1 count enable*/
+#define   MMCR0_PMCjCE	0x00004000UL /* PMCj count enable*/
+#define   MMCR0_TRIGGER	0x00002000UL /* TRIGGER enable */
+#define   MMCR0_PMAO	0x00000080UL /* performance monitor alert has occurred, set to 0 after handling exception */
+#define   MMCR0_SHRFC	0x00000040UL /* SHRre freeze conditions between threads */
+#define   MMCR0_FCTI	0x00000008UL /* freeze counters in tags inactive mode */
+#define   MMCR0_FCTA	0x00000004UL /* freeze counters in tags active mode */
+#define   MMCR0_FCWAIT	0x00000002UL /* freeze counter in WAIT state */
+#define   MMCR0_FCHV	0x00000001UL /* freeze conditions in hypervisor mode */
+#define SPRN_MMCR1	798
+#define SPRN_MMCRA	0x312
+#define   MMCRA_SIHV	0x10000000UL /* state of MSR HV when SIAR set */
+#define   MMCRA_SIPR	0x08000000UL /* state of MSR PR when SIAR set */
+#define   MMCRA_SLOT	0x07000000UL /* SLOT bits (37-39) */
+#define   MMCRA_SLOT_SHIFT	24
+#define   MMCRA_SAMPLE_ENABLE 0x00000001UL /* enable sampling */
+#define   POWER6_MMCRA_SIHV   0x0000040000000000ULL
+#define   POWER6_MMCRA_SIPR   0x0000020000000000ULL
+#define   POWER6_MMCRA_THRM	0x00000020UL
+#define   POWER6_MMCRA_OTHER	0x0000000EUL
+#define SPRN_PMC1	787
+#define SPRN_PMC2	788
+#define SPRN_PMC3	789
+#define SPRN_PMC4	790
+#define SPRN_PMC5	791
+#define SPRN_PMC6	792
+#define SPRN_PMC7	793
+#define SPRN_PMC8	794
+#define SPRN_SIAR	780
+#define SPRN_SDAR	781
+
+#define SPRN_PA6T_MMCR0 795
+#define   PA6T_MMCR0_EN0	0x0000000000000001UL
+#define   PA6T_MMCR0_EN1	0x0000000000000002UL
+#define   PA6T_MMCR0_EN2	0x0000000000000004UL
+#define   PA6T_MMCR0_EN3	0x0000000000000008UL
+#define   PA6T_MMCR0_EN4	0x0000000000000010UL
+#define   PA6T_MMCR0_EN5	0x0000000000000020UL
+#define   PA6T_MMCR0_SUPEN	0x0000000000000040UL
+#define   PA6T_MMCR0_PREN	0x0000000000000080UL
+#define   PA6T_MMCR0_HYPEN	0x0000000000000100UL
+#define   PA6T_MMCR0_FCM0	0x0000000000000200UL
+#define   PA6T_MMCR0_FCM1	0x0000000000000400UL
+#define   PA6T_MMCR0_INTGEN	0x0000000000000800UL
+#define   PA6T_MMCR0_INTEN0	0x0000000000001000UL
+#define   PA6T_MMCR0_INTEN1	0x0000000000002000UL
+#define   PA6T_MMCR0_INTEN2	0x0000000000004000UL
+#define   PA6T_MMCR0_INTEN3	0x0000000000008000UL
+#define   PA6T_MMCR0_INTEN4	0x0000000000010000UL
+#define   PA6T_MMCR0_INTEN5	0x0000000000020000UL
+#define   PA6T_MMCR0_DISCNT	0x0000000000040000UL
+#define   PA6T_MMCR0_UOP	0x0000000000080000UL
+#define   PA6T_MMCR0_TRG	0x0000000000100000UL
+#define   PA6T_MMCR0_TRGEN	0x0000000000200000UL
+#define   PA6T_MMCR0_TRGREG	0x0000000001600000UL
+#define   PA6T_MMCR0_SIARLOG	0x0000000002000000UL
+#define   PA6T_MMCR0_SDARLOG	0x0000000004000000UL
+#define   PA6T_MMCR0_PROEN	0x0000000008000000UL
+#define   PA6T_MMCR0_PROLOG	0x0000000010000000UL
+#define   PA6T_MMCR0_DAMEN2	0x0000000020000000UL
+#define   PA6T_MMCR0_DAMEN3	0x0000000040000000UL
+#define   PA6T_MMCR0_DAMEN4	0x0000000080000000UL
+#define   PA6T_MMCR0_DAMEN5	0x0000000100000000UL
+#define   PA6T_MMCR0_DAMSEL2	0x0000000200000000UL
+#define   PA6T_MMCR0_DAMSEL3	0x0000000400000000UL
+#define   PA6T_MMCR0_DAMSEL4	0x0000000800000000UL
+#define   PA6T_MMCR0_DAMSEL5	0x0000001000000000UL
+#define   PA6T_MMCR0_HANDDIS	0x0000002000000000UL
+#define   PA6T_MMCR0_PCTEN	0x0000004000000000UL
+#define   PA6T_MMCR0_SOCEN	0x0000008000000000UL
+#define   PA6T_MMCR0_SOCMOD	0x0000010000000000UL
+
+#define SPRN_PA6T_MMCR1 798
+#define   PA6T_MMCR1_ES2	0x00000000000000ffUL
+#define   PA6T_MMCR1_ES3	0x000000000000ff00UL
+#define   PA6T_MMCR1_ES4	0x0000000000ff0000UL
+#define   PA6T_MMCR1_ES5	0x00000000ff000000UL
+
+#define SPRN_PA6T_UPMC0 771	/* User PerfMon Counter 0 */
+#define SPRN_PA6T_UPMC1 772	/* ... */
+#define SPRN_PA6T_UPMC2 773
+#define SPRN_PA6T_UPMC3 774
+#define SPRN_PA6T_UPMC4 775
+#define SPRN_PA6T_UPMC5 776
+#define SPRN_PA6T_UMMCR0 779	/* User Monitor Mode Control Register 0 */
+#define SPRN_PA6T_SIAR	780	/* Sampled Instruction Address */
+#define SPRN_PA6T_UMMCR1 782	/* User Monitor Mode Control Register 1 */
+#define SPRN_PA6T_SIER	785	/* Sampled Instruction Event Register */
+#define SPRN_PA6T_PMC0	787
+#define SPRN_PA6T_PMC1	788
+#define SPRN_PA6T_PMC2	789
+#define SPRN_PA6T_PMC3	790
+#define SPRN_PA6T_PMC4	791
+#define SPRN_PA6T_PMC5	792
+#define SPRN_PA6T_TSR0	793	/* Timestamp Register 0 */
+#define SPRN_PA6T_TSR1	794	/* Timestamp Register 1 */
+#define SPRN_PA6T_TSR2	799	/* Timestamp Register 2 */
+#define SPRN_PA6T_TSR3	784	/* Timestamp Register 3 */
+
+#define SPRN_PA6T_IER	981	/* Icache Error Register */
+#define SPRN_PA6T_DER	982	/* Dcache Error Register */
+#define SPRN_PA6T_BER	862	/* BIU Error Address Register */
+#define SPRN_PA6T_MER	849	/* MMU Error Register */
+
+#define SPRN_PA6T_IMA0	880	/* Instruction Match Array 0 */
+#define SPRN_PA6T_IMA1	881	/* ... */
+#define SPRN_PA6T_IMA2	882
+#define SPRN_PA6T_IMA3	883
+#define SPRN_PA6T_IMA4	884
+#define SPRN_PA6T_IMA5	885
+#define SPRN_PA6T_IMA6	886
+#define SPRN_PA6T_IMA7	887
+#define SPRN_PA6T_IMA8	888
+#define SPRN_PA6T_IMA9	889
+#define SPRN_PA6T_BTCR	978	/* Breakpoint and Tagging Control Register */
+#define SPRN_PA6T_IMAAT	979	/* Instruction Match Array Action Table */
+#define SPRN_PA6T_PCCR	1019	/* Power Counter Control Register */
+#define SPRN_BKMK	1020	/* Cell Bookmark Register */
+#define SPRN_PA6T_RPCCR	1021	/* Retire PC Trace Control Register */
+
+
+#else /* 32-bit */
+#define SPRN_MMCR0	952	/* Monitor Mode Control Register 0 */
+#define   MMCR0_FC	0x80000000UL /* freeze counters */
+#define   MMCR0_FCS	0x40000000UL /* freeze in supervisor state */
+#define   MMCR0_FCP	0x20000000UL /* freeze in problem state */
+#define   MMCR0_FCM1	0x10000000UL /* freeze counters while MSR mark = 1 */
+#define   MMCR0_FCM0	0x08000000UL /* freeze counters while MSR mark = 0 */
+#define   MMCR0_PMXE	0x04000000UL /* performance monitor exception enable */
+#define   MMCR0_FCECE	0x02000000UL /* freeze ctrs on enabled cond or event */
+#define   MMCR0_TBEE	0x00400000UL /* time base exception enable */
+#define   MMCR0_PMC1CE	0x00008000UL /* PMC1 count enable*/
+#define   MMCR0_PMCnCE	0x00004000UL /* count enable for all but PMC 1*/
+#define   MMCR0_TRIGGER	0x00002000UL /* TRIGGER enable */
+#define   MMCR0_PMC1SEL	0x00001fc0UL /* PMC 1 Event */
+#define   MMCR0_PMC2SEL	0x0000003fUL /* PMC 2 Event */
+
+#define SPRN_MMCR1	956
+#define   MMCR1_PMC3SEL	0xf8000000UL /* PMC 3 Event */
+#define   MMCR1_PMC4SEL	0x07c00000UL /* PMC 4 Event */
+#define   MMCR1_PMC5SEL	0x003e0000UL /* PMC 5 Event */
+#define   MMCR1_PMC6SEL 0x0001f800UL /* PMC 6 Event */
+#define SPRN_MMCR2	944
+#define SPRN_PMC1	953	/* Performance Counter Register 1 */
+#define SPRN_PMC2	954	/* Performance Counter Register 2 */
+#define SPRN_PMC3	957	/* Performance Counter Register 3 */
+#define SPRN_PMC4	958	/* Performance Counter Register 4 */
+#define SPRN_PMC5	945	/* Performance Counter Register 5 */
+#define SPRN_PMC6	946	/* Performance Counter Register 6 */
+
+#define SPRN_SIAR	955	/* Sampled Instruction Address Register */
+
+/* Bit definitions for MMCR0 and PMC1 / PMC2. */
+#define MMCR0_PMC1_CYCLES	(1 << 7)
+#define MMCR0_PMC1_ICACHEMISS	(5 << 7)
+#define MMCR0_PMC1_DTLB		(6 << 7)
+#define MMCR0_PMC2_DCACHEMISS	0x6
+#define MMCR0_PMC2_CYCLES	0x1
+#define MMCR0_PMC2_ITLB		0x7
+#define MMCR0_PMC2_LOADMISSTIME	0x5
+#endif
+
+/*
+ * An mtfsf instruction with the L bit set. On CPUs that support this a
+ * full 64bits of FPSCR is restored and on other CPUs the L bit is ignored.
+ *
+ * Until binutils gets the new form of mtfsf, hardwire the instruction.
+ */
+#ifdef CONFIG_PPC64
+#define MTFSF_L(REG) \
+	.long (0xfc00058e | ((0xff) << 17) | ((REG) << 11) | (1 << 25))
+#else
+#define MTFSF_L(REG)	mtfsf	0xff, (REG)
+#endif
+
+/* Processor Version Register (PVR) field extraction */
+
+#define PVR_VER(pvr)	(((pvr) >>  16) & 0xFFFF)	/* Version field */
+#define PVR_REV(pvr)	(((pvr) >>   0) & 0xFFFF)	/* Revison field */
+
+#define __is_processor(pv)	(PVR_VER(mfspr(SPRN_PVR)) == (pv))
+
+/*
+ * IBM has further subdivided the standard PowerPC 16-bit version and
+ * revision subfields of the PVR for the PowerPC 403s into the following:
+ */
+
+#define PVR_FAM(pvr)	(((pvr) >> 20) & 0xFFF)	/* Family field */
+#define PVR_MEM(pvr)	(((pvr) >> 16) & 0xF)	/* Member field */
+#define PVR_CORE(pvr)	(((pvr) >> 12) & 0xF)	/* Core field */
+#define PVR_CFG(pvr)	(((pvr) >>  8) & 0xF)	/* Configuration field */
+#define PVR_MAJ(pvr)	(((pvr) >>  4) & 0xF)	/* Major revision field */
+#define PVR_MIN(pvr)	(((pvr) >>  0) & 0xF)	/* Minor revision field */
+
+/* Processor Version Numbers */
+
+#define PVR_403GA	0x00200000
+#define PVR_403GB	0x00200100
+#define PVR_403GC	0x00200200
+#define PVR_403GCX	0x00201400
+#define PVR_405GP	0x40110000
+#define PVR_STB03XXX	0x40310000
+#define PVR_NP405H	0x41410000
+#define PVR_NP405L	0x41610000
+#define PVR_601		0x00010000
+#define PVR_602		0x00050000
+#define PVR_603		0x00030000
+#define PVR_603e	0x00060000
+#define PVR_603ev	0x00070000
+#define PVR_603r	0x00071000
+#define PVR_604		0x00040000
+#define PVR_604e	0x00090000
+#define PVR_604r	0x000A0000
+#define PVR_620		0x00140000
+#define PVR_740		0x00080000
+#define PVR_750		PVR_740
+#define PVR_740P	0x10080000
+#define PVR_750P	PVR_740P
+#define PVR_7400	0x000C0000
+#define PVR_7410	0x800C0000
+#define PVR_7450	0x80000000
+#define PVR_8540	0x80200000
+#define PVR_8560	0x80200000
+/*
+ * For the 8xx processors, all of them report the same PVR family for
+ * the PowerPC core. The various versions of these processors must be
+ * differentiated by the version number in the Communication Processor
+ * Module (CPM).
+ */
+#define PVR_821		0x00500000
+#define PVR_823		PVR_821
+#define PVR_850		PVR_821
+#define PVR_860		PVR_821
+#define PVR_8240	0x00810100
+#define PVR_8245	0x80811014
+#define PVR_8260	PVR_8240
+
+/* 64-bit processors */
+/* XXX the prefix should be PVR_, we'll do a global sweep to fix it one day */
+#define PV_NORTHSTAR	0x0033
+#define PV_PULSAR	0x0034
+#define PV_POWER4	0x0035
+#define PV_ICESTAR	0x0036
+#define PV_SSTAR	0x0037
+#define PV_POWER4p	0x0038
+#define PV_970		0x0039
+#define PV_POWER5	0x003A
+#define PV_POWER5p	0x003B
+#define PV_970FX	0x003C
+#define PV_630		0x0040
+#define PV_630p	0x0041
+#define PV_970MP	0x0044
+#define PV_970GX	0x0045
+#define PV_BE		0x0070
+#define PV_PA6T		0x0090
+
+/* Macros for setting and retrieving special purpose registers */
+#ifndef __ASSEMBLY__
+#define mfmsr()		({unsigned long rval; \
+			asm volatile("mfmsr %0" : "=r" (rval)); rval;})
+#ifdef CONFIG_PPC64
+#define __mtmsrd(v, l)	asm volatile("mtmsrd %0," __stringify(l) \
+				     : : "r" (v))
+#define mtmsrd(v)	__mtmsrd((v), 0)
+#define mtmsr(v)	mtmsrd(v)
+#else
+#define mtmsr(v)	asm volatile("mtmsr %0" : : "r" (v))
+#endif
+
+#define mfspr(rn)	({unsigned long rval; \
+			asm volatile("mfspr %0," __stringify(rn) \
+				: "=r" (rval)); rval;})
+#define mtspr(rn, v)	asm volatile("mtspr " __stringify(rn) ",%0" : : "r" (v))
+
+#ifdef __powerpc64__
+#ifdef CONFIG_PPC_CELL
+#define mftb()		({unsigned long rval;				\
+			asm volatile(					\
+				"90:	mftb %0;\n"			\
+				"97:	cmpwi %0,0;\n"			\
+				"	beq- 90b;\n"			\
+				"99:\n"					\
+				".section __ftr_fixup,\"a\"\n"		\
+				".align 3\n"				\
+				"98:\n"					\
+				"	.llong %1\n"			\
+				"	.llong %1\n"			\
+				"	.llong 97b-98b\n"		\
+				"	.llong 99b-98b\n"		\
+				"	.llong 0\n"			\
+				"	.llong 0\n"			\
+				".previous"				\
+			: "=r" (rval) : "i" (CPU_FTR_CELL_TB_BUG)); rval;})
+#else
+#define mftb()		({unsigned long rval;	\
+			asm volatile("mftb %0" : "=r" (rval)); rval;})
+#endif /* !CONFIG_PPC_CELL */
+
+#else /* __powerpc64__ */
+
+#define mftbl()		({unsigned long rval;	\
+			asm volatile("mftbl %0" : "=r" (rval)); rval;})
+#define mftbu()		({unsigned long rval;	\
+			asm volatile("mftbu %0" : "=r" (rval)); rval;})
+#endif /* !__powerpc64__ */
+
+#define mttbl(v)	asm volatile("mttbl %0":: "r"(v))
+#define mttbu(v)	asm volatile("mttbu %0":: "r"(v))
+
+#ifdef CONFIG_PPC32
+#define mfsrin(v)	({unsigned int rval; \
+			asm volatile("mfsrin %0,%1" : "=r" (rval) : "r" (v)); \
+					rval;})
+#endif
+
+#define proc_trap()	asm volatile("trap")
+
+#ifdef CONFIG_PPC64
+
+extern void ppc64_runlatch_on(void);
+extern void ppc64_runlatch_off(void);
+
+extern unsigned long scom970_read(unsigned int address);
+extern void scom970_write(unsigned int address, unsigned long value);
+
+#else
+#define ppc64_runlatch_on()
+#define ppc64_runlatch_off()
+
+#endif /* CONFIG_PPC64 */
+
+#define __get_SP()	({unsigned long sp; \
+			asm volatile("mr %0,1": "=r" (sp)); sp;})
+
+#endif /* __ASSEMBLY__ */
+#endif /* __KERNEL__ */
+#endif /* _ASM_POWERPC_REG_H */
