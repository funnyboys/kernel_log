commit 6909f179ca7a73f243dca7c829facca1cc1d4ff5
Author: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
Date:   Tue Apr 7 14:17:42 2020 +0530

    powerpc/sysfs: Show idle_purr and idle_spurr for every CPU
    
    On Pseries LPARs, to calculate utilization, we need to know the
    [S]PURR ticks when the CPUs were busy or idle.
    
    The total PURR and SPURR ticks are already exposed via the per-cpu
    sysfs files "purr" and "spurr". This patch adds support for exposing
    the idle PURR and SPURR ticks via new per-cpu sysfs files named
    "idle_purr" and "idle_spurr".
    
    This patch also adds helper functions to accurately read the values of
    idle_purr and idle_spurr especially from an interrupt context between
    when the interrupt has occurred between the pseries_idle_prolog() and
    pseries_idle_epilog(). This will ensure that the idle purr/spurr
    values corresponding to the latest idle period is accounted for before
    these values are read.
    
    Signed-off-by: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/1586249263-14048-5-git-send-email-ego@linux.vnet.ibm.com

diff --git a/arch/powerpc/include/asm/idle.h b/arch/powerpc/include/asm/idle.h
index 0efb25071d87..accd1f50085a 100644
--- a/arch/powerpc/include/asm/idle.h
+++ b/arch/powerpc/include/asm/idle.h
@@ -57,5 +57,37 @@ static inline void pseries_idle_epilog(void)
 	ppc64_runlatch_on();
 }
 
+static inline u64 read_this_idle_purr(void)
+{
+	/*
+	 * If we are reading from an idle context, update the
+	 * idle-purr cycles corresponding to the last idle period.
+	 * Since the idle context is not yet over, take a fresh
+	 * snapshot of the idle-purr.
+	 */
+	if (unlikely(get_lppaca()->idle == 1)) {
+		update_idle_purr_accounting();
+		snapshot_purr_idle_entry();
+	}
+
+	return be64_to_cpu(get_lppaca()->wait_state_cycles);
+}
+
+static inline u64 read_this_idle_spurr(void)
+{
+	/*
+	 * If we are reading from an idle context, update the
+	 * idle-spurr cycles corresponding to the last idle period.
+	 * Since the idle context is not yet over, take a fresh
+	 * snapshot of the idle-spurr.
+	 */
+	if (get_lppaca()->idle == 1) {
+		update_idle_spurr_accounting();
+		snapshot_spurr_idle_entry();
+	}
+
+	return *this_cpu_ptr(&idle_spurr_cycles);
+}
+
 #endif /* CONFIG_PPC_PSERIES */
 #endif

commit dc8afce5f45b099e3ea52a16b2f90e92f90f3af0
Author: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
Date:   Tue Apr 7 14:17:41 2020 +0530

    powerpc/pseries: Account for SPURR ticks on idle CPUs
    
    On Pseries LPARs, to calculate utilization, we need to know the
    [S]PURR ticks when the CPUs were busy or idle.
    
    Via pseries_idle_prolog(), pseries_idle_epilog(), we track the idle
    PURR ticks in the VPA variable "wait_state_cycles". This patch extends
    the support to account for the idle SPURR ticks.
    
    Signed-off-by: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/1586249263-14048-4-git-send-email-ego@linux.vnet.ibm.com

diff --git a/arch/powerpc/include/asm/idle.h b/arch/powerpc/include/asm/idle.h
index b90d75aa1f9e..0efb25071d87 100644
--- a/arch/powerpc/include/asm/idle.h
+++ b/arch/powerpc/include/asm/idle.h
@@ -5,13 +5,20 @@
 #include <asm/paca.h>
 
 #ifdef CONFIG_PPC_PSERIES
+DECLARE_PER_CPU(u64, idle_spurr_cycles);
 DECLARE_PER_CPU(u64, idle_entry_purr_snap);
+DECLARE_PER_CPU(u64, idle_entry_spurr_snap);
 
 static inline void snapshot_purr_idle_entry(void)
 {
 	*this_cpu_ptr(&idle_entry_purr_snap) = mfspr(SPRN_PURR);
 }
 
+static inline void snapshot_spurr_idle_entry(void)
+{
+	*this_cpu_ptr(&idle_entry_spurr_snap) = mfspr(SPRN_SPURR);
+}
+
 static inline void update_idle_purr_accounting(void)
 {
 	u64 wait_cycles;
@@ -22,10 +29,19 @@ static inline void update_idle_purr_accounting(void)
 	get_lppaca()->wait_state_cycles = cpu_to_be64(wait_cycles);
 }
 
+static inline void update_idle_spurr_accounting(void)
+{
+	u64 *idle_spurr_cycles_ptr = this_cpu_ptr(&idle_spurr_cycles);
+	u64 in_spurr = *this_cpu_ptr(&idle_entry_spurr_snap);
+
+	*idle_spurr_cycles_ptr += mfspr(SPRN_SPURR) - in_spurr;
+}
+
 static inline void pseries_idle_prolog(void)
 {
 	ppc64_runlatch_off();
 	snapshot_purr_idle_entry();
+	snapshot_spurr_idle_entry();
 	/*
 	 * Indicate to the HV that we are idle. Now would be
 	 * a good time to find other work to dispatch.
@@ -36,6 +52,7 @@ static inline void pseries_idle_prolog(void)
 static inline void pseries_idle_epilog(void)
 {
 	update_idle_purr_accounting();
+	update_idle_spurr_accounting();
 	get_lppaca()->idle = 0;
 	ppc64_runlatch_on();
 }

commit c4019198cfa81224d32846915cd401e981f81b81
Author: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
Date:   Tue Apr 7 14:17:40 2020 +0530

    powerpc/idle: Store PURR snapshot in a per-cpu global variable
    
    Currently when CPU goes idle, we take a snapshot of PURR via
    pseries_idle_prolog() which is used at the CPU idle exit to compute
    the idle PURR cycles via the function pseries_idle_epilog().  Thus,
    the value of idle PURR cycle thus read before pseries_idle_prolog() and
    after pseries_idle_epilog() is always correct.
    
    However, if we were to read the idle PURR cycles from an interrupt
    context between pseries_idle_prolog() and pseries_idle_epilog() (this
    will be done in a future patch), then, the value of the idle PURR thus
    read will not include the cycles spent in the most recent idle period.
    Thus, in that interrupt context, we will need access to the snapshot
    of the PURR before going idle, in order to compute the idle PURR
    cycles for the latest idle duration.
    
    In this patch, we save the snapshot of PURR in pseries_idle_prolog()
    in a per-cpu variable, instead of on the stack, so that it can be
    accessed from an interrupt context.
    
    Signed-off-by: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/1586249263-14048-3-git-send-email-ego@linux.vnet.ibm.com

diff --git a/arch/powerpc/include/asm/idle.h b/arch/powerpc/include/asm/idle.h
index 32064a4c0dd7..b90d75aa1f9e 100644
--- a/arch/powerpc/include/asm/idle.h
+++ b/arch/powerpc/include/asm/idle.h
@@ -5,10 +5,27 @@
 #include <asm/paca.h>
 
 #ifdef CONFIG_PPC_PSERIES
-static inline void pseries_idle_prolog(unsigned long *in_purr)
+DECLARE_PER_CPU(u64, idle_entry_purr_snap);
+
+static inline void snapshot_purr_idle_entry(void)
+{
+	*this_cpu_ptr(&idle_entry_purr_snap) = mfspr(SPRN_PURR);
+}
+
+static inline void update_idle_purr_accounting(void)
+{
+	u64 wait_cycles;
+	u64 in_purr = *this_cpu_ptr(&idle_entry_purr_snap);
+
+	wait_cycles = be64_to_cpu(get_lppaca()->wait_state_cycles);
+	wait_cycles += mfspr(SPRN_PURR) - in_purr;
+	get_lppaca()->wait_state_cycles = cpu_to_be64(wait_cycles);
+}
+
+static inline void pseries_idle_prolog(void)
 {
 	ppc64_runlatch_off();
-	*in_purr = mfspr(SPRN_PURR);
+	snapshot_purr_idle_entry();
 	/*
 	 * Indicate to the HV that we are idle. Now would be
 	 * a good time to find other work to dispatch.
@@ -16,16 +33,12 @@ static inline void pseries_idle_prolog(unsigned long *in_purr)
 	get_lppaca()->idle = 1;
 }
 
-static inline void pseries_idle_epilog(unsigned long in_purr)
+static inline void pseries_idle_epilog(void)
 {
-	u64 wait_cycles;
-
-	wait_cycles = be64_to_cpu(get_lppaca()->wait_state_cycles);
-	wait_cycles += mfspr(SPRN_PURR) - in_purr;
-	get_lppaca()->wait_state_cycles = cpu_to_be64(wait_cycles);
+	update_idle_purr_accounting();
 	get_lppaca()->idle = 0;
-
 	ppc64_runlatch_on();
 }
+
 #endif /* CONFIG_PPC_PSERIES */
 #endif

commit e4a884cc28fa3f5d8b81de46998ffe29b4ad169e
Author: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
Date:   Tue Apr 7 14:17:39 2020 +0530

    powerpc: Move idle_loop_prolog()/epilog() functions to header file
    
    Currently prior to entering an idle state on a Linux Guest, the
    pseries cpuidle driver implement an idle_loop_prolog() and
    idle_loop_epilog() functions which ensure that idle_purr is correctly
    computed, and the hypervisor is informed that the CPU cycles have been
    donated.
    
    These prolog and epilog functions are also required in the default
    idle call, i.e pseries_lpar_idle(). Hence move these accessor
    functions to a common header file and call them from
    pseries_lpar_idle(). Since the existing header files such as
    asm/processor.h have enough clutter, create a new header file
    asm/idle.h. Finally rename idle_loop_prolog() and idle_loop_epilog()
    to pseries_idle_prolog() and pseries_idle_epilog() as they are only
    relavent for on pseries guests.
    
    Signed-off-by: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/1586249263-14048-2-git-send-email-ego@linux.vnet.ibm.com

diff --git a/arch/powerpc/include/asm/idle.h b/arch/powerpc/include/asm/idle.h
new file mode 100644
index 000000000000..32064a4c0dd7
--- /dev/null
+++ b/arch/powerpc/include/asm/idle.h
@@ -0,0 +1,31 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
+#ifndef _ASM_POWERPC_IDLE_H
+#define _ASM_POWERPC_IDLE_H
+#include <asm/runlatch.h>
+#include <asm/paca.h>
+
+#ifdef CONFIG_PPC_PSERIES
+static inline void pseries_idle_prolog(unsigned long *in_purr)
+{
+	ppc64_runlatch_off();
+	*in_purr = mfspr(SPRN_PURR);
+	/*
+	 * Indicate to the HV that we are idle. Now would be
+	 * a good time to find other work to dispatch.
+	 */
+	get_lppaca()->idle = 1;
+}
+
+static inline void pseries_idle_epilog(unsigned long in_purr)
+{
+	u64 wait_cycles;
+
+	wait_cycles = be64_to_cpu(get_lppaca()->wait_state_cycles);
+	wait_cycles += mfspr(SPRN_PURR) - in_purr;
+	get_lppaca()->wait_state_cycles = cpu_to_be64(wait_cycles);
+	get_lppaca()->idle = 0;
+
+	ppc64_runlatch_on();
+}
+#endif /* CONFIG_PPC_PSERIES */
+#endif
