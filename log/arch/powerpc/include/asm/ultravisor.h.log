commit 22945688acd4d0ec2620b0670a53110401ed9c59
Author: Bharata B Rao <bharata@linux.ibm.com>
Date:   Mon Nov 25 08:36:30 2019 +0530

    KVM: PPC: Book3S HV: Support reset of secure guest
    
    Add support for reset of secure guest via a new ioctl KVM_PPC_SVM_OFF.
    This ioctl will be issued by QEMU during reset and includes the
    the following steps:
    
    - Release all device pages of the secure guest.
    - Ask UV to terminate the guest via UV_SVM_TERMINATE ucall
    - Unpin the VPA pages so that they can be migrated back to secure
      side when guest becomes secure again. This is required because
      pinned pages can't be migrated.
    - Reinit the partition scoped page tables
    
    After these steps, guest is ready to issue UV_ESM call once again
    to switch to secure mode.
    
    Signed-off-by: Bharata B Rao <bharata@linux.ibm.com>
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
            [Implementation of uv_svm_terminate() and its call from
            guest shutdown path]
    Signed-off-by: Ram Pai <linuxram@us.ibm.com>
            [Unpinning of VPA pages]
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/ultravisor.h b/arch/powerpc/include/asm/ultravisor.h
index b8e59b7b4ac8..790b0e63681f 100644
--- a/arch/powerpc/include/asm/ultravisor.h
+++ b/arch/powerpc/include/asm/ultravisor.h
@@ -77,4 +77,9 @@ static inline int uv_page_inval(u64 lpid, u64 gpa, u64 page_shift)
 	return ucall_norets(UV_PAGE_INVAL, lpid, gpa, page_shift);
 }
 
+static inline int uv_svm_terminate(u64 lpid)
+{
+	return ucall_norets(UV_SVM_TERMINATE, lpid);
+}
+
 #endif	/* _ASM_POWERPC_ULTRAVISOR_H */

commit c32622575dd0ecb6fd0b41e3a451bd58152971ba
Author: Bharata B Rao <bharata@linux.ibm.com>
Date:   Mon Nov 25 08:36:29 2019 +0530

    KVM: PPC: Book3S HV: Handle memory plug/unplug to secure VM
    
    Register the new memslot with UV during plug and unregister
    the memslot during unplug. In addition, release all the
    device pages during unplug.
    
    Signed-off-by: Bharata B Rao <bharata@linux.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/ultravisor.h b/arch/powerpc/include/asm/ultravisor.h
index 40cc8bace654..b8e59b7b4ac8 100644
--- a/arch/powerpc/include/asm/ultravisor.h
+++ b/arch/powerpc/include/asm/ultravisor.h
@@ -67,6 +67,11 @@ static inline int uv_register_mem_slot(u64 lpid, u64 start_gpa, u64 size,
 			    size, flags, slotid);
 }
 
+static inline int uv_unregister_mem_slot(u64 lpid, u64 slotid)
+{
+	return ucall_norets(UV_UNREGISTER_MEM_SLOT, lpid, slotid);
+}
+
 static inline int uv_page_inval(u64 lpid, u64 gpa, u64 page_shift)
 {
 	return ucall_norets(UV_PAGE_INVAL, lpid, gpa, page_shift);

commit 008e359c76d85facb10d10fa21fd5bc8c3a4e5d6
Author: Bharata B Rao <bharata@linux.ibm.com>
Date:   Mon Nov 25 08:36:28 2019 +0530

    KVM: PPC: Book3S HV: Radix changes for secure guest
    
    - After the guest becomes secure, when we handle a page fault of a page
      belonging to SVM in HV, send that page to UV via UV_PAGE_IN.
    - Whenever a page is unmapped on the HV side, inform UV via UV_PAGE_INVAL.
    - Ensure all those routines that walk the secondary page tables of
      the guest don't do so in case of secure VM. For secure guest, the
      active secondary page tables are in secure memory and the secondary
      page tables in HV are freed when guest becomes secure.
    
    Signed-off-by: Bharata B Rao <bharata@linux.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/ultravisor.h b/arch/powerpc/include/asm/ultravisor.h
index 79bb005e8ee9..40cc8bace654 100644
--- a/arch/powerpc/include/asm/ultravisor.h
+++ b/arch/powerpc/include/asm/ultravisor.h
@@ -67,4 +67,9 @@ static inline int uv_register_mem_slot(u64 lpid, u64 start_gpa, u64 size,
 			    size, flags, slotid);
 }
 
+static inline int uv_page_inval(u64 lpid, u64 gpa, u64 page_shift)
+{
+	return ucall_norets(UV_PAGE_INVAL, lpid, gpa, page_shift);
+}
+
 #endif	/* _ASM_POWERPC_ULTRAVISOR_H */

commit ca9f4942670c37407bb109090eaf776ce2ccc54c
Author: Bharata B Rao <bharata@linux.ibm.com>
Date:   Mon Nov 25 08:36:26 2019 +0530

    KVM: PPC: Book3S HV: Support for running secure guests
    
    A pseries guest can be run as secure guest on Ultravisor-enabled
    POWER platforms. On such platforms, this driver will be used to manage
    the movement of guest pages between the normal memory managed by
    hypervisor (HV) and secure memory managed by Ultravisor (UV).
    
    HV is informed about the guest's transition to secure mode via hcalls:
    
    H_SVM_INIT_START: Initiate securing a VM
    H_SVM_INIT_DONE: Conclude securing a VM
    
    As part of H_SVM_INIT_START, register all existing memslots with
    the UV. H_SVM_INIT_DONE call by UV informs HV that transition of
    the guest to secure mode is complete.
    
    These two states (transition to secure mode STARTED and transition
    to secure mode COMPLETED) are recorded in kvm->arch.secure_guest.
    Setting these states will cause the assembly code that enters the
    guest to call the UV_RETURN ucall instead of trying to enter the
    guest directly.
    
    Migration of pages betwen normal and secure memory of secure
    guest is implemented in H_SVM_PAGE_IN and H_SVM_PAGE_OUT hcalls.
    
    H_SVM_PAGE_IN: Move the content of a normal page to secure page
    H_SVM_PAGE_OUT: Move the content of a secure page to normal page
    
    Private ZONE_DEVICE memory equal to the amount of secure memory
    available in the platform for running secure guests is created.
    Whenever a page belonging to the guest becomes secure, a page from
    this private device memory is used to represent and track that secure
    page on the HV side. The movement of pages between normal and secure
    memory is done via migrate_vma_pages() using UV_PAGE_IN and
    UV_PAGE_OUT ucalls.
    
    In order to prevent the device private pages (that correspond to pages
    of secure guest) from participating in KSM merging, H_SVM_PAGE_IN
    calls ksm_madvise() under read version of mmap_sem. However
    ksm_madvise() needs to be under write lock.  Hence we call
    kvmppc_svm_page_in with mmap_sem held for writing, and it then
    downgrades to a read lock after calling ksm_madvise.
    
    [paulus@ozlabs.org - roll in patch "KVM: PPC: Book3S HV: Take write
     mmap_sem when calling ksm_madvise"]
    
    Signed-off-by: Bharata B Rao <bharata@linux.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/ultravisor.h b/arch/powerpc/include/asm/ultravisor.h
index b1bc2e043ed4..79bb005e8ee9 100644
--- a/arch/powerpc/include/asm/ultravisor.h
+++ b/arch/powerpc/include/asm/ultravisor.h
@@ -46,4 +46,25 @@ static inline int uv_unshare_all_pages(void)
 	return ucall_norets(UV_UNSHARE_ALL_PAGES);
 }
 
+static inline int uv_page_in(u64 lpid, u64 src_ra, u64 dst_gpa, u64 flags,
+			     u64 page_shift)
+{
+	return ucall_norets(UV_PAGE_IN, lpid, src_ra, dst_gpa, flags,
+			    page_shift);
+}
+
+static inline int uv_page_out(u64 lpid, u64 dst_ra, u64 src_gpa, u64 flags,
+			      u64 page_shift)
+{
+	return ucall_norets(UV_PAGE_OUT, lpid, dst_ra, src_gpa, flags,
+			    page_shift);
+}
+
+static inline int uv_register_mem_slot(u64 lpid, u64 start_gpa, u64 size,
+				       u64 flags, u64 slotid)
+{
+	return ucall_norets(UV_REGISTER_MEM_SLOT, lpid, start_gpa,
+			    size, flags, slotid);
+}
+
 #endif	/* _ASM_POWERPC_ULTRAVISOR_H */

commit 256ba2c1689efd4f5383cf7ebe2f9970c198b79d
Author: Ram Pai <linuxram@us.ibm.com>
Date:   Mon Aug 19 23:13:20 2019 -0300

    powerpc/pseries/svm: Unshare all pages before kexecing a new kernel
    
    A new kernel deserves a clean slate. Any pages shared with the hypervisor
    is unshared before invoking the new kernel. However there are exceptions.
    If the new kernel is invoked to dump the current kernel, or if there is a
    explicit request to preserve the state of the current kernel, unsharing
    of pages is skipped.
    
    NOTE: While testing crashkernel, make sure at least 256M is reserved for
    crashkernel. Otherwise SWIOTLB allocation will fail and crash kernel will
    fail to boot.
    
    Signed-off-by: Ram Pai <linuxram@us.ibm.com>
    Signed-off-by: Thiago Jung Bauermann <bauerman@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190820021326.6884-11-bauerman@linux.ibm.com

diff --git a/arch/powerpc/include/asm/ultravisor.h b/arch/powerpc/include/asm/ultravisor.h
index e5c8413de06f..b1bc2e043ed4 100644
--- a/arch/powerpc/include/asm/ultravisor.h
+++ b/arch/powerpc/include/asm/ultravisor.h
@@ -41,4 +41,9 @@ static inline int uv_unshare_page(u64 pfn, u64 npages)
 	return ucall_norets(UV_UNSHARE_PAGE, pfn, npages);
 }
 
+static inline int uv_unshare_all_pages(void)
+{
+	return ucall_norets(UV_UNSHARE_ALL_PAGES);
+}
+
 #endif	/* _ASM_POWERPC_ULTRAVISOR_H */

commit f7777e008cad17bf757ca256709070c07efd8283
Author: Ram Pai <linuxram@us.ibm.com>
Date:   Mon Aug 19 23:13:15 2019 -0300

    powerpc/pseries/svm: Add helpers for UV_SHARE_PAGE and UV_UNSHARE_PAGE
    
    These functions are used when the guest wants to grant the hypervisor
    access to certain pages.
    
    Signed-off-by: Ram Pai <linuxram@us.ibm.com>
    Signed-off-by: Thiago Jung Bauermann <bauerman@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190820021326.6884-6-bauerman@linux.ibm.com

diff --git a/arch/powerpc/include/asm/ultravisor.h b/arch/powerpc/include/asm/ultravisor.h
index d7aa97aa7834..e5c8413de06f 100644
--- a/arch/powerpc/include/asm/ultravisor.h
+++ b/arch/powerpc/include/asm/ultravisor.h
@@ -31,4 +31,14 @@ static inline int uv_register_pate(u64 lpid, u64 dw0, u64 dw1)
 	return ucall_norets(UV_WRITE_PATE, lpid, dw0, dw1);
 }
 
+static inline int uv_share_page(u64 pfn, u64 npages)
+{
+	return ucall_norets(UV_SHARE_PAGE, pfn, npages);
+}
+
+static inline int uv_unshare_page(u64 pfn, u64 npages)
+{
+	return ucall_norets(UV_UNSHARE_PAGE, pfn, npages);
+}
+
 #endif	/* _ASM_POWERPC_ULTRAVISOR_H */

commit 5223134029a87db925ecc9449f9501bad391a52e
Author: Claudio Carvalho <cclaudio@linux.ibm.com>
Date:   Thu Aug 22 00:48:36 2019 -0300

    powerpc/mm: Write to PTCR only if ultravisor disabled
    
    In ultravisor enabled systems, PTCR becomes ultravisor privileged only
    for writing and an attempt to write to it will cause a Hypervisor
    Emulation Assitance interrupt.
    
    This patch uses the set_ptcr_when_no_uv() function to restrict PTCR
    writing to only when ultravisor is disabled.
    
    Signed-off-by: Claudio Carvalho <cclaudio@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190822034838.27876-6-cclaudio@linux.ibm.com

diff --git a/arch/powerpc/include/asm/ultravisor.h b/arch/powerpc/include/asm/ultravisor.h
index 6fe1f365dec8..d7aa97aa7834 100644
--- a/arch/powerpc/include/asm/ultravisor.h
+++ b/arch/powerpc/include/asm/ultravisor.h
@@ -10,10 +10,22 @@
 
 #include <asm/asm-prototypes.h>
 #include <asm/ultravisor-api.h>
+#include <asm/firmware.h>
 
 int early_init_dt_scan_ultravisor(unsigned long node, const char *uname,
 				  int depth, void *data);
 
+/*
+ * In ultravisor enabled systems, PTCR becomes ultravisor privileged only for
+ * writing and an attempt to write to it will cause a Hypervisor Emulation
+ * Assistance interrupt.
+ */
+static inline void set_ptcr_when_no_uv(u64 val)
+{
+	if (!firmware_has_feature(FW_FEATURE_ULTRAVISOR))
+		mtspr(SPRN_PTCR, val);
+}
+
 static inline int uv_register_pate(u64 lpid, u64 dw0, u64 dw1)
 {
 	return ucall_norets(UV_WRITE_PATE, lpid, dw0, dw1);

commit 139a1d2842ec181cf017502a46bb8d947682a960
Author: Michael Anderson <andmike@linux.ibm.com>
Date:   Thu Aug 22 00:48:35 2019 -0300

    powerpc/mm: Use UV_WRITE_PATE ucall to register a PATE
    
    When Ultravisor (UV) is enabled, the partition table is stored in secure
    memory and can only be accessed via the UV. The Hypervisor (HV) however
    maintains a copy of the partition table in normal memory to allow Nest MMU
    translations to occur (for normal VMs). The HV copy includes partition
    table entries (PATE)s for secure VMs which would currently be unused
    (Nest MMU translations cannot access secure memory) but they would be
    needed as we add functionality.
    
    This patch adds the UV_WRITE_PATE ucall which is used to update the PATE
    for a VM (both normal and secure) when Ultravisor is enabled.
    
    Signed-off-by: Michael Anderson <andmike@linux.ibm.com>
    Signed-off-by: Madhavan Srinivasan <maddy@linux.vnet.ibm.com>
    Signed-off-by: Ram Pai <linuxram@us.ibm.com>
    [ cclaudio: Write the PATE in HV's table before doing that in UV's ]
    Signed-off-by: Claudio Carvalho <cclaudio@linux.ibm.com>
    Reviewed-by: Ryan Grimm <grimm@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190822034838.27876-5-cclaudio@linux.ibm.com

diff --git a/arch/powerpc/include/asm/ultravisor.h b/arch/powerpc/include/asm/ultravisor.h
index dc6e1ea198f2..6fe1f365dec8 100644
--- a/arch/powerpc/include/asm/ultravisor.h
+++ b/arch/powerpc/include/asm/ultravisor.h
@@ -8,7 +8,15 @@
 #ifndef _ASM_POWERPC_ULTRAVISOR_H
 #define _ASM_POWERPC_ULTRAVISOR_H
 
+#include <asm/asm-prototypes.h>
+#include <asm/ultravisor-api.h>
+
 int early_init_dt_scan_ultravisor(unsigned long node, const char *uname,
 				  int depth, void *data);
 
+static inline int uv_register_pate(u64 lpid, u64 dw0, u64 dw1)
+{
+	return ucall_norets(UV_WRITE_PATE, lpid, dw0, dw1);
+}
+
 #endif	/* _ASM_POWERPC_ULTRAVISOR_H */

commit bb04ffe85eebebd64d5e673a9434d968e80f3aa1
Author: Claudio Carvalho <cclaudio@linux.ibm.com>
Date:   Thu Aug 22 00:48:34 2019 -0300

    powerpc/powernv: Introduce FW_FEATURE_ULTRAVISOR
    
    In PEF enabled systems, some of the resources which were previously
    hypervisor privileged are now ultravisor privileged and controlled by
    the ultravisor firmware.
    
    This adds FW_FEATURE_ULTRAVISOR to indicate if PEF is enabled.
    
    The host kernel can use FW_FEATURE_ULTRAVISOR, for instance, to skip
    accessing resources (e.g. PTCR and LDBAR) in case PEF is enabled.
    
    Signed-off-by: Claudio Carvalho <cclaudio@linux.ibm.com>
    [ andmike: Device node name to "ibm,ultravisor" ]
    Signed-off-by: Michael Anderson <andmike@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20190822034838.27876-4-cclaudio@linux.ibm.com

diff --git a/arch/powerpc/include/asm/ultravisor.h b/arch/powerpc/include/asm/ultravisor.h
new file mode 100644
index 000000000000..dc6e1ea198f2
--- /dev/null
+++ b/arch/powerpc/include/asm/ultravisor.h
@@ -0,0 +1,14 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Ultravisor definitions
+ *
+ * Copyright 2019, IBM Corporation.
+ *
+ */
+#ifndef _ASM_POWERPC_ULTRAVISOR_H
+#define _ASM_POWERPC_ULTRAVISOR_H
+
+int early_init_dt_scan_ultravisor(unsigned long node, const char *uname,
+				  int depth, void *data);
+
+#endif	/* _ASM_POWERPC_ULTRAVISOR_H */
