commit d94d71cb45fda694a7189839f1c6aacb4f615f95
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed May 29 07:12:40 2019 -0700

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 266
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license version 2 as
      published by the free software foundation this program is
      distributed in the hope that it will be useful but without any
      warranty without even the implied warranty of merchantability or
      fitness for a particular purpose see the gnu general public license
      for more details you should have received a copy of the gnu general
      public license along with this program if not write to the free
      software foundation 51 franklin street fifth floor boston ma 02110
      1301 usa
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-only
    
    has been chosen to replace the boilerplate/reference in 67 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Reviewed-by: Richard Fontana <rfontana@redhat.com>
    Reviewed-by: Alexios Zavras <alexios.zavras@intel.com>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190529141333.953658117@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index eb3ba6390108..45704f2716e2 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -1,16 +1,5 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
 /*
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License, version 2, as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  *
  * Copyright SUSE Linux Products GmbH 2009
  *

commit 8e3f5fc1045dc49fd175b978c5457f5f51e7a2ce
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Mon Oct 8 16:31:03 2018 +1100

    KVM: PPC: Book3S HV: Framework and hcall stubs for nested virtualization
    
    This starts the process of adding the code to support nested HV-style
    virtualization.  It defines a new H_SET_PARTITION_TABLE hypercall which
    a nested hypervisor can use to set the base address and size of a
    partition table in its memory (analogous to the PTCR register).
    On the host (level 0 hypervisor) side, the H_SET_PARTITION_TABLE
    hypercall from the guest is handled by code that saves the virtual
    PTCR value for the guest.
    
    This also adds code for creating and destroying nested guests and for
    reading the partition table entry for a nested guest from L1 memory.
    Each nested guest has its own shadow LPID value, different in general
    from the LPID value used by the nested hypervisor to refer to it.  The
    shadow LPID value is allocated at nested guest creation time.
    
    Nested hypervisor functionality is only available for a radix guest,
    which therefore means a radix host on a POWER9 (or later) processor.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index d978fdf698af..eb3ba6390108 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -25,6 +25,9 @@
 #define XICS_MFRR		0xc
 #define XICS_IPI		2	/* interrupt source # for IPIs */
 
+/* LPIDs we support with this build -- runtime limit may be lower */
+#define KVMPPC_NR_LPIDS			(LPID_RSVD + 1)
+
 /* Maximum number of threads per physical core */
 #define MAX_SMT_THREADS		8
 

commit 4bb3c7a0208fc13ca70598efd109901a7cd45ae7
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Wed Mar 21 21:32:01 2018 +1100

    KVM: PPC: Book3S HV: Work around transactional memory bugs in POWER9
    
    POWER9 has hardware bugs relating to transactional memory and thread
    reconfiguration (changes to hardware SMT mode).  Specifically, the core
    does not have enough storage to store a complete checkpoint of all the
    architected state for all four threads.  The DD2.2 version of POWER9
    includes hardware modifications designed to allow hypervisor software
    to implement workarounds for these problems.  This patch implements
    those workarounds in KVM code so that KVM guests see a full, working
    transactional memory implementation.
    
    The problems center around the use of TM suspended state, where the
    CPU has a checkpointed state but execution is not transactional.  The
    workaround is to implement a "fake suspend" state, which looks to the
    guest like suspended state but the CPU does not store a checkpoint.
    In this state, any instruction that would cause a transition to
    transactional state (rfid, rfebb, mtmsrd, tresume) or would use the
    checkpointed state (treclaim) causes a "soft patch" interrupt (vector
    0x1500) to the hypervisor so that it can be emulated.  The trechkpt
    instruction also causes a soft patch interrupt.
    
    On POWER9 DD2.2, we avoid returning to the guest in any state which
    would require a checkpoint to be present.  The trechkpt in the guest
    entry path which would normally create that checkpoint is replaced by
    either a transition to fake suspend state, if the guest is in suspend
    state, or a rollback to the pre-transactional state if the guest is in
    transactional state.  Fake suspend state is indicated by a flag in the
    PACA plus a new bit in the PSSCR.  The new PSSCR bit is write-only and
    reads back as 0.
    
    On exit from the guest, if the guest is in fake suspend state, we still
    do the treclaim instruction as we would in real suspend state, in order
    to get into non-transactional state, but we do not save the resulting
    register state since there was no checkpoint.
    
    Emulation of the instructions that cause a softpatch interrupt is
    handled in two paths.  If the guest is in real suspend mode, we call
    kvmhv_p9_tm_emulation_early() to handle the cases where the guest is
    transitioning to transactional state.  This is called before we do the
    treclaim in the guest exit path; because we haven't done treclaim, we
    can get back to the guest with the transaction still active.  If the
    instruction is a case that kvmhv_p9_tm_emulation_early() doesn't
    handle, or if the guest is in fake suspend state, then we proceed to
    do the complete guest exit path and subsequently call
    kvmhv_p9_tm_emulation() in host context with the MMU on.  This handles
    all the cases including the cases that generate program interrupts
    (illegal instruction or TM Bad Thing) and facility unavailable
    interrupts.
    
    The emulation is reasonably straightforward and is mostly concerned
    with checking for exception conditions and updating the state of
    registers such as MSR and CR0.  The treclaim emulation takes care to
    ensure that the TEXASR register gets updated as if it were the guest
    treclaim instruction that had done failure recording, not the treclaim
    done in hypervisor state in the guest exit path.
    
    With this, the KVM_CAP_PPC_HTM capability returns true (1) even if
    transactional memory is not available to host userspace.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index ab386af2904f..d978fdf698af 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -119,6 +119,7 @@ struct kvmppc_host_state {
 	u8 host_ipi;
 	u8 ptid;		/* thread number within subcore when split */
 	u8 tid;			/* thread number within whole core */
+	u8 fake_suspend;
 	struct kvm_vcpu *kvm_vcpu;
 	struct kvmppc_vcore *kvm_vcore;
 	void __iomem *xics_phys;

commit c01015091a77035de1939ef106bfbcaf9a21395f
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Thu Oct 19 14:11:23 2017 +1100

    KVM: PPC: Book3S HV: Run HPT guests on POWER9 radix hosts
    
    This patch removes the restriction that a radix host can only run
    radix guests, allowing us to run HPT (hashed page table) guests as
    well.  This is useful because it provides a way to run old guest
    kernels that know about POWER8 but not POWER9.
    
    Unfortunately, POWER9 currently has a restriction that all threads
    in a given code must either all be in HPT mode, or all in radix mode.
    This means that when entering a HPT guest, we have to obtain control
    of all 4 threads in the core and get them to switch their LPIDR and
    LPCR registers, even if they are not going to run a guest.  On guest
    exit we also have to get all threads to switch LPIDR and LPCR back
    to host values.
    
    To make this feasible, we require that KVM not be in the "independent
    threads" mode, and that the CPU cores be in single-threaded mode from
    the host kernel's perspective (only thread 0 online; threads 1, 2 and
    3 offline).  That allows us to use the same code as on POWER8 for
    obtaining control of the secondary threads.
    
    To manage the LPCR/LPIDR changes required, we extend the kvm_split_info
    struct to contain the information needed by the secondary threads.
    All threads perform a barrier synchronization (where all threads wait
    for every other thread to reach the synchronization point) on guest
    entry, both before and after loading LPCR and LPIDR.  On guest exit,
    they all once again perform a barrier synchronization both before
    and after loading host values into LPCR and LPIDR.
    
    Finally, it is also currently necessary to flush the entire TLB every
    time we enter a HPT guest on a radix host.  We do this on thread 0
    with a loop of tlbiel instructions.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 7cea76f11c26..ab386af2904f 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -82,6 +82,16 @@ struct kvm_split_mode {
 	u8		do_nap;
 	u8		napped[MAX_SMT_THREADS];
 	struct kvmppc_vcore *vc[MAX_SUBCORES];
+	/* Bits for changing lpcr on P9 */
+	unsigned long	lpcr_req;
+	unsigned long	lpidr_req;
+	unsigned long	host_lpcr;
+	u32		do_set;
+	u32		do_restore;
+	union {
+		u32	allphases;
+		u8	phase[4];
+	} lpcr_sync;
 };
 
 /*
@@ -107,7 +117,8 @@ struct kvmppc_host_state {
 	u8 hwthread_req;
 	u8 hwthread_state;
 	u8 host_ipi;
-	u8 ptid;
+	u8 ptid;		/* thread number within subcore when split */
+	u8 tid;			/* thread number within whole core */
 	struct kvm_vcpu *kvm_vcpu;
 	struct kvmppc_vcore *kvm_vcore;
 	void __iomem *xics_phys;

commit 31a4d4480c616bf0fa475f1869e5df852d3544bd
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Thu Oct 19 15:14:20 2017 +1100

    Revert "KVM: PPC: Book3S HV: POWER9 does not require secondary thread management"
    
    This reverts commit 94a04bc25a2c6296bd0c5e82c10e8231c2b11f77.
    
    In order to run HPT guests on a radix POWER9 host, we will have to run
    the host in single-threaded mode, because POWER9 processors do not
    currently support running some threads of a core in HPT mode while
    others are in radix mode ("mixed mode").
    
    That means that we will need the same mechanisms that are used on
    POWER8 to make the secondary threads available to KVM, which were
    disabled on POWER9 by commit 94a04bc25a2c.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 83596f32f50b..7cea76f11c26 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -104,10 +104,6 @@ struct kvmppc_host_state {
 	u8 napping;
 
 #ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE
-	/*
-	 * hwthread_req/hwthread_state pair is used to pull sibling threads
-	 * out of guest on pre-ISAv3.0B CPUs where threads share MMU.
-	 */
 	u8 hwthread_req;
 	u8 hwthread_state;
 	u8 host_ipi;

commit 94a04bc25a2c6296bd0c5e82c10e8231c2b11f77
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Fri Aug 25 14:30:33 2017 +1000

    KVM: PPC: Book3S HV: POWER9 does not require secondary thread management
    
    POWER9 CPUs have independent MMU contexts per thread, so KVM does not
    need to quiesce secondary threads, so the hwthread_req/hwthread_state
    protocol does not have to be used. So patch it away on POWER9, and patch
    away the branch from the Linux idle wakeup to kvm_start_guest that is
    never used.
    
    Add a warning and error out of kvmppc_grab_hwthread in case it is ever
    called on POWER9.
    
    This avoids a hwsync in the idle wakeup path on POWER9.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Acked-by: Paul Mackerras <paulus@ozlabs.org>
    [mpe: Use WARN(...) instead of WARN_ON()/pr_err(...)]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 7cea76f11c26..83596f32f50b 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -104,6 +104,10 @@ struct kvmppc_host_state {
 	u8 napping;
 
 #ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE
+	/*
+	 * hwthread_req/hwthread_state pair is used to pull sibling threads
+	 * out of guest on pre-ISAv3.0B CPUs where threads share MMU.
+	 */
 	u8 hwthread_req;
 	u8 hwthread_state;
 	u8 host_ipi;

commit 898b25b202f3504335ae00055d7a2863bd93f2f8
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Thu Jun 22 15:08:42 2017 +1000

    KVM: PPC: Book3S HV: Simplify dynamic micro-threading code
    
    Since commit b009031f74da ("KVM: PPC: Book3S HV: Take out virtual
    core piggybacking code", 2016-09-15), we only have at most one
    vcore per subcore.  Previously, the fact that there might be more
    than one vcore per subcore meant that we had the notion of a
    "master vcore", which was the vcore that controlled thread 0 of
    the subcore.  We also needed a list per subcore in the core_info
    struct to record which vcores belonged to each subcore.  Now that
    there can only be one vcore in the subcore, we can replace the
    list with a simple pointer and get rid of the notion of the
    master vcore (and in fact treat every vcore as a master vcore).
    
    We can also get rid of the subcore_vm[] field in the core_info
    struct since it is never read.
    
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index b148496ffe36..7cea76f11c26 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -81,7 +81,7 @@ struct kvm_split_mode {
 	u8		subcore_size;
 	u8		do_nap;
 	u8		napped[MAX_SMT_THREADS];
-	struct kvmppc_vcore *master_vcs[MAX_SUBCORES];
+	struct kvmppc_vcore *vc[MAX_SUBCORES];
 };
 
 /*

commit 5af50993850a48ba749b122173d789ea90976c72
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Apr 5 17:54:56 2017 +1000

    KVM: PPC: Book3S HV: Native usage of the XIVE interrupt controller
    
    This patch makes KVM capable of using the XIVE interrupt controller
    to provide the standard PAPR "XICS" style hypercalls. It is necessary
    for proper operations when the host uses XIVE natively.
    
    This has been lightly tested on an actual system, including PCI
    pass-through with a TG3 device.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    [mpe: Cleanup pr_xxx(), unsplit pr_xxx() strings, etc., fix build
     failures by adding KVM_XIVE which depends on KVM_XICS and XIVE, and
     adding empty stubs for the kvm_xive_xxx() routines, fixup subject,
     integrate fixes from Paul for building PR=y HV=n]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 0593d9479f74..b148496ffe36 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -111,6 +111,8 @@ struct kvmppc_host_state {
 	struct kvm_vcpu *kvm_vcpu;
 	struct kvmppc_vcore *kvm_vcore;
 	void __iomem *xics_phys;
+	void __iomem *xive_tima_phys;
+	void __iomem *xive_tima_virt;
 	u32 saved_xirr;
 	u64 dabr;
 	u64 host_mmcr[7];	/* MMCR 0,1,A, SIAR, SDAR, MMCR2, SIER */

commit d381d7caf812f7aa9f05cfeb858c9004ac654412
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Apr 5 17:54:54 2017 +1000

    powerpc: Consolidate variants of real-mode MMIOs
    
    We have all sort of variants of MMIO accessors for the real mode
    instructions. This creates a clean set of accessors based on
    Linux normal naming conventions, replacing all occurrences of
    the old ones in the tree.
    
    I have purposefully removed the "out/in" variants in favor of
    only including __raw variants. Any code using these is already
    pretty much hand tuned to operate in a very specific environment.
    I've fixed up the 2 users (only one of them actually needed
    a barrier in the first place).
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index d318d432caa9..0593d9479f74 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -110,7 +110,7 @@ struct kvmppc_host_state {
 	u8 ptid;
 	struct kvm_vcpu *kvm_vcpu;
 	struct kvmppc_vcore *kvm_vcore;
-	unsigned long xics_phys;
+	void __iomem *xics_phys;
 	u32 saved_xirr;
 	u64 dabr;
 	u64 host_mmcr[7];	/* MMCR 0,1,A, SIAR, SDAR, MMCR2, SIER */

commit bcef83a00dc44ee25ff4d6e078cf6432ddf74dec
Author: Shreyas B. Prabhu <shreyas@linux.vnet.ibm.com>
Date:   Fri Jul 8 11:50:49 2016 +0530

    powerpc/powernv: Add platform support for stop instruction
    
    POWER ISA v3 defines a new idle processor core mechanism. In summary,
     a) new instruction named stop is added. This instruction replaces
            instructions like nap, sleep, rvwinkle.
     b) new per thread SPR named Processor Stop Status and Control Register
            (PSSCR) is added which controls the behavior of stop instruction.
    
    PSSCR layout:
    ----------------------------------------------------------
    | PLS | /// | SD | ESL | EC | PSLL | /// | TR | MTL | RL |
    ----------------------------------------------------------
    0      4     41   42    43   44     48    54   56    60
    
    PSSCR key fields:
            Bits 0:3  - Power-Saving Level Status. This field indicates the lowest
            power-saving state the thread entered since stop instruction was last
            executed.
    
            Bit 42 - Enable State Loss
            0 - No state is lost irrespective of other fields
            1 - Allows state loss
    
            Bits 44:47 - Power-Saving Level Limit
            This limits the power-saving level that can be entered into.
    
            Bits 60:63 - Requested Level
            Used to specify which power-saving level must be entered on executing
            stop instruction
    
    This patch adds support for stop instruction and PSSCR handling.
    
    Reviewed-by: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
    Signed-off-by: Shreyas B. Prabhu <shreyas@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 72b6225aca73..d318d432caa9 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -162,7 +162,7 @@ struct kvmppc_book3s_shadow_vcpu {
 
 /* Values for kvm_state */
 #define KVM_HWTHREAD_IN_KERNEL	0
-#define KVM_HWTHREAD_IN_NAP	1
+#define KVM_HWTHREAD_IN_IDLE	1
 #define KVM_HWTHREAD_IN_KVM	2
 
 #endif /* __ASM_KVM_BOOK3S_ASM_H__ */

commit c63517c2e3810071359af926f621c1f784388c3f
Author: Sam bobroff <sam.bobroff@au1.ibm.com>
Date:   Wed May 27 09:56:57 2015 +1000

    KVM: PPC: Book3S: correct width in XER handling
    
    In 64 bit kernels, the Fixed Point Exception Register (XER) is a 64
    bit field (e.g. in kvm_regs and kvm_vcpu_arch) and in most places it is
    accessed as such.
    
    This patch corrects places where it is accessed as a 32 bit field by a
    64 bit kernel.  In some cases this is via a 32 bit load or store
    instruction which, depending on endianness, will cause either the
    lower or upper 32 bits to be missed.  In another case it is cast as a
    u32, causing the upper 32 bits to be cleared.
    
    This patch corrects those places by extending the access methods to
    64 bits.
    
    Signed-off-by: Sam Bobroff <sam.bobroff@au1.ibm.com>
    Reviewed-by: Laurent Vivier <lvivier@redhat.com>
    Reviewed-by: Thomas Huth <thuth@redhat.com>
    Tested-by: Thomas Huth <thuth@redhat.com>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 57d5dfef48bd..72b6225aca73 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -132,7 +132,7 @@ struct kvmppc_book3s_shadow_vcpu {
 	bool in_use;
 	ulong gpr[14];
 	u32 cr;
-	u32 xer;
+	ulong xer;
 	ulong ctr;
 	ulong lr;
 	ulong pc;

commit b4deba5c41e9f6d3239606c9e060853d9decfee1
Author: Paul Mackerras <paulus@samba.org>
Date:   Thu Jul 2 20:38:16 2015 +1000

    KVM: PPC: Book3S HV: Implement dynamic micro-threading on POWER8
    
    This builds on the ability to run more than one vcore on a physical
    core by using the micro-threading (split-core) modes of the POWER8
    chip.  Previously, only vcores from the same VM could be run together,
    and (on POWER8) only if they had just one thread per core.  With the
    ability to split the core on guest entry and unsplit it on guest exit,
    we can run up to 8 vcpu threads from up to 4 different VMs, and we can
    run multiple vcores with 2 or 4 vcpus per vcore.
    
    Dynamic micro-threading is only available if the static configuration
    of the cores is whole-core mode (unsplit), and only on POWER8.
    
    To manage this, we introduce a new kvm_split_mode struct which is
    shared across all of the subcores in the core, with a pointer in the
    paca on each thread.  In addition we extend the core_info struct to
    have information on each subcore.  When deciding whether to add a
    vcore to the set already on the core, we now have two possibilities:
    (a) piggyback the vcore onto an existing subcore, or (b) start a new
    subcore.
    
    Currently, when any vcpu needs to exit the guest and switch to host
    virtual mode, we interrupt all the threads in all subcores and switch
    the core back to whole-core mode.  It may be possible in future to
    allow some of the subcores to keep executing in the guest while
    subcore 0 switches to the host, but that is not implemented in this
    patch.
    
    This adds a module parameter called dynamic_mt_modes which controls
    which micro-threading (split-core) modes the code will consider, as a
    bitmap.  In other words, if it is 0, no micro-threading mode is
    considered; if it is 2, only 2-way micro-threading is considered; if
    it is 4, only 4-way, and if it is 6, both 2-way and 4-way
    micro-threading mode will be considered.  The default is 6.
    
    With this, we now have secondary threads which are the primary thread
    for their subcore and therefore need to do the MMU switch.  These
    threads will need to be started even if they have no vcpu to run, so
    we use the vcore pointer in the PACA rather than the vcpu pointer to
    trigger them.
    
    It is now possible for thread 0 to find that an exit has been
    requested before it gets to switch the subcore state to the guest.  In
    that case we haven't added the guest's timebase offset to the
    timebase, so we need to be careful not to subtract the offset in the
    guest exit path.  In fact we just skip the whole path that switches
    back to host context, since we haven't switched to the guest context.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 5bdfb5dd3400..57d5dfef48bd 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -25,6 +25,12 @@
 #define XICS_MFRR		0xc
 #define XICS_IPI		2	/* interrupt source # for IPIs */
 
+/* Maximum number of threads per physical core */
+#define MAX_SMT_THREADS		8
+
+/* Maximum number of subcores per physical core */
+#define MAX_SUBCORES		4
+
 #ifdef __ASSEMBLY__
 
 #ifdef CONFIG_KVM_BOOK3S_HANDLER
@@ -65,6 +71,19 @@ kvmppc_resume_\intno:
 
 #else  /*__ASSEMBLY__ */
 
+struct kvmppc_vcore;
+
+/* Struct used for coordinating micro-threading (split-core) mode changes */
+struct kvm_split_mode {
+	unsigned long	rpr;
+	unsigned long	pmmar;
+	unsigned long	ldbar;
+	u8		subcore_size;
+	u8		do_nap;
+	u8		napped[MAX_SMT_THREADS];
+	struct kvmppc_vcore *master_vcs[MAX_SUBCORES];
+};
+
 /*
  * This struct goes in the PACA on 64-bit processors.  It is used
  * to store host state that needs to be saved when we enter a guest
@@ -100,6 +119,7 @@ struct kvmppc_host_state {
 	u64 host_spurr;
 	u64 host_dscr;
 	u64 dec_expires;
+	struct kvm_split_mode *kvm_split_mode;
 #endif
 #ifdef CONFIG_PPC_BOOK3S_64
 	u64 cfar;

commit 616dff86028298dbc91174fb3d12b8ed8cd74955
Author: Alexander Graf <agraf@suse.de>
Date:   Tue Apr 29 16:48:44 2014 +0200

    KVM: PPC: Book3S PR: Handle Facility interrupt and FSCR
    
    POWER8 introduced a new interrupt type called "Facility unavailable interrupt"
    which contains its status message in a new register called FSCR.
    
    Handle these exits and try to emulate instructions for unhandled facilities.
    Follow-on patches enable KVM to expose specific facilities into the guest.
    
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 821725c1bf46..5bdfb5dd3400 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -104,6 +104,7 @@ struct kvmppc_host_state {
 #ifdef CONFIG_PPC_BOOK3S_64
 	u64 cfar;
 	u64 ppr;
+	u64 host_fscr;
 #endif
 };
 
@@ -133,6 +134,7 @@ struct kvmppc_book3s_shadow_vcpu {
 		u64     esid;
 		u64     vsid;
 	} slb[64];			/* guest SLB */
+	u64 shadow_fscr;
 #endif
 };
 

commit 72cde5a88d37ba88ad1d47aecf957a9e528636d7
Author: Paul Mackerras <paulus@samba.org>
Date:   Tue Mar 25 10:47:08 2014 +1100

    KVM: PPC: Book3S HV: Save/restore host PMU registers that are new in POWER8
    
    Currently we save the host PMU configuration, counter values, etc.,
    when entering a guest, and restore it on return from the guest.
    (We have to do this because the guest has control of the PMU while
    it is executing.)  However, we missed saving/restoring the SIAR and
    SDAR registers, as well as the registers which are new on POWER8,
    namely SIER and MMCR2.
    
    This adds code to save the values of these registers when entering
    the guest and restore them on exit.  This also works around the bug
    in POWER8 where setting PMAE with a counter already negative doesn't
    generate an interrupt.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Acked-by: Scott Wood <scottwood@freescale.com>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index f3a91dc02c98..821725c1bf46 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -94,7 +94,7 @@ struct kvmppc_host_state {
 	unsigned long xics_phys;
 	u32 saved_xirr;
 	u64 dabr;
-	u64 host_mmcr[3];
+	u64 host_mmcr[7];	/* MMCR 0,1,A, SIAR, SDAR, MMCR2, SIER */
 	u32 host_pmc[8];
 	u64 host_purr;
 	u64 host_spurr;

commit b73117c49364551ff789db7c424a115ac5b77850
Merge: 77f01bdfa5e5 4068890931f6
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Wed Jan 29 18:29:01 2014 +0100

    Merge branch 'kvm-ppc-next' of git://github.com/agraf/linux-2.6 into kvm-queue
    
    Conflicts:
            arch/powerpc/kvm/book3s_hv_rmhandlers.S
            arch/powerpc/kvm/booke.c

commit e0b7ec058c0eb7ba8d5d937d81de2bd16db6970e
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Jan 8 21:25:20 2014 +1100

    KVM: PPC: Book3S HV: Align physical and virtual CPU thread numbers
    
    On a threaded processor such as POWER7, we group VCPUs into virtual
    cores and arrange that the VCPUs in a virtual core run on the same
    physical core.  Currently we don't enforce any correspondence between
    virtual thread numbers within a virtual core and physical thread
    numbers.  Physical threads are allocated starting at 0 on a first-come
    first-served basis to runnable virtual threads (VCPUs).
    
    POWER8 implements a new "msgsndp" instruction which guest kernels can
    use to interrupt other threads in the same core or sub-core.  Since
    the instruction takes the destination physical thread ID as a parameter,
    it becomes necessary to align the physical thread IDs with the virtual
    thread IDs, that is, to make sure virtual thread N within a virtual
    core always runs on physical thread N.
    
    This means that it's possible that thread 0, which is where we call
    __kvmppc_vcore_entry, may end up running some other vcpu than the
    one whose task called kvmppc_run_core(), or it may end up running
    no vcpu at all, if for example thread 0 of the virtual core is
    currently executing in userspace.  However, we do need thread 0
    to be responsible for switching the MMU -- a previous version of
    this patch that had other threads switching the MMU was found to
    be responsible for occasional memory corruption and machine check
    interrupts in the guest on POWER7 machines.
    
    To accommodate this, we no longer pass the vcpu pointer to
    __kvmppc_vcore_entry, but instead let the assembly code load it from
    the PACA.  Since the assembly code will need to know the kvm pointer
    and the thread ID for threads which don't have a vcpu, we move the
    thread ID into the PACA and we add a kvm pointer to the virtual core
    structure.
    
    In the case where thread 0 has no vcpu to run, it still calls into
    kvmppc_hv_entry in order to do the MMU switch, and then naps until
    either its vcpu is ready to run in the guest, or some other thread
    needs to exit the guest.  In the latter case, thread 0 jumps to the
    code that switches the MMU back to the host.  This control flow means
    that now we switch the MMU before loading any guest vcpu state.
    Similarly, on guest exit we now save all the guest vcpu state before
    switching the MMU back to the host.  This has required substantial
    code movement, making the diff rather large.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 0bd9348a4db9..490b34f5d6bf 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -87,6 +87,7 @@ struct kvmppc_host_state {
 	u8 hwthread_req;
 	u8 hwthread_state;
 	u8 host_ipi;
+	u8 ptid;
 	struct kvm_vcpu *kvm_vcpu;
 	struct kvmppc_vcore *kvm_vcore;
 	unsigned long xics_phys;

commit 36e7bb38028d3d812aa7749208249d600a30c22c
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Mon Nov 11 19:29:47 2013 +0530

    powerpc: book3s: kvm: Don't abuse host r2 in exit path
    
    We don't use PACATOC for PR. Avoid updating HOST_R2 with PR
    KVM mode when both HV and PR are enabled in the kernel. Without this we
    get the below crash
    
    (qemu)
    Unable to handle kernel paging request for data at address 0xffffffffffff8310
    Faulting instruction address: 0xc00000000001d5a4
    cpu 0x2: Vector: 300 (Data Access) at [c0000001dc53aef0]
        pc: c00000000001d5a4: .vtime_delta.isra.1+0x34/0x1d0
        lr: c00000000001d760: .vtime_account_system+0x20/0x60
        sp: c0000001dc53b170
       msr: 8000000000009032
       dar: ffffffffffff8310
     dsisr: 40000000
      current = 0xc0000001d76c62d0
      paca    = 0xc00000000fef1100   softe: 0        irq_happened: 0x01
        pid   = 4472, comm = qemu-system-ppc
    enter ? for help
    [c0000001dc53b200] c00000000001d760 .vtime_account_system+0x20/0x60
    [c0000001dc53b290] c00000000008d050 .kvmppc_handle_exit_pr+0x60/0xa50
    [c0000001dc53b340] c00000000008f51c kvm_start_lightweight+0xb4/0xc4
    [c0000001dc53b510] c00000000008cdf0 .kvmppc_vcpu_run_pr+0x150/0x2e0
    [c0000001dc53b9e0] c00000000008341c .kvmppc_vcpu_run+0x2c/0x40
    [c0000001dc53ba50] c000000000080af4 .kvm_arch_vcpu_ioctl_run+0x54/0x1b0
    [c0000001dc53bae0] c00000000007b4c8 .kvm_vcpu_ioctl+0x478/0x730
    [c0000001dc53bca0] c0000000002140cc .do_vfs_ioctl+0x4ac/0x770
    [c0000001dc53bd80] c0000000002143e8 .SyS_ioctl+0x58/0xb0
    [c0000001dc53be30] c000000000009e58 syscall_exit+0x0/0x98
    
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 412b2f389474..192917d2239c 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -79,6 +79,7 @@ struct kvmppc_host_state {
 	ulong vmhandler;
 	ulong scratch0;
 	ulong scratch1;
+	ulong scratch2;
 	u8 in_guest;
 	u8 restore_hid5;
 	u8 napping;

commit 40fdd8c88c4a5e9b26bfbed2215ac661f24aef07
Author: Alexander Graf <agraf@suse.de>
Date:   Fri Nov 29 02:29:00 2013 +0100

    KVM: PPC: Book3S: PR: Make svcpu -> vcpu store preempt savvy
    
    As soon as we get back to our "highmem" handler in virtual address
    space we may get preempted. Today the reason we can get preempted is
    that we replay interrupts and all the lazy logic thinks we have
    interrupts enabled.
    
    However, it's not hard to make the code interruptible and that way
    we can enable and handle interrupts even earlier.
    
    This fixes random guest crashes that happened with CONFIG_PREEMPT=y
    for me.
    
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 0bd9348a4db9..412b2f389474 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -106,6 +106,7 @@ struct kvmppc_host_state {
 };
 
 struct kvmppc_book3s_shadow_vcpu {
+	bool in_use;
 	ulong gpr[14];
 	u32 cr;
 	u32 xer;

commit 9975f5e3692d320b4259a4d2edd8a979adb1e535
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Mon Oct 7 22:17:52 2013 +0530

    kvm: powerpc: book3s: Add a new config variable CONFIG_KVM_BOOK3S_HV_POSSIBLE
    
    This help ups to select the relevant code in the kernel code
    when we later move HV and PR bits as seperate modules. The patch
    also makes the config options for PR KVM selectable
    
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 62737113c2b9..0bd9348a4db9 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -83,7 +83,7 @@ struct kvmppc_host_state {
 	u8 restore_hid5;
 	u8 napping;
 
-#ifdef CONFIG_KVM_BOOK3S_64_HV
+#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE
 	u8 hwthread_req;
 	u8 hwthread_state;
 	u8 host_ipi;

commit a2d56020d1d91934e7bb3e7c8a5a3b5921ce121b
Author: Paul Mackerras <paulus@samba.org>
Date:   Fri Sep 20 14:52:43 2013 +1000

    KVM: PPC: Book3S PR: Keep volatile reg values in vcpu rather than shadow_vcpu
    
    Currently PR-style KVM keeps the volatile guest register values
    (R0 - R13, CR, LR, CTR, XER, PC) in a shadow_vcpu struct rather than
    the main kvm_vcpu struct.  For 64-bit, the shadow_vcpu exists in two
    places, a kmalloc'd struct and in the PACA, and it gets copied back
    and forth in kvmppc_core_vcpu_load/put(), because the real-mode code
    can't rely on being able to access the kmalloc'd struct.
    
    This changes the code to copy the volatile values into the shadow_vcpu
    as one of the last things done before entering the guest.  Similarly
    the values are copied back out of the shadow_vcpu to the kvm_vcpu
    immediately after exiting the guest.  We arrange for interrupts to be
    still disabled at this point so that we can't get preempted on 64-bit
    and end up copying values from the wrong PACA.
    
    This means that the accessor functions in kvm_book3s.h for these
    registers are greatly simplified, and are same between PR and HV KVM.
    In places where accesses to shadow_vcpu fields are now replaced by
    accesses to the kvm_vcpu, we can also remove the svcpu_get/put pairs.
    Finally, on 64-bit, we don't need the kmalloc'd struct at all any more.
    
    With this, the time to read the PVR one million times in a loop went
    from 567.7ms to 575.5ms (averages of 6 values), an increase of about
    1.4% for this worse-case test for guest entries and exits.  The
    standard deviation of the measurements is about 11ms, so the
    difference is only marginally significant statistically.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 22f46061ae84..62737113c2b9 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -109,14 +109,14 @@ struct kvmppc_book3s_shadow_vcpu {
 	ulong gpr[14];
 	u32 cr;
 	u32 xer;
-
-	u32 fault_dsisr;
-	u32 last_inst;
 	ulong ctr;
 	ulong lr;
 	ulong pc;
+
 	ulong shadow_srr1;
 	ulong fault_dar;
+	u32 fault_dsisr;
+	u32 last_inst;
 
 #ifdef CONFIG_PPC_BOOK3S_32
 	u32     sr[16];			/* Guest SRs */

commit 4b8473c9c19dff1b0c672f182cc50b9952cf42e7
Author: Paul Mackerras <paulus@samba.org>
Date:   Fri Sep 20 14:52:39 2013 +1000

    KVM: PPC: Book3S HV: Add support for guest Program Priority Register
    
    POWER7 and later IBM server processors have a register called the
    Program Priority Register (PPR), which controls the priority of
    each hardware CPU SMT thread, and affects how fast it runs compared
    to other SMT threads.  This priority can be controlled by writing to
    the PPR or by use of a set of instructions of the form or rN,rN,rN
    which are otherwise no-ops but have been defined to set the priority
    to particular levels.
    
    This adds code to context switch the PPR when entering and exiting
    guests and to make the PPR value accessible through the SET/GET_ONE_REG
    interface.  When entering the guest, we set the PPR as late as
    possible, because if we are setting a low thread priority it will
    make the code run slowly from that point on.  Similarly, the
    first-level interrupt handlers save the PPR value in the PACA very
    early on, and set the thread priority to the medium level, so that
    the interrupt handling code runs at a reasonable speed.
    
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 9039d3c97eec..22f46061ae84 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -101,6 +101,7 @@ struct kvmppc_host_state {
 #endif
 #ifdef CONFIG_PPC_BOOK3S_64
 	u64 cfar;
+	u64 ppr;
 #endif
 };
 

commit 54695c3088a74e25474db8eb6b490b45d1aeb0ca
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Apr 17 20:30:50 2013 +0000

    KVM: PPC: Book3S HV: Speed up wakeups of CPUs on HV KVM
    
    Currently, we wake up a CPU by sending a host IPI with
    smp_send_reschedule() to thread 0 of that core, which will take all
    threads out of the guest, and cause them to re-evaluate their
    interrupt status on the way back in.
    
    This adds a mechanism to differentiate real host IPIs from IPIs sent
    by KVM for guest threads to poke each other, in order to target the
    guest threads precisely when possible and avoid that global switch of
    the core to host state.
    
    We then use this new facility in the in-kernel XICS code.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index cdc3d2717cc6..9039d3c97eec 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -20,6 +20,11 @@
 #ifndef __ASM_KVM_BOOK3S_ASM_H__
 #define __ASM_KVM_BOOK3S_ASM_H__
 
+/* XICS ICP register offsets */
+#define XICS_XIRR		4
+#define XICS_MFRR		0xc
+#define XICS_IPI		2	/* interrupt source # for IPIs */
+
 #ifdef __ASSEMBLY__
 
 #ifdef CONFIG_KVM_BOOK3S_HANDLER
@@ -81,10 +86,11 @@ struct kvmppc_host_state {
 #ifdef CONFIG_KVM_BOOK3S_64_HV
 	u8 hwthread_req;
 	u8 hwthread_state;
-
+	u8 host_ipi;
 	struct kvm_vcpu *kvm_vcpu;
 	struct kvmppc_vcore *kvm_vcore;
 	unsigned long xics_phys;
+	u32 saved_xirr;
 	u64 dabr;
 	u64 host_mmcr[3];
 	u32 host_pmc[8];

commit 0acb91112a148fbb31678e66839ef757f3be3aa4
Author: Paul Mackerras <paulus@samba.org>
Date:   Mon Feb 4 18:10:51 2013 +0000

    powerpc/kvm/book3s_hv: Preserve guest CFAR register value
    
    The CFAR (Come-From Address Register) is a useful debugging aid that
    exists on POWER7 processors.  Currently HV KVM doesn't save or restore
    the CFAR register for guest vcpus, making the CFAR of limited use in
    guests.
    
    This adds the necessary code to capture the CFAR value saved in the
    early exception entry code (it has to be saved before any branch is
    executed), save it in the vcpu.arch struct, and restore it on entry
    to the guest.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 88609b23b775..cdc3d2717cc6 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -93,6 +93,9 @@ struct kvmppc_host_state {
 	u64 host_dscr;
 	u64 dec_expires;
 #endif
+#ifdef CONFIG_PPC_BOOK3S_64
+	u64 cfar;
+#endif
 };
 
 struct kvmppc_book3s_shadow_vcpu {

commit 0127262c01f0beb485f917c720d1d95d165dfdbf
Author: Mihai Caraman <mihai.caraman@freescale.com>
Date:   Thu Sep 6 02:49:44 2012 +0000

    powerpc: Restore VDSO information on critical exception om BookE
    
    Critical exception on 64-bit booke uses user-visible SPRG3 as scratch.
    Restore VDSO information in SPRG3 on exception prolog.
    
    Use a common sprg3 field in PACA for all powerpc64 architectures.
    
    Signed-off-by: Mihai Caraman <mihai.caraman@freescale.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index bfcd00c1485d..88609b23b775 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -74,7 +74,6 @@ struct kvmppc_host_state {
 	ulong vmhandler;
 	ulong scratch0;
 	ulong scratch1;
-	ulong sprg3;
 	u8 in_guest;
 	u8 restore_hid5;
 	u8 napping;

commit 18ad51dd342a7eb09dbcd059d0b451b616d4dafc
Author: Anton Blanchard <anton@samba.org>
Date:   Wed Jul 4 20:37:11 2012 +0000

    powerpc: Add VDSO version of getcpu
    
    We have a request for a fast method of getting CPU and NUMA node IDs
    from userspace. This patch implements a getcpu VDSO function,
    similar to x86.
    
    Ben suggested we use SPRG3 which is userspace readable. SPRG3 can be
    modified by a KVM guest, so we save the SPRG3 value in the paca and
    restore it when transitioning from the guest to the host.
    
    I have a glibc patch that implements sched_getcpu on top of this.
    Testing on a POWER7:
    
    baseline: 538 cycles
    vdso:      30 cycles
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 88609b23b775..bfcd00c1485d 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -74,6 +74,7 @@ struct kvmppc_host_state {
 	ulong vmhandler;
 	ulong scratch0;
 	ulong scratch1;
+	ulong sprg3;
 	u8 in_guest;
 	u8 restore_hid5;
 	u8 napping;

commit f0888f70151c7f53de2b45ee20ff1905837943e8
Author: Paul Mackerras <paulus@samba.org>
Date:   Fri Feb 3 00:54:17 2012 +0000

    KVM: PPC: Book3S HV: Make secondary threads more robust against stray IPIs
    
    Currently on POWER7, if we are running the guest on a core and we don't
    need all the hardware threads, we do nothing to ensure that the unused
    threads aren't executing in the kernel (other than checking that they
    are offline).  We just assume they're napping and we don't do anything
    to stop them trying to enter the kernel while the guest is running.
    This means that a stray IPI can wake up the hardware thread and it will
    then try to enter the kernel, but since the core is in guest context,
    it will execute code from the guest in hypervisor mode once it turns the
    MMU on, which tends to lead to crashes or hangs in the host.
    
    This fixes the problem by adding two new one-byte flags in the
    kvmppc_host_state structure in the PACA which are used to interlock
    between the primary thread and the unused secondary threads when entering
    the guest.  With these flags, the primary thread can ensure that the
    unused secondaries are not already in kernel mode (i.e. handling a stray
    IPI) and then indicate that they should not try to enter the kernel
    if they do get woken for any reason.  Instead they will go into KVM code,
    find that there is no vcpu to run, acknowledge and clear the IPI and go
    back to nap mode.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 1f2f5b6156bd..88609b23b775 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -79,6 +79,9 @@ struct kvmppc_host_state {
 	u8 napping;
 
 #ifdef CONFIG_KVM_BOOK3S_64_HV
+	u8 hwthread_req;
+	u8 hwthread_state;
+
 	struct kvm_vcpu *kvm_vcpu;
 	struct kvmppc_vcore *kvm_vcore;
 	unsigned long xics_phys;
@@ -122,4 +125,9 @@ struct kvmppc_book3s_shadow_vcpu {
 
 #endif /*__ASSEMBLY__ */
 
+/* Values for kvm_state */
+#define KVM_HWTHREAD_IN_KERNEL	0
+#define KVM_HWTHREAD_IN_NAP	1
+#define KVM_HWTHREAD_IN_KVM	2
+
 #endif /* __ASM_KVM_BOOK3S_ASM_H__ */

commit 19ccb76a1938ab364a412253daec64613acbf3df
Author: Paul Mackerras <paulus@samba.org>
Date:   Sat Jul 23 17:42:46 2011 +1000

    KVM: PPC: Implement H_CEDE hcall for book3s_hv in real-mode code
    
    With a KVM guest operating in SMT4 mode (i.e. 4 hardware threads per
    core), whenever a CPU goes idle, we have to pull all the other
    hardware threads in the core out of the guest, because the H_CEDE
    hcall is handled in the kernel.  This is inefficient.
    
    This adds code to book3s_hv_rmhandlers.S to handle the H_CEDE hcall
    in real mode.  When a guest vcpu does an H_CEDE hcall, we now only
    exit to the kernel if all the other vcpus in the same core are also
    idle.  Otherwise we mark this vcpu as napping, save state that could
    be lost in nap mode (mainly GPRs and FPRs), and execute the nap
    instruction.  When the thread wakes up, because of a decrementer or
    external interrupt, we come back in at kvm_start_guest (from the
    system reset interrupt vector), find the `napping' flag set in the
    paca, and go to the resume path.
    
    This has some other ramifications.  First, when starting a core, we
    now start all the threads, both those that are immediately runnable and
    those that are idle.  This is so that we don't have to pull all the
    threads out of the guest when an idle thread gets a decrementer interrupt
    and wants to start running.  In fact the idle threads will all start
    with the H_CEDE hcall returning; being idle they will just do another
    H_CEDE immediately and go to nap mode.
    
    This required some changes to kvmppc_run_core() and kvmppc_run_vcpu().
    These functions have been restructured to make them simpler and clearer.
    We introduce a level of indirection in the wait queue that gets woken
    when external and decrementer interrupts get generated for a vcpu, so
    that we can have the 4 vcpus in a vcore using the same wait queue.
    We need this because the 4 vcpus are being handled by one thread.
    
    Secondly, when we need to exit from the guest to the kernel, we now
    have to generate an IPI for any napping threads, because an HDEC
    interrupt doesn't wake up a napping thread.
    
    Thirdly, we now need to be able to handle virtual external interrupts
    and decrementer interrupts becoming pending while a thread is napping,
    and deliver those interrupts to the guest when the thread wakes.
    This is done in kvmppc_cede_reentry, just before fast_guest_return.
    
    Finally, since we are not using the generic kvm_vcpu_block for book3s_hv,
    and hence not calling kvm_arch_vcpu_runnable, we can remove the #ifdef
    from kvm_arch_vcpu_runnable.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index af73469530e6..1f2f5b6156bd 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -76,6 +76,7 @@ struct kvmppc_host_state {
 	ulong scratch1;
 	u8 in_guest;
 	u8 restore_hid5;
+	u8 napping;
 
 #ifdef CONFIG_KVM_BOOK3S_64_HV
 	struct kvm_vcpu *kvm_vcpu;

commit 02143947603fe90237a0423d34dd8943de229f78
Author: Paul Mackerras <paulus@samba.org>
Date:   Sat Jul 23 17:41:44 2011 +1000

    KVM: PPC: book3s_pr: Simplify transitions between virtual and real mode
    
    This simplifies the way that the book3s_pr makes the transition to
    real mode when entering the guest.  We now call kvmppc_entry_trampoline
    (renamed from kvmppc_rmcall) in the base kernel using a normal function
    call instead of doing an indirect call through a pointer in the vcpu.
    If kvm is a module, the module loader takes care of generating a
    trampoline as it does for other calls to functions outside the module.
    
    kvmppc_entry_trampoline then disables interrupts and jumps to
    kvmppc_handler_trampoline_enter in real mode using an rfi[d].
    That then uses the link register as the address to return to
    (potentially in module space) when the guest exits.
    
    This also simplifies the way that we call the Linux interrupt handler
    when we exit the guest due to an external, decrementer or performance
    monitor interrupt.  Instead of turning on the MMU, then deciding that
    we need to call the Linux handler and turning the MMU back off again,
    we now go straight to the handler at the point where we would turn the
    MMU on.  The handler will then return to the virtual-mode code
    (potentially in the module).
    
    Along the way, this moves the setting and clearing of the HID5 DCBZ32
    bit into real-mode interrupts-off code, and also makes sure that
    we clear the MSR[RI] bit before loading values into SRR0/1.
    
    The net result is that we no longer need any code addresses to be
    stored in vcpu->arch.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index ef7b3688c3b6..af73469530e6 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -75,6 +75,7 @@ struct kvmppc_host_state {
 	ulong scratch0;
 	ulong scratch1;
 	u8 in_guest;
+	u8 restore_hid5;
 
 #ifdef CONFIG_KVM_BOOK3S_64_HV
 	struct kvm_vcpu *kvm_vcpu;

commit 9e368f2915601cd5bc7f5fd638b58435b018bbd7
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Jun 29 00:40:08 2011 +0000

    KVM: PPC: book3s_hv: Add support for PPC970-family processors
    
    This adds support for running KVM guests in supervisor mode on those
    PPC970 processors that have a usable hypervisor mode.  Unfortunately,
    Apple G5 machines have supervisor mode disabled (MSR[HV] is forced to
    1), but the YDL PowerStation does have a usable hypervisor mode.
    
    There are several differences between the PPC970 and POWER7 in how
    guests are managed.  These differences are accommodated using the
    CPU_FTR_ARCH_201 (PPC970) and CPU_FTR_ARCH_206 (POWER7) CPU feature
    bits.  Notably, on PPC970:
    
    * The LPCR, LPID or RMOR registers don't exist, and the functions of
      those registers are provided by bits in HID4 and one bit in HID0.
    
    * External interrupts can be directed to the hypervisor, but unlike
      POWER7 they are masked by MSR[EE] in non-hypervisor modes and use
      SRR0/1 not HSRR0/1.
    
    * There is no virtual RMA (VRMA) mode; the guest must use an RMO
      (real mode offset) area.
    
    * The TLB entries are not tagged with the LPID, so it is necessary to
      flush the whole TLB on partition switch.  Furthermore, when switching
      partitions we have to ensure that no other CPU is executing the tlbie
      or tlbsync instructions in either the old or the new partition,
      otherwise undefined behaviour can occur.
    
    * The PMU has 8 counters (PMC registers) rather than 6.
    
    * The DSCR, PURR, SPURR, AMR, AMOR, UAMOR registers don't exist.
    
    * The SLB has 64 entries rather than 32.
    
    * There is no mediated external interrupt facility, so if we switch to
      a guest that has a virtual external interrupt pending but the guest
      has MSR[EE] = 0, we have to arrange to have an interrupt pending for
      it so that we can get control back once it re-enables interrupts.  We
      do that by sending ourselves an IPI with smp_send_reschedule after
      hard-disabling interrupts.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 9cfd5436782d..ef7b3688c3b6 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -82,7 +82,7 @@ struct kvmppc_host_state {
 	unsigned long xics_phys;
 	u64 dabr;
 	u64 host_mmcr[3];
-	u32 host_pmc[6];
+	u32 host_pmc[8];
 	u64 host_purr;
 	u64 host_spurr;
 	u64 host_dscr;

commit 371fefd6f2dc46668e00871930dde613b88d4bde
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Jun 29 00:23:08 2011 +0000

    KVM: PPC: Allow book3s_hv guests to use SMT processor modes
    
    This lifts the restriction that book3s_hv guests can only run one
    hardware thread per core, and allows them to use up to 4 threads
    per core on POWER7.  The host still has to run single-threaded.
    
    This capability is advertised to qemu through a new KVM_CAP_PPC_SMT
    capability.  The return value of the ioctl querying this capability
    is the number of vcpus per virtual CPU core (vcore), currently 4.
    
    To use this, the host kernel should be booted with all threads
    active, and then all the secondary threads should be offlined.
    This will put the secondary threads into nap mode.  KVM will then
    wake them from nap mode and use them for running guest code (while
    they are still offline).  To wake the secondary threads, we send
    them an IPI using a new xics_wake_cpu() function, implemented in
    arch/powerpc/sysdev/xics/icp-native.c.  In other words, at this stage
    we assume that the platform has a XICS interrupt controller and
    we are using icp-native.c to drive it.  Since the woken thread will
    need to acknowledge and clear the IPI, we also export the base
    physical address of the XICS registers using kvmppc_set_xics_phys()
    for use in the low-level KVM book3s code.
    
    When a vcpu is created, it is assigned to a virtual CPU core.
    The vcore number is obtained by dividing the vcpu number by the
    number of threads per core in the host.  This number is exported
    to userspace via the KVM_CAP_PPC_SMT capability.  If qemu wishes
    to run the guest in single-threaded mode, it should make all vcpu
    numbers be multiples of the number of threads per core.
    
    We distinguish three states of a vcpu: runnable (i.e., ready to execute
    the guest), blocked (that is, idle), and busy in host.  We currently
    implement a policy that the vcore can run only when all its threads
    are runnable or blocked.  This way, if a vcpu needs to execute elsewhere
    in the kernel or in qemu, it can do so without being starved of CPU
    by the other vcpus.
    
    When a vcore starts to run, it executes in the context of one of the
    vcpu threads.  The other vcpu threads all go to sleep and stay asleep
    until something happens requiring the vcpu thread to return to qemu,
    or to wake up to run the vcore (this can happen when another vcpu
    thread goes from busy in host state to blocked).
    
    It can happen that a vcpu goes from blocked to runnable state (e.g.
    because of an interrupt), and the vcore it belongs to is already
    running.  In that case it can start to run immediately as long as
    the none of the vcpus in the vcore have started to exit the guest.
    We send the next free thread in the vcore an IPI to get it to start
    to execute the guest.  It synchronizes with the other threads via
    the vcore->entry_exit_count field to make sure that it doesn't go
    into the guest if the other vcpus are exiting by the time that it
    is ready to actually enter the guest.
    
    Note that there is no fixed relationship between the hardware thread
    number and the vcpu number.  Hardware threads are assigned to vcpus
    as they become runnable, so we will always use the lower-numbered
    hardware threads in preference to higher-numbered threads if not all
    the vcpus in the vcore are runnable, regardless of which vcpus are
    runnable.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index b7b039532fbc..9cfd5436782d 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -78,6 +78,8 @@ struct kvmppc_host_state {
 
 #ifdef CONFIG_KVM_BOOK3S_64_HV
 	struct kvm_vcpu *kvm_vcpu;
+	struct kvmppc_vcore *kvm_vcore;
+	unsigned long xics_phys;
 	u64 dabr;
 	u64 host_mmcr[3];
 	u32 host_pmc[6];

commit de56a948b9182fbcf92cb8212f114de096c2d574
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Jun 29 00:21:34 2011 +0000

    KVM: PPC: Add support for Book3S processors in hypervisor mode
    
    This adds support for KVM running on 64-bit Book 3S processors,
    specifically POWER7, in hypervisor mode.  Using hypervisor mode means
    that the guest can use the processor's supervisor mode.  That means
    that the guest can execute privileged instructions and access privileged
    registers itself without trapping to the host.  This gives excellent
    performance, but does mean that KVM cannot emulate a processor
    architecture other than the one that the hardware implements.
    
    This code assumes that the guest is running paravirtualized using the
    PAPR (Power Architecture Platform Requirements) interface, which is the
    interface that IBM's PowerVM hypervisor uses.  That means that existing
    Linux distributions that run on IBM pSeries machines will also run
    under KVM without modification.  In order to communicate the PAPR
    hypercalls to qemu, this adds a new KVM_EXIT_PAPR_HCALL exit code
    to include/linux/kvm.h.
    
    Currently the choice between book3s_hv support and book3s_pr support
    (i.e. the existing code, which runs the guest in user mode) has to be
    made at kernel configuration time, so a given kernel binary can only
    do one or the other.
    
    This new book3s_hv code doesn't support MMIO emulation at present.
    Since we are running paravirtualized guests, this isn't a serious
    restriction.
    
    With the guest running in supervisor mode, most exceptions go straight
    to the guest.  We will never get data or instruction storage or segment
    interrupts, alignment interrupts, decrementer interrupts, program
    interrupts, single-step interrupts, etc., coming to the hypervisor from
    the guest.  Therefore this introduces a new KVMTEST_NONHV macro for the
    exception entry path so that we don't have to do the KVM test on entry
    to those exception handlers.
    
    We do however get hypervisor decrementer, hypervisor data storage,
    hypervisor instruction storage, and hypervisor emulation assist
    interrupts, so we have to handle those.
    
    In hypervisor mode, real-mode accesses can access all of RAM, not just
    a limited amount.  Therefore we put all the guest state in the vcpu.arch
    and use the shadow_vcpu in the PACA only for temporary scratch space.
    We allocate the vcpu with kzalloc rather than vzalloc, and we don't use
    anything in the kvmppc_vcpu_book3s struct, so we don't allocate it.
    We don't have a shared page with the guest, but we still need a
    kvm_vcpu_arch_shared struct to store the values of various registers,
    so we include one in the vcpu_arch struct.
    
    The POWER7 processor has a restriction that all threads in a core have
    to be in the same partition.  MMU-on kernel code counts as a partition
    (partition 0), so we have to do a partition switch on every entry to and
    exit from the guest.  At present we require the host and guest to run
    in single-thread mode because of this hardware restriction.
    
    This code allocates a hashed page table for the guest and initializes
    it with HPTEs for the guest's Virtual Real Memory Area (VRMA).  We
    require that the guest memory is allocated using 16MB huge pages, in
    order to simplify the low-level memory management.  This also means that
    we can get away without tracking paging activity in the host for now,
    since huge pages can't be paged or swapped.
    
    This also adds a few new exports needed by the book3s_hv code.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 312617529864..b7b039532fbc 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -70,10 +70,22 @@ kvmppc_resume_\intno:
 struct kvmppc_host_state {
 	ulong host_r1;
 	ulong host_r2;
+	ulong host_msr;
 	ulong vmhandler;
 	ulong scratch0;
 	ulong scratch1;
 	u8 in_guest;
+
+#ifdef CONFIG_KVM_BOOK3S_64_HV
+	struct kvm_vcpu *kvm_vcpu;
+	u64 dabr;
+	u64 host_mmcr[3];
+	u32 host_pmc[6];
+	u64 host_purr;
+	u64 host_spurr;
+	u64 host_dscr;
+	u64 dec_expires;
+#endif
 };
 
 struct kvmppc_book3s_shadow_vcpu {

commit 3c42bf8a717cb636e0ed2ed77194669e2ac3ed56
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Jun 29 00:20:58 2011 +0000

    KVM: PPC: Split host-state fields out of kvmppc_book3s_shadow_vcpu
    
    There are several fields in struct kvmppc_book3s_shadow_vcpu that
    temporarily store bits of host state while a guest is running,
    rather than anything relating to the particular guest or vcpu.
    This splits them out into a new kvmppc_host_state structure and
    modifies the definitions in asm-offsets.c to suit.
    
    On 32-bit, we have a kvmppc_host_state structure inside the
    kvmppc_book3s_shadow_vcpu since the assembly code needs to be able
    to get to them both with one pointer.  On 64-bit they are separate
    fields in the PACA.  This means that on 64-bit we don't need to
    copy the kvmppc_host_state in and out on vcpu load/unload, and
    in future will mean that the book3s_hv code doesn't need a
    shadow_vcpu struct in the PACA at all.  That does mean that we
    have to be careful not to rely on any values persisting in the
    hstate field of the paca across any point where we could block
    or get preempted.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index d5a8a3861635..312617529864 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -60,6 +60,22 @@ kvmppc_resume_\intno:
 
 #else  /*__ASSEMBLY__ */
 
+/*
+ * This struct goes in the PACA on 64-bit processors.  It is used
+ * to store host state that needs to be saved when we enter a guest
+ * and restored when we exit, but isn't specific to any particular
+ * guest or vcpu.  It also has some scratch fields used by the guest
+ * exit code.
+ */
+struct kvmppc_host_state {
+	ulong host_r1;
+	ulong host_r2;
+	ulong vmhandler;
+	ulong scratch0;
+	ulong scratch1;
+	u8 in_guest;
+};
+
 struct kvmppc_book3s_shadow_vcpu {
 	ulong gpr[14];
 	u32 cr;
@@ -73,17 +89,12 @@ struct kvmppc_book3s_shadow_vcpu {
 	ulong shadow_srr1;
 	ulong fault_dar;
 
-	ulong host_r1;
-	ulong host_r2;
-	ulong handler;
-	ulong scratch0;
-	ulong scratch1;
-	ulong vmhandler;
-	u8 in_guest;
-
 #ifdef CONFIG_PPC_BOOK3S_32
 	u32     sr[16];			/* Guest SRs */
+
+	struct kvmppc_host_state hstate;
 #endif
+
 #ifdef CONFIG_PPC_BOOK3S_64
 	u8 slb_max;			/* highest used guest slb entry */
 	struct  {

commit a5d4f3ad3a28cf046836b9bfae61d532b8f77036
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Apr 5 14:20:31 2011 +1000

    powerpc: Base support for exceptions using HSRR0/1
    
    Pass the register type to the prolog, also provides alternate "HV"
    version of hardware interrupt (0x500) and adjust LPES accordingly
    
    We tag those interrupts by setting bit 0x2 in the trap number
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 36fdb3aff30b..d5a8a3861635 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -34,6 +34,7 @@
 	    (\intno == BOOK3S_INTERRUPT_DATA_SEGMENT) || \
 	    (\intno == BOOK3S_INTERRUPT_INST_SEGMENT) || \
 	    (\intno == BOOK3S_INTERRUPT_EXTERNAL) || \
+	    (\intno == BOOK3S_INTERRUPT_EXTERNAL_HV) || \
 	    (\intno == BOOK3S_INTERRUPT_ALIGNMENT) || \
 	    (\intno == BOOK3S_INTERRUPT_PROGRAM) || \
 	    (\intno == BOOK3S_INTERRUPT_FP_UNAVAIL) || \

commit c14dea04a248a59fe01f1b49ac94615042016558
Author: Alexander Graf <agraf@suse.de>
Date:   Fri Apr 16 00:11:41 2010 +0200

    KVM: PPC: Use KVM_BOOK3S_HANDLER
    
    So far we had a lot of conditional code on CONFIG_KVM_BOOK3S_64_HANDLER.
    As we're moving towards common code between 32 and 64 bits, most of
    these ifdefs can be moved to a more generic term define, called
    CONFIG_KVM_BOOK3S_HANDLER.
    
    This patch adds the new generic config option and moves ifdefs over.
    
    Signed-off-by: Alexander Graf <agraf@suse.de>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index e915e7dfa622..36fdb3aff30b 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -22,7 +22,7 @@
 
 #ifdef __ASSEMBLY__
 
-#ifdef CONFIG_KVM_BOOK3S_64_HANDLER
+#ifdef CONFIG_KVM_BOOK3S_HANDLER
 
 #include <asm/kvm_asm.h>
 
@@ -55,7 +55,7 @@ kvmppc_resume_\intno:
 .macro DO_KVM intno
 .endm
 
-#endif /* CONFIG_KVM_BOOK3S_64_HANDLER */
+#endif /* CONFIG_KVM_BOOK3S_HANDLER */
 
 #else  /*__ASSEMBLY__ */
 

commit 66bb170655799a0149df0844fb8232f27e54323c
Author: Alexander Graf <agraf@suse.de>
Date:   Fri Apr 16 00:11:39 2010 +0200

    KVM: PPC: Add fields to shadow vcpu
    
    After a lot of thought on how to make the entry / exit code easier,
    I figured it'd be clever to put even more register state into the
    shadow vcpu. That way we have more registers available to use, making
    the code easier to read.
    
    So this patch adds a few new fields to that shadow vcpu. Later on we
    will remove the originals from the vcpu and paca.
    
    Signed-off-by: Alexander Graf <agraf@suse.de>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 183461b48407..e915e7dfa622 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -63,12 +63,33 @@ struct kvmppc_book3s_shadow_vcpu {
 	ulong gpr[14];
 	u32 cr;
 	u32 xer;
+
+	u32 fault_dsisr;
+	u32 last_inst;
+	ulong ctr;
+	ulong lr;
+	ulong pc;
+	ulong shadow_srr1;
+	ulong fault_dar;
+
 	ulong host_r1;
 	ulong host_r2;
 	ulong handler;
 	ulong scratch0;
 	ulong scratch1;
 	ulong vmhandler;
+	u8 in_guest;
+
+#ifdef CONFIG_PPC_BOOK3S_32
+	u32     sr[16];			/* Guest SRs */
+#endif
+#ifdef CONFIG_PPC_BOOK3S_64
+	u8 slb_max;			/* highest used guest slb entry */
+	struct  {
+		u64     esid;
+		u64     vsid;
+	} slb[64];			/* guest SLB */
+#endif
 };
 
 #endif /*__ASSEMBLY__ */

commit 2191d657c9eaa4c444c33e014199ed9de1ac339d
Author: Alexander Graf <agraf@suse.de>
Date:   Fri Apr 16 00:11:32 2010 +0200

    KVM: PPC: Name generic 64-bit code generic
    
    We have quite some code that can be used by Book3S_32 and Book3S_64 alike,
    so let's call it "Book3S" instead of "Book3S_64", so we can later on
    use it from the 32 bit port too.
    
    Signed-off-by: Alexander Graf <agraf@suse.de>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
new file mode 100644
index 000000000000..183461b48407
--- /dev/null
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -0,0 +1,76 @@
+/*
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License, version 2, as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+ * Copyright SUSE Linux Products GmbH 2009
+ *
+ * Authors: Alexander Graf <agraf@suse.de>
+ */
+
+#ifndef __ASM_KVM_BOOK3S_ASM_H__
+#define __ASM_KVM_BOOK3S_ASM_H__
+
+#ifdef __ASSEMBLY__
+
+#ifdef CONFIG_KVM_BOOK3S_64_HANDLER
+
+#include <asm/kvm_asm.h>
+
+.macro DO_KVM intno
+	.if (\intno == BOOK3S_INTERRUPT_SYSTEM_RESET) || \
+	    (\intno == BOOK3S_INTERRUPT_MACHINE_CHECK) || \
+	    (\intno == BOOK3S_INTERRUPT_DATA_STORAGE) || \
+	    (\intno == BOOK3S_INTERRUPT_INST_STORAGE) || \
+	    (\intno == BOOK3S_INTERRUPT_DATA_SEGMENT) || \
+	    (\intno == BOOK3S_INTERRUPT_INST_SEGMENT) || \
+	    (\intno == BOOK3S_INTERRUPT_EXTERNAL) || \
+	    (\intno == BOOK3S_INTERRUPT_ALIGNMENT) || \
+	    (\intno == BOOK3S_INTERRUPT_PROGRAM) || \
+	    (\intno == BOOK3S_INTERRUPT_FP_UNAVAIL) || \
+	    (\intno == BOOK3S_INTERRUPT_DECREMENTER) || \
+	    (\intno == BOOK3S_INTERRUPT_SYSCALL) || \
+	    (\intno == BOOK3S_INTERRUPT_TRACE) || \
+	    (\intno == BOOK3S_INTERRUPT_PERFMON) || \
+	    (\intno == BOOK3S_INTERRUPT_ALTIVEC) || \
+	    (\intno == BOOK3S_INTERRUPT_VSX)
+
+	b	kvmppc_trampoline_\intno
+kvmppc_resume_\intno:
+
+	.endif
+.endm
+
+#else
+
+.macro DO_KVM intno
+.endm
+
+#endif /* CONFIG_KVM_BOOK3S_64_HANDLER */
+
+#else  /*__ASSEMBLY__ */
+
+struct kvmppc_book3s_shadow_vcpu {
+	ulong gpr[14];
+	u32 cr;
+	u32 xer;
+	ulong host_r1;
+	ulong host_r2;
+	ulong handler;
+	ulong scratch0;
+	ulong scratch1;
+	ulong vmhandler;
+};
+
+#endif /*__ASSEMBLY__ */
+
+#endif /* __ASM_KVM_BOOK3S_ASM_H__ */
