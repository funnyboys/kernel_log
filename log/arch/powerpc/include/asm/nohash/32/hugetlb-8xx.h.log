commit 34536d78068318def0a370462cbc3319e1ca9014
Author: Christophe Leroy <christophe.leroy@csgroup.eu>
Date:   Tue May 19 05:49:22 2020 +0000

    powerpc/8xx: Add a function to early map kernel via huge pages
    
    Add a function to early map kernel memory using huge pages.
    
    For 512k pages, just use standard page table and map in using 512k
    pages.
    
    For 8M pages, create a hugepd table and populate the two PGD
    entries with it.
    
    This function can only be used to create page tables at startup. Once
    the regular SLAB allocation functions replace memblock functions,
    this function cannot allocate new pages anymore. However it can still
    update existing mappings with new protections.
    
    hugepd_none() macro is moved into asm/hugetlb.h to be usable outside
    of mm/hugetlbpage.c
    
    early_pte_alloc_kernel() is made visible.
    
    _PAGE_HUGE flag is now displayed by ptdump.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@csgroup.eu>
    [mpe: Change ptdump display to use "huge"]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/68325bcd3b6f93127f7810418a2352c3519066d6.1589866984.git.christophe.leroy@csgroup.eu

diff --git a/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h b/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h
index 1c7d4693a78e..e752a5807a59 100644
--- a/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h
+++ b/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h
@@ -35,6 +35,11 @@ static inline void hugepd_populate(hugepd_t *hpdp, pte_t *new, unsigned int pshi
 	*hpdp = __hugepd(__pa(new) | _PMD_USER | _PMD_PRESENT | _PMD_PAGE_8M);
 }
 
+static inline void hugepd_populate_kernel(hugepd_t *hpdp, pte_t *new, unsigned int pshift)
+{
+	*hpdp = __hugepd(__pa(new) | _PMD_PRESENT | _PMD_PAGE_8M);
+}
+
 static inline int check_and_get_huge_psize(int shift)
 {
 	return shift_to_mmu_psize(shift);

commit d4870b89acd7c362ded08f9295e8d143cf7e0024
Author: Christophe Leroy <christophe.leroy@csgroup.eu>
Date:   Tue May 19 05:49:10 2020 +0000

    powerpc/8xx: Only 8M pages are hugepte pages now
    
    512k pages are now standard pages, so only 8M pages
    are hugepte.
    
    No more handling of normal page tables through hugepd allocation
    and freeing, and hugepte helpers can also be simplified.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@csgroup.eu>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/2c6135d57fb76eebf70673fbac3dc9e740767879.1589866984.git.christophe.leroy@csgroup.eu

diff --git a/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h b/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h
index 785437323576..1c7d4693a78e 100644
--- a/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h
+++ b/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h
@@ -13,13 +13,13 @@ static inline pte_t *hugepd_page(hugepd_t hpd)
 
 static inline unsigned int hugepd_shift(hugepd_t hpd)
 {
-	return ((hpd_val(hpd) & _PMD_PAGE_MASK) >> 1) + 17;
+	return PAGE_SHIFT_8M;
 }
 
 static inline pte_t *hugepte_offset(hugepd_t hpd, unsigned long addr,
 				    unsigned int pdshift)
 {
-	unsigned long idx = (addr & ((1UL << pdshift) - 1)) >> PAGE_SHIFT;
+	unsigned long idx = (addr & (SZ_4M - 1)) >> PAGE_SHIFT;
 
 	return hugepd_page(hpd) + idx;
 }
@@ -32,8 +32,7 @@ static inline void flush_hugetlb_page(struct vm_area_struct *vma,
 
 static inline void hugepd_populate(hugepd_t *hpdp, pte_t *new, unsigned int pshift)
 {
-	*hpdp = __hugepd(__pa(new) | _PMD_USER | _PMD_PRESENT |
-			 (pshift == PAGE_SHIFT_8M ? _PMD_PAGE_8M : _PMD_PAGE_512K));
+	*hpdp = __hugepd(__pa(new) | _PMD_USER | _PMD_PRESENT | _PMD_PAGE_8M);
 }
 
 static inline int check_and_get_huge_psize(int shift)

commit b12c07a4bb064c0a8db7554557b89d40f57c936f
Author: Christophe Leroy <christophe.leroy@csgroup.eu>
Date:   Tue May 19 05:49:06 2020 +0000

    powerpc/mm: Reduce hugepd size for 8M hugepages on 8xx
    
    Commit 55c8fc3f4930 ("powerpc/8xx: reintroduce 16K pages with HW
    assistance") redefined pte_t as a struct of 4 pte_basic_t, because
    in 16K pages mode there are four identical entries in the page table.
    But hugepd entries for 8M pages require only one entry of size
    pte_basic_t. So there is no point in creating a cache for 4 entries
    page tables.
    
    Calculate PTE_T_ORDER using the size of pte_basic_t instead of pte_t.
    
    Define specific huge_pte helpers (set_huge_pte_at(), huge_pte_clear(),
    huge_ptep_set_wrprotect()) to write the pte in a single entry instead
    of using set_pte_at() which writes 4 identical entries in 16k pages
    mode. Also make sure that __ptep_set_access_flags() properly handle
    the huge_pte case.
    
    Define set_pte_filter() inline otherwise GCC doesn't inline it anymore
    because it is now used twice, and that gives a pretty suboptimal code
    because of pte_t being a struct of 4 entries.
    
    Those functions are also used for 512k pages which only require one
    entry as well allthough replicating it four times was harmless as 512k
    pages entries are spread every 128 bytes in the table.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@csgroup.eu>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/43050d1a0c2d6e1541cab9c1126fc80bc7015ebd.1589866984.git.christophe.leroy@csgroup.eu

diff --git a/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h b/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h
index a46616937d20..785437323576 100644
--- a/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h
+++ b/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h
@@ -41,4 +41,24 @@ static inline int check_and_get_huge_psize(int shift)
 	return shift_to_mmu_psize(shift);
 }
 
+#define __HAVE_ARCH_HUGE_SET_HUGE_PTE_AT
+void set_huge_pte_at(struct mm_struct *mm, unsigned long addr, pte_t *ptep, pte_t pte);
+
+#define __HAVE_ARCH_HUGE_PTE_CLEAR
+static inline void huge_pte_clear(struct mm_struct *mm, unsigned long addr,
+				  pte_t *ptep, unsigned long sz)
+{
+	pte_update(mm, addr, ptep, ~0UL, 0, 1);
+}
+
+#define __HAVE_ARCH_HUGE_PTEP_SET_WRPROTECT
+static inline void huge_ptep_set_wrprotect(struct mm_struct *mm,
+					   unsigned long addr, pte_t *ptep)
+{
+	unsigned long clr = ~pte_val(pte_wrprotect(__pte(~0)));
+	unsigned long set = pte_val(pte_wrprotect(__pte(0)));
+
+	pte_update(mm, addr, ptep, clr, set, 1);
+}
+
 #endif /* _ASM_POWERPC_NOHASH_32_HUGETLB_8XX_H */

commit 723f268f19daddba56a987b934f3e34a04b6499d
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Fri Apr 26 05:59:46 2019 +0000

    powerpc/mm: cleanup ifdef mess in add_huge_page_size()
    
    Introduce a subarch specific helper check_and_get_huge_psize()
    to check the huge page sizes and cleanup the ifdef mess in
    add_huge_page_size()
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h b/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h
index 75676885bec2..a46616937d20 100644
--- a/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h
+++ b/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h
@@ -36,4 +36,9 @@ static inline void hugepd_populate(hugepd_t *hpdp, pte_t *new, unsigned int pshi
 			 (pshift == PAGE_SHIFT_8M ? _PMD_PAGE_8M : _PMD_PAGE_512K));
 }
 
+static inline int check_and_get_huge_psize(int shift)
+{
+	return shift_to_mmu_psize(shift);
+}
+
 #endif /* _ASM_POWERPC_NOHASH_32_HUGETLB_8XX_H */

commit 5fb84fec46015758271fcd2a746633fd4d48e619
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Fri Apr 26 05:59:45 2019 +0000

    powerpc/mm: add a helper to populate hugepd
    
    This patchs adds a subarch helper to populate hugepd.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h b/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h
index 997f5b3d6b99..75676885bec2 100644
--- a/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h
+++ b/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h
@@ -2,6 +2,8 @@
 #ifndef _ASM_POWERPC_NOHASH_32_HUGETLB_8XX_H
 #define _ASM_POWERPC_NOHASH_32_HUGETLB_8XX_H
 
+#define PAGE_SHIFT_8M		23
+
 static inline pte_t *hugepd_page(hugepd_t hpd)
 {
 	BUG_ON(!hugepd_ok(hpd));
@@ -28,4 +30,10 @@ static inline void flush_hugetlb_page(struct vm_area_struct *vma,
 	flush_tlb_page(vma, vmaddr);
 }
 
+static inline void hugepd_populate(hugepd_t *hpdp, pte_t *new, unsigned int pshift)
+{
+	*hpdp = __hugepd(__pa(new) | _PMD_USER | _PMD_PRESENT |
+			 (pshift == PAGE_SHIFT_8M ? _PMD_PAGE_8M : _PMD_PAGE_512K));
+}
+
 #endif /* _ASM_POWERPC_NOHASH_32_HUGETLB_8XX_H */

commit 8197af22be01e7c9ab476138652e0dc8cd22a207
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Fri Apr 26 05:59:44 2019 +0000

    powerpc/mm: split asm/hugetlb.h into dedicated subarch files
    
    Three subarches support hugepages:
      - fsl book3e
      - book3s/64
      - 8xx
    
    This patch splits asm/hugetlb.h to reduce the #ifdef mess.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h b/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h
new file mode 100644
index 000000000000..997f5b3d6b99
--- /dev/null
+++ b/arch/powerpc/include/asm/nohash/32/hugetlb-8xx.h
@@ -0,0 +1,31 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+#ifndef _ASM_POWERPC_NOHASH_32_HUGETLB_8XX_H
+#define _ASM_POWERPC_NOHASH_32_HUGETLB_8XX_H
+
+static inline pte_t *hugepd_page(hugepd_t hpd)
+{
+	BUG_ON(!hugepd_ok(hpd));
+
+	return (pte_t *)__va(hpd_val(hpd) & ~HUGEPD_SHIFT_MASK);
+}
+
+static inline unsigned int hugepd_shift(hugepd_t hpd)
+{
+	return ((hpd_val(hpd) & _PMD_PAGE_MASK) >> 1) + 17;
+}
+
+static inline pte_t *hugepte_offset(hugepd_t hpd, unsigned long addr,
+				    unsigned int pdshift)
+{
+	unsigned long idx = (addr & ((1UL << pdshift) - 1)) >> PAGE_SHIFT;
+
+	return hugepd_page(hpd) + idx;
+}
+
+static inline void flush_hugetlb_page(struct vm_area_struct *vma,
+				      unsigned long vmaddr)
+{
+	flush_tlb_page(vma, vmaddr);
+}
+
+#endif /* _ASM_POWERPC_NOHASH_32_HUGETLB_8XX_H */
