commit ca5999fde0a1761665a38e4c9a72dbcd7d190a81
Author: Mike Rapoport <rppt@linux.ibm.com>
Date:   Mon Jun 8 21:32:38 2020 -0700

    mm: introduce include/linux/pgtable.h
    
    The include/linux/pgtable.h is going to be the home of generic page table
    manipulation functions.
    
    Start with moving asm-generic/pgtable.h to include/linux/pgtable.h and
    make the latter include asm/pgtable.h.
    
    Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Cain <bcain@codeaurora.org>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Zankel <chris@zankel.net>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Greentime Hu <green.hu@gmail.com>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: Guan Xuetao <gxt@pku.edu.cn>
    Cc: Guo Ren <guoren@kernel.org>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Helge Deller <deller@gmx.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Ley Foon Tan <ley.foon.tan@intel.com>
    Cc: Mark Salter <msalter@redhat.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Matt Turner <mattst88@gmail.com>
    Cc: Max Filippov <jcmvbkbc@gmail.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Michal Simek <monstr@monstr.eu>
    Cc: Nick Hu <nickhu@andestech.com>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Rich Felker <dalias@libc.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Stafford Horne <shorne@gmail.com>
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vincent Chen <deanbo422@gmail.com>
    Cc: Vineet Gupta <vgupta@synopsys.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
    Link: http://lkml.kernel.org/r/20200514170327.31389-3-rppt@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/include/asm/kup.h b/arch/powerpc/include/asm/kup.h
index c745ee41ad66..1d0f7d838b2e 100644
--- a/arch/powerpc/include/asm/kup.h
+++ b/arch/powerpc/include/asm/kup.h
@@ -39,7 +39,7 @@
 
 #else /* !__ASSEMBLY__ */
 
-#include <asm/pgtable.h>
+#include <linux/pgtable.h>
 
 void setup_kup(void);
 

commit 4fe5cda9f89d0aea8e915b7c96ae34bda4e12e51
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Fri Apr 3 07:20:53 2020 +0000

    powerpc/uaccess: Implement user_read_access_begin and user_write_access_begin
    
    Add support for selective read or write user access with
    user_read_access_begin/end and user_write_access_begin/end.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/6c83af0f0809ef2a955c39ac622767f6cbede035.1585898438.git.christophe.leroy@c-s.fr

diff --git a/arch/powerpc/include/asm/kup.h b/arch/powerpc/include/asm/kup.h
index 92bcd1a26d73..c745ee41ad66 100644
--- a/arch/powerpc/include/asm/kup.h
+++ b/arch/powerpc/include/asm/kup.h
@@ -10,7 +10,9 @@
  * Use the current saved situation instead of the to/from/size params.
  * Used on book3s/32
  */
-#define KUAP_CURRENT	4
+#define KUAP_CURRENT_READ	4
+#define KUAP_CURRENT_WRITE	8
+#define KUAP_CURRENT		(KUAP_CURRENT_READ | KUAP_CURRENT_WRITE)
 
 #ifdef CONFIG_PPC64
 #include <asm/book3s/64/kup-radix.h>
@@ -101,6 +103,16 @@ static inline void prevent_current_access_user(void)
 	prevent_user_access(NULL, NULL, ~0UL, KUAP_CURRENT);
 }
 
+static inline void prevent_current_read_from_user(void)
+{
+	prevent_user_access(NULL, NULL, ~0UL, KUAP_CURRENT_READ);
+}
+
+static inline void prevent_current_write_to_user(void)
+{
+	prevent_user_access(NULL, NULL, ~0UL, KUAP_CURRENT_WRITE);
+}
+
 #endif /* !__ASSEMBLY__ */
 
 #endif /* _ASM_POWERPC_KUAP_H_ */

commit 3d7dfd632f9b60cfce069b4da517e6b1a1c3f613
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Fri Jan 24 11:54:45 2020 +0000

    powerpc: Implement user_access_save() and user_access_restore()
    
    Implement user_access_save() and user_access_restore()
    
    On 8xx and radix:
      - On save, get the value of the associated special register then
        prevent user access.
      - On restore, set back the saved value to the associated special
        register.
    
    On book3s/32:
      - On save, get the value stored in current->thread.kuap and prevent
        user access.
      - On restore, regenerate address range from the stored value and
        reopen read/write access for that range.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/54f2f74938006b33c55a416674807b42ef222068.1579866752.git.christophe.leroy@c-s.fr

diff --git a/arch/powerpc/include/asm/kup.h b/arch/powerpc/include/asm/kup.h
index c3ce7e8ae9ea..92bcd1a26d73 100644
--- a/arch/powerpc/include/asm/kup.h
+++ b/arch/powerpc/include/asm/kup.h
@@ -55,6 +55,8 @@ static inline void allow_user_access(void __user *to, const void __user *from,
 				     unsigned long size, unsigned long dir) { }
 static inline void prevent_user_access(void __user *to, const void __user *from,
 				       unsigned long size, unsigned long dir) { }
+static inline unsigned long prevent_user_access_return(void) { return 0UL; }
+static inline void restore_user_access(unsigned long flags) { }
 static inline bool
 bad_kuap_fault(struct pt_regs *regs, unsigned long address, bool is_write)
 {

commit bedb4dbe443c11ff551b4ae4e48c8676fdc96467
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Fri Jan 24 11:54:43 2020 +0000

    powerpc/32s: Prepare prevent_user_access() for user_access_end()
    
    In preparation of implementing user_access_begin and friends
    on powerpc, the book3s/32 version of prevent_user_access() need
    to be prepared for user_access_end().
    
    user_access_end() doesn't provide the address and size which
    were passed to user_access_begin(), required by prevent_user_access()
    to know which segment to modify.
    
    The list of segments which where unprotected by allow_user_access()
    are available in current->kuap. But we don't want prevent_user_access()
    to read this all the time, especially everytime it is 0 (for instance
    because the access was not a write access).
    
    Implement a special direction named KUAP_CURRENT. In this case only,
    the addr and end are retrieved from current->kuap.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/55bcc1f25d8200892a31f67a0b024ff3b816c3cc.1579866752.git.christophe.leroy@c-s.fr

diff --git a/arch/powerpc/include/asm/kup.h b/arch/powerpc/include/asm/kup.h
index 94f24928916a..c3ce7e8ae9ea 100644
--- a/arch/powerpc/include/asm/kup.h
+++ b/arch/powerpc/include/asm/kup.h
@@ -5,6 +5,12 @@
 #define KUAP_READ	1
 #define KUAP_WRITE	2
 #define KUAP_READ_WRITE	(KUAP_READ | KUAP_WRITE)
+/*
+ * For prevent_user_access() only.
+ * Use the current saved situation instead of the to/from/size params.
+ * Used on book3s/32
+ */
+#define KUAP_CURRENT	4
 
 #ifdef CONFIG_PPC64
 #include <asm/book3s/64/kup-radix.h>
@@ -88,6 +94,11 @@ static inline void prevent_read_write_user(void __user *to, const void __user *f
 	prevent_user_access(to, from, size, KUAP_READ_WRITE);
 }
 
+static inline void prevent_current_access_user(void)
+{
+	prevent_user_access(NULL, NULL, ~0UL, KUAP_CURRENT);
+}
+
 #endif /* !__ASSEMBLY__ */
 
 #endif /* _ASM_POWERPC_KUAP_H_ */

commit 1d8f739b07bd538f272f60bf53f10e7e6248d295
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Fri Jan 24 11:54:41 2020 +0000

    powerpc/kuap: Fix set direction in allow/prevent_user_access()
    
    __builtin_constant_p() always return 0 for pointers, so on RADIX
    we always end up opening both direction (by writing 0 in SPR29):
    
      0000000000000170 <._copy_to_user>:
      ...
       1b0: 4c 00 01 2c     isync
       1b4: 39 20 00 00     li      r9,0
       1b8: 7d 3d 03 a6     mtspr   29,r9
       1bc: 4c 00 01 2c     isync
       1c0: 48 00 00 01     bl      1c0 <._copy_to_user+0x50>
                            1c0: R_PPC64_REL24      .__copy_tofrom_user
      ...
      0000000000000220 <._copy_from_user>:
      ...
       2ac: 4c 00 01 2c     isync
       2b0: 39 20 00 00     li      r9,0
       2b4: 7d 3d 03 a6     mtspr   29,r9
       2b8: 4c 00 01 2c     isync
       2bc: 7f c5 f3 78     mr      r5,r30
       2c0: 7f 83 e3 78     mr      r3,r28
       2c4: 48 00 00 01     bl      2c4 <._copy_from_user+0xa4>
                            2c4: R_PPC64_REL24      .__copy_tofrom_user
      ...
    
    Use an explicit parameter for direction selection, so that GCC
    is able to see it is a constant:
    
      00000000000001b0 <._copy_to_user>:
      ...
       1f0: 4c 00 01 2c     isync
       1f4: 3d 20 40 00     lis     r9,16384
       1f8: 79 29 07 c6     rldicr  r9,r9,32,31
       1fc: 7d 3d 03 a6     mtspr   29,r9
       200: 4c 00 01 2c     isync
       204: 48 00 00 01     bl      204 <._copy_to_user+0x54>
                            204: R_PPC64_REL24      .__copy_tofrom_user
      ...
      0000000000000260 <._copy_from_user>:
      ...
       2ec: 4c 00 01 2c     isync
       2f0: 39 20 ff ff     li      r9,-1
       2f4: 79 29 00 04     rldicr  r9,r9,0,0
       2f8: 7d 3d 03 a6     mtspr   29,r9
       2fc: 4c 00 01 2c     isync
       300: 7f c5 f3 78     mr      r5,r30
       304: 7f 83 e3 78     mr      r3,r28
       308: 48 00 00 01     bl      308 <._copy_from_user+0xa8>
                            308: R_PPC64_REL24      .__copy_tofrom_user
      ...
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    [mpe: Spell out the directions, s/KUAP_R/KUAP_READ/ etc.]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/f4e88ec4941d5facb35ce75026b0112f980086c3.1579866752.git.christophe.leroy@c-s.fr

diff --git a/arch/powerpc/include/asm/kup.h b/arch/powerpc/include/asm/kup.h
index 812e66f31934..94f24928916a 100644
--- a/arch/powerpc/include/asm/kup.h
+++ b/arch/powerpc/include/asm/kup.h
@@ -2,6 +2,10 @@
 #ifndef _ASM_POWERPC_KUP_H_
 #define _ASM_POWERPC_KUP_H_
 
+#define KUAP_READ	1
+#define KUAP_WRITE	2
+#define KUAP_READ_WRITE	(KUAP_READ | KUAP_WRITE)
+
 #ifdef CONFIG_PPC64
 #include <asm/book3s/64/kup-radix.h>
 #endif
@@ -42,9 +46,9 @@ void setup_kuap(bool disabled);
 #else
 static inline void setup_kuap(bool disabled) { }
 static inline void allow_user_access(void __user *to, const void __user *from,
-				     unsigned long size) { }
+				     unsigned long size, unsigned long dir) { }
 static inline void prevent_user_access(void __user *to, const void __user *from,
-				       unsigned long size) { }
+				       unsigned long size, unsigned long dir) { }
 static inline bool
 bad_kuap_fault(struct pt_regs *regs, unsigned long address, bool is_write)
 {
@@ -54,24 +58,36 @@ bad_kuap_fault(struct pt_regs *regs, unsigned long address, bool is_write)
 
 static inline void allow_read_from_user(const void __user *from, unsigned long size)
 {
-	allow_user_access(NULL, from, size);
+	allow_user_access(NULL, from, size, KUAP_READ);
 }
 
 static inline void allow_write_to_user(void __user *to, unsigned long size)
 {
-	allow_user_access(to, NULL, size);
+	allow_user_access(to, NULL, size, KUAP_WRITE);
+}
+
+static inline void allow_read_write_user(void __user *to, const void __user *from,
+					 unsigned long size)
+{
+	allow_user_access(to, from, size, KUAP_READ_WRITE);
 }
 
 static inline void prevent_read_from_user(const void __user *from, unsigned long size)
 {
-	prevent_user_access(NULL, from, size);
+	prevent_user_access(NULL, from, size, KUAP_READ);
 }
 
 static inline void prevent_write_to_user(void __user *to, unsigned long size)
 {
-	prevent_user_access(to, NULL, size);
+	prevent_user_access(to, NULL, size, KUAP_WRITE);
+}
+
+static inline void prevent_read_write_user(void __user *to, const void __user *from,
+					   unsigned long size)
+{
+	prevent_user_access(to, from, size, KUAP_READ_WRITE);
 }
 
 #endif /* !__ASSEMBLY__ */
 
-#endif /* _ASM_POWERPC_KUP_H_ */
+#endif /* _ASM_POWERPC_KUAP_H_ */

commit 6ec20aa2e510b6297906c45f009aa08b2d97269a
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Fri Jan 24 11:54:40 2020 +0000

    powerpc/32s: Fix bad_kuap_fault()
    
    At the moment, bad_kuap_fault() reports a fault only if a bad access
    to userspace occurred while access to userspace was not granted.
    
    But if a fault occurs for a write outside the allowed userspace
    segment(s) that have been unlocked, bad_kuap_fault() fails to
    detect it and the kernel loops forever in do_page_fault().
    
    Fix it by checking that the accessed address is within the allowed
    range.
    
    Fixes: a68c31fc01ef ("powerpc/32s: Implement Kernel Userspace Access Protection")
    Cc: stable@vger.kernel.org # v5.2+
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/f48244e9485ada0a304ed33ccbb8da271180c80d.1579866752.git.christophe.leroy@c-s.fr

diff --git a/arch/powerpc/include/asm/kup.h b/arch/powerpc/include/asm/kup.h
index 5b5e39643a27..812e66f31934 100644
--- a/arch/powerpc/include/asm/kup.h
+++ b/arch/powerpc/include/asm/kup.h
@@ -45,7 +45,11 @@ static inline void allow_user_access(void __user *to, const void __user *from,
 				     unsigned long size) { }
 static inline void prevent_user_access(void __user *to, const void __user *from,
 				       unsigned long size) { }
-static inline bool bad_kuap_fault(struct pt_regs *regs, bool is_write) { return false; }
+static inline bool
+bad_kuap_fault(struct pt_regs *regs, unsigned long address, bool is_write)
+{
+	return false;
+}
 #endif /* CONFIG_PPC_KUAP */
 
 static inline void allow_read_from_user(const void __user *from, unsigned long size)

commit 31ed2b13c48d779efc838ad54e30121e088a62af
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Mon Mar 11 08:30:35 2019 +0000

    powerpc/32s: Implement Kernel Userspace Execution Prevention.
    
    To implement Kernel Userspace Execution Prevention, this patch
    sets NX bit on all user segments on kernel entry and clears NX bit
    on all user segments on kernel exit.
    
    Note that powerpc 601 doesn't have the NX bit, so KUEP will not
    work on it. A warning is displayed at startup.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/kup.h b/arch/powerpc/include/asm/kup.h
index 043c800ec5fb..5b5e39643a27 100644
--- a/arch/powerpc/include/asm/kup.h
+++ b/arch/powerpc/include/asm/kup.h
@@ -8,6 +8,9 @@
 #ifdef CONFIG_PPC_8xx
 #include <asm/nohash/32/kup-8xx.h>
 #endif
+#ifdef CONFIG_PPC_BOOK3S_32
+#include <asm/book3s/32/kup.h>
+#endif
 
 #ifdef __ASSEMBLY__
 #ifndef CONFIG_PPC_KUAP

commit 2679f9bd0abafb3044bcbaac0600b32159ac8bf2
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Mon Mar 11 08:30:34 2019 +0000

    powerpc/8xx: Add Kernel Userspace Access Protection
    
    This patch adds Kernel Userspace Access Protection on the 8xx.
    
    When a page is RO or RW, it is set RO or RW for Key 0 and NA
    for Key 1.
    
    Up to now, the User group is defined with Key 0 for both User and
    Supervisor.
    
    By changing the group to Key 0 for User and Key 1 for Supervisor,
    this patch prevents the Kernel from being able to access user data.
    
    At exception entry, the kernel saves SPRN_MD_AP in the regs struct,
    and reapply the protection. At exception exit it restores SPRN_MD_AP
    with the value saved on exception entry.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    [mpe: Drop allow_read/write_to/from_user() as they're now in kup.h]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/kup.h b/arch/powerpc/include/asm/kup.h
index 7d8ad3d6729d..043c800ec5fb 100644
--- a/arch/powerpc/include/asm/kup.h
+++ b/arch/powerpc/include/asm/kup.h
@@ -5,6 +5,9 @@
 #ifdef CONFIG_PPC64
 #include <asm/book3s/64/kup-radix.h>
 #endif
+#ifdef CONFIG_PPC_8xx
+#include <asm/nohash/32/kup-8xx.h>
+#endif
 
 #ifdef __ASSEMBLY__
 #ifndef CONFIG_PPC_KUAP

commit e2fb9f5444312fd01627c84a3e018c1fe8ac6ebb
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Mon Mar 11 08:30:31 2019 +0000

    powerpc/32: Prepare for Kernel Userspace Access Protection
    
    This patch adds ASM macros for saving, restoring and checking
    the KUAP state, and modifies setup_32 to call them on exceptions
    from kernel.
    
    The macros are defined as empty by default for when CONFIG_PPC_KUAP
    is not selected and/or for platforms which don't handle (yet) KUAP.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/kup.h b/arch/powerpc/include/asm/kup.h
index 28ad4654eed2..7d8ad3d6729d 100644
--- a/arch/powerpc/include/asm/kup.h
+++ b/arch/powerpc/include/asm/kup.h
@@ -6,7 +6,20 @@
 #include <asm/book3s/64/kup-radix.h>
 #endif
 
-#ifndef __ASSEMBLY__
+#ifdef __ASSEMBLY__
+#ifndef CONFIG_PPC_KUAP
+.macro kuap_save_and_lock	sp, thread, gpr1, gpr2, gpr3
+.endm
+
+.macro kuap_restore	sp, current, gpr1, gpr2, gpr3
+.endm
+
+.macro kuap_check	current, gpr
+.endm
+
+#endif
+
+#else /* !__ASSEMBLY__ */
 
 #include <asm/pgtable.h>
 

commit 5e5be3aed23032d40d5ab7407f344f1a74f2765b
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Apr 18 16:51:25 2019 +1000

    powerpc/mm: Detect bad KUAP faults
    
    When KUAP is enabled we have logic to detect page faults that occur
    outside of a valid user access region and are blocked by the AMR.
    
    What we don't have at the moment is logic to detect a fault *within* a
    valid user access region, that has been incorrectly blocked by AMR.
    This is not meant to ever happen, but it can if we incorrectly
    save/restore the AMR, or if the AMR was overwritten for some other
    reason.
    
    Currently if that happens we assume it's just a regular fault that
    will be corrected by handling the fault normally, so we just return.
    But there is nothing the fault handling code can do to fix it, so the
    fault just happens again and we spin forever, leading to soft lockups.
    
    So add some logic to detect that case and WARN() if we ever see it.
    Arguably it should be a BUG(), but it's more polite to fail the access
    and let the kernel continue, rather than taking down the box. There
    should be no data integrity issue with failing the fault rather than
    BUG'ing, as we're just going to disallow an access that should have
    been allowed.
    
    To make the code a little easier to follow, unroll the condition at
    the end of bad_kernel_fault() and comment each case, before adding the
    call to bad_kuap_fault().
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/kup.h b/arch/powerpc/include/asm/kup.h
index d7312defbe1c..28ad4654eed2 100644
--- a/arch/powerpc/include/asm/kup.h
+++ b/arch/powerpc/include/asm/kup.h
@@ -26,6 +26,7 @@ static inline void allow_user_access(void __user *to, const void __user *from,
 				     unsigned long size) { }
 static inline void prevent_user_access(void __user *to, const void __user *from,
 				       unsigned long size) { }
+static inline bool bad_kuap_fault(struct pt_regs *regs, bool is_write) { return false; }
 #endif /* CONFIG_PPC_KUAP */
 
 static inline void allow_read_from_user(const void __user *from, unsigned long size)

commit 890274c2dc4c0a57ae5a12d6a76fa6d05b599d98
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Apr 18 16:51:24 2019 +1000

    powerpc/64s: Implement KUAP for Radix MMU
    
    Kernel Userspace Access Prevention utilises a feature of the Radix MMU
    which disallows read and write access to userspace addresses. By
    utilising this, the kernel is prevented from accessing user data from
    outside of trusted paths that perform proper safety checks, such as
    copy_{to/from}_user() and friends.
    
    Userspace access is disabled from early boot and is only enabled when
    performing an operation like copy_{to/from}_user(). The register that
    controls this (AMR) does not prevent userspace from accessing itself,
    so there is no need to save and restore when entering and exiting
    userspace.
    
    When entering the kernel from the kernel we save AMR and if it is not
    blocking user access (because eg. we faulted doing a user access) we
    reblock user access for the duration of the exception (ie. the page
    fault) and then restore the AMR when returning back to the kernel.
    
    This feature can be tested by using the lkdtm driver (CONFIG_LKDTM=y)
    and performing the following:
    
      # (echo ACCESS_USERSPACE) > [debugfs]/provoke-crash/DIRECT
    
    If enabled, this should send SIGSEGV to the thread.
    
    We also add paranoid checking of AMR in switch and syscall return
    under CONFIG_PPC_KUAP_DEBUG.
    
    Co-authored-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Russell Currey <ruscur@russell.cc>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/kup.h b/arch/powerpc/include/asm/kup.h
index 4d78b9d8c99c..d7312defbe1c 100644
--- a/arch/powerpc/include/asm/kup.h
+++ b/arch/powerpc/include/asm/kup.h
@@ -2,6 +2,10 @@
 #ifndef _ASM_POWERPC_KUP_H_
 #define _ASM_POWERPC_KUP_H_
 
+#ifdef CONFIG_PPC64
+#include <asm/book3s/64/kup-radix.h>
+#endif
+
 #ifndef __ASSEMBLY__
 
 #include <asm/pgtable.h>

commit de78a9c42a790011f179bc94a7da3f5d8721f4cc
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Apr 18 16:51:20 2019 +1000

    powerpc: Add a framework for Kernel Userspace Access Protection
    
    This patch implements a framework for Kernel Userspace Access
    Protection.
    
    Then subarches will have the possibility to provide their own
    implementation by providing setup_kuap() and
    allow/prevent_user_access().
    
    Some platforms will need to know the area accessed and whether it is
    accessed from read, write or both. Therefore source, destination and
    size and handed over to the two functions.
    
    mpe: Rename to allow/prevent rather than unlock/lock, and add
    read/write wrappers. Drop the 32-bit code for now until we have an
    implementation for it. Add kuap to pt_regs for 64-bit as well as
    32-bit. Don't split strings, use pr_crit_ratelimited().
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Russell Currey <ruscur@russell.cc>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/kup.h b/arch/powerpc/include/asm/kup.h
index a2a959cb4e36..4d78b9d8c99c 100644
--- a/arch/powerpc/include/asm/kup.h
+++ b/arch/powerpc/include/asm/kup.h
@@ -4,6 +4,8 @@
 
 #ifndef __ASSEMBLY__
 
+#include <asm/pgtable.h>
+
 void setup_kup(void);
 
 #ifdef CONFIG_PPC_KUEP
@@ -12,6 +14,36 @@ void setup_kuep(bool disabled);
 static inline void setup_kuep(bool disabled) { }
 #endif /* CONFIG_PPC_KUEP */
 
+#ifdef CONFIG_PPC_KUAP
+void setup_kuap(bool disabled);
+#else
+static inline void setup_kuap(bool disabled) { }
+static inline void allow_user_access(void __user *to, const void __user *from,
+				     unsigned long size) { }
+static inline void prevent_user_access(void __user *to, const void __user *from,
+				       unsigned long size) { }
+#endif /* CONFIG_PPC_KUAP */
+
+static inline void allow_read_from_user(const void __user *from, unsigned long size)
+{
+	allow_user_access(NULL, from, size);
+}
+
+static inline void allow_write_to_user(void __user *to, unsigned long size)
+{
+	allow_user_access(to, NULL, size);
+}
+
+static inline void prevent_read_from_user(const void __user *from, unsigned long size)
+{
+	prevent_user_access(NULL, from, size);
+}
+
+static inline void prevent_write_to_user(void __user *to, unsigned long size)
+{
+	prevent_user_access(to, NULL, size);
+}
+
 #endif /* !__ASSEMBLY__ */
 
 #endif /* _ASM_POWERPC_KUP_H_ */

commit 0fb1c25ab523614b056ace11be67aac8f8ccabb1
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Apr 18 16:51:19 2019 +1000

    powerpc: Add skeleton for Kernel Userspace Execution Prevention
    
    This patch adds a skeleton for Kernel Userspace Execution Prevention.
    
    Then subarches implementing it have to define CONFIG_PPC_HAVE_KUEP
    and provide setup_kuep() function.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    [mpe: Don't split strings, use pr_crit_ratelimited()]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/kup.h b/arch/powerpc/include/asm/kup.h
index 7a88b8b9b54d..a2a959cb4e36 100644
--- a/arch/powerpc/include/asm/kup.h
+++ b/arch/powerpc/include/asm/kup.h
@@ -6,6 +6,12 @@
 
 void setup_kup(void);
 
+#ifdef CONFIG_PPC_KUEP
+void setup_kuep(bool disabled);
+#else
+static inline void setup_kuep(bool disabled) { }
+#endif /* CONFIG_PPC_KUEP */
+
 #endif /* !__ASSEMBLY__ */
 
 #endif /* _ASM_POWERPC_KUP_H_ */

commit 69795cabe4cfe5122438d50010ad5310c113a013
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Apr 18 16:51:18 2019 +1000

    powerpc: Add framework for Kernel Userspace Protection
    
    This patch adds a skeleton for Kernel Userspace Protection
    functionnalities like Kernel Userspace Access Protection and Kernel
    Userspace Execution Prevention
    
    The subsequent implementation of KUAP for radix makes use of a MMU
    feature in order to patch out assembly when KUAP is disabled or
    unsupported. This won't work unless there's an entry point for KUP
    support before the feature magic happens, so for PPC64 setup_kup() is
    called early in setup.
    
    On PPC32, feature_fixup() is done too early to allow the same.
    
    Suggested-by: Russell Currey <ruscur@russell.cc>
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/kup.h b/arch/powerpc/include/asm/kup.h
new file mode 100644
index 000000000000..7a88b8b9b54d
--- /dev/null
+++ b/arch/powerpc/include/asm/kup.h
@@ -0,0 +1,11 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+#ifndef _ASM_POWERPC_KUP_H_
+#define _ASM_POWERPC_KUP_H_
+
+#ifndef __ASSEMBLY__
+
+void setup_kup(void);
+
+#endif /* !__ASSEMBLY__ */
+
+#endif /* _ASM_POWERPC_KUP_H_ */
