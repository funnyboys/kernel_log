commit 650b55b707fdfa764e9f2b81314d3eb4216fb962
Author: Jordan Niethe <jniethe5@gmail.com>
Date:   Fri May 15 12:12:55 2020 +1000

    powerpc: Add prefixed instructions to instruction data type
    
    For powerpc64, redefine the ppc_inst type so both word and prefixed
    instructions can be represented. On powerpc32 the type will remain the
    same. Update places which had assumed instructions to be 4 bytes long.
    
    Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
    Reviewed-by: Alistair Popple <alistair@popple.id.au>
    [mpe: Rework the get_user_inst() macros to be parameterised, and don't
          assign to the dest if an error occurred. Use CONFIG_PPC64 not
          __powerpc64__ in a few places. Address other comments from
          Christophe. Fix some sparse complaints.]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20200506034050.24806-24-jniethe5@gmail.com

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index c1df75edde44..2a39c716c343 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -158,6 +158,9 @@
 /* VMX Vector Store Instructions */
 #define OP_31_XOP_STVX          231
 
+/* Prefixed Instructions */
+#define OP_PREFIX		1
+
 #define OP_31   31
 #define OP_LWZ  32
 #define OP_STFS 52

commit 192f0f8e9db7efe4ac98d47f5fa4334e43c1204d
Merge: ec9249752465 f5a9e488d623
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jul 13 16:08:36 2019 -0700

    Merge tag 'powerpc-5.3-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Notable changes:
    
       - Removal of the NPU DMA code, used by the out-of-tree Nvidia driver,
         as well as some other functions only used by drivers that haven't
         (yet?) made it upstream.
    
       - A fix for a bug in our handling of hardware watchpoints (eg. perf
         record -e mem: ...) which could lead to register corruption and
         kernel crashes.
    
       - Enable HAVE_ARCH_HUGE_VMAP, which allows us to use large pages for
         vmalloc when using the Radix MMU.
    
       - A large but incremental rewrite of our exception handling code to
         use gas macros rather than multiple levels of nested CPP macros.
    
      And the usual small fixes, cleanups and improvements.
    
      Thanks to: Alastair D'Silva, Alexey Kardashevskiy, Andreas Schwab,
      Aneesh Kumar K.V, Anju T Sudhakar, Anton Blanchard, Arnd Bergmann,
      Athira Rajeev, CÃ©dric Le Goater, Christian Lamparter, Christophe
      Leroy, Christophe Lombard, Christoph Hellwig, Daniel Axtens, Denis
      Efremov, Enrico Weigelt, Frederic Barrat, Gautham R. Shenoy, Geert
      Uytterhoeven, Geliang Tang, Gen Zhang, Greg Kroah-Hartman, Greg Kurz,
      Gustavo Romero, Krzysztof Kozlowski, Madhavan Srinivasan, Masahiro
      Yamada, Mathieu Malaterre, Michael Neuling, Nathan Lynch, Naveen N.
      Rao, Nicholas Piggin, Nishad Kamdar, Oliver O'Halloran, Qian Cai, Ravi
      Bangoria, Sachin Sant, Sam Bobroff, Satheesh Rajendran, Segher
      Boessenkool, Shaokun Zhang, Shawn Anastasio, Stewart Smith, Suraj
      Jitindar Singh, Thiago Jung Bauermann, YueHaibing"
    
    * tag 'powerpc-5.3-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (163 commits)
      powerpc/powernv/idle: Fix restore of SPRN_LDBAR for POWER9 stop state.
      powerpc/eeh: Handle hugepages in ioremap space
      ocxl: Update for AFU descriptor template version 1.1
      powerpc/boot: pass CONFIG options in a simpler and more robust way
      powerpc/boot: add {get, put}_unaligned_be32 to xz_config.h
      powerpc/irq: Don't WARN continuously in arch_local_irq_restore()
      powerpc/module64: Use symbolic instructions names.
      powerpc/module32: Use symbolic instructions names.
      powerpc: Move PPC_HA() PPC_HI() and PPC_LO() to ppc-opcode.h
      powerpc/module64: Fix comment in R_PPC64_ENTRY handling
      powerpc/boot: Add lzo support for uImage
      powerpc/boot: Add lzma support for uImage
      powerpc/boot: don't force gzipped uImage
      powerpc/8xx: Add microcode patch to move SMC parameter RAM.
      powerpc/8xx: Use IO accessors in microcode programming.
      powerpc/8xx: replace #ifdefs by IS_ENABLED() in microcode.c
      powerpc/8xx: refactor programming of microcode CPM params.
      powerpc/8xx: refactor printing of microcode patch name.
      powerpc/8xx: Refactor microcode write
      powerpc/8xx: refactor writing of CPM microcode arrays
      ...

commit 7f9c929a7ff203eae60b4225bb6824c3eb31796c
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Fri May 3 06:40:15 2019 +0000

    powerpc: Move PPC_HA() PPC_HI() and PPC_LO() to ppc-opcode.h
    
    PPC_HA() PPC_HI() and PPC_LO() macros are nice macros. Move them
    from module64.c to ppc-opcode.h in order to use them in other places.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    [mpe: Clean up formatting in new code, drop duplicates in ftrace.c]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 971bdf84f6fc..f544432aef82 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -412,6 +412,15 @@
 #define __PPC_SPR(r)	((((r) & 0x1f) << 16) | ((((r) >> 5) & 0x1f) << 11))
 #define __PPC_RC21	(0x1 << 10)
 
+/*
+ * Both low and high 16 bits are added as SIGNED additions, so if low 16 bits
+ * has high bit set, high 16 bits must be adjusted. These macros do that (stolen
+ * from binutils).
+ */
+#define PPC_LO(v)	((v) & 0xffff)
+#define PPC_HI(v)	(((v) >> 16) & 0xffff)
+#define PPC_HA(v)	PPC_HI((v) + 0x8000)
+
 /*
  * Only use the larx hint bit on 64bit CPUs. e500v1/v2 based CPUs will treat a
  * larx with EH set as an illegal instruction.

commit 6c46fcce39f0eb4830078c5f1db289dd7196f84a
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Sun Jun 23 20:41:52 2019 +1000

    powerpc/64s/radix: keep kernel ERAT over local process/guest invalidates
    
    ISA v3.0 radix modes provide SLBIA variants which can invalidate ERAT
    for effPID!=0 or for effLPID!=0, which allows user and guest
    invalidations to retain kernel/host ERAT entries.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 14f43b6cf7ec..971bdf84f6fc 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -591,7 +591,16 @@
 
 #define PPC_SLBIA(IH)	stringify_in_c(.long PPC_INST_SLBIA | \
 				       ((IH & 0x7) << 21))
+
+/*
+ * These may only be used on ISA v3.0 or later (aka. CPU_FTR_ARCH_300, radix
+ * implies CPU_FTR_ARCH_300). USER/GUEST invalidates may only be used by radix
+ * mode (on HPT these would also invalidate various SLBEs which may not be
+ * desired).
+ */
 #define PPC_ISA_3_0_INVALIDATE_ERAT	PPC_SLBIA(7)
+#define PPC_RADIX_INVALIDATE_ERAT_USER	PPC_SLBIA(3)
+#define PPC_RADIX_INVALIDATE_ERAT_GUEST	PPC_SLBIA(6)
 
 #define VCMPEQUD_RC(vrt, vra, vrb)	stringify_in_c(.long PPC_INST_VCMPEQUD | \
 			      ___PPC_RT(vrt) | ___PPC_RA(vra) | \

commit fe7946ce0808eb0e43711f5db7d2d1599b362d02
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Sun Jun 23 20:41:51 2019 +1000

    powerpc/64s: Rename PPC_INVALIDATE_ERAT to PPC_ISA_3_0_INVALIDATE_ERAT
    
    This makes it clear to the caller that it can only be used on POWER9
    and later CPUs.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Use "ISA_3_0" rather than "ARCH_300"]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 23f7ed796f38..14f43b6cf7ec 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -591,7 +591,7 @@
 
 #define PPC_SLBIA(IH)	stringify_in_c(.long PPC_INST_SLBIA | \
 				       ((IH & 0x7) << 21))
-#define PPC_INVALIDATE_ERAT	PPC_SLBIA(7)
+#define PPC_ISA_3_0_INVALIDATE_ERAT	PPC_SLBIA(7)
 
 #define VCMPEQUD_RC(vrt, vra, vrb)	stringify_in_c(.long PPC_INST_VCMPEQUD | \
 			      ___PPC_RT(vrt) | ___PPC_RA(vra) | \

commit 758f2046ea040773ae8ea7f72dd3bbd8fa984501
Author: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
Date:   Thu Jun 13 00:21:40 2019 +0530

    powerpc/bpf: use unsigned division instruction for 64-bit operations
    
    BPF_ALU64 div/mod operations are currently using signed division, unlike
    BPF_ALU32 operations. Fix the same. DIV64 and MOD64 overflow tests pass
    with this fix.
    
    Fixes: 156d0e290e969c ("powerpc/ebpf/jit: Implement JIT compiler for extended BPF")
    Cc: stable@vger.kernel.org # v4.8+
    Signed-off-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 493c5c943acd..2291daf39cd1 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -338,6 +338,7 @@
 #define PPC_INST_MADDLD			0x10000033
 #define PPC_INST_DIVWU			0x7c000396
 #define PPC_INST_DIVD			0x7c0003d2
+#define PPC_INST_DIVDU			0x7c000392
 #define PPC_INST_RLWINM			0x54000000
 #define PPC_INST_RLWINM_DOT		0x54000001
 #define PPC_INST_RLWIMI			0x50000000

commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 23f7ed796f38..493c5c943acd 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -1,11 +1,7 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
 /*
  * Copyright 2009 Freescale Semiconductor, Inc.
  *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version
- * 2 of the License, or (at your option) any later version.
- *
  * provides masks and opcode images for use by code generation, emulation
  * and for instructions that older assemblers might not know about
  */

commit 0aedadcf6b4863a0d6eaad05a26425cc52944027
Merge: 4589e28db46e 86be36f6502c
Author: David S. Miller <davem@davemloft.net>
Date:   Sat Mar 16 12:20:08 2019 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf
    
    Daniel Borkmann says:
    
    ====================
    pull-request: bpf 2019-03-16
    
    The following pull-request contains BPF updates for your *net* tree.
    
    The main changes are:
    
    1) Fix a umem memory leak on cleanup in AF_XDP, from BjÃ¶rn.
    
    2) Fix BTF to properly resolve forward-declared enums into their corresponding
       full enum definition types during deduplication, from Andrii.
    
    3) Fix libbpf to reject invalid flags in xsk_socket__create(), from Magnus.
    
    4) Fix accessing invalid pointer returned from bpf_tcp_sock() and
       bpf_sk_fullsock() after bpf_sk_release() was called, from Martin.
    
    5) Fix generation of load/store DW instructions in PPC JIT, from Naveen.
    
    6) Various fixes in BPF helper function documentation in bpf.h UAPI header
       used to bpf-helpers(7) man page, from Quentin.
    
    7) Fix segfault in BPF test_progs when prog loading failed, from Yonghong.
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 86be36f6502c52ddb4b85938145324fd07332da1
Author: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
Date:   Fri Mar 15 20:21:19 2019 +0530

    powerpc: bpf: Fix generation of load/store DW instructions
    
    Yauheni Kaliuta pointed out that PTR_TO_STACK store/load verifier test
    was failing on powerpc64 BE, and rightfully indicated that the PPC_LD()
    macro is not masking away the last two bits of the offset per the ISA,
    resulting in the generation of 'lwa' instruction instead of the intended
    'ld' instruction.
    
    Segher also pointed out that we can't simply mask away the last two bits
    as that will result in loading/storing from/to a memory location that
    was not intended.
    
    This patch addresses this by using ldx/stdx if the offset is not
    word-aligned. We load the offset into a temporary register (TMP_REG_2)
    and use that as the index register in a subsequent ldx/stdx. We fix
    PPC_LD() macro to mask off the last two bits, but enhance PPC_BPF_LL()
    and PPC_BPF_STL() to factor in the offset value and generate the proper
    instruction sequence. We also convert all existing users of PPC_LD() and
    PPC_STD() to use these macros. All existing uses of these macros have
    been audited to ensure that TMP_REG_2 can be clobbered.
    
    Fixes: 156d0e290e96 ("powerpc/ebpf/jit: Implement JIT compiler for extended BPF")
    Cc: stable@vger.kernel.org # v4.9+
    
    Reported-by: Yauheni Kaliuta <yauheni.kaliuta@redhat.com>
    Signed-off-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index f9513ad38fa6..e6c9ad088f45 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -302,6 +302,7 @@
 /* Misc instructions for BPF compiler */
 #define PPC_INST_LBZ			0x88000000
 #define PPC_INST_LD			0xe8000000
+#define PPC_INST_LDX			0x7c00002a
 #define PPC_INST_LHZ			0xa0000000
 #define PPC_INST_LWZ			0x80000000
 #define PPC_INST_LHBRX			0x7c00062c
@@ -309,6 +310,7 @@
 #define PPC_INST_STB			0x98000000
 #define PPC_INST_STH			0xb0000000
 #define PPC_INST_STD			0xf8000000
+#define PPC_INST_STDX			0x7c00012a
 #define PPC_INST_STDU			0xf8000001
 #define PPC_INST_STW			0x90000000
 #define PPC_INST_STWU			0x94000000

commit 6c3ac1134371b51c9601171af2c32153ccb11100
Merge: d72cb8c7d9db 9580b71b5a78
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 7 12:56:26 2019 -0800

    Merge tag 'powerpc-5.1-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Notable changes:
    
       - Enable THREAD_INFO_IN_TASK to move thread_info off the stack.
    
       - A big series from Christoph reworking our DMA code to use more of
         the generic infrastructure, as he said:
           "This series switches the powerpc port to use the generic swiotlb
            and noncoherent dma ops, and to use more generic code for the
            coherent direct mapping, as well as removing a lot of dead
            code."
    
       - Increase our vmalloc space to 512T with the Hash MMU on modern
         CPUs, allowing us to support machines with larger amounts of total
         RAM or distance between nodes.
    
       - Two series from Christophe, one to optimise TLB miss handlers on
         6xx, and another to optimise the way STRICT_KERNEL_RWX is
         implemented on some 32-bit CPUs.
    
       - Support for KCOV coverage instrumentation which means we can run
         syzkaller and discover even more bugs in our code.
    
      And as always many clean-ups, reworks and minor fixes etc.
    
      Thanks to: Alan Modra, Alexey Kardashevskiy, Alistair Popple, Andrea
      Arcangeli, Andrew Donnellan, Aneesh Kumar K.V, Aravinda Prasad, Balbir
      Singh, Brajeswar Ghosh, Breno Leitao, Christian Lamparter, Christian
      Zigotzky, Christophe Leroy, Christoph Hellwig, Corentin Labbe, Daniel
      Axtens, David Gibson, Diana Craciun, Firoz Khan, Gustavo A. R. Silva,
      Igor Stoppa, Joe Lawrence, Joel Stanley, Jonathan NeuschÃ¤fer, Jordan
      Niethe, Laurent Dufour, Madhavan Srinivasan, Mahesh Salgaonkar, Mark
      Cave-Ayland, Masahiro Yamada, Mathieu Malaterre, Matteo Croce, Meelis
      Roos, Michael W. Bringmann, Nathan Chancellor, Nathan Fontenot,
      Nicholas Piggin, Nick Desaulniers, Nicolai Stange, Oliver O'Halloran,
      Paul Mackerras, Peter Xu, PrasannaKumar Muralidharan, Qian Cai,
      Rashmica Gupta, Reza Arbab, Robert P. J. Day, Russell Currey,
      Sabyasachi Gupta, Sam Bobroff, Sandipan Das, Sergey Senozhatsky,
      Souptick Joarder, Stewart Smith, Tyrel Datwyler, Vaibhav Jain,
      YueHaibing"
    
    * tag 'powerpc-5.1-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (200 commits)
      powerpc/32: Clear on-stack exception marker upon exception return
      powerpc: Remove export of save_stack_trace_tsk_reliable()
      powerpc/mm: fix "section_base" set but not used
      powerpc/mm: Fix "sz" set but not used warning
      powerpc/mm: Check secondary hash page table
      powerpc: remove nargs from __SYSCALL
      powerpc/64s: Fix unrelocated interrupt trampoline address test
      powerpc/powernv/ioda: Fix locked_vm counting for memory used by IOMMU tables
      powerpc/fsl: Fix the flush of branch predictor.
      powerpc/powernv: Make opal log only readable by root
      powerpc/xmon: Fix opcode being uninitialized in print_insn_powerpc
      powerpc/powernv: move OPAL call wrapper tracing and interrupt handling to C
      powerpc/64s: Fix data interrupts vs d-side MCE reentrancy
      powerpc/64s: Prepare to handle data interrupts vs d-side MCE reentrancy
      powerpc/64s: system reset interrupt preserve HSRRs
      powerpc/64s: Fix HV NMI vs HV interrupt recoverability test
      powerpc/mm/hash: Handle mmap_min_addr correctly in get_unmapped_area topdown search
      powerpc/hugetlb: Handle mmap_min_addr correctly in get_unmapped_area callback
      selftests/powerpc: Remove duplicate header
      powerpc sstep: Add support for modsd, modud instructions
      ...

commit 930d6288a26787d2e7f633705434171a506db9c5
Author: Sandipan Das <sandipan@linux.ibm.com>
Date:   Fri Feb 22 12:23:27 2019 +0530

    powerpc: sstep: Add support for maddhd, maddhdu, maddld instructions
    
    This adds emulation support for the following integer instructions:
      * Multiply-Add High Doubleword (maddhd)
      * Multiply-Add High Doubleword Unsigned (maddhdu)
      * Multiply-Add Low Doubleword (maddld)
    
    As suggested by Michael, this uses a raw .long for specifying the
    instruction word when using inline assembly to retain compatibility
    with older binutils.
    
    Signed-off-by: Sandipan Das <sandipan@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 87b73aa56b53..2bc949414669 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -335,6 +335,9 @@
 #define PPC_INST_MULLW			0x7c0001d6
 #define PPC_INST_MULHWU			0x7c000016
 #define PPC_INST_MULLI			0x1c000000
+#define PPC_INST_MADDHD			0x10000030
+#define PPC_INST_MADDHDU		0x10000031
+#define PPC_INST_MADDLD			0x10000033
 #define PPC_INST_DIVWU			0x7c000396
 #define PPC_INST_DIVD			0x7c0003d2
 #define PPC_INST_RLWINM			0x54000000
@@ -377,6 +380,7 @@
 /* macros to insert fields into opcodes */
 #define ___PPC_RA(a)	(((a) & 0x1f) << 16)
 #define ___PPC_RB(b)	(((b) & 0x1f) << 11)
+#define ___PPC_RC(c)	(((c) & 0x1f) << 6)
 #define ___PPC_RS(s)	(((s) & 0x1f) << 21)
 #define ___PPC_RT(t)	___PPC_RS(t)
 #define ___PPC_R(r)	(((r) & 0x1) << 16)
@@ -396,7 +400,7 @@
 #define __PPC_WS(w)	(((w) & 0x1f) << 11)
 #define __PPC_SH(s)	__PPC_WS(s)
 #define __PPC_SH64(s)	(__PPC_SH(s) | (((s) & 0x20) >> 4))
-#define __PPC_MB(s)	(((s) & 0x1f) << 6)
+#define __PPC_MB(s)	___PPC_RC(s)
 #define __PPC_ME(s)	(((s) & 0x1f) << 1)
 #define __PPC_MB64(s)	(__PPC_MB(s) | ((s) & 0x20))
 #define __PPC_ME64(s)	__PPC_MB64(s)
@@ -438,6 +442,15 @@
 #define PPC_STQCX(t, a, b)	stringify_in_c(.long PPC_INST_STQCX | \
 					___PPC_RT(t) | ___PPC_RA(a) | \
 					___PPC_RB(b))
+#define PPC_MADDHD(t, a, b, c)	stringify_in_c(.long PPC_INST_MADDHD | \
+					___PPC_RT(t) | ___PPC_RA(a)  | \
+					___PPC_RB(b) | ___PPC_RC(c))
+#define PPC_MADDHDU(t, a, b, c)	stringify_in_c(.long PPC_INST_MADDHDU | \
+					___PPC_RT(t) | ___PPC_RA(a)   | \
+					___PPC_RB(b) | ___PPC_RC(c))
+#define PPC_MADDLD(t, a, b, c)	stringify_in_c(.long PPC_INST_MADDLD | \
+					___PPC_RT(t) | ___PPC_RA(a)  | \
+					___PPC_RB(b) | ___PPC_RC(c))
 #define PPC_MSGSND(b)		stringify_in_c(.long PPC_INST_MSGSND | \
 					___PPC_RB(b))
 #define PPC_MSGSYNC		stringify_in_c(.long PPC_INST_MSGSYNC)

commit 78a8da0600940d679bb727cea7e153685e211723
Author: Sandipan Das <sandipan@linux.ibm.com>
Date:   Wed Feb 20 12:27:00 2019 +0530

    powerpc: sstep: Add tests for addc[.] instruction
    
    This adds test cases for the addc[.] instruction.
    
    Signed-off-by: Sandipan Das <sandipan@linux.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 19a8834e0398..87b73aa56b53 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -326,6 +326,7 @@
 #define PPC_INST_ADDI			0x38000000
 #define PPC_INST_ADDIS			0x3c000000
 #define PPC_INST_ADD			0x7c000214
+#define PPC_INST_ADDC			0x7c000014
 #define PPC_INST_SUB			0x7c000050
 #define PPC_INST_BLR			0x4e800020
 #define PPC_INST_BLRL			0x4e800021

commit 5f6459966d0abca8b799440f6e1b18dac153c54d
Author: Jiong Wang <jiong.wang@netronome.com>
Date:   Sat Jan 26 12:26:10 2019 -0500

    ppc: bpf: implement jitting of JMP32
    
    This patch implements code-gen for new JMP32 instructions on ppc.
    
    For JMP32 | JSET, instruction encoding for PPC_RLWINM_DOT is added to check
    the result of ANDing low 32-bit of operands.
    
    Cc: Naveen N. Rao <naveen.n.rao@linux.ibm.com>
    Cc: Sandipan Das <sandipan@linux.ibm.com>
    Signed-off-by: Jiong Wang <jiong.wang@netronome.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 19a8834e0398..f9513ad38fa6 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -337,6 +337,7 @@
 #define PPC_INST_DIVWU			0x7c000396
 #define PPC_INST_DIVD			0x7c0003d2
 #define PPC_INST_RLWINM			0x54000000
+#define PPC_INST_RLWINM_DOT		0x54000001
 #define PPC_INST_RLWIMI			0x50000000
 #define PPC_INST_RLDICL			0x78000000
 #define PPC_INST_RLDICR			0x78000004

commit e0c38a4d1f196a4b17d2eba36afff8f656a4f1de
Merge: 7f9f852c75e7 90cadbbf341d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Dec 27 13:04:52 2018 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next
    
    Pull networking updates from David Miller:
    
     1) New ipset extensions for matching on destination MAC addresses, from
        Stefano Brivio.
    
     2) Add ipv4 ttl and tos, plus ipv6 flow label and hop limit offloads to
        nfp driver. From Stefano Brivio.
    
     3) Implement GRO for plain UDP sockets, from Paolo Abeni.
    
     4) Lots of work from MichaÅ MirosÅaw to eliminate the VLAN_TAG_PRESENT
        bit so that we could support the entire vlan_tci value.
    
     5) Rework the IPSEC policy lookups to better optimize more usecases,
        from Florian Westphal.
    
     6) Infrastructure changes eliminating direct manipulation of SKB lists
        wherever possible, and to always use the appropriate SKB list
        helpers. This work is still ongoing...
    
     7) Lots of PHY driver and state machine improvements and
        simplifications, from Heiner Kallweit.
    
     8) Various TSO deferral refinements, from Eric Dumazet.
    
     9) Add ntuple filter support to aquantia driver, from Dmitry Bogdanov.
    
    10) Batch dropping of XDP packets in tuntap, from Jason Wang.
    
    11) Lots of cleanups and improvements to the r8169 driver from Heiner
        Kallweit, including support for ->xmit_more. This driver has been
        getting some much needed love since he started working on it.
    
    12) Lots of new forwarding selftests from Petr Machata.
    
    13) Enable VXLAN learning in mlxsw driver, from Ido Schimmel.
    
    14) Packed ring support for virtio, from Tiwei Bie.
    
    15) Add new Aquantia AQtion USB driver, from Dmitry Bezrukov.
    
    16) Add XDP support to dpaa2-eth driver, from Ioana Ciocoi Radulescu.
    
    17) Implement coalescing on TCP backlog queue, from Eric Dumazet.
    
    18) Implement carrier change in tun driver, from Nicolas Dichtel.
    
    19) Support msg_zerocopy in UDP, from Willem de Bruijn.
    
    20) Significantly improve garbage collection of neighbor objects when
        the table has many PERMANENT entries, from David Ahern.
    
    21) Remove egdev usage from nfp and mlx5, and remove the facility
        completely from the tree as it no longer has any users. From Oz
        Shlomo and others.
    
    22) Add a NETDEV_PRE_CHANGEADDR so that drivers can veto the change and
        therefore abort the operation before the commit phase (which is the
        NETDEV_CHANGEADDR event). From Petr Machata.
    
    23) Add indirect call wrappers to avoid retpoline overhead, and use them
        in the GRO code paths. From Paolo Abeni.
    
    24) Add support for netlink FDB get operations, from Roopa Prabhu.
    
    25) Support bloom filter in mlxsw driver, from Nir Dotan.
    
    26) Add SKB extension infrastructure. This consolidates the handling of
        the auxiliary SKB data used by IPSEC and bridge netfilter, and is
        designed to support the needs to MPTCP which could be integrated in
        the future.
    
    27) Lots of XDP TX optimizations in mlx5 from Tariq Toukan.
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next: (1845 commits)
      net: dccp: fix kernel crash on module load
      drivers/net: appletalk/cops: remove redundant if statement and mask
      bnx2x: Fix NULL pointer dereference in bnx2x_del_all_vlans() on some hw
      net/net_namespace: Check the return value of register_pernet_subsys()
      net/netlink_compat: Fix a missing check of nla_parse_nested
      ieee802154: lowpan_header_create check must check daddr
      net/mlx4_core: drop useless LIST_HEAD
      mlxsw: spectrum: drop useless LIST_HEAD
      net/mlx5e: drop useless LIST_HEAD
      iptunnel: Set tun_flags in the iptunnel_metadata_reply from src
      net/mlx5e: fix semicolon.cocci warnings
      staging: octeon: fix build failure with XFRM enabled
      net: Revert recent Spectre-v1 patches.
      can: af_can: Fix Spectre v1 vulnerability
      packet: validate address length if non-zero
      nfc: af_nfc: Fix Spectre v1 vulnerability
      phonet: af_phonet: Fix Spectre v1 vulnerability
      net: core: Fix Spectre v1 vulnerability
      net: minor cleanup in skb_ext_add()
      net: drop the unused helper skb_ext_get()
      ...

commit d16952a629129ce3f20ff7299de87c4d63b27a30
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Fri Nov 9 17:33:28 2018 +0000

    powerpc/signal: Use code patching instead of hardcoding
    
    Instead of hardcoding code modifications, use code patching functions.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index a6e9e314c707..7f693e0f7499 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -257,6 +257,7 @@
 #define PPC_INST_MTSPR_DSCR_USER_MASK	0xfc1ffffe
 #define PPC_INST_MFVSRD			0x7c000066
 #define PPC_INST_MTVSRD			0x7c000166
+#define PPC_INST_SC			0x44000002
 #define PPC_INST_SLBFEE			0x7c0007a7
 #define PPC_INST_SLBIA			0x7c0003e4
 

commit 44cf43c04bb5f7c688608ff4136b13f2a8a7a129
Author: Jiong Wang <jiong.wang@netronome.com>
Date:   Wed Dec 5 13:52:31 2018 -0500

    ppc: bpf: implement jitting of BPF_ALU | BPF_ARSH | BPF_*
    
    This patch implements code-gen for BPF_ALU | BPF_ARSH | BPF_*.
    
    Cc: Naveen N. Rao <naveen.n.rao@linux.ibm.com>
    Cc: Sandipan Das <sandipan@linux.ibm.com>
    Signed-off-by: Jiong Wang <jiong.wang@netronome.com>
    Reviewed-by: Sandipan Das <sandipan@linux.ibm.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index a6e9e314c707..901459226eca 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -342,6 +342,8 @@
 #define PPC_INST_SLW			0x7c000030
 #define PPC_INST_SLD			0x7c000036
 #define PPC_INST_SRW			0x7c000430
+#define PPC_INST_SRAW			0x7c000630
+#define PPC_INST_SRAWI			0x7c000670
 #define PPC_INST_SRD			0x7c000436
 #define PPC_INST_SRAD			0x7c000634
 #define PPC_INST_SRADI			0x7c000674

commit 08e6a3434e2125e4b21d0d3f84678d427345bc0d
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Nov 6 19:25:18 2018 +1100

    powerpc/mm/64s: Use PPC_SLBFEE macro
    
    Old toolchains don't know about slbfee and break the build, eg:
      {standard input}:37: Error: Unrecognized opcode: `slbfee.'
    
    Fix it by using the macro version. We need to add an underscore
    version that takes raw register numbers from the inline asm, rather
    than our Rx macros.
    
    Fixes: e15a4fea4dee ("powerpc/64s/hash: Add some SLB debugging tests")
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 6093bc8f74e5..a6e9e314c707 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -493,6 +493,8 @@
 					__PPC_RS(t) | __PPC_RA0(a) | __PPC_RB(b))
 #define PPC_SLBFEE_DOT(t, b)	stringify_in_c(.long PPC_INST_SLBFEE | \
 					__PPC_RT(t) | __PPC_RB(b))
+#define __PPC_SLBFEE_DOT(t, b)	stringify_in_c(.long PPC_INST_SLBFEE |	\
+					       ___PPC_RT(t) | ___PPC_RB(b))
 #define PPC_ICBT(c,a,b)		stringify_in_c(.long PPC_INST_ICBT | \
 				       __PPC_CT(c) | __PPC_RA0(a) | __PPC_RB(b))
 /* PASemi instructions */

commit e3b6b4661527e821ffbe3db83952fdb1e6e47c49
Author: Suraj Jitindar Singh <sjitindarsingh@gmail.com>
Date:   Mon Oct 8 16:31:09 2018 +1100

    KVM: PPC: Book3S HV: Implement H_TLB_INVALIDATE hcall
    
    When running a nested (L2) guest the guest (L1) hypervisor will use
    the H_TLB_INVALIDATE hcall when it needs to change the partition
    scoped page tables or the partition table which it manages.  It will
    use this hcall in the situations where it would use a partition-scoped
    tlbie instruction if it were running in hypervisor mode.
    
    The H_TLB_INVALIDATE hcall can invalidate different scopes:
    
    Invalidate TLB for a given target address:
    - This invalidates a single L2 -> L1 pte
    - We need to invalidate any L2 -> L0 shadow_pgtable ptes which map the L2
      address space which is being invalidated. This is because a single
      L2 -> L1 pte may have been mapped with more than one pte in the
      L2 -> L0 page tables.
    
    Invalidate the entire TLB for a given LPID or for all LPIDs:
    - Invalidate the entire shadow_pgtable for a given nested guest, or
      for all nested guests.
    
    Invalidate the PWC (page walk cache) for a given LPID or for all LPIDs:
    - We don't cache the PWC, so nothing to do.
    
    Invalidate the entire TLB, PWC and partition table for a given/all LPIDs:
    - Here we re-read the partition table entry and remove the nested state
      for any nested guest for which the first doubleword of the partition
      table entry is now zero.
    
    The H_TLB_INVALIDATE hcall takes as parameters the tlbie instruction
    word (of which only the RIC, PRS and R fields are used), the rS value
    (giving the lpid, where required) and the rB value (giving the IS, AP
    and EPN values).
    
    [paulus@ozlabs.org - adapted to having the partition table in guest
    memory, added the H_TLB_INVALIDATE implementation, removed tlbie
    instruction emulation, reworded the commit message.]
    
    Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
    Signed-off-by: Suraj Jitindar Singh <sjitindarsingh@gmail.com>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 665af14850e4..6093bc8f74e5 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -104,6 +104,7 @@
 #define OP_31_XOP_LHZUX     311
 #define OP_31_XOP_MSGSNDP   142
 #define OP_31_XOP_MSGCLRP   174
+#define OP_31_XOP_TLBIE     306
 #define OP_31_XOP_MFSPR     339
 #define OP_31_XOP_LWAX      341
 #define OP_31_XOP_LHAX      343

commit 5c35a02c545a7bbe77f3a1ae337d9e29beed079b
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Jul 5 16:24:59 2018 +0000

    powerpc: clean the inclusion of stringify.h
    
    Only include linux/stringify.h is files using __stringify()
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 954edf935158..665af14850e4 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -12,7 +12,6 @@
 #ifndef _ASM_POWERPC_PPC_OPCODE_H
 #define _ASM_POWERPC_PPC_OPCODE_H
 
-#include <linux/stringify.h>
 #include <asm/asm-const.h>
 
 #define	__REG_R0	0

commit ec0c464cdbf38bf6ddabec8bfa595bd421cab203
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Jul 5 16:24:57 2018 +0000

    powerpc: move ASM_CONST and stringify_in_c() into asm-const.h
    
    This patch moves ASM_CONST() and stringify_in_c() into
    dedicated asm-const.h, then cleans all related inclusions.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    [mpe: asm-compat.h should include asm-const.h]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index c103caf99897..954edf935158 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -13,7 +13,7 @@
 #define _ASM_POWERPC_PPC_OPCODE_H
 
 #include <linux/stringify.h>
-#include <asm/asm-compat.h>
+#include <asm/asm-const.h>
 
 #define	__REG_R0	0
 #define	__REG_R1	1

commit f1ecbaf466be5a7a5c666b41eede6991caff8646
Author: Simon Guo <wei.guo.simon@gmail.com>
Date:   Thu Jun 7 09:57:52 2018 +0800

    powerpc: add vcmpequd/vcmpequb ppc instruction macro
    
    Some old tool chains don't know about instructions like vcmpequd.
    
    This patch adds .long macro for vcmpequd and vcmpequb, which is
    a preparation to optimize ppc64 memcmp with VMX instructions.
    
    Signed-off-by: Simon Guo <wei.guo.simon@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 4436887bc415..c103caf99897 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -367,6 +367,8 @@
 #define PPC_INST_STFDX			0x7c0005ae
 #define PPC_INST_LVX			0x7c0000ce
 #define PPC_INST_STVX			0x7c0001ce
+#define PPC_INST_VCMPEQUD		0x100000c7
+#define PPC_INST_VCMPEQUB		0x10000006
 
 /* macros to insert fields into opcodes */
 #define ___PPC_RA(a)	(((a) & 0x1f) << 16)
@@ -397,6 +399,7 @@
 #define __PPC_BI(s)	(((s) & 0x1f) << 16)
 #define __PPC_CT(t)	(((t) & 0x0f) << 21)
 #define __PPC_SPR(r)	((((r) & 0x1f) << 16) | ((((r) >> 5) & 0x1f) << 11))
+#define __PPC_RC21	(0x1 << 10)
 
 /*
  * Only use the larx hint bit on 64bit CPUs. e500v1/v2 based CPUs will treat a
@@ -568,4 +571,12 @@
 				       ((IH & 0x7) << 21))
 #define PPC_INVALIDATE_ERAT	PPC_SLBIA(7)
 
+#define VCMPEQUD_RC(vrt, vra, vrb)	stringify_in_c(.long PPC_INST_VCMPEQUD | \
+			      ___PPC_RT(vrt) | ___PPC_RA(vra) | \
+			      ___PPC_RB(vrb) | __PPC_RC21)
+
+#define VCMPEQUB_RC(vrt, vra, vrb)	stringify_in_c(.long PPC_INST_VCMPEQUB | \
+			      ___PPC_RT(vrt) | ___PPC_RA(vra) | \
+			      ___PPC_RB(vrb) | __PPC_RC21)
+
 #endif /* _ASM_POWERPC_PPC_OPCODE_H */

commit 8a0b1120cb25ccd4480ba4fe3650bc22b0dfadf4
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Wed May 23 09:04:04 2018 +0200

    powerpc/mm: Use instruction symbolic names in store_updates_sp()
    
    Use symbolic names defined in asm/ppc-opcode.h
    instead of hardcoded values.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 18883b8a6dac..4436887bc415 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -162,6 +162,7 @@
 /* VMX Vector Store Instructions */
 #define OP_31_XOP_STVX          231
 
+#define OP_31   31
 #define OP_LWZ  32
 #define OP_STFS 52
 #define OP_STFSU 53

commit a26cf1c9fe3c2e3b671b490aeb708ea72fb5ac0a
Merge: 78e5dfea84dc 681c617b7c42
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Sat Mar 24 08:43:18 2018 +1100

    Merge branch 'topic/ppc-kvm' into next
    
    This brings in two series from Paul, one of which touches KVM code and
    may need to be merged into the kvm-ppc tree to resolve conflicts.

commit 4bb3c7a0208fc13ca70598efd109901a7cd45ae7
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Wed Mar 21 21:32:01 2018 +1100

    KVM: PPC: Book3S HV: Work around transactional memory bugs in POWER9
    
    POWER9 has hardware bugs relating to transactional memory and thread
    reconfiguration (changes to hardware SMT mode).  Specifically, the core
    does not have enough storage to store a complete checkpoint of all the
    architected state for all four threads.  The DD2.2 version of POWER9
    includes hardware modifications designed to allow hypervisor software
    to implement workarounds for these problems.  This patch implements
    those workarounds in KVM code so that KVM guests see a full, working
    transactional memory implementation.
    
    The problems center around the use of TM suspended state, where the
    CPU has a checkpointed state but execution is not transactional.  The
    workaround is to implement a "fake suspend" state, which looks to the
    guest like suspended state but the CPU does not store a checkpoint.
    In this state, any instruction that would cause a transition to
    transactional state (rfid, rfebb, mtmsrd, tresume) or would use the
    checkpointed state (treclaim) causes a "soft patch" interrupt (vector
    0x1500) to the hypervisor so that it can be emulated.  The trechkpt
    instruction also causes a soft patch interrupt.
    
    On POWER9 DD2.2, we avoid returning to the guest in any state which
    would require a checkpoint to be present.  The trechkpt in the guest
    entry path which would normally create that checkpoint is replaced by
    either a transition to fake suspend state, if the guest is in suspend
    state, or a rollback to the pre-transactional state if the guest is in
    transactional state.  Fake suspend state is indicated by a flag in the
    PACA plus a new bit in the PSSCR.  The new PSSCR bit is write-only and
    reads back as 0.
    
    On exit from the guest, if the guest is in fake suspend state, we still
    do the treclaim instruction as we would in real suspend state, in order
    to get into non-transactional state, but we do not save the resulting
    register state since there was no checkpoint.
    
    Emulation of the instructions that cause a softpatch interrupt is
    handled in two paths.  If the guest is in real suspend mode, we call
    kvmhv_p9_tm_emulation_early() to handle the cases where the guest is
    transitioning to transactional state.  This is called before we do the
    treclaim in the guest exit path; because we haven't done treclaim, we
    can get back to the guest with the transaction still active.  If the
    instruction is a case that kvmhv_p9_tm_emulation_early() doesn't
    handle, or if the guest is in fake suspend state, then we proceed to
    do the complete guest exit path and subsequently call
    kvmhv_p9_tm_emulation() in host context with the MMU on.  This handles
    all the cases including the cases that generate program interrupts
    (illegal instruction or TM Bad Thing) and facility unavailable
    interrupts.
    
    The emulation is reasonably straightforward and is mostly concerned
    with checking for exception conditions and updating the state of
    registers such as MSR and CR0.  The treclaim emulation takes care to
    ensure that the TEXASR register gets updated as if it were the guest
    treclaim instruction that had done failure recording, not the treclaim
    done in hypervisor state in the guest exit path.
    
    With this, the KVM_CAP_PPC_HTM capability returns true (1) even if
    transactional memory is not available to host userspace.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index f1083bcf449c..772eff7fd446 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -232,6 +232,7 @@
 #define PPC_INST_MSGSYNC		0x7c0006ec
 #define PPC_INST_MSGSNDP		0x7c00011c
 #define PPC_INST_MSGCLRP		0x7c00015c
+#define PPC_INST_MTMSRD			0x7c000164
 #define PPC_INST_MTTMR			0x7c0003dc
 #define PPC_INST_NOP			0x60000000
 #define PPC_INST_PASTE			0x7c20070d
@@ -239,8 +240,10 @@
 #define PPC_INST_POPCNTB_MASK		0xfc0007fe
 #define PPC_INST_POPCNTD		0x7c0003f4
 #define PPC_INST_POPCNTW		0x7c0002f4
+#define PPC_INST_RFEBB			0x4c000124
 #define PPC_INST_RFCI			0x4c000066
 #define PPC_INST_RFDI			0x4c00004e
+#define PPC_INST_RFID			0x4c000024
 #define PPC_INST_RFMCI			0x4c00004c
 #define PPC_INST_MFSPR			0x7c0002a6
 #define PPC_INST_MFSPR_DSCR		0x7c1102a6
@@ -277,6 +280,7 @@
 #define PPC_INST_TRECHKPT		0x7c0007dd
 #define PPC_INST_TRECLAIM		0x7c00075d
 #define PPC_INST_TABORT			0x7c00071d
+#define PPC_INST_TSR			0x7c0005dd
 
 #define PPC_INST_NAP			0x4c000364
 #define PPC_INST_SLEEP			0x4c0003a4

commit 751ba79cc552c146595cd439b21c4ff8998c3b69
Author: Matt Brown <matthew.brown.dev@gmail.com>
Date:   Fri Aug 4 13:42:32 2017 +1000

    lib/raid6/altivec: Add vpermxor implementation for raid6 Q syndrome
    
    This patch uses the vpermxor instruction to optimise the raid6 Q
    syndrome. This instruction was made available with POWER8, ISA version
    2.07. It allows for both vperm and vxor instructions to be done in a
    single instruction. This has been tested for correctness on a ppc64le
    vm with a basic RAID6 setup containing 5 drives.
    
    The performance benchmarks are from the raid6test in the
    /lib/raid6/test directory. These results are from an IBM Firestone
    machine with ppc64le architecture. The benchmark results show a 35%
    speed increase over the best existing algorithm for powerpc (altivec).
    The raid6test has also been run on a big-endian ppc64 vm to ensure it
    also works for big-endian architectures.
    
    Performance benchmarks:
      raid6: altivecx4 gen() 18773 MB/s
      raid6: altivecx8 gen() 19438 MB/s
    
      raid6: vpermxor4 gen() 25112 MB/s
      raid6: vpermxor8 gen() 26279 MB/s
    
    Signed-off-by: Matt Brown <matthew.brown.dev@gmail.com>
    Reviewed-by: Daniel Axtens <dja@axtens.net>
    [mpe: Add VPERMXOR macro so we can build with old binutils]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index f1083bcf449c..7370da18035e 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -271,6 +271,7 @@
 #define PPC_INST_TLBSRX_DOT		0x7c0006a5
 #define PPC_INST_VPMSUMW		0x10000488
 #define PPC_INST_VPMSUMD		0x100004c8
+#define PPC_INST_VPERMXOR		0x1000002d
 #define PPC_INST_XXLOR			0xf0000490
 #define PPC_INST_XXSWAPD		0xf0000250
 #define PPC_INST_XVCPSGNDP		0xf0000780
@@ -517,6 +518,11 @@
 #define XVCPSGNDP(t, a, b)	stringify_in_c(.long (PPC_INST_XVCPSGNDP | \
 					       VSX_XX3((t), (a), (b))))
 
+#define VPERMXOR(vrt, vra, vrb, vrc)				\
+	stringify_in_c(.long (PPC_INST_VPERMXOR |		\
+			      ___PPC_RT(vrt) | ___PPC_RA(vra) | \
+			      ___PPC_RB(vrb) | (((vrc) & 0x1f) << 6)))
+
 #define PPC_NAP			stringify_in_c(.long PPC_INST_NAP)
 #define PPC_SLEEP		stringify_in_c(.long PPC_INST_SLEEP)
 #define PPC_WINKLE		stringify_in_c(.long PPC_INST_WINKLE)

commit 15303ba5d1cd9b28d03a980456c0978c0ea3b208
Merge: 9a61df9e5f74 1ab03c072feb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Feb 10 13:16:35 2018 -0800

    Merge tag 'kvm-4.16-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull KVM updates from Radim KrÄmÃ¡Å:
     "ARM:
    
       - icache invalidation optimizations, improving VM startup time
    
       - support for forwarded level-triggered interrupts, improving
         performance for timers and passthrough platform devices
    
       - a small fix for power-management notifiers, and some cosmetic
         changes
    
      PPC:
    
       - add MMIO emulation for vector loads and stores
    
       - allow HPT guests to run on a radix host on POWER9 v2.2 CPUs without
         requiring the complex thread synchronization of older CPU versions
    
       - improve the handling of escalation interrupts with the XIVE
         interrupt controller
    
       - support decrement register migration
    
       - various cleanups and bugfixes.
    
      s390:
    
       - Cornelia Huck passed maintainership to Janosch Frank
    
       - exitless interrupts for emulated devices
    
       - cleanup of cpuflag handling
    
       - kvm_stat counter improvements
    
       - VSIE improvements
    
       - mm cleanup
    
      x86:
    
       - hypervisor part of SEV
    
       - UMIP, RDPID, and MSR_SMI_COUNT emulation
    
       - paravirtualized TLB shootdown using the new KVM_VCPU_PREEMPTED bit
    
       - allow guests to see TOPOEXT, GFNI, VAES, VPCLMULQDQ, and more
         AVX512 features
    
       - show vcpu id in its anonymous inode name
    
       - many fixes and cleanups
    
       - per-VCPU MSR bitmaps (already merged through x86/pti branch)
    
       - stable KVM clock when nesting on Hyper-V (merged through
         x86/hyperv)"
    
    * tag 'kvm-4.16-1' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (197 commits)
      KVM: PPC: Book3S: Add MMIO emulation for VMX instructions
      KVM: PPC: Book3S HV: Branch inside feature section
      KVM: PPC: Book3S HV: Make HPT resizing work on POWER9
      KVM: PPC: Book3S HV: Fix handling of secondary HPTEG in HPT resizing code
      KVM: PPC: Book3S PR: Fix broken select due to misspelling
      KVM: x86: don't forget vcpu_put() in kvm_arch_vcpu_ioctl_set_sregs()
      KVM: PPC: Book3S PR: Fix svcpu copying with preemption enabled
      KVM: PPC: Book3S HV: Drop locks before reading guest memory
      kvm: x86: remove efer_reload entry in kvm_vcpu_stat
      KVM: x86: AMD Processor Topology Information
      x86/kvm/vmx: do not use vm-exit instruction length for fast MMIO when running nested
      kvm: embed vcpu id to dentry of vcpu anon inode
      kvm: Map PFN-type memory regions as writable (if possible)
      x86/kvm: Make it compile on 32bit and with HYPYERVISOR_GUEST=n
      KVM: arm/arm64: Fixup userspace irqchip static key optimization
      KVM: arm/arm64: Fix userspace_irqchip_in_use counting
      KVM: arm/arm64: Fix incorrect timer_is_pending logic
      MAINTAINERS: update KVM/s390 maintainers
      MAINTAINERS: add Halil as additional vfio-ccw maintainer
      MAINTAINERS: add David as a reviewer for KVM/s390
      ...

commit 09f984961c137c4b252c368adab7e1c9f035fa59
Author: Jose Ricardo Ziviani <joserz@linux.vnet.ibm.com>
Date:   Sat Feb 3 18:24:26 2018 -0200

    KVM: PPC: Book3S: Add MMIO emulation for VMX instructions
    
    This patch provides the MMIO load/store vector indexed
    X-Form emulation.
    
    Instructions implemented:
    lvx: the quadword in storage addressed by the result of EA &
    0xffff_ffff_ffff_fff0 is loaded into VRT.
    
    stvx: the contents of VRS are stored into the quadword in storage
    addressed by the result of EA & 0xffff_ffff_ffff_fff0.
    
    Reported-by: Gopesh Kumar Chaudhary <gopchaud@in.ibm.com>
    Reported-by: Balamuruhan S <bala24@linux.vnet.ibm.com>
    Signed-off-by: Jose Ricardo Ziviani <joserz@linux.vnet.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index ce0930d68857..a51febca08c5 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -156,6 +156,12 @@
 #define OP_31_XOP_LFDX          599
 #define OP_31_XOP_LFDUX		631
 
+/* VMX Vector Load Instructions */
+#define OP_31_XOP_LVX           103
+
+/* VMX Vector Store Instructions */
+#define OP_31_XOP_STVX          231
+
 #define OP_LWZ  32
 #define OP_STFS 52
 #define OP_STFSU 53

commit cd99ddbea250ee79027df6c469f51ad9e5452738
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Fri Jan 12 13:45:23 2018 +0100

    powerpc/8xx: Only perform perf counting when perf is in use.
    
    In TLB miss handlers, updating the perf counter is only useful
    when performing a perf analysis. As it has a noticeable overhead,
    let's only do it when needed.
    
    In order to do so, the exit of the miss handlers will be patched
    when starting/stopping 'perf': the first register restore
    instruction of each exit point will be replaced by a jump to
    the counting code.
    
    Once this is done, CONFIG_PPC_8xx_PERF_EVENT becomes useless as
    this feature doesn't add any overhead.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index ce0930d68857..ab5c1588b487 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -236,6 +236,7 @@
 #define PPC_INST_RFCI			0x4c000066
 #define PPC_INST_RFDI			0x4c00004e
 #define PPC_INST_RFMCI			0x4c00004c
+#define PPC_INST_MFSPR			0x7c0002a6
 #define PPC_INST_MFSPR_DSCR		0x7c1102a6
 #define PPC_INST_MFSPR_DSCR_MASK	0xfc1ffffe
 #define PPC_INST_MTSPR_DSCR		0x7c1103a6
@@ -383,6 +384,7 @@
 #define __PPC_ME64(s)	__PPC_MB64(s)
 #define __PPC_BI(s)	(((s) & 0x1f) << 16)
 #define __PPC_CT(t)	(((t) & 0x0f) << 21)
+#define __PPC_SPR(r)	((((r) & 0x1f) << 16) | ((((r) >> 5) & 0x1f) << 11))
 
 /*
  * Only use the larx hint bit on 64bit CPUs. e500v1/v2 based CPUs will treat a

commit 350779a29f11f80ac66a8b38a7718ad30f003f18
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Wed Aug 30 14:12:27 2017 +1000

    powerpc: Handle most loads and stores in instruction emulation code
    
    This extends the instruction emulation infrastructure in sstep.c to
    handle all the load and store instructions defined in the Power ISA
    v3.0, except for the atomic memory operations, ldmx (which was never
    implemented), lfdp/stfdp, and the vector element load/stores.
    
    The instructions added are:
    
    Integer loads and stores: lbarx, lharx, lqarx, stbcx., sthcx., stqcx.,
    lq, stq.
    
    VSX loads and stores: lxsiwzx, lxsiwax, stxsiwx, lxvx, lxvl, lxvll,
    lxvdsx, lxvwsx, stxvx, stxvl, stxvll, lxsspx, lxsdx, stxsspx, stxsdx,
    lxvw4x, lxsibzx, lxvh8x, lxsihzx, lxvb16x, stxvw4x, stxsibx, stxvh8x,
    stxsihx, stxvb16x, lxsd, lxssp, lxv, stxsd, stxssp, stxv.
    
    These instructions are handled both in the analyse_instr phase and in
    the emulate_step phase.
    
    The code for lxvd2ux and stxvd2ux has been taken out, as those
    instructions were never implemented in any processor and have been
    taken out of the architecture, and their opcodes have been reused for
    other instructions in POWER9 (lxvb16x and stxvb16x).
    
    The emulation for the VSX loads and stores uses helper functions
    which don't access registers or memory directly, which can hopefully
    be reused by KVM later.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 3dd8a6e43bb2..ce0930d68857 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -205,6 +205,8 @@
 #define PPC_INST_ISEL_MASK		0xfc00003e
 #define PPC_INST_LDARX			0x7c0000a8
 #define PPC_INST_STDCX			0x7c0001ad
+#define PPC_INST_LQARX			0x7c000228
+#define PPC_INST_STQCX			0x7c00016d
 #define PPC_INST_LSWI			0x7c0004aa
 #define PPC_INST_LSWX			0x7c00042a
 #define PPC_INST_LWARX			0x7c000028
@@ -403,12 +405,18 @@
 					__PPC_RA(a) | __PPC_RB(b))
 #define	PPC_DCBZL(a, b)		stringify_in_c(.long PPC_INST_DCBZL | \
 					__PPC_RA(a) | __PPC_RB(b))
+#define PPC_LQARX(t, a, b, eh)	stringify_in_c(.long PPC_INST_LQARX | \
+					___PPC_RT(t) | ___PPC_RA(a) | \
+					___PPC_RB(b) | __PPC_EH(eh))
 #define PPC_LDARX(t, a, b, eh)	stringify_in_c(.long PPC_INST_LDARX | \
 					___PPC_RT(t) | ___PPC_RA(a) | \
 					___PPC_RB(b) | __PPC_EH(eh))
 #define PPC_LWARX(t, a, b, eh)	stringify_in_c(.long PPC_INST_LWARX | \
 					___PPC_RT(t) | ___PPC_RA(a) | \
 					___PPC_RB(b) | __PPC_EH(eh))
+#define PPC_STQCX(t, a, b)	stringify_in_c(.long PPC_INST_STQCX | \
+					___PPC_RT(t) | ___PPC_RA(a) | \
+					___PPC_RB(b))
 #define PPC_MSGSND(b)		stringify_in_c(.long PPC_INST_MSGSND | \
 					___PPC_RB(b))
 #define PPC_MSGSYNC		stringify_in_c(.long PPC_INST_MSGSYNC)

commit 93b2d3cf3733b4060d3623161551f51ea1ab5499
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Wed Aug 30 14:12:24 2017 +1000

    powerpc: Correct instruction code for xxlor instruction
    
    The instruction code for xxlor that commit 0016a4cf5582 ("powerpc:
    Emulate most Book I instructions in emulate_step()", 2010-06-15)
    added is actually the code for xxlnor.  It is used in get_vsr()
    and put_vsr() and the effect of the error is that if emulate_step
    is used to emulate a VSX load or store from any register other
    than vsr0, the bitwise complement of the correct value will be
    loaded or stored.  This corrects the error.
    
    Fixes: 0016a4cf5582 ("powerpc: Emulate most Book I instructions in emulate_step()")
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index b5e1b51b8ba9..3dd8a6e43bb2 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -262,7 +262,7 @@
 #define PPC_INST_TLBSRX_DOT		0x7c0006a5
 #define PPC_INST_VPMSUMW		0x10000488
 #define PPC_INST_VPMSUMD		0x100004c8
-#define PPC_INST_XXLOR			0xf0000510
+#define PPC_INST_XXLOR			0xf0000490
 #define PPC_INST_XXSWAPD		0xf0000250
 #define PPC_INST_XVCPSGNDP		0xf0000780
 #define PPC_INST_TRECHKPT		0x7c0007dd

commit 2392c8c8c0450293625dbef19ff5e206fb7b6749
Author: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
Date:   Mon Aug 28 23:23:40 2017 -0700

    powerpc/powernv/vas: Define copy/paste interfaces
    
    Define interfaces (wrappers) to the 'copy' and 'paste'
    instructions (which are new in PowerISA 3.0). These are intended to be
    used to by NX driver(s) to submit Coprocessor Request Blocks (CRBs) to
    the NX hardware engines.
    
    Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 041ba15aa2b9..b5e1b51b8ba9 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -418,6 +418,8 @@
 					___PPC_RB(b))
 #define PPC_MSGCLRP(b)		stringify_in_c(.long PPC_INST_MSGCLRP | \
 					___PPC_RB(b))
+#define PPC_PASTE(a, b)		stringify_in_c(.long PPC_INST_PASTE | \
+					___PPC_RA(a) | ___PPC_RB(b))
 #define PPC_POPCNTB(a, s)	stringify_in_c(.long PPC_INST_POPCNTB | \
 					__PPC_RA(a) | __PPC_RS(s))
 #define PPC_POPCNTD(a, s)	stringify_in_c(.long PPC_INST_POPCNTD | \

commit e66ca3db5917f4bcad039d3a3df9f1003797c249
Author: Matt Brown <matthew.brown.dev@gmail.com>
Date:   Fri Aug 4 11:12:18 2017 +1000

    powerpc/powernv: Use darn instruction for get_random_seed() on Power9
    
    This adds powernv_get_random_darn() which utilises the darn instruction,
    introduced in ISA v3.0/POWER9.
    
    The darn instruction can potentially return an error, which is supported
    by the get_random_seed() API, in normal usage if we see an error we just
    return that to the caller.
    
    However when detecting whether darn is functional at boot we try up to
    10 times, before deciding that darn doesn't work and failing the
    registration of get_random_seed(). That way an intermittent failure
    at boot doesn't deprive the system of randomness until the next reboot.
    
    Signed-off-by: Matt Brown <matthew.brown.dev@gmail.com>
    [mpe: Move init into a function, tweak change log]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index fa9ebaead91e..041ba15aa2b9 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -193,6 +193,7 @@
 #define PPC_INST_CLRBHRB		0x7c00035c
 #define PPC_INST_COPY			0x7c20060c
 #define PPC_INST_CP_ABORT		0x7c00068c
+#define PPC_INST_DARN			0x7c0005e6
 #define PPC_INST_DCBA			0x7c0005ec
 #define PPC_INST_DCBA_MASK		0xfc0007fe
 #define PPC_INST_DCBAL			0x7c2005ec
@@ -395,6 +396,9 @@
 #define	PPC_CP_ABORT		stringify_in_c(.long PPC_INST_CP_ABORT)
 #define	PPC_COPY(a, b)		stringify_in_c(.long PPC_INST_COPY | \
 					___PPC_RA(a) | ___PPC_RB(b))
+#define PPC_DARN(t, l)		stringify_in_c(.long PPC_INST_DARN |  \
+						___PPC_RT(t)	   |  \
+						(((l) & 0x3) << 16))
 #define	PPC_DCBAL(a, b)		stringify_in_c(.long PPC_INST_DCBAL | \
 					__PPC_RA(a) | __PPC_RB(b))
 #define	PPC_DCBZL(a, b)		stringify_in_c(.long PPC_INST_DCBZL | \

commit d691b7e7d1b5186eae62fd32adee65d3316bfdf6
Merge: b59eea554f57 1e0fc9d1eb2b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jul 7 13:55:45 2017 -0700

    Merge tag 'powerpc-4.13-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Highlights include:
    
       - Support for STRICT_KERNEL_RWX on 64-bit server CPUs.
    
       - Platform support for FSP2 (476fpe) board
    
       - Enable ZONE_DEVICE on 64-bit server CPUs.
    
       - Generic & powerpc spin loop primitives to optimise busy waiting
    
       - Convert VDSO update function to use new update_vsyscall() interface
    
       - Optimisations to hypercall/syscall/context-switch paths
    
       - Improvements to the CPU idle code on Power8 and Power9.
    
      As well as many other fixes and improvements.
    
      Thanks to: Akshay Adiga, Andrew Donnellan, Andrew Jeffery, Anshuman
      Khandual, Anton Blanchard, Balbir Singh, Benjamin Herrenschmidt,
      Christophe Leroy, Christophe Lombard, Colin Ian King, Dan Carpenter,
      Gautham R. Shenoy, Hari Bathini, Ian Munsie, Ivan Mikhaylov, Javier
      Martinez Canillas, Madhavan Srinivasan, Masahiro Yamada, Matt Brown,
      Michael Neuling, Michal Suchanek, Murilo Opsfelder Araujo, Naveen N.
      Rao, Nicholas Piggin, Oliver O'Halloran, Paul Mackerras, Pavel Machek,
      Russell Currey, Santosh Sivaraj, Stephen Rothwell, Thiago Jung
      Bauermann, Yang Li"
    
    * tag 'powerpc-4.13-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (158 commits)
      powerpc/Kconfig: Enable STRICT_KERNEL_RWX for some configs
      powerpc/mm/radix: Implement STRICT_RWX/mark_rodata_ro() for Radix
      powerpc/mm/hash: Implement mark_rodata_ro() for hash
      powerpc/vmlinux.lds: Align __init_begin to 16M
      powerpc/lib/code-patching: Use alternate map for patch_instruction()
      powerpc/xmon: Add patch_instruction() support for xmon
      powerpc/kprobes/optprobes: Use patch_instruction()
      powerpc/kprobes: Move kprobes over to patch_instruction()
      powerpc/mm/radix: Fix execute permissions for interrupt_vectors
      powerpc/pseries: Fix passing of pp0 in updatepp() and updateboltedpp()
      powerpc/64s: Blacklist rtas entry/exit from kprobes
      powerpc/64s: Blacklist functions invoked on a trap
      powerpc/64s: Un-blacklist system_call() from kprobes
      powerpc/64s: Move system_call() symbol to just after setting MSR_EE
      powerpc/64s: Blacklist system_call() and system_call_common() from kprobes
      powerpc/64s: Convert .L__replay_interrupt_return to a local label
      powerpc64/elfv1: Only dereference function descriptor for non-text symbols
      cxl: Export library to support IBM XSL
      powerpc/dts: Use #include "..." to include local DT
      powerpc/perf/hv-24x7: Aggregate result elements on POWER9 SMT8
      ...

commit a9af97aa0a12c30178dd7ad9af8887d5b9c4647b
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Jun 13 23:05:48 2017 +1000

    powerpc/64s: msgclr when handling doorbell exceptions from system reset
    
    msgsnd doorbell exceptions are cleared when the doorbell interrupt is
    taken. However if a doorbell exception causes a system reset interrupt
    wake from power saving state, the message is not cleared. Processing
    the doorbell from the system reset interrupt requires msgclr to avoid
    taking the exception again.
    
    Testing this plus the previous wakup direct patch gives:
    
                                    original         wakeup direct     msgclr
    Different threads, same core:   315k/s           264k/s            345k/s
    Different cores:                235k/s           242k/s            242k/s
    
    Net speedup is +10% for same core, and +3% for different core.
    
    Reviewed-by: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 3b6bbf5a8683..4e2cf719c9b2 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -220,6 +220,7 @@
 #define PPC_INST_MSGCLR			0x7c0001dc
 #define PPC_INST_MSGSYNC		0x7c0006ec
 #define PPC_INST_MSGSNDP		0x7c00011c
+#define PPC_INST_MSGCLRP		0x7c00015c
 #define PPC_INST_MTTMR			0x7c0003dc
 #define PPC_INST_NOP			0x60000000
 #define PPC_INST_PASTE			0x7c20070d
@@ -409,6 +410,8 @@
 					___PPC_RB(b))
 #define PPC_MSGSNDP(b)		stringify_in_c(.long PPC_INST_MSGSNDP | \
 					___PPC_RB(b))
+#define PPC_MSGCLRP(b)		stringify_in_c(.long PPC_INST_MSGCLRP | \
+					___PPC_RB(b))
 #define PPC_POPCNTB(a, s)	stringify_in_c(.long PPC_INST_POPCNTB | \
 					__PPC_RA(a) | __PPC_RS(s))
 #define PPC_POPCNTD(a, s)	stringify_in_c(.long PPC_INST_POPCNTD | \

commit 579006944e0d675361e987c646b83d2d1725966c
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Tue May 16 16:41:20 2017 +1000

    KVM: PPC: Book3S HV: Virtualize doorbell facility on POWER9
    
    On POWER9, we no longer have the restriction that we had on POWER8
    where all threads in a core have to be in the same partition, so
    the CPU threads are now independent.  However, we still want to be
    able to run guests with a virtual SMT topology, if only to allow
    migration of guests from POWER8 systems to POWER9.
    
    A guest that has a virtual SMT mode greater than 1 will expect to
    be able to use the doorbell facility; it will expect the msgsndp
    and msgclrp instructions to work appropriately and to be able to read
    sensible values from the TIR (thread identification register) and
    DPDES (directed privileged doorbell exception status) special-purpose
    registers.  However, since each CPU thread is a separate sub-processor
    in POWER9, these instructions and registers can only be used within
    a single CPU thread.
    
    In order for these instructions to appear to act correctly according
    to the guest's virtual SMT mode, we have to trap and emulate them.
    We cause them to trap by clearing the HFSCR_MSGP bit in the HFSCR
    register.  The emulation is triggered by the hypervisor facility
    unavailable interrupt that occurs when the guest uses them.
    
    To cause a doorbell interrupt to occur within the guest, we set the
    DPDES register to 1.  If the guest has interrupts enabled, the CPU
    will generate a doorbell interrupt and clear the DPDES register in
    hardware.  The DPDES hardware register for the guest is saved in the
    vcpu->arch.vcore->dpdes field.  Since this gets written by the guest
    exit code, other VCPUs wishing to cause a doorbell interrupt don't
    write that field directly, but instead set a vcpu->arch.doorbell_request
    flag.  This is consumed and set to 0 by the guest entry code, which
    then sets DPDES to 1.
    
    Emulating reads of the DPDES register is somewhat involved, because
    it requires reading the doorbell pending interrupt status of all of the
    VCPU threads in the virtual core, and if any of those VCPUs are
    running, their doorbell status is only up-to-date in the hardware
    DPDES registers of the CPUs where they are running.  In order to get
    a reasonable approximation of the current doorbell status, we send
    those CPUs an IPI, causing an exit from the guest which will update
    the vcpu->arch.vcore->dpdes field.  We then use that value in
    constructing the emulated DPDES register value.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 3a8d278e7421..1a9b45198c06 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -103,6 +103,8 @@
 #define OP_31_XOP_STBUX     247
 #define OP_31_XOP_LHZX      279
 #define OP_31_XOP_LHZUX     311
+#define OP_31_XOP_MSGSNDP   142
+#define OP_31_XOP_MSGCLRP   174
 #define OP_31_XOP_MFSPR     339
 #define OP_31_XOP_LWAX      341
 #define OP_31_XOP_LHAX      343

commit 07d2a628bc0008f90754ac7982289f6cb0f46cf8
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Fri Jun 9 01:36:09 2017 +1000

    powerpc/64s: Avoid cpabort in context switch when possible
    
    The ISA v3.0B copy-paste facility only requires cpabort when switching
    to a process that has foreign real addresses mapped (direct access to
    accelerators), to clear a potential copy buffer filled by a previous
    thread. There is no accelerator driver implemented yet, so cpabort can
    be removed. It can be be re-added when a driver is implemented.
    
    POWER9 DD1 requires the copy buffer to always be cleared on context
    switch, but if accelerators are not in use, then an unpaired copy from
    a dummy region is sufficient to clear data out of the copy buffer.
    
    This increases context switch performance by about 5% on POWER9.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 3a8d278e7421..3b6bbf5a8683 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -189,8 +189,7 @@
 /* sorted alphabetically */
 #define PPC_INST_BHRBE			0x7c00025c
 #define PPC_INST_CLRBHRB		0x7c00035c
-#define PPC_INST_COPY			0x7c00060c
-#define PPC_INST_COPY_FIRST		0x7c20060c
+#define PPC_INST_COPY			0x7c20060c
 #define PPC_INST_CP_ABORT		0x7c00068c
 #define PPC_INST_DCBA			0x7c0005ec
 #define PPC_INST_DCBA_MASK		0xfc0007fe
@@ -223,8 +222,7 @@
 #define PPC_INST_MSGSNDP		0x7c00011c
 #define PPC_INST_MTTMR			0x7c0003dc
 #define PPC_INST_NOP			0x60000000
-#define PPC_INST_PASTE			0x7c00070c
-#define PPC_INST_PASTE_LAST		0x7c20070d
+#define PPC_INST_PASTE			0x7c20070d
 #define PPC_INST_POPCNTB		0x7c0000f4
 #define PPC_INST_POPCNTB_MASK		0xfc0007fe
 #define PPC_INST_POPCNTD		0x7c0003f4
@@ -392,6 +390,8 @@
 
 /* Deal with instructions that older assemblers aren't aware of */
 #define	PPC_CP_ABORT		stringify_in_c(.long PPC_INST_CP_ABORT)
+#define	PPC_COPY(a, b)		stringify_in_c(.long PPC_INST_COPY | \
+					___PPC_RA(a) | ___PPC_RB(b))
 #define	PPC_DCBAL(a, b)		stringify_in_c(.long PPC_INST_DCBAL | \
 					__PPC_RA(a) | __PPC_RB(b))
 #define	PPC_DCBZL(a, b)		stringify_in_c(.long PPC_INST_DCBZL | \

commit 2d3e4866dea96b0506395b47bfefb234f2088dac
Merge: 9c6ee01ed5bb 2e5b0bd9cc61
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon May 8 12:37:56 2017 -0700

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull KVM updates from Paolo Bonzini:
     "ARM:
       - HYP mode stub supports kexec/kdump on 32-bit
       - improved PMU support
       - virtual interrupt controller performance improvements
       - support for userspace virtual interrupt controller (slower, but
         necessary for KVM on the weird Broadcom SoCs used by the Raspberry
         Pi 3)
    
      MIPS:
       - basic support for hardware virtualization (ImgTec P5600/P6600/I6400
         and Cavium Octeon III)
    
      PPC:
       - in-kernel acceleration for VFIO
    
      s390:
       - support for guests without storage keys
       - adapter interruption suppression
    
      x86:
       - usual range of nVMX improvements, notably nested EPT support for
         accessed and dirty bits
       - emulation of CPL3 CPUID faulting
    
      generic:
       - first part of VCPU thread request API
       - kvm_stat improvements"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (227 commits)
      kvm: nVMX: Don't validate disabled secondary controls
      KVM: put back #ifndef CONFIG_S390 around kvm_vcpu_kick
      Revert "KVM: Support vCPU-based gfn->hva cache"
      tools/kvm: fix top level makefile
      KVM: x86: don't hold kvm->lock in KVM_SET_GSI_ROUTING
      KVM: Documentation: remove VM mmap documentation
      kvm: nVMX: Remove superfluous VMX instruction fault checks
      KVM: x86: fix emulation of RSM and IRET instructions
      KVM: mark requests that need synchronization
      KVM: return if kvm_vcpu_wake_up() did wake up the VCPU
      KVM: add explicit barrier to kvm_vcpu_kick
      KVM: perform a wake_up in kvm_make_all_cpus_request
      KVM: mark requests that do not need a wakeup
      KVM: remove #ifndef CONFIG_S390 around kvm_vcpu_wake_up
      KVM: x86: always use kvm_make_request instead of set_bit
      KVM: add kvm_{test,clear}_request to replace {test,clear}_bit
      s390: kvm: Cpu model support for msa6, msa7 and msa8
      KVM: x86: remove irq disablement around KVM_SET_CLOCK/KVM_GET_CLOCK
      kvm: better MWAIT emulation for guests
      KVM: x86: virtualize cpuid faulting
      ...

commit 9b5ab0051306033b0b1e83dd72e1f84a0c8dd4bf
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Thu Mar 23 11:55:16 2017 +1100

    KVM: PPC: Add MMIO emulation for remaining floating-point instructions
    
    For completeness, this adds emulation of the lfiwax and lfiwzx
    instructions.  With this, all floating-point load and store instructions
    as of Power ISA V2.07 are emulated.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 738bac164f8b..73f06f4dddc7 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -122,6 +122,8 @@
 #define OP_31_XOP_STFDX     727
 #define OP_31_XOP_STFDUX    759
 #define OP_31_XOP_LHBRX     790
+#define OP_31_XOP_LFIWAX    855
+#define OP_31_XOP_LFIWZX    887
 #define OP_31_XOP_STHBRX    918
 #define OP_31_XOP_STFIWX    983
 

commit ceba57df43a25ede55a96a795703c46022b1d1d0
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Tue Mar 21 15:43:47 2017 +1100

    KVM: PPC: Emulation for more integer loads and stores
    
    This adds emulation for the following integer loads and stores,
    thus enabling them to be used in a guest for accessing emulated
    MMIO locations.
    
    - lhaux
    - lwaux
    - lwzux
    - ldu
    - lwa
    - stdux
    - stwux
    - stdu
    - ldbrx
    - stdbrx
    
    Previously, most of these would cause an emulation failure exit to
    userspace, though ldu and lwa got treated incorrectly as ld, and
    stdu got treated incorrectly as std.
    
    This also tidies up some of the formatting and updates the comment
    listing instructions that still need to be implemented.
    
    With this, all integer loads and stores that are defined in the Power
    ISA v2.07 are emulated, except for those that are permitted to trap
    when used on cache-inhibited or write-through mappings (and which do
    in fact trap on POWER8), that is, lmw/stmw, lswi/stswi, lswx/stswx,
    lq/stq, and l[bhwdq]arx/st[bhwdq]cx.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 94e7df22630e..738bac164f8b 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -96,6 +96,8 @@
 #define OP_31_XOP_LBZX      87
 #define OP_31_XOP_STDX      149
 #define OP_31_XOP_STWX      151
+#define OP_31_XOP_STDUX     181
+#define OP_31_XOP_STWUX     183
 #define OP_31_XOP_STBX      215
 #define OP_31_XOP_LBZUX     119
 #define OP_31_XOP_STBUX     247
@@ -104,13 +106,16 @@
 #define OP_31_XOP_MFSPR     339
 #define OP_31_XOP_LWAX      341
 #define OP_31_XOP_LHAX      343
+#define OP_31_XOP_LWAUX     373
 #define OP_31_XOP_LHAUX     375
 #define OP_31_XOP_STHX      407
 #define OP_31_XOP_STHUX     439
 #define OP_31_XOP_MTSPR     467
 #define OP_31_XOP_DCBI      470
+#define OP_31_XOP_LDBRX     532
 #define OP_31_XOP_LWBRX     534
 #define OP_31_XOP_TLBSYNC   566
+#define OP_31_XOP_STDBRX    660
 #define OP_31_XOP_STWBRX    662
 #define OP_31_XOP_STFSX	    663
 #define OP_31_XOP_STFSUX    695

commit 91242fd1a3eb96e4efe43bdf96c2fcec97fdf4ff
Author: Alexey Kardashevskiy <aik@ozlabs.ru>
Date:   Fri Mar 17 19:31:38 2017 +1100

    KVM: PPC: Add MMIO emulation for stdx (store doubleword indexed)
    
    This adds missing stdx emulation for emulated MMIO accesses by KVM
    guests.  This allows the Mellanox mlx5_core driver from recent kernels
    to work when MMIO emulation is enforced by userspace.
    
    Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 1e37c3c0733a..94e7df22630e 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -94,6 +94,7 @@
 #define OP_31_XOP_TRAP_64   68
 #define OP_31_XOP_DCBF      86
 #define OP_31_XOP_LBZX      87
+#define OP_31_XOP_STDX      149
 #define OP_31_XOP_STWX      151
 #define OP_31_XOP_STBX      215
 #define OP_31_XOP_LBZUX     119

commit 6f63e81bda98cbb549b01faf978884692ded438d
Author: Bin Lu <lblulb@linux.vnet.ibm.com>
Date:   Tue Feb 21 21:12:36 2017 +0800

    KVM: PPC: Book3S: Add MMIO emulation for FP and VSX instructions
    
    This patch provides the MMIO load/store emulation for instructions
    of 'double & vector unsigned char & vector signed char & vector
    unsigned short & vector signed short & vector unsigned int & vector
    signed int & vector double '.
    
    The instructions that this adds emulation for are:
    
    - ldx, ldux, lwax,
    - lfs, lfsx, lfsu, lfsux, lfd, lfdx, lfdu, lfdux,
    - stfs, stfsx, stfsu, stfsux, stfd, stfdx, stfdu, stfdux, stfiwx,
    - lxsdx, lxsspx, lxsiwax, lxsiwzx, lxvd2x, lxvw4x, lxvdsx,
    - stxsdx, stxsspx, stxsiwx, stxvd2x, stxvw4x
    
    [paulus@ozlabs.org - some cleanups, fixes and rework, make it
     compile for Book E, fix build when PR KVM is built in]
    
    Signed-off-by: Bin Lu <lblulb@linux.vnet.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index e7d6d86563ee..1e37c3c0733a 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -86,7 +86,9 @@
 #define OP_TRAP_64 2
 
 #define OP_31_XOP_TRAP      4
+#define OP_31_XOP_LDX       21
 #define OP_31_XOP_LWZX      23
+#define OP_31_XOP_LDUX      53
 #define OP_31_XOP_DCBST     54
 #define OP_31_XOP_LWZUX     55
 #define OP_31_XOP_TRAP_64   68
@@ -99,6 +101,7 @@
 #define OP_31_XOP_LHZX      279
 #define OP_31_XOP_LHZUX     311
 #define OP_31_XOP_MFSPR     339
+#define OP_31_XOP_LWAX      341
 #define OP_31_XOP_LHAX      343
 #define OP_31_XOP_LHAUX     375
 #define OP_31_XOP_STHX      407
@@ -108,10 +111,46 @@
 #define OP_31_XOP_LWBRX     534
 #define OP_31_XOP_TLBSYNC   566
 #define OP_31_XOP_STWBRX    662
+#define OP_31_XOP_STFSX	    663
+#define OP_31_XOP_STFSUX    695
+#define OP_31_XOP_STFDX     727
+#define OP_31_XOP_STFDUX    759
 #define OP_31_XOP_LHBRX     790
 #define OP_31_XOP_STHBRX    918
+#define OP_31_XOP_STFIWX    983
+
+/* VSX Scalar Load Instructions */
+#define OP_31_XOP_LXSDX         588
+#define OP_31_XOP_LXSSPX        524
+#define OP_31_XOP_LXSIWAX       76
+#define OP_31_XOP_LXSIWZX       12
+
+/* VSX Scalar Store Instructions */
+#define OP_31_XOP_STXSDX        716
+#define OP_31_XOP_STXSSPX       652
+#define OP_31_XOP_STXSIWX       140
+
+/* VSX Vector Load Instructions */
+#define OP_31_XOP_LXVD2X        844
+#define OP_31_XOP_LXVW4X        780
+
+/* VSX Vector Load and Splat Instruction */
+#define OP_31_XOP_LXVDSX        332
+
+/* VSX Vector Store Instructions */
+#define OP_31_XOP_STXVD2X       972
+#define OP_31_XOP_STXVW4X       908
+
+#define OP_31_XOP_LFSX          535
+#define OP_31_XOP_LFSUX         567
+#define OP_31_XOP_LFDX          599
+#define OP_31_XOP_LFDUX		631
 
 #define OP_LWZ  32
+#define OP_STFS 52
+#define OP_STFSU 53
+#define OP_STFD 54
+#define OP_STFDU 55
 #define OP_LD   58
 #define OP_LWZU 33
 #define OP_LBZ  34
@@ -127,6 +166,17 @@
 #define OP_LHAU 43
 #define OP_STH  44
 #define OP_STHU 45
+#define OP_LMW  46
+#define OP_STMW 47
+#define OP_LFS  48
+#define OP_LFSU 49
+#define OP_LFD  50
+#define OP_LFDU 51
+#define OP_STFS 52
+#define OP_STFSU 53
+#define OP_STFD  54
+#define OP_STFDU 55
+#define OP_LQ    56
 
 /* sorted alphabetically */
 #define PPC_INST_BHRBE			0x7c00025c

commit 6b3edefefa6752df57ad636f26baa1b0a502ddab
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Thu Apr 13 20:16:24 2017 +1000

    powerpc/powernv: POWER9 support for msgsnd/doorbell IPI
    
    POWER9 requires msgsync for receiver-side synchronization, and a DD1
    workaround restricts IPIs to core-local.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Drop no longer needed asm feature macro changes]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index e7d6d86563ee..142d78d645f4 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -161,6 +161,7 @@
 #define PPC_INST_MFTMR			0x7c0002dc
 #define PPC_INST_MSGSND			0x7c00019c
 #define PPC_INST_MSGCLR			0x7c0001dc
+#define PPC_INST_MSGSYNC		0x7c0006ec
 #define PPC_INST_MSGSNDP		0x7c00011c
 #define PPC_INST_MTTMR			0x7c0003dc
 #define PPC_INST_NOP			0x60000000
@@ -345,6 +346,7 @@
 					___PPC_RB(b) | __PPC_EH(eh))
 #define PPC_MSGSND(b)		stringify_in_c(.long PPC_INST_MSGSND | \
 					___PPC_RB(b))
+#define PPC_MSGSYNC		stringify_in_c(.long PPC_INST_MSGSYNC)
 #define PPC_MSGCLR(b)		stringify_in_c(.long PPC_INST_MSGCLR | \
 					___PPC_RB(b))
 #define PPC_MSGSNDP(b)		stringify_in_c(.long PPC_INST_MSGSNDP | \

commit 4ceae137bdab2232e57b2e6fd5631a22a0160938
Author: Ravi Bangoria <ravi.bangoria@linux.vnet.ibm.com>
Date:   Tue Feb 14 14:46:43 2017 +0530

    powerpc: emulate_step() tests for load/store instructions
    
    Add new selftest that test emulate_step for Normal, Floating Point,
    Vector and Vector Scalar - load/store instructions. Test should run
    at boot time if CONFIG_KPROBES_SANITY_TEST and CONFIG_PPC64 is set.
    
    Sample log:
    
      emulate_step_test: ld             : PASS
      emulate_step_test: lwz            : PASS
      emulate_step_test: lwzx           : PASS
      emulate_step_test: std            : PASS
      emulate_step_test: ldarx / stdcx. : PASS
      emulate_step_test: lfsx           : PASS
      emulate_step_test: stfsx          : PASS
      emulate_step_test: lfdx           : PASS
      emulate_step_test: stfdx          : PASS
      emulate_step_test: lvx            : PASS
      emulate_step_test: stvx           : PASS
      emulate_step_test: lxvd2x         : PASS
      emulate_step_test: stxvd2x        : PASS
    
    Signed-off-by: Ravi Bangoria <ravi.bangoria@linux.vnet.ibm.com>
    [mpe: Drop start/complete lines, make it all __init]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index d99bd442aacb..e7d6d86563ee 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -284,6 +284,13 @@
 #define PPC_INST_BRANCH_COND		0x40800000
 #define PPC_INST_LBZCIX			0x7c0006aa
 #define PPC_INST_STBCIX			0x7c0007aa
+#define PPC_INST_LWZX			0x7c00002e
+#define PPC_INST_LFSX			0x7c00042e
+#define PPC_INST_STFSX			0x7c00052e
+#define PPC_INST_LFDX			0x7c0004ae
+#define PPC_INST_STFDX			0x7c0005ae
+#define PPC_INST_LVX			0x7c0000ce
+#define PPC_INST_STVX			0x7c0001ce
 
 /* macros to insert fields into opcodes */
 #define ___PPC_RA(a)	(((a) & 0x1f) << 16)

commit c233f5979b3dbb39a5b2473b5fcaf58baec8f1bd
Author: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
Date:   Wed Feb 8 14:27:29 2017 +0530

    powerpc/bpf: Introduce __PPC_SH64()
    
    Introduce __PPC_SH64() as a 64-bit variant to encode shift field in some
    of the shift and rotate instructions operating on double-words. Convert
    some of the BPF instruction macros to use the same.
    
    Signed-off-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index c4ced1d01d57..d99bd442aacb 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -306,6 +306,7 @@
 #define __PPC_WC(w)	(((w) & 0x3) << 21)
 #define __PPC_WS(w)	(((w) & 0x1f) << 11)
 #define __PPC_SH(s)	__PPC_WS(s)
+#define __PPC_SH64(s)	(__PPC_SH(s) | (((s) & 0x20) >> 4))
 #define __PPC_MB(s)	(((s) & 0x1f) << 6)
 #define __PPC_ME(s)	(((s) & 0x1f) << 1)
 #define __PPC_MB64(s)	(__PPC_MB(s) | ((s) & 0x20))

commit 178f358208ceb8b38e5cff3f815e0db4a6a70a07
Author: Anton Blanchard <anton@samba.org>
Date:   Thu Jan 19 14:19:10 2017 +1100

    powerpc: Ignore reserved field in DCSR and PVR reads and writes
    
    IBM bit 31 (for the rest of us - bit 0) is a reserved field in the
    instruction definition of mtspr and mfspr. Hardware is encouraged to
    (and does) ignore it.
    
    As a result, if userspace executes an mtspr DSCR with the reserved bit
    set, we get a DSCR facility unavailable exception. The kernel fails to
    match against the expected value/mask, and we silently return to
    userspace to try and re-execute the same mtspr DSCR instruction. We
    loop forever until the process is killed.
    
    We should do something here, and it seems mirroring what hardware does
    is the better option vs killing the process. While here, relax the
    matching of mfspr PVR too.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index c56ea8c84abb..c4ced1d01d57 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -157,7 +157,7 @@
 #define PPC_INST_MCRXR			0x7c000400
 #define PPC_INST_MCRXR_MASK		0xfc0007fe
 #define PPC_INST_MFSPR_PVR		0x7c1f42a6
-#define PPC_INST_MFSPR_PVR_MASK		0xfc1fffff
+#define PPC_INST_MFSPR_PVR_MASK		0xfc1ffffe
 #define PPC_INST_MFTMR			0x7c0002dc
 #define PPC_INST_MSGSND			0x7c00019c
 #define PPC_INST_MSGCLR			0x7c0001dc
@@ -174,13 +174,13 @@
 #define PPC_INST_RFDI			0x4c00004e
 #define PPC_INST_RFMCI			0x4c00004c
 #define PPC_INST_MFSPR_DSCR		0x7c1102a6
-#define PPC_INST_MFSPR_DSCR_MASK	0xfc1fffff
+#define PPC_INST_MFSPR_DSCR_MASK	0xfc1ffffe
 #define PPC_INST_MTSPR_DSCR		0x7c1103a6
-#define PPC_INST_MTSPR_DSCR_MASK	0xfc1fffff
+#define PPC_INST_MTSPR_DSCR_MASK	0xfc1ffffe
 #define PPC_INST_MFSPR_DSCR_USER	0x7c0302a6
-#define PPC_INST_MFSPR_DSCR_USER_MASK	0xfc1fffff
+#define PPC_INST_MFSPR_DSCR_USER_MASK	0xfc1ffffe
 #define PPC_INST_MTSPR_DSCR_USER	0x7c0303a6
-#define PPC_INST_MTSPR_DSCR_USER_MASK	0xfc1fffff
+#define PPC_INST_MTSPR_DSCR_USER_MASK	0xfc1ffffe
 #define PPC_INST_MFVSRD			0x7c000066
 #define PPC_INST_MTVSRD			0x7c000166
 #define PPC_INST_SLBFEE			0x7c0007a7

commit 96ed1fe511a8b4948e53f3bad431d8737e8f231f
Author: Michael Neuling <mikey@neuling.org>
Date:   Fri Nov 18 14:08:56 2016 +1100

    powerpc/mm/radix: Invalidate ERAT on tlbiel for POWER9 DD1
    
    On POWER9 DD1, when we do a local TLB invalidate we also need to explicitly
    invalidate the ERAT.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 0132831b3081..c56ea8c84abb 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -460,5 +460,6 @@
 
 #define PPC_SLBIA(IH)	stringify_in_c(.long PPC_INST_SLBIA | \
 				       ((IH & 0x7) << 21))
+#define PPC_INVALIDATE_ERAT	PPC_SLBIA(7)
 
 #endif /* _ASM_POWERPC_PPC_OPCODE_H */

commit 065397a969a0f80624598c5030c2551abbd986fd
Merge: 8321564a11bb e0b80f00bb96
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Oct 11 20:07:56 2016 +1100

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/scottwood/linux into next
    
    Freescale updates from Scott:
    
    "Highlights include qbman support (a prerequisite for datapath drivers
    such as ethernet), a PCI DMA fix+improvement, reset handler changes, more
    8xx optimizations, and some cleanups and fixes."

commit ce0761419faefbe9e450749ccc879ff88843af12
Author: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
Date:   Sat Sep 24 02:05:01 2016 +0530

    powerpc/bpf: Implement support for tail calls
    
    Tail calls allow JIT'ed eBPF programs to call into other JIT'ed eBPF
    programs. This can be achieved either by:
    (1) retaining the stack setup by the first eBPF program and having all
    subsequent eBPF programs re-using it, or,
    (2) by unwinding/tearing down the stack and having each eBPF program
    deal with its own stack as it sees fit.
    
    To ensure that this does not create loops, there is a limit to how many
    tail calls can be done (currently 32). This requires the JIT'ed code to
    maintain a count of the number of tail calls done so far.
    
    Approach (1) is simple, but requires every eBPF program to have (almost)
    the same prologue/epilogue, regardless of whether they need it. This is
    inefficient for small eBPF programs which may not sometimes need a
    prologue at all. As such, to minimize impact of tail call
    implementation, we use approach (2) here which needs each eBPF program
    in the chain to use its own prologue/epilogue. This is not ideal when
    many tail calls are involved and when all the eBPF programs in the chain
    have similar prologue/epilogue. However, the impact is restricted to
    programs that do tail calls. Individual eBPF programs are not affected.
    
    We maintain the tail call count in a fixed location on the stack and
    updated tail call count values are passed in through this. The very
    first eBPF program in a chain sets this up to 0 (the first 2
    instructions). Subsequent tail calls skip the first two eBPF JIT
    instructions to maintain the count. For programs that don't do tail
    calls themselves, the first two instructions are NOPs.
    
    Signed-off-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 127ebf5862b4..54ff8ce7fa96 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -236,6 +236,7 @@
 #define PPC_INST_STWU			0x94000000
 #define PPC_INST_MFLR			0x7c0802a6
 #define PPC_INST_MTLR			0x7c0803a6
+#define PPC_INST_MTCTR			0x7c0903a6
 #define PPC_INST_CMPWI			0x2c000000
 #define PPC_INST_CMPDI			0x2c200000
 #define PPC_INST_CMPW			0x7c000000
@@ -250,6 +251,7 @@
 #define PPC_INST_SUB			0x7c000050
 #define PPC_INST_BLR			0x4e800020
 #define PPC_INST_BLRL			0x4e800021
+#define PPC_INST_BCTR			0x4e800420
 #define PPC_INST_MULLD			0x7c0001d2
 #define PPC_INST_MULLW			0x7c0001d6
 #define PPC_INST_MULHWU			0x7c000016

commit ddc6cd0d70a6f958b2c01758ee53279d36db2234
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Tue May 17 14:01:39 2016 +0200

    powerpc32: Use instruction symbolic names in check_io_access()
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Scott Wood <oss@buserror.net>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 127ebf5862b4..e6d2c33781fc 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -152,6 +152,7 @@
 #define PPC_INST_LWSYNC			0x7c2004ac
 #define PPC_INST_SYNC			0x7c0004ac
 #define PPC_INST_SYNC_MASK		0xfc0007fe
+#define PPC_INST_ISYNC			0x4c00012c
 #define PPC_INST_LXVD2X			0x7c000698
 #define PPC_INST_MCRXR			0x7c000400
 #define PPC_INST_MCRXR_MASK		0xfc0007fe

commit bad60e6f259a01cf9f29a1ef8d435ab6c60b2de9
Merge: dd0f0cf58af7 719dbb2df78f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jul 30 21:01:36 2016 -0700

    Merge tag 'powerpc-4.8-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "Highlights:
       - PowerNV PCI hotplug support.
       - Lots more Power9 support.
       - eBPF JIT support on ppc64le.
       - Lots of cxl updates.
       - Boot code consolidation.
    
      Bug fixes:
       - Fix spin_unlock_wait() from Boqun Feng
       - Fix stack pointer corruption in __tm_recheckpoint() from Michael
         Neuling
       - Fix multiple bugs in memory_hotplug_max() from Bharata B Rao
       - mm: Ensure "special" zones are empty from Oliver O'Halloran
       - ftrace: Separate the heuristics for checking call sites from
         Michael Ellerman
       - modules: Never restore r2 for a mprofile-kernel style mcount() call
         from Michael Ellerman
       - Fix endianness when reading TCEs from Alexey Kardashevskiy
       - start rtasd before PCI probing from Greg Kurz
       - PCI: rpaphp: Fix slot registration for multiple slots under a PHB
         from Tyrel Datwyler
       - powerpc/mm: Add memory barrier in __hugepte_alloc() from Sukadev
         Bhattiprolu
    
      Cleanups & fixes:
       - Drop support for MPIC in pseries from Rashmica Gupta
       - Define and use PPC64_ELF_ABI_v2/v1 from Michael Ellerman
       - Remove unused symbols in asm-offsets.c from Rashmica Gupta
       - Fix SRIOV not building without EEH enabled from Russell Currey
       - Remove kretprobe_trampoline_holder from Thiago Jung Bauermann
       - Reduce log level of PCI I/O space warning from Benjamin
         Herrenschmidt
       - Add array bounds checking to crash_shutdown_handlers from Suraj
         Jitindar Singh
       - Avoid -maltivec when using clang integrated assembler from Anton
         Blanchard
       - Fix array overrun in ppc_rtas() syscall from Andrew Donnellan
       - Fix error return value in cmm_mem_going_offline() from Rasmus
         Villemoes
       - export cpu_to_core_id() from Mauricio Faria de Oliveira
       - Remove old symbols from defconfigs from Andrew Donnellan
       - Update obsolete comments in setup_32.c about entry conditions from
         Benjamin Herrenschmidt
       - Add comment explaining the purpose of setup_kdump_trampoline() from
         Benjamin Herrenschmidt
       - Merge the RELOCATABLE config entries for ppc32 and ppc64 from Kevin
         Hao
       - Remove RELOCATABLE_PPC32 from Kevin Hao
       - Fix .long's in tlb-radix.c to more meaningful from Balbir Singh
    
      Minor cleanups & fixes:
       - Andrew Donnellan, Anna-Maria Gleixner, Anton Blanchard, Benjamin
         Herrenschmidt, Bharata B Rao, Christophe Leroy, Colin Ian King,
         Geliang Tang, Greg Kurz, Madhavan Srinivasan, Michael Ellerman,
         Michael Ellerman, Stephen Rothwell, Stewart Smith.
    
      Freescale updates from Scott:
       - "Highlights include more 8xx optimizations, device tree updates,
         and MVME7100 support."
    
      PowerNV PCI hotplug from Gavin Shan:
       - PCI: Add pcibios_setup_bridge()
       - Override pcibios_setup_bridge()
       - Remove PCI_RESET_DELAY_US
       - Move pnv_pci_ioda_setup_opal_tce_kill() around
       - Increase PE# capacity
       - Allocate PE# in reverse order
       - Create PEs in pcibios_setup_bridge()
       - Setup PE for root bus
       - Extend PCI bridge resources
       - Make pnv_ioda_deconfigure_pe() visible
       - Dynamically release PE
       - Update bridge windows on PCI plug
       - Delay populating pdn
       - Support PCI slot ID
       - Use PCI slot reset infrastructure
       - Introduce pnv_pci_get_slot_id()
       - Functions to get/set PCI slot state
       - PCI/hotplug: PowerPC PowerNV PCI hotplug driver
       - Print correct PHB type names
    
      Power9 idle support from Shreyas B. Prabhu:
       - set power_save func after the idle states are initialized
       - Use PNV_THREAD_WINKLE macro while requesting for winkle
       - make hypervisor state restore a function
       - Rename idle_power7.S to idle_book3s.S
       - Rename reusable idle functions to hardware agnostic names
       - Make pnv_powersave_common more generic
       - abstraction for saving SPRs before entering deep idle states
       - Add platform support for stop instruction
       - cpuidle/powernv: Use CPUIDLE_STATE_MAX instead of MAX_POWERNV_IDLE_STATES
       - cpuidle/powernv: cleanup cpuidle-powernv.c
       - cpuidle/powernv: Add support for POWER ISA v3 idle states
       - Use deepest stop state when cpu is offlined
    
      Power9 PMU from Madhavan Srinivasan:
       - factor out power8 pmu macros and defines
       - factor out power8 pmu functions
       - factor out power8 __init_pmu code
       - Add power9 event list macros for generic and cache events
       - Power9 PMU support
       - Export Power9 generic and cache events to sysfs
    
      Power9 preliminary interrupt & PCI support from Benjamin Herrenschmidt:
       - Add XICS emulation APIs
       - Move a few exception common handlers to make room
       - Add support for HV virtualization interrupts
       - Add mechanism to force a replay of interrupts
       - Add ICP OPAL backend
       - Discover IODA3 PHBs
       - pci: Remove obsolete SW invalidate
       - opal: Add real mode call wrappers
       - Rename TCE invalidation calls
       - Remove SWINV constants and obsolete TCE code
       - Rework accessing the TCE invalidate register
       - Fallback to OPAL for TCE invalidations
       - Use the device-tree to get available range of M64's
       - Check status of a PHB before using it
       - pci: Don't try to allocate resources that will be reassigned
    
      Other Power9:
       - Send SIGBUS on unaligned copy and paste from Chris Smart
       - Large Decrementer support from Oliver O'Halloran
       - Load Monitor Register Support from Jack Miller
    
      Performance improvements from Anton Blanchard:
       - Avoid load hit store in __giveup_fpu() and __giveup_altivec()
       - Avoid load hit store in setup_sigcontext()
       - Remove assembly versions of strcpy, strcat, strlen and strcmp
       - Align hot loops of some string functions
    
      eBPF JIT from Naveen N. Rao:
       - Fix/enhance 32-bit Load Immediate implementation
       - Optimize 64-bit Immediate loads
       - Introduce rotate immediate instructions
       - A few cleanups
       - Isolate classic BPF JIT specifics into a separate header
       - Implement JIT compiler for extended BPF
    
      Operator Panel driver from Suraj Jitindar Singh:
       - devicetree/bindings: Add binding for operator panel on FSP machines
       - Add inline function to get rc from an ASYNC_COMP opal_msg
       - Add driver for operator panel on FSP machines
    
      Sparse fixes from Daniel Axtens:
       - make some things static
       - Introduce asm-prototypes.h
       - Include headers containing prototypes
       - Use #ifdef __BIG_ENDIAN__ #else for REG_BYTE
       - kvm: Clarify __user annotations
       - Pass endianness to sparse
       - Make ppc_md.{halt, restart} __noreturn
    
      MM fixes & cleanups from Aneesh Kumar K.V:
       - radix: Update LPCR HR bit as per ISA
       - use _raw variant of page table accessors
       - Compile out radix related functions if RADIX_MMU is disabled
       - Clear top 16 bits of va only on older cpus
       - Print formation regarding the the MMU mode
       - hash: Update SDR1 size encoding as documented in ISA 3.0
       - radix: Update PID switch sequence
       - radix: Update machine call back to support new HCALL.
       - radix: Add LPID based tlb flush helpers
       - radix: Add a kernel command line to disable radix
       - Cleanup LPCR defines
    
      Boot code consolidation from Benjamin Herrenschmidt:
       - Move epapr_paravirt_early_init() to early_init_devtree()
       - cell: Don't use flat device-tree after boot
       - ge_imp3a: Don't use the flat device-tree after boot
       - mpc85xx_ds: Don't use the flat device-tree after boot
       - mpc85xx_rdb: Don't use the flat device-tree after boot
       - Don't test for machine type in rtas_initialize()
       - Don't test for machine type in smp_setup_cpu_maps()
       - dt: Add of_device_compatible_match()
       - Factor do_feature_fixup calls
       - Move 64-bit feature fixup earlier
       - Move 64-bit memory reserves to setup_arch()
       - Use a cachable DART
       - Move FW feature probing out of pseries probe()
       - Put exception configuration in a common place
       - Remove early allocation of the SMU command buffer
       - Move MMU backend selection out of platform code
       - pasemi: Remove IOBMAP allocation from platform probe()
       - mm/hash: Don't use machine_is() early during boot
       - Don't test for machine type to detect HEA special case
       - pmac: Remove spurrious machine type test
       - Move hash table ops to a separate structure
       - Ensure that ppc_md is empty before probing for machine type
       - Move 64-bit probe_machine() to later in the boot process
       - Move 32-bit probe() machine to later in the boot process
       - Get rid of ppc_md.init_early()
       - Move the boot time info banner to a separate function
       - Move setting of {i,d}cache_bsize to initialize_cache_info()
       - Move the content of setup_system() to setup_arch()
       - Move cache info inits to a separate function
       - Re-order the call to smp_setup_cpu_maps()
       - Re-order setup_panic()
       - Make a few boot functions __init
       - Merge 32-bit and 64-bit setup_arch()
    
      Other new features:
       - tty/hvc: Use IRQF_SHARED for OPAL hvc consoles from Sam Mendoza-Jonas
       - tty/hvc: Use opal irqchip interface if available from Sam Mendoza-Jonas
       - powerpc: Add module autoloading based on CPU features from Alastair D'Silva
       - crypto: vmx - Convert to CPU feature based module autoloading from Alastair D'Silva
       - Wake up kopald polling thread before waiting for events from Benjamin Herrenschmidt
       - xmon: Dump ISA 2.06 SPRs from Michael Ellerman
       - xmon: Dump ISA 2.07 SPRs from Michael Ellerman
       - Add a parameter to disable 1TB segs from Oliver O'Halloran
       - powerpc/boot: Add OPAL console to epapr wrappers from Oliver O'Halloran
       - Assign fixed PHB number based on device-tree properties from Guilherme G. Piccoli
       - pseries: Add pseries hotplug workqueue from John Allen
       - pseries: Add support for hotplug interrupt source from John Allen
       - pseries: Use kernel hotplug queue for PowerVM hotplug events from John Allen
       - pseries: Move property cloning into its own routine from Nathan Fontenot
       - pseries: Dynamic add entires to associativity lookup array from Nathan Fontenot
       - pseries: Auto-online hotplugged memory from Nathan Fontenot
       - pseries: Remove call to memblock_add() from Nathan Fontenot
    
      cxl:
       - Add set and get private data to context struct from Michael Neuling
       - make base more explicitly non-modular from Paul Gortmaker
       - Use for_each_compatible_node() macro from Wei Yongjun
       - Frederic Barrat
       - Abstract the differences between the PSL and XSL
       - Make vPHB device node match adapter's
       - Philippe Bergheaud
       - Add mechanism for delivering AFU driver specific events
       - Ignore CAPI adapters misplaced in switched slots
       - Refine slice error debug messages
       - Andrew Donnellan
       - static-ify variables to fix sparse warnings
       - PCI/hotplug: pnv_php: export symbols and move struct types needed by cxl
       - PCI/hotplug: pnv_php: handle OPAL_PCI_SLOT_OFFLINE power state
       - Add cxl_check_and_switch_mode() API to switch bi-modal cards
       - remove dead Kconfig options
       - fix potential NULL dereference in free_adapter()
       - Ian Munsie
       - Update process element after allocating interrupts
       - Add support for CAPP DMA mode
       - Fix allowing bogus AFU descriptors with 0 maximum processes
       - Fix allocating a minimum of 2 pages for the SPA
       - Fix bug where AFU disable operation had no effect
       - Workaround XSL bug that does not clear the RA bit after a reset
       - Fix NULL pointer dereference on kernel contexts with no AFU interrupts
       - powerpc/powernv: Split cxl code out into a separate file
       - Add cxl_slot_is_supported API
       - Enable bus mastering for devices using CAPP DMA mode
       - Move cxl_afu_get / cxl_afu_put to base
       - Allow a default context to be associated with an external pci_dev
       - Do not create vPHB if there are no AFU configuration records
       - powerpc/powernv: Add support for the cxl kernel api on the real phb
       - Add support for using the kernel API with a real PHB
       - Add kernel APIs to get & set the max irqs per context
       - Add preliminary workaround for CX4 interrupt limitation
       - Add support for interrupts on the Mellanox CX4
       - Workaround PE=0 hardware limitation in Mellanox CX4
       - powerpc/powernv: Fix pci-cxl.c build when CONFIG_MODULES=n
    
      selftests:
       - Test unaligned copy and paste from Chris Smart
       - Load Monitor Register Tests from Jack Miller
       - Cyril Bur
       - exec() with suspended transaction
       - Use signed long to read perf_event_paranoid
       - Fix usage message in context_switch
       - Fix generation of vector instructions/types in context_switch
       - Michael Ellerman
       - Use "Delta" rather than "Error" in normal output
       - Import Anton's mmap & futex micro benchmarks
       - Add a test for PROT_SAO"
    
    * tag 'powerpc-4.8-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (263 commits)
      powerpc/mm: Parenthesise IS_ENABLED() in if condition
      tty/hvc: Use opal irqchip interface if available
      tty/hvc: Use IRQF_SHARED for OPAL hvc consoles
      selftests/powerpc: exec() with suspended transaction
      powerpc: Improve comment explaining why we modify VRSAVE
      powerpc/mm: Drop unused externs for hpte_init_beat[_v3]()
      powerpc/mm: Rename hpte_init_lpar() and move the fallback to a header
      powerpc/mm: Fix build break when PPC_NATIVE=n
      crypto: vmx - Convert to CPU feature based module autoloading
      powerpc: Add module autoloading based on CPU features
      powerpc/powernv/ioda: Fix endianness when reading TCEs
      powerpc/mm: Add memory barrier in __hugepte_alloc()
      powerpc/modules: Never restore r2 for a mprofile-kernel style mcount() call
      powerpc/ftrace: Separate the heuristics for checking call sites
      powerpc: Merge 32-bit and 64-bit setup_arch()
      powerpc/64: Make a few boot functions __init
      powerpc: Re-order setup_panic()
      powerpc: Re-order the call to smp_setup_cpu_maps()
      powerpc/32: Move cache info inits to a separate function
      powerpc/64: Move the content of setup_system() to setup_arch()
      ...

commit 09cf5bcb0c93550db87f738b6012d97dbf73beb7
Author: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
Date:   Wed Jul 13 15:05:27 2016 +0530

    powerpc/mm/radix: Update PID switch sequence
    
    Update the PID switch as per ISA doc. slbia is needed in radix to
    invalidate any implementation specific lookaside information.
    We use the .long format due to build errors with the below compiler
    version.
    
    gcc (Ubuntu 5.3.1-14ubuntu2.1) 5.3.1 20160413
    GNU assembler (GNU Binutils for Ubuntu) 2.26
    
    CC      arch/powerpc/mm//mmu_context_book3s64.o
    {standard input}: Assembler messages:
    {standard input}:506: Error: junk at end of line: `0x7'
    scripts/Makefile.build:291: recipe for target 'arch/powerpc/mm//mmu_context_book3s64.o' failed
    make[1]: *** [arch/powerpc/mm//mmu_context_book3s64.o] Error 1
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 1c18a43e0d65..5ecfb04fec98 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -181,6 +181,7 @@
 #define PPC_INST_MTSPR_DSCR_USER	0x7c0303a6
 #define PPC_INST_MTSPR_DSCR_USER_MASK	0xfc1fffff
 #define PPC_INST_SLBFEE			0x7c0007a7
+#define PPC_INST_SLBIA			0x7c0003e4
 
 #define PPC_INST_STRING			0x7c00042a
 #define PPC_INST_STRING_MASK		0xfc0007fe
@@ -442,5 +443,7 @@
 					       ___PPC_RA(a) |		\
 					       ___PPC_RB(b))
 
+#define PPC_SLBIA(IH)	stringify_in_c(.long PPC_INST_SLBIA | \
+				       ((IH & 0x7) << 21))
 
 #endif /* _ASM_POWERPC_PPC_OPCODE_H */

commit 8cd6d3c23e226ec6cb8825e1aa6a391ebda71c72
Author: Balbir Singh <bsingharora@gmail.com>
Date:   Wed Jul 13 15:05:20 2016 +0530

    powerpc/mm: Fix .long's in tlb-radix.c to more meaningful
    
    The .longs with the shifts are harder to read, use more meaningful names
    for the opcodes. PPC_TLBIE_5 is introduced for the 5 opcode variation of
    the instruction due to an existing op-code for the 2 opcode variant.
    
    Signed-off-by: Balbir Singh <bsingharora@gmail.com>
    Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 81657a1e03fe..1c18a43e0d65 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -190,6 +190,7 @@
 #define PPC_INST_STSWX			0x7c00052a
 #define PPC_INST_STXVD2X		0x7c000798
 #define PPC_INST_TLBIE			0x7c000264
+#define PPC_INST_TLBIEL			0x7c000224
 #define PPC_INST_TLBILX			0x7c000024
 #define PPC_INST_WAIT			0x7c00007c
 #define PPC_INST_TLBIVAX		0x7c000624
@@ -281,6 +282,9 @@
 #define ___PPC_RB(b)	(((b) & 0x1f) << 11)
 #define ___PPC_RS(s)	(((s) & 0x1f) << 21)
 #define ___PPC_RT(t)	___PPC_RS(t)
+#define ___PPC_R(r)	(((r) & 0x1) << 16)
+#define ___PPC_PRS(prs)	(((prs) & 0x1) << 17)
+#define ___PPC_RIC(ric)	(((ric) & 0x3) << 18)
 #define __PPC_RA(a)	___PPC_RA(__REG_##a)
 #define __PPC_RA0(a)	___PPC_RA(__REGA0_##a)
 #define __PPC_RB(b)	___PPC_RB(__REG_##b)
@@ -347,6 +351,16 @@
 					__PPC_WC(w))
 #define PPC_TLBIE(lp,a) 	stringify_in_c(.long PPC_INST_TLBIE | \
 					       ___PPC_RB(a) | ___PPC_RS(lp))
+#define	PPC_TLBIE_5(rb,rs,ric,prs,r) \
+				stringify_in_c(.long PPC_INST_TLBIE | \
+					___PPC_RB(rb) | ___PPC_RS(rs) | \
+					___PPC_RIC(ric) | ___PPC_PRS(prs) | \
+					___PPC_R(r))
+#define	PPC_TLBIEL(rb,rs,ric,prs,r) \
+				stringify_in_c(.long PPC_INST_TLBIEL | \
+					___PPC_RB(rb) | ___PPC_RS(rs) | \
+					___PPC_RIC(ric) | ___PPC_PRS(prs) | \
+					___PPC_R(r))
 #define PPC_TLBSRX_DOT(a,b)	stringify_in_c(.long PPC_INST_TLBSRX_DOT | \
 					__PPC_RA0(a) | __PPC_RB(b))
 #define PPC_TLBIVAX(a,b)	stringify_in_c(.long PPC_INST_TLBIVAX | \

commit bcef83a00dc44ee25ff4d6e078cf6432ddf74dec
Author: Shreyas B. Prabhu <shreyas@linux.vnet.ibm.com>
Date:   Fri Jul 8 11:50:49 2016 +0530

    powerpc/powernv: Add platform support for stop instruction
    
    POWER ISA v3 defines a new idle processor core mechanism. In summary,
     a) new instruction named stop is added. This instruction replaces
            instructions like nap, sleep, rvwinkle.
     b) new per thread SPR named Processor Stop Status and Control Register
            (PSSCR) is added which controls the behavior of stop instruction.
    
    PSSCR layout:
    ----------------------------------------------------------
    | PLS | /// | SD | ESL | EC | PSLL | /// | TR | MTL | RL |
    ----------------------------------------------------------
    0      4     41   42    43   44     48    54   56    60
    
    PSSCR key fields:
            Bits 0:3  - Power-Saving Level Status. This field indicates the lowest
            power-saving state the thread entered since stop instruction was last
            executed.
    
            Bit 42 - Enable State Loss
            0 - No state is lost irrespective of other fields
            1 - Allows state loss
    
            Bits 44:47 - Power-Saving Level Limit
            This limits the power-saving level that can be entered into.
    
            Bits 60:63 - Requested Level
            Used to specify which power-saving level must be entered on executing
            stop instruction
    
    This patch adds support for stop instruction and PSSCR handling.
    
    Reviewed-by: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
    Signed-off-by: Shreyas B. Prabhu <shreyas@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 9de9df14a8d9..81657a1e03fe 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -205,6 +205,8 @@
 #define PPC_INST_SLEEP			0x4c0003a4
 #define PPC_INST_WINKLE			0x4c0003e4
 
+#define PPC_INST_STOP			0x4c0002e4
+
 /* A2 specific instructions */
 #define PPC_INST_ERATWE			0x7c0001a6
 #define PPC_INST_ERATRE			0x7c000166
@@ -394,6 +396,8 @@
 #define PPC_SLEEP		stringify_in_c(.long PPC_INST_SLEEP)
 #define PPC_WINKLE		stringify_in_c(.long PPC_INST_WINKLE)
 
+#define PPC_STOP		stringify_in_c(.long PPC_INST_STOP)
+
 /* BHRB instructions */
 #define PPC_CLRBHRB		stringify_in_c(.long PPC_INST_CLRBHRB)
 #define PPC_MFBHRBE(r, n)	stringify_in_c(.long PPC_INST_BHRBE | \

commit 6dd7a82cc54ebd2936763befd3dcd4beb727a704
Author: Anton Blanchard <anton@samba.org>
Date:   Fri Jul 1 08:19:45 2016 +1000

    crypto: powerpc - Add POWER8 optimised crc32c
    
    Use the vector polynomial multiply-sum instructions in POWER8 to
    speed up crc32c.
    
    This is just over 41x faster than the slice-by-8 method that it
    replaces. Measurements on a 4.1 GHz POWER8 show it sustaining
    52 GiB/sec.
    
    A simple btrfs write performance test:
    
        dd if=/dev/zero of=/mnt/tmpfile bs=1M count=4096
        sync
    
    is over 3.7x faster.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 1d035c1cc889..49cd8760aa7c 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -174,6 +174,8 @@
 #define PPC_INST_MFSPR_DSCR_USER_MASK	0xfc1fffff
 #define PPC_INST_MTSPR_DSCR_USER	0x7c0303a6
 #define PPC_INST_MTSPR_DSCR_USER_MASK	0xfc1fffff
+#define PPC_INST_MFVSRD			0x7c000066
+#define PPC_INST_MTVSRD			0x7c000166
 #define PPC_INST_SLBFEE			0x7c0007a7
 
 #define PPC_INST_STRING			0x7c00042a
@@ -188,6 +190,8 @@
 #define PPC_INST_WAIT			0x7c00007c
 #define PPC_INST_TLBIVAX		0x7c000624
 #define PPC_INST_TLBSRX_DOT		0x7c0006a5
+#define PPC_INST_VPMSUMW		0x10000488
+#define PPC_INST_VPMSUMD		0x100004c8
 #define PPC_INST_XXLOR			0xf0000510
 #define PPC_INST_XXSWAPD		0xf0000250
 #define PPC_INST_XVCPSGNDP		0xf0000780
@@ -359,6 +363,14 @@
 					       VSX_XX1((s), a, b))
 #define LXVD2X(s, a, b)		stringify_in_c(.long PPC_INST_LXVD2X | \
 					       VSX_XX1((s), a, b))
+#define MFVRD(a, t)		stringify_in_c(.long PPC_INST_MFVSRD | \
+					       VSX_XX1((t)+32, a, R0))
+#define MTVRD(t, a)		stringify_in_c(.long PPC_INST_MTVSRD | \
+					       VSX_XX1((t)+32, a, R0))
+#define VPMSUMW(t, a, b)	stringify_in_c(.long PPC_INST_VPMSUMW | \
+					       VSX_XX3((t), a, b))
+#define VPMSUMD(t, a, b)	stringify_in_c(.long PPC_INST_VPMSUMD | \
+					       VSX_XX3((t), a, b))
 #define XXLOR(t, a, b)		stringify_in_c(.long PPC_INST_XXLOR | \
 					       VSX_XX3((t), a, b))
 #define XXSWAPD(t, a)		stringify_in_c(.long PPC_INST_XXSWAPD | \

commit ae26b36f8098c793a754549662771099215904ed
Author: Chris Smart <chris@distroguy.com>
Date:   Fri Jun 17 09:33:45 2016 +1000

    powerpc: Send SIGBUS on unaligned copy and paste
    
    Calling ISA 3.0 instructions copy, copy_first, paste and paste_last
    generates an alignment fault when copying or pasting unaligned
    data (128 byte). We catch this and send SIGBUS to the userspace
    process that caused it.
    
    We do not emulate these because paste may contain additional metadata
    when pasting to a co-processor and paste_last is the synchronisation
    point for preceding copy/paste sequences.
    
    Thanks to Michael Neuling <mikey@neuling.org> for his help.
    
    Signed-off-by: Chris Smart <chris@distroguy.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 6a77d1304d4d..9de9df14a8d9 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -131,6 +131,8 @@
 /* sorted alphabetically */
 #define PPC_INST_BHRBE			0x7c00025c
 #define PPC_INST_CLRBHRB		0x7c00035c
+#define PPC_INST_COPY			0x7c00060c
+#define PPC_INST_COPY_FIRST		0x7c20060c
 #define PPC_INST_CP_ABORT		0x7c00068c
 #define PPC_INST_DCBA			0x7c0005ec
 #define PPC_INST_DCBA_MASK		0xfc0007fe
@@ -161,6 +163,8 @@
 #define PPC_INST_MSGSNDP		0x7c00011c
 #define PPC_INST_MTTMR			0x7c0003dc
 #define PPC_INST_NOP			0x60000000
+#define PPC_INST_PASTE			0x7c00070c
+#define PPC_INST_PASTE_LAST		0x7c20070d
 #define PPC_INST_POPCNTB		0x7c0000f4
 #define PPC_INST_POPCNTB_MASK		0xfc0007fe
 #define PPC_INST_POPCNTD		0x7c0003f4

commit 156d0e290e969caba25f1851c52417c14d141b24
Author: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
Date:   Wed Jun 22 21:55:07 2016 +0530

    powerpc/ebpf/jit: Implement JIT compiler for extended BPF
    
    PPC64 eBPF JIT compiler.
    
    Enable with:
      echo 1 > /proc/sys/net/core/bpf_jit_enable
    or
      echo 2 > /proc/sys/net/core/bpf_jit_enable
    
    ... to see the generated JIT code. This can further be processed with
    tools/net/bpf_jit_disasm.
    
    With CONFIG_TEST_BPF=m and 'modprobe test_bpf':
    
     test_bpf: Summary: 305 PASSED, 0 FAILED, [297/297 JIT'ed]
    
    ... on both ppc64 BE and LE.
    
    The details of the approach are documented through various comments in
    the code.
    
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index fd8d640a8e28..6a77d1304d4d 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -142,9 +142,11 @@
 #define PPC_INST_ISEL			0x7c00001e
 #define PPC_INST_ISEL_MASK		0xfc00003e
 #define PPC_INST_LDARX			0x7c0000a8
+#define PPC_INST_STDCX			0x7c0001ad
 #define PPC_INST_LSWI			0x7c0004aa
 #define PPC_INST_LSWX			0x7c00042a
 #define PPC_INST_LWARX			0x7c000028
+#define PPC_INST_STWCX			0x7c00012d
 #define PPC_INST_LWSYNC			0x7c2004ac
 #define PPC_INST_SYNC			0x7c0004ac
 #define PPC_INST_SYNC_MASK		0xfc0007fe
@@ -211,8 +213,11 @@
 #define PPC_INST_LBZ			0x88000000
 #define PPC_INST_LD			0xe8000000
 #define PPC_INST_LHZ			0xa0000000
-#define PPC_INST_LHBRX			0x7c00062c
 #define PPC_INST_LWZ			0x80000000
+#define PPC_INST_LHBRX			0x7c00062c
+#define PPC_INST_LDBRX			0x7c000428
+#define PPC_INST_STB			0x98000000
+#define PPC_INST_STH			0xb0000000
 #define PPC_INST_STD			0xf8000000
 #define PPC_INST_STDU			0xf8000001
 #define PPC_INST_STW			0x90000000
@@ -221,22 +226,34 @@
 #define PPC_INST_MTLR			0x7c0803a6
 #define PPC_INST_CMPWI			0x2c000000
 #define PPC_INST_CMPDI			0x2c200000
+#define PPC_INST_CMPW			0x7c000000
+#define PPC_INST_CMPD			0x7c200000
 #define PPC_INST_CMPLW			0x7c000040
+#define PPC_INST_CMPLD			0x7c200040
 #define PPC_INST_CMPLWI			0x28000000
+#define PPC_INST_CMPLDI			0x28200000
 #define PPC_INST_ADDI			0x38000000
 #define PPC_INST_ADDIS			0x3c000000
 #define PPC_INST_ADD			0x7c000214
 #define PPC_INST_SUB			0x7c000050
 #define PPC_INST_BLR			0x4e800020
 #define PPC_INST_BLRL			0x4e800021
+#define PPC_INST_MULLD			0x7c0001d2
 #define PPC_INST_MULLW			0x7c0001d6
 #define PPC_INST_MULHWU			0x7c000016
 #define PPC_INST_MULLI			0x1c000000
 #define PPC_INST_DIVWU			0x7c000396
+#define PPC_INST_DIVD			0x7c0003d2
 #define PPC_INST_RLWINM			0x54000000
+#define PPC_INST_RLWIMI			0x50000000
+#define PPC_INST_RLDICL			0x78000000
 #define PPC_INST_RLDICR			0x78000004
 #define PPC_INST_SLW			0x7c000030
+#define PPC_INST_SLD			0x7c000036
 #define PPC_INST_SRW			0x7c000430
+#define PPC_INST_SRD			0x7c000436
+#define PPC_INST_SRAD			0x7c000634
+#define PPC_INST_SRADI			0x7c000674
 #define PPC_INST_AND			0x7c000038
 #define PPC_INST_ANDDOT			0x7c000039
 #define PPC_INST_OR			0x7c000378
@@ -247,6 +264,7 @@
 #define PPC_INST_XORI			0x68000000
 #define PPC_INST_XORIS			0x6c000000
 #define PPC_INST_NEG			0x7c0000d0
+#define PPC_INST_EXTSW			0x7c0007b4
 #define PPC_INST_BRANCH			0x48000000
 #define PPC_INST_BRANCH_COND		0x40800000
 #define PPC_INST_LBZCIX			0x7c0006aa

commit 277285b854c666308cf6cb92a696748f976d6f64
Author: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
Date:   Wed Jun 22 21:55:04 2016 +0530

    powerpc/bpf/jit: Introduce rotate immediate instructions
    
    Since we will be using the rotate immediate instructions for extended
    BPF JIT, let's introduce macros for the same. And since the shift
    immediate operations use the rotate immediate instructions, let's redo
    those macros to use the newly introduced instructions.
    
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 1d035c1cc889..fd8d640a8e28 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -272,6 +272,8 @@
 #define __PPC_SH(s)	__PPC_WS(s)
 #define __PPC_MB(s)	(((s) & 0x1f) << 6)
 #define __PPC_ME(s)	(((s) & 0x1f) << 1)
+#define __PPC_MB64(s)	(__PPC_MB(s) | ((s) & 0x20))
+#define __PPC_ME64(s)	__PPC_MB64(s)
 #define __PPC_BI(s)	(((s) & 0x1f) << 16)
 #define __PPC_CT(t)	(((t) & 0x0f) << 21)
 

commit 8a649045e75a4b9091ea9d041f5bb599f8ec1f8a
Author: Chris Smart <chris@distroguy.com>
Date:   Tue Apr 26 10:28:50 2016 +1000

    powerpc: Add support for userspace P9 copy paste
    
    The copy paste facility introduced in POWER9 provides an optimised
    mechanism for a userspace application to copy a cacheline. This is
    provided by a pair of instructions, copy and paste, while a third,
    cp_abort (copy paste abort), provides a clean up of the state in case of
    a failure.
    
    The copy instruction will read a 128 byte cacheline and store it in an
    internal buffer. The subsequent paste instruction will store this
    internal buffer to memory and set a CR field if the paste succeeds.
    
    Since the state of the copy paste buffer is internal (and not
    architecturally visible), in the unlikely event of a context switch, the
    state cannot be stored and the paste should therefore fail.
    
    The cp_abort instruction exists to fail and clean up any such
    interrupted copy paste sequence and is to be called by the kernel as
    part of the context switch. Doing so prevents data from a preceding copy
    in one process leaking into the paste of another.
    
    This code enables use of the cp_abort instruction if a supported
    processor is detected.
    
    NOTE: this is for userspace only, not in kernel, and does not deal
    with KVM guests.
    
    Patch created with much assistance from Michael Neuling
    <mikey@neuling.org>
    
    Signed-off-by: Chris Smart <chris@distroguy.com>
    Reviewed-by: Cyril Bur <cyrilbur@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 7ab04fc59e24..1d035c1cc889 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -131,6 +131,7 @@
 /* sorted alphabetically */
 #define PPC_INST_BHRBE			0x7c00025c
 #define PPC_INST_CLRBHRB		0x7c00035c
+#define PPC_INST_CP_ABORT		0x7c00068c
 #define PPC_INST_DCBA			0x7c0005ec
 #define PPC_INST_DCBA_MASK		0xfc0007fe
 #define PPC_INST_DCBAL			0x7c2005ec
@@ -285,6 +286,7 @@
 #endif
 
 /* Deal with instructions that older assemblers aren't aware of */
+#define	PPC_CP_ABORT		stringify_in_c(.long PPC_INST_CP_ABORT)
 #define	PPC_DCBAL(a, b)		stringify_in_c(.long PPC_INST_DCBAL | \
 					__PPC_RA(a) | __PPC_RB(b))
 #define	PPC_DCBZL(a, b)		stringify_in_c(.long PPC_INST_DCBZL | \

commit 23316316c1af0677a041c81f3ad6efb9dc470b33
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Oct 21 16:03:14 2015 +1100

    powerpc: Revert "Use the POWER8 Micro Partition Prefetch Engine in KVM HV on POWER8"
    
    This reverts commit 9678cdaae939 ("Use the POWER8 Micro Partition
    Prefetch Engine in KVM HV on POWER8") because the original commit had
    multiple, partly self-cancelling bugs, that could cause occasional
    memory corruption.
    
    In fact the logmpp instruction was incorrectly using register r0 as the
    source of the buffer address and operation code, and depending on what
    was in r0, it would either do nothing or corrupt the 64k page pointed to
    by r0.
    
    The logmpp instruction encoding and the operation code definitions could
    be corrected, but then there is the problem that there is no clearly
    defined way to know when the hardware has finished writing to the
    buffer.
    
    The original commit attempted to work around this by aborting the
    write-out before starting the prefetch, but this is ineffective in the
    case where the virtual core is now executing on a different physical
    core from the one where the write-out was initiated.
    
    These problems plus advice from the hardware designers not to use the
    function (since the measured performance improvement from using the
    feature was actually mostly negative), mean that reverting the code is
    the best option.
    
    Fixes: 9678cdaae939 ("Use the POWER8 Micro Partition Prefetch Engine in KVM HV on POWER8")
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 790f5d1d9a46..7ab04fc59e24 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -141,7 +141,6 @@
 #define PPC_INST_ISEL			0x7c00001e
 #define PPC_INST_ISEL_MASK		0xfc00003e
 #define PPC_INST_LDARX			0x7c0000a8
-#define PPC_INST_LOGMPP			0x7c0007e4
 #define PPC_INST_LSWI			0x7c0004aa
 #define PPC_INST_LSWX			0x7c00042a
 #define PPC_INST_LWARX			0x7c000028
@@ -285,20 +284,6 @@
 #define __PPC_EH(eh)	0
 #endif
 
-/* POWER8 Micro Partition Prefetch (MPP) parameters */
-/* Address mask is common for LOGMPP instruction and MPPR SPR */
-#define PPC_MPPE_ADDRESS_MASK 0xffffffffc000ULL
-
-/* Bits 60 and 61 of MPP SPR should be set to one of the following */
-/* Aborting the fetch is indeed setting 00 in the table size bits */
-#define PPC_MPPR_FETCH_ABORT (0x0ULL << 60)
-#define PPC_MPPR_FETCH_WHOLE_TABLE (0x2ULL << 60)
-
-/* Bits 54 and 55 of register for LOGMPP instruction should be set to: */
-#define PPC_LOGMPP_LOG_L2 (0x02ULL << 54)
-#define PPC_LOGMPP_LOG_L2L3 (0x01ULL << 54)
-#define PPC_LOGMPP_LOG_ABORT (0x03ULL << 54)
-
 /* Deal with instructions that older assemblers aren't aware of */
 #define	PPC_DCBAL(a, b)		stringify_in_c(.long PPC_INST_DCBAL | \
 					__PPC_RA(a) | __PPC_RB(b))
@@ -307,8 +292,6 @@
 #define PPC_LDARX(t, a, b, eh)	stringify_in_c(.long PPC_INST_LDARX | \
 					___PPC_RT(t) | ___PPC_RA(a) | \
 					___PPC_RB(b) | __PPC_EH(eh))
-#define PPC_LOGMPP(b)		stringify_in_c(.long PPC_INST_LOGMPP | \
-					__PPC_RB(b))
 #define PPC_LWARX(t, a, b, eh)	stringify_in_c(.long PPC_INST_LWARX | \
 					___PPC_RT(t) | ___PPC_RA(a) | \
 					___PPC_RB(b) | __PPC_EH(eh))

commit 5358a96341a7fba23cbf0eaf01ce1ab4d738fc90
Author: Thomas Huth <thuth@redhat.com>
Date:   Fri May 22 09:25:02 2015 +0200

    KVM: PPC: Fix warnings from sparse
    
    When compiling the KVM code for POWER with "make C=1", sparse
    complains about functions missing proper prototypes and a 64-bit
    constant missing the ULL prefix. Let's fix this by making the
    functions static or by including the proper header with the
    prototypes, and by appending a ULL prefix to the constant
    PPC_MPPE_ADDRESS_MASK.
    
    Signed-off-by: Thomas Huth <thuth@redhat.com>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 8452335661a5..790f5d1d9a46 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -287,7 +287,7 @@
 
 /* POWER8 Micro Partition Prefetch (MPP) parameters */
 /* Address mask is common for LOGMPP instruction and MPPR SPR */
-#define PPC_MPPE_ADDRESS_MASK 0xffffffffc000
+#define PPC_MPPE_ADDRESS_MASK 0xffffffffc000ULL
 
 /* Bits 60 and 61 of MPP SPR should be set to one of the following */
 /* Aborting the fetch is indeed setting 00 in the table size bits */

commit edc424f8cd84bbae530d8a9f86caf1923606fb24
Author: Dan Streetman <ddstreet@ieee.org>
Date:   Thu May 7 13:49:13 2015 -0400

    powerpc: Add ICSWX instruction
    
    Add the asm ICSWX and ICSWEPX opcodes.  Add definitions for the
    Coprocessor Request structures needed to use the icswx calls to
    coprocessors.  Add icswx() function to perform the ICSWX asm
    using the provided Coprocessor Command Word value and
    Coprocessor Request Block structure.
    
    This is required for communication with the NX-842 coprocessor on
    a PowerNV system.
    
    Signed-off-by: Dan Streetman <ddstreet@ieee.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 5c93f691b495..8452335661a5 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -136,6 +136,8 @@
 #define PPC_INST_DCBAL			0x7c2005ec
 #define PPC_INST_DCBZL			0x7c2007ec
 #define PPC_INST_ICBT			0x7c00002c
+#define PPC_INST_ICSWX			0x7c00032d
+#define PPC_INST_ICSWEPX		0x7c00076d
 #define PPC_INST_ISEL			0x7c00001e
 #define PPC_INST_ISEL_MASK		0xfc00003e
 #define PPC_INST_LDARX			0x7c0000a8
@@ -403,4 +405,15 @@
 #define MFTMR(tmr, r)		stringify_in_c(.long PPC_INST_MFTMR | \
 					       TMRN(tmr) | ___PPC_RT(r))
 
+/* Coprocessor instructions */
+#define PPC_ICSWX(s, a, b)	stringify_in_c(.long PPC_INST_ICSWX |	\
+					       ___PPC_RS(s) |		\
+					       ___PPC_RA(a) |		\
+					       ___PPC_RB(b))
+#define PPC_ICSWEPX(s, a, b)	stringify_in_c(.long PPC_INST_ICSWEPX | \
+					       ___PPC_RS(s) |		\
+					       ___PPC_RA(a) |		\
+					       ___PPC_RB(b))
+
+
 #endif /* _ASM_POWERPC_PPC_OPCODE_H */

commit 9f0d34bc344889c2e6c593bd949d7ab821f0f4a5
Merge: e4a924f5768c 0a4812798fae
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Apr 2 16:16:53 2015 -0400

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Conflicts:
            drivers/net/usb/asix_common.c
            drivers/net/usb/sr9800.c
            drivers/net/usb/usbnet.c
            include/linux/usb/usbnet.h
            net/ipv4/tcp_ipv4.c
            net/ipv6/tcp_ipv6.c
    
    The TCP conflicts were overlapping changes.  In 'net' we added a
    READ_ONCE() to the socket cached RX route read, whilst in 'net-next'
    Eric Dumazet touched the surrounding code dealing with how mini
    sockets are handled.
    
    With USB, it's a case of the same bug fix first going into net-next
    and then I cherry picked it back into net.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 755563bc79c764c90b9f44db5e4fe6c556d3440c
Author: Paul Mackerras <paulus@samba.org>
Date:   Thu Mar 19 19:29:01 2015 +1100

    powerpc/powernv: Fixes for hypervisor doorbell handling
    
    Since we can now use hypervisor doorbells for host IPIs, this makes
    sure we clear the host IPI flag when taking a doorbell interrupt, and
    clears any pending doorbell IPI in pnv_smp_cpu_kill_self() (as we
    already do for IPIs sent via the XICS interrupt controller).  Otherwise
    if there did happen to be a leftover pending doorbell interrupt for
    an offline CPU thread for any reason, it would prevent that thread from
    going into a power-saving mode; it would instead keep waking up because
    of the interrupt.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 03cd858a401c..4cbe23af400a 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -153,6 +153,7 @@
 #define PPC_INST_MFSPR_PVR_MASK		0xfc1fffff
 #define PPC_INST_MFTMR			0x7c0002dc
 #define PPC_INST_MSGSND			0x7c00019c
+#define PPC_INST_MSGCLR			0x7c0001dc
 #define PPC_INST_MSGSNDP		0x7c00011c
 #define PPC_INST_MTTMR			0x7c0003dc
 #define PPC_INST_NOP			0x60000000
@@ -309,6 +310,8 @@
 					___PPC_RB(b) | __PPC_EH(eh))
 #define PPC_MSGSND(b)		stringify_in_c(.long PPC_INST_MSGSND | \
 					___PPC_RB(b))
+#define PPC_MSGCLR(b)		stringify_in_c(.long PPC_INST_MSGCLR | \
+					___PPC_RB(b))
 #define PPC_MSGSNDP(b)		stringify_in_c(.long PPC_INST_MSGSNDP | \
 					___PPC_RB(b))
 #define PPC_POPCNTB(a, s)	stringify_in_c(.long PPC_INST_POPCNTB | \

commit 693930d69c67145dcdf512fe863dbb1095b744b9
Author: Denis Kirjanov <kda@linux-powerpc.org>
Date:   Tue Feb 17 10:04:39 2015 +0300

    ppc: bpf: add reqired opcodes for ppc32
    
    Signed-off-by: Denis Kirjanov <kda@linux-powerpc.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 03cd858a401c..2eadde0b98fb 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -212,6 +212,8 @@
 #define PPC_INST_LWZ			0x80000000
 #define PPC_INST_STD			0xf8000000
 #define PPC_INST_STDU			0xf8000001
+#define PPC_INST_STW			0x90000000
+#define PPC_INST_STWU			0x94000000
 #define PPC_INST_MFLR			0x7c0802a6
 #define PPC_INST_MTLR			0x7c0803a6
 #define PPC_INST_CMPWI			0x2c000000

commit 34b85e3574424beb30e4cd163e6da2e2282d2683
Merge: d5e80b4b1857 d70a54e2d085
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Dec 19 12:57:45 2014 -0800

    Merge tag 'powerpc-3.19-2' of git://git.kernel.org/pub/scm/linux/kernel/git/mpe/linux
    
    Pull second batch of powerpc updates from Michael Ellerman:
     "The highlight is the series that reworks the idle management on
      powernv, which allows us to use deeper idle states on those machines.
    
      There's the fix from Anton for the "BUG at kernel/smpboot.c:134!"
      problem.
    
      An i2c driver for powernv.  This is acked by Wolfram Sang, and he
      asked that we take it through the powerpc tree.
    
      A fix for audit from rgb at Red Hat, acked by Paul Moore who is one of
      the audit maintainers.
    
      A patch from Ben to export the symbol map of our OPAL firmware as a
      sysfs file, so that tools can use it.
    
      Also some CXL fixes, a couple of powerpc perf fixes, a fix for
      smt-enabled, and the patch to add __force to get_user() so we can use
      bitwise types"
    
    * tag 'powerpc-3.19-2' of git://git.kernel.org/pub/scm/linux/kernel/git/mpe/linux:
      powerpc/powernv: Ignore smt-enabled on Power8 and later
      powerpc/uaccess: Allow get_user() with bitwise types
      powerpc/powernv: Expose OPAL firmware symbol map
      powernv/powerpc: Add winkle support for offline cpus
      powernv/cpuidle: Redesign idle states management
      powerpc/powernv: Enable Offline CPUs to enter deep idle states
      powerpc/powernv: Switch off MMU before entering nap/sleep/rvwinkle mode
      i2c: Driver to expose PowerNV platform i2c busses
      powerpc: add little endian flag to syscall_get_arch()
      power/perf/hv-24x7: Use kmem_cache_free() instead of kfree
      powerpc/perf/hv-24x7: Use per-cpu page buffer
      cxl: Unmap MMIO regions when detaching a context
      cxl: Add timeout to process element commands
      cxl: Change contexts_lock to a mutex to fix sleep while atomic bug
      powerpc: Secondary CPUs must set cpu_callin_map after setting active and online

commit 77b54e9f213f76a23736940cf94bcd765fc00f40
Author: Shreyas B. Prabhu <shreyas@linux.vnet.ibm.com>
Date:   Wed Dec 10 00:26:53 2014 +0530

    powernv/powerpc: Add winkle support for offline cpus
    
    Winkle is a deep idle state supported in power8 chips. A core enters
    winkle when all the threads of the core enter winkle. In this state
    power supply to the entire chiplet i.e core, private L2 and private L3
    is turned off. As a result it gives higher powersavings compared to
    sleep.
    
    But entering winkle results in a total hypervisor state loss. Hence the
    hypervisor context has to be preserved before entering winkle and
    restored upon wake up.
    
    Power-on Reset Engine (PORE) is a dedicated engine which is responsible
    for powering on the chiplet during wake up. It can be programmed to
    restore the register contests of a few specific registers. This patch
    uses PORE to restore register state wherever possible and uses stack to
    save and restore rest of the necessary registers.
    
    With hypervisor state restore things fall under three categories-
    per-core state, per-subcore state and per-thread state. To manage this,
    extend the infrastructure introduced for sleep. Mainly we add a paca
    variable subcore_sibling_mask. Using this and the core_idle_state we can
    distingush first thread in core and subcore.
    
    Signed-off-by: Shreyas B. Prabhu <shreyas@linux.vnet.ibm.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: linuxppc-dev@lists.ozlabs.org
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 6f8536208049..5155be7c0d48 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -194,6 +194,7 @@
 
 #define PPC_INST_NAP			0x4c000364
 #define PPC_INST_SLEEP			0x4c0003a4
+#define PPC_INST_WINKLE			0x4c0003e4
 
 /* A2 specific instructions */
 #define PPC_INST_ERATWE			0x7c0001a6
@@ -374,6 +375,7 @@
 
 #define PPC_NAP			stringify_in_c(.long PPC_INST_NAP)
 #define PPC_SLEEP		stringify_in_c(.long PPC_INST_SLEEP)
+#define PPC_WINKLE		stringify_in_c(.long PPC_INST_WINKLE)
 
 /* BHRB instructions */
 #define PPC_CLRBHRB		stringify_in_c(.long PPC_INST_CLRBHRB)

commit 4e2357611323d562fe255d9d71309b3ece30b8cd
Author: Denis Kirjanov <kda@linux-powerpc.org>
Date:   Thu Oct 30 09:12:15 2014 +0300

    PPC: bpf_jit_comp: add SKF_AD_PKTTYPE instruction
    
    Add BPF extension SKF_AD_PKTTYPE to ppc JIT to load
    skb->pkt_type field.
    
    Before:
    [   88.262622] test_bpf: #11 LD_IND_NET 86 97 99 PASS
    [   88.265740] test_bpf: #12 LD_PKTTYPE 109 107 PASS
    
    After:
    [   80.605964] test_bpf: #11 LD_IND_NET 44 40 39 PASS
    [   80.607370] test_bpf: #12 LD_PKTTYPE 9 9 PASS
    
    CC: Alexei Starovoitov<alexei.starovoitov@gmail.com>
    CC: Michael Ellerman<mpe@ellerman.id.au>
    Cc: Matt Evans <matt@ozlabs.org>
    Signed-off-by: Denis Kirjanov <kda@linux-powerpc.org>
    
    v2: Added test rusults
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 6f8536208049..1a5287759fc8 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -204,6 +204,7 @@
 #define PPC_INST_ERATSX_DOT		0x7c000127
 
 /* Misc instructions for BPF compiler */
+#define PPC_INST_LBZ			0x88000000
 #define PPC_INST_LD			0xe8000000
 #define PPC_INST_LHZ			0xa0000000
 #define PPC_INST_LHBRX			0x7c00062c

commit 66bb0aa077978dbb76e6283531eb3cc7a878de38
Merge: e306e3be1cbe c77dcacb3975
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Aug 7 11:35:30 2014 -0700

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull second round of KVM changes from Paolo Bonzini:
     "Here are the PPC and ARM changes for KVM, which I separated because
      they had small conflicts (respectively within KVM documentation, and
      with 3.16-rc changes).  Since they were all within the subsystem, I
      took care of them.
    
      Stephen Rothwell reported some snags in PPC builds, but they are all
      fixed now; the latest linux-next report was clean.
    
      New features for ARM include:
       - KVM VGIC v2 emulation on GICv3 hardware
       - Big-Endian support for arm/arm64 (guest and host)
       - Debug Architecture support for arm64 (arm32 is on Christoffer's todo list)
    
      And for PPC:
       - Book3S: Good number of LE host fixes, enable HV on LE
       - Book3S HV: Add in-guest debug support
    
      This release drops support for KVM on the PPC440.  As a result, the
      PPC merge removes more lines than it adds.  :)
    
      I also included an x86 change, since Davidlohr tied it to an
      independent bug report and the reporter quickly provided a Tested-by;
      there was no reason to wait for -rc2"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (122 commits)
      KVM: Move more code under CONFIG_HAVE_KVM_IRQFD
      KVM: nVMX: fix "acknowledge interrupt on exit" when APICv is in use
      KVM: nVMX: Fix nested vmexit ack intr before load vmcs01
      KVM: PPC: Enable IRQFD support for the XICS interrupt controller
      KVM: Give IRQFD its own separate enabling Kconfig option
      KVM: Move irq notifier implementation into eventfd.c
      KVM: Move all accesses to kvm::irq_routing into irqchip.c
      KVM: irqchip: Provide and use accessors for irq routing table
      KVM: Don't keep reference to irq routing table in irqfd struct
      KVM: PPC: drop duplicate tracepoint
      arm64: KVM: fix 64bit CP15 VM access for 32bit guests
      KVM: arm64: GICv3: mandate page-aligned GICV region
      arm64: KVM: GICv3: move system register access to msr_s/mrs_s
      KVM: PPC: PR: Handle FSCR feature deselects
      KVM: PPC: HV: Remove generic instruction emulation
      KVM: PPC: BOOKEHV: rename e500hv_spr to bookehv_spr
      KVM: PPC: Remove DCR handling
      KVM: PPC: Expose helper functions for data/inst faults
      KVM: PPC: Separate loadstore emulation from priv emulation
      KVM: PPC: Handle magic page in kvmppc_ld/st
      ...

commit e16c8765533a155ebd3d7c36fc80440a03bbf46a
Author: Andy Fleming <afleming@freescale.com>
Date:   Thu Dec 8 01:20:27 2011 -0600

    powerpc/e6500: Add support for hardware threads
    
    The general idea is that each core will release all of its
    threads into the secondary thread startup code, which will
    eventually wait in the secondary core holding area, for the
    appropriate bit in the PACA to be set. The kick_cpu function
    pointer will set that bit in the PACA, and thus "release"
    the core/thread to boot. We also need to do a few things that
    U-Boot normally does for CPUs (like enable branch prediction).
    
    Signed-off-by: Andy Fleming <afleming@freescale.com>
    [scottwood@freescale.com: various changes, including only enabling
     threads if Linux wants to kick them]
    Signed-off-by: Scott Wood <scottwood@freescale.com>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 3132bb9365f3..e316dad6ba76 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -150,8 +150,10 @@
 #define PPC_INST_MCRXR_MASK		0xfc0007fe
 #define PPC_INST_MFSPR_PVR		0x7c1f42a6
 #define PPC_INST_MFSPR_PVR_MASK		0xfc1fffff
+#define PPC_INST_MFTMR			0x7c0002dc
 #define PPC_INST_MSGSND			0x7c00019c
 #define PPC_INST_MSGSNDP		0x7c00011c
+#define PPC_INST_MTTMR			0x7c0003dc
 #define PPC_INST_NOP			0x60000000
 #define PPC_INST_POPCNTB		0x7c0000f4
 #define PPC_INST_POPCNTB_MASK		0xfc0007fe
@@ -369,4 +371,11 @@
 #define TABORT(r)		stringify_in_c(.long PPC_INST_TABORT \
 					       | __PPC_RA(r))
 
+/* book3e thread control instructions */
+#define TMRN(x)			((((x) & 0x1f) << 16) | (((x) & 0x3e0) << 6))
+#define MTTMR(tmr, r)		stringify_in_c(.long PPC_INST_MTTMR | \
+					       TMRN(tmr) | ___PPC_RS(r))
+#define MFTMR(tmr, r)		stringify_in_c(.long PPC_INST_MFTMR | \
+					       TMRN(tmr) | ___PPC_RT(r))
+
 #endif /* _ASM_POWERPC_PPC_OPCODE_H */

commit 9678cdaae93932473f696fdea5debf3eee1e1260
Author: Stewart Smith <stewart@linux.vnet.ibm.com>
Date:   Fri Jul 18 14:18:43 2014 +1000

    Use the POWER8 Micro Partition Prefetch Engine in KVM HV on POWER8
    
    The POWER8 processor has a Micro Partition Prefetch Engine, which is
    a fancy way of saying "has way to store and load contents of L2 or
    L2+MRU way of L3 cache". We initiate the storing of the log (list of
    addresses) using the logmpp instruction and start restore by writing
    to a SPR.
    
    The logmpp instruction takes parameters in a single 64bit register:
    - starting address of the table to store log of L2/L2+L3 cache contents
      - 32kb for L2
      - 128kb for L2+L3
      - Aligned relative to maximum size of the table (32kb or 128kb)
    - Log control (no-op, L2 only, L2 and L3, abort logout)
    
    We should abort any ongoing logging before initiating one.
    
    To initiate restore, we write to the MPPR SPR. The format of what to write
    to the SPR is similar to the logmpp instruction parameter:
    - starting address of the table to read from (same alignment requirements)
    - table size (no data, until end of table)
    - prefetch rate (from fastest possible to slower. about every 8, 16, 24 or
      32 cycles)
    
    The idea behind loading and storing the contents of L2/L3 cache is to
    reduce memory latency in a system that is frequently swapping vcores on
    a physical CPU.
    
    The best case scenario for doing this is when some vcores are doing very
    cache heavy workloads. The worst case is when they have about 0 cache hits,
    so we just generate needless memory operations.
    
    This implementation just does L2 store/load. In my benchmarks this proves
    to be useful.
    
    Benchmark 1:
     - 16 core POWER8
     - 3x Ubuntu 14.04LTS guests (LE) with 8 VCPUs each
     - No split core/SMT
     - two guests running sysbench memory test.
       sysbench --test=memory --num-threads=8 run
     - one guest running apache bench (of default HTML page)
       ab -n 490000 -c 400 http://localhost/
    
    This benchmark aims to measure performance of real world application (apache)
    where other guests are cache hot with their own workloads. The sysbench memory
    benchmark does pointer sized writes to a (small) memory buffer in a loop.
    
    In this benchmark with this patch I can see an improvement both in requests
    per second (~5%) and in mean and median response times (again, about 5%).
    The spread of minimum and maximum response times were largely unchanged.
    
    benchmark 2:
     - Same VM config as benchmark 1
     - all three guests running sysbench memory benchmark
    
    This benchmark aims to see if there is a positive or negative affect to this
    cache heavy benchmark. Although due to the nature of the benchmark (stores) we
    may not see a difference in performance, but rather hopefully an improvement
    in consistency of performance (when vcore switched in, don't have to wait
    many times for cachelines to be pulled in)
    
    The results of this benchmark are improvements in consistency of performance
    rather than performance itself. With this patch, the few outliers in duration
    go away and we get more consistent performance in each guest.
    
    benchmark 3:
     - same 3 guests and CPU configuration as benchmark 1 and 2.
     - two idle guests
     - 1 guest running STREAM benchmark
    
    This scenario also saw performance improvement with this patch. On Copy and
    Scale workloads from STREAM, I got 5-6% improvement with this patch. For
    Add and triad, it was around 10% (or more).
    
    benchmark 4:
     - same 3 guests as previous benchmarks
     - two guests running sysbench --memory, distinctly different cache heavy
       workload
     - one guest running STREAM benchmark.
    
    Similar improvements to benchmark 3.
    
    benchmark 5:
     - 1 guest, 8 VCPUs, Ubuntu 14.04
     - Host configured with split core (SMT8, subcores-per-core=4)
     - STREAM benchmark
    
    In this benchmark, we see a 10-20% performance improvement across the board
    of STREAM benchmark results with this patch.
    
    Based on preliminary investigation and microbenchmarks
    by Prerna Saxena <prerna@linux.vnet.ibm.com>
    
    Signed-off-by: Stewart Smith <stewart@linux.vnet.ibm.com>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 3132bb9365f3..c636841fc772 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -139,6 +139,7 @@
 #define PPC_INST_ISEL			0x7c00001e
 #define PPC_INST_ISEL_MASK		0xfc00003e
 #define PPC_INST_LDARX			0x7c0000a8
+#define PPC_INST_LOGMPP			0x7c0007e4
 #define PPC_INST_LSWI			0x7c0004aa
 #define PPC_INST_LSWX			0x7c00042a
 #define PPC_INST_LWARX			0x7c000028
@@ -275,6 +276,20 @@
 #define __PPC_EH(eh)	0
 #endif
 
+/* POWER8 Micro Partition Prefetch (MPP) parameters */
+/* Address mask is common for LOGMPP instruction and MPPR SPR */
+#define PPC_MPPE_ADDRESS_MASK 0xffffffffc000
+
+/* Bits 60 and 61 of MPP SPR should be set to one of the following */
+/* Aborting the fetch is indeed setting 00 in the table size bits */
+#define PPC_MPPR_FETCH_ABORT (0x0ULL << 60)
+#define PPC_MPPR_FETCH_WHOLE_TABLE (0x2ULL << 60)
+
+/* Bits 54 and 55 of register for LOGMPP instruction should be set to: */
+#define PPC_LOGMPP_LOG_L2 (0x02ULL << 54)
+#define PPC_LOGMPP_LOG_L2L3 (0x01ULL << 54)
+#define PPC_LOGMPP_LOG_ABORT (0x03ULL << 54)
+
 /* Deal with instructions that older assemblers aren't aware of */
 #define	PPC_DCBAL(a, b)		stringify_in_c(.long PPC_INST_DCBAL | \
 					__PPC_RA(a) | __PPC_RB(b))
@@ -283,6 +298,8 @@
 #define PPC_LDARX(t, a, b, eh)	stringify_in_c(.long PPC_INST_LDARX | \
 					___PPC_RT(t) | ___PPC_RA(a) | \
 					___PPC_RB(b) | __PPC_EH(eh))
+#define PPC_LOGMPP(b)		stringify_in_c(.long PPC_INST_LOGMPP | \
+					__PPC_RB(b))
 #define PPC_LWARX(t, a, b, eh)	stringify_in_c(.long PPC_INST_LWARX | \
 					___PPC_RT(t) | ___PPC_RA(a) | \
 					___PPC_RB(b) | __PPC_EH(eh))

commit a40a2b670706494610d794927b9aebe77e18af8d
Author: Vladimir Murzin <murzin.v@gmail.com>
Date:   Sat Sep 28 10:22:00 2013 +0200

    powerpc/bpf: Fix DIVWU instruction opcode
    
    Currently DIVWU stands for *signed* divw opcode:
    
    7d 2a 4b 96     divwu   r9,r10,r9
    7d 2a 4b d6     divw    r9,r10,r9
    
    Use the *unsigned* divw opcode for DIVWU.
    
    Suggested-by: Vassili Karpov <av1474@comtv.ru>
    Reviewed-by: Vassili Karpov <av1474@comtv.ru>
    Signed-off-by: Vladimir Murzin <murzin.v@gmail.com>
    Acked-by: Matt Evans <matt@ozlabs.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 99f87906de17..3132bb9365f3 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -222,7 +222,7 @@
 #define PPC_INST_MULLW			0x7c0001d6
 #define PPC_INST_MULHWU			0x7c000016
 #define PPC_INST_MULLI			0x1c000000
-#define PPC_INST_DIVWU			0x7c0003d6
+#define PPC_INST_DIVWU			0x7c000396
 #define PPC_INST_RLWINM			0x54000000
 #define PPC_INST_RLDICR			0x78000004
 #define PPC_INST_SLW			0x7c000030

commit 9c662cad2fb66ff3a44b1d4f545bf496bf67ab10
Author: Philippe Bergheaud <felix@linux.vnet.ibm.com>
Date:   Tue Sep 24 14:13:35 2013 +0200

    powerpc/bpf: BPF JIT compiler for 64-bit Little Endian
    
    This enables the Berkeley Packet Filter JIT compiler
    for the PowerPC running in 64bit Little Endian.
    
    Signed-off-by: Philippe Bergheaud <felix@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 442edee4b6aa..99f87906de17 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -203,6 +203,7 @@
 /* Misc instructions for BPF compiler */
 #define PPC_INST_LD			0xe8000000
 #define PPC_INST_LHZ			0xa0000000
+#define PPC_INST_LHBRX			0x7c00062c
 #define PPC_INST_LWZ			0x80000000
 #define PPC_INST_STD			0xf8000000
 #define PPC_INST_STDU			0xf8000001

commit 9863c28a2af90a56c088f5f6288d7f6d2c923c14
Author: James Yang <James.Yang@freescale.com>
Date:   Wed Jul 3 16:26:47 2013 -0500

    powerpc: Emulate sync instruction variants
    
    Reserved fields of the sync instruction have been used for other
    instructions (e.g. lwsync).  On processors that do not support variants
    of the sync instruction, emulate it by executing a sync to subsume the
    effect of the intended instruction.
    
    Signed-off-by: James Yang <James.Yang@freescale.com>
    [scottwood@freescale.com: whitespace and subject line fix]
    Signed-off-by: Scott Wood <scottwood@freescale.com>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index ad5fcf51b252..442edee4b6aa 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -143,6 +143,8 @@
 #define PPC_INST_LSWX			0x7c00042a
 #define PPC_INST_LWARX			0x7c000028
 #define PPC_INST_LWSYNC			0x7c2004ac
+#define PPC_INST_SYNC			0x7c0004ac
+#define PPC_INST_SYNC_MASK		0xfc0007fe
 #define PPC_INST_LXVD2X			0x7c000698
 #define PPC_INST_MCRXR			0x7c000400
 #define PPC_INST_MCRXR_MASK		0xfc0007fe

commit 926f160f460170b0361f600f365369685ad74009
Author: Anton Blanchard <anton@samba.org>
Date:   Mon Sep 23 12:04:39 2013 +1000

    powerpc: Little endian builds double word swap VSX state during context save/restore
    
    The elements within VSX loads and stores are big endian ordered
    regardless of endianness. Our VSX context save/restore code uses
    lxvd2x and stxvd2x which is a 2x doubleword operation. This means
    the two doublewords will be swapped and we have to perform another
    swap to undo it.
    
    We need to do this on save and restore.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index d7fe9f5b46d4..ad5fcf51b252 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -181,6 +181,7 @@
 #define PPC_INST_TLBIVAX		0x7c000624
 #define PPC_INST_TLBSRX_DOT		0x7c0006a5
 #define PPC_INST_XXLOR			0xf0000510
+#define PPC_INST_XXSWAPD		0xf0000250
 #define PPC_INST_XVCPSGNDP		0xf0000780
 #define PPC_INST_TRECHKPT		0x7c0007dd
 #define PPC_INST_TRECLAIM		0x7c00075d
@@ -344,6 +345,8 @@
 					       VSX_XX1((s), a, b))
 #define XXLOR(t, a, b)		stringify_in_c(.long PPC_INST_XXLOR | \
 					       VSX_XX3((t), a, b))
+#define XXSWAPD(t, a)		stringify_in_c(.long PPC_INST_XXSWAPD | \
+					       VSX_XX3((t), a, a))
 #define XVCPSGNDP(t, a, b)	stringify_in_c(.long (PPC_INST_XVCPSGNDP | \
 					       VSX_XX3((t), (a), (b))))
 

commit 9123c5ed45a583311d8373e99f5e3ee4c0b4306b
Author: Hongtao Jia <hongtao.jia@freescale.com>
Date:   Sun Apr 28 13:20:07 2013 +0800

    powerpc: Move opcode definitions from kvm/emulate.c to asm/ppc-opcode.h
    
    Opcode and xopcode are useful definitions not just for KVM. Move these
    definitions to asm/ppc-opcode.h for public use.
    
    Also add the opcodes for LHAUX and LWZUX.
    
    Signed-off-by: Jia Hongtao <hongtao.jia@freescale.com>
    Signed-off-by: Li Yang <leoli@freescale.com>
    [scottwood@freesacle.com: update commit message and rebase]
    Signed-off-by: Scott Wood <scottwood@freescale.com>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index eccfc161e58e..d7fe9f5b46d4 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -81,6 +81,53 @@
 #define	__REGA0_R30	30
 #define	__REGA0_R31	31
 
+/* opcode and xopcode for instructions */
+#define OP_TRAP 3
+#define OP_TRAP_64 2
+
+#define OP_31_XOP_TRAP      4
+#define OP_31_XOP_LWZX      23
+#define OP_31_XOP_DCBST     54
+#define OP_31_XOP_LWZUX     55
+#define OP_31_XOP_TRAP_64   68
+#define OP_31_XOP_DCBF      86
+#define OP_31_XOP_LBZX      87
+#define OP_31_XOP_STWX      151
+#define OP_31_XOP_STBX      215
+#define OP_31_XOP_LBZUX     119
+#define OP_31_XOP_STBUX     247
+#define OP_31_XOP_LHZX      279
+#define OP_31_XOP_LHZUX     311
+#define OP_31_XOP_MFSPR     339
+#define OP_31_XOP_LHAX      343
+#define OP_31_XOP_LHAUX     375
+#define OP_31_XOP_STHX      407
+#define OP_31_XOP_STHUX     439
+#define OP_31_XOP_MTSPR     467
+#define OP_31_XOP_DCBI      470
+#define OP_31_XOP_LWBRX     534
+#define OP_31_XOP_TLBSYNC   566
+#define OP_31_XOP_STWBRX    662
+#define OP_31_XOP_LHBRX     790
+#define OP_31_XOP_STHBRX    918
+
+#define OP_LWZ  32
+#define OP_LD   58
+#define OP_LWZU 33
+#define OP_LBZ  34
+#define OP_LBZU 35
+#define OP_STW  36
+#define OP_STWU 37
+#define OP_STD  62
+#define OP_STB  38
+#define OP_STBU 39
+#define OP_LHZ  40
+#define OP_LHZU 41
+#define OP_LHA  42
+#define OP_LHAU 43
+#define OP_STH  44
+#define OP_STHU 45
+
 /* sorted alphabetically */
 #define PPC_INST_BHRBE			0x7c00025c
 #define PPC_INST_CLRBHRB		0x7c00035c

commit 73d2fb758e678c93bc76d40876c2359f0729b0ef
Author: Anton Blanchard <anton@samba.org>
Date:   Wed May 1 20:06:33 2013 +0000

    powerpc: Emulate non privileged DSCR read and write
    
    POWER8 allows read and write of the DSCR in userspace. We added
    kernel emulation so applications could always use the instructions
    regardless of the CPU type.
    
    Unfortunately there are two SPRs for the DSCR and we only added
    emulation for the privileged one. Add code to match the non
    privileged one.
    
    A simple test was created to verify the fix:
    
    http://ozlabs.org/~anton/junkcode/user_dscr_test.c
    
    Without the patch we get a SIGILL and it passes with the patch.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Cc: <stable@kernel.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 0c34e4803499..eccfc161e58e 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -115,6 +115,10 @@
 #define PPC_INST_MFSPR_DSCR_MASK	0xfc1fffff
 #define PPC_INST_MTSPR_DSCR		0x7c1103a6
 #define PPC_INST_MTSPR_DSCR_MASK	0xfc1fffff
+#define PPC_INST_MFSPR_DSCR_USER	0x7c0302a6
+#define PPC_INST_MFSPR_DSCR_USER_MASK	0xfc1fffff
+#define PPC_INST_MTSPR_DSCR_USER	0x7c0303a6
+#define PPC_INST_MTSPR_DSCR_USER_MASK	0xfc1fffff
 #define PPC_INST_SLBFEE			0x7c0007a7
 
 #define PPC_INST_STRING			0x7c00042a

commit 95213959aefc94f1cfe6718449a8bcdc8df86060
Author: Anshuman Khandual <khandual@linux.vnet.ibm.com>
Date:   Mon Apr 22 19:42:40 2013 +0000

    powerpc/perf: Add new BHRB related instructions for POWER8
    
    This patch adds new POWER8 instruction encoding for reading
    and clearing Branch History Rolling Buffer entries. The new
    instruction 'mfbhrbe' (move from branch history rolling buffer
    entry) is used to read BHRB buffer entries and instruction
    'clrbhrb' (clear branch history rolling buffer) is used to
    clear the entire buffer. The instruction 'clrbhrb' has straight
    forward encoding. But the instruction encoding format for
    reading the BHRB entries is like 'mfbhrbe RT, BHRBE' where it
    takes two arguments, i.e the index for the BHRB buffer entry to
    read and a general purpose register to put the value which was
    read from the buffer entry.
    
    Signed-off-by: Anshuman Khandual <khandual@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 8752bc8e34a3..0c34e4803499 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -82,6 +82,8 @@
 #define	__REGA0_R31	31
 
 /* sorted alphabetically */
+#define PPC_INST_BHRBE			0x7c00025c
+#define PPC_INST_CLRBHRB		0x7c00035c
 #define PPC_INST_DCBA			0x7c0005ec
 #define PPC_INST_DCBA_MASK		0xfc0007fe
 #define PPC_INST_DCBAL			0x7c2005ec
@@ -297,6 +299,12 @@
 #define PPC_NAP			stringify_in_c(.long PPC_INST_NAP)
 #define PPC_SLEEP		stringify_in_c(.long PPC_INST_SLEEP)
 
+/* BHRB instructions */
+#define PPC_CLRBHRB		stringify_in_c(.long PPC_INST_CLRBHRB)
+#define PPC_MFBHRBE(r, n)	stringify_in_c(.long PPC_INST_BHRBE | \
+						__PPC_RT(r) | \
+							(((n) & 0x3ff) << 11))
+
 /* Transactional memory instructions */
 #define TRECHKPT		stringify_in_c(.long PPC_INST_TRECHKPT)
 #define TRECLAIM(r)		stringify_in_c(.long PPC_INST_TRECLAIM \

commit 14c39a4cf6bc4c3ef8ec40caa366047a87b0e031
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed Feb 13 16:21:30 2013 +0000

    powerpc: Add new instructions for transactional memory
    
    Here we define the new instructions we need for transactional memory in the
    kernel.  This is so we can support compiling with binutils that don't support
    the new transactional memory instructions.
    
    Transactional memory results in two sets of architected state (GPRs/VSRs
    etc).
    
    treclaim allows us to read the checkpointed state (from the tbegin) so that we
    can store it away on a context switch.  It does this by overwriting the exiting
    architected state, so you have to save that away before you treclaim.  treclaim
    will also abort a transaction, so you can give a register value which contains
    an abort reason.
    
    trecheckpoint allows us to inject into the checkpointed state as if it were at
    the tbegin.  It does this by copying the current architected state into the
    checkpointed state.
    
    Signed-off-by: Matt Evans <matt@ozlabs.org>
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 0fd1928efb93..8752bc8e34a3 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -129,6 +129,9 @@
 #define PPC_INST_TLBSRX_DOT		0x7c0006a5
 #define PPC_INST_XXLOR			0xf0000510
 #define PPC_INST_XVCPSGNDP		0xf0000780
+#define PPC_INST_TRECHKPT		0x7c0007dd
+#define PPC_INST_TRECLAIM		0x7c00075d
+#define PPC_INST_TABORT			0x7c00071d
 
 #define PPC_INST_NAP			0x4c000364
 #define PPC_INST_SLEEP			0x4c0003a4
@@ -294,4 +297,11 @@
 #define PPC_NAP			stringify_in_c(.long PPC_INST_NAP)
 #define PPC_SLEEP		stringify_in_c(.long PPC_INST_SLEEP)
 
+/* Transactional memory instructions */
+#define TRECHKPT		stringify_in_c(.long PPC_INST_TRECHKPT)
+#define TRECLAIM(r)		stringify_in_c(.long PPC_INST_TRECLAIM \
+					       | __PPC_RA(r))
+#define TABORT(r)		stringify_in_c(.long PPC_INST_TABORT \
+					       | __PPC_RA(r))
+
 #endif /* _ASM_POWERPC_PPC_OPCODE_H */

commit 42d02b81f265b77be39262666c888d50cb488fc5
Author: Ian Munsie <imunsie@au1.ibm.com>
Date:   Wed Nov 14 18:49:44 2012 +0000

    powerpc: Define differences between doorbells on book3e and book3s
    
    There are a few key differences between doorbells on server compared
    with embedded that we care about on Linux, namely:
    
    - We have a new msgsndp instruction for directed privileged doorbells.
      msgsnd is used for directed hypervisor doorbells.
    - The tag we use in the instruction is the Thread Identification
      Register of the recipient thread (since server doorbells can only
      occur between threads within a single core), and is only 7 bits wide.
    - A new message type is introduced for server doorbells (none of the
      existing book3e message types are currently supported on book3s).
    
    Signed-off-by: Ian Munsie <imunsie@au1.ibm.com>
    Tested-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 51fb00a20d7e..0fd1928efb93 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -100,6 +100,7 @@
 #define PPC_INST_MFSPR_PVR		0x7c1f42a6
 #define PPC_INST_MFSPR_PVR_MASK		0xfc1fffff
 #define PPC_INST_MSGSND			0x7c00019c
+#define PPC_INST_MSGSNDP		0x7c00011c
 #define PPC_INST_NOP			0x60000000
 #define PPC_INST_POPCNTB		0x7c0000f4
 #define PPC_INST_POPCNTB_MASK		0xfc0007fe
@@ -227,6 +228,8 @@
 					___PPC_RB(b) | __PPC_EH(eh))
 #define PPC_MSGSND(b)		stringify_in_c(.long PPC_INST_MSGSND | \
 					___PPC_RB(b))
+#define PPC_MSGSNDP(b)		stringify_in_c(.long PPC_INST_MSGSNDP | \
+					___PPC_RB(b))
 #define PPC_POPCNTB(a, s)	stringify_in_c(.long PPC_INST_POPCNTB | \
 					__PPC_RA(a) | __PPC_RS(s))
 #define PPC_POPCNTD(a, s)	stringify_in_c(.long PPC_INST_POPCNTD | \

commit 16e024f30ce96ef5fa651e2914e19d175a924cab
Merge: c36e0501ee91 376bddd34433
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 18 09:58:09 2012 -0800

    Merge branch 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc
    
    Pull powerpc update from Benjamin Herrenschmidt:
     "The main highlight is probably some base POWER8 support.  There's more
      to come such as transactional memory support but that will wait for
      the next one.
    
      Overall it's pretty quiet, or rather I've been pretty poor at picking
      things up from patchwork and reviewing them this time around and Kumar
      no better on the FSL side it seems..."
    
    * 'next' of git://git.kernel.org/pub/scm/linux/kernel/git/benh/powerpc: (73 commits)
      powerpc+of: Rename and fix OF reconfig notifier error inject module
      powerpc: mpc5200: Add a3m071 board support
      powerpc/512x: don't compile any platform DIU code if the DIU is not enabled
      powerpc/mpc52xx: use module_platform_driver macro
      powerpc+of: Export of_reconfig_notifier_[register,unregister]
      powerpc/dma/raidengine: add raidengine device
      powerpc/iommu/fsl: Add PAMU bypass enable register to ccsr_guts struct
      powerpc/mpc85xx: Change spin table to cached memory
      powerpc/fsl-pci: Add PCI controller ATMU PM support
      powerpc/86xx: fsl_pcibios_fixup_bus requires CONFIG_PCI
      drivers/virt: the Freescale hypervisor driver doesn't need to check MSR[GS]
      powerpc/85xx: p1022ds: Use NULL instead of 0 for pointers
      powerpc: Disable relocation on exceptions when kexecing
      powerpc: Enable relocation on during exceptions at boot
      powerpc: Move get_longbusy_msecs into hvcall.h and remove duplicate function
      powerpc: Add wrappers to enable/disable relocation on exceptions
      powerpc: Add set_mode hcall
      powerpc: Setup relocation on exceptions for bare metal systems
      powerpc: Move initial mfspr LPCR out of __init_LPCR
      powerpc: Add relocation on exception vector handlers
      ...

commit 02871903a1fcdf306a906c38566ca0d48a45a431
Author: Daniel Borkmann <dxchgb@gmail.com>
Date:   Thu Nov 8 11:39:41 2012 +0000

    PPC: net: bpf_jit_comp: add XOR instruction for BPF JIT
    
    This patch is a follow-up for patch "filter: add XOR instruction for use
    with X/K" that implements BPF PowerPC JIT parts for the BPF XOR operation.
    
    Signed-off-by: Daniel Borkmann <daniel.borkmann@tik.ee.ethz.ch>
    Cc: Matt Evans <matt@ozlabs.org>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Acked-by: Matt Evans <matt@ozlabs.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 5f73ce63fcae..42b1f43b943b 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -168,9 +168,12 @@
 #define PPC_INST_AND			0x7c000038
 #define PPC_INST_ANDDOT			0x7c000039
 #define PPC_INST_OR			0x7c000378
+#define PPC_INST_XOR			0x7c000278
 #define PPC_INST_ANDI			0x70000000
 #define PPC_INST_ORI			0x60000000
 #define PPC_INST_ORIS			0x64000000
+#define PPC_INST_XORI			0x68000000
+#define PPC_INST_XORIS			0x6c000000
 #define PPC_INST_NEG			0x7c0000d0
 #define PPC_INST_BRANCH			0x48000000
 #define PPC_INST_BRANCH_COND		0x40800000

commit 8a56e1ee9229ef1c5c558b53f696af9152024a15
Author: Yang Li <leoli@freescale.com>
Date:   Thu Nov 1 18:53:42 2012 +0000

    powerpc: Fix typos in Freescale copyright claims
    
    There are many cases that Semiconductor is misspelled.  The patch
    fix these typos.
    
    Signed-off-by: Li Yang <leoli@freescale.com>
    Acked-by: Timur Tabi <timur@freescale.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 66bec4611cac..e434d8b68dda 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -1,5 +1,5 @@
 /*
- * Copyright 2009 Freescale Semicondutor, Inc.
+ * Copyright 2009 Freescale Semiconductor, Inc.
  *
  * This program is free software; you can redistribute it and/or
  * modify it under the terms of the GNU General Public License

commit 1afc149def25ac1c44a83882f6c0e42a8e88ce9f
Author: Tony Breeds <tony@bakeyournoodle.com>
Date:   Tue Oct 2 15:52:19 2012 +0000

    powerpc/47x: Use the new ppc-opcode infrastructure
    
    Don't use 47x only #defines for TLBIVAX or ICBT, supply and use helpers
    in ppc-opcode.h
    
    This fixes a compile breakage.
    
    Signed-off-by: Tony Breeds <tony@bakeyournoodle.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 5f73ce63fcae..66bec4611cac 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -86,6 +86,7 @@
 #define PPC_INST_DCBA_MASK		0xfc0007fe
 #define PPC_INST_DCBAL			0x7c2005ec
 #define PPC_INST_DCBZL			0x7c2007ec
+#define PPC_INST_ICBT			0x7c00002c
 #define PPC_INST_ISEL			0x7c00001e
 #define PPC_INST_ISEL_MASK		0xfc00003e
 #define PPC_INST_LDARX			0x7c0000a8
@@ -198,6 +199,7 @@
 #define __PPC_MB(s)	(((s) & 0x1f) << 6)
 #define __PPC_ME(s)	(((s) & 0x1f) << 1)
 #define __PPC_BI(s)	(((s) & 0x1f) << 16)
+#define __PPC_CT(t)	(((t) & 0x0f) << 21)
 
 /*
  * Only use the larx hint bit on 64bit CPUs. e500v1/v2 based CPUs will treat a
@@ -260,6 +262,8 @@
 					__PPC_RS(t) | __PPC_RA0(a) | __PPC_RB(b))
 #define PPC_SLBFEE_DOT(t, b)	stringify_in_c(.long PPC_INST_SLBFEE | \
 					__PPC_RT(t) | __PPC_RB(b))
+#define PPC_ICBT(c,a,b)		stringify_in_c(.long PPC_INST_ICBT | \
+				       __PPC_CT(c) | __PPC_RA0(a) | __PPC_RB(b))
 /* PASemi instructions */
 #define LBZCIX(t,a,b)		stringify_in_c(.long PPC_INST_LBZCIX | \
 				       __PPC_RT(t) | __PPC_RA(a) | __PPC_RB(b))

commit b92a66a65cb4480774066d9a3080c77eb34b7232
Author: Michael Neuling <mikey@neuling.org>
Date:   Mon Sep 10 00:35:26 2012 +0000

    powerpc: Add denormalisation exception handling for POWER6/7
    
    On POWER6 and POWER7 if the input operand to an instruction is a
    denormalised single precision binary floating point value we can take
    a denormalisation exception where it's expected that the hypervisor
    (HV=1) will fix up the inputs before the instruction is run.
    
    This adds code to handle this denormalisation exception for POWER6 and
    POWER7.
    
    It also add a CONFIG_PPC_DENORMALISATION option and sets it in
    pseries/ppc64_defconfig.
    
    This is useful on bare metal systems only.  Based on patch from Milton
    Miller.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 4c25319f2fbc..5f73ce63fcae 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -126,6 +126,7 @@
 #define PPC_INST_TLBIVAX		0x7c000624
 #define PPC_INST_TLBSRX_DOT		0x7c0006a5
 #define PPC_INST_XXLOR			0xf0000510
+#define PPC_INST_XVCPSGNDP		0xf0000780
 
 #define PPC_INST_NAP			0x4c000364
 #define PPC_INST_SLEEP			0x4c0003a4
@@ -277,6 +278,8 @@
 					       VSX_XX1((s), a, b))
 #define XXLOR(t, a, b)		stringify_in_c(.long PPC_INST_XXLOR | \
 					       VSX_XX3((t), a, b))
+#define XVCPSGNDP(t, a, b)	stringify_in_c(.long (PPC_INST_XVCPSGNDP | \
+					       VSX_XX3((t), (a), (b))))
 
 #define PPC_NAP			stringify_in_c(.long PPC_INST_NAP)
 #define PPC_SLEEP		stringify_in_c(.long PPC_INST_SLEEP)

commit 962cffbd8a21ad380ec71a6f5ea55a8e08f32dd1
Author: Michael Neuling <mikey@neuling.org>
Date:   Mon Jun 25 13:33:25 2012 +0000

    powerpc: Enforce usage of RA 0-R31 where possible
    
    Some macros use RA where when RA=R0 the values is 0, so make this
    the enforced mnemonic in the macro.
    
    Idea suggested by Andreas Schwab.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 03ec90fca009..4c25319f2fbc 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -231,7 +231,7 @@
 #define PPC_RFDI		stringify_in_c(.long PPC_INST_RFDI)
 #define PPC_RFMCI		stringify_in_c(.long PPC_INST_RFMCI)
 #define PPC_TLBILX(t, a, b)	stringify_in_c(.long PPC_INST_TLBILX | \
-					__PPC_T_TLB(t) | __PPC_RA(a) | __PPC_RB(b))
+					__PPC_T_TLB(t) | __PPC_RA0(a) | __PPC_RB(b))
 #define PPC_TLBILX_ALL(a, b)	PPC_TLBILX(0, a, b)
 #define PPC_TLBILX_PID(a, b)	PPC_TLBILX(1, a, b)
 #define PPC_TLBILX_VA(a, b)	PPC_TLBILX(3, a, b)
@@ -240,23 +240,23 @@
 #define PPC_TLBIE(lp,a) 	stringify_in_c(.long PPC_INST_TLBIE | \
 					       ___PPC_RB(a) | ___PPC_RS(lp))
 #define PPC_TLBSRX_DOT(a,b)	stringify_in_c(.long PPC_INST_TLBSRX_DOT | \
-					__PPC_RA(a) | __PPC_RB(b))
+					__PPC_RA0(a) | __PPC_RB(b))
 #define PPC_TLBIVAX(a,b)	stringify_in_c(.long PPC_INST_TLBIVAX | \
-					__PPC_RA(a) | __PPC_RB(b))
+					__PPC_RA0(a) | __PPC_RB(b))
 
 #define PPC_ERATWE(s, a, w)	stringify_in_c(.long PPC_INST_ERATWE | \
 					__PPC_RS(s) | __PPC_RA(a) | __PPC_WS(w))
 #define PPC_ERATRE(s, a, w)	stringify_in_c(.long PPC_INST_ERATRE | \
 					__PPC_RS(s) | __PPC_RA(a) | __PPC_WS(w))
 #define PPC_ERATILX(t, a, b)	stringify_in_c(.long PPC_INST_ERATILX | \
-					__PPC_T_TLB(t) | __PPC_RA(a) | \
+					__PPC_T_TLB(t) | __PPC_RA0(a) | \
 					__PPC_RB(b))
 #define PPC_ERATIVAX(s, a, b)	stringify_in_c(.long PPC_INST_ERATIVAX | \
-					__PPC_RS(s) | __PPC_RA(a) | __PPC_RB(b))
+					__PPC_RS(s) | __PPC_RA0(a) | __PPC_RB(b))
 #define PPC_ERATSX(t, a, w)	stringify_in_c(.long PPC_INST_ERATSX | \
-					__PPC_RS(t) | __PPC_RA(a) | __PPC_RB(b))
+					__PPC_RS(t) | __PPC_RA0(a) | __PPC_RB(b))
 #define PPC_ERATSX_DOT(t, a, w)	stringify_in_c(.long PPC_INST_ERATSX_DOT | \
-					__PPC_RS(t) | __PPC_RA(a) | __PPC_RB(b))
+					__PPC_RS(t) | __PPC_RA0(a) | __PPC_RB(b))
 #define PPC_SLBFEE_DOT(t, b)	stringify_in_c(.long PPC_INST_SLBFEE | \
 					__PPC_RT(t) | __PPC_RB(b))
 /* PASemi instructions */

commit f4c015795c74ec31b7ad0b8e11d07946fe853db4
Author: Michael Neuling <mikey@neuling.org>
Date:   Mon Jun 25 13:33:24 2012 +0000

    powerpc: Add defines for RA 0-R31
    
    R0 is special since it'll be 0.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index d14508f82247..03ec90fca009 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -48,6 +48,39 @@
 #define	__REG_R30	30
 #define	__REG_R31	31
 
+#define	__REGA0_0	0
+#define	__REGA0_R1	1
+#define	__REGA0_R2	2
+#define	__REGA0_R3	3
+#define	__REGA0_R4	4
+#define	__REGA0_R5	5
+#define	__REGA0_R6	6
+#define	__REGA0_R7	7
+#define	__REGA0_R8	8
+#define	__REGA0_R9	9
+#define	__REGA0_R10	10
+#define	__REGA0_R11	11
+#define	__REGA0_R12	12
+#define	__REGA0_R13	13
+#define	__REGA0_R14	14
+#define	__REGA0_R15	15
+#define	__REGA0_R16	16
+#define	__REGA0_R17	17
+#define	__REGA0_R18	18
+#define	__REGA0_R19	19
+#define	__REGA0_R20	20
+#define	__REGA0_R21	21
+#define	__REGA0_R22	22
+#define	__REGA0_R23	23
+#define	__REGA0_R24	24
+#define	__REGA0_R25	25
+#define	__REGA0_R26	26
+#define	__REGA0_R27	27
+#define	__REGA0_R28	28
+#define	__REGA0_R29	29
+#define	__REGA0_R30	30
+#define	__REGA0_R31	31
+
 /* sorted alphabetically */
 #define PPC_INST_DCBA			0x7c0005ec
 #define PPC_INST_DCBA_MASK		0xfc0007fe
@@ -149,6 +182,7 @@
 #define ___PPC_RS(s)	(((s) & 0x1f) << 21)
 #define ___PPC_RT(t)	___PPC_RS(t)
 #define __PPC_RA(a)	___PPC_RA(__REG_##a)
+#define __PPC_RA0(a)	___PPC_RA(__REGA0_##a)
 #define __PPC_RB(b)	___PPC_RB(__REG_##b)
 #define __PPC_RS(s)	___PPC_RS(__REG_##s)
 #define __PPC_RT(t)	___PPC_RT(__REG_##t)

commit 0b7673c35e9240a364594ac4f2c2dd2c111c0aba
Author: Michael Neuling <mikey@neuling.org>
Date:   Mon Jun 25 13:33:23 2012 +0000

    powerpc: Enforce usage of R0-R31 where possible
    
    Enforce the use of R0-R31 in macros where possible now we have all the
    fixes in.
    
    R0-R31 macros are removed here so that can't be used anymore.  They
    should not be defined anywhere.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index c74e00778f72..d14508f82247 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -15,39 +15,6 @@
 #include <linux/stringify.h>
 #include <asm/asm-compat.h>
 
-#define	R0	0
-#define	R1	1
-#define	R2	2
-#define	R3	3
-#define	R4	4
-#define	R5	5
-#define	R6	6
-#define	R7	7
-#define	R8	8
-#define	R9	9
-#define	R10	10
-#define	R11	11
-#define	R12	12
-#define	R13	13
-#define	R14	14
-#define	R15	15
-#define	R16	16
-#define	R17	17
-#define	R18	18
-#define	R19	19
-#define	R20	20
-#define	R21	21
-#define	R22	22
-#define	R23	23
-#define	R24	24
-#define	R25	25
-#define	R26	26
-#define	R27	27
-#define	R28	28
-#define	R29	29
-#define	R30	30
-#define	R31	31
-
 #define	__REG_R0	0
 #define	__REG_R1	1
 #define	__REG_R2	2
@@ -181,10 +148,10 @@
 #define ___PPC_RB(b)	(((b) & 0x1f) << 11)
 #define ___PPC_RS(s)	(((s) & 0x1f) << 21)
 #define ___PPC_RT(t)	___PPC_RS(t)
-#define __PPC_RA(a)	(((a) & 0x1f) << 16)
-#define __PPC_RB(b)	(((b) & 0x1f) << 11)
-#define __PPC_RS(s)	(((s) & 0x1f) << 21)
-#define __PPC_RT(s)	__PPC_RS(s)
+#define __PPC_RA(a)	___PPC_RA(__REG_##a)
+#define __PPC_RB(b)	___PPC_RB(__REG_##b)
+#define __PPC_RS(s)	___PPC_RS(__REG_##s)
+#define __PPC_RT(t)	___PPC_RT(__REG_##t)
 #define __PPC_XA(a)	((((a) & 0x1f) << 16) | (((a) & 0x20) >> 3))
 #define __PPC_XB(b)	((((b) & 0x1f) << 11) | (((b) & 0x20) >> 4))
 #define __PPC_XS(s)	((((s) & 0x1f) << 21) | (((s) & 0x20) >> 5))

commit 0972def44fd76899fea8682ec8e3c47d429f33ca
Author: Michael Neuling <mikey@neuling.org>
Date:   Mon Jun 25 13:33:22 2012 +0000

    powerpc: Introduce new __REG_R macros
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 104cfefea4ad..c74e00778f72 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -48,6 +48,39 @@
 #define	R30	30
 #define	R31	31
 
+#define	__REG_R0	0
+#define	__REG_R1	1
+#define	__REG_R2	2
+#define	__REG_R3	3
+#define	__REG_R4	4
+#define	__REG_R5	5
+#define	__REG_R6	6
+#define	__REG_R7	7
+#define	__REG_R8	8
+#define	__REG_R9	9
+#define	__REG_R10	10
+#define	__REG_R11	11
+#define	__REG_R12	12
+#define	__REG_R13	13
+#define	__REG_R14	14
+#define	__REG_R15	15
+#define	__REG_R16	16
+#define	__REG_R17	17
+#define	__REG_R18	18
+#define	__REG_R19	19
+#define	__REG_R20	20
+#define	__REG_R21	21
+#define	__REG_R22	22
+#define	__REG_R23	23
+#define	__REG_R24	24
+#define	__REG_R25	25
+#define	__REG_R26	26
+#define	__REG_R27	27
+#define	__REG_R28	28
+#define	__REG_R29	29
+#define	__REG_R30	30
+#define	__REG_R31	31
+
 /* sorted alphabetically */
 #define PPC_INST_DCBA			0x7c0005ec
 #define PPC_INST_DCBA_MASK		0xfc0007fe

commit cdaade71291e90d8e9cc8885ae5ebc20ed4ddfd8
Author: Michael Neuling <mikey@neuling.org>
Date:   Mon Jun 25 13:33:21 2012 +0000

    powerpc: Start using ___PPC_RA/B/S/T where necessary
    
    Now have ___PPC_RA/B/S/T we can use it in some places.  These are
    places where we can't use the existing defines which will soon enforce
    R0-R31 usage.
    
    The macros being changed here are being used in inline asm, which
    can't convert to enforce the R0-R31 usage.
    
    bpf_jit uses a mix of both generated and non-generated with the same
    code, so just convert all these to use the ___PPC_R versions which
    won't enforce R usage later.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 7ad07dfbfdf7..104cfefea4ad 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -180,13 +180,13 @@
 #define	PPC_DCBZL(a, b)		stringify_in_c(.long PPC_INST_DCBZL | \
 					__PPC_RA(a) | __PPC_RB(b))
 #define PPC_LDARX(t, a, b, eh)	stringify_in_c(.long PPC_INST_LDARX | \
-					__PPC_RT(t) | __PPC_RA(a) | \
-					__PPC_RB(b) | __PPC_EH(eh))
+					___PPC_RT(t) | ___PPC_RA(a) | \
+					___PPC_RB(b) | __PPC_EH(eh))
 #define PPC_LWARX(t, a, b, eh)	stringify_in_c(.long PPC_INST_LWARX | \
-					__PPC_RT(t) | __PPC_RA(a) | \
-					__PPC_RB(b) | __PPC_EH(eh))
+					___PPC_RT(t) | ___PPC_RA(a) | \
+					___PPC_RB(b) | __PPC_EH(eh))
 #define PPC_MSGSND(b)		stringify_in_c(.long PPC_INST_MSGSND | \
-					__PPC_RB(b))
+					___PPC_RB(b))
 #define PPC_POPCNTB(a, s)	stringify_in_c(.long PPC_INST_POPCNTB | \
 					__PPC_RA(a) | __PPC_RS(s))
 #define PPC_POPCNTD(a, s)	stringify_in_c(.long PPC_INST_POPCNTD | \
@@ -204,7 +204,7 @@
 #define PPC_WAIT(w)		stringify_in_c(.long PPC_INST_WAIT | \
 					__PPC_WC(w))
 #define PPC_TLBIE(lp,a) 	stringify_in_c(.long PPC_INST_TLBIE | \
-					       __PPC_RB(a) | __PPC_RS(lp))
+					       ___PPC_RB(a) | ___PPC_RS(lp))
 #define PPC_TLBSRX_DOT(a,b)	stringify_in_c(.long PPC_INST_TLBSRX_DOT | \
 					__PPC_RA(a) | __PPC_RB(b))
 #define PPC_TLBIVAX(a,b)	stringify_in_c(.long PPC_INST_TLBIVAX | \

commit 55a5db184667433add3c8136c9e3b27899c79d3c
Author: Michael Neuling <mikey@neuling.org>
Date:   Mon Jun 25 13:33:20 2012 +0000

    powerpc: Introduce new ___PPC_RA/B/S/T macros
    
    These are currently the same as __PPC_RA/B/S/T but we'll wrap them
    soon.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 2671a6d9e4a7..7ad07dfbfdf7 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -144,6 +144,10 @@
 #define PPC_INST_STBCIX			0x7c0007aa
 
 /* macros to insert fields into opcodes */
+#define ___PPC_RA(a)	(((a) & 0x1f) << 16)
+#define ___PPC_RB(b)	(((b) & 0x1f) << 11)
+#define ___PPC_RS(s)	(((s) & 0x1f) << 21)
+#define ___PPC_RT(t)	___PPC_RS(t)
 #define __PPC_RA(a)	(((a) & 0x1f) << 16)
 #define __PPC_RB(b)	(((b) & 0x1f) << 11)
 #define __PPC_RS(s)	(((s) & 0x1f) << 21)

commit 178f2ae092a6e70b08bcbf98dc2b7499d8196885
Author: Michael Neuling <mikey@neuling.org>
Date:   Mon Jun 25 13:33:19 2012 +0000

    powerpc: Fix VSX macros so register names aren't wrapped
    
    We need to do this so we can enforce the name of a and b in called
    macros PPC_RA/B later.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 73eecd1fd5cc..2671a6d9e4a7 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -234,11 +234,11 @@
 #define VSX_XX1(s, a, b)	(__PPC_XS(s) | __PPC_RA(a) | __PPC_RB(b))
 #define VSX_XX3(t, a, b)	(__PPC_XT(t) | __PPC_XA(a) | __PPC_XB(b))
 #define STXVD2X(s, a, b)	stringify_in_c(.long PPC_INST_STXVD2X | \
-					       VSX_XX1((s), (a), (b)))
+					       VSX_XX1((s), a, b))
 #define LXVD2X(s, a, b)		stringify_in_c(.long PPC_INST_LXVD2X | \
-					       VSX_XX1((s), (a), (b)))
+					       VSX_XX1((s), a, b))
 #define XXLOR(t, a, b)		stringify_in_c(.long PPC_INST_XXLOR | \
-					       VSX_XX3((t), (a), (b)))
+					       VSX_XX3((t), a, b))
 
 #define PPC_NAP			stringify_in_c(.long PPC_INST_NAP)
 #define PPC_SLEEP		stringify_in_c(.long PPC_INST_SLEEP)

commit 4404a9f98f0d426907a926c094a2dfbaa17b796d
Author: Michael Neuling <mikey@neuling.org>
Date:   Mon Jun 25 13:33:13 2012 +0000

    powerpc/pasemi: Move lbz/stbciz to ppc-opcode.h
    
    move lbz/stbciz to ppc-opcode.h.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 015a3289e222..73eecd1fd5cc 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -140,6 +140,8 @@
 #define PPC_INST_NEG			0x7c0000d0
 #define PPC_INST_BRANCH			0x48000000
 #define PPC_INST_BRANCH_COND		0x40800000
+#define PPC_INST_LBZCIX			0x7c0006aa
+#define PPC_INST_STBCIX			0x7c0007aa
 
 /* macros to insert fields into opcodes */
 #define __PPC_RA(a)	(((a) & 0x1f) << 16)
@@ -219,6 +221,11 @@
 					__PPC_RS(t) | __PPC_RA(a) | __PPC_RB(b))
 #define PPC_SLBFEE_DOT(t, b)	stringify_in_c(.long PPC_INST_SLBFEE | \
 					__PPC_RT(t) | __PPC_RB(b))
+/* PASemi instructions */
+#define LBZCIX(t,a,b)		stringify_in_c(.long PPC_INST_LBZCIX | \
+				       __PPC_RT(t) | __PPC_RA(a) | __PPC_RB(b))
+#define STBCIX(s,a,b)		stringify_in_c(.long PPC_INST_STBCIX | \
+				       __PPC_RS(s) | __PPC_RA(a) | __PPC_RB(b))
 
 /*
  * Define what the VSX XX1 form instructions will look like, then add

commit 82fff310f18e274a8e3f0aff5669928ab45c8dab
Author: Michael Neuling <mikey@neuling.org>
Date:   Mon Jun 25 13:33:08 2012 +0000

    powerpc: Add defines for R0-R31
    
    We are going to use these later and convert r0 to %r0 etc.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index d81f99430fe7..015a3289e222 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -15,6 +15,39 @@
 #include <linux/stringify.h>
 #include <asm/asm-compat.h>
 
+#define	R0	0
+#define	R1	1
+#define	R2	2
+#define	R3	3
+#define	R4	4
+#define	R5	5
+#define	R6	6
+#define	R7	7
+#define	R8	8
+#define	R9	9
+#define	R10	10
+#define	R11	11
+#define	R12	12
+#define	R13	13
+#define	R14	14
+#define	R15	15
+#define	R16	16
+#define	R17	17
+#define	R18	18
+#define	R19	19
+#define	R20	20
+#define	R21	21
+#define	R22	22
+#define	R23	23
+#define	R24	24
+#define	R25	25
+#define	R26	26
+#define	R27	27
+#define	R28	28
+#define	R29	29
+#define	R30	30
+#define	R31	31
+
 /* sorted alphabetically */
 #define PPC_INST_DCBA			0x7c0005ec
 #define PPC_INST_DCBA_MASK		0xfc0007fe

commit 697d3899dcb4bcd918d060a92db57b794e56b077
Author: Paul Mackerras <paulus@samba.org>
Date:   Mon Dec 12 12:36:37 2011 +0000

    KVM: PPC: Implement MMIO emulation support for Book3S HV guests
    
    This provides the low-level support for MMIO emulation in Book3S HV
    guests.  When the guest tries to map a page which is not covered by
    any memslot, that page is taken to be an MMIO emulation page.  Instead
    of inserting a valid HPTE, we insert an HPTE that has the valid bit
    clear but another hypervisor software-use bit set, which we call
    HPTE_V_ABSENT, to indicate that this is an absent page.  An
    absent page is treated much like a valid page as far as guest hcalls
    (H_ENTER, H_REMOVE, H_READ etc.) are concerned, except of course that
    an absent HPTE doesn't need to be invalidated with tlbie since it
    was never valid as far as the hardware is concerned.
    
    When the guest accesses a page for which there is an absent HPTE, it
    will take a hypervisor data storage interrupt (HDSI) since we now set
    the VPM1 bit in the LPCR.  Our HDSI handler for HPTE-not-present faults
    looks up the hash table and if it finds an absent HPTE mapping the
    requested virtual address, will switch to kernel mode and handle the
    fault in kvmppc_book3s_hv_page_fault(), which at present just calls
    kvmppc_hv_emulate_mmio() to set up the MMIO emulation.
    
    This is based on an earlier patch by Benjamin Herrenschmidt, but since
    heavily reworked.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>
    Signed-off-by: Avi Kivity <avi@redhat.com>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index e980faae4225..d81f99430fe7 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -45,6 +45,7 @@
 #define PPC_INST_MFSPR_DSCR_MASK	0xfc1fffff
 #define PPC_INST_MTSPR_DSCR		0x7c1103a6
 #define PPC_INST_MTSPR_DSCR_MASK	0xfc1fffff
+#define PPC_INST_SLBFEE			0x7c0007a7
 
 #define PPC_INST_STRING			0x7c00042a
 #define PPC_INST_STRING_MASK		0xfc0007fe
@@ -183,7 +184,8 @@
 					__PPC_RS(t) | __PPC_RA(a) | __PPC_RB(b))
 #define PPC_ERATSX_DOT(t, a, w)	stringify_in_c(.long PPC_INST_ERATSX_DOT | \
 					__PPC_RS(t) | __PPC_RA(a) | __PPC_RB(b))
-
+#define PPC_SLBFEE_DOT(t, b)	stringify_in_c(.long PPC_INST_SLBFEE | \
+					__PPC_RT(t) | __PPC_RB(b))
 
 /*
  * Define what the VSX XX1 form instructions will look like, then add

commit 0ca87f05ba8bdc6791c14878464efc901ad71e99
Author: Matt Evans <matt@ozlabs.org>
Date:   Wed Jul 20 15:51:00 2011 +0000

    net: filter: BPF 'JIT' compiler for PPC64
    
    An implementation of a code generator for BPF programs to speed up packet
    filtering on PPC64, inspired by Eric Dumazet's x86-64 version.
    
    Filter code is generated as an ABI-compliant function in module_alloc()'d mem
    with stackframe & prologue/epilogue generated if required (simple filters don't
    need anything more than an li/blr).  The filter's local variables, M[], live in
    registers.  Supports all BPF opcodes, although "complicated" loads from negative
    packet offsets (e.g. SKF_LL_OFF) are not yet supported.
    
    There are a couple of further optimisations left for future work; many-pass
    assembly with branch-reach reduction and a register allocator to push M[]
    variables into volatile registers would improve the code quality further.
    
    This currently supports big-endian 64-bit PowerPC only (but is fairly simple
    to port to PPC32 or LE!).
    
    Enabled in the same way as x86-64:
    
            echo 1 > /proc/sys/net/core/bpf_jit_enable
    
    Or, enabled with extra debug output:
    
            echo 2 > /proc/sys/net/core/bpf_jit_enable
    
    Signed-off-by: Matt Evans <matt@ozlabs.org>
    Acked-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index e472659d906c..e980faae4225 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -71,6 +71,42 @@
 #define PPC_INST_ERATSX			0x7c000126
 #define PPC_INST_ERATSX_DOT		0x7c000127
 
+/* Misc instructions for BPF compiler */
+#define PPC_INST_LD			0xe8000000
+#define PPC_INST_LHZ			0xa0000000
+#define PPC_INST_LWZ			0x80000000
+#define PPC_INST_STD			0xf8000000
+#define PPC_INST_STDU			0xf8000001
+#define PPC_INST_MFLR			0x7c0802a6
+#define PPC_INST_MTLR			0x7c0803a6
+#define PPC_INST_CMPWI			0x2c000000
+#define PPC_INST_CMPDI			0x2c200000
+#define PPC_INST_CMPLW			0x7c000040
+#define PPC_INST_CMPLWI			0x28000000
+#define PPC_INST_ADDI			0x38000000
+#define PPC_INST_ADDIS			0x3c000000
+#define PPC_INST_ADD			0x7c000214
+#define PPC_INST_SUB			0x7c000050
+#define PPC_INST_BLR			0x4e800020
+#define PPC_INST_BLRL			0x4e800021
+#define PPC_INST_MULLW			0x7c0001d6
+#define PPC_INST_MULHWU			0x7c000016
+#define PPC_INST_MULLI			0x1c000000
+#define PPC_INST_DIVWU			0x7c0003d6
+#define PPC_INST_RLWINM			0x54000000
+#define PPC_INST_RLDICR			0x78000004
+#define PPC_INST_SLW			0x7c000030
+#define PPC_INST_SRW			0x7c000430
+#define PPC_INST_AND			0x7c000038
+#define PPC_INST_ANDDOT			0x7c000039
+#define PPC_INST_OR			0x7c000378
+#define PPC_INST_ANDI			0x70000000
+#define PPC_INST_ORI			0x60000000
+#define PPC_INST_ORIS			0x64000000
+#define PPC_INST_NEG			0x7c0000d0
+#define PPC_INST_BRANCH			0x48000000
+#define PPC_INST_BRANCH_COND		0x40800000
+
 /* macros to insert fields into opcodes */
 #define __PPC_RA(a)	(((a) & 0x1f) << 16)
 #define __PPC_RB(b)	(((b) & 0x1f) << 11)
@@ -83,6 +119,10 @@
 #define __PPC_T_TLB(t)	(((t) & 0x3) << 21)
 #define __PPC_WC(w)	(((w) & 0x3) << 21)
 #define __PPC_WS(w)	(((w) & 0x1f) << 11)
+#define __PPC_SH(s)	__PPC_WS(s)
+#define __PPC_MB(s)	(((s) & 0x1f) << 6)
+#define __PPC_ME(s)	(((s) & 0x1f) << 1)
+#define __PPC_BI(s)	(((s) & 0x1f) << 16)
 
 /*
  * Only use the larx hint bit on 64bit CPUs. e500v1/v2 based CPUs will treat a

commit efcac6589a277c10060e4be44b9455cf43838dc1
Author: Alexey Kardashevskiy <aik@au1.ibm.com>
Date:   Wed Mar 2 15:18:48 2011 +0000

    powerpc: Per process DSCR + some fixes (try#4)
    
    The DSCR (aka Data Stream Control Register) is supported on some
    server PowerPC chips and allow some control over the prefetch
    of data streams.
    
    This patch allows the value to be specified per thread by emulating
    the corresponding mfspr and mtspr instructions. Children of such
    threads inherit the value. Other threads use a default value that
    can be specified in sysfs - /sys/devices/system/cpu/dscr_default.
    
    If a thread starts with non default value in the sysfs entry,
    all children threads inherit this non default value even if
    the sysfs value is changed later.
    
    Signed-off-by: Alexey Kardashevskiy <aik@au1.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 3e25b258568e..e472659d906c 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -41,6 +41,10 @@
 #define PPC_INST_RFCI			0x4c000066
 #define PPC_INST_RFDI			0x4c00004e
 #define PPC_INST_RFMCI			0x4c00004c
+#define PPC_INST_MFSPR_DSCR		0x7c1102a6
+#define PPC_INST_MFSPR_DSCR_MASK	0xfc1fffff
+#define PPC_INST_MTSPR_DSCR		0x7c1103a6
+#define PPC_INST_MTSPR_DSCR_MASK	0xfc1fffff
 
 #define PPC_INST_STRING			0x7c00042a
 #define PPC_INST_STRING_MASK		0xfc0007fe

commit 931e1241a266e701157d3478d0d44fc58d6e84b4
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Apr 14 22:31:56 2011 +0000

    powerpc/a2: Add some #defines for A2 specific instructions
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 384a96db794a..3e25b258568e 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -59,6 +59,14 @@
 #define PPC_INST_NAP			0x4c000364
 #define PPC_INST_SLEEP			0x4c0003a4
 
+/* A2 specific instructions */
+#define PPC_INST_ERATWE			0x7c0001a6
+#define PPC_INST_ERATRE			0x7c000166
+#define PPC_INST_ERATILX		0x7c000066
+#define PPC_INST_ERATIVAX		0x7c000666
+#define PPC_INST_ERATSX			0x7c000126
+#define PPC_INST_ERATSX_DOT		0x7c000127
+
 /* macros to insert fields into opcodes */
 #define __PPC_RA(a)	(((a) & 0x1f) << 16)
 #define __PPC_RB(b)	(((b) & 0x1f) << 11)
@@ -70,6 +78,8 @@
 #define __PPC_XT(s)	__PPC_XS(s)
 #define __PPC_T_TLB(t)	(((t) & 0x3) << 21)
 #define __PPC_WC(w)	(((w) & 0x3) << 21)
+#define __PPC_WS(w)	(((w) & 0x1f) << 11)
+
 /*
  * Only use the larx hint bit on 64bit CPUs. e500v1/v2 based CPUs will treat a
  * larx with EH set as an illegal instruction.
@@ -116,6 +126,21 @@
 #define PPC_TLBIVAX(a,b)	stringify_in_c(.long PPC_INST_TLBIVAX | \
 					__PPC_RA(a) | __PPC_RB(b))
 
+#define PPC_ERATWE(s, a, w)	stringify_in_c(.long PPC_INST_ERATWE | \
+					__PPC_RS(s) | __PPC_RA(a) | __PPC_WS(w))
+#define PPC_ERATRE(s, a, w)	stringify_in_c(.long PPC_INST_ERATRE | \
+					__PPC_RS(s) | __PPC_RA(a) | __PPC_WS(w))
+#define PPC_ERATILX(t, a, b)	stringify_in_c(.long PPC_INST_ERATILX | \
+					__PPC_T_TLB(t) | __PPC_RA(a) | \
+					__PPC_RB(b))
+#define PPC_ERATIVAX(s, a, b)	stringify_in_c(.long PPC_INST_ERATIVAX | \
+					__PPC_RS(s) | __PPC_RA(a) | __PPC_RB(b))
+#define PPC_ERATSX(t, a, w)	stringify_in_c(.long PPC_INST_ERATSX | \
+					__PPC_RS(t) | __PPC_RA(a) | __PPC_RB(b))
+#define PPC_ERATSX_DOT(t, a, w)	stringify_in_c(.long PPC_INST_ERATSX_DOT | \
+					__PPC_RS(t) | __PPC_RA(a) | __PPC_RB(b))
+
+
 /*
  * Define what the VSX XX1 form instructions will look like, then add
  * the 128 bit load store instructions based on that.

commit 948cf67c4726cca2fc57533dccadfb54d890689d
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon Jan 24 18:42:41 2011 +1100

    powerpc: Add NAP mode support on Power7 in HV mode
    
    Wakeup comes from the system reset handler with a potential loss of
    the non-hypervisor CPU state. We save the non-volatile state on the
    stack and a pointer to it in the PACA, which the system reset handler
    uses to restore things
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 1255569387b6..384a96db794a 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -56,6 +56,9 @@
 #define PPC_INST_TLBSRX_DOT		0x7c0006a5
 #define PPC_INST_XXLOR			0xf0000510
 
+#define PPC_INST_NAP			0x4c000364
+#define PPC_INST_SLEEP			0x4c0003a4
+
 /* macros to insert fields into opcodes */
 #define __PPC_RA(a)	(((a) & 0x1f) << 16)
 #define __PPC_RB(b)	(((b) & 0x1f) << 11)
@@ -126,4 +129,7 @@
 #define XXLOR(t, a, b)		stringify_in_c(.long PPC_INST_XXLOR | \
 					       VSX_XX3((t), (a), (b)))
 
+#define PPC_NAP			stringify_in_c(.long PPC_INST_NAP)
+#define PPC_SLEEP		stringify_in_c(.long PPC_INST_SLEEP)
+
 #endif /* _ASM_POWERPC_PPC_OPCODE_H */

commit b5f9b6665b70b4c844bed5452f6a14743eefa57c
Author: Anton Blanchard <anton@samba.org>
Date:   Tue Dec 7 19:58:17 2010 +0000

    powerpc: Hardcode popcnt instructions for old assemblers
    
    The popcnt instructions went into binutils relatively recently. As with a
    number of other instructions, create macros and hardcode them.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 43adc8b819ed..1255569387b6 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -36,6 +36,8 @@
 #define PPC_INST_NOP			0x60000000
 #define PPC_INST_POPCNTB		0x7c0000f4
 #define PPC_INST_POPCNTB_MASK		0xfc0007fe
+#define PPC_INST_POPCNTD		0x7c0003f4
+#define PPC_INST_POPCNTW		0x7c0002f4
 #define PPC_INST_RFCI			0x4c000066
 #define PPC_INST_RFDI			0x4c00004e
 #define PPC_INST_RFMCI			0x4c00004c
@@ -88,6 +90,12 @@
 					__PPC_RB(b) | __PPC_EH(eh))
 #define PPC_MSGSND(b)		stringify_in_c(.long PPC_INST_MSGSND | \
 					__PPC_RB(b))
+#define PPC_POPCNTB(a, s)	stringify_in_c(.long PPC_INST_POPCNTB | \
+					__PPC_RA(a) | __PPC_RS(s))
+#define PPC_POPCNTD(a, s)	stringify_in_c(.long PPC_INST_POPCNTD | \
+					__PPC_RA(a) | __PPC_RS(s))
+#define PPC_POPCNTW(a, s)	stringify_in_c(.long PPC_INST_POPCNTW | \
+					__PPC_RA(a) | __PPC_RS(s))
 #define PPC_RFCI		stringify_in_c(.long PPC_INST_RFCI)
 #define PPC_RFDI		stringify_in_c(.long PPC_INST_RFDI)
 #define PPC_RFMCI		stringify_in_c(.long PPC_INST_RFMCI)

commit 0016a4cf5582415849fafbf9f019dd9530824789
Author: Paul Mackerras <paulus@samba.org>
Date:   Tue Jun 15 14:48:58 2010 +1000

    powerpc: Emulate most Book I instructions in emulate_step()
    
    This extends the emulate_step() function to handle a large proportion
    of the Book I instructions implemented on current 64-bit server
    processors.  The aim is to handle all the load and store instructions
    used in the kernel, plus all of the instructions that appear between
    l[wd]arx and st[wd]cx., so this handles the Altivec/VMX lvx and stvx
    and the VSX lxv2dx and stxv2dx instructions (implemented in POWER7).
    
    The new code can emulate user mode instructions, and checks the
    effective address for a load or store if the saved state is for
    user mode.  It doesn't handle little-endian mode at present.
    
    For floating-point, Altivec/VMX and VSX instructions, it checks
    that the saved MSR has the enable bit for the relevant facility
    set, and if so, assumes that the FP/VMX/VSX registers contain
    valid state, and does loads or stores directly to/from the
    FP/VMX/VSX registers, using assembly helpers in ldstfp.S.
    
    Instructions supported now include:
    * Loads and stores, including some but not all VMX and VSX instructions,
      and lmw/stmw
    * Atomic loads and stores (l[dw]arx, st[dw]cx.)
    * Arithmetic instructions (add, subtract, multiply, divide, etc.)
    * Compare instructions
    * Rotate and mask instructions
    * Shift instructions
    * Logical instructions (and, or, xor, etc.)
    * Condition register logical instructions
    * mtcrf, cntlz[wd], exts[bhw]
    * isync, sync, lwsync, ptesync, eieio
    * Cache operations (dcbf, dcbst, dcbt, dcbtst)
    
    The overflow-checking arithmetic instructions are not included, but
    they appear not to be ever used in C code.
    
    This uses decimal values for the minor opcodes in the switch statements
    because that is what appears in the Power ISA specification, thus it is
    easier to check that they are correct if they are in decimal.
    
    If this is used to single-step an instruction where a data breakpoint
    interrupt occurred, then there is the possibility that the instruction
    is a lwarx or ldarx.  In that case we have to be careful not to lose the
    reservation until we get to the matching st[wd]cx., or we'll never make
    forward progress.  One alternative is to try to arrange that we can
    return from interrupts and handle data breakpoint interrupts without
    losing the reservation, which means not using any spinlocks, mutexes,
    or atomic ops (including bitops).  That seems rather fragile.  The
    other alternative is to emulate the larx/stcx and all the instructions
    in between.  This is why this commit adds support for a wide range
    of integer instructions.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index d553bbeb726c..43adc8b819ed 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -52,13 +52,17 @@
 #define PPC_INST_WAIT			0x7c00007c
 #define PPC_INST_TLBIVAX		0x7c000624
 #define PPC_INST_TLBSRX_DOT		0x7c0006a5
+#define PPC_INST_XXLOR			0xf0000510
 
 /* macros to insert fields into opcodes */
 #define __PPC_RA(a)	(((a) & 0x1f) << 16)
 #define __PPC_RB(b)	(((b) & 0x1f) << 11)
 #define __PPC_RS(s)	(((s) & 0x1f) << 21)
 #define __PPC_RT(s)	__PPC_RS(s)
+#define __PPC_XA(a)	((((a) & 0x1f) << 16) | (((a) & 0x20) >> 3))
+#define __PPC_XB(b)	((((b) & 0x1f) << 11) | (((b) & 0x20) >> 4))
 #define __PPC_XS(s)	((((s) & 0x1f) << 21) | (((s) & 0x20) >> 5))
+#define __PPC_XT(s)	__PPC_XS(s)
 #define __PPC_T_TLB(t)	(((t) & 0x3) << 21)
 #define __PPC_WC(w)	(((w) & 0x3) << 21)
 /*
@@ -106,9 +110,12 @@
  * the 128 bit load store instructions based on that.
  */
 #define VSX_XX1(s, a, b)	(__PPC_XS(s) | __PPC_RA(a) | __PPC_RB(b))
+#define VSX_XX3(t, a, b)	(__PPC_XT(t) | __PPC_XA(a) | __PPC_XB(b))
 #define STXVD2X(s, a, b)	stringify_in_c(.long PPC_INST_STXVD2X | \
 					       VSX_XX1((s), (a), (b)))
 #define LXVD2X(s, a, b)		stringify_in_c(.long PPC_INST_LXVD2X | \
 					       VSX_XX1((s), (a), (b)))
+#define XXLOR(t, a, b)		stringify_in_c(.long PPC_INST_XXLOR | \
+					       VSX_XX3((t), (a), (b)))
 
 #endif /* _ASM_POWERPC_PPC_OPCODE_H */

commit d6ccb1f55ddf5146219707c0e71b85e3a52179b4
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Wed Mar 10 23:33:25 2010 -0600

    powerpc/85xx: Make sure lwarx hint isn't set on ppc32
    
    e500v1/v2 based chips will treat any reserved field being set in an
    opcode as illegal.  Thus always setting the hint in the opcode is
    a bad idea.
    
    Anton should be kept away from the powerpc opcode map.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index aea714797590..d553bbeb726c 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -25,7 +25,7 @@
 #define PPC_INST_LDARX			0x7c0000a8
 #define PPC_INST_LSWI			0x7c0004aa
 #define PPC_INST_LSWX			0x7c00042a
-#define PPC_INST_LWARX			0x7c000029
+#define PPC_INST_LWARX			0x7c000028
 #define PPC_INST_LWSYNC			0x7c2004ac
 #define PPC_INST_LXVD2X			0x7c000698
 #define PPC_INST_MCRXR			0x7c000400
@@ -62,8 +62,8 @@
 #define __PPC_T_TLB(t)	(((t) & 0x3) << 21)
 #define __PPC_WC(w)	(((w) & 0x3) << 21)
 /*
- * Only use the larx hint bit on 64bit CPUs. Once we verify it doesn't have
- * any side effects on all 32bit processors, we can do this all the time.
+ * Only use the larx hint bit on 64bit CPUs. e500v1/v2 based CPUs will treat a
+ * larx with EH set as an illegal instruction.
  */
 #ifdef CONFIG_PPC64
 #define __PPC_EH(eh)	(((eh) & 0x1) << 0)

commit 864b9e6fd76489aab422bac62162f57c52e06ed8
Author: Anton Blanchard <anton@samba.org>
Date:   Wed Feb 10 01:02:36 2010 +0000

    powerpc: Use lwarx/ldarx hint in bit locks
    
    This patch implements the lwarx/ldarx hint bit for bit locks.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index ecec76051184..aea714797590 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -22,6 +22,7 @@
 #define PPC_INST_DCBZL			0x7c2007ec
 #define PPC_INST_ISEL			0x7c00001e
 #define PPC_INST_ISEL_MASK		0xfc00003e
+#define PPC_INST_LDARX			0x7c0000a8
 #define PPC_INST_LSWI			0x7c0004aa
 #define PPC_INST_LSWX			0x7c00042a
 #define PPC_INST_LWARX			0x7c000029
@@ -75,6 +76,9 @@
 					__PPC_RA(a) | __PPC_RB(b))
 #define	PPC_DCBZL(a, b)		stringify_in_c(.long PPC_INST_DCBZL | \
 					__PPC_RA(a) | __PPC_RB(b))
+#define PPC_LDARX(t, a, b, eh)	stringify_in_c(.long PPC_INST_LDARX | \
+					__PPC_RT(t) | __PPC_RA(a) | \
+					__PPC_RB(b) | __PPC_EH(eh))
 #define PPC_LWARX(t, a, b, eh)	stringify_in_c(.long PPC_INST_LWARX | \
 					__PPC_RT(t) | __PPC_RA(a) | \
 					__PPC_RB(b) | __PPC_EH(eh))

commit 4e14a4d17a8cd66ccab180d32c977091922cfbed
Author: Anton Blanchard <anton@samba.org>
Date:   Wed Feb 10 00:57:28 2010 +0000

    powerpc: Use lwarx hint in spinlocks
    
    Recent versions of the PowerPC architecture added a hint bit to the larx
    instructions to differentiate between an atomic operation and a lock operation:
    
    > 0 Other programs might attempt to modify the word in storage addressed by EA
    > even if the subsequent Store Conditional succeeds.
    >
    > 1 Other programs will not attempt to modify the word in storage addressed by
    > EA until the program that has acquired the lock performs a subsequent store
    > releasing the lock.
    
    To avoid a binutils dependency this patch create macros for the extended lwarx
    format and uses it in the spinlock code. To test this change I used a simple
    test case that acquires and releases a global pthread mutex:
    
            pthread_mutex_lock(&mutex);
            pthread_mutex_unlock(&mutex);
    
    On a 32 core POWER6, running 32 test threads we spend almost all our time in
    the futex spinlock code:
    
        94.37%     perf  [kernel]                     [k] ._raw_spin_lock
                   |
                   |--99.95%-- ._raw_spin_lock
                   |          |
                   |          |--63.29%-- .futex_wake
                   |          |
                   |          |--36.64%-- .futex_wait_setup
    
    Which is a good test for this patch. The results (in lock/unlock operations per
    second) are:
    
    before: 1538203 ops/sec
    after:  2189219 ops/sec
    
    An improvement of 42%
    
    A 32 core POWER7 improves even more:
    
    before: 1279529 ops/sec
    after:  2282076 ops/sec
    
    An improvement of 78%
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index ef9aa84cac5a..ecec76051184 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -24,6 +24,7 @@
 #define PPC_INST_ISEL_MASK		0xfc00003e
 #define PPC_INST_LSWI			0x7c0004aa
 #define PPC_INST_LSWX			0x7c00042a
+#define PPC_INST_LWARX			0x7c000029
 #define PPC_INST_LWSYNC			0x7c2004ac
 #define PPC_INST_LXVD2X			0x7c000698
 #define PPC_INST_MCRXR			0x7c000400
@@ -55,15 +56,28 @@
 #define __PPC_RA(a)	(((a) & 0x1f) << 16)
 #define __PPC_RB(b)	(((b) & 0x1f) << 11)
 #define __PPC_RS(s)	(((s) & 0x1f) << 21)
+#define __PPC_RT(s)	__PPC_RS(s)
 #define __PPC_XS(s)	((((s) & 0x1f) << 21) | (((s) & 0x20) >> 5))
 #define __PPC_T_TLB(t)	(((t) & 0x3) << 21)
 #define __PPC_WC(w)	(((w) & 0x3) << 21)
+/*
+ * Only use the larx hint bit on 64bit CPUs. Once we verify it doesn't have
+ * any side effects on all 32bit processors, we can do this all the time.
+ */
+#ifdef CONFIG_PPC64
+#define __PPC_EH(eh)	(((eh) & 0x1) << 0)
+#else
+#define __PPC_EH(eh)	0
+#endif
 
 /* Deal with instructions that older assemblers aren't aware of */
 #define	PPC_DCBAL(a, b)		stringify_in_c(.long PPC_INST_DCBAL | \
 					__PPC_RA(a) | __PPC_RB(b))
 #define	PPC_DCBZL(a, b)		stringify_in_c(.long PPC_INST_DCBZL | \
 					__PPC_RA(a) | __PPC_RB(b))
+#define PPC_LWARX(t, a, b, eh)	stringify_in_c(.long PPC_INST_LWARX | \
+					__PPC_RT(t) | __PPC_RA(a) | \
+					__PPC_RB(b) | __PPC_EH(eh))
 #define PPC_MSGSND(b)		stringify_in_c(.long PPC_INST_MSGSND | \
 					__PPC_RB(b))
 #define PPC_RFCI		stringify_in_c(.long PPC_INST_RFCI)

commit 29c09e8fbaf65698c51aeffe34acc284a454a38f
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Jul 23 23:15:11 2009 +0000

    powerpc/mm: Add opcode definitions for tlbivax and tlbsrx.
    
    This adds the opcode definitions to ppc-opcode.h for the two instructions
    tlbivax and tlbsrx. as defined by Book3E 2.06
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index b74f16d45cb4..ef9aa84cac5a 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -48,6 +48,8 @@
 #define PPC_INST_TLBIE			0x7c000264
 #define PPC_INST_TLBILX			0x7c000024
 #define PPC_INST_WAIT			0x7c00007c
+#define PPC_INST_TLBIVAX		0x7c000624
+#define PPC_INST_TLBSRX_DOT		0x7c0006a5
 
 /* macros to insert fields into opcodes */
 #define __PPC_RA(a)	(((a) & 0x1f) << 16)
@@ -76,6 +78,10 @@
 					__PPC_WC(w))
 #define PPC_TLBIE(lp,a) 	stringify_in_c(.long PPC_INST_TLBIE | \
 					       __PPC_RB(a) | __PPC_RS(lp))
+#define PPC_TLBSRX_DOT(a,b)	stringify_in_c(.long PPC_INST_TLBSRX_DOT | \
+					__PPC_RA(a) | __PPC_RB(b))
+#define PPC_TLBIVAX(a,b)	stringify_in_c(.long PPC_INST_TLBIVAX | \
+					__PPC_RA(a) | __PPC_RB(b))
 
 /*
  * Define what the VSX XX1 form instructions will look like, then add

commit 60dbf4385130136847ea73657da329f8e7dbe16e
Author: Milton Miller <miltonm@bga.com>
Date:   Wed Apr 29 20:58:01 2009 +0000

    powerpc: Add 2.06 tlbie mnemonics
    
    This adds the PowerPC 2.06 tlbie mnemonics and keeps backwards
    compatibilty for CPUs before 2.06.
    
    Only useful for bare metal systems.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 39bcc9f9ff62..b74f16d45cb4 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -45,12 +45,14 @@
 #define PPC_INST_STSWI			0x7c0005aa
 #define PPC_INST_STSWX			0x7c00052a
 #define PPC_INST_STXVD2X		0x7c000798
+#define PPC_INST_TLBIE			0x7c000264
 #define PPC_INST_TLBILX			0x7c000024
 #define PPC_INST_WAIT			0x7c00007c
 
 /* macros to insert fields into opcodes */
 #define __PPC_RA(a)	(((a) & 0x1f) << 16)
 #define __PPC_RB(b)	(((b) & 0x1f) << 11)
+#define __PPC_RS(s)	(((s) & 0x1f) << 21)
 #define __PPC_XS(s)	((((s) & 0x1f) << 21) | (((s) & 0x20) >> 5))
 #define __PPC_T_TLB(t)	(((t) & 0x3) << 21)
 #define __PPC_WC(w)	(((w) & 0x3) << 21)
@@ -72,6 +74,8 @@
 #define PPC_TLBILX_VA(a, b)	PPC_TLBILX(3, a, b)
 #define PPC_WAIT(w)		stringify_in_c(.long PPC_INST_WAIT | \
 					__PPC_WC(w))
+#define PPC_TLBIE(lp,a) 	stringify_in_c(.long PPC_INST_TLBIE | \
+					       __PPC_RB(a) | __PPC_RS(lp))
 
 /*
  * Define what the VSX XX1 form instructions will look like, then add

commit dfb432cb960bfcbdf668d0a228bc909897156b31
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed Apr 29 20:58:01 2009 +0000

    powerpc: Move VSX load/stores into ppc-opcode.h
    
    Cleans up the VSX load/store instructions by moving them into
    ppc-opcode.h.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Acked-by: Kumar Gala <galak@kernel.crashing.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 1c819501de22..39bcc9f9ff62 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -25,6 +25,7 @@
 #define PPC_INST_LSWI			0x7c0004aa
 #define PPC_INST_LSWX			0x7c00042a
 #define PPC_INST_LWSYNC			0x7c2004ac
+#define PPC_INST_LXVD2X			0x7c000698
 #define PPC_INST_MCRXR			0x7c000400
 #define PPC_INST_MCRXR_MASK		0xfc0007fe
 #define PPC_INST_MFSPR_PVR		0x7c1f42a6
@@ -43,12 +44,14 @@
 
 #define PPC_INST_STSWI			0x7c0005aa
 #define PPC_INST_STSWX			0x7c00052a
+#define PPC_INST_STXVD2X		0x7c000798
 #define PPC_INST_TLBILX			0x7c000024
 #define PPC_INST_WAIT			0x7c00007c
 
 /* macros to insert fields into opcodes */
 #define __PPC_RA(a)	(((a) & 0x1f) << 16)
 #define __PPC_RB(b)	(((b) & 0x1f) << 11)
+#define __PPC_XS(s)	((((s) & 0x1f) << 21) | (((s) & 0x20) >> 5))
 #define __PPC_T_TLB(t)	(((t) & 0x3) << 21)
 #define __PPC_WC(w)	(((w) & 0x3) << 21)
 
@@ -70,4 +73,14 @@
 #define PPC_WAIT(w)		stringify_in_c(.long PPC_INST_WAIT | \
 					__PPC_WC(w))
 
+/*
+ * Define what the VSX XX1 form instructions will look like, then add
+ * the 128 bit load store instructions based on that.
+ */
+#define VSX_XX1(s, a, b)	(__PPC_XS(s) | __PPC_RA(a) | __PPC_RB(b))
+#define STXVD2X(s, a, b)	stringify_in_c(.long PPC_INST_STXVD2X | \
+					       VSX_XX1((s), (a), (b)))
+#define LXVD2X(s, a, b)		stringify_in_c(.long PPC_INST_LXVD2X | \
+					       VSX_XX1((s), (a), (b)))
+
 #endif /* _ASM_POWERPC_PPC_OPCODE_H */

commit da6b43c833f885d8604aee7f9711bb457a40d863
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed Apr 29 20:58:01 2009 +0000

    powerpc: Cleanup macros in ppc-opcode.h
    
    Make macros more braces happy.
    
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Acked-by: Kumar Gala <galak@kernel.crashing.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 640ccbbc0977..1c819501de22 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -47,10 +47,10 @@
 #define PPC_INST_WAIT			0x7c00007c
 
 /* macros to insert fields into opcodes */
-#define __PPC_RA(a)	((a & 0x1f) << 16)
-#define __PPC_RB(b)	((b & 0x1f) << 11)
-#define __PPC_T_TLB(t)	((t & 0x3) << 21)
-#define __PPC_WC(w)	((w & 0x3) << 21)
+#define __PPC_RA(a)	(((a) & 0x1f) << 16)
+#define __PPC_RB(b)	(((b) & 0x1f) << 11)
+#define __PPC_T_TLB(t)	(((t) & 0x3) << 21)
+#define __PPC_WC(w)	(((w) & 0x3) << 21)
 
 /* Deal with instructions that older assemblers aren't aware of */
 #define	PPC_DCBAL(a, b)		stringify_in_c(.long PPC_INST_DCBAL | \

commit 323d23aeac4918c7a540b597a26fa7a67645593a
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Thu Apr 23 08:51:22 2009 -0500

    Revert "powerpc: Add support for early tlbilx opcode"
    
    This reverts commit e9965577406a2148ade97b5e0ce7c448b4ba4ef6.  Our HW
    guys were able to fix this so it never sees the light of day.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index ef4da37f3c10..640ccbbc0977 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -44,7 +44,6 @@
 #define PPC_INST_STSWI			0x7c0005aa
 #define PPC_INST_STSWX			0x7c00052a
 #define PPC_INST_TLBILX			0x7c000024
-#define PPC_INST_TLBILX_EARLY		0x7c000626
 #define PPC_INST_WAIT			0x7c00007c
 
 /* macros to insert fields into opcodes */
@@ -64,18 +63,10 @@
 #define PPC_RFDI		stringify_in_c(.long PPC_INST_RFDI)
 #define PPC_RFMCI		stringify_in_c(.long PPC_INST_RFMCI)
 #define PPC_TLBILX(t, a, b)	stringify_in_c(.long PPC_INST_TLBILX | \
-					__PPC_T_TLB(t) | \
-					__PPC_RA(a) | __PPC_RB(b))
+					__PPC_T_TLB(t) | __PPC_RA(a) | __PPC_RB(b))
 #define PPC_TLBILX_ALL(a, b)	PPC_TLBILX(0, a, b)
 #define PPC_TLBILX_PID(a, b)	PPC_TLBILX(1, a, b)
 #define PPC_TLBILX_VA(a, b)	PPC_TLBILX(3, a, b)
-
-#define PPC_TLBILX_EARLY(t, a, b) stringify_in_c(.long PPC_INST_TLBILX_EARLY | \
-						__PPC_T_TLB(t) | \
-						__PPC_RA(a) | __PPC_RB(b))
-#define PPC_TLBILX_ALL_EARLY(a, b)	PPC_TLBILX_EARLY(0, a, b)
-#define PPC_TLBILX_PID_EARLY(a, b)	PPC_TLBILX_EARLY(1, a, b)
-#define PPC_TLBILX_VA_EARLY(a, b)	PPC_TLBILX_EARLY(3, a, b)
 #define PPC_WAIT(w)		stringify_in_c(.long PPC_INST_WAIT | \
 					__PPC_WC(w))
 

commit e9965577406a2148ade97b5e0ce7c448b4ba4ef6
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Mon Apr 6 23:36:50 2009 -0500

    powerpc: Add support for early tlbilx opcode
    
    During the ISA 2.06 development the opcode for tlbilx changed and some
    early implementations used to old opcode.  Add support for a MMU_FTR
    fixup to deal with this.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index 640ccbbc0977..ef4da37f3c10 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -44,6 +44,7 @@
 #define PPC_INST_STSWI			0x7c0005aa
 #define PPC_INST_STSWX			0x7c00052a
 #define PPC_INST_TLBILX			0x7c000024
+#define PPC_INST_TLBILX_EARLY		0x7c000626
 #define PPC_INST_WAIT			0x7c00007c
 
 /* macros to insert fields into opcodes */
@@ -63,10 +64,18 @@
 #define PPC_RFDI		stringify_in_c(.long PPC_INST_RFDI)
 #define PPC_RFMCI		stringify_in_c(.long PPC_INST_RFMCI)
 #define PPC_TLBILX(t, a, b)	stringify_in_c(.long PPC_INST_TLBILX | \
-					__PPC_T_TLB(t) | __PPC_RA(a) | __PPC_RB(b))
+					__PPC_T_TLB(t) | \
+					__PPC_RA(a) | __PPC_RB(b))
 #define PPC_TLBILX_ALL(a, b)	PPC_TLBILX(0, a, b)
 #define PPC_TLBILX_PID(a, b)	PPC_TLBILX(1, a, b)
 #define PPC_TLBILX_VA(a, b)	PPC_TLBILX(3, a, b)
+
+#define PPC_TLBILX_EARLY(t, a, b) stringify_in_c(.long PPC_INST_TLBILX_EARLY | \
+						__PPC_T_TLB(t) | \
+						__PPC_RA(a) | __PPC_RB(b))
+#define PPC_TLBILX_ALL_EARLY(a, b)	PPC_TLBILX_EARLY(0, a, b)
+#define PPC_TLBILX_PID_EARLY(a, b)	PPC_TLBILX_EARLY(1, a, b)
+#define PPC_TLBILX_VA_EARLY(a, b)	PPC_TLBILX_EARLY(3, a, b)
 #define PPC_WAIT(w)		stringify_in_c(.long PPC_INST_WAIT | \
 					__PPC_WC(w))
 

commit 7281f5dc2c9582f3efaed9b367837ca6117d7b7f
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Mon Apr 6 15:25:52 2009 -0500

    powerpc: Fix tlbilx opcode
    
    The tlbilx opcode was not matching the Power ISA 2.06 arch spec.
    The old opcode was an early suggested opcode that changed during the
    2.06 architecture process.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
index f4a4db8d5555..640ccbbc0977 100644
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -43,7 +43,7 @@
 
 #define PPC_INST_STSWI			0x7c0005aa
 #define PPC_INST_STSWX			0x7c00052a
-#define PPC_INST_TLBILX			0x7c000626
+#define PPC_INST_TLBILX			0x7c000024
 #define PPC_INST_WAIT			0x7c00007c
 
 /* macros to insert fields into opcodes */

commit 16c57b3620d77e0bc981da5ef32beae730512684
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Tue Feb 10 20:10:44 2009 +0000

    powerpc: Unify opcode definitions and support
    
    Create a new header that becomes a single location for defining PowerPC
    opcodes used by code that is either generationg instructions
    at runtime (fixups, debug, etc.), emulating instructions, or just
    compiling instructions old assemblers don't know about.
    
    We currently don't handle the floating point emulation or alignment decode
    as both are better handled by the specific decode support they already
    have.
    
    Added support for the new dcbzl, dcbal, msgsnd, tlbilx, & wait instructions
    since older assemblers don't know about them.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/ppc-opcode.h b/arch/powerpc/include/asm/ppc-opcode.h
new file mode 100644
index 000000000000..f4a4db8d5555
--- /dev/null
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@ -0,0 +1,73 @@
+/*
+ * Copyright 2009 Freescale Semicondutor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ *
+ * provides masks and opcode images for use by code generation, emulation
+ * and for instructions that older assemblers might not know about
+ */
+#ifndef _ASM_POWERPC_PPC_OPCODE_H
+#define _ASM_POWERPC_PPC_OPCODE_H
+
+#include <linux/stringify.h>
+#include <asm/asm-compat.h>
+
+/* sorted alphabetically */
+#define PPC_INST_DCBA			0x7c0005ec
+#define PPC_INST_DCBA_MASK		0xfc0007fe
+#define PPC_INST_DCBAL			0x7c2005ec
+#define PPC_INST_DCBZL			0x7c2007ec
+#define PPC_INST_ISEL			0x7c00001e
+#define PPC_INST_ISEL_MASK		0xfc00003e
+#define PPC_INST_LSWI			0x7c0004aa
+#define PPC_INST_LSWX			0x7c00042a
+#define PPC_INST_LWSYNC			0x7c2004ac
+#define PPC_INST_MCRXR			0x7c000400
+#define PPC_INST_MCRXR_MASK		0xfc0007fe
+#define PPC_INST_MFSPR_PVR		0x7c1f42a6
+#define PPC_INST_MFSPR_PVR_MASK		0xfc1fffff
+#define PPC_INST_MSGSND			0x7c00019c
+#define PPC_INST_NOP			0x60000000
+#define PPC_INST_POPCNTB		0x7c0000f4
+#define PPC_INST_POPCNTB_MASK		0xfc0007fe
+#define PPC_INST_RFCI			0x4c000066
+#define PPC_INST_RFDI			0x4c00004e
+#define PPC_INST_RFMCI			0x4c00004c
+
+#define PPC_INST_STRING			0x7c00042a
+#define PPC_INST_STRING_MASK		0xfc0007fe
+#define PPC_INST_STRING_GEN_MASK	0xfc00067e
+
+#define PPC_INST_STSWI			0x7c0005aa
+#define PPC_INST_STSWX			0x7c00052a
+#define PPC_INST_TLBILX			0x7c000626
+#define PPC_INST_WAIT			0x7c00007c
+
+/* macros to insert fields into opcodes */
+#define __PPC_RA(a)	((a & 0x1f) << 16)
+#define __PPC_RB(b)	((b & 0x1f) << 11)
+#define __PPC_T_TLB(t)	((t & 0x3) << 21)
+#define __PPC_WC(w)	((w & 0x3) << 21)
+
+/* Deal with instructions that older assemblers aren't aware of */
+#define	PPC_DCBAL(a, b)		stringify_in_c(.long PPC_INST_DCBAL | \
+					__PPC_RA(a) | __PPC_RB(b))
+#define	PPC_DCBZL(a, b)		stringify_in_c(.long PPC_INST_DCBZL | \
+					__PPC_RA(a) | __PPC_RB(b))
+#define PPC_MSGSND(b)		stringify_in_c(.long PPC_INST_MSGSND | \
+					__PPC_RB(b))
+#define PPC_RFCI		stringify_in_c(.long PPC_INST_RFCI)
+#define PPC_RFDI		stringify_in_c(.long PPC_INST_RFDI)
+#define PPC_RFMCI		stringify_in_c(.long PPC_INST_RFMCI)
+#define PPC_TLBILX(t, a, b)	stringify_in_c(.long PPC_INST_TLBILX | \
+					__PPC_T_TLB(t) | __PPC_RA(a) | __PPC_RB(b))
+#define PPC_TLBILX_ALL(a, b)	PPC_TLBILX(0, a, b)
+#define PPC_TLBILX_PID(a, b)	PPC_TLBILX(1, a, b)
+#define PPC_TLBILX_VA(a, b)	PPC_TLBILX(3, a, b)
+#define PPC_WAIT(w)		stringify_in_c(.long PPC_INST_WAIT | \
+					__PPC_WC(w))
+
+#endif /* _ASM_POWERPC_PPC_OPCODE_H */
