commit 2874c5fd284268364ece81a7bd936f3c8168e567
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon May 27 08:55:01 2019 +0200

    treewide: Replace GPLv2 boilerplate/reference with SPDX - rule 152
    
    Based on 1 normalized pattern(s):
    
      this program is free software you can redistribute it and or modify
      it under the terms of the gnu general public license as published by
      the free software foundation either version 2 of the license or at
      your option any later version
    
    extracted by the scancode license scanner the SPDX license identifier
    
      GPL-2.0-or-later
    
    has been chosen to replace the boilerplate/reference in 3029 file(s).
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Allison Randal <allison@lohutok.net>
    Cc: linux-spdx@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190527070032.746973796@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 0de717e16dd6..49a25e2400f2 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -1,3 +1,4 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
 /* 
  * smp.h: PowerPC-specific SMP code.
  *
@@ -6,11 +7,6 @@
  *
  * Copyright (C) 1996 David S. Miller (davem@caip.rutgers.edu)
  * Copyright (C) 1996-2001 Cort Dougan <cort@fsmlabs.com>
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; either version
- * 2 of the License, or (at your option) any later version.
  */
 
 #ifndef _ASM_POWERPC_SMP_H

commit ed1cd6deb013a11959d17a94e35ce159197632da
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Thu Jan 31 10:08:58 2019 +0000

    powerpc: Activate CONFIG_THREAD_INFO_IN_TASK
    
    This patch activates CONFIG_THREAD_INFO_IN_TASK which
    moves the thread_info into task_struct.
    
    Moving thread_info into task_struct has the following advantages:
      - It protects thread_info from corruption in the case of stack
        overflows.
      - Its address is harder to determine if stack addresses are leaked,
        making a number of attacks more difficult.
    
    This has the following consequences:
      - thread_info is now located at the beginning of task_struct.
      - The 'cpu' field is now in task_struct, and only exists when
        CONFIG_SMP is active.
      - thread_info doesn't have anymore the 'task' field.
    
    This patch:
      - Removes all recopy of thread_info struct when the stack changes.
      - Changes the CURRENT_THREAD_INFO() macro to point to current.
      - Selects CONFIG_THREAD_INFO_IN_TASK.
      - Modifies raw_smp_processor_id() to get ->cpu from current without
        including linux/sched.h to avoid circular inclusion and without
        including asm/asm-offsets.h to avoid symbol names duplication
        between ASM constants and C constants.
      - Modifies klp_init_thread_info() to take a task_struct pointer
        argument.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Add task_stack.h to livepatch.h to fix build fails]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 41695745032c..0de717e16dd6 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -83,7 +83,22 @@ int is_cpu_dead(unsigned int cpu);
 /* 32-bit */
 extern int smp_hw_index[];
 
-#define raw_smp_processor_id()	(current_thread_info()->cpu)
+/*
+ * This is particularly ugly: it appears we can't actually get the definition
+ * of task_struct here, but we need access to the CPU this task is running on.
+ * Instead of using task_struct we're using _TASK_CPU which is extracted from
+ * asm-offsets.h by kbuild to get the current processor ID.
+ *
+ * This also needs to be safeguarded when building asm-offsets.s because at
+ * that time _TASK_CPU is not defined yet. It could have been guarded by
+ * _TASK_CPU itself, but we want the build to fail if _TASK_CPU is missing
+ * when building something else than asm-offsets.s
+ */
+#ifdef GENERATING_ASM_OFFSETS
+#define raw_smp_processor_id()		(0)
+#else
+#define raw_smp_processor_id()		(*(unsigned int *)((void *)current + _TASK_CPU))
+#endif
 #define hard_smp_processor_id() 	(smp_hw_index[smp_processor_id()])
 
 static inline int get_hard_smp_processor_id(int cpu)

commit 425752c63b6f3fed7b5a9cba2b8101a92cf36995
Author: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
Date:   Thu Oct 11 11:03:01 2018 +0530

    powerpc: Detect the presence of big-cores via "ibm, thread-groups"
    
    On IBM POWER9, the device tree exposes a property array identifed by
    "ibm,thread-groups" which will indicate which groups of threads share
    a particular set of resources.
    
    As of today we only have one form of grouping identifying the group of
    threads in the core that share the L1 cache, translation cache and
    instruction data flow.
    
    This patch adds helper functions to parse the contents of
    "ibm,thread-groups" and populate a per-cpu variable to cache
    information about siblings of each CPU that share the L1, traslation
    cache and instruction data-flow.
    
    It also defines a new global variable named "has_big_cores" which
    indicates if the cores on this configuration have multiple groups of
    threads that share L1 cache.
    
    For each online CPU, it maintains a cpu_smallcore_mask, which
    indicates the online siblings which share the L1-cache with it.
    
    Signed-off-by: Gautham R. Shenoy <ego@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 95b66a0c639b..41695745032c 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -100,6 +100,7 @@ static inline void set_hard_smp_processor_id(int cpu, int phys)
 DECLARE_PER_CPU(cpumask_var_t, cpu_sibling_map);
 DECLARE_PER_CPU(cpumask_var_t, cpu_l2_cache_map);
 DECLARE_PER_CPU(cpumask_var_t, cpu_core_map);
+DECLARE_PER_CPU(cpumask_var_t, cpu_smallcore_map);
 
 static inline struct cpumask *cpu_sibling_mask(int cpu)
 {
@@ -116,6 +117,11 @@ static inline struct cpumask *cpu_l2_cache_mask(int cpu)
 	return per_cpu(cpu_l2_cache_map, cpu);
 }
 
+static inline struct cpumask *cpu_smallcore_mask(int cpu)
+{
+	return per_cpu(cpu_smallcore_map, cpu);
+}
+
 extern int cpu_to_core_id(int cpu);
 
 /* Since OpenPIC has only 4 IPIs, we use slightly different message numbers.
@@ -166,6 +172,11 @@ static inline const struct cpumask *cpu_sibling_mask(int cpu)
 	return cpumask_of(cpu);
 }
 
+static inline const struct cpumask *cpu_smallcore_mask(int cpu)
+{
+	return cpumask_of(cpu);
+}
+
 #endif /* CONFIG_SMP */
 
 #ifdef CONFIG_PPC64

commit 5b73151fff63fb019db8171cb81c6c978533844b
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Wed Apr 25 15:17:59 2018 +1000

    powerpc: NMI IPI make NMI IPIs fully sychronous
    
    There is an asynchronous aspect to smp_send_nmi_ipi. The caller waits
    for all CPUs to call in to the handler, but it does not wait for
    completion of the handler. This is a needless complication, so remove
    it and always wait synchronously.
    
    The synchronous wait allows the caller to easily time out and clear
    the wait for completion (zero nmi_ipi_busy_count) in the case of badly
    behaved handlers. This would have prevented the recent smp_send_stop
    NMI IPI bug from causing the system to hang.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 29ffaabdf75b..95b66a0c639b 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -56,7 +56,6 @@ struct smp_ops_t {
 	int   (*cpu_bootable)(unsigned int nr);
 };
 
-extern void smp_flush_nmi_ipi(u64 delay_us);
 extern int smp_send_nmi_ipi(int cpu, void (*fn)(struct pt_regs *), u64 delay_us);
 extern int smp_send_safe_nmi_ipi(int cpu, void (*fn)(struct pt_regs *), u64 delay_us);
 extern void smp_send_debugger_break(void);

commit 6ba55716a24f5f399ad4d37685e4bb721f8e6dd5
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed May 2 23:07:27 2018 +1000

    powerpc/nmi: Add an API for sending "safe" NMIs
    
    Currently the options we have for sending NMIs are not necessarily
    safe, that is they can potentially interrupt a CPU in a
    non-recoverable region of code, meaning the kernel must then panic().
    
    But we'd like to use smp_send_nmi_ipi() to do cross-CPU calls in
    situations where we don't want to risk a panic(), because it doesn't
    have the requirement that interrupts must be enabled like
    smp_call_function().
    
    So add an API for the caller to indicate that it wants to use the NMI
    infrastructure, but doesn't want to do anything "unsafe".
    
    Currently that is implemented by not actually calling cause_nmi_ipi(),
    instead falling back to an IPI. In future we can pass the safe
    parameter down to cause_nmi_ipi() and the individual backends can
    potentially take it into account before deciding what to do.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index cfecfee1194b..29ffaabdf75b 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -58,6 +58,7 @@ struct smp_ops_t {
 
 extern void smp_flush_nmi_ipi(u64 delay_us);
 extern int smp_send_nmi_ipi(int cpu, void (*fn)(struct pt_regs *), u64 delay_us);
+extern int smp_send_safe_nmi_ipi(int cpu, void (*fn)(struct pt_regs *), u64 delay_us);
 extern void smp_send_debugger_break(void);
 extern void start_secondary_resume(void);
 extern void smp_generic_give_timebase(void);

commit 9f593f131ed463dc571290980dd12cb9e56d8ea5
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Wed Feb 14 01:08:18 2018 +1000

    powerpc/setup: Add cpu_to_phys_id array
    
    Build an array that finds hardware CPU number from logical CPU
    number in firmware CPU discovery. Use that rather than setting
    paca of other CPUs directly, to begin with. Subsequent patch will
    not have pacas allocated at this point.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Fix SMP=n build by adding #ifdef in arch_match_cpu_phys_id()]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index ec7b299350d9..cfecfee1194b 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -31,6 +31,7 @@
 
 extern int boot_cpuid;
 extern int spinning_secondaries;
+extern u32 *cpu_to_phys_id;
 
 extern void cpu_die(void);
 extern int cpu_to_chip_id(int cpu);

commit d2e60075a3d4422dc54b919f3b125d8066b839d4
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Wed Feb 14 01:08:12 2018 +1000

    powerpc/64: Use array of paca pointers and allocate pacas individually
    
    Change the paca array into an array of pointers to pacas. Allocate
    pacas individually.
    
    This allows flexibility in where the PACAs are allocated. Future work
    will allocate them node-local. Platforms that don't have address limits
    on PACAs would be able to defer PACA allocations until later in boot
    rather than allocate all possible ones up-front then freeing unused.
    
    This is slightly more overhead (one additional indirection) for cross
    CPU paca references, but those aren't too common.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index fac963e10d39..ec7b299350d9 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -170,12 +170,12 @@ static inline const struct cpumask *cpu_sibling_mask(int cpu)
 #ifdef CONFIG_PPC64
 static inline int get_hard_smp_processor_id(int cpu)
 {
-	return paca[cpu].hw_cpu_id;
+	return paca_ptrs[cpu]->hw_cpu_id;
 }
 
 static inline void set_hard_smp_processor_id(int cpu, int phys)
 {
-	paca[cpu].hw_cpu_id = phys;
+	paca_ptrs[cpu]->hw_cpu_id = phys;
 }
 #else
 /* 32-bit */

commit 2a636a56d2d39676fe85190dec102c7440e24977
Author: Oliver O'Halloran <oohall@gmail.com>
Date:   Thu Jun 29 17:12:55 2017 +1000

    powerpc/smp: Add cpu_l2_cache_map
    
    We want to add an extra level to the CPU scheduler topology to account
    for cores which share a cache. To do this we need to build a cpumask
    for each CPU that indicates which CPUs share this cache to use as an
    input to the scheduler.
    
    Signed-off-by: Oliver O'Halloran <oohall@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 8ea98504f900..fac963e10d39 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -97,6 +97,7 @@ static inline void set_hard_smp_processor_id(int cpu, int phys)
 #endif
 
 DECLARE_PER_CPU(cpumask_var_t, cpu_sibling_map);
+DECLARE_PER_CPU(cpumask_var_t, cpu_l2_cache_map);
 DECLARE_PER_CPU(cpumask_var_t, cpu_core_map);
 
 static inline struct cpumask *cpu_sibling_mask(int cpu)
@@ -109,6 +110,11 @@ static inline struct cpumask *cpu_core_mask(int cpu)
 	return per_cpu(cpu_core_map, cpu);
 }
 
+static inline struct cpumask *cpu_l2_cache_mask(int cpu)
+{
+	return per_cpu(cpu_l2_cache_map, cpu);
+}
+
 extern int cpu_to_core_id(int cpu);
 
 /* Since OpenPIC has only 4 IPIs, we use slightly different message numbers.

commit 2104180a53698df5aec35aed5f840a26ade0551d
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Wed Jul 12 14:35:52 2017 -0700

    powerpc/64s: implement arch-specific hardlockup watchdog
    
    Implement an arch-speicfic watchdog rather than use the perf-based
    hardlockup detector.
    
    The new watchdog takes the soft-NMI directly, rather than going through
    perf.  Perf interrupts are to be made maskable in future, so that would
    prevent the perf detector from working in those regions.
    
    Additionally, implement a SMP based detector where all CPUs watch one
    another by pinging a shared cpumask.  This is because powerpc Book3S
    does not have a true periodic local NMI, but some platforms do implement
    a true NMI IPI.
    
    If a CPU is stuck with interrupts hard disabled, the soft-NMI watchdog
    does not work, but the SMP watchdog will.  Even on platforms without a
    true NMI IPI to get a good trace from the stuck CPU, other CPUs will
    notice the lockup sufficiently to report it and panic.
    
    [npiggin@gmail.com: honor watchdog disable at boot/hotplug]
      Link: http://lkml.kernel.org/r/20170621001346.5bb337c9@roar.ozlabs.ibm.com
    [npiggin@gmail.com: fix false positive warning at CPU unplug]
      Link: http://lkml.kernel.org/r/20170630080740.20766-1-npiggin@gmail.com
    [akpm@linux-foundation.org: coding-style fixes]
    Link: http://lkml.kernel.org/r/20170616065715.18390-6-npiggin@gmail.com
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Reviewed-by: Don Zickus <dzickus@redhat.com>
    Tested-by: Babu Moger <babu.moger@oracle.com>   [sparc]
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index ebddb2111d87..8ea98504f900 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -55,6 +55,8 @@ struct smp_ops_t {
 	int   (*cpu_bootable)(unsigned int nr);
 };
 
+extern void smp_flush_nmi_ipi(u64 delay_us);
+extern int smp_send_nmi_ipi(int cpu, void (*fn)(struct pt_regs *), u64 delay_us);
 extern void smp_send_debugger_break(void);
 extern void start_secondary_resume(void);
 extern void smp_generic_give_timebase(void);

commit c64af6458e2e2ddf86aff559837d3925fbf9cbb5
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Dec 20 04:30:09 2016 +1000

    powerpc: Add struct smp_ops_t.cause_nmi_ipi operation
    
    Have the NMI IPI code use this op when the platform defines it.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 78c311ee0049..ebddb2111d87 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -42,6 +42,7 @@ struct smp_ops_t {
 #ifdef CONFIG_PPC_SMP_MUXED_IPI
 	void  (*cause_ipi)(int cpu);
 #endif
+	int   (*cause_nmi_ipi)(int cpu);
 	void  (*probe)(void);
 	int   (*kick_cpu)(int nr);
 	int   (*prepare_cpu)(int nr);

commit ddd703ca06ede1b2d01ed1b0cb8d4315ab808099
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Tue Dec 20 04:30:08 2016 +1000

    powerpc: Add NMI IPI infrastructure
    
    Add a simple NMI IPI system that handles concurrency and reentrancy.
    
    The platform does not have to implement a true non-maskable interrupt,
    the default is to simply use the debugger break IPI message. This has
    now been co-opted for a general IPI message, and users (debugger and
    crash) have been reimplemented on top of the NMI system.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Incorporate incremental fixes from Nick]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 751b2bd944fc..78c311ee0049 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -112,14 +112,22 @@ extern int cpu_to_core_id(int cpu);
  *
  * Make sure this matches openpic_request_IPIs in open_pic.c, or what shows up
  * in /proc/interrupts will be wrong!!! --Troy */
-#define PPC_MSG_CALL_FUNCTION   0
-#define PPC_MSG_RESCHEDULE      1
+#define PPC_MSG_CALL_FUNCTION	0
+#define PPC_MSG_RESCHEDULE	1
 #define PPC_MSG_TICK_BROADCAST	2
-#define PPC_MSG_DEBUGGER_BREAK  3
+#define PPC_MSG_NMI_IPI		3
 
 /* This is only used by the powernv kernel */
 #define PPC_MSG_RM_HOST_ACTION	4
 
+#define NMI_IPI_ALL_OTHERS		-2
+
+#ifdef CONFIG_NMI_IPI
+extern int smp_handle_nmi_ipi(struct pt_regs *regs);
+#else
+static inline int smp_handle_nmi_ipi(struct pt_regs *regs) { return 0; }
+#endif
+
 /* for irq controllers that have dedicated ipis per message (4) */
 extern int smp_request_message_ipi(int virq, int message);
 extern const char *smp_ipi_name[];

commit b87ac0218355a83abb899a0022bb2e5252879fc0
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Thu Apr 13 20:16:22 2017 +1000

    powerpc: Introduce msgsnd/doorbell barrier primitives
    
    POWER9 changes requirements and adds new instructions for
    synchronization.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index d9ed3b02615e..751b2bd944fc 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -128,6 +128,7 @@ extern const char *smp_ipi_name[];
 extern void smp_muxed_ipi_message_pass(int cpu, int msg);
 extern void smp_muxed_ipi_set_message(int cpu, int msg);
 extern irqreturn_t smp_ipi_demux(void);
+extern irqreturn_t smp_ipi_demux_relaxed(void);
 
 void smp_init_pSeries(void);
 void smp_init_cell(void);

commit b866cc2199d6a6cdcefe4acfe4cfca3ac3c6d38e
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Thu Apr 13 20:16:21 2017 +1000

    powerpc: Change the doorbell IPI calling convention
    
    Change the doorbell callers to know about their msgsnd addressing,
    rather than have them set a per-cpu target data tag at boot that gets
    sent to the cause_ipi functions. The data is only used for doorbell IPI
    functions, no other IPI types, so it makes sense to keep that detail
    local to doorbell.
    
    Have the platform code understand doorbell IPIs, rather than the
    interrupt controller code understand them. Platform code can look at
    capabilities it has available and decide which to use.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 63fa780b71a0..d9ed3b02615e 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -40,7 +40,7 @@ extern int cpu_to_chip_id(int cpu);
 struct smp_ops_t {
 	void  (*message_pass)(int cpu, int msg);
 #ifdef CONFIG_PPC_SMP_MUXED_IPI
-	void  (*cause_ipi)(int cpu, unsigned long data);
+	void  (*cause_ipi)(int cpu);
 #endif
 	void  (*probe)(void);
 	int   (*kick_cpu)(int nr);
@@ -125,7 +125,6 @@ extern int smp_request_message_ipi(int virq, int message);
 extern const char *smp_ipi_name[];
 
 /* for irq controllers with only a single ipi */
-extern void smp_muxed_ipi_set_data(int cpu, unsigned long data);
 extern void smp_muxed_ipi_message_pass(int cpu, int msg);
 extern void smp_muxed_ipi_set_message(int cpu, int msg);
 extern irqreturn_t smp_ipi_demux(void);

commit a978e13965a40ac07163643cc3fa0ddb0d354198
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Apr 5 17:54:49 2017 +1000

    powerpc/smp: Remove migrate_irq() custom implementation
    
    Some powerpc platforms use this to move IRQs away from a CPU being
    unplugged. This function has several bugs such as not taking the right
    locks or failing to NULL check pointers.
    
    There's a new generic function doing exactly the same thing without all
    the bugs, so let's use it instead.
    
    mpe: The obvious place for the select of GENERIC_IRQ_MIGRATION is on
    HOTPLUG_CPU, but that doesn't work. On some configs PM_SLEEP_SMP will
    select HOTPLUG_CPU even though its dependencies are not met, which means
    the select of GENERIC_IRQ_MIGRATION doesn't happen. That leads to the
    build breaking. Fix it by moving the select of GENERIC_IRQ_MIGRATION to
    SMP.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 2f8e36f91acd..63fa780b71a0 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -62,7 +62,6 @@ extern void smp_generic_take_timebase(void);
 DECLARE_PER_CPU(unsigned int, cpu_pvr);
 
 #ifdef CONFIG_HOTPLUG_CPU
-extern void migrate_irqs(void);
 int generic_cpu_disable(void);
 void generic_cpu_die(unsigned int cpu);
 void generic_set_cpu_dead(unsigned int cpu);

commit 14d4ae5c4cb89c05262fe41cb7a26f6ba949d8df
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Apr 5 17:54:48 2017 +1000

    powerpc: Add optional smp_ops->prepare_cpu SMP callback
    
    Some platforms (will) need to perform allocations before bringing
    a new CPU online. Doing it from smp_ops->setup_cpu is the wrong
    thing to do:
    
     - It has no useful failure path (too late)
     - Calling any allocator will enable interrupts prematurely
       causing problems with large decrementer among others
    
    Instead, add a new callback that is called from __cpu_up (so from
    the context trying to online the new CPU) at a point where we
    can safely allocate and handle failures.
    
    This will be used by XIVE support.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 32db16d2e7ad..2f8e36f91acd 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -44,6 +44,7 @@ struct smp_ops_t {
 #endif
 	void  (*probe)(void);
 	int   (*kick_cpu)(int nr);
+	int   (*prepare_cpu)(int nr);
 	void  (*setup_cpu)(int nr);
 	void  (*bringup_done)(void);
 	void  (*take_timebase)(void);

commit da6658859b9c734fee36570f3a7d51764c6c3838
Author: Thiago Jung Bauermann <bauerman@linux.vnet.ibm.com>
Date:   Tue Nov 29 23:45:50 2016 +1100

    powerpc: Change places using CONFIG_KEXEC to use CONFIG_KEXEC_CORE instead.
    
    Commit 2965faa5e03d ("kexec: split kexec_load syscall from kexec core
    code") introduced CONFIG_KEXEC_CORE so that CONFIG_KEXEC means whether
    the kexec_load system call should be compiled-in and CONFIG_KEXEC_FILE
    means whether the kexec_file_load system call should be compiled-in.
    These options can be set independently from each other.
    
    Since until now powerpc only supported kexec_load, CONFIG_KEXEC and
    CONFIG_KEXEC_CORE were synonyms. That is not the case anymore, so we
    need to make a distinction. Almost all places where CONFIG_KEXEC was
    being used should be using CONFIG_KEXEC_CORE instead, since
    kexec_file_load also needs that code compiled in.
    
    Signed-off-by: Thiago Jung Bauermann <bauerman@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 0d02c11dc331..32db16d2e7ad 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -176,7 +176,7 @@ static inline void set_hard_smp_processor_id(int cpu, int phys)
 #endif /* !CONFIG_SMP */
 #endif /* !CONFIG_PPC64 */
 
-#if defined(CONFIG_PPC64) && (defined(CONFIG_SMP) || defined(CONFIG_KEXEC))
+#if defined(CONFIG_PPC64) && (defined(CONFIG_SMP) || defined(CONFIG_KEXEC_CORE))
 extern void smp_release_cpus(void);
 #else
 static inline void smp_release_cpus(void) { };

commit b1923caa6e641f3d0a93b5d045aef67ded5aef67
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Tue Jul 5 15:07:51 2016 +1000

    powerpc: Merge 32-bit and 64-bit setup_arch()
    
    There is little enough differences now.
    
    mpe: Add a/p/k/setup.h to contain the prototypes and empty versions of
    functions we need, rather than using weak functions. Add a few other
    empty versions to avoid as many #ifdefs as possible in the code.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index e1afd4c4f695..0d02c11dc331 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -160,9 +160,6 @@ static inline void set_hard_smp_processor_id(int cpu, int phys)
 {
 	paca[cpu].hw_cpu_id = phys;
 }
-
-extern void smp_release_cpus(void);
-
 #else
 /* 32-bit */
 #ifndef CONFIG_SMP
@@ -179,6 +176,12 @@ static inline void set_hard_smp_processor_id(int cpu, int phys)
 #endif /* !CONFIG_SMP */
 #endif /* !CONFIG_PPC64 */
 
+#if defined(CONFIG_PPC64) && (defined(CONFIG_SMP) || defined(CONFIG_KEXEC))
+extern void smp_release_cpus(void);
+#else
+static inline void smp_release_cpus(void) { };
+#endif
+
 extern int smt_enabled_at_boot;
 
 extern void smp_mpic_probe(void);

commit d5e2d00898bdfed9586472679760fc81a2ca2d02
Merge: 31e182363b39 6e669f085d59
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Mar 19 15:38:41 2016 -0700

    Merge tag 'powerpc-4.6-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc updates from Michael Ellerman:
     "This was delayed a day or two by some build-breakage on old toolchains
      which we've now fixed.
    
      There's two PCI commits both acked by Bjorn.
    
      There's one commit to mm/hugepage.c which is (co)authored by Kirill.
    
      Highlights:
       - Restructure Linux PTE on Book3S/64 to Radix format from Paul
         Mackerras
       - Book3s 64 MMU cleanup in preparation for Radix MMU from Aneesh
         Kumar K.V
       - Add POWER9 cputable entry from Michael Neuling
       - FPU/Altivec/VSX save/restore optimisations from Cyril Bur
       - Add support for new ftrace ABI on ppc64le from Torsten Duwe
    
      Various cleanups & minor fixes from:
       - Adam Buchbinder, Andrew Donnellan, Balbir Singh, Christophe Leroy,
         Cyril Bur, Luis Henriques, Madhavan Srinivasan, Pan Xinhui, Russell
         Currey, Sukadev Bhattiprolu, Suraj Jitindar Singh.
    
      General:
       - atomics: Allow architectures to define their own __atomic_op_*
         helpers from Boqun Feng
       - Implement atomic{, 64}_*_return_* variants and acquire/release/
         relaxed variants for (cmp)xchg from Boqun Feng
       - Add powernv_defconfig from Jeremy Kerr
       - Fix BUG_ON() reporting in real mode from Balbir Singh
       - Add xmon command to dump OPAL msglog from Andrew Donnellan
       - Add xmon command to dump process/task similar to ps(1) from Douglas
         Miller
       - Clean up memory hotplug failure paths from David Gibson
    
      pci/eeh:
       - Redesign SR-IOV on PowerNV to give absolute isolation between VFs
         from Wei Yang.
       - EEH Support for SRIOV VFs from Wei Yang and Gavin Shan.
       - PCI/IOV: Rename and export virtfn_{add, remove} from Wei Yang
       - PCI: Add pcibios_bus_add_device() weak function from Wei Yang
       - MAINTAINERS: Update EEH details and maintainership from Russell
         Currey
    
      cxl:
       - Support added to the CXL driver for running on both bare-metal and
         hypervisor systems, from Christophe Lombard and Frederic Barrat.
       - Ignore probes for virtual afu pci devices from Vaibhav Jain
    
      perf:
       - Export Power8 generic and cache events to sysfs from Sukadev
         Bhattiprolu
       - hv-24x7: Fix usage with chip events, display change in counter
         values, display domain indices in sysfs, eliminate domain suffix in
         event names, from Sukadev Bhattiprolu
    
      Freescale:
       - Updates from Scott: "Highlights include 8xx optimizations, 32-bit
         checksum optimizations, 86xx consolidation, e5500/e6500 cpu
         hotplug, more fman and other dt bits, and minor fixes/cleanup"
    
    * tag 'powerpc-4.6-1' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux: (179 commits)
      powerpc: Fix unrecoverable SLB miss during restore_math()
      powerpc/8xx: Fix do_mtspr_cpu6() build on older compilers
      powerpc/rcpm: Fix build break when SMP=n
      powerpc/book3e-64: Use hardcoded mttmr opcode
      powerpc/fsl/dts: Add "jedec,spi-nor" flash compatible
      powerpc/T104xRDB: add tdm riser card node to device tree
      powerpc32: PAGE_EXEC required for inittext
      powerpc/mpc85xx: Add pcsphy nodes to FManV3 device tree
      powerpc/mpc85xx: Add MDIO bus muxing support to the board device tree(s)
      powerpc/86xx: Introduce and use common dtsi
      powerpc/86xx: Update device tree
      powerpc/86xx: Move dts files to fsl directory
      powerpc/86xx: Switch to kconfig fragments approach
      powerpc/86xx: Update defconfigs
      powerpc/86xx: Consolidate common platform code
      powerpc32: Remove one insn in mulhdu
      powerpc32: small optimisation in flush_icache_range()
      powerpc: Simplify test in __dma_sync()
      powerpc32: move xxxxx_dcache_range() functions inline
      powerpc32: Remove clear_pages() and define clear_page() inline
      ...

commit 6becef7ea04a695f64299238fe13d41e41607469
Author: chenhui zhao <chenhui.zhao@freescale.com>
Date:   Fri Nov 20 17:14:02 2015 +0800

    powerpc/mpc85xx: Add CPU hotplug support for E6500
    
    Support Freescale E6500 core-based platforms, like t4240.
    Support disabling/enabling individual CPU thread dynamically.
    
    Signed-off-by: Chenhui Zhao <chenhui.zhao@freescale.com>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index bdb811116d85..174271ef2767 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -200,6 +200,7 @@ extern void generic_secondary_thread_init(void);
 extern unsigned long __secondary_hold_spinloop;
 extern unsigned long __secondary_hold_acknowledge;
 extern char __secondary_hold;
+extern unsigned int booting_thread_hwid;
 
 extern void __early_start(void);
 #endif /* __ASSEMBLY__ */

commit 2f4f1f815bc6d03ea42d4f67dd1e284525e7524e
Author: chenhui zhao <chenhui.zhao@freescale.com>
Date:   Fri Nov 20 17:14:01 2015 +0800

    powerpc/mpc85xx: Add hotplug support on E5500 and E500MC cores
    
    Freescale E500MC and E5500 core-based platforms, like P4080, T1040,
    support disabling/enabling CPU dynamically.
    This patch adds this feature on those platforms.
    
    Signed-off-by: Chenhui Zhao <chenhui.zhao@freescale.com>
    Signed-off-by: Tang Yuantian <Yuantian.Tang@feescale.com>
    [scottwood: removed unused pr_fmt]
    Signed-off-by: Scott Wood <oss@buserror.net>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 825663c30945..bdb811116d85 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -67,6 +67,9 @@ void generic_cpu_die(unsigned int cpu);
 void generic_set_cpu_dead(unsigned int cpu);
 void generic_set_cpu_up(unsigned int cpu);
 int generic_check_cpu_restart(unsigned int cpu);
+int is_cpu_dead(unsigned int cpu);
+#else
+#define generic_set_cpu_up(i)	do { } while (0)
 #endif
 
 #ifdef CONFIG_PPC64

commit 31639c77e0a7f9f742c813ae697f337b44981ed2
Author: Suresh Warrier <warrier@linux.vnet.ibm.com>
Date:   Thu Dec 17 14:59:04 2015 -0600

    powerpc/smp: Add smp_muxed_ipi_set_message
    
    smp_muxed_ipi_message_pass() invokes smp_ops->cause_ipi, which
    uses an ioremapped address to access registers on the XICS
    interrupt controller to cause the IPI. Because of this real
    mode callers cannot call smp_muxed_ipi_message_pass() for IPI
    messaging.
    
    This patch creates a separate function smp_muxed_ipi_set_message
    just to set the IPI message without the cause_ipi routine.
    After calling this function to set the IPI message, real
    mode callers must cause the IPI by writing to the XICS registers
    directly.
    
    As part of this, we also change smp_muxed_ipi_message_pass
    to call smp_muxed_ipi_set_message to set the message instead
    of doing it directly inside the routine.
    
    Signed-off-by: Suresh Warrier <warrier@linux.vnet.ibm.com>
    Acked-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 9ef9c37cb398..78083ed20792 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -124,6 +124,7 @@ extern const char *smp_ipi_name[];
 /* for irq controllers with only a single ipi */
 extern void smp_muxed_ipi_set_data(int cpu, unsigned long data);
 extern void smp_muxed_ipi_message_pass(int cpu, int msg);
+extern void smp_muxed_ipi_set_message(int cpu, int msg);
 extern irqreturn_t smp_ipi_demux(void);
 
 void smp_init_pSeries(void);

commit bd7f561f76563f0b21701628874d8adc863b0c25
Author: Suresh Warrier <warrier@linux.vnet.ibm.com>
Date:   Thu Dec 17 14:59:03 2015 -0600

    powerpc/smp: Support more IPI messages
    
    This patch increases the number of demuxed messages for a
    controller with a single ipi to 8 for 64-bit systems.
    
    This is required because we want to use the IPI mechanism
    to send messages from a CPU running in KVM real mode in a
    guest to a CPU in the host to take some action. Currently,
    we only support 4 messages and all 4 are already taken.
    
    Define a fifth message PPC_MSG_RM_HOST_ACTION for this
    purpose.
    
    Signed-off-by: Suresh Warrier <warrier@linux.vnet.ibm.com>
    Acked-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 825663c30945..9ef9c37cb398 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -114,6 +114,9 @@ extern int cpu_to_core_id(int cpu);
 #define PPC_MSG_TICK_BROADCAST	2
 #define PPC_MSG_DEBUGGER_BREAK  3
 
+/* This is only used by the powernv kernel */
+#define PPC_MSG_RM_HOST_ACTION	4
+
 /* for irq controllers that have dedicated ipis per message (4) */
 extern int smp_request_message_ipi(int virq, int message);
 extern const char *smp_ipi_name[];

commit a7f4ee1fe93aa9ae191971be9324edb8f9fbcb4a
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Sat Apr 4 19:28:50 2015 +1100

    powerpc: Drop return value of smp_ops->probe()
    
    smp_ops->probe() is currently supposed to return the number of cpus in
    the system.
    
    The last actual usage of the value was removed in May 2007 in e147ec8f1808
    "[POWERPC] Simplify smp_space_timers". We still passed the value around
    until June 2010 when even that was finally removed in c1aa687d499a
    "powerpc: Clean up obsolete code relating to decrementer and timebase".
    
    So drop that requirement, probe() now returns void, and update all
    implementations.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 7c19959cd705..825663c30945 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -42,7 +42,7 @@ struct smp_ops_t {
 #ifdef CONFIG_PPC_SMP_MUXED_IPI
 	void  (*cause_ipi)(int cpu, unsigned long data);
 #endif
-	int   (*probe)(void);
+	void  (*probe)(void);
 	int   (*kick_cpu)(int nr);
 	void  (*setup_cpu)(int nr);
 	void  (*bringup_done)(void);
@@ -174,7 +174,7 @@ static inline void set_hard_smp_processor_id(int cpu, int phys)
 
 extern int smt_enabled_at_boot;
 
-extern int smp_mpic_probe(void);
+extern void smp_mpic_probe(void);
 extern void smp_mpic_setup_cpu(int cpu);
 extern int smp_generic_kick_cpu(int nr);
 extern int smp_generic_cpu_bootable(unsigned int nr);

commit bf4981a00636347ddcef3fc008e4dd979380a851
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Mar 19 15:15:20 2015 +1100

    powerpc: Remove the celleb support
    
    The celleb code has seen no actual development for ~7 years.
    
    We (maintainers) have no access to test hardware, and it is highly
    likely the code has bit-rotted.
    
    As far as we're aware the hardware was never widely available, and is
    certainly no longer available, and no one on the list has shown any
    interest in it over the years.
    
    So remove it. If anyone has one and cares please speak up.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Acked-by: Jeremy Kerr <jk@ozlabs.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index d607df5081a7..7c19959cd705 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -125,7 +125,6 @@ extern irqreturn_t smp_ipi_demux(void);
 
 void smp_init_pSeries(void);
 void smp_init_cell(void);
-void smp_init_celleb(void);
 void smp_setup_cpu_maps(void);
 
 extern int __cpu_disable(void);

commit 8aa989b8fba1428b50a1be771c01285f1de0227b
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Tue Jan 27 16:48:03 2015 +1100

    powerpc: Remove some unused functions
    
    Remove slice_set_psize() which is not used.
    
    It was added in 3a8247cc2c85 "powerpc: Only demote individual slices
    rather than whole process" but was never used.
    
    Remove vsx_assist_exception() which is not used.
    
    It was added in ce48b2100785 "powerpc: Add VSX context save/restore,
    ptrace and signal support" but was never used.
    
    Remove generic_mach_cpu_die() which is not used.
    
    Its last caller was removed in 375f561a4131 "powerpc/powernv: Always go
    into nap mode when CPU is offline".
    
    Remove mpc7448_hpc2_power_off() and mpc7448_hpc2_halt() which are
    unused.
    
    These were introduced in c5d56332fd6c "[POWERPC] Add general support for
    mpc7448hpc2 (Taiga) platform" but were never used.
    
    This was partially found by using a static code analysis program called
    cppcheck.
    
    Signed-off-by: Rickard Strandqvist <rickard_strandqvist@spectrumdigital.se>
    [mpe: Update changelog with details on when/why they are unused]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 5a6614a7f0b2..d607df5081a7 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -64,7 +64,6 @@ DECLARE_PER_CPU(unsigned int, cpu_pvr);
 extern void migrate_irqs(void);
 int generic_cpu_disable(void);
 void generic_cpu_die(unsigned int cpu);
-void generic_mach_cpu_die(void);
 void generic_set_cpu_dead(unsigned int cpu);
 void generic_set_cpu_up(unsigned int cpu);
 int generic_check_cpu_restart(unsigned int cpu);

commit 441c19c8a290f5f1e1b263691641124c84232b6e
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Fri May 23 18:15:25 2014 +1000

    powerpc/kvm/book3s_hv: Rework the secondary inhibit code
    
    As part of the support for split core on POWER8, we want to be able to
    block splitting of the core while KVM VMs are active.
    
    The logic to do that would be exactly the same as the code we currently
    have for inhibiting onlining of secondaries.
    
    Instead of adding an identical mechanism to block split core, rework the
    secondary inhibit code to be a "HV KVM is active" check. We can then use
    that in both the cpu hotplug code and the upcoming split core code.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Acked-by: Alexander Graf <agraf@suse.de>
    Acked-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index ff51046b6466..5a6614a7f0b2 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -68,14 +68,6 @@ void generic_mach_cpu_die(void);
 void generic_set_cpu_dead(unsigned int cpu);
 void generic_set_cpu_up(unsigned int cpu);
 int generic_check_cpu_restart(unsigned int cpu);
-
-extern void inhibit_secondary_onlining(void);
-extern void uninhibit_secondary_onlining(void);
-
-#else /* HOTPLUG_CPU */
-static inline void inhibit_secondary_onlining(void) {}
-static inline void uninhibit_secondary_onlining(void) {}
-
 #endif
 
 #ifdef CONFIG_PPC64

commit 1b67bee129a36c22c17186cc2a9981678e9323ee
Author: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
Date:   Wed Feb 26 05:37:43 2014 +0530

    powerpc: Implement tick broadcast IPI as a fixed IPI message
    
    For scalability and performance reasons, we want the tick broadcast IPIs
    to be handled as efficiently as possible. Fixed IPI messages
    are one of the most efficient mechanisms available - they are faster than
    the smp_call_function mechanism because the IPI handlers are fixed and hence
    they don't involve costly operations such as adding IPI handlers to the target
    CPU's function queue, acquiring locks for synchronization etc.
    
    Luckily we have an unused IPI message slot, so use that to implement
    tick broadcast IPIs efficiently.
    
    Signed-off-by: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    [Functions renamed to tick_broadcast* and Changelog modified by
     Preeti U. Murthy<preeti@linux.vnet.ibm.com>]
    Signed-off-by: Preeti U. Murthy <preeti@linux.vnet.ibm.com>
    Acked-by: Geoff Levand <geoff@infradead.org> [For the PS3 part]
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 9f7356bf6482..ff51046b6466 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -120,7 +120,7 @@ extern int cpu_to_core_id(int cpu);
  * in /proc/interrupts will be wrong!!! --Troy */
 #define PPC_MSG_CALL_FUNCTION   0
 #define PPC_MSG_RESCHEDULE      1
-#define PPC_MSG_UNUSED		2
+#define PPC_MSG_TICK_BROADCAST	2
 #define PPC_MSG_DEBUGGER_BREAK  3
 
 /* for irq controllers that have dedicated ipis per message (4) */

commit 402d9a1e02f7215628f13b7c80ff3e98c3a0cadc
Author: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
Date:   Wed Feb 26 05:37:29 2014 +0530

    powerpc: Free up the slot of PPC_MSG_CALL_FUNC_SINGLE IPI message
    
    The IPI handlers for both PPC_MSG_CALL_FUNC and PPC_MSG_CALL_FUNC_SINGLE map
    to a common implementation - generic_smp_call_function_single_interrupt(). So,
    we can consolidate them and save one of the IPI message slots, (which are
    precious on powerpc, since only 4 of those slots are available).
    
    So, implement the functionality of PPC_MSG_CALL_FUNC_SINGLE using
    PPC_MSG_CALL_FUNC itself and release its IPI message slot, so that it can be
    used for something else in the future, if desired.
    
    Signed-off-by: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Signed-off-by: Preeti U. Murthy <preeti@linux.vnet.ibm.com>
    Acked-by: Geoff Levand <geoff@infradead.org> [For the PS3 part]
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 084e0807db98..9f7356bf6482 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -120,7 +120,7 @@ extern int cpu_to_core_id(int cpu);
  * in /proc/interrupts will be wrong!!! --Troy */
 #define PPC_MSG_CALL_FUNCTION   0
 #define PPC_MSG_RESCHEDULE      1
-#define PPC_MSG_CALL_FUNC_SINGLE	2
+#define PPC_MSG_UNUSED		2
 #define PPC_MSG_DEBUGGER_BREAK  3
 
 /* for irq controllers that have dedicated ipis per message (4) */

commit 3eb906c6b6c123513718e7742a96a4189f900382
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Nov 20 11:05:01 2013 +1100

    powerpc: Make cpu_to_chip_id() available when SMP=n
    
    Up until now we have only used cpu_to_chip_id() in the topology code,
    which is only used on SMP builds. However my recent commit a4da0d5
    "Implement arch_get_random_long/int() for powernv" added a usage when
    SMP=n, breaking the build.
    
    Move cpu_to_chip_id() into prom.c so it is available for SMP=n builds.
    
    We would move the extern to prom.h, but that breaks the include in
    topology.h. Instead we leave it in smp.h, but move it out of the
    CONFIG_SMP #ifdef. We also need to include asm/smp.h in rng.c, because
    the linux version skips asm/smp.h on UP. What a mess.
    
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 98da78e0c2c0..084e0807db98 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -33,6 +33,7 @@ extern int boot_cpuid;
 extern int spinning_secondaries;
 
 extern void cpu_die(void);
+extern int cpu_to_chip_id(int cpu);
 
 #ifdef CONFIG_SMP
 
@@ -112,7 +113,6 @@ static inline struct cpumask *cpu_core_mask(int cpu)
 }
 
 extern int cpu_to_core_id(int cpu);
-extern int cpu_to_chip_id(int cpu);
 
 /* Since OpenPIC has only 4 IPIs, we use slightly different message numbers.
  *

commit 15863ff3b8dae4cacd831ce10aa34992e9ababb0
Author: Vasant Hegde <hegdevasant@linux.vnet.ibm.com>
Date:   Mon Aug 12 17:35:57 2013 +0530

    powerpc: Make chip-id information available to userspace
    
    So far "/sys/devices/system/cpu/cpuX/topology/physical_package_id"
    was always default (-1) on ppc64 architecture.
    
    Now, some systems have an ibm,chip-id property in the cpu nodes in
    the device tree. On these systems, we now use this information to
    display physical_package_id.
    
    Signed-off-by: Vasant Hegde <hegdevasant@linux.vnet.ibm.com>
    Signed-off-by: Shivaprasad G Bhat <sbhat@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 9a5e71b0aea4..98da78e0c2c0 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -112,6 +112,7 @@ static inline struct cpumask *cpu_core_mask(int cpu)
 }
 
 extern int cpu_to_core_id(int cpu);
+extern int cpu_to_chip_id(int cpu);
 
 /* Since OpenPIC has only 4 IPIs, we use slightly different message numbers.
  *

commit 3cd852502316d42e3e75859e92d9f0a952bb55a2
Author: Andy Fleming <afleming@freescale.com>
Date:   Mon Aug 5 14:58:34 2013 -0500

    powerpc: Add smp_generic_cpu_bootable
    
    Cell and PSeries both implemented their own versions of a
    cpu_bootable smp_op which do the same thing (well, the PSeries
    one has support for more than 2 threads). Copy the PSeries one
    to generic code, and rename it smp_generic_cpu_bootable.
    
    Signed-off-by: Andy Fleming <afleming@freescale.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 48cfc858abd6..9a5e71b0aea4 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -186,6 +186,8 @@ extern int smt_enabled_at_boot;
 extern int smp_mpic_probe(void);
 extern void smp_mpic_setup_cpu(int cpu);
 extern int smp_generic_kick_cpu(int nr);
+extern int smp_generic_cpu_bootable(unsigned int nr);
+
 
 extern void smp_generic_give_timebase(void);
 extern void smp_generic_take_timebase(void);

commit 3be7db6ab45b21345386d1a466da133b19cde5e4
Author: Robert Jennings <rcj@linux.vnet.ibm.com>
Date:   Wed Jul 24 20:13:21 2013 -0500

    powerpc: VPHN topology change updates all siblings
    
    When an associativity level change is found for one thread, the
    siblings threads need to be updated as well.  This is done today
    for PRRN in stage_topology_update() but is missing for VPHN in
    update_cpu_associativity_changes_mask().  This patch will correctly
    update all thread siblings during a topology change.
    
    Without this patch a topology update can result in a CPU in
    init_sched_groups_power() getting stuck indefinitely in a loop.
    
    This loop is built in build_sched_groups(). As a result of the thread
    moving to a node separate from its siblings the struct sched_group will
    have its next pointer set to point to itself rather than the sched_group
    struct of the next thread.  This happens because we have a domain without
    the SD_OVERLAP flag, which is correct, and a topology that doesn't conform
    with reality (threads on the same core assigned to different numa nodes).
    When this list is traversed by init_sched_groups_power() it will reach
    the thread's sched_group structure and loop indefinitely; the cpu will
    be stuck at this point.
    
    The bug was exposed when VPHN was enabled in commit b7abef0 (v3.9).
    
    Cc: <stable@vger.kernel.org> [v3.9+]
    Reported-by: Jan Stancek <jstancek@redhat.com>
    Signed-off-by: Robert Jennings <rcj@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index ffbaabebcdca..48cfc858abd6 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -145,6 +145,10 @@ extern void __cpu_die(unsigned int cpu);
 #define smp_setup_cpu_maps()
 static inline void inhibit_secondary_onlining(void) {}
 static inline void uninhibit_secondary_onlining(void) {}
+static inline const struct cpumask *cpu_sibling_mask(int cpu)
+{
+	return cpumask_of(cpu);
+}
 
 #endif /* CONFIG_SMP */
 

commit 3cc33d50f52521760da29ebd9db239741da7f21a
Author: Paul Mackerras <paulus@samba.org>
Date:   Mon Apr 15 20:28:01 2013 +0000

    powerpc: Fix build errors with UP configs in HV-style KVM
    
    This fixes these errors when building UP with CONFIG_KVM_BOOK3S_64_HV=y:
    
    arch/powerpc/kvm/book3s_hv.c:1855:2: error: implicit declaration of function 'inhibit_secondary_onlining' [-Werror=implicit-function-declaration]
    arch/powerpc/kvm/book3s_hv.c:1862:2: error: implicit declaration of function 'uninhibit_secondary_onlining' [-Werror=implicit-function-declaration]
    cc1: all warnings being treated as errors
    
    and this error (with CONFIG_KVM_BOOK3S_64=m, or a vmlinux link error
    with CONFIG_KVM_BOOK3S_64=y):
    
    ERROR: "smp_send_reschedule" [arch/powerpc/kvm/kvm.ko] undefined!
    make[2]: *** [__modpost] Error 1
    
    The fix for the link error is suboptimal; ideally we want a self_ipi()
    function from irq.c, connected at least to the MPIC code, to initiate
    an IPI to this cpu.  The fix here at least lets the code build, and it
    will work, just with interrupts being delayed sometimes.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 195ce2ac5691..ffbaabebcdca 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -143,6 +143,8 @@ extern void __cpu_die(unsigned int cpu);
 /* for UP */
 #define hard_smp_processor_id()		get_hard_smp_processor_id(0)
 #define smp_setup_cpu_maps()
+static inline void inhibit_secondary_onlining(void) {}
+static inline void uninhibit_secondary_onlining(void) {}
 
 #endif /* CONFIG_SMP */
 

commit cad5cef62a5a0c525d39118d2e94b6e2034d5e05
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Fri Dec 21 14:04:10 2012 -0800

    POWERPC: drivers: remove __dev* attributes.
    
    CONFIG_HOTPLUG is going away as an option.  As a result, the __dev*
    markings need to be removed.
    
    This change removes the use of __devinit, __devexit_p, __devinitdata,
    __devinitconst, and __devexit from these drivers.
    
    Based on patches originally written by Bill Pemberton, but redone by me
    in order to handle some of the coding style issues better, by hand.
    
    Cc: Bill Pemberton <wfp5p@virginia.edu>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 5a4e437c238d..195ce2ac5691 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -54,8 +54,8 @@ struct smp_ops_t {
 
 extern void smp_send_debugger_break(void);
 extern void start_secondary_resume(void);
-extern void __devinit smp_generic_give_timebase(void);
-extern void __devinit smp_generic_take_timebase(void);
+extern void smp_generic_give_timebase(void);
+extern void smp_generic_take_timebase(void);
 
 DECLARE_PER_CPU(unsigned int, cpu_pvr);
 

commit 0588000eac9ba4178cebade437da3b28e8fad48f
Merge: 8b5869ad85f7 81c52c56e2b4
Author: Alexander Graf <agraf@suse.de>
Date:   Wed Oct 31 13:36:18 2012 +0100

    Merge commit 'origin/queue' into for-queue
    
    Conflicts:
            arch/powerpc/include/asm/Kbuild
            arch/powerpc/include/uapi/asm/Kbuild

commit 512691d4907d7cf4b8d05c6f8572d1fa60ccec20
Author: Paul Mackerras <paulus@samba.org>
Date:   Mon Oct 15 01:15:41 2012 +0000

    KVM: PPC: Book3S HV: Allow KVM guests to stop secondary threads coming online
    
    When a Book3S HV KVM guest is running, we need the host to be in
    single-thread mode, that is, all of the cores (or at least all of
    the cores where the KVM guest could run) to be running only one
    active hardware thread.  This is because of the hardware restriction
    in POWER processors that all of the hardware threads in the core
    must be in the same logical partition.  Complying with this restriction
    is much easier if, from the host kernel's point of view, only one
    hardware thread is active.
    
    This adds two hooks in the SMP hotplug code to allow the KVM code to
    make sure that secondary threads (i.e. hardware threads other than
    thread 0) cannot come online while any KVM guest exists.  The KVM
    code still has to check that any core where it runs a guest has the
    secondary threads offline, but having done that check it can now be
    sure that they will not come online while the guest is running.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index ebc24dc5b1a1..b625a1a9ad16 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -66,6 +66,14 @@ void generic_cpu_die(unsigned int cpu);
 void generic_mach_cpu_die(void);
 void generic_set_cpu_dead(unsigned int cpu);
 int generic_check_cpu_restart(unsigned int cpu);
+
+extern void inhibit_secondary_onlining(void);
+extern void uninhibit_secondary_onlining(void);
+
+#else /* HOTPLUG_CPU */
+static inline void inhibit_secondary_onlining(void) {}
+static inline void uninhibit_secondary_onlining(void) {}
+
 #endif
 
 #ifdef CONFIG_PPC64

commit d0832a75075b1119635e0f48549e378040cf5e67
Author: Zhao Chenhui <chenhui.zhao@freescale.com>
Date:   Fri Jul 20 20:42:36 2012 +0800

    powerpc/85xx: add HOTPLUG_CPU support
    
    Add support to disable and re-enable individual cores at runtime on
    MPC85xx/QorIQ SMP machines. Currently support e500v1/e500v2 core.
    
    MPC85xx machines use ePAPR spin-table in boot page for CPU kick-off.  This
    patch uses the boot page from bootloader to boot core at runtime.  It
    supports 32-bit and 36-bit physical address.
    
    Signed-off-by: Li Yang <leoli@freescale.com>
    Signed-off-by: Jin Qing <b24347@freescale.com>
    Signed-off-by: Zhao Chenhui <chenhui.zhao@freescale.com>
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index ce8e2bdf84ed..e807e9d8e3f7 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -191,6 +191,7 @@ extern unsigned long __secondary_hold_spinloop;
 extern unsigned long __secondary_hold_acknowledge;
 extern char __secondary_hold;
 
+extern void __early_start(void);
 #endif /* __ASSEMBLY__ */
 
 #endif /* __KERNEL__ */

commit ae5cab476342bc7311945cf89d5cbd8d57f4a5a9
Author: Zhao Chenhui <chenhui.zhao@freescale.com>
Date:   Fri Jul 20 20:42:34 2012 +0800

    powerpc/smp: add generic_set_cpu_up() to set cpu_state as CPU_UP_PREPARE
    
    In the case of cpu hotplug, the cpu_state should be set to CPU_UP_PREPARE
    when kicking cpu.  Otherwise, the cpu_state is always CPU_DEAD after
    calling generic_set_cpu_dead(), which makes the delay in generic_cpu_die()
    not happen.
    
    Signed-off-by: Zhao Chenhui <chenhui.zhao@freescale.com>
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index ebc24dc5b1a1..ce8e2bdf84ed 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -65,6 +65,7 @@ int generic_cpu_disable(void);
 void generic_cpu_die(unsigned int cpu);
 void generic_mach_cpu_die(void);
 void generic_set_cpu_dead(unsigned int cpu);
+void generic_set_cpu_up(unsigned int cpu);
 int generic_check_cpu_restart(unsigned int cpu);
 #endif
 

commit 1d9a47315042606b4217691bcea36cfa6ccbde66
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Wed Mar 21 18:23:27 2012 +0000

    powerpc: Random little legacy iSeries removal tidy ups
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index adba970ce918..ebc24dc5b1a1 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -122,7 +122,6 @@ extern void smp_muxed_ipi_set_data(int cpu, unsigned long data);
 extern void smp_muxed_ipi_message_pass(int cpu, int msg);
 extern irqreturn_t smp_ipi_demux(void);
 
-void smp_init_iSeries(void);
 void smp_init_pSeries(void);
 void smp_init_cell(void);
 void smp_init_celleb(void);

commit fb82b83970a32263698e54a8779d2ce88cd3b060
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon Sep 19 17:44:49 2011 +0000

    powerpc/smp: More generic support for "soft hotplug"
    
    This adds more generic support for doing CPU hotplug with a simple
    idle loop and no actual reset of the processors. The generic
    smp_generic_kick_cpu() does the hotplug bringup trick if the PACA
    shows that the CPU has already been started at boot and we provide
    an accessor for the CPU state.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 15a70b7f638b..adba970ce918 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -65,6 +65,7 @@ int generic_cpu_disable(void);
 void generic_cpu_die(unsigned int cpu);
 void generic_mach_cpu_die(void);
 void generic_set_cpu_dead(unsigned int cpu);
+int generic_check_cpu_restart(unsigned int cpu);
 #endif
 
 #ifdef CONFIG_PPC64

commit 3d97a619acbb2c8a7a9a7da08c2d3041dfdd241f
Author: Scott Wood <scottwood@freescale.com>
Date:   Wed Jun 22 11:19:49 2011 +0000

    powerpc/book3e-64: Reraise doorbell when masked by soft-irq-disable
    
    Signed-off-by: Scott Wood <scottwood@freescale.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index b2a4c2d0b7f2..15a70b7f638b 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -119,7 +119,6 @@ extern const char *smp_ipi_name[];
 /* for irq controllers with only a single ipi */
 extern void smp_muxed_ipi_set_data(int cpu, unsigned long data);
 extern void smp_muxed_ipi_message_pass(int cpu, int msg);
-extern void smp_muxed_ipi_resend(void);
 extern irqreturn_t smp_ipi_demux(void);
 
 void smp_init_iSeries(void);

commit 7ac87abb8166b99584149fcfb2efef5773a078e9
Author: Matt Evans <matt@ozlabs.org>
Date:   Wed May 25 18:09:12 2011 +0000

    powerpc: Fix early boot accounting of CPUs
    
    smp_release_cpus() waits for all cpus (including the bootcpu) due to an
    off-by-one count on boot_cpu_count (which is all CPUs).  This patch replaces
    that with spinning_secondaries (which is all secondary CPUs).
    
    Signed-off-by: Matt Evans <matt@ozlabs.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 11eb404b5606..b2a4c2d0b7f2 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -30,7 +30,7 @@
 #include <asm/percpu.h>
 
 extern int boot_cpuid;
-extern int boot_cpu_count;
+extern int spinning_secondaries;
 
 extern void cpu_die(void);
 

commit 7ef71d753ea0286bfeb4251b9ba592716ebdd9e8
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 24 20:34:18 2011 +0000

    powerpc/cell: Use common smp ipi actions
    
    The cell iic interrupt controller has enough software caused interrupts
    to use a unique interrupt for each of the 4 messages powerpc uses.
    This means each interrupt gets its own irq action/data combination.
    
    Use the seperate, optimized, arch common ipi action functions
    registered via the helper smp_request_message_ipi instead passing the
    message as action data to a single action that then demultipexes to
    the required acton via a switch statement.
    
    smp_request_message_ipi will register the action as IRQF_PER_CPU
    and IRQF_DISABLED, and WARN if the allocation fails for some reason,
    so no need to print on that failure.  It will return positive if
    the message will not be used by the kernel, in which case we can
    free the virq.
    
    In addition to elimiating inefficient code, this also corrects the
    error that a kernel built with kexec but without a debugger would
    not register the ipi for kdump to notify the other cpus of a crash.
    
    This also restores the debugger action to be static to kernel/smp.c.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 880b8c1e6e53..11eb404b5606 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -191,8 +191,6 @@ extern unsigned long __secondary_hold_spinloop;
 extern unsigned long __secondary_hold_acknowledge;
 extern char __secondary_hold;
 
-extern irqreturn_t debug_ipi_action(int irq, void *data);
-
 #endif /* __ASSEMBLY__ */
 
 #endif /* __KERNEL__ */

commit 1ece355b6825b7c61d1dc39a5c6cf49dc746e193
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 10 19:29:42 2011 +0000

    powerpc: Add kconfig for muxed smp ipi support
    
    Compile the new smp ipi mux and demux code only if a platform
    will make use of it.  The new config is selected as required.
    
    The new cause_ipi smp op is only available conditionally to point out
    configs where the select is required; this makes setting the op an
    immediate fail instead of a deferred unresolved symbol at link.
    
    This also creates a new config for power surge powermac upgrade support
    that can be disabled in expert mode but is default on.
    
    I also removed the depends / default y on CONFIG_XICS since it is selected
    by PSERIES.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 26f861560c51..880b8c1e6e53 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -38,7 +38,9 @@ extern void cpu_die(void);
 
 struct smp_ops_t {
 	void  (*message_pass)(int cpu, int msg);
+#ifdef CONFIG_PPC_SMP_MUXED_IPI
 	void  (*cause_ipi)(int cpu, unsigned long data);
+#endif
 	int   (*probe)(void);
 	int   (*kick_cpu)(int nr);
 	void  (*setup_cpu)(int nr);

commit 23d72bfd8f9f24aa9efafed3586a99f5669c23d7
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 10 19:29:39 2011 +0000

    powerpc: Consolidate ipi message mux and demux
    
    Consolidate the mux and demux of ipi messages into smp.c and call
    a new smp_ops callback to actually trigger the ipi.
    
    The powerpc architecture code is optimised for having 4 distinct
    ipi triggers, which are mapped to 4 distinct messages (ipi many, ipi
    single, scheduler ipi, and enter debugger).  However, several interrupt
    controllers only provide a single software triggered interrupt that
    can be delivered to each cpu.  To resolve this limitation, each smp_ops
    implementation created a per-cpu variable that is manipulated with atomic
    bitops.  Since these lines will be contended they are optimialy marked as
    shared_aligned and take a full cache line for each cpu.  Distro kernels
    may have 2 or 3 of these in their config, each taking per-cpu space
    even though at most one will be in use.
    
    This consolidation removes smp_message_recv and replaces the single call
    actions cases with direct calls from the common message recognition loop.
    The complicated debugger ipi case with its muxed crash handling code is
    moved to debug_ipi_action which is now called from the demux code (instead
    of the multi-message action calling smp_message_recv).
    
    I put a call to reschedule_action to increase the likelyhood of correctly
    merging the anticipated scheduler_ipi() hook coming from the scheduler
    tree; that single required call can be inlined later.
    
    The actual message decode is a copy of the old pseries xics code with its
    memory barriers and cache line spacing, augmented with a per-cpu unsigned
    long based on the book-e doorbell code.  The optional data is set via a
    callback from the implementation and is passed to the new cause-ipi hook
    along with the logical cpu number.  While currently only the doorbell
    implemntation uses this data it should be almost zero cost to retrieve and
    pass it -- it adds a single register load for the argument from the same
    cache line to which we just completed a store and the register is dead
    on return from the call.  I extended the data element from unsigned int
    to unsigned long in case some other code wanted to associate a pointer.
    
    The doorbell check_self is replaced by a call to smp_muxed_ipi_resend,
    conditioned on the CPU_DBELL feature.  The ifdef guard could be relaxed
    to CONFIG_SMP but I left it with BOOKE for now.
    
    Also, the doorbell interrupt vector for book-e was not calling irq_enter
    and irq_exit, which throws off cpu accounting and causes code to not
    realize it is running in interrupt context.  Add the missing calls.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 6f7c95c0027a..26f861560c51 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -20,6 +20,7 @@
 #include <linux/threads.h>
 #include <linux/cpumask.h>
 #include <linux/kernel.h>
+#include <linux/irqreturn.h>
 
 #ifndef __ASSEMBLY__
 
@@ -37,6 +38,7 @@ extern void cpu_die(void);
 
 struct smp_ops_t {
 	void  (*message_pass)(int cpu, int msg);
+	void  (*cause_ipi)(int cpu, unsigned long data);
 	int   (*probe)(void);
 	int   (*kick_cpu)(int nr);
 	void  (*setup_cpu)(int nr);
@@ -49,7 +51,6 @@ struct smp_ops_t {
 };
 
 extern void smp_send_debugger_break(void);
-extern void smp_message_recv(int);
 extern void start_secondary_resume(void);
 extern void __devinit smp_generic_give_timebase(void);
 extern void __devinit smp_generic_take_timebase(void);
@@ -109,13 +110,16 @@ extern int cpu_to_core_id(int cpu);
 #define PPC_MSG_CALL_FUNC_SINGLE	2
 #define PPC_MSG_DEBUGGER_BREAK  3
 
-/*
- * irq controllers that have dedicated ipis per message and don't
- * need additional code in the action handler may use this
- */
+/* for irq controllers that have dedicated ipis per message (4) */
 extern int smp_request_message_ipi(int virq, int message);
 extern const char *smp_ipi_name[];
 
+/* for irq controllers with only a single ipi */
+extern void smp_muxed_ipi_set_data(int cpu, unsigned long data);
+extern void smp_muxed_ipi_message_pass(int cpu, int msg);
+extern void smp_muxed_ipi_resend(void);
+extern irqreturn_t smp_ipi_demux(void);
+
 void smp_init_iSeries(void);
 void smp_init_pSeries(void);
 void smp_init_cell(void);
@@ -185,6 +189,8 @@ extern unsigned long __secondary_hold_spinloop;
 extern unsigned long __secondary_hold_acknowledge;
 extern char __secondary_hold;
 
+extern irqreturn_t debug_ipi_action(int irq, void *data);
+
 #endif /* __ASSEMBLY__ */
 
 #endif /* __KERNEL__ */

commit 17f9c8a73bac2c7dfe28a520516ea6b8bbbe977e
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 10 19:29:35 2011 +0000

    powerpc: Move smp_ops_t from machdep.h to smp.h
    
    I can't see any reason these functions are needed by machdep.h
    and they are all hidden by CONFIG_SMP with no UP alternative.
    
    Also move the declarations for the fallback timebase ops, which
    are used to fill in the smp ops.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 91472c56800f..6f7c95c0027a 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -35,9 +35,24 @@ extern void cpu_die(void);
 
 #ifdef CONFIG_SMP
 
+struct smp_ops_t {
+	void  (*message_pass)(int cpu, int msg);
+	int   (*probe)(void);
+	int   (*kick_cpu)(int nr);
+	void  (*setup_cpu)(int nr);
+	void  (*bringup_done)(void);
+	void  (*take_timebase)(void);
+	void  (*give_timebase)(void);
+	int   (*cpu_disable)(void);
+	void  (*cpu_die)(unsigned int nr);
+	int   (*cpu_bootable)(unsigned int nr);
+};
+
 extern void smp_send_debugger_break(void);
 extern void smp_message_recv(int);
 extern void start_secondary_resume(void);
+extern void __devinit smp_generic_give_timebase(void);
+extern void __devinit smp_generic_take_timebase(void);
 
 DECLARE_PER_CPU(unsigned int, cpu_pvr);
 

commit e04763713286b1e00e1c2a33fe2741caf9470f2b
Author: Milton Miller <miltonm@bga.com>
Date:   Tue May 10 19:29:06 2011 +0000

    powerpc: Remove call sites of MSG_ALL_BUT_SELF
    
    The only user of MSG_ALL_BUT_SELF in the whole kernel tree is powerpc,
    and it only uses it to start the debugger. Both debuggers always call
    smp_send_debugger_break with MSG_ALL_BUT_SELF, and only mpic can do
    anything more optimal than a loop over all online cpus, but all message
    passing implementations have to code for this special delivery target.
    
    Convert smp_send_debugger_break to take void and loop calling the smp_ops
    message_pass function for each of the other cpus in the online cpumask.
    
    Use raw_smp_processor_id() because we are either entering the debugger
    or trying to start kdump and the additional warning it not useful were
    it to trigger.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 50873493a97c..91472c56800f 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -35,7 +35,7 @@ extern void cpu_die(void);
 
 #ifdef CONFIG_SMP
 
-extern void smp_send_debugger_break(int cpu);
+extern void smp_send_debugger_break(void);
 extern void smp_message_recv(int);
 extern void start_secondary_resume(void);
 

commit de300974761d92f71cb583730ac9e1d4eb1b7156
Author: Michael Ellerman <michael@ozlabs.org>
Date:   Mon Apr 11 21:46:19 2011 +0000

    powerpc/smp: smp_ops->kick_cpu() should be able to fail
    
    When we start a cpu we use smp_ops->kick_cpu(), which currently
    returns void, it should be able to fail. Convert it to return
    int, and update all uses.
    
    Convert all the current error cases to return -ENOENT, which is
    what would eventually be returned by __cpu_up() currently when
    it doesn't detect the cpu as coming up in time.
    
    Signed-off-by: Michael Ellerman <michael@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index bb4c033a8fb0..50873493a97c 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -150,7 +150,7 @@ extern int smt_enabled_at_boot;
 
 extern int smp_mpic_probe(void);
 extern void smp_mpic_setup_cpu(int cpu);
-extern void smp_generic_kick_cpu(int nr);
+extern int smp_generic_kick_cpu(int nr);
 
 extern void smp_generic_give_timebase(void);
 extern void smp_generic_take_timebase(void);

commit 9d07bc841c9779b4d7902e417f4e509996ce805d
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Mar 16 14:54:35 2011 +1100

    powerpc: Properly handshake CPUs going out of boot spin loop
    
    We need to wait a bit for them to have done their CPU setup
    or we might end up with translation and EE on with different
    LPCR values between threads
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index a902a0d3ae0d..bb4c033a8fb0 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -29,6 +29,7 @@
 #include <asm/percpu.h>
 
 extern int boot_cpuid;
+extern int boot_cpu_count;
 
 extern void cpu_die(void);
 

commit 105765f451d3ff007bb4ae3761e825686d9615db
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Apr 1 09:23:37 2011 +1100

    powerpc/smp: Don't expose per-cpu "cpu_state" array
    
    Instead, keep it static, expose an accessor and use that from
    the PowerMac code. Avoids easy namespace collisions and will
    make it easier to consolidate with other implementations.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 7e997715bf1e..a902a0d3ae0d 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -45,7 +45,7 @@ extern void migrate_irqs(void);
 int generic_cpu_disable(void);
 void generic_cpu_die(unsigned int cpu);
 void generic_mach_cpu_die(void);
-DECLARE_PER_CPU(int, cpu_state);
+void generic_set_cpu_dead(unsigned int cpu);
 #endif
 
 #ifdef CONFIG_PPC64

commit 1c91cc570576dfd0f288d664c095d64d11aaace4
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Feb 11 13:05:17 2011 +1100

    powerpc/pmac/smp: Rename fixup_irqs() to migrate_irqs() and use it on ppc32
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 9fe559785b39..7e997715bf1e 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -41,7 +41,7 @@ extern void start_secondary_resume(void);
 DECLARE_PER_CPU(unsigned int, cpu_pvr);
 
 #ifdef CONFIG_HOTPLUG_CPU
-extern void fixup_irqs(const struct cpumask *map);
+extern void migrate_irqs(void);
 int generic_cpu_disable(void);
 void generic_cpu_die(unsigned int cpu);
 void generic_mach_cpu_die(void);

commit fb49f864c3c3f8ac5b68563774171fe43634ffeb
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Feb 11 14:09:32 2011 +1100

    powerpc/pmac/smp: Fix 32-bit PowerMac cpu_die
    
    Use generic cpu_state, call idle_task_exit() properly, and
    remove smp_core99_cpu_die() which isn't useful, the generic
    function does the job just fine.

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index a629b6fef882..9fe559785b39 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -45,6 +45,7 @@ extern void fixup_irqs(const struct cpumask *map);
 int generic_cpu_disable(void);
 void generic_cpu_die(unsigned int cpu);
 void generic_mach_cpu_die(void);
+DECLARE_PER_CPU(int, cpu_state);
 #endif
 
 #ifdef CONFIG_PPC64

commit b527d07114fdab83f39040c69b4b0a4b1b232c16
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Feb 11 12:46:41 2011 +1100

    powerpc/smp: Remove unused generic_cpu_enable()
    
    Nobody uses it, besides we should always use the normal __cpu_up
    path anyways
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 1de0e97a394f..a629b6fef882 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -43,7 +43,6 @@ DECLARE_PER_CPU(unsigned int, cpu_pvr);
 #ifdef CONFIG_HOTPLUG_CPU
 extern void fixup_irqs(const struct cpumask *map);
 int generic_cpu_disable(void);
-int generic_cpu_enable(unsigned int cpu);
 void generic_cpu_die(unsigned int cpu);
 void generic_mach_cpu_die(void);
 #endif

commit fa3f82c8bb7acbe049ea71f258b3ae0a33d9d40b
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Feb 10 18:45:24 2011 +1100

    powerpc/smp: soft-replugged CPUs must go back to start_secondary
    
    Various thing are torn down when a CPU is hot-unplugged. That CPU
    is expected to go back to start_secondary when re-plugged to re
    initialize everything, such as clock sources, maps, ...
    
    Some implementations just return from cpu_die() callback
    in the idle loop when the CPU is "re-plugged". This is not enough.
    
    We fix it using a little asm trampoline which resets the stack
    and calls back into start_secondary as if we were all fresh from
    boot. The trampoline already existed on ppc64, but we add it for
    ppc32
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 66e237bbe15f..1de0e97a394f 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -36,6 +36,7 @@ extern void cpu_die(void);
 
 extern void smp_send_debugger_break(int cpu);
 extern void smp_message_recv(int);
+extern void start_secondary_resume(void);
 
 DECLARE_PER_CPU(unsigned int, cpu_pvr);
 

commit cc1ba8ea6dde3f049b2b365d8fdc13976aee25cb
Author: Anton Blanchard <anton@samba.org>
Date:   Mon Apr 26 15:32:41 2010 +0000

    powerpc/cpumask: Dynamically allocate cpu_sibling_map and cpu_core_map cpumasks
    
    Dynamically allocate cpu_sibling_map and cpu_core_map cpumasks.
    
    We don't need to set_cpu_online() the boot cpu in smp_prepare_boot_cpu,
    init/main.c does it for us.
    
    We also postpone setting of the boot cpu in cpu_sibling_map and cpu_core_map
    until when the memory allocator is available (smp_prepare_cpus), similar
    to x86.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 4d332296c40d..66e237bbe15f 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -68,8 +68,19 @@ static inline void set_hard_smp_processor_id(int cpu, int phys)
 }
 #endif
 
-DECLARE_PER_CPU(cpumask_t, cpu_sibling_map);
-DECLARE_PER_CPU(cpumask_t, cpu_core_map);
+DECLARE_PER_CPU(cpumask_var_t, cpu_sibling_map);
+DECLARE_PER_CPU(cpumask_var_t, cpu_core_map);
+
+static inline struct cpumask *cpu_sibling_mask(int cpu)
+{
+	return per_cpu(cpu_sibling_map, cpu);
+}
+
+static inline struct cpumask *cpu_core_mask(int cpu)
+{
+	return per_cpu(cpu_core_map, cpu);
+}
+
 extern int cpu_to_core_id(int cpu);
 
 /* Since OpenPIC has only 4 IPIs, we use slightly different message numbers.
@@ -93,7 +104,6 @@ void smp_init_pSeries(void);
 void smp_init_cell(void);
 void smp_init_celleb(void);
 void smp_setup_cpu_maps(void);
-void smp_setup_cpu_sibling_map(void);
 
 extern int __cpu_disable(void);
 extern void __cpu_die(unsigned int cpu);

commit b6decb707952c678d110699abb5ed86d45ca6927
Author: Anton Blanchard <anton@samba.org>
Date:   Mon Apr 26 15:32:35 2010 +0000

    powerpc/cpumask: Convert fixup_irqs to new cpumask API
    
    Use new cpumask_* functions, and dynamically allocate cpumask in fixup_irqs.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 1d3b270d3083..4d332296c40d 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -40,7 +40,7 @@ extern void smp_message_recv(int);
 DECLARE_PER_CPU(unsigned int, cpu_pvr);
 
 #ifdef CONFIG_HOTPLUG_CPU
-extern void fixup_irqs(cpumask_t map);
+extern void fixup_irqs(const struct cpumask *map);
 int generic_cpu_disable(void);
 int generic_cpu_enable(unsigned int cpu);
 void generic_cpu_die(unsigned int cpu);

commit 6b7487fc6517736a6e32ccc0f8b46109c1b998ec
Author: Tejun Heo <tj@kernel.org>
Date:   Thu Oct 29 22:34:14 2009 +0900

    percpu: make percpu symbols in powerpc unique
    
    This patch updates percpu related symbols in powerpc such that percpu
    symbols are unique and don't clash with local symbols.  This serves
    two purposes of decreasing the possibility of global percpu symbol
    collision and allowing dropping per_cpu__ prefix from percpu symbols.
    
    * arch/powerpc/kernel/perf_callchain.c: s/callchain/cpu_perf_callchain/
    
    * arch/powerpc/kernel/setup-common.c: s/pvr/cpu_pvr/
    
    * arch/powerpc/platforms/pseries/dtl.c: s/dtl/cpu_dtl/
    
    * arch/powerpc/platforms/cell/interrupt.c: s/iic/cpu_iic/
    
    Partly based on Rusty Russell's "alloc_percpu: rename percpu vars
    which cause name clashes" patch.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: linuxppc-dev@ozlabs.org

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index d9ea8d39c342..1d3b270d3083 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -37,7 +37,7 @@ extern void cpu_die(void);
 extern void smp_send_debugger_break(int cpu);
 extern void smp_message_recv(int);
 
-DECLARE_PER_CPU(unsigned int, pvr);
+DECLARE_PER_CPU(unsigned int, cpu_pvr);
 
 #ifdef CONFIG_HOTPLUG_CPU
 extern void fixup_irqs(cpumask_t map);

commit 0748bd01773395003208996c4c0b3f80caf80976
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Thu Sep 24 09:34:46 2009 -0600

    cpumask: remove arch_send_call_function_ipi
    
    Now everyone is converted to arch_send_call_function_ipi_mask, remove
    the shim and the #defines.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 1491bfe822d9..d9ea8d39c342 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -147,7 +147,6 @@ extern struct smp_ops_t *smp_ops;
 
 extern void arch_send_call_function_single_ipi(int cpu);
 extern void arch_send_call_function_ipi_mask(const struct cpumask *mask);
-#define arch_send_call_function_ipi_mask arch_send_call_function_ipi_mask
 
 /* Definitions relative to the secondary CPU spin loop
  * and entry point. Not all of them exist on both 32 and

commit f063ea02fba5782099b6730d5733ee44638df8f9
Author: Rusty Russell <rusty@rustcorp.com.au>
Date:   Thu Sep 24 09:34:45 2009 -0600

    cpumask: arch_send_call_function_ipi_mask: powerpc
    
    We're weaning the core code off handing cpumask's around on-stack.
    This introduces arch_send_call_function_ipi_mask(), and by defining
    it, the old arch_send_call_function_ipi is defined by the core code.
    
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index c0d3b8af9319..1491bfe822d9 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -146,7 +146,8 @@ extern void smp_generic_take_timebase(void);
 extern struct smp_ops_t *smp_ops;
 
 extern void arch_send_call_function_single_ipi(int cpu);
-extern void arch_send_call_function_ipi(cpumask_t mask);
+extern void arch_send_call_function_ipi_mask(const struct cpumask *mask);
+#define arch_send_call_function_ipi_mask arch_send_call_function_ipi_mask
 
 /* Definitions relative to the secondary CPU spin loop
  * and entry point. Not all of them exist on both 32 and

commit 2d27cfd3286966c04d4192a9db5a6c7ea60eebf1
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Jul 23 23:15:59 2009 +0000

    powerpc: Remaining 64-bit Book3E support
    
    This contains all the bits that didn't fit in previous patches :-) This
    includes the actual exception handlers assembly, the changes to the
    kernel entry, other misc bits and wiring it all up in Kconfig.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index e782f43ee669..c0d3b8af9319 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -153,6 +153,7 @@ extern void arch_send_call_function_ipi(cpumask_t mask);
  * 64-bit but defining them all here doesn't harm
  */
 extern void generic_secondary_smp_init(void);
+extern void generic_secondary_thread_init(void);
 extern unsigned long __secondary_hold_spinloop;
 extern unsigned long __secondary_hold_acknowledge;
 extern char __secondary_hold;

commit cf54dc7cd4f9aab55cd3e1794b0b74c3c88cd1a0
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Thu Jul 23 23:15:28 2009 +0000

    powerpc: Move definitions of secondary CPU spinloop to header file
    
    Those definitions are currently declared extern in the .c file where
    they are used, move them to a header file instead.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index c25f73d1d842..e782f43ee669 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -148,6 +148,15 @@ extern struct smp_ops_t *smp_ops;
 extern void arch_send_call_function_single_ipi(int cpu);
 extern void arch_send_call_function_ipi(cpumask_t mask);
 
+/* Definitions relative to the secondary CPU spin loop
+ * and entry point. Not all of them exist on both 32 and
+ * 64-bit but defining them all here doesn't harm
+ */
+extern void generic_secondary_smp_init(void);
+extern unsigned long __secondary_hold_spinloop;
+extern unsigned long __secondary_hold_acknowledge;
+extern char __secondary_hold;
+
 #endif /* __ASSEMBLY__ */
 
 #endif /* __KERNEL__ */

commit 25ddd738c2ebffb6c2d3cf29c91b986d1bb39c99
Author: Milton Miller <miltonm@bga.com>
Date:   Fri Nov 14 20:11:49 2008 +0000

    powerpc: Provide a separate handler for each IPI action
    
    With the new generic smp call function helpers, I noticed the code in
    smp_message_recv was a single function call in many cases.  While
    getting the message number from the ipi data is easy, we can reduce
    the path length by a function and data-dependent switch by registering
    seperate IPI actions for these simple calls.
    
    Originally I left the ipi action array exposed, but then I realized the
    registration code should be common too.
    
    The three users each had their own name array, so I made a fourth
    to convert all users to use a common one.
    
    Signed-off-by: Milton Miller <miltonm@bga.com>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 1866cec4f967..c25f73d1d842 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -81,6 +81,13 @@ extern int cpu_to_core_id(int cpu);
 #define PPC_MSG_CALL_FUNC_SINGLE	2
 #define PPC_MSG_DEBUGGER_BREAK  3
 
+/*
+ * irq controllers that have dedicated ipis per message and don't
+ * need additional code in the action handler may use this
+ */
+extern int smp_request_message_ipi(int virq, int message);
+extern const char *smp_ipi_name[];
+
 void smp_init_iSeries(void);
 void smp_init_pSeries(void);
 void smp_init_cell(void);

commit 78b5b626fa9048337530cc3ba4ceb9e4ee96a386
Author: Kumar Gala <galak@kernel.crashing.org>
Date:   Fri Oct 10 09:44:33 2008 +0000

    powerpc: Make ppc32 respect the boot cpu id for !CONFIG_SMP
    
    Previously the FDT header field boot_cpuid_phys wasn't actually used
    on ppc32.  Instead the physical boot cpuid was assumed to be 0 for
    !CONFIG_SMP.
    
    Signed-off-by: Kumar Gala <galak@kernel.crashing.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index c092f84302fd..1866cec4f967 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -93,7 +93,7 @@ extern void __cpu_die(unsigned int cpu);
 
 #else
 /* for UP */
-#define hard_smp_processor_id()		0
+#define hard_smp_processor_id()		get_hard_smp_processor_id(0)
 #define smp_setup_cpu_maps()
 
 #endif /* CONFIG_SMP */
@@ -122,6 +122,7 @@ static inline int get_hard_smp_processor_id(int cpu)
 
 static inline void set_hard_smp_processor_id(int cpu, int phys)
 {
+	boot_cpuid_phys = phys;
 }
 #endif /* !CONFIG_SMP */
 #endif /* !CONFIG_PPC64 */

commit 41eba0ad0033967eda346dd833194e96fdf5f405
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Mon Aug 18 14:23:48 2008 +1000

    powerpc: Turn get/set_hard_smp_proccessor_id into inlines
    
    They don't need to be macros, and having them as inline functions
    avoids warnings about unused variables on some configurations when the
    argument isn't evaluated.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
index 4d28e1e4521b..c092f84302fd 100644
--- a/arch/powerpc/include/asm/smp.h
+++ b/arch/powerpc/include/asm/smp.h
@@ -56,9 +56,16 @@ extern int smp_hw_index[];
 
 #define raw_smp_processor_id()	(current_thread_info()->cpu)
 #define hard_smp_processor_id() 	(smp_hw_index[smp_processor_id()])
-#define get_hard_smp_processor_id(cpu)	(smp_hw_index[(cpu)])
-#define set_hard_smp_processor_id(cpu, phys)\
-					(smp_hw_index[(cpu)] = (phys))
+
+static inline int get_hard_smp_processor_id(int cpu)
+{
+	return smp_hw_index[cpu];
+}
+
+static inline void set_hard_smp_processor_id(int cpu, int phys)
+{
+	smp_hw_index[cpu] = phys;
+}
 #endif
 
 DECLARE_PER_CPU(cpumask_t, cpu_sibling_map);
@@ -92,9 +99,15 @@ extern void __cpu_die(unsigned int cpu);
 #endif /* CONFIG_SMP */
 
 #ifdef CONFIG_PPC64
-#define get_hard_smp_processor_id(CPU) (paca[(CPU)].hw_cpu_id)
-#define set_hard_smp_processor_id(CPU, VAL) \
-	do { (paca[(CPU)].hw_cpu_id = (VAL)); } while (0)
+static inline int get_hard_smp_processor_id(int cpu)
+{
+	return paca[cpu].hw_cpu_id;
+}
+
+static inline void set_hard_smp_processor_id(int cpu, int phys)
+{
+	paca[cpu].hw_cpu_id = phys;
+}
 
 extern void smp_release_cpus(void);
 
@@ -102,10 +115,16 @@ extern void smp_release_cpus(void);
 /* 32-bit */
 #ifndef CONFIG_SMP
 extern int boot_cpuid_phys;
-#define get_hard_smp_processor_id(cpu) 	boot_cpuid_phys
-#define set_hard_smp_processor_id(cpu, phys)
-#endif
-#endif
+static inline int get_hard_smp_processor_id(int cpu)
+{
+	return boot_cpuid_phys;
+}
+
+static inline void set_hard_smp_processor_id(int cpu, int phys)
+{
+}
+#endif /* !CONFIG_SMP */
+#endif /* !CONFIG_PPC64 */
 
 extern int smt_enabled_at_boot;
 

commit b8b572e1015f81b4e748417be2629dfe51ab99f9
Author: Stephen Rothwell <sfr@canb.auug.org.au>
Date:   Fri Aug 1 15:20:30 2008 +1000

    powerpc: Move include files to arch/powerpc/include/asm
    
    from include/asm-powerpc.  This is the result of a
    
    mkdir arch/powerpc/include/asm
    git mv include/asm-powerpc/* arch/powerpc/include/asm
    
    Followed by a few documentation/comment fixups and a couple of places
    where <asm-powepc/...> was being used explicitly.  Of the latter only
    one was outside the arch code and it is a driver only built for powerpc.
    
    Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

diff --git a/arch/powerpc/include/asm/smp.h b/arch/powerpc/include/asm/smp.h
new file mode 100644
index 000000000000..4d28e1e4521b
--- /dev/null
+++ b/arch/powerpc/include/asm/smp.h
@@ -0,0 +1,127 @@
+/* 
+ * smp.h: PowerPC-specific SMP code.
+ *
+ * Original was a copy of sparc smp.h.  Now heavily modified
+ * for PPC.
+ *
+ * Copyright (C) 1996 David S. Miller (davem@caip.rutgers.edu)
+ * Copyright (C) 1996-2001 Cort Dougan <cort@fsmlabs.com>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+#ifndef _ASM_POWERPC_SMP_H
+#define _ASM_POWERPC_SMP_H
+#ifdef __KERNEL__
+
+#include <linux/threads.h>
+#include <linux/cpumask.h>
+#include <linux/kernel.h>
+
+#ifndef __ASSEMBLY__
+
+#ifdef CONFIG_PPC64
+#include <asm/paca.h>
+#endif
+#include <asm/percpu.h>
+
+extern int boot_cpuid;
+
+extern void cpu_die(void);
+
+#ifdef CONFIG_SMP
+
+extern void smp_send_debugger_break(int cpu);
+extern void smp_message_recv(int);
+
+DECLARE_PER_CPU(unsigned int, pvr);
+
+#ifdef CONFIG_HOTPLUG_CPU
+extern void fixup_irqs(cpumask_t map);
+int generic_cpu_disable(void);
+int generic_cpu_enable(unsigned int cpu);
+void generic_cpu_die(unsigned int cpu);
+void generic_mach_cpu_die(void);
+#endif
+
+#ifdef CONFIG_PPC64
+#define raw_smp_processor_id()	(local_paca->paca_index)
+#define hard_smp_processor_id() (get_paca()->hw_cpu_id)
+#else
+/* 32-bit */
+extern int smp_hw_index[];
+
+#define raw_smp_processor_id()	(current_thread_info()->cpu)
+#define hard_smp_processor_id() 	(smp_hw_index[smp_processor_id()])
+#define get_hard_smp_processor_id(cpu)	(smp_hw_index[(cpu)])
+#define set_hard_smp_processor_id(cpu, phys)\
+					(smp_hw_index[(cpu)] = (phys))
+#endif
+
+DECLARE_PER_CPU(cpumask_t, cpu_sibling_map);
+DECLARE_PER_CPU(cpumask_t, cpu_core_map);
+extern int cpu_to_core_id(int cpu);
+
+/* Since OpenPIC has only 4 IPIs, we use slightly different message numbers.
+ *
+ * Make sure this matches openpic_request_IPIs in open_pic.c, or what shows up
+ * in /proc/interrupts will be wrong!!! --Troy */
+#define PPC_MSG_CALL_FUNCTION   0
+#define PPC_MSG_RESCHEDULE      1
+#define PPC_MSG_CALL_FUNC_SINGLE	2
+#define PPC_MSG_DEBUGGER_BREAK  3
+
+void smp_init_iSeries(void);
+void smp_init_pSeries(void);
+void smp_init_cell(void);
+void smp_init_celleb(void);
+void smp_setup_cpu_maps(void);
+void smp_setup_cpu_sibling_map(void);
+
+extern int __cpu_disable(void);
+extern void __cpu_die(unsigned int cpu);
+
+#else
+/* for UP */
+#define hard_smp_processor_id()		0
+#define smp_setup_cpu_maps()
+
+#endif /* CONFIG_SMP */
+
+#ifdef CONFIG_PPC64
+#define get_hard_smp_processor_id(CPU) (paca[(CPU)].hw_cpu_id)
+#define set_hard_smp_processor_id(CPU, VAL) \
+	do { (paca[(CPU)].hw_cpu_id = (VAL)); } while (0)
+
+extern void smp_release_cpus(void);
+
+#else
+/* 32-bit */
+#ifndef CONFIG_SMP
+extern int boot_cpuid_phys;
+#define get_hard_smp_processor_id(cpu) 	boot_cpuid_phys
+#define set_hard_smp_processor_id(cpu, phys)
+#endif
+#endif
+
+extern int smt_enabled_at_boot;
+
+extern int smp_mpic_probe(void);
+extern void smp_mpic_setup_cpu(int cpu);
+extern void smp_generic_kick_cpu(int nr);
+
+extern void smp_generic_give_timebase(void);
+extern void smp_generic_take_timebase(void);
+
+extern struct smp_ops_t *smp_ops;
+
+extern void arch_send_call_function_single_ipi(int cpu);
+extern void arch_send_call_function_ipi(cpumask_t mask);
+
+#endif /* __ASSEMBLY__ */
+
+#endif /* __KERNEL__ */
+#endif /* _ASM_POWERPC_SMP_H) */
